cpu-bind=MASK - gn33, task  0  0 [4087193]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 4
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn33
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 4     --machine_rank 0     --main_process_ip gn33     --main_process_port 29500     --num_processes 16     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62950704     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train_curriculum.py"     --rank=64 --learning_rate=4e-7 --total_epochs=3 --beta=0.2 --curriculum_stage=2
-------------------------------------------
[2025-06-10 23:53:46,136] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0610 23:53:48.039000 4087240 torch/distributed/run.py:792] 
W0610 23:53:48.039000 4087240 torch/distributed/run.py:792] *****************************************
W0610 23:53:48.039000 4087240 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0610 23:53:48.039000 4087240 torch/distributed/run.py:792] *****************************************
[2025-06-10 23:53:53,995] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-10 23:53:54,047] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-10 23:53:54,052] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-10 23:53:54,054] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[load_data_curriculum.py]: Training data of type 'bad_lang_examples':    3489
[load_data_curriculum.py]: Training data of type 'short_examples':       699
[load_data_curriculum.py]: Training data of type 'choose_examples':      13379
[load_data_curriculum.py]: Training data of type 'bad_format_examples':  3148
[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *
[load_data_curriculum.py]: Evaluation data size: 953
[load_data_curriculum.py]: Curriculum stage 0 training data size: 4890
[load_data_curriculum.py]: Curriculum stage 1 training data size: 6689
[load_data_curriculum.py]: Curriculum stage 2 training data size: 6690
[load_data.py]: Number of validation examples: 953
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2, curriculum_stage=2)
4e-07
World size: 16
Setting gradient accumulation steps to: 1
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2, curriculum_stage=2)
4e-07
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2, curriculum_stage=2)
4e-07
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2, curriculum_stage=2)
4e-07
Created datasets
Train dataset size: 6690
Validation dataset size: 953
Steps per epoch: 418
Evaluate each 209 steps
[2025-06-10 23:54:00,774] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-10 23:54:00,774] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-06-10 23:54:00,796] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-10 23:54:00,800] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-10 23:54:00,810] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
Loading model from: /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/trained_models/Curriculum_DPO_models/GaMS-9B-DPO-Curri-1
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:24<01:13, 24.38s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:24<01:14, 24.75s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:24<01:14, 24.75s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:24<01:14, 24.75s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:49<00:50, 25.02s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:50<00:50, 25.26s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:50<00:50, 25.32s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:50<00:50, 25.26s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.58s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.77s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.82s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.80s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.78s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.74s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.88s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.88s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.69s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.88s/it]
Loaded model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
[rank2]:[W610 23:55:36.014834716 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s][rank1]:[W610 23:55:36.273707081 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   8%|▊         | 560/6690 [00:00<00:01, 5529.15 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1134/6690 [00:00<00:00, 5650.51 examples/s][rank3]:[W610 23:55:37.478260709 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:  26%|██▌       | 1716/6690 [00:00<00:00, 5712.73 examples/s]Extracting prompt in train dataset:  38%|███▊      | 2569/6690 [00:00<00:00, 5698.36 examples/s]Extracting prompt in train dataset:  47%|████▋     | 3150/6690 [00:00<00:00, 5714.78 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 3730/6690 [00:00<00:00, 5736.77 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 4313/6690 [00:00<00:00, 5762.80 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 5130/6690 [00:00<00:00, 5626.39 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 5712/6690 [00:01<00:00, 5676.85 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 6291/6690 [00:01<00:00, 5706.27 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5627.60 examples/s]
Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   4%|▍         | 297/6690 [00:00<00:02, 2939.27 examples/s]Applying chat template to train dataset:   9%|▉         | 620/6690 [00:00<00:01, 3105.52 examples/s]Applying chat template to train dataset:  14%|█▍        | 946/6690 [00:00<00:01, 3172.86 examples/s]Applying chat template to train dataset:  19%|█▉        | 1268/6690 [00:00<00:01, 3189.18 examples/s]Applying chat template to train dataset:  24%|██▍       | 1593/6690 [00:00<00:01, 3206.79 examples/s]Applying chat template to train dataset:  29%|██▊       | 1919/6690 [00:00<00:01, 3223.35 examples/s]Applying chat template to train dataset:  34%|███▎      | 2244/6690 [00:00<00:01, 3230.52 examples/s]Applying chat template to train dataset:  41%|████      | 2727/6690 [00:00<00:01, 3218.94 examples/s]Applying chat template to train dataset:  46%|████▌     | 3052/6690 [00:00<00:01, 3225.78 examples/s]Applying chat template to train dataset:  50%|█████     | 3378/6690 [00:01<00:01, 3233.39 examples/s]Applying chat template to train dataset:  55%|█████▌    | 3703/6690 [00:01<00:00, 3232.56 examples/s]Applying chat template to train dataset:  60%|██████    | 4030/6690 [00:01<00:00, 3237.34 examples/s]Applying chat template to train dataset:  65%|██████▌   | 4355/6690 [00:01<00:00, 3239.87 examples/s]Applying chat template to train dataset:  72%|███████▏  | 4812/6690 [00:01<00:00, 3161.27 examples/s]Applying chat template to train dataset:  77%|███████▋  | 5137/6690 [00:01<00:00, 3181.88 examples/s]Applying chat template to train dataset:  82%|████████▏ | 5461/6690 [00:01<00:00, 3195.05 examples/s]Applying chat template to train dataset:  86%|████████▋ | 5786/6690 [00:01<00:00, 3208.29 examples/s]Applying chat template to train dataset:  91%|█████████▏| 6111/6690 [00:01<00:00, 3216.87 examples/s]Applying chat template to train dataset:  96%|█████████▌| 6434/6690 [00:02<00:00, 3220.28 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3199.27 examples/s]
Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 36/6690 [00:00<00:19, 349.25 examples/s]Tokenizing train dataset:   1%|          | 83/6690 [00:00<00:16, 411.84 examples/s]Tokenizing train dataset:   2%|▏         | 147/6690 [00:00<00:15, 413.76 examples/s]Tokenizing train dataset:   3%|▎         | 196/6690 [00:00<00:14, 437.18 examples/s]Tokenizing train dataset:   4%|▍         | 263/6690 [00:00<00:14, 437.97 examples/s]Tokenizing train dataset:   5%|▍         | 326/6690 [00:00<00:14, 426.00 examples/s]Tokenizing train dataset:   6%|▌         | 374/6690 [00:00<00:14, 439.41 examples/s]Tokenizing train dataset:   6%|▋         | 420/6690 [00:00<00:14, 437.91 examples/s]Tokenizing train dataset:   7%|▋         | 472/6690 [00:01<00:13, 458.31 examples/s]Tokenizing train dataset:   8%|▊         | 540/6690 [00:01<00:13, 453.66 examples/s]Tokenizing train dataset:   9%|▉         | 589/6690 [00:01<00:13, 455.74 examples/s]Tokenizing train dataset:  10%|▉         | 640/6690 [00:01<00:13, 464.96 examples/s]Tokenizing train dataset:  10%|█         | 687/6690 [00:01<00:13, 461.35 examples/s]Tokenizing train dataset:  11%|█         | 735/6690 [00:01<00:12, 464.29 examples/s]Tokenizing train dataset:  12%|█▏        | 787/6690 [00:01<00:12, 473.94 examples/s]Tokenizing train dataset:  13%|█▎        | 854/6690 [00:01<00:12, 458.79 examples/s]Tokenizing train dataset:  14%|█▎        | 915/6690 [00:02<00:13, 437.55 examples/s]Tokenizing train dataset:  15%|█▍        | 978/6690 [00:02<00:13, 430.43 examples/s]Tokenizing train dataset:  15%|█▌        | 1022/6690 [00:02<00:13, 430.28 examples/s]Tokenizing train dataset:  16%|█▌        | 1073/6690 [00:02<00:12, 445.44 examples/s]Tokenizing train dataset:  17%|█▋        | 1136/6690 [00:02<00:12, 433.74 examples/s]Tokenizing train dataset:  18%|█▊        | 1181/6690 [00:02<00:12, 434.73 examples/s]Tokenizing train dataset:  19%|█▊        | 1242/6690 [00:02<00:12, 421.07 examples/s]Tokenizing train dataset:  19%|█▉        | 1286/6690 [00:02<00:12, 424.16 examples/s]Tokenizing train dataset:  20%|█▉        | 1334/6690 [00:03<00:12, 436.19 examples/s]Tokenizing train dataset:  21%|██        | 1380/6690 [00:03<00:12, 431.94 examples/s]Tokenizing train dataset:  21%|██▏       | 1438/6690 [00:03<00:12, 413.52 examples/s]Tokenizing train dataset:  22%|██▏       | 1501/6690 [00:03<00:12, 411.29 examples/s]Tokenizing train dataset:  23%|██▎       | 1552/6690 [00:03<00:11, 429.29 examples/s]Tokenizing train dataset:  24%|██▍       | 1614/6690 [00:03<00:12, 422.63 examples/s]Tokenizing train dataset:  25%|██▌       | 1680/6690 [00:03<00:11, 422.87 examples/s]Tokenizing train dataset:  26%|██▌       | 1724/6690 [00:03<00:11, 426.03 examples/s]Tokenizing train dataset:  26%|██▋       | 1770/6690 [00:04<00:11, 429.71 examples/s]Tokenizing train dataset:  27%|██▋       | 1837/6690 [00:04<00:11, 430.45 examples/s]Tokenizing train dataset:  28%|██▊       | 1881/6690 [00:04<00:11, 431.21 examples/s]Tokenizing train dataset:  29%|██▉       | 1943/6690 [00:04<00:11, 420.36 examples/s]Tokenizing train dataset:  30%|██▉       | 2000/6690 [00:04<00:11, 403.90 examples/s]Tokenizing train dataset:  31%|███       | 2042/6690 [00:04<00:11, 407.47 examples/s]Tokenizing train dataset:  31%|███       | 2085/6690 [00:04<00:11, 410.08 examples/s]Tokenizing train dataset:  32%|███▏      | 2131/6690 [00:04<00:10, 418.63 examples/s]Tokenizing train dataset:  33%|███▎      | 2180/6690 [00:05<00:10, 433.45 examples/s]Tokenizing train dataset:  33%|███▎      | 2230/6690 [00:05<00:09, 447.75 examples/s]Tokenizing train dataset:  34%|███▍      | 2292/6690 [00:05<00:10, 432.84 examples/s]Tokenizing train dataset:  35%|███▌      | 2360/6690 [00:05<00:09, 433.36 examples/s]Tokenizing train dataset:  36%|███▌      | 2423/6690 [00:05<00:10, 425.08 examples/s]Tokenizing train dataset:  37%|███▋      | 2470/6690 [00:05<00:09, 434.57 examples/s]Tokenizing train dataset:  38%|███▊      | 2514/6690 [00:05<00:09, 433.93 examples/s]Tokenizing train dataset:  38%|███▊      | 2563/6690 [00:05<00:09, 446.01 examples/s]Tokenizing train dataset:  39%|███▉      | 2611/6690 [00:06<00:08, 453.49 examples/s]Tokenizing train dataset:  40%|███▉      | 2670/6690 [00:06<00:09, 425.60 examples/s]Tokenizing train dataset:  41%|████      | 2732/6690 [00:06<00:09, 416.14 examples/s]Tokenizing train dataset:  42%|████▏     | 2791/6690 [00:06<00:09, 405.26 examples/s]Tokenizing train dataset:  42%|████▏     | 2835/6690 [00:06<00:09, 406.46 examples/s]Tokenizing train dataset:  43%|████▎     | 2879/6690 [00:06<00:09, 412.07 examples/s]Tokenizing train dataset:  44%|████▍     | 2928/6690 [00:06<00:08, 428.09 examples/s]Tokenizing train dataset:  44%|████▍     | 2977/6690 [00:06<00:08, 440.83 examples/s]Tokenizing train dataset:  45%|████▌     | 3023/6690 [00:06<00:08, 445.79 examples/s]Tokenizing train dataset:  46%|████▌     | 3075/6690 [00:07<00:07, 463.76 examples/s]Tokenizing train dataset:  47%|████▋     | 3140/6690 [00:07<00:07, 444.19 examples/s]Tokenizing train dataset:  48%|████▊     | 3210/6690 [00:07<00:07, 443.10 examples/s]Tokenizing train dataset:  49%|████▊     | 3256/6690 [00:07<00:07, 442.69 examples/s]Tokenizing train dataset:  50%|████▉     | 3313/6690 [00:07<00:08, 415.44 examples/s]Tokenizing train dataset:  50%|█████     | 3356/6690 [00:07<00:08, 416.54 examples/s]Tokenizing train dataset:  51%|█████     | 3413/6690 [00:07<00:08, 401.91 examples/s]Tokenizing train dataset:  52%|█████▏    | 3470/6690 [00:08<00:08, 389.86 examples/s]Tokenizing train dataset:  53%|█████▎    | 3514/6690 [00:08<00:07, 400.29 examples/s]Tokenizing train dataset:  53%|█████▎    | 3570/6690 [00:08<00:08, 385.39 examples/s]Tokenizing train dataset:  54%|█████▍    | 3610/6690 [00:08<00:08, 378.10 examples/s]Tokenizing train dataset:  55%|█████▍    | 3656/6690 [00:08<00:07, 397.07 examples/s]Tokenizing train dataset:  55%|█████▌    | 3697/6690 [00:08<00:07, 399.77 examples/s]Tokenizing train dataset:  56%|█████▌    | 3747/6690 [00:08<00:07, 373.83 examples/s]Tokenizing train dataset:  57%|█████▋    | 3793/6690 [00:08<00:07, 389.05 examples/s]Tokenizing train dataset:  57%|█████▋    | 3835/6690 [00:09<00:07, 395.12 examples/s]Tokenizing train dataset:  58%|█████▊    | 3880/6690 [00:09<00:06, 406.04 examples/s]Tokenizing train dataset:  59%|█████▊    | 3926/6690 [00:09<00:06, 419.56 examples/s]Tokenizing train dataset:  59%|█████▉    | 3972/6690 [00:09<00:06, 427.09 examples/s]Tokenizing train dataset:  60%|██████    | 4020/6690 [00:09<00:06, 437.69 examples/s]Tokenizing train dataset:  61%|██████    | 4078/6690 [00:09<00:06, 416.24 examples/s]Tokenizing train dataset:  62%|██████▏   | 4125/6690 [00:09<00:06, 426.82 examples/s]Tokenizing train dataset:  62%|██████▏   | 4172/6690 [00:09<00:05, 434.33 examples/s]Tokenizing train dataset:  63%|██████▎   | 4216/6690 [00:09<00:05, 431.88 examples/s]Tokenizing train dataset:  64%|██████▍   | 4279/6690 [00:10<00:05, 425.84 examples/s]Tokenizing train dataset:  65%|██████▍   | 4326/6690 [00:10<00:05, 434.30 examples/s]Tokenizing train dataset:  65%|██████▌   | 4381/6690 [00:10<00:05, 405.19 examples/s]Tokenizing train dataset:  66%|██████▌   | 4425/6690 [00:10<00:05, 412.45 examples/s]Tokenizing train dataset:  67%|██████▋   | 4489/6690 [00:10<00:05, 412.85 examples/s]Tokenizing train dataset:  68%|██████▊   | 4532/6690 [00:10<00:05, 416.46 examples/s]Tokenizing train dataset:  68%|██████▊   | 4576/6690 [00:10<00:05, 420.84 examples/s]Tokenizing train dataset:  69%|██████▉   | 4624/6690 [00:10<00:04, 432.44 examples/s]Tokenizing train dataset:  70%|██████▉   | 4670/6690 [00:10<00:04, 436.89 examples/s]Tokenizing train dataset:  70%|███████   | 4715/6690 [00:11<00:04, 435.88 examples/s]Tokenizing train dataset:  71%|███████   | 4759/6690 [00:11<00:04, 433.42 examples/s]Tokenizing train dataset:  72%|███████▏  | 4815/6690 [00:11<00:04, 405.99 examples/s]Tokenizing train dataset:  73%|███████▎  | 4862/6690 [00:11<00:04, 418.81 examples/s]Tokenizing train dataset:  74%|███████▎  | 4922/6690 [00:11<00:04, 406.12 examples/s]Tokenizing train dataset:  74%|███████▍  | 4967/6690 [00:11<00:04, 414.10 examples/s]Tokenizing train dataset:  75%|███████▌  | 5027/6690 [00:11<00:04, 407.46 examples/s]Tokenizing train dataset:  76%|███████▌  | 5069/6690 [00:11<00:03, 407.54 examples/s]Tokenizing train dataset:  77%|███████▋  | 5130/6690 [00:12<00:03, 397.22 examples/s]Tokenizing train dataset:  77%|███████▋  | 5179/6690 [00:12<00:03, 417.27 examples/s]Tokenizing train dataset:  78%|███████▊  | 5241/6690 [00:12<00:03, 412.41 examples/s]Tokenizing train dataset:  79%|███████▉  | 5285/6690 [00:12<00:03, 417.76 examples/s]Tokenizing train dataset:  80%|███████▉  | 5347/6690 [00:12<00:03, 409.63 examples/s]Tokenizing train dataset:  81%|████████  | 5397/6690 [00:12<00:03, 428.37 examples/s]Tokenizing train dataset:  82%|████████▏ | 5460/6690 [00:12<00:02, 422.20 examples/s]Tokenizing train dataset:  83%|████████▎ | 5522/6690 [00:13<00:02, 417.38 examples/s]Tokenizing train dataset:  83%|████████▎ | 5583/6690 [00:13<00:02, 411.82 examples/s]Tokenizing train dataset:  84%|████████▍ | 5646/6690 [00:13<00:02, 412.23 examples/s]Tokenizing train dataset:  85%|████████▌ | 5688/6690 [00:13<00:02, 411.37 examples/s]Tokenizing train dataset:  86%|████████▌ | 5735/6690 [00:13<00:02, 420.57 examples/s]Tokenizing train dataset:  87%|████████▋ | 5800/6690 [00:13<00:02, 422.19 examples/s]Tokenizing train dataset:  88%|████████▊ | 5858/6690 [00:13<00:02, 404.82 examples/s]Tokenizing train dataset:  88%|████████▊ | 5908/6690 [00:13<00:01, 425.78 examples/s]Tokenizing train dataset:  89%|████████▉ | 5970/6690 [00:14<00:01, 416.34 examples/s]Tokenizing train dataset:  90%|████████▉ | 6014/6690 [00:14<00:01, 416.88 examples/s]Tokenizing train dataset:  91%|█████████ | 6059/6690 [00:14<00:01, 418.61 examples/s]Tokenizing train dataset:  91%|█████████▏| 6112/6690 [00:14<00:01, 442.57 examples/s]Tokenizing train dataset:  92%|█████████▏| 6176/6690 [00:14<00:01, 432.50 examples/s]Tokenizing train dataset:  93%|█████████▎| 6233/6690 [00:14<00:01, 411.08 examples/s]Tokenizing train dataset:  94%|█████████▍| 6293/6690 [00:14<00:00, 403.52 examples/s]Tokenizing train dataset:  95%|█████████▍| 6352/6690 [00:15<00:00, 397.37 examples/s]Tokenizing train dataset:  96%|█████████▌| 6417/6690 [00:15<00:00, 405.25 examples/s]Tokenizing train dataset:  97%|█████████▋| 6458/6690 [00:15<00:00, 406.03 examples/s]Tokenizing train dataset:  97%|█████████▋| 6500/6690 [00:15<00:00, 405.71 examples/s]Tokenizing train dataset:  98%|█████████▊| 6545/6690 [00:15<00:00, 412.21 examples/s]Tokenizing train dataset:  98%|█████████▊| 6589/6690 [00:15<00:00, 410.94 examples/s]Tokenizing train dataset:  99%|█████████▉| 6646/6690 [00:15<00:00, 397.72 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 397.90 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 421.22 examples/s]
[rank0]:[W610 23:55:57.677807926 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  61%|██████    | 579/953 [00:00<00:00, 5746.68 examples/s]Extracting prompt in train dataset:   9%|▊         | 569/6690 [00:00<00:01, 5600.67 examples/s]Extracting prompt in train dataset:   8%|▊         | 564/6690 [00:00<00:01, 5551.08 examples/s]Extracting prompt in train dataset:   9%|▊         | 570/6690 [00:00<00:01, 5559.98 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5673.74 examples/s]
Extracting prompt in train dataset:  17%|█▋        | 1148/6690 [00:00<00:00, 5684.76 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1140/6690 [00:00<00:00, 5638.62 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1140/6690 [00:00<00:00, 5628.94 examples/s]Extracting prompt in train dataset:  26%|██▌       | 1729/6690 [00:00<00:00, 5738.87 examples/s]Extracting prompt in train dataset:  26%|██▌       | 1730/6690 [00:00<00:00, 5723.54 examples/s]Extracting prompt in train dataset:  26%|██▌       | 1730/6690 [00:00<00:00, 5728.83 examples/s]Extracting prompt in train dataset:  39%|███▊      | 2590/6690 [00:00<00:00, 5725.13 examples/s]Extracting prompt in train dataset:  39%|███▊      | 2590/6690 [00:00<00:00, 5721.01 examples/s]Extracting prompt in train dataset:  39%|███▊      | 2590/6690 [00:00<00:00, 5711.86 examples/s]Extracting prompt in train dataset:  48%|████▊     | 3180/6690 [00:00<00:00, 5769.12 examples/s]Extracting prompt in train dataset:  48%|████▊     | 3178/6690 [00:00<00:00, 5761.90 examples/s]Extracting prompt in train dataset:  48%|████▊     | 3240/6690 [00:00<00:00, 5130.91 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 3759/6690 [00:00<00:00, 5775.65 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 3780/6690 [00:00<00:00, 5824.92 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  57%|█████▋    | 3822/6690 [00:00<00:00, 5324.32 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 4346/6690 [00:00<00:00, 5789.81 examples/s]Applying chat template to eval dataset:  33%|███▎      | 316/953 [00:00<00:00, 3127.65 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 4380/6690 [00:00<00:00, 5704.99 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 4380/6690 [00:00<00:00, 5331.00 examples/s]Applying chat template to eval dataset:  68%|██████▊   | 644/953 [00:00<00:00, 3216.17 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 4965/6690 [00:00<00:00, 5748.12 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 5170/6690 [00:00<00:00, 5653.50 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 4964/6690 [00:00<00:00, 5476.94 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3209.64 examples/s]
Extracting prompt in train dataset:  83%|████████▎ | 5545/6690 [00:00<00:00, 5746.36 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 5753/6690 [00:01<00:00, 5701.36 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 5550/6690 [00:01<00:00, 5571.84 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 6339/6690 [00:01<00:00, 5745.27 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 6139/6690 [00:01<00:00, 5663.52 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 6391/6690 [00:01<00:00, 5701.64 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5686.45 examples/s]
Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5672.93 examples/s]
Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5504.94 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 32/953 [00:00<00:03, 298.07 examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing eval dataset:   8%|▊         | 72/953 [00:00<00:03, 266.32 examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   4%|▍         | 287/6690 [00:00<00:02, 2841.92 examples/s]Applying chat template to train dataset:   4%|▍         | 300/6690 [00:00<00:02, 2966.65 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:00<00:03, 264.50 examples/s]Applying chat template to train dataset:   4%|▍         | 291/6690 [00:00<00:02, 2876.72 examples/s]Applying chat template to train dataset:   9%|▉         | 600/6690 [00:00<00:02, 3008.22 examples/s]Applying chat template to train dataset:   9%|▉         | 633/6690 [00:00<00:01, 3174.83 examples/s]Applying chat template to train dataset:   9%|▉         | 611/6690 [00:00<00:01, 3059.43 examples/s]Applying chat template to train dataset:  14%|█▎        | 917/6690 [00:00<00:01, 3079.66 examples/s]Applying chat template to train dataset:  14%|█▍        | 968/6690 [00:00<00:01, 3245.71 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:00<00:03, 257.03 examples/s]Applying chat template to train dataset:  14%|█▍        | 932/6690 [00:00<00:01, 3125.02 examples/s]Applying chat template to train dataset:  18%|█▊        | 1231/6690 [00:00<00:01, 3098.64 examples/s]Applying chat template to train dataset:  19%|█▉        | 1298/6690 [00:00<00:01, 3264.48 examples/s]Applying chat template to train dataset:  19%|█▊        | 1251/6690 [00:00<00:01, 3145.79 examples/s]Tokenizing eval dataset:  18%|█▊        | 176/953 [00:00<00:03, 245.46 examples/s]Applying chat template to train dataset:  23%|██▎       | 1549/6690 [00:00<00:01, 3120.75 examples/s]Applying chat template to train dataset:  24%|██▍       | 1630/6690 [00:00<00:01, 3281.68 examples/s]Applying chat template to train dataset:  23%|██▎       | 1572/6690 [00:00<00:01, 3165.88 examples/s]Applying chat template to train dataset:  28%|██▊       | 1865/6690 [00:00<00:01, 3130.87 examples/s]Applying chat template to train dataset:  29%|██▉       | 1964/6690 [00:00<00:01, 3298.53 examples/s]Tokenizing eval dataset:  22%|██▏       | 213/953 [00:00<00:03, 242.55 examples/s]Applying chat template to train dataset:  28%|██▊       | 1893/6690 [00:00<00:01, 3179.12 examples/s]Applying chat template to train dataset:  33%|███▎      | 2181/6690 [00:00<00:01, 3137.91 examples/s]Tokenizing eval dataset:  28%|██▊       | 270/953 [00:00<00:02, 321.10 examples/s]Applying chat template to train dataset:  33%|███▎      | 2214/6690 [00:00<00:01, 3187.52 examples/s]Applying chat template to train dataset:  37%|███▋      | 2457/6690 [00:00<00:01, 3291.21 examples/s]Tokenizing eval dataset:  35%|███▌      | 335/953 [00:01<00:01, 403.67 examples/s]Applying chat template to train dataset:  40%|███▉      | 2650/6690 [00:00<00:01, 3127.70 examples/s]Applying chat template to train dataset:  40%|████      | 2689/6690 [00:00<00:01, 3174.65 examples/s]Applying chat template to train dataset:  44%|████▍     | 2946/6690 [00:00<00:01, 3277.45 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:01<00:01, 447.67 examples/s]Applying chat template to train dataset:  44%|████▍     | 2966/6690 [00:00<00:01, 3135.35 examples/s]Applying chat template to train dataset:  45%|████▍     | 3009/6690 [00:00<00:01, 3179.73 examples/s]Tokenizing eval dataset:  49%|████▉     | 467/953 [00:01<00:00, 517.63 examples/s]Applying chat template to train dataset:  49%|████▉     | 3282/6690 [00:01<00:01, 3139.42 examples/s]Applying chat template to train dataset:  51%|█████▏    | 3436/6690 [00:01<00:00, 3266.65 examples/s]Applying chat template to train dataset:  50%|████▉     | 3330/6690 [00:01<00:01, 3182.27 examples/s]Tokenizing eval dataset:  55%|█████▌    | 525/953 [00:01<00:00, 531.57 examples/s]Applying chat template to train dataset:  54%|█████▍    | 3598/6690 [00:01<00:00, 3140.37 examples/s]Applying chat template to train dataset:  55%|█████▍    | 3650/6690 [00:01<00:00, 3183.48 examples/s]Applying chat template to train dataset:  59%|█████▊    | 3924/6690 [00:01<00:00, 3256.50 examples/s]Tokenizing eval dataset:  62%|██████▏   | 590/953 [00:01<00:00, 562.17 examples/s]Applying chat template to train dataset:  58%|█████▊    | 3913/6690 [00:01<00:00, 3141.47 examples/s]Applying chat template to train dataset:  59%|█████▉    | 3971/6690 [00:01<00:00, 3188.49 examples/s]Tokenizing eval dataset:  68%|██████▊   | 650/953 [00:01<00:00, 571.59 examples/s]Applying chat template to train dataset:  63%|██████▎   | 4230/6690 [00:01<00:00, 3144.01 examples/s]Applying chat template to train dataset:  66%|██████▌   | 4390/6690 [00:01<00:00, 3181.22 examples/s]Applying chat template to train dataset:  64%|██████▍   | 4291/6690 [00:01<00:00, 3190.08 examples/s]Applying chat template to train dataset:  70%|███████   | 4713/6690 [00:01<00:00, 3190.92 examples/s]Applying chat template to train dataset:  70%|██████▉   | 4675/6690 [00:01<00:00, 3074.57 examples/s]Tokenizing eval dataset:  77%|███████▋  | 734/953 [00:01<00:00, 559.77 examples/s]Applying chat template to train dataset:  71%|███████   | 4743/6690 [00:01<00:00, 3120.10 examples/s]Applying chat template to train dataset:  75%|███████▌  | 5037/6690 [00:01<00:00, 3201.15 examples/s]Applying chat template to train dataset:  75%|███████▍  | 4989/6690 [00:01<00:00, 3090.67 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:01<00:00, 529.99 examples/s]Applying chat template to train dataset:  76%|███████▌  | 5062/6690 [00:01<00:00, 3135.65 examples/s]Applying chat template to train dataset:  80%|████████  | 5360/6690 [00:01<00:00, 3207.81 examples/s]Applying chat template to train dataset:  79%|███████▉  | 5303/6690 [00:01<00:00, 3101.83 examples/s]Applying chat template to train dataset:  80%|████████  | 5381/6690 [00:01<00:00, 3148.97 examples/s]Applying chat template to train dataset:  85%|████████▍ | 5686/6690 [00:01<00:00, 3217.94 examples/s]Applying chat template to train dataset:  84%|████████▍ | 5619/6690 [00:01<00:00, 3115.17 examples/s]Tokenizing eval dataset:  92%|█████████▏| 881/953 [00:02<00:00, 510.97 examples/s]Applying chat template to train dataset:  85%|████████▌ | 5701/6690 [00:01<00:00, 3159.54 examples/s]Applying chat template to train dataset:  90%|████████▉ | 6011/6690 [00:01<00:00, 3223.10 examples/s]Applying chat template to train dataset:  89%|████████▊ | 5933/6690 [00:01<00:00, 3120.22 examples/s]Applying chat template to train dataset:  90%|████████▉ | 6020/6690 [00:01<00:00, 3167.06 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 496.83 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 435.09 examples/s]
Applying chat template to train dataset:  95%|█████████▍| 6339/6690 [00:01<00:00, 3237.05 examples/s]Applying chat template to train dataset:  93%|█████████▎| 6249/6690 [00:02<00:00, 3127.26 examples/s]Applying chat template to train dataset:  95%|█████████▍| 6340/6690 [00:02<00:00, 3171.36 examples/s]Applying chat template to train dataset: 100%|█████████▉| 6670/6690 [00:02<00:00, 3254.02 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3227.55 examples/s]
Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3125.08 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3106.80 examples/s]
Applying chat template to train dataset: 100%|█████████▉| 6660/6690 [00:02<00:00, 3171.22 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3152.25 examples/s]
Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 37/6690 [00:00<00:18, 359.63 examples/s]Tokenizing train dataset:   1%|          | 38/6690 [00:00<00:17, 373.88 examples/s]Tokenizing train dataset:   1%|          | 38/6690 [00:00<00:17, 375.14 examples/s]Tokenizing train dataset:   1%|▏         | 84/6690 [00:00<00:15, 419.15 examples/s]Tokenizing train dataset:   1%|▏         | 88/6690 [00:00<00:15, 434.84 examples/s]Tokenizing train dataset:   1%|▏         | 88/6690 [00:00<00:15, 436.82 examples/s]Tokenizing train dataset:   2%|▏         | 149/6690 [00:00<00:15, 419.04 examples/s]Tokenizing train dataset:   2%|▏         | 153/6690 [00:00<00:15, 426.76 examples/s]Tokenizing train dataset:   2%|▏         | 153/6690 [00:00<00:15, 428.79 examples/s]Tokenizing train dataset:   3%|▎         | 201/6690 [00:00<00:14, 445.98 examples/s]Tokenizing train dataset:   3%|▎         | 203/6690 [00:00<00:14, 446.29 examples/s]Tokenizing train dataset:   3%|▎         | 203/6690 [00:00<00:14, 448.27 examples/s]Tokenizing train dataset:   4%|▎         | 247/6690 [00:00<00:14, 448.08 examples/s]Tokenizing train dataset:   4%|▍         | 254/6690 [00:00<00:14, 456.37 examples/s]Tokenizing train dataset:   4%|▍         | 254/6690 [00:00<00:14, 457.78 examples/s]Tokenizing train dataset:   5%|▍         | 312/6690 [00:00<00:14, 437.12 examples/s]Tokenizing train dataset:   5%|▍         | 317/6690 [00:00<00:14, 440.84 examples/s]Tokenizing train dataset:   5%|▍         | 319/6690 [00:00<00:14, 440.46 examples/s]Tokenizing train dataset:   5%|▌         | 357/6690 [00:00<00:14, 439.18 examples/s]Tokenizing train dataset:   5%|▌         | 365/6690 [00:00<00:14, 449.46 examples/s]Tokenizing train dataset:   6%|▌         | 370/6690 [00:00<00:13, 456.16 examples/s]Tokenizing train dataset:   6%|▌         | 406/6690 [00:00<00:13, 448.89 examples/s]Tokenizing train dataset:   6%|▌         | 412/6690 [00:00<00:13, 451.71 examples/s]Tokenizing train dataset:   7%|▋         | 457/6690 [00:01<00:13, 462.63 examples/s]Tokenizing train dataset:   7%|▋         | 443/6690 [00:00<00:13, 462.99 examples/s]Tokenizing train dataset:   7%|▋         | 462/6690 [00:01<00:13, 463.68 examples/s]Tokenizing train dataset:   8%|▊         | 507/6690 [00:01<00:13, 470.72 examples/s]Tokenizing train dataset:   7%|▋         | 492/6690 [00:01<00:13, 465.80 examples/s]Tokenizing train dataset:   8%|▊         | 510/6690 [00:01<00:13, 465.79 examples/s]Tokenizing train dataset:   8%|▊         | 541/6690 [00:01<00:13, 469.90 examples/s]Tokenizing train dataset:   8%|▊         | 559/6690 [00:01<00:13, 470.30 examples/s]Tokenizing train dataset:   9%|▊         | 581/6690 [00:01<00:12, 470.21 examples/s]Tokenizing train dataset:   9%|▉         | 589/6690 [00:01<00:12, 470.51 examples/s]Tokenizing train dataset:   9%|▉         | 608/6690 [00:01<00:12, 469.91 examples/s]Tokenizing train dataset:   9%|▉         | 630/6690 [00:01<00:12, 468.63 examples/s]Tokenizing train dataset:  10%|▉         | 641/6690 [00:01<00:12, 478.01 examples/s]Tokenizing train dataset:  10%|▉         | 657/6690 [00:01<00:12, 473.81 examples/s]Tokenizing train dataset:  10%|█         | 700/6690 [00:01<00:12, 462.59 examples/s]Tokenizing train dataset:  11%|█         | 705/6690 [00:01<00:12, 474.70 examples/s]Tokenizing train dataset:  10%|█         | 690/6690 [00:01<00:12, 475.05 examples/s]Tokenizing train dataset:  11%|█▏        | 754/6690 [00:01<00:12, 475.98 examples/s]Tokenizing train dataset:  11%|█▏        | 757/6690 [00:01<00:12, 487.05 examples/s]Tokenizing train dataset:  11%|█         | 743/6690 [00:01<00:12, 488.06 examples/s]Tokenizing train dataset:  12%|█▏        | 807/6690 [00:01<00:12, 483.67 examples/s]Tokenizing train dataset:  12%|█▏        | 809/6690 [00:01<00:11, 496.00 examples/s]Tokenizing train dataset:  12%|█▏        | 793/6690 [00:01<00:12, 486.57 examples/s]Tokenizing train dataset:  13%|█▎        | 877/6690 [00:01<00:12, 467.25 examples/s]Tokenizing train dataset:  13%|█▎        | 877/6690 [00:01<00:12, 472.28 examples/s]Tokenizing train dataset:  13%|█▎        | 866/6690 [00:01<00:12, 476.15 examples/s]Tokenizing train dataset:  14%|█▍        | 936/6690 [00:02<00:13, 441.09 examples/s]Tokenizing train dataset:  14%|█▍        | 940/6690 [00:02<00:12, 444.88 examples/s]Tokenizing train dataset:  14%|█▍        | 926/6690 [00:02<00:12, 446.81 examples/s]Tokenizing train dataset:  15%|█▍        | 973/6690 [00:02<00:12, 451.72 examples/s]Tokenizing train dataset:  15%|█▍        | 1003/6690 [00:02<00:12, 439.64 examples/s]Tokenizing train dataset:  15%|█▌        | 1010/6690 [00:02<00:12, 443.59 examples/s]Tokenizing train dataset:  16%|█▌        | 1048/6690 [00:02<00:12, 440.50 examples/s]Tokenizing train dataset:  16%|█▌        | 1039/6690 [00:02<00:12, 444.79 examples/s]Tokenizing train dataset:  16%|█▌        | 1060/6690 [00:02<00:12, 451.28 examples/s]Tokenizing train dataset:  16%|█▋        | 1098/6690 [00:02<00:12, 449.11 examples/s]Tokenizing train dataset:  16%|█▋        | 1088/6690 [00:02<00:12, 450.67 examples/s]Tokenizing train dataset:  17%|█▋        | 1127/6690 [00:02<00:12, 444.99 examples/s]Tokenizing train dataset:  17%|█▋        | 1163/6690 [00:02<00:12, 440.02 examples/s]Tokenizing train dataset:  17%|█▋        | 1155/6690 [00:02<00:12, 443.84 examples/s]Tokenizing train dataset:  18%|█▊        | 1197/6690 [00:02<00:12, 448.90 examples/s]Tokenizing train dataset:  18%|█▊        | 1210/6690 [00:02<00:12, 438.86 examples/s]Tokenizing train dataset:  18%|█▊        | 1203/6690 [00:02<00:12, 446.36 examples/s]Tokenizing train dataset:  19%|█▉        | 1260/6690 [00:02<00:12, 437.29 examples/s]Tokenizing train dataset:  19%|█▉        | 1275/6690 [00:02<00:12, 432.10 examples/s]Tokenizing train dataset:  19%|█▉        | 1268/6690 [00:02<00:12, 438.12 examples/s]Tokenizing train dataset:  20%|█▉        | 1305/6690 [00:02<00:12, 434.90 examples/s]Tokenizing train dataset:  20%|█▉        | 1325/6690 [00:02<00:12, 445.18 examples/s]Tokenizing train dataset:  20%|█▉        | 1317/6690 [00:02<00:11, 448.38 examples/s]Tokenizing train dataset:  20%|██        | 1358/6690 [00:02<00:11, 456.13 examples/s]Tokenizing train dataset:  20%|██        | 1363/6690 [00:02<00:11, 447.44 examples/s]Tokenizing train dataset:  21%|██        | 1389/6690 [00:03<00:12, 434.04 examples/s]Tokenizing train dataset:  21%|██        | 1413/6690 [00:03<00:12, 423.78 examples/s]Tokenizing train dataset:  21%|██        | 1421/6690 [00:03<00:12, 423.56 examples/s]Tokenizing train dataset:  22%|██▏       | 1451/6690 [00:03<00:12, 420.51 examples/s]Tokenizing train dataset:  22%|██▏       | 1457/6690 [00:03<00:12, 423.23 examples/s]Tokenizing train dataset:  22%|██▏       | 1465/6690 [00:03<00:12, 424.54 examples/s]Tokenizing train dataset:  22%|██▏       | 1494/6690 [00:03<00:12, 418.41 examples/s]Tokenizing train dataset:  22%|██▏       | 1500/6690 [00:03<00:12, 421.79 examples/s]Tokenizing train dataset:  23%|██▎       | 1510/6690 [00:03<00:12, 428.63 examples/s]Tokenizing train dataset:  23%|██▎       | 1548/6690 [00:03<00:11, 444.14 examples/s]Tokenizing train dataset:  23%|██▎       | 1552/6690 [00:03<00:11, 442.77 examples/s]Tokenizing train dataset:  23%|██▎       | 1559/6690 [00:03<00:11, 441.38 examples/s]Tokenizing train dataset:  24%|██▍       | 1609/6690 [00:03<00:11, 425.68 examples/s]Tokenizing train dataset:  24%|██▍       | 1617/6690 [00:03<00:11, 435.09 examples/s]Tokenizing train dataset:  24%|██▍       | 1626/6690 [00:03<00:11, 438.21 examples/s]Tokenizing train dataset:  25%|██▍       | 1653/6690 [00:03<00:11, 426.23 examples/s]Tokenizing train dataset:  25%|██▌       | 1683/6690 [00:03<00:11, 431.62 examples/s]Tokenizing train dataset:  25%|██▌       | 1699/6690 [00:03<00:11, 433.99 examples/s]Tokenizing train dataset:  25%|██▌       | 1692/6690 [00:03<00:11, 434.99 examples/s]Tokenizing train dataset:  26%|██▌       | 1730/6690 [00:03<00:11, 436.92 examples/s]Tokenizing train dataset:  26%|██▌       | 1744/6690 [00:03<00:11, 436.38 examples/s]Tokenizing train dataset:  26%|██▌       | 1739/6690 [00:03<00:11, 441.58 examples/s]Tokenizing train dataset:  27%|██▋       | 1777/6690 [00:03<00:11, 442.42 examples/s]Tokenizing train dataset:  27%|██▋       | 1789/6690 [00:04<00:11, 435.13 examples/s]Tokenizing train dataset:  27%|██▋       | 1785/6690 [00:03<00:11, 439.07 examples/s]Tokenizing train dataset:  27%|██▋       | 1836/6690 [00:04<00:11, 439.19 examples/s]Tokenizing train dataset:  27%|██▋       | 1832/6690 [00:04<00:10, 445.61 examples/s]Tokenizing train dataset:  28%|██▊       | 1843/6690 [00:04<00:11, 437.38 examples/s]Tokenizing train dataset:  28%|██▊       | 1890/6690 [00:04<00:10, 443.39 examples/s]Tokenizing train dataset:  28%|██▊       | 1900/6690 [00:04<00:11, 429.15 examples/s]Tokenizing train dataset:  28%|██▊       | 1900/6690 [00:04<00:11, 434.86 examples/s]Tokenizing train dataset:  29%|██▉       | 1953/6690 [00:04<00:11, 429.22 examples/s]Tokenizing train dataset:  29%|██▉       | 1946/6690 [00:04<00:10, 435.03 examples/s]Tokenizing train dataset:  29%|██▉       | 1967/6690 [00:04<00:11, 428.71 examples/s]Tokenizing train dataset:  30%|███       | 2010/6690 [00:04<00:11, 410.75 examples/s]Tokenizing train dataset:  30%|██▉       | 2003/6690 [00:04<00:11, 412.19 examples/s]Tokenizing train dataset:  30%|███       | 2025/6690 [00:04<00:11, 409.87 examples/s]Tokenizing train dataset:  31%|███       | 2053/6690 [00:04<00:11, 414.92 examples/s]Tokenizing train dataset:  31%|███       | 2046/6690 [00:04<00:11, 414.74 examples/s]Tokenizing train dataset:  31%|███       | 2070/6690 [00:04<00:11, 415.04 examples/s]Tokenizing train dataset:  31%|███▏      | 2097/6690 [00:04<00:10, 417.87 examples/s]Tokenizing train dataset:  31%|███       | 2090/6690 [00:04<00:11, 417.56 examples/s]Tokenizing train dataset:  32%|███▏      | 2117/6690 [00:04<00:10, 424.83 examples/s]Tokenizing train dataset:  32%|███▏      | 2147/6690 [00:04<00:10, 434.58 examples/s]Tokenizing train dataset:  32%|███▏      | 2139/6690 [00:04<00:10, 433.77 examples/s]Tokenizing train dataset:  32%|███▏      | 2162/6690 [00:04<00:10, 428.06 examples/s]Tokenizing train dataset:  33%|███▎      | 2196/6690 [00:04<00:10, 446.01 examples/s]Tokenizing train dataset:  33%|███▎      | 2188/6690 [00:04<00:10, 448.19 examples/s]Tokenizing train dataset:  33%|███▎      | 2215/6690 [00:05<00:09, 453.36 examples/s]Tokenizing train dataset:  34%|███▎      | 2247/6690 [00:05<00:09, 457.44 examples/s]Tokenizing train dataset:  33%|███▎      | 2238/6690 [00:05<00:09, 461.28 examples/s]Tokenizing train dataset:  34%|███▍      | 2280/6690 [00:05<00:09, 442.89 examples/s]Tokenizing train dataset:  34%|███▍      | 2300/6690 [00:05<00:10, 437.34 examples/s]Tokenizing train dataset:  35%|███▍      | 2310/6690 [00:05<00:10, 433.52 examples/s]Tokenizing train dataset:  35%|███▌      | 2347/6690 [00:05<00:09, 435.02 examples/s]Tokenizing train dataset:  35%|███▌      | 2347/6690 [00:05<00:09, 440.63 examples/s]Tokenizing train dataset:  35%|███▌      | 2360/6690 [00:05<00:09, 443.78 examples/s]Tokenizing train dataset:  36%|███▌      | 2393/6690 [00:05<00:09, 440.00 examples/s]Tokenizing train dataset:  36%|███▌      | 2395/6690 [00:05<00:09, 445.77 examples/s]Tokenizing train dataset:  36%|███▌      | 2423/6690 [00:05<00:09, 434.32 examples/s]Tokenizing train dataset:  37%|███▋      | 2460/6690 [00:05<00:09, 439.84 examples/s]Tokenizing train dataset:  37%|███▋      | 2471/6690 [00:05<00:09, 442.40 examples/s]Tokenizing train dataset:  37%|███▋      | 2463/6690 [00:05<00:09, 444.52 examples/s]Tokenizing train dataset:  37%|███▋      | 2508/6690 [00:05<00:09, 443.30 examples/s]Tokenizing train dataset:  38%|███▊      | 2518/6690 [00:05<00:09, 442.34 examples/s]Tokenizing train dataset:  38%|███▊      | 2528/6690 [00:05<00:09, 441.11 examples/s]Tokenizing train dataset:  38%|███▊      | 2559/6690 [00:05<00:09, 458.54 examples/s]Tokenizing train dataset:  38%|███▊      | 2571/6690 [00:05<00:08, 462.87 examples/s]Tokenizing train dataset:  39%|███▊      | 2580/6690 [00:05<00:09, 456.62 examples/s]Tokenizing train dataset:  39%|███▉      | 2619/6690 [00:05<00:08, 466.35 examples/s]Tokenizing train dataset:  39%|███▉      | 2608/6690 [00:05<00:08, 463.03 examples/s]Tokenizing train dataset:  39%|███▉      | 2627/6690 [00:05<00:08, 455.28 examples/s]Tokenizing train dataset:  40%|████      | 2678/6690 [00:06<00:09, 436.87 examples/s]Tokenizing train dataset:  40%|███▉      | 2667/6690 [00:05<00:09, 434.14 examples/s]Tokenizing train dataset:  40%|████      | 2687/6690 [00:06<00:09, 432.72 examples/s]Tokenizing train dataset:  41%|████      | 2712/6690 [00:06<00:09, 433.88 examples/s]Tokenizing train dataset:  41%|████      | 2740/6690 [00:06<00:09, 420.73 examples/s]Tokenizing train dataset:  41%|████      | 2748/6690 [00:06<00:09, 420.68 examples/s]Tokenizing train dataset:  41%|████▏     | 2771/6690 [00:06<00:09, 416.56 examples/s]Tokenizing train dataset:  42%|████▏     | 2802/6690 [00:06<00:09, 415.59 examples/s]Tokenizing train dataset:  42%|████▏     | 2806/6690 [00:06<00:09, 406.04 examples/s]Tokenizing train dataset:  42%|████▏     | 2834/6690 [00:06<00:09, 414.58 examples/s]Tokenizing train dataset:  43%|████▎     | 2851/6690 [00:06<00:09, 414.59 examples/s]Tokenizing train dataset:  43%|████▎     | 2869/6690 [00:06<00:09, 421.72 examples/s]Tokenizing train dataset:  43%|████▎     | 2878/6690 [00:06<00:09, 417.32 examples/s]Tokenizing train dataset:  43%|████▎     | 2895/6690 [00:06<00:09, 414.98 examples/s]Tokenizing train dataset:  44%|████▎     | 2917/6690 [00:06<00:08, 432.25 examples/s]Tokenizing train dataset:  44%|████▍     | 2927/6690 [00:06<00:08, 435.00 examples/s]Tokenizing train dataset:  44%|████▍     | 2950/6690 [00:06<00:08, 445.41 examples/s]Tokenizing train dataset:  44%|████▍     | 2967/6690 [00:06<00:08, 442.71 examples/s]Tokenizing train dataset:  44%|████▍     | 2976/6690 [00:06<00:08, 449.39 examples/s]Tokenizing train dataset:  45%|████▍     | 2998/6690 [00:06<00:08, 454.10 examples/s]Tokenizing train dataset:  45%|████▌     | 3016/6690 [00:06<00:08, 451.24 examples/s]Tokenizing train dataset:  45%|████▌     | 3024/6690 [00:06<00:08, 455.55 examples/s]Tokenizing train dataset:  46%|████▌     | 3066/6690 [00:06<00:07, 461.69 examples/s]Tokenizing train dataset:  46%|████▌     | 3071/6690 [00:06<00:07, 463.81 examples/s]Tokenizing train dataset:  46%|████▌     | 3078/6690 [00:06<00:07, 472.33 examples/s]Tokenizing train dataset:  47%|████▋     | 3116/6690 [00:07<00:07, 466.34 examples/s]Tokenizing train dataset:  47%|████▋     | 3119/6690 [00:07<00:07, 463.39 examples/s]Tokenizing train dataset:  47%|████▋     | 3144/6690 [00:07<00:07, 456.20 examples/s]Tokenizing train dataset:  48%|████▊     | 3179/6690 [00:07<00:07, 446.13 examples/s]Tokenizing train dataset:  48%|████▊     | 3184/6690 [00:07<00:07, 440.46 examples/s]Tokenizing train dataset:  48%|████▊     | 3212/6690 [00:07<00:07, 447.22 examples/s]Tokenizing train dataset:  48%|████▊     | 3228/6690 [00:07<00:07, 450.48 examples/s]Tokenizing train dataset:  48%|████▊     | 3234/6690 [00:07<00:07, 451.49 examples/s]Tokenizing train dataset:  49%|████▊     | 3259/6690 [00:07<00:07, 451.93 examples/s]Tokenizing train dataset:  49%|████▉     | 3275/6690 [00:07<00:07, 451.31 examples/s]Tokenizing train dataset:  49%|████▉     | 3298/6690 [00:07<00:07, 438.65 examples/s]Tokenizing train dataset:  50%|████▉     | 3315/6690 [00:07<00:07, 423.00 examples/s]Tokenizing train dataset:  50%|████▉     | 3330/6690 [00:07<00:08, 415.14 examples/s]Tokenizing train dataset:  50%|█████     | 3356/6690 [00:07<00:07, 418.80 examples/s]Tokenizing train dataset:  50%|█████     | 3360/6690 [00:07<00:07, 424.15 examples/s]Tokenizing train dataset:  51%|█████     | 3390/6690 [00:07<00:08, 407.59 examples/s]Tokenizing train dataset:  51%|█████     | 3413/6690 [00:07<00:08, 404.93 examples/s]Tokenizing train dataset:  51%|█████     | 3420/6690 [00:07<00:08, 404.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 3448/6690 [00:07<00:08, 397.37 examples/s]Tokenizing train dataset:  52%|█████▏    | 3470/6690 [00:07<00:08, 393.30 examples/s]Tokenizing train dataset:  52%|█████▏    | 3486/6690 [00:07<00:07, 410.75 examples/s]Tokenizing train dataset:  52%|█████▏    | 3495/6690 [00:07<00:07, 411.35 examples/s]Tokenizing train dataset:  53%|█████▎    | 3515/6690 [00:08<00:07, 402.99 examples/s]Tokenizing train dataset:  53%|█████▎    | 3528/6690 [00:08<00:07, 407.16 examples/s]Tokenizing train dataset:  53%|█████▎    | 3553/6690 [00:08<00:07, 396.37 examples/s]Tokenizing train dataset:  53%|█████▎    | 3570/6690 [00:08<00:08, 388.67 examples/s]Tokenizing train dataset:  54%|█████▎    | 3581/6690 [00:08<00:08, 383.07 examples/s]Tokenizing train dataset:  54%|█████▍    | 3610/6690 [00:08<00:08, 382.52 examples/s]Tokenizing train dataset:  54%|█████▍    | 3610/6690 [00:08<00:08, 380.95 examples/s]Tokenizing train dataset:  54%|█████▍    | 3620/6690 [00:08<00:08, 383.42 examples/s]Tokenizing train dataset:  55%|█████▍    | 3657/6690 [00:08<00:07, 401.50 examples/s]Tokenizing train dataset:  55%|█████▍    | 3657/6690 [00:08<00:07, 401.38 examples/s]Tokenizing train dataset:  55%|█████▍    | 3666/6690 [00:08<00:07, 398.59 examples/s]Tokenizing train dataset:  55%|█████▌    | 3699/6690 [00:08<00:07, 404.70 examples/s]Tokenizing train dataset:  55%|█████▌    | 3699/6690 [00:08<00:07, 403.27 examples/s]Tokenizing train dataset:  56%|█████▌    | 3720/6690 [00:08<00:07, 375.30 examples/s]Tokenizing train dataset:  56%|█████▌    | 3749/6690 [00:08<00:07, 376.67 examples/s]Tokenizing train dataset:  56%|█████▌    | 3748/6690 [00:08<00:07, 371.41 examples/s]Tokenizing train dataset:  56%|█████▌    | 3762/6690 [00:08<00:07, 385.60 examples/s]Tokenizing train dataset:  57%|█████▋    | 3794/6690 [00:08<00:07, 391.09 examples/s]Tokenizing train dataset:  57%|█████▋    | 3793/6690 [00:08<00:07, 388.72 examples/s]Tokenizing train dataset:  57%|█████▋    | 3804/6690 [00:08<00:07, 393.90 examples/s]Tokenizing train dataset:  57%|█████▋    | 3839/6690 [00:08<00:07, 405.37 examples/s]Tokenizing train dataset:  57%|█████▋    | 3835/6690 [00:08<00:07, 396.14 examples/s]Tokenizing train dataset:  58%|█████▊    | 3850/6690 [00:08<00:06, 407.32 examples/s]Tokenizing train dataset:  58%|█████▊    | 3884/6690 [00:08<00:06, 410.98 examples/s]Tokenizing train dataset:  58%|█████▊    | 3880/6690 [00:08<00:06, 407.73 examples/s]Tokenizing train dataset:  58%|█████▊    | 3899/6690 [00:08<00:06, 426.81 examples/s]Tokenizing train dataset:  59%|█████▉    | 3931/6690 [00:09<00:06, 423.97 examples/s]Tokenizing train dataset:  59%|█████▊    | 3928/6690 [00:09<00:06, 421.85 examples/s]Tokenizing train dataset:  59%|█████▉    | 3948/6690 [00:09<00:06, 441.09 examples/s]Tokenizing train dataset:  59%|█████▉    | 3980/6690 [00:09<00:06, 434.99 examples/s]Tokenizing train dataset:  59%|█████▉    | 3976/6690 [00:09<00:06, 433.44 examples/s]Tokenizing train dataset:  60%|█████▉    | 3994/6690 [00:09<00:06, 438.77 examples/s]Tokenizing train dataset:  60%|██████    | 4029/6690 [00:09<00:05, 446.29 examples/s]Tokenizing train dataset:  60%|██████    | 4023/6690 [00:09<00:06, 442.40 examples/s]Tokenizing train dataset:  61%|██████    | 4060/6690 [00:09<00:06, 434.02 examples/s]Tokenizing train dataset:  61%|██████    | 4090/6690 [00:09<00:06, 426.29 examples/s]Tokenizing train dataset:  61%|██████    | 4082/6690 [00:09<00:06, 420.17 examples/s]Tokenizing train dataset:  61%|██████▏   | 4104/6690 [00:09<00:06, 428.48 examples/s]Tokenizing train dataset:  62%|██████▏   | 4136/6690 [00:09<00:05, 434.71 examples/s]Tokenizing train dataset:  62%|██████▏   | 4130/6690 [00:09<00:05, 431.65 examples/s]Tokenizing train dataset:  62%|██████▏   | 4151/6690 [00:09<00:05, 435.63 examples/s]Tokenizing train dataset:  63%|██████▎   | 4182/6690 [00:09<00:05, 440.77 examples/s]Tokenizing train dataset:  62%|██████▏   | 4178/6690 [00:09<00:05, 442.25 examples/s]Tokenizing train dataset:  63%|██████▎   | 4200/6690 [00:09<00:05, 443.41 examples/s]Tokenizing train dataset:  63%|██████▎   | 4227/6690 [00:09<00:05, 435.58 examples/s]Tokenizing train dataset:  63%|██████▎   | 4245/6690 [00:09<00:05, 440.58 examples/s]Tokenizing train dataset:  63%|██████▎   | 4244/6690 [00:09<00:05, 438.67 examples/s]Tokenizing train dataset:  64%|██████▍   | 4292/6690 [00:09<00:05, 430.54 examples/s]Tokenizing train dataset:  64%|██████▍   | 4312/6690 [00:09<00:05, 436.22 examples/s]Tokenizing train dataset:  64%|██████▍   | 4308/6690 [00:09<00:05, 432.27 examples/s]Tokenizing train dataset:  65%|██████▍   | 4340/6690 [00:09<00:05, 439.72 examples/s]Tokenizing train dataset:  65%|██████▌   | 4371/6690 [00:10<00:05, 417.28 examples/s]Tokenizing train dataset:  65%|██████▌   | 4369/6690 [00:10<00:05, 419.65 examples/s]Tokenizing train dataset:  66%|██████▌   | 4398/6690 [00:10<00:05, 416.47 examples/s]Tokenizing train dataset:  66%|██████▋   | 4444/6690 [00:10<00:05, 423.49 examples/s]Tokenizing train dataset:  66%|██████▋   | 4439/6690 [00:10<00:05, 425.73 examples/s]Tokenizing train dataset:  66%|██████▋   | 4435/6690 [00:10<00:05, 422.27 examples/s]Tokenizing train dataset:  67%|██████▋   | 4487/6690 [00:10<00:05, 419.91 examples/s]Tokenizing train dataset:  67%|██████▋   | 4497/6690 [00:10<00:05, 416.28 examples/s]Tokenizing train dataset:  67%|██████▋   | 4500/6690 [00:10<00:05, 413.61 examples/s]Tokenizing train dataset:  68%|██████▊   | 4530/6690 [00:10<00:05, 421.05 examples/s]Tokenizing train dataset:  68%|██████▊   | 4543/6690 [00:10<00:05, 424.68 examples/s]Tokenizing train dataset:  68%|██████▊   | 4550/6690 [00:10<00:05, 427.43 examples/s]Tokenizing train dataset:  68%|██████▊   | 4576/6690 [00:10<00:04, 427.88 examples/s]Tokenizing train dataset:  69%|██████▊   | 4586/6690 [00:10<00:04, 421.75 examples/s]Tokenizing train dataset:  69%|██████▉   | 4624/6690 [00:10<00:04, 440.69 examples/s]Tokenizing train dataset:  69%|██████▉   | 4620/6690 [00:10<00:04, 437.93 examples/s]Tokenizing train dataset:  69%|██████▉   | 4635/6690 [00:10<00:04, 437.41 examples/s]Tokenizing train dataset:  70%|██████▉   | 4670/6690 [00:10<00:04, 445.21 examples/s]Tokenizing train dataset:  70%|██████▉   | 4668/6690 [00:10<00:04, 446.55 examples/s]Tokenizing train dataset:  70%|██████▉   | 4681/6690 [00:10<00:04, 438.95 examples/s]Tokenizing train dataset:  70%|███████   | 4715/6690 [00:10<00:04, 444.19 examples/s]Tokenizing train dataset:  71%|███████   | 4728/6690 [00:10<00:04, 444.68 examples/s]Tokenizing train dataset:  71%|███████   | 4736/6690 [00:10<00:04, 445.53 examples/s]Tokenizing train dataset:  71%|███████   | 4760/6690 [00:10<00:04, 436.11 examples/s]Tokenizing train dataset:  72%|███████▏  | 4790/6690 [00:11<00:04, 415.88 examples/s]Tokenizing train dataset:  72%|███████▏  | 4786/6690 [00:11<00:04, 415.40 examples/s]Tokenizing train dataset:  72%|███████▏  | 4818/6690 [00:11<00:04, 412.00 examples/s]Tokenizing train dataset:  72%|███████▏  | 4840/6690 [00:11<00:04, 429.18 examples/s]Tokenizing train dataset:  72%|███████▏  | 4831/6690 [00:11<00:04, 422.73 examples/s]Tokenizing train dataset:  73%|███████▎  | 4865/6690 [00:11<00:04, 424.05 examples/s]Tokenizing train dataset:  73%|███████▎  | 4877/6690 [00:11<00:04, 429.96 examples/s]Tokenizing train dataset:  73%|███████▎  | 4884/6690 [00:11<00:04, 427.02 examples/s]Tokenizing train dataset:  74%|███████▎  | 4928/6690 [00:11<00:04, 413.69 examples/s]Tokenizing train dataset:  74%|███████▍  | 4937/6690 [00:11<00:04, 414.64 examples/s]Tokenizing train dataset:  74%|███████▍  | 4948/6690 [00:11<00:04, 422.69 examples/s]Tokenizing train dataset:  74%|███████▍  | 4972/6690 [00:11<00:04, 412.59 examples/s]Tokenizing train dataset:  75%|███████▍  | 5016/6690 [00:11<00:03, 418.62 examples/s]Tokenizing train dataset:  75%|███████▍  | 5001/6690 [00:11<00:04, 414.10 examples/s]Tokenizing train dataset:  75%|███████▍  | 5009/6690 [00:11<00:04, 413.71 examples/s]Tokenizing train dataset:  76%|███████▌  | 5063/6690 [00:11<00:03, 410.07 examples/s]Tokenizing train dataset:  76%|███████▌  | 5079/6690 [00:11<00:03, 410.74 examples/s]Tokenizing train dataset:  76%|███████▌  | 5072/6690 [00:11<00:03, 411.65 examples/s]Tokenizing train dataset:  76%|███████▋  | 5105/6690 [00:11<00:03, 409.73 examples/s]Tokenizing train dataset:  76%|███████▋  | 5115/6690 [00:11<00:03, 409.21 examples/s]Tokenizing train dataset:  77%|███████▋  | 5140/6690 [00:11<00:03, 405.46 examples/s]Tokenizing train dataset:  77%|███████▋  | 5157/6690 [00:11<00:03, 409.04 examples/s]Tokenizing train dataset:  78%|███████▊  | 5187/6690 [00:11<00:03, 420.10 examples/s]Tokenizing train dataset:  77%|███████▋  | 5169/6690 [00:12<00:03, 411.72 examples/s]Tokenizing train dataset:  78%|███████▊  | 5207/6690 [00:11<00:03, 428.30 examples/s]Tokenizing train dataset:  78%|███████▊  | 5216/6690 [00:12<00:03, 423.87 examples/s]Tokenizing train dataset:  78%|███████▊  | 5230/6690 [00:12<00:03, 415.15 examples/s]Tokenizing train dataset:  79%|███████▉  | 5276/6690 [00:12<00:03, 421.63 examples/s]Tokenizing train dataset:  79%|███████▉  | 5270/6690 [00:12<00:03, 420.65 examples/s]Tokenizing train dataset:  79%|███████▉  | 5279/6690 [00:12<00:03, 418.11 examples/s]Tokenizing train dataset:  80%|███████▉  | 5338/6690 [00:12<00:03, 410.28 examples/s]Tokenizing train dataset:  80%|███████▉  | 5332/6690 [00:12<00:03, 409.81 examples/s]Tokenizing train dataset:  80%|███████▉  | 5338/6690 [00:12<00:03, 405.69 examples/s]Tokenizing train dataset:  81%|████████  | 5391/6690 [00:12<00:02, 437.71 examples/s]Tokenizing train dataset:  80%|████████  | 5385/6690 [00:12<00:03, 434.64 examples/s]Tokenizing train dataset:  81%|████████  | 5391/6690 [00:12<00:03, 431.66 examples/s]Tokenizing train dataset:  81%|████████▏ | 5452/6690 [00:12<00:02, 422.84 examples/s]Tokenizing train dataset:  81%|████████▏ | 5450/6690 [00:12<00:02, 427.22 examples/s]Tokenizing train dataset:  81%|████████▏ | 5450/6690 [00:12<00:02, 413.56 examples/s]Tokenizing train dataset:  82%|████████▏ | 5497/6690 [00:12<00:02, 425.37 examples/s]Tokenizing train dataset:  82%|████████▏ | 5497/6690 [00:12<00:02, 430.60 examples/s]Tokenizing train dataset:  82%|████████▏ | 5497/6690 [00:12<00:02, 419.86 examples/s]Tokenizing train dataset:  83%|████████▎ | 5540/6690 [00:12<00:02, 412.74 examples/s]Tokenizing train dataset:  83%|████████▎ | 5560/6690 [00:12<00:02, 413.05 examples/s]Tokenizing train dataset:  83%|████████▎ | 5560/6690 [00:12<00:02, 416.73 examples/s]Tokenizing train dataset:  83%|████████▎ | 5582/6690 [00:13<00:02, 408.19 examples/s]Tokenizing train dataset:  84%|████████▍ | 5622/6690 [00:13<00:02, 410.26 examples/s]Tokenizing train dataset:  84%|████████▍ | 5624/6690 [00:12<00:02, 413.64 examples/s]Tokenizing train dataset:  84%|████████▍ | 5646/6690 [00:13<00:02, 411.24 examples/s]Tokenizing train dataset:  85%|████████▍ | 5667/6690 [00:13<00:02, 417.13 examples/s]Tokenizing train dataset:  85%|████████▍ | 5669/6690 [00:13<00:02, 418.70 examples/s]Tokenizing train dataset:  85%|████████▌ | 5688/6690 [00:13<00:02, 410.54 examples/s]Tokenizing train dataset:  85%|████████▌ | 5710/6690 [00:13<00:02, 416.98 examples/s]Tokenizing train dataset:  85%|████████▌ | 5712/6690 [00:13<00:02, 417.22 examples/s]Tokenizing train dataset:  86%|████████▌ | 5735/6690 [00:13<00:02, 421.87 examples/s]Tokenizing train dataset:  86%|████████▌ | 5759/6690 [00:13<00:02, 430.43 examples/s]Tokenizing train dataset:  86%|████████▌ | 5762/6690 [00:13<00:02, 430.60 examples/s]Tokenizing train dataset:  87%|████████▋ | 5808/6690 [00:13<00:02, 435.03 examples/s]Tokenizing train dataset:  87%|████████▋ | 5821/6690 [00:13<00:02, 422.13 examples/s]Tokenizing train dataset:  87%|████████▋ | 5802/6690 [00:13<00:02, 424.46 examples/s]Tokenizing train dataset:  88%|████████▊ | 5865/6690 [00:13<00:02, 411.73 examples/s]Tokenizing train dataset:  88%|████████▊ | 5881/6690 [00:13<00:01, 406.13 examples/s]Tokenizing train dataset:  88%|████████▊ | 5860/6690 [00:13<00:02, 403.62 examples/s]Tokenizing train dataset:  88%|████████▊ | 5915/6690 [00:13<00:01, 429.12 examples/s]Tokenizing train dataset:  88%|████████▊ | 5913/6690 [00:13<00:01, 430.32 examples/s]Tokenizing train dataset:  89%|████████▊ | 5932/6690 [00:13<00:01, 426.01 examples/s]Tokenizing train dataset:  89%|████████▉ | 5976/6690 [00:13<00:01, 423.06 examples/s]Tokenizing train dataset:  89%|████████▉ | 5977/6690 [00:13<00:01, 416.92 examples/s]Tokenizing train dataset:  89%|████████▉ | 5976/6690 [00:13<00:01, 416.92 examples/s]Tokenizing train dataset:  90%|█████████ | 6021/6690 [00:13<00:01, 428.09 examples/s]Tokenizing train dataset:  90%|█████████ | 6023/6690 [00:13<00:01, 422.60 examples/s]Tokenizing train dataset:  90%|█████████ | 6021/6690 [00:14<00:01, 422.44 examples/s]Tokenizing train dataset:  91%|█████████ | 6066/6690 [00:14<00:01, 431.84 examples/s]Tokenizing train dataset:  91%|█████████ | 6071/6690 [00:14<00:01, 433.04 examples/s]Tokenizing train dataset:  91%|█████████ | 6066/6690 [00:14<00:01, 427.54 examples/s]Tokenizing train dataset:  91%|█████████▏| 6120/6690 [00:14<00:01, 457.62 examples/s]Tokenizing train dataset:  92%|█████████▏| 6124/6690 [00:14<00:01, 456.49 examples/s]Tokenizing train dataset:  91%|█████████▏| 6120/6690 [00:14<00:01, 453.22 examples/s]Tokenizing train dataset:  92%|█████████▏| 6184/6690 [00:14<00:01, 444.00 examples/s]Tokenizing train dataset:  93%|█████████▎| 6189/6690 [00:14<00:01, 446.36 examples/s]Tokenizing train dataset:  92%|█████████▏| 6184/6690 [00:14<00:01, 441.31 examples/s]Tokenizing train dataset:  93%|█████████▎| 6238/6690 [00:14<00:01, 410.32 examples/s]Tokenizing train dataset:  93%|█████████▎| 6240/6690 [00:14<00:01, 404.82 examples/s]Tokenizing train dataset:  93%|█████████▎| 6237/6690 [00:14<00:01, 408.95 examples/s]Tokenizing train dataset:  94%|█████████▍| 6285/6690 [00:14<00:00, 413.01 examples/s]Tokenizing train dataset:  94%|█████████▍| 6301/6690 [00:14<00:00, 411.60 examples/s]Tokenizing train dataset:  94%|█████████▍| 6301/6690 [00:14<00:00, 409.30 examples/s]Tokenizing train dataset:  95%|█████████▍| 6345/6690 [00:14<00:00, 400.59 examples/s]Tokenizing train dataset:  95%|█████████▌| 6358/6690 [00:14<00:00, 399.42 examples/s]Tokenizing train dataset:  95%|█████████▌| 6358/6690 [00:14<00:00, 397.25 examples/s]Tokenizing train dataset:  96%|█████████▌| 6400/6690 [00:14<00:00, 398.11 examples/s]Tokenizing train dataset:  96%|█████████▌| 6408/6690 [00:14<00:00, 404.51 examples/s]Tokenizing train dataset:  96%|█████████▋| 6447/6690 [00:14<00:00, 415.46 examples/s]Tokenizing train dataset:  96%|█████████▌| 6425/6690 [00:15<00:00, 409.51 examples/s]Tokenizing train dataset:  96%|█████████▋| 6452/6690 [00:14<00:00, 411.70 examples/s]Tokenizing train dataset:  97%|█████████▋| 6490/6690 [00:15<00:00, 414.30 examples/s]Tokenizing train dataset:  97%|█████████▋| 6467/6690 [00:15<00:00, 407.97 examples/s]Tokenizing train dataset:  97%|█████████▋| 6496/6690 [00:15<00:00, 416.99 examples/s]Tokenizing train dataset:  98%|█████████▊| 6534/6690 [00:15<00:00, 417.46 examples/s]Tokenizing train dataset:  97%|█████████▋| 6510/6690 [00:15<00:00, 411.74 examples/s]Tokenizing train dataset:  98%|█████████▊| 6539/6690 [00:15<00:00, 416.30 examples/s]Tokenizing train dataset:  98%|█████████▊| 6552/6690 [00:15<00:00, 409.35 examples/s]Tokenizing train dataset:  99%|█████████▊| 6598/6690 [00:15<00:00, 414.33 examples/s]Tokenizing train dataset:  99%|█████████▊| 6601/6690 [00:15<00:00, 411.43 examples/s]Tokenizing train dataset:  99%|█████████▊| 6596/6690 [00:15<00:00, 411.64 examples/s]Tokenizing train dataset: 100%|█████████▉| 6657/6690 [00:15<00:00, 399.71 examples/s]Tokenizing train dataset: 100%|█████████▉| 6658/6690 [00:15<00:00, 397.72 examples/s]Tokenizing train dataset:  99%|█████████▉| 6653/6690 [00:15<00:00, 396.65 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 429.31 examples/s]
Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 430.29 examples/s]
Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 426.30 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  59%|█████▉    | 562/953 [00:00<00:00, 5586.30 examples/s]Extracting prompt in eval dataset:  60%|█████▉    | 571/953 [00:00<00:00, 5626.16 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5515.37 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5606.28 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4275.08 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4274.11 examples/s]

Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  33%|███▎      | 314/953 [00:00<00:00, 3107.35 examples/s]Applying chat template to eval dataset:  32%|███▏      | 302/953 [00:00<00:00, 2974.01 examples/s]Applying chat template to eval dataset:  33%|███▎      | 312/953 [00:00<00:00, 3078.94 examples/s]Applying chat template to eval dataset:  66%|██████▋   | 633/953 [00:00<00:00, 3141.44 examples/s]Applying chat template to eval dataset:  64%|██████▍   | 610/953 [00:00<00:00, 3027.11 examples/s]Applying chat template to eval dataset:  66%|██████▋   | 632/953 [00:00<00:00, 3144.16 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3146.31 examples/s]
Applying chat template to eval dataset:  97%|█████████▋| 923/953 [00:00<00:00, 3069.66 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3037.17 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3173.48 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3140.30 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 29/953 [00:00<00:03, 285.27 examples/s]Tokenizing eval dataset:   3%|▎         | 32/953 [00:00<00:03, 292.38 examples/s]Tokenizing eval dataset:   3%|▎         | 32/953 [00:00<00:03, 294.02 examples/s]Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:03, 257.59 examples/s]Tokenizing eval dataset:   7%|▋         | 70/953 [00:00<00:03, 261.29 examples/s]Tokenizing eval dataset:   7%|▋         | 70/953 [00:00<00:03, 262.31 examples/s]Tokenizing eval dataset:  10%|█         | 96/953 [00:00<00:03, 260.32 examples/s]Tokenizing eval dataset:  10%|█         | 97/953 [00:00<00:03, 259.53 examples/s]Tokenizing eval dataset:  10%|█         | 97/953 [00:00<00:03, 260.80 examples/s]Tokenizing eval dataset:  14%|█▍        | 135/953 [00:00<00:03, 254.16 examples/s]Tokenizing eval dataset:  14%|█▍        | 136/953 [00:00<00:03, 254.65 examples/s]Tokenizing eval dataset:  14%|█▍        | 136/953 [00:00<00:03, 256.31 examples/s]Tokenizing eval dataset:  18%|█▊        | 169/953 [00:00<00:03, 240.29 examples/s]Tokenizing eval dataset:  18%|█▊        | 170/953 [00:00<00:03, 237.87 examples/s]Tokenizing eval dataset:  18%|█▊        | 170/953 [00:00<00:03, 239.30 examples/s]Tokenizing eval dataset:  22%|██▏       | 207/953 [00:00<00:03, 237.46 examples/s]Tokenizing eval dataset:  22%|██▏       | 206/953 [00:00<00:03, 236.39 examples/s]Tokenizing eval dataset:  22%|██▏       | 207/953 [00:00<00:03, 237.99 examples/s]Tokenizing eval dataset:  26%|██▌       | 250/953 [00:00<00:02, 284.29 examples/s]Tokenizing eval dataset:  26%|██▌       | 250/953 [00:00<00:02, 283.19 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:00<00:02, 289.25 examples/s]Tokenizing eval dataset:  33%|███▎      | 312/953 [00:01<00:01, 368.54 examples/s]Tokenizing eval dataset:  33%|███▎      | 310/953 [00:01<00:01, 363.93 examples/s]Tokenizing eval dataset:  33%|███▎      | 312/953 [00:01<00:01, 365.53 examples/s]Tokenizing eval dataset:  38%|███▊      | 363/953 [00:01<00:01, 403.60 examples/s]Tokenizing eval dataset:  38%|███▊      | 363/953 [00:01<00:01, 401.69 examples/s]Tokenizing eval dataset:  38%|███▊      | 363/953 [00:01<00:01, 402.32 examples/s]Tokenizing eval dataset:  44%|████▍     | 419/953 [00:01<00:01, 444.75 examples/s]Tokenizing eval dataset:  44%|████▍     | 419/953 [00:01<00:01, 442.52 examples/s]Tokenizing eval dataset:  44%|████▍     | 419/953 [00:01<00:01, 443.84 examples/s]Tokenizing eval dataset:  50%|█████     | 477/953 [00:01<00:00, 479.77 examples/s]Tokenizing eval dataset:  50%|█████     | 477/953 [00:01<00:00, 476.80 examples/s]Tokenizing eval dataset:  50%|█████     | 477/953 [00:01<00:00, 478.96 examples/s]Tokenizing eval dataset:  56%|█████▌    | 529/953 [00:01<00:00, 488.54 examples/s]Tokenizing eval dataset:  55%|█████▌    | 528/953 [00:01<00:00, 483.65 examples/s]Tokenizing eval dataset:  56%|█████▌    | 529/953 [00:01<00:00, 488.68 examples/s]Tokenizing eval dataset:  61%|██████▏   | 586/953 [00:01<00:00, 511.06 examples/s]Tokenizing eval dataset:  61%|██████▏   | 586/953 [00:01<00:00, 506.17 examples/s]Tokenizing eval dataset:  61%|██████▏   | 586/953 [00:01<00:00, 509.54 examples/s]Tokenizing eval dataset:  67%|██████▋   | 643/953 [00:01<00:00, 523.03 examples/s]Tokenizing eval dataset:  67%|██████▋   | 643/953 [00:01<00:00, 518.27 examples/s]Tokenizing eval dataset:  67%|██████▋   | 643/953 [00:01<00:00, 523.29 examples/s]Tokenizing eval dataset:  75%|███████▌  | 719/953 [00:01<00:00, 506.98 examples/s]Tokenizing eval dataset:  75%|███████▌  | 718/953 [00:01<00:00, 503.60 examples/s]Tokenizing eval dataset:  75%|███████▌  | 719/953 [00:01<00:00, 508.71 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:01<00:00, 470.00 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:01<00:00, 470.81 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:01<00:00, 474.12 examples/s]Tokenizing eval dataset:  89%|████████▉ | 848/953 [00:02<00:00, 449.59 examples/s]Tokenizing eval dataset:  89%|████████▉ | 848/953 [00:02<00:00, 449.89 examples/s]Tokenizing eval dataset:  89%|████████▉ | 848/953 [00:02<00:00, 453.85 examples/s]Tokenizing eval dataset:  95%|█████████▌| 908/953 [00:02<00:00, 428.65 examples/s]Tokenizing eval dataset:  95%|█████████▌| 908/953 [00:02<00:00, 428.77 examples/s]Tokenizing eval dataset:  95%|█████████▌| 910/953 [00:02<00:00, 432.27 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 424.27 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 396.76 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 423.62 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 395.54 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 398.28 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4778783321380615 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3670923709869385 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3253064155578613 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.452057361602783 seconds
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250610_235652-rsv4ledi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Curri-2-DPO_r-64_lr-4e-07_e-3_b-0.2
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/rsv4ledi
  0%|          | 0/1257 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/1257 [00:12<4:20:47, 12.46s/it]  0%|          | 2/1257 [00:15<2:30:09,  7.18s/it]  0%|          | 3/1257 [00:19<1:56:29,  5.57s/it]  0%|          | 4/1257 [00:22<1:37:21,  4.66s/it]  0%|          | 5/1257 [00:26<1:32:22,  4.43s/it]  0%|          | 6/1257 [00:30<1:26:58,  4.17s/it]  1%|          | 7/1257 [00:34<1:24:12,  4.04s/it]  1%|          | 8/1257 [00:38<1:21:54,  3.93s/it]  1%|          | 9/1257 [00:41<1:19:59,  3.85s/it]  1%|          | 10/1257 [00:45<1:22:40,  3.98s/it]                                                   {'loss': 0.6944, 'grad_norm': 44.944618225097656, 'learning_rate': 8.61244019138756e-09, 'rewards/chosen': -0.00853881798684597, 'rewards/rejected': -0.015456771478056908, 'rewards/accuracies': 0.3125, 'rewards/margins': 0.006893920712172985, 'logps/chosen': -107.19999694824219, 'logps/rejected': -115.5999984741211, 'logits/chosen': -7.03125, 'logits/rejected': -7.125, 'epoch': 0.02}
  1%|          | 10/1257 [00:45<1:22:40,  3.98s/it]  1%|          | 11/1257 [00:49<1:21:54,  3.94s/it]  1%|          | 12/1257 [00:53<1:20:48,  3.89s/it]  1%|          | 13/1257 [00:57<1:19:15,  3.82s/it]  1%|          | 14/1257 [01:01<1:19:54,  3.86s/it]  1%|          | 15/1257 [01:05<1:20:16,  3.88s/it]  1%|▏         | 16/1257 [01:09<1:20:41,  3.90s/it]  1%|▏         | 17/1257 [01:11<1:13:42,  3.57s/it]  1%|▏         | 18/1257 [01:16<1:17:41,  3.76s/it]  2%|▏         | 19/1257 [01:20<1:20:46,  3.91s/it]  2%|▏         | 20/1257 [01:23<1:15:04,  3.64s/it]                                                   {'loss': 0.7079, 'grad_norm': 52.83094024658203, 'learning_rate': 1.818181818181818e-08, 'rewards/chosen': 0.00213623046875, 'rewards/rejected': 0.01659545861184597, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.01449432410299778, 'logps/chosen': -134.10000610351562, 'logps/rejected': -169.39999389648438, 'logits/chosen': -7.09375, 'logits/rejected': -6.971875190734863, 'epoch': 0.05}
  2%|▏         | 20/1257 [01:23<1:15:04,  3.64s/it]  2%|▏         | 21/1257 [01:27<1:18:09,  3.79s/it]  2%|▏         | 22/1257 [01:30<1:14:39,  3.63s/it]  2%|▏         | 23/1257 [01:34<1:12:41,  3.53s/it]  2%|▏         | 24/1257 [01:38<1:16:08,  3.70s/it]  2%|▏         | 25/1257 [01:41<1:16:37,  3.73s/it]  2%|▏         | 26/1257 [01:44<1:11:52,  3.50s/it]  2%|▏         | 27/1257 [01:48<1:15:00,  3.66s/it]  2%|▏         | 28/1257 [01:51<1:09:50,  3.41s/it]  2%|▏         | 29/1257 [01:55<1:13:52,  3.61s/it]  2%|▏         | 30/1257 [01:59<1:11:15,  3.48s/it]                                                   {'loss': 0.7046, 'grad_norm': 51.94615173339844, 'learning_rate': 2.7751196172248803e-08, 'rewards/chosen': -0.0066818236373364925, 'rewards/rejected': 0.0057083130814135075, 'rewards/accuracies': 0.4437499940395355, 'rewards/margins': -0.012310028076171875, 'logps/chosen': -143.77499389648438, 'logps/rejected': -158.0500030517578, 'logits/chosen': -6.918749809265137, 'logits/rejected': -6.893750190734863, 'epoch': 0.07}
  2%|▏         | 30/1257 [01:59<1:11:15,  3.48s/it]  2%|▏         | 31/1257 [02:02<1:09:40,  3.41s/it]  3%|▎         | 32/1257 [02:06<1:13:30,  3.60s/it]  3%|▎         | 33/1257 [02:10<1:15:35,  3.71s/it]  3%|▎         | 34/1257 [02:13<1:09:53,  3.43s/it]  3%|▎         | 35/1257 [02:16<1:08:47,  3.38s/it]  3%|▎         | 36/1257 [02:19<1:05:21,  3.21s/it]  3%|▎         | 37/1257 [02:22<1:03:08,  3.11s/it]  3%|▎         | 38/1257 [02:25<1:08:16,  3.36s/it]  3%|▎         | 39/1257 [02:30<1:13:09,  3.60s/it]  3%|▎         | 40/1257 [02:33<1:09:34,  3.43s/it]                                                   {'loss': 0.7489, 'grad_norm': 51.53031539916992, 'learning_rate': 3.7320574162679424e-08, 'rewards/chosen': -0.013140869326889515, 'rewards/rejected': 0.050514984875917435, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': -0.06346626579761505, 'logps/chosen': -130.0, 'logps/rejected': -158.89999389648438, 'logits/chosen': -7.28125, 'logits/rejected': -7.21875, 'epoch': 0.1}
  3%|▎         | 40/1257 [02:33<1:09:34,  3.43s/it]  3%|▎         | 41/1257 [02:36<1:09:22,  3.42s/it]  3%|▎         | 42/1257 [02:40<1:12:31,  3.58s/it]  3%|▎         | 43/1257 [02:43<1:08:25,  3.38s/it]  4%|▎         | 44/1257 [02:46<1:06:15,  3.28s/it]  4%|▎         | 45/1257 [02:50<1:12:02,  3.57s/it]  4%|▎         | 46/1257 [02:54<1:11:42,  3.55s/it]  4%|▎         | 47/1257 [02:58<1:13:30,  3.64s/it]  4%|▍         | 48/1257 [03:00<1:08:51,  3.42s/it]  4%|▍         | 49/1257 [03:04<1:10:24,  3.50s/it]  4%|▍         | 50/1257 [03:08<1:13:03,  3.63s/it]                                                   {'loss': 0.692, 'grad_norm': 44.005462646484375, 'learning_rate': 4.688995215311005e-08, 'rewards/chosen': 0.00988922081887722, 'rewards/rejected': 0.0009246825939044356, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.008975219912827015, 'logps/chosen': -107.5999984741211, 'logps/rejected': -136.10000610351562, 'logits/chosen': -7.103125095367432, 'logits/rejected': -7.034375190734863, 'epoch': 0.12}
  4%|▍         | 50/1257 [03:08<1:13:03,  3.63s/it]  4%|▍         | 51/1257 [03:12<1:11:33,  3.56s/it]  4%|▍         | 52/1257 [03:15<1:09:42,  3.47s/it]  4%|▍         | 53/1257 [03:18<1:10:43,  3.52s/it]  4%|▍         | 54/1257 [03:23<1:15:15,  3.75s/it]  4%|▍         | 55/1257 [03:27<1:18:30,  3.92s/it]  4%|▍         | 56/1257 [03:31<1:18:18,  3.91s/it]  5%|▍         | 57/1257 [03:35<1:19:41,  3.98s/it]  5%|▍         | 58/1257 [03:39<1:20:31,  4.03s/it]  5%|▍         | 59/1257 [03:43<1:16:12,  3.82s/it]  5%|▍         | 60/1257 [03:46<1:15:39,  3.79s/it]                                                   {'loss': 0.7126, 'grad_norm': 44.90645980834961, 'learning_rate': 5.645933014354066e-08, 'rewards/chosen': -0.01728668250143528, 'rewards/rejected': 0.0064025879837572575, 'rewards/accuracies': 0.375, 'rewards/margins': -0.023712158203125, 'logps/chosen': -98.5999984741211, 'logps/rejected': -131.9499969482422, 'logits/chosen': -7.162499904632568, 'logits/rejected': -6.9375, 'epoch': 0.14}
  5%|▍         | 60/1257 [03:46<1:15:39,  3.79s/it]  5%|▍         | 61/1257 [03:50<1:16:49,  3.85s/it]  5%|▍         | 62/1257 [03:54<1:14:24,  3.74s/it]  5%|▌         | 63/1257 [03:57<1:08:49,  3.46s/it]  5%|▌         | 64/1257 [04:00<1:06:27,  3.34s/it]  5%|▌         | 65/1257 [04:03<1:05:50,  3.31s/it]  5%|▌         | 66/1257 [04:06<1:04:53,  3.27s/it]  5%|▌         | 67/1257 [04:10<1:10:17,  3.54s/it]  5%|▌         | 68/1257 [04:14<1:12:38,  3.67s/it]  5%|▌         | 69/1257 [04:18<1:14:27,  3.76s/it]  6%|▌         | 70/1257 [04:22<1:16:22,  3.86s/it]                                                   {'loss': 0.6988, 'grad_norm': 54.76704406738281, 'learning_rate': 6.602870813397129e-08, 'rewards/chosen': 0.004475402645766735, 'rewards/rejected': -0.00018577575974632055, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.004649353213608265, 'logps/chosen': -168.10000610351562, 'logps/rejected': -197.64999389648438, 'logits/chosen': -7.025000095367432, 'logits/rejected': -6.881249904632568, 'epoch': 0.17}
  6%|▌         | 70/1257 [04:22<1:16:22,  3.86s/it]  6%|▌         | 71/1257 [04:26<1:18:08,  3.95s/it]  6%|▌         | 72/1257 [04:30<1:18:00,  3.95s/it]  6%|▌         | 73/1257 [04:34<1:15:55,  3.85s/it]  6%|▌         | 74/1257 [04:37<1:11:53,  3.65s/it]  6%|▌         | 75/1257 [04:41<1:13:12,  3.72s/it]  6%|▌         | 76/1257 [04:45<1:13:25,  3.73s/it]  6%|▌         | 77/1257 [04:48<1:11:01,  3.61s/it]  6%|▌         | 78/1257 [04:52<1:11:59,  3.66s/it]  6%|▋         | 79/1257 [04:56<1:12:58,  3.72s/it]  6%|▋         | 80/1257 [04:59<1:10:33,  3.60s/it]                                                   {'loss': 0.6904, 'grad_norm': 43.82582092285156, 'learning_rate': 7.559808612440191e-08, 'rewards/chosen': 0.0074142455123364925, 'rewards/rejected': -0.01744689978659153, 'rewards/accuracies': 0.4937500059604645, 'rewards/margins': 0.02496337890625, 'logps/chosen': -125.5, 'logps/rejected': -142.89999389648438, 'logits/chosen': -7.137499809265137, 'logits/rejected': -7.065625190734863, 'epoch': 0.19}
  6%|▋         | 80/1257 [04:59<1:10:33,  3.60s/it]  6%|▋         | 81/1257 [05:02<1:07:01,  3.42s/it]  7%|▋         | 82/1257 [05:06<1:09:15,  3.54s/it]  7%|▋         | 83/1257 [05:10<1:11:18,  3.64s/it]  7%|▋         | 84/1257 [05:13<1:10:25,  3.60s/it]  7%|▋         | 85/1257 [05:17<1:12:13,  3.70s/it]  7%|▋         | 86/1257 [05:21<1:13:11,  3.75s/it]  7%|▋         | 87/1257 [05:25<1:11:43,  3.68s/it]  7%|▋         | 88/1257 [05:28<1:12:25,  3.72s/it]  7%|▋         | 89/1257 [05:31<1:05:48,  3.38s/it]  7%|▋         | 90/1257 [05:35<1:08:58,  3.55s/it]                                                   {'loss': 0.7344, 'grad_norm': 177.43255615234375, 'learning_rate': 8.516746411483253e-08, 'rewards/chosen': -0.00547866802662611, 'rewards/rejected': 0.035736083984375, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.0413665771484375, 'logps/chosen': -137.89999389648438, 'logps/rejected': -148.6999969482422, 'logits/chosen': -7.034375190734863, 'logits/rejected': -6.928124904632568, 'epoch': 0.21}
  7%|▋         | 90/1257 [05:35<1:08:58,  3.55s/it]  7%|▋         | 91/1257 [05:39<1:11:42,  3.69s/it]  7%|▋         | 92/1257 [05:42<1:07:40,  3.49s/it]  7%|▋         | 93/1257 [05:45<1:07:54,  3.50s/it]  7%|▋         | 94/1257 [05:50<1:12:13,  3.73s/it]  8%|▊         | 95/1257 [05:52<1:06:17,  3.42s/it]  8%|▊         | 96/1257 [05:56<1:09:21,  3.58s/it]  8%|▊         | 97/1257 [06:00<1:10:22,  3.64s/it]  8%|▊         | 98/1257 [06:04<1:10:45,  3.66s/it]  8%|▊         | 99/1257 [06:08<1:13:24,  3.80s/it]  8%|▊         | 100/1257 [06:12<1:11:46,  3.72s/it]                                                    {'loss': 0.6742, 'grad_norm': 48.48621368408203, 'learning_rate': 9.473684210526315e-08, 'rewards/chosen': 0.06713256984949112, 'rewards/rejected': -0.01404418982565403, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.080963134765625, 'logps/chosen': -165.8000030517578, 'logps/rejected': -176.9499969482422, 'logits/chosen': -6.921875, 'logits/rejected': -6.731249809265137, 'epoch': 0.24}
  8%|▊         | 100/1257 [06:12<1:11:46,  3.72s/it]  8%|▊         | 101/1257 [06:15<1:08:54,  3.58s/it]  8%|▊         | 102/1257 [06:19<1:12:30,  3.77s/it]  8%|▊         | 103/1257 [06:23<1:14:30,  3.87s/it]  8%|▊         | 104/1257 [06:26<1:09:18,  3.61s/it]  8%|▊         | 105/1257 [06:29<1:05:58,  3.44s/it]  8%|▊         | 106/1257 [06:33<1:08:41,  3.58s/it]  9%|▊         | 107/1257 [06:37<1:11:25,  3.73s/it]  9%|▊         | 108/1257 [06:40<1:07:18,  3.51s/it]  9%|▊         | 109/1257 [06:44<1:09:03,  3.61s/it]  9%|▉         | 110/1257 [06:47<1:04:15,  3.36s/it]                                                    {'loss': 0.7386, 'grad_norm': 44.43603515625, 'learning_rate': 1.0430622009569377e-07, 'rewards/chosen': 0.004172706510871649, 'rewards/rejected': 0.05106658861041069, 'rewards/accuracies': 0.4375, 'rewards/margins': -0.04683838039636612, 'logps/chosen': -144.0, 'logps/rejected': -175.1999969482422, 'logits/chosen': -6.987500190734863, 'logits/rejected': -6.840624809265137, 'epoch': 0.26}
  9%|▉         | 110/1257 [06:47<1:04:15,  3.36s/it]  9%|▉         | 111/1257 [06:50<1:02:06,  3.25s/it]  9%|▉         | 112/1257 [06:53<1:01:00,  3.20s/it]  9%|▉         | 113/1257 [06:56<1:00:40,  3.18s/it]  9%|▉         | 114/1257 [06:59<59:13,  3.11s/it]    9%|▉         | 115/1257 [07:03<1:02:06,  3.26s/it]  9%|▉         | 116/1257 [07:06<1:05:44,  3.46s/it]  9%|▉         | 117/1257 [07:10<1:08:12,  3.59s/it]  9%|▉         | 118/1257 [07:13<1:04:33,  3.40s/it]  9%|▉         | 119/1257 [07:17<1:04:30,  3.40s/it] 10%|▉         | 120/1257 [07:21<1:07:35,  3.57s/it]                                                    {'loss': 0.6935, 'grad_norm': 102.47228240966797, 'learning_rate': 1.138755980861244e-07, 'rewards/chosen': 0.004595947451889515, 'rewards/rejected': 0.0003692627069540322, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': 0.0042442320846021175, 'logps/chosen': -130.89999389648438, 'logps/rejected': -152.0, 'logits/chosen': -6.965624809265137, 'logits/rejected': -6.878125190734863, 'epoch': 0.29}
 10%|▉         | 120/1257 [07:21<1:07:35,  3.57s/it] 10%|▉         | 121/1257 [07:23<1:03:00,  3.33s/it] 10%|▉         | 122/1257 [07:27<1:06:26,  3.51s/it] 10%|▉         | 123/1257 [07:31<1:06:23,  3.51s/it] 10%|▉         | 124/1257 [07:34<1:02:24,  3.30s/it] 10%|▉         | 125/1257 [07:38<1:05:58,  3.50s/it] 10%|█         | 126/1257 [07:41<1:04:07,  3.40s/it] 10%|█         | 127/1257 [07:44<1:01:37,  3.27s/it] 10%|█         | 128/1257 [07:48<1:08:07,  3.62s/it] 10%|█         | 129/1257 [07:52<1:09:00,  3.67s/it] 10%|█         | 130/1257 [07:56<1:10:08,  3.73s/it]                                                    {'loss': 0.7024, 'grad_norm': 59.8011360168457, 'learning_rate': 1.2344497607655502e-07, 'rewards/chosen': -0.01279449462890625, 'rewards/rejected': -0.00980987586081028, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': -0.0030059814453125, 'logps/chosen': -108.80000305175781, 'logps/rejected': -127.3499984741211, 'logits/chosen': -7.0625, 'logits/rejected': -6.984375, 'epoch': 0.31}
 10%|█         | 130/1257 [07:56<1:10:08,  3.73s/it] 10%|█         | 131/1257 [08:00<1:12:25,  3.86s/it] 11%|█         | 132/1257 [08:04<1:12:05,  3.85s/it] 11%|█         | 133/1257 [08:08<1:13:47,  3.94s/it] 11%|█         | 134/1257 [08:11<1:06:33,  3.56s/it] 11%|█         | 135/1257 [08:15<1:10:17,  3.76s/it] 11%|█         | 136/1257 [08:19<1:10:57,  3.80s/it] 11%|█         | 137/1257 [08:22<1:07:34,  3.62s/it] 11%|█         | 138/1257 [08:25<1:05:12,  3.50s/it] 11%|█         | 139/1257 [08:29<1:07:01,  3.60s/it] 11%|█         | 140/1257 [08:32<1:05:53,  3.54s/it]                                                    {'loss': 0.6824, 'grad_norm': 52.52684783935547, 'learning_rate': 1.3301435406698566e-07, 'rewards/chosen': 0.0053619383834302425, 'rewards/rejected': -0.01790161058306694, 'rewards/accuracies': 0.48124998807907104, 'rewards/margins': 0.023284912109375, 'logps/chosen': -103.6500015258789, 'logps/rejected': -141.1999969482422, 'logits/chosen': -7.21875, 'logits/rejected': -7.099999904632568, 'epoch': 0.33}
 11%|█         | 140/1257 [08:32<1:05:53,  3.54s/it] 11%|█         | 141/1257 [08:36<1:08:13,  3.67s/it] 11%|█▏        | 142/1257 [08:40<1:06:06,  3.56s/it] 11%|█▏        | 143/1257 [08:43<1:06:36,  3.59s/it] 11%|█▏        | 144/1257 [08:47<1:05:27,  3.53s/it] 12%|█▏        | 145/1257 [08:50<1:06:34,  3.59s/it] 12%|█▏        | 146/1257 [08:55<1:09:43,  3.77s/it] 12%|█▏        | 147/1257 [08:58<1:08:27,  3.70s/it] 12%|█▏        | 148/1257 [09:02<1:09:14,  3.75s/it] 12%|█▏        | 149/1257 [09:06<1:10:26,  3.81s/it] 12%|█▏        | 150/1257 [09:10<1:13:45,  4.00s/it]                                                    {'loss': 0.6958, 'grad_norm': 66.55774688720703, 'learning_rate': 1.4258373205741624e-07, 'rewards/chosen': -0.0023368834517896175, 'rewards/rejected': -0.01326904259622097, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.01094665564596653, 'logps/chosen': -132.75, 'logps/rejected': -160.35000610351562, 'logits/chosen': -6.956250190734863, 'logits/rejected': -6.865624904632568, 'epoch': 0.36}
 12%|█▏        | 150/1257 [09:10<1:13:45,  4.00s/it] 12%|█▏        | 151/1257 [09:14<1:13:38,  4.00s/it] 12%|█▏        | 152/1257 [09:17<1:07:08,  3.65s/it] 12%|█▏        | 153/1257 [09:21<1:05:11,  3.54s/it] 12%|█▏        | 154/1257 [09:24<1:06:49,  3.64s/it] 12%|█▏        | 155/1257 [09:28<1:06:51,  3.64s/it] 12%|█▏        | 156/1257 [09:32<1:06:28,  3.62s/it] 12%|█▏        | 157/1257 [09:35<1:03:45,  3.48s/it] 13%|█▎        | 158/1257 [09:38<1:03:37,  3.47s/it] 13%|█▎        | 159/1257 [09:42<1:06:10,  3.62s/it] 13%|█▎        | 160/1257 [09:45<59:36,  3.26s/it]                                                    {'loss': 0.6903, 'grad_norm': 45.83570861816406, 'learning_rate': 1.5215311004784688e-07, 'rewards/chosen': 0.01218261756002903, 'rewards/rejected': -0.008976745419204235, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.02123870886862278, 'logps/chosen': -94.75, 'logps/rejected': -125.30000305175781, 'logits/chosen': -7.106249809265137, 'logits/rejected': -7.009375095367432, 'epoch': 0.38}
 13%|█▎        | 160/1257 [09:45<59:36,  3.26s/it] 13%|█▎        | 161/1257 [09:48<57:31,  3.15s/it] 13%|█▎        | 162/1257 [09:51<1:01:37,  3.38s/it] 13%|█▎        | 163/1257 [09:56<1:05:44,  3.61s/it] 13%|█▎        | 164/1257 [09:59<1:05:01,  3.57s/it] 13%|█▎        | 165/1257 [10:02<59:06,  3.25s/it]   13%|█▎        | 166/1257 [10:04<56:10,  3.09s/it] 13%|█▎        | 167/1257 [10:08<58:26,  3.22s/it] 13%|█▎        | 168/1257 [10:11<1:00:18,  3.32s/it] 13%|█▎        | 169/1257 [10:15<1:00:51,  3.36s/it] 14%|█▎        | 170/1257 [10:18<59:43,  3.30s/it]                                                    {'loss': 0.6733, 'grad_norm': 51.119712829589844, 'learning_rate': 1.617224880382775e-07, 'rewards/chosen': 0.01458587683737278, 'rewards/rejected': -0.03621368482708931, 'rewards/accuracies': 0.48124998807907104, 'rewards/margins': 0.05081329494714737, 'logps/chosen': -104.55000305175781, 'logps/rejected': -123.55000305175781, 'logits/chosen': -6.959374904632568, 'logits/rejected': -6.943749904632568, 'epoch': 0.41}
 14%|█▎        | 170/1257 [10:18<59:43,  3.30s/it] 14%|█▎        | 171/1257 [10:21<58:53,  3.25s/it] 14%|█▎        | 172/1257 [10:25<1:03:32,  3.51s/it] 14%|█▍        | 173/1257 [10:29<1:07:14,  3.72s/it] 14%|█▍        | 174/1257 [10:34<1:10:08,  3.89s/it] 14%|█▍        | 175/1257 [10:37<1:07:03,  3.72s/it] 14%|█▍        | 176/1257 [10:41<1:08:31,  3.80s/it] 14%|█▍        | 177/1257 [10:44<1:01:51,  3.44s/it] 14%|█▍        | 178/1257 [10:48<1:04:32,  3.59s/it] 14%|█▍        | 179/1257 [10:51<1:05:53,  3.67s/it] 14%|█▍        | 180/1257 [10:55<1:06:01,  3.68s/it]                                                    {'loss': 0.6713, 'grad_norm': 44.34431838989258, 'learning_rate': 1.7129186602870813e-07, 'rewards/chosen': 0.05225982517004013, 'rewards/rejected': -0.03371276706457138, 'rewards/accuracies': 0.518750011920929, 'rewards/margins': 0.0859832763671875, 'logps/chosen': -141.10000610351562, 'logps/rejected': -135.0500030517578, 'logits/chosen': -7.090624809265137, 'logits/rejected': -7.115624904632568, 'epoch': 0.43}
 14%|█▍        | 180/1257 [10:55<1:06:01,  3.68s/it] 14%|█▍        | 181/1257 [10:59<1:05:31,  3.65s/it] 14%|█▍        | 182/1257 [11:03<1:06:33,  3.72s/it] 15%|█▍        | 183/1257 [11:07<1:08:38,  3.83s/it] 15%|█▍        | 184/1257 [11:11<1:10:37,  3.95s/it] 15%|█▍        | 185/1257 [11:15<1:10:35,  3.95s/it] 15%|█▍        | 186/1257 [11:19<1:09:46,  3.91s/it] 15%|█▍        | 187/1257 [11:23<1:10:14,  3.94s/it] 15%|█▍        | 188/1257 [11:26<1:08:41,  3.86s/it] 15%|█▌        | 189/1257 [11:29<1:02:14,  3.50s/it] 15%|█▌        | 190/1257 [11:33<1:02:36,  3.52s/it]                                                    {'loss': 0.6663, 'grad_norm': 59.692665100097656, 'learning_rate': 1.8086124401913874e-07, 'rewards/chosen': 0.01569824293255806, 'rewards/rejected': -0.05518798902630806, 'rewards/accuracies': 0.53125, 'rewards/margins': 0.07093505561351776, 'logps/chosen': -177.85000610351562, 'logps/rejected': -193.1999969482422, 'logits/chosen': -6.931250095367432, 'logits/rejected': -6.949999809265137, 'epoch': 0.45}
 15%|█▌        | 190/1257 [11:33<1:02:36,  3.52s/it] 15%|█▌        | 191/1257 [11:36<1:01:54,  3.48s/it] 15%|█▌        | 192/1257 [11:40<1:02:14,  3.51s/it] 15%|█▌        | 193/1257 [11:43<1:01:43,  3.48s/it] 15%|█▌        | 194/1257 [11:46<1:01:28,  3.47s/it] 16%|█▌        | 195/1257 [11:50<1:02:58,  3.56s/it] 16%|█▌        | 196/1257 [11:54<1:04:43,  3.66s/it] 16%|█▌        | 197/1257 [11:58<1:07:35,  3.83s/it] 16%|█▌        | 198/1257 [12:01<1:02:27,  3.54s/it] 16%|█▌        | 199/1257 [12:04<1:01:17,  3.48s/it] 16%|█▌        | 200/1257 [12:07<58:28,  3.32s/it]                                                    {'loss': 0.6738, 'grad_norm': 50.162513732910156, 'learning_rate': 1.9043062200956935e-07, 'rewards/chosen': 0.02095642127096653, 'rewards/rejected': -0.02492981031537056, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.04590911790728569, 'logps/chosen': -101.80000305175781, 'logps/rejected': -118.9000015258789, 'logits/chosen': -7.196875095367432, 'logits/rejected': -7.0625, 'epoch': 0.48}
 16%|█▌        | 200/1257 [12:07<58:28,  3.32s/it] 16%|█▌        | 201/1257 [12:11<1:01:49,  3.51s/it] 16%|█▌        | 202/1257 [12:15<1:03:49,  3.63s/it] 16%|█▌        | 203/1257 [12:18<1:01:25,  3.50s/it] 16%|█▌        | 204/1257 [12:23<1:04:58,  3.70s/it] 16%|█▋        | 205/1257 [12:27<1:06:21,  3.78s/it] 16%|█▋        | 206/1257 [12:30<1:03:47,  3.64s/it] 16%|█▋        | 207/1257 [12:33<1:01:57,  3.54s/it] 17%|█▋        | 208/1257 [12:37<1:01:42,  3.53s/it] 17%|█▋        | 209/1257 [12:40<58:33,  3.35s/it]  
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:49,  1.17it/s][A
  5%|▌         | 3/60 [00:03<01:06,  1.16s/it][A
  7%|▋         | 4/60 [00:04<01:15,  1.34s/it][A
  8%|▊         | 5/60 [00:06<01:18,  1.42s/it][A
 10%|█         | 6/60 [00:08<01:22,  1.52s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.54s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:13<01:22,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.61s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.65s/it][A
 20%|██        | 12/60 [00:18<01:18,  1.63s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.61s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:40,  1.00s/it][A
 35%|███▌      | 21/60 [00:28<00:39,  1.00s/it][A
 37%|███▋      | 22/60 [00:29<00:41,  1.10s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:39,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:46<00:32,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:32,  1.33s/it][A
 62%|██████▏   | 37/60 [00:48<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:53<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:57<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:01<00:18,  1.41s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.33s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:08<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:09<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:13<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A                                                  
                                               [A{'eval_loss': 0.7163835763931274, 'eval_runtime': 80.8064, 'eval_samples_per_second': 11.794, 'eval_steps_per_second': 0.743, 'eval_rewards/chosen': 0.12097880244255066, 'eval_rewards/rejected': 0.0742545798420906, 'eval_rewards/accuracies': 0.454745352268219, 'eval_rewards/margins': 0.046553801745176315, 'eval_logps/chosen': -374.7416687011719, 'eval_logps/rejected': -150.8333282470703, 'eval_logits/chosen': -6.516927242279053, 'eval_logits/rejected': -7.3828125, 'epoch': 0.5}
 17%|█▋        | 209/1257 [14:01<58:33,  3.35s/it]
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 17%|█▋        | 210/1257 [14:16<9:05:00, 31.23s/it]                                                    {'loss': 0.6479, 'grad_norm': 44.523162841796875, 'learning_rate': 2e-07, 'rewards/chosen': 0.08055420219898224, 'rewards/rejected': -0.04849853366613388, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.12895813584327698, 'logps/chosen': -173.22500610351562, 'logps/rejected': -211.64999389648438, 'logits/chosen': -7.068749904632568, 'logits/rejected': -6.753125190734863, 'epoch': 0.5}
 17%|█▋        | 210/1257 [14:16<9:05:00, 31.23s/it] 17%|█▋        | 211/1257 [14:20<6:42:38, 23.10s/it] 17%|█▋        | 212/1257 [14:24<5:02:10, 17.35s/it] 17%|█▋        | 213/1257 [14:27<3:48:46, 13.15s/it] 17%|█▋        | 214/1257 [14:31<3:00:48, 10.40s/it] 17%|█▋        | 215/1257 [14:35<2:24:21,  8.31s/it] 17%|█▋        | 216/1257 [14:39<2:02:17,  7.05s/it] 17%|█▋        | 217/1257 [14:43<1:47:24,  6.20s/it] 17%|█▋        | 218/1257 [14:46<1:32:16,  5.33s/it] 17%|█▋        | 219/1257 [14:51<1:26:22,  4.99s/it] 18%|█▊        | 220/1257 [14:53<1:13:14,  4.24s/it]                                                    {'loss': 0.6666, 'grad_norm': 56.95463180541992, 'learning_rate': 2.0956937799043063e-07, 'rewards/chosen': 0.04157714918255806, 'rewards/rejected': -0.03409729152917862, 'rewards/accuracies': 0.581250011920929, 'rewards/margins': 0.07560119777917862, 'logps/chosen': -168.9499969482422, 'logps/rejected': -178.4499969482422, 'logits/chosen': -6.965624809265137, 'logits/rejected': -6.981249809265137, 'epoch': 0.53}
 18%|█▊        | 220/1257 [14:53<1:13:14,  4.24s/it] 18%|█▊        | 221/1257 [14:57<1:10:01,  4.06s/it] 18%|█▊        | 222/1257 [15:01<1:10:27,  4.08s/it] 18%|█▊        | 223/1257 [15:04<1:07:38,  3.93s/it] 18%|█▊        | 224/1257 [15:09<1:09:24,  4.03s/it] 18%|█▊        | 225/1257 [15:12<1:05:39,  3.82s/it] 18%|█▊        | 226/1257 [15:16<1:06:45,  3.88s/it] 18%|█▊        | 227/1257 [15:20<1:07:22,  3.92s/it] 18%|█▊        | 228/1257 [15:23<1:01:10,  3.57s/it] 18%|█▊        | 229/1257 [15:26<1:00:33,  3.53s/it] 18%|█▊        | 230/1257 [15:30<1:00:36,  3.54s/it]                                                    {'loss': 0.6675, 'grad_norm': 54.8426628112793, 'learning_rate': 2.1913875598086124e-07, 'rewards/chosen': 0.030961990356445312, 'rewards/rejected': -0.04224853590130806, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.07313232123851776, 'logps/chosen': -103.6500015258789, 'logps/rejected': -137.6999969482422, 'logits/chosen': -7.125, 'logits/rejected': -6.984375, 'epoch': 0.55}
 18%|█▊        | 230/1257 [15:30<1:00:36,  3.54s/it] 18%|█▊        | 231/1257 [15:34<1:01:29,  3.60s/it] 18%|█▊        | 232/1257 [15:37<1:01:13,  3.58s/it] 19%|█▊        | 233/1257 [15:40<56:01,  3.28s/it]   19%|█▊        | 234/1257 [15:43<55:07,  3.23s/it] 19%|█▊        | 235/1257 [15:47<1:01:01,  3.58s/it] 19%|█▉        | 236/1257 [15:51<1:02:18,  3.66s/it] 19%|█▉        | 237/1257 [15:54<58:08,  3.42s/it]   19%|█▉        | 238/1257 [15:57<57:23,  3.38s/it] 19%|█▉        | 239/1257 [16:01<58:11,  3.43s/it] 19%|█▉        | 240/1257 [16:04<57:47,  3.41s/it]                                                  {'loss': 0.6676, 'grad_norm': 51.79145050048828, 'learning_rate': 2.2870813397129188e-07, 'rewards/chosen': 0.03162841871380806, 'rewards/rejected': -0.043340303003787994, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.07498779147863388, 'logps/chosen': -98.75, 'logps/rejected': -134.64999389648438, 'logits/chosen': -7.131249904632568, 'logits/rejected': -6.881249904632568, 'epoch': 0.57}
 19%|█▉        | 240/1257 [16:04<57:47,  3.41s/it] 19%|█▉        | 241/1257 [16:08<1:02:12,  3.67s/it] 19%|█▉        | 242/1257 [16:12<1:00:53,  3.60s/it] 19%|█▉        | 243/1257 [16:16<1:01:57,  3.67s/it] 19%|█▉        | 244/1257 [16:19<1:02:03,  3.68s/it] 19%|█▉        | 245/1257 [16:24<1:04:24,  3.82s/it] 20%|█▉        | 246/1257 [16:27<1:01:24,  3.64s/it] 20%|█▉        | 247/1257 [16:31<1:02:47,  3.73s/it] 20%|█▉        | 248/1257 [16:34<1:02:59,  3.75s/it] 20%|█▉        | 249/1257 [16:38<1:02:53,  3.74s/it] 20%|█▉        | 250/1257 [16:42<1:03:17,  3.77s/it]                                                    {'loss': 0.6818, 'grad_norm': 65.31635284423828, 'learning_rate': 2.382775119617225e-07, 'rewards/chosen': -0.017852783203125, 'rewards/rejected': -0.05375976487994194, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.03586425632238388, 'logps/chosen': -113.1500015258789, 'logps/rejected': -121.44999694824219, 'logits/chosen': -7.006249904632568, 'logits/rejected': -7.099999904632568, 'epoch': 0.6}
 20%|█▉        | 250/1257 [16:42<1:03:17,  3.77s/it] 20%|█▉        | 251/1257 [16:46<1:02:39,  3.74s/it] 20%|██        | 252/1257 [16:50<1:04:44,  3.86s/it] 20%|██        | 253/1257 [16:54<1:06:33,  3.98s/it] 20%|██        | 254/1257 [16:57<1:03:28,  3.80s/it] 20%|██        | 255/1257 [17:01<1:01:31,  3.68s/it] 20%|██        | 256/1257 [17:04<56:49,  3.41s/it]   20%|██        | 257/1257 [17:08<59:59,  3.60s/it] 21%|██        | 258/1257 [17:12<1:03:00,  3.78s/it] 21%|██        | 259/1257 [17:15<1:00:47,  3.65s/it] 21%|██        | 260/1257 [17:19<1:03:07,  3.80s/it]                                                    {'loss': 0.6597, 'grad_norm': 45.11241149902344, 'learning_rate': 2.478468899521531e-07, 'rewards/chosen': 0.005757140927016735, 'rewards/rejected': -0.08979034423828125, 'rewards/accuracies': 0.606249988079071, 'rewards/margins': 0.095489501953125, 'logps/chosen': -113.30000305175781, 'logps/rejected': -126.7750015258789, 'logits/chosen': -7.087500095367432, 'logits/rejected': -7.099999904632568, 'epoch': 0.62}
 21%|██        | 260/1257 [17:19<1:03:07,  3.80s/it] 21%|██        | 261/1257 [17:23<1:03:22,  3.82s/it] 21%|██        | 262/1257 [17:27<1:02:06,  3.74s/it] 21%|██        | 263/1257 [17:31<1:04:28,  3.89s/it] 21%|██        | 264/1257 [17:35<1:02:07,  3.75s/it] 21%|██        | 265/1257 [17:38<58:20,  3.53s/it]   21%|██        | 266/1257 [17:41<56:58,  3.45s/it] 21%|██        | 267/1257 [17:44<56:34,  3.43s/it] 21%|██▏       | 268/1257 [17:47<52:47,  3.20s/it] 21%|██▏       | 269/1257 [17:51<55:11,  3.35s/it] 21%|██▏       | 270/1257 [17:55<58:29,  3.56s/it]                                                  {'loss': 0.6492, 'grad_norm': 58.13456344604492, 'learning_rate': 2.574162679425837e-07, 'rewards/chosen': 0.03628692775964737, 'rewards/rejected': -0.08193359524011612, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.11827697604894638, 'logps/chosen': -108.1500015258789, 'logps/rejected': -129.5500030517578, 'logits/chosen': -7.178124904632568, 'logits/rejected': -7.096875190734863, 'epoch': 0.64}
 21%|██▏       | 270/1257 [17:55<58:29,  3.56s/it] 22%|██▏       | 271/1257 [17:58<57:27,  3.50s/it] 22%|██▏       | 272/1257 [18:01<57:30,  3.50s/it] 22%|██▏       | 273/1257 [18:05<59:27,  3.63s/it] 22%|██▏       | 274/1257 [18:09<1:00:58,  3.72s/it] 22%|██▏       | 275/1257 [18:13<1:01:41,  3.77s/it] 22%|██▏       | 276/1257 [18:17<1:03:26,  3.88s/it] 22%|██▏       | 277/1257 [18:21<1:00:34,  3.71s/it] 22%|██▏       | 278/1257 [18:24<57:33,  3.53s/it]   22%|██▏       | 279/1257 [18:26<52:41,  3.23s/it] 22%|██▏       | 280/1257 [18:30<56:05,  3.44s/it]                                                  {'loss': 0.6667, 'grad_norm': 65.67845916748047, 'learning_rate': 2.669856459330143e-07, 'rewards/chosen': 0.05172119289636612, 'rewards/rejected': -0.03447876125574112, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.08601073920726776, 'logps/chosen': -143.89999389648438, 'logps/rejected': -149.77499389648438, 'logits/chosen': -7.143750190734863, 'logits/rejected': -7.137499809265137, 'epoch': 0.67}
 22%|██▏       | 280/1257 [18:30<56:05,  3.44s/it] 22%|██▏       | 281/1257 [18:34<56:47,  3.49s/it] 22%|██▏       | 282/1257 [18:38<58:33,  3.60s/it] 23%|██▎       | 283/1257 [18:41<59:20,  3.66s/it] 23%|██▎       | 284/1257 [18:44<55:10,  3.40s/it] 23%|██▎       | 285/1257 [18:48<54:56,  3.39s/it] 23%|██▎       | 286/1257 [18:52<57:58,  3.58s/it] 23%|██▎       | 287/1257 [18:55<54:44,  3.39s/it] 23%|██▎       | 288/1257 [18:59<57:23,  3.55s/it] 23%|██▎       | 289/1257 [19:03<1:00:28,  3.75s/it] 23%|██▎       | 290/1257 [19:07<1:01:24,  3.81s/it]                                                    {'loss': 0.6814, 'grad_norm': 209.3079833984375, 'learning_rate': 2.76555023923445e-07, 'rewards/chosen': 0.15231934189796448, 'rewards/rejected': 0.04642333835363388, 'rewards/accuracies': 0.625, 'rewards/margins': 0.10600586235523224, 'logps/chosen': -163.35000610351562, 'logps/rejected': -170.1999969482422, 'logits/chosen': -6.925000190734863, 'logits/rejected': -6.940625190734863, 'epoch': 0.69}
 23%|██▎       | 290/1257 [19:07<1:01:24,  3.81s/it] 23%|██▎       | 291/1257 [19:10<58:36,  3.64s/it]   23%|██▎       | 292/1257 [19:13<56:30,  3.51s/it] 23%|██▎       | 293/1257 [19:16<55:03,  3.43s/it] 23%|██▎       | 294/1257 [19:21<58:41,  3.66s/it] 23%|██▎       | 295/1257 [19:24<59:18,  3.70s/it] 24%|██▎       | 296/1257 [19:28<1:00:23,  3.77s/it] 24%|██▎       | 297/1257 [19:31<55:41,  3.48s/it]   24%|██▎       | 298/1257 [19:35<56:36,  3.54s/it] 24%|██▍       | 299/1257 [19:38<53:06,  3.33s/it] 24%|██▍       | 300/1257 [19:41<53:16,  3.34s/it]                                                  {'loss': 0.6317, 'grad_norm': 50.25319290161133, 'learning_rate': 2.861244019138756e-07, 'rewards/chosen': 0.04805908352136612, 'rewards/rejected': -0.11492919921875, 'rewards/accuracies': 0.668749988079071, 'rewards/margins': 0.16335448622703552, 'logps/chosen': -112.9000015258789, 'logps/rejected': -112.3499984741211, 'logits/chosen': -7.340624809265137, 'logits/rejected': -7.525000095367432, 'epoch': 0.72}
 24%|██▍       | 300/1257 [19:41<53:16,  3.34s/it] 24%|██▍       | 301/1257 [19:45<54:10,  3.40s/it] 24%|██▍       | 302/1257 [19:48<55:39,  3.50s/it] 24%|██▍       | 303/1257 [19:52<57:15,  3.60s/it] 24%|██▍       | 304/1257 [19:56<58:24,  3.68s/it] 24%|██▍       | 305/1257 [19:59<56:53,  3.59s/it] 24%|██▍       | 306/1257 [20:03<59:23,  3.75s/it] 24%|██▍       | 307/1257 [20:05<51:13,  3.24s/it] 25%|██▍       | 308/1257 [20:09<53:43,  3.40s/it] 25%|██▍       | 309/1257 [20:13<57:12,  3.62s/it] 25%|██▍       | 310/1257 [20:17<55:34,  3.52s/it]                                                  {'loss': 0.6272, 'grad_norm': 56.527828216552734, 'learning_rate': 2.956937799043062e-07, 'rewards/chosen': 0.06187133863568306, 'rewards/rejected': -0.102783203125, 'rewards/accuracies': 0.6625000238418579, 'rewards/margins': 0.16455078125, 'logps/chosen': -103.2249984741211, 'logps/rejected': -132.8000030517578, 'logits/chosen': -7.162499904632568, 'logits/rejected': -6.962500095367432, 'epoch': 0.74}
 25%|██▍       | 310/1257 [20:17<55:34,  3.52s/it] 25%|██▍       | 311/1257 [20:21<58:46,  3.73s/it] 25%|██▍       | 312/1257 [20:24<55:59,  3.56s/it] 25%|██▍       | 313/1257 [20:27<54:24,  3.46s/it] 25%|██▍       | 314/1257 [20:31<57:34,  3.66s/it] 25%|██▌       | 315/1257 [20:34<53:33,  3.41s/it] 25%|██▌       | 316/1257 [20:38<56:14,  3.59s/it] 25%|██▌       | 317/1257 [20:41<54:03,  3.45s/it] 25%|██▌       | 318/1257 [20:45<56:06,  3.59s/it] 25%|██▌       | 319/1257 [20:48<53:10,  3.40s/it] 25%|██▌       | 320/1257 [20:52<53:23,  3.42s/it]                                                  {'loss': 0.5875, 'grad_norm': 48.776920318603516, 'learning_rate': 3.052631578947368e-07, 'rewards/chosen': 0.1219482421875, 'rewards/rejected': -0.152099609375, 'rewards/accuracies': 0.6937500238418579, 'rewards/margins': 0.2740234434604645, 'logps/chosen': -99.9000015258789, 'logps/rejected': -125.5999984741211, 'logits/chosen': -7.265625, 'logits/rejected': -7.240624904632568, 'epoch': 0.76}
 25%|██▌       | 320/1257 [20:52<53:23,  3.42s/it] 26%|██▌       | 321/1257 [20:54<49:28,  3.17s/it] 26%|██▌       | 322/1257 [20:58<53:51,  3.46s/it] 26%|██▌       | 323/1257 [21:01<51:06,  3.28s/it] 26%|██▌       | 324/1257 [21:05<54:12,  3.49s/it] 26%|██▌       | 325/1257 [21:09<55:14,  3.56s/it] 26%|██▌       | 326/1257 [21:12<53:51,  3.47s/it] 26%|██▌       | 327/1257 [21:16<54:42,  3.53s/it] 26%|██▌       | 328/1257 [21:20<56:38,  3.66s/it] 26%|██▌       | 329/1257 [21:24<57:52,  3.74s/it] 26%|██▋       | 330/1257 [21:28<58:47,  3.81s/it]                                                  {'loss': 0.5924, 'grad_norm': 90.18240356445312, 'learning_rate': 3.148325358851675e-07, 'rewards/chosen': 0.1643936187028885, 'rewards/rejected': -0.10063476860523224, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.26484376192092896, 'logps/chosen': -137.9499969482422, 'logps/rejected': -161.4499969482422, 'logits/chosen': -7.131249904632568, 'logits/rejected': -7.056250095367432, 'epoch': 0.79}
 26%|██▋       | 330/1257 [21:28<58:47,  3.81s/it] 26%|██▋       | 331/1257 [21:32<59:56,  3.88s/it] 26%|██▋       | 332/1257 [21:35<55:33,  3.60s/it] 26%|██▋       | 333/1257 [21:39<57:48,  3.75s/it] 27%|██▋       | 334/1257 [21:43<57:15,  3.72s/it] 27%|██▋       | 335/1257 [21:46<56:52,  3.70s/it] 27%|██▋       | 336/1257 [21:50<57:05,  3.72s/it] 27%|██▋       | 337/1257 [21:53<54:59,  3.59s/it] 27%|██▋       | 338/1257 [21:56<52:54,  3.45s/it] 27%|██▋       | 339/1257 [22:01<56:23,  3.69s/it] 27%|██▋       | 340/1257 [22:04<54:23,  3.56s/it]                                                  {'loss': 0.6218, 'grad_norm': 53.62024688720703, 'learning_rate': 3.2440191387559805e-07, 'rewards/chosen': 0.04946289211511612, 'rewards/rejected': -0.17431640625, 'rewards/accuracies': 0.637499988079071, 'rewards/margins': 0.22382812201976776, 'logps/chosen': -101.1500015258789, 'logps/rejected': -129.89999389648438, 'logits/chosen': -7.278124809265137, 'logits/rejected': -7.121874809265137, 'epoch': 0.81}
 27%|██▋       | 340/1257 [22:04<54:23,  3.56s/it] 27%|██▋       | 341/1257 [22:07<52:56,  3.47s/it] 27%|██▋       | 342/1257 [22:10<49:44,  3.26s/it] 27%|██▋       | 343/1257 [22:12<44:10,  2.90s/it] 27%|██▋       | 344/1257 [22:15<46:12,  3.04s/it] 27%|██▋       | 345/1257 [22:19<50:17,  3.31s/it] 28%|██▊       | 346/1257 [22:23<51:13,  3.37s/it] 28%|██▊       | 347/1257 [22:25<48:01,  3.17s/it] 28%|██▊       | 348/1257 [22:29<51:48,  3.42s/it] 28%|██▊       | 349/1257 [22:34<55:08,  3.64s/it] 28%|██▊       | 350/1257 [22:38<57:23,  3.80s/it]                                                  {'loss': 0.61, 'grad_norm': 69.1715316772461, 'learning_rate': 3.3397129186602866e-07, 'rewards/chosen': 0.13300780951976776, 'rewards/rejected': -0.1201171875, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.25341796875, 'logps/chosen': -141.10000610351562, 'logps/rejected': -160.89999389648438, 'logits/chosen': -7.353125095367432, 'logits/rejected': -7.015625, 'epoch': 0.84}
 28%|██▊       | 350/1257 [22:38<57:23,  3.80s/it] 28%|██▊       | 351/1257 [22:42<58:06,  3.85s/it] 28%|██▊       | 352/1257 [22:46<57:55,  3.84s/it] 28%|██▊       | 353/1257 [22:48<52:39,  3.50s/it] 28%|██▊       | 354/1257 [22:52<55:14,  3.67s/it] 28%|██▊       | 355/1257 [22:56<53:40,  3.57s/it] 28%|██▊       | 356/1257 [23:00<55:15,  3.68s/it] 28%|██▊       | 357/1257 [23:03<52:36,  3.51s/it] 28%|██▊       | 358/1257 [23:06<51:53,  3.46s/it] 29%|██▊       | 359/1257 [23:10<52:03,  3.48s/it] 29%|██▊       | 360/1257 [23:14<55:00,  3.68s/it]                                                  {'loss': 0.6098, 'grad_norm': 58.83371353149414, 'learning_rate': 3.435406698564593e-07, 'rewards/chosen': 0.04313964769244194, 'rewards/rejected': -0.21633300185203552, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.25947266817092896, 'logps/chosen': -117.44999694824219, 'logps/rejected': -139.9499969482422, 'logits/chosen': -7.215624809265137, 'logits/rejected': -7.096875190734863, 'epoch': 0.86}
 29%|██▊       | 360/1257 [23:14<55:00,  3.68s/it] 29%|██▊       | 361/1257 [23:18<55:41,  3.73s/it] 29%|██▉       | 362/1257 [23:21<54:31,  3.65s/it] 29%|██▉       | 363/1257 [23:25<54:32,  3.66s/it] 29%|██▉       | 364/1257 [23:28<53:23,  3.59s/it] 29%|██▉       | 365/1257 [23:32<52:43,  3.55s/it] 29%|██▉       | 366/1257 [23:36<55:40,  3.75s/it] 29%|██▉       | 367/1257 [23:39<55:08,  3.72s/it] 29%|██▉       | 368/1257 [23:43<53:56,  3.64s/it] 29%|██▉       | 369/1257 [23:46<51:11,  3.46s/it] 29%|██▉       | 370/1257 [23:50<51:45,  3.50s/it]                                                  {'loss': 0.6442, 'grad_norm': 61.76700973510742, 'learning_rate': 3.5311004784688993e-07, 'rewards/chosen': 0.07241211086511612, 'rewards/rejected': -0.14013671875, 'rewards/accuracies': 0.643750011920929, 'rewards/margins': 0.21220703423023224, 'logps/chosen': -109.5, 'logps/rejected': -119.4749984741211, 'logits/chosen': -7.387499809265137, 'logits/rejected': -7.296875, 'epoch': 0.88}
 29%|██▉       | 370/1257 [23:50<51:45,  3.50s/it] 30%|██▉       | 371/1257 [23:53<52:33,  3.56s/it] 30%|██▉       | 372/1257 [23:58<55:37,  3.77s/it] 30%|██▉       | 373/1257 [24:01<54:36,  3.71s/it] 30%|██▉       | 374/1257 [24:05<56:14,  3.82s/it] 30%|██▉       | 375/1257 [24:09<56:16,  3.83s/it] 30%|██▉       | 376/1257 [24:13<55:56,  3.81s/it] 30%|██▉       | 377/1257 [24:16<53:31,  3.65s/it] 30%|███       | 378/1257 [24:19<52:11,  3.56s/it] 30%|███       | 379/1257 [24:23<51:49,  3.54s/it] 30%|███       | 380/1257 [24:27<52:20,  3.58s/it]                                                  {'loss': 0.606, 'grad_norm': 46.7698860168457, 'learning_rate': 3.6267942583732054e-07, 'rewards/chosen': 0.08480529487133026, 'rewards/rejected': -0.20986327528953552, 'rewards/accuracies': 0.6937500238418579, 'rewards/margins': 0.29438477754592896, 'logps/chosen': -146.8000030517578, 'logps/rejected': -167.5500030517578, 'logits/chosen': -7.137499809265137, 'logits/rejected': -6.934374809265137, 'epoch': 0.91}
 30%|███       | 380/1257 [24:27<52:20,  3.58s/it] 30%|███       | 381/1257 [24:31<53:53,  3.69s/it] 30%|███       | 382/1257 [24:34<54:48,  3.76s/it] 30%|███       | 383/1257 [24:37<48:54,  3.36s/it] 31%|███       | 384/1257 [24:41<51:06,  3.51s/it] 31%|███       | 385/1257 [24:44<47:57,  3.30s/it] 31%|███       | 386/1257 [24:47<50:35,  3.48s/it] 31%|███       | 387/1257 [24:51<50:55,  3.51s/it] 31%|███       | 388/1257 [24:55<50:51,  3.51s/it] 31%|███       | 389/1257 [24:59<53:26,  3.69s/it] 31%|███       | 390/1257 [25:03<55:28,  3.84s/it]                                                  {'loss': 0.5735, 'grad_norm': 48.9980354309082, 'learning_rate': 3.722488038277512e-07, 'rewards/chosen': 0.013348388485610485, 'rewards/rejected': -0.34931641817092896, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.36259764432907104, 'logps/chosen': -109.1500015258789, 'logps/rejected': -137.9499969482422, 'logits/chosen': -7.275000095367432, 'logits/rejected': -7.134375095367432, 'epoch': 0.93}
 31%|███       | 390/1257 [25:03<55:28,  3.84s/it] 31%|███       | 391/1257 [25:07<55:19,  3.83s/it] 31%|███       | 392/1257 [25:11<56:37,  3.93s/it] 31%|███▏      | 393/1257 [25:13<50:23,  3.50s/it] 31%|███▏      | 394/1257 [25:17<49:01,  3.41s/it] 31%|███▏      | 395/1257 [25:20<50:38,  3.52s/it] 32%|███▏      | 396/1257 [25:23<47:54,  3.34s/it] 32%|███▏      | 397/1257 [25:27<50:10,  3.50s/it] 32%|███▏      | 398/1257 [25:31<51:22,  3.59s/it] 32%|███▏      | 399/1257 [25:33<43:19,  3.03s/it] 32%|███▏      | 400/1257 [25:36<46:35,  3.26s/it]                                                  {'loss': 0.5638, 'grad_norm': 38.826236724853516, 'learning_rate': 3.818181818181818e-07, 'rewards/chosen': 0.071075439453125, 'rewards/rejected': -0.32060545682907104, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.3916015625, 'logps/chosen': -94.3499984741211, 'logps/rejected': -116.92500305175781, 'logits/chosen': -7.215624809265137, 'logits/rejected': -7.150000095367432, 'epoch': 0.95}
 32%|███▏      | 400/1257 [25:36<46:35,  3.26s/it] 32%|███▏      | 401/1257 [25:40<49:34,  3.47s/it] 32%|███▏      | 402/1257 [25:44<50:55,  3.57s/it] 32%|███▏      | 403/1257 [25:48<52:37,  3.70s/it] 32%|███▏      | 404/1257 [25:51<48:26,  3.41s/it] 32%|███▏      | 405/1257 [25:55<51:20,  3.62s/it] 32%|███▏      | 406/1257 [25:59<52:44,  3.72s/it] 32%|███▏      | 407/1257 [26:02<47:43,  3.37s/it] 32%|███▏      | 408/1257 [26:05<47:55,  3.39s/it] 33%|███▎      | 409/1257 [26:09<51:24,  3.64s/it] 33%|███▎      | 410/1257 [26:13<53:59,  3.83s/it]                                                  {'loss': 0.5882, 'grad_norm': 69.03779602050781, 'learning_rate': 3.9138755980861243e-07, 'rewards/chosen': 0.09628906100988388, 'rewards/rejected': -0.2840820252895355, 'rewards/accuracies': 0.65625, 'rewards/margins': 0.3814453184604645, 'logps/chosen': -132.5500030517578, 'logps/rejected': -166.0500030517578, 'logits/chosen': -7.306250095367432, 'logits/rejected': -7.212500095367432, 'epoch': 0.98}
 33%|███▎      | 410/1257 [26:13<53:59,  3.83s/it] 33%|███▎      | 411/1257 [26:17<51:43,  3.67s/it] 33%|███▎      | 412/1257 [26:21<54:06,  3.84s/it] 33%|███▎      | 413/1257 [26:24<51:16,  3.64s/it] 33%|███▎      | 414/1257 [26:28<52:28,  3.74s/it] 33%|███▎      | 415/1257 [26:32<53:57,  3.85s/it] 33%|███▎      | 416/1257 [26:36<54:30,  3.89s/it] 33%|███▎      | 417/1257 [26:40<55:23,  3.96s/it] 33%|███▎      | 418/1257 [26:45<56:15,  4.02s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:13<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.61s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:39,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:32,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.41s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.33s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                  
                                               [A{'eval_loss': 0.659946620464325, 'eval_runtime': 80.5857, 'eval_samples_per_second': 11.826, 'eval_steps_per_second': 0.745, 'eval_rewards/chosen': 0.9183222651481628, 'eval_rewards/rejected': 0.3859090209007263, 'eval_rewards/accuracies': 0.6284722685813904, 'eval_rewards/margins': 0.5334330201148987, 'eval_logps/chosen': -370.82501220703125, 'eval_logps/rejected': -149.2312469482422, 'eval_logits/chosen': -6.6697916984558105, 'eval_logits/rejected': -7.477604389190674, 'epoch': 1.0}
 33%|███▎      | 418/1257 [28:05<56:15,  4.02s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 33%|███▎      | 419/1257 [28:21<7:25:17, 31.88s/it] 33%|███▎      | 420/1257 [28:24<5:23:43, 23.21s/it]                                                    {'loss': 0.6087, 'grad_norm': 37.087791442871094, 'learning_rate': 3.999987381206723e-07, 'rewards/chosen': 0.13981933891773224, 'rewards/rejected': -0.32597655057907104, 'rewards/accuracies': 0.706250011920929, 'rewards/margins': 0.46552735567092896, 'logps/chosen': -130.89999389648438, 'logps/rejected': -170.3000030517578, 'logits/chosen': -7.490624904632568, 'logits/rejected': -7.25, 'epoch': 1.0}
 33%|███▎      | 420/1257 [28:24<5:23:43, 23.21s/it] 33%|███▎      | 421/1257 [28:28<4:00:24, 17.25s/it] 34%|███▎      | 422/1257 [28:30<2:59:02, 12.87s/it] 34%|███▎      | 423/1257 [28:33<2:17:06,  9.86s/it] 34%|███▎      | 424/1257 [28:36<1:48:00,  7.78s/it] 34%|███▍      | 425/1257 [28:40<1:32:52,  6.70s/it] 34%|███▍      | 426/1257 [28:44<1:21:15,  5.87s/it] 34%|███▍      | 427/1257 [28:47<1:07:04,  4.85s/it] 34%|███▍      | 428/1257 [28:51<1:03:06,  4.57s/it] 34%|███▍      | 429/1257 [28:54<58:03,  4.21s/it]   34%|███▍      | 430/1257 [28:57<54:51,  3.98s/it]                                                  {'loss': 0.5692, 'grad_norm': 59.69348907470703, 'learning_rate': 3.998473340082952e-07, 'rewards/chosen': 0.03893432766199112, 'rewards/rejected': -0.36616212129592896, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4048828184604645, 'logps/chosen': -101.9000015258789, 'logps/rejected': -119.5, 'logits/chosen': -7.434374809265137, 'logits/rejected': -7.1875, 'epoch': 1.03}
 34%|███▍      | 430/1257 [28:57<54:51,  3.98s/it] 34%|███▍      | 431/1257 [29:01<51:52,  3.77s/it] 34%|███▍      | 432/1257 [29:04<48:42,  3.54s/it] 34%|███▍      | 433/1257 [29:07<48:08,  3.51s/it] 35%|███▍      | 434/1257 [29:10<45:35,  3.32s/it] 35%|███▍      | 435/1257 [29:14<46:40,  3.41s/it] 35%|███▍      | 436/1257 [29:18<49:26,  3.61s/it] 35%|███▍      | 437/1257 [29:22<51:36,  3.78s/it] 35%|███▍      | 438/1257 [29:26<52:04,  3.82s/it] 35%|███▍      | 439/1257 [29:30<52:45,  3.87s/it] 35%|███▌      | 440/1257 [29:33<51:25,  3.78s/it]                                                  {'loss': 0.5902, 'grad_norm': 36.16697311401367, 'learning_rate': 3.9944379724837345e-07, 'rewards/chosen': -0.02097168006002903, 'rewards/rejected': -0.3955078125, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.37480467557907104, 'logps/chosen': -102.5250015258789, 'logps/rejected': -126.75, 'logits/chosen': -7.381249904632568, 'logits/rejected': -7.193749904632568, 'epoch': 1.05}
 35%|███▌      | 440/1257 [29:33<51:25,  3.78s/it] 35%|███▌      | 441/1257 [29:38<53:23,  3.93s/it] 35%|███▌      | 442/1257 [29:42<54:05,  3.98s/it] 35%|███▌      | 443/1257 [29:46<53:07,  3.92s/it] 35%|███▌      | 444/1257 [29:49<52:15,  3.86s/it] 35%|███▌      | 445/1257 [29:52<48:14,  3.56s/it] 35%|███▌      | 446/1257 [29:55<46:03,  3.41s/it] 36%|███▌      | 447/1257 [29:58<45:16,  3.35s/it] 36%|███▌      | 448/1257 [30:02<47:36,  3.53s/it] 36%|███▌      | 449/1257 [30:06<46:55,  3.48s/it] 36%|███▌      | 450/1257 [30:09<44:58,  3.34s/it]                                                  {'loss': 0.5431, 'grad_norm': 30.61377716064453, 'learning_rate': 3.98788693569569e-07, 'rewards/chosen': 0.11507873237133026, 'rewards/rejected': -0.4117187559604645, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.527148425579071, 'logps/chosen': -106.69999694824219, 'logps/rejected': -130.14999389648438, 'logits/chosen': -7.403124809265137, 'logits/rejected': -7.259375095367432, 'epoch': 1.07}
 36%|███▌      | 450/1257 [30:09<44:58,  3.34s/it] 36%|███▌      | 451/1257 [30:13<48:09,  3.59s/it] 36%|███▌      | 452/1257 [30:17<49:33,  3.69s/it] 36%|███▌      | 453/1257 [30:21<49:34,  3.70s/it] 36%|███▌      | 454/1257 [30:24<49:21,  3.69s/it] 36%|███▌      | 455/1257 [30:27<46:54,  3.51s/it] 36%|███▋      | 456/1257 [30:31<49:39,  3.72s/it] 36%|███▋      | 457/1257 [30:36<50:48,  3.81s/it] 36%|███▋      | 458/1257 [30:39<47:41,  3.58s/it] 37%|███▋      | 459/1257 [30:42<48:45,  3.67s/it] 37%|███▋      | 460/1257 [30:46<49:36,  3.73s/it]                                                  {'loss': 0.5485, 'grad_norm': 44.101261138916016, 'learning_rate': 3.978829413787401e-07, 'rewards/chosen': -0.0073638916946947575, 'rewards/rejected': -0.538867175579071, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.532031238079071, 'logps/chosen': -102.25, 'logps/rejected': -138.35000610351562, 'logits/chosen': -7.359375, 'logits/rejected': -7.037499904632568, 'epoch': 1.1}
 37%|███▋      | 460/1257 [30:46<49:36,  3.73s/it] 37%|███▋      | 461/1257 [30:50<48:43,  3.67s/it] 37%|███▋      | 462/1257 [30:54<48:35,  3.67s/it] 37%|███▋      | 463/1257 [30:57<49:17,  3.72s/it] 37%|███▋      | 464/1257 [31:02<51:21,  3.89s/it] 37%|███▋      | 465/1257 [31:06<52:12,  3.96s/it] 37%|███▋      | 466/1257 [31:09<49:07,  3.73s/it] 37%|███▋      | 467/1257 [31:13<49:05,  3.73s/it] 37%|███▋      | 468/1257 [31:16<48:56,  3.72s/it] 37%|███▋      | 469/1257 [31:20<49:45,  3.79s/it] 37%|███▋      | 470/1257 [31:25<51:20,  3.91s/it]                                                  {'loss': 0.5514, 'grad_norm': 54.70941925048828, 'learning_rate': 3.9672781047340214e-07, 'rewards/chosen': -0.06993408501148224, 'rewards/rejected': -0.568359375, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.4988769590854645, 'logps/chosen': -102.5, 'logps/rejected': -151.89999389648438, 'logits/chosen': -7.378125190734863, 'logits/rejected': -7.03125, 'epoch': 1.12}
 37%|███▋      | 470/1257 [31:25<51:20,  3.91s/it] 37%|███▋      | 471/1257 [31:28<49:40,  3.79s/it] 38%|███▊      | 472/1257 [31:31<48:11,  3.68s/it] 38%|███▊      | 473/1257 [31:35<49:06,  3.76s/it] 38%|███▊      | 474/1257 [31:39<50:14,  3.85s/it] 38%|███▊      | 475/1257 [31:43<50:32,  3.88s/it] 38%|███▊      | 476/1257 [31:47<49:17,  3.79s/it] 38%|███▊      | 477/1257 [31:50<48:08,  3.70s/it] 38%|███▊      | 478/1257 [31:54<48:08,  3.71s/it] 38%|███▊      | 479/1257 [31:58<49:59,  3.86s/it] 38%|███▊      | 480/1257 [32:02<50:12,  3.88s/it]                                                  {'loss': 0.5906, 'grad_norm': 43.411380767822266, 'learning_rate': 3.95324920261566e-07, 'rewards/chosen': 0.28547364473342896, 'rewards/rejected': -0.23593750596046448, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.521191418170929, 'logps/chosen': -185.5, 'logps/rejected': -201.0500030517578, 'logits/chosen': -7.403124809265137, 'logits/rejected': -7.1875, 'epoch': 1.15}
 38%|███▊      | 480/1257 [32:02<50:12,  3.88s/it] 38%|███▊      | 481/1257 [32:06<50:29,  3.90s/it] 38%|███▊      | 482/1257 [32:10<50:18,  3.89s/it] 38%|███▊      | 483/1257 [32:14<51:20,  3.98s/it] 39%|███▊      | 484/1257 [32:18<49:06,  3.81s/it] 39%|███▊      | 485/1257 [32:22<50:18,  3.91s/it] 39%|███▊      | 486/1257 [32:25<47:37,  3.71s/it] 39%|███▊      | 487/1257 [32:29<49:20,  3.85s/it] 39%|███▉      | 488/1257 [32:33<48:50,  3.81s/it] 39%|███▉      | 489/1257 [32:37<49:13,  3.85s/it] 39%|███▉      | 490/1257 [32:41<49:38,  3.88s/it]                                                  {'loss': 0.4729, 'grad_norm': 42.48030090332031, 'learning_rate': 3.9367623749144775e-07, 'rewards/chosen': 0.381591796875, 'rewards/rejected': -0.4124999940395355, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.794726550579071, 'logps/chosen': -158.60000610351562, 'logps/rejected': -187.0500030517578, 'logits/chosen': -7.290625095367432, 'logits/rejected': -7.237500190734863, 'epoch': 1.17}
 39%|███▉      | 490/1257 [32:41<49:38,  3.88s/it] 39%|███▉      | 491/1257 [32:45<48:45,  3.82s/it] 39%|███▉      | 492/1257 [32:49<50:12,  3.94s/it] 39%|███▉      | 493/1257 [32:53<49:33,  3.89s/it] 39%|███▉      | 494/1257 [32:56<49:27,  3.89s/it] 39%|███▉      | 495/1257 [33:00<49:12,  3.87s/it] 39%|███▉      | 496/1257 [33:04<49:59,  3.94s/it] 40%|███▉      | 497/1257 [33:08<49:02,  3.87s/it] 40%|███▉      | 498/1257 [33:12<48:37,  3.84s/it] 40%|███▉      | 499/1257 [33:16<49:25,  3.91s/it] 40%|███▉      | 500/1257 [33:19<47:05,  3.73s/it]                                                  {'loss': 0.54, 'grad_norm': 33.34567642211914, 'learning_rate': 3.917840734942332e-07, 'rewards/chosen': -0.0032104491256177425, 'rewards/rejected': -0.7115234136581421, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.706835925579071, 'logps/chosen': -118.0999984741211, 'logps/rejected': -140.10000610351562, 'logits/chosen': -7.440625190734863, 'logits/rejected': -7.396874904632568, 'epoch': 1.19}
 40%|███▉      | 500/1257 [33:19<47:05,  3.73s/it] 40%|███▉      | 501/1257 [33:23<46:49,  3.72s/it] 40%|███▉      | 502/1257 [33:26<44:21,  3.52s/it] 40%|████      | 503/1257 [33:30<46:01,  3.66s/it] 40%|████      | 504/1257 [33:34<47:12,  3.76s/it] 40%|████      | 505/1257 [33:38<47:02,  3.75s/it] 40%|████      | 506/1257 [33:41<44:13,  3.53s/it] 40%|████      | 507/1257 [33:45<45:47,  3.66s/it] 40%|████      | 508/1257 [33:48<43:33,  3.49s/it] 40%|████      | 509/1257 [33:52<45:45,  3.67s/it] 41%|████      | 510/1257 [33:55<44:06,  3.54s/it]                                                  {'loss': 0.5444, 'grad_norm': 42.52541732788086, 'learning_rate': 3.89651080943763e-07, 'rewards/chosen': -0.027338409796357155, 'rewards/rejected': -0.630078136920929, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.6030517816543579, 'logps/chosen': -105.0, 'logps/rejected': -129.10000610351562, 'logits/chosen': -7.431250095367432, 'logits/rejected': -7.253125190734863, 'epoch': 1.22}
 41%|████      | 510/1257 [33:55<44:06,  3.54s/it] 41%|████      | 511/1257 [33:59<46:14,  3.72s/it] 41%|████      | 512/1257 [34:03<44:56,  3.62s/it] 41%|████      | 513/1257 [34:07<46:09,  3.72s/it] 41%|████      | 514/1257 [34:10<45:33,  3.68s/it] 41%|████      | 515/1257 [34:14<46:03,  3.72s/it] 41%|████      | 516/1257 [34:17<43:22,  3.51s/it] 41%|████      | 517/1257 [34:21<44:04,  3.57s/it] 41%|████      | 518/1257 [34:25<45:55,  3.73s/it] 41%|████▏     | 519/1257 [34:28<43:42,  3.55s/it] 41%|████▏     | 520/1257 [34:31<42:44,  3.48s/it]                                                  {'loss': 0.5231, 'grad_norm': 45.96000671386719, 'learning_rate': 3.872802501376797e-07, 'rewards/chosen': 0.5414367914199829, 'rewards/rejected': -0.10761718451976776, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.64947509765625, 'logps/chosen': -166.8000030517578, 'logps/rejected': -187.39999389648438, 'logits/chosen': -7.287499904632568, 'logits/rejected': -7.171875, 'epoch': 1.24}
 41%|████▏     | 520/1257 [34:31<42:44,  3.48s/it] 41%|████▏     | 521/1257 [34:36<45:12,  3.69s/it] 42%|████▏     | 522/1257 [34:39<44:41,  3.65s/it] 42%|████▏     | 523/1257 [34:42<42:53,  3.51s/it] 42%|████▏     | 524/1257 [34:46<45:03,  3.69s/it] 42%|████▏     | 525/1257 [34:51<47:07,  3.86s/it] 42%|████▏     | 526/1257 [34:55<47:30,  3.90s/it] 42%|████▏     | 527/1257 [34:58<46:23,  3.81s/it] 42%|████▏     | 528/1257 [35:02<47:32,  3.91s/it] 42%|████▏     | 529/1257 [35:06<47:37,  3.93s/it] 42%|████▏     | 530/1257 [35:10<47:51,  3.95s/it]                                                  {'loss': 0.5136, 'grad_norm': 57.93739700317383, 'learning_rate': 3.846749048052527e-07, 'rewards/chosen': 0.21663817763328552, 'rewards/rejected': -0.5, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7173827886581421, 'logps/chosen': -141.8000030517578, 'logps/rejected': -175.4499969482422, 'logits/chosen': -7.237500190734863, 'logits/rejected': -7.056250095367432, 'epoch': 1.26}
 42%|████▏     | 530/1257 [35:10<47:51,  3.95s/it] 42%|████▏     | 531/1257 [35:14<46:49,  3.87s/it] 42%|████▏     | 532/1257 [35:18<47:54,  3.96s/it] 42%|████▏     | 533/1257 [35:21<44:59,  3.73s/it] 42%|████▏     | 534/1257 [35:25<45:49,  3.80s/it] 43%|████▎     | 535/1257 [35:27<38:25,  3.19s/it] 43%|████▎     | 536/1257 [35:31<39:15,  3.27s/it] 43%|████▎     | 537/1257 [35:33<36:31,  3.04s/it] 43%|████▎     | 538/1257 [35:36<37:01,  3.09s/it] 43%|████▎     | 539/1257 [35:40<38:57,  3.26s/it] 43%|████▎     | 540/1257 [35:43<39:49,  3.33s/it]                                                  {'loss': 0.5155, 'grad_norm': 36.221065521240234, 'learning_rate': 3.8183869744775487e-07, 'rewards/chosen': 0.0010772704845294356, 'rewards/rejected': -0.7513672113418579, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.7528320550918579, 'logps/chosen': -102.55000305175781, 'logps/rejected': -140.60000610351562, 'logits/chosen': -7.5, 'logits/rejected': -7.215624809265137, 'epoch': 1.29}
 43%|████▎     | 540/1257 [35:43<39:49,  3.33s/it] 43%|████▎     | 541/1257 [35:48<42:35,  3.57s/it] 43%|████▎     | 542/1257 [35:50<39:57,  3.35s/it] 43%|████▎     | 543/1257 [35:54<41:58,  3.53s/it] 43%|████▎     | 544/1257 [35:58<43:30,  3.66s/it] 43%|████▎     | 545/1257 [36:02<44:28,  3.75s/it] 43%|████▎     | 546/1257 [36:06<43:18,  3.65s/it] 44%|████▎     | 547/1257 [36:09<42:50,  3.62s/it] 44%|████▎     | 548/1257 [36:12<41:20,  3.50s/it] 44%|████▎     | 549/1257 [36:15<38:53,  3.30s/it] 44%|████▍     | 550/1257 [36:20<42:19,  3.59s/it]                                                  {'loss': 0.5183, 'grad_norm': 44.770633697509766, 'learning_rate': 3.787756042179271e-07, 'rewards/chosen': 0.669604480266571, 'rewards/rejected': -0.12832030653953552, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.7974609136581421, 'logps/chosen': -192.35000610351562, 'logps/rejected': -191.85000610351562, 'logits/chosen': -7.146874904632568, 'logits/rejected': -7.046875, 'epoch': 1.31}
 44%|████▍     | 550/1257 [36:20<42:19,  3.59s/it] 44%|████▍     | 551/1257 [36:24<44:04,  3.75s/it] 44%|████▍     | 552/1257 [36:28<44:39,  3.80s/it] 44%|████▍     | 553/1257 [36:30<40:10,  3.42s/it] 44%|████▍     | 554/1257 [36:34<42:41,  3.64s/it] 44%|████▍     | 555/1257 [36:37<40:58,  3.50s/it] 44%|████▍     | 556/1257 [36:41<41:35,  3.56s/it] 44%|████▍     | 557/1257 [36:44<39:28,  3.38s/it] 44%|████▍     | 558/1257 [36:47<38:51,  3.34s/it] 44%|████▍     | 559/1257 [36:52<41:43,  3.59s/it] 45%|████▍     | 560/1257 [36:55<42:23,  3.65s/it]                                                  {'loss': 0.5202, 'grad_norm': 36.700626373291016, 'learning_rate': 3.7548991934570597e-07, 'rewards/chosen': -0.10993652045726776, 'rewards/rejected': -0.775390625, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6650390625, 'logps/chosen': -114.05000305175781, 'logps/rejected': -128.60000610351562, 'logits/chosen': -7.375, 'logits/rejected': -7.412499904632568, 'epoch': 1.34}
 45%|████▍     | 560/1257 [36:55<42:23,  3.65s/it] 45%|████▍     | 561/1257 [36:59<41:50,  3.61s/it] 45%|████▍     | 562/1257 [37:02<39:52,  3.44s/it] 45%|████▍     | 563/1257 [37:06<42:32,  3.68s/it] 45%|████▍     | 564/1257 [37:10<44:03,  3.81s/it] 45%|████▍     | 565/1257 [37:13<39:17,  3.41s/it] 45%|████▌     | 566/1257 [37:16<38:29,  3.34s/it] 45%|████▌     | 567/1257 [37:20<41:22,  3.60s/it] 45%|████▌     | 568/1257 [37:24<43:41,  3.80s/it] 45%|████▌     | 569/1257 [37:28<43:30,  3.80s/it] 45%|████▌     | 570/1257 [37:31<40:24,  3.53s/it]                                                  {'loss': 0.5044, 'grad_norm': 36.82920837402344, 'learning_rate': 3.719862491180314e-07, 'rewards/chosen': 0.00800476036965847, 'rewards/rejected': -0.7275390625, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.735546886920929, 'logps/chosen': -104.8499984741211, 'logps/rejected': -121.0999984741211, 'logits/chosen': -7.46875, 'logits/rejected': -7.262499809265137, 'epoch': 1.36}
 45%|████▌     | 570/1257 [37:31<40:24,  3.53s/it] 45%|████▌     | 571/1257 [37:34<37:27,  3.28s/it] 46%|████▌     | 572/1257 [37:38<39:38,  3.47s/it] 46%|████▌     | 573/1257 [37:40<37:11,  3.26s/it] 46%|████▌     | 574/1257 [37:44<38:42,  3.40s/it] 46%|████▌     | 575/1257 [37:48<39:13,  3.45s/it] 46%|████▌     | 576/1257 [37:51<37:55,  3.34s/it] 46%|████▌     | 577/1257 [37:55<39:54,  3.52s/it] 46%|████▌     | 578/1257 [37:59<41:25,  3.66s/it] 46%|████▌     | 579/1257 [38:02<41:34,  3.68s/it] 46%|████▌     | 580/1257 [38:07<43:02,  3.81s/it]                                                  {'loss': 0.5286, 'grad_norm': 38.34408950805664, 'learning_rate': 3.6826950542117343e-07, 'rewards/chosen': 0.10908202826976776, 'rewards/rejected': -0.581250011920929, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.689648449420929, 'logps/chosen': -140.5500030517578, 'logps/rejected': -166.0, 'logits/chosen': -7.25, 'logits/rejected': -7.040625095367432, 'epoch': 1.38}
 46%|████▌     | 580/1257 [38:07<43:02,  3.81s/it] 46%|████▌     | 581/1257 [38:10<41:50,  3.71s/it] 46%|████▋     | 582/1257 [38:13<38:01,  3.38s/it] 46%|████▋     | 583/1257 [38:16<38:09,  3.40s/it] 46%|████▋     | 584/1257 [38:20<39:15,  3.50s/it] 47%|████▋     | 585/1257 [38:24<40:41,  3.63s/it] 47%|████▋     | 586/1257 [38:28<41:19,  3.69s/it] 47%|████▋     | 587/1257 [38:32<42:09,  3.78s/it] 47%|████▋     | 588/1257 [38:35<40:40,  3.65s/it] 47%|████▋     | 589/1257 [38:39<41:52,  3.76s/it] 47%|████▋     | 590/1257 [38:43<41:48,  3.76s/it]                                                  {'loss': 0.5314, 'grad_norm': 63.80107879638672, 'learning_rate': 3.6434489885463144e-07, 'rewards/chosen': 0.529449462890625, 'rewards/rejected': -0.29570311307907104, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.8263183832168579, 'logps/chosen': -157.25, 'logps/rejected': -187.85000610351562, 'logits/chosen': -7.28125, 'logits/rejected': -7.087500095367432, 'epoch': 1.41}
 47%|████▋     | 590/1257 [38:43<41:48,  3.76s/it] 47%|████▋     | 591/1257 [38:47<42:29,  3.83s/it] 47%|████▋     | 592/1257 [38:50<39:21,  3.55s/it] 47%|████▋     | 593/1257 [38:53<37:05,  3.35s/it] 47%|████▋     | 594/1257 [38:56<37:30,  3.39s/it] 47%|████▋     | 595/1257 [38:59<34:34,  3.13s/it] 47%|████▋     | 596/1257 [39:02<35:46,  3.25s/it] 47%|████▋     | 597/1257 [39:05<35:58,  3.27s/it] 48%|████▊     | 598/1257 [39:09<38:12,  3.48s/it] 48%|████▊     | 599/1257 [39:12<37:01,  3.38s/it] 48%|████▊     | 600/1257 [39:16<38:38,  3.53s/it]                                                  {'loss': 0.4949, 'grad_norm': 35.46062469482422, 'learning_rate': 3.6021793142625916e-07, 'rewards/chosen': 0.24403992295265198, 'rewards/rejected': -0.47929686307907104, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.7240234613418579, 'logps/chosen': -135.25, 'logps/rejected': -147.0, 'logits/chosen': -7.303124904632568, 'logits/rejected': -7.21875, 'epoch': 1.43}
 48%|████▊     | 600/1257 [39:16<38:38,  3.53s/it] 48%|████▊     | 601/1257 [39:20<38:37,  3.53s/it] 48%|████▊     | 602/1257 [39:24<40:45,  3.73s/it] 48%|████▊     | 603/1257 [39:28<41:48,  3.84s/it] 48%|████▊     | 604/1257 [39:32<41:07,  3.78s/it] 48%|████▊     | 605/1257 [39:36<42:17,  3.89s/it] 48%|████▊     | 606/1257 [39:39<40:09,  3.70s/it] 48%|████▊     | 607/1257 [39:42<38:22,  3.54s/it] 48%|████▊     | 608/1257 [39:46<37:40,  3.48s/it] 48%|████▊     | 609/1257 [39:48<34:32,  3.20s/it] 49%|████▊     | 610/1257 [39:52<36:11,  3.36s/it]                                                  {'loss': 0.5265, 'grad_norm': 43.56227493286133, 'learning_rate': 3.558943888388572e-07, 'rewards/chosen': 0.09066162258386612, 'rewards/rejected': -0.574023425579071, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.665234386920929, 'logps/chosen': -133.6999969482422, 'logps/rejected': -160.6999969482422, 'logits/chosen': -7.253125190734863, 'logits/rejected': -7.103125095367432, 'epoch': 1.46}
 49%|████▊     | 610/1257 [39:52<36:11,  3.36s/it] 49%|████▊     | 611/1257 [39:56<36:58,  3.43s/it] 49%|████▊     | 612/1257 [40:00<38:16,  3.56s/it] 49%|████▉     | 613/1257 [40:04<40:24,  3.77s/it] 49%|████▉     | 614/1257 [40:07<38:40,  3.61s/it] 49%|████▉     | 615/1257 [40:11<39:29,  3.69s/it] 49%|████▉     | 616/1257 [40:15<39:54,  3.73s/it] 49%|████▉     | 617/1257 [40:18<39:37,  3.72s/it] 49%|████▉     | 618/1257 [40:21<36:40,  3.44s/it] 49%|████▉     | 619/1257 [40:24<36:08,  3.40s/it] 49%|████▉     | 620/1257 [40:28<35:56,  3.39s/it]                                                  {'loss': 0.5598, 'grad_norm': 64.1527099609375, 'learning_rate': 3.513803323790459e-07, 'rewards/chosen': -0.21240234375, 'rewards/rejected': -0.8304687738418579, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.617626965045929, 'logps/chosen': -106.75, 'logps/rejected': -123.5999984741211, 'logits/chosen': -7.46875, 'logits/rejected': -7.259375095367432, 'epoch': 1.48}
 49%|████▉     | 620/1257 [40:28<35:56,  3.39s/it] 49%|████▉     | 621/1257 [40:32<36:50,  3.48s/it] 49%|████▉     | 622/1257 [40:35<36:51,  3.48s/it] 50%|████▉     | 623/1257 [40:38<36:24,  3.44s/it] 50%|████▉     | 624/1257 [40:42<37:33,  3.56s/it] 50%|████▉     | 625/1257 [40:46<38:24,  3.65s/it] 50%|████▉     | 626/1257 [40:49<35:19,  3.36s/it] 50%|████▉     | 627/1257 [40:52<36:20,  3.46s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.61s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:39,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:32,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:32,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.41s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.33s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                  
                                               [A{'eval_loss': 0.7232967019081116, 'eval_runtime': 80.6036, 'eval_samples_per_second': 11.823, 'eval_steps_per_second': 0.744, 'eval_rewards/chosen': 1.9979830980300903, 'eval_rewards/rejected': 0.8592203855514526, 'eval_rewards/accuracies': 0.6597222089767456, 'eval_rewards/margins': 1.1389241218566895, 'eval_logps/chosen': -365.57501220703125, 'eval_logps/rejected': -146.82708740234375, 'eval_logits/chosen': -6.733593940734863, 'eval_logits/rejected': -7.496354103088379, 'epoch': 1.5}
 50%|████▉     | 627/1257 [42:13<36:20,  3.46s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 50%|████▉     | 628/1257 [42:40<6:04:11, 34.74s/it] 50%|█████     | 629/1257 [42:44<4:27:45, 25.58s/it] 50%|█████     | 630/1257 [42:48<3:18:40, 19.01s/it]                                                    {'loss': 0.4222, 'grad_norm': 41.07364273071289, 'learning_rate': 3.466820904197903e-07, 'rewards/chosen': -0.03168029710650444, 'rewards/rejected': -1.058984398841858, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.0261719226837158, 'logps/chosen': -93.05000305175781, 'logps/rejected': -139.8000030517578, 'logits/chosen': -7.396874904632568, 'logits/rejected': -7.181250095367432, 'epoch': 1.5}
 50%|█████     | 630/1257 [42:48<3:18:40, 19.01s/it] 50%|█████     | 631/1257 [42:52<2:30:52, 14.46s/it] 50%|█████     | 632/1257 [42:55<1:56:37, 11.20s/it] 50%|█████     | 633/1257 [43:00<1:34:52,  9.12s/it] 50%|█████     | 634/1257 [43:04<1:19:05,  7.62s/it] 51%|█████     | 635/1257 [43:08<1:07:11,  6.48s/it] 51%|█████     | 636/1257 [43:12<1:00:01,  5.80s/it] 51%|█████     | 637/1257 [43:16<55:07,  5.33s/it]   51%|█████     | 638/1257 [43:20<50:46,  4.92s/it] 51%|█████     | 639/1257 [43:23<44:05,  4.28s/it] 51%|█████     | 640/1257 [43:25<37:24,  3.64s/it]                                                  {'loss': 0.5033, 'grad_norm': 39.70356750488281, 'learning_rate': 3.418062495484899e-07, 'rewards/chosen': -0.10791931301355362, 'rewards/rejected': -0.9546874761581421, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.8462890386581421, 'logps/chosen': -103.05000305175781, 'logps/rejected': -124.8499984741211, 'logits/chosen': -7.456250190734863, 'logits/rejected': -7.234375, 'epoch': 1.53}
 51%|█████     | 640/1257 [43:25<37:24,  3.64s/it] 51%|█████     | 641/1257 [43:29<38:15,  3.73s/it] 51%|█████     | 642/1257 [43:33<37:49,  3.69s/it] 51%|█████     | 643/1257 [43:36<37:52,  3.70s/it] 51%|█████     | 644/1257 [43:39<35:07,  3.44s/it] 51%|█████▏    | 645/1257 [43:43<36:38,  3.59s/it] 51%|█████▏    | 646/1257 [43:47<37:41,  3.70s/it] 51%|█████▏    | 647/1257 [43:51<37:48,  3.72s/it] 52%|█████▏    | 648/1257 [43:54<35:45,  3.52s/it] 52%|█████▏    | 649/1257 [43:58<36:51,  3.64s/it] 52%|█████▏    | 650/1257 [44:02<37:24,  3.70s/it]                                                  {'loss': 0.4616, 'grad_norm': 48.40827178955078, 'learning_rate': 3.3675964533307044e-07, 'rewards/chosen': 0.16466979682445526, 'rewards/rejected': -0.810546875, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.974609375, 'logps/chosen': -139.25, 'logps/rejected': -161.64999389648438, 'logits/chosen': -7.324999809265137, 'logits/rejected': -7.081250190734863, 'epoch': 1.55}
 52%|█████▏    | 650/1257 [44:02<37:24,  3.70s/it] 52%|█████▏    | 651/1257 [44:06<38:46,  3.84s/it] 52%|█████▏    | 652/1257 [44:10<39:48,  3.95s/it] 52%|█████▏    | 653/1257 [44:13<36:14,  3.60s/it] 52%|█████▏    | 654/1257 [44:17<38:01,  3.78s/it] 52%|█████▏    | 655/1257 [44:21<37:34,  3.75s/it] 52%|█████▏    | 656/1257 [44:25<38:18,  3.83s/it] 52%|█████▏    | 657/1257 [44:28<35:42,  3.57s/it] 52%|█████▏    | 658/1257 [44:32<37:36,  3.77s/it] 52%|█████▏    | 659/1257 [44:35<35:06,  3.52s/it] 53%|█████▎    | 660/1257 [44:38<33:36,  3.38s/it]                                                  {'loss': 0.4821, 'grad_norm': 25.718185424804688, 'learning_rate': 3.315493527390239e-07, 'rewards/chosen': -0.18625488877296448, 'rewards/rejected': -1.0593750476837158, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.873046875, 'logps/chosen': -104.44999694824219, 'logps/rejected': -132.0, 'logits/chosen': -7.515625, 'logits/rejected': -7.356249809265137, 'epoch': 1.58}
 53%|█████▎    | 660/1257 [44:38<33:36,  3.38s/it] 53%|█████▎    | 661/1257 [44:41<31:38,  3.19s/it] 53%|█████▎    | 662/1257 [44:45<33:48,  3.41s/it] 53%|█████▎    | 663/1257 [44:48<35:06,  3.55s/it] 53%|█████▎    | 664/1257 [44:51<31:33,  3.19s/it] 53%|█████▎    | 665/1257 [44:55<33:31,  3.40s/it] 53%|█████▎    | 666/1257 [44:59<35:42,  3.63s/it] 53%|█████▎    | 667/1257 [45:02<33:27,  3.40s/it] 53%|█████▎    | 668/1257 [45:05<33:39,  3.43s/it] 53%|█████▎    | 669/1257 [45:08<31:59,  3.26s/it] 53%|█████▎    | 670/1257 [45:12<33:42,  3.44s/it]                                                  {'loss': 0.5334, 'grad_norm': 47.799129486083984, 'learning_rate': 3.2618267621083083e-07, 'rewards/chosen': -0.19194336235523224, 'rewards/rejected': -0.9195312261581421, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.7279297113418579, 'logps/chosen': -106.55000305175781, 'logps/rejected': -118.30000305175781, 'logits/chosen': -7.353125095367432, 'logits/rejected': -7.340624809265137, 'epoch': 1.6}
 53%|█████▎    | 670/1257 [45:12<33:42,  3.44s/it] 53%|█████▎    | 671/1257 [45:15<34:04,  3.49s/it] 53%|█████▎    | 672/1257 [45:19<33:50,  3.47s/it] 54%|█████▎    | 673/1257 [45:23<34:51,  3.58s/it] 54%|█████▎    | 674/1257 [45:26<33:59,  3.50s/it] 54%|█████▎    | 675/1257 [45:29<30:56,  3.19s/it] 54%|█████▍    | 676/1257 [45:32<32:29,  3.35s/it] 54%|█████▍    | 677/1257 [45:36<34:08,  3.53s/it] 54%|█████▍    | 678/1257 [45:39<31:46,  3.29s/it] 54%|█████▍    | 679/1257 [45:43<34:09,  3.55s/it] 54%|█████▍    | 680/1257 [45:47<35:11,  3.66s/it]                                                  {'loss': 0.5093, 'grad_norm': 39.85972213745117, 'learning_rate': 3.2066713943166967e-07, 'rewards/chosen': 0.094970703125, 'rewards/rejected': -0.846875011920929, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.940625011920929, 'logps/chosen': -127.67500305175781, 'logps/rejected': -144.25, 'logits/chosen': -7.143750190734863, 'logits/rejected': -7.043749809265137, 'epoch': 1.62}
 54%|█████▍    | 680/1257 [45:47<35:11,  3.66s/it] 54%|█████▍    | 681/1257 [45:50<32:43,  3.41s/it] 54%|█████▍    | 682/1257 [45:54<34:02,  3.55s/it] 54%|█████▍    | 683/1257 [45:57<34:00,  3.55s/it] 54%|█████▍    | 684/1257 [46:01<34:43,  3.64s/it] 54%|█████▍    | 685/1257 [46:05<34:55,  3.66s/it] 55%|█████▍    | 686/1257 [46:09<36:19,  3.82s/it] 55%|█████▍    | 687/1257 [46:12<34:37,  3.64s/it] 55%|█████▍    | 688/1257 [46:15<31:07,  3.28s/it] 55%|█████▍    | 689/1257 [46:18<31:00,  3.28s/it] 55%|█████▍    | 690/1257 [46:21<30:35,  3.24s/it]                                                  {'loss': 0.5287, 'grad_norm': 37.655853271484375, 'learning_rate': 3.1501047477576993e-07, 'rewards/chosen': -0.209716796875, 'rewards/rejected': -1.0085937976837158, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.798632800579071, 'logps/chosen': -100.25, 'logps/rejected': -134.89999389648438, 'logits/chosen': -7.315625190734863, 'logits/rejected': -7.140625, 'epoch': 1.65}
 55%|█████▍    | 690/1257 [46:21<30:35,  3.24s/it] 55%|█████▍    | 691/1257 [46:24<28:25,  3.01s/it] 55%|█████▌    | 692/1257 [46:27<30:43,  3.26s/it] 55%|█████▌    | 693/1257 [46:31<32:49,  3.49s/it] 55%|█████▌    | 694/1257 [46:35<32:02,  3.41s/it] 55%|█████▌    | 695/1257 [46:38<30:43,  3.28s/it] 55%|█████▌    | 696/1257 [46:41<31:35,  3.38s/it] 55%|█████▌    | 697/1257 [46:45<33:01,  3.54s/it] 56%|█████▌    | 698/1257 [46:48<31:57,  3.43s/it] 56%|█████▌    | 699/1257 [46:52<31:24,  3.38s/it] 56%|█████▌    | 700/1257 [46:56<32:53,  3.54s/it]                                                  {'loss': 0.5866, 'grad_norm': 44.117164611816406, 'learning_rate': 3.0922061246819646e-07, 'rewards/chosen': 0.14814452826976776, 'rewards/rejected': -0.567187488079071, 'rewards/accuracies': 0.668749988079071, 'rewards/margins': 0.716601550579071, 'logps/chosen': -142.6999969482422, 'logps/rejected': -167.0500030517578, 'logits/chosen': -7.418749809265137, 'logits/rejected': -7.256249904632568, 'epoch': 1.67}
 56%|█████▌    | 700/1257 [46:56<32:53,  3.54s/it] 56%|█████▌    | 701/1257 [47:00<34:17,  3.70s/it] 56%|█████▌    | 702/1257 [47:03<34:10,  3.69s/it] 56%|█████▌    | 703/1257 [47:06<31:38,  3.43s/it] 56%|█████▌    | 704/1257 [47:10<33:44,  3.66s/it] 56%|█████▌    | 705/1257 [47:14<34:59,  3.80s/it] 56%|█████▌    | 706/1257 [47:18<35:08,  3.83s/it] 56%|█████▌    | 707/1257 [47:21<31:25,  3.43s/it] 56%|█████▋    | 708/1257 [47:24<30:44,  3.36s/it] 56%|█████▋    | 709/1257 [47:28<32:55,  3.61s/it] 56%|█████▋    | 710/1257 [47:32<33:13,  3.64s/it]                                                  {'loss': 0.4843, 'grad_norm': 46.4208984375, 'learning_rate': 3.033056694672604e-07, 'rewards/chosen': -0.19542236626148224, 'rewards/rejected': -1.066796898841858, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.87109375, 'logps/chosen': -109.75, 'logps/rejected': -123.0250015258789, 'logits/chosen': -7.303124904632568, 'logits/rejected': -7.240624904632568, 'epoch': 1.69}
 56%|█████▋    | 710/1257 [47:32<33:13,  3.64s/it] 57%|█████▋    | 711/1257 [47:36<34:04,  3.74s/it] 57%|█████▋    | 712/1257 [47:40<34:00,  3.74s/it] 57%|█████▋    | 713/1257 [47:43<32:40,  3.60s/it] 57%|█████▋    | 714/1257 [47:47<34:18,  3.79s/it] 57%|█████▋    | 715/1257 [47:51<34:38,  3.83s/it] 57%|█████▋    | 716/1257 [47:54<32:59,  3.66s/it] 57%|█████▋    | 717/1257 [47:58<33:45,  3.75s/it] 57%|█████▋    | 718/1257 [48:02<32:19,  3.60s/it] 57%|█████▋    | 719/1257 [48:05<33:00,  3.68s/it] 57%|█████▋    | 720/1257 [48:08<30:38,  3.42s/it]                                                  {'loss': 0.5004, 'grad_norm': 37.7210807800293, 'learning_rate': 2.9727393808514503e-07, 'rewards/chosen': 0.0030029297340661287, 'rewards/rejected': -0.8812500238418579, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.8851562738418579, 'logps/chosen': -129.0500030517578, 'logps/rejected': -163.0, 'logits/chosen': -7.515625, 'logits/rejected': -7.271874904632568, 'epoch': 1.72}
 57%|█████▋    | 720/1257 [48:08<30:38,  3.42s/it] 57%|█████▋    | 721/1257 [48:11<28:38,  3.21s/it] 57%|█████▋    | 722/1257 [48:14<27:42,  3.11s/it] 58%|█████▊    | 723/1257 [48:18<31:21,  3.52s/it] 58%|█████▊    | 724/1257 [48:22<30:56,  3.48s/it] 58%|█████▊    | 725/1257 [48:24<27:36,  3.11s/it] 58%|█████▊    | 726/1257 [48:28<30:41,  3.47s/it] 58%|█████▊    | 727/1257 [48:32<30:06,  3.41s/it] 58%|█████▊    | 728/1257 [48:36<32:16,  3.66s/it] 58%|█████▊    | 729/1257 [48:40<33:47,  3.84s/it] 58%|█████▊    | 730/1257 [48:43<30:43,  3.50s/it]                                                  {'loss': 0.432, 'grad_norm': 33.261940002441406, 'learning_rate': 2.911338743626974e-07, 'rewards/chosen': -0.18183593451976776, 'rewards/rejected': -1.2082030773162842, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.025976538658142, 'logps/chosen': -100.9000015258789, 'logps/rejected': -142.25, 'logits/chosen': -7.375, 'logits/rejected': -7.196875095367432, 'epoch': 1.74}
 58%|█████▊    | 730/1257 [48:43<30:43,  3.50s/it] 58%|█████▊    | 731/1257 [48:47<31:52,  3.64s/it] 58%|█████▊    | 732/1257 [48:51<33:24,  3.82s/it] 58%|█████▊    | 733/1257 [48:55<33:59,  3.89s/it] 58%|█████▊    | 734/1257 [48:58<32:03,  3.68s/it] 58%|█████▊    | 735/1257 [49:01<29:43,  3.42s/it] 59%|█████▊    | 736/1257 [49:05<31:02,  3.57s/it] 59%|█████▊    | 737/1257 [49:09<32:39,  3.77s/it] 59%|█████▊    | 738/1257 [49:12<31:20,  3.62s/it] 59%|█████▉    | 739/1257 [49:16<31:44,  3.68s/it] 59%|█████▉    | 740/1257 [49:20<32:05,  3.72s/it]                                                  {'loss': 0.436, 'grad_norm': 43.70119857788086, 'learning_rate': 2.848940862146858e-07, 'rewards/chosen': 0.22524413466453552, 'rewards/rejected': -0.8218749761581421, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.046875, 'logps/chosen': -134.25, 'logps/rejected': -169.0, 'logits/chosen': -7.356249809265137, 'logits/rejected': -7.268750190734863, 'epoch': 1.77}
 59%|█████▉    | 740/1257 [49:20<32:05,  3.72s/it] 59%|█████▉    | 741/1257 [49:24<31:22,  3.65s/it] 59%|█████▉    | 742/1257 [49:27<30:54,  3.60s/it] 59%|█████▉    | 743/1257 [49:31<31:30,  3.68s/it] 59%|█████▉    | 744/1257 [49:34<30:57,  3.62s/it] 59%|█████▉    | 745/1257 [49:38<30:56,  3.63s/it] 59%|█████▉    | 746/1257 [49:42<31:54,  3.75s/it] 59%|█████▉    | 747/1257 [49:45<29:25,  3.46s/it] 60%|█████▉    | 748/1257 [49:47<26:18,  3.10s/it] 60%|█████▉    | 749/1257 [49:51<28:21,  3.35s/it] 60%|█████▉    | 750/1257 [49:55<29:52,  3.54s/it]                                                  {'loss': 0.5207, 'grad_norm': 76.79391479492188, 'learning_rate': 2.785633213621402e-07, 'rewards/chosen': -0.25677490234375, 'rewards/rejected': -1.054296851158142, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.7972656488418579, 'logps/chosen': -115.0999984741211, 'logps/rejected': -120.1500015258789, 'logits/chosen': -7.203125, 'logits/rejected': -7.296875, 'epoch': 1.79}
 60%|█████▉    | 750/1257 [49:55<29:52,  3.54s/it] 60%|█████▉    | 751/1257 [49:58<27:43,  3.29s/it] 60%|█████▉    | 752/1257 [50:01<27:51,  3.31s/it] 60%|█████▉    | 753/1257 [50:04<27:37,  3.29s/it] 60%|█████▉    | 754/1257 [50:08<28:28,  3.40s/it] 60%|██████    | 755/1257 [50:12<29:50,  3.57s/it] 60%|██████    | 756/1257 [50:16<31:11,  3.74s/it] 60%|██████    | 757/1257 [50:20<31:36,  3.79s/it] 60%|██████    | 758/1257 [50:24<32:18,  3.89s/it] 60%|██████    | 759/1257 [50:27<29:17,  3.53s/it] 60%|██████    | 760/1257 [50:31<30:19,  3.66s/it]                                                  {'loss': 0.4871, 'grad_norm': 84.25546264648438, 'learning_rate': 2.721504550686949e-07, 'rewards/chosen': 0.3184066712856293, 'rewards/rejected': -0.592578113079071, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 0.911816418170929, 'logps/chosen': -153.25, 'logps/rejected': -162.39999389648438, 'logits/chosen': -7.240624904632568, 'logits/rejected': -7.275000095367432, 'epoch': 1.81}
 60%|██████    | 760/1257 [50:31<30:19,  3.66s/it] 61%|██████    | 761/1257 [50:34<29:33,  3.58s/it] 61%|██████    | 762/1257 [50:38<30:22,  3.68s/it] 61%|██████    | 763/1257 [50:42<30:59,  3.76s/it] 61%|██████    | 764/1257 [50:46<31:15,  3.80s/it] 61%|██████    | 765/1257 [50:50<31:17,  3.82s/it] 61%|██████    | 766/1257 [50:53<30:07,  3.68s/it] 61%|██████    | 767/1257 [50:56<29:10,  3.57s/it] 61%|██████    | 768/1257 [51:00<28:38,  3.51s/it] 61%|██████    | 769/1257 [51:04<29:18,  3.60s/it] 61%|██████▏   | 770/1257 [51:07<27:44,  3.42s/it]                                                  {'loss': 0.4817, 'grad_norm': 27.870166778564453, 'learning_rate': 2.656644776981262e-07, 'rewards/chosen': 0.15611572563648224, 'rewards/rejected': -0.949999988079071, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.104882836341858, 'logps/chosen': -133.64999389648438, 'logps/rejected': -156.6999969482422, 'logits/chosen': -7.428124904632568, 'logits/rejected': -7.384375095367432, 'epoch': 1.84}
 61%|██████▏   | 770/1257 [51:07<27:44,  3.42s/it] 61%|██████▏   | 771/1257 [51:10<27:28,  3.39s/it] 61%|██████▏   | 772/1257 [51:14<28:58,  3.58s/it] 61%|██████▏   | 773/1257 [51:17<27:50,  3.45s/it] 62%|██████▏   | 774/1257 [51:20<27:20,  3.40s/it] 62%|██████▏   | 775/1257 [51:24<27:02,  3.37s/it] 62%|██████▏   | 776/1257 [51:28<28:10,  3.51s/it] 62%|██████▏   | 777/1257 [51:32<29:46,  3.72s/it] 62%|██████▏   | 778/1257 [51:34<26:38,  3.34s/it] 62%|██████▏   | 779/1257 [51:38<27:04,  3.40s/it] 62%|██████▏   | 780/1257 [51:42<28:41,  3.61s/it]                                                  {'loss': 0.5388, 'grad_norm': 39.25352478027344, 'learning_rate': 2.591144821105276e-07, 'rewards/chosen': -0.07807616889476776, 'rewards/rejected': -0.940234363079071, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.8607422113418579, 'logps/chosen': -140.3000030517578, 'logps/rejected': -149.35000610351562, 'logits/chosen': -7.246874809265137, 'logits/rejected': -7.15625, 'epoch': 1.86}
 62%|██████▏   | 780/1257 [51:42<28:41,  3.61s/it] 62%|██████▏   | 781/1257 [51:45<27:52,  3.51s/it] 62%|██████▏   | 782/1257 [51:49<28:48,  3.64s/it] 62%|██████▏   | 783/1257 [51:52<27:46,  3.52s/it] 62%|██████▏   | 784/1257 [51:56<29:07,  3.69s/it] 62%|██████▏   | 785/1257 [52:00<29:41,  3.77s/it] 63%|██████▎   | 786/1257 [52:04<29:55,  3.81s/it] 63%|██████▎   | 787/1257 [52:07<28:16,  3.61s/it] 63%|██████▎   | 788/1257 [52:11<28:57,  3.71s/it] 63%|██████▎   | 789/1257 [52:15<28:04,  3.60s/it] 63%|██████▎   | 790/1257 [52:19<28:40,  3.68s/it]                                                  {'loss': 0.4868, 'grad_norm': 64.04642486572266, 'learning_rate': 2.525096509147937e-07, 'rewards/chosen': 0.4022460877895355, 'rewards/rejected': -0.6234375238418579, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.025390625, 'logps/chosen': -168.0500030517578, 'logps/rejected': -194.35000610351562, 'logits/chosen': -7.390625, 'logits/rejected': -7.171875, 'epoch': 1.89}
 63%|██████▎   | 790/1257 [52:19<28:40,  3.68s/it] 63%|██████▎   | 791/1257 [52:22<28:33,  3.68s/it] 63%|██████▎   | 792/1257 [52:25<27:29,  3.55s/it] 63%|██████▎   | 793/1257 [52:29<27:22,  3.54s/it] 63%|██████▎   | 794/1257 [52:32<25:33,  3.31s/it] 63%|██████▎   | 795/1257 [52:36<27:38,  3.59s/it] 63%|██████▎   | 796/1257 [52:40<28:24,  3.70s/it] 63%|██████▎   | 797/1257 [52:43<26:19,  3.43s/it] 63%|██████▎   | 798/1257 [52:46<26:59,  3.53s/it] 64%|██████▎   | 799/1257 [52:50<27:23,  3.59s/it] 64%|██████▎   | 800/1257 [52:54<28:45,  3.78s/it]                                                  {'loss': 0.4825, 'grad_norm': 38.30690002441406, 'learning_rate': 2.458592435952818e-07, 'rewards/chosen': -0.3222106993198395, 'rewards/rejected': -1.2667968273162842, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.943554699420929, 'logps/chosen': -112.44999694824219, 'logps/rejected': -148.89999389648438, 'logits/chosen': -7.371874809265137, 'logits/rejected': -7.275000095367432, 'epoch': 1.91}
 64%|██████▎   | 800/1257 [52:54<28:45,  3.78s/it] 64%|██████▎   | 801/1257 [52:59<29:38,  3.90s/it] 64%|██████▍   | 802/1257 [53:02<27:52,  3.68s/it] 64%|██████▍   | 803/1257 [53:05<26:09,  3.46s/it] 64%|██████▍   | 804/1257 [53:07<23:51,  3.16s/it] 64%|██████▍   | 805/1257 [53:11<25:18,  3.36s/it] 64%|██████▍   | 806/1257 [53:15<26:58,  3.59s/it] 64%|██████▍   | 807/1257 [53:19<28:04,  3.74s/it] 64%|██████▍   | 808/1257 [53:22<26:12,  3.50s/it] 64%|██████▍   | 809/1257 [53:26<27:34,  3.69s/it] 64%|██████▍   | 810/1257 [53:31<28:42,  3.85s/it]                                                  {'loss': 0.4343, 'grad_norm': 56.276275634765625, 'learning_rate': 2.3917258353070065e-07, 'rewards/chosen': 0.07828368991613388, 'rewards/rejected': -1.0007812976837158, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.0792968273162842, 'logps/chosen': -143.0, 'logps/rejected': -161.4499969482422, 'logits/chosen': -7.190625190734863, 'logits/rejected': -7.1875, 'epoch': 1.93}
 64%|██████▍   | 810/1257 [53:31<28:42,  3.85s/it] 65%|██████▍   | 811/1257 [53:34<28:39,  3.86s/it] 65%|██████▍   | 812/1257 [53:38<27:05,  3.65s/it] 65%|██████▍   | 813/1257 [53:41<26:15,  3.55s/it] 65%|██████▍   | 814/1257 [53:44<25:15,  3.42s/it] 65%|██████▍   | 815/1257 [53:47<24:57,  3.39s/it] 65%|██████▍   | 816/1257 [53:51<25:14,  3.43s/it] 65%|██████▍   | 817/1257 [53:55<25:43,  3.51s/it] 65%|██████▌   | 818/1257 [53:57<23:35,  3.22s/it] 65%|██████▌   | 819/1257 [54:00<23:21,  3.20s/it] 65%|██████▌   | 820/1257 [54:04<24:39,  3.39s/it]                                                  {'loss': 0.4552, 'grad_norm': 45.9698371887207, 'learning_rate': 2.324590449234237e-07, 'rewards/chosen': -0.23007813096046448, 'rewards/rejected': -1.3054687976837158, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.076171875, 'logps/chosen': -98.5999984741211, 'logps/rejected': -131.4499969482422, 'logits/chosen': -7.515625, 'logits/rejected': -7.353125095367432, 'epoch': 1.96}
 65%|██████▌   | 820/1257 [54:04<24:39,  3.39s/it] 65%|██████▌   | 821/1257 [54:08<26:06,  3.59s/it] 65%|██████▌   | 822/1257 [54:12<26:45,  3.69s/it] 65%|██████▌   | 823/1257 [54:16<26:23,  3.65s/it] 66%|██████▌   | 824/1257 [54:20<27:02,  3.75s/it] 66%|██████▌   | 825/1257 [54:23<26:31,  3.68s/it] 66%|██████▌   | 826/1257 [54:27<26:40,  3.71s/it] 66%|██████▌   | 827/1257 [54:31<26:53,  3.75s/it] 66%|██████▌   | 828/1257 [54:34<26:43,  3.74s/it] 66%|██████▌   | 829/1257 [54:38<26:27,  3.71s/it] 66%|██████▌   | 830/1257 [54:42<26:39,  3.75s/it]                                                  {'loss': 0.4758, 'grad_norm': 68.10318756103516, 'learning_rate': 2.2572803965755134e-07, 'rewards/chosen': 0.07338257133960724, 'rewards/rejected': -0.987500011920929, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.059960961341858, 'logps/chosen': -143.9499969482422, 'logps/rejected': -176.9499969482422, 'logits/chosen': -7.353125095367432, 'logits/rejected': -7.212500095367432, 'epoch': 1.98}
 66%|██████▌   | 830/1257 [54:42<26:39,  3.75s/it] 66%|██████▌   | 831/1257 [54:46<26:57,  3.80s/it] 66%|██████▌   | 832/1257 [54:50<26:46,  3.78s/it] 66%|██████▋   | 833/1257 [54:53<26:43,  3.78s/it] 66%|██████▋   | 834/1257 [54:58<27:28,  3.90s/it] 66%|██████▋   | 835/1257 [55:01<25:29,  3.62s/it] 67%|██████▋   | 836/1257 [55:04<25:31,  3.64s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:13<01:22,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.62s/it][A
 18%|█▊        | 11/60 [00:16<01:21,  1.66s/it][A
 20%|██        | 12/60 [00:18<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:17,  1.64s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.63s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.53s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.40s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.30s/it][A
 30%|███       | 18/60 [00:25<00:46,  1.11s/it][A
 32%|███▏      | 19/60 [00:26<00:47,  1.16s/it][A
 33%|███▎      | 20/60 [00:27<00:40,  1.02s/it][A
 35%|███▌      | 21/60 [00:28<00:39,  1.02s/it][A
 37%|███▋      | 22/60 [00:29<00:42,  1.11s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.13s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.09s/it][A
 42%|████▏     | 25/60 [00:33<00:44,  1.27s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.32s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.16s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.09s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:41<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:39,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:46<00:32,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:48<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:53<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:57<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:01<00:18,  1.41s/it][A
 80%|████████  | 48/60 [01:02<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.33s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:08<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:09<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:13<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:16<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A                                                  
                                               [A{'eval_loss': 0.7485078573226929, 'eval_runtime': 80.9362, 'eval_samples_per_second': 11.775, 'eval_steps_per_second': 0.741, 'eval_rewards/chosen': 2.1196086406707764, 'eval_rewards/rejected': 0.7967773675918579, 'eval_rewards/accuracies': 0.6826388835906982, 'eval_rewards/margins': 1.324865698814392, 'eval_logps/chosen': -364.7250061035156, 'eval_logps/rejected': -147.13333129882812, 'eval_logits/chosen': -6.771093845367432, 'eval_logits/rejected': -7.499479293823242, 'epoch': 2.0}
 67%|██████▋   | 836/1257 [56:25<25:31,  3.64s/it]
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 67%|██████▋   | 837/1257 [56:39<3:35:58, 30.85s/it] 67%|██████▋   | 838/1257 [56:42<2:37:00, 22.48s/it] 67%|██████▋   | 839/1257 [56:45<1:56:12, 16.68s/it] 67%|██████▋   | 840/1257 [56:47<1:26:42, 12.48s/it]                                                    {'loss': 0.5008, 'grad_norm': 41.789371490478516, 'learning_rate': 2.1898900410414613e-07, 'rewards/chosen': -0.4261718690395355, 'rewards/rejected': -1.209375023841858, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.7828124761581421, 'logps/chosen': -96.44999694824219, 'logps/rejected': -147.64999389648438, 'logits/chosen': -7.34375, 'logits/rejected': -6.9375, 'epoch': 2.0}
 67%|██████▋   | 840/1257 [56:47<1:26:42, 12.48s/it] 67%|██████▋   | 841/1257 [56:51<1:07:14,  9.70s/it] 67%|██████▋   | 842/1257 [56:55<55:50,  8.07s/it]   67%|██████▋   | 843/1257 [56:58<46:23,  6.72s/it] 67%|██████▋   | 844/1257 [57:02<40:31,  5.89s/it] 67%|██████▋   | 845/1257 [57:06<36:49,  5.36s/it] 67%|██████▋   | 846/1257 [57:10<32:56,  4.81s/it] 67%|██████▋   | 847/1257 [57:14<30:17,  4.43s/it] 67%|██████▋   | 848/1257 [57:17<28:53,  4.24s/it] 68%|██████▊   | 849/1257 [57:21<27:11,  4.00s/it] 68%|██████▊   | 850/1257 [57:24<25:09,  3.71s/it]                                                  {'loss': 0.4706, 'grad_norm': 41.027320861816406, 'learning_rate': 2.122513858921393e-07, 'rewards/chosen': -0.053466796875, 'rewards/rejected': -1.2160155773162842, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.161718726158142, 'logps/chosen': -139.9499969482422, 'logps/rejected': -180.6999969482422, 'logits/chosen': -7.328125, 'logits/rejected': -7.178124904632568, 'epoch': 2.03}
 68%|██████▊   | 850/1257 [57:24<25:09,  3.71s/it] 68%|██████▊   | 851/1257 [57:27<24:37,  3.64s/it] 68%|██████▊   | 852/1257 [57:31<25:32,  3.78s/it] 68%|██████▊   | 853/1257 [57:36<26:19,  3.91s/it] 68%|██████▊   | 854/1257 [57:40<26:42,  3.98s/it] 68%|██████▊   | 855/1257 [57:43<25:56,  3.87s/it] 68%|██████▊   | 856/1257 [57:47<26:03,  3.90s/it] 68%|██████▊   | 857/1257 [57:50<24:29,  3.67s/it] 68%|██████▊   | 858/1257 [57:54<23:33,  3.54s/it] 68%|██████▊   | 859/1257 [57:58<24:10,  3.64s/it] 68%|██████▊   | 860/1257 [58:01<24:14,  3.66s/it]                                                  {'loss': 0.4782, 'grad_norm': 47.74909591674805, 'learning_rate': 2.0552463066345438e-07, 'rewards/chosen': -0.33251953125, 'rewards/rejected': -1.3523437976837158, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.0203125476837158, 'logps/chosen': -111.9000015258789, 'logps/rejected': -147.5, 'logits/chosen': -7.521874904632568, 'logits/rejected': -7.290625095367432, 'epoch': 2.05}
 68%|██████▊   | 860/1257 [58:01<24:14,  3.66s/it] 68%|██████▊   | 861/1257 [58:05<23:56,  3.63s/it] 69%|██████▊   | 862/1257 [58:07<21:41,  3.29s/it] 69%|██████▊   | 863/1257 [58:12<23:43,  3.61s/it] 69%|██████▊   | 864/1257 [58:16<24:19,  3.71s/it] 69%|██████▉   | 865/1257 [58:19<23:40,  3.62s/it] 69%|██████▉   | 866/1257 [58:22<22:16,  3.42s/it] 69%|██████▉   | 867/1257 [58:26<22:31,  3.46s/it] 69%|██████▉   | 868/1257 [58:28<20:52,  3.22s/it] 69%|██████▉   | 869/1257 [58:32<22:10,  3.43s/it] 69%|██████▉   | 870/1257 [58:35<21:05,  3.27s/it]                                                  {'loss': 0.4126, 'grad_norm': 38.231075286865234, 'learning_rate': 1.9881816883091643e-07, 'rewards/chosen': 0.20346680283546448, 'rewards/rejected': -0.966015636920929, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.169921875, 'logps/chosen': -128.1999969482422, 'logps/rejected': -153.60000610351562, 'logits/chosen': -7.275000095367432, 'logits/rejected': -7.25, 'epoch': 2.08}
 69%|██████▉   | 870/1257 [58:35<21:05,  3.27s/it] 69%|██████▉   | 871/1257 [58:39<22:06,  3.44s/it] 69%|██████▉   | 872/1257 [58:43<23:00,  3.59s/it] 69%|██████▉   | 873/1257 [58:46<22:15,  3.48s/it] 70%|██████▉   | 874/1257 [58:50<22:12,  3.48s/it] 70%|██████▉   | 875/1257 [58:53<22:23,  3.52s/it] 70%|██████▉   | 876/1257 [58:56<21:57,  3.46s/it] 70%|██████▉   | 877/1257 [59:00<21:28,  3.39s/it] 70%|██████▉   | 878/1257 [59:03<20:54,  3.31s/it] 70%|██████▉   | 879/1257 [59:07<22:25,  3.56s/it] 70%|███████   | 880/1257 [59:10<20:56,  3.33s/it]                                                  {'loss': 0.4639, 'grad_norm': 22.666996002197266, 'learning_rate': 1.921414023575116e-07, 'rewards/chosen': 0.08022461086511612, 'rewards/rejected': -0.9214843511581421, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.001562476158142, 'logps/chosen': -131.8000030517578, 'logps/rejected': -156.9499969482422, 'logits/chosen': -7.362500190734863, 'logits/rejected': -7.193749904632568, 'epoch': 2.1}
 70%|███████   | 880/1257 [59:10<20:56,  3.33s/it] 70%|███████   | 881/1257 [59:13<21:20,  3.41s/it] 70%|███████   | 882/1257 [59:17<22:08,  3.54s/it] 70%|███████   | 883/1257 [59:21<22:50,  3.66s/it] 70%|███████   | 884/1257 [59:25<23:21,  3.76s/it] 70%|███████   | 885/1257 [59:28<21:02,  3.39s/it] 70%|███████   | 886/1257 [59:31<20:26,  3.31s/it] 71%|███████   | 887/1257 [59:34<20:35,  3.34s/it] 71%|███████   | 888/1257 [59:38<20:35,  3.35s/it] 71%|███████   | 889/1257 [59:40<18:41,  3.05s/it] 71%|███████   | 890/1257 [59:43<19:29,  3.19s/it]                                                  {'loss': 0.3659, 'grad_norm': 53.104976654052734, 'learning_rate': 1.855036915755309e-07, 'rewards/chosen': -0.0606689453125, 'rewards/rejected': -1.4265625476837158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 1.366796851158142, 'logps/chosen': -101.6500015258789, 'logps/rejected': -134.6999969482422, 'logits/chosen': -7.471875190734863, 'logits/rejected': -7.278124809265137, 'epoch': 2.12}
 71%|███████   | 890/1257 [59:43<19:29,  3.19s/it] 71%|███████   | 891/1257 [59:47<20:52,  3.42s/it] 71%|███████   | 892/1257 [59:52<22:07,  3.64s/it] 71%|███████   | 893/1257 [59:56<22:48,  3.76s/it] 71%|███████   | 894/1257 [59:59<22:47,  3.77s/it] 71%|███████   | 895/1257 [1:00:04<23:33,  3.91s/it] 71%|███████▏  | 896/1257 [1:00:07<23:05,  3.84s/it] 71%|███████▏  | 897/1257 [1:00:10<20:29,  3.42s/it] 71%|███████▏  | 898/1257 [1:00:13<19:23,  3.24s/it] 72%|███████▏  | 899/1257 [1:00:15<18:07,  3.04s/it] 72%|███████▏  | 900/1257 [1:00:18<17:51,  3.00s/it]                                                    {'loss': 0.4687, 'grad_norm': 30.41463279724121, 'learning_rate': 1.7891434206407747e-07, 'rewards/chosen': -0.22331543266773224, 'rewards/rejected': -1.263085961341858, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.0419921875, 'logps/chosen': -109.5999984741211, 'logps/rejected': -135.6750030517578, 'logits/chosen': -7.528124809265137, 'logits/rejected': -7.268750190734863, 'epoch': 2.15}
 72%|███████▏  | 900/1257 [1:00:18<17:51,  3.00s/it] 72%|███████▏  | 901/1257 [1:00:22<19:05,  3.22s/it] 72%|███████▏  | 902/1257 [1:00:26<20:39,  3.49s/it] 72%|███████▏  | 903/1257 [1:00:30<21:09,  3.59s/it] 72%|███████▏  | 904/1257 [1:00:34<22:05,  3.76s/it] 72%|███████▏  | 905/1257 [1:00:38<22:54,  3.90s/it] 72%|███████▏  | 906/1257 [1:00:41<20:29,  3.50s/it] 72%|███████▏  | 907/1257 [1:00:45<21:13,  3.64s/it] 72%|███████▏  | 908/1257 [1:00:49<21:43,  3.74s/it] 72%|███████▏  | 909/1257 [1:00:52<21:46,  3.75s/it] 72%|███████▏  | 910/1257 [1:00:57<22:29,  3.89s/it]                                                    {'loss': 0.3839, 'grad_norm': 45.84712600708008, 'learning_rate': 1.7238259160333346e-07, 'rewards/chosen': 0.09600830078125, 'rewards/rejected': -1.14453125, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 1.240625023841858, 'logps/chosen': -125.5, 'logps/rejected': -151.4499969482422, 'logits/chosen': -7.390625, 'logits/rejected': -7.178124904632568, 'epoch': 2.17}
 72%|███████▏  | 910/1257 [1:00:57<22:29,  3.89s/it] 72%|███████▏  | 911/1257 [1:00:59<20:39,  3.58s/it] 73%|███████▎  | 912/1257 [1:01:02<18:59,  3.30s/it] 73%|███████▎  | 913/1257 [1:01:05<18:33,  3.24s/it] 73%|███████▎  | 914/1257 [1:01:08<17:52,  3.13s/it] 73%|███████▎  | 915/1257 [1:01:12<18:52,  3.31s/it] 73%|███████▎  | 916/1257 [1:01:15<19:06,  3.36s/it] 73%|███████▎  | 917/1257 [1:01:19<19:08,  3.38s/it] 73%|███████▎  | 918/1257 [1:01:22<19:28,  3.45s/it] 73%|███████▎  | 919/1257 [1:01:26<19:31,  3.47s/it] 73%|███████▎  | 920/1257 [1:01:30<20:06,  3.58s/it]                                                    {'loss': 0.4299, 'grad_norm': 55.28487014770508, 'learning_rate': 1.659175972238763e-07, 'rewards/chosen': -0.18829345703125, 'rewards/rejected': -1.34765625, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.1574218273162842, 'logps/chosen': -100.69999694824219, 'logps/rejected': -131.60000610351562, 'logits/chosen': -7.378125190734863, 'logits/rejected': -7.265625, 'epoch': 2.2}
 73%|███████▎  | 920/1257 [1:01:30<20:06,  3.58s/it] 73%|███████▎  | 921/1257 [1:01:34<21:09,  3.78s/it] 73%|███████▎  | 922/1257 [1:01:37<20:41,  3.71s/it] 73%|███████▎  | 923/1257 [1:01:41<21:01,  3.78s/it] 74%|███████▎  | 924/1257 [1:01:45<20:58,  3.78s/it] 74%|███████▎  | 925/1257 [1:01:49<21:10,  3.83s/it] 74%|███████▎  | 926/1257 [1:01:53<20:48,  3.77s/it] 74%|███████▎  | 927/1257 [1:01:56<20:46,  3.78s/it] 74%|███████▍  | 928/1257 [1:02:01<21:22,  3.90s/it] 74%|███████▍  | 929/1257 [1:02:05<21:12,  3.88s/it] 74%|███████▍  | 930/1257 [1:02:08<20:44,  3.81s/it]                                                    {'loss': 0.3753, 'grad_norm': 45.84329605102539, 'learning_rate': 1.5952842236919945e-07, 'rewards/chosen': 0.531933605670929, 'rewards/rejected': -0.8179687261581421, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.3515625, 'logps/chosen': -159.85000610351562, 'logps/rejected': -181.14999389648438, 'logits/chosen': -7.293749809265137, 'logits/rejected': -7.300000190734863, 'epoch': 2.22}
 74%|███████▍  | 930/1257 [1:02:08<20:44,  3.81s/it] 74%|███████▍  | 931/1257 [1:02:12<20:47,  3.83s/it] 74%|███████▍  | 932/1257 [1:02:16<21:08,  3.90s/it] 74%|███████▍  | 933/1257 [1:02:20<20:18,  3.76s/it] 74%|███████▍  | 934/1257 [1:02:23<20:31,  3.81s/it] 74%|███████▍  | 935/1257 [1:02:27<19:24,  3.62s/it] 74%|███████▍  | 936/1257 [1:02:30<19:44,  3.69s/it] 75%|███████▍  | 937/1257 [1:02:34<19:29,  3.66s/it] 75%|███████▍  | 938/1257 [1:02:37<18:08,  3.41s/it] 75%|███████▍  | 939/1257 [1:02:40<17:12,  3.25s/it] 75%|███████▍  | 940/1257 [1:02:44<18:49,  3.56s/it]                                                    {'loss': 0.4854, 'grad_norm': 96.76842498779297, 'learning_rate': 1.5322402418943604e-07, 'rewards/chosen': 0.08925781399011612, 'rewards/rejected': -0.873828113079071, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.9619140625, 'logps/chosen': -145.85000610351562, 'logps/rejected': -157.8000030517578, 'logits/chosen': -7.393750190734863, 'logits/rejected': -7.306250095367432, 'epoch': 2.24}
 75%|███████▍  | 940/1257 [1:02:44<18:49,  3.56s/it] 75%|███████▍  | 941/1257 [1:02:47<17:34,  3.34s/it] 75%|███████▍  | 942/1257 [1:02:51<18:54,  3.60s/it] 75%|███████▌  | 943/1257 [1:02:55<18:41,  3.57s/it] 75%|███████▌  | 944/1257 [1:02:59<19:40,  3.77s/it] 75%|███████▌  | 945/1257 [1:03:03<19:59,  3.84s/it] 75%|███████▌  | 946/1257 [1:03:07<20:04,  3.87s/it] 75%|███████▌  | 947/1257 [1:03:10<18:20,  3.55s/it] 75%|███████▌  | 948/1257 [1:03:14<19:32,  3.79s/it] 75%|███████▌  | 949/1257 [1:03:17<17:44,  3.46s/it] 76%|███████▌  | 950/1257 [1:03:20<17:49,  3.48s/it]                                                    {'loss': 0.4111, 'grad_norm': 55.0029182434082, 'learning_rate': 1.4701324098409703e-07, 'rewards/chosen': 0.11004638671875, 'rewards/rejected': -1.136328101158142, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.245703101158142, 'logps/chosen': -125.9000015258789, 'logps/rejected': -153.10000610351562, 'logits/chosen': -7.546875, 'logits/rejected': -7.234375, 'epoch': 2.27}
 76%|███████▌  | 950/1257 [1:03:20<17:49,  3.48s/it] 76%|███████▌  | 951/1257 [1:03:23<16:41,  3.27s/it] 76%|███████▌  | 952/1257 [1:03:27<17:27,  3.44s/it] 76%|███████▌  | 953/1257 [1:03:30<17:16,  3.41s/it] 76%|███████▌  | 954/1257 [1:03:34<18:03,  3.58s/it] 76%|███████▌  | 955/1257 [1:03:37<17:25,  3.46s/it] 76%|███████▌  | 956/1257 [1:03:41<18:17,  3.65s/it] 76%|███████▌  | 957/1257 [1:03:45<18:42,  3.74s/it] 76%|███████▌  | 958/1257 [1:03:49<18:03,  3.62s/it] 76%|███████▋  | 959/1257 [1:03:53<18:37,  3.75s/it] 76%|███████▋  | 960/1257 [1:03:56<17:53,  3.62s/it]                                                    {'loss': 0.4346, 'grad_norm': 59.34175109863281, 'learning_rate': 1.409047798114302e-07, 'rewards/chosen': 0.5172363519668579, 'rewards/rejected': -0.6246093511581421, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.142968773841858, 'logps/chosen': -168.10000610351562, 'logps/rejected': -177.64999389648438, 'logits/chosen': -7.21875, 'logits/rejected': -7.181250095367432, 'epoch': 2.29}
 76%|███████▋  | 960/1257 [1:03:56<17:53,  3.62s/it] 76%|███████▋  | 961/1257 [1:03:59<16:46,  3.40s/it] 77%|███████▋  | 962/1257 [1:04:03<18:02,  3.67s/it] 77%|███████▋  | 963/1257 [1:04:07<17:30,  3.57s/it] 77%|███████▋  | 964/1257 [1:04:10<16:59,  3.48s/it] 77%|███████▋  | 965/1257 [1:04:14<17:31,  3.60s/it] 77%|███████▋  | 966/1257 [1:04:17<17:35,  3.63s/it] 77%|███████▋  | 967/1257 [1:04:21<17:34,  3.64s/it] 77%|███████▋  | 968/1257 [1:04:25<17:21,  3.60s/it] 77%|███████▋  | 969/1257 [1:04:27<16:15,  3.39s/it] 77%|███████▋  | 970/1257 [1:04:31<16:37,  3.48s/it]                                                    {'loss': 0.4079, 'grad_norm': 57.28004837036133, 'learning_rate': 1.349072042817685e-07, 'rewards/chosen': -0.22890624403953552, 'rewards/rejected': -1.4421875476837158, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.214453101158142, 'logps/chosen': -106.25, 'logps/rejected': -137.64999389648438, 'logits/chosen': -7.503125190734863, 'logits/rejected': -7.234375, 'epoch': 2.32}
 77%|███████▋  | 970/1257 [1:04:31<16:37,  3.48s/it] 77%|███████▋  | 971/1257 [1:04:35<17:15,  3.62s/it] 77%|███████▋  | 972/1257 [1:04:39<18:04,  3.80s/it] 77%|███████▋  | 973/1257 [1:04:44<18:35,  3.93s/it] 77%|███████▋  | 974/1257 [1:04:47<18:09,  3.85s/it] 78%|███████▊  | 975/1257 [1:04:51<18:18,  3.90s/it] 78%|███████▊  | 976/1257 [1:04:55<18:36,  3.97s/it] 78%|███████▊  | 977/1257 [1:04:58<17:05,  3.66s/it] 78%|███████▊  | 978/1257 [1:05:02<17:17,  3.72s/it] 78%|███████▊  | 979/1257 [1:05:06<17:18,  3.73s/it] 78%|███████▊  | 980/1257 [1:05:09<16:48,  3.64s/it]                                                    {'loss': 0.4387, 'grad_norm': 27.208545684814453, 'learning_rate': 1.2902892255198288e-07, 'rewards/chosen': -0.33256834745407104, 'rewards/rejected': -1.44921875, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.1171875, 'logps/chosen': -99.55000305175781, 'logps/rejected': -143.64999389648438, 'logits/chosen': -7.537499904632568, 'logits/rejected': -7.1875, 'epoch': 2.34}
 78%|███████▊  | 980/1257 [1:05:09<16:48,  3.64s/it] 78%|███████▊  | 981/1257 [1:05:13<16:39,  3.62s/it] 78%|███████▊  | 982/1257 [1:05:17<17:19,  3.78s/it] 78%|███████▊  | 983/1257 [1:05:20<16:39,  3.65s/it] 78%|███████▊  | 984/1257 [1:05:24<16:03,  3.53s/it] 78%|███████▊  | 985/1257 [1:05:27<15:55,  3.51s/it] 78%|███████▊  | 986/1257 [1:05:31<15:41,  3.47s/it] 79%|███████▊  | 987/1257 [1:05:34<15:29,  3.44s/it] 79%|███████▊  | 988/1257 [1:05:37<15:36,  3.48s/it] 79%|███████▊  | 989/1257 [1:05:41<15:50,  3.55s/it] 79%|███████▉  | 990/1257 [1:05:45<15:57,  3.58s/it]                                                    {'loss': 0.4191, 'grad_norm': 50.47730255126953, 'learning_rate': 1.232781755378684e-07, 'rewards/chosen': -0.2641235291957855, 'rewards/rejected': -1.4738280773162842, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.2062499523162842, 'logps/chosen': -103.80000305175781, 'logps/rejected': -149.14999389648438, 'logits/chosen': -7.659375190734863, 'logits/rejected': -7.25, 'epoch': 2.36}
 79%|███████▉  | 990/1257 [1:05:45<15:57,  3.58s/it] 79%|███████▉  | 991/1257 [1:05:49<16:46,  3.78s/it] 79%|███████▉  | 992/1257 [1:05:53<16:55,  3.83s/it] 79%|███████▉  | 993/1257 [1:05:57<16:31,  3.75s/it] 79%|███████▉  | 994/1257 [1:06:00<15:59,  3.65s/it] 79%|███████▉  | 995/1257 [1:06:03<14:38,  3.35s/it] 79%|███████▉  | 996/1257 [1:06:06<14:12,  3.27s/it] 79%|███████▉  | 997/1257 [1:06:09<14:12,  3.28s/it] 79%|███████▉  | 998/1257 [1:06:13<14:27,  3.35s/it] 79%|███████▉  | 999/1257 [1:06:16<14:35,  3.39s/it] 80%|███████▉  | 1000/1257 [1:06:20<15:07,  3.53s/it]                                                     {'loss': 0.436, 'grad_norm': 33.96931838989258, 'learning_rate': 1.1766302536099078e-07, 'rewards/chosen': -0.01357421837747097, 'rewards/rejected': -1.153906226158142, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.138671875, 'logps/chosen': -141.10000610351562, 'logps/rejected': -168.0, 'logits/chosen': -7.478125095367432, 'logits/rejected': -7.349999904632568, 'epoch': 2.39}
 80%|███████▉  | 1000/1257 [1:06:20<15:07,  3.53s/it] 80%|███████▉  | 1001/1257 [1:06:24<15:22,  3.60s/it] 80%|███████▉  | 1002/1257 [1:06:27<15:35,  3.67s/it] 80%|███████▉  | 1003/1257 [1:06:30<14:31,  3.43s/it] 80%|███████▉  | 1004/1257 [1:06:34<15:02,  3.57s/it] 80%|███████▉  | 1005/1257 [1:06:38<15:46,  3.75s/it] 80%|████████  | 1006/1257 [1:06:42<15:04,  3.60s/it] 80%|████████  | 1007/1257 [1:06:45<15:15,  3.66s/it] 80%|████████  | 1008/1257 [1:06:50<15:45,  3.80s/it] 80%|████████  | 1009/1257 [1:06:53<15:28,  3.74s/it] 80%|████████  | 1010/1257 [1:06:57<15:44,  3.82s/it]                                                     {'loss': 0.464, 'grad_norm': 51.007774353027344, 'learning_rate': 1.121913440461884e-07, 'rewards/chosen': -0.3725341856479645, 'rewards/rejected': -1.532812476158142, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.1609375476837158, 'logps/chosen': -118.44999694824219, 'logps/rejected': -145.39999389648438, 'logits/chosen': -7.375, 'logits/rejected': -7.153124809265137, 'epoch': 2.41}
 80%|████████  | 1010/1257 [1:06:57<15:44,  3.82s/it] 80%|████████  | 1011/1257 [1:07:01<15:32,  3.79s/it] 81%|████████  | 1012/1257 [1:07:04<14:46,  3.62s/it] 81%|████████  | 1013/1257 [1:07:08<15:10,  3.73s/it] 81%|████████  | 1014/1257 [1:07:11<14:33,  3.60s/it] 81%|████████  | 1015/1257 [1:07:15<15:03,  3.73s/it] 81%|████████  | 1016/1257 [1:07:19<14:18,  3.56s/it] 81%|████████  | 1017/1257 [1:07:22<13:43,  3.43s/it] 81%|████████  | 1018/1257 [1:07:26<14:39,  3.68s/it] 81%|████████  | 1019/1257 [1:07:29<14:14,  3.59s/it] 81%|████████  | 1020/1257 [1:07:33<13:49,  3.50s/it]                                                     {'loss': 0.3569, 'grad_norm': 33.4285888671875, 'learning_rate': 1.068708024855768e-07, 'rewards/chosen': -0.23779296875, 'rewards/rejected': -1.6785156726837158, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 1.441015601158142, 'logps/chosen': -103.94999694824219, 'logps/rejected': -144.3000030517578, 'logits/chosen': -7.571875095367432, 'logits/rejected': -7.315625190734863, 'epoch': 2.43}
 81%|████████  | 1020/1257 [1:07:33<13:49,  3.50s/it] 81%|████████  | 1021/1257 [1:07:37<14:19,  3.64s/it] 81%|████████▏ | 1022/1257 [1:07:41<14:39,  3.74s/it] 81%|████████▏ | 1023/1257 [1:07:43<13:05,  3.36s/it] 81%|████████▏ | 1024/1257 [1:07:47<13:45,  3.54s/it] 82%|████████▏ | 1025/1257 [1:07:51<14:26,  3.74s/it] 82%|████████▏ | 1026/1257 [1:07:55<14:09,  3.68s/it] 82%|████████▏ | 1027/1257 [1:07:59<14:44,  3.84s/it] 82%|████████▏ | 1028/1257 [1:08:03<14:58,  3.92s/it] 82%|████████▏ | 1029/1257 [1:08:07<14:19,  3.77s/it] 82%|████████▏ | 1030/1257 [1:08:10<14:01,  3.71s/it]                                                     {'loss': 0.4082, 'grad_norm': 32.87372589111328, 'learning_rate': 1.0170885968452543e-07, 'rewards/chosen': 0.007519531063735485, 'rewards/rejected': -1.25390625, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 1.26171875, 'logps/chosen': -153.60000610351562, 'logps/rejected': -178.8000030517578, 'logits/chosen': -7.359375, 'logits/rejected': -7.206250190734863, 'epoch': 2.46}
 82%|████████▏ | 1030/1257 [1:08:10<14:01,  3.71s/it] 82%|████████▏ | 1031/1257 [1:08:14<14:32,  3.86s/it] 82%|████████▏ | 1032/1257 [1:08:18<14:29,  3.87s/it] 82%|████████▏ | 1033/1257 [1:08:22<14:37,  3.92s/it] 82%|████████▏ | 1034/1257 [1:08:26<14:46,  3.98s/it] 82%|████████▏ | 1035/1257 [1:08:30<13:54,  3.76s/it] 82%|████████▏ | 1036/1257 [1:08:33<13:23,  3.63s/it] 82%|████████▏ | 1037/1257 [1:08:36<12:44,  3.48s/it] 83%|████████▎ | 1038/1257 [1:08:40<13:13,  3.62s/it] 83%|████████▎ | 1039/1257 [1:08:43<12:05,  3.33s/it] 83%|████████▎ | 1040/1257 [1:08:45<11:20,  3.14s/it]                                                     {'loss': 0.4407, 'grad_norm': 50.5564079284668, 'learning_rate': 9.671275230468437e-08, 'rewards/chosen': 0.656933605670929, 'rewards/rejected': -0.8226562738418579, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.478515625, 'logps/chosen': -156.60000610351562, 'logps/rejected': -165.75, 'logits/chosen': -7.384375095367432, 'logits/rejected': -7.193749904632568, 'epoch': 2.48}
 83%|████████▎ | 1040/1257 [1:08:45<11:20,  3.14s/it] 83%|████████▎ | 1041/1257 [1:08:49<12:10,  3.38s/it] 83%|████████▎ | 1042/1257 [1:08:53<12:01,  3.36s/it] 83%|████████▎ | 1043/1257 [1:08:56<11:53,  3.33s/it] 83%|████████▎ | 1044/1257 [1:09:00<12:24,  3.50s/it] 83%|████████▎ | 1045/1257 [1:09:03<12:07,  3.43s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.61s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:39,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.38s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:32,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.41s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.33s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:06,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.7469097971916199, 'eval_runtime': 80.6146, 'eval_samples_per_second': 11.822, 'eval_steps_per_second': 0.744, 'eval_rewards/chosen': 2.3160157203674316, 'eval_rewards/rejected': 0.794696033000946, 'eval_rewards/accuracies': 0.7003471851348877, 'eval_rewards/margins': 1.5178711414337158, 'eval_logps/chosen': -363.9083251953125, 'eval_logps/rejected': -147.24166870117188, 'eval_logits/chosen': -6.795833110809326, 'eval_logits/rejected': -7.508854389190674, 'epoch': 2.49}
 83%|████████▎ | 1045/1257 [1:10:24<12:07,  3.43s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 83%|████████▎ | 1046/1257 [1:10:41<1:51:47, 31.79s/it] 83%|████████▎ | 1047/1257 [1:10:45<1:22:08, 23.47s/it] 83%|████████▎ | 1048/1257 [1:10:49<1:01:06, 17.54s/it] 83%|████████▎ | 1049/1257 [1:10:52<46:22, 13.38s/it]   84%|████████▎ | 1050/1257 [1:10:56<36:20, 10.53s/it]                                                     {'loss': 0.4392, 'grad_norm': 46.20908737182617, 'learning_rate': 9.188948451872067e-08, 'rewards/chosen': 0.03662109375, 'rewards/rejected': -1.213281273841858, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.2507812976837158, 'logps/chosen': -144.39999389648438, 'logps/rejected': -163.6999969482422, 'logits/chosen': -7.256249904632568, 'logits/rejected': -7.324999809265137, 'epoch': 2.51}
 84%|████████▎ | 1050/1257 [1:10:56<36:20, 10.53s/it] 84%|████████▎ | 1051/1257 [1:11:00<28:35,  8.33s/it] 84%|████████▎ | 1052/1257 [1:11:03<23:22,  6.84s/it] 84%|████████▍ | 1053/1257 [1:11:07<20:11,  5.94s/it] 84%|████████▍ | 1054/1257 [1:11:09<16:49,  4.97s/it] 84%|████████▍ | 1055/1257 [1:11:12<14:31,  4.31s/it] 84%|████████▍ | 1056/1257 [1:11:16<14:08,  4.22s/it] 84%|████████▍ | 1057/1257 [1:11:20<13:12,  3.96s/it] 84%|████████▍ | 1058/1257 [1:11:24<13:10,  3.97s/it] 84%|████████▍ | 1059/1257 [1:11:27<12:26,  3.77s/it] 84%|████████▍ | 1060/1257 [1:11:30<11:57,  3.64s/it]                                                     {'loss': 0.463, 'grad_norm': 34.17266845703125, 'learning_rate': 8.724581819098671e-08, 'rewards/chosen': -0.3090377748012543, 'rewards/rejected': -1.322265625, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.0125000476837158, 'logps/chosen': -104.25, 'logps/rejected': -124.3499984741211, 'logits/chosen': -7.490624904632568, 'logits/rejected': -7.356249809265137, 'epoch': 2.53}
 84%|████████▍ | 1060/1257 [1:11:30<11:57,  3.64s/it] 84%|████████▍ | 1061/1257 [1:11:34<11:43,  3.59s/it] 84%|████████▍ | 1062/1257 [1:11:37<11:41,  3.60s/it] 85%|████████▍ | 1063/1257 [1:11:40<11:10,  3.45s/it] 85%|████████▍ | 1064/1257 [1:11:44<11:29,  3.57s/it] 85%|████████▍ | 1065/1257 [1:11:48<11:57,  3.74s/it] 85%|████████▍ | 1066/1257 [1:11:52<11:58,  3.76s/it] 85%|████████▍ | 1067/1257 [1:11:56<11:51,  3.75s/it] 85%|████████▍ | 1068/1257 [1:12:00<12:09,  3.86s/it] 85%|████████▌ | 1069/1257 [1:12:03<11:15,  3.59s/it] 85%|████████▌ | 1070/1257 [1:12:07<11:44,  3.77s/it]                                                     {'loss': 0.4214, 'grad_norm': 26.35761833190918, 'learning_rate': 8.278826339788691e-08, 'rewards/chosen': -0.2828613221645355, 'rewards/rejected': -1.5851562023162842, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.302343726158142, 'logps/chosen': -113.94999694824219, 'logps/rejected': -134.5, 'logits/chosen': -7.568749904632568, 'logits/rejected': -7.471875190734863, 'epoch': 2.55}
 85%|████████▌ | 1070/1257 [1:12:07<11:44,  3.77s/it] 85%|████████▌ | 1071/1257 [1:12:10<11:07,  3.59s/it] 85%|████████▌ | 1072/1257 [1:12:14<11:24,  3.70s/it] 85%|████████▌ | 1073/1257 [1:12:17<10:33,  3.45s/it] 85%|████████▌ | 1074/1257 [1:12:21<10:36,  3.48s/it] 86%|████████▌ | 1075/1257 [1:12:25<10:58,  3.62s/it] 86%|████████▌ | 1076/1257 [1:12:28<10:56,  3.63s/it] 86%|████████▌ | 1077/1257 [1:12:32<10:57,  3.65s/it] 86%|████████▌ | 1078/1257 [1:12:36<11:09,  3.74s/it] 86%|████████▌ | 1079/1257 [1:12:40<11:16,  3.80s/it] 86%|████████▌ | 1080/1257 [1:12:43<10:56,  3.71s/it]                                                     {'loss': 0.4142, 'grad_norm': 39.41338348388672, 'learning_rate': 7.852306930123254e-08, 'rewards/chosen': 0.5636230707168579, 'rewards/rejected': -0.753125011920929, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.31640625, 'logps/chosen': -148.14999389648438, 'logps/rejected': -168.5500030517578, 'logits/chosen': -7.446875095367432, 'logits/rejected': -7.334374904632568, 'epoch': 2.58}
 86%|████████▌ | 1080/1257 [1:12:43<10:56,  3.71s/it] 86%|████████▌ | 1081/1257 [1:12:46<10:09,  3.46s/it] 86%|████████▌ | 1082/1257 [1:12:50<10:34,  3.63s/it] 86%|████████▌ | 1083/1257 [1:12:54<10:18,  3.56s/it] 86%|████████▌ | 1084/1257 [1:12:58<10:37,  3.69s/it] 86%|████████▋ | 1085/1257 [1:13:01<10:17,  3.59s/it] 86%|████████▋ | 1086/1257 [1:13:04<10:03,  3.53s/it] 86%|████████▋ | 1087/1257 [1:13:09<10:38,  3.76s/it] 87%|████████▋ | 1088/1257 [1:13:12<09:45,  3.46s/it] 87%|████████▋ | 1089/1257 [1:13:15<10:01,  3.58s/it] 87%|████████▋ | 1090/1257 [1:13:19<09:46,  3.51s/it]                                                     {'loss': 0.4512, 'grad_norm': 30.875688552856445, 'learning_rate': 7.445621538737983e-08, 'rewards/chosen': -0.34138184785842896, 'rewards/rejected': -1.4054687023162842, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.064843773841858, 'logps/chosen': -111.6500015258789, 'logps/rejected': -140.14999389648438, 'logits/chosen': -7.268750190734863, 'logits/rejected': -7.190625190734863, 'epoch': 2.6}
 87%|████████▋ | 1090/1257 [1:13:19<09:46,  3.51s/it] 87%|████████▋ | 1091/1257 [1:13:23<10:02,  3.63s/it] 87%|████████▋ | 1092/1257 [1:13:26<09:36,  3.49s/it] 87%|████████▋ | 1093/1257 [1:13:28<08:50,  3.23s/it] 87%|████████▋ | 1094/1257 [1:13:31<08:35,  3.16s/it] 87%|████████▋ | 1095/1257 [1:13:34<07:54,  2.93s/it] 87%|████████▋ | 1096/1257 [1:13:37<08:13,  3.07s/it] 87%|████████▋ | 1097/1257 [1:13:40<08:19,  3.12s/it] 87%|████████▋ | 1098/1257 [1:13:44<08:50,  3.34s/it] 87%|████████▋ | 1099/1257 [1:13:47<08:19,  3.16s/it] 88%|████████▊ | 1100/1257 [1:13:50<08:24,  3.22s/it]                                                     {'loss': 0.3893, 'grad_norm': 44.63139724731445, 'learning_rate': 7.059340308443225e-08, 'rewards/chosen': -0.18984374403953552, 'rewards/rejected': -1.4796874523162842, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.290624976158142, 'logps/chosen': -99.3499984741211, 'logps/rejected': -124.80000305175781, 'logits/chosen': -7.515625, 'logits/rejected': -7.315625190734863, 'epoch': 2.63}
 88%|████████▊ | 1100/1257 [1:13:50<08:24,  3.22s/it] 88%|████████▊ | 1101/1257 [1:13:54<08:55,  3.43s/it] 88%|████████▊ | 1102/1257 [1:13:59<09:28,  3.67s/it] 88%|████████▊ | 1103/1257 [1:14:02<09:06,  3.55s/it] 88%|████████▊ | 1104/1257 [1:14:06<09:21,  3.67s/it] 88%|████████▊ | 1105/1257 [1:14:10<09:26,  3.73s/it] 88%|████████▊ | 1106/1257 [1:14:14<09:41,  3.85s/it] 88%|████████▊ | 1107/1257 [1:14:18<09:46,  3.91s/it] 88%|████████▊ | 1108/1257 [1:14:21<09:09,  3.69s/it] 88%|████████▊ | 1109/1257 [1:14:25<09:17,  3.77s/it] 88%|████████▊ | 1110/1257 [1:14:29<09:20,  3.81s/it]                                                     {'loss': 0.41, 'grad_norm': 38.520294189453125, 'learning_rate': 6.6940047769261e-08, 'rewards/chosen': 1.0991942882537842, 'rewards/rejected': -0.22187499701976776, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.3203125, 'logps/chosen': -185.1999969482422, 'logps/rejected': -211.0, 'logits/chosen': -7.362500190734863, 'logits/rejected': -7.134375095367432, 'epoch': 2.65}
 88%|████████▊ | 1110/1257 [1:14:29<09:20,  3.81s/it] 88%|████████▊ | 1111/1257 [1:14:32<08:53,  3.65s/it] 88%|████████▊ | 1112/1257 [1:14:36<09:14,  3.82s/it] 89%|████████▊ | 1113/1257 [1:14:40<09:15,  3.86s/it] 89%|████████▊ | 1114/1257 [1:14:44<09:10,  3.85s/it] 89%|████████▊ | 1115/1257 [1:14:48<08:53,  3.76s/it] 89%|████████▉ | 1116/1257 [1:14:51<08:47,  3.74s/it] 89%|████████▉ | 1117/1257 [1:14:55<08:43,  3.74s/it] 89%|████████▉ | 1118/1257 [1:14:59<08:48,  3.80s/it] 89%|████████▉ | 1119/1257 [1:15:03<08:45,  3.81s/it] 89%|████████▉ | 1120/1257 [1:15:07<08:56,  3.91s/it]                                                     {'loss': 0.4734, 'grad_norm': 32.76844787597656, 'learning_rate': 6.35012711755471e-08, 'rewards/chosen': -0.37089842557907104, 'rewards/rejected': -1.5402343273162842, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.1710937023162842, 'logps/chosen': -117.6500015258789, 'logps/rejected': -137.85000610351562, 'logits/chosen': -7.349999904632568, 'logits/rejected': -7.231249809265137, 'epoch': 2.67}
 89%|████████▉ | 1120/1257 [1:15:07<08:56,  3.91s/it] 89%|████████▉ | 1121/1257 [1:15:11<08:54,  3.93s/it] 89%|████████▉ | 1122/1257 [1:15:15<08:53,  3.95s/it] 89%|████████▉ | 1123/1257 [1:15:19<08:55,  4.00s/it] 89%|████████▉ | 1124/1257 [1:15:23<08:49,  3.98s/it] 89%|████████▉ | 1125/1257 [1:15:26<08:23,  3.81s/it] 90%|████████▉ | 1126/1257 [1:15:30<08:13,  3.76s/it] 90%|████████▉ | 1127/1257 [1:15:34<07:55,  3.66s/it] 90%|████████▉ | 1128/1257 [1:15:37<07:58,  3.71s/it] 90%|████████▉ | 1129/1257 [1:15:41<08:01,  3.76s/it] 90%|████████▉ | 1130/1257 [1:15:45<08:14,  3.89s/it]                                                     {'loss': 0.4609, 'grad_norm': 63.085086822509766, 'learning_rate': 6.028189421349007e-08, 'rewards/chosen': 0.02841796912252903, 'rewards/rejected': -1.0499999523162842, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.0789062976837158, 'logps/chosen': -137.64999389648438, 'logps/rejected': -160.5, 'logits/chosen': -7.375, 'logits/rejected': -7.209374904632568, 'epoch': 2.7}
 90%|████████▉ | 1130/1257 [1:15:45<08:14,  3.89s/it] 90%|████████▉ | 1131/1257 [1:15:49<07:52,  3.75s/it] 90%|█████████ | 1132/1257 [1:15:52<07:35,  3.64s/it] 90%|█████████ | 1133/1257 [1:15:55<06:57,  3.37s/it] 90%|█████████ | 1134/1257 [1:15:58<06:51,  3.35s/it] 90%|█████████ | 1135/1257 [1:16:03<07:23,  3.64s/it] 90%|█████████ | 1136/1257 [1:16:07<07:31,  3.73s/it] 90%|█████████ | 1137/1257 [1:16:10<07:07,  3.56s/it] 91%|█████████ | 1138/1257 [1:16:13<07:01,  3.54s/it] 91%|█████████ | 1139/1257 [1:16:17<07:01,  3.57s/it] 91%|█████████ | 1140/1257 [1:16:20<06:57,  3.57s/it]                                                     {'loss': 0.4575, 'grad_norm': 60.190921783447266, 'learning_rate': 5.728643021124882e-08, 'rewards/chosen': -0.4233032166957855, 'rewards/rejected': -1.447656273841858, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.023828148841858, 'logps/chosen': -102.94999694824219, 'logps/rejected': -131.9499969482422, 'logits/chosen': -7.525000095367432, 'logits/rejected': -7.256249904632568, 'epoch': 2.72}
 91%|█████████ | 1140/1257 [1:16:20<06:57,  3.57s/it] 91%|█████████ | 1141/1257 [1:16:23<06:33,  3.39s/it] 91%|█████████ | 1142/1257 [1:16:27<06:49,  3.56s/it] 91%|█████████ | 1143/1257 [1:16:31<06:36,  3.47s/it] 91%|█████████ | 1144/1257 [1:16:35<06:57,  3.69s/it] 91%|█████████ | 1145/1257 [1:16:39<06:59,  3.75s/it] 91%|█████████ | 1146/1257 [1:16:42<06:49,  3.69s/it] 91%|█████████ | 1147/1257 [1:16:45<06:27,  3.53s/it] 91%|█████████▏| 1148/1257 [1:16:49<06:36,  3.64s/it] 91%|█████████▏| 1149/1257 [1:16:53<06:35,  3.66s/it] 91%|█████████▏| 1150/1257 [1:16:56<06:07,  3.44s/it]                                                     {'loss': 0.4613, 'grad_norm': 39.98072052001953, 'learning_rate': 5.451907858758977e-08, 'rewards/chosen': 0.11977539211511612, 'rewards/rejected': -1.1023437976837158, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.222070336341858, 'logps/chosen': -130.10000610351562, 'logps/rejected': -171.64999389648438, 'logits/chosen': -7.209374904632568, 'logits/rejected': -7.037499904632568, 'epoch': 2.74}
 91%|█████████▏| 1150/1257 [1:16:56<06:07,  3.44s/it] 92%|█████████▏| 1151/1257 [1:16:58<05:34,  3.16s/it] 92%|█████████▏| 1152/1257 [1:17:02<05:40,  3.24s/it] 92%|█████████▏| 1153/1257 [1:17:05<05:33,  3.21s/it] 92%|█████████▏| 1154/1257 [1:17:09<05:52,  3.43s/it] 92%|█████████▏| 1155/1257 [1:17:11<05:14,  3.08s/it] 92%|█████████▏| 1156/1257 [1:17:15<05:37,  3.34s/it] 92%|█████████▏| 1157/1257 [1:17:19<05:54,  3.54s/it] 92%|█████████▏| 1158/1257 [1:17:22<05:42,  3.46s/it] 92%|█████████▏| 1159/1257 [1:17:26<05:31,  3.38s/it] 92%|█████████▏| 1160/1257 [1:17:29<05:23,  3.34s/it]                                                     {'loss': 0.4481, 'grad_norm': 30.55638313293457, 'learning_rate': 5.198371896461241e-08, 'rewards/chosen': -0.20760497450828552, 'rewards/rejected': -1.2999999523162842, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.0910155773162842, 'logps/chosen': -100.4000015258789, 'logps/rejected': -110.92500305175781, 'logits/chosen': -7.403124809265137, 'logits/rejected': -7.309374809265137, 'epoch': 2.77}
 92%|█████████▏| 1160/1257 [1:17:29<05:23,  3.34s/it] 92%|█████████▏| 1161/1257 [1:17:32<05:01,  3.14s/it] 92%|█████████▏| 1162/1257 [1:17:34<04:39,  2.94s/it] 93%|█████████▎| 1163/1257 [1:17:37<04:34,  2.92s/it] 93%|█████████▎| 1164/1257 [1:17:40<04:43,  3.05s/it] 93%|█████████▎| 1165/1257 [1:17:44<05:05,  3.32s/it] 93%|█████████▎| 1166/1257 [1:17:48<05:21,  3.54s/it] 93%|█████████▎| 1167/1257 [1:17:51<05:07,  3.42s/it] 93%|█████████▎| 1168/1257 [1:17:55<05:02,  3.40s/it] 93%|█████████▎| 1169/1257 [1:17:58<04:54,  3.35s/it] 93%|█████████▎| 1170/1257 [1:18:01<04:44,  3.27s/it]                                                     {'loss': 0.4487, 'grad_norm': 30.66794204711914, 'learning_rate': 4.968390572880652e-08, 'rewards/chosen': -0.35473328828811646, 'rewards/rejected': -1.421484351158142, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.066796898841858, 'logps/chosen': -106.0999984741211, 'logps/rejected': -127.6500015258789, 'logits/chosen': -7.324999809265137, 'logits/rejected': -7.265625, 'epoch': 2.79}
 93%|█████████▎| 1170/1257 [1:18:01<04:44,  3.27s/it] 93%|█████████▎| 1171/1257 [1:18:04<04:30,  3.15s/it] 93%|█████████▎| 1172/1257 [1:18:07<04:28,  3.16s/it] 93%|█████████▎| 1173/1257 [1:18:11<04:55,  3.52s/it] 93%|█████████▎| 1174/1257 [1:18:15<05:02,  3.64s/it] 93%|█████████▎| 1175/1257 [1:18:19<05:10,  3.79s/it] 94%|█████████▎| 1176/1257 [1:18:23<05:08,  3.81s/it] 94%|█████████▎| 1177/1257 [1:18:27<04:55,  3.69s/it] 94%|█████████▎| 1178/1257 [1:18:31<05:02,  3.83s/it] 94%|█████████▍| 1179/1257 [1:18:35<05:01,  3.87s/it] 94%|█████████▍| 1180/1257 [1:18:39<04:58,  3.88s/it]                                                     {'loss': 0.3802, 'grad_norm': 33.47893524169922, 'learning_rate': 4.762286304806536e-08, 'rewards/chosen': 0.18354491889476776, 'rewards/rejected': -1.1375000476837158, 'rewards/accuracies': 0.875, 'rewards/margins': 1.318750023841858, 'logps/chosen': -130.89999389648438, 'logps/rejected': -170.75, 'logits/chosen': -7.381249904632568, 'logits/rejected': -7.137499809265137, 'epoch': 2.82}
 94%|█████████▍| 1180/1257 [1:18:39<04:58,  3.88s/it] 94%|█████████▍| 1181/1257 [1:18:43<04:54,  3.88s/it] 94%|█████████▍| 1182/1257 [1:18:46<04:41,  3.75s/it] 94%|█████████▍| 1183/1257 [1:18:48<04:04,  3.31s/it] 94%|█████████▍| 1184/1257 [1:18:52<04:13,  3.47s/it] 94%|█████████▍| 1185/1257 [1:18:56<04:22,  3.64s/it] 94%|█████████▍| 1186/1257 [1:19:00<04:24,  3.72s/it] 94%|█████████▍| 1187/1257 [1:19:04<04:26,  3.81s/it] 95%|█████████▍| 1188/1257 [1:19:08<04:14,  3.69s/it] 95%|█████████▍| 1189/1257 [1:19:12<04:16,  3.78s/it] 95%|█████████▍| 1190/1257 [1:19:16<04:22,  3.92s/it]                                                     {'loss': 0.4454, 'grad_norm': 37.82941436767578, 'learning_rate': 4.5803480351641034e-08, 'rewards/chosen': -0.3804931640625, 'rewards/rejected': -1.494531273841858, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.1160156726837158, 'logps/chosen': -112.80000305175781, 'logps/rejected': -143.9499969482422, 'logits/chosen': -7.400000095367432, 'logits/rejected': -7.178124904632568, 'epoch': 2.84}
 95%|█████████▍| 1190/1257 [1:19:16<04:22,  3.92s/it] 95%|█████████▍| 1191/1257 [1:19:20<04:23,  3.99s/it] 95%|█████████▍| 1192/1257 [1:19:24<04:18,  3.98s/it] 95%|█████████▍| 1193/1257 [1:19:28<04:12,  3.94s/it] 95%|█████████▍| 1194/1257 [1:19:32<04:06,  3.92s/it] 95%|█████████▌| 1195/1257 [1:19:36<04:03,  3.92s/it] 95%|█████████▌| 1196/1257 [1:19:40<04:00,  3.94s/it] 95%|█████████▌| 1197/1257 [1:19:43<03:41,  3.69s/it] 95%|█████████▌| 1198/1257 [1:19:47<03:46,  3.83s/it] 95%|█████████▌| 1199/1257 [1:19:50<03:31,  3.64s/it] 95%|█████████▌| 1200/1257 [1:19:54<03:35,  3.78s/it]                                                     {'loss': 0.4575, 'grad_norm': 68.57723236083984, 'learning_rate': 4.422830827937861e-08, 'rewards/chosen': 0.475830078125, 'rewards/rejected': -0.7515624761581421, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.2265625, 'logps/chosen': -164.6999969482422, 'logps/rejected': -180.64999389648438, 'logits/chosen': -7.331250190734863, 'logits/rejected': -7.15625, 'epoch': 2.86}
 95%|█████████▌| 1200/1257 [1:19:54<03:35,  3.78s/it] 96%|█████████▌| 1201/1257 [1:19:57<03:22,  3.62s/it] 96%|█████████▌| 1202/1257 [1:20:01<03:24,  3.72s/it] 96%|█████████▌| 1203/1257 [1:20:05<03:19,  3.70s/it] 96%|█████████▌| 1204/1257 [1:20:09<03:22,  3.82s/it] 96%|█████████▌| 1205/1257 [1:20:13<03:20,  3.85s/it] 96%|█████████▌| 1206/1257 [1:20:17<03:16,  3.85s/it] 96%|█████████▌| 1207/1257 [1:20:21<03:11,  3.84s/it] 96%|█████████▌| 1208/1257 [1:20:25<03:08,  3.84s/it] 96%|█████████▌| 1209/1257 [1:20:28<03:06,  3.88s/it] 96%|█████████▋| 1210/1257 [1:20:32<02:51,  3.66s/it]                                                     {'loss': 0.372, 'grad_norm': 29.359355926513672, 'learning_rate': 4.2899555105907845e-08, 'rewards/chosen': -0.3737548887729645, 'rewards/rejected': -1.709375023841858, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.3367187976837158, 'logps/chosen': -109.5999984741211, 'logps/rejected': -150.39999389648438, 'logits/chosen': -7.456250190734863, 'logits/rejected': -7.215624809265137, 'epoch': 2.89}
 96%|█████████▋| 1210/1257 [1:20:32<02:51,  3.66s/it] 96%|█████████▋| 1211/1257 [1:20:36<02:56,  3.84s/it] 96%|█████████▋| 1212/1257 [1:20:40<02:50,  3.80s/it] 96%|█████████▋| 1213/1257 [1:20:43<02:47,  3.82s/it] 97%|█████████▋| 1214/1257 [1:20:47<02:46,  3.86s/it] 97%|█████████▋| 1215/1257 [1:20:51<02:39,  3.80s/it] 97%|█████████▋| 1216/1257 [1:20:55<02:34,  3.77s/it] 97%|█████████▋| 1217/1257 [1:20:58<02:18,  3.47s/it] 97%|█████████▋| 1218/1257 [1:21:02<02:22,  3.66s/it] 97%|█████████▋| 1219/1257 [1:21:05<02:15,  3.57s/it] 97%|█████████▋| 1220/1257 [1:21:08<02:10,  3.53s/it]                                                     {'loss': 0.4642, 'grad_norm': 35.413673400878906, 'learning_rate': 4.181908364480563e-08, 'rewards/chosen': 0.03774414211511612, 'rewards/rejected': -1.11328125, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.1515624523162842, 'logps/chosen': -153.9499969482422, 'logps/rejected': -172.35000610351562, 'logits/chosen': -7.346875190734863, 'logits/rejected': -7.243750095367432, 'epoch': 2.91}
 97%|█████████▋| 1220/1257 [1:21:08<02:10,  3.53s/it] 97%|█████████▋| 1221/1257 [1:21:12<02:06,  3.50s/it] 97%|█████████▋| 1222/1257 [1:21:15<01:54,  3.28s/it] 97%|█████████▋| 1223/1257 [1:21:18<01:49,  3.22s/it] 97%|█████████▋| 1224/1257 [1:21:22<01:54,  3.46s/it] 97%|█████████▋| 1225/1257 [1:21:26<01:56,  3.65s/it] 98%|█████████▊| 1226/1257 [1:21:29<01:49,  3.52s/it] 98%|█████████▊| 1227/1257 [1:21:33<01:47,  3.57s/it] 98%|█████████▊| 1228/1257 [1:21:36<01:44,  3.59s/it] 98%|█████████▊| 1229/1257 [1:21:40<01:42,  3.64s/it] 98%|█████████▊| 1230/1257 [1:21:44<01:41,  3.76s/it]                                                     {'loss': 0.3882, 'grad_norm': 36.18552780151367, 'learning_rate': 4.09884086370693e-08, 'rewards/chosen': 0.1197509765625, 'rewards/rejected': -1.275781273841858, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.3953125476837158, 'logps/chosen': -134.1999969482422, 'logps/rejected': -170.6999969482422, 'logits/chosen': -7.40625, 'logits/rejected': -7.284375190734863, 'epoch': 2.94}
 98%|█████████▊| 1230/1257 [1:21:44<01:41,  3.76s/it] 98%|█████████▊| 1231/1257 [1:21:48<01:40,  3.86s/it] 98%|█████████▊| 1232/1257 [1:21:51<01:27,  3.49s/it] 98%|█████████▊| 1233/1257 [1:21:54<01:18,  3.25s/it] 98%|█████████▊| 1234/1257 [1:21:57<01:12,  3.17s/it] 98%|█████████▊| 1235/1257 [1:22:00<01:10,  3.19s/it] 98%|█████████▊| 1236/1257 [1:22:03<01:09,  3.32s/it] 98%|█████████▊| 1237/1257 [1:22:07<01:08,  3.44s/it] 98%|█████████▊| 1238/1257 [1:22:11<01:08,  3.58s/it] 99%|█████████▊| 1239/1257 [1:22:15<01:07,  3.74s/it] 99%|█████████▊| 1240/1257 [1:22:19<01:04,  3.78s/it]                                                     {'loss': 0.439, 'grad_norm': 51.36600875854492, 'learning_rate': 4.040869462756188e-08, 'rewards/chosen': 0.12160644680261612, 'rewards/rejected': -1.05859375, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 1.1799805164337158, 'logps/chosen': -143.10000610351562, 'logps/rejected': -153.8000030517578, 'logits/chosen': -7.587500095367432, 'logits/rejected': -7.443749904632568, 'epoch': 2.96}
 99%|█████████▊| 1240/1257 [1:22:19<01:04,  3.78s/it] 99%|█████████▊| 1241/1257 [1:22:23<01:02,  3.89s/it] 99%|█████████▉| 1242/1257 [1:22:27<00:59,  3.94s/it] 99%|█████████▉| 1243/1257 [1:22:31<00:55,  3.98s/it] 99%|█████████▉| 1244/1257 [1:22:34<00:47,  3.63s/it] 99%|█████████▉| 1245/1257 [1:22:37<00:39,  3.30s/it] 99%|█████████▉| 1246/1257 [1:22:40<00:37,  3.43s/it] 99%|█████████▉| 1247/1257 [1:22:45<00:36,  3.64s/it] 99%|█████████▉| 1248/1257 [1:22:48<00:33,  3.70s/it] 99%|█████████▉| 1249/1257 [1:22:52<00:30,  3.77s/it] 99%|█████████▉| 1250/1257 [1:22:55<00:24,  3.49s/it]                                                     {'loss': 0.4319, 'grad_norm': 58.831504821777344, 'learning_rate': 4.008075433240644e-08, 'rewards/chosen': -0.4094085693359375, 'rewards/rejected': -1.432031273841858, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.022216796875, 'logps/chosen': -118.94999694824219, 'logps/rejected': -136.5500030517578, 'logits/chosen': -7.359375, 'logits/rejected': -7.393750190734863, 'epoch': 2.98}
 99%|█████████▉| 1250/1257 [1:22:55<00:24,  3.49s/it]100%|█████████▉| 1251/1257 [1:22:59<00:21,  3.62s/it]100%|█████████▉| 1252/1257 [1:23:01<00:15,  3.19s/it]100%|█████████▉| 1253/1257 [1:23:05<00:13,  3.40s/it]100%|█████████▉| 1254/1257 [1:23:09<00:11,  3.67s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.61s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.65s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.63s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.61s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:39,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.33s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.7530443668365479, 'eval_runtime': 80.6872, 'eval_samples_per_second': 11.811, 'eval_steps_per_second': 0.744, 'eval_rewards/chosen': 2.3127787113189697, 'eval_rewards/rejected': 0.772875964641571, 'eval_rewards/accuracies': 0.6930555105209351, 'eval_rewards/margins': 1.5390543937683105, 'eval_logps/chosen': -363.8500061035156, 'eval_logps/rejected': -147.375, 'eval_logits/chosen': -6.7872395515441895, 'eval_logits/rejected': -7.498437404632568, 'epoch': 2.99}
100%|█████████▉| 1254/1257 [1:24:30<00:11,  3.67s/it]
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 1255/1257 [1:24:48<01:04, 32.11s/it]100%|█████████▉| 1256/1257 [1:24:52<00:23, 23.58s/it]100%|██████████| 1257/1257 [1:24:55<00:00, 17.46s/it]                                                     {'train_runtime': 5125.2979, 'train_samples_per_second': 3.916, 'train_steps_per_second': 0.245, 'train_loss': 0.5357800679445835, 'epoch': 3.0}
100%|██████████| 1257/1257 [1:25:17<00:00, 17.46s/it]100%|██████████| 1257/1257 [1:25:17<00:00,  4.07s/it]
Training complete
Saving model
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mCurri-2-DPO_r-64_lr-4e-07_e-3_b-0.2[0m at: [34mhttps://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/rsv4ledi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250610_235652-rsv4ledi/logs[0m
[rank0]:[W611 01:22:59.806062511 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 0 ---
