cpu-bind=MASK - gn01, task  0  0 [3146782]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 4
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn01
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 4     --machine_rank 0     --main_process_ip gn01     --main_process_port 29500     --num_processes 16     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_63002798     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=1e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-06-11 12:39:38,230] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0611 12:39:40.093000 3146834 torch/distributed/run.py:792] 
W0611 12:39:40.093000 3146834 torch/distributed/run.py:792] *****************************************
W0611 12:39:40.093000 3146834 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0611 12:39:40.093000 3146834 torch/distributed/run.py:792] *****************************************
[2025-06-11 12:40:12,856] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-11 12:40:12,906] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-11 12:40:12,919] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-11 12:40:12,927] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Namespace(rank=64, learning_rate=1e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=1e-07, total_epochs=3, beta=0.2)
[load_data.py]: Number of validation examples: Namespace(rank=64, learning_rate=1e-07, total_epochs=3, beta=0.2)
1e-07
1e-07
953
1e-07
Namespace(rank=64, learning_rate=1e-07, total_epochs=3, beta=0.2)
1e-07
World size: 16
Setting gradient accumulation steps to: 1
[2025-06-11 12:40:18,188] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-11 12:40:18,217] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-11 12:40:18,278] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Train dataset size: 24227
Validation dataset size: 953
Steps per epoch: 1514
Evaluate each 504 steps
[2025-06-11 12:40:18,949] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-11 12:40:18,958] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:08, 22.74s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:10, 23.46s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:10, 23.45s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:10, 23.44s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:45, 22.58s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:45, 22.94s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:46, 23.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:46<00:45, 22.94s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:10<00:23, 23.81s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:11<00:24, 24.09s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:11<00:24, 24.02s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:11<00:24, 24.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.33s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.14s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.50s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.49s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.49s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.22s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.22s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.21s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Total Parameters: 9457.78M
Total Parameters: 9457.78M
Percentage of Trainable Params: 2.2846%
Trainable Parameters (LoRA): 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Percentage of Trainable Params: 2.2846%
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 524/24227 [00:00<00:04, 5189.06 examples/s][rank1]:[W611 12:41:53.897479357 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   5%|▌         | 1280/24227 [00:00<00:04, 5081.96 examples/s][rank3]:[W611 12:41:53.991105174 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   8%|▊         | 1920/24227 [00:00<00:04, 4667.80 examples/s][rank2]:[W611 12:41:53.093452271 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:  10%|█         | 2470/24227 [00:00<00:05, 4158.96 examples/s]Extracting prompt in train dataset:  12%|█▏        | 2941/24227 [00:00<00:04, 4307.49 examples/s]Extracting prompt in train dataset:  14%|█▍        | 3500/24227 [00:00<00:05, 3887.37 examples/s]Extracting prompt in train dataset:  16%|█▋        | 3970/24227 [00:00<00:04, 4087.08 examples/s]Extracting prompt in train dataset:  19%|█▉        | 4570/24227 [00:01<00:04, 4049.14 examples/s]Extracting prompt in train dataset:  21%|██        | 5090/24227 [00:01<00:04, 4321.94 examples/s]Extracting prompt in train dataset:  23%|██▎       | 5590/24227 [00:01<00:04, 3958.70 examples/s]Extracting prompt in train dataset:  25%|██▌       | 6150/24227 [00:01<00:04, 3804.48 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6720/24227 [00:01<00:05, 3167.54 examples/s]Extracting prompt in train dataset:  30%|███       | 7281/24227 [00:01<00:05, 3102.08 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7796/24227 [00:02<00:04, 3495.33 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8330/24227 [00:02<00:04, 3893.97 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8850/24227 [00:02<00:03, 4189.56 examples/s]Extracting prompt in train dataset:  39%|███▊      | 9380/24227 [00:02<00:03, 4459.99 examples/s]Extracting prompt in train dataset:  41%|████      | 9920/24227 [00:02<00:03, 4694.46 examples/s]Extracting prompt in train dataset:  44%|████▍     | 10664/24227 [00:02<00:02, 4776.71 examples/s]Extracting prompt in train dataset:  46%|████▋     | 11227/24227 [00:02<00:03, 3859.79 examples/s]Extracting prompt in train dataset:  49%|████▊     | 11790/24227 [00:02<00:03, 3715.24 examples/s]Extracting prompt in train dataset:  50%|█████     | 12190/24227 [00:03<00:03, 3765.35 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12870/24227 [00:03<00:02, 3989.91 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 13520/24227 [00:03<00:02, 4088.41 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 14100/24227 [00:03<00:02, 3968.97 examples/s]Extracting prompt in train dataset:  61%|██████    | 14780/24227 [00:03<00:02, 4125.96 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 15376/24227 [00:03<00:02, 4078.66 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 15947/24227 [00:03<00:02, 3904.17 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 16510/24227 [00:04<00:02, 3318.38 examples/s]Extracting prompt in train dataset:  70%|███████   | 17053/24227 [00:04<00:01, 3728.75 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17640/24227 [00:04<00:01, 3326.42 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 18220/24227 [00:04<00:01, 3253.91 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18570/24227 [00:04<00:01, 3292.99 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 19110/24227 [00:04<00:01, 3739.54 examples/s]Extracting prompt in train dataset:  81%|████████  | 19653/24227 [00:05<00:01, 4132.50 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 20174/24227 [00:05<00:00, 4403.04 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 20842/24227 [00:05<00:00, 4410.98 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21539/24227 [00:05<00:00, 4482.42 examples/s]Extracting prompt in train dataset:  91%|█████████▏| 22128/24227 [00:05<00:00, 3884.15 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 22710/24227 [00:05<00:00, 3660.63 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 23310/24227 [00:06<00:00, 3521.92 examples/s]Extracting prompt in train dataset:  99%|█████████▊| 23900/24227 [00:06<00:00, 3193.69 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:06<00:00, 3803.00 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 285/24227 [00:00<00:08, 2827.98 examples/s]Applying chat template to train dataset:   2%|▏         | 597/24227 [00:00<00:11, 2031.99 examples/s]Applying chat template to train dataset:   4%|▎         | 886/24227 [00:00<00:10, 2329.52 examples/s]Applying chat template to train dataset:   5%|▍         | 1203/24227 [00:00<00:11, 2082.00 examples/s]Applying chat template to train dataset:   6%|▌         | 1454/24227 [00:00<00:10, 2199.00 examples/s]Applying chat template to train dataset:   7%|▋         | 1710/24227 [00:00<00:09, 2300.11 examples/s]Applying chat template to train dataset:   8%|▊         | 2025/24227 [00:00<00:11, 1850.86 examples/s]Applying chat template to train dataset:  10%|▉         | 2340/24227 [00:01<00:12, 1780.14 examples/s]Applying chat template to train dataset:  11%|█         | 2600/24227 [00:01<00:11, 1954.76 examples/s]Applying chat template to train dataset:  12%|█▏        | 2895/24227 [00:01<00:10, 1954.91 examples/s]Applying chat template to train dataset:  13%|█▎        | 3180/24227 [00:01<00:09, 2157.34 examples/s]Applying chat template to train dataset:  14%|█▍        | 3430/24227 [00:01<00:09, 2237.93 examples/s]Applying chat template to train dataset:  15%|█▌        | 3704/24227 [00:01<00:08, 2367.63 examples/s]Applying chat template to train dataset:  17%|█▋        | 4089/24227 [00:01<00:08, 2434.77 examples/s]Applying chat template to train dataset:  18%|█▊        | 4389/24227 [00:01<00:07, 2575.15 examples/s]Applying chat template to train dataset:  19%|█▉        | 4687/24227 [00:02<00:07, 2680.87 examples/s]Applying chat template to train dataset:  21%|██        | 5000/24227 [00:02<00:08, 2254.47 examples/s]Applying chat template to train dataset:  22%|██▏       | 5313/24227 [00:02<00:09, 1986.69 examples/s]Applying chat template to train dataset:  23%|██▎       | 5550/24227 [00:02<00:09, 2016.80 examples/s]Applying chat template to train dataset:  24%|██▍       | 5840/24227 [00:02<00:08, 2220.65 examples/s]Applying chat template to train dataset:  25%|██▌       | 6111/24227 [00:02<00:07, 2339.36 examples/s]Applying chat template to train dataset:  26%|██▋       | 6406/24227 [00:02<00:07, 2497.36 examples/s]Applying chat template to train dataset:  28%|██▊       | 6811/24227 [00:03<00:06, 2564.54 examples/s]Applying chat template to train dataset:  30%|██▉       | 7228/24227 [00:03<00:06, 2633.38 examples/s]Applying chat template to train dataset:  31%|███       | 7550/24227 [00:03<00:07, 2353.56 examples/s]Applying chat template to train dataset:  33%|███▎      | 7877/24227 [00:03<00:08, 1896.70 examples/s]Applying chat template to train dataset:  34%|███▍      | 8219/24227 [00:03<00:08, 1997.72 examples/s]Applying chat template to train dataset:  35%|███▌      | 8504/24227 [00:03<00:07, 2169.00 examples/s]Applying chat template to train dataset:  37%|███▋      | 8863/24227 [00:04<00:06, 2233.60 examples/s]Applying chat template to train dataset:  38%|███▊      | 9187/24227 [00:04<00:06, 2193.73 examples/s]Applying chat template to train dataset:  39%|███▉      | 9512/24227 [00:04<00:07, 1958.84 examples/s]Applying chat template to train dataset:  40%|████      | 9753/24227 [00:04<00:07, 2050.27 examples/s]Applying chat template to train dataset:  42%|████▏     | 10085/24227 [00:04<00:06, 2097.90 examples/s]Applying chat template to train dataset:  43%|████▎     | 10354/24227 [00:04<00:06, 2228.69 examples/s]Applying chat template to train dataset:  44%|████▍     | 10728/24227 [00:04<00:05, 2309.76 examples/s]Applying chat template to train dataset:  46%|████▌     | 11043/24227 [00:05<00:06, 2185.36 examples/s]Applying chat template to train dataset:  47%|████▋     | 11391/24227 [00:05<00:05, 2225.26 examples/s]Applying chat template to train dataset:  48%|████▊     | 11675/24227 [00:05<00:05, 2361.45 examples/s]Applying chat template to train dataset:  49%|████▉     | 11962/24227 [00:05<00:04, 2483.75 examples/s]Applying chat template to train dataset:  51%|█████     | 12285/24227 [00:05<00:06, 1930.32 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12556/24227 [00:05<00:05, 2092.74 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12861/24227 [00:05<00:04, 2309.94 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13189/24227 [00:05<00:04, 2267.16 examples/s]Applying chat template to train dataset:  56%|█████▌    | 13524/24227 [00:06<00:04, 2254.45 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13847/24227 [00:06<00:04, 2081.42 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14169/24227 [00:06<00:05, 1796.42 examples/s]Applying chat template to train dataset:  60%|█████▉    | 14425/24227 [00:06<00:05, 1943.01 examples/s]Applying chat template to train dataset:  61%|██████    | 14755/24227 [00:06<00:05, 1861.01 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15006/24227 [00:06<00:04, 1993.03 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15351/24227 [00:07<00:04, 2084.58 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15653/24227 [00:07<00:03, 2294.15 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15973/24227 [00:07<00:03, 2097.99 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16289/24227 [00:07<00:04, 1837.27 examples/s]Applying chat template to train dataset:  69%|██████▊   | 16607/24227 [00:07<00:04, 1704.50 examples/s]Applying chat template to train dataset:  70%|██████▉   | 16869/24227 [00:07<00:03, 1876.47 examples/s]Applying chat template to train dataset:  71%|███████   | 17196/24227 [00:08<00:04, 1591.48 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17487/24227 [00:08<00:03, 1829.74 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17771/24227 [00:08<00:03, 2036.55 examples/s]Applying chat template to train dataset:  75%|███████▍  | 18097/24227 [00:08<00:03, 1899.05 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18424/24227 [00:08<00:03, 1693.58 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18761/24227 [00:08<00:02, 1833.73 examples/s]Applying chat template to train dataset:  79%|███████▊  | 19061/24227 [00:09<00:02, 2063.64 examples/s]Applying chat template to train dataset:  80%|████████  | 19429/24227 [00:09<00:02, 2177.67 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19758/24227 [00:09<00:02, 2003.97 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19982/24227 [00:09<00:02, 2051.80 examples/s]Applying chat template to train dataset:  84%|████████▍ | 20310/24227 [00:09<00:01, 2043.76 examples/s]Applying chat template to train dataset:  85%|████████▌ | 20690/24227 [00:09<00:01, 2188.31 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21025/24227 [00:10<00:01, 1939.73 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21353/24227 [00:10<00:01, 1946.24 examples/s]Applying chat template to train dataset:  89%|████████▉ | 21664/24227 [00:10<00:01, 2179.16 examples/s]Applying chat template to train dataset:  90%|█████████ | 21920/24227 [00:10<00:01, 2262.07 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22307/24227 [00:10<00:00, 2361.51 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22603/24227 [00:10<00:00, 2502.19 examples/s]Applying chat template to train dataset:  95%|█████████▍| 23010/24227 [00:10<00:00, 2572.46 examples/s]Applying chat template to train dataset:  96%|█████████▋| 23343/24227 [00:11<00:00, 2307.66 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23680/24227 [00:11<00:00, 2214.63 examples/s]Applying chat template to train dataset:  99%|█████████▉| 24019/24227 [00:11<00:00, 2037.11 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:11<00:00, 2107.73 examples/s]
Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/24227 [00:00<01:01, 394.84 examples/s]Tokenizing train dataset:   0%|          | 89/24227 [00:00<01:43, 233.01 examples/s]Tokenizing train dataset:   1%|          | 126/24227 [00:00<01:43, 233.52 examples/s]Tokenizing train dataset:   1%|          | 154/24227 [00:00<01:39, 242.49 examples/s]Tokenizing train dataset:   1%|          | 182/24227 [00:00<01:51, 215.71 examples/s]Tokenizing train dataset:   1%|          | 214/24227 [00:00<01:40, 240.11 examples/s]Tokenizing train dataset:   1%|          | 250/24227 [00:01<01:40, 237.94 examples/s]Tokenizing train dataset:   1%|          | 278/24227 [00:01<01:37, 245.32 examples/s]Tokenizing train dataset:   1%|▏         | 312/24227 [00:01<01:53, 210.33 examples/s]Tokenizing train dataset:   1%|▏         | 343/24227 [00:01<02:03, 192.98 examples/s]Tokenizing train dataset:   2%|▏         | 370/24227 [00:01<01:54, 208.69 examples/s]Tokenizing train dataset:   2%|▏         | 401/24227 [00:01<01:44, 227.69 examples/s]Tokenizing train dataset:   2%|▏         | 431/24227 [00:01<01:38, 242.20 examples/s]Tokenizing train dataset:   2%|▏         | 457/24227 [00:01<01:37, 244.54 examples/s]Tokenizing train dataset:   2%|▏         | 488/24227 [00:02<01:46, 222.56 examples/s]Tokenizing train dataset:   2%|▏         | 519/24227 [00:02<01:55, 204.95 examples/s]Tokenizing train dataset:   2%|▏         | 547/24227 [00:02<01:47, 220.65 examples/s]Tokenizing train dataset:   2%|▏         | 578/24227 [00:02<01:56, 203.61 examples/s]Tokenizing train dataset:   2%|▏         | 605/24227 [00:02<01:49, 215.35 examples/s]Tokenizing train dataset:   3%|▎         | 642/24227 [00:02<01:34, 250.77 examples/s]Tokenizing train dataset:   3%|▎         | 677/24227 [00:02<01:37, 242.18 examples/s]Tokenizing train dataset:   3%|▎         | 711/24227 [00:03<01:40, 234.86 examples/s]Tokenizing train dataset:   3%|▎         | 747/24227 [00:03<01:29, 261.89 examples/s]Tokenizing train dataset:   3%|▎         | 776/24227 [00:03<01:40, 233.63 examples/s]Tokenizing train dataset:   3%|▎         | 806/24227 [00:03<01:55, 202.48 examples/s]Tokenizing train dataset:   3%|▎         | 828/24227 [00:03<01:54, 204.13 examples/s]Tokenizing train dataset:   4%|▎         | 859/24227 [00:03<01:43, 226.53 examples/s]Tokenizing train dataset:   4%|▎         | 890/24227 [00:03<01:34, 245.79 examples/s]Tokenizing train dataset:   4%|▍         | 920/24227 [00:03<01:31, 254.56 examples/s]Tokenizing train dataset:   4%|▍         | 952/24227 [00:04<01:48, 214.98 examples/s]Tokenizing train dataset:   4%|▍         | 983/24227 [00:04<01:59, 194.73 examples/s]Tokenizing train dataset:   4%|▍         | 1012/24227 [00:04<02:02, 189.74 examples/s]Tokenizing train dataset:   4%|▍         | 1040/24227 [00:04<01:53, 203.81 examples/s]Tokenizing train dataset:   4%|▍         | 1068/24227 [00:04<01:46, 217.41 examples/s]Tokenizing train dataset:   5%|▍         | 1099/24227 [00:04<01:36, 239.55 examples/s]Tokenizing train dataset:   5%|▍         | 1136/24227 [00:05<01:35, 240.70 examples/s]Tokenizing train dataset:   5%|▍         | 1164/24227 [00:05<01:34, 245.17 examples/s]Tokenizing train dataset:   5%|▍         | 1193/24227 [00:05<01:31, 253.01 examples/s]Tokenizing train dataset:   5%|▌         | 1231/24227 [00:05<01:31, 250.77 examples/s]Tokenizing train dataset:   5%|▌         | 1259/24227 [00:05<01:29, 257.20 examples/s]Tokenizing train dataset:   5%|▌         | 1287/24227 [00:05<01:28, 259.40 examples/s]Tokenizing train dataset:   5%|▌         | 1320/24227 [00:05<01:23, 274.00 examples/s]Tokenizing train dataset:   6%|▌         | 1354/24227 [00:05<01:31, 250.38 examples/s]Tokenizing train dataset:   6%|▌         | 1386/24227 [00:06<02:09, 176.87 examples/s]Tokenizing train dataset:   6%|▌         | 1412/24227 [00:06<01:58, 192.09 examples/s]Tokenizing train dataset:   6%|▌         | 1438/24227 [00:06<01:51, 204.33 examples/s]Tokenizing train dataset:   6%|▌         | 1462/24227 [00:06<01:48, 209.83 examples/s]Tokenizing train dataset:   6%|▌         | 1495/24227 [00:06<01:48, 209.77 examples/s]Tokenizing train dataset:   6%|▋         | 1530/24227 [00:06<02:07, 178.06 examples/s]Tokenizing train dataset:   6%|▋         | 1563/24227 [00:07<02:03, 183.78 examples/s]Tokenizing train dataset:   7%|▋         | 1593/24227 [00:07<02:00, 187.39 examples/s]Tokenizing train dataset:   7%|▋         | 1613/24227 [00:07<02:00, 188.44 examples/s]Tokenizing train dataset:   7%|▋         | 1644/24227 [00:07<01:45, 214.24 examples/s]Tokenizing train dataset:   7%|▋         | 1667/24227 [00:07<01:46, 211.92 examples/s]Tokenizing train dataset:   7%|▋         | 1695/24227 [00:07<01:39, 227.31 examples/s]Tokenizing train dataset:   7%|▋         | 1720/24227 [00:07<01:37, 230.94 examples/s]Tokenizing train dataset:   7%|▋         | 1751/24227 [00:07<01:29, 250.18 examples/s]Tokenizing train dataset:   7%|▋         | 1781/24227 [00:07<01:26, 259.78 examples/s]Tokenizing train dataset:   7%|▋         | 1809/24227 [00:08<01:25, 263.21 examples/s]Tokenizing train dataset:   8%|▊         | 1849/24227 [00:08<01:26, 258.83 examples/s]Tokenizing train dataset:   8%|▊         | 1885/24227 [00:08<01:29, 250.96 examples/s]Tokenizing train dataset:   8%|▊         | 1921/24227 [00:08<01:31, 244.57 examples/s]Tokenizing train dataset:   8%|▊         | 1957/24227 [00:08<01:32, 240.84 examples/s]Tokenizing train dataset:   8%|▊         | 1990/24227 [00:08<01:35, 231.99 examples/s]Tokenizing train dataset:   8%|▊         | 2025/24227 [00:09<01:51, 199.63 examples/s]Tokenizing train dataset:   9%|▊         | 2060/24227 [00:09<01:53, 194.87 examples/s]Tokenizing train dataset:   9%|▊         | 2082/24227 [00:09<01:51, 199.03 examples/s]Tokenizing train dataset:   9%|▊         | 2109/24227 [00:09<01:44, 211.64 examples/s]Tokenizing train dataset:   9%|▉         | 2146/24227 [00:09<01:40, 219.88 examples/s]Tokenizing train dataset:   9%|▉         | 2174/24227 [00:09<01:35, 230.22 examples/s]Tokenizing train dataset:   9%|▉         | 2204/24227 [00:09<01:40, 218.43 examples/s]Tokenizing train dataset:   9%|▉         | 2243/24227 [00:10<01:57, 187.00 examples/s]Tokenizing train dataset:   9%|▉         | 2275/24227 [00:10<01:44, 209.73 examples/s]Tokenizing train dataset:  10%|▉         | 2306/24227 [00:10<01:56, 187.55 examples/s]Tokenizing train dataset:  10%|▉         | 2327/24227 [00:10<01:54, 191.24 examples/s]Tokenizing train dataset:  10%|▉         | 2352/24227 [00:10<01:48, 202.30 examples/s]Tokenizing train dataset:  10%|▉         | 2383/24227 [00:10<01:50, 197.06 examples/s]Tokenizing train dataset:  10%|▉         | 2415/24227 [00:11<01:56, 187.92 examples/s]Tokenizing train dataset:  10%|█         | 2440/24227 [00:11<01:49, 198.21 examples/s]Tokenizing train dataset:  10%|█         | 2466/24227 [00:11<01:43, 210.87 examples/s]Tokenizing train dataset:  10%|█         | 2499/24227 [00:11<01:49, 198.95 examples/s]Tokenizing train dataset:  10%|█         | 2527/24227 [00:11<01:52, 192.82 examples/s]Tokenizing train dataset:  11%|█         | 2560/24227 [00:11<01:54, 189.01 examples/s]Tokenizing train dataset:  11%|█         | 2591/24227 [00:11<01:42, 211.81 examples/s]Tokenizing train dataset:  11%|█         | 2626/24227 [00:12<01:42, 209.74 examples/s]Tokenizing train dataset:  11%|█         | 2660/24227 [00:12<01:44, 206.95 examples/s]Tokenizing train dataset:  11%|█         | 2685/24227 [00:12<01:40, 213.41 examples/s]Tokenizing train dataset:  11%|█         | 2719/24227 [00:12<01:29, 240.89 examples/s]Tokenizing train dataset:  11%|█▏        | 2745/24227 [00:12<01:28, 243.07 examples/s]Tokenizing train dataset:  12%|█▏        | 2787/24227 [00:12<01:24, 252.86 examples/s]Tokenizing train dataset:  12%|█▏        | 2827/24227 [00:12<01:23, 255.46 examples/s]Tokenizing train dataset:  12%|█▏        | 2853/24227 [00:12<01:24, 254.34 examples/s]Tokenizing train dataset:  12%|█▏        | 2881/24227 [00:13<01:40, 213.27 examples/s]Tokenizing train dataset:  12%|█▏        | 2915/24227 [00:13<01:53, 188.01 examples/s]Tokenizing train dataset:  12%|█▏        | 2950/24227 [00:13<01:53, 186.71 examples/s]Tokenizing train dataset:  12%|█▏        | 2977/24227 [00:13<01:45, 201.53 examples/s]Tokenizing train dataset:  12%|█▏        | 3005/24227 [00:13<01:38, 215.33 examples/s]Tokenizing train dataset:  13%|█▎        | 3030/24227 [00:13<01:37, 218.52 examples/s]Tokenizing train dataset:  13%|█▎        | 3056/24227 [00:13<01:33, 226.21 examples/s]Tokenizing train dataset:  13%|█▎        | 3091/24227 [00:14<01:33, 227.13 examples/s]Tokenizing train dataset:  13%|█▎        | 3123/24227 [00:14<01:46, 198.05 examples/s]Tokenizing train dataset:  13%|█▎        | 3157/24227 [00:14<01:44, 200.88 examples/s]Tokenizing train dataset:  13%|█▎        | 3194/24227 [00:14<01:51, 188.95 examples/s]Tokenizing train dataset:  13%|█▎        | 3221/24227 [00:14<01:43, 202.41 examples/s]Tokenizing train dataset:  13%|█▎        | 3259/24227 [00:14<01:41, 207.14 examples/s]Tokenizing train dataset:  14%|█▎        | 3284/24227 [00:15<01:37, 215.55 examples/s]Tokenizing train dataset:  14%|█▎        | 3312/24227 [00:15<01:31, 229.32 examples/s]Tokenizing train dataset:  14%|█▍        | 3340/24227 [00:15<01:26, 240.77 examples/s]Tokenizing train dataset:  14%|█▍        | 3376/24227 [00:15<01:28, 235.79 examples/s]Tokenizing train dataset:  14%|█▍        | 3410/24227 [00:15<01:30, 228.83 examples/s]Tokenizing train dataset:  14%|█▍        | 3434/24227 [00:15<01:30, 229.09 examples/s]Tokenizing train dataset:  14%|█▍        | 3469/24227 [00:15<01:31, 227.55 examples/s]Tokenizing train dataset:  14%|█▍        | 3509/24227 [00:16<01:27, 237.31 examples/s]Tokenizing train dataset:  15%|█▍        | 3543/24227 [00:16<01:29, 231.55 examples/s]Tokenizing train dataset:  15%|█▍        | 3580/24227 [00:16<01:19, 259.38 examples/s]Tokenizing train dataset:  15%|█▍        | 3609/24227 [00:16<01:17, 264.56 examples/s]Tokenizing train dataset:  15%|█▌        | 3640/24227 [00:16<01:15, 274.34 examples/s]Tokenizing train dataset:  15%|█▌        | 3676/24227 [00:16<01:37, 210.67 examples/s]Tokenizing train dataset:  15%|█▌        | 3705/24227 [00:16<01:45, 194.43 examples/s]Tokenizing train dataset:  15%|█▌        | 3736/24227 [00:17<01:44, 196.62 examples/s]Tokenizing train dataset:  16%|█▌        | 3770/24227 [00:17<01:31, 223.42 examples/s]Tokenizing train dataset:  16%|█▌        | 3809/24227 [00:17<01:28, 230.12 examples/s]Tokenizing train dataset:  16%|█▌        | 3838/24227 [00:17<01:24, 242.07 examples/s]Tokenizing train dataset:  16%|█▌        | 3877/24227 [00:17<01:22, 245.71 examples/s]Tokenizing train dataset:  16%|█▌        | 3907/24227 [00:17<01:34, 214.05 examples/s]Tokenizing train dataset:  16%|█▌        | 3933/24227 [00:17<01:42, 197.30 examples/s]Tokenizing train dataset:  16%|█▋        | 3964/24227 [00:18<01:32, 219.09 examples/s]Tokenizing train dataset:  16%|█▋        | 3992/24227 [00:18<01:27, 231.27 examples/s]Tokenizing train dataset:  17%|█▋        | 4019/24227 [00:18<01:24, 238.18 examples/s]Tokenizing train dataset:  17%|█▋        | 4048/24227 [00:18<01:21, 247.71 examples/s]Tokenizing train dataset:  17%|█▋        | 4081/24227 [00:18<01:51, 180.83 examples/s]Tokenizing train dataset:  17%|█▋        | 4115/24227 [00:18<01:59, 168.90 examples/s]Tokenizing train dataset:  17%|█▋        | 4139/24227 [00:18<01:50, 181.18 examples/s]Tokenizing train dataset:  17%|█▋        | 4172/24227 [00:19<02:01, 165.57 examples/s]Tokenizing train dataset:  17%|█▋        | 4194/24227 [00:19<01:55, 173.65 examples/s]Tokenizing train dataset:  17%|█▋        | 4215/24227 [00:19<01:51, 178.89 examples/s]Tokenizing train dataset:  18%|█▊        | 4246/24227 [00:19<01:54, 174.84 examples/s]Tokenizing train dataset:  18%|█▊        | 4265/24227 [00:19<01:54, 175.08 examples/s]Tokenizing train dataset:  18%|█▊        | 4296/24227 [00:19<01:50, 180.00 examples/s]Tokenizing train dataset:  18%|█▊        | 4321/24227 [00:19<01:42, 193.64 examples/s]Tokenizing train dataset:  18%|█▊        | 4350/24227 [00:20<01:32, 215.46 examples/s]Tokenizing train dataset:  18%|█▊        | 4380/24227 [00:20<01:46, 187.17 examples/s]Tokenizing train dataset:  18%|█▊        | 4411/24227 [00:20<01:32, 213.78 examples/s]Tokenizing train dataset:  18%|█▊        | 4450/24227 [00:20<01:28, 224.04 examples/s]Tokenizing train dataset:  18%|█▊        | 4481/24227 [00:20<01:41, 195.27 examples/s]Tokenizing train dataset:  19%|█▊        | 4505/24227 [00:20<01:37, 202.45 examples/s]Tokenizing train dataset:  19%|█▊        | 4534/24227 [00:21<01:56, 169.62 examples/s]Tokenizing train dataset:  19%|█▉        | 4565/24227 [00:21<01:53, 173.52 examples/s]Tokenizing train dataset:  19%|█▉        | 4596/24227 [00:21<01:39, 197.72 examples/s]Tokenizing train dataset:  19%|█▉        | 4627/24227 [00:21<01:40, 195.96 examples/s]Tokenizing train dataset:  19%|█▉        | 4657/24227 [00:21<02:12, 148.17 examples/s]Tokenizing train dataset:  19%|█▉        | 4689/24227 [00:22<02:00, 162.78 examples/s]Tokenizing train dataset:  19%|█▉        | 4720/24227 [00:22<02:02, 159.24 examples/s]Tokenizing train dataset:  20%|█▉        | 4750/24227 [00:22<01:45, 183.93 examples/s]Tokenizing train dataset:  20%|█▉        | 4776/24227 [00:22<01:37, 198.49 examples/s]Tokenizing train dataset:  20%|█▉        | 4816/24227 [00:22<01:29, 216.78 examples/s]Tokenizing train dataset:  20%|█▉        | 4840/24227 [00:22<01:44, 185.57 examples/s]Tokenizing train dataset:  20%|██        | 4868/24227 [00:22<01:34, 203.79 examples/s]Tokenizing train dataset:  20%|██        | 4900/24227 [00:23<01:40, 192.66 examples/s]Tokenizing train dataset:  20%|██        | 4924/24227 [00:23<01:35, 201.36 examples/s]Tokenizing train dataset:  20%|██        | 4952/24227 [00:23<01:38, 195.30 examples/s]Tokenizing train dataset:  21%|██        | 4986/24227 [00:23<01:41, 189.39 examples/s]Tokenizing train dataset:  21%|██        | 5014/24227 [00:23<01:32, 207.94 examples/s]Tokenizing train dataset:  21%|██        | 5040/24227 [00:23<01:29, 215.54 examples/s]Tokenizing train dataset:  21%|██        | 5072/24227 [00:23<01:30, 211.41 examples/s]Tokenizing train dataset:  21%|██        | 5098/24227 [00:23<01:26, 220.36 examples/s]Tokenizing train dataset:  21%|██        | 5121/24227 [00:24<01:27, 217.15 examples/s]Tokenizing train dataset:  21%|██        | 5144/24227 [00:24<01:26, 219.56 examples/s]Tokenizing train dataset:  21%|██▏       | 5172/24227 [00:24<01:33, 203.58 examples/s]Tokenizing train dataset:  21%|██▏       | 5193/24227 [00:24<01:33, 203.85 examples/s]Tokenizing train dataset:  22%|██▏       | 5222/24227 [00:24<01:47, 177.39 examples/s]Tokenizing train dataset:  22%|██▏       | 5241/24227 [00:24<01:47, 176.76 examples/s]Tokenizing train dataset:  22%|██▏       | 5269/24227 [00:24<01:50, 171.60 examples/s]Tokenizing train dataset:  22%|██▏       | 5293/24227 [00:25<01:41, 186.23 examples/s]Tokenizing train dataset:  22%|██▏       | 5321/24227 [00:25<01:43, 182.66 examples/s]Tokenizing train dataset:  22%|██▏       | 5356/24227 [00:25<01:37, 193.55 examples/s]Tokenizing train dataset:  22%|██▏       | 5380/24227 [00:25<01:43, 181.43 examples/s]Tokenizing train dataset:  22%|██▏       | 5410/24227 [00:25<02:11, 142.82 examples/s]Tokenizing train dataset:  22%|██▏       | 5430/24227 [00:25<02:08, 146.52 examples/s]Tokenizing train dataset:  22%|██▏       | 5447/24227 [00:26<04:03, 77.17 examples/s] Tokenizing train dataset:  23%|██▎       | 5465/24227 [00:26<03:28, 89.89 examples/s]Tokenizing train dataset:  23%|██▎       | 5486/24227 [00:26<02:54, 107.14 examples/s]Tokenizing train dataset:  23%|██▎       | 5519/24227 [00:26<02:25, 128.44 examples/s]Tokenizing train dataset:  23%|██▎       | 5549/24227 [00:27<02:10, 143.25 examples/s]Tokenizing train dataset:  23%|██▎       | 5579/24227 [00:27<01:48, 171.45 examples/s]Tokenizing train dataset:  23%|██▎       | 5611/24227 [00:27<01:32, 200.39 examples/s]Tokenizing train dataset:  23%|██▎       | 5642/24227 [00:27<01:23, 223.50 examples/s]Tokenizing train dataset:  23%|██▎       | 5676/24227 [00:27<01:14, 247.64 examples/s]Tokenizing train dataset:  24%|██▎       | 5706/24227 [00:27<01:11, 258.46 examples/s]Tokenizing train dataset:  24%|██▎       | 5738/24227 [00:27<01:21, 228.12 examples/s]Tokenizing train dataset:  24%|██▍       | 5773/24227 [00:27<01:21, 226.63 examples/s]Tokenizing train dataset:  24%|██▍       | 5810/24227 [00:28<01:19, 231.04 examples/s]Tokenizing train dataset:  24%|██▍       | 5840/24227 [00:28<01:15, 244.12 examples/s]Tokenizing train dataset:  24%|██▍       | 5873/24227 [00:28<01:10, 261.27 examples/s]Tokenizing train dataset:  24%|██▍       | 5903/24227 [00:28<01:26, 211.48 examples/s]Tokenizing train dataset:  24%|██▍       | 5930/24227 [00:28<01:22, 221.43 examples/s]Tokenizing train dataset:  25%|██▍       | 5962/24227 [00:28<01:27, 209.65 examples/s]Tokenizing train dataset:  25%|██▍       | 5990/24227 [00:28<01:30, 201.13 examples/s]Tokenizing train dataset:  25%|██▍       | 6020/24227 [00:29<01:36, 188.46 examples/s]Tokenizing train dataset:  25%|██▌       | 6057/24227 [00:29<01:32, 195.55 examples/s]Tokenizing train dataset:  25%|██▌       | 6078/24227 [00:29<01:39, 182.23 examples/s]Tokenizing train dataset:  25%|██▌       | 6104/24227 [00:29<01:31, 197.36 examples/s]Tokenizing train dataset:  25%|██▌       | 6132/24227 [00:29<01:24, 214.92 examples/s]Tokenizing train dataset:  25%|██▌       | 6165/24227 [00:29<01:14, 241.40 examples/s]Tokenizing train dataset:  26%|██▌       | 6198/24227 [00:29<01:08, 261.64 examples/s]Tokenizing train dataset:  26%|██▌       | 6230/24227 [00:29<01:05, 275.19 examples/s]Tokenizing train dataset:  26%|██▌       | 6277/24227 [00:30<01:02, 285.15 examples/s]Tokenizing train dataset:  26%|██▌       | 6309/24227 [00:30<01:01, 292.09 examples/s]Tokenizing train dataset:  26%|██▌       | 6353/24227 [00:30<01:03, 280.53 examples/s]Tokenizing train dataset:  26%|██▋       | 6397/24227 [00:30<01:03, 282.62 examples/s]Tokenizing train dataset:  27%|██▋       | 6427/24227 [00:30<01:02, 284.87 examples/s]Tokenizing train dataset:  27%|██▋       | 6462/24227 [00:30<00:59, 297.45 examples/s]Tokenizing train dataset:  27%|██▋       | 6500/24227 [00:30<01:03, 277.31 examples/s]Tokenizing train dataset:  27%|██▋       | 6533/24227 [00:31<01:22, 214.41 examples/s]Tokenizing train dataset:  27%|██▋       | 6559/24227 [00:31<01:19, 222.99 examples/s]Tokenizing train dataset:  27%|██▋       | 6593/24227 [00:31<01:19, 222.63 examples/s]Tokenizing train dataset:  27%|██▋       | 6617/24227 [00:31<01:31, 191.88 examples/s]Tokenizing train dataset:  27%|██▋       | 6649/24227 [00:31<01:20, 217.77 examples/s]Tokenizing train dataset:  28%|██▊       | 6680/24227 [00:31<01:14, 235.53 examples/s]Tokenizing train dataset:  28%|██▊       | 6719/24227 [00:32<01:21, 214.42 examples/s]Tokenizing train dataset:  28%|██▊       | 6752/24227 [00:32<01:13, 237.93 examples/s]Tokenizing train dataset:  28%|██▊       | 6787/24227 [00:32<01:21, 213.32 examples/s]Tokenizing train dataset:  28%|██▊       | 6825/24227 [00:32<01:10, 247.03 examples/s]Tokenizing train dataset:  28%|██▊       | 6861/24227 [00:32<01:11, 242.39 examples/s]Tokenizing train dataset:  28%|██▊       | 6889/24227 [00:32<01:09, 250.25 examples/s]Tokenizing train dataset:  29%|██▊       | 6929/24227 [00:32<01:12, 237.66 examples/s]Tokenizing train dataset:  29%|██▉       | 6970/24227 [00:32<01:03, 272.44 examples/s]Tokenizing train dataset:  29%|██▉       | 7000/24227 [00:33<01:01, 277.97 examples/s]Tokenizing train dataset:  29%|██▉       | 7033/24227 [00:33<00:59, 289.93 examples/s]Tokenizing train dataset:  29%|██▉       | 7065/24227 [00:33<00:58, 294.99 examples/s]Tokenizing train dataset:  29%|██▉       | 7098/24227 [00:33<00:56, 301.56 examples/s]Tokenizing train dataset:  29%|██▉       | 7146/24227 [00:33<00:56, 302.47 examples/s]Tokenizing train dataset:  30%|██▉       | 7183/24227 [00:33<01:20, 212.36 examples/s]Tokenizing train dataset:  30%|██▉       | 7221/24227 [00:33<01:18, 216.45 examples/s]Tokenizing train dataset:  30%|██▉       | 7262/24227 [00:34<01:13, 229.74 examples/s]Tokenizing train dataset:  30%|███       | 7290/24227 [00:34<01:10, 239.26 examples/s]Tokenizing train dataset:  30%|███       | 7326/24227 [00:34<01:14, 227.74 examples/s]Tokenizing train dataset:  30%|███       | 7356/24227 [00:34<01:09, 242.91 examples/s]Tokenizing train dataset:  31%|███       | 7399/24227 [00:34<01:06, 253.48 examples/s]Tokenizing train dataset:  31%|███       | 7442/24227 [00:34<01:04, 259.22 examples/s]Tokenizing train dataset:  31%|███       | 7475/24227 [00:34<01:01, 274.16 examples/s]Tokenizing train dataset:  31%|███       | 7514/24227 [00:35<01:11, 234.81 examples/s]Tokenizing train dataset:  31%|███       | 7542/24227 [00:35<01:09, 241.21 examples/s]Tokenizing train dataset:  31%|███       | 7570/24227 [00:35<01:07, 248.29 examples/s]Tokenizing train dataset:  31%|███▏      | 7609/24227 [00:35<01:07, 246.63 examples/s]Tokenizing train dataset:  32%|███▏      | 7644/24227 [00:35<01:12, 227.80 examples/s]Tokenizing train dataset:  32%|███▏      | 7691/24227 [00:35<01:19, 208.08 examples/s]Tokenizing train dataset:  32%|███▏      | 7723/24227 [00:36<01:37, 169.55 examples/s]Tokenizing train dataset:  32%|███▏      | 7767/24227 [00:36<01:17, 213.73 examples/s]Tokenizing train dataset:  32%|███▏      | 7804/24227 [00:36<01:08, 240.96 examples/s]Tokenizing train dataset:  32%|███▏      | 7860/24227 [00:36<00:53, 307.99 examples/s]Tokenizing train dataset:  33%|███▎      | 7922/24227 [00:36<00:43, 379.17 examples/s]Tokenizing train dataset:  33%|███▎      | 7998/24227 [00:36<00:41, 386.81 examples/s]Tokenizing train dataset:  33%|███▎      | 8064/24227 [00:37<00:40, 401.00 examples/s]Tokenizing train dataset:  34%|███▎      | 8126/24227 [00:37<00:35, 449.10 examples/s]Tokenizing train dataset:  34%|███▍      | 8190/24227 [00:37<00:36, 433.80 examples/s]Tokenizing train dataset:  34%|███▍      | 8270/24227 [00:37<00:37, 425.10 examples/s]Tokenizing train dataset:  34%|███▍      | 8330/24227 [00:37<00:34, 458.80 examples/s]Tokenizing train dataset:  35%|███▍      | 8389/24227 [00:37<00:32, 486.56 examples/s]Tokenizing train dataset:  35%|███▍      | 8462/24227 [00:37<00:36, 433.65 examples/s]Tokenizing train dataset:  35%|███▌      | 8520/24227 [00:37<00:33, 463.34 examples/s]Tokenizing train dataset:  35%|███▌      | 8570/24227 [00:38<00:33, 471.15 examples/s]Tokenizing train dataset:  36%|███▌      | 8649/24227 [00:38<00:28, 549.19 examples/s]Tokenizing train dataset:  36%|███▌      | 8711/24227 [00:38<00:27, 563.44 examples/s]Tokenizing train dataset:  36%|███▌      | 8775/24227 [00:38<00:26, 582.27 examples/s]Tokenizing train dataset:  37%|███▋      | 8864/24227 [00:38<00:26, 583.68 examples/s]Tokenizing train dataset:  37%|███▋      | 8939/24227 [00:38<00:28, 537.68 examples/s]Tokenizing train dataset:  37%|███▋      | 9005/24227 [00:38<00:26, 564.43 examples/s]Tokenizing train dataset:  37%|███▋      | 9076/24227 [00:38<00:25, 599.07 examples/s]Tokenizing train dataset:  38%|███▊      | 9145/24227 [00:39<00:27, 548.31 examples/s]Tokenizing train dataset:  38%|███▊      | 9214/24227 [00:39<00:30, 490.01 examples/s]Tokenizing train dataset:  38%|███▊      | 9291/24227 [00:39<00:31, 474.89 examples/s]Tokenizing train dataset:  39%|███▊      | 9347/24227 [00:39<00:30, 490.02 examples/s]Tokenizing train dataset:  39%|███▉      | 9409/24227 [00:39<00:28, 513.44 examples/s]Tokenizing train dataset:  39%|███▉      | 9480/24227 [00:39<00:26, 559.65 examples/s]Tokenizing train dataset:  39%|███▉      | 9553/24227 [00:39<00:30, 484.73 examples/s]Tokenizing train dataset:  40%|███▉      | 9608/24227 [00:40<00:29, 498.82 examples/s]Tokenizing train dataset:  40%|███▉      | 9690/24227 [00:40<00:28, 512.17 examples/s]Tokenizing train dataset:  40%|████      | 9751/24227 [00:40<00:27, 534.59 examples/s]Tokenizing train dataset:  40%|████      | 9811/24227 [00:40<00:26, 543.78 examples/s]Tokenizing train dataset:  41%|████      | 9895/24227 [00:40<00:26, 549.06 examples/s]Tokenizing train dataset:  41%|████▏     | 9994/24227 [00:40<00:24, 584.56 examples/s]Tokenizing train dataset:  42%|████▏     | 10086/24227 [00:40<00:24, 588.83 examples/s]Tokenizing train dataset:  42%|████▏     | 10164/24227 [00:40<00:25, 562.38 examples/s]Tokenizing train dataset:  42%|████▏     | 10222/24227 [00:41<00:31, 438.86 examples/s]Tokenizing train dataset:  42%|████▏     | 10280/24227 [00:41<00:36, 383.53 examples/s]Tokenizing train dataset:  43%|████▎     | 10333/24227 [00:41<00:42, 327.55 examples/s]Tokenizing train dataset:  43%|████▎     | 10374/24227 [00:41<00:48, 285.92 examples/s]Tokenizing train dataset:  43%|████▎     | 10412/24227 [00:42<00:50, 271.96 examples/s]Tokenizing train dataset:  43%|████▎     | 10454/24227 [00:42<00:51, 269.38 examples/s]Tokenizing train dataset:  43%|████▎     | 10492/24227 [00:42<00:52, 262.77 examples/s]Tokenizing train dataset:  43%|████▎     | 10530/24227 [00:42<00:53, 253.81 examples/s]Tokenizing train dataset:  44%|████▎     | 10564/24227 [00:42<00:50, 269.60 examples/s]Tokenizing train dataset:  44%|████▎     | 10593/24227 [00:42<00:50, 272.49 examples/s]Tokenizing train dataset:  44%|████▍     | 10626/24227 [00:42<00:47, 284.42 examples/s]Tokenizing train dataset:  44%|████▍     | 10660/24227 [00:42<00:45, 295.59 examples/s]Tokenizing train dataset:  44%|████▍     | 10698/24227 [00:43<00:48, 278.17 examples/s]Tokenizing train dataset:  44%|████▍     | 10736/24227 [00:43<00:44, 302.01 examples/s]Tokenizing train dataset:  44%|████▍     | 10771/24227 [00:43<00:49, 273.97 examples/s]Tokenizing train dataset:  45%|████▍     | 10806/24227 [00:43<00:45, 292.46 examples/s]Tokenizing train dataset:  45%|████▍     | 10842/24227 [00:43<00:52, 256.87 examples/s]Tokenizing train dataset:  45%|████▍     | 10883/24227 [00:43<00:51, 258.10 examples/s]Tokenizing train dataset:  45%|████▌     | 10914/24227 [00:43<00:49, 267.52 examples/s]Tokenizing train dataset:  45%|████▌     | 10953/24227 [00:44<00:55, 237.64 examples/s]Tokenizing train dataset:  45%|████▌     | 10996/24227 [00:44<00:54, 241.68 examples/s]Tokenizing train dataset:  46%|████▌     | 11039/24227 [00:44<01:23, 158.61 examples/s]Tokenizing train dataset:  46%|████▌     | 11080/24227 [00:44<01:19, 165.09 examples/s]Tokenizing train dataset:  46%|████▌     | 11100/24227 [00:45<01:17, 168.83 examples/s]Tokenizing train dataset:  46%|████▌     | 11139/24227 [00:45<01:10, 184.55 examples/s]Tokenizing train dataset:  46%|████▌     | 11169/24227 [00:45<01:04, 203.64 examples/s]Tokenizing train dataset:  46%|████▌     | 11202/24227 [00:45<00:56, 228.76 examples/s]Tokenizing train dataset:  46%|████▋     | 11228/24227 [00:45<00:55, 234.24 examples/s]Tokenizing train dataset:  47%|████▋     | 11269/24227 [00:45<00:52, 245.30 examples/s]Tokenizing train dataset:  47%|████▋     | 11306/24227 [00:45<00:58, 220.21 examples/s]Tokenizing train dataset:  47%|████▋     | 11346/24227 [00:46<01:49, 118.04 examples/s]Tokenizing train dataset:  47%|████▋     | 11380/24227 [00:46<01:40, 127.49 examples/s]Tokenizing train dataset:  47%|████▋     | 11411/24227 [00:46<01:31, 140.55 examples/s]Tokenizing train dataset:  47%|████▋     | 11431/24227 [00:47<01:35, 133.33 examples/s]Tokenizing train dataset:  47%|████▋     | 11461/24227 [00:47<01:19, 159.69 examples/s]Tokenizing train dataset:  47%|████▋     | 11502/24227 [00:47<01:13, 172.53 examples/s]Tokenizing train dataset:  48%|████▊     | 11530/24227 [00:47<01:06, 190.10 examples/s]Tokenizing train dataset:  48%|████▊     | 11566/24227 [00:47<01:05, 194.00 examples/s]Tokenizing train dataset:  48%|████▊     | 11596/24227 [00:47<00:59, 213.78 examples/s]Tokenizing train dataset:  48%|████▊     | 11624/24227 [00:47<00:55, 226.38 examples/s]Tokenizing train dataset:  48%|████▊     | 11659/24227 [00:47<00:49, 254.50 examples/s]Tokenizing train dataset:  48%|████▊     | 11690/24227 [00:48<00:46, 267.02 examples/s]Tokenizing train dataset:  48%|████▊     | 11728/24227 [00:48<00:52, 239.22 examples/s]Tokenizing train dataset:  49%|████▊     | 11763/24227 [00:48<00:59, 208.38 examples/s]Tokenizing train dataset:  49%|████▊     | 11793/24227 [00:48<00:55, 225.75 examples/s]Tokenizing train dataset:  49%|████▉     | 11831/24227 [00:48<00:55, 222.50 examples/s]Tokenizing train dataset:  49%|████▉     | 11863/24227 [00:48<00:53, 229.40 examples/s]Tokenizing train dataset:  49%|████▉     | 11905/24227 [00:49<00:45, 272.18 examples/s]Tokenizing train dataset:  49%|████▉     | 11950/24227 [00:49<00:39, 314.70 examples/s]Tokenizing train dataset:  49%|████▉     | 11990/24227 [00:49<00:37, 328.57 examples/s]Tokenizing train dataset:  50%|████▉     | 12035/24227 [00:49<00:42, 285.52 examples/s]Tokenizing train dataset:  50%|████▉     | 12067/24227 [00:49<00:51, 235.66 examples/s]Tokenizing train dataset:  50%|█████     | 12118/24227 [00:49<00:41, 292.14 examples/s]Tokenizing train dataset:  50%|█████     | 12175/24227 [00:49<00:33, 355.07 examples/s]Tokenizing train dataset:  51%|█████     | 12250/24227 [00:50<00:34, 348.11 examples/s]Tokenizing train dataset:  51%|█████     | 12318/24227 [00:50<00:28, 417.48 examples/s]Tokenizing train dataset:  51%|█████     | 12390/24227 [00:50<00:28, 408.22 examples/s]Tokenizing train dataset:  51%|█████▏    | 12459/24227 [00:50<00:27, 422.54 examples/s]Tokenizing train dataset:  52%|█████▏    | 12525/24227 [00:50<00:24, 469.81 examples/s]Tokenizing train dataset:  52%|█████▏    | 12605/24227 [00:50<00:23, 486.68 examples/s]Tokenizing train dataset:  52%|█████▏    | 12683/24227 [00:50<00:25, 448.25 examples/s]Tokenizing train dataset:  53%|█████▎    | 12735/24227 [00:51<00:24, 460.82 examples/s]Tokenizing train dataset:  53%|█████▎    | 12810/24227 [00:51<00:26, 428.11 examples/s]Tokenizing train dataset:  53%|█████▎    | 12859/24227 [00:51<00:25, 439.81 examples/s]Tokenizing train dataset:  53%|█████▎    | 12920/24227 [00:51<00:23, 477.16 examples/s]Tokenizing train dataset:  54%|█████▎    | 12975/24227 [00:51<00:22, 492.91 examples/s]Tokenizing train dataset:  54%|█████▍    | 13034/24227 [00:51<00:21, 516.47 examples/s]Tokenizing train dataset:  54%|█████▍    | 13103/24227 [00:51<00:24, 448.04 examples/s]Tokenizing train dataset:  54%|█████▍    | 13182/24227 [00:52<00:23, 471.75 examples/s]Tokenizing train dataset:  55%|█████▍    | 13242/24227 [00:52<00:30, 364.98 examples/s]Tokenizing train dataset:  55%|█████▍    | 13306/24227 [00:52<00:28, 378.16 examples/s]Tokenizing train dataset:  55%|█████▌    | 13359/24227 [00:52<00:26, 406.36 examples/s]Tokenizing train dataset:  55%|█████▌    | 13413/24227 [00:52<00:24, 435.05 examples/s]Tokenizing train dataset:  56%|█████▌    | 13492/24227 [00:52<00:29, 359.12 examples/s]Tokenizing train dataset:  56%|█████▌    | 13548/24227 [00:53<00:26, 397.45 examples/s]Tokenizing train dataset:  56%|█████▌    | 13626/24227 [00:53<00:26, 407.05 examples/s]Tokenizing train dataset:  56%|█████▋    | 13682/24227 [00:53<00:24, 437.09 examples/s]Tokenizing train dataset:  57%|█████▋    | 13763/24227 [00:53<00:26, 393.18 examples/s]Tokenizing train dataset:  57%|█████▋    | 13834/24227 [00:53<00:22, 454.57 examples/s]Tokenizing train dataset:  57%|█████▋    | 13900/24227 [00:53<00:20, 497.64 examples/s]Tokenizing train dataset:  58%|█████▊    | 13961/24227 [00:53<00:19, 522.02 examples/s]Tokenizing train dataset:  58%|█████▊    | 14053/24227 [00:54<00:18, 547.71 examples/s]Tokenizing train dataset:  58%|█████▊    | 14116/24227 [00:54<00:17, 566.59 examples/s]Tokenizing train dataset:  59%|█████▊    | 14186/24227 [00:54<00:16, 600.38 examples/s]Tokenizing train dataset:  59%|█████▉    | 14265/24227 [00:54<00:17, 568.63 examples/s]Tokenizing train dataset:  59%|█████▉    | 14339/24227 [00:54<00:19, 508.60 examples/s]Tokenizing train dataset:  59%|█████▉    | 14403/24227 [00:54<00:20, 482.09 examples/s]Tokenizing train dataset:  60%|█████▉    | 14475/24227 [00:54<00:21, 455.95 examples/s]Tokenizing train dataset:  60%|██████    | 14549/24227 [00:55<00:20, 464.40 examples/s]Tokenizing train dataset:  60%|██████    | 14619/24227 [00:55<00:20, 459.86 examples/s]Tokenizing train dataset:  61%|██████    | 14690/24227 [00:55<00:22, 415.33 examples/s]Tokenizing train dataset:  61%|██████    | 14734/24227 [00:55<00:22, 418.64 examples/s]Tokenizing train dataset:  61%|██████    | 14790/24227 [00:55<00:21, 448.54 examples/s]Tokenizing train dataset:  61%|██████▏   | 14848/24227 [00:55<00:26, 350.00 examples/s]Tokenizing train dataset:  62%|██████▏   | 14907/24227 [00:56<00:28, 328.35 examples/s]Tokenizing train dataset:  62%|██████▏   | 14959/24227 [00:56<00:33, 280.14 examples/s]Tokenizing train dataset:  62%|██████▏   | 15012/24227 [00:56<00:31, 294.68 examples/s]Tokenizing train dataset:  62%|██████▏   | 15063/24227 [00:56<00:30, 305.06 examples/s]Tokenizing train dataset:  62%|██████▏   | 15098/24227 [00:56<00:29, 309.76 examples/s]Tokenizing train dataset:  63%|██████▎   | 15150/24227 [00:56<00:28, 317.46 examples/s]Tokenizing train dataset:  63%|██████▎   | 15195/24227 [00:57<00:29, 307.37 examples/s]Tokenizing train dataset:  63%|██████▎   | 15231/24227 [00:57<00:31, 281.34 examples/s]Tokenizing train dataset:  63%|██████▎   | 15270/24227 [00:57<00:36, 242.90 examples/s]Tokenizing train dataset:  63%|██████▎   | 15300/24227 [00:57<00:35, 250.37 examples/s]Tokenizing train dataset:  63%|██████▎   | 15337/24227 [00:57<00:39, 226.73 examples/s]Tokenizing train dataset:  63%|██████▎   | 15367/24227 [00:57<00:37, 239.00 examples/s]Tokenizing train dataset:  64%|██████▎   | 15413/24227 [00:57<00:34, 258.44 examples/s]Tokenizing train dataset:  64%|██████▎   | 15441/24227 [00:58<00:33, 260.23 examples/s]Tokenizing train dataset:  64%|██████▍   | 15479/24227 [00:58<00:36, 240.08 examples/s]Tokenizing train dataset:  64%|██████▍   | 15506/24227 [00:58<00:35, 244.22 examples/s]Tokenizing train dataset:  64%|██████▍   | 15545/24227 [00:58<00:37, 232.79 examples/s]Tokenizing train dataset:  64%|██████▍   | 15588/24227 [00:58<00:34, 248.18 examples/s]Tokenizing train dataset:  64%|██████▍   | 15617/24227 [00:58<00:33, 256.55 examples/s]Tokenizing train dataset:  65%|██████▍   | 15648/24227 [00:58<00:31, 268.50 examples/s]Tokenizing train dataset:  65%|██████▍   | 15680/24227 [00:59<00:30, 278.35 examples/s]Tokenizing train dataset:  65%|██████▍   | 15724/24227 [00:59<00:30, 275.10 examples/s]Tokenizing train dataset:  65%|██████▌   | 15760/24227 [00:59<00:29, 291.93 examples/s]Tokenizing train dataset:  65%|██████▌   | 15807/24227 [00:59<00:28, 294.73 examples/s]Tokenizing train dataset:  65%|██████▌   | 15850/24227 [00:59<00:29, 287.35 examples/s]Tokenizing train dataset:  66%|██████▌   | 15884/24227 [00:59<00:27, 298.54 examples/s]Tokenizing train dataset:  66%|██████▌   | 15930/24227 [00:59<00:27, 298.31 examples/s]Tokenizing train dataset:  66%|██████▌   | 15964/24227 [01:00<00:30, 273.12 examples/s]Tokenizing train dataset:  66%|██████▌   | 15995/24227 [01:00<00:29, 280.51 examples/s]Tokenizing train dataset:  66%|██████▌   | 16029/24227 [01:00<00:27, 293.08 examples/s]Tokenizing train dataset:  66%|██████▋   | 16071/24227 [01:00<00:28, 284.97 examples/s]Tokenizing train dataset:  67%|██████▋   | 16112/24227 [01:00<00:34, 238.44 examples/s]Tokenizing train dataset:  67%|██████▋   | 16150/24227 [01:00<00:30, 267.45 examples/s]Tokenizing train dataset:  67%|██████▋   | 16181/24227 [01:00<00:29, 275.76 examples/s]Tokenizing train dataset:  67%|██████▋   | 16228/24227 [01:00<00:27, 285.70 examples/s]Tokenizing train dataset:  67%|██████▋   | 16260/24227 [01:01<00:27, 291.41 examples/s]Tokenizing train dataset:  67%|██████▋   | 16297/24227 [01:01<00:29, 271.90 examples/s]Tokenizing train dataset:  67%|██████▋   | 16332/24227 [01:01<00:31, 248.59 examples/s]Tokenizing train dataset:  68%|██████▊   | 16367/24227 [01:01<00:33, 237.32 examples/s]Tokenizing train dataset:  68%|██████▊   | 16408/24227 [01:01<00:31, 244.83 examples/s]Tokenizing train dataset:  68%|██████▊   | 16447/24227 [01:01<00:31, 246.97 examples/s]Tokenizing train dataset:  68%|██████▊   | 16487/24227 [01:02<00:34, 226.17 examples/s]Tokenizing train dataset:  68%|██████▊   | 16525/24227 [01:02<00:30, 251.14 examples/s]Tokenizing train dataset:  68%|██████▊   | 16594/24227 [01:02<00:22, 346.46 examples/s]Tokenizing train dataset:  69%|██████▉   | 16667/24227 [01:02<00:19, 386.69 examples/s]Tokenizing train dataset:  69%|██████▉   | 16712/24227 [01:02<00:18, 398.65 examples/s]Tokenizing train dataset:  69%|██████▉   | 16763/24227 [01:02<00:17, 425.62 examples/s]Tokenizing train dataset:  69%|██████▉   | 16825/24227 [01:02<00:15, 475.55 examples/s]Tokenizing train dataset:  70%|██████▉   | 16895/24227 [01:02<00:15, 462.92 examples/s]Tokenizing train dataset:  70%|██████▉   | 16951/24227 [01:03<00:14, 485.97 examples/s]Tokenizing train dataset:  70%|███████   | 17018/24227 [01:03<00:13, 532.78 examples/s]Tokenizing train dataset:  70%|███████   | 17076/24227 [01:03<00:13, 541.23 examples/s]Tokenizing train dataset:  71%|███████   | 17145/24227 [01:03<00:12, 582.21 examples/s]Tokenizing train dataset:  71%|███████   | 17207/24227 [01:03<00:11, 591.22 examples/s]Tokenizing train dataset:  71%|███████▏  | 17287/24227 [01:03<00:12, 564.59 examples/s]Tokenizing train dataset:  72%|███████▏  | 17354/24227 [01:03<00:11, 589.89 examples/s]Tokenizing train dataset:  72%|███████▏  | 17430/24227 [01:03<00:12, 549.66 examples/s]Tokenizing train dataset:  72%|███████▏  | 17514/24227 [01:03<00:12, 549.73 examples/s]Tokenizing train dataset:  73%|███████▎  | 17597/24227 [01:04<00:13, 485.02 examples/s]Tokenizing train dataset:  73%|███████▎  | 17652/24227 [01:04<00:13, 497.47 examples/s]Tokenizing train dataset:  73%|███████▎  | 17723/24227 [01:04<00:14, 461.74 examples/s]Tokenizing train dataset:  73%|███████▎  | 17772/24227 [01:04<00:13, 465.73 examples/s]Tokenizing train dataset:  74%|███████▎  | 17840/24227 [01:04<00:14, 451.93 examples/s]Tokenizing train dataset:  74%|███████▍  | 17899/24227 [01:04<00:15, 418.03 examples/s]Tokenizing train dataset:  74%|███████▍  | 17952/24227 [01:05<00:14, 440.88 examples/s]Tokenizing train dataset:  74%|███████▍  | 18027/24227 [01:05<00:13, 457.40 examples/s]Tokenizing train dataset:  75%|███████▍  | 18076/24227 [01:05<00:13, 463.93 examples/s]Tokenizing train dataset:  75%|███████▍  | 18140/24227 [01:05<00:12, 503.45 examples/s]Tokenizing train dataset:  75%|███████▌  | 18203/24227 [01:05<00:11, 535.25 examples/s]Tokenizing train dataset:  75%|███████▌  | 18273/24227 [01:05<00:10, 575.53 examples/s]Tokenizing train dataset:  76%|███████▌  | 18343/24227 [01:05<00:09, 602.62 examples/s]Tokenizing train dataset:  76%|███████▌  | 18431/24227 [01:05<00:09, 594.76 examples/s]Tokenizing train dataset:  76%|███████▋  | 18503/24227 [01:06<00:11, 492.72 examples/s]Tokenizing train dataset:  77%|███████▋  | 18588/24227 [01:06<00:11, 512.31 examples/s]Tokenizing train dataset:  77%|███████▋  | 18646/24227 [01:06<00:10, 524.27 examples/s]Tokenizing train dataset:  77%|███████▋  | 18714/24227 [01:06<00:09, 558.76 examples/s]Tokenizing train dataset:  78%|███████▊  | 18795/24227 [01:06<00:12, 449.87 examples/s]Tokenizing train dataset:  78%|███████▊  | 18876/24227 [01:06<00:13, 382.26 examples/s]Tokenizing train dataset:  78%|███████▊  | 18920/24227 [01:07<00:13, 391.08 examples/s]Tokenizing train dataset:  78%|███████▊  | 18965/24227 [01:07<00:13, 400.18 examples/s]Tokenizing train dataset:  79%|███████▊  | 19026/24227 [01:07<00:14, 355.24 examples/s]Tokenizing train dataset:  79%|███████▊  | 19076/24227 [01:07<00:13, 383.90 examples/s]Tokenizing train dataset:  79%|███████▉  | 19152/24227 [01:07<00:15, 337.50 examples/s]Tokenizing train dataset:  79%|███████▉  | 19226/24227 [01:07<00:12, 412.27 examples/s]Tokenizing train dataset:  80%|███████▉  | 19288/24227 [01:07<00:10, 454.36 examples/s]Tokenizing train dataset:  80%|███████▉  | 19341/24227 [01:08<00:10, 468.33 examples/s]Tokenizing train dataset:  80%|████████  | 19399/24227 [01:08<00:11, 422.25 examples/s]Tokenizing train dataset:  80%|████████  | 19491/24227 [01:08<00:08, 536.54 examples/s]Tokenizing train dataset:  81%|████████  | 19578/24227 [01:08<00:07, 617.65 examples/s]Tokenizing train dataset:  81%|████████  | 19646/24227 [01:08<00:07, 617.58 examples/s]Tokenizing train dataset:  82%|████████▏ | 19770/24227 [01:08<00:06, 675.47 examples/s]Tokenizing train dataset:  82%|████████▏ | 19880/24227 [01:08<00:05, 778.92 examples/s]Tokenizing train dataset:  82%|████████▏ | 19981/24227 [01:08<00:05, 837.51 examples/s]Tokenizing train dataset:  83%|████████▎ | 20082/24227 [01:08<00:04, 880.17 examples/s]Tokenizing train dataset:  83%|████████▎ | 20219/24227 [01:09<00:04, 888.99 examples/s]Tokenizing train dataset:  84%|████████▍ | 20340/24227 [01:09<00:04, 845.00 examples/s]Tokenizing train dataset:  84%|████████▍ | 20448/24227 [01:09<00:04, 900.94 examples/s]Tokenizing train dataset:  85%|████████▍ | 20578/24227 [01:09<00:04, 884.05 examples/s]Tokenizing train dataset:  85%|████████▌ | 20703/24227 [01:09<00:04, 865.91 examples/s]Tokenizing train dataset:  86%|████████▌ | 20811/24227 [01:09<00:03, 913.77 examples/s]Tokenizing train dataset:  86%|████████▋ | 20913/24227 [01:09<00:03, 937.65 examples/s]Tokenizing train dataset:  87%|████████▋ | 21020/24227 [01:09<00:03, 969.67 examples/s]Tokenizing train dataset:  87%|████████▋ | 21142/24227 [01:10<00:03, 909.80 examples/s]Tokenizing train dataset:  88%|████████▊ | 21268/24227 [01:10<00:03, 804.05 examples/s]Tokenizing train dataset:  88%|████████▊ | 21380/24227 [01:10<00:03, 874.40 examples/s]Tokenizing train dataset:  89%|████████▉ | 21502/24227 [01:10<00:03, 845.31 examples/s]Tokenizing train dataset:  89%|████████▉ | 21610/24227 [01:10<00:02, 899.80 examples/s]Tokenizing train dataset:  90%|████████▉ | 21729/24227 [01:10<00:03, 733.27 examples/s]Tokenizing train dataset:  90%|█████████ | 21853/24227 [01:11<00:04, 520.34 examples/s]Tokenizing train dataset:  91%|█████████ | 21941/24227 [01:11<00:03, 576.13 examples/s]Tokenizing train dataset:  91%|█████████ | 22029/24227 [01:11<00:03, 631.84 examples/s]Tokenizing train dataset:  91%|█████████▏| 22141/24227 [01:11<00:02, 732.43 examples/s]Tokenizing train dataset:  92%|█████████▏| 22260/24227 [01:11<00:02, 734.83 examples/s]Tokenizing train dataset:  92%|█████████▏| 22360/24227 [01:11<00:02, 791.64 examples/s]Tokenizing train dataset:  93%|█████████▎| 22477/24227 [01:11<00:01, 880.21 examples/s]Tokenizing train dataset:  93%|█████████▎| 22578/24227 [01:12<00:01, 910.14 examples/s]Tokenizing train dataset:  94%|█████████▎| 22690/24227 [01:12<00:01, 960.99 examples/s]Tokenizing train dataset:  94%|█████████▍| 22804/24227 [01:12<00:01, 1007.69 examples/s]Tokenizing train dataset:  95%|█████████▍| 22929/24227 [01:12<00:01, 932.86 examples/s] Tokenizing train dataset:  95%|█████████▌| 23041/24227 [01:12<00:01, 980.03 examples/s]Tokenizing train dataset:  96%|█████████▌| 23171/24227 [01:12<00:01, 934.96 examples/s]Tokenizing train dataset:  96%|█████████▌| 23315/24227 [01:12<00:00, 939.19 examples/s]Tokenizing train dataset:  97%|█████████▋| 23452/24227 [01:12<00:00, 927.70 examples/s]Tokenizing train dataset:  97%|█████████▋| 23599/24227 [01:13<00:00, 941.22 examples/s]Tokenizing train dataset:  98%|█████████▊| 23707/24227 [01:13<00:00, 972.28 examples/s]Tokenizing train dataset:  98%|█████████▊| 23863/24227 [01:13<00:00, 991.48 examples/s]Tokenizing train dataset:  99%|█████████▉| 23970/24227 [01:13<00:00, 1008.89 examples/s]Tokenizing train dataset:  99%|█████████▉| 24090/24227 [01:13<00:00, 911.84 examples/s] Tokenizing train dataset: 100%|█████████▉| 24200/24227 [01:13<00:00, 954.31 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:13<00:00, 328.09 examples/s]
[rank0]:[W611 12:43:25.686399398 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 538/24227 [00:00<00:04, 5317.85 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5464.27 examples/s]Extracting prompt in train dataset:   2%|▏         | 540/24227 [00:00<00:04, 5244.36 examples/s]Extracting prompt in train dataset:   2%|▏         | 520/24227 [00:00<00:04, 5118.87 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3963.19 examples/s]
Extracting prompt in train dataset:   5%|▌         | 1300/24227 [00:00<00:04, 5132.62 examples/s]Extracting prompt in train dataset:   5%|▌         | 1250/24227 [00:00<00:04, 4879.03 examples/s]Extracting prompt in train dataset:   4%|▍         | 1070/24227 [00:00<00:07, 3101.44 examples/s]Extracting prompt in train dataset:   9%|▊         | 2070/24227 [00:00<00:04, 5120.66 examples/s]Extracting prompt in train dataset:   8%|▊         | 1892/24227 [00:00<00:04, 4583.47 examples/s]Extracting prompt in train dataset:   7%|▋         | 1580/24227 [00:00<00:06, 3736.45 examples/s]Extracting prompt in train dataset:  11%|█         | 2637/24227 [00:00<00:04, 4418.36 examples/s]Extracting prompt in train dataset:  10%|█         | 2455/24227 [00:00<00:05, 4139.24 examples/s]Extracting prompt in train dataset:   9%|▉         | 2200/24227 [00:00<00:05, 3886.67 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  13%|█▎        | 3090/24227 [00:00<00:04, 4442.21 examples/s]Extracting prompt in train dataset:  13%|█▎        | 3050/24227 [00:00<00:05, 4059.97 examples/s]Extracting prompt in train dataset:  11%|█▏        | 2780/24227 [00:00<00:05, 3864.90 examples/s]Applying chat template to eval dataset:  32%|███▏      | 307/953 [00:00<00:00, 3025.56 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3605/24227 [00:00<00:04, 4640.54 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3611/24227 [00:00<00:05, 3549.52 examples/s]Extracting prompt in train dataset:  14%|█▎        | 3308/24227 [00:00<00:06, 3267.83 examples/s]Applying chat template to eval dataset:  66%|██████▌   | 631/953 [00:00<00:00, 1853.08 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4004/24227 [00:01<00:05, 3628.51 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4175/24227 [00:01<00:06, 3322.75 examples/s]Extracting prompt in train dataset:  16%|█▌        | 3861/24227 [00:01<00:07, 2823.21 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1333.69 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1381.19 examples/s]
Extracting prompt in train dataset:  19%|█▉        | 4564/24227 [00:01<00:07, 2514.05 examples/s]Extracting prompt in train dataset:  20%|█▉        | 4740/24227 [00:01<00:07, 2453.99 examples/s]Extracting prompt in train dataset:  18%|█▊        | 4430/24227 [00:01<00:07, 2801.55 examples/s]Extracting prompt in train dataset:  20%|██        | 4910/24227 [00:01<00:07, 2676.43 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5310/24227 [00:01<00:06, 2757.62 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5320/24227 [00:01<00:06, 2956.10 examples/s]Extracting prompt in train dataset:  21%|██        | 4998/24227 [00:01<00:06, 2904.34 examples/s]Extracting prompt in train dataset:  23%|██▎       | 5690/24227 [00:01<00:06, 2940.59 examples/s]Extracting prompt in train dataset:  24%|██▎       | 5720/24227 [00:01<00:05, 3181.86 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5410/24227 [00:01<00:06, 3131.42 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  26%|██▌       | 6200/24227 [00:01<00:05, 3368.98 examples/s]Extracting prompt in train dataset:  26%|██▌       | 6250/24227 [00:01<00:04, 3683.04 examples/s]Extracting prompt in train dataset:  24%|██▍       | 5866/24227 [00:01<00:05, 3431.18 examples/s]Extracting prompt in train dataset:  27%|██▋       | 6600/24227 [00:01<00:05, 3503.79 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 320.05 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6828/24227 [00:01<00:04, 3490.92 examples/s]Extracting prompt in train dataset:  27%|██▋       | 6440/24227 [00:01<00:05, 3335.50 examples/s]Extracting prompt in train dataset:  30%|███       | 7270/24227 [00:02<00:04, 3800.55 examples/s]Tokenizing eval dataset:   7%|▋         | 71/953 [00:00<00:03, 267.19 examples/s]Extracting prompt in train dataset:  30%|██▉       | 7220/24227 [00:02<00:04, 3575.89 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7720/24227 [00:02<00:04, 3951.24 examples/s]Extracting prompt in train dataset:  29%|██▉       | 7070/24227 [00:02<00:04, 3581.07 examples/s]Tokenizing eval dataset:  11%|█         | 101/953 [00:00<00:04, 196.98 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7800/24227 [00:02<00:05, 3051.20 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8314/24227 [00:02<00:04, 3371.93 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7650/24227 [00:02<00:05, 3247.20 examples/s]Tokenizing eval dataset:  13%|█▎        | 126/953 [00:00<00:03, 209.06 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8313/24227 [00:02<00:04, 3477.97 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8903/24227 [00:02<00:04, 3281.12 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8237/24227 [00:02<00:04, 3203.53 examples/s]Tokenizing eval dataset:  16%|█▌        | 153/953 [00:00<00:04, 174.89 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8978/24227 [00:02<00:04, 3765.85 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9494/24227 [00:02<00:04, 3200.40 examples/s]Extracting prompt in train dataset:  36%|███▋      | 8828/24227 [00:02<00:04, 3175.65 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9566/24227 [00:02<00:03, 3712.59 examples/s]Tokenizing eval dataset:  19%|█▊        | 178/953 [00:00<00:04, 161.40 examples/s]Extracting prompt in train dataset:  41%|████      | 9969/24227 [00:02<00:04, 3499.83 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9417/24227 [00:02<00:04, 3298.39 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10154/24227 [00:02<00:03, 3564.84 examples/s]Tokenizing eval dataset:  22%|██▏       | 206/953 [00:01<00:05, 143.47 examples/s]Extracting prompt in train dataset:  40%|████      | 9776/24227 [00:02<00:04, 3354.33 examples/s]Extracting prompt in train dataset:  44%|████▍     | 10619/24227 [00:02<00:03, 3787.89 examples/s]Extracting prompt in train dataset:  44%|████▎     | 10550/24227 [00:03<00:04, 3252.56 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:01<00:05, 141.07 examples/s]Extracting prompt in train dataset:  43%|████▎     | 10360/24227 [00:03<00:04, 3171.07 examples/s]Tokenizing eval dataset:  29%|██▉       | 276/953 [00:01<00:03, 221.68 examples/s]Extracting prompt in train dataset:  46%|████▌     | 11200/24227 [00:03<00:03, 3480.40 examples/s]Extracting prompt in train dataset:  46%|████▌     | 11130/24227 [00:03<00:04, 3195.94 examples/s]Extracting prompt in train dataset:  45%|████▍     | 10870/24227 [00:03<00:03, 3553.46 examples/s]Tokenizing eval dataset:  35%|███▍      | 329/953 [00:01<00:02, 291.82 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11689/24227 [00:03<00:03, 3772.89 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11570/24227 [00:03<00:03, 3426.74 examples/s]Extracting prompt in train dataset:  47%|████▋     | 11410/24227 [00:03<00:03, 3956.53 examples/s]Tokenizing eval dataset:  41%|████      | 387/953 [00:01<00:01, 360.23 examples/s]Extracting prompt in train dataset:  51%|█████     | 12239/24227 [00:03<00:02, 4174.45 examples/s]Extracting prompt in train dataset:  50%|█████     | 12154/24227 [00:03<00:03, 3537.80 examples/s]Tokenizing eval dataset:  45%|████▌     | 429/953 [00:01<00:01, 374.15 examples/s]Extracting prompt in train dataset:  50%|█████     | 12116/24227 [00:03<00:02, 4191.88 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12884/24227 [00:03<00:02, 4212.17 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 12564/24227 [00:03<00:03, 3654.44 examples/s]Tokenizing eval dataset:  50%|████▉     | 473/953 [00:01<00:01, 390.81 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 12590/24227 [00:03<00:02, 4311.47 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 13510/24227 [00:03<00:02, 4191.08 examples/s]Tokenizing eval dataset:  56%|█████▌    | 534/953 [00:01<00:00, 445.62 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 13209/24227 [00:03<00:02, 3857.12 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 13240/24227 [00:03<00:02, 4307.03 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 14009/24227 [00:03<00:02, 4377.58 examples/s]Tokenizing eval dataset:  64%|██████▎   | 606/953 [00:02<00:00, 426.21 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13700/24227 [00:03<00:02, 4364.88 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 14476/24227 [00:03<00:02, 4450.12 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13795/24227 [00:03<00:02, 3544.54 examples/s]Tokenizing eval dataset:  70%|███████   | 669/953 [00:02<00:00, 421.29 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 14320/24227 [00:04<00:02, 4277.41 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 15090/24227 [00:04<00:02, 4079.62 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 14380/24227 [00:04<00:02, 3463.39 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:02<00:00, 392.92 examples/s]Extracting prompt in train dataset:  61%|██████▏   | 14896/24227 [00:04<00:02, 3690.13 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 15670/24227 [00:04<00:02, 3548.24 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 14960/24227 [00:04<00:02, 3209.95 examples/s]Tokenizing eval dataset:  83%|████████▎ | 790/953 [00:02<00:00, 390.07 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 16220/24227 [00:04<00:02, 3946.92 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 15450/24227 [00:04<00:02, 3677.45 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 15380/24227 [00:04<00:02, 3338.76 examples/s]Tokenizing eval dataset:  88%|████████▊ | 839/953 [00:02<00:00, 409.71 examples/s]Extracting prompt in train dataset:  69%|██████▊   | 16651/24227 [00:04<00:01, 4030.38 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 16030/24227 [00:04<00:02, 3407.68 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 15960/24227 [00:04<00:02, 3115.64 examples/s]Tokenizing eval dataset:  93%|█████████▎| 889/953 [00:02<00:00, 347.32 examples/s]Extracting prompt in train dataset:  71%|███████   | 17240/24227 [00:04<00:02, 2971.74 examples/s]Extracting prompt in train dataset:  69%|██████▊   | 16610/24227 [00:04<00:02, 3143.32 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 16540/24227 [00:04<00:02, 2997.51 examples/s]Tokenizing eval dataset:  99%|█████████▊| 941/953 [00:03<00:00, 337.33 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 306.15 examples/s]
Extracting prompt in train dataset:  73%|███████▎  | 17744/24227 [00:04<00:01, 3364.66 examples/s]Extracting prompt in train dataset:  71%|███████   | 17156/24227 [00:04<00:01, 3581.23 examples/s]Extracting prompt in train dataset:  70%|███████   | 17070/24227 [00:04<00:02, 3425.45 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 18168/24227 [00:04<00:01, 3551.13 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17653/24227 [00:05<00:01, 3869.69 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17602/24227 [00:05<00:01, 3825.02 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18713/24227 [00:05<00:01, 3986.17 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 18307/24227 [00:05<00:01, 4014.73 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 18190/24227 [00:05<00:01, 3813.37 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 18776/24227 [00:05<00:01, 4161.78 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 19300/24227 [00:05<00:01, 3694.76 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18713/24227 [00:05<00:01, 4125.98 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 19330/24227 [00:05<00:01, 4491.31 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 19184/24227 [00:05<00:01, 4258.72 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19860/24227 [00:05<00:01, 4115.34 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19820/24227 [00:05<00:00, 4583.20 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19930/24227 [00:05<00:00, 4494.30 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 20460/24227 [00:05<00:00, 4051.70 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 20420/24227 [00:05<00:00, 3846.42 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 20530/24227 [00:05<00:00, 4274.06 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 21060/24227 [00:05<00:00, 3889.09 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 21020/24227 [00:05<00:00, 3799.58 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 21136/24227 [00:05<00:00, 4084.21 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21670/24227 [00:05<00:00, 3855.31 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21620/24227 [00:05<00:00, 3834.70 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 21790/24227 [00:06<00:00, 4153.53 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22360/24227 [00:06<00:00, 4061.00 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22270/24227 [00:06<00:00, 3970.11 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22390/24227 [00:06<00:00, 3991.55 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 22960/24227 [00:06<00:00, 3983.77 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 22831/24227 [00:06<00:00, 4332.31 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 22930/24227 [00:06<00:00, 4292.44 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 23500/24227 [00:06<00:00, 4289.75 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 23580/24227 [00:06<00:00, 4528.31 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 23650/24227 [00:06<00:00, 4450.72 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:06<00:00, 4463.08 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 24150/24227 [00:06<00:00, 4788.36 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:06<00:00, 3717.33 examples/s]
Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:06<00:00, 3695.27 examples/s]
Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:06<00:00, 4248.22 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:06<00:00, 3631.53 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 288/24227 [00:00<00:08, 2849.10 examples/s]Applying chat template to train dataset:   1%|          | 273/24227 [00:00<00:08, 2701.79 examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 631/24227 [00:00<00:09, 2463.54 examples/s]Applying chat template to train dataset:   3%|▎         | 632/24227 [00:00<00:09, 2485.97 examples/s]Applying chat template to train dataset:   1%|          | 290/24227 [00:00<00:08, 2875.02 examples/s]Applying chat template to train dataset:   4%|▍         | 943/24227 [00:00<00:10, 2173.82 examples/s]Applying chat template to train dataset:   4%|▍         | 951/24227 [00:00<00:10, 2305.45 examples/s]Applying chat template to train dataset:   3%|▎         | 720/24227 [00:00<00:08, 2863.34 examples/s]Applying chat template to train dataset:   5%|▌         | 1243/24227 [00:00<00:09, 2427.19 examples/s]Applying chat template to train dataset:   5%|▌         | 1238/24227 [00:00<00:09, 2482.86 examples/s]Applying chat template to train dataset:   4%|▍         | 1022/24227 [00:00<00:07, 2918.47 examples/s]Applying chat template to train dataset:   6%|▌         | 1498/24227 [00:00<00:09, 2463.02 examples/s]Applying chat template to train dataset:   6%|▌         | 1512/24227 [00:00<00:08, 2560.70 examples/s]Applying chat template to train dataset:   6%|▌         | 1350/24227 [00:00<00:09, 2459.57 examples/s]Applying chat template to train dataset:   8%|▊         | 1818/24227 [00:00<00:10, 2194.32 examples/s]Applying chat template to train dataset:   7%|▋         | 1817/24227 [00:00<00:10, 2129.68 examples/s]Applying chat template to train dataset:   7%|▋         | 1663/24227 [00:00<00:10, 2125.62 examples/s]Applying chat template to train dataset:   9%|▉         | 2135/24227 [00:00<00:10, 2024.43 examples/s]Applying chat template to train dataset:   9%|▉         | 2121/24227 [00:01<00:12, 1728.69 examples/s]Applying chat template to train dataset:  10%|▉         | 2407/24227 [00:01<00:09, 2187.51 examples/s]Applying chat template to train dataset:   8%|▊         | 1989/24227 [00:00<00:10, 2116.15 examples/s]Applying chat template to train dataset:  10%|▉         | 2413/24227 [00:01<00:11, 1979.77 examples/s]Applying chat template to train dataset:  11%|█         | 2707/24227 [00:01<00:09, 2390.66 examples/s]Applying chat template to train dataset:   9%|▉         | 2283/24227 [00:00<00:09, 2311.36 examples/s]Applying chat template to train dataset:  11%|█         | 2656/24227 [00:01<00:10, 2082.60 examples/s]Applying chat template to train dataset:  13%|█▎        | 3105/24227 [00:01<00:08, 2480.55 examples/s]Applying chat template to train dataset:  11%|█         | 2682/24227 [00:01<00:08, 2426.35 examples/s]Applying chat template to train dataset:  12%|█▏        | 2905/24227 [00:01<00:09, 2179.11 examples/s]Applying chat template to train dataset:  14%|█▍        | 3404/24227 [00:01<00:07, 2606.88 examples/s]Applying chat template to train dataset:  12%|█▏        | 2970/24227 [00:01<00:08, 2509.58 examples/s]Applying chat template to train dataset:  13%|█▎        | 3164/24227 [00:01<00:09, 2281.88 examples/s]Applying chat template to train dataset:  14%|█▍        | 3454/24227 [00:01<00:08, 2448.92 examples/s]Applying chat template to train dataset:  16%|█▌        | 3784/24227 [00:01<00:07, 2579.17 examples/s]Applying chat template to train dataset:  14%|█▍        | 3357/24227 [00:01<00:08, 2530.76 examples/s]Applying chat template to train dataset:  16%|█▌        | 3761/24227 [00:01<00:09, 2071.37 examples/s]Applying chat template to train dataset:  17%|█▋        | 4108/24227 [00:01<00:09, 2226.37 examples/s]Applying chat template to train dataset:  15%|█▌        | 3684/24227 [00:01<00:09, 2198.30 examples/s]Applying chat template to train dataset:  17%|█▋        | 4070/24227 [00:01<00:10, 1908.49 examples/s]Applying chat template to train dataset:  18%|█▊        | 4432/24227 [00:01<00:09, 2009.75 examples/s]Applying chat template to train dataset:  17%|█▋        | 4014/24227 [00:01<00:11, 1788.37 examples/s]Applying chat template to train dataset:  18%|█▊        | 4359/24227 [00:02<00:09, 2123.67 examples/s]Applying chat template to train dataset:  18%|█▊        | 4315/24227 [00:01<00:09, 2016.19 examples/s]Applying chat template to train dataset:  20%|█▉        | 4756/24227 [00:02<00:10, 1943.99 examples/s]Applying chat template to train dataset:  19%|█▉        | 4630/24227 [00:02<00:08, 2262.01 examples/s]Applying chat template to train dataset:  20%|██        | 4966/24227 [00:02<00:09, 1973.99 examples/s]Applying chat template to train dataset:  19%|█▉        | 4700/24227 [00:02<00:08, 2170.78 examples/s]Applying chat template to train dataset:  21%|██        | 4989/24227 [00:02<00:08, 2303.03 examples/s]Applying chat template to train dataset:  22%|██▏       | 5271/24227 [00:02<00:08, 2214.35 examples/s]Applying chat template to train dataset:  21%|██        | 5055/24227 [00:02<00:08, 2224.59 examples/s]Applying chat template to train dataset:  23%|██▎       | 5550/24227 [00:02<00:08, 2326.57 examples/s]Applying chat template to train dataset:  22%|██▏       | 5344/24227 [00:02<00:08, 2320.85 examples/s]Applying chat template to train dataset:  22%|██▏       | 5440/24227 [00:02<00:08, 2318.90 examples/s]Applying chat template to train dataset:  25%|██▍       | 5940/24227 [00:02<00:07, 2416.89 examples/s]Applying chat template to train dataset:  24%|██▎       | 5703/24227 [00:02<00:08, 2279.60 examples/s]Applying chat template to train dataset:  24%|██▍       | 5804/24227 [00:02<00:07, 2347.55 examples/s]Applying chat template to train dataset:  26%|██▌       | 6262/24227 [00:02<00:08, 2059.90 examples/s]Applying chat template to train dataset:  25%|██▍       | 6011/24227 [00:02<00:09, 1941.86 examples/s]Applying chat template to train dataset:  25%|██▌       | 6168/24227 [00:02<00:07, 2368.54 examples/s]Applying chat template to train dataset:  27%|██▋       | 6569/24227 [00:02<00:07, 2276.35 examples/s]Applying chat template to train dataset:  26%|██▌       | 6322/24227 [00:02<00:09, 1946.95 examples/s]Applying chat template to train dataset:  27%|██▋       | 6479/24227 [00:02<00:07, 2528.78 examples/s]Applying chat template to train dataset:  28%|██▊       | 6874/24227 [00:03<00:07, 2455.66 examples/s]Applying chat template to train dataset:  27%|██▋       | 6661/24227 [00:03<00:08, 2032.76 examples/s]Applying chat template to train dataset:  28%|██▊       | 6810/24227 [00:02<00:07, 2373.07 examples/s]Applying chat template to train dataset:  30%|██▉       | 7206/24227 [00:03<00:07, 2369.23 examples/s]Applying chat template to train dataset:  29%|██▉       | 6971/24227 [00:03<00:08, 1946.95 examples/s]Applying chat template to train dataset:  29%|██▉       | 7140/24227 [00:03<00:07, 2182.08 examples/s]Applying chat template to train dataset:  31%|███       | 7531/24227 [00:03<00:07, 2087.55 examples/s]Applying chat template to train dataset:  30%|███       | 7280/24227 [00:03<00:08, 1971.67 examples/s]Applying chat template to train dataset:  31%|███       | 7470/24227 [00:03<00:07, 2167.11 examples/s]Applying chat template to train dataset:  33%|███▎      | 7890/24227 [00:03<00:07, 2177.06 examples/s]Applying chat template to train dataset:  31%|███▏      | 7573/24227 [00:03<00:07, 2171.67 examples/s]Applying chat template to train dataset:  32%|███▏      | 7738/24227 [00:03<00:07, 2275.92 examples/s]Applying chat template to train dataset:  34%|███▎      | 8142/24227 [00:03<00:07, 2251.61 examples/s]Applying chat template to train dataset:  33%|███▎      | 7990/24227 [00:03<00:06, 2330.13 examples/s]Applying chat template to train dataset:  35%|███▍      | 8438/24227 [00:03<00:06, 2418.61 examples/s]Applying chat template to train dataset:  33%|███▎      | 7915/24227 [00:03<00:07, 2200.27 examples/s]Applying chat template to train dataset:  36%|███▌      | 8698/24227 [00:03<00:06, 2461.14 examples/s]Applying chat template to train dataset:  35%|███▍      | 8385/24227 [00:03<00:06, 2428.44 examples/s]Applying chat template to train dataset:  34%|███▍      | 8232/24227 [00:03<00:07, 2165.99 examples/s]Applying chat template to train dataset:  37%|███▋      | 9032/24227 [00:03<00:06, 2214.76 examples/s]Applying chat template to train dataset:  36%|███▌      | 8724/24227 [00:03<00:07, 2194.90 examples/s]Applying chat template to train dataset:  35%|███▌      | 8550/24227 [00:04<00:08, 1943.51 examples/s]Applying chat template to train dataset:  38%|███▊      | 9308/24227 [00:04<00:06, 2341.58 examples/s]Applying chat template to train dataset:  37%|███▋      | 9024/24227 [00:03<00:06, 2371.40 examples/s]Applying chat template to train dataset:  37%|███▋      | 8869/24227 [00:04<00:08, 1915.34 examples/s]Applying chat template to train dataset:  40%|███▉      | 9641/24227 [00:04<00:07, 2061.49 examples/s]Applying chat template to train dataset:  39%|███▊      | 9362/24227 [00:04<00:06, 2193.44 examples/s]Applying chat template to train dataset:  38%|███▊      | 9191/24227 [00:04<00:07, 1978.29 examples/s]Applying chat template to train dataset:  41%|████▏     | 10006/24227 [00:04<00:06, 2171.98 examples/s]Applying chat template to train dataset:  40%|████      | 9722/24227 [00:04<00:06, 2254.88 examples/s]Applying chat template to train dataset:  39%|███▉      | 9426/24227 [00:04<00:07, 2054.32 examples/s]Applying chat template to train dataset:  43%|████▎     | 10328/24227 [00:04<00:07, 1857.17 examples/s]Applying chat template to train dataset:  42%|████▏     | 10060/24227 [00:04<00:07, 1835.98 examples/s]Applying chat template to train dataset:  40%|████      | 9742/24227 [00:04<00:08, 1766.48 examples/s]Applying chat template to train dataset:  44%|████▍     | 10632/24227 [00:04<00:06, 2089.65 examples/s]Applying chat template to train dataset:  43%|████▎     | 10368/24227 [00:04<00:06, 2068.95 examples/s]Applying chat template to train dataset:  41%|████▏     | 10044/24227 [00:04<00:07, 2016.97 examples/s]Applying chat template to train dataset:  45%|████▌     | 10950/24227 [00:04<00:06, 2037.37 examples/s]Applying chat template to train dataset:  44%|████▍     | 10730/24227 [00:04<00:06, 2167.72 examples/s]Applying chat template to train dataset:  43%|████▎     | 10395/24227 [00:04<00:06, 2112.75 examples/s]Applying chat template to train dataset:  46%|████▋     | 11240/24227 [00:05<00:05, 2219.65 examples/s]Applying chat template to train dataset:  45%|████▌     | 11021/24227 [00:04<00:05, 2323.44 examples/s]Applying chat template to train dataset:  44%|████▍     | 10642/24227 [00:05<00:06, 2190.19 examples/s]Applying chat template to train dataset:  48%|████▊     | 11561/24227 [00:05<00:07, 1736.70 examples/s]Applying chat template to train dataset:  47%|████▋     | 11345/24227 [00:05<00:07, 1691.73 examples/s]Applying chat template to train dataset:  45%|████▌     | 10946/24227 [00:05<00:08, 1557.34 examples/s]Applying chat template to train dataset:  49%|████▉     | 11880/24227 [00:05<00:07, 1646.73 examples/s]Applying chat template to train dataset:  48%|████▊     | 11668/24227 [00:05<00:07, 1625.34 examples/s]Applying chat template to train dataset:  46%|████▋     | 11251/24227 [00:05<00:08, 1536.22 examples/s]Applying chat template to train dataset:  50%|█████     | 12137/24227 [00:05<00:06, 1815.21 examples/s]Applying chat template to train dataset:  50%|████▉     | 11994/24227 [00:05<00:07, 1617.41 examples/s]Applying chat template to train dataset:  48%|████▊     | 11555/24227 [00:05<00:08, 1451.56 examples/s]Applying chat template to train dataset:  51%|█████▏    | 12463/24227 [00:05<00:07, 1676.54 examples/s]Applying chat template to train dataset:  50%|█████     | 12220/24227 [00:05<00:06, 1729.95 examples/s]Applying chat template to train dataset:  49%|████▊     | 11808/24227 [00:05<00:07, 1634.96 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12740/24227 [00:05<00:06, 1882.85 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12485/24227 [00:05<00:06, 1912.86 examples/s]Applying chat template to train dataset:  50%|████▉     | 12072/24227 [00:06<00:06, 1830.83 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13053/24227 [00:06<00:05, 2145.55 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12819/24227 [00:06<00:08, 1366.32 examples/s]Applying chat template to train dataset:  51%|█████     | 12390/24227 [00:06<00:08, 1370.30 examples/s]Applying chat template to train dataset:  55%|█████▌    | 13383/24227 [00:06<00:07, 1541.75 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13070/24227 [00:06<00:07, 1551.51 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12710/24227 [00:06<00:07, 1458.08 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13710/24227 [00:06<00:06, 1598.28 examples/s]Applying chat template to train dataset:  55%|█████▌    | 13382/24227 [00:06<00:05, 1847.12 examples/s]Applying chat template to train dataset:  54%|█████▎    | 13008/24227 [00:06<00:06, 1719.39 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14025/24227 [00:06<00:05, 1874.10 examples/s]Applying chat template to train dataset:  56%|█████▋    | 13680/24227 [00:06<00:05, 2084.33 examples/s]Applying chat template to train dataset:  55%|█████▍    | 13285/24227 [00:06<00:05, 1926.59 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14353/24227 [00:06<00:05, 1936.87 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14011/24227 [00:06<00:05, 2037.94 examples/s]Applying chat template to train dataset:  60%|██████    | 14627/24227 [00:06<00:04, 2101.42 examples/s]Applying chat template to train dataset:  56%|█████▌    | 13596/24227 [00:06<00:05, 1908.80 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14286/24227 [00:06<00:04, 2195.28 examples/s]Applying chat template to train dataset:  62%|██████▏   | 14950/24227 [00:07<00:04, 2011.01 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13911/24227 [00:07<00:05, 1860.24 examples/s]Applying chat template to train dataset:  60%|██████    | 14620/24227 [00:06<00:04, 2099.44 examples/s]Applying chat template to train dataset:  59%|█████▊    | 14213/24227 [00:07<00:04, 2099.78 examples/s]Applying chat template to train dataset:  62%|██████▏   | 14932/24227 [00:07<00:03, 2328.50 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15330/24227 [00:07<00:04, 2162.51 examples/s]Applying chat template to train dataset:  60%|█████▉    | 14504/24227 [00:07<00:04, 2284.46 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15640/24227 [00:07<00:03, 2363.69 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15280/24227 [00:07<00:03, 2280.88 examples/s]Applying chat template to train dataset:  61%|██████▏   | 14893/24227 [00:07<00:03, 2381.63 examples/s]Applying chat template to train dataset:  66%|██████▌   | 16031/24227 [00:07<00:03, 2437.78 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15677/24227 [00:07<00:03, 2393.23 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16405/24227 [00:07<00:03, 2453.27 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15279/24227 [00:07<00:04, 2158.21 examples/s]Applying chat template to train dataset:  66%|██████▌   | 16041/24227 [00:07<00:03, 2400.68 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16730/24227 [00:07<00:03, 2325.99 examples/s]Applying chat template to train dataset:  64%|██████▍   | 15616/24227 [00:07<00:03, 2180.25 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16381/24227 [00:07<00:03, 2358.06 examples/s]Applying chat template to train dataset:  70%|███████   | 17057/24227 [00:08<00:03, 2188.12 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15928/24227 [00:08<00:04, 1947.78 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16710/24227 [00:07<00:03, 2045.16 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17337/24227 [00:08<00:02, 2318.91 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16219/24227 [00:08<00:03, 2139.30 examples/s]Applying chat template to train dataset:  70%|███████   | 17022/24227 [00:07<00:03, 2263.31 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17633/24227 [00:08<00:02, 2468.18 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16504/24227 [00:08<00:03, 2295.86 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17329/24227 [00:08<00:02, 2443.19 examples/s]Applying chat template to train dataset:  74%|███████▍  | 17963/24227 [00:08<00:03, 2068.74 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16819/24227 [00:08<00:03, 2086.46 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17661/24227 [00:08<00:02, 2243.91 examples/s]Applying chat template to train dataset:  75%|███████▌  | 18203/24227 [00:08<00:02, 2137.93 examples/s]Applying chat template to train dataset:  70%|███████   | 17064/24227 [00:08<00:03, 2165.63 examples/s]Applying chat template to train dataset:  74%|███████▍  | 17912/24227 [00:08<00:02, 2303.52 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18441/24227 [00:08<00:02, 2193.70 examples/s]Applying chat template to train dataset:  71%|███████▏  | 17310/24227 [00:08<00:03, 2230.41 examples/s]Applying chat template to train dataset:  75%|███████▌  | 18279/24227 [00:08<00:02, 2348.38 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18734/24227 [00:08<00:02, 2376.58 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17657/24227 [00:08<00:02, 2256.89 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18610/24227 [00:08<00:02, 2121.08 examples/s]Applying chat template to train dataset:  79%|███████▊  | 19060/24227 [00:08<00:02, 2268.39 examples/s]Applying chat template to train dataset:  74%|███████▍  | 17952/24227 [00:08<00:02, 2424.76 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18963/24227 [00:08<00:02, 2188.31 examples/s]Applying chat template to train dataset:  80%|████████  | 19390/24227 [00:09<00:02, 1658.27 examples/s]Applying chat template to train dataset:  75%|███████▌  | 18268/24227 [00:09<00:04, 1487.37 examples/s]Applying chat template to train dataset:  81%|████████  | 19638/24227 [00:09<00:02, 1812.83 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19297/24227 [00:09<00:02, 1791.13 examples/s]Applying chat template to train dataset:  76%|███████▋  | 18517/24227 [00:09<00:03, 1661.47 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19926/24227 [00:09<00:02, 2038.15 examples/s]Applying chat template to train dataset:  81%|████████  | 19571/24227 [00:09<00:02, 1966.88 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18835/24227 [00:09<00:03, 1565.54 examples/s]Applying chat template to train dataset:  84%|████████▎ | 20266/24227 [00:09<00:02, 1833.90 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19912/24227 [00:09<00:02, 1797.47 examples/s]Applying chat template to train dataset:  79%|███████▊  | 19053/24227 [00:09<00:03, 1678.51 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20514/24227 [00:09<00:01, 1965.16 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20130/24227 [00:09<00:02, 1869.34 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19371/24227 [00:09<00:03, 1509.01 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20854/24227 [00:09<00:01, 1710.93 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20474/24227 [00:09<00:02, 1669.10 examples/s]Applying chat template to train dataset:  81%|████████  | 19664/24227 [00:10<00:02, 1769.71 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21160/24227 [00:10<00:01, 1971.82 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20734/24227 [00:09<00:01, 1843.95 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19987/24227 [00:10<00:02, 1772.52 examples/s]Applying chat template to train dataset:  89%|████████▊ | 21500/24227 [00:10<00:01, 1937.16 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21076/24227 [00:10<00:01, 1825.17 examples/s]Applying chat template to train dataset:  84%|████████▎ | 20286/24227 [00:10<00:01, 2019.05 examples/s]Applying chat template to train dataset:  90%|█████████ | 21817/24227 [00:10<00:01, 2193.86 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21402/24227 [00:10<00:01, 2114.97 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20562/24227 [00:10<00:01, 2182.02 examples/s]Applying chat template to train dataset:  91%|█████████▏| 22158/24227 [00:10<00:00, 2178.28 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21745/24227 [00:10<00:01, 2140.74 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22397/24227 [00:10<00:00, 2224.90 examples/s]Applying chat template to train dataset:  91%|█████████ | 22005/24227 [00:10<00:00, 2241.42 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20886/24227 [00:10<00:01, 2043.77 examples/s]Applying chat template to train dataset:  94%|█████████▎| 22674/24227 [00:10<00:00, 2356.02 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22307/24227 [00:10<00:00, 2425.79 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21171/24227 [00:10<00:01, 2223.47 examples/s]Applying chat template to train dataset:  95%|█████████▍| 23015/24227 [00:10<00:00, 2314.02 examples/s]Applying chat template to train dataset:  94%|█████████▎| 22664/24227 [00:10<00:00, 2408.42 examples/s]Applying chat template to train dataset:  89%|████████▉ | 21509/24227 [00:10<00:01, 2232.40 examples/s]Applying chat template to train dataset:  96%|█████████▋| 23379/24227 [00:11<00:00, 2349.53 examples/s]Applying chat template to train dataset:  95%|█████████▌| 23046/24227 [00:10<00:00, 2450.70 examples/s]Applying chat template to train dataset:  90%|█████████ | 21843/24227 [00:10<00:01, 2228.36 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23720/24227 [00:11<00:00, 1717.21 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23390/24227 [00:11<00:00, 1759.77 examples/s]Applying chat template to train dataset:  91%|█████████▏| 22166/24227 [00:11<00:01, 1626.89 examples/s]Applying chat template to train dataset:  99%|█████████▉| 24043/24227 [00:11<00:00, 1993.03 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23718/24227 [00:11<00:00, 2035.19 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22471/24227 [00:11<00:00, 1881.60 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:11<00:00, 2105.03 examples/s]
Applying chat template to train dataset:  99%|█████████▉| 24035/24227 [00:11<00:00, 2267.95 examples/s]Applying chat template to train dataset:  94%|█████████▍| 22730/24227 [00:11<00:00, 2024.40 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:11<00:00, 2118.15 examples/s]
Applying chat template to train dataset:  95%|█████████▌| 23053/24227 [00:11<00:00, 2024.83 examples/s]Applying chat template to train dataset:  96%|█████████▋| 23377/24227 [00:11<00:00, 2018.36 examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:  98%|█████████▊| 23671/24227 [00:11<00:00, 2216.76 examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 404.64 examples/s]Applying chat template to train dataset:  99%|█████████▉| 23983/24227 [00:12<00:00, 2051.32 examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 408.94 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:12<00:00, 1979.54 examples/s]
Tokenizing train dataset:   0%|          | 90/24227 [00:00<01:12, 331.19 examples/s]Tokenizing train dataset:   0%|          | 87/24227 [00:00<01:14, 324.75 examples/s]Tokenizing train dataset:   1%|          | 138/24227 [00:00<01:37, 247.28 examples/s]Tokenizing train dataset:   1%|          | 133/24227 [00:00<01:40, 239.26 examples/s]Tokenizing train dataset:   1%|          | 179/24227 [00:00<01:35, 251.86 examples/s]Tokenizing train dataset:   1%|          | 163/24227 [00:00<01:35, 251.49 examples/s]Tokenizing train dataset:   1%|          | 206/24227 [00:00<01:33, 255.76 examples/s]Tokenizing train dataset:   1%|          | 239/24227 [00:00<01:28, 271.81 examples/s]Tokenizing train dataset:   1%|          | 194/24227 [00:00<01:55, 208.86 examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 277/24227 [00:01<01:31, 262.81 examples/s]Tokenizing train dataset:   1%|          | 231/24227 [00:00<01:49, 219.24 examples/s]Tokenizing train dataset:   0%|          | 40/24227 [00:00<01:03, 380.78 examples/s]Tokenizing train dataset:   1%|▏         | 309/24227 [00:01<01:27, 273.80 examples/s]Tokenizing train dataset:   1%|          | 263/24227 [00:01<01:40, 239.11 examples/s]Tokenizing train dataset:   0%|          | 83/24227 [00:00<01:18, 309.27 examples/s]Tokenizing train dataset:   1%|▏         | 341/24227 [00:01<01:41, 236.47 examples/s]Tokenizing train dataset:   1%|          | 299/24227 [00:01<01:47, 223.07 examples/s]Tokenizing train dataset:   0%|          | 119/24227 [00:00<01:29, 270.27 examples/s]Tokenizing train dataset:   2%|▏         | 370/24227 [00:01<01:37, 245.90 examples/s]Tokenizing train dataset:   1%|▏         | 331/24227 [00:01<01:39, 240.30 examples/s]Tokenizing train dataset:   1%|          | 148/24227 [00:00<01:29, 270.24 examples/s]Tokenizing train dataset:   2%|▏         | 406/24227 [00:01<01:39, 240.29 examples/s]Tokenizing train dataset:   2%|▏         | 368/24227 [00:01<01:40, 238.21 examples/s]Tokenizing train dataset:   1%|          | 186/24227 [00:00<01:32, 258.89 examples/s]Tokenizing train dataset:   2%|▏         | 437/24227 [00:01<01:33, 254.43 examples/s]Tokenizing train dataset:   1%|          | 216/24227 [00:00<01:30, 265.44 examples/s]Tokenizing train dataset:   2%|▏         | 405/24227 [00:01<01:41, 235.85 examples/s]Tokenizing train dataset:   1%|          | 247/24227 [00:00<01:27, 273.46 examples/s]Tokenizing train dataset:   2%|▏         | 476/24227 [00:01<01:35, 249.45 examples/s]Tokenizing train dataset:   2%|▏         | 439/24227 [00:01<01:43, 230.06 examples/s]Tokenizing train dataset:   1%|          | 278/24227 [00:01<01:25, 278.60 examples/s]Tokenizing train dataset:   2%|▏         | 506/24227 [00:02<01:44, 226.45 examples/s]Tokenizing train dataset:   2%|▏         | 463/24227 [00:01<01:43, 229.48 examples/s]Tokenizing train dataset:   1%|▏         | 314/24227 [00:01<01:32, 258.88 examples/s]Tokenizing train dataset:   2%|▏         | 542/24227 [00:02<01:43, 228.20 examples/s]Tokenizing train dataset:   2%|▏         | 495/24227 [00:02<01:46, 223.11 examples/s]Tokenizing train dataset:   2%|▏         | 566/24227 [00:02<01:44, 226.11 examples/s]Tokenizing train dataset:   1%|▏         | 345/24227 [00:01<01:48, 220.19 examples/s]Tokenizing train dataset:   2%|▏         | 535/24227 [00:02<01:41, 234.17 examples/s]Tokenizing train dataset:   2%|▏         | 596/24227 [00:02<01:38, 238.94 examples/s]Tokenizing train dataset:   2%|▏         | 375/24227 [00:01<01:41, 234.82 examples/s]Tokenizing train dataset:   2%|▏         | 566/24227 [00:02<01:35, 248.73 examples/s]Tokenizing train dataset:   3%|▎         | 630/24227 [00:02<01:30, 261.99 examples/s]Tokenizing train dataset:   2%|▏         | 402/24227 [00:01<01:38, 241.71 examples/s]Tokenizing train dataset:   2%|▏         | 597/24227 [00:02<01:41, 232.87 examples/s]Tokenizing train dataset:   3%|▎         | 659/24227 [00:02<01:28, 265.31 examples/s]Tokenizing train dataset:   2%|▏         | 434/24227 [00:01<01:59, 198.42 examples/s]Tokenizing train dataset:   3%|▎         | 689/24227 [00:02<01:53, 207.23 examples/s]Tokenizing train dataset:   3%|▎         | 637/24227 [00:02<01:53, 208.12 examples/s]Tokenizing train dataset:   2%|▏         | 462/24227 [00:01<02:15, 175.47 examples/s]Tokenizing train dataset:   3%|▎         | 732/24227 [00:02<01:42, 228.68 examples/s]Tokenizing train dataset:   3%|▎         | 671/24227 [00:02<01:52, 210.27 examples/s]Tokenizing train dataset:   2%|▏         | 485/24227 [00:02<02:08, 184.61 examples/s]Tokenizing train dataset:   3%|▎         | 771/24227 [00:03<01:39, 236.21 examples/s]Tokenizing train dataset:   3%|▎         | 699/24227 [00:03<01:57, 200.43 examples/s]Tokenizing train dataset:   2%|▏         | 517/24227 [00:02<02:04, 190.48 examples/s]Tokenizing train dataset:   3%|▎         | 736/24227 [00:03<01:40, 234.44 examples/s]Tokenizing train dataset:   3%|▎         | 811/24227 [00:03<01:36, 243.59 examples/s]Tokenizing train dataset:   2%|▏         | 548/24227 [00:02<01:49, 216.13 examples/s]Tokenizing train dataset:   3%|▎         | 769/24227 [00:03<02:00, 194.30 examples/s]Tokenizing train dataset:   3%|▎         | 842/24227 [00:03<01:55, 201.97 examples/s]Tokenizing train dataset:   2%|▏         | 578/24227 [00:02<02:05, 188.99 examples/s]Tokenizing train dataset:   3%|▎         | 798/24227 [00:03<02:08, 181.90 examples/s]Tokenizing train dataset:   4%|▎         | 875/24227 [00:03<01:59, 195.72 examples/s]Tokenizing train dataset:   2%|▏         | 605/24227 [00:02<02:23, 165.10 examples/s]Tokenizing train dataset:   3%|▎         | 826/24227 [00:03<01:58, 197.51 examples/s]Tokenizing train dataset:   4%|▎         | 906/24227 [00:03<01:47, 216.54 examples/s]Tokenizing train dataset:   3%|▎         | 637/24227 [00:02<02:02, 193.35 examples/s]Tokenizing train dataset:   4%|▎         | 860/24227 [00:03<02:00, 194.06 examples/s]Tokenizing train dataset:   4%|▍         | 936/24227 [00:04<02:29, 155.39 examples/s]Tokenizing train dataset:   3%|▎         | 666/24227 [00:03<03:04, 127.76 examples/s]Tokenizing train dataset:   4%|▎         | 899/24227 [00:04<02:21, 164.99 examples/s]Tokenizing train dataset:   4%|▍         | 970/24227 [00:04<02:21, 164.23 examples/s]Tokenizing train dataset:   3%|▎         | 690/24227 [00:03<02:42, 144.82 examples/s]Tokenizing train dataset:   4%|▍         | 930/24227 [00:04<02:19, 167.54 examples/s]Tokenizing train dataset:   3%|▎         | 711/24227 [00:03<02:30, 155.84 examples/s]Tokenizing train dataset:   4%|▍         | 1001/24227 [00:04<02:13, 174.42 examples/s]Tokenizing train dataset:   4%|▍         | 962/24227 [00:04<02:31, 153.51 examples/s]Tokenizing train dataset:   3%|▎         | 733/24227 [00:03<03:01, 129.74 examples/s]Tokenizing train dataset:   4%|▍         | 1030/24227 [00:04<02:44, 140.68 examples/s]Tokenizing train dataset:   3%|▎         | 750/24227 [00:03<02:57, 131.91 examples/s]Tokenizing train dataset:   4%|▍         | 991/24227 [00:04<02:26, 158.38 examples/s]Tokenizing train dataset:   4%|▍         | 1061/24227 [00:04<02:18, 166.86 examples/s]Tokenizing train dataset:   3%|▎         | 766/24227 [00:03<02:50, 137.21 examples/s]Tokenizing train dataset:   4%|▍         | 1017/24227 [00:04<02:12, 175.07 examples/s]Tokenizing train dataset:   5%|▍         | 1098/24227 [00:05<02:11, 175.41 examples/s]Tokenizing train dataset:   4%|▍         | 1043/24227 [00:04<02:02, 189.80 examples/s]Tokenizing train dataset:   3%|▎         | 793/24227 [00:04<02:37, 149.01 examples/s]Tokenizing train dataset:   5%|▍         | 1127/24227 [00:05<02:12, 173.96 examples/s]Tokenizing train dataset:   3%|▎         | 821/24227 [00:04<02:33, 152.31 examples/s]Tokenizing train dataset:   4%|▍         | 1080/24227 [00:05<01:59, 192.93 examples/s]Tokenizing train dataset:   5%|▍         | 1155/24227 [00:05<01:59, 192.38 examples/s]Tokenizing train dataset:   3%|▎         | 843/24227 [00:04<02:20, 165.85 examples/s]Tokenizing train dataset:   5%|▍         | 1105/24227 [00:05<01:53, 203.51 examples/s]Tokenizing train dataset:   5%|▍         | 1181/24227 [00:05<01:51, 206.07 examples/s]Tokenizing train dataset:   4%|▎         | 869/24227 [00:04<02:06, 185.35 examples/s]Tokenizing train dataset:   5%|▍         | 1133/24227 [00:05<01:58, 195.10 examples/s]Tokenizing train dataset:   5%|▌         | 1214/24227 [00:05<02:10, 176.93 examples/s]Tokenizing train dataset:   4%|▎         | 890/24227 [00:04<02:44, 141.45 examples/s]Tokenizing train dataset:   5%|▍         | 1164/24227 [00:05<02:22, 162.41 examples/s]Tokenizing train dataset:   5%|▌         | 1245/24227 [00:05<01:53, 202.47 examples/s]Tokenizing train dataset:   4%|▍         | 914/24227 [00:04<02:25, 159.91 examples/s]Tokenizing train dataset:   5%|▍         | 1200/24227 [00:05<02:25, 158.77 examples/s]Tokenizing train dataset:   5%|▌         | 1274/24227 [00:06<02:17, 167.39 examples/s]Tokenizing train dataset:   4%|▍         | 942/24227 [00:05<02:49, 137.30 examples/s]Tokenizing train dataset:   5%|▌         | 1298/24227 [00:06<02:08, 178.92 examples/s]Tokenizing train dataset:   5%|▌         | 1232/24227 [00:06<02:14, 170.76 examples/s]Tokenizing train dataset:   4%|▍         | 971/24227 [00:05<02:21, 164.78 examples/s]Tokenizing train dataset:   5%|▌         | 1320/24227 [00:06<02:03, 185.42 examples/s]Tokenizing train dataset:   5%|▌         | 1265/24227 [00:06<01:56, 197.75 examples/s]Tokenizing train dataset:   4%|▍         | 1003/24227 [00:05<02:12, 175.50 examples/s]Tokenizing train dataset:   6%|▌         | 1346/24227 [00:06<01:53, 200.80 examples/s]Tokenizing train dataset:   5%|▌         | 1291/24227 [00:06<01:49, 209.16 examples/s]Tokenizing train dataset:   4%|▍         | 1025/24227 [00:05<02:07, 182.53 examples/s]Tokenizing train dataset:   6%|▌         | 1381/24227 [00:06<01:49, 208.86 examples/s]Tokenizing train dataset:   5%|▌         | 1327/24227 [00:06<01:54, 200.70 examples/s]Tokenizing train dataset:   4%|▍         | 1056/24227 [00:05<02:04, 185.91 examples/s]Tokenizing train dataset:   6%|▌         | 1407/24227 [00:06<01:43, 219.70 examples/s]Tokenizing train dataset:   6%|▌         | 1357/24227 [00:06<02:00, 189.89 examples/s]Tokenizing train dataset:   4%|▍         | 1090/24227 [00:05<02:00, 192.55 examples/s]Tokenizing train dataset:   6%|▌         | 1438/24227 [00:06<01:54, 198.78 examples/s]Tokenizing train dataset:   6%|▌         | 1460/24227 [00:06<01:53, 200.78 examples/s]Tokenizing train dataset:   6%|▌         | 1390/24227 [00:06<01:57, 194.61 examples/s]Tokenizing train dataset:   5%|▍         | 1120/24227 [00:05<02:00, 191.46 examples/s]Tokenizing train dataset:   6%|▌         | 1486/24227 [00:06<01:47, 212.17 examples/s]Tokenizing train dataset:   6%|▌         | 1422/24227 [00:07<02:13, 170.97 examples/s]Tokenizing train dataset:   5%|▍         | 1149/24227 [00:06<02:31, 152.56 examples/s]Tokenizing train dataset:   6%|▋         | 1515/24227 [00:07<02:05, 181.14 examples/s]Tokenizing train dataset:   6%|▌         | 1454/24227 [00:07<02:08, 177.66 examples/s]Tokenizing train dataset:   5%|▍         | 1178/24227 [00:06<02:26, 156.81 examples/s]Tokenizing train dataset:   6%|▋         | 1536/24227 [00:07<02:30, 150.62 examples/s]Tokenizing train dataset:   5%|▍         | 1201/24227 [00:06<02:16, 169.29 examples/s]Tokenizing train dataset:   6%|▌         | 1484/24227 [00:07<02:14, 169.69 examples/s]Tokenizing train dataset:   6%|▋         | 1563/24227 [00:07<02:10, 174.08 examples/s]Tokenizing train dataset:   5%|▌         | 1231/24227 [00:06<02:45, 139.24 examples/s]Tokenizing train dataset:   6%|▌         | 1513/24227 [00:07<02:47, 135.37 examples/s]Tokenizing train dataset:   7%|▋         | 1591/24227 [00:07<02:50, 132.52 examples/s]Tokenizing train dataset:   5%|▌         | 1250/24227 [00:06<02:53, 132.64 examples/s]Tokenizing train dataset:   6%|▋         | 1533/24227 [00:07<02:49, 133.90 examples/s]Tokenizing train dataset:   7%|▋         | 1610/24227 [00:08<02:58, 126.59 examples/s]Tokenizing train dataset:   5%|▌         | 1269/24227 [00:07<02:57, 129.66 examples/s]Tokenizing train dataset:   6%|▋         | 1549/24227 [00:08<02:49, 133.69 examples/s]Tokenizing train dataset:   7%|▋         | 1627/24227 [00:08<02:58, 126.83 examples/s]Tokenizing train dataset:   5%|▌         | 1284/24227 [00:07<03:37, 105.43 examples/s]Tokenizing train dataset:   7%|▋         | 1646/24227 [00:08<03:21, 111.85 examples/s]Tokenizing train dataset:   6%|▋         | 1566/24227 [00:08<03:33, 106.11 examples/s]Tokenizing train dataset:   5%|▌         | 1312/24227 [00:07<02:48, 135.78 examples/s]Tokenizing train dataset:   7%|▋         | 1661/24227 [00:08<03:24, 110.55 examples/s]Tokenizing train dataset:   7%|▋         | 1580/24227 [00:08<03:38, 103.53 examples/s]Tokenizing train dataset:   5%|▌         | 1332/24227 [00:07<02:35, 147.70 examples/s]Tokenizing train dataset:   7%|▋         | 1685/24227 [00:08<02:46, 135.45 examples/s]Tokenizing train dataset:   7%|▋         | 1601/24227 [00:08<03:05, 121.76 examples/s]Tokenizing train dataset:   6%|▌         | 1361/24227 [00:07<02:25, 157.23 examples/s]Tokenizing train dataset:   7%|▋         | 1714/24227 [00:08<02:14, 167.54 examples/s]Tokenizing train dataset:   7%|▋         | 1630/24227 [00:08<02:26, 154.45 examples/s]Tokenizing train dataset:   7%|▋         | 1650/24227 [00:08<02:34, 146.06 examples/s]Tokenizing train dataset:   6%|▌         | 1390/24227 [00:07<02:32, 149.78 examples/s]Tokenizing train dataset:   7%|▋         | 1751/24227 [00:08<02:11, 170.52 examples/s]Tokenizing train dataset:   7%|▋         | 1678/24227 [00:08<02:08, 174.87 examples/s]Tokenizing train dataset:   6%|▌         | 1407/24227 [00:08<02:36, 145.51 examples/s]Tokenizing train dataset:   7%|▋         | 1770/24227 [00:09<02:40, 140.12 examples/s]Tokenizing train dataset:   7%|▋         | 1701/24227 [00:09<02:38, 142.07 examples/s]Tokenizing train dataset:   6%|▌         | 1423/24227 [00:08<03:06, 122.34 examples/s]Tokenizing train dataset:   7%|▋         | 1790/24227 [00:09<02:37, 142.36 examples/s]Tokenizing train dataset:   7%|▋         | 1723/24227 [00:09<02:23, 156.58 examples/s]Tokenizing train dataset:   6%|▌         | 1438/24227 [00:08<02:58, 127.51 examples/s]Tokenizing train dataset:   7%|▋         | 1815/24227 [00:09<02:18, 162.34 examples/s]Tokenizing train dataset:   7%|▋         | 1751/24227 [00:09<02:03, 181.88 examples/s]Tokenizing train dataset:   6%|▌         | 1461/24227 [00:08<02:33, 148.06 examples/s]Tokenizing train dataset:   8%|▊         | 1837/24227 [00:09<02:09, 173.48 examples/s]Tokenizing train dataset:   7%|▋         | 1786/24227 [00:09<01:41, 220.30 examples/s]Tokenizing train dataset:   6%|▌         | 1479/24227 [00:08<02:29, 151.84 examples/s]Tokenizing train dataset:   8%|▊         | 1865/24227 [00:09<01:52, 198.65 examples/s]Tokenizing train dataset:   7%|▋         | 1815/24227 [00:09<01:49, 205.49 examples/s]Tokenizing train dataset:   6%|▌         | 1508/24227 [00:08<02:19, 162.85 examples/s]Tokenizing train dataset:   8%|▊         | 1898/24227 [00:09<01:49, 204.80 examples/s]Tokenizing train dataset:   8%|▊         | 1840/24227 [00:09<01:44, 213.67 examples/s]Tokenizing train dataset:   6%|▋         | 1530/24227 [00:08<02:09, 175.71 examples/s]Tokenizing train dataset:   8%|▊         | 1920/24227 [00:09<01:47, 207.42 examples/s]Tokenizing train dataset:   8%|▊         | 1863/24227 [00:09<01:44, 213.82 examples/s]Tokenizing train dataset:   6%|▋         | 1550/24227 [00:08<02:06, 178.68 examples/s]Tokenizing train dataset:   8%|▊         | 1944/24227 [00:09<01:44, 212.35 examples/s]Tokenizing train dataset:   8%|▊         | 1890/24227 [00:10<02:00, 186.13 examples/s]Tokenizing train dataset:   8%|▊         | 1913/24227 [00:10<01:55, 192.88 examples/s]Tokenizing train dataset:   7%|▋         | 1581/24227 [00:09<02:36, 144.29 examples/s]Tokenizing train dataset:   8%|▊         | 1972/24227 [00:10<02:19, 159.98 examples/s]Tokenizing train dataset:   8%|▊         | 1941/24227 [00:10<01:59, 186.47 examples/s]Tokenizing train dataset:   7%|▋         | 1612/24227 [00:09<02:24, 156.92 examples/s]Tokenizing train dataset:   8%|▊         | 2005/24227 [00:10<02:08, 172.61 examples/s]Tokenizing train dataset:   8%|▊         | 1971/24227 [00:10<02:00, 184.10 examples/s]Tokenizing train dataset:   7%|▋         | 1630/24227 [00:09<02:44, 137.43 examples/s]Tokenizing train dataset:   8%|▊         | 2025/24227 [00:10<02:26, 151.20 examples/s]Tokenizing train dataset:   8%|▊         | 1999/24227 [00:10<01:49, 202.67 examples/s]Tokenizing train dataset:   7%|▋         | 1657/24227 [00:09<02:18, 163.22 examples/s]Tokenizing train dataset:   8%|▊         | 2051/24227 [00:10<02:09, 171.79 examples/s]Tokenizing train dataset:   8%|▊         | 2024/24227 [00:10<01:44, 212.73 examples/s]Tokenizing train dataset:   7%|▋         | 1684/24227 [00:09<02:01, 185.78 examples/s]Tokenizing train dataset:   9%|▊         | 2081/24227 [00:10<01:51, 199.16 examples/s]Tokenizing train dataset:   8%|▊         | 2054/24227 [00:10<01:34, 234.56 examples/s]Tokenizing train dataset:   9%|▊         | 2115/24227 [00:10<01:47, 205.43 examples/s]Tokenizing train dataset:   7%|▋         | 1719/24227 [00:09<01:55, 195.71 examples/s]Tokenizing train dataset:   9%|▊         | 2087/24227 [00:10<01:26, 256.61 examples/s]Tokenizing train dataset:   9%|▉         | 2144/24227 [00:11<01:38, 224.01 examples/s]Tokenizing train dataset:   7%|▋         | 1747/24227 [00:10<01:45, 212.86 examples/s]Tokenizing train dataset:   9%|▊         | 2118/24227 [00:10<01:22, 269.25 examples/s]Tokenizing train dataset:   7%|▋         | 1772/24227 [00:10<01:41, 221.29 examples/s]Tokenizing train dataset:   9%|▉         | 2168/24227 [00:11<01:38, 224.81 examples/s]Tokenizing train dataset:   7%|▋         | 1800/24227 [00:10<01:36, 231.88 examples/s]Tokenizing train dataset:   9%|▉         | 2195/24227 [00:11<01:35, 231.65 examples/s]Tokenizing train dataset:   9%|▉         | 2150/24227 [00:11<01:40, 220.65 examples/s]Tokenizing train dataset:   8%|▊         | 1827/24227 [00:10<01:49, 205.12 examples/s]Tokenizing train dataset:   9%|▉         | 2226/24227 [00:11<01:42, 214.56 examples/s]Tokenizing train dataset:   9%|▉         | 2181/24227 [00:11<01:44, 211.33 examples/s]Tokenizing train dataset:   8%|▊         | 1856/24227 [00:10<02:09, 172.98 examples/s]Tokenizing train dataset:   9%|▉         | 2263/24227 [00:11<02:01, 180.62 examples/s]Tokenizing train dataset:   9%|▉         | 2209/24227 [00:11<02:25, 151.84 examples/s]Tokenizing train dataset:   8%|▊         | 1876/24227 [00:10<02:06, 177.09 examples/s]Tokenizing train dataset:   9%|▉         | 2238/24227 [00:11<02:06, 174.37 examples/s]Tokenizing train dataset:   9%|▉         | 2293/24227 [00:11<02:04, 175.83 examples/s]Tokenizing train dataset:   8%|▊         | 1906/24227 [00:10<02:03, 180.45 examples/s]Tokenizing train dataset:   9%|▉         | 2263/24227 [00:11<01:57, 187.57 examples/s]Tokenizing train dataset:  10%|▉         | 2320/24227 [00:11<01:54, 191.92 examples/s]Tokenizing train dataset:   8%|▊         | 1929/24227 [00:11<01:58, 187.75 examples/s]Tokenizing train dataset:   9%|▉         | 2290/24227 [00:11<01:47, 203.37 examples/s]Tokenizing train dataset:  10%|▉         | 2349/24227 [00:12<02:29, 146.70 examples/s]Tokenizing train dataset:   8%|▊         | 1958/24227 [00:11<02:39, 139.80 examples/s]Tokenizing train dataset:  10%|▉         | 2323/24227 [00:12<02:13, 163.59 examples/s]Tokenizing train dataset:  10%|▉         | 2370/24227 [00:12<02:19, 156.96 examples/s]Tokenizing train dataset:   8%|▊         | 1984/24227 [00:11<02:18, 160.42 examples/s]Tokenizing train dataset:  10%|▉         | 2347/24227 [00:12<02:03, 177.54 examples/s]Tokenizing train dataset:  10%|▉         | 2401/24227 [00:12<02:40, 135.59 examples/s]Tokenizing train dataset:   8%|▊         | 2016/24227 [00:11<02:29, 149.06 examples/s]Tokenizing train dataset:  10%|▉         | 2380/24227 [00:12<02:19, 157.07 examples/s]Tokenizing train dataset:  10%|█         | 2428/24227 [00:12<02:18, 156.97 examples/s]Tokenizing train dataset:   8%|▊         | 2041/24227 [00:11<02:12, 166.87 examples/s]Tokenizing train dataset:  10%|▉         | 2406/24227 [00:12<02:05, 174.55 examples/s]Tokenizing train dataset:  10%|█         | 2452/24227 [00:12<02:05, 172.86 examples/s]Tokenizing train dataset:   9%|▊         | 2075/24227 [00:11<01:50, 200.78 examples/s]Tokenizing train dataset:  10%|█         | 2432/24227 [00:12<01:54, 191.00 examples/s]Tokenizing train dataset:  10%|█         | 2485/24227 [00:12<01:46, 205.10 examples/s]Tokenizing train dataset:   9%|▊         | 2109/24227 [00:12<02:06, 174.62 examples/s]Tokenizing train dataset:  10%|█         | 2462/24227 [00:13<02:14, 161.95 examples/s]Tokenizing train dataset:   9%|▉         | 2131/24227 [00:12<02:01, 182.16 examples/s]Tokenizing train dataset:  10%|█         | 2512/24227 [00:13<02:20, 154.83 examples/s]Tokenizing train dataset:  10%|█         | 2497/24227 [00:13<02:11, 165.63 examples/s]Tokenizing train dataset:   9%|▉         | 2160/24227 [00:12<02:04, 177.23 examples/s]Tokenizing train dataset:  10%|█         | 2540/24227 [00:13<02:22, 152.29 examples/s]Tokenizing train dataset:  10%|█         | 2516/24227 [00:13<02:08, 169.10 examples/s]Tokenizing train dataset:  11%|█         | 2569/24227 [00:13<02:02, 177.22 examples/s]Tokenizing train dataset:  10%|█         | 2536/24227 [00:13<02:04, 173.59 examples/s]Tokenizing train dataset:   9%|▉         | 2190/24227 [00:12<02:00, 182.86 examples/s]Tokenizing train dataset:  11%|█         | 2602/24227 [00:13<01:43, 208.80 examples/s]Tokenizing train dataset:  11%|█         | 2570/24227 [00:13<01:43, 209.34 examples/s]Tokenizing train dataset:   9%|▉         | 2221/24227 [00:12<01:57, 187.75 examples/s]Tokenizing train dataset:   9%|▉         | 2243/24227 [00:12<01:53, 193.21 examples/s]Tokenizing train dataset:  11%|█         | 2637/24227 [00:13<01:45, 204.45 examples/s]Tokenizing train dataset:  11%|█         | 2606/24227 [00:13<01:47, 201.70 examples/s]Tokenizing train dataset:   9%|▉         | 2270/24227 [00:12<01:44, 209.72 examples/s]Tokenizing train dataset:  11%|█         | 2664/24227 [00:13<01:39, 216.61 examples/s]Tokenizing train dataset:  11%|█         | 2630/24227 [00:13<01:43, 207.93 examples/s]Tokenizing train dataset:   9%|▉         | 2298/24227 [00:13<01:52, 194.86 examples/s]Tokenizing train dataset:  11%|█         | 2702/24227 [00:14<01:44, 206.28 examples/s]Tokenizing train dataset:  11%|█         | 2664/24227 [00:14<01:52, 191.76 examples/s]Tokenizing train dataset:  11%|█▏        | 2728/24227 [00:14<01:39, 216.11 examples/s]Tokenizing train dataset:  10%|▉         | 2327/24227 [00:13<01:56, 187.60 examples/s]Tokenizing train dataset:  11%|█         | 2702/24227 [00:14<02:01, 177.15 examples/s]Tokenizing train dataset:  11%|█▏        | 2759/24227 [00:14<01:47, 199.34 examples/s]Tokenizing train dataset:  10%|▉         | 2353/24227 [00:13<02:17, 158.56 examples/s]Tokenizing train dataset:  11%|█▏        | 2730/24227 [00:14<01:49, 196.32 examples/s]Tokenizing train dataset:  12%|█▏        | 2791/24227 [00:14<01:47, 199.03 examples/s]Tokenizing train dataset:  10%|▉         | 2379/24227 [00:13<02:03, 176.63 examples/s]Tokenizing train dataset:  11%|█▏        | 2757/24227 [00:14<01:41, 210.55 examples/s]Tokenizing train dataset:  12%|█▏        | 2817/24227 [00:14<01:41, 210.88 examples/s]Tokenizing train dataset:  10%|▉         | 2409/24227 [00:13<02:07, 171.54 examples/s]Tokenizing train dataset:  12%|█▏        | 2788/24227 [00:14<01:46, 201.99 examples/s]Tokenizing train dataset:  10%|█         | 2432/24227 [00:13<01:59, 182.19 examples/s]Tokenizing train dataset:  12%|█▏        | 2812/24227 [00:14<01:42, 209.64 examples/s]Tokenizing train dataset:  12%|█▏        | 2848/24227 [00:14<01:55, 185.67 examples/s]Tokenizing train dataset:  10%|█         | 2454/24227 [00:14<01:54, 189.73 examples/s]Tokenizing train dataset:  12%|█▏        | 2838/24227 [00:14<01:37, 219.82 examples/s]Tokenizing train dataset:  12%|█▏        | 2880/24227 [00:15<01:51, 191.26 examples/s]Tokenizing train dataset:  12%|█▏        | 2907/24227 [00:15<01:43, 206.43 examples/s]Tokenizing train dataset:  10%|█         | 2489/24227 [00:14<01:53, 191.05 examples/s]Tokenizing train dataset:  12%|█▏        | 2868/24227 [00:15<01:47, 198.19 examples/s]Tokenizing train dataset:  12%|█▏        | 2933/24227 [00:15<01:38, 216.03 examples/s]Tokenizing train dataset:  10%|█         | 2517/24227 [00:14<01:55, 187.84 examples/s]Tokenizing train dataset:  12%|█▏        | 2900/24227 [00:15<01:49, 194.33 examples/s]Tokenizing train dataset:  12%|█▏        | 2966/24227 [00:15<01:51, 190.18 examples/s]Tokenizing train dataset:  11%|█         | 2549/24227 [00:14<02:01, 178.15 examples/s]Tokenizing train dataset:  12%|█▏        | 2930/24227 [00:15<01:56, 183.36 examples/s]Tokenizing train dataset:  12%|█▏        | 2994/24227 [00:15<01:41, 209.06 examples/s]Tokenizing train dataset:  11%|█         | 2577/24227 [00:14<01:50, 196.29 examples/s]Tokenizing train dataset:  12%|█▏        | 2960/24227 [00:15<01:43, 205.29 examples/s]Tokenizing train dataset:  12%|█▏        | 3025/24227 [00:15<01:32, 229.85 examples/s]Tokenizing train dataset:  11%|█         | 2610/24227 [00:14<01:35, 225.53 examples/s]Tokenizing train dataset:  12%|█▏        | 2987/24227 [00:15<01:37, 218.89 examples/s]Tokenizing train dataset:  13%|█▎        | 3054/24227 [00:15<01:49, 194.05 examples/s]Tokenizing train dataset:  11%|█         | 2643/24227 [00:14<01:44, 206.18 examples/s]Tokenizing train dataset:  12%|█▏        | 3018/24227 [00:15<01:46, 199.42 examples/s]Tokenizing train dataset:  13%|█▎        | 3077/24227 [00:15<01:45, 199.93 examples/s]Tokenizing train dataset:  11%|█         | 2672/24227 [00:15<01:36, 222.30 examples/s]Tokenizing train dataset:  13%|█▎        | 3048/24227 [00:15<01:37, 218.24 examples/s]Tokenizing train dataset:  13%|█▎        | 3108/24227 [00:16<02:08, 164.24 examples/s]Tokenizing train dataset:  11%|█         | 2708/24227 [00:15<02:04, 172.75 examples/s]Tokenizing train dataset:  13%|█▎        | 3077/24227 [00:16<02:46, 126.98 examples/s]Tokenizing train dataset:  13%|█▎        | 3138/24227 [00:16<02:23, 147.07 examples/s]Tokenizing train dataset:  11%|█▏        | 2735/24227 [00:15<02:12, 162.19 examples/s]Tokenizing train dataset:  13%|█▎        | 3104/24227 [00:16<02:21, 149.21 examples/s]Tokenizing train dataset:  13%|█▎        | 3168/24227 [00:16<02:01, 173.22 examples/s]Tokenizing train dataset:  11%|█▏        | 2762/24227 [00:15<01:58, 180.42 examples/s]Tokenizing train dataset:  13%|█▎        | 3135/24227 [00:16<02:14, 157.34 examples/s]Tokenizing train dataset:  13%|█▎        | 3203/24227 [00:16<01:53, 185.08 examples/s]Tokenizing train dataset:  12%|█▏        | 2794/24227 [00:15<02:01, 176.25 examples/s]Tokenizing train dataset:  13%|█▎        | 3167/24227 [00:16<02:33, 137.34 examples/s]Tokenizing train dataset:  13%|█▎        | 3235/24227 [00:17<02:27, 141.92 examples/s]Tokenizing train dataset:  13%|█▎        | 3197/24227 [00:17<02:08, 163.15 examples/s]Tokenizing train dataset:  12%|█▏        | 2822/24227 [00:16<02:42, 131.46 examples/s]Tokenizing train dataset:  13%|█▎        | 3263/24227 [00:17<02:08, 163.57 examples/s]Tokenizing train dataset:  13%|█▎        | 3226/24227 [00:17<01:54, 184.18 examples/s]Tokenizing train dataset:  12%|█▏        | 2848/24227 [00:16<02:21, 150.70 examples/s]Tokenizing train dataset:  14%|█▎        | 3290/24227 [00:17<01:54, 182.14 examples/s]Tokenizing train dataset:  13%|█▎        | 3260/24227 [00:17<01:37, 215.63 examples/s]Tokenizing train dataset:  12%|█▏        | 2876/24227 [00:16<02:03, 172.98 examples/s]Tokenizing train dataset:  14%|█▎        | 3320/24227 [00:17<01:56, 178.90 examples/s]Tokenizing train dataset:  14%|█▎        | 3292/24227 [00:17<01:42, 204.22 examples/s]Tokenizing train dataset:  12%|█▏        | 2907/24227 [00:16<02:22, 149.67 examples/s]Tokenizing train dataset:  14%|█▎        | 3317/24227 [00:17<01:38, 212.75 examples/s]Tokenizing train dataset:  14%|█▍        | 3357/24227 [00:17<01:46, 195.14 examples/s]Tokenizing train dataset:  12%|█▏        | 2937/24227 [00:16<02:16, 155.44 examples/s]Tokenizing train dataset:  14%|█▍        | 3350/24227 [00:17<01:43, 202.08 examples/s]Tokenizing train dataset:  14%|█▍        | 3383/24227 [00:17<02:07, 163.52 examples/s]Tokenizing train dataset:  12%|█▏        | 2962/24227 [00:16<02:04, 171.08 examples/s]Tokenizing train dataset:  14%|█▍        | 3385/24227 [00:17<01:40, 207.90 examples/s]Tokenizing train dataset:  14%|█▍        | 3409/24227 [00:17<01:55, 180.88 examples/s]Tokenizing train dataset:  12%|█▏        | 2990/24227 [00:17<01:51, 190.62 examples/s]Tokenizing train dataset:  14%|█▍        | 3409/24227 [00:18<01:38, 212.26 examples/s]Tokenizing train dataset:  14%|█▍        | 3430/24227 [00:18<01:52, 184.71 examples/s]Tokenizing train dataset:  12%|█▏        | 3018/24227 [00:17<01:41, 209.02 examples/s]Tokenizing train dataset:  14%|█▍        | 3436/24227 [00:18<02:01, 171.79 examples/s]Tokenizing train dataset:  14%|█▍        | 3456/24227 [00:18<02:17, 151.41 examples/s]Tokenizing train dataset:  13%|█▎        | 3047/24227 [00:17<02:02, 173.45 examples/s]Tokenizing train dataset:  14%|█▍        | 3458/24227 [00:18<01:54, 180.94 examples/s]Tokenizing train dataset:  14%|█▍        | 3481/24227 [00:18<02:26, 142.04 examples/s]Tokenizing train dataset:  13%|█▎        | 3073/24227 [00:17<02:11, 160.69 examples/s]Tokenizing train dataset:  14%|█▍        | 3487/24227 [00:18<01:53, 182.80 examples/s]Tokenizing train dataset:  15%|█▍        | 3515/24227 [00:18<01:56, 178.49 examples/s]Tokenizing train dataset:  13%|█▎        | 3097/24227 [00:17<02:01, 174.38 examples/s]Tokenizing train dataset:  15%|█▍        | 3520/24227 [00:18<01:36, 214.05 examples/s]Tokenizing train dataset:  15%|█▍        | 3543/24227 [00:18<01:44, 198.34 examples/s]Tokenizing train dataset:  13%|█▎        | 3127/24227 [00:17<01:58, 178.09 examples/s]Tokenizing train dataset:  15%|█▍        | 3559/24227 [00:18<01:31, 226.33 examples/s]Tokenizing train dataset:  15%|█▍        | 3567/24227 [00:18<01:42, 201.84 examples/s]Tokenizing train dataset:  13%|█▎        | 3149/24227 [00:17<01:54, 184.88 examples/s]Tokenizing train dataset:  15%|█▍        | 3585/24227 [00:18<01:28, 233.22 examples/s]Tokenizing train dataset:  13%|█▎        | 3176/24227 [00:18<01:43, 203.10 examples/s]Tokenizing train dataset:  15%|█▍        | 3599/24227 [00:19<01:44, 196.47 examples/s]Tokenizing train dataset:  15%|█▍        | 3616/24227 [00:19<01:36, 212.76 examples/s]Tokenizing train dataset:  13%|█▎        | 3204/24227 [00:18<01:36, 217.35 examples/s]Tokenizing train dataset:  15%|█▍        | 3629/24227 [00:19<01:34, 217.87 examples/s]Tokenizing train dataset:  15%|█▌        | 3640/24227 [00:19<01:34, 217.34 examples/s]Tokenizing train dataset:  13%|█▎        | 3227/24227 [00:18<01:36, 218.74 examples/s]Tokenizing train dataset:  15%|█▌        | 3656/24227 [00:19<01:30, 226.61 examples/s]Tokenizing train dataset:  15%|█▌        | 3670/24227 [00:19<01:26, 237.32 examples/s]Tokenizing train dataset:  13%|█▎        | 3259/24227 [00:18<01:25, 245.09 examples/s]Tokenizing train dataset:  15%|█▌        | 3687/24227 [00:19<01:23, 245.40 examples/s]Tokenizing train dataset:  15%|█▌        | 3697/24227 [00:19<01:24, 243.53 examples/s]Tokenizing train dataset:  14%|█▎        | 3287/24227 [00:18<01:34, 221.80 examples/s]Tokenizing train dataset:  15%|█▌        | 3720/24227 [00:19<01:28, 230.67 examples/s]Tokenizing train dataset:  15%|█▌        | 3737/24227 [00:19<01:23, 245.85 examples/s]Tokenizing train dataset:  14%|█▎        | 3313/24227 [00:18<01:31, 228.48 examples/s]Tokenizing train dataset:  16%|█▌        | 3761/24227 [00:19<01:24, 241.48 examples/s]Tokenizing train dataset:  16%|█▌        | 3771/24227 [00:19<01:16, 268.32 examples/s]Tokenizing train dataset:  14%|█▍        | 3342/24227 [00:18<01:27, 239.26 examples/s]Tokenizing train dataset:  16%|█▌        | 3796/24227 [00:19<01:35, 214.54 examples/s]Tokenizing train dataset:  16%|█▌        | 3804/24227 [00:19<01:32, 219.91 examples/s]Tokenizing train dataset:  14%|█▍        | 3371/24227 [00:18<01:48, 191.51 examples/s]Tokenizing train dataset:  16%|█▌        | 3822/24227 [00:19<01:31, 222.13 examples/s]Tokenizing train dataset:  16%|█▌        | 3841/24227 [00:19<01:30, 225.02 examples/s]Tokenizing train dataset:  14%|█▍        | 3399/24227 [00:19<01:50, 189.02 examples/s]Tokenizing train dataset:  16%|█▌        | 3858/24227 [00:20<01:29, 226.41 examples/s]Tokenizing train dataset:  14%|█▍        | 3420/24227 [00:19<01:49, 189.69 examples/s]Tokenizing train dataset:  16%|█▌        | 3876/24227 [00:20<01:30, 225.74 examples/s]Tokenizing train dataset:  16%|█▌        | 3890/24227 [00:20<01:32, 220.58 examples/s]Tokenizing train dataset:  16%|█▌        | 3900/24227 [00:20<01:29, 226.80 examples/s]Tokenizing train dataset:  14%|█▍        | 3450/24227 [00:19<01:48, 191.11 examples/s]Tokenizing train dataset:  16%|█▌        | 3914/24227 [00:20<01:31, 222.83 examples/s]Tokenizing train dataset:  16%|█▌        | 3924/24227 [00:20<01:29, 226.15 examples/s]Tokenizing train dataset:  14%|█▍        | 3471/24227 [00:19<01:47, 193.64 examples/s]Tokenizing train dataset:  16%|█▋        | 3941/24227 [00:20<01:41, 200.56 examples/s]Tokenizing train dataset:  16%|█▋        | 3954/24227 [00:20<01:35, 211.27 examples/s]Tokenizing train dataset:  14%|█▍        | 3500/24227 [00:19<01:52, 184.02 examples/s]Tokenizing train dataset:  16%|█▋        | 3974/24227 [00:20<01:28, 228.20 examples/s]Tokenizing train dataset:  16%|█▋        | 3982/24227 [00:20<01:29, 225.76 examples/s]Tokenizing train dataset:  15%|█▍        | 3523/24227 [00:19<01:50, 186.59 examples/s]Tokenizing train dataset:  17%|█▋        | 4007/24227 [00:20<01:31, 220.79 examples/s]Tokenizing train dataset:  17%|█▋        | 4015/24227 [00:20<01:43, 194.80 examples/s]Tokenizing train dataset:  15%|█▍        | 3556/24227 [00:19<01:52, 183.00 examples/s]Tokenizing train dataset:  17%|█▋        | 4038/24227 [00:20<01:34, 213.34 examples/s]Tokenizing train dataset:  17%|█▋        | 4046/24227 [00:21<01:53, 177.86 examples/s]Tokenizing train dataset:  15%|█▍        | 3589/24227 [00:20<02:03, 167.17 examples/s]Tokenizing train dataset:  17%|█▋        | 4069/24227 [00:21<01:44, 193.15 examples/s]Tokenizing train dataset:  17%|█▋        | 4083/24227 [00:21<01:43, 194.29 examples/s]Tokenizing train dataset:  15%|█▍        | 3620/24227 [00:20<02:06, 162.93 examples/s]Tokenizing train dataset:  17%|█▋        | 4115/24227 [00:21<01:32, 217.22 examples/s]Tokenizing train dataset:  17%|█▋        | 4107/24227 [00:21<01:43, 193.72 examples/s]Tokenizing train dataset:  15%|█▌        | 3648/24227 [00:20<01:51, 183.77 examples/s]Tokenizing train dataset:  17%|█▋        | 4146/24227 [00:21<01:25, 234.61 examples/s]Tokenizing train dataset:  17%|█▋        | 4141/24227 [00:21<01:44, 191.80 examples/s]Tokenizing train dataset:  15%|█▌        | 3680/24227 [00:20<01:47, 190.93 examples/s]Tokenizing train dataset:  17%|█▋        | 4163/24227 [00:21<01:42, 195.51 examples/s]Tokenizing train dataset:  17%|█▋        | 4180/24227 [00:21<01:32, 217.82 examples/s]Tokenizing train dataset:  15%|█▌        | 3708/24227 [00:20<01:52, 182.66 examples/s]Tokenizing train dataset:  17%|█▋        | 4198/24227 [00:21<01:37, 205.23 examples/s]Tokenizing train dataset:  17%|█▋        | 4212/24227 [00:21<01:36, 207.18 examples/s]Tokenizing train dataset:  15%|█▌        | 3733/24227 [00:21<02:15, 151.19 examples/s]Tokenizing train dataset:  17%|█▋        | 4228/24227 [00:22<02:07, 157.22 examples/s]Tokenizing train dataset:  18%|█▊        | 4244/24227 [00:22<02:04, 161.11 examples/s]Tokenizing train dataset:  15%|█▌        | 3752/24227 [00:21<02:09, 157.50 examples/s]Tokenizing train dataset:  16%|█▌        | 3772/24227 [00:21<02:07, 160.33 examples/s]Tokenizing train dataset:  18%|█▊        | 4259/24227 [00:22<01:59, 166.79 examples/s]Tokenizing train dataset:  18%|█▊        | 4278/24227 [00:22<01:53, 175.76 examples/s]Tokenizing train dataset:  16%|█▌        | 3801/24227 [00:21<01:49, 186.85 examples/s]Tokenizing train dataset:  18%|█▊        | 4291/24227 [00:22<01:53, 176.23 examples/s]Tokenizing train dataset:  18%|█▊        | 4307/24227 [00:22<02:03, 161.74 examples/s]Tokenizing train dataset:  16%|█▌        | 3836/24227 [00:21<01:42, 198.72 examples/s]Tokenizing train dataset:  18%|█▊        | 4314/24227 [00:22<01:47, 184.62 examples/s]Tokenizing train dataset:  18%|█▊        | 4325/24227 [00:22<02:01, 163.88 examples/s]Tokenizing train dataset:  16%|█▌        | 3869/24227 [00:21<01:40, 202.94 examples/s]Tokenizing train dataset:  18%|█▊        | 4349/24227 [00:22<01:44, 190.10 examples/s]Tokenizing train dataset:  18%|█▊        | 4352/24227 [00:22<01:47, 184.64 examples/s]Tokenizing train dataset:  16%|█▌        | 3901/24227 [00:21<01:39, 204.29 examples/s]Tokenizing train dataset:  18%|█▊        | 4379/24227 [00:22<01:45, 188.75 examples/s]Tokenizing train dataset:  18%|█▊        | 4382/24227 [00:22<01:58, 167.33 examples/s]Tokenizing train dataset:  18%|█▊        | 4399/24227 [00:23<01:52, 176.76 examples/s]Tokenizing train dataset:  16%|█▌        | 3927/24227 [00:22<01:50, 183.37 examples/s]Tokenizing train dataset:  18%|█▊        | 4401/24227 [00:22<01:56, 169.87 examples/s]Tokenizing train dataset:  18%|█▊        | 4419/24227 [00:23<01:49, 180.38 examples/s]Tokenizing train dataset:  16%|█▋        | 3956/24227 [00:22<01:59, 169.76 examples/s]Tokenizing train dataset:  18%|█▊        | 4439/24227 [00:23<01:53, 173.84 examples/s]Tokenizing train dataset:  18%|█▊        | 4434/24227 [00:23<02:00, 164.09 examples/s]Tokenizing train dataset:  16%|█▋        | 3983/24227 [00:22<01:47, 188.73 examples/s]Tokenizing train dataset:  18%|█▊        | 4466/24227 [00:23<01:41, 194.97 examples/s]Tokenizing train dataset:  18%|█▊        | 4460/24227 [00:23<01:48, 181.73 examples/s]Tokenizing train dataset:  17%|█▋        | 4006/24227 [00:22<01:43, 194.51 examples/s]Tokenizing train dataset:  19%|█▊        | 4495/24227 [00:23<01:30, 217.67 examples/s]Tokenizing train dataset:  18%|█▊        | 4481/24227 [00:23<01:45, 186.43 examples/s]Tokenizing train dataset:  17%|█▋        | 4039/24227 [00:22<01:41, 198.26 examples/s]Tokenizing train dataset:  19%|█▊        | 4527/24227 [00:23<01:32, 212.31 examples/s]Tokenizing train dataset:  19%|█▊        | 4512/24227 [00:23<01:43, 190.27 examples/s]Tokenizing train dataset:  17%|█▋        | 4068/24227 [00:22<01:46, 189.02 examples/s]Tokenizing train dataset:  19%|█▉        | 4558/24227 [00:23<01:35, 206.85 examples/s]Tokenizing train dataset:  17%|█▋        | 4096/24227 [00:22<01:36, 208.12 examples/s]Tokenizing train dataset:  19%|█▊        | 4540/24227 [00:23<02:05, 157.17 examples/s]Tokenizing train dataset:  19%|█▉        | 4590/24227 [00:23<01:36, 203.37 examples/s]Tokenizing train dataset:  17%|█▋        | 4121/24227 [00:23<01:33, 215.21 examples/s]Tokenizing train dataset:  19%|█▉        | 4558/24227 [00:23<02:04, 157.77 examples/s]Tokenizing train dataset:  19%|█▉        | 4618/24227 [00:24<01:29, 218.53 examples/s]Tokenizing train dataset:  17%|█▋        | 4147/24227 [00:23<01:30, 221.22 examples/s]Tokenizing train dataset:  19%|█▉        | 4580/24227 [00:24<01:55, 169.59 examples/s]Tokenizing train dataset:  19%|█▉        | 4647/24227 [00:24<01:24, 231.48 examples/s]Tokenizing train dataset:  19%|█▉        | 4602/24227 [00:24<01:50, 178.09 examples/s]Tokenizing train dataset:  17%|█▋        | 4180/24227 [00:23<01:31, 218.89 examples/s]Tokenizing train dataset:  19%|█▉        | 4630/24227 [00:24<01:39, 197.84 examples/s]Tokenizing train dataset:  19%|█▉        | 4680/24227 [00:24<01:29, 219.54 examples/s]Tokenizing train dataset:  17%|█▋        | 4205/24227 [00:23<01:28, 226.24 examples/s]Tokenizing train dataset:  19%|█▉        | 4663/24227 [00:24<01:48, 180.89 examples/s]Tokenizing train dataset:  19%|█▉        | 4710/24227 [00:24<01:46, 184.10 examples/s]Tokenizing train dataset:  17%|█▋        | 4232/24227 [00:23<02:10, 153.51 examples/s]Tokenizing train dataset:  19%|█▉        | 4696/24227 [00:24<01:46, 182.70 examples/s]Tokenizing train dataset:  20%|█▉        | 4744/24227 [00:24<01:40, 193.30 examples/s]Tokenizing train dataset:  18%|█▊        | 4251/24227 [00:23<02:05, 158.97 examples/s]Tokenizing train dataset:  18%|█▊        | 4271/24227 [00:23<02:00, 165.52 examples/s]Tokenizing train dataset:  20%|█▉        | 4725/24227 [00:24<01:48, 179.91 examples/s]Tokenizing train dataset:  20%|█▉        | 4776/24227 [00:24<01:43, 188.01 examples/s]Tokenizing train dataset:  18%|█▊        | 4294/24227 [00:24<01:51, 178.63 examples/s]Tokenizing train dataset:  20%|█▉        | 4744/24227 [00:24<01:50, 176.14 examples/s]Tokenizing train dataset:  20%|█▉        | 4805/24227 [00:25<01:49, 177.96 examples/s]Tokenizing train dataset:  18%|█▊        | 4326/24227 [00:24<01:46, 187.25 examples/s]Tokenizing train dataset:  20%|█▉        | 4776/24227 [00:25<01:48, 179.39 examples/s]Tokenizing train dataset:  20%|█▉        | 4836/24227 [00:25<01:46, 182.76 examples/s]Tokenizing train dataset:  18%|█▊        | 4354/24227 [00:24<01:36, 205.49 examples/s]Tokenizing train dataset:  20%|█▉        | 4804/24227 [00:25<02:01, 159.98 examples/s]Tokenizing train dataset:  18%|█▊        | 4383/24227 [00:24<01:46, 186.75 examples/s]Tokenizing train dataset:  20%|██        | 4868/24227 [00:25<01:48, 178.52 examples/s]Tokenizing train dataset:  18%|█▊        | 4403/24227 [00:24<01:49, 180.87 examples/s]Tokenizing train dataset:  20%|█▉        | 4832/24227 [00:25<02:02, 158.50 examples/s]Tokenizing train dataset:  20%|██        | 4901/24227 [00:25<01:49, 176.53 examples/s]Tokenizing train dataset:  18%|█▊        | 4425/24227 [00:24<01:45, 188.34 examples/s]Tokenizing train dataset:  20%|██        | 4924/24227 [00:25<01:44, 184.27 examples/s]Tokenizing train dataset:  20%|██        | 4862/24227 [00:25<01:57, 165.16 examples/s]Tokenizing train dataset:  18%|█▊        | 4457/24227 [00:24<01:46, 186.22 examples/s]Tokenizing train dataset:  20%|██        | 4884/24227 [00:25<01:51, 173.62 examples/s]Tokenizing train dataset:  20%|██        | 4950/24227 [00:25<01:41, 190.86 examples/s]Tokenizing train dataset:  19%|█▊        | 4485/24227 [00:25<02:04, 158.84 examples/s]Tokenizing train dataset:  20%|██        | 4902/24227 [00:25<02:23, 134.40 examples/s]Tokenizing train dataset:  21%|██        | 4980/24227 [00:26<02:13, 144.02 examples/s]Tokenizing train dataset:  19%|█▊        | 4515/24227 [00:25<02:02, 160.83 examples/s]Tokenizing train dataset:  20%|██        | 4931/24227 [00:26<02:15, 142.64 examples/s]Tokenizing train dataset:  21%|██        | 5004/24227 [00:26<01:59, 160.85 examples/s]Tokenizing train dataset:  20%|██        | 4949/24227 [00:26<02:27, 130.42 examples/s]Tokenizing train dataset:  21%|██        | 5024/24227 [00:26<02:12, 144.70 examples/s]Tokenizing train dataset:  19%|█▊        | 4540/24227 [00:25<02:17, 143.66 examples/s]Tokenizing train dataset:  20%|██        | 4964/24227 [00:26<02:25, 132.44 examples/s]Tokenizing train dataset:  21%|██        | 5044/24227 [00:26<02:03, 155.54 examples/s]Tokenizing train dataset:  19%|█▉        | 4558/24227 [00:25<02:15, 145.27 examples/s]Tokenizing train dataset:  21%|██        | 4982/24227 [00:26<02:17, 140.18 examples/s]Tokenizing train dataset:  21%|██        | 5077/24227 [00:26<01:50, 172.54 examples/s]Tokenizing train dataset:  21%|██        | 5009/24227 [00:26<01:54, 168.41 examples/s]Tokenizing train dataset:  19%|█▉        | 4586/24227 [00:25<02:11, 149.05 examples/s]Tokenizing train dataset:  21%|██        | 5029/24227 [00:26<01:58, 162.65 examples/s]Tokenizing train dataset:  19%|█▉        | 4604/24227 [00:25<02:19, 140.19 examples/s]Tokenizing train dataset:  21%|██        | 5108/24227 [00:26<01:59, 160.46 examples/s]Tokenizing train dataset:  21%|██        | 5057/24227 [00:26<01:41, 189.68 examples/s]Tokenizing train dataset:  19%|█▉        | 4630/24227 [00:26<02:17, 142.33 examples/s]Tokenizing train dataset:  21%|██        | 5139/24227 [00:27<01:53, 167.59 examples/s]Tokenizing train dataset:  19%|█▉        | 4648/24227 [00:26<02:11, 149.14 examples/s]Tokenizing train dataset:  21%|██        | 5086/24227 [00:27<01:56, 164.21 examples/s]Tokenizing train dataset:  21%|██▏       | 5169/24227 [00:27<02:01, 156.35 examples/s]Tokenizing train dataset:  19%|█▉        | 4677/24227 [00:26<02:02, 159.74 examples/s]Tokenizing train dataset:  21%|██        | 5119/24227 [00:27<01:54, 167.06 examples/s]Tokenizing train dataset:  21%|██▏       | 5186/24227 [00:27<02:05, 151.43 examples/s]Tokenizing train dataset:  19%|█▉        | 4704/24227 [00:26<02:08, 151.46 examples/s]Tokenizing train dataset:  21%|██▏       | 5203/24227 [00:27<02:07, 149.06 examples/s]Tokenizing train dataset:  21%|██▏       | 5150/24227 [00:27<01:56, 164.23 examples/s]Tokenizing train dataset:  19%|█▉        | 4720/24227 [00:26<02:09, 150.71 examples/s]Tokenizing train dataset:  22%|██▏       | 5220/24227 [00:27<02:08, 148.47 examples/s]Tokenizing train dataset:  21%|██▏       | 5181/24227 [00:27<01:50, 172.93 examples/s]Tokenizing train dataset:  20%|█▉        | 4750/24227 [00:26<01:46, 182.54 examples/s]Tokenizing train dataset:  22%|██▏       | 5240/24227 [00:27<02:08, 147.94 examples/s]Tokenizing train dataset:  21%|██▏       | 5199/24227 [00:27<01:51, 171.29 examples/s]Tokenizing train dataset:  20%|█▉        | 4777/24227 [00:26<01:48, 179.40 examples/s]Tokenizing train dataset:  22%|██▏       | 5266/24227 [00:27<01:50, 172.06 examples/s]Tokenizing train dataset:  22%|██▏       | 5232/24227 [00:27<01:43, 183.11 examples/s]Tokenizing train dataset:  20%|█▉        | 4801/24227 [00:27<01:41, 190.94 examples/s]Tokenizing train dataset:  22%|██▏       | 5291/24227 [00:28<01:39, 189.74 examples/s]Tokenizing train dataset:  22%|██▏       | 5261/24227 [00:28<01:46, 177.64 examples/s]Tokenizing train dataset:  20%|█▉        | 4829/24227 [00:27<01:48, 179.58 examples/s]Tokenizing train dataset:  22%|██▏       | 5316/24227 [00:28<02:00, 156.99 examples/s]Tokenizing train dataset:  22%|██▏       | 5279/24227 [00:28<01:47, 177.02 examples/s]Tokenizing train dataset:  20%|██        | 4861/24227 [00:27<01:42, 188.83 examples/s]Tokenizing train dataset:  22%|██▏       | 5350/24227 [00:28<01:47, 175.17 examples/s]Tokenizing train dataset:  20%|██        | 4881/24227 [00:27<01:41, 190.21 examples/s]Tokenizing train dataset:  22%|██▏       | 5305/24227 [00:28<01:50, 172.01 examples/s]Tokenizing train dataset:  22%|██▏       | 5377/24227 [00:28<01:48, 173.69 examples/s]Tokenizing train dataset:  20%|██        | 4911/24227 [00:27<01:46, 181.80 examples/s]Tokenizing train dataset:  22%|██▏       | 5330/24227 [00:28<01:58, 159.53 examples/s]Tokenizing train dataset:  22%|██▏       | 5397/24227 [00:28<01:45, 178.16 examples/s]Tokenizing train dataset:  20%|██        | 4941/24227 [00:27<01:46, 180.64 examples/s]Tokenizing train dataset:  22%|██▏       | 5350/24227 [00:28<02:07, 147.81 examples/s]Tokenizing train dataset:  22%|██▏       | 5432/24227 [00:28<01:45, 178.11 examples/s]Tokenizing train dataset:  20%|██        | 4964/24227 [00:28<01:57, 164.46 examples/s]Tokenizing train dataset:  22%|██▏       | 5377/24227 [00:28<02:07, 148.21 examples/s]Tokenizing train dataset:  23%|██▎       | 5463/24227 [00:29<01:46, 175.57 examples/s]Tokenizing train dataset:  22%|██▏       | 5393/24227 [00:29<02:24, 130.25 examples/s]Tokenizing train dataset:  21%|██        | 4996/24227 [00:28<02:04, 154.53 examples/s]Tokenizing train dataset:  23%|██▎       | 5495/24227 [00:29<01:48, 172.53 examples/s]Tokenizing train dataset:  22%|██▏       | 5410/24227 [00:29<02:26, 128.29 examples/s]Tokenizing train dataset:  21%|██        | 5016/24227 [00:28<01:59, 161.28 examples/s]Tokenizing train dataset:  23%|██▎       | 5515/24227 [00:29<02:08, 145.93 examples/s]Tokenizing train dataset:  22%|██▏       | 5430/24227 [00:29<02:33, 122.11 examples/s]Tokenizing train dataset:  21%|██        | 5035/24227 [00:28<02:17, 139.31 examples/s]Tokenizing train dataset:  23%|██▎       | 5532/24227 [00:29<02:05, 149.49 examples/s]Tokenizing train dataset:  22%|██▏       | 5447/24227 [00:29<02:28, 126.79 examples/s]Tokenizing train dataset:  21%|██        | 5050/24227 [00:28<02:16, 140.83 examples/s]Tokenizing train dataset:  23%|██▎       | 5557/24227 [00:29<01:50, 168.78 examples/s]Tokenizing train dataset:  23%|██▎       | 5473/24227 [00:29<02:01, 154.91 examples/s]Tokenizing train dataset:  21%|██        | 5071/24227 [00:28<02:02, 156.03 examples/s]Tokenizing train dataset:  23%|██▎       | 5587/24227 [00:29<01:34, 197.02 examples/s]Tokenizing train dataset:  23%|██▎       | 5499/24227 [00:29<01:45, 178.29 examples/s]Tokenizing train dataset:  23%|██▎       | 5610/24227 [00:29<01:32, 201.67 examples/s]Tokenizing train dataset:  21%|██        | 5100/24227 [00:28<01:59, 159.65 examples/s]Tokenizing train dataset:  23%|██▎       | 5520/24227 [00:29<01:41, 184.31 examples/s]Tokenizing train dataset:  23%|██▎       | 5635/24227 [00:29<01:27, 213.15 examples/s]Tokenizing train dataset:  21%|██        | 5118/24227 [00:29<02:09, 148.07 examples/s]Tokenizing train dataset:  23%|██▎       | 5549/24227 [00:29<01:44, 178.88 examples/s]Tokenizing train dataset:  21%|██        | 5136/24227 [00:29<02:03, 154.41 examples/s]Tokenizing train dataset:  23%|██▎       | 5675/24227 [00:30<01:28, 210.24 examples/s]Tokenizing train dataset:  23%|██▎       | 5590/24227 [00:30<01:43, 179.27 examples/s]Tokenizing train dataset:  21%|██▏       | 5162/24227 [00:29<02:07, 149.39 examples/s]Tokenizing train dataset:  24%|██▎       | 5709/24227 [00:30<01:31, 202.78 examples/s]Tokenizing train dataset:  23%|██▎       | 5611/24227 [00:30<01:40, 184.56 examples/s]Tokenizing train dataset:  21%|██▏       | 5179/24227 [00:29<02:04, 152.51 examples/s]Tokenizing train dataset:  24%|██▎       | 5741/24227 [00:30<01:50, 166.72 examples/s]Tokenizing train dataset:  23%|██▎       | 5648/24227 [00:30<01:49, 169.74 examples/s]Tokenizing train dataset:  21%|██▏       | 5208/24227 [00:29<02:39, 119.36 examples/s]Tokenizing train dataset:  23%|██▎       | 5677/24227 [00:30<01:36, 192.51 examples/s]Tokenizing train dataset:  24%|██▍       | 5767/24227 [00:30<01:52, 164.31 examples/s]Tokenizing train dataset:  22%|██▏       | 5222/24227 [00:29<02:59, 105.99 examples/s]Tokenizing train dataset:  24%|██▎       | 5710/24227 [00:30<01:49, 168.62 examples/s]Tokenizing train dataset:  24%|██▍       | 5796/24227 [00:30<02:05, 146.95 examples/s]Tokenizing train dataset:  22%|██▏       | 5243/24227 [00:30<02:33, 123.77 examples/s]Tokenizing train dataset:  24%|██▎       | 5737/24227 [00:31<01:39, 186.04 examples/s]Tokenizing train dataset:  24%|██▍       | 5827/24227 [00:31<01:45, 173.80 examples/s]Tokenizing train dataset:  22%|██▏       | 5263/24227 [00:30<02:17, 137.98 examples/s]Tokenizing train dataset:  24%|██▍       | 5847/24227 [00:31<01:44, 175.76 examples/s]Tokenizing train dataset:  24%|██▍       | 5767/24227 [00:31<01:37, 188.50 examples/s]Tokenizing train dataset:  24%|██▍       | 5883/24227 [00:31<01:25, 214.88 examples/s]Tokenizing train dataset:  22%|██▏       | 5289/24227 [00:30<02:16, 138.47 examples/s]Tokenizing train dataset:  24%|██▍       | 5788/24227 [00:31<01:36, 190.20 examples/s]Tokenizing train dataset:  24%|██▍       | 5909/24227 [00:31<01:36, 189.86 examples/s]Tokenizing train dataset:  22%|██▏       | 5312/24227 [00:30<02:26, 129.51 examples/s]Tokenizing train dataset:  24%|██▍       | 5823/24227 [00:31<01:38, 186.78 examples/s]Tokenizing train dataset:  25%|██▍       | 5944/24227 [00:31<01:32, 197.34 examples/s]Tokenizing train dataset:  22%|██▏       | 5337/24227 [00:30<02:23, 132.06 examples/s]Tokenizing train dataset:  24%|██▍       | 5861/24227 [00:31<01:31, 201.46 examples/s]Tokenizing train dataset:  25%|██▍       | 5967/24227 [00:31<01:29, 203.81 examples/s]Tokenizing train dataset:  22%|██▏       | 5357/24227 [00:30<02:11, 143.81 examples/s]Tokenizing train dataset:  24%|██▍       | 5882/24227 [00:31<01:38, 186.25 examples/s]Tokenizing train dataset:  22%|██▏       | 5383/24227 [00:30<01:53, 166.62 examples/s]Tokenizing train dataset:  25%|██▍       | 5995/24227 [00:31<01:33, 194.51 examples/s]Tokenizing train dataset:  24%|██▍       | 5901/24227 [00:31<01:38, 185.48 examples/s]Tokenizing train dataset:  25%|██▍       | 6018/24227 [00:32<01:30, 201.56 examples/s]Tokenizing train dataset:  22%|██▏       | 5408/24227 [00:31<01:42, 184.21 examples/s]Tokenizing train dataset:  24%|██▍       | 5933/24227 [00:31<01:24, 215.33 examples/s]Tokenizing train dataset:  25%|██▍       | 6051/24227 [00:32<01:30, 199.99 examples/s]Tokenizing train dataset:  22%|██▏       | 5442/24227 [00:31<01:44, 180.08 examples/s]Tokenizing train dataset:  25%|██▍       | 5965/24227 [00:32<01:34, 193.65 examples/s]Tokenizing train dataset:  25%|██▌       | 6087/24227 [00:32<01:16, 236.44 examples/s]Tokenizing train dataset:  23%|██▎       | 5464/24227 [00:31<01:41, 184.76 examples/s]Tokenizing train dataset:  25%|██▍       | 5986/24227 [00:32<01:32, 196.46 examples/s]Tokenizing train dataset:  25%|██▌       | 6125/24227 [00:32<01:16, 238.08 examples/s]Tokenizing train dataset:  23%|██▎       | 5496/24227 [00:31<01:38, 190.64 examples/s]Tokenizing train dataset:  25%|██▍       | 6017/24227 [00:32<01:46, 171.28 examples/s]Tokenizing train dataset:  25%|██▌       | 6162/24227 [00:32<01:18, 231.56 examples/s]Tokenizing train dataset:  23%|██▎       | 5527/24227 [00:31<01:39, 188.59 examples/s]Tokenizing train dataset:  25%|██▍       | 6040/24227 [00:32<01:39, 182.56 examples/s]Tokenizing train dataset:  26%|██▌       | 6193/24227 [00:32<01:12, 248.95 examples/s]Tokenizing train dataset:  25%|██▌       | 6062/24227 [00:32<01:50, 164.76 examples/s]Tokenizing train dataset:  23%|██▎       | 5555/24227 [00:31<01:57, 158.43 examples/s]Tokenizing train dataset:  26%|██▌       | 6229/24227 [00:32<01:22, 217.18 examples/s]Tokenizing train dataset:  25%|██▌       | 6089/24227 [00:32<01:37, 186.51 examples/s]Tokenizing train dataset:  23%|██▎       | 5586/24227 [00:32<01:39, 187.31 examples/s]Tokenizing train dataset:  26%|██▌       | 6259/24227 [00:33<01:17, 233.24 examples/s]Tokenizing train dataset:  25%|██▌       | 6129/24227 [00:33<01:29, 201.66 examples/s]Tokenizing train dataset:  23%|██▎       | 5623/24227 [00:32<01:37, 190.45 examples/s]Tokenizing train dataset:  25%|██▌       | 6158/24227 [00:33<01:22, 219.91 examples/s]Tokenizing train dataset:  26%|██▌       | 6300/24227 [00:33<01:22, 216.30 examples/s]Tokenizing train dataset:  23%|██▎       | 5654/24227 [00:32<01:41, 182.42 examples/s]Tokenizing train dataset:  26%|██▌       | 6194/24227 [00:33<01:22, 219.37 examples/s]Tokenizing train dataset:  26%|██▌       | 6340/24227 [00:33<01:22, 216.43 examples/s]Tokenizing train dataset:  23%|██▎       | 5676/24227 [00:32<01:38, 187.50 examples/s]Tokenizing train dataset:  26%|██▌       | 6224/24227 [00:33<01:16, 236.39 examples/s]Tokenizing train dataset:  26%|██▋       | 6380/24227 [00:33<01:18, 227.89 examples/s]Tokenizing train dataset:  24%|██▎       | 5705/24227 [00:32<01:29, 206.14 examples/s]Tokenizing train dataset:  26%|██▌       | 6266/24227 [00:33<01:18, 227.88 examples/s]Tokenizing train dataset:  26%|██▋       | 6420/24227 [00:33<01:16, 233.49 examples/s]Tokenizing train dataset:  24%|██▎       | 5737/24227 [00:32<01:39, 185.77 examples/s]Tokenizing train dataset:  26%|██▌       | 6300/24227 [00:33<01:11, 250.84 examples/s]Tokenizing train dataset:  27%|██▋       | 6461/24227 [00:33<01:17, 228.11 examples/s]Tokenizing train dataset:  24%|██▍       | 5762/24227 [00:33<01:46, 173.51 examples/s]Tokenizing train dataset:  26%|██▌       | 6340/24227 [00:33<01:12, 247.55 examples/s]Tokenizing train dataset:  27%|██▋       | 6494/24227 [00:34<01:11, 246.98 examples/s]Tokenizing train dataset:  24%|██▍       | 5790/24227 [00:33<01:46, 173.87 examples/s]Tokenizing train dataset:  27%|██▋       | 6520/24227 [00:34<01:11, 247.96 examples/s]Tokenizing train dataset:  26%|██▋       | 6380/24227 [00:34<01:13, 242.59 examples/s]Tokenizing train dataset:  24%|██▍       | 5819/24227 [00:33<01:33, 196.55 examples/s]Tokenizing train dataset:  27%|██▋       | 6554/24227 [00:34<01:05, 268.66 examples/s]Tokenizing train dataset:  26%|██▋       | 6420/24227 [00:34<01:11, 247.33 examples/s]Tokenizing train dataset:  24%|██▍       | 5861/24227 [00:33<01:24, 218.11 examples/s]Tokenizing train dataset:  27%|██▋       | 6451/24227 [00:34<01:08, 260.55 examples/s]Tokenizing train dataset:  27%|██▋       | 6589/24227 [00:34<01:13, 241.30 examples/s]Tokenizing train dataset:  24%|██▍       | 5891/24227 [00:33<01:18, 233.86 examples/s]Tokenizing train dataset:  27%|██▋       | 6489/24227 [00:34<01:15, 235.75 examples/s]Tokenizing train dataset:  27%|██▋       | 6630/24227 [00:34<01:19, 221.22 examples/s]Tokenizing train dataset:  24%|██▍       | 5917/24227 [00:33<01:32, 198.74 examples/s]Tokenizing train dataset:  27%|██▋       | 6526/24227 [00:34<01:24, 209.74 examples/s]Tokenizing train dataset:  28%|██▊       | 6673/24227 [00:34<01:18, 223.29 examples/s]Tokenizing train dataset:  25%|██▍       | 5948/24227 [00:33<01:33, 195.26 examples/s]Tokenizing train dataset:  27%|██▋       | 6566/24227 [00:34<01:25, 205.73 examples/s]Tokenizing train dataset:  28%|██▊       | 6711/24227 [00:35<01:26, 201.60 examples/s]Tokenizing train dataset:  27%|██▋       | 6589/24227 [00:35<01:24, 209.75 examples/s]Tokenizing train dataset:  25%|██▍       | 5977/24227 [00:34<01:59, 152.27 examples/s]Tokenizing train dataset:  28%|██▊       | 6734/24227 [00:35<01:24, 205.82 examples/s]Tokenizing train dataset:  27%|██▋       | 6625/24227 [00:35<01:13, 239.36 examples/s]Tokenizing train dataset:  25%|██▍       | 5999/24227 [00:34<01:51, 162.94 examples/s]Tokenizing train dataset:  28%|██▊       | 6664/24227 [00:35<01:04, 272.85 examples/s]Tokenizing train dataset:  28%|██▊       | 6770/24227 [00:35<01:24, 205.52 examples/s]Tokenizing train dataset:  25%|██▍       | 6021/24227 [00:34<01:44, 173.88 examples/s]Tokenizing train dataset:  28%|██▊       | 6703/24227 [00:35<01:06, 263.95 examples/s]Tokenizing train dataset:  28%|██▊       | 6810/24227 [00:35<01:21, 214.70 examples/s]Tokenizing train dataset:  25%|██▍       | 6055/24227 [00:34<01:48, 168.26 examples/s]Tokenizing train dataset:  28%|██▊       | 6742/24227 [00:35<01:12, 242.19 examples/s]Tokenizing train dataset:  25%|██▌       | 6074/24227 [00:34<01:54, 158.57 examples/s]Tokenizing train dataset:  28%|██▊       | 6844/24227 [00:35<01:30, 191.29 examples/s]Tokenizing train dataset:  28%|██▊       | 6768/24227 [00:35<01:11, 243.92 examples/s]Tokenizing train dataset:  25%|██▌       | 6092/24227 [00:34<01:51, 161.97 examples/s]Tokenizing train dataset:  28%|██▊       | 6864/24227 [00:35<01:45, 164.21 examples/s]Tokenizing train dataset:  28%|██▊       | 6889/24227 [00:36<01:42, 169.07 examples/s]Tokenizing train dataset:  28%|██▊       | 6807/24227 [00:36<01:32, 188.07 examples/s]Tokenizing train dataset:  25%|██▌       | 6128/24227 [00:35<02:07, 142.50 examples/s]Tokenizing train dataset:  29%|██▊       | 6910/24227 [00:36<01:48, 160.21 examples/s]Tokenizing train dataset:  25%|██▌       | 6146/24227 [00:35<02:11, 137.99 examples/s]Tokenizing train dataset:  28%|██▊       | 6841/24227 [00:36<01:36, 181.10 examples/s]Tokenizing train dataset:  29%|██▊       | 6950/24227 [00:36<01:22, 208.22 examples/s]Tokenizing train dataset:  25%|██▌       | 6162/24227 [00:35<02:17, 131.08 examples/s]Tokenizing train dataset:  28%|██▊       | 6862/24227 [00:36<01:36, 179.75 examples/s]Tokenizing train dataset:  26%|██▌       | 6181/24227 [00:35<02:09, 139.57 examples/s]Tokenizing train dataset:  28%|██▊       | 6887/24227 [00:36<01:32, 188.28 examples/s]Tokenizing train dataset:  29%|██▉       | 6990/24227 [00:36<01:26, 198.89 examples/s]Tokenizing train dataset:  26%|██▌       | 6198/24227 [00:35<02:09, 139.60 examples/s]Tokenizing train dataset:  29%|██▊       | 6909/24227 [00:36<01:39, 174.02 examples/s]Tokenizing train dataset:  26%|██▌       | 6217/24227 [00:35<01:59, 150.48 examples/s]Tokenizing train dataset:  29%|██▉       | 7028/24227 [00:36<01:34, 182.93 examples/s]Tokenizing train dataset:  29%|██▊       | 6945/24227 [00:36<01:21, 212.05 examples/s]Tokenizing train dataset:  26%|██▌       | 6247/24227 [00:35<01:36, 186.12 examples/s]Tokenizing train dataset:  29%|██▉       | 7059/24227 [00:36<01:24, 203.80 examples/s]Tokenizing train dataset:  29%|██▉       | 6978/24227 [00:36<01:12, 237.49 examples/s]Tokenizing train dataset:  26%|██▌       | 6284/24227 [00:35<01:17, 231.65 examples/s]Tokenizing train dataset:  29%|██▉       | 7101/24227 [00:37<01:20, 212.06 examples/s]Tokenizing train dataset:  29%|██▉       | 7017/24227 [00:37<01:23, 205.00 examples/s]Tokenizing train dataset:  26%|██▌       | 6320/24227 [00:36<01:27, 204.84 examples/s]Tokenizing train dataset:  29%|██▉       | 7129/24227 [00:37<01:16, 224.89 examples/s]Tokenizing train dataset:  29%|██▉       | 7049/24227 [00:37<01:44, 163.76 examples/s]Tokenizing train dataset:  26%|██▋       | 6360/24227 [00:36<01:45, 168.73 examples/s]Tokenizing train dataset:  30%|██▉       | 7169/24227 [00:37<01:46, 160.59 examples/s]Tokenizing train dataset:  29%|██▉       | 7073/24227 [00:37<01:48, 158.22 examples/s]Tokenizing train dataset:  26%|██▋       | 6393/24227 [00:36<01:51, 159.60 examples/s]Tokenizing train dataset:  30%|██▉       | 7205/24227 [00:37<01:37, 174.30 examples/s]Tokenizing train dataset:  29%|██▉       | 7092/24227 [00:37<01:55, 148.57 examples/s]Tokenizing train dataset:  26%|██▋       | 6419/24227 [00:36<01:41, 175.93 examples/s]Tokenizing train dataset:  30%|██▉       | 7226/24227 [00:37<01:34, 179.09 examples/s]Tokenizing train dataset:  29%|██▉       | 7111/24227 [00:37<02:06, 135.09 examples/s]Tokenizing train dataset:  27%|██▋       | 6440/24227 [00:36<01:47, 166.04 examples/s]Tokenizing train dataset:  30%|██▉       | 7248/24227 [00:37<01:35, 178.63 examples/s]Tokenizing train dataset:  29%|██▉       | 7134/24227 [00:37<01:51, 152.90 examples/s]Tokenizing train dataset:  30%|███       | 7276/24227 [00:38<01:25, 199.25 examples/s]Tokenizing train dataset:  27%|██▋       | 6471/24227 [00:37<01:32, 191.33 examples/s]Tokenizing train dataset:  30%|██▉       | 7152/24227 [00:38<01:59, 143.05 examples/s]Tokenizing train dataset:  30%|███       | 7312/24227 [00:38<01:28, 191.69 examples/s]Tokenizing train dataset:  27%|██▋       | 6508/24227 [00:37<01:35, 185.87 examples/s]Tokenizing train dataset:  30%|██▉       | 7182/24227 [00:38<01:37, 174.18 examples/s]Tokenizing train dataset:  30%|███       | 7352/24227 [00:38<01:20, 209.35 examples/s]Tokenizing train dataset:  30%|███       | 7377/24227 [00:38<01:18, 215.02 examples/s]Tokenizing train dataset:  27%|██▋       | 6541/24227 [00:37<01:48, 162.87 examples/s]Tokenizing train dataset:  30%|██▉       | 7220/24227 [00:38<01:45, 161.28 examples/s]Tokenizing train dataset:  27%|██▋       | 6560/24227 [00:37<01:57, 150.26 examples/s]Tokenizing train dataset:  30%|██▉       | 7241/24227 [00:38<01:52, 150.98 examples/s]Tokenizing train dataset:  31%|███       | 7412/24227 [00:38<01:25, 197.76 examples/s]Tokenizing train dataset:  27%|██▋       | 6579/24227 [00:37<02:02, 144.48 examples/s]Tokenizing train dataset:  30%|██▉       | 7261/24227 [00:38<01:53, 149.30 examples/s]Tokenizing train dataset:  27%|██▋       | 6599/24227 [00:37<01:54, 154.07 examples/s]Tokenizing train dataset:  31%|███       | 7451/24227 [00:38<01:27, 190.82 examples/s]Tokenizing train dataset:  30%|███       | 7282/24227 [00:38<01:45, 160.31 examples/s]Tokenizing train dataset:  27%|██▋       | 6626/24227 [00:38<01:38, 178.56 examples/s]Tokenizing train dataset:  31%|███       | 7472/24227 [00:39<01:45, 159.54 examples/s]Tokenizing train dataset:  30%|███       | 7302/24227 [00:39<02:23, 118.12 examples/s]Tokenizing train dataset:  27%|██▋       | 6648/24227 [00:38<01:59, 147.19 examples/s]Tokenizing train dataset:  31%|███       | 7494/24227 [00:39<01:39, 167.72 examples/s]Tokenizing train dataset:  30%|███       | 7320/24227 [00:39<02:17, 123.07 examples/s]Tokenizing train dataset:  28%|██▊       | 6669/24227 [00:38<01:55, 152.14 examples/s]Tokenizing train dataset:  31%|███       | 7531/24227 [00:39<01:35, 173.98 examples/s]Tokenizing train dataset:  30%|███       | 7357/24227 [00:39<01:38, 171.64 examples/s]Tokenizing train dataset:  28%|██▊       | 6691/24227 [00:38<01:46, 164.19 examples/s]Tokenizing train dataset:  31%|███       | 7566/24227 [00:39<01:33, 177.64 examples/s]Tokenizing train dataset:  28%|██▊       | 6709/24227 [00:38<02:15, 129.35 examples/s]Tokenizing train dataset:  31%|███       | 7395/24227 [00:39<01:43, 163.18 examples/s]Tokenizing train dataset:  31%|███▏      | 7600/24227 [00:39<01:28, 188.65 examples/s]Tokenizing train dataset:  28%|██▊       | 6740/24227 [00:38<01:45, 165.17 examples/s]Tokenizing train dataset:  31%|███       | 7428/24227 [00:39<01:39, 168.75 examples/s]Tokenizing train dataset:  31%|███▏      | 7631/24227 [00:39<01:18, 210.45 examples/s]Tokenizing train dataset:  28%|██▊       | 6768/24227 [00:38<01:31, 190.15 examples/s]Tokenizing train dataset:  31%|███       | 7465/24227 [00:39<01:21, 206.14 examples/s]Tokenizing train dataset:  32%|███▏      | 7656/24227 [00:40<01:15, 218.67 examples/s]Tokenizing train dataset:  28%|██▊       | 6790/24227 [00:39<01:29, 194.92 examples/s]Tokenizing train dataset:  31%|███       | 7496/24227 [00:40<01:14, 225.54 examples/s]Tokenizing train dataset:  32%|███▏      | 7687/24227 [00:40<01:09, 237.69 examples/s]Tokenizing train dataset:  28%|██▊       | 6814/24227 [00:39<01:24, 205.48 examples/s]Tokenizing train dataset:  32%|███▏      | 7720/24227 [00:40<01:03, 259.70 examples/s]Tokenizing train dataset:  31%|███       | 7542/24227 [00:40<01:07, 247.02 examples/s]Tokenizing train dataset:  28%|██▊       | 6845/24227 [00:39<01:30, 192.59 examples/s]Tokenizing train dataset:  32%|███▏      | 7768/24227 [00:40<00:52, 314.62 examples/s]Tokenizing train dataset:  32%|███▏      | 7804/24227 [00:40<01:07, 243.31 examples/s]Tokenizing train dataset:  31%|███▏      | 7575/24227 [00:40<01:30, 183.75 examples/s]Tokenizing train dataset:  28%|██▊       | 6888/24227 [00:39<01:39, 175.03 examples/s]Tokenizing train dataset:  32%|███▏      | 7859/24227 [00:40<00:52, 311.46 examples/s]Tokenizing train dataset:  31%|███▏      | 7603/24227 [00:40<01:22, 200.40 examples/s]Tokenizing train dataset:  29%|██▊       | 6910/24227 [00:39<01:35, 181.03 examples/s]Tokenizing train dataset:  33%|███▎      | 7908/24227 [00:40<00:46, 352.72 examples/s]Tokenizing train dataset:  31%|███▏      | 7628/24227 [00:40<01:19, 209.36 examples/s]Tokenizing train dataset:  29%|██▊       | 6943/24227 [00:39<01:21, 211.17 examples/s]Tokenizing train dataset:  33%|███▎      | 7976/24227 [00:40<00:37, 435.61 examples/s]Tokenizing train dataset:  29%|██▉       | 6971/24227 [00:39<01:16, 226.66 examples/s]Tokenizing train dataset:  32%|███▏      | 7672/24227 [00:40<01:11, 231.26 examples/s]Tokenizing train dataset:  33%|███▎      | 8043/24227 [00:41<00:36, 437.50 examples/s]Tokenizing train dataset:  29%|██▉       | 7000/24227 [00:40<01:12, 238.26 examples/s]Tokenizing train dataset:  32%|███▏      | 7709/24227 [00:40<01:03, 260.56 examples/s]Tokenizing train dataset:  33%|███▎      | 8102/24227 [00:41<00:34, 473.53 examples/s]Tokenizing train dataset:  32%|███▏      | 7743/24227 [00:41<01:07, 243.06 examples/s]Tokenizing train dataset:  29%|██▉       | 7036/24227 [00:40<01:22, 208.85 examples/s]Tokenizing train dataset:  34%|███▎      | 8165/24227 [00:41<00:36, 437.79 examples/s]Tokenizing train dataset:  32%|███▏      | 7784/24227 [00:41<00:58, 279.90 examples/s]Tokenizing train dataset:  32%|███▏      | 7842/24227 [00:41<00:46, 352.02 examples/s]Tokenizing train dataset:  29%|██▉       | 7072/24227 [00:40<01:26, 198.12 examples/s]Tokenizing train dataset:  34%|███▍      | 8249/24227 [00:41<00:33, 473.30 examples/s]Tokenizing train dataset:  33%|███▎      | 7917/24227 [00:41<00:42, 387.20 examples/s]Tokenizing train dataset:  29%|██▉       | 7108/24227 [00:40<01:23, 205.73 examples/s]Tokenizing train dataset:  34%|███▍      | 8329/24227 [00:41<00:40, 392.68 examples/s]Tokenizing train dataset:  33%|███▎      | 7995/24227 [00:41<00:40, 402.82 examples/s]Tokenizing train dataset:  29%|██▉       | 7141/24227 [00:40<01:32, 185.62 examples/s]Tokenizing train dataset:  35%|███▍      | 8387/24227 [00:41<00:37, 427.73 examples/s]Tokenizing train dataset:  33%|███▎      | 8050/24227 [00:41<00:37, 431.80 examples/s]Tokenizing train dataset:  35%|███▍      | 8438/24227 [00:41<00:35, 443.58 examples/s]Tokenizing train dataset:  30%|██▉       | 7172/24227 [00:40<01:21, 208.05 examples/s]Tokenizing train dataset:  34%|███▎      | 8122/24227 [00:42<00:40, 402.09 examples/s]Tokenizing train dataset:  35%|███▌      | 8512/24227 [00:42<00:36, 434.82 examples/s]Tokenizing train dataset:  30%|██▉       | 7206/24227 [00:41<01:27, 194.39 examples/s]Tokenizing train dataset:  34%|███▍      | 8185/24227 [00:42<00:46, 342.44 examples/s]Tokenizing train dataset:  35%|███▌      | 8589/24227 [00:42<00:45, 343.40 examples/s]Tokenizing train dataset:  34%|███▍      | 8226/24227 [00:42<00:46, 343.07 examples/s]Tokenizing train dataset:  30%|██▉       | 7243/24227 [00:41<01:53, 149.39 examples/s]Tokenizing train dataset:  36%|███▌      | 8654/24227 [00:42<00:39, 396.47 examples/s]Tokenizing train dataset:  34%|███▍      | 8285/24227 [00:42<00:40, 390.02 examples/s]Tokenizing train dataset:  30%|███       | 7270/24227 [00:41<01:40, 168.11 examples/s]Tokenizing train dataset:  36%|███▌      | 8710/24227 [00:42<00:36, 427.67 examples/s]Tokenizing train dataset:  34%|███▍      | 8351/24227 [00:42<00:35, 449.49 examples/s]Tokenizing train dataset:  30%|███       | 7299/24227 [00:41<01:29, 188.46 examples/s]Tokenizing train dataset:  36%|███▌      | 8781/24227 [00:42<00:35, 438.26 examples/s]Tokenizing train dataset:  30%|███       | 7328/24227 [00:41<01:21, 206.09 examples/s]Tokenizing train dataset:  35%|███▍      | 8432/24227 [00:42<00:33, 475.92 examples/s]Tokenizing train dataset:  36%|███▋      | 8830/24227 [00:42<00:34, 448.33 examples/s]Tokenizing train dataset:  30%|███       | 7352/24227 [00:41<01:19, 213.40 examples/s]Tokenizing train dataset:  35%|███▌      | 8514/24227 [00:42<00:31, 496.77 examples/s]Tokenizing train dataset:  37%|███▋      | 8881/24227 [00:42<00:33, 462.23 examples/s]Tokenizing train dataset:  30%|███       | 7380/24227 [00:42<01:15, 223.80 examples/s]Tokenizing train dataset:  35%|███▌      | 8591/24227 [00:43<00:32, 481.49 examples/s]Tokenizing train dataset:  37%|███▋      | 8956/24227 [00:43<00:36, 423.99 examples/s]Tokenizing train dataset:  31%|███       | 7413/24227 [00:42<01:27, 191.33 examples/s]Tokenizing train dataset:  31%|███       | 7442/24227 [00:42<01:20, 209.63 examples/s]Tokenizing train dataset:  36%|███▌      | 8670/24227 [00:43<00:35, 434.61 examples/s]Tokenizing train dataset:  37%|███▋      | 9030/24227 [00:43<00:36, 420.56 examples/s]Tokenizing train dataset:  31%|███       | 7478/24227 [00:42<01:08, 242.84 examples/s]Tokenizing train dataset:  36%|███▌      | 8738/24227 [00:43<00:32, 481.30 examples/s]Tokenizing train dataset:  37%|███▋      | 9076/24227 [00:43<00:36, 411.74 examples/s]Tokenizing train dataset:  31%|███       | 7509/24227 [00:42<01:05, 256.95 examples/s]Tokenizing train dataset:  36%|███▋      | 8800/24227 [00:43<00:35, 433.02 examples/s]Tokenizing train dataset:  38%|███▊      | 9136/24227 [00:43<00:38, 392.98 examples/s]Tokenizing train dataset:  31%|███       | 7550/24227 [00:42<01:04, 257.16 examples/s]Tokenizing train dataset:  37%|███▋      | 8871/24227 [00:43<00:39, 390.19 examples/s]Tokenizing train dataset:  38%|███▊      | 9208/24227 [00:43<00:41, 362.96 examples/s]Tokenizing train dataset:  31%|███▏      | 7583/24227 [00:42<01:16, 217.41 examples/s]Tokenizing train dataset:  38%|███▊      | 9248/24227 [00:43<00:41, 363.78 examples/s]Tokenizing train dataset:  37%|███▋      | 8944/24227 [00:43<00:37, 406.98 examples/s]Tokenizing train dataset:  31%|███▏      | 7615/24227 [00:43<01:30, 182.94 examples/s]Tokenizing train dataset:  38%|███▊      | 9287/24227 [00:44<00:47, 312.58 examples/s]Tokenizing train dataset:  37%|███▋      | 8989/24227 [00:44<00:43, 352.44 examples/s]Tokenizing train dataset:  38%|███▊      | 9326/24227 [00:44<00:47, 316.51 examples/s]Tokenizing train dataset:  37%|███▋      | 9038/24227 [00:44<00:40, 378.37 examples/s]Tokenizing train dataset:  32%|███▏      | 7648/24227 [00:43<01:29, 184.35 examples/s]Tokenizing train dataset:  39%|███▊      | 9361/24227 [00:44<00:48, 308.99 examples/s]Tokenizing train dataset:  37%|███▋      | 9082/24227 [00:44<00:41, 365.93 examples/s]Tokenizing train dataset:  39%|███▉      | 9394/24227 [00:44<00:47, 309.08 examples/s]Tokenizing train dataset:  32%|███▏      | 7699/24227 [00:43<01:17, 212.53 examples/s]Tokenizing train dataset:  38%|███▊      | 9128/24227 [00:44<00:39, 386.16 examples/s]Tokenizing train dataset:  39%|███▉      | 9441/24227 [00:44<00:42, 345.79 examples/s]Tokenizing train dataset:  32%|███▏      | 7727/24227 [00:43<01:15, 217.44 examples/s]Tokenizing train dataset:  38%|███▊      | 9199/24227 [00:44<00:36, 409.13 examples/s]Tokenizing train dataset:  39%|███▉      | 9481/24227 [00:44<00:42, 344.05 examples/s]Tokenizing train dataset:  32%|███▏      | 7768/24227 [00:43<01:04, 254.16 examples/s]Tokenizing train dataset:  38%|███▊      | 9273/24227 [00:44<00:36, 411.73 examples/s]Tokenizing train dataset:  39%|███▉      | 9519/24227 [00:44<00:50, 293.17 examples/s]Tokenizing train dataset:  32%|███▏      | 7803/24227 [00:43<01:10, 231.41 examples/s]Tokenizing train dataset:  39%|███▊      | 9330/24227 [00:44<00:33, 445.16 examples/s]Tokenizing train dataset:  40%|███▉      | 9570/24227 [00:45<00:43, 340.55 examples/s]Tokenizing train dataset:  32%|███▏      | 7860/24227 [00:44<00:54, 302.33 examples/s]Tokenizing train dataset:  39%|███▊      | 9381/24227 [00:44<00:32, 458.39 examples/s]Tokenizing train dataset:  33%|███▎      | 7898/24227 [00:44<00:51, 320.07 examples/s]Tokenizing train dataset:  40%|███▉      | 9638/24227 [00:45<00:39, 373.76 examples/s]Tokenizing train dataset:  39%|███▉      | 9448/24227 [00:45<00:28, 510.41 examples/s]Tokenizing train dataset:  33%|███▎      | 7951/24227 [00:44<00:43, 371.43 examples/s]Tokenizing train dataset:  40%|████      | 9704/24227 [00:45<00:33, 438.38 examples/s]Tokenizing train dataset:  39%|███▉      | 9506/24227 [00:45<00:27, 527.25 examples/s]Tokenizing train dataset:  33%|███▎      | 8017/24227 [00:44<00:36, 446.02 examples/s]Tokenizing train dataset:  40%|████      | 9777/24227 [00:45<00:33, 437.33 examples/s]Tokenizing train dataset:  40%|███▉      | 9571/24227 [00:45<00:31, 466.22 examples/s]Tokenizing train dataset:  33%|███▎      | 8082/24227 [00:44<00:39, 406.69 examples/s]Tokenizing train dataset:  41%|████      | 9836/24227 [00:45<00:30, 472.29 examples/s]Tokenizing train dataset:  40%|███▉      | 9639/24227 [00:45<00:34, 426.61 examples/s]Tokenizing train dataset:  34%|███▎      | 8154/24227 [00:44<00:37, 427.34 examples/s]Tokenizing train dataset:  41%|████      | 9898/24227 [00:45<00:32, 437.89 examples/s]Tokenizing train dataset:  40%|████      | 9696/24227 [00:45<00:31, 456.48 examples/s]Tokenizing train dataset:  34%|███▍      | 8224/24227 [00:44<00:37, 423.56 examples/s]Tokenizing train dataset:  40%|████      | 9749/24227 [00:45<00:30, 470.22 examples/s]Tokenizing train dataset:  41%|████      | 9985/24227 [00:45<00:29, 480.93 examples/s]Tokenizing train dataset:  34%|███▍      | 8292/24227 [00:44<00:33, 480.41 examples/s]Tokenizing train dataset:  40%|████      | 9810/24227 [00:45<00:28, 498.66 examples/s]Tokenizing train dataset:  34%|███▍      | 8351/24227 [00:45<00:31, 505.90 examples/s]Tokenizing train dataset:  41%|████▏     | 10052/24227 [00:46<00:33, 422.53 examples/s]Tokenizing train dataset:  41%|████      | 9870/24227 [00:46<00:31, 457.49 examples/s]Tokenizing train dataset:  35%|███▍      | 8420/24227 [00:45<00:32, 484.58 examples/s]Tokenizing train dataset:  41%|████      | 9939/24227 [00:46<00:27, 514.61 examples/s]Tokenizing train dataset:  42%|████▏     | 10129/24227 [00:46<00:31, 445.76 examples/s]Tokenizing train dataset:  35%|███▌      | 8498/24227 [00:45<00:31, 494.12 examples/s]Tokenizing train dataset:  41%|████▏     | 10021/24227 [00:46<00:34, 409.34 examples/s]Tokenizing train dataset:  42%|████▏     | 10178/24227 [00:46<00:43, 322.37 examples/s]Tokenizing train dataset:  35%|███▌      | 8564/24227 [00:45<00:34, 455.53 examples/s]Tokenizing train dataset:  42%|████▏     | 10088/24227 [00:46<00:37, 379.91 examples/s]Tokenizing train dataset:  36%|███▌      | 8614/24227 [00:45<00:42, 369.90 examples/s]Tokenizing train dataset:  42%|████▏     | 10219/24227 [00:46<00:53, 263.09 examples/s]Tokenizing train dataset:  42%|████▏     | 10157/24227 [00:46<00:32, 439.05 examples/s]Tokenizing train dataset:  36%|███▌      | 8680/24227 [00:45<00:36, 425.81 examples/s]Tokenizing train dataset:  42%|████▏     | 10255/24227 [00:46<00:50, 277.77 examples/s]Tokenizing train dataset:  36%|███▌      | 8733/24227 [00:45<00:34, 446.93 examples/s]Tokenizing train dataset:  42%|████▏     | 10219/24227 [00:46<00:36, 388.90 examples/s]Tokenizing train dataset:  42%|████▏     | 10291/24227 [00:47<00:57, 243.97 examples/s]Tokenizing train dataset:  36%|███▋      | 8793/24227 [00:46<00:36, 418.23 examples/s]Tokenizing train dataset:  42%|████▏     | 10280/24227 [00:47<00:39, 354.88 examples/s]Tokenizing train dataset:  43%|████▎     | 10329/24227 [00:47<01:01, 226.58 examples/s]Tokenizing train dataset:  37%|███▋      | 8859/24227 [00:46<00:39, 391.75 examples/s]Tokenizing train dataset:  43%|████▎     | 10333/24227 [00:47<00:47, 289.93 examples/s]Tokenizing train dataset:  43%|████▎     | 10370/24227 [00:47<01:05, 211.58 examples/s]Tokenizing train dataset:  37%|███▋      | 8935/24227 [00:46<00:40, 375.30 examples/s]Tokenizing train dataset:  43%|████▎     | 10406/24227 [00:47<00:58, 236.41 examples/s]Tokenizing train dataset:  37%|███▋      | 8999/24227 [00:46<00:35, 425.85 examples/s]Tokenizing train dataset:  43%|████▎     | 10382/24227 [00:47<00:46, 296.40 examples/s]Tokenizing train dataset:  43%|████▎     | 10445/24227 [00:47<00:57, 238.41 examples/s]Tokenizing train dataset:  37%|███▋      | 9079/24227 [00:46<00:35, 423.47 examples/s]Tokenizing train dataset:  43%|████▎     | 10479/24227 [00:47<00:53, 256.93 examples/s]Tokenizing train dataset:  43%|████▎     | 10423/24227 [00:47<00:55, 249.83 examples/s]Tokenizing train dataset:  38%|███▊      | 9128/24227 [00:46<00:34, 436.52 examples/s]Tokenizing train dataset:  43%|████▎     | 10522/24227 [00:48<00:52, 262.41 examples/s]Tokenizing train dataset:  43%|████▎     | 10466/24227 [00:47<00:53, 256.47 examples/s]Tokenizing train dataset:  38%|███▊      | 9201/24227 [00:47<00:33, 447.40 examples/s]Tokenizing train dataset:  44%|████▎     | 10551/24227 [00:48<00:51, 266.05 examples/s]Tokenizing train dataset:  43%|████▎     | 10504/24227 [00:48<00:58, 235.89 examples/s]Tokenizing train dataset:  38%|███▊      | 9275/24227 [00:47<00:40, 367.36 examples/s]Tokenizing train dataset:  44%|████▎     | 10590/24227 [00:48<01:00, 225.29 examples/s]Tokenizing train dataset:  44%|████▎     | 10543/24227 [00:48<00:57, 237.49 examples/s]Tokenizing train dataset:  39%|███▊      | 9345/24227 [00:47<00:40, 365.57 examples/s]Tokenizing train dataset:  44%|████▍     | 10629/24227 [00:48<01:06, 205.64 examples/s]Tokenizing train dataset:  44%|████▎     | 10580/24227 [00:48<01:07, 202.25 examples/s]Tokenizing train dataset:  39%|███▉      | 9420/24227 [00:47<00:37, 397.56 examples/s]Tokenizing train dataset:  44%|████▍     | 10660/24227 [00:48<01:00, 223.78 examples/s]Tokenizing train dataset:  44%|████▍     | 10612/24227 [00:48<01:01, 221.45 examples/s]Tokenizing train dataset:  39%|███▉      | 9478/24227 [00:47<00:34, 431.35 examples/s]Tokenizing train dataset:  44%|████▍     | 10685/24227 [00:48<00:59, 228.67 examples/s]Tokenizing train dataset:  44%|████▍     | 10651/24227 [00:48<01:02, 216.90 examples/s]Tokenizing train dataset:  39%|███▉      | 9545/24227 [00:48<00:36, 407.52 examples/s]Tokenizing train dataset:  44%|████▍     | 10728/24227 [00:49<01:04, 208.27 examples/s]Tokenizing train dataset:  44%|████▍     | 10685/24227 [00:49<01:13, 183.48 examples/s]Tokenizing train dataset:  40%|███▉      | 9600/24227 [00:48<00:46, 314.99 examples/s]Tokenizing train dataset:  44%|████▍     | 10764/24227 [00:49<01:27, 154.28 examples/s]Tokenizing train dataset:  40%|███▉      | 9638/24227 [00:48<00:52, 276.96 examples/s]Tokenizing train dataset:  44%|████▍     | 10728/24227 [00:49<01:19, 170.05 examples/s]Tokenizing train dataset:  45%|████▍     | 10801/24227 [00:49<01:18, 171.08 examples/s]Tokenizing train dataset:  40%|███▉      | 9673/24227 [00:48<00:52, 276.43 examples/s]Tokenizing train dataset:  44%|████▍     | 10748/24227 [00:49<01:20, 168.16 examples/s]Tokenizing train dataset:  45%|████▍     | 10839/24227 [00:49<01:05, 204.55 examples/s]Tokenizing train dataset:  40%|████      | 9733/24227 [00:48<00:42, 338.49 examples/s]Tokenizing train dataset:  44%|████▍     | 10779/24227 [00:49<01:09, 192.78 examples/s]Tokenizing train dataset:  45%|████▍     | 10864/24227 [00:49<01:02, 212.77 examples/s]Tokenizing train dataset:  40%|████      | 9788/24227 [00:48<00:37, 382.03 examples/s]Tokenizing train dataset:  45%|████▍     | 10815/24227 [00:49<00:59, 226.13 examples/s]Tokenizing train dataset:  45%|████▍     | 10891/24227 [00:49<00:59, 222.45 examples/s]Tokenizing train dataset:  41%|████      | 9859/24227 [00:48<00:35, 409.21 examples/s]Tokenizing train dataset:  45%|████▍     | 10851/24227 [00:49<01:01, 218.38 examples/s]Tokenizing train dataset:  45%|████▌     | 10935/24227 [00:50<00:54, 241.98 examples/s]Tokenizing train dataset:  41%|████      | 9927/24227 [00:49<00:37, 379.53 examples/s]Tokenizing train dataset:  45%|████▍     | 10888/24227 [00:50<01:06, 199.22 examples/s]Tokenizing train dataset:  41%|████      | 9990/24227 [00:49<00:33, 430.53 examples/s]Tokenizing train dataset:  45%|████▌     | 10976/24227 [00:50<01:00, 217.90 examples/s]Tokenizing train dataset:  45%|████▌     | 10920/24227 [00:50<01:08, 194.24 examples/s]Tokenizing train dataset:  41%|████▏     | 10051/24227 [00:49<00:33, 417.69 examples/s]Tokenizing train dataset:  45%|████▌     | 11016/24227 [00:50<00:58, 225.55 examples/s]Tokenizing train dataset:  45%|████▌     | 10941/24227 [00:50<01:12, 182.34 examples/s]Tokenizing train dataset:  46%|████▌     | 11041/24227 [00:50<01:09, 189.24 examples/s]Tokenizing train dataset:  42%|████▏     | 10123/24227 [00:49<00:40, 351.56 examples/s]Tokenizing train dataset:  45%|████▌     | 10986/24227 [00:50<01:02, 211.64 examples/s]Tokenizing train dataset:  46%|████▌     | 11076/24227 [00:50<01:00, 218.96 examples/s]Tokenizing train dataset:  45%|████▌     | 11010/24227 [00:50<01:01, 213.59 examples/s]Tokenizing train dataset:  42%|████▏     | 10176/24227 [00:49<00:40, 347.41 examples/s]Tokenizing train dataset:  46%|████▌     | 11106/24227 [00:50<00:55, 235.20 examples/s]Tokenizing train dataset:  46%|████▌     | 11041/24227 [00:50<00:56, 234.45 examples/s]Tokenizing train dataset:  42%|████▏     | 10218/24227 [00:50<00:43, 324.67 examples/s]Tokenizing train dataset:  46%|████▌     | 11149/24227 [00:50<00:53, 243.15 examples/s]Tokenizing train dataset:  46%|████▌     | 11082/24227 [00:51<00:56, 232.84 examples/s]Tokenizing train dataset:  42%|████▏     | 10270/24227 [00:50<00:42, 325.85 examples/s]Tokenizing train dataset:  46%|████▌     | 11187/24227 [00:51<00:53, 243.79 examples/s]Tokenizing train dataset:  46%|████▌     | 11117/24227 [00:51<01:08, 191.33 examples/s]Tokenizing train dataset:  46%|████▋     | 11226/24227 [00:51<00:57, 225.79 examples/s]Tokenizing train dataset:  43%|████▎     | 10319/24227 [00:50<00:51, 272.47 examples/s]Tokenizing train dataset:  46%|████▌     | 11141/24227 [00:51<01:18, 166.36 examples/s]Tokenizing train dataset:  46%|████▋     | 11261/24227 [00:51<01:08, 189.00 examples/s]Tokenizing train dataset:  43%|████▎     | 10360/24227 [00:50<00:56, 244.50 examples/s]Tokenizing train dataset:  46%|████▌     | 11175/24227 [00:51<01:05, 197.82 examples/s]Tokenizing train dataset:  47%|████▋     | 11290/24227 [00:51<01:02, 206.23 examples/s]Tokenizing train dataset:  46%|████▋     | 11211/24227 [00:51<00:57, 227.72 examples/s]Tokenizing train dataset:  43%|████▎     | 10400/24227 [00:50<00:55, 249.00 examples/s]Tokenizing train dataset:  47%|████▋     | 11315/24227 [00:51<01:00, 213.66 examples/s]Tokenizing train dataset:  46%|████▋     | 11249/24227 [00:51<01:02, 209.25 examples/s]Tokenizing train dataset:  43%|████▎     | 10438/24227 [00:51<01:17, 177.53 examples/s]Tokenizing train dataset:  47%|████▋     | 11357/24227 [00:52<01:17, 165.28 examples/s]Tokenizing train dataset:  47%|████▋     | 11286/24227 [00:52<01:08, 188.76 examples/s]Tokenizing train dataset:  43%|████▎     | 10476/24227 [00:51<01:22, 166.76 examples/s]Tokenizing train dataset:  47%|████▋     | 11388/24227 [00:52<01:29, 143.16 examples/s]Tokenizing train dataset:  47%|████▋     | 11327/24227 [00:52<01:26, 149.61 examples/s]Tokenizing train dataset:  43%|████▎     | 10510/24227 [00:51<01:28, 154.56 examples/s]Tokenizing train dataset:  47%|████▋     | 11421/24227 [00:52<01:34, 136.10 examples/s]Tokenizing train dataset:  47%|████▋     | 11348/24227 [00:52<01:33, 138.46 examples/s]Tokenizing train dataset:  43%|████▎     | 10529/24227 [00:51<01:39, 137.06 examples/s]Tokenizing train dataset:  47%|████▋     | 11443/24227 [00:52<01:44, 122.39 examples/s]Tokenizing train dataset:  47%|████▋     | 11366/24227 [00:52<01:42, 125.21 examples/s]Tokenizing train dataset:  44%|████▎     | 10551/24227 [00:52<01:32, 148.57 examples/s]Tokenizing train dataset:  47%|████▋     | 11463/24227 [00:53<01:37, 131.58 examples/s]Tokenizing train dataset:  47%|████▋     | 11383/24227 [00:53<01:39, 129.59 examples/s]Tokenizing train dataset:  44%|████▎     | 10570/24227 [00:52<01:43, 132.32 examples/s]Tokenizing train dataset:  47%|████▋     | 11487/24227 [00:53<01:31, 139.26 examples/s]Tokenizing train dataset:  47%|████▋     | 11399/24227 [00:53<02:08, 100.19 examples/s]Tokenizing train dataset:  44%|████▎     | 10590/24227 [00:52<01:54, 119.34 examples/s]Tokenizing train dataset:  47%|████▋     | 11507/24227 [00:53<01:53, 111.80 examples/s]Tokenizing train dataset:  47%|████▋     | 11416/24227 [00:53<02:02, 104.92 examples/s]Tokenizing train dataset:  44%|████▍     | 10607/24227 [00:52<01:48, 125.43 examples/s]Tokenizing train dataset:  48%|████▊     | 11525/24227 [00:53<01:52, 112.85 examples/s]Tokenizing train dataset:  47%|████▋     | 11438/24227 [00:53<01:54, 111.93 examples/s]Tokenizing train dataset:  44%|████▍     | 10626/24227 [00:52<02:23, 95.04 examples/s] Tokenizing train dataset:  48%|████▊     | 11544/24227 [00:53<02:04, 101.88 examples/s]Tokenizing train dataset:  47%|████▋     | 11459/24227 [00:53<01:59, 107.01 examples/s]Tokenizing train dataset:  44%|████▍     | 10649/24227 [00:53<01:56, 116.61 examples/s]Tokenizing train dataset:  48%|████▊     | 11572/24227 [00:54<01:35, 131.94 examples/s]Tokenizing train dataset:  47%|████▋     | 11485/24227 [00:53<01:34, 134.26 examples/s]Tokenizing train dataset:  44%|████▍     | 10667/24227 [00:53<02:16, 99.06 examples/s] Tokenizing train dataset:  48%|████▊     | 11591/24227 [00:54<02:01, 103.82 examples/s]Tokenizing train dataset:  47%|████▋     | 11505/24227 [00:54<02:01, 104.42 examples/s]Tokenizing train dataset:  44%|████▍     | 10681/24227 [00:53<02:16, 99.60 examples/s]Tokenizing train dataset:  48%|████▊     | 11620/24227 [00:54<01:33, 134.22 examples/s]Tokenizing train dataset:  48%|████▊     | 11536/24227 [00:54<01:31, 138.84 examples/s]Tokenizing train dataset:  44%|████▍     | 10700/24227 [00:53<02:00, 112.69 examples/s]Tokenizing train dataset:  48%|████▊     | 11641/24227 [00:54<01:30, 138.88 examples/s]Tokenizing train dataset:  44%|████▍     | 10725/24227 [00:53<01:36, 139.96 examples/s]Tokenizing train dataset:  48%|████▊     | 11574/24227 [00:54<01:20, 157.99 examples/s]Tokenizing train dataset:  48%|████▊     | 11659/24227 [00:54<01:26, 145.85 examples/s]Tokenizing train dataset:  44%|████▍     | 10743/24227 [00:53<01:32, 145.91 examples/s]Tokenizing train dataset:  48%|████▊     | 11593/24227 [00:54<01:21, 155.25 examples/s]Tokenizing train dataset:  48%|████▊     | 11678/24227 [00:54<01:27, 143.45 examples/s]Tokenizing train dataset:  44%|████▍     | 10760/24227 [00:53<01:37, 137.46 examples/s]Tokenizing train dataset:  48%|████▊     | 11613/24227 [00:54<01:29, 140.42 examples/s]Tokenizing train dataset:  48%|████▊     | 11697/24227 [00:54<01:36, 129.93 examples/s]Tokenizing train dataset:  44%|████▍     | 10777/24227 [00:54<01:51, 120.33 examples/s]Tokenizing train dataset:  48%|████▊     | 11632/24227 [00:55<01:32, 135.61 examples/s]Tokenizing train dataset:  48%|████▊     | 11718/24227 [00:55<01:35, 130.56 examples/s]Tokenizing train dataset:  45%|████▍     | 10795/24227 [00:54<01:48, 123.64 examples/s]Tokenizing train dataset:  48%|████▊     | 11651/24227 [00:55<01:37, 128.87 examples/s]Tokenizing train dataset:  48%|████▊     | 11737/24227 [00:55<01:35, 131.43 examples/s]Tokenizing train dataset:  45%|████▍     | 10818/24227 [00:54<01:42, 130.25 examples/s]Tokenizing train dataset:  48%|████▊     | 11670/24227 [00:55<01:32, 135.34 examples/s]Tokenizing train dataset:  49%|████▊     | 11757/24227 [00:55<01:27, 142.10 examples/s]Tokenizing train dataset:  45%|████▍     | 10841/24227 [00:54<01:28, 151.68 examples/s]Tokenizing train dataset:  48%|████▊     | 11703/24227 [00:55<01:10, 176.76 examples/s]Tokenizing train dataset:  49%|████▊     | 11785/24227 [00:55<01:11, 173.38 examples/s]Tokenizing train dataset:  45%|████▍     | 10869/24227 [00:54<01:13, 181.58 examples/s]Tokenizing train dataset:  48%|████▊     | 11740/24227 [00:55<01:08, 182.30 examples/s]Tokenizing train dataset:  45%|████▍     | 10890/24227 [00:54<01:28, 151.04 examples/s]Tokenizing train dataset:  49%|████▊     | 11760/24227 [00:55<01:10, 177.38 examples/s]Tokenizing train dataset:  49%|████▉     | 11816/24227 [00:55<01:32, 134.21 examples/s]Tokenizing train dataset:  45%|████▌     | 10907/24227 [00:54<01:26, 153.41 examples/s]Tokenizing train dataset:  49%|████▊     | 11784/24227 [00:55<01:05, 189.79 examples/s]Tokenizing train dataset:  49%|████▉     | 11832/24227 [00:55<01:31, 135.22 examples/s]Tokenizing train dataset:  45%|████▌     | 10943/24227 [00:55<01:20, 165.55 examples/s]Tokenizing train dataset:  49%|████▉     | 11863/24227 [00:56<01:19, 154.95 examples/s]Tokenizing train dataset:  49%|████▉     | 11817/24227 [00:56<01:10, 176.20 examples/s]Tokenizing train dataset:  45%|████▌     | 10975/24227 [00:55<01:06, 197.80 examples/s]Tokenizing train dataset:  49%|████▉     | 11930/24227 [00:56<00:46, 262.45 examples/s]Tokenizing train dataset:  49%|████▉     | 11964/24227 [00:56<00:44, 278.00 examples/s]Tokenizing train dataset:  49%|████▉     | 11867/24227 [00:56<01:01, 200.83 examples/s]Tokenizing train dataset:  45%|████▌     | 11014/24227 [00:55<01:06, 198.48 examples/s]Tokenizing train dataset:  50%|████▉     | 12027/24227 [00:56<00:33, 362.79 examples/s]Tokenizing train dataset:  49%|████▉     | 11923/24227 [00:56<00:45, 272.34 examples/s]Tokenizing train dataset:  46%|████▌     | 11052/24227 [00:55<00:55, 236.31 examples/s]Tokenizing train dataset:  49%|████▉     | 11957/24227 [00:56<00:45, 267.54 examples/s]Tokenizing train dataset:  50%|████▉     | 12097/24227 [00:56<00:32, 371.49 examples/s]Tokenizing train dataset:  46%|████▌     | 11090/24227 [00:55<00:58, 223.27 examples/s]Tokenizing train dataset:  50%|████▉     | 12010/24227 [00:56<00:37, 326.66 examples/s]Tokenizing train dataset:  50%|█████     | 12171/24227 [00:56<00:33, 359.58 examples/s]Tokenizing train dataset:  50%|████▉     | 12052/24227 [00:56<00:43, 276.71 examples/s]Tokenizing train dataset:  46%|████▌     | 11122/24227 [00:55<01:10, 186.81 examples/s]Tokenizing train dataset:  50%|█████     | 12211/24227 [00:56<00:37, 317.83 examples/s]Tokenizing train dataset:  50%|████▉     | 12088/24227 [00:56<00:46, 263.87 examples/s]Tokenizing train dataset:  46%|████▌     | 11144/24227 [00:56<01:20, 162.54 examples/s]Tokenizing train dataset:  51%|█████     | 12250/24227 [00:57<00:41, 289.68 examples/s]Tokenizing train dataset:  50%|█████     | 12126/24227 [00:57<01:00, 201.20 examples/s]Tokenizing train dataset:  51%|█████     | 12285/24227 [00:57<00:52, 227.26 examples/s]Tokenizing train dataset:  46%|████▌     | 11179/24227 [00:56<01:39, 131.45 examples/s]Tokenizing train dataset:  50%|█████     | 12165/24227 [00:57<00:59, 202.08 examples/s]Tokenizing train dataset:  51%|█████     | 12322/24227 [00:57<00:48, 243.74 examples/s]Tokenizing train dataset:  46%|████▌     | 11198/24227 [00:56<01:33, 138.70 examples/s]Tokenizing train dataset:  51%|█████     | 12236/24227 [00:57<00:41, 292.10 examples/s]Tokenizing train dataset:  51%|█████     | 12382/24227 [00:57<00:37, 312.58 examples/s]Tokenizing train dataset:  46%|████▋     | 11230/24227 [00:56<01:16, 168.85 examples/s]Tokenizing train dataset:  51%|█████     | 12301/24227 [00:57<00:32, 362.98 examples/s]Tokenizing train dataset:  51%|█████▏    | 12434/24227 [00:57<00:32, 357.66 examples/s]Tokenizing train dataset:  46%|████▋     | 11265/24227 [00:56<01:19, 162.20 examples/s]Tokenizing train dataset:  51%|█████     | 12378/24227 [00:58<00:41, 282.22 examples/s]Tokenizing train dataset:  52%|█████▏    | 12504/24227 [00:58<00:45, 256.74 examples/s]Tokenizing train dataset:  47%|████▋     | 11300/24227 [00:57<01:26, 149.68 examples/s]Tokenizing train dataset:  52%|█████▏    | 12545/24227 [00:58<00:41, 281.71 examples/s]Tokenizing train dataset:  51%|█████▏    | 12440/24227 [00:58<00:38, 305.61 examples/s]Tokenizing train dataset:  47%|████▋     | 11321/24227 [00:57<01:26, 148.91 examples/s]Tokenizing train dataset:  52%|█████▏    | 12488/24227 [00:58<00:34, 335.62 examples/s]Tokenizing train dataset:  52%|█████▏    | 12614/24227 [00:58<00:35, 323.91 examples/s]Tokenizing train dataset:  47%|████▋     | 11341/24227 [00:57<01:31, 140.99 examples/s]Tokenizing train dataset:  52%|█████▏    | 12655/24227 [00:58<00:39, 291.48 examples/s]Tokenizing train dataset:  52%|█████▏    | 12561/24227 [00:58<00:35, 330.54 examples/s]Tokenizing train dataset:  47%|████▋     | 11361/24227 [00:57<01:45, 121.75 examples/s]Tokenizing train dataset:  52%|█████▏    | 12694/24227 [00:58<00:48, 237.45 examples/s]Tokenizing train dataset:  52%|█████▏    | 12628/24227 [00:58<00:47, 241.79 examples/s]Tokenizing train dataset:  47%|████▋     | 11376/24227 [00:58<02:51, 75.12 examples/s] Tokenizing train dataset:  53%|█████▎    | 12732/24227 [00:59<01:11, 161.85 examples/s]Tokenizing train dataset:  52%|█████▏    | 12671/24227 [00:59<00:54, 211.79 examples/s]Tokenizing train dataset:  47%|████▋     | 11390/24227 [00:58<02:53, 74.02 examples/s]Tokenizing train dataset:  53%|█████▎    | 12768/24227 [00:59<01:05, 173.87 examples/s]Tokenizing train dataset:  52%|█████▏    | 12709/24227 [00:59<00:53, 215.71 examples/s]Tokenizing train dataset:  47%|████▋     | 11405/24227 [00:58<02:38, 81.05 examples/s]Tokenizing train dataset:  53%|█████▎    | 12810/24227 [00:59<00:54, 208.15 examples/s]Tokenizing train dataset:  53%|█████▎    | 12744/24227 [00:59<00:52, 219.93 examples/s]Tokenizing train dataset:  47%|████▋     | 11422/24227 [00:58<02:21, 90.57 examples/s]Tokenizing train dataset:  53%|█████▎    | 12849/24227 [00:59<00:50, 224.17 examples/s]Tokenizing train dataset:  53%|█████▎    | 12783/24227 [00:59<00:46, 248.12 examples/s]Tokenizing train dataset:  47%|████▋     | 11453/24227 [00:58<01:39, 128.69 examples/s]Tokenizing train dataset:  53%|█████▎    | 12885/24227 [00:59<00:48, 231.88 examples/s]Tokenizing train dataset:  53%|█████▎    | 12827/24227 [00:59<00:42, 266.21 examples/s]Tokenizing train dataset:  47%|████▋     | 11471/24227 [00:58<01:37, 130.96 examples/s]Tokenizing train dataset:  53%|█████▎    | 12946/24227 [00:59<00:36, 306.74 examples/s]Tokenizing train dataset:  53%|█████▎    | 12889/24227 [00:59<00:33, 338.10 examples/s]Tokenizing train dataset:  47%|████▋     | 11505/24227 [00:59<01:12, 174.29 examples/s]Tokenizing train dataset:  54%|█████▎    | 13001/24227 [01:00<00:31, 359.32 examples/s]Tokenizing train dataset:  53%|█████▎    | 12960/24227 [01:00<00:30, 366.85 examples/s]Tokenizing train dataset:  48%|████▊     | 11539/24227 [00:59<01:14, 170.10 examples/s]Tokenizing train dataset:  54%|█████▍    | 13076/24227 [01:00<00:32, 345.92 examples/s]Tokenizing train dataset:  54%|█████▍    | 13027/24227 [01:00<00:28, 387.88 examples/s]Tokenizing train dataset:  48%|████▊     | 11564/24227 [00:59<01:08, 185.70 examples/s]Tokenizing train dataset:  54%|█████▍    | 13142/24227 [01:00<00:30, 366.19 examples/s]Tokenizing train dataset:  54%|█████▍    | 13069/24227 [01:00<00:35, 312.62 examples/s]Tokenizing train dataset:  48%|████▊     | 11585/24227 [00:59<01:24, 149.74 examples/s]Tokenizing train dataset:  55%|█████▍    | 13210/24227 [01:00<00:28, 386.71 examples/s]Tokenizing train dataset:  54%|█████▍    | 13115/24227 [01:00<00:32, 341.76 examples/s]Tokenizing train dataset:  55%|█████▍    | 13263/24227 [01:00<00:26, 416.20 examples/s]Tokenizing train dataset:  48%|████▊     | 11620/24227 [00:59<01:14, 170.08 examples/s]Tokenizing train dataset:  54%|█████▍    | 13183/24227 [01:00<00:30, 361.14 examples/s]Tokenizing train dataset:  55%|█████▍    | 13311/24227 [01:00<00:25, 430.11 examples/s]Tokenizing train dataset:  48%|████▊     | 11646/24227 [00:59<01:07, 187.21 examples/s]Tokenizing train dataset:  55%|█████▍    | 13244/24227 [01:00<00:30, 364.30 examples/s]Tokenizing train dataset:  55%|█████▌    | 13380/24227 [01:00<00:25, 420.02 examples/s]Tokenizing train dataset:  48%|████▊     | 11679/24227 [01:00<01:06, 188.20 examples/s]Tokenizing train dataset:  55%|█████▍    | 13295/24227 [01:00<00:27, 393.15 examples/s]Tokenizing train dataset:  48%|████▊     | 11701/24227 [01:00<01:04, 193.47 examples/s]Tokenizing train dataset:  56%|█████▌    | 13460/24227 [01:01<00:23, 453.63 examples/s]Tokenizing train dataset:  48%|████▊     | 11731/24227 [01:00<00:57, 216.93 examples/s]Tokenizing train dataset:  55%|█████▌    | 13363/24227 [01:01<00:26, 409.40 examples/s]Tokenizing train dataset:  56%|█████▌    | 13539/24227 [01:01<00:22, 471.18 examples/s]Tokenizing train dataset:  49%|████▊     | 11766/24227 [01:00<00:58, 211.71 examples/s]Tokenizing train dataset:  55%|█████▌    | 13432/24227 [01:01<00:28, 376.54 examples/s]Tokenizing train dataset:  56%|█████▌    | 13619/24227 [01:01<00:21, 484.27 examples/s]Tokenizing train dataset:  49%|████▊     | 11789/24227 [01:00<00:57, 215.25 examples/s]Tokenizing train dataset:  56%|█████▌    | 13509/24227 [01:01<00:26, 411.25 examples/s]Tokenizing train dataset:  57%|█████▋    | 13700/24227 [01:01<00:21, 486.59 examples/s]Tokenizing train dataset:  49%|████▉     | 11814/24227 [01:00<01:22, 149.62 examples/s]Tokenizing train dataset:  56%|█████▌    | 13589/24227 [01:01<00:26, 406.81 examples/s]Tokenizing train dataset:  57%|█████▋    | 13781/24227 [01:01<00:27, 375.16 examples/s]Tokenizing train dataset:  49%|████▉     | 11856/24227 [01:01<01:14, 165.51 examples/s]Tokenizing train dataset:  56%|█████▋    | 13666/24227 [01:01<00:28, 367.37 examples/s]Tokenizing train dataset:  49%|████▉     | 11888/24227 [01:01<01:09, 178.74 examples/s]Tokenizing train dataset:  57%|█████▋    | 13710/24227 [01:02<00:28, 372.63 examples/s]Tokenizing train dataset:  57%|█████▋    | 13859/24227 [01:02<00:27, 381.88 examples/s]Tokenizing train dataset:  57%|█████▋    | 13905/24227 [01:02<00:26, 395.16 examples/s]Tokenizing train dataset:  49%|████▉     | 11944/24227 [01:01<00:48, 251.52 examples/s]Tokenizing train dataset:  57%|█████▋    | 13771/24227 [01:02<00:24, 419.31 examples/s]Tokenizing train dataset:  58%|█████▊    | 13957/24227 [01:02<00:24, 418.70 examples/s]Tokenizing train dataset:  50%|████▉     | 11995/24227 [01:01<00:39, 306.95 examples/s]Tokenizing train dataset:  57%|█████▋    | 13818/24227 [01:02<00:24, 430.06 examples/s]Tokenizing train dataset:  58%|█████▊    | 14009/24227 [01:02<00:23, 440.27 examples/s]Tokenizing train dataset:  50%|████▉     | 12057/24227 [01:01<00:31, 380.36 examples/s]Tokenizing train dataset:  57%|█████▋    | 13897/24227 [01:02<00:20, 512.92 examples/s]Tokenizing train dataset:  58%|█████▊    | 14079/24227 [01:02<00:22, 443.18 examples/s]Tokenizing train dataset:  50%|█████     | 12125/24227 [01:01<00:32, 372.67 examples/s]Tokenizing train dataset:  58%|█████▊    | 13963/24227 [01:02<00:23, 441.28 examples/s]Tokenizing train dataset:  58%|█████▊    | 14140/24227 [01:02<00:21, 479.39 examples/s]Tokenizing train dataset:  50%|█████     | 12200/24227 [01:01<00:30, 395.37 examples/s]Tokenizing train dataset:  59%|█████▊    | 14208/24227 [01:02<00:19, 521.44 examples/s]Tokenizing train dataset:  58%|█████▊    | 14029/24227 [01:02<00:23, 438.64 examples/s]Tokenizing train dataset:  51%|█████     | 12268/24227 [01:01<00:26, 453.44 examples/s]Tokenizing train dataset:  59%|█████▉    | 14277/24227 [01:03<00:24, 401.03 examples/s]Tokenizing train dataset:  58%|█████▊    | 14096/24227 [01:02<00:29, 343.30 examples/s]Tokenizing train dataset:  51%|█████     | 12340/24227 [01:02<00:30, 389.16 examples/s]Tokenizing train dataset:  59%|█████▉    | 14346/24227 [01:03<00:21, 459.95 examples/s]Tokenizing train dataset:  58%|█████▊    | 14171/24227 [01:03<00:24, 414.72 examples/s]Tokenizing train dataset:  51%|█████     | 12404/24227 [01:02<00:29, 394.87 examples/s]Tokenizing train dataset:  59%|█████▉    | 14407/24227 [01:03<00:22, 442.23 examples/s]Tokenizing train dataset:  59%|█████▉    | 14256/24227 [01:03<00:21, 455.56 examples/s]Tokenizing train dataset:  51%|█████▏    | 12469/24227 [01:02<00:29, 402.79 examples/s]Tokenizing train dataset:  60%|█████▉    | 14479/24227 [01:03<00:21, 445.26 examples/s]Tokenizing train dataset:  59%|█████▉    | 14330/24227 [01:03<00:22, 442.44 examples/s]Tokenizing train dataset:  52%|█████▏    | 12528/24227 [01:02<00:26, 440.70 examples/s]Tokenizing train dataset:  59%|█████▉    | 14390/24227 [01:03<00:20, 472.35 examples/s]Tokenizing train dataset:  60%|██████    | 14548/24227 [01:03<00:22, 428.25 examples/s]Tokenizing train dataset:  52%|█████▏    | 12600/24227 [01:02<00:27, 422.15 examples/s]Tokenizing train dataset:  60%|█████▉    | 14454/24227 [01:03<00:19, 508.87 examples/s]Tokenizing train dataset:  60%|██████    | 14608/24227 [01:03<00:20, 462.40 examples/s]Tokenizing train dataset:  52%|█████▏    | 12649/24227 [01:02<00:26, 433.53 examples/s]Tokenizing train dataset:  60%|█████▉    | 14526/24227 [01:03<00:19, 490.43 examples/s]Tokenizing train dataset:  61%|██████    | 14686/24227 [01:03<00:19, 479.64 examples/s]Tokenizing train dataset:  53%|█████▎    | 12722/24227 [01:03<00:25, 445.00 examples/s]Tokenizing train dataset:  60%|██████    | 14597/24227 [01:03<00:20, 479.71 examples/s]Tokenizing train dataset:  61%|██████    | 14737/24227 [01:04<00:22, 425.72 examples/s]Tokenizing train dataset:  53%|█████▎    | 12799/24227 [01:03<00:27, 412.84 examples/s]Tokenizing train dataset:  61%|██████    | 14673/24227 [01:04<00:21, 451.99 examples/s]Tokenizing train dataset:  61%|██████    | 14797/24227 [01:04<00:25, 371.29 examples/s]Tokenizing train dataset:  53%|█████▎    | 12869/24227 [01:03<00:28, 396.59 examples/s]Tokenizing train dataset:  61%|██████    | 14731/24227 [01:04<00:23, 406.11 examples/s]Tokenizing train dataset:  61%|██████    | 14837/24227 [01:04<00:27, 337.66 examples/s]Tokenizing train dataset:  53%|█████▎    | 12914/24227 [01:03<00:27, 406.63 examples/s]Tokenizing train dataset:  61%|██████    | 14790/24227 [01:04<00:33, 281.97 examples/s]Tokenizing train dataset:  61%|██████▏   | 14877/24227 [01:04<00:54, 172.92 examples/s]Tokenizing train dataset:  54%|█████▎    | 12980/24227 [01:04<00:48, 230.37 examples/s]Tokenizing train dataset:  61%|██████    | 14828/24227 [01:05<00:42, 223.09 examples/s]Tokenizing train dataset:  62%|██████▏   | 14917/24227 [01:05<00:51, 181.55 examples/s]Tokenizing train dataset:  54%|█████▎    | 13014/24227 [01:04<00:51, 219.14 examples/s]Tokenizing train dataset:  61%|██████▏   | 14868/24227 [01:05<00:43, 213.61 examples/s]Tokenizing train dataset:  54%|█████▍    | 13070/24227 [01:04<00:41, 268.56 examples/s]Tokenizing train dataset:  62%|██████▏   | 14959/24227 [01:05<00:46, 198.82 examples/s]Tokenizing train dataset:  62%|██████▏   | 14901/24227 [01:05<00:40, 229.66 examples/s]Tokenizing train dataset:  54%|█████▍    | 13119/24227 [01:04<00:36, 305.72 examples/s]Tokenizing train dataset:  62%|██████▏   | 14996/24227 [01:05<00:48, 189.92 examples/s]Tokenizing train dataset:  62%|██████▏   | 14939/24227 [01:05<00:49, 189.12 examples/s]Tokenizing train dataset:  62%|██████▏   | 15020/24227 [01:05<00:58, 158.54 examples/s]Tokenizing train dataset:  54%|█████▍    | 13185/24227 [01:04<00:48, 225.51 examples/s]Tokenizing train dataset:  62%|██████▏   | 14976/24227 [01:05<00:48, 190.34 examples/s]Tokenizing train dataset:  62%|██████▏   | 15041/24227 [01:05<00:55, 165.11 examples/s]Tokenizing train dataset:  55%|█████▍    | 13223/24227 [01:05<00:44, 247.12 examples/s]Tokenizing train dataset:  62%|██████▏   | 15018/24227 [01:06<00:46, 198.86 examples/s]Tokenizing train dataset:  62%|██████▏   | 15062/24227 [01:06<01:00, 152.61 examples/s]Tokenizing train dataset:  55%|█████▍    | 13282/24227 [01:05<00:42, 257.84 examples/s]Tokenizing train dataset:  62%|██████▏   | 15059/24227 [01:06<00:44, 204.01 examples/s]Tokenizing train dataset:  62%|██████▏   | 15082/24227 [01:06<01:08, 134.16 examples/s]Tokenizing train dataset:  55%|█████▌    | 13346/24227 [01:05<00:41, 259.50 examples/s]Tokenizing train dataset:  62%|██████▏   | 15096/24227 [01:06<00:46, 197.92 examples/s]Tokenizing train dataset:  62%|██████▏   | 15100/24227 [01:06<01:13, 124.68 examples/s]Tokenizing train dataset:  55%|█████▌    | 13402/24227 [01:05<00:38, 280.22 examples/s]Tokenizing train dataset:  62%|██████▏   | 15127/24227 [01:06<00:41, 217.04 examples/s]Tokenizing train dataset:  62%|██████▏   | 15121/24227 [01:06<01:20, 112.42 examples/s]Tokenizing train dataset:  55%|█████▌    | 13444/24227 [01:05<00:40, 268.60 examples/s]Tokenizing train dataset:  63%|██████▎   | 15170/24227 [01:06<00:49, 183.59 examples/s]Tokenizing train dataset:  62%|██████▏   | 15141/24227 [01:06<01:19, 113.58 examples/s]Tokenizing train dataset:  56%|█████▌    | 13482/24227 [01:05<00:41, 256.74 examples/s]Tokenizing train dataset:  63%|██████▎   | 15197/24227 [01:06<00:45, 197.79 examples/s]Tokenizing train dataset:  63%|██████▎   | 15166/24227 [01:07<01:07, 135.01 examples/s]Tokenizing train dataset:  56%|█████▌    | 13518/24227 [01:06<00:55, 193.44 examples/s]Tokenizing train dataset:  63%|██████▎   | 15186/24227 [01:07<01:28, 101.90 examples/s]Tokenizing train dataset:  56%|█████▌    | 13556/24227 [01:06<00:48, 221.66 examples/s]Tokenizing train dataset:  63%|██████▎   | 15234/24227 [01:07<00:59, 151.63 examples/s]Tokenizing train dataset:  63%|██████▎   | 15210/24227 [01:07<01:12, 124.07 examples/s]Tokenizing train dataset:  56%|█████▌    | 13595/24227 [01:06<00:42, 252.18 examples/s]Tokenizing train dataset:  63%|██████▎   | 15255/24227 [01:07<01:00, 149.00 examples/s]Tokenizing train dataset:  63%|██████▎   | 15240/24227 [01:07<00:57, 156.33 examples/s]Tokenizing train dataset:  56%|█████▋    | 13647/24227 [01:06<00:34, 306.87 examples/s]Tokenizing train dataset:  63%|██████▎   | 15276/24227 [01:07<00:56, 158.06 examples/s]Tokenizing train dataset:  63%|██████▎   | 15261/24227 [01:07<00:53, 167.20 examples/s]Tokenizing train dataset:  56%|█████▋    | 13686/24227 [01:06<00:32, 323.90 examples/s]Tokenizing train dataset:  63%|██████▎   | 15311/24227 [01:07<00:45, 194.26 examples/s]Tokenizing train dataset:  63%|██████▎   | 15291/24227 [01:07<00:45, 196.96 examples/s]Tokenizing train dataset:  57%|█████▋    | 13742/24227 [01:06<00:27, 379.85 examples/s]Tokenizing train dataset:  63%|██████▎   | 15350/24227 [01:07<00:42, 208.45 examples/s]Tokenizing train dataset:  63%|██████▎   | 15330/24227 [01:07<00:41, 215.73 examples/s]Tokenizing train dataset:  57%|█████▋    | 13817/24227 [01:07<00:31, 332.79 examples/s]Tokenizing train dataset:  64%|██████▎   | 15386/24227 [01:08<00:47, 185.21 examples/s]Tokenizing train dataset:  63%|██████▎   | 15367/24227 [01:08<00:46, 189.64 examples/s]Tokenizing train dataset:  57%|█████▋    | 13858/24227 [01:07<00:31, 327.20 examples/s]Tokenizing train dataset:  64%|██████▎   | 15419/24227 [01:08<00:41, 211.45 examples/s]Tokenizing train dataset:  64%|██████▎   | 15390/24227 [01:08<00:44, 197.63 examples/s]Tokenizing train dataset:  57%|█████▋    | 13912/24227 [01:07<00:27, 371.73 examples/s]Tokenizing train dataset:  64%|██████▍   | 15446/24227 [01:08<00:39, 222.30 examples/s]Tokenizing train dataset:  64%|██████▎   | 15420/24227 [01:08<00:40, 219.13 examples/s]Tokenizing train dataset:  58%|█████▊    | 13976/24227 [01:07<00:27, 379.66 examples/s]Tokenizing train dataset:  64%|██████▍   | 15448/24227 [01:08<00:37, 232.85 examples/s]Tokenizing train dataset:  64%|██████▍   | 15484/24227 [01:08<00:37, 231.33 examples/s]Tokenizing train dataset:  58%|█████▊    | 14038/24227 [01:07<00:26, 377.86 examples/s]Tokenizing train dataset:  64%|██████▍   | 15484/24227 [01:08<00:39, 223.80 examples/s]Tokenizing train dataset:  58%|█████▊    | 14078/24227 [01:07<00:26, 381.47 examples/s]Tokenizing train dataset:  64%|██████▍   | 15523/24227 [01:08<00:41, 211.73 examples/s]Tokenizing train dataset:  64%|██████▍   | 15516/24227 [01:08<00:35, 246.29 examples/s]Tokenizing train dataset:  58%|█████▊    | 14118/24227 [01:07<00:30, 327.66 examples/s]Tokenizing train dataset:  64%|██████▍   | 15560/24227 [01:08<00:45, 189.57 examples/s]Tokenizing train dataset:  59%|█████▊    | 14173/24227 [01:08<00:26, 376.51 examples/s]Tokenizing train dataset:  64%|██████▍   | 15554/24227 [01:08<00:44, 196.03 examples/s]Tokenizing train dataset:  64%|██████▍   | 15583/24227 [01:08<00:45, 190.50 examples/s]Tokenizing train dataset:  59%|█████▉    | 14240/24227 [01:08<00:28, 350.43 examples/s]Tokenizing train dataset:  64%|██████▍   | 15595/24227 [01:09<00:45, 190.49 examples/s]Tokenizing train dataset:  64%|██████▍   | 15619/24227 [01:09<00:53, 160.74 examples/s]Tokenizing train dataset:  59%|█████▉    | 14312/24227 [01:08<00:28, 348.61 examples/s]Tokenizing train dataset:  65%|██████▍   | 15630/24227 [01:09<00:45, 188.05 examples/s]Tokenizing train dataset:  65%|██████▍   | 15648/24227 [01:09<00:47, 182.32 examples/s]Tokenizing train dataset:  59%|█████▉    | 14369/24227 [01:08<00:25, 391.61 examples/s]Tokenizing train dataset:  65%|██████▍   | 15657/24227 [01:09<00:42, 202.33 examples/s]Tokenizing train dataset:  65%|██████▍   | 15681/24227 [01:09<00:40, 210.91 examples/s]Tokenizing train dataset:  60%|█████▉    | 14433/24227 [01:08<00:27, 353.55 examples/s]Tokenizing train dataset:  65%|██████▍   | 15698/24227 [01:09<00:43, 197.75 examples/s]Tokenizing train dataset:  65%|██████▍   | 15728/24227 [01:09<00:38, 219.01 examples/s]Tokenizing train dataset:  60%|█████▉    | 14480/24227 [01:08<00:25, 375.28 examples/s]Tokenizing train dataset:  65%|██████▍   | 15720/24227 [01:09<00:43, 196.25 examples/s]Tokenizing train dataset:  65%|██████▌   | 15768/24227 [01:09<00:36, 229.39 examples/s]Tokenizing train dataset:  60%|██████    | 14547/24227 [01:09<00:25, 379.69 examples/s]Tokenizing train dataset:  65%|██████▍   | 15741/24227 [01:10<00:48, 174.51 examples/s]Tokenizing train dataset:  65%|██████▌   | 15807/24227 [01:10<00:36, 230.39 examples/s]Tokenizing train dataset:  60%|██████    | 14589/24227 [01:09<00:24, 387.50 examples/s]Tokenizing train dataset:  65%|██████▌   | 15773/24227 [01:10<00:41, 204.60 examples/s]Tokenizing train dataset:  65%|██████▌   | 15838/24227 [01:10<00:34, 243.20 examples/s]Tokenizing train dataset:  60%|██████    | 14630/24227 [01:09<00:25, 381.94 examples/s]Tokenizing train dataset:  65%|██████▌   | 15799/24227 [01:10<00:38, 216.38 examples/s]Tokenizing train dataset:  66%|██████▌   | 15880/24227 [01:10<00:33, 250.86 examples/s]Tokenizing train dataset:  61%|██████    | 14695/24227 [01:09<00:24, 395.42 examples/s]Tokenizing train dataset:  65%|██████▌   | 15838/24227 [01:10<00:39, 210.25 examples/s]Tokenizing train dataset:  66%|██████▌   | 15920/24227 [01:10<00:33, 248.31 examples/s]Tokenizing train dataset:  61%|██████    | 14750/24227 [01:09<00:28, 327.62 examples/s]Tokenizing train dataset:  66%|██████▌   | 15876/24227 [01:10<00:39, 209.66 examples/s]Tokenizing train dataset:  66%|██████▌   | 15959/24227 [01:10<00:33, 245.85 examples/s]Tokenizing train dataset:  61%|██████    | 14796/24227 [01:09<00:26, 352.93 examples/s]Tokenizing train dataset:  66%|██████▌   | 15909/24227 [01:10<00:35, 234.04 examples/s]Tokenizing train dataset:  66%|██████▌   | 15995/24227 [01:10<00:34, 241.57 examples/s]Tokenizing train dataset:  66%|██████▌   | 15946/24227 [01:10<00:36, 224.69 examples/s]Tokenizing train dataset:  61%|██████▏   | 14851/24227 [01:09<00:30, 305.86 examples/s]Tokenizing train dataset:  66%|██████▌   | 16021/24227 [01:10<00:33, 244.35 examples/s]Tokenizing train dataset:  66%|██████▌   | 15976/24227 [01:10<00:34, 238.14 examples/s]Tokenizing train dataset:  61%|██████▏   | 14889/24227 [01:10<00:39, 234.16 examples/s]Tokenizing train dataset:  66%|██████▋   | 16061/24227 [01:11<00:42, 193.81 examples/s]Tokenizing train dataset:  66%|██████▌   | 16017/24227 [01:11<00:39, 209.46 examples/s]Tokenizing train dataset:  62%|██████▏   | 14928/24227 [01:10<00:41, 222.73 examples/s]Tokenizing train dataset:  66%|██████▋   | 16057/24227 [01:11<00:40, 203.32 examples/s]Tokenizing train dataset:  66%|██████▋   | 16102/24227 [01:11<00:41, 194.41 examples/s]Tokenizing train dataset:  62%|██████▏   | 14954/24227 [01:10<00:40, 227.64 examples/s]Tokenizing train dataset:  67%|██████▋   | 16131/24227 [01:11<00:38, 211.00 examples/s]Tokenizing train dataset:  66%|██████▋   | 16082/24227 [01:11<00:38, 210.46 examples/s]Tokenizing train dataset:  67%|██████▋   | 16165/24227 [01:11<00:34, 236.49 examples/s]Tokenizing train dataset:  67%|██████▋   | 16120/24227 [01:11<00:33, 242.37 examples/s]Tokenizing train dataset:  62%|██████▏   | 14994/24227 [01:10<00:39, 234.54 examples/s]Tokenizing train dataset:  67%|██████▋   | 16207/24227 [01:11<00:32, 246.97 examples/s]Tokenizing train dataset:  67%|██████▋   | 16162/24227 [01:11<00:34, 237.07 examples/s]Tokenizing train dataset:  62%|██████▏   | 15035/24227 [01:10<00:41, 221.01 examples/s]Tokenizing train dataset:  67%|██████▋   | 16242/24227 [01:11<00:33, 237.48 examples/s]Tokenizing train dataset:  62%|██████▏   | 15072/24227 [01:11<00:36, 247.48 examples/s]Tokenizing train dataset:  67%|██████▋   | 16206/24227 [01:11<00:32, 250.24 examples/s]Tokenizing train dataset:  67%|██████▋   | 16273/24227 [01:11<00:31, 251.56 examples/s]Tokenizing train dataset:  62%|██████▏   | 15105/24227 [01:11<00:34, 264.06 examples/s]Tokenizing train dataset:  67%|██████▋   | 16239/24227 [01:12<00:30, 264.99 examples/s]Tokenizing train dataset:  67%|██████▋   | 16309/24227 [01:12<00:33, 233.37 examples/s]Tokenizing train dataset:  63%|██████▎   | 15142/24227 [01:11<00:39, 232.36 examples/s]Tokenizing train dataset:  67%|██████▋   | 16279/24227 [01:12<00:34, 229.59 examples/s]Tokenizing train dataset:  63%|██████▎   | 15177/24227 [01:11<00:35, 253.27 examples/s]Tokenizing train dataset:  67%|██████▋   | 16350/24227 [01:12<00:33, 237.31 examples/s]Tokenizing train dataset:  67%|██████▋   | 16304/24227 [01:12<00:34, 231.57 examples/s]Tokenizing train dataset:  63%|██████▎   | 15205/24227 [01:11<00:35, 256.48 examples/s]Tokenizing train dataset:  68%|██████▊   | 16387/24227 [01:12<00:32, 237.63 examples/s]Tokenizing train dataset:  67%|██████▋   | 16344/24227 [01:12<00:32, 239.49 examples/s]Tokenizing train dataset:  63%|██████▎   | 15247/24227 [01:11<00:34, 261.06 examples/s]Tokenizing train dataset:  68%|██████▊   | 16423/24227 [01:12<00:37, 208.09 examples/s]Tokenizing train dataset:  68%|██████▊   | 16377/24227 [01:12<00:42, 183.91 examples/s]Tokenizing train dataset:  63%|██████▎   | 15283/24227 [01:11<00:40, 221.66 examples/s]Tokenizing train dataset:  68%|██████▊   | 16459/24227 [01:12<00:37, 207.71 examples/s]Tokenizing train dataset:  68%|██████▊   | 16407/24227 [01:12<00:38, 203.34 examples/s]Tokenizing train dataset:  63%|██████▎   | 15320/24227 [01:12<00:47, 188.57 examples/s]Tokenizing train dataset:  68%|██████▊   | 16517/24227 [01:13<00:43, 177.32 examples/s]Tokenizing train dataset:  68%|██████▊   | 16441/24227 [01:13<00:55, 140.49 examples/s]Tokenizing train dataset:  63%|██████▎   | 15355/24227 [01:12<00:51, 170.98 examples/s]Tokenizing train dataset:  68%|██████▊   | 16560/24227 [01:13<00:36, 210.28 examples/s]Tokenizing train dataset:  63%|██████▎   | 15376/24227 [01:12<00:50, 176.96 examples/s]Tokenizing train dataset:  68%|██████▊   | 16478/24227 [01:13<00:48, 161.10 examples/s]Tokenizing train dataset:  69%|██████▊   | 16599/24227 [01:13<00:32, 238.00 examples/s]Tokenizing train dataset:  64%|██████▎   | 15397/24227 [01:12<00:48, 182.08 examples/s]Tokenizing train dataset:  68%|██████▊   | 16549/24227 [01:13<00:30, 251.66 examples/s]Tokenizing train dataset:  69%|██████▊   | 16647/24227 [01:13<00:26, 284.58 examples/s]Tokenizing train dataset:  64%|██████▎   | 15427/24227 [01:12<00:42, 207.10 examples/s]Tokenizing train dataset:  68%|██████▊   | 16592/24227 [01:13<00:27, 280.25 examples/s]Tokenizing train dataset:  69%|██████▉   | 16691/24227 [01:13<00:23, 317.14 examples/s]Tokenizing train dataset:  64%|██████▍   | 15450/24227 [01:12<00:41, 209.78 examples/s]Tokenizing train dataset:  69%|██████▊   | 16652/24227 [01:14<00:29, 253.45 examples/s]Tokenizing train dataset:  69%|██████▉   | 16729/24227 [01:13<00:31, 241.17 examples/s]Tokenizing train dataset:  69%|██████▉   | 16688/24227 [01:14<00:31, 237.64 examples/s]Tokenizing train dataset:  64%|██████▍   | 15486/24227 [01:13<01:05, 134.37 examples/s]Tokenizing train dataset:  69%|██████▉   | 16767/24227 [01:14<00:33, 222.13 examples/s]Tokenizing train dataset:  69%|██████▉   | 16760/24227 [01:14<00:23, 321.96 examples/s]Tokenizing train dataset:  69%|██████▉   | 16836/24227 [01:14<00:23, 309.04 examples/s]Tokenizing train dataset:  64%|██████▍   | 15520/24227 [01:13<00:52, 165.79 examples/s]Tokenizing train dataset:  69%|██████▉   | 16805/24227 [01:14<00:21, 346.82 examples/s]Tokenizing train dataset:  70%|██████▉   | 16896/24227 [01:14<00:19, 367.89 examples/s]Tokenizing train dataset:  64%|██████▍   | 15549/24227 [01:13<00:46, 186.99 examples/s]Tokenizing train dataset:  70%|██████▉   | 16849/24227 [01:14<00:20, 366.07 examples/s]Tokenizing train dataset:  70%|██████▉   | 16949/24227 [01:14<00:18, 401.95 examples/s]Tokenizing train dataset:  64%|██████▍   | 15590/24227 [01:13<00:50, 170.51 examples/s]Tokenizing train dataset:  70%|██████▉   | 16921/24227 [01:14<00:22, 324.54 examples/s]Tokenizing train dataset:  70%|███████   | 17026/24227 [01:14<00:21, 341.85 examples/s]Tokenizing train dataset:  64%|██████▍   | 15618/24227 [01:13<00:45, 189.28 examples/s]Tokenizing train dataset:  70%|███████   | 16993/24227 [01:14<00:21, 334.15 examples/s]Tokenizing train dataset:  71%|███████   | 17100/24227 [01:14<00:21, 328.85 examples/s]Tokenizing train dataset:  65%|██████▍   | 15656/24227 [01:14<00:56, 152.98 examples/s]Tokenizing train dataset:  70%|███████   | 17030/24227 [01:15<00:27, 260.34 examples/s]Tokenizing train dataset:  71%|███████   | 17145/24227 [01:15<00:24, 287.30 examples/s]Tokenizing train dataset:  70%|███████   | 17079/24227 [01:15<00:23, 299.28 examples/s]Tokenizing train dataset:  65%|██████▍   | 15695/24227 [01:14<00:50, 167.45 examples/s]Tokenizing train dataset:  71%|███████   | 17200/24227 [01:15<00:21, 331.54 examples/s]Tokenizing train dataset:  71%|███████   | 17152/24227 [01:15<00:18, 383.43 examples/s]Tokenizing train dataset:  65%|██████▍   | 15730/24227 [01:14<00:43, 196.73 examples/s]Tokenizing train dataset:  71%|███████   | 17260/24227 [01:15<00:18, 384.16 examples/s]Tokenizing train dataset:  71%|███████   | 17209/24227 [01:15<00:16, 417.64 examples/s]Tokenizing train dataset:  65%|██████▌   | 15761/24227 [01:14<00:38, 217.89 examples/s]Tokenizing train dataset:  72%|███████▏  | 17330/24227 [01:15<00:15, 451.01 examples/s]Tokenizing train dataset:  71%|███████▏  | 17262/24227 [01:15<00:15, 443.28 examples/s]Tokenizing train dataset:  65%|██████▌   | 15794/24227 [01:14<00:43, 193.48 examples/s]Tokenizing train dataset:  72%|███████▏  | 17410/24227 [01:15<00:18, 364.31 examples/s]Tokenizing train dataset:  72%|███████▏  | 17338/24227 [01:15<00:18, 369.96 examples/s]Tokenizing train dataset:  65%|██████▌   | 15832/24227 [01:15<00:43, 192.90 examples/s]Tokenizing train dataset:  72%|███████▏  | 17457/24227 [01:15<00:17, 383.04 examples/s]Tokenizing train dataset:  72%|███████▏  | 17403/24227 [01:16<00:16, 426.34 examples/s]Tokenizing train dataset:  65%|██████▌   | 15858/24227 [01:15<00:41, 203.83 examples/s]Tokenizing train dataset:  72%|███████▏  | 17456/24227 [01:16<00:15, 445.70 examples/s]Tokenizing train dataset:  72%|███████▏  | 17531/24227 [01:16<00:16, 411.21 examples/s]Tokenizing train dataset:  66%|██████▌   | 15896/24227 [01:15<00:47, 176.55 examples/s]Tokenizing train dataset:  72%|███████▏  | 17519/24227 [01:16<00:21, 318.51 examples/s]Tokenizing train dataset:  66%|██████▌   | 15916/24227 [01:15<00:48, 170.96 examples/s]Tokenizing train dataset:  73%|███████▎  | 17589/24227 [01:16<00:23, 281.91 examples/s]Tokenizing train dataset:  73%|███████▎  | 17575/24227 [01:16<00:18, 362.37 examples/s]Tokenizing train dataset:  66%|██████▌   | 15944/24227 [01:15<00:43, 192.01 examples/s]Tokenizing train dataset:  73%|███████▎  | 17656/24227 [01:16<00:19, 342.93 examples/s]Tokenizing train dataset:  73%|███████▎  | 17642/24227 [01:16<00:17, 369.56 examples/s]Tokenizing train dataset:  73%|███████▎  | 17714/24227 [01:16<00:16, 386.51 examples/s]Tokenizing train dataset:  66%|██████▌   | 15979/24227 [01:15<00:40, 201.92 examples/s]Tokenizing train dataset:  73%|███████▎  | 17704/24227 [01:16<00:15, 419.43 examples/s]Tokenizing train dataset:  73%|███████▎  | 17780/24227 [01:16<00:14, 442.62 examples/s]Tokenizing train dataset:  66%|██████▌   | 16014/24227 [01:15<00:35, 232.05 examples/s]Tokenizing train dataset:  73%|███████▎  | 17779/24227 [01:17<00:17, 372.42 examples/s]Tokenizing train dataset:  74%|███████▎  | 17849/24227 [01:17<00:17, 371.71 examples/s]Tokenizing train dataset:  66%|██████▋   | 16053/24227 [01:16<00:40, 202.96 examples/s]Tokenizing train dataset:  74%|███████▎  | 17829/24227 [01:17<00:16, 396.13 examples/s]Tokenizing train dataset:  74%|███████▍  | 17917/24227 [01:17<00:16, 390.43 examples/s]Tokenizing train dataset:  66%|██████▋   | 16092/24227 [01:16<00:37, 217.21 examples/s]Tokenizing train dataset:  74%|███████▍  | 17891/24227 [01:17<00:18, 350.68 examples/s]Tokenizing train dataset:  74%|███████▍  | 17990/24227 [01:17<00:17, 363.98 examples/s]Tokenizing train dataset:  67%|██████▋   | 16133/24227 [01:16<00:42, 191.22 examples/s]Tokenizing train dataset:  74%|███████▍  | 18040/24227 [01:17<00:15, 388.32 examples/s]Tokenizing train dataset:  74%|███████▍  | 17962/24227 [01:17<00:17, 358.89 examples/s]Tokenizing train dataset:  67%|██████▋   | 16166/24227 [01:16<00:37, 215.51 examples/s]Tokenizing train dataset:  75%|███████▍  | 18120/24227 [01:17<00:16, 373.54 examples/s]Tokenizing train dataset:  74%|███████▍  | 18036/24227 [01:17<00:17, 351.51 examples/s]Tokenizing train dataset:  67%|██████▋   | 16203/24227 [01:16<00:42, 187.22 examples/s]Tokenizing train dataset:  75%|███████▍  | 18075/24227 [01:17<00:19, 316.42 examples/s]Tokenizing train dataset:  75%|███████▌  | 18194/24227 [01:17<00:16, 361.63 examples/s]Tokenizing train dataset:  67%|██████▋   | 16238/24227 [01:17<00:41, 194.00 examples/s]Tokenizing train dataset:  75%|███████▍  | 18131/24227 [01:18<00:16, 360.69 examples/s]Tokenizing train dataset:  75%|███████▌  | 18266/24227 [01:18<00:14, 425.74 examples/s]Tokenizing train dataset:  67%|██████▋   | 16263/24227 [01:17<00:39, 202.81 examples/s]Tokenizing train dataset:  75%|███████▌  | 18208/24227 [01:18<00:16, 364.36 examples/s]Tokenizing train dataset:  76%|███████▌  | 18343/24227 [01:18<00:14, 411.44 examples/s]Tokenizing train dataset:  75%|███████▌  | 18249/24227 [01:18<00:16, 371.94 examples/s]Tokenizing train dataset:  67%|██████▋   | 16299/24227 [01:17<00:45, 172.73 examples/s]Tokenizing train dataset:  76%|███████▌  | 18389/24227 [01:18<00:13, 419.71 examples/s]Tokenizing train dataset:  76%|███████▌  | 18293/24227 [01:18<00:15, 386.78 examples/s]Tokenizing train dataset:  67%|██████▋   | 16330/24227 [01:17<00:40, 196.64 examples/s]Tokenizing train dataset:  76%|███████▌  | 18445/24227 [01:18<00:12, 449.79 examples/s]Tokenizing train dataset:  76%|███████▌  | 18363/24227 [01:18<00:12, 458.96 examples/s]Tokenizing train dataset:  68%|██████▊   | 16358/24227 [01:17<00:37, 210.35 examples/s]Tokenizing train dataset:  76%|███████▋  | 18520/24227 [01:18<00:12, 462.14 examples/s]Tokenizing train dataset:  76%|███████▌  | 18434/24227 [01:18<00:12, 459.57 examples/s]Tokenizing train dataset:  77%|███████▋  | 18581/24227 [01:18<00:11, 491.52 examples/s]Tokenizing train dataset:  68%|██████▊   | 16391/24227 [01:17<00:37, 211.11 examples/s]Tokenizing train dataset:  76%|███████▋  | 18494/24227 [01:18<00:11, 493.26 examples/s]Tokenizing train dataset:  77%|███████▋  | 18660/24227 [01:18<00:11, 475.77 examples/s]Tokenizing train dataset:  68%|██████▊   | 16427/24227 [01:18<00:39, 199.42 examples/s]Tokenizing train dataset:  77%|███████▋  | 18564/24227 [01:18<00:11, 481.60 examples/s]Tokenizing train dataset:  77%|███████▋  | 18738/24227 [01:19<00:12, 444.80 examples/s]Tokenizing train dataset:  68%|██████▊   | 16460/24227 [01:18<00:52, 147.51 examples/s]Tokenizing train dataset:  77%|███████▋  | 18641/24227 [01:19<00:16, 340.77 examples/s]Tokenizing train dataset:  78%|███████▊  | 18819/24227 [01:19<00:12, 427.65 examples/s]Tokenizing train dataset:  68%|██████▊   | 16503/24227 [01:18<00:40, 191.56 examples/s]Tokenizing train dataset:  77%|███████▋  | 18710/24227 [01:19<00:13, 401.00 examples/s]Tokenizing train dataset:  78%|███████▊  | 18889/24227 [01:19<00:11, 480.55 examples/s]Tokenizing train dataset:  68%|██████▊   | 16582/24227 [01:18<00:25, 302.22 examples/s]Tokenizing train dataset:  78%|███████▊  | 18790/24227 [01:19<00:12, 435.42 examples/s]Tokenizing train dataset:  78%|███████▊  | 18962/24227 [01:19<00:10, 479.75 examples/s]Tokenizing train dataset:  69%|██████▊   | 16650/24227 [01:18<00:22, 342.88 examples/s]Tokenizing train dataset:  78%|███████▊  | 18867/24227 [01:19<00:10, 503.12 examples/s]Tokenizing train dataset:  79%|███████▊  | 19019/24227 [01:19<00:10, 498.18 examples/s]Tokenizing train dataset:  69%|██████▉   | 16712/24227 [01:18<00:18, 397.76 examples/s]Tokenizing train dataset:  78%|███████▊  | 18932/24227 [01:19<00:09, 535.34 examples/s]Tokenizing train dataset:  79%|███████▉  | 19084/24227 [01:19<00:09, 531.40 examples/s]Tokenizing train dataset:  69%|██████▉   | 16774/24227 [01:18<00:16, 447.92 examples/s]Tokenizing train dataset:  78%|███████▊  | 18998/24227 [01:19<00:10, 486.13 examples/s]Tokenizing train dataset:  79%|███████▉  | 19162/24227 [01:19<00:09, 510.27 examples/s]Tokenizing train dataset:  70%|██████▉   | 16845/24227 [01:19<00:16, 435.06 examples/s]Tokenizing train dataset:  79%|███████▊  | 19077/24227 [01:20<00:10, 494.70 examples/s]Tokenizing train dataset:  79%|███████▉  | 19247/24227 [01:20<00:10, 485.89 examples/s]Tokenizing train dataset:  70%|██████▉   | 16906/24227 [01:19<00:15, 475.13 examples/s]Tokenizing train dataset:  79%|███████▉  | 19155/24227 [01:20<00:10, 500.67 examples/s]Tokenizing train dataset:  80%|███████▉  | 19311/24227 [01:20<00:10, 448.39 examples/s]Tokenizing train dataset:  70%|███████   | 16966/24227 [01:19<00:19, 371.51 examples/s]Tokenizing train dataset:  79%|███████▉  | 19235/24227 [01:20<00:09, 505.62 examples/s]Tokenizing train dataset:  80%|████████  | 19384/24227 [01:20<00:10, 455.04 examples/s]Tokenizing train dataset:  70%|███████   | 17011/24227 [01:19<00:18, 385.89 examples/s]Tokenizing train dataset:  80%|███████▉  | 19303/24227 [01:20<00:10, 487.23 examples/s]Tokenizing train dataset:  80%|████████  | 19470/24227 [01:20<00:10, 436.45 examples/s]Tokenizing train dataset:  70%|███████   | 17080/24227 [01:19<00:25, 276.45 examples/s]Tokenizing train dataset:  81%|████████  | 19534/24227 [01:20<00:12, 370.23 examples/s]Tokenizing train dataset:  80%|███████▉  | 19356/24227 [01:20<00:16, 293.25 examples/s]Tokenizing train dataset:  71%|███████   | 17120/24227 [01:20<00:26, 269.45 examples/s]Tokenizing train dataset:  81%|████████  | 19600/24227 [01:21<00:13, 336.23 examples/s]Tokenizing train dataset:  71%|███████   | 17160/24227 [01:20<00:26, 267.38 examples/s]Tokenizing train dataset:  80%|████████  | 19415/24227 [01:21<00:17, 267.74 examples/s]Tokenizing train dataset:  81%|████████▏ | 19719/24227 [01:21<00:09, 480.53 examples/s]Tokenizing train dataset:  71%|███████   | 17210/24227 [01:20<00:22, 307.13 examples/s]Tokenizing train dataset:  80%|████████  | 19487/24227 [01:21<00:14, 335.06 examples/s]Tokenizing train dataset:  82%|████████▏ | 19808/24227 [01:21<00:07, 559.00 examples/s]Tokenizing train dataset:  71%|███████▏  | 17281/24227 [01:20<00:17, 389.16 examples/s]Tokenizing train dataset:  81%|████████  | 19610/24227 [01:21<00:09, 492.13 examples/s]Tokenizing train dataset:  82%|████████▏ | 19899/24227 [01:21<00:06, 633.99 examples/s]Tokenizing train dataset:  72%|███████▏  | 17342/24227 [01:20<00:15, 438.73 examples/s]Tokenizing train dataset:  81%|████████▏ | 19701/24227 [01:21<00:07, 575.17 examples/s]Tokenizing train dataset:  83%|████████▎ | 20021/24227 [01:21<00:05, 771.31 examples/s]Tokenizing train dataset:  72%|███████▏  | 17413/24227 [01:20<00:13, 503.61 examples/s]Tokenizing train dataset:  82%|████████▏ | 19825/24227 [01:21<00:06, 642.13 examples/s]Tokenizing train dataset:  83%|████████▎ | 20150/24227 [01:21<00:05, 785.86 examples/s]Tokenizing train dataset:  72%|███████▏  | 17481/24227 [01:20<00:13, 484.09 examples/s]Tokenizing train dataset:  82%|████████▏ | 19960/24227 [01:21<00:05, 715.04 examples/s]Tokenizing train dataset:  84%|████████▎ | 20274/24227 [01:21<00:04, 795.97 examples/s]Tokenizing train dataset:  72%|███████▏  | 17544/24227 [01:20<00:14, 459.59 examples/s]Tokenizing train dataset:  83%|████████▎ | 20040/24227 [01:21<00:05, 731.98 examples/s]Tokenizing train dataset:  84%|████████▍ | 20383/24227 [01:21<00:04, 860.98 examples/s]Tokenizing train dataset:  73%|███████▎  | 17599/24227 [01:21<00:17, 381.94 examples/s]Tokenizing train dataset:  83%|████████▎ | 20168/24227 [01:22<00:06, 617.22 examples/s]Tokenizing train dataset:  85%|████████▍ | 20504/24227 [01:22<00:05, 687.00 examples/s]Tokenizing train dataset:  73%|███████▎  | 17670/24227 [01:21<00:16, 390.61 examples/s]Tokenizing train dataset:  84%|████████▎ | 20281/24227 [01:22<00:05, 715.52 examples/s]Tokenizing train dataset:  85%|████████▌ | 20620/24227 [01:22<00:05, 621.39 examples/s]Tokenizing train dataset:  73%|███████▎  | 17745/24227 [01:21<00:21, 304.98 examples/s]Tokenizing train dataset:  84%|████████▍ | 20405/24227 [01:22<00:07, 489.61 examples/s]Tokenizing train dataset:  73%|███████▎  | 17794/24227 [01:21<00:19, 334.25 examples/s]Tokenizing train dataset:  86%|████████▌ | 20745/24227 [01:22<00:06, 547.84 examples/s]Tokenizing train dataset:  85%|████████▍ | 20510/24227 [01:22<00:06, 575.43 examples/s]Tokenizing train dataset:  74%|███████▎  | 17849/24227 [01:21<00:17, 373.32 examples/s]Tokenizing train dataset:  86%|████████▌ | 20824/24227 [01:22<00:05, 587.35 examples/s]Tokenizing train dataset:  85%|████████▌ | 20620/24227 [01:22<00:05, 668.96 examples/s]Tokenizing train dataset:  86%|████████▋ | 20908/24227 [01:22<00:05, 634.80 examples/s]Tokenizing train dataset:  74%|███████▍  | 17897/24227 [01:22<00:16, 391.32 examples/s]Tokenizing train dataset:  86%|████████▌ | 20746/24227 [01:23<00:05, 606.18 examples/s]Tokenizing train dataset:  87%|████████▋ | 21030/24227 [01:23<00:05, 566.09 examples/s]Tokenizing train dataset:  74%|███████▍  | 17966/24227 [01:22<00:19, 325.88 examples/s]Tokenizing train dataset:  86%|████████▌ | 20837/24227 [01:23<00:05, 661.26 examples/s]Tokenizing train dataset:  87%|████████▋ | 21134/24227 [01:23<00:04, 653.01 examples/s]Tokenizing train dataset:  74%|███████▍  | 18037/24227 [01:22<00:18, 332.27 examples/s]Tokenizing train dataset:  87%|████████▋ | 20960/24227 [01:23<00:04, 681.18 examples/s]Tokenizing train dataset:  88%|████████▊ | 21263/24227 [01:23<00:04, 708.95 examples/s]Tokenizing train dataset:  75%|███████▍  | 18075/24227 [01:22<00:23, 264.35 examples/s]Tokenizing train dataset:  87%|████████▋ | 21085/24227 [01:23<00:05, 551.01 examples/s]Tokenizing train dataset:  88%|████████▊ | 21388/24227 [01:23<00:05, 547.65 examples/s]Tokenizing train dataset:  75%|███████▍  | 18114/24227 [01:22<00:21, 280.82 examples/s]Tokenizing train dataset:  87%|████████▋ | 21179/24227 [01:23<00:04, 616.07 examples/s]Tokenizing train dataset:  89%|████████▉ | 21506/24227 [01:23<00:04, 652.44 examples/s]Tokenizing train dataset:  75%|███████▌  | 18172/24227 [01:22<00:18, 336.37 examples/s]Tokenizing train dataset:  88%|████████▊ | 21295/24227 [01:24<00:04, 720.68 examples/s]Tokenizing train dataset:  89%|████████▉ | 21612/24227 [01:23<00:03, 730.44 examples/s]Tokenizing train dataset:  75%|███████▌  | 18247/24227 [01:23<00:14, 423.81 examples/s]Tokenizing train dataset:  88%|████████▊ | 21396/24227 [01:24<00:03, 782.60 examples/s]Tokenizing train dataset:  90%|████████▉ | 21708/24227 [01:24<00:03, 778.75 examples/s]Tokenizing train dataset:  76%|███████▌  | 18301/24227 [01:23<00:13, 449.56 examples/s]Tokenizing train dataset:  89%|████████▉ | 21522/24227 [01:24<00:03, 781.80 examples/s]Tokenizing train dataset:  90%|█████████ | 21849/24227 [01:24<00:02, 827.44 examples/s]Tokenizing train dataset:  76%|███████▌  | 18386/24227 [01:23<00:12, 486.58 examples/s]Tokenizing train dataset:  89%|████████▉ | 21641/24227 [01:24<00:03, 742.77 examples/s]Tokenizing train dataset:  91%|█████████ | 21970/24227 [01:24<00:03, 667.19 examples/s]Tokenizing train dataset:  90%|████████▉ | 21724/24227 [01:24<00:03, 760.39 examples/s]Tokenizing train dataset:  76%|███████▌  | 18454/24227 [01:23<00:15, 371.02 examples/s]Tokenizing train dataset:  91%|█████████ | 22074/24227 [01:24<00:02, 738.54 examples/s]Tokenizing train dataset:  76%|███████▋  | 18503/24227 [01:23<00:14, 393.46 examples/s]Tokenizing train dataset:  90%|█████████ | 21850/24227 [01:24<00:03, 778.14 examples/s]Tokenizing train dataset:  92%|█████████▏| 22196/24227 [01:24<00:02, 682.34 examples/s]Tokenizing train dataset:  77%|███████▋  | 18564/24227 [01:23<00:15, 368.53 examples/s]Tokenizing train dataset:  91%|█████████ | 21970/24227 [01:24<00:02, 759.22 examples/s]Tokenizing train dataset:  92%|█████████▏| 22303/24227 [01:24<00:02, 758.34 examples/s]Tokenizing train dataset:  77%|███████▋  | 18618/24227 [01:24<00:13, 402.08 examples/s]Tokenizing train dataset:  91%|█████████ | 22050/24227 [01:24<00:02, 766.54 examples/s]Tokenizing train dataset:  93%|█████████▎| 22418/24227 [01:24<00:02, 844.00 examples/s]Tokenizing train dataset:  77%|███████▋  | 18700/24227 [01:24<00:13, 396.34 examples/s]Tokenizing train dataset:  92%|█████████▏| 22174/24227 [01:25<00:02, 685.97 examples/s]Tokenizing train dataset:  93%|█████████▎| 22558/24227 [01:25<00:01, 869.68 examples/s]Tokenizing train dataset:  77%|███████▋  | 18764/24227 [01:24<00:12, 443.23 examples/s]Tokenizing train dataset:  92%|█████████▏| 22275/24227 [01:25<00:02, 753.14 examples/s]Tokenizing train dataset:  94%|█████████▎| 22681/24227 [01:25<00:01, 776.99 examples/s]Tokenizing train dataset:  78%|███████▊  | 18839/24227 [01:24<00:13, 398.78 examples/s]Tokenizing train dataset:  92%|█████████▏| 22393/24227 [01:25<00:02, 655.87 examples/s]Tokenizing train dataset:  94%|█████████▍| 22809/24227 [01:25<00:01, 748.83 examples/s]Tokenizing train dataset:  78%|███████▊  | 18906/24227 [01:24<00:11, 451.22 examples/s]Tokenizing train dataset:  93%|█████████▎| 22518/24227 [01:25<00:02, 689.40 examples/s]Tokenizing train dataset:  95%|█████████▍| 22920/24227 [01:25<00:01, 820.86 examples/s]Tokenizing train dataset:  78%|███████▊  | 18963/24227 [01:24<00:11, 474.37 examples/s]Tokenizing train dataset:  93%|█████████▎| 22613/24227 [01:25<00:02, 741.79 examples/s]Tokenizing train dataset:  95%|█████████▌| 23027/24227 [01:25<00:01, 875.12 examples/s]Tokenizing train dataset:  78%|███████▊  | 19015/24227 [01:24<00:10, 484.34 examples/s]Tokenizing train dataset:  94%|█████████▍| 22730/24227 [01:25<00:01, 836.20 examples/s]Tokenizing train dataset:  96%|█████████▌| 23143/24227 [01:25<00:01, 942.44 examples/s]Tokenizing train dataset:  94%|█████████▍| 22849/24227 [01:25<00:01, 920.08 examples/s]Tokenizing train dataset:  79%|███████▉  | 19084/24227 [01:25<00:11, 456.05 examples/s]Tokenizing train dataset:  96%|█████████▌| 23262/24227 [01:25<00:00, 1001.48 examples/s]Tokenizing train dataset:  95%|█████████▍| 22963/24227 [01:26<00:01, 975.29 examples/s]Tokenizing train dataset:  79%|███████▉  | 19152/24227 [01:25<00:10, 506.28 examples/s]Tokenizing train dataset:  97%|█████████▋| 23381/24227 [01:26<00:00, 1049.01 examples/s]Tokenizing train dataset:  95%|█████████▌| 23080/24227 [01:26<00:01, 1023.23 examples/s]Tokenizing train dataset:  79%|███████▉  | 19216/24227 [01:25<00:09, 534.88 examples/s]Tokenizing train dataset:  97%|█████████▋| 23510/24227 [01:26<00:00, 975.60 examples/s] Tokenizing train dataset:  96%|█████████▌| 23207/24227 [01:26<00:01, 881.87 examples/s] Tokenizing train dataset:  80%|███████▉  | 19287/24227 [01:25<00:10, 454.87 examples/s]Tokenizing train dataset:  98%|█████████▊| 23633/24227 [01:26<00:00, 808.74 examples/s]Tokenizing train dataset:  96%|█████████▌| 23303/24227 [01:26<00:01, 896.77 examples/s]Tokenizing train dataset:  80%|███████▉  | 19361/24227 [01:25<00:10, 461.02 examples/s]Tokenizing train dataset:  98%|█████████▊| 23778/24227 [01:26<00:00, 854.46 examples/s]Tokenizing train dataset:  97%|█████████▋| 23429/24227 [01:26<00:00, 850.08 examples/s]Tokenizing train dataset:  80%|████████  | 19418/24227 [01:25<00:11, 422.19 examples/s]Tokenizing train dataset:  81%|████████  | 19518/24227 [01:25<00:08, 546.60 examples/s]Tokenizing train dataset:  99%|█████████▊| 23900/24227 [01:26<00:00, 742.57 examples/s]Tokenizing train dataset:  97%|█████████▋| 23554/24227 [01:26<00:00, 764.28 examples/s]Tokenizing train dataset:  81%|████████  | 19634/24227 [01:25<00:06, 690.14 examples/s]Tokenizing train dataset:  99%|█████████▉| 24012/24227 [01:26<00:00, 815.16 examples/s]Tokenizing train dataset:  98%|█████████▊| 23656/24227 [01:26<00:00, 819.15 examples/s]Tokenizing train dataset:  82%|████████▏ | 19758/24227 [01:26<00:06, 724.85 examples/s]Tokenizing train dataset: 100%|█████████▉| 24139/24227 [01:27<00:00, 822.35 examples/s]Tokenizing train dataset:  98%|█████████▊| 23779/24227 [01:27<00:00, 816.88 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:27<00:00, 799.09 examples/s]Tokenizing train dataset:  82%|████████▏ | 19890/24227 [01:26<00:05, 772.09 examples/s]Tokenizing train dataset:  99%|█████████▊| 23903/24227 [01:27<00:00, 818.11 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:27<00:00, 277.89 examples/s]
Tokenizing train dataset:  83%|████████▎ | 20004/24227 [01:26<00:04, 856.73 examples/s]Tokenizing train dataset:  99%|█████████▉| 24015/24227 [01:27<00:00, 886.60 examples/s]Tokenizing train dataset:  83%|████████▎ | 20130/24227 [01:26<00:06, 661.80 examples/s]Tokenizing train dataset: 100%|█████████▉| 24141/24227 [01:27<00:00, 678.30 examples/s]Tokenizing train dataset:  84%|████████▎ | 20244/24227 [01:26<00:05, 755.05 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:27<00:00, 276.21 examples/s]
Tokenizing train dataset:  84%|████████▍ | 20360/24227 [01:26<00:04, 840.50 examples/s]Tokenizing train dataset:  85%|████████▍ | 20480/24227 [01:27<00:05, 629.21 examples/s]Tokenizing train dataset:  85%|████████▍ | 20570/24227 [01:27<00:05, 679.50 examples/s]Tokenizing train dataset:  85%|████████▌ | 20690/24227 [01:27<00:05, 643.89 examples/s]Tokenizing train dataset:  86%|████████▌ | 20809/24227 [01:27<00:05, 662.90 examples/s]Tokenizing train dataset:  86%|████████▋ | 20910/24227 [01:27<00:04, 727.80 examples/s]Tokenizing train dataset:  87%|████████▋ | 21003/24227 [01:27<00:04, 771.36 examples/s]Tokenizing train dataset:  87%|████████▋ | 21109/24227 [01:27<00:03, 838.18 examples/s]Tokenizing train dataset:  88%|████████▊ | 21208/24227 [01:28<00:03, 874.90 examples/s]Tokenizing train dataset:  88%|████████▊ | 21330/24227 [01:28<00:03, 759.06 examples/s]Tokenizing train dataset:  89%|████████▊ | 21455/24227 [01:28<00:03, 729.46 examples/s]Tokenizing train dataset:  89%|████████▉ | 21563/24227 [01:28<00:03, 804.17 examples/s]Tokenizing train dataset:  89%|████████▉ | 21667/24227 [01:28<00:02, 858.84 examples/s]Tokenizing train dataset:  90%|████████▉ | 21793/24227 [01:28<00:02, 848.41 examples/s]Tokenizing train dataset:  91%|█████████ | 21941/24227 [01:28<00:02, 888.50 examples/s]Tokenizing train dataset:  91%|█████████ | 22091/24227 [01:29<00:02, 921.55 examples/s]Tokenizing train dataset:  92%|█████████▏| 22187/24227 [01:29<00:02, 928.61 examples/s]Tokenizing train dataset:  92%|█████████▏| 22304/24227 [01:29<00:02, 695.97 examples/s]Tokenizing train dataset:  93%|█████████▎| 22441/24227 [01:29<00:02, 753.61 examples/s]Tokenizing train dataset:  93%|█████████▎| 22573/24227 [01:29<00:02, 788.04 examples/s]Tokenizing train dataset:  94%|█████████▎| 22660/24227 [01:29<00:01, 802.54 examples/s]Tokenizing train dataset:  94%|█████████▍| 22784/24227 [01:30<00:01, 800.99 examples/s]Tokenizing train dataset:  95%|█████████▍| 22909/24227 [01:30<00:01, 761.56 examples/s]Tokenizing train dataset:  95%|█████████▌| 23019/24227 [01:30<00:01, 832.64 examples/s]Tokenizing train dataset:  96%|█████████▌| 23149/24227 [01:30<00:01, 841.67 examples/s]Tokenizing train dataset:  96%|█████████▌| 23298/24227 [01:30<00:01, 885.18 examples/s]Tokenizing train dataset:  97%|█████████▋| 23405/24227 [01:30<00:00, 926.47 examples/s]Tokenizing train dataset:  97%|█████████▋| 23550/24227 [01:30<00:00, 935.83 examples/s]Tokenizing train dataset:  98%|█████████▊| 23670/24227 [01:31<00:00, 783.24 examples/s]Tokenizing train dataset:  98%|█████████▊| 23791/24227 [01:31<00:00, 672.96 examples/s]Tokenizing train dataset:  99%|█████████▊| 23898/24227 [01:31<00:00, 745.58 examples/s]Tokenizing train dataset:  99%|█████████▉| 24033/24227 [01:31<00:00, 789.34 examples/s]Tokenizing train dataset: 100%|█████████▉| 24127/24227 [01:31<00:00, 820.80 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:31<00:00, 755.18 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:31<00:00, 263.39 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5464.18 examples/s]Extracting prompt in eval dataset:  56%|█████▌    | 530/953 [00:00<00:00, 5204.90 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5466.06 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4952.03 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5057.09 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4150.21 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  27%|██▋       | 256/953 [00:00<00:00, 2530.54 examples/s]Applying chat template to eval dataset:  27%|██▋       | 254/953 [00:00<00:00, 2511.54 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  67%|██████▋   | 637/953 [00:00<00:00, 1913.82 examples/s]Applying chat template to eval dataset:  54%|█████▍    | 516/953 [00:00<00:00, 1053.09 examples/s]Applying chat template to eval dataset:  30%|███       | 290/953 [00:00<00:00, 2845.19 examples/s]Applying chat template to eval dataset:  95%|█████████▍| 904/953 [00:00<00:00, 1635.75 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1741.04 examples/s]
Applying chat template to eval dataset:  79%|███████▉  | 753/953 [00:00<00:00, 1387.10 examples/s]Applying chat template to eval dataset:  61%|██████    | 580/953 [00:00<00:00, 2866.35 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1497.81 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2862.90 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2785.71 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 26/953 [00:00<00:03, 254.58 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 24/953 [00:00<00:03, 235.25 examples/s]Tokenizing eval dataset:   5%|▌         | 52/953 [00:00<00:06, 147.90 examples/s]Tokenizing eval dataset:   3%|▎         | 30/953 [00:00<00:03, 292.97 examples/s]Tokenizing eval dataset:   6%|▌         | 57/953 [00:00<00:04, 221.31 examples/s]Tokenizing eval dataset:   8%|▊         | 72/953 [00:00<00:05, 158.89 examples/s]Tokenizing eval dataset:  10%|▉         | 91/953 [00:00<00:03, 216.93 examples/s]Tokenizing eval dataset:   7%|▋         | 71/953 [00:00<00:04, 217.44 examples/s]Tokenizing eval dataset:  10%|█         | 99/953 [00:00<00:05, 165.33 examples/s]Tokenizing eval dataset:  12%|█▏        | 113/953 [00:00<00:03, 214.20 examples/s]Tokenizing eval dataset:  10%|█         | 97/953 [00:00<00:03, 229.47 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:04, 173.48 examples/s]Tokenizing eval dataset:  15%|█▍        | 142/953 [00:00<00:04, 182.01 examples/s]Tokenizing eval dataset:  15%|█▌        | 144/953 [00:00<00:03, 206.64 examples/s]Tokenizing eval dataset:  14%|█▍        | 136/953 [00:00<00:03, 238.23 examples/s]Tokenizing eval dataset:  17%|█▋        | 162/953 [00:01<00:06, 129.78 examples/s]Tokenizing eval dataset:  17%|█▋        | 166/953 [00:00<00:05, 142.75 examples/s]Tokenizing eval dataset:  18%|█▊        | 172/953 [00:00<00:04, 165.48 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:05, 137.32 examples/s]Tokenizing eval dataset:  20%|██        | 192/953 [00:01<00:05, 149.68 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:01<00:04, 174.14 examples/s]Tokenizing eval dataset:  22%|██▏       | 211/953 [00:01<00:05, 143.29 examples/s]Tokenizing eval dataset:  22%|██▏       | 214/953 [00:01<00:05, 144.02 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:01<00:04, 171.99 examples/s]Tokenizing eval dataset:  24%|██▍       | 229/953 [00:01<00:04, 146.01 examples/s]Tokenizing eval dataset:  25%|██▍       | 237/953 [00:01<00:04, 160.63 examples/s]Tokenizing eval dataset:  26%|██▌       | 250/953 [00:01<00:04, 168.52 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:01<00:04, 154.93 examples/s]Tokenizing eval dataset:  27%|██▋       | 260/953 [00:01<00:04, 165.57 examples/s]Tokenizing eval dataset:  29%|██▉       | 279/953 [00:01<00:03, 182.40 examples/s]Tokenizing eval dataset:  29%|██▉       | 277/953 [00:01<00:04, 167.82 examples/s]Tokenizing eval dataset:  30%|███       | 289/953 [00:01<00:03, 184.75 examples/s]Tokenizing eval dataset:  35%|███▍      | 333/953 [00:01<00:02, 259.57 examples/s]Tokenizing eval dataset:  34%|███▍      | 322/953 [00:01<00:02, 234.48 examples/s]Tokenizing eval dataset:  33%|███▎      | 310/953 [00:01<00:03, 183.27 examples/s]Tokenizing eval dataset:  39%|███▉      | 372/953 [00:01<00:02, 289.28 examples/s]Tokenizing eval dataset:  37%|███▋      | 355/953 [00:01<00:02, 255.70 examples/s]Tokenizing eval dataset:  37%|███▋      | 351/953 [00:01<00:02, 236.61 examples/s]Tokenizing eval dataset:  45%|████▍     | 427/953 [00:01<00:01, 352.56 examples/s]Tokenizing eval dataset:  40%|████      | 385/953 [00:02<00:02, 263.90 examples/s]Tokenizing eval dataset:  41%|████      | 390/953 [00:01<00:02, 275.78 examples/s]Tokenizing eval dataset:  44%|████▍     | 422/953 [00:02<00:01, 287.47 examples/s]Tokenizing eval dataset:  51%|█████     | 484/953 [00:01<00:01, 342.38 examples/s]Tokenizing eval dataset:  46%|████▌     | 435/953 [00:02<00:01, 282.13 examples/s]Tokenizing eval dataset:  48%|████▊     | 453/953 [00:02<00:01, 277.73 examples/s]Tokenizing eval dataset:  49%|████▉     | 466/953 [00:02<00:01, 279.57 examples/s]Tokenizing eval dataset:  57%|█████▋    | 540/953 [00:02<00:01, 337.09 examples/s]Tokenizing eval dataset:  51%|█████     | 483/953 [00:02<00:01, 283.10 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:02<00:01, 302.25 examples/s]Tokenizing eval dataset:  55%|█████▍    | 522/953 [00:02<00:01, 311.53 examples/s]Tokenizing eval dataset:  63%|██████▎   | 601/953 [00:02<00:00, 356.13 examples/s]Tokenizing eval dataset:  59%|█████▊    | 558/953 [00:02<00:01, 319.64 examples/s]Tokenizing eval dataset:  58%|█████▊    | 556/953 [00:02<00:01, 286.74 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:02<00:00, 359.86 examples/s]Tokenizing eval dataset:  64%|██████▎   | 607/953 [00:02<00:00, 368.13 examples/s]Tokenizing eval dataset:  72%|███████▏  | 682/953 [00:02<00:00, 374.12 examples/s]Tokenizing eval dataset:  63%|██████▎   | 604/953 [00:02<00:01, 330.13 examples/s]Tokenizing eval dataset:  68%|██████▊   | 652/953 [00:02<00:00, 390.82 examples/s]Tokenizing eval dataset:  68%|██████▊   | 646/953 [00:02<00:00, 349.78 examples/s]Tokenizing eval dataset:  76%|███████▌  | 725/953 [00:02<00:00, 382.03 examples/s]Tokenizing eval dataset:  72%|███████▏  | 689/953 [00:02<00:00, 364.73 examples/s]Tokenizing eval dataset:  75%|███████▍  | 711/953 [00:02<00:00, 390.58 examples/s]Tokenizing eval dataset:  82%|████████▏ | 777/953 [00:02<00:00, 367.87 examples/s]Tokenizing eval dataset:  77%|███████▋  | 735/953 [00:03<00:00, 338.69 examples/s]Tokenizing eval dataset:  81%|████████  | 774/953 [00:02<00:00, 396.46 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:02<00:00, 359.51 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:03<00:00, 285.09 examples/s]Tokenizing eval dataset:  91%|█████████▏| 871/953 [00:03<00:00, 270.47 examples/s]Tokenizing eval dataset:  88%|████████▊ | 838/953 [00:03<00:00, 300.64 examples/s]Tokenizing eval dataset:  87%|████████▋ | 827/953 [00:03<00:00, 284.11 examples/s]Tokenizing eval dataset:  95%|█████████▍| 903/953 [00:03<00:00, 277.87 examples/s]Tokenizing eval dataset:  94%|█████████▍| 894/953 [00:03<00:00, 315.53 examples/s]Tokenizing eval dataset:  98%|█████████▊| 936/953 [00:03<00:00, 287.32 examples/s]Tokenizing eval dataset:  92%|█████████▏| 880/953 [00:03<00:00, 299.00 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 276.17 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  99%|█████████▉| 947/953 [00:03<00:00, 324.91 examples/s]Tokenizing eval dataset:  96%|█████████▋| 918/953 [00:03<00:00, 312.42 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 260.43 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 311.31 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 241.26 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.757538318634033 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...

Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.9416847229003906 seconds
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.997469425201416 seconds
Time to load cpu_adam op: 2.9165947437286377 seconds
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250611_124551-cgvcgntg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-1e-07_e-3_b-0.2_63002798
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/cgvcgntg
  0%|          | 0/4545 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/4545 [00:12<15:29:37, 12.28s/it]  0%|          | 2/4545 [00:16<9:16:07,  7.34s/it]   0%|          | 3/4545 [00:20<7:17:06,  5.77s/it]  0%|          | 4/4545 [00:23<6:12:21,  4.92s/it]  0%|          | 5/4545 [00:27<5:45:16,  4.56s/it]  0%|          | 6/4545 [00:31<5:36:47,  4.45s/it]  0%|          | 7/4545 [00:35<5:28:03,  4.34s/it]  0%|          | 8/4545 [00:39<5:16:08,  4.18s/it]  0%|          | 9/4545 [00:43<5:14:54,  4.17s/it]  0%|          | 10/4545 [00:47<5:04:21,  4.03s/it]                                                   {'loss': 0.7304, 'grad_norm': 61.97761917114258, 'learning_rate': 5.9445178335535e-10, 'rewards/chosen': -0.04407653957605362, 'rewards/rejected': 0.0009277343633584678, 'rewards/accuracies': 0.11249999701976776, 'rewards/margins': -0.04497070237994194, 'logps/chosen': -447.75, 'logps/rejected': -256.82501220703125, 'logits/chosen': -6.0625, 'logits/rejected': -6.162499904632568, 'epoch': 0.01}
  0%|          | 10/4545 [00:47<5:04:21,  4.03s/it]  0%|          | 11/4545 [00:51<5:07:54,  4.07s/it]  0%|          | 12/4545 [00:55<5:04:06,  4.03s/it]  0%|          | 13/4545 [00:57<4:20:22,  3.45s/it]  0%|          | 14/4545 [01:26<13:58:53, 11.11s/it]  0%|          | 15/4545 [01:30<11:15:00,  8.94s/it]  0%|          | 16/4545 [01:33<9:07:58,  7.26s/it]   0%|          | 17/4545 [01:37<7:51:56,  6.25s/it]  0%|          | 18/4545 [01:42<7:05:15,  5.64s/it]  0%|          | 19/4545 [01:45<6:05:36,  4.85s/it]  0%|          | 20/4545 [01:48<5:44:23,  4.57s/it]                                                   {'loss': 0.6869, 'grad_norm': 51.8979377746582, 'learning_rate': 1.2549537648612944e-09, 'rewards/chosen': 0.014034271240234375, 'rewards/rejected': 0.0016586303245276213, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': 0.012336445041000843, 'logps/chosen': -254.77499389648438, 'logps/rejected': -121.0999984741211, 'logits/chosen': -6.278124809265137, 'logits/rejected': -6.671875, 'epoch': 0.01}
  0%|          | 20/4545 [01:49<5:44:23,  4.57s/it]  0%|          | 21/4545 [01:52<5:15:44,  4.19s/it]  0%|          | 22/4545 [01:56<5:09:52,  4.11s/it]  1%|          | 23/4545 [02:00<5:05:26,  4.05s/it]  1%|          | 24/4545 [02:03<4:45:49,  3.79s/it]  1%|          | 25/4545 [02:07<4:48:33,  3.83s/it]  1%|          | 26/4545 [02:10<4:38:48,  3.70s/it]  1%|          | 27/4545 [02:14<4:43:42,  3.77s/it]  1%|          | 28/4545 [02:18<4:45:59,  3.80s/it]  1%|          | 29/4545 [02:22<4:48:31,  3.83s/it]  1%|          | 30/4545 [02:26<4:57:09,  3.95s/it]                                                   {'loss': 0.6989, 'grad_norm': 49.02035903930664, 'learning_rate': 1.915455746367239e-09, 'rewards/chosen': -0.0071929930709302425, 'rewards/rejected': -0.008331298828125, 'rewards/accuracies': 0.4124999940395355, 'rewards/margins': 0.0011230468517169356, 'logps/chosen': -283.20001220703125, 'logps/rejected': -142.4499969482422, 'logits/chosen': -6.196875095367432, 'logits/rejected': -6.553124904632568, 'epoch': 0.02}
  1%|          | 30/4545 [02:26<4:57:09,  3.95s/it]  1%|          | 31/4545 [02:30<5:02:04,  4.02s/it]  1%|          | 32/4545 [02:34<5:01:57,  4.01s/it]  1%|          | 33/4545 [02:38<4:59:59,  3.99s/it]  1%|          | 34/4545 [02:42<5:04:59,  4.06s/it]  1%|          | 35/4545 [02:46<5:01:53,  4.02s/it]  1%|          | 36/4545 [02:50<4:54:02,  3.91s/it]  1%|          | 37/4545 [02:54<4:46:12,  3.81s/it]  1%|          | 38/4545 [02:57<4:43:55,  3.78s/it]  1%|          | 39/4545 [03:01<4:46:59,  3.82s/it]  1%|          | 40/4545 [03:05<4:49:11,  3.85s/it]                                                   {'loss': 0.7029, 'grad_norm': 327.1829833984375, 'learning_rate': 2.5759577278731833e-09, 'rewards/chosen': 0.0021308897994458675, 'rewards/rejected': 0.0014190673828125, 'rewards/accuracies': 0.4124999940395355, 'rewards/margins': 0.0006835937383584678, 'logps/chosen': -416.0, 'logps/rejected': -175.1999969482422, 'logits/chosen': -6.268750190734863, 'logits/rejected': -6.565625190734863, 'epoch': 0.03}
  1%|          | 40/4545 [03:05<4:49:11,  3.85s/it]  1%|          | 41/4545 [03:09<4:42:52,  3.77s/it]  1%|          | 42/4545 [03:13<4:46:18,  3.81s/it]  1%|          | 43/4545 [03:17<4:49:21,  3.86s/it]  1%|          | 44/4545 [03:21<4:54:31,  3.93s/it]  1%|          | 45/4545 [03:25<4:58:42,  3.98s/it]  1%|          | 46/4545 [03:29<5:00:14,  4.00s/it]  1%|          | 47/4545 [03:32<4:51:00,  3.88s/it]  1%|          | 48/4545 [03:36<4:52:10,  3.90s/it]  1%|          | 49/4545 [03:40<4:52:13,  3.90s/it]  1%|          | 50/4545 [03:44<4:52:27,  3.90s/it]                                                   {'loss': 0.7411, 'grad_norm': 378.5684814453125, 'learning_rate': 3.236459709379128e-09, 'rewards/chosen': -0.0414886474609375, 'rewards/rejected': 0.0005615234258584678, 'rewards/accuracies': 0.4437499940395355, 'rewards/margins': -0.04221801832318306, 'logps/chosen': -366.8500061035156, 'logps/rejected': -200.9499969482422, 'logits/chosen': -6.293749809265137, 'logits/rejected': -6.474999904632568, 'epoch': 0.03}
  1%|          | 50/4545 [03:44<4:52:27,  3.90s/it]  1%|          | 51/4545 [03:48<4:48:25,  3.85s/it]  1%|          | 52/4545 [03:52<4:46:59,  3.83s/it]  1%|          | 53/4545 [03:55<4:42:38,  3.78s/it]  1%|          | 54/4545 [03:59<4:50:31,  3.88s/it]  1%|          | 55/4545 [04:03<4:51:23,  3.89s/it]  1%|          | 56/4545 [04:07<4:48:23,  3.85s/it]  1%|▏         | 57/4545 [04:11<4:49:39,  3.87s/it]  1%|▏         | 58/4545 [04:15<4:46:03,  3.83s/it]  1%|▏         | 59/4545 [04:18<4:30:52,  3.62s/it]  1%|▏         | 60/4545 [04:22<4:36:49,  3.70s/it]                                                   {'loss': 0.6881, 'grad_norm': 123.8697280883789, 'learning_rate': 3.896961690885073e-09, 'rewards/chosen': 0.01513519324362278, 'rewards/rejected': -0.005451965145766735, 'rewards/accuracies': 0.4625000059604645, 'rewards/margins': 0.0206451416015625, 'logps/chosen': -227.35000610351562, 'logps/rejected': -122.69999694824219, 'logits/chosen': -6.384375095367432, 'logits/rejected': -6.587500095367432, 'epoch': 0.04}
  1%|▏         | 60/4545 [04:22<4:36:49,  3.70s/it]  1%|▏         | 61/4545 [04:25<4:26:11,  3.56s/it]  1%|▏         | 62/4545 [04:29<4:29:28,  3.61s/it]  1%|▏         | 63/4545 [04:33<4:36:47,  3.71s/it]  1%|▏         | 64/4545 [04:37<4:47:39,  3.85s/it]  1%|▏         | 65/4545 [04:40<4:24:22,  3.54s/it]  1%|▏         | 66/4545 [04:43<4:26:07,  3.57s/it]  1%|▏         | 67/4545 [04:47<4:34:39,  3.68s/it]  1%|▏         | 68/4545 [04:51<4:34:45,  3.68s/it]  2%|▏         | 69/4545 [04:55<4:40:10,  3.76s/it]  2%|▏         | 70/4545 [04:59<4:38:16,  3.73s/it]                                                   {'loss': 0.6996, 'grad_norm': 82.57534790039062, 'learning_rate': 4.557463672391017e-09, 'rewards/chosen': 0.022324372082948685, 'rewards/rejected': 0.0051422119140625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.017290115356445312, 'logps/chosen': -315.95001220703125, 'logps/rejected': -154.9250030517578, 'logits/chosen': -6.15625, 'logits/rejected': -6.559374809265137, 'epoch': 0.05}
  2%|▏         | 70/4545 [04:59<4:38:16,  3.73s/it]  2%|▏         | 71/4545 [05:03<4:47:55,  3.86s/it]  2%|▏         | 72/4545 [05:06<4:31:03,  3.64s/it]  2%|▏         | 73/4545 [05:10<4:43:04,  3.80s/it]  2%|▏         | 74/4545 [05:14<4:49:23,  3.88s/it]  2%|▏         | 75/4545 [05:18<4:50:32,  3.90s/it]  2%|▏         | 76/4545 [05:22<4:45:08,  3.83s/it]  2%|▏         | 77/4545 [05:26<4:49:46,  3.89s/it]  2%|▏         | 78/4545 [05:30<4:51:35,  3.92s/it]  2%|▏         | 79/4545 [05:34<4:51:49,  3.92s/it]  2%|▏         | 80/4545 [05:38<4:51:53,  3.92s/it]                                                   {'loss': 0.7494, 'grad_norm': 343.72265625, 'learning_rate': 5.217965653896962e-09, 'rewards/chosen': -0.01509704627096653, 'rewards/rejected': 0.03540649265050888, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.05038147047162056, 'logps/chosen': -352.8500061035156, 'logps/rejected': -216.60000610351562, 'logits/chosen': -6.240624904632568, 'logits/rejected': -6.425000190734863, 'epoch': 0.05}
  2%|▏         | 80/4545 [05:38<4:51:53,  3.92s/it]  2%|▏         | 81/4545 [05:41<4:52:05,  3.93s/it]  2%|▏         | 82/4545 [05:45<4:47:10,  3.86s/it]  2%|▏         | 83/4545 [05:49<4:46:27,  3.85s/it]  2%|▏         | 84/4545 [05:52<4:28:27,  3.61s/it]  2%|▏         | 85/4545 [05:56<4:39:45,  3.76s/it]  2%|▏         | 86/4545 [06:00<4:45:59,  3.85s/it]  2%|▏         | 87/4545 [06:04<4:47:52,  3.87s/it]  2%|▏         | 88/4545 [06:08<4:48:57,  3.89s/it]  2%|▏         | 89/4545 [06:11<4:32:12,  3.67s/it]  2%|▏         | 90/4545 [06:15<4:25:13,  3.57s/it]                                                   {'loss': 0.7113, 'grad_norm': 55.7037467956543, 'learning_rate': 5.878467635402906e-09, 'rewards/chosen': -0.013209533877670765, 'rewards/rejected': 0.018524551764130592, 'rewards/accuracies': 0.3812499940395355, 'rewards/margins': -0.03171386569738388, 'logps/chosen': -322.1000061035156, 'logps/rejected': -167.375, 'logits/chosen': -6.375, 'logits/rejected': -6.653124809265137, 'epoch': 0.06}
  2%|▏         | 90/4545 [06:15<4:25:13,  3.57s/it]  2%|▏         | 91/4545 [06:19<4:33:55,  3.69s/it]  2%|▏         | 92/4545 [06:22<4:39:08,  3.76s/it]  2%|▏         | 93/4545 [06:26<4:42:51,  3.81s/it]  2%|▏         | 94/4545 [06:30<4:45:30,  3.85s/it]  2%|▏         | 95/4545 [06:34<4:47:06,  3.87s/it]  2%|▏         | 96/4545 [06:38<4:47:50,  3.88s/it]  2%|▏         | 97/4545 [06:42<4:49:05,  3.90s/it]  2%|▏         | 98/4545 [06:45<4:36:17,  3.73s/it]  2%|▏         | 99/4545 [06:49<4:21:07,  3.52s/it]  2%|▏         | 100/4545 [06:52<4:17:44,  3.48s/it]                                                    {'loss': 0.7407, 'grad_norm': 42.22023391723633, 'learning_rate': 6.53896961690885e-09, 'rewards/chosen': -0.053484342992305756, 'rewards/rejected': -0.00311279296875, 'rewards/accuracies': 0.375, 'rewards/margins': -0.05026855319738388, 'logps/chosen': -330.54998779296875, 'logps/rejected': -159.8249969482422, 'logits/chosen': -6.306250095367432, 'logits/rejected': -6.671875, 'epoch': 0.07}
  2%|▏         | 100/4545 [06:52<4:17:44,  3.48s/it]  2%|▏         | 101/4545 [06:56<4:27:50,  3.62s/it]  2%|▏         | 102/4545 [07:00<4:34:12,  3.70s/it]  2%|▏         | 103/4545 [07:02<4:10:32,  3.38s/it]  2%|▏         | 104/4545 [07:06<4:19:08,  3.50s/it]  2%|▏         | 105/4545 [07:10<4:18:50,  3.50s/it]  2%|▏         | 106/4545 [07:13<4:24:53,  3.58s/it]  2%|▏         | 107/4545 [07:17<4:33:08,  3.69s/it]  2%|▏         | 108/4545 [07:21<4:32:37,  3.69s/it]  2%|▏         | 109/4545 [07:25<4:37:46,  3.76s/it]  2%|▏         | 110/4545 [07:29<4:47:40,  3.89s/it]                                                    {'loss': 0.6977, 'grad_norm': 544.1755981445312, 'learning_rate': 7.1994715984147955e-09, 'rewards/chosen': -0.0012695312034338713, 'rewards/rejected': -0.00612640380859375, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': 0.0048828125, 'logps/chosen': -221.4499969482422, 'logps/rejected': -128.39999389648438, 'logits/chosen': -6.318749904632568, 'logits/rejected': -6.640625, 'epoch': 0.07}
  2%|▏         | 110/4545 [07:29<4:47:40,  3.89s/it]  2%|▏         | 111/4545 [07:33<4:50:37,  3.93s/it]  2%|▏         | 112/4545 [07:37<4:50:35,  3.93s/it]  2%|▏         | 113/4545 [07:41<4:50:30,  3.93s/it]  3%|▎         | 114/4545 [07:45<4:50:16,  3.93s/it]  3%|▎         | 115/4545 [07:49<4:51:21,  3.95s/it]  3%|▎         | 116/4545 [07:53<4:50:54,  3.94s/it]  3%|▎         | 117/4545 [07:57<4:56:50,  4.02s/it]  3%|▎         | 118/4545 [08:01<5:01:10,  4.08s/it]  3%|▎         | 119/4545 [08:05<4:56:26,  4.02s/it]  3%|▎         | 120/4545 [08:09<4:48:31,  3.91s/it]                                                    {'loss': 0.6956, 'grad_norm': 49.757205963134766, 'learning_rate': 7.85997357992074e-09, 'rewards/chosen': -0.013018799014389515, 'rewards/rejected': -0.008052825927734375, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.0050048828125, 'logps/chosen': -429.79998779296875, 'logps/rejected': -149.64999389648438, 'logits/chosen': -6.125, 'logits/rejected': -6.65625, 'epoch': 0.08}
  3%|▎         | 120/4545 [08:09<4:48:31,  3.91s/it]  3%|▎         | 121/4545 [08:13<4:49:45,  3.93s/it]  3%|▎         | 122/4545 [08:17<4:49:42,  3.93s/it]  3%|▎         | 123/4545 [08:21<4:49:47,  3.93s/it]  3%|▎         | 124/4545 [08:24<4:44:29,  3.86s/it]  3%|▎         | 125/4545 [08:29<4:51:44,  3.96s/it]  3%|▎         | 126/4545 [08:33<4:52:28,  3.97s/it]  3%|▎         | 127/4545 [08:36<4:45:26,  3.88s/it]  3%|▎         | 128/4545 [08:40<4:46:23,  3.89s/it]  3%|▎         | 129/4545 [08:44<4:47:35,  3.91s/it]  3%|▎         | 130/4545 [08:48<4:47:49,  3.91s/it]                                                    {'loss': 0.6736, 'grad_norm': 320.1873474121094, 'learning_rate': 8.520475561426684e-09, 'rewards/chosen': 0.026343917474150658, 'rewards/rejected': -0.03560638427734375, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.06210022047162056, 'logps/chosen': -398.75, 'logps/rejected': -264.3999938964844, 'logits/chosen': -6.162499904632568, 'logits/rejected': -6.375, 'epoch': 0.09}
  3%|▎         | 130/4545 [08:49<4:47:49,  3.91s/it]  3%|▎         | 131/4545 [08:53<5:04:38,  4.14s/it]  3%|▎         | 132/4545 [08:56<4:51:03,  3.96s/it]  3%|▎         | 133/4545 [08:59<4:30:46,  3.68s/it]  3%|▎         | 134/4545 [09:03<4:26:50,  3.63s/it]  3%|▎         | 135/4545 [09:05<4:00:48,  3.28s/it]  3%|▎         | 136/4545 [09:08<3:57:08,  3.23s/it]  3%|▎         | 137/4545 [09:12<4:15:54,  3.48s/it]  3%|▎         | 138/4545 [09:16<4:25:50,  3.62s/it]  3%|▎         | 139/4545 [09:20<4:29:34,  3.67s/it]  3%|▎         | 140/4545 [09:24<4:35:07,  3.75s/it]                                                    {'loss': 0.6939, 'grad_norm': 324.3599853515625, 'learning_rate': 9.180977542932628e-09, 'rewards/chosen': 0.0027404786087572575, 'rewards/rejected': -0.00130462646484375, 'rewards/accuracies': 0.4312500059604645, 'rewards/margins': 0.0040191649459302425, 'logps/chosen': -325.6000061035156, 'logps/rejected': -180.89999389648438, 'logits/chosen': -6.425000190734863, 'logits/rejected': -6.784375190734863, 'epoch': 0.09}
  3%|▎         | 140/4545 [09:24<4:35:07,  3.75s/it]  3%|▎         | 141/4545 [09:28<4:39:30,  3.81s/it]  3%|▎         | 142/4545 [09:32<4:45:33,  3.89s/it]  3%|▎         | 143/4545 [09:36<4:47:39,  3.92s/it]  3%|▎         | 144/4545 [09:40<4:47:27,  3.92s/it]  3%|▎         | 145/4545 [09:44<4:47:15,  3.92s/it]  3%|▎         | 146/4545 [09:47<4:37:34,  3.79s/it]  3%|▎         | 147/4545 [09:51<4:34:19,  3.74s/it]  3%|▎         | 148/4545 [09:55<4:38:24,  3.80s/it]  3%|▎         | 149/4545 [09:59<4:41:12,  3.84s/it]  3%|▎         | 150/4545 [10:02<4:24:14,  3.61s/it]                                                    {'loss': 0.7181, 'grad_norm': 34.059898376464844, 'learning_rate': 9.841479524438572e-09, 'rewards/chosen': -0.00054931640625, 'rewards/rejected': 0.03065795823931694, 'rewards/accuracies': 0.375, 'rewards/margins': -0.03121032752096653, 'logps/chosen': -283.29998779296875, 'logps/rejected': -116.7750015258789, 'logits/chosen': -6.34375, 'logits/rejected': -6.690625190734863, 'epoch': 0.1}
  3%|▎         | 150/4545 [10:02<4:24:14,  3.61s/it]  3%|▎         | 151/4545 [10:05<4:12:39,  3.45s/it]  3%|▎         | 152/4545 [10:09<4:19:29,  3.54s/it]  3%|▎         | 153/4545 [10:13<4:28:03,  3.66s/it]  3%|▎         | 154/4545 [10:16<4:27:18,  3.65s/it]  3%|▎         | 155/4545 [10:20<4:33:40,  3.74s/it]  3%|▎         | 156/4545 [10:24<4:34:32,  3.75s/it]  3%|▎         | 157/4545 [10:28<4:34:46,  3.76s/it]  3%|▎         | 158/4545 [10:32<4:33:57,  3.75s/it]  3%|▎         | 159/4545 [10:36<4:43:43,  3.88s/it]  4%|▎         | 160/4545 [10:40<4:45:05,  3.90s/it]                                                    {'loss': 0.6936, 'grad_norm': 180.0369873046875, 'learning_rate': 1.0501981505944516e-08, 'rewards/chosen': 0.0017456054920330644, 'rewards/rejected': -0.0032638548873364925, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.004992675967514515, 'logps/chosen': -295.3999938964844, 'logps/rejected': -159.6999969482422, 'logits/chosen': -6.209374904632568, 'logits/rejected': -6.618750095367432, 'epoch': 0.11}
  4%|▎         | 160/4545 [10:40<4:45:05,  3.90s/it]  4%|▎         | 161/4545 [10:44<4:51:29,  3.99s/it]  4%|▎         | 162/4545 [10:48<4:50:13,  3.97s/it]  4%|▎         | 163/4545 [10:52<4:54:16,  4.03s/it]  4%|▎         | 164/4545 [10:56<4:51:59,  4.00s/it]  4%|▎         | 165/4545 [10:59<4:40:11,  3.84s/it]  4%|▎         | 166/4545 [11:03<4:42:14,  3.87s/it]  4%|▎         | 167/4545 [11:07<4:43:44,  3.89s/it]  4%|▎         | 168/4545 [11:11<4:44:54,  3.91s/it]  4%|▎         | 169/4545 [11:15<4:44:40,  3.90s/it]  4%|▎         | 170/4545 [11:19<4:45:16,  3.91s/it]                                                    {'loss': 0.7227, 'grad_norm': 602.474609375, 'learning_rate': 1.1162483487450462e-08, 'rewards/chosen': 0.02846374548971653, 'rewards/rejected': 0.03245849534869194, 'rewards/accuracies': 0.4312500059604645, 'rewards/margins': -0.0040191649459302425, 'logps/chosen': -464.6499938964844, 'logps/rejected': -206.4250030517578, 'logits/chosen': -6.053124904632568, 'logits/rejected': -6.703125, 'epoch': 0.11}
  4%|▎         | 170/4545 [11:19<4:45:16,  3.91s/it]  4%|▍         | 171/4545 [11:22<4:23:36,  3.62s/it]  4%|▍         | 172/4545 [11:26<4:34:48,  3.77s/it]  4%|▍         | 173/4545 [11:30<4:38:24,  3.82s/it]  4%|▍         | 174/4545 [11:34<4:43:44,  3.89s/it]  4%|▍         | 175/4545 [11:37<4:30:41,  3.72s/it]  4%|▍         | 176/4545 [11:41<4:35:33,  3.78s/it]  4%|▍         | 177/4545 [11:44<4:13:22,  3.48s/it]  4%|▍         | 178/4545 [11:48<4:23:55,  3.63s/it]  4%|▍         | 179/4545 [11:51<4:15:46,  3.52s/it]  4%|▍         | 180/4545 [11:55<4:24:52,  3.64s/it]                                                    {'loss': 0.6845, 'grad_norm': 50.920188903808594, 'learning_rate': 1.1822985468956406e-08, 'rewards/chosen': 0.04641113430261612, 'rewards/rejected': -0.004437255673110485, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.050811767578125, 'logps/chosen': -284.45001220703125, 'logps/rejected': -182.125, 'logits/chosen': -6.337500095367432, 'logits/rejected': -6.587500095367432, 'epoch': 0.12}
  4%|▍         | 180/4545 [11:55<4:24:52,  3.64s/it]  4%|▍         | 181/4545 [11:59<4:32:20,  3.74s/it]  4%|▍         | 182/4545 [12:03<4:22:29,  3.61s/it]  4%|▍         | 183/4545 [12:06<4:26:53,  3.67s/it]  4%|▍         | 184/4545 [12:10<4:32:34,  3.75s/it]  4%|▍         | 185/4545 [12:14<4:36:37,  3.81s/it]  4%|▍         | 186/4545 [12:18<4:32:15,  3.75s/it]  4%|▍         | 187/4545 [12:22<4:36:03,  3.80s/it]  4%|▍         | 188/4545 [12:25<4:21:08,  3.60s/it]  4%|▍         | 189/4545 [12:28<4:12:22,  3.48s/it]  4%|▍         | 190/4545 [12:31<4:04:27,  3.37s/it]                                                    {'loss': 0.7149, 'grad_norm': 49.83602523803711, 'learning_rate': 1.248348745046235e-08, 'rewards/chosen': -0.01791992224752903, 'rewards/rejected': 0.016951750963926315, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.03481139987707138, 'logps/chosen': -302.45001220703125, 'logps/rejected': -155.77499389648438, 'logits/chosen': -6.3125, 'logits/rejected': -6.731249809265137, 'epoch': 0.13}
  4%|▍         | 190/4545 [12:31<4:04:27,  3.37s/it]  4%|▍         | 191/4545 [12:35<4:16:52,  3.54s/it]  4%|▍         | 192/4545 [12:39<4:20:10,  3.59s/it]  4%|▍         | 193/4545 [12:42<4:03:21,  3.36s/it]  4%|▍         | 194/4545 [12:45<3:51:40,  3.19s/it]  4%|▍         | 195/4545 [12:49<4:11:01,  3.46s/it]  4%|▍         | 196/4545 [12:52<4:18:58,  3.57s/it]  4%|▍         | 197/4545 [12:57<4:34:03,  3.78s/it]  4%|▍         | 198/4545 [13:01<4:37:31,  3.83s/it]  4%|▍         | 199/4545 [13:05<4:38:55,  3.85s/it]  4%|▍         | 200/4545 [13:08<4:40:18,  3.87s/it]                                                    {'loss': 0.7323, 'grad_norm': 504.11065673828125, 'learning_rate': 1.3143989431968294e-08, 'rewards/chosen': 0.01142272911965847, 'rewards/rejected': 0.05018310621380806, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': -0.03860015794634819, 'logps/chosen': -356.67498779296875, 'logps/rejected': -241.1999969482422, 'logits/chosen': -6.178124904632568, 'logits/rejected': -6.603125095367432, 'epoch': 0.13}
  4%|▍         | 200/4545 [13:09<4:40:18,  3.87s/it]  4%|▍         | 201/4545 [13:12<4:42:43,  3.91s/it]  4%|▍         | 202/4545 [13:16<4:41:07,  3.88s/it]  4%|▍         | 203/4545 [13:20<4:38:42,  3.85s/it]  4%|▍         | 204/4545 [13:24<4:46:55,  3.97s/it]  5%|▍         | 205/4545 [13:28<4:43:56,  3.93s/it]  5%|▍         | 206/4545 [13:32<4:44:12,  3.93s/it]  5%|▍         | 207/4545 [13:36<4:44:38,  3.94s/it]  5%|▍         | 208/4545 [13:40<4:35:01,  3.80s/it]  5%|▍         | 209/4545 [13:44<4:42:03,  3.90s/it]  5%|▍         | 210/4545 [13:48<4:48:56,  4.00s/it]                                                    {'loss': 0.7046, 'grad_norm': 377.90972900390625, 'learning_rate': 1.380449141347424e-08, 'rewards/chosen': -0.01762695237994194, 'rewards/rejected': -0.0059684752486646175, 'rewards/accuracies': 0.35624998807907104, 'rewards/margins': -0.011592102237045765, 'logps/chosen': -296.3500061035156, 'logps/rejected': -194.75, 'logits/chosen': -6.262499809265137, 'logits/rejected': -6.546875, 'epoch': 0.14}
  5%|▍         | 210/4545 [13:48<4:48:56,  4.00s/it]  5%|▍         | 211/4545 [13:52<4:50:01,  4.01s/it]  5%|▍         | 212/4545 [13:56<4:50:54,  4.03s/it]  5%|▍         | 213/4545 [14:00<4:48:37,  4.00s/it]  5%|▍         | 214/4545 [14:04<4:46:23,  3.97s/it]  5%|▍         | 215/4545 [14:08<4:44:00,  3.94s/it]  5%|▍         | 216/4545 [14:12<4:44:12,  3.94s/it]  5%|▍         | 217/4545 [14:16<4:44:02,  3.94s/it]  5%|▍         | 218/4545 [14:19<4:44:01,  3.94s/it]  5%|▍         | 219/4545 [14:23<4:29:44,  3.74s/it]  5%|▍         | 220/4545 [14:27<4:37:53,  3.86s/it]                                                    {'loss': 0.7116, 'grad_norm': 48.5986442565918, 'learning_rate': 1.4464993394980185e-08, 'rewards/chosen': -0.0026977539528161287, 'rewards/rejected': 0.0007369995000772178, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.003387451171875, 'logps/chosen': -326.75, 'logps/rejected': -182.25, 'logits/chosen': -6.268750190734863, 'logits/rejected': -6.599999904632568, 'epoch': 0.15}
  5%|▍         | 220/4545 [14:27<4:37:53,  3.86s/it]  5%|▍         | 221/4545 [14:31<4:32:33,  3.78s/it]  5%|▍         | 222/4545 [14:35<4:42:02,  3.91s/it]  5%|▍         | 223/4545 [14:39<4:42:21,  3.92s/it]  5%|▍         | 224/4545 [14:43<4:42:39,  3.93s/it]  5%|▍         | 225/4545 [14:47<4:48:54,  4.01s/it]  5%|▍         | 226/4545 [14:49<4:17:57,  3.58s/it]  5%|▍         | 227/4545 [14:53<4:25:44,  3.69s/it]  5%|▌         | 228/4545 [14:57<4:24:45,  3.68s/it]  5%|▌         | 229/4545 [15:00<4:15:18,  3.55s/it]  5%|▌         | 230/4545 [15:04<4:23:44,  3.67s/it]                                                    {'loss': 0.7128, 'grad_norm': 826.9734497070312, 'learning_rate': 1.5125495376486128e-08, 'rewards/chosen': 0.03603210300207138, 'rewards/rejected': 0.00298309326171875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 0.03311615064740181, 'logps/chosen': -488.1499938964844, 'logps/rejected': -244.10000610351562, 'logits/chosen': -6.046875, 'logits/rejected': -6.315625190734863, 'epoch': 0.15}
  5%|▌         | 230/4545 [15:04<4:23:44,  3.67s/it]  5%|▌         | 231/4545 [15:08<4:36:57,  3.85s/it]  5%|▌         | 232/4545 [15:13<4:43:06,  3.94s/it]  5%|▌         | 233/4545 [15:16<4:36:53,  3.85s/it]  5%|▌         | 234/4545 [15:20<4:40:12,  3.90s/it]  5%|▌         | 235/4545 [15:24<4:44:41,  3.96s/it]  5%|▌         | 236/4545 [15:28<4:32:17,  3.79s/it]  5%|▌         | 237/4545 [15:32<4:36:34,  3.85s/it]  5%|▌         | 238/4545 [15:34<4:02:44,  3.38s/it]  5%|▌         | 239/4545 [15:38<4:17:14,  3.58s/it]  5%|▌         | 240/4545 [15:42<4:27:19,  3.73s/it]                                                    {'loss': 0.6896, 'grad_norm': 319.9150085449219, 'learning_rate': 1.5785997357992072e-08, 'rewards/chosen': 0.01994018629193306, 'rewards/rejected': 0.00954284705221653, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': 0.010388183407485485, 'logps/chosen': -298.3999938964844, 'logps/rejected': -137.02499389648438, 'logits/chosen': -6.290625095367432, 'logits/rejected': -6.587500095367432, 'epoch': 0.16}
  5%|▌         | 240/4545 [15:42<4:27:19,  3.73s/it]  5%|▌         | 241/4545 [15:45<4:17:01,  3.58s/it]  5%|▌         | 242/4545 [15:50<4:29:55,  3.76s/it]  5%|▌         | 243/4545 [15:53<4:16:32,  3.58s/it]  5%|▌         | 244/4545 [15:57<4:24:05,  3.68s/it]  5%|▌         | 245/4545 [16:01<4:29:29,  3.76s/it]  5%|▌         | 246/4545 [16:05<4:32:29,  3.80s/it]  5%|▌         | 247/4545 [16:08<4:36:14,  3.86s/it]  5%|▌         | 248/4545 [16:12<4:38:00,  3.88s/it]  5%|▌         | 249/4545 [16:16<4:39:22,  3.90s/it]  6%|▌         | 250/4545 [16:21<4:46:27,  4.00s/it]                                                    {'loss': 0.6884, 'grad_norm': 39.77725601196289, 'learning_rate': 1.644649933949802e-08, 'rewards/chosen': 0.11232338100671768, 'rewards/rejected': 0.01017150841653347, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.10216674953699112, 'logps/chosen': -395.95001220703125, 'logps/rejected': -172.5749969482422, 'logits/chosen': -6.121874809265137, 'logits/rejected': -6.328125, 'epoch': 0.17}
  6%|▌         | 250/4545 [16:21<4:46:27,  4.00s/it]  6%|▌         | 251/4545 [16:25<4:44:48,  3.98s/it]  6%|▌         | 252/4545 [16:28<4:44:07,  3.97s/it]  6%|▌         | 253/4545 [16:32<4:28:49,  3.76s/it]  6%|▌         | 254/4545 [16:36<4:31:42,  3.80s/it]  6%|▌         | 255/4545 [16:39<4:32:28,  3.81s/it]  6%|▌         | 256/4545 [16:44<4:40:53,  3.93s/it]  6%|▌         | 257/4545 [16:48<4:44:33,  3.98s/it]  6%|▌         | 258/4545 [16:51<4:34:46,  3.85s/it]  6%|▌         | 259/4545 [16:53<3:55:19,  3.29s/it]  6%|▌         | 260/4545 [16:58<4:14:07,  3.56s/it]                                                    {'loss': 0.6995, 'grad_norm': 686.390625, 'learning_rate': 1.710700132100396e-08, 'rewards/chosen': 0.01846160925924778, 'rewards/rejected': 0.02241497114300728, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.0039535523392260075, 'logps/chosen': -212.10000610351562, 'logps/rejected': -105.0, 'logits/chosen': -6.459374904632568, 'logits/rejected': -6.743750095367432, 'epoch': 0.17}
  6%|▌         | 260/4545 [16:58<4:14:07,  3.56s/it]  6%|▌         | 261/4545 [17:01<4:19:08,  3.63s/it]  6%|▌         | 262/4545 [17:05<4:25:31,  3.72s/it]  6%|▌         | 263/4545 [17:09<4:33:41,  3.83s/it]  6%|▌         | 264/4545 [17:13<4:21:26,  3.66s/it]  6%|▌         | 265/4545 [17:17<4:27:27,  3.75s/it]  6%|▌         | 266/4545 [17:20<4:31:32,  3.81s/it]  6%|▌         | 267/4545 [17:24<4:34:24,  3.85s/it]  6%|▌         | 268/4545 [17:28<4:22:34,  3.68s/it]  6%|▌         | 269/4545 [17:32<4:27:54,  3.76s/it]  6%|▌         | 270/4545 [17:36<4:31:17,  3.81s/it]                                                    {'loss': 0.7234, 'grad_norm': 367.18157958984375, 'learning_rate': 1.7767503302509907e-08, 'rewards/chosen': 0.02607879601418972, 'rewards/rejected': 0.02517242357134819, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': 0.0008331298595294356, 'logps/chosen': -463.95001220703125, 'logps/rejected': -260.0249938964844, 'logits/chosen': -6.206250190734863, 'logits/rejected': -6.396874904632568, 'epoch': 0.18}
  6%|▌         | 270/4545 [17:36<4:31:17,  3.81s/it]  6%|▌         | 271/4545 [17:40<4:34:59,  3.86s/it]  6%|▌         | 272/4545 [17:43<4:31:55,  3.82s/it]  6%|▌         | 273/4545 [17:47<4:34:10,  3.85s/it]  6%|▌         | 274/4545 [17:51<4:37:18,  3.90s/it]  6%|▌         | 275/4545 [17:54<4:19:06,  3.64s/it]  6%|▌         | 276/4545 [17:59<4:33:04,  3.84s/it]  6%|▌         | 277/4545 [18:03<4:35:54,  3.88s/it]  6%|▌         | 278/4545 [18:06<4:37:27,  3.90s/it]  6%|▌         | 279/4545 [18:10<4:28:30,  3.78s/it]  6%|▌         | 280/4545 [18:14<4:32:33,  3.83s/it]                                                    {'loss': 0.7012, 'grad_norm': 64.52909851074219, 'learning_rate': 1.842800528401585e-08, 'rewards/chosen': 0.08439788967370987, 'rewards/rejected': 0.02950439415872097, 'rewards/accuracies': 0.40625, 'rewards/margins': 0.05492553859949112, 'logps/chosen': -392.04998779296875, 'logps/rejected': -171.47500610351562, 'logits/chosen': -6.34375, 'logits/rejected': -6.65625, 'epoch': 0.18}
  6%|▌         | 280/4545 [18:14<4:32:33,  3.83s/it]  6%|▌         | 281/4545 [18:18<4:40:07,  3.94s/it]  6%|▌         | 282/4545 [18:21<4:17:51,  3.63s/it]  6%|▌         | 283/4545 [18:24<4:11:05,  3.53s/it]  6%|▌         | 284/4545 [18:28<4:20:50,  3.67s/it]  6%|▋         | 285/4545 [18:32<4:27:01,  3.76s/it]  6%|▋         | 286/4545 [18:35<4:12:46,  3.56s/it]  6%|▋         | 287/4545 [18:38<3:57:03,  3.34s/it]  6%|▋         | 288/4545 [18:42<4:05:45,  3.46s/it]  6%|▋         | 289/4545 [18:46<4:15:42,  3.60s/it]  6%|▋         | 290/4545 [18:50<4:23:00,  3.71s/it]                                                    {'loss': 0.673, 'grad_norm': 481.0479736328125, 'learning_rate': 1.9088507265521795e-08, 'rewards/chosen': 0.08306274563074112, 'rewards/rejected': -0.0063156126998364925, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08945922553539276, 'logps/chosen': -379.25, 'logps/rejected': -227.72500610351562, 'logits/chosen': -6.090624809265137, 'logits/rejected': -6.53125, 'epoch': 0.19}
  6%|▋         | 290/4545 [18:50<4:23:00,  3.71s/it]  6%|▋         | 291/4545 [18:53<4:19:42,  3.66s/it]  6%|▋         | 292/4545 [18:57<4:25:36,  3.75s/it]  6%|▋         | 293/4545 [19:01<4:32:57,  3.85s/it]  6%|▋         | 294/4545 [19:05<4:34:34,  3.88s/it]  6%|▋         | 295/4545 [19:09<4:27:23,  3.78s/it]  7%|▋         | 296/4545 [19:13<4:30:52,  3.82s/it]  7%|▋         | 297/4545 [19:17<4:33:08,  3.86s/it]  7%|▋         | 298/4545 [19:20<4:10:08,  3.53s/it]  7%|▋         | 299/4545 [19:24<4:27:23,  3.78s/it]  7%|▋         | 300/4545 [19:27<4:14:17,  3.59s/it]                                                    {'loss': 0.696, 'grad_norm': 45.20180892944336, 'learning_rate': 1.974900924702774e-08, 'rewards/chosen': 0.04552306979894638, 'rewards/rejected': 0.0022140503861010075, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.04337005689740181, 'logps/chosen': -284.0, 'logps/rejected': -149.35000610351562, 'logits/chosen': -6.234375, 'logits/rejected': -6.5, 'epoch': 0.2}
  7%|▋         | 300/4545 [19:27<4:14:17,  3.59s/it]  7%|▋         | 301/4545 [19:30<4:08:24,  3.51s/it]  7%|▋         | 302/4545 [19:35<4:21:29,  3.70s/it]  7%|▋         | 303/4545 [19:37<4:02:14,  3.43s/it]  7%|▋         | 304/4545 [19:41<4:08:40,  3.52s/it]  7%|▋         | 305/4545 [19:45<4:19:17,  3.67s/it]  7%|▋         | 306/4545 [19:49<4:25:02,  3.75s/it]  7%|▋         | 307/4545 [19:53<4:28:47,  3.81s/it]  7%|▋         | 308/4545 [19:57<4:31:27,  3.84s/it]  7%|▋         | 309/4545 [20:01<4:34:46,  3.89s/it]  7%|▋         | 310/4545 [20:05<4:37:12,  3.93s/it]                                                    {'loss': 0.6589, 'grad_norm': 275.559326171875, 'learning_rate': 2.0409511228533686e-08, 'rewards/chosen': 0.33035582304000854, 'rewards/rejected': 0.01934967003762722, 'rewards/accuracies': 0.5, 'rewards/margins': 0.31117552518844604, 'logps/chosen': -481.95001220703125, 'logps/rejected': -264.0, 'logits/chosen': -6.087500095367432, 'logits/rejected': -6.215624809265137, 'epoch': 0.2}
  7%|▋         | 310/4545 [20:05<4:37:12,  3.93s/it]  7%|▋         | 311/4545 [20:09<4:39:29,  3.96s/it]  7%|▋         | 312/4545 [20:12<4:21:50,  3.71s/it]  7%|▋         | 313/4545 [20:16<4:26:41,  3.78s/it]  7%|▋         | 314/4545 [20:20<4:30:09,  3.83s/it]  7%|▋         | 315/4545 [20:24<4:32:29,  3.87s/it]  7%|▋         | 316/4545 [20:28<4:32:09,  3.86s/it]  7%|▋         | 317/4545 [20:30<4:03:08,  3.45s/it]  7%|▋         | 318/4545 [20:34<4:13:23,  3.60s/it]  7%|▋         | 319/4545 [20:38<4:21:25,  3.71s/it]  7%|▋         | 320/4545 [20:42<4:26:56,  3.79s/it]                                                    {'loss': 0.7076, 'grad_norm': 56.215633392333984, 'learning_rate': 2.107001321003963e-08, 'rewards/chosen': 0.04265747219324112, 'rewards/rejected': 0.0058044432662427425, 'rewards/accuracies': 0.48124998807907104, 'rewards/margins': 0.036818694323301315, 'logps/chosen': -290.70001220703125, 'logps/rejected': -168.9499969482422, 'logits/chosen': -6.356249809265137, 'logits/rejected': -6.712500095367432, 'epoch': 0.21}
  7%|▋         | 320/4545 [20:42<4:26:56,  3.79s/it]  7%|▋         | 321/4545 [20:46<4:18:29,  3.67s/it]  7%|▋         | 322/4545 [20:50<4:26:12,  3.78s/it]  7%|▋         | 323/4545 [20:54<4:36:25,  3.93s/it]  7%|▋         | 324/4545 [20:57<4:29:23,  3.83s/it]  7%|▋         | 325/4545 [21:01<4:25:45,  3.78s/it]  7%|▋         | 326/4545 [21:05<4:28:54,  3.82s/it]  7%|▋         | 327/4545 [21:09<4:34:19,  3.90s/it]  7%|▋         | 328/4545 [21:13<4:35:11,  3.92s/it]  7%|▋         | 329/4545 [21:17<4:35:29,  3.92s/it]  7%|▋         | 330/4545 [21:21<4:33:28,  3.89s/it]                                                    {'loss': 0.7445, 'grad_norm': 51.02286148071289, 'learning_rate': 2.1730515191545574e-08, 'rewards/chosen': 0.0029815672896802425, 'rewards/rejected': 0.032906342297792435, 'rewards/accuracies': 0.46875, 'rewards/margins': -0.02995147742331028, 'logps/chosen': -227.39999389648438, 'logps/rejected': -147.35000610351562, 'logits/chosen': -6.396874904632568, 'logits/rejected': -6.415625095367432, 'epoch': 0.22}
  7%|▋         | 330/4545 [21:21<4:33:28,  3.89s/it]  7%|▋         | 331/4545 [21:24<4:20:30,  3.71s/it]  7%|▋         | 332/4545 [21:28<4:28:52,  3.83s/it]  7%|▋         | 333/4545 [21:32<4:22:18,  3.74s/it]  7%|▋         | 334/4545 [21:36<4:30:40,  3.86s/it]  7%|▋         | 335/4545 [21:39<4:20:24,  3.71s/it]  7%|▋         | 336/4545 [21:43<4:10:37,  3.57s/it]  7%|▋         | 337/4545 [21:47<4:22:35,  3.74s/it]  7%|▋         | 338/4545 [21:50<4:09:53,  3.56s/it]  7%|▋         | 339/4545 [21:54<4:17:49,  3.68s/it]  7%|▋         | 340/4545 [21:58<4:23:34,  3.76s/it]                                                    {'loss': 0.6946, 'grad_norm': 69.28193664550781, 'learning_rate': 2.239101717305152e-08, 'rewards/chosen': 0.04502563551068306, 'rewards/rejected': 0.03087768517434597, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 0.014134978875517845, 'logps/chosen': -178.8000030517578, 'logps/rejected': -114.2750015258789, 'logits/chosen': -6.453125, 'logits/rejected': -6.790625095367432, 'epoch': 0.22}
  7%|▋         | 340/4545 [21:58<4:23:34,  3.76s/it]  8%|▊         | 341/4545 [22:02<4:29:46,  3.85s/it]  8%|▊         | 342/4545 [22:06<4:31:27,  3.88s/it]  8%|▊         | 343/4545 [22:10<4:34:27,  3.92s/it]  8%|▊         | 344/4545 [22:13<4:28:20,  3.83s/it]  8%|▊         | 345/4545 [22:16<4:09:07,  3.56s/it]  8%|▊         | 346/4545 [22:20<4:17:36,  3.68s/it]  8%|▊         | 347/4545 [22:24<4:28:26,  3.84s/it]  8%|▊         | 348/4545 [22:29<4:34:46,  3.93s/it]  8%|▊         | 349/4545 [22:33<4:35:15,  3.94s/it]  8%|▊         | 350/4545 [22:36<4:35:09,  3.94s/it]                                                    {'loss': 0.6709, 'grad_norm': 34.739662170410156, 'learning_rate': 2.3051519154557462e-08, 'rewards/chosen': 0.20089110732078552, 'rewards/rejected': -0.008251952938735485, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.2091064453125, 'logps/chosen': -400.04998779296875, 'logps/rejected': -194.89999389648438, 'logits/chosen': -6.125, 'logits/rejected': -6.290625095367432, 'epoch': 0.23}
  8%|▊         | 350/4545 [22:37<4:35:09,  3.94s/it]  8%|▊         | 351/4545 [22:40<4:36:00,  3.95s/it]  8%|▊         | 352/4545 [22:43<4:07:47,  3.55s/it]  8%|▊         | 353/4545 [22:47<4:16:30,  3.67s/it]  8%|▊         | 354/4545 [22:51<4:22:42,  3.76s/it]  8%|▊         | 355/4545 [23:24<14:37:59, 12.57s/it]  8%|▊         | 356/4545 [23:32<12:52:44, 11.07s/it]  8%|▊         | 357/4545 [23:39<11:24:51,  9.81s/it]  8%|▊         | 358/4545 [23:45<10:03:34,  8.65s/it]  8%|▊         | 359/4545 [23:52<9:38:31,  8.29s/it]   8%|▊         | 360/4545 [23:59<9:22:04,  8.06s/it]                                                    {'loss': 0.6926, 'grad_norm': 139.931396484375, 'learning_rate': 2.3712021136063406e-08, 'rewards/chosen': 0.14461669325828552, 'rewards/rejected': 0.03372802585363388, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.11090698093175888, 'logps/chosen': -330.6499938964844, 'logps/rejected': -172.4250030517578, 'logits/chosen': -6.278124809265137, 'logits/rejected': -6.543749809265137, 'epoch': 0.24}
  8%|▊         | 360/4545 [24:00<9:22:04,  8.06s/it]  8%|▊         | 361/4545 [24:06<8:55:50,  7.68s/it]  8%|▊         | 362/4545 [24:14<8:52:15,  7.63s/it]  8%|▊         | 363/4545 [24:21<8:50:00,  7.60s/it]  8%|▊         | 364/4545 [24:28<8:30:05,  7.32s/it]  8%|▊         | 365/4545 [24:35<8:32:13,  7.35s/it]  8%|▊         | 366/4545 [24:43<8:37:15,  7.43s/it]  8%|▊         | 367/4545 [24:51<8:41:15,  7.49s/it]  8%|▊         | 368/4545 [24:58<8:40:27,  7.48s/it]  8%|▊         | 369/4545 [25:06<8:40:27,  7.48s/it]  8%|▊         | 370/4545 [25:13<8:40:21,  7.48s/it]                                                    {'loss': 0.6782, 'grad_norm': 60.869873046875, 'learning_rate': 2.437252311756935e-08, 'rewards/chosen': 0.2560791075229645, 'rewards/rejected': 0.0416412353515625, 'rewards/accuracies': 0.40625, 'rewards/margins': 0.21430663764476776, 'logps/chosen': -492.54998779296875, 'logps/rejected': -244.1999969482422, 'logits/chosen': -6.203125, 'logits/rejected': -6.568749904632568, 'epoch': 0.24}
  8%|▊         | 370/4545 [25:13<8:40:21,  7.48s/it]  8%|▊         | 371/4545 [25:20<8:28:26,  7.31s/it]  8%|▊         | 372/4545 [25:28<8:38:26,  7.45s/it]  8%|▊         | 373/4545 [25:35<8:40:50,  7.49s/it]  8%|▊         | 374/4545 [25:43<8:33:58,  7.39s/it]  8%|▊         | 375/4545 [25:49<8:13:28,  7.10s/it]  8%|▊         | 376/4545 [25:56<8:21:21,  7.22s/it]  8%|▊         | 377/4545 [26:04<8:28:27,  7.32s/it]  8%|▊         | 378/4545 [26:11<8:31:28,  7.36s/it]  8%|▊         | 379/4545 [26:16<7:42:11,  6.66s/it]  8%|▊         | 380/4545 [26:24<7:58:33,  6.89s/it]                                                    {'loss': 0.6858, 'grad_norm': 34.44125747680664, 'learning_rate': 2.5033025099075294e-08, 'rewards/chosen': 0.0840301513671875, 'rewards/rejected': 0.01686554029583931, 'rewards/accuracies': 0.4937500059604645, 'rewards/margins': 0.067108154296875, 'logps/chosen': -209.89999389648438, 'logps/rejected': -136.60000610351562, 'logits/chosen': -6.381249904632568, 'logits/rejected': -6.618750095367432, 'epoch': 0.25}
  8%|▊         | 380/4545 [26:24<7:58:33,  6.89s/it]  8%|▊         | 381/4545 [26:31<7:58:36,  6.90s/it]  8%|▊         | 382/4545 [26:38<8:10:12,  7.07s/it]  8%|▊         | 383/4545 [26:46<8:17:27,  7.17s/it]  8%|▊         | 384/4545 [26:53<8:24:47,  7.28s/it]  8%|▊         | 385/4545 [27:01<8:26:33,  7.31s/it]  8%|▊         | 386/4545 [27:08<8:30:53,  7.37s/it]  9%|▊         | 387/4545 [27:50<20:37:22, 17.86s/it]  9%|▊         | 388/4545 [28:07<20:19:27, 17.60s/it]  9%|▊         | 389/4545 [28:24<20:03:22, 17.37s/it]  9%|▊         | 390/4545 [28:41<19:54:53, 17.25s/it]                                                     {'loss': 0.6992, 'grad_norm': 479.9858703613281, 'learning_rate': 2.569352708058124e-08, 'rewards/chosen': 0.07872314751148224, 'rewards/rejected': 0.02285156212747097, 'rewards/accuracies': 0.4437499940395355, 'rewards/margins': 0.05579528957605362, 'logps/chosen': -377.54998779296875, 'logps/rejected': -191.64999389648438, 'logits/chosen': -6.234375, 'logits/rejected': -6.571875095367432, 'epoch': 0.26}
  9%|▊         | 390/4545 [28:41<19:54:53, 17.25s/it]  9%|▊         | 391/4545 [28:59<19:57:00, 17.29s/it]  9%|▊         | 392/4545 [29:16<19:54:27, 17.26s/it]  9%|▊         | 393/4545 [29:33<19:46:41, 17.15s/it]  9%|▊         | 394/4545 [29:50<19:41:07, 17.07s/it]  9%|▊         | 395/4545 [30:06<19:34:23, 16.98s/it]  9%|▊         | 396/4545 [30:23<19:34:02, 16.98s/it]  9%|▊         | 397/4545 [30:41<19:47:33, 17.18s/it]  9%|▉         | 398/4545 [30:58<19:45:45, 17.16s/it]  9%|▉         | 399/4545 [31:15<19:43:34, 17.13s/it]  9%|▉         | 400/4545 [31:32<19:45:44, 17.16s/it]                                                     {'loss': 0.6774, 'grad_norm': 55.10557556152344, 'learning_rate': 2.6354029062087186e-08, 'rewards/chosen': 0.1739501953125, 'rewards/rejected': 0.01231460552662611, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.16175231337547302, 'logps/chosen': -303.1499938964844, 'logps/rejected': -166.375, 'logits/chosen': -6.321875095367432, 'logits/rejected': -6.71875, 'epoch': 0.26}
  9%|▉         | 400/4545 [31:33<19:45:44, 17.16s/it]  9%|▉         | 401/4545 [31:49<19:29:45, 16.94s/it]  9%|▉         | 402/4545 [32:06<19:44:18, 17.15s/it]  9%|▉         | 403/4545 [32:24<19:44:46, 17.16s/it]  9%|▉         | 404/4545 [32:41<19:50:21, 17.25s/it]  9%|▉         | 405/4545 [32:57<19:17:26, 16.77s/it]  9%|▉         | 406/4545 [33:00<14:30:02, 12.61s/it]  9%|▉         | 407/4545 [33:02<11:06:30,  9.66s/it]  9%|▉         | 408/4545 [33:06<9:09:15,  7.97s/it]   9%|▉         | 409/4545 [33:10<7:37:25,  6.64s/it]  9%|▉         | 410/4545 [33:14<6:35:03,  5.73s/it]                                                    {'loss': 0.6999, 'grad_norm': 45.90869903564453, 'learning_rate': 2.701453104359313e-08, 'rewards/chosen': 0.09254150092601776, 'rewards/rejected': 0.026284407824277878, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.06619872897863388, 'logps/chosen': -199.85000610351562, 'logps/rejected': -128.5, 'logits/chosen': -6.309374809265137, 'logits/rejected': -6.599999904632568, 'epoch': 0.27}
  9%|▉         | 410/4545 [33:14<6:35:03,  5.73s/it]  9%|▉         | 411/4545 [33:18<5:58:53,  5.21s/it]  9%|▉         | 412/4545 [33:21<5:32:02,  4.82s/it]  9%|▉         | 413/4545 [33:25<5:02:04,  4.39s/it]  9%|▉         | 414/4545 [33:29<4:56:30,  4.31s/it]  9%|▉         | 415/4545 [33:32<4:23:39,  3.83s/it]  9%|▉         | 416/4545 [33:35<4:02:36,  3.53s/it]  9%|▉         | 417/4545 [33:38<4:11:11,  3.65s/it]  9%|▉         | 418/4545 [33:42<3:59:22,  3.48s/it]  9%|▉         | 419/4545 [33:45<4:08:41,  3.62s/it]  9%|▉         | 420/4545 [33:49<3:58:25,  3.47s/it]                                                    {'loss': 0.6818, 'grad_norm': 104.8524398803711, 'learning_rate': 2.7675033025099077e-08, 'rewards/chosen': 0.17500610649585724, 'rewards/rejected': 0.02112121507525444, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.1539863646030426, 'logps/chosen': -269.79998779296875, 'logps/rejected': -144.27499389648438, 'logits/chosen': -6.25, 'logits/rejected': -6.571875095367432, 'epoch': 0.28}
  9%|▉         | 420/4545 [33:49<3:58:25,  3.47s/it]  9%|▉         | 421/4545 [33:53<4:08:25,  3.61s/it]  9%|▉         | 422/4545 [33:56<4:14:47,  3.71s/it]  9%|▉         | 423/4545 [34:00<4:05:31,  3.57s/it]  9%|▉         | 424/4545 [34:03<4:06:07,  3.58s/it]  9%|▉         | 425/4545 [34:07<4:09:53,  3.64s/it]  9%|▉         | 426/4545 [34:11<4:15:27,  3.72s/it]  9%|▉         | 427/4545 [34:15<4:21:26,  3.81s/it]  9%|▉         | 428/4545 [34:17<3:46:58,  3.31s/it]  9%|▉         | 429/4545 [34:21<3:48:31,  3.33s/it]  9%|▉         | 430/4545 [34:25<4:03:34,  3.55s/it]                                                    {'loss': 0.6869, 'grad_norm': 68.59838104248047, 'learning_rate': 2.8335535006605014e-08, 'rewards/chosen': 0.13111571967601776, 'rewards/rejected': 0.05440216138958931, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.07645263522863388, 'logps/chosen': -283.7749938964844, 'logps/rejected': -120.1500015258789, 'logits/chosen': -6.143750190734863, 'logits/rejected': -6.518750190734863, 'epoch': 0.28}
  9%|▉         | 430/4545 [34:25<4:03:34,  3.55s/it]  9%|▉         | 431/4545 [34:29<4:19:40,  3.79s/it] 10%|▉         | 432/4545 [34:33<4:22:43,  3.83s/it] 10%|▉         | 433/4545 [34:37<4:27:38,  3.91s/it] 10%|▉         | 434/4545 [34:41<4:33:30,  3.99s/it] 10%|▉         | 435/4545 [34:44<4:11:39,  3.67s/it] 10%|▉         | 436/4545 [34:48<4:17:29,  3.76s/it] 10%|▉         | 437/4545 [34:52<4:26:07,  3.89s/it] 10%|▉         | 438/4545 [34:55<4:11:11,  3.67s/it] 10%|▉         | 439/4545 [34:58<3:54:38,  3.43s/it] 10%|▉         | 440/4545 [35:02<4:06:15,  3.60s/it]                                                    {'loss': 0.6839, 'grad_norm': 69.18516540527344, 'learning_rate': 2.8996036988110962e-08, 'rewards/chosen': 0.1331787109375, 'rewards/rejected': 0.06526489555835724, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.06792297214269638, 'logps/chosen': -214.3249969482422, 'logps/rejected': -163.9499969482422, 'logits/chosen': -6.293749809265137, 'logits/rejected': -6.509375095367432, 'epoch': 0.29}
 10%|▉         | 440/4545 [35:03<4:06:15,  3.60s/it] 10%|▉         | 441/4545 [35:06<4:14:46,  3.72s/it] 10%|▉         | 442/4545 [35:10<4:07:14,  3.62s/it] 10%|▉         | 443/4545 [35:39<12:53:42, 11.32s/it] 10%|▉         | 444/4545 [35:43<10:22:10,  9.10s/it] 10%|▉         | 445/4545 [35:46<8:11:18,  7.19s/it]  10%|▉         | 446/4545 [35:50<7:09:52,  6.29s/it] 10%|▉         | 447/4545 [35:52<5:52:28,  5.16s/it] 10%|▉         | 448/4545 [35:56<5:27:36,  4.80s/it] 10%|▉         | 449/4545 [36:00<5:09:37,  4.54s/it] 10%|▉         | 450/4545 [36:04<4:57:21,  4.36s/it]                                                    {'loss': 0.6452, 'grad_norm': 40.25138854980469, 'learning_rate': 2.9656538969616906e-08, 'rewards/chosen': 0.317678838968277, 'rewards/rejected': -0.020780181512236595, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.3384200930595398, 'logps/chosen': -362.54998779296875, 'logps/rejected': -181.375, 'logits/chosen': -6.196875095367432, 'logits/rejected': -6.525000095367432, 'epoch': 0.3}
 10%|▉         | 450/4545 [36:04<4:57:21,  4.36s/it] 10%|▉         | 451/4545 [36:08<4:51:31,  4.27s/it] 10%|▉         | 452/4545 [36:12<4:43:59,  4.16s/it] 10%|▉         | 453/4545 [36:16<4:40:05,  4.11s/it] 10%|▉         | 454/4545 [36:45<13:10:43, 11.60s/it] 10%|█         | 455/4545 [36:49<10:33:46,  9.30s/it] 10%|█         | 456/4545 [36:53<8:40:23,  7.64s/it]  10%|█         | 457/4545 [36:57<7:24:46,  6.53s/it] 10%|█         | 458/4545 [37:01<6:31:38,  5.75s/it] 10%|█         | 459/4545 [37:05<5:56:14,  5.23s/it] 10%|█         | 460/4545 [37:08<5:25:30,  4.78s/it]                                                    {'loss': 0.6827, 'grad_norm': 66.06932830810547, 'learning_rate': 3.031704095112285e-08, 'rewards/chosen': 0.3486167788505554, 'rewards/rejected': 0.015106201171875, 'rewards/accuracies': 0.48124998807907104, 'rewards/margins': 0.33295899629592896, 'logps/chosen': -540.0, 'logps/rejected': -280.54998779296875, 'logits/chosen': -6.071875095367432, 'logits/rejected': -6.337500095367432, 'epoch': 0.3}
 10%|█         | 460/4545 [37:09<5:25:30,  4.78s/it] 10%|█         | 461/4545 [37:12<5:07:29,  4.52s/it] 10%|█         | 462/4545 [37:17<4:59:09,  4.40s/it] 10%|█         | 463/4545 [37:20<4:50:07,  4.26s/it] 10%|█         | 464/4545 [37:24<4:28:50,  3.95s/it] 10%|█         | 465/4545 [37:28<4:28:29,  3.95s/it] 10%|█         | 466/4545 [37:31<4:06:30,  3.63s/it] 10%|█         | 467/4545 [37:34<4:12:50,  3.72s/it] 10%|█         | 468/4545 [37:38<4:17:43,  3.79s/it] 10%|█         | 469/4545 [37:42<4:20:44,  3.84s/it] 10%|█         | 470/4545 [37:45<3:52:56,  3.43s/it]                                                    {'loss': 0.6695, 'grad_norm': 44.64848709106445, 'learning_rate': 3.09775429326288e-08, 'rewards/chosen': 0.17276306450366974, 'rewards/rejected': 0.0028808594215661287, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.16998901963233948, 'logps/chosen': -208.10000610351562, 'logps/rejected': -99.9749984741211, 'logits/chosen': -6.287499904632568, 'logits/rejected': -6.375, 'epoch': 0.31}
 10%|█         | 470/4545 [37:45<3:52:56,  3.43s/it] 10%|█         | 471/4545 [37:49<4:04:53,  3.61s/it] 10%|█         | 472/4545 [37:53<4:16:50,  3.78s/it] 10%|█         | 473/4545 [37:57<4:22:21,  3.87s/it] 10%|█         | 474/4545 [38:01<4:22:03,  3.86s/it] 10%|█         | 475/4545 [38:05<4:23:44,  3.89s/it] 10%|█         | 476/4545 [38:09<4:27:52,  3.95s/it] 10%|█         | 477/4545 [38:13<4:27:21,  3.94s/it] 11%|█         | 478/4545 [38:17<4:21:24,  3.86s/it] 11%|█         | 479/4545 [38:20<4:10:10,  3.69s/it] 11%|█         | 480/4545 [38:24<4:15:49,  3.78s/it]                                                    {'loss': 0.6692, 'grad_norm': 254.34498596191406, 'learning_rate': 3.163804491413474e-08, 'rewards/chosen': 0.22804565727710724, 'rewards/rejected': -0.0037986754905432463, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.23179931938648224, 'logps/chosen': -274.04998779296875, 'logps/rejected': -161.625, 'logits/chosen': -6.25, 'logits/rejected': -6.578125, 'epoch': 0.32}
 11%|█         | 480/4545 [38:24<4:15:49,  3.78s/it] 11%|█         | 481/4545 [38:28<4:20:08,  3.84s/it] 11%|█         | 482/4545 [38:32<4:21:55,  3.87s/it] 11%|█         | 483/4545 [38:36<4:20:34,  3.85s/it] 11%|█         | 484/4545 [38:40<4:24:57,  3.91s/it] 11%|█         | 485/4545 [38:44<4:29:35,  3.98s/it] 11%|█         | 486/4545 [38:47<4:23:05,  3.89s/it] 11%|█         | 487/4545 [38:50<3:58:15,  3.52s/it] 11%|█         | 488/4545 [38:54<4:07:40,  3.66s/it] 11%|█         | 489/4545 [38:58<4:15:01,  3.77s/it] 11%|█         | 490/4545 [39:02<4:17:43,  3.81s/it]                                                    {'loss': 0.6744, 'grad_norm': 59.2936897277832, 'learning_rate': 3.2298546895640685e-08, 'rewards/chosen': 0.27559202909469604, 'rewards/rejected': 0.039592742919921875, 'rewards/accuracies': 0.53125, 'rewards/margins': 0.23583984375, 'logps/chosen': -260.79998779296875, 'logps/rejected': -112.44999694824219, 'logits/chosen': -6.337500095367432, 'logits/rejected': -6.550000190734863, 'epoch': 0.32}
 11%|█         | 490/4545 [39:02<4:17:43,  3.81s/it] 11%|█         | 491/4545 [39:05<3:52:03,  3.43s/it] 11%|█         | 492/4545 [39:09<4:04:37,  3.62s/it] 11%|█         | 493/4545 [39:13<4:17:02,  3.81s/it] 11%|█         | 494/4545 [39:17<4:23:27,  3.90s/it] 11%|█         | 495/4545 [39:21<4:20:24,  3.86s/it] 11%|█         | 496/4545 [39:24<4:13:23,  3.75s/it] 11%|█         | 497/4545 [39:28<4:14:23,  3.77s/it] 11%|█         | 498/4545 [39:32<4:18:02,  3.83s/it] 11%|█         | 499/4545 [39:36<4:18:31,  3.83s/it] 11%|█         | 500/4545 [39:40<4:22:18,  3.89s/it]                                                    {'loss': 0.6729, 'grad_norm': 57.01392364501953, 'learning_rate': 3.295904887714663e-08, 'rewards/chosen': 0.17359618842601776, 'rewards/rejected': 0.03309326246380806, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.14051666855812073, 'logps/chosen': -231.5, 'logps/rejected': -104.25, 'logits/chosen': -6.334374904632568, 'logits/rejected': -6.715624809265137, 'epoch': 0.33}
 11%|█         | 500/4545 [39:40<4:22:18,  3.89s/it] 11%|█         | 501/4545 [39:44<4:16:36,  3.81s/it] 11%|█         | 502/4545 [39:47<4:19:00,  3.84s/it] 11%|█         | 503/4545 [39:51<4:11:20,  3.73s/it] 11%|█         | 504/4545 [39:55<4:15:23,  3.79s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:44,  1.31it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:22,  1.55s/it][A
 13%|█▎        | 8/60 [00:11<01:27,  1.68s/it][A
 15%|█▌        | 9/60 [00:13<01:25,  1.67s/it][A
 17%|█▋        | 10/60 [00:14<01:22,  1.64s/it][A
 18%|█▊        | 11/60 [00:16<01:21,  1.67s/it][A
 20%|██        | 12/60 [00:18<01:21,  1.70s/it][A
 22%|██▏       | 13/60 [00:20<01:18,  1.67s/it][A
 23%|██▎       | 14/60 [00:22<01:22,  1.78s/it][A
 25%|██▌       | 15/60 [00:23<01:13,  1.63s/it][A
 27%|██▋       | 16/60 [00:25<01:04,  1.46s/it][A
 28%|██▊       | 17/60 [00:25<01:03,  1.48s/it][A
 30%|███       | 18/60 [00:27<00:51,  1.22s/it][A
 32%|███▏      | 19/60 [00:53<06:00,  8.79s/it][A
 33%|███▎      | 20/60 [00:53<04:14,  6.35s/it][A
 35%|███▌      | 21/60 [00:54<03:05,  4.75s/it][A
 37%|███▋      | 22/60 [00:55<02:21,  3.71s/it][A
 38%|███▊      | 23/60 [00:57<01:48,  2.94s/it][A
 40%|████      | 24/60 [00:58<01:25,  2.38s/it][A
 42%|████▏     | 25/60 [00:59<01:15,  2.16s/it][A
 43%|████▎     | 26/60 [01:01<01:05,  1.94s/it][A
 45%|████▌     | 27/60 [01:01<00:52,  1.59s/it][A
 47%|████▋     | 28/60 [01:02<00:44,  1.39s/it][A
 48%|████▊     | 29/60 [01:04<00:41,  1.34s/it][A
 50%|█████     | 30/60 [01:05<00:43,  1.43s/it][A
 52%|█████▏    | 31/60 [01:07<00:42,  1.47s/it][A
 53%|█████▎    | 32/60 [01:08<00:40,  1.46s/it][A
 55%|█████▌    | 33/60 [01:10<00:38,  1.42s/it][A
 57%|█████▋    | 34/60 [01:10<00:32,  1.24s/it][A
 58%|█████▊    | 35/60 [01:12<00:32,  1.30s/it][A
 60%|██████    | 36/60 [01:13<00:32,  1.34s/it][A
 62%|██████▏   | 37/60 [01:14<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [01:15<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [01:17<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [01:17<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [01:19<00:22,  1.20s/it][A
 70%|███████   | 42/60 [01:20<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [01:21<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [01:23<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [01:24<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [01:25<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:27<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:28<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:29<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:31<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:33<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:34<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:35<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:36<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:37<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:39<00:05,  1.32s/it][A
 95%|█████████▌| 57/60 [01:40<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:42<00:02,  1.42s/it][A
 98%|█████████▊| 59/60 [01:44<00:01,  1.47s/it][A
100%|██████████| 60/60 [01:45<00:00,  1.52s/it][A                                                    
                                               [A{'eval_loss': 0.6432034373283386, 'eval_runtime': 107.3444, 'eval_samples_per_second': 8.878, 'eval_steps_per_second': 0.559, 'eval_rewards/chosen': 0.33326974511146545, 'eval_rewards/rejected': 0.06374673545360565, 'eval_rewards/accuracies': 0.6082175970077515, 'eval_rewards/margins': 0.2691940367221832, 'eval_logps/chosen': -375.9166564941406, 'eval_logps/rejected': -151.6666717529297, 'eval_logits/chosen': -6.02734375, 'eval_logits/rejected': -6.949479103088379, 'epoch': 0.33}
 11%|█         | 504/4545 [41:42<4:15:23,  3.79s/it]
100%|██████████| 60/60 [01:45<00:00,  1.52s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 11%|█         | 505/4545 [42:01<45:16:41, 40.35s/it] 11%|█         | 506/4545 [42:04<32:44:39, 29.19s/it] 11%|█         | 507/4545 [42:08<24:14:29, 21.61s/it] 11%|█         | 508/4545 [42:12<18:17:20, 16.31s/it] 11%|█         | 509/4545 [42:15<13:53:28, 12.39s/it] 11%|█         | 510/4545 [42:19<11:02:30,  9.85s/it]                                                     {'loss': 0.6604, 'grad_norm': 43.816856384277344, 'learning_rate': 3.361955085865257e-08, 'rewards/chosen': 0.3167480528354645, 'rewards/rejected': 0.14706726372241974, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.16968384385108948, 'logps/chosen': -389.5249938964844, 'logps/rejected': -219.8000030517578, 'logits/chosen': -6.15625, 'logits/rejected': -6.65625, 'epoch': 0.34}
 11%|█         | 510/4545 [42:19<11:02:30,  9.85s/it] 11%|█         | 511/4545 [42:23<9:14:15,  8.24s/it]  11%|█▏        | 512/4545 [42:27<7:42:22,  6.88s/it] 11%|█▏        | 513/4545 [42:31<6:43:29,  6.00s/it] 11%|█▏        | 514/4545 [42:35<6:01:26,  5.38s/it] 11%|█▏        | 515/4545 [42:38<5:15:57,  4.70s/it] 11%|█▏        | 516/4545 [42:42<4:58:07,  4.44s/it] 11%|█▏        | 517/4545 [42:45<4:33:46,  4.08s/it] 11%|█▏        | 518/4545 [42:49<4:22:30,  3.91s/it] 11%|█▏        | 519/4545 [42:52<4:23:51,  3.93s/it] 11%|█▏        | 520/4545 [42:56<4:24:50,  3.95s/it]                                                    {'loss': 0.6548, 'grad_norm': 47.242584228515625, 'learning_rate': 3.428005284015852e-08, 'rewards/chosen': 0.2726638913154602, 'rewards/rejected': 0.05580444261431694, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.21714477241039276, 'logps/chosen': -297.54998779296875, 'logps/rejected': -134.9499969482422, 'logits/chosen': -6.300000190734863, 'logits/rejected': -6.584374904632568, 'epoch': 0.34}
 11%|█▏        | 520/4545 [42:57<4:24:50,  3.95s/it] 11%|█▏        | 521/4545 [43:25<12:48:02, 11.45s/it] 11%|█▏        | 522/4545 [43:30<10:25:52,  9.33s/it] 12%|█▏        | 523/4545 [43:34<8:37:24,  7.72s/it]  12%|█▏        | 524/4545 [43:38<7:20:56,  6.58s/it] 12%|█▏        | 525/4545 [43:41<6:23:16,  5.72s/it] 12%|█▏        | 526/4545 [43:46<5:51:24,  5.25s/it] 12%|█▏        | 527/4545 [43:50<5:26:57,  4.88s/it] 12%|█▏        | 528/4545 [44:44<22:06:26, 19.81s/it] 12%|█▏        | 529/4545 [44:50<17:17:21, 15.50s/it] 12%|█▏        | 530/4545 [44:54<13:28:53, 12.09s/it]                                                     {'loss': 0.6694, 'grad_norm': 65.57242584228516, 'learning_rate': 3.494055482166446e-08, 'rewards/chosen': 0.2576538026332855, 'rewards/rejected': 0.030975341796875, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.22644653916358948, 'logps/chosen': -263.54998779296875, 'logps/rejected': -128.83749389648438, 'logits/chosen': -6.303124904632568, 'logits/rejected': -6.721875190734863, 'epoch': 0.35}
 12%|█▏        | 530/4545 [44:54<13:28:53, 12.09s/it] 12%|█▏        | 531/4545 [44:58<10:45:59,  9.66s/it] 12%|█▏        | 532/4545 [45:02<8:50:59,  7.94s/it]  12%|█▏        | 533/4545 [45:05<7:14:28,  6.50s/it] 12%|█▏        | 534/4545 [45:09<6:28:10,  5.81s/it] 12%|█▏        | 535/4545 [45:13<5:50:08,  5.24s/it] 12%|█▏        | 536/4545 [45:17<5:24:06,  4.85s/it] 12%|█▏        | 537/4545 [45:20<4:44:54,  4.27s/it] 12%|█▏        | 538/4545 [45:24<4:34:02,  4.10s/it] 12%|█▏        | 539/4545 [45:27<4:30:10,  4.05s/it] 12%|█▏        | 540/4545 [45:31<4:27:38,  4.01s/it]                                                    {'loss': 0.6668, 'grad_norm': 41.59557342529297, 'learning_rate': 3.560105680317041e-08, 'rewards/chosen': 0.29039305448532104, 'rewards/rejected': 0.10592041164636612, 'rewards/accuracies': 0.612500011920929, 'rewards/margins': 0.18452148139476776, 'logps/chosen': -223.8000030517578, 'logps/rejected': -141.5749969482422, 'logits/chosen': -6.384375095367432, 'logits/rejected': -6.521874904632568, 'epoch': 0.36}
 12%|█▏        | 540/4545 [45:31<4:27:38,  4.01s/it] 12%|█▏        | 541/4545 [45:35<4:26:43,  4.00s/it] 12%|█▏        | 542/4545 [45:39<4:24:40,  3.97s/it] 12%|█▏        | 543/4545 [45:43<4:19:53,  3.90s/it] 12%|█▏        | 544/4545 [45:47<4:20:35,  3.91s/it] 12%|█▏        | 545/4545 [45:51<4:27:41,  4.02s/it] 12%|█▏        | 546/4545 [45:55<4:25:35,  3.98s/it] 12%|█▏        | 547/4545 [45:59<4:24:14,  3.97s/it] 12%|█▏        | 548/4545 [46:03<4:15:14,  3.83s/it] 12%|█▏        | 549/4545 [46:06<4:09:33,  3.75s/it] 12%|█▏        | 550/4545 [46:10<4:13:29,  3.81s/it]                                                    {'loss': 0.6279, 'grad_norm': 58.429786682128906, 'learning_rate': 3.6261558784676356e-08, 'rewards/chosen': 0.4251953065395355, 'rewards/rejected': 0.03952636569738388, 'rewards/accuracies': 0.6625000238418579, 'rewards/margins': 0.3859619200229645, 'logps/chosen': -334.54998779296875, 'logps/rejected': -184.5500030517578, 'logits/chosen': -6.159375190734863, 'logits/rejected': -6.537499904632568, 'epoch': 0.36}
 12%|█▏        | 550/4545 [46:10<4:13:29,  3.81s/it] 12%|█▏        | 551/4545 [46:14<4:17:34,  3.87s/it] 12%|█▏        | 552/4545 [46:18<4:19:02,  3.89s/it] 12%|█▏        | 553/4545 [46:22<4:20:06,  3.91s/it] 12%|█▏        | 554/4545 [46:25<4:09:39,  3.75s/it] 12%|█▏        | 555/4545 [46:29<4:13:27,  3.81s/it] 12%|█▏        | 556/4545 [46:33<4:16:55,  3.86s/it] 12%|█▏        | 557/4545 [46:36<3:51:57,  3.49s/it] 12%|█▏        | 558/4545 [46:40<4:02:22,  3.65s/it] 12%|█▏        | 559/4545 [46:43<3:51:47,  3.49s/it] 12%|█▏        | 560/4545 [46:47<3:59:52,  3.61s/it]                                                    {'loss': 0.6589, 'grad_norm': 53.115447998046875, 'learning_rate': 3.692206076618229e-08, 'rewards/chosen': 0.41313475370407104, 'rewards/rejected': 0.12559814751148224, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.28712159395217896, 'logps/chosen': -335.25, 'logps/rejected': -204.75, 'logits/chosen': -6.240624904632568, 'logits/rejected': -6.5625, 'epoch': 0.37}
 12%|█▏        | 560/4545 [46:47<3:59:52,  3.61s/it] 12%|█▏        | 561/4545 [46:51<4:05:11,  3.69s/it] 12%|█▏        | 562/4545 [46:55<4:09:54,  3.76s/it] 12%|█▏        | 563/4545 [46:58<3:56:30,  3.56s/it] 12%|█▏        | 564/4545 [47:01<3:53:51,  3.52s/it] 12%|█▏        | 565/4545 [47:05<4:03:56,  3.68s/it] 12%|█▏        | 566/4545 [47:09<4:08:47,  3.75s/it] 12%|█▏        | 567/4545 [47:13<4:09:41,  3.77s/it] 12%|█▏        | 568/4545 [47:17<4:12:54,  3.82s/it] 13%|█▎        | 569/4545 [47:21<4:12:12,  3.81s/it] 13%|█▎        | 570/4545 [47:25<4:16:56,  3.88s/it]                                                    {'loss': 0.6601, 'grad_norm': 434.5377502441406, 'learning_rate': 3.758256274768824e-08, 'rewards/chosen': 0.36762696504592896, 'rewards/rejected': 0.14979247748851776, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.21831054985523224, 'logps/chosen': -266.3999938964844, 'logps/rejected': -176.52499389648438, 'logits/chosen': -6.487500190734863, 'logits/rejected': -6.71875, 'epoch': 0.38}
 13%|█▎        | 570/4545 [47:25<4:16:56,  3.88s/it] 13%|█▎        | 571/4545 [47:29<4:18:40,  3.91s/it] 13%|█▎        | 572/4545 [47:33<4:19:17,  3.92s/it] 13%|█▎        | 573/4545 [47:37<4:25:50,  4.02s/it] 13%|█▎        | 574/4545 [47:41<4:28:01,  4.05s/it] 13%|█▎        | 575/4545 [47:45<4:25:41,  4.02s/it] 13%|█▎        | 576/4545 [47:49<4:23:10,  3.98s/it] 13%|█▎        | 577/4545 [47:53<4:22:00,  3.96s/it] 13%|█▎        | 578/4545 [47:56<4:11:05,  3.80s/it] 13%|█▎        | 579/4545 [47:59<3:53:56,  3.54s/it] 13%|█▎        | 580/4545 [48:03<4:05:40,  3.72s/it]                                                    {'loss': 0.637, 'grad_norm': 47.95269775390625, 'learning_rate': 3.824306472919419e-08, 'rewards/chosen': 0.45012205839157104, 'rewards/rejected': 0.11375732719898224, 'rewards/accuracies': 0.6187499761581421, 'rewards/margins': 0.3366943299770355, 'logps/chosen': -310.6499938964844, 'logps/rejected': -181.5500030517578, 'logits/chosen': -6.3125, 'logits/rejected': -6.662499904632568, 'epoch': 0.38}
 13%|█▎        | 580/4545 [48:03<4:05:40,  3.72s/it] 13%|█▎        | 581/4545 [48:06<3:55:24,  3.56s/it] 13%|█▎        | 582/4545 [48:10<4:03:39,  3.69s/it] 13%|█▎        | 583/4545 [48:13<3:48:37,  3.46s/it] 13%|█▎        | 584/4545 [48:17<3:58:36,  3.61s/it] 13%|█▎        | 585/4545 [48:21<3:52:09,  3.52s/it] 13%|█▎        | 586/4545 [48:25<4:00:16,  3.64s/it] 13%|█▎        | 587/4545 [48:29<4:11:35,  3.81s/it] 13%|█▎        | 588/4545 [48:33<4:14:20,  3.86s/it] 13%|█▎        | 589/4545 [48:36<3:53:33,  3.54s/it] 13%|█▎        | 590/4545 [48:39<3:53:15,  3.54s/it]                                                    {'loss': 0.6378, 'grad_norm': 45.09102249145508, 'learning_rate': 3.890356671070013e-08, 'rewards/chosen': 0.40498656034469604, 'rewards/rejected': 0.11224975436925888, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2934066653251648, 'logps/chosen': -323.54998779296875, 'logps/rejected': -199.25, 'logits/chosen': -6.240624904632568, 'logits/rejected': -6.643750190734863, 'epoch': 0.39}
 13%|█▎        | 590/4545 [48:39<3:53:15,  3.54s/it] 13%|█▎        | 591/4545 [48:43<4:03:33,  3.70s/it] 13%|█▎        | 592/4545 [48:47<3:57:14,  3.60s/it] 13%|█▎        | 593/4545 [48:50<3:54:36,  3.56s/it] 13%|█▎        | 594/4545 [48:54<4:02:29,  3.68s/it] 13%|█▎        | 595/4545 [48:58<4:05:05,  3.72s/it] 13%|█▎        | 596/4545 [49:02<4:09:18,  3.79s/it] 13%|█▎        | 597/4545 [49:06<4:18:43,  3.93s/it] 13%|█▎        | 598/4545 [49:09<4:02:46,  3.69s/it] 13%|█▎        | 599/4545 [49:13<4:14:00,  3.86s/it] 13%|█▎        | 600/4545 [49:17<3:59:46,  3.65s/it]                                                    {'loss': 0.635, 'grad_norm': 47.4371452331543, 'learning_rate': 3.9564068692206076e-08, 'rewards/chosen': 0.4789062440395355, 'rewards/rejected': 0.180084228515625, 'rewards/accuracies': 0.6625000238418579, 'rewards/margins': 0.2982238829135895, 'logps/chosen': -304.1499938964844, 'logps/rejected': -188.60000610351562, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.678124904632568, 'epoch': 0.4}
 13%|█▎        | 600/4545 [49:17<3:59:46,  3.65s/it] 13%|█▎        | 601/4545 [49:20<3:57:41,  3.62s/it] 13%|█▎        | 602/4545 [49:24<3:53:57,  3.56s/it] 13%|█▎        | 603/4545 [49:27<4:01:17,  3.67s/it] 13%|█▎        | 604/4545 [49:31<3:55:25,  3.58s/it] 13%|█▎        | 605/4545 [49:35<4:08:24,  3.78s/it] 13%|█▎        | 606/4545 [49:38<3:59:32,  3.65s/it] 13%|█▎        | 607/4545 [49:42<4:08:20,  3.78s/it] 13%|█▎        | 608/4545 [49:47<4:13:02,  3.86s/it] 13%|█▎        | 609/4545 [49:50<4:14:09,  3.87s/it] 13%|█▎        | 610/4545 [49:54<4:16:03,  3.90s/it]                                                    {'loss': 0.6295, 'grad_norm': 50.61137771606445, 'learning_rate': 4.022457067371202e-08, 'rewards/chosen': 0.662353515625, 'rewards/rejected': 0.076568603515625, 'rewards/accuracies': 0.625, 'rewards/margins': 0.586621105670929, 'logps/chosen': -380.29998779296875, 'logps/rejected': -186.52499389648438, 'logits/chosen': -6.096875190734863, 'logits/rejected': -6.484375, 'epoch': 0.4}
 13%|█▎        | 610/4545 [49:54<4:16:03,  3.90s/it] 13%|█▎        | 611/4545 [49:59<4:21:46,  3.99s/it] 13%|█▎        | 612/4545 [50:02<4:00:48,  3.67s/it] 13%|█▎        | 613/4545 [50:05<4:05:50,  3.75s/it] 14%|█▎        | 614/4545 [50:09<4:09:14,  3.80s/it] 14%|█▎        | 615/4545 [50:12<3:51:14,  3.53s/it] 14%|█▎        | 616/4545 [50:16<3:51:47,  3.54s/it] 14%|█▎        | 617/4545 [50:20<3:57:36,  3.63s/it] 14%|█▎        | 618/4545 [50:23<3:44:24,  3.43s/it] 14%|█▎        | 619/4545 [50:27<3:55:02,  3.59s/it] 14%|█▎        | 620/4545 [50:29<3:36:31,  3.31s/it]                                                    {'loss': 0.6421, 'grad_norm': 48.324867248535156, 'learning_rate': 4.0885072655217964e-08, 'rewards/chosen': 0.4062866270542145, 'rewards/rejected': 0.03664550930261612, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.36921387910842896, 'logps/chosen': -224.85000610351562, 'logps/rejected': -114.625, 'logits/chosen': -6.471875190734863, 'logits/rejected': -6.546875, 'epoch': 0.41}
 14%|█▎        | 620/4545 [50:29<3:36:31,  3.31s/it] 14%|█▎        | 621/4545 [50:33<3:49:21,  3.51s/it] 14%|█▎        | 622/4545 [50:37<3:57:46,  3.64s/it] 14%|█▎        | 623/4545 [50:41<3:58:37,  3.65s/it] 14%|█▎        | 624/4545 [50:45<4:02:46,  3.71s/it] 14%|█▍        | 625/4545 [50:49<4:07:47,  3.79s/it] 14%|█▍        | 626/4545 [50:53<4:12:18,  3.86s/it] 14%|█▍        | 627/4545 [50:56<4:05:46,  3.76s/it] 14%|█▍        | 628/4545 [51:00<4:07:10,  3.79s/it] 14%|█▍        | 629/4545 [51:04<4:10:12,  3.83s/it] 14%|█▍        | 630/4545 [51:08<4:11:52,  3.86s/it]                                                    {'loss': 0.6369, 'grad_norm': 56.985931396484375, 'learning_rate': 4.154557463672391e-08, 'rewards/chosen': 0.4250732362270355, 'rewards/rejected': 0.1385200470685959, 'rewards/accuracies': 0.668749988079071, 'rewards/margins': 0.28767091035842896, 'logps/chosen': -282.20001220703125, 'logps/rejected': -151.60000610351562, 'logits/chosen': -6.184374809265137, 'logits/rejected': -6.568749904632568, 'epoch': 0.42}
 14%|█▍        | 630/4545 [51:08<4:11:52,  3.86s/it] 14%|█▍        | 631/4545 [51:12<4:21:26,  4.01s/it] 14%|█▍        | 632/4545 [51:16<4:19:53,  3.99s/it] 14%|█▍        | 633/4545 [51:20<4:13:36,  3.89s/it] 14%|█▍        | 634/4545 [51:24<4:19:52,  3.99s/it] 14%|█▍        | 635/4545 [51:28<4:22:53,  4.03s/it] 14%|█▍        | 636/4545 [51:32<4:25:42,  4.08s/it] 14%|█▍        | 637/4545 [51:37<4:26:14,  4.09s/it] 14%|█▍        | 638/4545 [51:41<4:23:06,  4.04s/it] 14%|█▍        | 639/4545 [52:10<12:44:23, 11.74s/it] 14%|█▍        | 640/4545 [52:14<10:07:08,  9.33s/it]                                                     {'loss': 0.6388, 'grad_norm': 45.740447998046875, 'learning_rate': 4.220607661822985e-08, 'rewards/chosen': 0.2641357481479645, 'rewards/rejected': 0.04121093824505806, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.22314453125, 'logps/chosen': -199.6999969482422, 'logps/rejected': -134.52499389648438, 'logits/chosen': -6.390625, 'logits/rejected': -6.765625, 'epoch': 0.42}
 14%|█▍        | 640/4545 [52:14<10:07:08,  9.33s/it] 14%|█▍        | 641/4545 [52:18<8:27:39,  7.80s/it]  14%|█▍        | 642/4545 [52:48<15:30:01, 14.30s/it] 14%|█▍        | 643/4545 [52:52<12:07:21, 11.18s/it] 14%|█▍        | 644/4545 [52:55<9:45:11,  9.00s/it]  14%|█▍        | 645/4545 [52:59<8:06:32,  7.49s/it] 14%|█▍        | 646/4545 [53:03<6:57:29,  6.42s/it] 14%|█▍        | 647/4545 [53:06<5:53:04,  5.43s/it] 14%|█▍        | 648/4545 [53:10<5:23:34,  4.98s/it] 14%|█▍        | 649/4545 [53:14<5:04:04,  4.68s/it] 14%|█▍        | 650/4545 [53:18<4:49:41,  4.46s/it]                                                    {'loss': 0.5988, 'grad_norm': 36.89931869506836, 'learning_rate': 4.2866578599735796e-08, 'rewards/chosen': 0.781787097454071, 'rewards/rejected': 0.14829102158546448, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.632702648639679, 'logps/chosen': -437.79998779296875, 'logps/rejected': -230.02499389648438, 'logits/chosen': -6.121874809265137, 'logits/rejected': -6.493750095367432, 'epoch': 0.43}
 14%|█▍        | 650/4545 [53:18<4:49:41,  4.46s/it] 14%|█▍        | 651/4545 [53:22<4:40:24,  4.32s/it] 14%|█▍        | 652/4545 [53:26<4:27:47,  4.13s/it] 14%|█▍        | 653/4545 [53:30<4:26:12,  4.10s/it] 14%|█▍        | 654/4545 [53:34<4:22:37,  4.05s/it] 14%|█▍        | 655/4545 [53:37<4:10:36,  3.87s/it] 14%|█▍        | 656/4545 [53:41<4:07:00,  3.81s/it] 14%|█▍        | 657/4545 [53:45<4:17:33,  3.97s/it] 14%|█▍        | 658/4545 [53:48<3:50:28,  3.56s/it] 14%|█▍        | 659/4545 [53:52<3:57:41,  3.67s/it] 15%|█▍        | 660/4545 [53:56<4:04:03,  3.77s/it]                                                    {'loss': 0.6254, 'grad_norm': 36.64808654785156, 'learning_rate': 4.352708058124174e-08, 'rewards/chosen': 0.6717284917831421, 'rewards/rejected': 0.100341796875, 'rewards/accuracies': 0.6937500238418579, 'rewards/margins': 0.5712646245956421, 'logps/chosen': -313.0, 'logps/rejected': -143.4499969482422, 'logits/chosen': -6.303124904632568, 'logits/rejected': -6.559374809265137, 'epoch': 0.44}
 15%|█▍        | 660/4545 [53:56<4:04:03,  3.77s/it] 15%|█▍        | 661/4545 [54:00<4:12:09,  3.90s/it] 15%|█▍        | 662/4545 [54:04<4:17:57,  3.99s/it] 15%|█▍        | 663/4545 [54:08<4:11:31,  3.89s/it] 15%|█▍        | 664/4545 [54:12<4:04:38,  3.78s/it] 15%|█▍        | 665/4545 [54:15<3:59:24,  3.70s/it] 15%|█▍        | 666/4545 [54:19<4:02:59,  3.76s/it] 15%|█▍        | 667/4545 [54:23<4:06:13,  3.81s/it] 15%|█▍        | 668/4545 [54:26<4:00:16,  3.72s/it] 15%|█▍        | 669/4545 [54:30<4:04:17,  3.78s/it] 15%|█▍        | 670/4545 [54:34<4:08:31,  3.85s/it]                                                    {'loss': 0.6527, 'grad_norm': 48.67012405395508, 'learning_rate': 4.418758256274769e-08, 'rewards/chosen': 0.18964843451976776, 'rewards/rejected': 0.05979614332318306, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.12974853813648224, 'logps/chosen': -150.5, 'logps/rejected': -94.7750015258789, 'logits/chosen': -6.478125095367432, 'logits/rejected': -6.662499904632568, 'epoch': 0.44}
 15%|█▍        | 670/4545 [54:34<4:08:31,  3.85s/it] 15%|█▍        | 671/4545 [54:38<4:10:52,  3.89s/it] 15%|█▍        | 672/4545 [54:42<4:15:43,  3.96s/it] 15%|█▍        | 673/4545 [54:46<4:04:17,  3.79s/it] 15%|█▍        | 674/4545 [54:50<4:06:57,  3.83s/it] 15%|█▍        | 675/4545 [54:54<4:08:02,  3.85s/it] 15%|█▍        | 676/4545 [54:57<4:08:56,  3.86s/it] 15%|█▍        | 677/4545 [55:00<3:44:39,  3.48s/it] 15%|█▍        | 678/4545 [55:04<3:53:06,  3.62s/it] 15%|█▍        | 679/4545 [55:08<4:03:00,  3.77s/it] 15%|█▍        | 680/4545 [55:12<4:05:49,  3.82s/it]                                                    {'loss': 0.6209, 'grad_norm': 40.41345977783203, 'learning_rate': 4.484808454425363e-08, 'rewards/chosen': 0.7431640625, 'rewards/rejected': 0.07564010471105576, 'rewards/accuracies': 0.6625000238418579, 'rewards/margins': 0.6675781011581421, 'logps/chosen': -369.8999938964844, 'logps/rejected': -163.60000610351562, 'logits/chosen': -6.324999809265137, 'logits/rejected': -6.571875095367432, 'epoch': 0.45}
 15%|█▍        | 680/4545 [55:12<4:05:49,  3.82s/it] 15%|█▍        | 681/4545 [55:16<4:15:33,  3.97s/it] 15%|█▌        | 682/4545 [55:20<4:12:37,  3.92s/it] 15%|█▌        | 683/4545 [55:24<4:14:18,  3.95s/it] 15%|█▌        | 684/4545 [55:28<4:19:02,  4.03s/it] 15%|█▌        | 685/4545 [55:32<4:17:30,  4.00s/it] 15%|█▌        | 686/4545 [55:36<4:15:58,  3.98s/it] 15%|█▌        | 687/4545 [55:40<4:10:52,  3.90s/it] 15%|█▌        | 688/4545 [55:44<4:11:40,  3.92s/it] 15%|█▌        | 689/4545 [55:48<4:05:03,  3.81s/it] 15%|█▌        | 690/4545 [55:51<4:07:19,  3.85s/it]                                                    {'loss': 0.6196, 'grad_norm': 40.46296310424805, 'learning_rate': 4.550858652575957e-08, 'rewards/chosen': 0.700927734375, 'rewards/rejected': 0.16979369521141052, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.530957043170929, 'logps/chosen': -334.6499938964844, 'logps/rejected': -149.27499389648438, 'logits/chosen': -6.278124809265137, 'logits/rejected': -6.696875095367432, 'epoch': 0.46}
 15%|█▌        | 690/4545 [55:52<4:07:19,  3.85s/it] 15%|█▌        | 691/4545 [55:56<4:13:24,  3.95s/it] 15%|█▌        | 692/4545 [55:58<3:45:42,  3.51s/it] 15%|█▌        | 693/4545 [56:02<3:56:24,  3.68s/it] 15%|█▌        | 694/4545 [56:06<3:52:09,  3.62s/it] 15%|█▌        | 695/4545 [56:10<4:03:45,  3.80s/it] 15%|█▌        | 696/4545 [56:14<4:06:26,  3.84s/it] 15%|█▌        | 697/4545 [56:18<4:02:39,  3.78s/it] 15%|█▌        | 698/4545 [56:21<4:05:47,  3.83s/it] 15%|█▌        | 699/4545 [56:25<4:07:41,  3.86s/it] 15%|█▌        | 700/4545 [56:29<4:06:55,  3.85s/it]                                                    {'loss': 0.6108, 'grad_norm': 48.14736557006836, 'learning_rate': 4.6169088507265516e-08, 'rewards/chosen': 0.5877929925918579, 'rewards/rejected': 0.15845337510108948, 'rewards/accuracies': 0.706250011920929, 'rewards/margins': 0.42919921875, 'logps/chosen': -269.1499938964844, 'logps/rejected': -155.77499389648438, 'logits/chosen': -6.346875190734863, 'logits/rejected': -6.503125190734863, 'epoch': 0.46}
 15%|█▌        | 700/4545 [56:30<4:06:55,  3.85s/it] 15%|█▌        | 701/4545 [56:33<4:09:05,  3.89s/it] 15%|█▌        | 702/4545 [56:37<4:10:11,  3.91s/it] 15%|█▌        | 703/4545 [56:41<4:15:47,  3.99s/it] 15%|█▌        | 704/4545 [56:44<3:56:48,  3.70s/it] 16%|█▌        | 705/4545 [56:48<3:58:27,  3.73s/it] 16%|█▌        | 706/4545 [56:52<4:03:24,  3.80s/it] 16%|█▌        | 707/4545 [56:57<4:19:39,  4.06s/it] 16%|█▌        | 708/4545 [57:01<4:29:06,  4.21s/it] 16%|█▌        | 709/4545 [57:05<4:24:30,  4.14s/it] 16%|█▌        | 710/4545 [57:09<4:20:28,  4.08s/it]                                                    {'loss': 0.6233, 'grad_norm': 63.52643966674805, 'learning_rate': 4.6829590488771467e-08, 'rewards/chosen': 0.44023436307907104, 'rewards/rejected': 0.04915161058306694, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.3907226622104645, 'logps/chosen': -234.85000610351562, 'logps/rejected': -99.42500305175781, 'logits/chosen': -6.296875, 'logits/rejected': -6.753125190734863, 'epoch': 0.47}
 16%|█▌        | 710/4545 [57:09<4:20:28,  4.08s/it] 16%|█▌        | 711/4545 [57:12<3:52:16,  3.63s/it] 16%|█▌        | 712/4545 [57:16<3:58:51,  3.74s/it] 16%|█▌        | 713/4545 [57:20<4:01:41,  3.78s/it] 16%|█▌        | 714/4545 [57:24<4:05:18,  3.84s/it] 16%|█▌        | 715/4545 [57:28<4:05:10,  3.84s/it] 16%|█▌        | 716/4545 [57:31<3:56:19,  3.70s/it] 16%|█▌        | 717/4545 [57:35<4:00:39,  3.77s/it] 16%|█▌        | 718/4545 [57:39<4:08:42,  3.90s/it] 16%|█▌        | 719/4545 [57:42<3:49:44,  3.60s/it] 16%|█▌        | 720/4545 [57:46<4:01:49,  3.79s/it]                                                    {'loss': 0.6326, 'grad_norm': 52.138893127441406, 'learning_rate': 4.749009247027741e-08, 'rewards/chosen': 0.5366455316543579, 'rewards/rejected': 0.15645751357078552, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.3801116943359375, 'logps/chosen': -291.70001220703125, 'logps/rejected': -209.1999969482422, 'logits/chosen': -6.168749809265137, 'logits/rejected': -6.618750095367432, 'epoch': 0.48}
 16%|█▌        | 720/4545 [57:46<4:01:49,  3.79s/it] 16%|█▌        | 721/4545 [57:50<4:05:30,  3.85s/it] 16%|█▌        | 722/4545 [57:54<3:59:14,  3.75s/it] 16%|█▌        | 723/4545 [57:58<4:03:40,  3.83s/it] 16%|█▌        | 724/4545 [58:02<4:05:39,  3.86s/it] 16%|█▌        | 725/4545 [58:06<4:07:01,  3.88s/it] 16%|█▌        | 726/4545 [58:10<4:08:24,  3.90s/it] 16%|█▌        | 727/4545 [58:12<3:43:51,  3.52s/it] 16%|█▌        | 728/4545 [58:14<3:13:32,  3.04s/it] 16%|█▌        | 729/4545 [58:17<3:09:11,  2.97s/it] 16%|█▌        | 730/4545 [58:21<3:27:47,  3.27s/it]                                                    {'loss': 0.6102, 'grad_norm': 193.5460968017578, 'learning_rate': 4.8150594451783355e-08, 'rewards/chosen': 0.673828125, 'rewards/rejected': 0.10810546576976776, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.565600574016571, 'logps/chosen': -302.625, 'logps/rejected': -147.60000610351562, 'logits/chosen': -6.340624809265137, 'logits/rejected': -6.462500095367432, 'epoch': 0.48}
 16%|█▌        | 730/4545 [58:21<3:27:47,  3.27s/it] 16%|█▌        | 731/4545 [58:23<3:15:10,  3.07s/it] 16%|█▌        | 732/4545 [58:27<3:31:34,  3.33s/it] 16%|█▌        | 733/4545 [58:31<3:43:20,  3.52s/it] 16%|█▌        | 734/4545 [58:35<3:51:32,  3.65s/it] 16%|█▌        | 735/4545 [58:40<4:02:57,  3.83s/it] 16%|█▌        | 736/4545 [58:44<4:06:10,  3.88s/it] 16%|█▌        | 737/4545 [58:47<4:07:15,  3.90s/it] 16%|█▌        | 738/4545 [58:52<4:11:29,  3.96s/it] 16%|█▋        | 739/4545 [58:55<3:59:07,  3.77s/it] 16%|█▋        | 740/4545 [58:59<4:08:26,  3.92s/it]                                                    {'loss': 0.6115, 'grad_norm': 37.5694465637207, 'learning_rate': 4.881109643328929e-08, 'rewards/chosen': 0.6781250238418579, 'rewards/rejected': 0.22027587890625, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.45635986328125, 'logps/chosen': -332.20001220703125, 'logps/rejected': -196.4875030517578, 'logits/chosen': -6.128125190734863, 'logits/rejected': -6.434374809265137, 'epoch': 0.49}
 16%|█▋        | 740/4545 [58:59<4:08:26,  3.92s/it] 16%|█▋        | 741/4545 [59:03<4:09:47,  3.94s/it] 16%|█▋        | 742/4545 [59:07<4:00:25,  3.79s/it] 16%|█▋        | 743/4545 [59:10<3:55:50,  3.72s/it] 16%|█▋        | 744/4545 [59:14<3:59:51,  3.79s/it] 16%|█▋        | 745/4545 [59:18<3:53:52,  3.69s/it] 16%|█▋        | 746/4545 [59:22<4:04:20,  3.86s/it] 16%|█▋        | 747/4545 [59:26<4:05:54,  3.88s/it] 16%|█▋        | 748/4545 [59:29<3:52:52,  3.68s/it] 16%|█▋        | 749/4545 [59:33<3:58:33,  3.77s/it] 17%|█▋        | 750/4545 [1:00:02<11:53:09, 11.28s/it]                                                       {'loss': 0.6286, 'grad_norm': 48.65765380859375, 'learning_rate': 4.947159841479524e-08, 'rewards/chosen': 0.38037109375, 'rewards/rejected': 0.044684600085020065, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.3357910215854645, 'logps/chosen': -214.6999969482422, 'logps/rejected': -109.0999984741211, 'logits/chosen': -6.371874809265137, 'logits/rejected': -6.643750190734863, 'epoch': 0.5}
 17%|█▋        | 750/4545 [1:00:02<11:53:09, 11.28s/it] 17%|█▋        | 751/4545 [1:00:06<9:35:10,  9.10s/it]  17%|█▋        | 752/4545 [1:00:10<7:55:40,  7.52s/it] 17%|█▋        | 753/4545 [1:00:14<6:53:18,  6.54s/it] 17%|█▋        | 754/4545 [1:00:17<5:53:45,  5.60s/it] 17%|█▋        | 755/4545 [1:00:21<5:22:12,  5.10s/it] 17%|█▋        | 756/4545 [1:00:26<5:06:55,  4.86s/it] 17%|█▋        | 757/4545 [1:00:29<4:49:28,  4.59s/it] 17%|█▋        | 758/4545 [1:00:33<4:37:45,  4.40s/it] 17%|█▋        | 759/4545 [1:00:37<4:26:03,  4.22s/it] 17%|█▋        | 760/4545 [1:00:41<4:15:36,  4.05s/it]                                                      {'loss': 0.5771, 'grad_norm': 35.06178283691406, 'learning_rate': 5.013210039630119e-08, 'rewards/chosen': 1.1055176258087158, 'rewards/rejected': 0.1997528076171875, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.9043945074081421, 'logps/chosen': -432.45001220703125, 'logps/rejected': -223.10000610351562, 'logits/chosen': -6.081250190734863, 'logits/rejected': -6.609375, 'epoch': 0.5}
 17%|█▋        | 760/4545 [1:00:41<4:15:36,  4.05s/it] 17%|█▋        | 761/4545 [1:00:45<4:15:44,  4.06s/it] 17%|█▋        | 762/4545 [1:00:49<4:13:32,  4.02s/it] 17%|█▋        | 763/4545 [1:00:52<4:00:13,  3.81s/it] 17%|█▋        | 764/4545 [1:00:56<4:00:38,  3.82s/it] 17%|█▋        | 765/4545 [1:00:59<3:42:04,  3.53s/it] 17%|█▋        | 766/4545 [1:01:03<3:51:14,  3.67s/it] 17%|█▋        | 767/4545 [1:01:07<3:56:05,  3.75s/it] 17%|█▋        | 768/4545 [1:01:11<4:03:39,  3.87s/it] 17%|█▋        | 769/4545 [1:01:14<3:49:55,  3.65s/it] 17%|█▋        | 770/4545 [1:01:17<3:39:28,  3.49s/it]                                                      {'loss': 0.627, 'grad_norm': 47.33943176269531, 'learning_rate': 5.079260237780714e-08, 'rewards/chosen': 0.5452636480331421, 'rewards/rejected': 0.14934082329273224, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.3957763612270355, 'logps/chosen': -248.60000610351562, 'logps/rejected': -151.625, 'logits/chosen': -6.421875, 'logits/rejected': -6.640625, 'epoch': 0.51}
 17%|█▋        | 770/4545 [1:01:17<3:39:28,  3.49s/it] 17%|█▋        | 771/4545 [1:01:20<3:20:52,  3.19s/it] 17%|█▋        | 772/4545 [1:01:24<3:43:51,  3.56s/it] 17%|█▋        | 773/4545 [1:01:27<3:22:48,  3.23s/it] 17%|█▋        | 774/4545 [1:01:30<3:30:28,  3.35s/it] 17%|█▋        | 775/4545 [1:01:34<3:46:55,  3.61s/it] 17%|█▋        | 776/4545 [1:01:38<3:52:34,  3.70s/it] 17%|█▋        | 777/4545 [1:01:42<3:44:40,  3.58s/it] 17%|█▋        | 778/4545 [1:01:45<3:43:52,  3.57s/it] 17%|█▋        | 779/4545 [1:01:49<3:56:51,  3.77s/it] 17%|█▋        | 780/4545 [1:01:53<3:59:51,  3.82s/it]                                                      {'loss': 0.5889, 'grad_norm': 41.039180755615234, 'learning_rate': 5.145310435931307e-08, 'rewards/chosen': 0.645703136920929, 'rewards/rejected': 0.05502929538488388, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.591357409954071, 'logps/chosen': -263.79998779296875, 'logps/rejected': -151.52499389648438, 'logits/chosen': -6.224999904632568, 'logits/rejected': -6.528124809265137, 'epoch': 0.51}
 17%|█▋        | 780/4545 [1:01:54<3:59:51,  3.82s/it] 17%|█▋        | 781/4545 [1:01:56<3:43:35,  3.56s/it] 17%|█▋        | 782/4545 [1:02:00<3:52:57,  3.71s/it] 17%|█▋        | 783/4545 [1:02:05<4:02:59,  3.88s/it] 17%|█▋        | 784/4545 [1:02:08<3:56:04,  3.77s/it] 17%|█▋        | 785/4545 [1:02:12<3:59:14,  3.82s/it] 17%|█▋        | 786/4545 [1:02:16<4:00:37,  3.84s/it] 17%|█▋        | 787/4545 [1:02:20<4:02:20,  3.87s/it] 17%|█▋        | 788/4545 [1:02:24<4:04:01,  3.90s/it] 17%|█▋        | 789/4545 [1:02:27<3:51:38,  3.70s/it] 17%|█▋        | 790/4545 [1:02:30<3:33:19,  3.41s/it]                                                      {'loss': 0.6024, 'grad_norm': 42.58362579345703, 'learning_rate': 5.211360634081902e-08, 'rewards/chosen': 0.613330066204071, 'rewards/rejected': 0.09561767429113388, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.5187743902206421, 'logps/chosen': -241.10000610351562, 'logps/rejected': -102.7249984741211, 'logits/chosen': -6.240624904632568, 'logits/rejected': -6.746874809265137, 'epoch': 0.52}
 17%|█▋        | 790/4545 [1:02:30<3:33:19,  3.41s/it] 17%|█▋        | 791/4545 [1:02:33<3:29:01,  3.34s/it] 17%|█▋        | 792/4545 [1:02:37<3:44:12,  3.58s/it] 17%|█▋        | 793/4545 [1:02:41<3:54:33,  3.75s/it] 17%|█▋        | 794/4545 [1:02:46<4:04:01,  3.90s/it] 17%|█▋        | 795/4545 [1:02:50<4:07:51,  3.97s/it] 18%|█▊        | 796/4545 [1:02:54<4:05:58,  3.94s/it] 18%|█▊        | 797/4545 [1:02:58<4:06:06,  3.94s/it] 18%|█▊        | 798/4545 [1:03:01<4:05:50,  3.94s/it] 18%|█▊        | 799/4545 [1:03:05<4:04:50,  3.92s/it] 18%|█▊        | 800/4545 [1:03:09<4:05:08,  3.93s/it]                                                      {'loss': 0.5763, 'grad_norm': 33.20289611816406, 'learning_rate': 5.277410832232496e-08, 'rewards/chosen': 0.757617175579071, 'rewards/rejected': 0.091278076171875, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.666748046875, 'logps/chosen': -318.54998779296875, 'logps/rejected': -148.875, 'logits/chosen': -6.284375190734863, 'logits/rejected': -6.556250095367432, 'epoch': 0.53}
 18%|█▊        | 800/4545 [1:03:09<4:05:08,  3.93s/it] 18%|█▊        | 801/4545 [1:03:13<4:05:00,  3.93s/it] 18%|█▊        | 802/4545 [1:03:17<4:00:22,  3.85s/it] 18%|█▊        | 803/4545 [1:03:21<3:55:55,  3.78s/it] 18%|█▊        | 804/4545 [1:03:25<4:03:57,  3.91s/it] 18%|█▊        | 805/4545 [1:03:29<4:04:08,  3.92s/it] 18%|█▊        | 806/4545 [1:03:32<3:56:47,  3.80s/it] 18%|█▊        | 807/4545 [1:03:36<3:59:05,  3.84s/it] 18%|█▊        | 808/4545 [1:03:40<4:00:46,  3.87s/it] 18%|█▊        | 809/4545 [1:03:43<3:51:55,  3.72s/it] 18%|█▊        | 810/4545 [1:03:47<3:55:34,  3.78s/it]                                                      {'loss': 0.6555, 'grad_norm': 32.797393798828125, 'learning_rate': 5.3434610303830907e-08, 'rewards/chosen': 0.5289062261581421, 'rewards/rejected': 0.22324219346046448, 'rewards/accuracies': 0.75, 'rewards/margins': 0.30620115995407104, 'logps/chosen': -225.375, 'logps/rejected': -152.3000030517578, 'logits/chosen': -6.275000095367432, 'logits/rejected': -6.384375095367432, 'epoch': 0.53}
 18%|█▊        | 810/4545 [1:03:47<3:55:34,  3.78s/it] 18%|█▊        | 811/4545 [1:03:51<3:58:46,  3.84s/it] 18%|█▊        | 812/4545 [1:03:55<4:00:24,  3.86s/it] 18%|█▊        | 813/4545 [1:03:59<4:01:33,  3.88s/it] 18%|█▊        | 814/4545 [1:04:03<3:52:05,  3.73s/it] 18%|█▊        | 815/4545 [1:04:07<3:56:06,  3.80s/it] 18%|█▊        | 816/4545 [1:04:10<3:58:36,  3.84s/it] 18%|█▊        | 817/4545 [1:04:13<3:31:39,  3.41s/it] 18%|█▊        | 818/4545 [1:04:17<3:42:56,  3.59s/it] 18%|█▊        | 819/4545 [1:04:21<3:53:08,  3.75s/it] 18%|█▊        | 820/4545 [1:04:25<3:58:25,  3.84s/it]                                                      {'loss': 0.559, 'grad_norm': 49.198692321777344, 'learning_rate': 5.409511228533685e-08, 'rewards/chosen': 1.1041991710662842, 'rewards/rejected': 0.12749938666820526, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.9771484136581421, 'logps/chosen': -419.1000061035156, 'logps/rejected': -197.375, 'logits/chosen': -6.009375095367432, 'logits/rejected': -6.456250190734863, 'epoch': 0.54}
 18%|█▊        | 820/4545 [1:04:25<3:58:25,  3.84s/it] 18%|█▊        | 821/4545 [1:04:29<4:06:57,  3.98s/it] 18%|█▊        | 822/4545 [1:04:34<4:11:10,  4.05s/it] 18%|█▊        | 823/4545 [1:04:38<4:11:23,  4.05s/it] 18%|█▊        | 824/4545 [1:04:41<3:53:56,  3.77s/it] 18%|█▊        | 825/4545 [1:04:45<3:56:43,  3.82s/it] 18%|█▊        | 826/4545 [1:04:48<3:45:48,  3.64s/it] 18%|█▊        | 827/4545 [1:04:52<3:53:53,  3.77s/it] 18%|█▊        | 828/4545 [1:04:56<3:56:37,  3.82s/it] 18%|█▊        | 829/4545 [1:05:00<4:04:28,  3.95s/it] 18%|█▊        | 830/4545 [1:05:04<3:54:56,  3.79s/it]                                                      {'loss': 0.5851, 'grad_norm': 32.78101348876953, 'learning_rate': 5.4755614266842795e-08, 'rewards/chosen': 0.7705078125, 'rewards/rejected': 0.109771728515625, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.6605468988418579, 'logps/chosen': -304.1000061035156, 'logps/rejected': -159.0500030517578, 'logits/chosen': -6.184374809265137, 'logits/rejected': -6.612500190734863, 'epoch': 0.55}
 18%|█▊        | 830/4545 [1:05:04<3:54:56,  3.79s/it] 18%|█▊        | 831/4545 [1:05:08<4:02:17,  3.91s/it] 18%|█▊        | 832/4545 [1:05:11<3:54:04,  3.78s/it] 18%|█▊        | 833/4545 [1:05:15<3:56:27,  3.82s/it] 18%|█▊        | 834/4545 [1:05:19<4:03:23,  3.94s/it] 18%|█▊        | 835/4545 [1:05:23<3:59:04,  3.87s/it] 18%|█▊        | 836/4545 [1:05:26<3:33:33,  3.45s/it] 18%|█▊        | 837/4545 [1:05:29<3:28:06,  3.37s/it] 18%|█▊        | 838/4545 [1:05:33<3:38:29,  3.54s/it] 18%|█▊        | 839/4545 [1:05:36<3:32:48,  3.45s/it] 18%|█▊        | 840/4545 [1:05:39<3:34:08,  3.47s/it]                                                      {'loss': 0.6199, 'grad_norm': 50.60978698730469, 'learning_rate': 5.5416116248348745e-08, 'rewards/chosen': 0.68994140625, 'rewards/rejected': 0.12504883110523224, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.563427746295929, 'logps/chosen': -256.95001220703125, 'logps/rejected': -135.64999389648438, 'logits/chosen': -6.296875, 'logits/rejected': -6.578125, 'epoch': 0.55}
 18%|█▊        | 840/4545 [1:05:39<3:34:08,  3.47s/it] 19%|█▊        | 841/4545 [1:05:43<3:43:07,  3.61s/it] 19%|█▊        | 842/4545 [1:05:45<3:13:49,  3.14s/it] 19%|█▊        | 843/4545 [1:05:49<3:30:56,  3.42s/it] 19%|█▊        | 844/4545 [1:05:53<3:31:43,  3.43s/it] 19%|█▊        | 845/4545 [1:05:57<3:40:23,  3.57s/it] 19%|█▊        | 846/4545 [1:06:01<3:49:15,  3.72s/it] 19%|█▊        | 847/4545 [1:06:04<3:40:56,  3.58s/it] 19%|█▊        | 848/4545 [1:06:08<3:50:57,  3.75s/it] 19%|█▊        | 849/4545 [1:06:12<3:56:44,  3.84s/it] 19%|█▊        | 850/4545 [1:06:16<3:51:10,  3.75s/it]                                                      {'loss': 0.6039, 'grad_norm': 66.4443130493164, 'learning_rate': 5.607661822985469e-08, 'rewards/chosen': 0.6200195550918579, 'rewards/rejected': 0.12116698920726776, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.49921876192092896, 'logps/chosen': -255.3000030517578, 'logps/rejected': -134.39999389648438, 'logits/chosen': -6.324999809265137, 'logits/rejected': -6.428124904632568, 'epoch': 0.56}
 19%|█▊        | 850/4545 [1:06:16<3:51:10,  3.75s/it] 19%|█▊        | 851/4545 [1:06:19<3:43:54,  3.64s/it] 19%|█▊        | 852/4545 [1:06:48<11:34:43, 11.29s/it] 19%|█▉        | 853/4545 [1:06:52<9:12:23,  8.98s/it]  19%|█▉        | 854/4545 [1:06:55<7:24:50,  7.23s/it] 19%|█▉        | 855/4545 [1:06:59<6:23:36,  6.24s/it] 19%|█▉        | 856/4545 [1:07:02<5:31:04,  5.38s/it] 19%|█▉        | 857/4545 [1:07:06<5:04:21,  4.95s/it] 19%|█▉        | 858/4545 [1:07:10<4:46:55,  4.67s/it] 19%|█▉        | 859/4545 [1:07:14<4:22:11,  4.27s/it] 19%|█▉        | 860/4545 [1:07:17<4:08:54,  4.05s/it]                                                      {'loss': 0.6042, 'grad_norm': 39.32364273071289, 'learning_rate': 5.673712021136063e-08, 'rewards/chosen': 0.692089855670929, 'rewards/rejected': 0.05493774265050888, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.638446033000946, 'logps/chosen': -233.35000610351562, 'logps/rejected': -109.0250015258789, 'logits/chosen': -6.368750095367432, 'logits/rejected': -6.484375, 'epoch': 0.57}
 19%|█▉        | 860/4545 [1:07:17<4:08:54,  4.05s/it] 19%|█▉        | 861/4545 [1:07:21<4:06:46,  4.02s/it] 19%|█▉        | 862/4545 [1:07:25<4:02:50,  3.96s/it] 19%|█▉        | 863/4545 [1:07:29<4:06:21,  4.01s/it] 19%|█▉        | 864/4545 [1:07:33<4:04:23,  3.98s/it] 19%|█▉        | 865/4545 [1:07:36<3:52:56,  3.80s/it] 19%|█▉        | 866/4545 [1:07:40<3:52:47,  3.80s/it] 19%|█▉        | 867/4545 [1:07:44<3:53:49,  3.81s/it] 19%|█▉        | 868/4545 [1:07:48<3:56:40,  3.86s/it] 19%|█▉        | 869/4545 [1:07:51<3:43:51,  3.65s/it] 19%|█▉        | 870/4545 [1:08:20<11:32:11, 11.30s/it]                                                       {'loss': 0.5837, 'grad_norm': 47.90751266479492, 'learning_rate': 5.739762219286658e-08, 'rewards/chosen': 0.667773425579071, 'rewards/rejected': 0.06125488132238388, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.6059905886650085, 'logps/chosen': -251.9499969482422, 'logps/rejected': -116.92500305175781, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.784375190734863, 'epoch': 0.57}
 19%|█▉        | 870/4545 [1:08:21<11:32:11, 11.30s/it] 19%|█▉        | 871/4545 [1:08:24<9:09:59,  8.98s/it]  19%|█▉        | 872/4545 [1:08:27<7:23:58,  7.25s/it] 19%|█▉        | 873/4545 [1:08:30<6:10:51,  6.06s/it] 19%|█▉        | 874/4545 [1:08:34<5:33:02,  5.44s/it] 19%|█▉        | 875/4545 [1:08:37<4:41:46,  4.61s/it] 19%|█▉        | 876/4545 [1:08:41<4:29:05,  4.40s/it] 19%|█▉        | 877/4545 [1:08:45<4:23:44,  4.31s/it] 19%|█▉        | 878/4545 [1:08:49<4:11:18,  4.11s/it] 19%|█▉        | 879/4545 [1:08:53<4:07:56,  4.06s/it] 19%|█▉        | 880/4545 [1:08:56<4:01:38,  3.96s/it]                                                      {'loss': 0.6025, 'grad_norm': 44.571685791015625, 'learning_rate': 5.805812417437253e-08, 'rewards/chosen': 0.84033203125, 'rewards/rejected': 0.15908202528953552, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.681835949420929, 'logps/chosen': -302.5, 'logps/rejected': -147.625, 'logits/chosen': -6.196875095367432, 'logits/rejected': -6.609375, 'epoch': 0.58}
 19%|█▉        | 880/4545 [1:08:56<4:01:38,  3.96s/it] 19%|█▉        | 881/4545 [1:09:01<4:05:51,  4.03s/it] 19%|█▉        | 882/4545 [1:09:05<4:03:54,  4.00s/it] 19%|█▉        | 883/4545 [1:09:08<4:01:08,  3.95s/it] 19%|█▉        | 884/4545 [1:09:12<3:52:20,  3.81s/it] 19%|█▉        | 885/4545 [1:09:15<3:39:48,  3.60s/it] 19%|█▉        | 886/4545 [1:09:19<3:44:00,  3.67s/it] 20%|█▉        | 887/4545 [1:09:23<3:45:41,  3.70s/it] 20%|█▉        | 888/4545 [1:09:26<3:32:57,  3.49s/it] 20%|█▉        | 889/4545 [1:09:30<3:43:07,  3.66s/it] 20%|█▉        | 890/4545 [1:09:34<3:54:05,  3.84s/it]                                                      {'loss': 0.5586, 'grad_norm': 34.833404541015625, 'learning_rate': 5.871862615587847e-08, 'rewards/chosen': 0.7552734613418579, 'rewards/rejected': 0.06973876804113388, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.684619128704071, 'logps/chosen': -246.47500610351562, 'logps/rejected': -118.5999984741211, 'logits/chosen': -6.296875, 'logits/rejected': -6.493750095367432, 'epoch': 0.59}
 20%|█▉        | 890/4545 [1:09:34<3:54:05,  3.84s/it] 20%|█▉        | 891/4545 [1:09:38<3:56:26,  3.88s/it] 20%|█▉        | 892/4545 [1:09:42<3:57:34,  3.90s/it] 20%|█▉        | 893/4545 [1:09:45<3:50:46,  3.79s/it] 20%|█▉        | 894/4545 [1:09:49<3:44:00,  3.68s/it] 20%|█▉        | 895/4545 [1:09:53<3:48:13,  3.75s/it] 20%|█▉        | 896/4545 [1:09:57<3:51:12,  3.80s/it] 20%|█▉        | 897/4545 [1:10:01<3:53:21,  3.84s/it] 20%|█▉        | 898/4545 [1:10:05<3:58:00,  3.92s/it] 20%|█▉        | 899/4545 [1:10:09<3:56:52,  3.90s/it] 20%|█▉        | 900/4545 [1:10:12<3:57:17,  3.91s/it]                                                      {'loss': 0.5703, 'grad_norm': 105.17072296142578, 'learning_rate': 5.93791281373844e-08, 'rewards/chosen': 1.2294921875, 'rewards/rejected': 0.212840273976326, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.0167968273162842, 'logps/chosen': -472.20001220703125, 'logps/rejected': -250.52499389648438, 'logits/chosen': -6.040625095367432, 'logits/rejected': -6.425000190734863, 'epoch': 0.59}
 20%|█▉        | 900/4545 [1:10:13<3:57:17,  3.91s/it] 20%|█▉        | 901/4545 [1:10:16<3:48:15,  3.76s/it] 20%|█▉        | 902/4545 [1:10:20<3:50:59,  3.80s/it] 20%|█▉        | 903/4545 [1:10:24<3:49:28,  3.78s/it] 20%|█▉        | 904/4545 [1:10:27<3:38:13,  3.60s/it] 20%|█▉        | 905/4545 [1:10:31<3:43:49,  3.69s/it] 20%|█▉        | 906/4545 [1:10:34<3:47:34,  3.75s/it] 20%|█▉        | 907/4545 [1:10:39<3:55:57,  3.89s/it] 20%|█▉        | 908/4545 [1:10:43<3:56:13,  3.90s/it] 20%|██        | 909/4545 [1:10:47<3:57:09,  3.91s/it] 20%|██        | 910/4545 [1:10:50<3:47:31,  3.76s/it]                                                      {'loss': 0.6029, 'grad_norm': 55.16666793823242, 'learning_rate': 6.003963011889035e-08, 'rewards/chosen': 0.6937500238418579, 'rewards/rejected': 0.20754393935203552, 'rewards/accuracies': 0.6937500238418579, 'rewards/margins': 0.48707276582717896, 'logps/chosen': -249.60000610351562, 'logps/rejected': -155.625, 'logits/chosen': -6.171875, 'logits/rejected': -6.574999809265137, 'epoch': 0.6}
 20%|██        | 910/4545 [1:10:50<3:47:31,  3.76s/it] 20%|██        | 911/4545 [1:10:54<3:53:30,  3.86s/it] 20%|██        | 912/4545 [1:10:58<3:56:31,  3.91s/it] 20%|██        | 913/4545 [1:11:02<3:57:44,  3.93s/it] 20%|██        | 914/4545 [1:11:06<3:57:45,  3.93s/it] 20%|██        | 915/4545 [1:11:09<3:48:36,  3.78s/it] 20%|██        | 916/4545 [1:11:13<3:50:50,  3.82s/it] 20%|██        | 917/4545 [1:11:17<3:52:39,  3.85s/it] 20%|██        | 918/4545 [1:11:19<3:21:36,  3.34s/it] 20%|██        | 919/4545 [1:11:23<3:28:54,  3.46s/it] 20%|██        | 920/4545 [1:11:27<3:38:59,  3.62s/it]                                                      {'loss': 0.5902, 'grad_norm': 44.810359954833984, 'learning_rate': 6.07001321003963e-08, 'rewards/chosen': 1.186914086341858, 'rewards/rejected': 0.18084716796875, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.00732421875, 'logps/chosen': -412.79998779296875, 'logps/rejected': -184.0749969482422, 'logits/chosen': -6.096875190734863, 'logits/rejected': -6.443749904632568, 'epoch': 0.61}
 20%|██        | 920/4545 [1:11:27<3:38:59,  3.62s/it] 20%|██        | 921/4545 [1:11:30<3:33:14,  3.53s/it] 20%|██        | 922/4545 [1:11:33<3:21:47,  3.34s/it] 20%|██        | 923/4545 [1:11:37<3:32:10,  3.51s/it] 20%|██        | 924/4545 [1:11:41<3:40:13,  3.65s/it] 20%|██        | 925/4545 [1:11:45<3:48:58,  3.80s/it] 20%|██        | 926/4545 [1:11:50<3:57:02,  3.93s/it] 20%|██        | 927/4545 [1:11:53<3:43:22,  3.70s/it] 20%|██        | 928/4545 [1:11:57<3:46:50,  3.76s/it] 20%|██        | 929/4545 [1:12:00<3:44:15,  3.72s/it] 20%|██        | 930/4545 [1:12:04<3:50:37,  3.83s/it]                                                      {'loss': 0.5552, 'grad_norm': 46.799339294433594, 'learning_rate': 6.136063408190223e-08, 'rewards/chosen': 0.7630859613418579, 'rewards/rejected': 0.06909789890050888, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 0.69287109375, 'logps/chosen': -258.6499938964844, 'logps/rejected': -132.6999969482422, 'logits/chosen': -6.284375190734863, 'logits/rejected': -6.721875190734863, 'epoch': 0.61}
 20%|██        | 930/4545 [1:12:05<3:50:37,  3.83s/it] 20%|██        | 931/4545 [1:12:09<3:58:59,  3.97s/it] 21%|██        | 932/4545 [1:12:12<3:49:59,  3.82s/it] 21%|██        | 933/4545 [1:12:15<3:37:28,  3.61s/it] 21%|██        | 934/4545 [1:12:19<3:33:38,  3.55s/it] 21%|██        | 935/4545 [1:12:49<11:41:24, 11.66s/it] 21%|██        | 936/4545 [1:12:52<8:52:05,  8.85s/it]  21%|██        | 937/4545 [1:12:55<7:23:09,  7.37s/it] 21%|██        | 938/4545 [1:12:59<6:21:37,  6.35s/it] 21%|██        | 939/4545 [1:13:03<5:35:57,  5.59s/it] 21%|██        | 940/4545 [1:13:07<5:10:43,  5.17s/it]                                                      {'loss': 0.5947, 'grad_norm': 54.77812576293945, 'learning_rate': 6.202113606340819e-08, 'rewards/chosen': 0.60498046875, 'rewards/rejected': 0.11787109076976776, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.48585206270217896, 'logps/chosen': -204.9499969482422, 'logps/rejected': -111.5250015258789, 'logits/chosen': -6.478125095367432, 'logits/rejected': -6.743750095367432, 'epoch': 0.62}
 21%|██        | 940/4545 [1:13:08<5:10:43,  5.17s/it] 21%|██        | 941/4545 [1:13:12<4:54:20,  4.90s/it] 21%|██        | 942/4545 [1:13:16<4:36:12,  4.60s/it] 21%|██        | 943/4545 [1:13:19<4:20:27,  4.34s/it] 21%|██        | 944/4545 [1:13:22<3:43:44,  3.73s/it] 21%|██        | 945/4545 [1:13:25<3:41:12,  3.69s/it] 21%|██        | 946/4545 [1:13:29<3:40:18,  3.67s/it] 21%|██        | 947/4545 [1:13:33<3:45:00,  3.75s/it] 21%|██        | 948/4545 [1:13:36<3:37:57,  3.64s/it] 21%|██        | 949/4545 [1:13:40<3:43:10,  3.72s/it] 21%|██        | 950/4545 [1:13:44<3:46:41,  3.78s/it]                                                      {'loss': 0.6099, 'grad_norm': 37.812191009521484, 'learning_rate': 6.268163804491414e-08, 'rewards/chosen': 0.727343738079071, 'rewards/rejected': 0.1671142578125, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.559619128704071, 'logps/chosen': -219.25, 'logps/rejected': -129.5, 'logits/chosen': -6.334374904632568, 'logits/rejected': -6.540625095367432, 'epoch': 0.63}
 21%|██        | 950/4545 [1:13:44<3:46:41,  3.78s/it] 21%|██        | 951/4545 [1:13:46<3:22:30,  3.38s/it] 21%|██        | 952/4545 [1:13:50<3:16:51,  3.29s/it] 21%|██        | 953/4545 [1:13:54<3:29:56,  3.51s/it] 21%|██        | 954/4545 [1:13:58<3:39:49,  3.67s/it] 21%|██        | 955/4545 [1:14:02<3:45:50,  3.77s/it] 21%|██        | 956/4545 [1:14:06<3:48:24,  3.82s/it] 21%|██        | 957/4545 [1:14:09<3:50:01,  3.85s/it] 21%|██        | 958/4545 [1:14:13<3:51:28,  3.87s/it] 21%|██        | 959/4545 [1:14:17<3:52:17,  3.89s/it] 21%|██        | 960/4545 [1:14:21<3:48:11,  3.82s/it]                                                      {'loss': 0.5529, 'grad_norm': 50.797203063964844, 'learning_rate': 6.334214002642007e-08, 'rewards/chosen': 1.2999999523162842, 'rewards/rejected': 0.13690415024757385, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.1624023914337158, 'logps/chosen': -456.07501220703125, 'logps/rejected': -216.60000610351562, 'logits/chosen': -6.103125095367432, 'logits/rejected': -6.581250190734863, 'epoch': 0.63}
 21%|██        | 960/4545 [1:14:21<3:48:11,  3.82s/it] 21%|██        | 961/4545 [1:14:25<3:46:21,  3.79s/it] 21%|██        | 962/4545 [1:14:29<3:53:06,  3.90s/it] 21%|██        | 963/4545 [1:14:32<3:48:00,  3.82s/it] 21%|██        | 964/4545 [1:14:36<3:49:41,  3.85s/it] 21%|██        | 965/4545 [1:14:40<3:51:16,  3.88s/it] 21%|██▏       | 966/4545 [1:14:44<3:51:16,  3.88s/it] 21%|██▏       | 967/4545 [1:14:48<3:51:53,  3.89s/it] 21%|██▏       | 968/4545 [1:14:52<3:52:25,  3.90s/it] 21%|██▏       | 969/4545 [1:14:56<3:52:19,  3.90s/it] 21%|██▏       | 970/4545 [1:14:59<3:43:45,  3.76s/it]                                                      {'loss': 0.5714, 'grad_norm': 37.176063537597656, 'learning_rate': 6.400264200792602e-08, 'rewards/chosen': 1.10400390625, 'rewards/rejected': 0.17656250298023224, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.927050769329071, 'logps/chosen': -377.3500061035156, 'logps/rejected': -167.375, 'logits/chosen': -6.1875, 'logits/rejected': -6.637499809265137, 'epoch': 0.64}
 21%|██▏       | 970/4545 [1:15:00<3:43:45,  3.76s/it] 21%|██▏       | 971/4545 [1:15:02<3:31:58,  3.56s/it] 21%|██▏       | 972/4545 [1:15:07<3:43:34,  3.75s/it] 21%|██▏       | 973/4545 [1:15:11<3:47:00,  3.81s/it] 21%|██▏       | 974/4545 [1:15:15<3:48:35,  3.84s/it] 21%|██▏       | 975/4545 [1:15:18<3:49:49,  3.86s/it] 21%|██▏       | 976/4545 [1:15:23<3:56:14,  3.97s/it] 21%|██▏       | 977/4545 [1:15:27<3:53:47,  3.93s/it] 22%|██▏       | 978/4545 [1:15:29<3:30:40,  3.54s/it] 22%|██▏       | 979/4545 [1:15:33<3:37:15,  3.66s/it] 22%|██▏       | 980/4545 [1:15:37<3:47:09,  3.82s/it]                                                      {'loss': 0.5409, 'grad_norm': 39.68429183959961, 'learning_rate': 6.466314398943196e-08, 'rewards/chosen': 1.1925780773162842, 'rewards/rejected': 0.18584899604320526, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0065429210662842, 'logps/chosen': -375.75, 'logps/rejected': -195.375, 'logits/chosen': -6.328125, 'logits/rejected': -6.628125190734863, 'epoch': 0.65}
 22%|██▏       | 980/4545 [1:15:37<3:47:09,  3.82s/it] 22%|██▏       | 981/4545 [1:15:41<3:49:34,  3.86s/it] 22%|██▏       | 982/4545 [1:15:45<3:55:42,  3.97s/it] 22%|██▏       | 983/4545 [1:15:48<3:22:55,  3.42s/it] 22%|██▏       | 984/4545 [1:15:51<3:30:58,  3.55s/it] 22%|██▏       | 985/4545 [1:15:54<3:20:14,  3.37s/it] 22%|██▏       | 986/4545 [1:15:57<3:06:37,  3.15s/it] 22%|██▏       | 987/4545 [1:16:00<3:10:48,  3.22s/it] 22%|██▏       | 988/4545 [1:16:04<3:23:03,  3.43s/it] 22%|██▏       | 989/4545 [1:16:07<3:12:40,  3.25s/it] 22%|██▏       | 990/4545 [1:16:11<3:24:49,  3.46s/it]                                                      {'loss': 0.5606, 'grad_norm': 47.172080993652344, 'learning_rate': 6.532364597093791e-08, 'rewards/chosen': 0.4990234375, 'rewards/rejected': 0.034912109375, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.4644531309604645, 'logps/chosen': -143.47500610351562, 'logps/rejected': -80.23750305175781, 'logits/chosen': -6.384375095367432, 'logits/rejected': -6.390625, 'epoch': 0.65}
 22%|██▏       | 990/4545 [1:16:11<3:24:49,  3.46s/it] 22%|██▏       | 991/4545 [1:16:15<3:38:41,  3.69s/it] 22%|██▏       | 992/4545 [1:16:18<3:22:49,  3.43s/it] 22%|██▏       | 993/4545 [1:16:22<3:27:19,  3.50s/it] 22%|██▏       | 994/4545 [1:16:26<3:35:05,  3.63s/it] 22%|██▏       | 995/4545 [1:16:29<3:28:33,  3.53s/it] 22%|██▏       | 996/4545 [1:16:31<3:05:46,  3.14s/it] 22%|██▏       | 997/4545 [1:16:36<3:27:37,  3.51s/it] 22%|██▏       | 998/4545 [1:16:40<3:37:55,  3.69s/it] 22%|██▏       | 999/4545 [1:16:44<3:45:13,  3.81s/it] 22%|██▏       | 1000/4545 [1:16:48<3:43:17,  3.78s/it]                                                       {'loss': 0.5657, 'grad_norm': 55.250057220458984, 'learning_rate': 6.598414795244386e-08, 'rewards/chosen': 0.5302734375, 'rewards/rejected': 0.03613739088177681, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.49370115995407104, 'logps/chosen': -157.8000030517578, 'logps/rejected': -90.4000015258789, 'logits/chosen': -6.471875190734863, 'logits/rejected': -6.631249904632568, 'epoch': 0.66}
 22%|██▏       | 1000/4545 [1:16:48<3:43:17,  3.78s/it] 22%|██▏       | 1001/4545 [1:16:51<3:44:18,  3.80s/it] 22%|██▏       | 1002/4545 [1:16:56<3:49:36,  3.89s/it] 22%|██▏       | 1003/4545 [1:16:59<3:49:00,  3.88s/it] 22%|██▏       | 1004/4545 [1:17:03<3:44:24,  3.80s/it] 22%|██▏       | 1005/4545 [1:17:06<3:25:29,  3.48s/it] 22%|██▏       | 1006/4545 [1:17:10<3:41:22,  3.75s/it] 22%|██▏       | 1007/4545 [1:17:14<3:35:13,  3.65s/it] 22%|██▏       | 1008/4545 [1:17:17<3:37:38,  3.69s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:39,  1.45it/s][A
  5%|▌         | 3/60 [00:03<01:00,  1.06s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.54s/it][A
 13%|█▎        | 8/60 [00:11<01:24,  1.63s/it][A
 15%|█▌        | 9/60 [00:13<01:23,  1.64s/it][A
 17%|█▋        | 10/60 [00:14<01:21,  1.62s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.65s/it][A
 20%|██        | 12/60 [00:18<01:20,  1.68s/it][A
 22%|██▏       | 13/60 [00:19<01:17,  1.66s/it][A
 23%|██▎       | 14/60 [00:21<01:16,  1.65s/it][A
 25%|██▌       | 15/60 [00:22<01:09,  1.54s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.40s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.30s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.15s/it][A
 33%|███▎      | 20/60 [00:27<00:40,  1.00s/it][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.10s/it][A
 42%|████▏     | 25/60 [00:33<00:44,  1.26s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.09s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:41<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:44<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:46<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:48<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:53<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:57<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:01<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.33s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:08<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:09<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:13<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:16<00:02,  1.41s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.46s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A                                                       
                                               [A{'eval_loss': 0.45590296387672424, 'eval_runtime': 81.2365, 'eval_samples_per_second': 11.731, 'eval_steps_per_second': 0.739, 'eval_rewards/chosen': 1.1461262702941895, 'eval_rewards/rejected': 0.17040914297103882, 'eval_rewards/accuracies': 0.887384295463562, 'eval_rewards/margins': 0.975415050983429, 'eval_logps/chosen': -372.0333251953125, 'eval_logps/rejected': -151.10833740234375, 'eval_logits/chosen': -6.017968654632568, 'eval_logits/rejected': -6.890104293823242, 'epoch': 0.67}
 22%|██▏       | 1008/4545 [1:18:39<3:37:38,  3.69s/it]
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 22%|██▏       | 1009/4545 [1:18:57<32:01:15, 32.60s/it] 22%|██▏       | 1010/4545 [1:19:01<23:33:58, 24.00s/it]                                                        {'loss': 0.586, 'grad_norm': 45.5854606628418, 'learning_rate': 6.66446499339498e-08, 'rewards/chosen': 0.552539050579071, 'rewards/rejected': 0.055110931396484375, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.4969726502895355, 'logps/chosen': -185.0, 'logps/rejected': -103.55000305175781, 'logits/chosen': -6.381249904632568, 'logits/rejected': -6.706250190734863, 'epoch': 0.67}
 22%|██▏       | 1010/4545 [1:19:01<23:33:58, 24.00s/it] 22%|██▏       | 1011/4545 [1:19:05<17:39:53, 17.99s/it] 22%|██▏       | 1012/4545 [1:19:09<13:31:14, 13.78s/it] 22%|██▏       | 1013/4545 [1:19:13<10:36:54, 10.82s/it] 22%|██▏       | 1014/4545 [1:19:17<8:35:08,  8.75s/it]  22%|██▏       | 1015/4545 [1:19:21<7:09:32,  7.30s/it] 22%|██▏       | 1016/4545 [1:19:25<6:10:05,  6.29s/it] 22%|██▏       | 1017/4545 [1:19:29<5:26:55,  5.56s/it] 22%|██▏       | 1018/4545 [1:19:31<4:30:46,  4.61s/it] 22%|██▏       | 1019/4545 [1:19:35<4:21:51,  4.46s/it] 22%|██▏       | 1020/4545 [1:19:39<4:00:30,  4.09s/it]                                                       {'loss': 0.5572, 'grad_norm': 35.314918518066406, 'learning_rate': 6.730515191545574e-08, 'rewards/chosen': 1.0283203125, 'rewards/rejected': 0.09369468688964844, 'rewards/accuracies': 0.75, 'rewards/margins': 0.932910144329071, 'logps/chosen': -310.3999938964844, 'logps/rejected': -181.10000610351562, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.587500095367432, 'epoch': 0.67}
 22%|██▏       | 1020/4545 [1:19:39<4:00:30,  4.09s/it] 22%|██▏       | 1021/4545 [1:19:41<3:24:50,  3.49s/it] 22%|██▏       | 1022/4545 [1:19:43<3:14:05,  3.31s/it] 23%|██▎       | 1023/4545 [1:19:47<3:18:02,  3.37s/it] 23%|██▎       | 1024/4545 [1:19:51<3:31:14,  3.60s/it] 23%|██▎       | 1025/4545 [1:19:55<3:37:35,  3.71s/it] 23%|██▎       | 1026/4545 [1:19:59<3:41:02,  3.77s/it] 23%|██▎       | 1027/4545 [1:20:03<3:37:08,  3.70s/it] 23%|██▎       | 1028/4545 [1:20:06<3:36:26,  3.69s/it] 23%|██▎       | 1029/4545 [1:20:10<3:43:38,  3.82s/it] 23%|██▎       | 1030/4545 [1:20:14<3:45:38,  3.85s/it]                                                       {'loss': 0.558, 'grad_norm': 40.981563568115234, 'learning_rate': 6.796565389696169e-08, 'rewards/chosen': 0.6966797113418579, 'rewards/rejected': 0.06981201469898224, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.6273437738418579, 'logps/chosen': -203.0, 'logps/rejected': -124.4749984741211, 'logits/chosen': -6.565625190734863, 'logits/rejected': -6.690625190734863, 'epoch': 0.68}
 23%|██▎       | 1030/4545 [1:20:15<3:45:38,  3.85s/it] 23%|██▎       | 1031/4545 [1:20:18<3:37:08,  3.71s/it] 23%|██▎       | 1032/4545 [1:20:21<3:35:46,  3.69s/it] 23%|██▎       | 1033/4545 [1:20:25<3:40:13,  3.76s/it] 23%|██▎       | 1034/4545 [1:20:28<3:25:48,  3.52s/it] 23%|██▎       | 1035/4545 [1:20:32<3:35:51,  3.69s/it] 23%|██▎       | 1036/4545 [1:20:35<3:27:32,  3.55s/it] 23%|██▎       | 1037/4545 [1:20:39<3:24:27,  3.50s/it] 23%|██▎       | 1038/4545 [1:20:42<3:11:35,  3.28s/it] 23%|██▎       | 1039/4545 [1:20:46<3:23:00,  3.47s/it] 23%|██▎       | 1040/4545 [1:20:49<3:19:50,  3.42s/it]                                                       {'loss': 0.5798, 'grad_norm': 40.831966400146484, 'learning_rate': 6.862615587846763e-08, 'rewards/chosen': 0.708203136920929, 'rewards/rejected': 0.077606201171875, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.629931628704071, 'logps/chosen': -183.89999389648438, 'logps/rejected': -109.0250015258789, 'logits/chosen': -6.40625, 'logits/rejected': -6.525000095367432, 'epoch': 0.69}
 23%|██▎       | 1040/4545 [1:20:49<3:19:50,  3.42s/it] 23%|██▎       | 1041/4545 [1:20:53<3:30:03,  3.60s/it] 23%|██▎       | 1042/4545 [1:20:56<3:30:22,  3.60s/it] 23%|██▎       | 1043/4545 [1:21:00<3:24:59,  3.51s/it] 23%|██▎       | 1044/4545 [1:21:04<3:30:35,  3.61s/it] 23%|██▎       | 1045/4545 [1:21:08<3:36:20,  3.71s/it] 23%|██▎       | 1046/4545 [1:21:11<3:39:52,  3.77s/it] 23%|██▎       | 1047/4545 [1:21:15<3:42:23,  3.81s/it] 23%|██▎       | 1048/4545 [1:21:19<3:45:05,  3.86s/it] 23%|██▎       | 1049/4545 [1:21:23<3:36:30,  3.72s/it] 23%|██▎       | 1050/4545 [1:21:27<3:40:02,  3.78s/it]                                                       {'loss': 0.509, 'grad_norm': 27.510116577148438, 'learning_rate': 6.928665785997358e-08, 'rewards/chosen': 1.1843750476837158, 'rewards/rejected': 0.12474365532398224, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.0593750476837158, 'logps/chosen': -349.54998779296875, 'logps/rejected': -166.4499969482422, 'logits/chosen': -6.203125, 'logits/rejected': -6.571875095367432, 'epoch': 0.69}
 23%|██▎       | 1050/4545 [1:21:27<3:40:02,  3.78s/it] 23%|██▎       | 1051/4545 [1:21:31<3:45:45,  3.88s/it] 23%|██▎       | 1052/4545 [1:21:35<3:45:46,  3.88s/it] 23%|██▎       | 1053/4545 [1:21:38<3:40:36,  3.79s/it] 23%|██▎       | 1054/4545 [1:21:42<3:33:21,  3.67s/it] 23%|██▎       | 1055/4545 [1:21:45<3:33:35,  3.67s/it] 23%|██▎       | 1056/4545 [1:21:49<3:35:47,  3.71s/it] 23%|██▎       | 1057/4545 [1:21:53<3:39:08,  3.77s/it] 23%|██▎       | 1058/4545 [1:21:56<3:27:03,  3.56s/it] 23%|██▎       | 1059/4545 [1:22:00<3:33:27,  3.67s/it] 23%|██▎       | 1060/4545 [1:22:04<3:39:42,  3.78s/it]                                                       {'loss': 0.5437, 'grad_norm': 39.405113220214844, 'learning_rate': 6.994715984147951e-08, 'rewards/chosen': 0.9556640386581421, 'rewards/rejected': 0.17313233017921448, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.782910168170929, 'logps/chosen': -289.625, 'logps/rejected': -164.25, 'logits/chosen': -6.400000095367432, 'logits/rejected': -6.462500095367432, 'epoch': 0.7}
 23%|██▎       | 1060/4545 [1:22:04<3:39:42,  3.78s/it] 23%|██▎       | 1061/4545 [1:22:08<3:42:42,  3.84s/it] 23%|██▎       | 1062/4545 [1:22:12<3:50:25,  3.97s/it] 23%|██▎       | 1063/4545 [1:22:16<3:41:54,  3.82s/it] 23%|██▎       | 1064/4545 [1:22:20<3:43:48,  3.86s/it] 23%|██▎       | 1065/4545 [1:22:24<3:48:29,  3.94s/it] 23%|██▎       | 1066/4545 [1:22:28<3:52:52,  4.02s/it] 23%|██▎       | 1067/4545 [1:22:31<3:38:13,  3.76s/it] 23%|██▎       | 1068/4545 [1:22:35<3:36:48,  3.74s/it] 24%|██▎       | 1069/4545 [1:22:38<3:34:00,  3.69s/it] 24%|██▎       | 1070/4545 [1:22:42<3:28:38,  3.60s/it]                                                       {'loss': 0.5055, 'grad_norm': 31.707778930664062, 'learning_rate': 7.060766182298546e-08, 'rewards/chosen': 0.724804699420929, 'rewards/rejected': -0.011706543155014515, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 0.735546886920929, 'logps/chosen': -191.35000610351562, 'logps/rejected': -98.19999694824219, 'logits/chosen': -6.306250095367432, 'logits/rejected': -6.662499904632568, 'epoch': 0.71}
 24%|██▎       | 1070/4545 [1:22:42<3:28:38,  3.60s/it] 24%|██▎       | 1071/4545 [1:22:46<3:34:33,  3.71s/it] 24%|██▎       | 1072/4545 [1:22:50<3:39:10,  3.79s/it] 24%|██▎       | 1073/4545 [1:22:54<3:41:38,  3.83s/it] 24%|██▎       | 1074/4545 [1:22:58<3:42:45,  3.85s/it] 24%|██▎       | 1075/4545 [1:23:02<3:46:14,  3.91s/it] 24%|██▎       | 1076/4545 [1:23:05<3:29:51,  3.63s/it] 24%|██▎       | 1077/4545 [1:23:09<3:34:58,  3.72s/it] 24%|██▎       | 1078/4545 [1:23:12<3:38:34,  3.78s/it] 24%|██▎       | 1079/4545 [1:23:16<3:40:56,  3.82s/it] 24%|██▍       | 1080/4545 [1:23:20<3:42:37,  3.85s/it]                                                       {'loss': 0.574, 'grad_norm': 50.35028076171875, 'learning_rate': 7.126816380449141e-08, 'rewards/chosen': 1.4392578601837158, 'rewards/rejected': 0.4272522032260895, 'rewards/accuracies': 0.706250011920929, 'rewards/margins': 1.012304663658142, 'logps/chosen': -460.54998779296875, 'logps/rejected': -217.60000610351562, 'logits/chosen': -5.887499809265137, 'logits/rejected': -6.121874809265137, 'epoch': 0.71}
 24%|██▍       | 1080/4545 [1:23:20<3:42:37,  3.85s/it] 24%|██▍       | 1081/4545 [1:23:24<3:44:51,  3.89s/it] 24%|██▍       | 1082/4545 [1:23:28<3:46:48,  3.93s/it] 24%|██▍       | 1083/4545 [1:23:31<3:32:46,  3.69s/it] 24%|██▍       | 1084/4545 [1:23:36<3:39:34,  3.81s/it] 24%|██▍       | 1085/4545 [1:23:39<3:34:55,  3.73s/it] 24%|██▍       | 1086/4545 [1:23:42<3:19:01,  3.45s/it] 24%|██▍       | 1087/4545 [1:23:45<3:10:15,  3.30s/it] 24%|██▍       | 1088/4545 [1:23:49<3:21:09,  3.49s/it] 24%|██▍       | 1089/4545 [1:23:53<3:28:14,  3.62s/it] 24%|██▍       | 1090/4545 [1:23:57<3:37:32,  3.78s/it]                                                       {'loss': 0.549, 'grad_norm': 46.4014892578125, 'learning_rate': 7.192866578599735e-08, 'rewards/chosen': 0.9287109375, 'rewards/rejected': -0.01298370398581028, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.942675769329071, 'logps/chosen': -246.47500610351562, 'logps/rejected': -112.875, 'logits/chosen': -6.384375095367432, 'logits/rejected': -6.568749904632568, 'epoch': 0.72}
 24%|██▍       | 1090/4545 [1:23:57<3:37:32,  3.78s/it] 24%|██▍       | 1091/4545 [1:24:00<3:33:47,  3.71s/it] 24%|██▍       | 1092/4545 [1:24:02<3:05:20,  3.22s/it] 24%|██▍       | 1093/4545 [1:24:06<3:18:43,  3.45s/it] 24%|██▍       | 1094/4545 [1:24:10<3:18:40,  3.45s/it] 24%|██▍       | 1095/4545 [1:24:14<3:26:32,  3.59s/it] 24%|██▍       | 1096/4545 [1:24:17<3:15:25,  3.40s/it] 24%|██▍       | 1097/4545 [1:24:21<3:28:30,  3.63s/it] 24%|██▍       | 1098/4545 [1:24:25<3:35:59,  3.76s/it] 24%|██▍       | 1099/4545 [1:24:29<3:38:44,  3.81s/it] 24%|██▍       | 1100/4545 [1:24:33<3:43:49,  3.90s/it]                                                       {'loss': 0.5415, 'grad_norm': 39.58277130126953, 'learning_rate': 7.25891677675033e-08, 'rewards/chosen': 0.9075683355331421, 'rewards/rejected': 0.13059082627296448, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.7762451171875, 'logps/chosen': -256.3500061035156, 'logps/rejected': -127.13749694824219, 'logits/chosen': -6.449999809265137, 'logits/rejected': -6.712500095367432, 'epoch': 0.73}
 24%|██▍       | 1100/4545 [1:24:33<3:43:49,  3.90s/it] 24%|██▍       | 1101/4545 [1:24:37<3:45:59,  3.94s/it] 24%|██▍       | 1102/4545 [1:24:41<3:45:40,  3.93s/it] 24%|██▍       | 1103/4545 [1:24:44<3:35:42,  3.76s/it] 24%|██▍       | 1104/4545 [1:24:48<3:38:27,  3.81s/it] 24%|██▍       | 1105/4545 [1:24:52<3:43:25,  3.90s/it] 24%|██▍       | 1106/4545 [1:24:56<3:43:44,  3.90s/it] 24%|██▍       | 1107/4545 [1:25:01<3:49:34,  4.01s/it] 24%|██▍       | 1108/4545 [1:25:03<3:24:05,  3.56s/it] 24%|██▍       | 1109/4545 [1:25:07<3:29:59,  3.67s/it] 24%|██▍       | 1110/4545 [1:25:10<3:21:25,  3.52s/it]                                                       {'loss': 0.5251, 'grad_norm': 43.268802642822266, 'learning_rate': 7.324966974900924e-08, 'rewards/chosen': 1.114648461341858, 'rewards/rejected': 0.16064453125, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.955371081829071, 'logps/chosen': -306.67498779296875, 'logps/rejected': -165.0749969482422, 'logits/chosen': -6.265625, 'logits/rejected': -6.606249809265137, 'epoch': 0.73}
 24%|██▍       | 1110/4545 [1:25:10<3:21:25,  3.52s/it] 24%|██▍       | 1111/4545 [1:25:13<3:05:21,  3.24s/it] 24%|██▍       | 1112/4545 [1:25:17<3:17:06,  3.44s/it] 24%|██▍       | 1113/4545 [1:25:20<3:21:56,  3.53s/it] 25%|██▍       | 1114/4545 [1:25:24<3:28:33,  3.65s/it] 25%|██▍       | 1115/4545 [1:25:29<3:38:14,  3.82s/it] 25%|██▍       | 1116/4545 [1:25:32<3:28:47,  3.65s/it] 25%|██▍       | 1117/4545 [1:25:34<3:02:41,  3.20s/it] 25%|██▍       | 1118/4545 [1:25:38<3:20:16,  3.51s/it] 25%|██▍       | 1119/4545 [1:25:42<3:26:16,  3.61s/it] 25%|██▍       | 1120/4545 [1:25:46<3:28:39,  3.66s/it]                                                       {'loss': 0.4934, 'grad_norm': 30.943599700927734, 'learning_rate': 7.391017173051519e-08, 'rewards/chosen': 1.0107421875, 'rewards/rejected': 0.0819091796875, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 0.9300781488418579, 'logps/chosen': -263.625, 'logps/rejected': -134.02499389648438, 'logits/chosen': -6.506249904632568, 'logits/rejected': -6.75, 'epoch': 0.74}
 25%|██▍       | 1120/4545 [1:25:46<3:28:39,  3.66s/it] 25%|██▍       | 1121/4545 [1:25:50<3:39:42,  3.85s/it] 25%|██▍       | 1122/4545 [1:25:54<3:42:57,  3.91s/it] 25%|██▍       | 1123/4545 [1:25:58<3:41:34,  3.89s/it] 25%|██▍       | 1124/4545 [1:26:02<3:42:14,  3.90s/it] 25%|██▍       | 1125/4545 [1:26:05<3:32:29,  3.73s/it] 25%|██▍       | 1126/4545 [1:26:09<3:35:28,  3.78s/it] 25%|██▍       | 1127/4545 [1:26:13<3:30:23,  3.69s/it] 25%|██▍       | 1128/4545 [1:26:16<3:20:46,  3.53s/it] 25%|██▍       | 1129/4545 [1:26:20<3:30:02,  3.69s/it] 25%|██▍       | 1130/4545 [1:26:22<2:59:58,  3.16s/it]                                                       {'loss': 0.5232, 'grad_norm': 29.788558959960938, 'learning_rate': 7.457067371202114e-08, 'rewards/chosen': 0.8974609375, 'rewards/rejected': 0.02946777269244194, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 0.867382824420929, 'logps/chosen': -213.72500610351562, 'logps/rejected': -106.19999694824219, 'logits/chosen': -6.459374904632568, 'logits/rejected': -6.5625, 'epoch': 0.75}
 25%|██▍       | 1130/4545 [1:26:22<2:59:58,  3.16s/it] 25%|██▍       | 1131/4545 [1:26:26<3:11:16,  3.36s/it] 25%|██▍       | 1132/4545 [1:26:28<3:03:29,  3.23s/it] 25%|██▍       | 1133/4545 [1:26:32<3:13:29,  3.40s/it] 25%|██▍       | 1134/4545 [1:26:36<3:10:38,  3.35s/it] 25%|██▍       | 1135/4545 [1:26:39<3:19:54,  3.52s/it] 25%|██▍       | 1136/4545 [1:26:43<3:15:29,  3.44s/it] 25%|██▌       | 1137/4545 [1:26:46<3:13:26,  3.41s/it] 25%|██▌       | 1138/4545 [1:26:50<3:22:20,  3.56s/it] 25%|██▌       | 1139/4545 [1:26:56<4:07:53,  4.37s/it] 25%|██▌       | 1140/4545 [1:27:00<3:53:24,  4.11s/it]                                                       {'loss': 0.5796, 'grad_norm': 71.8296890258789, 'learning_rate': 7.523117569352708e-08, 'rewards/chosen': 0.675000011920929, 'rewards/rejected': 0.11501464992761612, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.5596923828125, 'logps/chosen': -162.0, 'logps/rejected': -113.125, 'logits/chosen': -6.375, 'logits/rejected': -6.456250190734863, 'epoch': 0.75}
 25%|██▌       | 1140/4545 [1:27:00<3:53:24,  4.11s/it] 25%|██▌       | 1141/4545 [1:27:04<3:51:12,  4.08s/it] 25%|██▌       | 1142/4545 [1:27:07<3:36:39,  3.82s/it] 25%|██▌       | 1143/4545 [1:27:10<3:28:51,  3.68s/it] 25%|██▌       | 1144/4545 [1:27:14<3:32:59,  3.76s/it] 25%|██▌       | 1145/4545 [1:27:18<3:35:53,  3.81s/it] 25%|██▌       | 1146/4545 [1:27:22<3:37:55,  3.85s/it] 25%|██▌       | 1147/4545 [1:27:25<3:25:27,  3.63s/it] 25%|██▌       | 1148/4545 [1:27:28<3:12:48,  3.41s/it] 25%|██▌       | 1149/4545 [1:27:32<3:17:01,  3.48s/it] 25%|██▌       | 1150/4545 [1:27:35<3:17:08,  3.48s/it]                                                       {'loss': 0.5032, 'grad_norm': 27.925512313842773, 'learning_rate': 7.589167767503302e-08, 'rewards/chosen': 1.1667969226837158, 'rewards/rejected': 0.09431152045726776, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.0720703601837158, 'logps/chosen': -302.5249938964844, 'logps/rejected': -170.5749969482422, 'logits/chosen': -6.309374809265137, 'logits/rejected': -6.359375, 'epoch': 0.76}
 25%|██▌       | 1150/4545 [1:27:35<3:17:08,  3.48s/it] 25%|██▌       | 1151/4545 [1:27:39<3:26:28,  3.65s/it] 25%|██▌       | 1152/4545 [1:27:43<3:31:02,  3.73s/it] 25%|██▌       | 1153/4545 [1:27:47<3:34:05,  3.79s/it] 25%|██▌       | 1154/4545 [1:27:49<2:55:09,  3.10s/it] 25%|██▌       | 1155/4545 [1:27:53<3:09:30,  3.35s/it] 25%|██▌       | 1156/4545 [1:27:56<3:16:12,  3.47s/it] 25%|██▌       | 1157/4545 [1:28:00<3:25:03,  3.63s/it] 25%|██▌       | 1158/4545 [1:28:04<3:29:59,  3.72s/it] 26%|██▌       | 1159/4545 [1:28:08<3:33:32,  3.78s/it] 26%|██▌       | 1160/4545 [1:28:11<3:19:51,  3.54s/it]                                                       {'loss': 0.4972, 'grad_norm': 31.210355758666992, 'learning_rate': 7.655217965653897e-08, 'rewards/chosen': 1.2869141101837158, 'rewards/rejected': 0.11042480170726776, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.1740233898162842, 'logps/chosen': -282.7250061035156, 'logps/rejected': -133.125, 'logits/chosen': -6.434374809265137, 'logits/rejected': -6.834374904632568, 'epoch': 0.77}
 26%|██▌       | 1160/4545 [1:28:11<3:19:51,  3.54s/it] 26%|██▌       | 1161/4545 [1:28:41<10:53:11, 11.58s/it] 26%|██▌       | 1162/4545 [1:28:45<8:44:01,  9.29s/it]  26%|██▌       | 1163/4545 [1:28:49<7:13:12,  7.69s/it] 26%|██▌       | 1164/4545 [1:28:53<6:11:48,  6.60s/it] 26%|██▌       | 1165/4545 [1:28:57<5:26:35,  5.80s/it] 26%|██▌       | 1166/4545 [1:29:00<4:31:21,  4.82s/it] 26%|██▌       | 1167/4545 [1:29:04<4:16:36,  4.56s/it] 26%|██▌       | 1168/4545 [1:29:08<4:07:48,  4.40s/it] 26%|██▌       | 1169/4545 [1:29:11<3:53:05,  4.14s/it] 26%|██▌       | 1170/4545 [1:29:16<3:54:24,  4.17s/it]                                                       {'loss': 0.4956, 'grad_norm': 46.757232666015625, 'learning_rate': 7.72126816380449e-08, 'rewards/chosen': 1.1875, 'rewards/rejected': -0.0036865235306322575, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 1.1921875476837158, 'logps/chosen': -337.1499938964844, 'logps/rejected': -136.02499389648438, 'logits/chosen': -6.206250190734863, 'logits/rejected': -6.578125, 'epoch': 0.77}
 26%|██▌       | 1170/4545 [1:29:16<3:54:24,  4.17s/it] 26%|██▌       | 1171/4545 [1:29:19<3:34:22,  3.81s/it] 26%|██▌       | 1172/4545 [1:29:23<3:36:14,  3.85s/it] 26%|██▌       | 1173/4545 [1:29:26<3:28:18,  3.71s/it] 26%|██▌       | 1174/4545 [1:29:30<3:31:52,  3.77s/it] 26%|██▌       | 1175/4545 [1:29:34<3:33:44,  3.81s/it] 26%|██▌       | 1176/4545 [1:29:38<3:35:54,  3.85s/it] 26%|██▌       | 1177/4545 [1:29:41<3:30:57,  3.76s/it] 26%|██▌       | 1178/4545 [1:29:45<3:34:03,  3.81s/it] 26%|██▌       | 1179/4545 [1:29:49<3:40:46,  3.94s/it] 26%|██▌       | 1180/4545 [1:29:54<3:45:30,  4.02s/it]                                                       {'loss': 0.4936, 'grad_norm': 316.0193786621094, 'learning_rate': 7.787318361955085e-08, 'rewards/chosen': 1.2833983898162842, 'rewards/rejected': 0.15412597358226776, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.1279296875, 'logps/chosen': -314.45001220703125, 'logps/rejected': -183.22500610351562, 'logits/chosen': -6.4375, 'logits/rejected': -6.728125095367432, 'epoch': 0.78}
 26%|██▌       | 1180/4545 [1:29:54<3:45:30,  4.02s/it] 26%|██▌       | 1181/4545 [1:29:58<3:47:26,  4.06s/it] 26%|██▌       | 1182/4545 [1:30:02<3:45:17,  4.02s/it] 26%|██▌       | 1183/4545 [1:30:06<3:49:14,  4.09s/it] 26%|██▌       | 1184/4545 [1:30:10<3:46:32,  4.04s/it] 26%|██▌       | 1185/4545 [1:30:13<3:24:59,  3.66s/it] 26%|██▌       | 1186/4545 [1:30:17<3:29:22,  3.74s/it] 26%|██▌       | 1187/4545 [1:30:21<3:32:20,  3.79s/it] 26%|██▌       | 1188/4545 [1:30:24<3:34:33,  3.83s/it] 26%|██▌       | 1189/4545 [1:30:28<3:26:38,  3.69s/it] 26%|██▌       | 1190/4545 [1:30:32<3:30:29,  3.76s/it]                                                       {'loss': 0.4741, 'grad_norm': 56.75946044921875, 'learning_rate': 7.853368560105679e-08, 'rewards/chosen': 1.269921898841858, 'rewards/rejected': 0.10598144680261612, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.1650390625, 'logps/chosen': -297.3500061035156, 'logps/rejected': -197.1999969482422, 'logits/chosen': -6.387499809265137, 'logits/rejected': -6.834374904632568, 'epoch': 0.79}
 26%|██▌       | 1190/4545 [1:30:32<3:30:29,  3.76s/it] 26%|██▌       | 1191/4545 [1:30:35<3:22:41,  3.63s/it] 26%|██▌       | 1192/4545 [1:30:39<3:31:43,  3.79s/it] 26%|██▌       | 1193/4545 [1:30:43<3:29:43,  3.75s/it] 26%|██▋       | 1194/4545 [1:30:47<3:31:40,  3.79s/it] 26%|██▋       | 1195/4545 [1:30:51<3:33:25,  3.82s/it] 26%|██▋       | 1196/4545 [1:30:55<3:35:05,  3.85s/it] 26%|██▋       | 1197/4545 [1:30:58<3:35:53,  3.87s/it] 26%|██▋       | 1198/4545 [1:31:01<3:20:27,  3.59s/it] 26%|██▋       | 1199/4545 [1:31:05<3:11:45,  3.44s/it] 26%|██▋       | 1200/4545 [1:31:09<3:24:09,  3.66s/it]                                                       {'loss': 0.5115, 'grad_norm': 61.97114944458008, 'learning_rate': 7.919418758256274e-08, 'rewards/chosen': 1.028906226158142, 'rewards/rejected': 0.12699584662914276, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.901171863079071, 'logps/chosen': -261.8500061035156, 'logps/rejected': -147.27499389648438, 'logits/chosen': -6.425000190734863, 'logits/rejected': -6.40625, 'epoch': 0.79}
 26%|██▋       | 1200/4545 [1:31:09<3:24:09,  3.66s/it] 26%|██▋       | 1201/4545 [1:31:12<3:11:37,  3.44s/it] 26%|██▋       | 1202/4545 [1:31:15<3:18:20,  3.56s/it] 26%|██▋       | 1203/4545 [1:31:20<3:28:19,  3.74s/it] 26%|██▋       | 1204/4545 [1:31:23<3:27:26,  3.73s/it] 27%|██▋       | 1205/4545 [1:31:27<3:30:02,  3.77s/it] 27%|██▋       | 1206/4545 [1:31:30<3:21:25,  3.62s/it] 27%|██▋       | 1207/4545 [1:31:34<3:25:08,  3.69s/it] 27%|██▋       | 1208/4545 [1:31:38<3:28:52,  3.76s/it] 27%|██▋       | 1209/4545 [1:31:42<3:34:59,  3.87s/it] 27%|██▋       | 1210/4545 [1:31:46<3:35:55,  3.88s/it]                                                       {'loss': 0.4568, 'grad_norm': 39.41507339477539, 'learning_rate': 7.985468956406869e-08, 'rewards/chosen': 1.0390625, 'rewards/rejected': 0.04049072414636612, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.9986327886581421, 'logps/chosen': -225.6999969482422, 'logps/rejected': -129.875, 'logits/chosen': -6.340624809265137, 'logits/rejected': -6.759375095367432, 'epoch': 0.8}
 27%|██▋       | 1210/4545 [1:31:46<3:35:55,  3.88s/it] 27%|██▋       | 1211/4545 [1:31:50<3:36:46,  3.90s/it] 27%|██▋       | 1212/4545 [1:31:54<3:37:09,  3.91s/it] 27%|██▋       | 1213/4545 [1:31:58<3:37:23,  3.91s/it] 27%|██▋       | 1214/4545 [1:32:02<3:41:24,  3.99s/it] 27%|██▋       | 1215/4545 [1:32:31<10:31:40, 11.38s/it] 27%|██▋       | 1216/4545 [1:32:35<8:23:19,  9.07s/it]  27%|██▋       | 1217/4545 [1:32:38<6:58:04,  7.54s/it] 27%|██▋       | 1218/4545 [1:32:43<6:02:51,  6.54s/it] 27%|██▋       | 1219/4545 [1:32:47<5:19:05,  5.76s/it] 27%|██▋       | 1220/4545 [1:32:51<4:48:32,  5.21s/it]                                                       {'loss': 0.4919, 'grad_norm': 27.261310577392578, 'learning_rate': 8.051519154557463e-08, 'rewards/chosen': 1.3810546398162842, 'rewards/rejected': 0.15223999321460724, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.227929711341858, 'logps/chosen': -332.20001220703125, 'logps/rejected': -183.9250030517578, 'logits/chosen': -6.246874809265137, 'logits/rejected': -6.340624809265137, 'epoch': 0.81}
 27%|██▋       | 1220/4545 [1:32:51<4:48:32,  5.21s/it] 27%|██▋       | 1221/4545 [1:32:54<4:21:30,  4.72s/it] 27%|██▋       | 1222/4545 [1:32:58<4:02:08,  4.37s/it] 27%|██▋       | 1223/4545 [1:33:02<3:53:55,  4.23s/it] 27%|██▋       | 1224/4545 [1:33:06<3:48:40,  4.13s/it] 27%|██▋       | 1225/4545 [1:33:09<3:35:33,  3.90s/it] 27%|██▋       | 1226/4545 [1:33:13<3:36:08,  3.91s/it] 27%|██▋       | 1227/4545 [1:33:17<3:36:22,  3.91s/it] 27%|██▋       | 1228/4545 [1:33:21<3:39:33,  3.97s/it] 27%|██▋       | 1229/4545 [1:33:25<3:37:37,  3.94s/it] 27%|██▋       | 1230/4545 [1:33:28<3:31:13,  3.82s/it]                                                       {'loss': 0.4908, 'grad_norm': 38.57236099243164, 'learning_rate': 8.117569352708058e-08, 'rewards/chosen': 1.609375, 'rewards/rejected': 0.29353028535842896, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.3136718273162842, 'logps/chosen': -346.0, 'logps/rejected': -249.1999969482422, 'logits/chosen': -6.128125190734863, 'logits/rejected': -6.40625, 'epoch': 0.81}
 27%|██▋       | 1230/4545 [1:33:28<3:31:13,  3.82s/it] 27%|██▋       | 1231/4545 [1:33:32<3:33:22,  3.86s/it] 27%|██▋       | 1232/4545 [1:33:36<3:34:23,  3.88s/it] 27%|██▋       | 1233/4545 [1:33:40<3:32:42,  3.85s/it] 27%|██▋       | 1234/4545 [1:33:44<3:37:59,  3.95s/it] 27%|██▋       | 1235/4545 [1:33:47<3:21:52,  3.66s/it] 27%|██▋       | 1236/4545 [1:33:51<3:25:50,  3.73s/it] 27%|██▋       | 1237/4545 [1:33:55<3:28:44,  3.79s/it] 27%|██▋       | 1238/4545 [1:33:59<3:30:57,  3.83s/it] 27%|██▋       | 1239/4545 [1:34:03<3:33:02,  3.87s/it] 27%|██▋       | 1240/4545 [1:34:07<3:33:30,  3.88s/it]                                                       {'loss': 0.5041, 'grad_norm': 46.0181999206543, 'learning_rate': 8.183619550858652e-08, 'rewards/chosen': 1.871484398841858, 'rewards/rejected': 0.2947753965854645, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 1.575781226158142, 'logps/chosen': -430.79998779296875, 'logps/rejected': -218.4499969482422, 'logits/chosen': -6.306250095367432, 'logits/rejected': -6.381249904632568, 'epoch': 0.82}
 27%|██▋       | 1240/4545 [1:34:07<3:33:30,  3.88s/it] 27%|██▋       | 1241/4545 [1:34:11<3:34:16,  3.89s/it] 27%|██▋       | 1242/4545 [1:34:15<3:35:39,  3.92s/it] 27%|██▋       | 1243/4545 [1:34:18<3:35:25,  3.91s/it] 27%|██▋       | 1244/4545 [1:34:23<3:40:45,  4.01s/it] 27%|██▋       | 1245/4545 [1:34:27<3:39:15,  3.99s/it] 27%|██▋       | 1246/4545 [1:34:31<3:38:52,  3.98s/it] 27%|██▋       | 1247/4545 [1:34:34<3:32:21,  3.86s/it] 27%|██▋       | 1248/4545 [1:34:38<3:33:07,  3.88s/it] 27%|██▋       | 1249/4545 [1:34:42<3:36:56,  3.95s/it] 28%|██▊       | 1250/4545 [1:34:46<3:36:31,  3.94s/it]                                                       {'loss': 0.5669, 'grad_norm': 76.24896240234375, 'learning_rate': 8.249669749009247e-08, 'rewards/chosen': 0.9898437261581421, 'rewards/rejected': 0.09125976264476776, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 0.898974597454071, 'logps/chosen': -227.75, 'logps/rejected': -147.5500030517578, 'logits/chosen': -6.403124809265137, 'logits/rejected': -6.534375190734863, 'epoch': 0.83}
 28%|██▊       | 1250/4545 [1:34:46<3:36:31,  3.94s/it] 28%|██▊       | 1251/4545 [1:34:50<3:29:36,  3.82s/it] 28%|██▊       | 1252/4545 [1:34:53<3:24:41,  3.73s/it] 28%|██▊       | 1253/4545 [1:34:57<3:26:07,  3.76s/it] 28%|██▊       | 1254/4545 [1:35:01<3:27:25,  3.78s/it] 28%|██▊       | 1255/4545 [1:35:05<3:28:42,  3.81s/it] 28%|██▊       | 1256/4545 [1:35:09<3:30:32,  3.84s/it] 28%|██▊       | 1257/4545 [1:35:13<3:36:50,  3.96s/it] 28%|██▊       | 1258/4545 [1:35:17<3:41:07,  4.04s/it] 28%|██▊       | 1259/4545 [1:35:21<3:40:51,  4.03s/it] 28%|██▊       | 1260/4545 [1:35:24<3:14:25,  3.55s/it]                                                       {'loss': 0.5404, 'grad_norm': 47.740020751953125, 'learning_rate': 8.315719947159842e-08, 'rewards/chosen': 0.8804687261581421, 'rewards/rejected': 0.02700195275247097, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.8531249761581421, 'logps/chosen': -197.9499969482422, 'logps/rejected': -133.1750030517578, 'logits/chosen': -6.484375, 'logits/rejected': -6.556250095367432, 'epoch': 0.83}
 28%|██▊       | 1260/4545 [1:35:24<3:14:25,  3.55s/it] 28%|██▊       | 1261/4545 [1:35:28<3:21:32,  3.68s/it] 28%|██▊       | 1262/4545 [1:35:32<3:26:56,  3.78s/it] 28%|██▊       | 1263/4545 [1:35:35<3:25:09,  3.75s/it] 28%|██▊       | 1264/4545 [1:35:39<3:27:48,  3.80s/it] 28%|██▊       | 1265/4545 [1:35:43<3:28:47,  3.82s/it] 28%|██▊       | 1266/4545 [1:35:47<3:28:16,  3.81s/it] 28%|██▊       | 1267/4545 [1:35:50<3:13:03,  3.53s/it] 28%|██▊       | 1268/4545 [1:35:54<3:19:54,  3.66s/it] 28%|██▊       | 1269/4545 [1:35:57<3:17:38,  3.62s/it] 28%|██▊       | 1270/4545 [1:36:01<3:24:29,  3.75s/it]                                                       {'loss': 0.5054, 'grad_norm': 54.96493148803711, 'learning_rate': 8.381770145310434e-08, 'rewards/chosen': 1.2873046398162842, 'rewards/rejected': 0.14638671278953552, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.142187476158142, 'logps/chosen': -300.1000061035156, 'logps/rejected': -132.3249969482422, 'logits/chosen': -6.3125, 'logits/rejected': -6.543749809265137, 'epoch': 0.84}
 28%|██▊       | 1270/4545 [1:36:01<3:24:29,  3.75s/it] 28%|██▊       | 1271/4545 [1:36:05<3:33:10,  3.91s/it] 28%|██▊       | 1272/4545 [1:36:08<3:17:51,  3.63s/it] 28%|██▊       | 1273/4545 [1:36:12<3:22:50,  3.72s/it] 28%|██▊       | 1274/4545 [1:36:16<3:26:16,  3.78s/it] 28%|██▊       | 1275/4545 [1:36:19<3:15:26,  3.59s/it] 28%|██▊       | 1276/4545 [1:36:22<3:05:23,  3.40s/it] 28%|██▊       | 1277/4545 [1:36:26<3:13:54,  3.56s/it] 28%|██▊       | 1278/4545 [1:36:31<3:23:30,  3.74s/it] 28%|██▊       | 1279/4545 [1:36:34<3:13:07,  3.55s/it] 28%|██▊       | 1280/4545 [1:36:38<3:19:05,  3.66s/it]                                                       {'loss': 0.4251, 'grad_norm': 25.801008224487305, 'learning_rate': 8.44782034346103e-08, 'rewards/chosen': 1.644921898841858, 'rewards/rejected': 0.1474609375, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.496484398841858, 'logps/chosen': -350.8999938964844, 'logps/rejected': -179.10000610351562, 'logits/chosen': -6.224999904632568, 'logits/rejected': -6.606249809265137, 'epoch': 0.84}
 28%|██▊       | 1280/4545 [1:36:38<3:19:05,  3.66s/it] 28%|██▊       | 1281/4545 [1:36:41<3:21:26,  3.70s/it] 28%|██▊       | 1282/4545 [1:37:10<10:10:35, 11.23s/it] 28%|██▊       | 1283/4545 [1:37:13<7:55:58,  8.76s/it]  28%|██▊       | 1284/4545 [1:37:17<6:30:29,  7.18s/it] 28%|██▊       | 1285/4545 [1:37:20<5:35:05,  6.17s/it] 28%|██▊       | 1286/4545 [1:37:24<4:59:00,  5.50s/it] 28%|██▊       | 1287/4545 [1:37:28<4:33:08,  5.03s/it] 28%|██▊       | 1288/4545 [1:37:32<4:14:57,  4.70s/it] 28%|██▊       | 1289/4545 [1:37:36<4:01:59,  4.46s/it] 28%|██▊       | 1290/4545 [1:37:40<3:57:39,  4.38s/it]                                                       {'loss': 0.4793, 'grad_norm': 31.5883846282959, 'learning_rate': 8.513870541611625e-08, 'rewards/chosen': 1.485742211341858, 'rewards/rejected': -0.7887817621231079, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.272656202316284, 'logps/chosen': -340.6000061035156, 'logps/rejected': -176.77499389648438, 'logits/chosen': -6.368750095367432, 'logits/rejected': -6.471875190734863, 'epoch': 0.85}
 28%|██▊       | 1290/4545 [1:37:40<3:57:39,  4.38s/it] 28%|██▊       | 1291/4545 [1:37:44<3:53:25,  4.30s/it] 28%|██▊       | 1292/4545 [1:37:48<3:40:47,  4.07s/it] 28%|██▊       | 1293/4545 [1:37:52<3:38:22,  4.03s/it] 28%|██▊       | 1294/4545 [1:37:56<3:37:49,  4.02s/it] 28%|██▊       | 1295/4545 [1:38:00<3:35:53,  3.99s/it] 29%|██▊       | 1296/4545 [1:38:03<3:24:51,  3.78s/it] 29%|██▊       | 1297/4545 [1:38:06<3:15:51,  3.62s/it] 29%|██▊       | 1298/4545 [1:38:10<3:19:16,  3.68s/it] 29%|██▊       | 1299/4545 [1:38:13<2:58:18,  3.30s/it] 29%|██▊       | 1300/4545 [1:38:17<3:13:42,  3.58s/it]                                                       {'loss': 0.4854, 'grad_norm': 41.7280387878418, 'learning_rate': 8.579920739762218e-08, 'rewards/chosen': 1.105859398841858, 'rewards/rejected': -0.06170654296875, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.1687500476837158, 'logps/chosen': -229.39999389648438, 'logps/rejected': -88.625, 'logits/chosen': -6.496874809265137, 'logits/rejected': -6.803124904632568, 'epoch': 0.86}
 29%|██▊       | 1300/4545 [1:38:17<3:13:42,  3.58s/it] 29%|██▊       | 1301/4545 [1:38:21<3:24:44,  3.79s/it] 29%|██▊       | 1302/4545 [1:38:25<3:26:50,  3.83s/it] 29%|██▊       | 1303/4545 [1:38:28<3:17:27,  3.65s/it] 29%|██▊       | 1304/4545 [1:38:32<3:22:07,  3.74s/it] 29%|██▊       | 1305/4545 [1:38:36<3:24:43,  3.79s/it] 29%|██▊       | 1306/4545 [1:38:40<3:24:04,  3.78s/it] 29%|██▉       | 1307/4545 [1:38:44<3:30:51,  3.91s/it] 29%|██▉       | 1308/4545 [1:38:47<3:09:47,  3.52s/it] 29%|██▉       | 1309/4545 [1:38:50<3:05:58,  3.45s/it] 29%|██▉       | 1310/4545 [1:38:53<2:56:58,  3.28s/it]                                                       {'loss': 0.4712, 'grad_norm': 27.434368133544922, 'learning_rate': 8.645970937912813e-08, 'rewards/chosen': 1.085351586341858, 'rewards/rejected': -0.07871093600988388, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.1658203601837158, 'logps/chosen': -224.6999969482422, 'logps/rejected': -129.125, 'logits/chosen': -6.484375, 'logits/rejected': -6.556250095367432, 'epoch': 0.86}
 29%|██▉       | 1310/4545 [1:38:54<2:56:58,  3.28s/it] 29%|██▉       | 1311/4545 [1:38:57<3:09:10,  3.51s/it] 29%|██▉       | 1312/4545 [1:39:01<3:13:06,  3.58s/it] 29%|██▉       | 1313/4545 [1:39:03<2:59:19,  3.33s/it] 29%|██▉       | 1314/4545 [1:39:07<3:09:54,  3.53s/it] 29%|██▉       | 1315/4545 [1:39:11<3:10:32,  3.54s/it] 29%|██▉       | 1316/4545 [1:39:15<3:12:06,  3.57s/it] 29%|██▉       | 1317/4545 [1:39:19<3:20:34,  3.73s/it] 29%|██▉       | 1318/4545 [1:39:23<3:26:30,  3.84s/it] 29%|██▉       | 1319/4545 [1:39:27<3:26:31,  3.84s/it] 29%|██▉       | 1320/4545 [1:39:30<3:20:49,  3.74s/it]                                                       {'loss': 0.5148, 'grad_norm': 41.88544464111328, 'learning_rate': 8.712021136063407e-08, 'rewards/chosen': 1.123437523841858, 'rewards/rejected': 0.011309814639389515, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.1101562976837158, 'logps/chosen': -240.35000610351562, 'logps/rejected': -144.375, 'logits/chosen': -6.40625, 'logits/rejected': -6.556250095367432, 'epoch': 0.87}
 29%|██▉       | 1320/4545 [1:39:30<3:20:49,  3.74s/it] 29%|██▉       | 1321/4545 [1:39:34<3:24:50,  3.81s/it] 29%|██▉       | 1322/4545 [1:39:38<3:29:47,  3.91s/it] 29%|██▉       | 1323/4545 [1:39:42<3:20:30,  3.73s/it] 29%|██▉       | 1324/4545 [1:39:45<3:17:22,  3.68s/it] 29%|██▉       | 1325/4545 [1:39:49<3:16:01,  3.65s/it] 29%|██▉       | 1326/4545 [1:39:53<3:20:05,  3.73s/it] 29%|██▉       | 1327/4545 [1:39:56<3:13:25,  3.61s/it] 29%|██▉       | 1328/4545 [1:40:00<3:19:42,  3.72s/it] 29%|██▉       | 1329/4545 [1:40:04<3:23:00,  3.79s/it] 29%|██▉       | 1330/4545 [1:40:06<2:59:23,  3.35s/it]                                                       {'loss': 0.5244, 'grad_norm': 24.983482360839844, 'learning_rate': 8.778071334214002e-08, 'rewards/chosen': 0.87890625, 'rewards/rejected': 0.0609130859375, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.817187488079071, 'logps/chosen': -182.35000610351562, 'logps/rejected': -129.52499389648438, 'logits/chosen': -6.443749904632568, 'logits/rejected': -6.693749904632568, 'epoch': 0.88}
 29%|██▉       | 1330/4545 [1:40:06<2:59:23,  3.35s/it] 29%|██▉       | 1331/4545 [1:40:10<3:09:22,  3.54s/it] 29%|██▉       | 1332/4545 [1:40:14<3:13:04,  3.61s/it] 29%|██▉       | 1333/4545 [1:40:18<3:18:55,  3.72s/it] 29%|██▉       | 1334/4545 [1:40:22<3:22:24,  3.78s/it] 29%|██▉       | 1335/4545 [1:40:26<3:24:42,  3.83s/it] 29%|██▉       | 1336/4545 [1:40:30<3:27:15,  3.88s/it] 29%|██▉       | 1337/4545 [1:40:34<3:31:37,  3.96s/it] 29%|██▉       | 1338/4545 [1:40:38<3:25:49,  3.85s/it] 29%|██▉       | 1339/4545 [1:40:41<3:27:11,  3.88s/it] 29%|██▉       | 1340/4545 [1:40:45<3:28:06,  3.90s/it]                                                       {'loss': 0.4402, 'grad_norm': 42.49147415161133, 'learning_rate': 8.844121532364597e-08, 'rewards/chosen': 1.8386719226837158, 'rewards/rejected': 0.20595702528953552, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.6316406726837158, 'logps/chosen': -405.70001220703125, 'logps/rejected': -195.47500610351562, 'logits/chosen': -6.184374809265137, 'logits/rejected': -6.731249809265137, 'epoch': 0.88}
 29%|██▉       | 1340/4545 [1:40:45<3:28:06,  3.90s/it] 30%|██▉       | 1341/4545 [1:40:49<3:16:06,  3.67s/it] 30%|██▉       | 1342/4545 [1:40:52<3:07:33,  3.51s/it] 30%|██▉       | 1343/4545 [1:40:55<3:06:18,  3.49s/it] 30%|██▉       | 1344/4545 [1:40:59<3:16:51,  3.69s/it] 30%|██▉       | 1345/4545 [1:41:03<3:19:17,  3.74s/it] 30%|██▉       | 1346/4545 [1:41:07<3:24:57,  3.84s/it] 30%|██▉       | 1347/4545 [1:41:11<3:26:11,  3.87s/it] 30%|██▉       | 1348/4545 [1:41:15<3:26:44,  3.88s/it] 30%|██▉       | 1349/4545 [1:41:19<3:27:37,  3.90s/it] 30%|██▉       | 1350/4545 [1:41:23<3:27:52,  3.90s/it]                                                       {'loss': 0.4689, 'grad_norm': 52.32534408569336, 'learning_rate': 8.910171730515191e-08, 'rewards/chosen': 1.6941406726837158, 'rewards/rejected': 0.16617432236671448, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5265624523162842, 'logps/chosen': -383.45001220703125, 'logps/rejected': -208.14999389648438, 'logits/chosen': -6.300000190734863, 'logits/rejected': -6.543749809265137, 'epoch': 0.89}
 30%|██▉       | 1350/4545 [1:41:23<3:27:52,  3.90s/it] 30%|██▉       | 1351/4545 [1:41:27<3:33:27,  4.01s/it] 30%|██▉       | 1352/4545 [1:41:30<3:09:12,  3.56s/it] 30%|██▉       | 1353/4545 [1:41:33<3:04:53,  3.48s/it] 30%|██▉       | 1354/4545 [1:41:37<3:14:41,  3.66s/it] 30%|██▉       | 1355/4545 [1:41:41<3:19:00,  3.74s/it] 30%|██▉       | 1356/4545 [1:41:45<3:18:08,  3.73s/it] 30%|██▉       | 1357/4545 [1:41:49<3:25:18,  3.86s/it] 30%|██▉       | 1358/4545 [1:41:52<3:18:16,  3.73s/it] 30%|██▉       | 1359/4545 [1:41:56<3:21:28,  3.79s/it] 30%|██▉       | 1360/4545 [1:42:00<3:25:48,  3.88s/it]                                                       {'loss': 0.4926, 'grad_norm': 38.57218551635742, 'learning_rate': 8.976221928665786e-08, 'rewards/chosen': 1.716796875, 'rewards/rejected': 0.3125, 'rewards/accuracies': 0.75, 'rewards/margins': 1.402734398841858, 'logps/chosen': -360.25, 'logps/rejected': -192.5749969482422, 'logits/chosen': -6.368750095367432, 'logits/rejected': -6.603125095367432, 'epoch': 0.9}
 30%|██▉       | 1360/4545 [1:42:00<3:25:48,  3.88s/it] 30%|██▉       | 1361/4545 [1:42:04<3:29:22,  3.95s/it] 30%|██▉       | 1362/4545 [1:42:07<3:06:32,  3.52s/it] 30%|██▉       | 1363/4545 [1:42:11<3:12:56,  3.64s/it] 30%|███       | 1364/4545 [1:42:15<3:20:41,  3.79s/it] 30%|███       | 1365/4545 [1:42:19<3:22:32,  3.82s/it] 30%|███       | 1366/4545 [1:42:23<3:25:41,  3.88s/it] 30%|███       | 1367/4545 [1:42:26<3:12:00,  3.63s/it] 30%|███       | 1368/4545 [1:42:30<3:13:10,  3.65s/it] 30%|███       | 1369/4545 [1:42:33<3:16:20,  3.71s/it] 30%|███       | 1370/4545 [1:42:37<3:18:51,  3.76s/it]                                                       {'loss': 0.4992, 'grad_norm': 30.67422866821289, 'learning_rate': 9.042272126816381e-08, 'rewards/chosen': 1.2253906726837158, 'rewards/rejected': -0.03229980543255806, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.258398413658142, 'logps/chosen': -225.64999389648438, 'logps/rejected': -120.875, 'logits/chosen': -6.556250095367432, 'logits/rejected': -6.571875095367432, 'epoch': 0.9}
 30%|███       | 1370/4545 [1:42:37<3:18:51,  3.76s/it] 30%|███       | 1371/4545 [1:42:41<3:22:00,  3.82s/it] 30%|███       | 1372/4545 [1:42:45<3:16:03,  3.71s/it] 30%|███       | 1373/4545 [1:42:49<3:23:56,  3.86s/it] 30%|███       | 1374/4545 [1:42:51<3:01:35,  3.44s/it] 30%|███       | 1375/4545 [1:42:55<3:09:28,  3.59s/it] 30%|███       | 1376/4545 [1:42:58<2:59:44,  3.40s/it] 30%|███       | 1377/4545 [1:43:02<2:57:53,  3.37s/it] 30%|███       | 1378/4545 [1:43:05<3:00:14,  3.41s/it] 30%|███       | 1379/4545 [1:43:09<3:08:13,  3.57s/it] 30%|███       | 1380/4545 [1:43:13<3:14:00,  3.68s/it]                                                       {'loss': 0.4717, 'grad_norm': 26.931928634643555, 'learning_rate': 9.108322324966975e-08, 'rewards/chosen': 1.5031249523162842, 'rewards/rejected': 0.03278808668255806, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.4728515148162842, 'logps/chosen': -281.17498779296875, 'logps/rejected': -110.5875015258789, 'logits/chosen': -6.462500095367432, 'logits/rejected': -6.681250095367432, 'epoch': 0.91}
 30%|███       | 1380/4545 [1:43:13<3:14:00,  3.68s/it] 30%|███       | 1381/4545 [1:43:17<3:19:19,  3.78s/it] 30%|███       | 1382/4545 [1:43:21<3:16:47,  3.73s/it] 30%|███       | 1383/4545 [1:43:25<3:19:46,  3.79s/it] 30%|███       | 1384/4545 [1:43:29<3:22:38,  3.85s/it] 30%|███       | 1385/4545 [1:43:32<3:23:40,  3.87s/it] 30%|███       | 1386/4545 [1:43:37<3:28:14,  3.96s/it] 31%|███       | 1387/4545 [1:43:41<3:27:49,  3.95s/it] 31%|███       | 1388/4545 [1:43:44<3:26:16,  3.92s/it] 31%|███       | 1389/4545 [1:43:48<3:26:15,  3.92s/it] 31%|███       | 1390/4545 [1:43:52<3:26:17,  3.92s/it]                                                       {'loss': 0.4312, 'grad_norm': 32.72206497192383, 'learning_rate': 9.17437252311757e-08, 'rewards/chosen': 2.271484375, 'rewards/rejected': 0.29780274629592896, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.9714844226837158, 'logps/chosen': -459.3999938964844, 'logps/rejected': -244.35000610351562, 'logits/chosen': -6.259375095367432, 'logits/rejected': -6.553124904632568, 'epoch': 0.92}
 31%|███       | 1390/4545 [1:43:52<3:26:17,  3.92s/it] 31%|███       | 1391/4545 [1:43:56<3:27:14,  3.94s/it] 31%|███       | 1392/4545 [1:44:00<3:25:35,  3.91s/it] 31%|███       | 1393/4545 [1:44:04<3:25:25,  3.91s/it] 31%|███       | 1394/4545 [1:44:08<3:23:38,  3.88s/it] 31%|███       | 1395/4545 [1:44:12<3:22:37,  3.86s/it] 31%|███       | 1396/4545 [1:44:16<3:23:37,  3.88s/it] 31%|███       | 1397/4545 [1:44:20<3:24:50,  3.90s/it] 31%|███       | 1398/4545 [1:44:24<3:27:29,  3.96s/it] 31%|███       | 1399/4545 [1:44:27<3:23:26,  3.88s/it] 31%|███       | 1400/4545 [1:44:31<3:27:37,  3.96s/it]                                                       {'loss': 0.5054, 'grad_norm': 30.290117263793945, 'learning_rate': 9.240422721268162e-08, 'rewards/chosen': 1.3718750476837158, 'rewards/rejected': 0.05991210788488388, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.3126952648162842, 'logps/chosen': -234.0500030517578, 'logps/rejected': -110.625, 'logits/chosen': -6.515625, 'logits/rejected': -6.759375095367432, 'epoch': 0.92}
 31%|███       | 1400/4545 [1:44:32<3:27:37,  3.96s/it] 31%|███       | 1401/4545 [1:44:35<3:22:31,  3.87s/it] 31%|███       | 1402/4545 [1:44:39<3:22:58,  3.87s/it] 31%|███       | 1403/4545 [1:44:42<3:16:52,  3.76s/it] 31%|███       | 1404/4545 [1:44:46<3:19:08,  3.80s/it] 31%|███       | 1405/4545 [1:44:50<3:20:39,  3.83s/it] 31%|███       | 1406/4545 [1:44:54<3:26:39,  3.95s/it] 31%|███       | 1407/4545 [1:44:58<3:22:01,  3.86s/it] 31%|███       | 1408/4545 [1:45:02<3:22:40,  3.88s/it] 31%|███       | 1409/4545 [1:45:06<3:16:37,  3.76s/it] 31%|███       | 1410/4545 [1:45:09<3:09:00,  3.62s/it]                                                       {'loss': 0.4349, 'grad_norm': 36.227447509765625, 'learning_rate': 9.306472919418757e-08, 'rewards/chosen': 1.045312523841858, 'rewards/rejected': -0.22501221299171448, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.2687499523162842, 'logps/chosen': -178.4499969482422, 'logps/rejected': -89.0999984741211, 'logits/chosen': -6.59375, 'logits/rejected': -6.8125, 'epoch': 0.93}
 31%|███       | 1410/4545 [1:45:09<3:09:00,  3.62s/it] 31%|███       | 1411/4545 [1:45:12<3:04:35,  3.53s/it] 31%|███       | 1412/4545 [1:45:16<3:10:58,  3.66s/it] 31%|███       | 1413/4545 [1:45:20<3:07:40,  3.60s/it] 31%|███       | 1414/4545 [1:45:23<3:03:04,  3.51s/it] 31%|███       | 1415/4545 [1:45:27<3:09:21,  3.63s/it] 31%|███       | 1416/4545 [1:45:31<3:16:17,  3.76s/it] 31%|███       | 1417/4545 [1:45:34<3:09:32,  3.64s/it] 31%|███       | 1418/4545 [1:45:37<3:01:07,  3.48s/it] 31%|███       | 1419/4545 [1:45:41<3:08:15,  3.61s/it] 31%|███       | 1420/4545 [1:45:44<2:51:28,  3.29s/it]                                                       {'loss': 0.4626, 'grad_norm': 33.003421783447266, 'learning_rate': 9.372523117569352e-08, 'rewards/chosen': 1.1447265148162842, 'rewards/rejected': 0.06718750298023224, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.077734351158142, 'logps/chosen': -232.9499969482422, 'logps/rejected': -140.9499969482422, 'logits/chosen': -6.568749904632568, 'logits/rejected': -6.553124904632568, 'epoch': 0.94}
 31%|███       | 1420/4545 [1:45:44<2:51:28,  3.29s/it] 31%|███▏      | 1421/4545 [1:45:48<3:03:14,  3.52s/it] 31%|███▏      | 1422/4545 [1:45:52<3:08:01,  3.61s/it] 31%|███▏      | 1423/4545 [1:45:55<3:09:17,  3.64s/it] 31%|███▏      | 1424/4545 [1:45:59<3:14:27,  3.74s/it] 31%|███▏      | 1425/4545 [1:46:02<3:05:16,  3.56s/it] 31%|███▏      | 1426/4545 [1:46:06<3:10:46,  3.67s/it] 31%|███▏      | 1427/4545 [1:46:10<3:13:20,  3.72s/it] 31%|███▏      | 1428/4545 [1:46:14<3:16:46,  3.79s/it] 31%|███▏      | 1429/4545 [1:46:17<3:02:12,  3.51s/it] 31%|███▏      | 1430/4545 [1:46:20<2:48:27,  3.24s/it]                                                       {'loss': 0.4866, 'grad_norm': 46.78006362915039, 'learning_rate': 9.438573315719946e-08, 'rewards/chosen': 1.11083984375, 'rewards/rejected': 4.272460864740424e-05, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.1124999523162842, 'logps/chosen': -205.89999389648438, 'logps/rejected': -157.14999389648438, 'logits/chosen': -6.534375190734863, 'logits/rejected': -6.587500095367432, 'epoch': 0.94}
 31%|███▏      | 1430/4545 [1:46:20<2:48:27,  3.24s/it] 31%|███▏      | 1431/4545 [1:46:24<3:00:50,  3.48s/it] 32%|███▏      | 1432/4545 [1:46:28<3:07:39,  3.62s/it] 32%|███▏      | 1433/4545 [1:46:32<3:12:18,  3.71s/it] 32%|███▏      | 1434/4545 [1:46:35<3:15:25,  3.77s/it] 32%|███▏      | 1435/4545 [1:46:40<3:22:36,  3.91s/it] 32%|███▏      | 1436/4545 [1:46:44<3:22:32,  3.91s/it] 32%|███▏      | 1437/4545 [1:46:48<3:23:16,  3.92s/it] 32%|███▏      | 1438/4545 [1:46:51<3:21:46,  3.90s/it] 32%|███▏      | 1439/4545 [1:46:56<3:25:23,  3.97s/it] 32%|███▏      | 1440/4545 [1:46:58<3:06:50,  3.61s/it]                                                       {'loss': 0.4512, 'grad_norm': 34.185394287109375, 'learning_rate': 9.504623513870541e-08, 'rewards/chosen': 1.4861328601837158, 'rewards/rejected': 0.02656250074505806, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.462304711341858, 'logps/chosen': -288.95001220703125, 'logps/rejected': -149.22500610351562, 'logits/chosen': -6.425000190734863, 'logits/rejected': -6.603125095367432, 'epoch': 0.95}
 32%|███▏      | 1440/4545 [1:46:58<3:06:50,  3.61s/it] 32%|███▏      | 1441/4545 [1:47:02<3:05:15,  3.58s/it] 32%|███▏      | 1442/4545 [1:47:06<3:11:15,  3.70s/it] 32%|███▏      | 1443/4545 [1:47:10<3:15:42,  3.79s/it] 32%|███▏      | 1444/4545 [1:47:14<3:18:32,  3.84s/it] 32%|███▏      | 1445/4545 [1:47:17<3:13:21,  3.74s/it] 32%|███▏      | 1446/4545 [1:47:21<3:05:42,  3.60s/it] 32%|███▏      | 1447/4545 [1:47:23<2:41:00,  3.12s/it] 32%|███▏      | 1448/4545 [1:47:26<2:53:24,  3.36s/it] 32%|███▏      | 1449/4545 [1:47:30<2:49:40,  3.29s/it] 32%|███▏      | 1450/4545 [1:47:34<3:00:32,  3.50s/it]                                                       {'loss': 0.3958, 'grad_norm': 30.698888778686523, 'learning_rate': 9.570673712021135e-08, 'rewards/chosen': 1.669921875, 'rewards/rejected': 0.04990234225988388, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 1.6218750476837158, 'logps/chosen': -307.8999938964844, 'logps/rejected': -181.875, 'logits/chosen': -6.365624904632568, 'logits/rejected': -6.584374904632568, 'epoch': 0.96}
 32%|███▏      | 1450/4545 [1:47:34<3:00:32,  3.50s/it] 32%|███▏      | 1451/4545 [1:47:36<2:45:05,  3.20s/it] 32%|███▏      | 1452/4545 [1:47:38<2:32:14,  2.95s/it] 32%|███▏      | 1453/4545 [1:47:42<2:35:32,  3.02s/it] 32%|███▏      | 1454/4545 [1:47:45<2:45:57,  3.22s/it] 32%|███▏      | 1455/4545 [1:47:49<2:57:52,  3.45s/it] 32%|███▏      | 1456/4545 [1:47:53<2:56:14,  3.42s/it] 32%|███▏      | 1457/4545 [1:47:57<3:03:43,  3.57s/it] 32%|███▏      | 1458/4545 [1:48:00<2:56:56,  3.44s/it] 32%|███▏      | 1459/4545 [1:48:04<3:04:16,  3.58s/it] 32%|███▏      | 1460/4545 [1:48:08<3:09:20,  3.68s/it]                                                       {'loss': 0.4939, 'grad_norm': 44.27630615234375, 'learning_rate': 9.63672391017173e-08, 'rewards/chosen': 1.280664086341858, 'rewards/rejected': 0.0018554687267169356, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.2770507335662842, 'logps/chosen': -244.6999969482422, 'logps/rejected': -150.85000610351562, 'logits/chosen': -6.481249809265137, 'logits/rejected': -6.740624904632568, 'epoch': 0.96}
 32%|███▏      | 1460/4545 [1:48:08<3:09:20,  3.68s/it] 32%|███▏      | 1461/4545 [1:48:12<3:17:30,  3.84s/it] 32%|███▏      | 1462/4545 [1:48:15<3:12:49,  3.75s/it] 32%|███▏      | 1463/4545 [1:48:19<3:13:25,  3.77s/it] 32%|███▏      | 1464/4545 [1:48:23<3:16:12,  3.82s/it] 32%|███▏      | 1465/4545 [1:48:27<3:13:50,  3.78s/it] 32%|███▏      | 1466/4545 [1:48:30<3:12:58,  3.76s/it] 32%|███▏      | 1467/4545 [1:48:34<3:15:24,  3.81s/it] 32%|███▏      | 1468/4545 [1:48:39<3:21:43,  3.93s/it] 32%|███▏      | 1469/4545 [1:48:42<3:18:46,  3.88s/it] 32%|███▏      | 1470/4545 [1:48:46<3:18:21,  3.87s/it]                                                       {'loss': 0.4962, 'grad_norm': 39.67750549316406, 'learning_rate': 9.702774108322325e-08, 'rewards/chosen': 1.0857422351837158, 'rewards/rejected': -0.02398986741900444, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.108300805091858, 'logps/chosen': -205.10000610351562, 'logps/rejected': -133.1999969482422, 'logits/chosen': -6.487500190734863, 'logits/rejected': -6.678124904632568, 'epoch': 0.97}
 32%|███▏      | 1470/4545 [1:48:46<3:18:21,  3.87s/it] 32%|███▏      | 1471/4545 [1:48:50<3:21:03,  3.92s/it] 32%|███▏      | 1472/4545 [1:48:54<3:24:42,  4.00s/it] 32%|███▏      | 1473/4545 [1:48:58<3:15:52,  3.83s/it] 32%|███▏      | 1474/4545 [1:49:01<3:05:18,  3.62s/it] 32%|███▏      | 1475/4545 [1:49:04<3:03:19,  3.58s/it] 32%|███▏      | 1476/4545 [1:49:09<3:12:43,  3.77s/it] 32%|███▏      | 1477/4545 [1:49:13<3:16:19,  3.84s/it] 33%|███▎      | 1478/4545 [1:49:16<3:05:23,  3.63s/it] 33%|███▎      | 1479/4545 [1:49:45<9:31:33, 11.19s/it] 33%|███▎      | 1480/4545 [1:49:48<7:36:19,  8.93s/it]                                                       {'loss': 0.4247, 'grad_norm': 50.97895812988281, 'learning_rate': 9.768824306472919e-08, 'rewards/chosen': 2.052929639816284, 'rewards/rejected': 0.07172851264476776, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.9832031726837158, 'logps/chosen': -385.04998779296875, 'logps/rejected': -183.14999389648438, 'logits/chosen': -6.53125, 'logits/rejected': -6.759375095367432, 'epoch': 0.98}
 33%|███▎      | 1480/4545 [1:49:49<7:36:19,  8.93s/it] 33%|███▎      | 1481/4545 [1:49:52<6:20:50,  7.46s/it] 33%|███▎      | 1482/4545 [1:49:55<5:04:08,  5.96s/it] 33%|███▎      | 1483/4545 [1:49:59<4:32:33,  5.34s/it] 33%|███▎      | 1484/4545 [1:50:03<4:15:19,  5.00s/it] 33%|███▎      | 1485/4545 [1:50:07<3:58:54,  4.68s/it] 33%|███▎      | 1486/4545 [1:50:11<3:47:05,  4.45s/it] 33%|███▎      | 1487/4545 [1:50:14<3:36:01,  4.24s/it] 33%|███▎      | 1488/4545 [1:50:18<3:23:31,  3.99s/it] 33%|███▎      | 1489/4545 [1:50:22<3:24:38,  4.02s/it] 33%|███▎      | 1490/4545 [1:50:26<3:26:37,  4.06s/it]                                                       {'loss': 0.4485, 'grad_norm': 32.532081604003906, 'learning_rate': 9.834874504623514e-08, 'rewards/chosen': 1.6179687976837158, 'rewards/rejected': 0.00201416015625, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.617578148841858, 'logps/chosen': -291.8500061035156, 'logps/rejected': -137.6750030517578, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.559374809265137, 'epoch': 0.98}
 33%|███▎      | 1490/4545 [1:50:26<3:26:37,  4.06s/it] 33%|███▎      | 1491/4545 [1:50:30<3:25:29,  4.04s/it] 33%|███▎      | 1492/4545 [1:50:34<3:28:28,  4.10s/it] 33%|███▎      | 1493/4545 [1:50:37<3:06:15,  3.66s/it] 33%|███▎      | 1494/4545 [1:50:40<3:01:40,  3.57s/it] 33%|███▎      | 1495/4545 [1:50:44<3:05:33,  3.65s/it] 33%|███▎      | 1496/4545 [1:50:48<3:00:29,  3.55s/it] 33%|███▎      | 1497/4545 [1:50:51<3:05:21,  3.65s/it] 33%|███▎      | 1498/4545 [1:50:54<2:55:44,  3.46s/it] 33%|███▎      | 1499/4545 [1:50:59<3:07:44,  3.70s/it] 33%|███▎      | 1500/4545 [1:51:03<3:15:12,  3.85s/it]                                                       {'loss': 0.4578, 'grad_norm': 38.772708892822266, 'learning_rate': 9.900924702774109e-08, 'rewards/chosen': 1.2804687023162842, 'rewards/rejected': -0.1229248046875, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.399804711341858, 'logps/chosen': -226.4499969482422, 'logps/rejected': -101.4000015258789, 'logits/chosen': -6.634375095367432, 'logits/rejected': -6.75, 'epoch': 0.99}
 33%|███▎      | 1500/4545 [1:51:03<3:15:12,  3.85s/it] 33%|███▎      | 1501/4545 [1:51:07<3:16:47,  3.88s/it] 33%|███▎      | 1502/4545 [1:51:11<3:17:20,  3.89s/it] 33%|███▎      | 1503/4545 [1:51:14<3:11:58,  3.79s/it] 33%|███▎      | 1504/4545 [1:51:18<3:14:13,  3.83s/it] 33%|███▎      | 1505/4545 [1:51:22<3:15:45,  3.86s/it] 33%|███▎      | 1506/4545 [1:51:26<3:14:33,  3.84s/it] 33%|███▎      | 1507/4545 [1:51:29<3:07:50,  3.71s/it] 33%|███▎      | 1508/4545 [1:51:32<2:56:19,  3.48s/it] 33%|███▎      | 1509/4545 [1:51:36<3:04:10,  3.64s/it] 33%|███▎      | 1510/4545 [1:51:40<3:12:01,  3.80s/it]                                                       {'loss': 0.4616, 'grad_norm': 45.47323989868164, 'learning_rate': 9.966974900924703e-08, 'rewards/chosen': 2.112109422683716, 'rewards/rejected': 0.402099609375, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.7097656726837158, 'logps/chosen': -403.8999938964844, 'logps/rejected': -187.125, 'logits/chosen': -6.224999904632568, 'logits/rejected': -6.462500095367432, 'epoch': 1.0}
 33%|███▎      | 1510/4545 [1:51:41<3:12:01,  3.80s/it] 33%|███▎      | 1511/4545 [1:51:44<3:14:12,  3.84s/it] 33%|███▎      | 1512/4545 [1:51:48<3:15:16,  3.86s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:43,  1.32it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:22,  1.55s/it][A
 13%|█▎        | 8/60 [00:11<01:23,  1.60s/it][A
 15%|█▌        | 9/60 [00:13<01:22,  1.62s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.61s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:18<01:19,  1.65s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.64s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.64s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.53s/it][A
 27%|██▋       | 16/60 [00:49<06:43,  9.18s/it][A
 28%|██▊       | 17/60 [00:50<04:49,  6.74s/it][A
 30%|███       | 18/60 [00:51<03:25,  4.90s/it][A
 32%|███▏      | 19/60 [00:52<02:36,  3.81s/it][A
 33%|███▎      | 20/60 [00:53<01:54,  2.86s/it][A
 35%|███▌      | 21/60 [00:54<01:29,  2.30s/it][A
 37%|███▋      | 22/60 [00:55<01:16,  2.00s/it][A
 38%|███▊      | 23/60 [00:56<01:04,  1.74s/it][A
 40%|████      | 24/60 [00:58<00:57,  1.60s/it][A
 42%|████▏     | 25/60 [00:59<00:56,  1.62s/it][A
 43%|████▎     | 26/60 [01:01<00:53,  1.56s/it][A
 45%|████▌     | 27/60 [01:01<00:43,  1.33s/it][A
 47%|████▋     | 28/60 [01:02<00:38,  1.21s/it][A
 48%|████▊     | 29/60 [01:03<00:37,  1.21s/it][A
 50%|█████     | 30/60 [01:05<00:40,  1.34s/it][A
 52%|█████▏    | 31/60 [01:07<00:40,  1.41s/it][A
 53%|█████▎    | 32/60 [01:08<00:39,  1.42s/it][A
 55%|█████▌    | 33/60 [01:09<00:37,  1.39s/it][A
 57%|█████▋    | 34/60 [01:10<00:31,  1.22s/it][A
 58%|█████▊    | 35/60 [01:12<00:32,  1.28s/it][A
 60%|██████    | 36/60 [01:13<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [01:14<00:29,  1.27s/it][A
 63%|██████▎   | 38/60 [01:16<00:29,  1.36s/it][A
 65%|██████▌   | 39/60 [01:17<00:27,  1.30s/it][A
 67%|██████▋   | 40/60 [01:18<00:22,  1.14s/it][A
 68%|██████▊   | 41/60 [01:19<00:23,  1.24s/it][A
 70%|███████   | 42/60 [01:21<00:24,  1.34s/it][A
 72%|███████▏  | 43/60 [01:22<00:20,  1.23s/it][A
 73%|███████▎  | 44/60 [01:23<00:20,  1.30s/it][A
 75%|███████▌  | 45/60 [01:24<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [01:26<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:27<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:28<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:30<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:31<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:33<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:34<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:35<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:37<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:37<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:39<00:05,  1.32s/it][A
 95%|█████████▌| 57/60 [01:41<00:04,  1.40s/it][A
 97%|█████████▋| 58/60 [01:42<00:02,  1.39s/it][A
 98%|█████████▊| 59/60 [01:44<00:01,  1.45s/it][A
100%|██████████| 60/60 [01:45<00:00,  1.51s/it][A                                                       
                                               [A{'eval_loss': 0.395484060049057, 'eval_runtime': 107.4971, 'eval_samples_per_second': 8.865, 'eval_steps_per_second': 0.558, 'eval_rewards/chosen': 1.8202474117279053, 'eval_rewards/rejected': 0.2204509675502777, 'eval_rewards/accuracies': 0.8582175970077515, 'eval_rewards/margins': 1.5995036363601685, 'eval_logps/chosen': -368.5833435058594, 'eval_logps/rejected': -150.93540954589844, 'eval_logits/chosen': -6.207291603088379, 'eval_logits/rejected': -7.005208492279053, 'epoch': 1.0}
 33%|███▎      | 1512/4545 [1:53:36<3:15:16,  3.86s/it]
100%|██████████| 60/60 [01:45<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 33%|███▎      | 1513/4545 [1:53:55<34:09:22, 40.56s/it] 33%|███▎      | 1514/4545 [1:53:59<24:57:36, 29.65s/it] 33%|███▎      | 1515/4545 [1:54:03<18:27:26, 21.93s/it] 33%|███▎      | 1516/4545 [1:54:07<13:54:31, 16.53s/it] 33%|███▎      | 1517/4545 [1:54:10<10:29:00, 12.46s/it] 33%|███▎      | 1518/4545 [1:54:39<14:46:23, 17.57s/it] 33%|███▎      | 1519/4545 [1:54:43<11:19:27, 13.47s/it] 33%|███▎      | 1520/4545 [1:54:47<8:57:29, 10.66s/it]                                                        {'loss': 0.425, 'grad_norm': 28.043914794921875, 'learning_rate': 9.999939570440647e-08, 'rewards/chosen': 2.7681641578674316, 'rewards/rejected': 0.15131835639476776, 'rewards/accuracies': 0.810416579246521, 'rewards/margins': 2.617968797683716, 'logps/chosen': -589.9000244140625, 'logps/rejected': -194.9499969482422, 'logits/chosen': -6.112500190734863, 'logits/rejected': -6.493750095367432, 'epoch': 1.0}
 33%|███▎      | 1520/4545 [1:54:47<8:57:29, 10.66s/it] 33%|███▎      | 1521/4545 [1:54:51<7:23:00,  8.79s/it] 33%|███▎      | 1522/4545 [1:54:55<6:09:38,  7.34s/it] 34%|███▎      | 1523/4545 [1:54:59<5:18:48,  6.33s/it] 34%|███▎      | 1524/4545 [1:55:03<4:42:22,  5.61s/it] 34%|███▎      | 1525/4545 [1:55:07<4:16:37,  5.10s/it] 34%|███▎      | 1526/4545 [1:55:11<3:59:16,  4.76s/it] 34%|███▎      | 1527/4545 [1:55:40<9:58:51, 11.91s/it] 34%|███▎      | 1528/4545 [1:55:44<7:58:08,  9.51s/it] 34%|███▎      | 1529/4545 [1:55:47<6:25:21,  7.67s/it] 34%|███▎      | 1530/4545 [1:55:50<5:11:25,  6.20s/it]                                                       {'loss': 0.4552, 'grad_norm': 44.95671081542969, 'learning_rate': 9.999456143703726e-08, 'rewards/chosen': 2.2529296875, 'rewards/rejected': 0.10767821967601776, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.149218797683716, 'logps/chosen': -462.6000061035156, 'logps/rejected': -195.8000030517578, 'logits/chosen': -6.375, 'logits/rejected': -6.462500095367432, 'epoch': 1.01}
 34%|███▎      | 1530/4545 [1:55:50<5:11:25,  6.20s/it] 34%|███▎      | 1531/4545 [1:55:54<4:39:27,  5.56s/it] 34%|███▎      | 1532/4545 [1:55:57<4:06:29,  4.91s/it] 34%|███▎      | 1533/4545 [1:56:02<3:56:11,  4.71s/it] 34%|███▍      | 1534/4545 [1:56:05<3:44:27,  4.47s/it] 34%|███▍      | 1535/4545 [1:56:08<3:20:39,  4.00s/it] 34%|███▍      | 1536/4545 [1:56:11<2:53:20,  3.46s/it] 34%|███▍      | 1537/4545 [1:56:15<3:02:06,  3.63s/it] 34%|███▍      | 1538/4545 [1:56:18<2:55:29,  3.50s/it] 34%|███▍      | 1539/4545 [1:56:21<2:57:04,  3.53s/it] 34%|███▍      | 1540/4545 [1:56:25<3:02:51,  3.65s/it]                                                       {'loss': 0.3954, 'grad_norm': 29.653369903564453, 'learning_rate': 9.998489342164231e-08, 'rewards/chosen': 1.509765625, 'rewards/rejected': -0.11416015774011612, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.625, 'logps/chosen': -258.57501220703125, 'logps/rejected': -151.5, 'logits/chosen': -6.615624904632568, 'logits/rejected': -6.956250190734863, 'epoch': 1.02}
 34%|███▍      | 1540/4545 [1:56:25<3:02:51,  3.65s/it] 34%|███▍      | 1541/4545 [1:56:29<3:07:26,  3.74s/it] 34%|███▍      | 1542/4545 [1:56:33<3:10:00,  3.80s/it] 34%|███▍      | 1543/4545 [1:57:05<10:16:39, 12.32s/it] 34%|███▍      | 1544/4545 [1:57:13<9:02:12, 10.84s/it]  34%|███▍      | 1545/4545 [1:57:20<8:11:42,  9.83s/it] 34%|███▍      | 1546/4545 [1:57:28<7:34:53,  9.10s/it] 34%|███▍      | 1547/4545 [1:57:35<7:09:28,  8.60s/it] 34%|███▍      | 1548/4545 [1:57:43<6:57:31,  8.36s/it] 34%|███▍      | 1549/4545 [1:57:50<6:41:09,  8.03s/it] 34%|███▍      | 1550/4545 [1:57:58<6:33:55,  7.89s/it]                                                       {'loss': 0.3838, 'grad_norm': 32.65476608276367, 'learning_rate': 9.99703926968527e-08, 'rewards/chosen': 1.803125023841858, 'rewards/rejected': 0.04931640625, 'rewards/accuracies': 0.875, 'rewards/margins': 1.754296898841858, 'logps/chosen': -314.8500061035156, 'logps/rejected': -169.27499389648438, 'logits/chosen': -6.474999904632568, 'logits/rejected': -6.653124809265137, 'epoch': 1.02}
 34%|███▍      | 1550/4545 [1:57:58<6:33:55,  7.89s/it] 34%|███▍      | 1551/4545 [1:58:06<6:34:20,  7.90s/it] 34%|███▍      | 1552/4545 [1:58:13<6:19:44,  7.61s/it] 34%|███▍      | 1553/4545 [1:58:19<6:03:13,  7.28s/it] 34%|███▍      | 1554/4545 [1:58:27<6:06:22,  7.35s/it] 34%|███▍      | 1555/4545 [1:58:34<6:07:09,  7.37s/it] 34%|███▍      | 1556/4545 [1:58:41<6:08:53,  7.41s/it] 34%|███▍      | 1557/4545 [1:58:49<6:15:43,  7.54s/it] 34%|███▍      | 1558/4545 [1:59:31<14:39:52, 17.67s/it] 34%|███▍      | 1559/4545 [1:59:47<14:20:34, 17.29s/it] 34%|███▍      | 1560/4545 [2:00:04<14:11:18, 17.11s/it]                                                        {'loss': 0.3937, 'grad_norm': 31.494064331054688, 'learning_rate': 9.995106082047558e-08, 'rewards/chosen': 1.9910156726837158, 'rewards/rejected': 0.14638671278953552, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.8445312976837158, 'logps/chosen': -359.75, 'logps/rejected': -194.52499389648438, 'logits/chosen': -6.412499904632568, 'logits/rejected': -6.646874904632568, 'epoch': 1.03}
 34%|███▍      | 1560/4545 [2:00:04<14:11:18, 17.11s/it] 34%|███▍      | 1561/4545 [2:00:46<20:28:41, 24.71s/it] 34%|███▍      | 1562/4545 [2:01:04<18:42:51, 22.59s/it] 34%|███▍      | 1563/4545 [2:01:21<17:25:51, 21.04s/it] 34%|███▍      | 1564/4545 [2:01:37<16:11:54, 19.56s/it] 34%|███▍      | 1565/4545 [2:01:55<15:39:33, 18.92s/it] 34%|███▍      | 1566/4545 [2:02:12<15:12:11, 18.37s/it] 34%|███▍      | 1567/4545 [2:02:29<14:52:54, 17.99s/it] 34%|███▍      | 1568/4545 [2:02:46<14:36:54, 17.67s/it] 35%|███▍      | 1569/4545 [2:03:03<14:21:44, 17.37s/it] 35%|███▍      | 1570/4545 [2:03:19<14:04:00, 17.02s/it]                                                        {'loss': 0.4958, 'grad_norm': 58.484947204589844, 'learning_rate': 9.992689986932682e-08, 'rewards/chosen': 1.5173828601837158, 'rewards/rejected': 0.04753417894244194, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.4714844226837158, 'logps/chosen': -295.3500061035156, 'logps/rejected': -158.0500030517578, 'logits/chosen': -6.625, 'logits/rejected': -6.671875, 'epoch': 1.04}
 35%|███▍      | 1570/4545 [2:03:19<14:04:00, 17.02s/it] 35%|███▍      | 1571/4545 [2:03:36<14:01:00, 16.97s/it] 35%|███▍      | 1572/4545 [2:03:53<14:03:04, 17.01s/it] 35%|███▍      | 1573/4545 [2:03:57<10:49:31, 13.11s/it] 35%|███▍      | 1574/4545 [2:04:00<8:20:57, 10.12s/it]  35%|███▍      | 1575/4545 [2:04:03<6:36:14,  8.00s/it] 35%|███▍      | 1576/4545 [2:04:06<5:27:12,  6.61s/it] 35%|███▍      | 1577/4545 [2:04:09<4:35:23,  5.57s/it] 35%|███▍      | 1578/4545 [2:04:13<4:11:04,  5.08s/it] 35%|███▍      | 1579/4545 [2:04:17<3:45:41,  4.57s/it] 35%|███▍      | 1580/4545 [2:04:21<3:38:07,  4.41s/it]                                                       {'loss': 0.4131, 'grad_norm': 31.335559844970703, 'learning_rate': 9.98979124390079e-08, 'rewards/chosen': 1.0693359375, 'rewards/rejected': -0.2997070252895355, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 1.373046875, 'logps/chosen': -187.10000610351562, 'logps/rejected': -94.94999694824219, 'logits/chosen': -6.809374809265137, 'logits/rejected': -6.900000095367432, 'epoch': 1.04}
 35%|███▍      | 1580/4545 [2:04:21<3:38:07,  4.41s/it] 35%|███▍      | 1581/4545 [2:04:24<3:14:38,  3.94s/it] 35%|███▍      | 1582/4545 [2:04:27<3:10:14,  3.85s/it] 35%|███▍      | 1583/4545 [2:04:31<3:12:33,  3.90s/it] 35%|███▍      | 1584/4545 [2:04:36<3:17:14,  4.00s/it] 35%|███▍      | 1585/4545 [2:04:39<3:15:47,  3.97s/it] 35%|███▍      | 1586/4545 [2:04:42<2:49:40,  3.44s/it] 35%|███▍      | 1587/4545 [2:04:46<3:01:17,  3.68s/it] 35%|███▍      | 1588/4545 [2:04:50<3:07:29,  3.80s/it] 35%|███▍      | 1589/4545 [2:04:54<3:12:17,  3.90s/it] 35%|███▍      | 1590/4545 [2:04:58<3:06:23,  3.78s/it]                                                       {'loss': 0.3749, 'grad_norm': 25.43288230895996, 'learning_rate': 9.986410164362702e-08, 'rewards/chosen': 1.016992211341858, 'rewards/rejected': -0.36998289823532104, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.3878905773162842, 'logps/chosen': -172.0, 'logps/rejected': -89.7249984741211, 'logits/chosen': -6.628125190734863, 'logits/rejected': -6.881249904632568, 'epoch': 1.05}
 35%|███▍      | 1590/4545 [2:04:58<3:06:23,  3.78s/it] 35%|███▌      | 1591/4545 [2:05:02<3:09:31,  3.85s/it] 35%|███▌      | 1592/4545 [2:05:05<3:00:25,  3.67s/it] 35%|███▌      | 1593/4545 [2:05:09<3:04:46,  3.76s/it] 35%|███▌      | 1594/4545 [2:05:12<2:53:39,  3.53s/it] 35%|███▌      | 1595/4545 [2:05:15<2:42:55,  3.31s/it] 35%|███▌      | 1596/4545 [2:05:19<2:53:14,  3.52s/it] 35%|███▌      | 1597/4545 [2:05:22<2:54:24,  3.55s/it] 35%|███▌      | 1598/4545 [2:05:26<2:59:43,  3.66s/it] 35%|███▌      | 1599/4545 [2:05:30<3:07:29,  3.82s/it] 35%|███▌      | 1600/4545 [2:05:35<3:13:39,  3.95s/it]                                                       {'loss': 0.4232, 'grad_norm': 30.770015716552734, 'learning_rate': 9.982547111546467e-08, 'rewards/chosen': 1.4064452648162842, 'rewards/rejected': -0.2744140625, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.679296851158142, 'logps/chosen': -234.1999969482422, 'logps/rejected': -144.375, 'logits/chosen': -6.815625190734863, 'logits/rejected': -6.612500190734863, 'epoch': 1.06}
 35%|███▌      | 1600/4545 [2:05:35<3:13:39,  3.95s/it] 35%|███▌      | 1601/4545 [2:05:38<3:09:52,  3.87s/it] 35%|███▌      | 1602/4545 [2:05:42<3:10:33,  3.89s/it] 35%|███▌      | 1603/4545 [2:05:46<3:13:51,  3.95s/it] 35%|███▌      | 1604/4545 [2:05:51<3:17:29,  4.03s/it] 35%|███▌      | 1605/4545 [2:05:54<3:09:11,  3.86s/it] 35%|███▌      | 1606/4545 [2:05:58<3:12:44,  3.93s/it] 35%|███▌      | 1607/4545 [2:06:02<3:12:38,  3.93s/it] 35%|███▌      | 1608/4545 [2:06:06<3:12:16,  3.93s/it] 35%|███▌      | 1609/4545 [2:06:09<2:55:19,  3.58s/it] 35%|███▌      | 1610/4545 [2:06:12<2:51:38,  3.51s/it]                                                       {'loss': 0.4097, 'grad_norm': 43.33842849731445, 'learning_rate': 9.978202500458325e-08, 'rewards/chosen': 2.1392579078674316, 'rewards/rejected': -0.10126952826976776, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.241015672683716, 'logps/chosen': -369.45001220703125, 'logps/rejected': -164.97500610351562, 'logits/chosen': -6.337500095367432, 'logits/rejected': -6.493750095367432, 'epoch': 1.06}
 35%|███▌      | 1610/4545 [2:06:12<2:51:38,  3.51s/it] 35%|███▌      | 1611/4545 [2:06:16<3:00:48,  3.70s/it] 35%|███▌      | 1612/4545 [2:06:20<3:06:52,  3.82s/it] 35%|███▌      | 1613/4545 [2:06:24<3:02:31,  3.74s/it] 36%|███▌      | 1614/4545 [2:06:28<3:05:57,  3.81s/it] 36%|███▌      | 1615/4545 [2:06:32<3:07:33,  3.84s/it] 36%|███▌      | 1616/4545 [2:06:34<2:49:04,  3.46s/it] 36%|███▌      | 1617/4545 [2:06:38<2:55:53,  3.60s/it] 36%|███▌      | 1618/4545 [2:06:42<3:01:45,  3.73s/it] 36%|███▌      | 1619/4545 [2:06:46<3:01:12,  3.72s/it] 36%|███▌      | 1620/4545 [2:06:50<2:58:31,  3.66s/it]                                                       {'loss': 0.3793, 'grad_norm': 44.6746826171875, 'learning_rate': 9.973376797838135e-08, 'rewards/chosen': 2.2119140625, 'rewards/rejected': 0.19755859673023224, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.0140624046325684, 'logps/chosen': -390.6000061035156, 'logps/rejected': -224.25, 'logits/chosen': -6.334374904632568, 'logits/rejected': -6.584374904632568, 'epoch': 1.07}
 36%|███▌      | 1620/4545 [2:06:50<2:58:31,  3.66s/it] 36%|███▌      | 1621/4545 [2:06:54<3:08:22,  3.87s/it] 36%|███▌      | 1622/4545 [2:06:58<3:09:00,  3.88s/it] 36%|███▌      | 1623/4545 [2:07:01<3:05:04,  3.80s/it] 36%|███▌      | 1624/4545 [2:07:06<3:10:46,  3.92s/it] 36%|███▌      | 1625/4545 [2:07:10<3:11:45,  3.94s/it] 36%|███▌      | 1626/4545 [2:07:13<3:11:20,  3.93s/it] 36%|███▌      | 1627/4545 [2:07:17<3:05:59,  3.82s/it] 36%|███▌      | 1628/4545 [2:07:19<2:43:24,  3.36s/it] 36%|███▌      | 1629/4545 [2:07:23<2:49:12,  3.48s/it] 36%|███▌      | 1630/4545 [2:07:27<2:53:19,  3.57s/it]                                                       {'loss': 0.4322, 'grad_norm': 24.795703887939453, 'learning_rate': 9.968070522109233e-08, 'rewards/chosen': 1.2130858898162842, 'rewards/rejected': -0.2848144471645355, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.498046875, 'logps/chosen': -239.125, 'logps/rejected': -101.625, 'logits/chosen': -6.599999904632568, 'logits/rejected': -6.796875, 'epoch': 1.08}
 36%|███▌      | 1630/4545 [2:07:27<2:53:19,  3.57s/it] 36%|███▌      | 1631/4545 [2:07:30<2:48:25,  3.47s/it] 36%|███▌      | 1632/4545 [2:07:34<2:50:06,  3.50s/it] 36%|███▌      | 1633/4545 [2:07:38<2:54:21,  3.59s/it] 36%|███▌      | 1634/4545 [2:07:41<2:59:13,  3.69s/it] 36%|███▌      | 1635/4545 [2:07:45<3:02:31,  3.76s/it] 36%|███▌      | 1636/4545 [2:07:49<3:04:30,  3.81s/it] 36%|███▌      | 1637/4545 [2:07:53<3:09:42,  3.91s/it] 36%|███▌      | 1638/4545 [2:07:57<3:09:41,  3.92s/it] 36%|███▌      | 1639/4545 [2:08:01<3:05:20,  3.83s/it] 36%|███▌      | 1640/4545 [2:08:04<2:51:28,  3.54s/it]                                                       {'loss': 0.4168, 'grad_norm': 35.23058319091797, 'learning_rate': 9.96228424332273e-08, 'rewards/chosen': 1.4304687976837158, 'rewards/rejected': -0.11777343600988388, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.5457031726837158, 'logps/chosen': -245.9499969482422, 'logps/rejected': -142.8249969482422, 'logits/chosen': -6.5, 'logits/rejected': -6.634375095367432, 'epoch': 1.08}
 36%|███▌      | 1640/4545 [2:08:04<2:51:28,  3.54s/it] 36%|███▌      | 1641/4545 [2:08:07<2:44:27,  3.40s/it] 36%|███▌      | 1642/4545 [2:08:11<2:52:51,  3.57s/it] 36%|███▌      | 1643/4545 [2:08:14<2:46:30,  3.44s/it] 36%|███▌      | 1644/4545 [2:08:18<2:53:18,  3.58s/it] 36%|███▌      | 1645/4545 [2:08:22<2:55:01,  3.62s/it] 36%|███▌      | 1646/4545 [2:08:26<3:03:17,  3.79s/it] 36%|███▌      | 1647/4545 [2:08:30<3:03:24,  3.80s/it] 36%|███▋      | 1648/4545 [2:08:32<2:47:12,  3.46s/it] 36%|███▋      | 1649/4545 [2:08:36<2:50:09,  3.53s/it] 36%|███▋      | 1650/4545 [2:08:38<2:29:19,  3.09s/it]                                                       {'loss': 0.485, 'grad_norm': 23.22533416748047, 'learning_rate': 9.956018583096278e-08, 'rewards/chosen': 0.957812488079071, 'rewards/rejected': -0.20140381157398224, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.16015625, 'logps/chosen': -171.6750030517578, 'logps/rejected': -104.375, 'logits/chosen': -6.696875095367432, 'logits/rejected': -6.421875, 'epoch': 1.09}
 36%|███▋      | 1650/4545 [2:08:38<2:29:19,  3.09s/it] 36%|███▋      | 1651/4545 [2:08:42<2:43:03,  3.38s/it] 36%|███▋      | 1652/4545 [2:08:46<2:51:31,  3.56s/it] 36%|███▋      | 1653/4545 [2:08:50<2:56:43,  3.67s/it] 36%|███▋      | 1654/4545 [2:08:54<2:54:11,  3.62s/it] 36%|███▋      | 1655/4545 [2:08:57<2:58:40,  3.71s/it] 36%|███▋      | 1656/4545 [2:09:01<2:55:47,  3.65s/it] 36%|███▋      | 1657/4545 [2:09:05<2:59:29,  3.73s/it] 36%|███▋      | 1658/4545 [2:09:09<3:02:22,  3.79s/it] 37%|███▋      | 1659/4545 [2:09:12<2:51:00,  3.56s/it] 37%|███▋      | 1660/4545 [2:09:16<2:58:19,  3.71s/it]                                                       {'loss': 0.4144, 'grad_norm': 42.84916305541992, 'learning_rate': 9.949274214547291e-08, 'rewards/chosen': 1.9445312023162842, 'rewards/rejected': -0.010974121280014515, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.956640601158142, 'logps/chosen': -327.6000061035156, 'logps/rejected': -149.4250030517578, 'logits/chosen': -6.671875, 'logits/rejected': -6.696875095367432, 'epoch': 1.1}
 37%|███▋      | 1660/4545 [2:09:16<2:58:19,  3.71s/it] 37%|███▋      | 1661/4545 [2:09:20<3:04:41,  3.84s/it] 37%|███▋      | 1662/4545 [2:09:24<3:05:41,  3.86s/it] 37%|███▋      | 1663/4545 [2:09:27<2:58:41,  3.72s/it] 37%|███▋      | 1664/4545 [2:09:31<3:02:07,  3.79s/it] 37%|███▋      | 1665/4545 [2:09:34<2:51:14,  3.57s/it] 37%|███▋      | 1666/4545 [2:09:38<2:56:28,  3.68s/it] 37%|███▋      | 1667/4545 [2:09:42<2:56:04,  3.67s/it] 37%|███▋      | 1668/4545 [2:09:45<2:53:34,  3.62s/it] 37%|███▋      | 1669/4545 [2:09:50<3:01:32,  3.79s/it] 37%|███▋      | 1670/4545 [2:09:54<3:03:20,  3.83s/it]                                                       {'loss': 0.3692, 'grad_norm': 24.868648529052734, 'learning_rate': 9.942051862220628e-08, 'rewards/chosen': 1.4972655773162842, 'rewards/rejected': -0.26472169160842896, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 1.759765625, 'logps/chosen': -263.0, 'logps/rejected': -142.8249969482422, 'logits/chosen': -6.634375095367432, 'logits/rejected': -6.684374809265137, 'epoch': 1.1}
 37%|███▋      | 1670/4545 [2:09:54<3:03:20,  3.83s/it] 37%|███▋      | 1671/4545 [2:09:58<3:06:51,  3.90s/it] 37%|███▋      | 1672/4545 [2:10:02<3:06:59,  3.91s/it] 37%|███▋      | 1673/4545 [2:10:06<3:11:02,  3.99s/it] 37%|███▋      | 1674/4545 [2:10:09<3:01:58,  3.80s/it] 37%|███▋      | 1675/4545 [2:10:13<3:03:37,  3.84s/it] 37%|███▋      | 1676/4545 [2:10:16<2:52:26,  3.61s/it] 37%|███▋      | 1677/4545 [2:10:20<2:54:03,  3.64s/it] 37%|███▋      | 1678/4545 [2:10:24<2:58:10,  3.73s/it] 37%|███▋      | 1679/4545 [2:10:28<3:01:03,  3.79s/it] 37%|███▋      | 1680/4545 [2:10:31<2:57:06,  3.71s/it]                                                       {'loss': 0.3844, 'grad_norm': 27.91640281677246, 'learning_rate': 9.934352302010754e-08, 'rewards/chosen': 1.759765625, 'rewards/rejected': -0.2916015684604645, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.052734375, 'logps/chosen': -318.04998779296875, 'logps/rejected': -121.05000305175781, 'logits/chosen': -6.534375190734863, 'logits/rejected': -6.887499809265137, 'epoch': 1.11}
 37%|███▋      | 1680/4545 [2:10:31<2:57:06,  3.71s/it] 37%|███▋      | 1681/4545 [2:10:35<2:56:32,  3.70s/it] 37%|███▋      | 1682/4545 [2:10:38<2:43:21,  3.42s/it] 37%|███▋      | 1683/4545 [2:10:41<2:39:29,  3.34s/it] 37%|███▋      | 1684/4545 [2:10:44<2:36:22,  3.28s/it] 37%|███▋      | 1685/4545 [2:10:48<2:45:57,  3.48s/it] 37%|███▋      | 1686/4545 [2:10:52<2:52:07,  3.61s/it] 37%|███▋      | 1687/4545 [2:10:56<2:56:16,  3.70s/it] 37%|███▋      | 1688/4545 [2:11:00<3:00:12,  3.78s/it] 37%|███▋      | 1689/4545 [2:11:04<3:02:12,  3.83s/it] 37%|███▋      | 1690/4545 [2:11:08<3:03:39,  3.86s/it]                                                       {'loss': 0.4282, 'grad_norm': 61.259212493896484, 'learning_rate': 9.926176361078394e-08, 'rewards/chosen': 1.657812476158142, 'rewards/rejected': -0.04221191257238388, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.698828101158142, 'logps/chosen': -281.45001220703125, 'logps/rejected': -152.39999389648438, 'logits/chosen': -6.525000095367432, 'logits/rejected': -6.84375, 'epoch': 1.12}
 37%|███▋      | 1690/4545 [2:11:08<3:03:39,  3.86s/it] 37%|███▋      | 1691/4545 [2:11:12<3:05:14,  3.89s/it] 37%|███▋      | 1692/4545 [2:11:15<3:05:42,  3.91s/it] 37%|███▋      | 1693/4545 [2:11:19<3:05:42,  3.91s/it] 37%|███▋      | 1694/4545 [2:11:23<2:57:16,  3.73s/it] 37%|███▋      | 1695/4545 [2:11:26<2:51:31,  3.61s/it] 37%|███▋      | 1696/4545 [2:11:30<2:56:02,  3.71s/it] 37%|███▋      | 1697/4545 [2:11:34<2:59:17,  3.78s/it] 37%|███▋      | 1698/4545 [2:11:38<3:01:05,  3.82s/it] 37%|███▋      | 1699/4545 [2:11:41<2:58:15,  3.76s/it] 37%|███▋      | 1700/4545 [2:11:46<3:04:35,  3.89s/it]                                                       {'loss': 0.3914, 'grad_norm': 20.557119369506836, 'learning_rate': 9.917524917761663e-08, 'rewards/chosen': 2.185742139816284, 'rewards/rejected': -0.03398437425494194, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.221874952316284, 'logps/chosen': -353.75, 'logps/rejected': -178.85000610351562, 'logits/chosen': -6.381249904632568, 'logits/rejected': -6.646874904632568, 'epoch': 1.12}
 37%|███▋      | 1700/4545 [2:11:46<3:04:35,  3.89s/it] 37%|███▋      | 1701/4545 [2:11:49<3:04:17,  3.89s/it] 37%|███▋      | 1702/4545 [2:11:52<2:49:59,  3.59s/it] 37%|███▋      | 1703/4545 [2:11:56<2:54:30,  3.68s/it] 37%|███▋      | 1704/4545 [2:12:00<2:57:47,  3.75s/it] 38%|███▊      | 1705/4545 [2:12:04<3:00:04,  3.80s/it] 38%|███▊      | 1706/4545 [2:12:08<3:01:34,  3.84s/it] 38%|███▊      | 1707/4545 [2:12:12<3:02:49,  3.87s/it] 38%|███▊      | 1708/4545 [2:12:16<3:05:40,  3.93s/it] 38%|███▊      | 1709/4545 [2:12:20<3:02:26,  3.86s/it] 38%|███▊      | 1710/4545 [2:12:24<3:06:21,  3.94s/it]                                                       {'loss': 0.4105, 'grad_norm': 25.30415153503418, 'learning_rate': 9.908398901481712e-08, 'rewards/chosen': 2.25, 'rewards/rejected': 0.16220703721046448, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.0875000953674316, 'logps/chosen': -378.0, 'logps/rejected': -221.75, 'logits/chosen': -6.474999904632568, 'logits/rejected': -6.550000190734863, 'epoch': 1.13}
 38%|███▊      | 1710/4545 [2:12:24<3:06:21,  3.94s/it] 38%|███▊      | 1711/4545 [2:12:27<2:48:38,  3.57s/it] 38%|███▊      | 1712/4545 [2:12:30<2:50:35,  3.61s/it] 38%|███▊      | 1713/4545 [2:12:34<2:58:27,  3.78s/it] 38%|███▊      | 1714/4545 [2:12:38<3:00:22,  3.82s/it] 38%|███▊      | 1715/4545 [2:12:43<3:05:59,  3.94s/it] 38%|███▊      | 1716/4545 [2:12:47<3:05:31,  3.93s/it] 38%|███▊      | 1717/4545 [2:12:50<2:59:03,  3.80s/it] 38%|███▊      | 1718/4545 [2:12:54<2:54:32,  3.70s/it] 38%|███▊      | 1719/4545 [2:12:57<2:46:29,  3.53s/it] 38%|███▊      | 1720/4545 [2:13:01<2:51:43,  3.65s/it]                                                       {'loss': 0.378, 'grad_norm': 42.29623794555664, 'learning_rate': 9.898799292642878e-08, 'rewards/chosen': 1.4689452648162842, 'rewards/rejected': -0.3788818418979645, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.84765625, 'logps/chosen': -208.1999969482422, 'logps/rejected': -120.5999984741211, 'logits/chosen': -6.728125095367432, 'logits/rejected': -6.737500190734863, 'epoch': 1.14}
 38%|███▊      | 1720/4545 [2:13:02<2:51:43,  3.65s/it] 38%|███▊      | 1721/4545 [2:13:06<3:10:34,  4.05s/it] 38%|███▊      | 1722/4545 [2:13:09<3:08:34,  4.01s/it] 38%|███▊      | 1723/4545 [2:13:13<3:08:55,  4.02s/it] 38%|███▊      | 1724/4545 [2:13:16<2:54:05,  3.70s/it] 38%|███▊      | 1725/4545 [2:13:20<2:56:47,  3.76s/it] 38%|███▊      | 1726/4545 [2:13:24<2:56:54,  3.77s/it] 38%|███▊      | 1727/4545 [2:13:27<2:49:12,  3.60s/it] 38%|███▊      | 1728/4545 [2:13:31<2:53:43,  3.70s/it] 38%|███▊      | 1729/4545 [2:13:35<2:56:40,  3.76s/it] 38%|███▊      | 1730/4545 [2:13:39<2:58:44,  3.81s/it]                                                       {'loss': 0.4462, 'grad_norm': 29.217288970947266, 'learning_rate': 9.888727122527362e-08, 'rewards/chosen': 2.398632764816284, 'rewards/rejected': 0.06086425855755806, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 2.33984375, 'logps/chosen': -396.2250061035156, 'logps/rejected': -194.5500030517578, 'logits/chosen': -6.637499809265137, 'logits/rejected': -6.525000095367432, 'epoch': 1.14}
 38%|███▊      | 1730/4545 [2:13:39<2:58:44,  3.81s/it] 38%|███▊      | 1731/4545 [2:13:43<2:57:21,  3.78s/it] 38%|███▊      | 1732/4545 [2:13:47<2:58:07,  3.80s/it] 38%|███▊      | 1733/4545 [2:13:52<3:16:31,  4.19s/it] 38%|███▊      | 1734/4545 [2:13:56<3:12:29,  4.11s/it] 38%|███▊      | 1735/4545 [2:14:12<6:02:44,  7.75s/it] 38%|███▊      | 1736/4545 [2:14:16<5:12:29,  6.67s/it] 38%|███▊      | 1737/4545 [2:14:20<4:33:33,  5.85s/it] 38%|███▊      | 1738/4545 [2:14:24<4:01:06,  5.15s/it] 38%|███▊      | 1739/4545 [2:14:26<3:29:34,  4.48s/it] 38%|███▊      | 1740/4545 [2:14:30<3:21:12,  4.30s/it]                                                       {'loss': 0.3891, 'grad_norm': 29.039934158325195, 'learning_rate': 9.878183473184433e-08, 'rewards/chosen': 1.7218749523162842, 'rewards/rejected': -0.11220703274011612, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.831640601158142, 'logps/chosen': -287.6000061035156, 'logps/rejected': -182.52499389648438, 'logits/chosen': -6.643750190734863, 'logits/rejected': -6.759375095367432, 'epoch': 1.15}
 38%|███▊      | 1740/4545 [2:14:31<3:21:12,  4.30s/it] 38%|███▊      | 1741/4545 [2:14:35<3:21:17,  4.31s/it] 38%|███▊      | 1742/4545 [2:14:37<2:56:17,  3.77s/it] 38%|███▊      | 1743/4545 [2:14:41<2:49:41,  3.63s/it] 38%|███▊      | 1744/4545 [2:15:38<15:23:27, 19.78s/it] 38%|███▊      | 1745/4545 [2:15:45<12:30:18, 16.08s/it] 38%|███▊      | 1746/4545 [2:15:53<10:26:17, 13.43s/it] 38%|███▊      | 1747/4545 [2:16:00<9:03:14, 11.65s/it]  38%|███▊      | 1748/4545 [2:16:08<8:04:35, 10.40s/it] 38%|███▊      | 1749/4545 [2:16:15<7:16:12,  9.36s/it] 39%|███▊      | 1750/4545 [2:16:21<6:38:48,  8.56s/it]                                                       {'loss': 0.3892, 'grad_norm': 51.257022857666016, 'learning_rate': 9.86716947731419e-08, 'rewards/chosen': 1.350000023841858, 'rewards/rejected': -0.34760743379592896, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.6980469226837158, 'logps/chosen': -213.22500610351562, 'logps/rejected': -156.39999389648438, 'logits/chosen': -6.784375190734863, 'logits/rejected': -6.821875095367432, 'epoch': 1.16}
 39%|███▊      | 1750/4545 [2:16:21<6:38:48,  8.56s/it] 39%|███▊      | 1751/4545 [2:16:28<6:12:30,  8.00s/it] 39%|███▊      | 1752/4545 [2:16:35<6:04:37,  7.83s/it] 39%|███▊      | 1753/4545 [2:16:43<6:00:34,  7.75s/it] 39%|███▊      | 1754/4545 [2:16:50<5:55:55,  7.65s/it] 39%|███▊      | 1755/4545 [2:16:58<5:56:21,  7.66s/it] 39%|███▊      | 1756/4545 [2:17:05<5:53:12,  7.60s/it] 39%|███▊      | 1757/4545 [2:17:13<5:45:11,  7.43s/it] 39%|███▊      | 1758/4545 [2:17:19<5:29:10,  7.09s/it] 39%|███▊      | 1759/4545 [2:17:26<5:25:11,  7.00s/it] 39%|███▊      | 1760/4545 [2:17:32<5:21:37,  6.93s/it]                                                       {'loss': 0.3609, 'grad_norm': 18.895498275756836, 'learning_rate': 9.855686318145876e-08, 'rewards/chosen': 1.167578101158142, 'rewards/rejected': -0.5556640625, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 1.7234375476837158, 'logps/chosen': -189.5500030517578, 'logps/rejected': -95.42500305175781, 'logits/chosen': -6.696875095367432, 'logits/rejected': -6.762499809265137, 'epoch': 1.16}
 39%|███▊      | 1760/4545 [2:17:32<5:21:37,  6.93s/it] 39%|███▊      | 1761/4545 [2:17:40<5:28:09,  7.07s/it] 39%|███▉      | 1762/4545 [2:17:48<5:37:28,  7.28s/it] 39%|███▉      | 1763/4545 [2:17:55<5:41:49,  7.37s/it] 39%|███▉      | 1764/4545 [2:18:03<5:43:21,  7.41s/it] 39%|███▉      | 1765/4545 [2:18:09<5:34:15,  7.21s/it] 39%|███▉      | 1766/4545 [2:18:17<5:38:24,  7.31s/it] 39%|███▉      | 1767/4545 [2:18:24<5:33:02,  7.19s/it] 39%|███▉      | 1768/4545 [2:18:31<5:36:37,  7.27s/it] 39%|███▉      | 1769/4545 [2:18:39<5:39:59,  7.35s/it] 39%|███▉      | 1770/4545 [2:18:46<5:31:48,  7.17s/it]                                                       {'loss': 0.3743, 'grad_norm': 27.045330047607422, 'learning_rate': 9.843735229310759e-08, 'rewards/chosen': 1.6794922351837158, 'rewards/rejected': -0.097442626953125, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.774999976158142, 'logps/chosen': -281.8999938964844, 'logps/rejected': -159.14999389648438, 'logits/chosen': -6.699999809265137, 'logits/rejected': -6.834374904632568, 'epoch': 1.17}
 39%|███▉      | 1770/4545 [2:18:46<5:31:48,  7.17s/it] 39%|███▉      | 1771/4545 [2:18:53<5:41:08,  7.38s/it] 39%|███▉      | 1772/4545 [2:19:01<5:40:12,  7.36s/it] 39%|███▉      | 1773/4545 [2:19:09<5:45:11,  7.47s/it] 39%|███▉      | 1774/4545 [2:19:16<5:44:16,  7.45s/it] 39%|███▉      | 1775/4545 [2:19:24<5:49:05,  7.56s/it] 39%|███▉      | 1776/4545 [2:19:31<5:47:53,  7.54s/it] 39%|███▉      | 1777/4545 [2:19:38<5:36:43,  7.30s/it] 39%|███▉      | 1778/4545 [2:19:46<5:44:14,  7.46s/it] 39%|███▉      | 1779/4545 [2:19:52<5:30:43,  7.17s/it] 39%|███▉      | 1780/4545 [2:20:00<5:35:32,  7.28s/it]                                                       {'loss': 0.3436, 'grad_norm': 30.599584579467773, 'learning_rate': 9.83131749470961e-08, 'rewards/chosen': 1.542578101158142, 'rewards/rejected': -0.30585938692092896, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 1.84765625, 'logps/chosen': -245.3000030517578, 'logps/rejected': -138.52499389648438, 'logits/chosen': -6.6875, 'logits/rejected': -6.903124809265137, 'epoch': 1.17}
 39%|███▉      | 1780/4545 [2:20:00<5:35:32,  7.28s/it] 39%|███▉      | 1781/4545 [2:20:07<5:39:15,  7.36s/it] 39%|███▉      | 1782/4545 [2:20:50<13:45:56, 17.94s/it] 39%|███▉      | 1783/4545 [2:21:07<13:31:17, 17.62s/it] 39%|███▉      | 1784/4545 [2:21:24<13:20:22, 17.39s/it] 39%|███▉      | 1785/4545 [2:21:41<13:14:57, 17.28s/it] 39%|███▉      | 1786/4545 [2:21:58<13:07:29, 17.13s/it] 39%|███▉      | 1787/4545 [2:22:14<12:56:06, 16.88s/it] 39%|███▉      | 1788/4545 [2:22:31<12:59:02, 16.95s/it] 39%|███▉      | 1789/4545 [2:22:48<12:59:26, 16.97s/it] 39%|███▉      | 1790/4545 [2:23:06<13:07:02, 17.14s/it]                                                        {'loss': 0.3943, 'grad_norm': 36.67649841308594, 'learning_rate': 9.81843444837477e-08, 'rewards/chosen': 2.541796922683716, 'rewards/rejected': -0.07832030951976776, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.6171875, 'logps/chosen': -368.04998779296875, 'logps/rejected': -182.6750030517578, 'logits/chosen': -6.631249904632568, 'logits/rejected': -6.678124904632568, 'epoch': 1.18}
 39%|███▉      | 1790/4545 [2:23:06<13:07:02, 17.14s/it] 39%|███▉      | 1791/4545 [2:23:23<13:11:38, 17.25s/it] 39%|███▉      | 1792/4545 [2:23:40<13:13:03, 17.28s/it] 39%|███▉      | 1793/4545 [2:23:55<12:37:16, 16.51s/it] 39%|███▉      | 1794/4545 [2:23:59<9:43:54, 12.74s/it]  39%|███▉      | 1795/4545 [2:24:03<7:41:29, 10.07s/it] 40%|███▉      | 1796/4545 [2:24:07<6:20:44,  8.31s/it] 40%|███▉      | 1797/4545 [2:24:11<5:20:15,  6.99s/it] 40%|███▉      | 1798/4545 [2:24:15<4:37:59,  6.07s/it] 40%|███▉      | 1799/4545 [2:24:19<4:08:28,  5.43s/it] 40%|███▉      | 1800/4545 [2:24:22<3:43:27,  4.88s/it]                                                       {'loss': 0.4058, 'grad_norm': 46.55302810668945, 'learning_rate': 9.805087474326836e-08, 'rewards/chosen': 1.685546875, 'rewards/rejected': -0.09573974460363388, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.775781273841858, 'logps/chosen': -296.75, 'logps/rejected': -156.5500030517578, 'logits/chosen': -6.628125190734863, 'logits/rejected': -6.537499904632568, 'epoch': 1.19}
 40%|███▉      | 1800/4545 [2:24:23<3:43:27,  4.88s/it] 40%|███▉      | 1801/4545 [2:24:26<3:31:17,  4.62s/it] 40%|███▉      | 1802/4545 [2:24:30<3:21:40,  4.41s/it] 40%|███▉      | 1803/4545 [2:24:34<3:17:24,  4.32s/it] 40%|███▉      | 1804/4545 [2:24:38<3:07:57,  4.11s/it] 40%|███▉      | 1805/4545 [2:24:42<3:07:09,  4.10s/it] 40%|███▉      | 1806/4545 [2:24:46<3:01:51,  3.98s/it] 40%|███▉      | 1807/4545 [2:24:49<2:51:59,  3.77s/it] 40%|███▉      | 1808/4545 [2:24:52<2:39:50,  3.50s/it] 40%|███▉      | 1809/4545 [2:24:56<2:48:11,  3.69s/it] 40%|███▉      | 1810/4545 [2:25:00<2:43:21,  3.58s/it]                                                       {'loss': 0.403, 'grad_norm': 47.40060806274414, 'learning_rate': 9.791278006425974e-08, 'rewards/chosen': 1.3972656726837158, 'rewards/rejected': -0.40673828125, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.8046875, 'logps/chosen': -215.35000610351562, 'logps/rejected': -116.4749984741211, 'logits/chosen': -6.731249809265137, 'logits/rejected': -6.809374809265137, 'epoch': 1.19}
 40%|███▉      | 1810/4545 [2:25:00<2:43:21,  3.58s/it] 40%|███▉      | 1811/4545 [2:25:03<2:48:36,  3.70s/it] 40%|███▉      | 1812/4545 [2:25:07<2:51:33,  3.77s/it] 40%|███▉      | 1813/4545 [2:25:11<2:53:31,  3.81s/it] 40%|███▉      | 1814/4545 [2:25:15<2:55:43,  3.86s/it] 40%|███▉      | 1815/4545 [2:25:19<2:57:42,  3.91s/it] 40%|███▉      | 1816/4545 [2:25:23<2:57:38,  3.91s/it] 40%|███▉      | 1817/4545 [2:25:27<3:00:33,  3.97s/it] 40%|████      | 1818/4545 [2:25:31<2:56:48,  3.89s/it] 40%|████      | 1819/4545 [2:25:35<3:01:14,  3.99s/it] 40%|████      | 1820/4545 [2:25:39<3:00:13,  3.97s/it]                                                       {'loss': 0.357, 'grad_norm': 42.944034576416016, 'learning_rate': 9.777007528217889e-08, 'rewards/chosen': 2.9027342796325684, 'rewards/rejected': 0.07449035346508026, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.8304686546325684, 'logps/chosen': -451.79998779296875, 'logps/rejected': -231.02499389648438, 'logits/chosen': -6.478125095367432, 'logits/rejected': -6.659375190734863, 'epoch': 1.2}
 40%|████      | 1820/4545 [2:25:39<3:00:13,  3.97s/it] 40%|████      | 1821/4545 [2:25:43<3:00:09,  3.97s/it] 40%|████      | 1822/4545 [2:25:47<3:00:14,  3.97s/it] 40%|████      | 1823/4545 [2:25:51<2:59:25,  3.96s/it] 40%|████      | 1824/4545 [2:25:54<2:48:20,  3.71s/it] 40%|████      | 1825/4545 [2:25:58<2:51:16,  3.78s/it] 40%|████      | 1826/4545 [2:26:01<2:37:54,  3.48s/it] 40%|████      | 1827/4545 [2:26:05<2:47:29,  3.70s/it] 40%|████      | 1828/4545 [2:26:09<2:54:28,  3.85s/it] 40%|████      | 1829/4545 [2:26:13<2:47:29,  3.70s/it] 40%|████      | 1830/4545 [2:26:15<2:30:57,  3.34s/it]                                                       {'loss': 0.3849, 'grad_norm': 23.008092880249023, 'learning_rate': 9.762277572774435e-08, 'rewards/chosen': 1.841406226158142, 'rewards/rejected': -0.11916504055261612, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.962499976158142, 'logps/chosen': -272.54998779296875, 'logps/rejected': -168.14999389648438, 'logits/chosen': -6.571875095367432, 'logits/rejected': -6.721875190734863, 'epoch': 1.21}
 40%|████      | 1830/4545 [2:26:15<2:30:57,  3.34s/it] 40%|████      | 1831/4545 [2:26:19<2:39:45,  3.53s/it] 40%|████      | 1832/4545 [2:26:23<2:49:23,  3.75s/it] 40%|████      | 1833/4545 [2:26:27<2:50:03,  3.76s/it] 40%|████      | 1834/4545 [2:26:31<2:50:18,  3.77s/it] 40%|████      | 1835/4545 [2:26:34<2:41:23,  3.57s/it] 40%|████      | 1836/4545 [2:26:38<2:45:48,  3.67s/it] 40%|████      | 1837/4545 [2:26:42<2:51:50,  3.81s/it] 40%|████      | 1838/4545 [2:26:46<2:47:15,  3.71s/it] 40%|████      | 1839/4545 [2:26:48<2:28:10,  3.29s/it] 40%|████      | 1840/4545 [2:26:52<2:41:56,  3.59s/it]                                                       {'loss': 0.4313, 'grad_norm': 52.99598693847656, 'learning_rate': 9.74708972252893e-08, 'rewards/chosen': 1.357812523841858, 'rewards/rejected': -0.33935546875, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.6984374523162842, 'logps/chosen': -219.9499969482422, 'logps/rejected': -126.5999984741211, 'logits/chosen': -6.768750190734863, 'logits/rejected': -6.815625190734863, 'epoch': 1.21}
 40%|████      | 1840/4545 [2:26:52<2:41:56,  3.59s/it] 41%|████      | 1841/4545 [2:26:56<2:48:23,  3.74s/it] 41%|████      | 1842/4545 [2:27:00<2:50:36,  3.79s/it] 41%|████      | 1843/4545 [2:27:04<2:52:19,  3.83s/it] 41%|████      | 1844/4545 [2:27:07<2:39:10,  3.54s/it] 41%|████      | 1845/4545 [2:27:11<2:41:35,  3.59s/it] 41%|████      | 1846/4545 [2:27:13<2:28:31,  3.30s/it] 41%|████      | 1847/4545 [2:27:17<2:38:05,  3.52s/it] 41%|████      | 1848/4545 [2:27:21<2:45:27,  3.68s/it] 41%|████      | 1849/4545 [2:27:25<2:48:26,  3.75s/it] 41%|████      | 1850/4545 [2:27:29<2:50:25,  3.79s/it]                                                       {'loss': 0.3725, 'grad_norm': 37.564659118652344, 'learning_rate': 9.731445609106147e-08, 'rewards/chosen': 2.0269532203674316, 'rewards/rejected': -0.18203124403953552, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.2109375, 'logps/chosen': -323.7749938964844, 'logps/rejected': -177.0500030517578, 'logits/chosen': -6.75, 'logits/rejected': -6.824999809265137, 'epoch': 1.22}
 41%|████      | 1850/4545 [2:27:29<2:50:25,  3.79s/it] 41%|████      | 1851/4545 [2:27:33<2:52:35,  3.84s/it] 41%|████      | 1852/4545 [2:27:37<2:50:01,  3.79s/it] 41%|████      | 1853/4545 [2:27:41<2:51:51,  3.83s/it] 41%|████      | 1854/4545 [2:27:45<2:53:40,  3.87s/it] 41%|████      | 1855/4545 [2:27:49<2:54:13,  3.89s/it] 41%|████      | 1856/4545 [2:27:53<2:54:35,  3.90s/it] 41%|████      | 1857/4545 [2:27:56<2:55:00,  3.91s/it] 41%|████      | 1858/4545 [2:28:00<2:56:30,  3.94s/it] 41%|████      | 1859/4545 [2:28:03<2:42:26,  3.63s/it] 41%|████      | 1860/4545 [2:28:07<2:46:12,  3.71s/it]                                                       {'loss': 0.3679, 'grad_norm': 33.0282096862793, 'learning_rate': 9.715346913147034e-08, 'rewards/chosen': 2.6172852516174316, 'rewards/rejected': -0.01723632775247097, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.6382813453674316, 'logps/chosen': -404.8500061035156, 'logps/rejected': -231.64999389648438, 'logits/chosen': -6.418749809265137, 'logits/rejected': -6.696875095367432, 'epoch': 1.23}
 41%|████      | 1860/4545 [2:28:07<2:46:12,  3.71s/it] 41%|████      | 1861/4545 [2:28:11<2:50:03,  3.80s/it] 41%|████      | 1862/4545 [2:28:15<2:51:46,  3.84s/it] 41%|████      | 1863/4545 [2:28:19<2:48:26,  3.77s/it] 41%|████      | 1864/4545 [2:28:23<2:50:19,  3.81s/it] 41%|████      | 1865/4545 [2:28:27<2:56:39,  3.95s/it] 41%|████      | 1866/4545 [2:28:31<2:56:11,  3.95s/it] 41%|████      | 1867/4545 [2:28:34<2:46:27,  3.73s/it] 41%|████      | 1868/4545 [2:28:38<2:49:02,  3.79s/it] 41%|████      | 1869/4545 [2:28:42<2:50:50,  3.83s/it] 41%|████      | 1870/4545 [2:28:46<2:52:06,  3.86s/it]                                                       {'loss': 0.3975, 'grad_norm': 25.955974578857422, 'learning_rate': 9.698795364128163e-08, 'rewards/chosen': 2.7457032203674316, 'rewards/rejected': 0.0062500000931322575, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.741406202316284, 'logps/chosen': -389.0, 'logps/rejected': -206.39999389648438, 'logits/chosen': -6.512499809265137, 'logits/rejected': -6.671875, 'epoch': 1.23}
 41%|████      | 1870/4545 [2:28:46<2:52:06,  3.86s/it] 41%|████      | 1871/4545 [2:28:50<2:53:26,  3.89s/it] 41%|████      | 1872/4545 [2:28:54<2:50:01,  3.82s/it] 41%|████      | 1873/4545 [2:28:56<2:30:58,  3.39s/it] 41%|████      | 1874/4545 [2:29:00<2:39:13,  3.58s/it] 41%|████▏     | 1875/4545 [2:29:04<2:42:36,  3.65s/it] 41%|████▏     | 1876/4545 [2:29:07<2:30:07,  3.37s/it] 41%|████▏     | 1877/4545 [2:29:11<2:37:49,  3.55s/it] 41%|████▏     | 1878/4545 [2:29:14<2:42:35,  3.66s/it] 41%|████▏     | 1879/4545 [2:29:18<2:42:19,  3.65s/it] 41%|████▏     | 1880/4545 [2:29:22<2:45:58,  3.74s/it]                                                       {'loss': 0.3388, 'grad_norm': 21.42974090576172, 'learning_rate': 9.681792740175927e-08, 'rewards/chosen': 1.4386718273162842, 'rewards/rejected': -0.6875, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.124218702316284, 'logps/chosen': -219.5500030517578, 'logps/rejected': -81.94999694824219, 'logits/chosen': -6.821875095367432, 'logits/rejected': -6.96875, 'epoch': 1.24}
 41%|████▏     | 1880/4545 [2:29:22<2:45:58,  3.74s/it] 41%|████▏     | 1881/4545 [2:29:25<2:38:34,  3.57s/it] 41%|████▏     | 1882/4545 [2:29:29<2:45:10,  3.72s/it] 41%|████▏     | 1883/4545 [2:29:33<2:40:19,  3.61s/it] 41%|████▏     | 1884/4545 [2:29:37<2:44:12,  3.70s/it] 41%|████▏     | 1885/4545 [2:29:41<2:49:49,  3.83s/it] 41%|████▏     | 1886/4545 [2:29:45<2:51:07,  3.86s/it] 42%|████▏     | 1887/4545 [2:29:48<2:51:45,  3.88s/it] 42%|████▏     | 1888/4545 [2:29:52<2:46:21,  3.76s/it] 42%|████▏     | 1889/4545 [2:29:56<2:46:37,  3.76s/it] 42%|████▏     | 1890/4545 [2:29:59<2:35:59,  3.53s/it]                                                       {'loss': 0.4264, 'grad_norm': 44.926841735839844, 'learning_rate': 9.66434086787553e-08, 'rewards/chosen': 1.499609351158142, 'rewards/rejected': -0.23793944716453552, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.7394530773162842, 'logps/chosen': -235.3000030517578, 'logps/rejected': -175.1750030517578, 'logits/chosen': -6.800000190734863, 'logits/rejected': -6.778124809265137, 'epoch': 1.25}
 42%|████▏     | 1890/4545 [2:29:59<2:35:59,  3.53s/it] 42%|████▏     | 1891/4545 [2:30:03<2:44:17,  3.71s/it] 42%|████▏     | 1892/4545 [2:30:07<2:47:05,  3.78s/it] 42%|████▏     | 1893/4545 [2:30:11<2:49:00,  3.82s/it] 42%|████▏     | 1894/4545 [2:30:14<2:44:19,  3.72s/it] 42%|████▏     | 1895/4545 [2:30:18<2:39:30,  3.61s/it] 42%|████▏     | 1896/4545 [2:30:22<2:45:50,  3.76s/it] 42%|████▏     | 1897/4545 [2:30:24<2:27:56,  3.35s/it] 42%|████▏     | 1898/4545 [2:30:28<2:35:33,  3.53s/it] 42%|████▏     | 1899/4545 [2:30:32<2:41:06,  3.65s/it] 42%|████▏     | 1900/4545 [2:30:36<2:44:38,  3.73s/it]                                                       {'loss': 0.3058, 'grad_norm': 22.080852508544922, 'learning_rate': 9.64644162207474e-08, 'rewards/chosen': 2.7671875953674316, 'rewards/rejected': -0.010546875186264515, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 2.7816405296325684, 'logps/chosen': -405.25, 'logps/rejected': -238.1750030517578, 'logits/chosen': -6.456250190734863, 'logits/rejected': -6.631249904632568, 'epoch': 1.25}
 42%|████▏     | 1900/4545 [2:30:36<2:44:38,  3.73s/it] 42%|████▏     | 1901/4545 [2:30:40<2:50:11,  3.86s/it] 42%|████▏     | 1902/4545 [2:30:44<2:54:32,  3.96s/it] 42%|████▏     | 1903/4545 [2:30:48<2:56:36,  4.01s/it] 42%|████▏     | 1904/4545 [2:30:52<2:53:12,  3.94s/it] 42%|████▏     | 1905/4545 [2:30:56<2:54:52,  3.97s/it] 42%|████▏     | 1906/4545 [2:31:00<2:54:10,  3.96s/it] 42%|████▏     | 1907/4545 [2:31:04<2:48:08,  3.82s/it] 42%|████▏     | 1908/4545 [2:31:08<2:53:18,  3.94s/it] 42%|████▏     | 1909/4545 [2:31:12<2:53:03,  3.94s/it] 42%|████▏     | 1910/4545 [2:31:16<2:52:54,  3.94s/it]                                                       {'loss': 0.3476, 'grad_norm': 39.865142822265625, 'learning_rate': 9.628096925682491e-08, 'rewards/chosen': 2.1265625953674316, 'rewards/rejected': -0.46220701932907104, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.5843749046325684, 'logps/chosen': -327.8999938964844, 'logps/rejected': -161.6999969482422, 'logits/chosen': -6.771874904632568, 'logits/rejected': -6.740624904632568, 'epoch': 1.26}
 42%|████▏     | 1910/4545 [2:31:16<2:52:54,  3.94s/it] 42%|████▏     | 1911/4545 [2:31:20<2:57:30,  4.04s/it] 42%|████▏     | 1912/4545 [2:31:23<2:48:38,  3.84s/it] 42%|████▏     | 1913/4545 [2:31:27<2:49:35,  3.87s/it] 42%|████▏     | 1914/4545 [2:31:31<2:50:06,  3.88s/it] 42%|████▏     | 1915/4545 [2:31:35<2:50:33,  3.89s/it] 42%|████▏     | 1916/4545 [2:31:39<2:48:39,  3.85s/it] 42%|████▏     | 1917/4545 [2:31:43<2:49:22,  3.87s/it] 42%|████▏     | 1918/4545 [2:31:47<2:50:29,  3.89s/it] 42%|████▏     | 1919/4545 [2:31:50<2:40:53,  3.68s/it] 42%|████▏     | 1920/4545 [2:31:54<2:43:59,  3.75s/it]                                                       {'loss': 0.3385, 'grad_norm': 41.10932922363281, 'learning_rate': 9.609308749462294e-08, 'rewards/chosen': 2.059375047683716, 'rewards/rejected': -0.22280272841453552, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.2816405296325684, 'logps/chosen': -316.20001220703125, 'logps/rejected': -182.60000610351562, 'logits/chosen': -6.678124904632568, 'logits/rejected': -6.746874809265137, 'epoch': 1.27}
 42%|████▏     | 1920/4545 [2:31:54<2:43:59,  3.75s/it] 42%|████▏     | 1921/4545 [2:31:58<2:51:37,  3.92s/it] 42%|████▏     | 1922/4545 [2:32:02<2:49:49,  3.88s/it] 42%|████▏     | 1923/4545 [2:32:06<2:48:50,  3.86s/it] 42%|████▏     | 1924/4545 [2:32:10<2:53:01,  3.96s/it] 42%|████▏     | 1925/4545 [2:32:14<2:52:14,  3.94s/it] 42%|████▏     | 1926/4545 [2:32:18<2:49:35,  3.89s/it] 42%|████▏     | 1927/4545 [2:32:21<2:44:48,  3.78s/it] 42%|████▏     | 1928/4545 [2:32:24<2:39:08,  3.65s/it] 42%|████▏     | 1929/4545 [2:32:28<2:42:33,  3.73s/it] 42%|████▏     | 1930/4545 [2:32:31<2:33:36,  3.52s/it]                                                       {'loss': 0.4413, 'grad_norm': 30.46438980102539, 'learning_rate': 9.590079111820528e-08, 'rewards/chosen': 1.051171898841858, 'rewards/rejected': -0.591992199420929, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.642968773841858, 'logps/chosen': -186.60000610351562, 'logps/rejected': -112.25, 'logits/chosen': -6.75, 'logits/rejected': -6.740624904632568, 'epoch': 1.27}
 42%|████▏     | 1930/4545 [2:32:32<2:33:36,  3.52s/it] 42%|████▏     | 1931/4545 [2:32:35<2:35:23,  3.57s/it] 43%|████▎     | 1932/4545 [2:32:39<2:39:45,  3.67s/it] 43%|████▎     | 1933/4545 [2:32:42<2:27:54,  3.40s/it] 43%|████▎     | 1934/4545 [2:32:46<2:36:36,  3.60s/it] 43%|████▎     | 1935/4545 [2:32:50<2:40:44,  3.70s/it] 43%|████▎     | 1936/4545 [2:32:54<2:42:42,  3.74s/it] 43%|████▎     | 1937/4545 [2:32:57<2:43:43,  3.77s/it] 43%|████▎     | 1938/4545 [2:33:01<2:45:49,  3.82s/it] 43%|████▎     | 1939/4545 [2:33:05<2:49:20,  3.90s/it] 43%|████▎     | 1940/4545 [2:33:09<2:49:27,  3.90s/it]                                                       {'loss': 0.3606, 'grad_norm': 45.27170181274414, 'learning_rate': 9.570410078589592e-08, 'rewards/chosen': 1.963281273841858, 'rewards/rejected': -2.4372315406799316, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 4.384375095367432, 'logps/chosen': -293.3999938964844, 'logps/rejected': -189.10000610351562, 'logits/chosen': -6.65625, 'logits/rejected': -6.578125, 'epoch': 1.28}
 43%|████▎     | 1940/4545 [2:33:09<2:49:27,  3.90s/it] 43%|████▎     | 1941/4545 [2:33:14<2:54:12,  4.01s/it] 43%|████▎     | 1942/4545 [2:33:18<2:52:51,  3.98s/it] 43%|████▎     | 1943/4545 [2:33:22<2:52:12,  3.97s/it] 43%|████▎     | 1944/4545 [2:33:25<2:51:37,  3.96s/it] 43%|████▎     | 1945/4545 [2:33:29<2:40:46,  3.71s/it] 43%|████▎     | 1946/4545 [2:33:32<2:43:28,  3.77s/it] 43%|████▎     | 1947/4545 [2:33:35<2:30:45,  3.48s/it] 43%|████▎     | 1948/4545 [2:34:04<7:58:04, 11.05s/it] 43%|████▎     | 1949/4545 [2:34:08<6:25:27,  8.91s/it] 43%|████▎     | 1950/4545 [2:34:12<5:23:08,  7.47s/it]                                                       {'loss': 0.3788, 'grad_norm': 73.65486907958984, 'learning_rate': 9.55030376280599e-08, 'rewards/chosen': 1.254785180091858, 'rewards/rejected': -0.4234375059604645, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.677343726158142, 'logps/chosen': -199.8000030517578, 'logps/rejected': -143.97500610351562, 'logits/chosen': -6.896874904632568, 'logits/rejected': -6.787499904632568, 'epoch': 1.29}
 43%|████▎     | 1950/4545 [2:34:12<5:23:08,  7.47s/it] 43%|████▎     | 1951/4545 [2:34:16<4:38:21,  6.44s/it] 43%|████▎     | 1952/4545 [2:34:20<4:05:27,  5.68s/it] 43%|████▎     | 1953/4545 [2:34:24<3:39:26,  5.08s/it] 43%|████▎     | 1954/4545 [2:34:28<3:24:25,  4.73s/it] 43%|████▎     | 1955/4545 [2:34:32<3:17:18,  4.57s/it] 43%|████▎     | 1956/4545 [2:34:36<3:08:40,  4.37s/it] 43%|████▎     | 1957/4545 [2:34:40<3:02:40,  4.24s/it] 43%|████▎     | 1958/4545 [2:34:42<2:37:24,  3.65s/it] 43%|████▎     | 1959/4545 [2:34:44<2:20:09,  3.25s/it] 43%|████▎     | 1960/4545 [2:34:48<2:23:01,  3.32s/it]                                                       {'loss': 0.3875, 'grad_norm': 35.602622985839844, 'learning_rate': 9.52976232448331e-08, 'rewards/chosen': 1.938867211341858, 'rewards/rejected': -0.3697753846645355, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.3070311546325684, 'logps/chosen': -304.8500061035156, 'logps/rejected': -143.1750030517578, 'logits/chosen': -6.756249904632568, 'logits/rejected': -6.915625095367432, 'epoch': 1.29}
 43%|████▎     | 1960/4545 [2:34:48<2:23:01,  3.32s/it] 43%|████▎     | 1961/4545 [2:34:52<2:36:20,  3.63s/it] 43%|████▎     | 1962/4545 [2:34:55<2:23:42,  3.34s/it] 43%|████▎     | 1963/4545 [2:34:58<2:29:42,  3.48s/it] 43%|████▎     | 1964/4545 [2:35:03<2:36:50,  3.65s/it] 43%|████▎     | 1965/4545 [2:35:06<2:34:36,  3.60s/it] 43%|████▎     | 1966/4545 [2:35:10<2:35:04,  3.61s/it] 43%|████▎     | 1967/4545 [2:35:14<2:39:26,  3.71s/it] 43%|████▎     | 1968/4545 [2:35:17<2:41:51,  3.77s/it] 43%|████▎     | 1969/4545 [2:35:22<2:46:23,  3.88s/it] 43%|████▎     | 1970/4545 [2:35:25<2:43:54,  3.82s/it]                                                       {'loss': 0.3947, 'grad_norm': 45.90403366088867, 'learning_rate': 9.508787970380187e-08, 'rewards/chosen': 1.413476586341858, 'rewards/rejected': -0.761914074420929, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.174999952316284, 'logps/chosen': -228.8249969482422, 'logps/rejected': -98.5999984741211, 'logits/chosen': -6.693749904632568, 'logits/rejected': -6.643750190734863, 'epoch': 1.3}
 43%|████▎     | 1970/4545 [2:35:25<2:43:54,  3.82s/it] 43%|████▎     | 1971/4545 [2:35:29<2:42:04,  3.78s/it] 43%|████▎     | 1972/4545 [2:35:32<2:33:45,  3.59s/it] 43%|████▎     | 1973/4545 [2:35:36<2:37:58,  3.69s/it] 43%|████▎     | 1974/4545 [2:35:40<2:41:23,  3.77s/it] 43%|████▎     | 1975/4545 [2:35:44<2:40:29,  3.75s/it] 43%|████▎     | 1976/4545 [2:35:48<2:46:00,  3.88s/it] 43%|████▎     | 1977/4545 [2:35:52<2:45:03,  3.86s/it] 44%|████▎     | 1978/4545 [2:35:56<2:45:42,  3.87s/it] 44%|████▎     | 1979/4545 [2:36:00<2:48:12,  3.93s/it] 44%|████▎     | 1980/4545 [2:36:04<2:49:04,  3.96s/it]                                                       {'loss': 0.3943, 'grad_norm': 23.462848663330078, 'learning_rate': 9.487382953763224e-08, 'rewards/chosen': 1.7839844226837158, 'rewards/rejected': -0.30224609375, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.086718797683716, 'logps/chosen': -240.75, 'logps/rejected': -141.97500610351562, 'logits/chosen': -6.628125190734863, 'logits/rejected': -6.759375095367432, 'epoch': 1.31}
 44%|████▎     | 1980/4545 [2:36:04<2:49:04,  3.96s/it] 44%|████▎     | 1981/4545 [2:36:07<2:40:56,  3.77s/it] 44%|████▎     | 1982/4545 [2:36:11<2:44:21,  3.85s/it] 44%|████▎     | 1983/4545 [2:36:15<2:44:16,  3.85s/it] 44%|████▎     | 1984/4545 [2:36:18<2:39:50,  3.74s/it] 44%|████▎     | 1985/4545 [2:36:22<2:42:04,  3.80s/it] 44%|████▎     | 1986/4545 [2:36:26<2:43:29,  3.83s/it] 44%|████▎     | 1987/4545 [2:36:30<2:48:20,  3.95s/it] 44%|████▎     | 1988/4545 [2:36:34<2:48:36,  3.96s/it] 44%|████▍     | 1989/4545 [2:36:38<2:44:25,  3.86s/it] 44%|████▍     | 1990/4545 [2:36:42<2:47:45,  3.94s/it]                                                       {'loss': 0.3931, 'grad_norm': 28.886903762817383, 'learning_rate': 9.465549574164936e-08, 'rewards/chosen': 1.541601538658142, 'rewards/rejected': -0.4940429627895355, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.0376954078674316, 'logps/chosen': -244.64999389648438, 'logps/rejected': -138.8000030517578, 'logits/chosen': -6.746874809265137, 'logits/rejected': -6.896874904632568, 'epoch': 1.31}
 44%|████▍     | 1990/4545 [2:36:42<2:47:45,  3.94s/it] 44%|████▍     | 1991/4545 [2:36:46<2:48:12,  3.95s/it] 44%|████▍     | 1992/4545 [2:36:50<2:47:53,  3.95s/it] 44%|████▍     | 1993/4545 [2:36:54<2:47:44,  3.94s/it] 44%|████▍     | 1994/4545 [2:36:58<2:47:17,  3.93s/it] 44%|████▍     | 1995/4545 [2:37:02<2:49:22,  3.99s/it] 44%|████▍     | 1996/4545 [2:37:06<2:45:02,  3.88s/it] 44%|████▍     | 1997/4545 [2:37:09<2:42:48,  3.83s/it] 44%|████▍     | 1998/4545 [2:37:13<2:43:56,  3.86s/it] 44%|████▍     | 1999/4545 [2:37:17<2:38:17,  3.73s/it] 44%|████▍     | 2000/4545 [2:37:20<2:37:00,  3.70s/it]                                                       {'loss': 0.4395, 'grad_norm': 97.71331024169922, 'learning_rate': 9.443290177136699e-08, 'rewards/chosen': 2.101367235183716, 'rewards/rejected': 0.19291992485523224, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.9070312976837158, 'logps/chosen': -342.25, 'logps/rejected': -241.8000030517578, 'logits/chosen': -6.743750095367432, 'logits/rejected': -6.612500190734863, 'epoch': 1.32}
 44%|████▍     | 2000/4545 [2:37:20<2:37:00,  3.70s/it] 44%|████▍     | 2001/4545 [2:37:24<2:31:15,  3.57s/it] 44%|████▍     | 2002/4545 [2:37:28<2:37:18,  3.71s/it] 44%|████▍     | 2003/4545 [2:37:32<2:39:14,  3.76s/it] 44%|████▍     | 2004/4545 [2:37:35<2:38:25,  3.74s/it] 44%|████▍     | 2005/4545 [2:37:39<2:39:29,  3.77s/it] 44%|████▍     | 2006/4545 [2:37:43<2:41:21,  3.81s/it] 44%|████▍     | 2007/4545 [2:37:47<2:42:42,  3.85s/it] 44%|████▍     | 2008/4545 [2:37:51<2:43:25,  3.87s/it] 44%|████▍     | 2009/4545 [2:37:55<2:44:04,  3.88s/it] 44%|████▍     | 2010/4545 [2:37:59<2:44:52,  3.90s/it]                                                       {'loss': 0.4264, 'grad_norm': 38.604793548583984, 'learning_rate': 9.42060715399677e-08, 'rewards/chosen': 2.230273485183716, 'rewards/rejected': -0.1732177734375, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 2.404101610183716, 'logps/chosen': -344.25, 'logps/rejected': -192.97500610351562, 'logits/chosen': -6.834374904632568, 'logits/rejected': -6.706250190734863, 'epoch': 1.33}
 44%|████▍     | 2010/4545 [2:37:59<2:44:52,  3.90s/it] 44%|████▍     | 2011/4545 [2:38:03<2:45:23,  3.92s/it] 44%|████▍     | 2012/4545 [2:38:06<2:40:07,  3.79s/it] 44%|████▍     | 2013/4545 [2:38:09<2:28:26,  3.52s/it] 44%|████▍     | 2014/4545 [2:38:13<2:34:13,  3.66s/it] 44%|████▍     | 2015/4545 [2:38:17<2:37:45,  3.74s/it] 44%|████▍     | 2016/4545 [2:38:21<2:39:48,  3.79s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:44,  1.31it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.40s/it][A
 10%|█         | 6/60 [00:07<01:20,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.62s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.52s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.10s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.08s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.33s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.40s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.40s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.45s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.51s/it][A                                                       
                                               [A{'eval_loss': 0.4022497534751892, 'eval_runtime': 80.6447, 'eval_samples_per_second': 11.817, 'eval_steps_per_second': 0.744, 'eval_rewards/chosen': 2.1810383796691895, 'eval_rewards/rejected': 0.07800140231847763, 'eval_rewards/accuracies': 0.8170138597488403, 'eval_rewards/margins': 2.101548194885254, 'eval_logps/chosen': -366.7583312988281, 'eval_logps/rejected': -151.63333129882812, 'eval_logits/chosen': -6.447916507720947, 'eval_logits/rejected': -7.175520896911621, 'epoch': 1.33}
 44%|████▍     | 2016/4545 [2:39:42<2:39:48,  3.79s/it]
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 44%|████▍     | 2017/4545 [2:39:56<21:59:44, 31.32s/it] 44%|████▍     | 2018/4545 [2:40:00<16:09:32, 23.02s/it] 44%|████▍     | 2019/4545 [2:40:04<12:10:57, 17.36s/it] 44%|████▍     | 2020/4545 [2:40:08<9:22:44, 13.37s/it]                                                        {'loss': 0.3633, 'grad_norm': 152.07501220703125, 'learning_rate': 9.397502941573402e-08, 'rewards/chosen': 1.903906226158142, 'rewards/rejected': -0.45795899629592896, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.3648438453674316, 'logps/chosen': -311.25, 'logps/rejected': -156.25, 'logits/chosen': -6.868750095367432, 'logits/rejected': -6.981249809265137, 'epoch': 1.33}
 44%|████▍     | 2020/4545 [2:40:08<9:22:44, 13.37s/it] 44%|████▍     | 2021/4545 [2:40:12<7:23:57, 10.55s/it] 44%|████▍     | 2022/4545 [2:40:16<5:59:19,  8.55s/it] 45%|████▍     | 2023/4545 [2:40:20<4:55:16,  7.02s/it] 45%|████▍     | 2024/4545 [2:40:24<4:19:44,  6.18s/it] 45%|████▍     | 2025/4545 [2:40:28<3:52:47,  5.54s/it] 45%|████▍     | 2026/4545 [2:40:31<3:27:09,  4.93s/it] 45%|████▍     | 2027/4545 [2:40:36<3:19:08,  4.75s/it] 45%|████▍     | 2028/4545 [2:40:38<2:52:51,  4.12s/it] 45%|████▍     | 2029/4545 [2:40:43<2:53:42,  4.14s/it] 45%|████▍     | 2030/4545 [2:40:46<2:47:40,  4.00s/it]                                                       {'loss': 0.3056, 'grad_norm': 26.76760482788086, 'learning_rate': 9.37398002194304e-08, 'rewards/chosen': 2.229687452316284, 'rewards/rejected': -0.27910155057907104, 'rewards/accuracies': 0.875, 'rewards/margins': 2.507031202316284, 'logps/chosen': -325.04998779296875, 'logps/rejected': -199.375, 'logits/chosen': -6.946875095367432, 'logits/rejected': -6.953125, 'epoch': 1.34}
 45%|████▍     | 2030/4545 [2:40:46<2:47:40,  4.00s/it] 45%|████▍     | 2031/4545 [2:40:50<2:49:30,  4.05s/it] 45%|████▍     | 2032/4545 [2:40:54<2:48:06,  4.01s/it] 45%|████▍     | 2033/4545 [2:40:58<2:47:51,  4.01s/it] 45%|████▍     | 2034/4545 [2:41:02<2:46:43,  3.98s/it] 45%|████▍     | 2035/4545 [2:41:06<2:45:48,  3.96s/it] 45%|████▍     | 2036/4545 [2:41:10<2:45:46,  3.96s/it] 45%|████▍     | 2037/4545 [2:41:14<2:45:05,  3.95s/it] 45%|████▍     | 2038/4545 [2:41:18<2:39:29,  3.82s/it] 45%|████▍     | 2039/4545 [2:41:22<2:41:01,  3.86s/it] 45%|████▍     | 2040/4545 [2:41:26<2:44:59,  3.95s/it]                                                       {'loss': 0.3456, 'grad_norm': 27.930313110351562, 'learning_rate': 9.350040922163682e-08, 'rewards/chosen': 2.493359327316284, 'rewards/rejected': 0.0006347656017169356, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.492968797683716, 'logps/chosen': -349.70001220703125, 'logps/rejected': -186.5749969482422, 'logits/chosen': -6.618750095367432, 'logits/rejected': -6.831250190734863, 'epoch': 1.35}
 45%|████▍     | 2040/4545 [2:41:26<2:44:59,  3.95s/it] 45%|████▍     | 2041/4545 [2:41:29<2:41:54,  3.88s/it] 45%|████▍     | 2042/4545 [2:41:34<2:45:55,  3.98s/it] 45%|████▍     | 2043/4545 [2:41:38<2:45:09,  3.96s/it] 45%|████▍     | 2044/4545 [2:41:41<2:44:55,  3.96s/it] 45%|████▍     | 2045/4545 [2:41:45<2:44:12,  3.94s/it] 45%|████▌     | 2046/4545 [2:41:49<2:37:19,  3.78s/it] 45%|████▌     | 2047/4545 [2:41:53<2:40:00,  3.84s/it] 45%|████▌     | 2048/4545 [2:41:57<2:42:12,  3.90s/it] 45%|████▌     | 2049/4545 [2:42:25<7:49:21, 11.28s/it] 45%|████▌     | 2050/4545 [2:42:29<6:12:35,  8.96s/it]                                                       {'loss': 0.3249, 'grad_norm': 37.90523910522461, 'learning_rate': 9.325688214003396e-08, 'rewards/chosen': 1.674414038658142, 'rewards/rejected': -0.634844958782196, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.3140625953674316, 'logps/chosen': -242.875, 'logps/rejected': -154.125, 'logits/chosen': -6.787499904632568, 'logits/rejected': -6.78125, 'epoch': 1.35}
 45%|████▌     | 2050/4545 [2:42:29<6:12:35,  8.96s/it] 45%|████▌     | 2051/4545 [2:42:33<5:06:34,  7.38s/it] 45%|████▌     | 2052/4545 [2:42:36<4:21:43,  6.30s/it] 45%|████▌     | 2053/4545 [2:42:40<3:52:28,  5.60s/it] 45%|████▌     | 2054/4545 [2:42:44<3:32:02,  5.11s/it] 45%|████▌     | 2055/4545 [2:42:48<3:17:22,  4.76s/it] 45%|████▌     | 2056/4545 [2:42:51<2:53:54,  4.19s/it] 45%|████▌     | 2057/4545 [2:42:55<2:50:25,  4.11s/it] 45%|████▌     | 2058/4545 [2:42:59<2:48:07,  4.06s/it] 45%|████▌     | 2059/4545 [2:43:03<2:46:26,  4.02s/it] 45%|████▌     | 2060/4545 [2:43:06<2:29:53,  3.62s/it]                                                       {'loss': 0.3363, 'grad_norm': 51.1531982421875, 'learning_rate': 9.300924513664032e-08, 'rewards/chosen': 2.764843702316284, 'rewards/rejected': -0.4208984375, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 3.1871094703674316, 'logps/chosen': -401.25, 'logps/rejected': -159.875, 'logits/chosen': -6.615624904632568, 'logits/rejected': -6.553124904632568, 'epoch': 1.36}
 45%|████▌     | 2060/4545 [2:43:06<2:29:53,  3.62s/it] 45%|████▌     | 2061/4545 [2:43:10<2:35:02,  3.75s/it] 45%|████▌     | 2062/4545 [2:43:13<2:37:14,  3.80s/it] 45%|████▌     | 2063/4545 [2:43:43<7:52:41, 11.43s/it] 45%|████▌     | 2064/4545 [2:43:47<6:20:10,  9.19s/it] 45%|████▌     | 2065/4545 [2:43:50<5:07:38,  7.44s/it] 45%|████▌     | 2066/4545 [2:43:53<4:16:35,  6.21s/it] 45%|████▌     | 2067/4545 [2:43:58<3:52:05,  5.62s/it] 46%|████▌     | 2068/4545 [2:44:02<3:31:03,  5.11s/it] 46%|████▌     | 2069/4545 [2:44:06<3:18:26,  4.81s/it] 46%|████▌     | 2070/4545 [2:44:10<3:07:34,  4.55s/it]                                                       {'loss': 0.386, 'grad_norm': 48.56747055053711, 'learning_rate': 9.275752481500174e-08, 'rewards/chosen': 1.327539086341858, 'rewards/rejected': -0.44453126192092896, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.771875023841858, 'logps/chosen': -206.0, 'logps/rejected': -161.8249969482422, 'logits/chosen': -6.921875, 'logits/rejected': -6.890625, 'epoch': 1.37}
 46%|████▌     | 2070/4545 [2:44:10<3:07:34,  4.55s/it] 46%|████▌     | 2071/4545 [2:44:14<3:00:52,  4.39s/it] 46%|████▌     | 2072/4545 [2:44:17<2:49:42,  4.12s/it] 46%|████▌     | 2073/4545 [2:44:21<2:47:33,  4.07s/it] 46%|████▌     | 2074/4545 [2:44:24<2:36:25,  3.80s/it] 46%|████▌     | 2075/4545 [2:44:28<2:36:45,  3.81s/it] 46%|████▌     | 2076/4545 [2:44:32<2:32:38,  3.71s/it] 46%|████▌     | 2077/4545 [2:44:35<2:34:17,  3.75s/it] 46%|████▌     | 2078/4545 [2:44:39<2:36:27,  3.81s/it] 46%|████▌     | 2079/4545 [2:44:43<2:34:15,  3.75s/it] 46%|████▌     | 2080/4545 [2:44:46<2:24:11,  3.51s/it]                                                       {'loss': 0.379, 'grad_norm': 33.60763931274414, 'learning_rate': 9.250174821733328e-08, 'rewards/chosen': 1.0028808116912842, 'rewards/rejected': -0.794628918170929, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.798437476158142, 'logps/chosen': -153.8000030517578, 'logps/rejected': -106.80000305175781, 'logits/chosen': -6.824999809265137, 'logits/rejected': -6.878125190734863, 'epoch': 1.37}
 46%|████▌     | 2080/4545 [2:44:46<2:24:11,  3.51s/it] 46%|████▌     | 2081/4545 [2:44:48<2:12:03,  3.22s/it] 46%|████▌     | 2082/4545 [2:44:52<2:14:12,  3.27s/it] 46%|████▌     | 2083/4545 [2:44:56<2:23:57,  3.51s/it] 46%|████▌     | 2084/4545 [2:45:25<7:38:48, 11.19s/it] 46%|████▌     | 2085/4545 [2:45:29<6:12:55,  9.10s/it] 46%|████▌     | 2086/4545 [2:45:33<5:09:02,  7.54s/it] 46%|████▌     | 2087/4545 [2:45:37<4:24:45,  6.46s/it] 46%|████▌     | 2088/4545 [2:45:41<3:53:29,  5.70s/it] 46%|████▌     | 2089/4545 [2:45:45<3:30:17,  5.14s/it] 46%|████▌     | 2090/4545 [2:45:48<3:12:09,  4.70s/it]                                                       {'loss': 0.3766, 'grad_norm': 32.86662292480469, 'learning_rate': 9.224194282161415e-08, 'rewards/chosen': 2.186328172683716, 'rewards/rejected': -0.38428956270217896, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.5703125, 'logps/chosen': -330.75, 'logps/rejected': -227.25, 'logits/chosen': -6.721875190734863, 'logits/rejected': -6.703125, 'epoch': 1.38}
 46%|████▌     | 2090/4545 [2:45:49<3:12:09,  4.70s/it] 46%|████▌     | 2091/4545 [2:45:52<3:00:03,  4.40s/it] 46%|████▌     | 2092/4545 [2:45:56<2:48:04,  4.11s/it] 46%|████▌     | 2093/4545 [2:46:00<2:46:02,  4.06s/it] 46%|████▌     | 2094/4545 [2:46:04<2:47:23,  4.10s/it] 46%|████▌     | 2095/4545 [2:46:07<2:41:26,  3.95s/it] 46%|████▌     | 2096/4545 [2:46:11<2:41:04,  3.95s/it] 46%|████▌     | 2097/4545 [2:46:15<2:40:44,  3.94s/it] 46%|████▌     | 2098/4545 [2:46:19<2:40:34,  3.94s/it] 46%|████▌     | 2099/4545 [2:46:23<2:40:31,  3.94s/it] 46%|████▌     | 2100/4545 [2:46:27<2:40:13,  3.93s/it]                                                       {'loss': 0.373, 'grad_norm': 19.96626853942871, 'learning_rate': 9.197813653863578e-08, 'rewards/chosen': 2.7359375953674316, 'rewards/rejected': -0.03339843824505806, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.7699217796325684, 'logps/chosen': -402.6000061035156, 'logps/rejected': -205.39999389648438, 'logits/chosen': -6.471875190734863, 'logits/rejected': -6.696875095367432, 'epoch': 1.39}
 46%|████▌     | 2100/4545 [2:46:27<2:40:13,  3.93s/it] 46%|████▌     | 2101/4545 [2:46:31<2:43:17,  4.01s/it] 46%|████▌     | 2102/4545 [2:46:35<2:42:20,  3.99s/it] 46%|████▋     | 2103/4545 [2:46:39<2:41:17,  3.96s/it] 46%|████▋     | 2104/4545 [2:46:43<2:40:42,  3.95s/it] 46%|████▋     | 2105/4545 [2:46:47<2:41:28,  3.97s/it] 46%|████▋     | 2106/4545 [2:46:51<2:41:03,  3.96s/it] 46%|████▋     | 2107/4545 [2:46:55<2:42:51,  4.01s/it] 46%|████▋     | 2108/4545 [2:46:59<2:42:05,  3.99s/it] 46%|████▋     | 2109/4545 [2:47:03<2:41:28,  3.98s/it] 46%|████▋     | 2110/4545 [2:47:07<2:41:00,  3.97s/it]                                                       {'loss': 0.3094, 'grad_norm': 46.96064758300781, 'learning_rate': 9.171035770900328e-08, 'rewards/chosen': 3.4261717796325684, 'rewards/rejected': -0.111083984375, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.5414061546325684, 'logps/chosen': -508.3999938964844, 'logps/rejected': -266.3999938964844, 'logits/chosen': -6.581250190734863, 'logits/rejected': -6.787499904632568, 'epoch': 1.39}
 46%|████▋     | 2110/4545 [2:47:07<2:41:00,  3.97s/it] 46%|████▋     | 2111/4545 [2:47:11<2:45:58,  4.09s/it] 46%|████▋     | 2112/4545 [2:47:15<2:35:57,  3.85s/it] 46%|████▋     | 2113/4545 [2:47:18<2:36:48,  3.87s/it] 47%|████▋     | 2114/4545 [2:47:22<2:37:18,  3.88s/it] 47%|████▋     | 2115/4545 [2:47:26<2:37:56,  3.90s/it] 47%|████▋     | 2116/4545 [2:47:30<2:38:17,  3.91s/it] 47%|████▋     | 2117/4545 [2:47:34<2:31:30,  3.74s/it] 47%|████▋     | 2118/4545 [2:47:38<2:34:54,  3.83s/it] 47%|████▋     | 2119/4545 [2:47:42<2:39:13,  3.94s/it] 47%|████▋     | 2120/4545 [2:47:45<2:34:16,  3.82s/it]                                                       {'loss': 0.3741, 'grad_norm': 49.71239471435547, 'learning_rate': 9.143863510009096e-08, 'rewards/chosen': 2.826953172683716, 'rewards/rejected': -0.14052733778953552, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.96875, 'logps/chosen': -399.3500061035156, 'logps/rejected': -210.6999969482422, 'logits/chosen': -6.771874904632568, 'logits/rejected': -6.753125190734863, 'epoch': 1.4}
 47%|████▋     | 2120/4545 [2:47:45<2:34:16,  3.82s/it] 47%|████▋     | 2121/4545 [2:47:49<2:36:07,  3.86s/it] 47%|████▋     | 2122/4545 [2:47:53<2:36:55,  3.89s/it] 47%|████▋     | 2123/4545 [2:47:57<2:31:14,  3.75s/it] 47%|████▋     | 2124/4545 [2:48:01<2:35:38,  3.86s/it] 47%|████▋     | 2125/4545 [2:48:05<2:37:38,  3.91s/it] 47%|████▋     | 2126/4545 [2:48:08<2:27:46,  3.67s/it] 47%|████▋     | 2127/4545 [2:48:12<2:30:42,  3.74s/it] 47%|████▋     | 2128/4545 [2:48:16<2:33:02,  3.80s/it] 47%|████▋     | 2129/4545 [2:48:20<2:34:29,  3.84s/it] 47%|████▋     | 2130/4545 [2:48:24<2:35:39,  3.87s/it]                                                       {'loss': 0.3716, 'grad_norm': 35.4084587097168, 'learning_rate': 9.116299790295174e-08, 'rewards/chosen': 2.2548828125, 'rewards/rejected': -0.759765625, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.010937452316284, 'logps/chosen': -345.6499938964844, 'logps/rejected': -142.0749969482422, 'logits/chosen': -6.665625095367432, 'logits/rejected': -6.662499904632568, 'epoch': 1.41}
 47%|████▋     | 2130/4545 [2:48:24<2:35:39,  3.87s/it] 47%|████▋     | 2131/4545 [2:48:28<2:36:43,  3.90s/it] 47%|████▋     | 2132/4545 [2:48:31<2:33:33,  3.82s/it] 47%|████▋     | 2133/4545 [2:48:35<2:35:02,  3.86s/it] 47%|████▋     | 2134/4545 [2:48:39<2:35:45,  3.88s/it] 47%|████▋     | 2135/4545 [2:48:43<2:36:31,  3.90s/it] 47%|████▋     | 2136/4545 [2:48:47<2:36:58,  3.91s/it] 47%|████▋     | 2137/4545 [2:48:51<2:36:24,  3.90s/it] 47%|████▋     | 2138/4545 [2:48:55<2:36:51,  3.91s/it] 47%|████▋     | 2139/4545 [2:48:58<2:27:39,  3.68s/it] 47%|████▋     | 2140/4545 [2:49:02<2:30:38,  3.76s/it]                                                       {'loss': 0.3172, 'grad_norm': 27.018325805664062, 'learning_rate': 9.088347572918121e-08, 'rewards/chosen': 3.410449266433716, 'rewards/rejected': 0.0391845703125, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.3687500953674316, 'logps/chosen': -497.6000061035156, 'logps/rejected': -240.60000610351562, 'logits/chosen': -6.556250095367432, 'logits/rejected': -6.768750190734863, 'epoch': 1.41}
 47%|████▋     | 2140/4545 [2:49:02<2:30:38,  3.76s/it] 47%|████▋     | 2141/4545 [2:49:06<2:32:47,  3.81s/it] 47%|████▋     | 2142/4545 [2:49:10<2:34:17,  3.85s/it] 47%|████▋     | 2143/4545 [2:49:13<2:22:34,  3.56s/it] 47%|████▋     | 2144/4545 [2:49:15<2:12:40,  3.32s/it] 47%|████▋     | 2145/4545 [2:49:19<2:21:50,  3.55s/it] 47%|████▋     | 2146/4545 [2:49:23<2:26:19,  3.66s/it] 47%|████▋     | 2147/4545 [2:49:27<2:28:41,  3.72s/it] 47%|████▋     | 2148/4545 [2:49:31<2:31:09,  3.78s/it] 47%|████▋     | 2149/4545 [2:49:35<2:26:00,  3.66s/it] 47%|████▋     | 2150/4545 [2:49:38<2:29:17,  3.74s/it]                                                       {'loss': 0.3106, 'grad_norm': 41.225852966308594, 'learning_rate': 9.060009860773648e-08, 'rewards/chosen': 1.47265625, 'rewards/rejected': -0.91943359375, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.3890624046325684, 'logps/chosen': -220.5500030517578, 'logps/rejected': -107.07499694824219, 'logits/chosen': -6.793749809265137, 'logits/rejected': -6.771874904632568, 'epoch': 1.42}
 47%|████▋     | 2150/4545 [2:49:39<2:29:17,  3.74s/it] 47%|████▋     | 2151/4545 [2:49:43<2:34:59,  3.88s/it] 47%|████▋     | 2152/4545 [2:49:47<2:35:30,  3.90s/it] 47%|████▋     | 2153/4545 [2:49:51<2:35:28,  3.90s/it] 47%|████▋     | 2154/4545 [2:49:54<2:26:20,  3.67s/it] 47%|████▋     | 2155/4545 [2:49:58<2:30:24,  3.78s/it] 47%|████▋     | 2156/4545 [2:50:00<2:14:10,  3.37s/it] 47%|████▋     | 2157/4545 [2:50:04<2:22:52,  3.59s/it] 47%|████▋     | 2158/4545 [2:50:08<2:26:52,  3.69s/it] 48%|████▊     | 2159/4545 [2:50:11<2:17:26,  3.46s/it] 48%|████▊     | 2160/4545 [2:50:15<2:23:34,  3.61s/it]                                                       {'loss': 0.4055, 'grad_norm': 54.491920471191406, 'learning_rate': 9.031289698171017e-08, 'rewards/chosen': 2.3246092796325684, 'rewards/rejected': -0.4219726622104645, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.748046875, 'logps/chosen': -354.54998779296875, 'logps/rejected': -150.22500610351562, 'logits/chosen': -6.540625095367432, 'logits/rejected': -6.521874904632568, 'epoch': 1.43}
 48%|████▊     | 2160/4545 [2:50:15<2:23:34,  3.61s/it] 48%|████▊     | 2161/4545 [2:50:19<2:22:32,  3.59s/it] 48%|████▊     | 2162/4545 [2:50:22<2:26:35,  3.69s/it] 48%|████▊     | 2163/4545 [2:50:27<2:31:47,  3.82s/it] 48%|████▊     | 2164/4545 [2:50:31<2:33:15,  3.86s/it] 48%|████▊     | 2165/4545 [2:50:35<2:37:06,  3.96s/it] 48%|████▊     | 2166/4545 [2:50:39<2:36:15,  3.94s/it] 48%|████▊     | 2167/4545 [2:50:41<2:23:03,  3.61s/it] 48%|████▊     | 2168/4545 [2:50:45<2:26:43,  3.70s/it] 48%|████▊     | 2169/4545 [2:50:49<2:29:26,  3.77s/it] 48%|████▊     | 2170/4545 [2:50:53<2:26:54,  3.71s/it]                                                       {'loss': 0.375, 'grad_norm': 28.495403289794922, 'learning_rate': 9.002190170505995e-08, 'rewards/chosen': 1.8820312023162842, 'rewards/rejected': -0.6177978515625, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.5003905296325684, 'logps/chosen': -274.29998779296875, 'logps/rejected': -121.5999984741211, 'logits/chosen': -6.918749809265137, 'logits/rejected': -7.115624904632568, 'epoch': 1.43}
 48%|████▊     | 2170/4545 [2:50:53<2:26:54,  3.71s/it] 48%|████▊     | 2171/4545 [2:50:57<2:30:33,  3.81s/it] 48%|████▊     | 2172/4545 [2:51:01<2:35:44,  3.94s/it] 48%|████▊     | 2173/4545 [2:51:05<2:30:54,  3.82s/it] 48%|████▊     | 2174/4545 [2:51:09<2:32:13,  3.85s/it] 48%|████▊     | 2175/4545 [2:51:12<2:25:10,  3.68s/it] 48%|████▊     | 2176/4545 [2:51:16<2:30:08,  3.80s/it] 48%|████▊     | 2177/4545 [2:51:20<2:31:40,  3.84s/it] 48%|████▊     | 2178/4545 [2:51:24<2:32:42,  3.87s/it] 48%|████▊     | 2179/4545 [2:51:27<2:21:51,  3.60s/it] 48%|████▊     | 2180/4545 [2:51:31<2:25:48,  3.70s/it]                                                       {'loss': 0.3015, 'grad_norm': 13.670323371887207, 'learning_rate': 8.972714403929383e-08, 'rewards/chosen': 2.411816358566284, 'rewards/rejected': -0.715624988079071, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.124218702316284, 'logps/chosen': -332.29998779296875, 'logps/rejected': -138.3000030517578, 'logits/chosen': -6.818749904632568, 'logits/rejected': -6.828125, 'epoch': 1.44}
 48%|████▊     | 2180/4545 [2:51:31<2:25:48,  3.70s/it] 48%|████▊     | 2181/4545 [2:51:35<2:28:38,  3.77s/it] 48%|████▊     | 2182/4545 [2:51:38<2:27:00,  3.73s/it] 48%|████▊     | 2183/4545 [2:51:42<2:31:08,  3.84s/it] 48%|████▊     | 2184/4545 [2:51:46<2:32:13,  3.87s/it] 48%|████▊     | 2185/4545 [2:51:51<2:36:49,  3.99s/it] 48%|████▊     | 2186/4545 [2:51:55<2:36:45,  3.99s/it] 48%|████▊     | 2187/4545 [2:51:59<2:36:07,  3.97s/it] 48%|████▊     | 2188/4545 [2:52:02<2:29:17,  3.80s/it] 48%|████▊     | 2189/4545 [2:52:06<2:27:28,  3.76s/it] 48%|████▊     | 2190/4545 [2:52:09<2:23:19,  3.65s/it]                                                       {'loss': 0.3004, 'grad_norm': 28.385778427124023, 'learning_rate': 8.942865565011183e-08, 'rewards/chosen': 1.8181641101837158, 'rewards/rejected': -0.774975597858429, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.59375, 'logps/chosen': -243.4499969482422, 'logps/rejected': -165.8249969482422, 'logits/chosen': -6.931250095367432, 'logits/rejected': -6.800000190734863, 'epoch': 1.45}
 48%|████▊     | 2190/4545 [2:52:09<2:23:19,  3.65s/it] 48%|████▊     | 2191/4545 [2:52:13<2:27:48,  3.77s/it] 48%|████▊     | 2192/4545 [2:52:17<2:29:29,  3.81s/it] 48%|████▊     | 2193/4545 [2:52:21<2:30:27,  3.84s/it] 48%|████▊     | 2194/4545 [2:52:25<2:33:47,  3.92s/it] 48%|████▊     | 2195/4545 [2:52:29<2:33:56,  3.93s/it] 48%|████▊     | 2196/4545 [2:52:33<2:34:02,  3.93s/it] 48%|████▊     | 2197/4545 [2:52:37<2:34:17,  3.94s/it] 48%|████▊     | 2198/4545 [2:52:41<2:34:10,  3.94s/it] 48%|████▊     | 2199/4545 [2:52:45<2:31:22,  3.87s/it] 48%|████▊     | 2200/4545 [2:52:48<2:32:05,  3.89s/it]                                                       {'loss': 0.2872, 'grad_norm': 28.505775451660156, 'learning_rate': 8.912646860400415e-08, 'rewards/chosen': 2.955078125, 'rewards/rejected': -0.31767576932907104, 'rewards/accuracies': 0.875, 'rewards/margins': 3.270312547683716, 'logps/chosen': -435.54998779296875, 'logps/rejected': -233.625, 'logits/chosen': -6.365624904632568, 'logits/rejected': -6.503125190734863, 'epoch': 1.45}
 48%|████▊     | 2200/4545 [2:52:49<2:32:05,  3.89s/it] 48%|████▊     | 2201/4545 [2:52:52<2:24:39,  3.70s/it] 48%|████▊     | 2202/4545 [2:52:55<2:20:27,  3.60s/it] 48%|████▊     | 2203/4545 [2:52:58<2:14:31,  3.45s/it] 48%|████▊     | 2204/4545 [2:53:02<2:17:56,  3.54s/it] 49%|████▊     | 2205/4545 [2:53:06<2:25:55,  3.74s/it] 49%|████▊     | 2206/4545 [2:53:10<2:24:42,  3.71s/it] 49%|████▊     | 2207/4545 [2:53:14<2:27:21,  3.78s/it] 49%|████▊     | 2208/4545 [2:53:18<2:32:39,  3.92s/it] 49%|████▊     | 2209/4545 [2:53:22<2:32:52,  3.93s/it] 49%|████▊     | 2210/4545 [2:53:26<2:32:46,  3.93s/it]                                                       {'loss': 0.3818, 'grad_norm': 45.862857818603516, 'learning_rate': 8.882061536480616e-08, 'rewards/chosen': 1.383203148841858, 'rewards/rejected': -0.77587890625, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.1597657203674316, 'logps/chosen': -231.25, 'logps/rejected': -127.3499984741211, 'logits/chosen': -6.900000095367432, 'logits/rejected': -6.790625095367432, 'epoch': 1.46}
 49%|████▊     | 2210/4545 [2:53:26<2:32:46,  3.93s/it] 49%|████▊     | 2211/4545 [2:53:30<2:33:30,  3.95s/it] 49%|████▊     | 2212/4545 [2:53:34<2:33:40,  3.95s/it] 49%|████▊     | 2213/4545 [2:53:38<2:34:13,  3.97s/it] 49%|████▊     | 2214/4545 [2:53:42<2:32:24,  3.92s/it] 49%|████▊     | 2215/4545 [2:54:10<7:19:10, 11.31s/it] 49%|████▉     | 2216/4545 [2:54:14<5:53:05,  9.10s/it] 49%|████▉     | 2217/4545 [2:54:18<4:54:50,  7.60s/it] 49%|████▉     | 2218/4545 [2:54:22<4:11:56,  6.50s/it] 49%|████▉     | 2219/4545 [2:54:26<3:42:01,  5.73s/it] 49%|████▉     | 2220/4545 [2:54:30<3:20:57,  5.19s/it]                                                       {'loss': 0.3645, 'grad_norm': 26.693199157714844, 'learning_rate': 8.851112879021102e-08, 'rewards/chosen': 2.2777342796325684, 'rewards/rejected': -0.4906249940395355, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.7710938453674316, 'logps/chosen': -322.0, 'logps/rejected': -167.39999389648438, 'logits/chosen': -6.678124904632568, 'logits/rejected': -6.824999809265137, 'epoch': 1.47}
 49%|████▉     | 2220/4545 [2:54:30<3:20:57,  5.19s/it] 49%|████▉     | 2221/4545 [2:54:34<3:03:45,  4.74s/it] 49%|████▉     | 2222/4545 [2:54:37<2:50:32,  4.40s/it] 49%|████▉     | 2223/4545 [2:54:41<2:45:07,  4.27s/it] 49%|████▉     | 2224/4545 [2:54:45<2:41:13,  4.17s/it] 49%|████▉     | 2225/4545 [2:54:49<2:38:18,  4.09s/it] 49%|████▉     | 2226/4545 [2:54:53<2:36:21,  4.05s/it] 49%|████▉     | 2227/4545 [2:54:57<2:32:04,  3.94s/it] 49%|████▉     | 2228/4545 [2:55:01<2:31:51,  3.93s/it] 49%|████▉     | 2229/4545 [2:55:03<2:17:22,  3.56s/it] 49%|████▉     | 2230/4545 [2:55:07<2:21:41,  3.67s/it]                                                       {'loss': 0.3515, 'grad_norm': 29.8878173828125, 'learning_rate': 8.81980421282396e-08, 'rewards/chosen': 2.7900390625, 'rewards/rejected': -0.27094727754592896, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.0621094703674316, 'logps/chosen': -384.95001220703125, 'logps/rejected': -206.14999389648438, 'logits/chosen': -6.587500095367432, 'logits/rejected': -6.525000095367432, 'epoch': 1.47}
 49%|████▉     | 2230/4545 [2:55:07<2:21:41,  3.67s/it] 49%|████▉     | 2231/4545 [2:55:11<2:26:19,  3.79s/it] 49%|████▉     | 2232/4545 [2:55:15<2:25:49,  3.78s/it] 49%|████▉     | 2233/4545 [2:55:19<2:28:13,  3.85s/it] 49%|████▉     | 2234/4545 [2:55:23<2:29:09,  3.87s/it] 49%|████▉     | 2235/4545 [2:55:26<2:20:29,  3.65s/it] 49%|████▉     | 2236/4545 [2:55:30<2:27:27,  3.83s/it] 49%|████▉     | 2237/4545 [2:55:34<2:28:37,  3.86s/it] 49%|████▉     | 2238/4545 [2:55:38<2:29:23,  3.89s/it] 49%|████▉     | 2239/4545 [2:55:42<2:29:55,  3.90s/it] 49%|████▉     | 2240/4545 [2:55:45<2:15:42,  3.53s/it]                                                       {'loss': 0.2858, 'grad_norm': 30.835289001464844, 'learning_rate': 8.788138901366876e-08, 'rewards/chosen': 2.5445313453674316, 'rewards/rejected': -0.528613269329071, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.0718750953674316, 'logps/chosen': -321.79998779296875, 'logps/rejected': -157.35000610351562, 'logits/chosen': -6.709374904632568, 'logits/rejected': -6.784375190734863, 'epoch': 1.48}
 49%|████▉     | 2240/4545 [2:55:45<2:15:42,  3.53s/it] 49%|████▉     | 2241/4545 [2:55:49<2:21:03,  3.67s/it] 49%|████▉     | 2242/4545 [2:55:52<2:15:45,  3.54s/it] 49%|████▉     | 2243/4545 [2:55:56<2:17:29,  3.58s/it] 49%|████▉     | 2244/4545 [2:55:58<2:04:58,  3.26s/it] 49%|████▉     | 2245/4545 [2:56:02<2:12:31,  3.46s/it] 49%|████▉     | 2246/4545 [2:56:06<2:17:47,  3.60s/it] 49%|████▉     | 2247/4545 [2:56:10<2:21:45,  3.70s/it] 49%|████▉     | 2248/4545 [2:56:14<2:24:24,  3.77s/it] 49%|████▉     | 2249/4545 [2:56:18<2:27:35,  3.86s/it] 50%|████▉     | 2250/4545 [2:56:22<2:31:50,  3.97s/it]                                                       {'loss': 0.3319, 'grad_norm': 27.196880340576172, 'learning_rate': 8.7561203464418e-08, 'rewards/chosen': 2.093017578125, 'rewards/rejected': -0.603515625, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.6968750953674316, 'logps/chosen': -293.45001220703125, 'logps/rejected': -168.1999969482422, 'logits/chosen': -6.731249809265137, 'logits/rejected': -6.771874904632568, 'epoch': 1.49}
 50%|████▉     | 2250/4545 [2:56:23<2:31:50,  3.97s/it] 50%|████▉     | 2251/4545 [2:56:27<2:34:23,  4.04s/it] 50%|████▉     | 2252/4545 [2:56:30<2:33:19,  4.01s/it] 50%|████▉     | 2253/4545 [2:56:34<2:25:54,  3.82s/it] 50%|████▉     | 2254/4545 [2:56:38<2:27:19,  3.86s/it] 50%|████▉     | 2255/4545 [2:56:41<2:19:21,  3.65s/it] 50%|████▉     | 2256/4545 [2:56:45<2:24:19,  3.78s/it] 50%|████▉     | 2257/4545 [2:56:49<2:27:36,  3.87s/it] 50%|████▉     | 2258/4545 [2:56:53<2:27:15,  3.86s/it] 50%|████▉     | 2259/4545 [2:56:57<2:27:57,  3.88s/it] 50%|████▉     | 2260/4545 [2:57:01<2:28:16,  3.89s/it]                                                       {'loss': 0.3275, 'grad_norm': 43.65753173828125, 'learning_rate': 8.723751987789482e-08, 'rewards/chosen': 2.0547852516174316, 'rewards/rejected': -0.53857421875, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.5960936546325684, 'logps/chosen': -301.8500061035156, 'logps/rejected': -176.1999969482422, 'logits/chosen': -6.871874809265137, 'logits/rejected': -6.793749809265137, 'epoch': 1.49}
 50%|████▉     | 2260/4545 [2:57:01<2:28:16,  3.89s/it] 50%|████▉     | 2261/4545 [2:57:04<2:18:38,  3.64s/it] 50%|████▉     | 2262/4545 [2:57:08<2:21:28,  3.72s/it] 50%|████▉     | 2263/4545 [2:57:12<2:27:43,  3.88s/it] 50%|████▉     | 2264/4545 [2:57:16<2:29:45,  3.94s/it] 50%|████▉     | 2265/4545 [2:57:21<2:37:07,  4.13s/it] 50%|████▉     | 2266/4545 [2:57:25<2:33:39,  4.05s/it] 50%|████▉     | 2267/4545 [2:57:28<2:32:34,  4.02s/it] 50%|████▉     | 2268/4545 [2:57:31<2:18:36,  3.65s/it] 50%|████▉     | 2269/4545 [2:57:35<2:24:37,  3.81s/it] 50%|████▉     | 2270/4545 [2:57:39<2:22:33,  3.76s/it]                                                       {'loss': 0.3086, 'grad_norm': 37.536922454833984, 'learning_rate': 8.691037302729957e-08, 'rewards/chosen': 1.089941382408142, 'rewards/rejected': -0.9522460699081421, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.044140577316284, 'logps/chosen': -172.10000610351562, 'logps/rejected': -107.30000305175781, 'logits/chosen': -6.9375, 'logits/rejected': -6.946875095367432, 'epoch': 1.5}
 50%|████▉     | 2270/4545 [2:57:39<2:22:33,  3.76s/it] 50%|████▉     | 2271/4545 [2:57:43<2:27:10,  3.88s/it] 50%|████▉     | 2272/4545 [2:57:46<2:13:36,  3.53s/it] 50%|█████     | 2273/4545 [2:57:50<2:16:28,  3.60s/it] 50%|█████     | 2274/4545 [2:57:53<2:11:07,  3.46s/it] 50%|█████     | 2275/4545 [2:57:57<2:19:14,  3.68s/it] 50%|█████     | 2276/4545 [2:58:00<2:15:48,  3.59s/it] 50%|█████     | 2277/4545 [2:58:04<2:19:28,  3.69s/it] 50%|█████     | 2278/4545 [2:58:08<2:19:24,  3.69s/it] 50%|█████     | 2279/4545 [2:58:12<2:23:04,  3.79s/it] 50%|█████     | 2280/4545 [2:58:16<2:24:47,  3.84s/it]                                                       {'loss': 0.4249, 'grad_norm': 27.22681427001953, 'learning_rate': 8.657979805788957e-08, 'rewards/chosen': 1.234765648841858, 'rewards/rejected': -0.7972656488418579, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.0335936546325684, 'logps/chosen': -209.3000030517578, 'logps/rejected': -95.9000015258789, 'logits/chosen': -6.896874904632568, 'logits/rejected': -6.953125, 'epoch': 1.5}
 50%|█████     | 2280/4545 [2:58:17<2:24:47,  3.84s/it] 50%|█████     | 2281/4545 [2:58:20<2:29:25,  3.96s/it] 50%|█████     | 2282/4545 [2:58:24<2:23:15,  3.80s/it] 50%|█████     | 2283/4545 [2:58:28<2:25:06,  3.85s/it] 50%|█████     | 2284/4545 [2:58:32<2:26:10,  3.88s/it] 50%|█████     | 2285/4545 [2:58:35<2:20:53,  3.74s/it] 50%|█████     | 2286/4545 [2:58:39<2:22:51,  3.79s/it] 50%|█████     | 2287/4545 [2:58:43<2:24:47,  3.85s/it] 50%|█████     | 2288/4545 [2:58:47<2:25:50,  3.88s/it] 50%|█████     | 2289/4545 [2:58:51<2:26:37,  3.90s/it] 50%|█████     | 2290/4545 [2:58:55<2:27:51,  3.93s/it]                                                       {'loss': 0.3267, 'grad_norm': 50.647098541259766, 'learning_rate': 8.624583048320373e-08, 'rewards/chosen': 3.188671827316284, 'rewards/rejected': -0.368896484375, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.5601563453674316, 'logps/chosen': -438.04998779296875, 'logps/rejected': -229.0749969482422, 'logits/chosen': -6.734375, 'logits/rejected': -6.840624809265137, 'epoch': 1.51}
 50%|█████     | 2290/4545 [2:58:55<2:27:51,  3.93s/it] 50%|█████     | 2291/4545 [2:58:58<2:23:36,  3.82s/it] 50%|█████     | 2292/4545 [2:59:02<2:19:39,  3.72s/it] 50%|█████     | 2293/4545 [2:59:06<2:24:54,  3.86s/it] 50%|█████     | 2294/4545 [2:59:10<2:26:14,  3.90s/it] 50%|█████     | 2295/4545 [2:59:14<2:27:44,  3.94s/it] 51%|█████     | 2296/4545 [2:59:18<2:27:37,  3.94s/it] 51%|█████     | 2297/4545 [2:59:22<2:24:13,  3.85s/it] 51%|█████     | 2298/4545 [2:59:26<2:28:29,  3.97s/it] 51%|█████     | 2299/4545 [2:59:30<2:28:01,  3.95s/it] 51%|█████     | 2300/4545 [2:59:34<2:31:35,  4.05s/it]                                                       {'loss': 0.2895, 'grad_norm': 38.928367614746094, 'learning_rate': 8.590850618124714e-08, 'rewards/chosen': 2.9058594703674316, 'rewards/rejected': -0.6044921875, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.5093750953674316, 'logps/chosen': -404.0, 'logps/rejected': -194.1999969482422, 'logits/chosen': -6.709374904632568, 'logits/rejected': -6.762499809265137, 'epoch': 1.52}
 51%|█████     | 2300/4545 [2:59:34<2:31:35,  4.05s/it] 51%|█████     | 2301/4545 [2:59:38<2:34:29,  4.13s/it] 51%|█████     | 2302/4545 [2:59:42<2:33:03,  4.09s/it] 51%|█████     | 2303/4545 [2:59:46<2:30:28,  4.03s/it] 51%|█████     | 2304/4545 [2:59:50<2:21:26,  3.79s/it] 51%|█████     | 2305/4545 [2:59:53<2:19:59,  3.75s/it] 51%|█████     | 2306/4545 [2:59:57<2:16:03,  3.65s/it] 51%|█████     | 2307/4545 [3:00:01<2:19:22,  3.74s/it] 51%|█████     | 2308/4545 [3:00:05<2:21:29,  3.80s/it] 51%|█████     | 2309/4545 [3:00:08<2:20:55,  3.78s/it] 51%|█████     | 2310/4545 [3:00:12<2:16:06,  3.65s/it]                                                       {'loss': 0.4027, 'grad_norm': 49.9326286315918, 'learning_rate': 8.556786139063679e-08, 'rewards/chosen': 2.16796875, 'rewards/rejected': -0.34257811307907104, 'rewards/accuracies': 0.75, 'rewards/margins': 2.512500047683716, 'logps/chosen': -296.29998779296875, 'logps/rejected': -180.35000610351562, 'logits/chosen': -6.853125095367432, 'logits/rejected': -6.696875095367432, 'epoch': 1.52}
 51%|█████     | 2310/4545 [3:00:12<2:16:06,  3.65s/it] 51%|█████     | 2311/4545 [3:00:16<2:19:50,  3.76s/it] 51%|█████     | 2312/4545 [3:00:20<2:21:49,  3.81s/it] 51%|█████     | 2313/4545 [3:00:23<2:23:09,  3.85s/it] 51%|█████     | 2314/4545 [3:00:27<2:19:46,  3.76s/it] 51%|█████     | 2315/4545 [3:00:31<2:24:52,  3.90s/it] 51%|█████     | 2316/4545 [3:00:35<2:25:12,  3.91s/it] 51%|█████     | 2317/4545 [3:00:39<2:20:42,  3.79s/it] 51%|█████     | 2318/4545 [3:00:43<2:22:37,  3.84s/it] 51%|█████     | 2319/4545 [3:00:47<2:26:45,  3.96s/it] 51%|█████     | 2320/4545 [3:00:51<2:27:37,  3.98s/it]                                                       {'loss': 0.3355, 'grad_norm': 29.874515533447266, 'learning_rate': 8.522393270670845e-08, 'rewards/chosen': 3.0909667015075684, 'rewards/rejected': -0.2674804627895355, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.3609375953674316, 'logps/chosen': -429.95001220703125, 'logps/rejected': -248.39999389648438, 'logits/chosen': -6.696875095367432, 'logits/rejected': -6.565625190734863, 'epoch': 1.53}
 51%|█████     | 2320/4545 [3:00:51<2:27:37,  3.98s/it] 51%|█████     | 2321/4545 [3:00:55<2:25:46,  3.93s/it] 51%|█████     | 2322/4545 [3:00:59<2:25:48,  3.94s/it] 51%|█████     | 2323/4545 [3:01:03<2:25:51,  3.94s/it] 51%|█████     | 2324/4545 [3:01:07<2:25:38,  3.93s/it] 51%|█████     | 2325/4545 [3:01:11<2:25:50,  3.94s/it] 51%|█████     | 2326/4545 [3:01:15<2:29:17,  4.04s/it] 51%|█████     | 2327/4545 [3:01:19<2:28:13,  4.01s/it] 51%|█████     | 2328/4545 [3:01:23<2:28:10,  4.01s/it] 51%|█████     | 2329/4545 [3:01:27<2:29:38,  4.05s/it] 51%|█████▏    | 2330/4545 [3:01:31<2:28:26,  4.02s/it]                                                       {'loss': 0.3324, 'grad_norm': 31.65141487121582, 'learning_rate': 8.48767570775853e-08, 'rewards/chosen': 3.4599609375, 'rewards/rejected': -0.12949219346046448, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.58984375, 'logps/chosen': -490.25, 'logps/rejected': -245.3000030517578, 'logits/chosen': -6.459374904632568, 'logits/rejected': -6.584374904632568, 'epoch': 1.54}
 51%|█████▏    | 2330/4545 [3:01:31<2:28:26,  4.02s/it] 51%|█████▏    | 2331/4545 [3:01:35<2:28:35,  4.03s/it] 51%|█████▏    | 2332/4545 [3:01:39<2:27:11,  3.99s/it] 51%|█████▏    | 2333/4545 [3:01:43<2:28:41,  4.03s/it] 51%|█████▏    | 2334/4545 [3:01:46<2:18:46,  3.77s/it] 51%|█████▏    | 2335/4545 [3:01:50<2:20:38,  3.82s/it] 51%|█████▏    | 2336/4545 [3:01:53<2:14:40,  3.66s/it] 51%|█████▏    | 2337/4545 [3:01:56<1:59:44,  3.25s/it] 51%|█████▏    | 2338/4545 [3:02:00<2:08:35,  3.50s/it] 51%|█████▏    | 2339/4545 [3:02:04<2:13:53,  3.64s/it] 51%|█████▏    | 2340/4545 [3:02:08<2:17:15,  3.74s/it]                                                       {'loss': 0.2905, 'grad_norm': 39.64340591430664, 'learning_rate': 8.452637180020848e-08, 'rewards/chosen': 2.128124952316284, 'rewards/rejected': -0.7689453363418579, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.8960938453674316, 'logps/chosen': -283.45001220703125, 'logps/rejected': -171.10000610351562, 'logits/chosen': -6.928124904632568, 'logits/rejected': -6.903124809265137, 'epoch': 1.54}
 51%|█████▏    | 2340/4545 [3:02:08<2:17:15,  3.74s/it] 52%|█████▏    | 2341/4545 [3:02:12<2:19:41,  3.80s/it] 52%|█████▏    | 2342/4545 [3:02:16<2:22:52,  3.89s/it] 52%|█████▏    | 2343/4545 [3:02:20<2:25:13,  3.96s/it] 52%|█████▏    | 2344/4545 [3:02:24<2:25:06,  3.96s/it] 52%|█████▏    | 2345/4545 [3:02:28<2:24:50,  3.95s/it] 52%|█████▏    | 2346/4545 [3:02:32<2:24:27,  3.94s/it] 52%|█████▏    | 2347/4545 [3:02:36<2:26:38,  4.00s/it] 52%|█████▏    | 2348/4545 [3:02:40<2:26:41,  4.01s/it] 52%|█████▏    | 2349/4545 [3:02:44<2:26:15,  4.00s/it] 52%|█████▏    | 2350/4545 [3:02:47<2:22:45,  3.90s/it]                                                       {'loss': 0.3081, 'grad_norm': 47.39250183105469, 'learning_rate': 8.417281451633048e-08, 'rewards/chosen': 2.504589796066284, 'rewards/rejected': -0.49077147245407104, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 2.9921875, 'logps/chosen': -359.6499938964844, 'logps/rejected': -211.3000030517578, 'logits/chosen': -6.740624904632568, 'logits/rejected': -6.571875095367432, 'epoch': 1.55}
 52%|█████▏    | 2350/4545 [3:02:48<2:22:45,  3.90s/it] 52%|█████▏    | 2351/4545 [3:02:51<2:23:42,  3.93s/it] 52%|█████▏    | 2352/4545 [3:02:55<2:21:21,  3.87s/it] 52%|█████▏    | 2353/4545 [3:02:58<2:10:23,  3.57s/it] 52%|█████▏    | 2354/4545 [3:03:02<2:17:27,  3.76s/it] 52%|█████▏    | 2355/4545 [3:03:06<2:18:35,  3.80s/it] 52%|█████▏    | 2356/4545 [3:03:10<2:23:15,  3.93s/it] 52%|█████▏    | 2357/4545 [3:03:13<2:10:30,  3.58s/it] 52%|█████▏    | 2358/4545 [3:03:17<2:09:54,  3.56s/it] 52%|█████▏    | 2359/4545 [3:03:21<2:15:09,  3.71s/it] 52%|█████▏    | 2360/4545 [3:03:23<2:05:04,  3.43s/it]                                                       {'loss': 0.3362, 'grad_norm': 31.853961944580078, 'learning_rate': 8.381612320847114e-08, 'rewards/chosen': 0.903613269329071, 'rewards/rejected': -1.0529296398162842, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 1.95703125, 'logps/chosen': -157.9499969482422, 'logps/rejected': -107.8499984741211, 'logits/chosen': -6.971875190734863, 'logits/rejected': -6.834374904632568, 'epoch': 1.56}
 52%|█████▏    | 2360/4545 [3:03:23<2:05:04,  3.43s/it] 52%|█████▏    | 2361/4545 [3:03:27<2:11:39,  3.62s/it] 52%|█████▏    | 2362/4545 [3:03:31<2:15:10,  3.72s/it] 52%|█████▏    | 2363/4545 [3:03:35<2:08:43,  3.54s/it] 52%|█████▏    | 2364/4545 [3:03:38<2:13:08,  3.66s/it] 52%|█████▏    | 2365/4545 [3:03:42<2:07:33,  3.51s/it] 52%|█████▏    | 2366/4545 [3:03:46<2:15:27,  3.73s/it] 52%|█████▏    | 2367/4545 [3:03:48<2:01:14,  3.34s/it] 52%|█████▏    | 2368/4545 [3:03:52<2:07:33,  3.52s/it] 52%|█████▏    | 2369/4545 [3:03:56<2:12:49,  3.66s/it] 52%|█████▏    | 2370/4545 [3:03:59<1:59:31,  3.30s/it]                                                       {'loss': 0.3554, 'grad_norm': 19.04940414428711, 'learning_rate': 8.345633619583724e-08, 'rewards/chosen': 1.874609351158142, 'rewards/rejected': -0.3521484434604645, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.221874952316284, 'logps/chosen': -239.39999389648438, 'logps/rejected': -164.125, 'logits/chosen': -6.928124904632568, 'logits/rejected': -6.925000190734863, 'epoch': 1.56}
 52%|█████▏    | 2370/4545 [3:03:59<1:59:31,  3.30s/it] 52%|█████▏    | 2371/4545 [3:04:03<2:07:11,  3.51s/it] 52%|█████▏    | 2372/4545 [3:04:07<2:13:47,  3.69s/it] 52%|█████▏    | 2373/4545 [3:04:11<2:15:16,  3.74s/it] 52%|█████▏    | 2374/4545 [3:04:14<2:05:40,  3.47s/it] 52%|█████▏    | 2375/4545 [3:04:17<2:04:38,  3.45s/it] 52%|█████▏    | 2376/4545 [3:04:21<2:09:59,  3.60s/it] 52%|█████▏    | 2377/4545 [3:04:25<2:15:11,  3.74s/it] 52%|█████▏    | 2378/4545 [3:04:29<2:19:36,  3.87s/it] 52%|█████▏    | 2379/4545 [3:04:33<2:18:48,  3.84s/it] 52%|█████▏    | 2380/4545 [3:04:37<2:19:38,  3.87s/it]                                                       {'loss': 0.2506, 'grad_norm': 23.056838989257812, 'learning_rate': 8.309349213020597e-08, 'rewards/chosen': 1.468359351158142, 'rewards/rejected': -1.2001953125, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.671093702316284, 'logps/chosen': -231.35000610351562, 'logps/rejected': -135.125, 'logits/chosen': -6.712500095367432, 'logits/rejected': -6.903124809265137, 'epoch': 1.57}
 52%|█████▏    | 2380/4545 [3:04:37<2:19:38,  3.87s/it] 52%|█████▏    | 2381/4545 [3:04:40<2:10:10,  3.61s/it] 52%|█████▏    | 2382/4545 [3:04:44<2:14:13,  3.72s/it] 52%|█████▏    | 2383/4545 [3:04:48<2:18:29,  3.84s/it] 52%|█████▏    | 2384/4545 [3:04:52<2:22:03,  3.94s/it] 52%|█████▏    | 2385/4545 [3:04:55<2:14:10,  3.73s/it] 52%|█████▏    | 2386/4545 [3:04:59<2:10:09,  3.62s/it] 53%|█████▎    | 2387/4545 [3:05:03<2:14:04,  3.73s/it] 53%|█████▎    | 2388/4545 [3:05:07<2:16:16,  3.79s/it] 53%|█████▎    | 2389/4545 [3:05:11<2:17:49,  3.84s/it] 53%|█████▎    | 2390/4545 [3:05:14<2:16:30,  3.80s/it]                                                       {'loss': 0.3441, 'grad_norm': 54.620147705078125, 'learning_rate': 8.272762999177247e-08, 'rewards/chosen': 2.2215819358825684, 'rewards/rejected': -0.36738282442092896, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.5921874046325684, 'logps/chosen': -304.0, 'logps/rejected': -212.8249969482422, 'logits/chosen': -6.778124809265137, 'logits/rejected': -6.90625, 'epoch': 1.58}
 53%|█████▎    | 2390/4545 [3:05:14<2:16:30,  3.80s/it] 53%|█████▎    | 2391/4545 [3:05:18<2:14:51,  3.76s/it] 53%|█████▎    | 2392/4545 [3:05:21<2:12:40,  3.70s/it] 53%|█████▎    | 2393/4545 [3:05:25<2:11:07,  3.66s/it] 53%|█████▎    | 2394/4545 [3:05:29<2:15:50,  3.79s/it] 53%|█████▎    | 2395/4545 [3:05:33<2:17:45,  3.84s/it] 53%|█████▎    | 2396/4545 [3:05:36<2:11:17,  3.67s/it] 53%|█████▎    | 2397/4545 [3:05:40<2:09:17,  3.61s/it] 53%|█████▎    | 2398/4545 [3:05:43<2:04:24,  3.48s/it] 53%|█████▎    | 2399/4545 [3:05:47<2:09:34,  3.62s/it] 53%|█████▎    | 2400/4545 [3:05:51<2:16:34,  3.82s/it]                                                       {'loss': 0.3179, 'grad_norm': 45.16211700439453, 'learning_rate': 8.23587890849623e-08, 'rewards/chosen': 1.758398413658142, 'rewards/rejected': -0.872851550579071, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 2.628124952316284, 'logps/chosen': -242.875, 'logps/rejected': -142.25, 'logits/chosen': -6.881249904632568, 'logits/rejected': -7.0625, 'epoch': 1.58}
 53%|█████▎    | 2400/4545 [3:05:51<2:16:34,  3.82s/it] 53%|█████▎    | 2401/4545 [3:05:55<2:18:51,  3.89s/it] 53%|█████▎    | 2402/4545 [3:05:59<2:19:18,  3.90s/it] 53%|█████▎    | 2403/4545 [3:06:03<2:19:39,  3.91s/it] 53%|█████▎    | 2404/4545 [3:06:07<2:19:57,  3.92s/it] 53%|█████▎    | 2405/4545 [3:06:11<2:20:06,  3.93s/it] 53%|█████▎    | 2406/4545 [3:06:15<2:19:35,  3.92s/it] 53%|█████▎    | 2407/4545 [3:06:18<2:10:28,  3.66s/it] 53%|█████▎    | 2408/4545 [3:06:22<2:12:18,  3.71s/it] 53%|█████▎    | 2409/4545 [3:06:26<2:17:52,  3.87s/it] 53%|█████▎    | 2410/4545 [3:06:30<2:18:43,  3.90s/it]                                                       {'loss': 0.2676, 'grad_norm': 20.784990310668945, 'learning_rate': 8.198700903420888e-08, 'rewards/chosen': 2.674023389816284, 'rewards/rejected': -0.9126952886581421, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.586718797683716, 'logps/chosen': -353.3999938964844, 'logps/rejected': -193.22500610351562, 'logits/chosen': -6.887499809265137, 'logits/rejected': -6.837500095367432, 'epoch': 1.59}
 53%|█████▎    | 2410/4545 [3:06:30<2:18:43,  3.90s/it] 53%|█████▎    | 2411/4545 [3:06:34<2:18:46,  3.90s/it] 53%|█████▎    | 2412/4545 [3:06:38<2:19:05,  3.91s/it] 53%|█████▎    | 2413/4545 [3:06:42<2:19:21,  3.92s/it] 53%|█████▎    | 2414/4545 [3:06:46<2:22:52,  4.02s/it] 53%|█████▎    | 2415/4545 [3:06:50<2:20:55,  3.97s/it] 53%|█████▎    | 2416/4545 [3:06:54<2:17:53,  3.89s/it] 53%|█████▎    | 2417/4545 [3:06:58<2:20:22,  3.96s/it] 53%|█████▎    | 2418/4545 [3:07:02<2:20:09,  3.95s/it] 53%|█████▎    | 2419/4545 [3:07:05<2:12:39,  3.74s/it] 53%|█████▎    | 2420/4545 [3:07:08<2:06:31,  3.57s/it]                                                       {'loss': 0.3237, 'grad_norm': 30.779611587524414, 'learning_rate': 8.161232977969675e-08, 'rewards/chosen': 1.35595703125, 'rewards/rejected': -0.8285156488418579, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.1812500953674316, 'logps/chosen': -210.75, 'logps/rejected': -135.89999389648438, 'logits/chosen': -6.981249809265137, 'logits/rejected': -6.859375, 'epoch': 1.6}
 53%|█████▎    | 2420/4545 [3:07:08<2:06:31,  3.57s/it] 53%|█████▎    | 2421/4545 [3:07:37<6:37:14, 11.22s/it] 53%|█████▎    | 2422/4545 [3:07:41<5:20:23,  9.05s/it] 53%|█████▎    | 2423/4545 [3:07:45<4:26:47,  7.54s/it] 53%|█████▎    | 2424/4545 [3:07:49<3:48:39,  6.47s/it] 53%|█████▎    | 2425/4545 [3:07:52<3:10:58,  5.41s/it] 53%|█████▎    | 2426/4545 [3:07:56<2:56:41,  5.00s/it] 53%|█████▎    | 2427/4545 [3:08:00<2:45:27,  4.69s/it] 53%|█████▎    | 2428/4545 [3:08:03<2:23:29,  4.07s/it] 53%|█████▎    | 2429/4545 [3:08:07<2:22:02,  4.03s/it] 53%|█████▎    | 2430/4545 [3:08:10<2:17:44,  3.91s/it]                                                       {'loss': 0.3297, 'grad_norm': 44.45783233642578, 'learning_rate': 8.123479157307072e-08, 'rewards/chosen': 2.109375, 'rewards/rejected': -0.5951172113418579, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.702343702316284, 'logps/chosen': -277.8999938964844, 'logps/rejected': -154.85000610351562, 'logits/chosen': -6.824999809265137, 'logits/rejected': -6.890625, 'epoch': 1.6}
 53%|█████▎    | 2430/4545 [3:08:10<2:17:44,  3.91s/it] 53%|█████▎    | 2431/4545 [3:08:14<2:18:45,  3.94s/it] 54%|█████▎    | 2432/4545 [3:08:18<2:18:44,  3.94s/it] 54%|█████▎    | 2433/4545 [3:08:48<6:49:43, 11.64s/it] 54%|█████▎    | 2434/4545 [3:08:52<5:29:43,  9.37s/it] 54%|█████▎    | 2435/4545 [3:08:55<4:22:52,  7.47s/it] 54%|█████▎    | 2436/4545 [3:08:58<3:34:36,  6.11s/it] 54%|█████▎    | 2437/4545 [3:09:02<3:13:42,  5.51s/it] 54%|█████▎    | 2438/4545 [3:09:06<2:55:41,  5.00s/it] 54%|█████▎    | 2439/4545 [3:09:10<2:41:52,  4.61s/it] 54%|█████▎    | 2440/4545 [3:09:13<2:34:13,  4.40s/it]                                                       {'loss': 0.4131, 'grad_norm': 35.572566986083984, 'learning_rate': 8.085443497311178e-08, 'rewards/chosen': 1.288671851158142, 'rewards/rejected': -0.837353527545929, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.1265625953674316, 'logps/chosen': -190.875, 'logps/rejected': -142.02499389648438, 'logits/chosen': -7.090624809265137, 'logits/rejected': -7.003125190734863, 'epoch': 1.61}
 54%|█████▎    | 2440/4545 [3:09:13<2:34:13,  4.40s/it] 54%|█████▎    | 2441/4545 [3:09:17<2:30:07,  4.28s/it] 54%|█████▎    | 2442/4545 [3:09:21<2:23:57,  4.11s/it] 54%|█████▍    | 2443/4545 [3:09:25<2:22:09,  4.06s/it] 54%|█████▍    | 2444/4545 [3:09:29<2:17:37,  3.93s/it] 54%|█████▍    | 2445/4545 [3:09:33<2:17:38,  3.93s/it] 54%|█████▍    | 2446/4545 [3:09:37<2:16:43,  3.91s/it] 54%|█████▍    | 2447/4545 [3:09:40<2:17:30,  3.93s/it] 54%|█████▍    | 2448/4545 [3:09:45<2:19:11,  3.98s/it] 54%|█████▍    | 2449/4545 [3:09:49<2:18:38,  3.97s/it] 54%|█████▍    | 2450/4545 [3:09:52<2:18:27,  3.97s/it]                                                       {'loss': 0.3749, 'grad_norm': 18.249969482421875, 'learning_rate': 8.047130084137973e-08, 'rewards/chosen': 2.3072266578674316, 'rewards/rejected': -0.4544433653354645, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.763671875, 'logps/chosen': -335.75, 'logps/rejected': -210.5, 'logits/chosen': -6.849999904632568, 'logits/rejected': -6.846875190734863, 'epoch': 1.62}
 54%|█████▍    | 2450/4545 [3:09:53<2:18:27,  3.97s/it] 54%|█████▍    | 2451/4545 [3:09:56<2:12:21,  3.79s/it] 54%|█████▍    | 2452/4545 [3:09:59<2:08:28,  3.68s/it] 54%|█████▍    | 2453/4545 [3:10:03<2:13:20,  3.82s/it] 54%|█████▍    | 2454/4545 [3:10:07<2:14:23,  3.86s/it] 54%|█████▍    | 2455/4545 [3:10:11<2:15:13,  3.88s/it] 54%|█████▍    | 2456/4545 [3:10:15<2:15:51,  3.90s/it] 54%|█████▍    | 2457/4545 [3:10:19<2:15:55,  3.91s/it] 54%|█████▍    | 2458/4545 [3:10:23<2:16:16,  3.92s/it] 54%|█████▍    | 2459/4545 [3:10:27<2:17:11,  3.95s/it] 54%|█████▍    | 2460/4545 [3:10:31<2:18:37,  3.99s/it]                                                       {'loss': 0.4225, 'grad_norm': 39.60953140258789, 'learning_rate': 8.008543033782354e-08, 'rewards/chosen': 2.6421875953674316, 'rewards/rejected': -0.15234375, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.7906250953674316, 'logps/chosen': -388.29998779296875, 'logps/rejected': -214.14999389648438, 'logits/chosen': -6.599999904632568, 'logits/rejected': -6.840624809265137, 'epoch': 1.62}
 54%|█████▍    | 2460/4545 [3:10:31<2:18:37,  3.99s/it] 54%|█████▍    | 2461/4545 [3:10:35<2:16:31,  3.93s/it] 54%|█████▍    | 2462/4545 [3:10:37<2:00:36,  3.47s/it] 54%|█████▍    | 2463/4545 [3:10:41<2:05:35,  3.62s/it] 54%|█████▍    | 2464/4545 [3:10:45<2:08:49,  3.71s/it] 54%|█████▍    | 2465/4545 [3:10:49<2:05:06,  3.61s/it] 54%|█████▍    | 2466/4545 [3:10:52<2:06:07,  3.64s/it] 54%|█████▍    | 2467/4545 [3:10:57<2:12:28,  3.83s/it] 54%|█████▍    | 2468/4545 [3:11:01<2:15:21,  3.91s/it] 54%|█████▍    | 2469/4545 [3:11:05<2:15:40,  3.92s/it] 54%|█████▍    | 2470/4545 [3:11:08<2:13:12,  3.85s/it]                                                       {'loss': 0.3082, 'grad_norm': 42.789337158203125, 'learning_rate': 7.969686491635956e-08, 'rewards/chosen': 1.338281273841858, 'rewards/rejected': -1.0968749523162842, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.4359374046325684, 'logps/chosen': -207.25, 'logps/rejected': -147.25, 'logits/chosen': -6.831250190734863, 'logits/rejected': -6.809374809265137, 'epoch': 1.63}
 54%|█████▍    | 2470/4545 [3:11:08<2:13:12,  3.85s/it] 54%|█████▍    | 2471/4545 [3:11:12<2:14:24,  3.89s/it] 54%|█████▍    | 2472/4545 [3:11:16<2:15:10,  3.91s/it] 54%|█████▍    | 2473/4545 [3:11:20<2:14:33,  3.90s/it] 54%|█████▍    | 2474/4545 [3:11:24<2:13:40,  3.87s/it] 54%|█████▍    | 2475/4545 [3:11:28<2:14:43,  3.91s/it] 54%|█████▍    | 2476/4545 [3:11:31<2:09:11,  3.75s/it] 54%|█████▍    | 2477/4545 [3:11:35<2:06:01,  3.66s/it] 55%|█████▍    | 2478/4545 [3:11:38<2:05:51,  3.65s/it] 55%|█████▍    | 2479/4545 [3:11:42<2:04:11,  3.61s/it] 55%|█████▍    | 2480/4545 [3:11:46<2:10:33,  3.79s/it]                                                       {'loss': 0.4269, 'grad_norm': 42.75623321533203, 'learning_rate': 7.930564632041805e-08, 'rewards/chosen': 0.982592761516571, 'rewards/rejected': -0.8285156488418579, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.810937523841858, 'logps/chosen': -151.10000610351562, 'logps/rejected': -102.5, 'logits/chosen': -7.018750190734863, 'logits/rejected': -6.949999809265137, 'epoch': 1.64}
 55%|█████▍    | 2480/4545 [3:11:46<2:10:33,  3.79s/it] 55%|█████▍    | 2481/4545 [3:11:50<2:14:40,  3.92s/it] 55%|█████▍    | 2482/4545 [3:11:54<2:13:00,  3.87s/it] 55%|█████▍    | 2483/4545 [3:11:58<2:13:22,  3.88s/it] 55%|█████▍    | 2484/4545 [3:12:02<2:14:11,  3.91s/it] 55%|█████▍    | 2485/4545 [3:12:06<2:14:27,  3.92s/it] 55%|█████▍    | 2486/4545 [3:12:08<1:59:47,  3.49s/it] 55%|█████▍    | 2487/4545 [3:12:12<2:00:18,  3.51s/it] 55%|█████▍    | 2488/4545 [3:12:15<1:56:01,  3.38s/it] 55%|█████▍    | 2489/4545 [3:12:19<1:59:11,  3.48s/it] 55%|█████▍    | 2490/4545 [3:12:22<1:55:53,  3.38s/it]                                                       {'loss': 0.4064, 'grad_norm': 36.08372116088867, 'learning_rate': 7.891181657845882e-08, 'rewards/chosen': 1.4207763671875, 'rewards/rejected': -0.9222167730331421, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.3421874046325684, 'logps/chosen': -225.9499969482422, 'logps/rejected': -132.85000610351562, 'logits/chosen': -6.962500095367432, 'logits/rejected': -7.081250190734863, 'epoch': 1.64}
 55%|█████▍    | 2490/4545 [3:12:22<1:55:53,  3.38s/it] 55%|█████▍    | 2491/4545 [3:12:26<2:02:18,  3.57s/it] 55%|█████▍    | 2492/4545 [3:12:30<2:03:06,  3.60s/it] 55%|█████▍    | 2493/4545 [3:12:34<2:06:16,  3.69s/it] 55%|█████▍    | 2494/4545 [3:12:37<2:06:00,  3.69s/it] 55%|█████▍    | 2495/4545 [3:12:41<2:08:34,  3.76s/it] 55%|█████▍    | 2496/4545 [3:12:45<2:10:39,  3.83s/it] 55%|█████▍    | 2497/4545 [3:12:49<2:15:07,  3.96s/it] 55%|█████▍    | 2498/4545 [3:12:53<2:09:03,  3.78s/it] 55%|█████▍    | 2499/4545 [3:12:57<2:10:41,  3.83s/it] 55%|█████▌    | 2500/4545 [3:13:01<2:10:47,  3.84s/it]                                                       {'loss': 0.4019, 'grad_norm': 30.823638916015625, 'learning_rate': 7.851541799945603e-08, 'rewards/chosen': 1.3875000476837158, 'rewards/rejected': -0.839648425579071, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.2265625, 'logps/chosen': -203.5749969482422, 'logps/rejected': -156.97500610351562, 'logits/chosen': -7.006249904632568, 'logits/rejected': -6.903124809265137, 'epoch': 1.65}
 55%|█████▌    | 2500/4545 [3:13:01<2:10:47,  3.84s/it] 55%|█████▌    | 2501/4545 [3:13:04<2:07:50,  3.75s/it] 55%|█████▌    | 2502/4545 [3:13:08<2:09:59,  3.82s/it] 55%|█████▌    | 2503/4545 [3:13:11<2:00:22,  3.54s/it] 55%|█████▌    | 2504/4545 [3:13:15<2:07:18,  3.74s/it] 55%|█████▌    | 2505/4545 [3:13:19<2:09:21,  3.80s/it] 55%|█████▌    | 2506/4545 [3:13:23<2:10:49,  3.85s/it] 55%|█████▌    | 2507/4545 [3:13:27<2:11:45,  3.88s/it] 55%|█████▌    | 2508/4545 [3:13:31<2:12:17,  3.90s/it] 55%|█████▌    | 2509/4545 [3:13:34<2:05:03,  3.69s/it] 55%|█████▌    | 2510/4545 [3:13:36<1:49:25,  3.23s/it]                                                       {'loss': 0.2724, 'grad_norm': 22.720487594604492, 'learning_rate': 7.811649316835297e-08, 'rewards/chosen': 3.030078172683716, 'rewards/rejected': -0.8993164300918579, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.932812452316284, 'logps/chosen': -374.3500061035156, 'logps/rejected': -155.3000030517578, 'logits/chosen': -6.646874904632568, 'logits/rejected': -6.762499809265137, 'epoch': 1.66}
 55%|█████▌    | 2510/4545 [3:13:36<1:49:25,  3.23s/it] 55%|█████▌    | 2511/4545 [3:14:05<6:05:05, 10.77s/it] 55%|█████▌    | 2512/4545 [3:14:09<4:57:59,  8.79s/it] 55%|█████▌    | 2513/4545 [3:14:13<4:08:26,  7.34s/it] 55%|█████▌    | 2514/4545 [3:14:17<3:36:27,  6.39s/it] 55%|█████▌    | 2515/4545 [3:14:21<3:12:22,  5.69s/it] 55%|█████▌    | 2516/4545 [3:14:25<2:54:40,  5.17s/it] 55%|█████▌    | 2517/4545 [3:14:29<2:37:37,  4.66s/it] 55%|█████▌    | 2518/4545 [3:14:32<2:30:17,  4.45s/it] 55%|█████▌    | 2519/4545 [3:14:36<2:25:09,  4.30s/it] 55%|█████▌    | 2520/4545 [3:14:40<2:16:54,  4.06s/it]                                                       {'loss': 0.2843, 'grad_norm': 27.280860900878906, 'learning_rate': 7.771508494148728e-08, 'rewards/chosen': 2.8140625953674316, 'rewards/rejected': -0.873242199420929, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.682812452316284, 'logps/chosen': -393.8500061035156, 'logps/rejected': -179.3000030517578, 'logits/chosen': -6.693749904632568, 'logits/rejected': -6.756249904632568, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [3:14:40<2:16:54,  4.06s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:37,  1.54it/s][A
  5%|▌         | 3/60 [00:02<00:59,  1.04s/it][A
  7%|▋         | 4/60 [00:04<01:10,  1.27s/it][A
  8%|▊         | 5/60 [00:06<01:15,  1.37s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.46s/it][A
 12%|█▏        | 7/60 [00:09<01:25,  1.62s/it][A
 13%|█▎        | 8/60 [00:11<01:26,  1.65s/it][A
 15%|█▌        | 9/60 [00:13<01:24,  1.65s/it][A
 17%|█▋        | 10/60 [00:14<01:21,  1.64s/it][A
 18%|█▊        | 11/60 [00:16<01:21,  1.67s/it][A
 20%|██        | 12/60 [00:18<01:19,  1.66s/it][A
 22%|██▏       | 13/60 [00:19<01:17,  1.65s/it][A
 23%|██▎       | 14/60 [00:21<01:16,  1.65s/it][A
 25%|██▌       | 15/60 [00:22<01:09,  1.55s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.41s/it][A
 28%|██▊       | 17/60 [00:24<00:56,  1.31s/it][A
 30%|███       | 18/60 [00:25<00:46,  1.11s/it][A
 32%|███▏      | 19/60 [00:26<00:47,  1.16s/it][A
 33%|███▎      | 20/60 [00:27<00:40,  1.02s/it][A
 35%|███▌      | 21/60 [00:28<00:39,  1.02s/it][A
 37%|███▋      | 22/60 [00:29<00:42,  1.11s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.12s/it][A
 40%|████      | 24/60 [00:32<00:39,  1.10s/it][A
 42%|████▏     | 25/60 [00:33<00:44,  1.27s/it][A
 43%|████▎     | 26/60 [00:35<00:45,  1.33s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.16s/it][A
 47%|████▋     | 28/60 [00:36<00:35,  1.10s/it][A
 48%|████▊     | 29/60 [00:38<00:34,  1.13s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.29s/it][A
 52%|█████▏    | 31/60 [00:41<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:44<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:46<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:48<00:26,  1.17s/it][A
 63%|██████▎   | 38/60 [00:50<00:28,  1.29s/it][A
 65%|██████▌   | 39/60 [00:51<00:26,  1.24s/it][A
 67%|██████▋   | 40/60 [00:51<00:22,  1.11s/it][A
 68%|██████▊   | 41/60 [00:53<00:23,  1.21s/it][A
 70%|███████   | 42/60 [00:55<00:23,  1.32s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:57<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:58<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:01<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:02<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:07<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:08<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:09<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:11<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:13<00:05,  1.34s/it][A
 95%|█████████▌| 57/60 [01:15<00:04,  1.40s/it][A
 97%|█████████▋| 58/60 [01:16<00:02,  1.40s/it][A
 98%|█████████▊| 59/60 [01:18<00:01,  1.45s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A                                                       
                                               [A{'eval_loss': 0.4186326563358307, 'eval_runtime': 81.5807, 'eval_samples_per_second': 11.682, 'eval_steps_per_second': 0.735, 'eval_rewards/chosen': 2.3788819313049316, 'eval_rewards/rejected': -0.07558390498161316, 'eval_rewards/accuracies': 0.7959490418434143, 'eval_rewards/margins': 2.4526407718658447, 'eval_logps/chosen': -365.6666564941406, 'eval_logps/rejected': -152.40625, 'eval_logits/chosen': -6.620051860809326, 'eval_logits/rejected': -7.294270992279053, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [3:16:02<2:16:54,  4.06s/it]
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 55%|█████▌    | 2521/4545 [3:16:17<17:58:58, 31.99s/it] 55%|█████▌    | 2522/4545 [3:16:21<13:14:46, 23.57s/it] 56%|█████▌    | 2523/4545 [3:16:25<9:55:55, 17.68s/it]  56%|█████▌    | 2524/4545 [3:16:29<7:34:18, 13.49s/it] 56%|█████▌    | 2525/4545 [3:16:31<5:46:20, 10.29s/it] 56%|█████▌    | 2526/4545 [3:16:36<4:45:07,  8.47s/it] 56%|█████▌    | 2527/4545 [3:16:39<3:53:41,  6.95s/it] 56%|█████▌    | 2528/4545 [3:16:43<3:18:01,  5.89s/it] 56%|█████▌    | 2529/4545 [3:16:47<2:59:45,  5.35s/it] 56%|█████▌    | 2530/4545 [3:16:51<2:45:22,  4.92s/it]                                                       {'loss': 0.3921, 'grad_norm': 44.38761901855469, 'learning_rate': 7.731123644198677e-08, 'rewards/chosen': 2.050976514816284, 'rewards/rejected': -0.741015613079071, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.7914061546325684, 'logps/chosen': -292.0, 'logps/rejected': -193.52499389648438, 'logits/chosen': -6.918749809265137, 'logits/rejected': -7.09375, 'epoch': 1.67}
 56%|█████▌    | 2530/4545 [3:16:51<2:45:22,  4.92s/it] 56%|█████▌    | 2531/4545 [3:16:55<2:35:41,  4.64s/it] 56%|█████▌    | 2532/4545 [3:16:59<2:29:14,  4.45s/it] 56%|█████▌    | 2533/4545 [3:17:02<2:22:15,  4.24s/it] 56%|█████▌    | 2534/4545 [3:17:06<2:20:58,  4.21s/it] 56%|█████▌    | 2535/4545 [3:17:09<2:04:01,  3.70s/it] 56%|█████▌    | 2536/4545 [3:17:13<2:06:22,  3.77s/it] 56%|█████▌    | 2537/4545 [3:17:17<2:08:03,  3.83s/it] 56%|█████▌    | 2538/4545 [3:17:19<1:56:05,  3.47s/it] 56%|█████▌    | 2539/4545 [3:17:23<2:01:13,  3.63s/it] 56%|█████▌    | 2540/4545 [3:17:26<1:51:04,  3.32s/it]                                                       {'loss': 0.4142, 'grad_norm': 42.40143585205078, 'learning_rate': 7.690499105513678e-08, 'rewards/chosen': 2.695117235183716, 'rewards/rejected': -0.568066418170929, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.264843702316284, 'logps/chosen': -351.0, 'logps/rejected': -167.375, 'logits/chosen': -6.934374809265137, 'logits/rejected': -6.746874809265137, 'epoch': 1.68}
 56%|█████▌    | 2540/4545 [3:17:26<1:51:04,  3.32s/it] 56%|█████▌    | 2541/4545 [3:17:30<2:00:41,  3.61s/it] 56%|█████▌    | 2542/4545 [3:17:33<1:49:20,  3.28s/it] 56%|█████▌    | 2543/4545 [3:17:37<1:56:53,  3.50s/it] 56%|█████▌    | 2544/4545 [3:17:41<2:02:41,  3.68s/it] 56%|█████▌    | 2545/4545 [3:17:45<2:05:02,  3.75s/it] 56%|█████▌    | 2546/4545 [3:17:47<1:52:47,  3.39s/it] 56%|█████▌    | 2547/4545 [3:17:52<2:00:25,  3.62s/it] 56%|█████▌    | 2548/4545 [3:17:56<2:03:35,  3.71s/it] 56%|█████▌    | 2549/4545 [3:17:59<2:05:39,  3.78s/it] 56%|█████▌    | 2550/4545 [3:18:03<2:06:27,  3.80s/it]                                                       {'loss': 0.3268, 'grad_norm': 33.76457977294922, 'learning_rate': 7.649639242371933e-08, 'rewards/chosen': 1.6332519054412842, 'rewards/rejected': -0.92041015625, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.5531249046325684, 'logps/chosen': -224.97500610351562, 'logps/rejected': -134.97500610351562, 'logits/chosen': -6.965624809265137, 'logits/rejected': -6.884375095367432, 'epoch': 1.68}
 56%|█████▌    | 2550/4545 [3:18:03<2:06:27,  3.80s/it] 56%|█████▌    | 2551/4545 [3:18:07<2:07:49,  3.85s/it] 56%|█████▌    | 2552/4545 [3:18:11<2:11:14,  3.95s/it] 56%|█████▌    | 2553/4545 [3:18:16<2:13:07,  4.01s/it] 56%|█████▌    | 2554/4545 [3:18:20<2:12:14,  3.99s/it] 56%|█████▌    | 2555/4545 [3:18:23<2:11:39,  3.97s/it] 56%|█████▌    | 2556/4545 [3:18:27<2:10:30,  3.94s/it] 56%|█████▋    | 2557/4545 [3:18:31<2:10:25,  3.94s/it] 56%|█████▋    | 2558/4545 [3:18:35<2:11:00,  3.96s/it] 56%|█████▋    | 2559/4545 [3:18:39<2:04:33,  3.76s/it] 56%|█████▋    | 2560/4545 [3:18:42<2:03:43,  3.74s/it]                                                       {'loss': 0.3536, 'grad_norm': 32.465492248535156, 'learning_rate': 7.608548444332458e-08, 'rewards/chosen': 2.4478516578674316, 'rewards/rejected': -0.588085949420929, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.0374999046325684, 'logps/chosen': -354.29998779296875, 'logps/rejected': -200.4250030517578, 'logits/chosen': -6.734375, 'logits/rejected': -6.731249809265137, 'epoch': 1.69}
 56%|█████▋    | 2560/4545 [3:18:42<2:03:43,  3.74s/it] 56%|█████▋    | 2561/4545 [3:18:45<1:52:05,  3.39s/it] 56%|█████▋    | 2562/4545 [3:18:49<1:58:19,  3.58s/it] 56%|█████▋    | 2563/4545 [3:18:51<1:42:19,  3.10s/it] 56%|█████▋    | 2564/4545 [3:18:55<1:51:39,  3.38s/it] 56%|█████▋    | 2565/4545 [3:18:59<1:58:35,  3.59s/it] 56%|█████▋    | 2566/4545 [3:19:02<1:57:26,  3.56s/it] 56%|█████▋    | 2567/4545 [3:19:06<1:58:58,  3.61s/it] 57%|█████▋    | 2568/4545 [3:19:10<1:59:57,  3.64s/it] 57%|█████▋    | 2569/4545 [3:19:14<2:01:00,  3.67s/it] 57%|█████▋    | 2570/4545 [3:19:17<1:53:02,  3.43s/it]                                                       {'loss': 0.2995, 'grad_norm': 33.82420349121094, 'learning_rate': 7.567231125763512e-08, 'rewards/chosen': 1.214453101158142, 'rewards/rejected': -1.309350609779358, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.5257811546325684, 'logps/chosen': -161.9499969482422, 'logps/rejected': -120.1500015258789, 'logits/chosen': -7.071875095367432, 'logits/rejected': -6.856249809265137, 'epoch': 1.7}
 57%|█████▋    | 2570/4545 [3:19:17<1:53:02,  3.43s/it] 57%|█████▋    | 2571/4545 [3:19:20<1:57:07,  3.56s/it] 57%|█████▋    | 2572/4545 [3:19:24<1:58:31,  3.60s/it] 57%|█████▋    | 2573/4545 [3:19:27<1:55:54,  3.53s/it] 57%|█████▋    | 2574/4545 [3:19:32<2:02:01,  3.71s/it] 57%|█████▋    | 2575/4545 [3:19:35<2:04:00,  3.78s/it] 57%|█████▋    | 2576/4545 [3:19:39<2:04:05,  3.78s/it] 57%|█████▋    | 2577/4545 [3:19:43<2:05:31,  3.83s/it] 57%|█████▋    | 2578/4545 [3:19:47<2:06:03,  3.85s/it] 57%|█████▋    | 2579/4545 [3:19:51<2:05:22,  3.83s/it] 57%|█████▋    | 2580/4545 [3:19:55<2:06:25,  3.86s/it]                                                       {'loss': 0.2618, 'grad_norm': 24.46965789794922, 'learning_rate': 7.52569172536837e-08, 'rewards/chosen': 1.832617163658142, 'rewards/rejected': -1.389550805091858, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.2242188453674316, 'logps/chosen': -259.8999938964844, 'logps/rejected': -132.3249969482422, 'logits/chosen': -7.037499904632568, 'logits/rejected': -7.112500190734863, 'epoch': 1.7}
 57%|█████▋    | 2580/4545 [3:19:55<2:06:25,  3.86s/it] 57%|█████▋    | 2581/4545 [3:19:59<2:10:22,  3.98s/it] 57%|█████▋    | 2582/4545 [3:20:03<2:09:36,  3.96s/it] 57%|█████▋    | 2583/4545 [3:20:07<2:09:11,  3.95s/it] 57%|█████▋    | 2584/4545 [3:20:11<2:05:31,  3.84s/it] 57%|█████▋    | 2585/4545 [3:20:14<2:04:39,  3.82s/it] 57%|█████▋    | 2586/4545 [3:20:18<2:05:53,  3.86s/it] 57%|█████▋    | 2587/4545 [3:20:21<1:57:50,  3.61s/it] 57%|█████▋    | 2588/4545 [3:20:25<2:00:51,  3.71s/it] 57%|█████▋    | 2589/4545 [3:20:29<2:05:00,  3.83s/it] 57%|█████▋    | 2590/4545 [3:20:33<2:06:01,  3.87s/it]                                                       {'loss': 0.347, 'grad_norm': 19.547405242919922, 'learning_rate': 7.48393470570846e-08, 'rewards/chosen': 2.085156202316284, 'rewards/rejected': -1.16455078125, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 3.2484374046325684, 'logps/chosen': -281.54998779296875, 'logps/rejected': -131.875, 'logits/chosen': -6.868750095367432, 'logits/rejected': -6.918749809265137, 'epoch': 1.71}
 57%|█████▋    | 2590/4545 [3:20:33<2:06:01,  3.87s/it] 57%|█████▋    | 2591/4545 [3:20:37<2:04:36,  3.83s/it] 57%|█████▋    | 2592/4545 [3:20:41<2:05:55,  3.87s/it] 57%|█████▋    | 2593/4545 [3:20:44<1:59:03,  3.66s/it] 57%|█████▋    | 2594/4545 [3:20:48<2:01:40,  3.74s/it] 57%|█████▋    | 2595/4545 [3:20:52<2:05:08,  3.85s/it] 57%|█████▋    | 2596/4545 [3:20:56<2:05:56,  3.88s/it] 57%|█████▋    | 2597/4545 [3:21:00<2:02:33,  3.77s/it] 57%|█████▋    | 2598/4545 [3:21:04<2:03:56,  3.82s/it] 57%|█████▋    | 2599/4545 [3:21:08<2:06:19,  3.89s/it] 57%|█████▋    | 2600/4545 [3:21:12<2:07:01,  3.92s/it]                                                       {'loss': 0.3154, 'grad_norm': 75.92061614990234, 'learning_rate': 7.441964552723977e-08, 'rewards/chosen': 3.243359327316284, 'rewards/rejected': -0.6622558832168579, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.9046874046325684, 'logps/chosen': -451.70001220703125, 'logps/rejected': -239.60000610351562, 'logits/chosen': -6.618750095367432, 'logits/rejected': -6.784375190734863, 'epoch': 1.72}
 57%|█████▋    | 2600/4545 [3:21:12<2:07:01,  3.92s/it] 57%|█████▋    | 2601/4545 [3:21:16<2:10:02,  4.01s/it] 57%|█████▋    | 2602/4545 [3:21:20<2:06:34,  3.91s/it] 57%|█████▋    | 2603/4545 [3:21:23<2:03:00,  3.80s/it] 57%|█████▋    | 2604/4545 [3:21:27<2:04:09,  3.84s/it] 57%|█████▋    | 2605/4545 [3:21:31<2:05:52,  3.89s/it] 57%|█████▋    | 2606/4545 [3:21:35<2:06:40,  3.92s/it] 57%|█████▋    | 2607/4545 [3:21:39<2:06:44,  3.92s/it] 57%|█████▋    | 2608/4545 [3:21:41<1:52:54,  3.50s/it] 57%|█████▋    | 2609/4545 [3:21:45<1:55:10,  3.57s/it] 57%|█████▋    | 2610/4545 [3:21:49<1:58:37,  3.68s/it]                                                       {'loss': 0.3321, 'grad_norm': 45.37921142578125, 'learning_rate': 7.399785775251933e-08, 'rewards/chosen': 1.1525390148162842, 'rewards/rejected': -1.123437523841858, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.27734375, 'logps/chosen': -169.64999389648438, 'logps/rejected': -151.3000030517578, 'logits/chosen': -7.03125, 'logits/rejected': -6.959374904632568, 'epoch': 1.72}
 57%|█████▋    | 2610/4545 [3:21:49<1:58:37,  3.68s/it] 57%|█████▋    | 2611/4545 [3:21:53<2:01:33,  3.77s/it] 57%|█████▋    | 2612/4545 [3:21:57<2:03:09,  3.82s/it] 57%|█████▋    | 2613/4545 [3:22:01<2:07:09,  3.95s/it] 58%|█████▊    | 2614/4545 [3:22:05<2:09:25,  4.02s/it] 58%|█████▊    | 2615/4545 [3:22:09<2:08:19,  3.99s/it] 58%|█████▊    | 2616/4545 [3:22:13<2:07:51,  3.98s/it] 58%|█████▊    | 2617/4545 [3:22:17<2:00:40,  3.76s/it] 58%|█████▊    | 2618/4545 [3:22:21<2:02:35,  3.82s/it] 58%|█████▊    | 2619/4545 [3:22:24<2:00:44,  3.76s/it] 58%|█████▊    | 2620/4545 [3:22:27<1:51:19,  3.47s/it]                                                       {'loss': 0.3013, 'grad_norm': 29.616302490234375, 'learning_rate': 7.357402904541789e-08, 'rewards/chosen': 2.868945360183716, 'rewards/rejected': -0.6785644292831421, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.55078125, 'logps/chosen': -351.82501220703125, 'logps/rejected': -204.5, 'logits/chosen': -6.965624809265137, 'logits/rejected': -6.659375190734863, 'epoch': 1.73}
 58%|█████▊    | 2620/4545 [3:22:27<1:51:19,  3.47s/it] 58%|█████▊    | 2621/4545 [3:22:30<1:49:29,  3.41s/it] 58%|█████▊    | 2622/4545 [3:22:34<1:54:28,  3.57s/it] 58%|█████▊    | 2623/4545 [3:22:38<1:52:20,  3.51s/it] 58%|█████▊    | 2624/4545 [3:22:42<1:58:07,  3.69s/it] 58%|█████▊    | 2625/4545 [3:22:46<2:00:27,  3.76s/it] 58%|█████▊    | 2626/4545 [3:22:50<2:01:59,  3.81s/it] 58%|█████▊    | 2627/4545 [3:22:54<2:05:06,  3.91s/it] 58%|█████▊    | 2628/4545 [3:22:56<1:50:34,  3.46s/it] 58%|█████▊    | 2629/4545 [3:22:59<1:48:22,  3.39s/it] 58%|█████▊    | 2630/4545 [3:23:03<1:49:35,  3.43s/it]                                                       {'loss': 0.3532, 'grad_norm': 36.303165435791016, 'learning_rate': 7.314820493768666e-08, 'rewards/chosen': 2.021777391433716, 'rewards/rejected': -1.034521460533142, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 3.0570311546325684, 'logps/chosen': -315.8500061035156, 'logps/rejected': -158.3000030517578, 'logits/chosen': -6.881249904632568, 'logits/rejected': -6.709374904632568, 'epoch': 1.74}
 58%|█████▊    | 2630/4545 [3:23:03<1:49:35,  3.43s/it] 58%|█████▊    | 2631/4545 [3:23:07<1:54:55,  3.60s/it] 58%|█████▊    | 2632/4545 [3:23:11<2:00:41,  3.79s/it] 58%|█████▊    | 2633/4545 [3:23:15<2:01:27,  3.81s/it] 58%|█████▊    | 2634/4545 [3:23:19<2:02:49,  3.86s/it] 58%|█████▊    | 2635/4545 [3:23:23<2:06:14,  3.97s/it] 58%|█████▊    | 2636/4545 [3:23:27<2:01:24,  3.82s/it] 58%|█████▊    | 2637/4545 [3:23:31<2:05:43,  3.95s/it] 58%|█████▊    | 2638/4545 [3:23:35<2:05:27,  3.95s/it] 58%|█████▊    | 2639/4545 [3:23:39<2:05:18,  3.94s/it] 58%|█████▊    | 2640/4545 [3:23:43<2:05:11,  3.94s/it]                                                       {'loss': 0.3225, 'grad_norm': 36.58680725097656, 'learning_rate': 7.272043117544196e-08, 'rewards/chosen': 2.2342896461486816, 'rewards/rejected': -0.87890625, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.1148438453674316, 'logps/chosen': -310.1499938964844, 'logps/rejected': -145.60000610351562, 'logits/chosen': -6.803124904632568, 'logits/rejected': -6.643750190734863, 'epoch': 1.74}
 58%|█████▊    | 2640/4545 [3:23:43<2:05:11,  3.94s/it] 58%|█████▊    | 2641/4545 [3:23:47<2:06:36,  3.99s/it] 58%|█████▊    | 2642/4545 [3:23:51<2:06:04,  3.98s/it] 58%|█████▊    | 2643/4545 [3:23:54<2:03:13,  3.89s/it] 58%|█████▊    | 2644/4545 [3:23:58<1:57:28,  3.71s/it] 58%|█████▊    | 2645/4545 [3:24:02<1:59:42,  3.78s/it] 58%|█████▊    | 2646/4545 [3:24:06<2:01:09,  3.83s/it] 58%|█████▊    | 2647/4545 [3:24:09<2:02:12,  3.86s/it] 58%|█████▊    | 2648/4545 [3:24:13<2:02:56,  3.89s/it] 58%|█████▊    | 2649/4545 [3:24:17<2:03:13,  3.90s/it] 58%|█████▊    | 2650/4545 [3:24:21<2:03:26,  3.91s/it]                                                       {'loss': 0.235, 'grad_norm': 21.03708267211914, 'learning_rate': 7.229075371425066e-08, 'rewards/chosen': 3.096484422683716, 'rewards/rejected': -0.9046875238418579, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 3.9984374046325684, 'logps/chosen': -387.25, 'logps/rejected': -191.64999389648438, 'logits/chosen': -6.653124809265137, 'logits/rejected': -6.931250095367432, 'epoch': 1.75}
 58%|█████▊    | 2650/4545 [3:24:21<2:03:26,  3.91s/it] 58%|█████▊    | 2651/4545 [3:24:25<2:03:15,  3.90s/it] 58%|█████▊    | 2652/4545 [3:24:29<2:03:41,  3.92s/it] 58%|█████▊    | 2653/4545 [3:24:33<2:06:01,  4.00s/it] 58%|█████▊    | 2654/4545 [3:24:37<2:05:24,  3.98s/it] 58%|█████▊    | 2655/4545 [3:24:41<2:03:19,  3.92s/it] 58%|█████▊    | 2656/4545 [3:24:45<2:05:53,  4.00s/it] 58%|█████▊    | 2657/4545 [3:24:49<2:02:15,  3.89s/it] 58%|█████▊    | 2658/4545 [3:24:53<2:02:32,  3.90s/it] 59%|█████▊    | 2659/4545 [3:24:57<2:01:17,  3.86s/it] 59%|█████▊    | 2660/4545 [3:25:00<2:01:46,  3.88s/it]                                                       {'loss': 0.3365, 'grad_norm': 30.51411247253418, 'learning_rate': 7.185921871419329e-08, 'rewards/chosen': 2.391796827316284, 'rewards/rejected': -0.964648425579071, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.356250047683716, 'logps/chosen': -350.3500061035156, 'logps/rejected': -184.10000610351562, 'logits/chosen': -6.815625190734863, 'logits/rejected': -6.765625, 'epoch': 1.76}
 59%|█████▊    | 2660/4545 [3:25:01<2:01:46,  3.88s/it] 59%|█████▊    | 2661/4545 [3:25:30<6:07:53, 11.72s/it] 59%|█████▊    | 2662/4545 [3:25:34<4:53:48,  9.36s/it] 59%|█████▊    | 2663/4545 [3:25:38<4:00:38,  7.67s/it] 59%|█████▊    | 2664/4545 [3:25:42<3:25:18,  6.55s/it] 59%|█████▊    | 2665/4545 [3:25:46<2:57:54,  5.68s/it] 59%|█████▊    | 2666/4545 [3:25:50<2:43:22,  5.22s/it] 59%|█████▊    | 2667/4545 [3:25:54<2:33:06,  4.89s/it] 59%|█████▊    | 2668/4545 [3:25:58<2:25:47,  4.66s/it] 59%|█████▊    | 2669/4545 [3:26:02<2:19:39,  4.47s/it] 59%|█████▊    | 2670/4545 [3:26:04<1:59:26,  3.82s/it]                                                       {'loss': 0.3801, 'grad_norm': 43.71108627319336, 'learning_rate': 7.142587253490512e-08, 'rewards/chosen': 1.9450194835662842, 'rewards/rejected': -0.916821300983429, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.866406202316284, 'logps/chosen': -308.67498779296875, 'logps/rejected': -173.9499969482422, 'logits/chosen': -7.003125190734863, 'logits/rejected': -7.065625190734863, 'epoch': 1.76}
 59%|█████▊    | 2670/4545 [3:26:04<1:59:26,  3.82s/it] 59%|█████▉    | 2671/4545 [3:26:07<1:50:15,  3.53s/it] 59%|█████▉    | 2672/4545 [3:26:36<5:50:08, 11.22s/it] 59%|█████▉    | 2673/4545 [3:26:40<4:39:57,  8.97s/it] 59%|█████▉    | 2674/4545 [3:26:44<3:52:44,  7.46s/it] 59%|█████▉    | 2675/4545 [3:27:13<7:17:24, 14.03s/it] 59%|█████▉    | 2676/4545 [3:27:17<5:42:53, 11.01s/it] 59%|█████▉    | 2677/4545 [3:27:21<4:34:43,  8.82s/it] 59%|█████▉    | 2678/4545 [3:27:25<3:48:56,  7.36s/it] 59%|█████▉    | 2679/4545 [3:27:29<3:14:38,  6.26s/it] 59%|█████▉    | 2680/4545 [3:27:33<2:52:59,  5.57s/it]                                                       {'loss': 0.3081, 'grad_norm': 46.60047912597656, 'learning_rate': 7.099076173059557e-08, 'rewards/chosen': 2.315234422683716, 'rewards/rejected': -0.618408203125, 'rewards/accuracies': 0.875, 'rewards/margins': 2.9296875, 'logps/chosen': -322.25, 'logps/rejected': -188.1999969482422, 'logits/chosen': -6.762499809265137, 'logits/rejected': -6.609375, 'epoch': 1.77}
 59%|█████▉    | 2680/4545 [3:27:33<2:52:59,  5.57s/it] 59%|█████▉    | 2681/4545 [3:27:37<2:38:03,  5.09s/it] 59%|█████▉    | 2682/4545 [3:28:09<6:52:57, 13.30s/it] 59%|█████▉    | 2683/4545 [3:28:17<6:00:08, 11.61s/it] 59%|█████▉    | 2684/4545 [3:28:24<5:23:53, 10.44s/it] 59%|█████▉    | 2685/4545 [3:28:32<4:58:57,  9.64s/it] 59%|█████▉    | 2686/4545 [3:28:40<4:42:20,  9.11s/it] 59%|█████▉    | 2687/4545 [3:28:48<4:30:21,  8.73s/it] 59%|█████▉    | 2688/4545 [3:28:55<4:19:02,  8.37s/it] 59%|█████▉    | 2689/4545 [3:29:02<3:58:31,  7.71s/it] 59%|█████▉    | 2690/4545 [3:29:09<3:57:47,  7.69s/it]                                                       {'loss': 0.3734, 'grad_norm': 52.343746185302734, 'learning_rate': 7.055393304504711e-08, 'rewards/chosen': 2.467334032058716, 'rewards/rejected': -0.5390625, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 3.0062499046325684, 'logps/chosen': -335.0, 'logps/rejected': -203.75, 'logits/chosen': -6.896874904632568, 'logits/rejected': -6.934374809265137, 'epoch': 1.78}
 59%|█████▉    | 2690/4545 [3:29:09<3:57:47,  7.69s/it] 59%|█████▉    | 2691/4545 [3:29:17<3:57:27,  7.68s/it] 59%|█████▉    | 2692/4545 [3:29:25<3:56:28,  7.66s/it] 59%|█████▉    | 2693/4545 [3:29:32<3:56:27,  7.66s/it] 59%|█████▉    | 2694/4545 [3:29:40<3:54:02,  7.59s/it] 59%|█████▉    | 2695/4545 [3:29:47<3:52:26,  7.54s/it] 59%|█████▉    | 2696/4545 [3:29:53<3:38:32,  7.09s/it] 59%|█████▉    | 2697/4545 [3:30:01<3:43:42,  7.26s/it] 59%|█████▉    | 2698/4545 [3:30:09<3:47:46,  7.40s/it] 59%|█████▉    | 2699/4545 [3:30:15<3:39:00,  7.12s/it] 59%|█████▉    | 2700/4545 [3:30:23<3:44:23,  7.30s/it]                                                       {'loss': 0.3429, 'grad_norm': 38.79671859741211, 'learning_rate': 7.011543340659352e-08, 'rewards/chosen': 1.8917968273162842, 'rewards/rejected': -1.1296875476837158, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.018749952316284, 'logps/chosen': -272.3999938964844, 'logps/rejected': -142.4499969482422, 'logits/chosen': -6.987500190734863, 'logits/rejected': -7.015625, 'epoch': 1.78}
 59%|█████▉    | 2700/4545 [3:30:23<3:44:23,  7.30s/it] 59%|█████▉    | 2701/4545 [3:30:30<3:41:37,  7.21s/it] 59%|█████▉    | 2702/4545 [3:30:36<3:36:38,  7.05s/it] 59%|█████▉    | 2703/4545 [3:30:44<3:44:25,  7.31s/it] 59%|█████▉    | 2704/4545 [3:30:52<3:47:09,  7.40s/it] 60%|█████▉    | 2705/4545 [3:31:00<3:49:51,  7.50s/it] 60%|█████▉    | 2706/4545 [3:31:07<3:49:42,  7.49s/it] 60%|█████▉    | 2707/4545 [3:31:15<3:51:43,  7.56s/it] 60%|█████▉    | 2708/4545 [3:31:23<3:53:38,  7.63s/it] 60%|█████▉    | 2709/4545 [3:31:30<3:50:34,  7.53s/it] 60%|█████▉    | 2710/4545 [3:31:37<3:47:46,  7.45s/it]                                                       {'loss': 0.2915, 'grad_norm': 29.084468841552734, 'learning_rate': 6.967530992307832e-08, 'rewards/chosen': 1.649804711341858, 'rewards/rejected': -1.258203148841858, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.905468702316284, 'logps/chosen': -222.10000610351562, 'logps/rejected': -137.35000610351562, 'logits/chosen': -7.012499809265137, 'logits/rejected': -7.106249809265137, 'epoch': 1.79}
 60%|█████▉    | 2710/4545 [3:31:37<3:47:46,  7.45s/it] 60%|█████▉    | 2711/4545 [3:31:45<3:49:39,  7.51s/it] 60%|█████▉    | 2712/4545 [3:31:52<3:46:01,  7.40s/it] 60%|█████▉    | 2713/4545 [3:32:00<3:47:43,  7.46s/it] 60%|█████▉    | 2714/4545 [3:32:07<3:49:42,  7.53s/it] 60%|█████▉    | 2715/4545 [3:32:15<3:49:59,  7.54s/it] 60%|█████▉    | 2716/4545 [3:32:21<3:41:47,  7.28s/it] 60%|█████▉    | 2717/4545 [3:32:29<3:45:11,  7.39s/it] 60%|█████▉    | 2718/4545 [3:32:37<3:47:12,  7.46s/it] 60%|█████▉    | 2719/4545 [3:32:44<3:47:56,  7.49s/it] 60%|█████▉    | 2720/4545 [3:32:52<3:49:07,  7.53s/it]                                                       {'loss': 0.3925, 'grad_norm': 37.564476013183594, 'learning_rate': 6.923360987679416e-08, 'rewards/chosen': 1.541601538658142, 'rewards/rejected': -1.1083984375, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.649218797683716, 'logps/chosen': -231.5500030517578, 'logps/rejected': -128.75, 'logits/chosen': -6.909375190734863, 'logits/rejected': -6.9375, 'epoch': 1.8}
 60%|█████▉    | 2720/4545 [3:32:52<3:49:07,  7.53s/it] 60%|█████▉    | 2721/4545 [3:32:58<3:31:13,  6.95s/it] 60%|█████▉    | 2722/4545 [3:33:05<3:37:09,  7.15s/it] 60%|█████▉    | 2723/4545 [3:33:13<3:41:17,  7.29s/it] 60%|█████▉    | 2724/4545 [3:33:20<3:40:29,  7.26s/it] 60%|█████▉    | 2725/4545 [3:33:27<3:41:10,  7.29s/it] 60%|█████▉    | 2726/4545 [3:33:35<3:46:17,  7.46s/it] 60%|██████    | 2727/4545 [3:33:43<3:47:55,  7.52s/it] 60%|██████    | 2728/4545 [3:34:13<7:14:11, 14.34s/it] 60%|██████    | 2729/4545 [3:34:17<5:35:07, 11.07s/it] 60%|██████    | 2730/4545 [3:34:20<4:30:08,  8.93s/it]                                                       {'loss': 0.2802, 'grad_norm': 36.431663513183594, 'learning_rate': 6.879038071940315e-08, 'rewards/chosen': 1.77294921875, 'rewards/rejected': -0.9779297113418579, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 2.7523436546325684, 'logps/chosen': -225.125, 'logps/rejected': -133.64999389648438, 'logits/chosen': -7.206250190734863, 'logits/rejected': -7.262499809265137, 'epoch': 1.8}
 60%|██████    | 2730/4545 [3:34:21<4:30:08,  8.93s/it] 60%|██████    | 2731/4545 [3:34:25<3:45:29,  7.46s/it] 60%|██████    | 2732/4545 [3:34:28<3:13:32,  6.40s/it] 60%|██████    | 2733/4545 [3:34:32<2:49:41,  5.62s/it] 60%|██████    | 2734/4545 [3:34:36<2:31:01,  5.00s/it] 60%|██████    | 2735/4545 [3:34:40<2:22:36,  4.73s/it] 60%|██████    | 2736/4545 [3:34:44<2:15:29,  4.49s/it] 60%|██████    | 2737/4545 [3:34:47<2:04:00,  4.12s/it] 60%|██████    | 2738/4545 [3:34:51<2:04:01,  4.12s/it] 60%|██████    | 2739/4545 [3:34:55<2:02:19,  4.06s/it] 60%|██████    | 2740/4545 [3:34:59<2:01:09,  4.03s/it]                                                       {'loss': 0.314, 'grad_norm': 36.10453796386719, 'learning_rate': 6.834567006683921e-08, 'rewards/chosen': 2.444140672683716, 'rewards/rejected': -0.8119140863418579, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.254687547683716, 'logps/chosen': -316.0, 'logps/rejected': -152.375, 'logits/chosen': -7.03125, 'logits/rejected': -7.165625095367432, 'epoch': 1.81}
 60%|██████    | 2740/4545 [3:34:59<2:01:09,  4.03s/it] 60%|██████    | 2741/4545 [3:35:03<1:57:56,  3.92s/it] 60%|██████    | 2742/4545 [3:35:07<1:58:01,  3.93s/it] 60%|██████    | 2743/4545 [3:35:11<1:58:13,  3.94s/it] 60%|██████    | 2744/4545 [3:35:14<1:50:17,  3.67s/it] 60%|██████    | 2745/4545 [3:35:17<1:49:35,  3.65s/it] 60%|██████    | 2746/4545 [3:35:21<1:53:32,  3.79s/it] 60%|██████    | 2747/4545 [3:35:25<1:52:55,  3.77s/it] 60%|██████    | 2748/4545 [3:35:29<1:50:42,  3.70s/it] 60%|██████    | 2749/4545 [3:35:32<1:47:08,  3.58s/it] 61%|██████    | 2750/4545 [3:35:36<1:51:01,  3.71s/it]                                                       {'loss': 0.3098, 'grad_norm': 25.09029769897461, 'learning_rate': 6.789952569419271e-08, 'rewards/chosen': 1.1206543445587158, 'rewards/rejected': -1.1685059070587158, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.28515625, 'logps/chosen': -164.8000030517578, 'logps/rejected': -123.2249984741211, 'logits/chosen': -7.078125, 'logits/rejected': -7.021874904632568, 'epoch': 1.82}
 61%|██████    | 2750/4545 [3:35:36<1:51:01,  3.71s/it] 61%|██████    | 2751/4545 [3:35:40<1:56:04,  3.88s/it] 61%|██████    | 2752/4545 [3:35:44<1:52:24,  3.76s/it] 61%|██████    | 2753/4545 [3:35:47<1:46:46,  3.58s/it] 61%|██████    | 2754/4545 [3:35:51<1:49:57,  3.68s/it] 61%|██████    | 2755/4545 [3:35:54<1:44:23,  3.50s/it] 61%|██████    | 2756/4545 [3:35:57<1:44:38,  3.51s/it] 61%|██████    | 2757/4545 [3:36:02<1:49:47,  3.68s/it] 61%|██████    | 2758/4545 [3:36:05<1:51:52,  3.76s/it] 61%|██████    | 2759/4545 [3:36:10<1:55:36,  3.88s/it] 61%|██████    | 2760/4545 [3:36:14<1:57:48,  3.96s/it]                                                       {'loss': 0.3403, 'grad_norm': 38.16830062866211, 'learning_rate': 6.745199553057802e-08, 'rewards/chosen': 1.5144531726837158, 'rewards/rejected': -1.134033203125, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.6468749046325684, 'logps/chosen': -212.85000610351562, 'logps/rejected': -140.8000030517578, 'logits/chosen': -7.034375190734863, 'logits/rejected': -6.993750095367432, 'epoch': 1.82}
 61%|██████    | 2760/4545 [3:36:14<1:57:48,  3.96s/it] 61%|██████    | 2761/4545 [3:36:18<1:57:55,  3.97s/it] 61%|██████    | 2762/4545 [3:36:22<1:57:34,  3.96s/it] 61%|██████    | 2763/4545 [3:36:25<1:51:14,  3.75s/it] 61%|██████    | 2764/4545 [3:36:29<1:53:17,  3.82s/it] 61%|██████    | 2765/4545 [3:36:33<1:51:21,  3.75s/it] 61%|██████    | 2766/4545 [3:36:36<1:49:38,  3.70s/it] 61%|██████    | 2767/4545 [3:36:40<1:54:41,  3.87s/it] 61%|██████    | 2768/4545 [3:36:44<1:55:25,  3.90s/it] 61%|██████    | 2769/4545 [3:36:48<1:56:56,  3.95s/it] 61%|██████    | 2770/4545 [3:36:52<1:56:51,  3.95s/it]                                                       {'loss': 0.3341, 'grad_norm': 45.007957458496094, 'learning_rate': 6.700312765398448e-08, 'rewards/chosen': 2.599804639816284, 'rewards/rejected': -0.8285156488418579, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.4296875, 'logps/chosen': -341.3999938964844, 'logps/rejected': -218.5, 'logits/chosen': -6.831250190734863, 'logits/rejected': -6.840624809265137, 'epoch': 1.83}
 61%|██████    | 2770/4545 [3:36:52<1:56:51,  3.95s/it] 61%|██████    | 2771/4545 [3:36:56<1:57:00,  3.96s/it] 61%|██████    | 2772/4545 [3:37:00<1:57:22,  3.97s/it] 61%|██████    | 2773/4545 [3:37:04<1:50:55,  3.76s/it] 61%|██████    | 2774/4545 [3:37:08<1:52:29,  3.81s/it] 61%|██████    | 2775/4545 [3:37:11<1:53:33,  3.85s/it] 61%|██████    | 2776/4545 [3:37:15<1:52:20,  3.81s/it] 61%|██████    | 2777/4545 [3:37:19<1:48:45,  3.69s/it] 61%|██████    | 2778/4545 [3:37:23<1:50:54,  3.77s/it] 61%|██████    | 2779/4545 [3:37:26<1:50:01,  3.74s/it] 61%|██████    | 2780/4545 [3:37:30<1:50:30,  3.76s/it]                                                       {'loss': 0.3205, 'grad_norm': 19.948333740234375, 'learning_rate': 6.655297028611137e-08, 'rewards/chosen': 1.806640625, 'rewards/rejected': -1.0959961414337158, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.903125047683716, 'logps/chosen': -265.0, 'logps/rejected': -167.5, 'logits/chosen': -7.087500095367432, 'logits/rejected': -6.965624809265137, 'epoch': 1.83}
 61%|██████    | 2780/4545 [3:37:30<1:50:30,  3.76s/it] 61%|██████    | 2781/4545 [3:37:34<1:53:35,  3.86s/it] 61%|██████    | 2782/4545 [3:37:38<1:54:06,  3.88s/it] 61%|██████    | 2783/4545 [3:37:42<1:51:09,  3.79s/it] 61%|██████▏   | 2784/4545 [3:37:46<1:54:37,  3.91s/it] 61%|██████▏   | 2785/4545 [3:37:50<1:54:44,  3.91s/it] 61%|██████▏   | 2786/4545 [3:37:54<1:56:57,  3.99s/it] 61%|██████▏   | 2787/4545 [3:37:58<1:56:22,  3.97s/it] 61%|██████▏   | 2788/4545 [3:38:01<1:48:01,  3.69s/it] 61%|██████▏   | 2789/4545 [3:38:05<1:51:29,  3.81s/it] 61%|██████▏   | 2790/4545 [3:38:09<1:52:39,  3.85s/it]                                                       {'loss': 0.3915, 'grad_norm': 38.344112396240234, 'learning_rate': 6.610157178718757e-08, 'rewards/chosen': 1.7091796398162842, 'rewards/rejected': -0.9541015625, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.658984422683716, 'logps/chosen': -251.3000030517578, 'logps/rejected': -163.9499969482422, 'logits/chosen': -6.953125, 'logits/rejected': -6.831250190734863, 'epoch': 1.84}
 61%|██████▏   | 2790/4545 [3:38:09<1:52:39,  3.85s/it] 61%|██████▏   | 2791/4545 [3:38:13<1:53:51,  3.90s/it] 61%|██████▏   | 2792/4545 [3:38:17<1:57:01,  4.01s/it] 61%|██████▏   | 2793/4545 [3:38:21<1:54:52,  3.93s/it] 61%|██████▏   | 2794/4545 [3:38:25<1:54:55,  3.94s/it] 61%|██████▏   | 2795/4545 [3:38:28<1:51:26,  3.82s/it] 62%|██████▏   | 2796/4545 [3:38:32<1:52:24,  3.86s/it] 62%|██████▏   | 2797/4545 [3:38:36<1:48:53,  3.74s/it] 62%|██████▏   | 2798/4545 [3:38:40<1:51:57,  3.85s/it] 62%|██████▏   | 2799/4545 [3:39:09<5:34:31, 11.50s/it] 62%|██████▏   | 2800/4545 [3:39:12<4:15:44,  8.79s/it]                                                       {'loss': 0.3419, 'grad_norm': 16.81606674194336, 'learning_rate': 6.564898065077612e-08, 'rewards/chosen': 1.6865234375, 'rewards/rejected': -0.8857421875, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.572265625, 'logps/chosen': -252.60000610351562, 'logps/rejected': -159.27499389648438, 'logits/chosen': -6.928124904632568, 'logits/rejected': -6.824999809265137, 'epoch': 1.85}
 62%|██████▏   | 2800/4545 [3:39:12<4:15:44,  8.79s/it] 62%|██████▏   | 2801/4545 [3:39:16<3:32:10,  7.30s/it] 62%|██████▏   | 2802/4545 [3:39:18<2:52:42,  5.95s/it] 62%|██████▏   | 2803/4545 [3:39:21<2:28:01,  5.10s/it] 62%|██████▏   | 2804/4545 [3:39:25<2:11:11,  4.52s/it] 62%|██████▏   | 2805/4545 [3:39:28<2:01:15,  4.18s/it] 62%|██████▏   | 2806/4545 [3:39:32<1:59:57,  4.14s/it] 62%|██████▏   | 2807/4545 [3:39:35<1:50:17,  3.81s/it] 62%|██████▏   | 2808/4545 [3:39:39<1:52:45,  3.90s/it] 62%|██████▏   | 2809/4545 [3:39:43<1:53:10,  3.91s/it] 62%|██████▏   | 2810/4545 [3:39:46<1:41:58,  3.53s/it]                                                       {'loss': 0.3261, 'grad_norm': 23.3752498626709, 'learning_rate': 6.519524549856472e-08, 'rewards/chosen': 0.9417968988418579, 'rewards/rejected': -1.3214843273162842, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.2601561546325684, 'logps/chosen': -135.10000610351562, 'logps/rejected': -86.94999694824219, 'logits/chosen': -7.290625095367432, 'logits/rejected': -7.328125, 'epoch': 1.85}
 62%|██████▏   | 2810/4545 [3:39:46<1:41:58,  3.53s/it] 62%|██████▏   | 2811/4545 [3:39:49<1:42:18,  3.54s/it] 62%|██████▏   | 2812/4545 [3:39:54<1:47:36,  3.73s/it] 62%|██████▏   | 2813/4545 [3:40:22<5:24:37, 11.25s/it] 62%|██████▏   | 2814/4545 [3:40:27<4:23:25,  9.13s/it] 62%|██████▏   | 2815/4545 [3:40:30<3:38:06,  7.56s/it] 62%|██████▏   | 2816/4545 [3:40:34<3:07:14,  6.50s/it] 62%|██████▏   | 2817/4545 [3:40:38<2:45:28,  5.75s/it] 62%|██████▏   | 2818/4545 [3:40:42<2:30:49,  5.24s/it] 62%|██████▏   | 2819/4545 [3:40:47<2:21:04,  4.90s/it] 62%|██████▏   | 2820/4545 [3:40:50<2:07:52,  4.45s/it]                                                       {'loss': 0.3341, 'grad_norm': 26.867605209350586, 'learning_rate': 6.474041507514215e-08, 'rewards/chosen': 1.900976538658142, 'rewards/rejected': -1.049902319908142, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.952343702316284, 'logps/chosen': -277.04998779296875, 'logps/rejected': -159.6999969482422, 'logits/chosen': -7.006249904632568, 'logits/rejected': -6.993750095367432, 'epoch': 1.86}
 62%|██████▏   | 2820/4545 [3:40:50<2:07:52,  4.45s/it] 62%|██████▏   | 2821/4545 [3:40:54<2:04:11,  4.32s/it] 62%|██████▏   | 2822/4545 [3:40:57<1:52:45,  3.93s/it] 62%|██████▏   | 2823/4545 [3:40:59<1:36:37,  3.37s/it] 62%|██████▏   | 2824/4545 [3:41:02<1:34:59,  3.31s/it] 62%|██████▏   | 2825/4545 [3:41:06<1:42:51,  3.59s/it] 62%|██████▏   | 2826/4545 [3:41:10<1:46:20,  3.71s/it] 62%|██████▏   | 2827/4545 [3:41:13<1:40:14,  3.50s/it] 62%|██████▏   | 2828/4545 [3:41:17<1:43:53,  3.63s/it] 62%|██████▏   | 2829/4545 [3:41:21<1:45:47,  3.70s/it] 62%|██████▏   | 2830/4545 [3:41:25<1:47:41,  3.77s/it]                                                       {'loss': 0.3542, 'grad_norm': 25.23027229309082, 'learning_rate': 6.42845382427618e-08, 'rewards/chosen': 2.150097608566284, 'rewards/rejected': -1.052001953125, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.2007813453674316, 'logps/chosen': -308.20001220703125, 'logps/rejected': -140.8249969482422, 'logits/chosen': -6.984375, 'logits/rejected': -6.884375095367432, 'epoch': 1.87}
 62%|██████▏   | 2830/4545 [3:41:25<1:47:41,  3.77s/it] 62%|██████▏   | 2831/4545 [3:41:29<1:49:31,  3.83s/it] 62%|██████▏   | 2832/4545 [3:41:32<1:43:56,  3.64s/it] 62%|██████▏   | 2833/4545 [3:41:36<1:46:27,  3.73s/it] 62%|██████▏   | 2834/4545 [3:41:39<1:39:53,  3.50s/it] 62%|██████▏   | 2835/4545 [3:41:43<1:37:29,  3.42s/it] 62%|██████▏   | 2836/4545 [3:41:46<1:34:07,  3.30s/it] 62%|██████▏   | 2837/4545 [3:41:48<1:26:04,  3.02s/it] 62%|██████▏   | 2838/4545 [3:41:52<1:34:11,  3.31s/it] 62%|██████▏   | 2839/4545 [3:41:56<1:39:11,  3.49s/it] 62%|██████▏   | 2840/4545 [3:42:00<1:42:56,  3.62s/it]                                                       {'loss': 0.3463, 'grad_norm': 55.664554595947266, 'learning_rate': 6.382766397609233e-08, 'rewards/chosen': 1.070898413658142, 'rewards/rejected': -1.1589844226837158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.2289061546325684, 'logps/chosen': -173.9499969482422, 'logps/rejected': -130.6999969482422, 'logits/chosen': -7.134375095367432, 'logits/rejected': -7.140625, 'epoch': 1.87}
 62%|██████▏   | 2840/4545 [3:42:00<1:42:56,  3.62s/it] 63%|██████▎   | 2841/4545 [3:42:04<1:46:13,  3.74s/it] 63%|██████▎   | 2842/4545 [3:42:07<1:44:23,  3.68s/it] 63%|██████▎   | 2843/4545 [3:42:11<1:45:41,  3.73s/it] 63%|██████▎   | 2844/4545 [3:42:15<1:47:46,  3.80s/it] 63%|██████▎   | 2845/4545 [3:42:19<1:46:18,  3.75s/it] 63%|██████▎   | 2846/4545 [3:42:23<1:47:49,  3.81s/it] 63%|██████▎   | 2847/4545 [3:42:27<1:51:15,  3.93s/it] 63%|██████▎   | 2848/4545 [3:42:57<5:33:52, 11.80s/it] 63%|██████▎   | 2849/4545 [3:43:01<4:27:01,  9.45s/it] 63%|██████▎   | 2850/4545 [3:43:05<3:40:04,  7.79s/it]                                                       {'loss': 0.3232, 'grad_norm': 45.29332733154297, 'learning_rate': 6.336984135695638e-08, 'rewards/chosen': 2.1083984375, 'rewards/rejected': -1.035668969154358, 'rewards/accuracies': 0.875, 'rewards/margins': 3.140625, 'logps/chosen': -283.3999938964844, 'logps/rejected': -174.375, 'logits/chosen': -7.03125, 'logits/rejected': -7.074999809265137, 'epoch': 1.88}
 63%|██████▎   | 2850/4545 [3:43:05<3:40:04,  7.79s/it] 63%|██████▎   | 2851/4545 [3:43:09<3:07:25,  6.64s/it] 63%|██████▎   | 2852/4545 [3:43:13<2:44:32,  5.83s/it] 63%|██████▎   | 2853/4545 [3:43:17<2:28:32,  5.27s/it] 63%|██████▎   | 2854/4545 [3:43:21<2:17:21,  4.87s/it] 63%|██████▎   | 2855/4545 [3:43:24<2:02:03,  4.33s/it] 63%|██████▎   | 2856/4545 [3:43:27<1:49:10,  3.88s/it] 63%|██████▎   | 2857/4545 [3:43:31<1:50:17,  3.92s/it] 63%|██████▎   | 2858/4545 [3:43:35<1:50:25,  3.93s/it] 63%|██████▎   | 2859/4545 [3:43:39<1:52:37,  4.01s/it] 63%|██████▎   | 2860/4545 [3:43:42<1:48:07,  3.85s/it]                                                       {'loss': 0.3095, 'grad_norm': 30.307588577270508, 'learning_rate': 6.291111956905776e-08, 'rewards/chosen': 2.5716795921325684, 'rewards/rejected': -0.8978515863418579, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.465625047683716, 'logps/chosen': -331.04998779296875, 'logps/rejected': -167.8000030517578, 'logits/chosen': -6.896874904632568, 'logits/rejected': -6.809374809265137, 'epoch': 1.89}
 63%|██████▎   | 2860/4545 [3:43:42<1:48:07,  3.85s/it] 63%|██████▎   | 2861/4545 [3:43:46<1:49:04,  3.89s/it] 63%|██████▎   | 2862/4545 [3:43:50<1:43:35,  3.69s/it] 63%|██████▎   | 2863/4545 [3:43:54<1:46:53,  3.81s/it] 63%|██████▎   | 2864/4545 [3:43:58<1:47:59,  3.85s/it] 63%|██████▎   | 2865/4545 [3:44:01<1:47:37,  3.84s/it] 63%|██████▎   | 2866/4545 [3:44:30<5:13:41, 11.21s/it] 63%|██████▎   | 2867/4545 [3:44:33<4:08:52,  8.90s/it] 63%|██████▎   | 2868/4545 [3:44:37<3:24:30,  7.32s/it] 63%|██████▎   | 2869/4545 [3:44:40<2:52:50,  6.19s/it] 63%|██████▎   | 2870/4545 [3:44:44<2:33:54,  5.51s/it]                                                       {'loss': 0.3224, 'grad_norm': 34.01667404174805, 'learning_rate': 6.245154789269756e-08, 'rewards/chosen': 2.754101514816284, 'rewards/rejected': -0.95166015625, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.7015624046325684, 'logps/chosen': -380.29998779296875, 'logps/rejected': -203.02499389648438, 'logits/chosen': -6.724999904632568, 'logits/rejected': -6.746874809265137, 'epoch': 1.89}
 63%|██████▎   | 2870/4545 [3:44:44<2:33:54,  5.51s/it] 63%|██████▎   | 2871/4545 [3:44:49<2:22:52,  5.12s/it] 63%|██████▎   | 2872/4545 [3:44:52<2:11:03,  4.70s/it] 63%|██████▎   | 2873/4545 [3:44:56<2:06:01,  4.52s/it] 63%|██████▎   | 2874/4545 [3:45:00<2:01:58,  4.38s/it] 63%|██████▎   | 2875/4545 [3:45:04<1:57:02,  4.21s/it] 63%|██████▎   | 2876/4545 [3:45:07<1:46:34,  3.83s/it] 63%|██████▎   | 2877/4545 [3:45:11<1:44:18,  3.75s/it] 63%|██████▎   | 2878/4545 [3:45:15<1:48:27,  3.90s/it] 63%|██████▎   | 2879/4545 [3:45:19<1:50:17,  3.97s/it] 63%|██████▎   | 2880/4545 [3:45:23<1:50:37,  3.99s/it]                                                       {'loss': 0.3797, 'grad_norm': 41.61531448364258, 'learning_rate': 6.199117569948011e-08, 'rewards/chosen': 1.3756835460662842, 'rewards/rejected': -1.157617211341858, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.535937547683716, 'logps/chosen': -209.6999969482422, 'logps/rejected': -107.82499694824219, 'logits/chosen': -6.974999904632568, 'logits/rejected': -6.896874904632568, 'epoch': 1.9}
 63%|██████▎   | 2880/4545 [3:45:23<1:50:37,  3.99s/it] 63%|██████▎   | 2881/4545 [3:45:27<1:48:36,  3.92s/it] 63%|██████▎   | 2882/4545 [3:45:31<1:46:05,  3.83s/it] 63%|██████▎   | 2883/4545 [3:45:34<1:42:09,  3.69s/it] 63%|██████▎   | 2884/4545 [3:45:38<1:44:11,  3.76s/it] 63%|██████▎   | 2885/4545 [3:45:42<1:48:10,  3.91s/it] 63%|██████▎   | 2886/4545 [3:45:46<1:50:48,  4.01s/it] 64%|██████▎   | 2887/4545 [3:45:50<1:51:28,  4.03s/it] 64%|██████▎   | 2888/4545 [3:45:54<1:43:58,  3.76s/it] 64%|██████▎   | 2889/4545 [3:45:58<1:45:29,  3.82s/it] 64%|██████▎   | 2890/4545 [3:46:01<1:45:58,  3.84s/it]                                                       {'loss': 0.2977, 'grad_norm': 45.65605926513672, 'learning_rate': 6.153005244700894e-08, 'rewards/chosen': 1.792089819908142, 'rewards/rejected': -0.8335937261581421, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.628124952316284, 'logps/chosen': -252.5500030517578, 'logps/rejected': -166.85000610351562, 'logits/chosen': -6.918749809265137, 'logits/rejected': -6.887499809265137, 'epoch': 1.91}
 64%|██████▎   | 2890/4545 [3:46:02<1:45:58,  3.84s/it] 64%|██████▎   | 2891/4545 [3:46:05<1:44:38,  3.80s/it] 64%|██████▎   | 2892/4545 [3:46:08<1:36:40,  3.51s/it] 64%|██████▎   | 2893/4545 [3:46:12<1:41:00,  3.67s/it] 64%|██████▎   | 2894/4545 [3:46:16<1:42:40,  3.73s/it] 64%|██████▎   | 2895/4545 [3:46:20<1:44:09,  3.79s/it] 64%|██████▎   | 2896/4545 [3:46:24<1:45:09,  3.83s/it] 64%|██████▎   | 2897/4545 [3:46:28<1:46:14,  3.87s/it] 64%|██████▍   | 2898/4545 [3:46:32<1:46:53,  3.89s/it] 64%|██████▍   | 2899/4545 [3:46:36<1:47:18,  3.91s/it] 64%|██████▍   | 2900/4545 [3:46:40<1:47:36,  3.93s/it]                                                       {'loss': 0.349, 'grad_norm': 17.179359436035156, 'learning_rate': 6.106822767357355e-08, 'rewards/chosen': 3.259765625, 'rewards/rejected': -0.7491210699081421, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 4.00390625, 'logps/chosen': -403.29998779296875, 'logps/rejected': -181.72500610351562, 'logits/chosen': -6.728125095367432, 'logits/rejected': -6.84375, 'epoch': 1.91}
 64%|██████▍   | 2900/4545 [3:46:40<1:47:36,  3.93s/it] 64%|██████▍   | 2901/4545 [3:46:43<1:45:01,  3.83s/it] 64%|██████▍   | 2902/4545 [3:46:47<1:42:52,  3.76s/it] 64%|██████▍   | 2903/4545 [3:46:51<1:43:42,  3.79s/it] 64%|██████▍   | 2904/4545 [3:46:54<1:43:55,  3.80s/it] 64%|██████▍   | 2905/4545 [3:46:58<1:41:51,  3.73s/it] 64%|██████▍   | 2906/4545 [3:47:02<1:43:33,  3.79s/it] 64%|██████▍   | 2907/4545 [3:47:06<1:44:43,  3.84s/it] 64%|██████▍   | 2908/4545 [3:47:10<1:45:10,  3.85s/it] 64%|██████▍   | 2909/4545 [3:47:13<1:41:33,  3.72s/it] 64%|██████▍   | 2910/4545 [3:47:17<1:40:09,  3.68s/it]                                                       {'loss': 0.3218, 'grad_norm': 26.33702850341797, 'learning_rate': 6.060575099282757e-08, 'rewards/chosen': 1.527929663658142, 'rewards/rejected': -1.058203101158142, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.5859375, 'logps/chosen': -212.0500030517578, 'logps/rejected': -143.5500030517578, 'logits/chosen': -7.118750095367432, 'logits/rejected': -7.059374809265137, 'epoch': 1.92}
 64%|██████▍   | 2910/4545 [3:47:17<1:40:09,  3.68s/it] 64%|██████▍   | 2911/4545 [3:47:21<1:46:43,  3.92s/it] 64%|██████▍   | 2912/4545 [3:47:25<1:47:49,  3.96s/it] 64%|██████▍   | 2913/4545 [3:47:29<1:47:37,  3.96s/it] 64%|██████▍   | 2914/4545 [3:47:33<1:49:50,  4.04s/it] 64%|██████▍   | 2915/4545 [3:47:37<1:48:11,  3.98s/it] 64%|██████▍   | 2916/4545 [3:47:41<1:46:36,  3.93s/it] 64%|██████▍   | 2917/4545 [3:47:45<1:46:42,  3.93s/it] 64%|██████▍   | 2918/4545 [3:47:49<1:48:21,  4.00s/it] 64%|██████▍   | 2919/4545 [3:47:53<1:47:04,  3.95s/it] 64%|██████▍   | 2920/4545 [3:47:57<1:46:54,  3.95s/it]                                                       {'loss': 0.3241, 'grad_norm': 31.62450408935547, 'learning_rate': 6.01426720884588e-08, 'rewards/chosen': 2.7554688453674316, 'rewards/rejected': -0.845019519329071, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.5999999046325684, 'logps/chosen': -326.54998779296875, 'logps/rejected': -192.5749969482422, 'logits/chosen': -6.862500190734863, 'logits/rejected': -6.75, 'epoch': 1.93}
 64%|██████▍   | 2920/4545 [3:47:57<1:46:54,  3.95s/it] 64%|██████▍   | 2921/4545 [3:48:01<1:46:04,  3.92s/it] 64%|██████▍   | 2922/4545 [3:48:04<1:35:47,  3.54s/it] 64%|██████▍   | 2923/4545 [3:48:06<1:25:11,  3.15s/it] 64%|██████▍   | 2924/4545 [3:48:10<1:31:37,  3.39s/it] 64%|██████▍   | 2925/4545 [3:48:14<1:37:44,  3.62s/it] 64%|██████▍   | 2926/4545 [3:48:18<1:38:09,  3.64s/it] 64%|██████▍   | 2927/4545 [3:48:22<1:40:36,  3.73s/it] 64%|██████▍   | 2928/4545 [3:48:26<1:44:26,  3.88s/it] 64%|██████▍   | 2929/4545 [3:48:30<1:44:49,  3.89s/it] 64%|██████▍   | 2930/4545 [3:48:33<1:41:33,  3.77s/it]                                                       {'loss': 0.3504, 'grad_norm': 31.10700798034668, 'learning_rate': 5.967904070885169e-08, 'rewards/chosen': 1.912500023841858, 'rewards/rejected': -0.9149414300918579, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.8265624046325684, 'logps/chosen': -242.97500610351562, 'logps/rejected': -157.47500610351562, 'logits/chosen': -6.953125, 'logits/rejected': -6.884375095367432, 'epoch': 1.93}
 64%|██████▍   | 2930/4545 [3:48:33<1:41:33,  3.77s/it] 64%|██████▍   | 2931/4545 [3:48:36<1:33:33,  3.48s/it] 65%|██████▍   | 2932/4545 [3:48:40<1:37:21,  3.62s/it] 65%|██████▍   | 2933/4545 [3:48:44<1:37:46,  3.64s/it] 65%|██████▍   | 2934/4545 [3:48:47<1:38:40,  3.68s/it] 65%|██████▍   | 2935/4545 [3:48:51<1:40:46,  3.76s/it] 65%|██████▍   | 2936/4545 [3:48:55<1:39:57,  3.73s/it] 65%|██████▍   | 2937/4545 [3:48:59<1:39:20,  3.71s/it] 65%|██████▍   | 2938/4545 [3:49:02<1:38:47,  3.69s/it] 65%|██████▍   | 2939/4545 [3:49:06<1:42:17,  3.82s/it] 65%|██████▍   | 2940/4545 [3:49:10<1:44:40,  3.91s/it]                                                       {'loss': 0.3382, 'grad_norm': 60.3095817565918, 'learning_rate': 5.9214906661742837e-08, 'rewards/chosen': 1.007421851158142, 'rewards/rejected': -1.5382812023162842, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.5453124046325684, 'logps/chosen': -170.4499969482422, 'logps/rejected': -126.5999984741211, 'logits/chosen': -7.09375, 'logits/rejected': -6.875, 'epoch': 1.94}
 65%|██████▍   | 2940/4545 [3:49:11<1:44:40,  3.91s/it] 65%|██████▍   | 2941/4545 [3:49:14<1:43:13,  3.86s/it] 65%|██████▍   | 2942/4545 [3:49:18<1:38:58,  3.70s/it] 65%|██████▍   | 2943/4545 [3:49:22<1:42:57,  3.86s/it] 65%|██████▍   | 2944/4545 [3:49:25<1:33:53,  3.52s/it] 65%|██████▍   | 2945/4545 [3:49:29<1:39:12,  3.72s/it] 65%|██████▍   | 2946/4545 [3:49:33<1:42:29,  3.85s/it] 65%|██████▍   | 2947/4545 [3:49:37<1:43:07,  3.87s/it] 65%|██████▍   | 2948/4545 [3:49:41<1:45:01,  3.95s/it] 65%|██████▍   | 2949/4545 [3:50:10<5:05:40, 11.49s/it] 65%|██████▍   | 2950/4545 [3:50:13<3:57:24,  8.93s/it]                                                       {'loss': 0.2325, 'grad_norm': 26.184480667114258, 'learning_rate': 5.875031980887026e-08, 'rewards/chosen': 1.4919922351837158, 'rewards/rejected': -1.6140625476837158, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 3.109375, 'logps/chosen': -205.85000610351562, 'logps/rejected': -114.94999694824219, 'logits/chosen': -7.137499809265137, 'logits/rejected': -7.028124809265137, 'epoch': 1.95}
 65%|██████▍   | 2950/4545 [3:50:13<3:57:24,  8.93s/it] 65%|██████▍   | 2951/4545 [3:50:17<3:17:46,  7.44s/it] 65%|██████▍   | 2952/4545 [3:50:19<2:37:38,  5.94s/it] 65%|██████▍   | 2953/4545 [3:50:24<2:23:57,  5.43s/it] 65%|██████▍   | 2954/4545 [3:50:28<2:12:29,  5.00s/it] 65%|██████▌   | 2955/4545 [3:50:31<2:03:51,  4.67s/it] 65%|██████▌   | 2956/4545 [3:50:34<1:49:04,  4.12s/it] 65%|██████▌   | 2957/4545 [3:50:38<1:47:32,  4.06s/it] 65%|██████▌   | 2958/4545 [3:50:42<1:48:39,  4.11s/it] 65%|██████▌   | 2959/4545 [3:50:47<1:48:08,  4.09s/it] 65%|██████▌   | 2960/4545 [3:50:49<1:33:00,  3.52s/it]                                                       {'loss': 0.3449, 'grad_norm': 27.860319137573242, 'learning_rate': 5.8285330060616697e-08, 'rewards/chosen': 2.25390625, 'rewards/rejected': -0.7383788824081421, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.991406202316284, 'logps/chosen': -305.8999938964844, 'logps/rejected': -189.8000030517578, 'logits/chosen': -6.821875095367432, 'logits/rejected': -6.759375095367432, 'epoch': 1.95}
 65%|██████▌   | 2960/4545 [3:50:49<1:33:00,  3.52s/it] 65%|██████▌   | 2961/4545 [3:50:53<1:37:12,  3.68s/it] 65%|██████▌   | 2962/4545 [3:50:57<1:39:54,  3.79s/it] 65%|██████▌   | 2963/4545 [3:51:01<1:42:32,  3.89s/it] 65%|██████▌   | 2964/4545 [3:51:04<1:39:28,  3.77s/it] 65%|██████▌   | 2965/4545 [3:51:08<1:41:00,  3.84s/it] 65%|██████▌   | 2966/4545 [3:51:12<1:41:50,  3.87s/it] 65%|██████▌   | 2967/4545 [3:51:16<1:37:42,  3.72s/it] 65%|██████▌   | 2968/4545 [3:51:20<1:39:20,  3.78s/it] 65%|██████▌   | 2969/4545 [3:51:24<1:41:48,  3.88s/it] 65%|██████▌   | 2970/4545 [3:51:28<1:42:21,  3.90s/it]                                                       {'loss': 0.3184, 'grad_norm': 23.86806297302246, 'learning_rate': 5.7819987370647824e-08, 'rewards/chosen': 2.508593797683716, 'rewards/rejected': -1.139062523841858, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.649218797683716, 'logps/chosen': -341.6000061035156, 'logps/rejected': -161.35000610351562, 'logits/chosen': -6.915625095367432, 'logits/rejected': -6.775000095367432, 'epoch': 1.96}
 65%|██████▌   | 2970/4545 [3:51:28<1:42:21,  3.90s/it] 65%|██████▌   | 2971/4545 [3:51:32<1:42:50,  3.92s/it] 65%|██████▌   | 2972/4545 [3:51:35<1:40:36,  3.84s/it] 65%|██████▌   | 2973/4545 [3:51:40<1:43:54,  3.97s/it] 65%|██████▌   | 2974/4545 [3:51:43<1:43:11,  3.94s/it] 65%|██████▌   | 2975/4545 [3:51:47<1:43:40,  3.96s/it] 65%|██████▌   | 2976/4545 [3:51:51<1:43:26,  3.96s/it] 66%|██████▌   | 2977/4545 [3:51:55<1:43:34,  3.96s/it] 66%|██████▌   | 2978/4545 [3:52:00<1:44:43,  4.01s/it] 66%|██████▌   | 2979/4545 [3:52:04<1:45:31,  4.04s/it] 66%|██████▌   | 2980/4545 [3:52:08<1:44:43,  4.01s/it]                                                       {'loss': 0.3645, 'grad_norm': 17.530691146850586, 'learning_rate': 5.735434173054562e-08, 'rewards/chosen': 2.7474608421325684, 'rewards/rejected': -0.632031261920929, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.37890625, 'logps/chosen': -401.1000061035156, 'logps/rejected': -214.0500030517578, 'logits/chosen': -6.956250190734863, 'logits/rejected': -6.981249809265137, 'epoch': 1.97}
 66%|██████▌   | 2980/4545 [3:52:08<1:44:43,  4.01s/it] 66%|██████▌   | 2981/4545 [3:52:11<1:39:02,  3.80s/it] 66%|██████▌   | 2982/4545 [3:52:15<1:40:18,  3.85s/it] 66%|██████▌   | 2983/4545 [3:52:18<1:37:56,  3.76s/it] 66%|██████▌   | 2984/4545 [3:52:22<1:38:48,  3.80s/it] 66%|██████▌   | 2985/4545 [3:52:26<1:36:04,  3.70s/it] 66%|██████▌   | 2986/4545 [3:52:30<1:37:53,  3.77s/it] 66%|██████▌   | 2987/4545 [3:52:34<1:39:23,  3.83s/it] 66%|██████▌   | 2988/4545 [3:52:37<1:37:01,  3.74s/it] 66%|██████▌   | 2989/4545 [3:52:41<1:40:16,  3.87s/it] 66%|██████▌   | 2990/4545 [3:52:45<1:41:10,  3.90s/it]                                                       {'loss': 0.3194, 'grad_norm': 22.136823654174805, 'learning_rate': 5.688844316443797e-08, 'rewards/chosen': 1.9163086414337158, 'rewards/rejected': -1.6025390625, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.5218749046325684, 'logps/chosen': -281.3999938964844, 'logps/rejected': -136.14999389648438, 'logits/chosen': -6.918749809265137, 'logits/rejected': -6.828125, 'epoch': 1.97}
 66%|██████▌   | 2990/4545 [3:52:45<1:41:10,  3.90s/it] 66%|██████▌   | 2991/4545 [3:52:49<1:41:54,  3.93s/it] 66%|██████▌   | 2992/4545 [3:52:54<1:44:03,  4.02s/it] 66%|██████▌   | 2993/4545 [3:52:58<1:45:45,  4.09s/it] 66%|██████▌   | 2994/4545 [3:53:02<1:44:28,  4.04s/it] 66%|██████▌   | 2995/4545 [3:53:06<1:43:39,  4.01s/it] 66%|██████▌   | 2996/4545 [3:53:09<1:34:45,  3.67s/it] 66%|██████▌   | 2997/4545 [3:53:12<1:36:42,  3.75s/it] 66%|██████▌   | 2998/4545 [3:53:16<1:36:05,  3.73s/it] 66%|██████▌   | 2999/4545 [3:53:20<1:37:33,  3.79s/it] 66%|██████▌   | 3000/4545 [3:53:24<1:36:06,  3.73s/it]                                                       {'loss': 0.318, 'grad_norm': 35.11859130859375, 'learning_rate': 5.642234172362442e-08, 'rewards/chosen': 2.459765672683716, 'rewards/rejected': -1.116064429283142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.578125, 'logps/chosen': -359.0, 'logps/rejected': -190.8249969482422, 'logits/chosen': -6.953125, 'logits/rejected': -6.912499904632568, 'epoch': 1.98}
 66%|██████▌   | 3000/4545 [3:53:24<1:36:06,  3.73s/it] 66%|██████▌   | 3001/4545 [3:53:28<1:38:04,  3.81s/it] 66%|██████▌   | 3002/4545 [3:53:31<1:36:40,  3.76s/it] 66%|██████▌   | 3003/4545 [3:53:35<1:37:58,  3.81s/it] 66%|██████▌   | 3004/4545 [3:53:39<1:38:50,  3.85s/it] 66%|██████▌   | 3005/4545 [3:53:43<1:41:46,  3.97s/it] 66%|██████▌   | 3006/4545 [3:53:47<1:38:15,  3.83s/it] 66%|██████▌   | 3007/4545 [3:53:51<1:37:45,  3.81s/it] 66%|██████▌   | 3008/4545 [3:53:55<1:38:44,  3.85s/it] 66%|██████▌   | 3009/4545 [3:53:58<1:33:08,  3.64s/it] 66%|██████▌   | 3010/4545 [3:54:01<1:32:19,  3.61s/it]                                                       {'loss': 0.3156, 'grad_norm': 36.4786376953125, 'learning_rate': 5.595608748119933e-08, 'rewards/chosen': 2.322070360183716, 'rewards/rejected': -1.043359398841858, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.366406202316284, 'logps/chosen': -334.6000061035156, 'logps/rejected': -156.89999389648438, 'logits/chosen': -6.803124904632568, 'logits/rejected': -6.856249809265137, 'epoch': 1.99}
 66%|██████▌   | 3010/4545 [3:54:01<1:32:19,  3.61s/it] 66%|██████▌   | 3011/4545 [3:54:05<1:32:28,  3.62s/it] 66%|██████▋   | 3012/4545 [3:54:09<1:34:51,  3.71s/it] 66%|██████▋   | 3013/4545 [3:54:13<1:35:39,  3.75s/it] 66%|██████▋   | 3014/4545 [3:54:17<1:37:05,  3.81s/it] 66%|██████▋   | 3015/4545 [3:54:21<1:38:04,  3.85s/it] 66%|██████▋   | 3016/4545 [3:54:25<1:40:10,  3.93s/it] 66%|██████▋   | 3017/4545 [3:54:27<1:27:47,  3.45s/it] 66%|██████▋   | 3018/4545 [3:54:31<1:31:24,  3.59s/it] 66%|██████▋   | 3019/4545 [3:54:35<1:33:52,  3.69s/it] 66%|██████▋   | 3020/4545 [3:54:38<1:29:33,  3.52s/it]                                                       {'loss': 0.2676, 'grad_norm': 15.659615516662598, 'learning_rate': 5.548973052667244e-08, 'rewards/chosen': 1.9914062023162842, 'rewards/rejected': -1.3957030773162842, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 3.3812499046325684, 'logps/chosen': -239.25, 'logps/rejected': -112.4000015258789, 'logits/chosen': -7.09375, 'logits/rejected': -6.965624809265137, 'epoch': 1.99}
 66%|██████▋   | 3020/4545 [3:54:38<1:29:33,  3.52s/it] 66%|██████▋   | 3021/4545 [3:54:42<1:32:04,  3.62s/it] 66%|██████▋   | 3022/4545 [3:54:45<1:30:07,  3.55s/it] 67%|██████▋   | 3023/4545 [3:54:49<1:32:53,  3.66s/it] 67%|██████▋   | 3024/4545 [3:54:53<1:36:16,  3.80s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:42,  1.36it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.09s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.53s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.63s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.52s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.39s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.08s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.33s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.40s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.40s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.45s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A                                                       
                                               [A{'eval_loss': 0.42966240644454956, 'eval_runtime': 80.7721, 'eval_samples_per_second': 11.799, 'eval_steps_per_second': 0.743, 'eval_rewards/chosen': 2.3635823726654053, 'eval_rewards/rejected': -0.25176799297332764, 'eval_rewards/accuracies': 0.789930522441864, 'eval_rewards/margins': 2.614957571029663, 'eval_logps/chosen': -365.85833740234375, 'eval_logps/rejected': -153.30416870117188, 'eval_logits/chosen': -6.6934895515441895, 'eval_logits/rejected': -7.334374904632568, 'epoch': 2.0}
 67%|██████▋   | 3024/4545 [3:56:14<1:36:16,  3.80s/it]
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 67%|██████▋   | 3025/4545 [3:56:29<13:14:19, 31.35s/it] 67%|██████▋   | 3026/4545 [3:56:33<9:45:01, 23.11s/it]  67%|██████▋   | 3027/4545 [3:56:37<7:18:59, 17.35s/it] 67%|██████▋   | 3028/4545 [3:56:41<5:36:11, 13.30s/it] 67%|██████▋   | 3029/4545 [3:56:45<4:25:07, 10.49s/it] 67%|██████▋   | 3030/4545 [3:56:49<3:35:21,  8.53s/it]                                                       {'loss': 0.318, 'grad_norm': 24.24675750732422, 'learning_rate': 5.5023320960587824e-08, 'rewards/chosen': 4.320703029632568, 'rewards/rejected': -0.14072266221046448, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.458593845367432, 'logps/chosen': -573.5499877929688, 'logps/rejected': -308.1000061035156, 'logits/chosen': -6.571875095367432, 'logits/rejected': -6.681250095367432, 'epoch': 2.0}
 67%|██████▋   | 3030/4545 [3:56:49<3:35:21,  8.53s/it] 67%|██████▋   | 3031/4545 [3:56:52<2:56:34,  7.00s/it] 67%|██████▋   | 3032/4545 [3:56:56<2:33:19,  6.08s/it] 67%|██████▋   | 3033/4545 [3:57:00<2:15:21,  5.37s/it] 67%|██████▋   | 3034/4545 [3:57:03<1:59:29,  4.74s/it] 67%|██████▋   | 3035/4545 [3:57:06<1:50:42,  4.40s/it] 67%|██████▋   | 3036/4545 [3:57:10<1:47:18,  4.27s/it] 67%|██████▋   | 3037/4545 [3:57:14<1:44:52,  4.17s/it] 67%|██████▋   | 3038/4545 [3:57:18<1:43:27,  4.12s/it] 67%|██████▋   | 3039/4545 [3:57:22<1:41:18,  4.04s/it] 67%|██████▋   | 3040/4545 [3:57:26<1:37:16,  3.88s/it]                                                       {'loss': 0.2507, 'grad_norm': 24.195850372314453, 'learning_rate': 5.4556908889141596e-08, 'rewards/chosen': 1.70263671875, 'rewards/rejected': -1.485937476158142, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.1875, 'logps/chosen': -255.64999389648438, 'logps/rejected': -149.5500030517578, 'logits/chosen': -7.0, 'logits/rejected': -6.943749904632568, 'epoch': 2.01}
 67%|██████▋   | 3040/4545 [3:57:26<1:37:16,  3.88s/it] 67%|██████▋   | 3041/4545 [3:57:29<1:34:42,  3.78s/it] 67%|██████▋   | 3042/4545 [3:57:33<1:37:18,  3.88s/it] 67%|██████▋   | 3043/4545 [3:57:38<1:39:08,  3.96s/it] 67%|██████▋   | 3044/4545 [3:57:40<1:27:23,  3.49s/it] 67%|██████▋   | 3045/4545 [3:57:44<1:30:39,  3.63s/it] 67%|██████▋   | 3046/4545 [3:57:47<1:24:45,  3.39s/it] 67%|██████▋   | 3047/4545 [3:57:51<1:28:48,  3.56s/it] 67%|██████▋   | 3048/4545 [3:57:54<1:30:30,  3.63s/it] 67%|██████▋   | 3049/4545 [3:57:58<1:32:48,  3.72s/it] 67%|██████▋   | 3050/4545 [3:58:01<1:27:08,  3.50s/it]                                                       {'loss': 0.3105, 'grad_norm': 31.98021697998047, 'learning_rate': 5.4090544418799e-08, 'rewards/chosen': 2.514697313308716, 'rewards/rejected': -1.096289038658142, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.6070313453674316, 'logps/chosen': -346.25, 'logps/rejected': -140.77499389648438, 'logits/chosen': -6.896874904632568, 'logits/rejected': -7.025000095367432, 'epoch': 2.01}
 67%|██████▋   | 3050/4545 [3:58:02<1:27:08,  3.50s/it] 67%|██████▋   | 3051/4545 [3:58:05<1:31:03,  3.66s/it] 67%|██████▋   | 3052/4545 [3:58:10<1:35:06,  3.82s/it] 67%|██████▋   | 3053/4545 [3:58:14<1:37:07,  3.91s/it] 67%|██████▋   | 3054/4545 [3:58:18<1:37:26,  3.92s/it] 67%|██████▋   | 3055/4545 [3:58:22<1:37:43,  3.93s/it] 67%|██████▋   | 3056/4545 [3:58:26<1:39:32,  4.01s/it] 67%|██████▋   | 3057/4545 [3:58:30<1:38:49,  3.99s/it] 67%|██████▋   | 3058/4545 [3:58:34<1:38:36,  3.98s/it] 67%|██████▋   | 3059/4545 [3:58:38<1:38:17,  3.97s/it] 67%|██████▋   | 3060/4545 [3:58:41<1:34:20,  3.81s/it]                                                       {'loss': 0.3128, 'grad_norm': 28.916549682617188, 'learning_rate': 5.362427765091152e-08, 'rewards/chosen': 2.205676317214966, 'rewards/rejected': -1.176904320716858, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.382031202316284, 'logps/chosen': -298.8500061035156, 'logps/rejected': -174.6750030517578, 'logits/chosen': -6.893750190734863, 'logits/rejected': -6.681250095367432, 'epoch': 2.02}
 67%|██████▋   | 3060/4545 [3:58:41<1:34:20,  3.81s/it] 67%|██████▋   | 3061/4545 [3:58:45<1:35:53,  3.88s/it] 67%|██████▋   | 3062/4545 [3:58:49<1:36:18,  3.90s/it] 67%|██████▋   | 3063/4545 [3:58:53<1:36:34,  3.91s/it] 67%|██████▋   | 3064/4545 [3:58:57<1:35:01,  3.85s/it] 67%|██████▋   | 3065/4545 [3:59:01<1:37:25,  3.95s/it] 67%|██████▋   | 3066/4545 [3:59:04<1:33:24,  3.79s/it] 67%|██████▋   | 3067/4545 [3:59:08<1:34:00,  3.82s/it] 68%|██████▊   | 3068/4545 [3:59:12<1:35:55,  3.90s/it] 68%|██████▊   | 3069/4545 [3:59:16<1:33:07,  3.79s/it] 68%|██████▊   | 3070/4545 [3:59:19<1:26:19,  3.51s/it]                                                       {'loss': 0.3299, 'grad_norm': 24.310508728027344, 'learning_rate': 5.315815867633456e-08, 'rewards/chosen': 1.2152831554412842, 'rewards/rejected': -1.480859398841858, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.6937499046325684, 'logps/chosen': -172.5500030517578, 'logps/rejected': -98.375, 'logits/chosen': -7.118750095367432, 'logits/rejected': -7.125, 'epoch': 2.03}
 68%|██████▊   | 3070/4545 [3:59:19<1:26:19,  3.51s/it] 68%|██████▊   | 3071/4545 [3:59:23<1:31:32,  3.73s/it] 68%|██████▊   | 3072/4545 [3:59:27<1:33:02,  3.79s/it] 68%|██████▊   | 3073/4545 [3:59:31<1:35:31,  3.89s/it] 68%|██████▊   | 3074/4545 [3:59:34<1:31:44,  3.74s/it] 68%|██████▊   | 3075/4545 [3:59:38<1:33:05,  3.80s/it] 68%|██████▊   | 3076/4545 [3:59:42<1:34:03,  3.84s/it] 68%|██████▊   | 3077/4545 [3:59:46<1:34:32,  3.86s/it] 68%|██████▊   | 3078/4545 [3:59:50<1:33:29,  3.82s/it] 68%|██████▊   | 3079/4545 [3:59:54<1:34:16,  3.86s/it] 68%|██████▊   | 3080/4545 [3:59:56<1:25:22,  3.50s/it]                                                       {'loss': 0.2385, 'grad_norm': 24.791738510131836, 'learning_rate': 5.269223757004607e-08, 'rewards/chosen': 2.095898389816284, 'rewards/rejected': -1.267919898033142, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.362499952316284, 'logps/chosen': -282.0, 'logps/rejected': -182.52499389648438, 'logits/chosen': -6.834374904632568, 'logits/rejected': -6.765625, 'epoch': 2.03}
 68%|██████▊   | 3080/4545 [3:59:57<1:25:22,  3.50s/it] 68%|██████▊   | 3081/4545 [4:00:01<1:29:55,  3.69s/it] 68%|██████▊   | 3082/4545 [4:00:04<1:31:03,  3.73s/it] 68%|██████▊   | 3083/4545 [4:00:09<1:33:52,  3.85s/it] 68%|██████▊   | 3084/4545 [4:00:13<1:34:22,  3.88s/it] 68%|██████▊   | 3085/4545 [4:00:16<1:34:10,  3.87s/it] 68%|██████▊   | 3086/4545 [4:00:19<1:23:37,  3.44s/it] 68%|██████▊   | 3087/4545 [4:00:23<1:27:16,  3.59s/it] 68%|██████▊   | 3088/4545 [4:00:27<1:29:51,  3.70s/it] 68%|██████▊   | 3089/4545 [4:00:31<1:31:27,  3.77s/it] 68%|██████▊   | 3090/4545 [4:00:35<1:32:38,  3.82s/it]                                                       {'loss': 0.3535, 'grad_norm': 36.66554260253906, 'learning_rate': 5.2226564385767115e-08, 'rewards/chosen': 2.307812452316284, 'rewards/rejected': -1.0099608898162842, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.317187547683716, 'logps/chosen': -311.07501220703125, 'logps/rejected': -155.39999389648438, 'logits/chosen': -6.896874904632568, 'logits/rejected': -6.837500095367432, 'epoch': 2.04}
 68%|██████▊   | 3090/4545 [4:00:35<1:32:38,  3.82s/it] 68%|██████▊   | 3091/4545 [4:00:38<1:29:27,  3.69s/it] 68%|██████▊   | 3092/4545 [4:00:42<1:28:49,  3.67s/it] 68%|██████▊   | 3093/4545 [4:00:46<1:31:00,  3.76s/it] 68%|██████▊   | 3094/4545 [4:00:49<1:32:07,  3.81s/it] 68%|██████▊   | 3095/4545 [4:00:52<1:22:17,  3.40s/it] 68%|██████▊   | 3096/4545 [4:00:56<1:26:10,  3.57s/it] 68%|██████▊   | 3097/4545 [4:01:00<1:30:04,  3.73s/it] 68%|██████▊   | 3098/4545 [4:01:04<1:31:27,  3.79s/it] 68%|██████▊   | 3099/4545 [4:01:08<1:32:36,  3.84s/it] 68%|██████▊   | 3100/4545 [4:01:12<1:33:17,  3.87s/it]                                                       {'loss': 0.4144, 'grad_norm': 22.227779388427734, 'learning_rate': 5.17611891505846e-08, 'rewards/chosen': 2.76171875, 'rewards/rejected': -0.45317381620407104, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.215625047683716, 'logps/chosen': -346.20001220703125, 'logps/rejected': -208.75, 'logits/chosen': -6.981249809265137, 'logits/rejected': -6.671875, 'epoch': 2.05}
 68%|██████▊   | 3100/4545 [4:01:12<1:33:17,  3.87s/it] 68%|██████▊   | 3101/4545 [4:01:15<1:30:38,  3.77s/it] 68%|██████▊   | 3102/4545 [4:01:19<1:32:04,  3.83s/it] 68%|██████▊   | 3103/4545 [4:01:23<1:33:06,  3.87s/it] 68%|██████▊   | 3104/4545 [4:01:28<1:35:36,  3.98s/it] 68%|██████▊   | 3105/4545 [4:01:30<1:24:14,  3.51s/it] 68%|██████▊   | 3106/4545 [4:01:34<1:28:07,  3.67s/it] 68%|██████▊   | 3107/4545 [4:01:37<1:24:02,  3.51s/it] 68%|██████▊   | 3108/4545 [4:01:41<1:26:59,  3.63s/it] 68%|██████▊   | 3109/4545 [4:01:45<1:30:01,  3.76s/it] 68%|██████▊   | 3110/4545 [4:01:49<1:31:16,  3.82s/it]                                                       {'loss': 0.3456, 'grad_norm': 42.84370803833008, 'learning_rate': 5.129616185957687e-08, 'rewards/chosen': 2.2982420921325684, 'rewards/rejected': -0.907031238079071, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.2085938453674316, 'logps/chosen': -283.54998779296875, 'logps/rejected': -139.10000610351562, 'logits/chosen': -7.068749904632568, 'logits/rejected': -7.006249904632568, 'epoch': 2.05}
 68%|██████▊   | 3110/4545 [4:01:49<1:31:16,  3.82s/it] 68%|██████▊   | 3111/4545 [4:01:53<1:32:21,  3.86s/it] 68%|██████▊   | 3112/4545 [4:01:57<1:35:05,  3.98s/it] 68%|██████▊   | 3113/4545 [4:02:00<1:28:28,  3.71s/it] 69%|██████▊   | 3114/4545 [4:02:04<1:30:09,  3.78s/it] 69%|██████▊   | 3115/4545 [4:02:08<1:31:17,  3.83s/it] 69%|██████▊   | 3116/4545 [4:02:12<1:31:50,  3.86s/it] 69%|██████▊   | 3117/4545 [4:02:16<1:33:20,  3.92s/it] 69%|██████▊   | 3118/4545 [4:02:20<1:33:21,  3.93s/it] 69%|██████▊   | 3119/4545 [4:02:24<1:33:26,  3.93s/it] 69%|██████▊   | 3120/4545 [4:02:28<1:30:38,  3.82s/it]                                                       {'loss': 0.2552, 'grad_norm': 23.97006607055664, 'learning_rate': 5.083153247044277e-08, 'rewards/chosen': 4.016992092132568, 'rewards/rejected': -0.58203125, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.598437309265137, 'logps/chosen': -484.6499938964844, 'logps/rejected': -249.9250030517578, 'logits/chosen': -6.637499809265137, 'logits/rejected': -6.715624809265137, 'epoch': 2.06}
 69%|██████▊   | 3120/4545 [4:02:29<1:30:38,  3.82s/it] 69%|██████▊   | 3121/4545 [4:02:32<1:34:10,  3.97s/it] 69%|██████▊   | 3122/4545 [4:02:36<1:35:55,  4.04s/it] 69%|██████▊   | 3123/4545 [4:02:40<1:35:05,  4.01s/it] 69%|██████▊   | 3124/4545 [4:02:43<1:26:09,  3.64s/it] 69%|██████▉   | 3125/4545 [4:02:47<1:28:39,  3.75s/it] 69%|██████▉   | 3126/4545 [4:02:50<1:22:51,  3.50s/it] 69%|██████▉   | 3127/4545 [4:02:54<1:25:53,  3.63s/it] 69%|██████▉   | 3128/4545 [4:02:58<1:28:54,  3.76s/it] 69%|██████▉   | 3129/4545 [4:03:00<1:19:27,  3.37s/it] 69%|██████▉   | 3130/4545 [4:03:04<1:21:50,  3.47s/it]                                                       {'loss': 0.3025, 'grad_norm': 61.784637451171875, 'learning_rate': 5.0367350898134686e-08, 'rewards/chosen': 2.16796875, 'rewards/rejected': -0.638916015625, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.80859375, 'logps/chosen': -277.625, 'logps/rejected': -199.8000030517578, 'logits/chosen': -7.087500095367432, 'logits/rejected': -6.875, 'epoch': 2.07}
 69%|██████▉   | 3130/4545 [4:03:05<1:21:50,  3.47s/it] 69%|██████▉   | 3131/4545 [4:03:07<1:20:33,  3.42s/it] 69%|██████▉   | 3132/4545 [4:03:12<1:26:27,  3.67s/it] 69%|██████▉   | 3133/4545 [4:03:14<1:20:18,  3.41s/it] 69%|██████▉   | 3134/4545 [4:03:18<1:23:57,  3.57s/it] 69%|██████▉   | 3135/4545 [4:03:22<1:26:34,  3.68s/it] 69%|██████▉   | 3136/4545 [4:03:26<1:29:12,  3.80s/it] 69%|██████▉   | 3137/4545 [4:03:31<1:31:53,  3.92s/it] 69%|██████▉   | 3138/4545 [4:03:33<1:24:22,  3.60s/it] 69%|██████▉   | 3139/4545 [4:03:37<1:24:57,  3.63s/it] 69%|██████▉   | 3140/4545 [4:03:41<1:26:58,  3.71s/it]                                                       {'loss': 0.318, 'grad_norm': 51.31014633178711, 'learning_rate': 4.990366700949626e-08, 'rewards/chosen': 1.8953125476837158, 'rewards/rejected': -0.9837646484375, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.8812499046325684, 'logps/chosen': -254.35000610351562, 'logps/rejected': -176.47500610351562, 'logits/chosen': -7.074999809265137, 'logits/rejected': -6.909375190734863, 'epoch': 2.07}
 69%|██████▉   | 3140/4545 [4:03:41<1:26:58,  3.71s/it] 69%|██████▉   | 3141/4545 [4:03:45<1:29:01,  3.80s/it] 69%|██████▉   | 3142/4545 [4:03:49<1:29:58,  3.85s/it] 69%|██████▉   | 3143/4545 [4:03:52<1:21:35,  3.49s/it] 69%|██████▉   | 3144/4545 [4:03:55<1:22:35,  3.54s/it] 69%|██████▉   | 3145/4545 [4:03:59<1:25:12,  3.65s/it] 69%|██████▉   | 3146/4545 [4:04:03<1:27:10,  3.74s/it] 69%|██████▉   | 3147/4545 [4:04:07<1:28:48,  3.81s/it] 69%|██████▉   | 3148/4545 [4:04:11<1:29:42,  3.85s/it] 69%|██████▉   | 3149/4545 [4:04:14<1:20:51,  3.48s/it] 69%|██████▉   | 3150/4545 [4:04:18<1:24:07,  3.62s/it]                                                       {'loss': 0.3588, 'grad_norm': 61.59639358520508, 'learning_rate': 4.944053061790515e-08, 'rewards/chosen': 2.5626220703125, 'rewards/rejected': -0.8728469610214233, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.4351563453674316, 'logps/chosen': -339.5, 'logps/rejected': -168.0749969482422, 'logits/chosen': -6.768750190734863, 'logits/rejected': -6.706250190734863, 'epoch': 2.08}
 69%|██████▉   | 3150/4545 [4:04:18<1:24:07,  3.62s/it] 69%|██████▉   | 3151/4545 [4:04:22<1:27:57,  3.79s/it] 69%|██████▉   | 3152/4545 [4:04:26<1:29:13,  3.84s/it] 69%|██████▉   | 3153/4545 [4:04:30<1:31:18,  3.94s/it] 69%|██████▉   | 3154/4545 [4:04:34<1:31:10,  3.93s/it] 69%|██████▉   | 3155/4545 [4:04:38<1:30:33,  3.91s/it] 69%|██████▉   | 3156/4545 [4:04:40<1:20:23,  3.47s/it] 69%|██████▉   | 3157/4545 [4:04:44<1:19:39,  3.44s/it] 69%|██████▉   | 3158/4545 [4:04:48<1:23:49,  3.63s/it] 70%|██████▉   | 3159/4545 [4:05:17<4:23:25, 11.40s/it] 70%|██████▉   | 3160/4545 [4:05:21<3:31:32,  9.16s/it]                                                       {'loss': 0.298, 'grad_norm': 47.20470428466797, 'learning_rate': 4.8977991477921596e-08, 'rewards/chosen': 2.263378858566284, 'rewards/rejected': -0.6989501714706421, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.9609375, 'logps/chosen': -290.54998779296875, 'logps/rejected': -221.4250030517578, 'logits/chosen': -6.778124809265137, 'logits/rejected': -6.634375095367432, 'epoch': 2.09}
 70%|██████▉   | 3160/4545 [4:05:21<3:31:32,  9.16s/it] 70%|██████▉   | 3161/4545 [4:05:25<2:52:51,  7.49s/it] 70%|██████▉   | 3162/4545 [4:05:29<2:28:08,  6.43s/it] 70%|██████▉   | 3163/4545 [4:05:32<2:10:08,  5.65s/it] 70%|██████▉   | 3164/4545 [4:05:36<1:55:06,  5.00s/it] 70%|██████▉   | 3165/4545 [4:05:39<1:44:18,  4.53s/it] 70%|██████▉   | 3166/4545 [4:05:43<1:40:02,  4.35s/it] 70%|██████▉   | 3167/4545 [4:05:47<1:37:04,  4.23s/it] 70%|██████▉   | 3168/4545 [4:05:51<1:34:34,  4.12s/it] 70%|██████▉   | 3169/4545 [4:05:55<1:32:50,  4.05s/it] 70%|██████▉   | 3170/4545 [4:05:59<1:33:37,  4.09s/it]                                                       {'loss': 0.2545, 'grad_norm': 18.560089111328125, 'learning_rate': 4.851609927994337e-08, 'rewards/chosen': 1.92919921875, 'rewards/rejected': -1.598046898841858, 'rewards/accuracies': 0.875, 'rewards/margins': 3.53125, 'logps/chosen': -265.0, 'logps/rejected': -158.4250030517578, 'logits/chosen': -6.990624904632568, 'logits/rejected': -6.815625190734863, 'epoch': 2.09}
 70%|██████▉   | 3170/4545 [4:05:59<1:33:37,  4.09s/it] 70%|██████▉   | 3171/4545 [4:06:03<1:29:11,  3.89s/it] 70%|██████▉   | 3172/4545 [4:06:07<1:29:50,  3.93s/it] 70%|██████▉   | 3173/4545 [4:06:11<1:32:11,  4.03s/it] 70%|██████▉   | 3174/4545 [4:06:15<1:31:26,  4.00s/it] 70%|██████▉   | 3175/4545 [4:06:18<1:28:07,  3.86s/it] 70%|██████▉   | 3176/4545 [4:06:22<1:28:34,  3.88s/it] 70%|██████▉   | 3177/4545 [4:06:26<1:28:47,  3.89s/it] 70%|██████▉   | 3178/4545 [4:06:30<1:29:05,  3.91s/it] 70%|██████▉   | 3179/4545 [4:06:34<1:29:17,  3.92s/it] 70%|██████▉   | 3180/4545 [4:06:38<1:29:29,  3.93s/it]                                                       {'loss': 0.3157, 'grad_norm': 16.503711700439453, 'learning_rate': 4.805490364486749e-08, 'rewards/chosen': 3.696484327316284, 'rewards/rejected': -0.5126708745956421, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.209374904632568, 'logps/chosen': -449.8999938964844, 'logps/rejected': -203.75, 'logits/chosen': -6.643750190734863, 'logits/rejected': -6.896874904632568, 'epoch': 2.1}
 70%|██████▉   | 3180/4545 [4:06:38<1:29:29,  3.93s/it] 70%|██████▉   | 3181/4545 [4:06:42<1:30:57,  4.00s/it] 70%|███████   | 3182/4545 [4:06:46<1:30:31,  3.98s/it] 70%|███████   | 3183/4545 [4:06:50<1:30:02,  3.97s/it] 70%|███████   | 3184/4545 [4:06:54<1:29:44,  3.96s/it] 70%|███████   | 3185/4545 [4:06:58<1:30:05,  3.97s/it] 70%|███████   | 3186/4545 [4:07:02<1:27:08,  3.85s/it] 70%|███████   | 3187/4545 [4:07:05<1:23:24,  3.69s/it] 70%|███████   | 3188/4545 [4:07:09<1:25:54,  3.80s/it] 70%|███████   | 3189/4545 [4:07:13<1:27:58,  3.89s/it] 70%|███████   | 3190/4545 [4:07:17<1:28:34,  3.92s/it]                                                       {'loss': 0.2803, 'grad_norm': 29.81793785095215, 'learning_rate': 4.759445411875952e-08, 'rewards/chosen': 2.452343702316284, 'rewards/rejected': -1.196435570716858, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.6468749046325684, 'logps/chosen': -282.5, 'logps/rejected': -151.5749969482422, 'logits/chosen': -7.003125190734863, 'logits/rejected': -7.037499904632568, 'epoch': 2.11}
 70%|███████   | 3190/4545 [4:07:17<1:28:34,  3.92s/it] 70%|███████   | 3191/4545 [4:07:21<1:31:14,  4.04s/it] 70%|███████   | 3192/4545 [4:07:26<1:31:42,  4.07s/it] 70%|███████   | 3193/4545 [4:07:29<1:24:42,  3.76s/it] 70%|███████   | 3194/4545 [4:07:33<1:27:24,  3.88s/it] 70%|███████   | 3195/4545 [4:07:37<1:28:18,  3.92s/it] 70%|███████   | 3196/4545 [4:07:41<1:28:40,  3.94s/it] 70%|███████   | 3197/4545 [4:07:45<1:28:39,  3.95s/it] 70%|███████   | 3198/4545 [4:07:48<1:26:47,  3.87s/it] 70%|███████   | 3199/4545 [4:07:52<1:27:19,  3.89s/it] 70%|███████   | 3200/4545 [4:07:56<1:28:48,  3.96s/it]                                                       {'loss': 0.2818, 'grad_norm': 35.08869934082031, 'learning_rate': 4.713480016753083e-08, 'rewards/chosen': 3.3711915016174316, 'rewards/rejected': -0.5107177495956421, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.887500047683716, 'logps/chosen': -414.3999938964844, 'logps/rejected': -233.1999969482422, 'logits/chosen': -6.724999904632568, 'logits/rejected': -6.868750095367432, 'epoch': 2.11}
 70%|███████   | 3200/4545 [4:07:57<1:28:48,  3.96s/it] 70%|███████   | 3201/4545 [4:08:00<1:29:19,  3.99s/it] 70%|███████   | 3202/4545 [4:08:04<1:26:07,  3.85s/it] 70%|███████   | 3203/4545 [4:08:08<1:27:11,  3.90s/it] 70%|███████   | 3204/4545 [4:08:11<1:21:03,  3.63s/it] 71%|███████   | 3205/4545 [4:08:13<1:11:37,  3.21s/it] 71%|███████   | 3206/4545 [4:08:18<1:18:37,  3.52s/it] 71%|███████   | 3207/4545 [4:08:21<1:18:18,  3.51s/it] 71%|███████   | 3208/4545 [4:08:24<1:14:09,  3.33s/it] 71%|███████   | 3209/4545 [4:08:27<1:12:58,  3.28s/it] 71%|███████   | 3210/4545 [4:08:31<1:16:04,  3.42s/it]                                                       {'loss': 0.3019, 'grad_norm': 37.492305755615234, 'learning_rate': 4.6675991171624454e-08, 'rewards/chosen': 1.6730468273162842, 'rewards/rejected': -1.673437476158142, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.346874952316284, 'logps/chosen': -210.35000610351562, 'logps/rejected': -109.9749984741211, 'logits/chosen': -7.053124904632568, 'logits/rejected': -6.990624904632568, 'epoch': 2.12}
 71%|███████   | 3210/4545 [4:08:31<1:16:04,  3.42s/it] 71%|███████   | 3211/4545 [4:08:35<1:20:46,  3.63s/it] 71%|███████   | 3212/4545 [4:08:39<1:22:50,  3.73s/it] 71%|███████   | 3213/4545 [4:08:43<1:24:19,  3.80s/it] 71%|███████   | 3214/4545 [4:08:47<1:25:16,  3.84s/it] 71%|███████   | 3215/4545 [4:08:51<1:26:55,  3.92s/it] 71%|███████   | 3216/4545 [4:08:54<1:21:13,  3.67s/it] 71%|███████   | 3217/4545 [4:08:58<1:23:07,  3.76s/it] 71%|███████   | 3218/4545 [4:09:02<1:24:18,  3.81s/it] 71%|███████   | 3219/4545 [4:09:06<1:25:09,  3.85s/it] 71%|███████   | 3220/4545 [4:09:10<1:25:02,  3.85s/it]                                                       {'loss': 0.3473, 'grad_norm': 36.42623519897461, 'learning_rate': 4.6218076420710275e-08, 'rewards/chosen': 3.144726514816284, 'rewards/rejected': -0.6499999761581421, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.7953124046325684, 'logps/chosen': -404.45001220703125, 'logps/rejected': -202.4499969482422, 'logits/chosen': -6.775000095367432, 'logits/rejected': -6.996874809265137, 'epoch': 2.13}
 71%|███████   | 3220/4545 [4:09:10<1:25:02,  3.85s/it] 71%|███████   | 3221/4545 [4:09:14<1:26:14,  3.91s/it] 71%|███████   | 3222/4545 [4:09:16<1:18:07,  3.54s/it] 71%|███████   | 3223/4545 [4:09:20<1:20:26,  3.65s/it] 71%|███████   | 3224/4545 [4:09:24<1:23:21,  3.79s/it] 71%|███████   | 3225/4545 [4:09:27<1:18:05,  3.55s/it] 71%|███████   | 3226/4545 [4:09:30<1:14:39,  3.40s/it] 71%|███████   | 3227/4545 [4:09:34<1:18:09,  3.56s/it] 71%|███████   | 3228/4545 [4:09:39<1:22:39,  3.77s/it] 71%|███████   | 3229/4545 [4:09:42<1:21:10,  3.70s/it] 71%|███████   | 3230/4545 [4:09:46<1:22:37,  3.77s/it]                                                       {'loss': 0.3329, 'grad_norm': 44.05671691894531, 'learning_rate': 4.576110510838973e-08, 'rewards/chosen': 1.608007788658142, 'rewards/rejected': -1.422460913658142, 'rewards/accuracies': 0.8125, 'rewards/margins': 3.02734375, 'logps/chosen': -253.02499389648438, 'logps/rejected': -148.0500030517578, 'logits/chosen': -6.956250190734863, 'logits/rejected': -6.871874809265137, 'epoch': 2.13}
 71%|███████   | 3230/4545 [4:09:46<1:22:37,  3.77s/it] 71%|███████   | 3231/4545 [4:09:50<1:22:07,  3.75s/it] 71%|███████   | 3232/4545 [4:09:53<1:21:32,  3.73s/it] 71%|███████   | 3233/4545 [4:09:57<1:22:50,  3.79s/it] 71%|███████   | 3234/4545 [4:10:02<1:25:05,  3.89s/it] 71%|███████   | 3235/4545 [4:10:06<1:27:07,  3.99s/it] 71%|███████   | 3236/4545 [4:10:10<1:26:40,  3.97s/it] 71%|███████   | 3237/4545 [4:10:14<1:26:29,  3.97s/it] 71%|███████   | 3238/4545 [4:10:18<1:26:14,  3.96s/it] 71%|███████▏  | 3239/4545 [4:10:21<1:25:04,  3.91s/it] 71%|███████▏  | 3240/4545 [4:10:24<1:19:31,  3.66s/it]                                                       {'loss': 0.2989, 'grad_norm': 31.029033660888672, 'learning_rate': 4.530512632691106e-08, 'rewards/chosen': 2.208203077316284, 'rewards/rejected': -1.5234375, 'rewards/accuracies': 0.875, 'rewards/margins': 3.7328124046325684, 'logps/chosen': -260.45001220703125, 'logps/rejected': -121.5, 'logits/chosen': -7.184374809265137, 'logits/rejected': -7.090624809265137, 'epoch': 2.14}
 71%|███████▏  | 3240/4545 [4:10:25<1:19:31,  3.66s/it] 71%|███████▏  | 3241/4545 [4:10:29<1:23:51,  3.86s/it] 71%|███████▏  | 3242/4545 [4:10:33<1:24:14,  3.88s/it] 71%|███████▏  | 3243/4545 [4:10:36<1:22:41,  3.81s/it] 71%|███████▏  | 3244/4545 [4:10:40<1:23:23,  3.85s/it] 71%|███████▏  | 3245/4545 [4:10:44<1:24:00,  3.88s/it] 71%|███████▏  | 3246/4545 [4:10:47<1:19:34,  3.68s/it] 71%|███████▏  | 3247/4545 [4:10:51<1:16:38,  3.54s/it] 71%|███████▏  | 3248/4545 [4:10:55<1:19:09,  3.66s/it] 71%|███████▏  | 3249/4545 [4:10:59<1:22:00,  3.80s/it] 72%|███████▏  | 3250/4545 [4:11:02<1:19:27,  3.68s/it]                                                       {'loss': 0.2964, 'grad_norm': 52.71323776245117, 'learning_rate': 4.4850189061895284e-08, 'rewards/chosen': 2.5531249046325684, 'rewards/rejected': -0.9287338256835938, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.4828124046325684, 'logps/chosen': -322.3500061035156, 'logps/rejected': -173.8000030517578, 'logits/chosen': -6.875, 'logits/rejected': -7.071875095367432, 'epoch': 2.15}
 72%|███████▏  | 3250/4545 [4:11:03<1:19:27,  3.68s/it] 72%|███████▏  | 3251/4545 [4:11:06<1:23:19,  3.86s/it] 72%|███████▏  | 3252/4545 [4:11:39<4:30:35, 12.56s/it] 72%|███████▏  | 3253/4545 [4:11:46<3:55:20, 10.93s/it] 72%|███████▏  | 3254/4545 [4:11:54<3:34:49,  9.98s/it] 72%|███████▏  | 3255/4545 [4:12:02<3:21:58,  9.39s/it] 72%|███████▏  | 3256/4545 [4:12:09<3:04:02,  8.57s/it] 72%|███████▏  | 3257/4545 [4:12:16<2:57:00,  8.25s/it] 72%|███████▏  | 3258/4545 [4:12:24<2:53:26,  8.09s/it] 72%|███████▏  | 3259/4545 [4:12:32<2:50:38,  7.96s/it] 72%|███████▏  | 3260/4545 [4:12:39<2:48:05,  7.85s/it]                                                       {'loss': 0.3709, 'grad_norm': 48.240318298339844, 'learning_rate': 4.439634218707371e-08, 'rewards/chosen': 1.803613305091858, 'rewards/rejected': -1.0481445789337158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.8515625, 'logps/chosen': -248.85000610351562, 'logps/rejected': -162.5500030517578, 'logits/chosen': -6.971875190734863, 'logits/rejected': -7.109375, 'epoch': 2.15}
 72%|███████▏  | 3260/4545 [4:12:40<2:48:05,  7.85s/it] 72%|███████▏  | 3261/4545 [4:12:47<2:46:24,  7.78s/it] 72%|███████▏  | 3262/4545 [4:12:55<2:45:46,  7.75s/it] 72%|███████▏  | 3263/4545 [4:13:02<2:42:36,  7.61s/it] 72%|███████▏  | 3264/4545 [4:13:09<2:38:23,  7.42s/it] 72%|███████▏  | 3265/4545 [4:13:16<2:39:28,  7.48s/it] 72%|███████▏  | 3266/4545 [4:13:24<2:41:00,  7.55s/it] 72%|███████▏  | 3267/4545 [4:13:32<2:40:54,  7.55s/it] 72%|███████▏  | 3268/4545 [4:13:38<2:34:32,  7.26s/it] 72%|███████▏  | 3269/4545 [4:13:46<2:37:33,  7.41s/it] 72%|███████▏  | 3270/4545 [4:13:54<2:40:48,  7.57s/it]                                                       {'loss': 0.3144, 'grad_norm': 19.006053924560547, 'learning_rate': 4.394363445903749e-08, 'rewards/chosen': 2.6474609375, 'rewards/rejected': -0.12412109225988388, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.7734375, 'logps/chosen': -331.0, 'logps/rejected': -248.52499389648438, 'logits/chosen': -7.078125, 'logits/rejected': -6.978125095367432, 'epoch': 2.16}
 72%|███████▏  | 3270/4545 [4:13:54<2:40:48,  7.57s/it] 72%|███████▏  | 3271/4545 [4:14:02<2:41:10,  7.59s/it] 72%|███████▏  | 3272/4545 [4:14:09<2:37:04,  7.40s/it] 72%|███████▏  | 3273/4545 [4:14:16<2:37:52,  7.45s/it] 72%|███████▏  | 3274/4545 [4:14:23<2:30:56,  7.13s/it] 72%|███████▏  | 3275/4545 [4:14:30<2:29:52,  7.08s/it] 72%|███████▏  | 3276/4545 [4:14:34<2:10:40,  6.18s/it] 72%|███████▏  | 3277/4545 [4:14:37<1:54:09,  5.40s/it] 72%|███████▏  | 3278/4545 [4:14:41<1:44:46,  4.96s/it] 72%|███████▏  | 3279/4545 [4:14:45<1:38:08,  4.65s/it] 72%|███████▏  | 3280/4545 [4:14:48<1:26:28,  4.10s/it]                                                       {'loss': 0.3447, 'grad_norm': 34.70955276489258, 'learning_rate': 4.3492114511999646e-08, 'rewards/chosen': 1.778833031654358, 'rewards/rejected': -1.293359398841858, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.0703125, 'logps/chosen': -237.0749969482422, 'logps/rejected': -117.80000305175781, 'logits/chosen': -7.175000190734863, 'logits/rejected': -7.046875, 'epoch': 2.17}
 72%|███████▏  | 3280/4545 [4:14:48<1:26:28,  4.10s/it] 72%|███████▏  | 3281/4545 [4:14:52<1:24:21,  4.00s/it] 72%|███████▏  | 3282/4545 [4:14:54<1:15:30,  3.59s/it] 72%|███████▏  | 3283/4545 [4:14:58<1:17:27,  3.68s/it] 72%|███████▏  | 3284/4545 [4:15:02<1:19:01,  3.76s/it] 72%|███████▏  | 3285/4545 [4:15:05<1:15:40,  3.60s/it] 72%|███████▏  | 3286/4545 [4:15:09<1:18:38,  3.75s/it] 72%|███████▏  | 3287/4545 [4:15:12<1:11:06,  3.39s/it] 72%|███████▏  | 3288/4545 [4:15:16<1:14:30,  3.56s/it] 72%|███████▏  | 3289/4545 [4:15:19<1:10:05,  3.35s/it] 72%|███████▏  | 3290/4545 [4:15:23<1:14:28,  3.56s/it]                                                       {'loss': 0.2922, 'grad_norm': 37.695003509521484, 'learning_rate': 4.304183085257038e-08, 'rewards/chosen': 1.4207031726837158, 'rewards/rejected': -1.2058594226837158, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.625, 'logps/chosen': -199.25, 'logps/rejected': -120.17500305175781, 'logits/chosen': -6.990624904632568, 'logits/rejected': -6.90625, 'epoch': 2.17}
 72%|███████▏  | 3290/4545 [4:15:23<1:14:28,  3.56s/it] 72%|███████▏  | 3291/4545 [4:15:27<1:15:32,  3.61s/it] 72%|███████▏  | 3292/4545 [4:15:30<1:16:40,  3.67s/it] 72%|███████▏  | 3293/4545 [4:15:34<1:15:47,  3.63s/it] 72%|███████▏  | 3294/4545 [4:15:38<1:17:53,  3.74s/it] 72%|███████▏  | 3295/4545 [4:15:42<1:19:04,  3.80s/it] 73%|███████▎  | 3296/4545 [4:15:46<1:19:52,  3.84s/it] 73%|███████▎  | 3297/4545 [4:15:50<1:20:53,  3.89s/it] 73%|███████▎  | 3298/4545 [4:15:54<1:21:06,  3.90s/it] 73%|███████▎  | 3299/4545 [4:16:22<3:54:58, 11.32s/it] 73%|███████▎  | 3300/4545 [4:16:26<3:08:51,  9.10s/it]                                                       {'loss': 0.3004, 'grad_norm': 36.35164260864258, 'learning_rate': 4.2592831854546016e-08, 'rewards/chosen': 1.817724585533142, 'rewards/rejected': -1.3826172351837158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.2054686546325684, 'logps/chosen': -244.4499969482422, 'logps/rejected': -101.75, 'logits/chosen': -6.959374904632568, 'logits/rejected': -6.90625, 'epoch': 2.18}
 73%|███████▎  | 3300/4545 [4:16:26<3:08:51,  9.10s/it] 73%|███████▎  | 3301/4545 [4:16:30<2:34:42,  7.46s/it] 73%|███████▎  | 3302/4545 [4:16:33<2:08:50,  6.22s/it] 73%|███████▎  | 3303/4545 [4:16:37<1:55:50,  5.60s/it] 73%|███████▎  | 3304/4545 [4:16:41<1:41:21,  4.90s/it] 73%|███████▎  | 3305/4545 [4:16:45<1:35:02,  4.60s/it] 73%|███████▎  | 3306/4545 [4:16:48<1:30:43,  4.39s/it] 73%|███████▎  | 3307/4545 [4:16:52<1:27:50,  4.26s/it] 73%|███████▎  | 3308/4545 [4:16:56<1:25:56,  4.17s/it] 73%|███████▎  | 3309/4545 [4:17:01<1:26:06,  4.18s/it] 73%|███████▎  | 3310/4545 [4:17:04<1:23:12,  4.04s/it]                                                       {'loss': 0.3108, 'grad_norm': 28.911535263061523, 'learning_rate': 4.214516575371218e-08, 'rewards/chosen': 2.103076219558716, 'rewards/rejected': -1.493749976158142, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.598437547683716, 'logps/chosen': -284.79998779296875, 'logps/rejected': -148.3000030517578, 'logits/chosen': -7.0625, 'logits/rejected': -6.9375, 'epoch': 2.18}
 73%|███████▎  | 3310/4545 [4:17:04<1:23:12,  4.04s/it] 73%|███████▎  | 3311/4545 [4:17:08<1:22:57,  4.03s/it] 73%|███████▎  | 3312/4545 [4:17:12<1:22:15,  4.00s/it] 73%|███████▎  | 3313/4545 [4:17:17<1:23:46,  4.08s/it] 73%|███████▎  | 3314/4545 [4:17:20<1:21:43,  3.98s/it] 73%|███████▎  | 3315/4545 [4:17:24<1:21:22,  3.97s/it] 73%|███████▎  | 3316/4545 [4:17:28<1:22:41,  4.04s/it] 73%|███████▎  | 3317/4545 [4:17:31<1:14:00,  3.62s/it] 73%|███████▎  | 3318/4545 [4:17:35<1:14:54,  3.66s/it] 73%|███████▎  | 3319/4545 [4:17:38<1:14:07,  3.63s/it] 73%|███████▎  | 3320/4545 [4:17:42<1:16:57,  3.77s/it]                                                       {'loss': 0.2972, 'grad_norm': 88.707275390625, 'learning_rate': 4.169888064266188e-08, 'rewards/chosen': 2.854296922683716, 'rewards/rejected': -0.934374988079071, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.7890625, 'logps/chosen': -350.70001220703125, 'logps/rejected': -183.625, 'logits/chosen': -6.775000095367432, 'logits/rejected': -6.771874904632568, 'epoch': 2.19}
 73%|███████▎  | 3320/4545 [4:17:42<1:16:57,  3.77s/it] 73%|███████▎  | 3321/4545 [4:17:46<1:15:35,  3.71s/it] 73%|███████▎  | 3322/4545 [4:17:49<1:13:00,  3.58s/it] 73%|███████▎  | 3323/4545 [4:17:53<1:15:04,  3.69s/it] 73%|███████▎  | 3324/4545 [4:17:57<1:16:55,  3.78s/it] 73%|███████▎  | 3325/4545 [4:18:00<1:10:09,  3.45s/it] 73%|███████▎  | 3326/4545 [4:18:04<1:13:05,  3.60s/it] 73%|███████▎  | 3327/4545 [4:18:08<1:14:56,  3.69s/it] 73%|███████▎  | 3328/4545 [4:18:11<1:14:56,  3.69s/it] 73%|███████▎  | 3329/4545 [4:18:15<1:16:35,  3.78s/it] 73%|███████▎  | 3330/4545 [4:18:19<1:17:17,  3.82s/it]                                                       {'loss': 0.3222, 'grad_norm': 21.65970230102539, 'learning_rate': 4.1254024465628934e-08, 'rewards/chosen': 1.418359398841858, 'rewards/rejected': -1.031640648841858, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.4515624046325684, 'logps/chosen': -209.25, 'logps/rejected': -134.1750030517578, 'logits/chosen': -7.1875, 'logits/rejected': -7.078125, 'epoch': 2.2}
 73%|███████▎  | 3330/4545 [4:18:19<1:17:17,  3.82s/it] 73%|███████▎  | 3331/4545 [4:18:23<1:18:07,  3.86s/it] 73%|███████▎  | 3332/4545 [4:18:27<1:18:35,  3.89s/it] 73%|███████▎  | 3333/4545 [4:18:31<1:17:00,  3.81s/it] 73%|███████▎  | 3334/4545 [4:18:34<1:11:02,  3.52s/it] 73%|███████▎  | 3335/4545 [4:18:37<1:07:13,  3.33s/it] 73%|███████▎  | 3336/4545 [4:18:39<1:02:54,  3.12s/it] 73%|███████▎  | 3337/4545 [4:18:42<1:01:44,  3.07s/it] 73%|███████▎  | 3338/4545 [4:18:46<1:06:55,  3.33s/it] 73%|███████▎  | 3339/4545 [4:18:49<1:06:37,  3.31s/it] 73%|███████▎  | 3340/4545 [4:18:52<1:00:16,  3.00s/it]                                                       {'loss': 0.3403, 'grad_norm': 19.864704132080078, 'learning_rate': 4.081064501333738e-08, 'rewards/chosen': 1.1572265625, 'rewards/rejected': -1.669921875, 'rewards/accuracies': 0.875, 'rewards/margins': 2.8257813453674316, 'logps/chosen': -154.4499969482422, 'logps/rejected': -98.44999694824219, 'logits/chosen': -7.162499904632568, 'logits/rejected': -7.003125190734863, 'epoch': 2.2}
 73%|███████▎  | 3340/4545 [4:18:52<1:00:16,  3.00s/it] 74%|███████▎  | 3341/4545 [4:18:56<1:06:26,  3.31s/it] 74%|███████▎  | 3342/4545 [4:19:00<1:11:00,  3.54s/it] 74%|███████▎  | 3343/4545 [4:19:04<1:14:03,  3.70s/it] 74%|███████▎  | 3344/4545 [4:19:08<1:15:28,  3.77s/it] 74%|███████▎  | 3345/4545 [4:19:11<1:12:44,  3.64s/it] 74%|███████▎  | 3346/4545 [4:19:15<1:15:04,  3.76s/it] 74%|███████▎  | 3347/4545 [4:19:19<1:15:20,  3.77s/it] 74%|███████▎  | 3348/4545 [4:19:23<1:17:02,  3.86s/it] 74%|███████▎  | 3349/4545 [4:19:27<1:15:29,  3.79s/it] 74%|███████▎  | 3350/4545 [4:19:30<1:14:25,  3.74s/it]                                                       {'loss': 0.3735, 'grad_norm': 55.329002380371094, 'learning_rate': 4.036878991786724e-08, 'rewards/chosen': 1.444238305091858, 'rewards/rejected': -1.4124023914337158, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.854687452316284, 'logps/chosen': -223.10000610351562, 'logps/rejected': -151.4250030517578, 'logits/chosen': -6.981249809265137, 'logits/rejected': -6.824999809265137, 'epoch': 2.21}
 74%|███████▎  | 3350/4545 [4:19:30<1:14:25,  3.74s/it] 74%|███████▎  | 3351/4545 [4:19:34<1:12:56,  3.67s/it] 74%|███████▍  | 3352/4545 [4:19:37<1:12:42,  3.66s/it] 74%|███████▍  | 3353/4545 [4:19:41<1:12:47,  3.66s/it] 74%|███████▍  | 3354/4545 [4:19:45<1:14:27,  3.75s/it] 74%|███████▍  | 3355/4545 [4:19:49<1:13:39,  3.71s/it] 74%|███████▍  | 3356/4545 [4:19:53<1:15:03,  3.79s/it] 74%|███████▍  | 3357/4545 [4:19:57<1:15:56,  3.84s/it] 74%|███████▍  | 3358/4545 [4:20:01<1:16:27,  3.86s/it] 74%|███████▍  | 3359/4545 [4:20:04<1:16:51,  3.89s/it] 74%|███████▍  | 3360/4545 [4:20:08<1:17:07,  3.90s/it]                                                       {'loss': 0.3538, 'grad_norm': 34.083675384521484, 'learning_rate': 3.9928506647537505e-08, 'rewards/chosen': 2.8505859375, 'rewards/rejected': -0.789746105670929, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.637500047683716, 'logps/chosen': -372.20001220703125, 'logps/rejected': -204.1999969482422, 'logits/chosen': -6.878125190734863, 'logits/rejected': -6.956250190734863, 'epoch': 2.22}
 74%|███████▍  | 3360/4545 [4:20:08<1:17:07,  3.90s/it] 74%|███████▍  | 3361/4545 [4:20:12<1:17:31,  3.93s/it] 74%|███████▍  | 3362/4545 [4:20:16<1:15:11,  3.81s/it] 74%|███████▍  | 3363/4545 [4:20:20<1:15:26,  3.83s/it] 74%|███████▍  | 3364/4545 [4:20:24<1:15:59,  3.86s/it] 74%|███████▍  | 3365/4545 [4:20:28<1:15:49,  3.86s/it] 74%|███████▍  | 3366/4545 [4:20:31<1:15:34,  3.85s/it] 74%|███████▍  | 3367/4545 [4:20:36<1:17:29,  3.95s/it] 74%|███████▍  | 3368/4545 [4:20:38<1:09:43,  3.55s/it] 74%|███████▍  | 3369/4545 [4:20:42<1:11:53,  3.67s/it] 74%|███████▍  | 3370/4545 [4:20:46<1:13:27,  3.75s/it]                                                       {'loss': 0.267, 'grad_norm': 25.920547485351562, 'learning_rate': 3.9489842501806645e-08, 'rewards/chosen': 2.128613233566284, 'rewards/rejected': -1.288183569908142, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.4203124046325684, 'logps/chosen': -277.0, 'logps/rejected': -152.9499969482422, 'logits/chosen': -7.018750190734863, 'logits/rejected': -6.946875095367432, 'epoch': 2.22}
 74%|███████▍  | 3370/4545 [4:20:47<1:13:27,  3.75s/it] 74%|███████▍  | 3371/4545 [4:20:50<1:13:43,  3.77s/it] 74%|███████▍  | 3372/4545 [4:20:54<1:14:38,  3.82s/it] 74%|███████▍  | 3373/4545 [4:20:57<1:12:50,  3.73s/it] 74%|███████▍  | 3374/4545 [4:21:02<1:15:12,  3.85s/it] 74%|███████▍  | 3375/4545 [4:21:05<1:15:37,  3.88s/it] 74%|███████▍  | 3376/4545 [4:21:08<1:10:21,  3.61s/it] 74%|███████▍  | 3377/4545 [4:21:12<1:11:22,  3.67s/it] 74%|███████▍  | 3378/4545 [4:21:16<1:09:19,  3.56s/it] 74%|███████▍  | 3379/4545 [4:21:20<1:13:10,  3.77s/it] 74%|███████▍  | 3380/4545 [4:21:23<1:11:36,  3.69s/it]                                                       {'loss': 0.3679, 'grad_norm': 56.718143463134766, 'learning_rate': 3.905284460619117e-08, 'rewards/chosen': 2.057324171066284, 'rewards/rejected': -0.759765625, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.81640625, 'logps/chosen': -269.25, 'logps/rejected': -193.8000030517578, 'logits/chosen': -7.09375, 'logits/rejected': -6.803124904632568, 'epoch': 2.23}
 74%|███████▍  | 3380/4545 [4:21:23<1:11:36,  3.69s/it] 74%|███████▍  | 3381/4545 [4:21:27<1:12:14,  3.72s/it] 74%|███████▍  | 3382/4545 [4:21:31<1:13:26,  3.79s/it] 74%|███████▍  | 3383/4545 [4:21:35<1:12:02,  3.72s/it] 74%|███████▍  | 3384/4545 [4:21:39<1:14:50,  3.87s/it] 74%|███████▍  | 3385/4545 [4:21:43<1:16:13,  3.94s/it] 74%|███████▍  | 3386/4545 [4:21:47<1:17:39,  4.02s/it] 75%|███████▍  | 3387/4545 [4:21:51<1:17:04,  3.99s/it] 75%|███████▍  | 3388/4545 [4:21:55<1:18:19,  4.06s/it] 75%|███████▍  | 3389/4545 [4:22:00<1:19:18,  4.12s/it] 75%|███████▍  | 3390/4545 [4:22:28<3:42:31, 11.56s/it]                                                       {'loss': 0.3264, 'grad_norm': 43.58442687988281, 'learning_rate': 3.8617559907203015e-08, 'rewards/chosen': 2.2607421875, 'rewards/rejected': -1.1004638671875, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.3609375953674316, 'logps/chosen': -306.8500061035156, 'logps/rejected': -199.6999969482422, 'logits/chosen': -6.971875190734863, 'logits/rejected': -6.959374904632568, 'epoch': 2.24}
 75%|███████▍  | 3390/4545 [4:22:29<3:42:31, 11.56s/it] 75%|███████▍  | 3391/4545 [4:22:32<2:58:57,  9.30s/it] 75%|███████▍  | 3392/4545 [4:22:37<2:29:50,  7.80s/it] 75%|███████▍  | 3393/4545 [4:22:40<2:05:11,  6.52s/it] 75%|███████▍  | 3394/4545 [4:22:44<1:50:12,  5.74s/it] 75%|███████▍  | 3395/4545 [4:22:48<1:39:31,  5.19s/it] 75%|███████▍  | 3396/4545 [4:22:51<1:28:18,  4.61s/it] 75%|███████▍  | 3397/4545 [4:22:55<1:24:29,  4.42s/it] 75%|███████▍  | 3398/4545 [4:22:58<1:15:27,  3.95s/it] 75%|███████▍  | 3399/4545 [4:23:02<1:12:12,  3.78s/it] 75%|███████▍  | 3400/4545 [4:23:05<1:09:48,  3.66s/it]                                                       {'loss': 0.255, 'grad_norm': 19.93439292907715, 'learning_rate': 3.818403516730604e-08, 'rewards/chosen': 2.279101610183716, 'rewards/rejected': -1.49609375, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.774218797683716, 'logps/chosen': -266.29998779296875, 'logps/rejected': -183.89999389648438, 'logits/chosen': -7.256249904632568, 'logits/rejected': -6.993750095367432, 'epoch': 2.24}
 75%|███████▍  | 3400/4545 [4:23:05<1:09:48,  3.66s/it] 75%|███████▍  | 3401/4545 [4:23:09<1:13:00,  3.83s/it] 75%|███████▍  | 3402/4545 [4:23:13<1:13:50,  3.88s/it] 75%|███████▍  | 3403/4545 [4:23:17<1:15:20,  3.96s/it] 75%|███████▍  | 3404/4545 [4:23:22<1:16:53,  4.04s/it] 75%|███████▍  | 3405/4545 [4:23:25<1:13:59,  3.89s/it] 75%|███████▍  | 3406/4545 [4:23:28<1:05:12,  3.43s/it] 75%|███████▍  | 3407/4545 [4:23:31<1:03:02,  3.32s/it] 75%|███████▍  | 3408/4545 [4:23:35<1:07:01,  3.54s/it] 75%|███████▌  | 3409/4545 [4:23:38<1:08:32,  3.62s/it] 75%|███████▌  | 3410/4545 [4:23:42<1:09:40,  3.68s/it]                                                       {'loss': 0.2953, 'grad_norm': 45.62369155883789, 'learning_rate': 3.775231695989244e-08, 'rewards/chosen': 1.292333960533142, 'rewards/rejected': -1.88671875, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.1812500953674316, 'logps/chosen': -219.4499969482422, 'logps/rejected': -107.5250015258789, 'logits/chosen': -7.037499904632568, 'logits/rejected': -6.965624809265137, 'epoch': 2.25}
 75%|███████▌  | 3410/4545 [4:23:42<1:09:40,  3.68s/it] 75%|███████▌  | 3411/4545 [4:23:46<1:10:55,  3.75s/it] 75%|███████▌  | 3412/4545 [4:23:50<1:11:06,  3.77s/it] 75%|███████▌  | 3413/4545 [4:23:54<1:12:03,  3.82s/it] 75%|███████▌  | 3414/4545 [4:23:57<1:07:39,  3.59s/it] 75%|███████▌  | 3415/4545 [4:24:01<1:08:29,  3.64s/it] 75%|███████▌  | 3416/4545 [4:24:05<1:10:05,  3.73s/it] 75%|███████▌  | 3417/4545 [4:24:09<1:11:11,  3.79s/it] 75%|███████▌  | 3418/4545 [4:24:12<1:11:28,  3.81s/it] 75%|███████▌  | 3419/4545 [4:24:16<1:11:49,  3.83s/it] 75%|███████▌  | 3420/4545 [4:24:20<1:10:09,  3.74s/it]                                                       {'loss': 0.2735, 'grad_norm': 692.912353515625, 'learning_rate': 3.732245166427933e-08, 'rewards/chosen': 1.7634766101837158, 'rewards/rejected': -1.375, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.137500047683716, 'logps/chosen': -242.39999389648438, 'logps/rejected': -152.85000610351562, 'logits/chosen': -7.068749904632568, 'logits/rejected': -7.012499809265137, 'epoch': 2.26}
 75%|███████▌  | 3420/4545 [4:24:20<1:10:09,  3.74s/it] 75%|███████▌  | 3421/4545 [4:24:24<1:12:27,  3.87s/it] 75%|███████▌  | 3422/4545 [4:24:28<1:14:33,  3.98s/it] 75%|███████▌  | 3423/4545 [4:24:31<1:08:22,  3.66s/it] 75%|███████▌  | 3424/4545 [4:24:35<1:11:40,  3.84s/it] 75%|███████▌  | 3425/4545 [4:24:39<1:12:42,  3.90s/it] 75%|███████▌  | 3426/4545 [4:24:43<1:12:11,  3.87s/it] 75%|███████▌  | 3427/4545 [4:24:47<1:11:53,  3.86s/it] 75%|███████▌  | 3428/4545 [4:24:51<1:12:12,  3.88s/it] 75%|███████▌  | 3429/4545 [4:24:55<1:12:47,  3.91s/it] 75%|███████▌  | 3430/4545 [4:24:59<1:12:55,  3.92s/it]                                                       {'loss': 0.2906, 'grad_norm': 32.68522644042969, 'learning_rate': 3.6894485460726186e-08, 'rewards/chosen': 1.9420897960662842, 'rewards/rejected': -1.1794922351837158, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.121875047683716, 'logps/chosen': -287.04998779296875, 'logps/rejected': -165.625, 'logits/chosen': -6.987500190734863, 'logits/rejected': -6.840624809265137, 'epoch': 2.26}
 75%|███████▌  | 3430/4545 [4:24:59<1:12:55,  3.92s/it] 75%|███████▌  | 3431/4545 [4:25:01<1:05:14,  3.51s/it] 76%|███████▌  | 3432/4545 [4:25:30<3:22:31, 10.92s/it] 76%|███████▌  | 3433/4545 [4:25:34<2:43:21,  8.81s/it] 76%|███████▌  | 3434/4545 [4:25:38<2:16:09,  7.35s/it] 76%|███████▌  | 3435/4545 [4:25:41<1:55:10,  6.23s/it] 76%|███████▌  | 3436/4545 [4:25:45<1:42:25,  5.54s/it] 76%|███████▌  | 3437/4545 [4:25:49<1:33:25,  5.06s/it] 76%|███████▌  | 3438/4545 [4:26:18<3:44:35, 12.17s/it] 76%|███████▌  | 3439/4545 [4:26:22<3:00:22,  9.79s/it] 76%|███████▌  | 3440/4545 [4:26:26<2:25:42,  7.91s/it]                                                       {'loss': 0.2411, 'grad_norm': 37.640682220458984, 'learning_rate': 3.646846432547387e-08, 'rewards/chosen': 1.8706543445587158, 'rewards/rejected': -1.583984375, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.44921875, 'logps/chosen': -222.4499969482422, 'logps/rejected': -100.0250015258789, 'logits/chosen': -7.081250190734863, 'logits/rejected': -6.962500095367432, 'epoch': 2.27}
 76%|███████▌  | 3440/4545 [4:26:26<2:25:42,  7.91s/it] 76%|███████▌  | 3441/4545 [4:26:30<2:04:19,  6.76s/it] 76%|███████▌  | 3442/4545 [4:26:34<1:48:31,  5.90s/it] 76%|███████▌  | 3443/4545 [4:26:37<1:37:36,  5.31s/it] 76%|███████▌  | 3444/4545 [4:26:41<1:30:00,  4.90s/it] 76%|███████▌  | 3445/4545 [4:26:46<1:25:40,  4.67s/it] 76%|███████▌  | 3446/4545 [4:26:49<1:21:33,  4.45s/it] 76%|███████▌  | 3447/4545 [4:26:53<1:17:18,  4.22s/it] 76%|███████▌  | 3448/4545 [4:26:57<1:16:32,  4.19s/it] 76%|███████▌  | 3449/4545 [4:27:01<1:15:10,  4.11s/it] 76%|███████▌  | 3450/4545 [4:27:05<1:14:10,  4.06s/it]                                                       {'loss': 0.2933, 'grad_norm': 32.28725051879883, 'learning_rate': 3.6044434025805224e-08, 'rewards/chosen': 2.4517579078674316, 'rewards/rejected': -1.29443359375, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.7484374046325684, 'logps/chosen': -302.70001220703125, 'logps/rejected': -151.4250030517578, 'logits/chosen': -6.940625190734863, 'logits/rejected': -6.824999809265137, 'epoch': 2.28}
 76%|███████▌  | 3450/4545 [4:27:05<1:14:10,  4.06s/it] 76%|███████▌  | 3451/4545 [4:27:09<1:13:40,  4.04s/it] 76%|███████▌  | 3452/4545 [4:27:12<1:06:29,  3.65s/it] 76%|███████▌  | 3453/4545 [4:27:15<1:03:00,  3.46s/it] 76%|███████▌  | 3454/4545 [4:27:19<1:05:33,  3.61s/it] 76%|███████▌  | 3455/4545 [4:27:23<1:07:03,  3.69s/it] 76%|███████▌  | 3456/4545 [4:27:27<1:08:24,  3.77s/it] 76%|███████▌  | 3457/4545 [4:27:31<1:10:46,  3.90s/it] 76%|███████▌  | 3458/4545 [4:27:35<1:10:54,  3.91s/it] 76%|███████▌  | 3459/4545 [4:27:39<1:12:22,  4.00s/it] 76%|███████▌  | 3460/4545 [4:27:42<1:08:19,  3.78s/it]                                                       {'loss': 0.3215, 'grad_norm': 33.00823974609375, 'learning_rate': 3.562244011512845e-08, 'rewards/chosen': 2.6537108421325684, 'rewards/rejected': -0.8462890386581421, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.499218702316284, 'logps/chosen': -324.70001220703125, 'logps/rejected': -160.10000610351562, 'logits/chosen': -6.993750095367432, 'logits/rejected': -6.921875, 'epoch': 2.28}
 76%|███████▌  | 3460/4545 [4:27:42<1:08:19,  3.78s/it] 76%|███████▌  | 3461/4545 [4:27:46<1:09:31,  3.85s/it] 76%|███████▌  | 3462/4545 [4:27:50<1:07:33,  3.74s/it] 76%|███████▌  | 3463/4545 [4:27:54<1:09:38,  3.86s/it] 76%|███████▌  | 3464/4545 [4:27:58<1:09:56,  3.88s/it] 76%|███████▌  | 3465/4545 [4:28:02<1:11:28,  3.97s/it] 76%|███████▋  | 3466/4545 [4:28:05<1:07:35,  3.76s/it] 76%|███████▋  | 3467/4545 [4:28:09<1:08:35,  3.82s/it] 76%|███████▋  | 3468/4545 [4:28:13<1:06:30,  3.71s/it] 76%|███████▋  | 3469/4545 [4:28:17<1:08:17,  3.81s/it] 76%|███████▋  | 3470/4545 [4:28:21<1:09:21,  3.87s/it]                                                       {'loss': 0.2802, 'grad_norm': 46.68500518798828, 'learning_rate': 3.520252792808328e-08, 'rewards/chosen': 2.3275389671325684, 'rewards/rejected': -1.3642578125, 'rewards/accuracies': 0.875, 'rewards/margins': 3.698437452316284, 'logps/chosen': -242.60000610351562, 'logps/rejected': -158.75, 'logits/chosen': -7.175000190734863, 'logits/rejected': -6.96875, 'epoch': 2.29}
 76%|███████▋  | 3470/4545 [4:28:21<1:09:21,  3.87s/it] 76%|███████▋  | 3471/4545 [4:28:25<1:11:56,  4.02s/it] 76%|███████▋  | 3472/4545 [4:28:29<1:11:30,  4.00s/it] 76%|███████▋  | 3473/4545 [4:28:32<1:07:45,  3.79s/it] 76%|███████▋  | 3474/4545 [4:28:36<1:08:35,  3.84s/it] 76%|███████▋  | 3475/4545 [4:28:40<1:05:53,  3.69s/it] 76%|███████▋  | 3476/4545 [4:28:44<1:07:12,  3.77s/it] 77%|███████▋  | 3477/4545 [4:28:48<1:08:07,  3.83s/it] 77%|███████▋  | 3478/4545 [4:28:52<1:08:39,  3.86s/it] 77%|███████▋  | 3479/4545 [4:28:56<1:09:03,  3.89s/it] 77%|███████▋  | 3480/4545 [4:28:59<1:09:14,  3.90s/it]                                                       {'loss': 0.2595, 'grad_norm': 21.339378356933594, 'learning_rate': 3.4784742575670736e-08, 'rewards/chosen': 3.541430711746216, 'rewards/rejected': -0.91815185546875, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.464062690734863, 'logps/chosen': -472.54998779296875, 'logps/rejected': -179.6999969482422, 'logits/chosen': -6.959374904632568, 'logits/rejected': -6.928124904632568, 'epoch': 2.3}
 77%|███████▋  | 3480/4545 [4:29:00<1:09:14,  3.90s/it] 77%|███████▋  | 3481/4545 [4:29:03<1:09:38,  3.93s/it] 77%|███████▋  | 3482/4545 [4:29:07<1:09:41,  3.93s/it] 77%|███████▋  | 3483/4545 [4:29:11<1:10:04,  3.96s/it] 77%|███████▋  | 3484/4545 [4:29:15<1:08:50,  3.89s/it] 77%|███████▋  | 3485/4545 [4:29:19<1:09:23,  3.93s/it] 77%|███████▋  | 3486/4545 [4:29:23<1:06:58,  3.80s/it] 77%|███████▋  | 3487/4545 [4:29:26<1:04:46,  3.67s/it] 77%|███████▋  | 3488/4545 [4:29:30<1:05:05,  3.69s/it] 77%|███████▋  | 3489/4545 [4:29:34<1:06:18,  3.77s/it] 77%|███████▋  | 3490/4545 [4:29:38<1:08:42,  3.91s/it]                                                       {'loss': 0.2915, 'grad_norm': 100.06210327148438, 'learning_rate': 3.436912894040672e-08, 'rewards/chosen': 2.8589844703674316, 'rewards/rejected': -1.0412108898162842, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.90625, 'logps/chosen': -360.0, 'logps/rejected': -179.875, 'logits/chosen': -6.78125, 'logits/rejected': -6.887499809265137, 'epoch': 2.3}
 77%|███████▋  | 3490/4545 [4:29:38<1:08:42,  3.91s/it] 77%|███████▋  | 3491/4545 [4:29:42<1:09:10,  3.94s/it] 77%|███████▋  | 3492/4545 [4:29:45<1:05:22,  3.73s/it] 77%|███████▋  | 3493/4545 [4:29:49<1:07:35,  3.86s/it] 77%|███████▋  | 3494/4545 [4:29:52<59:41,  3.41s/it]   77%|███████▋  | 3495/4545 [4:29:55<59:23,  3.39s/it] 77%|███████▋  | 3496/4545 [4:29:59<1:02:41,  3.59s/it] 77%|███████▋  | 3497/4545 [4:30:03<1:05:41,  3.76s/it] 77%|███████▋  | 3498/4545 [4:30:07<1:06:38,  3.82s/it] 77%|███████▋  | 3499/4545 [4:30:11<1:07:01,  3.84s/it] 77%|███████▋  | 3500/4545 [4:30:15<1:05:58,  3.79s/it]                                                       {'loss': 0.3542, 'grad_norm': 53.94325637817383, 'learning_rate': 3.395573167150054e-08, 'rewards/chosen': 2.258007764816284, 'rewards/rejected': -0.9339843988418579, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.194531202316284, 'logps/chosen': -266.67498779296875, 'logps/rejected': -145.14999389648438, 'logits/chosen': -7.178124904632568, 'logits/rejected': -7.087500095367432, 'epoch': 2.31}
 77%|███████▋  | 3500/4545 [4:30:15<1:05:58,  3.79s/it] 77%|███████▋  | 3501/4545 [4:30:19<1:07:54,  3.90s/it] 77%|███████▋  | 3502/4545 [4:30:23<1:08:59,  3.97s/it] 77%|███████▋  | 3503/4545 [4:30:27<1:08:50,  3.96s/it] 77%|███████▋  | 3504/4545 [4:30:30<1:02:13,  3.59s/it] 77%|███████▋  | 3505/4545 [4:30:33<1:02:54,  3.63s/it] 77%|███████▋  | 3506/4545 [4:30:36<57:35,  3.33s/it]   77%|███████▋  | 3507/4545 [4:30:40<1:01:43,  3.57s/it] 77%|███████▋  | 3508/4545 [4:30:44<1:03:29,  3.67s/it] 77%|███████▋  | 3509/4545 [4:30:48<1:04:52,  3.76s/it] 77%|███████▋  | 3510/4545 [4:30:52<1:03:45,  3.70s/it]                                                       {'loss': 0.318, 'grad_norm': 27.022985458374023, 'learning_rate': 3.354459518005807e-08, 'rewards/chosen': 2.909960985183716, 'rewards/rejected': -0.816601574420929, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.719531297683716, 'logps/chosen': -353.0, 'logps/rejected': -213.47500610351562, 'logits/chosen': -6.928124904632568, 'logits/rejected': -6.84375, 'epoch': 2.32}
 77%|███████▋  | 3510/4545 [4:30:52<1:03:45,  3.70s/it] 77%|███████▋  | 3511/4545 [4:30:56<1:07:12,  3.90s/it] 77%|███████▋  | 3512/4545 [4:31:00<1:07:26,  3.92s/it] 77%|███████▋  | 3513/4545 [4:31:04<1:07:31,  3.93s/it] 77%|███████▋  | 3514/4545 [4:31:08<1:07:31,  3.93s/it] 77%|███████▋  | 3515/4545 [4:31:11<1:05:30,  3.82s/it] 77%|███████▋  | 3516/4545 [4:31:15<1:06:06,  3.85s/it] 77%|███████▋  | 3517/4545 [4:31:19<1:06:29,  3.88s/it] 77%|███████▋  | 3518/4545 [4:31:23<1:05:39,  3.84s/it] 77%|███████▋  | 3519/4545 [4:31:26<1:00:47,  3.55s/it] 77%|███████▋  | 3520/4545 [4:31:30<1:02:42,  3.67s/it]                                                       {'loss': 0.2626, 'grad_norm': 43.19095993041992, 'learning_rate': 3.3135763634310754e-08, 'rewards/chosen': 4.16796875, 'rewards/rejected': -0.379150390625, 'rewards/accuracies': 0.875, 'rewards/margins': 4.547656059265137, 'logps/chosen': -455.25, 'logps/rejected': -256.8999938964844, 'logits/chosen': -6.790625095367432, 'logits/rejected': -6.753125190734863, 'epoch': 2.32}
 77%|███████▋  | 3520/4545 [4:31:30<1:02:42,  3.67s/it] 77%|███████▋  | 3521/4545 [4:31:34<1:03:45,  3.74s/it] 77%|███████▋  | 3522/4545 [4:31:38<1:04:45,  3.80s/it] 78%|███████▊  | 3523/4545 [4:31:41<1:04:24,  3.78s/it] 78%|███████▊  | 3524/4545 [4:31:45<1:05:05,  3.82s/it] 78%|███████▊  | 3525/4545 [4:31:49<1:04:12,  3.78s/it] 78%|███████▊  | 3526/4545 [4:31:52<1:02:10,  3.66s/it] 78%|███████▊  | 3527/4545 [4:31:55<57:48,  3.41s/it]   78%|███████▊  | 3528/4545 [4:31:59<1:00:00,  3.54s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:44,  1.31it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:15,  1.35s/it][A
  8%|▊         | 5/60 [00:06<01:18,  1.43s/it][A
 10%|█         | 6/60 [00:08<01:21,  1.50s/it][A
 12%|█▏        | 7/60 [00:09<01:22,  1.56s/it][A
 13%|█▎        | 8/60 [00:11<01:23,  1.60s/it][A
 15%|█▌        | 9/60 [00:13<01:22,  1.62s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.61s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:18<01:21,  1.69s/it][A
 22%|██▏       | 13/60 [00:19<01:18,  1.67s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.64s/it][A
 25%|██▌       | 15/60 [00:22<01:09,  1.53s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.39s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.15s/it][A
 33%|███▎      | 20/60 [00:27<00:40,  1.00s/it][A
 35%|███▌      | 21/60 [00:28<00:39,  1.00s/it][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.10s/it][A
 42%|████▏     | 25/60 [00:33<00:44,  1.26s/it][A
 43%|████▎     | 26/60 [00:35<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.09s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:41<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:46<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:48<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:51<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:53<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:57<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:58<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:01<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:02<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:15,  1.39s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.48s/it][A
 85%|████████▌ | 51/60 [01:07<00:13,  1.50s/it][A
 87%|████████▋ | 52/60 [01:08<00:11,  1.43s/it][A
 88%|████████▊ | 53/60 [01:09<00:09,  1.33s/it][A
 90%|█████████ | 54/60 [01:11<00:08,  1.40s/it][A
 92%|█████████▏| 55/60 [01:11<00:06,  1.20s/it][A
 93%|█████████▎| 56/60 [01:13<00:05,  1.35s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.42s/it][A
 97%|█████████▋| 58/60 [01:16<00:02,  1.42s/it][A
 98%|█████████▊| 59/60 [01:18<00:01,  1.47s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.52s/it][A                                                       
                                               [A{'eval_loss': 0.41532349586486816, 'eval_runtime': 81.3555, 'eval_samples_per_second': 11.714, 'eval_steps_per_second': 0.738, 'eval_rewards/chosen': 2.5508503913879395, 'eval_rewards/rejected': -0.3329671323299408, 'eval_rewards/accuracies': 0.8021990656852722, 'eval_rewards/margins': 2.8828532695770264, 'eval_logps/chosen': -364.9750061035156, 'eval_logps/rejected': -153.62916564941406, 'eval_logits/chosen': -6.7130208015441895, 'eval_logits/rejected': -7.327083110809326, 'epoch': 2.33}
 78%|███████▊  | 3528/4545 [4:33:21<1:00:00,  3.54s/it]
100%|██████████| 60/60 [01:19<00:00,  1.52s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 78%|███████▊  | 3529/4545 [4:33:37<8:59:37, 31.87s/it] 78%|███████▊  | 3530/4545 [4:33:41<6:38:23, 23.55s/it]                                                       {'loss': 0.2774, 'grad_norm': 20.86932945251465, 'learning_rate': 3.2729280954870655e-08, 'rewards/chosen': 1.707495093345642, 'rewards/rejected': -1.52239990234375, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.232421875, 'logps/chosen': -234.75, 'logps/rejected': -128.3249969482422, 'logits/chosen': -6.987500190734863, 'logits/rejected': -6.987500190734863, 'epoch': 2.33}
 78%|███████▊  | 3530/4545 [4:33:41<6:38:23, 23.55s/it] 78%|███████▊  | 3531/4545 [4:33:45<4:57:35, 17.61s/it] 78%|███████▊  | 3532/4545 [4:33:49<3:49:19, 13.58s/it] 78%|███████▊  | 3533/4545 [4:33:53<2:58:49, 10.60s/it] 78%|███████▊  | 3534/4545 [4:33:57<2:24:24,  8.57s/it] 78%|███████▊  | 3535/4545 [4:34:01<2:01:01,  7.19s/it] 78%|███████▊  | 3536/4545 [4:34:04<1:42:20,  6.09s/it] 78%|███████▊  | 3537/4545 [4:34:08<1:30:12,  5.37s/it] 78%|███████▊  | 3538/4545 [4:34:10<1:16:32,  4.56s/it] 78%|███████▊  | 3539/4545 [4:34:14<1:12:10,  4.30s/it] 78%|███████▊  | 3540/4545 [4:34:18<1:09:00,  4.12s/it]                                                       {'loss': 0.261, 'grad_norm': 24.411945343017578, 'learning_rate': 3.232519081001205e-08, 'rewards/chosen': 0.883984386920929, 'rewards/rejected': -1.802343726158142, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.6890625953674316, 'logps/chosen': -139.5, 'logps/rejected': -103.42500305175781, 'logits/chosen': -7.196875095367432, 'logits/rejected': -6.978125095367432, 'epoch': 2.34}
 78%|███████▊  | 3540/4545 [4:34:18<1:09:00,  4.12s/it] 78%|███████▊  | 3541/4545 [4:34:22<1:09:49,  4.17s/it] 78%|███████▊  | 3542/4545 [4:34:26<1:09:51,  4.18s/it] 78%|███████▊  | 3543/4545 [4:34:30<1:08:30,  4.10s/it] 78%|███████▊  | 3544/4545 [4:34:34<1:06:38,  3.99s/it] 78%|███████▊  | 3545/4545 [4:34:38<1:06:15,  3.98s/it] 78%|███████▊  | 3546/4545 [4:35:08<3:15:04, 11.72s/it] 78%|███████▊  | 3547/4545 [4:35:12<2:35:58,  9.38s/it] 78%|███████▊  | 3548/4545 [4:35:15<2:04:07,  7.47s/it] 78%|███████▊  | 3549/4545 [4:35:19<1:46:46,  6.43s/it] 78%|███████▊  | 3550/4545 [4:35:23<1:34:08,  5.68s/it]                                                       {'loss': 0.3292, 'grad_norm': 30.101335525512695, 'learning_rate': 3.1923536610980124e-08, 'rewards/chosen': 2.1656250953674316, 'rewards/rejected': -1.1845703125, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.34765625, 'logps/chosen': -273.6499938964844, 'logps/rejected': -163.35000610351562, 'logits/chosen': -6.990624904632568, 'logits/rejected': -6.831250190734863, 'epoch': 2.34}
 78%|███████▊  | 3550/4545 [4:35:23<1:34:08,  5.68s/it] 78%|███████▊  | 3551/4545 [4:35:27<1:25:32,  5.16s/it] 78%|███████▊  | 3552/4545 [4:35:30<1:19:21,  4.80s/it] 78%|███████▊  | 3553/4545 [4:35:35<1:15:24,  4.56s/it] 78%|███████▊  | 3554/4545 [4:35:38<1:11:30,  4.33s/it] 78%|███████▊  | 3555/4545 [4:35:42<1:09:33,  4.22s/it] 78%|███████▊  | 3556/4545 [4:35:46<1:08:21,  4.15s/it] 78%|███████▊  | 3557/4545 [4:35:50<1:05:56,  4.00s/it] 78%|███████▊  | 3558/4545 [4:35:54<1:05:34,  3.99s/it] 78%|███████▊  | 3559/4545 [4:35:57<1:01:48,  3.76s/it] 78%|███████▊  | 3560/4545 [4:36:01<1:01:59,  3.78s/it]                                                       {'loss': 0.3211, 'grad_norm': 26.263042449951172, 'learning_rate': 3.1524361507327403e-08, 'rewards/chosen': 2.900390625, 'rewards/rejected': -1.0509765148162842, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.950000047683716, 'logps/chosen': -351.3999938964844, 'logps/rejected': -186.9499969482422, 'logits/chosen': -6.800000190734863, 'logits/rejected': -6.887499809265137, 'epoch': 2.35}
 78%|███████▊  | 3560/4545 [4:36:01<1:01:59,  3.78s/it] 78%|███████▊  | 3561/4545 [4:36:04<1:00:50,  3.71s/it] 78%|███████▊  | 3562/4545 [4:36:08<1:01:16,  3.74s/it] 78%|███████▊  | 3563/4545 [4:36:12<1:00:11,  3.68s/it] 78%|███████▊  | 3564/4545 [4:36:16<1:01:25,  3.76s/it] 78%|███████▊  | 3565/4545 [4:36:20<1:02:13,  3.81s/it] 78%|███████▊  | 3566/4545 [4:36:24<1:02:28,  3.83s/it] 78%|███████▊  | 3567/4545 [4:36:27<1:02:34,  3.84s/it] 79%|███████▊  | 3568/4545 [4:36:32<1:04:13,  3.94s/it] 79%|███████▊  | 3569/4545 [4:37:02<3:11:03, 11.75s/it] 79%|███████▊  | 3570/4545 [4:37:05<2:32:52,  9.41s/it]                                                       {'loss': 0.3026, 'grad_norm': 24.194520950317383, 'learning_rate': 3.1127708382278184e-08, 'rewards/chosen': 2.0107421875, 'rewards/rejected': -1.403906226158142, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.413281202316284, 'logps/chosen': -249.77499389648438, 'logps/rejected': -135.10000610351562, 'logits/chosen': -7.056250095367432, 'logits/rejected': -6.771874904632568, 'epoch': 2.36}
 79%|███████▊  | 3570/4545 [4:37:06<2:32:52,  9.41s/it] 79%|███████▊  | 3571/4545 [4:37:10<2:07:36,  7.86s/it] 79%|███████▊  | 3572/4545 [4:37:14<1:48:27,  6.69s/it] 79%|███████▊  | 3573/4545 [4:37:47<3:56:19, 14.59s/it] 79%|███████▊  | 3574/4545 [4:37:54<3:22:10, 12.49s/it] 79%|███████▊  | 3575/4545 [4:38:02<2:57:05, 10.95s/it] 79%|███████▊  | 3576/4545 [4:38:09<2:38:08,  9.79s/it] 79%|███████▊  | 3577/4545 [4:38:15<2:21:57,  8.80s/it] 79%|███████▊  | 3578/4545 [4:38:23<2:16:26,  8.47s/it] 79%|███████▊  | 3579/4545 [4:38:31<2:12:49,  8.25s/it] 79%|███████▉  | 3580/4545 [4:38:38<2:09:37,  8.06s/it]                                                       {'loss': 0.307, 'grad_norm': 40.39717102050781, 'learning_rate': 3.0733619848121514e-08, 'rewards/chosen': 2.8099608421325684, 'rewards/rejected': -0.7489258050918579, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.561718702316284, 'logps/chosen': -355.95001220703125, 'logps/rejected': -203.60000610351562, 'logits/chosen': -6.946875095367432, 'logits/rejected': -6.837500095367432, 'epoch': 2.36}
 79%|███████▉  | 3580/4545 [4:38:39<2:09:37,  8.06s/it] 79%|███████▉  | 3581/4545 [4:38:46<2:08:08,  7.98s/it] 79%|███████▉  | 3582/4545 [4:38:54<2:06:45,  7.90s/it] 79%|███████▉  | 3583/4545 [4:39:01<2:05:08,  7.80s/it] 79%|███████▉  | 3584/4545 [4:39:09<2:03:00,  7.68s/it] 79%|███████▉  | 3585/4545 [4:39:16<2:02:29,  7.66s/it] 79%|███████▉  | 3586/4545 [4:39:24<2:01:17,  7.59s/it] 79%|███████▉  | 3587/4545 [4:39:31<2:01:05,  7.58s/it] 79%|███████▉  | 3588/4545 [4:39:38<1:58:14,  7.41s/it] 79%|███████▉  | 3589/4545 [4:39:46<1:58:58,  7.47s/it] 79%|███████▉  | 3590/4545 [4:39:54<2:00:35,  7.58s/it]                                                       {'loss': 0.3061, 'grad_norm': 28.486326217651367, 'learning_rate': 3.0342138241633584e-08, 'rewards/chosen': 2.582812547683716, 'rewards/rejected': -1.1957275867462158, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.7789063453674316, 'logps/chosen': -315.20001220703125, 'logps/rejected': -178.625, 'logits/chosen': -6.859375, 'logits/rejected': -6.884375095367432, 'epoch': 2.37}
 79%|███████▉  | 3590/4545 [4:39:54<2:00:35,  7.58s/it] 79%|███████▉  | 3591/4545 [4:40:01<2:00:45,  7.60s/it] 79%|███████▉  | 3592/4545 [4:40:09<2:00:57,  7.62s/it] 79%|███████▉  | 3593/4545 [4:40:17<2:01:25,  7.65s/it] 79%|███████▉  | 3594/4545 [4:40:25<2:03:02,  7.76s/it] 79%|███████▉  | 3595/4545 [4:40:32<2:02:01,  7.71s/it] 79%|███████▉  | 3596/4545 [4:40:40<2:02:06,  7.72s/it] 79%|███████▉  | 3597/4545 [4:40:48<2:00:48,  7.65s/it] 79%|███████▉  | 3598/4545 [4:40:55<2:00:12,  7.62s/it] 79%|███████▉  | 3599/4545 [4:41:03<2:00:53,  7.67s/it] 79%|███████▉  | 3600/4545 [4:41:11<2:01:39,  7.72s/it]                                                       {'loss': 0.3698, 'grad_norm': 25.315200805664062, 'learning_rate': 2.995330561952924e-08, 'rewards/chosen': 1.9386718273162842, 'rewards/rejected': -1.3474609851837158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.2890625, 'logps/chosen': -315.0, 'logps/rejected': -176.39999389648438, 'logits/chosen': -6.868750095367432, 'logits/rejected': -7.006249904632568, 'epoch': 2.38}
 79%|███████▉  | 3600/4545 [4:41:11<2:01:39,  7.72s/it] 79%|███████▉  | 3601/4545 [4:42:18<6:42:16, 25.57s/it] 79%|███████▉  | 3602/4545 [4:42:34<5:57:49, 22.77s/it] 79%|███████▉  | 3603/4545 [4:42:51<5:30:05, 21.02s/it] 79%|███████▉  | 3604/4545 [4:43:08<5:08:55, 19.70s/it] 79%|███████▉  | 3605/4545 [4:43:25<4:54:33, 18.80s/it] 79%|███████▉  | 3606/4545 [4:43:41<4:44:17, 18.17s/it] 79%|███████▉  | 3607/4545 [4:43:58<4:37:53, 17.78s/it] 79%|███████▉  | 3608/4545 [4:44:15<4:32:26, 17.45s/it] 79%|███████▉  | 3609/4545 [4:44:30<4:21:03, 16.73s/it] 79%|███████▉  | 3610/4545 [4:44:34<3:20:52, 12.89s/it]                                                       {'loss': 0.335, 'grad_norm': 41.991355895996094, 'learning_rate': 2.9567163753944058e-08, 'rewards/chosen': 2.030956983566284, 'rewards/rejected': -1.2617676258087158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.29296875, 'logps/chosen': -282.3999938964844, 'logps/rejected': -129.4499969482422, 'logits/chosen': -6.928124904632568, 'logits/rejected': -6.90625, 'epoch': 2.38}
 79%|███████▉  | 3610/4545 [4:44:34<3:20:52, 12.89s/it] 79%|███████▉  | 3611/4545 [4:44:38<2:38:21, 10.17s/it] 79%|███████▉  | 3612/4545 [4:44:42<2:08:54,  8.29s/it] 79%|███████▉  | 3613/4545 [4:44:45<1:47:10,  6.90s/it] 80%|███████▉  | 3614/4545 [4:44:49<1:33:15,  6.01s/it] 80%|███████▉  | 3615/4545 [4:44:53<1:23:28,  5.39s/it] 80%|███████▉  | 3616/4545 [4:44:56<1:13:56,  4.78s/it] 80%|███████▉  | 3617/4545 [4:45:00<1:10:00,  4.53s/it] 80%|███████▉  | 3618/4545 [4:45:04<1:07:10,  4.35s/it] 80%|███████▉  | 3619/4545 [4:45:08<1:05:11,  4.22s/it] 80%|███████▉  | 3620/4545 [4:45:12<1:01:38,  4.00s/it]                                                       {'loss': 0.3019, 'grad_norm': 22.824460983276367, 'learning_rate': 2.9183754127946682e-08, 'rewards/chosen': 2.1351561546325684, 'rewards/rejected': -1.225000023841858, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.3609375953674316, 'logps/chosen': -281.20001220703125, 'logps/rejected': -160.25, 'logits/chosen': -6.875, 'logits/rejected': -6.734375, 'epoch': 2.39}
 80%|███████▉  | 3620/4545 [4:45:12<1:01:38,  4.00s/it] 80%|███████▉  | 3621/4545 [4:45:16<1:02:04,  4.03s/it] 80%|███████▉  | 3622/4545 [4:45:20<1:02:47,  4.08s/it] 80%|███████▉  | 3623/4545 [4:45:23<56:29,  3.68s/it]   80%|███████▉  | 3624/4545 [4:45:27<57:38,  3.75s/it] 80%|███████▉  | 3625/4545 [4:45:30<57:39,  3.76s/it] 80%|███████▉  | 3626/4545 [4:45:34<58:26,  3.82s/it] 80%|███████▉  | 3627/4545 [4:45:38<58:26,  3.82s/it] 80%|███████▉  | 3628/4545 [4:45:42<59:38,  3.90s/it] 80%|███████▉  | 3629/4545 [4:45:45<54:16,  3.55s/it] 80%|███████▉  | 3630/4545 [4:45:49<55:58,  3.67s/it]                                                     {'loss': 0.329, 'grad_norm': 38.4583625793457, 'learning_rate': 2.88031179310823e-08, 'rewards/chosen': 3.2142577171325684, 'rewards/rejected': -0.9624999761581421, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 4.175000190734863, 'logps/chosen': -416.8999938964844, 'logps/rejected': -213.625, 'logits/chosen': -6.703125, 'logits/rejected': -6.803124904632568, 'epoch': 2.4}
 80%|███████▉  | 3630/4545 [4:45:49<55:58,  3.67s/it] 80%|███████▉  | 3631/4545 [4:45:53<56:44,  3.73s/it] 80%|███████▉  | 3632/4545 [4:45:57<58:29,  3.84s/it] 80%|███████▉  | 3633/4545 [4:46:01<57:28,  3.78s/it] 80%|███████▉  | 3634/4545 [4:46:05<58:22,  3.84s/it] 80%|███████▉  | 3635/4545 [4:46:09<58:47,  3.88s/it] 80%|████████  | 3636/4545 [4:46:13<59:13,  3.91s/it] 80%|████████  | 3637/4545 [4:46:16<57:35,  3.81s/it] 80%|████████  | 3638/4545 [4:46:20<58:07,  3.85s/it] 80%|████████  | 3639/4545 [4:46:24<57:58,  3.84s/it] 80%|████████  | 3640/4545 [4:46:28<58:20,  3.87s/it]                                                     {'loss': 0.2805, 'grad_norm': 49.80929183959961, 'learning_rate': 2.8425296054947735e-08, 'rewards/chosen': 3.809375047683716, 'rewards/rejected': -0.853320300579071, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.665625095367432, 'logps/chosen': -423.95001220703125, 'logps/rejected': -171.8000030517578, 'logits/chosen': -6.803124904632568, 'logits/rejected': -6.884375095367432, 'epoch': 2.4}
 80%|████████  | 3640/4545 [4:46:28<58:20,  3.87s/it] 80%|████████  | 3641/4545 [4:46:32<1:00:01,  3.98s/it] 80%|████████  | 3642/4545 [4:46:35<55:52,  3.71s/it]   80%|████████  | 3643/4545 [4:46:39<57:11,  3.80s/it] 80%|████████  | 3644/4545 [4:46:43<57:44,  3.85s/it] 80%|████████  | 3645/4545 [4:46:46<53:40,  3.58s/it] 80%|████████  | 3646/4545 [4:46:50<54:45,  3.65s/it] 80%|████████  | 3647/4545 [4:46:53<54:11,  3.62s/it] 80%|████████  | 3648/4545 [4:46:56<51:05,  3.42s/it] 80%|████████  | 3649/4545 [4:47:00<53:51,  3.61s/it] 80%|████████  | 3650/4545 [4:47:04<55:17,  3.71s/it]                                                     {'loss': 0.2787, 'grad_norm': 37.82473373413086, 'learning_rate': 2.8050329088798453e-08, 'rewards/chosen': 1.558691382408142, 'rewards/rejected': -1.5476562976837158, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.108593702316284, 'logps/chosen': -221.0749969482422, 'logps/rejected': -120.1500015258789, 'logits/chosen': -7.059374809265137, 'logits/rejected': -6.715624809265137, 'epoch': 2.41}
 80%|████████  | 3650/4545 [4:47:04<55:17,  3.71s/it] 80%|████████  | 3651/4545 [4:47:08<52:54,  3.55s/it] 80%|████████  | 3652/4545 [4:47:11<54:33,  3.67s/it] 80%|████████  | 3653/4545 [4:47:15<55:44,  3.75s/it] 80%|████████  | 3654/4545 [4:47:19<56:45,  3.82s/it] 80%|████████  | 3655/4545 [4:47:23<57:11,  3.86s/it] 80%|████████  | 3656/4545 [4:47:27<57:33,  3.88s/it] 80%|████████  | 3657/4545 [4:47:31<58:58,  3.98s/it] 80%|████████  | 3658/4545 [4:47:35<58:40,  3.97s/it] 81%|████████  | 3659/4545 [4:47:39<58:27,  3.96s/it] 81%|████████  | 3660/4545 [4:47:43<58:21,  3.96s/it]                                                     {'loss': 0.3215, 'grad_norm': 22.243989944458008, 'learning_rate': 2.7678257315188e-08, 'rewards/chosen': 3.3753905296325684, 'rewards/rejected': -0.849609375, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 4.229687690734863, 'logps/chosen': -371.8999938964844, 'logps/rejected': -208.10000610351562, 'logits/chosen': -6.75, 'logits/rejected': -6.787499904632568, 'epoch': 2.42}
 81%|████████  | 3660/4545 [4:47:44<58:21,  3.96s/it] 81%|████████  | 3661/4545 [4:47:48<59:25,  4.03s/it] 81%|████████  | 3662/4545 [4:47:52<59:21,  4.03s/it] 81%|████████  | 3663/4545 [4:47:55<58:52,  4.01s/it] 81%|████████  | 3664/4545 [4:48:00<59:26,  4.05s/it] 81%|████████  | 3665/4545 [4:48:03<54:55,  3.75s/it] 81%|████████  | 3666/4545 [4:48:07<55:43,  3.80s/it] 81%|████████  | 3667/4545 [4:48:10<54:59,  3.76s/it] 81%|████████  | 3668/4545 [4:48:14<56:17,  3.85s/it] 81%|████████  | 3669/4545 [4:48:18<56:37,  3.88s/it] 81%|████████  | 3670/4545 [4:48:22<56:52,  3.90s/it]                                                     {'loss': 0.2302, 'grad_norm': 25.21930503845215, 'learning_rate': 2.730912070564064e-08, 'rewards/chosen': 3.0191407203674316, 'rewards/rejected': -1.231835961341858, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.247656345367432, 'logps/chosen': -377.75, 'logps/rejected': -202.1999969482422, 'logits/chosen': -7.009375095367432, 'logits/rejected': -6.818749904632568, 'epoch': 2.42}
 81%|████████  | 3670/4545 [4:48:23<56:52,  3.90s/it] 81%|████████  | 3671/4545 [4:48:26<58:09,  3.99s/it] 81%|████████  | 3672/4545 [4:48:30<55:36,  3.82s/it] 81%|████████  | 3673/4545 [4:48:33<54:11,  3.73s/it] 81%|████████  | 3674/4545 [4:48:37<55:05,  3.80s/it] 81%|████████  | 3675/4545 [4:48:41<55:40,  3.84s/it] 81%|████████  | 3676/4545 [4:48:45<56:06,  3.87s/it] 81%|████████  | 3677/4545 [4:48:49<56:22,  3.90s/it] 81%|████████  | 3678/4545 [4:48:53<56:52,  3.94s/it] 81%|████████  | 3679/4545 [4:48:57<56:47,  3.93s/it] 81%|████████  | 3680/4545 [4:49:01<55:50,  3.87s/it]                                                     {'loss': 0.2672, 'grad_norm': 22.134967803955078, 'learning_rate': 2.6942958916356994e-08, 'rewards/chosen': 2.8148436546325684, 'rewards/rejected': -0.7191406488418579, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.534374952316284, 'logps/chosen': -321.70001220703125, 'logps/rejected': -244.4499969482422, 'logits/chosen': -6.887499809265137, 'logits/rejected': -6.865624904632568, 'epoch': 2.43}
 81%|████████  | 3680/4545 [4:49:02<55:50,  3.87s/it] 81%|████████  | 3681/4545 [4:49:04<54:07,  3.76s/it] 81%|████████  | 3682/4545 [4:49:08<54:48,  3.81s/it] 81%|████████  | 3683/4545 [4:49:12<55:30,  3.86s/it] 81%|████████  | 3684/4545 [4:49:16<55:44,  3.88s/it] 81%|████████  | 3685/4545 [4:49:19<50:20,  3.51s/it] 81%|████████  | 3686/4545 [4:49:23<53:35,  3.74s/it] 81%|████████  | 3687/4545 [4:49:27<54:20,  3.80s/it] 81%|████████  | 3688/4545 [4:49:31<55:03,  3.85s/it] 81%|████████  | 3689/4545 [4:49:35<55:18,  3.88s/it] 81%|████████  | 3690/4545 [4:49:39<55:27,  3.89s/it]                                                     {'loss': 0.2297, 'grad_norm': 41.7503547668457, 'learning_rate': 2.6579811283953978e-08, 'rewards/chosen': 3.883984327316284, 'rewards/rejected': -1.07421875, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 4.949999809265137, 'logps/chosen': -457.3500061035156, 'logps/rejected': -236.85000610351562, 'logits/chosen': -6.909375190734863, 'logits/rejected': -6.75, 'epoch': 2.44}
 81%|████████  | 3690/4545 [4:49:39<55:27,  3.89s/it] 81%|████████  | 3691/4545 [4:49:43<54:37,  3.84s/it] 81%|████████  | 3692/4545 [4:49:47<55:06,  3.88s/it] 81%|████████▏ | 3693/4545 [4:49:51<55:26,  3.90s/it] 81%|████████▏ | 3694/4545 [4:49:54<52:48,  3.72s/it] 81%|████████▏ | 3695/4545 [4:49:58<53:48,  3.80s/it] 81%|████████▏ | 3696/4545 [4:50:02<54:25,  3.85s/it] 81%|████████▏ | 3697/4545 [4:50:04<49:21,  3.49s/it] 81%|████████▏ | 3698/4545 [4:50:09<52:29,  3.72s/it] 81%|████████▏ | 3699/4545 [4:50:12<50:04,  3.55s/it] 81%|████████▏ | 3700/4545 [4:50:16<51:38,  3.67s/it]                                                     {'loss': 0.3218, 'grad_norm': 33.7840461730957, 'learning_rate': 2.621971682123883e-08, 'rewards/chosen': 2.100292921066284, 'rewards/rejected': -1.051367163658142, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.151562452316284, 'logps/chosen': -258.95001220703125, 'logps/rejected': -184.9250030517578, 'logits/chosen': -6.971875190734863, 'logits/rejected': -7.040625095367432, 'epoch': 2.44}
 81%|████████▏ | 3700/4545 [4:50:16<51:38,  3.67s/it] 81%|████████▏ | 3701/4545 [4:50:20<52:33,  3.74s/it] 81%|████████▏ | 3702/4545 [4:50:24<53:20,  3.80s/it] 81%|████████▏ | 3703/4545 [4:50:28<53:52,  3.84s/it] 81%|████████▏ | 3704/4545 [4:50:32<54:16,  3.87s/it] 82%|████████▏ | 3705/4545 [4:50:36<55:12,  3.94s/it] 82%|████████▏ | 3706/4545 [4:50:40<55:08,  3.94s/it] 82%|████████▏ | 3707/4545 [4:50:43<54:23,  3.89s/it] 82%|████████▏ | 3708/4545 [4:50:47<53:48,  3.86s/it] 82%|████████▏ | 3709/4545 [4:50:51<54:15,  3.89s/it] 82%|████████▏ | 3710/4545 [4:50:55<54:04,  3.89s/it]                                                     {'loss': 0.3177, 'grad_norm': 58.67063903808594, 'learning_rate': 2.5862714213017923e-08, 'rewards/chosen': 1.864648461341858, 'rewards/rejected': -0.8960937261581421, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 2.758593797683716, 'logps/chosen': -240.9499969482422, 'logps/rejected': -190.64999389648438, 'logits/chosen': -7.137499809265137, 'logits/rejected': -6.953125, 'epoch': 2.45}
 82%|████████▏ | 3710/4545 [4:50:55<54:04,  3.89s/it] 82%|████████▏ | 3711/4545 [4:50:59<55:17,  3.98s/it] 82%|████████▏ | 3712/4545 [4:51:03<56:23,  4.06s/it] 82%|████████▏ | 3713/4545 [4:51:07<55:45,  4.02s/it] 82%|████████▏ | 3714/4545 [4:51:11<53:26,  3.86s/it] 82%|████████▏ | 3715/4545 [4:51:15<54:44,  3.96s/it] 82%|████████▏ | 3716/4545 [4:51:19<53:22,  3.86s/it] 82%|████████▏ | 3717/4545 [4:51:23<54:14,  3.93s/it] 82%|████████▏ | 3718/4545 [4:51:27<53:37,  3.89s/it] 82%|████████▏ | 3719/4545 [4:51:30<53:44,  3.90s/it] 82%|████████▏ | 3720/4545 [4:51:59<2:36:43, 11.40s/it]                                                       {'loss': 0.3705, 'grad_norm': 19.016633987426758, 'learning_rate': 2.550884181194095e-08, 'rewards/chosen': 1.5949218273162842, 'rewards/rejected': -1.259423851966858, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.852343797683716, 'logps/chosen': -234.3000030517578, 'logps/rejected': -142.8000030517578, 'logits/chosen': -6.965624809265137, 'logits/rejected': -6.962500095367432, 'epoch': 2.46}
 82%|████████▏ | 3720/4545 [4:51:59<2:36:43, 11.40s/it] 82%|████████▏ | 3721/4545 [4:52:02<2:01:50,  8.87s/it] 82%|████████▏ | 3722/4545 [4:52:06<1:41:26,  7.40s/it] 82%|████████▏ | 3723/4545 [4:52:10<1:27:06,  6.36s/it] 82%|████████▏ | 3724/4545 [4:52:14<1:17:55,  5.70s/it] 82%|████████▏ | 3725/4545 [4:52:17<1:06:13,  4.85s/it] 82%|████████▏ | 3726/4545 [4:52:21<1:03:44,  4.67s/it] 82%|████████▏ | 3727/4545 [4:52:25<1:00:43,  4.45s/it] 82%|████████▏ | 3728/4545 [4:52:30<59:39,  4.38s/it]   82%|████████▏ | 3729/4545 [4:52:34<58:59,  4.34s/it] 82%|████████▏ | 3730/4545 [4:52:37<54:53,  4.04s/it]                                                     {'loss': 0.2572, 'grad_norm': 17.740636825561523, 'learning_rate': 2.5158137634380684e-08, 'rewards/chosen': 3.6337890625, 'rewards/rejected': -0.9769531488418579, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.611718654632568, 'logps/chosen': -387.45001220703125, 'logps/rejected': -194.39999389648438, 'logits/chosen': -7.103125095367432, 'logits/rejected': -6.887499809265137, 'epoch': 2.46}
 82%|████████▏ | 3730/4545 [4:52:38<54:53,  4.04s/it] 82%|████████▏ | 3731/4545 [4:52:41<55:17,  4.08s/it] 82%|████████▏ | 3732/4545 [4:52:45<52:35,  3.88s/it] 82%|████████▏ | 3733/4545 [4:52:49<52:48,  3.90s/it] 82%|████████▏ | 3734/4545 [4:52:53<54:07,  4.00s/it] 82%|████████▏ | 3735/4545 [4:52:56<51:30,  3.82s/it] 82%|████████▏ | 3736/4545 [4:53:00<52:09,  3.87s/it] 82%|████████▏ | 3737/4545 [4:53:04<50:09,  3.72s/it] 82%|████████▏ | 3738/4545 [4:53:08<50:56,  3.79s/it] 82%|████████▏ | 3739/4545 [4:53:12<51:27,  3.83s/it] 82%|████████▏ | 3740/4545 [4:53:16<52:13,  3.89s/it]                                                     {'loss': 0.2704, 'grad_norm': 55.99713134765625, 'learning_rate': 2.4810639356348882e-08, 'rewards/chosen': 2.148144483566284, 'rewards/rejected': -1.268896460533142, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.4124999046325684, 'logps/chosen': -257.79998779296875, 'logps/rejected': -166.75, 'logits/chosen': -7.009375095367432, 'logits/rejected': -7.037499904632568, 'epoch': 2.47}
 82%|████████▏ | 3740/4545 [4:53:16<52:13,  3.89s/it] 82%|████████▏ | 3741/4545 [4:53:20<53:19,  3.98s/it] 82%|████████▏ | 3742/4545 [4:53:24<53:06,  3.97s/it] 82%|████████▏ | 3743/4545 [4:53:27<51:17,  3.84s/it] 82%|████████▏ | 3744/4545 [4:53:31<51:36,  3.87s/it] 82%|████████▏ | 3745/4545 [4:53:36<53:01,  3.98s/it] 82%|████████▏ | 3746/4545 [4:53:40<54:05,  4.06s/it] 82%|████████▏ | 3747/4545 [4:53:44<53:01,  3.99s/it] 82%|████████▏ | 3748/4545 [4:53:47<52:32,  3.96s/it] 82%|████████▏ | 3749/4545 [4:53:52<53:27,  4.03s/it] 83%|████████▎ | 3750/4545 [4:53:56<53:20,  4.03s/it]                                                     {'loss': 0.2914, 'grad_norm': 21.67258644104004, 'learning_rate': 2.4466384309448795e-08, 'rewards/chosen': 1.8193359375, 'rewards/rejected': -1.632910132408142, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.452343702316284, 'logps/chosen': -257.1499938964844, 'logps/rejected': -145.9499969482422, 'logits/chosen': -7.021874904632568, 'logits/rejected': -6.890625, 'epoch': 2.48}
 83%|████████▎ | 3750/4545 [4:53:56<53:20,  4.03s/it] 83%|████████▎ | 3751/4545 [4:54:00<52:29,  3.97s/it] 83%|████████▎ | 3752/4545 [4:54:04<52:57,  4.01s/it] 83%|████████▎ | 3753/4545 [4:54:07<51:02,  3.87s/it] 83%|████████▎ | 3754/4545 [4:54:11<51:16,  3.89s/it] 83%|████████▎ | 3755/4545 [4:54:15<51:31,  3.91s/it] 83%|████████▎ | 3756/4545 [4:54:19<52:18,  3.98s/it] 83%|████████▎ | 3757/4545 [4:54:22<48:30,  3.69s/it] 83%|████████▎ | 3758/4545 [4:54:26<50:12,  3.83s/it] 83%|████████▎ | 3759/4545 [4:54:31<51:51,  3.96s/it] 83%|████████▎ | 3760/4545 [4:54:34<50:26,  3.85s/it]                                                     {'loss': 0.2906, 'grad_norm': 23.79267692565918, 'learning_rate': 2.4125409476864618e-08, 'rewards/chosen': 1.276269555091858, 'rewards/rejected': -1.814062476158142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.0875000953674316, 'logps/chosen': -179.9499969482422, 'logps/rejected': -136.35000610351562, 'logits/chosen': -7.118750095367432, 'logits/rejected': -7.162499904632568, 'epoch': 2.48}
 83%|████████▎ | 3760/4545 [4:54:34<50:26,  3.85s/it] 83%|████████▎ | 3761/4545 [4:54:38<50:54,  3.90s/it] 83%|████████▎ | 3762/4545 [4:54:40<42:22,  3.25s/it] 83%|████████▎ | 3763/4545 [4:54:44<45:57,  3.53s/it] 83%|████████▎ | 3764/4545 [4:54:47<44:33,  3.42s/it] 83%|████████▎ | 3765/4545 [4:54:50<39:49,  3.06s/it] 83%|████████▎ | 3766/4545 [4:54:54<43:16,  3.33s/it] 83%|████████▎ | 3767/4545 [4:54:58<46:20,  3.57s/it] 83%|████████▎ | 3768/4545 [4:55:02<48:43,  3.76s/it] 83%|████████▎ | 3769/4545 [4:55:05<47:45,  3.69s/it] 83%|████████▎ | 3770/4545 [4:55:10<49:22,  3.82s/it]                                                     {'loss': 0.304, 'grad_norm': 79.05239868164062, 'learning_rate': 2.378775148938838e-08, 'rewards/chosen': 2.285937547683716, 'rewards/rejected': -0.9292968511581421, 'rewards/accuracies': 0.875, 'rewards/margins': 3.217968702316284, 'logps/chosen': -272.29998779296875, 'logps/rejected': -184.89999389648438, 'logits/chosen': -7.231249809265137, 'logits/rejected': -7.209374904632568, 'epoch': 2.49}
 83%|████████▎ | 3770/4545 [4:55:10<49:22,  3.82s/it] 83%|████████▎ | 3771/4545 [4:55:14<50:45,  3.93s/it] 83%|████████▎ | 3772/4545 [4:55:18<52:23,  4.07s/it] 83%|████████▎ | 3773/4545 [4:55:21<48:57,  3.81s/it] 83%|████████▎ | 3774/4545 [4:55:25<49:27,  3.85s/it] 83%|████████▎ | 3775/4545 [4:55:29<50:30,  3.94s/it] 83%|████████▎ | 3776/4545 [4:55:33<50:26,  3.94s/it] 83%|████████▎ | 3777/4545 [4:55:37<49:49,  3.89s/it] 83%|████████▎ | 3778/4545 [4:55:41<50:41,  3.97s/it] 83%|████████▎ | 3779/4545 [4:55:45<50:34,  3.96s/it] 83%|████████▎ | 3780/4545 [4:55:49<50:22,  3.95s/it]                                                     {'loss': 0.2628, 'grad_norm': 38.43938064575195, 'learning_rate': 2.3453446621484804e-08, 'rewards/chosen': 1.5986328125, 'rewards/rejected': -1.5661132335662842, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.1624999046325684, 'logps/chosen': -231.39999389648438, 'logps/rejected': -152.3000030517578, 'logits/chosen': -6.953125, 'logits/rejected': -6.878125190734863, 'epoch': 2.5}
 83%|████████▎ | 3780/4545 [4:55:49<50:22,  3.95s/it] 83%|████████▎ | 3781/4545 [4:55:53<50:29,  3.97s/it] 83%|████████▎ | 3782/4545 [4:55:56<45:20,  3.57s/it] 83%|████████▎ | 3783/4545 [4:56:00<46:44,  3.68s/it] 83%|████████▎ | 3784/4545 [4:56:03<45:59,  3.63s/it] 83%|████████▎ | 3785/4545 [4:56:07<47:08,  3.72s/it] 83%|████████▎ | 3786/4545 [4:56:11<48:44,  3.85s/it] 83%|████████▎ | 3787/4545 [4:56:14<44:20,  3.51s/it] 83%|████████▎ | 3788/4545 [4:56:18<45:02,  3.57s/it] 83%|████████▎ | 3789/4545 [4:56:21<43:54,  3.48s/it] 83%|████████▎ | 3790/4545 [4:56:25<44:40,  3.55s/it]                                                     {'loss': 0.3135, 'grad_norm': 40.632930755615234, 'learning_rate': 2.312253078739427e-08, 'rewards/chosen': 1.563085913658142, 'rewards/rejected': -1.437109351158142, 'rewards/accuracies': 0.875, 'rewards/margins': 3.0, 'logps/chosen': -238.8000030517578, 'logps/rejected': -168.85000610351562, 'logits/chosen': -7.106249809265137, 'logits/rejected': -6.824999809265137, 'epoch': 2.5}
 83%|████████▎ | 3790/4545 [4:56:25<44:40,  3.55s/it] 83%|████████▎ | 3791/4545 [4:56:29<46:19,  3.69s/it] 83%|████████▎ | 3792/4545 [4:56:32<46:38,  3.72s/it] 83%|████████▎ | 3793/4545 [4:56:36<46:01,  3.67s/it] 83%|████████▎ | 3794/4545 [4:56:40<45:22,  3.62s/it] 83%|████████▎ | 3795/4545 [4:56:44<46:41,  3.73s/it] 84%|████████▎ | 3796/4545 [4:56:47<46:35,  3.73s/it] 84%|████████▎ | 3797/4545 [4:56:51<47:10,  3.78s/it] 84%|████████▎ | 3798/4545 [4:56:55<48:25,  3.89s/it] 84%|████████▎ | 3799/4545 [4:56:59<48:01,  3.86s/it] 84%|████████▎ | 3800/4545 [4:57:02<45:43,  3.68s/it]                                                     {'loss': 0.3294, 'grad_norm': 56.71363830566406, 'learning_rate': 2.2795039537274573e-08, 'rewards/chosen': 1.1513671875, 'rewards/rejected': -1.529687523841858, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.680468797683716, 'logps/chosen': -129.6999969482422, 'logps/rejected': -105.0250015258789, 'logits/chosen': -7.428124904632568, 'logits/rejected': -7.296875, 'epoch': 2.51}
 84%|████████▎ | 3800/4545 [4:57:03<45:43,  3.68s/it] 84%|████████▎ | 3801/4545 [4:57:07<47:19,  3.82s/it] 84%|████████▎ | 3802/4545 [4:57:10<47:44,  3.86s/it] 84%|████████▎ | 3803/4545 [4:57:14<45:24,  3.67s/it] 84%|████████▎ | 3804/4545 [4:57:18<47:23,  3.84s/it] 84%|████████▎ | 3805/4545 [4:57:21<45:03,  3.65s/it] 84%|████████▎ | 3806/4545 [4:57:25<45:41,  3.71s/it] 84%|████████▍ | 3807/4545 [4:57:29<45:02,  3.66s/it] 84%|████████▍ | 3808/4545 [4:57:33<46:15,  3.77s/it] 84%|████████▍ | 3809/4545 [4:57:37<47:41,  3.89s/it] 84%|████████▍ | 3810/4545 [4:57:40<44:14,  3.61s/it]                                                     {'loss': 0.275, 'grad_norm': 20.460689544677734, 'learning_rate': 2.247100805338182e-08, 'rewards/chosen': 1.349707007408142, 'rewards/rejected': -1.9445312023162842, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.296093702316284, 'logps/chosen': -191.5, 'logps/rejected': -118.4749984741211, 'logits/chosen': -7.056250095367432, 'logits/rejected': -7.040625095367432, 'epoch': 2.51}
 84%|████████▍ | 3810/4545 [4:57:40<44:14,  3.61s/it] 84%|████████▍ | 3811/4545 [4:57:44<45:30,  3.72s/it] 84%|████████▍ | 3812/4545 [4:57:48<46:14,  3.79s/it] 84%|████████▍ | 3813/4545 [4:57:50<42:34,  3.49s/it] 84%|████████▍ | 3814/4545 [4:57:54<42:54,  3.52s/it] 84%|████████▍ | 3815/4545 [4:57:58<44:22,  3.65s/it] 84%|████████▍ | 3816/4545 [4:58:02<45:34,  3.75s/it] 84%|████████▍ | 3817/4545 [4:58:06<46:11,  3.81s/it] 84%|████████▍ | 3818/4545 [4:58:09<44:34,  3.68s/it] 84%|████████▍ | 3819/4545 [4:58:13<45:28,  3.76s/it] 84%|████████▍ | 3820/4545 [4:58:17<46:07,  3.82s/it]                                                     {'loss': 0.3238, 'grad_norm': 43.511146545410156, 'learning_rate': 2.215047114629079e-08, 'rewards/chosen': 3.7798829078674316, 'rewards/rejected': -0.557177722454071, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.330468654632568, 'logps/chosen': -461.45001220703125, 'logps/rejected': -240.6999969482422, 'logits/chosen': -6.768750190734863, 'logits/rejected': -6.9375, 'epoch': 2.52}
 84%|████████▍ | 3820/4545 [4:58:17<46:07,  3.82s/it] 84%|████████▍ | 3821/4545 [4:58:21<46:42,  3.87s/it] 84%|████████▍ | 3822/4545 [4:58:25<45:17,  3.76s/it] 84%|████████▍ | 3823/4545 [4:58:29<46:49,  3.89s/it] 84%|████████▍ | 3824/4545 [4:58:33<46:55,  3.90s/it] 84%|████████▍ | 3825/4545 [4:58:37<47:37,  3.97s/it] 84%|████████▍ | 3826/4545 [4:58:40<44:45,  3.74s/it] 84%|████████▍ | 3827/4545 [4:58:44<46:41,  3.90s/it] 84%|████████▍ | 3828/4545 [4:58:47<43:48,  3.67s/it] 84%|████████▍ | 3829/4545 [4:58:52<45:00,  3.77s/it] 84%|████████▍ | 3830/4545 [4:58:55<45:24,  3.81s/it]                                                     {'loss': 0.231, 'grad_norm': 18.419504165649414, 'learning_rate': 2.1833463251155264e-08, 'rewards/chosen': 1.6531250476837158, 'rewards/rejected': -1.7355468273162842, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.3921875953674316, 'logps/chosen': -238.10000610351562, 'logps/rejected': -154.5, 'logits/chosen': -7.037499904632568, 'logits/rejected': -6.896874904632568, 'epoch': 2.53}
 84%|████████▍ | 3830/4545 [4:58:56<45:24,  3.81s/it] 84%|████████▍ | 3831/4545 [4:59:00<46:25,  3.90s/it] 84%|████████▍ | 3832/4545 [4:59:02<41:47,  3.52s/it] 84%|████████▍ | 3833/4545 [4:59:06<41:50,  3.53s/it] 84%|████████▍ | 3834/4545 [4:59:10<43:37,  3.68s/it] 84%|████████▍ | 3835/4545 [4:59:14<44:31,  3.76s/it] 84%|████████▍ | 3836/4545 [4:59:18<45:04,  3.81s/it] 84%|████████▍ | 3837/4545 [4:59:22<45:29,  3.85s/it] 84%|████████▍ | 3838/4545 [4:59:25<44:14,  3.75s/it] 84%|████████▍ | 3839/4545 [4:59:28<42:01,  3.57s/it] 84%|████████▍ | 3840/4545 [4:59:32<43:53,  3.74s/it]                                                     {'loss': 0.2854, 'grad_norm': 49.9277229309082, 'learning_rate': 2.1520018424008645e-08, 'rewards/chosen': 2.577343702316284, 'rewards/rejected': -0.904980480670929, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.4859375953674316, 'logps/chosen': -290.625, 'logps/rejected': -202.0, 'logits/chosen': -7.043749809265137, 'logits/rejected': -6.971875190734863, 'epoch': 2.53}
 84%|████████▍ | 3840/4545 [4:59:32<43:53,  3.74s/it] 85%|████████▍ | 3841/4545 [4:59:36<44:42,  3.81s/it] 85%|████████▍ | 3842/4545 [4:59:40<44:19,  3.78s/it] 85%|████████▍ | 3843/4545 [4:59:44<44:45,  3.83s/it] 85%|████████▍ | 3844/4545 [4:59:48<45:11,  3.87s/it] 85%|████████▍ | 3845/4545 [4:59:52<44:36,  3.82s/it] 85%|████████▍ | 3846/4545 [4:59:56<45:00,  3.86s/it] 85%|████████▍ | 3847/4545 [5:00:00<46:23,  3.99s/it] 85%|████████▍ | 3848/4545 [5:00:03<43:49,  3.77s/it] 85%|████████▍ | 3849/4545 [5:00:07<43:55,  3.79s/it] 85%|████████▍ | 3850/4545 [5:00:11<44:15,  3.82s/it]                                                     {'loss': 0.2342, 'grad_norm': 47.17750930786133, 'learning_rate': 2.1210170338105325e-08, 'rewards/chosen': 1.7607421875, 'rewards/rejected': -1.812890648841858, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 3.571093797683716, 'logps/chosen': -233.85000610351562, 'logps/rejected': -116.67500305175781, 'logits/chosen': -7.109375, 'logits/rejected': -6.893750190734863, 'epoch': 2.54}
 85%|████████▍ | 3850/4545 [5:00:12<44:15,  3.82s/it] 85%|████████▍ | 3851/4545 [5:00:15<45:31,  3.94s/it] 85%|████████▍ | 3852/4545 [5:00:19<46:24,  4.02s/it] 85%|████████▍ | 3853/4545 [5:00:23<44:33,  3.86s/it] 85%|████████▍ | 3854/4545 [5:00:27<44:37,  3.88s/it] 85%|████████▍ | 3855/4545 [5:00:31<44:16,  3.85s/it] 85%|████████▍ | 3856/4545 [5:00:34<42:03,  3.66s/it] 85%|████████▍ | 3857/4545 [5:00:38<43:19,  3.78s/it] 85%|████████▍ | 3858/4545 [5:00:42<44:11,  3.86s/it] 85%|████████▍ | 3859/4545 [5:00:45<42:32,  3.72s/it] 85%|████████▍ | 3860/4545 [5:00:49<43:00,  3.77s/it]                                                     {'loss': 0.3117, 'grad_norm': 33.63016891479492, 'learning_rate': 2.0903952280303228e-08, 'rewards/chosen': 1.930029273033142, 'rewards/rejected': -1.4210937023162842, 'rewards/accuracies': 0.875, 'rewards/margins': 3.3578124046325684, 'logps/chosen': -243.35000610351562, 'logps/rejected': -160.52499389648438, 'logits/chosen': -6.943749904632568, 'logits/rejected': -6.646874904632568, 'epoch': 2.55}
 85%|████████▍ | 3860/4545 [5:00:49<43:00,  3.77s/it] 85%|████████▍ | 3861/4545 [5:00:53<44:33,  3.91s/it] 85%|████████▍ | 3862/4545 [5:00:57<44:34,  3.92s/it] 85%|████████▍ | 3863/4545 [5:01:01<44:36,  3.92s/it] 85%|████████▌ | 3864/4545 [5:01:04<41:04,  3.62s/it] 85%|████████▌ | 3865/4545 [5:01:08<40:16,  3.55s/it] 85%|████████▌ | 3866/4545 [5:01:10<37:41,  3.33s/it] 85%|████████▌ | 3867/4545 [5:01:14<39:42,  3.51s/it] 85%|████████▌ | 3868/4545 [5:01:18<41:12,  3.65s/it] 85%|████████▌ | 3869/4545 [5:01:22<42:06,  3.74s/it] 85%|████████▌ | 3870/4545 [5:01:25<40:21,  3.59s/it]                                                     {'loss': 0.3062, 'grad_norm': 20.600006103515625, 'learning_rate': 2.0601397147487793e-08, 'rewards/chosen': 2.174999952316284, 'rewards/rejected': -1.143945336341858, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.321093797683716, 'logps/chosen': -287.3500061035156, 'logps/rejected': -149.1999969482422, 'logits/chosen': -7.056250095367432, 'logits/rejected': -7.025000095367432, 'epoch': 2.55}
 85%|████████▌ | 3870/4545 [5:01:26<40:21,  3.59s/it] 85%|████████▌ | 3871/4545 [5:01:29<39:17,  3.50s/it] 85%|████████▌ | 3872/4545 [5:01:33<40:42,  3.63s/it] 85%|████████▌ | 3873/4545 [5:01:37<42:30,  3.80s/it] 85%|████████▌ | 3874/4545 [5:01:39<38:38,  3.46s/it] 85%|████████▌ | 3875/4545 [5:01:43<40:09,  3.60s/it] 85%|████████▌ | 3876/4545 [5:01:48<41:55,  3.76s/it] 85%|████████▌ | 3877/4545 [5:01:52<42:27,  3.81s/it] 85%|████████▌ | 3878/4545 [5:01:56<43:05,  3.88s/it] 85%|████████▌ | 3879/4545 [5:01:59<42:46,  3.85s/it] 85%|████████▌ | 3880/4545 [5:02:03<43:17,  3.91s/it]                                                     {'loss': 0.3208, 'grad_norm': 50.253116607666016, 'learning_rate': 2.0302537443037818e-08, 'rewards/chosen': 2.812084913253784, 'rewards/rejected': -0.632031261920929, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.4429688453674316, 'logps/chosen': -348.54998779296875, 'logps/rejected': -173.77499389648438, 'logits/chosen': -6.971875190734863, 'logits/rejected': -6.956250190734863, 'epoch': 2.56}
 85%|████████▌ | 3880/4545 [5:02:03<43:17,  3.91s/it] 85%|████████▌ | 3881/4545 [5:02:05<36:58,  3.34s/it] 85%|████████▌ | 3882/4545 [5:02:09<36:44,  3.32s/it] 85%|████████▌ | 3883/4545 [5:02:12<37:49,  3.43s/it] 85%|████████▌ | 3884/4545 [5:02:16<40:09,  3.65s/it] 85%|████████▌ | 3885/4545 [5:02:19<37:32,  3.41s/it] 86%|████████▌ | 3886/4545 [5:02:23<39:14,  3.57s/it] 86%|████████▌ | 3887/4545 [5:02:27<40:21,  3.68s/it] 86%|████████▌ | 3888/4545 [5:02:31<41:10,  3.76s/it] 86%|████████▌ | 3889/4545 [5:02:35<41:43,  3.82s/it] 86%|████████▌ | 3890/4545 [5:02:38<38:31,  3.53s/it]                                                     {'loss': 0.296, 'grad_norm': 21.276233673095703, 'learning_rate': 2.0007405273333765e-08, 'rewards/chosen': 2.866406202316284, 'rewards/rejected': -1.416015625, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.278124809265137, 'logps/chosen': -363.2749938964844, 'logps/rejected': -186.625, 'logits/chosen': -6.896874904632568, 'logits/rejected': -6.928124904632568, 'epoch': 2.57}
 86%|████████▌ | 3890/4545 [5:02:38<38:31,  3.53s/it] 86%|████████▌ | 3891/4545 [5:02:42<38:35,  3.54s/it] 86%|████████▌ | 3892/4545 [5:02:43<33:03,  3.04s/it] 86%|████████▌ | 3893/4545 [5:02:47<35:55,  3.31s/it] 86%|████████▌ | 3894/4545 [5:02:50<33:49,  3.12s/it] 86%|████████▌ | 3895/4545 [5:02:54<36:28,  3.37s/it] 86%|████████▌ | 3896/4545 [5:02:57<35:54,  3.32s/it] 86%|████████▌ | 3897/4545 [5:03:01<37:39,  3.49s/it] 86%|████████▌ | 3898/4545 [5:03:05<39:06,  3.63s/it] 86%|████████▌ | 3899/4545 [5:03:09<38:47,  3.60s/it] 86%|████████▌ | 3900/4545 [5:03:13<40:25,  3.76s/it]                                                     {'loss': 0.304, 'grad_norm': 76.92189025878906, 'learning_rate': 1.9716032344308464e-08, 'rewards/chosen': 1.6886718273162842, 'rewards/rejected': -1.444921851158142, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.133593797683716, 'logps/chosen': -207.8249969482422, 'logps/rejected': -138.22500610351562, 'logits/chosen': -7.181250095367432, 'logits/rejected': -7.099999904632568, 'epoch': 2.57}
 86%|████████▌ | 3900/4545 [5:03:13<40:25,  3.76s/it] 86%|████████▌ | 3901/4545 [5:03:17<41:05,  3.83s/it] 86%|████████▌ | 3902/4545 [5:03:20<38:42,  3.61s/it] 86%|████████▌ | 3903/4545 [5:03:24<40:13,  3.76s/it] 86%|████████▌ | 3904/4545 [5:03:28<40:43,  3.81s/it] 86%|████████▌ | 3905/4545 [5:03:32<41:59,  3.94s/it] 86%|████████▌ | 3906/4545 [5:03:36<41:40,  3.91s/it] 86%|████████▌ | 3907/4545 [5:03:40<41:40,  3.92s/it] 86%|████████▌ | 3908/4545 [5:03:43<40:22,  3.80s/it] 86%|████████▌ | 3909/4545 [5:03:47<39:56,  3.77s/it] 86%|████████▌ | 3910/4545 [5:03:51<39:12,  3.70s/it]                                                     {'loss': 0.3254, 'grad_norm': 54.85232162475586, 'learning_rate': 1.9428449958040967e-08, 'rewards/chosen': 1.814062476158142, 'rewards/rejected': -1.7230956554412842, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.539843797683716, 'logps/chosen': -255.22500610351562, 'logps/rejected': -162.0500030517578, 'logits/chosen': -7.224999904632568, 'logits/rejected': -7.03125, 'epoch': 2.58}
 86%|████████▌ | 3910/4545 [5:03:51<39:12,  3.70s/it] 86%|████████▌ | 3911/4545 [5:03:55<40:45,  3.86s/it] 86%|████████▌ | 3912/4545 [5:03:59<40:12,  3.81s/it] 86%|████████▌ | 3913/4545 [5:04:02<40:35,  3.85s/it] 86%|████████▌ | 3914/4545 [5:04:06<40:48,  3.88s/it] 86%|████████▌ | 3915/4545 [5:04:10<38:51,  3.70s/it] 86%|████████▌ | 3916/4545 [5:04:14<39:20,  3.75s/it] 86%|████████▌ | 3917/4545 [5:04:17<39:19,  3.76s/it] 86%|████████▌ | 3918/4545 [5:04:21<37:48,  3.62s/it] 86%|████████▌ | 3919/4545 [5:04:24<38:01,  3.64s/it] 86%|████████▌ | 3920/4545 [5:04:28<38:52,  3.73s/it]                                                     {'loss': 0.2919, 'grad_norm': 35.721534729003906, 'learning_rate': 1.914468900939386e-08, 'rewards/chosen': 2.058837890625, 'rewards/rejected': -4.378710746765137, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 6.432421684265137, 'logps/chosen': -296.6000061035156, 'logps/rejected': -181.5, 'logits/chosen': -7.009375095367432, 'logits/rejected': -7.006249904632568, 'epoch': 2.59}
 86%|████████▌ | 3920/4545 [5:04:29<38:52,  3.73s/it] 86%|████████▋ | 3921/4545 [5:04:32<39:49,  3.83s/it] 86%|████████▋ | 3922/4545 [5:04:36<38:00,  3.66s/it] 86%|████████▋ | 3923/4545 [5:04:40<39:17,  3.79s/it] 86%|████████▋ | 3924/4545 [5:04:44<39:24,  3.81s/it] 86%|████████▋ | 3925/4545 [5:04:47<38:01,  3.68s/it] 86%|████████▋ | 3926/4545 [5:04:51<39:21,  3.81s/it] 86%|████████▋ | 3927/4545 [5:04:55<39:40,  3.85s/it] 86%|████████▋ | 3928/4545 [5:04:59<39:35,  3.85s/it] 86%|████████▋ | 3929/4545 [5:05:03<39:48,  3.88s/it] 86%|████████▋ | 3930/4545 [5:05:07<39:53,  3.89s/it]                                                     {'loss': 0.3026, 'grad_norm': 24.37552833557129, 'learning_rate': 1.886477998269418e-08, 'rewards/chosen': 2.6078124046325684, 'rewards/rejected': -1.149804711341858, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.7640624046325684, 'logps/chosen': -320.1499938964844, 'logps/rejected': -199.875, 'logits/chosen': -6.818749904632568, 'logits/rejected': -6.6875, 'epoch': 2.59}
 86%|████████▋ | 3930/4545 [5:05:07<39:53,  3.89s/it] 86%|████████▋ | 3931/4545 [5:05:10<38:05,  3.72s/it] 87%|████████▋ | 3932/4545 [5:05:14<38:39,  3.78s/it] 87%|████████▋ | 3933/4545 [5:05:18<38:09,  3.74s/it] 87%|████████▋ | 3934/4545 [5:05:22<38:46,  3.81s/it] 87%|████████▋ | 3935/4545 [5:05:26<40:00,  3.94s/it] 87%|████████▋ | 3936/4545 [5:05:30<39:55,  3.93s/it] 87%|████████▋ | 3937/4545 [5:05:34<40:30,  4.00s/it] 87%|████████▋ | 3938/4545 [5:05:38<39:37,  3.92s/it] 87%|████████▋ | 3939/4545 [5:05:42<40:16,  3.99s/it] 87%|████████▋ | 3940/4545 [5:05:45<38:55,  3.86s/it]                                                     {'loss': 0.3164, 'grad_norm': 26.292339324951172, 'learning_rate': 1.8588752948458475e-08, 'rewards/chosen': 2.046875, 'rewards/rejected': -1.313378930091858, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.358593702316284, 'logps/chosen': -279.70001220703125, 'logps/rejected': -157.39999389648438, 'logits/chosen': -6.971875190734863, 'logits/rejected': -6.878125190734863, 'epoch': 2.6}
 87%|████████▋ | 3940/4545 [5:05:46<38:55,  3.86s/it] 87%|████████▋ | 3941/4545 [5:05:49<39:23,  3.91s/it] 87%|████████▋ | 3942/4545 [5:05:53<39:59,  3.98s/it] 87%|████████▋ | 3943/4545 [5:05:57<39:01,  3.89s/it] 87%|████████▋ | 3944/4545 [5:06:01<39:08,  3.91s/it] 87%|████████▋ | 3945/4545 [5:06:05<38:19,  3.83s/it] 87%|████████▋ | 3946/4545 [5:06:09<38:50,  3.89s/it] 87%|████████▋ | 3947/4545 [5:06:13<39:24,  3.95s/it] 87%|████████▋ | 3948/4545 [5:06:17<39:03,  3.92s/it] 87%|████████▋ | 3949/4545 [5:06:21<39:02,  3.93s/it] 87%|████████▋ | 3950/4545 [5:06:25<39:01,  3.94s/it]                                                     {'loss': 0.2469, 'grad_norm': 28.32117462158203, 'learning_rate': 1.8316637560162394e-08, 'rewards/chosen': 2.3941407203674316, 'rewards/rejected': -1.1296875476837158, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.5257811546325684, 'logps/chosen': -299.8500061035156, 'logps/rejected': -207.10000610351562, 'logits/chosen': -6.890625, 'logits/rejected': -6.75, 'epoch': 2.61}
 87%|████████▋ | 3950/4545 [5:06:25<39:01,  3.94s/it] 87%|████████▋ | 3951/4545 [5:06:29<39:40,  4.01s/it] 87%|████████▋ | 3952/4545 [5:06:33<39:26,  3.99s/it] 87%|████████▋ | 3953/4545 [5:06:37<39:29,  4.00s/it] 87%|████████▋ | 3954/4545 [5:06:40<36:12,  3.68s/it] 87%|████████▋ | 3955/4545 [5:06:44<36:55,  3.76s/it] 87%|████████▋ | 3956/4545 [5:06:47<36:17,  3.70s/it] 87%|████████▋ | 3957/4545 [5:06:51<37:41,  3.85s/it] 87%|████████▋ | 3958/4545 [5:06:55<38:12,  3.91s/it] 87%|████████▋ | 3959/4545 [5:06:59<38:20,  3.93s/it] 87%|████████▋ | 3960/4545 [5:07:04<38:46,  3.98s/it]                                                     {'loss': 0.2805, 'grad_norm': 40.89581298828125, 'learning_rate': 1.8048463051055013e-08, 'rewards/chosen': 2.7017579078674316, 'rewards/rejected': -1.3263671398162842, 'rewards/accuracies': 0.875, 'rewards/margins': 4.029687404632568, 'logps/chosen': -303.45001220703125, 'logps/rejected': -176.0, 'logits/chosen': -7.084374904632568, 'logits/rejected': -6.753125190734863, 'epoch': 2.61}
 87%|████████▋ | 3960/4545 [5:07:04<38:46,  3.98s/it] 87%|████████▋ | 3961/4545 [5:07:08<38:50,  3.99s/it] 87%|████████▋ | 3962/4545 [5:07:12<39:02,  4.02s/it] 87%|████████▋ | 3963/4545 [5:07:16<38:53,  4.01s/it] 87%|████████▋ | 3964/4545 [5:07:19<37:51,  3.91s/it] 87%|████████▋ | 3965/4545 [5:07:23<36:29,  3.77s/it] 87%|████████▋ | 3966/4545 [5:07:26<35:01,  3.63s/it] 87%|████████▋ | 3967/4545 [5:07:30<36:34,  3.80s/it] 87%|████████▋ | 3968/4545 [5:07:34<35:59,  3.74s/it] 87%|████████▋ | 3969/4545 [5:07:37<35:16,  3.67s/it] 87%|████████▋ | 3970/4545 [5:07:40<33:11,  3.46s/it]                                                     {'loss': 0.2607, 'grad_norm': 22.518362045288086, 'learning_rate': 1.778425823101828e-08, 'rewards/chosen': 1.461328148841858, 'rewards/rejected': -1.803125023841858, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.268749952316284, 'logps/chosen': -198.4499969482422, 'logps/rejected': -137.3249969482422, 'logits/chosen': -7.118750095367432, 'logits/rejected': -6.928124904632568, 'epoch': 2.62}
 87%|████████▋ | 3970/4545 [5:07:41<33:11,  3.46s/it] 87%|████████▋ | 3971/4545 [5:07:45<35:57,  3.76s/it] 87%|████████▋ | 3972/4545 [5:07:48<34:32,  3.62s/it] 87%|████████▋ | 3973/4545 [5:07:52<35:35,  3.73s/it] 87%|████████▋ | 3974/4545 [5:07:56<35:21,  3.72s/it] 87%|████████▋ | 3975/4545 [5:08:00<36:40,  3.86s/it] 87%|████████▋ | 3976/4545 [5:08:04<36:48,  3.88s/it] 88%|████████▊ | 3977/4545 [5:08:08<36:53,  3.90s/it] 88%|████████▊ | 3978/4545 [5:08:12<36:55,  3.91s/it] 88%|████████▊ | 3979/4545 [5:08:15<34:43,  3.68s/it] 88%|████████▊ | 3980/4545 [5:08:19<35:21,  3.75s/it]                                                     {'loss': 0.2602, 'grad_norm': 34.305084228515625, 'learning_rate': 1.7524051483472048e-08, 'rewards/chosen': 2.523242235183716, 'rewards/rejected': -1.3649413585662842, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.8843750953674316, 'logps/chosen': -300.04998779296875, 'logps/rejected': -156.0, 'logits/chosen': -6.962500095367432, 'logits/rejected': -7.037499904632568, 'epoch': 2.63}
 88%|████████▊ | 3980/4545 [5:08:19<35:21,  3.75s/it] 88%|████████▊ | 3981/4545 [5:08:23<35:53,  3.82s/it] 88%|████████▊ | 3982/4545 [5:08:27<36:39,  3.91s/it] 88%|████████▊ | 3983/4545 [5:08:31<36:42,  3.92s/it] 88%|████████▊ | 3984/4545 [5:08:34<35:07,  3.76s/it] 88%|████████▊ | 3985/4545 [5:08:38<35:33,  3.81s/it] 88%|████████▊ | 3986/4545 [5:08:42<35:57,  3.86s/it] 88%|████████▊ | 3987/4545 [5:08:46<36:05,  3.88s/it] 88%|████████▊ | 3988/4545 [5:08:50<37:00,  3.99s/it] 88%|████████▊ | 3989/4545 [5:08:55<37:48,  4.08s/it] 88%|████████▊ | 3990/4545 [5:08:57<34:07,  3.69s/it]                                                     {'loss': 0.3175, 'grad_norm': 32.209197998046875, 'learning_rate': 1.726787076232476e-08, 'rewards/chosen': 2.280956983566284, 'rewards/rejected': -1.572265625, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.852343797683716, 'logps/chosen': -296.3999938964844, 'logps/rejected': -178.39999389648438, 'logits/chosen': -7.112500190734863, 'logits/rejected': -6.987500190734863, 'epoch': 2.63}
 88%|████████▊ | 3990/4545 [5:08:57<34:07,  3.69s/it] 88%|████████▊ | 3991/4545 [5:09:01<34:15,  3.71s/it] 88%|████████▊ | 3992/4545 [5:09:05<34:42,  3.77s/it] 88%|████████▊ | 3993/4545 [5:09:08<32:22,  3.52s/it] 88%|████████▊ | 3994/4545 [5:09:12<33:44,  3.67s/it] 88%|████████▊ | 3995/4545 [5:09:16<34:24,  3.75s/it] 88%|████████▊ | 3996/4545 [5:09:20<34:49,  3.81s/it] 88%|████████▊ | 3997/4545 [5:09:23<33:40,  3.69s/it] 88%|████████▊ | 3998/4545 [5:09:27<34:20,  3.77s/it] 88%|████████▊ | 3999/4545 [5:09:31<35:06,  3.86s/it] 88%|████████▊ | 4000/4545 [5:09:36<36:03,  3.97s/it]                                                     {'loss': 0.232, 'grad_norm': 24.858095169067383, 'learning_rate': 1.7015743588970472e-08, 'rewards/chosen': 2.181445360183716, 'rewards/rejected': -1.9128906726837158, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 4.090624809265137, 'logps/chosen': -275.54998779296875, 'logps/rejected': -154.0, 'logits/chosen': -7.175000190734863, 'logits/rejected': -7.0, 'epoch': 2.64}
 88%|████████▊ | 4000/4545 [5:09:36<36:03,  3.97s/it] 88%|████████▊ | 4001/4545 [5:09:39<33:56,  3.74s/it] 88%|████████▊ | 4002/4545 [5:09:43<34:38,  3.83s/it] 88%|████████▊ | 4003/4545 [5:09:47<34:53,  3.86s/it] 88%|████████▊ | 4004/4545 [5:09:50<32:53,  3.65s/it] 88%|████████▊ | 4005/4545 [5:09:54<33:36,  3.73s/it] 88%|████████▊ | 4006/4545 [5:09:58<34:53,  3.88s/it] 88%|████████▊ | 4007/4545 [5:10:01<32:53,  3.67s/it] 88%|████████▊ | 4008/4545 [5:10:05<33:31,  3.74s/it] 88%|████████▊ | 4009/4545 [5:10:09<33:56,  3.80s/it] 88%|████████▊ | 4010/4545 [5:10:13<34:39,  3.89s/it]                                                     {'loss': 0.2788, 'grad_norm': 33.90955352783203, 'learning_rate': 1.6767697049332196e-08, 'rewards/chosen': 1.927392601966858, 'rewards/rejected': -1.6501953601837158, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.5796875953674316, 'logps/chosen': -245.375, 'logps/rejected': -101.0999984741211, 'logits/chosen': -7.137499809265137, 'logits/rejected': -7.021874904632568, 'epoch': 2.65}
 88%|████████▊ | 4010/4545 [5:10:13<34:39,  3.89s/it] 88%|████████▊ | 4011/4545 [5:10:17<35:44,  4.02s/it] 88%|████████▊ | 4012/4545 [5:10:21<35:28,  3.99s/it] 88%|████████▊ | 4013/4545 [5:10:24<31:35,  3.56s/it] 88%|████████▊ | 4014/4545 [5:10:28<32:27,  3.67s/it] 88%|████████▊ | 4015/4545 [5:10:31<31:55,  3.61s/it] 88%|████████▊ | 4016/4545 [5:10:35<32:30,  3.69s/it] 88%|████████▊ | 4017/4545 [5:10:39<33:07,  3.76s/it] 88%|████████▊ | 4018/4545 [5:10:43<33:28,  3.81s/it] 88%|████████▊ | 4019/4545 [5:10:47<34:13,  3.90s/it] 88%|████████▊ | 4020/4545 [5:10:50<31:53,  3.64s/it]                                                     {'loss': 0.2635, 'grad_norm': 28.008459091186523, 'learning_rate': 1.6523757790952032e-08, 'rewards/chosen': 1.865625023841858, 'rewards/rejected': -1.5359375476837158, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.401562452316284, 'logps/chosen': -242.6999969482422, 'logps/rejected': -169.5, 'logits/chosen': -7.059374809265137, 'logits/rejected': -7.034375190734863, 'epoch': 2.65}
 88%|████████▊ | 4020/4545 [5:10:50<31:53,  3.64s/it] 88%|████████▊ | 4021/4545 [5:10:54<32:52,  3.77s/it] 88%|████████▊ | 4022/4545 [5:10:58<33:46,  3.87s/it] 89%|████████▊ | 4023/4545 [5:11:03<34:26,  3.96s/it] 89%|████████▊ | 4024/4545 [5:11:05<31:01,  3.57s/it] 89%|████████▊ | 4025/4545 [5:11:09<31:54,  3.68s/it] 89%|████████▊ | 4026/4545 [5:11:12<29:27,  3.41s/it] 89%|████████▊ | 4027/4545 [5:11:16<30:07,  3.49s/it] 89%|████████▊ | 4028/4545 [5:11:19<28:53,  3.35s/it] 89%|████████▊ | 4029/4545 [5:11:23<30:20,  3.53s/it] 89%|████████▊ | 4030/4545 [5:11:27<32:10,  3.75s/it]                                                     {'loss': 0.3425, 'grad_norm': 34.77946090698242, 'learning_rate': 1.6283952020128504e-08, 'rewards/chosen': 1.9890625476837158, 'rewards/rejected': -1.453125, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.442187547683716, 'logps/chosen': -282.20001220703125, 'logps/rejected': -152.0, 'logits/chosen': -7.053124904632568, 'logits/rejected': -7.053124904632568, 'epoch': 2.66}
 89%|████████▊ | 4030/4545 [5:11:27<32:10,  3.75s/it] 89%|████████▊ | 4031/4545 [5:11:31<32:49,  3.83s/it] 89%|████████▊ | 4032/4545 [5:11:34<31:08,  3.64s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:43,  1.33it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.53s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.63s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.52s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.10s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.09s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.26s/it][A
 43%|████▎     | 26/60 [01:00<05:11,  9.17s/it][A
 45%|████▌     | 27/60 [01:01<03:39,  6.65s/it][A
 47%|████▋     | 28/60 [01:02<02:37,  4.93s/it][A
 48%|████▊     | 29/60 [01:03<01:58,  3.81s/it][A
 50%|█████     | 30/60 [01:05<01:35,  3.17s/it][A
 52%|█████▏    | 31/60 [01:07<01:17,  2.69s/it][A
 53%|█████▎    | 32/60 [01:08<01:04,  2.31s/it][A
 55%|█████▌    | 33/60 [01:09<00:54,  2.02s/it][A
 57%|█████▋    | 34/60 [01:10<00:43,  1.66s/it][A
 58%|█████▊    | 35/60 [01:12<00:39,  1.59s/it][A
 60%|██████    | 36/60 [01:13<00:37,  1.54s/it][A
 62%|██████▏   | 37/60 [01:14<00:28,  1.26s/it][A
 63%|██████▎   | 38/60 [01:15<00:29,  1.35s/it][A
 65%|██████▌   | 39/60 [01:16<00:27,  1.29s/it][A
 67%|██████▋   | 40/60 [01:17<00:22,  1.14s/it][A
 68%|██████▊   | 41/60 [01:19<00:23,  1.23s/it][A
 70%|███████   | 42/60 [01:20<00:24,  1.33s/it][A
 72%|███████▏  | 43/60 [01:21<00:20,  1.22s/it][A
 73%|███████▎  | 44/60 [01:23<00:20,  1.30s/it][A
 75%|███████▌  | 45/60 [01:23<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [01:25<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:27<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:27<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:29<00:14,  1.34s/it][A
 83%|████████▎ | 50/60 [01:31<00:14,  1.45s/it][A
 85%|████████▌ | 51/60 [01:32<00:13,  1.48s/it][A
 87%|████████▋ | 52/60 [01:34<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:35<00:09,  1.32s/it][A
 90%|█████████ | 54/60 [01:36<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:37<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:39<00:05,  1.32s/it][A
 95%|█████████▌| 57/60 [01:40<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:42<00:02,  1.44s/it][A
 98%|█████████▊| 59/60 [01:43<00:01,  1.48s/it][A
100%|██████████| 60/60 [01:45<00:00,  1.53s/it][A                                                     
                                               [A{'eval_loss': 0.410354346036911, 'eval_runtime': 107.2974, 'eval_samples_per_second': 8.882, 'eval_steps_per_second': 0.559, 'eval_rewards/chosen': 2.61370849609375, 'eval_rewards/rejected': -0.39104411005973816, 'eval_rewards/accuracies': 0.7980324029922485, 'eval_rewards/margins': 3.0014710426330566, 'eval_logps/chosen': -364.4916687011719, 'eval_logps/rejected': -153.98333740234375, 'eval_logits/chosen': -6.742447853088379, 'eval_logits/rejected': -7.3494791984558105, 'epoch': 2.66}
 89%|████████▊ | 4032/4545 [5:13:22<31:08,  3.64s/it]
100%|██████████| 60/60 [01:45<00:00,  1.53s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 89%|████████▊ | 4033/4545 [5:13:38<5:37:41, 39.57s/it] 89%|████████▉ | 4034/4545 [5:13:41<4:05:55, 28.88s/it] 89%|████████▉ | 4035/4545 [5:13:45<3:01:07, 21.31s/it] 89%|████████▉ | 4036/4545 [5:13:49<2:15:30, 15.97s/it] 89%|████████▉ | 4037/4545 [5:13:53<1:44:42, 12.37s/it] 89%|████████▉ | 4038/4545 [5:13:56<1:21:21,  9.63s/it] 89%|████████▉ | 4039/4545 [5:14:00<1:06:47,  7.92s/it] 89%|████████▉ | 4040/4545 [5:14:04<56:32,  6.72s/it]                                                       {'loss': 0.3233, 'grad_norm': 25.747385025024414, 'learning_rate': 1.6048305499101194e-08, 'rewards/chosen': 1.7306640148162842, 'rewards/rejected': -1.6847655773162842, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.4164061546325684, 'logps/chosen': -231.10000610351562, 'logps/rejected': -114.42500305175781, 'logits/chosen': -7.15625, 'logits/rejected': -7.021874904632568, 'epoch': 2.67}
 89%|████████▉ | 4040/4545 [5:14:04<56:32,  6.72s/it] 89%|████████▉ | 4041/4545 [5:14:08<49:45,  5.92s/it] 89%|████████▉ | 4042/4545 [5:14:11<44:02,  5.25s/it] 89%|████████▉ | 4043/4545 [5:14:14<36:45,  4.39s/it] 89%|████████▉ | 4044/4545 [5:14:18<35:48,  4.29s/it] 89%|████████▉ | 4045/4545 [5:14:22<34:55,  4.19s/it] 89%|████████▉ | 4046/4545 [5:14:26<34:02,  4.09s/it] 89%|████████▉ | 4047/4545 [5:14:30<33:33,  4.04s/it] 89%|████████▉ | 4048/4545 [5:14:33<33:00,  3.98s/it] 89%|████████▉ | 4049/4545 [5:14:36<30:10,  3.65s/it] 89%|████████▉ | 4050/4545 [5:14:40<30:17,  3.67s/it]                                                     {'loss': 0.2701, 'grad_norm': 43.00161361694336, 'learning_rate': 1.5816843543283102e-08, 'rewards/chosen': 2.007617235183716, 'rewards/rejected': -1.402246117591858, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.4078125953674316, 'logps/chosen': -237.5500030517578, 'logps/rejected': -163.0, 'logits/chosen': -7.193749904632568, 'logits/rejected': -6.943749904632568, 'epoch': 2.67}
 89%|████████▉ | 4050/4545 [5:14:40<30:17,  3.67s/it] 89%|████████▉ | 4051/4545 [5:14:44<31:06,  3.78s/it] 89%|████████▉ | 4052/4545 [5:14:47<29:47,  3.62s/it] 89%|████████▉ | 4053/4545 [5:14:51<31:00,  3.78s/it] 89%|████████▉ | 4054/4545 [5:14:56<32:11,  3.93s/it] 89%|████████▉ | 4055/4545 [5:15:00<32:09,  3.94s/it] 89%|████████▉ | 4056/4545 [5:15:04<32:06,  3.94s/it] 89%|████████▉ | 4057/4545 [5:15:08<32:08,  3.95s/it] 89%|████████▉ | 4058/4545 [5:15:11<30:24,  3.75s/it] 89%|████████▉ | 4059/4545 [5:15:14<29:43,  3.67s/it] 89%|████████▉ | 4060/4545 [5:15:18<30:18,  3.75s/it]                                                     {'loss': 0.3321, 'grad_norm': 64.68738555908203, 'learning_rate': 1.558959101854105e-08, 'rewards/chosen': 3.0044922828674316, 'rewards/rejected': -1.5275390148162842, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.525781154632568, 'logps/chosen': -372.75, 'logps/rejected': -170.14999389648438, 'logits/chosen': -7.0, 'logits/rejected': -7.006249904632568, 'epoch': 2.68}
 89%|████████▉ | 4060/4545 [5:15:18<30:18,  3.75s/it] 89%|████████▉ | 4061/4545 [5:15:22<31:00,  3.84s/it] 89%|████████▉ | 4062/4545 [5:15:26<31:09,  3.87s/it] 89%|████████▉ | 4063/4545 [5:15:29<27:36,  3.44s/it] 89%|████████▉ | 4064/4545 [5:15:33<29:05,  3.63s/it] 89%|████████▉ | 4065/4545 [5:15:37<29:50,  3.73s/it] 89%|████████▉ | 4066/4545 [5:15:41<30:41,  3.85s/it] 89%|████████▉ | 4067/4545 [5:15:44<28:27,  3.57s/it] 90%|████████▉ | 4068/4545 [5:15:48<29:17,  3.68s/it] 90%|████████▉ | 4069/4545 [5:15:50<25:22,  3.20s/it] 90%|████████▉ | 4070/4545 [5:15:54<27:03,  3.42s/it]                                                     {'loss': 0.2522, 'grad_norm': 15.100937843322754, 'learning_rate': 1.5366572338524305e-08, 'rewards/chosen': 2.26806640625, 'rewards/rejected': -1.631250023841858, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 3.8984375, 'logps/chosen': -262.5, 'logps/rejected': -141.0, 'logits/chosen': -6.987500190734863, 'logits/rejected': -6.806250095367432, 'epoch': 2.69}
 90%|████████▉ | 4070/4545 [5:15:54<27:03,  3.42s/it] 90%|████████▉ | 4071/4545 [5:15:58<28:25,  3.60s/it] 90%|████████▉ | 4072/4545 [5:16:02<29:12,  3.70s/it] 90%|████████▉ | 4073/4545 [5:16:05<28:10,  3.58s/it] 90%|████████▉ | 4074/4545 [5:16:09<28:56,  3.69s/it] 90%|████████▉ | 4075/4545 [5:16:13<29:28,  3.76s/it] 90%|████████▉ | 4076/4545 [5:16:17<30:18,  3.88s/it] 90%|████████▉ | 4077/4545 [5:16:21<30:57,  3.97s/it] 90%|████████▉ | 4078/4545 [5:16:24<27:59,  3.60s/it] 90%|████████▉ | 4079/4545 [5:16:28<28:42,  3.70s/it] 90%|████████▉ | 4080/4545 [5:16:32<28:41,  3.70s/it]                                                     {'loss': 0.2738, 'grad_norm': 25.329683303833008, 'learning_rate': 1.51478114620419e-08, 'rewards/chosen': 3.407177686691284, 'rewards/rejected': -1.1682617664337158, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.584374904632568, 'logps/chosen': -391.3999938964844, 'logps/rejected': -180.0500030517578, 'logits/chosen': -6.768750190734863, 'logits/rejected': -6.696875095367432, 'epoch': 2.69}
 90%|████████▉ | 4080/4545 [5:16:32<28:41,  3.70s/it] 90%|████████▉ | 4081/4545 [5:16:36<29:42,  3.84s/it] 90%|████████▉ | 4082/4545 [5:16:40<29:43,  3.85s/it] 90%|████████▉ | 4083/4545 [5:16:44<30:23,  3.95s/it] 90%|████████▉ | 4084/4545 [5:16:47<27:50,  3.62s/it] 90%|████████▉ | 4085/4545 [5:16:51<28:30,  3.72s/it] 90%|████████▉ | 4086/4545 [5:16:54<28:26,  3.72s/it] 90%|████████▉ | 4087/4545 [5:16:58<28:53,  3.78s/it] 90%|████████▉ | 4088/4545 [5:17:02<29:09,  3.83s/it] 90%|████████▉ | 4089/4545 [5:17:06<29:21,  3.86s/it] 90%|████████▉ | 4090/4545 [5:17:10<28:45,  3.79s/it]                                                     {'loss': 0.3246, 'grad_norm': 32.700775146484375, 'learning_rate': 1.4933331890488704e-08, 'rewards/chosen': 3.0511717796325684, 'rewards/rejected': -0.9423828125, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.9945311546325684, 'logps/chosen': -356.45001220703125, 'logps/rejected': -185.6999969482422, 'logits/chosen': -7.015625, 'logits/rejected': -7.034375190734863, 'epoch': 2.7}
 90%|████████▉ | 4090/4545 [5:17:10<28:45,  3.79s/it] 90%|█████████ | 4091/4545 [5:17:14<29:02,  3.84s/it] 90%|█████████ | 4092/4545 [5:17:18<29:12,  3.87s/it] 90%|█████████ | 4093/4545 [5:17:22<29:20,  3.89s/it] 90%|█████████ | 4094/4545 [5:17:25<28:27,  3.79s/it] 90%|█████████ | 4095/4545 [5:17:29<28:46,  3.84s/it] 90%|█████████ | 4096/4545 [5:17:32<26:56,  3.60s/it] 90%|█████████ | 4097/4545 [5:17:36<27:38,  3.70s/it] 90%|█████████ | 4098/4545 [5:17:39<26:37,  3.57s/it] 90%|█████████ | 4099/4545 [5:17:43<27:19,  3.68s/it] 90%|█████████ | 4100/4545 [5:17:47<28:14,  3.81s/it]                                                     {'loss': 0.3763, 'grad_norm': 31.14531898498535, 'learning_rate': 1.4723156665320644e-08, 'rewards/chosen': 3.038012742996216, 'rewards/rejected': -1.087548851966858, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 4.11962890625, 'logps/chosen': -371.04998779296875, 'logps/rejected': -172.1999969482422, 'logits/chosen': -6.903124809265137, 'logits/rejected': -6.881249904632568, 'epoch': 2.71}
 90%|█████████ | 4100/4545 [5:17:48<28:14,  3.81s/it] 90%|█████████ | 4101/4545 [5:17:51<28:44,  3.88s/it] 90%|█████████ | 4102/4545 [5:17:55<28:52,  3.91s/it] 90%|█████████ | 4103/4545 [5:17:59<28:56,  3.93s/it] 90%|█████████ | 4104/4545 [5:18:03<28:55,  3.93s/it] 90%|█████████ | 4105/4545 [5:18:08<29:26,  4.02s/it] 90%|█████████ | 4106/4545 [5:18:12<29:57,  4.10s/it] 90%|█████████ | 4107/4545 [5:18:16<29:34,  4.05s/it] 90%|█████████ | 4108/4545 [5:18:20<29:37,  4.07s/it] 90%|█████████ | 4109/4545 [5:18:24<29:33,  4.07s/it] 90%|█████████ | 4110/4545 [5:18:28<29:14,  4.03s/it]                                                     {'loss': 0.2906, 'grad_norm': 25.37396240234375, 'learning_rate': 1.4517308365579442e-08, 'rewards/chosen': 2.432543992996216, 'rewards/rejected': -1.459375023841858, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.891406297683716, 'logps/chosen': -297.75, 'logps/rejected': -166.9499969482422, 'logits/chosen': -7.168749809265137, 'logits/rejected': -7.106249809265137, 'epoch': 2.71}
 90%|█████████ | 4110/4545 [5:18:28<29:14,  4.03s/it] 90%|█████████ | 4111/4545 [5:18:32<29:01,  4.01s/it] 90%|█████████ | 4112/4545 [5:18:36<28:33,  3.96s/it] 90%|█████████ | 4113/4545 [5:18:40<28:51,  4.01s/it] 91%|█████████ | 4114/4545 [5:18:44<28:06,  3.91s/it] 91%|█████████ | 4115/4545 [5:18:47<26:52,  3.75s/it] 91%|█████████ | 4116/4545 [5:18:50<26:02,  3.64s/it] 91%|█████████ | 4117/4545 [5:18:54<26:36,  3.73s/it] 91%|█████████ | 4118/4545 [5:18:58<26:57,  3.79s/it] 91%|█████████ | 4119/4545 [5:19:02<26:42,  3.76s/it] 91%|█████████ | 4120/4545 [5:19:06<27:00,  3.81s/it]                                                     {'loss': 0.2486, 'grad_norm': 14.16683292388916, 'learning_rate': 1.4315809105466942e-08, 'rewards/chosen': 1.838281273841858, 'rewards/rejected': -1.7783935070037842, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.617968797683716, 'logps/chosen': -211.10000610351562, 'logps/rejected': -121.2750015258789, 'logits/chosen': -7.209374904632568, 'logits/rejected': -6.915625095367432, 'epoch': 2.72}
 91%|█████████ | 4120/4545 [5:19:06<27:00,  3.81s/it] 91%|█████████ | 4121/4545 [5:19:36<1:22:45, 11.71s/it] 91%|█████████ | 4122/4545 [5:19:40<1:06:40,  9.46s/it] 91%|█████████ | 4123/4545 [5:19:44<53:43,  7.64s/it]   91%|█████████ | 4124/4545 [5:19:48<45:52,  6.54s/it] 91%|█████████ | 4125/4545 [5:19:51<39:44,  5.68s/it] 91%|█████████ | 4126/4545 [5:19:55<36:01,  5.16s/it] 91%|█████████ | 4127/4545 [5:19:59<32:50,  4.71s/it] 91%|█████████ | 4128/4545 [5:20:03<31:16,  4.50s/it] 91%|█████████ | 4129/4545 [5:20:07<30:01,  4.33s/it] 91%|█████████ | 4130/4545 [5:20:11<29:27,  4.26s/it]                                                     {'loss': 0.292, 'grad_norm': 44.40340042114258, 'learning_rate': 1.4118680531969333e-08, 'rewards/chosen': 1.932714819908142, 'rewards/rejected': -1.997656226158142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.9273438453674316, 'logps/chosen': -278.8500061035156, 'logps/rejected': -139.375, 'logits/chosen': -6.903124809265137, 'logits/rejected': -6.96875, 'epoch': 2.73}
 91%|█████████ | 4130/4545 [5:20:11<29:27,  4.26s/it] 91%|█████████ | 4131/4545 [5:20:15<29:22,  4.26s/it] 91%|█████████ | 4132/4545 [5:20:19<29:12,  4.24s/it] 91%|█████████ | 4133/4545 [5:20:23<28:55,  4.21s/it] 91%|█████████ | 4134/4545 [5:20:26<26:23,  3.85s/it] 91%|█████████ | 4135/4545 [5:20:30<26:16,  3.85s/it] 91%|█████████ | 4136/4545 [5:20:34<26:06,  3.83s/it] 91%|█████████ | 4137/4545 [5:20:37<23:12,  3.41s/it] 91%|█████████ | 4138/4545 [5:20:41<24:39,  3.64s/it] 91%|█████████ | 4139/4545 [5:20:45<25:18,  3.74s/it] 91%|█████████ | 4140/4545 [5:20:48<24:23,  3.61s/it]                                                     {'loss': 0.2432, 'grad_norm': 13.074249267578125, 'learning_rate': 1.3925943822531674e-08, 'rewards/chosen': 0.9823242425918579, 'rewards/rejected': -2.469531297683716, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 3.4507813453674316, 'logps/chosen': -138.60000610351562, 'logps/rejected': -96.82499694824219, 'logits/chosen': -7.278124809265137, 'logits/rejected': -6.940625190734863, 'epoch': 2.73}
 91%|█████████ | 4140/4545 [5:20:48<24:23,  3.61s/it] 91%|█████████ | 4141/4545 [5:20:51<23:28,  3.49s/it] 91%|█████████ | 4142/4545 [5:21:24<1:22:17, 12.25s/it] 91%|█████████ | 4143/4545 [5:22:05<2:21:04, 21.06s/it] 91%|█████████ | 4144/4545 [5:22:22<2:11:41, 19.71s/it] 91%|█████████ | 4145/4545 [5:22:39<2:05:49, 18.87s/it] 91%|█████████ | 4146/4545 [5:22:56<2:01:37, 18.29s/it] 91%|█████████ | 4147/4545 [5:23:12<1:56:38, 17.58s/it] 91%|█████████▏| 4148/4545 [5:23:29<1:55:44, 17.49s/it] 91%|█████████▏| 4149/4545 [5:23:45<1:52:25, 17.03s/it] 91%|█████████▏| 4150/4545 [5:24:02<1:52:27, 17.08s/it]                                                       {'loss': 0.2705, 'grad_norm': 14.601638793945312, 'learning_rate': 1.373761968278282e-08, 'rewards/chosen': 2.2669920921325684, 'rewards/rejected': -1.6653320789337158, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.934375047683716, 'logps/chosen': -287.95001220703125, 'logps/rejected': -127.1500015258789, 'logits/chosen': -6.918749809265137, 'logits/rejected': -6.878125190734863, 'epoch': 2.74}
 91%|█████████▏| 4150/4545 [5:24:03<1:52:27, 17.08s/it] 91%|█████████▏| 4151/4545 [5:24:19<1:52:22, 17.11s/it] 91%|█████████▏| 4152/4545 [5:24:32<1:42:45, 15.69s/it] 91%|█████████▏| 4153/4545 [5:24:36<1:19:25, 12.16s/it] 91%|█████████▏| 4154/4545 [5:24:39<1:02:40,  9.62s/it] 91%|█████████▏| 4155/4545 [5:24:42<48:01,  7.39s/it]   91%|█████████▏| 4156/4545 [5:24:46<41:12,  6.36s/it] 91%|█████████▏| 4157/4545 [5:24:49<36:24,  5.63s/it] 91%|█████████▏| 4158/4545 [5:24:53<33:02,  5.12s/it] 92%|█████████▏| 4159/4545 [5:24:57<29:21,  4.56s/it] 92%|█████████▏| 4160/4545 [5:25:01<28:05,  4.38s/it]                                                     {'loss': 0.2531, 'grad_norm': 16.86709213256836, 'learning_rate': 1.3553728344310958e-08, 'rewards/chosen': 2.438281297683716, 'rewards/rejected': -1.1818358898162842, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.6187500953674316, 'logps/chosen': -268.82501220703125, 'logps/rejected': -194.77499389648438, 'logits/chosen': -7.171875, 'logits/rejected': -6.871874809265137, 'epoch': 2.75}
 92%|█████████▏| 4160/4545 [5:25:01<28:05,  4.38s/it] 92%|█████████▏| 4161/4545 [5:25:04<25:40,  4.01s/it] 92%|█████████▏| 4162/4545 [5:25:06<23:04,  3.62s/it] 92%|█████████▏| 4163/4545 [5:25:10<23:44,  3.73s/it] 92%|█████████▏| 4164/4545 [5:25:14<24:00,  3.78s/it] 92%|█████████▏| 4165/4545 [5:25:18<24:14,  3.83s/it] 92%|█████████▏| 4166/4545 [5:25:22<24:22,  3.86s/it] 92%|█████████▏| 4167/4545 [5:25:26<23:29,  3.73s/it] 92%|█████████▏| 4168/4545 [5:25:30<23:49,  3.79s/it] 92%|█████████▏| 4169/4545 [5:25:33<23:20,  3.72s/it] 92%|█████████▏| 4170/4545 [5:25:37<23:34,  3.77s/it]                                                     {'loss': 0.3182, 'grad_norm': 22.016477584838867, 'learning_rate': 1.3374289562490212e-08, 'rewards/chosen': 1.997460961341858, 'rewards/rejected': -1.2980468273162842, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.29296875, 'logps/chosen': -247.0, 'logps/rejected': -170.14999389648438, 'logits/chosen': -7.096875190734863, 'logits/rejected': -6.909375190734863, 'epoch': 2.75}
 92%|█████████▏| 4170/4545 [5:25:37<23:34,  3.77s/it] 92%|█████████▏| 4171/4545 [5:25:41<23:24,  3.76s/it] 92%|█████████▏| 4172/4545 [5:25:45<23:52,  3.84s/it] 92%|█████████▏| 4173/4545 [5:25:47<21:25,  3.46s/it] 92%|█████████▏| 4174/4545 [5:25:51<22:16,  3.60s/it] 92%|█████████▏| 4175/4545 [5:25:54<21:21,  3.46s/it] 92%|█████████▏| 4176/4545 [5:25:58<22:09,  3.60s/it] 92%|█████████▏| 4177/4545 [5:26:01<21:13,  3.46s/it] 92%|█████████▏| 4178/4545 [5:26:05<21:45,  3.56s/it] 92%|█████████▏| 4179/4545 [5:26:08<19:51,  3.26s/it] 92%|█████████▏| 4180/4545 [5:26:11<19:58,  3.28s/it]                                                     {'loss': 0.3079, 'grad_norm': 24.952098846435547, 'learning_rate': 1.3199322614358294e-08, 'rewards/chosen': 2.3939452171325684, 'rewards/rejected': -1.5159180164337158, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.913281202316284, 'logps/chosen': -295.6000061035156, 'logps/rejected': -151.875, 'logits/chosen': -6.996874809265137, 'logits/rejected': -6.918749809265137, 'epoch': 2.76}
 92%|█████████▏| 4180/4545 [5:26:11<19:58,  3.28s/it] 92%|█████████▏| 4181/4545 [5:26:15<20:06,  3.31s/it] 92%|█████████▏| 4182/4545 [5:26:19<21:12,  3.51s/it] 92%|█████████▏| 4183/4545 [5:26:22<21:55,  3.63s/it] 92%|█████████▏| 4184/4545 [5:26:26<22:23,  3.72s/it] 92%|█████████▏| 4185/4545 [5:26:30<22:37,  3.77s/it] 92%|█████████▏| 4186/4545 [5:26:34<22:52,  3.82s/it] 92%|█████████▏| 4187/4545 [5:26:38<23:35,  3.95s/it] 92%|█████████▏| 4188/4545 [5:26:42<23:29,  3.95s/it] 92%|█████████▏| 4189/4545 [5:26:46<23:22,  3.94s/it] 92%|█████████▏| 4190/4545 [5:26:50<22:50,  3.86s/it]                                                     {'loss': 0.3761, 'grad_norm': 62.28941345214844, 'learning_rate': 1.3028846296545564e-08, 'rewards/chosen': 3.2054686546325684, 'rewards/rejected': -0.626953125, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.83203125, 'logps/chosen': -397.6000061035156, 'logps/rejected': -252.4499969482422, 'logits/chosen': -6.824999809265137, 'logits/rejected': -6.75, 'epoch': 2.77}
 92%|█████████▏| 4190/4545 [5:26:50<22:50,  3.86s/it] 92%|█████████▏| 4191/4545 [5:26:54<22:17,  3.78s/it] 92%|█████████▏| 4192/4545 [5:26:56<20:28,  3.48s/it] 92%|█████████▏| 4193/4545 [5:27:00<20:32,  3.50s/it] 92%|█████████▏| 4194/4545 [5:27:04<20:57,  3.58s/it] 92%|█████████▏| 4195/4545 [5:27:08<21:31,  3.69s/it] 92%|█████████▏| 4196/4545 [5:27:11<21:30,  3.70s/it] 92%|█████████▏| 4197/4545 [5:27:15<21:51,  3.77s/it] 92%|█████████▏| 4198/4545 [5:27:18<20:34,  3.56s/it] 92%|█████████▏| 4199/4545 [5:27:22<21:10,  3.67s/it] 92%|█████████▏| 4200/4545 [5:27:26<21:31,  3.74s/it]                                                     {'loss': 0.2611, 'grad_norm': 20.651548385620117, 'learning_rate': 1.2862878923255766e-08, 'rewards/chosen': 1.568017601966858, 'rewards/rejected': -2.0765624046325684, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.643749952316284, 'logps/chosen': -237.75, 'logps/rejected': -117.875, 'logits/chosen': -7.09375, 'logits/rejected': -7.012499809265137, 'epoch': 2.77}
 92%|█████████▏| 4200/4545 [5:27:26<21:31,  3.74s/it] 92%|█████████▏| 4201/4545 [5:27:30<21:40,  3.78s/it] 92%|█████████▏| 4202/4545 [5:27:34<22:09,  3.88s/it] 92%|█████████▏| 4203/4545 [5:27:38<22:12,  3.90s/it] 92%|█████████▏| 4204/4545 [5:27:42<21:48,  3.84s/it] 93%|█████████▎| 4205/4545 [5:27:46<21:55,  3.87s/it] 93%|█████████▎| 4206/4545 [5:27:50<21:58,  3.89s/it] 93%|█████████▎| 4207/4545 [5:27:54<21:48,  3.87s/it] 93%|█████████▎| 4208/4545 [5:27:57<21:54,  3.90s/it] 93%|█████████▎| 4209/4545 [5:28:01<21:54,  3.91s/it] 93%|█████████▎| 4210/4545 [5:28:05<21:33,  3.86s/it]                                                     {'loss': 0.3353, 'grad_norm': 62.31414794921875, 'learning_rate': 1.2701438324298467e-08, 'rewards/chosen': 3.4395508766174316, 'rewards/rejected': -0.5667968988418579, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 4.004687309265137, 'logps/chosen': -417.45001220703125, 'logps/rejected': -214.39999389648438, 'logits/chosen': -6.818749904632568, 'logits/rejected': -6.971875190734863, 'epoch': 2.78}
 93%|█████████▎| 4210/4545 [5:28:05<21:33,  3.86s/it] 93%|█████████▎| 4211/4545 [5:28:09<21:47,  3.91s/it] 93%|█████████▎| 4212/4545 [5:28:13<21:07,  3.81s/it] 93%|█████████▎| 4213/4545 [5:28:17<20:58,  3.79s/it] 93%|█████████▎| 4214/4545 [5:28:20<19:45,  3.58s/it] 93%|█████████▎| 4215/4545 [5:28:24<20:25,  3.72s/it] 93%|█████████▎| 4216/4545 [5:28:27<20:00,  3.65s/it] 93%|█████████▎| 4217/4545 [5:28:31<20:20,  3.72s/it] 93%|█████████▎| 4218/4545 [5:28:34<19:52,  3.65s/it] 93%|█████████▎| 4219/4545 [5:28:37<18:44,  3.45s/it] 93%|█████████▎| 4220/4545 [5:28:41<19:30,  3.60s/it]                                                     {'loss': 0.3034, 'grad_norm': 48.48722457885742, 'learning_rate': 1.2544541843173678e-08, 'rewards/chosen': 1.4425780773162842, 'rewards/rejected': -1.8572266101837158, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.299999952316284, 'logps/chosen': -179.5500030517578, 'logps/rejected': -114.30000305175781, 'logits/chosen': -7.209374904632568, 'logits/rejected': -6.884375095367432, 'epoch': 2.79}
 93%|█████████▎| 4220/4545 [5:28:42<19:30,  3.60s/it] 93%|█████████▎| 4221/4545 [5:28:45<20:10,  3.74s/it] 93%|█████████▎| 4222/4545 [5:28:50<20:45,  3.86s/it] 93%|█████████▎| 4223/4545 [5:28:54<20:51,  3.89s/it] 93%|█████████▎| 4224/4545 [5:28:57<20:51,  3.90s/it] 93%|█████████▎| 4225/4545 [5:29:01<20:50,  3.91s/it] 93%|█████████▎| 4226/4545 [5:29:05<20:50,  3.92s/it] 93%|█████████▎| 4227/4545 [5:29:09<20:25,  3.85s/it] 93%|█████████▎| 4228/4545 [5:29:13<20:31,  3.88s/it] 93%|█████████▎| 4229/4545 [5:29:17<20:31,  3.90s/it] 93%|█████████▎| 4230/4545 [5:29:20<19:40,  3.75s/it]                                                     {'loss': 0.2907, 'grad_norm': 46.834190368652344, 'learning_rate': 1.2392206335208627e-08, 'rewards/chosen': 1.689453125, 'rewards/rejected': -1.8371093273162842, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.5250000953674316, 'logps/chosen': -231.0500030517578, 'logps/rejected': -130.25, 'logits/chosen': -7.09375, 'logits/rejected': -6.815625190734863, 'epoch': 2.79}
 93%|█████████▎| 4230/4545 [5:29:21<19:40,  3.75s/it] 93%|█████████▎| 4231/4545 [5:29:24<19:59,  3.82s/it] 93%|█████████▎| 4232/4545 [5:29:28<20:18,  3.89s/it] 93%|█████████▎| 4233/4545 [5:29:32<20:16,  3.90s/it] 93%|█████████▎| 4234/4545 [5:29:37<20:40,  3.99s/it] 93%|█████████▎| 4235/4545 [5:29:41<20:47,  4.02s/it] 93%|█████████▎| 4236/4545 [5:29:45<20:36,  4.00s/it] 93%|█████████▎| 4237/4545 [5:29:48<19:44,  3.85s/it] 93%|█████████▎| 4238/4545 [5:29:52<19:59,  3.91s/it] 93%|█████████▎| 4239/4545 [5:29:55<18:17,  3.59s/it] 93%|█████████▎| 4240/4545 [5:29:59<19:12,  3.78s/it]                                                     {'loss': 0.3165, 'grad_norm': 47.279823303222656, 'learning_rate': 1.2244448165746961e-08, 'rewards/chosen': 2.0956053733825684, 'rewards/rejected': -1.4337646961212158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.5296874046325684, 'logps/chosen': -278.8500061035156, 'logps/rejected': -178.10000610351562, 'logits/chosen': -7.037499904632568, 'logits/rejected': -6.881249904632568, 'epoch': 2.8}
 93%|█████████▎| 4240/4545 [5:29:59<19:12,  3.78s/it] 93%|█████████▎| 4241/4545 [5:30:03<19:05,  3.77s/it] 93%|█████████▎| 4242/4545 [5:30:07<18:50,  3.73s/it] 93%|█████████▎| 4243/4545 [5:30:11<19:21,  3.85s/it] 93%|█████████▎| 4244/4545 [5:30:15<19:27,  3.88s/it] 93%|█████████▎| 4245/4545 [5:30:19<19:49,  3.96s/it] 93%|█████████▎| 4246/4545 [5:30:23<19:41,  3.95s/it] 93%|█████████▎| 4247/4545 [5:30:27<19:36,  3.95s/it] 93%|█████████▎| 4248/4545 [5:30:30<19:06,  3.86s/it] 93%|█████████▎| 4249/4545 [5:30:34<19:25,  3.94s/it] 94%|█████████▎| 4250/4545 [5:30:38<19:20,  3.94s/it]                                                     {'loss': 0.2349, 'grad_norm': 12.46621322631836, 'learning_rate': 1.210128320839068e-08, 'rewards/chosen': 4.370703220367432, 'rewards/rejected': -0.908618152141571, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 5.285937309265137, 'logps/chosen': -484.6000061035156, 'logps/rejected': -226.85000610351562, 'logits/chosen': -6.909375190734863, 'logits/rejected': -6.821875095367432, 'epoch': 2.81}
 94%|█████████▎| 4250/4545 [5:30:39<19:20,  3.94s/it] 94%|█████████▎| 4251/4545 [5:30:43<19:47,  4.04s/it] 94%|█████████▎| 4252/4545 [5:30:47<19:34,  4.01s/it] 94%|█████████▎| 4253/4545 [5:30:51<19:24,  3.99s/it] 94%|█████████▎| 4254/4545 [5:30:55<19:36,  4.04s/it] 94%|█████████▎| 4255/4545 [5:30:58<19:00,  3.93s/it] 94%|█████████▎| 4256/4545 [5:31:02<18:58,  3.94s/it] 94%|█████████▎| 4257/4545 [5:31:06<18:24,  3.83s/it] 94%|█████████▎| 4258/4545 [5:31:10<18:24,  3.85s/it] 94%|█████████▎| 4259/4545 [5:31:14<18:29,  3.88s/it] 94%|█████████▎| 4260/4545 [5:31:16<16:27,  3.47s/it]                                                     {'loss': 0.2775, 'grad_norm': 25.720550537109375, 'learning_rate': 1.196272684329479e-08, 'rewards/chosen': 2.3433594703674316, 'rewards/rejected': -1.236914038658142, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.585156202316284, 'logps/chosen': -291.67498779296875, 'logps/rejected': -172.6750030517578, 'logits/chosen': -7.056250095367432, 'logits/rejected': -6.903124809265137, 'epoch': 2.81}
 94%|█████████▎| 4260/4545 [5:31:16<16:27,  3.47s/it] 94%|█████████▍| 4261/4545 [5:31:21<17:36,  3.72s/it] 94%|█████████▍| 4262/4545 [5:31:24<17:51,  3.79s/it] 94%|█████████▍| 4263/4545 [5:31:28<17:21,  3.69s/it] 94%|█████████▍| 4264/4545 [5:31:32<17:38,  3.77s/it] 94%|█████████▍| 4265/4545 [5:31:35<16:51,  3.61s/it] 94%|█████████▍| 4266/4545 [5:31:39<17:42,  3.81s/it] 94%|█████████▍| 4267/4545 [5:31:43<17:59,  3.88s/it] 94%|█████████▍| 4268/4545 [5:31:47<18:00,  3.90s/it] 94%|█████████▍| 4269/4545 [5:31:51<17:43,  3.85s/it] 94%|█████████▍| 4270/4545 [5:31:55<18:12,  3.97s/it]                                                     {'loss': 0.3349, 'grad_norm': 35.81331253051758, 'learning_rate': 1.1828793955515074e-08, 'rewards/chosen': 2.7542967796325684, 'rewards/rejected': -0.6591796875, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 3.4164061546325684, 'logps/chosen': -324.20001220703125, 'logps/rejected': -202.77499389648438, 'logits/chosen': -6.940625190734863, 'logits/rejected': -6.78125, 'epoch': 2.82}
 94%|█████████▍| 4270/4545 [5:31:55<18:12,  3.97s/it] 94%|█████████▍| 4271/4545 [5:31:59<18:08,  3.97s/it] 94%|█████████▍| 4272/4545 [5:32:02<16:30,  3.63s/it] 94%|█████████▍| 4273/4545 [5:32:06<16:09,  3.56s/it] 94%|█████████▍| 4274/4545 [5:32:34<49:42, 11.01s/it] 94%|█████████▍| 4275/4545 [5:32:38<39:59,  8.89s/it] 94%|█████████▍| 4276/4545 [5:32:42<32:52,  7.33s/it] 94%|█████████▍| 4277/4545 [5:32:44<25:28,  5.70s/it] 94%|█████████▍| 4278/4545 [5:32:48<23:09,  5.20s/it] 94%|█████████▍| 4279/4545 [5:32:51<20:32,  4.63s/it] 94%|█████████▍| 4280/4545 [5:32:55<19:31,  4.42s/it]                                                     {'loss': 0.2198, 'grad_norm': 12.899775505065918, 'learning_rate': 1.1699498933408943e-08, 'rewards/chosen': 1.975000023841858, 'rewards/rejected': -1.673242211341858, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 3.6460938453674316, 'logps/chosen': -232.64999389648438, 'logps/rejected': -131.375, 'logits/chosen': -7.084374904632568, 'logits/rejected': -6.915625095367432, 'epoch': 2.83}
 94%|█████████▍| 4280/4545 [5:32:55<19:31,  4.42s/it] 94%|█████████▍| 4281/4545 [5:32:59<18:54,  4.30s/it] 94%|█████████▍| 4282/4545 [5:33:03<18:26,  4.21s/it] 94%|█████████▍| 4283/4545 [5:33:07<18:01,  4.13s/it] 94%|█████████▍| 4284/4545 [5:33:10<16:48,  3.86s/it] 94%|█████████▍| 4285/4545 [5:33:14<16:50,  3.89s/it] 94%|█████████▍| 4286/4545 [5:33:17<16:06,  3.73s/it] 94%|█████████▍| 4287/4545 [5:33:20<15:18,  3.56s/it] 94%|█████████▍| 4288/4545 [5:33:24<15:44,  3.67s/it] 94%|█████████▍| 4289/4545 [5:33:28<16:02,  3.76s/it] 94%|█████████▍| 4290/4545 [5:33:32<16:23,  3.86s/it]                                                     {'loss': 0.2758, 'grad_norm': 60.283966064453125, 'learning_rate': 1.1574855667089744e-08, 'rewards/chosen': 2.0526366233825684, 'rewards/rejected': -1.4451172351837158, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.495312452316284, 'logps/chosen': -267.95001220703125, 'logps/rejected': -138.375, 'logits/chosen': -7.112500190734863, 'logits/rejected': -7.096875190734863, 'epoch': 2.83}
 94%|█████████▍| 4290/4545 [5:33:33<16:23,  3.86s/it] 94%|█████████▍| 4291/4545 [5:33:36<16:28,  3.89s/it] 94%|█████████▍| 4292/4545 [5:33:40<15:39,  3.71s/it] 94%|█████████▍| 4293/4545 [5:33:44<15:56,  3.79s/it] 94%|█████████▍| 4294/4545 [5:33:47<15:31,  3.71s/it] 94%|█████████▍| 4295/4545 [5:33:51<15:44,  3.78s/it] 95%|█████████▍| 4296/4545 [5:33:54<14:14,  3.43s/it] 95%|█████████▍| 4297/4545 [5:33:58<14:59,  3.63s/it] 95%|█████████▍| 4298/4545 [5:34:02<15:18,  3.72s/it] 95%|█████████▍| 4299/4545 [5:34:06<15:16,  3.73s/it] 95%|█████████▍| 4300/4545 [5:34:10<15:47,  3.87s/it]                                                     {'loss': 0.2759, 'grad_norm': 38.24490737915039, 'learning_rate': 1.1454877546934497e-08, 'rewards/chosen': 1.2273437976837158, 'rewards/rejected': -1.81640625, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.043750047683716, 'logps/chosen': -206.6999969482422, 'logps/rejected': -130.5500030517578, 'logits/chosen': -7.040625095367432, 'logits/rejected': -6.971875190734863, 'epoch': 2.84}
 95%|█████████▍| 4300/4545 [5:34:10<15:47,  3.87s/it] 95%|█████████▍| 4301/4545 [5:34:14<15:52,  3.90s/it] 95%|█████████▍| 4302/4545 [5:34:18<15:51,  3.92s/it] 95%|█████████▍| 4303/4545 [5:34:22<15:49,  3.93s/it] 95%|█████████▍| 4304/4545 [5:34:26<15:53,  3.96s/it] 95%|█████████▍| 4305/4545 [5:34:30<15:45,  3.94s/it] 95%|█████████▍| 4306/4545 [5:34:34<15:42,  3.94s/it] 95%|█████████▍| 4307/4545 [5:34:37<15:37,  3.94s/it] 95%|█████████▍| 4308/4545 [5:34:40<13:38,  3.45s/it] 95%|█████████▍| 4309/4545 [5:34:44<14:17,  3.63s/it] 95%|█████████▍| 4310/4545 [5:34:47<13:54,  3.55s/it]                                                     {'loss': 0.2889, 'grad_norm': 27.755910873413086, 'learning_rate': 1.133957746214545e-08, 'rewards/chosen': 3.072021484375, 'rewards/rejected': -1.145117163658142, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.215624809265137, 'logps/chosen': -387.6499938964844, 'logps/rejected': -185.3000030517578, 'logits/chosen': -6.737500190734863, 'logits/rejected': -6.771874904632568, 'epoch': 2.84}
 95%|█████████▍| 4310/4545 [5:34:47<13:54,  3.55s/it] 95%|█████████▍| 4311/4545 [5:34:52<14:46,  3.79s/it] 95%|█████████▍| 4312/4545 [5:34:54<13:04,  3.37s/it] 95%|█████████▍| 4313/4545 [5:34:58<13:40,  3.54s/it] 95%|█████████▍| 4314/4545 [5:35:02<14:22,  3.73s/it] 95%|█████████▍| 4315/4545 [5:35:06<14:37,  3.81s/it] 95%|█████████▍| 4316/4545 [5:35:09<13:57,  3.66s/it] 95%|█████████▍| 4317/4545 [5:35:13<14:14,  3.75s/it] 95%|█████████▌| 4318/4545 [5:35:17<14:05,  3.73s/it] 95%|█████████▌| 4319/4545 [5:35:21<14:16,  3.79s/it] 95%|█████████▌| 4320/4545 [5:35:23<12:41,  3.38s/it]                                                     {'loss': 0.3733, 'grad_norm': 62.957481384277344, 'learning_rate': 1.1228967799365325e-08, 'rewards/chosen': 3.019238233566284, 'rewards/rejected': -0.3807617127895355, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 3.40234375, 'logps/chosen': -350.1000061035156, 'logps/rejected': -222.39999389648438, 'logits/chosen': -6.987500190734863, 'logits/rejected': -6.946875095367432, 'epoch': 2.85}
 95%|█████████▌| 4320/4545 [5:35:23<12:41,  3.38s/it] 95%|█████████▌| 4321/4545 [5:35:27<13:19,  3.57s/it] 95%|█████████▌| 4322/4545 [5:35:31<13:45,  3.70s/it] 95%|█████████▌| 4323/4545 [5:35:35<13:56,  3.77s/it] 95%|█████████▌| 4324/4545 [5:36:04<41:43, 11.33s/it] 95%|█████████▌| 4325/4545 [5:36:08<32:41,  8.92s/it] 95%|█████████▌| 4326/4545 [5:36:11<26:28,  7.25s/it] 95%|█████████▌| 4327/4545 [5:36:15<22:35,  6.22s/it] 95%|█████████▌| 4328/4545 [5:36:19<20:00,  5.53s/it] 95%|█████████▌| 4329/4545 [5:36:23<18:10,  5.05s/it] 95%|█████████▌| 4330/4545 [5:36:26<16:53,  4.71s/it]                                                     {'loss': 0.3344, 'grad_norm': 21.720962524414062, 'learning_rate': 1.1123060441346647e-08, 'rewards/chosen': 1.8865234851837158, 'rewards/rejected': -1.361328125, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.250781297683716, 'logps/chosen': -231.1999969482422, 'logps/rejected': -160.25, 'logits/chosen': -7.190625190734863, 'logits/rejected': -7.043749809265137, 'epoch': 2.86}
 95%|█████████▌| 4330/4545 [5:36:27<16:53,  4.71s/it] 95%|█████████▌| 4331/4545 [5:36:29<14:29,  4.06s/it] 95%|█████████▌| 4332/4545 [5:36:33<14:30,  4.09s/it] 95%|█████████▌| 4333/4545 [5:36:37<14:17,  4.05s/it] 95%|█████████▌| 4334/4545 [5:37:10<44:09, 12.56s/it] 95%|█████████▌| 4335/4545 [5:37:17<38:22, 10.96s/it] 95%|█████████▌| 4336/4545 [5:37:24<34:35,  9.93s/it] 95%|█████████▌| 4337/4545 [5:37:32<32:09,  9.28s/it] 95%|█████████▌| 4338/4545 [5:37:39<29:15,  8.48s/it] 95%|█████████▌| 4339/4545 [5:37:46<27:27,  8.00s/it] 95%|█████████▌| 4340/4545 [5:37:53<27:01,  7.91s/it]                                                     {'loss': 0.3774, 'grad_norm': 39.280513763427734, 'learning_rate': 1.1021866765675219e-08, 'rewards/chosen': 2.568554639816284, 'rewards/rejected': -1.3328125476837158, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 3.9000000953674316, 'logps/chosen': -320.875, 'logps/rejected': -188.64999389648438, 'logits/chosen': -7.131249904632568, 'logits/rejected': -6.856249809265137, 'epoch': 2.86}
 95%|█████████▌| 4340/4545 [5:37:53<27:01,  7.91s/it] 96%|█████████▌| 4341/4545 [5:38:01<26:28,  7.78s/it] 96%|█████████▌| 4342/4545 [5:38:08<26:11,  7.74s/it] 96%|█████████▌| 4343/4545 [5:38:15<25:21,  7.53s/it] 96%|█████████▌| 4344/4545 [5:38:23<25:18,  7.56s/it] 96%|█████████▌| 4345/4545 [5:38:31<25:05,  7.53s/it] 96%|█████████▌| 4346/4545 [5:38:38<25:02,  7.55s/it] 96%|█████████▌| 4347/4545 [5:38:46<25:05,  7.60s/it] 96%|█████████▌| 4348/4545 [5:38:53<24:56,  7.60s/it] 96%|█████████▌| 4349/4545 [5:39:01<24:49,  7.60s/it] 96%|█████████▌| 4350/4545 [5:39:09<24:46,  7.63s/it]                                                     {'loss': 0.2978, 'grad_norm': 37.01557540893555, 'learning_rate': 1.0925397643547785e-08, 'rewards/chosen': 2.6114258766174316, 'rewards/rejected': -1.3759765625, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.984375, 'logps/chosen': -323.1499938964844, 'logps/rejected': -168.60000610351562, 'logits/chosen': -6.993750095367432, 'logits/rejected': -6.912499904632568, 'epoch': 2.87}
 96%|█████████▌| 4350/4545 [5:39:09<24:46,  7.63s/it] 96%|█████████▌| 4351/4545 [5:39:16<24:16,  7.51s/it] 96%|█████████▌| 4352/4545 [5:39:23<23:23,  7.27s/it] 96%|█████████▌| 4353/4545 [5:39:30<23:42,  7.41s/it] 96%|█████████▌| 4354/4545 [5:39:38<24:05,  7.57s/it] 96%|█████████▌| 4355/4545 [5:39:44<22:32,  7.12s/it] 96%|█████████▌| 4356/4545 [5:39:51<21:57,  6.97s/it] 96%|█████████▌| 4357/4545 [5:39:58<22:01,  7.03s/it] 96%|█████████▌| 4358/4545 [5:40:05<21:42,  6.97s/it] 96%|█████████▌| 4359/4545 [5:40:12<21:50,  7.05s/it] 96%|█████████▌| 4360/4545 [5:40:20<22:18,  7.23s/it]                                                     {'loss': 0.2662, 'grad_norm': 18.562786102294922, 'learning_rate': 1.083366343860416e-08, 'rewards/chosen': 1.7292969226837158, 'rewards/rejected': -1.3019530773162842, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.0335936546325684, 'logps/chosen': -207.85000610351562, 'logps/rejected': -166.89999389648438, 'logits/chosen': -7.137499809265137, 'logits/rejected': -7.043749809265137, 'epoch': 2.88}
 96%|█████████▌| 4360/4545 [5:40:21<22:18,  7.23s/it] 96%|█████████▌| 4361/4545 [5:40:28<22:43,  7.41s/it] 96%|█████████▌| 4362/4545 [5:40:35<22:45,  7.46s/it] 96%|█████████▌| 4363/4545 [5:40:42<21:36,  7.12s/it] 96%|█████████▌| 4364/4545 [5:40:49<21:42,  7.20s/it] 96%|█████████▌| 4365/4545 [5:40:57<22:00,  7.34s/it] 96%|█████████▌| 4366/4545 [5:41:04<21:58,  7.37s/it] 96%|█████████▌| 4367/4545 [5:41:12<22:11,  7.48s/it] 96%|█████████▌| 4368/4545 [5:41:20<22:14,  7.54s/it] 96%|█████████▌| 4369/4545 [5:41:26<21:22,  7.29s/it] 96%|█████████▌| 4370/4545 [5:41:34<21:34,  7.40s/it]                                                     {'loss': 0.3103, 'grad_norm': 62.583431243896484, 'learning_rate': 1.0746674005813887e-08, 'rewards/chosen': 2.3890624046325684, 'rewards/rejected': -1.232666015625, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.620312452316284, 'logps/chosen': -280.54998779296875, 'logps/rejected': -148.39999389648438, 'logits/chosen': -7.037499904632568, 'logits/rejected': -6.918749809265137, 'epoch': 2.88}
 96%|█████████▌| 4370/4545 [5:41:34<21:34,  7.40s/it] 96%|█████████▌| 4371/4545 [5:41:42<21:38,  7.46s/it] 96%|█████████▌| 4372/4545 [5:41:49<21:27,  7.44s/it] 96%|█████████▌| 4373/4545 [5:41:57<21:40,  7.56s/it] 96%|█████████▌| 4374/4545 [5:42:04<21:31,  7.55s/it] 96%|█████████▋| 4375/4545 [5:42:12<21:28,  7.58s/it] 96%|█████████▋| 4376/4545 [5:42:19<21:05,  7.49s/it] 96%|█████████▋| 4377/4545 [5:42:27<21:10,  7.56s/it] 96%|█████████▋| 4378/4545 [5:42:35<21:05,  7.58s/it] 96%|█████████▋| 4379/4545 [5:42:42<21:04,  7.62s/it] 96%|█████████▋| 4380/4545 [5:42:49<19:53,  7.23s/it]                                                     {'loss': 0.3122, 'grad_norm': 35.52700424194336, 'learning_rate': 1.0664438690417481e-08, 'rewards/chosen': 2.576977491378784, 'rewards/rejected': -0.997021496295929, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.57421875, 'logps/chosen': -312.1499938964844, 'logps/rejected': -188.22500610351562, 'logits/chosen': -6.996874809265137, 'logits/rejected': -7.053124904632568, 'epoch': 2.89}
 96%|█████████▋| 4380/4545 [5:42:49<19:53,  7.23s/it] 96%|█████████▋| 4381/4545 [5:42:56<19:54,  7.28s/it] 96%|█████████▋| 4382/4545 [5:43:04<20:05,  7.40s/it] 96%|█████████▋| 4383/4545 [5:43:11<20:07,  7.46s/it] 96%|█████████▋| 4384/4545 [5:43:19<20:25,  7.61s/it] 96%|█████████▋| 4385/4545 [5:43:27<20:18,  7.61s/it] 97%|█████████▋| 4386/4545 [5:43:35<20:18,  7.66s/it] 97%|█████████▋| 4387/4545 [5:43:42<20:07,  7.64s/it] 97%|█████████▋| 4388/4545 [5:43:50<19:46,  7.56s/it] 97%|█████████▋| 4389/4545 [5:43:57<19:17,  7.42s/it] 97%|█████████▋| 4390/4545 [5:44:04<19:15,  7.46s/it]                                                     {'loss': 0.3048, 'grad_norm': 41.74454116821289, 'learning_rate': 1.0586966326922517e-08, 'rewards/chosen': 3.451367139816284, 'rewards/rejected': -0.9627441167831421, 'rewards/accuracies': 0.875, 'rewards/margins': 4.418749809265137, 'logps/chosen': -399.1499938964844, 'logps/rejected': -181.0500030517578, 'logits/chosen': -6.918749809265137, 'logits/rejected': -6.696875095367432, 'epoch': 2.9}
 97%|█████████▋| 4390/4545 [5:44:04<19:15,  7.46s/it] 97%|█████████▋| 4391/4545 [5:44:11<18:30,  7.21s/it] 97%|█████████▋| 4392/4545 [5:44:18<18:27,  7.24s/it] 97%|█████████▋| 4393/4545 [5:44:48<35:21, 13.96s/it] 97%|█████████▋| 4394/4545 [5:44:52<27:34, 10.96s/it] 97%|█████████▋| 4395/4545 [5:44:55<21:24,  8.56s/it] 97%|█████████▋| 4396/4545 [5:44:59<18:03,  7.27s/it] 97%|█████████▋| 4397/4545 [5:45:03<15:28,  6.27s/it] 97%|█████████▋| 4398/4545 [5:45:06<13:16,  5.42s/it] 97%|█████████▋| 4399/4545 [5:45:10<12:04,  4.96s/it] 97%|█████████▋| 4400/4545 [5:45:14<11:10,  4.63s/it]                                                     {'loss': 0.2627, 'grad_norm': 54.06488037109375, 'learning_rate': 1.051426523815451e-08, 'rewards/chosen': 1.7380859851837158, 'rewards/rejected': -1.763671875, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.50390625, 'logps/chosen': -233.39999389648438, 'logps/rejected': -133.8249969482422, 'logits/chosen': -7.037499904632568, 'logits/rejected': -6.828125, 'epoch': 2.9}
 97%|█████████▋| 4400/4545 [5:45:14<11:10,  4.63s/it] 97%|█████████▋| 4401/4545 [5:45:18<10:32,  4.39s/it] 97%|█████████▋| 4402/4545 [5:45:22<10:12,  4.29s/it] 97%|█████████▋| 4403/4545 [5:45:26<10:03,  4.25s/it] 97%|█████████▋| 4404/4545 [5:45:29<08:57,  3.81s/it] 97%|█████████▋| 4405/4545 [5:45:33<08:55,  3.83s/it] 97%|█████████▋| 4406/4545 [5:45:37<08:55,  3.86s/it] 97%|█████████▋| 4407/4545 [5:45:41<08:51,  3.85s/it] 97%|█████████▋| 4408/4545 [5:45:45<08:51,  3.88s/it] 97%|█████████▋| 4409/4545 [5:45:48<08:50,  3.90s/it] 97%|█████████▋| 4410/4545 [5:45:53<09:01,  4.01s/it]                                                     {'loss': 0.2674, 'grad_norm': 25.82775115966797, 'learning_rate': 1.04463432343628e-08, 'rewards/chosen': 2.2230467796325684, 'rewards/rejected': -1.544213891029358, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.7718749046325684, 'logps/chosen': -300.75, 'logps/rejected': -147.35000610351562, 'logits/chosen': -6.953125, 'logits/rejected': -7.03125, 'epoch': 2.91}
 97%|█████████▋| 4410/4545 [5:45:53<09:01,  4.01s/it] 97%|█████████▋| 4411/4545 [5:45:56<08:38,  3.87s/it] 97%|█████████▋| 4412/4545 [5:45:59<07:52,  3.55s/it] 97%|█████████▋| 4413/4545 [5:46:02<07:28,  3.40s/it] 97%|█████████▋| 4414/4545 [5:46:06<07:45,  3.56s/it] 97%|█████████▋| 4415/4545 [5:46:10<07:58,  3.68s/it] 97%|█████████▋| 4416/4545 [5:46:39<23:56, 11.14s/it] 97%|█████████▋| 4417/4545 [5:46:42<18:59,  8.90s/it] 97%|█████████▋| 4418/4545 [5:46:46<15:41,  7.41s/it] 97%|█████████▋| 4419/4545 [5:46:50<13:24,  6.39s/it] 97%|█████████▋| 4420/4545 [5:46:54<11:46,  5.65s/it]                                                     {'loss': 0.2294, 'grad_norm': 25.259645462036133, 'learning_rate': 1.0383207612381542e-08, 'rewards/chosen': 2.2713866233825684, 'rewards/rejected': -1.6837890148162842, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.9515624046325684, 'logps/chosen': -279.1000061035156, 'logps/rejected': -124.9000015258789, 'logits/chosen': -6.965624809265137, 'logits/rejected': -6.921875, 'epoch': 2.92}
 97%|█████████▋| 4420/4545 [5:46:54<11:46,  5.65s/it] 97%|█████████▋| 4421/4545 [5:46:58<10:48,  5.23s/it] 97%|█████████▋| 4422/4545 [5:47:02<09:55,  4.84s/it] 97%|█████████▋| 4423/4545 [5:47:35<26:39, 13.11s/it] 97%|█████████▋| 4424/4545 [5:47:42<23:08, 11.47s/it] 97%|█████████▋| 4425/4545 [5:47:50<20:37, 10.32s/it] 97%|█████████▋| 4426/4545 [5:47:57<18:48,  9.49s/it] 97%|█████████▋| 4427/4545 [5:48:05<17:28,  8.88s/it] 97%|█████████▋| 4428/4545 [5:48:11<15:53,  8.15s/it] 97%|█████████▋| 4429/4545 [5:48:19<15:36,  8.07s/it] 97%|█████████▋| 4430/4545 [5:48:27<15:05,  7.88s/it]                                                     {'loss': 0.3518, 'grad_norm': 34.3894157409668, 'learning_rate': 1.0324865154845744e-08, 'rewards/chosen': 3.005078077316284, 'rewards/rejected': -0.8421875238418579, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.846874952316284, 'logps/chosen': -372.45001220703125, 'logps/rejected': -222.10000610351562, 'logits/chosen': -6.953125, 'logits/rejected': -7.159375190734863, 'epoch': 2.92}
 97%|█████████▋| 4430/4545 [5:48:27<15:05,  7.88s/it] 97%|█████████▋| 4431/4545 [5:48:35<15:04,  7.93s/it] 98%|█████████▊| 4432/4545 [5:48:42<14:41,  7.80s/it] 98%|█████████▊| 4433/4545 [5:48:50<14:29,  7.77s/it] 98%|█████████▊| 4434/4545 [5:48:58<14:16,  7.72s/it] 98%|█████████▊| 4435/4545 [5:49:05<14:06,  7.70s/it] 98%|█████████▊| 4436/4545 [5:49:13<13:57,  7.68s/it] 98%|█████████▊| 4437/4545 [5:49:21<13:53,  7.71s/it] 98%|█████████▊| 4438/4545 [5:49:28<13:48,  7.75s/it] 98%|█████████▊| 4439/4545 [5:49:36<13:37,  7.71s/it] 98%|█████████▊| 4440/4545 [5:49:44<13:37,  7.78s/it]                                                     {'loss': 0.2644, 'grad_norm': 24.929500579833984, 'learning_rate': 1.0271322129462656e-08, 'rewards/chosen': 3.6587891578674316, 'rewards/rejected': -0.46995848417282104, 'rewards/accuracies': 0.875, 'rewards/margins': 4.131249904632568, 'logps/chosen': -411.95001220703125, 'logps/rejected': -272.6499938964844, 'logits/chosen': -6.790625095367432, 'logits/rejected': -6.915625095367432, 'epoch': 2.93}
 98%|█████████▊| 4440/4545 [5:49:44<13:37,  7.78s/it] 98%|█████████▊| 4441/4545 [5:49:52<13:22,  7.71s/it] 98%|█████████▊| 4442/4545 [5:49:59<13:09,  7.66s/it] 98%|█████████▊| 4443/4545 [5:50:06<12:46,  7.52s/it] 98%|█████████▊| 4444/4545 [5:50:14<12:51,  7.64s/it] 98%|█████████▊| 4445/4545 [5:50:22<12:41,  7.62s/it] 98%|█████████▊| 4446/4545 [5:51:05<30:10, 18.28s/it] 98%|█████████▊| 4447/4545 [5:51:21<28:33, 17.48s/it] 98%|█████████▊| 4448/4545 [5:51:37<27:54, 17.27s/it] 98%|█████████▊| 4449/4545 [5:51:54<27:08, 16.96s/it] 98%|█████████▊| 4450/4545 [5:52:10<26:48, 16.93s/it]                                                     {'loss': 0.3942, 'grad_norm': 41.5377197265625, 'learning_rate': 1.0222584288338424e-08, 'rewards/chosen': 1.653222680091858, 'rewards/rejected': -1.509558081626892, 'rewards/accuracies': 0.8125, 'rewards/margins': 3.16015625, 'logps/chosen': -229.4499969482422, 'logps/rejected': -129.1750030517578, 'logits/chosen': -7.196875095367432, 'logits/rejected': -7.084374904632568, 'epoch': 2.94}
 98%|█████████▊| 4450/4545 [5:52:11<26:48, 16.93s/it] 98%|█████████▊| 4451/4545 [5:52:28<26:54, 17.17s/it] 98%|█████████▊| 4452/4545 [5:52:44<26:12, 16.91s/it] 98%|█████████▊| 4453/4545 [5:53:01<25:55, 16.90s/it] 98%|█████████▊| 4454/4545 [5:53:18<25:36, 16.88s/it] 98%|█████████▊| 4455/4545 [5:53:35<25:23, 16.93s/it] 98%|█████████▊| 4456/4545 [5:53:53<25:15, 17.02s/it] 98%|█████████▊| 4457/4545 [5:54:09<24:45, 16.89s/it] 98%|█████████▊| 4458/4545 [5:54:26<24:40, 17.02s/it] 98%|█████████▊| 4459/4545 [5:54:43<24:23, 17.02s/it] 98%|█████████▊| 4460/4545 [5:54:48<18:44, 13.22s/it]                                                     {'loss': 0.2974, 'grad_norm': 40.18806076049805, 'learning_rate': 1.0178656867360132e-08, 'rewards/chosen': 2.856640577316284, 'rewards/rejected': -0.8096679449081421, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.663281202316284, 'logps/chosen': -341.1000061035156, 'logps/rejected': -211.0749969482422, 'logits/chosen': -7.162499904632568, 'logits/rejected': -6.862500190734863, 'epoch': 2.94}
 98%|█████████▊| 4460/4545 [5:54:48<18:44, 13.22s/it] 98%|█████████▊| 4461/4545 [5:54:52<14:39, 10.46s/it] 98%|█████████▊| 4462/4545 [5:54:56<11:46,  8.51s/it] 98%|█████████▊| 4463/4545 [5:55:00<09:52,  7.22s/it] 98%|█████████▊| 4464/4545 [5:55:03<08:11,  6.06s/it] 98%|█████████▊| 4465/4545 [5:55:07<07:04,  5.30s/it] 98%|█████████▊| 4466/4545 [5:55:11<06:23,  4.85s/it] 98%|█████████▊| 4467/4545 [5:55:14<05:49,  4.49s/it] 98%|█████████▊| 4468/4545 [5:55:18<05:36,  4.37s/it] 98%|█████████▊| 4469/4545 [5:55:22<05:22,  4.24s/it] 98%|█████████▊| 4470/4545 [5:55:26<05:11,  4.15s/it]                                                     {'loss': 0.2406, 'grad_norm': 22.565038681030273, 'learning_rate': 1.0139544585633334e-08, 'rewards/chosen': 2.72607421875, 'rewards/rejected': -2.0384764671325684, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 4.756249904632568, 'logps/chosen': -343.79998779296875, 'logps/rejected': -173.0749969482422, 'logits/chosen': -7.012499809265137, 'logits/rejected': -6.971875190734863, 'epoch': 2.95}
 98%|█████████▊| 4470/4545 [5:55:26<05:11,  4.15s/it] 98%|█████████▊| 4471/4545 [5:55:30<05:03,  4.10s/it] 98%|█████████▊| 4472/4545 [5:55:34<04:55,  4.05s/it] 98%|█████████▊| 4473/4545 [5:55:37<04:32,  3.79s/it] 98%|█████████▊| 4474/4545 [5:55:41<04:32,  3.83s/it] 98%|█████████▊| 4475/4545 [5:55:45<04:30,  3.87s/it] 98%|█████████▊| 4476/4545 [5:55:48<04:05,  3.55s/it] 99%|█████████▊| 4477/4545 [5:55:51<03:48,  3.36s/it] 99%|█████████▊| 4478/4545 [5:55:55<03:56,  3.52s/it] 99%|█████████▊| 4479/4545 [5:55:59<04:03,  3.69s/it] 99%|█████████▊| 4480/4545 [5:56:02<03:50,  3.55s/it]                                                     {'loss': 0.3303, 'grad_norm': 20.571243286132812, 'learning_rate': 1.0105251644975057e-08, 'rewards/chosen': 2.3245606422424316, 'rewards/rejected': -1.0869140625, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.4156250953674316, 'logps/chosen': -274.20001220703125, 'logps/rejected': -199.1999969482422, 'logits/chosen': -6.859375, 'logits/rejected': -6.721875190734863, 'epoch': 2.96}
 99%|█████████▊| 4480/4545 [5:56:03<03:50,  3.55s/it] 99%|█████████▊| 4481/4545 [5:56:06<03:56,  3.70s/it] 99%|█████████▊| 4482/4545 [5:56:10<03:57,  3.77s/it] 99%|█████████▊| 4483/4545 [5:56:14<03:56,  3.82s/it] 99%|█████████▊| 4484/4545 [5:56:18<03:55,  3.86s/it] 99%|█████████▊| 4485/4545 [5:56:22<03:53,  3.89s/it] 99%|█████████▊| 4486/4545 [5:56:26<03:52,  3.95s/it] 99%|█████████▊| 4487/4545 [5:56:29<03:37,  3.76s/it] 99%|█████████▊| 4488/4545 [5:56:34<03:42,  3.90s/it] 99%|█████████▉| 4489/4545 [5:56:37<03:29,  3.74s/it] 99%|█████████▉| 4490/4545 [5:56:41<03:32,  3.86s/it]                                                     {'loss': 0.327, 'grad_norm': 41.137046813964844, 'learning_rate': 1.0075781729462413e-08, 'rewards/chosen': 2.494824171066284, 'rewards/rejected': -1.554785132408142, 'rewards/accuracies': 0.875, 'rewards/margins': 4.048437595367432, 'logps/chosen': -322.79998779296875, 'logps/rejected': -166.125, 'logits/chosen': -6.984375, 'logits/rejected': -6.671875, 'epoch': 2.96}
 99%|█████████▉| 4490/4545 [5:56:41<03:32,  3.86s/it] 99%|█████████▉| 4491/4545 [5:56:45<03:29,  3.88s/it] 99%|█████████▉| 4492/4545 [5:56:48<03:08,  3.56s/it] 99%|█████████▉| 4493/4545 [5:56:52<03:07,  3.61s/it] 99%|█████████▉| 4494/4545 [5:56:54<02:52,  3.38s/it] 99%|█████████▉| 4495/4545 [5:56:58<02:57,  3.55s/it] 99%|█████████▉| 4496/4545 [5:57:02<02:57,  3.62s/it] 99%|█████████▉| 4497/4545 [5:57:06<02:58,  3.72s/it] 99%|█████████▉| 4498/4545 [5:57:10<02:59,  3.81s/it] 99%|█████████▉| 4499/4545 [5:57:14<02:57,  3.85s/it] 99%|█████████▉| 4500/4545 [5:57:17<02:45,  3.67s/it]                                                     {'loss': 0.3191, 'grad_norm': 42.52345657348633, 'learning_rate': 1.0051138005036843e-08, 'rewards/chosen': 2.62109375, 'rewards/rejected': -1.488867163658142, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.119531154632568, 'logps/chosen': -344.29998779296875, 'logps/rejected': -144.75, 'logits/chosen': -6.865624904632568, 'logits/rejected': -6.974999904632568, 'epoch': 2.97}
 99%|█████████▉| 4500/4545 [5:57:18<02:45,  3.67s/it] 99%|█████████▉| 4501/4545 [5:57:21<02:34,  3.52s/it] 99%|█████████▉| 4502/4545 [5:57:24<02:25,  3.38s/it] 99%|█████████▉| 4503/4545 [5:57:27<02:18,  3.30s/it] 99%|█████████▉| 4504/4545 [5:57:30<02:21,  3.44s/it] 99%|█████████▉| 4505/4545 [5:57:34<02:23,  3.59s/it] 99%|█████████▉| 4506/4545 [5:57:37<02:11,  3.38s/it] 99%|█████████▉| 4507/4545 [5:57:41<02:14,  3.53s/it] 99%|█████████▉| 4508/4545 [5:57:45<02:15,  3.66s/it] 99%|█████████▉| 4509/4545 [5:57:49<02:15,  3.78s/it] 99%|█████████▉| 4510/4545 [5:57:53<02:15,  3.86s/it]                                                     {'loss': 0.2695, 'grad_norm': 33.40140151977539, 'learning_rate': 1.0031323119163944e-08, 'rewards/chosen': 2.4627928733825684, 'rewards/rejected': -1.360937476158142, 'rewards/accuracies': 0.875, 'rewards/margins': 3.8218750953674316, 'logps/chosen': -302.70001220703125, 'logps/rejected': -150.14999389648438, 'logits/chosen': -6.993750095367432, 'logits/rejected': -6.962500095367432, 'epoch': 2.98}
 99%|█████████▉| 4510/4545 [5:57:53<02:15,  3.86s/it] 99%|█████████▉| 4511/4545 [5:57:58<02:15,  4.00s/it] 99%|█████████▉| 4512/4545 [5:58:02<02:11,  3.98s/it] 99%|█████████▉| 4513/4545 [5:58:05<02:07,  3.98s/it] 99%|█████████▉| 4514/4545 [5:58:09<01:58,  3.82s/it] 99%|█████████▉| 4515/4545 [5:58:39<05:53, 11.79s/it] 99%|█████████▉| 4516/4545 [5:58:43<04:34,  9.46s/it] 99%|█████████▉| 4517/4545 [5:59:12<07:06, 15.22s/it] 99%|█████████▉| 4518/4545 [5:59:15<05:13, 11.63s/it] 99%|█████████▉| 4519/4545 [5:59:19<04:02,  9.32s/it] 99%|█████████▉| 4520/4545 [5:59:22<03:06,  7.45s/it]                                                     {'loss': 0.3147, 'grad_norm': 89.24252319335938, 'learning_rate': 1.001633920054912e-08, 'rewards/chosen': 1.7839844226837158, 'rewards/rejected': -1.1492187976837158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.93359375, 'logps/chosen': -248.6999969482422, 'logps/rejected': -179.52499389648438, 'logits/chosen': -7.143750190734863, 'logits/rejected': -7.012499809265137, 'epoch': 2.98}
 99%|█████████▉| 4520/4545 [5:59:22<03:06,  7.45s/it] 99%|█████████▉| 4521/4545 [5:59:25<02:27,  6.13s/it] 99%|█████████▉| 4522/4545 [5:59:29<02:06,  5.51s/it]100%|█████████▉| 4523/4545 [5:59:33<01:46,  4.84s/it]100%|█████████▉| 4524/4545 [5:59:37<01:38,  4.67s/it]100%|█████████▉| 4525/4545 [5:59:41<01:29,  4.45s/it]100%|█████████▉| 4526/4545 [5:59:45<01:21,  4.30s/it]100%|█████████▉| 4527/4545 [5:59:49<01:15,  4.17s/it]100%|█████████▉| 4528/4545 [5:59:53<01:10,  4.17s/it]100%|█████████▉| 4529/4545 [5:59:57<01:05,  4.10s/it]100%|█████████▉| 4530/4545 [6:00:01<01:00,  4.05s/it]                                                     {'loss': 0.3117, 'grad_norm': 45.89542770385742, 'learning_rate': 1.0006187858908838e-08, 'rewards/chosen': 2.5966796875, 'rewards/rejected': -1.3118164539337158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.910937547683716, 'logps/chosen': -325.8500061035156, 'logps/rejected': -161.3000030517578, 'logits/chosen': -7.118750095367432, 'logits/rejected': -6.831250190734863, 'epoch': 2.99}
100%|█████████▉| 4530/4545 [6:00:01<01:00,  4.05s/it]100%|█████████▉| 4531/4545 [6:00:05<00:56,  4.03s/it]100%|█████████▉| 4532/4545 [6:00:09<00:52,  4.04s/it]100%|█████████▉| 4533/4545 [6:00:13<00:48,  4.01s/it]100%|█████████▉| 4534/4545 [6:00:17<00:44,  4.00s/it]100%|█████████▉| 4535/4545 [6:00:21<00:39,  3.98s/it]100%|█████████▉| 4536/4545 [6:00:25<00:36,  4.05s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:42,  1.35it/s][A
  5%|▌         | 3/60 [00:03<01:01,  1.09s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:08<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.54s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:12<01:22,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.64s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.53s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.39s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.09s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.26s/it][A
 43%|████▎     | 26/60 [01:00<05:11,  9.15s/it][A
 45%|████▌     | 27/60 [01:01<03:39,  6.64s/it][A
 47%|████▋     | 28/60 [01:02<02:37,  4.93s/it][A
 48%|████▊     | 29/60 [01:03<01:58,  3.81s/it][A
 50%|█████     | 30/60 [01:05<01:34,  3.16s/it][A
 52%|█████▏    | 31/60 [01:07<01:17,  2.68s/it][A
 53%|█████▎    | 32/60 [01:08<01:04,  2.31s/it][A
 55%|█████▌    | 33/60 [01:09<00:54,  2.02s/it][A
 57%|█████▋    | 34/60 [01:10<00:43,  1.66s/it][A
 58%|█████▊    | 35/60 [01:12<00:39,  1.59s/it][A
 60%|██████    | 36/60 [01:13<00:37,  1.54s/it][A
 62%|██████▏   | 37/60 [01:14<00:28,  1.26s/it][A
 63%|██████▎   | 38/60 [01:15<00:29,  1.35s/it][A
 65%|██████▌   | 39/60 [01:16<00:27,  1.29s/it][A
 67%|██████▋   | 40/60 [01:17<00:22,  1.14s/it][A
 68%|██████▊   | 41/60 [01:19<00:23,  1.24s/it][A
 70%|███████   | 42/60 [01:20<00:24,  1.33s/it][A
 72%|███████▏  | 43/60 [01:21<00:20,  1.23s/it][A
 73%|███████▎  | 44/60 [01:22<00:20,  1.30s/it][A
 75%|███████▌  | 45/60 [01:23<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [01:25<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:27<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:27<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:29<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:31<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:32<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:33<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:35<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:36<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:37<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:38<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:40<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:41<00:02,  1.41s/it][A
 98%|█████████▊| 59/60 [01:43<00:01,  1.46s/it][A
100%|██████████| 60/60 [01:45<00:00,  1.51s/it][A                                                     
                                               [A{'eval_loss': 0.40348339080810547, 'eval_runtime': 106.9221, 'eval_samples_per_second': 8.913, 'eval_steps_per_second': 0.561, 'eval_rewards/chosen': 2.6498494148254395, 'eval_rewards/rejected': -0.4430989623069763, 'eval_rewards/accuracies': 0.8074073791503906, 'eval_rewards/margins': 3.0935425758361816, 'eval_logps/chosen': -364.5249938964844, 'eval_logps/rejected': -154.22708129882812, 'eval_logits/chosen': -6.747656345367432, 'eval_logits/rejected': -7.342708110809326, 'epoch': 2.99}
100%|█████████▉| 4536/4545 [6:02:12<00:36,  4.05s/it]
100%|██████████| 60/60 [01:45<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 4537/4545 [6:02:28<05:18, 39.84s/it]100%|█████████▉| 4538/4545 [6:02:32<03:23, 29.14s/it]100%|█████████▉| 4539/4545 [6:02:36<02:09, 21.58s/it]100%|█████████▉| 4540/4545 [6:02:41<01:21, 16.38s/it]                                                     {'loss': 0.3192, 'grad_norm': 40.201202392578125, 'learning_rate': 1.000087018479775e-08, 'rewards/chosen': 1.6376953125, 'rewards/rejected': -1.4486602544784546, 'rewards/accuracies': 0.875, 'rewards/margins': 3.0859375, 'logps/chosen': -227.1999969482422, 'logps/rejected': -153.8000030517578, 'logits/chosen': -7.074999809265137, 'logits/rejected': -6.921875, 'epoch': 3.0}
100%|█████████▉| 4540/4545 [6:02:41<01:21, 16.38s/it]100%|█████████▉| 4541/4545 [6:02:44<00:50, 12.65s/it]100%|█████████▉| 4542/4545 [6:02:49<00:30, 10.13s/it]100%|█████████▉| 4543/4545 [6:02:53<00:16,  8.28s/it]100%|█████████▉| 4544/4545 [6:02:57<00:06,  6.98s/it]100%|██████████| 4545/4545 [6:03:00<00:00,  5.89s/it]                                                     {'train_runtime': 21805.5111, 'train_samples_per_second': 3.333, 'train_steps_per_second': 0.208, 'train_loss': 0.4186598621185857, 'epoch': 3.0}
100%|██████████| 4545/4545 [6:03:19<00:00,  5.89s/it]100%|██████████| 4545/4545 [6:03:19<00:00,  4.80s/it]
Training complete
Saving model
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mDPO_r-64_lr-1e-07_e-3_b-0.2_63002798[0m at: [34mhttps://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/cgvcgntg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250611_124551-cgvcgntg/logs[0m
[rank0]:[W611 18:49:56.448850320 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 0 ---
