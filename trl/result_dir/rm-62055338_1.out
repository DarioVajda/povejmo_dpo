cpu-bind=MASK - gn27, task  1  0 [3667953]: mask 0x1000000000000000000000000000000010000000000000000000000000000 set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn22
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 1     --main_process_ip gn22     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62055338     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-30 16:13:35,525] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0530 16:13:38.204000 3667998 torch/distributed/run.py:792] 
W0530 16:13:38.204000 3667998 torch/distributed/run.py:792] *****************************************
W0530 16:13:38.204000 3667998 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0530 16:13:38.204000 3667998 torch/distributed/run.py:792] *****************************************
[2025-05-30 16:14:03,688] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 16:14:03,695] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 16:14:03,728] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 16:14:03,768] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 1
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
[2025-05-30 16:14:12,975] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 16:14:12,981] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 8564
Eval steps: 4282
[2025-05-30 16:14:13,007] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 16:14:13,023] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
[2025-05-30 16:14:16,422] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 16:14:16,422] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 16:14:16,432] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 16:14:16,432] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:50<02:31, 50.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:50<02:31, 50.63s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:50<02:31, 50.63s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:50<02:31, 50.64s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:45<01:46, 53.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:45<01:46, 53.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:45<01:46, 53.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:45<01:46, 53.10s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:42<00:55, 55.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:42<00:55, 55.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:42<00:55, 55.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:42<00:55, 55.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 49.84s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 49.84s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 51.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 51.17s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 49.84s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 51.17s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 49.85s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 51.17s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Using LoRA and set up the model model
-------------------- CHECKING GRADIENTS --------------------
Trainable parameters:
- base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.40.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.40.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.41.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.41.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
Total trainable parameters: 216072192
------------------------------------------------------------
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 1/8564 [00:03<8:31:39,  3.59s/ examples]Extracting prompt in train dataset:   0%|          | 2/8564 [00:03<3:39:06,  1.54s/ examples]Extracting prompt in train dataset:   0%|          | 10/8564 [00:04<42:57,  3.32 examples/s] Extracting prompt in train dataset:   2%|▏         | 190/8564 [00:04<01:32, 91.01 examples/s]Extracting prompt in train dataset:   5%|▍         | 390/8564 [00:04<00:38, 214.77 examples/s]Extracting prompt in train dataset:   7%|▋         | 566/8564 [00:04<00:23, 346.01 examples/s]Extracting prompt in train dataset:   9%|▉         | 750/8564 [00:05<00:15, 507.02 examples/s]Extracting prompt in train dataset:  11%|█         | 950/8564 [00:05<00:10, 706.24 examples/s]Extracting prompt in train dataset:  14%|█▎        | 1170/8564 [00:05<00:07, 943.80 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1391/8564 [00:05<00:06, 1177.59 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1680/8564 [00:05<00:06, 1136.25 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1890/8564 [00:05<00:05, 1295.91 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2110/8564 [00:05<00:04, 1455.18 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2341/8564 [00:05<00:03, 1643.88 examples/s]Extracting prompt in train dataset:  30%|██▉       | 2549/8564 [00:06<00:03, 1748.38 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2763/8564 [00:06<00:03, 1841.90 examples/s]Extracting prompt in train dataset:  35%|███▍      | 2970/8564 [00:06<00:02, 1880.46 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3200/8564 [00:06<00:03, 1540.63 examples/s]Extracting prompt in train dataset:  40%|███▉      | 3420/8564 [00:06<00:03, 1685.12 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3630/8564 [00:06<00:02, 1753.47 examples/s]Extracting prompt in train dataset:  45%|████▍     | 3840/8564 [00:06<00:02, 1838.94 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4060/8564 [00:06<00:02, 1879.57 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4270/8564 [00:06<00:02, 1935.33 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4480/8564 [00:07<00:02, 1907.92 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4740/8564 [00:07<00:02, 1839.50 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4943/8564 [00:07<00:01, 1887.64 examples/s]Extracting prompt in train dataset:  60%|██████    | 5150/8564 [00:07<00:01, 1913.61 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5470/8564 [00:07<00:01, 1907.38 examples/s]Extracting prompt in train dataset:  66%|██████▋   | 5674/8564 [00:07<00:01, 1925.77 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5891/8564 [00:07<00:01, 1906.54 examples/s]Extracting prompt in train dataset:  71%|███████▏  | 6102/8564 [00:07<00:01, 1958.73 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6340/8564 [00:08<00:01, 2037.86 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 6550/8564 [00:08<00:00, 2043.84 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6761/8564 [00:08<00:00, 2061.45 examples/s]Extracting prompt in train dataset:  81%|████████▏ | 6975/8564 [00:08<00:00, 2083.92 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7283/8564 [00:08<00:00, 2061.76 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7607/8564 [00:08<00:00, 2076.68 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7837/8564 [00:08<00:00, 1412.12 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8060/8564 [00:09<00:00, 1562.04 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8290/8564 [00:09<00:00, 1715.76 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8510/8564 [00:09<00:00, 1780.02 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:09<00:00, 903.25 examples/s] 
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 90/8564 [00:00<00:10, 773.36 examples/s]Applying chat template to train dataset:   3%|▎         | 215/8564 [00:00<00:08, 1011.61 examples/s]Applying chat template to train dataset:   4%|▍         | 329/8564 [00:00<00:07, 1062.29 examples/s]Applying chat template to train dataset:   5%|▌         | 441/8564 [00:00<00:07, 1084.17 examples/s]Applying chat template to train dataset:   7%|▋         | 557/8564 [00:00<00:07, 1109.79 examples/s]Applying chat template to train dataset:   8%|▊         | 670/8564 [00:00<00:07, 1113.62 examples/s]Applying chat template to train dataset:   9%|▉         | 790/8564 [00:00<00:06, 1136.36 examples/s]Applying chat template to train dataset:  11%|█         | 906/8564 [00:00<00:06, 1142.42 examples/s]Applying chat template to train dataset:  13%|█▎        | 1076/8564 [00:00<00:06, 1136.25 examples/s]Applying chat template to train dataset:  14%|█▍        | 1190/8564 [00:01<00:06, 1136.00 examples/s]Applying chat template to train dataset:  15%|█▌        | 1307/8564 [00:01<00:06, 1142.99 examples/s]Applying chat template to train dataset:  17%|█▋        | 1480/8564 [00:01<00:06, 1110.73 examples/s]Applying chat template to train dataset:  19%|█▊        | 1596/8564 [00:01<00:06, 1121.08 examples/s]Applying chat template to train dataset:  21%|██        | 1763/8564 [00:01<00:06, 1116.11 examples/s]Applying chat template to train dataset:  23%|██▎       | 1959/8564 [00:01<00:05, 1119.63 examples/s]Applying chat template to train dataset:  24%|██▍       | 2074/8564 [00:01<00:05, 1124.08 examples/s]Applying chat template to train dataset:  26%|██▌       | 2217/8564 [00:01<00:05, 1159.75 examples/s]Applying chat template to train dataset:  27%|██▋       | 2336/8564 [00:02<00:05, 1127.53 examples/s]Applying chat template to train dataset:  29%|██▉       | 2468/8564 [00:02<00:05, 1150.23 examples/s]Applying chat template to train dataset:  30%|███       | 2590/8564 [00:02<00:05, 1152.35 examples/s]Applying chat template to train dataset:  32%|███▏      | 2722/8564 [00:02<00:04, 1196.34 examples/s]Applying chat template to train dataset:  33%|███▎      | 2844/8564 [00:02<00:05, 1115.24 examples/s]Applying chat template to train dataset:  35%|███▍      | 2990/8564 [00:02<00:04, 1163.13 examples/s]Applying chat template to train dataset:  36%|███▋      | 3120/8564 [00:02<00:05, 1088.04 examples/s]Applying chat template to train dataset:  38%|███▊      | 3257/8564 [00:02<00:04, 1128.16 examples/s]Applying chat template to train dataset:  40%|███▉      | 3425/8564 [00:03<00:04, 1124.98 examples/s]Applying chat template to train dataset:  42%|████▏     | 3591/8564 [00:03<00:04, 1118.29 examples/s]Applying chat template to train dataset:  43%|████▎     | 3705/8564 [00:03<00:04, 1120.89 examples/s]Applying chat template to train dataset:  45%|████▍     | 3826/8564 [00:03<00:04, 1098.69 examples/s]Applying chat template to train dataset:  46%|████▌     | 3950/8564 [00:03<00:04, 1093.76 examples/s]Applying chat template to train dataset:  47%|████▋     | 4062/8564 [00:03<00:04, 1100.34 examples/s]Applying chat template to train dataset:  49%|████▉     | 4224/8564 [00:03<00:03, 1231.47 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4395/8564 [00:03<00:03, 1176.36 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4563/8564 [00:04<00:03, 1153.02 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4720/8564 [00:04<00:03, 1100.35 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4840/8564 [00:04<00:03, 1114.77 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4954/8564 [00:04<00:03, 1101.98 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5070/8564 [00:04<00:03, 1115.54 examples/s]Applying chat template to train dataset:  61%|██████    | 5239/8564 [00:04<00:02, 1109.84 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5361/8564 [00:04<00:02, 1109.75 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5489/8564 [00:04<00:02, 1145.68 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5680/8564 [00:05<00:02, 1154.30 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5864/8564 [00:05<00:02, 1153.37 examples/s]Applying chat template to train dataset:  70%|███████   | 6018/8564 [00:05<00:02, 1233.05 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6203/8564 [00:05<00:01, 1230.83 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6383/8564 [00:05<00:01, 1192.41 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6557/8564 [00:05<00:01, 1158.06 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6752/8564 [00:05<00:01, 1309.30 examples/s]Applying chat template to train dataset:  81%|████████  | 6912/8564 [00:05<00:01, 1356.92 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7052/8564 [00:06<00:01, 1336.49 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7189/8564 [00:06<00:01, 1263.73 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7369/8564 [00:06<00:01, 1187.87 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7493/8564 [00:06<00:00, 1198.47 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7653/8564 [00:06<00:00, 1151.11 examples/s]Applying chat template to train dataset:  91%|█████████ | 7778/8564 [00:07<00:01, 692.59 examples/s] Applying chat template to train dataset:  92%|█████████▏| 7893/8564 [00:07<00:00, 769.65 examples/s]Applying chat template to train dataset:  94%|█████████▎| 8027/8564 [00:07<00:00, 865.73 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8143/8564 [00:07<00:00, 927.18 examples/s]Applying chat template to train dataset:  96%|█████████▋| 8263/8564 [00:07<00:00, 989.73 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8377/8564 [00:07<00:00, 1026.08 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8510/8564 [00:07<00:00, 1048.10 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:07<00:00, 1110.22 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 1/8564 [00:00<41:10,  3.47 examples/s]Tokenizing train dataset:   0%|          | 30/8564 [00:00<01:28, 96.35 examples/s]Tokenizing train dataset:   1%|          | 52/8564 [00:00<01:24, 101.09 examples/s]Tokenizing train dataset:   1%|          | 69/8564 [00:00<01:21, 103.76 examples/s]Tokenizing train dataset:   1%|          | 82/8564 [00:00<01:20, 105.66 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:01<01:21, 104.14 examples/s]Tokenizing train dataset:   1%|▏         | 116/8564 [00:01<01:21, 103.55 examples/s]Tokenizing train dataset:   2%|▏         | 134/8564 [00:01<01:20, 104.52 examples/s]Tokenizing train dataset:   2%|▏         | 154/8564 [00:01<01:10, 118.74 examples/s]Tokenizing train dataset:   2%|▏         | 170/8564 [00:01<01:16, 109.99 examples/s]Tokenizing train dataset:   2%|▏         | 187/8564 [00:01<01:17, 108.40 examples/s]Tokenizing train dataset:   2%|▏         | 199/8564 [00:01<01:16, 109.21 examples/s]Tokenizing train dataset:   2%|▏         | 212/8564 [00:02<01:14, 112.43 examples/s]Tokenizing train dataset:   3%|▎         | 233/8564 [00:02<01:03, 131.63 examples/s]Tokenizing train dataset:   3%|▎         | 247/8564 [00:02<01:03, 130.20 examples/s]Tokenizing train dataset:   3%|▎         | 263/8564 [00:02<01:00, 136.23 examples/s]Tokenizing train dataset:   3%|▎         | 280/8564 [00:02<00:59, 138.79 examples/s]Tokenizing train dataset:   4%|▎         | 300/8564 [00:02<01:04, 128.69 examples/s]Tokenizing train dataset:   4%|▎         | 321/8564 [00:02<01:06, 123.35 examples/s]Tokenizing train dataset:   4%|▍         | 338/8564 [00:03<01:09, 118.95 examples/s]Tokenizing train dataset:   4%|▍         | 357/8564 [00:03<01:10, 117.06 examples/s]Tokenizing train dataset:   4%|▍         | 375/8564 [00:03<01:10, 116.91 examples/s]Tokenizing train dataset:   5%|▍         | 388/8564 [00:03<01:09, 117.32 examples/s]Tokenizing train dataset:   5%|▍         | 403/8564 [00:03<01:14, 109.87 examples/s]Tokenizing train dataset:   5%|▍         | 416/8564 [00:03<01:11, 113.45 examples/s]Tokenizing train dataset:   5%|▌         | 431/8564 [00:03<01:10, 115.35 examples/s]Tokenizing train dataset:   5%|▌         | 443/8564 [00:03<01:16, 106.57 examples/s]Tokenizing train dataset:   5%|▌         | 455/8564 [00:04<01:14, 108.23 examples/s]Tokenizing train dataset:   5%|▌         | 466/8564 [00:04<01:15, 107.62 examples/s]Tokenizing train dataset:   6%|▌         | 478/8564 [00:04<01:14, 108.41 examples/s]Tokenizing train dataset:   6%|▌         | 492/8564 [00:04<01:19, 101.43 examples/s]Tokenizing train dataset:   6%|▌         | 505/8564 [00:04<01:15, 107.24 examples/s]Tokenizing train dataset:   6%|▌         | 517/8564 [00:04<01:16, 105.83 examples/s]Tokenizing train dataset:   6%|▌         | 530/8564 [00:04<01:13, 110.04 examples/s]Tokenizing train dataset:   6%|▋         | 545/8564 [00:04<01:11, 112.27 examples/s]Tokenizing train dataset:   7%|▋         | 558/8564 [00:05<01:10, 113.37 examples/s]Tokenizing train dataset:   7%|▋         | 570/8564 [00:05<01:11, 112.57 examples/s]Tokenizing train dataset:   7%|▋         | 582/8564 [00:05<01:14, 107.42 examples/s]Tokenizing train dataset:   7%|▋         | 594/8564 [00:05<01:14, 107.28 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:05<01:16, 104.30 examples/s]Tokenizing train dataset:   7%|▋         | 626/8564 [00:05<01:10, 112.23 examples/s]Tokenizing train dataset:   7%|▋         | 640/8564 [00:05<01:10, 112.87 examples/s]Tokenizing train dataset:   8%|▊         | 653/8564 [00:05<01:07, 117.08 examples/s]Tokenizing train dataset:   8%|▊         | 668/8564 [00:06<01:12, 108.89 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:06<01:12, 109.21 examples/s]Tokenizing train dataset:   8%|▊         | 696/8564 [00:06<01:18, 99.91 examples/s] Tokenizing train dataset:   8%|▊         | 708/8564 [00:06<01:18, 100.09 examples/s]Tokenizing train dataset:   8%|▊         | 721/8564 [00:06<01:14, 104.92 examples/s]Tokenizing train dataset:   9%|▊         | 740/8564 [00:06<01:04, 121.54 examples/s]Tokenizing train dataset:   9%|▉         | 757/8564 [00:06<01:07, 114.91 examples/s]Tokenizing train dataset:   9%|▉         | 770/8564 [00:06<01:07, 115.01 examples/s]Tokenizing train dataset:   9%|▉         | 786/8564 [00:07<01:11, 108.93 examples/s]Tokenizing train dataset:   9%|▉         | 800/8564 [00:07<01:17, 100.73 examples/s]Tokenizing train dataset:   9%|▉         | 813/8564 [00:07<01:13, 105.82 examples/s]Tokenizing train dataset:  10%|▉         | 825/8564 [00:07<01:25, 90.75 examples/s] Tokenizing train dataset:  10%|▉         | 839/8564 [00:07<01:19, 96.78 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:07<01:18, 98.62 examples/s]Tokenizing train dataset:  10%|█         | 863/8564 [00:07<01:15, 101.99 examples/s]Tokenizing train dataset:  10%|█         | 878/8564 [00:08<01:12, 105.47 examples/s]Tokenizing train dataset:  10%|█         | 899/8564 [00:08<01:00, 126.12 examples/s]Tokenizing train dataset:  11%|█         | 915/8564 [00:08<01:04, 118.35 examples/s]Tokenizing train dataset:  11%|█         | 931/8564 [00:08<01:09, 110.15 examples/s]Tokenizing train dataset:  11%|█         | 944/8564 [00:08<01:07, 112.58 examples/s]Tokenizing train dataset:  11%|█         | 960/8564 [00:08<01:15, 100.71 examples/s]Tokenizing train dataset:  11%|█▏        | 972/8564 [00:08<01:13, 103.59 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:09<01:17, 97.41 examples/s] Tokenizing train dataset:  12%|█▏        | 1001/8564 [00:09<01:15, 99.90 examples/s]Tokenizing train dataset:  12%|█▏        | 1023/8564 [00:09<01:01, 121.83 examples/s]Tokenizing train dataset:  12%|█▏        | 1037/8564 [00:09<01:07, 111.21 examples/s]Tokenizing train dataset:  12%|█▏        | 1050/8564 [00:09<01:08, 109.13 examples/s]Tokenizing train dataset:  12%|█▏        | 1062/8564 [00:09<01:07, 110.76 examples/s]Tokenizing train dataset:  13%|█▎        | 1076/8564 [00:09<01:06, 112.75 examples/s]Tokenizing train dataset:  13%|█▎        | 1091/8564 [00:09<01:02, 120.34 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:10<01:05, 113.01 examples/s]Tokenizing train dataset:  13%|█▎        | 1124/8564 [00:10<01:10, 104.83 examples/s]Tokenizing train dataset:  13%|█▎        | 1137/8564 [00:10<01:07, 109.25 examples/s]Tokenizing train dataset:  13%|█▎        | 1150/8564 [00:10<01:06, 112.24 examples/s]Tokenizing train dataset:  14%|█▎        | 1162/8564 [00:10<01:14, 98.69 examples/s] Tokenizing train dataset:  14%|█▍        | 1181/8564 [00:10<01:04, 114.97 examples/s]Tokenizing train dataset:  14%|█▍        | 1197/8564 [00:10<01:01, 119.59 examples/s]Tokenizing train dataset:  14%|█▍        | 1213/8564 [00:11<01:08, 107.18 examples/s]Tokenizing train dataset:  14%|█▍        | 1229/8564 [00:11<01:04, 113.19 examples/s]Tokenizing train dataset:  15%|█▍        | 1246/8564 [00:11<00:58, 125.13 examples/s]Tokenizing train dataset:  15%|█▍        | 1265/8564 [00:11<01:03, 114.15 examples/s]Tokenizing train dataset:  15%|█▍        | 1281/8564 [00:11<01:08, 105.59 examples/s]Tokenizing train dataset:  15%|█▌        | 1293/8564 [00:11<01:07, 107.85 examples/s]Tokenizing train dataset:  15%|█▌        | 1306/8564 [00:11<01:06, 109.95 examples/s]Tokenizing train dataset:  15%|█▌        | 1318/8564 [00:11<01:04, 111.76 examples/s]Tokenizing train dataset:  16%|█▌        | 1333/8564 [00:12<01:07, 106.76 examples/s]Tokenizing train dataset:  16%|█▌        | 1346/8564 [00:12<01:08, 105.62 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:12<01:14, 97.01 examples/s] Tokenizing train dataset:  16%|█▌        | 1372/8564 [00:12<01:14, 96.53 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:12<01:10, 102.19 examples/s]Tokenizing train dataset:  16%|█▋        | 1397/8564 [00:12<01:10, 102.06 examples/s]Tokenizing train dataset:  16%|█▋        | 1409/8564 [00:12<01:10, 101.64 examples/s]Tokenizing train dataset:  17%|█▋        | 1420/8564 [00:13<01:10, 100.79 examples/s]Tokenizing train dataset:  17%|█▋        | 1434/8564 [00:13<01:07, 105.87 examples/s]Tokenizing train dataset:  17%|█▋        | 1446/8564 [00:13<01:10, 100.56 examples/s]Tokenizing train dataset:  17%|█▋        | 1457/8564 [00:13<01:10, 100.15 examples/s]Tokenizing train dataset:  17%|█▋        | 1470/8564 [00:13<01:07, 105.42 examples/s]Tokenizing train dataset:  17%|█▋        | 1485/8564 [00:13<01:12, 97.94 examples/s] Tokenizing train dataset:  17%|█▋        | 1497/8564 [00:13<01:10, 100.29 examples/s]Tokenizing train dataset:  18%|█▊        | 1512/8564 [00:13<01:12, 97.69 examples/s] Tokenizing train dataset:  18%|█▊        | 1526/8564 [00:14<01:07, 104.24 examples/s]Tokenizing train dataset:  18%|█▊        | 1539/8564 [00:14<01:04, 108.49 examples/s]Tokenizing train dataset:  18%|█▊        | 1557/8564 [00:14<01:05, 107.58 examples/s]Tokenizing train dataset:  18%|█▊        | 1569/8564 [00:14<01:05, 106.02 examples/s]Tokenizing train dataset:  18%|█▊        | 1580/8564 [00:14<01:06, 105.43 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:14<01:08, 101.80 examples/s]Tokenizing train dataset:  19%|█▊        | 1604/8564 [00:14<01:04, 108.48 examples/s]Tokenizing train dataset:  19%|█▉        | 1619/8564 [00:14<01:01, 113.29 examples/s]Tokenizing train dataset:  19%|█▉        | 1636/8564 [00:15<01:01, 111.83 examples/s]Tokenizing train dataset:  19%|█▉        | 1653/8564 [00:15<00:58, 118.90 examples/s]Tokenizing train dataset:  19%|█▉        | 1669/8564 [00:15<01:01, 112.94 examples/s]Tokenizing train dataset:  20%|█▉        | 1689/8564 [00:15<00:58, 116.55 examples/s]Tokenizing train dataset:  20%|█▉        | 1710/8564 [00:15<00:52, 129.69 examples/s]Tokenizing train dataset:  20%|██        | 1726/8564 [00:15<00:56, 120.08 examples/s]Tokenizing train dataset:  20%|██        | 1742/8564 [00:15<01:00, 113.36 examples/s]Tokenizing train dataset:  21%|██        | 1762/8564 [00:16<00:57, 117.81 examples/s]Tokenizing train dataset:  21%|██        | 1778/8564 [00:16<00:59, 113.43 examples/s]Tokenizing train dataset:  21%|██        | 1790/8564 [00:16<01:02, 108.84 examples/s]Tokenizing train dataset:  21%|██        | 1806/8564 [00:16<00:58, 116.19 examples/s]Tokenizing train dataset:  21%|██▏       | 1820/8564 [00:16<00:57, 117.33 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:16<00:57, 117.71 examples/s]Tokenizing train dataset:  22%|██▏       | 1850/8564 [00:16<00:59, 113.01 examples/s]Tokenizing train dataset:  22%|██▏       | 1866/8564 [00:17<01:01, 108.77 examples/s]Tokenizing train dataset:  22%|██▏       | 1877/8564 [00:17<01:01, 108.17 examples/s]Tokenizing train dataset:  22%|██▏       | 1889/8564 [00:17<01:02, 107.64 examples/s]Tokenizing train dataset:  22%|██▏       | 1907/8564 [00:17<00:56, 118.79 examples/s]Tokenizing train dataset:  23%|██▎       | 1929/8564 [00:17<00:47, 138.32 examples/s]Tokenizing train dataset:  23%|██▎       | 1948/8564 [00:17<00:51, 129.30 examples/s]Tokenizing train dataset:  23%|██▎       | 1963/8564 [00:17<00:51, 126.99 examples/s]Tokenizing train dataset:  23%|██▎       | 1980/8564 [00:17<00:49, 132.04 examples/s]Tokenizing train dataset:  23%|██▎       | 1999/8564 [00:18<00:52, 125.61 examples/s]Tokenizing train dataset:  24%|██▎       | 2013/8564 [00:18<00:51, 128.34 examples/s]Tokenizing train dataset:  24%|██▎       | 2028/8564 [00:18<00:49, 132.62 examples/s]Tokenizing train dataset:  24%|██▍       | 2043/8564 [00:18<00:48, 135.59 examples/s]Tokenizing train dataset:  24%|██▍       | 2061/8564 [00:18<00:48, 134.02 examples/s]Tokenizing train dataset:  24%|██▍       | 2083/8564 [00:18<00:49, 130.10 examples/s]Tokenizing train dataset:  25%|██▍       | 2099/8564 [00:18<00:49, 129.98 examples/s]Tokenizing train dataset:  25%|██▍       | 2113/8564 [00:18<00:48, 131.88 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:19<00:47, 135.85 examples/s]Tokenizing train dataset:  25%|██▌       | 2149/8564 [00:19<00:48, 131.27 examples/s]Tokenizing train dataset:  25%|██▌       | 2169/8564 [00:19<00:50, 127.26 examples/s]Tokenizing train dataset:  26%|██▌       | 2184/8564 [00:19<00:50, 127.11 examples/s]Tokenizing train dataset:  26%|██▌       | 2202/8564 [00:19<00:47, 133.58 examples/s]Tokenizing train dataset:  26%|██▌       | 2219/8564 [00:19<00:45, 139.34 examples/s]Tokenizing train dataset:  26%|██▌       | 2242/8564 [00:19<00:45, 138.49 examples/s]Tokenizing train dataset:  26%|██▋       | 2257/8564 [00:20<00:46, 136.50 examples/s]Tokenizing train dataset:  27%|██▋       | 2279/8564 [00:20<00:40, 155.20 examples/s]Tokenizing train dataset:  27%|██▋       | 2302/8564 [00:20<00:38, 164.62 examples/s]Tokenizing train dataset:  27%|██▋       | 2320/8564 [00:20<00:43, 143.63 examples/s]Tokenizing train dataset:  27%|██▋       | 2336/8564 [00:20<00:44, 141.47 examples/s]Tokenizing train dataset:  28%|██▊       | 2363/8564 [00:20<00:42, 147.50 examples/s]Tokenizing train dataset:  28%|██▊       | 2379/8564 [00:20<00:41, 149.63 examples/s]Tokenizing train dataset:  28%|██▊       | 2402/8564 [00:20<00:41, 148.77 examples/s]Tokenizing train dataset:  28%|██▊       | 2418/8564 [00:21<00:48, 126.92 examples/s]Tokenizing train dataset:  28%|██▊       | 2433/8564 [00:21<00:47, 127.99 examples/s]Tokenizing train dataset:  29%|██▊       | 2450/8564 [00:21<00:51, 119.36 examples/s]Tokenizing train dataset:  29%|██▉       | 2466/8564 [00:21<00:49, 123.67 examples/s]Tokenizing train dataset:  29%|██▉       | 2479/8564 [00:21<00:49, 124.07 examples/s]Tokenizing train dataset:  29%|██▉       | 2495/8564 [00:21<00:52, 115.74 examples/s]Tokenizing train dataset:  29%|██▉       | 2507/8564 [00:21<00:54, 111.64 examples/s]Tokenizing train dataset:  29%|██▉       | 2519/8564 [00:22<00:54, 110.91 examples/s]Tokenizing train dataset:  30%|██▉       | 2540/8564 [00:22<00:45, 132.41 examples/s]Tokenizing train dataset:  30%|██▉       | 2563/8564 [00:22<00:39, 151.03 examples/s]Tokenizing train dataset:  30%|███       | 2579/8564 [00:22<00:40, 149.61 examples/s]Tokenizing train dataset:  30%|███       | 2600/8564 [00:22<00:42, 141.15 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:22<00:47, 125.13 examples/s]Tokenizing train dataset:  31%|███       | 2640/8564 [00:23<01:00, 97.49 examples/s] Tokenizing train dataset:  31%|███       | 2652/8564 [00:23<00:58, 100.63 examples/s]Tokenizing train dataset:  31%|███       | 2667/8564 [00:23<00:55, 105.61 examples/s]Tokenizing train dataset:  31%|███▏      | 2679/8564 [00:23<00:55, 105.59 examples/s]Tokenizing train dataset:  31%|███▏      | 2692/8564 [00:23<00:53, 110.42 examples/s]Tokenizing train dataset:  32%|███▏      | 2710/8564 [00:23<00:50, 116.88 examples/s]Tokenizing train dataset:  32%|███▏      | 2724/8564 [00:23<00:48, 121.35 examples/s]Tokenizing train dataset:  32%|███▏      | 2737/8564 [00:23<00:49, 117.39 examples/s]Tokenizing train dataset:  32%|███▏      | 2751/8564 [00:23<00:49, 116.66 examples/s]Tokenizing train dataset:  32%|███▏      | 2763/8564 [00:24<00:49, 116.42 examples/s]Tokenizing train dataset:  32%|███▏      | 2779/8564 [00:24<00:47, 122.18 examples/s]Tokenizing train dataset:  33%|███▎      | 2794/8564 [00:24<00:44, 129.19 examples/s]Tokenizing train dataset:  33%|███▎      | 2809/8564 [00:24<00:43, 133.30 examples/s]Tokenizing train dataset:  33%|███▎      | 2827/8564 [00:24<00:41, 137.11 examples/s]Tokenizing train dataset:  33%|███▎      | 2848/8564 [00:24<00:43, 131.11 examples/s]Tokenizing train dataset:  33%|███▎      | 2864/8564 [00:24<00:46, 121.69 examples/s]Tokenizing train dataset:  34%|███▎      | 2884/8564 [00:25<00:47, 120.65 examples/s]Tokenizing train dataset:  34%|███▍      | 2900/8564 [00:25<00:44, 128.16 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:25<00:39, 141.27 examples/s]Tokenizing train dataset:  34%|███▍      | 2936/8564 [00:25<00:39, 141.77 examples/s]Tokenizing train dataset:  34%|███▍      | 2953/8564 [00:25<00:38, 146.82 examples/s]Tokenizing train dataset:  35%|███▍      | 2973/8564 [00:25<00:39, 140.14 examples/s]Tokenizing train dataset:  35%|███▍      | 2990/8564 [00:25<00:38, 146.05 examples/s]Tokenizing train dataset:  35%|███▌      | 3007/8564 [00:25<00:38, 146.00 examples/s]Tokenizing train dataset:  35%|███▌      | 3028/8564 [00:25<00:39, 138.89 examples/s]Tokenizing train dataset:  36%|███▌      | 3047/8564 [00:26<00:42, 128.84 examples/s]Tokenizing train dataset:  36%|███▌      | 3068/8564 [00:26<00:42, 130.03 examples/s]Tokenizing train dataset:  36%|███▌      | 3084/8564 [00:26<00:41, 131.41 examples/s]Tokenizing train dataset:  36%|███▌      | 3099/8564 [00:26<00:42, 128.86 examples/s]Tokenizing train dataset:  36%|███▋      | 3113/8564 [00:26<00:42, 129.24 examples/s]Tokenizing train dataset:  37%|███▋      | 3131/8564 [00:26<00:43, 125.01 examples/s]Tokenizing train dataset:  37%|███▋      | 3146/8564 [00:26<00:41, 129.24 examples/s]Tokenizing train dataset:  37%|███▋      | 3161/8564 [00:27<00:42, 127.70 examples/s]Tokenizing train dataset:  37%|███▋      | 3177/8564 [00:27<00:45, 118.56 examples/s]Tokenizing train dataset:  37%|███▋      | 3195/8564 [00:27<00:46, 115.51 examples/s]Tokenizing train dataset:  37%|███▋      | 3210/8564 [00:27<00:43, 121.72 examples/s]Tokenizing train dataset:  38%|███▊      | 3225/8564 [00:27<00:42, 127.11 examples/s]Tokenizing train dataset:  38%|███▊      | 3250/8564 [00:27<00:40, 129.62 examples/s]Tokenizing train dataset:  38%|███▊      | 3265/8564 [00:27<00:41, 128.96 examples/s]Tokenizing train dataset:  38%|███▊      | 3279/8564 [00:27<00:40, 129.68 examples/s]Tokenizing train dataset:  39%|███▊      | 3299/8564 [00:28<00:42, 124.48 examples/s]Tokenizing train dataset:  39%|███▊      | 3315/8564 [00:28<00:40, 129.08 examples/s]Tokenizing train dataset:  39%|███▉      | 3334/8564 [00:28<00:42, 121.72 examples/s]Tokenizing train dataset:  39%|███▉      | 3349/8564 [00:28<00:41, 126.59 examples/s]Tokenizing train dataset:  39%|███▉      | 3364/8564 [00:28<00:40, 127.42 examples/s]Tokenizing train dataset:  39%|███▉      | 3377/8564 [00:28<00:40, 127.42 examples/s]Tokenizing train dataset:  40%|███▉      | 3394/8564 [00:28<00:37, 137.34 examples/s]Tokenizing train dataset:  40%|███▉      | 3409/8564 [00:28<00:37, 138.22 examples/s]Tokenizing train dataset:  40%|████      | 3430/8564 [00:29<00:39, 129.66 examples/s]Tokenizing train dataset:  40%|████      | 3445/8564 [00:29<00:39, 130.30 examples/s]Tokenizing train dataset:  40%|████      | 3461/8564 [00:29<00:37, 135.85 examples/s]Tokenizing train dataset:  41%|████      | 3481/8564 [00:29<00:38, 131.31 examples/s]Tokenizing train dataset:  41%|████      | 3504/8564 [00:29<00:37, 134.68 examples/s]Tokenizing train dataset:  41%|████      | 3520/8564 [00:29<00:36, 138.79 examples/s]Tokenizing train dataset:  41%|████▏     | 3541/8564 [00:29<00:37, 132.90 examples/s]Tokenizing train dataset:  42%|████▏     | 3561/8564 [00:30<00:38, 130.81 examples/s]Tokenizing train dataset:  42%|████▏     | 3577/8564 [00:30<00:37, 132.66 examples/s]Tokenizing train dataset:  42%|████▏     | 3593/8564 [00:30<00:35, 138.20 examples/s]Tokenizing train dataset:  42%|████▏     | 3608/8564 [00:30<00:36, 135.40 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:30<00:36, 136.74 examples/s]Tokenizing train dataset:  43%|████▎     | 3645/8564 [00:30<00:35, 137.56 examples/s]Tokenizing train dataset:  43%|████▎     | 3659/8564 [00:30<00:36, 136.12 examples/s]Tokenizing train dataset:  43%|████▎     | 3676/8564 [00:31<00:39, 122.80 examples/s]Tokenizing train dataset:  43%|████▎     | 3691/8564 [00:31<00:38, 127.81 examples/s]Tokenizing train dataset:  43%|████▎     | 3710/8564 [00:31<00:39, 124.09 examples/s]Tokenizing train dataset:  44%|████▎     | 3727/8564 [00:31<00:37, 128.57 examples/s]Tokenizing train dataset:  44%|████▍     | 3748/8564 [00:31<00:36, 130.29 examples/s]Tokenizing train dataset:  44%|████▍     | 3764/8564 [00:31<00:35, 135.45 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:31<00:35, 135.27 examples/s]Tokenizing train dataset:  44%|████▍     | 3794/8564 [00:31<00:35, 134.61 examples/s]Tokenizing train dataset:  45%|████▍     | 3811/8564 [00:32<00:38, 124.63 examples/s]Tokenizing train dataset:  45%|████▍     | 3825/8564 [00:32<00:37, 125.26 examples/s]Tokenizing train dataset:  45%|████▍     | 3840/8564 [00:32<00:37, 125.61 examples/s]Tokenizing train dataset:  45%|████▍     | 3853/8564 [00:32<00:37, 124.33 examples/s]Tokenizing train dataset:  45%|████▌     | 3868/8564 [00:32<00:37, 126.84 examples/s]Tokenizing train dataset:  45%|████▌     | 3882/8564 [00:32<00:37, 124.40 examples/s]Tokenizing train dataset:  46%|████▌     | 3899/8564 [00:32<00:41, 112.54 examples/s]Tokenizing train dataset:  46%|████▌     | 3911/8564 [00:32<00:41, 111.98 examples/s]Tokenizing train dataset:  46%|████▌     | 3925/8564 [00:33<00:39, 118.25 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:33<00:38, 118.88 examples/s]Tokenizing train dataset:  46%|████▌     | 3957/8564 [00:33<00:37, 123.72 examples/s]Tokenizing train dataset:  46%|████▋     | 3972/8564 [00:33<00:35, 127.67 examples/s]Tokenizing train dataset:  47%|████▋     | 3991/8564 [00:33<00:36, 125.59 examples/s]Tokenizing train dataset:  47%|████▋     | 4005/8564 [00:33<00:36, 123.59 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:33<00:34, 130.86 examples/s]Tokenizing train dataset:  47%|████▋     | 4036/8564 [00:33<00:33, 134.28 examples/s]Tokenizing train dataset:  47%|████▋     | 4051/8564 [00:33<00:34, 131.73 examples/s]Tokenizing train dataset:  47%|████▋     | 4065/8564 [00:34<00:33, 132.72 examples/s]Tokenizing train dataset:  48%|████▊     | 4083/8564 [00:34<00:35, 127.20 examples/s]Tokenizing train dataset:  48%|████▊     | 4097/8564 [00:34<00:35, 124.29 examples/s]Tokenizing train dataset:  48%|████▊     | 4113/8564 [00:34<00:35, 126.60 examples/s]Tokenizing train dataset:  48%|████▊     | 4127/8564 [00:34<00:34, 128.89 examples/s]Tokenizing train dataset:  48%|████▊     | 4141/8564 [00:34<00:33, 131.28 examples/s]Tokenizing train dataset:  49%|████▊     | 4162/8564 [00:34<00:30, 144.70 examples/s]Tokenizing train dataset:  49%|████▉     | 4179/8564 [00:34<00:30, 142.91 examples/s]Tokenizing train dataset:  49%|████▉     | 4194/8564 [00:35<00:30, 144.09 examples/s]Tokenizing train dataset:  49%|████▉     | 4209/8564 [00:35<00:30, 144.40 examples/s]Tokenizing train dataset:  49%|████▉     | 4224/8564 [00:35<00:30, 144.52 examples/s]Tokenizing train dataset:  50%|████▉     | 4242/8564 [00:35<00:32, 134.04 examples/s]Tokenizing train dataset:  50%|████▉     | 4263/8564 [00:35<00:33, 127.82 examples/s]Tokenizing train dataset:  50%|████▉     | 4280/8564 [00:35<00:32, 131.71 examples/s]Tokenizing train dataset:  50%|█████     | 4294/8564 [00:35<00:32, 131.19 examples/s]Tokenizing train dataset:  50%|█████     | 4309/8564 [00:35<00:33, 128.85 examples/s]Tokenizing train dataset:  51%|█████     | 4328/8564 [00:36<00:34, 123.83 examples/s]Tokenizing train dataset:  51%|█████     | 4348/8564 [00:36<00:34, 120.83 examples/s]Tokenizing train dataset:  51%|█████     | 4362/8564 [00:36<00:34, 123.29 examples/s]Tokenizing train dataset:  51%|█████     | 4378/8564 [00:36<00:32, 128.13 examples/s]Tokenizing train dataset:  51%|█████▏    | 4394/8564 [00:36<00:31, 134.33 examples/s]Tokenizing train dataset:  52%|█████▏    | 4411/8564 [00:36<00:35, 117.67 examples/s]Tokenizing train dataset:  52%|█████▏    | 4426/8564 [00:36<00:33, 122.71 examples/s]Tokenizing train dataset:  52%|█████▏    | 4439/8564 [00:36<00:33, 122.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 4454/8564 [00:37<00:33, 124.14 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:37<00:32, 126.83 examples/s]Tokenizing train dataset:  52%|█████▏    | 4485/8564 [00:37<00:31, 127.71 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:37<00:33, 123.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 4519/8564 [00:37<00:32, 124.02 examples/s]Tokenizing train dataset:  53%|█████▎    | 4540/8564 [00:37<00:32, 124.04 examples/s]Tokenizing train dataset:  53%|█████▎    | 4555/8564 [00:37<00:31, 128.75 examples/s]Tokenizing train dataset:  53%|█████▎    | 4570/8564 [00:38<00:31, 126.82 examples/s]Tokenizing train dataset:  54%|█████▎    | 4590/8564 [00:38<00:32, 121.70 examples/s]Tokenizing train dataset:  54%|█████▍    | 4604/8564 [00:38<00:34, 115.97 examples/s]Tokenizing train dataset:  54%|█████▍    | 4621/8564 [00:38<00:31, 124.72 examples/s]Tokenizing train dataset:  54%|█████▍    | 4640/8564 [00:38<00:33, 115.48 examples/s]Tokenizing train dataset:  54%|█████▍    | 4654/8564 [00:38<00:33, 117.33 examples/s]Tokenizing train dataset:  55%|█████▍    | 4671/8564 [00:38<00:34, 111.64 examples/s]Tokenizing train dataset:  55%|█████▍    | 4686/8564 [00:39<00:34, 112.48 examples/s]Tokenizing train dataset:  55%|█████▍    | 4698/8564 [00:39<00:34, 112.66 examples/s]Tokenizing train dataset:  55%|█████▌    | 4716/8564 [00:39<00:34, 110.37 examples/s]Tokenizing train dataset:  55%|█████▌    | 4728/8564 [00:39<00:34, 111.50 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:39<00:33, 113.07 examples/s]Tokenizing train dataset:  56%|█████▌    | 4754/8564 [00:39<00:35, 107.92 examples/s]Tokenizing train dataset:  56%|█████▌    | 4767/8564 [00:39<00:34, 109.97 examples/s]Tokenizing train dataset:  56%|█████▌    | 4779/8564 [00:39<00:35, 106.36 examples/s]Tokenizing train dataset:  56%|█████▌    | 4793/8564 [00:39<00:33, 113.69 examples/s]Tokenizing train dataset:  56%|█████▌    | 4812/8564 [00:40<00:28, 132.69 examples/s]Tokenizing train dataset:  57%|█████▋    | 4846/8564 [00:40<00:20, 178.35 examples/s]Tokenizing train dataset:  57%|█████▋    | 4866/8564 [00:40<00:20, 181.97 examples/s]Tokenizing train dataset:  57%|█████▋    | 4898/8564 [00:40<00:20, 180.91 examples/s]Tokenizing train dataset:  58%|█████▊    | 4931/8564 [00:40<00:17, 207.47 examples/s]Tokenizing train dataset:  58%|█████▊    | 4965/8564 [00:40<00:17, 203.87 examples/s]Tokenizing train dataset:  58%|█████▊    | 4990/8564 [00:40<00:17, 203.72 examples/s]Tokenizing train dataset:  59%|█████▊    | 5015/8564 [00:41<00:16, 211.06 examples/s]Tokenizing train dataset:  59%|█████▉    | 5050/8564 [00:41<00:17, 205.52 examples/s]Tokenizing train dataset:  59%|█████▉    | 5076/8564 [00:41<00:16, 215.94 examples/s]Tokenizing train dataset:  60%|█████▉    | 5099/8564 [00:41<00:15, 217.26 examples/s]Tokenizing train dataset:  60%|█████▉    | 5136/8564 [00:41<00:15, 224.70 examples/s]Tokenizing train dataset:  60%|██████    | 5161/8564 [00:41<00:14, 230.21 examples/s]Tokenizing train dataset:  61%|██████    | 5186/8564 [00:41<00:14, 232.72 examples/s]Tokenizing train dataset:  61%|██████    | 5215/8564 [00:41<00:14, 237.64 examples/s]Tokenizing train dataset:  61%|██████    | 5240/8564 [00:41<00:13, 238.11 examples/s]Tokenizing train dataset:  62%|██████▏   | 5272/8564 [00:42<00:12, 255.79 examples/s]Tokenizing train dataset:  62%|██████▏   | 5307/8564 [00:42<00:13, 246.61 examples/s]Tokenizing train dataset:  62%|██████▏   | 5336/8564 [00:42<00:14, 223.67 examples/s]Tokenizing train dataset:  63%|██████▎   | 5359/8564 [00:42<00:14, 224.41 examples/s]Tokenizing train dataset:  63%|██████▎   | 5388/8564 [00:42<00:15, 209.55 examples/s]Tokenizing train dataset:  63%|██████▎   | 5429/8564 [00:42<00:13, 224.08 examples/s]Tokenizing train dataset:  64%|██████▎   | 5453/8564 [00:42<00:14, 218.27 examples/s]Tokenizing train dataset:  64%|██████▍   | 5485/8564 [00:43<00:14, 206.13 examples/s]Tokenizing train dataset:  64%|██████▍   | 5512/8564 [00:43<00:14, 212.52 examples/s]Tokenizing train dataset:  65%|██████▍   | 5536/8564 [00:43<00:13, 216.97 examples/s]Tokenizing train dataset:  65%|██████▌   | 5567/8564 [00:43<00:14, 206.43 examples/s]Tokenizing train dataset:  65%|██████▌   | 5593/8564 [00:43<00:13, 217.66 examples/s]Tokenizing train dataset:  66%|██████▌   | 5620/8564 [00:43<00:12, 228.88 examples/s]Tokenizing train dataset:  66%|██████▌   | 5646/8564 [00:43<00:12, 235.56 examples/s]Tokenizing train dataset:  66%|██████▋   | 5677/8564 [00:43<00:12, 222.53 examples/s]Tokenizing train dataset:  67%|██████▋   | 5706/8564 [00:44<00:12, 231.62 examples/s]Tokenizing train dataset:  67%|██████▋   | 5741/8564 [00:44<00:12, 225.77 examples/s]Tokenizing train dataset:  67%|██████▋   | 5771/8564 [00:44<00:11, 242.75 examples/s]Tokenizing train dataset:  68%|██████▊   | 5797/8564 [00:44<00:11, 246.98 examples/s]Tokenizing train dataset:  68%|██████▊   | 5825/8564 [00:44<00:10, 253.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 5852/8564 [00:44<00:12, 210.10 examples/s]Tokenizing train dataset:  69%|██████▊   | 5875/8564 [00:44<00:14, 187.70 examples/s]Tokenizing train dataset:  69%|██████▉   | 5897/8564 [00:45<00:13, 193.41 examples/s]Tokenizing train dataset:  69%|██████▉   | 5924/8564 [00:45<00:12, 211.93 examples/s]Tokenizing train dataset:  69%|██████▉   | 5948/8564 [00:45<00:11, 218.98 examples/s]Tokenizing train dataset:  70%|██████▉   | 5974/8564 [00:45<00:11, 220.06 examples/s]Tokenizing train dataset:  70%|███████   | 6005/8564 [00:45<00:17, 149.49 examples/s]Tokenizing train dataset:  70%|███████   | 6032/8564 [00:45<00:14, 171.13 examples/s]Tokenizing train dataset:  71%|███████   | 6061/8564 [00:45<00:13, 190.23 examples/s]Tokenizing train dataset:  71%|███████   | 6091/8564 [00:46<00:13, 184.98 examples/s]Tokenizing train dataset:  71%|███████▏  | 6114/8564 [00:46<00:12, 193.59 examples/s]Tokenizing train dataset:  72%|███████▏  | 6143/8564 [00:46<00:11, 215.73 examples/s]Tokenizing train dataset:  72%|███████▏  | 6168/8564 [00:46<00:11, 216.62 examples/s]Tokenizing train dataset:  72%|███████▏  | 6196/8564 [00:46<00:10, 229.84 examples/s]Tokenizing train dataset:  73%|███████▎  | 6222/8564 [00:46<00:09, 236.30 examples/s]Tokenizing train dataset:  73%|███████▎  | 6262/8564 [00:46<00:09, 241.76 examples/s]Tokenizing train dataset:  73%|███████▎  | 6294/8564 [00:46<00:09, 230.42 examples/s]Tokenizing train dataset:  74%|███████▍  | 6319/8564 [00:47<00:09, 228.78 examples/s]Tokenizing train dataset:  74%|███████▍  | 6348/8564 [00:47<00:09, 230.71 examples/s]Tokenizing train dataset:  74%|███████▍  | 6380/8564 [00:47<00:08, 243.61 examples/s]Tokenizing train dataset:  75%|███████▍  | 6414/8564 [00:47<00:09, 233.69 examples/s]Tokenizing train dataset:  75%|███████▌  | 6443/8564 [00:47<00:09, 234.09 examples/s]Tokenizing train dataset:  76%|███████▌  | 6479/8564 [00:47<00:09, 223.62 examples/s]Tokenizing train dataset:  76%|███████▌  | 6510/8564 [00:47<00:09, 210.77 examples/s]Tokenizing train dataset:  76%|███████▋  | 6540/8564 [00:48<00:09, 210.03 examples/s]Tokenizing train dataset:  77%|███████▋  | 6567/8564 [00:48<00:10, 194.89 examples/s]Tokenizing train dataset:  77%|███████▋  | 6591/8564 [00:48<00:10, 180.39 examples/s]Tokenizing train dataset:  77%|███████▋  | 6611/8564 [00:48<00:12, 160.53 examples/s]Tokenizing train dataset:  77%|███████▋  | 6633/8564 [00:48<00:11, 172.57 examples/s]Tokenizing train dataset:  78%|███████▊  | 6660/8564 [00:48<00:10, 188.75 examples/s]Tokenizing train dataset:  78%|███████▊  | 6687/8564 [00:48<00:09, 207.54 examples/s]Tokenizing train dataset:  78%|███████▊  | 6715/8564 [00:48<00:08, 223.22 examples/s]Tokenizing train dataset:  79%|███████▉  | 6745/8564 [00:49<00:08, 207.51 examples/s]Tokenizing train dataset:  79%|███████▉  | 6770/8564 [00:49<00:08, 208.52 examples/s]Tokenizing train dataset:  79%|███████▉  | 6792/8564 [00:49<00:08, 211.33 examples/s]Tokenizing train dataset:  80%|███████▉  | 6822/8564 [00:49<00:08, 200.27 examples/s]Tokenizing train dataset:  80%|████████  | 6856/8564 [00:49<00:08, 198.50 examples/s]Tokenizing train dataset:  80%|████████  | 6885/8564 [00:49<00:07, 211.19 examples/s]Tokenizing train dataset:  81%|████████  | 6911/8564 [00:49<00:07, 220.95 examples/s]Tokenizing train dataset:  81%|████████  | 6938/8564 [00:49<00:07, 231.89 examples/s]Tokenizing train dataset:  81%|████████▏ | 6962/8564 [00:50<00:07, 222.78 examples/s]Tokenizing train dataset:  82%|████████▏ | 6987/8564 [00:50<00:07, 220.30 examples/s]Tokenizing train dataset:  82%|████████▏ | 7015/8564 [00:50<00:07, 203.15 examples/s]Tokenizing train dataset:  82%|████████▏ | 7039/8564 [00:50<00:07, 210.83 examples/s]Tokenizing train dataset:  83%|████████▎ | 7070/8564 [00:50<00:07, 203.40 examples/s]Tokenizing train dataset:  83%|████████▎ | 7097/8564 [00:50<00:06, 212.84 examples/s]Tokenizing train dataset:  83%|████████▎ | 7122/8564 [00:50<00:06, 218.83 examples/s]Tokenizing train dataset:  83%|████████▎ | 7150/8564 [00:51<00:07, 193.12 examples/s]Tokenizing train dataset:  84%|████████▍ | 7173/8564 [00:51<00:06, 201.17 examples/s]Tokenizing train dataset:  84%|████████▍ | 7203/8564 [00:51<00:06, 221.99 examples/s]Tokenizing train dataset:  85%|████████▍ | 7238/8564 [00:51<00:06, 213.52 examples/s]Tokenizing train dataset:  85%|████████▍ | 7274/8564 [00:51<00:05, 219.83 examples/s]Tokenizing train dataset:  85%|████████▌ | 7304/8564 [00:51<00:06, 208.68 examples/s]Tokenizing train dataset:  86%|████████▌ | 7326/8564 [00:51<00:05, 209.98 examples/s]Tokenizing train dataset:  86%|████████▌ | 7350/8564 [00:51<00:05, 211.07 examples/s]Tokenizing train dataset:  86%|████████▌ | 7373/8564 [00:52<00:05, 213.85 examples/s]Tokenizing train dataset:  86%|████████▋ | 7402/8564 [00:52<00:05, 199.11 examples/s]Tokenizing train dataset:  87%|████████▋ | 7430/8564 [00:52<00:05, 217.53 examples/s]Tokenizing train dataset:  87%|████████▋ | 7455/8564 [00:52<00:04, 225.73 examples/s]Tokenizing train dataset:  87%|████████▋ | 7488/8564 [00:52<00:04, 222.33 examples/s]Tokenizing train dataset:  88%|████████▊ | 7528/8564 [00:52<00:04, 219.31 examples/s]Tokenizing train dataset:  88%|████████▊ | 7551/8564 [00:52<00:04, 220.69 examples/s]Tokenizing train dataset:  89%|████████▊ | 7580/8564 [00:52<00:04, 231.35 examples/s]Tokenizing train dataset:  89%|████████▉ | 7613/8564 [00:53<00:04, 217.75 examples/s]Tokenizing train dataset:  89%|████████▉ | 7637/8564 [00:53<00:04, 215.24 examples/s]Tokenizing train dataset:  89%|████████▉ | 7664/8564 [00:53<00:04, 196.74 examples/s]Tokenizing train dataset:  90%|████████▉ | 7688/8564 [00:53<00:04, 206.43 examples/s]Tokenizing train dataset:  90%|█████████ | 7711/8564 [00:53<00:04, 208.89 examples/s]Tokenizing train dataset:  90%|█████████ | 7743/8564 [00:53<00:04, 202.74 examples/s]Tokenizing train dataset:  91%|█████████ | 7771/8564 [00:53<00:04, 196.09 examples/s]Tokenizing train dataset:  91%|█████████ | 7794/8564 [00:54<00:03, 196.64 examples/s]Tokenizing train dataset:  91%|█████████▏| 7825/8564 [00:54<00:03, 197.10 examples/s]Tokenizing train dataset:  92%|█████████▏| 7853/8564 [00:54<00:03, 215.25 examples/s]Tokenizing train dataset:  92%|█████████▏| 7880/8564 [00:54<00:03, 200.79 examples/s]Tokenizing train dataset:  92%|█████████▏| 7907/8564 [00:54<00:03, 212.15 examples/s]Tokenizing train dataset:  93%|█████████▎| 7940/8564 [00:54<00:03, 206.24 examples/s]Tokenizing train dataset:  93%|█████████▎| 7964/8564 [00:54<00:02, 213.34 examples/s]Tokenizing train dataset:  93%|█████████▎| 7990/8564 [00:54<00:02, 216.62 examples/s]Tokenizing train dataset:  94%|█████████▎| 8020/8564 [00:55<00:02, 229.24 examples/s]Tokenizing train dataset:  94%|█████████▍| 8056/8564 [00:55<00:02, 221.50 examples/s]Tokenizing train dataset:  94%|█████████▍| 8086/8564 [00:55<00:02, 211.48 examples/s]Tokenizing train dataset:  95%|█████████▍| 8116/8564 [00:55<00:02, 203.75 examples/s]Tokenizing train dataset:  95%|█████████▌| 8140/8564 [00:55<00:02, 209.70 examples/s]Tokenizing train dataset:  95%|█████████▌| 8164/8564 [00:55<00:01, 208.71 examples/s]Tokenizing train dataset:  96%|█████████▌| 8190/8564 [00:55<00:01, 219.44 examples/s]Tokenizing train dataset:  96%|█████████▌| 8222/8564 [00:56<00:01, 212.41 examples/s]Tokenizing train dataset:  96%|█████████▋| 8248/8564 [00:56<00:01, 223.33 examples/s]Tokenizing train dataset:  97%|█████████▋| 8282/8564 [00:56<00:01, 246.13 examples/s]Tokenizing train dataset:  97%|█████████▋| 8310/8564 [00:56<00:01, 252.06 examples/s]Tokenizing train dataset:  97%|█████████▋| 8342/8564 [00:56<00:00, 227.93 examples/s]Tokenizing train dataset:  98%|█████████▊| 8372/8564 [00:56<00:00, 215.37 examples/s]Tokenizing train dataset:  98%|█████████▊| 8404/8564 [00:56<00:00, 212.31 examples/s]Tokenizing train dataset:  98%|█████████▊| 8430/8564 [00:56<00:00, 213.10 examples/s]Tokenizing train dataset:  99%|█████████▊| 8453/8564 [00:57<00:00, 208.99 examples/s]Tokenizing train dataset:  99%|█████████▉| 8481/8564 [00:57<00:00, 221.81 examples/s]Tokenizing train dataset:  99%|█████████▉| 8517/8564 [00:57<00:00, 222.51 examples/s]Tokenizing train dataset: 100%|█████████▉| 8549/8564 [00:57<00:00, 216.43 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:57<00:00, 148.64 examples/s]
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 153/8564 [00:00<00:05, 1501.12 examples/s]Extracting prompt in eval dataset:  33%|███▎      | 310/953 [00:00<00:00, 3067.10 examples/s]Extracting prompt in train dataset:   2%|▏         | 150/8564 [00:00<00:06, 1321.88 examples/s]Extracting prompt in train dataset:   2%|▏         | 170/8564 [00:00<00:05, 1556.18 examples/s]Extracting prompt in train dataset:   4%|▎         | 304/8564 [00:00<00:05, 1379.66 examples/s]Extracting prompt in train dataset:   5%|▍         | 410/8564 [00:00<00:04, 2011.64 examples/s]Extracting prompt in train dataset:   4%|▍         | 380/8564 [00:00<00:05, 1482.66 examples/s]Extracting prompt in eval dataset:  75%|███████▍  | 710/953 [00:00<00:00, 2785.99 examples/s]Extracting prompt in train dataset:   6%|▌         | 480/8564 [00:00<00:05, 1492.72 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2768.62 examples/s]
Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:00<00:05, 1500.55 examples/s]Extracting prompt in train dataset:   7%|▋         | 630/8564 [00:00<00:04, 1656.73 examples/s]Extracting prompt in train dataset:   8%|▊         | 690/8564 [00:00<00:04, 1712.97 examples/s]Extracting prompt in train dataset:   8%|▊         | 707/8564 [00:00<00:05, 1516.66 examples/s]Extracting prompt in train dataset:   9%|▉         | 810/8564 [00:00<00:04, 1701.46 examples/s]Extracting prompt in train dataset:  11%|█         | 900/8564 [00:00<00:04, 1831.01 examples/s]Extracting prompt in train dataset:  10%|█         | 862/8564 [00:00<00:05, 1473.62 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1030/8564 [00:00<00:04, 1564.64 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1110/8564 [00:00<00:04, 1841.48 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1070/8564 [00:00<00:04, 1647.62 examples/s]Extracting prompt in train dataset:  15%|█▍        | 1282/8564 [00:00<00:04, 1791.96 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1370/8564 [00:00<00:04, 1791.42 examples/s]Extracting prompt in train dataset:  15%|█▌        | 1290/8564 [00:00<00:04, 1590.43 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1551/8564 [00:00<00:03, 1795.73 examples/s]Extracting prompt in train dataset:  19%|█▊        | 1590/8564 [00:00<00:03, 1853.27 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1525/8564 [00:00<00:04, 1546.01 examples/s]Extracting prompt in train dataset:  21%|██        | 1780/8564 [00:01<00:04, 1677.65 examples/s]Extracting prompt in train dataset:  21%|██        | 1780/8564 [00:01<00:03, 1803.25 examples/s]Extracting prompt in train dataset:  20%|██        | 1722/8564 [00:01<00:04, 1639.96 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1929/8564 [00:01<00:03, 1747.26 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2040/8564 [00:01<00:03, 1688.34 examples/s]Extracting prompt in train dataset:  23%|██▎       | 2010/8564 [00:01<00:03, 1699.54 examples/s]Extracting prompt in train dataset:  25%|██▌       | 2170/8564 [00:01<00:03, 1918.52 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2220/8564 [00:01<00:03, 1677.39 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2200/8564 [00:01<00:03, 1696.75 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2400/8564 [00:01<00:03, 1700.24 examples/s]Extracting prompt in train dataset:  29%|██▊       | 2446/8564 [00:01<00:03, 1838.50 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  28%|██▊       | 2440/8564 [00:01<00:03, 1646.55 examples/s]Applying chat template to eval dataset:  39%|███▉      | 375/953 [00:00<00:00, 3721.03 examples/s]Extracting prompt in train dataset:  31%|███       | 2650/8564 [00:01<00:03, 1820.12 examples/s]Extracting prompt in train dataset:  31%|███       | 2650/8564 [00:01<00:03, 1625.08 examples/s]Extracting prompt in train dataset:  31%|███▏      | 2686/8564 [00:01<00:03, 1628.57 examples/s]Applying chat template to eval dataset:  93%|█████████▎| 887/953 [00:00<00:00, 3406.77 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2896/8564 [00:01<00:03, 1747.18 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3539.98 examples/s]
Extracting prompt in train dataset:  34%|███▍      | 2891/8564 [00:01<00:03, 1615.49 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2850/8564 [00:01<00:03, 1580.19 examples/s]Extracting prompt in train dataset:  35%|███▌      | 3020/8564 [00:01<00:03, 1597.58 examples/s]Extracting prompt in train dataset:  36%|███▋      | 3120/8564 [00:01<00:03, 1636.01 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3135/8564 [00:01<00:03, 1661.80 examples/s]Extracting prompt in train dataset:  39%|███▊      | 3309/8564 [00:01<00:03, 1684.63 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3266/8564 [00:01<00:03, 1607.61 examples/s]Extracting prompt in train dataset:  40%|███▉      | 3388/8564 [00:02<00:03, 1645.53 examples/s]Extracting prompt in train dataset:  40%|████      | 3450/8564 [00:02<00:03, 1657.25 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3572/8564 [00:02<00:02, 1698.70 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3588/8564 [00:02<00:03, 1629.35 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3631/8564 [00:02<00:02, 1695.68 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3760/8564 [00:02<00:02, 1733.05 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3788/8564 [00:02<00:02, 1658.13 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3809/8564 [00:02<00:02, 1716.78 examples/s]Extracting prompt in train dataset:  46%|████▌     | 3956/8564 [00:02<00:02, 1786.65 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4000/8564 [00:02<00:02, 1696.01 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4060/8564 [00:02<00:02, 1675.42 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4181/8564 [00:02<00:02, 1778.22 examples/s]Extracting prompt in train dataset:  50%|█████     | 4300/8564 [00:02<00:02, 1782.55 examples/s]Extracting prompt in train dataset:  51%|█████     | 4376/8564 [00:02<00:02, 1760.43 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4280/8564 [00:02<00:02, 1733.11 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4482/8564 [00:02<00:02, 1732.14 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4480/8564 [00:02<00:02, 1789.40 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 4653/8564 [00:02<00:02, 1678.75 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 4678/8564 [00:02<00:02, 1788.78 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4723/8564 [00:02<00:02, 1693.65 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4860/8564 [00:02<00:02, 1736.80 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4893/8564 [00:02<00:02, 1647.17 examples/s]Tokenizing eval dataset:   1%|          | 10/953 [00:00<00:11, 85.33 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4990/8564 [00:03<00:02, 1644.70 examples/s]Tokenizing eval dataset:   2%|▏         | 23/953 [00:00<00:09, 100.64 examples/s]Extracting prompt in train dataset:  60%|██████    | 5170/8564 [00:03<00:01, 1760.69 examples/s]Extracting prompt in train dataset:  60%|██████    | 5160/8564 [00:03<00:02, 1635.03 examples/s]Extracting prompt in train dataset:  61%|██████    | 5200/8564 [00:03<00:01, 1744.31 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:09, 99.62 examples/s] Extracting prompt in train dataset:  63%|██████▎   | 5365/8564 [00:03<00:01, 1731.50 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5328/8564 [00:03<00:02, 1597.73 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5400/8564 [00:03<00:01, 1803.18 examples/s]Tokenizing eval dataset:   5%|▍         | 45/953 [00:00<00:09, 96.09 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5500/8564 [00:03<00:01, 1619.50 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5542/8564 [00:03<00:01, 1723.70 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 5650/8564 [00:03<00:01, 1735.76 examples/s]Tokenizing eval dataset:   6%|▌         | 55/953 [00:00<00:09, 90.84 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5730/8564 [00:03<00:01, 1555.11 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5820/8564 [00:03<00:01, 1694.18 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5848/8564 [00:03<00:01, 1789.94 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5910/8564 [00:03<00:01, 1611.34 examples/s]Tokenizing eval dataset:   7%|▋         | 67/953 [00:00<00:10, 84.02 examples/s]Extracting prompt in train dataset:  71%|███████   | 6076/8564 [00:03<00:01, 1628.25 examples/s]Extracting prompt in train dataset:  71%|███████▏  | 6110/8564 [00:03<00:01, 1734.90 examples/s]Extracting prompt in train dataset:  71%|███████   | 6090/8564 [00:03<00:01, 1641.13 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:09, 89.42 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6244/8564 [00:03<00:01, 1625.54 examples/s]Extracting prompt in train dataset:  74%|███████▎  | 6300/8564 [00:03<00:01, 1767.32 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6260/8564 [00:03<00:01, 1644.55 examples/s]Tokenizing eval dataset:   9%|▉         | 89/953 [00:00<00:09, 87.55 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 6409/8564 [00:03<00:01, 1628.43 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 6450/8564 [00:03<00:01, 1708.36 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 6500/8564 [00:03<00:01, 1763.13 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:01<00:10, 79.05 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6630/8564 [00:03<00:01, 1546.06 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6715/8564 [00:03<00:01, 1727.12 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6776/8564 [00:03<00:01, 1773.82 examples/s]Tokenizing eval dataset:  12%|█▏        | 113/953 [00:01<00:09, 85.35 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6800/8564 [00:04<00:01, 1557.51 examples/s]Extracting prompt in train dataset:  81%|████████  | 6927/8564 [00:04<00:00, 1769.28 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 7035/8564 [00:04<00:00, 1725.19 examples/s]Extracting prompt in train dataset:  81%|████████▏ | 6964/8564 [00:04<00:01, 1527.47 examples/s]Tokenizing eval dataset:  13%|█▎        | 124/953 [00:01<00:10, 78.77 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7231/8564 [00:04<00:00, 1779.81 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7203/8564 [00:04<00:00, 1736.84 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7130/8564 [00:04<00:00, 1548.02 examples/s]Tokenizing eval dataset:  14%|█▍        | 136/953 [00:01<00:09, 84.12 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7420/8564 [00:04<00:00, 1739.62 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7292/8564 [00:04<00:00, 1566.97 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7469/8564 [00:04<00:00, 1745.43 examples/s]Extracting prompt in train dataset:  89%|████████▊ | 7600/8564 [00:04<00:00, 1723.60 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7460/8564 [00:04<00:00, 1592.37 examples/s]Tokenizing eval dataset:  15%|█▌        | 147/953 [00:01<00:10, 77.17 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7630/8564 [00:04<00:00, 1557.56 examples/s]Tokenizing eval dataset:  16%|█▋        | 156/953 [00:01<00:10, 79.26 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7730/8564 [00:04<00:00, 1110.50 examples/s]Tokenizing eval dataset:  18%|█▊        | 167/953 [00:02<00:11, 67.61 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7910/8564 [00:04<00:00, 1110.58 examples/s]Extracting prompt in train dataset:  91%|█████████ | 7790/8564 [00:04<00:00, 984.05 examples/s] Extracting prompt in train dataset:  92%|█████████▏| 7890/8564 [00:04<00:00, 1148.30 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8131/8564 [00:05<00:00, 1278.99 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7955/8564 [00:05<00:00, 1117.41 examples/s]Tokenizing eval dataset:  19%|█▊        | 178/953 [00:02<00:12, 64.45 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8081/8564 [00:05<00:00, 1286.81 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8120/8564 [00:05<00:00, 1233.15 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8346/8564 [00:05<00:00, 1418.53 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:02<00:11, 64.61 examples/s]Extracting prompt in train dataset:  96%|█████████▋| 8260/8564 [00:05<00:00, 1324.91 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8300/8564 [00:05<00:00, 1363.87 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 8560/8564 [00:05<00:00, 1565.35 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1629.71 examples/s]
Extracting prompt in train dataset:  99%|█████████▉| 8469/8564 [00:05<00:00, 1483.33 examples/s]Tokenizing eval dataset:  21%|██        | 196/953 [00:02<00:11, 68.15 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8510/8564 [00:05<00:00, 1495.11 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1602.28 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1578.38 examples/s]
Tokenizing eval dataset:  22%|██▏       | 207/953 [00:02<00:09, 76.56 examples/s]Tokenizing eval dataset:  23%|██▎       | 219/953 [00:02<00:10, 70.19 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:02<00:08, 89.18 examples/s]Tokenizing eval dataset:  27%|██▋       | 257/953 [00:03<00:06, 115.97 examples/s]Tokenizing eval dataset:  30%|██▉       | 283/953 [00:03<00:04, 147.39 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:03<00:04, 155.93 examples/s]Tokenizing eval dataset:  34%|███▍      | 328/953 [00:03<00:03, 176.36 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  37%|███▋      | 350/953 [00:03<00:03, 187.17 examples/s]Applying chat template to train dataset:   1%|          | 95/8564 [00:00<00:09, 938.68 examples/s]Applying chat template to train dataset:   2%|▏         | 200/8564 [00:00<00:08, 998.19 examples/s]Tokenizing eval dataset:  39%|███▉      | 375/953 [00:03<00:02, 193.15 examples/s]Tokenizing eval dataset:  42%|████▏     | 400/953 [00:03<00:02, 200.48 examples/s]Applying chat template to train dataset:   4%|▍         | 346/8564 [00:00<00:08, 980.28 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|▏         | 127/8564 [00:00<00:06, 1255.94 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  45%|████▌     | 430/953 [00:03<00:02, 189.73 examples/s]Applying chat template to train dataset:   5%|▌         | 468/8564 [00:00<00:09, 876.73 examples/s]Tokenizing eval dataset:  48%|████▊     | 456/953 [00:03<00:02, 206.32 examples/s]Applying chat template to train dataset:   3%|▎         | 265/8564 [00:00<00:06, 1277.98 examples/s]Applying chat template to train dataset:   1%|          | 68/8564 [00:00<00:16, 512.56 examples/s]Applying chat template to train dataset:   7%|▋         | 602/8564 [00:00<00:09, 881.31 examples/s]Applying chat template to train dataset:   2%|▏         | 164/8564 [00:00<00:11, 706.91 examples/s]Applying chat template to train dataset:   5%|▍         | 415/8564 [00:00<00:07, 1100.67 examples/s]Applying chat template to train dataset:   8%|▊         | 698/8564 [00:00<00:08, 877.11 examples/s]Tokenizing eval dataset:  51%|█████     | 483/953 [00:04<00:02, 184.91 examples/s]Applying chat template to train dataset:   3%|▎         | 261/8564 [00:00<00:10, 811.21 examples/s]Tokenizing eval dataset:  53%|█████▎    | 505/953 [00:04<00:02, 190.86 examples/s]Applying chat template to train dataset:   7%|▋         | 565/8564 [00:00<00:07, 1056.18 examples/s]Applying chat template to train dataset:  10%|▉         | 829/8564 [00:00<00:08, 872.77 examples/s]Applying chat template to train dataset:   4%|▍         | 353/8564 [00:00<00:09, 849.70 examples/s]Tokenizing eval dataset:  55%|█████▌    | 525/953 [00:04<00:02, 180.45 examples/s]Applying chat template to train dataset:  11%|█         | 919/8564 [00:01<00:08, 878.44 examples/s]Applying chat template to train dataset:   5%|▌         | 459/8564 [00:00<00:09, 888.93 examples/s]Applying chat template to train dataset:   8%|▊         | 708/8564 [00:00<00:07, 1015.68 examples/s]Applying chat template to train dataset:   7%|▋         | 594/8564 [00:00<00:07, 1036.91 examples/s]Tokenizing eval dataset:  58%|█████▊    | 556/953 [00:04<00:02, 187.36 examples/s]Applying chat template to train dataset:  12%|█▏        | 1047/8564 [00:01<00:08, 835.53 examples/s]Applying chat template to train dataset:  10%|▉         | 819/8564 [00:00<00:08, 915.61 examples/s] Applying chat template to train dataset:  13%|█▎        | 1142/8564 [00:01<00:08, 862.32 examples/s]Applying chat template to train dataset:   9%|▊         | 730/8564 [00:00<00:07, 982.91 examples/s] Applying chat template to train dataset:  11%|█         | 919/8564 [00:00<00:08, 935.51 examples/s]Tokenizing eval dataset:  61%|██████▏   | 586/953 [00:04<00:02, 181.24 examples/s]Applying chat template to train dataset:  12%|█▏        | 1016/8564 [00:01<00:08, 943.45 examples/s]Applying chat template to train dataset:  10%|▉         | 848/8564 [00:00<00:07, 1000.68 examples/s]Applying chat template to train dataset:  15%|█▍        | 1270/8564 [00:01<00:08, 838.97 examples/s]Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:04<00:01, 185.80 examples/s]Applying chat template to train dataset:  16%|█▌        | 1367/8564 [00:01<00:08, 869.14 examples/s]Applying chat template to train dataset:  13%|█▎        | 1153/8564 [00:01<00:07, 927.30 examples/s]Applying chat template to train dataset:  12%|█▏        | 991/8564 [00:01<00:07, 982.60 examples/s] Tokenizing eval dataset:  66%|██████▌   | 628/953 [00:04<00:01, 180.20 examples/s]Applying chat template to train dataset:  17%|█▋        | 1461/8564 [00:01<00:08, 886.37 examples/s]Applying chat template to train dataset:  15%|█▍        | 1250/8564 [00:01<00:07, 935.08 examples/s]Tokenizing eval dataset:  68%|██████▊   | 649/953 [00:05<00:01, 178.91 examples/s]Applying chat template to train dataset:  13%|█▎        | 1140/8564 [00:01<00:07, 974.74 examples/s]Applying chat template to train dataset:  18%|█▊        | 1557/8564 [00:01<00:07, 897.53 examples/s]Tokenizing eval dataset:  70%|███████   | 670/953 [00:05<00:01, 177.49 examples/s]Applying chat template to train dataset:  14%|█▍        | 1241/8564 [00:01<00:07, 982.13 examples/s]Applying chat template to train dataset:  16%|█▌        | 1384/8564 [00:01<00:07, 899.62 examples/s]Applying chat template to train dataset:  19%|█▉        | 1648/8564 [00:01<00:07, 900.11 examples/s]Tokenizing eval dataset:  73%|███████▎  | 691/953 [00:05<00:01, 184.26 examples/s]Applying chat template to train dataset:  16%|█▌        | 1345/8564 [00:01<00:07, 996.59 examples/s]Applying chat template to train dataset:  18%|█▊        | 1520/8564 [00:01<00:07, 899.68 examples/s]Applying chat template to train dataset:  21%|██        | 1788/8564 [00:02<00:07, 911.06 examples/s]Applying chat template to train dataset:  17%|█▋        | 1487/8564 [00:01<00:07, 975.23 examples/s]Tokenizing eval dataset:  76%|███████▌  | 720/953 [00:05<00:01, 178.69 examples/s]Applying chat template to train dataset:  22%|██▏       | 1881/8564 [00:02<00:07, 915.57 examples/s]Applying chat template to train dataset:  19%|█▉        | 1654/8564 [00:01<00:07, 895.62 examples/s]Applying chat template to train dataset:  23%|██▎       | 1973/8564 [00:02<00:07, 909.68 examples/s]Applying chat template to train dataset:  19%|█▉        | 1630/8564 [00:01<00:07, 948.64 examples/s]Applying chat template to train dataset:  21%|██        | 1760/8564 [00:01<00:07, 914.85 examples/s]Tokenizing eval dataset:  78%|███████▊  | 744/953 [00:05<00:01, 152.42 examples/s]Applying chat template to train dataset:  24%|██▍       | 2068/8564 [00:02<00:07, 916.85 examples/s]Applying chat template to train dataset:  22%|██▏       | 1858/8564 [00:01<00:07, 929.70 examples/s]Applying chat template to train dataset:  20%|██        | 1740/8564 [00:01<00:07, 958.96 examples/s]Tokenizing eval dataset:  80%|████████  | 765/953 [00:05<00:01, 164.02 examples/s]Applying chat template to train dataset:  25%|██▌       | 2160/8564 [00:02<00:07, 909.91 examples/s]Applying chat template to train dataset:  21%|██▏       | 1838/8564 [00:01<00:07, 940.14 examples/s]Applying chat template to train dataset:  23%|██▎       | 2001/8564 [00:02<00:07, 935.94 examples/s]Applying chat template to train dataset:  26%|██▋       | 2256/8564 [00:02<00:07, 869.73 examples/s]Applying chat template to train dataset:  23%|██▎       | 1982/8564 [00:02<00:06, 1067.17 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:05<00:01, 148.42 examples/s]Applying chat template to train dataset:  25%|██▍       | 2126/8564 [00:02<00:07, 899.70 examples/s]Applying chat template to train dataset:  27%|██▋       | 2347/8564 [00:02<00:07, 880.25 examples/s]Applying chat template to train dataset:  25%|██▍       | 2124/8564 [00:02<00:06, 1000.24 examples/s]Applying chat template to train dataset:  26%|██▌       | 2232/8564 [00:02<00:06, 936.87 examples/s]Applying chat template to train dataset:  29%|██▊       | 2452/8564 [00:02<00:06, 927.87 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:06<00:01, 139.30 examples/s]Applying chat template to train dataset:  26%|██▌       | 2236/8564 [00:02<00:06, 1007.82 examples/s]Tokenizing eval dataset:  86%|████████▋ | 824/953 [00:06<00:00, 146.77 examples/s]Applying chat template to train dataset:  28%|██▊       | 2366/8564 [00:02<00:06, 921.14 examples/s]Applying chat template to train dataset:  30%|███       | 2584/8564 [00:02<00:06, 882.45 examples/s]Applying chat template to train dataset:  27%|██▋       | 2346/8564 [00:02<00:06, 1030.11 examples/s]Tokenizing eval dataset:  88%|████████▊ | 840/953 [00:06<00:00, 148.36 examples/s]Applying chat template to train dataset:  29%|██▊       | 2460/8564 [00:02<00:06, 923.89 examples/s]Applying chat template to train dataset:  31%|███▏      | 2680/8564 [00:03<00:06, 896.04 examples/s]Applying chat template to train dataset:  29%|██▉       | 2500/8564 [00:02<00:05, 1027.19 examples/s]Applying chat template to train dataset:  32%|███▏      | 2777/8564 [00:03<00:06, 914.72 examples/s]Tokenizing eval dataset:  90%|█████████ | 861/953 [00:06<00:00, 141.26 examples/s]Applying chat template to train dataset:  30%|███       | 2598/8564 [00:02<00:06, 894.02 examples/s]Applying chat template to train dataset:  34%|███▎      | 2871/8564 [00:03<00:06, 920.45 examples/s]Tokenizing eval dataset:  92%|█████████▏| 880/953 [00:06<00:00, 146.91 examples/s]Applying chat template to train dataset:  31%|███       | 2650/8564 [00:02<00:06, 985.31 examples/s] Applying chat template to train dataset:  32%|███▏      | 2701/8564 [00:02<00:06, 877.17 examples/s]Applying chat template to train dataset:  32%|███▏      | 2758/8564 [00:02<00:05, 1007.06 examples/s]Tokenizing eval dataset:  94%|█████████▍| 896/953 [00:06<00:00, 147.76 examples/s]Applying chat template to train dataset:  35%|███▌      | 3006/8564 [00:03<00:06, 911.38 examples/s]Applying chat template to train dataset:  33%|███▎      | 2794/8564 [00:02<00:06, 879.30 examples/s]Applying chat template to train dataset:  34%|███▍      | 2894/8564 [00:03<00:06, 908.72 examples/s]Applying chat template to train dataset:  34%|███▍      | 2905/8564 [00:03<00:05, 978.35 examples/s] Tokenizing eval dataset:  96%|█████████▌| 915/953 [00:06<00:00, 137.73 examples/s]Applying chat template to train dataset:  37%|███▋      | 3149/8564 [00:03<00:07, 754.10 examples/s]Applying chat template to train dataset:  35%|███▌      | 3015/8564 [00:03<00:05, 963.74 examples/s]Tokenizing eval dataset:  99%|█████████▊| 940/953 [00:06<00:00, 157.50 examples/s]Applying chat template to train dataset:  35%|███▌      | 3040/8564 [00:03<00:06, 902.80 examples/s]Applying chat template to train dataset:  38%|███▊      | 3258/8564 [00:03<00:06, 824.39 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:07<00:00, 134.42 examples/s]
Applying chat template to train dataset:  37%|███▋      | 3150/8564 [00:03<00:07, 773.05 examples/s]Applying chat template to train dataset:  37%|███▋      | 3127/8564 [00:03<00:07, 715.23 examples/s]Applying chat template to train dataset:  39%|███▉      | 3371/8564 [00:03<00:06, 745.09 examples/s]Applying chat template to train dataset:  38%|███▊      | 3247/8564 [00:03<00:06, 816.27 examples/s]Applying chat template to train dataset:  40%|████      | 3459/8564 [00:04<00:06, 730.66 examples/s]Applying chat template to train dataset:  39%|███▉      | 3344/8564 [00:03<00:06, 852.77 examples/s]Applying chat template to train dataset:  38%|███▊      | 3229/8564 [00:03<00:07, 692.19 examples/s]Applying chat template to train dataset:  40%|████      | 3440/8564 [00:03<00:06, 848.66 examples/s]Applying chat template to train dataset:  42%|████▏     | 3574/8564 [00:04<00:06, 730.04 examples/s]Applying chat template to train dataset:  39%|███▉      | 3342/8564 [00:03<00:07, 678.57 examples/s]Applying chat template to train dataset:  41%|████▏     | 3541/8564 [00:03<00:05, 865.83 examples/s]Applying chat template to train dataset:  40%|████      | 3461/8564 [00:03<00:07, 707.84 examples/s]Applying chat template to train dataset:  43%|████▎     | 3666/8564 [00:04<00:07, 632.93 examples/s]Applying chat template to train dataset:  43%|████▎     | 3644/8564 [00:03<00:05, 885.20 examples/s]Applying chat template to train dataset:  44%|████▍     | 3749/8564 [00:04<00:05, 816.67 examples/s]Applying chat template to train dataset:  42%|████▏     | 3568/8564 [00:04<00:07, 686.17 examples/s]Applying chat template to train dataset:  44%|████▍     | 3759/8564 [00:04<00:07, 615.33 examples/s]Applying chat template to train dataset:  43%|████▎     | 3640/8564 [00:04<00:07, 684.42 examples/s]Applying chat template to train dataset:  45%|████▌     | 3861/8564 [00:04<00:06, 683.65 examples/s]Applying chat template to train dataset:  45%|████▌     | 3876/8564 [00:04<00:05, 794.72 examples/s]Applying chat template to train dataset:  43%|████▎     | 3718/8564 [00:04<00:07, 691.37 examples/s]Applying chat template to train dataset:  46%|████▌     | 3960/8564 [00:04<00:06, 749.42 examples/s]Applying chat template to train dataset:  47%|████▋     | 3987/8564 [00:04<00:05, 839.10 examples/s]Applying chat template to train dataset:  47%|████▋     | 4049/8564 [00:04<00:05, 781.80 examples/s]Applying chat template to train dataset:  45%|████▍     | 3840/8564 [00:04<00:06, 719.65 examples/s]Applying chat template to train dataset:  48%|████▊     | 4091/8564 [00:04<00:05, 795.12 examples/s]Applying chat template to train dataset:  49%|████▉     | 4181/8564 [00:05<00:05, 813.36 examples/s]Applying chat template to train dataset:  46%|████▌     | 3950/8564 [00:04<00:06, 680.45 examples/s]Applying chat template to train dataset:  49%|████▉     | 4226/8564 [00:04<00:05, 772.81 examples/s]Applying chat template to train dataset:  50%|█████     | 4299/8564 [00:05<00:05, 802.76 examples/s]Applying chat template to train dataset:  50%|█████     | 4315/8564 [00:04<00:05, 779.16 examples/s]Applying chat template to train dataset:  51%|█████     | 4389/8564 [00:05<00:05, 825.39 examples/s]Applying chat template to train dataset:  47%|████▋     | 4051/8564 [00:04<00:06, 652.37 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4486/8564 [00:05<00:04, 860.98 examples/s]Applying chat template to train dataset:  48%|████▊     | 4132/8564 [00:04<00:06, 661.08 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4575/8564 [00:05<00:04, 854.26 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4445/8564 [00:05<00:05, 715.38 examples/s]Applying chat template to train dataset:  49%|████▉     | 4221/8564 [00:05<00:06, 662.13 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4666/8564 [00:05<00:04, 867.52 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4524/8564 [00:05<00:05, 690.62 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4762/8564 [00:05<00:04, 890.32 examples/s]Applying chat template to train dataset:  50%|█████     | 4308/8564 [00:05<00:07, 605.27 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4627/8564 [00:05<00:05, 693.74 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4863/8564 [00:05<00:04, 905.52 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4408/8564 [00:05<00:06, 691.14 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4978/8564 [00:05<00:03, 941.88 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4509/8564 [00:05<00:05, 748.47 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4730/8564 [00:05<00:05, 664.44 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5080/8564 [00:06<00:03, 928.25 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4631/8564 [00:05<00:04, 815.45 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4802/8564 [00:05<00:05, 635.87 examples/s]Applying chat template to train dataset:  61%|██████    | 5211/8564 [00:06<00:03, 996.58 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4735/8564 [00:05<00:04, 865.58 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4888/8564 [00:05<00:05, 662.56 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5315/8564 [00:06<00:03, 979.95 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4847/8564 [00:05<00:04, 914.86 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4958/8564 [00:05<00:05, 670.19 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5430/8564 [00:06<00:03, 1025.99 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4949/8564 [00:05<00:03, 942.64 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5535/8564 [00:06<00:03, 990.85 examples/s] Applying chat template to train dataset:  59%|█████▉    | 5065/8564 [00:05<00:03, 966.25 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5068/8564 [00:06<00:05, 604.90 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5640/8564 [00:06<00:02, 984.80 examples/s]Applying chat template to train dataset:  60%|██████    | 5174/8564 [00:06<00:03, 970.00 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5272/8564 [00:06<00:03, 970.40 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5747/8564 [00:06<00:02, 962.93 examples/s]Applying chat template to train dataset:  60%|██████    | 5173/8564 [00:06<00:05, 576.90 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5370/8564 [00:06<00:03, 972.04 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5286/8564 [00:06<00:05, 618.26 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5860/8564 [00:06<00:03, 796.36 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5517/8564 [00:06<00:03, 943.03 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5374/8564 [00:06<00:04, 671.70 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5960/8564 [00:07<00:03, 730.66 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5635/8564 [00:06<00:03, 966.22 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5460/8564 [00:06<00:04, 678.21 examples/s]Applying chat template to train dataset:  71%|███████   | 6042/8564 [00:07<00:03, 716.46 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5561/8564 [00:06<00:04, 730.73 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5770/8564 [00:06<00:03, 841.46 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6149/8564 [00:07<00:03, 782.40 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5674/8564 [00:06<00:03, 824.47 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6248/8564 [00:07<00:02, 833.49 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5787/8564 [00:06<00:03, 901.78 examples/s]Applying chat template to train dataset:  69%|██████▊   | 5872/8564 [00:06<00:03, 748.30 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6354/8564 [00:07<00:02, 891.66 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5892/8564 [00:07<00:02, 940.81 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5964/8564 [00:07<00:03, 743.01 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6455/8564 [00:07<00:02, 922.81 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5990/8564 [00:07<00:02, 924.04 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6122/8564 [00:07<00:02, 985.23 examples/s]Applying chat template to train dataset:  71%|███████   | 6077/8564 [00:07<00:03, 724.43 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6578/8564 [00:07<00:02, 749.79 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6240/8564 [00:07<00:02, 1034.29 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6170/8564 [00:07<00:03, 742.61 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6699/8564 [00:07<00:02, 835.01 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6395/8564 [00:07<00:02, 1030.39 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6258/8564 [00:07<00:03, 722.05 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6798/8564 [00:07<00:02, 871.22 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6360/8564 [00:07<00:02, 777.34 examples/s]Applying chat template to train dataset:  81%|████████  | 6903/8564 [00:08<00:01, 916.42 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6557/8564 [00:07<00:02, 897.87 examples/s] Applying chat template to train dataset:  75%|███████▌  | 6457/8564 [00:07<00:02, 710.62 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7042/8564 [00:08<00:01, 918.81 examples/s]Applying chat template to train dataset:  84%|████████▎ | 7169/8564 [00:08<00:01, 1005.60 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6711/8564 [00:07<00:02, 892.40 examples/s]Applying chat template to train dataset:  76%|███████▋  | 6549/8564 [00:07<00:02, 682.73 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7292/8564 [00:08<00:01, 1036.21 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6838/8564 [00:08<00:01, 951.94 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6638/8564 [00:08<00:03, 631.45 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7449/8564 [00:08<00:01, 1038.22 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6720/8564 [00:08<00:02, 659.57 examples/s]Applying chat template to train dataset:  82%|████████▏ | 6987/8564 [00:08<00:01, 825.84 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7570/8564 [00:08<00:00, 1079.40 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6831/8564 [00:08<00:02, 733.07 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7694/8564 [00:08<00:00, 1088.28 examples/s]Applying chat template to train dataset:  81%|████████  | 6923/8564 [00:08<00:02, 754.18 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7113/8564 [00:08<00:01, 748.79 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7009/8564 [00:08<00:01, 779.68 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7228/8564 [00:08<00:01, 731.72 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7132/8564 [00:08<00:01, 746.61 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7844/8564 [00:09<00:01, 680.87 examples/s] Applying chat template to train dataset:  85%|████████▌ | 7315/8564 [00:08<00:01, 668.42 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7220/8564 [00:08<00:01, 726.35 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7943/8564 [00:09<00:00, 735.30 examples/s]Applying chat template to train dataset:  86%|████████▋ | 7406/8564 [00:08<00:01, 702.17 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8042/8564 [00:09<00:00, 785.44 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7324/8564 [00:08<00:01, 718.41 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7496/8564 [00:09<00:01, 712.48 examples/s]Applying chat template to train dataset:  86%|████████▋ | 7397/8564 [00:09<00:01, 720.60 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8178/8564 [00:09<00:00, 800.14 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7611/8564 [00:09<00:01, 681.37 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8287/8564 [00:09<00:00, 863.56 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7493/8564 [00:09<00:01, 680.38 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7700/8564 [00:09<00:01, 704.58 examples/s]Applying chat template to train dataset:  99%|█████████▊| 8445/8564 [00:09<00:00, 922.55 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7563/8564 [00:09<00:01, 655.82 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8547/8564 [00:09<00:00, 942.89 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7662/8564 [00:09<00:01, 721.69 examples/s]Applying chat template to train dataset:  91%|█████████ | 7800/8564 [00:09<00:01, 623.45 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:09<00:00, 858.71 examples/s]
Applying chat template to train dataset:  90%|█████████ | 7743/8564 [00:09<00:01, 710.94 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7904/8564 [00:09<00:00, 709.53 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7838/8564 [00:09<00:01, 625.67 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8050/8564 [00:09<00:00, 732.27 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7917/8564 [00:09<00:01, 631.54 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8142/8564 [00:10<00:00, 708.68 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8035/8564 [00:09<00:00, 762.03 examples/s]Applying chat template to train dataset:  96%|█████████▋| 8244/8564 [00:10<00:00, 775.76 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8135/8564 [00:10<00:00, 816.94 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8346/8564 [00:10<00:00, 828.26 examples/s]Applying chat template to train dataset:  96%|█████████▋| 8250/8564 [00:10<00:00, 902.43 examples/s]Applying chat template to train dataset:  99%|█████████▊| 8455/8564 [00:10<00:00, 891.28 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8560/8564 [00:10<00:00, 930.99 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 821.60 examples/s]
Applying chat template to train dataset:  98%|█████████▊| 8382/8564 [00:10<00:00, 822.99 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8489/8564 [00:10<00:00, 780.40 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 807.93 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 1/8564 [00:00<14:19,  9.97 examples/s]Tokenizing train dataset:   0%|          | 10/8564 [00:00<02:45, 51.70 examples/s]Tokenizing train dataset:   0%|          | 35/8564 [00:00<01:11, 118.84 examples/s]Tokenizing train dataset:   1%|          | 50/8564 [00:00<01:23, 101.80 examples/s]Tokenizing train dataset:   1%|          | 62/8564 [00:00<01:22, 102.58 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 74/8564 [00:00<01:21, 104.10 examples/s]Tokenizing train dataset:   0%|          | 14/8564 [00:00<01:14, 115.08 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 85/8564 [00:00<01:21, 103.81 examples/s]Tokenizing train dataset:   0%|          | 29/8564 [00:00<01:11, 119.00 examples/s]Tokenizing train dataset:   0%|          | 19/8564 [00:00<00:49, 173.92 examples/s]Tokenizing train dataset:   1%|          | 96/8564 [00:01<01:29, 94.95 examples/s] Tokenizing train dataset:   0%|          | 38/8564 [00:00<00:47, 178.41 examples/s]Tokenizing train dataset:   1%|          | 107/8564 [00:01<01:28, 95.86 examples/s]Tokenizing train dataset:   0%|          | 41/8564 [00:00<01:43, 82.01 examples/s] Tokenizing train dataset:   1%|▏         | 117/8564 [00:01<01:29, 94.80 examples/s]Tokenizing train dataset:   1%|          | 56/8564 [00:00<01:49, 77.63 examples/s]Tokenizing train dataset:   1%|▏         | 127/8564 [00:01<01:31, 92.32 examples/s]Tokenizing train dataset:   1%|          | 60/8564 [00:00<01:23, 102.14 examples/s]Tokenizing train dataset:   2%|▏         | 140/8564 [00:01<01:23, 101.21 examples/s]Tokenizing train dataset:   1%|          | 69/8564 [00:00<01:38, 85.94 examples/s]Tokenizing train dataset:   1%|          | 81/8564 [00:00<01:30, 93.46 examples/s]Tokenizing train dataset:   2%|▏         | 153/8564 [00:01<01:21, 103.26 examples/s]Tokenizing train dataset:   1%|          | 78/8564 [00:00<01:31, 92.43 examples/s] Tokenizing train dataset:   1%|          | 96/8564 [00:01<01:33, 90.74 examples/s]Tokenizing train dataset:   2%|▏         | 166/8564 [00:01<01:38, 85.57 examples/s] Tokenizing train dataset:   1%|          | 90/8564 [00:00<01:44, 80.92 examples/s]Tokenizing train dataset:   1%|          | 107/8564 [00:01<01:32, 91.47 examples/s]Tokenizing train dataset:   1%|▏         | 118/8564 [00:01<01:33, 90.41 examples/s]Tokenizing train dataset:   1%|          | 102/8564 [00:01<01:54, 74.03 examples/s]Tokenizing train dataset:   2%|▏         | 181/8564 [00:02<01:50, 75.54 examples/s]Tokenizing train dataset:   2%|▏         | 192/8564 [00:02<01:45, 79.06 examples/s]Tokenizing train dataset:   2%|▏         | 134/8564 [00:01<01:31, 92.01 examples/s]Tokenizing train dataset:   1%|▏         | 114/8564 [00:01<01:59, 70.50 examples/s]Tokenizing train dataset:   2%|▏         | 147/8564 [00:01<01:26, 97.40 examples/s]Tokenizing train dataset:   2%|▏         | 201/8564 [00:02<01:51, 74.92 examples/s]Tokenizing train dataset:   1%|▏         | 127/8564 [00:01<01:59, 70.48 examples/s]Tokenizing train dataset:   2%|▏         | 212/8564 [00:02<01:49, 76.29 examples/s]Tokenizing train dataset:   2%|▏         | 160/8564 [00:01<01:34, 89.25 examples/s]Tokenizing train dataset:   2%|▏         | 140/8564 [00:01<01:45, 79.50 examples/s]Tokenizing train dataset:   3%|▎         | 222/8564 [00:02<01:49, 76.46 examples/s]Tokenizing train dataset:   2%|▏         | 154/8564 [00:01<01:34, 88.66 examples/s]Tokenizing train dataset:   2%|▏         | 173/8564 [00:02<01:52, 74.30 examples/s]Tokenizing train dataset:   3%|▎         | 236/8564 [00:02<01:40, 83.14 examples/s]Tokenizing train dataset:   2%|▏         | 165/8564 [00:01<01:44, 80.27 examples/s]Tokenizing train dataset:   2%|▏         | 188/8564 [00:02<01:38, 84.95 examples/s]Tokenizing train dataset:   3%|▎         | 248/8564 [00:02<01:46, 77.73 examples/s]Tokenizing train dataset:   2%|▏         | 175/8564 [00:02<01:42, 81.91 examples/s]Tokenizing train dataset:   2%|▏         | 198/8564 [00:02<01:46, 78.53 examples/s]Tokenizing train dataset:   3%|▎         | 258/8564 [00:02<01:45, 78.53 examples/s]Tokenizing train dataset:   2%|▏         | 186/8564 [00:02<01:39, 83.79 examples/s]Tokenizing train dataset:   3%|▎         | 273/8564 [00:03<01:27, 94.32 examples/s]Tokenizing train dataset:   2%|▏         | 211/8564 [00:02<01:47, 77.35 examples/s]Tokenizing train dataset:   2%|▏         | 198/8564 [00:02<01:31, 91.32 examples/s]Tokenizing train dataset:   3%|▎         | 285/8564 [00:03<01:26, 96.04 examples/s]Tokenizing train dataset:   2%|▏         | 210/8564 [00:02<01:28, 94.14 examples/s]Tokenizing train dataset:   3%|▎         | 224/8564 [00:02<01:50, 75.52 examples/s]Tokenizing train dataset:   3%|▎         | 299/8564 [00:03<01:19, 104.34 examples/s]Tokenizing train dataset:   3%|▎         | 220/8564 [00:02<01:29, 93.44 examples/s]Tokenizing train dataset:   4%|▎         | 310/8564 [00:03<01:19, 103.26 examples/s]Tokenizing train dataset:   3%|▎         | 234/8564 [00:02<01:21, 102.52 examples/s]Tokenizing train dataset:   3%|▎         | 237/8564 [00:02<01:49, 76.09 examples/s]Tokenizing train dataset:   4%|▍         | 323/8564 [00:03<01:19, 103.86 examples/s]Tokenizing train dataset:   3%|▎         | 245/8564 [00:02<01:51, 74.62 examples/s]Tokenizing train dataset:   3%|▎         | 247/8564 [00:02<01:31, 90.80 examples/s] Tokenizing train dataset:   4%|▍         | 340/8564 [00:03<01:21, 101.53 examples/s]Tokenizing train dataset:   3%|▎         | 256/8564 [00:03<01:52, 73.80 examples/s]Tokenizing train dataset:   3%|▎         | 258/8564 [00:02<01:28, 93.37 examples/s]Tokenizing train dataset:   3%|▎         | 274/8564 [00:03<01:19, 104.51 examples/s]Tokenizing train dataset:   3%|▎         | 267/8564 [00:03<01:53, 73.29 examples/s]Tokenizing train dataset:   4%|▍         | 357/8564 [00:03<01:31, 89.37 examples/s] Tokenizing train dataset:   3%|▎         | 287/8564 [00:03<01:16, 107.78 examples/s]Tokenizing train dataset:   3%|▎         | 277/8564 [00:03<01:52, 73.71 examples/s]Tokenizing train dataset:   4%|▍         | 367/8564 [00:04<01:32, 88.45 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:03<01:38, 84.43 examples/s]Tokenizing train dataset:   4%|▎         | 300/8564 [00:03<01:27, 94.39 examples/s] Tokenizing train dataset:   4%|▍         | 384/8564 [00:04<01:18, 104.15 examples/s]Tokenizing train dataset:   5%|▍         | 397/8564 [00:04<01:19, 102.47 examples/s]Tokenizing train dataset:   4%|▎         | 300/8564 [00:03<01:53, 73.02 examples/s]Tokenizing train dataset:   4%|▎         | 312/8564 [00:03<01:43, 79.89 examples/s]Tokenizing train dataset:   4%|▎         | 312/8564 [00:03<01:43, 79.74 examples/s]Tokenizing train dataset:   5%|▍         | 410/8564 [00:04<01:22, 99.40 examples/s] Tokenizing train dataset:   4%|▍         | 325/8564 [00:03<01:35, 86.58 examples/s]Tokenizing train dataset:   4%|▍         | 326/8564 [00:03<01:31, 90.38 examples/s]Tokenizing train dataset:   4%|▍         | 336/8564 [00:03<01:29, 91.43 examples/s]Tokenizing train dataset:   4%|▍         | 337/8564 [00:04<01:30, 91.20 examples/s]Tokenizing train dataset:   5%|▍         | 426/8564 [00:04<01:33, 87.40 examples/s]Tokenizing train dataset:   4%|▍         | 346/8564 [00:03<01:32, 88.97 examples/s]Tokenizing train dataset:   4%|▍         | 347/8564 [00:04<01:29, 92.12 examples/s]Tokenizing train dataset:   4%|▍         | 359/8564 [00:03<01:23, 98.05 examples/s]Tokenizing train dataset:   5%|▌         | 436/8564 [00:04<01:43, 78.26 examples/s]Tokenizing train dataset:   4%|▍         | 360/8564 [00:04<01:26, 94.44 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:04<01:25, 96.38 examples/s]Tokenizing train dataset:   4%|▍         | 372/8564 [00:04<01:23, 98.48 examples/s]Tokenizing train dataset:   4%|▍         | 385/8564 [00:04<01:17, 105.26 examples/s]Tokenizing train dataset:   5%|▌         | 448/8564 [00:05<01:58, 68.77 examples/s]Tokenizing train dataset:   5%|▍         | 387/8564 [00:04<01:16, 106.24 examples/s]Tokenizing train dataset:   5%|▌         | 457/8564 [00:05<01:58, 68.62 examples/s]Tokenizing train dataset:   5%|▍         | 400/8564 [00:04<01:22, 98.68 examples/s] Tokenizing train dataset:   5%|▍         | 401/8564 [00:04<01:24, 96.66 examples/s] Tokenizing train dataset:   5%|▍         | 411/8564 [00:04<01:20, 100.82 examples/s]Tokenizing train dataset:   5%|▌         | 465/8564 [00:05<01:59, 67.55 examples/s]Tokenizing train dataset:   5%|▍         | 414/8564 [00:04<01:18, 103.88 examples/s]Tokenizing train dataset:   5%|▍         | 422/8564 [00:04<01:22, 99.24 examples/s] Tokenizing train dataset:   6%|▌         | 474/8564 [00:05<01:57, 68.84 examples/s]Tokenizing train dataset:   5%|▍         | 426/8564 [00:04<01:18, 103.03 examples/s]Tokenizing train dataset:   5%|▌         | 433/8564 [00:04<01:20, 101.17 examples/s]Tokenizing train dataset:   5%|▌         | 439/8564 [00:05<01:19, 101.80 examples/s]Tokenizing train dataset:   6%|▌         | 485/8564 [00:05<02:12, 61.14 examples/s]Tokenizing train dataset:   5%|▌         | 446/8564 [00:04<01:31, 88.97 examples/s] Tokenizing train dataset:   5%|▌         | 454/8564 [00:05<01:23, 96.67 examples/s] Tokenizing train dataset:   6%|▌         | 497/8564 [00:05<02:08, 62.99 examples/s]Tokenizing train dataset:   5%|▌         | 456/8564 [00:05<01:36, 83.73 examples/s]Tokenizing train dataset:   5%|▌         | 466/8564 [00:05<01:20, 100.15 examples/s]Tokenizing train dataset:   6%|▌         | 505/8564 [00:06<02:09, 62.09 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:05<01:36, 83.56 examples/s]Tokenizing train dataset:   6%|▌         | 478/8564 [00:05<01:18, 103.48 examples/s]Tokenizing train dataset:   6%|▌         | 517/8564 [00:06<01:52, 71.24 examples/s]Tokenizing train dataset:   6%|▌         | 491/8564 [00:05<01:25, 94.41 examples/s] Tokenizing train dataset:   6%|▌         | 530/8564 [00:06<01:39, 81.08 examples/s]Tokenizing train dataset:   6%|▌         | 480/8564 [00:05<02:02, 65.91 examples/s]Tokenizing train dataset:   6%|▌         | 502/8564 [00:05<01:25, 93.88 examples/s]Tokenizing train dataset:   6%|▋         | 543/8564 [00:06<01:28, 90.62 examples/s]Tokenizing train dataset:   6%|▌         | 490/8564 [00:05<01:56, 69.49 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:05<01:27, 92.32 examples/s]Tokenizing train dataset:   6%|▌         | 501/8564 [00:05<01:44, 77.02 examples/s]Tokenizing train dataset:   7%|▋         | 557/8564 [00:06<01:37, 81.73 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:05<01:39, 81.06 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:05<01:37, 82.49 examples/s]Tokenizing train dataset:   7%|▋         | 569/8564 [00:06<01:32, 86.49 examples/s]Tokenizing train dataset:   6%|▋         | 537/8564 [00:06<01:26, 92.66 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:05<01:34, 84.95 examples/s]Tokenizing train dataset:   7%|▋         | 580/8564 [00:06<01:31, 87.40 examples/s]Tokenizing train dataset:   6%|▋         | 549/8564 [00:06<01:23, 95.58 examples/s]Tokenizing train dataset:   6%|▌         | 533/8564 [00:06<01:39, 80.74 examples/s]Tokenizing train dataset:   7%|▋         | 592/8564 [00:06<01:24, 94.02 examples/s]Tokenizing train dataset:   7%|▋         | 559/8564 [00:06<01:23, 96.30 examples/s]Tokenizing train dataset:   6%|▋         | 545/8564 [00:06<01:38, 81.66 examples/s]Tokenizing train dataset:   7%|▋         | 605/8564 [00:07<01:29, 88.48 examples/s]Tokenizing train dataset:   7%|▋         | 570/8564 [00:06<01:30, 88.58 examples/s]Tokenizing train dataset:   7%|▋         | 620/8564 [00:07<01:20, 98.97 examples/s]Tokenizing train dataset:   7%|▋         | 580/8564 [00:06<01:31, 87.70 examples/s]Tokenizing train dataset:   6%|▋         | 554/8564 [00:06<02:00, 66.33 examples/s]Tokenizing train dataset:   7%|▋         | 638/8564 [00:07<01:09, 113.82 examples/s]Tokenizing train dataset:   7%|▋         | 563/8564 [00:06<01:53, 70.34 examples/s]Tokenizing train dataset:   7%|▋         | 593/8564 [00:06<01:35, 83.50 examples/s]Tokenizing train dataset:   8%|▊         | 650/8564 [00:07<01:10, 112.97 examples/s]Tokenizing train dataset:   7%|▋         | 571/8564 [00:06<02:00, 66.11 examples/s]Tokenizing train dataset:   8%|▊         | 666/8564 [00:07<01:13, 107.30 examples/s]Tokenizing train dataset:   7%|▋         | 603/8564 [00:06<01:48, 73.71 examples/s]Tokenizing train dataset:   7%|▋         | 580/8564 [00:06<02:05, 63.63 examples/s]Tokenizing train dataset:   8%|▊         | 680/8564 [00:07<01:12, 109.38 examples/s]Tokenizing train dataset:   7%|▋         | 613/8564 [00:07<01:47, 73.65 examples/s]Tokenizing train dataset:   7%|▋         | 590/8564 [00:06<01:54, 69.53 examples/s]Tokenizing train dataset:   7%|▋         | 623/8564 [00:07<01:45, 75.57 examples/s]Tokenizing train dataset:   7%|▋         | 600/8564 [00:07<01:48, 73.35 examples/s]Tokenizing train dataset:   8%|▊         | 693/8564 [00:07<01:31, 86.37 examples/s] Tokenizing train dataset:   7%|▋         | 637/8564 [00:07<01:38, 80.24 examples/s]Tokenizing train dataset:   7%|▋         | 614/8564 [00:07<01:34, 84.38 examples/s]Tokenizing train dataset:   7%|▋         | 630/8564 [00:07<01:20, 99.14 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:08<01:45, 74.60 examples/s]Tokenizing train dataset:   8%|▊         | 650/8564 [00:07<01:47, 73.75 examples/s]Tokenizing train dataset:   7%|▋         | 641/8564 [00:07<01:18, 100.74 examples/s]Tokenizing train dataset:   8%|▊         | 661/8564 [00:07<01:41, 77.72 examples/s]Tokenizing train dataset:   8%|▊         | 654/8564 [00:07<01:15, 104.96 examples/s]Tokenizing train dataset:   8%|▊         | 721/8564 [00:08<01:46, 73.69 examples/s]Tokenizing train dataset:   8%|▊         | 673/8564 [00:07<01:32, 84.94 examples/s]Tokenizing train dataset:   9%|▊         | 732/8564 [00:08<01:38, 79.38 examples/s]Tokenizing train dataset:   8%|▊         | 665/8564 [00:07<01:29, 88.62 examples/s] Tokenizing train dataset:   8%|▊         | 686/8564 [00:07<01:26, 91.54 examples/s]Tokenizing train dataset:   9%|▊         | 741/8564 [00:08<01:42, 76.60 examples/s]Tokenizing train dataset:   8%|▊         | 696/8564 [00:08<01:30, 87.33 examples/s]Tokenizing train dataset:   8%|▊         | 676/8564 [00:07<01:37, 81.01 examples/s]Tokenizing train dataset:   9%|▉         | 750/8564 [00:08<01:41, 77.16 examples/s]Tokenizing train dataset:   8%|▊         | 685/8564 [00:07<01:39, 79.36 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:08<01:30, 86.65 examples/s]Tokenizing train dataset:   9%|▉         | 759/8564 [00:08<01:51, 70.28 examples/s]Tokenizing train dataset:   8%|▊         | 721/8564 [00:08<01:21, 96.41 examples/s]Tokenizing train dataset:   9%|▉         | 768/8564 [00:09<01:51, 70.01 examples/s]Tokenizing train dataset:   9%|▊         | 738/8564 [00:08<01:10, 110.31 examples/s]Tokenizing train dataset:   8%|▊         | 697/8564 [00:08<02:05, 62.65 examples/s]Tokenizing train dataset:   9%|▉         | 754/8564 [00:08<01:12, 108.00 examples/s]Tokenizing train dataset:   9%|▉         | 778/8564 [00:09<02:00, 64.50 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:08<02:06, 62.20 examples/s]Tokenizing train dataset:   9%|▉         | 785/8564 [00:09<02:01, 64.07 examples/s]Tokenizing train dataset:   9%|▉         | 770/8564 [00:08<01:15, 102.74 examples/s]Tokenizing train dataset:   8%|▊         | 716/8564 [00:08<02:04, 62.88 examples/s]Tokenizing train dataset:   9%|▊         | 728/8564 [00:08<01:44, 74.65 examples/s]Tokenizing train dataset:   9%|▉         | 795/8564 [00:09<02:10, 59.75 examples/s]Tokenizing train dataset:   9%|▉         | 785/8564 [00:08<01:19, 97.93 examples/s] Tokenizing train dataset:   9%|▊         | 738/8564 [00:08<01:41, 77.21 examples/s]Tokenizing train dataset:   9%|▉         | 796/8564 [00:08<01:21, 95.07 examples/s]Tokenizing train dataset:   9%|▉         | 804/8564 [00:09<02:14, 57.78 examples/s]Tokenizing train dataset:   9%|▊         | 748/8564 [00:08<01:44, 74.91 examples/s]Tokenizing train dataset:   9%|▉         | 807/8564 [00:09<01:21, 94.92 examples/s]Tokenizing train dataset:  10%|▉         | 818/8564 [00:09<02:02, 63.30 examples/s]Tokenizing train dataset:   9%|▉         | 756/8564 [00:09<01:49, 71.52 examples/s]Tokenizing train dataset:  10%|▉         | 819/8564 [00:09<01:17, 99.75 examples/s]Tokenizing train dataset:  10%|▉         | 827/8564 [00:10<02:15, 56.94 examples/s]Tokenizing train dataset:  10%|▉         | 833/8564 [00:09<01:22, 93.31 examples/s]Tokenizing train dataset:   9%|▉         | 768/8564 [00:09<01:55, 67.28 examples/s]Tokenizing train dataset:  10%|▉         | 834/8564 [00:10<02:11, 58.68 examples/s]Tokenizing train dataset:  10%|▉         | 845/8564 [00:09<01:21, 95.21 examples/s]Tokenizing train dataset:   9%|▉         | 778/8564 [00:09<02:01, 64.27 examples/s]Tokenizing train dataset:  10%|▉         | 842/8564 [00:10<02:08, 59.94 examples/s]Tokenizing train dataset:  10%|█         | 862/8564 [00:09<01:21, 94.17 examples/s]Tokenizing train dataset:   9%|▉         | 788/8564 [00:09<01:55, 67.04 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:10<02:12, 58.27 examples/s]Tokenizing train dataset:  10%|█         | 873/8564 [00:09<01:31, 84.04 examples/s]Tokenizing train dataset:   9%|▉         | 798/8564 [00:09<02:01, 63.71 examples/s]Tokenizing train dataset:  10%|█         | 862/8564 [00:10<01:54, 67.43 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:09<01:27, 88.22 examples/s]Tokenizing train dataset:   9%|▉         | 807/8564 [00:09<01:53, 68.27 examples/s]Tokenizing train dataset:  10%|█         | 874/8564 [00:10<01:41, 75.84 examples/s]Tokenizing train dataset:  11%|█         | 902/8564 [00:10<01:14, 102.67 examples/s]Tokenizing train dataset:  10%|▉         | 815/8564 [00:09<01:51, 69.38 examples/s]Tokenizing train dataset:  10%|█         | 884/8564 [00:10<01:47, 71.66 examples/s]Tokenizing train dataset:  10%|▉         | 825/8564 [00:10<01:50, 70.00 examples/s]Tokenizing train dataset:  11%|█         | 917/8564 [00:10<01:22, 92.69 examples/s] Tokenizing train dataset:  10%|█         | 899/8564 [00:11<01:34, 81.00 examples/s]Tokenizing train dataset:  10%|▉         | 834/8564 [00:10<01:45, 73.45 examples/s]Tokenizing train dataset:  11%|█         | 909/8564 [00:11<01:30, 84.50 examples/s]Tokenizing train dataset:  10%|▉         | 843/8564 [00:10<01:41, 75.83 examples/s]Tokenizing train dataset:  11%|█         | 930/8564 [00:10<01:32, 82.62 examples/s]Tokenizing train dataset:  11%|█         | 918/8564 [00:11<01:31, 83.57 examples/s]Tokenizing train dataset:  10%|█         | 858/8564 [00:10<01:33, 82.46 examples/s]Tokenizing train dataset:  11%|█         | 940/8564 [00:10<01:41, 75.30 examples/s]Tokenizing train dataset:  11%|█         | 930/8564 [00:11<01:49, 69.78 examples/s]Tokenizing train dataset:  10%|█         | 869/8564 [00:10<01:39, 76.97 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:10<01:35, 79.50 examples/s]Tokenizing train dataset:  11%|█         | 938/8564 [00:11<01:46, 71.64 examples/s]Tokenizing train dataset:  10%|█         | 883/8564 [00:10<01:26, 89.29 examples/s]Tokenizing train dataset:  11%|█         | 961/8564 [00:10<01:33, 81.53 examples/s]Tokenizing train dataset:  11%|█         | 950/8564 [00:11<01:37, 78.29 examples/s]Tokenizing train dataset:  11%|█▏        | 972/8564 [00:11<01:27, 86.28 examples/s]Tokenizing train dataset:  10%|█         | 899/8564 [00:10<01:25, 89.65 examples/s]Tokenizing train dataset:  11%|█         | 961/8564 [00:11<01:36, 78.90 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:11<01:42, 74.24 examples/s]Tokenizing train dataset:  11%|█         | 910/8564 [00:11<01:28, 86.91 examples/s]Tokenizing train dataset:  11%|█▏        | 973/8564 [00:11<01:35, 79.84 examples/s]Tokenizing train dataset:  12%|█▏        | 991/8564 [00:11<01:46, 71.22 examples/s]Tokenizing train dataset:  11%|█         | 924/8564 [00:11<01:27, 87.74 examples/s]Tokenizing train dataset:  12%|█▏        | 1004/8564 [00:11<01:34, 80.39 examples/s]Tokenizing train dataset:  12%|█▏        | 985/8564 [00:12<01:48, 69.68 examples/s]Tokenizing train dataset:  11%|█         | 936/8564 [00:11<01:38, 77.22 examples/s]Tokenizing train dataset:  12%|█▏        | 995/8564 [00:12<01:40, 75.37 examples/s]Tokenizing train dataset:  12%|█▏        | 1013/8564 [00:11<01:53, 66.59 examples/s]Tokenizing train dataset:  11%|█         | 945/8564 [00:11<01:41, 75.37 examples/s]Tokenizing train dataset:  12%|█▏        | 1006/8564 [00:12<01:32, 81.93 examples/s]Tokenizing train dataset:  12%|█▏        | 1024/8564 [00:11<01:50, 68.07 examples/s]Tokenizing train dataset:  12%|█▏        | 1020/8564 [00:12<01:29, 84.58 examples/s]Tokenizing train dataset:  11%|█         | 957/8564 [00:11<01:52, 67.57 examples/s]Tokenizing train dataset:  12%|█▏        | 1030/8564 [00:12<01:29, 83.73 examples/s]Tokenizing train dataset:  11%|█▏        | 966/8564 [00:11<01:47, 70.90 examples/s]Tokenizing train dataset:  12%|█▏        | 1037/8564 [00:12<01:57, 63.92 examples/s]Tokenizing train dataset:  12%|█▏        | 1040/8564 [00:12<01:29, 84.28 examples/s]Tokenizing train dataset:  12%|█▏        | 1045/8564 [00:12<02:05, 60.14 examples/s]Tokenizing train dataset:  11%|█▏        | 977/8564 [00:12<01:53, 66.60 examples/s]Tokenizing train dataset:  12%|█▏        | 1052/8564 [00:12<01:21, 92.22 examples/s]Tokenizing train dataset:  12%|█▏        | 1056/8564 [00:12<01:51, 67.46 examples/s]Tokenizing train dataset:  12%|█▏        | 1066/8564 [00:12<01:13, 101.85 examples/s]Tokenizing train dataset:  12%|█▏        | 986/8564 [00:12<02:12, 57.39 examples/s]Tokenizing train dataset:  13%|█▎        | 1078/8564 [00:13<01:13, 101.86 examples/s]Tokenizing train dataset:  12%|█▏        | 1067/8564 [00:12<01:48, 69.12 examples/s]Tokenizing train dataset:  13%|█▎        | 1091/8564 [00:13<01:08, 108.42 examples/s]Tokenizing train dataset:  12%|█▏        | 996/8564 [00:12<02:05, 60.51 examples/s]Tokenizing train dataset:  13%|█▎        | 1075/8564 [00:12<01:46, 70.24 examples/s]Tokenizing train dataset:  13%|█▎        | 1105/8564 [00:13<01:13, 101.77 examples/s]Tokenizing train dataset:  12%|█▏        | 1003/8564 [00:12<02:08, 58.89 examples/s]Tokenizing train dataset:  13%|█▎        | 1085/8564 [00:12<01:44, 71.55 examples/s]Tokenizing train dataset:  13%|█▎        | 1119/8564 [00:13<01:10, 105.77 examples/s]Tokenizing train dataset:  13%|█▎        | 1096/8564 [00:12<01:37, 76.57 examples/s]Tokenizing train dataset:  12%|█▏        | 1011/8564 [00:12<02:10, 57.83 examples/s]Tokenizing train dataset:  12%|█▏        | 1019/8564 [00:12<02:04, 60.55 examples/s]Tokenizing train dataset:  13%|█▎        | 1104/8564 [00:12<01:46, 70.25 examples/s]Tokenizing train dataset:  13%|█▎        | 1131/8564 [00:13<01:18, 94.40 examples/s] Tokenizing train dataset:  13%|█▎        | 1141/8564 [00:13<01:18, 94.79 examples/s]Tokenizing train dataset:  13%|█▎        | 1117/8564 [00:13<01:38, 75.40 examples/s]Tokenizing train dataset:  12%|█▏        | 1028/8564 [00:12<02:12, 57.04 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:13<01:18, 94.16 examples/s]Tokenizing train dataset:  12%|█▏        | 1034/8564 [00:13<02:13, 56.50 examples/s]Tokenizing train dataset:  14%|█▎        | 1162/8564 [00:13<01:19, 93.30 examples/s]Tokenizing train dataset:  13%|█▎        | 1125/8564 [00:13<02:04, 59.90 examples/s]Tokenizing train dataset:  12%|█▏        | 1040/8564 [00:13<02:12, 56.72 examples/s]Tokenizing train dataset:  13%|█▎        | 1135/8564 [00:13<01:53, 65.30 examples/s]Tokenizing train dataset:  12%|█▏        | 1050/8564 [00:13<01:57, 64.10 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:14<01:30, 81.21 examples/s]Tokenizing train dataset:  13%|█▎        | 1149/8564 [00:13<01:32, 80.05 examples/s]Tokenizing train dataset:  12%|█▏        | 1061/8564 [00:13<01:41, 73.78 examples/s]Tokenizing train dataset:  14%|█▍        | 1188/8564 [00:14<01:35, 77.49 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:13<01:32, 80.57 examples/s]Tokenizing train dataset:  14%|█▎        | 1160/8564 [00:13<01:38, 75.14 examples/s]Tokenizing train dataset:  14%|█▍        | 1200/8564 [00:14<01:25, 86.07 examples/s]Tokenizing train dataset:  13%|█▎        | 1090/8564 [00:13<01:13, 101.06 examples/s]Tokenizing train dataset:  14%|█▍        | 1210/8564 [00:14<01:27, 84.30 examples/s]Tokenizing train dataset:  14%|█▎        | 1173/8564 [00:13<01:46, 69.40 examples/s]Tokenizing train dataset:  13%|█▎        | 1102/8564 [00:13<01:28, 83.93 examples/s] Tokenizing train dataset:  14%|█▍        | 1220/8564 [00:14<01:29, 81.78 examples/s]Tokenizing train dataset:  14%|█▍        | 1187/8564 [00:14<01:29, 81.97 examples/s]Tokenizing train dataset:  14%|█▍        | 1202/8564 [00:14<01:19, 92.64 examples/s]Tokenizing train dataset:  13%|█▎        | 1117/8564 [00:14<01:34, 78.57 examples/s]Tokenizing train dataset:  14%|█▍        | 1232/8564 [00:14<01:38, 74.40 examples/s]Tokenizing train dataset:  14%|█▍        | 1213/8564 [00:14<01:21, 90.14 examples/s]Tokenizing train dataset:  15%|█▍        | 1247/8564 [00:15<01:20, 90.56 examples/s]Tokenizing train dataset:  14%|█▍        | 1231/8564 [00:14<01:06, 109.81 examples/s]Tokenizing train dataset:  13%|█▎        | 1126/8564 [00:14<02:00, 61.62 examples/s]Tokenizing train dataset:  15%|█▍        | 1252/8564 [00:14<00:56, 129.64 examples/s]Tokenizing train dataset:  15%|█▍        | 1260/8564 [00:15<01:31, 80.22 examples/s]Tokenizing train dataset:  15%|█▍        | 1268/8564 [00:14<00:55, 131.86 examples/s]Tokenizing train dataset:  13%|█▎        | 1136/8564 [00:14<02:04, 59.52 examples/s]Tokenizing train dataset:  15%|█▍        | 1270/8564 [00:15<01:35, 76.17 examples/s]Tokenizing train dataset:  13%|█▎        | 1146/8564 [00:14<01:52, 66.05 examples/s]Tokenizing train dataset:  15%|█▍        | 1283/8564 [00:14<01:03, 114.59 examples/s]Tokenizing train dataset:  15%|█▍        | 1279/8564 [00:15<01:38, 74.08 examples/s]Tokenizing train dataset:  14%|█▎        | 1157/8564 [00:14<01:41, 73.02 examples/s]Tokenizing train dataset:  15%|█▌        | 1288/8564 [00:15<01:39, 73.45 examples/s]Tokenizing train dataset:  14%|█▎        | 1166/8564 [00:14<01:39, 74.24 examples/s]Tokenizing train dataset:  15%|█▌        | 1301/8564 [00:15<01:25, 85.04 examples/s]Tokenizing train dataset:  15%|█▌        | 1300/8564 [00:15<01:19, 91.13 examples/s] Tokenizing train dataset:  14%|█▎        | 1174/8564 [00:14<01:44, 70.99 examples/s]Tokenizing train dataset:  15%|█▌        | 1313/8564 [00:15<01:22, 87.54 examples/s]Tokenizing train dataset:  15%|█▌        | 1312/8564 [00:15<01:15, 95.88 examples/s]Tokenizing train dataset:  14%|█▍        | 1185/8564 [00:15<01:37, 75.81 examples/s]Tokenizing train dataset:  15%|█▌        | 1323/8564 [00:15<01:15, 96.44 examples/s]Tokenizing train dataset:  15%|█▌        | 1327/8564 [00:16<01:30, 80.26 examples/s]Tokenizing train dataset:  14%|█▍        | 1198/8564 [00:15<01:32, 79.44 examples/s]Tokenizing train dataset:  16%|█▌        | 1334/8564 [00:15<01:18, 92.53 examples/s]Tokenizing train dataset:  16%|█▌        | 1340/8564 [00:16<01:22, 87.92 examples/s]Tokenizing train dataset:  16%|█▌        | 1348/8564 [00:15<01:13, 97.68 examples/s]Tokenizing train dataset:  14%|█▍        | 1210/8564 [00:15<01:47, 68.19 examples/s]Tokenizing train dataset:  16%|█▌        | 1352/8564 [00:16<01:19, 91.11 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:15<01:25, 84.19 examples/s]Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:15<01:39, 73.58 examples/s]Tokenizing train dataset:  16%|█▌        | 1364/8564 [00:16<01:30, 79.53 examples/s]Tokenizing train dataset:  14%|█▍        | 1239/8564 [00:15<01:19, 92.00 examples/s]Tokenizing train dataset:  16%|█▌        | 1369/8564 [00:15<01:24, 84.80 examples/s]Tokenizing train dataset:  16%|█▌        | 1380/8564 [00:15<01:22, 86.84 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:15<01:19, 92.44 examples/s]Tokenizing train dataset:  16%|█▌        | 1375/8564 [00:16<01:43, 69.80 examples/s]Tokenizing train dataset:  16%|█▋        | 1392/8564 [00:16<01:19, 90.24 examples/s]Tokenizing train dataset:  15%|█▍        | 1262/8564 [00:15<01:16, 95.29 examples/s]Tokenizing train dataset:  16%|█▌        | 1385/8564 [00:16<01:38, 72.70 examples/s]Tokenizing train dataset:  15%|█▍        | 1273/8564 [00:16<01:14, 97.93 examples/s]Tokenizing train dataset:  16%|█▋        | 1406/8564 [00:16<01:14, 96.20 examples/s]Tokenizing train dataset:  15%|█▍        | 1284/8564 [00:16<01:13, 99.68 examples/s]Tokenizing train dataset:  17%|█▋        | 1417/8564 [00:16<01:14, 95.64 examples/s]Tokenizing train dataset:  16%|█▋        | 1396/8564 [00:17<01:46, 67.36 examples/s]Tokenizing train dataset:  15%|█▌        | 1296/8564 [00:16<01:11, 101.14 examples/s]Tokenizing train dataset:  17%|█▋        | 1427/8564 [00:16<01:14, 95.69 examples/s]Tokenizing train dataset:  16%|█▋        | 1406/8564 [00:17<01:52, 63.76 examples/s]Tokenizing train dataset:  15%|█▌        | 1309/8564 [00:16<01:07, 107.42 examples/s]Tokenizing train dataset:  17%|█▋        | 1437/8564 [00:16<01:16, 93.03 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:16<01:11, 100.86 examples/s]Tokenizing train dataset:  17%|█▋        | 1417/8564 [00:17<01:44, 68.24 examples/s]Tokenizing train dataset:  17%|█▋        | 1448/8564 [00:16<01:13, 96.45 examples/s]Tokenizing train dataset:  16%|█▌        | 1332/8564 [00:16<01:09, 104.63 examples/s]Tokenizing train dataset:  17%|█▋        | 1458/8564 [00:16<01:18, 91.08 examples/s]Tokenizing train dataset:  17%|█▋        | 1425/8564 [00:17<01:51, 64.03 examples/s]Tokenizing train dataset:  17%|█▋        | 1470/8564 [00:16<01:13, 96.74 examples/s]Tokenizing train dataset:  16%|█▌        | 1349/8564 [00:16<01:10, 101.94 examples/s]Tokenizing train dataset:  17%|█▋        | 1433/8564 [00:17<01:53, 62.58 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:17<01:14, 95.14 examples/s]Tokenizing train dataset:  17%|█▋        | 1440/8564 [00:17<02:03, 57.80 examples/s]Tokenizing train dataset:  16%|█▌        | 1362/8564 [00:16<01:17, 93.46 examples/s] Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:17<01:14, 95.11 examples/s]Tokenizing train dataset:  17%|█▋        | 1449/8564 [00:17<01:53, 62.75 examples/s]Tokenizing train dataset:  18%|█▊        | 1501/8564 [00:17<01:12, 96.80 examples/s]Tokenizing train dataset:  16%|█▌        | 1376/8564 [00:17<01:17, 92.49 examples/s]Tokenizing train dataset:  17%|█▋        | 1457/8564 [00:18<01:54, 61.94 examples/s]Tokenizing train dataset:  16%|█▌        | 1387/8564 [00:17<01:16, 94.00 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:17<01:19, 89.05 examples/s]Tokenizing train dataset:  17%|█▋        | 1465/8564 [00:18<01:52, 63.13 examples/s]Tokenizing train dataset:  16%|█▋        | 1399/8564 [00:17<01:12, 98.87 examples/s]Tokenizing train dataset:  18%|█▊        | 1531/8564 [00:17<01:13, 95.74 examples/s]Tokenizing train dataset:  17%|█▋        | 1472/8564 [00:18<01:53, 62.66 examples/s]Tokenizing train dataset:  17%|█▋        | 1414/8564 [00:17<01:13, 96.96 examples/s]Tokenizing train dataset:  18%|█▊        | 1546/8564 [00:17<01:08, 101.79 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:18<01:52, 62.70 examples/s]Tokenizing train dataset:  17%|█▋        | 1426/8564 [00:17<01:14, 95.75 examples/s]Tokenizing train dataset:  17%|█▋        | 1489/8564 [00:18<01:44, 67.89 examples/s]Tokenizing train dataset:  18%|█▊        | 1559/8564 [00:17<01:14, 93.67 examples/s] Tokenizing train dataset:  17%|█▋        | 1440/8564 [00:17<01:19, 89.77 examples/s]Tokenizing train dataset:  18%|█▊        | 1569/8564 [00:18<01:21, 86.10 examples/s]Tokenizing train dataset:  18%|█▊        | 1500/8564 [00:18<01:50, 63.78 examples/s]Tokenizing train dataset:  17%|█▋        | 1452/8564 [00:17<01:21, 87.79 examples/s]Tokenizing train dataset:  18%|█▊        | 1579/8564 [00:18<01:20, 86.92 examples/s]Tokenizing train dataset:  18%|█▊        | 1508/8564 [00:18<01:48, 65.30 examples/s]Tokenizing train dataset:  17%|█▋        | 1462/8564 [00:18<01:21, 86.68 examples/s]Tokenizing train dataset:  18%|█▊        | 1515/8564 [00:18<01:50, 63.91 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:18<01:34, 73.55 examples/s]Tokenizing train dataset:  17%|█▋        | 1473/8564 [00:18<01:20, 88.58 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:19<01:28, 79.09 examples/s]Tokenizing train dataset:  19%|█▉        | 1608/8564 [00:18<01:19, 87.82 examples/s]Tokenizing train dataset:  18%|█▊        | 1540/8564 [00:19<01:26, 81.09 examples/s]Tokenizing train dataset:  17%|█▋        | 1483/8564 [00:18<01:38, 72.07 examples/s]Tokenizing train dataset:  19%|█▉        | 1620/8564 [00:18<01:16, 91.28 examples/s]Tokenizing train dataset:  18%|█▊        | 1551/8564 [00:19<01:23, 83.60 examples/s]Tokenizing train dataset:  19%|█▉        | 1631/8564 [00:18<01:13, 94.43 examples/s]Tokenizing train dataset:  17%|█▋        | 1494/8564 [00:18<01:36, 72.96 examples/s]Tokenizing train dataset:  18%|█▊        | 1565/8564 [00:19<01:12, 96.42 examples/s]Tokenizing train dataset:  19%|█▉        | 1644/8564 [00:18<01:10, 97.58 examples/s]Tokenizing train dataset:  18%|█▊        | 1504/8564 [00:18<01:43, 68.03 examples/s]Tokenizing train dataset:  18%|█▊        | 1580/8564 [00:19<01:13, 95.46 examples/s]Tokenizing train dataset:  19%|█▉        | 1657/8564 [00:18<01:12, 95.01 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:19<01:11, 97.15 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:18<01:46, 65.97 examples/s]Tokenizing train dataset:  19%|█▉        | 1669/8564 [00:19<01:20, 85.32 examples/s]Tokenizing train dataset:  18%|█▊        | 1532/8564 [00:18<01:22, 84.83 examples/s]Tokenizing train dataset:  19%|█▉        | 1609/8564 [00:19<01:19, 87.07 examples/s]Tokenizing train dataset:  18%|█▊        | 1542/8564 [00:19<01:26, 81.58 examples/s]Tokenizing train dataset:  20%|█▉        | 1682/8564 [00:19<01:29, 77.30 examples/s]Tokenizing train dataset:  19%|█▉        | 1619/8564 [00:20<01:19, 87.52 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:19<01:07, 102.28 examples/s]Tokenizing train dataset:  18%|█▊        | 1553/8564 [00:19<01:31, 76.95 examples/s]Tokenizing train dataset:  19%|█▉        | 1630/8564 [00:20<01:29, 77.28 examples/s]Tokenizing train dataset:  20%|██        | 1715/8564 [00:19<01:07, 101.66 examples/s]Tokenizing train dataset:  18%|█▊        | 1566/8564 [00:19<01:23, 84.26 examples/s]Tokenizing train dataset:  18%|█▊        | 1577/8564 [00:19<01:18, 88.84 examples/s]Tokenizing train dataset:  20%|██        | 1730/8564 [00:19<01:11, 95.20 examples/s] Tokenizing train dataset:  19%|█▉        | 1649/8564 [00:20<01:26, 80.18 examples/s]Tokenizing train dataset:  20%|██        | 1742/8564 [00:19<01:11, 95.28 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:19<01:32, 75.78 examples/s]Tokenizing train dataset:  19%|█▉        | 1662/8564 [00:20<01:34, 72.67 examples/s]Tokenizing train dataset:  21%|██        | 1758/8564 [00:20<01:06, 103.12 examples/s]Tokenizing train dataset:  19%|█▊        | 1600/8564 [00:19<01:32, 75.53 examples/s]Tokenizing train dataset:  20%|█▉        | 1672/8564 [00:20<01:32, 74.75 examples/s]Tokenizing train dataset:  21%|██        | 1769/8564 [00:20<01:05, 104.30 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:20<01:38, 70.90 examples/s]Tokenizing train dataset:  20%|█▉        | 1680/8564 [00:20<01:37, 70.84 examples/s]Tokenizing train dataset:  21%|██        | 1783/8564 [00:20<01:09, 97.17 examples/s] Tokenizing train dataset:  19%|█▉        | 1625/8564 [00:20<01:23, 83.56 examples/s]Tokenizing train dataset:  20%|█▉        | 1697/8564 [00:21<01:18, 87.19 examples/s]Tokenizing train dataset:  21%|██        | 1797/8564 [00:20<01:06, 101.37 examples/s]Tokenizing train dataset:  20%|█▉        | 1710/8564 [00:21<01:11, 95.34 examples/s]Tokenizing train dataset:  19%|█▉        | 1636/8564 [00:20<01:31, 76.03 examples/s]Tokenizing train dataset:  21%|██        | 1813/8564 [00:20<01:05, 102.59 examples/s]Tokenizing train dataset:  19%|█▉        | 1646/8564 [00:20<01:30, 76.40 examples/s]Tokenizing train dataset:  21%|██▏       | 1824/8564 [00:20<01:06, 101.87 examples/s]Tokenizing train dataset:  20%|██        | 1727/8564 [00:21<01:15, 89.97 examples/s]Tokenizing train dataset:  21%|██▏       | 1839/8564 [00:20<00:59, 112.08 examples/s]Tokenizing train dataset:  19%|█▉        | 1656/8564 [00:20<01:30, 76.29 examples/s]Tokenizing train dataset:  20%|██        | 1737/8564 [00:21<01:18, 87.21 examples/s]Tokenizing train dataset:  22%|██▏       | 1852/8564 [00:20<01:05, 102.61 examples/s]Tokenizing train dataset:  20%|██        | 1749/8564 [00:21<01:18, 87.04 examples/s]Tokenizing train dataset:  19%|█▉        | 1669/8564 [00:20<01:32, 74.94 examples/s]Tokenizing train dataset:  22%|██▏       | 1863/8564 [00:21<01:05, 102.92 examples/s]Tokenizing train dataset:  21%|██        | 1761/8564 [00:21<01:15, 90.01 examples/s]Tokenizing train dataset:  20%|█▉        | 1679/8564 [00:20<01:33, 74.02 examples/s]Tokenizing train dataset:  21%|██        | 1773/8564 [00:21<01:15, 89.75 examples/s]Tokenizing train dataset:  22%|██▏       | 1879/8564 [00:21<01:07, 98.61 examples/s] Tokenizing train dataset:  20%|█▉        | 1692/8564 [00:21<01:25, 80.53 examples/s]Tokenizing train dataset:  21%|██        | 1783/8564 [00:22<01:17, 87.54 examples/s]Tokenizing train dataset:  20%|█▉        | 1709/8564 [00:21<01:08, 99.49 examples/s]Tokenizing train dataset:  22%|██▏       | 1890/8564 [00:21<01:19, 84.15 examples/s]Tokenizing train dataset:  21%|██        | 1796/8564 [00:22<01:10, 95.81 examples/s]Tokenizing train dataset:  20%|██        | 1724/8564 [00:21<01:10, 97.71 examples/s]Tokenizing train dataset:  22%|██▏       | 1900/8564 [00:21<01:19, 83.42 examples/s]Tokenizing train dataset:  21%|██        | 1808/8564 [00:22<01:09, 97.62 examples/s]Tokenizing train dataset:  22%|██▏       | 1920/8564 [00:21<01:03, 104.60 examples/s]Tokenizing train dataset:  21%|██▏       | 1820/8564 [00:22<01:09, 97.31 examples/s]Tokenizing train dataset:  23%|██▎       | 1934/8564 [00:21<01:00, 110.06 examples/s]Tokenizing train dataset:  20%|██        | 1737/8564 [00:21<01:27, 77.69 examples/s]Tokenizing train dataset:  21%|██▏       | 1830/8564 [00:22<01:09, 96.59 examples/s]Tokenizing train dataset:  20%|██        | 1748/8564 [00:21<01:24, 81.09 examples/s]Tokenizing train dataset:  23%|██▎       | 1947/8564 [00:21<01:00, 109.02 examples/s]Tokenizing train dataset:  22%|██▏       | 1842/8564 [00:22<01:06, 100.69 examples/s]Tokenizing train dataset:  23%|██▎       | 1964/8564 [00:22<01:01, 108.09 examples/s]Tokenizing train dataset:  21%|██        | 1762/8564 [00:21<01:23, 81.63 examples/s]Tokenizing train dataset:  22%|██▏       | 1857/8564 [00:22<01:12, 91.91 examples/s] Tokenizing train dataset:  21%|██        | 1772/8564 [00:21<01:20, 84.52 examples/s]Tokenizing train dataset:  23%|██▎       | 1981/8564 [00:22<01:02, 105.28 examples/s]Tokenizing train dataset:  21%|██        | 1781/8564 [00:22<01:19, 84.86 examples/s]Tokenizing train dataset:  22%|██▏       | 1867/8564 [00:22<01:32, 72.58 examples/s]Tokenizing train dataset:  23%|██▎       | 1996/8564 [00:22<00:59, 110.46 examples/s]Tokenizing train dataset:  21%|██        | 1796/8564 [00:22<01:12, 93.74 examples/s]Tokenizing train dataset:  22%|██▏       | 1876/8564 [00:23<01:29, 74.75 examples/s]Tokenizing train dataset:  23%|██▎       | 2009/8564 [00:22<01:07, 97.57 examples/s] Tokenizing train dataset:  21%|██        | 1807/8564 [00:22<01:12, 93.62 examples/s]Tokenizing train dataset:  22%|██▏       | 1888/8564 [00:23<01:19, 83.85 examples/s]Tokenizing train dataset:  21%|██        | 1817/8564 [00:22<01:11, 94.52 examples/s]Tokenizing train dataset:  24%|██▎       | 2021/8564 [00:22<01:07, 97.39 examples/s]Tokenizing train dataset:  22%|██▏       | 1900/8564 [00:23<01:15, 88.51 examples/s]Tokenizing train dataset:  21%|██▏       | 1830/8564 [00:22<01:08, 97.79 examples/s]Tokenizing train dataset:  22%|██▏       | 1922/8564 [00:23<01:00, 110.38 examples/s]Tokenizing train dataset:  24%|██▍       | 2034/8564 [00:22<01:11, 91.26 examples/s]Tokenizing train dataset:  22%|██▏       | 1843/8564 [00:22<01:04, 104.11 examples/s]Tokenizing train dataset:  24%|██▍       | 2048/8564 [00:22<01:04, 100.80 examples/s]Tokenizing train dataset:  23%|██▎       | 1934/8564 [00:23<01:07, 98.57 examples/s] Tokenizing train dataset:  24%|██▍       | 2061/8564 [00:23<01:01, 106.14 examples/s]Tokenizing train dataset:  22%|██▏       | 1858/8564 [00:22<01:11, 93.32 examples/s] Tokenizing train dataset:  23%|██▎       | 1949/8564 [00:23<01:04, 102.52 examples/s]Tokenizing train dataset:  22%|██▏       | 1870/8564 [00:22<01:11, 93.01 examples/s]Tokenizing train dataset:  24%|██▍       | 2076/8564 [00:23<01:05, 98.37 examples/s] Tokenizing train dataset:  23%|██▎       | 1964/8564 [00:23<01:08, 96.35 examples/s] Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:23<01:01, 105.15 examples/s]Tokenizing train dataset:  23%|██▎       | 1977/8564 [00:24<01:03, 102.95 examples/s]Tokenizing train dataset:  22%|██▏       | 1882/8564 [00:23<01:26, 77.43 examples/s]Tokenizing train dataset:  25%|██▍       | 2104/8564 [00:23<00:59, 108.54 examples/s]Tokenizing train dataset:  23%|██▎       | 1988/8564 [00:24<01:08, 95.49 examples/s] Tokenizing train dataset:  25%|██▍       | 2120/8564 [00:23<00:56, 113.26 examples/s]Tokenizing train dataset:  22%|██▏       | 1894/8564 [00:23<01:32, 71.75 examples/s]Tokenizing train dataset:  23%|██▎       | 2000/8564 [00:24<01:07, 96.79 examples/s]Tokenizing train dataset:  25%|██▍       | 2136/8564 [00:23<00:52, 121.93 examples/s]Tokenizing train dataset:  22%|██▏       | 1912/8564 [00:23<01:15, 87.67 examples/s]Tokenizing train dataset:  24%|██▎       | 2013/8564 [00:24<01:13, 89.63 examples/s]Tokenizing train dataset:  25%|██▌       | 2153/8564 [00:23<00:54, 116.96 examples/s]Tokenizing train dataset:  23%|██▎       | 1928/8564 [00:23<01:15, 87.56 examples/s]Tokenizing train dataset:  24%|██▎       | 2023/8564 [00:24<01:14, 87.61 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:23<00:53, 119.97 examples/s]Tokenizing train dataset:  25%|██▌       | 2181/8564 [00:24<00:53, 119.82 examples/s]Tokenizing train dataset:  24%|██▎       | 2033/8564 [00:24<01:16, 84.94 examples/s]Tokenizing train dataset:  23%|██▎       | 1943/8564 [00:23<01:15, 87.58 examples/s]Tokenizing train dataset:  26%|██▌       | 2198/8564 [00:24<00:52, 122.24 examples/s]Tokenizing train dataset:  23%|██▎       | 1954/8564 [00:23<01:13, 89.43 examples/s]Tokenizing train dataset:  24%|██▍       | 2046/8564 [00:24<01:19, 81.61 examples/s]Tokenizing train dataset:  23%|██▎       | 1968/8564 [00:24<01:07, 98.36 examples/s]Tokenizing train dataset:  24%|██▍       | 2058/8564 [00:24<01:14, 86.97 examples/s]Tokenizing train dataset:  26%|██▌       | 2217/8564 [00:24<00:52, 121.58 examples/s]Tokenizing train dataset:  23%|██▎       | 1980/8564 [00:24<01:05, 100.55 examples/s]Tokenizing train dataset:  26%|██▌       | 2231/8564 [00:24<00:52, 121.25 examples/s]Tokenizing train dataset:  23%|██▎       | 1992/8564 [00:24<01:03, 104.17 examples/s]Tokenizing train dataset:  24%|██▍       | 2069/8564 [00:25<01:26, 75.49 examples/s]Tokenizing train dataset:  26%|██▌       | 2244/8564 [00:24<00:51, 122.36 examples/s]Tokenizing train dataset:  23%|██▎       | 2007/8564 [00:24<00:58, 111.23 examples/s]Tokenizing train dataset:  24%|██▍       | 2079/8564 [00:25<01:25, 76.26 examples/s]Tokenizing train dataset:  26%|██▋       | 2257/8564 [00:24<00:52, 119.47 examples/s]Tokenizing train dataset:  24%|██▎       | 2020/8564 [00:24<00:57, 113.75 examples/s]Tokenizing train dataset:  27%|██▋       | 2272/8564 [00:24<00:49, 126.84 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:25<01:24, 76.69 examples/s]Tokenizing train dataset:  24%|██▍       | 2034/8564 [00:24<00:56, 115.90 examples/s]Tokenizing train dataset:  27%|██▋       | 2290/8564 [00:24<00:47, 131.69 examples/s]Tokenizing train dataset:  25%|██▍       | 2099/8564 [00:25<01:23, 77.48 examples/s]Tokenizing train dataset:  24%|██▍       | 2050/8564 [00:24<00:53, 121.26 examples/s]Tokenizing train dataset:  27%|██▋       | 2304/8564 [00:25<00:50, 124.17 examples/s]Tokenizing train dataset:  25%|██▍       | 2109/8564 [00:25<01:25, 75.72 examples/s]Tokenizing train dataset:  24%|██▍       | 2064/8564 [00:24<00:51, 125.50 examples/s]Tokenizing train dataset:  27%|██▋       | 2320/8564 [00:25<00:56, 110.83 examples/s]Tokenizing train dataset:  25%|██▍       | 2122/8564 [00:25<01:27, 73.77 examples/s]Tokenizing train dataset:  24%|██▍       | 2082/8564 [00:25<00:54, 118.67 examples/s]Tokenizing train dataset:  27%|██▋       | 2333/8564 [00:25<00:54, 114.73 examples/s]Tokenizing train dataset:  25%|██▍       | 2134/8564 [00:26<01:18, 81.83 examples/s]Tokenizing train dataset:  25%|██▌       | 2147/8564 [00:26<01:11, 89.90 examples/s]Tokenizing train dataset:  27%|██▋       | 2347/8564 [00:25<00:59, 103.81 examples/s]Tokenizing train dataset:  25%|██▍       | 2099/8564 [00:25<01:05, 98.50 examples/s] Tokenizing train dataset:  25%|██▍       | 2111/8564 [00:25<01:03, 100.94 examples/s]Tokenizing train dataset:  25%|██▌       | 2159/8564 [00:26<01:10, 90.59 examples/s]Tokenizing train dataset:  28%|██▊       | 2358/8564 [00:25<01:02, 99.30 examples/s] Tokenizing train dataset:  25%|██▌       | 2172/8564 [00:26<01:03, 99.99 examples/s]Tokenizing train dataset:  28%|██▊       | 2373/8564 [00:25<00:59, 104.80 examples/s]Tokenizing train dataset:  25%|██▍       | 2127/8564 [00:25<01:07, 95.19 examples/s] Tokenizing train dataset:  28%|██▊       | 2387/8564 [00:25<00:55, 111.26 examples/s]Tokenizing train dataset:  26%|██▌       | 2187/8564 [00:26<01:04, 98.90 examples/s]Tokenizing train dataset:  28%|██▊       | 2403/8564 [00:25<00:50, 123.14 examples/s]Tokenizing train dataset:  26%|██▌       | 2200/8564 [00:26<01:04, 98.38 examples/s]Tokenizing train dataset:  25%|██▍       | 2140/8564 [00:25<01:18, 82.00 examples/s]Tokenizing train dataset:  28%|██▊       | 2421/8564 [00:26<00:51, 120.43 examples/s]Tokenizing train dataset:  25%|██▌       | 2154/8564 [00:25<01:09, 92.03 examples/s]Tokenizing train dataset:  26%|██▌       | 2212/8564 [00:26<01:05, 97.27 examples/s]Tokenizing train dataset:  28%|██▊       | 2434/8564 [00:26<00:51, 120.00 examples/s]Tokenizing train dataset:  26%|██▌       | 2227/8564 [00:26<01:02, 101.64 examples/s]Tokenizing train dataset:  25%|██▌       | 2168/8564 [00:26<01:13, 87.43 examples/s]Tokenizing train dataset:  29%|██▊       | 2448/8564 [00:26<00:49, 122.99 examples/s]Tokenizing train dataset:  26%|██▌       | 2242/8564 [00:27<01:06, 95.09 examples/s] Tokenizing train dataset:  29%|██▉       | 2465/8564 [00:26<00:47, 127.61 examples/s]Tokenizing train dataset:  25%|██▌       | 2180/8564 [00:26<01:20, 79.60 examples/s]Tokenizing train dataset:  26%|██▋       | 2255/8564 [00:27<01:03, 99.44 examples/s]Tokenizing train dataset:  26%|██▌       | 2194/8564 [00:26<01:10, 90.82 examples/s]Tokenizing train dataset:  26%|██▋       | 2267/8564 [00:27<01:05, 95.45 examples/s]Tokenizing train dataset:  26%|██▌       | 2209/8564 [00:26<01:03, 100.41 examples/s]Tokenizing train dataset:  29%|██▉       | 2485/8564 [00:26<01:03, 96.08 examples/s] Tokenizing train dataset:  27%|██▋       | 2282/8564 [00:27<00:58, 107.73 examples/s]Tokenizing train dataset:  26%|██▌       | 2223/8564 [00:26<00:58, 108.86 examples/s]Tokenizing train dataset:  27%|██▋       | 2295/8564 [00:27<00:56, 111.44 examples/s]Tokenizing train dataset:  29%|██▉       | 2498/8564 [00:26<01:07, 89.46 examples/s]Tokenizing train dataset:  26%|██▌       | 2237/8564 [00:26<00:56, 111.12 examples/s]Tokenizing train dataset:  26%|██▋       | 2253/8564 [00:26<00:51, 121.74 examples/s]Tokenizing train dataset:  27%|██▋       | 2310/8564 [00:27<01:03, 97.89 examples/s] Tokenizing train dataset:  29%|██▉       | 2510/8564 [00:27<01:14, 81.07 examples/s]Tokenizing train dataset:  27%|██▋       | 2275/8564 [00:26<00:50, 124.96 examples/s]Tokenizing train dataset:  27%|██▋       | 2321/8564 [00:27<01:04, 97.10 examples/s]Tokenizing train dataset:  29%|██▉       | 2521/8564 [00:27<01:10, 85.27 examples/s]Tokenizing train dataset:  27%|██▋       | 2290/8564 [00:27<00:50, 123.53 examples/s]Tokenizing train dataset:  27%|██▋       | 2336/8564 [00:27<00:59, 104.16 examples/s]Tokenizing train dataset:  30%|██▉       | 2538/8564 [00:27<01:09, 86.13 examples/s]Tokenizing train dataset:  27%|██▋       | 2347/8564 [00:28<01:00, 102.30 examples/s]Tokenizing train dataset:  27%|██▋       | 2306/8564 [00:27<00:54, 115.05 examples/s]Tokenizing train dataset:  30%|██▉       | 2549/8564 [00:27<01:08, 88.06 examples/s]Tokenizing train dataset:  28%|██▊       | 2361/8564 [00:28<01:05, 94.48 examples/s] Tokenizing train dataset:  27%|██▋       | 2321/8564 [00:27<00:59, 105.13 examples/s]Tokenizing train dataset:  30%|██▉       | 2561/8564 [00:27<01:07, 88.68 examples/s]Tokenizing train dataset:  28%|██▊       | 2377/8564 [00:28<00:59, 103.27 examples/s]Tokenizing train dataset:  27%|██▋       | 2336/8564 [00:27<00:57, 109.04 examples/s]Tokenizing train dataset:  30%|███       | 2573/8564 [00:27<01:09, 86.13 examples/s]Tokenizing train dataset:  28%|██▊       | 2391/8564 [00:28<00:55, 110.35 examples/s]Tokenizing train dataset:  30%|███       | 2587/8564 [00:27<01:08, 87.19 examples/s]Tokenizing train dataset:  27%|██▋       | 2352/8564 [00:27<00:57, 107.68 examples/s]Tokenizing train dataset:  28%|██▊       | 2405/8564 [00:28<01:02, 99.21 examples/s] Tokenizing train dataset:  30%|███       | 2600/8564 [00:28<01:07, 88.72 examples/s]Tokenizing train dataset:  28%|██▊       | 2370/8564 [00:27<00:58, 105.91 examples/s]Tokenizing train dataset:  28%|██▊       | 2420/8564 [00:28<01:06, 92.73 examples/s]Tokenizing train dataset:  28%|██▊       | 2381/8564 [00:28<00:58, 105.86 examples/s]Tokenizing train dataset:  30%|███       | 2610/8564 [00:28<01:07, 88.43 examples/s]Tokenizing train dataset:  28%|██▊       | 2396/8564 [00:28<00:53, 114.25 examples/s]Tokenizing train dataset:  31%|███       | 2619/8564 [00:28<01:13, 80.39 examples/s]Tokenizing train dataset:  28%|██▊       | 2435/8564 [00:29<01:07, 90.70 examples/s]Tokenizing train dataset:  31%|███       | 2629/8564 [00:28<01:11, 83.43 examples/s]Tokenizing train dataset:  28%|██▊       | 2412/8564 [00:28<01:00, 101.57 examples/s]Tokenizing train dataset:  29%|██▊       | 2445/8564 [00:29<01:15, 81.47 examples/s]Tokenizing train dataset:  31%|███       | 2638/8564 [00:28<01:11, 83.40 examples/s]Tokenizing train dataset:  28%|██▊       | 2426/8564 [00:28<00:56, 108.92 examples/s]Tokenizing train dataset:  29%|██▊       | 2459/8564 [00:29<01:05, 93.36 examples/s]Tokenizing train dataset:  29%|██▉       | 2472/8564 [00:29<01:00, 101.13 examples/s]Tokenizing train dataset:  31%|███       | 2650/8564 [00:28<01:19, 74.39 examples/s]Tokenizing train dataset:  29%|██▊       | 2441/8564 [00:28<01:00, 101.08 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:28<01:16, 76.94 examples/s]Tokenizing train dataset:  29%|██▊       | 2456/8564 [00:28<00:55, 111.02 examples/s]Tokenizing train dataset:  29%|██▉       | 2488/8564 [00:29<01:08, 89.02 examples/s] Tokenizing train dataset:  31%|███       | 2669/8564 [00:29<01:19, 73.79 examples/s]Tokenizing train dataset:  29%|██▉       | 2470/8564 [00:28<00:56, 107.15 examples/s]Tokenizing train dataset:  29%|██▉       | 2500/8564 [00:29<01:06, 91.12 examples/s]Tokenizing train dataset:  29%|██▉       | 2511/8564 [00:29<01:05, 92.46 examples/s]Tokenizing train dataset:  29%|██▉       | 2486/8564 [00:29<01:00, 100.75 examples/s]Tokenizing train dataset:  31%|███▏      | 2680/8564 [00:29<01:28, 66.78 examples/s]Tokenizing train dataset:  29%|██▉       | 2522/8564 [00:29<01:05, 92.51 examples/s]Tokenizing train dataset:  31%|███▏      | 2692/8564 [00:29<01:22, 71.13 examples/s]Tokenizing train dataset:  29%|██▉       | 2499/8564 [00:29<01:06, 90.87 examples/s] Tokenizing train dataset:  30%|██▉       | 2537/8564 [00:30<00:59, 100.69 examples/s]Tokenizing train dataset:  32%|███▏      | 2702/8564 [00:29<01:22, 70.96 examples/s]Tokenizing train dataset:  30%|██▉       | 2553/8564 [00:30<00:53, 112.82 examples/s]Tokenizing train dataset:  29%|██▉       | 2512/8564 [00:29<01:11, 84.50 examples/s]Tokenizing train dataset:  32%|███▏      | 2717/8564 [00:29<01:07, 87.03 examples/s]Tokenizing train dataset:  30%|██▉       | 2568/8564 [00:30<00:49, 121.60 examples/s]Tokenizing train dataset:  29%|██▉       | 2526/8564 [00:29<01:05, 91.64 examples/s]Tokenizing train dataset:  32%|███▏      | 2729/8564 [00:29<01:01, 94.17 examples/s]Tokenizing train dataset:  30%|███       | 2581/8564 [00:30<00:51, 116.22 examples/s]Tokenizing train dataset:  30%|██▉       | 2538/8564 [00:29<01:05, 91.85 examples/s]Tokenizing train dataset:  32%|███▏      | 2740/8564 [00:29<01:04, 89.88 examples/s]Tokenizing train dataset:  30%|███       | 2595/8564 [00:30<00:51, 116.93 examples/s]Tokenizing train dataset:  32%|███▏      | 2752/8564 [00:29<01:01, 94.57 examples/s]Tokenizing train dataset:  30%|██▉       | 2554/8564 [00:29<01:05, 91.94 examples/s]Tokenizing train dataset:  30%|███       | 2608/8564 [00:30<00:55, 107.90 examples/s]Tokenizing train dataset:  32%|███▏      | 2763/8564 [00:30<01:00, 95.10 examples/s]Tokenizing train dataset:  30%|██▉       | 2564/8564 [00:29<01:04, 92.99 examples/s]Tokenizing train dataset:  32%|███▏      | 2777/8564 [00:30<00:55, 104.81 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:30<01:11, 83.71 examples/s] Tokenizing train dataset:  33%|███▎      | 2790/8564 [00:30<00:52, 110.01 examples/s]Tokenizing train dataset:  30%|███       | 2577/8564 [00:30<01:11, 83.17 examples/s]Tokenizing train dataset:  33%|███▎      | 2803/8564 [00:30<00:50, 114.57 examples/s]Tokenizing train dataset:  31%|███       | 2630/8564 [00:31<01:13, 80.25 examples/s]Tokenizing train dataset:  30%|███       | 2590/8564 [00:30<01:14, 80.32 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:30<00:46, 122.54 examples/s]Tokenizing train dataset:  31%|███       | 2641/8564 [00:31<01:15, 78.60 examples/s]Tokenizing train dataset:  30%|███       | 2601/8564 [00:30<01:18, 76.34 examples/s]Tokenizing train dataset:  33%|███▎      | 2837/8564 [00:30<00:48, 118.30 examples/s]Tokenizing train dataset:  31%|███       | 2652/8564 [00:31<01:21, 72.67 examples/s]Tokenizing train dataset:  30%|███       | 2610/8564 [00:30<01:20, 73.76 examples/s]Tokenizing train dataset:  33%|███▎      | 2850/8564 [00:30<00:49, 115.59 examples/s]Tokenizing train dataset:  31%|███       | 2666/8564 [00:31<01:12, 81.48 examples/s]Tokenizing train dataset:  31%|███       | 2618/8564 [00:30<01:23, 71.30 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:30<00:52, 108.65 examples/s]Tokenizing train dataset:  31%|███       | 2626/8564 [00:30<01:23, 71.27 examples/s]Tokenizing train dataset:  31%|███       | 2675/8564 [00:31<01:25, 69.07 examples/s]Tokenizing train dataset:  34%|███▎      | 2887/8564 [00:31<00:52, 108.05 examples/s]Tokenizing train dataset:  31%|███▏      | 2688/8564 [00:31<01:12, 80.85 examples/s]Tokenizing train dataset:  31%|███       | 2640/8564 [00:30<01:17, 76.76 examples/s]Tokenizing train dataset:  34%|███▍      | 2902/8564 [00:31<00:48, 116.56 examples/s]Tokenizing train dataset:  32%|███▏      | 2701/8564 [00:31<01:04, 90.83 examples/s]Tokenizing train dataset:  31%|███       | 2649/8564 [00:31<01:16, 77.78 examples/s]Tokenizing train dataset:  34%|███▍      | 2919/8564 [00:31<00:43, 128.75 examples/s]Tokenizing train dataset:  32%|███▏      | 2714/8564 [00:32<00:58, 99.90 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:31<01:15, 78.26 examples/s]Tokenizing train dataset:  32%|███▏      | 2727/8564 [00:32<00:57, 101.92 examples/s]Tokenizing train dataset:  34%|███▍      | 2940/8564 [00:31<00:43, 128.87 examples/s]Tokenizing train dataset:  31%|███       | 2669/8564 [00:31<01:24, 70.07 examples/s]Tokenizing train dataset:  32%|███▏      | 2740/8564 [00:32<01:01, 94.37 examples/s] Tokenizing train dataset:  31%|███▏      | 2679/8564 [00:31<01:20, 73.27 examples/s]Tokenizing train dataset:  35%|███▍      | 2960/8564 [00:31<00:46, 120.18 examples/s]Tokenizing train dataset:  32%|███▏      | 2751/8564 [00:32<01:00, 96.83 examples/s]Tokenizing train dataset:  35%|███▍      | 2980/8564 [00:31<00:42, 132.55 examples/s]Tokenizing train dataset:  31%|███▏      | 2690/8564 [00:31<01:16, 77.28 examples/s]Tokenizing train dataset:  32%|███▏      | 2762/8564 [00:32<01:07, 86.35 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:31<01:03, 91.67 examples/s]Tokenizing train dataset:  35%|███▌      | 2999/8564 [00:32<00:45, 121.36 examples/s]Tokenizing train dataset:  32%|███▏      | 2776/8564 [00:32<01:00, 94.99 examples/s]Tokenizing train dataset:  32%|███▏      | 2720/8564 [00:31<00:56, 103.47 examples/s]Tokenizing train dataset:  32%|███▏      | 2731/8564 [00:31<00:55, 104.29 examples/s]Tokenizing train dataset:  33%|███▎      | 2792/8564 [00:32<00:54, 105.32 examples/s]Tokenizing train dataset:  35%|███▌      | 3017/8564 [00:32<00:54, 101.20 examples/s]Tokenizing train dataset:  33%|███▎      | 2808/8564 [00:32<00:48, 117.76 examples/s]Tokenizing train dataset:  32%|███▏      | 2746/8564 [00:32<00:58, 100.06 examples/s]Tokenizing train dataset:  33%|███▎      | 2822/8564 [00:33<00:46, 122.74 examples/s]Tokenizing train dataset:  32%|███▏      | 2759/8564 [00:32<00:54, 106.06 examples/s]Tokenizing train dataset:  35%|███▌      | 3029/8564 [00:32<01:04, 85.86 examples/s] Tokenizing train dataset:  33%|███▎      | 2836/8564 [00:33<00:48, 117.54 examples/s]Tokenizing train dataset:  35%|███▌      | 3040/8564 [00:32<01:01, 89.44 examples/s]Tokenizing train dataset:  32%|███▏      | 2771/8564 [00:32<01:05, 88.55 examples/s] Tokenizing train dataset:  33%|███▎      | 2850/8564 [00:33<00:49, 115.57 examples/s]Tokenizing train dataset:  36%|███▌      | 3053/8564 [00:32<00:57, 95.28 examples/s]Tokenizing train dataset:  33%|███▎      | 2786/8564 [00:32<00:58, 98.70 examples/s]Tokenizing train dataset:  36%|███▌      | 3066/8564 [00:32<00:54, 100.05 examples/s]Tokenizing train dataset:  33%|███▎      | 2801/8564 [00:32<00:55, 103.83 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:33<01:00, 94.21 examples/s] Tokenizing train dataset:  33%|███▎      | 2819/8564 [00:32<00:49, 116.36 examples/s]Tokenizing train dataset:  36%|███▌      | 3085/8564 [00:33<00:58, 93.03 examples/s] Tokenizing train dataset:  34%|███▎      | 2887/8564 [00:33<00:56, 99.67 examples/s]Tokenizing train dataset:  33%|███▎      | 2836/8564 [00:32<00:50, 113.36 examples/s]Tokenizing train dataset:  34%|███▍      | 2901/8564 [00:33<00:52, 107.73 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:33<01:07, 81.58 examples/s]Tokenizing train dataset:  33%|███▎      | 2849/8564 [00:33<00:50, 113.50 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:33<00:46, 122.64 examples/s]Tokenizing train dataset:  36%|███▋      | 3111/8564 [00:33<00:59, 91.76 examples/s]Tokenizing train dataset:  33%|███▎      | 2866/8564 [00:33<00:52, 108.39 examples/s]Tokenizing train dataset:  34%|███▍      | 2937/8564 [00:34<00:51, 108.45 examples/s]Tokenizing train dataset:  37%|███▋      | 3127/8564 [00:33<01:05, 83.49 examples/s]Tokenizing train dataset:  34%|███▍      | 2953/8564 [00:34<00:48, 114.83 examples/s]Tokenizing train dataset:  34%|███▎      | 2881/8564 [00:33<00:56, 100.81 examples/s]Tokenizing train dataset:  37%|███▋      | 3143/8564 [00:33<00:55, 97.47 examples/s]Tokenizing train dataset:  35%|███▍      | 2969/8564 [00:34<00:45, 121.93 examples/s]Tokenizing train dataset:  34%|███▍      | 2894/8564 [00:33<00:59, 95.44 examples/s] Tokenizing train dataset:  37%|███▋      | 3156/8564 [00:33<00:53, 100.92 examples/s]Tokenizing train dataset:  35%|███▍      | 2986/8564 [00:34<00:42, 132.54 examples/s]Tokenizing train dataset:  34%|███▍      | 2909/8564 [00:33<00:57, 98.40 examples/s]Tokenizing train dataset:  37%|███▋      | 3169/8564 [00:33<00:52, 103.51 examples/s]Tokenizing train dataset:  35%|███▌      | 3000/8564 [00:34<00:48, 114.83 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:33<00:55, 102.47 examples/s]Tokenizing train dataset:  37%|███▋      | 3184/8564 [00:34<00:54, 99.58 examples/s] Tokenizing train dataset:  34%|███▍      | 2933/8564 [00:33<00:56, 100.18 examples/s]Tokenizing train dataset:  35%|███▌      | 3016/8564 [00:34<00:52, 104.99 examples/s]Tokenizing train dataset:  37%|███▋      | 3195/8564 [00:34<00:53, 100.86 examples/s]Tokenizing train dataset:  34%|███▍      | 2948/8564 [00:34<00:51, 109.15 examples/s]Tokenizing train dataset:  35%|███▌      | 3029/8564 [00:34<00:51, 108.35 examples/s]Tokenizing train dataset:  37%|███▋      | 3206/8564 [00:34<00:55, 96.86 examples/s] Tokenizing train dataset:  35%|███▍      | 2961/8564 [00:34<00:50, 109.92 examples/s]Tokenizing train dataset:  35%|███▍      | 2982/8564 [00:34<00:42, 132.32 examples/s]Tokenizing train dataset:  38%|███▊      | 3217/8564 [00:34<01:01, 86.67 examples/s]Tokenizing train dataset:  36%|███▌      | 3045/8564 [00:35<00:58, 93.76 examples/s] Tokenizing train dataset:  38%|███▊      | 3230/8564 [00:34<00:56, 95.02 examples/s]Tokenizing train dataset:  36%|███▌      | 3065/8564 [00:35<00:54, 100.91 examples/s]Tokenizing train dataset:  35%|███▌      | 3000/8564 [00:34<00:50, 109.94 examples/s]Tokenizing train dataset:  38%|███▊      | 3243/8564 [00:34<00:58, 91.05 examples/s]Tokenizing train dataset:  35%|███▌      | 3014/8564 [00:34<00:49, 111.11 examples/s]Tokenizing train dataset:  38%|███▊      | 3253/8564 [00:34<00:58, 90.67 examples/s]Tokenizing train dataset:  36%|███▌      | 3080/8564 [00:35<01:01, 89.33 examples/s] Tokenizing train dataset:  35%|███▌      | 3028/8564 [00:34<00:47, 116.28 examples/s]Tokenizing train dataset:  36%|███▌      | 3093/8564 [00:35<00:59, 92.69 examples/s]Tokenizing train dataset:  38%|███▊      | 3264/8564 [00:35<01:06, 79.31 examples/s]Tokenizing train dataset:  36%|███▌      | 3045/8564 [00:34<00:48, 112.80 examples/s]Tokenizing train dataset:  38%|███▊      | 3276/8564 [00:35<01:05, 81.18 examples/s]Tokenizing train dataset:  36%|███▋      | 3109/8564 [00:35<01:00, 89.89 examples/s]Tokenizing train dataset:  36%|███▌      | 3062/8564 [00:35<00:50, 109.45 examples/s]Tokenizing train dataset:  36%|███▋      | 3121/8564 [00:36<01:04, 84.58 examples/s]Tokenizing train dataset:  38%|███▊      | 3290/8564 [00:35<01:08, 76.66 examples/s]Tokenizing train dataset:  36%|███▌      | 3080/8564 [00:35<00:50, 108.28 examples/s]Tokenizing train dataset:  37%|███▋      | 3130/8564 [00:36<01:07, 80.81 examples/s]Tokenizing train dataset:  39%|███▊      | 3300/8564 [00:35<01:10, 75.07 examples/s]Tokenizing train dataset:  36%|███▌      | 3092/8564 [00:35<00:50, 108.68 examples/s]Tokenizing train dataset:  37%|███▋      | 3140/8564 [00:36<01:04, 84.59 examples/s]Tokenizing train dataset:  39%|███▊      | 3313/8564 [00:35<01:01, 85.59 examples/s]Tokenizing train dataset:  36%|███▋      | 3106/8564 [00:35<00:47, 114.33 examples/s]Tokenizing train dataset:  37%|███▋      | 3154/8564 [00:36<00:55, 97.10 examples/s]Tokenizing train dataset:  36%|███▋      | 3118/8564 [00:35<00:49, 110.54 examples/s]Tokenizing train dataset:  37%|███▋      | 3166/8564 [00:36<00:54, 98.22 examples/s]Tokenizing train dataset:  39%|███▉      | 3325/8564 [00:35<01:08, 76.63 examples/s]Tokenizing train dataset:  37%|███▋      | 3131/8564 [00:35<00:49, 109.67 examples/s]Tokenizing train dataset:  37%|███▋      | 3178/8564 [00:36<00:52, 101.93 examples/s]Tokenizing train dataset:  37%|███▋      | 3146/8564 [00:35<00:45, 118.69 examples/s]Tokenizing train dataset:  39%|███▉      | 3338/8564 [00:35<01:09, 75.20 examples/s]Tokenizing train dataset:  37%|███▋      | 3190/8564 [00:36<00:51, 104.05 examples/s]Tokenizing train dataset:  37%|███▋      | 3162/8564 [00:35<00:43, 125.55 examples/s]Tokenizing train dataset:  39%|███▉      | 3353/8564 [00:36<00:57, 89.90 examples/s]Tokenizing train dataset:  37%|███▋      | 3204/8564 [00:36<00:56, 94.73 examples/s] Tokenizing train dataset:  39%|███▉      | 3365/8564 [00:36<00:55, 93.04 examples/s]Tokenizing train dataset:  37%|███▋      | 3179/8564 [00:36<00:46, 117.01 examples/s]Tokenizing train dataset:  39%|███▉      | 3380/8564 [00:36<00:49, 104.88 examples/s]Tokenizing train dataset:  37%|███▋      | 3194/8564 [00:36<00:45, 119.07 examples/s]Tokenizing train dataset:  38%|███▊      | 3221/8564 [00:37<00:59, 90.21 examples/s]Tokenizing train dataset:  37%|███▋      | 3209/8564 [00:36<00:42, 125.72 examples/s]Tokenizing train dataset:  40%|███▉      | 3395/8564 [00:36<00:51, 100.14 examples/s]Tokenizing train dataset:  38%|███▊      | 3232/8564 [00:37<00:57, 93.21 examples/s]Tokenizing train dataset:  40%|███▉      | 3409/8564 [00:36<00:47, 108.62 examples/s]Tokenizing train dataset:  38%|███▊      | 3229/8564 [00:36<00:43, 121.93 examples/s]Tokenizing train dataset:  38%|███▊      | 3247/8564 [00:37<01:00, 88.09 examples/s]Tokenizing train dataset:  40%|███▉      | 3425/8564 [00:36<00:47, 107.38 examples/s]Tokenizing train dataset:  38%|███▊      | 3246/8564 [00:36<00:41, 129.25 examples/s]Tokenizing train dataset:  40%|████      | 3440/8564 [00:36<00:44, 114.85 examples/s]Tokenizing train dataset:  38%|███▊      | 3260/8564 [00:36<00:40, 130.05 examples/s]Tokenizing train dataset:  38%|███▊      | 3260/8564 [00:37<01:06, 80.04 examples/s]Tokenizing train dataset:  40%|████      | 3459/8564 [00:36<00:41, 123.76 examples/s]Tokenizing train dataset:  38%|███▊      | 3270/8564 [00:37<01:04, 82.62 examples/s]Tokenizing train dataset:  38%|███▊      | 3276/8564 [00:36<00:44, 119.14 examples/s]Tokenizing train dataset:  38%|███▊      | 3289/8564 [00:36<00:45, 116.59 examples/s]Tokenizing train dataset:  41%|████      | 3477/8564 [00:37<00:43, 117.62 examples/s]Tokenizing train dataset:  38%|███▊      | 3280/8564 [00:37<01:10, 75.24 examples/s]Tokenizing train dataset:  38%|███▊      | 3293/8564 [00:37<01:03, 82.66 examples/s]Tokenizing train dataset:  39%|███▊      | 3305/8564 [00:37<00:48, 108.71 examples/s]Tokenizing train dataset:  41%|████      | 3491/8564 [00:37<00:47, 106.91 examples/s]Tokenizing train dataset:  39%|███▊      | 3304/8564 [00:38<01:00, 86.93 examples/s]Tokenizing train dataset:  39%|███▊      | 3318/8564 [00:37<00:46, 113.19 examples/s]Tokenizing train dataset:  41%|████      | 3506/8564 [00:37<00:45, 110.86 examples/s]Tokenizing train dataset:  39%|███▊      | 3317/8564 [00:38<00:59, 88.59 examples/s]Tokenizing train dataset:  39%|███▉      | 3332/8564 [00:37<00:53, 97.02 examples/s] Tokenizing train dataset:  41%|████      | 3524/8564 [00:37<00:46, 108.86 examples/s]Tokenizing train dataset:  39%|███▉      | 3328/8564 [00:38<01:03, 82.71 examples/s]Tokenizing train dataset:  39%|███▉      | 3343/8564 [00:37<00:56, 91.70 examples/s]Tokenizing train dataset:  41%|████▏     | 3542/8564 [00:37<00:47, 106.04 examples/s]Tokenizing train dataset:  39%|███▉      | 3339/8564 [00:38<01:01, 85.48 examples/s]Tokenizing train dataset:  39%|███▉      | 3359/8564 [00:37<00:55, 93.50 examples/s]Tokenizing train dataset:  39%|███▉      | 3353/8564 [00:38<00:56, 92.24 examples/s]Tokenizing train dataset:  42%|████▏     | 3555/8564 [00:37<00:51, 97.29 examples/s] Tokenizing train dataset:  39%|███▉      | 3365/8564 [00:38<00:52, 98.49 examples/s]Tokenizing train dataset:  42%|████▏     | 3565/8564 [00:38<00:54, 91.83 examples/s]Tokenizing train dataset:  39%|███▉      | 3371/8564 [00:37<01:02, 83.38 examples/s]Tokenizing train dataset:  39%|███▉      | 3380/8564 [00:38<00:48, 105.80 examples/s]Tokenizing train dataset:  39%|███▉      | 3382/8564 [00:38<01:00, 85.26 examples/s]Tokenizing train dataset:  42%|████▏     | 3580/8564 [00:38<00:55, 89.80 examples/s]Tokenizing train dataset:  40%|███▉      | 3397/8564 [00:38<00:42, 120.52 examples/s]Tokenizing train dataset:  40%|███▉      | 3394/8564 [00:38<00:57, 90.66 examples/s]Tokenizing train dataset:  42%|████▏     | 3590/8564 [00:38<00:55, 89.02 examples/s]Tokenizing train dataset:  40%|███▉      | 3411/8564 [00:39<00:42, 121.73 examples/s]Tokenizing train dataset:  40%|███▉      | 3405/8564 [00:38<00:56, 91.37 examples/s]Tokenizing train dataset:  40%|███▉      | 3425/8564 [00:39<00:42, 120.24 examples/s]Tokenizing train dataset:  42%|████▏     | 3600/8564 [00:38<00:54, 90.32 examples/s]Tokenizing train dataset:  40%|███▉      | 3415/8564 [00:38<01:01, 83.34 examples/s]Tokenizing train dataset:  40%|████      | 3440/8564 [00:39<00:42, 121.98 examples/s]Tokenizing train dataset:  42%|████▏     | 3610/8564 [00:38<01:01, 80.35 examples/s]Tokenizing train dataset:  40%|███▉      | 3425/8564 [00:38<01:01, 83.25 examples/s]Tokenizing train dataset:  40%|████      | 3454/8564 [00:39<00:41, 123.56 examples/s]Tokenizing train dataset:  42%|████▏     | 3619/8564 [00:38<01:01, 80.19 examples/s]Tokenizing train dataset:  40%|████      | 3437/8564 [00:38<00:58, 87.30 examples/s]Tokenizing train dataset:  41%|████      | 3470/8564 [00:39<00:41, 122.82 examples/s]Tokenizing train dataset:  42%|████▏     | 3631/8564 [00:38<00:59, 82.91 examples/s]Tokenizing train dataset:  41%|████      | 3483/8564 [00:39<00:41, 123.44 examples/s]Tokenizing train dataset:  40%|████      | 3450/8564 [00:38<01:03, 81.15 examples/s]Tokenizing train dataset:  43%|████▎     | 3643/8564 [00:39<01:03, 77.26 examples/s]Tokenizing train dataset:  41%|████      | 3504/8564 [00:39<00:40, 124.47 examples/s]Tokenizing train dataset:  40%|████      | 3460/8564 [00:38<01:01, 82.66 examples/s]Tokenizing train dataset:  43%|████▎     | 3654/8564 [00:39<01:07, 72.66 examples/s]Tokenizing train dataset:  41%|████      | 3520/8564 [00:39<00:40, 125.84 examples/s]Tokenizing train dataset:  41%|████      | 3469/8564 [00:39<01:03, 80.87 examples/s]Tokenizing train dataset:  43%|████▎     | 3663/8564 [00:39<01:07, 72.18 examples/s]Tokenizing train dataset:  41%|████      | 3478/8564 [00:39<01:08, 74.53 examples/s]Tokenizing train dataset:  41%|████▏     | 3537/8564 [00:40<00:41, 121.11 examples/s]Tokenizing train dataset:  43%|████▎     | 3672/8564 [00:39<01:09, 70.34 examples/s]Tokenizing train dataset:  41%|████      | 3488/8564 [00:39<01:08, 74.26 examples/s]Tokenizing train dataset:  42%|████▏     | 3555/8564 [00:40<00:42, 119.12 examples/s]Tokenizing train dataset:  41%|████      | 3503/8564 [00:39<00:56, 89.44 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:39<01:19, 61.62 examples/s]Tokenizing train dataset:  42%|████▏     | 3567/8564 [00:40<00:44, 113.44 examples/s]Tokenizing train dataset:  41%|████      | 3517/8564 [00:39<00:52, 96.67 examples/s]Tokenizing train dataset:  43%|████▎     | 3695/8564 [00:39<01:02, 78.38 examples/s]Tokenizing train dataset:  42%|████▏     | 3580/8564 [00:40<00:46, 107.30 examples/s]Tokenizing train dataset:  41%|████      | 3528/8564 [00:39<00:52, 95.62 examples/s]Tokenizing train dataset:  43%|████▎     | 3706/8564 [00:39<00:57, 84.14 examples/s]Tokenizing train dataset:  42%|████▏     | 3597/8564 [00:40<00:46, 106.03 examples/s]Tokenizing train dataset:  41%|████▏     | 3538/8564 [00:39<00:55, 91.31 examples/s]Tokenizing train dataset:  43%|████▎     | 3722/8564 [00:40<00:49, 98.36 examples/s]Tokenizing train dataset:  42%|████▏     | 3610/8564 [00:40<00:47, 104.10 examples/s]Tokenizing train dataset:  41%|████▏     | 3550/8564 [00:39<00:55, 90.32 examples/s]Tokenizing train dataset:  42%|████▏     | 3628/8564 [00:40<00:41, 119.65 examples/s]Tokenizing train dataset:  44%|████▎     | 3737/8564 [00:40<00:57, 84.45 examples/s]Tokenizing train dataset:  42%|████▏     | 3560/8564 [00:40<00:58, 85.45 examples/s]Tokenizing train dataset:  44%|████▍     | 3751/8564 [00:40<00:56, 85.04 examples/s]Tokenizing train dataset:  43%|████▎     | 3646/8564 [00:41<00:44, 109.73 examples/s]Tokenizing train dataset:  42%|████▏     | 3573/8564 [00:40<01:00, 82.88 examples/s]Tokenizing train dataset:  43%|████▎     | 3660/8564 [00:41<00:45, 108.88 examples/s]Tokenizing train dataset:  42%|████▏     | 3585/8564 [00:40<00:58, 85.63 examples/s]Tokenizing train dataset:  44%|████▍     | 3765/8564 [00:40<01:00, 79.31 examples/s]Tokenizing train dataset:  42%|████▏     | 3598/8564 [00:40<00:53, 93.39 examples/s]Tokenizing train dataset:  43%|████▎     | 3676/8564 [00:41<00:48, 101.46 examples/s]Tokenizing train dataset:  44%|████▍     | 3775/8564 [00:40<01:01, 78.44 examples/s]Tokenizing train dataset:  42%|████▏     | 3610/8564 [00:40<00:50, 98.71 examples/s]Tokenizing train dataset:  44%|████▍     | 3786/8564 [00:40<01:00, 79.53 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:40<00:44, 111.89 examples/s]Tokenizing train dataset:  43%|████▎     | 3690/8564 [00:41<00:53, 91.54 examples/s] Tokenizing train dataset:  43%|████▎     | 3640/8564 [00:40<00:42, 115.36 examples/s]Tokenizing train dataset:  44%|████▍     | 3800/8564 [00:41<00:59, 79.87 examples/s]Tokenizing train dataset:  43%|████▎     | 3702/8564 [00:41<00:56, 86.01 examples/s]Tokenizing train dataset:  45%|████▍     | 3812/8564 [00:41<00:57, 82.16 examples/s]Tokenizing train dataset:  43%|████▎     | 3720/8564 [00:41<00:47, 100.97 examples/s]Tokenizing train dataset:  43%|████▎     | 3655/8564 [00:41<00:55, 88.16 examples/s] Tokenizing train dataset:  45%|████▍     | 3821/8564 [00:41<00:59, 79.69 examples/s]Tokenizing train dataset:  44%|████▎     | 3733/8564 [00:41<00:47, 102.59 examples/s]Tokenizing train dataset:  43%|████▎     | 3668/8564 [00:41<00:58, 84.02 examples/s]Tokenizing train dataset:  44%|████▍     | 3749/8564 [00:42<00:43, 110.98 examples/s]Tokenizing train dataset:  45%|████▍     | 3830/8564 [00:41<01:03, 74.02 examples/s]Tokenizing train dataset:  45%|████▍     | 3843/8564 [00:41<00:58, 81.14 examples/s]Tokenizing train dataset:  44%|████▍     | 3765/8564 [00:42<00:46, 103.57 examples/s]Tokenizing train dataset:  43%|████▎     | 3682/8564 [00:41<01:00, 81.16 examples/s]Tokenizing train dataset:  45%|████▍     | 3852/8564 [00:41<00:57, 81.93 examples/s]Tokenizing train dataset:  43%|████▎     | 3697/8564 [00:41<00:54, 89.91 examples/s]Tokenizing train dataset:  44%|████▍     | 3779/8564 [00:42<00:52, 91.69 examples/s] Tokenizing train dataset:  45%|████▌     | 3866/8564 [00:41<00:52, 90.29 examples/s]Tokenizing train dataset:  43%|████▎     | 3710/8564 [00:41<00:49, 98.37 examples/s]Tokenizing train dataset:  44%|████▍     | 3791/8564 [00:42<00:51, 91.93 examples/s]Tokenizing train dataset:  44%|████▎     | 3726/8564 [00:41<00:43, 112.04 examples/s]Tokenizing train dataset:  45%|████▌     | 3876/8564 [00:42<01:01, 76.61 examples/s]Tokenizing train dataset:  45%|████▌     | 3888/8564 [00:42<00:56, 82.72 examples/s]Tokenizing train dataset:  44%|████▍     | 3803/8564 [00:42<00:56, 83.88 examples/s]Tokenizing train dataset:  44%|████▍     | 3747/8564 [00:41<00:42, 114.45 examples/s]Tokenizing train dataset:  46%|████▌     | 3899/8564 [00:42<00:54, 86.12 examples/s]Tokenizing train dataset:  44%|████▍     | 3762/8564 [00:42<00:39, 120.26 examples/s]Tokenizing train dataset:  45%|████▍     | 3812/8564 [00:42<00:58, 81.85 examples/s]Tokenizing train dataset:  46%|████▌     | 3910/8564 [00:42<00:52, 88.05 examples/s]Tokenizing train dataset:  44%|████▍     | 3775/8564 [00:42<00:40, 118.54 examples/s]Tokenizing train dataset:  45%|████▍     | 3824/8564 [00:43<01:01, 77.50 examples/s]Tokenizing train dataset:  46%|████▌     | 3921/8564 [00:42<00:50, 91.15 examples/s]Tokenizing train dataset:  44%|████▍     | 3789/8564 [00:42<00:38, 122.64 examples/s]Tokenizing train dataset:  45%|████▍     | 3834/8564 [00:43<01:00, 77.95 examples/s]Tokenizing train dataset:  46%|████▌     | 3937/8564 [00:42<00:44, 103.62 examples/s]Tokenizing train dataset:  44%|████▍     | 3807/8564 [00:42<00:40, 118.14 examples/s]Tokenizing train dataset:  46%|████▌     | 3950/8564 [00:42<00:44, 104.71 examples/s]Tokenizing train dataset:  45%|████▍     | 3847/8564 [00:43<01:02, 74.92 examples/s]Tokenizing train dataset:  45%|████▍     | 3820/8564 [00:42<00:40, 115.79 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:42<00:43, 106.78 examples/s]Tokenizing train dataset:  45%|████▍     | 3832/8564 [00:42<00:40, 116.04 examples/s]Tokenizing train dataset:  45%|████▌     | 3855/8564 [00:43<01:04, 73.16 examples/s]Tokenizing train dataset:  46%|████▋     | 3977/8564 [00:42<00:40, 113.76 examples/s]Tokenizing train dataset:  45%|████▍     | 3845/8564 [00:42<00:40, 115.61 examples/s]Tokenizing train dataset:  45%|████▌     | 3865/8564 [00:43<01:01, 76.25 examples/s]Tokenizing train dataset:  47%|████▋     | 3990/8564 [00:43<00:41, 109.44 examples/s]Tokenizing train dataset:  45%|████▌     | 3858/8564 [00:42<00:41, 113.93 examples/s]Tokenizing train dataset:  45%|████▌     | 3875/8564 [00:43<00:59, 78.43 examples/s]Tokenizing train dataset:  47%|████▋     | 4005/8564 [00:43<00:40, 112.51 examples/s]Tokenizing train dataset:  45%|████▌     | 3885/8564 [00:43<00:57, 81.15 examples/s]Tokenizing train dataset:  45%|████▌     | 3876/8564 [00:43<00:39, 120.01 examples/s]Tokenizing train dataset:  46%|████▌     | 3897/8564 [00:43<00:53, 86.75 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:43<00:38, 120.94 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:43<00:45, 99.65 examples/s] Tokenizing train dataset:  46%|████▌     | 3909/8564 [00:44<00:49, 93.65 examples/s]Tokenizing train dataset:  46%|████▌     | 3907/8564 [00:43<00:41, 111.96 examples/s]Tokenizing train dataset:  47%|████▋     | 4033/8564 [00:43<00:46, 97.11 examples/s]Tokenizing train dataset:  46%|████▌     | 3920/8564 [00:44<00:49, 93.29 examples/s]Tokenizing train dataset:  46%|████▌     | 3935/8564 [00:44<00:44, 103.81 examples/s]Tokenizing train dataset:  46%|████▌     | 3924/8564 [00:43<00:42, 108.60 examples/s]Tokenizing train dataset:  47%|████▋     | 4045/8564 [00:43<00:51, 87.97 examples/s]Tokenizing train dataset:  46%|████▌     | 3947/8564 [00:44<00:44, 104.83 examples/s]Tokenizing train dataset:  46%|████▌     | 3939/8564 [00:43<00:40, 114.33 examples/s]Tokenizing train dataset:  47%|████▋     | 4058/8564 [00:43<00:53, 84.74 examples/s]Tokenizing train dataset:  46%|████▋     | 3961/8564 [00:44<00:40, 112.72 examples/s]Tokenizing train dataset:  46%|████▌     | 3959/8564 [00:43<00:38, 118.63 examples/s]Tokenizing train dataset:  46%|████▋     | 3973/8564 [00:44<00:41, 109.56 examples/s]Tokenizing train dataset:  48%|████▊     | 4070/8564 [00:44<00:55, 80.60 examples/s]Tokenizing train dataset:  46%|████▋     | 3972/8564 [00:43<00:39, 115.63 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:44<00:56, 79.11 examples/s]Tokenizing train dataset:  47%|████▋     | 3991/8564 [00:44<00:40, 111.54 examples/s]Tokenizing train dataset:  47%|████▋     | 3989/8564 [00:44<00:40, 113.40 examples/s]Tokenizing train dataset:  47%|████▋     | 4004/8564 [00:44<00:41, 111.13 examples/s]Tokenizing train dataset:  48%|████▊     | 4090/8564 [00:44<00:59, 74.77 examples/s]Tokenizing train dataset:  47%|████▋     | 4001/8564 [00:44<00:40, 113.92 examples/s]Tokenizing train dataset:  47%|████▋     | 4019/8564 [00:45<00:37, 120.17 examples/s]Tokenizing train dataset:  48%|████▊     | 4101/8564 [00:44<00:58, 76.42 examples/s]Tokenizing train dataset:  47%|████▋     | 4016/8564 [00:44<00:45, 99.57 examples/s] Tokenizing train dataset:  47%|████▋     | 4037/8564 [00:45<00:38, 118.22 examples/s]Tokenizing train dataset:  48%|████▊     | 4112/8564 [00:44<00:55, 80.34 examples/s]Tokenizing train dataset:  47%|████▋     | 4050/8564 [00:45<00:38, 118.51 examples/s]Tokenizing train dataset:  47%|████▋     | 4027/8564 [00:44<00:46, 96.98 examples/s]Tokenizing train dataset:  48%|████▊     | 4124/8564 [00:44<00:58, 75.81 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:45<00:37, 118.99 examples/s]Tokenizing train dataset:  47%|████▋     | 4038/8564 [00:44<00:54, 83.58 examples/s]Tokenizing train dataset:  48%|████▊     | 4133/8564 [00:44<00:59, 74.92 examples/s]Tokenizing train dataset:  48%|████▊     | 4078/8564 [00:45<00:36, 124.19 examples/s]Tokenizing train dataset:  47%|████▋     | 4050/8564 [00:44<00:49, 91.17 examples/s]Tokenizing train dataset:  48%|████▊     | 4142/8564 [00:44<01:00, 73.35 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:44<00:45, 98.51 examples/s]Tokenizing train dataset:  48%|████▊     | 4091/8564 [00:45<00:49, 91.23 examples/s] Tokenizing train dataset:  48%|████▊     | 4151/8564 [00:45<00:59, 73.74 examples/s]Tokenizing train dataset:  48%|████▊     | 4078/8564 [00:44<00:42, 106.07 examples/s]Tokenizing train dataset:  49%|████▊     | 4161/8564 [00:45<00:59, 73.92 examples/s]Tokenizing train dataset:  48%|████▊     | 4105/8564 [00:45<00:50, 88.15 examples/s]Tokenizing train dataset:  48%|████▊     | 4090/8564 [00:45<00:43, 102.60 examples/s]Tokenizing train dataset:  49%|████▊     | 4170/8564 [00:45<00:59, 74.23 examples/s]Tokenizing train dataset:  48%|████▊     | 4104/8564 [00:45<00:40, 111.29 examples/s]Tokenizing train dataset:  49%|████▉     | 4183/8564 [00:45<00:52, 83.34 examples/s]Tokenizing train dataset:  48%|████▊     | 4117/8564 [00:45<00:40, 110.29 examples/s]Tokenizing train dataset:  48%|████▊     | 4122/8564 [00:46<00:57, 76.61 examples/s]Tokenizing train dataset:  49%|████▉     | 4196/8564 [00:45<00:47, 92.58 examples/s]Tokenizing train dataset:  48%|████▊     | 4134/8564 [00:46<00:55, 80.27 examples/s]Tokenizing train dataset:  49%|████▉     | 4208/8564 [00:45<00:44, 98.16 examples/s]Tokenizing train dataset:  48%|████▊     | 4132/8564 [00:45<00:47, 94.10 examples/s] Tokenizing train dataset:  48%|████▊     | 4149/8564 [00:46<00:49, 89.84 examples/s]Tokenizing train dataset:  48%|████▊     | 4146/8564 [00:45<00:44, 100.11 examples/s]Tokenizing train dataset:  49%|████▉     | 4220/8564 [00:45<00:52, 83.07 examples/s]Tokenizing train dataset:  49%|████▊     | 4160/8564 [00:46<00:48, 91.08 examples/s]Tokenizing train dataset:  49%|████▊     | 4157/8564 [00:45<00:49, 88.57 examples/s] Tokenizing train dataset:  49%|████▉     | 4230/8564 [00:46<00:50, 85.74 examples/s]Tokenizing train dataset:  49%|████▊     | 4171/8564 [00:46<00:47, 92.48 examples/s]Tokenizing train dataset:  49%|████▉     | 4188/8564 [00:46<00:40, 107.78 examples/s]Tokenizing train dataset:  50%|████▉     | 4240/8564 [00:46<00:52, 81.85 examples/s]Tokenizing train dataset:  49%|████▊     | 4170/8564 [00:45<00:51, 85.68 examples/s]Tokenizing train dataset:  49%|████▉     | 4202/8564 [00:46<00:38, 114.49 examples/s]Tokenizing train dataset:  50%|████▉     | 4249/8564 [00:46<00:54, 79.33 examples/s]Tokenizing train dataset:  49%|████▉     | 4180/8564 [00:46<00:51, 84.34 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:46<00:52, 82.49 examples/s]Tokenizing train dataset:  49%|████▉     | 4189/8564 [00:46<00:52, 83.51 examples/s]Tokenizing train dataset:  49%|████▉     | 4220/8564 [00:47<00:38, 112.19 examples/s]Tokenizing train dataset:  50%|████▉     | 4269/8564 [00:46<00:52, 82.09 examples/s]Tokenizing train dataset:  49%|████▉     | 4201/8564 [00:46<00:49, 87.83 examples/s]Tokenizing train dataset:  49%|████▉     | 4234/8564 [00:47<00:37, 114.51 examples/s]Tokenizing train dataset:  49%|████▉     | 4210/8564 [00:46<00:51, 84.20 examples/s]Tokenizing train dataset:  50%|████▉     | 4247/8564 [00:47<00:38, 112.24 examples/s]Tokenizing train dataset:  50%|████▉     | 4280/8564 [00:46<00:53, 79.48 examples/s]Tokenizing train dataset:  49%|████▉     | 4219/8564 [00:46<00:54, 80.33 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:47<00:38, 112.11 examples/s]Tokenizing train dataset:  50%|█████     | 4290/8564 [00:46<00:54, 78.06 examples/s]Tokenizing train dataset:  50%|████▉     | 4274/8564 [00:47<00:36, 117.49 examples/s]Tokenizing train dataset:  49%|████▉     | 4229/8564 [00:46<00:54, 79.72 examples/s]Tokenizing train dataset:  50%|█████     | 4299/8564 [00:46<01:00, 70.87 examples/s]Tokenizing train dataset:  50%|█████     | 4286/8564 [00:47<00:37, 113.49 examples/s]Tokenizing train dataset:  49%|████▉     | 4239/8564 [00:46<00:54, 79.62 examples/s]Tokenizing train dataset:  50%|█████     | 4309/8564 [00:47<00:57, 73.69 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:47<00:37, 113.95 examples/s]Tokenizing train dataset:  50%|████▉     | 4248/8564 [00:46<00:58, 73.88 examples/s]Tokenizing train dataset:  50%|█████     | 4318/8564 [00:47<00:55, 76.90 examples/s]Tokenizing train dataset:  50%|█████     | 4315/8564 [00:47<00:36, 116.22 examples/s]Tokenizing train dataset:  50%|████▉     | 4258/8564 [00:47<00:55, 78.24 examples/s]Tokenizing train dataset:  51%|█████     | 4326/8564 [00:47<00:56, 74.41 examples/s]Tokenizing train dataset:  51%|█████     | 4328/8564 [00:48<00:35, 119.33 examples/s]Tokenizing train dataset:  50%|████▉     | 4268/8564 [00:47<00:51, 83.17 examples/s]Tokenizing train dataset:  51%|█████     | 4335/8564 [00:47<00:59, 70.62 examples/s]Tokenizing train dataset:  50%|█████     | 4282/8564 [00:47<00:45, 94.60 examples/s]Tokenizing train dataset:  51%|█████     | 4344/8564 [00:48<00:41, 101.62 examples/s]Tokenizing train dataset:  51%|█████     | 4347/8564 [00:47<00:52, 79.69 examples/s]Tokenizing train dataset:  50%|█████     | 4293/8564 [00:47<00:43, 97.68 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:47<00:45, 92.44 examples/s]Tokenizing train dataset:  50%|█████     | 4308/8564 [00:47<00:39, 107.39 examples/s]Tokenizing train dataset:  51%|█████     | 4359/8564 [00:48<00:45, 92.62 examples/s] Tokenizing train dataset:  51%|█████     | 4377/8564 [00:47<00:39, 104.87 examples/s]Tokenizing train dataset:  51%|█████     | 4369/8564 [00:48<00:46, 90.47 examples/s]Tokenizing train dataset:  51%|█████     | 4328/8564 [00:47<00:38, 111.23 examples/s]Tokenizing train dataset:  51%|█████▏    | 4392/8564 [00:47<00:38, 108.45 examples/s]Tokenizing train dataset:  51%|█████     | 4379/8564 [00:48<00:48, 85.58 examples/s]Tokenizing train dataset:  51%|█████▏    | 4403/8564 [00:48<00:41, 100.61 examples/s]Tokenizing train dataset:  51%|█████     | 4346/8564 [00:47<00:39, 108.03 examples/s]Tokenizing train dataset:  51%|█████     | 4388/8564 [00:48<00:49, 83.97 examples/s]Tokenizing train dataset:  51%|█████     | 4360/8564 [00:47<00:36, 115.00 examples/s]Tokenizing train dataset:  51%|█████▏    | 4400/8564 [00:48<00:46, 89.13 examples/s]Tokenizing train dataset:  52%|█████▏    | 4419/8564 [00:48<00:48, 85.27 examples/s] Tokenizing train dataset:  51%|█████     | 4375/8564 [00:48<00:35, 117.08 examples/s]Tokenizing train dataset:  52%|█████▏    | 4411/8564 [00:49<00:48, 85.85 examples/s]Tokenizing train dataset:  52%|█████▏    | 4430/8564 [00:48<00:46, 88.00 examples/s]Tokenizing train dataset:  51%|█████▏    | 4390/8564 [00:48<00:40, 103.20 examples/s]Tokenizing train dataset:  52%|█████▏    | 4425/8564 [00:49<00:43, 95.27 examples/s]Tokenizing train dataset:  52%|█████▏    | 4445/8564 [00:48<00:41, 99.44 examples/s]Tokenizing train dataset:  52%|█████▏    | 4438/8564 [00:49<00:39, 103.71 examples/s]Tokenizing train dataset:  52%|█████▏    | 4456/8564 [00:48<00:40, 101.35 examples/s]Tokenizing train dataset:  51%|█████▏    | 4402/8564 [00:48<00:42, 98.23 examples/s] Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:49<00:40, 101.32 examples/s]Tokenizing train dataset:  52%|█████▏    | 4471/8564 [00:48<00:38, 105.78 examples/s]Tokenizing train dataset:  52%|█████▏    | 4465/8564 [00:49<00:38, 106.44 examples/s]Tokenizing train dataset:  52%|█████▏    | 4420/8564 [00:48<00:47, 87.28 examples/s]Tokenizing train dataset:  52%|█████▏    | 4486/8564 [00:48<00:43, 94.83 examples/s] Tokenizing train dataset:  52%|█████▏    | 4481/8564 [00:49<00:36, 113.06 examples/s]Tokenizing train dataset:  52%|█████▏    | 4433/8564 [00:48<00:50, 81.80 examples/s]Tokenizing train dataset:  52%|█████▏    | 4494/8564 [00:49<00:36, 112.08 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:49<00:47, 85.16 examples/s]Tokenizing train dataset:  52%|█████▏    | 4443/8564 [00:48<00:50, 81.21 examples/s]Tokenizing train dataset:  53%|█████▎    | 4507/8564 [00:49<00:36, 111.14 examples/s]Tokenizing train dataset:  52%|█████▏    | 4453/8564 [00:49<00:51, 80.54 examples/s]Tokenizing train dataset:  53%|█████▎    | 4520/8564 [00:49<00:35, 114.50 examples/s]Tokenizing train dataset:  53%|█████▎    | 4510/8564 [00:49<00:52, 76.65 examples/s]Tokenizing train dataset:  53%|█████▎    | 4534/8564 [00:50<00:34, 116.46 examples/s]Tokenizing train dataset:  53%|█████▎    | 4522/8564 [00:49<00:51, 79.17 examples/s]Tokenizing train dataset:  52%|█████▏    | 4467/8564 [00:49<00:52, 77.55 examples/s]Tokenizing train dataset:  53%|█████▎    | 4546/8564 [00:50<00:34, 116.34 examples/s]Tokenizing train dataset:  53%|█████▎    | 4532/8564 [00:49<00:51, 78.69 examples/s]Tokenizing train dataset:  52%|█████▏    | 4478/8564 [00:49<00:50, 80.55 examples/s]Tokenizing train dataset:  53%|█████▎    | 4560/8564 [00:50<00:33, 118.79 examples/s]Tokenizing train dataset:  53%|█████▎    | 4542/8564 [00:49<00:50, 80.31 examples/s]Tokenizing train dataset:  53%|█████▎    | 4576/8564 [00:50<00:35, 112.86 examples/s]Tokenizing train dataset:  52%|█████▏    | 4490/8564 [00:49<00:53, 75.98 examples/s]Tokenizing train dataset:  53%|█████▎    | 4552/8564 [00:49<00:49, 80.85 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:49<00:53, 76.15 examples/s]Tokenizing train dataset:  53%|█████▎    | 4562/8564 [00:49<00:50, 78.69 examples/s]Tokenizing train dataset:  54%|█████▎    | 4594/8564 [00:50<00:35, 111.45 examples/s]Tokenizing train dataset:  54%|█████▍    | 4609/8564 [00:50<00:34, 114.67 examples/s]Tokenizing train dataset:  53%|█████▎    | 4510/8564 [00:49<00:56, 71.43 examples/s]Tokenizing train dataset:  53%|█████▎    | 4570/8564 [00:50<00:56, 71.28 examples/s]Tokenizing train dataset:  53%|█████▎    | 4519/8564 [00:50<00:56, 71.92 examples/s]Tokenizing train dataset:  54%|█████▍    | 4627/8564 [00:50<00:34, 113.79 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:50<00:56, 71.10 examples/s]Tokenizing train dataset:  53%|█████▎    | 4529/8564 [00:50<00:56, 72.04 examples/s]Tokenizing train dataset:  54%|█████▎    | 4590/8564 [00:50<00:54, 72.62 examples/s]Tokenizing train dataset:  54%|█████▍    | 4642/8564 [00:51<00:36, 107.67 examples/s]Tokenizing train dataset:  54%|█████▎    | 4598/8564 [00:50<00:55, 71.55 examples/s]Tokenizing train dataset:  53%|█████▎    | 4540/8564 [00:50<00:54, 73.59 examples/s]Tokenizing train dataset:  54%|█████▍    | 4655/8564 [00:51<00:35, 109.31 examples/s]Tokenizing train dataset:  53%|█████▎    | 4555/8564 [00:50<00:44, 89.88 examples/s]Tokenizing train dataset:  54%|█████▍    | 4667/8564 [00:51<00:36, 106.74 examples/s]Tokenizing train dataset:  54%|█████▍    | 4610/8564 [00:50<00:54, 72.91 examples/s]Tokenizing train dataset:  55%|█████▍    | 4678/8564 [00:51<00:36, 106.16 examples/s]Tokenizing train dataset:  54%|█████▍    | 4624/8564 [00:50<00:44, 87.94 examples/s]Tokenizing train dataset:  53%|█████▎    | 4569/8564 [00:50<00:48, 82.82 examples/s]Tokenizing train dataset:  55%|█████▍    | 4690/8564 [00:51<00:38, 101.66 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:50<00:48, 82.13 examples/s]Tokenizing train dataset:  54%|█████▍    | 4638/8564 [00:50<00:47, 82.61 examples/s]Tokenizing train dataset:  55%|█████▍    | 4706/8564 [00:51<00:39, 97.74 examples/s] Tokenizing train dataset:  54%|█████▎    | 4591/8564 [00:50<00:49, 81.04 examples/s]Tokenizing train dataset:  54%|█████▍    | 4649/8564 [00:51<00:51, 76.57 examples/s]Tokenizing train dataset:  55%|█████▌    | 4717/8564 [00:51<00:38, 99.36 examples/s]Tokenizing train dataset:  54%|█████▎    | 4603/8564 [00:50<00:44, 89.18 examples/s]Tokenizing train dataset:  54%|█████▍    | 4658/8564 [00:51<00:51, 75.22 examples/s]Tokenizing train dataset:  55%|█████▌    | 4729/8564 [00:51<00:36, 104.25 examples/s]Tokenizing train dataset:  54%|█████▍    | 4615/8564 [00:51<00:41, 96.09 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:52<00:36, 104.87 examples/s]Tokenizing train dataset:  54%|█████▍    | 4631/8564 [00:51<00:38, 102.16 examples/s]Tokenizing train dataset:  55%|█████▍    | 4671/8564 [00:51<00:54, 71.85 examples/s]Tokenizing train dataset:  56%|█████▌    | 4754/8564 [00:52<00:40, 94.01 examples/s] Tokenizing train dataset:  55%|█████▍    | 4680/8564 [00:51<00:51, 74.93 examples/s]Tokenizing train dataset:  54%|█████▍    | 4643/8564 [00:51<00:38, 101.35 examples/s]Tokenizing train dataset:  55%|█████▍    | 4691/8564 [00:51<00:46, 82.57 examples/s]Tokenizing train dataset:  56%|█████▌    | 4766/8564 [00:52<00:39, 95.91 examples/s]Tokenizing train dataset:  55%|█████▍    | 4701/8564 [00:51<00:46, 83.60 examples/s]Tokenizing train dataset:  54%|█████▍    | 4657/8564 [00:51<00:46, 84.87 examples/s] Tokenizing train dataset:  56%|█████▌    | 4782/8564 [00:52<00:40, 94.46 examples/s]Tokenizing train dataset:  55%|█████▌    | 4712/8564 [00:51<00:44, 86.57 examples/s]Tokenizing train dataset:  56%|█████▌    | 4796/8564 [00:52<00:37, 101.01 examples/s]Tokenizing train dataset:  55%|█████▍    | 4670/8564 [00:51<00:50, 77.65 examples/s]Tokenizing train dataset:  55%|█████▌    | 4725/8564 [00:51<00:40, 95.73 examples/s]Tokenizing train dataset:  56%|█████▌    | 4816/8564 [00:52<00:30, 121.38 examples/s]Tokenizing train dataset:  55%|█████▌    | 4737/8564 [00:52<00:37, 100.92 examples/s]Tokenizing train dataset:  56%|█████▋    | 4835/8564 [00:52<00:26, 138.18 examples/s]Tokenizing train dataset:  55%|█████▍    | 4684/8564 [00:51<00:52, 73.78 examples/s]Tokenizing train dataset:  57%|█████▋    | 4855/8564 [00:52<00:24, 154.17 examples/s]Tokenizing train dataset:  55%|█████▌    | 4750/8564 [00:52<00:42, 90.08 examples/s] Tokenizing train dataset:  55%|█████▍    | 4697/8564 [00:52<00:51, 74.46 examples/s]Tokenizing train dataset:  57%|█████▋    | 4874/8564 [00:53<00:23, 155.18 examples/s]Tokenizing train dataset:  56%|█████▌    | 4763/8564 [00:52<00:45, 83.50 examples/s]Tokenizing train dataset:  57%|█████▋    | 4894/8564 [00:53<00:22, 164.17 examples/s]Tokenizing train dataset:  55%|█████▍    | 4709/8564 [00:52<00:53, 71.67 examples/s]Tokenizing train dataset:  56%|█████▌    | 4772/8564 [00:52<00:46, 81.77 examples/s]Tokenizing train dataset:  57%|█████▋    | 4916/8564 [00:53<00:21, 172.34 examples/s]Tokenizing train dataset:  55%|█████▌    | 4718/8564 [00:52<00:55, 69.92 examples/s]Tokenizing train dataset:  56%|█████▌    | 4783/8564 [00:52<00:43, 86.90 examples/s]Tokenizing train dataset:  58%|█████▊    | 4941/8564 [00:53<00:19, 183.77 examples/s]Tokenizing train dataset:  56%|█████▌    | 4799/8564 [00:52<00:37, 101.55 examples/s]Tokenizing train dataset:  58%|█████▊    | 4960/8564 [00:53<00:19, 183.74 examples/s]Tokenizing train dataset:  55%|█████▌    | 4730/8564 [00:52<00:53, 71.12 examples/s]Tokenizing train dataset:  56%|█████▋    | 4822/8564 [00:52<00:29, 126.78 examples/s]Tokenizing train dataset:  58%|█████▊    | 4984/8564 [00:53<00:18, 189.91 examples/s]Tokenizing train dataset:  55%|█████▌    | 4739/8564 [00:52<00:53, 71.34 examples/s]Tokenizing train dataset:  57%|█████▋    | 4849/8564 [00:53<00:23, 159.34 examples/s]Tokenizing train dataset:  58%|█████▊    | 5008/8564 [00:53<00:18, 194.39 examples/s]Tokenizing train dataset:  55%|█████▌    | 4750/8564 [00:52<00:58, 65.56 examples/s]Tokenizing train dataset:  57%|█████▋    | 4877/8564 [00:53<00:22, 163.40 examples/s]Tokenizing train dataset:  59%|█████▉    | 5033/8564 [00:53<00:19, 177.55 examples/s]Tokenizing train dataset:  57%|█████▋    | 4895/8564 [00:53<00:22, 166.29 examples/s]Tokenizing train dataset:  56%|█████▌    | 4760/8564 [00:53<00:59, 64.17 examples/s]Tokenizing train dataset:  59%|█████▉    | 5060/8564 [00:53<00:17, 198.36 examples/s]Tokenizing train dataset:  57%|█████▋    | 4916/8564 [00:53<00:20, 176.92 examples/s]Tokenizing train dataset:  59%|█████▉    | 5085/8564 [00:54<00:16, 209.57 examples/s]Tokenizing train dataset:  56%|█████▌    | 4767/8564 [00:53<00:59, 63.30 examples/s]Tokenizing train dataset:  58%|█████▊    | 4940/8564 [00:53<00:19, 184.89 examples/s]Tokenizing train dataset:  60%|█████▉    | 5116/8564 [00:54<00:16, 204.04 examples/s]Tokenizing train dataset:  56%|█████▌    | 4777/8564 [00:53<01:01, 61.69 examples/s]Tokenizing train dataset:  58%|█████▊    | 4960/8564 [00:53<00:19, 184.47 examples/s]Tokenizing train dataset:  56%|█████▌    | 4787/8564 [00:53<00:54, 69.44 examples/s]Tokenizing train dataset:  58%|█████▊    | 4981/8564 [00:53<00:18, 190.89 examples/s]Tokenizing train dataset:  60%|██████    | 5143/8564 [00:54<00:16, 207.26 examples/s]Tokenizing train dataset:  60%|██████    | 5169/8564 [00:54<00:15, 220.09 examples/s]Tokenizing train dataset:  58%|█████▊    | 5007/8564 [00:53<00:17, 201.33 examples/s]Tokenizing train dataset:  56%|█████▌    | 4803/8564 [00:53<00:47, 78.82 examples/s]Tokenizing train dataset:  56%|█████▌    | 4816/8564 [00:53<00:41, 89.25 examples/s]Tokenizing train dataset:  61%|██████    | 5201/8564 [00:54<00:19, 174.28 examples/s]Tokenizing train dataset:  59%|█████▊    | 5030/8564 [00:54<00:24, 145.18 examples/s]Tokenizing train dataset:  57%|█████▋    | 4839/8564 [00:53<00:33, 111.69 examples/s]Tokenizing train dataset:  61%|██████    | 5226/8564 [00:54<00:17, 187.06 examples/s]Tokenizing train dataset:  59%|█████▉    | 5047/8564 [00:54<00:24, 143.06 examples/s]Tokenizing train dataset:  57%|█████▋    | 4856/8564 [00:54<00:31, 116.03 examples/s]Tokenizing train dataset:  61%|██████▏   | 5250/8564 [00:54<00:16, 197.10 examples/s]Tokenizing train dataset:  57%|█████▋    | 4869/8564 [00:54<00:32, 113.40 examples/s]Tokenizing train dataset:  62%|██████▏   | 5282/8564 [00:55<00:15, 217.92 examples/s]Tokenizing train dataset:  59%|█████▉    | 5072/8564 [00:54<00:25, 138.43 examples/s]Tokenizing train dataset:  59%|█████▉    | 5089/8564 [00:54<00:24, 140.07 examples/s]Tokenizing train dataset:  57%|█████▋    | 4884/8564 [00:54<00:36, 102.03 examples/s]Tokenizing train dataset:  62%|██████▏   | 5310/8564 [00:55<00:16, 200.83 examples/s]Tokenizing train dataset:  60%|█████▉    | 5107/8564 [00:54<00:24, 138.44 examples/s]Tokenizing train dataset:  57%|█████▋    | 4909/8564 [00:54<00:27, 133.73 examples/s]Tokenizing train dataset:  62%|██████▏   | 5337/8564 [00:55<00:18, 178.37 examples/s]Tokenizing train dataset:  60%|█████▉    | 5123/8564 [00:54<00:24, 141.94 examples/s]Tokenizing train dataset:  58%|█████▊    | 4931/8564 [00:54<00:23, 151.64 examples/s]Tokenizing train dataset:  63%|██████▎   | 5360/8564 [00:55<00:17, 181.77 examples/s]Tokenizing train dataset:  60%|██████    | 5147/8564 [00:54<00:24, 140.65 examples/s]Tokenizing train dataset:  58%|█████▊    | 4950/8564 [00:54<00:27, 129.40 examples/s]Tokenizing train dataset:  63%|██████▎   | 5387/8564 [00:55<00:18, 176.00 examples/s]Tokenizing train dataset:  60%|██████    | 5170/8564 [00:55<00:23, 146.99 examples/s]Tokenizing train dataset:  58%|█████▊    | 4970/8564 [00:54<00:25, 140.00 examples/s]Tokenizing train dataset:  61%|██████    | 5193/8564 [00:55<00:20, 164.66 examples/s]Tokenizing train dataset:  58%|█████▊    | 4993/8564 [00:54<00:22, 159.76 examples/s]Tokenizing train dataset:  63%|██████▎   | 5409/8564 [00:55<00:21, 148.04 examples/s]Tokenizing train dataset:  61%|██████    | 5216/8564 [00:55<00:18, 180.23 examples/s]Tokenizing train dataset:  59%|█████▊    | 5015/8564 [00:55<00:20, 172.37 examples/s]Tokenizing train dataset:  61%|██████    | 5235/8564 [00:55<00:19, 174.31 examples/s]Tokenizing train dataset:  63%|██████▎   | 5434/8564 [00:56<00:21, 146.74 examples/s]Tokenizing train dataset:  59%|█████▉    | 5047/8564 [00:55<00:20, 174.20 examples/s]Tokenizing train dataset:  61%|██████▏   | 5263/8564 [00:55<00:16, 201.19 examples/s]Tokenizing train dataset:  64%|██████▎   | 5453/8564 [00:56<00:21, 144.36 examples/s]Tokenizing train dataset:  59%|█████▉    | 5074/8564 [00:55<00:18, 193.12 examples/s]Tokenizing train dataset:  62%|██████▏   | 5287/8564 [00:55<00:18, 174.62 examples/s]Tokenizing train dataset:  59%|█████▉    | 5095/8564 [00:55<00:17, 195.80 examples/s]Tokenizing train dataset:  64%|██████▍   | 5471/8564 [00:56<00:24, 128.16 examples/s]Tokenizing train dataset:  60%|█████▉    | 5116/8564 [00:55<00:17, 194.18 examples/s]Tokenizing train dataset:  64%|██████▍   | 5485/8564 [00:56<00:23, 129.62 examples/s]Tokenizing train dataset:  62%|██████▏   | 5312/8564 [00:55<00:20, 155.36 examples/s]Tokenizing train dataset:  60%|██████    | 5139/8564 [00:55<00:16, 201.79 examples/s]Tokenizing train dataset:  64%|██████▍   | 5500/8564 [00:56<00:24, 126.85 examples/s]Tokenizing train dataset:  60%|██████    | 5167/8564 [00:55<00:15, 214.86 examples/s]Tokenizing train dataset:  62%|██████▏   | 5332/8564 [00:56<00:23, 139.93 examples/s]Tokenizing train dataset:  64%|██████▍   | 5516/8564 [00:56<00:23, 127.23 examples/s]Tokenizing train dataset:  61%|██████    | 5200/8564 [00:55<00:15, 213.71 examples/s]Tokenizing train dataset:  62%|██████▏   | 5350/8564 [00:56<00:23, 138.76 examples/s]Tokenizing train dataset:  65%|██████▍   | 5533/8564 [00:56<00:23, 128.13 examples/s]Tokenizing train dataset:  61%|██████    | 5225/8564 [00:56<00:15, 215.87 examples/s]Tokenizing train dataset:  63%|██████▎   | 5366/8564 [00:56<00:23, 133.28 examples/s]Tokenizing train dataset:  65%|██████▍   | 5549/8564 [00:57<00:24, 125.56 examples/s]Tokenizing train dataset:  61%|██████▏   | 5249/8564 [00:56<00:15, 220.38 examples/s]Tokenizing train dataset:  63%|██████▎   | 5381/8564 [00:56<00:25, 126.46 examples/s]Tokenizing train dataset:  62%|██████▏   | 5279/8564 [00:56<00:14, 232.99 examples/s]Tokenizing train dataset:  65%|██████▌   | 5572/8564 [00:57<00:24, 121.79 examples/s]Tokenizing train dataset:  63%|██████▎   | 5394/8564 [00:56<00:26, 118.49 examples/s]Tokenizing train dataset:  62%|██████▏   | 5309/8564 [00:56<00:15, 216.93 examples/s]Tokenizing train dataset:  65%|██████▌   | 5593/8564 [00:57<00:22, 131.86 examples/s]Tokenizing train dataset:  63%|██████▎   | 5407/8564 [00:56<00:26, 117.42 examples/s]Tokenizing train dataset:  62%|██████▏   | 5340/8564 [00:56<00:15, 204.39 examples/s]Tokenizing train dataset:  63%|██████▎   | 5431/8564 [00:56<00:22, 139.36 examples/s]Tokenizing train dataset:  66%|██████▌   | 5610/8564 [00:57<00:23, 125.07 examples/s]Tokenizing train dataset:  63%|██████▎   | 5366/8564 [00:56<00:15, 209.08 examples/s]Tokenizing train dataset:  66%|██████▌   | 5634/8564 [00:57<00:19, 150.22 examples/s]Tokenizing train dataset:  64%|██████▎   | 5451/8564 [00:56<00:23, 132.65 examples/s]Tokenizing train dataset:  66%|██████▌   | 5658/8564 [00:57<00:17, 165.60 examples/s]Tokenizing train dataset:  63%|██████▎   | 5396/8564 [00:56<00:16, 192.97 examples/s]Tokenizing train dataset:  66%|██████▋   | 5677/8564 [00:57<00:17, 167.45 examples/s]Tokenizing train dataset:  64%|██████▍   | 5466/8564 [00:57<00:27, 111.85 examples/s]Tokenizing train dataset:  67%|██████▋   | 5698/8564 [00:57<00:16, 176.01 examples/s]Tokenizing train dataset:  63%|██████▎   | 5437/8564 [00:57<00:14, 208.60 examples/s]Tokenizing train dataset:  64%|██████▍   | 5483/8564 [00:57<00:25, 120.21 examples/s]Tokenizing train dataset:  64%|██████▍   | 5500/8564 [00:57<00:24, 125.13 examples/s]Tokenizing train dataset:  64%|██████▍   | 5464/8564 [00:57<00:15, 197.48 examples/s]Tokenizing train dataset:  67%|██████▋   | 5724/8564 [00:58<00:17, 161.08 examples/s]Tokenizing train dataset:  64%|██████▍   | 5514/8564 [00:57<00:24, 123.70 examples/s]Tokenizing train dataset:  64%|██████▍   | 5492/8564 [00:57<00:16, 189.94 examples/s]Tokenizing train dataset:  67%|██████▋   | 5744/8564 [00:58<00:19, 143.37 examples/s]Tokenizing train dataset:  65%|██████▍   | 5530/8564 [00:57<00:24, 125.39 examples/s]Tokenizing train dataset:  64%|██████▍   | 5514/8564 [00:57<00:15, 194.78 examples/s]Tokenizing train dataset:  67%|██████▋   | 5766/8564 [00:58<00:18, 150.55 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:57<00:24, 125.13 examples/s]Tokenizing train dataset:  65%|██████▍   | 5534/8564 [00:57<00:15, 194.69 examples/s]Tokenizing train dataset:  68%|██████▊   | 5786/8564 [00:58<00:17, 154.98 examples/s]Tokenizing train dataset:  65%|██████▍   | 5564/8564 [00:57<00:26, 114.42 examples/s]Tokenizing train dataset:  65%|██████▍   | 5564/8564 [00:57<00:16, 181.93 examples/s]Tokenizing train dataset:  68%|██████▊   | 5809/8564 [00:58<00:17, 159.00 examples/s]Tokenizing train dataset:  65%|██████▌   | 5589/8564 [00:57<00:15, 196.83 examples/s]Tokenizing train dataset:  65%|██████▌   | 5582/8564 [00:58<00:24, 122.57 examples/s]Tokenizing train dataset:  68%|██████▊   | 5830/8564 [00:58<00:18, 143.93 examples/s]Tokenizing train dataset:  66%|██████▌   | 5615/8564 [00:58<00:14, 203.84 examples/s]Tokenizing train dataset:  65%|██████▌   | 5602/8564 [00:58<00:22, 131.52 examples/s]Tokenizing train dataset:  66%|██████▌   | 5636/8564 [00:58<00:14, 203.04 examples/s]Tokenizing train dataset:  68%|██████▊   | 5847/8564 [00:59<00:19, 136.74 examples/s]Tokenizing train dataset:  66%|██████▌   | 5620/8564 [00:58<00:22, 131.03 examples/s]Tokenizing train dataset:  66%|██████▌   | 5662/8564 [00:58<00:13, 208.33 examples/s]Tokenizing train dataset:  66%|██████▌   | 5640/8564 [00:58<00:21, 137.81 examples/s]Tokenizing train dataset:  68%|██████▊   | 5866/8564 [00:59<00:22, 122.38 examples/s]Tokenizing train dataset:  66%|██████▋   | 5692/8564 [00:58<00:14, 202.87 examples/s]Tokenizing train dataset:  66%|██████▌   | 5659/8564 [00:58<00:20, 139.46 examples/s]Tokenizing train dataset:  69%|██████▊   | 5879/8564 [00:59<00:22, 120.07 examples/s]Tokenizing train dataset:  67%|██████▋   | 5715/8564 [00:58<00:13, 208.50 examples/s]Tokenizing train dataset:  66%|██████▋   | 5680/8564 [00:58<00:21, 136.48 examples/s]Tokenizing train dataset:  69%|██████▉   | 5892/8564 [00:59<00:24, 110.56 examples/s]Tokenizing train dataset:  67%|██████▋   | 5748/8564 [00:58<00:14, 199.32 examples/s]Tokenizing train dataset:  67%|██████▋   | 5696/8564 [00:58<00:20, 137.89 examples/s]Tokenizing train dataset:  69%|██████▉   | 5916/8564 [00:59<00:19, 138.79 examples/s]Tokenizing train dataset:  68%|██████▊   | 5791/8564 [00:58<00:10, 253.28 examples/s]Tokenizing train dataset:  67%|██████▋   | 5710/8564 [00:59<00:23, 123.18 examples/s]Tokenizing train dataset:  68%|██████▊   | 5826/8564 [00:58<00:11, 240.01 examples/s]Tokenizing train dataset:  69%|██████▉   | 5943/8564 [00:59<00:20, 127.44 examples/s]Tokenizing train dataset:  67%|██████▋   | 5727/8564 [00:59<00:23, 122.56 examples/s]Tokenizing train dataset:  67%|██████▋   | 5743/8564 [00:59<00:22, 126.80 examples/s]Tokenizing train dataset:  70%|██████▉   | 5965/8564 [00:59<00:20, 128.69 examples/s]Tokenizing train dataset:  68%|██████▊   | 5853/8564 [00:59<00:13, 204.65 examples/s]Tokenizing train dataset:  67%|██████▋   | 5763/8564 [00:59<00:20, 139.27 examples/s]Tokenizing train dataset:  69%|██████▊   | 5882/8564 [00:59<00:13, 199.28 examples/s]Tokenizing train dataset:  68%|██████▊   | 5781/8564 [00:59<00:19, 139.49 examples/s]Tokenizing train dataset:  69%|██████▉   | 5904/8564 [00:59<00:13, 197.67 examples/s]Tokenizing train dataset:  68%|██████▊   | 5801/8564 [00:59<00:17, 154.21 examples/s]Tokenizing train dataset:  69%|██████▉   | 5935/8564 [00:59<00:12, 205.34 examples/s]Tokenizing train dataset:  68%|██████▊   | 5827/8564 [00:59<00:15, 171.21 examples/s]Tokenizing train dataset:  70%|██████▉   | 5957/8564 [00:59<00:12, 206.67 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [01:00<00:37, 69.83 examples/s] Tokenizing train dataset:  68%|██████▊   | 5846/8564 [00:59<00:18, 145.06 examples/s]Tokenizing train dataset:  70%|███████   | 6014/8564 [01:00<00:24, 104.32 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [00:59<00:16, 161.21 examples/s]Tokenizing train dataset:  68%|██████▊   | 5863/8564 [01:00<00:18, 149.56 examples/s]Tokenizing train dataset:  70%|███████   | 6032/8564 [01:00<00:22, 112.00 examples/s]Tokenizing train dataset:  69%|██████▉   | 5888/8564 [01:00<00:16, 162.27 examples/s]Tokenizing train dataset:  71%|███████   | 6058/8564 [01:00<00:18, 135.43 examples/s]Tokenizing train dataset:  70%|███████   | 6001/8564 [01:00<00:16, 150.80 examples/s]Tokenizing train dataset:  69%|██████▉   | 5915/8564 [01:00<00:14, 180.16 examples/s]Tokenizing train dataset:  70%|███████   | 6019/8564 [01:00<00:16, 153.80 examples/s]Tokenizing train dataset:  69%|██████▉   | 5937/8564 [01:00<00:14, 181.49 examples/s]Tokenizing train dataset:  71%|███████   | 6081/8564 [01:01<00:19, 125.06 examples/s]Tokenizing train dataset:  71%|███████   | 6043/8564 [01:00<00:17, 143.32 examples/s]Tokenizing train dataset:  71%|███████▏  | 6102/8564 [01:01<00:18, 134.67 examples/s]Tokenizing train dataset:  70%|██████▉   | 5961/8564 [01:00<00:16, 162.37 examples/s]Tokenizing train dataset:  71%|███████   | 6062/8564 [01:00<00:17, 145.58 examples/s]Tokenizing train dataset:  72%|███████▏  | 6130/8564 [01:01<00:15, 160.56 examples/s]Tokenizing train dataset:  72%|███████▏  | 6175/8564 [01:01<00:10, 222.75 examples/s]Tokenizing train dataset:  71%|███████   | 6081/8564 [01:00<00:16, 150.47 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [01:00<00:20, 128.38 examples/s]Tokenizing train dataset:  72%|███████▏  | 6202/8564 [01:01<00:10, 233.27 examples/s]Tokenizing train dataset:  70%|███████   | 6005/8564 [01:00<00:16, 152.24 examples/s]Tokenizing train dataset:  71%|███████▏  | 6102/8564 [01:00<00:19, 129.51 examples/s]Tokenizing train dataset:  70%|███████   | 6023/8564 [01:01<00:16, 153.74 examples/s]Tokenizing train dataset:  73%|███████▎  | 6233/8564 [01:01<00:11, 200.34 examples/s]Tokenizing train dataset:  71%|███████▏  | 6120/8564 [01:00<00:18, 130.85 examples/s]Tokenizing train dataset:  71%|███████   | 6048/8564 [01:01<00:14, 175.42 examples/s]Tokenizing train dataset:  72%|███████▏  | 6143/8564 [01:01<00:16, 145.29 examples/s]Tokenizing train dataset:  73%|███████▎  | 6258/8564 [01:01<00:12, 179.14 examples/s]Tokenizing train dataset:  71%|███████   | 6070/8564 [01:01<00:13, 184.30 examples/s]Tokenizing train dataset:  72%|███████▏  | 6175/8564 [01:01<00:15, 152.49 examples/s]Tokenizing train dataset:  71%|███████   | 6094/8564 [01:01<00:14, 165.63 examples/s]Tokenizing train dataset:  73%|███████▎  | 6286/8564 [01:02<00:13, 163.61 examples/s]Tokenizing train dataset:  74%|███████▎  | 6305/8564 [01:02<00:13, 165.61 examples/s]Tokenizing train dataset:  72%|███████▏  | 6193/8564 [01:01<00:16, 140.94 examples/s]Tokenizing train dataset:  71%|███████▏  | 6120/8564 [01:01<00:15, 156.37 examples/s]Tokenizing train dataset:  74%|███████▍  | 6330/8564 [01:02<00:12, 173.50 examples/s]Tokenizing train dataset:  73%|███████▎  | 6221/8564 [01:01<00:14, 164.62 examples/s]Tokenizing train dataset:  72%|███████▏  | 6139/8564 [01:01<00:14, 163.34 examples/s]Tokenizing train dataset:  74%|███████▍  | 6355/8564 [01:02<00:11, 190.41 examples/s]Tokenizing train dataset:  73%|███████▎  | 6243/8564 [01:01<00:13, 175.67 examples/s]Tokenizing train dataset:  72%|███████▏  | 6157/8564 [01:01<00:15, 160.29 examples/s]Tokenizing train dataset:  74%|███████▍  | 6380/8564 [01:02<00:11, 192.45 examples/s]Tokenizing train dataset:  73%|███████▎  | 6264/8564 [01:01<00:13, 176.23 examples/s]Tokenizing train dataset:  72%|███████▏  | 6182/8564 [01:02<00:14, 166.09 examples/s]Tokenizing train dataset:  75%|███████▍  | 6403/8564 [01:02<00:12, 173.07 examples/s]Tokenizing train dataset:  72%|███████▏  | 6208/8564 [01:02<00:12, 188.45 examples/s]Tokenizing train dataset:  73%|███████▎  | 6291/8564 [01:01<00:13, 166.93 examples/s]Tokenizing train dataset:  73%|███████▎  | 6234/8564 [01:02<00:11, 197.38 examples/s]Tokenizing train dataset:  74%|███████▎  | 6311/8564 [01:02<00:14, 152.24 examples/s]Tokenizing train dataset:  75%|███████▌  | 6428/8564 [01:02<00:13, 156.77 examples/s]Tokenizing train dataset:  73%|███████▎  | 6261/8564 [01:02<00:10, 211.32 examples/s]Tokenizing train dataset:  74%|███████▍  | 6330/8564 [01:02<00:14, 152.74 examples/s]Tokenizing train dataset:  73%|███████▎  | 6283/8564 [01:02<00:11, 200.14 examples/s]Tokenizing train dataset:  75%|███████▌  | 6456/8564 [01:03<00:14, 149.68 examples/s]Tokenizing train dataset:  74%|███████▍  | 6350/8564 [01:02<00:14, 149.93 examples/s]Tokenizing train dataset:  74%|███████▍  | 6316/8564 [01:02<00:10, 206.74 examples/s]Tokenizing train dataset:  74%|███████▍  | 6372/8564 [01:02<00:13, 157.57 examples/s]Tokenizing train dataset:  76%|███████▌  | 6478/8564 [01:03<00:14, 139.41 examples/s]Tokenizing train dataset:  74%|███████▍  | 6338/8564 [01:02<00:10, 203.56 examples/s]Tokenizing train dataset:  74%|███████▍  | 6368/8564 [01:02<00:09, 227.30 examples/s]Tokenizing train dataset:  75%|███████▍  | 6397/8564 [01:02<00:14, 145.17 examples/s]Tokenizing train dataset:  76%|███████▌  | 6501/8564 [01:03<00:15, 131.07 examples/s]Tokenizing train dataset:  75%|███████▍  | 6398/8564 [01:02<00:10, 210.98 examples/s]Tokenizing train dataset:  75%|███████▍  | 6412/8564 [01:02<00:15, 136.66 examples/s]Tokenizing train dataset:  76%|███████▌  | 6517/8564 [01:03<00:15, 129.23 examples/s]Tokenizing train dataset:  75%|███████▌  | 6429/8564 [01:02<00:15, 134.22 examples/s]Tokenizing train dataset:  75%|███████▌  | 6430/8564 [01:03<00:10, 206.21 examples/s]Tokenizing train dataset:  76%|███████▋  | 6535/8564 [01:03<00:16, 123.66 examples/s]Tokenizing train dataset:  75%|███████▌  | 6451/8564 [01:03<00:15, 137.86 examples/s]Tokenizing train dataset:  77%|███████▋  | 6553/8564 [01:03<00:15, 126.99 examples/s]Tokenizing train dataset:  75%|███████▌  | 6461/8564 [01:03<00:10, 200.90 examples/s]Tokenizing train dataset:  75%|███████▌  | 6465/8564 [01:03<00:15, 132.97 examples/s]Tokenizing train dataset:  77%|███████▋  | 6567/8564 [01:04<00:15, 128.09 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [01:03<00:10, 195.29 examples/s]Tokenizing train dataset:  77%|███████▋  | 6580/8564 [01:04<00:15, 124.54 examples/s]Tokenizing train dataset:  76%|███████▌  | 6480/8564 [01:03<00:17, 118.76 examples/s]Tokenizing train dataset:  76%|███████▌  | 6516/8564 [01:03<00:10, 200.35 examples/s]Tokenizing train dataset:  76%|███████▌  | 6496/8564 [01:03<00:16, 127.07 examples/s]Tokenizing train dataset:  76%|███████▋  | 6539/8564 [01:03<00:10, 200.71 examples/s]Tokenizing train dataset:  77%|███████▋  | 6600/8564 [01:04<00:16, 117.46 examples/s]Tokenizing train dataset:  76%|███████▌  | 6519/8564 [01:03<00:13, 151.78 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [01:03<00:11, 180.91 examples/s]Tokenizing train dataset:  76%|███████▋  | 6542/8564 [01:03<00:12, 164.62 examples/s]Tokenizing train dataset:  77%|███████▋  | 6613/8564 [01:04<00:18, 103.41 examples/s]Tokenizing train dataset:  77%|███████▋  | 6563/8564 [01:03<00:11, 170.79 examples/s]Tokenizing train dataset:  77%|███████▋  | 6632/8564 [01:04<00:16, 115.34 examples/s]Tokenizing train dataset:  77%|███████▋  | 6586/8564 [01:04<00:12, 160.08 examples/s]Tokenizing train dataset:  78%|███████▊  | 6646/8564 [01:04<00:16, 114.98 examples/s]Tokenizing train dataset:  77%|███████▋  | 6587/8564 [01:03<00:11, 165.70 examples/s]Tokenizing train dataset:  78%|███████▊  | 6663/8564 [01:04<00:15, 120.48 examples/s]Tokenizing train dataset:  77%|███████▋  | 6610/8564 [01:04<00:12, 155.41 examples/s]Tokenizing train dataset:  77%|███████▋  | 6608/8564 [01:04<00:15, 127.59 examples/s]Tokenizing train dataset:  78%|███████▊  | 6680/8564 [01:05<00:14, 127.78 examples/s]Tokenizing train dataset:  77%|███████▋  | 6632/8564 [01:04<00:11, 169.11 examples/s]Tokenizing train dataset:  77%|███████▋  | 6623/8564 [01:04<00:15, 125.15 examples/s]Tokenizing train dataset:  78%|███████▊  | 6699/8564 [01:05<00:13, 138.68 examples/s]Tokenizing train dataset:  78%|███████▊  | 6656/8564 [01:04<00:10, 178.60 examples/s]Tokenizing train dataset:  78%|███████▊  | 6640/8564 [01:04<00:15, 126.16 examples/s]Tokenizing train dataset:  78%|███████▊  | 6717/8564 [01:05<00:13, 137.22 examples/s]Tokenizing train dataset:  78%|███████▊  | 6679/8564 [01:04<00:09, 190.18 examples/s]Tokenizing train dataset:  78%|███████▊  | 6659/8564 [01:04<00:14, 132.27 examples/s]Tokenizing train dataset:  79%|███████▊  | 6733/8564 [01:05<00:13, 133.80 examples/s]Tokenizing train dataset:  78%|███████▊  | 6706/8564 [01:04<00:09, 201.10 examples/s]Tokenizing train dataset:  78%|███████▊  | 6684/8564 [01:04<00:13, 138.17 examples/s]Tokenizing train dataset:  79%|███████▉  | 6756/8564 [01:05<00:11, 151.12 examples/s]Tokenizing train dataset:  79%|███████▊  | 6729/8564 [01:04<00:09, 200.97 examples/s]Tokenizing train dataset:  79%|███████▉  | 6750/8564 [01:04<00:08, 202.97 examples/s]Tokenizing train dataset:  78%|███████▊  | 6701/8564 [01:04<00:13, 141.55 examples/s]Tokenizing train dataset:  79%|███████▉  | 6774/8564 [01:05<00:12, 139.12 examples/s]Tokenizing train dataset:  79%|███████▉  | 6774/8564 [01:04<00:08, 204.70 examples/s]Tokenizing train dataset:  78%|███████▊  | 6720/8564 [01:05<00:13, 138.26 examples/s]Tokenizing train dataset:  79%|███████▉  | 6800/8564 [01:05<00:10, 161.67 examples/s]Tokenizing train dataset:  79%|███████▉  | 6804/8564 [01:05<00:08, 201.37 examples/s]Tokenizing train dataset:  80%|███████▉  | 6819/8564 [01:05<00:10, 160.98 examples/s]Tokenizing train dataset:  79%|███████▊  | 6738/8564 [01:05<00:14, 129.51 examples/s]Tokenizing train dataset:  80%|███████▉  | 6837/8564 [01:06<00:10, 158.10 examples/s]Tokenizing train dataset:  79%|███████▉  | 6760/8564 [01:05<00:12, 144.40 examples/s]Tokenizing train dataset:  80%|███████▉  | 6834/8564 [01:05<00:09, 183.42 examples/s]Tokenizing train dataset:  80%|████████  | 6857/8564 [01:06<00:10, 168.03 examples/s]Tokenizing train dataset:  80%|████████  | 6853/8564 [01:05<00:09, 184.21 examples/s]Tokenizing train dataset:  80%|████████  | 6883/8564 [01:06<00:08, 188.45 examples/s]Tokenizing train dataset:  79%|███████▉  | 6780/8564 [01:05<00:14, 123.51 examples/s]Tokenizing train dataset:  80%|████████  | 6876/8564 [01:05<00:08, 194.34 examples/s]Tokenizing train dataset:  79%|███████▉  | 6801/8564 [01:05<00:12, 135.73 examples/s]Tokenizing train dataset:  81%|████████  | 6911/8564 [01:06<00:09, 181.94 examples/s]Tokenizing train dataset:  81%|████████  | 6904/8564 [01:05<00:08, 188.76 examples/s]Tokenizing train dataset:  81%|████████  | 6940/8564 [01:06<00:07, 207.66 examples/s]Tokenizing train dataset:  80%|███████▉  | 6816/8564 [01:05<00:13, 132.52 examples/s]Tokenizing train dataset:  81%|████████  | 6930/8564 [01:05<00:08, 199.68 examples/s]Tokenizing train dataset:  80%|███████▉  | 6831/8564 [01:06<00:14, 120.81 examples/s]Tokenizing train dataset:  81%|████████▏ | 6966/8564 [01:06<00:08, 183.25 examples/s]Tokenizing train dataset:  81%|████████▏ | 6961/8564 [01:05<00:08, 197.15 examples/s]Tokenizing train dataset:  82%|████████▏ | 6989/8564 [01:06<00:08, 194.19 examples/s]Tokenizing train dataset:  82%|████████▏ | 6983/8564 [01:05<00:07, 201.04 examples/s]Tokenizing train dataset:  80%|███████▉  | 6849/8564 [01:06<00:14, 114.92 examples/s]Tokenizing train dataset:  82%|████████▏ | 7015/8564 [01:06<00:08, 178.56 examples/s]Tokenizing train dataset:  80%|████████  | 6870/8564 [01:06<00:13, 122.34 examples/s]Tokenizing train dataset:  82%|████████▏ | 7011/8564 [01:06<00:08, 186.09 examples/s]Tokenizing train dataset:  82%|████████▏ | 7035/8564 [01:07<00:08, 176.87 examples/s]Tokenizing train dataset:  80%|████████  | 6886/8564 [01:06<00:13, 122.21 examples/s]Tokenizing train dataset:  82%|████████▏ | 7040/8564 [01:06<00:08, 183.17 examples/s]Tokenizing train dataset:  82%|████████▏ | 7060/8564 [01:07<00:07, 191.53 examples/s]Tokenizing train dataset:  81%|████████  | 6900/8564 [01:06<00:13, 119.25 examples/s]Tokenizing train dataset:  82%|████████▏ | 7060/8564 [01:06<00:08, 185.52 examples/s]Tokenizing train dataset:  83%|████████▎ | 7089/8564 [01:07<00:07, 205.54 examples/s]Tokenizing train dataset:  83%|████████▎ | 7089/8564 [01:06<00:07, 202.38 examples/s]Tokenizing train dataset:  81%|████████  | 6919/8564 [01:06<00:13, 119.03 examples/s]Tokenizing train dataset:  83%|████████▎ | 7117/8564 [01:07<00:07, 196.40 examples/s]Tokenizing train dataset:  81%|████████  | 6945/8564 [01:06<00:11, 144.24 examples/s]Tokenizing train dataset:  83%|████████▎ | 7119/8564 [01:06<00:07, 192.30 examples/s]Tokenizing train dataset:  83%|████████▎ | 7141/8564 [01:07<00:07, 202.42 examples/s]Tokenizing train dataset:  81%|████████▏ | 6961/8564 [01:06<00:10, 146.86 examples/s]Tokenizing train dataset:  84%|████████▍ | 7173/8564 [01:07<00:06, 204.16 examples/s]Tokenizing train dataset:  83%|████████▎ | 7144/8564 [01:06<00:08, 174.33 examples/s]Tokenizing train dataset:  82%|████████▏ | 6982/8564 [01:07<00:09, 161.34 examples/s]Tokenizing train dataset:  84%|████████▍ | 7202/8564 [01:07<00:06, 221.70 examples/s]Tokenizing train dataset:  82%|████████▏ | 7000/8564 [01:07<00:09, 156.86 examples/s]Tokenizing train dataset:  84%|████████▎ | 7167/8564 [01:07<00:09, 151.56 examples/s]Tokenizing train dataset:  82%|████████▏ | 7020/8564 [01:07<00:09, 157.55 examples/s]Tokenizing train dataset:  84%|████████▍ | 7225/8564 [01:08<00:07, 190.94 examples/s]Tokenizing train dataset:  84%|████████▍ | 7185/8564 [01:07<00:09, 149.84 examples/s]Tokenizing train dataset:  82%|████████▏ | 7046/8564 [01:07<00:08, 183.18 examples/s]Tokenizing train dataset:  85%|████████▍ | 7257/8564 [01:08<00:06, 194.93 examples/s]Tokenizing train dataset:  84%|████████▍ | 7203/8564 [01:07<00:09, 150.94 examples/s]Tokenizing train dataset:  83%|████████▎ | 7069/8564 [01:07<00:07, 194.75 examples/s]Tokenizing train dataset:  84%|████████▍ | 7221/8564 [01:07<00:08, 150.71 examples/s]Tokenizing train dataset:  83%|████████▎ | 7092/8564 [01:07<00:07, 197.09 examples/s]Tokenizing train dataset:  85%|████████▌ | 7282/8564 [01:08<00:07, 172.87 examples/s]Tokenizing train dataset:  83%|████████▎ | 7115/8564 [01:07<00:07, 204.82 examples/s]Tokenizing train dataset:  85%|████████▍ | 7244/8564 [01:07<00:09, 135.04 examples/s]Tokenizing train dataset:  83%|████████▎ | 7140/8564 [01:07<00:06, 211.71 examples/s]Tokenizing train dataset:  85%|████████▌ | 7310/8564 [01:08<00:07, 167.36 examples/s]Tokenizing train dataset:  85%|████████▍ | 7267/8564 [01:07<00:08, 154.75 examples/s]Tokenizing train dataset:  84%|████████▍ | 7174/8564 [01:08<00:06, 212.90 examples/s]Tokenizing train dataset:  86%|████████▌ | 7329/8564 [01:08<00:08, 150.87 examples/s]Tokenizing train dataset:  85%|████████▌ | 7290/8564 [01:07<00:07, 164.20 examples/s]Tokenizing train dataset:  84%|████████▍ | 7202/8564 [01:08<00:06, 225.96 examples/s]Tokenizing train dataset:  86%|████████▌ | 7353/8564 [01:08<00:07, 151.59 examples/s]Tokenizing train dataset:  85%|████████▌ | 7313/8564 [01:08<00:08, 141.52 examples/s]Tokenizing train dataset:  84%|████████▍ | 7231/8564 [01:08<00:06, 204.16 examples/s]Tokenizing train dataset:  86%|████████▌ | 7375/8564 [01:08<00:07, 162.28 examples/s]Tokenizing train dataset:  86%|████████▌ | 7333/8564 [01:08<00:08, 152.71 examples/s]Tokenizing train dataset:  86%|████████▋ | 7393/8564 [01:09<00:07, 164.57 examples/s]Tokenizing train dataset:  85%|████████▍ | 7254/8564 [01:08<00:07, 172.43 examples/s]Tokenizing train dataset:  86%|████████▌ | 7360/8564 [01:08<00:06, 172.09 examples/s]Tokenizing train dataset:  87%|████████▋ | 7417/8564 [01:09<00:06, 174.98 examples/s]Tokenizing train dataset:  86%|████████▌ | 7384/8564 [01:08<00:06, 177.61 examples/s]Tokenizing train dataset:  87%|████████▋ | 7447/8564 [01:09<00:05, 197.63 examples/s]Tokenizing train dataset:  85%|████████▍ | 7278/8564 [01:08<00:07, 163.92 examples/s]Tokenizing train dataset:  87%|████████▋ | 7471/8564 [01:09<00:05, 205.66 examples/s]Tokenizing train dataset:  85%|████████▌ | 7296/8564 [01:08<00:07, 160.54 examples/s]Tokenizing train dataset:  86%|████████▋ | 7405/8564 [01:08<00:07, 151.55 examples/s]Tokenizing train dataset:  87%|████████▋ | 7492/8564 [01:09<00:05, 202.19 examples/s]Tokenizing train dataset:  87%|████████▋ | 7426/8564 [01:08<00:07, 161.93 examples/s]Tokenizing train dataset:  85%|████████▌ | 7314/8564 [01:08<00:09, 137.41 examples/s]Tokenizing train dataset:  87%|████████▋ | 7450/8564 [01:08<00:06, 169.28 examples/s]Tokenizing train dataset:  86%|████████▌ | 7336/8564 [01:09<00:07, 154.24 examples/s]Tokenizing train dataset:  88%|████████▊ | 7524/8564 [01:09<00:05, 179.41 examples/s]Tokenizing train dataset:  86%|████████▌ | 7361/8564 [01:09<00:06, 174.96 examples/s]Tokenizing train dataset:  88%|████████▊ | 7546/8564 [01:09<00:05, 176.85 examples/s]Tokenizing train dataset:  87%|████████▋ | 7470/8564 [01:08<00:06, 174.17 examples/s]Tokenizing train dataset:  88%|████████▊ | 7565/8564 [01:09<00:05, 179.06 examples/s]Tokenizing train dataset:  87%|████████▋ | 7490/8564 [01:09<00:06, 156.03 examples/s]Tokenizing train dataset:  86%|████████▌ | 7383/8564 [01:09<00:07, 158.73 examples/s]Tokenizing train dataset:  89%|████████▊ | 7588/8564 [01:10<00:05, 184.16 examples/s]Tokenizing train dataset:  88%|████████▊ | 7509/8564 [01:09<00:06, 161.76 examples/s]Tokenizing train dataset:  86%|████████▋ | 7404/8564 [01:09<00:07, 146.05 examples/s]Tokenizing train dataset:  88%|████████▊ | 7533/8564 [01:09<00:05, 172.80 examples/s]Tokenizing train dataset:  89%|████████▉ | 7607/8564 [01:10<00:05, 163.38 examples/s]Tokenizing train dataset:  87%|████████▋ | 7430/8564 [01:09<00:06, 168.75 examples/s]Tokenizing train dataset:  89%|████████▉ | 7624/8564 [01:10<00:06, 152.44 examples/s]Tokenizing train dataset:  87%|████████▋ | 7455/8564 [01:09<00:05, 187.62 examples/s]Tokenizing train dataset:  88%|████████▊ | 7559/8564 [01:09<00:06, 158.51 examples/s]Tokenizing train dataset:  89%|████████▊ | 7584/8564 [01:09<00:05, 178.95 examples/s]Tokenizing train dataset:  89%|████████▉ | 7646/8564 [01:10<00:06, 148.13 examples/s]Tokenizing train dataset:  87%|████████▋ | 7481/8564 [01:09<00:05, 180.83 examples/s]Tokenizing train dataset:  88%|████████▊ | 7501/8564 [01:09<00:05, 183.96 examples/s]Tokenizing train dataset:  90%|████████▉ | 7667/8564 [01:10<00:06, 143.19 examples/s]Tokenizing train dataset:  89%|████████▉ | 7610/8564 [01:09<00:06, 155.45 examples/s]Tokenizing train dataset:  88%|████████▊ | 7522/8564 [01:10<00:05, 187.55 examples/s]Tokenizing train dataset:  90%|████████▉ | 7690/8564 [01:10<00:05, 151.66 examples/s]Tokenizing train dataset:  89%|████████▉ | 7636/8564 [01:09<00:05, 174.22 examples/s]Tokenizing train dataset:  88%|████████▊ | 7550/8564 [01:10<00:05, 198.98 examples/s]Tokenizing train dataset:  90%|█████████ | 7712/8564 [01:10<00:05, 165.41 examples/s]Tokenizing train dataset:  89%|████████▉ | 7655/8564 [01:10<00:05, 173.94 examples/s]Tokenizing train dataset:  89%|████████▊ | 7585/8564 [01:10<00:04, 198.31 examples/s]Tokenizing train dataset:  90%|█████████ | 7730/8564 [01:11<00:05, 155.48 examples/s]Tokenizing train dataset:  90%|████████▉ | 7681/8564 [01:10<00:05, 172.30 examples/s]Tokenizing train dataset:  91%|█████████ | 7752/8564 [01:11<00:05, 153.59 examples/s]Tokenizing train dataset:  90%|████████▉ | 7704/8564 [01:10<00:04, 182.90 examples/s]Tokenizing train dataset:  89%|████████▉ | 7615/8564 [01:10<00:04, 190.66 examples/s]Tokenizing train dataset:  90%|█████████ | 7725/8564 [01:10<00:04, 186.08 examples/s]Tokenizing train dataset:  91%|█████████ | 7774/8564 [01:11<00:05, 151.07 examples/s]Tokenizing train dataset:  89%|████████▉ | 7643/8564 [01:10<00:05, 182.91 examples/s]Tokenizing train dataset:  90%|█████████ | 7747/8564 [01:10<00:04, 192.24 examples/s]Tokenizing train dataset:  91%|█████████ | 7790/8564 [01:11<00:05, 132.24 examples/s]Tokenizing train dataset:  90%|████████▉ | 7670/8564 [01:10<00:05, 175.81 examples/s]Tokenizing train dataset:  91%|█████████ | 7774/8564 [01:10<00:04, 181.27 examples/s]Tokenizing train dataset:  91%|█████████ | 7806/8564 [01:11<00:05, 136.87 examples/s]Tokenizing train dataset:  91%|█████████ | 7793/8564 [01:10<00:04, 183.17 examples/s]Tokenizing train dataset:  90%|████████▉ | 7690/8564 [01:11<00:05, 166.88 examples/s]Tokenizing train dataset:  91%|█████████▏| 7829/8564 [01:11<00:04, 155.43 examples/s]Tokenizing train dataset:  91%|█████████▏| 7819/8564 [01:11<00:04, 176.84 examples/s]Tokenizing train dataset:  90%|█████████ | 7712/8564 [01:11<00:05, 156.21 examples/s]Tokenizing train dataset:  92%|█████████▏| 7854/8564 [01:11<00:04, 152.63 examples/s]Tokenizing train dataset:  90%|█████████ | 7736/8564 [01:11<00:04, 171.36 examples/s]Tokenizing train dataset:  92%|█████████▏| 7846/8564 [01:11<00:04, 170.70 examples/s]Tokenizing train dataset:  92%|█████████▏| 7873/8564 [01:12<00:05, 135.36 examples/s]Tokenizing train dataset:  91%|█████████ | 7762/8564 [01:11<00:04, 167.86 examples/s]Tokenizing train dataset:  92%|█████████▏| 7870/8564 [01:11<00:04, 163.68 examples/s]Tokenizing train dataset:  92%|█████████▏| 7892/8564 [01:12<00:05, 128.33 examples/s]Tokenizing train dataset:  92%|█████████▏| 7890/8564 [01:11<00:04, 167.17 examples/s]Tokenizing train dataset:  91%|█████████ | 7790/8564 [01:11<00:04, 165.31 examples/s]Tokenizing train dataset:  92%|█████████▏| 7914/8564 [01:12<00:04, 140.44 examples/s]Tokenizing train dataset:  91%|█████████ | 7808/8564 [01:11<00:04, 164.18 examples/s]Tokenizing train dataset:  92%|█████████▏| 7915/8564 [01:11<00:04, 155.11 examples/s]Tokenizing train dataset:  91%|█████████▏| 7830/8564 [01:11<00:04, 174.48 examples/s]Tokenizing train dataset:  93%|█████████▎| 7936/8564 [01:12<00:04, 142.81 examples/s]Tokenizing train dataset:  92%|█████████▏| 7855/8564 [01:11<00:03, 192.31 examples/s]Tokenizing train dataset:  93%|█████████▎| 7961/8564 [01:12<00:04, 147.44 examples/s]Tokenizing train dataset:  93%|█████████▎| 7938/8564 [01:11<00:04, 132.24 examples/s]Tokenizing train dataset:  92%|█████████▏| 7875/8564 [01:12<00:03, 193.01 examples/s]Tokenizing train dataset:  93%|█████████▎| 7986/8564 [01:12<00:03, 168.72 examples/s]Tokenizing train dataset:  93%|█████████▎| 7953/8564 [01:11<00:04, 131.88 examples/s]Tokenizing train dataset:  92%|█████████▏| 7899/8564 [01:12<00:03, 201.24 examples/s]Tokenizing train dataset:  93%|█████████▎| 7975/8564 [01:12<00:03, 150.11 examples/s]Tokenizing train dataset:  93%|█████████▎| 8007/8564 [01:12<00:03, 164.94 examples/s]Tokenizing train dataset:  92%|█████████▏| 7921/8564 [01:12<00:03, 201.15 examples/s]Tokenizing train dataset:  93%|█████████▎| 8002/8564 [01:12<00:03, 172.10 examples/s]Tokenizing train dataset:  94%|█████████▍| 8030/8564 [01:13<00:03, 152.40 examples/s]Tokenizing train dataset:  93%|█████████▎| 7944/8564 [01:12<00:03, 173.90 examples/s]Tokenizing train dataset:  94%|█████████▎| 8026/8564 [01:12<00:02, 183.22 examples/s]Tokenizing train dataset:  94%|█████████▍| 8052/8564 [01:13<00:03, 163.61 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:12<00:02, 183.32 examples/s]Tokenizing train dataset:  93%|█████████▎| 7973/8564 [01:12<00:03, 165.35 examples/s]Tokenizing train dataset:  94%|█████████▍| 8072/8564 [01:12<00:02, 186.92 examples/s]Tokenizing train dataset:  94%|█████████▍| 8078/8564 [01:13<00:03, 161.54 examples/s]Tokenizing train dataset:  93%|█████████▎| 7993/8564 [01:12<00:03, 164.10 examples/s]Tokenizing train dataset:  95%|█████████▍| 8096/8564 [01:12<00:02, 193.82 examples/s]Tokenizing train dataset:  94%|█████████▎| 8020/8564 [01:12<00:03, 173.24 examples/s]Tokenizing train dataset:  95%|█████████▍| 8104/8564 [01:13<00:03, 143.72 examples/s]Tokenizing train dataset:  95%|█████████▍| 8124/8564 [01:12<00:02, 188.68 examples/s]Tokenizing train dataset:  95%|█████████▍| 8120/8564 [01:13<00:03, 141.79 examples/s]Tokenizing train dataset:  94%|█████████▍| 8047/8564 [01:13<00:03, 162.56 examples/s]Tokenizing train dataset:  95%|█████████▌| 8148/8564 [01:12<00:02, 199.30 examples/s]Tokenizing train dataset:  95%|█████████▌| 8172/8564 [01:13<00:01, 207.57 examples/s]Tokenizing train dataset:  94%|█████████▍| 8068/8564 [01:13<00:03, 164.70 examples/s]Tokenizing train dataset:  95%|█████████▌| 8144/8564 [01:13<00:03, 138.06 examples/s]Tokenizing train dataset:  96%|█████████▌| 8199/8564 [01:13<00:01, 217.67 examples/s]Tokenizing train dataset:  95%|█████████▌| 8161/8564 [01:14<00:02, 139.69 examples/s]Tokenizing train dataset:  94%|█████████▍| 8088/8564 [01:13<00:03, 141.77 examples/s]Tokenizing train dataset:  96%|█████████▌| 8184/8564 [01:14<00:02, 159.51 examples/s]Tokenizing train dataset:  96%|█████████▌| 8226/8564 [01:13<00:01, 203.34 examples/s]Tokenizing train dataset:  96%|█████████▌| 8204/8564 [01:14<00:02, 163.26 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [01:13<00:01, 209.97 examples/s]Tokenizing train dataset:  95%|█████████▍| 8109/8564 [01:13<00:03, 131.90 examples/s]Tokenizing train dataset:  97%|█████████▋| 8282/8564 [01:13<00:01, 234.18 examples/s]Tokenizing train dataset:  96%|█████████▌| 8223/8564 [01:14<00:02, 165.29 examples/s]Tokenizing train dataset:  95%|█████████▍| 8131/8564 [01:13<00:03, 129.87 examples/s]Tokenizing train dataset:  96%|█████████▋| 8250/8564 [01:14<00:01, 191.26 examples/s]Tokenizing train dataset:  97%|█████████▋| 8307/8564 [01:13<00:01, 226.20 examples/s]Tokenizing train dataset:  97%|█████████▋| 8277/8564 [01:14<00:01, 200.46 examples/s]Tokenizing train dataset:  95%|█████████▌| 8153/8564 [01:13<00:03, 128.64 examples/s]Tokenizing train dataset:  97%|█████████▋| 8333/8564 [01:13<00:01, 201.15 examples/s]Tokenizing train dataset:  95%|█████████▌| 8172/8564 [01:14<00:02, 133.29 examples/s]Tokenizing train dataset:  97%|█████████▋| 8305/8564 [01:14<00:01, 172.70 examples/s]Tokenizing train dataset:  98%|█████████▊| 8360/8564 [01:13<00:01, 186.31 examples/s]Tokenizing train dataset:  98%|█████████▊| 8384/8564 [01:14<00:00, 198.31 examples/s]Tokenizing train dataset:  96%|█████████▌| 8197/8564 [01:14<00:03, 120.42 examples/s]Tokenizing train dataset:  97%|█████████▋| 8331/8564 [01:15<00:01, 145.89 examples/s]Tokenizing train dataset:  96%|█████████▌| 8210/8564 [01:14<00:02, 118.86 examples/s]Tokenizing train dataset:  98%|█████████▊| 8412/8564 [01:14<00:00, 167.18 examples/s]Tokenizing train dataset:  96%|█████████▌| 8235/8564 [01:14<00:02, 145.26 examples/s]Tokenizing train dataset:  98%|█████████▊| 8352/8564 [01:15<00:01, 129.42 examples/s]Tokenizing train dataset:  98%|█████████▊| 8432/8564 [01:14<00:00, 164.11 examples/s]Tokenizing train dataset:  96%|█████████▋| 8259/8564 [01:14<00:01, 166.53 examples/s]Tokenizing train dataset:  98%|█████████▊| 8373/8564 [01:15<00:01, 125.15 examples/s]Tokenizing train dataset:  97%|█████████▋| 8290/8564 [01:14<00:01, 194.01 examples/s]Tokenizing train dataset:  99%|█████████▊| 8453/8564 [01:14<00:00, 142.18 examples/s]Tokenizing train dataset:  98%|█████████▊| 8388/8564 [01:15<00:01, 128.64 examples/s]Tokenizing train dataset:  97%|█████████▋| 8312/8564 [01:14<00:01, 198.30 examples/s]Tokenizing train dataset:  99%|█████████▉| 8470/8564 [01:14<00:00, 144.85 examples/s]Tokenizing train dataset:  98%|█████████▊| 8404/8564 [01:15<00:01, 125.50 examples/s]Tokenizing train dataset:  97%|█████████▋| 8342/8564 [01:15<00:01, 196.20 examples/s]Tokenizing train dataset:  99%|█████████▉| 8486/8564 [01:14<00:00, 134.54 examples/s]Tokenizing train dataset:  98%|█████████▊| 8422/8564 [01:15<00:01, 131.58 examples/s]Tokenizing train dataset:  99%|█████████▉| 8503/8564 [01:14<00:00, 141.67 examples/s]Tokenizing train dataset:  98%|█████████▊| 8363/8564 [01:15<00:01, 153.15 examples/s]Tokenizing train dataset: 100%|█████████▉| 8529/8564 [01:15<00:00, 163.87 examples/s]Tokenizing train dataset:  99%|█████████▊| 8441/8564 [01:15<00:00, 127.05 examples/s]Tokenizing train dataset:  98%|█████████▊| 8386/8564 [01:15<00:01, 158.72 examples/s]Tokenizing train dataset: 100%|█████████▉| 8551/8564 [01:15<00:00, 166.69 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:15<00:00, 113.74 examples/s]
Tokenizing train dataset:  99%|█████████▉| 8465/8564 [01:16<00:00, 126.12 examples/s]Tokenizing train dataset:  98%|█████████▊| 8407/8564 [01:15<00:01, 144.48 examples/s]Tokenizing train dataset:  99%|█████████▉| 8487/8564 [01:16<00:00, 141.17 examples/s]Tokenizing train dataset:  98%|█████████▊| 8424/8564 [01:15<00:00, 145.24 examples/s]Tokenizing train dataset:  99%|█████████▉| 8509/8564 [01:16<00:00, 136.61 examples/s]Tokenizing train dataset:  99%|█████████▊| 8447/8564 [01:15<00:00, 137.89 examples/s]Tokenizing train dataset: 100%|█████████▉| 8526/8564 [01:16<00:00, 137.99 examples/s]Tokenizing train dataset:  99%|█████████▉| 8470/8564 [01:16<00:00, 145.38 examples/s]Tokenizing train dataset: 100%|█████████▉| 8543/8564 [01:16<00:00, 120.91 examples/s]Tokenizing train dataset:  99%|█████████▉| 8491/8564 [01:16<00:00, 156.00 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:16<00:00, 129.49 examples/s]Tokenizing train dataset:  99%|█████████▉| 8513/8564 [01:16<00:00, 166.66 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:16<00:00, 111.34 examples/s]
Tokenizing train dataset: 100%|█████████▉| 8539/8564 [01:16<00:00, 145.40 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:16<00:00, 166.70 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:16<00:00, 111.84 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  63%|██████▎   | 596/953 [00:00<00:00, 5908.62 examples/s]Extracting prompt in eval dataset:  36%|███▋      | 347/953 [00:00<00:00, 2960.61 examples/s]Extracting prompt in eval dataset:  39%|███▉      | 370/953 [00:00<00:00, 3664.64 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4435.20 examples/s]
Extracting prompt in eval dataset:  88%|████████▊ | 840/953 [00:00<00:00, 4036.67 examples/s]Extracting prompt in eval dataset:  89%|████████▉ | 850/953 [00:00<00:00, 4326.43 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4345.58 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3808.38 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  70%|███████   | 668/953 [00:00<00:00, 6434.12 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 6980.22 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  78%|███████▊  | 746/953 [00:00<00:00, 6984.58 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 6653.92 examples/s]
Applying chat template to eval dataset:  50%|█████     | 481/953 [00:00<00:00, 4237.72 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4524.07 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   2%|▏         | 20/953 [00:00<00:05, 186.38 examples/s]Tokenizing eval dataset:   4%|▍         | 40/953 [00:00<00:05, 161.20 examples/s]Tokenizing eval dataset:   6%|▌         | 57/953 [00:00<00:05, 157.64 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:05, 169.74 examples/s]Tokenizing eval dataset:  11%|█         | 103/953 [00:00<00:05, 160.35 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   1%|          | 10/953 [00:00<00:10, 87.87 examples/s]Tokenizing eval dataset:  13%|█▎        | 121/953 [00:00<00:06, 136.07 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   2%|▏         | 21/953 [00:00<00:09, 95.80 examples/s]Tokenizing eval dataset:   2%|▏         | 17/953 [00:00<00:05, 158.07 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Tokenizing eval dataset:  14%|█▍        | 137/953 [00:00<00:06, 120.63 examples/s]Tokenizing eval dataset:   3%|▎         | 33/953 [00:00<00:08, 102.44 examples/s]Tokenizing eval dataset:   4%|▎         | 35/953 [00:00<00:05, 162.27 examples/s]Tokenizing eval dataset:   5%|▍         | 47/953 [00:00<00:07, 115.44 examples/s]Tokenizing eval dataset:  16%|█▌        | 150/953 [00:01<00:07, 101.01 examples/s]Tokenizing eval dataset:   6%|▌         | 59/953 [00:00<00:07, 114.06 examples/s]Tokenizing eval dataset:   6%|▌         | 53/953 [00:00<00:07, 127.51 examples/s]Tokenizing eval dataset:  17%|█▋        | 162/953 [00:01<00:07, 102.20 examples/s]Tokenizing eval dataset:   7%|▋         | 71/953 [00:00<00:07, 113.42 examples/s]Tokenizing eval dataset:  18%|█▊        | 174/953 [00:01<00:07, 104.02 examples/s]Tokenizing eval dataset:   9%|▉         | 89/953 [00:00<00:06, 124.70 examples/s]Tokenizing eval dataset:   7%|▋         | 70/953 [00:00<00:08, 98.72 examples/s] Tokenizing eval dataset:  20%|█▉        | 188/953 [00:01<00:06, 111.19 examples/s]Tokenizing eval dataset:   9%|▊         | 83/953 [00:00<00:08, 105.12 examples/s]Tokenizing eval dataset:  11%|█         | 103/953 [00:00<00:08, 104.93 examples/s]Tokenizing eval dataset:  22%|██▏       | 205/953 [00:01<00:06, 123.49 examples/s]Tokenizing eval dataset:  24%|██▍       | 229/953 [00:01<00:04, 151.42 examples/s]Tokenizing eval dataset:  10%|█         | 96/953 [00:00<00:09, 94.17 examples/s] Tokenizing eval dataset:  12%|█▏        | 118/953 [00:01<00:08, 96.18 examples/s] Tokenizing eval dataset:  28%|██▊       | 270/953 [00:01<00:03, 219.62 examples/s]Tokenizing eval dataset:  11%|█         | 107/953 [00:01<00:09, 88.83 examples/s]Tokenizing eval dataset:  32%|███▏      | 301/953 [00:01<00:02, 240.17 examples/s]Tokenizing eval dataset:  13%|█▎        | 124/953 [00:01<00:07, 106.10 examples/s]Tokenizing eval dataset:  14%|█▎        | 130/953 [00:01<00:09, 82.43 examples/s]Tokenizing eval dataset:  34%|███▍      | 328/953 [00:02<00:02, 216.80 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:01<00:07, 115.72 examples/s]Tokenizing eval dataset:  15%|█▌        | 144/953 [00:01<00:08, 92.55 examples/s]Tokenizing eval dataset:  16%|█▋        | 157/953 [00:01<00:07, 100.11 examples/s]Tokenizing eval dataset:  38%|███▊      | 358/953 [00:02<00:02, 202.27 examples/s]Tokenizing eval dataset:  16%|█▋        | 157/953 [00:01<00:07, 109.75 examples/s]Tokenizing eval dataset:  18%|█▊        | 170/953 [00:01<00:07, 107.24 examples/s]Tokenizing eval dataset:  40%|████      | 384/953 [00:02<00:02, 190.76 examples/s]Tokenizing eval dataset:  18%|█▊        | 175/953 [00:01<00:07, 110.81 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:01<00:06, 118.33 examples/s]Tokenizing eval dataset:  19%|█▉        | 185/953 [00:01<00:08, 87.43 examples/s] Tokenizing eval dataset:  44%|████▍     | 421/953 [00:02<00:02, 207.61 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:02<00:01, 266.45 examples/s]Tokenizing eval dataset:  20%|██        | 195/953 [00:02<00:09, 83.62 examples/s]Tokenizing eval dataset:  22%|██▏       | 207/953 [00:01<00:06, 109.94 examples/s]Tokenizing eval dataset:  53%|█████▎    | 509/953 [00:02<00:01, 297.72 examples/s]Tokenizing eval dataset:  22%|██▏       | 206/953 [00:02<00:08, 87.56 examples/s]Tokenizing eval dataset:  24%|██▎       | 224/953 [00:02<00:06, 108.53 examples/s]Tokenizing eval dataset:  58%|█████▊    | 555/953 [00:02<00:01, 337.02 examples/s]Tokenizing eval dataset:  23%|██▎       | 216/953 [00:02<00:08, 86.25 examples/s]Tokenizing eval dataset:  25%|██▌       | 240/953 [00:02<00:05, 119.08 examples/s]Tokenizing eval dataset:  63%|██████▎   | 597/953 [00:02<00:00, 358.43 examples/s]Tokenizing eval dataset:  24%|██▍       | 233/953 [00:02<00:06, 103.01 examples/s]Tokenizing eval dataset:  27%|██▋       | 261/953 [00:02<00:05, 138.04 examples/s]Tokenizing eval dataset:  67%|██████▋   | 636/953 [00:03<00:00, 348.24 examples/s]Tokenizing eval dataset:  27%|██▋       | 254/953 [00:02<00:05, 127.76 examples/s]Tokenizing eval dataset:  30%|███       | 287/953 [00:02<00:03, 167.73 examples/s]Tokenizing eval dataset:  29%|██▉       | 276/953 [00:02<00:04, 150.67 examples/s]Tokenizing eval dataset:  72%|███████▏  | 690/953 [00:03<00:00, 345.65 examples/s]Tokenizing eval dataset:  34%|███▎      | 320/953 [00:02<00:03, 178.63 examples/s]Tokenizing eval dataset:  31%|███▏      | 300/953 [00:02<00:03, 168.85 examples/s]Tokenizing eval dataset:  78%|███████▊  | 740/953 [00:03<00:00, 335.65 examples/s]Tokenizing eval dataset:  36%|███▌      | 341/953 [00:02<00:03, 180.51 examples/s]Tokenizing eval dataset:  34%|███▍      | 324/953 [00:02<00:03, 174.85 examples/s]Tokenizing eval dataset:  82%|████████▏ | 777/953 [00:03<00:00, 337.83 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:02<00:03, 172.10 examples/s]Tokenizing eval dataset:  37%|███▋      | 348/953 [00:02<00:03, 185.07 examples/s]Tokenizing eval dataset:  39%|███▊      | 369/953 [00:03<00:03, 182.66 examples/s]Tokenizing eval dataset:  86%|████████▌ | 817/953 [00:03<00:00, 273.16 examples/s]Tokenizing eval dataset:  41%|████      | 387/953 [00:02<00:03, 171.00 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:03<00:02, 199.14 examples/s]Tokenizing eval dataset:  89%|████████▉ | 850/953 [00:03<00:00, 278.78 examples/s]Tokenizing eval dataset:  43%|████▎     | 407/953 [00:03<00:03, 174.57 examples/s]Tokenizing eval dataset:  46%|████▌     | 435/953 [00:03<00:02, 249.15 examples/s]Tokenizing eval dataset:  45%|████▌     | 430/953 [00:03<00:02, 185.19 examples/s]Tokenizing eval dataset:  93%|█████████▎| 888/953 [00:03<00:00, 266.55 examples/s]Tokenizing eval dataset:  48%|████▊     | 460/953 [00:03<00:02, 189.67 examples/s]Tokenizing eval dataset:  49%|████▊     | 464/953 [00:03<00:02, 193.24 examples/s]Tokenizing eval dataset:  52%|█████▏    | 494/953 [00:03<00:02, 224.83 examples/s]Tokenizing eval dataset:  96%|█████████▌| 917/953 [00:04<00:00, 192.57 examples/s]Tokenizing eval dataset:  55%|█████▌    | 527/953 [00:03<00:01, 249.70 examples/s]Tokenizing eval dataset:  52%|█████▏    | 500/953 [00:03<00:02, 201.76 examples/s]Tokenizing eval dataset:  56%|█████▌    | 534/953 [00:03<00:01, 229.90 examples/s]Tokenizing eval dataset:  59%|█████▊    | 558/953 [00:03<00:01, 256.62 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:04<00:00, 181.55 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:04<00:00, 210.97 examples/s]
Tokenizing eval dataset:  60%|█████▉    | 570/953 [00:03<00:01, 258.39 examples/s]Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:03<00:01, 269.75 examples/s]Tokenizing eval dataset:  63%|██████▎   | 600/953 [00:03<00:01, 266.99 examples/s]Tokenizing eval dataset:  67%|██████▋   | 641/953 [00:04<00:01, 303.34 examples/s]Tokenizing eval dataset:  67%|██████▋   | 641/953 [00:03<00:01, 252.96 examples/s]Tokenizing eval dataset:  71%|███████   | 675/953 [00:04<00:01, 271.76 examples/s]Tokenizing eval dataset:  72%|███████▏  | 689/953 [00:04<00:00, 305.63 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  74%|███████▍  | 706/953 [00:04<00:00, 280.14 examples/s]Tokenizing eval dataset:  77%|███████▋  | 731/953 [00:04<00:00, 283.99 examples/s]Tokenizing eval dataset:  78%|███████▊  | 741/953 [00:04<00:00, 294.91 examples/s]Tokenizing eval dataset:  80%|████████  | 767/953 [00:04<00:00, 300.99 examples/s]Tokenizing eval dataset:  82%|████████▏ | 777/953 [00:04<00:00, 269.35 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:04<00:00, 282.48 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:04<00:00, 269.17 examples/s]Tokenizing eval dataset:  88%|████████▊ | 841/953 [00:04<00:00, 295.77 examples/s]Tokenizing eval dataset:  89%|████████▉ | 850/953 [00:04<00:00, 271.24 examples/s]Tokenizing eval dataset:  93%|█████████▎| 884/953 [00:04<00:00, 288.45 examples/s]Tokenizing eval dataset:  93%|█████████▎| 890/953 [00:04<00:00, 263.48 examples/s]Tokenizing eval dataset:  98%|█████████▊| 930/953 [00:05<00:00, 290.63 examples/s]Tokenizing eval dataset:  96%|█████████▌| 917/953 [00:04<00:00, 263.92 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 185.03 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|█████████▉| 952/953 [00:05<00:00, 284.31 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 189.13 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 7.757113456726074 seconds
Time to load cpu_adam op: 7.726644277572632 seconds
Time to load cpu_adam op: 8.02133297920227 seconds
Time to load cpu_adam op: 8.201475858688354 seconds
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
W0530 16:25:25.420000 3667998 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3668073 closing signal SIGTERM
W0530 16:25:26.377000 3667998 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3668074 closing signal SIGTERM
W0530 16:25:26.377000 3667998 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3668075 closing signal SIGTERM
E0530 16:25:29.751000 3667998 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -9) local_rank: 0 (pid: 3668072) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1182, in launch_command
    deepspeed_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 861, in deepspeed_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
train.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-30_16:25:24
  host      : pm5-nod78.vega.pri
  rank      : 4 (local_rank: 0)
  exitcode  : -9 (pid: 3668072)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 3668072
========================================================
slurmstepd: error: Detected 1 oom_kill event in StepId=62055338.0. Some of the step tasks have been OOM Killed.
