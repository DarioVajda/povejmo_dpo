cpu-bind=MASK - gn25, task  0  0 [3904605]: mask 0x1000000000000000000000000000000010000000000000000000000000000 set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn25
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 0     --main_process_ip gn25     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62035524     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-29 23:34:16,409] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0529 23:34:20.929000 3904647 torch/distributed/run.py:792] 
W0529 23:34:20.929000 3904647 torch/distributed/run.py:792] *****************************************
W0529 23:34:20.929000 3904647 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0529 23:34:20.929000 3904647 torch/distributed/run.py:792] *****************************************
[2025-05-29 23:35:03,340] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-29 23:35:03,351] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-29 23:35:03,386] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-29 23:35:03,372] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasetsCreated datasets
Created datasets
Created datasets
Number of training examples: Number of training examples: 
Number of training examples:85648564Number of training examples: 8564

 
Number of validation examples: Number of validation examples: 8564Number of validation examples: 953
953

953Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
Number of validation examples:

3e-07
 Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 9533e-07[2025-05-29 23:35:18,433] [INFO] [comm.py:658:init_distributed] cdb=None
8

Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
Setting gradient accumulation steps to: 
3e-071
[2025-05-29 23:35:18,981] [INFO] [comm.py:658:init_distributed] cdb=None

Created datasets
Steps per epoch:[2025-05-29 23:35:19,426] [INFO] [comm.py:658:init_distributed] cdb=None
 8564
Eval steps: 4282
[2025-05-29 23:35:19,669] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-29 23:35:19,682] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
[2025-05-29 23:35:24,710] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-29 23:35:24,710] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-29 23:35:24,711] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-29 23:35:24,712] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
hpZeRO group size: 4
gn25:3904812:3904812 [0] NCCL INFO Bootstrap : Using ib0:10.210.4.9<0>
gn25:3904812:3904812 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gn25:3904812:3904812 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gn25:3904812:3904812 [0] NCCL INFO NET/Plugin: Using internal network plugin.
gn25:3904812:3904812 [0] NCCL INFO cudaDriverVersion 12070
NCCL version 2.21.5+cuda12.4
gn25:3904813:3904813 [1] NCCL INFO cudaDriverVersion 12070
gn25:3904813:3904813 [1] NCCL INFO Bootstrap : Using ib0:10.210.4.9<0>
gn25:3904815:3904815 [3] NCCL INFO cudaDriverVersion 12070
gn25:3904814:3904814 [2] NCCL INFO cudaDriverVersion 12070
gn25:3904812:3904812 [0] NCCL INFO Comm config Blocking set to 1
gn25:3904813:3904813 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gn25:3904813:3904813 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gn25:3904815:3904815 [3] NCCL INFO Bootstrap : Using ib0:10.210.4.9<0>
gn25:3904815:3904815 [3] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gn25:3904814:3904814 [2] NCCL INFO Bootstrap : Using ib0:10.210.4.9<0>
gn25:3904814:3904814 [2] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gn25:3904813:3904813 [1] NCCL INFO NET/Plugin: Using internal network plugin.
gn25:3904815:3904815 [3] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gn25:3904815:3904815 [3] NCCL INFO NET/Plugin: Using internal network plugin.
gn25:3904814:3904814 [2] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gn25:3904814:3904814 [2] NCCL INFO NET/Plugin: Using internal network plugin.
gn25:3904813:3904813 [1] NCCL INFO Comm config Blocking set to 1
gn25:3904815:3904815 [3] NCCL INFO Comm config Blocking set to 1
gn25:3904814:3904814 [2] NCCL INFO Comm config Blocking set to 1
gn25:3904815:3905383 [3] NCCL INFO Failed to open libibverbs.so[.1]
gn25:3904815:3905383 [3] NCCL INFO NET/Socket : Using [0]ib0:10.210.4.9<0>
gn25:3904815:3905383 [3] NCCL INFO Using non-device net plugin version 0
gn25:3904815:3905383 [3] NCCL INFO Using network Socket
gn25:3904813:3905382 [1] NCCL INFO Failed to open libibverbs.so[.1]
gn25:3904813:3905382 [1] NCCL INFO NET/Socket : Using [0]ib0:10.210.4.9<0>
gn25:3904812:3905381 [0] NCCL INFO Failed to open libibverbs.so[.1]
gn25:3904812:3905381 [0] NCCL INFO NET/Socket : Using [0]ib0:10.210.4.9<0>
gn25:3904813:3905382 [1] NCCL INFO Using non-device net plugin version 0
gn25:3904813:3905382 [1] NCCL INFO Using network Socket
gn25:3904814:3905384 [2] NCCL INFO Failed to open libibverbs.so[.1]
gn25:3904814:3905384 [2] NCCL INFO NET/Socket : Using [0]ib0:10.210.4.9<0>
gn25:3904812:3905381 [0] NCCL INFO Using non-device net plugin version 0
gn25:3904814:3905384 [2] NCCL INFO Using non-device net plugin version 0
gn25:3904814:3905384 [2] NCCL INFO Using network Socket
gn25:3904812:3905381 [0] NCCL INFO Using network Socket
gn25:3904815:3905383 [3] NCCL INFO ncclCommInitRank comm 0x55c3e3628720 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId c4000 commId 0x60747fb73e14cebf - Init START
gn25:3904812:3905381 [0] NCCL INFO ncclCommInitRank comm 0x55b29527afd0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 3000 commId 0x60747fb73e14cebf - Init START
gn25:3904813:3905382 [1] NCCL INFO ncclCommInitRank comm 0x562371173980 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 44000 commId 0x60747fb73e14cebf - Init START
gn25:3904814:3905384 [2] NCCL INFO ncclCommInitRank comm 0x55dc56e8f3f0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 84000 commId 0x60747fb73e14cebf - Init START
gn25:3904813:3905382 [1] NCCL INFO NVLS multicast support is not available on dev 1
gn25:3904814:3905384 [2] NCCL INFO Setting affinity for GPU 2 to 010000,00000000,00000000,00000000,00010000,00000000,00000000,00000000
gn25:3904814:3905384 [2] NCCL INFO NVLS multicast support is not available on dev 2
gn25:3904815:3905383 [3] NCCL INFO NVLS multicast support is not available on dev 3
gn25:3904812:3905381 [0] NCCL INFO NVLS multicast support is not available on dev 0
gn25:3904812:3905381 [0] NCCL INFO comm 0x55b29527afd0 rank 0 nRanks 8 nNodes 2 localRanks 4 localRank 0 MNNVL 0
gn25:3904813:3905382 [1] NCCL INFO comm 0x562371173980 rank 1 nRanks 8 nNodes 2 localRanks 4 localRank 1 MNNVL 0
gn25:3904814:3905384 [2] NCCL INFO comm 0x55dc56e8f3f0 rank 2 nRanks 8 nNodes 2 localRanks 4 localRank 2 MNNVL 0
gn25:3904815:3905383 [3] NCCL INFO comm 0x55c3e3628720 rank 3 nRanks 8 nNodes 2 localRanks 4 localRank 3 MNNVL 0
gn25:3904812:3905381 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
gn25:3904813:3905382 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
gn25:3904814:3905384 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
gn25:3904815:3905383 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
gn25:3904812:3905381 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
gn25:3904813:3905382 [1] NCCL INFO P2P Chunksize set to 131072
gn25:3904814:3905384 [2] NCCL INFO P2P Chunksize set to 131072
gn25:3904815:3905383 [3] NCCL INFO P2P Chunksize set to 131072
gn25:3904812:3905381 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->4
gn25:3904812:3905381 [0] NCCL INFO P2P Chunksize set to 131072
gn25:3904813:3905382 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3905382 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3905384 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3905383 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[0] [send] via NET/Socket/0
gn25:3904815:3905383 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[0] [send] via NET/Socket/0
gn25:3904812:3905381 [0] NCCL INFO Channel 00/0 : 7[3] -> 0[0] [receive] via NET/Socket/0
gn25:3904814:3905384 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3905381 [0] NCCL INFO Channel 01/0 : 7[3] -> 0[0] [receive] via NET/Socket/0
gn25:3904812:3905381 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3905381 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3905383 [3] NCCL INFO Connected all rings
gn25:3904815:3905383 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3905382 [1] NCCL INFO Connected all rings
gn25:3904812:3905381 [0] NCCL INFO Connected all rings
gn25:3904815:3905383 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3905384 [2] NCCL INFO Connected all rings
gn25:3904813:3905382 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904813:3905382 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3905381 [0] NCCL INFO Channel 00/0 : 4[0] -> 0[0] [receive] via NET/Socket/0
gn25:3904814:3905384 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3905384 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3905381 [0] NCCL INFO Channel 01/0 : 4[0] -> 0[0] [receive] via NET/Socket/0
gn25:3904815:3905383 [3] NCCL INFO Connected all trees
gn25:3904815:3905383 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn25:3904812:3905381 [0] NCCL INFO Channel 00/0 : 0[0] -> 4[0] [send] via NET/Socket/0
gn25:3904815:3905383 [3] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn25:3904812:3905381 [0] NCCL INFO Channel 01/0 : 0[0] -> 4[0] [send] via NET/Socket/0
gn25:3904814:3905384 [2] NCCL INFO Connected all trees
gn25:3904814:3905384 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn25:3904814:3905384 [2] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn25:3904812:3905381 [0] NCCL INFO Connected all trees
gn25:3904812:3905381 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn25:3904813:3905382 [1] NCCL INFO Connected all trees
gn25:3904812:3905381 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn25:3904813:3905382 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn25:3904813:3905382 [1] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn25:3904814:3905384 [2] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gn25:3904814:3905384 [2] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gn25:3904812:3905381 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gn25:3904813:3905382 [1] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gn25:3904815:3905383 [3] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gn25:3904814:3905384 [2] NCCL INFO ncclCommInitRank comm 0x55dc56e8f3f0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 84000 commId 0x60747fb73e14cebf - Init COMPLETE
gn25:3904812:3905381 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gn25:3904812:3905381 [0] NCCL INFO ncclCommInitRank comm 0x55b29527afd0 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 3000 commId 0x60747fb73e14cebf - Init COMPLETE
gn25:3904813:3905382 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gn25:3904815:3905383 [3] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gn25:3904815:3905383 [3] NCCL INFO ncclCommInitRank comm 0x55c3e3628720 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId c4000 commId 0x60747fb73e14cebf - Init COMPLETE
gn25:3904813:3905382 [1] NCCL INFO ncclCommInitRank comm 0x562371173980 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 44000 commId 0x60747fb73e14cebf - Init COMPLETE
[2025-05-29 23:37:03,994] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 465, num_elems = 10.16B
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [01:06<03:19, 66.47s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [01:06<03:19, 66.44s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [01:06<03:19, 66.48s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [01:06<03:19, 66.46s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:13<02:13, 66.51s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:12<02:13, 66.51s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:13<02:13, 66.50s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:13<02:13, 66.51s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:18<01:05, 65.98s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:18<01:05, 65.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:18<01:05, 66.00s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:18<01:05, 65.99s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.15s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.14s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.22s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.21s/it]


Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.21s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
-------------------- CHECKING GRADIENTS --------------------
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Trainable parameters:
- model.embed_tokens.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.norm.weight (shape: torch.Size([0]), numel: 0)
Total trainable parameters: 0
CRITICAL ERROR: NO TRAINABLE PARAMETERS FOUND!
------------------------------------------------------------
Using LoRA and set up the model model
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 1/8564 [00:05<14:02:35,  5.90s/ examples]Extracting prompt in train dataset:   0%|          | 10/8564 [00:09<1:53:56,  1.25 examples/s]Extracting prompt in train dataset:   1%|          | 70/8564 [00:09<11:43, 12.08 examples/s]  Extracting prompt in train dataset:   2%|▏         | 150/8564 [00:09<04:23, 31.92 examples/s]Extracting prompt in train dataset:   2%|▏         | 200/8564 [00:09<02:54, 48.03 examples/s]Extracting prompt in train dataset:   3%|▎         | 270/8564 [00:09<01:47, 77.44 examples/s]Extracting prompt in train dataset:   4%|▍         | 360/8564 [00:10<01:03, 128.35 examples/s]Extracting prompt in train dataset:   5%|▌         | 460/8564 [00:10<00:43, 185.68 examples/s]Extracting prompt in train dataset:   7%|▋         | 590/8564 [00:10<00:27, 292.17 examples/s]Extracting prompt in train dataset:   8%|▊         | 670/8564 [00:10<00:22, 346.67 examples/s]Extracting prompt in train dataset:  10%|▉         | 840/8564 [00:10<00:14, 519.18 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1080/8564 [00:10<00:09, 796.66 examples/s]Extracting prompt in train dataset:  15%|█▌        | 1300/8564 [00:10<00:07, 1033.07 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1540/8564 [00:11<00:06, 1067.37 examples/s]Extracting prompt in train dataset:  20%|██        | 1752/8564 [00:11<00:05, 1251.70 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1960/8564 [00:11<00:05, 1114.64 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2100/8564 [00:11<00:06, 1039.76 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2320/8564 [00:11<00:05, 1117.88 examples/s]Extracting prompt in train dataset:  29%|██▉       | 2510/8564 [00:11<00:05, 1135.61 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2700/8564 [00:12<00:04, 1244.29 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2920/8564 [00:12<00:04, 1372.17 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3170/8564 [00:12<00:04, 1240.75 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3330/8564 [00:12<00:04, 1307.10 examples/s]Extracting prompt in train dataset:  41%|████      | 3490/8564 [00:12<00:03, 1366.21 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3690/8564 [00:12<00:03, 1479.01 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3885/8564 [00:12<00:02, 1592.12 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4085/8564 [00:12<00:03, 1458.87 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4264/8564 [00:13<00:03, 1291.33 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4430/8564 [00:13<00:03, 1286.13 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4580/8564 [00:13<00:03, 1305.51 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4730/8564 [00:13<00:02, 1312.01 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4964/8564 [00:13<00:02, 1355.93 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 5122/8564 [00:13<00:02, 1408.88 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5310/8564 [00:13<00:02, 1524.85 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5490/8564 [00:13<00:01, 1554.73 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5700/8564 [00:14<00:01, 1672.83 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5913/8564 [00:14<00:01, 1743.27 examples/s]Extracting prompt in train dataset:  71%|███████   | 6090/8564 [00:14<00:01, 1700.80 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6361/8564 [00:14<00:01, 1709.55 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6590/8564 [00:14<00:01, 1706.07 examples/s]Extracting prompt in train dataset:  80%|████████  | 6876/8564 [00:14<00:01, 1537.20 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 7050/8564 [00:14<00:00, 1566.41 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7225/8564 [00:15<00:00, 1545.87 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7385/8564 [00:15<00:00, 1511.36 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7560/8564 [00:15<00:00, 1564.79 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7730/8564 [00:15<00:00, 1021.12 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7900/8564 [00:15<00:00, 1147.16 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8112/8564 [00:15<00:00, 1320.99 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8330/8564 [00:15<00:00, 1341.52 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8500/8564 [00:16<00:00, 1382.55 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:16<00:00, 505.13 examples/s] 
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:04<11:02:42,  4.64s/ examples]Applying chat template to train dataset:   1%|          | 96/8564 [00:04<05:00, 28.22 examples/s]  Applying chat template to train dataset:   2%|▏         | 178/8564 [00:04<02:20, 59.78 examples/s]Applying chat template to train dataset:   3%|▎         | 278/8564 [00:05<01:15, 109.97 examples/s]Applying chat template to train dataset:   4%|▍         | 384/8564 [00:05<00:46, 174.11 examples/s]Applying chat template to train dataset:   6%|▌         | 491/8564 [00:05<00:31, 254.50 examples/s]Applying chat template to train dataset:   7%|▋         | 602/8564 [00:05<00:22, 350.40 examples/s]Applying chat template to train dataset:   8%|▊         | 718/8564 [00:05<00:17, 455.96 examples/s]Applying chat template to train dataset:  10%|█         | 872/8564 [00:05<00:13, 585.32 examples/s]Applying chat template to train dataset:  11%|█▏        | 977/8564 [00:05<00:11, 654.76 examples/s]Applying chat template to train dataset:  13%|█▎        | 1099/8564 [00:05<00:10, 721.02 examples/s]Applying chat template to train dataset:  14%|█▍        | 1221/8564 [00:05<00:08, 825.78 examples/s]Applying chat template to train dataset:  16%|█▌        | 1331/8564 [00:06<00:08, 853.80 examples/s]Applying chat template to train dataset:  17%|█▋        | 1432/8564 [00:06<00:08, 873.60 examples/s]Applying chat template to train dataset:  18%|█▊        | 1560/8564 [00:06<00:07, 907.29 examples/s]Applying chat template to train dataset:  20%|█▉        | 1682/8564 [00:06<00:07, 937.07 examples/s]Applying chat template to train dataset:  21%|██        | 1797/8564 [00:06<00:07, 959.41 examples/s]Applying chat template to train dataset:  22%|██▏       | 1912/8564 [00:06<00:06, 985.41 examples/s]Applying chat template to train dataset:  24%|██▍       | 2060/8564 [00:06<00:06, 936.28 examples/s]Applying chat template to train dataset:  26%|██▌       | 2184/8564 [00:07<00:07, 817.07 examples/s]Applying chat template to train dataset:  27%|██▋       | 2313/8564 [00:07<00:07, 814.24 examples/s]Applying chat template to train dataset:  29%|██▊       | 2455/8564 [00:07<00:07, 844.42 examples/s]Applying chat template to train dataset:  30%|██▉       | 2549/8564 [00:07<00:06, 864.63 examples/s]Applying chat template to train dataset:  31%|███       | 2660/8564 [00:07<00:06, 913.31 examples/s]Applying chat template to train dataset:  33%|███▎      | 2799/8564 [00:07<00:05, 1007.83 examples/s]Applying chat template to train dataset:  34%|███▍      | 2920/8564 [00:07<00:05, 1029.40 examples/s]Applying chat template to train dataset:  35%|███▌      | 3027/8564 [00:07<00:05, 968.77 examples/s] Applying chat template to train dataset:  37%|███▋      | 3156/8564 [00:08<00:07, 727.01 examples/s]Applying chat template to train dataset:  38%|███▊      | 3253/8564 [00:08<00:06, 767.06 examples/s]Applying chat template to train dataset:  39%|███▉      | 3354/8564 [00:08<00:06, 779.64 examples/s]Applying chat template to train dataset:  40%|████      | 3447/8564 [00:08<00:06, 794.20 examples/s]Applying chat template to train dataset:  41%|████▏     | 3552/8564 [00:08<00:05, 850.32 examples/s]Applying chat template to train dataset:  43%|████▎     | 3663/8564 [00:08<00:05, 894.67 examples/s]Applying chat template to train dataset:  44%|████▍     | 3770/8564 [00:08<00:05, 914.83 examples/s]Applying chat template to train dataset:  46%|████▌     | 3910/8564 [00:08<00:05, 907.99 examples/s]Applying chat template to train dataset:  47%|████▋     | 4028/8564 [00:09<00:05, 840.03 examples/s]Applying chat template to train dataset:  48%|████▊     | 4125/8564 [00:09<00:05, 864.37 examples/s]Applying chat template to train dataset:  49%|████▉     | 4234/8564 [00:09<00:04, 877.06 examples/s]Applying chat template to train dataset:  51%|█████     | 4334/8564 [00:09<00:04, 882.90 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4483/8564 [00:09<00:04, 896.36 examples/s]Applying chat template to train dataset:  54%|█████▎    | 4590/8564 [00:09<00:04, 920.27 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4722/8564 [00:09<00:03, 1020.66 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4878/8564 [00:10<00:03, 1000.26 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4984/8564 [00:10<00:03, 1013.54 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5089/8564 [00:10<00:03, 1021.53 examples/s]Applying chat template to train dataset:  61%|██████    | 5219/8564 [00:10<00:03, 1038.93 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5331/8564 [00:10<00:03, 1030.29 examples/s]Applying chat template to train dataset:  64%|██████▎   | 5441/8564 [00:10<00:03, 1021.47 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5554/8564 [00:10<00:02, 1024.71 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5668/8564 [00:10<00:02, 1031.31 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5784/8564 [00:10<00:02, 998.72 examples/s] Applying chat template to train dataset:  69%|██████▉   | 5895/8564 [00:11<00:02, 1004.53 examples/s]Applying chat template to train dataset:  70%|███████   | 6019/8564 [00:11<00:02, 915.80 examples/s] Applying chat template to train dataset:  72%|███████▏  | 6130/8564 [00:11<00:02, 927.28 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6250/8564 [00:11<00:02, 949.91 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6348/8564 [00:11<00:02, 956.97 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6463/8564 [00:11<00:02, 944.91 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6580/8564 [00:11<00:02, 975.87 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6759/8564 [00:11<00:01, 1005.28 examples/s]Applying chat template to train dataset:  81%|████████  | 6913/8564 [00:12<00:01, 986.41 examples/s] Applying chat template to train dataset:  83%|████████▎ | 7066/8564 [00:12<00:01, 973.98 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7180/8564 [00:12<00:01, 964.65 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7285/8564 [00:12<00:01, 959.41 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7431/8564 [00:12<00:01, 867.87 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7533/8564 [00:12<00:01, 900.56 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7645/8564 [00:12<00:00, 926.25 examples/s]Applying chat template to train dataset:  90%|█████████ | 7750/8564 [00:13<00:01, 595.43 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7868/8564 [00:13<00:01, 686.20 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7978/8564 [00:13<00:00, 758.32 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8091/8564 [00:13<00:00, 755.82 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8180/8564 [00:13<00:00, 783.37 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8311/8564 [00:13<00:00, 850.82 examples/s]Applying chat template to train dataset:  99%|█████████▊| 8456/8564 [00:13<00:00, 887.73 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:14<00:00, 914.59 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:14<00:00, 605.72 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 1/8564 [00:00<1:03:15,  2.26 examples/s]Tokenizing train dataset:   0%|          | 10/8564 [00:01<15:22,  9.27 examples/s] Tokenizing train dataset:   0%|          | 24/8564 [00:01<05:53, 24.15 examples/s]Tokenizing train dataset:   0%|          | 37/8564 [00:01<03:38, 39.04 examples/s]Tokenizing train dataset:   1%|          | 50/8564 [00:01<02:59, 47.30 examples/s]Tokenizing train dataset:   1%|          | 59/8564 [00:01<02:37, 54.05 examples/s]Tokenizing train dataset:   1%|          | 74/8564 [00:01<01:58, 71.71 examples/s]Tokenizing train dataset:   1%|          | 86/8564 [00:01<01:44, 80.98 examples/s]Tokenizing train dataset:   1%|          | 99/8564 [00:02<01:32, 91.83 examples/s]Tokenizing train dataset:   1%|▏         | 111/8564 [00:02<01:40, 84.43 examples/s]Tokenizing train dataset:   1%|▏         | 122/8564 [00:02<01:39, 84.80 examples/s]Tokenizing train dataset:   2%|▏         | 138/8564 [00:02<01:34, 88.74 examples/s]Tokenizing train dataset:   2%|▏         | 149/8564 [00:02<01:30, 92.90 examples/s]Tokenizing train dataset:   2%|▏         | 160/8564 [00:02<01:30, 92.51 examples/s]Tokenizing train dataset:   2%|▏         | 171/8564 [00:02<01:32, 90.25 examples/s]Tokenizing train dataset:   2%|▏         | 183/8564 [00:03<01:40, 83.00 examples/s]Tokenizing train dataset:   2%|▏         | 195/8564 [00:03<01:32, 89.99 examples/s]Tokenizing train dataset:   3%|▎         | 217/8564 [00:03<01:19, 105.36 examples/s]Tokenizing train dataset:   3%|▎         | 231/8564 [00:03<01:17, 107.31 examples/s]Tokenizing train dataset:   3%|▎         | 247/8564 [00:03<01:13, 112.42 examples/s]Tokenizing train dataset:   3%|▎         | 259/8564 [00:03<01:18, 105.44 examples/s]Tokenizing train dataset:   3%|▎         | 270/8564 [00:03<01:22, 100.96 examples/s]Tokenizing train dataset:   3%|▎         | 283/8564 [00:03<01:20, 103.41 examples/s]Tokenizing train dataset:   3%|▎         | 296/8564 [00:04<01:18, 104.67 examples/s]Tokenizing train dataset:   4%|▎         | 309/8564 [00:04<01:28, 93.25 examples/s] Tokenizing train dataset:   4%|▍         | 323/8564 [00:04<01:28, 92.75 examples/s]Tokenizing train dataset:   4%|▍         | 336/8564 [00:04<01:42, 80.56 examples/s]Tokenizing train dataset:   4%|▍         | 348/8564 [00:04<01:45, 77.65 examples/s]Tokenizing train dataset:   4%|▍         | 360/8564 [00:04<01:35, 85.62 examples/s]Tokenizing train dataset:   4%|▍         | 372/8564 [00:05<01:44, 78.73 examples/s]Tokenizing train dataset:   4%|▍         | 384/8564 [00:05<01:35, 85.59 examples/s]Tokenizing train dataset:   5%|▍         | 399/8564 [00:05<01:33, 87.50 examples/s]Tokenizing train dataset:   5%|▍         | 411/8564 [00:05<01:28, 92.07 examples/s]Tokenizing train dataset:   5%|▌         | 430/8564 [00:05<01:13, 110.10 examples/s]Tokenizing train dataset:   5%|▌         | 444/8564 [00:05<01:10, 114.38 examples/s]Tokenizing train dataset:   5%|▌         | 461/8564 [00:05<01:06, 121.42 examples/s]Tokenizing train dataset:   6%|▌         | 478/8564 [00:05<01:11, 113.05 examples/s]Tokenizing train dataset:   6%|▌         | 495/8564 [00:06<01:18, 102.58 examples/s]Tokenizing train dataset:   6%|▌         | 509/8564 [00:06<01:24, 95.57 examples/s] Tokenizing train dataset:   6%|▌         | 519/8564 [00:06<01:26, 93.49 examples/s]Tokenizing train dataset:   6%|▌         | 533/8564 [00:06<01:19, 101.12 examples/s]Tokenizing train dataset:   6%|▋         | 550/8564 [00:06<01:20, 99.40 examples/s] Tokenizing train dataset:   7%|▋         | 562/8564 [00:06<01:18, 102.27 examples/s]Tokenizing train dataset:   7%|▋         | 577/8564 [00:07<01:23, 95.59 examples/s] Tokenizing train dataset:   7%|▋         | 588/8564 [00:07<02:22, 55.94 examples/s]Tokenizing train dataset:   7%|▋         | 599/8564 [00:07<02:10, 61.13 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:07<01:52, 70.82 examples/s]Tokenizing train dataset:   7%|▋         | 621/8564 [00:07<01:46, 74.32 examples/s]Tokenizing train dataset:   7%|▋         | 637/8564 [00:07<01:30, 87.12 examples/s]Tokenizing train dataset:   8%|▊         | 652/8564 [00:08<01:19, 99.99 examples/s]Tokenizing train dataset:   8%|▊         | 666/8564 [00:08<01:23, 94.26 examples/s]Tokenizing train dataset:   8%|▊         | 682/8564 [00:08<01:23, 94.87 examples/s]Tokenizing train dataset:   8%|▊         | 697/8564 [00:08<01:29, 88.35 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:08<01:28, 88.45 examples/s]Tokenizing train dataset:   8%|▊         | 723/8564 [00:08<01:19, 98.86 examples/s]Tokenizing train dataset:   9%|▊         | 739/8564 [00:08<01:10, 110.75 examples/s]Tokenizing train dataset:   9%|▉         | 752/8564 [00:09<01:13, 106.87 examples/s]Tokenizing train dataset:   9%|▉         | 768/8564 [00:09<01:18, 99.55 examples/s] Tokenizing train dataset:   9%|▉         | 781/8564 [00:09<01:25, 91.55 examples/s]Tokenizing train dataset:   9%|▉         | 791/8564 [00:09<01:34, 82.47 examples/s]Tokenizing train dataset:   9%|▉         | 804/8564 [00:09<01:34, 81.89 examples/s]Tokenizing train dataset:  10%|▉         | 819/8564 [00:09<01:32, 84.14 examples/s]Tokenizing train dataset:  10%|▉         | 832/8564 [00:10<01:40, 76.98 examples/s]Tokenizing train dataset:  10%|▉         | 841/8564 [00:10<01:38, 78.72 examples/s]Tokenizing train dataset:  10%|▉         | 853/8564 [00:10<01:39, 77.33 examples/s]Tokenizing train dataset:  10%|█         | 862/8564 [00:10<01:42, 74.95 examples/s]Tokenizing train dataset:  10%|█         | 872/8564 [00:10<01:36, 79.78 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:10<01:26, 88.99 examples/s]Tokenizing train dataset:  11%|█         | 903/8564 [00:10<01:08, 111.50 examples/s]Tokenizing train dataset:  11%|█         | 918/8564 [00:10<01:15, 101.36 examples/s]Tokenizing train dataset:  11%|█         | 931/8564 [00:11<01:17, 98.56 examples/s] Tokenizing train dataset:  11%|█         | 946/8564 [00:11<01:18, 97.00 examples/s]Tokenizing train dataset:  11%|█         | 959/8564 [00:11<01:15, 100.19 examples/s]Tokenizing train dataset:  11%|█▏        | 974/8564 [00:11<01:16, 98.76 examples/s] Tokenizing train dataset:  12%|█▏        | 987/8564 [00:11<01:22, 91.83 examples/s]Tokenizing train dataset:  12%|█▏        | 1000/8564 [00:11<01:19, 94.68 examples/s]Tokenizing train dataset:  12%|█▏        | 1010/8564 [00:11<01:19, 94.95 examples/s]Tokenizing train dataset:  12%|█▏        | 1023/8564 [00:12<01:23, 90.79 examples/s]Tokenizing train dataset:  12%|█▏        | 1037/8564 [00:12<01:27, 86.23 examples/s]Tokenizing train dataset:  12%|█▏        | 1046/8564 [00:12<01:30, 82.89 examples/s]Tokenizing train dataset:  12%|█▏        | 1059/8564 [00:12<01:24, 88.53 examples/s]Tokenizing train dataset:  12%|█▏        | 1069/8564 [00:12<01:24, 89.19 examples/s]Tokenizing train dataset:  13%|█▎        | 1090/8564 [00:12<01:04, 116.23 examples/s]Tokenizing train dataset:  13%|█▎        | 1106/8564 [00:12<01:07, 110.56 examples/s]Tokenizing train dataset:  13%|█▎        | 1121/8564 [00:13<01:10, 105.27 examples/s]Tokenizing train dataset:  13%|█▎        | 1137/8564 [00:13<01:15, 98.19 examples/s] Tokenizing train dataset:  13%|█▎        | 1152/8564 [00:13<01:19, 93.52 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:13<01:19, 92.44 examples/s]Tokenizing train dataset:  14%|█▍        | 1183/8564 [00:13<01:17, 94.77 examples/s]Tokenizing train dataset:  14%|█▍        | 1193/8564 [00:13<01:17, 94.54 examples/s]Tokenizing train dataset:  14%|█▍        | 1205/8564 [00:13<01:14, 98.82 examples/s]Tokenizing train dataset:  14%|█▍        | 1219/8564 [00:14<01:22, 88.86 examples/s]Tokenizing train dataset:  14%|█▍        | 1233/8564 [00:14<01:16, 96.27 examples/s]Tokenizing train dataset:  15%|█▍        | 1246/8564 [00:14<01:10, 103.48 examples/s]Tokenizing train dataset:  15%|█▍        | 1257/8564 [00:14<01:17, 93.68 examples/s] Tokenizing train dataset:  15%|█▍        | 1270/8564 [00:14<01:16, 95.67 examples/s]Tokenizing train dataset:  15%|█▍        | 1280/8564 [00:14<01:18, 93.10 examples/s]Tokenizing train dataset:  15%|█▌        | 1293/8564 [00:14<01:13, 98.28 examples/s]Tokenizing train dataset:  15%|█▌        | 1308/8564 [00:15<01:09, 104.60 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:15<01:18, 92.71 examples/s] Tokenizing train dataset:  16%|█▌        | 1334/8564 [00:15<01:18, 92.67 examples/s]Tokenizing train dataset:  16%|█▌        | 1348/8564 [00:15<01:13, 98.55 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:15<01:24, 85.30 examples/s]Tokenizing train dataset:  16%|█▌        | 1370/8564 [00:15<01:24, 85.59 examples/s]Tokenizing train dataset:  16%|█▌        | 1379/8564 [00:15<01:23, 85.78 examples/s]Tokenizing train dataset:  16%|█▌        | 1388/8564 [00:16<01:26, 82.68 examples/s]Tokenizing train dataset:  16%|█▋        | 1399/8564 [00:16<01:21, 88.44 examples/s]Tokenizing train dataset:  17%|█▋        | 1414/8564 [00:16<01:22, 87.13 examples/s]Tokenizing train dataset:  17%|█▋        | 1427/8564 [00:16<01:18, 91.17 examples/s]Tokenizing train dataset:  17%|█▋        | 1439/8564 [00:16<01:25, 83.05 examples/s]Tokenizing train dataset:  17%|█▋        | 1449/8564 [00:16<01:22, 86.36 examples/s]Tokenizing train dataset:  17%|█▋        | 1458/8564 [00:16<01:24, 83.68 examples/s]Tokenizing train dataset:  17%|█▋        | 1471/8564 [00:16<01:14, 94.59 examples/s]Tokenizing train dataset:  17%|█▋        | 1483/8564 [00:17<01:21, 87.23 examples/s]Tokenizing train dataset:  17%|█▋        | 1494/8564 [00:17<01:21, 86.88 examples/s]Tokenizing train dataset:  18%|█▊        | 1503/8564 [00:17<01:24, 83.72 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:17<01:24, 82.92 examples/s]Tokenizing train dataset:  18%|█▊        | 1534/8564 [00:17<01:07, 103.56 examples/s]Tokenizing train dataset:  18%|█▊        | 1549/8564 [00:17<01:12, 96.98 examples/s] Tokenizing train dataset:  18%|█▊        | 1560/8564 [00:17<01:14, 94.07 examples/s]Tokenizing train dataset:  18%|█▊        | 1570/8564 [00:18<01:26, 81.27 examples/s]Tokenizing train dataset:  18%|█▊        | 1581/8564 [00:18<01:23, 83.93 examples/s]Tokenizing train dataset:  19%|█▊        | 1594/8564 [00:18<01:14, 93.71 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:18<01:10, 98.80 examples/s]Tokenizing train dataset:  19%|█▉        | 1623/8564 [00:18<01:07, 102.61 examples/s]Tokenizing train dataset:  19%|█▉        | 1634/8564 [00:18<01:08, 101.11 examples/s]Tokenizing train dataset:  19%|█▉        | 1653/8564 [00:18<01:03, 108.26 examples/s]Tokenizing train dataset:  20%|█▉        | 1670/8564 [00:18<00:57, 120.72 examples/s]Tokenizing train dataset:  20%|█▉        | 1690/8564 [00:19<00:56, 122.23 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:19<00:57, 119.94 examples/s]Tokenizing train dataset:  20%|██        | 1721/8564 [00:19<01:01, 111.80 examples/s]Tokenizing train dataset:  20%|██        | 1734/8564 [00:19<01:02, 109.95 examples/s]Tokenizing train dataset:  20%|██        | 1748/8564 [00:19<01:01, 110.04 examples/s]Tokenizing train dataset:  21%|██        | 1761/8564 [00:19<01:00, 112.39 examples/s]Tokenizing train dataset:  21%|██        | 1774/8564 [00:19<01:10, 96.57 examples/s] Tokenizing train dataset:  21%|██        | 1787/8564 [00:20<01:15, 89.78 examples/s]Tokenizing train dataset:  21%|██        | 1797/8564 [00:20<01:14, 90.58 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:20<01:12, 92.70 examples/s]Tokenizing train dataset:  21%|██▏       | 1829/8564 [00:20<01:12, 92.46 examples/s]Tokenizing train dataset:  21%|██▏       | 1841/8564 [00:20<01:09, 96.35 examples/s]Tokenizing train dataset:  22%|██▏       | 1856/8564 [00:20<01:12, 92.85 examples/s]Tokenizing train dataset:  22%|██▏       | 1867/8564 [00:21<01:19, 84.15 examples/s]Tokenizing train dataset:  22%|██▏       | 1880/8564 [00:21<01:23, 79.60 examples/s]Tokenizing train dataset:  22%|██▏       | 1890/8564 [00:21<01:23, 80.40 examples/s]Tokenizing train dataset:  22%|██▏       | 1902/8564 [00:21<01:15, 88.70 examples/s]Tokenizing train dataset:  22%|██▏       | 1922/8564 [00:21<01:01, 108.53 examples/s]Tokenizing train dataset:  23%|██▎       | 1940/8564 [00:21<01:00, 109.02 examples/s]Tokenizing train dataset:  23%|██▎       | 1957/8564 [00:21<01:00, 109.21 examples/s]Tokenizing train dataset:  23%|██▎       | 1970/8564 [00:21<00:58, 112.62 examples/s]Tokenizing train dataset:  23%|██▎       | 1984/8564 [00:22<00:57, 114.87 examples/s]Tokenizing train dataset:  23%|██▎       | 1996/8564 [00:22<00:59, 111.03 examples/s]Tokenizing train dataset:  23%|██▎       | 2010/8564 [00:22<00:55, 117.58 examples/s]Tokenizing train dataset:  24%|██▎       | 2023/8564 [00:22<00:58, 111.53 examples/s]Tokenizing train dataset:  24%|██▍       | 2041/8564 [00:22<01:00, 108.33 examples/s]Tokenizing train dataset:  24%|██▍       | 2059/8564 [00:22<00:54, 118.41 examples/s]Tokenizing train dataset:  24%|██▍       | 2074/8564 [00:22<01:01, 105.05 examples/s]Tokenizing train dataset:  24%|██▍       | 2087/8564 [00:23<00:58, 110.03 examples/s]Tokenizing train dataset:  25%|██▍       | 2105/8564 [00:23<00:59, 107.71 examples/s]Tokenizing train dataset:  25%|██▍       | 2119/8564 [00:23<00:57, 113.03 examples/s]Tokenizing train dataset:  25%|██▍       | 2131/8564 [00:23<00:57, 111.01 examples/s]Tokenizing train dataset:  25%|██▌       | 2149/8564 [00:23<00:51, 123.84 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:23<00:46, 136.32 examples/s]Tokenizing train dataset:  25%|██▌       | 2181/8564 [00:23<00:48, 132.42 examples/s]Tokenizing train dataset:  26%|██▌       | 2200/8564 [00:23<00:50, 126.97 examples/s]Tokenizing train dataset:  26%|██▌       | 2221/8564 [00:24<00:51, 123.02 examples/s]Tokenizing train dataset:  26%|██▌       | 2235/8564 [00:24<00:52, 119.83 examples/s]Tokenizing train dataset:  26%|██▋       | 2249/8564 [00:24<00:51, 121.45 examples/s]Tokenizing train dataset:  26%|██▋       | 2268/8564 [00:24<00:53, 118.18 examples/s]Tokenizing train dataset:  27%|██▋       | 2282/8564 [00:24<00:52, 118.79 examples/s]Tokenizing train dataset:  27%|██▋       | 2296/8564 [00:24<00:51, 121.99 examples/s]Tokenizing train dataset:  27%|██▋       | 2314/8564 [00:24<00:54, 115.40 examples/s]Tokenizing train dataset:  27%|██▋       | 2328/8564 [00:25<00:56, 111.32 examples/s]Tokenizing train dataset:  27%|██▋       | 2344/8564 [00:25<00:58, 105.67 examples/s]Tokenizing train dataset:  28%|██▊       | 2360/8564 [00:25<01:02, 99.49 examples/s] Tokenizing train dataset:  28%|██▊       | 2375/8564 [00:25<00:57, 107.59 examples/s]Tokenizing train dataset:  28%|██▊       | 2389/8564 [00:25<00:54, 114.25 examples/s]Tokenizing train dataset:  28%|██▊       | 2403/8564 [00:25<00:51, 118.72 examples/s]Tokenizing train dataset:  28%|██▊       | 2420/8564 [00:25<00:55, 111.33 examples/s]Tokenizing train dataset:  28%|██▊       | 2440/8564 [00:25<00:48, 126.45 examples/s]Tokenizing train dataset:  29%|██▊       | 2457/8564 [00:26<00:46, 130.77 examples/s]Tokenizing train dataset:  29%|██▉       | 2471/8564 [00:26<00:47, 128.31 examples/s]Tokenizing train dataset:  29%|██▉       | 2488/8564 [00:26<00:53, 114.07 examples/s]Tokenizing train dataset:  29%|██▉       | 2500/8564 [00:26<00:56, 107.42 examples/s]Tokenizing train dataset:  29%|██▉       | 2519/8564 [00:26<00:55, 108.05 examples/s]Tokenizing train dataset:  30%|██▉       | 2532/8564 [00:26<00:53, 112.56 examples/s]Tokenizing train dataset:  30%|██▉       | 2545/8564 [00:26<00:52, 114.88 examples/s]Tokenizing train dataset:  30%|██▉       | 2562/8564 [00:27<00:48, 123.89 examples/s]Tokenizing train dataset:  30%|███       | 2578/8564 [00:27<00:46, 128.58 examples/s]Tokenizing train dataset:  30%|███       | 2599/8564 [00:27<00:52, 113.04 examples/s]Tokenizing train dataset:  31%|███       | 2613/8564 [00:27<00:57, 103.53 examples/s]Tokenizing train dataset:  31%|███       | 2625/8564 [00:27<01:10, 84.05 examples/s] Tokenizing train dataset:  31%|███       | 2641/8564 [00:27<01:08, 86.60 examples/s]Tokenizing train dataset:  31%|███       | 2657/8564 [00:28<01:05, 89.92 examples/s]Tokenizing train dataset:  31%|███       | 2669/8564 [00:28<01:04, 91.85 examples/s]Tokenizing train dataset:  31%|███▏      | 2685/8564 [00:28<01:05, 89.72 examples/s]Tokenizing train dataset:  32%|███▏      | 2698/8564 [00:28<01:00, 96.44 examples/s]Tokenizing train dataset:  32%|███▏      | 2709/8564 [00:28<00:59, 99.20 examples/s]Tokenizing train dataset:  32%|███▏      | 2723/8564 [00:28<00:56, 103.12 examples/s]Tokenizing train dataset:  32%|███▏      | 2735/8564 [00:28<00:56, 103.00 examples/s]Tokenizing train dataset:  32%|███▏      | 2747/8564 [00:28<00:57, 100.72 examples/s]Tokenizing train dataset:  32%|███▏      | 2761/8564 [00:29<01:01, 94.33 examples/s] Tokenizing train dataset:  32%|███▏      | 2772/8564 [00:29<00:59, 97.62 examples/s]Tokenizing train dataset:  33%|███▎      | 2788/8564 [00:29<00:53, 107.38 examples/s]Tokenizing train dataset:  33%|███▎      | 2804/8564 [00:29<00:56, 102.28 examples/s]Tokenizing train dataset:  33%|███▎      | 2825/8564 [00:29<00:45, 125.86 examples/s]Tokenizing train dataset:  33%|███▎      | 2840/8564 [00:29<00:49, 116.35 examples/s]Tokenizing train dataset:  33%|███▎      | 2857/8564 [00:29<00:51, 111.42 examples/s]Tokenizing train dataset:  34%|███▎      | 2873/8564 [00:30<00:54, 105.05 examples/s]Tokenizing train dataset:  34%|███▎      | 2886/8564 [00:30<00:52, 107.70 examples/s]Tokenizing train dataset:  34%|███▍      | 2900/8564 [00:30<00:49, 113.56 examples/s]Tokenizing train dataset:  34%|███▍      | 2913/8564 [00:30<00:48, 116.60 examples/s]Tokenizing train dataset:  34%|███▍      | 2926/8564 [00:30<00:48, 115.18 examples/s]Tokenizing train dataset:  34%|███▍      | 2942/8564 [00:30<00:45, 122.82 examples/s]Tokenizing train dataset:  35%|███▍      | 2958/8564 [00:30<00:43, 127.72 examples/s]Tokenizing train dataset:  35%|███▍      | 2977/8564 [00:30<00:39, 140.97 examples/s]Tokenizing train dataset:  35%|███▍      | 2993/8564 [00:31<00:40, 138.15 examples/s]Tokenizing train dataset:  35%|███▌      | 3007/8564 [00:31<00:43, 129.21 examples/s]Tokenizing train dataset:  35%|███▌      | 3029/8564 [00:31<00:42, 129.74 examples/s]Tokenizing train dataset:  36%|███▌      | 3044/8564 [00:31<00:46, 118.58 examples/s]Tokenizing train dataset:  36%|███▌      | 3059/8564 [00:31<00:50, 108.37 examples/s]Tokenizing train dataset:  36%|███▌      | 3072/8564 [00:31<00:50, 108.98 examples/s]Tokenizing train dataset:  36%|███▌      | 3088/8564 [00:31<00:46, 117.61 examples/s]Tokenizing train dataset:  36%|███▋      | 3109/8564 [00:32<00:44, 121.52 examples/s]Tokenizing train dataset:  36%|███▋      | 3123/8564 [00:32<00:50, 107.94 examples/s]Tokenizing train dataset:  37%|███▋      | 3142/8564 [00:32<00:50, 107.03 examples/s]Tokenizing train dataset:  37%|███▋      | 3158/8564 [00:32<00:46, 117.36 examples/s]Tokenizing train dataset:  37%|███▋      | 3171/8564 [00:32<00:55, 97.91 examples/s] Tokenizing train dataset:  37%|███▋      | 3185/8564 [00:32<00:51, 104.61 examples/s]Tokenizing train dataset:  37%|███▋      | 3198/8564 [00:32<00:49, 108.77 examples/s]Tokenizing train dataset:  37%|███▋      | 3210/8564 [00:33<00:50, 106.53 examples/s]Tokenizing train dataset:  38%|███▊      | 3227/8564 [00:33<00:46, 114.17 examples/s]Tokenizing train dataset:  38%|███▊      | 3240/8564 [00:33<00:45, 115.88 examples/s]Tokenizing train dataset:  38%|███▊      | 3253/8564 [00:33<00:46, 113.74 examples/s]Tokenizing train dataset:  38%|███▊      | 3269/8564 [00:33<00:50, 104.19 examples/s]Tokenizing train dataset:  38%|███▊      | 3283/8564 [00:33<00:53, 99.57 examples/s] Tokenizing train dataset:  38%|███▊      | 3294/8564 [00:33<00:54, 96.37 examples/s]Tokenizing train dataset:  39%|███▊      | 3308/8564 [00:33<00:51, 102.98 examples/s]Tokenizing train dataset:  39%|███▉      | 3323/8564 [00:34<00:46, 113.19 examples/s]Tokenizing train dataset:  39%|███▉      | 3338/8564 [00:34<00:45, 115.44 examples/s]Tokenizing train dataset:  39%|███▉      | 3357/8564 [00:34<00:39, 131.56 examples/s]Tokenizing train dataset:  39%|███▉      | 3375/8564 [00:34<00:42, 122.77 examples/s]Tokenizing train dataset:  40%|███▉      | 3391/8564 [00:34<00:44, 116.43 examples/s]Tokenizing train dataset:  40%|███▉      | 3410/8564 [00:34<00:44, 117.06 examples/s]Tokenizing train dataset:  40%|███▉      | 3423/8564 [00:34<00:44, 115.40 examples/s]Tokenizing train dataset:  40%|████      | 3438/8564 [00:35<00:43, 118.90 examples/s]Tokenizing train dataset:  40%|████      | 3456/8564 [00:35<00:43, 116.83 examples/s]Tokenizing train dataset:  41%|████      | 3469/8564 [00:35<00:45, 112.39 examples/s]Tokenizing train dataset:  41%|████      | 3486/8564 [00:35<00:48, 104.50 examples/s]Tokenizing train dataset:  41%|████      | 3500/8564 [00:35<00:46, 109.12 examples/s]Tokenizing train dataset:  41%|████      | 3520/8564 [00:35<00:41, 121.37 examples/s]Tokenizing train dataset:  41%|████▏     | 3535/8564 [00:35<00:41, 121.99 examples/s]Tokenizing train dataset:  41%|████▏     | 3548/8564 [00:36<00:43, 115.79 examples/s]Tokenizing train dataset:  42%|████▏     | 3564/8564 [00:36<00:46, 106.58 examples/s]Tokenizing train dataset:  42%|████▏     | 3580/8564 [00:36<00:44, 113.18 examples/s]Tokenizing train dataset:  42%|████▏     | 3592/8564 [00:36<00:43, 113.98 examples/s]Tokenizing train dataset:  42%|████▏     | 3610/8564 [00:36<00:39, 125.16 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:36<00:39, 124.02 examples/s]Tokenizing train dataset:  43%|████▎     | 3641/8564 [00:36<00:45, 108.08 examples/s]Tokenizing train dataset:  43%|████▎     | 3663/8564 [00:37<00:45, 107.02 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:37<00:46, 104.06 examples/s]Tokenizing train dataset:  43%|████▎     | 3693/8564 [00:37<00:46, 105.62 examples/s]Tokenizing train dataset:  43%|████▎     | 3710/8564 [00:37<00:46, 104.27 examples/s]Tokenizing train dataset:  44%|████▎     | 3731/8564 [00:37<00:40, 120.14 examples/s]Tokenizing train dataset:  44%|████▍     | 3750/8564 [00:37<00:41, 115.96 examples/s]Tokenizing train dataset:  44%|████▍     | 3765/8564 [00:37<00:41, 116.81 examples/s]Tokenizing train dataset:  44%|████▍     | 3783/8564 [00:38<00:42, 113.09 examples/s]Tokenizing train dataset:  44%|████▍     | 3800/8564 [00:38<00:43, 108.96 examples/s]Tokenizing train dataset:  45%|████▍     | 3812/8564 [00:38<00:43, 109.63 examples/s]Tokenizing train dataset:  45%|████▍     | 3827/8564 [00:38<00:42, 111.15 examples/s]Tokenizing train dataset:  45%|████▍     | 3840/8564 [00:38<00:44, 105.68 examples/s]Tokenizing train dataset:  45%|████▍     | 3851/8564 [00:38<00:44, 105.00 examples/s]Tokenizing train dataset:  45%|████▌     | 3866/8564 [00:38<00:41, 112.95 examples/s]Tokenizing train dataset:  45%|████▌     | 3883/8564 [00:39<00:42, 110.06 examples/s]Tokenizing train dataset:  46%|████▌     | 3899/8564 [00:39<00:38, 119.84 examples/s]Tokenizing train dataset:  46%|████▌     | 3912/8564 [00:39<00:45, 103.36 examples/s]Tokenizing train dataset:  46%|████▌     | 3927/8564 [00:39<00:47, 97.48 examples/s] Tokenizing train dataset:  46%|████▌     | 3948/8564 [00:39<00:39, 115.90 examples/s]Tokenizing train dataset:  46%|████▋     | 3961/8564 [00:39<00:39, 117.98 examples/s]Tokenizing train dataset:  46%|████▋     | 3980/8564 [00:39<00:39, 114.95 examples/s]Tokenizing train dataset:  47%|████▋     | 3994/8564 [00:40<00:39, 115.93 examples/s]Tokenizing train dataset:  47%|████▋     | 4009/8564 [00:40<00:39, 115.16 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:40<00:41, 110.59 examples/s]Tokenizing train dataset:  47%|████▋     | 4036/8564 [00:40<00:40, 113.09 examples/s]Tokenizing train dataset:  47%|████▋     | 4050/8564 [00:40<00:39, 115.49 examples/s]Tokenizing train dataset:  47%|████▋     | 4062/8564 [00:40<00:39, 112.78 examples/s]Tokenizing train dataset:  48%|████▊     | 4075/8564 [00:40<00:39, 112.85 examples/s]Tokenizing train dataset:  48%|████▊     | 4091/8564 [00:40<00:40, 109.46 examples/s]Tokenizing train dataset:  48%|████▊     | 4105/8564 [00:41<00:43, 101.93 examples/s]Tokenizing train dataset:  48%|████▊     | 4120/8564 [00:41<00:44, 98.86 examples/s] Tokenizing train dataset:  48%|████▊     | 4132/8564 [00:41<00:46, 95.28 examples/s]Tokenizing train dataset:  48%|████▊     | 4145/8564 [00:41<00:45, 97.98 examples/s]Tokenizing train dataset:  49%|████▊     | 4158/8564 [00:41<00:47, 92.16 examples/s]Tokenizing train dataset:  49%|████▊     | 4169/8564 [00:41<00:46, 93.64 examples/s]Tokenizing train dataset:  49%|████▉     | 4180/8564 [00:41<00:45, 95.99 examples/s]Tokenizing train dataset:  49%|████▉     | 4194/8564 [00:41<00:41, 104.26 examples/s]Tokenizing train dataset:  49%|████▉     | 4210/8564 [00:42<00:39, 110.33 examples/s]Tokenizing train dataset:  49%|████▉     | 4224/8564 [00:42<00:39, 111.17 examples/s]Tokenizing train dataset:  50%|████▉     | 4240/8564 [00:42<00:40, 105.49 examples/s]Tokenizing train dataset:  50%|████▉     | 4258/8564 [00:42<00:41, 104.86 examples/s]Tokenizing train dataset:  50%|████▉     | 4273/8564 [00:42<00:42, 100.23 examples/s]Tokenizing train dataset:  50%|█████     | 4285/8564 [00:42<00:41, 103.54 examples/s]Tokenizing train dataset:  50%|█████     | 4297/8564 [00:42<00:40, 104.76 examples/s]Tokenizing train dataset:  50%|█████     | 4313/8564 [00:43<00:41, 101.41 examples/s]Tokenizing train dataset:  51%|█████     | 4326/8564 [00:43<00:41, 101.47 examples/s]Tokenizing train dataset:  51%|█████     | 4340/8564 [00:43<00:43, 97.28 examples/s] Tokenizing train dataset:  51%|█████     | 4353/8564 [00:43<00:40, 103.29 examples/s]Tokenizing train dataset:  51%|█████     | 4364/8564 [00:43<00:40, 103.75 examples/s]Tokenizing train dataset:  51%|█████     | 4379/8564 [00:43<00:36, 114.19 examples/s]Tokenizing train dataset:  51%|█████▏    | 4394/8564 [00:43<00:34, 120.30 examples/s]Tokenizing train dataset:  52%|█████▏    | 4413/8564 [00:43<00:36, 115.04 examples/s]Tokenizing train dataset:  52%|█████▏    | 4425/8564 [00:44<00:36, 114.72 examples/s]Tokenizing train dataset:  52%|█████▏    | 4439/8564 [00:44<00:36, 114.22 examples/s]Tokenizing train dataset:  52%|█████▏    | 4456/8564 [00:44<00:38, 107.13 examples/s]Tokenizing train dataset:  52%|█████▏    | 4475/8564 [00:44<00:37, 109.56 examples/s]Tokenizing train dataset:  52%|█████▏    | 4487/8564 [00:44<00:39, 103.65 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:44<00:39, 103.67 examples/s]Tokenizing train dataset:  53%|█████▎    | 4510/8564 [00:44<00:39, 102.94 examples/s]Tokenizing train dataset:  53%|█████▎    | 4523/8564 [00:45<00:42, 94.04 examples/s] Tokenizing train dataset:  53%|█████▎    | 4536/8564 [00:45<00:41, 96.20 examples/s]Tokenizing train dataset:  53%|█████▎    | 4551/8564 [00:45<00:39, 102.70 examples/s]Tokenizing train dataset:  53%|█████▎    | 4563/8564 [00:45<00:37, 106.68 examples/s]Tokenizing train dataset:  53%|█████▎    | 4579/8564 [00:45<00:40, 98.33 examples/s] Tokenizing train dataset:  54%|█████▎    | 4590/8564 [00:45<00:40, 97.92 examples/s]Tokenizing train dataset:  54%|█████▎    | 4603/8564 [00:45<00:39, 100.83 examples/s]Tokenizing train dataset:  54%|█████▍    | 4618/8564 [00:45<00:36, 109.10 examples/s]Tokenizing train dataset:  54%|█████▍    | 4630/8564 [00:46<00:37, 104.27 examples/s]Tokenizing train dataset:  54%|█████▍    | 4643/8564 [00:46<00:41, 93.47 examples/s] Tokenizing train dataset:  54%|█████▍    | 4657/8564 [00:46<00:42, 91.85 examples/s]Tokenizing train dataset:  55%|█████▍    | 4673/8564 [00:46<00:49, 78.55 examples/s]Tokenizing train dataset:  55%|█████▍    | 4686/8564 [00:46<00:45, 84.81 examples/s]Tokenizing train dataset:  55%|█████▍    | 4697/8564 [00:46<00:43, 88.92 examples/s]Tokenizing train dataset:  55%|█████▍    | 4709/8564 [00:47<00:45, 84.98 examples/s]Tokenizing train dataset:  55%|█████▌    | 4722/8564 [00:47<00:43, 88.65 examples/s]Tokenizing train dataset:  55%|█████▌    | 4734/8564 [00:47<00:40, 94.71 examples/s]Tokenizing train dataset:  55%|█████▌    | 4744/8564 [00:47<00:40, 93.72 examples/s]Tokenizing train dataset:  56%|█████▌    | 4754/8564 [00:47<00:41, 91.53 examples/s]Tokenizing train dataset:  56%|█████▌    | 4764/8564 [00:47<00:41, 90.86 examples/s]Tokenizing train dataset:  56%|█████▌    | 4778/8564 [00:47<00:43, 87.36 examples/s]Tokenizing train dataset:  56%|█████▌    | 4791/8564 [00:47<00:38, 97.19 examples/s]Tokenizing train dataset:  56%|█████▌    | 4810/8564 [00:48<00:36, 102.09 examples/s]Tokenizing train dataset:  56%|█████▋    | 4829/8564 [00:48<00:31, 119.32 examples/s]Tokenizing train dataset:  57%|█████▋    | 4847/8564 [00:48<00:27, 133.76 examples/s]Tokenizing train dataset:  57%|█████▋    | 4861/8564 [00:48<00:27, 134.74 examples/s]Tokenizing train dataset:  57%|█████▋    | 4877/8564 [00:48<00:26, 140.61 examples/s]Tokenizing train dataset:  57%|█████▋    | 4894/8564 [00:48<00:26, 139.86 examples/s]Tokenizing train dataset:  57%|█████▋    | 4912/8564 [00:48<00:25, 142.85 examples/s]Tokenizing train dataset:  58%|█████▊    | 4939/8564 [00:48<00:20, 173.89 examples/s]Tokenizing train dataset:  58%|█████▊    | 4958/8564 [00:48<00:20, 171.95 examples/s]Tokenizing train dataset:  58%|█████▊    | 4980/8564 [00:49<00:19, 181.98 examples/s]Tokenizing train dataset:  58%|█████▊    | 4999/8564 [00:49<00:19, 178.92 examples/s]Tokenizing train dataset:  59%|█████▊    | 5020/8564 [00:49<00:19, 183.70 examples/s]Tokenizing train dataset:  59%|█████▉    | 5055/8564 [00:49<00:18, 193.74 examples/s]Tokenizing train dataset:  59%|█████▉    | 5082/8564 [00:49<00:17, 201.95 examples/s]Tokenizing train dataset:  60%|█████▉    | 5106/8564 [00:49<00:16, 204.13 examples/s]Tokenizing train dataset:  60%|█████▉    | 5127/8564 [00:49<00:16, 204.54 examples/s]Tokenizing train dataset:  60%|██████    | 5150/8564 [00:49<00:16, 206.10 examples/s]Tokenizing train dataset:  60%|██████    | 5176/8564 [00:50<00:15, 218.35 examples/s]Tokenizing train dataset:  61%|██████    | 5200/8564 [00:50<00:15, 211.81 examples/s]Tokenizing train dataset:  61%|██████    | 5230/8564 [00:50<00:16, 196.52 examples/s]Tokenizing train dataset:  61%|██████▏   | 5260/8564 [00:50<00:15, 208.13 examples/s]Tokenizing train dataset:  62%|██████▏   | 5282/8564 [00:50<00:15, 210.59 examples/s]Tokenizing train dataset:  62%|██████▏   | 5309/8564 [00:50<00:16, 193.82 examples/s]Tokenizing train dataset:  62%|██████▏   | 5330/8564 [00:50<00:16, 190.75 examples/s]Tokenizing train dataset:  62%|██████▏   | 5350/8564 [00:50<00:16, 192.34 examples/s]Tokenizing train dataset:  63%|██████▎   | 5380/8564 [00:51<00:17, 186.67 examples/s]Tokenizing train dataset:  63%|██████▎   | 5410/8564 [00:51<00:17, 182.68 examples/s]Tokenizing train dataset:  63%|██████▎   | 5437/8564 [00:51<00:15, 202.09 examples/s]Tokenizing train dataset:  64%|██████▍   | 5465/8564 [00:51<00:15, 194.51 examples/s]Tokenizing train dataset:  64%|██████▍   | 5496/8564 [00:51<00:16, 186.66 examples/s]Tokenizing train dataset:  64%|██████▍   | 5522/8564 [00:51<00:16, 180.75 examples/s]Tokenizing train dataset:  65%|██████▍   | 5548/8564 [00:52<00:17, 169.29 examples/s]Tokenizing train dataset:  65%|██████▌   | 5580/8564 [00:52<00:16, 178.71 examples/s]Tokenizing train dataset:  65%|██████▌   | 5607/8564 [00:52<00:15, 189.10 examples/s]Tokenizing train dataset:  66%|██████▌   | 5636/8564 [00:52<00:15, 187.79 examples/s]Tokenizing train dataset:  66%|██████▌   | 5663/8564 [00:52<00:14, 197.22 examples/s]Tokenizing train dataset:  66%|██████▋   | 5691/8564 [00:52<00:15, 188.48 examples/s]Tokenizing train dataset:  67%|██████▋   | 5715/8564 [00:52<00:14, 198.30 examples/s]Tokenizing train dataset:  67%|██████▋   | 5751/8564 [00:53<00:13, 210.59 examples/s]Tokenizing train dataset:  67%|██████▋   | 5778/8564 [00:53<00:12, 222.57 examples/s]Tokenizing train dataset:  68%|██████▊   | 5803/8564 [00:53<00:12, 220.11 examples/s]Tokenizing train dataset:  68%|██████▊   | 5836/8564 [00:53<00:12, 211.66 examples/s]Tokenizing train dataset:  68%|██████▊   | 5862/8564 [00:53<00:13, 193.57 examples/s]Tokenizing train dataset:  69%|██████▊   | 5883/8564 [00:53<00:15, 169.13 examples/s]Tokenizing train dataset:  69%|██████▉   | 5903/8564 [00:53<00:15, 168.50 examples/s]Tokenizing train dataset:  69%|██████▉   | 5930/8564 [00:53<00:13, 190.97 examples/s]Tokenizing train dataset:  70%|██████▉   | 5964/8564 [00:54<00:13, 194.08 examples/s]Tokenizing train dataset:  70%|██████▉   | 5992/8564 [00:54<00:22, 114.30 examples/s]Tokenizing train dataset:  70%|███████   | 6015/8564 [00:54<00:19, 130.97 examples/s]Tokenizing train dataset:  71%|███████   | 6040/8564 [00:54<00:18, 137.68 examples/s]Tokenizing train dataset:  71%|███████   | 6066/8564 [00:55<00:15, 157.03 examples/s]Tokenizing train dataset:  71%|███████   | 6089/8564 [00:55<00:16, 149.74 examples/s]Tokenizing train dataset:  71%|███████▏  | 6117/8564 [00:55<00:15, 158.53 examples/s]Tokenizing train dataset:  72%|███████▏  | 6141/8564 [00:55<00:13, 173.57 examples/s]Tokenizing train dataset:  72%|███████▏  | 6167/8564 [00:55<00:12, 188.43 examples/s]Tokenizing train dataset:  72%|███████▏  | 6197/8564 [00:55<00:13, 180.14 examples/s]Tokenizing train dataset:  73%|███████▎  | 6219/8564 [00:55<00:12, 186.21 examples/s]Tokenizing train dataset:  73%|███████▎  | 6241/8564 [00:55<00:12, 183.49 examples/s]Tokenizing train dataset:  73%|███████▎  | 6268/8564 [00:56<00:11, 200.83 examples/s]Tokenizing train dataset:  73%|███████▎  | 6290/8564 [00:56<00:11, 195.46 examples/s]Tokenizing train dataset:  74%|███████▎  | 6311/8564 [00:56<00:12, 186.36 examples/s]Tokenizing train dataset:  74%|███████▍  | 6332/8564 [00:56<00:11, 190.32 examples/s]Tokenizing train dataset:  74%|███████▍  | 6360/8564 [00:56<00:10, 208.66 examples/s]Tokenizing train dataset:  75%|███████▍  | 6387/8564 [00:56<00:09, 224.61 examples/s]Tokenizing train dataset:  75%|███████▍  | 6414/8564 [00:56<00:10, 199.61 examples/s]Tokenizing train dataset:  75%|███████▌  | 6440/8564 [00:56<00:10, 206.07 examples/s]Tokenizing train dataset:  76%|███████▌  | 6467/8564 [00:57<00:11, 188.91 examples/s]Tokenizing train dataset:  76%|███████▌  | 6487/8564 [00:57<00:11, 186.68 examples/s]Tokenizing train dataset:  76%|███████▌  | 6516/8564 [00:57<00:11, 181.97 examples/s]Tokenizing train dataset:  76%|███████▋  | 6539/8564 [00:57<00:10, 184.65 examples/s]Tokenizing train dataset:  77%|███████▋  | 6559/8564 [00:57<00:10, 186.90 examples/s]Tokenizing train dataset:  77%|███████▋  | 6579/8564 [00:57<00:12, 162.27 examples/s]Tokenizing train dataset:  77%|███████▋  | 6605/8564 [00:57<00:11, 163.94 examples/s]Tokenizing train dataset:  77%|███████▋  | 6630/8564 [00:58<00:11, 168.84 examples/s]Tokenizing train dataset:  78%|███████▊  | 6650/8564 [00:58<00:11, 172.17 examples/s]Tokenizing train dataset:  78%|███████▊  | 6678/8564 [00:58<00:09, 191.62 examples/s]Tokenizing train dataset:  78%|███████▊  | 6704/8564 [00:58<00:09, 194.14 examples/s]Tokenizing train dataset:  79%|███████▊  | 6726/8564 [00:58<00:09, 195.31 examples/s]Tokenizing train dataset:  79%|███████▉  | 6749/8564 [00:58<00:09, 199.38 examples/s]Tokenizing train dataset:  79%|███████▉  | 6770/8564 [00:58<00:09, 198.04 examples/s]Tokenizing train dataset:  79%|███████▉  | 6790/8564 [00:58<00:09, 188.55 examples/s]Tokenizing train dataset:  80%|███████▉  | 6812/8564 [00:58<00:09, 191.65 examples/s]Tokenizing train dataset:  80%|███████▉  | 6837/8564 [00:59<00:10, 166.71 examples/s]Tokenizing train dataset:  80%|████████  | 6860/8564 [00:59<00:09, 180.53 examples/s]Tokenizing train dataset:  80%|████████  | 6894/8564 [00:59<00:07, 213.27 examples/s]Tokenizing train dataset:  81%|████████  | 6930/8564 [00:59<00:07, 216.64 examples/s]Tokenizing train dataset:  81%|████████▏ | 6962/8564 [00:59<00:08, 199.29 examples/s]Tokenizing train dataset:  82%|████████▏ | 6983/8564 [00:59<00:07, 198.97 examples/s]Tokenizing train dataset:  82%|████████▏ | 7010/8564 [00:59<00:08, 188.47 examples/s]Tokenizing train dataset:  82%|████████▏ | 7032/8564 [01:00<00:09, 169.07 examples/s]Tokenizing train dataset:  82%|████████▏ | 7060/8564 [01:00<00:08, 185.11 examples/s]Tokenizing train dataset:  83%|████████▎ | 7085/8564 [01:00<00:07, 184.95 examples/s]Tokenizing train dataset:  83%|████████▎ | 7127/8564 [01:00<00:06, 207.69 examples/s]Tokenizing train dataset:  84%|████████▎ | 7155/8564 [01:00<00:06, 215.38 examples/s]Tokenizing train dataset:  84%|████████▍ | 7184/8564 [01:00<00:06, 226.97 examples/s]Tokenizing train dataset:  84%|████████▍ | 7208/8564 [01:00<00:05, 229.74 examples/s]Tokenizing train dataset:  84%|████████▍ | 7234/8564 [01:01<00:07, 183.08 examples/s]Tokenizing train dataset:  85%|████████▍ | 7261/8564 [01:01<00:07, 175.40 examples/s]Tokenizing train dataset:  85%|████████▌ | 7283/8564 [01:01<00:07, 178.91 examples/s]Tokenizing train dataset:  85%|████████▌ | 7309/8564 [01:01<00:06, 182.90 examples/s]Tokenizing train dataset:  86%|████████▌ | 7338/8564 [01:01<00:06, 183.58 examples/s]Tokenizing train dataset:  86%|████████▌ | 7363/8564 [01:01<00:06, 189.74 examples/s]Tokenizing train dataset:  86%|████████▋ | 7390/8564 [01:01<00:06, 181.04 examples/s]Tokenizing train dataset:  87%|████████▋ | 7426/8564 [01:02<00:05, 216.95 examples/s]Tokenizing train dataset:  87%|████████▋ | 7451/8564 [01:02<00:06, 181.95 examples/s]Tokenizing train dataset:  87%|████████▋ | 7472/8564 [01:02<00:05, 183.65 examples/s]Tokenizing train dataset:  88%|████████▊ | 7495/8564 [01:02<00:05, 193.41 examples/s]Tokenizing train dataset:  88%|████████▊ | 7530/8564 [01:02<00:05, 193.57 examples/s]Tokenizing train dataset:  88%|████████▊ | 7552/8564 [01:02<00:05, 197.28 examples/s]Tokenizing train dataset:  89%|████████▊ | 7585/8564 [01:02<00:04, 210.69 examples/s]Tokenizing train dataset:  89%|████████▉ | 7613/8564 [01:03<00:04, 195.75 examples/s]Tokenizing train dataset:  89%|████████▉ | 7643/8564 [01:03<00:04, 194.51 examples/s]Tokenizing train dataset:  90%|████████▉ | 7670/8564 [01:03<00:04, 184.97 examples/s]Tokenizing train dataset:  90%|████████▉ | 7690/8564 [01:03<00:04, 183.10 examples/s]Tokenizing train dataset:  90%|█████████ | 7714/8564 [01:03<00:04, 173.47 examples/s]Tokenizing train dataset:  90%|█████████ | 7740/8564 [01:03<00:04, 171.42 examples/s]Tokenizing train dataset:  91%|█████████ | 7762/8564 [01:04<00:05, 155.03 examples/s]Tokenizing train dataset:  91%|█████████ | 7790/8564 [01:04<00:04, 171.29 examples/s]Tokenizing train dataset:  91%|█████████ | 7808/8564 [01:04<00:04, 160.41 examples/s]Tokenizing train dataset:  91%|█████████▏| 7832/8564 [01:04<00:04, 169.83 examples/s]Tokenizing train dataset:  92%|█████████▏| 7852/8564 [01:04<00:04, 168.53 examples/s]Tokenizing train dataset:  92%|█████████▏| 7877/8564 [01:04<00:04, 161.07 examples/s]Tokenizing train dataset:  92%|█████████▏| 7898/8564 [01:04<00:03, 171.08 examples/s]Tokenizing train dataset:  92%|█████████▏| 7918/8564 [01:04<00:03, 174.50 examples/s]Tokenizing train dataset:  93%|█████████▎| 7940/8564 [01:05<00:03, 175.55 examples/s]Tokenizing train dataset:  93%|█████████▎| 7959/8564 [01:05<00:03, 178.38 examples/s]Tokenizing train dataset:  93%|█████████▎| 7985/8564 [01:05<00:03, 191.36 examples/s]Tokenizing train dataset:  94%|█████████▎| 8012/8564 [01:05<00:02, 208.64 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:05<00:02, 207.46 examples/s]Tokenizing train dataset:  94%|█████████▍| 8068/8564 [01:05<00:02, 198.30 examples/s]Tokenizing train dataset:  95%|█████████▍| 8097/8564 [01:05<00:02, 185.80 examples/s]Tokenizing train dataset:  95%|█████████▍| 8120/8564 [01:05<00:02, 173.40 examples/s]Tokenizing train dataset:  95%|█████████▌| 8140/8564 [01:06<00:02, 166.49 examples/s]Tokenizing train dataset:  95%|█████████▌| 8160/8564 [01:06<00:02, 173.24 examples/s]Tokenizing train dataset:  96%|█████████▌| 8186/8564 [01:06<00:02, 170.38 examples/s]Tokenizing train dataset:  96%|█████████▌| 8209/8564 [01:06<00:02, 172.70 examples/s]Tokenizing train dataset:  96%|█████████▌| 8240/8564 [01:06<00:01, 199.39 examples/s]Tokenizing train dataset:  97%|█████████▋| 8269/8564 [01:06<00:01, 214.80 examples/s]Tokenizing train dataset:  97%|█████████▋| 8297/8564 [01:06<00:01, 224.09 examples/s]Tokenizing train dataset:  97%|█████████▋| 8326/8564 [01:07<00:01, 206.09 examples/s]Tokenizing train dataset:  98%|█████████▊| 8353/8564 [01:07<00:01, 189.90 examples/s]Tokenizing train dataset:  98%|█████████▊| 8373/8564 [01:07<00:01, 189.29 examples/s]Tokenizing train dataset:  98%|█████████▊| 8405/8564 [01:07<00:00, 194.85 examples/s]Tokenizing train dataset:  98%|█████████▊| 8429/8564 [01:07<00:00, 197.01 examples/s]Tokenizing train dataset:  99%|█████████▊| 8456/8564 [01:07<00:00, 184.12 examples/s]Tokenizing train dataset:  99%|█████████▉| 8485/8564 [01:07<00:00, 204.41 examples/s]Tokenizing train dataset:  99%|█████████▉| 8510/8564 [01:07<00:00, 199.44 examples/s]Tokenizing train dataset: 100%|█████████▉| 8534/8564 [01:08<00:00, 199.37 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:08<00:00, 206.53 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:08<00:00, 125.43 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  75%|███████▌  | 718/953 [00:00<00:00, 7131.21 examples/s]Extracting prompt in train dataset:   0%|          | 10/8564 [00:00<01:34, 90.84 examples/s]Extracting prompt in train dataset:   1%|▏         | 120/8564 [00:00<00:09, 880.73 examples/s]Extracting prompt in train dataset:   2%|▏         | 144/8564 [00:00<00:08, 1009.94 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5142.23 examples/s]
Extracting prompt in train dataset:   4%|▍         | 330/8564 [00:00<00:05, 1424.44 examples/s]Extracting prompt in train dataset:   3%|▎         | 220/8564 [00:00<00:07, 1191.80 examples/s]Extracting prompt in train dataset:   4%|▎         | 310/8564 [00:00<00:05, 1386.16 examples/s]Extracting prompt in train dataset:   7%|▋         | 603/8564 [00:00<00:04, 1966.00 examples/s]Extracting prompt in train dataset:   5%|▍         | 386/8564 [00:00<00:07, 1060.54 examples/s]Extracting prompt in train dataset:   5%|▌         | 470/8564 [00:00<00:06, 1263.46 examples/s]Extracting prompt in train dataset:   6%|▋         | 538/8564 [00:00<00:06, 1206.95 examples/s]Extracting prompt in train dataset:   8%|▊         | 681/8564 [00:00<00:06, 1306.78 examples/s]Extracting prompt in train dataset:  10%|▉         | 832/8564 [00:00<00:05, 1485.59 examples/s]Extracting prompt in train dataset:   9%|▊         | 738/8564 [00:00<00:05, 1456.36 examples/s]Extracting prompt in train dataset:  10%|▉         | 840/8564 [00:00<00:06, 1207.21 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1110/8564 [00:00<00:04, 1575.51 examples/s]Extracting prompt in train dataset:  11%|█         | 914/8564 [00:00<00:05, 1315.79 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1340/8564 [00:00<00:04, 1723.33 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1068/8564 [00:00<00:05, 1315.03 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1100/8564 [00:00<00:05, 1459.49 examples/s]Extracting prompt in train dataset:  14%|█▍        | 1210/8564 [00:00<00:05, 1286.37 examples/s]Extracting prompt in train dataset:  15%|█▍        | 1260/8564 [00:00<00:04, 1487.92 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  19%|█▊        | 1590/8564 [00:01<00:04, 1494.22 examples/s]Extracting prompt in train dataset:  16%|█▋        | 1400/8564 [00:01<00:04, 1441.41 examples/s]Applying chat template to eval dataset:  71%|███████   | 678/953 [00:00<00:00, 6717.02 examples/s]Extracting prompt in train dataset:  21%|██▏       | 1837/8564 [00:01<00:03, 1710.41 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 6117.34 examples/s]
Extracting prompt in train dataset:  19%|█▉        | 1658/8564 [00:01<00:04, 1483.75 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1420/8564 [00:01<00:07, 979.24 examples/s] Extracting prompt in train dataset:  24%|██▍       | 2050/8564 [00:01<00:03, 1808.87 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1858/8564 [00:01<00:04, 1591.08 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1560/8564 [00:01<00:06, 1054.04 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2110/8564 [00:01<00:03, 1812.39 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2340/8564 [00:01<00:03, 1931.66 examples/s]Extracting prompt in train dataset:  20%|██        | 1736/8564 [00:01<00:06, 1039.85 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2281/8564 [00:01<00:05, 1233.38 examples/s]Extracting prompt in train dataset:  30%|███       | 2603/8564 [00:01<00:02, 2114.97 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1910/8564 [00:01<00:06, 1064.00 examples/s]Extracting prompt in train dataset:  29%|██▊       | 2450/8564 [00:01<00:05, 1170.15 examples/s]Extracting prompt in train dataset:  34%|███▎      | 2890/8564 [00:01<00:02, 2034.37 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2082/8564 [00:01<00:05, 1186.20 examples/s]Extracting prompt in train dataset:  30%|███       | 2603/8564 [00:01<00:04, 1229.09 examples/s]Extracting prompt in train dataset:  36%|███▌      | 3100/8564 [00:01<00:02, 2035.15 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  27%|██▋       | 2276/8564 [00:01<00:05, 1209.17 examples/s]Extracting prompt in train dataset:  39%|███▊      | 3310/8564 [00:01<00:02, 2011.52 examples/s]Tokenizing eval dataset:   2%|▏         | 18/953 [00:00<00:05, 165.68 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2853/8564 [00:02<00:04, 1227.05 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3568/8564 [00:02<00:02, 2163.71 examples/s]Extracting prompt in train dataset:  29%|██▉       | 2470/8564 [00:02<00:04, 1229.96 examples/s]Extracting prompt in train dataset:  36%|███▌      | 3050/8564 [00:02<00:04, 1200.48 examples/s]Tokenizing eval dataset:   4%|▍         | 40/953 [00:00<00:06, 131.07 examples/s]Extracting prompt in train dataset:  45%|████▍     | 3830/8564 [00:02<00:02, 1941.10 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2704/8564 [00:02<00:04, 1307.66 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3324/8564 [00:02<00:03, 1457.48 examples/s]Tokenizing eval dataset:   6%|▌         | 54/953 [00:00<00:08, 107.38 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2840/8564 [00:02<00:04, 1193.57 examples/s]Extracting prompt in train dataset:  49%|████▊     | 4170/8564 [00:02<00:02, 2012.44 examples/s]Extracting prompt in train dataset:  41%|████      | 3500/8564 [00:02<00:03, 1466.83 examples/s]Extracting prompt in train dataset:  35%|███▌      | 3030/8564 [00:02<00:04, 1344.19 examples/s]Tokenizing eval dataset:   7%|▋         | 69/953 [00:00<00:08, 101.56 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3659/8564 [00:02<00:03, 1378.84 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4499/8564 [00:02<00:02, 2000.56 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3880/8564 [00:02<00:03, 1476.04 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3243/8564 [00:02<00:03, 1344.79 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:08, 99.00 examples/s] Extracting prompt in train dataset:  48%|████▊     | 4100/8564 [00:02<00:02, 1644.46 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4730/8564 [00:02<00:02, 1600.18 examples/s]Tokenizing eval dataset:  10%|▉         | 94/953 [00:00<00:10, 85.75 examples/s]Extracting prompt in train dataset:  40%|████      | 3440/8564 [00:02<00:04, 1119.54 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4905/8564 [00:02<00:02, 1629.72 examples/s]Tokenizing eval dataset:  11%|█▏        | 108/953 [00:01<00:08, 97.30 examples/s]Extracting prompt in train dataset:  51%|█████▏    | 4391/8564 [00:03<00:02, 1493.73 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3609/8564 [00:03<00:04, 1232.87 examples/s]Extracting prompt in train dataset:  61%|██████    | 5220/8564 [00:03<00:01, 1761.10 examples/s]Extracting prompt in train dataset:  54%|█████▎    | 4590/8564 [00:03<00:02, 1577.86 examples/s]Tokenizing eval dataset:  13%|█▎        | 121/953 [00:01<00:09, 87.87 examples/s]Extracting prompt in train dataset:  45%|████▍     | 3850/8564 [00:03<00:03, 1254.81 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5540/8564 [00:03<00:01, 1810.96 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4890/8564 [00:03<00:02, 1679.91 examples/s]Tokenizing eval dataset:  14%|█▎        | 131/953 [00:01<00:09, 88.83 examples/s]Extracting prompt in train dataset:  47%|████▋     | 3996/8564 [00:03<00:04, 1136.57 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5729/8564 [00:03<00:01, 1791.83 examples/s]Extracting prompt in train dataset:  60%|██████    | 5170/8564 [00:03<00:01, 1930.55 examples/s]Tokenizing eval dataset:  16%|█▌        | 148/953 [00:01<00:09, 88.56 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5944/8564 [00:03<00:01, 1595.05 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4214/8564 [00:03<00:03, 1216.81 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5540/8564 [00:03<00:01, 1990.04 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4419/8564 [00:03<00:03, 1135.68 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6140/8564 [00:03<00:01, 1604.15 examples/s]Tokenizing eval dataset:  18%|█▊        | 167/953 [00:01<00:08, 92.32 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5860/8564 [00:03<00:01, 1744.99 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4579/8564 [00:03<00:03, 1172.45 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6356/8564 [00:03<00:01, 1320.98 examples/s]Extracting prompt in train dataset:  71%|███████   | 6084/8564 [00:03<00:01, 1774.68 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:02<00:10, 72.90 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 6541/8564 [00:03<00:01, 1421.84 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4780/8564 [00:04<00:03, 1178.16 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6700/8564 [00:04<00:01, 1455.43 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:02<00:10, 72.99 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6370/8564 [00:04<00:01, 1806.99 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4950/8564 [00:04<00:02, 1243.75 examples/s]Extracting prompt in train dataset:  81%|████████  | 6952/8564 [00:04<00:00, 1696.66 examples/s]Tokenizing eval dataset:  22%|██▏       | 205/953 [00:02<00:08, 86.61 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 5116/8564 [00:04<00:02, 1295.90 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6670/8564 [00:04<00:01, 1788.19 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5390/8564 [00:04<00:01, 1635.15 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7140/8564 [00:04<00:00, 1735.85 examples/s]Tokenizing eval dataset:  23%|██▎       | 215/953 [00:02<00:08, 83.65 examples/s]Extracting prompt in train dataset:  80%|████████  | 6870/8564 [00:04<00:01, 1676.20 examples/s]Extracting prompt in train dataset:  66%|██████▋   | 5690/8564 [00:04<00:01, 1966.83 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7520/8564 [00:04<00:00, 1714.69 examples/s]Tokenizing eval dataset:  25%|██▍       | 236/953 [00:02<00:07, 89.64 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5906/8564 [00:04<00:01, 1616.57 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7146/8564 [00:04<00:00, 1436.90 examples/s]Tokenizing eval dataset:  26%|██▌       | 250/953 [00:02<00:07, 94.81 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6180/8564 [00:04<00:01, 1783.26 examples/s]Tokenizing eval dataset:  28%|██▊       | 270/953 [00:02<00:06, 104.26 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7362/8564 [00:04<00:00, 1396.77 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7730/8564 [00:04<00:00, 1195.29 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 6470/8564 [00:04<00:01, 2042.26 examples/s]Tokenizing eval dataset:  31%|███       | 297/953 [00:02<00:04, 138.56 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7520/8564 [00:04<00:00, 1413.35 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7900/8564 [00:05<00:00, 1139.65 examples/s]Tokenizing eval dataset:  34%|███▍      | 322/953 [00:03<00:03, 163.77 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6779/8564 [00:05<00:00, 2041.00 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8061/8564 [00:05<00:00, 1210.12 examples/s]Tokenizing eval dataset:  36%|███▌      | 341/953 [00:03<00:03, 169.59 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7730/8564 [00:05<00:00, 1253.00 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7084/8564 [00:05<00:00, 2033.12 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 8236/8564 [00:05<00:00, 1319.32 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:03<00:03, 170.45 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7871/8564 [00:05<00:00, 1282.02 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8490/8564 [00:05<00:00, 1590.10 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7419/8564 [00:05<00:00, 2092.30 examples/s]Tokenizing eval dataset:  40%|███▉      | 380/953 [00:03<00:03, 168.32 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8122/8564 [00:05<00:00, 1378.94 examples/s]Tokenizing eval dataset:  42%|████▏     | 400/953 [00:03<00:03, 171.41 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 7681/8564 [00:05<00:00, 1823.22 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8420/8564 [00:05<00:00, 1502.74 examples/s]Tokenizing eval dataset:  46%|████▌     | 435/953 [00:03<00:02, 217.36 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1520.20 examples/s]
Tokenizing eval dataset:  48%|████▊     | 461/953 [00:03<00:02, 224.36 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8058/8564 [00:05<00:00, 1898.48 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8364/8564 [00:05<00:00, 1928.31 examples/s]Tokenizing eval dataset:  52%|█████▏    | 492/953 [00:03<00:02, 203.50 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1447.46 examples/s]
Tokenizing eval dataset:  54%|█████▍    | 516/953 [00:04<00:02, 209.29 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1884.97 examples/s]Tokenizing eval dataset:  58%|█████▊    | 548/953 [00:04<00:01, 235.55 examples/s]Tokenizing eval dataset:  61%|██████    | 581/953 [00:04<00:01, 257.55 examples/s]Tokenizing eval dataset:  64%|██████▍   | 612/953 [00:04<00:01, 263.05 examples/s]Tokenizing eval dataset:  67%|██████▋   | 639/953 [00:04<00:01, 257.52 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:06<00:00, 1328.30 examples/s]
Tokenizing eval dataset:  70%|███████   | 671/953 [00:04<00:01, 273.00 examples/s]Tokenizing eval dataset:  75%|███████▌  | 719/953 [00:04<00:00, 253.86 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  80%|████████  | 763/953 [00:04<00:00, 261.23 examples/s]Tokenizing eval dataset:  83%|████████▎ | 790/953 [00:05<00:00, 258.35 examples/s]Tokenizing eval dataset:  87%|████████▋ | 826/953 [00:05<00:00, 277.16 examples/s]Tokenizing eval dataset:  90%|████████▉ | 856/953 [00:05<00:00, 280.13 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:00<1:49:15,  1.31 examples/s]Tokenizing eval dataset:  93%|█████████▎| 887/953 [00:05<00:00, 284.62 examples/s]Applying chat template to train dataset:   2%|▏         | 178/8564 [00:00<00:30, 279.27 examples/s]Applying chat template to train dataset:   4%|▍         | 355/8564 [00:00<00:14, 552.06 examples/s]Tokenizing eval dataset:  98%|█████████▊| 930/953 [00:05<00:00, 281.99 examples/s]Applying chat template to train dataset:   6%|▋         | 542/8564 [00:01<00:09, 824.34 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 169.43 examples/s]
Applying chat template to train dataset:   0%|          | 1/8564 [00:00<1:54:51,  1.24 examples/s]Applying chat template to train dataset:   9%|▊         | 739/8564 [00:01<00:07, 1084.12 examples/s]Applying chat template to train dataset:   1%|          | 71/8564 [00:00<01:23, 101.59 examples/s]Applying chat template to train dataset:  11%|█         | 917/8564 [00:01<00:06, 1253.94 examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:00<1:16:13,  1.87 examples/s]Applying chat template to train dataset:   2%|▏         | 160/8564 [00:01<00:37, 226.04 examples/s]Applying chat template to train dataset:   1%|          | 101/8564 [00:00<00:40, 210.84 examples/s]Applying chat template to train dataset:   3%|▎         | 226/8564 [00:01<00:27, 307.73 examples/s]Applying chat template to train dataset:  13%|█▎        | 1092/8564 [00:01<00:07, 991.07 examples/s]Applying chat template to train dataset:   2%|▏         | 185/8564 [00:00<00:24, 338.40 examples/s]Applying chat template to train dataset:   4%|▎         | 305/8564 [00:01<00:20, 409.88 examples/s]Applying chat template to train dataset:   3%|▎         | 248/8564 [00:00<00:20, 407.59 examples/s]Applying chat template to train dataset:   5%|▍         | 421/8564 [00:01<00:15, 522.68 examples/s]Applying chat template to train dataset:   4%|▍         | 341/8564 [00:00<00:15, 539.09 examples/s]Applying chat template to train dataset:  15%|█▍        | 1270/8564 [00:01<00:08, 873.35 examples/s]Applying chat template to train dataset:   6%|▌         | 529/8564 [00:01<00:12, 635.48 examples/s]Applying chat template to train dataset:  16%|█▌        | 1387/8564 [00:01<00:08, 848.34 examples/s]Applying chat template to train dataset:   8%|▊         | 648/8564 [00:01<00:10, 769.33 examples/s]Applying chat template to train dataset:   5%|▌         | 451/8564 [00:01<00:15, 521.09 examples/s]Applying chat template to train dataset:   9%|▉         | 770/8564 [00:01<00:10, 770.98 examples/s]Applying chat template to train dataset:   7%|▋         | 560/8564 [00:01<00:13, 575.39 examples/s]Applying chat template to train dataset:  18%|█▊        | 1566/8564 [00:02<00:08, 843.71 examples/s]Applying chat template to train dataset:   7%|▋         | 638/8564 [00:01<00:13, 590.26 examples/s]Applying chat template to train dataset:  10%|█         | 880/8564 [00:01<00:10, 722.04 examples/s]Applying chat template to train dataset:  19%|█▉        | 1665/8564 [00:02<00:08, 823.54 examples/s]Applying chat template to train dataset:   9%|▉         | 773/8564 [00:01<00:10, 727.30 examples/s]Applying chat template to train dataset:  11%|█         | 960/8564 [00:02<00:10, 716.41 examples/s]Applying chat template to train dataset:  21%|██        | 1768/8564 [00:02<00:08, 842.38 examples/s]Applying chat template to train dataset:  11%|█         | 909/8564 [00:01<00:10, 716.98 examples/s]Applying chat template to train dataset:  13%|█▎        | 1080/8564 [00:02<00:11, 654.80 examples/s]Applying chat template to train dataset:  22%|██▏       | 1861/8564 [00:02<00:09, 687.14 examples/s]Applying chat template to train dataset:  12%|█▏        | 1019/8564 [00:01<00:10, 751.80 examples/s]Applying chat template to train dataset:  14%|█▎        | 1174/8564 [00:02<00:10, 701.13 examples/s]Applying chat template to train dataset:  23%|██▎       | 1952/8564 [00:02<00:09, 718.08 examples/s]Applying chat template to train dataset:  13%|█▎        | 1100/8564 [00:02<00:10, 732.04 examples/s]Applying chat template to train dataset:  15%|█▍        | 1270/8564 [00:02<00:09, 744.63 examples/s]Applying chat template to train dataset:  24%|██▍       | 2050/8564 [00:02<00:09, 710.06 examples/s]Applying chat template to train dataset:  16%|█▌        | 1367/8564 [00:02<00:09, 797.44 examples/s]Applying chat template to train dataset:  14%|█▎        | 1177/8564 [00:02<00:10, 694.22 examples/s]Applying chat template to train dataset:  25%|██▍       | 2132/8564 [00:02<00:08, 717.39 examples/s]Applying chat template to train dataset:  15%|█▍        | 1261/8564 [00:02<00:10, 728.47 examples/s]Applying chat template to train dataset:  17%|█▋        | 1465/8564 [00:02<00:08, 840.79 examples/s]Applying chat template to train dataset:  26%|██▌       | 2211/8564 [00:03<00:09, 700.00 examples/s]Applying chat template to train dataset:  16%|█▌        | 1358/8564 [00:02<00:09, 786.90 examples/s]Applying chat template to train dataset:  27%|██▋       | 2290/8564 [00:03<00:09, 696.28 examples/s]Applying chat template to train dataset:  19%|█▊        | 1587/8564 [00:02<00:09, 754.15 examples/s]Applying chat template to train dataset:  18%|█▊        | 1536/8564 [00:02<00:07, 926.42 examples/s]Applying chat template to train dataset:  19%|█▉        | 1635/8564 [00:02<00:07, 941.46 examples/s]Applying chat template to train dataset:  28%|██▊       | 2392/8564 [00:03<00:09, 647.60 examples/s]Applying chat template to train dataset:  20%|█▉        | 1679/8564 [00:03<00:10, 678.51 examples/s]Applying chat template to train dataset:  29%|██▊       | 2461/8564 [00:03<00:09, 638.11 examples/s]Applying chat template to train dataset:  21%|██        | 1764/8564 [00:03<00:09, 683.14 examples/s]Applying chat template to train dataset:  21%|██        | 1769/8564 [00:02<00:08, 835.40 examples/s]Applying chat template to train dataset:  30%|██▉       | 2562/8564 [00:03<00:08, 711.93 examples/s]Applying chat template to train dataset:  22%|██▏       | 1861/8564 [00:03<00:09, 715.15 examples/s]Applying chat template to train dataset:  22%|██▏       | 1890/8564 [00:02<00:07, 898.43 examples/s]Applying chat template to train dataset:  23%|██▎       | 1970/8564 [00:03<00:08, 803.49 examples/s]Applying chat template to train dataset:  23%|██▎       | 1990/8564 [00:03<00:07, 907.35 examples/s]Applying chat template to train dataset:  31%|███       | 2650/8564 [00:03<00:08, 712.64 examples/s]Applying chat template to train dataset:  25%|██▌       | 2170/8564 [00:03<00:06, 1004.00 examples/s]Applying chat template to train dataset:  24%|██▍       | 2078/8564 [00:03<00:09, 668.86 examples/s]Applying chat template to train dataset:  32%|███▏      | 2752/8564 [00:03<00:09, 602.39 examples/s]Applying chat template to train dataset:  27%|██▋       | 2271/8564 [00:03<00:06, 987.60 examples/s] Applying chat template to train dataset:  25%|██▌       | 2174/8564 [00:03<00:10, 619.09 examples/s]Applying chat template to train dataset:  28%|██▊       | 2377/8564 [00:03<00:06, 1004.03 examples/s]Applying chat template to train dataset:  33%|███▎      | 2860/8564 [00:04<00:09, 592.86 examples/s]Applying chat template to train dataset:  26%|██▋       | 2264/8564 [00:03<00:09, 642.89 examples/s]Applying chat template to train dataset:  29%|██▉       | 2478/8564 [00:03<00:06, 881.85 examples/s] Applying chat template to train dataset:  35%|███▍      | 2976/8564 [00:04<00:08, 620.95 examples/s]Applying chat template to train dataset:  28%|██▊       | 2386/8564 [00:04<00:08, 726.97 examples/s]Applying chat template to train dataset:  30%|███       | 2598/8564 [00:03<00:06, 853.33 examples/s]Applying chat template to train dataset:  36%|███▌      | 3050/8564 [00:04<00:10, 540.19 examples/s]Applying chat template to train dataset:  29%|██▉       | 2491/8564 [00:04<00:07, 789.46 examples/s]Applying chat template to train dataset:  31%|███▏      | 2692/8564 [00:03<00:07, 830.53 examples/s]Applying chat template to train dataset:  36%|███▋      | 3124/8564 [00:04<00:09, 579.10 examples/s]Applying chat template to train dataset:  38%|███▊      | 3226/8564 [00:04<00:08, 652.76 examples/s]Applying chat template to train dataset:  31%|███       | 2617/8564 [00:04<00:08, 681.80 examples/s]Applying chat template to train dataset:  33%|███▎      | 2819/8564 [00:03<00:07, 782.00 examples/s]Applying chat template to train dataset:  39%|███▊      | 3301/8564 [00:04<00:07, 662.20 examples/s]Applying chat template to train dataset:  32%|███▏      | 2729/8564 [00:04<00:09, 639.24 examples/s]Applying chat template to train dataset:  40%|███▉      | 3388/8564 [00:04<00:07, 712.47 examples/s]Applying chat template to train dataset:  34%|███▍      | 2931/8564 [00:04<00:08, 644.53 examples/s]Applying chat template to train dataset:  41%|████      | 3471/8564 [00:05<00:07, 722.69 examples/s]Applying chat template to train dataset:  33%|███▎      | 2815/8564 [00:04<00:09, 632.46 examples/s]Applying chat template to train dataset:  35%|███▌      | 3038/8564 [00:04<00:07, 727.37 examples/s]Applying chat template to train dataset:  42%|████▏     | 3555/8564 [00:05<00:07, 707.24 examples/s]Applying chat template to train dataset:  34%|███▍      | 2909/8564 [00:04<00:08, 672.43 examples/s]Applying chat template to train dataset:  35%|███▍      | 2980/8564 [00:04<00:08, 680.22 examples/s]Applying chat template to train dataset:  42%|████▏     | 3634/8564 [00:05<00:07, 672.32 examples/s]Applying chat template to train dataset:  37%|███▋      | 3190/8564 [00:04<00:07, 715.71 examples/s]Applying chat template to train dataset:  36%|███▌      | 3099/8564 [00:05<00:08, 654.70 examples/s]Applying chat template to train dataset:  44%|████▎     | 3728/8564 [00:05<00:07, 610.69 examples/s]Applying chat template to train dataset:  39%|███▉      | 3340/8564 [00:04<00:06, 777.36 examples/s]Applying chat template to train dataset:  37%|███▋      | 3171/8564 [00:05<00:08, 668.19 examples/s]Applying chat template to train dataset:  44%|████▍     | 3801/8564 [00:05<00:07, 614.02 examples/s]Applying chat template to train dataset:  38%|███▊      | 3289/8564 [00:05<00:06, 788.07 examples/s]Applying chat template to train dataset:  40%|████      | 3454/8564 [00:04<00:07, 700.18 examples/s]Applying chat template to train dataset:  45%|████▌     | 3895/8564 [00:05<00:06, 686.18 examples/s]Applying chat template to train dataset:  39%|███▉      | 3377/8564 [00:05<00:06, 810.64 examples/s]Applying chat template to train dataset:  47%|████▋     | 4000/8564 [00:05<00:05, 777.19 examples/s]Applying chat template to train dataset:  41%|████▏     | 3546/8564 [00:05<00:06, 729.75 examples/s]Applying chat template to train dataset:  41%|████      | 3474/8564 [00:05<00:06, 829.16 examples/s]Applying chat template to train dataset:  48%|████▊     | 4110/8564 [00:06<00:06, 675.95 examples/s]Applying chat template to train dataset:  43%|████▎     | 3656/8564 [00:05<00:07, 654.38 examples/s]Applying chat template to train dataset:  42%|████▏     | 3608/8564 [00:05<00:05, 849.63 examples/s]Applying chat template to train dataset:  44%|████▎     | 3726/8564 [00:05<00:07, 662.83 examples/s]Applying chat template to train dataset:  44%|████▎     | 3727/8564 [00:05<00:05, 829.33 examples/s]Applying chat template to train dataset:  49%|████▉     | 4230/8564 [00:06<00:06, 645.85 examples/s]Applying chat template to train dataset:  45%|████▍     | 3817/8564 [00:05<00:07, 609.11 examples/s]Applying chat template to train dataset:  45%|████▍     | 3823/8564 [00:05<00:05, 829.67 examples/s]Applying chat template to train dataset:  50%|█████     | 4310/8564 [00:06<00:06, 651.69 examples/s]Applying chat template to train dataset:  46%|████▌     | 3919/8564 [00:06<00:05, 805.45 examples/s]Applying chat template to train dataset:  46%|████▌     | 3951/8564 [00:05<00:07, 651.47 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4402/8564 [00:06<00:06, 607.94 examples/s]Applying chat template to train dataset:  47%|████▋     | 4060/8564 [00:05<00:06, 727.34 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4486/8564 [00:06<00:06, 638.33 examples/s]Applying chat template to train dataset:  47%|████▋     | 4041/8564 [00:06<00:05, 790.65 examples/s]Applying chat template to train dataset:  49%|████▊     | 4170/8564 [00:05<00:05, 768.06 examples/s]Applying chat template to train dataset:  54%|█████▎    | 4583/8564 [00:06<00:05, 713.77 examples/s]Applying chat template to train dataset:  48%|████▊     | 4143/8564 [00:06<00:06, 699.69 examples/s]Applying chat template to train dataset:  50%|████▉     | 4280/8564 [00:06<00:05, 832.15 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4665/8564 [00:06<00:05, 738.77 examples/s]Applying chat template to train dataset:  49%|████▉     | 4227/8564 [00:06<00:05, 729.20 examples/s]Applying chat template to train dataset:  51%|█████     | 4376/8564 [00:06<00:05, 804.30 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4772/8564 [00:06<00:05, 685.55 examples/s]Applying chat template to train dataset:  50%|█████     | 4321/8564 [00:06<00:06, 669.56 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4468/8564 [00:06<00:05, 715.87 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4845/8564 [00:07<00:05, 652.18 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4424/8564 [00:06<00:06, 684.02 examples/s]Applying chat template to train dataset:  54%|█████▎    | 4590/8564 [00:06<00:05, 734.24 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4950/8564 [00:07<00:05, 659.69 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4669/8564 [00:06<00:05, 739.44 examples/s]Applying chat template to train dataset:  59%|█████▊    | 5020/8564 [00:07<00:05, 668.09 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4549/8564 [00:07<00:05, 674.56 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4762/8564 [00:06<00:04, 764.07 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5095/8564 [00:07<00:06, 568.52 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4632/8564 [00:07<00:06, 591.52 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4846/8564 [00:06<00:04, 778.75 examples/s]Applying chat template to train dataset:  61%|██████    | 5220/8564 [00:07<00:04, 707.52 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4716/8564 [00:07<00:06, 566.99 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5330/8564 [00:07<00:04, 799.57 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4949/8564 [00:07<00:05, 680.76 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4866/8564 [00:07<00:04, 746.63 examples/s]Applying chat template to train dataset:  59%|█████▊    | 5031/8564 [00:07<00:05, 621.52 examples/s]Applying chat template to train dataset:  64%|██████▎   | 5455/8564 [00:07<00:04, 761.08 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4970/8564 [00:07<00:05, 672.36 examples/s]Applying chat template to train dataset:  60%|██████    | 5141/8564 [00:07<00:05, 660.96 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5582/8564 [00:08<00:04, 724.81 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5050/8564 [00:07<00:05, 674.72 examples/s]Applying chat template to train dataset:  61%|██████    | 5244/8564 [00:07<00:04, 735.39 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5674/8564 [00:08<00:03, 730.98 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5125/8564 [00:07<00:05, 675.36 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5349/8564 [00:07<00:04, 768.77 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5780/8564 [00:08<00:03, 744.31 examples/s]Applying chat template to train dataset:  61%|██████    | 5210/8564 [00:08<00:05, 612.39 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5471/8564 [00:07<00:04, 746.04 examples/s]Applying chat template to train dataset:  69%|██████▊   | 5880/8564 [00:08<00:03, 783.34 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5331/8564 [00:08<00:04, 746.12 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5560/8564 [00:07<00:03, 778.00 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5961/8564 [00:08<00:03, 788.30 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5438/8564 [00:08<00:03, 784.86 examples/s]Applying chat template to train dataset:  71%|███████   | 6060/8564 [00:08<00:02, 839.00 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5677/8564 [00:07<00:03, 776.61 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5563/8564 [00:08<00:03, 878.44 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6158/8564 [00:08<00:02, 873.01 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5672/8564 [00:08<00:03, 932.30 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6272/8564 [00:08<00:02, 925.99 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5771/8564 [00:08<00:04, 659.34 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5811/8564 [00:08<00:02, 1053.74 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6380/8564 [00:09<00:02, 842.96 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5845/8564 [00:08<00:04, 593.59 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5955/8564 [00:08<00:02, 976.15 examples/s] Applying chat template to train dataset:  69%|██████▉   | 5950/8564 [00:08<00:03, 688.22 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6495/8564 [00:09<00:02, 769.60 examples/s]Applying chat template to train dataset:  71%|███████   | 6090/8564 [00:08<00:02, 1008.16 examples/s]Applying chat template to train dataset:  71%|███████   | 6090/8564 [00:08<00:02, 851.32 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6582/8564 [00:09<00:02, 701.35 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6225/8564 [00:08<00:02, 859.83 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6200/8564 [00:09<00:02, 877.00 examples/s] Applying chat template to train dataset:  78%|███████▊  | 6673/8564 [00:09<00:02, 741.05 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6321/8564 [00:08<00:02, 880.72 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6350/8564 [00:09<00:02, 827.83 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6781/8564 [00:09<00:02, 688.57 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6438/8564 [00:08<00:02, 765.57 examples/s]Applying chat template to train dataset:  81%|████████  | 6902/8564 [00:09<00:02, 796.73 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6530/8564 [00:09<00:02, 794.90 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6504/8564 [00:09<00:02, 735.94 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7005/8564 [00:09<00:01, 847.15 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6590/8564 [00:09<00:03, 657.68 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7126/8564 [00:10<00:01, 798.74 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6660/8564 [00:09<00:02, 712.68 examples/s]Applying chat template to train dataset:  85%|████████▍ | 7247/8564 [00:10<00:01, 799.79 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6691/8564 [00:09<00:02, 634.70 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6767/8564 [00:09<00:02, 676.07 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7347/8564 [00:10<00:01, 830.95 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6785/8564 [00:10<00:03, 591.88 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7440/8564 [00:10<00:01, 830.78 examples/s]Applying chat template to train dataset:  80%|████████  | 6867/8564 [00:09<00:02, 626.07 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7540/8564 [00:10<00:01, 870.47 examples/s]Applying chat template to train dataset:  80%|████████  | 6873/8564 [00:10<00:02, 619.11 examples/s]Applying chat template to train dataset:  81%|████████▏ | 6960/8564 [00:09<00:02, 602.19 examples/s]Applying chat template to train dataset:  82%|████████▏ | 6996/8564 [00:10<00:02, 719.13 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7063/8564 [00:09<00:02, 686.84 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7650/8564 [00:10<00:01, 760.51 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7102/8564 [00:10<00:01, 790.66 examples/s]Applying chat template to train dataset:  84%|████████▎ | 7168/8564 [00:10<00:02, 685.65 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7199/8564 [00:10<00:01, 832.94 examples/s]Applying chat template to train dataset:  90%|█████████ | 7750/8564 [00:11<00:01, 580.23 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7378/8564 [00:10<00:01, 917.07 examples/s]Applying chat template to train dataset:  85%|████████▍ | 7277/8564 [00:10<00:01, 664.61 examples/s]Applying chat template to train dataset:  91%|█████████▏| 7824/8564 [00:11<00:01, 576.40 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7483/8564 [00:10<00:01, 936.58 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7947/8564 [00:11<00:00, 707.09 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7384/8564 [00:10<00:01, 609.26 examples/s]Applying chat template to train dataset:  89%|████████▊ | 7600/8564 [00:11<00:01, 827.23 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8034/8564 [00:11<00:00, 743.33 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7480/8564 [00:10<00:01, 657.71 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7700/8564 [00:11<00:01, 850.08 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8199/8564 [00:11<00:00, 859.05 examples/s]Applying chat template to train dataset:  89%|████████▊ | 7587/8564 [00:10<00:01, 638.14 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8320/8564 [00:11<00:00, 887.64 examples/s]Applying chat template to train dataset:  91%|█████████▏| 7822/8564 [00:11<00:00, 795.30 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7684/8564 [00:10<00:01, 699.87 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7944/8564 [00:11<00:00, 800.19 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8478/8564 [00:11<00:00, 842.47 examples/s]Applying chat template to train dataset:  94%|█████████▎| 8028/8564 [00:11<00:00, 808.62 examples/s]Applying chat template to train dataset:  91%|█████████ | 7775/8564 [00:11<00:01, 585.46 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:11<00:00, 715.79 examples/s]
Applying chat template to train dataset:  92%|█████████▏| 7856/8564 [00:11<00:01, 577.17 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8147/8564 [00:11<00:00, 760.66 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7930/8564 [00:11<00:01, 598.47 examples/s]Applying chat template to train dataset:  96%|█████████▋| 8244/8564 [00:11<00:00, 767.12 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8032/8564 [00:11<00:00, 681.84 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8346/8564 [00:12<00:00, 738.36 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8159/8564 [00:11<00:00, 791.77 examples/s]Applying chat template to train dataset:  99%|█████████▊| 8437/8564 [00:12<00:00, 605.79 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8307/8564 [00:11<00:00, 788.86 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8540/8564 [00:12<00:00, 675.32 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:12<00:00, 690.54 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8390/8564 [00:11<00:00, 712.30 examples/s]
Applying chat template to train dataset:  99%|█████████▉| 8482/8564 [00:12<00:00, 731.13 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:12<00:00, 703.14 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:12<00:00, 700.34 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 19/8564 [00:00<00:45, 186.32 examples/s]Tokenizing train dataset:   0%|          | 40/8564 [00:00<01:06, 128.79 examples/s]Tokenizing train dataset:   1%|          | 55/8564 [00:00<01:46, 79.65 examples/s] Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 68/8564 [00:00<01:50, 76.71 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 19/8564 [00:00<01:04, 133.26 examples/s]Tokenizing train dataset:   0%|          | 36/8564 [00:00<00:57, 147.79 examples/s]Tokenizing train dataset:   0%|          | 20/8564 [00:00<01:01, 138.91 examples/s]Tokenizing train dataset:   1%|          | 78/8564 [00:00<01:57, 72.18 examples/s]Tokenizing train dataset:   0%|          | 36/8564 [00:00<01:03, 134.02 examples/s]Tokenizing train dataset:   1%|          | 59/8564 [00:00<01:13, 115.25 examples/s]Tokenizing train dataset:   1%|          | 89/8564 [00:01<02:11, 64.33 examples/s]Tokenizing train dataset:   1%|          | 96/8564 [00:01<02:13, 63.45 examples/s]Tokenizing train dataset:   1%|          | 50/8564 [00:00<01:31, 93.43 examples/s] Tokenizing train dataset:   1%|          | 76/8564 [00:00<01:26, 98.08 examples/s] Tokenizing train dataset:   1%|▏         | 109/8564 [00:01<02:02, 69.18 examples/s]Tokenizing train dataset:   1%|          | 67/8564 [00:00<01:26, 98.72 examples/s]Tokenizing train dataset:   1%|          | 88/8564 [00:00<01:37, 86.74 examples/s]Tokenizing train dataset:   1%|▏         | 118/8564 [00:01<02:14, 62.87 examples/s]Tokenizing train dataset:   1%|          | 101/8564 [00:01<01:31, 92.20 examples/s]Tokenizing train dataset:   1%|          | 80/8564 [00:00<01:43, 82.32 examples/s]Tokenizing train dataset:   1%|▏         | 126/8564 [00:01<02:17, 61.37 examples/s]Tokenizing train dataset:   1%|▏         | 113/8564 [00:01<01:31, 92.85 examples/s]Tokenizing train dataset:   1%|          | 92/8564 [00:01<01:52, 75.47 examples/s]Tokenizing train dataset:   2%|▏         | 136/8564 [00:01<02:09, 65.28 examples/s]Tokenizing train dataset:   1%|          | 106/8564 [00:01<01:35, 88.17 examples/s]Tokenizing train dataset:   1%|▏         | 123/8564 [00:01<01:47, 78.73 examples/s]Tokenizing train dataset:   2%|▏         | 145/8564 [00:02<02:04, 67.36 examples/s]Tokenizing train dataset:   1%|▏         | 118/8564 [00:01<01:30, 93.62 examples/s]Tokenizing train dataset:   2%|▏         | 136/8564 [00:01<01:51, 75.59 examples/s]Tokenizing train dataset:   2%|▏         | 157/8564 [00:02<02:05, 67.00 examples/s]Tokenizing train dataset:   2%|▏         | 135/8564 [00:01<01:29, 94.13 examples/s]Tokenizing train dataset:   2%|▏         | 145/8564 [00:01<01:48, 77.59 examples/s]Tokenizing train dataset:   2%|▏         | 166/8564 [00:02<02:09, 64.94 examples/s]Tokenizing train dataset:   2%|▏         | 154/8564 [00:01<01:45, 79.99 examples/s]Tokenizing train dataset:   2%|▏         | 146/8564 [00:01<01:28, 95.17 examples/s]Tokenizing train dataset:   2%|▏         | 173/8564 [00:02<02:14, 62.29 examples/s]Tokenizing train dataset:   2%|▏         | 163/8564 [00:01<01:55, 73.02 examples/s]Tokenizing train dataset:   2%|▏         | 159/8564 [00:01<01:39, 84.33 examples/s]Tokenizing train dataset:   2%|▏         | 180/8564 [00:02<02:13, 62.80 examples/s]Tokenizing train dataset:   2%|▏         | 187/8564 [00:02<02:19, 60.13 examples/s]Tokenizing train dataset:   2%|▏         | 172/8564 [00:02<02:10, 64.22 examples/s]Tokenizing train dataset:   2%|▏         | 168/8564 [00:01<02:06, 66.12 examples/s]Tokenizing train dataset:   2%|▏         | 200/8564 [00:02<01:50, 75.71 examples/s]Tokenizing train dataset:   2%|▏         | 179/8564 [00:02<02:16, 61.57 examples/s]Tokenizing train dataset:   2%|▏         | 210/8564 [00:02<01:51, 74.62 examples/s]Tokenizing train dataset:   2%|▏         | 188/8564 [00:02<02:14, 62.28 examples/s]Tokenizing train dataset:   2%|▏         | 180/8564 [00:02<02:10, 64.09 examples/s]Tokenizing train dataset:   3%|▎         | 222/8564 [00:03<01:44, 80.09 examples/s]Tokenizing train dataset:   2%|▏         | 192/8564 [00:02<01:56, 72.01 examples/s]Tokenizing train dataset:   2%|▏         | 200/8564 [00:02<02:10, 64.20 examples/s]Tokenizing train dataset:   3%|▎         | 234/8564 [00:03<01:33, 89.17 examples/s]Tokenizing train dataset:   2%|▏         | 203/8564 [00:02<01:44, 79.67 examples/s]Tokenizing train dataset:   3%|▎         | 249/8564 [00:03<01:22, 100.23 examples/s]Tokenizing train dataset:   2%|▏         | 210/8564 [00:02<02:11, 63.31 examples/s]Tokenizing train dataset:   3%|▎         | 217/8564 [00:02<01:33, 89.49 examples/s]Tokenizing train dataset:   3%|▎         | 220/8564 [00:02<01:58, 70.19 examples/s]Tokenizing train dataset:   3%|▎         | 232/8564 [00:02<01:34, 88.15 examples/s]Tokenizing train dataset:   3%|▎         | 263/8564 [00:03<01:39, 83.05 examples/s] Tokenizing train dataset:   3%|▎         | 230/8564 [00:02<01:55, 71.97 examples/s]Tokenizing train dataset:   3%|▎         | 244/8564 [00:02<01:28, 94.11 examples/s]Tokenizing train dataset:   3%|▎         | 274/8564 [00:03<01:38, 84.10 examples/s]Tokenizing train dataset:   3%|▎         | 238/8564 [00:03<01:59, 69.52 examples/s]Tokenizing train dataset:   3%|▎         | 256/8564 [00:02<01:36, 86.05 examples/s]Tokenizing train dataset:   3%|▎         | 285/8564 [00:03<01:48, 76.43 examples/s]Tokenizing train dataset:   3%|▎         | 249/8564 [00:03<02:06, 65.84 examples/s]Tokenizing train dataset:   3%|▎         | 269/8564 [00:03<01:35, 87.18 examples/s]Tokenizing train dataset:   3%|▎         | 259/8564 [00:03<01:57, 70.86 examples/s]Tokenizing train dataset:   3%|▎         | 299/8564 [00:04<01:45, 78.24 examples/s]Tokenizing train dataset:   3%|▎         | 272/8564 [00:03<01:39, 83.09 examples/s]Tokenizing train dataset:   3%|▎         | 285/8564 [00:03<01:32, 89.47 examples/s]Tokenizing train dataset:   4%|▎         | 309/8564 [00:04<01:43, 79.92 examples/s]Tokenizing train dataset:   3%|▎         | 281/8564 [00:03<01:39, 83.35 examples/s]Tokenizing train dataset:   4%|▎         | 320/8564 [00:04<01:38, 83.96 examples/s]Tokenizing train dataset:   3%|▎         | 295/8564 [00:03<01:35, 86.31 examples/s]Tokenizing train dataset:   3%|▎         | 297/8564 [00:03<01:26, 96.06 examples/s]Tokenizing train dataset:   4%|▍         | 329/8564 [00:04<01:47, 76.70 examples/s]Tokenizing train dataset:   4%|▎         | 309/8564 [00:03<01:52, 73.61 examples/s]Tokenizing train dataset:   4%|▍         | 337/8564 [00:04<01:53, 72.64 examples/s]Tokenizing train dataset:   4%|▎         | 316/8564 [00:03<01:28, 93.43 examples/s]Tokenizing train dataset:   4%|▎         | 319/8564 [00:03<01:46, 77.72 examples/s]Tokenizing train dataset:   4%|▍         | 345/8564 [00:04<01:54, 71.97 examples/s]Tokenizing train dataset:   4%|▍         | 330/8564 [00:04<01:32, 88.94 examples/s]Tokenizing train dataset:   4%|▍         | 353/8564 [00:04<01:59, 68.87 examples/s]Tokenizing train dataset:   4%|▍         | 331/8564 [00:03<01:54, 72.09 examples/s]Tokenizing train dataset:   4%|▍         | 361/8564 [00:04<02:09, 63.37 examples/s]Tokenizing train dataset:   4%|▍         | 342/8564 [00:04<01:47, 76.83 examples/s]Tokenizing train dataset:   4%|▍         | 340/8564 [00:04<02:00, 68.00 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:05<02:11, 62.31 examples/s]Tokenizing train dataset:   4%|▍         | 354/8564 [00:04<01:50, 74.44 examples/s]Tokenizing train dataset:   4%|▍         | 354/8564 [00:04<02:03, 66.54 examples/s]Tokenizing train dataset:   4%|▍         | 381/8564 [00:05<01:53, 71.83 examples/s]Tokenizing train dataset:   4%|▍         | 372/8564 [00:04<01:26, 94.33 examples/s]Tokenizing train dataset:   4%|▍         | 361/8564 [00:04<02:11, 62.16 examples/s]Tokenizing train dataset:   4%|▍         | 384/8564 [00:04<01:27, 93.19 examples/s]Tokenizing train dataset:   5%|▍         | 390/8564 [00:05<02:14, 60.81 examples/s]Tokenizing train dataset:   4%|▍         | 375/8564 [00:04<01:50, 74.15 examples/s]Tokenizing train dataset:   5%|▍         | 397/8564 [00:04<01:30, 90.31 examples/s]Tokenizing train dataset:   5%|▍         | 399/8564 [00:05<02:15, 60.06 examples/s]Tokenizing train dataset:   5%|▍         | 389/8564 [00:04<01:35, 85.66 examples/s]Tokenizing train dataset:   5%|▍         | 411/8564 [00:05<01:37, 83.74 examples/s]Tokenizing train dataset:   5%|▍         | 411/8564 [00:05<02:11, 61.79 examples/s]Tokenizing train dataset:   5%|▍         | 400/8564 [00:04<01:47, 76.02 examples/s]Tokenizing train dataset:   5%|▍         | 419/8564 [00:05<02:11, 61.73 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:05<01:52, 72.49 examples/s]Tokenizing train dataset:   5%|▍         | 416/8564 [00:05<01:46, 76.39 examples/s]Tokenizing train dataset:   5%|▌         | 432/8564 [00:05<01:41, 79.74 examples/s]Tokenizing train dataset:   5%|▌         | 430/8564 [00:06<02:11, 61.93 examples/s]Tokenizing train dataset:   5%|▌         | 431/8564 [00:05<01:31, 89.23 examples/s]Tokenizing train dataset:   5%|▌         | 447/8564 [00:05<01:26, 94.23 examples/s]Tokenizing train dataset:   5%|▌         | 437/8564 [00:06<02:33, 52.90 examples/s]Tokenizing train dataset:   5%|▌         | 458/8564 [00:05<01:27, 92.25 examples/s]Tokenizing train dataset:   5%|▌         | 441/8564 [00:05<01:56, 69.65 examples/s]Tokenizing train dataset:   5%|▌         | 447/8564 [00:06<02:14, 60.42 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:05<01:25, 95.22 examples/s]Tokenizing train dataset:   5%|▌         | 453/8564 [00:05<01:46, 76.28 examples/s]Tokenizing train dataset:   5%|▌         | 458/8564 [00:06<01:56, 69.75 examples/s]Tokenizing train dataset:   5%|▌         | 462/8564 [00:05<01:45, 76.85 examples/s]Tokenizing train dataset:   6%|▌         | 481/8564 [00:05<01:44, 77.66 examples/s]Tokenizing train dataset:   5%|▌         | 466/8564 [00:06<02:27, 54.98 examples/s]Tokenizing train dataset:   6%|▌         | 474/8564 [00:05<01:44, 77.58 examples/s]Tokenizing train dataset:   6%|▌         | 492/8564 [00:06<01:59, 67.58 examples/s]Tokenizing train dataset:   6%|▌         | 476/8564 [00:06<02:13, 60.51 examples/s]Tokenizing train dataset:   6%|▌         | 501/8564 [00:06<01:54, 70.47 examples/s]Tokenizing train dataset:   6%|▌         | 483/8564 [00:06<02:13, 60.51 examples/s]Tokenizing train dataset:   6%|▌         | 484/8564 [00:06<02:08, 63.10 examples/s]Tokenizing train dataset:   6%|▌         | 492/8564 [00:06<02:06, 64.04 examples/s]Tokenizing train dataset:   6%|▌         | 490/8564 [00:07<02:17, 58.82 examples/s]Tokenizing train dataset:   6%|▌         | 513/8564 [00:06<01:59, 67.41 examples/s]Tokenizing train dataset:   6%|▌         | 502/8564 [00:06<01:57, 68.73 examples/s]Tokenizing train dataset:   6%|▌         | 500/8564 [00:07<02:01, 66.38 examples/s]Tokenizing train dataset:   6%|▌         | 525/8564 [00:06<01:52, 71.67 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:06<01:51, 72.07 examples/s]Tokenizing train dataset:   6%|▌         | 510/8564 [00:07<01:57, 68.29 examples/s]Tokenizing train dataset:   6%|▋         | 539/8564 [00:06<01:33, 85.46 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:06<01:38, 81.30 examples/s]Tokenizing train dataset:   6%|▌         | 519/8564 [00:07<01:54, 70.33 examples/s]Tokenizing train dataset:   6%|▋         | 550/8564 [00:06<01:44, 76.80 examples/s]Tokenizing train dataset:   6%|▌         | 535/8564 [00:06<01:46, 75.42 examples/s]Tokenizing train dataset:   6%|▌         | 533/8564 [00:07<01:53, 70.45 examples/s]Tokenizing train dataset:   6%|▋         | 546/8564 [00:06<01:37, 82.33 examples/s]Tokenizing train dataset:   7%|▋         | 563/8564 [00:07<01:55, 69.57 examples/s]Tokenizing train dataset:   6%|▋         | 542/8564 [00:07<01:53, 70.86 examples/s]Tokenizing train dataset:   7%|▋         | 557/8564 [00:06<01:35, 83.98 examples/s]Tokenizing train dataset:   7%|▋         | 574/8564 [00:07<01:59, 66.88 examples/s]Tokenizing train dataset:   7%|▋         | 569/8564 [00:07<01:30, 87.99 examples/s]Tokenizing train dataset:   6%|▋         | 554/8564 [00:07<01:56, 68.82 examples/s]Tokenizing train dataset:   7%|▋         | 561/8564 [00:08<02:01, 65.77 examples/s]Tokenizing train dataset:   7%|▋         | 584/8564 [00:07<01:30, 88.46 examples/s]Tokenizing train dataset:   7%|▋         | 586/8564 [00:07<02:06, 63.10 examples/s]Tokenizing train dataset:   7%|▋         | 569/8564 [00:08<02:00, 66.52 examples/s]Tokenizing train dataset:   7%|▋         | 594/8564 [00:07<01:30, 87.95 examples/s]Tokenizing train dataset:   7%|▋         | 594/8564 [00:07<02:09, 61.38 examples/s]Tokenizing train dataset:   7%|▋         | 577/8564 [00:08<01:59, 66.64 examples/s]Tokenizing train dataset:   7%|▋         | 604/8564 [00:07<01:34, 84.48 examples/s]Tokenizing train dataset:   7%|▋         | 585/8564 [00:08<02:00, 66.48 examples/s]Tokenizing train dataset:   7%|▋         | 603/8564 [00:07<02:10, 61.08 examples/s]Tokenizing train dataset:   7%|▋         | 617/8564 [00:07<01:26, 91.81 examples/s]Tokenizing train dataset:   7%|▋         | 630/8564 [00:07<01:19, 99.69 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:07<02:18, 57.52 examples/s]Tokenizing train dataset:   7%|▋         | 595/8564 [00:08<02:12, 59.99 examples/s]Tokenizing train dataset:   7%|▋         | 619/8564 [00:08<02:17, 57.78 examples/s]Tokenizing train dataset:   7%|▋         | 603/8564 [00:08<02:11, 60.55 examples/s]Tokenizing train dataset:   7%|▋         | 641/8564 [00:07<01:34, 84.20 examples/s]Tokenizing train dataset:   7%|▋         | 614/8564 [00:08<01:52, 70.72 examples/s]Tokenizing train dataset:   8%|▊         | 650/8564 [00:08<01:39, 79.24 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:08<01:54, 69.03 examples/s]Tokenizing train dataset:   7%|▋         | 631/8564 [00:08<01:27, 90.36 examples/s]Tokenizing train dataset:   8%|▊         | 659/8564 [00:08<01:48, 72.72 examples/s]Tokenizing train dataset:   8%|▊         | 644/8564 [00:08<02:07, 62.33 examples/s]Tokenizing train dataset:   8%|▊         | 643/8564 [00:09<01:26, 91.39 examples/s]Tokenizing train dataset:   8%|▊         | 667/8564 [00:08<01:53, 69.45 examples/s]Tokenizing train dataset:   8%|▊         | 655/8564 [00:08<01:58, 66.71 examples/s]Tokenizing train dataset:   8%|▊         | 657/8564 [00:09<01:32, 85.74 examples/s]Tokenizing train dataset:   8%|▊         | 675/8564 [00:08<01:50, 71.10 examples/s]Tokenizing train dataset:   8%|▊         | 663/8564 [00:08<02:03, 63.89 examples/s]Tokenizing train dataset:   8%|▊         | 666/8564 [00:09<01:33, 84.30 examples/s]Tokenizing train dataset:   8%|▊         | 684/8564 [00:08<01:47, 73.07 examples/s]Tokenizing train dataset:   8%|▊         | 670/8564 [00:08<02:11, 60.10 examples/s]Tokenizing train dataset:   8%|▊         | 680/8564 [00:09<01:33, 84.64 examples/s]Tokenizing train dataset:   8%|▊         | 679/8564 [00:08<01:58, 66.33 examples/s]Tokenizing train dataset:   8%|▊         | 695/8564 [00:08<02:11, 59.83 examples/s]Tokenizing train dataset:   8%|▊         | 689/8564 [00:09<01:36, 81.56 examples/s]Tokenizing train dataset:   8%|▊         | 686/8564 [00:09<02:02, 64.53 examples/s]Tokenizing train dataset:   8%|▊         | 703/8564 [00:09<02:30, 52.09 examples/s]Tokenizing train dataset:   8%|▊         | 696/8564 [00:09<01:57, 66.92 examples/s]Tokenizing train dataset:   8%|▊         | 699/8564 [00:09<02:00, 65.03 examples/s]Tokenizing train dataset:   8%|▊         | 711/8564 [00:09<02:19, 56.13 examples/s]Tokenizing train dataset:   8%|▊         | 711/8564 [00:10<01:46, 73.57 examples/s]Tokenizing train dataset:   8%|▊         | 703/8564 [00:09<02:15, 57.96 examples/s]Tokenizing train dataset:   8%|▊         | 727/8564 [00:09<01:50, 70.91 examples/s]Tokenizing train dataset:   9%|▊         | 728/8564 [00:10<01:24, 92.20 examples/s]Tokenizing train dataset:   8%|▊         | 712/8564 [00:09<02:10, 60.16 examples/s]Tokenizing train dataset:   9%|▊         | 739/8564 [00:09<01:36, 80.81 examples/s]Tokenizing train dataset:   9%|▊         | 739/8564 [00:10<01:29, 87.15 examples/s]Tokenizing train dataset:   9%|▊         | 728/8564 [00:09<01:39, 78.38 examples/s]Tokenizing train dataset:   9%|▊         | 749/8564 [00:09<01:35, 81.80 examples/s]Tokenizing train dataset:   9%|▊         | 740/8564 [00:09<01:36, 81.06 examples/s]Tokenizing train dataset:   9%|▉         | 759/8564 [00:09<01:33, 83.08 examples/s]Tokenizing train dataset:   9%|▉         | 750/8564 [00:10<01:35, 81.50 examples/s]Tokenizing train dataset:   9%|▉         | 768/8564 [00:09<01:36, 80.78 examples/s]Tokenizing train dataset:   9%|▉         | 750/8564 [00:09<01:38, 78.98 examples/s]Tokenizing train dataset:   9%|▉         | 759/8564 [00:10<01:42, 76.11 examples/s]Tokenizing train dataset:   9%|▉         | 778/8564 [00:09<01:35, 81.22 examples/s]Tokenizing train dataset:   9%|▉         | 759/8564 [00:10<01:42, 75.89 examples/s]Tokenizing train dataset:   9%|▉         | 768/8564 [00:10<01:41, 77.18 examples/s]Tokenizing train dataset:   9%|▉         | 790/8564 [00:09<01:28, 87.54 examples/s]Tokenizing train dataset:   9%|▉         | 778/8564 [00:10<01:41, 76.53 examples/s]Tokenizing train dataset:   9%|▉         | 771/8564 [00:10<01:52, 69.07 examples/s]Tokenizing train dataset:   9%|▉         | 787/8564 [00:10<01:41, 76.54 examples/s]Tokenizing train dataset:   9%|▉         | 800/8564 [00:10<01:42, 75.90 examples/s]Tokenizing train dataset:   9%|▉         | 780/8564 [00:10<01:49, 71.17 examples/s]Tokenizing train dataset:   9%|▉         | 799/8564 [00:11<01:37, 79.95 examples/s]Tokenizing train dataset:   9%|▉         | 810/8564 [00:10<01:42, 75.50 examples/s]Tokenizing train dataset:   9%|▉         | 789/8564 [00:10<01:46, 73.23 examples/s]Tokenizing train dataset:   9%|▉         | 810/8564 [00:11<01:30, 86.04 examples/s]Tokenizing train dataset:  10%|▉         | 818/8564 [00:10<01:42, 75.84 examples/s]Tokenizing train dataset:   9%|▉         | 798/8564 [00:10<01:43, 74.72 examples/s]Tokenizing train dataset:  10%|▉         | 824/8564 [00:11<01:19, 96.82 examples/s]Tokenizing train dataset:  10%|▉         | 826/8564 [00:10<01:57, 65.84 examples/s]Tokenizing train dataset:   9%|▉         | 807/8564 [00:10<01:47, 72.39 examples/s]Tokenizing train dataset:  10%|▉         | 836/8564 [00:11<01:27, 88.00 examples/s]Tokenizing train dataset:  10%|▉         | 816/8564 [00:10<01:41, 76.22 examples/s]Tokenizing train dataset:  10%|▉         | 834/8564 [00:10<02:03, 62.61 examples/s]Tokenizing train dataset:  10%|▉         | 847/8564 [00:11<01:28, 86.85 examples/s]Tokenizing train dataset:  10%|▉         | 846/8564 [00:10<01:50, 69.95 examples/s]Tokenizing train dataset:  10%|▉         | 826/8564 [00:10<01:54, 67.40 examples/s]Tokenizing train dataset:  10%|▉         | 856/8564 [00:11<01:35, 80.76 examples/s]Tokenizing train dataset:  10%|█         | 857/8564 [00:10<01:42, 75.08 examples/s]Tokenizing train dataset:  10%|▉         | 838/8564 [00:11<01:54, 67.41 examples/s]Tokenizing train dataset:  10%|█         | 866/8564 [00:11<01:48, 70.92 examples/s]Tokenizing train dataset:  10%|█         | 873/8564 [00:11<01:31, 83.86 examples/s]Tokenizing train dataset:  10%|▉         | 854/8564 [00:11<01:38, 77.90 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:11<01:28, 86.73 examples/s]Tokenizing train dataset:  10%|█         | 874/8564 [00:12<01:56, 65.91 examples/s]Tokenizing train dataset:  10%|█         | 865/8564 [00:11<01:33, 82.07 examples/s]Tokenizing train dataset:  11%|█         | 901/8564 [00:11<01:14, 102.77 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:12<01:47, 71.16 examples/s]Tokenizing train dataset:  10%|█         | 879/8564 [00:11<01:35, 80.08 examples/s]Tokenizing train dataset:  10%|█         | 899/8564 [00:12<01:31, 83.68 examples/s]Tokenizing train dataset:  11%|█         | 913/8564 [00:11<01:24, 90.95 examples/s] Tokenizing train dataset:  10%|█         | 890/8564 [00:11<01:33, 82.33 examples/s]Tokenizing train dataset:  11%|█         | 910/8564 [00:12<01:28, 86.74 examples/s]Tokenizing train dataset:  11%|█         | 923/8564 [00:11<01:26, 87.85 examples/s]Tokenizing train dataset:  11%|█         | 901/8564 [00:11<01:28, 86.11 examples/s]Tokenizing train dataset:  11%|█         | 921/8564 [00:12<01:46, 72.01 examples/s]Tokenizing train dataset:  11%|█         | 935/8564 [00:11<01:39, 76.39 examples/s]Tokenizing train dataset:  11%|█         | 912/8564 [00:12<01:40, 76.48 examples/s]Tokenizing train dataset:  11%|█         | 932/8564 [00:12<01:43, 73.91 examples/s]Tokenizing train dataset:  11%|█         | 947/8564 [00:12<01:46, 71.28 examples/s]Tokenizing train dataset:  11%|█         | 922/8564 [00:12<01:48, 70.62 examples/s]Tokenizing train dataset:  11%|█         | 943/8564 [00:12<01:52, 67.44 examples/s]Tokenizing train dataset:  11%|█         | 932/8564 [00:12<01:42, 74.61 examples/s]Tokenizing train dataset:  11%|█         | 958/8564 [00:12<01:54, 66.62 examples/s]Tokenizing train dataset:  11%|█         | 951/8564 [00:13<01:54, 66.59 examples/s]Tokenizing train dataset:  11%|█         | 943/8564 [00:12<01:37, 78.20 examples/s]Tokenizing train dataset:  11%|█▏        | 969/8564 [00:12<01:42, 74.38 examples/s]Tokenizing train dataset:  11%|█▏        | 964/8564 [00:13<01:38, 77.33 examples/s]Tokenizing train dataset:  11%|█         | 955/8564 [00:12<01:48, 69.86 examples/s]Tokenizing train dataset:  11%|█▏        | 978/8564 [00:12<02:05, 60.41 examples/s]Tokenizing train dataset:  11%|█▏        | 974/8564 [00:13<01:48, 69.82 examples/s]Tokenizing train dataset:  11%|█▏        | 966/8564 [00:12<01:38, 77.45 examples/s]Tokenizing train dataset:  12%|█▏        | 987/8564 [00:12<02:02, 61.78 examples/s]Tokenizing train dataset:  12%|█▏        | 985/8564 [00:13<01:52, 67.11 examples/s]Tokenizing train dataset:  11%|█▏        | 976/8564 [00:12<01:50, 68.91 examples/s]Tokenizing train dataset:  12%|█▏        | 999/8564 [00:12<01:44, 72.40 examples/s]Tokenizing train dataset:  12%|█▏        | 997/8564 [00:13<01:39, 76.03 examples/s]Tokenizing train dataset:  12%|█▏        | 1011/8564 [00:13<01:27, 86.51 examples/s]Tokenizing train dataset:  12%|█▏        | 986/8564 [00:13<01:57, 64.68 examples/s]Tokenizing train dataset:  12%|█▏        | 1009/8564 [00:12<01:53, 66.29 examples/s]Tokenizing train dataset:  12%|█▏        | 1017/8564 [00:13<01:55, 65.30 examples/s]Tokenizing train dataset:  12%|█▏        | 1025/8564 [00:13<01:26, 87.17 examples/s]Tokenizing train dataset:  12%|█▏        | 998/8564 [00:13<01:54, 65.88 examples/s]Tokenizing train dataset:  12%|█▏        | 1007/8564 [00:13<01:48, 69.80 examples/s]Tokenizing train dataset:  12%|█▏        | 1025/8564 [00:13<02:02, 61.53 examples/s]Tokenizing train dataset:  12%|█▏        | 1037/8564 [00:14<01:26, 86.93 examples/s]Tokenizing train dataset:  12%|█▏        | 1020/8564 [00:13<01:48, 69.65 examples/s]Tokenizing train dataset:  12%|█▏        | 1036/8564 [00:13<02:06, 59.54 examples/s]Tokenizing train dataset:  12%|█▏        | 1047/8564 [00:14<01:41, 74.27 examples/s]Tokenizing train dataset:  12%|█▏        | 1029/8564 [00:13<01:44, 72.16 examples/s]Tokenizing train dataset:  12%|█▏        | 1061/8564 [00:14<01:38, 76.18 examples/s]Tokenizing train dataset:  12%|█▏        | 1046/8564 [00:13<02:09, 58.01 examples/s]Tokenizing train dataset:  12%|█▏        | 1039/8564 [00:13<01:54, 65.73 examples/s]Tokenizing train dataset:  12%|█▏        | 1070/8564 [00:14<01:37, 77.18 examples/s]Tokenizing train dataset:  12%|█▏        | 1053/8564 [00:13<02:07, 59.01 examples/s]Tokenizing train dataset:  13%|█▎        | 1081/8564 [00:14<01:29, 83.99 examples/s]Tokenizing train dataset:  12%|█▏        | 1047/8564 [00:14<01:56, 64.69 examples/s]Tokenizing train dataset:  12%|█▏        | 1061/8564 [00:13<02:07, 58.86 examples/s]Tokenizing train dataset:  12%|█▏        | 1059/8564 [00:14<01:37, 76.79 examples/s]Tokenizing train dataset:  13%|█▎        | 1091/8564 [00:14<01:35, 77.97 examples/s]Tokenizing train dataset:  12%|█▏        | 1069/8564 [00:14<02:03, 60.90 examples/s]Tokenizing train dataset:  12%|█▏        | 1069/8564 [00:14<01:35, 78.58 examples/s]Tokenizing train dataset:  13%|█▎        | 1100/8564 [00:14<01:43, 72.30 examples/s]Tokenizing train dataset:  13%|█▎        | 1080/8564 [00:14<02:03, 60.74 examples/s]Tokenizing train dataset:  13%|█▎        | 1080/8564 [00:14<01:28, 84.91 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:15<01:42, 72.43 examples/s]Tokenizing train dataset:  13%|█▎        | 1092/8564 [00:14<01:42, 72.62 examples/s]Tokenizing train dataset:  13%|█▎        | 1090/8564 [00:14<01:24, 88.58 examples/s]Tokenizing train dataset:  13%|█▎        | 1119/8564 [00:15<01:42, 72.31 examples/s]Tokenizing train dataset:  13%|█▎        | 1104/8564 [00:14<01:50, 67.37 examples/s]Tokenizing train dataset:  13%|█▎        | 1104/8564 [00:14<01:44, 71.23 examples/s]Tokenizing train dataset:  13%|█▎        | 1130/8564 [00:15<01:45, 70.36 examples/s]Tokenizing train dataset:  13%|█▎        | 1114/8564 [00:14<01:45, 70.63 examples/s]Tokenizing train dataset:  13%|█▎        | 1117/8564 [00:14<01:32, 80.09 examples/s]Tokenizing train dataset:  13%|█▎        | 1122/8564 [00:14<01:47, 69.35 examples/s]Tokenizing train dataset:  13%|█▎        | 1142/8564 [00:15<01:44, 70.80 examples/s]Tokenizing train dataset:  13%|█▎        | 1128/8564 [00:15<01:41, 73.60 examples/s]Tokenizing train dataset:  13%|█▎        | 1130/8564 [00:14<01:54, 64.91 examples/s]Tokenizing train dataset:  13%|█▎        | 1138/8564 [00:15<01:35, 77.82 examples/s]Tokenizing train dataset:  13%|█▎        | 1152/8564 [00:15<02:04, 59.38 examples/s]Tokenizing train dataset:  13%|█▎        | 1138/8564 [00:15<01:53, 65.70 examples/s]Tokenizing train dataset:  14%|█▎        | 1160/8564 [00:15<01:59, 61.96 examples/s]Tokenizing train dataset:  13%|█▎        | 1146/8564 [00:15<01:49, 67.98 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:15<01:37, 75.67 examples/s]Tokenizing train dataset:  14%|█▎        | 1167/8564 [00:16<01:59, 61.70 examples/s]Tokenizing train dataset:  14%|█▎        | 1158/8564 [00:15<01:47, 68.86 examples/s]Tokenizing train dataset:  14%|█▎        | 1161/8564 [00:15<01:56, 63.50 examples/s]Tokenizing train dataset:  14%|█▍        | 1179/8564 [00:16<01:54, 64.75 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:15<01:42, 72.37 examples/s]Tokenizing train dataset:  14%|█▍        | 1189/8564 [00:16<01:43, 71.23 examples/s]Tokenizing train dataset:  14%|█▎        | 1171/8564 [00:15<01:57, 62.92 examples/s]Tokenizing train dataset:  14%|█▍        | 1183/8564 [00:15<01:27, 84.05 examples/s]Tokenizing train dataset:  14%|█▍        | 1199/8564 [00:16<01:37, 75.64 examples/s]Tokenizing train dataset:  14%|█▍        | 1181/8564 [00:15<01:52, 65.82 examples/s]Tokenizing train dataset:  14%|█▍        | 1201/8564 [00:15<01:17, 94.43 examples/s]Tokenizing train dataset:  14%|█▍        | 1210/8564 [00:16<01:51, 66.09 examples/s]Tokenizing train dataset:  14%|█▍        | 1192/8564 [00:16<01:49, 67.38 examples/s]Tokenizing train dataset:  14%|█▍        | 1220/8564 [00:15<01:12, 101.64 examples/s]Tokenizing train dataset:  14%|█▍        | 1220/8564 [00:16<02:14, 54.51 examples/s]Tokenizing train dataset:  14%|█▍        | 1200/8564 [00:16<02:27, 50.08 examples/s]Tokenizing train dataset:  14%|█▍        | 1230/8564 [00:17<01:57, 62.54 examples/s]Tokenizing train dataset:  14%|█▍        | 1231/8564 [00:16<01:49, 66.96 examples/s] Tokenizing train dataset:  14%|█▍        | 1206/8564 [00:16<02:29, 49.18 examples/s]Tokenizing train dataset:  15%|█▍        | 1246/8564 [00:17<01:29, 81.61 examples/s]Tokenizing train dataset:  15%|█▍        | 1247/8564 [00:16<01:31, 79.97 examples/s]Tokenizing train dataset:  14%|█▍        | 1213/8564 [00:16<02:25, 50.67 examples/s]Tokenizing train dataset:  15%|█▍        | 1262/8564 [00:17<01:23, 87.48 examples/s]Tokenizing train dataset:  15%|█▍        | 1258/8564 [00:16<01:35, 76.71 examples/s]Tokenizing train dataset:  14%|█▍        | 1219/8564 [00:16<02:26, 50.16 examples/s]Tokenizing train dataset:  15%|█▍        | 1276/8564 [00:17<01:17, 94.29 examples/s]Tokenizing train dataset:  15%|█▍        | 1269/8564 [00:16<01:31, 79.78 examples/s]Tokenizing train dataset:  14%|█▍        | 1230/8564 [00:16<02:03, 59.62 examples/s]Tokenizing train dataset:  15%|█▍        | 1279/8564 [00:16<01:36, 75.28 examples/s]Tokenizing train dataset:  15%|█▌        | 1289/8564 [00:17<01:32, 78.75 examples/s]Tokenizing train dataset:  14%|█▍        | 1240/8564 [00:17<02:14, 54.56 examples/s]Tokenizing train dataset:  15%|█▌        | 1292/8564 [00:16<01:28, 82.60 examples/s]Tokenizing train dataset:  15%|█▌        | 1301/8564 [00:17<01:25, 85.04 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:17<02:04, 58.92 examples/s]Tokenizing train dataset:  15%|█▌        | 1306/8564 [00:17<01:21, 88.93 examples/s]Tokenizing train dataset:  15%|█▌        | 1314/8564 [00:17<01:32, 78.42 examples/s]Tokenizing train dataset:  15%|█▍        | 1258/8564 [00:17<02:01, 59.95 examples/s]Tokenizing train dataset:  15%|█▌        | 1316/8564 [00:17<01:22, 88.32 examples/s]Tokenizing train dataset:  15%|█▍        | 1268/8564 [00:17<01:50, 66.01 examples/s]Tokenizing train dataset:  15%|█▌        | 1325/8564 [00:18<01:34, 76.93 examples/s]Tokenizing train dataset:  15%|█▌        | 1327/8564 [00:17<01:22, 87.30 examples/s]Tokenizing train dataset:  15%|█▍        | 1275/8564 [00:17<02:01, 60.16 examples/s]Tokenizing train dataset:  16%|█▌        | 1339/8564 [00:17<01:17, 93.48 examples/s]Tokenizing train dataset:  16%|█▌        | 1339/8564 [00:18<01:26, 83.85 examples/s]Tokenizing train dataset:  15%|█▍        | 1283/8564 [00:17<02:13, 54.46 examples/s]Tokenizing train dataset:  16%|█▌        | 1352/8564 [00:17<01:35, 75.28 examples/s]Tokenizing train dataset:  15%|█▌        | 1293/8564 [00:17<02:01, 60.01 examples/s]Tokenizing train dataset:  16%|█▌        | 1350/8564 [00:18<01:47, 67.17 examples/s]Tokenizing train dataset:  16%|█▌        | 1361/8564 [00:17<01:35, 75.35 examples/s]Tokenizing train dataset:  15%|█▌        | 1306/8564 [00:17<01:42, 70.95 examples/s]Tokenizing train dataset:  16%|█▌        | 1370/8564 [00:17<01:48, 66.57 examples/s]Tokenizing train dataset:  15%|█▌        | 1314/8564 [00:18<01:41, 71.39 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:18<02:13, 54.08 examples/s]Tokenizing train dataset:  16%|█▌        | 1378/8564 [00:18<01:44, 68.71 examples/s]Tokenizing train dataset:  15%|█▌        | 1323/8564 [00:18<01:41, 71.55 examples/s]Tokenizing train dataset:  16%|█▌        | 1367/8564 [00:18<02:15, 52.98 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:18<01:43, 69.07 examples/s]Tokenizing train dataset:  16%|█▌        | 1331/8564 [00:18<01:47, 67.57 examples/s]Tokenizing train dataset:  16%|█▌        | 1373/8564 [00:19<02:20, 51.14 examples/s]Tokenizing train dataset:  16%|█▋        | 1394/8564 [00:18<01:42, 70.14 examples/s]Tokenizing train dataset:  16%|█▌        | 1382/8564 [00:19<02:03, 58.14 examples/s]Tokenizing train dataset:  16%|█▌        | 1342/8564 [00:18<01:41, 71.20 examples/s]Tokenizing train dataset:  16%|█▋        | 1406/8564 [00:18<01:27, 81.60 examples/s]Tokenizing train dataset:  16%|█▌        | 1391/8564 [00:19<01:55, 62.26 examples/s]Tokenizing train dataset:  16%|█▌        | 1352/8564 [00:18<01:41, 70.93 examples/s]Tokenizing train dataset:  17%|█▋        | 1418/8564 [00:18<01:37, 73.55 examples/s]Tokenizing train dataset:  16%|█▋        | 1403/8564 [00:19<01:38, 72.69 examples/s]Tokenizing train dataset:  16%|█▌        | 1362/8564 [00:18<01:40, 71.41 examples/s]Tokenizing train dataset:  17%|█▋        | 1427/8564 [00:18<01:36, 74.14 examples/s]Tokenizing train dataset:  17%|█▋        | 1415/8564 [00:19<01:38, 72.36 examples/s]Tokenizing train dataset:  17%|█▋        | 1436/8564 [00:18<01:34, 75.65 examples/s]Tokenizing train dataset:  16%|█▌        | 1370/8564 [00:18<01:55, 62.45 examples/s]Tokenizing train dataset:  17%|█▋        | 1429/8564 [00:19<01:23, 85.68 examples/s]Tokenizing train dataset:  17%|█▋        | 1449/8564 [00:18<01:22, 86.15 examples/s]Tokenizing train dataset:  16%|█▌        | 1381/8564 [00:19<01:55, 62.37 examples/s]Tokenizing train dataset:  17%|█▋        | 1458/8564 [00:19<01:25, 83.54 examples/s]Tokenizing train dataset:  17%|█▋        | 1439/8564 [00:19<01:36, 73.52 examples/s]Tokenizing train dataset:  16%|█▌        | 1390/8564 [00:19<01:50, 65.09 examples/s]Tokenizing train dataset:  17%|█▋        | 1470/8564 [00:19<01:20, 88.21 examples/s]Tokenizing train dataset:  17%|█▋        | 1447/8564 [00:20<01:49, 64.81 examples/s]Tokenizing train dataset:  16%|█▋        | 1399/8564 [00:19<01:44, 68.80 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:19<01:22, 86.24 examples/s]Tokenizing train dataset:  17%|█▋        | 1456/8564 [00:20<01:46, 66.86 examples/s]Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:19<01:23, 84.68 examples/s]Tokenizing train dataset:  16%|█▋        | 1411/8564 [00:19<01:49, 65.20 examples/s]Tokenizing train dataset:  18%|█▊        | 1502/8564 [00:19<01:18, 89.83 examples/s]Tokenizing train dataset:  17%|█▋        | 1465/8564 [00:20<01:57, 60.33 examples/s]Tokenizing train dataset:  17%|█▋        | 1420/8564 [00:19<01:43, 69.06 examples/s]Tokenizing train dataset:  17%|█▋        | 1428/8564 [00:19<01:51, 64.24 examples/s]Tokenizing train dataset:  18%|█▊        | 1512/8564 [00:19<01:30, 77.94 examples/s]Tokenizing train dataset:  17%|█▋        | 1478/8564 [00:20<01:55, 61.13 examples/s]Tokenizing train dataset:  18%|█▊        | 1525/8564 [00:19<01:20, 86.94 examples/s]Tokenizing train dataset:  17%|█▋        | 1439/8564 [00:20<01:55, 61.55 examples/s]Tokenizing train dataset:  18%|█▊        | 1537/8564 [00:19<01:16, 92.18 examples/s]Tokenizing train dataset:  17%|█▋        | 1486/8564 [00:20<02:13, 53.15 examples/s]Tokenizing train dataset:  17%|█▋        | 1446/8564 [00:20<01:56, 61.26 examples/s]Tokenizing train dataset:  18%|█▊        | 1548/8564 [00:20<01:16, 91.90 examples/s]Tokenizing train dataset:  17%|█▋        | 1492/8564 [00:20<02:13, 52.84 examples/s]Tokenizing train dataset:  17%|█▋        | 1456/8564 [00:20<01:47, 66.26 examples/s]Tokenizing train dataset:  18%|█▊        | 1500/8564 [00:21<02:09, 54.55 examples/s]Tokenizing train dataset:  17%|█▋        | 1467/8564 [00:20<01:35, 74.40 examples/s]Tokenizing train dataset:  18%|█▊        | 1560/8564 [00:20<01:31, 76.78 examples/s]Tokenizing train dataset:  18%|█▊        | 1506/8564 [00:21<02:08, 54.89 examples/s]Tokenizing train dataset:  18%|█▊        | 1569/8564 [00:20<01:31, 76.35 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:20<01:33, 75.67 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:21<01:49, 64.12 examples/s]Tokenizing train dataset:  18%|█▊        | 1578/8564 [00:20<01:30, 77.08 examples/s]Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:20<01:32, 76.56 examples/s]Tokenizing train dataset:  18%|█▊        | 1527/8564 [00:21<01:46, 66.07 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:20<01:23, 83.09 examples/s]Tokenizing train dataset:  18%|█▊        | 1501/8564 [00:20<01:27, 80.47 examples/s]Tokenizing train dataset:  19%|█▉        | 1607/8564 [00:20<01:09, 100.02 examples/s]Tokenizing train dataset:  18%|█▊        | 1536/8564 [00:21<01:47, 65.10 examples/s]Tokenizing train dataset:  18%|█▊        | 1512/8564 [00:20<01:40, 70.19 examples/s]Tokenizing train dataset:  19%|█▉        | 1619/8564 [00:20<01:15, 92.07 examples/s] Tokenizing train dataset:  18%|█▊        | 1546/8564 [00:21<01:58, 59.35 examples/s]Tokenizing train dataset:  18%|█▊        | 1520/8564 [00:21<01:47, 65.72 examples/s]Tokenizing train dataset:  19%|█▉        | 1635/8564 [00:21<01:09, 99.07 examples/s]Tokenizing train dataset:  18%|█▊        | 1555/8564 [00:21<02:04, 56.39 examples/s]Tokenizing train dataset:  19%|█▉        | 1651/8564 [00:21<01:01, 113.16 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:21<01:43, 68.06 examples/s]Tokenizing train dataset:  18%|█▊        | 1568/8564 [00:22<01:44, 67.12 examples/s]Tokenizing train dataset:  18%|█▊        | 1538/8564 [00:21<01:44, 66.97 examples/s]Tokenizing train dataset:  20%|█▉        | 1671/8564 [00:21<01:00, 113.31 examples/s]Tokenizing train dataset:  18%|█▊        | 1548/8564 [00:21<01:39, 70.85 examples/s]Tokenizing train dataset:  20%|█▉        | 1685/8564 [00:21<00:59, 114.83 examples/s]Tokenizing train dataset:  18%|█▊        | 1581/8564 [00:22<01:58, 59.12 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:21<00:57, 118.77 examples/s]Tokenizing train dataset:  18%|█▊        | 1556/8564 [00:21<01:52, 62.08 examples/s]Tokenizing train dataset:  19%|█▊        | 1589/8564 [00:22<01:51, 62.56 examples/s]Tokenizing train dataset:  18%|█▊        | 1564/8564 [00:21<01:47, 64.90 examples/s]Tokenizing train dataset:  20%|██        | 1713/8564 [00:21<01:00, 114.16 examples/s]Tokenizing train dataset:  19%|█▊        | 1598/8564 [00:22<01:50, 63.21 examples/s]Tokenizing train dataset:  18%|█▊        | 1571/8564 [00:21<01:48, 64.26 examples/s]Tokenizing train dataset:  19%|█▉        | 1607/8564 [00:22<01:46, 65.37 examples/s]Tokenizing train dataset:  18%|█▊        | 1581/8564 [00:22<01:42, 68.46 examples/s]Tokenizing train dataset:  20%|██        | 1729/8564 [00:21<01:17, 87.63 examples/s] Tokenizing train dataset:  19%|█▉        | 1616/8564 [00:22<01:45, 65.94 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:22<01:37, 71.40 examples/s]Tokenizing train dataset:  20%|██        | 1742/8564 [00:22<01:22, 82.48 examples/s]Tokenizing train dataset:  19%|█▉        | 1625/8564 [00:22<01:43, 66.87 examples/s]Tokenizing train dataset:  19%|█▊        | 1601/8564 [00:22<01:31, 76.10 examples/s]Tokenizing train dataset:  19%|█▉        | 1634/8564 [00:23<01:47, 64.74 examples/s]Tokenizing train dataset:  20%|██        | 1755/8564 [00:22<01:24, 80.13 examples/s]Tokenizing train dataset:  19%|█▉        | 1612/8564 [00:22<01:34, 73.29 examples/s]Tokenizing train dataset:  19%|█▉        | 1641/8564 [00:23<01:47, 64.48 examples/s]Tokenizing train dataset:  19%|█▉        | 1620/8564 [00:22<01:41, 68.60 examples/s]Tokenizing train dataset:  21%|██        | 1766/8564 [00:22<01:21, 83.14 examples/s]Tokenizing train dataset:  19%|█▉        | 1652/8564 [00:23<01:40, 68.93 examples/s]Tokenizing train dataset:  19%|█▉        | 1631/8564 [00:22<01:31, 76.13 examples/s]Tokenizing train dataset:  21%|██        | 1776/8564 [00:22<01:37, 69.64 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:23<01:46, 64.95 examples/s]Tokenizing train dataset:  19%|█▉        | 1644/8564 [00:22<01:23, 82.98 examples/s]Tokenizing train dataset:  21%|██        | 1788/8564 [00:22<01:25, 78.80 examples/s]Tokenizing train dataset:  20%|█▉        | 1670/8564 [00:23<01:39, 69.33 examples/s]Tokenizing train dataset:  19%|█▉        | 1657/8564 [00:22<01:13, 94.01 examples/s]Tokenizing train dataset:  21%|██        | 1799/8564 [00:22<01:23, 81.31 examples/s]Tokenizing train dataset:  20%|█▉        | 1680/8564 [00:23<01:31, 75.55 examples/s]Tokenizing train dataset:  21%|██        | 1808/8564 [00:22<01:22, 82.05 examples/s]Tokenizing train dataset:  19%|█▉        | 1669/8564 [00:23<01:25, 80.98 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:23<01:08, 100.72 examples/s]Tokenizing train dataset:  21%|██        | 1817/8564 [00:23<01:24, 80.19 examples/s]Tokenizing train dataset:  20%|█▉        | 1684/8564 [00:23<01:20, 85.45 examples/s]Tokenizing train dataset:  20%|█▉        | 1711/8564 [00:23<01:12, 95.05 examples/s] Tokenizing train dataset:  21%|██▏       | 1830/8564 [00:23<01:14, 90.03 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:23<01:09, 98.65 examples/s]Tokenizing train dataset:  21%|██▏       | 1841/8564 [00:23<01:10, 94.97 examples/s]Tokenizing train dataset:  20%|██        | 1724/8564 [00:24<01:19, 86.51 examples/s]Tokenizing train dataset:  20%|██        | 1715/8564 [00:23<01:22, 82.90 examples/s]Tokenizing train dataset:  22%|██▏       | 1853/8564 [00:23<01:24, 79.87 examples/s]Tokenizing train dataset:  20%|██        | 1736/8564 [00:24<01:25, 80.33 examples/s]Tokenizing train dataset:  20%|██        | 1725/8564 [00:23<01:30, 75.98 examples/s]Tokenizing train dataset:  22%|██▏       | 1866/8564 [00:23<01:26, 77.87 examples/s]Tokenizing train dataset:  20%|██        | 1750/8564 [00:24<01:34, 72.27 examples/s]Tokenizing train dataset:  20%|██        | 1734/8564 [00:23<01:30, 75.46 examples/s]Tokenizing train dataset:  22%|██▏       | 1875/8564 [00:23<01:29, 74.62 examples/s]Tokenizing train dataset:  21%|██        | 1761/8564 [00:24<01:25, 79.46 examples/s]Tokenizing train dataset:  20%|██        | 1748/8564 [00:24<01:19, 86.01 examples/s]Tokenizing train dataset:  21%|██        | 1771/8564 [00:24<01:22, 82.68 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:23<01:30, 73.70 examples/s]Tokenizing train dataset:  21%|██        | 1759/8564 [00:24<01:16, 89.54 examples/s]Tokenizing train dataset:  21%|██        | 1781/8564 [00:24<01:26, 78.10 examples/s]Tokenizing train dataset:  21%|██        | 1770/8564 [00:24<01:12, 93.31 examples/s]Tokenizing train dataset:  22%|██▏       | 1900/8564 [00:24<01:31, 72.82 examples/s]Tokenizing train dataset:  21%|██        | 1783/8564 [00:24<01:07, 99.95 examples/s]Tokenizing train dataset:  21%|██        | 1790/8564 [00:25<01:34, 71.99 examples/s]Tokenizing train dataset:  22%|██▏       | 1919/8564 [00:24<01:10, 93.72 examples/s]Tokenizing train dataset:  21%|██        | 1796/8564 [00:24<01:03, 105.79 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:25<01:32, 73.18 examples/s]Tokenizing train dataset:  23%|██▎       | 1935/8564 [00:24<01:14, 88.78 examples/s]Tokenizing train dataset:  21%|██        | 1810/8564 [00:25<01:26, 77.84 examples/s]Tokenizing train dataset:  21%|██        | 1808/8564 [00:24<01:15, 89.92 examples/s] Tokenizing train dataset:  21%|██▏       | 1820/8564 [00:25<01:25, 79.28 examples/s]Tokenizing train dataset:  23%|██▎       | 1947/8564 [00:24<01:17, 85.06 examples/s]Tokenizing train dataset:  21%|██▏       | 1822/8564 [00:24<01:21, 82.91 examples/s]Tokenizing train dataset:  23%|██▎       | 1957/8564 [00:24<01:21, 80.68 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:25<01:30, 73.99 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:24<01:15, 88.77 examples/s]Tokenizing train dataset:  23%|██▎       | 1970/8564 [00:24<01:16, 86.75 examples/s]Tokenizing train dataset:  22%|██▏       | 1844/8564 [00:25<01:31, 73.64 examples/s]Tokenizing train dataset:  22%|██▏       | 1845/8564 [00:25<01:23, 80.87 examples/s]Tokenizing train dataset:  23%|██▎       | 1981/8564 [00:25<01:18, 83.69 examples/s]Tokenizing train dataset:  22%|██▏       | 1855/8564 [00:25<01:26, 77.75 examples/s]Tokenizing train dataset:  23%|██▎       | 1990/8564 [00:25<01:22, 80.12 examples/s]Tokenizing train dataset:  22%|██▏       | 1855/8564 [00:25<01:35, 70.47 examples/s]Tokenizing train dataset:  22%|██▏       | 1865/8564 [00:26<01:34, 70.71 examples/s]Tokenizing train dataset:  23%|██▎       | 2002/8564 [00:25<01:17, 84.62 examples/s]Tokenizing train dataset:  22%|██▏       | 1863/8564 [00:25<01:48, 61.91 examples/s]Tokenizing train dataset:  22%|██▏       | 1875/8564 [00:26<01:30, 74.12 examples/s]Tokenizing train dataset:  24%|██▎       | 2018/8564 [00:25<01:05, 99.42 examples/s]Tokenizing train dataset:  22%|██▏       | 1877/8564 [00:25<01:34, 70.54 examples/s]Tokenizing train dataset:  24%|██▎       | 2029/8564 [00:25<01:06, 98.99 examples/s]Tokenizing train dataset:  22%|██▏       | 1888/8564 [00:26<01:30, 73.60 examples/s]Tokenizing train dataset:  22%|██▏       | 1888/8564 [00:25<01:32, 72.17 examples/s]Tokenizing train dataset:  24%|██▍       | 2045/8564 [00:25<01:07, 96.11 examples/s]Tokenizing train dataset:  22%|██▏       | 1912/8564 [00:26<01:10, 94.20 examples/s]Tokenizing train dataset:  22%|██▏       | 1897/8564 [00:25<01:35, 70.12 examples/s]Tokenizing train dataset:  24%|██▍       | 2061/8564 [00:25<01:09, 92.96 examples/s]Tokenizing train dataset:  22%|██▏       | 1913/8564 [00:26<01:17, 86.14 examples/s]Tokenizing train dataset:  23%|██▎       | 1931/8564 [00:26<01:06, 99.79 examples/s]Tokenizing train dataset:  24%|██▍       | 2077/8564 [00:26<01:04, 101.03 examples/s]Tokenizing train dataset:  23%|██▎       | 1942/8564 [00:26<01:12, 90.75 examples/s]Tokenizing train dataset:  22%|██▏       | 1926/8564 [00:26<01:19, 83.24 examples/s]Tokenizing train dataset:  24%|██▍       | 2094/8564 [00:26<00:59, 109.06 examples/s]Tokenizing train dataset:  23%|██▎       | 1957/8564 [00:26<01:04, 101.68 examples/s]Tokenizing train dataset:  23%|██▎       | 1940/8564 [00:26<01:14, 88.54 examples/s]Tokenizing train dataset:  23%|██▎       | 1950/8564 [00:26<01:15, 87.75 examples/s]Tokenizing train dataset:  23%|██▎       | 1972/8564 [00:27<01:10, 93.62 examples/s] Tokenizing train dataset:  25%|██▍       | 2113/8564 [00:26<01:08, 93.84 examples/s] Tokenizing train dataset:  23%|██▎       | 1982/8564 [00:27<01:09, 94.26 examples/s]Tokenizing train dataset:  23%|██▎       | 1960/8564 [00:26<01:20, 82.51 examples/s]Tokenizing train dataset:  25%|██▍       | 2126/8564 [00:26<01:04, 99.79 examples/s]Tokenizing train dataset:  23%|██▎       | 2000/8564 [00:27<01:06, 99.04 examples/s]Tokenizing train dataset:  23%|██▎       | 1972/8564 [00:26<01:21, 81.06 examples/s]Tokenizing train dataset:  25%|██▍       | 2137/8564 [00:26<01:19, 81.14 examples/s]Tokenizing train dataset:  23%|██▎       | 1983/8564 [00:26<01:16, 85.65 examples/s]Tokenizing train dataset:  24%|██▎       | 2014/8564 [00:27<01:01, 107.23 examples/s]Tokenizing train dataset:  25%|██▌       | 2149/8564 [00:26<01:13, 87.68 examples/s]Tokenizing train dataset:  24%|██▎       | 2026/8564 [00:27<01:00, 108.51 examples/s]Tokenizing train dataset:  23%|██▎       | 1993/8564 [00:27<01:20, 82.08 examples/s]Tokenizing train dataset:  25%|██▌       | 2160/8564 [00:26<01:14, 85.80 examples/s]Tokenizing train dataset:  24%|██▍       | 2039/8564 [00:27<01:06, 97.91 examples/s] Tokenizing train dataset:  23%|██▎       | 2002/8564 [00:27<01:23, 78.50 examples/s]Tokenizing train dataset:  25%|██▌       | 2174/8564 [00:27<01:07, 94.34 examples/s]Tokenizing train dataset:  23%|██▎       | 2011/8564 [00:27<01:32, 70.87 examples/s]Tokenizing train dataset:  24%|██▍       | 2052/8564 [00:28<01:15, 86.18 examples/s]Tokenizing train dataset:  26%|██▌       | 2185/8564 [00:27<01:07, 94.24 examples/s]Tokenizing train dataset:  24%|██▎       | 2023/8564 [00:27<01:24, 77.57 examples/s]Tokenizing train dataset:  24%|██▍       | 2064/8564 [00:28<01:16, 84.99 examples/s]Tokenizing train dataset:  26%|██▌       | 2197/8564 [00:27<01:12, 87.83 examples/s]Tokenizing train dataset:  24%|██▍       | 2034/8564 [00:27<01:16, 84.92 examples/s]Tokenizing train dataset:  24%|██▍       | 2074/8564 [00:28<01:16, 85.28 examples/s]Tokenizing train dataset:  26%|██▌       | 2210/8564 [00:27<01:08, 92.20 examples/s]Tokenizing train dataset:  24%|██▍       | 2046/8564 [00:27<01:15, 86.85 examples/s]Tokenizing train dataset:  24%|██▍       | 2087/8564 [00:28<01:12, 89.13 examples/s]Tokenizing train dataset:  26%|██▌       | 2225/8564 [00:27<01:01, 102.74 examples/s]Tokenizing train dataset:  24%|██▍       | 2065/8564 [00:27<00:58, 110.78 examples/s]Tokenizing train dataset:  24%|██▍       | 2098/8564 [00:28<01:11, 90.85 examples/s]Tokenizing train dataset:  26%|██▌       | 2240/8564 [00:27<01:03, 99.01 examples/s] Tokenizing train dataset:  25%|██▍       | 2110/8564 [00:28<01:06, 97.60 examples/s]Tokenizing train dataset:  24%|██▍       | 2078/8564 [00:27<01:08, 94.36 examples/s] Tokenizing train dataset:  25%|██▍       | 2125/8564 [00:28<01:00, 105.98 examples/s]Tokenizing train dataset:  26%|██▋       | 2254/8564 [00:27<01:09, 90.63 examples/s]Tokenizing train dataset:  24%|██▍       | 2092/8564 [00:28<01:12, 88.75 examples/s]Tokenizing train dataset:  25%|██▍       | 2139/8564 [00:28<01:05, 97.99 examples/s] Tokenizing train dataset:  26%|██▋       | 2269/8564 [00:28<01:10, 89.55 examples/s]Tokenizing train dataset:  25%|██▍       | 2106/8564 [00:28<01:15, 85.64 examples/s]Tokenizing train dataset:  27%|██▋       | 2281/8564 [00:28<01:10, 89.75 examples/s]Tokenizing train dataset:  25%|██▌       | 2155/8564 [00:29<01:06, 95.81 examples/s]Tokenizing train dataset:  25%|██▍       | 2120/8564 [00:28<01:07, 95.87 examples/s]Tokenizing train dataset:  27%|██▋       | 2296/8564 [00:28<01:04, 97.13 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:29<01:08, 93.81 examples/s]Tokenizing train dataset:  25%|██▍       | 2134/8564 [00:28<01:01, 104.14 examples/s]Tokenizing train dataset:  27%|██▋       | 2309/8564 [00:28<01:01, 101.95 examples/s]Tokenizing train dataset:  25%|██▌       | 2146/8564 [00:28<01:04, 99.64 examples/s] Tokenizing train dataset:  25%|██▌       | 2180/8564 [00:29<01:07, 94.10 examples/s]Tokenizing train dataset:  27%|██▋       | 2320/8564 [00:28<01:02, 99.25 examples/s] Tokenizing train dataset:  25%|██▌       | 2159/8564 [00:28<01:00, 105.65 examples/s]Tokenizing train dataset:  26%|██▌       | 2194/8564 [00:29<01:09, 91.86 examples/s]Tokenizing train dataset:  27%|██▋       | 2331/8564 [00:28<01:04, 95.97 examples/s]Tokenizing train dataset:  25%|██▌       | 2172/8564 [00:28<00:59, 107.83 examples/s]Tokenizing train dataset:  26%|██▌       | 2207/8564 [00:29<01:04, 98.27 examples/s]Tokenizing train dataset:  26%|██▌       | 2188/8564 [00:29<00:59, 106.36 examples/s]Tokenizing train dataset:  26%|██▌       | 2220/8564 [00:29<01:04, 98.28 examples/s]Tokenizing train dataset:  27%|██▋       | 2343/8564 [00:28<01:15, 82.94 examples/s]Tokenizing train dataset:  26%|██▌       | 2199/8564 [00:29<01:01, 103.04 examples/s]Tokenizing train dataset:  26%|██▌       | 2235/8564 [00:29<01:09, 91.15 examples/s]Tokenizing train dataset:  26%|██▌       | 2217/8564 [00:29<01:01, 103.94 examples/s]Tokenizing train dataset:  27%|██▋       | 2353/8564 [00:29<01:31, 67.99 examples/s]Tokenizing train dataset:  26%|██▌       | 2230/8564 [00:29<00:59, 105.98 examples/s]Tokenizing train dataset:  26%|██▋       | 2250/8564 [00:30<01:15, 83.26 examples/s]Tokenizing train dataset:  28%|██▊       | 2366/8564 [00:29<01:32, 67.03 examples/s]Tokenizing train dataset:  28%|██▊       | 2377/8564 [00:29<01:23, 73.85 examples/s]Tokenizing train dataset:  26%|██▋       | 2260/8564 [00:30<01:15, 83.42 examples/s]Tokenizing train dataset:  26%|██▌       | 2246/8564 [00:29<01:01, 103.43 examples/s]Tokenizing train dataset:  28%|██▊       | 2398/8564 [00:29<01:01, 100.31 examples/s]Tokenizing train dataset:  27%|██▋       | 2275/8564 [00:30<01:09, 89.96 examples/s]Tokenizing train dataset:  26%|██▋       | 2258/8564 [00:29<01:02, 100.88 examples/s]Tokenizing train dataset:  28%|██▊       | 2412/8564 [00:29<00:57, 107.45 examples/s]Tokenizing train dataset:  26%|██▋       | 2269/8564 [00:29<01:04, 98.27 examples/s] Tokenizing train dataset:  27%|██▋       | 2287/8564 [00:30<01:08, 91.73 examples/s]Tokenizing train dataset:  27%|██▋       | 2282/8564 [00:29<01:01, 102.46 examples/s]Tokenizing train dataset:  28%|██▊       | 2430/8564 [00:29<00:57, 107.08 examples/s]Tokenizing train dataset:  27%|██▋       | 2301/8564 [00:30<01:09, 89.69 examples/s]Tokenizing train dataset:  27%|██▋       | 2295/8564 [00:30<00:58, 106.75 examples/s]Tokenizing train dataset:  29%|██▊       | 2445/8564 [00:30<01:07, 90.74 examples/s] Tokenizing train dataset:  27%|██▋       | 2311/8564 [00:30<01:23, 75.19 examples/s]Tokenizing train dataset:  27%|██▋       | 2308/8564 [00:30<01:06, 94.37 examples/s] Tokenizing train dataset:  29%|██▊       | 2460/8564 [00:30<01:00, 101.14 examples/s]Tokenizing train dataset:  27%|██▋       | 2321/8564 [00:31<01:18, 79.18 examples/s]Tokenizing train dataset:  27%|██▋       | 2318/8564 [00:30<01:12, 85.93 examples/s]Tokenizing train dataset:  29%|██▉       | 2473/8564 [00:30<00:57, 105.78 examples/s]Tokenizing train dataset:  27%|██▋       | 2332/8564 [00:31<01:16, 81.21 examples/s]Tokenizing train dataset:  27%|██▋       | 2328/8564 [00:30<01:15, 83.13 examples/s]Tokenizing train dataset:  29%|██▉       | 2486/8564 [00:30<00:56, 107.08 examples/s]Tokenizing train dataset:  27%|██▋       | 2348/8564 [00:31<01:08, 90.69 examples/s]Tokenizing train dataset:  29%|██▉       | 2500/8564 [00:30<01:00, 100.34 examples/s]Tokenizing train dataset:  27%|██▋       | 2340/8564 [00:30<01:19, 78.01 examples/s]Tokenizing train dataset:  28%|██▊       | 2359/8564 [00:31<01:06, 93.15 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:30<01:18, 79.47 examples/s]Tokenizing train dataset:  28%|██▊       | 2370/8564 [00:31<01:07, 91.36 examples/s]Tokenizing train dataset:  29%|██▉       | 2513/8564 [00:30<01:05, 92.28 examples/s] Tokenizing train dataset:  28%|██▊       | 2358/8564 [00:30<01:16, 81.44 examples/s]Tokenizing train dataset:  30%|██▉       | 2529/8564 [00:30<00:58, 102.96 examples/s]Tokenizing train dataset:  28%|██▊       | 2370/8564 [00:31<01:10, 87.74 examples/s]Tokenizing train dataset:  28%|██▊       | 2385/8564 [00:31<01:14, 83.36 examples/s]Tokenizing train dataset:  30%|██▉       | 2546/8564 [00:30<00:51, 117.21 examples/s]Tokenizing train dataset:  28%|██▊       | 2384/8564 [00:31<01:12, 85.55 examples/s]Tokenizing train dataset:  28%|██▊       | 2395/8564 [00:31<01:20, 76.45 examples/s]Tokenizing train dataset:  30%|██▉       | 2565/8564 [00:31<00:53, 112.59 examples/s]Tokenizing train dataset:  28%|██▊       | 2397/8564 [00:31<01:06, 92.11 examples/s]Tokenizing train dataset:  28%|██▊       | 2410/8564 [00:32<01:13, 83.60 examples/s]Tokenizing train dataset:  28%|██▊       | 2420/8564 [00:32<01:16, 80.74 examples/s]Tokenizing train dataset:  28%|██▊       | 2410/8564 [00:31<01:16, 80.78 examples/s]Tokenizing train dataset:  30%|███       | 2579/8564 [00:31<01:07, 88.36 examples/s] Tokenizing train dataset:  28%|██▊       | 2430/8564 [00:32<01:14, 82.33 examples/s]Tokenizing train dataset:  28%|██▊       | 2424/8564 [00:31<01:23, 73.34 examples/s]Tokenizing train dataset:  30%|███       | 2591/8564 [00:31<01:22, 72.11 examples/s]Tokenizing train dataset:  29%|██▊       | 2444/8564 [00:32<01:24, 72.57 examples/s]Tokenizing train dataset:  28%|██▊       | 2432/8564 [00:31<01:23, 73.00 examples/s]Tokenizing train dataset:  30%|███       | 2601/8564 [00:31<01:20, 74.32 examples/s]Tokenizing train dataset:  29%|██▊       | 2452/8564 [00:32<01:25, 71.37 examples/s]Tokenizing train dataset:  28%|██▊       | 2440/8564 [00:32<01:29, 68.77 examples/s]Tokenizing train dataset:  30%|███       | 2610/8564 [00:31<01:18, 76.29 examples/s]Tokenizing train dataset:  29%|██▊       | 2450/8564 [00:32<01:23, 73.29 examples/s]Tokenizing train dataset:  29%|██▉       | 2463/8564 [00:32<01:27, 70.11 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:32<01:25, 69.72 examples/s]Tokenizing train dataset:  29%|██▉       | 2473/8564 [00:32<01:21, 74.76 examples/s]Tokenizing train dataset:  29%|██▉       | 2463/8564 [00:32<01:15, 81.10 examples/s]Tokenizing train dataset:  31%|███       | 2634/8564 [00:32<01:13, 80.16 examples/s]Tokenizing train dataset:  29%|██▉       | 2474/8564 [00:32<01:12, 84.19 examples/s]Tokenizing train dataset:  31%|███       | 2647/8564 [00:32<01:07, 88.24 examples/s]Tokenizing train dataset:  29%|██▉       | 2485/8564 [00:33<01:27, 69.87 examples/s]Tokenizing train dataset:  29%|██▉       | 2488/8564 [00:32<01:04, 94.84 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:32<01:03, 92.95 examples/s]Tokenizing train dataset:  29%|██▉       | 2499/8564 [00:33<01:21, 74.64 examples/s]Tokenizing train dataset:  31%|███       | 2671/8564 [00:32<01:03, 92.66 examples/s]Tokenizing train dataset:  29%|██▉       | 2500/8564 [00:32<01:18, 76.96 examples/s]Tokenizing train dataset:  29%|██▉       | 2515/8564 [00:33<01:07, 89.84 examples/s]Tokenizing train dataset:  31%|███▏      | 2681/8564 [00:32<01:06, 87.92 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:33<01:00, 99.08 examples/s]Tokenizing train dataset:  29%|██▉       | 2510/8564 [00:32<01:26, 70.19 examples/s]Tokenizing train dataset:  31%|███▏      | 2693/8564 [00:32<01:02, 94.50 examples/s]Tokenizing train dataset:  29%|██▉       | 2522/8564 [00:32<01:15, 79.79 examples/s]Tokenizing train dataset:  32%|███▏      | 2708/8564 [00:32<00:57, 102.03 examples/s]Tokenizing train dataset:  30%|██▉       | 2550/8564 [00:33<01:01, 97.29 examples/s]Tokenizing train dataset:  30%|██▉       | 2534/8564 [00:33<01:08, 87.62 examples/s]Tokenizing train dataset:  32%|███▏      | 2722/8564 [00:33<00:54, 106.94 examples/s]Tokenizing train dataset:  30%|██▉       | 2545/8564 [00:33<01:05, 91.87 examples/s]Tokenizing train dataset:  30%|██▉       | 2569/8564 [00:33<01:02, 96.48 examples/s]Tokenizing train dataset:  32%|███▏      | 2735/8564 [00:33<01:02, 92.71 examples/s] Tokenizing train dataset:  30%|██▉       | 2555/8564 [00:33<01:12, 82.68 examples/s]Tokenizing train dataset:  30%|███       | 2579/8564 [00:34<01:05, 90.96 examples/s]Tokenizing train dataset:  30%|██▉       | 2566/8564 [00:33<01:13, 81.62 examples/s]Tokenizing train dataset:  30%|███       | 2592/8564 [00:34<01:08, 86.77 examples/s]Tokenizing train dataset:  32%|███▏      | 2747/8564 [00:33<01:13, 78.65 examples/s]Tokenizing train dataset:  30%|███       | 2584/8564 [00:33<00:58, 101.63 examples/s]Tokenizing train dataset:  30%|███       | 2603/8564 [00:34<01:07, 87.90 examples/s]Tokenizing train dataset:  32%|███▏      | 2757/8564 [00:33<01:13, 79.09 examples/s]Tokenizing train dataset:  30%|███       | 2598/8564 [00:33<00:58, 102.03 examples/s]Tokenizing train dataset:  31%|███       | 2615/8564 [00:34<01:06, 89.09 examples/s]Tokenizing train dataset:  32%|███▏      | 2771/8564 [00:33<01:06, 86.79 examples/s]Tokenizing train dataset:  31%|███       | 2615/8564 [00:33<00:50, 116.84 examples/s]Tokenizing train dataset:  33%|███▎      | 2784/8564 [00:33<01:02, 92.62 examples/s]Tokenizing train dataset:  31%|███       | 2627/8564 [00:34<01:19, 74.65 examples/s]Tokenizing train dataset:  31%|███       | 2630/8564 [00:34<00:57, 103.95 examples/s]Tokenizing train dataset:  33%|███▎      | 2799/8564 [00:33<00:55, 104.27 examples/s]Tokenizing train dataset:  31%|███       | 2640/8564 [00:34<01:11, 82.42 examples/s]Tokenizing train dataset:  31%|███       | 2646/8564 [00:34<00:58, 101.04 examples/s]Tokenizing train dataset:  33%|███▎      | 2810/8564 [00:34<01:04, 89.20 examples/s] Tokenizing train dataset:  31%|███       | 2649/8564 [00:34<01:18, 75.27 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:34<01:04, 89.40 examples/s]Tokenizing train dataset:  31%|███       | 2662/8564 [00:35<01:09, 85.00 examples/s]Tokenizing train dataset:  31%|███       | 2665/8564 [00:34<01:07, 87.89 examples/s] Tokenizing train dataset:  31%|███▏      | 2678/8564 [00:35<00:57, 101.99 examples/s]Tokenizing train dataset:  33%|███▎      | 2832/8564 [00:34<01:12, 78.65 examples/s]Tokenizing train dataset:  33%|███▎      | 2842/8564 [00:34<01:10, 80.87 examples/s]Tokenizing train dataset:  31%|███▏      | 2677/8564 [00:34<01:09, 84.13 examples/s]Tokenizing train dataset:  31%|███▏      | 2695/8564 [00:35<00:57, 102.63 examples/s]Tokenizing train dataset:  33%|███▎      | 2857/8564 [00:34<00:59, 95.26 examples/s]Tokenizing train dataset:  31%|███▏      | 2686/8564 [00:34<01:11, 82.40 examples/s]Tokenizing train dataset:  32%|███▏      | 2707/8564 [00:35<00:56, 103.63 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:34<00:58, 96.71 examples/s]Tokenizing train dataset:  32%|███▏      | 2698/8564 [00:34<01:09, 83.97 examples/s]Tokenizing train dataset:  32%|███▏      | 2722/8564 [00:35<00:58, 100.42 examples/s]Tokenizing train dataset:  34%|███▎      | 2883/8564 [00:34<00:53, 105.24 examples/s]Tokenizing train dataset:  32%|███▏      | 2712/8564 [00:35<01:08, 85.50 examples/s]Tokenizing train dataset:  34%|███▍      | 2899/8564 [00:34<00:50, 112.68 examples/s]Tokenizing train dataset:  32%|███▏      | 2721/8564 [00:35<01:07, 86.05 examples/s]Tokenizing train dataset:  32%|███▏      | 2738/8564 [00:35<01:04, 90.59 examples/s] Tokenizing train dataset:  34%|███▍      | 2913/8564 [00:35<00:47, 118.57 examples/s]Tokenizing train dataset:  32%|███▏      | 2735/8564 [00:35<01:01, 95.13 examples/s]Tokenizing train dataset:  34%|███▍      | 2929/8564 [00:35<00:45, 123.39 examples/s]Tokenizing train dataset:  32%|███▏      | 2754/8564 [00:36<01:07, 86.01 examples/s]Tokenizing train dataset:  32%|███▏      | 2747/8564 [00:35<01:09, 83.48 examples/s]Tokenizing train dataset:  34%|███▍      | 2949/8564 [00:35<00:45, 124.58 examples/s]Tokenizing train dataset:  32%|███▏      | 2769/8564 [00:36<01:00, 96.04 examples/s]Tokenizing train dataset:  32%|███▏      | 2757/8564 [00:35<01:07, 86.35 examples/s]Tokenizing train dataset:  35%|███▍      | 2964/8564 [00:35<00:48, 116.46 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:36<01:00, 95.77 examples/s]Tokenizing train dataset:  32%|███▏      | 2769/8564 [00:35<01:10, 81.85 examples/s]Tokenizing train dataset:  33%|███▎      | 2798/8564 [00:36<00:56, 101.28 examples/s]Tokenizing train dataset:  35%|███▍      | 2976/8564 [00:35<00:52, 107.22 examples/s]Tokenizing train dataset:  32%|███▏      | 2782/8564 [00:35<01:04, 90.33 examples/s]Tokenizing train dataset:  35%|███▍      | 2987/8564 [00:35<00:54, 103.13 examples/s]Tokenizing train dataset:  33%|███▎      | 2809/8564 [00:36<00:58, 98.04 examples/s] Tokenizing train dataset:  33%|███▎      | 2796/8564 [00:35<01:02, 91.68 examples/s]Tokenizing train dataset:  33%|███▎      | 2821/8564 [00:36<00:56, 101.10 examples/s]Tokenizing train dataset:  35%|███▌      | 2999/8564 [00:35<00:59, 93.28 examples/s] Tokenizing train dataset:  33%|███▎      | 2808/8564 [00:36<01:04, 89.28 examples/s]Tokenizing train dataset:  35%|███▌      | 3009/8564 [00:36<01:00, 92.26 examples/s]Tokenizing train dataset:  33%|███▎      | 2833/8564 [00:36<01:09, 82.39 examples/s] Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:36<01:06, 86.28 examples/s]Tokenizing train dataset:  35%|███▌      | 3022/8564 [00:36<00:58, 95.41 examples/s]Tokenizing train dataset:  33%|███▎      | 2844/8564 [00:36<01:06, 86.50 examples/s]Tokenizing train dataset:  33%|███▎      | 2854/8564 [00:37<01:05, 86.82 examples/s]Tokenizing train dataset:  33%|███▎      | 2832/8564 [00:36<01:18, 73.21 examples/s]Tokenizing train dataset:  35%|███▌      | 3033/8564 [00:36<01:11, 76.84 examples/s]Tokenizing train dataset:  33%|███▎      | 2864/8564 [00:37<01:06, 85.60 examples/s]Tokenizing train dataset:  36%|███▌      | 3042/8564 [00:36<01:10, 78.88 examples/s]Tokenizing train dataset:  33%|███▎      | 2842/8564 [00:36<01:18, 72.69 examples/s]Tokenizing train dataset:  34%|███▎      | 2873/8564 [00:37<01:14, 76.90 examples/s]Tokenizing train dataset:  36%|███▌      | 3054/8564 [00:36<01:04, 84.98 examples/s]Tokenizing train dataset:  33%|███▎      | 2850/8564 [00:36<01:19, 72.13 examples/s]Tokenizing train dataset:  36%|███▌      | 3065/8564 [00:36<01:03, 86.35 examples/s]Tokenizing train dataset:  34%|███▎      | 2887/8564 [00:37<01:11, 79.89 examples/s]Tokenizing train dataset:  33%|███▎      | 2860/8564 [00:36<01:21, 69.79 examples/s]Tokenizing train dataset:  34%|███▍      | 2899/8564 [00:37<01:06, 85.07 examples/s]Tokenizing train dataset:  36%|███▌      | 3077/8564 [00:36<01:07, 81.83 examples/s]Tokenizing train dataset:  34%|███▎      | 2869/8564 [00:37<01:17, 73.88 examples/s]Tokenizing train dataset:  34%|███▍      | 2913/8564 [00:37<01:01, 92.53 examples/s]Tokenizing train dataset:  36%|███▌      | 3087/8564 [00:36<01:07, 80.95 examples/s]Tokenizing train dataset:  34%|███▎      | 2880/8564 [00:37<01:28, 64.50 examples/s]Tokenizing train dataset:  34%|███▍      | 2924/8564 [00:37<01:01, 92.24 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:37<01:05, 82.87 examples/s]Tokenizing train dataset:  34%|███▍      | 2899/8564 [00:37<01:03, 88.63 examples/s]Tokenizing train dataset:  34%|███▍      | 2936/8564 [00:38<01:07, 83.38 examples/s]Tokenizing train dataset:  34%|███▍      | 2915/8564 [00:37<00:56, 100.25 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:37<01:10, 77.19 examples/s]Tokenizing train dataset:  34%|███▍      | 2948/8564 [00:38<01:02, 90.34 examples/s]Tokenizing train dataset:  36%|███▋      | 3119/8564 [00:37<01:10, 77.79 examples/s]Tokenizing train dataset:  35%|███▍      | 2960/8564 [00:38<00:59, 93.65 examples/s]Tokenizing train dataset:  34%|███▍      | 2933/8564 [00:37<00:56, 99.01 examples/s] Tokenizing train dataset:  37%|███▋      | 3132/8564 [00:37<01:07, 80.55 examples/s]Tokenizing train dataset:  35%|███▍      | 2980/8564 [00:38<00:49, 112.79 examples/s]Tokenizing train dataset:  34%|███▍      | 2947/8564 [00:37<01:01, 91.34 examples/s]Tokenizing train dataset:  37%|███▋      | 3142/8564 [00:37<01:07, 79.88 examples/s]Tokenizing train dataset:  37%|███▋      | 3155/8564 [00:37<01:00, 89.25 examples/s]Tokenizing train dataset:  35%|███▌      | 2998/8564 [00:38<00:55, 100.05 examples/s]Tokenizing train dataset:  35%|███▍      | 2960/8564 [00:38<01:10, 79.99 examples/s]Tokenizing train dataset:  37%|███▋      | 3167/8564 [00:37<01:06, 81.04 examples/s]Tokenizing train dataset:  35%|███▌      | 3014/8564 [00:38<00:55, 100.02 examples/s]Tokenizing train dataset:  35%|███▍      | 2975/8564 [00:38<01:02, 89.14 examples/s]Tokenizing train dataset:  35%|███▌      | 3027/8564 [00:39<01:05, 84.01 examples/s] Tokenizing train dataset:  37%|███▋      | 3181/8564 [00:38<01:15, 70.88 examples/s]Tokenizing train dataset:  35%|███▍      | 2987/8564 [00:38<01:11, 77.75 examples/s]Tokenizing train dataset:  37%|███▋      | 3190/8564 [00:38<01:13, 73.16 examples/s]Tokenizing train dataset:  35%|███▍      | 2996/8564 [00:38<01:12, 77.01 examples/s]Tokenizing train dataset:  35%|███▌      | 3037/8564 [00:39<01:10, 78.42 examples/s]Tokenizing train dataset:  37%|███▋      | 3205/8564 [00:38<01:02, 85.62 examples/s]Tokenizing train dataset:  35%|███▌      | 3007/8564 [00:38<01:11, 77.50 examples/s]Tokenizing train dataset:  36%|███▌      | 3047/8564 [00:39<01:10, 77.84 examples/s]Tokenizing train dataset:  38%|███▊      | 3221/8564 [00:38<00:59, 89.22 examples/s]Tokenizing train dataset:  35%|███▌      | 3017/8564 [00:38<01:29, 62.18 examples/s]Tokenizing train dataset:  36%|███▌      | 3056/8564 [00:39<01:30, 61.06 examples/s]Tokenizing train dataset:  38%|███▊      | 3235/8564 [00:38<01:08, 78.00 examples/s]Tokenizing train dataset:  35%|███▌      | 3027/8564 [00:39<01:21, 67.54 examples/s]Tokenizing train dataset:  36%|███▌      | 3065/8564 [00:39<01:24, 65.15 examples/s]Tokenizing train dataset:  35%|███▌      | 3036/8564 [00:39<01:17, 71.69 examples/s]Tokenizing train dataset:  36%|███▌      | 3076/8564 [00:39<01:14, 73.34 examples/s]Tokenizing train dataset:  38%|███▊      | 3248/8564 [00:38<01:03, 84.01 examples/s]Tokenizing train dataset:  36%|███▌      | 3086/8564 [00:39<01:13, 74.39 examples/s]Tokenizing train dataset:  36%|███▌      | 3046/8564 [00:39<01:21, 68.02 examples/s]Tokenizing train dataset:  38%|███▊      | 3261/8564 [00:39<01:08, 76.97 examples/s]Tokenizing train dataset:  36%|███▌      | 3099/8564 [00:40<01:04, 84.33 examples/s]Tokenizing train dataset:  36%|███▌      | 3054/8564 [00:39<01:24, 65.45 examples/s]Tokenizing train dataset:  38%|███▊      | 3271/8564 [00:39<01:11, 74.27 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:40<01:04, 84.71 examples/s]Tokenizing train dataset:  36%|███▌      | 3065/8564 [00:39<01:17, 70.97 examples/s]Tokenizing train dataset:  38%|███▊      | 3280/8564 [00:39<01:09, 76.44 examples/s]Tokenizing train dataset:  36%|███▋      | 3121/8564 [00:40<01:03, 85.33 examples/s]Tokenizing train dataset:  36%|███▌      | 3076/8564 [00:39<01:11, 76.88 examples/s]Tokenizing train dataset:  38%|███▊      | 3289/8564 [00:39<01:07, 78.34 examples/s]Tokenizing train dataset:  36%|███▌      | 3085/8564 [00:39<01:14, 73.36 examples/s]Tokenizing train dataset:  37%|███▋      | 3134/8564 [00:40<01:12, 74.77 examples/s]Tokenizing train dataset:  39%|███▊      | 3301/8564 [00:39<01:18, 67.18 examples/s]Tokenizing train dataset:  37%|███▋      | 3144/8564 [00:40<01:08, 78.74 examples/s]Tokenizing train dataset:  36%|███▌      | 3095/8564 [00:39<01:13, 74.64 examples/s]Tokenizing train dataset:  39%|███▊      | 3310/8564 [00:39<01:20, 65.45 examples/s]Tokenizing train dataset:  37%|███▋      | 3160/8564 [00:40<00:59, 91.40 examples/s]Tokenizing train dataset:  36%|███▋      | 3109/8564 [00:40<01:16, 71.59 examples/s]Tokenizing train dataset:  37%|███▋      | 3171/8564 [00:40<00:57, 94.14 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:40<01:14, 70.02 examples/s]Tokenizing train dataset:  36%|███▋      | 3120/8564 [00:40<01:19, 68.21 examples/s]Tokenizing train dataset:  37%|███▋      | 3185/8564 [00:41<00:57, 92.83 examples/s]Tokenizing train dataset:  39%|███▉      | 3332/8564 [00:40<01:14, 70.62 examples/s]Tokenizing train dataset:  37%|███▋      | 3132/8564 [00:40<01:15, 71.54 examples/s]Tokenizing train dataset:  37%|███▋      | 3195/8564 [00:41<01:03, 84.35 examples/s]Tokenizing train dataset:  39%|███▉      | 3340/8564 [00:40<01:16, 67.99 examples/s]Tokenizing train dataset:  37%|███▋      | 3144/8564 [00:40<01:07, 80.39 examples/s]Tokenizing train dataset:  39%|███▉      | 3350/8564 [00:40<01:11, 72.81 examples/s]Tokenizing train dataset:  37%|███▋      | 3207/8564 [00:41<01:09, 77.53 examples/s]Tokenizing train dataset:  37%|███▋      | 3160/8564 [00:40<00:56, 95.83 examples/s]Tokenizing train dataset:  39%|███▉      | 3362/8564 [00:40<01:07, 76.90 examples/s]Tokenizing train dataset:  38%|███▊      | 3221/8564 [00:41<00:59, 90.27 examples/s]Tokenizing train dataset:  37%|███▋      | 3172/8564 [00:40<01:00, 89.43 examples/s]Tokenizing train dataset:  39%|███▉      | 3370/8564 [00:40<01:11, 72.67 examples/s]Tokenizing train dataset:  38%|███▊      | 3232/8564 [00:41<00:57, 93.31 examples/s]Tokenizing train dataset:  40%|███▉      | 3393/8564 [00:40<00:47, 109.27 examples/s]Tokenizing train dataset:  37%|███▋      | 3185/8564 [00:40<01:01, 88.10 examples/s]Tokenizing train dataset:  38%|███▊      | 3243/8564 [00:41<00:55, 95.23 examples/s]Tokenizing train dataset:  38%|███▊      | 3253/8564 [00:41<00:55, 94.99 examples/s]Tokenizing train dataset:  40%|███▉      | 3410/8564 [00:40<00:48, 107.24 examples/s]Tokenizing train dataset:  37%|███▋      | 3197/8564 [00:41<01:04, 82.75 examples/s]Tokenizing train dataset:  38%|███▊      | 3263/8564 [00:41<00:58, 90.37 examples/s]Tokenizing train dataset:  37%|███▋      | 3206/8564 [00:41<01:04, 83.63 examples/s]Tokenizing train dataset:  40%|████      | 3426/8564 [00:41<00:49, 103.25 examples/s]Tokenizing train dataset:  38%|███▊      | 3273/8564 [00:42<01:02, 84.22 examples/s]Tokenizing train dataset:  38%|███▊      | 3216/8564 [00:41<01:02, 85.08 examples/s]Tokenizing train dataset:  40%|████      | 3437/8564 [00:41<00:49, 104.48 examples/s]Tokenizing train dataset:  38%|███▊      | 3282/8564 [00:42<01:11, 73.51 examples/s]Tokenizing train dataset:  38%|███▊      | 3232/8564 [00:41<01:01, 86.43 examples/s]Tokenizing train dataset:  40%|████      | 3451/8564 [00:41<00:49, 102.27 examples/s]Tokenizing train dataset:  38%|███▊      | 3294/8564 [00:42<01:04, 82.07 examples/s]Tokenizing train dataset:  40%|████      | 3468/8564 [00:41<00:51, 98.92 examples/s] Tokenizing train dataset:  39%|███▊      | 3307/8564 [00:42<00:58, 89.96 examples/s]Tokenizing train dataset:  38%|███▊      | 3251/8564 [00:41<01:02, 85.13 examples/s]Tokenizing train dataset:  39%|███▊      | 3318/8564 [00:42<00:56, 92.57 examples/s]Tokenizing train dataset:  41%|████      | 3479/8564 [00:41<00:58, 87.39 examples/s]Tokenizing train dataset:  38%|███▊      | 3263/8564 [00:41<01:04, 82.82 examples/s]Tokenizing train dataset:  39%|███▉      | 3330/8564 [00:42<01:00, 86.53 examples/s]Tokenizing train dataset:  41%|████      | 3493/8564 [00:41<00:57, 88.63 examples/s]Tokenizing train dataset:  38%|███▊      | 3279/8564 [00:42<01:01, 85.39 examples/s]Tokenizing train dataset:  39%|███▉      | 3340/8564 [00:42<01:02, 83.52 examples/s]Tokenizing train dataset:  41%|████      | 3507/8564 [00:42<00:51, 97.51 examples/s]Tokenizing train dataset:  38%|███▊      | 3296/8564 [00:42<00:51, 101.32 examples/s]Tokenizing train dataset:  39%|███▉      | 3350/8564 [00:42<01:08, 75.96 examples/s]Tokenizing train dataset:  41%|████      | 3520/8564 [00:42<01:03, 78.84 examples/s]Tokenizing train dataset:  39%|███▊      | 3309/8564 [00:42<00:58, 89.71 examples/s] Tokenizing train dataset:  39%|███▉      | 3362/8564 [00:43<01:00, 85.56 examples/s]Tokenizing train dataset:  41%|████▏     | 3533/8564 [00:42<00:57, 88.15 examples/s]Tokenizing train dataset:  39%|███▉      | 3371/8564 [00:43<01:00, 85.51 examples/s]Tokenizing train dataset:  39%|███▉      | 3322/8564 [00:42<01:00, 86.48 examples/s]Tokenizing train dataset:  41%|████▏     | 3550/8564 [00:42<00:49, 100.90 examples/s]Tokenizing train dataset:  39%|███▉      | 3382/8564 [00:43<01:09, 74.93 examples/s]Tokenizing train dataset:  39%|███▉      | 3336/8564 [00:42<01:02, 84.19 examples/s]Tokenizing train dataset:  42%|████▏     | 3561/8564 [00:42<00:50, 99.91 examples/s] Tokenizing train dataset:  40%|███▉      | 3397/8564 [00:43<00:56, 91.49 examples/s]Tokenizing train dataset:  39%|███▉      | 3350/8564 [00:42<00:54, 95.11 examples/s]Tokenizing train dataset:  42%|████▏     | 3572/8564 [00:42<00:57, 86.13 examples/s]Tokenizing train dataset:  40%|███▉      | 3409/8564 [00:43<00:53, 95.79 examples/s]Tokenizing train dataset:  39%|███▉      | 3362/8564 [00:42<00:54, 95.96 examples/s]Tokenizing train dataset:  42%|████▏     | 3583/8564 [00:42<00:58, 84.74 examples/s]Tokenizing train dataset:  40%|███▉      | 3423/8564 [00:43<00:55, 92.43 examples/s]Tokenizing train dataset:  42%|████▏     | 3594/8564 [00:43<00:55, 89.93 examples/s]Tokenizing train dataset:  39%|███▉      | 3378/8564 [00:43<00:57, 90.19 examples/s]Tokenizing train dataset:  40%|████      | 3435/8564 [00:43<00:53, 95.89 examples/s]Tokenizing train dataset:  42%|████▏     | 3609/8564 [00:43<00:48, 101.47 examples/s]Tokenizing train dataset:  40%|███▉      | 3390/8564 [00:43<00:58, 88.07 examples/s]Tokenizing train dataset:  40%|████      | 3448/8564 [00:44<01:00, 84.56 examples/s]Tokenizing train dataset:  42%|████▏     | 3623/8564 [00:43<00:48, 100.84 examples/s]Tokenizing train dataset:  40%|███▉      | 3402/8564 [00:43<00:57, 90.33 examples/s]Tokenizing train dataset:  40%|████      | 3457/8564 [00:44<01:00, 84.57 examples/s]Tokenizing train dataset:  42%|████▏     | 3636/8564 [00:43<00:48, 101.32 examples/s]Tokenizing train dataset:  40%|███▉      | 3412/8564 [00:43<00:56, 91.10 examples/s]Tokenizing train dataset:  40%|████      | 3467/8564 [00:44<01:00, 84.63 examples/s]Tokenizing train dataset:  40%|███▉      | 3424/8564 [00:43<01:02, 82.65 examples/s]Tokenizing train dataset:  43%|████▎     | 3650/8564 [00:43<00:53, 92.06 examples/s] Tokenizing train dataset:  41%|████      | 3478/8564 [00:44<00:59, 85.32 examples/s]Tokenizing train dataset:  40%|████      | 3434/8564 [00:43<00:59, 85.52 examples/s]Tokenizing train dataset:  43%|████▎     | 3661/8564 [00:43<00:53, 90.89 examples/s]Tokenizing train dataset:  41%|████      | 3489/8564 [00:44<01:05, 77.18 examples/s]Tokenizing train dataset:  43%|████▎     | 3671/8564 [00:43<01:00, 80.68 examples/s]Tokenizing train dataset:  41%|████      | 3500/8564 [00:44<01:01, 82.43 examples/s]Tokenizing train dataset:  40%|████      | 3449/8564 [00:44<01:02, 82.35 examples/s]Tokenizing train dataset:  40%|████      | 3458/8564 [00:44<01:03, 81.04 examples/s]Tokenizing train dataset:  41%|████      | 3514/8564 [00:44<00:54, 93.44 examples/s]Tokenizing train dataset:  43%|████▎     | 3683/8564 [00:44<01:04, 75.51 examples/s]Tokenizing train dataset:  40%|████      | 3467/8564 [00:44<01:02, 81.09 examples/s]Tokenizing train dataset:  41%|████      | 3525/8564 [00:44<00:55, 90.40 examples/s]Tokenizing train dataset:  43%|████▎     | 3693/8564 [00:44<01:03, 77.07 examples/s]Tokenizing train dataset:  41%|████▏     | 3537/8564 [00:45<00:55, 90.89 examples/s]Tokenizing train dataset:  41%|████      | 3480/8564 [00:44<01:06, 76.90 examples/s]Tokenizing train dataset:  43%|████▎     | 3707/8564 [00:44<01:03, 76.95 examples/s]Tokenizing train dataset:  41%|████▏     | 3550/8564 [00:45<00:56, 88.07 examples/s]Tokenizing train dataset:  43%|████▎     | 3722/8564 [00:44<00:54, 88.57 examples/s]Tokenizing train dataset:  41%|████      | 3492/8564 [00:44<01:06, 76.52 examples/s]Tokenizing train dataset:  42%|████▏     | 3561/8564 [00:45<00:54, 91.86 examples/s]Tokenizing train dataset:  41%|████      | 3504/8564 [00:44<01:08, 73.80 examples/s]Tokenizing train dataset:  44%|████▎     | 3735/8564 [00:44<00:57, 84.54 examples/s]Tokenizing train dataset:  42%|████▏     | 3572/8564 [00:45<00:54, 91.77 examples/s]Tokenizing train dataset:  41%|████      | 3514/8564 [00:44<01:08, 73.87 examples/s]Tokenizing train dataset:  44%|████▍     | 3752/8564 [00:44<00:50, 94.79 examples/s]Tokenizing train dataset:  42%|████▏     | 3590/8564 [00:45<00:53, 92.91 examples/s]Tokenizing train dataset:  41%|████      | 3529/8564 [00:45<01:00, 82.82 examples/s]Tokenizing train dataset:  42%|████▏     | 3605/8564 [00:45<00:48, 102.05 examples/s]Tokenizing train dataset:  44%|████▍     | 3764/8564 [00:44<00:55, 87.26 examples/s]Tokenizing train dataset:  41%|████▏     | 3540/8564 [00:45<00:58, 85.43 examples/s]Tokenizing train dataset:  44%|████▍     | 3773/8564 [00:45<00:54, 87.18 examples/s]Tokenizing train dataset:  42%|████▏     | 3617/8564 [00:45<00:49, 99.27 examples/s] Tokenizing train dataset:  41%|████▏     | 3550/8564 [00:45<01:00, 83.04 examples/s]Tokenizing train dataset:  42%|████▏     | 3633/8564 [00:46<00:43, 112.86 examples/s]Tokenizing train dataset:  44%|████▍     | 3782/8564 [00:45<00:59, 80.01 examples/s]Tokenizing train dataset:  42%|████▏     | 3562/8564 [00:45<00:55, 89.95 examples/s]Tokenizing train dataset:  44%|████▍     | 3794/8564 [00:45<00:58, 82.13 examples/s]Tokenizing train dataset:  42%|████▏     | 3580/8564 [00:45<00:46, 106.77 examples/s]Tokenizing train dataset:  43%|████▎     | 3645/8564 [00:46<00:49, 99.29 examples/s] Tokenizing train dataset:  44%|████▍     | 3803/8564 [00:45<01:01, 77.62 examples/s]Tokenizing train dataset:  42%|████▏     | 3596/8564 [00:45<00:50, 99.29 examples/s] Tokenizing train dataset:  43%|████▎     | 3660/8564 [00:46<00:57, 85.46 examples/s]Tokenizing train dataset:  45%|████▍     | 3815/8564 [00:45<00:55, 86.20 examples/s]Tokenizing train dataset:  42%|████▏     | 3609/8564 [00:45<00:50, 98.17 examples/s]Tokenizing train dataset:  43%|████▎     | 3675/8564 [00:46<00:56, 87.08 examples/s]Tokenizing train dataset:  45%|████▍     | 3830/8564 [00:45<00:59, 79.69 examples/s]Tokenizing train dataset:  42%|████▏     | 3620/8564 [00:45<00:51, 96.14 examples/s]Tokenizing train dataset:  43%|████▎     | 3687/8564 [00:46<00:53, 91.45 examples/s]Tokenizing train dataset:  45%|████▍     | 3839/8564 [00:45<00:59, 79.47 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:46<00:52, 93.75 examples/s]Tokenizing train dataset:  43%|████▎     | 3700/8564 [00:46<00:51, 94.25 examples/s]Tokenizing train dataset:  45%|████▍     | 3848/8564 [00:46<01:08, 69.18 examples/s]Tokenizing train dataset:  43%|████▎     | 3712/8564 [00:46<00:49, 98.18 examples/s]Tokenizing train dataset:  43%|████▎     | 3642/8564 [00:46<00:59, 82.74 examples/s]Tokenizing train dataset:  43%|████▎     | 3725/8564 [00:47<00:47, 100.95 examples/s]Tokenizing train dataset:  45%|████▌     | 3860/8564 [00:46<01:11, 65.89 examples/s]Tokenizing train dataset:  43%|████▎     | 3652/8564 [00:46<01:09, 70.97 examples/s]Tokenizing train dataset:  44%|████▎     | 3736/8564 [00:47<00:49, 98.22 examples/s] Tokenizing train dataset:  45%|████▌     | 3875/8564 [00:46<00:57, 81.64 examples/s]Tokenizing train dataset:  43%|████▎     | 3663/8564 [00:46<01:11, 68.67 examples/s]Tokenizing train dataset:  45%|████▌     | 3888/8564 [00:46<00:51, 91.25 examples/s]Tokenizing train dataset:  44%|████▍     | 3749/8564 [00:47<00:53, 89.97 examples/s]Tokenizing train dataset:  43%|████▎     | 3674/8564 [00:46<01:12, 67.74 examples/s]Tokenizing train dataset:  46%|████▌     | 3901/8564 [00:46<00:54, 86.15 examples/s]Tokenizing train dataset:  44%|████▍     | 3764/8564 [00:47<00:54, 87.47 examples/s]Tokenizing train dataset:  43%|████▎     | 3685/8564 [00:46<01:06, 73.43 examples/s]Tokenizing train dataset:  44%|████▍     | 3775/8564 [00:47<00:53, 89.35 examples/s]Tokenizing train dataset:  46%|████▌     | 3911/8564 [00:46<01:00, 76.78 examples/s]Tokenizing train dataset:  43%|████▎     | 3700/8564 [00:47<00:55, 87.80 examples/s]Tokenizing train dataset:  44%|████▍     | 3787/8564 [00:47<00:52, 91.54 examples/s]Tokenizing train dataset:  46%|████▌     | 3921/8564 [00:46<00:59, 78.23 examples/s]Tokenizing train dataset:  43%|████▎     | 3710/8564 [00:47<00:57, 85.03 examples/s]Tokenizing train dataset:  44%|████▍     | 3801/8564 [00:47<00:54, 87.20 examples/s]Tokenizing train dataset:  43%|████▎     | 3724/8564 [00:47<00:50, 96.23 examples/s]Tokenizing train dataset:  46%|████▌     | 3931/8564 [00:47<01:00, 76.22 examples/s]Tokenizing train dataset:  45%|████▍     | 3812/8564 [00:48<00:51, 91.67 examples/s]Tokenizing train dataset:  46%|████▌     | 3940/8564 [00:47<00:58, 78.52 examples/s]Tokenizing train dataset:  45%|████▍     | 3823/8564 [00:48<00:50, 94.40 examples/s]Tokenizing train dataset:  44%|████▎     | 3742/8564 [00:47<00:50, 94.86 examples/s]Tokenizing train dataset:  46%|████▌     | 3950/8564 [00:47<00:57, 80.05 examples/s]Tokenizing train dataset:  45%|████▍     | 3836/8564 [00:48<00:46, 102.69 examples/s]Tokenizing train dataset:  44%|████▍     | 3753/8564 [00:47<00:51, 94.11 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:47<00:53, 85.61 examples/s]Tokenizing train dataset:  45%|████▍     | 3850/8564 [00:48<00:42, 111.51 examples/s]Tokenizing train dataset:  46%|████▋     | 3973/8564 [00:47<00:55, 82.74 examples/s]Tokenizing train dataset:  44%|████▍     | 3766/8564 [00:47<00:53, 89.83 examples/s]Tokenizing train dataset:  45%|████▌     | 3868/8564 [00:48<00:43, 107.04 examples/s]Tokenizing train dataset:  47%|████▋     | 3984/8564 [00:47<00:59, 76.60 examples/s]Tokenizing train dataset:  44%|████▍     | 3783/8564 [00:47<00:52, 91.75 examples/s]Tokenizing train dataset:  44%|████▍     | 3799/8564 [00:48<00:47, 100.59 examples/s]Tokenizing train dataset:  47%|████▋     | 3998/8564 [00:47<00:58, 78.22 examples/s]Tokenizing train dataset:  45%|████▌     | 3883/8564 [00:48<00:51, 91.69 examples/s] Tokenizing train dataset:  45%|████▍     | 3812/8564 [00:48<00:46, 103.15 examples/s]Tokenizing train dataset:  47%|████▋     | 4009/8564 [00:48<00:56, 80.47 examples/s]Tokenizing train dataset:  45%|████▌     | 3893/8564 [00:48<01:02, 74.79 examples/s]Tokenizing train dataset:  45%|████▍     | 3827/8564 [00:48<00:45, 104.92 examples/s]Tokenizing train dataset:  47%|████▋     | 4018/8564 [00:48<00:57, 79.47 examples/s]Tokenizing train dataset:  45%|████▍     | 3839/8564 [00:48<00:45, 103.93 examples/s]Tokenizing train dataset:  47%|████▋     | 4027/8564 [00:48<00:56, 79.73 examples/s]Tokenizing train dataset:  46%|████▌     | 3905/8564 [00:49<01:03, 73.16 examples/s]Tokenizing train dataset:  47%|████▋     | 4036/8564 [00:48<00:57, 79.42 examples/s]Tokenizing train dataset:  45%|████▍     | 3850/8564 [00:48<00:47, 99.48 examples/s] Tokenizing train dataset:  45%|████▌     | 3860/8564 [00:48<00:47, 99.21 examples/s]Tokenizing train dataset:  47%|████▋     | 4050/8564 [00:48<00:48, 92.52 examples/s]Tokenizing train dataset:  46%|████▌     | 3916/8564 [00:49<01:11, 65.11 examples/s]Tokenizing train dataset:  45%|████▌     | 3873/8564 [00:48<00:44, 105.00 examples/s]Tokenizing train dataset:  46%|████▌     | 3925/8564 [00:49<01:07, 68.60 examples/s]Tokenizing train dataset:  47%|████▋     | 4060/8564 [00:48<00:54, 82.15 examples/s]Tokenizing train dataset:  45%|████▌     | 3886/8564 [00:48<00:42, 109.38 examples/s]Tokenizing train dataset:  46%|████▌     | 3933/8564 [00:49<01:05, 70.55 examples/s]Tokenizing train dataset:  48%|████▊     | 4070/8564 [00:48<00:54, 82.78 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:49<01:09, 66.07 examples/s]Tokenizing train dataset:  46%|████▌     | 3902/8564 [00:49<00:46, 100.12 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:48<00:52, 85.64 examples/s]Tokenizing train dataset:  46%|████▌     | 3956/8564 [00:49<00:55, 82.81 examples/s]Tokenizing train dataset:  48%|████▊     | 4093/8564 [00:49<00:53, 83.63 examples/s]Tokenizing train dataset:  46%|████▋     | 3967/8564 [00:49<00:53, 86.47 examples/s]Tokenizing train dataset:  46%|████▌     | 3916/8564 [00:49<00:52, 88.68 examples/s] Tokenizing train dataset:  48%|████▊     | 4103/8564 [00:49<00:51, 86.93 examples/s]Tokenizing train dataset:  46%|████▋     | 3978/8564 [00:50<01:02, 73.04 examples/s]Tokenizing train dataset:  46%|████▌     | 3927/8564 [00:49<01:09, 66.32 examples/s]Tokenizing train dataset:  48%|████▊     | 4117/8564 [00:49<01:02, 70.60 examples/s]Tokenizing train dataset:  47%|████▋     | 3988/8564 [00:50<01:00, 76.01 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:49<01:01, 74.90 examples/s]Tokenizing train dataset:  47%|████▋     | 3999/8564 [00:50<00:57, 80.01 examples/s]Tokenizing train dataset:  48%|████▊     | 4130/8564 [00:49<00:57, 76.86 examples/s]Tokenizing train dataset:  46%|████▌     | 3952/8564 [00:49<00:57, 80.71 examples/s]Tokenizing train dataset:  47%|████▋     | 4011/8564 [00:50<00:58, 78.15 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:49<00:53, 86.27 examples/s]Tokenizing train dataset:  48%|████▊     | 4142/8564 [00:49<01:00, 73.46 examples/s]Tokenizing train dataset:  47%|████▋     | 4024/8564 [00:50<00:54, 83.40 examples/s]Tokenizing train dataset:  48%|████▊     | 4150/8564 [00:49<01:03, 69.86 examples/s]Tokenizing train dataset:  46%|████▋     | 3980/8564 [00:50<00:49, 92.58 examples/s]Tokenizing train dataset:  49%|████▊     | 4160/8564 [00:49<00:59, 74.21 examples/s]Tokenizing train dataset:  47%|████▋     | 4039/8564 [00:50<00:52, 86.48 examples/s]Tokenizing train dataset:  47%|████▋     | 3991/8564 [00:50<00:53, 84.81 examples/s]Tokenizing train dataset:  49%|████▊     | 4172/8564 [00:50<00:55, 78.94 examples/s]Tokenizing train dataset:  47%|████▋     | 4052/8564 [00:50<00:53, 84.15 examples/s]Tokenizing train dataset:  47%|████▋     | 4002/8564 [00:50<00:54, 83.69 examples/s]Tokenizing train dataset:  49%|████▉     | 4189/8564 [00:50<00:45, 95.52 examples/s]Tokenizing train dataset:  47%|████▋     | 4065/8564 [00:51<00:54, 82.59 examples/s]Tokenizing train dataset:  49%|████▉     | 4200/8564 [00:50<00:47, 91.63 examples/s]Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:50<00:58, 77.47 examples/s]Tokenizing train dataset:  48%|████▊     | 4074/8564 [00:51<00:57, 78.04 examples/s]Tokenizing train dataset:  47%|████▋     | 4026/8564 [00:50<00:55, 81.07 examples/s]Tokenizing train dataset:  49%|████▉     | 4210/8564 [00:50<00:51, 84.72 examples/s]Tokenizing train dataset:  48%|████▊     | 4087/8564 [00:51<00:50, 88.63 examples/s]Tokenizing train dataset:  47%|████▋     | 4038/8564 [00:50<00:51, 88.54 examples/s]Tokenizing train dataset:  49%|████▉     | 4220/8564 [00:50<00:50, 86.79 examples/s]Tokenizing train dataset:  48%|████▊     | 4097/8564 [00:51<00:52, 85.76 examples/s]Tokenizing train dataset:  47%|████▋     | 4052/8564 [00:50<00:54, 82.14 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:51<00:47, 94.27 examples/s]Tokenizing train dataset:  49%|████▉     | 4233/8564 [00:50<00:55, 78.71 examples/s]Tokenizing train dataset:  48%|████▊     | 4120/8564 [00:51<00:47, 93.50 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:51<00:58, 77.39 examples/s]Tokenizing train dataset:  50%|████▉     | 4242/8564 [00:51<01:02, 69.15 examples/s]Tokenizing train dataset:  48%|████▊     | 4131/8564 [00:51<00:47, 92.69 examples/s]Tokenizing train dataset:  48%|████▊     | 4073/8564 [00:51<01:00, 73.90 examples/s]Tokenizing train dataset:  50%|████▉     | 4254/8564 [00:51<01:00, 70.76 examples/s]Tokenizing train dataset:  48%|████▊     | 4145/8564 [00:52<00:49, 89.02 examples/s]Tokenizing train dataset:  48%|████▊     | 4083/8564 [00:51<00:58, 77.21 examples/s]Tokenizing train dataset:  50%|████▉     | 4264/8564 [00:51<00:57, 74.59 examples/s]Tokenizing train dataset:  48%|████▊     | 4093/8564 [00:51<00:56, 79.51 examples/s]Tokenizing train dataset:  50%|████▉     | 4277/8564 [00:51<00:49, 86.58 examples/s]Tokenizing train dataset:  49%|████▊     | 4159/8564 [00:52<00:54, 80.69 examples/s]Tokenizing train dataset:  48%|████▊     | 4105/8564 [00:51<00:50, 88.11 examples/s]Tokenizing train dataset:  50%|█████     | 4290/8564 [00:51<00:46, 92.85 examples/s]Tokenizing train dataset:  49%|████▊     | 4170/8564 [00:52<00:53, 81.57 examples/s]Tokenizing train dataset:  48%|████▊     | 4117/8564 [00:51<00:47, 92.77 examples/s]Tokenizing train dataset:  50%|█████     | 4301/8564 [00:51<00:45, 94.47 examples/s]Tokenizing train dataset:  49%|████▉     | 4180/8564 [00:52<00:51, 84.32 examples/s]Tokenizing train dataset:  50%|█████     | 4313/8564 [00:51<00:42, 100.43 examples/s]Tokenizing train dataset:  48%|████▊     | 4127/8564 [00:51<00:56, 79.20 examples/s]Tokenizing train dataset:  49%|████▉     | 4197/8564 [00:52<00:47, 92.08 examples/s]Tokenizing train dataset:  51%|█████     | 4326/8564 [00:51<00:49, 84.85 examples/s] Tokenizing train dataset:  49%|████▉     | 4207/8564 [00:52<00:48, 89.74 examples/s]Tokenizing train dataset:  48%|████▊     | 4142/8564 [00:52<00:59, 74.82 examples/s]Tokenizing train dataset:  51%|█████     | 4336/8564 [00:52<00:49, 85.96 examples/s]Tokenizing train dataset:  49%|████▉     | 4217/8564 [00:52<00:50, 85.28 examples/s]Tokenizing train dataset:  49%|████▊     | 4154/8564 [00:52<00:54, 80.34 examples/s]Tokenizing train dataset:  51%|█████     | 4346/8564 [00:52<00:53, 79.41 examples/s]Tokenizing train dataset:  49%|████▉     | 4230/8564 [00:53<00:52, 82.29 examples/s]Tokenizing train dataset:  49%|████▊     | 4164/8564 [00:52<01:02, 70.44 examples/s]Tokenizing train dataset:  51%|█████     | 4356/8564 [00:52<00:53, 78.23 examples/s]Tokenizing train dataset:  49%|████▉     | 4180/8564 [00:52<00:50, 86.94 examples/s]Tokenizing train dataset:  50%|████▉     | 4240/8564 [00:53<01:05, 66.43 examples/s]Tokenizing train dataset:  49%|████▉     | 4194/8564 [00:52<00:44, 97.85 examples/s]Tokenizing train dataset:  51%|█████     | 4370/8564 [00:52<00:55, 75.05 examples/s]Tokenizing train dataset:  50%|████▉     | 4251/8564 [00:53<00:58, 73.45 examples/s]Tokenizing train dataset:  49%|████▉     | 4207/8564 [00:52<00:43, 99.74 examples/s]Tokenizing train dataset:  51%|█████     | 4379/8564 [00:52<00:59, 69.92 examples/s]Tokenizing train dataset:  49%|████▉     | 4218/8564 [00:52<00:43, 100.89 examples/s]Tokenizing train dataset:  50%|████▉     | 4261/8564 [00:53<00:56, 76.60 examples/s]Tokenizing train dataset:  51%|█████▏    | 4390/8564 [00:52<01:03, 66.21 examples/s]Tokenizing train dataset:  49%|████▉     | 4232/8564 [00:53<00:42, 101.48 examples/s]Tokenizing train dataset:  50%|████▉     | 4277/8564 [00:53<00:56, 75.59 examples/s]Tokenizing train dataset:  51%|█████▏    | 4404/8564 [00:52<00:52, 78.97 examples/s]Tokenizing train dataset:  50%|█████     | 4289/8564 [00:53<00:51, 83.68 examples/s]Tokenizing train dataset:  52%|█████▏    | 4420/8564 [00:53<00:44, 94.03 examples/s]Tokenizing train dataset:  50%|████▉     | 4247/8564 [00:53<00:51, 83.12 examples/s] Tokenizing train dataset:  50%|█████     | 4301/8564 [00:53<00:47, 90.60 examples/s]Tokenizing train dataset:  50%|█████     | 4312/8564 [00:54<00:47, 90.07 examples/s]Tokenizing train dataset:  52%|█████▏    | 4439/8564 [00:53<00:41, 100.57 examples/s]Tokenizing train dataset:  50%|████▉     | 4262/8564 [00:53<00:48, 89.14 examples/s]Tokenizing train dataset:  51%|█████     | 4326/8564 [00:54<00:49, 85.87 examples/s]Tokenizing train dataset:  50%|████▉     | 4274/8564 [00:53<00:51, 82.55 examples/s]Tokenizing train dataset:  52%|█████▏    | 4452/8564 [00:53<00:45, 90.13 examples/s] Tokenizing train dataset:  51%|█████     | 4338/8564 [00:54<00:47, 88.75 examples/s]Tokenizing train dataset:  50%|█████     | 4291/8564 [00:53<00:48, 87.63 examples/s]Tokenizing train dataset:  52%|█████▏    | 4466/8564 [00:53<00:47, 86.57 examples/s]Tokenizing train dataset:  50%|█████     | 4301/8564 [00:53<00:49, 86.19 examples/s]Tokenizing train dataset:  52%|█████▏    | 4476/8564 [00:53<00:50, 80.76 examples/s]Tokenizing train dataset:  51%|█████     | 4351/8564 [00:54<00:56, 74.22 examples/s]Tokenizing train dataset:  50%|█████     | 4315/8564 [00:54<00:45, 93.09 examples/s]Tokenizing train dataset:  52%|█████▏    | 4486/8564 [00:53<00:51, 79.63 examples/s]Tokenizing train dataset:  51%|█████     | 4362/8564 [00:54<00:57, 72.53 examples/s]Tokenizing train dataset:  51%|█████     | 4326/8564 [00:54<00:44, 95.60 examples/s]Tokenizing train dataset:  51%|█████     | 4373/8564 [00:54<00:53, 77.62 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:54<00:53, 76.07 examples/s]Tokenizing train dataset:  51%|█████     | 4339/8564 [00:54<00:46, 90.02 examples/s]Tokenizing train dataset:  51%|█████     | 4383/8564 [00:55<00:59, 70.64 examples/s]Tokenizing train dataset:  51%|█████     | 4353/8564 [00:54<00:43, 96.50 examples/s]Tokenizing train dataset:  53%|█████▎    | 4509/8564 [00:54<00:57, 70.47 examples/s]Tokenizing train dataset:  51%|█████     | 4364/8564 [00:54<00:42, 98.70 examples/s]Tokenizing train dataset:  51%|█████▏    | 4396/8564 [00:55<00:51, 81.49 examples/s]Tokenizing train dataset:  53%|█████▎    | 4518/8564 [00:54<00:55, 73.15 examples/s]Tokenizing train dataset:  51%|█████▏    | 4405/8564 [00:55<00:51, 81.41 examples/s]Tokenizing train dataset:  51%|█████     | 4375/8564 [00:54<00:43, 95.48 examples/s]Tokenizing train dataset:  53%|█████▎    | 4527/8564 [00:54<00:54, 73.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 4419/8564 [00:55<00:44, 92.27 examples/s]Tokenizing train dataset:  53%|█████▎    | 4536/8564 [00:54<00:52, 76.75 examples/s]Tokenizing train dataset:  51%|█████     | 4386/8564 [00:54<00:45, 92.27 examples/s]Tokenizing train dataset:  52%|█████▏    | 4432/8564 [00:55<00:41, 99.52 examples/s]Tokenizing train dataset:  53%|█████▎    | 4545/8564 [00:54<00:51, 77.76 examples/s]Tokenizing train dataset:  51%|█████▏    | 4398/8564 [00:54<00:50, 82.36 examples/s]Tokenizing train dataset:  52%|█████▏    | 4445/8564 [00:55<00:39, 103.33 examples/s]Tokenizing train dataset:  53%|█████▎    | 4555/8564 [00:54<00:50, 80.17 examples/s]Tokenizing train dataset:  52%|█████▏    | 4417/8564 [00:55<00:40, 103.67 examples/s]Tokenizing train dataset:  52%|█████▏    | 4456/8564 [00:55<00:47, 86.11 examples/s] Tokenizing train dataset:  52%|█████▏    | 4432/8564 [00:55<00:36, 112.80 examples/s]Tokenizing train dataset:  53%|█████▎    | 4570/8564 [00:55<00:54, 72.92 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:55<00:44, 91.96 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:55<00:53, 75.12 examples/s]Tokenizing train dataset:  52%|█████▏    | 4480/8564 [00:56<00:45, 89.92 examples/s]Tokenizing train dataset:  52%|█████▏    | 4445/8564 [00:55<00:46, 88.08 examples/s] Tokenizing train dataset:  54%|█████▎    | 4593/8564 [00:55<00:47, 83.84 examples/s]Tokenizing train dataset:  52%|█████▏    | 4490/8564 [00:56<00:47, 86.24 examples/s]Tokenizing train dataset:  54%|█████▎    | 4603/8564 [00:55<00:47, 84.09 examples/s]Tokenizing train dataset:  52%|█████▏    | 4458/8564 [00:55<00:49, 82.97 examples/s]Tokenizing train dataset:  53%|█████▎    | 4501/8564 [00:56<00:45, 90.28 examples/s]Tokenizing train dataset:  54%|█████▍    | 4617/8564 [00:55<00:46, 84.26 examples/s]Tokenizing train dataset:  52%|█████▏    | 4474/8564 [00:55<00:48, 83.70 examples/s]Tokenizing train dataset:  53%|█████▎    | 4519/8564 [00:56<00:41, 96.33 examples/s]Tokenizing train dataset:  54%|█████▍    | 4630/8564 [00:55<00:42, 92.78 examples/s]Tokenizing train dataset:  52%|█████▏    | 4484/8564 [00:55<00:49, 81.73 examples/s]Tokenizing train dataset:  53%|█████▎    | 4535/8564 [00:56<00:40, 98.52 examples/s]Tokenizing train dataset:  54%|█████▍    | 4641/8564 [00:55<00:43, 90.81 examples/s]Tokenizing train dataset:  52%|█████▏    | 4494/8564 [00:56<00:54, 74.79 examples/s]Tokenizing train dataset:  53%|█████▎    | 4549/8564 [00:56<00:40, 99.57 examples/s]Tokenizing train dataset:  54%|█████▍    | 4653/8564 [00:55<00:46, 84.25 examples/s]Tokenizing train dataset:  53%|█████▎    | 4508/8564 [00:56<00:50, 80.57 examples/s]Tokenizing train dataset:  53%|█████▎    | 4562/8564 [00:56<00:42, 93.67 examples/s]Tokenizing train dataset:  54%|█████▍    | 4663/8564 [00:56<00:51, 76.18 examples/s]Tokenizing train dataset:  53%|█████▎    | 4519/8564 [00:56<00:48, 83.26 examples/s]Tokenizing train dataset:  53%|█████▎    | 4572/8564 [00:57<00:47, 83.56 examples/s]Tokenizing train dataset:  53%|█████▎    | 4528/8564 [00:56<00:48, 83.78 examples/s]Tokenizing train dataset:  55%|█████▍    | 4675/8564 [00:56<00:48, 80.18 examples/s]Tokenizing train dataset:  53%|█████▎    | 4541/8564 [00:56<00:46, 86.67 examples/s]Tokenizing train dataset:  54%|█████▎    | 4584/8564 [00:57<00:52, 75.65 examples/s]Tokenizing train dataset:  55%|█████▍    | 4684/8564 [00:56<00:52, 73.65 examples/s]Tokenizing train dataset:  54%|█████▎    | 4598/8564 [00:57<00:45, 87.43 examples/s]Tokenizing train dataset:  53%|█████▎    | 4555/8564 [00:56<00:45, 88.93 examples/s]Tokenizing train dataset:  55%|█████▍    | 4693/8564 [00:56<01:00, 64.39 examples/s]Tokenizing train dataset:  54%|█████▍    | 4610/8564 [00:57<00:43, 91.76 examples/s]Tokenizing train dataset:  53%|█████▎    | 4564/8564 [00:56<00:48, 82.76 examples/s]Tokenizing train dataset:  55%|█████▍    | 4701/8564 [00:56<01:00, 63.80 examples/s]Tokenizing train dataset:  54%|█████▍    | 4621/8564 [00:57<00:43, 91.65 examples/s]Tokenizing train dataset:  53%|█████▎    | 4573/8564 [00:56<00:51, 76.99 examples/s]Tokenizing train dataset:  55%|█████▍    | 4709/8564 [00:56<01:00, 63.74 examples/s]Tokenizing train dataset:  54%|█████▍    | 4631/8564 [00:57<00:43, 90.64 examples/s]Tokenizing train dataset:  54%|█████▎    | 4582/8564 [00:57<00:50, 78.11 examples/s]Tokenizing train dataset:  55%|█████▌    | 4720/8564 [00:57<00:56, 68.22 examples/s]Tokenizing train dataset:  54%|█████▎    | 4596/8564 [00:57<00:43, 90.30 examples/s]Tokenizing train dataset:  54%|█████▍    | 4642/8564 [00:57<00:44, 88.91 examples/s]Tokenizing train dataset:  55%|█████▌    | 4730/8564 [00:57<00:56, 68.44 examples/s]Tokenizing train dataset:  54%|█████▍    | 4608/8564 [00:57<00:41, 95.47 examples/s]Tokenizing train dataset:  54%|█████▍    | 4653/8564 [00:58<00:49, 78.57 examples/s]Tokenizing train dataset:  55%|█████▌    | 4739/8564 [00:57<00:54, 69.89 examples/s]Tokenizing train dataset:  54%|█████▍    | 4622/8564 [00:57<00:39, 100.39 examples/s]Tokenizing train dataset:  54%|█████▍    | 4665/8564 [00:58<00:52, 74.51 examples/s]Tokenizing train dataset:  55%|█████▌    | 4750/8564 [00:57<00:58, 65.33 examples/s]Tokenizing train dataset:  54%|█████▍    | 4637/8564 [00:57<00:41, 94.26 examples/s] Tokenizing train dataset:  55%|█████▍    | 4673/8564 [00:58<00:53, 73.29 examples/s]Tokenizing train dataset:  56%|█████▌    | 4760/8564 [00:57<00:54, 69.27 examples/s]Tokenizing train dataset:  54%|█████▍    | 4651/8564 [00:57<00:42, 92.58 examples/s]Tokenizing train dataset:  55%|█████▍    | 4686/8564 [00:58<00:51, 75.72 examples/s]Tokenizing train dataset:  56%|█████▌    | 4770/8564 [00:57<00:52, 72.90 examples/s]Tokenizing train dataset:  54%|█████▍    | 4661/8564 [00:57<00:43, 88.96 examples/s]Tokenizing train dataset:  56%|█████▌    | 4783/8564 [00:57<00:44, 85.65 examples/s]Tokenizing train dataset:  55%|█████▍    | 4672/8564 [00:58<00:44, 88.35 examples/s]Tokenizing train dataset:  55%|█████▍    | 4698/8564 [00:58<00:56, 68.02 examples/s]Tokenizing train dataset:  56%|█████▌    | 4800/8564 [00:57<00:36, 104.50 examples/s]Tokenizing train dataset:  56%|█████▌    | 4813/8564 [00:58<00:33, 111.06 examples/s]Tokenizing train dataset:  55%|█████▌    | 4711/8564 [00:58<00:54, 71.13 examples/s]Tokenizing train dataset:  55%|█████▍    | 4684/8564 [00:58<00:49, 77.63 examples/s]Tokenizing train dataset:  57%|█████▋    | 4840/8564 [00:58<00:26, 142.24 examples/s]Tokenizing train dataset:  55%|█████▌    | 4720/8564 [00:58<00:53, 71.56 examples/s]Tokenizing train dataset:  55%|█████▍    | 4693/8564 [00:58<00:55, 70.20 examples/s]Tokenizing train dataset:  57%|█████▋    | 4872/8564 [00:58<00:19, 188.35 examples/s]Tokenizing train dataset:  55%|█████▌    | 4734/8564 [00:59<00:44, 85.60 examples/s]Tokenizing train dataset:  55%|█████▍    | 4701/8564 [00:58<00:55, 69.46 examples/s]Tokenizing train dataset:  55%|█████▌    | 4711/8564 [00:58<00:51, 75.23 examples/s]Tokenizing train dataset:  55%|█████▌    | 4749/8564 [00:59<00:48, 78.27 examples/s]Tokenizing train dataset:  57%|█████▋    | 4896/8564 [00:58<00:24, 148.45 examples/s]Tokenizing train dataset:  55%|█████▌    | 4720/8564 [00:58<00:49, 78.08 examples/s]Tokenizing train dataset:  56%|█████▌    | 4758/8564 [00:59<00:47, 79.81 examples/s]Tokenizing train dataset:  58%|█████▊    | 4926/8564 [00:58<00:24, 149.35 examples/s]Tokenizing train dataset:  55%|█████▌    | 4735/8564 [00:58<00:47, 80.98 examples/s]Tokenizing train dataset:  56%|█████▌    | 4769/8564 [00:59<00:50, 74.52 examples/s]Tokenizing train dataset:  58%|█████▊    | 4949/8564 [00:58<00:27, 131.26 examples/s]Tokenizing train dataset:  56%|█████▌    | 4778/8564 [00:59<00:57, 66.35 examples/s]Tokenizing train dataset:  55%|█████▌    | 4747/8564 [00:59<00:56, 67.58 examples/s]Tokenizing train dataset:  58%|█████▊    | 4965/8564 [00:59<00:27, 132.91 examples/s]Tokenizing train dataset:  56%|█████▌    | 4788/8564 [00:59<00:52, 71.43 examples/s]Tokenizing train dataset:  58%|█████▊    | 4980/8564 [00:59<00:26, 133.87 examples/s]Tokenizing train dataset:  56%|█████▌    | 4759/8564 [00:59<00:54, 69.60 examples/s]Tokenizing train dataset:  56%|█████▌    | 4798/8564 [01:00<00:55, 68.10 examples/s]Tokenizing train dataset:  56%|█████▌    | 4768/8564 [00:59<00:52, 71.89 examples/s]Tokenizing train dataset:  58%|█████▊    | 5000/8564 [00:59<00:27, 128.11 examples/s]Tokenizing train dataset:  56%|█████▌    | 4813/8564 [01:00<00:46, 80.22 examples/s]Tokenizing train dataset:  56%|█████▌    | 4778/8564 [00:59<00:49, 76.64 examples/s]Tokenizing train dataset:  59%|█████▊    | 5016/8564 [00:59<00:27, 128.39 examples/s]Tokenizing train dataset:  56%|█████▋    | 4832/8564 [01:00<00:36, 103.35 examples/s]Tokenizing train dataset:  56%|█████▌    | 4793/8564 [00:59<00:47, 79.81 examples/s]Tokenizing train dataset:  59%|█████▊    | 5031/8564 [00:59<00:27, 127.09 examples/s]Tokenizing train dataset:  57%|█████▋    | 4854/8564 [01:00<00:28, 128.84 examples/s]Tokenizing train dataset:  56%|█████▌    | 4802/8564 [00:59<00:46, 81.45 examples/s]Tokenizing train dataset:  59%|█████▉    | 5048/8564 [00:59<00:27, 129.23 examples/s]Tokenizing train dataset:  57%|█████▋    | 4875/8564 [01:00<00:25, 142.13 examples/s]Tokenizing train dataset:  56%|█████▋    | 4821/8564 [00:59<00:36, 103.23 examples/s]Tokenizing train dataset:  57%|█████▋    | 4892/8564 [01:00<00:25, 144.30 examples/s]Tokenizing train dataset:  59%|█████▉    | 5068/8564 [00:59<00:25, 136.03 examples/s]Tokenizing train dataset:  57%|█████▋    | 4849/8564 [01:00<00:26, 141.63 examples/s]Tokenizing train dataset:  57%|█████▋    | 4912/8564 [01:00<00:24, 150.52 examples/s]Tokenizing train dataset:  59%|█████▉    | 5083/8564 [00:59<00:26, 131.45 examples/s]Tokenizing train dataset:  57%|█████▋    | 4865/8564 [01:00<00:26, 140.14 examples/s]Tokenizing train dataset:  58%|█████▊    | 4935/8564 [01:00<00:21, 168.43 examples/s]Tokenizing train dataset:  60%|█████▉    | 5107/8564 [01:00<00:25, 135.06 examples/s]Tokenizing train dataset:  57%|█████▋    | 4887/8564 [01:00<00:26, 138.99 examples/s]Tokenizing train dataset:  58%|█████▊    | 4956/8564 [01:01<00:24, 148.68 examples/s]Tokenizing train dataset:  60%|█████▉    | 5134/8564 [01:00<00:23, 148.37 examples/s]Tokenizing train dataset:  57%|█████▋    | 4902/8564 [01:00<00:26, 137.87 examples/s]Tokenizing train dataset:  60%|██████    | 5168/8564 [01:00<00:17, 191.60 examples/s]Tokenizing train dataset:  57%|█████▋    | 4916/8564 [01:00<00:29, 121.71 examples/s]Tokenizing train dataset:  58%|█████▊    | 4982/8564 [01:01<00:26, 134.37 examples/s]Tokenizing train dataset:  58%|█████▊    | 4937/8564 [01:00<00:25, 142.42 examples/s]Tokenizing train dataset:  61%|██████    | 5200/8564 [01:00<00:17, 188.43 examples/s]Tokenizing train dataset:  58%|█████▊    | 5001/8564 [01:01<00:28, 126.38 examples/s]Tokenizing train dataset:  61%|██████    | 5221/8564 [01:00<00:17, 188.39 examples/s]Tokenizing train dataset:  58%|█████▊    | 4961/8564 [01:00<00:22, 156.70 examples/s]Tokenizing train dataset:  59%|█████▊    | 5020/8564 [01:01<00:26, 132.34 examples/s]Tokenizing train dataset:  61%|██████    | 5243/8564 [01:00<00:17, 187.93 examples/s]Tokenizing train dataset:  58%|█████▊    | 4984/8564 [01:01<00:26, 135.08 examples/s]Tokenizing train dataset:  62%|██████▏   | 5270/8564 [01:00<00:16, 200.53 examples/s]Tokenizing train dataset:  59%|█████▉    | 5049/8564 [01:01<00:26, 133.02 examples/s]Tokenizing train dataset:  59%|█████▉    | 5065/8564 [01:01<00:25, 137.81 examples/s]Tokenizing train dataset:  58%|█████▊    | 5004/8564 [01:01<00:28, 123.15 examples/s]Tokenizing train dataset:  62%|██████▏   | 5299/8564 [01:01<00:18, 172.38 examples/s]Tokenizing train dataset:  59%|█████▉    | 5085/8564 [01:02<00:23, 145.79 examples/s]Tokenizing train dataset:  59%|█████▊    | 5026/8564 [01:01<00:28, 124.86 examples/s]Tokenizing train dataset:  62%|██████▏   | 5318/8564 [01:01<00:20, 156.00 examples/s]Tokenizing train dataset:  60%|█████▉    | 5104/8564 [01:02<00:23, 148.71 examples/s]Tokenizing train dataset:  59%|█████▉    | 5042/8564 [01:01<00:27, 129.60 examples/s]Tokenizing train dataset:  59%|█████▉    | 5068/8564 [01:01<00:22, 157.72 examples/s]Tokenizing train dataset:  62%|██████▏   | 5341/8564 [01:01<00:23, 136.62 examples/s]Tokenizing train dataset:  60%|█████▉    | 5120/8564 [01:02<00:27, 126.13 examples/s]Tokenizing train dataset:  59%|█████▉    | 5090/8564 [01:01<00:20, 170.58 examples/s]Tokenizing train dataset:  60%|█████▉    | 5135/8564 [01:02<00:27, 125.37 examples/s]Tokenizing train dataset:  63%|██████▎   | 5363/8564 [01:01<00:24, 133.26 examples/s]Tokenizing train dataset:  60%|█████▉    | 5115/8564 [01:01<00:20, 164.65 examples/s]Tokenizing train dataset:  60%|██████    | 5157/8564 [01:02<00:23, 142.76 examples/s]Tokenizing train dataset:  63%|██████▎   | 5384/8564 [01:01<00:22, 140.29 examples/s]Tokenizing train dataset:  60%|██████    | 5143/8564 [01:02<00:18, 182.99 examples/s]Tokenizing train dataset:  60%|██████    | 5174/8564 [01:02<00:23, 141.57 examples/s]Tokenizing train dataset:  63%|██████▎   | 5402/8564 [01:01<00:21, 145.76 examples/s]Tokenizing train dataset:  63%|██████▎   | 5418/8564 [01:02<00:21, 147.90 examples/s]Tokenizing train dataset:  60%|██████    | 5171/8564 [01:02<00:18, 180.37 examples/s]Tokenizing train dataset:  61%|██████    | 5206/8564 [01:02<00:22, 148.40 examples/s]Tokenizing train dataset:  64%|██████▎   | 5453/8564 [01:02<00:16, 191.30 examples/s]Tokenizing train dataset:  61%|██████    | 5191/8564 [01:02<00:21, 156.77 examples/s]Tokenizing train dataset:  61%|██████    | 5236/8564 [01:02<00:18, 176.89 examples/s]Tokenizing train dataset:  61%|██████▏   | 5258/8564 [01:03<00:18, 180.44 examples/s]Tokenizing train dataset:  61%|██████    | 5209/8564 [01:02<00:22, 150.55 examples/s]Tokenizing train dataset:  64%|██████▍   | 5490/8564 [01:02<00:17, 176.96 examples/s]Tokenizing train dataset:  62%|██████▏   | 5282/8564 [01:03<00:18, 178.04 examples/s]Tokenizing train dataset:  61%|██████    | 5230/8564 [01:02<00:21, 152.51 examples/s]Tokenizing train dataset:  64%|██████▍   | 5510/8564 [01:02<00:19, 157.33 examples/s]Tokenizing train dataset:  62%|██████▏   | 5303/8564 [01:03<00:17, 181.88 examples/s]Tokenizing train dataset:  61%|██████▏   | 5251/8564 [01:02<00:20, 163.72 examples/s]Tokenizing train dataset:  65%|██████▍   | 5530/8564 [01:02<00:19, 153.70 examples/s]Tokenizing train dataset:  62%|██████▏   | 5276/8564 [01:02<00:17, 184.61 examples/s]Tokenizing train dataset:  62%|██████▏   | 5324/8564 [01:03<00:22, 145.93 examples/s]Tokenizing train dataset:  65%|██████▍   | 5549/8564 [01:02<00:21, 141.36 examples/s]Tokenizing train dataset:  62%|██████▏   | 5300/8564 [01:02<00:19, 164.09 examples/s]Tokenizing train dataset:  62%|██████▏   | 5340/8564 [01:03<00:22, 144.35 examples/s]Tokenizing train dataset:  65%|██████▍   | 5564/8564 [01:03<00:24, 123.26 examples/s]Tokenizing train dataset:  62%|██████▏   | 5320/8564 [01:03<00:21, 151.31 examples/s]Tokenizing train dataset:  63%|██████▎   | 5360/8564 [01:03<00:23, 139.04 examples/s]Tokenizing train dataset:  65%|██████▌   | 5585/8564 [01:03<00:21, 137.11 examples/s]Tokenizing train dataset:  62%|██████▏   | 5341/8564 [01:03<00:22, 143.26 examples/s]Tokenizing train dataset:  63%|██████▎   | 5375/8564 [01:03<00:25, 125.80 examples/s]Tokenizing train dataset:  66%|██████▌   | 5610/8564 [01:03<00:18, 160.25 examples/s]Tokenizing train dataset:  63%|██████▎   | 5359/8564 [01:03<00:21, 149.51 examples/s]Tokenizing train dataset:  66%|██████▌   | 5631/8564 [01:03<00:17, 169.59 examples/s]Tokenizing train dataset:  63%|██████▎   | 5394/8564 [01:04<00:28, 113.05 examples/s]Tokenizing train dataset:  63%|██████▎   | 5375/8564 [01:03<00:21, 145.49 examples/s]Tokenizing train dataset:  66%|██████▌   | 5661/8564 [01:03<00:14, 194.69 examples/s]Tokenizing train dataset:  63%|██████▎   | 5392/8564 [01:03<00:21, 148.03 examples/s]Tokenizing train dataset:  63%|██████▎   | 5408/8564 [01:04<00:27, 113.63 examples/s]Tokenizing train dataset:  63%|██████▎   | 5410/8564 [01:03<00:20, 152.17 examples/s]Tokenizing train dataset:  66%|██████▋   | 5691/8564 [01:03<00:15, 187.58 examples/s]Tokenizing train dataset:  63%|██████▎   | 5430/8564 [01:04<00:23, 132.88 examples/s]Tokenizing train dataset:  64%|██████▎   | 5443/8564 [01:03<00:17, 178.58 examples/s]Tokenizing train dataset:  64%|██████▎   | 5450/8564 [01:04<00:23, 134.30 examples/s]Tokenizing train dataset:  67%|██████▋   | 5724/8564 [01:03<00:14, 194.56 examples/s]Tokenizing train dataset:  64%|██████▍   | 5461/8564 [01:04<00:19, 159.94 examples/s]Tokenizing train dataset:  64%|██████▍   | 5465/8564 [01:04<00:27, 112.99 examples/s]Tokenizing train dataset:  67%|██████▋   | 5747/8564 [01:03<00:17, 164.52 examples/s]Tokenizing train dataset:  64%|██████▍   | 5480/8564 [01:04<00:25, 118.73 examples/s]Tokenizing train dataset:  67%|██████▋   | 5765/8564 [01:04<00:16, 166.22 examples/s]Tokenizing train dataset:  64%|██████▍   | 5483/8564 [01:04<00:22, 135.69 examples/s]Tokenizing train dataset:  64%|██████▍   | 5500/8564 [01:05<00:23, 130.52 examples/s]Tokenizing train dataset:  68%|██████▊   | 5789/8564 [01:04<00:16, 166.22 examples/s]Tokenizing train dataset:  64%|██████▍   | 5500/8564 [01:04<00:22, 138.87 examples/s]Tokenizing train dataset:  64%|██████▍   | 5520/8564 [01:05<00:21, 143.55 examples/s]Tokenizing train dataset:  64%|██████▍   | 5515/8564 [01:04<00:22, 136.14 examples/s]Tokenizing train dataset:  68%|██████▊   | 5810/8564 [01:04<00:16, 162.89 examples/s]Tokenizing train dataset:  65%|██████▍   | 5537/8564 [01:05<00:20, 148.53 examples/s]Tokenizing train dataset:  68%|██████▊   | 5830/8564 [01:04<00:18, 148.67 examples/s]Tokenizing train dataset:  65%|██████▍   | 5533/8564 [01:04<00:24, 121.45 examples/s]Tokenizing train dataset:  65%|██████▍   | 5562/8564 [01:05<00:21, 136.52 examples/s]Tokenizing train dataset:  68%|██████▊   | 5846/8564 [01:04<00:18, 149.92 examples/s]Tokenizing train dataset:  65%|██████▍   | 5549/8564 [01:04<00:25, 119.02 examples/s]Tokenizing train dataset:  65%|██████▌   | 5580/8564 [01:05<00:21, 137.49 examples/s]Tokenizing train dataset:  68%|██████▊   | 5863/8564 [01:04<00:19, 139.04 examples/s]Tokenizing train dataset:  65%|██████▍   | 5564/8564 [01:04<00:26, 115.22 examples/s]Tokenizing train dataset:  65%|██████▌   | 5600/8564 [01:05<00:21, 139.29 examples/s]Tokenizing train dataset:  69%|██████▊   | 5884/8564 [01:04<00:19, 135.76 examples/s]Tokenizing train dataset:  65%|██████▌   | 5581/8564 [01:05<00:24, 121.79 examples/s]Tokenizing train dataset:  66%|██████▌   | 5621/8564 [01:05<00:20, 141.34 examples/s]Tokenizing train dataset:  69%|██████▉   | 5904/8564 [01:05<00:18, 147.08 examples/s]Tokenizing train dataset:  65%|██████▌   | 5598/8564 [01:05<00:22, 130.23 examples/s]Tokenizing train dataset:  66%|██████▌   | 5642/8564 [01:05<00:19, 147.83 examples/s]Tokenizing train dataset:  69%|██████▉   | 5925/8564 [01:05<00:16, 156.83 examples/s]Tokenizing train dataset:  66%|██████▌   | 5616/8564 [01:05<00:21, 137.65 examples/s]Tokenizing train dataset:  66%|██████▌   | 5660/8564 [01:06<00:19, 151.15 examples/s]Tokenizing train dataset:  69%|██████▉   | 5944/8564 [01:05<00:16, 161.21 examples/s]Tokenizing train dataset:  66%|██████▌   | 5635/8564 [01:05<00:20, 145.64 examples/s]Tokenizing train dataset:  66%|██████▋   | 5683/8564 [01:06<00:17, 163.94 examples/s]Tokenizing train dataset:  70%|██████▉   | 5962/8564 [01:05<00:16, 153.46 examples/s]Tokenizing train dataset:  66%|██████▌   | 5659/8564 [01:05<00:19, 152.18 examples/s]Tokenizing train dataset:  67%|██████▋   | 5704/8564 [01:06<00:16, 171.73 examples/s]Tokenizing train dataset:  66%|██████▋   | 5680/8564 [01:05<00:17, 161.97 examples/s]Tokenizing train dataset:  67%|██████▋   | 5725/8564 [01:06<00:15, 180.46 examples/s]Tokenizing train dataset:  67%|██████▋   | 5706/8564 [01:05<00:15, 186.60 examples/s]Tokenizing train dataset:  67%|██████▋   | 5754/8564 [01:06<00:15, 178.99 examples/s]Tokenizing train dataset:  67%|██████▋   | 5734/8564 [01:05<00:15, 186.10 examples/s]Tokenizing train dataset:  67%|██████▋   | 5773/8564 [01:06<00:15, 175.71 examples/s]Tokenizing train dataset:  67%|██████▋   | 5768/8564 [01:06<00:14, 187.29 examples/s]Tokenizing train dataset:  68%|██████▊   | 5791/8564 [01:06<00:15, 175.86 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [01:05<00:36, 70.87 examples/s] Tokenizing train dataset:  70%|███████   | 5998/8564 [01:06<00:30, 84.81 examples/s]Tokenizing train dataset:  68%|██████▊   | 5796/8564 [01:06<00:15, 181.95 examples/s]Tokenizing train dataset:  68%|██████▊   | 5817/8564 [01:06<00:15, 172.31 examples/s]Tokenizing train dataset:  70%|███████   | 6016/8564 [01:06<00:25, 99.46 examples/s]Tokenizing train dataset:  68%|██████▊   | 5824/8564 [01:06<00:14, 191.90 examples/s]Tokenizing train dataset:  68%|██████▊   | 5838/8564 [01:07<00:18, 147.23 examples/s]Tokenizing train dataset:  68%|██████▊   | 5852/8564 [01:06<00:14, 182.36 examples/s]Tokenizing train dataset:  71%|███████   | 6048/8564 [01:06<00:23, 107.35 examples/s]Tokenizing train dataset:  68%|██████▊   | 5863/8564 [01:07<00:21, 127.28 examples/s]Tokenizing train dataset:  71%|███████   | 6070/8564 [01:06<00:19, 125.06 examples/s]Tokenizing train dataset:  69%|██████▊   | 5880/8564 [01:06<00:14, 178.96 examples/s]Tokenizing train dataset:  69%|██████▊   | 5879/8564 [01:07<00:20, 131.29 examples/s]Tokenizing train dataset:  71%|███████   | 6091/8564 [01:06<00:19, 125.65 examples/s]Tokenizing train dataset:  69%|██████▉   | 5904/8564 [01:06<00:16, 163.15 examples/s]Tokenizing train dataset:  69%|██████▉   | 5900/8564 [01:07<00:18, 147.38 examples/s]Tokenizing train dataset:  71%|███████▏  | 6121/8564 [01:06<00:15, 159.71 examples/s]Tokenizing train dataset:  69%|██████▉   | 5920/8564 [01:07<00:17, 148.44 examples/s]Tokenizing train dataset:  69%|██████▉   | 5923/8564 [01:07<00:17, 150.65 examples/s]Tokenizing train dataset:  72%|███████▏  | 6146/8564 [01:06<00:13, 178.06 examples/s]Tokenizing train dataset:  69%|██████▉   | 5944/8564 [01:07<00:15, 167.16 examples/s]Tokenizing train dataset:  72%|███████▏  | 6171/8564 [01:07<00:12, 184.76 examples/s]Tokenizing train dataset:  69%|██████▉   | 5949/8564 [01:07<00:17, 149.97 examples/s]Tokenizing train dataset:  70%|██████▉   | 5967/8564 [01:07<00:14, 180.12 examples/s]Tokenizing train dataset:  72%|███████▏  | 6207/8564 [01:07<00:10, 222.06 examples/s]Tokenizing train dataset:  70%|██████▉   | 5967/8564 [01:07<00:18, 140.67 examples/s]Tokenizing train dataset:  73%|███████▎  | 6239/8564 [01:07<00:10, 216.54 examples/s]Tokenizing train dataset:  70%|██████▉   | 5994/8564 [01:08<00:20, 127.20 examples/s]Tokenizing train dataset:  73%|███████▎  | 6269/8564 [01:07<00:12, 190.54 examples/s]Tokenizing train dataset:  70%|██████▉   | 5986/8564 [01:07<00:23, 107.48 examples/s]Tokenizing train dataset:  70%|███████   | 6018/8564 [01:08<00:17, 144.50 examples/s]Tokenizing train dataset:  70%|███████   | 6004/8564 [01:07<00:22, 113.59 examples/s]Tokenizing train dataset:  74%|███████▎  | 6299/8564 [01:07<00:12, 187.10 examples/s]Tokenizing train dataset:  70%|███████   | 6036/8564 [01:08<00:19, 130.28 examples/s]Tokenizing train dataset:  70%|███████   | 6025/8564 [01:07<00:19, 131.48 examples/s]Tokenizing train dataset:  74%|███████▍  | 6320/8564 [01:07<00:12, 186.36 examples/s]Tokenizing train dataset:  71%|███████   | 6052/8564 [01:08<00:19, 131.81 examples/s]Tokenizing train dataset:  71%|███████   | 6046/8564 [01:08<00:17, 140.90 examples/s]Tokenizing train dataset:  74%|███████▍  | 6345/8564 [01:08<00:13, 168.80 examples/s]Tokenizing train dataset:  71%|███████   | 6064/8564 [01:08<00:16, 149.08 examples/s]Tokenizing train dataset:  71%|███████   | 6074/8564 [01:08<00:19, 124.86 examples/s]Tokenizing train dataset:  74%|███████▍  | 6371/8564 [01:08<00:11, 185.87 examples/s]Tokenizing train dataset:  71%|███████   | 6089/8564 [01:08<00:16, 151.76 examples/s]Tokenizing train dataset:  71%|███████   | 6094/8564 [01:09<00:18, 131.42 examples/s]Tokenizing train dataset:  71%|███████▏  | 6111/8564 [01:09<00:18, 135.90 examples/s]Tokenizing train dataset:  75%|███████▍  | 6398/8564 [01:08<00:13, 158.82 examples/s]Tokenizing train dataset:  71%|███████▏  | 6113/8564 [01:08<00:16, 146.17 examples/s]Tokenizing train dataset:  72%|███████▏  | 6127/8564 [01:09<00:17, 138.41 examples/s]Tokenizing train dataset:  72%|███████▏  | 6129/8564 [01:08<00:16, 145.91 examples/s]Tokenizing train dataset:  75%|███████▍  | 6420/8564 [01:08<00:14, 151.20 examples/s]Tokenizing train dataset:  72%|███████▏  | 6155/8564 [01:09<00:13, 172.13 examples/s]Tokenizing train dataset:  72%|███████▏  | 6155/8564 [01:08<00:16, 143.14 examples/s]Tokenizing train dataset:  75%|███████▌  | 6441/8564 [01:08<00:21, 98.06 examples/s] Tokenizing train dataset:  72%|███████▏  | 6183/8564 [01:09<00:21, 109.45 examples/s]Tokenizing train dataset:  72%|███████▏  | 6180/8564 [01:09<00:20, 114.20 examples/s]Tokenizing train dataset:  75%|███████▌  | 6462/8564 [01:09<00:18, 112.04 examples/s]Tokenizing train dataset:  72%|███████▏  | 6202/8564 [01:09<00:20, 115.37 examples/s]Tokenizing train dataset:  72%|███████▏  | 6199/8564 [01:09<00:20, 116.61 examples/s]Tokenizing train dataset:  73%|███████▎  | 6219/8564 [01:10<00:19, 122.38 examples/s]Tokenizing train dataset:  76%|███████▌  | 6485/8564 [01:09<00:17, 116.85 examples/s]Tokenizing train dataset:  73%|███████▎  | 6215/8564 [01:09<00:18, 123.98 examples/s]Tokenizing train dataset:  73%|███████▎  | 6240/8564 [01:10<00:17, 135.14 examples/s]Tokenizing train dataset:  76%|███████▌  | 6501/8564 [01:09<00:16, 123.24 examples/s]Tokenizing train dataset:  73%|███████▎  | 6232/8564 [01:09<00:18, 127.77 examples/s]Tokenizing train dataset:  73%|███████▎  | 6269/8564 [01:10<00:13, 164.47 examples/s]Tokenizing train dataset:  76%|███████▌  | 6519/8564 [01:09<00:15, 132.82 examples/s]Tokenizing train dataset:  73%|███████▎  | 6252/8564 [01:09<00:16, 137.75 examples/s]Tokenizing train dataset:  76%|███████▋  | 6538/8564 [01:09<00:14, 135.75 examples/s]Tokenizing train dataset:  73%|███████▎  | 6270/8564 [01:09<00:16, 140.84 examples/s]Tokenizing train dataset:  74%|███████▎  | 6295/8564 [01:10<00:14, 160.32 examples/s]Tokenizing train dataset:  73%|███████▎  | 6290/8564 [01:09<00:15, 150.48 examples/s]Tokenizing train dataset:  77%|███████▋  | 6554/8564 [01:09<00:15, 132.24 examples/s]Tokenizing train dataset:  74%|███████▍  | 6317/8564 [01:10<00:13, 172.01 examples/s]Tokenizing train dataset:  74%|███████▍  | 6319/8564 [01:10<00:14, 152.18 examples/s]Tokenizing train dataset:  74%|███████▍  | 6338/8564 [01:10<00:14, 150.31 examples/s]Tokenizing train dataset:  77%|███████▋  | 6579/8564 [01:09<00:15, 127.08 examples/s]Tokenizing train dataset:  74%|███████▍  | 6339/8564 [01:10<00:14, 156.58 examples/s]Tokenizing train dataset:  74%|███████▍  | 6366/8564 [01:10<00:15, 141.85 examples/s]Tokenizing train dataset:  74%|███████▍  | 6371/8564 [01:10<00:11, 183.40 examples/s]Tokenizing train dataset:  77%|███████▋  | 6598/8564 [01:10<00:19, 102.70 examples/s]Tokenizing train dataset:  75%|███████▍  | 6392/8564 [01:10<00:11, 184.18 examples/s]Tokenizing train dataset:  77%|███████▋  | 6611/8564 [01:10<00:18, 105.73 examples/s]Tokenizing train dataset:  75%|███████▍  | 6388/8564 [01:11<00:16, 133.55 examples/s]Tokenizing train dataset:  75%|███████▍  | 6414/8564 [01:10<00:11, 190.91 examples/s]Tokenizing train dataset:  77%|███████▋  | 6630/8564 [01:10<00:17, 108.35 examples/s]Tokenizing train dataset:  75%|███████▍  | 6408/8564 [01:11<00:16, 127.41 examples/s]Tokenizing train dataset:  75%|███████▌  | 6443/8564 [01:10<00:11, 184.15 examples/s]Tokenizing train dataset:  78%|███████▊  | 6650/8564 [01:10<00:16, 119.30 examples/s]Tokenizing train dataset:  75%|███████▌  | 6431/8564 [01:11<00:16, 130.70 examples/s]Tokenizing train dataset:  75%|███████▌  | 6462/8564 [01:10<00:12, 171.55 examples/s]Tokenizing train dataset:  78%|███████▊  | 6668/8564 [01:10<00:15, 123.53 examples/s]Tokenizing train dataset:  75%|███████▌  | 6452/8564 [01:11<00:14, 144.70 examples/s]Tokenizing train dataset:  76%|███████▌  | 6484/8564 [01:10<00:13, 152.51 examples/s]Tokenizing train dataset:  76%|███████▌  | 6471/8564 [01:11<00:14, 148.44 examples/s]Tokenizing train dataset:  78%|███████▊  | 6690/8564 [01:10<00:16, 113.06 examples/s]Tokenizing train dataset:  76%|███████▌  | 6488/8564 [01:11<00:13, 153.14 examples/s]Tokenizing train dataset:  76%|███████▌  | 6501/8564 [01:11<00:15, 133.43 examples/s]Tokenizing train dataset:  78%|███████▊  | 6710/8564 [01:11<00:14, 129.03 examples/s]Tokenizing train dataset:  76%|███████▌  | 6516/8564 [01:11<00:15, 135.06 examples/s]Tokenizing train dataset:  76%|███████▌  | 6507/8564 [01:11<00:14, 142.68 examples/s]Tokenizing train dataset:  79%|███████▊  | 6725/8564 [01:11<00:14, 129.90 examples/s]Tokenizing train dataset:  76%|███████▋  | 6542/8564 [01:11<00:12, 163.74 examples/s]Tokenizing train dataset:  76%|███████▌  | 6530/8564 [01:12<00:13, 150.89 examples/s]Tokenizing train dataset:  79%|███████▊  | 6740/8564 [01:11<00:15, 119.24 examples/s]Tokenizing train dataset:  76%|███████▋  | 6547/8564 [01:12<00:13, 149.11 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [01:11<00:13, 153.17 examples/s]Tokenizing train dataset:  79%|███████▉  | 6759/8564 [01:11<00:14, 128.75 examples/s]Tokenizing train dataset:  77%|███████▋  | 6563/8564 [01:12<00:14, 142.27 examples/s]Tokenizing train dataset:  77%|███████▋  | 6588/8564 [01:11<00:13, 148.96 examples/s]Tokenizing train dataset:  79%|███████▉  | 6775/8564 [01:11<00:13, 130.88 examples/s]Tokenizing train dataset:  79%|███████▉  | 6790/8564 [01:11<00:13, 130.15 examples/s]Tokenizing train dataset:  77%|███████▋  | 6582/8564 [01:12<00:15, 126.28 examples/s]Tokenizing train dataset:  77%|███████▋  | 6607/8564 [01:11<00:13, 141.09 examples/s]Tokenizing train dataset:  80%|███████▉  | 6819/8564 [01:11<00:10, 170.27 examples/s]Tokenizing train dataset:  77%|███████▋  | 6600/8564 [01:12<00:16, 122.01 examples/s]Tokenizing train dataset:  77%|███████▋  | 6623/8564 [01:12<00:15, 127.36 examples/s]Tokenizing train dataset:  80%|███████▉  | 6837/8564 [01:11<00:10, 171.15 examples/s]Tokenizing train dataset:  78%|███████▊  | 6641/8564 [01:12<00:14, 134.87 examples/s]Tokenizing train dataset:  80%|████████  | 6863/8564 [01:12<00:10, 157.68 examples/s]Tokenizing train dataset:  77%|███████▋  | 6619/8564 [01:12<00:18, 107.14 examples/s]Tokenizing train dataset:  78%|███████▊  | 6660/8564 [01:12<00:12, 147.06 examples/s]Tokenizing train dataset:  80%|████████  | 6883/8564 [01:12<00:10, 158.58 examples/s]Tokenizing train dataset:  77%|███████▋  | 6633/8564 [01:13<00:18, 106.30 examples/s]Tokenizing train dataset:  78%|███████▊  | 6677/8564 [01:12<00:13, 140.45 examples/s]Tokenizing train dataset:  78%|███████▊  | 6697/8564 [01:12<00:12, 149.81 examples/s]Tokenizing train dataset:  81%|████████  | 6900/8564 [01:12<00:11, 148.13 examples/s]Tokenizing train dataset:  78%|███████▊  | 6655/8564 [01:13<00:16, 115.19 examples/s]Tokenizing train dataset:  81%|████████  | 6920/8564 [01:12<00:10, 158.70 examples/s]Tokenizing train dataset:  78%|███████▊  | 6717/8564 [01:12<00:11, 156.99 examples/s]Tokenizing train dataset:  78%|███████▊  | 6683/8564 [01:13<00:14, 134.08 examples/s]Tokenizing train dataset:  81%|████████  | 6948/8564 [01:12<00:09, 169.15 examples/s]Tokenizing train dataset:  78%|███████▊  | 6715/8564 [01:13<00:10, 168.49 examples/s]Tokenizing train dataset:  79%|███████▊  | 6744/8564 [01:12<00:13, 133.66 examples/s]Tokenizing train dataset:  79%|███████▊  | 6740/8564 [01:13<00:09, 184.75 examples/s]Tokenizing train dataset:  79%|███████▉  | 6766/8564 [01:12<00:11, 151.59 examples/s]Tokenizing train dataset:  81%|████████▏ | 6970/8564 [01:12<00:10, 147.22 examples/s]Tokenizing train dataset:  82%|████████▏ | 6987/8564 [01:12<00:10, 147.66 examples/s]Tokenizing train dataset:  79%|███████▉  | 6769/8564 [01:13<00:09, 182.32 examples/s]Tokenizing train dataset:  79%|███████▉  | 6789/8564 [01:13<00:12, 143.76 examples/s]Tokenizing train dataset:  82%|████████▏ | 7011/8564 [01:13<00:10, 154.23 examples/s]Tokenizing train dataset:  79%|███████▉  | 6796/8564 [01:13<00:11, 152.76 examples/s]Tokenizing train dataset:  79%|███████▉  | 6806/8564 [01:13<00:15, 115.17 examples/s]Tokenizing train dataset:  82%|████████▏ | 7030/8564 [01:13<00:11, 129.90 examples/s]Tokenizing train dataset:  80%|███████▉  | 6819/8564 [01:14<00:12, 140.69 examples/s]Tokenizing train dataset:  82%|████████▏ | 7046/8564 [01:13<00:11, 133.23 examples/s]Tokenizing train dataset:  80%|███████▉  | 6828/8564 [01:13<00:14, 121.02 examples/s]Tokenizing train dataset:  82%|████████▏ | 7061/8564 [01:13<00:11, 135.07 examples/s]Tokenizing train dataset:  80%|███████▉  | 6836/8564 [01:14<00:12, 140.14 examples/s]Tokenizing train dataset:  80%|███████▉  | 6845/8564 [01:13<00:13, 124.69 examples/s]Tokenizing train dataset:  83%|████████▎ | 7088/8564 [01:13<00:08, 165.44 examples/s]Tokenizing train dataset:  80%|███████▉  | 6851/8564 [01:14<00:14, 119.28 examples/s]Tokenizing train dataset:  80%|████████  | 6870/8564 [01:13<00:14, 118.76 examples/s]Tokenizing train dataset:  83%|████████▎ | 7108/8564 [01:13<00:09, 149.93 examples/s]Tokenizing train dataset:  80%|████████  | 6871/8564 [01:14<00:12, 132.40 examples/s]Tokenizing train dataset:  80%|████████  | 6892/8564 [01:13<00:12, 137.25 examples/s]Tokenizing train dataset:  83%|████████▎ | 7133/8564 [01:13<00:09, 152.02 examples/s]Tokenizing train dataset:  81%|████████  | 6920/8564 [01:14<00:10, 159.06 examples/s]Tokenizing train dataset:  84%|████████▎ | 7151/8564 [01:14<00:09, 150.78 examples/s]Tokenizing train dataset:  81%|████████  | 6898/8564 [01:14<00:12, 135.67 examples/s]Tokenizing train dataset:  81%|████████  | 6948/8564 [01:14<00:09, 178.62 examples/s]Tokenizing train dataset:  84%|████████▎ | 7170/8564 [01:14<00:09, 153.88 examples/s]Tokenizing train dataset:  81%|████████  | 6914/8564 [01:14<00:13, 123.22 examples/s]Tokenizing train dataset:  81%|████████  | 6928/8564 [01:15<00:13, 123.97 examples/s]Tokenizing train dataset:  84%|████████▍ | 7192/8564 [01:14<00:09, 151.43 examples/s]Tokenizing train dataset:  82%|████████▏ | 6982/8564 [01:14<00:09, 169.05 examples/s]Tokenizing train dataset:  81%|████████  | 6948/8564 [01:15<00:12, 127.72 examples/s]Tokenizing train dataset:  84%|████████▍ | 7214/8564 [01:14<00:08, 158.30 examples/s]Tokenizing train dataset:  82%|████████▏ | 7004/8564 [01:14<00:10, 146.36 examples/s]Tokenizing train dataset:  84%|████████▍ | 7233/8564 [01:14<00:09, 147.62 examples/s]Tokenizing train dataset:  81%|████████▏ | 6968/8564 [01:15<00:13, 121.63 examples/s]Tokenizing train dataset:  85%|████████▍ | 7251/8564 [01:14<00:08, 152.45 examples/s]Tokenizing train dataset:  82%|████████▏ | 6989/8564 [01:15<00:11, 133.37 examples/s]Tokenizing train dataset:  82%|████████▏ | 7020/8564 [01:14<00:11, 128.72 examples/s]Tokenizing train dataset:  85%|████████▍ | 7278/8564 [01:14<00:07, 177.75 examples/s]Tokenizing train dataset:  82%|████████▏ | 7040/8564 [01:14<00:10, 138.99 examples/s]Tokenizing train dataset:  82%|████████▏ | 7010/8564 [01:15<00:12, 121.25 examples/s]Tokenizing train dataset:  82%|████████▏ | 7060/8564 [01:15<00:10, 147.57 examples/s]Tokenizing train dataset:  85%|████████▌ | 7300/8564 [01:14<00:08, 154.75 examples/s]Tokenizing train dataset:  83%|████████▎ | 7084/8564 [01:15<00:08, 168.11 examples/s]Tokenizing train dataset:  82%|████████▏ | 7025/8564 [01:15<00:13, 110.49 examples/s]Tokenizing train dataset:  83%|████████▎ | 7104/8564 [01:15<00:08, 173.69 examples/s]Tokenizing train dataset:  85%|████████▌ | 7320/8564 [01:15<00:08, 139.77 examples/s]Tokenizing train dataset:  82%|████████▏ | 7050/8564 [01:16<00:11, 129.15 examples/s]Tokenizing train dataset:  83%|████████▎ | 7130/8564 [01:15<00:07, 187.78 examples/s]Tokenizing train dataset:  86%|████████▌ | 7337/8564 [01:15<00:08, 140.68 examples/s]Tokenizing train dataset:  83%|████████▎ | 7080/8564 [01:16<00:09, 161.71 examples/s]Tokenizing train dataset:  86%|████████▌ | 7352/8564 [01:15<00:08, 141.24 examples/s]Tokenizing train dataset:  84%|████████▎ | 7156/8564 [01:15<00:08, 173.93 examples/s]Tokenizing train dataset:  83%|████████▎ | 7102/8564 [01:16<00:08, 173.01 examples/s]Tokenizing train dataset:  86%|████████▌ | 7371/8564 [01:15<00:08, 147.84 examples/s]Tokenizing train dataset:  84%|████████▍ | 7180/8564 [01:15<00:07, 189.21 examples/s]Tokenizing train dataset:  83%|████████▎ | 7125/8564 [01:16<00:09, 159.21 examples/s]Tokenizing train dataset:  84%|████████▍ | 7201/8564 [01:15<00:07, 185.11 examples/s]Tokenizing train dataset:  86%|████████▋ | 7397/8564 [01:15<00:07, 149.34 examples/s]Tokenizing train dataset:  83%|████████▎ | 7145/8564 [01:16<00:08, 160.02 examples/s]Tokenizing train dataset:  87%|████████▋ | 7420/8564 [01:15<00:07, 159.52 examples/s]Tokenizing train dataset:  84%|████████▍ | 7221/8564 [01:16<00:09, 143.75 examples/s]Tokenizing train dataset:  87%|████████▋ | 7447/8564 [01:15<00:06, 180.22 examples/s]Tokenizing train dataset:  84%|████████▎ | 7170/8564 [01:16<00:10, 136.10 examples/s]Tokenizing train dataset:  87%|████████▋ | 7471/8564 [01:16<00:05, 186.94 examples/s]Tokenizing train dataset:  85%|████████▍ | 7238/8564 [01:16<00:10, 127.13 examples/s]Tokenizing train dataset:  84%|████████▍ | 7190/8564 [01:16<00:09, 139.50 examples/s]Tokenizing train dataset:  85%|████████▍ | 7256/8564 [01:16<00:09, 131.47 examples/s]Tokenizing train dataset:  88%|████████▊ | 7500/8564 [01:16<00:05, 181.01 examples/s]Tokenizing train dataset:  84%|████████▍ | 7211/8564 [01:17<00:09, 147.77 examples/s]Tokenizing train dataset:  85%|████████▍ | 7271/8564 [01:16<00:10, 119.50 examples/s]Tokenizing train dataset:  88%|████████▊ | 7527/8564 [01:16<00:05, 178.39 examples/s]Tokenizing train dataset:  85%|████████▌ | 7291/8564 [01:16<00:09, 136.44 examples/s]Tokenizing train dataset:  85%|████████▍ | 7238/8564 [01:17<00:09, 133.54 examples/s]Tokenizing train dataset:  88%|████████▊ | 7558/8564 [01:16<00:05, 186.26 examples/s]Tokenizing train dataset:  85%|████████▍ | 7257/8564 [01:17<00:09, 143.04 examples/s]Tokenizing train dataset:  85%|████████▌ | 7310/8564 [01:16<00:09, 129.77 examples/s]Tokenizing train dataset:  89%|████████▊ | 7581/8564 [01:16<00:05, 194.83 examples/s]Tokenizing train dataset:  85%|████████▌ | 7280/8564 [01:17<00:08, 158.52 examples/s]Tokenizing train dataset:  86%|████████▌ | 7330/8564 [01:16<00:08, 138.97 examples/s]Tokenizing train dataset:  85%|████████▌ | 7298/8564 [01:17<00:07, 162.07 examples/s]Tokenizing train dataset:  89%|████████▉ | 7610/8564 [01:16<00:05, 175.22 examples/s]Tokenizing train dataset:  86%|████████▌ | 7351/8564 [01:17<00:08, 136.12 examples/s]Tokenizing train dataset:  89%|████████▉ | 7630/8564 [01:16<00:05, 171.87 examples/s]Tokenizing train dataset:  86%|████████▌ | 7330/8564 [01:17<00:07, 174.07 examples/s]Tokenizing train dataset:  86%|████████▌ | 7377/8564 [01:17<00:07, 151.55 examples/s]Tokenizing train dataset:  86%|████████▌ | 7350/8564 [01:17<00:06, 176.47 examples/s]Tokenizing train dataset:  89%|████████▉ | 7651/8564 [01:17<00:05, 159.91 examples/s]Tokenizing train dataset:  86%|████████▋ | 7401/8564 [01:17<00:06, 171.29 examples/s]Tokenizing train dataset:  86%|████████▌ | 7369/8564 [01:18<00:07, 167.66 examples/s]Tokenizing train dataset:  87%|████████▋ | 7419/8564 [01:17<00:06, 171.07 examples/s]Tokenizing train dataset:  90%|████████▉ | 7668/8564 [01:17<00:06, 133.38 examples/s]Tokenizing train dataset:  87%|████████▋ | 7445/8564 [01:17<00:06, 178.22 examples/s]Tokenizing train dataset:  86%|████████▋ | 7393/8564 [01:18<00:07, 153.74 examples/s]Tokenizing train dataset:  90%|████████▉ | 7691/8564 [01:17<00:06, 125.98 examples/s]Tokenizing train dataset:  87%|████████▋ | 7465/8564 [01:17<00:06, 173.81 examples/s]Tokenizing train dataset:  87%|████████▋ | 7414/8564 [01:18<00:07, 162.90 examples/s]Tokenizing train dataset:  90%|█████████ | 7720/8564 [01:17<00:05, 152.46 examples/s]Tokenizing train dataset:  87%|████████▋ | 7443/8564 [01:18<00:06, 167.36 examples/s]Tokenizing train dataset:  87%|████████▋ | 7485/8564 [01:17<00:07, 148.18 examples/s]Tokenizing train dataset:  90%|█████████ | 7742/8564 [01:17<00:05, 160.19 examples/s]Tokenizing train dataset:  87%|████████▋ | 7471/8564 [01:18<00:05, 191.94 examples/s]Tokenizing train dataset:  88%|████████▊ | 7501/8564 [01:17<00:07, 143.78 examples/s]Tokenizing train dataset:  91%|█████████ | 7767/8564 [01:17<00:04, 161.46 examples/s]Tokenizing train dataset:  88%|████████▊ | 7495/8564 [01:18<00:05, 179.64 examples/s]Tokenizing train dataset:  88%|████████▊ | 7520/8564 [01:18<00:08, 128.60 examples/s]Tokenizing train dataset:  91%|█████████ | 7786/8564 [01:17<00:04, 158.00 examples/s]Tokenizing train dataset:  88%|████████▊ | 7538/8564 [01:18<00:07, 135.21 examples/s]Tokenizing train dataset:  88%|████████▊ | 7517/8564 [01:18<00:07, 140.20 examples/s]Tokenizing train dataset:  88%|████████▊ | 7575/8564 [01:18<00:05, 188.97 examples/s]Tokenizing train dataset:  91%|█████████ | 7807/8564 [01:18<00:05, 132.37 examples/s]Tokenizing train dataset:  88%|████████▊ | 7541/8564 [01:19<00:06, 159.75 examples/s]Tokenizing train dataset:  91%|█████████▏| 7823/8564 [01:18<00:06, 111.65 examples/s]Tokenizing train dataset:  89%|████████▉ | 7603/8564 [01:18<00:06, 151.52 examples/s]Tokenizing train dataset:  89%|████████▊ | 7580/8564 [01:19<00:06, 157.50 examples/s]Tokenizing train dataset:  92%|█████████▏| 7841/8564 [01:18<00:05, 121.32 examples/s]Tokenizing train dataset:  89%|████████▊ | 7599/8564 [01:19<00:06, 158.15 examples/s]Tokenizing train dataset:  89%|████████▉ | 7627/8564 [01:18<00:06, 153.17 examples/s]Tokenizing train dataset:  92%|█████████▏| 7861/8564 [01:18<00:05, 131.01 examples/s]Tokenizing train dataset:  89%|████████▉ | 7624/8564 [01:19<00:05, 176.02 examples/s]Tokenizing train dataset:  89%|████████▉ | 7650/8564 [01:18<00:06, 134.07 examples/s]Tokenizing train dataset:  92%|█████████▏| 7880/8564 [01:18<00:05, 126.50 examples/s]Tokenizing train dataset:  89%|████████▉ | 7644/8564 [01:19<00:06, 140.80 examples/s]Tokenizing train dataset:  92%|█████████▏| 7900/8564 [01:18<00:04, 135.02 examples/s]Tokenizing train dataset:  90%|████████▉ | 7670/8564 [01:19<00:06, 129.92 examples/s]Tokenizing train dataset:  93%|█████████▎| 7925/8564 [01:19<00:04, 136.88 examples/s]Tokenizing train dataset:  90%|████████▉ | 7665/8564 [01:19<00:07, 123.06 examples/s]Tokenizing train dataset:  90%|████████▉ | 7689/8564 [01:19<00:07, 122.45 examples/s]Tokenizing train dataset:  90%|████████▉ | 7703/8564 [01:19<00:07, 119.95 examples/s]Tokenizing train dataset:  90%|████████▉ | 7690/8564 [01:20<00:06, 140.78 examples/s]Tokenizing train dataset:  93%|█████████▎| 7947/8564 [01:19<00:04, 134.18 examples/s]Tokenizing train dataset:  90%|█████████ | 7719/8564 [01:19<00:06, 127.84 examples/s]Tokenizing train dataset:  93%|█████████▎| 7964/8564 [01:19<00:04, 130.16 examples/s]Tokenizing train dataset:  90%|█████████ | 7716/8564 [01:20<00:05, 148.92 examples/s]Tokenizing train dataset:  93%|█████████▎| 7987/8564 [01:19<00:03, 149.52 examples/s]Tokenizing train dataset:  90%|█████████ | 7742/8564 [01:19<00:06, 125.86 examples/s]Tokenizing train dataset:  90%|█████████ | 7741/8564 [01:20<00:05, 148.03 examples/s]Tokenizing train dataset:  93%|█████████▎| 8005/8564 [01:19<00:03, 150.48 examples/s]Tokenizing train dataset:  91%|█████████ | 7762/8564 [01:19<00:06, 122.35 examples/s]Tokenizing train dataset:  91%|█████████ | 7762/8564 [01:20<00:05, 143.33 examples/s]Tokenizing train dataset:  94%|█████████▍| 8029/8564 [01:19<00:03, 144.34 examples/s]Tokenizing train dataset:  91%|█████████ | 7781/8564 [01:20<00:06, 119.56 examples/s]Tokenizing train dataset:  94%|█████████▍| 8045/8564 [01:19<00:03, 146.82 examples/s]Tokenizing train dataset:  91%|█████████ | 7780/8564 [01:20<00:06, 130.63 examples/s]Tokenizing train dataset:  91%|█████████ | 7794/8564 [01:20<00:07, 109.38 examples/s]Tokenizing train dataset:  94%|█████████▍| 8068/8564 [01:20<00:03, 140.31 examples/s]Tokenizing train dataset:  91%|█████████ | 7798/8564 [01:20<00:06, 121.30 examples/s]Tokenizing train dataset:  91%|█████████ | 7810/8564 [01:20<00:06, 116.27 examples/s]Tokenizing train dataset:  94%|█████████▍| 8083/8564 [01:20<00:03, 139.24 examples/s]Tokenizing train dataset:  91%|█████████▏| 7832/8564 [01:20<00:05, 132.96 examples/s]Tokenizing train dataset:  91%|█████████▏| 7820/8564 [01:21<00:06, 120.94 examples/s]Tokenizing train dataset:  95%|█████████▍| 8103/8564 [01:20<00:03, 152.98 examples/s]Tokenizing train dataset:  92%|█████████▏| 7857/8564 [01:20<00:04, 155.20 examples/s]Tokenizing train dataset:  91%|█████████▏| 7833/8564 [01:21<00:06, 118.64 examples/s]Tokenizing train dataset:  95%|█████████▍| 8123/8564 [01:20<00:02, 162.85 examples/s]Tokenizing train dataset:  92%|█████████▏| 7854/8564 [01:21<00:05, 132.51 examples/s]Tokenizing train dataset:  92%|█████████▏| 7879/8564 [01:20<00:04, 148.39 examples/s]Tokenizing train dataset:  95%|█████████▌| 8148/8564 [01:20<00:02, 154.31 examples/s]Tokenizing train dataset:  92%|█████████▏| 7900/8564 [01:20<00:04, 152.21 examples/s]Tokenizing train dataset:  95%|█████████▌| 8169/8564 [01:20<00:02, 162.59 examples/s]Tokenizing train dataset:  92%|█████████▏| 7879/8564 [01:21<00:05, 122.78 examples/s]Tokenizing train dataset:  96%|█████████▌| 8197/8564 [01:20<00:01, 190.78 examples/s]Tokenizing train dataset:  93%|█████████▎| 7937/8564 [01:21<00:03, 173.56 examples/s]Tokenizing train dataset:  92%|█████████▏| 7897/8564 [01:21<00:05, 111.56 examples/s]Tokenizing train dataset:  93%|█████████▎| 7961/8564 [01:21<00:03, 151.90 examples/s]Tokenizing train dataset:  96%|█████████▌| 8225/8564 [01:21<00:02, 144.99 examples/s]Tokenizing train dataset:  92%|█████████▏| 7915/8564 [01:21<00:05, 119.15 examples/s]Tokenizing train dataset:  93%|█████████▎| 7928/8564 [01:22<00:05, 117.43 examples/s]Tokenizing train dataset:  96%|█████████▋| 8248/8564 [01:21<00:01, 158.68 examples/s]Tokenizing train dataset:  93%|█████████▎| 7983/8564 [01:21<00:03, 154.57 examples/s]Tokenizing train dataset:  97%|█████████▋| 8269/8564 [01:21<00:01, 167.63 examples/s]Tokenizing train dataset:  93%|█████████▎| 7999/8564 [01:21<00:04, 139.62 examples/s]Tokenizing train dataset:  93%|█████████▎| 7951/8564 [01:22<00:05, 121.64 examples/s]Tokenizing train dataset:  97%|█████████▋| 8290/8564 [01:21<00:01, 172.59 examples/s]Tokenizing train dataset:  94%|█████████▎| 8019/8564 [01:21<00:03, 146.04 examples/s]Tokenizing train dataset:  93%|█████████▎| 7970/8564 [01:22<00:04, 133.12 examples/s]Tokenizing train dataset:  97%|█████████▋| 8318/8564 [01:21<00:01, 193.86 examples/s]Tokenizing train dataset:  93%|█████████▎| 7988/8564 [01:22<00:04, 139.64 examples/s]Tokenizing train dataset:  94%|█████████▍| 8041/8564 [01:21<00:03, 138.24 examples/s]Tokenizing train dataset:  94%|█████████▎| 8010/8564 [01:22<00:03, 157.52 examples/s]Tokenizing train dataset:  97%|█████████▋| 8341/8564 [01:21<00:01, 169.71 examples/s]Tokenizing train dataset:  94%|█████████▍| 8062/8564 [01:21<00:03, 144.05 examples/s]Tokenizing train dataset:  94%|█████████▍| 8036/8564 [01:22<00:03, 139.28 examples/s]Tokenizing train dataset:  94%|█████████▍| 8080/8564 [01:22<00:03, 121.47 examples/s]Tokenizing train dataset:  94%|█████████▍| 8055/8564 [01:22<00:03, 147.66 examples/s]Tokenizing train dataset:  98%|█████████▊| 8361/8564 [01:22<00:01, 112.89 examples/s]Tokenizing train dataset:  98%|█████████▊| 8384/8564 [01:22<00:01, 133.26 examples/s]Tokenizing train dataset:  95%|█████████▍| 8094/8564 [01:22<00:04, 108.35 examples/s]Tokenizing train dataset:  94%|█████████▍| 8082/8564 [01:23<00:03, 148.21 examples/s]Tokenizing train dataset:  95%|█████████▍| 8106/8564 [01:22<00:04, 104.68 examples/s]Tokenizing train dataset:  98%|█████████▊| 8404/8564 [01:22<00:01, 118.69 examples/s]Tokenizing train dataset:  95%|█████████▍| 8107/8564 [01:23<00:03, 151.17 examples/s]Tokenizing train dataset:  95%|█████████▍| 8117/8564 [01:22<00:04, 103.90 examples/s]Tokenizing train dataset:  98%|█████████▊| 8425/8564 [01:22<00:01, 133.97 examples/s]Tokenizing train dataset:  95%|█████████▍| 8130/8564 [01:22<00:04, 106.19 examples/s]Tokenizing train dataset:  95%|█████████▍| 8125/8564 [01:23<00:03, 137.66 examples/s]Tokenizing train dataset:  95%|█████████▌| 8148/8564 [01:22<00:03, 117.51 examples/s]Tokenizing train dataset:  95%|█████████▌| 8146/8564 [01:23<00:02, 149.29 examples/s]Tokenizing train dataset:  99%|█████████▊| 8448/8564 [01:22<00:00, 131.50 examples/s]Tokenizing train dataset:  95%|█████████▌| 8164/8564 [01:23<00:02, 151.73 examples/s]Tokenizing train dataset:  95%|█████████▌| 8161/8564 [01:22<00:03, 112.98 examples/s]Tokenizing train dataset:  99%|█████████▉| 8470/8564 [01:22<00:00, 126.62 examples/s]Tokenizing train dataset:  96%|█████████▌| 8185/8564 [01:23<00:02, 164.55 examples/s]Tokenizing train dataset:  95%|█████████▌| 8176/8564 [01:23<00:03, 120.43 examples/s]Tokenizing train dataset:  99%|█████████▉| 8485/8564 [01:22<00:00, 129.50 examples/s]Tokenizing train dataset:  96%|█████████▌| 8204/8564 [01:23<00:02, 163.82 examples/s]Tokenizing train dataset:  96%|█████████▌| 8194/8564 [01:23<00:02, 134.30 examples/s]Tokenizing train dataset:  96%|█████████▌| 8229/8564 [01:24<00:02, 156.29 examples/s]Tokenizing train dataset:  96%|█████████▌| 8213/8564 [01:23<00:03, 115.38 examples/s]Tokenizing train dataset:  99%|█████████▉| 8510/8564 [01:23<00:00, 113.46 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [01:24<00:02, 148.49 examples/s]Tokenizing train dataset: 100%|█████████▉| 8533/8564 [01:23<00:00, 131.43 examples/s]Tokenizing train dataset:  96%|█████████▌| 8240/8564 [01:23<00:02, 135.91 examples/s]Tokenizing train dataset:  97%|█████████▋| 8273/8564 [01:24<00:01, 164.31 examples/s]Tokenizing train dataset: 100%|█████████▉| 8550/8564 [01:23<00:00, 112.64 examples/s]Tokenizing train dataset:  96%|█████████▋| 8261/8564 [01:23<00:02, 120.10 examples/s]Tokenizing train dataset:  97%|█████████▋| 8300/8564 [01:24<00:01, 143.33 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:23<00:00, 102.29 examples/s]Tokenizing train dataset:  97%|█████████▋| 8279/8564 [01:23<00:02, 129.73 examples/s]
Tokenizing train dataset:  97%|█████████▋| 8320/8564 [01:24<00:01, 152.91 examples/s]Tokenizing train dataset:  97%|█████████▋| 8298/8564 [01:23<00:02, 132.96 examples/s]Tokenizing train dataset:  97%|█████████▋| 8337/8564 [01:24<00:01, 156.61 examples/s]Tokenizing train dataset:  97%|█████████▋| 8325/8564 [01:24<00:01, 142.58 examples/s]Tokenizing train dataset:  98%|█████████▊| 8358/8564 [01:24<00:01, 148.37 examples/s]Tokenizing train dataset:  98%|█████████▊| 8380/8564 [01:24<00:01, 162.84 examples/s]Tokenizing train dataset:  97%|█████████▋| 8342/8564 [01:24<00:01, 124.91 examples/s]Tokenizing train dataset:  98%|█████████▊| 8407/8564 [01:25<00:00, 162.92 examples/s]Tokenizing train dataset:  98%|█████████▊| 8358/8564 [01:24<00:01, 114.13 examples/s]Tokenizing train dataset:  98%|█████████▊| 8430/8564 [01:25<00:00, 172.83 examples/s]Tokenizing train dataset:  98%|█████████▊| 8376/8564 [01:24<00:01, 120.82 examples/s]Tokenizing train dataset:  99%|█████████▊| 8452/8564 [01:25<00:00, 171.59 examples/s]Tokenizing train dataset:  98%|█████████▊| 8392/8564 [01:24<00:01, 125.94 examples/s]Tokenizing train dataset:  98%|█████████▊| 8409/8564 [01:24<00:01, 125.90 examples/s]Tokenizing train dataset:  99%|█████████▉| 8480/8564 [01:25<00:00, 167.13 examples/s]Tokenizing train dataset:  98%|█████████▊| 8427/8564 [01:25<00:00, 137.96 examples/s]Tokenizing train dataset:  99%|█████████▉| 8499/8564 [01:25<00:00, 139.89 examples/s]Tokenizing train dataset:  99%|█████████▊| 8445/8564 [01:25<00:00, 126.81 examples/s]Tokenizing train dataset:  99%|█████████▉| 8520/8564 [01:25<00:00, 142.17 examples/s]Tokenizing train dataset:  99%|█████████▉| 8462/8564 [01:25<00:00, 129.07 examples/s]Tokenizing train dataset:  99%|█████████▉| 8482/8564 [01:25<00:00, 142.56 examples/s]Tokenizing train dataset: 100%|█████████▉| 8539/8564 [01:26<00:00, 132.29 examples/s]Tokenizing train dataset:  99%|█████████▉| 8499/8564 [01:25<00:00, 144.72 examples/s]Tokenizing train dataset: 100%|█████████▉| 8558/8564 [01:26<00:00, 140.38 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:26<00:00, 99.25 examples/s] Tokenizing train dataset: 100%|█████████▉| 8526/8564 [01:25<00:00, 171.98 examples/s]
Tokenizing train dataset: 100%|█████████▉| 8546/8564 [01:25<00:00, 161.53 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:25<00:00, 159.88 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:25<00:00, 99.63 examples/s] 
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  56%|█████▌    | 530/953 [00:00<00:00, 5223.65 examples/s]Extracting prompt in eval dataset:  23%|██▎       | 221/953 [00:00<00:00, 2098.02 examples/s]Extracting prompt in eval dataset:  54%|█████▍    | 514/953 [00:00<00:00, 4982.19 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4668.77 examples/s]
Extracting prompt in eval dataset:  76%|███████▌  | 726/953 [00:00<00:00, 3795.07 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3724.71 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2577.93 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  90%|█████████ | 860/953 [00:00<00:00, 8503.02 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 6991.47 examples/s]
Applying chat template to eval dataset:  52%|█████▏    | 492/953 [00:00<00:00, 4562.51 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3896.66 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3252.52 examples/s]
Applying chat template to eval dataset:  43%|████▎     | 409/953 [00:00<00:00, 3582.67 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3663.37 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3252.77 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   2%|▏         | 15/953 [00:00<00:07, 120.67 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 31/953 [00:00<00:08, 108.26 examples/s]Tokenizing eval dataset:   2%|▏         | 23/953 [00:00<00:04, 216.85 examples/s]Tokenizing eval dataset:   5%|▌         | 49/953 [00:00<00:08, 107.16 examples/s]Tokenizing eval dataset:   5%|▍         | 47/953 [00:00<00:07, 122.44 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   7%|▋         | 66/953 [00:00<00:08, 104.96 examples/s]Tokenizing eval dataset:   2%|▏         | 21/953 [00:00<00:05, 169.50 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:08, 107.81 examples/s]Tokenizing eval dataset:   7%|▋         | 71/953 [00:00<00:07, 115.03 examples/s]Tokenizing eval dataset:   4%|▍         | 40/953 [00:00<00:05, 174.67 examples/s]Tokenizing eval dataset:  10%|█         | 99/953 [00:00<00:07, 112.13 examples/s]Tokenizing eval dataset:   9%|▉         | 85/953 [00:00<00:07, 119.12 examples/s]Tokenizing eval dataset:   6%|▋         | 60/953 [00:00<00:06, 147.98 examples/s]Tokenizing eval dataset:  12%|█▏        | 112/953 [00:01<00:07, 112.31 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:00<00:07, 106.85 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:05, 154.05 examples/s]Tokenizing eval dataset:  14%|█▎        | 130/953 [00:01<00:07, 106.93 examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:01<00:07, 106.13 examples/s]Tokenizing eval dataset:  10%|█         | 96/953 [00:00<00:06, 127.37 examples/s]Tokenizing eval dataset:  15%|█▌        | 143/953 [00:01<00:07, 109.68 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Tokenizing eval dataset:  14%|█▍        | 136/953 [00:01<00:07, 104.25 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:06, 124.29 examples/s]Tokenizing eval dataset:  17%|█▋        | 159/953 [00:01<00:08, 98.21 examples/s] Tokenizing eval dataset:  16%|█▌        | 153/953 [00:01<00:07, 103.67 examples/s]Tokenizing eval dataset:  13%|█▎        | 123/953 [00:01<00:08, 99.12 examples/s] Tokenizing eval dataset:  18%|█▊        | 167/953 [00:01<00:07, 108.79 examples/s]Tokenizing eval dataset:  18%|█▊        | 176/953 [00:01<00:07, 101.31 examples/s]Tokenizing eval dataset:  14%|█▍        | 137/953 [00:01<00:07, 103.69 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:01<00:07, 108.73 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:01<00:08, 91.04 examples/s] Tokenizing eval dataset:  20%|██        | 195/953 [00:01<00:07, 104.36 examples/s]Tokenizing eval dataset:  16%|█▌        | 151/953 [00:01<00:09, 84.99 examples/s] Tokenizing eval dataset:  22%|██▏       | 210/953 [00:02<00:07, 101.71 examples/s]Tokenizing eval dataset:  22%|██▏       | 210/953 [00:01<00:06, 113.97 examples/s]Tokenizing eval dataset:  17%|█▋        | 162/953 [00:01<00:09, 85.34 examples/s]Tokenizing eval dataset:  24%|██▎       | 226/953 [00:02<00:06, 112.35 examples/s]Tokenizing eval dataset:  23%|██▎       | 222/953 [00:01<00:06, 111.00 examples/s]Tokenizing eval dataset:  26%|██▌       | 250/953 [00:02<00:05, 140.08 examples/s]Tokenizing eval dataset:  18%|█▊        | 172/953 [00:01<00:08, 87.15 examples/s]Tokenizing eval dataset:  25%|██▌       | 241/953 [00:02<00:05, 129.94 examples/s]Tokenizing eval dataset:  30%|███       | 290/953 [00:02<00:03, 202.11 examples/s]Tokenizing eval dataset:  28%|██▊       | 264/953 [00:02<00:04, 153.33 examples/s]Tokenizing eval dataset:  19%|█▉        | 185/953 [00:01<00:09, 79.10 examples/s]Tokenizing eval dataset:  34%|███▍      | 324/953 [00:02<00:02, 229.68 examples/s]Tokenizing eval dataset:  32%|███▏      | 302/953 [00:02<00:03, 212.90 examples/s]Tokenizing eval dataset:  21%|██        | 201/953 [00:02<00:09, 77.34 examples/s]Tokenizing eval dataset:  37%|███▋      | 354/953 [00:02<00:02, 201.67 examples/s]Tokenizing eval dataset:  35%|███▌      | 338/953 [00:02<00:02, 215.26 examples/s]Tokenizing eval dataset:  23%|██▎       | 216/953 [00:02<00:08, 91.22 examples/s]Tokenizing eval dataset:  40%|████      | 385/953 [00:02<00:02, 195.58 examples/s]Tokenizing eval dataset:  24%|██▍       | 232/953 [00:02<00:07, 102.34 examples/s]Tokenizing eval dataset:  40%|███▉      | 381/953 [00:02<00:02, 217.11 examples/s]Tokenizing eval dataset:  44%|████▍     | 421/953 [00:02<00:02, 229.61 examples/s]Tokenizing eval dataset:  28%|██▊       | 265/953 [00:02<00:04, 153.02 examples/s]Tokenizing eval dataset:  42%|████▏     | 405/953 [00:02<00:02, 216.49 examples/s]Tokenizing eval dataset:  48%|████▊     | 455/953 [00:03<00:02, 246.48 examples/s]Tokenizing eval dataset:  31%|███       | 295/953 [00:02<00:03, 186.46 examples/s]Tokenizing eval dataset:  45%|████▌     | 431/953 [00:02<00:02, 214.86 examples/s]Tokenizing eval dataset:  33%|███▎      | 318/953 [00:02<00:03, 190.24 examples/s]Tokenizing eval dataset:  48%|████▊     | 455/953 [00:03<00:02, 208.21 examples/s]Tokenizing eval dataset:  51%|█████     | 488/953 [00:03<00:02, 217.00 examples/s]Tokenizing eval dataset:  37%|███▋      | 349/953 [00:02<00:02, 219.59 examples/s]Tokenizing eval dataset:  51%|█████     | 484/953 [00:03<00:02, 226.34 examples/s]Tokenizing eval dataset:  54%|█████▍    | 517/953 [00:03<00:02, 201.69 examples/s]Tokenizing eval dataset:  40%|████      | 385/953 [00:02<00:02, 222.09 examples/s]Tokenizing eval dataset:  53%|█████▎    | 508/953 [00:03<00:02, 219.87 examples/s]Tokenizing eval dataset:  58%|█████▊    | 552/953 [00:03<00:01, 216.38 examples/s]Tokenizing eval dataset:  44%|████▍     | 418/953 [00:02<00:02, 247.02 examples/s]Tokenizing eval dataset:  58%|█████▊    | 555/953 [00:03<00:01, 248.56 examples/s]Tokenizing eval dataset:  47%|████▋     | 448/953 [00:03<00:01, 258.65 examples/s]Tokenizing eval dataset:  61%|██████▏   | 586/953 [00:03<00:01, 207.43 examples/s]Tokenizing eval dataset:  61%|██████    | 582/953 [00:03<00:01, 247.14 examples/s]Tokenizing eval dataset:  50%|█████     | 477/953 [00:03<00:01, 260.95 examples/s]Tokenizing eval dataset:  66%|██████▌   | 628/953 [00:03<00:01, 251.32 examples/s]Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:03<00:01, 242.94 examples/s]Tokenizing eval dataset:  54%|█████▍    | 516/953 [00:03<00:01, 251.79 examples/s]Tokenizing eval dataset:  70%|██████▉   | 667/953 [00:03<00:01, 251.70 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:03<00:01, 231.45 examples/s]Tokenizing eval dataset:  58%|█████▊    | 552/953 [00:03<00:01, 276.45 examples/s]Tokenizing eval dataset:  73%|███████▎  | 697/953 [00:04<00:00, 259.09 examples/s]Tokenizing eval dataset:  70%|███████   | 670/953 [00:03<00:01, 218.20 examples/s]Tokenizing eval dataset:  61%|██████    | 582/953 [00:03<00:01, 247.56 examples/s]Tokenizing eval dataset:  76%|███████▌  | 726/953 [00:04<00:00, 257.15 examples/s]Tokenizing eval dataset:  73%|███████▎  | 692/953 [00:04<00:01, 210.68 examples/s]Tokenizing eval dataset:  64%|██████▍   | 614/953 [00:03<00:01, 231.57 examples/s]Tokenizing eval dataset:  76%|███████▌  | 722/953 [00:04<00:01, 230.19 examples/s]Tokenizing eval dataset:  79%|███████▉  | 753/953 [00:04<00:00, 226.99 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:03<00:01, 235.66 examples/s]Tokenizing eval dataset:  79%|███████▉  | 757/953 [00:04<00:00, 228.34 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:04<00:00, 195.31 examples/s]Tokenizing eval dataset:  72%|███████▏  | 684/953 [00:03<00:01, 253.53 examples/s]Tokenizing eval dataset:  84%|████████▍ | 805/953 [00:04<00:00, 198.97 examples/s]Tokenizing eval dataset:  82%|████████▏ | 781/953 [00:04<00:00, 230.16 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:04<00:00, 253.00 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:04<00:00, 202.56 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:04<00:00, 179.48 examples/s]Tokenizing eval dataset:  81%|████████  | 771/953 [00:04<00:00, 263.57 examples/s]Tokenizing eval dataset:  90%|█████████ | 861/953 [00:04<00:00, 196.19 examples/s]Tokenizing eval dataset:  87%|████████▋ | 827/953 [00:04<00:00, 177.66 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:05<00:00, 198.97 examples/s]Tokenizing eval dataset:  84%|████████▍ | 800/953 [00:04<00:00, 236.61 examples/s]Tokenizing eval dataset:  89%|████████▉ | 851/953 [00:04<00:00, 159.68 examples/s]Tokenizing eval dataset:  95%|█████████▌| 906/953 [00:05<00:00, 205.31 examples/s]Tokenizing eval dataset:  87%|████████▋ | 826/953 [00:04<00:00, 238.91 examples/s]Tokenizing eval dataset:  92%|█████████▏| 880/953 [00:05<00:00, 184.58 examples/s]Tokenizing eval dataset:  90%|████████▉ | 854/953 [00:04<00:00, 210.66 examples/s]Tokenizing eval dataset:  98%|█████████▊| 937/953 [00:05<00:00, 180.73 examples/s]Tokenizing eval dataset:  96%|█████████▌| 914/953 [00:05<00:00, 195.70 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 172.14 examples/s]Tokenizing eval dataset:  93%|█████████▎| 889/953 [00:04<00:00, 205.63 examples/s]Tokenizing eval dataset:  98%|█████████▊| 935/953 [00:05<00:00, 178.10 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 174.25 examples/s]
Tokenizing eval dataset:  97%|█████████▋| 926/953 [00:05<00:00, 210.19 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 183.69 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combinationLoading extension module cpu_adam...

Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.476416826248169 secondsTime to load cpu_adam op: 4.991591215133667 seconds
Time to load cpu_adam op: 5.825619220733643 seconds
Time to load cpu_adam op: 5.554765701293945 seconds

Parameter Offload: Total persistent parameters: 605696 in 169 params
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250529_234700-xjq7qkhb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-3e-07_e-3_b-0.2
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/xjq7qkhb
  0%|          | 0/1608 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
gn25:3904812:3904812 [0] NCCL INFO Comm config Blocking set to 1
gn25:3904813:3904813 [1] NCCL INFO Comm config Blocking set to 1
gn25:3904815:3904815 [3] NCCL INFO Comm config Blocking set to 1
gn25:3904814:3904814 [2] NCCL INFO Comm config Blocking set to 1
gn25:3904815:3906646 [3] NCCL INFO Using non-device net plugin version 0
gn25:3904815:3906646 [3] NCCL INFO Using network Socket
gn25:3904814:3906647 [2] NCCL INFO Using non-device net plugin version 0
gn25:3904812:3906644 [0] NCCL INFO Using non-device net plugin version 0
gn25:3904812:3906644 [0] NCCL INFO Using network Socket
gn25:3904814:3906647 [2] NCCL INFO Using network Socket
gn25:3904813:3906645 [1] NCCL INFO Using non-device net plugin version 0
gn25:3904813:3906645 [1] NCCL INFO Using network Socket
gn25:3904812:3906644 [0] NCCL INFO ncclCommInitRank comm 0x55b30243cb30 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 3000 commId 0x7a97dc34fa22357 - Init START
gn25:3904813:3906645 [1] NCCL INFO ncclCommInitRank comm 0x5624292d3590 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 44000 commId 0x7a97dc34fa22357 - Init START
gn25:3904814:3906647 [2] NCCL INFO ncclCommInitRank comm 0x55dcf478e950 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 84000 commId 0x7a97dc34fa22357 - Init START
gn25:3904815:3906646 [3] NCCL INFO ncclCommInitRank comm 0x55c461907920 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c4000 commId 0x7a97dc34fa22357 - Init START
gn25:3904814:3906647 [2] NCCL INFO Setting affinity for GPU 2 to 010000,00000000,00000000,00000000,00010000,00000000,00000000,00000000
gn25:3904814:3906647 [2] NCCL INFO NVLS multicast support is not available on dev 2
gn25:3904812:3906644 [0] NCCL INFO NVLS multicast support is not available on dev 0
gn25:3904815:3906646 [3] NCCL INFO NVLS multicast support is not available on dev 3
gn25:3904813:3906645 [1] NCCL INFO NVLS multicast support is not available on dev 1
gn25:3904812:3906644 [0] NCCL INFO comm 0x55b30243cb30 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
gn25:3904814:3906647 [2] NCCL INFO comm 0x55dcf478e950 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
gn25:3904813:3906645 [1] NCCL INFO comm 0x5624292d3590 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
gn25:3904815:3906646 [3] NCCL INFO comm 0x55c461907920 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
gn25:3904812:3906644 [0] NCCL INFO Channel 00/24 :    0   1   2   3
gn25:3904812:3906644 [0] NCCL INFO Channel 01/24 :    0   1   3   2
gn25:3904814:3906647 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
gn25:3904813:3906645 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
gn25:3904813:3906645 [1] NCCL INFO P2P Chunksize set to 524288
gn25:3904815:3906646 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
gn25:3904815:3906646 [3] NCCL INFO P2P Chunksize set to 524288
gn25:3904812:3906644 [0] NCCL INFO Channel 02/24 :    0   2   3   1
gn25:3904812:3906644 [0] NCCL INFO Channel 03/24 :    0   2   1   3
gn25:3904814:3906647 [2] NCCL INFO P2P Chunksize set to 524288
gn25:3904812:3906644 [0] NCCL INFO Channel 04/24 :    0   3   1   2
gn25:3904812:3906644 [0] NCCL INFO Channel 05/24 :    0   3   2   1
gn25:3904812:3906644 [0] NCCL INFO Channel 06/24 :    0   1   2   3
gn25:3904813:3906645 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 07/24 :    0   1   3   2
gn25:3904814:3906647 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 08/24 :    0   2   3   1
gn25:3904812:3906644 [0] NCCL INFO Channel 09/24 :    0   2   1   3
gn25:3904814:3906647 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 10/24 :    0   3   1   2
gn25:3904812:3906644 [0] NCCL INFO Channel 11/24 :    0   3   2   1
gn25:3904814:3906647 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 12/24 :    0   1   2   3
gn25:3904812:3906644 [0] NCCL INFO Channel 13/24 :    0   1   3   2
gn25:3904814:3906647 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 14/24 :    0   2   3   1
gn25:3904814:3906647 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 15/24 :    0   2   1   3
gn25:3904812:3906644 [0] NCCL INFO Channel 16/24 :    0   3   1   2
gn25:3904814:3906647 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 17/24 :    0   3   2   1
gn25:3904812:3906644 [0] NCCL INFO Channel 18/24 :    0   1   2   3
gn25:3904812:3906644 [0] NCCL INFO Channel 19/24 :    0   1   3   2
gn25:3904812:3906644 [0] NCCL INFO Channel 20/24 :    0   2   3   1
gn25:3904812:3906644 [0] NCCL INFO Channel 21/24 :    0   2   1   3
gn25:3904812:3906644 [0] NCCL INFO Channel 22/24 :    0   3   1   2
gn25:3904812:3906644 [0] NCCL INFO Channel 23/24 :    0   3   2   1
gn25:3904814:3906647 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
gn25:3904812:3906644 [0] NCCL INFO P2P Chunksize set to 524288
gn25:3904814:3906647 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Connected all rings
gn25:3904812:3906644 [0] NCCL INFO Connected all rings
gn25:3904815:3906646 [3] NCCL INFO Connected all rings
gn25:3904814:3906647 [2] NCCL INFO Connected all rings
gn25:3904813:3906645 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 08/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 10/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 11/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 20/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 22/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 15/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 14/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 23/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 21/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 22/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 20/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 17/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 23/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 21/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 19/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 22/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 23/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 04/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 05/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 05/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 04/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 05/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 06/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 06/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 05/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 07/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 06/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 07/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 06/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 16/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 17/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 17/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 16/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 17/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 18/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 18/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 17/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 18/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 19/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 18/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 19/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 08/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 09/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 20/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Channel 21/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 12/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 13/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 16/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 15/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 18/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 20/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 21/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904813:3906645 [1] NCCL INFO Channel 22/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904814:3906647 [2] NCCL INFO Channel 19/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 21/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904815:3906646 [3] NCCL INFO Channel 22/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904812:3906644 [0] NCCL INFO Connected all trees
gn25:3904812:3906644 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn25:3904814:3906647 [2] NCCL INFO Connected all trees
gn25:3904813:3906645 [1] NCCL INFO Connected all trees
gn25:3904815:3906646 [3] NCCL INFO Connected all trees
gn25:3904812:3906644 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gn25:3904814:3906647 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn25:3904814:3906647 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gn25:3904813:3906645 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn25:3904813:3906645 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gn25:3904815:3906646 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn25:3904815:3906646 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gn25:3904815:3906646 [3] NCCL INFO ncclCommInitRank comm 0x55c461907920 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c4000 commId 0x7a97dc34fa22357 - Init COMPLETE
gn25:3904812:3906644 [0] NCCL INFO ncclCommInitRank comm 0x55b30243cb30 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 3000 commId 0x7a97dc34fa22357 - Init COMPLETE
gn25:3904814:3906647 [2] NCCL INFO ncclCommInitRank comm 0x55dcf478e950 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 84000 commId 0x7a97dc34fa22357 - Init COMPLETE
gn25:3904813:3906645 [1] NCCL INFO ncclCommInitRank comm 0x5624292d3590 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 44000 commId 0x7a97dc34fa22357 - Init COMPLETE
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
gn25:3904812:3906755 [0] NCCL INFO Comm config Blocking set to 1
gn25:3904815:3906760 [3] NCCL INFO Comm config Blocking set to 1
gn25:3904814:3906764 [2] NCCL INFO Comm config Blocking set to 1
gn25:3904813:3906769 [1] NCCL INFO Comm config Blocking set to 1
gn25:3904812:3906793 [0] NCCL INFO Using non-device net plugin version 0
gn25:3904812:3906793 [0] NCCL INFO Using network Socket
gn25:3904815:3906794 [3] NCCL INFO Using non-device net plugin version 0
gn25:3904815:3906794 [3] NCCL INFO Using network Socket
gn25:3904814:3906795 [2] NCCL INFO Using non-device net plugin version 0
gn25:3904814:3906795 [2] NCCL INFO Using network Socket
gn25:3904813:3906796 [1] NCCL INFO Using non-device net plugin version 0
gn25:3904813:3906796 [1] NCCL INFO Using network Socket
gn25:3904815:3906794 [3] NCCL INFO ncclCommInitRank comm 0x7efc3aeea3e0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId c4000 commId 0xa659f5303d7f5fb3 - Init START
gn25:3904812:3906793 [0] NCCL INFO ncclCommInitRank comm 0x7f1b5caac540 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 3000 commId 0xa659f5303d7f5fb3 - Init START
gn25:3904813:3906796 [1] NCCL INFO ncclCommInitRank comm 0x7f4a3eed16f0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 44000 commId 0xa659f5303d7f5fb3 - Init START
gn25:3904814:3906795 [2] NCCL INFO ncclCommInitRank comm 0x7f008eec9560 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 84000 commId 0xa659f5303d7f5fb3 - Init START
gn25:3904814:3906795 [2] NCCL INFO Setting affinity for GPU 2 to 010000,00000000,00000000,00000000,00010000,00000000,00000000,00000000
gn25:3904814:3906795 [2] NCCL INFO NVLS multicast support is not available on dev 2
gn25:3904813:3906796 [1] NCCL INFO NVLS multicast support is not available on dev 1
gn25:3904815:3906794 [3] NCCL INFO NVLS multicast support is not available on dev 3
gn25:3904812:3906793 [0] NCCL INFO NVLS multicast support is not available on dev 0
gn25:3904812:3906793 [0] NCCL INFO comm 0x7f1b5caac540 rank 0 nRanks 8 nNodes 2 localRanks 4 localRank 0 MNNVL 0
gn25:3904813:3906796 [1] NCCL INFO comm 0x7f4a3eed16f0 rank 1 nRanks 8 nNodes 2 localRanks 4 localRank 1 MNNVL 0
gn25:3904813:3906796 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0
gn25:3904814:3906795 [2] NCCL INFO comm 0x7f008eec9560 rank 2 nRanks 8 nNodes 2 localRanks 4 localRank 2 MNNVL 0
gn25:3904815:3906794 [3] NCCL INFO comm 0x7efc3aeea3e0 rank 3 nRanks 8 nNodes 2 localRanks 4 localRank 3 MNNVL 0
gn25:3904812:3906793 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7
gn25:3904813:3906796 [1] NCCL INFO P2P Chunksize set to 131072
gn25:3904814:3906795 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1
gn25:3904814:3906795 [2] NCCL INFO P2P Chunksize set to 131072
gn25:3904815:3906794 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2
gn25:3904812:3906793 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7
gn25:3904813:3906796 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906795 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904815:3906794 [3] NCCL INFO P2P Chunksize set to 131072
gn25:3904812:3906793 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->4
gn25:3904812:3906793 [0] NCCL INFO P2P Chunksize set to 131072
gn25:3904813:3906796 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906795 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn25:3904812:3906793 [0] NCCL INFO Channel 00/0 : 7[3] -> 0[0] [receive] via NET/Socket/0
gn25:3904815:3906794 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[0] [send] via NET/Socket/0
gn25:3904812:3906793 [0] NCCL INFO Channel 01/0 : 7[3] -> 0[0] [receive] via NET/Socket/0
gn25:3904815:3906794 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[0] [send] via NET/Socket/0
gn25:3904812:3906793 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906793 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn25:3904815:3906794 [3] NCCL INFO Connected all rings
gn25:3904815:3906794 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906795 [2] NCCL INFO Connected all rings
gn25:3904815:3906794 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn25:3904814:3906795 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906793 [0] NCCL INFO Connected all rings
gn25:3904813:3906796 [1] NCCL INFO Connected all rings
gn25:3904814:3906795 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn25:3904812:3906793 [0] NCCL INFO Channel 00/0 : 4[0] -> 0[0] [receive] via NET/Socket/0
gn25:3904813:3906796 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906793 [0] NCCL INFO Channel 01/0 : 4[0] -> 0[0] [receive] via NET/Socket/0
gn25:3904813:3906796 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn25:3904812:3906793 [0] NCCL INFO Channel 00/0 : 0[0] -> 4[0] [send] via NET/Socket/0
gn25:3904815:3906794 [3] NCCL INFO Connected all trees
gn25:3904815:3906794 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn25:3904812:3906793 [0] NCCL INFO Channel 01/0 : 0[0] -> 4[0] [send] via NET/Socket/0
gn25:3904815:3906794 [3] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn25:3904814:3906795 [2] NCCL INFO Connected all trees
gn25:3904814:3906795 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn25:3904814:3906795 [2] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn25:3904812:3906793 [0] NCCL INFO Connected all trees
gn25:3904812:3906793 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn25:3904813:3906796 [1] NCCL INFO Connected all trees
gn25:3904813:3906796 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn25:3904812:3906793 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn25:3904813:3906796 [1] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn25:3904813:3906796 [1] NCCL INFO ncclCommInitRank comm 0x7f4a3eed16f0 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 44000 commId 0xa659f5303d7f5fb3 - Init COMPLETE
gn25:3904815:3906794 [3] NCCL INFO ncclCommInitRank comm 0x7efc3aeea3e0 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId c4000 commId 0xa659f5303d7f5fb3 - Init COMPLETE
gn25:3904814:3906795 [2] NCCL INFO ncclCommInitRank comm 0x7f008eec9560 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 84000 commId 0xa659f5303d7f5fb3 - Init COMPLETE
gn25:3904812:3906793 [0] NCCL INFO ncclCommInitRank comm 0x7f1b5caac540 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 3000 commId 0xa659f5303d7f5fb3 - Init COMPLETE
  0%|          | 1/1608 [01:14<33:13:09, 74.42s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 0.0, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -4416.0, 'logps/rejected': -3968.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.0}
  0%|          | 1/1608 [01:15<33:13:09, 74.42s/it]  0%|          | 2/1608 [01:59<25:37:43, 57.45s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 3.5030359645025685e-11, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -4640.0, 'logps/rejected': -4800.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.0}
  0%|          | 2/1608 [02:00<25:37:43, 57.45s/it]  0%|          | 3/1608 [02:43<22:47:38, 51.13s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 7.006071929005137e-11, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5760.0, 'logps/rejected': -5504.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 3/1608 [02:43<22:47:38, 51.13s/it]  0%|          | 4/1608 [03:25<21:08:34, 47.45s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 1.0509107893507707e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5120.0, 'logps/rejected': -5120.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 4/1608 [03:25<21:08:34, 47.45s/it]  0%|          | 5/1608 [04:08<20:23:39, 45.80s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 1.4012143858010274e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -4128.0, 'logps/rejected': -3936.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 5/1608 [04:08<20:23:39, 45.80s/it]  0%|          | 6/1608 [04:51<19:55:19, 44.77s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 1.7515179822512842e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -8384.0, 'logps/rejected': -6080.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 6/1608 [04:51<19:55:19, 44.77s/it]  0%|          | 7/1608 [05:33<19:30:59, 43.88s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 2.1018215787015413e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6304.0, 'logps/rejected': -4608.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 7/1608 [05:33<19:30:59, 43.88s/it]  0%|          | 8/1608 [06:15<19:17:30, 43.41s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 2.452125175151798e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6240.0, 'logps/rejected': -4704.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 8/1608 [06:15<19:17:30, 43.41s/it]  1%|          | 9/1608 [06:58<19:14:30, 43.32s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 2.802428771602055e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6528.0, 'logps/rejected': -5280.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.02}
  1%|          | 9/1608 [06:58<19:14:30, 43.32s/it]  1%|          | 10/1608 [07:41<19:09:21, 43.16s/it]                                                    {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 3.152732368052312e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6752.0, 'logps/rejected': -6112.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.02}
  1%|          | 10/1608 [07:41<19:09:21, 43.16s/it]  1%|          | 11/1608 [08:24<19:04:46, 43.01s/it]                                                    {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 3.5030359645025685e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5696.0, 'logps/rejected': -5024.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.02}
  1%|          | 11/1608 [08:24<19:04:46, 43.01s/it]  1%|          | 12/1608 [09:06<18:59:09, 42.83s/it]                                                    {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 3.8533395609528256e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5824.0, 'logps/rejected': -5888.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.02}
  1%|          | 12/1608 [09:06<18:59:09, 42.83s/it]slurmstepd: error: *** STEP 62035524.0 ON gn25 CANCELLED AT 2025-05-29T23:56:24 ***
