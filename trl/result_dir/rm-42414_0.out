cpu-bind=MASK - ixh, task  0  0 [1908978]: mask 0xff000000000000ff000000000000ff000000000000ff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 1
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3,4,5,6,7 ---
GPUs per Node: 8
Master Address: 
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 1     --machine_rank 0     --main_process_ip      --main_process_port 29500     --num_processes 8     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=128 --learning_rate=1e-6 --total_epochs=3 --beta=0.1
-------------------------------------------
[2025-07-12 22:55:01,793] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
df: /root/.triton/autotune: No such file or directory
W0712 22:55:03.144000 1909527 torch/distributed/run.py:792] 
W0712 22:55:03.144000 1909527 torch/distributed/run.py:792] *****************************************
W0712 22:55:03.144000 1909527 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0712 22:55:03.144000 1909527 torch/distributed/run.py:792] *****************************************
[load_data.py]: Training data of type 'bad_lang_examples':    5343
[load_data.py]: Training data of type 'short_examples':       699
[load_data.py]: Training data of type 'choose_examples':      13379
[load_data.py]: Training data of type 'bad_format_examples':  4806
Namespace(rank=128, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
Namespace(rank=128, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
[load_data.py]: Number of training examples: 24227
[load_data.py]: Number of validation examples: 953
Namespace(rank=128, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
World size: 8
Setting gradient accumulation steps to: 2
Namespace(rank=128, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
Namespace(rank=128, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
Namespace(rank=128, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
Namespace(rank=128, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
Namespace(rank=128, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
Created datasets
Train dataset size: 24227
Validation dataset size: 953
Steps per epoch: 1514
Evaluate each 504 steps
[2025-07-12 22:55:12,347] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-12 22:55:13,386] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-07-12 22:55:13,387] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-07-12 22:55:13,403] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-12 22:55:13,595] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-12 22:55:14,121] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Set up DPO configuration
[rank0]: Traceback (most recent call last):
[rank0]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 212, in <module>
[rank0]:     main(train_data, val_data, args.rank, args.learning_rate, args.total_epochs, args.beta)
[rank0]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 133, in main
[rank0]:     model = AutoModelForCausalLM.from_pretrained(model_path, attn_implementation="eager")
[rank0]:   File "/transformers/src/transformers/models/auto/auto_factory.py", line 504, in from_pretrained
[rank0]:     resolved_config_file = cached_file(
[rank0]:   File "/transformers/src/transformers/utils/hub.py", line 312, in cached_file
[rank0]:     file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
[rank0]:   File "/transformers/src/transformers/utils/hub.py", line 557, in cached_files
[rank0]:     raise e
[rank0]:   File "/transformers/src/transformers/utils/hub.py", line 470, in cached_files
[rank0]:     hf_hub_download(
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 1008, in hf_hub_download
[rank0]:     return _hf_hub_download_to_cache_dir(
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 1071, in _hf_hub_download_to_cache_dir
[rank0]:     (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = _get_metadata_or_catch_error(
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 1533, in _get_metadata_or_catch_error
[rank0]:     metadata = get_hf_file_metadata(
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 1450, in get_hf_file_metadata
[rank0]:     r = _request_wrapper(
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 286, in _request_wrapper
[rank0]:     response = _request_wrapper(
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 309, in _request_wrapper
[rank0]:     response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(429,))
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py", line 310, in http_backoff
[rank0]:     response = session.request(method=method, url=url, **kwargs)
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/requests/sessions.py", line 589, in request
[rank0]:     resp = self.send(prep, **send_kwargs)
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/requests/sessions.py", line 703, in send
[rank0]:     r = adapter.send(request, **kwargs)
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py", line 96, in send
[rank0]:     return super().send(request, *args, **kwargs)
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/requests/adapters.py", line 639, in send
[rank0]:     self.cert_verify(conn, request.url, verify, cert)
[rank0]:   File "/usr/local/lib/python3.10/dist-packages/requests/adapters.py", line 328, in cert_verify
[rank0]:     raise OSError(
[rank0]: OSError: Could not find a suitable TLS CA certificate bundle, invalid path: /shared/workspace/povejmo/translation_optimization/trl/cacert.pem
[2025-07-12 22:55:14,227] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-12 22:55:14,268] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-12 22:55:14,409] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-12 22:55:14,412] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-12 22:55:14,444] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-07-12 22:55:14,899] [INFO] [comm.py:669:init_distributed] cdb=None
[rank0]:[W712 22:55:14.449084383 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-07-12 22:55:15,476] [INFO] [comm.py:669:init_distributed] cdb=None
[rank7]: Traceback (most recent call last):
[rank7]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 212, in <module>
[rank7]:     main(train_data, val_data, args.rank, args.learning_rate, args.total_epochs, args.beta)
[rank7]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 133, in main
[rank7]:     model = AutoModelForCausalLM.from_pretrained(model_path, attn_implementation="eager")
[rank7]:   File "/transformers/src/transformers/models/auto/auto_factory.py", line 504, in from_pretrained
[rank7]:     resolved_config_file = cached_file(
[rank7]:   File "/transformers/src/transformers/utils/hub.py", line 312, in cached_file
[rank7]:     file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
[rank7]:   File "/transformers/src/transformers/utils/hub.py", line 557, in cached_files
[rank7]:     raise e
[rank7]:   File "/transformers/src/transformers/utils/hub.py", line 470, in cached_files
[rank7]:     hf_hub_download(
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 1008, in hf_hub_download
[rank7]:     return _hf_hub_download_to_cache_dir(
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 1071, in _hf_hub_download_to_cache_dir
[rank7]:     (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = _get_metadata_or_catch_error(
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 1533, in _get_metadata_or_catch_error
[rank7]:     metadata = get_hf_file_metadata(
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
[rank7]:     return fn(*args, **kwargs)
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 1450, in get_hf_file_metadata
[rank7]:     r = _request_wrapper(
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 286, in _request_wrapper
[rank7]:     response = _request_wrapper(
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py", line 309, in _request_wrapper
[rank7]:     response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(429,))
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py", line 310, in http_backoff
[rank7]:     response = session.request(method=method, url=url, **kwargs)
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/requests/sessions.py", line 589, in request
[rank7]:     resp = self.send(prep, **send_kwargs)
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/requests/sessions.py", line 703, in send
[rank7]:     r = adapter.send(request, **kwargs)
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py", line 96, in send
[rank7]:     return super().send(request, *args, **kwargs)
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/requests/adapters.py", line 639, in send
[rank7]:     self.cert_verify(conn, request.url, verify, cert)
[rank7]:   File "/usr/local/lib/python3.10/dist-packages/requests/adapters.py", line 328, in cert_verify
[rank7]:     raise OSError(
[rank7]: OSError: Could not find a suitable TLS CA certificate bundle, invalid path: /shared/workspace/povejmo/translation_optimization/trl/cacert.pem
[2025-07-12 22:55:15,666] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-07-12 22:55:15,678] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-07-12 22:55:15,679] [INFO] [comm.py:669:init_distributed] cdb=None
W0712 22:55:15.808000 1909527 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1909896 closing signal SIGTERM
W0712 22:55:15.809000 1909527 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1909897 closing signal SIGTERM
W0712 22:55:15.809000 1909527 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1909898 closing signal SIGTERM
W0712 22:55:15.810000 1909527 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1909899 closing signal SIGTERM
W0712 22:55:15.810000 1909527 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1909900 closing signal SIGTERM
W0712 22:55:15.811000 1909527 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1909901 closing signal SIGTERM
W0712 22:55:15.811000 1909527 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1909902 closing signal SIGTERM
E0712 22:55:16.418000 1909527 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 1909895) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1183, in launch_command
    deepspeed_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 868, in deepspeed_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-12_22:55:15
  host      : ixh
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1909895)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
