cpu-bind=MASK - gn35, task  0  0 [396373]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 1
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn35
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 1     --machine_rank 0     --main_process_ip gn35     --main_process_port 29500     --num_processes 4     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62111288     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-31 11:26:25,066] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0531 11:26:26.685000 396426 torch/distributed/run.py:792] 
W0531 11:26:26.685000 396426 torch/distributed/run.py:792] *****************************************
W0531 11:26:26.685000 396426 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0531 11:26:26.685000 396426 torch/distributed/run.py:792] *****************************************
[2025-05-31 11:26:32,038] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 11:26:32,080] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 11:26:32,091] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 11:26:32,143] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 4
Setting gradient accumulation steps to: 4
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Steps per epoch: 2141
Eval steps: 1070
[2025-05-31 11:26:34,308] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 11:26:34,308] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-05-31 11:26:34,312] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 11:26:34,314] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 11:26:34,373] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:57, 19.11s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:58, 19.41s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:58, 19.39s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:58, 19.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:37<00:36, 18.37s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:36<00:36, 18.24s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:37<00:36, 18.36s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:37<00:36, 18.36s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:57<00:19, 19.20s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:57<00:19, 19.20s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:57<00:19, 19.17s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:57<00:19, 19.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:11<00:00, 17.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:11<00:00, 17.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:11<00:00, 17.92s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:11<00:00, 17.85s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:11<00:00, 17.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:11<00:00, 17.91s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:11<00:00, 17.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:11<00:00, 17.91s/it]
/transformers/src/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
/transformers/src/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/transformers/src/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
[rank3]:[W531 11:27:54.955377352 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W531 11:27:54.961280693 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W531 11:27:54.965703461 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 1/8564 [00:00<1:39:30,  1.43 examples/s]Extracting prompt in train dataset:   2%|▏         | 130/8564 [00:00<00:39, 215.99 examples/s]Extracting prompt in train dataset:   4%|▍         | 370/8564 [00:00<00:13, 629.38 examples/s]Extracting prompt in train dataset:   8%|▊         | 710/8564 [00:01<00:06, 1219.59 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1120/8564 [00:01<00:03, 1887.82 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1420/8564 [00:01<00:03, 1979.78 examples/s]Extracting prompt in train dataset:  21%|██        | 1790/8564 [00:01<00:02, 2386.79 examples/s]Extracting prompt in train dataset:  25%|██▌       | 2160/8564 [00:01<00:02, 2719.75 examples/s]Extracting prompt in train dataset:  30%|███       | 2600/8564 [00:01<00:01, 3171.75 examples/s]Extracting prompt in train dataset:  36%|███▌      | 3050/8564 [00:01<00:01, 3475.03 examples/s]Extracting prompt in train dataset:  41%|████      | 3495/8564 [00:01<00:01, 3738.67 examples/s]Extracting prompt in train dataset:  46%|████▌     | 3940/8564 [00:01<00:01, 3929.52 examples/s]Extracting prompt in train dataset:  51%|█████▏    | 4390/8564 [00:01<00:01, 4078.05 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4850/8564 [00:02<00:00, 4221.97 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5370/8564 [00:02<00:00, 4496.71 examples/s]Extracting prompt in train dataset:  69%|██████▊   | 5877/8564 [00:02<00:00, 4662.14 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 6390/8564 [00:02<00:00, 4798.01 examples/s]Extracting prompt in train dataset:  80%|████████  | 6883/8564 [00:02<00:00, 4823.40 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7380/8564 [00:02<00:00, 4859.27 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8069/8564 [00:02<00:00, 4743.93 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 4789.27 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3020.46 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 252/8564 [00:00<00:03, 2498.08 examples/s]Applying chat template to train dataset:   7%|▋         | 560/8564 [00:00<00:02, 2829.32 examples/s]Applying chat template to train dataset:  10%|▉         | 851/8564 [00:00<00:02, 2861.44 examples/s]Applying chat template to train dataset:  14%|█▎        | 1173/8564 [00:00<00:02, 2999.28 examples/s]Applying chat template to train dataset:  17%|█▋        | 1490/8564 [00:00<00:02, 3055.30 examples/s]Applying chat template to train dataset:  21%|██        | 1813/8564 [00:00<00:02, 3110.05 examples/s]Applying chat template to train dataset:  25%|██▍       | 2138/8564 [00:00<00:02, 3151.57 examples/s]Applying chat template to train dataset:  29%|██▉       | 2463/8564 [00:00<00:01, 3177.41 examples/s]Applying chat template to train dataset:  33%|███▎      | 2787/8564 [00:00<00:01, 3196.50 examples/s]Applying chat template to train dataset:  38%|███▊      | 3255/8564 [00:01<00:01, 3158.58 examples/s]Applying chat template to train dataset:  42%|████▏     | 3578/8564 [00:01<00:01, 3176.93 examples/s]Applying chat template to train dataset:  46%|████▌     | 3902/8564 [00:01<00:01, 3187.85 examples/s]Applying chat template to train dataset:  49%|████▉     | 4226/8564 [00:01<00:01, 3199.18 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4549/8564 [00:01<00:01, 3206.13 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4871/8564 [00:01<00:01, 3208.30 examples/s]Applying chat template to train dataset:  61%|██████    | 5201/8564 [00:01<00:01, 3233.68 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5531/8564 [00:01<00:00, 3251.84 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5862/8564 [00:01<00:00, 3266.08 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6192/8564 [00:01<00:00, 3274.62 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6524/8564 [00:02<00:00, 3283.31 examples/s]Applying chat template to train dataset:  80%|████████  | 6854/8564 [00:02<00:00, 3284.96 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7232/8564 [00:02<00:00, 2983.26 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7562/8564 [00:02<00:00, 3067.05 examples/s]Applying chat template to train dataset:  94%|█████████▎| 8010/8564 [00:02<00:00, 3034.23 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8341/8564 [00:02<00:00, 3103.29 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3133.49 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 40/8564 [00:00<00:22, 375.05 examples/s]Tokenizing train dataset:   1%|          | 88/8564 [00:00<00:25, 331.64 examples/s]Tokenizing train dataset:   2%|▏         | 133/8564 [00:00<00:27, 310.59 examples/s]Tokenizing train dataset:   2%|▏         | 165/8564 [00:00<00:27, 309.19 examples/s]Tokenizing train dataset:   2%|▏         | 212/8564 [00:00<00:27, 306.35 examples/s]Tokenizing train dataset:   3%|▎         | 247/8564 [00:00<00:26, 317.49 examples/s]Tokenizing train dataset:   3%|▎         | 282/8564 [00:00<00:25, 325.80 examples/s]Tokenizing train dataset:   4%|▎         | 315/8564 [00:00<00:25, 322.97 examples/s]Tokenizing train dataset:   4%|▍         | 364/8564 [00:01<00:25, 319.53 examples/s]Tokenizing train dataset:   5%|▍         | 397/8564 [00:01<00:25, 319.66 examples/s]Tokenizing train dataset:   5%|▌         | 430/8564 [00:01<00:25, 321.07 examples/s]Tokenizing train dataset:   6%|▌         | 476/8564 [00:01<00:26, 307.50 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:01<00:26, 304.82 examples/s]Tokenizing train dataset:   7%|▋         | 557/8564 [00:01<00:25, 309.88 examples/s]Tokenizing train dataset:   7%|▋         | 602/8564 [00:01<00:26, 303.73 examples/s]Tokenizing train dataset:   7%|▋         | 640/8564 [00:02<00:24, 318.49 examples/s]Tokenizing train dataset:   8%|▊         | 686/8564 [00:02<00:25, 312.57 examples/s]Tokenizing train dataset:   9%|▊         | 736/8564 [00:02<00:24, 313.81 examples/s]Tokenizing train dataset:   9%|▉         | 768/8564 [00:02<00:24, 312.10 examples/s]Tokenizing train dataset:   9%|▉         | 810/8564 [00:02<00:26, 298.14 examples/s]Tokenizing train dataset:  10%|▉         | 854/8564 [00:02<00:26, 292.23 examples/s]Tokenizing train dataset:  10%|█         | 890/8564 [00:02<00:25, 305.43 examples/s]Tokenizing train dataset:  11%|█         | 922/8564 [00:02<00:25, 302.45 examples/s]Tokenizing train dataset:  11%|█         | 953/8564 [00:03<00:25, 303.51 examples/s]Tokenizing train dataset:  12%|█▏        | 997/8564 [00:03<00:25, 294.47 examples/s]Tokenizing train dataset:  12%|█▏        | 1040/8564 [00:03<00:26, 285.14 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:03<00:25, 292.90 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:03<00:24, 306.63 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:03<00:25, 293.54 examples/s]Tokenizing train dataset:  14%|█▍        | 1181/8564 [00:03<00:25, 294.30 examples/s]Tokenizing train dataset:  14%|█▍        | 1214/8564 [00:03<00:24, 298.51 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:04<00:23, 312.70 examples/s]Tokenizing train dataset:  15%|█▌        | 1299/8564 [00:04<00:23, 313.73 examples/s]Tokenizing train dataset:  16%|█▌        | 1331/8564 [00:04<00:23, 312.44 examples/s]Tokenizing train dataset:  16%|█▌        | 1373/8564 [00:04<00:24, 296.29 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:04<00:23, 302.47 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:04<00:23, 298.31 examples/s]Tokenizing train dataset:  17%|█▋        | 1498/8564 [00:04<00:23, 295.62 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:05<00:23, 295.59 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:05<00:23, 296.43 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:05<00:23, 292.16 examples/s]Tokenizing train dataset:  19%|█▉        | 1627/8564 [00:05<00:22, 302.62 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:05<00:22, 310.40 examples/s]Tokenizing train dataset:  20%|█▉        | 1702/8564 [00:05<00:20, 337.68 examples/s]Tokenizing train dataset:  20%|██        | 1751/8564 [00:05<00:20, 326.44 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:05<00:21, 320.20 examples/s]Tokenizing train dataset:  21%|██▏       | 1833/8564 [00:05<00:20, 321.83 examples/s]Tokenizing train dataset:  22%|██▏       | 1877/8564 [00:06<00:21, 308.10 examples/s]Tokenizing train dataset:  22%|██▏       | 1919/8564 [00:06<00:20, 331.96 examples/s]Tokenizing train dataset:  23%|██▎       | 1956/8564 [00:06<00:19, 338.82 examples/s]Tokenizing train dataset:  23%|██▎       | 1991/8564 [00:06<00:19, 340.71 examples/s]Tokenizing train dataset:  24%|██▎       | 2030/8564 [00:06<00:18, 352.20 examples/s]Tokenizing train dataset:  24%|██▍       | 2069/8564 [00:06<00:18, 357.65 examples/s]Tokenizing train dataset:  25%|██▍       | 2106/8564 [00:06<00:17, 359.24 examples/s]Tokenizing train dataset:  25%|██▌       | 2146/8564 [00:06<00:17, 368.63 examples/s]Tokenizing train dataset:  26%|██▌       | 2199/8564 [00:06<00:17, 361.53 examples/s]Tokenizing train dataset:  26%|██▌       | 2237/8564 [00:07<00:17, 364.02 examples/s]Tokenizing train dataset:  27%|██▋       | 2278/8564 [00:07<00:16, 375.67 examples/s]Tokenizing train dataset:  27%|██▋       | 2332/8564 [00:07<00:17, 363.90 examples/s]Tokenizing train dataset:  28%|██▊       | 2386/8564 [00:07<00:17, 360.30 examples/s]Tokenizing train dataset:  28%|██▊       | 2427/8564 [00:07<00:16, 369.85 examples/s]Tokenizing train dataset:  29%|██▉       | 2466/8564 [00:07<00:16, 370.43 examples/s]Tokenizing train dataset:  29%|██▉       | 2515/8564 [00:07<00:17, 354.34 examples/s]Tokenizing train dataset:  30%|██▉       | 2560/8564 [00:07<00:16, 374.10 examples/s]Tokenizing train dataset:  31%|███       | 2615/8564 [00:08<00:16, 367.22 examples/s]Tokenizing train dataset:  31%|███       | 2661/8564 [00:08<00:17, 344.58 examples/s]Tokenizing train dataset:  32%|███▏      | 2716/8564 [00:08<00:16, 346.46 examples/s]Tokenizing train dataset:  32%|███▏      | 2768/8564 [00:08<00:16, 341.37 examples/s]Tokenizing train dataset:  33%|███▎      | 2808/8564 [00:08<00:16, 352.15 examples/s]Tokenizing train dataset:  33%|███▎      | 2844/8564 [00:08<00:16, 351.76 examples/s]Tokenizing train dataset:  34%|███▍      | 2900/8564 [00:08<00:16, 352.35 examples/s]Tokenizing train dataset:  34%|███▍      | 2944/8564 [00:09<00:15, 371.89 examples/s]Tokenizing train dataset:  35%|███▍      | 2989/8564 [00:09<00:14, 387.83 examples/s]Tokenizing train dataset:  36%|███▌      | 3042/8564 [00:09<00:14, 373.76 examples/s]Tokenizing train dataset:  36%|███▌      | 3093/8564 [00:09<00:15, 358.81 examples/s]Tokenizing train dataset:  37%|███▋      | 3147/8564 [00:09<00:15, 357.61 examples/s]Tokenizing train dataset:  37%|███▋      | 3203/8564 [00:09<00:14, 359.10 examples/s]Tokenizing train dataset:  38%|███▊      | 3242/8564 [00:09<00:14, 364.11 examples/s]Tokenizing train dataset:  38%|███▊      | 3280/8564 [00:09<00:14, 362.41 examples/s]Tokenizing train dataset:  39%|███▉      | 3330/8564 [00:10<00:14, 350.17 examples/s]Tokenizing train dataset:  39%|███▉      | 3370/8564 [00:10<00:14, 354.90 examples/s]Tokenizing train dataset:  40%|███▉      | 3414/8564 [00:10<00:13, 371.52 examples/s]Tokenizing train dataset:  40%|████      | 3452/8564 [00:10<00:13, 369.72 examples/s]Tokenizing train dataset:  41%|████      | 3512/8564 [00:10<00:13, 378.26 examples/s]Tokenizing train dataset:  42%|████▏     | 3564/8564 [00:10<00:13, 363.96 examples/s]Tokenizing train dataset:  42%|████▏     | 3606/8564 [00:10<00:13, 376.16 examples/s]Tokenizing train dataset:  43%|████▎     | 3658/8564 [00:10<00:13, 364.94 examples/s]Tokenizing train dataset:  43%|████▎     | 3712/8564 [00:11<00:13, 357.96 examples/s]Tokenizing train dataset:  44%|████▍     | 3752/8564 [00:11<00:13, 365.09 examples/s]Tokenizing train dataset:  44%|████▍     | 3790/8564 [00:11<00:13, 367.08 examples/s]Tokenizing train dataset:  45%|████▍     | 3842/8564 [00:11<00:13, 357.94 examples/s]Tokenizing train dataset:  45%|████▌     | 3893/8564 [00:11<00:13, 348.83 examples/s]Tokenizing train dataset:  46%|████▌     | 3930/8564 [00:11<00:14, 311.68 examples/s]Tokenizing train dataset:  46%|████▋     | 3964/8564 [00:11<00:14, 314.93 examples/s]Tokenizing train dataset:  47%|████▋     | 4011/8564 [00:12<00:14, 311.04 examples/s]Tokenizing train dataset:  47%|████▋     | 4059/8564 [00:12<00:14, 309.62 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:12<00:14, 316.14 examples/s]Tokenizing train dataset:  48%|████▊     | 4150/8564 [00:12<00:14, 299.10 examples/s]Tokenizing train dataset:  49%|████▉     | 4186/8564 [00:12<00:14, 310.86 examples/s]Tokenizing train dataset:  49%|████▉     | 4219/8564 [00:12<00:13, 313.99 examples/s]Tokenizing train dataset:  50%|████▉     | 4270/8564 [00:12<00:13, 318.46 examples/s]Tokenizing train dataset:  50%|█████     | 4315/8564 [00:13<00:13, 309.51 examples/s]Tokenizing train dataset:  51%|█████     | 4359/8564 [00:13<00:13, 301.30 examples/s]Tokenizing train dataset:  51%|█████▏    | 4393/8564 [00:13<00:13, 306.73 examples/s]Tokenizing train dataset:  52%|█████▏    | 4429/8564 [00:13<00:13, 316.42 examples/s]Tokenizing train dataset:  52%|█████▏    | 4479/8564 [00:13<00:12, 321.56 examples/s]Tokenizing train dataset:  53%|█████▎    | 4529/8564 [00:13<00:12, 319.09 examples/s]Tokenizing train dataset:  53%|█████▎    | 4564/8564 [00:13<00:12, 323.47 examples/s]Tokenizing train dataset:  54%|█████▍    | 4610/8564 [00:13<00:12, 314.17 examples/s]Tokenizing train dataset:  54%|█████▍    | 4654/8564 [00:14<00:12, 304.28 examples/s]Tokenizing train dataset:  55%|█████▍    | 4698/8564 [00:14<00:12, 297.88 examples/s]Tokenizing train dataset:  55%|█████▌    | 4745/8564 [00:14<00:12, 298.67 examples/s]Tokenizing train dataset:  56%|█████▌    | 4790/8564 [00:14<00:12, 295.72 examples/s]Tokenizing train dataset:  57%|█████▋    | 4840/8564 [00:14<00:11, 338.33 examples/s]Tokenizing train dataset:  57%|█████▋    | 4882/8564 [00:14<00:10, 356.60 examples/s]Tokenizing train dataset:  58%|█████▊    | 4946/8564 [00:14<00:08, 423.72 examples/s]Tokenizing train dataset:  58%|█████▊    | 4993/8564 [00:15<00:08, 432.66 examples/s]Tokenizing train dataset:  59%|█████▉    | 5053/8564 [00:15<00:07, 477.68 examples/s]Tokenizing train dataset:  60%|█████▉    | 5107/8564 [00:15<00:07, 493.58 examples/s]Tokenizing train dataset:  60%|██████    | 5172/8564 [00:15<00:06, 536.72 examples/s]Tokenizing train dataset:  61%|██████    | 5234/8564 [00:15<00:06, 551.70 examples/s]Tokenizing train dataset:  62%|██████▏   | 5308/8564 [00:15<00:06, 474.71 examples/s]Tokenizing train dataset:  63%|██████▎   | 5362/8564 [00:15<00:06, 488.64 examples/s]Tokenizing train dataset:  64%|██████▎   | 5443/8564 [00:15<00:06, 502.37 examples/s]Tokenizing train dataset:  64%|██████▍   | 5495/8564 [00:15<00:06, 504.02 examples/s]Tokenizing train dataset:  65%|██████▍   | 5551/8564 [00:16<00:05, 511.74 examples/s]Tokenizing train dataset:  66%|██████▌   | 5616/8564 [00:16<00:05, 544.18 examples/s]Tokenizing train dataset:  66%|██████▋   | 5676/8564 [00:16<00:05, 557.38 examples/s]Tokenizing train dataset:  67%|██████▋   | 5770/8564 [00:16<00:04, 576.94 examples/s]Tokenizing train dataset:  68%|██████▊   | 5831/8564 [00:16<00:04, 584.20 examples/s]Tokenizing train dataset:  69%|██████▉   | 5913/8564 [00:16<00:04, 565.31 examples/s]Tokenizing train dataset:  70%|██████▉   | 5977/8564 [00:16<00:04, 578.38 examples/s]Tokenizing train dataset:  71%|███████   | 6055/8564 [00:16<00:04, 551.97 examples/s]Tokenizing train dataset:  72%|███████▏  | 6144/8564 [00:17<00:04, 559.70 examples/s]Tokenizing train dataset:  72%|███████▏  | 6202/8564 [00:17<00:04, 562.53 examples/s]Tokenizing train dataset:  73%|███████▎  | 6261/8564 [00:17<00:04, 568.20 examples/s]Tokenizing train dataset:  74%|███████▍  | 6320/8564 [00:17<00:03, 571.73 examples/s]Tokenizing train dataset:  75%|███████▍  | 6388/8564 [00:17<00:03, 598.34 examples/s]Tokenizing train dataset:  75%|███████▌  | 6452/8564 [00:17<00:03, 532.86 examples/s]Tokenizing train dataset:  76%|███████▋  | 6532/8564 [00:17<00:03, 528.01 examples/s]Tokenizing train dataset:  77%|███████▋  | 6600/8564 [00:17<00:03, 498.74 examples/s]Tokenizing train dataset:  78%|███████▊  | 6680/8564 [00:18<00:03, 504.73 examples/s]Tokenizing train dataset:  79%|███████▊  | 6734/8564 [00:18<00:03, 510.07 examples/s]Tokenizing train dataset:  79%|███████▉  | 6799/8564 [00:18<00:03, 543.52 examples/s]Tokenizing train dataset:  80%|████████  | 6874/8564 [00:18<00:03, 525.93 examples/s]Tokenizing train dataset:  81%|████████  | 6951/8564 [00:18<00:03, 517.05 examples/s]Tokenizing train dataset:  82%|████████▏ | 7025/8564 [00:18<00:03, 507.15 examples/s]Tokenizing train dataset:  83%|████████▎ | 7107/8564 [00:18<00:02, 517.86 examples/s]Tokenizing train dataset:  84%|████████▎ | 7163/8564 [00:19<00:02, 525.53 examples/s]Tokenizing train dataset:  84%|████████▍ | 7222/8564 [00:19<00:02, 538.68 examples/s]Tokenizing train dataset:  85%|████████▍ | 7279/8564 [00:19<00:02, 546.18 examples/s]Tokenizing train dataset:  86%|████████▌ | 7336/8564 [00:19<00:02, 550.91 examples/s]Tokenizing train dataset:  87%|████████▋ | 7420/8564 [00:19<00:02, 549.54 examples/s]Tokenizing train dataset:  87%|████████▋ | 7480/8564 [00:19<00:01, 558.58 examples/s]Tokenizing train dataset:  88%|████████▊ | 7543/8564 [00:19<00:01, 574.00 examples/s]Tokenizing train dataset:  89%|████████▉ | 7609/8564 [00:19<00:01, 593.49 examples/s]Tokenizing train dataset:  90%|████████▉ | 7683/8564 [00:19<00:01, 549.91 examples/s]Tokenizing train dataset:  91%|█████████ | 7763/8564 [00:20<00:01, 539.76 examples/s]Tokenizing train dataset:  91%|█████████▏| 7827/8564 [00:20<00:01, 500.42 examples/s]Tokenizing train dataset:  92%|█████████▏| 7882/8564 [00:20<00:01, 511.64 examples/s]Tokenizing train dataset:  93%|█████████▎| 7945/8564 [00:20<00:01, 457.53 examples/s]Tokenizing train dataset:  93%|█████████▎| 8004/8564 [00:20<00:01, 487.23 examples/s]Tokenizing train dataset:  94%|█████████▍| 8055/8564 [00:20<00:01, 492.73 examples/s]Tokenizing train dataset:  95%|█████████▍| 8128/8564 [00:20<00:00, 486.21 examples/s]Tokenizing train dataset:  96%|█████████▌| 8193/8564 [00:21<00:00, 524.56 examples/s]Tokenizing train dataset:  97%|█████████▋| 8280/8564 [00:21<00:00, 538.44 examples/s]Tokenizing train dataset:  97%|█████████▋| 8341/8564 [00:21<00:00, 554.21 examples/s]Tokenizing train dataset:  98%|█████████▊| 8411/8564 [00:21<00:00, 521.11 examples/s]Tokenizing train dataset:  99%|█████████▉| 8497/8564 [00:21<00:00, 532.15 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:21<00:00, 533.84 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:21<00:00, 394.28 examples/s]
[rank0]:[W531 11:28:23.974554968 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  78%|███████▊  | 745/953 [00:00<00:00, 7361.13 examples/s]Extracting prompt in train dataset:   6%|▌         | 510/8564 [00:00<00:01, 4904.66 examples/s]Extracting prompt in train dataset:   6%|▌         | 500/8564 [00:00<00:01, 4863.09 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 6321.04 examples/s]
Extracting prompt in train dataset:   2%|▏         | 180/8564 [00:00<00:04, 1687.23 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1030/8564 [00:00<00:01, 5091.70 examples/s]Extracting prompt in train dataset:  15%|█▍        | 1260/8564 [00:00<00:01, 4924.75 examples/s]Extracting prompt in train dataset:   4%|▍         | 370/8564 [00:00<00:05, 1572.28 examples/s]Extracting prompt in train dataset:   7%|▋         | 571/8564 [00:00<00:04, 1745.63 examples/s]Extracting prompt in train dataset:  19%|█▊        | 1600/8564 [00:00<00:01, 4091.76 examples/s]Extracting prompt in train dataset:  21%|██▏       | 1820/8564 [00:00<00:01, 4258.57 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2105/8564 [00:00<00:01, 4393.08 examples/s]Extracting prompt in train dataset:  11%|█         | 909/8564 [00:00<00:03, 1976.63 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  29%|██▉       | 2510/8564 [00:00<00:01, 4385.97 examples/s]Extracting prompt in train dataset:  31%|███       | 2614/8564 [00:00<00:01, 4606.38 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 12288.71 examples/s]
Extracting prompt in train dataset:  14%|█▍        | 1221/8564 [00:00<00:03, 2326.82 examples/s]Extracting prompt in train dataset:  35%|███▍      | 2960/8564 [00:00<00:01, 4410.26 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3371/8564 [00:00<00:01, 4778.96 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3580/8564 [00:00<00:01, 4290.00 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1620/8564 [00:00<00:03, 2043.54 examples/s]Extracting prompt in train dataset:  46%|████▌     | 3930/8564 [00:00<00:00, 4991.57 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1954/8564 [00:00<00:02, 2350.24 examples/s]Extracting prompt in train dataset:  50%|█████     | 4300/8564 [00:00<00:00, 4453.56 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 4686/8564 [00:00<00:00, 5008.72 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  27%|██▋       | 2330/8564 [00:01<00:02, 2705.55 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4780/8564 [00:01<00:00, 4535.45 examples/s]Extracting prompt in train dataset:  61%|██████▏   | 5250/8564 [00:01<00:00, 5157.70 examples/s]Tokenizing eval dataset:   3%|▎         | 33/953 [00:00<00:02, 318.36 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2792/8564 [00:01<00:02, 2827.92 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5390/8564 [00:01<00:00, 3907.46 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5832/8564 [00:01<00:00, 4347.30 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3180/8564 [00:01<00:01, 3087.88 examples/s]Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:03, 256.56 examples/s]Extracting prompt in train dataset:  69%|██████▊   | 5875/8564 [00:01<00:00, 4113.26 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 6387/8564 [00:01<00:00, 4636.17 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3610/8564 [00:01<00:01, 3398.37 examples/s]Tokenizing eval dataset:  10%|█         | 96/953 [00:00<00:03, 261.14 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 6460/8564 [00:01<00:00, 4527.92 examples/s]Extracting prompt in train dataset:  80%|████████  | 6890/8564 [00:01<00:00, 4730.98 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4035/8564 [00:01<00:01, 3625.49 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 7030/8564 [00:01<00:00, 4829.82 examples/s]Tokenizing eval dataset:  14%|█▍        | 133/953 [00:00<00:03, 248.27 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4430/8564 [00:01<00:01, 3703.50 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7645/8564 [00:01<00:00, 4834.39 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7564/8564 [00:01<00:00, 4956.89 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 5000/8564 [00:01<00:00, 3723.66 examples/s]Tokenizing eval dataset:  18%|█▊        | 168/953 [00:00<00:03, 237.97 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5470/8564 [00:01<00:00, 3957.18 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8430/8564 [00:01<00:00, 4196.37 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8360/8564 [00:01<00:00, 4357.06 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 4551.93 examples/s]
Tokenizing eval dataset:  21%|██        | 196/953 [00:00<00:03, 217.84 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 4416.99 examples/s]
Extracting prompt in train dataset:  69%|██████▉   | 5938/8564 [00:01<00:00, 4141.40 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:00<00:02, 256.42 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 6404/8564 [00:02<00:00, 4282.99 examples/s]Tokenizing eval dataset:  31%|███       | 295/953 [00:01<00:01, 343.88 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 6991/8564 [00:02<00:00, 4133.46 examples/s]Tokenizing eval dataset:  37%|███▋      | 355/953 [00:01<00:01, 411.51 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7480/8564 [00:02<00:00, 4307.76 examples/s]Tokenizing eval dataset:  43%|████▎     | 409/953 [00:01<00:01, 445.18 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7980/8564 [00:02<00:00, 3910.75 examples/s]Tokenizing eval dataset:  50%|█████     | 479/953 [00:01<00:01, 450.80 examples/s]Applying chat template to train dataset:   3%|▎         | 279/8564 [00:00<00:03, 2759.32 examples/s]Applying chat template to train dataset:   3%|▎         | 290/8564 [00:00<00:02, 2859.44 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8467/8564 [00:02<00:00, 4142.01 examples/s]Tokenizing eval dataset:  57%|█████▋    | 540/953 [00:01<00:00, 489.78 examples/s]Applying chat template to train dataset:   7%|▋         | 570/8564 [00:00<00:02, 2837.01 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3311.89 examples/s]
Applying chat template to train dataset:   7%|▋         | 594/8564 [00:00<00:02, 2960.89 examples/s]Applying chat template to train dataset:  10%|█         | 869/8564 [00:00<00:02, 2899.74 examples/s]Tokenizing eval dataset:  65%|██████▍   | 615/953 [00:01<00:00, 491.40 examples/s]Applying chat template to train dataset:  12%|█▏        | 1043/8564 [00:00<00:02, 2975.25 examples/s]Applying chat template to train dataset:  15%|█▌        | 1291/8564 [00:00<00:02, 2852.37 examples/s]Tokenizing eval dataset:  72%|███████▏  | 689/953 [00:01<00:00, 487.39 examples/s]Applying chat template to train dataset:  17%|█▋        | 1444/8564 [00:00<00:02, 2836.25 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:  19%|█▉        | 1660/8564 [00:00<00:02, 2682.64 examples/s]Applying chat template to train dataset:  20%|██        | 1733/8564 [00:00<00:02, 2848.84 examples/s]Tokenizing eval dataset:  80%|███████▉  | 759/953 [00:01<00:00, 478.39 examples/s]Applying chat template to train dataset:   3%|▎         | 250/8564 [00:00<00:03, 2468.06 examples/s]Applying chat template to train dataset:  23%|██▎       | 2010/8564 [00:00<00:02, 2547.59 examples/s]Applying chat template to train dataset:  25%|██▍       | 2130/8564 [00:00<00:02, 2763.91 examples/s]Tokenizing eval dataset:  86%|████████▌ | 821/953 [00:02<00:00, 453.69 examples/s]Applying chat template to train dataset:   6%|▋         | 536/8564 [00:00<00:02, 2693.56 examples/s]Applying chat template to train dataset:  27%|██▋       | 2280/8564 [00:00<00:02, 2582.77 examples/s]Applying chat template to train dataset:  28%|██▊       | 2435/8564 [00:00<00:02, 2837.50 examples/s]Tokenizing eval dataset:  93%|█████████▎| 890/953 [00:02<00:00, 450.96 examples/s]Applying chat template to train dataset:  30%|██▉       | 2546/8564 [00:00<00:02, 2602.06 examples/s]Applying chat template to train dataset:  32%|███▏      | 2745/8564 [00:00<00:02, 2907.66 examples/s]Applying chat template to train dataset:  11%|█         | 921/8564 [00:00<00:02, 2617.82 examples/s]Tokenizing eval dataset:  99%|█████████▊| 939/953 [00:02<00:00, 455.96 examples/s]Applying chat template to train dataset:  34%|███▎      | 2890/8564 [00:01<00:02, 2484.15 examples/s]Applying chat template to train dataset:  36%|███▌      | 3092/8564 [00:01<00:02, 2683.26 examples/s]Applying chat template to train dataset:  15%|█▌        | 1295/8564 [00:00<00:02, 2559.66 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 385.08 examples/s]
Applying chat template to train dataset:  38%|███▊      | 3286/8564 [00:01<00:02, 2534.55 examples/s]Applying chat template to train dataset:  41%|████      | 3519/8564 [00:01<00:01, 2736.65 examples/s]Applying chat template to train dataset:  20%|█▉        | 1671/8564 [00:00<00:02, 2535.40 examples/s]Applying chat template to train dataset:  42%|████▏     | 3571/8564 [00:01<00:01, 2610.74 examples/s]Applying chat template to train dataset:  44%|████▍     | 3800/8564 [00:01<00:01, 2749.39 examples/s]Applying chat template to train dataset:  23%|██▎       | 1949/8564 [00:00<00:02, 2599.47 examples/s]Applying chat template to train dataset:  47%|████▋     | 3984/8564 [00:01<00:01, 2657.22 examples/s]Applying chat template to train dataset:  49%|████▉     | 4224/8564 [00:01<00:01, 2774.49 examples/s]Applying chat template to train dataset:  27%|██▋       | 2276/8564 [00:00<00:02, 2354.33 examples/s]Applying chat template to train dataset:  50%|████▉     | 4281/8564 [00:01<00:01, 2731.40 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4533/8564 [00:01<00:01, 2850.78 examples/s]Applying chat template to train dataset:  30%|███       | 2574/8564 [00:01<00:02, 2509.69 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4579/8564 [00:01<00:01, 2792.63 examples/s]Applying chat template to train dataset:  56%|█████▋    | 4826/8564 [00:01<00:01, 2870.22 examples/s]Applying chat template to train dataset:  33%|███▎      | 2852/8564 [00:01<00:02, 2578.42 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5137/8564 [00:01<00:01, 2932.43 examples/s]Applying chat template to train dataset:  36%|███▋      | 3120/8564 [00:01<00:02, 2602.03 examples/s]Applying chat template to train dataset:  58%|█████▊    | 5003/8564 [00:01<00:01, 2802.31 examples/s]Applying chat template to train dataset:  40%|███▉      | 3407/8564 [00:01<00:01, 2676.93 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5309/8564 [00:01<00:01, 2865.90 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5585/8564 [00:01<00:01, 2948.83 examples/s]Applying chat template to train dataset:  43%|████▎     | 3716/8564 [00:01<00:01, 2791.54 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5610/8564 [00:02<00:01, 2902.65 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5896/8564 [00:02<00:00, 2989.00 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6210/8564 [00:02<00:00, 3026.49 examples/s]Applying chat template to train dataset:  48%|████▊     | 4142/8564 [00:01<00:01, 2804.80 examples/s]Applying chat template to train dataset:  71%|███████   | 6047/8564 [00:02<00:00, 2901.77 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6520/8564 [00:02<00:00, 3043.06 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4443/8564 [00:01<00:01, 2856.41 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6469/8564 [00:02<00:00, 2867.08 examples/s]Applying chat template to train dataset:  82%|████████▏ | 6984/8564 [00:02<00:00, 3055.73 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4883/8564 [00:01<00:01, 2881.08 examples/s]Applying chat template to train dataset:  80%|████████  | 6890/8564 [00:02<00:00, 2842.04 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7294/8564 [00:02<00:00, 3062.77 examples/s]Applying chat template to train dataset:  61%|██████▏   | 5250/8564 [00:01<00:01, 2731.54 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7296/8564 [00:02<00:00, 2793.58 examples/s]Applying chat template to train dataset:  90%|█████████ | 7750/8564 [00:02<00:00, 2953.22 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5561/8564 [00:02<00:01, 2823.37 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8063/8564 [00:02<00:00, 2993.48 examples/s]Applying chat template to train dataset:  69%|██████▊   | 5886/8564 [00:02<00:00, 2932.82 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7682/8564 [00:02<00:00, 2722.13 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8369/8564 [00:02<00:00, 3008.21 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6209/8564 [00:02<00:00, 3009.09 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8092/8564 [00:02<00:00, 2722.67 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 2892.50 examples/s]
Applying chat template to train dataset:  76%|███████▌  | 6530/8564 [00:02<00:00, 3061.64 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8369/8564 [00:03<00:00, 2731.03 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2719.53 examples/s]
Applying chat template to train dataset:  81%|████████  | 6952/8564 [00:02<00:00, 2967.52 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7350/8564 [00:02<00:00, 2855.87 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7662/8564 [00:02<00:00, 2919.78 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:  94%|█████████▎| 8018/8564 [00:02<00:00, 2727.59 examples/s]Tokenizing train dataset:   0%|          | 40/8564 [00:00<00:21, 387.98 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:  99%|█████████▊| 8441/8564 [00:03<00:00, 2756.20 examples/s]Tokenizing train dataset:   1%|          | 85/8564 [00:00<00:26, 320.83 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2731.10 examples/s]Tokenizing train dataset:   0%|          | 40/8564 [00:00<00:21, 388.01 examples/s]
Tokenizing train dataset:   1%|▏         | 119/8564 [00:00<00:31, 270.43 examples/s]Tokenizing train dataset:   1%|          | 82/8564 [00:00<00:27, 309.38 examples/s]Tokenizing train dataset:   2%|▏         | 156/8564 [00:00<00:32, 254.94 examples/s]Tokenizing train dataset:   1%|▏         | 120/8564 [00:00<00:30, 276.98 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   2%|▏         | 150/8564 [00:00<00:29, 283.60 examples/s]Tokenizing train dataset:   2%|▏         | 196/8564 [00:00<00:32, 256.58 examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:21, 399.63 examples/s]Tokenizing train dataset:   2%|▏         | 180/8564 [00:00<00:34, 246.24 examples/s]Tokenizing train dataset:   3%|▎         | 233/8564 [00:00<00:33, 250.59 examples/s]Tokenizing train dataset:   2%|▏         | 211/8564 [00:00<00:32, 259.98 examples/s]Tokenizing train dataset:   3%|▎         | 260/8564 [00:00<00:32, 253.80 examples/s]Tokenizing train dataset:   1%|          | 87/8564 [00:00<00:26, 320.91 examples/s]Tokenizing train dataset:   3%|▎         | 243/8564 [00:00<00:30, 274.90 examples/s]Tokenizing train dataset:   3%|▎         | 291/8564 [00:01<00:31, 266.10 examples/s]Tokenizing train dataset:   1%|▏         | 126/8564 [00:00<00:29, 283.34 examples/s]Tokenizing train dataset:   3%|▎         | 274/8564 [00:00<00:29, 280.97 examples/s]Tokenizing train dataset:   4%|▎         | 320/8564 [00:01<00:30, 268.88 examples/s]Tokenizing train dataset:   2%|▏         | 156/8564 [00:00<00:29, 285.61 examples/s]Tokenizing train dataset:   4%|▎         | 317/8564 [00:01<00:29, 278.69 examples/s]Tokenizing train dataset:   4%|▍         | 361/8564 [00:01<00:30, 265.38 examples/s]Tokenizing train dataset:   2%|▏         | 198/8564 [00:00<00:30, 278.10 examples/s]Tokenizing train dataset:   5%|▍         | 393/8564 [00:01<00:29, 275.10 examples/s]Tokenizing train dataset:   4%|▍         | 360/8564 [00:01<00:29, 276.90 examples/s]Tokenizing train dataset:   3%|▎         | 233/8564 [00:00<00:28, 294.88 examples/s]Tokenizing train dataset:   5%|▍         | 392/8564 [00:01<00:29, 280.88 examples/s]Tokenizing train dataset:   5%|▌         | 434/8564 [00:01<00:29, 271.75 examples/s]Tokenizing train dataset:   3%|▎         | 280/8564 [00:00<00:27, 296.27 examples/s]Tokenizing train dataset:   5%|▌         | 436/8564 [00:01<00:28, 282.01 examples/s]Tokenizing train dataset:   6%|▌         | 477/8564 [00:01<00:29, 274.16 examples/s]Tokenizing train dataset:   4%|▍         | 324/8564 [00:01<00:28, 291.01 examples/s]Tokenizing train dataset:   6%|▌         | 477/8564 [00:01<00:29, 274.85 examples/s]Tokenizing train dataset:   6%|▌         | 513/8564 [00:01<00:30, 262.52 examples/s]Tokenizing train dataset:   4%|▍         | 362/8564 [00:01<00:29, 276.84 examples/s]Tokenizing train dataset:   6%|▋         | 542/8564 [00:02<00:30, 266.71 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:01<00:31, 258.00 examples/s]Tokenizing train dataset:   5%|▍         | 393/8564 [00:01<00:28, 283.38 examples/s]Tokenizing train dataset:   7%|▋         | 583/8564 [00:02<00:29, 267.72 examples/s]Tokenizing train dataset:   6%|▋         | 548/8564 [00:02<00:33, 241.84 examples/s]Tokenizing train dataset:   5%|▌         | 429/8564 [00:01<00:37, 218.87 examples/s]Tokenizing train dataset:   7%|▋         | 614/8564 [00:02<00:35, 222.94 examples/s]Tokenizing train dataset:   7%|▋         | 580/8564 [00:02<00:35, 227.12 examples/s]Tokenizing train dataset:   8%|▊         | 649/8564 [00:02<00:31, 249.88 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:35, 229.88 examples/s]Tokenizing train dataset:   7%|▋         | 609/8564 [00:02<00:33, 238.81 examples/s]Tokenizing train dataset:   6%|▌         | 497/8564 [00:01<00:33, 238.47 examples/s]Tokenizing train dataset:   7%|▋         | 642/8564 [00:02<00:30, 259.19 examples/s]Tokenizing train dataset:   8%|▊         | 689/8564 [00:02<00:31, 251.85 examples/s]Tokenizing train dataset:   6%|▌         | 527/8564 [00:01<00:31, 251.16 examples/s]Tokenizing train dataset:   8%|▊         | 685/8564 [00:02<00:30, 262.10 examples/s]Tokenizing train dataset:   9%|▊         | 732/8564 [00:02<00:30, 259.21 examples/s]Tokenizing train dataset:   7%|▋         | 557/8564 [00:02<00:30, 258.86 examples/s]Tokenizing train dataset:   9%|▊         | 728/8564 [00:02<00:29, 267.13 examples/s]Tokenizing train dataset:   9%|▉         | 765/8564 [00:02<00:33, 231.76 examples/s]Tokenizing train dataset:   7%|▋         | 588/8564 [00:02<00:35, 226.31 examples/s]Tokenizing train dataset:   9%|▉         | 758/8564 [00:02<00:28, 271.95 examples/s]Tokenizing train dataset:   7%|▋         | 617/8564 [00:02<00:33, 238.24 examples/s]Tokenizing train dataset:   9%|▉         | 802/8564 [00:03<00:33, 233.84 examples/s]Tokenizing train dataset:   9%|▉         | 793/8564 [00:02<00:30, 254.03 examples/s]Tokenizing train dataset:   8%|▊         | 647/8564 [00:02<00:31, 251.79 examples/s]Tokenizing train dataset:  10%|▉         | 840/8564 [00:03<00:32, 236.42 examples/s]Tokenizing train dataset:  10%|▉         | 819/8564 [00:03<00:30, 252.51 examples/s]Tokenizing train dataset:   8%|▊         | 686/8564 [00:02<00:31, 251.69 examples/s]Tokenizing train dataset:  10%|█         | 866/8564 [00:03<00:32, 237.78 examples/s]Tokenizing train dataset:  10%|█         | 858/8564 [00:03<00:30, 251.57 examples/s]Tokenizing train dataset:  10%|█         | 894/8564 [00:03<00:31, 245.71 examples/s]Tokenizing train dataset:   8%|▊         | 726/8564 [00:02<00:30, 254.08 examples/s]Tokenizing train dataset:  10%|█         | 888/8564 [00:03<00:29, 260.82 examples/s]Tokenizing train dataset:  11%|█         | 923/8564 [00:03<00:38, 196.71 examples/s]Tokenizing train dataset:  11%|█         | 919/8564 [00:03<00:33, 225.66 examples/s]Tokenizing train dataset:   9%|▉         | 761/8564 [00:03<00:37, 209.27 examples/s]Tokenizing train dataset:  11%|█         | 955/8564 [00:03<00:37, 200.76 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:03<00:34, 218.53 examples/s]Tokenizing train dataset:   9%|▉         | 790/8564 [00:03<00:39, 198.85 examples/s]Tokenizing train dataset:  11%|█▏        | 981/8564 [00:03<00:35, 210.95 examples/s]Tokenizing train dataset:  11%|█▏        | 981/8564 [00:03<00:36, 206.84 examples/s]Tokenizing train dataset:  10%|▉         | 821/8564 [00:03<00:39, 198.09 examples/s]Tokenizing train dataset:  12%|█▏        | 1009/8564 [00:04<00:39, 190.98 examples/s]Tokenizing train dataset:  10%|▉         | 849/8564 [00:03<00:36, 214.09 examples/s]Tokenizing train dataset:  12%|█▏        | 1009/8564 [00:03<00:34, 219.18 examples/s]Tokenizing train dataset:  12%|█▏        | 1032/8564 [00:04<00:37, 199.43 examples/s]Tokenizing train dataset:  10%|█         | 878/8564 [00:03<00:33, 228.92 examples/s]Tokenizing train dataset:  12%|█▏        | 1042/8564 [00:04<00:34, 215.69 examples/s]Tokenizing train dataset:  12%|█▏        | 1060/8564 [00:04<00:34, 215.29 examples/s]Tokenizing train dataset:  11%|█         | 912/8564 [00:03<00:30, 254.11 examples/s]Tokenizing train dataset:  13%|█▎        | 1072/8564 [00:04<00:32, 232.49 examples/s]Tokenizing train dataset:  13%|█▎        | 1092/8564 [00:04<00:31, 238.97 examples/s]Tokenizing train dataset:  11%|█         | 939/8564 [00:03<00:29, 256.14 examples/s]Tokenizing train dataset:  13%|█▎        | 1104/8564 [00:04<00:29, 250.81 examples/s]Tokenizing train dataset:  13%|█▎        | 1120/8564 [00:04<00:30, 244.94 examples/s]Tokenizing train dataset:  11%|█▏        | 970/8564 [00:03<00:28, 265.07 examples/s]Tokenizing train dataset:  13%|█▎        | 1142/8564 [00:04<00:29, 247.60 examples/s]Tokenizing train dataset:  14%|█▎        | 1157/8564 [00:04<00:30, 240.22 examples/s]Tokenizing train dataset:  12%|█▏        | 1003/8564 [00:04<00:31, 242.54 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:04<00:30, 242.21 examples/s]Tokenizing train dataset:  14%|█▍        | 1194/8564 [00:04<00:30, 239.77 examples/s]Tokenizing train dataset:  12%|█▏        | 1036/8564 [00:04<00:32, 231.50 examples/s]Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:04<00:29, 247.08 examples/s]Tokenizing train dataset:  14%|█▍        | 1216/8564 [00:04<00:30, 244.55 examples/s]Tokenizing train dataset:  12%|█▏        | 1068/8564 [00:04<00:30, 247.31 examples/s]Tokenizing train dataset:  15%|█▍        | 1249/8564 [00:05<00:29, 252.03 examples/s]Tokenizing train dataset:  15%|█▍        | 1252/8564 [00:04<00:30, 240.99 examples/s]Tokenizing train dataset:  13%|█▎        | 1105/8564 [00:04<00:30, 244.54 examples/s]Tokenizing train dataset:  15%|█▍        | 1277/8564 [00:05<00:28, 256.34 examples/s]Tokenizing train dataset:  15%|█▍        | 1280/8564 [00:05<00:29, 247.99 examples/s]Tokenizing train dataset:  15%|█▌        | 1306/8564 [00:05<00:27, 263.54 examples/s]Tokenizing train dataset:  13%|█▎        | 1146/8564 [00:04<00:29, 248.71 examples/s]Tokenizing train dataset:  15%|█▌        | 1312/8564 [00:05<00:27, 263.25 examples/s]Tokenizing train dataset:  16%|█▌        | 1339/8564 [00:05<00:33, 217.33 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:04<00:34, 213.70 examples/s]Tokenizing train dataset:  16%|█▌        | 1344/8564 [00:05<00:31, 228.11 examples/s]Tokenizing train dataset:  14%|█▍        | 1205/8564 [00:04<00:32, 224.66 examples/s]Tokenizing train dataset:  16%|█▌        | 1373/8564 [00:05<00:33, 215.84 examples/s]Tokenizing train dataset:  16%|█▌        | 1380/8564 [00:05<00:31, 229.34 examples/s]Tokenizing train dataset:  14%|█▍        | 1236/8564 [00:05<00:30, 243.82 examples/s]Tokenizing train dataset:  16%|█▋        | 1403/8564 [00:05<00:30, 232.01 examples/s]Tokenizing train dataset:  16%|█▋        | 1408/8564 [00:05<00:30, 238.07 examples/s]Tokenizing train dataset:  15%|█▍        | 1269/8564 [00:05<00:28, 259.57 examples/s]Tokenizing train dataset:  17%|█▋        | 1435/8564 [00:05<00:29, 244.19 examples/s]Tokenizing train dataset:  17%|█▋        | 1440/8564 [00:05<00:30, 232.68 examples/s]Tokenizing train dataset:  15%|█▌        | 1311/8564 [00:05<00:27, 263.34 examples/s]Tokenizing train dataset:  17%|█▋        | 1467/8564 [00:06<00:29, 240.07 examples/s]Tokenizing train dataset:  17%|█▋        | 1473/8564 [00:05<00:28, 244.69 examples/s]Tokenizing train dataset:  16%|█▌        | 1345/8564 [00:05<00:32, 223.42 examples/s]Tokenizing train dataset:  17%|█▋        | 1496/8564 [00:06<00:33, 213.42 examples/s]Tokenizing train dataset:  18%|█▊        | 1505/8564 [00:06<00:30, 228.02 examples/s]Tokenizing train dataset:  16%|█▌        | 1370/8564 [00:05<00:31, 225.02 examples/s]Tokenizing train dataset:  18%|█▊        | 1525/8564 [00:06<00:30, 230.08 examples/s]Tokenizing train dataset:  18%|█▊        | 1543/8564 [00:06<00:30, 233.46 examples/s]Tokenizing train dataset:  18%|█▊        | 1550/8564 [00:06<00:29, 234.56 examples/s]Tokenizing train dataset:  16%|█▋        | 1400/8564 [00:05<00:29, 239.14 examples/s]Tokenizing train dataset:  18%|█▊        | 1568/8564 [00:06<00:29, 233.31 examples/s]Tokenizing train dataset:  19%|█▊        | 1589/8564 [00:06<00:28, 240.87 examples/s]Tokenizing train dataset:  17%|█▋        | 1438/8564 [00:05<00:29, 242.68 examples/s]Tokenizing train dataset:  19%|█▊        | 1596/8564 [00:06<00:28, 241.04 examples/s]Tokenizing train dataset:  19%|█▉        | 1620/8564 [00:06<00:27, 253.33 examples/s]Tokenizing train dataset:  17%|█▋        | 1470/8564 [00:05<00:30, 230.45 examples/s]Tokenizing train dataset:  19%|█▉        | 1630/8564 [00:06<00:29, 233.84 examples/s]Tokenizing train dataset:  19%|█▉        | 1652/8564 [00:06<00:25, 269.31 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:06<00:27, 247.82 examples/s]Tokenizing train dataset:  18%|█▊        | 1506/8564 [00:06<00:30, 229.99 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:06<00:24, 285.29 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:06<00:24, 278.71 examples/s]Tokenizing train dataset:  18%|█▊        | 1538/8564 [00:06<00:28, 247.73 examples/s]Tokenizing train dataset:  20%|██        | 1729/8564 [00:06<00:24, 278.44 examples/s]Tokenizing train dataset:  20%|██        | 1742/8564 [00:07<00:24, 279.56 examples/s]Tokenizing train dataset:  18%|█▊        | 1568/8564 [00:06<00:27, 256.28 examples/s]Tokenizing train dataset:  21%|██        | 1758/8564 [00:06<00:24, 276.31 examples/s]Tokenizing train dataset:  21%|██        | 1773/8564 [00:07<00:23, 284.92 examples/s]Tokenizing train dataset:  19%|█▉        | 1608/8564 [00:06<00:27, 255.12 examples/s]Tokenizing train dataset:  21%|██        | 1798/8564 [00:07<00:25, 270.60 examples/s]Tokenizing train dataset:  21%|██        | 1816/8564 [00:07<00:24, 280.73 examples/s]Tokenizing train dataset:  19%|█▉        | 1641/8564 [00:06<00:25, 268.46 examples/s]Tokenizing train dataset:  22%|██▏       | 1847/8564 [00:07<00:23, 284.70 examples/s]Tokenizing train dataset:  21%|██▏       | 1840/8564 [00:07<00:24, 271.05 examples/s]Tokenizing train dataset:  20%|█▉        | 1679/8564 [00:06<00:26, 258.81 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:07<00:24, 276.58 examples/s]Tokenizing train dataset:  20%|██        | 1714/8564 [00:06<00:24, 279.43 examples/s]Tokenizing train dataset:  22%|██▏       | 1877/8564 [00:07<00:25, 258.80 examples/s]Tokenizing train dataset:  22%|██▏       | 1919/8564 [00:07<00:23, 284.95 examples/s]Tokenizing train dataset:  20%|██        | 1753/8564 [00:07<00:25, 266.92 examples/s]Tokenizing train dataset:  23%|██▎       | 1927/8564 [00:07<00:23, 277.84 examples/s]Tokenizing train dataset:  23%|██▎       | 1958/8564 [00:07<00:24, 273.06 examples/s]Tokenizing train dataset:  21%|██        | 1784/8564 [00:07<00:24, 273.81 examples/s]Tokenizing train dataset:  23%|██▎       | 1959/8564 [00:07<00:23, 286.09 examples/s]Tokenizing train dataset:  23%|██▎       | 1991/8564 [00:07<00:23, 283.66 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:07<00:24, 274.96 examples/s]Tokenizing train dataset:  23%|██▎       | 1991/8564 [00:07<00:22, 291.98 examples/s]Tokenizing train dataset:  24%|██▎       | 2024/8564 [00:08<00:22, 294.08 examples/s]Tokenizing train dataset:  22%|██▏       | 1845/8564 [00:07<00:23, 280.71 examples/s]Tokenizing train dataset:  24%|██▎       | 2023/8564 [00:07<00:21, 298.10 examples/s]Tokenizing train dataset:  24%|██▍       | 2062/8564 [00:08<00:20, 312.37 examples/s]Tokenizing train dataset:  22%|██▏       | 1888/8564 [00:07<00:23, 279.62 examples/s]Tokenizing train dataset:  24%|██▍       | 2070/8564 [00:08<00:21, 299.27 examples/s]Tokenizing train dataset:  25%|██▍       | 2112/8564 [00:08<00:20, 318.33 examples/s]Tokenizing train dataset:  22%|██▏       | 1919/8564 [00:07<00:23, 284.03 examples/s]Tokenizing train dataset:  25%|██▍       | 2109/8564 [00:08<00:22, 282.05 examples/s]Tokenizing train dataset:  23%|██▎       | 1950/8564 [00:07<00:23, 285.50 examples/s]Tokenizing train dataset:  25%|██▌       | 2157/8564 [00:08<00:20, 308.36 examples/s]Tokenizing train dataset:  25%|██▌       | 2143/8564 [00:08<00:21, 293.69 examples/s]Tokenizing train dataset:  23%|██▎       | 1989/8564 [00:07<00:24, 273.36 examples/s]Tokenizing train dataset:  25%|██▌       | 2174/8564 [00:08<00:21, 296.48 examples/s]Tokenizing train dataset:  26%|██▌       | 2196/8564 [00:08<00:22, 288.01 examples/s]Tokenizing train dataset:  24%|██▎       | 2025/8564 [00:07<00:22, 292.92 examples/s]Tokenizing train dataset:  26%|██▌       | 2206/8564 [00:08<00:21, 299.68 examples/s]Tokenizing train dataset:  26%|██▌       | 2227/8564 [00:08<00:21, 290.49 examples/s]Tokenizing train dataset:  24%|██▍       | 2070/8564 [00:08<00:22, 292.58 examples/s]Tokenizing train dataset:  26%|██▌       | 2245/8564 [00:08<00:22, 279.01 examples/s]Tokenizing train dataset:  26%|██▋       | 2269/8564 [00:08<00:22, 283.30 examples/s]Tokenizing train dataset:  25%|██▍       | 2102/8564 [00:08<00:21, 294.84 examples/s]Tokenizing train dataset:  27%|██▋       | 2280/8564 [00:08<00:21, 291.47 examples/s]Tokenizing train dataset:  27%|██▋       | 2304/8564 [00:08<00:21, 297.51 examples/s]Tokenizing train dataset:  25%|██▍       | 2139/8564 [00:08<00:20, 313.15 examples/s]Tokenizing train dataset:  27%|██▋       | 2311/8564 [00:08<00:21, 293.06 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:09<00:21, 293.29 examples/s]Tokenizing train dataset:  26%|██▌       | 2187/8564 [00:08<00:20, 313.18 examples/s]Tokenizing train dataset:  27%|██▋       | 2351/8564 [00:09<00:22, 279.00 examples/s]Tokenizing train dataset:  28%|██▊       | 2391/8564 [00:09<00:21, 282.13 examples/s]Tokenizing train dataset:  26%|██▌       | 2220/8564 [00:08<00:20, 314.07 examples/s]Tokenizing train dataset:  28%|██▊       | 2388/8564 [00:09<00:20, 300.37 examples/s]Tokenizing train dataset:  28%|██▊       | 2424/8564 [00:09<00:21, 290.55 examples/s]Tokenizing train dataset:  26%|██▋       | 2256/8564 [00:08<00:19, 324.04 examples/s]Tokenizing train dataset:  28%|██▊       | 2420/8564 [00:09<00:20, 300.98 examples/s]Tokenizing train dataset:  27%|██▋       | 2296/8564 [00:08<00:18, 340.95 examples/s]Tokenizing train dataset:  29%|██▉       | 2473/8564 [00:09<00:20, 298.30 examples/s]Tokenizing train dataset:  29%|██▉       | 2468/8564 [00:09<00:20, 304.05 examples/s]Tokenizing train dataset:  27%|██▋       | 2339/8564 [00:08<00:19, 316.85 examples/s]Tokenizing train dataset:  29%|██▉       | 2519/8564 [00:09<00:20, 294.95 examples/s]Tokenizing train dataset:  29%|██▉       | 2510/8564 [00:09<00:20, 292.86 examples/s]Tokenizing train dataset:  30%|██▉       | 2556/8564 [00:09<00:19, 310.44 examples/s]Tokenizing train dataset:  28%|██▊       | 2381/8564 [00:09<00:20, 300.52 examples/s]Tokenizing train dataset:  30%|██▉       | 2549/8564 [00:09<00:19, 314.51 examples/s]Tokenizing train dataset:  30%|███       | 2590/8564 [00:09<00:18, 314.67 examples/s]Tokenizing train dataset:  28%|██▊       | 2419/8564 [00:09<00:19, 318.45 examples/s]Tokenizing train dataset:  30%|███       | 2585/8564 [00:09<00:18, 323.90 examples/s]Tokenizing train dataset:  29%|██▊       | 2455/8564 [00:09<00:18, 328.56 examples/s]Tokenizing train dataset:  31%|███       | 2635/8564 [00:10<00:19, 299.44 examples/s]Tokenizing train dataset:  31%|███       | 2629/8564 [00:09<00:19, 308.54 examples/s]Tokenizing train dataset:  29%|██▉       | 2500/8564 [00:09<00:19, 310.83 examples/s]Tokenizing train dataset:  31%|███       | 2671/8564 [00:10<00:21, 277.03 examples/s]Tokenizing train dataset:  31%|███       | 2668/8564 [00:10<00:20, 291.42 examples/s]Tokenizing train dataset:  30%|██▉       | 2535/8564 [00:09<00:18, 318.31 examples/s]Tokenizing train dataset:  32%|███▏      | 2702/8564 [00:10<00:20, 281.14 examples/s]Tokenizing train dataset:  32%|███▏      | 2698/8564 [00:10<00:20, 291.83 examples/s]Tokenizing train dataset:  32%|███▏      | 2733/8564 [00:10<00:20, 286.96 examples/s]Tokenizing train dataset:  30%|███       | 2578/8564 [00:09<00:19, 305.30 examples/s]Tokenizing train dataset:  32%|███▏      | 2731/8564 [00:10<00:19, 297.30 examples/s]Tokenizing train dataset:  32%|███▏      | 2778/8564 [00:10<00:20, 288.56 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:09<00:20, 290.81 examples/s]Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:10<00:19, 293.02 examples/s]Tokenizing train dataset:  33%|███▎      | 2807/8564 [00:10<00:19, 298.02 examples/s]Tokenizing train dataset:  33%|███▎      | 2825/8564 [00:10<00:19, 294.84 examples/s]Tokenizing train dataset:  31%|███       | 2661/8564 [00:10<00:20, 282.93 examples/s]Tokenizing train dataset:  33%|███▎      | 2855/8564 [00:10<00:19, 294.68 examples/s]Tokenizing train dataset:  31%|███▏      | 2693/8564 [00:10<00:20, 288.24 examples/s]Tokenizing train dataset:  33%|███▎      | 2848/8564 [00:10<00:19, 286.13 examples/s]Tokenizing train dataset:  32%|███▏      | 2727/8564 [00:10<00:19, 299.53 examples/s]Tokenizing train dataset:  34%|███▍      | 2904/8564 [00:11<00:18, 304.75 examples/s]Tokenizing train dataset:  34%|███▍      | 2899/8564 [00:10<00:19, 295.61 examples/s]Tokenizing train dataset:  34%|███▍      | 2944/8564 [00:11<00:17, 324.90 examples/s]Tokenizing train dataset:  32%|███▏      | 2773/8564 [00:10<00:19, 298.82 examples/s]Tokenizing train dataset:  34%|███▍      | 2939/8564 [00:10<00:17, 316.82 examples/s]Tokenizing train dataset:  35%|███▍      | 2985/8564 [00:11<00:16, 345.79 examples/s]Tokenizing train dataset:  33%|███▎      | 2810/8564 [00:10<00:18, 314.69 examples/s]Tokenizing train dataset:  35%|███▍      | 2980/8564 [00:11<00:16, 338.10 examples/s]Tokenizing train dataset:  35%|███▌      | 3029/8564 [00:11<00:17, 325.12 examples/s]Tokenizing train dataset:  33%|███▎      | 2859/8564 [00:10<00:18, 315.17 examples/s]Tokenizing train dataset:  35%|███▌      | 3021/8564 [00:11<00:17, 311.65 examples/s]Tokenizing train dataset:  34%|███▍      | 2895/8564 [00:10<00:17, 322.39 examples/s]Tokenizing train dataset:  36%|███▌      | 3075/8564 [00:11<00:17, 317.32 examples/s]Tokenizing train dataset:  36%|███▌      | 3066/8564 [00:11<00:18, 302.11 examples/s]Tokenizing train dataset:  34%|███▍      | 2949/8564 [00:10<00:16, 331.69 examples/s]Tokenizing train dataset:  36%|███▌      | 3098/8564 [00:11<00:18, 303.55 examples/s]Tokenizing train dataset:  36%|███▋      | 3122/8564 [00:11<00:17, 309.64 examples/s]Tokenizing train dataset:  35%|███▍      | 2990/8564 [00:11<00:16, 347.90 examples/s]Tokenizing train dataset:  37%|███▋      | 3141/8564 [00:11<00:18, 296.61 examples/s]Tokenizing train dataset:  37%|███▋      | 3164/8564 [00:11<00:18, 298.31 examples/s]Tokenizing train dataset:  35%|███▌      | 3034/8564 [00:11<00:17, 324.09 examples/s]Tokenizing train dataset:  37%|███▋      | 3187/8564 [00:11<00:18, 296.28 examples/s]Tokenizing train dataset:  37%|███▋      | 3210/8564 [00:12<00:18, 296.34 examples/s]Tokenizing train dataset:  36%|███▌      | 3083/8564 [00:11<00:17, 319.43 examples/s]Tokenizing train dataset:  38%|███▊      | 3217/8564 [00:11<00:18, 294.90 examples/s]Tokenizing train dataset:  38%|███▊      | 3243/8564 [00:12<00:17, 302.20 examples/s]Tokenizing train dataset:  36%|███▋      | 3117/8564 [00:11<00:16, 320.99 examples/s]Tokenizing train dataset:  38%|███▊      | 3253/8564 [00:12<00:17, 309.49 examples/s]Tokenizing train dataset:  38%|███▊      | 3277/8564 [00:12<00:17, 310.41 examples/s]Tokenizing train dataset:  37%|███▋      | 3153/8564 [00:11<00:16, 328.84 examples/s]Tokenizing train dataset:  38%|███▊      | 3287/8564 [00:12<00:16, 313.60 examples/s]Tokenizing train dataset:  39%|███▉      | 3323/8564 [00:12<00:17, 306.93 examples/s]Tokenizing train dataset:  37%|███▋      | 3205/8564 [00:11<00:16, 330.68 examples/s]Tokenizing train dataset:  39%|███▉      | 3330/8564 [00:12<00:17, 301.44 examples/s]Tokenizing train dataset:  39%|███▉      | 3370/8564 [00:12<00:17, 304.23 examples/s]Tokenizing train dataset:  38%|███▊      | 3252/8564 [00:11<00:16, 323.85 examples/s]Tokenizing train dataset:  39%|███▉      | 3375/8564 [00:12<00:17, 297.83 examples/s]Tokenizing train dataset:  40%|███▉      | 3411/8564 [00:12<00:15, 325.46 examples/s]Tokenizing train dataset:  40%|███▉      | 3413/8564 [00:12<00:16, 314.55 examples/s]Tokenizing train dataset:  39%|███▊      | 3298/8564 [00:12<00:16, 316.26 examples/s]Tokenizing train dataset:  40%|████      | 3449/8564 [00:12<00:17, 300.38 examples/s]Tokenizing train dataset:  40%|████      | 3465/8564 [00:12<00:15, 320.15 examples/s]Tokenizing train dataset:  39%|███▉      | 3348/8564 [00:12<00:16, 318.13 examples/s]Tokenizing train dataset:  41%|████      | 3493/8564 [00:12<00:17, 295.07 examples/s]Tokenizing train dataset:  41%|████      | 3500/8564 [00:12<00:17, 291.37 examples/s]Tokenizing train dataset:  41%|████      | 3527/8564 [00:13<00:16, 303.16 examples/s]Tokenizing train dataset:  40%|███▉      | 3400/8564 [00:12<00:16, 321.52 examples/s]Tokenizing train dataset:  41%|████      | 3530/8564 [00:12<00:17, 290.76 examples/s]Tokenizing train dataset:  42%|████▏     | 3560/8564 [00:13<00:18, 267.74 examples/s]Tokenizing train dataset:  40%|████      | 3441/8564 [00:12<00:16, 304.90 examples/s]Tokenizing train dataset:  42%|████▏     | 3560/8564 [00:13<00:17, 289.28 examples/s]Tokenizing train dataset:  42%|████▏     | 3595/8564 [00:13<00:17, 284.58 examples/s]Tokenizing train dataset:  41%|████      | 3478/8564 [00:12<00:16, 315.51 examples/s]Tokenizing train dataset:  42%|████▏     | 3598/8564 [00:13<00:15, 310.72 examples/s]Tokenizing train dataset:  42%|████▏     | 3629/8564 [00:13<00:16, 296.32 examples/s]Tokenizing train dataset:  41%|████      | 3517/8564 [00:12<00:15, 330.94 examples/s]Tokenizing train dataset:  42%|████▏     | 3633/8564 [00:13<00:15, 317.84 examples/s]Tokenizing train dataset:  43%|████▎     | 3662/8564 [00:13<00:18, 263.87 examples/s]Tokenizing train dataset:  42%|████▏     | 3570/8564 [00:12<00:16, 296.71 examples/s]Tokenizing train dataset:  43%|████▎     | 3692/8564 [00:13<00:17, 271.11 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:13<00:18, 260.98 examples/s]Tokenizing train dataset:  42%|████▏     | 3608/8564 [00:13<00:15, 312.82 examples/s]Tokenizing train dataset:  43%|████▎     | 3725/8564 [00:13<00:17, 284.24 examples/s]Tokenizing train dataset:  43%|████▎     | 3723/8564 [00:13<00:18, 264.23 examples/s]Tokenizing train dataset:  44%|████▍     | 3755/8564 [00:13<00:16, 284.44 examples/s]Tokenizing train dataset:  43%|████▎     | 3657/8564 [00:13<00:15, 313.59 examples/s]Tokenizing train dataset:  44%|████▍     | 3752/8564 [00:13<00:18, 267.04 examples/s]Tokenizing train dataset:  44%|████▍     | 3800/8564 [00:14<00:16, 284.18 examples/s]Tokenizing train dataset:  44%|████▍     | 3788/8564 [00:13<00:16, 286.54 examples/s]Tokenizing train dataset:  43%|████▎     | 3700/8564 [00:13<00:16, 299.77 examples/s]Tokenizing train dataset:  45%|████▍     | 3834/8564 [00:14<00:16, 293.09 examples/s]Tokenizing train dataset:  45%|████▍     | 3820/8564 [00:13<00:16, 293.51 examples/s]Tokenizing train dataset:  44%|████▎     | 3735/8564 [00:13<00:15, 309.84 examples/s]Tokenizing train dataset:  45%|████▌     | 3867/8564 [00:14<00:15, 301.73 examples/s]Tokenizing train dataset:  45%|████▌     | 3866/8564 [00:14<00:16, 293.15 examples/s]Tokenizing train dataset:  44%|████▍     | 3779/8564 [00:13<00:15, 301.69 examples/s]Tokenizing train dataset:  46%|████▌     | 3911/8564 [00:14<00:15, 294.46 examples/s]Tokenizing train dataset:  46%|████▌     | 3908/8564 [00:14<00:16, 285.56 examples/s]Tokenizing train dataset:  45%|████▍     | 3820/8564 [00:13<00:16, 288.07 examples/s]Tokenizing train dataset:  46%|████▌     | 3943/8564 [00:14<00:15, 297.16 examples/s]Tokenizing train dataset:  46%|████▌     | 3940/8564 [00:14<00:15, 292.17 examples/s]Tokenizing train dataset:  45%|████▌     | 3868/8564 [00:13<00:15, 296.24 examples/s]Tokenizing train dataset:  47%|████▋     | 3988/8564 [00:14<00:15, 292.34 examples/s]Tokenizing train dataset:  47%|████▋     | 3985/8564 [00:14<00:15, 291.52 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:14<00:15, 297.38 examples/s]Tokenizing train dataset:  46%|████▌     | 3915/8564 [00:14<00:15, 298.45 examples/s]Tokenizing train dataset:  47%|████▋     | 4034/8564 [00:14<00:15, 299.95 examples/s]Tokenizing train dataset:  46%|████▌     | 3960/8564 [00:14<00:15, 295.95 examples/s]Tokenizing train dataset:  48%|████▊     | 4068/8564 [00:14<00:15, 297.31 examples/s]Tokenizing train dataset:  48%|████▊     | 4068/8564 [00:14<00:14, 306.33 examples/s]Tokenizing train dataset:  47%|████▋     | 3994/8564 [00:14<00:15, 302.41 examples/s]Tokenizing train dataset:  48%|████▊     | 4113/8564 [00:15<00:15, 292.50 examples/s]Tokenizing train dataset:  48%|████▊     | 4117/8564 [00:14<00:14, 309.84 examples/s]Tokenizing train dataset:  47%|████▋     | 4032/8564 [00:14<00:14, 318.78 examples/s]Tokenizing train dataset:  49%|████▊     | 4158/8564 [00:15<00:14, 293.74 examples/s]Tokenizing train dataset:  49%|████▊     | 4159/8564 [00:15<00:14, 296.30 examples/s]Tokenizing train dataset:  48%|████▊     | 4070/8564 [00:14<00:15, 291.62 examples/s]Tokenizing train dataset:  49%|████▉     | 4202/8564 [00:15<00:14, 290.99 examples/s]Tokenizing train dataset:  49%|████▉     | 4206/8564 [00:15<00:14, 298.44 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:14<00:15, 280.07 examples/s]Tokenizing train dataset:  49%|████▉     | 4234/8564 [00:15<00:14, 293.06 examples/s]Tokenizing train dataset:  50%|████▉     | 4248/8564 [00:15<00:14, 290.62 examples/s]Tokenizing train dataset:  50%|████▉     | 4266/8564 [00:15<00:14, 297.37 examples/s]Tokenizing train dataset:  49%|████▊     | 4154/8564 [00:14<00:15, 281.67 examples/s]Tokenizing train dataset:  50%|█████     | 4282/8564 [00:15<00:14, 300.60 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:15<00:13, 306.60 examples/s]Tokenizing train dataset:  49%|████▉     | 4191/8564 [00:14<00:14, 298.15 examples/s]Tokenizing train dataset:  50%|█████     | 4313/8564 [00:15<00:14, 297.72 examples/s]Tokenizing train dataset:  49%|████▉     | 4222/8564 [00:15<00:14, 298.27 examples/s]Tokenizing train dataset:  51%|█████     | 4346/8564 [00:15<00:14, 299.04 examples/s]Tokenizing train dataset:  51%|█████     | 4356/8564 [00:15<00:14, 290.08 examples/s]Tokenizing train dataset:  50%|████▉     | 4266/8564 [00:15<00:14, 293.50 examples/s]Tokenizing train dataset:  51%|█████     | 4382/8564 [00:15<00:13, 311.16 examples/s]Tokenizing train dataset:  51%|█████▏    | 4391/8564 [00:15<00:13, 302.49 examples/s]Tokenizing train dataset:  50%|█████     | 4301/8564 [00:15<00:13, 304.86 examples/s]Tokenizing train dataset:  52%|█████▏    | 4414/8564 [00:16<00:13, 311.68 examples/s]Tokenizing train dataset:  52%|█████▏    | 4425/8564 [00:15<00:13, 309.71 examples/s]Tokenizing train dataset:  51%|█████     | 4336/8564 [00:15<00:13, 313.03 examples/s]Tokenizing train dataset:  52%|█████▏    | 4447/8564 [00:16<00:13, 312.45 examples/s]Tokenizing train dataset:  52%|█████▏    | 4475/8564 [00:16<00:13, 313.93 examples/s]Tokenizing train dataset:  51%|█████     | 4387/8564 [00:15<00:13, 320.02 examples/s]Tokenizing train dataset:  52%|█████▏    | 4489/8564 [00:16<00:13, 296.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 4423/8564 [00:15<00:12, 324.32 examples/s]Tokenizing train dataset:  53%|█████▎    | 4520/8564 [00:16<00:13, 306.72 examples/s]Tokenizing train dataset:  53%|█████▎    | 4537/8564 [00:16<00:13, 298.46 examples/s]Tokenizing train dataset:  53%|█████▎    | 4552/8564 [00:16<00:13, 307.38 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:15<00:13, 312.88 examples/s]Tokenizing train dataset:  53%|█████▎    | 4570/8564 [00:16<00:13, 299.83 examples/s]Tokenizing train dataset:  54%|█████▎    | 4597/8564 [00:16<00:13, 302.85 examples/s]Tokenizing train dataset:  53%|█████▎    | 4518/8564 [00:16<00:12, 313.31 examples/s]Tokenizing train dataset:  54%|█████▍    | 4615/8564 [00:16<00:13, 296.38 examples/s]Tokenizing train dataset:  53%|█████▎    | 4552/8564 [00:16<00:12, 318.56 examples/s]Tokenizing train dataset:  54%|█████▍    | 4640/8564 [00:16<00:13, 295.76 examples/s]Tokenizing train dataset:  54%|█████▍    | 4660/8564 [00:16<00:13, 293.65 examples/s]Tokenizing train dataset:  55%|█████▍    | 4670/8564 [00:16<00:13, 294.86 examples/s]Tokenizing train dataset:  54%|█████▎    | 4595/8564 [00:16<00:12, 305.65 examples/s]Tokenizing train dataset:  55%|█████▍    | 4702/8564 [00:17<00:13, 288.00 examples/s]Tokenizing train dataset:  55%|█████▌    | 4713/8564 [00:16<00:13, 289.29 examples/s]Tokenizing train dataset:  54%|█████▍    | 4637/8564 [00:16<00:13, 295.76 examples/s]Tokenizing train dataset:  55%|█████▌    | 4735/8564 [00:17<00:13, 294.09 examples/s]Tokenizing train dataset:  55%|█████▌    | 4744/8564 [00:17<00:13, 289.50 examples/s]Tokenizing train dataset:  55%|█████▍    | 4682/8564 [00:16<00:13, 296.41 examples/s]Tokenizing train dataset:  56%|█████▌    | 4772/8564 [00:17<00:13, 273.10 examples/s]Tokenizing train dataset:  56%|█████▌    | 4775/8564 [00:17<00:14, 259.26 examples/s]Tokenizing train dataset:  56%|█████▌    | 4806/8564 [00:17<00:13, 287.14 examples/s]Tokenizing train dataset:  55%|█████▌    | 4720/8564 [00:16<00:13, 278.46 examples/s]Tokenizing train dataset:  56%|█████▌    | 4817/8564 [00:17<00:12, 296.47 examples/s]Tokenizing train dataset:  57%|█████▋    | 4862/8564 [00:17<00:10, 353.00 examples/s]Tokenizing train dataset:  57%|█████▋    | 4864/8564 [00:17<00:10, 339.85 examples/s]Tokenizing train dataset:  56%|█████▌    | 4758/8564 [00:16<00:14, 268.14 examples/s]Tokenizing train dataset:  57%|█████▋    | 4912/8564 [00:17<00:09, 386.76 examples/s]Tokenizing train dataset:  58%|█████▊    | 4966/8564 [00:17<00:08, 424.86 examples/s]Tokenizing train dataset:  58%|█████▊    | 4931/8564 [00:17<00:09, 377.04 examples/s]Tokenizing train dataset:  56%|█████▌    | 4800/8564 [00:17<00:14, 268.74 examples/s]Tokenizing train dataset:  59%|█████▊    | 5025/8564 [00:17<00:07, 461.93 examples/s]Tokenizing train dataset:  58%|█████▊    | 4984/8564 [00:17<00:08, 409.09 examples/s]Tokenizing train dataset:  57%|█████▋    | 4850/8564 [00:17<00:11, 317.98 examples/s]Tokenizing train dataset:  59%|█████▉    | 5086/8564 [00:17<00:06, 499.87 examples/s]Tokenizing train dataset:  59%|█████▉    | 5040/8564 [00:17<00:08, 440.31 examples/s]Tokenizing train dataset:  57%|█████▋    | 4896/8564 [00:17<00:10, 348.68 examples/s]Tokenizing train dataset:  60%|██████    | 5143/8564 [00:18<00:06, 513.85 examples/s]Tokenizing train dataset:  59%|█████▉    | 5087/8564 [00:17<00:07, 444.33 examples/s]Tokenizing train dataset:  58%|█████▊    | 4943/8564 [00:17<00:09, 373.99 examples/s]Tokenizing train dataset:  61%|██████    | 5204/8564 [00:18<00:06, 537.36 examples/s]Tokenizing train dataset:  60%|██████    | 5147/8564 [00:17<00:07, 485.44 examples/s]Tokenizing train dataset:  58%|█████▊    | 5000/8564 [00:17<00:08, 423.21 examples/s]Tokenizing train dataset:  62%|██████▏   | 5273/8564 [00:18<00:05, 576.48 examples/s]Tokenizing train dataset:  61%|██████    | 5201/8564 [00:18<00:06, 498.77 examples/s]Tokenizing train dataset:  59%|█████▉    | 5060/8564 [00:17<00:07, 465.80 examples/s]Tokenizing train dataset:  62%|██████▏   | 5272/8564 [00:18<00:05, 552.36 examples/s]Tokenizing train dataset:  60%|█████▉    | 5111/8564 [00:17<00:07, 475.88 examples/s]Tokenizing train dataset:  63%|██████▎   | 5359/8564 [00:18<00:05, 570.63 examples/s]Tokenizing train dataset:  60%|██████    | 5162/8564 [00:17<00:07, 483.77 examples/s]Tokenizing train dataset:  63%|██████▎   | 5353/8564 [00:18<00:05, 547.13 examples/s]Tokenizing train dataset:  61%|██████    | 5226/8564 [00:17<00:06, 527.98 examples/s]Tokenizing train dataset:  64%|██████▎   | 5453/8564 [00:18<00:06, 503.15 examples/s]Tokenizing train dataset:  63%|██████▎   | 5431/8564 [00:18<00:05, 534.00 examples/s]Tokenizing train dataset:  62%|██████▏   | 5306/8564 [00:18<00:06, 525.16 examples/s]Tokenizing train dataset:  65%|██████▍   | 5532/8564 [00:18<00:06, 504.70 examples/s]Tokenizing train dataset:  64%|██████▍   | 5510/8564 [00:18<00:05, 526.15 examples/s]Tokenizing train dataset:  63%|██████▎   | 5362/8564 [00:18<00:06, 530.72 examples/s]Tokenizing train dataset:  66%|██████▌   | 5610/8564 [00:18<00:05, 504.19 examples/s]Tokenizing train dataset:  65%|██████▌   | 5597/8564 [00:18<00:05, 541.71 examples/s]Tokenizing train dataset:  64%|██████▎   | 5451/8564 [00:18<00:05, 551.48 examples/s]Tokenizing train dataset:  66%|██████▌   | 5665/8564 [00:19<00:05, 513.81 examples/s]Tokenizing train dataset:  66%|██████▌   | 5660/8564 [00:18<00:05, 561.16 examples/s]Tokenizing train dataset:  67%|██████▋   | 5718/8564 [00:19<00:05, 516.32 examples/s]Tokenizing train dataset:  65%|██████▍   | 5533/8564 [00:18<00:05, 542.04 examples/s]Tokenizing train dataset:  67%|██████▋   | 5743/8564 [00:19<00:05, 557.17 examples/s]Tokenizing train dataset:  67%|██████▋   | 5777/8564 [00:19<00:05, 533.73 examples/s]Tokenizing train dataset:  65%|██████▌   | 5590/8564 [00:18<00:05, 546.45 examples/s]Tokenizing train dataset:  68%|██████▊   | 5815/8564 [00:19<00:04, 595.35 examples/s]Tokenizing train dataset:  68%|██████▊   | 5837/8564 [00:19<00:04, 549.54 examples/s]Tokenizing train dataset:  66%|██████▌   | 5654/8564 [00:18<00:05, 566.23 examples/s]Tokenizing train dataset:  69%|██████▉   | 5889/8564 [00:19<00:04, 552.07 examples/s]Tokenizing train dataset:  69%|██████▉   | 5912/8564 [00:19<00:05, 529.19 examples/s]Tokenizing train dataset:  67%|██████▋   | 5739/8564 [00:18<00:05, 563.63 examples/s]Tokenizing train dataset:  69%|██████▉   | 5950/8564 [00:19<00:04, 558.82 examples/s]Tokenizing train dataset:  68%|██████▊   | 5801/8564 [00:18<00:04, 574.87 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [00:19<00:05, 498.95 examples/s]Tokenizing train dataset:  70%|███████   | 6022/8564 [00:19<00:04, 525.92 examples/s]Tokenizing train dataset:  69%|██████▊   | 5880/8564 [00:19<00:04, 554.81 examples/s]Tokenizing train dataset:  71%|███████   | 6059/8564 [00:19<00:04, 505.46 examples/s]Tokenizing train dataset:  71%|███████   | 6079/8564 [00:19<00:04, 534.42 examples/s]Tokenizing train dataset:  69%|██████▉   | 5943/8564 [00:19<00:04, 571.05 examples/s]Tokenizing train dataset:  72%|███████▏  | 6142/8564 [00:19<00:04, 516.75 examples/s]Tokenizing train dataset:  72%|███████▏  | 6160/8564 [00:19<00:04, 532.90 examples/s]Tokenizing train dataset:  70%|███████   | 6015/8564 [00:19<00:04, 532.60 examples/s]Tokenizing train dataset:  72%|███████▏  | 6196/8564 [00:20<00:04, 519.66 examples/s]Tokenizing train dataset:  73%|███████▎  | 6223/8564 [00:19<00:04, 554.84 examples/s]Tokenizing train dataset:  73%|███████▎  | 6263/8564 [00:20<00:04, 555.00 examples/s]Tokenizing train dataset:  71%|███████   | 6086/8564 [00:19<00:04, 509.58 examples/s]Tokenizing train dataset:  73%|███████▎  | 6283/8564 [00:20<00:04, 564.60 examples/s]Tokenizing train dataset:  72%|███████▏  | 6144/8564 [00:19<00:04, 524.71 examples/s]Tokenizing train dataset:  74%|███████▍  | 6349/8564 [00:20<00:03, 559.10 examples/s]Tokenizing train dataset:  74%|███████▍  | 6378/8564 [00:20<00:03, 584.17 examples/s]Tokenizing train dataset:  73%|███████▎  | 6215/8564 [00:19<00:04, 569.05 examples/s]Tokenizing train dataset:  75%|███████▍  | 6406/8564 [00:20<00:03, 556.71 examples/s]Tokenizing train dataset:  73%|███████▎  | 6280/8564 [00:19<00:03, 581.75 examples/s]Tokenizing train dataset:  75%|███████▌  | 6464/8564 [00:20<00:03, 578.76 examples/s]Tokenizing train dataset:  76%|███████▌  | 6487/8564 [00:20<00:03, 543.25 examples/s]Tokenizing train dataset:  74%|███████▍  | 6340/8564 [00:19<00:03, 584.48 examples/s]Tokenizing train dataset:  76%|███████▋  | 6548/8564 [00:20<00:03, 570.11 examples/s]Tokenizing train dataset:  77%|███████▋  | 6552/8564 [00:20<00:03, 504.76 examples/s]Tokenizing train dataset:  75%|███████▍  | 6410/8564 [00:20<00:04, 537.60 examples/s]Tokenizing train dataset:  77%|███████▋  | 6614/8564 [00:20<00:03, 528.35 examples/s]Tokenizing train dataset:  76%|███████▌  | 6467/8564 [00:20<00:03, 543.82 examples/s]Tokenizing train dataset:  77%|███████▋  | 6613/8564 [00:20<00:04, 469.71 examples/s]Tokenizing train dataset:  78%|███████▊  | 6678/8564 [00:20<00:04, 438.80 examples/s]Tokenizing train dataset:  76%|███████▌  | 6530/8564 [00:20<00:04, 435.93 examples/s]Tokenizing train dataset:  78%|███████▊  | 6678/8564 [00:21<00:04, 410.82 examples/s]Tokenizing train dataset:  79%|███████▊  | 6734/8564 [00:20<00:03, 462.36 examples/s]Tokenizing train dataset:  79%|███████▊  | 6734/8564 [00:21<00:04, 440.84 examples/s]Tokenizing train dataset:  77%|███████▋  | 6595/8564 [00:20<00:04, 433.44 examples/s]Tokenizing train dataset:  80%|███████▉  | 6809/8564 [00:21<00:03, 470.47 examples/s]Tokenizing train dataset:  79%|███████▉  | 6791/8564 [00:21<00:03, 469.91 examples/s]Tokenizing train dataset:  78%|███████▊  | 6642/8564 [00:20<00:04, 437.88 examples/s]Tokenizing train dataset:  80%|████████  | 6859/8564 [00:21<00:03, 475.73 examples/s]Tokenizing train dataset:  78%|███████▊  | 6701/8564 [00:20<00:03, 472.59 examples/s]Tokenizing train dataset:  80%|████████  | 6871/8564 [00:21<00:03, 488.09 examples/s]Tokenizing train dataset:  81%|████████  | 6942/8564 [00:21<00:03, 499.05 examples/s]Tokenizing train dataset:  81%|████████  | 6934/8564 [00:21<00:03, 519.94 examples/s]Tokenizing train dataset:  79%|███████▉  | 6778/8564 [00:20<00:03, 485.41 examples/s]Tokenizing train dataset:  82%|████████▏ | 7014/8564 [00:21<00:03, 487.00 examples/s]Tokenizing train dataset:  82%|████████▏ | 7008/8564 [00:21<00:03, 502.89 examples/s]Tokenizing train dataset:  80%|███████▉  | 6847/8564 [00:20<00:03, 474.50 examples/s]Tokenizing train dataset:  83%|████████▎ | 7071/8564 [00:21<00:02, 504.91 examples/s]Tokenizing train dataset:  82%|████████▏ | 7060/8564 [00:21<00:02, 502.76 examples/s]Tokenizing train dataset:  81%|████████  | 6908/8564 [00:21<00:03, 504.08 examples/s]Tokenizing train dataset:  83%|████████▎ | 7137/8564 [00:21<00:03, 443.02 examples/s]Tokenizing train dataset:  84%|████████▍ | 7188/8564 [00:21<00:03, 457.72 examples/s]Tokenizing train dataset:  83%|████████▎ | 7129/8564 [00:22<00:03, 367.21 examples/s]Tokenizing train dataset:  81%|████████▏ | 6970/8564 [00:21<00:04, 361.73 examples/s]Tokenizing train dataset:  85%|████████▍ | 7240/8564 [00:22<00:02, 465.84 examples/s]Tokenizing train dataset:  84%|████████▍ | 7190/8564 [00:22<00:03, 413.93 examples/s]Tokenizing train dataset:  82%|████████▏ | 7020/8564 [00:21<00:03, 386.24 examples/s]Tokenizing train dataset:  85%|████████▌ | 7294/8564 [00:22<00:02, 483.14 examples/s]Tokenizing train dataset:  83%|████████▎ | 7080/8564 [00:21<00:03, 430.18 examples/s]Tokenizing train dataset:  85%|████████▍ | 7260/8564 [00:22<00:03, 428.60 examples/s]Tokenizing train dataset:  83%|████████▎ | 7141/8564 [00:21<00:03, 470.12 examples/s]Tokenizing train dataset:  86%|████████▌ | 7376/8564 [00:22<00:02, 502.38 examples/s]Tokenizing train dataset:  86%|████████▌ | 7337/8564 [00:22<00:02, 451.59 examples/s]Tokenizing train dataset:  84%|████████▍ | 7203/8564 [00:21<00:02, 506.63 examples/s]Tokenizing train dataset:  87%|████████▋ | 7430/8564 [00:22<00:02, 510.80 examples/s]Tokenizing train dataset:  86%|████████▋ | 7393/8564 [00:22<00:02, 474.03 examples/s]Tokenizing train dataset:  85%|████████▌ | 7290/8564 [00:21<00:02, 523.89 examples/s]Tokenizing train dataset:  88%|████████▊ | 7508/8564 [00:22<00:02, 509.36 examples/s]Tokenizing train dataset:  87%|████████▋ | 7452/8564 [00:22<00:02, 500.64 examples/s]Tokenizing train dataset:  88%|████████▊ | 7577/8564 [00:22<00:01, 551.07 examples/s]Tokenizing train dataset:  88%|████████▊ | 7505/8564 [00:22<00:02, 505.65 examples/s]Tokenizing train dataset:  86%|████████▌ | 7373/8564 [00:22<00:02, 531.49 examples/s]Tokenizing train dataset:  89%|████████▉ | 7656/8564 [00:22<00:01, 535.37 examples/s]Tokenizing train dataset:  89%|████████▊ | 7590/8564 [00:22<00:01, 520.20 examples/s]Tokenizing train dataset:  87%|████████▋ | 7463/8564 [00:22<00:02, 547.31 examples/s]Tokenizing train dataset:  88%|████████▊ | 7520/8564 [00:22<00:01, 549.90 examples/s]Tokenizing train dataset:  90%|█████████ | 7734/8564 [00:22<00:01, 527.99 examples/s]Tokenizing train dataset:  89%|████████▉ | 7664/8564 [00:23<00:01, 508.59 examples/s]Tokenizing train dataset:  89%|████████▊ | 7590/8564 [00:22<00:01, 580.25 examples/s]Tokenizing train dataset:  91%|█████████ | 7810/8564 [00:23<00:01, 517.75 examples/s]Tokenizing train dataset:  90%|█████████ | 7742/8564 [00:23<00:01, 507.86 examples/s]Tokenizing train dataset:  90%|████████▉ | 7674/8564 [00:22<00:01, 567.88 examples/s]Tokenizing train dataset:  92%|█████████▏| 7894/8564 [00:23<00:01, 526.04 examples/s]Tokenizing train dataset:  91%|█████████ | 7808/8564 [00:23<00:01, 482.15 examples/s]Tokenizing train dataset:  91%|█████████ | 7755/8564 [00:22<00:01, 554.89 examples/s]Tokenizing train dataset:  92%|█████████▏| 7859/8564 [00:23<00:01, 484.83 examples/s]Tokenizing train dataset:  93%|█████████▎| 7974/8564 [00:23<00:01, 523.18 examples/s]Tokenizing train dataset:  92%|█████████▏| 7916/8564 [00:23<00:01, 503.50 examples/s]Tokenizing train dataset:  91%|█████████▏| 7832/8564 [00:22<00:01, 535.73 examples/s]Tokenizing train dataset:  94%|█████████▍| 8030/8564 [00:23<00:01, 528.49 examples/s]Tokenizing train dataset:  93%|█████████▎| 7994/8564 [00:23<00:01, 505.69 examples/s]Tokenizing train dataset:  92%|█████████▏| 7917/8564 [00:23<00:01, 542.46 examples/s]Tokenizing train dataset:  95%|█████████▍| 8106/8564 [00:23<00:00, 516.69 examples/s]Tokenizing train dataset:  94%|█████████▍| 8047/8564 [00:23<00:01, 508.01 examples/s]Tokenizing train dataset:  93%|█████████▎| 7976/8564 [00:23<00:01, 548.99 examples/s]Tokenizing train dataset:  95%|█████████▍| 8100/8564 [00:23<00:00, 512.88 examples/s]Tokenizing train dataset:  96%|█████████▌| 8181/8564 [00:23<00:00, 506.67 examples/s]Tokenizing train dataset:  94%|█████████▍| 8040/8564 [00:23<00:00, 566.48 examples/s]Tokenizing train dataset:  95%|█████████▌| 8153/8564 [00:24<00:00, 509.34 examples/s]Tokenizing train dataset:  97%|█████████▋| 8270/8564 [00:23<00:00, 529.20 examples/s]Tokenizing train dataset:  95%|█████████▍| 8107/8564 [00:23<00:00, 522.82 examples/s]Tokenizing train dataset:  96%|█████████▌| 8210/8564 [00:24<00:00, 521.40 examples/s]Tokenizing train dataset:  97%|█████████▋| 8330/8564 [00:24<00:00, 541.94 examples/s]Tokenizing train dataset:  97%|█████████▋| 8269/8564 [00:24<00:00, 537.86 examples/s]Tokenizing train dataset:  96%|█████████▌| 8190/8564 [00:23<00:00, 525.61 examples/s]Tokenizing train dataset:  98%|█████████▊| 8404/8564 [00:24<00:00, 522.42 examples/s]Tokenizing train dataset:  97%|█████████▋| 8332/8564 [00:24<00:00, 559.99 examples/s]Tokenizing train dataset:  96%|█████████▋| 8247/8564 [00:23<00:00, 535.30 examples/s]Tokenizing train dataset:  99%|█████████▉| 8459/8564 [00:24<00:00, 525.17 examples/s]Tokenizing train dataset:  97%|█████████▋| 8310/8564 [00:23<00:00, 557.95 examples/s]Tokenizing train dataset:  98%|█████████▊| 8409/8564 [00:24<00:00, 534.33 examples/s]Tokenizing train dataset:  99%|█████████▉| 8518/8564 [00:24<00:00, 540.22 examples/s]Tokenizing train dataset:  98%|█████████▊| 8387/8564 [00:23<00:00, 535.39 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:24<00:00, 349.21 examples/s]Tokenizing train dataset:  99%|█████████▉| 8490/8564 [00:24<00:00, 533.17 examples/s]
Tokenizing train dataset:  99%|█████████▉| 8458/8564 [00:24<00:00, 509.91 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:24<00:00, 531.50 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:24<00:00, 344.46 examples/s]
Tokenizing train dataset: 100%|█████████▉| 8526/8564 [00:24<00:00, 546.79 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:24<00:00, 352.66 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11205.16 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 10981.45 examples/s]
Extracting prompt in eval dataset:  82%|████████▏ | 780/953 [00:00<00:00, 7671.63 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 7624.77 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13491.97 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13640.32 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13242.51 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 322.94 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:03, 291.47 examples/s]Tokenizing eval dataset:   3%|▎         | 32/953 [00:00<00:03, 300.28 examples/s]Tokenizing eval dataset:   3%|▎         | 32/953 [00:00<00:03, 301.20 examples/s]Tokenizing eval dataset:  12%|█▏        | 118/953 [00:00<00:03, 277.51 examples/s]Tokenizing eval dataset:   8%|▊         | 72/953 [00:00<00:03, 268.35 examples/s]Tokenizing eval dataset:   8%|▊         | 72/953 [00:00<00:03, 269.51 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:00<00:03, 266.54 examples/s]Tokenizing eval dataset:  17%|█▋        | 158/953 [00:00<00:02, 267.60 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:00<00:03, 268.32 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:00<00:03, 259.61 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:00<00:02, 253.64 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:00<00:03, 261.25 examples/s]Tokenizing eval dataset:  24%|██▎       | 226/953 [00:00<00:02, 270.08 examples/s]Tokenizing eval dataset:  18%|█▊        | 176/953 [00:00<00:03, 247.43 examples/s]Tokenizing eval dataset:  18%|█▊        | 176/953 [00:00<00:03, 248.64 examples/s]Tokenizing eval dataset:  31%|███       | 292/953 [00:00<00:01, 371.93 examples/s]Tokenizing eval dataset:  37%|███▋      | 357/953 [00:01<00:01, 445.37 examples/s]Tokenizing eval dataset:  22%|██▏       | 214/953 [00:00<00:03, 246.02 examples/s]Tokenizing eval dataset:  22%|██▏       | 213/953 [00:00<00:03, 245.60 examples/s]Tokenizing eval dataset:  44%|████▍     | 419/953 [00:01<00:01, 492.49 examples/s]Tokenizing eval dataset:  29%|██▉       | 274/953 [00:00<00:02, 327.98 examples/s]Tokenizing eval dataset:  28%|██▊       | 270/953 [00:00<00:02, 325.57 examples/s]Tokenizing eval dataset:  51%|█████     | 488/953 [00:01<00:00, 545.28 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:01<00:01, 408.18 examples/s]Tokenizing eval dataset:  35%|███▌      | 336/953 [00:01<00:01, 410.44 examples/s]Tokenizing eval dataset:  58%|█████▊    | 556/953 [00:01<00:00, 579.22 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:01<00:01, 449.17 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:01<00:01, 452.15 examples/s]Tokenizing eval dataset:  65%|██████▌   | 620/953 [00:01<00:00, 591.86 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:01<00:00, 518.31 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:01<00:00, 520.13 examples/s]Tokenizing eval dataset:  72%|███████▏  | 685/953 [00:01<00:00, 603.64 examples/s]Tokenizing eval dataset:  55%|█████▌    | 528/953 [00:01<00:00, 534.03 examples/s]Tokenizing eval dataset:  55%|█████▌    | 528/953 [00:01<00:00, 536.30 examples/s]Tokenizing eval dataset:  63%|██████▎   | 597/953 [00:01<00:00, 576.31 examples/s]Tokenizing eval dataset:  63%|██████▎   | 596/953 [00:01<00:00, 576.55 examples/s]Tokenizing eval dataset:  81%|████████  | 769/953 [00:01<00:00, 579.69 examples/s]Tokenizing eval dataset:  69%|██████▉   | 658/953 [00:01<00:00, 584.62 examples/s]Tokenizing eval dataset:  69%|██████▉   | 658/953 [00:01<00:00, 586.33 examples/s]Tokenizing eval dataset:  88%|████████▊ | 841/953 [00:01<00:00, 542.53 examples/s]Tokenizing eval dataset:  78%|███████▊  | 740/953 [00:01<00:00, 562.21 examples/s]Tokenizing eval dataset:  78%|███████▊  | 740/953 [00:01<00:00, 564.02 examples/s]Tokenizing eval dataset:  96%|█████████▌| 913/953 [00:02<00:00, 517.35 examples/s]Tokenizing eval dataset:  85%|████████▌ | 813/953 [00:01<00:00, 530.71 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 457.28 examples/s]
Tokenizing eval dataset:  85%|████████▌ | 813/953 [00:01<00:00, 533.13 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  93%|█████████▎| 889/953 [00:02<00:00, 514.98 examples/s]Tokenizing eval dataset:  93%|█████████▎| 889/953 [00:02<00:00, 516.62 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 505.95 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 439.97 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 507.86 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 441.75 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/vresd/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/vresd/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.7496979236602783 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/vresd/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/vresd/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.325070381164551 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/vresd/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/vresd/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3411684036254883 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/vresd/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/vresd/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3274929523468018 seconds
[rank1]: Traceback (most recent call last):
[rank1]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 207, in <module>
[rank1]:     main(train_data, val_data, args.rank, args.learning_rate, args.total_epochs, args.beta)
[rank1]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 186, in main
[rank1]:     dpo_trainer.train()
[rank1]:   File "/transformers/src/transformers/trainer.py", line 2250, in train
[rank1]:     return inner_training_loop(
[rank1]:   File "/transformers/src/transformers/trainer.py", line 2374, in _inner_training_loop
[rank1]:     model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py", line 1383, in prepare
[rank1]:     result = self._prepare_deepspeed(*args)
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py", line 1924, in _prepare_deepspeed
[rank1]:     engine, optimizer, _, lr_scheduler = ds_initialize(**kwargs)
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/__init__.py", line 193, in initialize
[rank1]:     engine = DeepSpeedEngine(args=args,
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 273, in __init__
[rank1]:     self._configure_distributed_model(model)
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 1284, in _configure_distributed_model
[rank1]:     self._broadcast_model()
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 1202, in _broadcast_model
[rank1]:     dist.broadcast(p.data, groups._get_broadcast_src_rank(), group=self.seq_data_parallel_group)
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/comm/comm.py", line 117, in log_wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/comm/comm.py", line 224, in broadcast
[rank1]:     return cdb.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/comm/torch.py", line 206, in broadcast
[rank1]:     return torch.distributed.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[rank1]:     return func(*args, **kwargs)
[rank1]:   File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 2726, in broadcast
[rank1]:     work = group.broadcast([tensor], opts)
[rank1]: torch.distributed.DistBackendError: NCCL error in: /pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:268, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank1]: ncclUnhandledCudaError: Call to CUDA function failed.
[rank1]: Last error:
[rank1]: Cuda failure 2 'out of memory'
[rank2]: Traceback (most recent call last):
[rank2]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 207, in <module>
[rank2]:     main(train_data, val_data, args.rank, args.learning_rate, args.total_epochs, args.beta)
[rank2]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 186, in main
[rank2]:     dpo_trainer.train()
[rank2]:   File "/transformers/src/transformers/trainer.py", line 2250, in train
[rank2]:     return inner_training_loop(
[rank2]:   File "/transformers/src/transformers/trainer.py", line 2374, in _inner_training_loop
[rank2]:     model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py", line 1383, in prepare
[rank2]:     result = self._prepare_deepspeed(*args)
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py", line 1924, in _prepare_deepspeed
[rank2]:     engine, optimizer, _, lr_scheduler = ds_initialize(**kwargs)
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/__init__.py", line 193, in initialize
[rank2]:     engine = DeepSpeedEngine(args=args,
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 273, in __init__
[rank2]:     self._configure_distributed_model(model)
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 1284, in _configure_distributed_model
[rank2]:     self._broadcast_model()
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 1202, in _broadcast_model
[rank2]:     dist.broadcast(p.data, groups._get_broadcast_src_rank(), group=self.seq_data_parallel_group)
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/comm/comm.py", line 117, in log_wrapper
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/comm/comm.py", line 224, in broadcast
[rank2]:     return cdb.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/comm/torch.py", line 206, in broadcast
[rank2]:     return torch.distributed.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py", line 81, in wrapper
[rank2]:     return func(*args, **kwargs)
[rank2]:   File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 2726, in broadcast
[rank2]:     work = group.broadcast([tensor], opts)
[rank2]: torch.distributed.DistBackendError: NCCL error in: /pytorch/torch/csrc/distributed/c10d/NCCLUtils.hpp:268, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
[rank2]: ncclUnhandledCudaError: Call to CUDA function failed.
[rank2]: Last error:
[rank2]: Cuda failure 2 'out of memory'
W0531 11:29:21.540000 396426 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 396610 closing signal SIGTERM
W0531 11:29:21.584000 396426 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 396612 closing signal SIGTERM
W0531 11:29:21.584000 396426 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 396613 closing signal SIGTERM
E0531 11:29:22.119000 396426 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 1 (pid: 396611) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1182, in launch_command
    deepspeed_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 861, in deepspeed_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-31_11:29:21
  host      : pm6-nod12.vega.pri
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 396611)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
