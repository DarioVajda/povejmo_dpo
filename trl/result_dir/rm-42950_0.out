cpu-bind=MASK - ixh, task  0  0 [1639702]: mask 0xff00000000000000000000000000ff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 1
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: 
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 1     --machine_rank 0     --main_process_ip      --main_process_port 29500     --num_processes 4     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=1e-6 --total_epochs=3 --beta=0.1
-------------------------------------------
[2025-07-16 09:09:08,862] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
df: /root/.triton/autotune: No such file or directory
W0716 09:09:10.080000 1640341 torch/distributed/run.py:792] 
W0716 09:09:10.080000 1640341 torch/distributed/run.py:792] *****************************************
W0716 09:09:10.080000 1640341 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0716 09:09:10.080000 1640341 torch/distributed/run.py:792] *****************************************
[load_data.py]: Training data of type 'bad_lang_examples':    5470
[load_data.py]: Training data of type 'short_examples':       951
[load_data.py]: Training data of type 'choose_examples':      21177
[load_data.py]: Training data of type 'bad_format_examples':  5287
[load_data.py]: Number of training examples: 32885
[load_data.py]: Number of validation examples: 953
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
World size: 4
Setting gradient accumulation steps to: 4
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1)
1e-06
Created datasets
Train dataset size: 32885
Validation dataset size: 953
Steps per epoch: 2055
Evaluate each 685 steps
[2025-07-16 09:09:17,705] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-16 09:09:17,908] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-16 09:09:17,912] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-16 09:09:17,917] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-07-16 09:09:18,802] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-07-16 09:09:18,802] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
[2025-07-16 09:09:19,019] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-07-16 09:09:19,037] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-07-16 09:09:19,170] [INFO] [comm.py:669:init_distributed] cdb=None
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files:  25%|██▌       | 1/4 [00:21<01:03, 21.05s/it]Fetching 4 files:  25%|██▌       | 1/4 [00:20<01:02, 21.00s/it]Fetching 4 files:  25%|██▌       | 1/4 [00:20<01:02, 20.75s/it]Fetching 4 files:  25%|██▌       | 1/4 [00:21<01:03, 21.07s/it]Fetching 4 files:  50%|█████     | 2/4 [00:21<00:17,  8.90s/it]Fetching 4 files:  50%|█████     | 2/4 [00:21<00:17,  8.78s/it]Fetching 4 files:  50%|█████     | 2/4 [00:21<00:17,  8.88s/it]Fetching 4 files:  50%|█████     | 2/4 [00:21<00:17,  8.91s/it]Fetching 4 files: 100%|██████████| 4/4 [01:05<00:00, 17.19s/it]Fetching 4 files: 100%|██████████| 4/4 [01:05<00:00, 16.43s/it]
Fetching 4 files: 100%|██████████| 4/4 [01:05<00:00, 17.15s/it]Fetching 4 files: 100%|██████████| 4/4 [01:05<00:00, 16.35s/it]
Fetching 4 files: 100%|██████████| 4/4 [01:05<00:00, 17.20s/it]Fetching 4 files: 100%|██████████| 4/4 [01:05<00:00, 16.43s/it]
Fetching 4 files: 100%|██████████| 4/4 [01:05<00:00, 17.19s/it]Fetching 4 files: 100%|██████████| 4/4 [01:05<00:00, 16.42s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.32s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.51s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.52s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:10,  3.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.78s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.43s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.43s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.43s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:18<00:06,  6.93s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:19<00:07,  7.35s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:19<00:07,  7.36s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:19<00:07,  7.42s/it]slurmstepd: error: *** STEP 42950.0 ON ixh CANCELLED AT 2025-07-16T09:22:31 ***
slurmstepd: error: pyxis: child 1658818 terminated with signal 9
