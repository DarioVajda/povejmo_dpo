cpu-bind=MASK - gn29, task  1  0 [814895]: mask 0x1000000000000000000000000000000010000000000000000000000000000 set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn23
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 1     --main_process_ip gn23     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62067775     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-30 22:07:38,719] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0530 22:07:41.715000 814941 torch/distributed/run.py:792] 
W0530 22:07:41.715000 814941 torch/distributed/run.py:792] *****************************************
W0530 22:07:41.715000 814941 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0530 22:07:41.715000 814941 torch/distributed/run.py:792] *****************************************
[2025-05-30 22:08:13,539] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 22:08:13,610] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 22:08:13,657] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 22:08:13,663] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 2
[2025-05-30 22:08:25,136] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 22:08:25,145] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 22:08:25,158] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 4282
Eval steps: 2141
[2025-05-30 22:08:25,172] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
[2025-05-30 22:08:30,344] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 22:08:30,344] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 22:08:30,354] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 22:08:30,364] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:54<02:43, 54.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:54<02:43, 54.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:54<02:43, 54.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:54<02:43, 54.63s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:54<01:55, 57.76s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:54<01:55, 57.76s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:54<01:55, 57.76s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:54<01:55, 57.76s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:53<00:58, 58.44s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:53<00:58, 58.44s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:53<00:58, 58.44s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:53<00:58, 58.44s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:37<00:00, 52.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:37<00:00, 52.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:37<00:00, 54.32s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:37<00:00, 54.32s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [03:37<00:00, 52.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:37<00:00, 54.32s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [03:37<00:00, 52.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:37<00:00, 54.32s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 100.0000%
Total Parameters: 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 100.0000%
Using LoRA and set up the model
-------------------- CHECKING GRADIENTS --------------------
Trainable parameters:
- base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.40.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.40.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.41.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.41.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
Total trainable parameters: 216072192
------------------------------------------------------------
Total Parameters: 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 100.0000%
Total Parameters: 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 100.0000%
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 1/8564 [00:03<7:05:31,  2.98s/ examples]Extracting prompt in train dataset:   0%|          | 2/8564 [00:03<3:10:28,  1.33s/ examples]Extracting prompt in train dataset:   0%|          | 10/8564 [00:04<45:13,  3.15 examples/s] Extracting prompt in train dataset:   2%|▏         | 200/8564 [00:04<01:31, 91.39 examples/s]Extracting prompt in train dataset:   5%|▍         | 411/8564 [00:04<00:37, 217.18 examples/s]Extracting prompt in train dataset:   7%|▋         | 610/8564 [00:04<00:22, 359.14 examples/s]Extracting prompt in train dataset:   9%|▉         | 789/8564 [00:04<00:15, 507.64 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1000/8564 [00:05<00:10, 713.46 examples/s]Extracting prompt in train dataset:  14%|█▍        | 1217/8564 [00:05<00:07, 939.91 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1430/8564 [00:05<00:06, 1151.00 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1633/8564 [00:05<00:05, 1307.66 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1901/8564 [00:05<00:04, 1565.49 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2120/8564 [00:05<00:03, 1703.73 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2357/8564 [00:05<00:03, 1871.23 examples/s]Extracting prompt in train dataset:  31%|███       | 2666/8564 [00:05<00:03, 1925.77 examples/s]Extracting prompt in train dataset:  34%|███▎      | 2880/8564 [00:05<00:02, 1967.35 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3220/8564 [00:06<00:03, 1559.99 examples/s]Extracting prompt in train dataset:  41%|████      | 3510/8564 [00:06<00:02, 1799.95 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3790/8564 [00:06<00:02, 1981.88 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4093/8564 [00:06<00:02, 1965.44 examples/s]Extracting prompt in train dataset:  50%|█████     | 4310/8564 [00:06<00:02, 1991.32 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 4650/8564 [00:06<00:02, 1949.22 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4870/8564 [00:06<00:01, 1946.11 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 5090/8564 [00:07<00:01, 1998.29 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5314/8564 [00:07<00:01, 2034.79 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5530/8564 [00:07<00:01, 2048.75 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5750/8564 [00:07<00:01, 2080.11 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5970/8564 [00:07<00:01, 2090.92 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6277/8564 [00:07<00:01, 2029.85 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 6500/8564 [00:07<00:01, 2023.13 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6720/8564 [00:07<00:00, 2068.86 examples/s]Extracting prompt in train dataset:  81%|████████  | 6946/8564 [00:07<00:00, 2055.60 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7180/8564 [00:08<00:00, 2063.37 examples/s]Extracting prompt in train dataset:  86%|████████▋ | 7403/8564 [00:08<00:00, 2043.19 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7620/8564 [00:08<00:00, 2066.15 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7840/8564 [00:08<00:00, 1053.20 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8108/8564 [00:08<00:00, 1295.80 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8327/8564 [00:08<00:00, 1431.82 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 8550/8564 [00:09<00:00, 1594.67 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:09<00:00, 922.04 examples/s] 
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 102/8564 [00:00<00:08, 1006.03 examples/s]Applying chat template to train dataset:   3%|▎         | 220/8564 [00:00<00:07, 1101.65 examples/s]Applying chat template to train dataset:   4%|▍         | 336/8564 [00:00<00:07, 1126.26 examples/s]Applying chat template to train dataset:   6%|▌         | 490/8564 [00:00<00:07, 1075.79 examples/s]Applying chat template to train dataset:   7%|▋         | 614/8564 [00:00<00:07, 1108.20 examples/s]Applying chat template to train dataset:   9%|▉         | 758/8564 [00:00<00:06, 1121.39 examples/s]Applying chat template to train dataset:  10%|█         | 896/8564 [00:00<00:06, 1152.05 examples/s]Applying chat template to train dataset:  13%|█▎        | 1081/8564 [00:00<00:06, 1097.89 examples/s]Applying chat template to train dataset:  14%|█▍        | 1200/8564 [00:01<00:06, 1115.77 examples/s]Applying chat template to train dataset:  16%|█▌        | 1340/8564 [00:01<00:06, 1152.04 examples/s]Applying chat template to train dataset:  18%|█▊        | 1518/8564 [00:01<00:05, 1316.91 examples/s]Applying chat template to train dataset:  20%|█▉        | 1689/8564 [00:01<00:04, 1382.71 examples/s]Applying chat template to train dataset:  22%|██▏       | 1861/8564 [00:01<00:05, 1293.85 examples/s]Applying chat template to train dataset:  23%|██▎       | 2007/8564 [00:01<00:05, 1253.83 examples/s]Applying chat template to train dataset:  25%|██▌       | 2150/8564 [00:01<00:05, 1256.10 examples/s]Applying chat template to train dataset:  27%|██▋       | 2329/8564 [00:01<00:05, 1218.03 examples/s]Applying chat template to train dataset:  29%|██▉       | 2500/8564 [00:02<00:04, 1338.24 examples/s]Applying chat template to train dataset:  31%|███       | 2646/8564 [00:02<00:04, 1326.11 examples/s]Applying chat template to train dataset:  33%|███▎      | 2790/8564 [00:02<00:04, 1350.55 examples/s]Applying chat template to train dataset:  34%|███▍      | 2930/8564 [00:02<00:04, 1288.55 examples/s]Applying chat template to train dataset:  36%|███▋      | 3106/8564 [00:02<00:04, 1229.17 examples/s]Applying chat template to train dataset:  38%|███▊      | 3290/8564 [00:02<00:04, 1197.57 examples/s]Applying chat template to train dataset:  41%|████      | 3473/8564 [00:02<00:04, 1173.82 examples/s]Applying chat template to train dataset:  42%|████▏     | 3630/8564 [00:03<00:04, 1127.83 examples/s]Applying chat template to train dataset:  44%|████▍     | 3794/8564 [00:03<00:04, 1115.86 examples/s]Applying chat template to train dataset:  46%|████▌     | 3960/8564 [00:03<00:04, 1110.27 examples/s]Applying chat template to train dataset:  48%|████▊     | 4073/8564 [00:03<00:04, 1113.76 examples/s]Applying chat template to train dataset:  49%|████▉     | 4237/8564 [00:03<00:03, 1105.21 examples/s]Applying chat template to train dataset:  51%|█████     | 4350/8564 [00:03<00:03, 1081.34 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4464/8564 [00:03<00:03, 1089.79 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4642/8564 [00:03<00:03, 1090.86 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4758/8564 [00:04<00:03, 1101.36 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4872/8564 [00:04<00:03, 1109.70 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5037/8564 [00:04<00:03, 1056.45 examples/s]Applying chat template to train dataset:  60%|██████    | 5163/8564 [00:04<00:03, 1047.48 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5304/8564 [00:04<00:02, 1101.91 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5416/8564 [00:04<00:02, 1104.91 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5542/8564 [00:04<00:02, 1090.08 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5677/8564 [00:04<00:02, 1158.05 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5855/8564 [00:05<00:02, 1136.22 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5983/8564 [00:05<00:02, 1079.82 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6128/8564 [00:05<00:02, 1124.83 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6242/8564 [00:05<00:02, 1127.44 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6363/8564 [00:05<00:01, 1118.26 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6477/8564 [00:05<00:01, 1123.34 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6592/8564 [00:05<00:01, 1112.60 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6712/8564 [00:05<00:01, 1124.64 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6829/8564 [00:05<00:01, 1136.61 examples/s]Applying chat template to train dataset:  81%|████████  | 6949/8564 [00:06<00:01, 1148.86 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7147/8564 [00:06<00:01, 1213.06 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7280/8564 [00:06<00:01, 1182.22 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7423/8564 [00:06<00:00, 1190.77 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7542/8564 [00:06<00:00, 1189.48 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7671/8564 [00:06<00:00, 1151.70 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7868/8564 [00:07<00:01, 692.46 examples/s] Applying chat template to train dataset:  93%|█████████▎| 7999/8564 [00:07<00:00, 785.69 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8122/8564 [00:07<00:00, 856.71 examples/s]Applying chat template to train dataset:  96%|█████████▋| 8244/8564 [00:07<00:00, 931.78 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8363/8564 [00:07<00:00, 990.35 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8478/8564 [00:07<00:00, 1028.78 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:07<00:00, 1112.48 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 1/8564 [00:00<48:42,  2.93 examples/s]Tokenizing train dataset:   0%|          | 24/8564 [00:00<02:02, 69.54 examples/s]Tokenizing train dataset:   0%|          | 41/8564 [00:00<01:29, 95.74 examples/s]Tokenizing train dataset:   1%|          | 59/8564 [00:00<01:28, 96.50 examples/s]Tokenizing train dataset:   1%|          | 73/8564 [00:00<01:22, 103.22 examples/s]Tokenizing train dataset:   1%|          | 87/8564 [00:00<01:21, 104.43 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:01<01:21, 103.68 examples/s]Tokenizing train dataset:   1%|▏         | 113/8564 [00:01<01:18, 108.11 examples/s]Tokenizing train dataset:   2%|▏         | 130/8564 [00:01<01:18, 107.81 examples/s]Tokenizing train dataset:   2%|▏         | 146/8564 [00:01<01:12, 115.78 examples/s]Tokenizing train dataset:   2%|▏         | 162/8564 [00:01<01:15, 111.52 examples/s]Tokenizing train dataset:   2%|▏         | 177/8564 [00:01<01:20, 103.99 examples/s]Tokenizing train dataset:   2%|▏         | 190/8564 [00:01<01:19, 105.83 examples/s]Tokenizing train dataset:   2%|▏         | 206/8564 [00:02<01:22, 101.31 examples/s]Tokenizing train dataset:   3%|▎         | 222/8564 [00:02<01:16, 108.97 examples/s]Tokenizing train dataset:   3%|▎         | 237/8564 [00:02<01:12, 115.24 examples/s]Tokenizing train dataset:   3%|▎         | 257/8564 [00:02<01:06, 125.72 examples/s]Tokenizing train dataset:   3%|▎         | 273/8564 [00:02<01:02, 132.83 examples/s]Tokenizing train dataset:   3%|▎         | 287/8564 [00:02<01:02, 132.97 examples/s]Tokenizing train dataset:   4%|▎         | 302/8564 [00:02<01:10, 117.42 examples/s]Tokenizing train dataset:   4%|▍         | 322/8564 [00:03<01:08, 120.00 examples/s]Tokenizing train dataset:   4%|▍         | 337/8564 [00:03<01:13, 112.00 examples/s]Tokenizing train dataset:   4%|▍         | 352/8564 [00:03<01:16, 107.06 examples/s]Tokenizing train dataset:   4%|▍         | 366/8564 [00:03<01:14, 109.83 examples/s]Tokenizing train dataset:   4%|▍         | 380/8564 [00:03<01:13, 111.34 examples/s]Tokenizing train dataset:   5%|▍         | 392/8564 [00:03<01:15, 107.67 examples/s]Tokenizing train dataset:   5%|▍         | 403/8564 [00:03<01:19, 103.29 examples/s]Tokenizing train dataset:   5%|▍         | 418/8564 [00:03<01:12, 111.66 examples/s]Tokenizing train dataset:   5%|▌         | 430/8564 [00:04<01:11, 113.30 examples/s]Tokenizing train dataset:   5%|▌         | 443/8564 [00:04<01:23, 97.08 examples/s] Tokenizing train dataset:   5%|▌         | 455/8564 [00:04<01:19, 102.11 examples/s]Tokenizing train dataset:   6%|▌         | 473/8564 [00:04<01:17, 104.06 examples/s]Tokenizing train dataset:   6%|▌         | 490/8564 [00:04<01:20, 100.55 examples/s]Tokenizing train dataset:   6%|▌         | 501/8564 [00:04<01:21, 98.57 examples/s] Tokenizing train dataset:   6%|▌         | 511/8564 [00:04<01:26, 93.18 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:04<01:19, 101.24 examples/s]Tokenizing train dataset:   6%|▋         | 540/8564 [00:05<01:10, 114.27 examples/s]Tokenizing train dataset:   6%|▋         | 556/8564 [00:05<01:13, 108.79 examples/s]Tokenizing train dataset:   7%|▋         | 572/8564 [00:05<01:17, 103.38 examples/s]Tokenizing train dataset:   7%|▋         | 589/8564 [00:05<01:09, 114.19 examples/s]Tokenizing train dataset:   7%|▋         | 604/8564 [00:05<01:13, 107.72 examples/s]Tokenizing train dataset:   7%|▋         | 617/8564 [00:05<01:13, 108.76 examples/s]Tokenizing train dataset:   7%|▋         | 636/8564 [00:05<01:02, 127.83 examples/s]Tokenizing train dataset:   8%|▊         | 655/8564 [00:06<01:03, 124.19 examples/s]Tokenizing train dataset:   8%|▊         | 670/8564 [00:06<01:10, 112.25 examples/s]Tokenizing train dataset:   8%|▊         | 682/8564 [00:06<01:09, 113.84 examples/s]Tokenizing train dataset:   8%|▊         | 696/8564 [00:06<01:17, 101.60 examples/s]Tokenizing train dataset:   8%|▊         | 713/8564 [00:06<01:08, 114.42 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:06<01:03, 122.78 examples/s]Tokenizing train dataset:   9%|▊         | 743/8564 [00:06<01:03, 123.93 examples/s]Tokenizing train dataset:   9%|▉         | 756/8564 [00:06<01:04, 121.13 examples/s]Tokenizing train dataset:   9%|▉         | 769/8564 [00:07<01:04, 121.48 examples/s]Tokenizing train dataset:   9%|▉         | 784/8564 [00:07<01:11, 108.72 examples/s]Tokenizing train dataset:   9%|▉         | 800/8564 [00:07<01:17, 100.80 examples/s]Tokenizing train dataset:   9%|▉         | 812/8564 [00:07<01:14, 104.08 examples/s]Tokenizing train dataset:  10%|▉         | 825/8564 [00:07<01:15, 102.36 examples/s]Tokenizing train dataset:  10%|▉         | 836/8564 [00:07<01:15, 102.91 examples/s]Tokenizing train dataset:  10%|▉         | 848/8564 [00:07<01:14, 104.07 examples/s]Tokenizing train dataset:  10%|█         | 861/8564 [00:07<01:10, 108.85 examples/s]Tokenizing train dataset:  10%|█         | 879/8564 [00:08<01:11, 107.05 examples/s]Tokenizing train dataset:  10%|█         | 897/8564 [00:08<01:03, 120.93 examples/s]Tokenizing train dataset:  11%|█         | 911/8564 [00:08<01:03, 120.60 examples/s]Tokenizing train dataset:  11%|█         | 930/8564 [00:08<01:08, 110.94 examples/s]Tokenizing train dataset:  11%|█         | 948/8564 [00:08<01:11, 106.85 examples/s]Tokenizing train dataset:  11%|█         | 960/8564 [00:08<01:11, 106.13 examples/s]Tokenizing train dataset:  11%|█▏        | 973/8564 [00:09<01:09, 109.13 examples/s]Tokenizing train dataset:  12%|█▏        | 986/8564 [00:09<01:17, 97.81 examples/s] Tokenizing train dataset:  12%|█▏        | 1002/8564 [00:09<01:19, 95.58 examples/s]Tokenizing train dataset:  12%|█▏        | 1012/8564 [00:09<01:20, 94.22 examples/s]Tokenizing train dataset:  12%|█▏        | 1024/8564 [00:09<01:19, 95.13 examples/s]Tokenizing train dataset:  12%|█▏        | 1034/8564 [00:09<01:18, 95.54 examples/s]Tokenizing train dataset:  12%|█▏        | 1050/8564 [00:09<01:17, 96.73 examples/s]Tokenizing train dataset:  12%|█▏        | 1063/8564 [00:09<01:13, 101.98 examples/s]Tokenizing train dataset:  13%|█▎        | 1079/8564 [00:10<01:08, 109.47 examples/s]Tokenizing train dataset:  13%|█▎        | 1093/8564 [00:10<01:04, 115.75 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:10<01:05, 113.45 examples/s]Tokenizing train dataset:  13%|█▎        | 1125/8564 [00:10<01:04, 115.50 examples/s]Tokenizing train dataset:  13%|█▎        | 1142/8564 [00:10<01:06, 111.99 examples/s]Tokenizing train dataset:  14%|█▎        | 1159/8564 [00:10<01:08, 108.70 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:10<01:11, 102.72 examples/s]Tokenizing train dataset:  14%|█▍        | 1185/8564 [00:11<01:05, 112.38 examples/s]Tokenizing train dataset:  14%|█▍        | 1199/8564 [00:11<01:02, 118.38 examples/s]Tokenizing train dataset:  14%|█▍        | 1214/8564 [00:11<01:08, 107.54 examples/s]Tokenizing train dataset:  14%|█▍        | 1227/8564 [00:11<01:05, 112.17 examples/s]Tokenizing train dataset:  15%|█▍        | 1246/8564 [00:11<00:58, 126.10 examples/s]Tokenizing train dataset:  15%|█▍        | 1262/8564 [00:11<01:04, 112.60 examples/s]Tokenizing train dataset:  15%|█▍        | 1274/8564 [00:11<01:08, 106.39 examples/s]Tokenizing train dataset:  15%|█▌        | 1285/8564 [00:11<01:09, 104.02 examples/s]Tokenizing train dataset:  15%|█▌        | 1299/8564 [00:12<01:05, 111.59 examples/s]Tokenizing train dataset:  15%|█▌        | 1312/8564 [00:12<01:02, 115.92 examples/s]Tokenizing train dataset:  15%|█▌        | 1327/8564 [00:12<01:16, 94.06 examples/s] Tokenizing train dataset:  16%|█▌        | 1340/8564 [00:12<01:13, 98.40 examples/s]Tokenizing train dataset:  16%|█▌        | 1351/8564 [00:12<01:11, 100.75 examples/s]Tokenizing train dataset:  16%|█▌        | 1366/8564 [00:12<01:07, 106.13 examples/s]Tokenizing train dataset:  16%|█▌        | 1381/8564 [00:12<01:11, 101.11 examples/s]Tokenizing train dataset:  16%|█▋        | 1392/8564 [00:12<01:10, 101.98 examples/s]Tokenizing train dataset:  16%|█▋        | 1405/8564 [00:13<01:09, 103.13 examples/s]Tokenizing train dataset:  17%|█▋        | 1420/8564 [00:13<01:07, 105.91 examples/s]Tokenizing train dataset:  17%|█▋        | 1435/8564 [00:13<01:10, 101.76 examples/s]Tokenizing train dataset:  17%|█▋        | 1448/8564 [00:13<01:07, 105.48 examples/s]Tokenizing train dataset:  17%|█▋        | 1464/8564 [00:13<01:09, 101.80 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:13<01:10, 101.00 examples/s]Tokenizing train dataset:  17%|█▋        | 1491/8564 [00:13<01:09, 101.80 examples/s]Tokenizing train dataset:  18%|█▊        | 1503/8564 [00:14<01:09, 101.01 examples/s]Tokenizing train dataset:  18%|█▊        | 1514/8564 [00:14<01:11, 98.16 examples/s] Tokenizing train dataset:  18%|█▊        | 1527/8564 [00:14<01:06, 105.74 examples/s]Tokenizing train dataset:  18%|█▊        | 1540/8564 [00:14<01:06, 106.32 examples/s]Tokenizing train dataset:  18%|█▊        | 1552/8564 [00:14<01:04, 109.11 examples/s]Tokenizing train dataset:  18%|█▊        | 1566/8564 [00:14<01:04, 108.83 examples/s]Tokenizing train dataset:  18%|█▊        | 1577/8564 [00:14<01:07, 103.34 examples/s]Tokenizing train dataset:  19%|█▊        | 1592/8564 [00:14<01:00, 114.87 examples/s]Tokenizing train dataset:  19%|█▉        | 1608/8564 [00:15<01:01, 113.13 examples/s]Tokenizing train dataset:  19%|█▉        | 1622/8564 [00:15<00:59, 116.06 examples/s]Tokenizing train dataset:  19%|█▉        | 1640/8564 [00:15<01:01, 112.67 examples/s]Tokenizing train dataset:  19%|█▉        | 1658/8564 [00:15<01:05, 105.48 examples/s]Tokenizing train dataset:  19%|█▉        | 1669/8564 [00:15<01:06, 104.37 examples/s]Tokenizing train dataset:  20%|█▉        | 1680/8564 [00:15<01:07, 102.44 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:15<00:56, 120.47 examples/s]Tokenizing train dataset:  20%|██        | 1714/8564 [00:15<00:55, 122.76 examples/s]Tokenizing train dataset:  20%|██        | 1727/8564 [00:16<00:57, 118.56 examples/s]Tokenizing train dataset:  20%|██        | 1746/8564 [00:16<00:59, 114.34 examples/s]Tokenizing train dataset:  21%|██        | 1761/8564 [00:16<00:56, 121.36 examples/s]Tokenizing train dataset:  21%|██        | 1778/8564 [00:16<00:58, 116.43 examples/s]Tokenizing train dataset:  21%|██        | 1790/8564 [00:16<01:02, 108.60 examples/s]Tokenizing train dataset:  21%|██        | 1806/8564 [00:16<00:58, 115.30 examples/s]Tokenizing train dataset:  21%|██        | 1818/8564 [00:16<00:58, 115.67 examples/s]Tokenizing train dataset:  21%|██▏       | 1830/8564 [00:16<00:59, 112.38 examples/s]Tokenizing train dataset:  22%|██▏       | 1844/8564 [00:17<00:58, 114.46 examples/s]Tokenizing train dataset:  22%|██▏       | 1856/8564 [00:17<01:00, 110.39 examples/s]Tokenizing train dataset:  22%|██▏       | 1870/8564 [00:17<01:06, 101.03 examples/s]Tokenizing train dataset:  22%|██▏       | 1882/8564 [00:17<01:03, 104.76 examples/s]Tokenizing train dataset:  22%|██▏       | 1895/8564 [00:17<01:02, 107.46 examples/s]Tokenizing train dataset:  22%|██▏       | 1914/8564 [00:17<00:53, 124.94 examples/s]Tokenizing train dataset:  23%|██▎       | 1931/8564 [00:17<00:48, 136.35 examples/s]Tokenizing train dataset:  23%|██▎       | 1945/8564 [00:17<00:48, 135.50 examples/s]Tokenizing train dataset:  23%|██▎       | 1966/8564 [00:18<00:50, 130.94 examples/s]Tokenizing train dataset:  23%|██▎       | 1980/8564 [00:18<00:51, 128.90 examples/s]Tokenizing train dataset:  23%|██▎       | 1999/8564 [00:18<00:51, 126.86 examples/s]Tokenizing train dataset:  24%|██▎       | 2013/8564 [00:18<00:50, 129.02 examples/s]Tokenizing train dataset:  24%|██▎       | 2027/8564 [00:18<00:49, 131.16 examples/s]Tokenizing train dataset:  24%|██▍       | 2042/8564 [00:18<00:48, 135.03 examples/s]Tokenizing train dataset:  24%|██▍       | 2056/8564 [00:18<00:48, 134.61 examples/s]Tokenizing train dataset:  24%|██▍       | 2073/8564 [00:18<00:52, 124.23 examples/s]Tokenizing train dataset:  24%|██▍       | 2088/8564 [00:19<00:49, 130.16 examples/s]Tokenizing train dataset:  25%|██▍       | 2102/8564 [00:19<00:49, 131.00 examples/s]Tokenizing train dataset:  25%|██▍       | 2116/8564 [00:19<00:49, 130.24 examples/s]Tokenizing train dataset:  25%|██▍       | 2135/8564 [00:19<00:46, 136.91 examples/s]Tokenizing train dataset:  25%|██▌       | 2149/8564 [00:19<00:47, 136.19 examples/s]Tokenizing train dataset:  25%|██▌       | 2169/8564 [00:19<00:49, 128.86 examples/s]Tokenizing train dataset:  26%|██▌       | 2190/8564 [00:19<00:48, 130.41 examples/s]Tokenizing train dataset:  26%|██▌       | 2210/8564 [00:19<00:49, 129.49 examples/s]Tokenizing train dataset:  26%|██▌       | 2226/8564 [00:20<00:48, 131.98 examples/s]Tokenizing train dataset:  26%|██▌       | 2241/8564 [00:20<00:47, 134.10 examples/s]Tokenizing train dataset:  26%|██▋       | 2256/8564 [00:20<00:46, 135.79 examples/s]Tokenizing train dataset:  27%|██▋       | 2274/8564 [00:20<00:44, 141.55 examples/s]Tokenizing train dataset:  27%|██▋       | 2295/8564 [00:20<00:45, 138.54 examples/s]Tokenizing train dataset:  27%|██▋       | 2314/8564 [00:20<00:48, 129.14 examples/s]Tokenizing train dataset:  27%|██▋       | 2333/8564 [00:20<00:51, 119.94 examples/s]Tokenizing train dataset:  27%|██▋       | 2350/8564 [00:21<00:54, 114.32 examples/s]Tokenizing train dataset:  28%|██▊       | 2363/8564 [00:21<00:53, 115.62 examples/s]Tokenizing train dataset:  28%|██▊       | 2381/8564 [00:21<00:48, 127.33 examples/s]Tokenizing train dataset:  28%|██▊       | 2406/8564 [00:21<00:39, 154.84 examples/s]Tokenizing train dataset:  28%|██▊       | 2428/8564 [00:21<00:41, 147.79 examples/s]Tokenizing train dataset:  29%|██▊       | 2448/8564 [00:21<00:38, 158.82 examples/s]Tokenizing train dataset:  29%|██▉       | 2468/8564 [00:21<00:41, 147.88 examples/s]Tokenizing train dataset:  29%|██▉       | 2489/8564 [00:22<00:47, 127.90 examples/s]Tokenizing train dataset:  29%|██▉       | 2507/8564 [00:22<00:50, 120.31 examples/s]Tokenizing train dataset:  29%|██▉       | 2523/8564 [00:22<00:47, 127.55 examples/s]Tokenizing train dataset:  30%|██▉       | 2540/8564 [00:22<00:46, 130.60 examples/s]Tokenizing train dataset:  30%|██▉       | 2558/8564 [00:22<00:42, 140.78 examples/s]Tokenizing train dataset:  30%|███       | 2573/8564 [00:22<00:43, 138.88 examples/s]Tokenizing train dataset:  30%|███       | 2592/8564 [00:22<00:44, 133.44 examples/s]Tokenizing train dataset:  30%|███       | 2606/8564 [00:22<00:44, 133.16 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:23<01:06, 88.89 examples/s] Tokenizing train dataset:  31%|███       | 2631/8564 [00:23<01:04, 92.31 examples/s]Tokenizing train dataset:  31%|███       | 2646/8564 [00:23<00:58, 100.47 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:23<00:54, 107.66 examples/s]Tokenizing train dataset:  31%|███       | 2675/8564 [00:23<00:56, 103.93 examples/s]Tokenizing train dataset:  31%|███▏      | 2688/8564 [00:23<00:53, 109.51 examples/s]Tokenizing train dataset:  32%|███▏      | 2704/8564 [00:23<00:48, 119.93 examples/s]Tokenizing train dataset:  32%|███▏      | 2718/8564 [00:24<00:48, 121.51 examples/s]Tokenizing train dataset:  32%|███▏      | 2736/8564 [00:24<00:49, 117.41 examples/s]Tokenizing train dataset:  32%|███▏      | 2755/8564 [00:24<00:43, 133.93 examples/s]Tokenizing train dataset:  32%|███▏      | 2769/8564 [00:24<00:44, 129.79 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:24<00:44, 130.63 examples/s]Tokenizing train dataset:  33%|███▎      | 2799/8564 [00:24<00:44, 130.27 examples/s]Tokenizing train dataset:  33%|███▎      | 2816/8564 [00:24<00:42, 134.68 examples/s]Tokenizing train dataset:  33%|███▎      | 2830/8564 [00:24<00:42, 133.65 examples/s]Tokenizing train dataset:  33%|███▎      | 2850/8564 [00:25<00:44, 128.98 examples/s]Tokenizing train dataset:  33%|███▎      | 2866/8564 [00:25<00:47, 120.05 examples/s]Tokenizing train dataset:  34%|███▎      | 2887/8564 [00:25<00:45, 123.62 examples/s]Tokenizing train dataset:  34%|███▍      | 2904/8564 [00:25<00:42, 133.62 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:25<00:41, 136.86 examples/s]Tokenizing train dataset:  34%|███▍      | 2938/8564 [00:25<00:40, 138.37 examples/s]Tokenizing train dataset:  34%|███▍      | 2954/8564 [00:25<00:39, 141.96 examples/s]Tokenizing train dataset:  35%|███▍      | 2970/8564 [00:25<00:39, 143.39 examples/s]Tokenizing train dataset:  35%|███▍      | 2989/8564 [00:25<00:36, 151.74 examples/s]Tokenizing train dataset:  35%|███▌      | 3007/8564 [00:26<00:35, 155.81 examples/s]Tokenizing train dataset:  35%|███▌      | 3025/8564 [00:26<00:40, 137.72 examples/s]Tokenizing train dataset:  36%|███▌      | 3044/8564 [00:26<00:41, 131.75 examples/s]Tokenizing train dataset:  36%|███▌      | 3065/8564 [00:26<00:42, 129.07 examples/s]Tokenizing train dataset:  36%|███▌      | 3086/8564 [00:26<00:42, 127.92 examples/s]Tokenizing train dataset:  36%|███▋      | 3106/8564 [00:26<00:42, 127.39 examples/s]Tokenizing train dataset:  36%|███▋      | 3120/8564 [00:27<00:43, 123.95 examples/s]Tokenizing train dataset:  37%|███▋      | 3136/8564 [00:27<00:42, 127.14 examples/s]Tokenizing train dataset:  37%|███▋      | 3149/8564 [00:27<00:42, 127.15 examples/s]Tokenizing train dataset:  37%|███▋      | 3164/8564 [00:27<00:42, 127.34 examples/s]Tokenizing train dataset:  37%|███▋      | 3184/8564 [00:27<00:43, 124.66 examples/s]Tokenizing train dataset:  37%|███▋      | 3197/8564 [00:27<00:44, 121.78 examples/s]Tokenizing train dataset:  38%|███▊      | 3215/8564 [00:27<00:41, 129.33 examples/s]Tokenizing train dataset:  38%|███▊      | 3230/8564 [00:27<00:40, 132.26 examples/s]Tokenizing train dataset:  38%|███▊      | 3246/8564 [00:27<00:38, 139.20 examples/s]Tokenizing train dataset:  38%|███▊      | 3262/8564 [00:28<00:42, 124.16 examples/s]Tokenizing train dataset:  38%|███▊      | 3276/8564 [00:28<00:43, 122.18 examples/s]Tokenizing train dataset:  38%|███▊      | 3293/8564 [00:28<00:45, 116.83 examples/s]Tokenizing train dataset:  39%|███▊      | 3305/8564 [00:28<00:45, 116.78 examples/s]Tokenizing train dataset:  39%|███▊      | 3318/8564 [00:28<00:44, 117.13 examples/s]Tokenizing train dataset:  39%|███▉      | 3330/8564 [00:28<00:45, 114.35 examples/s]Tokenizing train dataset:  39%|███▉      | 3343/8564 [00:28<00:45, 115.38 examples/s]Tokenizing train dataset:  39%|███▉      | 3359/8564 [00:28<00:43, 120.02 examples/s]Tokenizing train dataset:  39%|███▉      | 3379/8564 [00:29<00:41, 123.61 examples/s]Tokenizing train dataset:  40%|███▉      | 3396/8564 [00:29<00:38, 134.42 examples/s]Tokenizing train dataset:  40%|███▉      | 3411/8564 [00:29<00:37, 138.03 examples/s]Tokenizing train dataset:  40%|████      | 3431/8564 [00:29<00:38, 133.15 examples/s]Tokenizing train dataset:  40%|████      | 3450/8564 [00:29<00:39, 128.99 examples/s]Tokenizing train dataset:  40%|████      | 3468/8564 [00:29<00:37, 134.16 examples/s]Tokenizing train dataset:  41%|████      | 3488/8564 [00:29<00:39, 129.32 examples/s]Tokenizing train dataset:  41%|████      | 3506/8564 [00:30<00:37, 135.06 examples/s]Tokenizing train dataset:  41%|████      | 3520/8564 [00:30<00:37, 133.87 examples/s]Tokenizing train dataset:  41%|████▏     | 3534/8564 [00:30<00:37, 134.41 examples/s]Tokenizing train dataset:  41%|████▏     | 3552/8564 [00:30<00:40, 124.97 examples/s]Tokenizing train dataset:  42%|████▏     | 3567/8564 [00:30<00:38, 128.83 examples/s]Tokenizing train dataset:  42%|████▏     | 3584/8564 [00:30<00:35, 138.51 examples/s]Tokenizing train dataset:  42%|████▏     | 3599/8564 [00:30<00:36, 135.49 examples/s]Tokenizing train dataset:  42%|████▏     | 3614/8564 [00:30<00:37, 131.86 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:31<00:36, 137.03 examples/s]Tokenizing train dataset:  43%|████▎     | 3647/8564 [00:31<00:38, 126.64 examples/s]Tokenizing train dataset:  43%|████▎     | 3661/8564 [00:31<00:38, 128.48 examples/s]Tokenizing train dataset:  43%|████▎     | 3679/8564 [00:31<00:39, 123.33 examples/s]Tokenizing train dataset:  43%|████▎     | 3692/8564 [00:31<00:39, 124.84 examples/s]Tokenizing train dataset:  43%|████▎     | 3711/8564 [00:31<00:38, 124.82 examples/s]Tokenizing train dataset:  44%|████▎     | 3728/8564 [00:31<00:37, 130.41 examples/s]Tokenizing train dataset:  44%|████▍     | 3750/8564 [00:31<00:36, 133.04 examples/s]Tokenizing train dataset:  44%|████▍     | 3764/8564 [00:32<00:35, 133.65 examples/s]Tokenizing train dataset:  44%|████▍     | 3779/8564 [00:32<00:34, 137.08 examples/s]Tokenizing train dataset:  44%|████▍     | 3793/8564 [00:32<00:36, 131.14 examples/s]Tokenizing train dataset:  44%|████▍     | 3809/8564 [00:32<00:34, 136.27 examples/s]Tokenizing train dataset:  45%|████▍     | 3823/8564 [00:32<00:36, 129.86 examples/s]Tokenizing train dataset:  45%|████▍     | 3838/8564 [00:32<00:36, 129.96 examples/s]Tokenizing train dataset:  45%|████▌     | 3858/8564 [00:32<00:36, 129.06 examples/s]Tokenizing train dataset:  45%|████▌     | 3873/8564 [00:32<00:36, 129.26 examples/s]Tokenizing train dataset:  45%|████▌     | 3889/8564 [00:33<00:35, 130.73 examples/s]Tokenizing train dataset:  46%|████▌     | 3907/8564 [00:33<00:38, 120.81 examples/s]Tokenizing train dataset:  46%|████▌     | 3927/8564 [00:33<00:37, 122.95 examples/s]Tokenizing train dataset:  46%|████▌     | 3942/8564 [00:33<00:37, 123.46 examples/s]Tokenizing train dataset:  46%|████▌     | 3956/8564 [00:33<00:37, 123.55 examples/s]Tokenizing train dataset:  46%|████▋     | 3971/8564 [00:33<00:36, 127.46 examples/s]Tokenizing train dataset:  47%|████▋     | 3990/8564 [00:33<00:37, 122.17 examples/s]Tokenizing train dataset:  47%|████▋     | 4005/8564 [00:33<00:35, 127.34 examples/s]Tokenizing train dataset:  47%|████▋     | 4020/8564 [00:34<00:34, 130.17 examples/s]Tokenizing train dataset:  47%|████▋     | 4036/8564 [00:34<00:34, 130.45 examples/s]Tokenizing train dataset:  47%|████▋     | 4052/8564 [00:34<00:33, 136.69 examples/s]Tokenizing train dataset:  47%|████▋     | 4066/8564 [00:34<00:34, 131.20 examples/s]Tokenizing train dataset:  48%|████▊     | 4081/8564 [00:34<00:34, 129.15 examples/s]Tokenizing train dataset:  48%|████▊     | 4100/8564 [00:34<00:35, 125.68 examples/s]Tokenizing train dataset:  48%|████▊     | 4116/8564 [00:34<00:34, 129.03 examples/s]Tokenizing train dataset:  48%|████▊     | 4130/8564 [00:34<00:35, 124.28 examples/s]Tokenizing train dataset:  48%|████▊     | 4144/8564 [00:35<00:35, 124.95 examples/s]Tokenizing train dataset:  49%|████▊     | 4158/8564 [00:35<00:34, 126.73 examples/s]Tokenizing train dataset:  49%|████▉     | 4179/8564 [00:35<00:34, 126.72 examples/s]Tokenizing train dataset:  49%|████▉     | 4200/8564 [00:35<00:33, 128.95 examples/s]Tokenizing train dataset:  49%|████▉     | 4219/8564 [00:35<00:34, 125.21 examples/s]Tokenizing train dataset:  49%|████▉     | 4239/8564 [00:35<00:34, 126.29 examples/s]Tokenizing train dataset:  50%|████▉     | 4252/8564 [00:35<00:35, 120.90 examples/s]Tokenizing train dataset:  50%|████▉     | 4270/8564 [00:36<00:33, 127.25 examples/s]Tokenizing train dataset:  50%|█████     | 4285/8564 [00:36<00:33, 127.39 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:36<00:33, 128.77 examples/s]Tokenizing train dataset:  50%|█████     | 4315/8564 [00:36<00:32, 131.97 examples/s]Tokenizing train dataset:  51%|█████     | 4334/8564 [00:36<00:33, 125.91 examples/s]Tokenizing train dataset:  51%|█████     | 4350/8564 [00:36<00:32, 131.12 examples/s]Tokenizing train dataset:  51%|█████     | 4370/8564 [00:36<00:29, 140.28 examples/s]Tokenizing train dataset:  51%|█████     | 4386/8564 [00:36<00:30, 138.94 examples/s]Tokenizing train dataset:  51%|█████▏    | 4401/8564 [00:36<00:29, 141.46 examples/s]Tokenizing train dataset:  52%|█████▏    | 4422/8564 [00:37<00:29, 138.33 examples/s]Tokenizing train dataset:  52%|█████▏    | 4443/8564 [00:37<00:31, 131.91 examples/s]Tokenizing train dataset:  52%|█████▏    | 4457/8564 [00:37<00:31, 131.21 examples/s]Tokenizing train dataset:  52%|█████▏    | 4478/8564 [00:37<00:30, 132.50 examples/s]Tokenizing train dataset:  53%|█████▎    | 4498/8564 [00:37<00:30, 131.38 examples/s]Tokenizing train dataset:  53%|█████▎    | 4512/8564 [00:37<00:35, 115.13 examples/s]Tokenizing train dataset:  53%|█████▎    | 4527/8564 [00:38<00:33, 119.27 examples/s]Tokenizing train dataset:  53%|█████▎    | 4542/8564 [00:38<00:32, 123.28 examples/s]Tokenizing train dataset:  53%|█████▎    | 4561/8564 [00:38<00:28, 139.00 examples/s]Tokenizing train dataset:  53%|█████▎    | 4578/8564 [00:38<00:31, 127.56 examples/s]Tokenizing train dataset:  54%|█████▎    | 4598/8564 [00:38<00:31, 125.57 examples/s]Tokenizing train dataset:  54%|█████▍    | 4611/8564 [00:38<00:31, 125.32 examples/s]Tokenizing train dataset:  54%|█████▍    | 4625/8564 [00:38<00:31, 125.86 examples/s]Tokenizing train dataset:  54%|█████▍    | 4643/8564 [00:38<00:32, 121.79 examples/s]Tokenizing train dataset:  54%|█████▍    | 4661/8564 [00:39<00:33, 117.82 examples/s]Tokenizing train dataset:  55%|█████▍    | 4674/8564 [00:39<00:33, 115.93 examples/s]Tokenizing train dataset:  55%|█████▍    | 4691/8564 [00:39<00:35, 109.04 examples/s]Tokenizing train dataset:  55%|█████▍    | 4709/8564 [00:39<00:34, 110.51 examples/s]Tokenizing train dataset:  55%|█████▌    | 4721/8564 [00:39<00:35, 107.73 examples/s]Tokenizing train dataset:  55%|█████▌    | 4737/8564 [00:39<00:32, 118.33 examples/s]Tokenizing train dataset:  55%|█████▌    | 4753/8564 [00:39<00:33, 112.26 examples/s]Tokenizing train dataset:  56%|█████▌    | 4767/8564 [00:40<00:33, 112.53 examples/s]Tokenizing train dataset:  56%|█████▌    | 4779/8564 [00:40<00:34, 109.71 examples/s]Tokenizing train dataset:  56%|█████▌    | 4795/8564 [00:40<00:32, 116.65 examples/s]Tokenizing train dataset:  56%|█████▌    | 4816/8564 [00:40<00:26, 139.35 examples/s]Tokenizing train dataset:  57%|█████▋    | 4843/8564 [00:40<00:22, 167.85 examples/s]Tokenizing train dataset:  57%|█████▋    | 4863/8564 [00:40<00:21, 168.62 examples/s]Tokenizing train dataset:  57%|█████▋    | 4894/8564 [00:40<00:21, 172.67 examples/s]Tokenizing train dataset:  57%|█████▋    | 4919/8564 [00:40<00:19, 186.81 examples/s]Tokenizing train dataset:  58%|█████▊    | 4943/8564 [00:41<00:18, 193.50 examples/s]Tokenizing train dataset:  58%|█████▊    | 4977/8564 [00:41<00:16, 220.56 examples/s]Tokenizing train dataset:  58%|█████▊    | 5003/8564 [00:41<00:16, 220.34 examples/s]Tokenizing train dataset:  59%|█████▉    | 5033/8564 [00:41<00:17, 207.42 examples/s]Tokenizing train dataset:  59%|█████▉    | 5062/8564 [00:41<00:15, 226.37 examples/s]Tokenizing train dataset:  59%|█████▉    | 5087/8564 [00:41<00:15, 231.59 examples/s]Tokenizing train dataset:  60%|█████▉    | 5118/8564 [00:41<00:15, 220.40 examples/s]Tokenizing train dataset:  60%|██████    | 5150/8564 [00:41<00:15, 216.24 examples/s]Tokenizing train dataset:  60%|██████    | 5177/8564 [00:42<00:14, 227.47 examples/s]Tokenizing train dataset:  61%|██████    | 5217/8564 [00:42<00:14, 227.22 examples/s]Tokenizing train dataset:  61%|██████▏   | 5252/8564 [00:42<00:14, 227.64 examples/s]Tokenizing train dataset:  62%|██████▏   | 5283/8564 [00:42<00:13, 244.77 examples/s]Tokenizing train dataset:  62%|██████▏   | 5320/8564 [00:42<00:13, 236.34 examples/s]Tokenizing train dataset:  63%|██████▎   | 5356/8564 [00:42<00:13, 229.44 examples/s]Tokenizing train dataset:  63%|██████▎   | 5388/8564 [00:42<00:14, 221.41 examples/s]Tokenizing train dataset:  63%|██████▎   | 5422/8564 [00:43<00:14, 213.49 examples/s]Tokenizing train dataset:  64%|██████▎   | 5451/8564 [00:43<00:13, 226.56 examples/s]Tokenizing train dataset:  64%|██████▍   | 5482/8564 [00:43<00:14, 211.56 examples/s]Tokenizing train dataset:  64%|██████▍   | 5506/8564 [00:43<00:14, 209.06 examples/s]Tokenizing train dataset:  65%|██████▍   | 5537/8564 [00:43<00:14, 205.12 examples/s]Tokenizing train dataset:  65%|██████▍   | 5559/8564 [00:43<00:15, 194.79 examples/s]Tokenizing train dataset:  65%|██████▌   | 5581/8564 [00:43<00:14, 199.31 examples/s]Tokenizing train dataset:  66%|██████▌   | 5611/8564 [00:44<00:13, 222.22 examples/s]Tokenizing train dataset:  66%|██████▌   | 5649/8564 [00:44<00:13, 221.71 examples/s]Tokenizing train dataset:  66%|██████▋   | 5682/8564 [00:44<00:13, 220.42 examples/s]Tokenizing train dataset:  67%|██████▋   | 5710/8564 [00:44<00:12, 232.52 examples/s]Tokenizing train dataset:  67%|██████▋   | 5734/8564 [00:44<00:12, 226.62 examples/s]Tokenizing train dataset:  67%|██████▋   | 5761/8564 [00:44<00:11, 235.96 examples/s]Tokenizing train dataset:  68%|██████▊   | 5788/8564 [00:44<00:11, 235.09 examples/s]Tokenizing train dataset:  68%|██████▊   | 5812/8564 [00:44<00:12, 226.60 examples/s]Tokenizing train dataset:  68%|██████▊   | 5835/8564 [00:45<00:12, 220.40 examples/s]Tokenizing train dataset:  68%|██████▊   | 5860/8564 [00:45<00:12, 217.45 examples/s]Tokenizing train dataset:  69%|██████▊   | 5884/8564 [00:45<00:13, 194.59 examples/s]Tokenizing train dataset:  69%|██████▉   | 5917/8564 [00:45<00:11, 221.67 examples/s]Tokenizing train dataset:  69%|██████▉   | 5940/8564 [00:45<00:11, 223.49 examples/s]Tokenizing train dataset:  70%|██████▉   | 5977/8564 [00:45<00:10, 254.24 examples/s]Tokenizing train dataset:  70%|███████   | 6014/8564 [00:46<00:19, 131.05 examples/s]Tokenizing train dataset:  70%|███████   | 6035/8564 [00:46<00:18, 139.35 examples/s]Tokenizing train dataset:  71%|███████   | 6062/8564 [00:46<00:15, 160.16 examples/s]Tokenizing train dataset:  71%|███████   | 6093/8564 [00:46<00:14, 166.15 examples/s]Tokenizing train dataset:  71%|███████▏  | 6115/8564 [00:46<00:13, 175.57 examples/s]Tokenizing train dataset:  72%|███████▏  | 6144/8564 [00:46<00:12, 198.58 examples/s]Tokenizing train dataset:  72%|███████▏  | 6175/8564 [00:46<00:10, 223.48 examples/s]Tokenizing train dataset:  72%|███████▏  | 6201/8564 [00:46<00:10, 232.44 examples/s]Tokenizing train dataset:  73%|███████▎  | 6239/8564 [00:47<00:08, 270.18 examples/s]Tokenizing train dataset:  73%|███████▎  | 6268/8564 [00:47<00:08, 268.46 examples/s]Tokenizing train dataset:  74%|███████▎  | 6300/8564 [00:47<00:09, 242.12 examples/s]Tokenizing train dataset:  74%|███████▍  | 6326/8564 [00:47<00:09, 240.88 examples/s]Tokenizing train dataset:  74%|███████▍  | 6354/8564 [00:47<00:08, 248.88 examples/s]Tokenizing train dataset:  75%|███████▍  | 6382/8564 [00:47<00:08, 253.42 examples/s]Tokenizing train dataset:  75%|███████▍  | 6408/8564 [00:47<00:08, 243.06 examples/s]Tokenizing train dataset:  75%|███████▌  | 6444/8564 [00:47<00:09, 232.82 examples/s]Tokenizing train dataset:  76%|███████▌  | 6477/8564 [00:48<00:09, 226.20 examples/s]Tokenizing train dataset:  76%|███████▌  | 6510/8564 [00:48<00:09, 216.85 examples/s]Tokenizing train dataset:  76%|███████▋  | 6535/8564 [00:48<00:09, 223.89 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [00:48<00:09, 207.45 examples/s]Tokenizing train dataset:  77%|███████▋  | 6589/8564 [00:48<00:10, 190.66 examples/s]Tokenizing train dataset:  77%|███████▋  | 6617/8564 [00:48<00:10, 181.53 examples/s]Tokenizing train dataset:  78%|███████▊  | 6642/8564 [00:48<00:09, 195.58 examples/s]Tokenizing train dataset:  78%|███████▊  | 6664/8564 [00:49<00:09, 200.89 examples/s]Tokenizing train dataset:  78%|███████▊  | 6699/8564 [00:49<00:08, 223.43 examples/s]Tokenizing train dataset:  79%|███████▊  | 6725/8564 [00:49<00:08, 217.26 examples/s]Tokenizing train dataset:  79%|███████▉  | 6750/8564 [00:49<00:08, 222.11 examples/s]Tokenizing train dataset:  79%|███████▉  | 6775/8564 [00:49<00:08, 219.08 examples/s]Tokenizing train dataset:  79%|███████▉  | 6804/8564 [00:49<00:07, 228.74 examples/s]Tokenizing train dataset:  80%|███████▉  | 6828/8564 [00:49<00:08, 213.37 examples/s]Tokenizing train dataset:  80%|████████  | 6859/8564 [00:49<00:08, 203.83 examples/s]Tokenizing train dataset:  80%|████████  | 6889/8564 [00:50<00:07, 214.78 examples/s]Tokenizing train dataset:  81%|████████  | 6919/8564 [00:50<00:07, 226.38 examples/s]Tokenizing train dataset:  81%|████████  | 6948/8564 [00:50<00:06, 233.47 examples/s]Tokenizing train dataset:  82%|████████▏ | 6982/8564 [00:50<00:07, 217.98 examples/s]Tokenizing train dataset:  82%|████████▏ | 7005/8564 [00:50<00:07, 213.39 examples/s]Tokenizing train dataset:  82%|████████▏ | 7037/8564 [00:50<00:07, 206.57 examples/s]Tokenizing train dataset:  82%|████████▏ | 7062/8564 [00:50<00:06, 215.71 examples/s]Tokenizing train dataset:  83%|████████▎ | 7090/8564 [00:50<00:06, 229.97 examples/s]Tokenizing train dataset:  83%|████████▎ | 7115/8564 [00:51<00:06, 232.46 examples/s]Tokenizing train dataset:  83%|████████▎ | 7150/8564 [00:51<00:06, 221.91 examples/s]Tokenizing train dataset:  84%|████████▍ | 7176/8564 [00:51<00:06, 226.40 examples/s]Tokenizing train dataset:  84%|████████▍ | 7209/8564 [00:51<00:05, 229.71 examples/s]Tokenizing train dataset:  85%|████████▍ | 7239/8564 [00:51<00:06, 208.04 examples/s]Tokenizing train dataset:  85%|████████▍ | 7261/8564 [00:51<00:06, 204.16 examples/s]Tokenizing train dataset:  85%|████████▌ | 7290/8564 [00:51<00:05, 218.71 examples/s]Tokenizing train dataset:  85%|████████▌ | 7314/8564 [00:51<00:05, 215.36 examples/s]Tokenizing train dataset:  86%|████████▌ | 7344/8564 [00:52<00:05, 233.59 examples/s]Tokenizing train dataset:  86%|████████▌ | 7381/8564 [00:52<00:04, 262.69 examples/s]Tokenizing train dataset:  87%|████████▋ | 7414/8564 [00:52<00:04, 244.32 examples/s]Tokenizing train dataset:  87%|████████▋ | 7443/8564 [00:52<00:04, 252.83 examples/s]Tokenizing train dataset:  87%|████████▋ | 7470/8564 [00:52<00:04, 247.66 examples/s]Tokenizing train dataset:  88%|████████▊ | 7504/8564 [00:52<00:04, 238.08 examples/s]Tokenizing train dataset:  88%|████████▊ | 7529/8564 [00:52<00:04, 236.45 examples/s]Tokenizing train dataset:  88%|████████▊ | 7553/8564 [00:52<00:04, 236.45 examples/s]Tokenizing train dataset:  89%|████████▊ | 7583/8564 [00:53<00:03, 252.98 examples/s]Tokenizing train dataset:  89%|████████▉ | 7620/8564 [00:53<00:03, 241.46 examples/s]Tokenizing train dataset:  89%|████████▉ | 7651/8564 [00:53<00:04, 227.25 examples/s]Tokenizing train dataset:  90%|████████▉ | 7682/8564 [00:53<00:04, 212.19 examples/s]Tokenizing train dataset:  90%|████████▉ | 7707/8564 [00:53<00:03, 220.08 examples/s]Tokenizing train dataset:  90%|█████████ | 7735/8564 [00:53<00:04, 201.89 examples/s]Tokenizing train dataset:  91%|█████████ | 7762/8564 [00:53<00:04, 192.39 examples/s]Tokenizing train dataset:  91%|█████████ | 7790/8564 [00:54<00:04, 187.98 examples/s]Tokenizing train dataset:  91%|█████████ | 7811/8564 [00:54<00:03, 191.76 examples/s]Tokenizing train dataset:  92%|█████████▏| 7838/8564 [00:54<00:03, 197.11 examples/s]Tokenizing train dataset:  92%|█████████▏| 7865/8564 [00:54<00:03, 204.82 examples/s]Tokenizing train dataset:  92%|█████████▏| 7891/8564 [00:54<00:03, 217.08 examples/s]Tokenizing train dataset:  93%|█████████▎| 7923/8564 [00:54<00:03, 213.62 examples/s]Tokenizing train dataset:  93%|█████████▎| 7951/8564 [00:54<00:02, 211.56 examples/s]Tokenizing train dataset:  93%|█████████▎| 7974/8564 [00:54<00:02, 215.76 examples/s]Tokenizing train dataset:  93%|█████████▎| 8002/8564 [00:55<00:02, 231.85 examples/s]Tokenizing train dataset:  94%|█████████▍| 8035/8564 [00:55<00:02, 220.41 examples/s]Tokenizing train dataset:  94%|█████████▍| 8063/8564 [00:55<00:02, 218.55 examples/s]Tokenizing train dataset:  94%|█████████▍| 8092/8564 [00:55<00:02, 207.71 examples/s]Tokenizing train dataset:  95%|█████████▍| 8115/8564 [00:55<00:02, 211.69 examples/s]Tokenizing train dataset:  95%|█████████▌| 8147/8564 [00:55<00:02, 203.94 examples/s]Tokenizing train dataset:  95%|█████████▌| 8172/8564 [00:55<00:01, 212.63 examples/s]Tokenizing train dataset:  96%|█████████▌| 8199/8564 [00:56<00:01, 211.92 examples/s]Tokenizing train dataset:  96%|█████████▌| 8222/8564 [00:56<00:01, 207.16 examples/s]Tokenizing train dataset:  96%|█████████▋| 8248/8564 [00:56<00:01, 220.23 examples/s]Tokenizing train dataset:  97%|█████████▋| 8284/8564 [00:56<00:01, 248.99 examples/s]Tokenizing train dataset:  97%|█████████▋| 8310/8564 [00:56<00:01, 240.77 examples/s]Tokenizing train dataset:  97%|█████████▋| 8344/8564 [00:56<00:00, 225.39 examples/s]Tokenizing train dataset:  98%|█████████▊| 8375/8564 [00:56<00:00, 216.44 examples/s]Tokenizing train dataset:  98%|█████████▊| 8417/8564 [00:56<00:00, 228.24 examples/s]Tokenizing train dataset:  99%|█████████▊| 8449/8564 [00:57<00:00, 220.69 examples/s]Tokenizing train dataset:  99%|█████████▉| 8487/8564 [00:57<00:00, 246.58 examples/s]Tokenizing train dataset:  99%|█████████▉| 8517/8564 [00:57<00:00, 257.62 examples/s]Tokenizing train dataset: 100%|█████████▉| 8546/8564 [00:57<00:00, 257.99 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:57<00:00, 148.86 examples/s]
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   4%|▎         | 309/8564 [00:00<00:02, 3017.55 examples/s]Extracting prompt in train dataset:   4%|▍         | 328/8564 [00:00<00:02, 3209.95 examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   7%|▋         | 640/8564 [00:00<00:02, 3154.56 examples/s]Extracting prompt in train dataset:   2%|▏         | 174/8564 [00:00<00:05, 1563.01 examples/s]Extracting prompt in train dataset:   9%|▉         | 770/8564 [00:00<00:03, 2398.53 examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   4%|▍         | 341/8564 [00:00<00:05, 1619.02 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1010/8564 [00:00<00:03, 2237.20 examples/s]Extracting prompt in eval dataset:  37%|███▋      | 350/953 [00:00<00:00, 3277.08 examples/s]Extracting prompt in train dataset:   6%|▌         | 520/8564 [00:00<00:05, 1602.63 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1090/8564 [00:00<00:03, 1948.49 examples/s]Extracting prompt in eval dataset:  72%|███████▏  | 690/953 [00:00<00:00, 3333.97 examples/s]Extracting prompt in train dataset:   8%|▊         | 686/8564 [00:00<00:04, 1602.81 examples/s]Extracting prompt in train dataset:  15%|█▍        | 1270/8564 [00:00<00:03, 2029.84 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3337.58 examples/s]
Extracting prompt in train dataset:  10%|▉         | 850/8564 [00:00<00:04, 1614.78 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1337/8564 [00:00<00:04, 1795.99 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1533/8564 [00:00<00:03, 1891.68 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1040/8564 [00:00<00:04, 1578.18 examples/s]Extracting prompt in train dataset:  19%|█▊        | 1590/8564 [00:00<00:04, 1743.19 examples/s]Extracting prompt in train dataset:  20%|██        | 1740/8564 [00:00<00:03, 1870.36 examples/s]Extracting prompt in train dataset:  14%|█▍        | 1230/8564 [00:00<00:04, 1661.78 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1940/8564 [00:00<00:03, 1899.73 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1420/8564 [00:00<00:04, 1677.31 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1845/8564 [00:01<00:04, 1676.29 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1610/8564 [00:00<00:03, 1739.77 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2232/8564 [00:01<00:03, 1857.52 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2090/8564 [00:01<00:03, 1648.26 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2430/8564 [00:01<00:03, 1884.99 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1850/8564 [00:01<00:04, 1671.63 examples/s]Extracting prompt in train dataset:  26%|██▋       | 2258/8564 [00:01<00:03, 1651.48 examples/s]Extracting prompt in train dataset:  24%|██▎       | 2025/8564 [00:01<00:03, 1684.04 examples/s]Extracting prompt in train dataset:  29%|██▊       | 2460/8564 [00:01<00:03, 1740.01 examples/s]Extracting prompt in train dataset:  31%|███▏      | 2691/8564 [00:01<00:03, 1773.81 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2221/8564 [00:01<00:03, 1759.57 examples/s]Extracting prompt in train dataset:  31%|███       | 2669/8564 [00:01<00:03, 1829.20 examples/s]Extracting prompt in train dataset:  34%|███▎      | 2873/8564 [00:01<00:03, 1784.58 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2401/8564 [00:01<00:03, 1743.44 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2950/8564 [00:01<00:03, 1821.45 examples/s]Extracting prompt in train dataset:  36%|███▌      | 3090/8564 [00:01<00:03, 1664.00 examples/s]Extracting prompt in train dataset:  30%|███       | 2603/8564 [00:01<00:03, 1821.02 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  38%|███▊      | 3260/8564 [00:01<00:03, 1664.78 examples/s]Applying chat template to eval dataset:  41%|████      | 386/953 [00:00<00:00, 3429.91 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3190/8564 [00:01<00:03, 1702.65 examples/s]Extracting prompt in train dataset:  34%|███▎      | 2870/8564 [00:01<00:03, 1744.77 examples/s]Extracting prompt in train dataset:  40%|████      | 3438/8564 [00:01<00:03, 1598.14 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3370/8564 [00:01<00:03, 1717.50 examples/s]Applying chat template to eval dataset:  89%|████████▉ | 851/953 [00:00<00:00, 3915.24 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3709.81 examples/s]
Extracting prompt in train dataset:  43%|████▎     | 3673/8564 [00:01<00:02, 1755.39 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3580/8564 [00:02<00:03, 1566.79 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3881/8564 [00:02<00:02, 1790.43 examples/s]Extracting prompt in train dataset:  36%|███▌      | 3050/8564 [00:01<00:04, 1194.88 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3350/8564 [00:02<00:03, 1554.73 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3810/8564 [00:02<00:03, 1451.89 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4090/8564 [00:02<00:02, 1592.42 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4000/8564 [00:02<00:03, 1519.58 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4260/8564 [00:02<00:02, 1555.41 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3590/8564 [00:02<00:03, 1561.63 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4460/8564 [00:02<00:02, 1638.41 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4222/8564 [00:02<00:02, 1490.12 examples/s]Extracting prompt in train dataset:  45%|████▍     | 3840/8564 [00:02<00:03, 1484.81 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 4690/8564 [00:02<00:02, 1775.13 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4444/8564 [00:02<00:02, 1436.33 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4970/8564 [00:02<00:01, 1991.17 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4060/8564 [00:02<00:03, 1458.74 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 4650/8564 [00:02<00:02, 1563.86 examples/s]Extracting prompt in train dataset:  60%|██████    | 5180/8564 [00:02<00:01, 2008.64 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4910/8564 [00:02<00:02, 1809.29 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4250/8564 [00:02<00:03, 1357.77 examples/s]Extracting prompt in train dataset:  61%|██████    | 5220/8564 [00:02<00:01, 2124.81 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4412/8564 [00:02<00:03, 1358.61 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5480/8564 [00:03<00:01, 1709.09 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5491/8564 [00:03<00:01, 2273.66 examples/s]Extracting prompt in train dataset:  54%|█████▎    | 4591/8564 [00:03<00:03, 1284.45 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5700/8564 [00:03<00:01, 1629.71 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5750/8564 [00:03<00:01, 2060.61 examples/s]Extracting prompt in train dataset:  69%|██████▊   | 5873/8564 [00:03<00:01, 1650.97 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4800/8564 [00:03<00:02, 1419.01 examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:09, 101.22 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4963/8564 [00:03<00:02, 1462.18 examples/s]Extracting prompt in train dataset:  70%|███████   | 6027/8564 [00:03<00:01, 1931.31 examples/s]Tokenizing eval dataset:   3%|▎         | 24/953 [00:00<00:08, 103.56 examples/s]Extracting prompt in train dataset:  71%|███████▏  | 6117/8564 [00:03<00:01, 1595.33 examples/s]Extracting prompt in train dataset:  60%|██████    | 5170/8564 [00:03<00:02, 1558.62 examples/s]Tokenizing eval dataset:   4%|▎         | 35/953 [00:00<00:09, 98.87 examples/s] Extracting prompt in train dataset:  74%|███████▎  | 6310/8564 [00:03<00:01, 1912.31 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6372/8564 [00:03<00:01, 1626.32 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5350/8564 [00:03<00:01, 1614.59 examples/s]Tokenizing eval dataset:   5%|▍         | 46/953 [00:00<00:09, 93.30 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5533/8564 [00:03<00:01, 1648.34 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6575/8564 [00:03<00:01, 1838.02 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6640/8564 [00:03<00:01, 1614.05 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5707/8564 [00:03<00:01, 1650.10 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6771/8564 [00:03<00:00, 1839.19 examples/s]Tokenizing eval dataset:   6%|▌         | 57/953 [00:00<00:11, 81.20 examples/s]Extracting prompt in train dataset:  80%|████████  | 6884/8564 [00:03<00:01, 1584.35 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5910/8564 [00:03<00:01, 1701.43 examples/s]Extracting prompt in train dataset:  81%|████████▏ | 6970/8564 [00:03<00:00, 1837.25 examples/s]Tokenizing eval dataset:   7%|▋         | 67/953 [00:00<00:10, 81.72 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 7260/8564 [00:04<00:00, 2103.33 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7110/8564 [00:04<00:00, 1560.65 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6160/8564 [00:03<00:01, 1626.82 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:10, 80.54 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7315/8564 [00:04<00:00, 1634.53 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7500/8564 [00:04<00:00, 1820.38 examples/s]Tokenizing eval dataset:   9%|▉         | 90/953 [00:01<00:10, 79.73 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6370/8564 [00:04<00:01, 1512.24 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7559/8564 [00:04<00:00, 1822.91 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6600/8564 [00:04<00:01, 1454.56 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:01<00:12, 67.81 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6790/8564 [00:04<00:01, 1435.88 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:01<00:12, 68.82 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7730/8564 [00:04<00:00, 1001.21 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7937/8564 [00:04<00:00, 1244.18 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:01<00:13, 62.70 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8270/8564 [00:04<00:00, 1580.36 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 7030/8564 [00:04<00:01, 1167.80 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7935/8564 [00:04<00:00, 1032.71 examples/s]Tokenizing eval dataset:  13%|█▎        | 128/953 [00:01<00:13, 63.36 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8511/8564 [00:04<00:00, 1699.68 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7180/8564 [00:04<00:01, 1225.80 examples/s]Extracting prompt in train dataset:  95%|█████████▌| 8160/8564 [00:04<00:00, 1227.08 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:01<00:11, 69.67 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7350/8564 [00:04<00:00, 1305.98 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8500/8564 [00:05<00:00, 1629.91 examples/s]Tokenizing eval dataset:  16%|█▌        | 149/953 [00:01<00:10, 73.29 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7540/8564 [00:05<00:00, 1436.32 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1667.76 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1662.81 examples/s]
Tokenizing eval dataset:  16%|█▋        | 157/953 [00:02<00:11, 71.48 examples/s]Tokenizing eval dataset:  17%|█▋        | 165/953 [00:02<00:10, 72.12 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7730/8564 [00:05<00:00, 1102.52 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:02<00:08, 86.65 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7876/8564 [00:05<00:00, 1046.94 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:02<00:08, 85.11 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8090/8564 [00:05<00:00, 1264.75 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8350/8564 [00:05<00:00, 1557.49 examples/s]Tokenizing eval dataset:  21%|██▏       | 203/953 [00:02<00:08, 83.53 examples/s]Tokenizing eval dataset:  22%|██▏       | 212/953 [00:02<00:08, 82.83 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 8560/8564 [00:05<00:00, 1635.78 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1484.62 examples/s]
Tokenizing eval dataset:  24%|██▍       | 229/953 [00:02<00:06, 104.13 examples/s]Tokenizing eval dataset:  26%|██▌       | 249/953 [00:02<00:05, 128.95 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  28%|██▊       | 266/953 [00:03<00:04, 139.46 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 102/8564 [00:00<00:10, 834.54 examples/s]Tokenizing eval dataset:  30%|███       | 290/953 [00:03<00:04, 160.96 examples/s]Applying chat template to train dataset:   1%|          | 82/8564 [00:00<00:11, 748.82 examples/s]Applying chat template to train dataset:   2%|▏         | 212/8564 [00:00<00:08, 975.48 examples/s]Applying chat template to train dataset:   2%|▏         | 188/8564 [00:00<00:09, 921.85 examples/s]Tokenizing eval dataset:  32%|███▏      | 308/953 [00:03<00:04, 156.29 examples/s]Applying chat template to train dataset:   4%|▍         | 326/8564 [00:00<00:07, 1042.63 examples/s]Applying chat template to train dataset:   4%|▎         | 307/8564 [00:00<00:08, 1018.48 examples/s]Tokenizing eval dataset:  35%|███▍      | 330/953 [00:03<00:03, 168.42 examples/s]Applying chat template to train dataset:   5%|▌         | 440/8564 [00:00<00:07, 1023.58 examples/s]Applying chat template to train dataset:   5%|▍         | 417/8564 [00:00<00:08, 1006.28 examples/s]Tokenizing eval dataset:  37%|███▋      | 350/953 [00:03<00:03, 174.88 examples/s]Applying chat template to train dataset:   6%|▋         | 550/8564 [00:00<00:07, 1044.62 examples/s]Applying chat template to train dataset:   6%|▌         | 526/8564 [00:00<00:07, 1033.54 examples/s]Tokenizing eval dataset:  39%|███▊      | 369/953 [00:03<00:03, 163.85 examples/s]Applying chat template to train dataset:   8%|▊         | 656/8564 [00:00<00:07, 1024.54 examples/s]Applying chat template to train dataset:   8%|▊         | 651/8564 [00:00<00:07, 1075.37 examples/s]Tokenizing eval dataset:  41%|████      | 391/953 [00:03<00:03, 173.92 examples/s]Applying chat template to train dataset:   9%|▉         | 770/8564 [00:00<00:07, 1059.26 examples/s]Applying chat template to train dataset:   9%|▉         | 770/8564 [00:00<00:07, 1107.78 examples/s]Tokenizing eval dataset:  43%|████▎     | 409/953 [00:03<00:03, 170.82 examples/s]Applying chat template to train dataset:  10%|█         | 881/8564 [00:00<00:07, 1073.37 examples/s]Applying chat template to train dataset:  11%|█         | 932/8564 [00:00<00:07, 1078.55 examples/s]Applying chat template to train dataset:  12%|█▏        | 999/8564 [00:00<00:07, 1077.88 examples/s]Tokenizing eval dataset:  46%|████▌     | 435/953 [00:03<00:02, 186.90 examples/s]Applying chat template to train dataset:  12%|█▏        | 1048/8564 [00:00<00:06, 1099.31 examples/s]Tokenizing eval dataset:  48%|████▊     | 461/953 [00:04<00:02, 201.99 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:  13%|█▎        | 1151/8564 [00:01<00:07, 1017.94 examples/s]Applying chat template to train dataset:   1%|          | 77/8564 [00:00<00:11, 757.41 examples/s]Applying chat template to train dataset:  14%|█▍        | 1201/8564 [00:01<00:07, 1032.88 examples/s]Tokenizing eval dataset:  51%|█████     | 484/953 [00:04<00:02, 178.58 examples/s]Applying chat template to train dataset:  15%|█▌        | 1292/8564 [00:01<00:07, 987.76 examples/s] Applying chat template to train dataset:   2%|▏         | 170/8564 [00:00<00:10, 805.06 examples/s]Applying chat template to train dataset:  15%|█▌        | 1313/8564 [00:01<00:07, 1025.76 examples/s]Tokenizing eval dataset:  53%|█████▎    | 506/953 [00:04<00:02, 186.16 examples/s]Applying chat template to train dataset:   3%|▎         | 263/8564 [00:00<00:09, 858.54 examples/s]Applying chat template to train dataset:  17%|█▋        | 1427/8564 [00:01<00:07, 956.74 examples/s]Applying chat template to train dataset:  17%|█▋        | 1422/8564 [00:01<00:06, 1024.51 examples/s]Applying chat template to train dataset:   4%|▍         | 369/8564 [00:00<00:08, 933.88 examples/s]Tokenizing eval dataset:  56%|█████▌    | 532/953 [00:04<00:02, 176.37 examples/s]Applying chat template to train dataset:  18%|█▊        | 1530/8564 [00:01<00:07, 971.93 examples/s]Applying chat template to train dataset:  18%|█▊        | 1573/8564 [00:01<00:06, 1016.84 examples/s]Applying chat template to train dataset:   5%|▌         | 470/8564 [00:00<00:08, 957.60 examples/s]Tokenizing eval dataset:  59%|█████▊    | 558/953 [00:04<00:02, 190.60 examples/s]Applying chat template to train dataset:  19%|█▉        | 1658/8564 [00:01<00:07, 930.03 examples/s]Applying chat template to train dataset:   7%|▋         | 575/8564 [00:00<00:08, 986.95 examples/s]Applying chat template to train dataset:  20%|██        | 1715/8564 [00:01<00:06, 991.72 examples/s] Tokenizing eval dataset:  62%|██████▏   | 587/953 [00:04<00:01, 186.23 examples/s]Applying chat template to train dataset:   8%|▊         | 675/8564 [00:00<00:08, 956.50 examples/s]Applying chat template to train dataset:  21%|██        | 1797/8564 [00:01<00:07, 927.27 examples/s]Tokenizing eval dataset:  64%|██████▍   | 610/953 [00:04<00:01, 191.41 examples/s]Applying chat template to train dataset:  22%|██▏       | 1856/8564 [00:01<00:07, 952.91 examples/s]Applying chat template to train dataset:   9%|▉         | 780/8564 [00:00<00:07, 981.20 examples/s]Applying chat template to train dataset:  22%|██▏       | 1926/8564 [00:01<00:07, 904.33 examples/s]Tokenizing eval dataset:  66%|██████▌   | 630/953 [00:04<00:01, 192.74 examples/s]Applying chat template to train dataset:  23%|██▎       | 1953/8564 [00:01<00:07, 940.27 examples/s]Applying chat template to train dataset:  10%|█         | 890/8564 [00:00<00:07, 997.65 examples/s]Applying chat template to train dataset:  24%|██▎       | 2025/8564 [00:02<00:07, 923.37 examples/s]Applying chat template to train dataset:  12%|█▏        | 1020/8564 [00:01<00:07, 1072.93 examples/s]Applying chat template to train dataset:  24%|██▍       | 2081/8564 [00:02<00:07, 907.78 examples/s]Tokenizing eval dataset:  69%|██████▉   | 657/953 [00:05<00:01, 181.27 examples/s]Applying chat template to train dataset:  25%|██▍       | 2121/8564 [00:02<00:07, 908.84 examples/s]Applying chat template to train dataset:  13%|█▎        | 1133/8564 [00:01<00:06, 1067.26 examples/s]Applying chat template to train dataset:  26%|██▌       | 2218/8564 [00:02<00:06, 912.44 examples/s]Applying chat template to train dataset:  26%|██▌       | 2220/8564 [00:02<00:07, 904.56 examples/s]Tokenizing eval dataset:  72%|███████▏  | 685/953 [00:05<00:01, 178.47 examples/s]Applying chat template to train dataset:  15%|█▌        | 1300/8564 [00:01<00:06, 1048.40 examples/s]Applying chat template to train dataset:  27%|██▋       | 2339/8564 [00:02<00:06, 968.03 examples/s]Applying chat template to train dataset:  27%|██▋       | 2318/8564 [00:02<00:06, 906.90 examples/s]Tokenizing eval dataset:  74%|███████▍  | 709/953 [00:05<00:01, 171.53 examples/s]Applying chat template to train dataset:  29%|██▊       | 2455/8564 [00:02<00:06, 993.58 examples/s]Applying chat template to train dataset:  28%|██▊       | 2418/8564 [00:02<00:06, 900.75 examples/s]Applying chat template to train dataset:  17%|█▋        | 1433/8564 [00:01<00:07, 990.22 examples/s] Applying chat template to train dataset:  30%|██▉       | 2558/8564 [00:02<00:06, 996.86 examples/s]Applying chat template to train dataset:  29%|██▉       | 2520/8564 [00:02<00:06, 928.29 examples/s]Tokenizing eval dataset:  77%|███████▋  | 734/953 [00:05<00:01, 168.59 examples/s]Applying chat template to train dataset:  18%|█▊        | 1567/8564 [00:01<00:07, 932.13 examples/s]Applying chat template to train dataset:  31%|███       | 2659/8564 [00:02<00:05, 999.28 examples/s]Applying chat template to train dataset:  31%|███       | 2620/8564 [00:02<00:06, 946.57 examples/s]Tokenizing eval dataset:  80%|███████▉  | 762/953 [00:05<00:01, 166.94 examples/s]Applying chat template to train dataset:  32%|███▏      | 2760/8564 [00:02<00:05, 998.06 examples/s]Applying chat template to train dataset:  32%|███▏      | 2720/8564 [00:02<00:06, 959.41 examples/s]Applying chat template to train dataset:  20%|█▉        | 1707/8564 [00:01<00:07, 929.75 examples/s]Tokenizing eval dataset:  82%|████████▏ | 780/953 [00:05<00:01, 161.22 examples/s]Applying chat template to train dataset:  34%|███▎      | 2881/8564 [00:02<00:05, 1028.41 examples/s]Applying chat template to train dataset:  21%|██        | 1804/8564 [00:01<00:07, 928.92 examples/s]Applying chat template to train dataset:  34%|███▎      | 2889/8564 [00:02<00:05, 959.92 examples/s]Applying chat template to train dataset:  35%|███▍      | 2987/8564 [00:03<00:05, 994.61 examples/s] Tokenizing eval dataset:  84%|████████▍ | 800/953 [00:06<00:01, 150.44 examples/s]Applying chat template to train dataset:  23%|██▎       | 1942/8564 [00:02<00:07, 924.42 examples/s]Applying chat template to train dataset:  35%|███▍      | 2988/8564 [00:03<00:05, 939.80 examples/s]Tokenizing eval dataset:  86%|████████▌ | 816/953 [00:06<00:00, 145.18 examples/s]Applying chat template to train dataset:  37%|███▋      | 3153/8564 [00:03<00:05, 950.15 examples/s]Applying chat template to train dataset:  24%|██▍       | 2077/8564 [00:02<00:07, 891.16 examples/s]Applying chat template to train dataset:  37%|███▋      | 3132/8564 [00:03<00:06, 790.08 examples/s]Tokenizing eval dataset:  88%|████████▊ | 839/953 [00:06<00:00, 144.79 examples/s]Applying chat template to train dataset:  39%|███▊      | 3301/8564 [00:03<00:05, 940.80 examples/s]Applying chat template to train dataset:  26%|██▌       | 2210/8564 [00:02<00:07, 887.07 examples/s]Applying chat template to train dataset:  38%|███▊      | 3230/8564 [00:03<00:06, 828.04 examples/s]Applying chat template to train dataset:  40%|███▉      | 3403/8564 [00:03<00:05, 954.40 examples/s]Applying chat template to train dataset:  27%|██▋       | 2302/8564 [00:02<00:07, 894.02 examples/s]Tokenizing eval dataset:  90%|█████████ | 860/953 [00:06<00:00, 137.94 examples/s]Applying chat template to train dataset:  39%|███▉      | 3337/8564 [00:03<00:05, 875.51 examples/s]Applying chat template to train dataset:  28%|██▊       | 2396/8564 [00:02<00:06, 902.92 examples/s]Tokenizing eval dataset:  92%|█████████▏| 878/953 [00:06<00:00, 145.59 examples/s]Applying chat template to train dataset:  41%|████▏     | 3540/8564 [00:03<00:05, 927.23 examples/s]Applying chat template to train dataset:  40%|████      | 3432/8564 [00:03<00:05, 889.62 examples/s]Applying chat template to train dataset:  29%|██▉       | 2494/8564 [00:02<00:06, 921.77 examples/s]Applying chat template to train dataset:  42%|████▏     | 3576/8564 [00:03<00:04, 1031.86 examples/s]Tokenizing eval dataset:  94%|█████████▎| 893/953 [00:06<00:00, 137.90 examples/s]Applying chat template to train dataset:  43%|████▎     | 3680/8564 [00:03<00:05, 878.56 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:06<00:00, 134.49 examples/s]Applying chat template to train dataset:  43%|████▎     | 3720/8564 [00:03<00:04, 1095.74 examples/s]Applying chat template to train dataset:  30%|███       | 2610/8564 [00:02<00:07, 821.99 examples/s]Applying chat template to train dataset:  44%|████▍     | 3772/8564 [00:03<00:05, 853.59 examples/s]Tokenizing eval dataset:  97%|█████████▋| 921/953 [00:06<00:00, 133.24 examples/s]Applying chat template to train dataset:  32%|███▏      | 2733/8564 [00:02<00:06, 869.97 examples/s]Applying chat template to train dataset:  45%|████▌     | 3887/8564 [00:03<00:04, 1072.04 examples/s]Applying chat template to train dataset:  45%|████▌     | 3865/8564 [00:04<00:05, 863.01 examples/s]Tokenizing eval dataset:  99%|█████████▊| 940/953 [00:07<00:00, 145.48 examples/s]Applying chat template to train dataset:  33%|███▎      | 2854/8564 [00:03<00:06, 921.89 examples/s]Applying chat template to train dataset:  46%|████▌     | 3952/8564 [00:04<00:05, 860.82 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:07<00:00, 132.71 examples/s]
Applying chat template to train dataset:  47%|████▋     | 4040/8564 [00:04<00:04, 1019.20 examples/s]Applying chat template to train dataset:  34%|███▍      | 2951/8564 [00:03<00:06, 915.35 examples/s]Applying chat template to train dataset:  48%|████▊     | 4095/8564 [00:04<00:04, 982.75 examples/s]Applying chat template to train dataset:  48%|████▊     | 4147/8564 [00:04<00:04, 1002.21 examples/s]Applying chat template to train dataset:  50%|████▉     | 4260/8564 [00:04<00:03, 1159.64 examples/s]Applying chat template to train dataset:  50%|█████     | 4283/8564 [00:04<00:03, 1089.12 examples/s]Applying chat template to train dataset:  36%|███▌      | 3050/8564 [00:03<00:07, 767.63 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4407/8564 [00:04<00:03, 1127.57 examples/s]Applying chat template to train dataset:  37%|███▋      | 3161/8564 [00:03<00:07, 755.22 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4411/8564 [00:04<00:04, 915.58 examples/s] Applying chat template to train dataset:  54%|█████▎    | 4591/8564 [00:04<00:03, 1314.82 examples/s]Applying chat template to train dataset:  38%|███▊      | 3253/8564 [00:03<00:07, 745.91 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4518/8564 [00:04<00:04, 897.17 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4761/8564 [00:04<00:03, 1162.50 examples/s]Applying chat template to train dataset:  39%|███▉      | 3342/8564 [00:03<00:06, 769.96 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4661/8564 [00:04<00:04, 832.54 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4913/8564 [00:04<00:03, 1109.96 examples/s]Applying chat template to train dataset:  40%|████      | 3449/8564 [00:03<00:06, 752.49 examples/s]Applying chat template to train dataset:  41%|████▏     | 3539/8564 [00:04<00:06, 739.96 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4763/8564 [00:05<00:05, 751.71 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5084/8564 [00:05<00:03, 1106.94 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4845/8564 [00:05<00:04, 758.61 examples/s]Applying chat template to train dataset:  43%|████▎     | 3640/8564 [00:04<00:06, 785.15 examples/s]Applying chat template to train dataset:  61%|██████    | 5231/8564 [00:05<00:03, 1048.38 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4930/8564 [00:05<00:05, 721.30 examples/s]Applying chat template to train dataset:  44%|████▎     | 3730/8564 [00:04<00:06, 718.18 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5347/8564 [00:05<00:03, 1064.59 examples/s]Applying chat template to train dataset:  45%|████▍     | 3825/8564 [00:04<00:06, 773.57 examples/s]Applying chat template to train dataset:  58%|█████▊    | 5005/8564 [00:05<00:05, 652.13 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5509/8564 [00:05<00:02, 1048.59 examples/s]Applying chat template to train dataset:  46%|████▌     | 3915/8564 [00:04<00:05, 795.76 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5099/8564 [00:05<00:04, 699.83 examples/s]Applying chat template to train dataset:  47%|████▋     | 4022/8564 [00:04<00:05, 811.91 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5634/8564 [00:05<00:03, 933.45 examples/s] Applying chat template to train dataset:  61%|██████    | 5200/8564 [00:05<00:04, 749.76 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5300/8564 [00:05<00:04, 810.15 examples/s]Applying chat template to train dataset:  48%|████▊     | 4109/8564 [00:04<00:05, 767.30 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5770/8564 [00:05<00:03, 876.58 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5411/8564 [00:05<00:03, 887.81 examples/s]Applying chat template to train dataset:  49%|████▉     | 4198/8564 [00:04<00:06, 713.68 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5518/8564 [00:06<00:03, 891.76 examples/s]Applying chat template to train dataset:  50%|█████     | 4282/8564 [00:04<00:05, 744.63 examples/s]Applying chat template to train dataset:  69%|██████▊   | 5879/8564 [00:06<00:03, 757.02 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5611/8564 [00:06<00:03, 901.20 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5990/8564 [00:06<00:03, 825.64 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4390/8564 [00:05<00:05, 700.09 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5711/8564 [00:06<00:03, 914.29 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6120/8564 [00:06<00:02, 904.26 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5841/8564 [00:06<00:02, 994.80 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4500/8564 [00:05<00:06, 650.65 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6238/8564 [00:06<00:02, 826.63 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5993/8564 [00:06<00:02, 998.89 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6337/8564 [00:06<00:02, 824.36 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6102/8564 [00:06<00:02, 1022.35 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4611/8564 [00:05<00:06, 645.60 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4721/8564 [00:05<00:05, 740.98 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6258/8564 [00:06<00:02, 1026.32 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6438/8564 [00:06<00:02, 760.69 examples/s]Applying chat template to train dataset:  56%|█████▋    | 4823/8564 [00:05<00:04, 805.11 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6370/8564 [00:06<00:02, 1026.68 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4930/8564 [00:05<00:04, 869.09 examples/s]Applying chat template to train dataset:  76%|███████▋  | 6550/8564 [00:06<00:02, 707.53 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6482/8564 [00:06<00:02, 1038.26 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5035/8564 [00:05<00:03, 887.10 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6625/8564 [00:06<00:02, 695.48 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6593/8564 [00:07<00:01, 1054.30 examples/s]Applying chat template to train dataset:  60%|██████    | 5146/8564 [00:06<00:03, 945.30 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6707/8564 [00:07<00:01, 1077.31 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6700/8564 [00:07<00:02, 654.64 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5291/8564 [00:06<00:03, 951.86 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6775/8564 [00:07<00:02, 666.43 examples/s]Applying chat template to train dataset:  80%|████████  | 6868/8564 [00:07<00:01, 1073.81 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5413/8564 [00:06<00:03, 992.66 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6848/8564 [00:07<00:02, 602.26 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7021/8564 [00:07<00:01, 995.42 examples/s] Applying chat template to train dataset:  65%|██████▍   | 5539/8564 [00:06<00:02, 1026.19 examples/s]Applying chat template to train dataset:  81%|████████  | 6927/8564 [00:07<00:02, 636.37 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5650/8564 [00:06<00:02, 1034.61 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7029/8564 [00:07<00:02, 721.30 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7146/8564 [00:07<00:01, 855.38 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5758/8564 [00:06<00:02, 1046.10 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7145/8564 [00:07<00:01, 807.49 examples/s]Applying chat template to train dataset:  69%|██████▊   | 5875/8564 [00:06<00:02, 1061.15 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7281/8564 [00:07<00:01, 861.23 examples/s]Applying chat template to train dataset:  70%|███████   | 6000/8564 [00:06<00:02, 1081.01 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7383/8564 [00:07<00:01, 884.48 examples/s]Applying chat template to train dataset:  85%|████████▍ | 7257/8564 [00:07<00:01, 738.78 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6115/8564 [00:06<00:02, 1068.17 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7500/8564 [00:08<00:01, 948.59 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7353/8564 [00:08<00:01, 692.66 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7601/8564 [00:08<00:01, 948.00 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6284/8564 [00:07<00:02, 1082.97 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7430/8564 [00:08<00:01, 685.79 examples/s]Applying chat template to train dataset:  90%|█████████ | 7721/8564 [00:08<00:00, 1004.90 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6449/8564 [00:07<00:02, 1050.82 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7511/8564 [00:08<00:01, 651.76 examples/s]Applying chat template to train dataset:  89%|████████▊ | 7582/8564 [00:08<00:01, 663.24 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6602/8564 [00:07<00:01, 1037.30 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7651/8564 [00:08<00:01, 667.40 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6714/8564 [00:07<00:01, 1051.69 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7855/8564 [00:08<00:01, 627.69 examples/s] Applying chat template to train dataset:  80%|███████▉  | 6830/8564 [00:07<00:01, 1077.06 examples/s]Applying chat template to train dataset:  90%|█████████ | 7743/8564 [00:08<00:01, 647.61 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7954/8564 [00:08<00:00, 692.91 examples/s]Applying chat template to train dataset:  81%|████████  | 6940/8564 [00:07<00:01, 1057.81 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8079/8564 [00:08<00:00, 773.79 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8190/8564 [00:08<00:00, 833.21 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7091/8564 [00:07<00:01, 1015.10 examples/s]Applying chat template to train dataset:  91%|█████████▏| 7829/8564 [00:08<00:01, 500.11 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7940/8564 [00:09<00:01, 622.45 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7229/8564 [00:08<00:01, 958.51 examples/s] Applying chat template to train dataset:  97%|█████████▋| 8330/8564 [00:09<00:00, 793.00 examples/s]Applying chat template to train dataset:  94%|█████████▎| 8020/8564 [00:09<00:00, 660.91 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7330/8564 [00:08<00:01, 964.42 examples/s]Applying chat template to train dataset:  99%|█████████▊| 8440/8564 [00:09<00:00, 773.96 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8122/8564 [00:09<00:00, 666.55 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7429/8564 [00:08<00:01, 969.35 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7538/8564 [00:08<00:01, 999.93 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:09<00:00, 775.08 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8207/8564 [00:09<00:00, 611.03 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:09<00:00, 895.56 examples/s]
Applying chat template to train dataset:  89%|████████▉ | 7650/8564 [00:08<00:00, 1030.50 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8318/8564 [00:09<00:00, 642.07 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8430/8564 [00:09<00:00, 747.24 examples/s]Applying chat template to train dataset:  91%|█████████ | 7786/8564 [00:08<00:00, 835.65 examples/s] Applying chat template to train dataset: 100%|█████████▉| 8540/8564 [00:09<00:00, 810.91 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:09<00:00, 869.81 examples/s]
Applying chat template to train dataset:  92%|█████████▏| 7888/8564 [00:08<00:00, 773.64 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7981/8564 [00:08<00:00, 778.62 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8109/8564 [00:09<00:00, 827.06 examples/s]Applying chat template to train dataset:  96%|█████████▋| 8247/8564 [00:09<00:00, 950.86 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8387/8564 [00:09<00:00, 883.91 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8537/8564 [00:09<00:00, 1024.54 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:09<00:00, 899.44 examples/s] 
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 1/8564 [00:00<18:54,  7.55 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 20/8564 [00:00<01:28, 96.98 examples/s]Tokenizing train dataset:   0%|          | 14/8564 [00:00<01:19, 108.16 examples/s]Tokenizing train dataset:   0%|          | 40/8564 [00:00<01:06, 128.54 examples/s]Tokenizing train dataset:   0%|          | 30/8564 [00:00<01:09, 122.48 examples/s]Tokenizing train dataset:   1%|          | 43/8564 [00:00<01:36, 88.62 examples/s] Tokenizing train dataset:   1%|          | 56/8564 [00:00<01:34, 90.42 examples/s] Tokenizing train dataset:   1%|          | 70/8564 [00:00<01:27, 97.08 examples/s]Tokenizing train dataset:   1%|          | 56/8564 [00:00<01:34, 90.02 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 71/8564 [00:00<01:20, 104.88 examples/s]Tokenizing train dataset:   1%|          | 85/8564 [00:00<01:18, 108.00 examples/s]Tokenizing train dataset:   0%|          | 13/8564 [00:00<01:28, 96.14 examples/s]Tokenizing train dataset:   1%|          | 85/8564 [00:00<01:19, 106.68 examples/s]Tokenizing train dataset:   0%|          | 27/8564 [00:00<01:18, 109.05 examples/s]Tokenizing train dataset:   1%|          | 101/8564 [00:01<01:41, 83.32 examples/s]Tokenizing train dataset:   0%|          | 41/8564 [00:00<01:12, 118.30 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:01<01:35, 88.63 examples/s]Tokenizing train dataset:   1%|          | 58/8564 [00:00<01:17, 109.68 examples/s]Tokenizing train dataset:   1%|▏         | 111/8564 [00:01<01:33, 90.52 examples/s]Tokenizing train dataset:   1%|▏         | 115/8564 [00:01<01:53, 74.18 examples/s]Tokenizing train dataset:   1%|          | 71/8564 [00:00<01:14, 113.81 examples/s]Tokenizing train dataset:   1%|▏         | 122/8564 [00:01<01:30, 93.29 examples/s]Tokenizing train dataset:   1%|          | 83/8564 [00:00<01:17, 109.21 examples/s]Tokenizing train dataset:   2%|▏         | 130/8564 [00:01<01:52, 74.73 examples/s]Tokenizing train dataset:   2%|▏         | 136/8564 [00:01<01:45, 80.09 examples/s]Tokenizing train dataset:   2%|▏         | 140/8564 [00:01<01:50, 76.48 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:00<01:19, 106.33 examples/s]Tokenizing train dataset:   2%|▏         | 147/8564 [00:01<01:45, 79.60 examples/s]Tokenizing train dataset:   1%|▏         | 112/8564 [00:01<01:20, 105.00 examples/s]Tokenizing train dataset:   2%|▏         | 149/8564 [00:01<01:55, 72.56 examples/s]Tokenizing train dataset:   1%|▏         | 123/8564 [00:01<01:25, 99.00 examples/s] Tokenizing train dataset:   2%|▏         | 160/8564 [00:01<01:56, 72.27 examples/s]Tokenizing train dataset:   2%|▏         | 161/8564 [00:01<01:48, 77.34 examples/s]Tokenizing train dataset:   2%|▏         | 138/8564 [00:01<01:16, 110.42 examples/s]Tokenizing train dataset:   2%|▏         | 170/8564 [00:02<01:52, 74.50 examples/s]Tokenizing train dataset:   2%|▏         | 153/8564 [00:01<01:14, 113.11 examples/s]Tokenizing train dataset:   2%|▏         | 172/8564 [00:02<02:04, 67.16 examples/s]Tokenizing train dataset:   2%|▏         | 179/8564 [00:02<01:49, 76.30 examples/s]Tokenizing train dataset:   2%|▏         | 193/8564 [00:02<01:36, 86.95 examples/s]Tokenizing train dataset:   2%|▏         | 180/8564 [00:02<02:06, 66.02 examples/s]Tokenizing train dataset:   2%|▏         | 167/8564 [00:01<01:21, 102.52 examples/s]Tokenizing train dataset:   2%|▏         | 203/8564 [00:02<01:35, 87.60 examples/s]Tokenizing train dataset:   2%|▏         | 178/8564 [00:01<01:22, 101.54 examples/s]Tokenizing train dataset:   2%|▏         | 189/8564 [00:02<02:05, 66.87 examples/s]Tokenizing train dataset:   2%|▏         | 189/8564 [00:01<01:23, 100.87 examples/s]Tokenizing train dataset:   3%|▎         | 217/8564 [00:02<01:27, 95.10 examples/s]Tokenizing train dataset:   2%|▏         | 198/8564 [00:02<02:01, 69.10 examples/s]Tokenizing train dataset:   3%|▎         | 231/8564 [00:02<01:20, 103.64 examples/s]Tokenizing train dataset:   2%|▏         | 202/8564 [00:01<01:23, 99.92 examples/s] Tokenizing train dataset:   2%|▏         | 206/8564 [00:02<02:04, 66.87 examples/s]Tokenizing train dataset:   3%|▎         | 243/8564 [00:02<01:19, 105.20 examples/s]Tokenizing train dataset:   3%|▎         | 216/8564 [00:02<01:17, 107.16 examples/s]Tokenizing train dataset:   3%|▎         | 215/8564 [00:02<01:57, 71.02 examples/s]Tokenizing train dataset:   3%|▎         | 254/8564 [00:02<01:21, 101.54 examples/s]Tokenizing train dataset:   3%|▎         | 230/8564 [00:02<01:14, 111.84 examples/s]Tokenizing train dataset:   3%|▎         | 226/8564 [00:02<01:50, 75.17 examples/s]Tokenizing train dataset:   3%|▎         | 270/8564 [00:03<01:12, 113.66 examples/s]Tokenizing train dataset:   3%|▎         | 243/8564 [00:02<01:14, 112.43 examples/s]Tokenizing train dataset:   3%|▎         | 234/8564 [00:02<01:56, 71.73 examples/s]Tokenizing train dataset:   3%|▎         | 288/8564 [00:03<01:15, 109.95 examples/s]Tokenizing train dataset:   3%|▎         | 247/8564 [00:03<01:44, 79.75 examples/s]Tokenizing train dataset:   3%|▎         | 257/8564 [00:02<01:24, 98.85 examples/s] Tokenizing train dataset:   3%|▎         | 259/8564 [00:03<01:35, 86.88 examples/s]Tokenizing train dataset:   4%|▎         | 306/8564 [00:03<01:19, 104.06 examples/s]Tokenizing train dataset:   3%|▎         | 273/8564 [00:02<01:28, 94.20 examples/s]Tokenizing train dataset:   3%|▎         | 275/8564 [00:03<01:22, 101.03 examples/s]Tokenizing train dataset:   3%|▎         | 288/8564 [00:03<01:22, 100.31 examples/s]Tokenizing train dataset:   4%|▎         | 320/8564 [00:03<01:27, 93.71 examples/s] Tokenizing train dataset:   3%|▎         | 285/8564 [00:02<01:40, 82.74 examples/s]Tokenizing train dataset:   4%|▎         | 300/8564 [00:03<01:22, 100.24 examples/s]Tokenizing train dataset:   3%|▎         | 295/8564 [00:02<01:39, 82.87 examples/s]Tokenizing train dataset:   4%|▍         | 331/8564 [00:03<01:41, 81.23 examples/s]Tokenizing train dataset:   4%|▎         | 313/8564 [00:03<01:19, 103.90 examples/s]Tokenizing train dataset:   4%|▍         | 340/8564 [00:03<01:45, 78.03 examples/s]Tokenizing train dataset:   4%|▎         | 309/8564 [00:03<01:46, 77.47 examples/s]Tokenizing train dataset:   4%|▍         | 325/8564 [00:03<01:18, 104.39 examples/s]Tokenizing train dataset:   4%|▍         | 336/8564 [00:03<01:21, 101.41 examples/s]Tokenizing train dataset:   4%|▍         | 352/8564 [00:04<01:53, 72.09 examples/s]Tokenizing train dataset:   4%|▍         | 322/8564 [00:03<01:51, 73.70 examples/s]Tokenizing train dataset:   4%|▍         | 350/8564 [00:04<01:24, 97.05 examples/s] Tokenizing train dataset:   4%|▍         | 361/8564 [00:04<01:53, 72.54 examples/s]Tokenizing train dataset:   4%|▍         | 331/8564 [00:03<01:58, 69.60 examples/s]Tokenizing train dataset:   4%|▍         | 364/8564 [00:04<01:18, 104.62 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:04<01:56, 70.63 examples/s]Tokenizing train dataset:   4%|▍         | 340/8564 [00:03<01:58, 69.25 examples/s]Tokenizing train dataset:   4%|▍         | 377/8564 [00:04<01:17, 105.78 examples/s]Tokenizing train dataset:   4%|▍         | 380/8564 [00:04<02:01, 67.60 examples/s]Tokenizing train dataset:   4%|▍         | 349/8564 [00:03<02:03, 66.42 examples/s]Tokenizing train dataset:   5%|▍         | 390/8564 [00:04<01:17, 105.14 examples/s]Tokenizing train dataset:   5%|▍         | 391/8564 [00:04<01:57, 69.51 examples/s]Tokenizing train dataset:   4%|▍         | 359/8564 [00:03<01:59, 68.58 examples/s]Tokenizing train dataset:   5%|▍         | 404/8564 [00:04<01:22, 98.84 examples/s] Tokenizing train dataset:   5%|▍         | 400/8564 [00:04<01:59, 68.10 examples/s]Tokenizing train dataset:   4%|▍         | 368/8564 [00:04<01:59, 68.44 examples/s]Tokenizing train dataset:   5%|▍         | 418/8564 [00:04<01:18, 103.95 examples/s]Tokenizing train dataset:   4%|▍         | 375/8564 [00:04<02:07, 64.14 examples/s]Tokenizing train dataset:   5%|▌         | 432/8564 [00:04<01:15, 107.33 examples/s]Tokenizing train dataset:   5%|▍         | 411/8564 [00:04<02:02, 66.55 examples/s]Tokenizing train dataset:   5%|▍         | 389/8564 [00:04<01:44, 78.31 examples/s]Tokenizing train dataset:   5%|▍         | 419/8564 [00:05<02:10, 62.46 examples/s]Tokenizing train dataset:   5%|▍         | 400/8564 [00:04<01:37, 84.06 examples/s]Tokenizing train dataset:   5%|▌         | 447/8564 [00:05<01:31, 89.00 examples/s] Tokenizing train dataset:   5%|▌         | 430/8564 [00:05<01:54, 71.11 examples/s]Tokenizing train dataset:   5%|▍         | 411/8564 [00:04<01:31, 88.65 examples/s]Tokenizing train dataset:   5%|▌         | 458/8564 [00:05<01:28, 91.53 examples/s]Tokenizing train dataset:   5%|▍         | 422/8564 [00:04<01:27, 93.50 examples/s]Tokenizing train dataset:   6%|▌         | 473/8564 [00:05<01:18, 102.70 examples/s]Tokenizing train dataset:   5%|▌         | 439/8564 [00:05<02:09, 62.82 examples/s]Tokenizing train dataset:   5%|▌         | 433/8564 [00:04<01:28, 92.06 examples/s]Tokenizing train dataset:   5%|▌         | 446/8564 [00:05<02:16, 59.65 examples/s]Tokenizing train dataset:   6%|▌         | 488/8564 [00:05<01:26, 93.53 examples/s] Tokenizing train dataset:   5%|▌         | 445/8564 [00:04<01:26, 93.36 examples/s]Tokenizing train dataset:   6%|▌         | 500/8564 [00:05<01:23, 96.55 examples/s]Tokenizing train dataset:   5%|▌         | 457/8564 [00:05<02:07, 63.65 examples/s]Tokenizing train dataset:   5%|▌         | 461/8564 [00:05<01:20, 100.89 examples/s]Tokenizing train dataset:   5%|▌         | 470/8564 [00:05<01:47, 75.57 examples/s]Tokenizing train dataset:   6%|▌         | 475/8564 [00:05<01:15, 106.72 examples/s]Tokenizing train dataset:   6%|▌         | 481/8564 [00:05<01:41, 79.74 examples/s]Tokenizing train dataset:   6%|▌         | 517/8564 [00:05<01:37, 82.38 examples/s]Tokenizing train dataset:   6%|▌         | 527/8564 [00:05<01:34, 85.13 examples/s]Tokenizing train dataset:   6%|▌         | 492/8564 [00:06<01:39, 81.37 examples/s]Tokenizing train dataset:   6%|▌         | 487/8564 [00:05<01:36, 83.65 examples/s] Tokenizing train dataset:   6%|▌         | 504/8564 [00:06<01:29, 89.59 examples/s]Tokenizing train dataset:   6%|▋         | 540/8564 [00:06<01:28, 90.48 examples/s]Tokenizing train dataset:   6%|▌         | 500/8564 [00:05<01:34, 85.13 examples/s]Tokenizing train dataset:   6%|▋         | 551/8564 [00:06<01:28, 90.93 examples/s]Tokenizing train dataset:   6%|▌         | 517/8564 [00:06<01:27, 91.75 examples/s]Tokenizing train dataset:   7%|▋         | 564/8564 [00:06<01:22, 96.57 examples/s]Tokenizing train dataset:   6%|▌         | 510/8564 [00:05<01:48, 74.21 examples/s]Tokenizing train dataset:   6%|▌         | 530/8564 [00:06<01:23, 96.17 examples/s]Tokenizing train dataset:   7%|▋         | 575/8564 [00:06<01:21, 98.01 examples/s]Tokenizing train dataset:   6%|▋         | 543/8564 [00:06<01:17, 104.07 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:05<01:49, 73.36 examples/s]Tokenizing train dataset:   7%|▋         | 586/8564 [00:06<01:22, 96.62 examples/s]Tokenizing train dataset:   7%|▋         | 560/8564 [00:06<01:17, 103.53 examples/s]Tokenizing train dataset:   6%|▌         | 534/8564 [00:05<01:46, 75.41 examples/s]Tokenizing train dataset:   7%|▋         | 596/8564 [00:06<01:25, 93.15 examples/s]Tokenizing train dataset:   7%|▋         | 571/8564 [00:06<01:22, 97.03 examples/s] Tokenizing train dataset:   6%|▋         | 542/8564 [00:06<01:51, 71.92 examples/s]Tokenizing train dataset:   7%|▋         | 584/8564 [00:06<01:16, 103.83 examples/s]Tokenizing train dataset:   6%|▋         | 552/8564 [00:06<01:43, 77.48 examples/s]Tokenizing train dataset:   7%|▋         | 614/8564 [00:06<01:31, 86.89 examples/s]Tokenizing train dataset:   7%|▋         | 599/8564 [00:07<01:21, 97.74 examples/s] Tokenizing train dataset:   7%|▋         | 566/8564 [00:06<01:32, 86.13 examples/s]Tokenizing train dataset:   7%|▋         | 628/8564 [00:06<01:29, 88.27 examples/s]Tokenizing train dataset:   7%|▋         | 577/8564 [00:06<01:27, 91.09 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:07<01:19, 100.57 examples/s]Tokenizing train dataset:   7%|▋         | 638/8564 [00:07<01:33, 84.36 examples/s]Tokenizing train dataset:   7%|▋         | 589/8564 [00:06<01:26, 91.95 examples/s]Tokenizing train dataset:   7%|▋         | 627/8564 [00:07<01:14, 106.67 examples/s]Tokenizing train dataset:   7%|▋         | 641/8564 [00:07<01:12, 109.23 examples/s]Tokenizing train dataset:   8%|▊         | 653/8564 [00:07<01:39, 79.52 examples/s]Tokenizing train dataset:   7%|▋         | 602/8564 [00:06<01:30, 87.55 examples/s]Tokenizing train dataset:   8%|▊         | 662/8564 [00:07<01:37, 80.67 examples/s]Tokenizing train dataset:   8%|▊         | 654/8564 [00:07<01:12, 108.97 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:06<01:33, 85.22 examples/s]Tokenizing train dataset:   8%|▊         | 671/8564 [00:07<01:38, 80.20 examples/s]Tokenizing train dataset:   8%|▊         | 665/8564 [00:07<01:16, 103.39 examples/s]Tokenizing train dataset:   8%|▊         | 684/8564 [00:07<01:26, 91.55 examples/s]Tokenizing train dataset:   7%|▋         | 628/8564 [00:07<01:34, 83.56 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:07<01:15, 104.00 examples/s]Tokenizing train dataset:   7%|▋         | 638/8564 [00:07<01:35, 83.03 examples/s]Tokenizing train dataset:   8%|▊         | 696/8564 [00:07<01:33, 83.81 examples/s]Tokenizing train dataset:   8%|▊         | 693/8564 [00:08<01:23, 93.84 examples/s] Tokenizing train dataset:   8%|▊         | 648/8564 [00:07<01:40, 79.06 examples/s]Tokenizing train dataset:   8%|▊         | 707/8564 [00:08<01:40, 77.83 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:08<01:25, 92.16 examples/s]Tokenizing train dataset:   8%|▊         | 657/8564 [00:07<01:47, 73.57 examples/s]Tokenizing train dataset:   8%|▊         | 721/8564 [00:08<01:18, 99.81 examples/s]Tokenizing train dataset:   8%|▊         | 718/8564 [00:08<01:53, 68.99 examples/s]Tokenizing train dataset:   8%|▊         | 666/8564 [00:07<01:43, 75.97 examples/s]Tokenizing train dataset:   9%|▊         | 736/8564 [00:08<01:11, 109.35 examples/s]Tokenizing train dataset:   9%|▊         | 733/8564 [00:08<01:32, 85.04 examples/s]Tokenizing train dataset:   8%|▊         | 675/8564 [00:07<01:49, 71.94 examples/s]Tokenizing train dataset:   9%|▉         | 750/8564 [00:08<01:20, 97.59 examples/s] Tokenizing train dataset:   8%|▊         | 688/8564 [00:07<01:34, 83.03 examples/s]Tokenizing train dataset:   9%|▊         | 748/8564 [00:08<01:33, 83.30 examples/s]Tokenizing train dataset:   8%|▊         | 697/8564 [00:07<01:36, 81.24 examples/s]Tokenizing train dataset:   9%|▉         | 766/8564 [00:08<01:20, 96.84 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:08<01:32, 85.00 examples/s]Tokenizing train dataset:   9%|▉         | 762/8564 [00:08<01:46, 72.95 examples/s]Tokenizing train dataset:   9%|▉         | 782/8564 [00:08<01:22, 94.28 examples/s]Tokenizing train dataset:   8%|▊         | 722/8564 [00:08<01:28, 88.70 examples/s]Tokenizing train dataset:   9%|▉         | 772/8564 [00:08<01:41, 76.63 examples/s]Tokenizing train dataset:   9%|▊         | 734/8564 [00:08<01:23, 93.83 examples/s]Tokenizing train dataset:   9%|▉         | 782/8564 [00:08<01:38, 78.76 examples/s]Tokenizing train dataset:   9%|▉         | 793/8564 [00:09<01:35, 81.49 examples/s]Tokenizing train dataset:   9%|▊         | 746/8564 [00:08<01:18, 99.48 examples/s]Tokenizing train dataset:   9%|▉         | 792/8564 [00:09<01:37, 79.33 examples/s]Tokenizing train dataset:   9%|▉         | 804/8564 [00:09<01:32, 84.12 examples/s]Tokenizing train dataset:   9%|▉         | 802/8564 [00:09<01:35, 81.00 examples/s]Tokenizing train dataset:  10%|▉         | 815/8564 [00:09<01:28, 87.46 examples/s]Tokenizing train dataset:   9%|▉         | 760/8564 [00:08<01:35, 81.34 examples/s]Tokenizing train dataset:   9%|▉         | 813/8564 [00:09<01:28, 87.66 examples/s]Tokenizing train dataset:  10%|▉         | 825/8564 [00:09<01:29, 86.30 examples/s]Tokenizing train dataset:   9%|▉         | 771/8564 [00:08<01:33, 83.50 examples/s]Tokenizing train dataset:  10%|▉         | 834/8564 [00:09<01:32, 83.82 examples/s]Tokenizing train dataset:  10%|▉         | 825/8564 [00:09<01:34, 81.99 examples/s]Tokenizing train dataset:  10%|▉         | 844/8564 [00:09<01:28, 87.03 examples/s]Tokenizing train dataset:   9%|▉         | 784/8564 [00:08<01:34, 82.26 examples/s]Tokenizing train dataset:  10%|▉         | 840/8564 [00:09<01:37, 79.13 examples/s]Tokenizing train dataset:  10%|█         | 858/8564 [00:09<01:20, 95.88 examples/s]Tokenizing train dataset:   9%|▉         | 794/8564 [00:09<01:51, 69.54 examples/s]Tokenizing train dataset:  10%|█         | 868/8564 [00:09<01:23, 92.06 examples/s]Tokenizing train dataset:  10%|▉         | 853/8564 [00:09<01:47, 71.93 examples/s]Tokenizing train dataset:  10%|█         | 880/8564 [00:10<01:21, 94.63 examples/s]Tokenizing train dataset:   9%|▉         | 804/8564 [00:09<01:55, 67.47 examples/s]Tokenizing train dataset:  10%|█         | 862/8564 [00:10<01:47, 71.35 examples/s]Tokenizing train dataset:  10%|█         | 899/8564 [00:10<01:04, 118.03 examples/s]Tokenizing train dataset:   9%|▉         | 812/8564 [00:09<01:54, 67.95 examples/s]Tokenizing train dataset:  11%|█         | 914/8564 [00:10<01:11, 107.30 examples/s]Tokenizing train dataset:  10%|▉         | 820/8564 [00:09<01:59, 65.01 examples/s]Tokenizing train dataset:  10%|█         | 873/8564 [00:10<01:54, 66.93 examples/s]Tokenizing train dataset:  10%|█         | 882/8564 [00:10<01:51, 69.01 examples/s]Tokenizing train dataset:  10%|▉         | 827/8564 [00:09<02:17, 56.10 examples/s]Tokenizing train dataset:  11%|█         | 931/8564 [00:10<01:16, 99.47 examples/s] Tokenizing train dataset:  10%|▉         | 840/8564 [00:09<01:49, 70.83 examples/s]Tokenizing train dataset:  10%|█         | 897/8564 [00:10<01:40, 76.66 examples/s]Tokenizing train dataset:  11%|█         | 942/8564 [00:10<01:19, 95.94 examples/s]Tokenizing train dataset:  11%|█         | 907/8564 [00:10<01:36, 79.61 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:10<01:48, 71.15 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:10<01:32, 82.08 examples/s]Tokenizing train dataset:  10%|█         | 863/8564 [00:10<01:34, 81.23 examples/s]Tokenizing train dataset:  11%|█         | 917/8564 [00:10<01:49, 69.94 examples/s]Tokenizing train dataset:  11%|█▏        | 966/8564 [00:10<01:24, 90.18 examples/s]Tokenizing train dataset:  11%|█▏        | 977/8564 [00:11<01:20, 93.75 examples/s]Tokenizing train dataset:  10%|█         | 875/8564 [00:10<01:42, 74.85 examples/s]Tokenizing train dataset:  11%|█         | 930/8564 [00:10<01:50, 68.93 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:10<01:42, 75.08 examples/s]Tokenizing train dataset:  12%|█▏        | 991/8564 [00:11<01:26, 87.84 examples/s]Tokenizing train dataset:  11%|█         | 940/8564 [00:11<01:57, 65.06 examples/s]Tokenizing train dataset:  10%|█         | 894/8564 [00:10<01:43, 73.82 examples/s]Tokenizing train dataset:  12%|█▏        | 1007/8564 [00:11<01:25, 88.72 examples/s]Tokenizing train dataset:  11%|█         | 908/8564 [00:10<01:26, 88.37 examples/s]Tokenizing train dataset:  11%|█         | 950/8564 [00:11<01:53, 66.90 examples/s]Tokenizing train dataset:  11%|█         | 960/8564 [00:11<01:53, 66.83 examples/s]Tokenizing train dataset:  12%|█▏        | 1020/8564 [00:11<01:30, 83.10 examples/s]Tokenizing train dataset:  11%|█         | 921/8564 [00:10<01:34, 80.55 examples/s]Tokenizing train dataset:  11%|█▏        | 969/8564 [00:11<01:51, 68.31 examples/s]Tokenizing train dataset:  12%|█▏        | 1029/8564 [00:11<01:34, 79.81 examples/s]Tokenizing train dataset:  11%|█         | 935/8564 [00:10<01:25, 89.04 examples/s]Tokenizing train dataset:  12%|█▏        | 1040/8564 [00:11<01:32, 81.76 examples/s]Tokenizing train dataset:  11%|█         | 946/8564 [00:11<01:26, 87.80 examples/s]Tokenizing train dataset:  11%|█▏        | 979/8564 [00:11<02:08, 59.25 examples/s]Tokenizing train dataset:  12%|█▏        | 1054/8564 [00:11<01:23, 90.15 examples/s]Tokenizing train dataset:  12%|█▏        | 988/8564 [00:11<01:58, 63.82 examples/s]Tokenizing train dataset:  11%|█         | 957/8564 [00:11<01:36, 79.06 examples/s]Tokenizing train dataset:  12%|█▏        | 1065/8564 [00:12<01:20, 92.65 examples/s]Tokenizing train dataset:  12%|█▏        | 998/8564 [00:12<01:46, 71.07 examples/s]Tokenizing train dataset:  11%|█▏        | 966/8564 [00:11<01:36, 78.95 examples/s]Tokenizing train dataset:  13%|█▎        | 1078/8564 [00:12<01:14, 100.21 examples/s]Tokenizing train dataset:  12%|█▏        | 1009/8564 [00:12<01:37, 77.15 examples/s]Tokenizing train dataset:  13%|█▎        | 1091/8564 [00:12<01:09, 107.46 examples/s]Tokenizing train dataset:  11%|█▏        | 978/8564 [00:11<01:45, 71.62 examples/s]Tokenizing train dataset:  12%|█▏        | 1020/8564 [00:12<01:34, 80.09 examples/s]Tokenizing train dataset:  13%|█▎        | 1106/8564 [00:12<01:14, 100.21 examples/s]Tokenizing train dataset:  12%|█▏        | 1030/8564 [00:12<01:33, 80.20 examples/s]Tokenizing train dataset:  13%|█▎        | 1119/8564 [00:12<01:12, 103.15 examples/s]Tokenizing train dataset:  12%|█▏        | 986/8564 [00:11<02:13, 56.65 examples/s]Tokenizing train dataset:  12%|█▏        | 1040/8564 [00:12<01:31, 82.64 examples/s]Tokenizing train dataset:  12%|█▏        | 996/8564 [00:11<01:58, 63.66 examples/s]Tokenizing train dataset:  13%|█▎        | 1130/8564 [00:12<01:24, 87.89 examples/s] Tokenizing train dataset:  12%|█▏        | 1049/8564 [00:12<01:36, 77.92 examples/s]Tokenizing train dataset:  12%|█▏        | 1009/8564 [00:12<01:40, 75.44 examples/s]Tokenizing train dataset:  13%|█▎        | 1140/8564 [00:12<01:26, 85.88 examples/s]Tokenizing train dataset:  12%|█▏        | 1060/8564 [00:12<01:40, 74.99 examples/s]Tokenizing train dataset:  12%|█▏        | 1020/8564 [00:12<01:36, 78.44 examples/s]Tokenizing train dataset:  13%|█▎        | 1149/8564 [00:13<01:32, 80.17 examples/s]Tokenizing train dataset:  12%|█▏        | 1068/8564 [00:12<01:41, 73.97 examples/s]Tokenizing train dataset:  12%|█▏        | 1029/8564 [00:12<01:33, 80.32 examples/s]Tokenizing train dataset:  12%|█▏        | 1039/8564 [00:12<01:31, 82.40 examples/s]Tokenizing train dataset:  13%|█▎        | 1080/8564 [00:13<01:43, 72.62 examples/s]Tokenizing train dataset:  14%|█▎        | 1160/8564 [00:13<01:46, 69.76 examples/s]Tokenizing train dataset:  12%|█▏        | 1050/8564 [00:12<01:25, 87.53 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:13<01:49, 67.55 examples/s]Tokenizing train dataset:  12%|█▏        | 1063/8564 [00:12<01:18, 95.01 examples/s]Tokenizing train dataset:  13%|█▎        | 1094/8564 [00:13<01:46, 70.44 examples/s]Tokenizing train dataset:  14%|█▍        | 1188/8564 [00:13<01:25, 86.61 examples/s]Tokenizing train dataset:  13%|█▎        | 1105/8564 [00:13<01:40, 74.48 examples/s]Tokenizing train dataset:  13%|█▎        | 1080/8564 [00:12<01:28, 84.98 examples/s]Tokenizing train dataset:  14%|█▍        | 1199/8564 [00:13<01:27, 83.80 examples/s]Tokenizing train dataset:  13%|█▎        | 1119/8564 [00:13<01:34, 78.99 examples/s]Tokenizing train dataset:  13%|█▎        | 1094/8564 [00:12<01:19, 93.52 examples/s]Tokenizing train dataset:  14%|█▍        | 1210/8564 [00:13<01:39, 73.55 examples/s]Tokenizing train dataset:  13%|█▎        | 1105/8564 [00:13<01:19, 93.24 examples/s]Tokenizing train dataset:  13%|█▎        | 1130/8564 [00:13<01:55, 64.54 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:13<01:41, 72.07 examples/s]Tokenizing train dataset:  13%|█▎        | 1118/8564 [00:13<01:13, 101.50 examples/s]Tokenizing train dataset:  13%|█▎        | 1137/8564 [00:13<01:59, 62.12 examples/s]Tokenizing train dataset:  14%|█▍        | 1230/8564 [00:14<01:45, 69.27 examples/s]Tokenizing train dataset:  13%|█▎        | 1133/8564 [00:13<01:23, 88.75 examples/s] Tokenizing train dataset:  13%|█▎        | 1146/8564 [00:14<02:00, 61.69 examples/s]Tokenizing train dataset:  15%|█▍        | 1243/8564 [00:14<01:31, 79.98 examples/s]Tokenizing train dataset:  13%|█▎        | 1146/8564 [00:13<01:17, 96.17 examples/s]Tokenizing train dataset:  13%|█▎        | 1155/8564 [00:14<01:56, 63.44 examples/s]Tokenizing train dataset:  15%|█▍        | 1257/8564 [00:14<01:28, 82.19 examples/s]Tokenizing train dataset:  14%|█▎        | 1160/8564 [00:13<01:32, 79.90 examples/s]Tokenizing train dataset:  14%|█▎        | 1168/8564 [00:14<02:02, 60.47 examples/s]Tokenizing train dataset:  15%|█▍        | 1270/8564 [00:14<01:32, 78.56 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:13<01:32, 80.21 examples/s]Tokenizing train dataset:  14%|█▍        | 1180/8564 [00:14<01:43, 71.08 examples/s]Tokenizing train dataset:  15%|█▍        | 1280/8564 [00:14<01:37, 74.72 examples/s]Tokenizing train dataset:  14%|█▍        | 1185/8564 [00:14<01:19, 92.96 examples/s]Tokenizing train dataset:  14%|█▍        | 1192/8564 [00:14<01:32, 79.74 examples/s]Tokenizing train dataset:  14%|█▍        | 1200/8564 [00:14<01:12, 101.37 examples/s]Tokenizing train dataset:  14%|█▍        | 1205/8564 [00:14<01:21, 90.02 examples/s]Tokenizing train dataset:  15%|█▌        | 1295/8564 [00:14<01:35, 76.18 examples/s]Tokenizing train dataset:  14%|█▍        | 1211/8564 [00:14<01:23, 88.13 examples/s] Tokenizing train dataset:  15%|█▌        | 1304/8564 [00:15<01:36, 75.42 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:14<01:26, 84.45 examples/s]Tokenizing train dataset:  14%|█▍        | 1224/8564 [00:14<01:16, 95.69 examples/s]Tokenizing train dataset:  15%|█▌        | 1313/8564 [00:15<01:35, 75.57 examples/s]Tokenizing train dataset:  14%|█▍        | 1230/8564 [00:15<01:22, 89.32 examples/s]Tokenizing train dataset:  15%|█▍        | 1247/8564 [00:15<01:09, 105.46 examples/s]Tokenizing train dataset:  14%|█▍        | 1239/8564 [00:14<01:19, 92.52 examples/s]Tokenizing train dataset:  15%|█▌        | 1324/8564 [00:15<01:37, 74.12 examples/s]Tokenizing train dataset:  15%|█▍        | 1254/8564 [00:14<01:15, 97.18 examples/s]Tokenizing train dataset:  15%|█▍        | 1259/8564 [00:15<01:20, 90.62 examples/s] Tokenizing train dataset:  16%|█▌        | 1339/8564 [00:15<01:31, 78.95 examples/s]Tokenizing train dataset:  15%|█▍        | 1270/8564 [00:15<01:17, 94.08 examples/s]Tokenizing train dataset:  15%|█▍        | 1267/8564 [00:14<01:21, 89.86 examples/s]Tokenizing train dataset:  16%|█▌        | 1348/8564 [00:15<01:46, 67.82 examples/s]Tokenizing train dataset:  15%|█▍        | 1281/8564 [00:15<01:21, 89.54 examples/s]Tokenizing train dataset:  15%|█▍        | 1278/8564 [00:15<01:20, 91.03 examples/s]Tokenizing train dataset:  16%|█▌        | 1356/8564 [00:15<01:44, 68.97 examples/s]Tokenizing train dataset:  16%|█▌        | 1366/8564 [00:15<01:36, 74.76 examples/s]Tokenizing train dataset:  15%|█▌        | 1294/8564 [00:15<01:27, 82.97 examples/s]Tokenizing train dataset:  15%|█▌        | 1291/8564 [00:15<01:34, 76.89 examples/s]Tokenizing train dataset:  16%|█▌        | 1377/8564 [00:16<01:31, 78.62 examples/s]Tokenizing train dataset:  15%|█▌        | 1304/8564 [00:15<01:28, 81.68 examples/s]Tokenizing train dataset:  15%|█▌        | 1304/8564 [00:15<01:28, 81.73 examples/s]Tokenizing train dataset:  16%|█▌        | 1389/8564 [00:16<01:21, 87.88 examples/s]Tokenizing train dataset:  15%|█▌        | 1313/8564 [00:16<01:31, 79.07 examples/s]Tokenizing train dataset:  15%|█▌        | 1313/8564 [00:15<01:31, 78.95 examples/s]Tokenizing train dataset:  16%|█▋        | 1400/8564 [00:16<01:19, 90.45 examples/s]Tokenizing train dataset:  15%|█▌        | 1325/8564 [00:16<01:37, 73.98 examples/s]Tokenizing train dataset:  16%|█▋        | 1410/8564 [00:16<01:20, 89.04 examples/s]Tokenizing train dataset:  15%|█▌        | 1325/8564 [00:15<01:37, 74.31 examples/s]Tokenizing train dataset:  16%|█▌        | 1333/8564 [00:16<01:41, 71.01 examples/s]Tokenizing train dataset:  17%|█▋        | 1423/8564 [00:16<01:14, 96.49 examples/s]Tokenizing train dataset:  16%|█▌        | 1333/8564 [00:15<01:41, 70.92 examples/s]Tokenizing train dataset:  17%|█▋        | 1434/8564 [00:16<01:14, 96.23 examples/s]Tokenizing train dataset:  16%|█▌        | 1342/8564 [00:16<01:41, 71.01 examples/s]Tokenizing train dataset:  16%|█▌        | 1342/8564 [00:15<01:41, 71.45 examples/s]Tokenizing train dataset:  17%|█▋        | 1444/8564 [00:16<01:13, 96.44 examples/s]Tokenizing train dataset:  16%|█▌        | 1353/8564 [00:16<01:49, 65.87 examples/s]Tokenizing train dataset:  17%|█▋        | 1454/8564 [00:16<01:14, 95.19 examples/s]Tokenizing train dataset:  16%|█▌        | 1352/8564 [00:16<01:49, 65.68 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:16<01:53, 63.30 examples/s]Tokenizing train dataset:  17%|█▋        | 1467/8564 [00:16<01:11, 98.97 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:17<01:11, 98.80 examples/s]Tokenizing train dataset:  16%|█▌        | 1362/8564 [00:16<02:03, 58.15 examples/s]Tokenizing train dataset:  16%|█▌        | 1369/8564 [00:16<02:06, 56.75 examples/s]Tokenizing train dataset:  17%|█▋        | 1495/8564 [00:17<01:07, 104.31 examples/s]Tokenizing train dataset:  16%|█▌        | 1369/8564 [00:16<02:05, 57.54 examples/s]Tokenizing train dataset:  16%|█▌        | 1379/8564 [00:17<01:55, 62.38 examples/s]Tokenizing train dataset:  18%|█▊        | 1507/8564 [00:17<01:08, 103.61 examples/s]Tokenizing train dataset:  16%|█▌        | 1375/8564 [00:16<02:06, 56.61 examples/s]Tokenizing train dataset:  16%|█▌        | 1390/8564 [00:17<01:39, 71.84 examples/s]Tokenizing train dataset:  18%|█▊        | 1523/8564 [00:17<01:07, 103.58 examples/s]Tokenizing train dataset:  16%|█▋        | 1402/8564 [00:17<01:29, 80.00 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:16<01:52, 63.98 examples/s]Tokenizing train dataset:  17%|█▋        | 1415/8564 [00:17<01:21, 87.92 examples/s]Tokenizing train dataset:  18%|█▊        | 1537/8564 [00:17<01:06, 105.13 examples/s]Tokenizing train dataset:  16%|█▋        | 1396/8564 [00:16<01:59, 60.16 examples/s]Tokenizing train dataset:  17%|█▋        | 1425/8564 [00:17<01:20, 88.15 examples/s]Tokenizing train dataset:  18%|█▊        | 1549/8564 [00:17<01:07, 103.51 examples/s]Tokenizing train dataset:  16%|█▋        | 1403/8564 [00:17<02:01, 59.18 examples/s]Tokenizing train dataset:  17%|█▋        | 1435/8564 [00:17<01:19, 89.14 examples/s]Tokenizing train dataset:  18%|█▊        | 1560/8564 [00:17<01:10, 99.66 examples/s] Tokenizing train dataset:  16%|█▋        | 1413/8564 [00:17<01:55, 61.90 examples/s]Tokenizing train dataset:  17%|█▋        | 1446/8564 [00:17<01:18, 90.88 examples/s]Tokenizing train dataset:  18%|█▊        | 1572/8564 [00:18<01:17, 90.76 examples/s]Tokenizing train dataset:  17%|█▋        | 1423/8564 [00:17<01:41, 70.33 examples/s]Tokenizing train dataset:  17%|█▋        | 1456/8564 [00:17<01:34, 75.00 examples/s]Tokenizing train dataset:  17%|█▋        | 1434/8564 [00:17<01:30, 79.13 examples/s]Tokenizing train dataset:  18%|█▊        | 1583/8564 [00:18<01:28, 79.24 examples/s]Tokenizing train dataset:  17%|█▋        | 1445/8564 [00:17<01:24, 83.81 examples/s]Tokenizing train dataset:  17%|█▋        | 1465/8564 [00:18<01:39, 71.51 examples/s]Tokenizing train dataset:  17%|█▋        | 1456/8564 [00:17<01:23, 85.42 examples/s]Tokenizing train dataset:  19%|█▊        | 1595/8564 [00:18<01:34, 73.97 examples/s]Tokenizing train dataset:  17%|█▋        | 1474/8564 [00:18<01:41, 70.00 examples/s]Tokenizing train dataset:  17%|█▋        | 1467/8564 [00:17<01:17, 91.30 examples/s]Tokenizing train dataset:  19%|█▉        | 1607/8564 [00:18<01:36, 72.36 examples/s]Tokenizing train dataset:  17%|█▋        | 1483/8564 [00:18<01:56, 60.79 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:17<01:17, 91.13 examples/s]Tokenizing train dataset:  19%|█▉        | 1617/8564 [00:18<01:37, 71.44 examples/s]Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:17<01:17, 91.79 examples/s]Tokenizing train dataset:  17%|█▋        | 1494/8564 [00:18<01:47, 65.88 examples/s]Tokenizing train dataset:  18%|█▊        | 1502/8564 [00:18<01:15, 93.83 examples/s]Tokenizing train dataset:  19%|█▉        | 1629/8564 [00:18<01:37, 70.86 examples/s]Tokenizing train dataset:  18%|█▊        | 1502/8564 [00:18<01:58, 59.47 examples/s]Tokenizing train dataset:  19%|█▉        | 1637/8564 [00:19<01:41, 67.97 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:18<01:19, 89.17 examples/s]Tokenizing train dataset:  18%|█▊        | 1510/8564 [00:18<02:04, 56.86 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:18<01:11, 97.72 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:19<01:32, 74.77 examples/s]Tokenizing train dataset:  18%|█▊        | 1517/8564 [00:19<02:01, 57.77 examples/s]Tokenizing train dataset:  18%|█▊        | 1542/8564 [00:18<01:09, 100.65 examples/s]Tokenizing train dataset:  19%|█▉        | 1660/8564 [00:19<01:38, 69.83 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:19<01:48, 64.99 examples/s]Tokenizing train dataset:  18%|█▊        | 1553/8564 [00:18<01:11, 97.40 examples/s] Tokenizing train dataset:  19%|█▉        | 1668/8564 [00:19<01:38, 70.34 examples/s]Tokenizing train dataset:  18%|█▊        | 1566/8564 [00:18<01:07, 104.04 examples/s]Tokenizing train dataset:  18%|█▊        | 1538/8564 [00:19<01:48, 64.69 examples/s]Tokenizing train dataset:  20%|█▉        | 1678/8564 [00:19<01:34, 72.74 examples/s]Tokenizing train dataset:  18%|█▊        | 1577/8564 [00:18<01:09, 100.14 examples/s]Tokenizing train dataset:  18%|█▊        | 1548/8564 [00:19<01:42, 68.55 examples/s]Tokenizing train dataset:  20%|█▉        | 1690/8564 [00:19<01:27, 78.14 examples/s]Tokenizing train dataset:  19%|█▊        | 1592/8564 [00:19<01:12, 96.33 examples/s] Tokenizing train dataset:  18%|█▊        | 1558/8564 [00:19<01:51, 63.06 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:19<01:23, 82.41 examples/s]Tokenizing train dataset:  19%|█▉        | 1608/8564 [00:19<01:06, 104.08 examples/s]Tokenizing train dataset:  18%|█▊        | 1567/8564 [00:19<01:45, 66.55 examples/s]Tokenizing train dataset:  20%|██        | 1715/8564 [00:20<01:28, 77.20 examples/s]Tokenizing train dataset:  19%|█▉        | 1620/8564 [00:19<01:07, 102.57 examples/s]Tokenizing train dataset:  18%|█▊        | 1574/8564 [00:19<01:53, 61.53 examples/s]Tokenizing train dataset:  19%|█▉        | 1632/8564 [00:19<01:05, 105.68 examples/s]Tokenizing train dataset:  20%|██        | 1724/8564 [00:20<01:31, 74.66 examples/s]Tokenizing train dataset:  18%|█▊        | 1582/8564 [00:20<01:52, 62.13 examples/s]Tokenizing train dataset:  19%|█▉        | 1648/8564 [00:19<01:00, 114.78 examples/s]Tokenizing train dataset:  20%|██        | 1736/8564 [00:20<01:38, 69.63 examples/s]Tokenizing train dataset:  19%|█▊        | 1592/8564 [00:20<01:55, 60.35 examples/s]Tokenizing train dataset:  19%|█▉        | 1663/8564 [00:19<01:03, 107.83 examples/s]Tokenizing train dataset:  19%|█▊        | 1600/8564 [00:20<01:53, 61.26 examples/s]Tokenizing train dataset:  20%|██        | 1748/8564 [00:20<01:35, 71.75 examples/s]Tokenizing train dataset:  20%|█▉        | 1676/8564 [00:19<01:03, 108.04 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:20<01:45, 66.19 examples/s]Tokenizing train dataset:  20%|█▉        | 1692/8564 [00:19<00:57, 120.35 examples/s]Tokenizing train dataset:  21%|██        | 1760/8564 [00:20<01:32, 73.17 examples/s]Tokenizing train dataset:  19%|█▉        | 1619/8564 [00:20<01:38, 70.44 examples/s]Tokenizing train dataset:  20%|█▉        | 1710/8564 [00:19<00:54, 126.66 examples/s]Tokenizing train dataset:  21%|██        | 1771/8564 [00:20<01:34, 72.05 examples/s]Tokenizing train dataset:  19%|█▉        | 1627/8564 [00:20<01:51, 62.42 examples/s]Tokenizing train dataset:  21%|██        | 1779/8564 [00:21<01:50, 61.15 examples/s]Tokenizing train dataset:  20%|██        | 1725/8564 [00:20<01:14, 92.37 examples/s] Tokenizing train dataset:  19%|█▉        | 1635/8564 [00:20<01:54, 60.63 examples/s]Tokenizing train dataset:  21%|██        | 1790/8564 [00:21<01:41, 67.07 examples/s]Tokenizing train dataset:  19%|█▉        | 1644/8564 [00:21<01:49, 63.23 examples/s]Tokenizing train dataset:  20%|██        | 1736/8564 [00:20<01:26, 78.97 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:21<01:32, 73.36 examples/s]Tokenizing train dataset:  19%|█▉        | 1655/8564 [00:21<01:37, 70.55 examples/s]Tokenizing train dataset:  20%|██        | 1750/8564 [00:20<01:18, 86.78 examples/s]Tokenizing train dataset:  21%|██        | 1810/8564 [00:21<01:25, 78.56 examples/s]Tokenizing train dataset:  19%|█▉        | 1667/8564 [00:21<01:37, 70.40 examples/s]Tokenizing train dataset:  21%|██        | 1760/8564 [00:20<01:16, 88.62 examples/s]Tokenizing train dataset:  21%|██▏       | 1823/8564 [00:21<01:16, 87.56 examples/s]Tokenizing train dataset:  21%|██        | 1772/8564 [00:20<01:13, 92.56 examples/s]Tokenizing train dataset:  21%|██▏       | 1837/8564 [00:21<01:08, 97.80 examples/s]Tokenizing train dataset:  20%|█▉        | 1676/8564 [00:21<01:41, 68.16 examples/s]Tokenizing train dataset:  21%|██        | 1783/8564 [00:20<01:12, 93.05 examples/s]Tokenizing train dataset:  20%|█▉        | 1686/8564 [00:21<01:36, 70.98 examples/s]Tokenizing train dataset:  22%|██▏       | 1853/8564 [00:21<01:11, 94.05 examples/s]Tokenizing train dataset:  21%|██        | 1796/8564 [00:21<01:08, 98.11 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:21<01:29, 77.12 examples/s]Tokenizing train dataset:  22%|██▏       | 1867/8564 [00:21<01:15, 88.15 examples/s]Tokenizing train dataset:  21%|██        | 1810/8564 [00:21<01:14, 90.72 examples/s]Tokenizing train dataset:  20%|██        | 1713/8564 [00:21<01:19, 86.13 examples/s]Tokenizing train dataset:  21%|██▏       | 1822/8564 [00:21<01:12, 92.75 examples/s]Tokenizing train dataset:  20%|██        | 1722/8564 [00:21<01:20, 84.69 examples/s]Tokenizing train dataset:  22%|██▏       | 1881/8564 [00:22<01:22, 80.94 examples/s]Tokenizing train dataset:  20%|██        | 1734/8564 [00:22<01:17, 88.33 examples/s]Tokenizing train dataset:  21%|██▏       | 1832/8564 [00:21<01:16, 88.09 examples/s]Tokenizing train dataset:  22%|██▏       | 1893/8564 [00:22<01:18, 85.31 examples/s]Tokenizing train dataset:  20%|██        | 1746/8564 [00:22<01:11, 94.94 examples/s]Tokenizing train dataset:  22%|██▏       | 1842/8564 [00:21<01:20, 83.77 examples/s]Tokenizing train dataset:  22%|██▏       | 1913/8564 [00:22<01:03, 104.80 examples/s]Tokenizing train dataset:  21%|██        | 1759/8564 [00:22<01:08, 99.81 examples/s]Tokenizing train dataset:  23%|██▎       | 1931/8564 [00:22<00:58, 113.35 examples/s]Tokenizing train dataset:  22%|██▏       | 1852/8564 [00:21<01:31, 73.05 examples/s]Tokenizing train dataset:  21%|██        | 1770/8564 [00:22<01:08, 98.92 examples/s]Tokenizing train dataset:  22%|██▏       | 1860/8564 [00:21<01:31, 72.87 examples/s]Tokenizing train dataset:  23%|██▎       | 1946/8564 [00:22<01:03, 103.83 examples/s]Tokenizing train dataset:  21%|██        | 1780/8564 [00:22<01:29, 76.22 examples/s]Tokenizing train dataset:  22%|██▏       | 1871/8564 [00:22<01:29, 75.12 examples/s]Tokenizing train dataset:  23%|██▎       | 1959/8564 [00:22<01:02, 105.91 examples/s]Tokenizing train dataset:  21%|██        | 1789/8564 [00:22<01:28, 76.88 examples/s]Tokenizing train dataset:  23%|██▎       | 1972/8564 [00:22<01:01, 106.37 examples/s]Tokenizing train dataset:  22%|██▏       | 1883/8564 [00:22<01:33, 71.39 examples/s]Tokenizing train dataset:  21%|██        | 1799/8564 [00:22<01:30, 74.71 examples/s]Tokenizing train dataset:  23%|██▎       | 1986/8564 [00:23<00:58, 112.78 examples/s]Tokenizing train dataset:  23%|██▎       | 2000/8564 [00:23<00:57, 113.64 examples/s]Tokenizing train dataset:  22%|██▏       | 1895/8564 [00:22<01:36, 69.01 examples/s]Tokenizing train dataset:  21%|██        | 1810/8564 [00:23<01:37, 69.57 examples/s]Tokenizing train dataset:  24%|██▎       | 2013/8564 [00:23<00:58, 112.91 examples/s]Tokenizing train dataset:  22%|██▏       | 1910/8564 [00:22<01:21, 81.49 examples/s]Tokenizing train dataset:  21%|██        | 1819/8564 [00:23<01:44, 64.71 examples/s]Tokenizing train dataset:  24%|██▎       | 2027/8564 [00:23<00:55, 118.56 examples/s]Tokenizing train dataset:  22%|██▏       | 1921/8564 [00:22<01:28, 75.27 examples/s]Tokenizing train dataset:  24%|██▍       | 2045/8564 [00:23<00:50, 128.29 examples/s]Tokenizing train dataset:  21%|██▏       | 1827/8564 [00:23<01:47, 62.43 examples/s]Tokenizing train dataset:  23%|██▎       | 1937/8564 [00:22<01:16, 86.44 examples/s]Tokenizing train dataset:  21%|██▏       | 1840/8564 [00:23<01:29, 75.07 examples/s]Tokenizing train dataset:  24%|██▍       | 2059/8564 [00:23<00:59, 110.03 examples/s]Tokenizing train dataset:  22%|██▏       | 1852/8564 [00:23<01:20, 83.23 examples/s]Tokenizing train dataset:  23%|██▎       | 1948/8564 [00:23<01:23, 78.88 examples/s]Tokenizing train dataset:  24%|██▍       | 2074/8564 [00:23<01:04, 101.27 examples/s]Tokenizing train dataset:  22%|██▏       | 1864/8564 [00:23<01:13, 91.09 examples/s]Tokenizing train dataset:  23%|██▎       | 1957/8564 [00:23<01:22, 80.00 examples/s]Tokenizing train dataset:  24%|██▍       | 2089/8564 [00:23<00:57, 111.94 examples/s]Tokenizing train dataset:  23%|██▎       | 1969/8564 [00:23<01:14, 88.58 examples/s]Tokenizing train dataset:  22%|██▏       | 1876/8564 [00:23<01:26, 77.26 examples/s]Tokenizing train dataset:  23%|██▎       | 1987/8564 [00:23<01:00, 108.75 examples/s]Tokenizing train dataset:  25%|██▍       | 2106/8564 [00:24<01:02, 103.92 examples/s]Tokenizing train dataset:  22%|██▏       | 1888/8564 [00:24<01:27, 76.16 examples/s]Tokenizing train dataset:  23%|██▎       | 2002/8564 [00:23<01:03, 104.10 examples/s]Tokenizing train dataset:  25%|██▍       | 2121/8564 [00:24<01:00, 107.02 examples/s]Tokenizing train dataset:  24%|██▎       | 2013/8564 [00:23<01:04, 100.79 examples/s]Tokenizing train dataset:  25%|██▍       | 2136/8564 [00:24<00:57, 112.64 examples/s]Tokenizing train dataset:  22%|██▏       | 1901/8564 [00:24<01:32, 72.23 examples/s]Tokenizing train dataset:  24%|██▎       | 2029/8564 [00:23<01:02, 104.52 examples/s]Tokenizing train dataset:  22%|██▏       | 1919/8564 [00:24<01:11, 92.35 examples/s]Tokenizing train dataset:  25%|██▌       | 2152/8564 [00:24<00:58, 109.70 examples/s]Tokenizing train dataset:  24%|██▍       | 2040/8564 [00:23<01:04, 101.56 examples/s]Tokenizing train dataset:  25%|██▌       | 2165/8564 [00:24<00:56, 113.65 examples/s]Tokenizing train dataset:  23%|██▎       | 1934/8564 [00:24<01:06, 99.93 examples/s]Tokenizing train dataset:  25%|██▌       | 2179/8564 [00:24<00:55, 115.55 examples/s]Tokenizing train dataset:  23%|██▎       | 1948/8564 [00:24<01:03, 104.01 examples/s]Tokenizing train dataset:  24%|██▍       | 2051/8564 [00:24<01:14, 87.75 examples/s] Tokenizing train dataset:  26%|██▌       | 2192/8564 [00:24<00:54, 116.47 examples/s]Tokenizing train dataset:  23%|██▎       | 1960/8564 [00:24<01:04, 102.98 examples/s]Tokenizing train dataset:  24%|██▍       | 2065/8564 [00:24<01:08, 95.55 examples/s]Tokenizing train dataset:  23%|██▎       | 1972/8564 [00:24<01:02, 104.68 examples/s]Tokenizing train dataset:  26%|██▌       | 2209/8564 [00:25<00:58, 108.66 examples/s]Tokenizing train dataset:  23%|██▎       | 1984/8564 [00:24<01:01, 107.17 examples/s]Tokenizing train dataset:  24%|██▍       | 2081/8564 [00:24<01:14, 86.83 examples/s]Tokenizing train dataset:  26%|██▌       | 2222/8564 [00:25<00:56, 111.62 examples/s]Tokenizing train dataset:  24%|██▍       | 2093/8564 [00:24<01:11, 90.94 examples/s]Tokenizing train dataset:  26%|██▌       | 2235/8564 [00:25<00:58, 108.56 examples/s]Tokenizing train dataset:  23%|██▎       | 2000/8564 [00:25<01:07, 97.55 examples/s] Tokenizing train dataset:  25%|██▍       | 2107/8564 [00:24<01:03, 101.47 examples/s]Tokenizing train dataset:  24%|██▎       | 2013/8564 [00:25<01:06, 98.68 examples/s]Tokenizing train dataset:  25%|██▍       | 2121/8564 [00:24<01:01, 104.60 examples/s]Tokenizing train dataset:  26%|██▋       | 2251/8564 [00:25<01:07, 93.97 examples/s] Tokenizing train dataset:  24%|██▎       | 2025/8564 [00:25<01:07, 96.81 examples/s]Tokenizing train dataset:  26%|██▋       | 2263/8564 [00:25<01:03, 98.85 examples/s]Tokenizing train dataset:  25%|██▍       | 2136/8564 [00:24<01:05, 98.82 examples/s] Tokenizing train dataset:  27%|██▋       | 2278/8564 [00:25<00:56, 110.32 examples/s]Tokenizing train dataset:  24%|██▍       | 2041/8564 [00:25<01:10, 92.81 examples/s]Tokenizing train dataset:  27%|██▋       | 2292/8564 [00:25<00:55, 113.16 examples/s]Tokenizing train dataset:  25%|██▌       | 2149/8564 [00:25<01:10, 90.80 examples/s]Tokenizing train dataset:  24%|██▍       | 2059/8564 [00:25<01:09, 93.46 examples/s]Tokenizing train dataset:  27%|██▋       | 2307/8564 [00:25<00:54, 113.93 examples/s]Tokenizing train dataset:  25%|██▌       | 2159/8564 [00:25<01:13, 86.95 examples/s]Tokenizing train dataset:  24%|██▍       | 2069/8564 [00:25<01:09, 93.01 examples/s]Tokenizing train dataset:  25%|██▌       | 2170/8564 [00:25<01:11, 89.24 examples/s]Tokenizing train dataset:  24%|██▍       | 2082/8564 [00:26<01:04, 101.05 examples/s]Tokenizing train dataset:  27%|██▋       | 2324/8564 [00:26<01:05, 95.88 examples/s] Tokenizing train dataset:  25%|██▌       | 2181/8564 [00:25<01:19, 80.64 examples/s]Tokenizing train dataset:  24%|██▍       | 2094/8564 [00:26<01:04, 100.31 examples/s]Tokenizing train dataset:  27%|██▋       | 2335/8564 [00:26<01:06, 94.35 examples/s]Tokenizing train dataset:  26%|██▌       | 2196/8564 [00:25<01:08, 93.02 examples/s]Tokenizing train dataset:  25%|██▍       | 2110/8564 [00:26<00:58, 109.73 examples/s]Tokenizing train dataset:  26%|██▌       | 2210/8564 [00:25<01:06, 95.69 examples/s]Tokenizing train dataset:  25%|██▍       | 2127/8564 [00:26<00:54, 118.92 examples/s]Tokenizing train dataset:  27%|██▋       | 2348/8564 [00:26<01:15, 82.85 examples/s]Tokenizing train dataset:  26%|██▌       | 2225/8564 [00:25<01:01, 102.72 examples/s]Tokenizing train dataset:  28%|██▊       | 2357/8564 [00:26<01:16, 81.33 examples/s]Tokenizing train dataset:  25%|██▌       | 2143/8564 [00:26<01:00, 106.55 examples/s]Tokenizing train dataset:  28%|██▊       | 2370/8564 [00:26<01:10, 87.50 examples/s]Tokenizing train dataset:  26%|██▌       | 2242/8564 [00:26<01:00, 103.86 examples/s]Tokenizing train dataset:  25%|██▌       | 2155/8564 [00:26<00:59, 107.65 examples/s]Tokenizing train dataset:  28%|██▊       | 2382/8564 [00:26<01:10, 88.22 examples/s]Tokenizing train dataset:  26%|██▋       | 2254/8564 [00:26<01:01, 102.84 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:26<00:59, 107.19 examples/s]Tokenizing train dataset:  25%|██▌       | 2180/8564 [00:26<00:56, 112.05 examples/s]Tokenizing train dataset:  28%|██▊       | 2393/8564 [00:27<01:16, 80.33 examples/s]Tokenizing train dataset:  27%|██▋       | 2270/8564 [00:26<01:03, 98.68 examples/s] Tokenizing train dataset:  26%|██▌       | 2194/8564 [00:26<00:54, 117.78 examples/s]Tokenizing train dataset:  28%|██▊       | 2408/8564 [00:27<01:08, 89.33 examples/s]Tokenizing train dataset:  27%|██▋       | 2281/8564 [00:26<01:07, 93.68 examples/s]Tokenizing train dataset:  26%|██▌       | 2207/8564 [00:27<00:57, 110.02 examples/s]Tokenizing train dataset:  27%|██▋       | 2291/8564 [00:26<01:07, 92.74 examples/s]Tokenizing train dataset:  26%|██▌       | 2223/8564 [00:27<00:52, 121.35 examples/s]Tokenizing train dataset:  28%|██▊       | 2423/8564 [00:27<01:12, 85.27 examples/s]Tokenizing train dataset:  27%|██▋       | 2303/8564 [00:26<01:08, 90.79 examples/s]Tokenizing train dataset:  28%|██▊       | 2432/8564 [00:27<01:11, 85.78 examples/s]Tokenizing train dataset:  26%|██▌       | 2237/8564 [00:27<00:52, 120.88 examples/s]Tokenizing train dataset:  26%|██▋       | 2250/8564 [00:27<00:51, 121.87 examples/s]Tokenizing train dataset:  29%|██▊       | 2441/8564 [00:27<01:17, 78.75 examples/s]Tokenizing train dataset:  27%|██▋       | 2317/8564 [00:26<01:14, 83.35 examples/s]Tokenizing train dataset:  29%|██▊       | 2450/8564 [00:27<01:16, 79.81 examples/s]Tokenizing train dataset:  27%|██▋       | 2330/8564 [00:27<01:08, 90.54 examples/s]Tokenizing train dataset:  26%|██▋       | 2269/8564 [00:27<00:56, 111.80 examples/s]Tokenizing train dataset:  29%|██▊       | 2462/8564 [00:27<01:12, 83.98 examples/s]Tokenizing train dataset:  27%|██▋       | 2341/8564 [00:27<01:06, 93.82 examples/s]Tokenizing train dataset:  27%|██▋       | 2281/8564 [00:27<00:59, 105.45 examples/s]Tokenizing train dataset:  27%|██▋       | 2351/8564 [00:27<01:07, 91.85 examples/s]Tokenizing train dataset:  29%|██▉       | 2476/8564 [00:28<01:15, 80.49 examples/s]Tokenizing train dataset:  27%|██▋       | 2296/8564 [00:27<01:02, 99.70 examples/s] Tokenizing train dataset:  28%|██▊       | 2363/8564 [00:27<01:07, 91.53 examples/s]Tokenizing train dataset:  29%|██▉       | 2489/8564 [00:28<01:08, 88.97 examples/s]Tokenizing train dataset:  28%|██▊       | 2376/8564 [00:27<01:01, 100.10 examples/s]Tokenizing train dataset:  29%|██▉       | 2500/8564 [00:28<01:11, 85.34 examples/s]Tokenizing train dataset:  27%|██▋       | 2311/8564 [00:28<01:14, 84.32 examples/s]Tokenizing train dataset:  28%|██▊       | 2392/8564 [00:27<00:55, 110.92 examples/s]Tokenizing train dataset:  29%|██▉       | 2509/8564 [00:28<01:14, 80.95 examples/s]Tokenizing train dataset:  28%|██▊       | 2407/8564 [00:27<00:51, 119.36 examples/s]Tokenizing train dataset:  27%|██▋       | 2329/8564 [00:28<01:11, 87.24 examples/s]Tokenizing train dataset:  29%|██▉       | 2523/8564 [00:28<01:06, 91.48 examples/s]Tokenizing train dataset:  28%|██▊       | 2420/8564 [00:27<01:00, 101.37 examples/s]Tokenizing train dataset:  30%|██▉       | 2540/8564 [00:28<00:57, 104.51 examples/s]Tokenizing train dataset:  28%|██▊       | 2434/8564 [00:27<00:56, 109.27 examples/s]Tokenizing train dataset:  27%|██▋       | 2341/8564 [00:28<01:23, 74.84 examples/s]Tokenizing train dataset:  30%|██▉       | 2555/8564 [00:28<00:53, 111.78 examples/s]Tokenizing train dataset:  29%|██▊       | 2446/8564 [00:28<00:55, 110.74 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:28<01:25, 72.52 examples/s]Tokenizing train dataset:  30%|███       | 2575/8564 [00:28<00:49, 121.22 examples/s]Tokenizing train dataset:  29%|██▉       | 2463/8564 [00:28<00:50, 121.12 examples/s]Tokenizing train dataset:  28%|██▊       | 2360/8564 [00:28<01:20, 76.82 examples/s]Tokenizing train dataset:  28%|██▊       | 2377/8564 [00:28<01:05, 94.71 examples/s]Tokenizing train dataset:  30%|███       | 2590/8564 [00:29<00:55, 106.76 examples/s]Tokenizing train dataset:  29%|██▉       | 2480/8564 [00:28<00:59, 102.22 examples/s]Tokenizing train dataset:  28%|██▊       | 2393/8564 [00:29<00:57, 107.45 examples/s]Tokenizing train dataset:  30%|███       | 2603/8564 [00:29<00:56, 104.92 examples/s]Tokenizing train dataset:  28%|██▊       | 2410/8564 [00:29<00:52, 116.31 examples/s]Tokenizing train dataset:  29%|██▉       | 2497/8564 [00:28<00:59, 102.75 examples/s]Tokenizing train dataset:  31%|███       | 2614/8564 [00:29<01:04, 92.25 examples/s] Tokenizing train dataset:  28%|██▊       | 2424/8564 [00:29<00:52, 116.68 examples/s]Tokenizing train dataset:  29%|██▉       | 2513/8564 [00:28<00:58, 102.60 examples/s]Tokenizing train dataset:  31%|███       | 2625/8564 [00:29<01:12, 82.33 examples/s]Tokenizing train dataset:  30%|██▉       | 2528/8564 [00:28<00:53, 111.90 examples/s]Tokenizing train dataset:  28%|██▊       | 2440/8564 [00:29<00:54, 112.39 examples/s]Tokenizing train dataset:  29%|██▊       | 2455/8564 [00:29<00:50, 119.95 examples/s]Tokenizing train dataset:  30%|██▉       | 2540/8564 [00:28<00:54, 109.94 examples/s]Tokenizing train dataset:  31%|███       | 2637/8564 [00:29<01:16, 77.63 examples/s]Tokenizing train dataset:  30%|██▉       | 2557/8564 [00:29<00:48, 123.12 examples/s]Tokenizing train dataset:  29%|██▉       | 2470/8564 [00:29<00:50, 119.54 examples/s]Tokenizing train dataset:  31%|███       | 2648/8564 [00:29<01:13, 80.20 examples/s]Tokenizing train dataset:  30%|███       | 2574/8564 [00:29<00:45, 131.39 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:30<01:12, 81.74 examples/s]Tokenizing train dataset:  29%|██▉       | 2484/8564 [00:29<01:04, 94.46 examples/s] Tokenizing train dataset:  30%|███       | 2592/8564 [00:29<00:51, 115.24 examples/s]Tokenizing train dataset:  31%|███       | 2671/8564 [00:30<01:08, 86.54 examples/s]Tokenizing train dataset:  29%|██▉       | 2496/8564 [00:30<01:03, 95.22 examples/s]Tokenizing train dataset:  31%|███▏      | 2682/8564 [00:30<01:04, 91.30 examples/s]Tokenizing train dataset:  30%|███       | 2607/8564 [00:29<00:59, 99.30 examples/s] Tokenizing train dataset:  32%|███▏      | 2698/8564 [00:30<00:56, 103.31 examples/s]Tokenizing train dataset:  29%|██▉       | 2510/8564 [00:30<01:08, 88.42 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:29<01:01, 97.09 examples/s]Tokenizing train dataset:  29%|██▉       | 2523/8564 [00:30<01:05, 92.91 examples/s]Tokenizing train dataset:  32%|███▏      | 2710/8564 [00:30<01:10, 82.49 examples/s] Tokenizing train dataset:  31%|███       | 2631/8564 [00:29<01:01, 96.99 examples/s]Tokenizing train dataset:  30%|██▉       | 2537/8564 [00:30<01:00, 99.47 examples/s]Tokenizing train dataset:  32%|███▏      | 2724/8564 [00:30<01:03, 92.19 examples/s]Tokenizing train dataset:  30%|██▉       | 2554/8564 [00:30<00:53, 112.34 examples/s]Tokenizing train dataset:  31%|███       | 2643/8564 [00:30<01:10, 84.25 examples/s]Tokenizing train dataset:  30%|██▉       | 2567/8564 [00:30<00:53, 112.98 examples/s]Tokenizing train dataset:  32%|███▏      | 2737/8564 [00:30<01:10, 82.56 examples/s]Tokenizing train dataset:  31%|███       | 2655/8564 [00:30<01:06, 88.61 examples/s]Tokenizing train dataset:  32%|███▏      | 2748/8564 [00:30<01:05, 88.16 examples/s]Tokenizing train dataset:  31%|███       | 2669/8564 [00:30<01:02, 94.74 examples/s]Tokenizing train dataset:  30%|███       | 2582/8564 [00:30<01:04, 93.29 examples/s] Tokenizing train dataset:  31%|███▏      | 2680/8564 [00:30<01:01, 96.03 examples/s]Tokenizing train dataset:  32%|███▏      | 2762/8564 [00:31<01:05, 88.60 examples/s]Tokenizing train dataset:  31%|███▏      | 2692/8564 [00:30<00:59, 98.39 examples/s]Tokenizing train dataset:  30%|███       | 2596/8564 [00:31<01:08, 86.95 examples/s]Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:31<01:01, 94.34 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:30<00:56, 104.50 examples/s]Tokenizing train dataset:  30%|███       | 2607/8564 [00:31<01:06, 89.94 examples/s]Tokenizing train dataset:  33%|███▎      | 2792/8564 [00:31<00:54, 104.95 examples/s]Tokenizing train dataset:  32%|███▏      | 2720/8564 [00:30<00:52, 110.75 examples/s]Tokenizing train dataset:  33%|███▎      | 2805/8564 [00:31<00:53, 107.41 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:31<01:11, 82.62 examples/s]Tokenizing train dataset:  32%|███▏      | 2732/8564 [00:30<00:52, 111.14 examples/s]Tokenizing train dataset:  32%|███▏      | 2744/8564 [00:30<00:52, 110.73 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:31<00:59, 97.31 examples/s] Tokenizing train dataset:  31%|███       | 2630/8564 [00:31<01:19, 74.95 examples/s]Tokenizing train dataset:  33%|███▎      | 2834/8564 [00:31<00:55, 103.08 examples/s]Tokenizing train dataset:  31%|███       | 2639/8564 [00:31<01:23, 71.29 examples/s]Tokenizing train dataset:  32%|███▏      | 2759/8564 [00:31<00:59, 97.98 examples/s] Tokenizing train dataset:  31%|███       | 2650/8564 [00:31<01:14, 78.91 examples/s]Tokenizing train dataset:  33%|███▎      | 2849/8564 [00:32<01:00, 94.31 examples/s] Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:31<00:59, 96.64 examples/s]Tokenizing train dataset:  31%|███       | 2665/8564 [00:31<01:08, 86.19 examples/s]Tokenizing train dataset:  33%|███▎      | 2789/8564 [00:31<00:56, 102.54 examples/s]Tokenizing train dataset:  33%|███▎      | 2864/8564 [00:32<01:06, 86.34 examples/s]Tokenizing train dataset:  33%|███▎      | 2801/8564 [00:31<00:55, 104.49 examples/s]Tokenizing train dataset:  31%|███       | 2674/8564 [00:32<01:23, 70.38 examples/s]Tokenizing train dataset:  33%|███▎      | 2815/8564 [00:31<00:51, 111.17 examples/s]Tokenizing train dataset:  34%|███▎      | 2877/8564 [00:32<01:10, 80.54 examples/s]Tokenizing train dataset:  31%|███▏      | 2683/8564 [00:32<01:21, 71.80 examples/s]Tokenizing train dataset:  33%|███▎      | 2830/8564 [00:31<00:50, 114.54 examples/s]Tokenizing train dataset:  34%|███▍      | 2891/8564 [00:32<01:05, 86.61 examples/s]Tokenizing train dataset:  31%|███▏      | 2695/8564 [00:32<01:15, 78.05 examples/s]Tokenizing train dataset:  33%|███▎      | 2847/8564 [00:31<00:52, 109.87 examples/s]Tokenizing train dataset:  32%|███▏      | 2706/8564 [00:32<01:15, 77.37 examples/s]Tokenizing train dataset:  34%|███▍      | 2911/8564 [00:32<01:01, 92.42 examples/s]Tokenizing train dataset:  32%|███▏      | 2720/8564 [00:32<01:04, 90.09 examples/s]Tokenizing train dataset:  34%|███▍      | 2928/8564 [00:32<00:52, 106.81 examples/s]Tokenizing train dataset:  33%|███▎      | 2863/8564 [00:32<00:58, 97.31 examples/s] Tokenizing train dataset:  32%|███▏      | 2732/8564 [00:32<01:01, 94.21 examples/s]Tokenizing train dataset:  34%|███▍      | 2940/8564 [00:32<00:55, 100.64 examples/s]Tokenizing train dataset:  34%|███▎      | 2878/8564 [00:32<01:00, 93.52 examples/s]Tokenizing train dataset:  32%|███▏      | 2748/8564 [00:32<01:03, 91.88 examples/s]Tokenizing train dataset:  35%|███▍      | 2957/8564 [00:33<00:54, 103.12 examples/s]Tokenizing train dataset:  34%|███▍      | 2898/8564 [00:32<00:49, 114.33 examples/s]Tokenizing train dataset:  35%|███▍      | 2969/8564 [00:33<00:53, 105.39 examples/s]Tokenizing train dataset:  34%|███▍      | 2914/8564 [00:32<00:46, 121.37 examples/s]Tokenizing train dataset:  32%|███▏      | 2763/8564 [00:33<01:10, 82.00 examples/s]Tokenizing train dataset:  35%|███▍      | 2987/8564 [00:33<00:47, 117.67 examples/s]Tokenizing train dataset:  34%|███▍      | 2929/8564 [00:32<00:51, 108.74 examples/s]Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:33<01:12, 79.54 examples/s]Tokenizing train dataset:  35%|███▌      | 3004/8564 [00:33<00:49, 111.55 examples/s]Tokenizing train dataset:  34%|███▍      | 2947/8564 [00:32<00:51, 109.62 examples/s]Tokenizing train dataset:  33%|███▎      | 2787/8564 [00:33<01:08, 84.45 examples/s]Tokenizing train dataset:  35%|███▌      | 3016/8564 [00:33<00:49, 112.66 examples/s]Tokenizing train dataset:  33%|███▎      | 2800/8564 [00:33<01:01, 93.98 examples/s]Tokenizing train dataset:  35%|███▍      | 2960/8564 [00:33<00:56, 98.34 examples/s] Tokenizing train dataset:  35%|███▌      | 3032/8564 [00:33<00:55, 99.38 examples/s] Tokenizing train dataset:  33%|███▎      | 2812/8564 [00:33<01:00, 95.27 examples/s]Tokenizing train dataset:  35%|███▍      | 2974/8564 [00:33<00:55, 100.16 examples/s]Tokenizing train dataset:  36%|███▌      | 3044/8564 [00:33<00:58, 94.35 examples/s]Tokenizing train dataset:  33%|███▎      | 2826/8564 [00:33<00:57, 99.45 examples/s]Tokenizing train dataset:  35%|███▍      | 2990/8564 [00:33<00:56, 97.87 examples/s] Tokenizing train dataset:  33%|███▎      | 2840/8564 [00:33<00:54, 105.29 examples/s]Tokenizing train dataset:  36%|███▌      | 3054/8564 [00:34<01:05, 84.69 examples/s]Tokenizing train dataset:  35%|███▌      | 3001/8564 [00:33<00:56, 99.25 examples/s]Tokenizing train dataset:  36%|███▌      | 3068/8564 [00:34<00:59, 92.92 examples/s]Tokenizing train dataset:  33%|███▎      | 2856/8564 [00:34<01:03, 90.49 examples/s] Tokenizing train dataset:  35%|███▌      | 3014/8564 [00:33<00:55, 99.14 examples/s]Tokenizing train dataset:  35%|███▌      | 3025/8564 [00:33<00:54, 101.29 examples/s]Tokenizing train dataset:  36%|███▌      | 3084/8564 [00:34<01:00, 90.83 examples/s]Tokenizing train dataset:  34%|███▎      | 2870/8564 [00:34<01:08, 83.49 examples/s]Tokenizing train dataset:  36%|███▌      | 3042/8564 [00:33<00:53, 103.00 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:34<01:05, 83.36 examples/s]Tokenizing train dataset:  34%|███▎      | 2884/8564 [00:34<01:07, 83.57 examples/s]Tokenizing train dataset:  36%|███▌      | 3053/8564 [00:33<00:55, 99.97 examples/s] Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:34<01:02, 87.91 examples/s]Tokenizing train dataset:  34%|███▍      | 2899/8564 [00:34<00:59, 95.89 examples/s]Tokenizing train dataset:  36%|███▌      | 3065/8564 [00:34<00:53, 103.59 examples/s]Tokenizing train dataset:  36%|███▋      | 3123/8564 [00:34<00:58, 93.71 examples/s]Tokenizing train dataset:  34%|███▍      | 2912/8564 [00:34<00:56, 99.59 examples/s]Tokenizing train dataset:  36%|███▌      | 3079/8564 [00:34<00:48, 112.42 examples/s]Tokenizing train dataset:  34%|███▍      | 2928/8564 [00:34<00:50, 112.68 examples/s]Tokenizing train dataset:  36%|███▌      | 3096/8564 [00:34<00:44, 121.88 examples/s]Tokenizing train dataset:  37%|███▋      | 3137/8564 [00:35<01:01, 87.70 examples/s]Tokenizing train dataset:  36%|███▋      | 3111/8564 [00:34<00:42, 127.15 examples/s]Tokenizing train dataset:  37%|███▋      | 3151/8564 [00:35<00:55, 98.33 examples/s]Tokenizing train dataset:  34%|███▍      | 2943/8564 [00:35<00:54, 102.70 examples/s]Tokenizing train dataset:  37%|███▋      | 3164/8564 [00:35<00:51, 105.20 examples/s]Tokenizing train dataset:  35%|███▍      | 2958/8564 [00:35<00:50, 112.10 examples/s]Tokenizing train dataset:  36%|███▋      | 3124/8564 [00:34<00:54, 99.46 examples/s] Tokenizing train dataset:  37%|███▋      | 3176/8564 [00:35<00:52, 103.47 examples/s]Tokenizing train dataset:  35%|███▍      | 2971/8564 [00:35<00:55, 101.60 examples/s]Tokenizing train dataset:  37%|███▋      | 3190/8564 [00:35<00:48, 110.68 examples/s]Tokenizing train dataset:  37%|███▋      | 3135/8564 [00:34<00:59, 91.17 examples/s]Tokenizing train dataset:  35%|███▍      | 2989/8564 [00:35<00:47, 116.41 examples/s]Tokenizing train dataset:  37%|███▋      | 3145/8564 [00:34<00:59, 91.47 examples/s]Tokenizing train dataset:  37%|███▋      | 3206/8564 [00:35<00:45, 116.71 examples/s]Tokenizing train dataset:  38%|███▊      | 3221/8564 [00:35<00:43, 123.47 examples/s]Tokenizing train dataset:  35%|███▌      | 3007/8564 [00:35<00:51, 108.62 examples/s]Tokenizing train dataset:  37%|███▋      | 3160/8564 [00:34<00:56, 94.95 examples/s]Tokenizing train dataset:  35%|███▌      | 3019/8564 [00:35<00:51, 108.34 examples/s]Tokenizing train dataset:  38%|███▊      | 3236/8564 [00:35<00:50, 104.59 examples/s]Tokenizing train dataset:  37%|███▋      | 3171/8564 [00:35<01:03, 84.48 examples/s]Tokenizing train dataset:  35%|███▌      | 3031/8564 [00:35<00:57, 97.01 examples/s] Tokenizing train dataset:  37%|███▋      | 3187/8564 [00:35<00:54, 98.91 examples/s]Tokenizing train dataset:  38%|███▊      | 3250/8564 [00:36<00:53, 98.71 examples/s] Tokenizing train dataset:  36%|███▌      | 3042/8564 [00:35<00:55, 98.80 examples/s]Tokenizing train dataset:  37%|███▋      | 3198/8564 [00:35<00:53, 100.71 examples/s]Tokenizing train dataset:  38%|███▊      | 3267/8564 [00:36<00:53, 98.57 examples/s]Tokenizing train dataset:  36%|███▌      | 3054/8564 [00:36<00:58, 94.23 examples/s]Tokenizing train dataset:  38%|███▊      | 3216/8564 [00:35<00:48, 109.16 examples/s]Tokenizing train dataset:  38%|███▊      | 3228/8564 [00:35<00:48, 110.35 examples/s]Tokenizing train dataset:  36%|███▌      | 3069/8564 [00:36<00:55, 99.13 examples/s]Tokenizing train dataset:  38%|███▊      | 3278/8564 [00:36<01:03, 82.90 examples/s]Tokenizing train dataset:  36%|███▌      | 3083/8564 [00:36<00:54, 101.29 examples/s]Tokenizing train dataset:  38%|███▊      | 3249/8564 [00:35<00:45, 116.64 examples/s]Tokenizing train dataset:  38%|███▊      | 3289/8564 [00:36<01:05, 80.31 examples/s]Tokenizing train dataset:  36%|███▌      | 3094/8564 [00:36<00:56, 97.00 examples/s] Tokenizing train dataset:  38%|███▊      | 3267/8564 [00:35<00:45, 115.66 examples/s]Tokenizing train dataset:  39%|███▊      | 3299/8564 [00:36<01:06, 79.42 examples/s]Tokenizing train dataset:  39%|███▊      | 3308/8564 [00:36<01:04, 81.26 examples/s]Tokenizing train dataset:  36%|███▋      | 3106/8564 [00:36<01:01, 88.23 examples/s]Tokenizing train dataset:  38%|███▊      | 3283/8564 [00:36<00:47, 111.23 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:36<01:03, 82.91 examples/s]Tokenizing train dataset:  38%|███▊      | 3295/8564 [00:36<00:47, 111.57 examples/s]Tokenizing train dataset:  36%|███▋      | 3117/8564 [00:36<01:07, 80.24 examples/s]Tokenizing train dataset:  39%|███▊      | 3311/8564 [00:36<00:44, 118.48 examples/s]Tokenizing train dataset:  37%|███▋      | 3127/8564 [00:36<01:06, 81.57 examples/s]Tokenizing train dataset:  39%|███▉      | 3332/8564 [00:37<01:10, 74.68 examples/s]Tokenizing train dataset:  39%|███▉      | 3348/8564 [00:37<00:56, 92.27 examples/s]Tokenizing train dataset:  37%|███▋      | 3140/8564 [00:37<01:09, 78.58 examples/s]Tokenizing train dataset:  39%|███▉      | 3327/8564 [00:36<00:52, 100.03 examples/s]Tokenizing train dataset:  39%|███▉      | 3361/8564 [00:37<00:52, 99.51 examples/s]Tokenizing train dataset:  37%|███▋      | 3156/8564 [00:37<00:57, 93.53 examples/s]Tokenizing train dataset:  39%|███▉      | 3373/8564 [00:37<00:50, 103.43 examples/s]Tokenizing train dataset:  39%|███▉      | 3347/8564 [00:36<00:55, 94.18 examples/s] Tokenizing train dataset:  37%|███▋      | 3169/8564 [00:37<01:00, 89.58 examples/s]Tokenizing train dataset:  40%|███▉      | 3390/8564 [00:37<00:43, 119.04 examples/s]Tokenizing train dataset:  37%|███▋      | 3181/8564 [00:37<00:56, 95.60 examples/s]Tokenizing train dataset:  40%|███▉      | 3405/8564 [00:37<00:40, 126.01 examples/s]Tokenizing train dataset:  39%|███▉      | 3358/8564 [00:36<01:01, 84.43 examples/s]Tokenizing train dataset:  40%|███▉      | 3425/8564 [00:37<00:40, 126.56 examples/s]Tokenizing train dataset:  39%|███▉      | 3369/8564 [00:37<01:02, 83.45 examples/s]Tokenizing train dataset:  37%|███▋      | 3199/8564 [00:37<00:58, 91.43 examples/s]Tokenizing train dataset:  40%|████      | 3438/8564 [00:37<00:40, 125.27 examples/s]Tokenizing train dataset:  39%|███▉      | 3380/8564 [00:37<01:00, 85.96 examples/s]Tokenizing train dataset:  37%|███▋      | 3210/8564 [00:37<00:59, 89.99 examples/s]Tokenizing train dataset:  40%|████      | 3452/8564 [00:38<00:40, 125.20 examples/s]Tokenizing train dataset:  40%|███▉      | 3396/8564 [00:37<00:53, 96.74 examples/s]Tokenizing train dataset:  38%|███▊      | 3224/8564 [00:37<00:53, 100.14 examples/s]Tokenizing train dataset:  40%|████      | 3466/8564 [00:38<00:39, 128.18 examples/s]Tokenizing train dataset:  40%|███▉      | 3409/8564 [00:37<00:49, 103.23 examples/s]Tokenizing train dataset:  38%|███▊      | 3236/8564 [00:38<01:02, 85.72 examples/s] Tokenizing train dataset:  41%|████      | 3483/8564 [00:38<00:41, 121.16 examples/s]Tokenizing train dataset:  40%|███▉      | 3422/8564 [00:37<00:50, 102.82 examples/s]Tokenizing train dataset:  38%|███▊      | 3251/8564 [00:38<00:53, 98.62 examples/s]Tokenizing train dataset:  40%|████      | 3436/8564 [00:37<00:46, 111.42 examples/s]Tokenizing train dataset:  41%|████      | 3497/8564 [00:38<00:48, 104.54 examples/s]Tokenizing train dataset:  40%|████      | 3450/8564 [00:37<00:45, 111.44 examples/s]Tokenizing train dataset:  38%|███▊      | 3266/8564 [00:38<00:56, 94.38 examples/s]Tokenizing train dataset:  41%|████      | 3509/8564 [00:38<00:51, 97.52 examples/s] Tokenizing train dataset:  40%|████      | 3465/8564 [00:37<00:44, 113.40 examples/s]Tokenizing train dataset:  38%|███▊      | 3278/8564 [00:38<00:52, 99.99 examples/s]Tokenizing train dataset:  41%|████      | 3525/8564 [00:38<00:45, 109.88 examples/s]Tokenizing train dataset:  38%|███▊      | 3290/8564 [00:38<00:51, 102.16 examples/s]Tokenizing train dataset:  41%|████▏     | 3537/8564 [00:38<00:46, 108.11 examples/s]Tokenizing train dataset:  41%|████      | 3481/8564 [00:38<00:50, 100.31 examples/s]Tokenizing train dataset:  39%|███▊      | 3304/8564 [00:38<00:54, 96.41 examples/s] Tokenizing train dataset:  41%|████      | 3492/8564 [00:38<00:53, 95.65 examples/s] Tokenizing train dataset:  39%|███▉      | 3321/8564 [00:38<00:50, 103.54 examples/s]Tokenizing train dataset:  41%|████      | 3507/8564 [00:38<00:48, 103.90 examples/s]Tokenizing train dataset:  41%|████▏     | 3551/8564 [00:39<01:02, 80.39 examples/s] Tokenizing train dataset:  39%|███▉      | 3332/8564 [00:39<00:51, 101.03 examples/s]Tokenizing train dataset:  41%|████      | 3525/8564 [00:38<00:42, 118.74 examples/s]Tokenizing train dataset:  42%|████▏     | 3562/8564 [00:39<01:02, 80.56 examples/s]Tokenizing train dataset:  42%|████▏     | 3576/8564 [00:39<00:53, 92.69 examples/s]Tokenizing train dataset:  39%|███▉      | 3343/8564 [00:39<00:59, 87.21 examples/s] Tokenizing train dataset:  41%|████▏     | 3547/8564 [00:38<00:40, 122.43 examples/s]Tokenizing train dataset:  42%|████▏     | 3588/8564 [00:39<00:56, 88.58 examples/s]Tokenizing train dataset:  39%|███▉      | 3355/8564 [00:39<01:00, 86.71 examples/s]Tokenizing train dataset:  42%|████▏     | 3562/8564 [00:38<00:45, 109.57 examples/s]Tokenizing train dataset:  42%|████▏     | 3599/8564 [00:39<00:53, 92.95 examples/s]Tokenizing train dataset:  39%|███▉      | 3366/8564 [00:39<01:01, 84.47 examples/s]Tokenizing train dataset:  42%|████▏     | 3610/8564 [00:39<00:53, 92.51 examples/s]Tokenizing train dataset:  42%|████▏     | 3580/8564 [00:39<00:47, 104.52 examples/s]Tokenizing train dataset:  39%|███▉      | 3380/8564 [00:39<00:59, 87.08 examples/s]Tokenizing train dataset:  42%|████▏     | 3624/8564 [00:39<00:50, 98.04 examples/s]Tokenizing train dataset:  42%|████▏     | 3594/8564 [00:39<00:46, 107.23 examples/s]Tokenizing train dataset:  40%|███▉      | 3394/8564 [00:39<00:57, 89.57 examples/s]Tokenizing train dataset:  42%|████▏     | 3635/8564 [00:40<00:50, 96.94 examples/s]Tokenizing train dataset:  42%|████▏     | 3609/8564 [00:39<00:44, 112.48 examples/s]Tokenizing train dataset:  40%|███▉      | 3408/8564 [00:39<00:51, 100.40 examples/s]Tokenizing train dataset:  43%|████▎     | 3645/8564 [00:40<00:57, 85.02 examples/s]Tokenizing train dataset:  42%|████▏     | 3629/8564 [00:39<00:42, 116.46 examples/s]Tokenizing train dataset:  40%|███▉      | 3421/8564 [00:40<00:50, 102.77 examples/s]Tokenizing train dataset:  43%|████▎     | 3641/8564 [00:39<00:43, 112.99 examples/s]Tokenizing train dataset:  43%|████▎     | 3654/8564 [00:40<01:02, 78.40 examples/s]Tokenizing train dataset:  40%|████      | 3436/8564 [00:40<00:45, 112.75 examples/s]Tokenizing train dataset:  43%|████▎     | 3663/8564 [00:40<01:01, 79.94 examples/s]Tokenizing train dataset:  40%|████      | 3450/8564 [00:40<00:45, 113.22 examples/s]Tokenizing train dataset:  43%|████▎     | 3659/8564 [00:39<00:44, 111.19 examples/s]Tokenizing train dataset:  40%|████      | 3465/8564 [00:40<00:43, 116.35 examples/s]Tokenizing train dataset:  43%|████▎     | 3672/8564 [00:40<01:14, 65.99 examples/s]Tokenizing train dataset:  43%|████▎     | 3676/8564 [00:39<00:44, 109.53 examples/s]Tokenizing train dataset:  41%|████      | 3482/8564 [00:40<00:45, 112.76 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:40<01:11, 68.37 examples/s]Tokenizing train dataset:  43%|████▎     | 3689/8564 [00:39<00:42, 113.51 examples/s]Tokenizing train dataset:  41%|████      | 3496/8564 [00:40<00:44, 114.47 examples/s]Tokenizing train dataset:  43%|████▎     | 3702/8564 [00:40<00:44, 109.72 examples/s]Tokenizing train dataset:  43%|████▎     | 3693/8564 [00:40<01:04, 75.15 examples/s]Tokenizing train dataset:  41%|████      | 3516/8564 [00:40<00:38, 131.28 examples/s]Tokenizing train dataset:  43%|████▎     | 3720/8564 [00:40<00:38, 125.02 examples/s]Tokenizing train dataset:  43%|████▎     | 3702/8564 [00:40<01:04, 75.92 examples/s]Tokenizing train dataset:  41%|████▏     | 3533/8564 [00:40<00:41, 121.45 examples/s]Tokenizing train dataset:  43%|████▎     | 3711/8564 [00:41<01:07, 72.36 examples/s]Tokenizing train dataset:  44%|████▎     | 3737/8564 [00:40<00:41, 117.68 examples/s]Tokenizing train dataset:  44%|████▍     | 3752/8564 [00:40<00:38, 124.65 examples/s]Tokenizing train dataset:  41%|████▏     | 3546/8564 [00:41<00:42, 116.83 examples/s]Tokenizing train dataset:  44%|████▎     | 3726/8564 [00:41<01:00, 80.17 examples/s]Tokenizing train dataset:  42%|████▏     | 3558/8564 [00:41<00:43, 115.78 examples/s]Tokenizing train dataset:  44%|████▍     | 3765/8564 [00:40<00:39, 121.04 examples/s]Tokenizing train dataset:  44%|████▎     | 3735/8564 [00:41<01:02, 77.54 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:40<00:37, 126.28 examples/s]Tokenizing train dataset:  42%|████▏     | 3570/8564 [00:41<00:44, 112.24 examples/s]Tokenizing train dataset:  44%|████▍     | 3748/8564 [00:41<01:00, 80.18 examples/s]Tokenizing train dataset:  42%|████▏     | 3588/8564 [00:41<00:38, 129.04 examples/s]Tokenizing train dataset:  44%|████▍     | 3799/8564 [00:40<00:39, 122.06 examples/s]Tokenizing train dataset:  44%|████▍     | 3759/8564 [00:41<00:55, 86.96 examples/s]Tokenizing train dataset:  42%|████▏     | 3602/8564 [00:41<00:39, 124.77 examples/s]Tokenizing train dataset:  45%|████▍     | 3816/8564 [00:40<00:40, 118.44 examples/s]Tokenizing train dataset:  42%|████▏     | 3619/8564 [00:41<00:41, 117.93 examples/s]Tokenizing train dataset:  44%|████▍     | 3773/8564 [00:41<00:58, 81.61 examples/s]Tokenizing train dataset:  45%|████▍     | 3830/8564 [00:41<00:40, 115.71 examples/s]Tokenizing train dataset:  42%|████▏     | 3632/8564 [00:41<00:40, 120.52 examples/s]Tokenizing train dataset:  44%|████▍     | 3783/8564 [00:41<00:57, 82.58 examples/s]Tokenizing train dataset:  45%|████▍     | 3842/8564 [00:41<00:41, 115.14 examples/s]Tokenizing train dataset:  43%|████▎     | 3645/8564 [00:41<00:42, 116.42 examples/s]Tokenizing train dataset:  44%|████▍     | 3795/8564 [00:42<01:01, 77.32 examples/s]Tokenizing train dataset:  43%|████▎     | 3658/8564 [00:42<00:41, 118.69 examples/s]Tokenizing train dataset:  45%|████▌     | 3860/8564 [00:41<00:40, 116.05 examples/s]Tokenizing train dataset:  44%|████▍     | 3805/8564 [00:42<01:02, 76.21 examples/s]Tokenizing train dataset:  45%|████▌     | 3874/8564 [00:41<00:39, 117.38 examples/s]Tokenizing train dataset:  43%|████▎     | 3674/8564 [00:42<00:44, 109.84 examples/s]Tokenizing train dataset:  45%|████▌     | 3887/8564 [00:41<00:39, 119.59 examples/s]Tokenizing train dataset:  45%|████▍     | 3815/8564 [00:42<01:03, 75.38 examples/s]Tokenizing train dataset:  43%|████▎     | 3690/8564 [00:42<00:42, 114.73 examples/s]Tokenizing train dataset:  45%|████▍     | 3823/8564 [00:42<01:05, 72.25 examples/s]Tokenizing train dataset:  46%|████▌     | 3906/8564 [00:41<00:41, 112.73 examples/s]Tokenizing train dataset:  43%|████▎     | 3703/8564 [00:42<00:42, 113.44 examples/s]Tokenizing train dataset:  45%|████▍     | 3834/8564 [00:42<01:02, 75.43 examples/s]Tokenizing train dataset:  46%|████▌     | 3918/8564 [00:41<00:42, 108.52 examples/s]Tokenizing train dataset:  43%|████▎     | 3720/8564 [00:42<00:39, 122.21 examples/s]Tokenizing train dataset:  46%|████▌     | 3930/8564 [00:42<00:41, 110.86 examples/s]Tokenizing train dataset:  44%|████▎     | 3740/8564 [00:42<00:40, 118.43 examples/s]Tokenizing train dataset:  45%|████▍     | 3848/8564 [00:42<01:05, 71.60 examples/s]Tokenizing train dataset:  46%|████▌     | 3943/8564 [00:42<00:41, 111.74 examples/s]Tokenizing train dataset:  44%|████▍     | 3755/8564 [00:42<00:39, 120.67 examples/s]Tokenizing train dataset:  45%|████▌     | 3856/8564 [00:43<01:07, 69.26 examples/s]Tokenizing train dataset:  46%|████▌     | 3957/8564 [00:42<00:41, 112.33 examples/s]Tokenizing train dataset:  44%|████▍     | 3770/8564 [00:42<00:38, 123.71 examples/s]Tokenizing train dataset:  45%|████▌     | 3870/8564 [00:43<00:55, 83.84 examples/s]Tokenizing train dataset:  46%|████▋     | 3970/8564 [00:42<00:44, 102.77 examples/s]Tokenizing train dataset:  45%|████▌     | 3883/8564 [00:43<00:49, 93.68 examples/s]Tokenizing train dataset:  44%|████▍     | 3788/8564 [00:43<00:43, 110.08 examples/s]Tokenizing train dataset:  47%|████▋     | 3987/8564 [00:42<00:43, 104.98 examples/s]Tokenizing train dataset:  45%|████▌     | 3895/8564 [00:43<00:48, 95.81 examples/s]Tokenizing train dataset:  47%|████▋     | 4000/8564 [00:42<00:42, 106.51 examples/s]Tokenizing train dataset:  46%|████▌     | 3907/8564 [00:43<00:48, 95.18 examples/s]Tokenizing train dataset:  44%|████▍     | 3803/8564 [00:43<00:49, 95.83 examples/s] Tokenizing train dataset:  47%|████▋     | 4011/8564 [00:42<00:42, 105.98 examples/s]Tokenizing train dataset:  46%|████▌     | 3921/8564 [00:43<00:49, 93.05 examples/s]Tokenizing train dataset:  45%|████▍     | 3820/8564 [00:43<00:52, 90.45 examples/s]Tokenizing train dataset:  47%|████▋     | 4030/8564 [00:42<00:42, 107.33 examples/s]Tokenizing train dataset:  46%|████▌     | 3935/8564 [00:43<00:46, 100.63 examples/s]Tokenizing train dataset:  47%|████▋     | 4044/8564 [00:43<00:39, 113.86 examples/s]Tokenizing train dataset:  46%|████▌     | 3950/8564 [00:43<00:42, 109.73 examples/s]Tokenizing train dataset:  45%|████▍     | 3834/8564 [00:43<00:57, 82.45 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:43<00:42, 105.16 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:43<00:43, 105.63 examples/s]Tokenizing train dataset:  45%|████▍     | 3847/8564 [00:43<00:53, 88.01 examples/s]Tokenizing train dataset:  46%|████▋     | 3974/8564 [00:44<00:44, 102.51 examples/s]Tokenizing train dataset:  48%|████▊     | 4070/8564 [00:43<00:47, 93.77 examples/s] Tokenizing train dataset:  45%|████▌     | 3859/8564 [00:44<00:50, 94.02 examples/s]Tokenizing train dataset:  45%|████▌     | 3872/8564 [00:44<00:46, 101.43 examples/s]Tokenizing train dataset:  47%|████▋     | 3987/8564 [00:44<00:51, 89.21 examples/s] Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:43<00:51, 86.51 examples/s]Tokenizing train dataset:  45%|████▌     | 3886/8564 [00:44<00:44, 104.94 examples/s]Tokenizing train dataset:  47%|████▋     | 3998/8564 [00:44<00:51, 89.50 examples/s]Tokenizing train dataset:  48%|████▊     | 4091/8564 [00:43<00:59, 75.37 examples/s]Tokenizing train dataset:  46%|████▌     | 3899/8564 [00:44<00:45, 103.20 examples/s]Tokenizing train dataset:  47%|████▋     | 4010/8564 [00:44<00:48, 93.10 examples/s]Tokenizing train dataset:  48%|████▊     | 4105/8564 [00:43<00:52, 85.23 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:44<00:49, 92.21 examples/s]Tokenizing train dataset:  46%|████▌     | 3914/8564 [00:44<00:47, 97.35 examples/s] Tokenizing train dataset:  47%|████▋     | 4035/8564 [00:44<00:44, 101.94 examples/s]Tokenizing train dataset:  48%|████▊     | 4120/8564 [00:44<00:51, 86.80 examples/s]Tokenizing train dataset:  47%|████▋     | 4046/8564 [00:44<00:43, 103.54 examples/s]Tokenizing train dataset:  46%|████▌     | 3929/8564 [00:44<00:52, 88.34 examples/s]Tokenizing train dataset:  48%|████▊     | 4133/8564 [00:44<00:53, 82.47 examples/s]Tokenizing train dataset:  47%|████▋     | 4060/8564 [00:44<00:42, 106.94 examples/s]Tokenizing train dataset:  46%|████▌     | 3939/8564 [00:44<00:53, 85.67 examples/s]Tokenizing train dataset:  48%|████▊     | 4145/8564 [00:44<00:50, 88.33 examples/s]Tokenizing train dataset:  48%|████▊     | 4073/8564 [00:45<00:41, 108.51 examples/s]Tokenizing train dataset:  46%|████▌     | 3950/8564 [00:44<00:52, 87.81 examples/s]Tokenizing train dataset:  49%|████▊     | 4158/8564 [00:44<00:48, 90.09 examples/s]Tokenizing train dataset:  48%|████▊     | 4086/8564 [00:45<00:41, 107.44 examples/s]Tokenizing train dataset:  46%|████▋     | 3962/8564 [00:45<00:56, 81.82 examples/s]Tokenizing train dataset:  49%|████▊     | 4173/8564 [00:44<00:44, 98.57 examples/s]Tokenizing train dataset:  48%|████▊     | 4097/8564 [00:45<00:49, 90.06 examples/s] Tokenizing train dataset:  46%|████▋     | 3972/8564 [00:45<00:55, 82.60 examples/s]Tokenizing train dataset:  49%|████▉     | 4188/8564 [00:44<00:39, 109.63 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:45<00:47, 94.56 examples/s]Tokenizing train dataset:  49%|████▉     | 4202/8564 [00:44<00:38, 114.25 examples/s]Tokenizing train dataset:  46%|████▋     | 3981/8564 [00:45<00:59, 77.30 examples/s]Tokenizing train dataset:  48%|████▊     | 4120/8564 [00:45<00:50, 88.29 examples/s]Tokenizing train dataset:  49%|████▉     | 4214/8564 [00:44<00:38, 114.29 examples/s]Tokenizing train dataset:  47%|████▋     | 3991/8564 [00:45<00:59, 76.58 examples/s]Tokenizing train dataset:  49%|████▉     | 4228/8564 [00:44<00:36, 119.69 examples/s]Tokenizing train dataset:  48%|████▊     | 4130/8564 [00:45<00:54, 81.37 examples/s]Tokenizing train dataset:  47%|████▋     | 4001/8564 [00:45<00:59, 76.68 examples/s]Tokenizing train dataset:  48%|████▊     | 4139/8564 [00:45<00:56, 78.81 examples/s]Tokenizing train dataset:  50%|████▉     | 4246/8564 [00:45<00:38, 112.20 examples/s]Tokenizing train dataset:  47%|████▋     | 4012/8564 [00:45<00:56, 80.66 examples/s]Tokenizing train dataset:  48%|████▊     | 4149/8564 [00:46<00:54, 80.61 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:45<00:55, 82.06 examples/s]Tokenizing train dataset:  50%|████▉     | 4263/8564 [00:45<00:40, 105.92 examples/s]Tokenizing train dataset:  49%|████▊     | 4160/8564 [00:46<00:50, 86.47 examples/s]Tokenizing train dataset:  47%|████▋     | 4030/8564 [00:46<00:54, 82.70 examples/s]Tokenizing train dataset:  49%|████▊     | 4172/8564 [00:46<00:46, 93.96 examples/s]Tokenizing train dataset:  50%|████▉     | 4275/8564 [00:45<00:43, 99.50 examples/s] Tokenizing train dataset:  47%|████▋     | 4044/8564 [00:46<00:56, 79.58 examples/s]Tokenizing train dataset:  49%|████▉     | 4188/8564 [00:46<00:40, 109.02 examples/s]Tokenizing train dataset:  50%|█████     | 4288/8564 [00:45<00:46, 91.11 examples/s]Tokenizing train dataset:  49%|████▉     | 4202/8564 [00:46<00:37, 116.80 examples/s]Tokenizing train dataset:  47%|████▋     | 4053/8564 [00:46<00:58, 77.15 examples/s]Tokenizing train dataset:  49%|████▉     | 4214/8564 [00:46<00:38, 112.52 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:46<00:56, 79.43 examples/s]Tokenizing train dataset:  50%|█████     | 4301/8564 [00:45<00:50, 84.52 examples/s]Tokenizing train dataset:  49%|████▉     | 4228/8564 [00:46<00:36, 118.23 examples/s]Tokenizing train dataset:  48%|████▊     | 4072/8564 [00:46<01:00, 73.95 examples/s]Tokenizing train dataset:  50%|█████     | 4313/8564 [00:45<00:50, 84.20 examples/s]Tokenizing train dataset:  50%|████▉     | 4243/8564 [00:46<00:39, 108.11 examples/s]Tokenizing train dataset:  48%|████▊     | 4083/8564 [00:46<00:59, 74.85 examples/s]Tokenizing train dataset:  51%|█████     | 4325/8564 [00:46<00:52, 81.48 examples/s]Tokenizing train dataset:  50%|████▉     | 4258/8564 [00:46<00:37, 113.84 examples/s]Tokenizing train dataset:  48%|████▊     | 4094/8564 [00:46<01:04, 68.91 examples/s]Tokenizing train dataset:  50%|████▉     | 4271/8564 [00:47<00:36, 117.08 examples/s]Tokenizing train dataset:  51%|█████     | 4337/8564 [00:46<00:53, 78.80 examples/s]Tokenizing train dataset:  50%|█████     | 4283/8564 [00:47<00:36, 116.64 examples/s]Tokenizing train dataset:  48%|████▊     | 4105/8564 [00:47<01:02, 71.57 examples/s]Tokenizing train dataset:  51%|█████     | 4346/8564 [00:46<00:57, 72.89 examples/s]Tokenizing train dataset:  50%|█████     | 4296/8564 [00:47<00:36, 116.46 examples/s]Tokenizing train dataset:  48%|████▊     | 4117/8564 [00:47<00:58, 75.89 examples/s]Tokenizing train dataset:  51%|█████     | 4357/8564 [00:46<00:54, 77.29 examples/s]Tokenizing train dataset:  50%|█████     | 4310/8564 [00:47<00:34, 121.85 examples/s]Tokenizing train dataset:  51%|█████     | 4365/8564 [00:46<00:55, 75.38 examples/s]Tokenizing train dataset:  48%|████▊     | 4127/8564 [00:47<00:59, 75.16 examples/s]Tokenizing train dataset:  51%|█████     | 4325/8564 [00:47<00:39, 106.95 examples/s]Tokenizing train dataset:  48%|████▊     | 4139/8564 [00:47<00:52, 84.52 examples/s]Tokenizing train dataset:  51%|█████     | 4376/8564 [00:46<00:52, 79.89 examples/s]Tokenizing train dataset:  48%|████▊     | 4150/8564 [00:47<00:50, 87.24 examples/s]Tokenizing train dataset:  51%|█████     | 4339/8564 [00:47<00:45, 92.03 examples/s] Tokenizing train dataset:  51%|█████     | 4389/8564 [00:46<00:54, 76.92 examples/s]Tokenizing train dataset:  49%|████▊     | 4161/8564 [00:47<00:48, 89.89 examples/s]Tokenizing train dataset:  51%|█████▏    | 4405/8564 [00:47<00:44, 93.93 examples/s]Tokenizing train dataset:  49%|████▊     | 4171/8564 [00:47<00:47, 92.14 examples/s]Tokenizing train dataset:  51%|█████     | 4350/8564 [00:47<00:50, 83.06 examples/s]Tokenizing train dataset:  52%|█████▏    | 4417/8564 [00:47<00:44, 93.83 examples/s]Tokenizing train dataset:  49%|████▉     | 4183/8564 [00:47<00:44, 98.54 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:48<00:52, 79.63 examples/s]Tokenizing train dataset:  52%|█████▏    | 4429/8564 [00:47<00:42, 97.96 examples/s]Tokenizing train dataset:  49%|████▉     | 4200/8564 [00:47<00:38, 112.77 examples/s]Tokenizing train dataset:  51%|█████     | 4375/8564 [00:48<00:48, 86.63 examples/s]Tokenizing train dataset:  49%|████▉     | 4213/8564 [00:48<00:38, 111.94 examples/s]Tokenizing train dataset:  52%|█████▏    | 4446/8564 [00:47<00:42, 97.08 examples/s]Tokenizing train dataset:  51%|█████     | 4389/8564 [00:48<00:49, 85.20 examples/s]Tokenizing train dataset:  52%|█████▏    | 4457/8564 [00:47<00:41, 98.14 examples/s]Tokenizing train dataset:  49%|████▉     | 4226/8564 [00:48<00:42, 101.50 examples/s]Tokenizing train dataset:  51%|█████▏    | 4403/8564 [00:48<00:46, 90.20 examples/s]Tokenizing train dataset:  52%|█████▏    | 4472/8564 [00:47<00:38, 106.67 examples/s]Tokenizing train dataset:  52%|█████▏    | 4484/8564 [00:47<00:38, 106.60 examples/s]Tokenizing train dataset:  49%|████▉     | 4239/8564 [00:48<00:53, 81.35 examples/s] Tokenizing train dataset:  52%|█████▏    | 4416/8564 [00:48<00:47, 86.72 examples/s]Tokenizing train dataset:  52%|█████▏    | 4495/8564 [00:47<00:41, 99.23 examples/s] Tokenizing train dataset:  50%|████▉     | 4250/8564 [00:48<00:52, 82.37 examples/s]Tokenizing train dataset:  52%|█████▏    | 4426/8564 [00:48<00:47, 86.73 examples/s]Tokenizing train dataset:  50%|████▉     | 4263/8564 [00:48<00:46, 91.78 examples/s]Tokenizing train dataset:  53%|█████▎    | 4507/8564 [00:48<00:41, 96.88 examples/s]Tokenizing train dataset:  52%|█████▏    | 4438/8564 [00:48<00:47, 87.46 examples/s]Tokenizing train dataset:  50%|████▉     | 4278/8564 [00:48<00:43, 99.46 examples/s]Tokenizing train dataset:  53%|█████▎    | 4519/8564 [00:48<00:41, 96.76 examples/s]Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:49<00:45, 91.20 examples/s]Tokenizing train dataset:  50%|█████     | 4291/8564 [00:48<00:43, 99.18 examples/s]Tokenizing train dataset:  52%|█████▏    | 4462/8564 [00:49<00:43, 94.68 examples/s]Tokenizing train dataset:  53%|█████▎    | 4534/8564 [00:48<00:45, 89.54 examples/s]Tokenizing train dataset:  50%|█████     | 4306/8564 [00:49<00:39, 107.44 examples/s]Tokenizing train dataset:  52%|█████▏    | 4477/8564 [00:49<00:39, 102.30 examples/s]Tokenizing train dataset:  53%|█████▎    | 4545/8564 [00:48<00:45, 88.97 examples/s]Tokenizing train dataset:  52%|█████▏    | 4488/8564 [00:49<00:40, 100.39 examples/s]Tokenizing train dataset:  50%|█████     | 4323/8564 [00:49<00:40, 104.91 examples/s]Tokenizing train dataset:  53%|█████▎    | 4556/8564 [00:48<00:44, 90.01 examples/s]Tokenizing train dataset:  51%|█████     | 4335/8564 [00:49<00:40, 104.52 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:49<00:45, 88.39 examples/s] Tokenizing train dataset:  53%|█████▎    | 4568/8564 [00:48<00:47, 83.29 examples/s]Tokenizing train dataset:  51%|█████     | 4349/8564 [00:49<00:39, 106.05 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:49<00:38, 108.81 examples/s]Tokenizing train dataset:  53%|█████▎    | 4512/8564 [00:49<00:50, 80.27 examples/s]Tokenizing train dataset:  53%|█████▎    | 4579/8564 [00:49<00:53, 74.83 examples/s]Tokenizing train dataset:  51%|█████     | 4374/8564 [00:49<00:38, 110.19 examples/s]Tokenizing train dataset:  53%|█████▎    | 4521/8564 [00:49<00:51, 78.19 examples/s]Tokenizing train dataset:  54%|█████▎    | 4587/8564 [00:49<00:53, 74.79 examples/s]Tokenizing train dataset:  51%|█████▏    | 4390/8564 [00:49<00:35, 117.24 examples/s]Tokenizing train dataset:  54%|█████▎    | 4596/8564 [00:49<00:51, 77.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 4534/8564 [00:50<00:51, 78.48 examples/s]Tokenizing train dataset:  51%|█████▏    | 4404/8564 [00:49<00:34, 120.99 examples/s]Tokenizing train dataset:  54%|█████▍    | 4604/8564 [00:49<00:54, 73.20 examples/s]Tokenizing train dataset:  53%|█████▎    | 4544/8564 [00:50<00:54, 73.59 examples/s]Tokenizing train dataset:  54%|█████▍    | 4616/8564 [00:49<00:49, 79.86 examples/s]Tokenizing train dataset:  52%|█████▏    | 4422/8564 [00:50<00:36, 114.43 examples/s]Tokenizing train dataset:  53%|█████▎    | 4558/8564 [00:50<00:47, 83.94 examples/s]Tokenizing train dataset:  52%|█████▏    | 4435/8564 [00:50<00:35, 114.83 examples/s]Tokenizing train dataset:  53%|█████▎    | 4568/8564 [00:50<00:48, 82.17 examples/s]Tokenizing train dataset:  54%|█████▍    | 4630/8564 [00:49<00:54, 72.02 examples/s]Tokenizing train dataset:  52%|█████▏    | 4449/8564 [00:50<00:35, 116.13 examples/s]Tokenizing train dataset:  54%|█████▍    | 4640/8564 [00:49<00:54, 71.89 examples/s]Tokenizing train dataset:  53%|█████▎    | 4579/8564 [00:50<00:53, 73.92 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:50<00:34, 118.01 examples/s]Tokenizing train dataset:  54%|█████▍    | 4648/8564 [00:49<00:56, 69.82 examples/s]Tokenizing train dataset:  52%|█████▏    | 4482/8564 [00:50<00:34, 117.70 examples/s]Tokenizing train dataset:  54%|█████▎    | 4590/8564 [00:50<00:57, 69.08 examples/s]Tokenizing train dataset:  54%|█████▍    | 4657/8564 [00:50<00:55, 70.22 examples/s]Tokenizing train dataset:  54%|█████▎    | 4602/8564 [00:50<00:49, 79.60 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:50<00:36, 112.42 examples/s]Tokenizing train dataset:  54%|█████▍    | 4614/8564 [00:51<00:45, 87.52 examples/s]Tokenizing train dataset:  53%|█████▎    | 4511/8564 [00:50<00:36, 111.22 examples/s]Tokenizing train dataset:  55%|█████▍    | 4669/8564 [00:50<00:58, 66.91 examples/s]Tokenizing train dataset:  54%|█████▍    | 4627/8564 [00:51<00:41, 94.04 examples/s]Tokenizing train dataset:  55%|█████▍    | 4678/8564 [00:50<00:56, 68.94 examples/s]Tokenizing train dataset:  53%|█████▎    | 4523/8564 [00:51<00:40, 99.41 examples/s] Tokenizing train dataset:  54%|█████▍    | 4638/8564 [00:51<00:42, 92.97 examples/s]Tokenizing train dataset:  53%|█████▎    | 4535/8564 [00:51<00:40, 98.53 examples/s]Tokenizing train dataset:  54%|█████▍    | 4649/8564 [00:51<00:40, 96.87 examples/s]Tokenizing train dataset:  55%|█████▍    | 4690/8564 [00:50<00:58, 66.12 examples/s]Tokenizing train dataset:  54%|█████▍    | 4661/8564 [00:51<00:42, 92.91 examples/s]Tokenizing train dataset:  53%|█████▎    | 4553/8564 [00:51<00:41, 96.08 examples/s]Tokenizing train dataset:  55%|█████▍    | 4701/8564 [00:50<00:59, 64.71 examples/s]Tokenizing train dataset:  55%|█████▌    | 4713/8564 [00:50<00:52, 74.04 examples/s]Tokenizing train dataset:  55%|█████▍    | 4673/8564 [00:51<00:46, 84.02 examples/s]Tokenizing train dataset:  53%|█████▎    | 4567/8564 [00:51<00:46, 85.37 examples/s]Tokenizing train dataset:  55%|█████▌    | 4728/8564 [00:51<00:45, 83.47 examples/s]Tokenizing train dataset:  55%|█████▍    | 4685/8564 [00:51<00:50, 77.00 examples/s]Tokenizing train dataset:  55%|█████▌    | 4740/8564 [00:51<00:42, 90.98 examples/s]Tokenizing train dataset:  53%|█████▎    | 4577/8564 [00:51<00:55, 71.20 examples/s]Tokenizing train dataset:  55%|█████▍    | 4696/8564 [00:52<00:47, 81.76 examples/s]Tokenizing train dataset:  54%|█████▎    | 4591/8564 [00:51<00:47, 83.44 examples/s]Tokenizing train dataset:  55%|█████▍    | 4708/8564 [00:52<00:42, 90.48 examples/s]Tokenizing train dataset:  55%|█████▌    | 4751/8564 [00:51<00:49, 77.33 examples/s]Tokenizing train dataset:  55%|█████▌    | 4719/8564 [00:52<00:41, 92.45 examples/s]Tokenizing train dataset:  54%|█████▍    | 4604/8564 [00:52<00:49, 80.42 examples/s]Tokenizing train dataset:  56%|█████▌    | 4766/8564 [00:51<00:44, 86.25 examples/s]Tokenizing train dataset:  55%|█████▌    | 4730/8564 [00:52<00:40, 93.82 examples/s]Tokenizing train dataset:  54%|█████▍    | 4616/8564 [00:52<00:48, 82.12 examples/s]Tokenizing train dataset:  56%|█████▌    | 4781/8564 [00:51<00:42, 89.45 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:52<00:38, 100.16 examples/s]Tokenizing train dataset:  56%|█████▌    | 4796/8564 [00:51<00:37, 100.85 examples/s]Tokenizing train dataset:  55%|█████▌    | 4753/8564 [00:52<00:38, 99.92 examples/s] Tokenizing train dataset:  54%|█████▍    | 4629/8564 [00:52<00:48, 80.98 examples/s]Tokenizing train dataset:  56%|█████▌    | 4813/8564 [00:51<00:32, 114.02 examples/s]Tokenizing train dataset:  54%|█████▍    | 4638/8564 [00:52<00:50, 77.93 examples/s]Tokenizing train dataset:  56%|█████▌    | 4764/8564 [00:52<00:43, 87.35 examples/s]Tokenizing train dataset:  56%|█████▋    | 4834/8564 [00:51<00:28, 132.96 examples/s]Tokenizing train dataset:  54%|█████▍    | 4646/8564 [00:52<00:54, 72.42 examples/s]Tokenizing train dataset:  57%|█████▋    | 4858/8564 [00:52<00:23, 159.11 examples/s]Tokenizing train dataset:  56%|█████▌    | 4780/8564 [00:52<00:44, 85.65 examples/s]Tokenizing train dataset:  54%|█████▍    | 4654/8564 [00:52<00:54, 71.33 examples/s]Tokenizing train dataset:  57%|█████▋    | 4875/8564 [00:52<00:22, 161.30 examples/s]Tokenizing train dataset:  56%|█████▌    | 4794/8564 [00:53<00:38, 96.79 examples/s]Tokenizing train dataset:  57%|█████▋    | 4894/8564 [00:52<00:21, 168.32 examples/s]Tokenizing train dataset:  54%|█████▍    | 4663/8564 [00:52<00:57, 67.39 examples/s]Tokenizing train dataset:  56%|█████▌    | 4816/8564 [00:53<00:32, 116.12 examples/s]Tokenizing train dataset:  55%|█████▍    | 4677/8564 [00:53<00:49, 78.26 examples/s]Tokenizing train dataset:  57%|█████▋    | 4915/8564 [00:52<00:23, 152.88 examples/s]Tokenizing train dataset:  57%|█████▋    | 4839/8564 [00:53<00:26, 142.60 examples/s]Tokenizing train dataset:  58%|█████▊    | 4939/8564 [00:52<00:20, 174.94 examples/s]Tokenizing train dataset:  55%|█████▍    | 4687/8564 [00:53<00:51, 75.50 examples/s]Tokenizing train dataset:  57%|█████▋    | 4862/8564 [00:53<00:24, 153.09 examples/s]Tokenizing train dataset:  58%|█████▊    | 4960/8564 [00:52<00:19, 182.07 examples/s]Tokenizing train dataset:  55%|█████▍    | 4699/8564 [00:53<00:45, 84.76 examples/s]Tokenizing train dataset:  57%|█████▋    | 4879/8564 [00:53<00:25, 143.34 examples/s]Tokenizing train dataset:  55%|█████▍    | 4709/8564 [00:53<00:44, 87.47 examples/s]Tokenizing train dataset:  58%|█████▊    | 4980/8564 [00:52<00:22, 157.53 examples/s]Tokenizing train dataset:  57%|█████▋    | 4896/8564 [00:53<00:25, 143.08 examples/s]Tokenizing train dataset:  55%|█████▌    | 4722/8564 [00:53<00:40, 95.20 examples/s]Tokenizing train dataset:  57%|█████▋    | 4920/8564 [00:53<00:21, 166.26 examples/s]Tokenizing train dataset:  58%|█████▊    | 5000/8564 [00:52<00:24, 148.40 examples/s]Tokenizing train dataset:  55%|█████▌    | 4737/8564 [00:53<00:35, 108.12 examples/s]Tokenizing train dataset:  58%|█████▊    | 4941/8564 [00:53<00:22, 161.62 examples/s]Tokenizing train dataset:  59%|█████▊    | 5017/8564 [00:53<00:24, 142.86 examples/s]Tokenizing train dataset:  55%|█████▌    | 4752/8564 [00:53<00:38, 100.26 examples/s]Tokenizing train dataset:  58%|█████▊    | 4960/8564 [00:54<00:24, 144.58 examples/s]Tokenizing train dataset:  59%|█████▉    | 5034/8564 [00:53<00:27, 130.59 examples/s]Tokenizing train dataset:  56%|█████▌    | 4763/8564 [00:53<00:38, 98.37 examples/s] Tokenizing train dataset:  59%|█████▉    | 5055/8564 [00:53<00:24, 141.50 examples/s]Tokenizing train dataset:  58%|█████▊    | 4985/8564 [00:54<00:25, 142.55 examples/s]Tokenizing train dataset:  56%|█████▌    | 4779/8564 [00:54<00:39, 96.90 examples/s]Tokenizing train dataset:  59%|█████▉    | 5071/8564 [00:53<00:26, 133.70 examples/s]Tokenizing train dataset:  58%|█████▊    | 5003/8564 [00:54<00:23, 150.47 examples/s]Tokenizing train dataset:  56%|█████▌    | 4790/8564 [00:54<00:37, 99.74 examples/s]Tokenizing train dataset:  59%|█████▉    | 5088/8564 [00:53<00:24, 139.79 examples/s]Tokenizing train dataset:  59%|█████▊    | 5025/8564 [00:54<00:21, 161.60 examples/s]Tokenizing train dataset:  60%|█████▉    | 5107/8564 [00:53<00:22, 151.13 examples/s]Tokenizing train dataset:  56%|█████▌    | 4804/8564 [00:54<00:41, 91.69 examples/s]Tokenizing train dataset:  59%|█████▉    | 5045/8564 [00:54<00:21, 163.37 examples/s]Tokenizing train dataset:  60%|█████▉    | 5126/8564 [00:53<00:22, 151.80 examples/s]Tokenizing train dataset:  56%|█████▋    | 4826/8564 [00:54<00:32, 115.73 examples/s]Tokenizing train dataset:  59%|█████▉    | 5072/8564 [00:54<00:20, 172.36 examples/s]Tokenizing train dataset:  57%|█████▋    | 4850/8564 [00:54<00:26, 140.68 examples/s]Tokenizing train dataset:  60%|██████    | 5149/8564 [00:54<00:23, 144.61 examples/s]Tokenizing train dataset:  59%|█████▉    | 5092/8564 [00:54<00:22, 155.09 examples/s]Tokenizing train dataset:  60%|██████    | 5178/8564 [00:54<00:18, 178.81 examples/s]Tokenizing train dataset:  60%|█████▉    | 5110/8564 [00:54<00:21, 157.69 examples/s]Tokenizing train dataset:  57%|█████▋    | 4874/8564 [00:54<00:27, 132.33 examples/s]Tokenizing train dataset:  61%|██████    | 5200/8564 [00:54<00:18, 183.74 examples/s]Tokenizing train dataset:  60%|█████▉    | 5134/8564 [00:55<00:19, 176.90 examples/s]Tokenizing train dataset:  57%|█████▋    | 4888/8564 [00:54<00:28, 129.59 examples/s]Tokenizing train dataset:  61%|██████    | 5227/8564 [00:54<00:16, 205.15 examples/s]Tokenizing train dataset:  60%|██████    | 5162/8564 [00:55<00:17, 192.62 examples/s]Tokenizing train dataset:  57%|█████▋    | 4909/8564 [00:55<00:27, 133.29 examples/s]Tokenizing train dataset:  61%|██████▏   | 5253/8564 [00:54<00:15, 213.87 examples/s]Tokenizing train dataset:  58%|█████▊    | 4933/8564 [00:55<00:23, 153.47 examples/s]Tokenizing train dataset:  62%|██████▏   | 5282/8564 [00:54<00:14, 226.25 examples/s]Tokenizing train dataset:  61%|██████    | 5186/8564 [00:55<00:19, 170.99 examples/s]Tokenizing train dataset:  58%|█████▊    | 4956/8564 [00:55<00:21, 164.98 examples/s]Tokenizing train dataset:  62%|██████▏   | 5307/8564 [00:54<00:14, 225.21 examples/s]Tokenizing train dataset:  61%|██████    | 5210/8564 [00:55<00:21, 158.09 examples/s]Tokenizing train dataset:  58%|█████▊    | 4980/8564 [00:55<00:22, 158.97 examples/s]Tokenizing train dataset:  62%|██████▏   | 5336/8564 [00:54<00:16, 196.74 examples/s]Tokenizing train dataset:  61%|██████    | 5231/8564 [00:55<00:20, 161.61 examples/s]Tokenizing train dataset:  61%|██████▏   | 5265/8564 [00:55<00:16, 197.66 examples/s]Tokenizing train dataset:  58%|█████▊    | 5001/8564 [00:55<00:24, 144.70 examples/s]Tokenizing train dataset:  63%|██████▎   | 5361/8564 [00:55<00:17, 182.84 examples/s]Tokenizing train dataset:  62%|██████▏   | 5289/8564 [00:55<00:16, 201.83 examples/s]Tokenizing train dataset:  59%|█████▊    | 5017/8564 [00:55<00:25, 136.88 examples/s]Tokenizing train dataset:  62%|██████▏   | 5312/8564 [00:56<00:15, 206.07 examples/s]Tokenizing train dataset:  63%|██████▎   | 5383/8564 [00:55<00:22, 144.40 examples/s]Tokenizing train dataset:  59%|█████▉    | 5034/8564 [00:55<00:26, 132.08 examples/s]Tokenizing train dataset:  62%|██████▏   | 5335/8564 [00:56<00:16, 200.07 examples/s]Tokenizing train dataset:  59%|█████▉    | 5061/8564 [00:56<00:21, 159.33 examples/s]Tokenizing train dataset:  63%|██████▎   | 5401/8564 [00:55<00:23, 133.04 examples/s]Tokenizing train dataset:  63%|██████▎   | 5356/8564 [00:56<00:16, 193.72 examples/s]Tokenizing train dataset:  59%|█████▉    | 5079/8564 [00:56<00:22, 152.05 examples/s]Tokenizing train dataset:  63%|██████▎   | 5426/8564 [00:55<00:20, 152.47 examples/s]Tokenizing train dataset:  63%|██████▎   | 5380/8564 [00:56<00:18, 170.62 examples/s]Tokenizing train dataset:  60%|█████▉    | 5096/8564 [00:56<00:22, 151.89 examples/s]Tokenizing train dataset:  64%|██████▎   | 5453/8564 [00:55<00:18, 171.08 examples/s]Tokenizing train dataset:  60%|█████▉    | 5113/8564 [00:56<00:23, 145.29 examples/s]Tokenizing train dataset:  63%|██████▎   | 5400/8564 [00:56<00:22, 143.64 examples/s]Tokenizing train dataset:  64%|██████▍   | 5483/8564 [00:55<00:18, 168.28 examples/s]Tokenizing train dataset:  60%|█████▉    | 5130/8564 [00:56<00:24, 140.53 examples/s]Tokenizing train dataset:  64%|██████▍   | 5503/8564 [00:55<00:17, 173.91 examples/s]Tokenizing train dataset:  63%|██████▎   | 5419/8564 [00:56<00:22, 141.67 examples/s]Tokenizing train dataset:  60%|██████    | 5145/8564 [00:56<00:24, 141.44 examples/s]Tokenizing train dataset:  65%|██████▍   | 5527/8564 [00:56<00:16, 182.21 examples/s]Tokenizing train dataset:  64%|██████▎   | 5441/8564 [00:56<00:20, 149.69 examples/s]Tokenizing train dataset:  60%|██████    | 5169/8564 [00:56<00:22, 154.07 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:56<00:16, 185.43 examples/s]Tokenizing train dataset:  64%|██████▍   | 5464/8564 [00:57<00:22, 135.84 examples/s]Tokenizing train dataset:  65%|██████▌   | 5579/8564 [00:56<00:15, 188.14 examples/s]Tokenizing train dataset:  61%|██████    | 5194/8564 [00:56<00:23, 142.77 examples/s]Tokenizing train dataset:  65%|██████▌   | 5600/8564 [00:56<00:15, 192.69 examples/s]Tokenizing train dataset:  64%|██████▍   | 5480/8564 [00:57<00:23, 128.50 examples/s]Tokenizing train dataset:  61%|██████    | 5212/8564 [00:57<00:23, 144.16 examples/s]Tokenizing train dataset:  66%|██████▌   | 5621/8564 [00:56<00:15, 191.93 examples/s]Tokenizing train dataset:  64%|██████▍   | 5500/8564 [00:57<00:22, 136.67 examples/s]Tokenizing train dataset:  61%|██████    | 5227/8564 [00:57<00:24, 136.78 examples/s]Tokenizing train dataset:  66%|██████▌   | 5646/8564 [00:56<00:14, 205.59 examples/s]Tokenizing train dataset:  64%|██████▍   | 5518/8564 [00:57<00:21, 138.49 examples/s]Tokenizing train dataset:  61%|██████▏   | 5251/8564 [00:57<00:21, 153.27 examples/s]Tokenizing train dataset:  66%|██████▌   | 5669/8564 [00:56<00:13, 209.93 examples/s]Tokenizing train dataset:  65%|██████▍   | 5537/8564 [00:57<00:20, 150.18 examples/s]Tokenizing train dataset:  62%|██████▏   | 5274/8564 [00:57<00:19, 164.90 examples/s]Tokenizing train dataset:  66%|██████▋   | 5691/8564 [00:56<00:14, 199.72 examples/s]Tokenizing train dataset:  65%|██████▍   | 5562/8564 [00:57<00:19, 153.60 examples/s]Tokenizing train dataset:  67%|██████▋   | 5719/8564 [00:57<00:12, 219.63 examples/s]Tokenizing train dataset:  62%|██████▏   | 5300/8564 [00:57<00:21, 152.28 examples/s]Tokenizing train dataset:  65%|██████▌   | 5585/8564 [00:57<00:17, 168.88 examples/s]Tokenizing train dataset:  66%|██████▌   | 5613/8564 [00:57<00:15, 196.52 examples/s]Tokenizing train dataset:  67%|██████▋   | 5748/8564 [00:57<00:14, 197.79 examples/s]Tokenizing train dataset:  62%|██████▏   | 5324/8564 [00:57<00:23, 136.36 examples/s]Tokenizing train dataset:  67%|██████▋   | 5780/8564 [00:57<00:12, 219.39 examples/s]Tokenizing train dataset:  62%|██████▏   | 5347/8564 [00:57<00:21, 152.19 examples/s]Tokenizing train dataset:  66%|██████▌   | 5642/8564 [00:58<00:16, 172.55 examples/s]Tokenizing train dataset:  68%|██████▊   | 5805/8564 [00:57<00:12, 226.45 examples/s]Tokenizing train dataset:  63%|██████▎   | 5366/8564 [00:58<00:20, 158.52 examples/s]Tokenizing train dataset:  66%|██████▌   | 5661/8564 [00:58<00:18, 153.15 examples/s]Tokenizing train dataset:  68%|██████▊   | 5838/8564 [00:57<00:12, 218.01 examples/s]Tokenizing train dataset:  63%|██████▎   | 5384/8564 [00:58<00:20, 154.03 examples/s]Tokenizing train dataset:  66%|██████▋   | 5685/8564 [00:58<00:18, 154.70 examples/s]Tokenizing train dataset:  63%|██████▎   | 5404/8564 [00:58<00:20, 156.88 examples/s]Tokenizing train dataset:  68%|██████▊   | 5863/8564 [00:57<00:14, 191.57 examples/s]Tokenizing train dataset:  67%|██████▋   | 5704/8564 [00:58<00:18, 153.57 examples/s]Tokenizing train dataset:  63%|██████▎   | 5431/8564 [00:58<00:17, 177.53 examples/s]Tokenizing train dataset:  69%|██████▉   | 5888/8564 [00:57<00:15, 173.71 examples/s]Tokenizing train dataset:  64%|██████▎   | 5453/8564 [00:58<00:16, 187.28 examples/s]Tokenizing train dataset:  67%|██████▋   | 5726/8564 [00:58<00:20, 139.72 examples/s]Tokenizing train dataset:  64%|██████▍   | 5477/8564 [00:58<00:17, 176.71 examples/s]Tokenizing train dataset:  69%|██████▉   | 5915/8564 [00:58<00:16, 160.99 examples/s]Tokenizing train dataset:  67%|██████▋   | 5743/8564 [00:58<00:22, 128.10 examples/s]Tokenizing train dataset:  64%|██████▍   | 5496/8564 [00:58<00:17, 179.34 examples/s]Tokenizing train dataset:  69%|██████▉   | 5935/8564 [00:58<00:15, 164.68 examples/s]Tokenizing train dataset:  67%|██████▋   | 5765/8564 [00:59<00:19, 146.38 examples/s]Tokenizing train dataset:  64%|██████▍   | 5516/8564 [00:58<00:17, 179.12 examples/s]Tokenizing train dataset:  70%|██████▉   | 5959/8564 [00:58<00:16, 158.76 examples/s]Tokenizing train dataset:  68%|██████▊   | 5791/8564 [00:59<00:16, 170.62 examples/s]Tokenizing train dataset:  65%|██████▍   | 5538/8564 [00:59<00:19, 152.04 examples/s]Tokenizing train dataset:  68%|██████▊   | 5821/8564 [00:59<00:14, 194.64 examples/s]Tokenizing train dataset:  70%|██████▉   | 5977/8564 [00:58<00:17, 150.78 examples/s]Tokenizing train dataset:  68%|██████▊   | 5842/8564 [00:59<00:14, 189.20 examples/s]Tokenizing train dataset:  65%|██████▍   | 5559/8564 [00:59<00:23, 130.31 examples/s]Tokenizing train dataset:  65%|██████▌   | 5580/8564 [00:59<00:21, 140.50 examples/s]Tokenizing train dataset:  68%|██████▊   | 5864/8564 [00:59<00:18, 149.09 examples/s]Tokenizing train dataset:  65%|██████▌   | 5601/8564 [00:59<00:20, 146.40 examples/s]Tokenizing train dataset:  69%|██████▊   | 5887/8564 [00:59<00:19, 138.64 examples/s]Tokenizing train dataset:  66%|██████▌   | 5621/8564 [00:59<00:19, 151.93 examples/s]Tokenizing train dataset:  70%|███████   | 6002/8564 [00:59<00:32, 79.59 examples/s] Tokenizing train dataset:  69%|██████▉   | 5908/8564 [00:59<00:18, 146.74 examples/s]Tokenizing train dataset:  66%|██████▌   | 5643/8564 [00:59<00:17, 162.96 examples/s]Tokenizing train dataset:  69%|██████▉   | 5930/8564 [01:00<00:16, 155.36 examples/s]Tokenizing train dataset:  70%|███████   | 6020/8564 [00:59<00:29, 87.14 examples/s]Tokenizing train dataset:  66%|██████▌   | 5665/8564 [00:59<00:18, 159.60 examples/s]Tokenizing train dataset:  70%|███████   | 6037/8564 [00:59<00:25, 98.97 examples/s]Tokenizing train dataset:  69%|██████▉   | 5949/8564 [01:00<00:17, 153.36 examples/s]Tokenizing train dataset:  66%|██████▋   | 5691/8564 [01:00<00:17, 162.75 examples/s]Tokenizing train dataset:  71%|███████   | 6063/8564 [00:59<00:20, 123.58 examples/s]Tokenizing train dataset:  70%|██████▉   | 5970/8564 [01:00<00:18, 141.10 examples/s]Tokenizing train dataset:  67%|██████▋   | 5712/8564 [01:00<00:16, 171.18 examples/s]Tokenizing train dataset:  71%|███████   | 6081/8564 [00:59<00:19, 129.72 examples/s]Tokenizing train dataset:  67%|██████▋   | 5730/8564 [01:00<00:17, 165.63 examples/s]Tokenizing train dataset:  71%|███████   | 6100/8564 [00:59<00:17, 140.89 examples/s]Tokenizing train dataset:  67%|██████▋   | 5753/8564 [01:00<00:15, 176.41 examples/s]Tokenizing train dataset:  70%|██████▉   | 5988/8564 [01:00<00:22, 112.06 examples/s]Tokenizing train dataset:  72%|███████▏  | 6126/8564 [00:59<00:14, 162.84 examples/s]Tokenizing train dataset:  70%|███████   | 6002/8564 [01:00<00:22, 115.55 examples/s]Tokenizing train dataset:  72%|███████▏  | 6157/8564 [00:59<00:12, 191.72 examples/s]Tokenizing train dataset:  68%|██████▊   | 5783/8564 [01:00<00:14, 193.24 examples/s]Tokenizing train dataset:  72%|███████▏  | 6181/8564 [01:00<00:11, 203.64 examples/s]Tokenizing train dataset:  70%|███████   | 6019/8564 [01:00<00:20, 123.15 examples/s]Tokenizing train dataset:  68%|██████▊   | 5807/8564 [01:00<00:14, 186.97 examples/s]Tokenizing train dataset:  73%|███████▎  | 6209/8564 [01:00<00:10, 220.71 examples/s]Tokenizing train dataset:  70%|███████   | 6034/8564 [01:01<00:22, 111.69 examples/s]Tokenizing train dataset:  73%|███████▎  | 6233/8564 [01:00<00:10, 219.18 examples/s]Tokenizing train dataset:  68%|██████▊   | 5830/8564 [01:00<00:16, 163.44 examples/s]Tokenizing train dataset:  71%|███████   | 6057/8564 [01:01<00:19, 128.96 examples/s]Tokenizing train dataset:  73%|███████▎  | 6258/8564 [01:00<00:10, 226.35 examples/s]Tokenizing train dataset:  68%|██████▊   | 5851/8564 [01:01<00:18, 145.46 examples/s]Tokenizing train dataset:  71%|███████   | 6071/8564 [01:01<00:19, 127.45 examples/s]Tokenizing train dataset:  73%|███████▎  | 6292/8564 [01:00<00:11, 204.56 examples/s]Tokenizing train dataset:  69%|██████▊   | 5867/8564 [01:01<00:20, 128.64 examples/s]Tokenizing train dataset:  71%|███████   | 6089/8564 [01:01<00:21, 116.81 examples/s]Tokenizing train dataset:  74%|███████▍  | 6328/8564 [01:00<00:10, 212.19 examples/s]Tokenizing train dataset:  69%|██████▉   | 5890/8564 [01:01<00:20, 127.82 examples/s]Tokenizing train dataset:  74%|███████▍  | 6356/8564 [01:00<00:09, 225.15 examples/s]Tokenizing train dataset:  71%|███████▏  | 6110/8564 [01:01<00:22, 110.95 examples/s]Tokenizing train dataset:  69%|██████▉   | 5918/8564 [01:01<00:17, 148.63 examples/s]Tokenizing train dataset:  72%|███████▏  | 6126/8564 [01:01<00:20, 116.22 examples/s]Tokenizing train dataset:  75%|███████▍  | 6390/8564 [01:01<00:10, 198.73 examples/s]Tokenizing train dataset:  69%|██████▉   | 5941/8564 [01:01<00:15, 165.47 examples/s]Tokenizing train dataset:  72%|███████▏  | 6150/8564 [01:01<00:17, 137.01 examples/s]Tokenizing train dataset:  70%|██████▉   | 5964/8564 [01:01<00:14, 178.85 examples/s]Tokenizing train dataset:  75%|███████▍  | 6422/8564 [01:01<00:10, 195.50 examples/s]Tokenizing train dataset:  72%|███████▏  | 6167/8564 [01:02<00:17, 140.35 examples/s]Tokenizing train dataset:  75%|███████▌  | 6446/8564 [01:01<00:10, 198.69 examples/s]Tokenizing train dataset:  70%|██████▉   | 5990/8564 [01:02<00:17, 150.04 examples/s]Tokenizing train dataset:  72%|███████▏  | 6190/8564 [01:02<00:17, 133.09 examples/s]Tokenizing train dataset:  76%|███████▌  | 6471/8564 [01:01<00:11, 187.69 examples/s]Tokenizing train dataset:  70%|███████   | 6017/8564 [01:02<00:14, 174.79 examples/s]Tokenizing train dataset:  72%|███████▏  | 6207/8564 [01:02<00:17, 137.81 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [01:01<00:10, 189.94 examples/s]Tokenizing train dataset:  71%|███████   | 6040/8564 [01:02<00:15, 167.01 examples/s]Tokenizing train dataset:  73%|███████▎  | 6234/8564 [01:02<00:16, 143.49 examples/s]Tokenizing train dataset:  76%|███████▌  | 6517/8564 [01:01<00:10, 191.84 examples/s]Tokenizing train dataset:  71%|███████   | 6063/8564 [01:02<00:13, 180.97 examples/s]Tokenizing train dataset:  76%|███████▋  | 6540/8564 [01:01<00:10, 195.87 examples/s]Tokenizing train dataset:  73%|███████▎  | 6257/8564 [01:02<00:16, 137.91 examples/s]Tokenizing train dataset:  77%|███████▋  | 6560/8564 [01:01<00:10, 195.63 examples/s]Tokenizing train dataset:  71%|███████   | 6094/8564 [01:02<00:14, 174.58 examples/s]Tokenizing train dataset:  73%|███████▎  | 6280/8564 [01:02<00:16, 137.98 examples/s]Tokenizing train dataset:  71%|███████▏  | 6113/8564 [01:02<00:14, 171.59 examples/s]Tokenizing train dataset:  77%|███████▋  | 6584/8564 [01:02<00:11, 169.65 examples/s]Tokenizing train dataset:  74%|███████▎  | 6297/8564 [01:02<00:15, 143.49 examples/s]Tokenizing train dataset:  72%|███████▏  | 6135/8564 [01:02<00:14, 172.84 examples/s]Tokenizing train dataset:  74%|███████▍  | 6320/8564 [01:03<00:13, 162.59 examples/s]Tokenizing train dataset:  77%|███████▋  | 6602/8564 [01:02<00:13, 143.38 examples/s]Tokenizing train dataset:  72%|███████▏  | 6157/8564 [01:02<00:14, 170.94 examples/s]Tokenizing train dataset:  74%|███████▍  | 6344/8564 [01:03<00:12, 173.59 examples/s]Tokenizing train dataset:  72%|███████▏  | 6179/8564 [01:03<00:13, 173.91 examples/s]Tokenizing train dataset:  74%|███████▍  | 6376/8564 [01:03<00:11, 198.87 examples/s]Tokenizing train dataset:  77%|███████▋  | 6625/8564 [01:02<00:14, 132.64 examples/s]Tokenizing train dataset:  72%|███████▏  | 6206/8564 [01:03<00:14, 164.76 examples/s]Tokenizing train dataset:  78%|███████▊  | 6643/8564 [01:02<00:14, 134.16 examples/s]Tokenizing train dataset:  75%|███████▍  | 6402/8564 [01:03<00:11, 189.53 examples/s]Tokenizing train dataset:  73%|███████▎  | 6225/8564 [01:03<00:14, 162.78 examples/s]Tokenizing train dataset:  78%|███████▊  | 6658/8564 [01:02<00:14, 131.17 examples/s]Tokenizing train dataset:  75%|███████▌  | 6425/8564 [01:03<00:11, 190.02 examples/s]Tokenizing train dataset:  78%|███████▊  | 6673/8564 [01:02<00:14, 130.98 examples/s]Tokenizing train dataset:  75%|███████▌  | 6450/8564 [01:03<00:10, 202.87 examples/s]Tokenizing train dataset:  73%|███████▎  | 6253/8564 [01:03<00:15, 152.13 examples/s]Tokenizing train dataset:  78%|███████▊  | 6690/8564 [01:02<00:13, 136.03 examples/s]Tokenizing train dataset:  76%|███████▌  | 6480/8564 [01:03<00:10, 191.76 examples/s]Tokenizing train dataset:  78%|███████▊  | 6710/8564 [01:03<00:12, 149.23 examples/s]Tokenizing train dataset:  73%|███████▎  | 6277/8564 [01:03<00:15, 148.27 examples/s]Tokenizing train dataset:  76%|███████▌  | 6500/8564 [01:03<00:11, 187.51 examples/s]Tokenizing train dataset:  76%|███████▌  | 6521/8564 [01:04<00:10, 191.97 examples/s]Tokenizing train dataset:  79%|███████▊  | 6729/8564 [01:03<00:14, 129.93 examples/s]Tokenizing train dataset:  74%|███████▎  | 6302/8564 [01:03<00:16, 139.10 examples/s]Tokenizing train dataset:  76%|███████▋  | 6542/8564 [01:04<00:10, 189.46 examples/s]Tokenizing train dataset:  79%|███████▉  | 6746/8564 [01:03<00:13, 130.72 examples/s]Tokenizing train dataset:  74%|███████▍  | 6323/8564 [01:04<00:14, 150.77 examples/s]Tokenizing train dataset:  79%|███████▉  | 6767/8564 [01:03<00:12, 142.50 examples/s]Tokenizing train dataset:  77%|███████▋  | 6570/8564 [01:04<00:10, 185.48 examples/s]Tokenizing train dataset:  74%|███████▍  | 6339/8564 [01:04<00:15, 143.95 examples/s]Tokenizing train dataset:  79%|███████▉  | 6783/8564 [01:03<00:12, 144.71 examples/s]Tokenizing train dataset:  74%|███████▍  | 6360/8564 [01:04<00:14, 152.16 examples/s]Tokenizing train dataset:  77%|███████▋  | 6595/8564 [01:04<00:11, 172.06 examples/s]Tokenizing train dataset:  79%|███████▉  | 6801/8564 [01:03<00:11, 147.93 examples/s]Tokenizing train dataset:  75%|███████▍  | 6381/8564 [01:04<00:15, 142.54 examples/s]Tokenizing train dataset:  77%|███████▋  | 6618/8564 [01:04<00:11, 165.27 examples/s]Tokenizing train dataset:  80%|███████▉  | 6819/8564 [01:03<00:11, 147.26 examples/s]Tokenizing train dataset:  75%|███████▍  | 6397/8564 [01:04<00:15, 143.26 examples/s]Tokenizing train dataset:  78%|███████▊  | 6644/8564 [01:04<00:10, 183.34 examples/s]Tokenizing train dataset:  80%|███████▉  | 6834/8564 [01:04<00:12, 140.59 examples/s]Tokenizing train dataset:  78%|███████▊  | 6672/8564 [01:04<00:09, 204.82 examples/s]Tokenizing train dataset:  75%|███████▍  | 6414/8564 [01:04<00:15, 137.84 examples/s]Tokenizing train dataset:  80%|████████  | 6855/8564 [01:04<00:10, 157.64 examples/s]Tokenizing train dataset:  75%|███████▌  | 6443/8564 [01:04<00:12, 168.39 examples/s]Tokenizing train dataset:  78%|███████▊  | 6697/8564 [01:04<00:09, 194.64 examples/s]Tokenizing train dataset:  80%|████████  | 6878/8564 [01:04<00:10, 167.36 examples/s]Tokenizing train dataset:  76%|███████▌  | 6466/8564 [01:04<00:11, 179.64 examples/s]Tokenizing train dataset:  81%|████████  | 6895/8564 [01:04<00:10, 156.77 examples/s]Tokenizing train dataset:  78%|███████▊  | 6718/8564 [01:05<00:10, 175.61 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [01:05<00:12, 169.99 examples/s]Tokenizing train dataset:  81%|████████  | 6920/8564 [01:04<00:10, 151.60 examples/s]Tokenizing train dataset:  79%|███████▊  | 6743/8564 [01:05<00:11, 157.32 examples/s]Tokenizing train dataset:  76%|███████▌  | 6513/8564 [01:05<00:11, 178.20 examples/s]Tokenizing train dataset:  81%|████████  | 6944/8564 [01:04<00:10, 158.28 examples/s]Tokenizing train dataset:  79%|███████▉  | 6761/8564 [01:05<00:11, 156.35 examples/s]Tokenizing train dataset:  76%|███████▋  | 6537/8564 [01:05<00:10, 189.24 examples/s]Tokenizing train dataset:  77%|███████▋  | 6559/8564 [01:05<00:10, 191.99 examples/s]Tokenizing train dataset:  79%|███████▉  | 6782/8564 [01:05<00:12, 146.03 examples/s]Tokenizing train dataset:  81%|████████▏ | 6964/8564 [01:04<00:11, 135.31 examples/s]Tokenizing train dataset:  77%|███████▋  | 6586/8564 [01:05<00:10, 180.83 examples/s]Tokenizing train dataset:  82%|████████▏ | 6985/8564 [01:04<00:10, 148.19 examples/s]Tokenizing train dataset:  79%|███████▉  | 6806/8564 [01:05<00:12, 142.10 examples/s]Tokenizing train dataset:  77%|███████▋  | 6610/8564 [01:05<00:12, 162.06 examples/s]Tokenizing train dataset:  80%|███████▉  | 6822/8564 [01:05<00:13, 127.50 examples/s]Tokenizing train dataset:  82%|████████▏ | 7006/8564 [01:05<00:12, 122.67 examples/s]Tokenizing train dataset:  77%|███████▋  | 6632/8564 [01:05<00:11, 174.25 examples/s]Tokenizing train dataset:  80%|███████▉  | 6837/8564 [01:06<00:14, 121.68 examples/s]Tokenizing train dataset:  78%|███████▊  | 6656/8564 [01:06<00:10, 181.51 examples/s]Tokenizing train dataset:  82%|████████▏ | 7020/8564 [01:05<00:14, 106.99 examples/s]Tokenizing train dataset:  80%|███████▉  | 6850/8564 [01:06<00:15, 113.24 examples/s]Tokenizing train dataset:  82%|████████▏ | 7045/8564 [01:05<00:11, 132.03 examples/s]Tokenizing train dataset:  78%|███████▊  | 6680/8564 [01:06<00:10, 180.52 examples/s]Tokenizing train dataset:  80%|████████  | 6874/8564 [01:06<00:12, 139.33 examples/s]Tokenizing train dataset:  83%|████████▎ | 7070/8564 [01:05<00:09, 149.51 examples/s]Tokenizing train dataset:  78%|███████▊  | 6700/8564 [01:06<00:11, 160.12 examples/s]Tokenizing train dataset:  80%|████████  | 6892/8564 [01:06<00:11, 143.58 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [01:05<00:09, 148.12 examples/s]Tokenizing train dataset:  79%|███████▊  | 6727/8564 [01:06<00:10, 177.82 examples/s]Tokenizing train dataset:  81%|████████  | 6910/8564 [01:06<00:11, 148.14 examples/s]Tokenizing train dataset:  83%|████████▎ | 7114/8564 [01:05<00:08, 165.26 examples/s]Tokenizing train dataset:  79%|███████▉  | 6753/8564 [01:06<00:09, 192.76 examples/s]Tokenizing train dataset:  83%|████████▎ | 7136/8564 [01:05<00:08, 178.03 examples/s]Tokenizing train dataset:  81%|████████  | 6940/8564 [01:06<00:10, 151.66 examples/s]Tokenizing train dataset:  79%|███████▉  | 6776/8564 [01:06<00:10, 168.71 examples/s]Tokenizing train dataset:  84%|████████▎ | 7156/8564 [01:06<00:07, 181.78 examples/s]Tokenizing train dataset:  81%|████████  | 6958/8564 [01:06<00:12, 130.20 examples/s]Tokenizing train dataset:  84%|████████▍ | 7185/8564 [01:06<00:06, 202.38 examples/s]Tokenizing train dataset:  79%|███████▉  | 6801/8564 [01:06<00:11, 154.68 examples/s]Tokenizing train dataset:  84%|████████▍ | 7210/8564 [01:06<00:06, 212.99 examples/s]Tokenizing train dataset:  82%|████████▏ | 6982/8564 [01:07<00:13, 120.59 examples/s]Tokenizing train dataset:  80%|███████▉  | 6822/8564 [01:07<00:11, 147.28 examples/s]Tokenizing train dataset:  84%|████████▍ | 7235/8564 [01:06<00:07, 182.42 examples/s]Tokenizing train dataset:  82%|████████▏ | 7001/8564 [01:07<00:11, 131.35 examples/s]Tokenizing train dataset:  85%|████████▍ | 7257/8564 [01:06<00:07, 185.27 examples/s]Tokenizing train dataset:  80%|███████▉  | 6849/8564 [01:07<00:12, 134.86 examples/s]Tokenizing train dataset:  82%|████████▏ | 7017/8564 [01:07<00:13, 116.85 examples/s]Tokenizing train dataset:  85%|████████▌ | 7282/8564 [01:06<00:06, 188.42 examples/s]Tokenizing train dataset:  80%|████████  | 6868/8564 [01:07<00:12, 135.10 examples/s]Tokenizing train dataset:  82%|████████▏ | 7036/8564 [01:07<00:11, 131.53 examples/s]Tokenizing train dataset:  85%|████████▌ | 7306/8564 [01:06<00:06, 193.39 examples/s]Tokenizing train dataset:  80%|████████  | 6890/8564 [01:07<00:11, 151.63 examples/s]Tokenizing train dataset:  82%|████████▏ | 7057/8564 [01:07<00:10, 144.87 examples/s]Tokenizing train dataset:  86%|████████▌ | 7328/8564 [01:07<00:07, 173.77 examples/s]Tokenizing train dataset:  81%|████████  | 6915/8564 [01:07<00:09, 171.69 examples/s]Tokenizing train dataset:  83%|████████▎ | 7074/8564 [01:07<00:10, 144.53 examples/s]Tokenizing train dataset:  86%|████████▌ | 7354/8564 [01:07<00:06, 193.70 examples/s]Tokenizing train dataset:  83%|████████▎ | 7100/8564 [01:07<00:09, 150.03 examples/s]Tokenizing train dataset:  81%|████████  | 6944/8564 [01:07<00:09, 163.35 examples/s]Tokenizing train dataset:  86%|████████▌ | 7375/8564 [01:07<00:07, 153.28 examples/s]Tokenizing train dataset:  83%|████████▎ | 7121/8564 [01:08<00:09, 152.56 examples/s]Tokenizing train dataset:  81%|████████▏ | 6965/8564 [01:08<00:10, 149.02 examples/s]Tokenizing train dataset:  86%|████████▋ | 7394/8564 [01:07<00:07, 155.61 examples/s]Tokenizing train dataset:  83%|████████▎ | 7140/8564 [01:08<00:09, 144.80 examples/s]Tokenizing train dataset:  82%|████████▏ | 6992/8564 [01:08<00:09, 164.41 examples/s]Tokenizing train dataset:  87%|████████▋ | 7416/8564 [01:07<00:07, 153.77 examples/s]Tokenizing train dataset:  82%|████████▏ | 7011/8564 [01:08<00:09, 167.41 examples/s]Tokenizing train dataset:  84%|████████▎ | 7156/8564 [01:08<00:10, 135.50 examples/s]Tokenizing train dataset:  87%|████████▋ | 7438/8564 [01:07<00:06, 162.55 examples/s]Tokenizing train dataset:  84%|████████▍ | 7179/8564 [01:08<00:08, 156.08 examples/s]Tokenizing train dataset:  82%|████████▏ | 7035/8564 [01:08<00:09, 160.23 examples/s]Tokenizing train dataset:  87%|████████▋ | 7465/8564 [01:07<00:06, 181.49 examples/s]Tokenizing train dataset:  84%|████████▍ | 7202/8564 [01:08<00:08, 156.74 examples/s]Tokenizing train dataset:  82%|████████▏ | 7060/8564 [01:08<00:08, 167.47 examples/s]Tokenizing train dataset:  88%|████████▊ | 7496/8564 [01:07<00:05, 187.86 examples/s]Tokenizing train dataset:  83%|████████▎ | 7078/8564 [01:08<00:09, 160.97 examples/s]Tokenizing train dataset:  84%|████████▍ | 7220/8564 [01:08<00:09, 135.63 examples/s]Tokenizing train dataset:  88%|████████▊ | 7528/8564 [01:08<00:05, 193.86 examples/s]Tokenizing train dataset:  88%|████████▊ | 7552/8564 [01:08<00:04, 203.54 examples/s]Tokenizing train dataset:  83%|████████▎ | 7102/8564 [01:08<00:09, 148.84 examples/s]Tokenizing train dataset:  85%|████████▍ | 7240/8564 [01:09<00:10, 124.69 examples/s]Tokenizing train dataset:  88%|████████▊ | 7577/8564 [01:08<00:04, 207.54 examples/s]Tokenizing train dataset:  83%|████████▎ | 7120/8564 [01:08<00:09, 146.33 examples/s]Tokenizing train dataset:  85%|████████▍ | 7257/8564 [01:09<00:10, 126.86 examples/s]Tokenizing train dataset:  89%|████████▊ | 7600/8564 [01:08<00:04, 210.81 examples/s]Tokenizing train dataset:  83%|████████▎ | 7138/8564 [01:09<00:10, 141.95 examples/s]Tokenizing train dataset:  85%|████████▍ | 7278/8564 [01:09<00:09, 132.30 examples/s]Tokenizing train dataset:  89%|████████▉ | 7624/8564 [01:08<00:04, 209.50 examples/s]Tokenizing train dataset:  85%|████████▌ | 7292/8564 [01:09<00:10, 121.72 examples/s]Tokenizing train dataset:  84%|████████▎ | 7162/8564 [01:09<00:10, 133.60 examples/s]Tokenizing train dataset:  89%|████████▉ | 7654/8564 [01:08<00:04, 195.50 examples/s]Tokenizing train dataset:  85%|████████▌ | 7312/8564 [01:09<00:09, 134.56 examples/s]Tokenizing train dataset:  84%|████████▍ | 7185/8564 [01:09<00:09, 144.19 examples/s]Tokenizing train dataset:  90%|████████▉ | 7681/8564 [01:08<00:04, 185.36 examples/s]Tokenizing train dataset:  84%|████████▍ | 7208/8564 [01:09<00:08, 161.15 examples/s]Tokenizing train dataset:  86%|████████▌ | 7333/8564 [01:09<00:09, 125.29 examples/s]Tokenizing train dataset:  90%|████████▉ | 7701/8564 [01:09<00:04, 184.72 examples/s]Tokenizing train dataset:  86%|████████▌ | 7360/8564 [01:09<00:07, 151.01 examples/s]Tokenizing train dataset:  90%|█████████ | 7722/8564 [01:09<00:04, 189.64 examples/s]Tokenizing train dataset:  84%|████████▍ | 7230/8564 [01:09<00:10, 125.73 examples/s]Tokenizing train dataset:  86%|████████▌ | 7382/8564 [01:09<00:07, 159.52 examples/s]Tokenizing train dataset:  90%|█████████ | 7743/8564 [01:09<00:04, 185.96 examples/s]Tokenizing train dataset:  86%|████████▋ | 7402/8564 [01:10<00:07, 159.70 examples/s]Tokenizing train dataset:  85%|████████▍ | 7250/8564 [01:09<00:10, 127.93 examples/s]Tokenizing train dataset:  91%|█████████ | 7769/8564 [01:09<00:04, 175.20 examples/s]Tokenizing train dataset:  91%|█████████ | 7787/8564 [01:09<00:04, 168.82 examples/s]Tokenizing train dataset:  87%|████████▋ | 7428/8564 [01:10<00:07, 145.19 examples/s]Tokenizing train dataset:  85%|████████▍ | 7277/8564 [01:10<00:09, 130.91 examples/s]Tokenizing train dataset:  85%|████████▌ | 7292/8564 [01:10<00:09, 134.52 examples/s]Tokenizing train dataset:  87%|████████▋ | 7447/8564 [01:10<00:07, 147.06 examples/s]Tokenizing train dataset:  91%|█████████ | 7811/8564 [01:09<00:05, 138.80 examples/s]Tokenizing train dataset:  85%|████████▌ | 7314/8564 [01:10<00:08, 152.04 examples/s]Tokenizing train dataset:  87%|████████▋ | 7465/8564 [01:10<00:07, 148.71 examples/s]Tokenizing train dataset:  86%|████████▌ | 7336/8564 [01:10<00:07, 167.03 examples/s]Tokenizing train dataset:  91%|█████████▏| 7833/8564 [01:09<00:05, 137.17 examples/s]Tokenizing train dataset:  87%|████████▋ | 7481/8564 [01:10<00:08, 128.57 examples/s]Tokenizing train dataset:  86%|████████▌ | 7362/8564 [01:10<00:06, 180.22 examples/s]Tokenizing train dataset:  92%|█████████▏| 7854/8564 [01:10<00:04, 142.21 examples/s]Tokenizing train dataset:  86%|████████▌ | 7382/8564 [01:10<00:06, 183.51 examples/s]Tokenizing train dataset:  88%|████████▊ | 7501/8564 [01:10<00:07, 136.75 examples/s]Tokenizing train dataset:  92%|█████████▏| 7873/8564 [01:10<00:05, 135.88 examples/s]Tokenizing train dataset:  87%|████████▋ | 7413/8564 [01:10<00:06, 186.64 examples/s]Tokenizing train dataset:  88%|████████▊ | 7529/8564 [01:11<00:07, 136.01 examples/s]Tokenizing train dataset:  92%|█████████▏| 7891/8564 [01:10<00:04, 137.31 examples/s]Tokenizing train dataset:  88%|████████▊ | 7552/8564 [01:11<00:06, 150.93 examples/s]Tokenizing train dataset:  87%|████████▋ | 7446/8564 [01:11<00:06, 183.06 examples/s]Tokenizing train dataset:  92%|█████████▏| 7908/8564 [01:10<00:04, 138.42 examples/s]Tokenizing train dataset:  89%|████████▊ | 7582/8564 [01:11<00:05, 180.22 examples/s]Tokenizing train dataset:  93%|█████████▎| 7930/8564 [01:10<00:04, 150.87 examples/s]Tokenizing train dataset:  87%|████████▋ | 7468/8564 [01:11<00:06, 165.82 examples/s]Tokenizing train dataset:  93%|█████████▎| 7951/8564 [01:10<00:03, 162.52 examples/s]Tokenizing train dataset:  89%|████████▉ | 7612/8564 [01:11<00:05, 180.85 examples/s]Tokenizing train dataset:  87%|████████▋ | 7485/8564 [01:11<00:07, 141.44 examples/s]Tokenizing train dataset:  89%|████████▉ | 7637/8564 [01:11<00:04, 193.91 examples/s]Tokenizing train dataset:  93%|█████████▎| 7974/8564 [01:10<00:03, 173.29 examples/s]Tokenizing train dataset:  88%|████████▊ | 7506/8564 [01:11<00:06, 154.74 examples/s]Tokenizing train dataset:  93%|█████████▎| 8001/8564 [01:10<00:02, 196.69 examples/s]Tokenizing train dataset:  88%|████████▊ | 7533/8564 [01:11<00:05, 179.06 examples/s]Tokenizing train dataset:  94%|█████████▎| 8024/8564 [01:11<00:02, 196.84 examples/s]Tokenizing train dataset:  89%|████████▉ | 7660/8564 [01:11<00:05, 153.84 examples/s]Tokenizing train dataset:  88%|████████▊ | 7553/8564 [01:11<00:05, 177.97 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:11<00:02, 198.94 examples/s]Tokenizing train dataset:  89%|████████▊ | 7583/8564 [01:11<00:04, 207.00 examples/s]Tokenizing train dataset:  90%|████████▉ | 7680/8564 [01:12<00:06, 135.80 examples/s]Tokenizing train dataset:  94%|█████████▍| 8068/8564 [01:11<00:02, 194.79 examples/s]Tokenizing train dataset:  90%|████████▉ | 7701/8564 [01:12<00:06, 137.06 examples/s]Tokenizing train dataset:  89%|████████▉ | 7613/8564 [01:12<00:04, 197.59 examples/s]Tokenizing train dataset:  95%|█████████▍| 8096/8564 [01:11<00:02, 184.20 examples/s]Tokenizing train dataset:  89%|████████▉ | 7634/8564 [01:12<00:04, 196.17 examples/s]Tokenizing train dataset:  90%|█████████ | 7717/8564 [01:12<00:06, 137.61 examples/s]Tokenizing train dataset:  95%|█████████▍| 8115/8564 [01:11<00:02, 183.40 examples/s]Tokenizing train dataset:  89%|████████▉ | 7660/8564 [01:12<00:04, 185.89 examples/s]Tokenizing train dataset:  90%|█████████ | 7739/8564 [01:12<00:06, 130.85 examples/s]Tokenizing train dataset:  95%|█████████▌| 8144/8564 [01:11<00:02, 183.91 examples/s]Tokenizing train dataset:  90%|████████▉ | 7680/8564 [01:12<00:04, 182.94 examples/s]Tokenizing train dataset:  95%|█████████▌| 8170/8564 [01:11<00:02, 194.91 examples/s]Tokenizing train dataset:  91%|█████████ | 7753/8564 [01:12<00:06, 125.67 examples/s]Tokenizing train dataset:  90%|████████▉ | 7701/8564 [01:12<00:04, 187.36 examples/s]Tokenizing train dataset:  96%|█████████▌| 8194/8564 [01:11<00:01, 204.43 examples/s]Tokenizing train dataset:  91%|█████████ | 7766/8564 [01:12<00:06, 116.55 examples/s]Tokenizing train dataset:  90%|█████████ | 7724/8564 [01:12<00:04, 187.85 examples/s]Tokenizing train dataset:  96%|█████████▌| 8220/8564 [01:12<00:01, 190.37 examples/s]Tokenizing train dataset:  91%|█████████ | 7780/8564 [01:12<00:06, 116.81 examples/s]Tokenizing train dataset:  91%|█████████ | 7753/8564 [01:12<00:04, 186.87 examples/s]Tokenizing train dataset:  96%|█████████▋| 8244/8564 [01:12<00:01, 201.98 examples/s]Tokenizing train dataset:  91%|█████████ | 7794/8564 [01:12<00:06, 114.74 examples/s]Tokenizing train dataset:  97%|█████████▋| 8272/8564 [01:12<00:01, 221.34 examples/s]Tokenizing train dataset:  91%|█████████ | 7807/8564 [01:13<00:06, 115.83 examples/s]Tokenizing train dataset:  91%|█████████ | 7781/8564 [01:12<00:04, 178.61 examples/s]Tokenizing train dataset:  97%|█████████▋| 8299/8564 [01:12<00:01, 222.22 examples/s]Tokenizing train dataset:  91%|█████████▏| 7820/8564 [01:13<00:06, 112.50 examples/s]Tokenizing train dataset:  91%|█████████ | 7808/8564 [01:13<00:04, 177.39 examples/s]Tokenizing train dataset:  92%|█████████▏| 7841/8564 [01:13<00:05, 135.48 examples/s]Tokenizing train dataset:  97%|█████████▋| 8330/8564 [01:12<00:01, 213.37 examples/s]Tokenizing train dataset:  92%|█████████▏| 7860/8564 [01:13<00:05, 139.27 examples/s]Tokenizing train dataset:  91%|█████████▏| 7830/8564 [01:13<00:05, 144.98 examples/s]Tokenizing train dataset:  98%|█████████▊| 8354/8564 [01:12<00:01, 185.96 examples/s]Tokenizing train dataset:  92%|█████████▏| 7877/8564 [01:13<00:05, 130.91 examples/s]Tokenizing train dataset:  92%|█████████▏| 7855/8564 [01:13<00:04, 154.36 examples/s]Tokenizing train dataset:  98%|█████████▊| 8386/8564 [01:12<00:00, 188.58 examples/s]Tokenizing train dataset:  92%|█████████▏| 7896/8564 [01:13<00:04, 139.94 examples/s]Tokenizing train dataset:  92%|█████████▏| 7877/8564 [01:13<00:04, 144.03 examples/s]Tokenizing train dataset:  98%|█████████▊| 8417/8564 [01:13<00:00, 192.38 examples/s]Tokenizing train dataset:  92%|█████████▏| 7916/8564 [01:13<00:04, 133.96 examples/s]Tokenizing train dataset:  99%|█████████▊| 8439/8564 [01:13<00:00, 189.30 examples/s]Tokenizing train dataset:  92%|█████████▏| 7899/8564 [01:13<00:04, 143.55 examples/s]Tokenizing train dataset:  93%|█████████▎| 7931/8564 [01:13<00:04, 128.36 examples/s]Tokenizing train dataset:  99%|█████████▉| 8474/8564 [01:13<00:00, 201.04 examples/s]Tokenizing train dataset:  92%|█████████▏| 7916/8564 [01:13<00:04, 134.72 examples/s]Tokenizing train dataset:  93%|█████████▎| 7950/8564 [01:14<00:04, 129.53 examples/s]Tokenizing train dataset:  93%|█████████▎| 7930/8564 [01:14<00:04, 132.75 examples/s]Tokenizing train dataset:  99%|█████████▉| 8502/8564 [01:13<00:00, 189.82 examples/s]Tokenizing train dataset:  93%|█████████▎| 7970/8564 [01:14<00:04, 120.92 examples/s]Tokenizing train dataset:  93%|█████████▎| 7950/8564 [01:14<00:04, 136.23 examples/s]Tokenizing train dataset: 100%|█████████▉| 8532/8564 [01:13<00:00, 212.50 examples/s]Tokenizing train dataset:  93%|█████████▎| 7987/8564 [01:14<00:04, 126.41 examples/s]Tokenizing train dataset:  93%|█████████▎| 7973/8564 [01:14<00:03, 151.62 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:13<00:00, 211.36 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:13<00:00, 116.11 examples/s]
Tokenizing train dataset:  93%|█████████▎| 7999/8564 [01:14<00:03, 177.02 examples/s]Tokenizing train dataset:  94%|█████████▎| 8009/8564 [01:14<00:04, 132.82 examples/s]Tokenizing train dataset:  94%|█████████▎| 8021/8564 [01:14<00:02, 182.05 examples/s]Tokenizing train dataset:  94%|█████████▍| 8030/8564 [01:14<00:04, 127.96 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:14<00:02, 187.22 examples/s]Tokenizing train dataset:  94%|█████████▍| 8070/8564 [01:14<00:02, 193.00 examples/s]Tokenizing train dataset:  94%|█████████▍| 8048/8564 [01:14<00:04, 123.49 examples/s]Tokenizing train dataset:  94%|█████████▍| 8068/8564 [01:15<00:03, 136.98 examples/s]Tokenizing train dataset:  94%|█████████▍| 8091/8564 [01:14<00:02, 177.33 examples/s]Tokenizing train dataset:  94%|█████████▍| 8089/8564 [01:15<00:03, 151.07 examples/s]Tokenizing train dataset:  95%|█████████▍| 8109/8564 [01:15<00:02, 156.83 examples/s]Tokenizing train dataset:  95%|█████████▍| 8117/8564 [01:15<00:02, 149.28 examples/s]Tokenizing train dataset:  95%|█████████▍| 8131/8564 [01:15<00:02, 171.01 examples/s]Tokenizing train dataset:  95%|█████████▌| 8139/8564 [01:15<00:02, 142.69 examples/s]Tokenizing train dataset:  95%|█████████▌| 8156/8564 [01:15<00:02, 174.47 examples/s]Tokenizing train dataset:  95%|█████████▌| 8161/8564 [01:15<00:02, 157.41 examples/s]Tokenizing train dataset:  96%|█████████▌| 8180/8564 [01:15<00:02, 165.51 examples/s]Tokenizing train dataset:  96%|█████████▌| 8192/8564 [01:15<00:01, 187.44 examples/s]Tokenizing train dataset:  96%|█████████▌| 8213/8564 [01:15<00:01, 186.72 examples/s]Tokenizing train dataset:  96%|█████████▌| 8204/8564 [01:15<00:02, 154.17 examples/s]Tokenizing train dataset:  96%|█████████▌| 8240/8564 [01:15<00:01, 201.63 examples/s]Tokenizing train dataset:  96%|█████████▌| 8222/8564 [01:15<00:02, 156.45 examples/s]Tokenizing train dataset:  96%|█████████▋| 8264/8564 [01:15<00:01, 202.49 examples/s]Tokenizing train dataset:  96%|█████████▋| 8245/8564 [01:16<00:01, 171.35 examples/s]Tokenizing train dataset:  97%|█████████▋| 8294/8564 [01:15<00:01, 224.33 examples/s]Tokenizing train dataset:  97%|█████████▋| 8271/8564 [01:16<00:01, 190.38 examples/s]Tokenizing train dataset:  97%|█████████▋| 8297/8564 [01:16<00:01, 204.60 examples/s]Tokenizing train dataset:  97%|█████████▋| 8329/8564 [01:16<00:01, 209.64 examples/s]Tokenizing train dataset:  97%|█████████▋| 8325/8564 [01:16<00:01, 216.67 examples/s]Tokenizing train dataset:  98%|█████████▊| 8352/8564 [01:16<00:01, 193.59 examples/s]Tokenizing train dataset:  98%|█████████▊| 8354/8564 [01:16<00:01, 162.04 examples/s]Tokenizing train dataset:  98%|█████████▊| 8384/8564 [01:16<00:00, 194.37 examples/s]Tokenizing train dataset:  98%|█████████▊| 8375/8564 [01:16<00:01, 151.90 examples/s]Tokenizing train dataset:  98%|█████████▊| 8392/8564 [01:16<00:01, 148.14 examples/s]Tokenizing train dataset:  98%|█████████▊| 8418/8564 [01:16<00:00, 195.96 examples/s]Tokenizing train dataset:  98%|█████████▊| 8417/8564 [01:16<00:00, 148.65 examples/s]Tokenizing train dataset:  99%|█████████▊| 8446/8564 [01:17<00:00, 190.99 examples/s]Tokenizing train dataset:  99%|█████████▊| 8436/8564 [01:17<00:00, 139.49 examples/s]Tokenizing train dataset:  99%|█████████▉| 8485/8564 [01:17<00:00, 183.58 examples/s]Tokenizing train dataset:  99%|█████████▊| 8452/8564 [01:17<00:00, 136.30 examples/s]Tokenizing train dataset:  99%|█████████▉| 8475/8564 [01:17<00:00, 152.57 examples/s]Tokenizing train dataset:  99%|█████████▉| 8507/8564 [01:17<00:00, 161.37 examples/s]Tokenizing train dataset: 100%|█████████▉| 8530/8564 [01:17<00:00, 173.50 examples/s]Tokenizing train dataset:  99%|█████████▉| 8494/8564 [01:17<00:00, 131.52 examples/s]Tokenizing train dataset:  99%|█████████▉| 8517/8564 [01:17<00:00, 151.92 examples/s]Tokenizing train dataset: 100%|█████████▉| 8558/8564 [01:17<00:00, 167.62 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:17<00:00, 110.08 examples/s]
Tokenizing train dataset: 100%|█████████▉| 8534/8564 [01:17<00:00, 144.37 examples/s]Tokenizing train dataset: 100%|█████████▉| 8557/8564 [01:17<00:00, 146.39 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:17<00:00, 109.89 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  25%|██▌       | 241/953 [00:00<00:00, 2376.48 examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5136.26 examples/s]Extracting prompt in eval dataset:  47%|████▋     | 444/953 [00:00<00:00, 4404.70 examples/s]Extracting prompt in eval dataset:  78%|███████▊  | 744/953 [00:00<00:00, 3762.31 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4089.17 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3935.52 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3663.99 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3719.02 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  49%|████▉     | 470/953 [00:00<00:00, 4397.14 examples/s]Applying chat template to eval dataset: 100%|█████████▉| 951/953 [00:00<00:00, 4630.85 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4329.26 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  47%|████▋     | 450/953 [00:00<00:00, 4118.22 examples/s]Applying chat template to eval dataset:  46%|████▌     | 440/953 [00:00<00:00, 4043.28 examples/s]Applying chat template to eval dataset:  92%|█████████▏| 881/953 [00:00<00:00, 3905.67 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4058.40 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4002.00 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3978.41 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   2%|▏         | 22/953 [00:00<00:05, 183.44 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   5%|▍         | 45/953 [00:00<00:07, 122.77 examples/s]Tokenizing eval dataset:   2%|▏         | 22/953 [00:00<00:04, 213.18 examples/s]Tokenizing eval dataset:   6%|▌         | 59/953 [00:00<00:08, 99.86 examples/s] Tokenizing eval dataset:   5%|▌         | 50/953 [00:00<00:04, 185.10 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   8%|▊         | 73/953 [00:00<00:09, 95.36 examples/s]Tokenizing eval dataset:   1%|          | 10/953 [00:00<00:10, 89.28 examples/s]Tokenizing eval dataset:   8%|▊         | 76/953 [00:00<00:04, 176.57 examples/s]Tokenizing eval dataset:   9%|▉         | 86/953 [00:00<00:08, 98.63 examples/s]Tokenizing eval dataset:  10%|▉         | 94/953 [00:00<00:05, 171.48 examples/s]Tokenizing eval dataset:   3%|▎         | 24/953 [00:00<00:10, 89.15 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:01<00:09, 89.98 examples/s]Tokenizing eval dataset:   4%|▍         | 36/953 [00:00<00:09, 91.76 examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:00<00:06, 132.49 examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:01<00:07, 104.85 examples/s]Tokenizing eval dataset:   5%|▍         | 46/953 [00:00<00:10, 83.99 examples/s]Tokenizing eval dataset:  14%|█▍        | 135/953 [00:00<00:05, 142.62 examples/s]Tokenizing eval dataset:  14%|█▎        | 131/953 [00:01<00:08, 100.16 examples/s]Tokenizing eval dataset:   6%|▌         | 58/953 [00:00<00:11, 76.76 examples/s]Tokenizing eval dataset:  15%|█▌        | 145/953 [00:01<00:07, 107.69 examples/s]Tokenizing eval dataset:  16%|█▌        | 151/953 [00:01<00:07, 113.85 examples/s]Tokenizing eval dataset:   8%|▊         | 74/953 [00:00<00:09, 96.33 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:01<00:06, 113.98 examples/s]Tokenizing eval dataset:   9%|▉         | 90/953 [00:00<00:07, 112.04 examples/s]Tokenizing eval dataset:  17%|█▋        | 165/953 [00:01<00:08, 97.09 examples/s] Tokenizing eval dataset:  11%|█▏        | 108/953 [00:01<00:06, 129.69 examples/s]Tokenizing eval dataset:  18%|█▊        | 172/953 [00:01<00:08, 95.05 examples/s] Tokenizing eval dataset:  19%|█▉        | 180/953 [00:01<00:08, 95.60 examples/s]Tokenizing eval dataset:  13%|█▎        | 123/953 [00:01<00:07, 108.22 examples/s]Tokenizing eval dataset:  20%|█▉        | 187/953 [00:01<00:08, 89.08 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:01<00:06, 117.64 examples/s]Tokenizing eval dataset:  21%|██        | 196/953 [00:01<00:08, 92.11 examples/s]Tokenizing eval dataset:  21%|██        | 200/953 [00:02<00:08, 85.77 examples/s]Tokenizing eval dataset:  16%|█▋        | 157/953 [00:01<00:06, 127.99 examples/s]Tokenizing eval dataset:  22%|██▏       | 207/953 [00:01<00:08, 90.54 examples/s]Tokenizing eval dataset:  22%|██▏       | 210/953 [00:02<00:08, 83.16 examples/s]Tokenizing eval dataset:  18%|█▊        | 174/953 [00:01<00:05, 134.26 examples/s]Tokenizing eval dataset:  23%|██▎       | 219/953 [00:01<00:07, 92.98 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:02<00:08, 91.08 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:02<00:04, 144.45 examples/s]Tokenizing eval dataset:  20%|██        | 191/953 [00:01<00:06, 121.62 examples/s]Tokenizing eval dataset:  25%|██▌       | 242/953 [00:02<00:06, 114.10 examples/s]Tokenizing eval dataset:  22%|██▏       | 207/953 [00:01<00:05, 130.04 examples/s]Tokenizing eval dataset:  30%|███       | 289/953 [00:02<00:03, 188.41 examples/s]Tokenizing eval dataset:  29%|██▊       | 273/953 [00:02<00:04, 154.20 examples/s]Tokenizing eval dataset:  24%|██▎       | 225/953 [00:01<00:05, 124.97 examples/s]Tokenizing eval dataset:  33%|███▎      | 311/953 [00:02<00:03, 209.51 examples/s]Tokenizing eval dataset:  33%|███▎      | 317/953 [00:02<00:03, 187.39 examples/s]Tokenizing eval dataset:  25%|██▌       | 243/953 [00:02<00:05, 136.50 examples/s]Tokenizing eval dataset:  37%|███▋      | 354/953 [00:02<00:02, 230.58 examples/s]Tokenizing eval dataset:  36%|███▌      | 342/953 [00:02<00:03, 202.86 examples/s]Tokenizing eval dataset:  28%|██▊       | 265/953 [00:02<00:04, 156.67 examples/s]Tokenizing eval dataset:  41%|████      | 387/953 [00:02<00:02, 254.35 examples/s]Tokenizing eval dataset:  31%|███       | 291/953 [00:02<00:03, 183.40 examples/s]Tokenizing eval dataset:  40%|███▉      | 381/953 [00:02<00:02, 211.15 examples/s]Tokenizing eval dataset:  45%|████▌     | 430/953 [00:02<00:02, 258.35 examples/s]Tokenizing eval dataset:  43%|████▎     | 408/953 [00:03<00:02, 216.52 examples/s]Tokenizing eval dataset:  34%|███▍      | 322/953 [00:02<00:03, 189.75 examples/s]Tokenizing eval dataset:  49%|████▉     | 470/953 [00:02<00:01, 288.40 examples/s]Tokenizing eval dataset:  45%|████▌     | 433/953 [00:03<00:02, 216.46 examples/s]Tokenizing eval dataset:  36%|███▌      | 344/953 [00:02<00:03, 188.85 examples/s]Tokenizing eval dataset:  53%|█████▎    | 508/953 [00:02<00:01, 307.80 examples/s]Tokenizing eval dataset:  48%|████▊     | 461/953 [00:03<00:02, 229.73 examples/s]Tokenizing eval dataset:  39%|███▊      | 369/953 [00:02<00:03, 178.44 examples/s]Tokenizing eval dataset:  58%|█████▊    | 550/953 [00:03<00:01, 276.72 examples/s]Tokenizing eval dataset:  52%|█████▏    | 494/953 [00:03<00:01, 249.45 examples/s]Tokenizing eval dataset:  41%|████      | 388/953 [00:02<00:03, 179.68 examples/s]Tokenizing eval dataset:  56%|█████▋    | 537/953 [00:03<00:01, 295.94 examples/s]Tokenizing eval dataset:  43%|████▎     | 408/953 [00:02<00:03, 178.78 examples/s]Tokenizing eval dataset:  61%|██████    | 583/953 [00:03<00:01, 334.79 examples/s]Tokenizing eval dataset:  62%|██████▏   | 590/953 [00:03<00:01, 234.03 examples/s]Tokenizing eval dataset:  46%|████▌     | 440/953 [00:03<00:02, 210.16 examples/s]Tokenizing eval dataset:  65%|██████▍   | 616/953 [00:03<00:01, 239.25 examples/s]Tokenizing eval dataset:  65%|██████▌   | 620/953 [00:03<00:01, 282.04 examples/s]Tokenizing eval dataset:  50%|█████     | 479/953 [00:03<00:01, 252.75 examples/s]Tokenizing eval dataset:  67%|██████▋   | 643/953 [00:03<00:01, 240.75 examples/s]Tokenizing eval dataset:  53%|█████▎    | 507/953 [00:03<00:01, 239.34 examples/s]Tokenizing eval dataset:  71%|███████   | 672/953 [00:03<00:01, 250.00 examples/s]Tokenizing eval dataset:  69%|██████▉   | 662/953 [00:03<00:01, 272.48 examples/s]Tokenizing eval dataset:  56%|█████▌    | 534/953 [00:03<00:01, 239.54 examples/s]Tokenizing eval dataset:  73%|███████▎  | 691/953 [00:04<00:00, 272.15 examples/s]Tokenizing eval dataset:  74%|███████▍  | 707/953 [00:03<00:01, 231.20 examples/s]Tokenizing eval dataset:  59%|█████▉    | 561/953 [00:03<00:01, 244.24 examples/s]Tokenizing eval dataset:  76%|███████▌  | 726/953 [00:04<00:00, 283.53 examples/s]Tokenizing eval dataset:  77%|███████▋  | 735/953 [00:03<00:01, 202.01 examples/s]Tokenizing eval dataset:  63%|██████▎   | 598/953 [00:03<00:01, 236.57 examples/s]Tokenizing eval dataset:  80%|███████▉  | 761/953 [00:04<00:00, 250.75 examples/s]Tokenizing eval dataset:  81%|████████  | 774/953 [00:04<00:00, 237.56 examples/s]Tokenizing eval dataset:  66%|██████▌   | 630/953 [00:03<00:01, 218.20 examples/s]Tokenizing eval dataset:  84%|████████▍ | 800/953 [00:04<00:00, 240.80 examples/s]Tokenizing eval dataset:  84%|████████▎ | 796/953 [00:04<00:00, 203.45 examples/s]Tokenizing eval dataset:  87%|████████▋ | 832/953 [00:04<00:00, 255.21 examples/s]Tokenizing eval dataset:  69%|██████▉   | 660/953 [00:03<00:01, 211.41 examples/s]Tokenizing eval dataset:  91%|█████████ | 863/953 [00:04<00:00, 261.11 examples/s]Tokenizing eval dataset:  72%|███████▏  | 683/953 [00:04<00:01, 209.65 examples/s]Tokenizing eval dataset:  86%|████████▋ | 823/953 [00:04<00:00, 194.54 examples/s]Tokenizing eval dataset:  95%|█████████▍| 901/953 [00:04<00:00, 285.06 examples/s]Tokenizing eval dataset:  74%|███████▍  | 707/953 [00:04<00:01, 190.43 examples/s]Tokenizing eval dataset:  98%|█████████▊| 936/953 [00:04<00:00, 297.32 examples/s]Tokenizing eval dataset:  89%|████████▉ | 851/953 [00:04<00:00, 170.80 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:04<00:00, 204.55 examples/s]
Tokenizing eval dataset:  77%|███████▋  | 733/953 [00:04<00:01, 179.15 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  92%|█████████▏| 878/953 [00:05<00:00, 163.77 examples/s]Tokenizing eval dataset:  80%|███████▉  | 762/953 [00:04<00:01, 175.64 examples/s]Tokenizing eval dataset:  95%|█████████▍| 902/953 [00:05<00:00, 176.06 examples/s]Tokenizing eval dataset:  83%|████████▎ | 795/953 [00:04<00:00, 208.24 examples/s]Tokenizing eval dataset:  97%|█████████▋| 926/953 [00:05<00:00, 187.21 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:04<00:00, 236.24 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 174.69 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  90%|█████████ | 859/953 [00:04<00:00, 244.48 examples/s]Tokenizing eval dataset:  93%|█████████▎| 890/953 [00:05<00:00, 260.11 examples/s]Tokenizing eval dataset:  97%|█████████▋| 920/953 [00:05<00:00, 270.18 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 182.66 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 7.326267957687378 seconds
Time to load cpu_adam op: 7.392192840576172 seconds
Time to load cpu_adam op: 7.394996404647827 seconds
Time to load cpu_adam op: 7.691149950027466 seconds
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
[rank7]:[E530 22:19:13.067030240 ProcessGroupNCCL.cpp:552] [Rank 7] Collective WorkNCCL(SeqNum=2578, OpType=_ALLGATHER_BASE, NumelIn=28672, NumelOut=229376, Timeout(ms)=1800000) raised the following async exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgressOpt: Call to recv from 10.210.4.7<57827> failed : Broken pipe
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fed5516c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7fed034211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7fed0342964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7fed0342b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7fed0342c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7fed5589d5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7fed57745ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7fed577d7a40 in /lib/x86_64-linux-gnu/libc.so.6)

[rank7]:[E530 22:19:13.476877071 ProcessGroupNCCL.cpp:2168] [PG ID 0 PG GUID 0(default_pg) Rank 7]  failure detected by watchdog at work sequence id: 2578 PG status: last enqueued work: 2578, last completed work: 2577
[rank7]:[E530 22:19:13.476913982 ProcessGroupNCCL.cpp:667] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.
W0530 22:19:12.446000 814941 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 815013 closing signal SIGTERM
W0530 22:19:15.375000 814941 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 815014 closing signal SIGTERM
W0530 22:19:15.376000 814941 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 815015 closing signal SIGTERM
E0530 22:19:18.680000 814941 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -9) local_rank: 0 (pid: 815012) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1182, in launch_command
    deepspeed_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 861, in deepspeed_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
train.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-30_22:19:12
  host      : pm5-nod90.vega.pri
  rank      : 4 (local_rank: 0)
  exitcode  : -9 (pid: 815012)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 815012
=======================================================
slurmstepd: error: Detected 1 oom_kill event in StepId=62067775.0. Some of the step tasks have been OOM Killed.
