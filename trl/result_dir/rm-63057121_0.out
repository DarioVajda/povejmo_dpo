cpu-bind=MASK - gn54, task  0  0 [1846079]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 4
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn54
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 4     --machine_rank 0     --main_process_ip gn54     --main_process_port 29500     --num_processes 16     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_63057121     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=1e-7 --total_epochs=3 --beta=0.1
-------------------------------------------
[2025-06-12 00:54:45,495] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0612 00:54:47.319000 1846129 torch/distributed/run.py:792] 
W0612 00:54:47.319000 1846129 torch/distributed/run.py:792] *****************************************
W0612 00:54:47.319000 1846129 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0612 00:54:47.319000 1846129 torch/distributed/run.py:792] *****************************************
[2025-06-12 00:54:59,020] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 00:54:59,071] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 00:54:59,079] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 00:54:59,087] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[load_data.py]: Training data of type 'bad_lang_examples':    5343
[load_data.py]: Training data of type 'short_examples':       699
[load_data.py]: Training data of type 'choose_examples':      13379
[load_data.py]: Training data of type 'bad_format_examples':  4806
[load_data.py]: Number of training examples: 24227
[load_data.py]: Number of validation examples: 953
Namespace(rank=64, learning_rate=1e-07, total_epochs=3, beta=0.1)
1e-07
World size: 16
Setting gradient accumulation steps to: 1
Namespace(rank=64, learning_rate=1e-07, total_epochs=3, beta=0.1)
1e-07
Namespace(rank=64, learning_rate=1e-07, total_epochs=3, beta=0.1)
1e-07
Namespace(rank=64, learning_rate=1e-07, total_epochs=3, beta=0.1)
1e-07
Created datasets
Train dataset size: 24227
Validation dataset size: 953
Steps per epoch: 1514
Evaluate each 504 steps
[2025-06-12 00:55:03,939] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 00:55:03,939] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-06-12 00:55:03,952] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 00:55:03,956] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 00:55:03,966] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:08, 22.98s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:10, 23.36s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:10, 23.36s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:10, 23.36s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:48<00:48, 24.41s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:48<00:49, 24.56s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:48<00:49, 24.55s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:48<00:49, 24.55s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:25, 25.06s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 25.00s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.84s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.78s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.85s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.85s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.85s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Loaded tokenizer
[rank2]:[W612 00:56:40.073931564 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s][rank1]:[W612 00:56:40.098419846 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W612 00:56:40.147262418 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   2%|▏         | 531/24227 [00:00<00:04, 5248.77 examples/s]Extracting prompt in train dataset:   4%|▍         | 1070/24227 [00:00<00:04, 5329.00 examples/s]Extracting prompt in train dataset:   7%|▋         | 1612/24227 [00:00<00:04, 5365.58 examples/s]Extracting prompt in train dataset:   9%|▉         | 2170/24227 [00:00<00:04, 5433.42 examples/s]Extracting prompt in train dataset:  11%|█▏        | 2730/24227 [00:00<00:03, 5480.45 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3541/24227 [00:00<00:03, 5431.58 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4103/24227 [00:00<00:03, 5486.00 examples/s]Extracting prompt in train dataset:  19%|█▉        | 4663/24227 [00:00<00:03, 5519.17 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5220/24227 [00:00<00:03, 5530.98 examples/s]Extracting prompt in train dataset:  25%|██▍       | 5982/24227 [00:01<00:03, 5345.30 examples/s]Extracting prompt in train dataset:  27%|██▋       | 6559/24227 [00:01<00:03, 5446.20 examples/s]Extracting prompt in train dataset:  29%|██▉       | 7129/24227 [00:01<00:03, 5510.23 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7700/24227 [00:01<00:02, 5545.07 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8284/24227 [00:01<00:02, 5627.93 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8870/24227 [00:01<00:02, 5683.44 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9454/24227 [00:01<00:02, 5728.77 examples/s]Extracting prompt in train dataset:  41%|████▏     | 10039/24227 [00:01<00:02, 5762.70 examples/s]Extracting prompt in train dataset:  45%|████▍     | 10900/24227 [00:01<00:02, 5724.00 examples/s]Extracting prompt in train dataset:  49%|████▊     | 11757/24227 [00:02<00:02, 5713.75 examples/s]Extracting prompt in train dataset:  51%|█████     | 12334/24227 [00:02<00:02, 5727.11 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12920/24227 [00:02<00:01, 5747.88 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 13501/24227 [00:02<00:01, 5762.62 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 14085/24227 [00:02<00:01, 5783.63 examples/s]Extracting prompt in train dataset:  61%|██████    | 14670/24227 [00:02<00:01, 5785.43 examples/s]Extracting prompt in train dataset:  64%|██████▎   | 15390/24227 [00:02<00:01, 5373.78 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 15970/24227 [00:02<00:01, 5458.80 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 16540/24227 [00:02<00:01, 5518.68 examples/s]Extracting prompt in train dataset:  71%|███████   | 17126/24227 [00:03<00:01, 5613.03 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17710/24227 [00:03<00:01, 5662.59 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 18295/24227 [00:03<00:01, 5714.11 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 18880/24227 [00:03<00:00, 5741.78 examples/s]Extracting prompt in train dataset:  80%|████████  | 19468/24227 [00:03<00:00, 5781.49 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 20060/24227 [00:03<00:00, 5813.96 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 20660/24227 [00:03<00:00, 5845.29 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 21260/24227 [00:03<00:00, 5870.12 examples/s]Extracting prompt in train dataset:  90%|█████████ | 21860/24227 [00:03<00:00, 5887.40 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 22460/24227 [00:03<00:00, 5899.27 examples/s]Extracting prompt in train dataset:  95%|█████████▌| 23060/24227 [00:04<00:00, 5907.22 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 23660/24227 [00:04<00:00, 5912.22 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:04<00:00, 5625.56 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 288/24227 [00:00<00:08, 2855.94 examples/s]Applying chat template to train dataset:   2%|▏         | 600/24227 [00:00<00:07, 2995.76 examples/s]Applying chat template to train dataset:   4%|▍         | 910/24227 [00:00<00:07, 3030.13 examples/s]Applying chat template to train dataset:   5%|▌         | 1226/24227 [00:00<00:07, 3078.56 examples/s]Applying chat template to train dataset:   6%|▋         | 1536/24227 [00:00<00:07, 3083.31 examples/s]Applying chat template to train dataset:   8%|▊         | 1850/24227 [00:00<00:07, 3101.05 examples/s]Applying chat template to train dataset:   9%|▉         | 2166/24227 [00:00<00:07, 3118.61 examples/s]Applying chat template to train dataset:  10%|█         | 2481/24227 [00:00<00:06, 3124.02 examples/s]Applying chat template to train dataset:  12%|█▏        | 2796/24227 [00:00<00:06, 3130.25 examples/s]Applying chat template to train dataset:  13%|█▎        | 3247/24227 [00:01<00:06, 3075.94 examples/s]Applying chat template to train dataset:  15%|█▍        | 3560/24227 [00:01<00:06, 3084.26 examples/s]Applying chat template to train dataset:  16%|█▌        | 3875/24227 [00:01<00:06, 3101.58 examples/s]Applying chat template to train dataset:  17%|█▋        | 4190/24227 [00:01<00:06, 3109.76 examples/s]Applying chat template to train dataset:  19%|█▊        | 4504/24227 [00:01<00:06, 3116.91 examples/s]Applying chat template to train dataset:  20%|█▉        | 4819/24227 [00:01<00:06, 3123.05 examples/s]Applying chat template to train dataset:  21%|██        | 5132/24227 [00:01<00:06, 3121.44 examples/s]Applying chat template to train dataset:  22%|██▏       | 5448/24227 [00:01<00:06, 3125.65 examples/s]Applying chat template to train dataset:  24%|██▍       | 5880/24227 [00:01<00:06, 3017.16 examples/s]Applying chat template to train dataset:  26%|██▌       | 6196/24227 [00:02<00:05, 3054.10 examples/s]Applying chat template to train dataset:  27%|██▋       | 6511/24227 [00:02<00:05, 3079.94 examples/s]Applying chat template to train dataset:  28%|██▊       | 6830/24227 [00:02<00:05, 3101.08 examples/s]Applying chat template to train dataset:  30%|██▉       | 7147/24227 [00:02<00:05, 3120.04 examples/s]Applying chat template to train dataset:  31%|███       | 7462/24227 [00:02<00:05, 3127.13 examples/s]Applying chat template to train dataset:  32%|███▏      | 7781/24227 [00:02<00:05, 3139.85 examples/s]Applying chat template to train dataset:  33%|███▎      | 8104/24227 [00:02<00:05, 3164.25 examples/s]Applying chat template to train dataset:  35%|███▍      | 8429/24227 [00:02<00:04, 3185.91 examples/s]Applying chat template to train dataset:  36%|███▌      | 8753/24227 [00:02<00:04, 3197.52 examples/s]Applying chat template to train dataset:  37%|███▋      | 9077/24227 [00:02<00:04, 3207.82 examples/s]Applying chat template to train dataset:  39%|███▉      | 9400/24227 [00:03<00:04, 3210.79 examples/s]Applying chat template to train dataset:  40%|████      | 9724/24227 [00:03<00:04, 3216.35 examples/s]Applying chat template to train dataset:  41%|████▏     | 10047/24227 [00:03<00:04, 3219.78 examples/s]Applying chat template to train dataset:  43%|████▎     | 10520/24227 [00:03<00:04, 3185.85 examples/s]Applying chat template to train dataset:  45%|████▌     | 10994/24227 [00:03<00:04, 3175.47 examples/s]Applying chat template to train dataset:  47%|████▋     | 11468/24227 [00:03<00:04, 3165.22 examples/s]Applying chat template to train dataset:  49%|████▉     | 11943/24227 [00:03<00:03, 3162.50 examples/s]Applying chat template to train dataset:  51%|█████     | 12267/24227 [00:03<00:03, 3178.38 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12590/24227 [00:04<00:03, 3187.56 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12914/24227 [00:04<00:03, 3199.63 examples/s]Applying chat template to train dataset:  55%|█████▍    | 13237/24227 [00:04<00:03, 3207.21 examples/s]Applying chat template to train dataset:  56%|█████▌    | 13560/24227 [00:04<00:03, 3209.32 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13887/24227 [00:04<00:03, 3224.08 examples/s]Applying chat template to train dataset:  59%|█████▊    | 14210/24227 [00:04<00:03, 3222.00 examples/s]Applying chat template to train dataset:  60%|█████▉    | 14534/24227 [00:04<00:03, 3223.15 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15013/24227 [00:04<00:02, 3208.80 examples/s]Applying chat template to train dataset:  64%|██████▎   | 15438/24227 [00:04<00:02, 3004.38 examples/s]Applying chat template to train dataset:  65%|██████▌   | 15753/24227 [00:05<00:02, 3040.38 examples/s]Applying chat template to train dataset:  66%|██████▋   | 16069/24227 [00:05<00:02, 3070.55 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16385/24227 [00:05<00:02, 3091.16 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16707/24227 [00:05<00:02, 3124.33 examples/s]Applying chat template to train dataset:  70%|███████   | 17030/24227 [00:05<00:02, 3150.48 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17355/24227 [00:05<00:02, 3176.53 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17679/24227 [00:05<00:02, 3192.58 examples/s]Applying chat template to train dataset:  74%|███████▍  | 18002/24227 [00:05<00:01, 3202.23 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18327/24227 [00:05<00:01, 3214.11 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18650/24227 [00:05<00:01, 3216.49 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18975/24227 [00:06<00:01, 3223.96 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19299/24227 [00:06<00:01, 3226.57 examples/s]Applying chat template to train dataset:  81%|████████  | 19626/24227 [00:06<00:01, 3237.60 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19956/24227 [00:06<00:01, 3252.57 examples/s]Applying chat template to train dataset:  84%|████████▎ | 20286/24227 [00:06<00:01, 3264.44 examples/s]Applying chat template to train dataset:  85%|████████▌ | 20616/24227 [00:06<00:01, 3272.27 examples/s]Applying chat template to train dataset:  86%|████████▋ | 20945/24227 [00:06<00:01, 3274.26 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21275/24227 [00:06<00:00, 3275.93 examples/s]Applying chat template to train dataset:  89%|████████▉ | 21604/24227 [00:06<00:00, 3272.00 examples/s]Applying chat template to train dataset:  91%|█████████ | 21935/24227 [00:06<00:00, 3279.13 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22265/24227 [00:07<00:00, 2565.31 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22595/24227 [00:07<00:00, 2744.99 examples/s]Applying chat template to train dataset:  95%|█████████▍| 22923/24227 [00:07<00:00, 2883.92 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23249/24227 [00:07<00:00, 2984.53 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23574/24227 [00:07<00:00, 3058.00 examples/s]Applying chat template to train dataset:  99%|█████████▊| 23900/24227 [00:07<00:00, 3110.09 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:07<00:00, 3153.86 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:07<00:00, 3126.99 examples/s]
Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/24227 [00:00<01:00, 398.27 examples/s]Tokenizing train dataset:   0%|          | 89/24227 [00:00<01:11, 338.40 examples/s]Tokenizing train dataset:   1%|          | 133/24227 [00:00<01:17, 312.84 examples/s]Tokenizing train dataset:   1%|          | 165/24227 [00:00<01:17, 309.97 examples/s]Tokenizing train dataset:   1%|          | 212/24227 [00:00<01:18, 304.69 examples/s]Tokenizing train dataset:   1%|          | 247/24227 [00:00<01:16, 314.86 examples/s]Tokenizing train dataset:   1%|          | 282/24227 [00:00<01:14, 322.56 examples/s]Tokenizing train dataset:   1%|▏         | 315/24227 [00:00<01:15, 318.78 examples/s]Tokenizing train dataset:   1%|▏         | 362/24227 [00:01<01:16, 312.78 examples/s]Tokenizing train dataset:   2%|▏         | 397/24227 [00:01<01:15, 315.48 examples/s]Tokenizing train dataset:   2%|▏         | 430/24227 [00:01<01:15, 316.51 examples/s]Tokenizing train dataset:   2%|▏         | 474/24227 [00:01<01:17, 305.31 examples/s]Tokenizing train dataset:   2%|▏         | 519/24227 [00:01<01:19, 297.81 examples/s]Tokenizing train dataset:   2%|▏         | 552/24227 [00:01<01:17, 304.33 examples/s]Tokenizing train dataset:   2%|▏         | 595/24227 [00:01<01:19, 296.24 examples/s]Tokenizing train dataset:   3%|▎         | 631/24227 [00:02<01:16, 309.25 examples/s]Tokenizing train dataset:   3%|▎         | 677/24227 [00:02<01:17, 304.34 examples/s]Tokenizing train dataset:   3%|▎         | 720/24227 [00:02<01:19, 295.72 examples/s]Tokenizing train dataset:   3%|▎         | 756/24227 [00:02<01:16, 305.36 examples/s]Tokenizing train dataset:   3%|▎         | 799/24227 [00:02<01:19, 293.27 examples/s]Tokenizing train dataset:   3%|▎         | 842/24227 [00:02<01:21, 288.14 examples/s]Tokenizing train dataset:   4%|▎         | 872/24227 [00:02<01:20, 289.54 examples/s]Tokenizing train dataset:   4%|▍         | 910/24227 [00:02<01:15, 308.01 examples/s]Tokenizing train dataset:   4%|▍         | 952/24227 [00:03<01:18, 295.89 examples/s]Tokenizing train dataset:   4%|▍         | 983/24227 [00:03<01:19, 292.22 examples/s]Tokenizing train dataset:   4%|▍         | 1025/24227 [00:03<01:21, 285.62 examples/s]Tokenizing train dataset:   4%|▍         | 1054/24227 [00:03<01:22, 282.54 examples/s]Tokenizing train dataset:   4%|▍         | 1090/24227 [00:03<01:17, 297.97 examples/s]Tokenizing train dataset:   5%|▍         | 1121/24227 [00:03<01:18, 293.62 examples/s]Tokenizing train dataset:   5%|▍         | 1164/24227 [00:03<01:21, 284.41 examples/s]Tokenizing train dataset:   5%|▍         | 1200/24227 [00:03<01:17, 297.33 examples/s]Tokenizing train dataset:   5%|▌         | 1231/24227 [00:04<01:18, 294.68 examples/s]Tokenizing train dataset:   5%|▌         | 1268/24227 [00:04<01:13, 311.48 examples/s]Tokenizing train dataset:   5%|▌         | 1314/24227 [00:04<01:15, 305.01 examples/s]Tokenizing train dataset:   6%|▌         | 1347/24227 [00:04<01:14, 308.66 examples/s]Tokenizing train dataset:   6%|▌         | 1387/24227 [00:04<01:18, 292.03 examples/s]Tokenizing train dataset:   6%|▌         | 1418/24227 [00:04<01:17, 293.76 examples/s]Tokenizing train dataset:   6%|▌         | 1448/24227 [00:04<01:17, 292.26 examples/s]Tokenizing train dataset:   6%|▌         | 1490/24227 [00:04<01:19, 285.97 examples/s]Tokenizing train dataset:   6%|▋         | 1538/24227 [00:05<01:17, 291.12 examples/s]Tokenizing train dataset:   6%|▋         | 1568/24227 [00:05<01:17, 291.03 examples/s]Tokenizing train dataset:   7%|▋         | 1598/24227 [00:05<01:17, 290.74 examples/s]Tokenizing train dataset:   7%|▋         | 1630/24227 [00:05<01:15, 297.69 examples/s]Tokenizing train dataset:   7%|▋         | 1666/24227 [00:05<01:12, 309.11 examples/s]Tokenizing train dataset:   7%|▋         | 1703/24227 [00:05<01:10, 319.15 examples/s]Tokenizing train dataset:   7%|▋         | 1738/24227 [00:05<01:08, 326.47 examples/s]Tokenizing train dataset:   7%|▋         | 1771/24227 [00:05<01:09, 324.08 examples/s]Tokenizing train dataset:   8%|▊         | 1818/24227 [00:05<01:11, 315.28 examples/s]Tokenizing train dataset:   8%|▊         | 1862/24227 [00:06<01:13, 303.14 examples/s]Tokenizing train dataset:   8%|▊         | 1900/24227 [00:06<01:18, 283.32 examples/s]Tokenizing train dataset:   8%|▊         | 1940/24227 [00:06<01:21, 272.27 examples/s]Tokenizing train dataset:   8%|▊         | 1968/24227 [00:06<01:21, 272.23 examples/s]Tokenizing train dataset:   8%|▊         | 2000/24227 [00:06<01:19, 279.70 examples/s]Tokenizing train dataset:   8%|▊         | 2033/24227 [00:06<01:16, 290.38 examples/s]Tokenizing train dataset:   9%|▊         | 2071/24227 [00:06<01:11, 309.26 examples/s]Tokenizing train dataset:   9%|▊         | 2104/24227 [00:06<01:10, 313.44 examples/s]Tokenizing train dataset:   9%|▉         | 2148/24227 [00:07<01:12, 305.23 examples/s]Tokenizing train dataset:   9%|▉         | 2192/24227 [00:07<01:14, 296.95 examples/s]Tokenizing train dataset:   9%|▉         | 2241/24227 [00:07<01:12, 302.51 examples/s]Tokenizing train dataset:   9%|▉         | 2275/24227 [00:07<01:11, 305.21 examples/s]Tokenizing train dataset:  10%|▉         | 2321/24227 [00:07<01:13, 299.91 examples/s]Tokenizing train dataset:  10%|▉         | 2365/24227 [00:07<01:15, 291.41 examples/s]Tokenizing train dataset:  10%|▉         | 2410/24227 [00:08<01:15, 288.35 examples/s]Tokenizing train dataset:  10%|█         | 2442/24227 [00:08<01:14, 293.41 examples/s]Tokenizing train dataset:  10%|█         | 2487/24227 [00:08<01:14, 292.88 examples/s]Tokenizing train dataset:  10%|█         | 2524/24227 [00:08<01:21, 267.50 examples/s]Tokenizing train dataset:  11%|█         | 2556/24227 [00:08<01:17, 278.20 examples/s]Tokenizing train dataset:  11%|█         | 2591/24227 [00:08<01:14, 291.48 examples/s]Tokenizing train dataset:  11%|█         | 2626/24227 [00:08<01:11, 301.63 examples/s]Tokenizing train dataset:  11%|█         | 2659/24227 [00:08<01:10, 305.35 examples/s]Tokenizing train dataset:  11%|█         | 2692/24227 [00:08<01:09, 310.70 examples/s]Tokenizing train dataset:  11%|█         | 2725/24227 [00:09<01:09, 310.99 examples/s]Tokenizing train dataset:  11%|█▏        | 2770/24227 [00:09<01:34, 225.97 examples/s]Tokenizing train dataset:  12%|█▏        | 2804/24227 [00:09<01:26, 246.77 examples/s]Tokenizing train dataset:  12%|█▏        | 2833/24227 [00:09<01:24, 253.16 examples/s]Tokenizing train dataset:  12%|█▏        | 2863/24227 [00:09<01:22, 260.28 examples/s]Tokenizing train dataset:  12%|█▏        | 2895/24227 [00:09<01:18, 272.00 examples/s]Tokenizing train dataset:  12%|█▏        | 2924/24227 [00:09<01:18, 273.00 examples/s]Tokenizing train dataset:  12%|█▏        | 2958/24227 [00:10<01:13, 287.76 examples/s]Tokenizing train dataset:  12%|█▏        | 2990/24227 [00:10<01:13, 289.04 examples/s]Tokenizing train dataset:  12%|█▏        | 3022/24227 [00:10<01:11, 295.25 examples/s]Tokenizing train dataset:  13%|█▎        | 3063/24227 [00:10<01:14, 282.92 examples/s]Tokenizing train dataset:  13%|█▎        | 3093/24227 [00:10<01:13, 286.28 examples/s]Tokenizing train dataset:  13%|█▎        | 3123/24227 [00:10<01:12, 289.16 examples/s]Tokenizing train dataset:  13%|█▎        | 3169/24227 [00:10<01:13, 288.45 examples/s]Tokenizing train dataset:  13%|█▎        | 3203/24227 [00:10<01:10, 296.82 examples/s]Tokenizing train dataset:  13%|█▎        | 3234/24227 [00:10<01:11, 294.78 examples/s]Tokenizing train dataset:  13%|█▎        | 3267/24227 [00:11<01:09, 302.03 examples/s]Tokenizing train dataset:  14%|█▎        | 3299/24227 [00:11<01:09, 299.97 examples/s]Tokenizing train dataset:  14%|█▍        | 3342/24227 [00:11<01:11, 292.79 examples/s]Tokenizing train dataset:  14%|█▍        | 3372/24227 [00:11<01:12, 289.08 examples/s]Tokenizing train dataset:  14%|█▍        | 3413/24227 [00:11<01:14, 278.57 examples/s]Tokenizing train dataset:  14%|█▍        | 3450/24227 [00:11<01:18, 263.80 examples/s]Tokenizing train dataset:  14%|█▍        | 3485/24227 [00:11<01:22, 250.77 examples/s]Tokenizing train dataset:  15%|█▍        | 3529/24227 [00:12<01:10, 293.49 examples/s]Tokenizing train dataset:  15%|█▍        | 3560/24227 [00:12<01:09, 295.54 examples/s]Tokenizing train dataset:  15%|█▍        | 3593/24227 [00:12<01:08, 303.31 examples/s]Tokenizing train dataset:  15%|█▌        | 3640/24227 [00:12<01:07, 303.91 examples/s]Tokenizing train dataset:  15%|█▌        | 3674/24227 [00:12<01:05, 311.50 examples/s]Tokenizing train dataset:  15%|█▌        | 3717/24227 [00:12<01:09, 296.39 examples/s]Tokenizing train dataset:  16%|█▌        | 3767/24227 [00:12<01:07, 304.46 examples/s]Tokenizing train dataset:  16%|█▌        | 3813/24227 [00:12<01:07, 302.95 examples/s]Tokenizing train dataset:  16%|█▌        | 3849/24227 [00:13<01:05, 310.91 examples/s]Tokenizing train dataset:  16%|█▌        | 3898/24227 [00:13<01:05, 309.54 examples/s]Tokenizing train dataset:  16%|█▌        | 3935/24227 [00:13<01:10, 287.84 examples/s]Tokenizing train dataset:  16%|█▋        | 3968/24227 [00:13<01:08, 295.31 examples/s]Tokenizing train dataset:  17%|█▋        | 4012/24227 [00:13<01:09, 291.48 examples/s]Tokenizing train dataset:  17%|█▋        | 4043/24227 [00:13<01:08, 292.64 examples/s]Tokenizing train dataset:  17%|█▋        | 4073/24227 [00:13<01:09, 291.43 examples/s]Tokenizing train dataset:  17%|█▋        | 4109/24227 [00:13<01:05, 305.13 examples/s]Tokenizing train dataset:  17%|█▋        | 4141/24227 [00:14<01:05, 306.75 examples/s]Tokenizing train dataset:  17%|█▋        | 4173/24227 [00:14<01:05, 304.96 examples/s]Tokenizing train dataset:  17%|█▋        | 4211/24227 [00:14<01:13, 273.82 examples/s]Tokenizing train dataset:  18%|█▊        | 4241/24227 [00:14<01:11, 278.43 examples/s]Tokenizing train dataset:  18%|█▊        | 4270/24227 [00:14<01:11, 280.38 examples/s]Tokenizing train dataset:  18%|█▊        | 4300/24227 [00:14<01:11, 280.51 examples/s]Tokenizing train dataset:  18%|█▊        | 4329/24227 [00:14<01:11, 279.45 examples/s]Tokenizing train dataset:  18%|█▊        | 4360/24227 [00:14<01:09, 285.57 examples/s]Tokenizing train dataset:  18%|█▊        | 4390/24227 [00:14<01:08, 287.80 examples/s]Tokenizing train dataset:  18%|█▊        | 4425/24227 [00:15<01:06, 299.18 examples/s]Tokenizing train dataset:  18%|█▊        | 4457/24227 [00:15<01:05, 303.20 examples/s]Tokenizing train dataset:  19%|█▊        | 4501/24227 [00:15<01:06, 295.44 examples/s]Tokenizing train dataset:  19%|█▊        | 4531/24227 [00:15<01:06, 295.27 examples/s]Tokenizing train dataset:  19%|█▉        | 4561/24227 [00:15<01:07, 292.47 examples/s]Tokenizing train dataset:  19%|█▉        | 4591/24227 [00:15<01:07, 289.39 examples/s]Tokenizing train dataset:  19%|█▉        | 4622/24227 [00:15<01:07, 291.14 examples/s]Tokenizing train dataset:  19%|█▉        | 4666/24227 [00:15<01:07, 290.36 examples/s]Tokenizing train dataset:  19%|█▉        | 4696/24227 [00:15<01:07, 287.71 examples/s]Tokenizing train dataset:  20%|█▉        | 4725/24227 [00:16<01:09, 282.57 examples/s]Tokenizing train dataset:  20%|█▉        | 4758/24227 [00:16<01:06, 291.31 examples/s]Tokenizing train dataset:  20%|█▉        | 4788/24227 [00:16<01:07, 286.91 examples/s]Tokenizing train dataset:  20%|█▉        | 4819/24227 [00:16<01:07, 288.40 examples/s]Tokenizing train dataset:  20%|██        | 4860/24227 [00:16<01:10, 276.38 examples/s]Tokenizing train dataset:  20%|██        | 4889/24227 [00:16<01:09, 278.36 examples/s]Tokenizing train dataset:  20%|██        | 4934/24227 [00:16<01:07, 283.96 examples/s]Tokenizing train dataset:  20%|██        | 4964/24227 [00:16<01:12, 266.94 examples/s]Tokenizing train dataset:  21%|██        | 4998/24227 [00:17<01:08, 282.53 examples/s]Tokenizing train dataset:  21%|██        | 5031/24227 [00:17<01:05, 294.59 examples/s]Tokenizing train dataset:  21%|██        | 5061/24227 [00:17<01:05, 291.84 examples/s]Tokenizing train dataset:  21%|██        | 5091/24227 [00:17<01:05, 290.01 examples/s]Tokenizing train dataset:  21%|██        | 5121/24227 [00:17<01:06, 287.94 examples/s]Tokenizing train dataset:  21%|██▏       | 5152/24227 [00:17<01:05, 290.99 examples/s]Tokenizing train dataset:  21%|██▏       | 5195/24227 [00:17<01:07, 282.88 examples/s]Tokenizing train dataset:  22%|██▏       | 5224/24227 [00:17<01:07, 282.81 examples/s]Tokenizing train dataset:  22%|██▏       | 5255/24227 [00:17<01:06, 285.62 examples/s]Tokenizing train dataset:  22%|██▏       | 5297/24227 [00:18<01:08, 276.11 examples/s]Tokenizing train dataset:  22%|██▏       | 5334/24227 [00:18<01:12, 260.21 examples/s]Tokenizing train dataset:  22%|██▏       | 5376/24227 [00:18<01:03, 296.96 examples/s]Tokenizing train dataset:  22%|██▏       | 5423/24227 [00:18<01:02, 300.55 examples/s]Tokenizing train dataset:  23%|██▎       | 5455/24227 [00:18<01:02, 302.42 examples/s]Tokenizing train dataset:  23%|██▎       | 5488/24227 [00:18<01:01, 303.82 examples/s]Tokenizing train dataset:  23%|██▎       | 5520/24227 [00:18<01:01, 304.06 examples/s]Tokenizing train dataset:  23%|██▎       | 5564/24227 [00:18<01:03, 294.89 examples/s]Tokenizing train dataset:  23%|██▎       | 5608/24227 [00:19<00:56, 329.59 examples/s]Tokenizing train dataset:  23%|██▎       | 5659/24227 [00:19<00:56, 327.15 examples/s]Tokenizing train dataset:  24%|██▎       | 5695/24227 [00:19<01:07, 273.33 examples/s]Tokenizing train dataset:  24%|██▎       | 5728/24227 [00:19<01:05, 280.92 examples/s]Tokenizing train dataset:  24%|██▍       | 5768/24227 [00:19<01:07, 272.33 examples/s]Tokenizing train dataset:  24%|██▍       | 5810/24227 [00:19<01:07, 273.77 examples/s]Tokenizing train dataset:  24%|██▍       | 5851/24227 [00:19<01:00, 303.99 examples/s]Tokenizing train dataset:  24%|██▍       | 5888/24227 [00:20<00:58, 313.02 examples/s]Tokenizing train dataset:  24%|██▍       | 5933/24227 [00:20<01:00, 304.59 examples/s]Tokenizing train dataset:  25%|██▍       | 5976/24227 [00:20<01:01, 296.68 examples/s]Tokenizing train dataset:  25%|██▍       | 6019/24227 [00:20<01:02, 290.71 examples/s]Tokenizing train dataset:  25%|██▍       | 6051/24227 [00:20<01:01, 294.86 examples/s]Tokenizing train dataset:  25%|██▌       | 6090/24227 [00:20<00:58, 312.70 examples/s]Tokenizing train dataset:  25%|██▌       | 6128/24227 [00:20<00:54, 329.10 examples/s]Tokenizing train dataset:  25%|██▌       | 6163/24227 [00:20<00:54, 332.21 examples/s]Tokenizing train dataset:  26%|██▌       | 6198/24227 [00:21<00:54, 333.56 examples/s]Tokenizing train dataset:  26%|██▌       | 6232/24227 [00:21<00:54, 331.79 examples/s]Tokenizing train dataset:  26%|██▌       | 6276/24227 [00:21<00:50, 357.70 examples/s]Tokenizing train dataset:  26%|██▌       | 6332/24227 [00:21<00:49, 359.26 examples/s]Tokenizing train dataset:  26%|██▋       | 6372/24227 [00:21<00:48, 367.88 examples/s]Tokenizing train dataset:  27%|██▋       | 6425/24227 [00:21<00:49, 358.89 examples/s]Tokenizing train dataset:  27%|██▋       | 6464/24227 [00:21<00:48, 365.53 examples/s]Tokenizing train dataset:  27%|██▋       | 6502/24227 [00:21<00:48, 365.99 examples/s]Tokenizing train dataset:  27%|██▋       | 6556/24227 [00:22<00:49, 356.92 examples/s]Tokenizing train dataset:  27%|██▋       | 6610/24227 [00:22<00:49, 352.80 examples/s]Tokenizing train dataset:  27%|██▋       | 6653/24227 [00:22<00:48, 364.76 examples/s]Tokenizing train dataset:  28%|██▊       | 6690/24227 [00:22<00:48, 363.04 examples/s]Tokenizing train dataset:  28%|██▊       | 6728/24227 [00:22<00:48, 364.14 examples/s]Tokenizing train dataset:  28%|██▊       | 6779/24227 [00:22<00:49, 351.94 examples/s]Tokenizing train dataset:  28%|██▊       | 6820/24227 [00:22<00:47, 363.28 examples/s]Tokenizing train dataset:  28%|██▊       | 6874/24227 [00:22<00:48, 356.29 examples/s]Tokenizing train dataset:  29%|██▊       | 6917/24227 [00:23<00:46, 372.51 examples/s]Tokenizing train dataset:  29%|██▊       | 6959/24227 [00:23<00:45, 381.63 examples/s]Tokenizing train dataset:  29%|██▉       | 7012/24227 [00:23<00:46, 368.86 examples/s]Tokenizing train dataset:  29%|██▉       | 7065/24227 [00:23<00:47, 358.13 examples/s]Tokenizing train dataset:  29%|██▉       | 7104/24227 [00:23<00:46, 364.49 examples/s]Tokenizing train dataset:  30%|██▉       | 7159/24227 [00:23<00:47, 361.35 examples/s]Tokenizing train dataset:  30%|██▉       | 7211/24227 [00:23<00:48, 352.79 examples/s]Tokenizing train dataset:  30%|██▉       | 7250/24227 [00:23<00:47, 358.01 examples/s]Tokenizing train dataset:  30%|███       | 7304/24227 [00:24<00:47, 355.69 examples/s]Tokenizing train dataset:  30%|███       | 7340/24227 [00:24<00:47, 354.67 examples/s]Tokenizing train dataset:  30%|███       | 7376/24227 [00:24<00:47, 354.42 examples/s]Tokenizing train dataset:  31%|███       | 7427/24227 [00:24<00:48, 346.26 examples/s]Tokenizing train dataset:  31%|███       | 7474/24227 [00:24<00:50, 333.16 examples/s]Tokenizing train dataset:  31%|███       | 7510/24227 [00:24<00:49, 335.63 examples/s]Tokenizing train dataset:  31%|███       | 7548/24227 [00:24<00:48, 344.48 examples/s]Tokenizing train dataset:  31%|███▏      | 7599/24227 [00:24<00:49, 337.45 examples/s]Tokenizing train dataset:  32%|███▏      | 7647/24227 [00:25<00:50, 328.30 examples/s]Tokenizing train dataset:  32%|███▏      | 7698/24227 [00:25<00:44, 367.41 examples/s]Tokenizing train dataset:  32%|███▏      | 7767/24227 [00:25<00:37, 443.41 examples/s]Tokenizing train dataset:  32%|███▏      | 7835/24227 [00:25<00:32, 501.24 examples/s]Tokenizing train dataset:  33%|███▎      | 7907/24227 [00:25<00:29, 559.55 examples/s]Tokenizing train dataset:  33%|███▎      | 7983/24227 [00:25<00:26, 613.81 examples/s]Tokenizing train dataset:  33%|███▎      | 8080/24227 [00:25<00:26, 621.03 examples/s]Tokenizing train dataset:  34%|███▎      | 8147/24227 [00:25<00:25, 628.96 examples/s]Tokenizing train dataset:  34%|███▍      | 8213/24227 [00:26<00:25, 633.82 examples/s]Tokenizing train dataset:  34%|███▍      | 8290/24227 [00:26<00:23, 666.32 examples/s]Tokenizing train dataset:  35%|███▍      | 8367/24227 [00:26<00:23, 689.12 examples/s]Tokenizing train dataset:  35%|███▍      | 8467/24227 [00:26<00:23, 675.37 examples/s]Tokenizing train dataset:  35%|███▌      | 8572/24227 [00:26<00:22, 682.94 examples/s]Tokenizing train dataset:  36%|███▌      | 8654/24227 [00:26<00:21, 710.20 examples/s]Tokenizing train dataset:  36%|███▌      | 8733/24227 [00:26<00:21, 727.45 examples/s]Tokenizing train dataset:  36%|███▋      | 8830/24227 [00:26<00:22, 696.20 examples/s]Tokenizing train dataset:  37%|███▋      | 8935/24227 [00:27<00:22, 689.44 examples/s]Tokenizing train dataset:  37%|███▋      | 9009/24227 [00:27<00:21, 700.84 examples/s]Tokenizing train dataset:  37%|███▋      | 9085/24227 [00:27<00:21, 711.93 examples/s]Tokenizing train dataset:  38%|███▊      | 9182/24227 [00:27<00:21, 686.99 examples/s]Tokenizing train dataset:  38%|███▊      | 9255/24227 [00:27<00:21, 696.78 examples/s]Tokenizing train dataset:  38%|███▊      | 9327/24227 [00:27<00:21, 701.95 examples/s]Tokenizing train dataset:  39%|███▉      | 9431/24227 [00:27<00:21, 696.18 examples/s]Tokenizing train dataset:  39%|███▉      | 9536/24227 [00:27<00:21, 693.31 examples/s]Tokenizing train dataset:  40%|███▉      | 9630/24227 [00:28<00:21, 663.89 examples/s]Tokenizing train dataset:  40%|████      | 9700/24227 [00:28<00:21, 668.01 examples/s]Tokenizing train dataset:  40%|████      | 9770/24227 [00:28<00:21, 672.66 examples/s]Tokenizing train dataset:  41%|████      | 9860/24227 [00:28<00:22, 640.84 examples/s]Tokenizing train dataset:  41%|████      | 9930/24227 [00:28<00:22, 649.00 examples/s]Tokenizing train dataset:  41%|████▏     | 10014/24227 [00:28<00:20, 696.80 examples/s]Tokenizing train dataset:  42%|████▏     | 10113/24227 [00:28<00:20, 678.39 examples/s]Tokenizing train dataset:  42%|████▏     | 10187/24227 [00:28<00:23, 609.31 examples/s]Tokenizing train dataset:  42%|████▏     | 10251/24227 [00:29<00:25, 540.62 examples/s]Tokenizing train dataset:  43%|████▎     | 10320/24227 [00:29<00:30, 459.48 examples/s]Tokenizing train dataset:  43%|████▎     | 10380/24227 [00:29<00:31, 438.27 examples/s]Tokenizing train dataset:  43%|████▎     | 10438/24227 [00:29<00:32, 420.72 examples/s]Tokenizing train dataset:  43%|████▎     | 10492/24227 [00:29<00:34, 401.48 examples/s]Tokenizing train dataset:  44%|████▎     | 10548/24227 [00:29<00:35, 389.33 examples/s]Tokenizing train dataset:  44%|████▍     | 10602/24227 [00:30<00:36, 376.35 examples/s]Tokenizing train dataset:  44%|████▍     | 10657/24227 [00:30<00:36, 370.60 examples/s]Tokenizing train dataset:  44%|████▍     | 10710/24227 [00:30<00:37, 357.79 examples/s]Tokenizing train dataset:  44%|████▍     | 10750/24227 [00:30<00:36, 364.89 examples/s]Tokenizing train dataset:  45%|████▍     | 10805/24227 [00:30<00:37, 361.79 examples/s]Tokenizing train dataset:  45%|████▍     | 10842/24227 [00:30<00:37, 359.89 examples/s]Tokenizing train dataset:  45%|████▍     | 10896/24227 [00:30<00:37, 354.70 examples/s]Tokenizing train dataset:  45%|████▌     | 10949/24227 [00:31<00:37, 350.48 examples/s]Tokenizing train dataset:  45%|████▌     | 10990/24227 [00:31<00:36, 360.91 examples/s]Tokenizing train dataset:  46%|████▌     | 11030/24227 [00:31<00:36, 365.20 examples/s]Tokenizing train dataset:  46%|████▌     | 11073/24227 [00:31<00:34, 376.35 examples/s]Tokenizing train dataset:  46%|████▌     | 11127/24227 [00:31<00:36, 363.53 examples/s]Tokenizing train dataset:  46%|████▌     | 11165/24227 [00:31<00:35, 365.19 examples/s]Tokenizing train dataset:  46%|████▌     | 11203/24227 [00:31<00:35, 366.77 examples/s]Tokenizing train dataset:  46%|████▋     | 11240/24227 [00:31<00:35, 363.85 examples/s]Tokenizing train dataset:  47%|████▋     | 11277/24227 [00:31<00:36, 359.05 examples/s]Tokenizing train dataset:  47%|████▋     | 11315/24227 [00:32<00:35, 358.69 examples/s]Tokenizing train dataset:  47%|████▋     | 11355/24227 [00:32<00:34, 368.14 examples/s]Tokenizing train dataset:  47%|████▋     | 11400/24227 [00:32<00:38, 336.86 examples/s]Tokenizing train dataset:  47%|████▋     | 11436/24227 [00:32<00:37, 341.64 examples/s]Tokenizing train dataset:  47%|████▋     | 11472/24227 [00:32<00:37, 343.46 examples/s]Tokenizing train dataset:  48%|████▊     | 11514/24227 [00:32<00:35, 361.04 examples/s]Tokenizing train dataset:  48%|████▊     | 11565/24227 [00:32<00:36, 349.79 examples/s]Tokenizing train dataset:  48%|████▊     | 11604/24227 [00:32<00:35, 357.18 examples/s]Tokenizing train dataset:  48%|████▊     | 11658/24227 [00:33<00:35, 356.35 examples/s]Tokenizing train dataset:  48%|████▊     | 11711/24227 [00:33<00:35, 352.70 examples/s]Tokenizing train dataset:  48%|████▊     | 11749/24227 [00:33<00:35, 353.80 examples/s]Tokenizing train dataset:  49%|████▊     | 11798/24227 [00:33<00:36, 342.02 examples/s]Tokenizing train dataset:  49%|████▉     | 11861/24227 [00:33<00:37, 326.48 examples/s]Tokenizing train dataset:  49%|████▉     | 11929/24227 [00:33<00:30, 402.35 examples/s]Tokenizing train dataset:  50%|████▉     | 11997/24227 [00:33<00:26, 465.71 examples/s]Tokenizing train dataset:  50%|████▉     | 12074/24227 [00:33<00:22, 538.34 examples/s]Tokenizing train dataset:  50%|█████     | 12142/24227 [00:34<00:21, 572.89 examples/s]Tokenizing train dataset:  50%|█████     | 12218/24227 [00:34<00:19, 620.06 examples/s]Tokenizing train dataset:  51%|█████     | 12290/24227 [00:34<00:18, 641.59 examples/s]Tokenizing train dataset:  51%|█████     | 12364/24227 [00:34<00:17, 662.29 examples/s]Tokenizing train dataset:  51%|█████▏    | 12463/24227 [00:34<00:17, 654.60 examples/s]Tokenizing train dataset:  52%|█████▏    | 12532/24227 [00:34<00:17, 656.27 examples/s]Tokenizing train dataset:  52%|█████▏    | 12605/24227 [00:34<00:19, 589.79 examples/s]Tokenizing train dataset:  52%|█████▏    | 12683/24227 [00:34<00:18, 631.25 examples/s]Tokenizing train dataset:  53%|█████▎    | 12751/24227 [00:34<00:17, 638.66 examples/s]Tokenizing train dataset:  53%|█████▎    | 12832/24227 [00:35<00:16, 684.21 examples/s]Tokenizing train dataset:  53%|█████▎    | 12936/24227 [00:35<00:16, 677.01 examples/s]Tokenizing train dataset:  54%|█████▍    | 13034/24227 [00:35<00:16, 663.22 examples/s]Tokenizing train dataset:  54%|█████▍    | 13104/24227 [00:35<00:16, 664.70 examples/s]Tokenizing train dataset:  54%|█████▍    | 13172/24227 [00:35<00:16, 666.05 examples/s]Tokenizing train dataset:  55%|█████▍    | 13262/24227 [00:35<00:17, 640.58 examples/s]Tokenizing train dataset:  55%|█████▌    | 13354/24227 [00:35<00:17, 629.73 examples/s]Tokenizing train dataset:  56%|█████▌    | 13448/24227 [00:36<00:17, 627.14 examples/s]Tokenizing train dataset:  56%|█████▌    | 13522/24227 [00:36<00:16, 648.26 examples/s]Tokenizing train dataset:  56%|█████▌    | 13590/24227 [00:36<00:16, 654.10 examples/s]Tokenizing train dataset:  56%|█████▋    | 13664/24227 [00:36<00:15, 672.95 examples/s]Tokenizing train dataset:  57%|█████▋    | 13743/24227 [00:36<00:14, 699.12 examples/s]Tokenizing train dataset:  57%|█████▋    | 13817/24227 [00:36<00:14, 708.85 examples/s]Tokenizing train dataset:  57%|█████▋    | 13897/24227 [00:36<00:14, 733.07 examples/s]Tokenizing train dataset:  58%|█████▊    | 13990/24227 [00:36<00:14, 687.90 examples/s]Tokenizing train dataset:  58%|█████▊    | 14083/24227 [00:36<00:15, 660.97 examples/s]Tokenizing train dataset:  58%|█████▊    | 14164/24227 [00:37<00:14, 697.53 examples/s]Tokenizing train dataset:  59%|█████▉    | 14236/24227 [00:37<00:14, 691.19 examples/s]Tokenizing train dataset:  59%|█████▉    | 14343/24227 [00:37<00:14, 694.38 examples/s]Tokenizing train dataset:  60%|█████▉    | 14442/24227 [00:37<00:14, 673.54 examples/s]Tokenizing train dataset:  60%|██████    | 14542/24227 [00:37<00:14, 658.67 examples/s]Tokenizing train dataset:  60%|██████    | 14614/24227 [00:37<00:14, 665.65 examples/s]Tokenizing train dataset:  61%|██████    | 14682/24227 [00:37<00:14, 668.04 examples/s]Tokenizing train dataset:  61%|██████    | 14766/24227 [00:37<00:15, 628.05 examples/s]Tokenizing train dataset:  61%|██████▏   | 14849/24227 [00:38<00:17, 538.68 examples/s]Tokenizing train dataset:  62%|██████▏   | 14907/24227 [00:38<00:19, 488.76 examples/s]Tokenizing train dataset:  62%|██████▏   | 14959/24227 [00:38<00:20, 443.84 examples/s]Tokenizing train dataset:  62%|██████▏   | 15015/24227 [00:38<00:21, 420.99 examples/s]Tokenizing train dataset:  62%|██████▏   | 15072/24227 [00:38<00:22, 407.19 examples/s]Tokenizing train dataset:  62%|██████▏   | 15130/24227 [00:38<00:23, 393.88 examples/s]Tokenizing train dataset:  63%|██████▎   | 15172/24227 [00:39<00:22, 396.47 examples/s]Tokenizing train dataset:  63%|██████▎   | 15226/24227 [00:39<00:23, 381.76 examples/s]Tokenizing train dataset:  63%|██████▎   | 15281/24227 [00:39<00:23, 373.80 examples/s]Tokenizing train dataset:  63%|██████▎   | 15337/24227 [00:39<00:23, 372.03 examples/s]Tokenizing train dataset:  64%|██████▎   | 15389/24227 [00:39<00:24, 359.88 examples/s]Tokenizing train dataset:  64%|██████▎   | 15427/24227 [00:39<00:24, 361.48 examples/s]Tokenizing train dataset:  64%|██████▍   | 15476/24227 [00:39<00:25, 343.40 examples/s]Tokenizing train dataset:  64%|██████▍   | 15529/24227 [00:40<00:25, 343.65 examples/s]Tokenizing train dataset:  64%|██████▍   | 15567/24227 [00:40<00:24, 349.73 examples/s]Tokenizing train dataset:  64%|██████▍   | 15607/24227 [00:40<00:24, 359.04 examples/s]Tokenizing train dataset:  65%|██████▍   | 15660/24227 [00:40<00:24, 354.11 examples/s]Tokenizing train dataset:  65%|██████▍   | 15703/24227 [00:40<00:23, 364.47 examples/s]Tokenizing train dataset:  65%|██████▍   | 15742/24227 [00:40<00:23, 368.16 examples/s]Tokenizing train dataset:  65%|██████▌   | 15780/24227 [00:40<00:22, 368.25 examples/s]Tokenizing train dataset:  65%|██████▌   | 15819/24227 [00:40<00:22, 370.17 examples/s]Tokenizing train dataset:  66%|██████▌   | 15871/24227 [00:41<00:23, 357.77 examples/s]Tokenizing train dataset:  66%|██████▌   | 15912/24227 [00:41<00:22, 368.37 examples/s]Tokenizing train dataset:  66%|██████▌   | 15964/24227 [00:41<00:23, 354.68 examples/s]Tokenizing train dataset:  66%|██████▌   | 16000/24227 [00:41<00:23, 349.20 examples/s]Tokenizing train dataset:  66%|██████▌   | 16041/24227 [00:41<00:22, 360.22 examples/s]Tokenizing train dataset:  66%|██████▋   | 16079/24227 [00:41<00:22, 363.26 examples/s]Tokenizing train dataset:  67%|██████▋   | 16120/24227 [00:41<00:21, 372.60 examples/s]Tokenizing train dataset:  67%|██████▋   | 16162/24227 [00:41<00:21, 379.89 examples/s]Tokenizing train dataset:  67%|██████▋   | 16218/24227 [00:41<00:21, 372.80 examples/s]Tokenizing train dataset:  67%|██████▋   | 16273/24227 [00:42<00:21, 362.79 examples/s]Tokenizing train dataset:  67%|██████▋   | 16327/24227 [00:42<00:22, 356.41 examples/s]Tokenizing train dataset:  68%|██████▊   | 16380/24227 [00:42<00:22, 347.71 examples/s]Tokenizing train dataset:  68%|██████▊   | 16432/24227 [00:42<00:22, 343.02 examples/s]Tokenizing train dataset:  68%|██████▊   | 16488/24227 [00:42<00:22, 349.05 examples/s]Tokenizing train dataset:  68%|██████▊   | 16568/24227 [00:42<00:17, 447.96 examples/s]Tokenizing train dataset:  69%|██████▊   | 16633/24227 [00:42<00:15, 491.07 examples/s]Tokenizing train dataset:  69%|██████▉   | 16705/24227 [00:43<00:13, 542.14 examples/s]Tokenizing train dataset:  69%|██████▉   | 16773/24227 [00:43<00:12, 576.04 examples/s]Tokenizing train dataset:  70%|██████▉   | 16846/24227 [00:43<00:11, 617.12 examples/s]Tokenizing train dataset:  70%|██████▉   | 16916/24227 [00:43<00:11, 636.58 examples/s]Tokenizing train dataset:  70%|███████   | 16982/24227 [00:43<00:11, 642.27 examples/s]Tokenizing train dataset:  70%|███████   | 17054/24227 [00:43<00:10, 658.42 examples/s]Tokenizing train dataset:  71%|███████   | 17133/24227 [00:43<00:10, 694.73 examples/s]Tokenizing train dataset:  71%|███████   | 17210/24227 [00:43<00:09, 703.79 examples/s]Tokenizing train dataset:  71%|███████▏  | 17287/24227 [00:43<00:09, 715.71 examples/s]Tokenizing train dataset:  72%|███████▏  | 17360/24227 [00:43<00:09, 718.35 examples/s]Tokenizing train dataset:  72%|███████▏  | 17459/24227 [00:44<00:09, 690.24 examples/s]Tokenizing train dataset:  72%|███████▏  | 17550/24227 [00:44<00:10, 652.34 examples/s]Tokenizing train dataset:  73%|███████▎  | 17642/24227 [00:44<00:10, 636.12 examples/s]Tokenizing train dataset:  73%|███████▎  | 17717/24227 [00:44<00:09, 656.24 examples/s]Tokenizing train dataset:  73%|███████▎  | 17790/24227 [00:44<00:09, 670.29 examples/s]Tokenizing train dataset:  74%|███████▍  | 17884/24227 [00:44<00:09, 648.45 examples/s]Tokenizing train dataset:  74%|███████▍  | 17950/24227 [00:44<00:09, 648.38 examples/s]Tokenizing train dataset:  74%|███████▍  | 18020/24227 [00:45<00:09, 659.73 examples/s]Tokenizing train dataset:  75%|███████▍  | 18099/24227 [00:45<00:08, 692.00 examples/s]Tokenizing train dataset:  75%|███████▌  | 18210/24227 [00:45<00:08, 704.41 examples/s]Tokenizing train dataset:  75%|███████▌  | 18287/24227 [00:45<00:08, 714.33 examples/s]Tokenizing train dataset:  76%|███████▌  | 18363/24227 [00:45<00:08, 720.49 examples/s]Tokenizing train dataset:  76%|███████▌  | 18468/24227 [00:45<00:08, 705.47 examples/s]Tokenizing train dataset:  77%|███████▋  | 18564/24227 [00:45<00:08, 681.40 examples/s]Tokenizing train dataset:  77%|███████▋  | 18637/24227 [00:45<00:08, 691.68 examples/s]Tokenizing train dataset:  77%|███████▋  | 18714/24227 [00:45<00:07, 700.55 examples/s]Tokenizing train dataset:  78%|███████▊  | 18793/24227 [00:46<00:07, 723.04 examples/s]Tokenizing train dataset:  78%|███████▊  | 18875/24227 [00:46<00:07, 744.55 examples/s]Tokenizing train dataset:  78%|███████▊  | 18977/24227 [00:46<00:07, 715.36 examples/s]Tokenizing train dataset:  79%|███████▊  | 19072/24227 [00:46<00:07, 686.18 examples/s]Tokenizing train dataset:  79%|███████▉  | 19146/24227 [00:46<00:07, 696.74 examples/s]Tokenizing train dataset:  79%|███████▉  | 19223/24227 [00:46<00:07, 713.96 examples/s]Tokenizing train dataset:  80%|███████▉  | 19323/24227 [00:46<00:07, 691.93 examples/s]Tokenizing train dataset:  80%|████████  | 19402/24227 [00:47<00:07, 631.48 examples/s]Tokenizing train dataset:  81%|████████  | 19509/24227 [00:47<00:06, 735.69 examples/s]Tokenizing train dataset:  81%|████████  | 19638/24227 [00:47<00:05, 873.91 examples/s]Tokenizing train dataset:  82%|████████▏ | 19762/24227 [00:47<00:04, 969.36 examples/s]Tokenizing train dataset:  82%|████████▏ | 19883/24227 [00:47<00:04, 1032.10 examples/s]Tokenizing train dataset:  83%|████████▎ | 20011/24227 [00:47<00:03, 1099.86 examples/s]Tokenizing train dataset:  83%|████████▎ | 20136/24227 [00:47<00:03, 1142.06 examples/s]Tokenizing train dataset:  84%|████████▎ | 20260/24227 [00:47<00:03, 1163.28 examples/s]Tokenizing train dataset:  84%|████████▍ | 20382/24227 [00:47<00:03, 1176.41 examples/s]Tokenizing train dataset:  85%|████████▍ | 20559/24227 [00:47<00:03, 1173.42 examples/s]Tokenizing train dataset:  86%|████████▌ | 20737/24227 [00:48<00:02, 1174.35 examples/s]Tokenizing train dataset:  86%|████████▋ | 20913/24227 [00:48<00:02, 1169.68 examples/s]Tokenizing train dataset:  87%|████████▋ | 21032/24227 [00:48<00:02, 1173.72 examples/s]Tokenizing train dataset:  87%|████████▋ | 21152/24227 [00:48<00:02, 1177.21 examples/s]Tokenizing train dataset:  88%|████████▊ | 21279/24227 [00:48<00:02, 1199.53 examples/s]Tokenizing train dataset:  89%|████████▊ | 21461/24227 [00:48<00:02, 1199.58 examples/s]Tokenizing train dataset:  89%|████████▉ | 21638/24227 [00:48<00:02, 1191.32 examples/s]Tokenizing train dataset:  90%|█████████ | 21819/24227 [00:49<00:02, 1193.50 examples/s]Tokenizing train dataset:  91%|█████████ | 21940/24227 [00:49<00:01, 1191.61 examples/s]Tokenizing train dataset:  91%|█████████ | 22060/24227 [00:49<00:01, 1188.99 examples/s]Tokenizing train dataset:  92%|█████████▏| 22180/24227 [00:49<00:01, 1189.28 examples/s]Tokenizing train dataset:  92%|█████████▏| 22299/24227 [00:49<00:01, 1182.70 examples/s]Tokenizing train dataset:  93%|█████████▎| 22480/24227 [00:49<00:01, 1184.34 examples/s]Tokenizing train dataset:  94%|█████████▎| 22658/24227 [00:49<00:01, 1181.75 examples/s]Tokenizing train dataset:  94%|█████████▍| 22780/24227 [00:49<00:01, 1189.38 examples/s]Tokenizing train dataset:  95%|█████████▍| 22905/24227 [00:49<00:01, 1204.24 examples/s]Tokenizing train dataset:  95%|█████████▌| 23087/24227 [00:50<00:00, 1205.38 examples/s]Tokenizing train dataset:  96%|█████████▌| 23210/24227 [00:50<00:00, 1208.73 examples/s]Tokenizing train dataset:  96%|█████████▋| 23332/24227 [00:50<00:00, 1207.95 examples/s]Tokenizing train dataset:  97%|█████████▋| 23453/24227 [00:50<00:00, 1207.88 examples/s]Tokenizing train dataset:  97%|█████████▋| 23575/24227 [00:50<00:00, 1208.95 examples/s]Tokenizing train dataset:  98%|█████████▊| 23751/24227 [00:50<00:00, 1192.41 examples/s]Tokenizing train dataset:  99%|█████████▊| 23875/24227 [00:50<00:00, 1203.07 examples/s]Tokenizing train dataset:  99%|█████████▉| 24050/24227 [00:50<00:00, 1188.24 examples/s]Tokenizing train dataset: 100%|█████████▉| 24175/24227 [00:50<00:00, 1200.35 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [00:51<00:00, 474.45 examples/s] 
[rank0]:[W612 00:57:44.148965533 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 561/953 [00:00<00:00, 5566.45 examples/s]Extracting prompt in train dataset:   2%|▏         | 526/24227 [00:00<00:04, 5217.80 examples/s]Extracting prompt in train dataset:   2%|▏         | 540/24227 [00:00<00:04, 5284.67 examples/s]Extracting prompt in train dataset:   2%|▏         | 540/24227 [00:00<00:04, 5279.30 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5571.93 examples/s]
Extracting prompt in train dataset:   4%|▍         | 1070/24227 [00:00<00:04, 5341.35 examples/s]Extracting prompt in train dataset:   5%|▍         | 1100/24227 [00:00<00:04, 5445.29 examples/s]Extracting prompt in train dataset:   5%|▍         | 1100/24227 [00:00<00:04, 5433.61 examples/s]Extracting prompt in train dataset:   7%|▋         | 1611/24227 [00:00<00:04, 5370.76 examples/s]Extracting prompt in train dataset:   7%|▋         | 1650/24227 [00:00<00:04, 5445.28 examples/s]Extracting prompt in train dataset:   7%|▋         | 1657/24227 [00:00<00:04, 5477.47 examples/s]Extracting prompt in train dataset:   9%|▉         | 2170/24227 [00:00<00:04, 5454.06 examples/s]Extracting prompt in train dataset:   9%|▉         | 2220/24227 [00:00<00:03, 5532.54 examples/s]Extracting prompt in train dataset:   9%|▉         | 2230/24227 [00:00<00:03, 5546.25 examples/s]Extracting prompt in train dataset:  11%|█▏        | 2732/24227 [00:00<00:03, 5510.13 examples/s]Extracting prompt in train dataset:  12%|█▏        | 2790/24227 [00:00<00:03, 5583.94 examples/s]Extracting prompt in train dataset:  12%|█▏        | 2810/24227 [00:00<00:03, 5475.76 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  14%|█▍        | 3380/24227 [00:00<00:03, 5544.91 examples/s]Applying chat template to eval dataset:  33%|███▎      | 310/953 [00:00<00:00, 3064.54 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3541/24227 [00:00<00:03, 5454.28 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3619/24227 [00:00<00:03, 5533.63 examples/s]Extracting prompt in train dataset:  16%|█▋        | 3960/24227 [00:00<00:03, 5598.54 examples/s]Applying chat template to eval dataset:  66%|██████▋   | 633/953 [00:00<00:00, 3158.89 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4106/24227 [00:00<00:03, 5510.32 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4190/24227 [00:00<00:03, 5564.22 examples/s]Extracting prompt in train dataset:  19%|█▊        | 4540/24227 [00:00<00:03, 5633.66 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3177.01 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3147.30 examples/s]
Extracting prompt in train dataset:  20%|█▉        | 4781/24227 [00:00<00:03, 5106.08 examples/s]Extracting prompt in train dataset:  20%|██        | 4919/24227 [00:00<00:03, 5274.36 examples/s]Extracting prompt in train dataset:  21%|██        | 5120/24227 [00:00<00:03, 5654.85 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5340/24227 [00:01<00:03, 5232.46 examples/s]Extracting prompt in train dataset:  23%|██▎       | 5484/24227 [00:01<00:03, 5367.88 examples/s]Extracting prompt in train dataset:  24%|██▍       | 5900/24227 [00:01<00:03, 5457.01 examples/s]Extracting prompt in train dataset:  25%|██▌       | 6104/24227 [00:01<00:03, 5175.08 examples/s]Extracting prompt in train dataset:  26%|██▌       | 6260/24227 [00:01<00:03, 5288.42 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  27%|██▋       | 6482/24227 [00:01<00:03, 5548.63 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6680/24227 [00:01<00:03, 5303.22 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6840/24227 [00:01<00:03, 5409.86 examples/s]Extracting prompt in train dataset:  29%|██▉       | 7061/24227 [00:01<00:03, 5613.34 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 320.67 examples/s]Extracting prompt in train dataset:  30%|██▉       | 7250/24227 [00:01<00:03, 5404.46 examples/s]Extracting prompt in train dataset:  31%|███       | 7420/24227 [00:01<00:03, 5504.70 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7640/24227 [00:01<00:02, 5658.08 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:03, 289.38 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7821/24227 [00:01<00:02, 5487.66 examples/s]Extracting prompt in train dataset:  33%|███▎      | 8010/24227 [00:01<00:02, 5597.88 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8240/24227 [00:01<00:02, 5734.63 examples/s]Extracting prompt in train dataset:  35%|███▍      | 8407/24227 [00:01<00:02, 5592.51 examples/s]Extracting prompt in train dataset:  36%|███▌      | 8610/24227 [00:01<00:02, 5687.59 examples/s]Extracting prompt in train dataset:  36%|███▋      | 8840/24227 [00:01<00:02, 5796.37 examples/s]Tokenizing eval dataset:  12%|█▏        | 118/953 [00:00<00:03, 277.38 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8995/24227 [00:01<00:02, 5659.11 examples/s]Extracting prompt in train dataset:  38%|███▊      | 9210/24227 [00:01<00:02, 5751.66 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9440/24227 [00:01<00:02, 5838.13 examples/s]Tokenizing eval dataset:  17%|█▋        | 158/953 [00:00<00:02, 267.95 examples/s]Extracting prompt in train dataset:  40%|███▉      | 9580/24227 [00:01<00:02, 5699.28 examples/s]Extracting prompt in train dataset:  40%|████      | 9810/24227 [00:01<00:02, 5797.92 examples/s]Extracting prompt in train dataset:  41%|████▏     | 10040/24227 [00:01<00:02, 5864.34 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10164/24227 [00:01<00:02, 5737.78 examples/s]Extracting prompt in train dataset:  43%|████▎     | 10400/24227 [00:01<00:02, 5813.65 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:00<00:02, 253.56 examples/s]Extracting prompt in train dataset:  45%|████▌     | 10914/24227 [00:01<00:02, 5847.61 examples/s]Extracting prompt in train dataset:  44%|████▍     | 10740/24227 [00:01<00:02, 5713.01 examples/s]Tokenizing eval dataset:  24%|██▍       | 231/953 [00:00<00:02, 277.68 examples/s]Extracting prompt in train dataset:  47%|████▋     | 11270/24227 [00:02<00:02, 5793.08 examples/s]Extracting prompt in train dataset:  49%|████▊     | 11781/24227 [00:02<00:02, 5821.46 examples/s]Tokenizing eval dataset:  31%|███       | 296/953 [00:00<00:01, 374.22 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11598/24227 [00:02<00:02, 5710.56 examples/s]Extracting prompt in train dataset:  50%|█████     | 12150/24227 [00:02<00:02, 5799.03 examples/s]Extracting prompt in train dataset:  51%|█████     | 12380/24227 [00:02<00:02, 5844.31 examples/s]Tokenizing eval dataset:  38%|███▊      | 359/953 [00:01<00:01, 443.17 examples/s]Extracting prompt in train dataset:  50%|█████     | 12173/24227 [00:02<00:02, 5712.55 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12750/24227 [00:02<00:01, 5826.03 examples/s]Extracting prompt in train dataset:  54%|█████▎    | 12980/24227 [00:02<00:01, 5868.74 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12760/24227 [00:02<00:01, 5741.33 examples/s]Tokenizing eval dataset:  44%|████▍     | 420/953 [00:01<00:01, 487.50 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 13350/24227 [00:02<00:01, 5845.79 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 13580/24227 [00:02<00:01, 5883.26 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 13344/24227 [00:02<00:01, 5768.06 examples/s]Tokenizing eval dataset:  51%|█████     | 488/953 [00:01<00:00, 540.79 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 13950/24227 [00:02<00:01, 5865.64 examples/s]Extracting prompt in train dataset:  59%|█████▊    | 14180/24227 [00:02<00:01, 5899.30 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13930/24227 [00:02<00:01, 5780.27 examples/s]Tokenizing eval dataset:  58%|█████▊    | 554/953 [00:01<00:00, 574.55 examples/s]Extracting prompt in train dataset:  60%|██████    | 14550/24227 [00:02<00:01, 5878.40 examples/s]Extracting prompt in train dataset:  61%|██████    | 14780/24227 [00:02<00:01, 5905.31 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 14514/24227 [00:02<00:01, 5795.68 examples/s]Tokenizing eval dataset:  65%|██████▍   | 616/953 [00:01<00:00, 585.59 examples/s]Tokenizing eval dataset:  71%|███████▏  | 680/953 [00:01<00:00, 596.62 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 15514/24227 [00:02<00:01, 5509.57 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 15380/24227 [00:02<00:01, 5489.06 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 15223/24227 [00:02<00:01, 5383.19 examples/s]Extracting prompt in train dataset:  66%|██████▋   | 16099/24227 [00:02<00:01, 5598.08 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 15962/24227 [00:02<00:01, 5571.13 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 15800/24227 [00:02<00:01, 5468.96 examples/s]Tokenizing eval dataset:  80%|████████  | 766/953 [00:01<00:00, 576.96 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 16680/24227 [00:02<00:01, 5647.60 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 16540/24227 [00:02<00:01, 5622.75 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 16370/24227 [00:02<00:01, 5528.03 examples/s]Tokenizing eval dataset:  88%|████████▊ | 840/953 [00:01<00:00, 541.44 examples/s]Extracting prompt in train dataset:  71%|███████▏  | 17280/24227 [00:03<00:01, 5731.34 examples/s]Extracting prompt in train dataset:  71%|███████   | 17140/24227 [00:03<00:01, 5705.31 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 16954/24227 [00:03<00:01, 5608.34 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 17880/24227 [00:03<00:01, 5789.14 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17740/24227 [00:03<00:01, 5764.63 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 17540/24227 [00:03<00:01, 5667.75 examples/s]Tokenizing eval dataset:  96%|█████████▌| 912/953 [00:02<00:00, 517.66 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 18480/24227 [00:03<00:00, 5834.48 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 18332/24227 [00:03<00:01, 5807.93 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 18125/24227 [00:03<00:01, 5719.74 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 454.51 examples/s]
Extracting prompt in train dataset:  79%|███████▉  | 19080/24227 [00:03<00:00, 5864.43 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 18930/24227 [00:03<00:00, 5838.11 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18710/24227 [00:03<00:00, 5743.05 examples/s]Extracting prompt in train dataset:  81%|████████  | 19684/24227 [00:03<00:00, 5903.46 examples/s]Extracting prompt in train dataset:  81%|████████  | 19530/24227 [00:03<00:00, 5862.79 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 19300/24227 [00:03<00:00, 5770.61 examples/s]Extracting prompt in train dataset:  84%|████████▎ | 20290/24227 [00:03<00:00, 5934.96 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 20135/24227 [00:03<00:00, 5916.64 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19891/24227 [00:03<00:00, 5810.60 examples/s]Extracting prompt in train dataset:  86%|████████▋ | 20896/24227 [00:03<00:00, 5971.19 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 20738/24227 [00:03<00:00, 5949.55 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 20490/24227 [00:03<00:00, 5843.33 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21506/24227 [00:03<00:00, 5991.53 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 21340/24227 [00:03<00:00, 5956.14 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 21090/24227 [00:03<00:00, 5866.71 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22400/24227 [00:03<00:00, 5962.88 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22210/24227 [00:03<00:00, 5875.90 examples/s]Extracting prompt in train dataset:  91%|█████████ | 21963/24227 [00:03<00:00, 5828.24 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 23004/24227 [00:03<00:00, 5974.09 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 22560/24227 [00:04<00:00, 5839.83 examples/s]Extracting prompt in train dataset:  95%|█████████▌| 23079/24227 [00:04<00:00, 5829.02 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 23150/24227 [00:04<00:00, 5844.75 examples/s]Extracting prompt in train dataset:  99%|█████████▊| 23900/24227 [00:04<00:00, 5962.32 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 23939/24227 [00:04<00:00, 5780.22 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:04<00:00, 5737.03 examples/s]
Extracting prompt in train dataset:  98%|█████████▊| 23739/24227 [00:04<00:00, 5856.21 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:04<00:00, 5655.37 examples/s]
Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:04<00:00, 5589.83 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 281/24227 [00:00<00:08, 2766.28 examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 279/24227 [00:00<00:08, 2768.41 examples/s]Applying chat template to train dataset:   2%|▏         | 587/24227 [00:00<00:08, 2931.22 examples/s]Applying chat template to train dataset:   1%|          | 283/24227 [00:00<00:08, 2802.23 examples/s]Applying chat template to train dataset:   2%|▏         | 580/24227 [00:00<00:08, 2899.43 examples/s]Applying chat template to train dataset:   4%|▎         | 889/24227 [00:00<00:07, 2969.68 examples/s]Applying chat template to train dataset:   2%|▏         | 590/24227 [00:00<00:08, 2948.05 examples/s]Applying chat template to train dataset:   4%|▎         | 881/24227 [00:00<00:07, 2936.82 examples/s]Applying chat template to train dataset:   5%|▍         | 1200/24227 [00:00<00:07, 3021.54 examples/s]Applying chat template to train dataset:   4%|▎         | 896/24227 [00:00<00:07, 2993.13 examples/s]Applying chat template to train dataset:   5%|▍         | 1184/24227 [00:00<00:07, 2969.89 examples/s]Applying chat template to train dataset:   6%|▌         | 1504/24227 [00:00<00:07, 3026.72 examples/s]Applying chat template to train dataset:   5%|▍         | 1205/24227 [00:00<00:07, 3022.28 examples/s]Applying chat template to train dataset:   6%|▌         | 1484/24227 [00:00<00:07, 2978.77 examples/s]Applying chat template to train dataset:   7%|▋         | 1812/24227 [00:00<00:07, 3041.73 examples/s]Applying chat template to train dataset:   6%|▌         | 1510/24227 [00:00<00:07, 3024.50 examples/s]Applying chat template to train dataset:   7%|▋         | 1789/24227 [00:00<00:07, 3001.22 examples/s]Applying chat template to train dataset:   9%|▉         | 2120/24227 [00:00<00:07, 3046.63 examples/s]Applying chat template to train dataset:   8%|▊         | 1820/24227 [00:00<00:07, 3048.32 examples/s]Applying chat template to train dataset:   9%|▊         | 2095/24227 [00:00<00:07, 3015.27 examples/s]Applying chat template to train dataset:  10%|█         | 2430/24227 [00:00<00:07, 3056.52 examples/s]Applying chat template to train dataset:   9%|▉         | 2130/24227 [00:00<00:07, 3064.06 examples/s]Applying chat template to train dataset:  10%|▉         | 2400/24227 [00:00<00:07, 3021.78 examples/s]Applying chat template to train dataset:  11%|█▏        | 2736/24227 [00:00<00:07, 3055.89 examples/s]Applying chat template to train dataset:  10%|█         | 2440/24227 [00:00<00:07, 3069.30 examples/s]Applying chat template to train dataset:  11%|█         | 2703/24227 [00:00<00:07, 3022.78 examples/s]Applying chat template to train dataset:  11%|█▏        | 2750/24227 [00:00<00:06, 3071.12 examples/s]Applying chat template to train dataset:  13%|█▎        | 3177/24227 [00:01<00:07, 3004.37 examples/s]Applying chat template to train dataset:  13%|█▎        | 3140/24227 [00:01<00:07, 2976.80 examples/s]Applying chat template to train dataset:  14%|█▍        | 3482/24227 [00:01<00:06, 3012.08 examples/s]Applying chat template to train dataset:  13%|█▎        | 3196/24227 [00:01<00:06, 3028.07 examples/s]Applying chat template to train dataset:  14%|█▍        | 3450/24227 [00:01<00:06, 3003.91 examples/s]Applying chat template to train dataset:  16%|█▌        | 3790/24227 [00:01<00:06, 3025.91 examples/s]Applying chat template to train dataset:  14%|█▍        | 3503/24227 [00:01<00:06, 3034.60 examples/s]Applying chat template to train dataset:  16%|█▌        | 3761/24227 [00:01<00:06, 3031.90 examples/s]Applying chat template to train dataset:  17%|█▋        | 4100/24227 [00:01<00:06, 3041.38 examples/s]Applying chat template to train dataset:  16%|█▌        | 3813/24227 [00:01<00:06, 3049.52 examples/s]Applying chat template to train dataset:  17%|█▋        | 4073/24227 [00:01<00:10, 1985.35 examples/s]Applying chat template to train dataset:  18%|█▊        | 4416/24227 [00:01<00:09, 2157.79 examples/s]Applying chat template to train dataset:  17%|█▋        | 4123/24227 [00:01<00:09, 2209.63 examples/s]Applying chat template to train dataset:  20%|█▉        | 4728/24227 [00:01<00:08, 2373.40 examples/s]Applying chat template to train dataset:  18%|█▊        | 4431/24227 [00:01<00:08, 2407.25 examples/s]Applying chat template to train dataset:  18%|█▊        | 4385/24227 [00:01<00:08, 2221.26 examples/s]Applying chat template to train dataset:  21%|██        | 5036/24227 [00:01<00:07, 2543.47 examples/s]Applying chat template to train dataset:  20%|█▉        | 4740/24227 [00:01<00:07, 2573.07 examples/s]Applying chat template to train dataset:  19%|█▉        | 4697/24227 [00:01<00:08, 2425.76 examples/s]Applying chat template to train dataset:  21%|██        | 5049/24227 [00:01<00:07, 2704.75 examples/s]Applying chat template to train dataset:  22%|██▏       | 5340/24227 [00:01<00:07, 2668.60 examples/s]Applying chat template to train dataset:  21%|██        | 5006/24227 [00:01<00:07, 2589.38 examples/s]Applying chat template to train dataset:  22%|██▏       | 5359/24227 [00:01<00:06, 2809.34 examples/s]Applying chat template to train dataset:  22%|██▏       | 5314/24227 [00:01<00:06, 2715.57 examples/s]Applying chat template to train dataset:  24%|██▍       | 5759/24227 [00:02<00:06, 2711.49 examples/s]Applying chat template to train dataset:  25%|██▌       | 6067/24227 [00:02<00:06, 2803.17 examples/s]Applying chat template to train dataset:  24%|██▍       | 5782/24227 [00:02<00:06, 2809.72 examples/s]Applying chat template to train dataset:  24%|██▎       | 5730/24227 [00:02<00:06, 2731.99 examples/s]Applying chat template to train dataset:  26%|██▋       | 6375/24227 [00:02<00:06, 2874.95 examples/s]Applying chat template to train dataset:  25%|██▌       | 6092/24227 [00:02<00:06, 2882.66 examples/s]Applying chat template to train dataset:  25%|██▍       | 6035/24227 [00:02<00:06, 2810.12 examples/s]Applying chat template to train dataset:  26%|██▋       | 6404/24227 [00:02<00:06, 2945.60 examples/s]Applying chat template to train dataset:  28%|██▊       | 6685/24227 [00:02<00:05, 2931.56 examples/s]Applying chat template to train dataset:  26%|██▌       | 6343/24227 [00:02<00:06, 2876.86 examples/s]Applying chat template to train dataset:  28%|██▊       | 6717/24227 [00:02<00:05, 2994.63 examples/s]Applying chat template to train dataset:  29%|██▉       | 6995/24227 [00:02<00:05, 2974.47 examples/s]Applying chat template to train dataset:  27%|██▋       | 6652/24227 [00:02<00:05, 2931.82 examples/s]Applying chat template to train dataset:  29%|██▉       | 7035/24227 [00:02<00:05, 3045.44 examples/s]Applying chat template to train dataset:  30%|███       | 7304/24227 [00:02<00:05, 3002.55 examples/s]Applying chat template to train dataset:  29%|██▉       | 6967/24227 [00:02<00:05, 2988.02 examples/s]Applying chat template to train dataset:  30%|███       | 7351/24227 [00:02<00:05, 3077.52 examples/s]Applying chat template to train dataset:  31%|███▏      | 7611/24227 [00:02<00:05, 3019.28 examples/s]Applying chat template to train dataset:  30%|███       | 7279/24227 [00:02<00:05, 3024.55 examples/s]Applying chat template to train dataset:  32%|███▏      | 7670/24227 [00:02<00:05, 3100.36 examples/s]Applying chat template to train dataset:  33%|███▎      | 7925/24227 [00:02<00:05, 3050.81 examples/s]Applying chat template to train dataset:  31%|███▏      | 7591/24227 [00:02<00:05, 3047.33 examples/s]Applying chat template to train dataset:  33%|███▎      | 7993/24227 [00:02<00:05, 3135.97 examples/s]Applying chat template to train dataset:  34%|███▍      | 8240/24227 [00:02<00:05, 3077.79 examples/s]Applying chat template to train dataset:  33%|███▎      | 7911/24227 [00:02<00:05, 3086.23 examples/s]Applying chat template to train dataset:  34%|███▍      | 8310/24227 [00:02<00:05, 3145.04 examples/s]Applying chat template to train dataset:  35%|███▌      | 8556/24227 [00:02<00:05, 3100.11 examples/s]Applying chat template to train dataset:  34%|███▍      | 8232/24227 [00:02<00:05, 3120.37 examples/s]Applying chat template to train dataset:  37%|███▋      | 8871/24227 [00:03<00:04, 3113.95 examples/s]Applying chat template to train dataset:  36%|███▌      | 8630/24227 [00:02<00:04, 3155.04 examples/s]Applying chat template to train dataset:  35%|███▌      | 8554/24227 [00:02<00:04, 3147.10 examples/s]Applying chat template to train dataset:  37%|███▋      | 8951/24227 [00:03<00:04, 3169.16 examples/s]Applying chat template to train dataset:  38%|███▊      | 9190/24227 [00:03<00:04, 3129.80 examples/s]Applying chat template to train dataset:  37%|███▋      | 8879/24227 [00:03<00:04, 3173.50 examples/s]Applying chat template to train dataset:  38%|███▊      | 9270/24227 [00:03<00:04, 3173.78 examples/s]Applying chat template to train dataset:  39%|███▉      | 9508/24227 [00:03<00:04, 3140.78 examples/s]Applying chat template to train dataset:  38%|███▊      | 9202/24227 [00:03<00:04, 3182.40 examples/s]Applying chat template to train dataset:  40%|███▉      | 9590/24227 [00:03<00:04, 3174.39 examples/s]Applying chat template to train dataset:  39%|███▉      | 9524/24227 [00:03<00:04, 3190.16 examples/s]Applying chat template to train dataset:  41%|████      | 9980/24227 [00:03<00:04, 3140.35 examples/s]Applying chat template to train dataset:  41%|████      | 9910/24227 [00:03<00:04, 3171.26 examples/s]Applying chat template to train dataset:  41%|████▏     | 10004/24227 [00:03<00:04, 3192.47 examples/s]Applying chat template to train dataset:  43%|████▎     | 10442/24227 [00:03<00:04, 3117.18 examples/s]Applying chat template to train dataset:  42%|████▏     | 10229/24227 [00:03<00:04, 3171.69 examples/s]Applying chat template to train dataset:  43%|████▎     | 10466/24227 [00:03<00:04, 3147.72 examples/s]Applying chat template to train dataset:  45%|████▌     | 10905/24227 [00:03<00:04, 3102.52 examples/s]Applying chat template to train dataset:  44%|████▍     | 10691/24227 [00:03<00:04, 3129.31 examples/s]Applying chat template to train dataset:  45%|████▌     | 10924/24227 [00:03<00:04, 3111.79 examples/s]Applying chat template to train dataset:  47%|████▋     | 11367/24227 [00:03<00:04, 3092.07 examples/s]Applying chat template to train dataset:  46%|████▌     | 11158/24227 [00:03<00:04, 3119.74 examples/s]Applying chat template to train dataset:  47%|████▋     | 11382/24227 [00:03<00:04, 3087.78 examples/s]Applying chat template to train dataset:  49%|████▉     | 11829/24227 [00:04<00:04, 3082.94 examples/s]Applying chat template to train dataset:  48%|████▊     | 11624/24227 [00:03<00:04, 3111.86 examples/s]Applying chat template to train dataset:  50%|█████     | 12144/24227 [00:04<00:03, 3095.78 examples/s]Applying chat template to train dataset:  49%|████▉     | 11939/24227 [00:04<00:03, 3115.56 examples/s]Applying chat template to train dataset:  49%|████▉     | 11840/24227 [00:04<00:04, 3072.76 examples/s]Applying chat template to train dataset:  51%|█████▏    | 12460/24227 [00:04<00:03, 3106.45 examples/s]Applying chat template to train dataset:  51%|█████     | 12258/24227 [00:04<00:03, 3131.79 examples/s]Applying chat template to train dataset:  50%|█████     | 12153/24227 [00:04<00:03, 3084.03 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12776/24227 [00:04<00:03, 3118.50 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12574/24227 [00:04<00:03, 3136.99 examples/s]Applying chat template to train dataset:  51%|█████▏    | 12466/24227 [00:04<00:03, 3090.58 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13092/24227 [00:04<00:03, 3127.06 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12893/24227 [00:04<00:03, 3148.62 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12780/24227 [00:04<00:03, 3098.26 examples/s]Applying chat template to train dataset:  55%|█████▌    | 13408/24227 [00:04<00:03, 3130.73 examples/s]Applying chat template to train dataset:  55%|█████▍    | 13211/24227 [00:04<00:03, 3154.39 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13093/24227 [00:04<00:03, 3103.30 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13724/24227 [00:04<00:03, 3137.21 examples/s]Applying chat template to train dataset:  56%|█████▌    | 13530/24227 [00:04<00:03, 3159.60 examples/s]Applying chat template to train dataset:  55%|█████▌    | 13407/24227 [00:04<00:03, 3106.92 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14040/24227 [00:04<00:03, 3141.43 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13850/24227 [00:04<00:03, 3166.63 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13720/24227 [00:04<00:03, 3109.70 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14360/24227 [00:04<00:03, 3153.53 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14170/24227 [00:04<00:03, 3167.22 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14038/24227 [00:04<00:03, 3127.01 examples/s]Applying chat template to train dataset:  61%|██████    | 14677/24227 [00:04<00:03, 3155.63 examples/s]Applying chat template to train dataset:  60%|█████▉    | 14490/24227 [00:04<00:03, 3170.73 examples/s]Applying chat template to train dataset:  60%|█████▉    | 14507/24227 [00:04<00:03, 3124.46 examples/s]Applying chat template to train dataset:  61%|██████    | 14808/24227 [00:04<00:02, 3167.98 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15120/24227 [00:05<00:03, 2939.39 examples/s]Applying chat template to train dataset:  62%|██████▏   | 14973/24227 [00:05<00:02, 3114.55 examples/s]Applying chat template to train dataset:  64%|██████▎   | 15429/24227 [00:05<00:02, 2977.20 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15275/24227 [00:05<00:03, 2945.87 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15739/24227 [00:05<00:02, 3008.36 examples/s]Applying chat template to train dataset:  64%|██████▎   | 15426/24227 [00:05<00:03, 2928.69 examples/s]Applying chat template to train dataset:  64%|██████▍   | 15587/24227 [00:05<00:02, 2986.51 examples/s]Applying chat template to train dataset:  66%|██████▌   | 16049/24227 [00:05<00:02, 3031.34 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15740/24227 [00:05<00:02, 2973.44 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15900/24227 [00:05<00:02, 3019.42 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16359/24227 [00:05<00:02, 3048.81 examples/s]Applying chat template to train dataset:  66%|██████▋   | 16054/24227 [00:05<00:02, 3014.21 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16212/24227 [00:05<00:02, 3044.71 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16671/24227 [00:05<00:02, 3066.17 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16360/24227 [00:05<00:02, 3023.81 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16524/24227 [00:05<00:02, 3063.22 examples/s]Applying chat template to train dataset:  70%|███████   | 16990/24227 [00:05<00:02, 3093.61 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16670/24227 [00:05<00:02, 3039.85 examples/s]Applying chat template to train dataset:  70%|██████▉   | 16841/24227 [00:05<00:02, 3092.71 examples/s]Applying chat template to train dataset:  71%|███████▏  | 17308/24227 [00:05<00:02, 3115.95 examples/s]Applying chat template to train dataset:  70%|███████   | 16983/24227 [00:05<00:02, 3063.04 examples/s]Applying chat template to train dataset:  71%|███████   | 17160/24227 [00:05<00:02, 3117.95 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17623/24227 [00:05<00:02, 3125.16 examples/s]Applying chat template to train dataset:  71%|███████▏  | 17297/24227 [00:05<00:02, 3083.79 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17480/24227 [00:05<00:02, 3135.91 examples/s]Applying chat template to train dataset:  74%|███████▍  | 17940/24227 [00:05<00:02, 3133.82 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17609/24227 [00:05<00:02, 3092.15 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17800/24227 [00:05<00:02, 3146.26 examples/s]Applying chat template to train dataset:  75%|███████▌  | 18258/24227 [00:06<00:01, 3146.41 examples/s]Applying chat template to train dataset:  74%|███████▍  | 17921/24227 [00:06<00:02, 3096.75 examples/s]Applying chat template to train dataset:  75%|███████▍  | 18120/24227 [00:05<00:01, 3153.65 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18573/24227 [00:06<00:01, 3146.99 examples/s]Applying chat template to train dataset:  75%|███████▌  | 18234/24227 [00:06<00:01, 3105.33 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18440/24227 [00:06<00:01, 3157.53 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18890/24227 [00:06<00:01, 3149.27 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18548/24227 [00:06<00:01, 3112.22 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18761/24227 [00:06<00:01, 3165.56 examples/s]Applying chat template to train dataset:  79%|███████▉  | 19208/24227 [00:06<00:01, 3154.29 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18861/24227 [00:06<00:01, 3115.18 examples/s]Applying chat template to train dataset:  79%|███████▉  | 19080/24227 [00:06<00:01, 3168.94 examples/s]Applying chat template to train dataset:  81%|████████  | 19530/24227 [00:06<00:01, 3168.28 examples/s]Applying chat template to train dataset:  79%|███████▉  | 19176/24227 [00:06<00:01, 3122.30 examples/s]Applying chat template to train dataset:  80%|████████  | 19400/24227 [00:06<00:01, 3171.60 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19870/24227 [00:06<00:01, 2810.69 examples/s]Applying chat template to train dataset:  81%|████████  | 19529/24227 [00:06<00:01, 2819.64 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19787/24227 [00:06<00:01, 2936.23 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20193/24227 [00:06<00:01, 2920.90 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19852/24227 [00:06<00:01, 2928.00 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20110/24227 [00:06<00:01, 3013.32 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20515/24227 [00:06<00:01, 3002.87 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20173/24227 [00:06<00:01, 3003.52 examples/s]Applying chat template to train dataset:  84%|████████▍ | 20433/24227 [00:06<00:01, 3073.22 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20836/24227 [00:06<00:01, 3061.14 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20491/24227 [00:06<00:01, 3051.61 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20758/24227 [00:06<00:01, 3120.36 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21157/24227 [00:07<00:00, 3102.90 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20810/24227 [00:06<00:01, 3087.11 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21080/24227 [00:06<00:01, 3146.24 examples/s]Applying chat template to train dataset:  89%|████████▊ | 21479/24227 [00:07<00:00, 3132.62 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21128/24227 [00:07<00:00, 3112.79 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21404/24227 [00:07<00:00, 3169.21 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21799/24227 [00:07<00:00, 3150.71 examples/s]Applying chat template to train dataset:  89%|████████▊ | 21446/24227 [00:07<00:00, 3128.63 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21727/24227 [00:07<00:00, 3184.04 examples/s]Applying chat template to train dataset:  91%|█████████▏| 22121/24227 [00:07<00:00, 3165.11 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21764/24227 [00:07<00:00, 3143.23 examples/s]Applying chat template to train dataset:  91%|█████████ | 22051/24227 [00:07<00:00, 3196.17 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22441/24227 [00:07<00:00, 3174.66 examples/s]Applying chat template to train dataset:  91%|█████████ | 22081/24227 [00:07<00:00, 3148.98 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22375/24227 [00:07<00:00, 3206.75 examples/s]Applying chat template to train dataset:  94%|█████████▍| 22762/24227 [00:07<00:00, 3183.88 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22400/24227 [00:07<00:00, 3153.50 examples/s]Applying chat template to train dataset:  94%|█████████▎| 22699/24227 [00:07<00:00, 3214.38 examples/s]Applying chat template to train dataset:  95%|█████████▌| 23082/24227 [00:07<00:00, 3187.98 examples/s]Applying chat template to train dataset:  94%|█████████▍| 22718/24227 [00:07<00:00, 3160.75 examples/s]Applying chat template to train dataset:  95%|█████████▌| 23022/24227 [00:07<00:00, 3215.11 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23404/24227 [00:07<00:00, 3194.69 examples/s]Applying chat template to train dataset:  95%|█████████▌| 23040/24227 [00:07<00:00, 3174.36 examples/s]Applying chat template to train dataset:  96%|█████████▋| 23344/24227 [00:07<00:00, 3215.59 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23726/24227 [00:07<00:00, 3199.37 examples/s]Applying chat template to train dataset:  96%|█████████▋| 23367/24227 [00:07<00:00, 3201.97 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23669/24227 [00:07<00:00, 3222.34 examples/s]Applying chat template to train dataset:  99%|█████████▉| 24049/24227 [00:07<00:00, 3205.50 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23693/24227 [00:07<00:00, 3217.44 examples/s]Applying chat template to train dataset:  99%|█████████▉| 23992/24227 [00:07<00:00, 3222.77 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:08<00:00, 3023.46 examples/s]
Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:07<00:00, 3054.00 examples/s]
Applying chat template to train dataset:  99%|█████████▉| 24020/24227 [00:07<00:00, 3229.96 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:08<00:00, 3002.38 examples/s]
Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 405.89 examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 405.39 examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:58, 411.12 examples/s]Tokenizing train dataset:   0%|          | 90/24227 [00:00<01:11, 338.78 examples/s]Tokenizing train dataset:   0%|          | 90/24227 [00:00<01:11, 339.67 examples/s]Tokenizing train dataset:   0%|          | 90/24227 [00:00<01:10, 341.39 examples/s]Tokenizing train dataset:   1%|          | 138/24227 [00:00<01:15, 320.63 examples/s]Tokenizing train dataset:   1%|          | 138/24227 [00:00<01:14, 321.20 examples/s]Tokenizing train dataset:   1%|          | 139/24227 [00:00<01:14, 321.73 examples/s]Tokenizing train dataset:   1%|          | 182/24227 [00:00<01:19, 303.79 examples/s]Tokenizing train dataset:   1%|          | 182/24227 [00:00<01:18, 304.59 examples/s]Tokenizing train dataset:   1%|          | 218/24227 [00:00<01:16, 313.63 examples/s]Tokenizing train dataset:   1%|          | 183/24227 [00:00<01:18, 307.08 examples/s]Tokenizing train dataset:   1%|          | 218/24227 [00:00<01:16, 314.36 examples/s]Tokenizing train dataset:   1%|          | 251/24227 [00:00<01:15, 316.01 examples/s]Tokenizing train dataset:   1%|          | 218/24227 [00:00<01:16, 314.26 examples/s]Tokenizing train dataset:   1%|          | 251/24227 [00:00<01:15, 316.82 examples/s]Tokenizing train dataset:   1%|          | 289/24227 [00:00<01:12, 331.57 examples/s]Tokenizing train dataset:   1%|          | 251/24227 [00:00<01:15, 316.51 examples/s]Tokenizing train dataset:   1%|          | 289/24227 [00:00<01:12, 332.07 examples/s]Tokenizing train dataset:   1%|          | 289/24227 [00:00<01:12, 332.18 examples/s]Tokenizing train dataset:   1%|▏         | 337/24227 [00:01<01:13, 323.25 examples/s]Tokenizing train dataset:   1%|▏         | 337/24227 [00:01<01:13, 323.68 examples/s]Tokenizing train dataset:   1%|▏         | 337/24227 [00:01<01:13, 323.90 examples/s]Tokenizing train dataset:   2%|▏         | 387/24227 [00:01<01:14, 321.04 examples/s]Tokenizing train dataset:   2%|▏         | 387/24227 [00:01<01:14, 321.35 examples/s]Tokenizing train dataset:   2%|▏         | 387/24227 [00:01<01:14, 321.46 examples/s]Tokenizing train dataset:   2%|▏         | 434/24227 [00:01<01:16, 312.58 examples/s]Tokenizing train dataset:   2%|▏         | 434/24227 [00:01<01:16, 313.06 examples/s]Tokenizing train dataset:   2%|▏         | 434/24227 [00:01<01:15, 313.22 examples/s]Tokenizing train dataset:   2%|▏         | 480/24227 [00:01<01:17, 306.39 examples/s]Tokenizing train dataset:   2%|▏         | 480/24227 [00:01<01:17, 306.69 examples/s]Tokenizing train dataset:   2%|▏         | 480/24227 [00:01<01:17, 306.80 examples/s]Tokenizing train dataset:   2%|▏         | 527/24227 [00:01<01:17, 305.52 examples/s]Tokenizing train dataset:   2%|▏         | 527/24227 [00:01<01:17, 305.57 examples/s]Tokenizing train dataset:   2%|▏         | 561/24227 [00:01<01:16, 310.29 examples/s]Tokenizing train dataset:   2%|▏         | 527/24227 [00:01<01:17, 305.95 examples/s]Tokenizing train dataset:   2%|▏         | 561/24227 [00:01<01:16, 310.21 examples/s]Tokenizing train dataset:   2%|▏         | 561/24227 [00:01<01:16, 310.77 examples/s]Tokenizing train dataset:   2%|▏         | 605/24227 [00:01<01:18, 299.80 examples/s]Tokenizing train dataset:   2%|▏         | 605/24227 [00:01<01:18, 299.74 examples/s]Tokenizing train dataset:   3%|▎         | 643/24227 [00:02<01:14, 317.80 examples/s]Tokenizing train dataset:   2%|▏         | 605/24227 [00:01<01:18, 300.04 examples/s]Tokenizing train dataset:   3%|▎         | 643/24227 [00:02<01:14, 317.67 examples/s]Tokenizing train dataset:   3%|▎         | 644/24227 [00:02<01:14, 317.28 examples/s]Tokenizing train dataset:   3%|▎         | 689/24227 [00:02<01:16, 307.68 examples/s]Tokenizing train dataset:   3%|▎         | 689/24227 [00:02<01:16, 307.90 examples/s]Tokenizing train dataset:   3%|▎         | 689/24227 [00:02<01:16, 308.48 examples/s]Tokenizing train dataset:   3%|▎         | 740/24227 [00:02<01:14, 314.13 examples/s]Tokenizing train dataset:   3%|▎         | 740/24227 [00:02<01:14, 314.39 examples/s]Tokenizing train dataset:   3%|▎         | 740/24227 [00:02<01:14, 315.04 examples/s]Tokenizing train dataset:   3%|▎         | 785/24227 [00:02<01:16, 305.13 examples/s]Tokenizing train dataset:   3%|▎         | 785/24227 [00:02<01:16, 305.31 examples/s]Tokenizing train dataset:   3%|▎         | 785/24227 [00:02<01:16, 305.80 examples/s]Tokenizing train dataset:   3%|▎         | 827/24227 [00:02<01:20, 292.10 examples/s]Tokenizing train dataset:   3%|▎         | 827/24227 [00:02<01:20, 292.05 examples/s]Tokenizing train dataset:   4%|▎         | 860/24227 [00:02<01:18, 297.40 examples/s]Tokenizing train dataset:   3%|▎         | 827/24227 [00:02<01:20, 292.47 examples/s]Tokenizing train dataset:   4%|▎         | 860/24227 [00:02<01:18, 297.20 examples/s]Tokenizing train dataset:   4%|▎         | 897/24227 [00:02<01:14, 313.45 examples/s]Tokenizing train dataset:   4%|▎         | 860/24227 [00:02<01:18, 297.62 examples/s]Tokenizing train dataset:   4%|▎         | 897/24227 [00:02<01:14, 312.81 examples/s]Tokenizing train dataset:   4%|▎         | 897/24227 [00:02<01:14, 313.16 examples/s]Tokenizing train dataset:   4%|▍         | 942/24227 [00:03<01:16, 303.20 examples/s]Tokenizing train dataset:   4%|▍         | 940/24227 [00:03<01:17, 300.46 examples/s]Tokenizing train dataset:   4%|▍         | 973/24227 [00:03<01:16, 302.59 examples/s]Tokenizing train dataset:   4%|▍         | 940/24227 [00:03<01:17, 300.60 examples/s]Tokenizing train dataset:   4%|▍         | 972/24227 [00:03<01:16, 303.86 examples/s]Tokenizing train dataset:   4%|▍         | 1013/24227 [00:03<01:20, 287.20 examples/s]Tokenizing train dataset:   4%|▍         | 973/24227 [00:03<01:41, 229.82 examples/s]Tokenizing train dataset:   4%|▍         | 1014/24227 [00:03<01:41, 227.62 examples/s]Tokenizing train dataset:   4%|▍         | 1060/24227 [00:03<01:20, 289.01 examples/s]Tokenizing train dataset:   4%|▍         | 1000/24227 [00:03<01:38, 235.33 examples/s]Tokenizing train dataset:   4%|▍         | 1042/24227 [00:03<01:38, 236.23 examples/s]Tokenizing train dataset:   5%|▍         | 1095/24227 [00:03<01:16, 301.80 examples/s]Tokenizing train dataset:   4%|▍         | 1028/24227 [00:03<01:35, 243.74 examples/s]Tokenizing train dataset:   4%|▍         | 1074/24227 [00:03<01:31, 254.29 examples/s]Tokenizing train dataset:   4%|▍         | 1060/24227 [00:03<01:29, 258.23 examples/s]Tokenizing train dataset:   5%|▍         | 1137/24227 [00:03<01:19, 289.32 examples/s]Tokenizing train dataset:   5%|▍         | 1108/24227 [00:03<01:24, 273.71 examples/s]Tokenizing train dataset:   5%|▍         | 1095/24227 [00:03<01:22, 280.08 examples/s]Tokenizing train dataset:   5%|▍         | 1167/24227 [00:03<01:19, 289.86 examples/s]Tokenizing train dataset:   5%|▍         | 1151/24227 [00:03<01:24, 272.63 examples/s]Tokenizing train dataset:   5%|▍         | 1202/24227 [00:03<01:16, 300.59 examples/s]Tokenizing train dataset:   5%|▍         | 1137/24227 [00:03<01:23, 274.91 examples/s]Tokenizing train dataset:   5%|▍         | 1181/24227 [00:03<01:22, 278.09 examples/s]Tokenizing train dataset:   5%|▌         | 1236/24227 [00:04<01:14, 306.69 examples/s]Tokenizing train dataset:   5%|▍         | 1167/24227 [00:03<01:22, 279.14 examples/s]Tokenizing train dataset:   5%|▌         | 1214/24227 [00:04<01:20, 286.32 examples/s]Tokenizing train dataset:   5%|▌         | 1270/24227 [00:04<01:14, 308.86 examples/s]Tokenizing train dataset:   5%|▍         | 1202/24227 [00:04<01:18, 293.58 examples/s]Tokenizing train dataset:   5%|▌         | 1250/24227 [00:04<01:15, 303.24 examples/s]Tokenizing train dataset:   5%|▌         | 1304/24227 [00:04<01:13, 313.00 examples/s]Tokenizing train dataset:   5%|▌         | 1235/24227 [00:04<01:16, 299.77 examples/s]Tokenizing train dataset:   6%|▌         | 1338/24227 [00:04<01:12, 316.86 examples/s]Tokenizing train dataset:   5%|▌         | 1299/24227 [00:04<01:14, 307.48 examples/s]Tokenizing train dataset:   5%|▌         | 1270/24227 [00:04<01:15, 305.72 examples/s]Tokenizing train dataset:   5%|▌         | 1331/24227 [00:04<01:14, 307.45 examples/s]Tokenizing train dataset:   5%|▌         | 1304/24227 [00:04<01:13, 310.98 examples/s]Tokenizing train dataset:   6%|▌         | 1379/24227 [00:04<01:17, 295.48 examples/s]Tokenizing train dataset:   6%|▌         | 1339/24227 [00:04<01:12, 314.92 examples/s]Tokenizing train dataset:   6%|▌         | 1410/24227 [00:04<01:17, 295.40 examples/s]Tokenizing train dataset:   6%|▌         | 1373/24227 [00:04<01:17, 293.21 examples/s]Tokenizing train dataset:   6%|▌         | 1440/24227 [00:04<01:17, 293.55 examples/s]Tokenizing train dataset:   6%|▌         | 1407/24227 [00:04<01:16, 299.93 examples/s]Tokenizing train dataset:   6%|▌         | 1379/24227 [00:04<01:17, 295.11 examples/s]Tokenizing train dataset:   6%|▌         | 1472/24227 [00:04<01:16, 298.52 examples/s]Tokenizing train dataset:   6%|▌         | 1410/24227 [00:04<01:17, 295.11 examples/s]Tokenizing train dataset:   6%|▌         | 1452/24227 [00:04<01:16, 297.35 examples/s]Tokenizing train dataset:   6%|▌         | 1440/24227 [00:04<01:17, 293.33 examples/s]Tokenizing train dataset:   6%|▌         | 1514/24227 [00:04<01:19, 286.90 examples/s]Tokenizing train dataset:   6%|▌         | 1495/24227 [00:05<01:17, 291.78 examples/s]Tokenizing train dataset:   6%|▌         | 1472/24227 [00:04<01:16, 298.62 examples/s]Tokenizing train dataset:   6%|▋         | 1548/24227 [00:05<01:15, 298.76 examples/s]Tokenizing train dataset:   6%|▋         | 1526/24227 [00:05<01:17, 294.64 examples/s]Tokenizing train dataset:   7%|▋         | 1591/24227 [00:05<01:17, 292.35 examples/s]Tokenizing train dataset:   6%|▌         | 1514/24227 [00:05<01:19, 286.87 examples/s]Tokenizing train dataset:   6%|▋         | 1558/24227 [00:05<01:16, 297.77 examples/s]Tokenizing train dataset:   6%|▋         | 1548/24227 [00:05<01:15, 298.85 examples/s]Tokenizing train dataset:   7%|▋         | 1627/24227 [00:05<01:14, 302.09 examples/s]Tokenizing train dataset:   7%|▋         | 1602/24227 [00:05<01:17, 293.67 examples/s]Tokenizing train dataset:   7%|▋         | 1661/24227 [00:05<01:12, 309.54 examples/s]Tokenizing train dataset:   7%|▋         | 1591/24227 [00:05<01:17, 292.32 examples/s]Tokenizing train dataset:   7%|▋         | 1637/24227 [00:05<01:14, 302.91 examples/s]Tokenizing train dataset:   7%|▋         | 1701/24227 [00:05<01:08, 328.67 examples/s]Tokenizing train dataset:   7%|▋         | 1627/24227 [00:05<01:14, 302.06 examples/s]Tokenizing train dataset:   7%|▋         | 1670/24227 [00:05<01:13, 307.36 examples/s]Tokenizing train dataset:   7%|▋         | 1661/24227 [00:05<01:12, 309.63 examples/s]Tokenizing train dataset:   7%|▋         | 1751/24227 [00:05<01:08, 325.78 examples/s]Tokenizing train dataset:   7%|▋         | 1710/24227 [00:05<01:09, 324.93 examples/s]Tokenizing train dataset:   7%|▋         | 1701/24227 [00:05<01:08, 328.81 examples/s]Tokenizing train dataset:   7%|▋         | 1788/24227 [00:05<01:06, 335.48 examples/s]Tokenizing train dataset:   7%|▋         | 1746/24227 [00:05<01:07, 330.86 examples/s]Tokenizing train dataset:   7%|▋         | 1781/24227 [00:05<01:07, 332.01 examples/s]Tokenizing train dataset:   7%|▋         | 1751/24227 [00:05<01:08, 326.25 examples/s]Tokenizing train dataset:   8%|▊         | 1829/24227 [00:05<01:12, 309.48 examples/s]Tokenizing train dataset:   7%|▋         | 1788/24227 [00:05<01:06, 335.91 examples/s]Tokenizing train dataset:   8%|▊         | 1826/24227 [00:06<01:11, 312.96 examples/s]Tokenizing train dataset:   8%|▊         | 1874/24227 [00:06<01:13, 304.44 examples/s]Tokenizing train dataset:   8%|▊         | 1829/24227 [00:06<01:12, 310.05 examples/s]Tokenizing train dataset:   8%|▊         | 1872/24227 [00:06<01:13, 305.01 examples/s]Tokenizing train dataset:   8%|▊         | 1910/24227 [00:06<01:19, 281.03 examples/s]Tokenizing train dataset:   8%|▊         | 1875/24227 [00:06<01:13, 305.79 examples/s]Tokenizing train dataset:   8%|▊         | 1953/24227 [00:06<01:19, 280.07 examples/s]Tokenizing train dataset:   8%|▊         | 1910/24227 [00:06<01:19, 281.20 examples/s]Tokenizing train dataset:   8%|▊         | 1913/24227 [00:06<01:18, 282.48 examples/s]Tokenizing train dataset:   8%|▊         | 1997/24227 [00:06<01:18, 282.31 examples/s]Tokenizing train dataset:   8%|▊         | 1953/24227 [00:06<01:19, 279.98 examples/s]Tokenizing train dataset:   8%|▊         | 2030/24227 [00:06<01:16, 291.08 examples/s]Tokenizing train dataset:   8%|▊         | 1956/24227 [00:06<01:19, 279.46 examples/s]Tokenizing train dataset:   8%|▊         | 1997/24227 [00:06<01:18, 281.97 examples/s]Tokenizing train dataset:   9%|▊         | 2068/24227 [00:06<01:11, 310.73 examples/s]Tokenizing train dataset:   8%|▊         | 2030/24227 [00:06<01:16, 290.81 examples/s]Tokenizing train dataset:   8%|▊         | 2000/24227 [00:06<01:19, 281.26 examples/s]Tokenizing train dataset:   9%|▊         | 2101/24227 [00:06<01:11, 311.61 examples/s]Tokenizing train dataset:   9%|▊         | 2068/24227 [00:06<01:11, 310.19 examples/s]Tokenizing train dataset:   8%|▊         | 2033/24227 [00:06<01:16, 291.21 examples/s]Tokenizing train dataset:   9%|▉         | 2147/24227 [00:07<01:11, 307.81 examples/s]Tokenizing train dataset:   9%|▊         | 2101/24227 [00:07<01:11, 311.08 examples/s]Tokenizing train dataset:   9%|▊         | 2071/24227 [00:06<01:11, 309.43 examples/s]Tokenizing train dataset:   9%|▉         | 2179/24227 [00:07<01:12, 305.05 examples/s]Tokenizing train dataset:   9%|▊         | 2106/24227 [00:07<01:10, 314.57 examples/s]Tokenizing train dataset:   9%|▉         | 2147/24227 [00:07<01:11, 306.95 examples/s]Tokenizing train dataset:   9%|▉         | 2222/24227 [00:07<01:14, 295.53 examples/s]Tokenizing train dataset:   9%|▉         | 2151/24227 [00:07<01:12, 303.47 examples/s]Tokenizing train dataset:   9%|▉         | 2192/24227 [00:07<01:13, 299.28 examples/s]Tokenizing train dataset:   9%|▉         | 2259/24227 [00:07<01:10, 310.95 examples/s]Tokenizing train dataset:   9%|▉         | 2196/24227 [00:07<01:13, 300.73 examples/s]Tokenizing train dataset:   9%|▉         | 2241/24227 [00:07<01:12, 305.11 examples/s]Tokenizing train dataset:  10%|▉         | 2305/24227 [00:07<01:12, 303.87 examples/s]Tokenizing train dataset:   9%|▉         | 2275/24227 [00:07<01:11, 308.36 examples/s]Tokenizing train dataset:   9%|▉         | 2246/24227 [00:07<01:11, 307.55 examples/s]Tokenizing train dataset:  10%|▉         | 2349/24227 [00:07<01:14, 294.42 examples/s]Tokenizing train dataset:   9%|▉         | 2293/24227 [00:07<01:11, 307.66 examples/s]Tokenizing train dataset:  10%|▉         | 2321/24227 [00:07<01:12, 303.50 examples/s]Tokenizing train dataset:  10%|▉         | 2380/24227 [00:07<01:14, 294.01 examples/s]Tokenizing train dataset:  10%|▉         | 2324/24227 [00:07<01:11, 306.27 examples/s]Tokenizing train dataset:  10%|▉         | 2410/24227 [00:07<01:14, 293.22 examples/s]Tokenizing train dataset:  10%|▉         | 2365/24227 [00:07<01:14, 295.04 examples/s]Tokenizing train dataset:  10%|▉         | 2367/24227 [00:07<01:13, 295.89 examples/s]Tokenizing train dataset:  10%|█         | 2443/24227 [00:08<01:13, 297.32 examples/s]Tokenizing train dataset:  10%|▉         | 2395/24227 [00:07<01:14, 292.64 examples/s]Tokenizing train dataset:  10%|█         | 2428/24227 [00:08<01:13, 297.06 examples/s]Tokenizing train dataset:  10%|▉         | 2412/24227 [00:08<01:14, 292.18 examples/s]Tokenizing train dataset:  10%|█         | 2491/24227 [00:08<01:12, 299.05 examples/s]Tokenizing train dataset:  10%|█         | 2445/24227 [00:08<01:13, 295.73 examples/s]Tokenizing train dataset:  10%|█         | 2471/24227 [00:08<01:15, 287.59 examples/s]Tokenizing train dataset:  10%|█         | 2524/24227 [00:08<01:20, 270.43 examples/s]Tokenizing train dataset:  11%|█         | 2558/24227 [00:08<01:26, 249.80 examples/s]Tokenizing train dataset:  10%|█         | 2475/24227 [00:08<01:33, 231.45 examples/s]Tokenizing train dataset:  10%|█         | 2512/24227 [00:08<01:34, 229.19 examples/s]Tokenizing train dataset:  11%|█         | 2592/24227 [00:08<01:20, 269.41 examples/s]Tokenizing train dataset:  10%|█         | 2501/24227 [00:08<01:32, 235.92 examples/s]Tokenizing train dataset:  10%|█         | 2540/24227 [00:08<01:31, 236.78 examples/s]Tokenizing train dataset:  11%|█         | 2627/24227 [00:08<01:15, 285.57 examples/s]Tokenizing train dataset:  10%|█         | 2540/24227 [00:08<01:29, 242.45 examples/s]Tokenizing train dataset:  11%|█         | 2574/24227 [00:08<01:24, 257.62 examples/s]Tokenizing train dataset:  11%|█         | 2660/24227 [00:08<01:13, 295.07 examples/s]Tokenizing train dataset:  11%|█         | 2574/24227 [00:08<01:22, 262.92 examples/s]Tokenizing train dataset:  11%|█         | 2611/24227 [00:08<01:16, 281.19 examples/s]Tokenizing train dataset:  11%|█         | 2695/24227 [00:08<01:10, 305.96 examples/s]Tokenizing train dataset:  11%|█         | 2611/24227 [00:08<01:15, 285.75 examples/s]Tokenizing train dataset:  11%|█         | 2645/24227 [00:08<01:13, 293.44 examples/s]Tokenizing train dataset:  11%|█▏        | 2727/24227 [00:09<01:10, 306.66 examples/s]Tokenizing train dataset:  11%|█         | 2645/24227 [00:08<01:12, 297.22 examples/s]Tokenizing train dataset:  11%|█         | 2676/24227 [00:09<01:13, 294.36 examples/s]Tokenizing train dataset:  11%|█         | 2676/24227 [00:09<01:12, 297.06 examples/s]Tokenizing train dataset:  11%|█         | 2712/24227 [00:09<01:09, 311.24 examples/s]Tokenizing train dataset:  11%|█▏        | 2770/24227 [00:09<01:12, 295.65 examples/s]Tokenizing train dataset:  11%|█         | 2712/24227 [00:09<01:08, 313.33 examples/s]Tokenizing train dataset:  12%|█▏        | 2804/24227 [00:09<01:10, 304.02 examples/s]Tokenizing train dataset:  11%|█▏        | 2756/24227 [00:09<01:11, 300.41 examples/s]Tokenizing train dataset:  11%|█▏        | 2756/24227 [00:09<01:11, 301.56 examples/s]Tokenizing train dataset:  12%|█▏        | 2787/24227 [00:09<01:11, 300.75 examples/s]Tokenizing train dataset:  12%|█▏        | 2848/24227 [00:09<01:12, 295.74 examples/s]Tokenizing train dataset:  12%|█▏        | 2818/24227 [00:09<01:11, 299.74 examples/s]Tokenizing train dataset:  12%|█▏        | 2788/24227 [00:09<01:11, 300.56 examples/s]Tokenizing train dataset:  12%|█▏        | 2879/24227 [00:09<01:12, 294.91 examples/s]Tokenizing train dataset:  12%|█▏        | 2820/24227 [00:09<01:10, 301.80 examples/s]Tokenizing train dataset:  12%|█▏        | 2910/24227 [00:09<01:11, 296.86 examples/s]Tokenizing train dataset:  12%|█▏        | 2863/24227 [00:09<01:12, 293.23 examples/s]Tokenizing train dataset:  12%|█▏        | 2942/24227 [00:09<01:11, 299.44 examples/s]Tokenizing train dataset:  12%|█▏        | 2863/24227 [00:09<01:12, 293.99 examples/s]Tokenizing train dataset:  12%|█▏        | 2895/24227 [00:09<01:11, 297.20 examples/s]Tokenizing train dataset:  12%|█▏        | 2974/24227 [00:09<01:10, 301.36 examples/s]Tokenizing train dataset:  12%|█▏        | 2895/24227 [00:09<01:11, 297.94 examples/s]Tokenizing train dataset:  12%|█▏        | 2942/24227 [00:09<01:11, 298.62 examples/s]Tokenizing train dataset:  12%|█▏        | 3005/24227 [00:09<01:11, 297.79 examples/s]Tokenizing train dataset:  12%|█▏        | 2942/24227 [00:09<01:11, 299.43 examples/s]Tokenizing train dataset:  12%|█▏        | 2974/24227 [00:10<01:10, 300.63 examples/s]Tokenizing train dataset:  13%|█▎        | 3051/24227 [00:10<01:11, 297.82 examples/s]Tokenizing train dataset:  12%|█▏        | 2974/24227 [00:10<01:10, 301.34 examples/s]Tokenizing train dataset:  12%|█▏        | 3005/24227 [00:10<01:11, 297.46 examples/s]Tokenizing train dataset:  12%|█▏        | 3005/24227 [00:10<01:11, 298.27 examples/s]Tokenizing train dataset:  13%|█▎        | 3094/24227 [00:10<01:12, 292.16 examples/s]Tokenizing train dataset:  13%|█▎        | 3051/24227 [00:10<01:11, 297.69 examples/s]Tokenizing train dataset:  13%|█▎        | 3126/24227 [00:10<01:11, 294.44 examples/s]Tokenizing train dataset:  13%|█▎        | 3051/24227 [00:10<01:10, 298.44 examples/s]Tokenizing train dataset:  13%|█▎        | 3094/24227 [00:10<01:12, 292.36 examples/s]Tokenizing train dataset:  13%|█▎        | 3170/24227 [00:10<01:12, 289.84 examples/s]Tokenizing train dataset:  13%|█▎        | 3094/24227 [00:10<01:12, 292.81 examples/s]Tokenizing train dataset:  13%|█▎        | 3126/24227 [00:10<01:11, 294.41 examples/s]Tokenizing train dataset:  13%|█▎        | 3204/24227 [00:10<01:10, 298.72 examples/s]Tokenizing train dataset:  13%|█▎        | 3126/24227 [00:10<01:11, 294.93 examples/s]Tokenizing train dataset:  13%|█▎        | 3170/24227 [00:10<01:12, 289.76 examples/s]Tokenizing train dataset:  13%|█▎        | 3235/24227 [00:10<01:10, 297.17 examples/s]Tokenizing train dataset:  13%|█▎        | 3170/24227 [00:10<01:12, 290.17 examples/s]Tokenizing train dataset:  13%|█▎        | 3204/24227 [00:10<01:10, 298.41 examples/s]Tokenizing train dataset:  13%|█▎        | 3269/24227 [00:10<01:08, 305.93 examples/s]Tokenizing train dataset:  13%|█▎        | 3204/24227 [00:10<01:10, 298.98 examples/s]Tokenizing train dataset:  13%|█▎        | 3235/24227 [00:10<01:10, 296.91 examples/s]Tokenizing train dataset:  14%|█▎        | 3300/24227 [00:10<01:09, 302.72 examples/s]Tokenizing train dataset:  13%|█▎        | 3235/24227 [00:10<01:10, 297.61 examples/s]Tokenizing train dataset:  13%|█▎        | 3269/24227 [00:11<01:08, 305.48 examples/s]Tokenizing train dataset:  14%|█▍        | 3347/24227 [00:11<01:08, 302.72 examples/s]Tokenizing train dataset:  13%|█▎        | 3269/24227 [00:11<01:08, 306.31 examples/s]Tokenizing train dataset:  14%|█▎        | 3300/24227 [00:11<01:09, 302.48 examples/s]Tokenizing train dataset:  14%|█▎        | 3300/24227 [00:11<01:09, 303.02 examples/s]Tokenizing train dataset:  14%|█▍        | 3387/24227 [00:11<01:13, 285.04 examples/s]Tokenizing train dataset:  14%|█▍        | 3347/24227 [00:11<01:09, 302.47 examples/s]Tokenizing train dataset:  14%|█▍        | 3347/24227 [00:11<01:08, 303.01 examples/s]Tokenizing train dataset:  14%|█▍        | 3428/24227 [00:11<01:14, 278.98 examples/s]Tokenizing train dataset:  14%|█▍        | 3387/24227 [00:11<01:13, 285.04 examples/s]Tokenizing train dataset:  14%|█▍        | 3387/24227 [00:11<01:13, 285.34 examples/s]Tokenizing train dataset:  14%|█▍        | 3465/24227 [00:11<01:19, 262.65 examples/s]Tokenizing train dataset:  14%|█▍        | 3428/24227 [00:11<01:14, 278.86 examples/s]Tokenizing train dataset:  14%|█▍        | 3428/24227 [00:11<01:14, 279.34 examples/s]Tokenizing train dataset:  15%|█▍        | 3514/24227 [00:11<01:14, 278.45 examples/s]Tokenizing train dataset:  14%|█▍        | 3465/24227 [00:11<01:18, 262.89 examples/s]Tokenizing train dataset:  15%|█▍        | 3548/24227 [00:11<01:11, 288.35 examples/s]Tokenizing train dataset:  14%|█▍        | 3465/24227 [00:11<01:18, 263.50 examples/s]Tokenizing train dataset:  15%|█▍        | 3585/24227 [00:11<01:07, 307.44 examples/s]Tokenizing train dataset:  15%|█▍        | 3515/24227 [00:11<01:13, 280.50 examples/s]Tokenizing train dataset:  15%|█▍        | 3515/24227 [00:11<01:13, 281.12 examples/s]Tokenizing train dataset:  15%|█▍        | 3548/24227 [00:12<01:11, 288.06 examples/s]Tokenizing train dataset:  15%|█▍        | 3633/24227 [00:12<01:07, 305.98 examples/s]Tokenizing train dataset:  15%|█▍        | 3548/24227 [00:12<01:11, 288.70 examples/s]Tokenizing train dataset:  15%|█▍        | 3585/24227 [00:12<01:07, 306.89 examples/s]Tokenizing train dataset:  15%|█▌        | 3668/24227 [00:12<01:05, 314.22 examples/s]Tokenizing train dataset:  15%|█▍        | 3585/24227 [00:12<01:07, 307.78 examples/s]Tokenizing train dataset:  15%|█▍        | 3633/24227 [00:12<01:07, 305.60 examples/s]Tokenizing train dataset:  15%|█▌        | 3710/24227 [00:12<01:08, 299.25 examples/s]Tokenizing train dataset:  15%|█▍        | 3632/24227 [00:12<01:07, 306.25 examples/s]Tokenizing train dataset:  15%|█▌        | 3668/24227 [00:12<01:05, 313.84 examples/s]Tokenizing train dataset:  15%|█▌        | 3666/24227 [00:12<01:05, 313.65 examples/s]Tokenizing train dataset:  16%|█▌        | 3756/24227 [00:12<01:08, 300.19 examples/s]Tokenizing train dataset:  15%|█▌        | 3710/24227 [00:12<01:08, 299.14 examples/s]Tokenizing train dataset:  16%|█▌        | 3789/24227 [00:12<01:07, 303.42 examples/s]Tokenizing train dataset:  15%|█▌        | 3710/24227 [00:12<01:08, 299.92 examples/s]Tokenizing train dataset:  16%|█▌        | 3756/24227 [00:12<01:08, 300.41 examples/s]Tokenizing train dataset:  16%|█▌        | 3826/24227 [00:12<01:04, 317.10 examples/s]Tokenizing train dataset:  16%|█▌        | 3756/24227 [00:12<01:07, 301.35 examples/s]Tokenizing train dataset:  16%|█▌        | 3789/24227 [00:12<01:07, 303.67 examples/s]Tokenizing train dataset:  16%|█▌        | 3873/24227 [00:12<01:04, 313.73 examples/s]Tokenizing train dataset:  16%|█▌        | 3789/24227 [00:12<01:07, 304.64 examples/s]Tokenizing train dataset:  16%|█▌        | 3826/24227 [00:12<01:04, 317.07 examples/s]Tokenizing train dataset:  16%|█▌        | 3826/24227 [00:12<01:04, 318.27 examples/s]Tokenizing train dataset:  16%|█▌        | 3916/24227 [00:13<01:07, 302.91 examples/s]Tokenizing train dataset:  16%|█▌        | 3873/24227 [00:13<01:04, 313.77 examples/s]Tokenizing train dataset:  16%|█▌        | 3859/24227 [00:12<01:03, 318.26 examples/s]Tokenizing train dataset:  16%|█▋        | 3961/24227 [00:13<01:08, 295.21 examples/s]Tokenizing train dataset:  16%|█▌        | 3916/24227 [00:13<01:07, 302.85 examples/s]Tokenizing train dataset:  16%|█▌        | 3904/24227 [00:13<01:05, 309.64 examples/s]Tokenizing train dataset:  16%|█▋        | 3991/24227 [00:13<01:08, 293.93 examples/s]Tokenizing train dataset:  16%|█▋        | 3961/24227 [00:13<01:08, 294.93 examples/s]Tokenizing train dataset:  17%|█▋        | 4022/24227 [00:13<01:08, 293.54 examples/s]Tokenizing train dataset:  16%|█▋        | 3943/24227 [00:13<01:10, 288.11 examples/s]Tokenizing train dataset:  16%|█▋        | 3991/24227 [00:13<01:47, 187.84 examples/s]Tokenizing train dataset:  17%|█▋        | 4053/24227 [00:13<01:51, 181.03 examples/s]Tokenizing train dataset:  16%|█▋        | 3979/24227 [00:13<01:40, 201.35 examples/s]Tokenizing train dataset:  17%|█▋        | 4086/24227 [00:13<01:36, 207.75 examples/s]Tokenizing train dataset:  17%|█▋        | 4022/24227 [00:13<01:37, 206.76 examples/s]Tokenizing train dataset:  17%|█▋        | 4010/24227 [00:13<01:32, 219.51 examples/s]Tokenizing train dataset:  17%|█▋        | 4120/24227 [00:13<01:26, 231.49 examples/s]Tokenizing train dataset:  17%|█▋        | 4053/24227 [00:13<01:29, 224.98 examples/s]Tokenizing train dataset:  17%|█▋        | 4041/24227 [00:13<01:25, 236.42 examples/s]Tokenizing train dataset:  17%|█▋        | 4154/24227 [00:14<01:18, 254.90 examples/s]Tokenizing train dataset:  17%|█▋        | 4086/24227 [00:14<01:21, 246.98 examples/s]Tokenizing train dataset:  17%|█▋        | 4070/24227 [00:13<01:22, 245.17 examples/s]Tokenizing train dataset:  17%|█▋        | 4190/24227 [00:14<01:12, 275.40 examples/s]Tokenizing train dataset:  17%|█▋        | 4120/24227 [00:14<01:16, 264.10 examples/s]Tokenizing train dataset:  17%|█▋        | 4107/24227 [00:14<01:13, 273.59 examples/s]Tokenizing train dataset:  17%|█▋        | 4154/24227 [00:14<01:11, 281.31 examples/s]Tokenizing train dataset:  17%|█▋        | 4140/24227 [00:14<01:10, 285.43 examples/s]Tokenizing train dataset:  17%|█▋        | 4222/24227 [00:14<01:10, 282.18 examples/s]Tokenizing train dataset:  17%|█▋        | 4189/24227 [00:14<01:07, 296.85 examples/s]Tokenizing train dataset:  17%|█▋        | 4172/24227 [00:14<01:08, 291.34 examples/s]Tokenizing train dataset:  18%|█▊        | 4268/24227 [00:14<01:09, 288.46 examples/s]Tokenizing train dataset:  17%|█▋        | 4208/24227 [00:14<01:05, 307.01 examples/s]Tokenizing train dataset:  17%|█▋        | 4235/24227 [00:14<01:07, 296.05 examples/s]Tokenizing train dataset:  18%|█▊        | 4311/24227 [00:14<01:09, 285.60 examples/s]Tokenizing train dataset:  18%|█▊        | 4253/24227 [00:14<01:06, 299.57 examples/s]Tokenizing train dataset:  18%|█▊        | 4344/24227 [00:14<01:07, 293.60 examples/s]Tokenizing train dataset:  18%|█▊        | 4281/24227 [00:14<01:07, 296.06 examples/s]Tokenizing train dataset:  18%|█▊        | 4297/24227 [00:14<01:07, 296.08 examples/s]Tokenizing train dataset:  18%|█▊        | 4389/24227 [00:14<01:07, 293.61 examples/s]Tokenizing train dataset:  18%|█▊        | 4323/24227 [00:14<01:08, 288.83 examples/s]Tokenizing train dataset:  18%|█▊        | 4422/24227 [00:14<01:05, 300.63 examples/s]Tokenizing train dataset:  18%|█▊        | 4344/24227 [00:14<01:06, 298.39 examples/s]Tokenizing train dataset:  18%|█▊        | 4358/24227 [00:14<01:06, 296.86 examples/s]Tokenizing train dataset:  18%|█▊        | 4455/24227 [00:15<01:04, 307.25 examples/s]Tokenizing train dataset:  18%|█▊        | 4389/24227 [00:15<01:06, 298.22 examples/s]Tokenizing train dataset:  18%|█▊        | 4389/24227 [00:14<01:06, 296.95 examples/s]Tokenizing train dataset:  18%|█▊        | 4422/24227 [00:15<01:05, 304.38 examples/s]Tokenizing train dataset:  18%|█▊        | 4422/24227 [00:15<01:05, 303.02 examples/s]Tokenizing train dataset:  19%|█▊        | 4501/24227 [00:15<01:06, 298.05 examples/s]Tokenizing train dataset:  18%|█▊        | 4455/24227 [00:15<01:03, 309.82 examples/s]Tokenizing train dataset:  18%|█▊        | 4455/24227 [00:15<01:04, 308.65 examples/s]Tokenizing train dataset:  19%|█▊        | 4532/24227 [00:15<01:06, 295.89 examples/s]Tokenizing train dataset:  19%|█▊        | 4500/24227 [00:15<01:05, 299.48 examples/s]Tokenizing train dataset:  19%|█▉        | 4563/24227 [00:15<01:06, 297.30 examples/s]Tokenizing train dataset:  19%|█▊        | 4501/24227 [00:15<01:05, 299.46 examples/s]Tokenizing train dataset:  19%|█▉        | 4593/24227 [00:15<01:06, 295.85 examples/s]Tokenizing train dataset:  19%|█▊        | 4531/24227 [00:15<01:05, 298.81 examples/s]Tokenizing train dataset:  19%|█▊        | 4532/24227 [00:15<01:06, 297.16 examples/s]Tokenizing train dataset:  19%|█▉        | 4624/24227 [00:15<01:06, 294.54 examples/s]Tokenizing train dataset:  19%|█▉        | 4573/24227 [00:15<01:08, 288.21 examples/s]Tokenizing train dataset:  19%|█▉        | 4564/24227 [00:15<01:06, 297.71 examples/s]Tokenizing train dataset:  19%|█▉        | 4654/24227 [00:15<01:06, 293.88 examples/s]Tokenizing train dataset:  19%|█▉        | 4608/24227 [00:15<01:05, 300.48 examples/s]Tokenizing train dataset:  19%|█▉        | 4596/24227 [00:15<01:05, 299.66 examples/s]Tokenizing train dataset:  19%|█▉        | 4698/24227 [00:15<01:06, 291.58 examples/s]Tokenizing train dataset:  19%|█▉        | 4627/24227 [00:15<01:06, 294.52 examples/s]Tokenizing train dataset:  19%|█▉        | 4651/24227 [00:15<01:06, 293.69 examples/s]Tokenizing train dataset:  19%|█▉        | 4658/24227 [00:15<01:06, 295.98 examples/s]Tokenizing train dataset:  20%|█▉        | 4744/24227 [00:16<01:06, 292.90 examples/s]Tokenizing train dataset:  19%|█▉        | 4696/24227 [00:16<01:06, 292.33 examples/s]Tokenizing train dataset:  19%|█▉        | 4688/24227 [00:15<01:06, 295.23 examples/s]Tokenizing train dataset:  20%|█▉        | 4788/24227 [00:16<01:07, 289.47 examples/s]Tokenizing train dataset:  20%|█▉        | 4743/24227 [00:16<01:06, 294.92 examples/s]Tokenizing train dataset:  20%|█▉        | 4733/24227 [00:16<01:07, 289.88 examples/s]Tokenizing train dataset:  20%|█▉        | 4819/24227 [00:16<01:06, 290.89 examples/s]Tokenizing train dataset:  20%|█▉        | 4773/24227 [00:16<01:07, 289.88 examples/s]Tokenizing train dataset:  20%|█▉        | 4764/24227 [00:16<01:06, 291.93 examples/s]Tokenizing train dataset:  20%|██        | 4860/24227 [00:16<01:09, 280.28 examples/s]Tokenizing train dataset:  20%|█▉        | 4819/24227 [00:16<01:06, 290.92 examples/s]Tokenizing train dataset:  20%|█▉        | 4810/24227 [00:16<01:06, 291.84 examples/s]Tokenizing train dataset:  20%|██        | 4890/24227 [00:16<01:08, 282.15 examples/s]Tokenizing train dataset:  20%|██        | 4919/24227 [00:16<01:08, 281.13 examples/s]Tokenizing train dataset:  20%|██        | 4860/24227 [00:16<01:08, 280.99 examples/s]Tokenizing train dataset:  20%|██        | 4851/24227 [00:16<01:08, 281.23 examples/s]Tokenizing train dataset:  20%|██        | 4890/24227 [00:16<01:08, 282.78 examples/s]Tokenizing train dataset:  20%|██        | 4950/24227 [00:16<01:10, 273.19 examples/s]Tokenizing train dataset:  20%|██        | 4896/24227 [00:16<01:08, 283.86 examples/s]Tokenizing train dataset:  21%|██        | 4980/24227 [00:16<01:09, 278.49 examples/s]Tokenizing train dataset:  20%|██        | 4936/24227 [00:16<01:07, 287.45 examples/s]Tokenizing train dataset:  20%|██        | 4925/24227 [00:16<01:08, 282.20 examples/s]Tokenizing train dataset:  21%|██        | 5014/24227 [00:16<01:06, 289.79 examples/s]Tokenizing train dataset:  20%|██        | 4964/24227 [00:16<01:10, 272.70 examples/s]Tokenizing train dataset:  21%|██        | 5050/24227 [00:17<01:02, 305.38 examples/s]Tokenizing train dataset:  21%|██        | 4980/24227 [00:17<01:09, 275.49 examples/s]Tokenizing train dataset:  21%|██        | 4998/24227 [00:17<01:06, 287.28 examples/s]Tokenizing train dataset:  21%|██        | 5014/24227 [00:17<01:07, 285.54 examples/s]Tokenizing train dataset:  21%|██        | 5093/24227 [00:17<01:04, 294.62 examples/s]Tokenizing train dataset:  21%|██        | 5033/24227 [00:17<01:04, 298.43 examples/s]Tokenizing train dataset:  21%|██        | 5050/24227 [00:17<01:03, 300.19 examples/s]Tokenizing train dataset:  21%|██        | 5138/24227 [00:17<01:04, 294.33 examples/s]Tokenizing train dataset:  21%|██        | 5066/24227 [00:17<01:03, 300.66 examples/s]Tokenizing train dataset:  21%|██        | 5095/24227 [00:17<01:05, 291.90 examples/s]Tokenizing train dataset:  21%|██▏       | 5181/24227 [00:17<01:06, 287.02 examples/s]Tokenizing train dataset:  21%|██        | 5110/24227 [00:17<01:05, 292.04 examples/s]Tokenizing train dataset:  21%|██        | 5125/24227 [00:17<01:05, 291.77 examples/s]Tokenizing train dataset:  22%|██▏       | 5212/24227 [00:17<01:05, 291.39 examples/s]Tokenizing train dataset:  21%|██        | 5140/24227 [00:17<01:05, 290.76 examples/s]Tokenizing train dataset:  21%|██▏       | 5155/24227 [00:17<01:05, 290.94 examples/s]Tokenizing train dataset:  22%|██▏       | 5243/24227 [00:17<01:04, 294.17 examples/s]Tokenizing train dataset:  21%|██▏       | 5184/24227 [00:17<01:05, 289.36 examples/s]Tokenizing train dataset:  21%|██▏       | 5199/24227 [00:17<01:05, 290.10 examples/s]Tokenizing train dataset:  22%|██▏       | 5283/24227 [00:17<01:07, 280.74 examples/s]Tokenizing train dataset:  22%|██▏       | 5215/24227 [00:17<01:05, 289.12 examples/s]Tokenizing train dataset:  22%|██▏       | 5231/24227 [00:17<01:04, 293.04 examples/s]Tokenizing train dataset:  22%|██▏       | 5248/24227 [00:17<01:04, 294.41 examples/s]Tokenizing train dataset:  22%|██▏       | 5320/24227 [00:18<01:11, 263.50 examples/s]Tokenizing train dataset:  22%|██▏       | 5272/24227 [00:18<01:06, 283.65 examples/s]Tokenizing train dataset:  22%|██▏       | 5351/24227 [00:18<01:09, 273.05 examples/s]Tokenizing train dataset:  22%|██▏       | 5288/24227 [00:18<01:07, 282.31 examples/s]Tokenizing train dataset:  22%|██▏       | 5311/24227 [00:18<01:09, 270.91 examples/s]Tokenizing train dataset:  22%|██▏       | 5393/24227 [00:18<01:01, 305.51 examples/s]Tokenizing train dataset:  22%|██▏       | 5324/24227 [00:18<01:11, 265.04 examples/s]Tokenizing train dataset:  22%|██▏       | 5425/24227 [00:18<01:01, 306.22 examples/s]Tokenizing train dataset:  22%|██▏       | 5357/24227 [00:18<01:07, 278.91 examples/s]Tokenizing train dataset:  22%|██▏       | 5360/24227 [00:18<01:06, 282.16 examples/s]Tokenizing train dataset:  23%|██▎       | 5458/24227 [00:18<01:00, 307.97 examples/s]Tokenizing train dataset:  22%|██▏       | 5395/24227 [00:18<01:03, 298.49 examples/s]Tokenizing train dataset:  22%|██▏       | 5399/24227 [00:18<01:01, 304.15 examples/s]Tokenizing train dataset:  23%|██▎       | 5490/24227 [00:18<01:10, 267.26 examples/s]Tokenizing train dataset:  22%|██▏       | 5434/24227 [00:18<00:59, 314.17 examples/s]Tokenizing train dataset:  22%|██▏       | 5434/24227 [00:18<01:06, 282.24 examples/s]Tokenizing train dataset:  23%|██▎       | 5523/24227 [00:18<01:06, 281.83 examples/s]Tokenizing train dataset:  23%|██▎       | 5463/24227 [00:18<01:06, 282.59 examples/s]Tokenizing train dataset:  23%|██▎       | 5480/24227 [00:18<01:01, 306.43 examples/s]Tokenizing train dataset:  23%|██▎       | 5495/24227 [00:18<01:04, 288.37 examples/s]Tokenizing train dataset:  23%|██▎       | 5567/24227 [00:18<01:06, 282.65 examples/s]Tokenizing train dataset:  23%|██▎       | 5514/24227 [00:18<00:59, 312.66 examples/s]Tokenizing train dataset:  23%|██▎       | 5528/24227 [00:18<01:03, 295.81 examples/s]Tokenizing train dataset:  23%|██▎       | 5610/24227 [00:19<00:58, 316.75 examples/s]Tokenizing train dataset:  23%|██▎       | 5557/24227 [00:18<01:02, 300.33 examples/s]Tokenizing train dataset:  23%|██▎       | 5644/24227 [00:19<00:58, 318.58 examples/s]Tokenizing train dataset:  23%|██▎       | 5576/24227 [00:19<01:01, 301.45 examples/s]Tokenizing train dataset:  23%|██▎       | 5600/24227 [00:19<00:56, 330.91 examples/s]Tokenizing train dataset:  23%|██▎       | 5680/24227 [00:19<00:56, 326.08 examples/s]Tokenizing train dataset:  23%|██▎       | 5617/24227 [00:19<00:56, 327.67 examples/s]Tokenizing train dataset:  23%|██▎       | 5650/24227 [00:19<00:56, 328.42 examples/s]Tokenizing train dataset:  24%|██▎       | 5729/24227 [00:19<00:57, 324.20 examples/s]Tokenizing train dataset:  23%|██▎       | 5670/24227 [00:19<00:56, 330.32 examples/s]Tokenizing train dataset:  23%|██▎       | 5689/24227 [00:19<00:54, 337.22 examples/s]Tokenizing train dataset:  24%|██▎       | 5704/24227 [00:19<00:56, 329.69 examples/s]Tokenizing train dataset:  24%|██▍       | 5769/24227 [00:19<01:01, 301.48 examples/s]Tokenizing train dataset:  24%|██▎       | 5737/24227 [00:19<00:56, 326.04 examples/s]Tokenizing train dataset:  24%|██▎       | 5750/24227 [00:19<00:58, 315.89 examples/s]Tokenizing train dataset:  24%|██▍       | 5817/24227 [00:19<01:00, 306.35 examples/s]Tokenizing train dataset:  24%|██▍       | 5776/24227 [00:19<01:01, 300.90 examples/s]Tokenizing train dataset:  24%|██▍       | 5857/24227 [00:19<00:56, 324.97 examples/s]Tokenizing train dataset:  24%|██▍       | 5792/24227 [00:19<01:01, 299.38 examples/s]Tokenizing train dataset:  24%|██▍       | 5891/24227 [00:19<00:56, 325.26 examples/s]Tokenizing train dataset:  24%|██▍       | 5828/24227 [00:19<00:59, 311.84 examples/s]Tokenizing train dataset:  24%|██▍       | 5828/24227 [00:19<00:59, 311.14 examples/s]Tokenizing train dataset:  24%|██▍       | 5868/24227 [00:19<00:55, 328.68 examples/s]Tokenizing train dataset:  24%|██▍       | 5868/24227 [00:19<00:55, 329.68 examples/s]Tokenizing train dataset:  25%|██▍       | 5937/24227 [00:20<00:58, 314.87 examples/s]Tokenizing train dataset:  24%|██▍       | 5911/24227 [00:20<00:59, 309.80 examples/s]Tokenizing train dataset:  24%|██▍       | 5911/24227 [00:20<00:59, 309.16 examples/s]Tokenizing train dataset:  25%|██▍       | 5980/24227 [00:20<01:00, 300.87 examples/s]Tokenizing train dataset:  25%|██▍       | 5946/24227 [00:20<00:58, 313.87 examples/s]Tokenizing train dataset:  25%|██▍       | 5946/24227 [00:20<00:58, 313.66 examples/s]Tokenizing train dataset:  25%|██▍       | 6024/24227 [00:20<01:01, 294.13 examples/s]Tokenizing train dataset:  25%|██▍       | 5990/24227 [00:20<01:00, 303.15 examples/s]Tokenizing train dataset:  25%|██▍       | 5990/24227 [00:20<01:00, 302.98 examples/s]Tokenizing train dataset:  25%|██▌       | 6061/24227 [00:20<00:59, 307.31 examples/s]Tokenizing train dataset:  25%|██▌       | 6099/24227 [00:20<00:56, 323.30 examples/s]Tokenizing train dataset:  25%|██▍       | 6037/24227 [00:20<01:00, 300.38 examples/s]Tokenizing train dataset:  25%|██▍       | 6037/24227 [00:20<01:00, 300.18 examples/s]Tokenizing train dataset:  25%|██▌       | 6138/24227 [00:20<00:53, 336.11 examples/s]Tokenizing train dataset:  25%|██▌       | 6074/24227 [00:20<00:57, 315.86 examples/s]Tokenizing train dataset:  25%|██▌       | 6074/24227 [00:20<00:57, 315.72 examples/s]Tokenizing train dataset:  25%|██▌       | 6175/24227 [00:20<00:53, 339.32 examples/s]Tokenizing train dataset:  25%|██▌       | 6109/24227 [00:20<00:56, 322.47 examples/s]Tokenizing train dataset:  25%|██▌       | 6109/24227 [00:20<00:56, 322.31 examples/s]Tokenizing train dataset:  26%|██▌       | 6210/24227 [00:20<00:53, 339.57 examples/s]Tokenizing train dataset:  25%|██▌       | 6148/24227 [00:20<00:53, 338.32 examples/s]Tokenizing train dataset:  25%|██▌       | 6148/24227 [00:20<00:53, 337.94 examples/s]Tokenizing train dataset:  26%|██▌       | 6245/24227 [00:20<00:53, 338.28 examples/s]Tokenizing train dataset:  26%|██▌       | 6183/24227 [00:20<00:53, 339.03 examples/s]Tokenizing train dataset:  26%|██▌       | 6183/24227 [00:20<00:53, 338.43 examples/s]Tokenizing train dataset:  26%|██▌       | 6287/24227 [00:21<00:49, 359.10 examples/s]Tokenizing train dataset:  26%|██▌       | 6219/24227 [00:20<00:52, 342.68 examples/s]Tokenizing train dataset:  26%|██▌       | 6219/24227 [00:21<00:52, 341.83 examples/s]Tokenizing train dataset:  26%|██▌       | 6324/24227 [00:21<00:50, 356.67 examples/s]Tokenizing train dataset:  26%|██▌       | 6254/24227 [00:21<00:52, 343.92 examples/s]Tokenizing train dataset:  26%|██▌       | 6254/24227 [00:21<00:52, 343.19 examples/s]Tokenizing train dataset:  26%|██▋       | 6366/24227 [00:21<00:47, 373.32 examples/s]Tokenizing train dataset:  26%|██▌       | 6297/24227 [00:21<00:49, 364.86 examples/s]Tokenizing train dataset:  26%|██▌       | 6297/24227 [00:21<00:49, 364.18 examples/s]Tokenizing train dataset:  26%|██▌       | 6334/24227 [00:21<00:49, 363.00 examples/s]Tokenizing train dataset:  26%|██▌       | 6334/24227 [00:21<00:49, 362.23 examples/s]Tokenizing train dataset:  26%|██▋       | 6420/24227 [00:21<00:48, 363.70 examples/s]Tokenizing train dataset:  26%|██▋       | 6375/24227 [00:21<00:48, 371.17 examples/s]Tokenizing train dataset:  26%|██▋       | 6375/24227 [00:21<00:48, 370.26 examples/s]Tokenizing train dataset:  27%|██▋       | 6461/24227 [00:21<00:47, 370.72 examples/s]Tokenizing train dataset:  27%|██▋       | 6430/24227 [00:21<00:48, 364.43 examples/s]Tokenizing train dataset:  27%|██▋       | 6430/24227 [00:21<00:48, 363.43 examples/s]Tokenizing train dataset:  27%|██▋       | 6514/24227 [00:21<00:48, 362.85 examples/s]Tokenizing train dataset:  27%|██▋       | 6471/24227 [00:21<00:47, 372.12 examples/s]Tokenizing train dataset:  27%|██▋       | 6471/24227 [00:21<00:47, 371.00 examples/s]Tokenizing train dataset:  27%|██▋       | 6553/24227 [00:21<00:48, 363.59 examples/s]Tokenizing train dataset:  27%|██▋       | 6523/24227 [00:21<00:49, 359.70 examples/s]Tokenizing train dataset:  27%|██▋       | 6523/24227 [00:21<00:49, 358.47 examples/s]Tokenizing train dataset:  27%|██▋       | 6607/24227 [00:21<00:49, 358.97 examples/s]Tokenizing train dataset:  27%|██▋       | 6561/24227 [00:21<00:48, 361.49 examples/s]Tokenizing train dataset:  27%|██▋       | 6561/24227 [00:22<00:49, 360.37 examples/s]Tokenizing train dataset:  27%|██▋       | 6649/24227 [00:22<00:47, 370.22 examples/s]Tokenizing train dataset:  27%|██▋       | 6598/24227 [00:22<00:49, 357.13 examples/s]Tokenizing train dataset:  27%|██▋       | 6598/24227 [00:22<00:49, 356.03 examples/s]Tokenizing train dataset:  28%|██▊       | 6687/24227 [00:22<00:47, 371.73 examples/s]Tokenizing train dataset:  27%|██▋       | 6640/24227 [00:22<00:47, 368.03 examples/s]Tokenizing train dataset:  27%|██▋       | 6640/24227 [00:22<00:47, 366.78 examples/s]Tokenizing train dataset:  28%|██▊       | 6742/24227 [00:22<00:48, 363.91 examples/s]Tokenizing train dataset:  28%|██▊       | 6680/24227 [00:22<00:46, 373.48 examples/s]Tokenizing train dataset:  28%|██▊       | 6680/24227 [00:22<00:47, 372.35 examples/s]Tokenizing train dataset:  28%|██▊       | 6719/24227 [00:22<00:47, 372.17 examples/s]Tokenizing train dataset:  28%|██▊       | 6719/24227 [00:22<00:47, 370.99 examples/s]Tokenizing train dataset:  28%|██▊       | 6797/24227 [00:22<00:48, 360.64 examples/s]Tokenizing train dataset:  28%|██▊       | 6836/24227 [00:22<00:48, 362.02 examples/s]Tokenizing train dataset:  28%|██▊       | 6772/24227 [00:22<00:48, 361.62 examples/s]Tokenizing train dataset:  28%|██▊       | 6772/24227 [00:22<00:48, 360.49 examples/s]Tokenizing train dataset:  28%|██▊       | 6874/24227 [00:22<00:47, 362.85 examples/s]Tokenizing train dataset:  28%|██▊       | 6813/24227 [00:22<00:47, 367.86 examples/s]Tokenizing train dataset:  28%|██▊       | 6813/24227 [00:22<00:47, 366.63 examples/s]Tokenizing train dataset:  29%|██▊       | 6918/24227 [00:22<00:45, 379.99 examples/s]Tokenizing train dataset:  28%|██▊       | 6867/24227 [00:22<00:48, 360.13 examples/s]Tokenizing train dataset:  28%|██▊       | 6867/24227 [00:22<00:48, 359.10 examples/s]Tokenizing train dataset:  29%|██▊       | 6960/24227 [00:22<00:44, 386.22 examples/s]Tokenizing train dataset:  29%|██▊       | 6910/24227 [00:22<00:46, 373.98 examples/s]Tokenizing train dataset:  29%|██▊       | 6910/24227 [00:22<00:46, 372.85 examples/s]Tokenizing train dataset:  29%|██▉       | 7017/24227 [00:23<00:45, 379.06 examples/s]Tokenizing train dataset:  29%|██▊       | 6952/24227 [00:22<00:44, 384.20 examples/s]Tokenizing train dataset:  29%|██▊       | 6952/24227 [00:23<00:45, 382.64 examples/s]Tokenizing train dataset:  29%|██▉       | 7070/24227 [00:23<00:46, 367.23 examples/s]Tokenizing train dataset:  29%|██▉       | 7010/24227 [00:23<00:45, 379.01 examples/s]Tokenizing train dataset:  29%|██▉       | 7010/24227 [00:23<00:45, 377.22 examples/s]Tokenizing train dataset:  29%|██▉       | 7108/24227 [00:23<00:46, 367.05 examples/s]Tokenizing train dataset:  29%|██▉       | 7061/24227 [00:23<00:47, 363.02 examples/s]Tokenizing train dataset:  29%|██▉       | 7061/24227 [00:23<00:47, 361.53 examples/s]Tokenizing train dataset:  30%|██▉       | 7162/24227 [00:23<00:47, 362.72 examples/s]Tokenizing train dataset:  29%|██▉       | 7102/24227 [00:23<00:46, 370.83 examples/s]Tokenizing train dataset:  29%|██▉       | 7102/24227 [00:23<00:46, 369.39 examples/s]Tokenizing train dataset:  30%|██▉       | 7217/24227 [00:23<00:47, 358.16 examples/s]Tokenizing train dataset:  30%|██▉       | 7159/24227 [00:23<00:46, 367.26 examples/s]Tokenizing train dataset:  30%|██▉       | 7159/24227 [00:23<00:46, 366.34 examples/s]Tokenizing train dataset:  30%|██▉       | 7258/24227 [00:23<01:00, 281.58 examples/s]Tokenizing train dataset:  30%|██▉       | 7215/24227 [00:23<00:58, 293.03 examples/s]Tokenizing train dataset:  30%|██▉       | 7215/24227 [00:23<00:56, 300.55 examples/s]Tokenizing train dataset:  30%|███       | 7292/24227 [00:23<00:57, 292.70 examples/s]Tokenizing train dataset:  30%|██▉       | 7253/24227 [00:23<00:54, 309.17 examples/s]Tokenizing train dataset:  30%|██▉       | 7252/24227 [00:23<00:54, 313.52 examples/s]Tokenizing train dataset:  30%|███       | 7328/24227 [00:24<00:55, 305.86 examples/s]Tokenizing train dataset:  30%|███       | 7289/24227 [00:23<00:53, 318.04 examples/s]Tokenizing train dataset:  30%|███       | 7289/24227 [00:24<00:52, 323.07 examples/s]Tokenizing train dataset:  30%|███       | 7365/24227 [00:24<00:52, 318.44 examples/s]Tokenizing train dataset:  31%|███       | 7404/24227 [00:24<00:50, 334.59 examples/s]Tokenizing train dataset:  30%|███       | 7344/24227 [00:24<00:50, 331.61 examples/s]Tokenizing train dataset:  30%|███       | 7344/24227 [00:24<00:50, 334.92 examples/s]Tokenizing train dataset:  30%|███       | 7380/24227 [00:24<00:50, 335.81 examples/s]Tokenizing train dataset:  30%|███       | 7380/24227 [00:24<00:49, 338.12 examples/s]Tokenizing train dataset:  31%|███       | 7459/24227 [00:24<00:48, 342.39 examples/s]Tokenizing train dataset:  31%|███       | 7497/24227 [00:24<00:47, 349.94 examples/s]Tokenizing train dataset:  31%|███       | 7432/24227 [00:24<00:49, 336.44 examples/s]Tokenizing train dataset:  31%|███       | 7432/24227 [00:24<00:49, 337.75 examples/s]Tokenizing train dataset:  31%|███       | 7535/24227 [00:24<00:46, 356.48 examples/s]Tokenizing train dataset:  31%|███       | 7473/24227 [00:24<00:47, 351.59 examples/s]Tokenizing train dataset:  31%|███       | 7473/24227 [00:24<00:47, 352.29 examples/s]Tokenizing train dataset:  31%|███       | 7510/24227 [00:24<00:47, 351.00 examples/s]Tokenizing train dataset:  31%|███       | 7510/24227 [00:24<00:47, 351.11 examples/s]Tokenizing train dataset:  31%|███▏      | 7585/24227 [00:24<00:48, 342.33 examples/s]Tokenizing train dataset:  31%|███       | 7548/24227 [00:24<00:46, 357.40 examples/s]Tokenizing train dataset:  31%|███       | 7548/24227 [00:24<00:46, 356.98 examples/s]Tokenizing train dataset:  32%|███▏      | 7636/24227 [00:24<00:49, 338.52 examples/s]Tokenizing train dataset:  31%|███▏      | 7599/24227 [00:24<00:47, 346.98 examples/s]Tokenizing train dataset:  31%|███▏      | 7599/24227 [00:24<00:48, 346.26 examples/s]Tokenizing train dataset:  32%|███▏      | 7672/24227 [00:25<00:48, 340.51 examples/s]Tokenizing train dataset:  32%|███▏      | 7647/24227 [00:25<00:49, 336.05 examples/s]Tokenizing train dataset:  32%|███▏      | 7738/24227 [00:25<00:39, 416.85 examples/s]Tokenizing train dataset:  32%|███▏      | 7647/24227 [00:25<00:49, 335.29 examples/s]Tokenizing train dataset:  32%|███▏      | 7698/24227 [00:25<00:44, 375.40 examples/s]Tokenizing train dataset:  32%|███▏      | 7808/24227 [00:25<00:33, 490.25 examples/s]Tokenizing train dataset:  32%|███▏      | 7698/24227 [00:25<00:44, 374.54 examples/s]Tokenizing train dataset:  33%|███▎      | 7880/24227 [00:25<00:29, 551.03 examples/s]Tokenizing train dataset:  32%|███▏      | 7768/24227 [00:25<00:36, 449.38 examples/s]Tokenizing train dataset:  32%|███▏      | 7767/24227 [00:25<00:36, 451.02 examples/s]Tokenizing train dataset:  33%|███▎      | 7955/24227 [00:25<00:26, 604.46 examples/s]Tokenizing train dataset:  32%|███▏      | 7835/24227 [00:25<00:32, 508.87 examples/s]Tokenizing train dataset:  32%|███▏      | 7841/24227 [00:25<00:31, 518.19 examples/s]Tokenizing train dataset:  33%|███▎      | 8027/24227 [00:25<00:25, 636.38 examples/s]Tokenizing train dataset:  33%|███▎      | 7909/24227 [00:25<00:28, 568.99 examples/s]Tokenizing train dataset:  33%|███▎      | 7914/24227 [00:25<00:28, 571.98 examples/s]Tokenizing train dataset:  33%|███▎      | 8094/24227 [00:25<00:25, 644.64 examples/s]Tokenizing train dataset:  33%|███▎      | 7986/24227 [00:25<00:26, 623.49 examples/s]Tokenizing train dataset:  33%|███▎      | 7994/24227 [00:25<00:25, 625.65 examples/s]Tokenizing train dataset:  33%|███▎      | 8059/24227 [00:25<00:25, 630.46 examples/s]Tokenizing train dataset:  34%|███▍      | 8191/24227 [00:25<00:25, 640.33 examples/s]Tokenizing train dataset:  33%|███▎      | 8085/24227 [00:25<00:25, 632.76 examples/s]Tokenizing train dataset:  34%|███▎      | 8127/24227 [00:25<00:25, 641.58 examples/s]Tokenizing train dataset:  34%|███▍      | 8270/24227 [00:25<00:23, 678.43 examples/s]Tokenizing train dataset:  34%|███▎      | 8150/24227 [00:25<00:25, 634.83 examples/s]Tokenizing train dataset:  34%|███▍      | 8349/24227 [00:26<00:22, 706.23 examples/s]Tokenizing train dataset:  34%|███▍      | 8219/24227 [00:25<00:24, 647.12 examples/s]Tokenizing train dataset:  34%|███▍      | 8231/24227 [00:25<00:24, 656.20 examples/s]Tokenizing train dataset:  34%|███▍      | 8294/24227 [00:26<00:23, 673.16 examples/s]Tokenizing train dataset:  34%|███▍      | 8307/24227 [00:26<00:23, 680.38 examples/s]Tokenizing train dataset:  35%|███▍      | 8449/24227 [00:26<00:22, 686.57 examples/s]Tokenizing train dataset:  35%|███▍      | 8371/24227 [00:26<00:22, 690.17 examples/s]Tokenizing train dataset:  35%|███▍      | 8380/24227 [00:26<00:22, 691.59 examples/s]Tokenizing train dataset:  35%|███▌      | 8520/24227 [00:26<00:22, 685.16 examples/s]Tokenizing train dataset:  36%|███▌      | 8601/24227 [00:26<00:21, 717.47 examples/s]Tokenizing train dataset:  35%|███▍      | 8475/24227 [00:26<00:22, 687.70 examples/s]Tokenizing train dataset:  35%|███▌      | 8486/24227 [00:26<00:22, 693.78 examples/s]Tokenizing train dataset:  36%|███▌      | 8677/24227 [00:26<00:21, 728.99 examples/s]Tokenizing train dataset:  35%|███▌      | 8600/24227 [00:26<00:21, 713.46 examples/s]Tokenizing train dataset:  35%|███▌      | 8589/24227 [00:26<00:22, 705.71 examples/s]Tokenizing train dataset:  36%|███▌      | 8781/24227 [00:26<00:21, 712.50 examples/s]Tokenizing train dataset:  36%|███▌      | 8678/24227 [00:26<00:21, 726.87 examples/s]Tokenizing train dataset:  36%|███▌      | 8668/24227 [00:26<00:21, 720.23 examples/s]Tokenizing train dataset:  36%|███▌      | 8751/24227 [00:26<00:21, 725.68 examples/s]Tokenizing train dataset:  36%|███▌      | 8745/24227 [00:26<00:21, 732.68 examples/s]Tokenizing train dataset:  37%|███▋      | 8883/24227 [00:26<00:21, 698.95 examples/s]Tokenizing train dataset:  37%|███▋      | 8959/24227 [00:26<00:21, 710.82 examples/s]Tokenizing train dataset:  37%|███▋      | 8849/24227 [00:26<00:22, 698.46 examples/s]Tokenizing train dataset:  36%|███▋      | 8840/24227 [00:26<00:22, 690.61 examples/s]Tokenizing train dataset:  37%|███▋      | 8921/24227 [00:26<00:21, 697.45 examples/s]Tokenizing train dataset:  37%|███▋      | 8912/24227 [00:26<00:22, 695.19 examples/s]Tokenizing train dataset:  37%|███▋      | 9076/24227 [00:27<00:20, 730.20 examples/s]Tokenizing train dataset:  37%|███▋      | 8997/24227 [00:26<00:21, 712.50 examples/s]Tokenizing train dataset:  37%|███▋      | 8991/24227 [00:27<00:21, 717.08 examples/s]Tokenizing train dataset:  38%|███▊      | 9172/24227 [00:27<00:21, 693.73 examples/s]Tokenizing train dataset:  37%|███▋      | 9077/24227 [00:27<00:20, 735.54 examples/s]Tokenizing train dataset:  37%|███▋      | 9065/24227 [00:27<00:20, 722.46 examples/s]Tokenizing train dataset:  38%|███▊      | 9246/24227 [00:27<00:21, 702.21 examples/s]Tokenizing train dataset:  38%|███▊      | 9172/24227 [00:27<00:21, 691.96 examples/s]Tokenizing train dataset:  38%|███▊      | 9162/24227 [00:27<00:21, 692.89 examples/s]Tokenizing train dataset:  38%|███▊      | 9325/24227 [00:27<00:20, 717.10 examples/s]Tokenizing train dataset:  38%|███▊      | 9246/24227 [00:27<00:21, 702.21 examples/s]Tokenizing train dataset:  38%|███▊      | 9272/24227 [00:27<00:21, 703.02 examples/s]Tokenizing train dataset:  39%|███▉      | 9433/24227 [00:27<00:20, 710.58 examples/s]Tokenizing train dataset:  38%|███▊      | 9325/24227 [00:27<00:20, 718.11 examples/s]Tokenizing train dataset:  39%|███▊      | 9344/24227 [00:27<00:21, 705.25 examples/s]Tokenizing train dataset:  39%|███▉      | 9538/24227 [00:27<00:20, 705.12 examples/s]Tokenizing train dataset:  39%|███▉      | 9433/24227 [00:27<00:20, 710.79 examples/s]Tokenizing train dataset:  39%|███▉      | 9450/24227 [00:27<00:21, 698.98 examples/s]Tokenizing train dataset:  40%|███▉      | 9634/24227 [00:27<00:21, 674.94 examples/s]Tokenizing train dataset:  39%|███▉      | 9523/24227 [00:27<00:20, 704.32 examples/s]Tokenizing train dataset:  39%|███▉      | 9539/24227 [00:27<00:20, 705.25 examples/s]Tokenizing train dataset:  40%|████      | 9704/24227 [00:27<00:21, 678.12 examples/s]Tokenizing train dataset:  40%|███▉      | 9619/24227 [00:27<00:21, 674.38 examples/s]Tokenizing train dataset:  40%|███▉      | 9634/24227 [00:27<00:21, 674.50 examples/s]Tokenizing train dataset:  40%|████      | 9777/24227 [00:28<00:21, 684.59 examples/s]Tokenizing train dataset:  40%|███▉      | 9689/24227 [00:28<00:21, 679.42 examples/s]Tokenizing train dataset:  40%|████      | 9704/24227 [00:27<00:21, 677.70 examples/s]Tokenizing train dataset:  41%|████      | 9869/24227 [00:28<00:22, 649.42 examples/s]Tokenizing train dataset:  40%|████      | 9777/24227 [00:28<00:21, 684.48 examples/s]Tokenizing train dataset:  40%|████      | 9796/24227 [00:28<00:21, 684.29 examples/s]Tokenizing train dataset:  41%|████      | 9943/24227 [00:28<00:21, 669.50 examples/s]Tokenizing train dataset:  41%|████      | 9869/24227 [00:28<00:22, 648.24 examples/s]Tokenizing train dataset:  41%|████▏     | 10024/24227 [00:28<00:20, 703.74 examples/s]Tokenizing train dataset:  41%|████      | 9884/24227 [00:28<00:22, 650.57 examples/s]Tokenizing train dataset:  41%|████      | 9943/24227 [00:28<00:21, 669.33 examples/s]Tokenizing train dataset:  41%|████      | 9961/24227 [00:28<00:21, 676.72 examples/s]Tokenizing train dataset:  42%|████▏     | 10126/24227 [00:28<00:20, 693.04 examples/s]Tokenizing train dataset:  41%|████▏     | 10024/24227 [00:28<00:20, 704.27 examples/s]Tokenizing train dataset:  41%|████▏     | 10033/24227 [00:28<00:20, 685.97 examples/s]Tokenizing train dataset:  42%|████▏     | 10104/24227 [00:28<00:20, 686.32 examples/s]Tokenizing train dataset:  42%|████▏     | 10126/24227 [00:28<00:20, 694.33 examples/s]Tokenizing train dataset:  42%|████▏     | 10216/24227 [00:28<00:24, 582.74 examples/s]Tokenizing train dataset:  42%|████▏     | 10184/24227 [00:28<00:22, 619.30 examples/s]Tokenizing train dataset:  42%|████▏     | 10216/24227 [00:28<00:23, 583.90 examples/s]Tokenizing train dataset:  42%|████▏     | 10248/24227 [00:29<00:25, 549.43 examples/s]Tokenizing train dataset:  42%|████▏     | 10293/24227 [00:29<00:30, 455.57 examples/s]Tokenizing train dataset:  42%|████▏     | 10291/24227 [00:29<00:27, 505.55 examples/s]Tokenizing train dataset:  43%|████▎     | 10353/24227 [00:29<00:31, 434.62 examples/s]Tokenizing train dataset:  43%|████▎     | 10317/24227 [00:29<00:30, 463.11 examples/s]Tokenizing train dataset:  43%|████▎     | 10346/24227 [00:29<00:29, 464.59 examples/s]Tokenizing train dataset:  43%|████▎     | 10411/24227 [00:29<00:33, 415.47 examples/s]Tokenizing train dataset:  43%|████▎     | 10377/24227 [00:29<00:31, 441.17 examples/s]Tokenizing train dataset:  43%|████▎     | 10406/24227 [00:29<00:31, 443.34 examples/s]Tokenizing train dataset:  43%|████▎     | 10469/24227 [00:29<00:33, 405.62 examples/s]Tokenizing train dataset:  43%|████▎     | 10436/24227 [00:29<00:32, 423.65 examples/s]Tokenizing train dataset:  43%|████▎     | 10466/24227 [00:29<00:32, 424.63 examples/s]Tokenizing train dataset:  43%|████▎     | 10525/24227 [00:29<00:34, 392.92 examples/s]Tokenizing train dataset:  43%|████▎     | 10491/24227 [00:29<00:33, 404.97 examples/s]Tokenizing train dataset:  43%|████▎     | 10520/24227 [00:29<00:33, 403.39 examples/s]Tokenizing train dataset:  44%|████▎     | 10580/24227 [00:29<00:35, 381.95 examples/s]Tokenizing train dataset:  44%|████▎     | 10548/24227 [00:29<00:34, 392.59 examples/s]Tokenizing train dataset:  44%|████▎     | 10575/24227 [00:29<00:34, 390.42 examples/s]Tokenizing train dataset:  44%|████▍     | 10636/24227 [00:29<00:36, 376.06 examples/s]Tokenizing train dataset:  44%|████▍     | 10602/24227 [00:29<00:35, 380.12 examples/s]Tokenizing train dataset:  44%|████▍     | 10630/24227 [00:29<00:35, 382.21 examples/s]Tokenizing train dataset:  44%|████▍     | 10687/24227 [00:30<00:37, 362.89 examples/s]Tokenizing train dataset:  44%|████▍     | 10657/24227 [00:30<00:36, 374.09 examples/s]Tokenizing train dataset:  44%|████▍     | 10681/24227 [00:30<00:36, 366.44 examples/s]Tokenizing train dataset:  44%|████▍     | 10728/24227 [00:30<00:36, 371.81 examples/s]Tokenizing train dataset:  44%|████▍     | 10722/24227 [00:30<00:36, 373.24 examples/s]Tokenizing train dataset:  44%|████▍     | 10710/24227 [00:30<00:37, 361.29 examples/s]Tokenizing train dataset:  44%|████▍     | 10780/24227 [00:30<00:37, 359.76 examples/s]Tokenizing train dataset:  44%|████▍     | 10750/24227 [00:30<00:36, 368.43 examples/s]Tokenizing train dataset:  44%|████▍     | 10775/24227 [00:30<00:36, 363.82 examples/s]Tokenizing train dataset:  45%|████▍     | 10822/24227 [00:30<00:36, 370.20 examples/s]Tokenizing train dataset:  45%|████▍     | 10816/24227 [00:30<00:36, 371.69 examples/s]Tokenizing train dataset:  45%|████▍     | 10805/24227 [00:30<00:36, 365.51 examples/s]Tokenizing train dataset:  45%|████▍     | 10874/24227 [00:30<00:37, 355.66 examples/s]Tokenizing train dataset:  45%|████▍     | 10842/24227 [00:30<00:36, 363.71 examples/s]Tokenizing train dataset:  45%|████▍     | 10868/24227 [00:30<00:37, 360.51 examples/s]Tokenizing train dataset:  45%|████▌     | 10911/24227 [00:30<00:37, 353.70 examples/s]Tokenizing train dataset:  45%|████▍     | 10896/24227 [00:30<00:37, 358.62 examples/s]Tokenizing train dataset:  45%|████▌     | 10949/24227 [00:30<00:37, 355.60 examples/s]Tokenizing train dataset:  45%|████▌     | 10920/24227 [00:30<00:37, 351.56 examples/s]Tokenizing train dataset:  45%|████▌     | 10990/24227 [00:30<00:36, 366.92 examples/s]Tokenizing train dataset:  45%|████▌     | 10959/24227 [00:30<00:37, 357.59 examples/s]Tokenizing train dataset:  45%|████▌     | 10950/24227 [00:30<00:37, 353.24 examples/s]Tokenizing train dataset:  46%|████▌     | 11030/24227 [00:31<00:35, 370.83 examples/s]Tokenizing train dataset:  45%|████▌     | 11000/24227 [00:30<00:36, 366.64 examples/s]Tokenizing train dataset:  45%|████▌     | 10992/24227 [00:31<00:36, 367.25 examples/s]Tokenizing train dataset:  46%|████▌     | 11073/24227 [00:31<00:34, 382.38 examples/s]Tokenizing train dataset:  46%|████▌     | 11045/24227 [00:31<00:34, 383.66 examples/s]Tokenizing train dataset:  46%|████▌     | 11036/24227 [00:31<00:34, 378.70 examples/s]Tokenizing train dataset:  46%|████▌     | 11084/24227 [00:31<00:34, 382.78 examples/s]Tokenizing train dataset:  46%|████▌     | 11075/24227 [00:31<00:34, 377.97 examples/s]Tokenizing train dataset:  46%|████▌     | 11127/24227 [00:31<00:35, 368.36 examples/s]Tokenizing train dataset:  46%|████▌     | 11165/24227 [00:31<00:35, 369.92 examples/s]Tokenizing train dataset:  46%|████▌     | 11140/24227 [00:31<00:34, 374.74 examples/s]Tokenizing train dataset:  46%|████▌     | 11130/24227 [00:31<00:35, 368.42 examples/s]Tokenizing train dataset:  46%|████▌     | 11204/24227 [00:31<00:35, 371.52 examples/s]Tokenizing train dataset:  46%|████▌     | 11196/24227 [00:31<00:35, 370.58 examples/s]Tokenizing train dataset:  46%|████▌     | 11187/24227 [00:31<00:35, 369.57 examples/s]Tokenizing train dataset:  46%|████▋     | 11242/24227 [00:31<00:35, 367.55 examples/s]Tokenizing train dataset:  46%|████▋     | 11226/24227 [00:31<00:35, 370.51 examples/s]Tokenizing train dataset:  46%|████▋     | 11250/24227 [00:31<00:35, 364.69 examples/s]Tokenizing train dataset:  47%|████▋     | 11295/24227 [00:31<00:35, 359.76 examples/s]Tokenizing train dataset:  47%|████▋     | 11280/24227 [00:31<00:35, 359.92 examples/s]Tokenizing train dataset:  47%|████▋     | 11335/24227 [00:31<00:34, 368.59 examples/s]Tokenizing train dataset:  47%|████▋     | 11305/24227 [00:31<00:35, 360.54 examples/s]Tokenizing train dataset:  47%|████▋     | 11319/24227 [00:31<00:35, 364.15 examples/s]Tokenizing train dataset:  47%|████▋     | 11346/24227 [00:31<00:34, 369.08 examples/s]Tokenizing train dataset:  47%|████▋     | 11387/24227 [00:32<00:36, 352.65 examples/s]Tokenizing train dataset:  47%|████▋     | 11360/24227 [00:32<00:34, 370.05 examples/s]Tokenizing train dataset:  47%|████▋     | 11394/24227 [00:32<00:36, 349.98 examples/s]Tokenizing train dataset:  47%|████▋     | 11440/24227 [00:32<00:37, 345.50 examples/s]Tokenizing train dataset:  47%|████▋     | 11406/24227 [00:32<00:37, 341.71 examples/s]Tokenizing train dataset:  47%|████▋     | 11480/24227 [00:32<00:35, 357.00 examples/s]Tokenizing train dataset:  47%|████▋     | 11449/24227 [00:32<00:36, 352.81 examples/s]Tokenizing train dataset:  47%|████▋     | 11443/24227 [00:32<00:36, 347.89 examples/s]Tokenizing train dataset:  48%|████▊     | 11519/24227 [00:32<00:34, 363.90 examples/s]Tokenizing train dataset:  47%|████▋     | 11490/24227 [00:32<00:35, 363.77 examples/s]Tokenizing train dataset:  47%|████▋     | 11485/24227 [00:32<00:35, 363.07 examples/s]Tokenizing train dataset:  48%|████▊     | 11572/24227 [00:32<00:35, 356.82 examples/s]Tokenizing train dataset:  48%|████▊     | 11543/24227 [00:32<00:35, 355.55 examples/s]Tokenizing train dataset:  48%|████▊     | 11539/24227 [00:32<00:35, 358.71 examples/s]Tokenizing train dataset:  48%|████▊     | 11609/24227 [00:32<00:35, 358.00 examples/s]Tokenizing train dataset:  48%|████▊     | 11583/24227 [00:32<00:34, 363.24 examples/s]Tokenizing train dataset:  48%|████▊     | 11576/24227 [00:32<00:35, 359.61 examples/s]Tokenizing train dataset:  48%|████▊     | 11648/24227 [00:32<00:34, 363.10 examples/s]Tokenizing train dataset:  48%|████▊     | 11613/24227 [00:32<00:35, 356.95 examples/s]Tokenizing train dataset:  48%|████▊     | 11639/24227 [00:32<00:34, 362.29 examples/s]Tokenizing train dataset:  48%|████▊     | 11651/24227 [00:32<00:35, 359.13 examples/s]Tokenizing train dataset:  48%|████▊     | 11699/24227 [00:32<00:35, 353.14 examples/s]Tokenizing train dataset:  48%|████▊     | 11691/24227 [00:32<00:35, 354.83 examples/s]Tokenizing train dataset:  48%|████▊     | 11688/24227 [00:32<00:34, 360.13 examples/s]Tokenizing train dataset:  48%|████▊     | 11737/24227 [00:33<00:35, 354.83 examples/s]Tokenizing train dataset:  48%|████▊     | 11728/24227 [00:32<00:34, 357.52 examples/s]Tokenizing train dataset:  49%|████▊     | 11773/24227 [00:33<00:35, 352.44 examples/s]Tokenizing train dataset:  48%|████▊     | 11741/24227 [00:33<00:35, 354.72 examples/s]Tokenizing train dataset:  49%|████▊     | 11780/24227 [00:33<00:35, 351.77 examples/s]Tokenizing train dataset:  49%|████▊     | 11779/24227 [00:33<00:35, 354.74 examples/s]Tokenizing train dataset:  49%|████▉     | 11816/24227 [00:33<00:40, 304.86 examples/s]Tokenizing train dataset:  49%|████▉     | 11816/24227 [00:33<00:40, 305.98 examples/s]Tokenizing train dataset:  49%|████▉     | 11861/24227 [00:33<00:36, 339.31 examples/s]Tokenizing train dataset:  49%|████▉     | 11816/24227 [00:33<00:41, 301.72 examples/s]Tokenizing train dataset:  49%|████▉     | 11862/24227 [00:33<00:36, 340.69 examples/s]Tokenizing train dataset:  49%|████▉     | 11930/24227 [00:33<00:28, 428.01 examples/s]Tokenizing train dataset:  49%|████▉     | 11861/24227 [00:33<00:36, 337.64 examples/s]Tokenizing train dataset:  49%|████▉     | 11932/24227 [00:33<00:29, 423.75 examples/s]Tokenizing train dataset:  50%|████▉     | 11999/24227 [00:33<00:24, 496.28 examples/s]Tokenizing train dataset:  49%|████▉     | 11930/24227 [00:33<00:28, 427.73 examples/s]Tokenizing train dataset:  50%|████▉     | 12002/24227 [00:33<00:24, 493.34 examples/s]Tokenizing train dataset:  50%|████▉     | 12076/24227 [00:33<00:21, 569.04 examples/s]Tokenizing train dataset:  50%|████▉     | 11999/24227 [00:33<00:24, 496.37 examples/s]Tokenizing train dataset:  50%|████▉     | 12080/24227 [00:33<00:21, 567.08 examples/s]Tokenizing train dataset:  50%|█████     | 12148/24227 [00:33<00:20, 603.13 examples/s]Tokenizing train dataset:  50%|████▉     | 12076/24227 [00:33<00:21, 569.55 examples/s]Tokenizing train dataset:  50%|█████     | 12150/24227 [00:33<00:20, 601.57 examples/s]Tokenizing train dataset:  50%|█████     | 12224/24227 [00:33<00:18, 647.27 examples/s]Tokenizing train dataset:  50%|█████     | 12148/24227 [00:34<00:25, 477.49 examples/s]Tokenizing train dataset:  51%|█████     | 12251/24227 [00:33<00:19, 624.29 examples/s]Tokenizing train dataset:  51%|█████     | 12320/24227 [00:34<00:18, 639.38 examples/s]Tokenizing train dataset:  50%|█████     | 12224/24227 [00:34<00:22, 544.69 examples/s]Tokenizing train dataset:  51%|█████     | 12322/24227 [00:34<00:18, 643.20 examples/s]Tokenizing train dataset:  51%|█████     | 12395/24227 [00:34<00:17, 659.78 examples/s]Tokenizing train dataset:  51%|█████     | 12297/24227 [00:34<00:20, 589.96 examples/s]Tokenizing train dataset:  51%|█████     | 12395/24227 [00:34<00:17, 662.46 examples/s]Tokenizing train dataset:  52%|█████▏    | 12497/24227 [00:34<00:17, 661.57 examples/s]Tokenizing train dataset:  51%|█████     | 12368/24227 [00:34<00:19, 621.24 examples/s]Tokenizing train dataset:  52%|█████▏    | 12497/24227 [00:34<00:17, 664.26 examples/s]Tokenizing train dataset:  52%|█████▏    | 12564/24227 [00:34<00:17, 659.85 examples/s]Tokenizing train dataset:  51%|█████▏    | 12465/24227 [00:34<00:18, 627.59 examples/s]Tokenizing train dataset:  52%|█████▏    | 12637/24227 [00:34<00:17, 672.35 examples/s]Tokenizing train dataset:  52%|█████▏    | 12602/24227 [00:34<00:17, 668.40 examples/s]Tokenizing train dataset:  52%|█████▏    | 12533/24227 [00:34<00:18, 639.87 examples/s]Tokenizing train dataset:  52%|█████▏    | 12712/24227 [00:34<00:16, 690.58 examples/s]Tokenizing train dataset:  52%|█████▏    | 12680/24227 [00:34<00:16, 694.01 examples/s]Tokenizing train dataset:  52%|█████▏    | 12605/24227 [00:34<00:17, 654.90 examples/s]Tokenizing train dataset:  53%|█████▎    | 12785/24227 [00:34<00:16, 699.05 examples/s]Tokenizing train dataset:  52%|█████▏    | 12684/24227 [00:34<00:16, 684.05 examples/s]Tokenizing train dataset:  53%|█████▎    | 12785/24227 [00:34<00:16, 694.11 examples/s]Tokenizing train dataset:  53%|█████▎    | 12860/24227 [00:34<00:16, 710.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 12860/24227 [00:34<00:16, 705.53 examples/s]Tokenizing train dataset:  53%|█████▎    | 12793/24227 [00:34<00:16, 695.71 examples/s]Tokenizing train dataset:  54%|█████▎    | 12966/24227 [00:35<00:16, 698.67 examples/s]Tokenizing train dataset:  53%|█████▎    | 12864/24227 [00:35<00:16, 698.05 examples/s]Tokenizing train dataset:  54%|█████▎    | 12965/24227 [00:34<00:16, 700.19 examples/s]Tokenizing train dataset:  54%|█████▍    | 13072/24227 [00:35<00:15, 699.31 examples/s]Tokenizing train dataset:  53%|█████▎    | 12937/24227 [00:35<00:16, 702.98 examples/s]Tokenizing train dataset:  54%|█████▍    | 13069/24227 [00:35<00:16, 695.34 examples/s]Tokenizing train dataset:  54%|█████▍    | 13170/24227 [00:35<00:16, 679.61 examples/s]Tokenizing train dataset:  54%|█████▍    | 13037/24227 [00:35<00:16, 685.56 examples/s]Tokenizing train dataset:  54%|█████▍    | 13167/24227 [00:35<00:16, 678.80 examples/s]Tokenizing train dataset:  55%|█████▍    | 13264/24227 [00:35<00:16, 658.51 examples/s]Tokenizing train dataset:  54%|█████▍    | 13137/24227 [00:35<00:16, 677.25 examples/s]Tokenizing train dataset:  55%|█████▍    | 13263/24227 [00:35<00:16, 658.49 examples/s]Tokenizing train dataset:  55%|█████▌    | 13358/24227 [00:35<00:16, 640.81 examples/s]Tokenizing train dataset:  55%|█████▍    | 13235/24227 [00:35<00:16, 665.96 examples/s]Tokenizing train dataset:  55%|█████▌    | 13355/24227 [00:35<00:16, 643.65 examples/s]Tokenizing train dataset:  56%|█████▌    | 13457/24227 [00:35<00:16, 645.41 examples/s]Tokenizing train dataset:  55%|█████▍    | 13323/24227 [00:35<00:17, 634.37 examples/s]Tokenizing train dataset:  56%|█████▌    | 13455/24227 [00:35<00:16, 647.35 examples/s]Tokenizing train dataset:  56%|█████▌    | 13532/24227 [00:35<00:16, 664.90 examples/s]Tokenizing train dataset:  55%|█████▌    | 13388/24227 [00:35<00:17, 634.44 examples/s]Tokenizing train dataset:  56%|█████▌    | 13530/24227 [00:35<00:16, 667.28 examples/s]Tokenizing train dataset:  56%|█████▌    | 13606/24227 [00:35<00:15, 681.85 examples/s]Tokenizing train dataset:  56%|█████▌    | 13459/24227 [00:35<00:16, 651.01 examples/s]Tokenizing train dataset:  56%|█████▌    | 13603/24227 [00:35<00:15, 681.46 examples/s]Tokenizing train dataset:  56%|█████▋    | 13680/24227 [00:36<00:15, 693.11 examples/s]Tokenizing train dataset:  56%|█████▌    | 13533/24227 [00:36<00:16, 666.52 examples/s]Tokenizing train dataset:  56%|█████▋    | 13676/24227 [00:36<00:15, 692.47 examples/s]Tokenizing train dataset:  57%|█████▋    | 13760/24227 [00:36<00:14, 719.66 examples/s]Tokenizing train dataset:  56%|█████▌    | 13609/24227 [00:36<00:15, 689.82 examples/s]Tokenizing train dataset:  57%|█████▋    | 13757/24227 [00:36<00:14, 720.26 examples/s]Tokenizing train dataset:  57%|█████▋    | 13839/24227 [00:36<00:14, 730.09 examples/s]Tokenizing train dataset:  56%|█████▋    | 13682/24227 [00:36<00:15, 699.29 examples/s]Tokenizing train dataset:  57%|█████▋    | 13835/24227 [00:36<00:14, 731.02 examples/s]Tokenizing train dataset:  57%|█████▋    | 13919/24227 [00:36<00:13, 744.31 examples/s]Tokenizing train dataset:  57%|█████▋    | 13763/24227 [00:36<00:14, 728.71 examples/s]Tokenizing train dataset:  57%|█████▋    | 13915/24227 [00:36<00:13, 749.17 examples/s]Tokenizing train dataset:  57%|█████▋    | 13839/24227 [00:36<00:14, 732.65 examples/s]Tokenizing train dataset:  58%|█████▊    | 14011/24227 [00:36<00:14, 684.29 examples/s]Tokenizing train dataset:  57%|█████▋    | 13919/24227 [00:36<00:13, 746.39 examples/s]Tokenizing train dataset:  58%|█████▊    | 14009/24227 [00:36<00:14, 696.78 examples/s]Tokenizing train dataset:  58%|█████▊    | 14116/24227 [00:36<00:14, 684.65 examples/s]Tokenizing train dataset:  58%|█████▊    | 14011/24227 [00:36<00:14, 684.08 examples/s]Tokenizing train dataset:  58%|█████▊    | 14110/24227 [00:36<00:14, 680.49 examples/s]Tokenizing train dataset:  59%|█████▊    | 14195/24227 [00:36<00:14, 707.75 examples/s]Tokenizing train dataset:  59%|█████▊    | 14191/24227 [00:36<00:14, 710.47 examples/s]Tokenizing train dataset:  58%|█████▊    | 14113/24227 [00:36<00:14, 680.87 examples/s]Tokenizing train dataset:  59%|█████▉    | 14297/24227 [00:36<00:14, 692.81 examples/s]Tokenizing train dataset:  59%|█████▊    | 14194/24227 [00:36<00:14, 707.87 examples/s]Tokenizing train dataset:  59%|█████▉    | 14293/24227 [00:36<00:14, 696.11 examples/s]Tokenizing train dataset:  59%|█████▉    | 14369/24227 [00:37<00:14, 697.45 examples/s]Tokenizing train dataset:  59%|█████▉    | 14368/24227 [00:37<00:14, 698.05 examples/s]Tokenizing train dataset:  59%|█████▉    | 14297/24227 [00:37<00:14, 692.71 examples/s]Tokenizing train dataset:  60%|█████▉    | 14472/24227 [00:37<00:14, 689.85 examples/s]Tokenizing train dataset:  59%|█████▉    | 14369/24227 [00:37<00:14, 696.68 examples/s]Tokenizing train dataset:  60%|█████▉    | 14472/24227 [00:37<00:14, 691.86 examples/s]Tokenizing train dataset:  60%|██████    | 14566/24227 [00:37<00:14, 666.97 examples/s]Tokenizing train dataset:  60%|█████▉    | 14472/24227 [00:37<00:14, 688.97 examples/s]Tokenizing train dataset:  60%|██████    | 14566/24227 [00:37<00:14, 669.26 examples/s]Tokenizing train dataset:  60%|██████    | 14640/24227 [00:37<00:14, 682.60 examples/s]Tokenizing train dataset:  60%|██████    | 14640/24227 [00:37<00:13, 684.84 examples/s]Tokenizing train dataset:  60%|██████    | 14566/24227 [00:37<00:14, 666.69 examples/s]Tokenizing train dataset:  61%|██████    | 14729/24227 [00:37<00:14, 650.40 examples/s]Tokenizing train dataset:  60%|██████    | 14640/24227 [00:37<00:14, 681.57 examples/s]Tokenizing train dataset:  61%|██████    | 14731/24227 [00:37<00:14, 650.74 examples/s]Tokenizing train dataset:  61%|██████    | 14806/24227 [00:37<00:15, 598.67 examples/s]Tokenizing train dataset:  61%|██████    | 14729/24227 [00:37<00:14, 649.51 examples/s]Tokenizing train dataset:  61%|██████    | 14808/24227 [00:37<00:15, 598.32 examples/s]Tokenizing train dataset:  61%|██████▏   | 14882/24227 [00:37<00:18, 511.96 examples/s]Tokenizing train dataset:  61%|██████    | 14806/24227 [00:37<00:15, 598.19 examples/s]Tokenizing train dataset:  61%|██████▏   | 14886/24227 [00:37<00:18, 515.27 examples/s]Tokenizing train dataset:  62%|██████▏   | 14939/24227 [00:38<00:19, 472.05 examples/s]Tokenizing train dataset:  61%|██████▏   | 14882/24227 [00:38<00:18, 511.43 examples/s]Tokenizing train dataset:  62%|██████▏   | 14942/24227 [00:38<00:19, 467.78 examples/s]Tokenizing train dataset:  62%|██████▏   | 14990/24227 [00:38<00:21, 429.67 examples/s]Tokenizing train dataset:  62%|██████▏   | 14939/24227 [00:38<00:19, 471.71 examples/s]Tokenizing train dataset:  62%|██████▏   | 14995/24227 [00:38<00:21, 431.92 examples/s]Tokenizing train dataset:  62%|██████▏   | 15053/24227 [00:38<00:21, 422.28 examples/s]Tokenizing train dataset:  62%|██████▏   | 14990/24227 [00:38<00:21, 429.46 examples/s]Tokenizing train dataset:  62%|██████▏   | 15057/24227 [00:38<00:21, 425.20 examples/s]Tokenizing train dataset:  62%|██████▏   | 15110/24227 [00:38<00:22, 404.44 examples/s]Tokenizing train dataset:  62%|██████▏   | 15053/24227 [00:38<00:21, 422.05 examples/s]Tokenizing train dataset:  62%|██████▏   | 15111/24227 [00:38<00:22, 404.97 examples/s]Tokenizing train dataset:  63%|██████▎   | 15174/24227 [00:38<00:22, 405.54 examples/s]Tokenizing train dataset:  62%|██████▏   | 15110/24227 [00:38<00:22, 404.24 examples/s]Tokenizing train dataset:  63%|██████▎   | 15174/24227 [00:38<00:22, 406.28 examples/s]Tokenizing train dataset:  63%|██████▎   | 15228/24227 [00:38<00:23, 388.77 examples/s]Tokenizing train dataset:  63%|██████▎   | 15174/24227 [00:38<00:22, 405.73 examples/s]Tokenizing train dataset:  63%|██████▎   | 15228/24227 [00:38<00:23, 389.06 examples/s]Tokenizing train dataset:  63%|██████▎   | 15284/24227 [00:39<00:23, 381.13 examples/s]Tokenizing train dataset:  63%|██████▎   | 15228/24227 [00:39<00:23, 388.98 examples/s]Tokenizing train dataset:  63%|██████▎   | 15275/24227 [00:39<00:24, 363.06 examples/s]Tokenizing train dataset:  63%|██████▎   | 15341/24227 [00:39<00:23, 376.87 examples/s]Tokenizing train dataset:  63%|██████▎   | 15312/24227 [00:39<00:24, 361.27 examples/s]Tokenizing train dataset:  63%|██████▎   | 15284/24227 [00:39<00:23, 381.47 examples/s]Tokenizing train dataset:  63%|██████▎   | 15350/24227 [00:39<00:24, 360.31 examples/s]Tokenizing train dataset:  64%|██████▎   | 15397/24227 [00:39<00:23, 372.17 examples/s]Tokenizing train dataset:  63%|██████▎   | 15341/24227 [00:39<00:23, 377.31 examples/s]Tokenizing train dataset:  64%|██████▎   | 15435/24227 [00:39<00:23, 369.78 examples/s]Tokenizing train dataset:  64%|██████▎   | 15407/24227 [00:39<00:24, 363.90 examples/s]Tokenizing train dataset:  64%|██████▎   | 15397/24227 [00:39<00:23, 372.71 examples/s]Tokenizing train dataset:  64%|██████▍   | 15489/24227 [00:39<00:24, 363.87 examples/s]Tokenizing train dataset:  64%|██████▍   | 15460/24227 [00:39<00:24, 357.16 examples/s]Tokenizing train dataset:  64%|██████▎   | 15435/24227 [00:39<00:23, 370.01 examples/s]Tokenizing train dataset:  64%|██████▍   | 15526/24227 [00:39<00:24, 359.25 examples/s]Tokenizing train dataset:  64%|██████▍   | 15499/24227 [00:39<00:24, 357.99 examples/s]Tokenizing train dataset:  64%|██████▍   | 15562/24227 [00:39<00:24, 359.25 examples/s]Tokenizing train dataset:  64%|██████▍   | 15489/24227 [00:39<00:23, 364.29 examples/s]Tokenizing train dataset:  64%|██████▍   | 15536/24227 [00:39<00:24, 358.99 examples/s]Tokenizing train dataset:  64%|██████▍   | 15603/24227 [00:39<00:23, 371.65 examples/s]Tokenizing train dataset:  64%|██████▍   | 15526/24227 [00:39<00:24, 359.51 examples/s]Tokenizing train dataset:  64%|██████▍   | 15574/24227 [00:39<00:23, 361.95 examples/s]Tokenizing train dataset:  64%|██████▍   | 15563/24227 [00:40<00:24, 359.82 examples/s]Tokenizing train dataset:  64%|██████▍   | 15613/24227 [00:39<00:23, 367.47 examples/s]Tokenizing train dataset:  65%|██████▍   | 15658/24227 [00:40<00:23, 365.79 examples/s]Tokenizing train dataset:  64%|██████▍   | 15604/24227 [00:40<00:23, 371.13 examples/s]Tokenizing train dataset:  65%|██████▍   | 15650/24227 [00:40<00:23, 365.24 examples/s]Tokenizing train dataset:  65%|██████▍   | 15698/24227 [00:40<00:22, 371.53 examples/s]Tokenizing train dataset:  65%|██████▍   | 15688/24227 [00:40<00:23, 366.37 examples/s]Tokenizing train dataset:  65%|██████▍   | 15740/24227 [00:40<00:22, 377.98 examples/s]Tokenizing train dataset:  65%|██████▍   | 15660/24227 [00:40<00:23, 364.72 examples/s]Tokenizing train dataset:  65%|██████▍   | 15731/24227 [00:40<00:22, 378.03 examples/s]Tokenizing train dataset:  65%|██████▍   | 15703/24227 [00:40<00:22, 373.65 examples/s]Tokenizing train dataset:  65%|██████▌   | 15795/24227 [00:40<00:22, 369.45 examples/s]Tokenizing train dataset:  65%|██████▌   | 15771/24227 [00:40<00:22, 377.64 examples/s]Tokenizing train dataset:  65%|██████▍   | 15742/24227 [00:40<00:22, 375.92 examples/s]Tokenizing train dataset:  65%|██████▌   | 15834/24227 [00:40<00:22, 372.36 examples/s]Tokenizing train dataset:  65%|██████▌   | 15809/24227 [00:40<00:22, 377.62 examples/s]Tokenizing train dataset:  65%|██████▌   | 15781/24227 [00:40<00:22, 376.85 examples/s]Tokenizing train dataset:  66%|██████▌   | 15890/24227 [00:40<00:22, 366.59 examples/s]Tokenizing train dataset:  65%|██████▌   | 15820/24227 [00:40<00:22, 372.61 examples/s]Tokenizing train dataset:  65%|██████▌   | 15864/24227 [00:40<00:22, 365.85 examples/s]Tokenizing train dataset:  66%|██████▌   | 15930/24227 [00:40<00:22, 371.18 examples/s]Tokenizing train dataset:  66%|██████▌   | 15906/24227 [00:40<00:22, 376.44 examples/s]Tokenizing train dataset:  66%|██████▌   | 15876/24227 [00:40<00:22, 366.14 examples/s]Tokenizing train dataset:  66%|██████▌   | 15980/24227 [00:40<00:23, 352.79 examples/s]Tokenizing train dataset:  66%|██████▌   | 15916/24227 [00:40<00:22, 372.76 examples/s]Tokenizing train dataset:  66%|██████▌   | 15959/24227 [00:40<00:22, 365.89 examples/s]Tokenizing train dataset:  66%|██████▌   | 16022/24227 [00:41<00:22, 364.53 examples/s]Tokenizing train dataset:  66%|██████▌   | 15969/24227 [00:41<00:22, 359.76 examples/s]Tokenizing train dataset:  66%|██████▌   | 16012/24227 [00:41<00:22, 358.77 examples/s]Tokenizing train dataset:  66%|██████▋   | 16061/24227 [00:41<00:22, 366.85 examples/s]Tokenizing train dataset:  66%|██████▌   | 16007/24227 [00:41<00:22, 359.76 examples/s]Tokenizing train dataset:  66%|██████▋   | 16052/24227 [00:41<00:22, 366.14 examples/s]Tokenizing train dataset:  66%|██████▋   | 16102/24227 [00:41<00:21, 370.02 examples/s]Tokenizing train dataset:  66%|██████▌   | 16046/24227 [00:41<00:22, 365.88 examples/s]Tokenizing train dataset:  67%|██████▋   | 16142/24227 [00:41<00:21, 377.48 examples/s]Tokenizing train dataset:  66%|██████▋   | 16110/24227 [00:41<00:21, 371.10 examples/s]Tokenizing train dataset:  67%|██████▋   | 16183/24227 [00:41<00:20, 383.14 examples/s]Tokenizing train dataset:  66%|██████▋   | 16103/24227 [00:41<00:22, 366.63 examples/s]Tokenizing train dataset:  67%|██████▋   | 16153/24227 [00:41<00:21, 383.74 examples/s]Tokenizing train dataset:  67%|██████▋   | 16146/24227 [00:41<00:21, 380.90 examples/s]Tokenizing train dataset:  67%|██████▋   | 16239/24227 [00:41<00:21, 370.93 examples/s]Tokenizing train dataset:  67%|██████▋   | 16211/24227 [00:41<00:21, 376.75 examples/s]Tokenizing train dataset:  67%|██████▋   | 16185/24227 [00:41<00:21, 380.25 examples/s]Tokenizing train dataset:  67%|██████▋   | 16294/24227 [00:41<00:21, 366.75 examples/s]Tokenizing train dataset:  67%|██████▋   | 16266/24227 [00:41<00:21, 370.84 examples/s]Tokenizing train dataset:  67%|██████▋   | 16240/24227 [00:41<00:21, 366.98 examples/s]Tokenizing train dataset:  67%|██████▋   | 16350/24227 [00:41<00:21, 363.88 examples/s]Tokenizing train dataset:  67%|██████▋   | 16279/24227 [00:41<00:21, 368.27 examples/s]Tokenizing train dataset:  67%|██████▋   | 16318/24227 [00:41<00:21, 361.12 examples/s]Tokenizing train dataset:  68%|██████▊   | 16355/24227 [00:41<00:21, 361.28 examples/s]Tokenizing train dataset:  68%|██████▊   | 16399/24227 [00:42<00:22, 349.05 examples/s]Tokenizing train dataset:  67%|██████▋   | 16334/24227 [00:42<00:21, 362.43 examples/s]Tokenizing train dataset:  68%|██████▊   | 16405/24227 [00:42<00:22, 349.48 examples/s]Tokenizing train dataset:  68%|██████▊   | 16450/24227 [00:42<00:22, 341.03 examples/s]Tokenizing train dataset:  68%|██████▊   | 16383/24227 [00:42<00:22, 347.82 examples/s]Tokenizing train dataset:  68%|██████▊   | 16492/24227 [00:42<00:21, 357.43 examples/s]Tokenizing train dataset:  68%|██████▊   | 16456/24227 [00:42<00:22, 344.33 examples/s]Tokenizing train dataset:  68%|██████▊   | 16435/24227 [00:42<00:22, 344.88 examples/s]Tokenizing train dataset:  68%|██████▊   | 16575/24227 [00:42<00:16, 470.61 examples/s]Tokenizing train dataset:  68%|██████▊   | 16502/24227 [00:42<00:20, 368.02 examples/s]Tokenizing train dataset:  68%|██████▊   | 16470/24227 [00:42<00:22, 339.86 examples/s]Tokenizing train dataset:  69%|██████▊   | 16638/24227 [00:42<00:14, 509.31 examples/s]Tokenizing train dataset:  68%|██████▊   | 16590/24227 [00:42<00:15, 489.06 examples/s]Tokenizing train dataset:  68%|██████▊   | 16541/24227 [00:42<00:17, 429.00 examples/s]Tokenizing train dataset:  69%|██████▉   | 16710/24227 [00:42<00:13, 560.76 examples/s]Tokenizing train dataset:  69%|██████▊   | 16652/24227 [00:42<00:14, 518.87 examples/s]Tokenizing train dataset:  69%|██████▊   | 16614/24227 [00:42<00:15, 506.00 examples/s]Tokenizing train dataset:  69%|██████▉   | 16780/24227 [00:42<00:12, 594.95 examples/s]Tokenizing train dataset:  69%|██████▉   | 16725/24227 [00:42<00:13, 567.49 examples/s]Tokenizing train dataset:  69%|██████▉   | 16680/24227 [00:42<00:13, 542.80 examples/s]Tokenizing train dataset:  70%|██████▉   | 16852/24227 [00:42<00:11, 629.31 examples/s]Tokenizing train dataset:  69%|██████▉   | 16798/24227 [00:42<00:12, 610.50 examples/s]Tokenizing train dataset:  69%|██████▉   | 16752/24227 [00:42<00:12, 584.23 examples/s]Tokenizing train dataset:  70%|██████▉   | 16923/24227 [00:42<00:11, 648.86 examples/s]Tokenizing train dataset:  70%|██████▉   | 16870/24227 [00:42<00:11, 639.29 examples/s]Tokenizing train dataset:  69%|██████▉   | 16826/24227 [00:43<00:11, 627.65 examples/s]Tokenizing train dataset:  70%|███████   | 16995/24227 [00:43<00:10, 665.54 examples/s]Tokenizing train dataset:  70%|██████▉   | 16940/24227 [00:42<00:11, 652.58 examples/s]Tokenizing train dataset:  70%|██████▉   | 16898/24227 [00:43<00:11, 652.09 examples/s]Tokenizing train dataset:  70%|███████   | 17013/24227 [00:43<00:10, 673.56 examples/s]Tokenizing train dataset:  71%|███████   | 17102/24227 [00:43<00:10, 682.03 examples/s]Tokenizing train dataset:  70%|███████   | 17001/24227 [00:43<00:11, 656.68 examples/s]Tokenizing train dataset:  71%|███████   | 17088/24227 [00:43<00:10, 687.12 examples/s]Tokenizing train dataset:  71%|███████   | 17180/24227 [00:43<00:09, 705.48 examples/s]Tokenizing train dataset:  70%|███████   | 17074/24227 [00:43<00:10, 666.50 examples/s]Tokenizing train dataset:  71%|███████   | 17166/24227 [00:43<00:09, 712.91 examples/s]Tokenizing train dataset:  71%|███████   | 17258/24227 [00:43<00:09, 721.42 examples/s]Tokenizing train dataset:  71%|███████   | 17156/24227 [00:43<00:10, 704.78 examples/s]Tokenizing train dataset:  71%|███████   | 17244/24227 [00:43<00:09, 725.84 examples/s]Tokenizing train dataset:  72%|███████▏  | 17370/24227 [00:43<00:09, 724.20 examples/s]Tokenizing train dataset:  71%|███████   | 17230/24227 [00:43<00:09, 709.76 examples/s]Tokenizing train dataset:  71%|███████▏  | 17320/24227 [00:43<00:09, 729.57 examples/s]Tokenizing train dataset:  71%|███████▏  | 17305/24227 [00:43<00:09, 716.30 examples/s]Tokenizing train dataset:  72%|███████▏  | 17398/24227 [00:43<00:09, 741.46 examples/s]Tokenizing train dataset:  72%|███████▏  | 17469/24227 [00:43<00:09, 696.37 examples/s]Tokenizing train dataset:  72%|███████▏  | 17381/24227 [00:43<00:09, 727.09 examples/s]Tokenizing train dataset:  72%|███████▏  | 17489/24227 [00:43<00:09, 687.17 examples/s]Tokenizing train dataset:  72%|███████▏  | 17562/24227 [00:43<00:09, 667.28 examples/s]Tokenizing train dataset:  72%|███████▏  | 17478/24227 [00:43<00:09, 689.43 examples/s]Tokenizing train dataset:  73%|███████▎  | 17578/24227 [00:43<00:10, 648.14 examples/s]Tokenizing train dataset:  73%|███████▎  | 17658/24227 [00:44<00:10, 652.76 examples/s]Tokenizing train dataset:  73%|███████▎  | 17568/24227 [00:44<00:10, 653.19 examples/s]Tokenizing train dataset:  73%|███████▎  | 17646/24227 [00:44<00:10, 653.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 17733/24227 [00:44<00:09, 673.35 examples/s]Tokenizing train dataset:  73%|███████▎  | 17715/24227 [00:44<00:09, 660.36 examples/s]Tokenizing train dataset:  73%|███████▎  | 17803/24227 [00:44<00:09, 677.23 examples/s]Tokenizing train dataset:  73%|███████▎  | 17660/24227 [00:44<00:10, 636.74 examples/s]Tokenizing train dataset:  73%|███████▎  | 17788/24227 [00:44<00:09, 676.41 examples/s]Tokenizing train dataset:  73%|███████▎  | 17739/24227 [00:44<00:09, 669.00 examples/s]Tokenizing train dataset:  74%|███████▍  | 17898/24227 [00:44<00:09, 654.20 examples/s]Tokenizing train dataset:  74%|███████▍  | 17883/24227 [00:44<00:09, 656.98 examples/s]Tokenizing train dataset:  74%|███████▍  | 17968/24227 [00:44<00:09, 664.12 examples/s]Tokenizing train dataset:  74%|███████▎  | 17840/24227 [00:44<00:09, 667.87 examples/s]Tokenizing train dataset:  74%|███████▍  | 18041/24227 [00:44<00:09, 680.12 examples/s]Tokenizing train dataset:  74%|███████▍  | 17988/24227 [00:44<00:09, 666.33 examples/s]Tokenizing train dataset:  74%|███████▍  | 17935/24227 [00:44<00:09, 651.66 examples/s]Tokenizing train dataset:  75%|███████▍  | 18120/24227 [00:44<00:08, 699.41 examples/s]Tokenizing train dataset:  75%|███████▍  | 18066/24227 [00:44<00:08, 693.32 examples/s]Tokenizing train dataset:  74%|███████▍  | 18009/24227 [00:44<00:09, 668.97 examples/s]Tokenizing train dataset:  75%|███████▌  | 18192/24227 [00:44<00:08, 704.15 examples/s]Tokenizing train dataset:  75%|███████▍  | 18138/24227 [00:44<00:08, 696.64 examples/s]Tokenizing train dataset:  75%|███████▍  | 18085/24227 [00:44<00:08, 689.60 examples/s]Tokenizing train dataset:  75%|███████▌  | 18271/24227 [00:44<00:08, 727.85 examples/s]Tokenizing train dataset:  75%|███████▌  | 18218/24227 [00:44<00:08, 720.74 examples/s]Tokenizing train dataset:  76%|███████▌  | 18349/24227 [00:45<00:07, 741.27 examples/s]Tokenizing train dataset:  75%|███████▌  | 18194/24227 [00:45<00:08, 700.81 examples/s]Tokenizing train dataset:  76%|███████▌  | 18337/24227 [00:44<00:07, 738.73 examples/s]Tokenizing train dataset:  75%|███████▌  | 18275/24227 [00:45<00:08, 722.41 examples/s]Tokenizing train dataset:  76%|███████▌  | 18454/24227 [00:45<00:07, 722.39 examples/s]Tokenizing train dataset:  76%|███████▌  | 18353/24227 [00:45<00:07, 734.30 examples/s]Tokenizing train dataset:  76%|███████▌  | 18440/24227 [00:45<00:08, 716.24 examples/s]Tokenizing train dataset:  77%|███████▋  | 18552/24227 [00:45<00:08, 695.40 examples/s]Tokenizing train dataset:  77%|███████▋  | 18542/24227 [00:45<00:08, 700.40 examples/s]Tokenizing train dataset:  76%|███████▌  | 18459/24227 [00:45<00:08, 714.72 examples/s]Tokenizing train dataset:  77%|███████▋  | 18662/24227 [00:45<00:07, 705.72 examples/s]Tokenizing train dataset:  77%|███████▋  | 18651/24227 [00:45<00:07, 705.44 examples/s]Tokenizing train dataset:  77%|███████▋  | 18558/24227 [00:45<00:08, 690.33 examples/s]Tokenizing train dataset:  77%|███████▋  | 18738/24227 [00:45<00:07, 716.98 examples/s]Tokenizing train dataset:  77%|███████▋  | 18728/24227 [00:45<00:07, 719.65 examples/s]Tokenizing train dataset:  77%|███████▋  | 18630/24227 [00:45<00:08, 694.24 examples/s]Tokenizing train dataset:  78%|███████▊  | 18818/24227 [00:45<00:07, 735.74 examples/s]Tokenizing train dataset:  78%|███████▊  | 18809/24227 [00:45<00:07, 740.90 examples/s]Tokenizing train dataset:  77%|███████▋  | 18707/24227 [00:45<00:07, 711.62 examples/s]Tokenizing train dataset:  78%|███████▊  | 18898/24227 [00:45<00:07, 750.96 examples/s]Tokenizing train dataset:  78%|███████▊  | 18890/24227 [00:45<00:07, 749.92 examples/s]Tokenizing train dataset:  78%|███████▊  | 18785/24227 [00:45<00:07, 726.05 examples/s]Tokenizing train dataset:  78%|███████▊  | 18995/24227 [00:45<00:07, 710.39 examples/s]Tokenizing train dataset:  78%|███████▊  | 18867/24227 [00:45<00:07, 748.70 examples/s]Tokenizing train dataset:  78%|███████▊  | 18992/24227 [00:45<00:07, 720.30 examples/s]Tokenizing train dataset:  79%|███████▉  | 19094/24227 [00:46<00:07, 689.30 examples/s]Tokenizing train dataset:  78%|███████▊  | 18971/24227 [00:46<00:07, 721.09 examples/s]Tokenizing train dataset:  79%|███████▉  | 19092/24227 [00:46<00:07, 694.33 examples/s]Tokenizing train dataset:  79%|███████▉  | 19174/24227 [00:46<00:07, 710.91 examples/s]Tokenizing train dataset:  79%|███████▉  | 19171/24227 [00:46<00:07, 714.21 examples/s]Tokenizing train dataset:  79%|███████▊  | 19070/24227 [00:46<00:07, 693.87 examples/s]Tokenizing train dataset:  79%|███████▉  | 19254/24227 [00:46<00:06, 728.27 examples/s]Tokenizing train dataset:  79%|███████▉  | 19145/24227 [00:46<00:07, 706.62 examples/s]Tokenizing train dataset:  79%|███████▉  | 19251/24227 [00:46<00:06, 730.74 examples/s]Tokenizing train dataset:  80%|███████▉  | 19342/24227 [00:46<00:07, 674.27 examples/s]Tokenizing train dataset:  79%|███████▉  | 19222/24227 [00:46<00:06, 721.30 examples/s]Tokenizing train dataset:  80%|███████▉  | 19342/24227 [00:46<00:07, 678.61 examples/s]Tokenizing train dataset:  80%|████████  | 19440/24227 [00:46<00:07, 657.04 examples/s]Tokenizing train dataset:  80%|███████▉  | 19323/24227 [00:46<00:06, 700.71 examples/s]Tokenizing train dataset:  80%|████████  | 19440/24227 [00:46<00:07, 660.93 examples/s]Tokenizing train dataset:  81%|████████  | 19568/24227 [00:46<00:05, 803.95 examples/s]Tokenizing train dataset:  80%|████████  | 19402/24227 [00:46<00:07, 639.26 examples/s]Tokenizing train dataset:  81%|████████  | 19568/24227 [00:46<00:05, 807.54 examples/s]Tokenizing train dataset:  81%|████████▏ | 19700/24227 [00:46<00:04, 932.02 examples/s]Tokenizing train dataset:  81%|████████  | 19510/24227 [00:46<00:06, 742.59 examples/s]Tokenizing train dataset:  81%|████████▏ | 19700/24227 [00:46<00:04, 935.83 examples/s]Tokenizing train dataset:  82%|████████▏ | 19823/24227 [00:46<00:04, 1009.82 examples/s]Tokenizing train dataset:  81%|████████  | 19641/24227 [00:46<00:05, 884.91 examples/s]Tokenizing train dataset:  82%|████████▏ | 19824/24227 [00:46<00:04, 1015.14 examples/s]Tokenizing train dataset:  82%|████████▏ | 19947/24227 [00:47<00:04, 1069.10 examples/s]Tokenizing train dataset:  82%|████████▏ | 19768/24227 [00:47<00:04, 985.54 examples/s]Tokenizing train dataset:  82%|████████▏ | 19948/24227 [00:46<00:03, 1075.10 examples/s]Tokenizing train dataset:  83%|████████▎ | 20076/24227 [00:47<00:03, 1130.38 examples/s]Tokenizing train dataset:  82%|████████▏ | 19890/24227 [00:47<00:04, 1044.01 examples/s]Tokenizing train dataset:  83%|████████▎ | 20079/24227 [00:47<00:03, 1137.98 examples/s]Tokenizing train dataset:  83%|████████▎ | 20203/24227 [00:47<00:03, 1168.84 examples/s]Tokenizing train dataset:  83%|████████▎ | 20019/24227 [00:47<00:03, 1111.72 examples/s]Tokenizing train dataset:  83%|████████▎ | 20206/24227 [00:47<00:03, 1174.62 examples/s]Tokenizing train dataset:  84%|████████▍ | 20323/24227 [00:47<00:03, 1176.14 examples/s]Tokenizing train dataset:  83%|████████▎ | 20143/24227 [00:47<00:03, 1146.07 examples/s]Tokenizing train dataset:  84%|████████▍ | 20328/24227 [00:47<00:03, 1185.26 examples/s]Tokenizing train dataset:  84%|████████▍ | 20445/24227 [00:47<00:03, 1186.50 examples/s]Tokenizing train dataset:  84%|████████▎ | 20267/24227 [00:47<00:03, 1171.18 examples/s]Tokenizing train dataset:  84%|████████▍ | 20450/24227 [00:47<00:03, 1189.50 examples/s]Tokenizing train dataset:  85%|████████▌ | 20620/24227 [00:47<00:03, 1171.20 examples/s]Tokenizing train dataset:  84%|████████▍ | 20390/24227 [00:47<00:03, 1180.43 examples/s]Tokenizing train dataset:  85%|████████▌ | 20628/24227 [00:47<00:03, 1181.24 examples/s]Tokenizing train dataset:  86%|████████▌ | 20744/24227 [00:47<00:02, 1188.05 examples/s]Tokenizing train dataset:  85%|████████▍ | 20567/24227 [00:47<00:03, 1176.30 examples/s]Tokenizing train dataset:  86%|████████▌ | 20751/24227 [00:47<00:02, 1190.81 examples/s]Tokenizing train dataset:  86%|████████▋ | 20923/24227 [00:47<00:02, 1187.24 examples/s]Tokenizing train dataset:  85%|████████▌ | 20686/24227 [00:47<00:03, 1176.60 examples/s]Tokenizing train dataset:  86%|████████▌ | 20872/24227 [00:47<00:02, 1194.30 examples/s]Tokenizing train dataset:  87%|████████▋ | 21045/24227 [00:47<00:02, 1192.90 examples/s]Tokenizing train dataset:  86%|████████▌ | 20865/24227 [00:47<00:02, 1179.79 examples/s]Tokenizing train dataset:  87%|████████▋ | 21055/24227 [00:47<00:02, 1200.44 examples/s]Tokenizing train dataset:  87%|████████▋ | 21166/24227 [00:48<00:02, 1194.41 examples/s]Tokenizing train dataset:  87%|████████▋ | 21177/24227 [00:47<00:02, 1204.39 examples/s]Tokenizing train dataset:  88%|████████▊ | 21295/24227 [00:48<00:02, 1215.57 examples/s]Tokenizing train dataset:  87%|████████▋ | 21046/24227 [00:48<00:02, 1183.41 examples/s]Tokenizing train dataset:  88%|████████▊ | 21303/24227 [00:48<00:02, 1216.66 examples/s]Tokenizing train dataset:  87%|████████▋ | 21167/24227 [00:48<00:02, 1189.19 examples/s]Tokenizing train dataset:  89%|████████▊ | 21479/24227 [00:48<00:02, 1216.45 examples/s]Tokenizing train dataset:  88%|████████▊ | 21428/24227 [00:48<00:02, 1225.43 examples/s]Tokenizing train dataset:  88%|████████▊ | 21295/24227 [00:48<00:02, 1207.95 examples/s]Tokenizing train dataset:  89%|████████▉ | 21654/24227 [00:48<00:02, 1196.66 examples/s]Tokenizing train dataset:  89%|████████▉ | 21610/24227 [00:48<00:02, 1216.68 examples/s]Tokenizing train dataset:  89%|████████▊ | 21478/24227 [00:48<00:02, 1208.61 examples/s]Tokenizing train dataset:  90%|████████▉ | 21777/24227 [00:48<00:02, 1202.50 examples/s]Tokenizing train dataset:  90%|████████▉ | 21792/24227 [00:48<00:02, 1211.73 examples/s]Tokenizing train dataset:  90%|█████████ | 21903/24227 [00:48<00:01, 1214.38 examples/s]Tokenizing train dataset:  89%|████████▉ | 21654/24227 [00:48<00:02, 1192.24 examples/s]Tokenizing train dataset:  90%|█████████ | 21916/24227 [00:48<00:01, 1217.00 examples/s]Tokenizing train dataset:  90%|████████▉ | 21777/24227 [00:48<00:02, 1197.95 examples/s]Tokenizing train dataset:  91%|█████████ | 22086/24227 [00:48<00:01, 1211.70 examples/s]Tokenizing train dataset:  90%|█████████ | 21901/24227 [00:48<00:01, 1207.38 examples/s]Tokenizing train dataset:  91%|█████████ | 22100/24227 [00:48<00:01, 1214.41 examples/s]Tokenizing train dataset:  92%|█████████▏| 22264/24227 [00:48<00:01, 1200.27 examples/s]Tokenizing train dataset:  91%|█████████ | 22085/24227 [00:48<00:01, 1205.92 examples/s]Tokenizing train dataset:  92%|█████████▏| 22280/24227 [00:48<00:01, 1202.91 examples/s]Tokenizing train dataset:  93%|█████████▎| 22445/24227 [00:49<00:01, 1196.17 examples/s]Tokenizing train dataset:  92%|█████████▏| 22262/24227 [00:49<00:01, 1194.39 examples/s]Tokenizing train dataset:  93%|█████████▎| 22465/24227 [00:49<00:01, 1208.31 examples/s]Tokenizing train dataset:  93%|█████████▎| 22626/24227 [00:49<00:01, 1197.68 examples/s]Tokenizing train dataset:  93%|█████████▎| 22442/24227 [00:49<00:01, 1192.34 examples/s]Tokenizing train dataset:  93%|█████████▎| 22646/24227 [00:49<00:01, 1203.45 examples/s]Tokenizing train dataset:  94%|█████████▍| 22750/24227 [00:49<00:01, 1204.16 examples/s]Tokenizing train dataset:  94%|█████████▍| 22770/24227 [00:49<00:01, 1208.28 examples/s]Tokenizing train dataset:  94%|█████████▍| 22874/24227 [00:49<00:01, 1209.40 examples/s]Tokenizing train dataset:  93%|█████████▎| 22622/24227 [00:49<00:01, 1189.59 examples/s]Tokenizing train dataset:  95%|█████████▍| 22898/24227 [00:49<00:01, 1224.17 examples/s]Tokenizing train dataset:  95%|█████████▍| 22999/24227 [00:49<00:01, 1217.44 examples/s]Tokenizing train dataset:  94%|█████████▍| 22745/24227 [00:49<00:01, 1197.52 examples/s]Tokenizing train dataset:  95%|█████████▌| 23021/24227 [00:49<00:00, 1222.15 examples/s]Tokenizing train dataset:  95%|█████████▌| 23125/24227 [00:49<00:00, 1226.69 examples/s]Tokenizing train dataset:  94%|█████████▍| 22868/24227 [00:49<00:01, 1203.31 examples/s]Tokenizing train dataset:  96%|█████████▌| 23149/24227 [00:49<00:00, 1236.24 examples/s]Tokenizing train dataset:  95%|█████████▍| 22992/24227 [00:49<00:01, 1206.39 examples/s]Tokenizing train dataset:  96%|█████████▌| 23310/24227 [00:49<00:00, 1221.90 examples/s]Tokenizing train dataset:  95%|█████████▌| 23119/24227 [00:49<00:00, 1222.22 examples/s]Tokenizing train dataset:  96%|█████████▋| 23334/24227 [00:49<00:00, 1229.30 examples/s]Tokenizing train dataset:  97%|█████████▋| 23434/24227 [00:49<00:00, 1224.71 examples/s]Tokenizing train dataset:  97%|█████████▋| 23459/24227 [00:49<00:00, 1230.64 examples/s]Tokenizing train dataset:  97%|█████████▋| 23558/24227 [00:49<00:00, 1226.71 examples/s]Tokenizing train dataset:  96%|█████████▌| 23302/24227 [00:49<00:00, 1216.08 examples/s]Tokenizing train dataset:  97%|█████████▋| 23426/24227 [00:50<00:00, 1219.72 examples/s]Tokenizing train dataset:  98%|█████████▊| 23643/24227 [00:49<00:00, 1226.63 examples/s]Tokenizing train dataset:  98%|█████████▊| 23737/24227 [00:50<00:00, 1208.14 examples/s]Tokenizing train dataset:  97%|█████████▋| 23549/24227 [00:50<00:00, 1221.20 examples/s]Tokenizing train dataset:  98%|█████████▊| 23862/24227 [00:50<00:00, 1216.03 examples/s]Tokenizing train dataset:  98%|█████████▊| 23826/24227 [00:50<00:00, 1219.52 examples/s]Tokenizing train dataset:  98%|█████████▊| 23723/24227 [00:50<00:00, 1197.94 examples/s]Tokenizing train dataset:  99%|█████████▉| 24040/24227 [00:50<00:00, 1200.09 examples/s]Tokenizing train dataset:  99%|█████████▉| 24006/24227 [00:50<00:00, 1211.99 examples/s]Tokenizing train dataset:  98%|█████████▊| 23849/24227 [00:50<00:00, 1213.01 examples/s]Tokenizing train dataset: 100%|█████████▉| 24167/24227 [00:50<00:00, 1215.81 examples/s]Tokenizing train dataset: 100%|█████████▉| 24130/24227 [00:50<00:00, 1216.38 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [00:50<00:00, 479.10 examples/s] 
Tokenizing train dataset:  99%|█████████▉| 24027/24227 [00:50<00:00, 1200.59 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [00:50<00:00, 479.75 examples/s] 
Tokenizing train dataset: 100%|█████████▉| 24150/24227 [00:50<00:00, 1202.96 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [00:50<00:00, 477.14 examples/s] 
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5424.94 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5519.66 examples/s]Extracting prompt in eval dataset:  55%|█████▍    | 520/953 [00:00<00:00, 5084.44 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5524.43 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5441.99 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5292.56 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  27%|██▋       | 260/953 [00:00<00:00, 2577.76 examples/s]Applying chat template to eval dataset:  28%|██▊       | 267/953 [00:00<00:00, 2632.25 examples/s]Applying chat template to eval dataset:  28%|██▊       | 270/953 [00:00<00:00, 2660.46 examples/s]Applying chat template to eval dataset:  57%|█████▋    | 540/953 [00:00<00:00, 2697.19 examples/s]Applying chat template to eval dataset:  57%|█████▋    | 543/953 [00:00<00:00, 2700.80 examples/s]Applying chat template to eval dataset:  58%|█████▊    | 551/953 [00:00<00:00, 2744.73 examples/s]Applying chat template to eval dataset:  86%|████████▋ | 822/953 [00:00<00:00, 2750.98 examples/s]Applying chat template to eval dataset:  87%|████████▋ | 825/953 [00:00<00:00, 2750.92 examples/s]Applying chat template to eval dataset:  88%|████████▊ | 836/953 [00:00<00:00, 2789.13 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2716.20 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2726.92 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2754.48 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 30/953 [00:00<00:03, 284.91 examples/s]Tokenizing eval dataset:   3%|▎         | 29/953 [00:00<00:03, 286.47 examples/s]Tokenizing eval dataset:   3%|▎         | 30/953 [00:00<00:03, 284.19 examples/s]Tokenizing eval dataset:   7%|▋         | 66/953 [00:00<00:03, 255.79 examples/s]Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:03, 253.21 examples/s]Tokenizing eval dataset:   7%|▋         | 67/953 [00:00<00:03, 253.04 examples/s]Tokenizing eval dataset:  10%|▉         | 93/953 [00:00<00:03, 257.18 examples/s]Tokenizing eval dataset:  10%|▉         | 95/953 [00:00<00:03, 255.17 examples/s]Tokenizing eval dataset:  10%|▉         | 94/953 [00:00<00:03, 255.67 examples/s]Tokenizing eval dataset:  13%|█▎        | 127/953 [00:00<00:03, 236.84 examples/s]Tokenizing eval dataset:  14%|█▎        | 130/953 [00:00<00:03, 237.77 examples/s]Tokenizing eval dataset:  13%|█▎        | 127/953 [00:00<00:03, 236.25 examples/s]Tokenizing eval dataset:  17%|█▋        | 161/953 [00:00<00:03, 226.65 examples/s]Tokenizing eval dataset:  17%|█▋        | 163/953 [00:00<00:03, 225.86 examples/s]Tokenizing eval dataset:  17%|█▋        | 161/953 [00:00<00:03, 226.22 examples/s]Tokenizing eval dataset:  20%|██        | 193/953 [00:00<00:03, 213.59 examples/s]Tokenizing eval dataset:  20%|██        | 191/953 [00:00<00:03, 211.56 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:00<00:03, 208.68 examples/s]Tokenizing eval dataset:  23%|██▎       | 216/953 [00:00<00:03, 217.16 examples/s]Tokenizing eval dataset:  23%|██▎       | 216/953 [00:00<00:03, 217.58 examples/s]Tokenizing eval dataset:  22%|██▏       | 214/953 [00:00<00:03, 215.11 examples/s]Tokenizing eval dataset:  29%|██▊       | 272/953 [00:01<00:02, 301.93 examples/s]Tokenizing eval dataset:  29%|██▊       | 272/953 [00:01<00:02, 301.63 examples/s]Tokenizing eval dataset:  28%|██▊       | 268/953 [00:01<00:02, 295.46 examples/s]Tokenizing eval dataset:  35%|███▍      | 332/953 [00:01<00:01, 378.15 examples/s]Tokenizing eval dataset:  35%|███▍      | 332/953 [00:01<00:01, 377.88 examples/s]Tokenizing eval dataset:  34%|███▍      | 328/953 [00:01<00:01, 374.92 examples/s]Tokenizing eval dataset:  41%|████      | 387/953 [00:01<00:01, 422.52 examples/s]Tokenizing eval dataset:  41%|████      | 389/953 [00:01<00:01, 427.74 examples/s]Tokenizing eval dataset:  40%|████      | 384/953 [00:01<00:01, 423.41 examples/s]Tokenizing eval dataset:  48%|████▊     | 457/953 [00:01<00:00, 497.15 examples/s]Tokenizing eval dataset:  48%|████▊     | 460/953 [00:01<00:00, 503.41 examples/s]Tokenizing eval dataset:  47%|████▋     | 450/953 [00:01<00:01, 488.26 examples/s]Tokenizing eval dataset:  54%|█████▍    | 516/953 [00:01<00:00, 519.46 examples/s]Tokenizing eval dataset:  54%|█████▍    | 518/953 [00:01<00:00, 522.97 examples/s]Tokenizing eval dataset:  54%|█████▍    | 513/953 [00:01<00:00, 523.76 examples/s]Tokenizing eval dataset:  61%|██████    | 582/953 [00:01<00:00, 557.16 examples/s]Tokenizing eval dataset:  61%|██████    | 583/953 [00:01<00:00, 557.63 examples/s]Tokenizing eval dataset:  61%|██████    | 577/953 [00:01<00:00, 555.09 examples/s]Tokenizing eval dataset:  68%|██████▊   | 648/953 [00:01<00:00, 582.75 examples/s]Tokenizing eval dataset:  68%|██████▊   | 648/953 [00:01<00:00, 582.40 examples/s]Tokenizing eval dataset:  68%|██████▊   | 644/953 [00:01<00:00, 581.07 examples/s]Tokenizing eval dataset:  74%|███████▍  | 708/953 [00:01<00:00, 583.41 examples/s]Tokenizing eval dataset:  74%|███████▍  | 708/953 [00:01<00:00, 583.26 examples/s]Tokenizing eval dataset:  77%|███████▋  | 733/953 [00:01<00:00, 577.16 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:01<00:00, 551.07 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:01<00:00, 551.60 examples/s]Tokenizing eval dataset:  84%|████████▍ | 804/953 [00:01<00:00, 532.72 examples/s]Tokenizing eval dataset:  90%|████████▉ | 856/953 [00:02<00:00, 514.12 examples/s]Tokenizing eval dataset:  90%|████████▉ | 856/953 [00:02<00:00, 513.30 examples/s]Tokenizing eval dataset:  92%|█████████▏| 875/953 [00:02<00:00, 506.86 examples/s]Tokenizing eval dataset:  97%|█████████▋| 926/953 [00:02<00:00, 491.72 examples/s]Tokenizing eval dataset:  97%|█████████▋| 926/953 [00:02<00:00, 490.76 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 413.97 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 414.78 examples/s]
Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:02<00:00, 481.10 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 411.37 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.5036635398864746 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3669273853302 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3371012210845947 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3608474731445312 seconds
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250612_005945-t5qe9bxf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-1e-07_e-3_b-0.1_63057121
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/t5qe9bxf
  0%|          | 0/4545 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/4545 [00:13<16:30:01, 13.07s/it]  0%|          | 2/4545 [00:16<9:38:08,  7.64s/it]   0%|          | 3/4545 [00:20<7:28:45,  5.93s/it]  0%|          | 4/4545 [00:24<6:19:04,  5.01s/it]  0%|          | 5/4545 [00:28<5:48:54,  4.61s/it]  0%|          | 6/4545 [00:32<5:38:24,  4.47s/it]  0%|          | 7/4545 [00:36<5:29:08,  4.35s/it]  0%|          | 8/4545 [00:40<5:16:45,  4.19s/it]  0%|          | 9/4545 [00:44<5:14:36,  4.16s/it]  0%|          | 10/4545 [00:48<5:03:39,  4.02s/it]                                                   {'loss': 0.7064, 'grad_norm': 28.90797996520996, 'learning_rate': 5.9445178335535e-10, 'rewards/chosen': -0.02097778394818306, 'rewards/rejected': -0.0034927367232739925, 'rewards/accuracies': 0.11874999850988388, 'rewards/margins': -0.0174560546875, 'logps/chosen': -447.75, 'logps/rejected': -256.7749938964844, 'logits/chosen': -6.0625, 'logits/rejected': -6.165625095367432, 'epoch': 0.01}
  0%|          | 10/4545 [00:48<5:03:39,  4.02s/it]  0%|          | 11/4545 [00:52<5:06:55,  4.06s/it]  0%|          | 12/4545 [00:56<5:03:05,  4.01s/it]  0%|          | 13/4545 [00:58<4:21:59,  3.47s/it]  0%|          | 14/4545 [01:01<4:18:14,  3.42s/it]  0%|          | 15/4545 [01:05<4:28:53,  3.56s/it]  0%|          | 16/4545 [01:09<4:23:50,  3.50s/it]  0%|          | 17/4545 [01:12<4:32:41,  3.61s/it]  0%|          | 18/4545 [01:17<4:44:52,  3.78s/it]  0%|          | 19/4545 [01:20<4:26:15,  3.53s/it]  0%|          | 20/4545 [01:23<4:34:42,  3.64s/it]                                                   {'loss': 0.6982, 'grad_norm': 29.624610900878906, 'learning_rate': 1.2549537648612944e-09, 'rewards/chosen': 0.0026344298385083675, 'rewards/rejected': 0.003287887666374445, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.0006500243907794356, 'logps/chosen': -254.6750030517578, 'logps/rejected': -121.05000305175781, 'logits/chosen': -6.28125, 'logits/rejected': -6.671875, 'epoch': 0.01}
  0%|          | 20/4545 [01:23<4:34:42,  3.64s/it]  0%|          | 21/4545 [01:27<4:24:56,  3.51s/it]  0%|          | 22/4545 [01:31<4:32:53,  3.62s/it]  1%|          | 23/4545 [01:34<4:39:34,  3.71s/it]  1%|          | 24/4545 [01:38<4:30:19,  3.59s/it]  1%|          | 25/4545 [01:42<4:37:26,  3.68s/it]  1%|          | 26/4545 [01:45<4:29:33,  3.58s/it]  1%|          | 27/4545 [01:49<4:37:10,  3.68s/it]  1%|          | 28/4545 [01:53<4:41:11,  3.74s/it]  1%|          | 29/4545 [01:57<4:46:06,  3.80s/it]  1%|          | 30/4545 [02:01<4:54:39,  3.92s/it]                                                   {'loss': 0.6909, 'grad_norm': 26.07942771911621, 'learning_rate': 1.915455746367239e-09, 'rewards/chosen': 0.017560195177793503, 'rewards/rejected': -0.0047668456099927425, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': 0.02239837683737278, 'logps/chosen': -283.1000061035156, 'logps/rejected': -142.5, 'logits/chosen': -6.199999809265137, 'logits/rejected': -6.553124904632568, 'epoch': 0.02}
  1%|          | 30/4545 [02:01<4:54:39,  3.92s/it]  1%|          | 31/4545 [02:05<4:56:14,  3.94s/it]  1%|          | 32/4545 [02:09<4:57:49,  3.96s/it]  1%|          | 33/4545 [02:13<4:59:32,  3.98s/it]  1%|          | 34/4545 [02:17<5:03:05,  4.03s/it]  1%|          | 35/4545 [02:21<4:59:56,  3.99s/it]  1%|          | 36/4545 [02:25<4:52:15,  3.89s/it]  1%|          | 37/4545 [02:28<4:43:47,  3.78s/it]  1%|          | 38/4545 [02:32<4:41:20,  3.75s/it]  1%|          | 39/4545 [02:36<4:44:59,  3.79s/it]  1%|          | 40/4545 [02:40<4:47:23,  3.83s/it]                                                   {'loss': 0.6973, 'grad_norm': 164.4727325439453, 'learning_rate': 2.5759577278731833e-09, 'rewards/chosen': 0.00482177734375, 'rewards/rejected': 0.010528564453125, 'rewards/accuracies': 0.39375001192092896, 'rewards/margins': -0.00570754986256361, 'logps/chosen': -416.20001220703125, 'logps/rejected': -175.1999969482422, 'logits/chosen': -6.265625, 'logits/rejected': -6.559374809265137, 'epoch': 0.03}
  1%|          | 40/4545 [02:40<4:47:23,  3.83s/it]  1%|          | 41/4545 [02:43<4:39:31,  3.72s/it]  1%|          | 42/4545 [02:47<4:46:20,  3.82s/it]  1%|          | 43/4545 [02:51<4:48:49,  3.85s/it]  1%|          | 44/4545 [02:55<4:53:33,  3.91s/it]  1%|          | 45/4545 [02:59<4:57:51,  3.97s/it]  1%|          | 46/4545 [03:03<4:55:55,  3.95s/it]  1%|          | 47/4545 [03:07<4:47:58,  3.84s/it]  1%|          | 48/4545 [03:11<4:49:25,  3.86s/it]  1%|          | 49/4545 [03:15<4:50:21,  3.87s/it]  1%|          | 50/4545 [03:18<4:51:10,  3.89s/it]                                                   {'loss': 0.7317, 'grad_norm': 189.97792053222656, 'learning_rate': 3.236459709379128e-09, 'rewards/chosen': -0.04275817796587944, 'rewards/rejected': 0.0021697997581213713, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': -0.044830322265625, 'logps/chosen': -367.04998779296875, 'logps/rejected': -201.0, 'logits/chosen': -6.284375190734863, 'logits/rejected': -6.478125095367432, 'epoch': 0.03}
  1%|          | 50/4545 [03:18<4:51:10,  3.89s/it]  1%|          | 51/4545 [03:22<4:50:36,  3.88s/it]  1%|          | 52/4545 [03:26<4:48:15,  3.85s/it]  1%|          | 53/4545 [03:30<4:43:11,  3.78s/it]  1%|          | 54/4545 [03:34<4:50:17,  3.88s/it]  1%|          | 55/4545 [03:38<4:50:45,  3.89s/it]  1%|          | 56/4545 [03:42<4:47:57,  3.85s/it]  1%|▏         | 57/4545 [03:45<4:49:26,  3.87s/it]  1%|▏         | 58/4545 [03:49<4:45:18,  3.82s/it]  1%|▏         | 59/4545 [03:52<4:28:58,  3.60s/it]  1%|▏         | 60/4545 [03:56<4:36:27,  3.70s/it]                                                   {'loss': 0.711, 'grad_norm': 29.479026794433594, 'learning_rate': 3.896961690885073e-09, 'rewards/chosen': -0.02115326002240181, 'rewards/rejected': 0.0020080567337572575, 'rewards/accuracies': 0.4312500059604645, 'rewards/margins': -0.02308044396340847, 'logps/chosen': -227.35000610351562, 'logps/rejected': -122.625, 'logits/chosen': -6.384375095367432, 'logits/rejected': -6.590624809265137, 'epoch': 0.04}
  1%|▏         | 60/4545 [03:56<4:36:27,  3.70s/it]  1%|▏         | 61/4545 [03:59<4:24:02,  3.53s/it]  1%|▏         | 62/4545 [04:03<4:26:48,  3.57s/it]  1%|▏         | 63/4545 [04:07<4:34:13,  3.67s/it]  1%|▏         | 64/4545 [04:11<4:40:05,  3.75s/it]  1%|▏         | 65/4545 [04:14<4:18:29,  3.46s/it]  1%|▏         | 66/4545 [04:17<4:22:38,  3.52s/it]  1%|▏         | 67/4545 [04:21<4:32:57,  3.66s/it]  1%|▏         | 68/4545 [04:25<4:32:11,  3.65s/it]  2%|▏         | 69/4545 [04:29<4:38:08,  3.73s/it]  2%|▏         | 70/4545 [04:32<4:36:32,  3.71s/it]                                                   {'loss': 0.6927, 'grad_norm': 31.15708351135254, 'learning_rate': 4.557463672391017e-09, 'rewards/chosen': 0.01090316753834486, 'rewards/rejected': -8.277893357444555e-05, 'rewards/accuracies': 0.5, 'rewards/margins': 0.01092681847512722, 'logps/chosen': -315.8500061035156, 'logps/rejected': -155.0500030517578, 'logits/chosen': -6.159375190734863, 'logits/rejected': -6.565625190734863, 'epoch': 0.05}
  2%|▏         | 70/4545 [04:32<4:36:32,  3.71s/it]  2%|▏         | 71/4545 [04:37<4:45:14,  3.83s/it]  2%|▏         | 72/4545 [04:40<4:28:16,  3.60s/it]  2%|▏         | 73/4545 [04:44<4:39:53,  3.76s/it]  2%|▏         | 74/4545 [04:48<4:46:46,  3.85s/it]  2%|▏         | 75/4545 [04:52<4:47:43,  3.86s/it]  2%|▏         | 76/4545 [04:55<4:42:17,  3.79s/it]  2%|▏         | 77/4545 [04:59<4:47:08,  3.86s/it]  2%|▏         | 78/4545 [05:03<4:50:06,  3.90s/it]  2%|▏         | 79/4545 [05:07<4:50:32,  3.90s/it]  2%|▏         | 80/4545 [05:11<4:51:47,  3.92s/it]                                                   {'loss': 0.701, 'grad_norm': 175.83453369140625, 'learning_rate': 5.217965653896962e-09, 'rewards/chosen': 0.0021423338912427425, 'rewards/rejected': -0.00780563335865736, 'rewards/accuracies': 0.4625000059604645, 'rewards/margins': 0.009938049130141735, 'logps/chosen': -352.8500061035156, 'logps/rejected': -217.02499389648438, 'logits/chosen': -6.240624904632568, 'logits/rejected': -6.425000190734863, 'epoch': 0.05}
  2%|▏         | 80/4545 [05:11<4:51:47,  3.92s/it]  2%|▏         | 81/4545 [05:15<4:51:05,  3.91s/it]  2%|▏         | 82/4545 [05:19<4:46:28,  3.85s/it]  2%|▏         | 83/4545 [05:23<4:45:17,  3.84s/it]  2%|▏         | 84/4545 [05:25<4:23:58,  3.55s/it]  2%|▏         | 85/4545 [05:30<4:36:12,  3.72s/it]  2%|▏         | 86/4545 [05:34<4:43:26,  3.81s/it]  2%|▏         | 87/4545 [05:38<4:45:44,  3.85s/it]  2%|▏         | 88/4545 [05:41<4:47:02,  3.86s/it]  2%|▏         | 89/4545 [05:45<4:30:49,  3.65s/it]  2%|▏         | 90/4545 [05:48<4:23:49,  3.55s/it]                                                   {'loss': 0.7129, 'grad_norm': 32.90862274169922, 'learning_rate': 5.878467635402906e-09, 'rewards/chosen': -0.015045166015625, 'rewards/rejected': 0.010936546139419079, 'rewards/accuracies': 0.375, 'rewards/margins': -0.0260162353515625, 'logps/chosen': -322.25, 'logps/rejected': -167.39999389648438, 'logits/chosen': -6.375, 'logits/rejected': -6.646874904632568, 'epoch': 0.06}
  2%|▏         | 90/4545 [05:48<4:23:49,  3.55s/it]  2%|▏         | 91/4545 [05:52<4:34:02,  3.69s/it]  2%|▏         | 92/4545 [05:56<4:38:47,  3.76s/it]  2%|▏         | 93/4545 [06:00<4:41:56,  3.80s/it]  2%|▏         | 94/4545 [06:04<4:44:18,  3.83s/it]  2%|▏         | 95/4545 [06:08<4:45:38,  3.85s/it]  2%|▏         | 96/4545 [06:11<4:45:42,  3.85s/it]  2%|▏         | 97/4545 [06:15<4:49:57,  3.91s/it]  2%|▏         | 98/4545 [06:19<4:36:40,  3.73s/it]  2%|▏         | 99/4545 [06:22<4:20:11,  3.51s/it]  2%|▏         | 100/4545 [06:25<4:20:26,  3.52s/it]                                                    {'loss': 0.6916, 'grad_norm': 21.573516845703125, 'learning_rate': 6.53896961690885e-09, 'rewards/chosen': -0.01006469689309597, 'rewards/rejected': -0.01772308349609375, 'rewards/accuracies': 0.40625, 'rewards/margins': 0.0076904296875, 'logps/chosen': -330.5, 'logps/rejected': -159.8125, 'logits/chosen': -6.3125, 'logits/rejected': -6.675000190734863, 'epoch': 0.07}
  2%|▏         | 100/4545 [06:25<4:20:26,  3.52s/it]  2%|▏         | 101/4545 [06:29<4:29:10,  3.63s/it]  2%|▏         | 102/4545 [06:33<4:34:35,  3.71s/it]  2%|▏         | 103/4545 [06:36<4:09:41,  3.37s/it]  2%|▏         | 104/4545 [06:39<4:13:38,  3.43s/it]  2%|▏         | 105/4545 [06:43<4:16:59,  3.47s/it]  2%|▏         | 106/4545 [06:47<4:22:44,  3.55s/it]  2%|▏         | 107/4545 [06:51<4:33:04,  3.69s/it]  2%|▏         | 108/4545 [06:54<4:31:25,  3.67s/it]  2%|▏         | 109/4545 [06:58<4:36:56,  3.75s/it]  2%|▏         | 110/4545 [07:02<4:46:36,  3.88s/it]                                                    {'loss': 0.6963, 'grad_norm': 273.9809265136719, 'learning_rate': 7.1994715984147955e-09, 'rewards/chosen': -0.007781982421875, 'rewards/rejected': -0.0025619505904614925, 'rewards/accuracies': 0.4312500059604645, 'rewards/margins': -0.00524139404296875, 'logps/chosen': -221.5500030517578, 'logps/rejected': -128.4499969482422, 'logits/chosen': -6.318749904632568, 'logits/rejected': -6.646874904632568, 'epoch': 0.07}
  2%|▏         | 110/4545 [07:02<4:46:36,  3.88s/it]  2%|▏         | 111/4545 [07:06<4:47:28,  3.89s/it]  2%|▏         | 112/4545 [07:10<4:47:52,  3.90s/it]  2%|▏         | 113/4545 [07:14<4:48:00,  3.90s/it]  3%|▎         | 114/4545 [07:18<4:48:02,  3.90s/it]  3%|▎         | 115/4545 [07:22<4:48:12,  3.90s/it]  3%|▎         | 116/4545 [07:26<4:48:33,  3.91s/it]  3%|▎         | 117/4545 [07:30<4:54:57,  4.00s/it]  3%|▎         | 118/4545 [07:34<4:59:42,  4.06s/it]  3%|▎         | 119/4545 [07:38<4:54:43,  4.00s/it]  3%|▎         | 120/4545 [07:42<4:46:29,  3.88s/it]                                                    {'loss': 0.6955, 'grad_norm': 24.671871185302734, 'learning_rate': 7.85997357992074e-09, 'rewards/chosen': -0.006619262509047985, 'rewards/rejected': -0.00379180908203125, 'rewards/accuracies': 0.39375001192092896, 'rewards/margins': -0.0028442381881177425, 'logps/chosen': -430.0, 'logps/rejected': -149.72500610351562, 'logits/chosen': -6.128125190734863, 'logits/rejected': -6.65625, 'epoch': 0.08}
  3%|▎         | 120/4545 [07:42<4:46:29,  3.88s/it]  3%|▎         | 121/4545 [07:46<4:46:52,  3.89s/it]  3%|▎         | 122/4545 [07:49<4:47:01,  3.89s/it]  3%|▎         | 123/4545 [07:53<4:46:56,  3.89s/it]  3%|▎         | 124/4545 [07:57<4:41:35,  3.82s/it]  3%|▎         | 125/4545 [08:01<4:48:32,  3.92s/it]  3%|▎         | 126/4545 [08:05<4:48:21,  3.92s/it]  3%|▎         | 127/4545 [08:09<4:41:58,  3.83s/it]  3%|▎         | 128/4545 [08:13<4:42:34,  3.84s/it]  3%|▎         | 129/4545 [08:16<4:43:43,  3.86s/it]  3%|▎         | 130/4545 [08:20<4:45:25,  3.88s/it]                                                    {'loss': 0.6892, 'grad_norm': 161.01629638671875, 'learning_rate': 8.520475561426684e-09, 'rewards/chosen': 0.007441711612045765, 'rewards/rejected': -0.01007843017578125, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': 0.01753387413918972, 'logps/chosen': -398.75, 'logps/rejected': -264.5, 'logits/chosen': -6.168749809265137, 'logits/rejected': -6.381249904632568, 'epoch': 0.09}
  3%|▎         | 130/4545 [08:20<4:45:25,  3.88s/it]  3%|▎         | 131/4545 [08:24<4:45:59,  3.89s/it]  3%|▎         | 132/4545 [08:28<4:37:45,  3.78s/it]  3%|▎         | 133/4545 [08:31<4:21:10,  3.55s/it]  3%|▎         | 134/4545 [08:34<4:21:13,  3.55s/it]  3%|▎         | 135/4545 [08:37<3:56:05,  3.21s/it]  3%|▎         | 136/4545 [08:40<3:53:41,  3.18s/it]  3%|▎         | 137/4545 [08:44<4:12:13,  3.43s/it]  3%|▎         | 138/4545 [08:48<4:23:14,  3.58s/it]  3%|▎         | 139/4545 [08:52<4:28:16,  3.65s/it]  3%|▎         | 140/4545 [08:56<4:33:59,  3.73s/it]                                                    {'loss': 0.7062, 'grad_norm': 162.95562744140625, 'learning_rate': 9.180977542932628e-09, 'rewards/chosen': -0.0002731323183979839, 'rewards/rejected': 0.0007644653087481856, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': -0.0010467529064044356, 'logps/chosen': -325.6499938964844, 'logps/rejected': -180.875, 'logits/chosen': -6.428124904632568, 'logits/rejected': -6.784375190734863, 'epoch': 0.09}
  3%|▎         | 140/4545 [08:56<4:33:59,  3.73s/it]  3%|▎         | 141/4545 [08:59<4:38:17,  3.79s/it]  3%|▎         | 142/4545 [09:04<4:43:57,  3.87s/it]  3%|▎         | 143/4545 [09:08<4:47:13,  3.91s/it]  3%|▎         | 144/4545 [09:11<4:46:46,  3.91s/it]  3%|▎         | 145/4545 [09:15<4:46:30,  3.91s/it]  3%|▎         | 146/4545 [09:19<4:36:59,  3.78s/it]  3%|▎         | 147/4545 [09:22<4:33:37,  3.73s/it]  3%|▎         | 148/4545 [09:26<4:37:07,  3.78s/it]  3%|▎         | 149/4545 [09:30<4:40:08,  3.82s/it]  3%|▎         | 150/4545 [09:33<4:22:40,  3.59s/it]                                                    {'loss': 0.6906, 'grad_norm': 19.162748336791992, 'learning_rate': 9.841479524438572e-09, 'rewards/chosen': 0.008884811773896217, 'rewards/rejected': 0.0037605285178869963, 'rewards/accuracies': 0.4312500059604645, 'rewards/margins': 0.0051177977584302425, 'logps/chosen': -283.29998779296875, 'logps/rejected': -116.92500305175781, 'logits/chosen': -6.353125095367432, 'logits/rejected': -6.690625190734863, 'epoch': 0.1}
  3%|▎         | 150/4545 [09:33<4:22:40,  3.59s/it]  3%|▎         | 151/4545 [09:36<4:11:59,  3.44s/it]  3%|▎         | 152/4545 [09:40<4:16:39,  3.51s/it]  3%|▎         | 153/4545 [09:44<4:27:54,  3.66s/it]  3%|▎         | 154/4545 [09:48<4:26:30,  3.64s/it]  3%|▎         | 155/4545 [09:52<4:31:33,  3.71s/it]  3%|▎         | 156/4545 [09:55<4:32:42,  3.73s/it]  3%|▎         | 157/4545 [09:59<4:33:37,  3.74s/it]  3%|▎         | 158/4545 [10:03<4:32:59,  3.73s/it]  3%|▎         | 159/4545 [10:07<4:41:09,  3.85s/it]  4%|▎         | 160/4545 [10:11<4:42:59,  3.87s/it]                                                    {'loss': 0.7073, 'grad_norm': 110.4932861328125, 'learning_rate': 1.0501981505944516e-08, 'rewards/chosen': 0.00180816650390625, 'rewards/rejected': 0.012747382745146751, 'rewards/accuracies': 0.46875, 'rewards/margins': -0.010911941528320312, 'logps/chosen': -295.5, 'logps/rejected': -159.6999969482422, 'logits/chosen': -6.199999809265137, 'logits/rejected': -6.618750095367432, 'epoch': 0.11}
  4%|▎         | 160/4545 [10:11<4:42:59,  3.87s/it]  4%|▎         | 161/4545 [10:15<4:48:42,  3.95s/it]  4%|▎         | 162/4545 [10:19<4:49:11,  3.96s/it]  4%|▎         | 163/4545 [10:23<4:52:57,  4.01s/it]  4%|▎         | 164/4545 [10:27<4:50:22,  3.98s/it]  4%|▎         | 165/4545 [10:30<4:38:40,  3.82s/it]  4%|▎         | 166/4545 [10:34<4:40:33,  3.84s/it]  4%|▎         | 167/4545 [10:38<4:42:06,  3.87s/it]  4%|▎         | 168/4545 [10:42<4:42:06,  3.87s/it]  4%|▎         | 169/4545 [10:46<4:42:20,  3.87s/it]  4%|▎         | 170/4545 [10:50<4:43:17,  3.89s/it]                                                    {'loss': 0.7118, 'grad_norm': 302.08673095703125, 'learning_rate': 1.1162483487450462e-08, 'rewards/chosen': -0.02035675011575222, 'rewards/rejected': -0.002499199006706476, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.01795654371380806, 'logps/chosen': -465.3500061035156, 'logps/rejected': -206.39999389648438, 'logits/chosen': -6.056250095367432, 'logits/rejected': -6.709374904632568, 'epoch': 0.11}
  4%|▎         | 170/4545 [10:50<4:43:17,  3.89s/it]  4%|▍         | 171/4545 [10:53<4:24:10,  3.62s/it]  4%|▍         | 172/4545 [10:57<4:34:59,  3.77s/it]  4%|▍         | 173/4545 [11:01<4:38:23,  3.82s/it]  4%|▍         | 174/4545 [11:05<4:43:30,  3.89s/it]  4%|▍         | 175/4545 [11:08<4:29:55,  3.71s/it]  4%|▍         | 176/4545 [11:12<4:34:02,  3.76s/it]  4%|▍         | 177/4545 [11:15<4:13:30,  3.48s/it]  4%|▍         | 178/4545 [11:19<4:23:00,  3.61s/it]  4%|▍         | 179/4545 [11:22<4:12:20,  3.47s/it]  4%|▍         | 180/4545 [11:26<4:22:20,  3.61s/it]                                                    {'loss': 0.6966, 'grad_norm': 24.29160499572754, 'learning_rate': 1.1822985468956406e-08, 'rewards/chosen': -0.0032775879371911287, 'rewards/rejected': 0.0023321150802075863, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.0056213377974927425, 'logps/chosen': -284.54998779296875, 'logps/rejected': -182.1750030517578, 'logits/chosen': -6.340624809265137, 'logits/rejected': -6.590624809265137, 'epoch': 0.12}
  4%|▍         | 180/4545 [11:26<4:22:20,  3.61s/it]  4%|▍         | 181/4545 [11:30<4:28:40,  3.69s/it]  4%|▍         | 182/4545 [11:33<4:19:08,  3.56s/it]  4%|▍         | 183/4545 [11:37<4:23:48,  3.63s/it]  4%|▍         | 184/4545 [11:41<4:30:04,  3.72s/it]  4%|▍         | 185/4545 [11:45<4:34:08,  3.77s/it]  4%|▍         | 186/4545 [11:48<4:30:07,  3.72s/it]  4%|▍         | 187/4545 [11:52<4:34:02,  3.77s/it]  4%|▍         | 188/4545 [11:55<4:19:57,  3.58s/it]  4%|▍         | 189/4545 [11:59<4:10:14,  3.45s/it]  4%|▍         | 190/4545 [12:02<4:04:45,  3.37s/it]                                                    {'loss': 0.6963, 'grad_norm': 24.82550811767578, 'learning_rate': 1.248348745046235e-08, 'rewards/chosen': -0.0037857056595385075, 'rewards/rejected': -0.0017333984142169356, 'rewards/accuracies': 0.4124999940395355, 'rewards/margins': -0.0020591735374182463, 'logps/chosen': -302.5, 'logps/rejected': -155.9499969482422, 'logits/chosen': -6.306250095367432, 'logits/rejected': -6.731249809265137, 'epoch': 0.13}
  4%|▍         | 190/4545 [12:02<4:04:45,  3.37s/it]  4%|▍         | 191/4545 [12:06<4:19:08,  3.57s/it]  4%|▍         | 192/4545 [12:09<4:20:29,  3.59s/it]  4%|▍         | 193/4545 [12:12<4:03:25,  3.36s/it]  4%|▍         | 194/4545 [12:15<3:51:11,  3.19s/it]  4%|▍         | 195/4545 [12:19<4:06:38,  3.40s/it]  4%|▍         | 196/4545 [12:23<4:15:35,  3.53s/it]  4%|▍         | 197/4545 [12:27<4:33:04,  3.77s/it]  4%|▍         | 198/4545 [12:31<4:35:58,  3.81s/it]  4%|▍         | 199/4545 [12:35<4:36:46,  3.82s/it]  4%|▍         | 200/4545 [12:39<4:38:25,  3.84s/it]                                                    {'loss': 0.7267, 'grad_norm': 243.686767578125, 'learning_rate': 1.3143989431968294e-08, 'rewards/chosen': -0.018795395269989967, 'rewards/rejected': 0.02236022986471653, 'rewards/accuracies': 0.46875, 'rewards/margins': -0.04116363450884819, 'logps/chosen': -356.7749938964844, 'logps/rejected': -241.27499389648438, 'logits/chosen': -6.181250095367432, 'logits/rejected': -6.599999904632568, 'epoch': 0.13}
  4%|▍         | 200/4545 [12:39<4:38:25,  3.84s/it]  4%|▍         | 201/4545 [12:43<4:40:24,  3.87s/it]  4%|▍         | 202/4545 [12:47<4:39:27,  3.86s/it]  4%|▍         | 203/4545 [12:50<4:37:28,  3.83s/it]  4%|▍         | 204/4545 [12:54<4:45:22,  3.94s/it]  5%|▍         | 205/4545 [12:58<4:42:34,  3.91s/it]  5%|▍         | 206/4545 [13:02<4:42:19,  3.90s/it]  5%|▍         | 207/4545 [13:06<4:42:45,  3.91s/it]  5%|▍         | 208/4545 [13:10<4:33:13,  3.78s/it]  5%|▍         | 209/4545 [13:14<4:40:14,  3.88s/it]  5%|▍         | 210/4545 [13:18<4:46:33,  3.97s/it]                                                    {'loss': 0.6942, 'grad_norm': 67.41912841796875, 'learning_rate': 1.380449141347424e-08, 'rewards/chosen': -0.013858413323760033, 'rewards/rejected': -0.024239350110292435, 'rewards/accuracies': 0.3687500059604645, 'rewards/margins': 0.01036987267434597, 'logps/chosen': -296.3999938964844, 'logps/rejected': -195.14999389648438, 'logits/chosen': -6.259375095367432, 'logits/rejected': -6.543749809265137, 'epoch': 0.14}
  5%|▍         | 210/4545 [13:18<4:46:33,  3.97s/it]  5%|▍         | 211/4545 [13:22<4:47:09,  3.98s/it]  5%|▍         | 212/4545 [13:26<4:48:52,  4.00s/it]  5%|▍         | 213/4545 [13:30<4:46:37,  3.97s/it]  5%|▍         | 214/4545 [13:34<4:44:16,  3.94s/it]  5%|▍         | 215/4545 [13:37<4:40:42,  3.89s/it]  5%|▍         | 216/4545 [13:41<4:41:19,  3.90s/it]  5%|▍         | 217/4545 [13:45<4:42:23,  3.91s/it]  5%|▍         | 218/4545 [13:49<4:42:08,  3.91s/it]  5%|▍         | 219/4545 [13:53<4:27:39,  3.71s/it]  5%|▍         | 220/4545 [13:57<4:35:41,  3.82s/it]                                                    {'loss': 0.7012, 'grad_norm': 24.821199417114258, 'learning_rate': 1.4464993394980185e-08, 'rewards/chosen': -0.0073791504837572575, 'rewards/rejected': 0.0060745240189135075, 'rewards/accuracies': 0.36250001192092896, 'rewards/margins': -0.013448715209960938, 'logps/chosen': -326.75, 'logps/rejected': -182.35000610351562, 'logits/chosen': -6.262499809265137, 'logits/rejected': -6.59375, 'epoch': 0.15}
  5%|▍         | 220/4545 [13:57<4:35:41,  3.82s/it]  5%|▍         | 221/4545 [14:00<4:29:08,  3.73s/it]  5%|▍         | 222/4545 [14:04<4:38:34,  3.87s/it]  5%|▍         | 223/4545 [14:08<4:39:18,  3.88s/it]  5%|▍         | 224/4545 [14:12<4:39:49,  3.89s/it]  5%|▍         | 225/4545 [14:16<4:46:09,  3.97s/it]  5%|▍         | 226/4545 [14:19<4:15:18,  3.55s/it]  5%|▍         | 227/4545 [14:23<4:24:48,  3.68s/it]  5%|▌         | 228/4545 [14:26<4:23:14,  3.66s/it]  5%|▌         | 229/4545 [14:30<4:13:40,  3.53s/it]  5%|▌         | 230/4545 [14:34<4:24:48,  3.68s/it]                                                    {'loss': 0.6875, 'grad_norm': 319.0409240722656, 'learning_rate': 1.5125495376486128e-08, 'rewards/chosen': 0.026547813788056374, 'rewards/rejected': -0.010517883114516735, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.03700561448931694, 'logps/chosen': -488.1499938964844, 'logps/rejected': -244.3000030517578, 'logits/chosen': -6.046875, 'logits/rejected': -6.3125, 'epoch': 0.15}
  5%|▌         | 230/4545 [14:34<4:24:48,  3.68s/it]  5%|▌         | 231/4545 [14:38<4:35:44,  3.84s/it]  5%|▌         | 232/4545 [14:42<4:41:47,  3.92s/it]  5%|▌         | 233/4545 [14:46<4:35:01,  3.83s/it]  5%|▌         | 234/4545 [14:50<4:38:05,  3.87s/it]  5%|▌         | 235/4545 [14:54<4:42:22,  3.93s/it]  5%|▌         | 236/4545 [14:57<4:33:13,  3.80s/it]  5%|▌         | 237/4545 [15:01<4:35:35,  3.84s/it]  5%|▌         | 238/4545 [15:03<4:01:06,  3.36s/it]  5%|▌         | 239/4545 [15:07<4:16:06,  3.57s/it]  5%|▌         | 240/4545 [15:11<4:23:17,  3.67s/it]                                                    {'loss': 0.6856, 'grad_norm': 161.91371154785156, 'learning_rate': 1.5785997357992072e-08, 'rewards/chosen': 0.0075775147415697575, 'rewards/rejected': -0.01075592078268528, 'rewards/accuracies': 0.4375, 'rewards/margins': 0.01831512525677681, 'logps/chosen': -298.3500061035156, 'logps/rejected': -137.35000610351562, 'logits/chosen': -6.287499904632568, 'logits/rejected': -6.587500095367432, 'epoch': 0.16}
  5%|▌         | 240/4545 [15:11<4:23:17,  3.67s/it]  5%|▌         | 241/4545 [15:14<4:13:13,  3.53s/it]  5%|▌         | 242/4545 [15:19<4:27:06,  3.72s/it]  5%|▌         | 243/4545 [15:22<4:14:00,  3.54s/it]  5%|▌         | 244/4545 [15:26<4:21:42,  3.65s/it]  5%|▌         | 245/4545 [15:30<4:27:41,  3.74s/it]  5%|▌         | 246/4545 [15:34<4:30:46,  3.78s/it]  5%|▌         | 247/4545 [15:37<4:34:04,  3.83s/it]  5%|▌         | 248/4545 [15:41<4:35:46,  3.85s/it]  5%|▌         | 249/4545 [15:45<4:37:22,  3.87s/it]  6%|▌         | 250/4545 [15:50<4:45:00,  3.98s/it]                                                    {'loss': 0.702, 'grad_norm': 33.74398422241211, 'learning_rate': 1.644649933949802e-08, 'rewards/chosen': 0.04744758456945419, 'rewards/rejected': 0.0077072144486010075, 'rewards/accuracies': 0.4937500059604645, 'rewards/margins': 0.03980712965130806, 'logps/chosen': -395.95001220703125, 'logps/rejected': -172.6750030517578, 'logits/chosen': -6.125, 'logits/rejected': -6.331250190734863, 'epoch': 0.17}
  6%|▌         | 250/4545 [15:50<4:45:00,  3.98s/it]  6%|▌         | 251/4545 [15:53<4:42:10,  3.94s/it]  6%|▌         | 252/4545 [15:57<4:41:11,  3.93s/it]  6%|▌         | 253/4545 [16:00<4:26:07,  3.72s/it]  6%|▌         | 254/4545 [16:04<4:29:51,  3.77s/it]  6%|▌         | 255/4545 [16:08<4:30:27,  3.78s/it]  6%|▌         | 256/4545 [16:12<4:38:59,  3.90s/it]  6%|▌         | 257/4545 [16:16<4:42:43,  3.96s/it]  6%|▌         | 258/4545 [16:20<4:32:58,  3.82s/it]  6%|▌         | 259/4545 [16:22<3:56:23,  3.31s/it]  6%|▌         | 260/4545 [16:26<4:13:08,  3.54s/it]                                                    {'loss': 0.6926, 'grad_norm': 344.8601379394531, 'learning_rate': 1.710700132100396e-08, 'rewards/chosen': 0.011756325140595436, 'rewards/rejected': 0.00880355853587389, 'rewards/accuracies': 0.40625, 'rewards/margins': 0.0029701231978833675, 'logps/chosen': -212.0, 'logps/rejected': -105.0999984741211, 'logits/chosen': -6.465624809265137, 'logits/rejected': -6.746874809265137, 'epoch': 0.17}
  6%|▌         | 260/4545 [16:26<4:13:08,  3.54s/it]  6%|▌         | 261/4545 [16:30<4:17:56,  3.61s/it]  6%|▌         | 262/4545 [16:34<4:24:22,  3.70s/it]  6%|▌         | 263/4545 [16:38<4:32:46,  3.82s/it]  6%|▌         | 264/4545 [16:41<4:22:39,  3.68s/it]  6%|▌         | 265/4545 [16:45<4:27:33,  3.75s/it]  6%|▌         | 266/4545 [16:49<4:30:56,  3.80s/it]  6%|▌         | 267/4545 [16:53<4:33:21,  3.83s/it]  6%|▌         | 268/4545 [16:56<4:20:56,  3.66s/it]  6%|▌         | 269/4545 [17:00<4:26:20,  3.74s/it]  6%|▌         | 270/4545 [17:04<4:29:47,  3.79s/it]                                                    {'loss': 0.6892, 'grad_norm': 185.8139190673828, 'learning_rate': 1.7767503302509907e-08, 'rewards/chosen': 0.013461303897202015, 'rewards/rejected': -0.02066192589700222, 'rewards/accuracies': 0.375, 'rewards/margins': 0.03416137769818306, 'logps/chosen': -463.8999938964844, 'logps/rejected': -260.625, 'logits/chosen': -6.199999809265137, 'logits/rejected': -6.384375095367432, 'epoch': 0.18}
  6%|▌         | 270/4545 [17:04<4:29:47,  3.79s/it]  6%|▌         | 271/4545 [17:08<4:32:21,  3.82s/it]  6%|▌         | 272/4545 [17:12<4:29:35,  3.79s/it]  6%|▌         | 273/4545 [17:16<4:33:45,  3.84s/it]  6%|▌         | 274/4545 [17:20<4:36:39,  3.89s/it]  6%|▌         | 275/4545 [17:23<4:18:43,  3.64s/it]  6%|▌         | 276/4545 [17:27<4:31:18,  3.81s/it]  6%|▌         | 277/4545 [17:31<4:33:16,  3.84s/it]  6%|▌         | 278/4545 [17:35<4:33:45,  3.85s/it]  6%|▌         | 279/4545 [17:38<4:25:08,  3.73s/it]  6%|▌         | 280/4545 [17:42<4:28:45,  3.78s/it]                                                    {'loss': 0.6808, 'grad_norm': 29.339622497558594, 'learning_rate': 1.842800528401585e-08, 'rewards/chosen': 0.06014537811279297, 'rewards/rejected': 0.02113647386431694, 'rewards/accuracies': 0.48124998807907104, 'rewards/margins': 0.03892211988568306, 'logps/chosen': -391.6499938964844, 'logps/rejected': -171.375, 'logits/chosen': -6.34375, 'logits/rejected': -6.65625, 'epoch': 0.18}
  6%|▌         | 280/4545 [17:42<4:28:45,  3.78s/it]  6%|▌         | 281/4545 [17:46<4:34:47,  3.87s/it]  6%|▌         | 282/4545 [17:49<4:14:36,  3.58s/it]  6%|▌         | 283/4545 [17:52<4:06:53,  3.48s/it]  6%|▌         | 284/4545 [17:56<4:16:27,  3.61s/it]  6%|▋         | 285/4545 [18:00<4:23:23,  3.71s/it]  6%|▋         | 286/4545 [18:03<4:08:58,  3.51s/it]  6%|▋         | 287/4545 [18:06<3:53:38,  3.29s/it]  6%|▋         | 288/4545 [18:10<4:03:51,  3.44s/it]  6%|▋         | 289/4545 [18:14<4:14:19,  3.59s/it]  6%|▋         | 290/4545 [18:18<4:21:24,  3.69s/it]                                                    {'loss': 0.6718, 'grad_norm': 241.7385711669922, 'learning_rate': 1.9088507265521795e-08, 'rewards/chosen': 0.06207466125488281, 'rewards/rejected': -0.02172393724322319, 'rewards/accuracies': 0.5687500238418579, 'rewards/margins': 0.08368682861328125, 'logps/chosen': -378.79998779296875, 'logps/rejected': -227.8000030517578, 'logits/chosen': -6.103125095367432, 'logits/rejected': -6.53125, 'epoch': 0.19}
  6%|▋         | 290/4545 [18:18<4:21:24,  3.69s/it]  6%|▋         | 291/4545 [18:21<4:16:48,  3.62s/it]  6%|▋         | 292/4545 [18:25<4:24:15,  3.73s/it]  6%|▋         | 293/4545 [18:29<4:31:13,  3.83s/it]  6%|▋         | 294/4545 [18:33<4:32:44,  3.85s/it]  6%|▋         | 295/4545 [18:37<4:25:44,  3.75s/it]  7%|▋         | 296/4545 [18:40<4:28:56,  3.80s/it]  7%|▋         | 297/4545 [18:44<4:31:11,  3.83s/it]  7%|▋         | 298/4545 [18:47<4:07:57,  3.50s/it]  7%|▋         | 299/4545 [18:51<4:23:31,  3.72s/it]  7%|▋         | 300/4545 [18:55<4:15:29,  3.61s/it]                                                    {'loss': 0.7092, 'grad_norm': 27.823305130004883, 'learning_rate': 1.974900924702774e-08, 'rewards/chosen': 0.02206573449075222, 'rewards/rejected': 0.02611389197409153, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.0040222168900072575, 'logps/chosen': -284.04998779296875, 'logps/rejected': -149.14999389648438, 'logits/chosen': -6.237500190734863, 'logits/rejected': -6.5, 'epoch': 0.2}
  7%|▋         | 300/4545 [18:55<4:15:29,  3.61s/it]  7%|▋         | 301/4545 [18:58<4:08:19,  3.51s/it]  7%|▋         | 302/4545 [19:02<4:21:03,  3.69s/it]  7%|▋         | 303/4545 [19:05<4:01:55,  3.42s/it]  7%|▋         | 304/4545 [19:09<4:08:03,  3.51s/it]  7%|▋         | 305/4545 [19:13<4:18:17,  3.65s/it]  7%|▋         | 306/4545 [19:17<4:23:39,  3.73s/it]  7%|▋         | 307/4545 [19:20<4:27:14,  3.78s/it]  7%|▋         | 308/4545 [19:24<4:29:46,  3.82s/it]  7%|▋         | 309/4545 [19:28<4:32:52,  3.87s/it]  7%|▋         | 310/4545 [19:32<4:34:51,  3.89s/it]                                                    {'loss': 0.6652, 'grad_norm': 40.827362060546875, 'learning_rate': 2.0409511228533686e-08, 'rewards/chosen': 0.16269072890281677, 'rewards/rejected': -0.012028503231704235, 'rewards/accuracies': 0.48750001192092896, 'rewards/margins': 0.17463378608226776, 'logps/chosen': -482.0, 'logps/rejected': -264.0249938964844, 'logits/chosen': -6.096875190734863, 'logits/rejected': -6.21875, 'epoch': 0.2}
  7%|▋         | 310/4545 [19:32<4:34:51,  3.89s/it]  7%|▋         | 311/4545 [19:36<4:35:20,  3.90s/it]  7%|▋         | 312/4545 [19:39<4:18:13,  3.66s/it]  7%|▋         | 313/4545 [19:43<4:23:55,  3.74s/it]  7%|▋         | 314/4545 [19:47<4:27:51,  3.80s/it]  7%|▋         | 315/4545 [19:51<4:30:40,  3.84s/it]  7%|▋         | 316/4545 [19:55<4:29:04,  3.82s/it]  7%|▋         | 317/4545 [19:57<4:04:14,  3.47s/it]  7%|▋         | 318/4545 [20:01<4:13:22,  3.60s/it]  7%|▋         | 319/4545 [20:05<4:20:42,  3.70s/it]  7%|▋         | 320/4545 [20:09<4:27:33,  3.80s/it]                                                    {'loss': 0.6896, 'grad_norm': 33.26336669921875, 'learning_rate': 2.107001321003963e-08, 'rewards/chosen': 0.02940063551068306, 'rewards/rejected': 0.0069519043900072575, 'rewards/accuracies': 0.512499988079071, 'rewards/margins': 0.02239837683737278, 'logps/chosen': -290.6499938964844, 'logps/rejected': -168.8249969482422, 'logits/chosen': -6.356249809265137, 'logits/rejected': -6.712500095367432, 'epoch': 0.21}
  7%|▋         | 320/4545 [20:09<4:27:33,  3.80s/it]  7%|▋         | 321/4545 [20:13<4:16:09,  3.64s/it]  7%|▋         | 322/4545 [20:17<4:23:59,  3.75s/it]  7%|▋         | 323/4545 [20:21<4:33:40,  3.89s/it]  7%|▋         | 324/4545 [20:24<4:26:35,  3.79s/it]  7%|▋         | 325/4545 [20:28<4:23:20,  3.74s/it]  7%|▋         | 326/4545 [20:32<4:27:10,  3.80s/it]  7%|▋         | 327/4545 [20:36<4:32:12,  3.87s/it]  7%|▋         | 328/4545 [20:40<4:32:50,  3.88s/it]  7%|▋         | 329/4545 [20:44<4:34:44,  3.91s/it]  7%|▋         | 330/4545 [20:48<4:32:14,  3.88s/it]                                                    {'loss': 0.721, 'grad_norm': 29.05752944946289, 'learning_rate': 2.1730515191545574e-08, 'rewards/chosen': -0.0038467408157885075, 'rewards/rejected': 0.01952514611184597, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.02337036095559597, 'logps/chosen': -227.4499969482422, 'logps/rejected': -147.25, 'logits/chosen': -6.396874904632568, 'logits/rejected': -6.415625095367432, 'epoch': 0.22}
  7%|▋         | 330/4545 [20:48<4:32:14,  3.88s/it]  7%|▋         | 331/4545 [20:51<4:18:14,  3.68s/it]  7%|▋         | 332/4545 [20:55<4:25:46,  3.79s/it]  7%|▋         | 333/4545 [20:58<4:19:17,  3.69s/it]  7%|▋         | 334/4545 [21:03<4:27:46,  3.82s/it]  7%|▋         | 335/4545 [21:06<4:17:56,  3.68s/it]  7%|▋         | 336/4545 [21:09<4:08:11,  3.54s/it]  7%|▋         | 337/4545 [21:13<4:19:27,  3.70s/it]  7%|▋         | 338/4545 [21:16<4:07:04,  3.52s/it]  7%|▋         | 339/4545 [21:20<4:15:11,  3.64s/it]  7%|▋         | 340/4545 [21:24<4:20:00,  3.71s/it]                                                    {'loss': 0.7072, 'grad_norm': 34.874088287353516, 'learning_rate': 2.239101717305152e-08, 'rewards/chosen': 0.017552757635712624, 'rewards/rejected': 0.020722199231386185, 'rewards/accuracies': 0.4375, 'rewards/margins': -0.003238677978515625, 'logps/chosen': -178.85000610351562, 'logps/rejected': -114.125, 'logits/chosen': -6.456250190734863, 'logits/rejected': -6.796875, 'epoch': 0.22}
  7%|▋         | 340/4545 [21:24<4:20:00,  3.71s/it]  8%|▊         | 341/4545 [21:28<4:24:15,  3.77s/it]  8%|▊         | 342/4545 [21:32<4:27:27,  3.82s/it]  8%|▊         | 343/4545 [21:36<4:30:50,  3.87s/it]  8%|▊         | 344/4545 [21:39<4:25:06,  3.79s/it]  8%|▊         | 345/4545 [21:42<4:05:53,  3.51s/it]  8%|▊         | 346/4545 [21:46<4:15:33,  3.65s/it]  8%|▊         | 347/4545 [21:51<4:26:45,  3.81s/it]  8%|▊         | 348/4545 [21:55<4:34:38,  3.93s/it]  8%|▊         | 349/4545 [21:59<4:34:58,  3.93s/it]  8%|▊         | 350/4545 [22:03<4:34:27,  3.93s/it]                                                    {'loss': 0.6748, 'grad_norm': 18.533594131469727, 'learning_rate': 2.3051519154557462e-08, 'rewards/chosen': 0.10074462741613388, 'rewards/rejected': 0.001972198486328125, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.09866943210363388, 'logps/chosen': -399.8999938964844, 'logps/rejected': -194.8000030517578, 'logits/chosen': -6.125, 'logits/rejected': -6.290625095367432, 'epoch': 0.23}
  8%|▊         | 350/4545 [22:03<4:34:27,  3.93s/it]  8%|▊         | 351/4545 [22:06<4:34:05,  3.92s/it]  8%|▊         | 352/4545 [22:09<4:07:25,  3.54s/it]  8%|▊         | 353/4545 [22:13<4:14:59,  3.65s/it]  8%|▊         | 354/4545 [22:17<4:20:33,  3.73s/it]  8%|▊         | 355/4545 [22:21<4:25:14,  3.80s/it]  8%|▊         | 356/4545 [22:25<4:30:55,  3.88s/it]  8%|▊         | 357/4545 [22:28<4:21:37,  3.75s/it]  8%|▊         | 358/4545 [22:31<3:54:24,  3.36s/it]  8%|▊         | 359/4545 [22:35<4:07:31,  3.55s/it]  8%|▊         | 360/4545 [22:39<4:15:00,  3.66s/it]                                                    {'loss': 0.6921, 'grad_norm': 70.03267669677734, 'learning_rate': 2.3712021136063406e-08, 'rewards/chosen': 0.08700847625732422, 'rewards/rejected': 0.017303466796875, 'rewards/accuracies': 0.39375001192092896, 'rewards/margins': 0.06988372653722763, 'logps/chosen': -330.8999938964844, 'logps/rejected': -172.39999389648438, 'logits/chosen': -6.278124809265137, 'logits/rejected': -6.546875, 'epoch': 0.24}
  8%|▊         | 360/4545 [22:39<4:15:00,  3.66s/it]  8%|▊         | 361/4545 [22:42<4:06:02,  3.53s/it]  8%|▊         | 362/4545 [22:46<4:14:00,  3.64s/it]  8%|▊         | 363/4545 [22:50<4:19:21,  3.72s/it]  8%|▊         | 364/4545 [22:53<4:07:03,  3.55s/it]  8%|▊         | 365/4545 [22:57<4:14:38,  3.66s/it]  8%|▊         | 366/4545 [23:01<4:20:02,  3.73s/it]  8%|▊         | 367/4545 [23:05<4:27:16,  3.84s/it]  8%|▊         | 368/4545 [23:09<4:28:30,  3.86s/it]  8%|▊         | 369/4545 [23:13<4:29:34,  3.87s/it]  8%|▊         | 370/4545 [23:17<4:30:21,  3.89s/it]                                                    {'loss': 0.6689, 'grad_norm': 33.76472473144531, 'learning_rate': 2.437252311756935e-08, 'rewards/chosen': 0.15381470322608948, 'rewards/rejected': 0.02413635328412056, 'rewards/accuracies': 0.4312500059604645, 'rewards/margins': 0.12965241074562073, 'logps/chosen': -492.29998779296875, 'logps/rejected': -244.0, 'logits/chosen': -6.199999809265137, 'logits/rejected': -6.556250095367432, 'epoch': 0.24}
  8%|▊         | 370/4545 [23:17<4:30:21,  3.89s/it]  8%|▊         | 371/4545 [23:20<4:16:48,  3.69s/it]  8%|▊         | 372/4545 [23:24<4:28:03,  3.85s/it]  8%|▊         | 373/4545 [23:28<4:29:08,  3.87s/it]  8%|▊         | 374/4545 [23:32<4:24:33,  3.81s/it]  8%|▊         | 375/4545 [23:34<4:01:50,  3.48s/it]  8%|▊         | 376/4545 [23:38<4:13:26,  3.65s/it]  8%|▊         | 377/4545 [23:42<4:18:50,  3.73s/it]  8%|▊         | 378/4545 [23:46<4:19:47,  3.74s/it]  8%|▊         | 379/4545 [23:47<3:31:11,  3.04s/it]  8%|▊         | 380/4545 [23:51<3:43:43,  3.22s/it]                                                    {'loss': 0.7018, 'grad_norm': 16.87987518310547, 'learning_rate': 2.5033025099075294e-08, 'rewards/chosen': 0.03737487643957138, 'rewards/rejected': 0.02674102783203125, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 0.0106353759765625, 'logps/chosen': -209.6999969482422, 'logps/rejected': -136.47500610351562, 'logits/chosen': -6.375, 'logits/rejected': -6.615624904632568, 'epoch': 0.25}
  8%|▊         | 380/4545 [23:51<3:43:43,  3.22s/it]  8%|▊         | 381/4545 [23:54<3:38:31,  3.15s/it]  8%|▊         | 382/4545 [23:58<3:53:38,  3.37s/it]  8%|▊         | 383/4545 [24:02<4:04:35,  3.53s/it]  8%|▊         | 384/4545 [24:06<4:12:49,  3.65s/it]  8%|▊         | 385/4545 [24:10<4:15:38,  3.69s/it]  8%|▊         | 386/4545 [24:14<4:23:02,  3.79s/it]  9%|▊         | 387/4545 [24:18<4:30:17,  3.90s/it]  9%|▊         | 388/4545 [24:22<4:30:35,  3.91s/it]  9%|▊         | 389/4545 [24:26<4:30:20,  3.90s/it]  9%|▊         | 390/4545 [24:29<4:30:15,  3.90s/it]                                                    {'loss': 0.6678, 'grad_norm': 240.96755981445312, 'learning_rate': 2.569352708058124e-08, 'rewards/chosen': 0.11011047661304474, 'rewards/rejected': 0.02388153038918972, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.08618469536304474, 'logps/chosen': -376.95001220703125, 'logps/rejected': -191.5, 'logits/chosen': -6.243750095367432, 'logits/rejected': -6.571875095367432, 'epoch': 0.26}
  9%|▊         | 390/4545 [24:29<4:30:15,  3.90s/it]  9%|▊         | 391/4545 [24:34<4:32:45,  3.94s/it]  9%|▊         | 392/4545 [24:38<4:37:54,  4.02s/it]  9%|▊         | 393/4545 [24:42<4:34:58,  3.97s/it]  9%|▊         | 394/4545 [24:45<4:29:00,  3.89s/it]  9%|▊         | 395/4545 [24:49<4:22:28,  3.79s/it]  9%|▊         | 396/4545 [24:53<4:25:31,  3.84s/it]  9%|▊         | 397/4545 [24:57<4:28:17,  3.88s/it]  9%|▉         | 398/4545 [25:01<4:25:27,  3.84s/it]  9%|▉         | 399/4545 [25:04<4:27:04,  3.87s/it]  9%|▉         | 400/4545 [25:08<4:28:36,  3.89s/it]                                                    {'loss': 0.6704, 'grad_norm': 78.07148742675781, 'learning_rate': 2.6354029062087186e-08, 'rewards/chosen': 0.140350341796875, 'rewards/rejected': 0.0157928466796875, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.12468872219324112, 'logps/chosen': -302.70001220703125, 'logps/rejected': -166.22500610351562, 'logits/chosen': -6.315625190734863, 'logits/rejected': -6.715624809265137, 'epoch': 0.26}
  9%|▉         | 400/4545 [25:08<4:28:36,  3.89s/it]  9%|▉         | 401/4545 [25:11<4:11:24,  3.64s/it]  9%|▉         | 402/4545 [25:16<4:22:49,  3.81s/it]  9%|▉         | 403/4545 [25:20<4:25:25,  3.84s/it]  9%|▉         | 404/4545 [25:24<4:30:02,  3.91s/it]  9%|▉         | 405/4545 [25:26<4:00:14,  3.48s/it]  9%|▉         | 406/4545 [25:29<3:47:44,  3.30s/it]  9%|▉         | 407/4545 [25:32<3:37:03,  3.15s/it]  9%|▉         | 408/4545 [25:36<3:57:15,  3.44s/it]  9%|▉         | 409/4545 [25:39<3:58:07,  3.45s/it]  9%|▉         | 410/4545 [25:43<4:01:38,  3.51s/it]                                                    {'loss': 0.6925, 'grad_norm': 21.649822235107422, 'learning_rate': 2.701453104359313e-08, 'rewards/chosen': 0.04417724534869194, 'rewards/rejected': 0.011851501651108265, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.03227653354406357, 'logps/chosen': -200.10000610351562, 'logps/rejected': -128.47500610351562, 'logits/chosen': -6.303124904632568, 'logits/rejected': -6.596875190734863, 'epoch': 0.27}
  9%|▉         | 410/4545 [25:43<4:01:38,  3.51s/it]  9%|▉         | 411/4545 [25:47<4:10:30,  3.64s/it]  9%|▉         | 412/4545 [25:51<4:16:02,  3.72s/it]  9%|▉         | 413/4545 [25:54<4:08:32,  3.61s/it]  9%|▉         | 414/4545 [25:58<4:18:30,  3.75s/it]  9%|▉         | 415/4545 [26:01<3:57:10,  3.45s/it]  9%|▉         | 416/4545 [26:04<3:44:53,  3.27s/it]  9%|▉         | 417/4545 [26:08<3:58:05,  3.46s/it]  9%|▉         | 418/4545 [26:11<3:46:37,  3.29s/it]  9%|▉         | 419/4545 [26:15<3:59:04,  3.48s/it]  9%|▉         | 420/4545 [26:18<3:53:55,  3.40s/it]                                                    {'loss': 0.6813, 'grad_norm': 79.90399932861328, 'learning_rate': 2.7675033025099077e-08, 'rewards/chosen': 0.061133574694395065, 'rewards/rejected': 0.005841446109116077, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 0.05521087720990181, 'logps/chosen': -270.0, 'logps/rejected': -144.4250030517578, 'logits/chosen': -6.243750095367432, 'logits/rejected': -6.571875095367432, 'epoch': 0.28}
  9%|▉         | 420/4545 [26:18<3:53:55,  3.40s/it]  9%|▉         | 421/4545 [26:22<4:04:49,  3.56s/it]  9%|▉         | 422/4545 [26:26<4:12:25,  3.67s/it]  9%|▉         | 423/4545 [26:29<4:03:15,  3.54s/it]  9%|▉         | 424/4545 [26:33<4:04:37,  3.56s/it]  9%|▉         | 425/4545 [26:36<4:08:32,  3.62s/it]  9%|▉         | 426/4545 [26:40<4:14:03,  3.70s/it]  9%|▉         | 427/4545 [26:44<4:19:51,  3.79s/it]  9%|▉         | 428/4545 [26:46<3:43:28,  3.26s/it]  9%|▉         | 429/4545 [26:50<3:45:49,  3.29s/it]  9%|▉         | 430/4545 [26:54<4:01:10,  3.52s/it]                                                    {'loss': 0.6773, 'grad_norm': 26.337060928344727, 'learning_rate': 2.8335535006605014e-08, 'rewards/chosen': 0.0877532958984375, 'rewards/rejected': 0.0203399658203125, 'rewards/accuracies': 0.518750011920929, 'rewards/margins': 0.06743278354406357, 'logps/chosen': -283.70001220703125, 'logps/rejected': -120.42500305175781, 'logits/chosen': -6.143750190734863, 'logits/rejected': -6.521874904632568, 'epoch': 0.28}
  9%|▉         | 430/4545 [26:54<4:01:10,  3.52s/it]  9%|▉         | 431/4545 [26:58<4:13:58,  3.70s/it] 10%|▉         | 432/4545 [27:02<4:18:01,  3.76s/it] 10%|▉         | 433/4545 [27:06<4:24:01,  3.85s/it] 10%|▉         | 434/4545 [27:10<4:32:33,  3.98s/it] 10%|▉         | 435/4545 [27:13<4:10:44,  3.66s/it] 10%|▉         | 436/4545 [27:17<4:16:39,  3.75s/it] 10%|▉         | 437/4545 [27:21<4:25:37,  3.88s/it] 10%|▉         | 438/4545 [27:24<4:09:58,  3.65s/it] 10%|▉         | 439/4545 [27:27<3:55:59,  3.45s/it] 10%|▉         | 440/4545 [27:31<4:05:53,  3.59s/it]                                                    {'loss': 0.686, 'grad_norm': 61.163719177246094, 'learning_rate': 2.8996036988110962e-08, 'rewards/chosen': 0.06738433986902237, 'rewards/rejected': 0.03709258884191513, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': 0.03032531775534153, 'logps/chosen': -214.27499389648438, 'logps/rejected': -163.89999389648438, 'logits/chosen': -6.290625095367432, 'logits/rejected': -6.506249904632568, 'epoch': 0.29}
 10%|▉         | 440/4545 [27:31<4:05:53,  3.59s/it] 10%|▉         | 441/4545 [27:35<4:12:26,  3.69s/it] 10%|▉         | 442/4545 [27:38<4:05:05,  3.58s/it] 10%|▉         | 443/4545 [27:42<4:14:52,  3.73s/it] 10%|▉         | 444/4545 [27:46<4:19:14,  3.79s/it] 10%|▉         | 445/4545 [27:49<3:56:28,  3.46s/it] 10%|▉         | 446/4545 [27:53<4:11:10,  3.68s/it] 10%|▉         | 447/4545 [27:56<3:47:09,  3.33s/it] 10%|▉         | 448/4545 [28:00<3:59:02,  3.50s/it] 10%|▉         | 449/4545 [28:04<4:08:11,  3.64s/it] 10%|▉         | 450/4545 [28:07<4:14:04,  3.72s/it]                                                    {'loss': 0.6622, 'grad_norm': 55.574195861816406, 'learning_rate': 2.9656538969616906e-08, 'rewards/chosen': 0.16068725287914276, 'rewards/rejected': 0.0049652098678052425, 'rewards/accuracies': 0.4937500059604645, 'rewards/margins': 0.15559081733226776, 'logps/chosen': -362.54998779296875, 'logps/rejected': -181.3249969482422, 'logits/chosen': -6.203125, 'logits/rejected': -6.528124809265137, 'epoch': 0.3}
 10%|▉         | 450/4545 [28:08<4:14:04,  3.72s/it] 10%|▉         | 451/4545 [28:11<4:18:00,  3.78s/it] 10%|▉         | 452/4545 [28:15<4:20:17,  3.82s/it] 10%|▉         | 453/4545 [28:19<4:24:13,  3.87s/it] 10%|▉         | 454/4545 [28:23<4:24:40,  3.88s/it] 10%|█         | 455/4545 [28:27<4:25:24,  3.89s/it] 10%|█         | 456/4545 [28:31<4:19:39,  3.81s/it] 10%|█         | 457/4545 [28:35<4:22:12,  3.85s/it] 10%|█         | 458/4545 [28:39<4:23:19,  3.87s/it] 10%|█         | 459/4545 [28:43<4:24:24,  3.88s/it] 10%|█         | 460/4545 [28:46<4:19:05,  3.81s/it]                                                    {'loss': 0.6569, 'grad_norm': 30.593894958496094, 'learning_rate': 3.031704095112285e-08, 'rewards/chosen': 0.24798163771629333, 'rewards/rejected': 0.02615966834127903, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.22142943739891052, 'logps/chosen': -539.2000122070312, 'logps/rejected': -280.3999938964844, 'logits/chosen': -6.074999809265137, 'logits/rejected': -6.337500095367432, 'epoch': 0.3}
 10%|█         | 460/4545 [28:46<4:19:05,  3.81s/it] 10%|█         | 461/4545 [28:50<4:20:26,  3.83s/it] 10%|█         | 462/4545 [28:54<4:28:14,  3.94s/it] 10%|█         | 463/4545 [28:58<4:28:07,  3.94s/it] 10%|█         | 464/4545 [29:01<4:13:02,  3.72s/it] 10%|█         | 465/4545 [29:05<4:16:54,  3.78s/it] 10%|█         | 466/4545 [29:08<4:02:47,  3.57s/it] 10%|█         | 467/4545 [29:12<4:08:57,  3.66s/it] 10%|█         | 468/4545 [29:16<4:13:56,  3.74s/it] 10%|█         | 469/4545 [29:20<4:16:28,  3.78s/it] 10%|█         | 470/4545 [29:23<3:52:41,  3.43s/it]                                                    {'loss': 0.6659, 'grad_norm': 22.552799224853516, 'learning_rate': 3.09775429326288e-08, 'rewards/chosen': 0.12572021782398224, 'rewards/rejected': -0.000759124755859375, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.12666015326976776, 'logps/chosen': -207.8000030517578, 'logps/rejected': -100.125, 'logits/chosen': -6.287499904632568, 'logits/rejected': -6.371874809265137, 'epoch': 0.31}
 10%|█         | 470/4545 [29:23<3:52:41,  3.43s/it] 10%|█         | 471/4545 [29:27<4:02:30,  3.57s/it] 10%|█         | 472/4545 [29:31<4:15:49,  3.77s/it] 10%|█         | 473/4545 [29:35<4:20:58,  3.85s/it] 10%|█         | 474/4545 [29:39<4:20:42,  3.84s/it] 10%|█         | 475/4545 [29:43<4:21:29,  3.85s/it] 10%|█         | 476/4545 [29:47<4:25:40,  3.92s/it] 10%|█         | 477/4545 [29:51<4:25:37,  3.92s/it] 11%|█         | 478/4545 [29:54<4:19:29,  3.83s/it] 11%|█         | 479/4545 [29:57<4:07:34,  3.65s/it] 11%|█         | 480/4545 [30:01<4:13:19,  3.74s/it]                                                    {'loss': 0.6678, 'grad_norm': 31.752613067626953, 'learning_rate': 3.163804491413474e-08, 'rewards/chosen': 0.13045501708984375, 'rewards/rejected': -0.01506805419921875, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 0.14549560844898224, 'logps/chosen': -273.75, 'logps/rejected': -161.75, 'logits/chosen': -6.243750095367432, 'logits/rejected': -6.574999809265137, 'epoch': 0.32}
 11%|█         | 480/4545 [30:01<4:13:19,  3.74s/it] 11%|█         | 481/4545 [30:05<4:19:00,  3.82s/it] 11%|█         | 482/4545 [30:09<4:21:00,  3.85s/it] 11%|█         | 483/4545 [30:13<4:19:29,  3.83s/it] 11%|█         | 484/4545 [30:17<4:23:05,  3.89s/it] 11%|█         | 485/4545 [30:21<4:26:20,  3.94s/it] 11%|█         | 486/4545 [30:25<4:20:21,  3.85s/it] 11%|█         | 487/4545 [30:27<3:52:30,  3.44s/it] 11%|█         | 488/4545 [30:31<4:05:02,  3.62s/it] 11%|█         | 489/4545 [30:35<4:11:10,  3.72s/it] 11%|█         | 490/4545 [30:39<4:16:05,  3.79s/it]                                                    {'loss': 0.6723, 'grad_norm': 29.5855712890625, 'learning_rate': 3.2298546895640685e-08, 'rewards/chosen': 0.149383544921875, 'rewards/rejected': 0.02113952673971653, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 0.1284637451171875, 'logps/chosen': -260.6000061035156, 'logps/rejected': -112.4749984741211, 'logits/chosen': -6.337500095367432, 'logits/rejected': -6.550000190734863, 'epoch': 0.32}
 11%|█         | 490/4545 [30:39<4:16:05,  3.79s/it] 11%|█         | 491/4545 [30:42<3:49:58,  3.40s/it] 11%|█         | 492/4545 [30:46<4:02:47,  3.59s/it] 11%|█         | 493/4545 [30:50<4:12:20,  3.74s/it] 11%|█         | 494/4545 [30:54<4:19:32,  3.84s/it] 11%|█         | 495/4545 [30:58<4:17:39,  3.82s/it] 11%|█         | 496/4545 [31:01<4:10:53,  3.72s/it] 11%|█         | 497/4545 [31:05<4:12:15,  3.74s/it] 11%|█         | 498/4545 [31:09<4:15:30,  3.79s/it] 11%|█         | 499/4545 [31:13<4:18:08,  3.83s/it] 11%|█         | 500/4545 [31:17<4:22:02,  3.89s/it]                                                    {'loss': 0.6678, 'grad_norm': 28.157325744628906, 'learning_rate': 3.295904887714663e-08, 'rewards/chosen': 0.13282470405101776, 'rewards/rejected': 0.010967254638671875, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.12164306640625, 'logps/chosen': -231.0500030517578, 'logps/rejected': -104.32499694824219, 'logits/chosen': -6.331250190734863, 'logits/rejected': -6.715624809265137, 'epoch': 0.33}
 11%|█         | 500/4545 [31:17<4:22:02,  3.89s/it] 11%|█         | 501/4545 [31:20<4:15:41,  3.79s/it] 11%|█         | 502/4545 [31:24<4:17:57,  3.83s/it] 11%|█         | 503/4545 [31:28<4:09:59,  3.71s/it] 11%|█         | 504/4545 [31:32<4:14:17,  3.78s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.65s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                    
                                               [A{'eval_loss': 0.6520597338676453, 'eval_runtime': 80.3716, 'eval_samples_per_second': 11.857, 'eval_steps_per_second': 0.747, 'eval_rewards/chosen': 0.24605636298656464, 'eval_rewards/rejected': 0.0499393455684185, 'eval_rewards/accuracies': 0.6032407283782959, 'eval_rewards/margins': 0.19609908759593964, 'eval_logps/chosen': -375.3833312988281, 'eval_logps/rejected': -151.60833740234375, 'eval_logits/chosen': -6.026562690734863, 'eval_logits/rejected': -6.949479103088379, 'epoch': 0.33}
 11%|█         | 504/4545 [32:52<4:14:17,  3.78s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 11%|█         | 505/4545 [33:07<35:03:16, 31.24s/it] 11%|█         | 506/4545 [33:10<25:33:34, 22.78s/it] 11%|█         | 507/4545 [33:14<19:11:55, 17.12s/it] 11%|█         | 508/4545 [33:18<14:45:00, 13.15s/it] 11%|█         | 509/4545 [33:21<11:24:26, 10.18s/it] 11%|█         | 510/4545 [33:25<9:18:18,  8.30s/it]                                                     {'loss': 0.6606, 'grad_norm': 45.17263412475586, 'learning_rate': 3.361955085865257e-08, 'rewards/chosen': 0.262359619140625, 'rewards/rejected': 0.10401306301355362, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.15845946967601776, 'logps/chosen': -388.0249938964844, 'logps/rejected': -219.4499969482422, 'logits/chosen': -6.153124809265137, 'logits/rejected': -6.653124809265137, 'epoch': 0.34}
 11%|█         | 510/4545 [33:25<9:18:18,  8.30s/it] 11%|█         | 511/4545 [33:29<7:55:53,  7.08s/it] 11%|█▏        | 512/4545 [33:33<6:48:54,  6.08s/it] 11%|█▏        | 513/4545 [33:37<6:04:40,  5.43s/it] 11%|█▏        | 514/4545 [33:41<5:34:18,  4.98s/it] 11%|█▏        | 515/4545 [33:44<4:56:39,  4.42s/it] 11%|█▏        | 516/4545 [33:48<4:44:26,  4.24s/it] 11%|█▏        | 517/4545 [33:51<4:20:51,  3.89s/it] 11%|█▏        | 518/4545 [33:54<4:12:45,  3.77s/it] 11%|█▏        | 519/4545 [33:58<4:16:06,  3.82s/it] 11%|█▏        | 520/4545 [34:02<4:19:04,  3.86s/it]                                                    {'loss': 0.6584, 'grad_norm': 25.887561798095703, 'learning_rate': 3.428005284015852e-08, 'rewards/chosen': 0.19382019340991974, 'rewards/rejected': 0.03377532958984375, 'rewards/accuracies': 0.5874999761581421, 'rewards/margins': 0.16002655029296875, 'logps/chosen': -297.25, 'logps/rejected': -134.97500610351562, 'logits/chosen': -6.300000190734863, 'logits/rejected': -6.584374904632568, 'epoch': 0.34}
 11%|█▏        | 520/4545 [34:02<4:19:04,  3.86s/it] 11%|█▏        | 521/4545 [34:06<4:22:05,  3.91s/it] 11%|█▏        | 522/4545 [34:10<4:28:56,  4.01s/it] 12%|█▏        | 523/4545 [34:14<4:26:40,  3.98s/it] 12%|█▏        | 524/4545 [34:18<4:25:21,  3.96s/it] 12%|█▏        | 525/4545 [34:22<4:20:02,  3.88s/it] 12%|█▏        | 526/4545 [34:26<4:23:43,  3.94s/it] 12%|█▏        | 527/4545 [34:30<4:23:38,  3.94s/it] 12%|█▏        | 528/4545 [34:34<4:27:32,  4.00s/it] 12%|█▏        | 529/4545 [34:38<4:17:43,  3.85s/it] 12%|█▏        | 530/4545 [34:42<4:24:19,  3.95s/it]                                                    {'loss': 0.6669, 'grad_norm': 39.304901123046875, 'learning_rate': 3.494055482166446e-08, 'rewards/chosen': 0.13686522841453552, 'rewards/rejected': 0.0303497314453125, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.10638809204101562, 'logps/chosen': -263.45001220703125, 'logps/rejected': -128.58749389648438, 'logits/chosen': -6.293749809265137, 'logits/rejected': -6.721875190734863, 'epoch': 0.35}
 12%|█▏        | 530/4545 [34:42<4:24:19,  3.95s/it] 12%|█▏        | 531/4545 [34:46<4:24:20,  3.95s/it] 12%|█▏        | 532/4545 [34:50<4:23:21,  3.94s/it] 12%|█▏        | 533/4545 [34:53<4:06:51,  3.69s/it] 12%|█▏        | 534/4545 [34:57<4:16:43,  3.84s/it] 12%|█▏        | 535/4545 [35:01<4:18:02,  3.86s/it] 12%|█▏        | 536/4545 [35:05<4:18:56,  3.88s/it] 12%|█▏        | 537/4545 [35:08<3:58:28,  3.57s/it] 12%|█▏        | 538/4545 [35:11<4:00:02,  3.59s/it] 12%|█▏        | 539/4545 [35:15<4:06:38,  3.69s/it] 12%|█▏        | 540/4545 [35:19<4:10:05,  3.75s/it]                                                    {'loss': 0.6714, 'grad_norm': 20.710498809814453, 'learning_rate': 3.560105680317041e-08, 'rewards/chosen': 0.16619262099266052, 'rewards/rejected': 0.05684814602136612, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.10936279594898224, 'logps/chosen': -223.39999389648438, 'logps/rejected': -141.64999389648438, 'logits/chosen': -6.371874809265137, 'logits/rejected': -6.53125, 'epoch': 0.36}
 12%|█▏        | 540/4545 [35:19<4:10:05,  3.75s/it] 12%|█▏        | 541/4545 [35:23<4:13:25,  3.80s/it] 12%|█▏        | 542/4545 [35:27<4:15:10,  3.82s/it] 12%|█▏        | 543/4545 [35:31<4:12:25,  3.78s/it] 12%|█▏        | 544/4545 [35:34<4:15:03,  3.82s/it] 12%|█▏        | 545/4545 [35:39<4:23:36,  3.95s/it] 12%|█▏        | 546/4545 [35:43<4:22:53,  3.94s/it] 12%|█▏        | 547/4545 [35:47<4:22:54,  3.95s/it] 12%|█▏        | 548/4545 [35:50<4:14:13,  3.82s/it] 12%|█▏        | 549/4545 [35:54<4:08:27,  3.73s/it] 12%|█▏        | 550/4545 [35:58<4:12:26,  3.79s/it]                                                    {'loss': 0.6504, 'grad_norm': 28.8421630859375, 'learning_rate': 3.6261558784676356e-08, 'rewards/chosen': 0.2640136778354645, 'rewards/rejected': 0.01874389685690403, 'rewards/accuracies': 0.637499988079071, 'rewards/margins': 0.24537353217601776, 'logps/chosen': -334.3500061035156, 'logps/rejected': -184.75, 'logits/chosen': -6.159375190734863, 'logits/rejected': -6.53125, 'epoch': 0.36}
 12%|█▏        | 550/4545 [35:58<4:12:26,  3.79s/it] 12%|█▏        | 551/4545 [36:01<4:14:20,  3.82s/it] 12%|█▏        | 552/4545 [36:05<4:16:15,  3.85s/it] 12%|█▏        | 553/4545 [36:09<4:17:58,  3.88s/it] 12%|█▏        | 554/4545 [36:13<4:07:47,  3.73s/it] 12%|█▏        | 555/4545 [36:17<4:11:42,  3.79s/it] 12%|█▏        | 556/4545 [36:21<4:14:44,  3.83s/it] 12%|█▏        | 557/4545 [36:23<3:48:54,  3.44s/it] 12%|█▏        | 558/4545 [36:27<4:01:36,  3.64s/it] 12%|█▏        | 559/4545 [36:30<3:50:19,  3.47s/it] 12%|█▏        | 560/4545 [36:34<3:58:37,  3.59s/it]                                                    {'loss': 0.6584, 'grad_norm': 37.962730407714844, 'learning_rate': 3.692206076618229e-08, 'rewards/chosen': 0.25441282987594604, 'rewards/rejected': 0.05922241136431694, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.19504699110984802, 'logps/chosen': -334.6499938964844, 'logps/rejected': -204.64999389648438, 'logits/chosen': -6.243750095367432, 'logits/rejected': -6.5625, 'epoch': 0.37}
 12%|█▏        | 560/4545 [36:34<3:58:37,  3.59s/it] 12%|█▏        | 561/4545 [36:38<4:03:02,  3.66s/it] 12%|█▏        | 562/4545 [36:42<4:07:46,  3.73s/it] 12%|█▏        | 563/4545 [36:45<3:53:33,  3.52s/it] 12%|█▏        | 564/4545 [36:48<3:50:42,  3.48s/it] 12%|█▏        | 565/4545 [36:52<4:00:40,  3.63s/it] 12%|█▏        | 566/4545 [36:56<4:06:21,  3.71s/it] 12%|█▏        | 567/4545 [37:00<4:07:25,  3.73s/it] 12%|█▏        | 568/4545 [37:04<4:11:05,  3.79s/it] 13%|█▎        | 569/4545 [37:08<4:10:19,  3.78s/it] 13%|█▎        | 570/4545 [37:12<4:18:01,  3.89s/it]                                                    {'loss': 0.6579, 'grad_norm': 23.909223556518555, 'learning_rate': 3.758256274768824e-08, 'rewards/chosen': 0.24577637016773224, 'rewards/rejected': 0.08491668850183487, 'rewards/accuracies': 0.612500011920929, 'rewards/margins': 0.16072387993335724, 'logps/chosen': -265.8500061035156, 'logps/rejected': -176.4499969482422, 'logits/chosen': -6.484375, 'logits/rejected': -6.71875, 'epoch': 0.38}
 13%|█▎        | 570/4545 [37:12<4:18:01,  3.89s/it] 13%|█▎        | 571/4545 [37:16<4:18:31,  3.90s/it] 13%|█▎        | 572/4545 [37:20<4:18:31,  3.90s/it] 13%|█▎        | 573/4545 [37:24<4:25:05,  4.00s/it] 13%|█▎        | 574/4545 [37:28<4:27:06,  4.04s/it] 13%|█▎        | 575/4545 [37:32<4:24:44,  4.00s/it] 13%|█▎        | 576/4545 [37:36<4:23:22,  3.98s/it] 13%|█▎        | 577/4545 [37:40<4:22:36,  3.97s/it] 13%|█▎        | 578/4545 [37:43<4:10:14,  3.78s/it] 13%|█▎        | 579/4545 [37:46<3:54:35,  3.55s/it] 13%|█▎        | 580/4545 [37:50<4:05:43,  3.72s/it]                                                    {'loss': 0.6483, 'grad_norm': 27.75834846496582, 'learning_rate': 3.824306472919419e-08, 'rewards/chosen': 0.2574829161167145, 'rewards/rejected': 0.06409911811351776, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.19321899116039276, 'logps/chosen': -310.1499938964844, 'logps/rejected': -181.4499969482422, 'logits/chosen': -6.315625190734863, 'logits/rejected': -6.659375190734863, 'epoch': 0.38}
 13%|█▎        | 580/4545 [37:50<4:05:43,  3.72s/it] 13%|█▎        | 581/4545 [37:53<3:54:20,  3.55s/it] 13%|█▎        | 582/4545 [37:57<4:01:21,  3.65s/it] 13%|█▎        | 583/4545 [38:00<3:46:18,  3.43s/it] 13%|█▎        | 584/4545 [38:04<3:56:24,  3.58s/it] 13%|█▎        | 585/4545 [38:07<3:51:18,  3.50s/it] 13%|█▎        | 586/4545 [38:12<4:03:17,  3.69s/it] 13%|█▎        | 587/4545 [38:16<4:13:05,  3.84s/it] 13%|█▎        | 588/4545 [38:20<4:14:54,  3.87s/it] 13%|█▎        | 589/4545 [38:22<3:53:17,  3.54s/it] 13%|█▎        | 590/4545 [38:26<3:54:03,  3.55s/it]                                                    {'loss': 0.6576, 'grad_norm': 23.12393569946289, 'learning_rate': 3.890356671070013e-08, 'rewards/chosen': 0.2854858338832855, 'rewards/rejected': 0.061771392822265625, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.22322997450828552, 'logps/chosen': -322.25, 'logps/rejected': -199.0500030517578, 'logits/chosen': -6.237500190734863, 'logits/rejected': -6.643750190734863, 'epoch': 0.39}
 13%|█▎        | 590/4545 [38:26<3:54:03,  3.55s/it] 13%|█▎        | 591/4545 [38:30<4:01:54,  3.67s/it] 13%|█▎        | 592/4545 [38:33<3:55:42,  3.58s/it] 13%|█▎        | 593/4545 [38:37<3:52:59,  3.54s/it] 13%|█▎        | 594/4545 [38:41<4:00:06,  3.65s/it] 13%|█▎        | 595/4545 [38:45<4:05:43,  3.73s/it] 13%|█▎        | 596/4545 [38:49<4:10:04,  3.80s/it] 13%|█▎        | 597/4545 [38:53<4:18:54,  3.93s/it] 13%|█▎        | 598/4545 [38:56<4:02:20,  3.68s/it] 13%|█▎        | 599/4545 [39:00<4:12:40,  3.84s/it] 13%|█▎        | 600/4545 [39:03<3:58:49,  3.63s/it]                                                    {'loss': 0.6487, 'grad_norm': 25.207242965698242, 'learning_rate': 3.9564068692206076e-08, 'rewards/chosen': 0.2923339903354645, 'rewards/rejected': 0.07907409965991974, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.21340331435203552, 'logps/chosen': -303.1499938964844, 'logps/rejected': -188.89999389648438, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.678124904632568, 'epoch': 0.4}
 13%|█▎        | 600/4545 [39:03<3:58:49,  3.63s/it] 13%|█▎        | 601/4545 [39:07<3:55:47,  3.59s/it] 13%|█▎        | 602/4545 [39:10<3:51:47,  3.53s/it] 13%|█▎        | 603/4545 [39:14<3:59:24,  3.64s/it] 13%|█▎        | 604/4545 [39:17<3:53:36,  3.56s/it] 13%|█▎        | 605/4545 [39:22<4:06:58,  3.76s/it] 13%|█▎        | 606/4545 [39:25<3:57:58,  3.62s/it] 13%|█▎        | 607/4545 [39:29<4:06:23,  3.75s/it] 13%|█▎        | 608/4545 [39:33<4:08:50,  3.79s/it] 13%|█▎        | 609/4545 [39:37<4:11:00,  3.83s/it] 13%|█▎        | 610/4545 [39:41<4:12:49,  3.86s/it]                                                    {'loss': 0.6418, 'grad_norm': 27.178592681884766, 'learning_rate': 4.022457067371202e-08, 'rewards/chosen': 0.45476073026657104, 'rewards/rejected': 0.06132812425494194, 'rewards/accuracies': 0.643750011920929, 'rewards/margins': 0.39337748289108276, 'logps/chosen': -379.45001220703125, 'logps/rejected': -186.27499389648438, 'logits/chosen': -6.087500095367432, 'logits/rejected': -6.481249809265137, 'epoch': 0.4}
 13%|█▎        | 610/4545 [39:41<4:12:49,  3.86s/it] 13%|█▎        | 611/4545 [39:45<4:18:12,  3.94s/it] 13%|█▎        | 612/4545 [39:48<3:57:13,  3.62s/it] 13%|█▎        | 613/4545 [39:52<4:02:52,  3.71s/it] 14%|█▎        | 614/4545 [39:56<4:10:34,  3.82s/it] 14%|█▎        | 615/4545 [39:59<3:50:57,  3.53s/it] 14%|█▎        | 616/4545 [40:02<3:50:40,  3.52s/it] 14%|█▎        | 617/4545 [40:06<3:56:57,  3.62s/it] 14%|█▎        | 618/4545 [40:09<3:44:01,  3.42s/it] 14%|█▎        | 619/4545 [40:13<3:54:22,  3.58s/it] 14%|█▎        | 620/4545 [40:15<3:35:35,  3.30s/it]                                                    {'loss': 0.6618, 'grad_norm': 32.31479263305664, 'learning_rate': 4.0885072655217964e-08, 'rewards/chosen': 0.2321624755859375, 'rewards/rejected': 0.006375121884047985, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.2256324738264084, 'logps/chosen': -224.5, 'logps/rejected': -114.69999694824219, 'logits/chosen': -6.471875190734863, 'logits/rejected': -6.553124904632568, 'epoch': 0.41}
 14%|█▎        | 620/4545 [40:15<3:35:35,  3.30s/it] 14%|█▎        | 621/4545 [40:19<3:47:44,  3.48s/it] 14%|█▎        | 622/4545 [40:23<3:56:13,  3.61s/it] 14%|█▎        | 623/4545 [40:27<3:56:41,  3.62s/it] 14%|█▎        | 624/4545 [40:31<4:04:06,  3.74s/it] 14%|█▍        | 625/4545 [40:35<4:07:28,  3.79s/it] 14%|█▍        | 626/4545 [40:39<4:09:57,  3.83s/it] 14%|█▍        | 627/4545 [40:42<4:02:34,  3.71s/it] 14%|█▍        | 628/4545 [40:46<4:04:39,  3.75s/it] 14%|█▍        | 629/4545 [40:50<4:07:21,  3.79s/it] 14%|█▍        | 630/4545 [40:54<4:10:07,  3.83s/it]                                                    {'loss': 0.6579, 'grad_norm': 26.723308563232422, 'learning_rate': 4.154557463672391e-08, 'rewards/chosen': 0.2707763612270355, 'rewards/rejected': 0.09716186672449112, 'rewards/accuracies': 0.6625000238418579, 'rewards/margins': 0.17313842475414276, 'logps/chosen': -281.6000061035156, 'logps/rejected': -151.27499389648438, 'logits/chosen': -6.181250095367432, 'logits/rejected': -6.565625190734863, 'epoch': 0.42}
 14%|█▍        | 630/4545 [40:54<4:10:07,  3.83s/it] 14%|█▍        | 631/4545 [40:58<4:17:21,  3.95s/it] 14%|█▍        | 632/4545 [41:02<4:16:36,  3.93s/it] 14%|█▍        | 633/4545 [41:06<4:11:49,  3.86s/it] 14%|█▍        | 634/4545 [41:10<4:17:57,  3.96s/it] 14%|█▍        | 635/4545 [41:14<4:21:14,  4.01s/it] 14%|█▍        | 636/4545 [41:18<4:22:28,  4.03s/it] 14%|█▍        | 637/4545 [41:22<4:24:10,  4.06s/it] 14%|█▍        | 638/4545 [41:26<4:21:29,  4.02s/it] 14%|█▍        | 639/4545 [41:30<4:14:38,  3.91s/it] 14%|█▍        | 640/4545 [41:33<4:09:51,  3.84s/it]                                                    {'loss': 0.6581, 'grad_norm': 26.143918991088867, 'learning_rate': 4.220607661822985e-08, 'rewards/chosen': 0.16156005859375, 'rewards/rejected': 0.03241424635052681, 'rewards/accuracies': 0.6937500238418579, 'rewards/margins': 0.12857666611671448, 'logps/chosen': -199.60000610351562, 'logps/rejected': -134.39999389648438, 'logits/chosen': -6.387499809265137, 'logits/rejected': -6.756249904632568, 'epoch': 0.42}
 14%|█▍        | 640/4545 [41:33<4:09:51,  3.84s/it] 14%|█▍        | 641/4545 [41:38<4:15:35,  3.93s/it] 14%|█▍        | 642/4545 [41:41<4:15:39,  3.93s/it] 14%|█▍        | 643/4545 [41:45<4:15:17,  3.93s/it] 14%|█▍        | 644/4545 [41:49<4:14:24,  3.91s/it] 14%|█▍        | 645/4545 [41:53<4:13:37,  3.90s/it] 14%|█▍        | 646/4545 [41:57<4:13:48,  3.91s/it] 14%|█▍        | 647/4545 [42:00<3:57:58,  3.66s/it] 14%|█▍        | 648/4545 [42:04<4:02:48,  3.74s/it] 14%|█▍        | 649/4545 [42:08<4:06:14,  3.79s/it] 14%|█▍        | 650/4545 [42:12<4:08:39,  3.83s/it]                                                    {'loss': 0.6221, 'grad_norm': 17.311809539794922, 'learning_rate': 4.2866578599735796e-08, 'rewards/chosen': 0.52978515625, 'rewards/rejected': 0.059661865234375, 'rewards/accuracies': 0.637499988079071, 'rewards/margins': 0.4697021543979645, 'logps/chosen': -437.1499938964844, 'logps/rejected': -230.125, 'logits/chosen': -6.121874809265137, 'logits/rejected': -6.490624904632568, 'epoch': 0.43}
 14%|█▍        | 650/4545 [42:12<4:08:39,  3.83s/it] 14%|█▍        | 651/4545 [42:16<4:10:11,  3.86s/it] 14%|█▍        | 652/4545 [42:19<4:06:20,  3.80s/it] 14%|█▍        | 653/4545 [42:23<4:08:32,  3.83s/it] 14%|█▍        | 654/4545 [42:27<4:10:01,  3.86s/it] 14%|█▍        | 655/4545 [42:31<4:01:23,  3.72s/it] 14%|█▍        | 656/4545 [42:34<4:00:09,  3.71s/it] 14%|█▍        | 657/4545 [42:39<4:09:59,  3.86s/it] 14%|█▍        | 658/4545 [42:41<3:44:32,  3.47s/it] 14%|█▍        | 659/4545 [42:45<3:53:03,  3.60s/it] 15%|█▍        | 660/4545 [42:49<4:01:56,  3.74s/it]                                                    {'loss': 0.6397, 'grad_norm': 20.85614013671875, 'learning_rate': 4.352708058124174e-08, 'rewards/chosen': 0.3758544921875, 'rewards/rejected': 0.03970642015337944, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.336221307516098, 'logps/chosen': -312.6499938964844, 'logps/rejected': -143.4250030517578, 'logits/chosen': -6.300000190734863, 'logits/rejected': -6.546875, 'epoch': 0.44}
 15%|█▍        | 660/4545 [42:49<4:01:56,  3.74s/it] 15%|█▍        | 661/4545 [42:53<4:08:35,  3.84s/it] 15%|█▍        | 662/4545 [42:57<4:15:14,  3.94s/it] 15%|█▍        | 663/4545 [43:01<4:09:15,  3.85s/it] 15%|█▍        | 664/4545 [43:05<4:01:45,  3.74s/it] 15%|█▍        | 665/4545 [43:08<3:56:14,  3.65s/it] 15%|█▍        | 666/4545 [43:12<4:00:32,  3.72s/it] 15%|█▍        | 667/4545 [43:16<4:04:11,  3.78s/it] 15%|█▍        | 668/4545 [43:19<3:58:27,  3.69s/it] 15%|█▍        | 669/4545 [43:23<4:04:52,  3.79s/it] 15%|█▍        | 670/4545 [43:27<4:09:17,  3.86s/it]                                                    {'loss': 0.6627, 'grad_norm': 24.18817138671875, 'learning_rate': 4.418758256274769e-08, 'rewards/chosen': 0.12109375, 'rewards/rejected': 0.02262573316693306, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.09861449897289276, 'logps/chosen': -150.10000610351562, 'logps/rejected': -94.875, 'logits/chosen': -6.471875190734863, 'logits/rejected': -6.650000095367432, 'epoch': 0.44}
 15%|█▍        | 670/4545 [43:27<4:09:17,  3.86s/it] 15%|█▍        | 671/4545 [43:31<4:10:18,  3.88s/it] 15%|█▍        | 672/4545 [43:35<4:14:45,  3.95s/it] 15%|█▍        | 673/4545 [43:39<4:03:21,  3.77s/it] 15%|█▍        | 674/4545 [43:43<4:06:24,  3.82s/it] 15%|█▍        | 675/4545 [43:46<4:06:42,  3.83s/it] 15%|█▍        | 676/4545 [43:50<4:07:36,  3.84s/it] 15%|█▍        | 677/4545 [43:53<3:42:05,  3.44s/it] 15%|█▍        | 678/4545 [43:57<3:51:28,  3.59s/it] 15%|█▍        | 679/4545 [44:01<4:00:59,  3.74s/it] 15%|█▍        | 680/4545 [44:05<4:04:07,  3.79s/it]                                                    {'loss': 0.6379, 'grad_norm': 21.6990966796875, 'learning_rate': 4.484808454425363e-08, 'rewards/chosen': 0.47480469942092896, 'rewards/rejected': 0.058013152331113815, 'rewards/accuracies': 0.668749988079071, 'rewards/margins': 0.41650390625, 'logps/chosen': -368.75, 'logps/rejected': -163.6999969482422, 'logits/chosen': -6.324999809265137, 'logits/rejected': -6.571875095367432, 'epoch': 0.45}
 15%|█▍        | 680/4545 [44:05<4:04:07,  3.79s/it] 15%|█▍        | 681/4545 [44:09<4:12:36,  3.92s/it] 15%|█▌        | 682/4545 [44:13<4:10:07,  3.88s/it] 15%|█▌        | 683/4545 [44:17<4:12:05,  3.92s/it] 15%|█▌        | 684/4545 [44:21<4:16:41,  3.99s/it] 15%|█▌        | 685/4545 [44:25<4:14:15,  3.95s/it] 15%|█▌        | 686/4545 [44:29<4:13:21,  3.94s/it] 15%|█▌        | 687/4545 [44:32<4:08:15,  3.86s/it] 15%|█▌        | 688/4545 [44:36<4:08:51,  3.87s/it] 15%|█▌        | 689/4545 [44:40<4:02:22,  3.77s/it] 15%|█▌        | 690/4545 [44:44<4:05:00,  3.81s/it]                                                    {'loss': 0.6398, 'grad_norm': 33.119476318359375, 'learning_rate': 4.550858652575957e-08, 'rewards/chosen': 0.4276367127895355, 'rewards/rejected': 0.09891357272863388, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.3292236328125, 'logps/chosen': -333.25, 'logps/rejected': -149.22500610351562, 'logits/chosen': -6.271874904632568, 'logits/rejected': -6.6875, 'epoch': 0.46}
 15%|█▌        | 690/4545 [44:44<4:05:00,  3.81s/it] 15%|█▌        | 691/4545 [44:48<4:10:41,  3.90s/it] 15%|█▌        | 692/4545 [44:50<3:43:30,  3.48s/it] 15%|█▌        | 693/4545 [44:54<3:54:50,  3.66s/it] 15%|█▌        | 694/4545 [44:58<3:48:58,  3.57s/it] 15%|█▌        | 695/4545 [45:02<4:01:12,  3.76s/it] 15%|█▌        | 696/4545 [45:06<4:03:58,  3.80s/it] 15%|█▌        | 697/4545 [45:10<4:00:37,  3.75s/it] 15%|█▌        | 698/4545 [45:13<4:03:50,  3.80s/it] 15%|█▌        | 699/4545 [45:17<4:05:55,  3.84s/it] 15%|█▌        | 700/4545 [45:21<4:05:46,  3.84s/it]                                                    {'loss': 0.6373, 'grad_norm': 21.620967864990234, 'learning_rate': 4.6169088507265516e-08, 'rewards/chosen': 0.32958984375, 'rewards/rejected': 0.0992431640625, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.23068848252296448, 'logps/chosen': -268.95001220703125, 'logps/rejected': -155.52499389648438, 'logits/chosen': -6.334374904632568, 'logits/rejected': -6.493750095367432, 'epoch': 0.46}
 15%|█▌        | 700/4545 [45:21<4:05:46,  3.84s/it] 15%|█▌        | 701/4545 [45:25<4:06:52,  3.85s/it] 15%|█▌        | 702/4545 [45:29<4:07:05,  3.86s/it] 15%|█▌        | 703/4545 [45:33<4:13:17,  3.96s/it] 15%|█▌        | 704/4545 [45:36<3:54:28,  3.66s/it] 16%|█▌        | 705/4545 [45:40<3:56:42,  3.70s/it] 16%|█▌        | 706/4545 [45:44<4:01:02,  3.77s/it] 16%|█▌        | 707/4545 [45:48<4:04:00,  3.81s/it] 16%|█▌        | 708/4545 [45:52<4:05:42,  3.84s/it] 16%|█▌        | 709/4545 [45:55<3:53:34,  3.65s/it] 16%|█▌        | 710/4545 [45:59<3:58:17,  3.73s/it]                                                    {'loss': 0.6373, 'grad_norm': 25.146209716796875, 'learning_rate': 4.6829590488771467e-08, 'rewards/chosen': 0.2998290956020355, 'rewards/rejected': 0.02394714392721653, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.2758773863315582, 'logps/chosen': -234.3000030517578, 'logps/rejected': -99.42500305175781, 'logits/chosen': -6.290625095367432, 'logits/rejected': -6.737500190734863, 'epoch': 0.47}
 16%|█▌        | 710/4545 [45:59<3:58:17,  3.73s/it] 16%|█▌        | 711/4545 [46:01<3:35:19,  3.37s/it] 16%|█▌        | 712/4545 [46:05<3:45:31,  3.53s/it] 16%|█▌        | 713/4545 [46:09<3:50:58,  3.62s/it] 16%|█▌        | 714/4545 [46:13<3:56:40,  3.71s/it] 16%|█▌        | 715/4545 [46:17<3:58:46,  3.74s/it] 16%|█▌        | 716/4545 [46:20<3:51:19,  3.62s/it] 16%|█▌        | 717/4545 [46:24<3:56:34,  3.71s/it] 16%|█▌        | 718/4545 [46:28<4:06:02,  3.86s/it] 16%|█▌        | 719/4545 [46:31<3:47:27,  3.57s/it] 16%|█▌        | 720/4545 [46:35<3:59:42,  3.76s/it]                                                    {'loss': 0.6394, 'grad_norm': 17.220338821411133, 'learning_rate': 4.749009247027741e-08, 'rewards/chosen': 0.3645996153354645, 'rewards/rejected': 0.0770263671875, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.2876396179199219, 'logps/chosen': -290.79998779296875, 'logps/rejected': -209.22500610351562, 'logits/chosen': -6.162499904632568, 'logits/rejected': -6.606249809265137, 'epoch': 0.48}
 16%|█▌        | 720/4545 [46:35<3:59:42,  3.76s/it] 16%|█▌        | 721/4545 [46:39<4:02:34,  3.81s/it] 16%|█▌        | 722/4545 [46:43<3:56:24,  3.71s/it] 16%|█▌        | 723/4545 [46:47<4:00:25,  3.77s/it] 16%|█▌        | 724/4545 [46:51<4:03:20,  3.82s/it] 16%|█▌        | 725/4545 [46:54<4:04:59,  3.85s/it] 16%|█▌        | 726/4545 [46:58<4:05:25,  3.86s/it] 16%|█▌        | 727/4545 [47:01<3:37:07,  3.41s/it] 16%|█▌        | 728/4545 [47:03<3:08:15,  2.96s/it] 16%|█▌        | 729/4545 [47:05<3:05:04,  2.91s/it] 16%|█▌        | 730/4545 [47:09<3:24:30,  3.22s/it]                                                    {'loss': 0.6455, 'grad_norm': 157.053466796875, 'learning_rate': 4.8150594451783355e-08, 'rewards/chosen': 0.4275878965854645, 'rewards/rejected': 0.08205413818359375, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.3454040586948395, 'logps/chosen': -301.8500061035156, 'logps/rejected': -147.39999389648438, 'logits/chosen': -6.334374904632568, 'logits/rejected': -6.449999809265137, 'epoch': 0.48}
 16%|█▌        | 730/4545 [47:09<3:24:30,  3.22s/it] 16%|█▌        | 731/4545 [47:12<3:11:34,  3.01s/it] 16%|█▌        | 732/4545 [47:16<3:29:11,  3.29s/it] 16%|█▌        | 733/4545 [47:20<3:43:44,  3.52s/it] 16%|█▌        | 734/4545 [47:24<3:51:34,  3.65s/it] 16%|█▌        | 735/4545 [47:28<4:02:45,  3.82s/it] 16%|█▌        | 736/4545 [47:32<4:05:46,  3.87s/it] 16%|█▌        | 737/4545 [47:36<4:06:23,  3.88s/it] 16%|█▌        | 738/4545 [47:40<4:10:37,  3.95s/it] 16%|█▋        | 739/4545 [47:43<3:57:07,  3.74s/it] 16%|█▋        | 740/4545 [47:48<4:06:37,  3.89s/it]                                                    {'loss': 0.6281, 'grad_norm': 21.82400894165039, 'learning_rate': 4.881109643328929e-08, 'rewards/chosen': 0.4742187559604645, 'rewards/rejected': 0.12239990383386612, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.35175782442092896, 'logps/chosen': -331.1499938964844, 'logps/rejected': -196.58749389648438, 'logits/chosen': -6.125, 'logits/rejected': -6.4375, 'epoch': 0.49}
 16%|█▋        | 740/4545 [47:48<4:06:37,  3.89s/it] 16%|█▋        | 741/4545 [47:51<4:07:04,  3.90s/it] 16%|█▋        | 742/4545 [47:55<3:56:44,  3.74s/it] 16%|█▋        | 743/4545 [47:58<3:52:33,  3.67s/it] 16%|█▋        | 744/4545 [48:02<3:56:05,  3.73s/it] 16%|█▋        | 745/4545 [48:06<3:50:36,  3.64s/it] 16%|█▋        | 746/4545 [48:10<4:01:07,  3.81s/it] 16%|█▋        | 747/4545 [48:14<4:03:02,  3.84s/it] 16%|█▋        | 748/4545 [48:17<3:50:13,  3.64s/it] 16%|█▋        | 749/4545 [48:21<3:57:01,  3.75s/it] 17%|█▋        | 750/4545 [48:25<4:00:29,  3.80s/it]                                                    {'loss': 0.643, 'grad_norm': 23.000072479248047, 'learning_rate': 4.947159841479524e-08, 'rewards/chosen': 0.2861328125, 'rewards/rejected': 0.01526489295065403, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.27058106660842896, 'logps/chosen': -213.89999389648438, 'logps/rejected': -109.17500305175781, 'logits/chosen': -6.359375, 'logits/rejected': -6.637499809265137, 'epoch': 0.5}
 17%|█▋        | 750/4545 [48:25<4:00:29,  3.80s/it] 17%|█▋        | 751/4545 [48:29<4:03:05,  3.84s/it] 17%|█▋        | 752/4545 [48:33<4:02:59,  3.84s/it] 17%|█▋        | 753/4545 [48:37<4:09:15,  3.94s/it] 17%|█▋        | 754/4545 [48:40<3:58:12,  3.77s/it] 17%|█▋        | 755/4545 [48:44<4:00:57,  3.81s/it] 17%|█▋        | 756/4545 [48:48<4:09:12,  3.95s/it] 17%|█▋        | 757/4545 [48:52<4:08:25,  3.94s/it] 17%|█▋        | 758/4545 [48:56<4:08:07,  3.93s/it] 17%|█▋        | 759/4545 [49:00<4:04:52,  3.88s/it] 17%|█▋        | 760/4545 [49:04<4:00:48,  3.82s/it]                                                    {'loss': 0.608, 'grad_norm': 40.9085578918457, 'learning_rate': 5.013210039630119e-08, 'rewards/chosen': 0.736132800579071, 'rewards/rejected': 0.14248046278953552, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 0.593334972858429, 'logps/chosen': -430.8500061035156, 'logps/rejected': -222.5, 'logits/chosen': -6.078125, 'logits/rejected': -6.599999904632568, 'epoch': 0.5}
 17%|█▋        | 760/4545 [49:04<4:00:48,  3.82s/it] 17%|█▋        | 761/4545 [49:08<4:04:35,  3.88s/it] 17%|█▋        | 762/4545 [49:12<4:05:28,  3.89s/it] 17%|█▋        | 763/4545 [49:15<3:53:32,  3.71s/it] 17%|█▋        | 764/4545 [49:19<3:55:02,  3.73s/it] 17%|█▋        | 765/4545 [49:21<3:37:00,  3.44s/it] 17%|█▋        | 766/4545 [49:25<3:46:13,  3.59s/it] 17%|█▋        | 767/4545 [49:29<3:52:08,  3.69s/it] 17%|█▋        | 768/4545 [49:33<4:00:16,  3.82s/it] 17%|█▋        | 769/4545 [49:36<3:46:41,  3.60s/it] 17%|█▋        | 770/4545 [49:40<3:36:46,  3.45s/it]                                                    {'loss': 0.6354, 'grad_norm': 20.611764907836914, 'learning_rate': 5.079260237780714e-08, 'rewards/chosen': 0.3785156309604645, 'rewards/rejected': 0.076446533203125, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.3015685975551605, 'logps/chosen': -247.6999969482422, 'logps/rejected': -151.52499389648438, 'logits/chosen': -6.409375190734863, 'logits/rejected': -6.618750095367432, 'epoch': 0.51}
 17%|█▋        | 770/4545 [49:40<3:36:46,  3.45s/it] 17%|█▋        | 771/4545 [49:42<3:17:44,  3.14s/it] 17%|█▋        | 772/4545 [49:46<3:40:38,  3.51s/it] 17%|█▋        | 773/4545 [49:49<3:19:42,  3.18s/it] 17%|█▋        | 774/4545 [49:52<3:28:07,  3.31s/it] 17%|█▋        | 775/4545 [49:57<3:48:26,  3.64s/it] 17%|█▋        | 776/4545 [50:01<3:53:26,  3.72s/it] 17%|█▋        | 777/4545 [50:04<3:45:14,  3.59s/it] 17%|█▋        | 778/4545 [50:07<3:43:53,  3.57s/it] 17%|█▋        | 779/4545 [50:12<3:56:20,  3.77s/it] 17%|█▋        | 780/4545 [50:16<3:59:16,  3.81s/it]                                                    {'loss': 0.6215, 'grad_norm': 19.90077018737793, 'learning_rate': 5.145310435931307e-08, 'rewards/chosen': 0.42656248807907104, 'rewards/rejected': 0.041484832763671875, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.3857665956020355, 'logps/chosen': -262.95001220703125, 'logps/rejected': -151.3249969482422, 'logits/chosen': -6.212500095367432, 'logits/rejected': -6.515625, 'epoch': 0.51}
 17%|█▋        | 780/4545 [50:16<3:59:16,  3.81s/it] 17%|█▋        | 781/4545 [50:18<3:41:08,  3.53s/it] 17%|█▋        | 782/4545 [50:23<3:51:20,  3.69s/it] 17%|█▋        | 783/4545 [50:27<4:01:20,  3.85s/it] 17%|█▋        | 784/4545 [50:30<3:54:21,  3.74s/it] 17%|█▋        | 785/4545 [50:34<3:57:28,  3.79s/it] 17%|█▋        | 786/4545 [50:38<3:59:06,  3.82s/it] 17%|█▋        | 787/4545 [50:42<4:01:12,  3.85s/it] 17%|█▋        | 788/4545 [50:46<4:02:19,  3.87s/it] 17%|█▋        | 789/4545 [50:49<3:50:13,  3.68s/it] 17%|█▋        | 790/4545 [50:52<3:27:30,  3.32s/it]                                                    {'loss': 0.6271, 'grad_norm': 22.431283950805664, 'learning_rate': 5.211360634081902e-08, 'rewards/chosen': 0.3838867247104645, 'rewards/rejected': 0.06352539360523224, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.3209594786167145, 'logps/chosen': -240.39999389648438, 'logps/rejected': -102.67500305175781, 'logits/chosen': -6.21875, 'logits/rejected': -6.731249809265137, 'epoch': 0.52}
 17%|█▋        | 790/4545 [50:52<3:27:30,  3.32s/it] 17%|█▋        | 791/4545 [50:55<3:23:28,  3.25s/it] 17%|█▋        | 792/4545 [50:59<3:41:14,  3.54s/it] 17%|█▋        | 793/4545 [51:03<3:52:27,  3.72s/it] 17%|█▋        | 794/4545 [51:07<4:01:55,  3.87s/it] 17%|█▋        | 795/4545 [51:11<4:06:25,  3.94s/it] 18%|█▊        | 796/4545 [51:15<4:04:42,  3.92s/it] 18%|█▊        | 797/4545 [51:19<4:04:26,  3.91s/it] 18%|█▊        | 798/4545 [51:23<4:04:39,  3.92s/it] 18%|█▊        | 799/4545 [51:27<4:03:26,  3.90s/it] 18%|█▊        | 800/4545 [51:31<4:03:24,  3.90s/it]                                                    {'loss': 0.6016, 'grad_norm': 17.782215118408203, 'learning_rate': 5.277410832232496e-08, 'rewards/chosen': 0.544384777545929, 'rewards/rejected': 0.04622192308306694, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.4985595643520355, 'logps/chosen': -317.1499938964844, 'logps/rejected': -148.625, 'logits/chosen': -6.265625, 'logits/rejected': -6.537499904632568, 'epoch': 0.53}
 18%|█▊        | 800/4545 [51:31<4:03:24,  3.90s/it] 18%|█▊        | 801/4545 [51:35<4:01:40,  3.87s/it] 18%|█▊        | 802/4545 [51:38<3:54:17,  3.76s/it] 18%|█▊        | 803/4545 [51:42<3:51:14,  3.71s/it] 18%|█▊        | 804/4545 [51:46<3:59:45,  3.85s/it] 18%|█▊        | 805/4545 [51:50<4:00:51,  3.86s/it] 18%|█▊        | 806/4545 [51:53<3:51:57,  3.72s/it] 18%|█▊        | 807/4545 [51:57<3:55:56,  3.79s/it] 18%|█▊        | 808/4545 [52:01<3:58:36,  3.83s/it] 18%|█▊        | 809/4545 [52:04<3:50:07,  3.70s/it] 18%|█▊        | 810/4545 [52:08<3:53:47,  3.76s/it]                                                    {'loss': 0.659, 'grad_norm': 17.093191146850586, 'learning_rate': 5.3434610303830907e-08, 'rewards/chosen': 0.3388671875, 'rewards/rejected': 0.14777526259422302, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.19144591689109802, 'logps/chosen': -224.75, 'logps/rejected': -151.8249969482422, 'logits/chosen': -6.259375095367432, 'logits/rejected': -6.371874809265137, 'epoch': 0.53}
 18%|█▊        | 810/4545 [52:08<3:53:47,  3.76s/it] 18%|█▊        | 811/4545 [52:12<3:56:56,  3.81s/it] 18%|█▊        | 812/4545 [52:16<3:59:10,  3.84s/it] 18%|█▊        | 813/4545 [52:20<4:00:21,  3.86s/it] 18%|█▊        | 814/4545 [52:23<3:51:02,  3.72s/it] 18%|█▊        | 815/4545 [52:27<3:54:56,  3.78s/it] 18%|█▊        | 816/4545 [52:31<3:57:29,  3.82s/it] 18%|█▊        | 817/4545 [52:34<3:30:50,  3.39s/it] 18%|█▊        | 818/4545 [52:38<3:40:44,  3.55s/it] 18%|█▊        | 819/4545 [52:42<3:51:17,  3.72s/it] 18%|█▊        | 820/4545 [52:46<3:54:46,  3.78s/it]                                                    {'loss': 0.6044, 'grad_norm': 24.526657104492188, 'learning_rate': 5.409511228533685e-08, 'rewards/chosen': 0.7679687738418579, 'rewards/rejected': 0.10976715385913849, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.657910168170929, 'logps/chosen': -416.6499938964844, 'logps/rejected': -196.9250030517578, 'logits/chosen': -5.990624904632568, 'logits/rejected': -6.434374809265137, 'epoch': 0.54}
 18%|█▊        | 820/4545 [52:46<3:54:46,  3.78s/it] 18%|█▊        | 821/4545 [52:50<4:02:26,  3.91s/it] 18%|█▊        | 822/4545 [52:54<4:06:07,  3.97s/it] 18%|█▊        | 823/4545 [52:58<4:08:05,  4.00s/it] 18%|█▊        | 824/4545 [53:01<3:51:26,  3.73s/it] 18%|█▊        | 825/4545 [53:05<3:54:35,  3.78s/it] 18%|█▊        | 826/4545 [53:08<3:42:49,  3.59s/it] 18%|█▊        | 827/4545 [53:12<3:51:58,  3.74s/it] 18%|█▊        | 828/4545 [53:16<3:55:10,  3.80s/it] 18%|█▊        | 829/4545 [53:20<4:03:20,  3.93s/it] 18%|█▊        | 830/4545 [53:24<3:54:03,  3.78s/it]                                                    {'loss': 0.6085, 'grad_norm': 16.50101661682129, 'learning_rate': 5.4755614266842795e-08, 'rewards/chosen': 0.4833007752895355, 'rewards/rejected': 0.06342773139476776, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.41972655057907104, 'logps/chosen': -303.3500061035156, 'logps/rejected': -159.0749969482422, 'logits/chosen': -6.165625095367432, 'logits/rejected': -6.587500095367432, 'epoch': 0.55}
 18%|█▊        | 830/4545 [53:24<3:54:03,  3.78s/it] 18%|█▊        | 831/4545 [53:28<4:00:08,  3.88s/it] 18%|█▊        | 832/4545 [53:31<3:52:12,  3.75s/it] 18%|█▊        | 833/4545 [53:35<3:55:29,  3.81s/it] 18%|█▊        | 834/4545 [53:40<4:02:09,  3.92s/it] 18%|█▊        | 835/4545 [53:43<3:57:06,  3.83s/it] 18%|█▊        | 836/4545 [53:46<3:32:00,  3.43s/it] 18%|█▊        | 837/4545 [53:49<3:26:53,  3.35s/it] 18%|█▊        | 838/4545 [53:53<3:37:19,  3.52s/it] 18%|█▊        | 839/4545 [53:56<3:31:16,  3.42s/it] 18%|█▊        | 840/4545 [53:59<3:33:03,  3.45s/it]                                                    {'loss': 0.6374, 'grad_norm': 22.46329116821289, 'learning_rate': 5.5416116248348745e-08, 'rewards/chosen': 0.47504884004592896, 'rewards/rejected': 0.07407226413488388, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.399993896484375, 'logps/chosen': -255.5, 'logps/rejected': -135.47500610351562, 'logits/chosen': -6.271874904632568, 'logits/rejected': -6.550000190734863, 'epoch': 0.55}
 18%|█▊        | 840/4545 [54:00<3:33:03,  3.45s/it] 19%|█▊        | 841/4545 [54:03<3:41:42,  3.59s/it] 19%|█▊        | 842/4545 [54:05<3:13:01,  3.13s/it] 19%|█▊        | 843/4545 [54:09<3:28:30,  3.38s/it] 19%|█▊        | 844/4545 [54:13<3:28:57,  3.39s/it] 19%|█▊        | 845/4545 [54:17<3:38:26,  3.54s/it] 19%|█▊        | 846/4545 [54:21<3:47:41,  3.69s/it] 19%|█▊        | 847/4545 [54:24<3:39:37,  3.56s/it] 19%|█▊        | 848/4545 [54:28<3:49:42,  3.73s/it] 19%|█▊        | 849/4545 [54:32<3:55:47,  3.83s/it] 19%|█▊        | 850/4545 [54:36<3:50:15,  3.74s/it]                                                    {'loss': 0.6273, 'grad_norm': 28.422874450683594, 'learning_rate': 5.607661822985469e-08, 'rewards/chosen': 0.4422851502895355, 'rewards/rejected': 0.10578612983226776, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.3357910215854645, 'logps/chosen': -253.6750030517578, 'logps/rejected': -133.9250030517578, 'logits/chosen': -6.296875, 'logits/rejected': -6.403124809265137, 'epoch': 0.56}
 19%|█▊        | 850/4545 [54:36<3:50:15,  3.74s/it] 19%|█▊        | 851/4545 [54:39<3:43:04,  3.62s/it] 19%|█▊        | 852/4545 [54:43<3:48:03,  3.71s/it] 19%|█▉        | 853/4545 [54:47<3:44:58,  3.66s/it] 19%|█▉        | 854/4545 [54:50<3:34:52,  3.49s/it] 19%|█▉        | 855/4545 [54:54<3:42:41,  3.62s/it] 19%|█▉        | 856/4545 [54:57<3:37:32,  3.54s/it] 19%|█▉        | 857/4545 [55:01<3:44:27,  3.65s/it] 19%|█▉        | 858/4545 [55:05<3:51:17,  3.76s/it] 19%|█▉        | 859/4545 [55:08<3:43:46,  3.64s/it] 19%|█▉        | 860/4545 [55:12<3:40:51,  3.60s/it]                                                    {'loss': 0.6257, 'grad_norm': 21.40008544921875, 'learning_rate': 5.673712021136063e-08, 'rewards/chosen': 0.45292967557907104, 'rewards/rejected': 0.03832511976361275, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.4151245057582855, 'logps/chosen': -232.1999969482422, 'logps/rejected': -108.94999694824219, 'logits/chosen': -6.349999904632568, 'logits/rejected': -6.456250190734863, 'epoch': 0.57}
 19%|█▉        | 860/4545 [55:12<3:40:51,  3.60s/it] 19%|█▉        | 861/4545 [55:16<3:46:49,  3.69s/it] 19%|█▉        | 862/4545 [55:19<3:48:33,  3.72s/it] 19%|█▉        | 863/4545 [55:24<3:56:12,  3.85s/it] 19%|█▉        | 864/4545 [55:27<3:57:20,  3.87s/it] 19%|█▉        | 865/4545 [55:31<3:47:51,  3.72s/it] 19%|█▉        | 866/4545 [55:35<3:49:33,  3.74s/it] 19%|█▉        | 867/4545 [55:39<3:52:10,  3.79s/it] 19%|█▉        | 868/4545 [55:43<3:55:45,  3.85s/it] 19%|█▉        | 869/4545 [55:46<3:43:24,  3.65s/it] 19%|█▉        | 870/4545 [55:50<3:48:39,  3.73s/it]                                                    {'loss': 0.615, 'grad_norm': 23.159692764282227, 'learning_rate': 5.739762219286658e-08, 'rewards/chosen': 0.4579101502895355, 'rewards/rejected': 0.03405456617474556, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.42433929443359375, 'logps/chosen': -250.6999969482422, 'logps/rejected': -116.875, 'logits/chosen': -6.359375, 'logits/rejected': -6.753125190734863, 'epoch': 0.57}
 19%|█▉        | 870/4545 [55:50<3:48:39,  3.73s/it] 19%|█▉        | 871/4545 [55:53<3:45:09,  3.68s/it] 19%|█▉        | 872/4545 [55:56<3:37:02,  3.55s/it] 19%|█▉        | 873/4545 [56:00<3:29:20,  3.42s/it] 19%|█▉        | 874/4545 [56:04<3:40:20,  3.60s/it] 19%|█▉        | 875/4545 [56:06<3:22:34,  3.31s/it] 19%|█▉        | 876/4545 [56:10<3:33:13,  3.49s/it] 19%|█▉        | 877/4545 [56:14<3:40:55,  3.61s/it] 19%|█▉        | 878/4545 [56:18<3:41:02,  3.62s/it] 19%|█▉        | 879/4545 [56:22<3:46:19,  3.70s/it] 19%|█▉        | 880/4545 [56:25<3:45:59,  3.70s/it]                                                    {'loss': 0.617, 'grad_norm': 23.513790130615234, 'learning_rate': 5.805812417437253e-08, 'rewards/chosen': 0.5542968511581421, 'rewards/rejected': 0.11246795952320099, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.4415527284145355, 'logps/chosen': -301.0, 'logps/rejected': -147.35000610351562, 'logits/chosen': -6.168749809265137, 'logits/rejected': -6.581250190734863, 'epoch': 0.58}
 19%|█▉        | 880/4545 [56:25<3:45:59,  3.70s/it] 19%|█▉        | 881/4545 [56:29<3:53:43,  3.83s/it] 19%|█▉        | 882/4545 [56:33<3:55:14,  3.85s/it] 19%|█▉        | 883/4545 [56:37<3:54:57,  3.85s/it] 19%|█▉        | 884/4545 [56:41<3:48:17,  3.74s/it] 19%|█▉        | 885/4545 [56:44<3:37:22,  3.56s/it] 19%|█▉        | 886/4545 [56:48<3:42:10,  3.64s/it] 20%|█▉        | 887/4545 [56:51<3:44:48,  3.69s/it] 20%|█▉        | 888/4545 [56:54<3:31:35,  3.47s/it] 20%|█▉        | 889/4545 [56:58<3:39:32,  3.60s/it] 20%|█▉        | 890/4545 [57:02<3:51:10,  3.79s/it]                                                    {'loss': 0.5945, 'grad_norm': 21.302339553833008, 'learning_rate': 5.871862615587847e-08, 'rewards/chosen': 0.48124998807907104, 'rewards/rejected': 0.04548034816980362, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.43452149629592896, 'logps/chosen': -245.4499969482422, 'logps/rejected': -118.55000305175781, 'logits/chosen': -6.275000095367432, 'logits/rejected': -6.465624809265137, 'epoch': 0.59}
 20%|█▉        | 890/4545 [57:02<3:51:10,  3.79s/it] 20%|█▉        | 891/4545 [57:06<3:53:15,  3.83s/it] 20%|█▉        | 892/4545 [57:10<3:54:58,  3.86s/it] 20%|█▉        | 893/4545 [57:14<3:48:42,  3.76s/it] 20%|█▉        | 894/4545 [57:17<3:43:14,  3.67s/it] 20%|█▉        | 895/4545 [57:21<3:48:00,  3.75s/it] 20%|█▉        | 896/4545 [57:25<3:50:48,  3.80s/it] 20%|█▉        | 897/4545 [57:29<3:53:10,  3.84s/it] 20%|█▉        | 898/4545 [57:33<3:57:25,  3.91s/it] 20%|█▉        | 899/4545 [57:37<3:56:50,  3.90s/it] 20%|█▉        | 900/4545 [57:41<3:57:13,  3.90s/it]                                                    {'loss': 0.5944, 'grad_norm': 51.36138153076172, 'learning_rate': 5.93791281373844e-08, 'rewards/chosen': 0.8658202886581421, 'rewards/rejected': 0.19537219405174255, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.6702636480331421, 'logps/chosen': -470.3500061035156, 'logps/rejected': -249.5749969482422, 'logits/chosen': -6.015625, 'logits/rejected': -6.396874904632568, 'epoch': 0.59}
 20%|█▉        | 900/4545 [57:41<3:57:13,  3.90s/it] 20%|█▉        | 901/4545 [57:44<3:47:36,  3.75s/it] 20%|█▉        | 902/4545 [57:48<3:50:32,  3.80s/it] 20%|█▉        | 903/4545 [57:52<3:48:41,  3.77s/it] 20%|█▉        | 904/4545 [57:55<3:38:05,  3.59s/it] 20%|█▉        | 905/4545 [57:59<3:43:50,  3.69s/it] 20%|█▉        | 906/4545 [58:03<3:47:40,  3.75s/it] 20%|█▉        | 907/4545 [58:07<3:56:11,  3.90s/it] 20%|█▉        | 908/4545 [58:11<3:57:18,  3.92s/it] 20%|██        | 909/4545 [58:15<3:57:22,  3.92s/it] 20%|██        | 910/4545 [58:18<3:47:23,  3.75s/it]                                                    {'loss': 0.619, 'grad_norm': 24.896812438964844, 'learning_rate': 6.003963011889035e-08, 'rewards/chosen': 0.44921875, 'rewards/rejected': 0.13475342094898224, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.31462401151657104, 'logps/chosen': -248.5500030517578, 'logps/rejected': -155.1750030517578, 'logits/chosen': -6.143750190734863, 'logits/rejected': -6.534375190734863, 'epoch': 0.6}
 20%|██        | 910/4545 [58:18<3:47:23,  3.75s/it] 20%|██        | 911/4545 [58:22<3:50:28,  3.81s/it] 20%|██        | 912/4545 [58:26<3:53:59,  3.86s/it] 20%|██        | 913/4545 [58:30<3:55:39,  3.89s/it] 20%|██        | 914/4545 [58:34<3:55:15,  3.89s/it] 20%|██        | 915/4545 [58:38<3:46:12,  3.74s/it] 20%|██        | 916/4545 [58:41<3:49:03,  3.79s/it] 20%|██        | 917/4545 [58:45<3:51:14,  3.82s/it] 20%|██        | 918/4545 [58:47<3:17:42,  3.27s/it] 20%|██        | 919/4545 [58:51<3:24:32,  3.38s/it] 20%|██        | 920/4545 [58:55<3:33:47,  3.54s/it]                                                    {'loss': 0.612, 'grad_norm': 21.154191970825195, 'learning_rate': 6.07001321003963e-08, 'rewards/chosen': 0.8521484136581421, 'rewards/rejected': 0.13395385444164276, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.7183593511581421, 'logps/chosen': -410.04998779296875, 'logps/rejected': -183.6750030517578, 'logits/chosen': -6.068749904632568, 'logits/rejected': -6.403124809265137, 'epoch': 0.61}
 20%|██        | 920/4545 [58:55<3:33:47,  3.54s/it] 20%|██        | 921/4545 [58:58<3:28:15,  3.45s/it] 20%|██        | 922/4545 [59:01<3:18:08,  3.28s/it] 20%|██        | 923/4545 [59:05<3:31:43,  3.51s/it] 20%|██        | 924/4545 [59:09<3:39:07,  3.63s/it] 20%|██        | 925/4545 [59:13<3:47:48,  3.78s/it] 20%|██        | 926/4545 [59:17<3:56:21,  3.92s/it] 20%|██        | 927/4545 [59:21<3:43:01,  3.70s/it] 20%|██        | 928/4545 [59:24<3:46:41,  3.76s/it] 20%|██        | 929/4545 [59:28<3:44:13,  3.72s/it] 20%|██        | 930/4545 [59:32<3:50:09,  3.82s/it]                                                    {'loss': 0.5895, 'grad_norm': 28.769161224365234, 'learning_rate': 6.136063408190223e-08, 'rewards/chosen': 0.530957043170929, 'rewards/rejected': 0.04985504224896431, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.48100584745407104, 'logps/chosen': -257.42498779296875, 'logps/rejected': -132.375, 'logits/chosen': -6.253125190734863, 'logits/rejected': -6.671875, 'epoch': 0.61}
 20%|██        | 930/4545 [59:32<3:50:09,  3.82s/it] 20%|██        | 931/4545 [59:36<3:56:59,  3.93s/it] 21%|██        | 932/4545 [59:40<3:47:34,  3.78s/it] 21%|██        | 933/4545 [59:43<3:35:36,  3.58s/it] 21%|██        | 934/4545 [59:46<3:32:38,  3.53s/it] 21%|██        | 935/4545 [59:50<3:43:45,  3.72s/it] 21%|██        | 936/4545 [59:53<3:16:11,  3.26s/it] 21%|██        | 937/4545 [59:57<3:30:24,  3.50s/it] 21%|██        | 938/4545 [1:00:01<3:37:08,  3.61s/it] 21%|██        | 939/4545 [1:00:04<3:40:48,  3.67s/it] 21%|██        | 940/4545 [1:00:09<3:50:21,  3.83s/it]                                                      {'loss': 0.6176, 'grad_norm': 21.997838973999023, 'learning_rate': 6.202113606340819e-08, 'rewards/chosen': 0.41816407442092896, 'rewards/rejected': 0.09506531059741974, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.3233398497104645, 'logps/chosen': -203.60000610351562, 'logps/rejected': -111.125, 'logits/chosen': -6.449999809265137, 'logits/rejected': -6.699999809265137, 'epoch': 0.62}
 21%|██        | 940/4545 [1:00:09<3:50:21,  3.83s/it] 21%|██        | 941/4545 [1:00:13<3:57:34,  3.96s/it] 21%|██        | 942/4545 [1:00:17<3:56:21,  3.94s/it] 21%|██        | 943/4545 [1:00:20<3:52:21,  3.87s/it] 21%|██        | 944/4545 [1:00:23<3:25:18,  3.42s/it] 21%|██        | 945/4545 [1:00:26<3:27:59,  3.47s/it] 21%|██        | 946/4545 [1:00:30<3:30:54,  3.52s/it] 21%|██        | 947/4545 [1:00:34<3:38:34,  3.64s/it] 21%|██        | 948/4545 [1:00:37<3:32:53,  3.55s/it] 21%|██        | 949/4545 [1:00:41<3:38:58,  3.65s/it] 21%|██        | 950/4545 [1:00:45<3:43:57,  3.74s/it]                                                      {'loss': 0.6222, 'grad_norm': 19.382349014282227, 'learning_rate': 6.268163804491414e-08, 'rewards/chosen': 0.46796876192092896, 'rewards/rejected': 0.11547164618968964, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 0.35295408964157104, 'logps/chosen': -218.22500610351562, 'logps/rejected': -129.22500610351562, 'logits/chosen': -6.303124904632568, 'logits/rejected': -6.512499809265137, 'epoch': 0.63}
 21%|██        | 950/4545 [1:00:45<3:43:57,  3.74s/it] 21%|██        | 951/4545 [1:00:48<3:19:29,  3.33s/it] 21%|██        | 952/4545 [1:00:51<3:14:20,  3.25s/it] 21%|██        | 953/4545 [1:00:54<3:26:19,  3.45s/it] 21%|██        | 954/4545 [1:00:59<3:36:56,  3.62s/it] 21%|██        | 955/4545 [1:01:02<3:41:30,  3.70s/it] 21%|██        | 956/4545 [1:01:06<3:45:25,  3.77s/it] 21%|██        | 957/4545 [1:01:10<3:48:01,  3.81s/it] 21%|██        | 958/4545 [1:01:14<3:49:52,  3.85s/it] 21%|██        | 959/4545 [1:01:18<3:51:21,  3.87s/it] 21%|██        | 960/4545 [1:01:22<3:47:24,  3.81s/it]                                                      {'loss': 0.5772, 'grad_norm': 24.36802864074707, 'learning_rate': 6.334214002642007e-08, 'rewards/chosen': 0.995068371295929, 'rewards/rejected': 0.1340789794921875, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.862072765827179, 'logps/chosen': -452.9750061035156, 'logps/rejected': -215.75, 'logits/chosen': -6.068749904632568, 'logits/rejected': -6.537499904632568, 'epoch': 0.63}
 21%|██        | 960/4545 [1:01:22<3:47:24,  3.81s/it] 21%|██        | 961/4545 [1:01:25<3:44:52,  3.76s/it] 21%|██        | 962/4545 [1:01:30<3:52:29,  3.89s/it] 21%|██        | 963/4545 [1:01:33<3:48:00,  3.82s/it] 21%|██        | 964/4545 [1:01:37<3:49:43,  3.85s/it] 21%|██        | 965/4545 [1:01:41<3:51:18,  3.88s/it] 21%|██▏       | 966/4545 [1:01:45<3:51:14,  3.88s/it] 21%|██▏       | 967/4545 [1:01:49<3:51:50,  3.89s/it] 21%|██▏       | 968/4545 [1:01:53<3:52:13,  3.90s/it] 21%|██▏       | 969/4545 [1:01:57<3:52:04,  3.89s/it] 21%|██▏       | 970/4545 [1:02:00<3:42:22,  3.73s/it]                                                      {'loss': 0.5848, 'grad_norm': 17.649761199951172, 'learning_rate': 6.400264200792602e-08, 'rewards/chosen': 0.7979491949081421, 'rewards/rejected': 0.0942787155508995, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.7032226324081421, 'logps/chosen': -374.25, 'logps/rejected': -167.47500610351562, 'logits/chosen': -6.150000095367432, 'logits/rejected': -6.596875190734863, 'epoch': 0.64}
 21%|██▏       | 970/4545 [1:02:00<3:42:22,  3.73s/it] 21%|██▏       | 971/4545 [1:02:03<3:28:38,  3.50s/it] 21%|██▏       | 972/4545 [1:02:07<3:40:56,  3.71s/it] 21%|██▏       | 973/4545 [1:02:11<3:44:37,  3.77s/it] 21%|██▏       | 974/4545 [1:02:15<3:47:05,  3.82s/it] 21%|██▏       | 975/4545 [1:02:19<3:49:01,  3.85s/it] 21%|██▏       | 976/4545 [1:02:23<3:55:01,  3.95s/it] 21%|██▏       | 977/4545 [1:02:27<3:53:18,  3.92s/it] 22%|██▏       | 978/4545 [1:02:30<3:30:15,  3.54s/it] 22%|██▏       | 979/4545 [1:02:34<3:36:51,  3.65s/it] 22%|██▏       | 980/4545 [1:02:38<3:46:29,  3.81s/it]                                                      {'loss': 0.5797, 'grad_norm': 21.115049362182617, 'learning_rate': 6.466314398943196e-08, 'rewards/chosen': 0.8609374761581421, 'rewards/rejected': 0.19110718369483948, 'rewards/accuracies': 0.75, 'rewards/margins': 0.669384777545929, 'logps/chosen': -372.54998779296875, 'logps/rejected': -194.25, 'logits/chosen': -6.296875, 'logits/rejected': -6.581250190734863, 'epoch': 0.65}
 22%|██▏       | 980/4545 [1:02:38<3:46:29,  3.81s/it] 22%|██▏       | 981/4545 [1:02:42<3:48:04,  3.84s/it] 22%|██▏       | 982/4545 [1:02:46<3:54:44,  3.95s/it] 22%|██▏       | 983/4545 [1:02:48<3:22:00,  3.40s/it] 22%|██▏       | 984/4545 [1:02:52<3:30:04,  3.54s/it] 22%|██▏       | 985/4545 [1:02:55<3:19:11,  3.36s/it] 22%|██▏       | 986/4545 [1:02:57<3:05:42,  3.13s/it] 22%|██▏       | 987/4545 [1:03:01<3:09:55,  3.20s/it] 22%|██▏       | 988/4545 [1:03:05<3:22:31,  3.42s/it] 22%|██▏       | 989/4545 [1:03:07<3:11:01,  3.22s/it] 22%|██▏       | 990/4545 [1:03:11<3:23:47,  3.44s/it]                                                      {'loss': 0.5949, 'grad_norm': 21.018308639526367, 'learning_rate': 6.532364597093791e-08, 'rewards/chosen': 0.34174805879592896, 'rewards/rejected': 0.01884765550494194, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 0.32331544160842896, 'logps/chosen': -142.5500030517578, 'logps/rejected': -80.05000305175781, 'logits/chosen': -6.349999904632568, 'logits/rejected': -6.349999904632568, 'epoch': 0.65}
 22%|██▏       | 990/4545 [1:03:11<3:23:47,  3.44s/it] 22%|██▏       | 991/4545 [1:03:16<3:35:55,  3.65s/it] 22%|██▏       | 992/4545 [1:03:18<3:21:14,  3.40s/it] 22%|██▏       | 993/4545 [1:03:22<3:26:08,  3.48s/it] 22%|██▏       | 994/4545 [1:03:26<3:33:32,  3.61s/it] 22%|██▏       | 995/4545 [1:03:29<3:27:09,  3.50s/it] 22%|██▏       | 996/4545 [1:03:31<3:04:45,  3.12s/it] 22%|██▏       | 997/4545 [1:03:36<3:27:08,  3.50s/it] 22%|██▏       | 998/4545 [1:03:40<3:36:06,  3.66s/it] 22%|██▏       | 999/4545 [1:03:44<3:44:15,  3.79s/it] 22%|██▏       | 1000/4545 [1:03:48<3:42:35,  3.77s/it]                                                       {'loss': 0.6026, 'grad_norm': 25.498815536499023, 'learning_rate': 6.598414795244386e-08, 'rewards/chosen': 0.3636718690395355, 'rewards/rejected': 0.04262695461511612, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.32123106718063354, 'logps/chosen': -157.0500030517578, 'logps/rejected': -90.19999694824219, 'logits/chosen': -6.425000190734863, 'logits/rejected': -6.590624809265137, 'epoch': 0.66}
 22%|██▏       | 1000/4545 [1:03:48<3:42:35,  3.77s/it] 22%|██▏       | 1001/4545 [1:03:51<3:42:40,  3.77s/it] 22%|██▏       | 1002/4545 [1:03:55<3:47:56,  3.86s/it] 22%|██▏       | 1003/4545 [1:03:59<3:47:24,  3.85s/it] 22%|██▏       | 1004/4545 [1:04:03<3:43:37,  3.79s/it] 22%|██▏       | 1005/4545 [1:04:06<3:26:38,  3.50s/it] 22%|██▏       | 1006/4545 [1:04:10<3:39:21,  3.72s/it] 22%|██▏       | 1007/4545 [1:04:13<3:34:35,  3.64s/it] 22%|██▏       | 1008/4545 [1:04:17<3:36:54,  3.68s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                       
                                               [A{'eval_loss': 0.502223014831543, 'eval_runtime': 80.337, 'eval_samples_per_second': 11.863, 'eval_steps_per_second': 0.747, 'eval_rewards/chosen': 0.8585612177848816, 'eval_rewards/rejected': 0.11989755928516388, 'eval_rewards/accuracies': 0.9225694537162781, 'eval_rewards/margins': 0.7378011345863342, 'eval_logps/chosen': -369.0416564941406, 'eval_logps/rejected': -150.875, 'eval_logits/chosen': -5.981510639190674, 'eval_logits/rejected': -6.832291603088379, 'epoch': 0.67}
 22%|██▏       | 1008/4545 [1:05:38<3:36:54,  3.68s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 22%|██▏       | 1009/4545 [1:05:52<30:35:33, 31.15s/it] 22%|██▏       | 1010/4545 [1:05:56<22:33:52, 22.98s/it]                                                        {'loss': 0.6033, 'grad_norm': 21.975019454956055, 'learning_rate': 6.66446499339498e-08, 'rewards/chosen': 0.39775389432907104, 'rewards/rejected': 0.03934326022863388, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.35859376192092896, 'logps/chosen': -183.6999969482422, 'logps/rejected': -103.25, 'logits/chosen': -6.34375, 'logits/rejected': -6.659375190734863, 'epoch': 0.67}
 22%|██▏       | 1010/4545 [1:05:56<22:33:52, 22.98s/it] 22%|██▏       | 1011/4545 [1:06:00<16:56:35, 17.26s/it] 22%|██▏       | 1012/4545 [1:06:04<13:00:48, 13.26s/it] 22%|██▏       | 1013/4545 [1:06:08<10:15:42, 10.46s/it] 22%|██▏       | 1014/4545 [1:06:12<8:20:19,  8.50s/it]  22%|██▏       | 1015/4545 [1:06:16<6:59:26,  7.13s/it] 22%|██▏       | 1016/4545 [1:06:20<6:02:43,  6.17s/it] 22%|██▏       | 1017/4545 [1:06:24<5:21:34,  5.47s/it] 22%|██▏       | 1018/4545 [1:06:26<4:26:37,  4.54s/it] 22%|██▏       | 1019/4545 [1:06:30<4:18:31,  4.40s/it] 22%|██▏       | 1020/4545 [1:06:33<3:55:53,  4.02s/it]                                                       {'loss': 0.5846, 'grad_norm': 20.077367782592773, 'learning_rate': 6.730515191545574e-08, 'rewards/chosen': 0.767382800579071, 'rewards/rejected': 0.08572731167078018, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.6822265386581421, 'logps/chosen': -308.25, 'logps/rejected': -180.875, 'logits/chosen': -6.334374904632568, 'logits/rejected': -6.528124809265137, 'epoch': 0.67}
 22%|██▏       | 1020/4545 [1:06:33<3:55:53,  4.02s/it] 22%|██▏       | 1021/4545 [1:06:35<3:20:11,  3.41s/it] 22%|██▏       | 1022/4545 [1:06:38<3:10:21,  3.24s/it] 23%|██▎       | 1023/4545 [1:06:42<3:15:30,  3.33s/it] 23%|██▎       | 1024/4545 [1:06:46<3:28:43,  3.56s/it] 23%|██▎       | 1025/4545 [1:06:50<3:35:30,  3.67s/it] 23%|██▎       | 1026/4545 [1:06:54<3:39:29,  3.74s/it] 23%|██▎       | 1027/4545 [1:06:57<3:35:21,  3.67s/it] 23%|██▎       | 1028/4545 [1:07:01<3:35:29,  3.68s/it] 23%|██▎       | 1029/4545 [1:07:05<3:43:02,  3.81s/it] 23%|██▎       | 1030/4545 [1:07:09<3:44:42,  3.84s/it]                                                       {'loss': 0.5924, 'grad_norm': 23.945844650268555, 'learning_rate': 6.796565389696169e-08, 'rewards/chosen': 0.5047851800918579, 'rewards/rejected': 0.04154663160443306, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.46308594942092896, 'logps/chosen': -201.5500030517578, 'logps/rejected': -124.5250015258789, 'logits/chosen': -6.525000095367432, 'logits/rejected': -6.625, 'epoch': 0.68}
 23%|██▎       | 1030/4545 [1:07:09<3:44:42,  3.84s/it] 23%|██▎       | 1031/4545 [1:07:12<3:34:00,  3.65s/it] 23%|██▎       | 1032/4545 [1:07:16<3:33:10,  3.64s/it] 23%|██▎       | 1033/4545 [1:07:20<3:37:31,  3.72s/it] 23%|██▎       | 1034/4545 [1:07:23<3:23:24,  3.48s/it] 23%|██▎       | 1035/4545 [1:07:27<3:33:27,  3.65s/it] 23%|██▎       | 1036/4545 [1:07:30<3:27:36,  3.55s/it] 23%|██▎       | 1037/4545 [1:07:33<3:23:17,  3.48s/it] 23%|██▎       | 1038/4545 [1:07:36<3:10:30,  3.26s/it] 23%|██▎       | 1039/4545 [1:07:40<3:25:41,  3.52s/it] 23%|██▎       | 1040/4545 [1:07:43<3:19:49,  3.42s/it]                                                       {'loss': 0.5978, 'grad_norm': 19.74962043762207, 'learning_rate': 6.862615587846763e-08, 'rewards/chosen': 0.4725585877895355, 'rewards/rejected': 0.06135864183306694, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.411376953125, 'logps/chosen': -182.8000030517578, 'logps/rejected': -108.75, 'logits/chosen': -6.362500190734863, 'logits/rejected': -6.462500095367432, 'epoch': 0.69}
 23%|██▎       | 1040/4545 [1:07:43<3:19:49,  3.42s/it] 23%|██▎       | 1041/4545 [1:07:47<3:28:23,  3.57s/it] 23%|██▎       | 1042/4545 [1:07:51<3:29:03,  3.58s/it] 23%|██▎       | 1043/4545 [1:07:54<3:23:59,  3.50s/it] 23%|██▎       | 1044/4545 [1:07:58<3:30:04,  3.60s/it] 23%|██▎       | 1045/4545 [1:08:02<3:36:27,  3.71s/it] 23%|██▎       | 1046/4545 [1:08:06<3:39:45,  3.77s/it] 23%|██▎       | 1047/4545 [1:08:10<3:42:00,  3.81s/it] 23%|██▎       | 1048/4545 [1:08:14<3:43:47,  3.84s/it] 23%|██▎       | 1049/4545 [1:08:17<3:35:32,  3.70s/it] 23%|██▎       | 1050/4545 [1:08:21<3:39:08,  3.76s/it]                                                       {'loss': 0.547, 'grad_norm': 15.357301712036133, 'learning_rate': 6.928665785997358e-08, 'rewards/chosen': 0.9041992425918579, 'rewards/rejected': 0.09169922024011612, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.8125976324081421, 'logps/chosen': -346.25, 'logps/rejected': -165.9250030517578, 'logits/chosen': -6.153124809265137, 'logits/rejected': -6.512499809265137, 'epoch': 0.69}
 23%|██▎       | 1050/4545 [1:08:21<3:39:08,  3.76s/it] 23%|██▎       | 1051/4545 [1:08:25<3:41:50,  3.81s/it] 23%|██▎       | 1052/4545 [1:08:29<3:42:45,  3.83s/it] 23%|██▎       | 1053/4545 [1:08:32<3:38:27,  3.75s/it] 23%|██▎       | 1054/4545 [1:08:36<3:31:34,  3.64s/it] 23%|██▎       | 1055/4545 [1:08:39<3:32:13,  3.65s/it] 23%|██▎       | 1056/4545 [1:08:43<3:34:24,  3.69s/it] 23%|██▎       | 1057/4545 [1:08:47<3:38:13,  3.75s/it] 23%|██▎       | 1058/4545 [1:08:50<3:24:48,  3.52s/it] 23%|██▎       | 1059/4545 [1:08:54<3:31:27,  3.64s/it] 23%|██▎       | 1060/4545 [1:08:58<3:37:51,  3.75s/it]                                                       {'loss': 0.5706, 'grad_norm': 19.616233825683594, 'learning_rate': 6.994715984147951e-08, 'rewards/chosen': 0.6908203363418579, 'rewards/rejected': 0.10405273735523224, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.5869140625, 'logps/chosen': -287.375, 'logps/rejected': -164.27499389648438, 'logits/chosen': -6.356249809265137, 'logits/rejected': -6.409375190734863, 'epoch': 0.7}
 23%|██▎       | 1060/4545 [1:08:58<3:37:51,  3.75s/it] 23%|██▎       | 1061/4545 [1:09:02<3:40:22,  3.80s/it] 23%|██▎       | 1062/4545 [1:09:06<3:47:32,  3.92s/it] 23%|██▎       | 1063/4545 [1:09:09<3:39:31,  3.78s/it] 23%|██▎       | 1064/4545 [1:09:13<3:41:01,  3.81s/it] 23%|██▎       | 1065/4545 [1:09:17<3:45:34,  3.89s/it] 23%|██▎       | 1066/4545 [1:09:22<3:50:27,  3.97s/it] 23%|██▎       | 1067/4545 [1:09:25<3:35:26,  3.72s/it] 23%|██▎       | 1068/4545 [1:09:28<3:34:40,  3.70s/it] 24%|██▎       | 1069/4545 [1:09:32<3:32:35,  3.67s/it] 24%|██▎       | 1070/4545 [1:09:35<3:27:08,  3.58s/it]                                                       {'loss': 0.5449, 'grad_norm': 18.194805145263672, 'learning_rate': 7.060766182298546e-08, 'rewards/chosen': 0.49775391817092896, 'rewards/rejected': -0.01308593712747097, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 0.5103515386581421, 'logps/chosen': -190.1999969482422, 'logps/rejected': -98.2750015258789, 'logits/chosen': -6.262499809265137, 'logits/rejected': -6.599999904632568, 'epoch': 0.71}
 24%|██▎       | 1070/4545 [1:09:35<3:27:08,  3.58s/it] 24%|██▎       | 1071/4545 [1:09:39<3:32:38,  3.67s/it] 24%|██▎       | 1072/4545 [1:09:43<3:37:27,  3.76s/it] 24%|██▎       | 1073/4545 [1:09:47<3:40:09,  3.80s/it] 24%|██▎       | 1074/4545 [1:09:51<3:41:44,  3.83s/it] 24%|██▎       | 1075/4545 [1:09:55<3:44:13,  3.88s/it] 24%|██▎       | 1076/4545 [1:09:58<3:28:46,  3.61s/it] 24%|██▎       | 1077/4545 [1:10:02<3:33:51,  3.70s/it] 24%|██▎       | 1078/4545 [1:10:06<3:37:34,  3.77s/it] 24%|██▎       | 1079/4545 [1:10:10<3:40:00,  3.81s/it] 24%|██▍       | 1080/4545 [1:10:14<3:40:52,  3.82s/it]                                                       {'loss': 0.5909, 'grad_norm': 24.913585662841797, 'learning_rate': 7.126816380449141e-08, 'rewards/chosen': 1.1017577648162842, 'rewards/rejected': 0.3123626708984375, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.7906249761581421, 'logps/chosen': -455.75, 'logps/rejected': -217.0, 'logits/chosen': -5.846875190734863, 'logits/rejected': -6.065625190734863, 'epoch': 0.71}
 24%|██▍       | 1080/4545 [1:10:14<3:40:52,  3.82s/it] 24%|██▍       | 1081/4545 [1:10:17<3:42:06,  3.85s/it] 24%|██▍       | 1082/4545 [1:10:21<3:43:12,  3.87s/it] 24%|██▍       | 1083/4545 [1:10:25<3:30:27,  3.65s/it] 24%|██▍       | 1084/4545 [1:10:29<3:37:41,  3.77s/it] 24%|██▍       | 1085/4545 [1:10:32<3:32:31,  3.69s/it] 24%|██▍       | 1086/4545 [1:10:35<3:16:02,  3.40s/it] 24%|██▍       | 1087/4545 [1:10:38<3:08:08,  3.26s/it] 24%|██▍       | 1088/4545 [1:10:42<3:20:46,  3.48s/it] 24%|██▍       | 1089/4545 [1:10:46<3:28:14,  3.62s/it] 24%|██▍       | 1090/4545 [1:10:50<3:37:13,  3.77s/it]                                                       {'loss': 0.5836, 'grad_norm': 27.216800689697266, 'learning_rate': 7.192866578599735e-08, 'rewards/chosen': 0.6485351324081421, 'rewards/rejected': 0.02614746056497097, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.622851550579071, 'logps/chosen': -244.85000610351562, 'logps/rejected': -112.69999694824219, 'logits/chosen': -6.340624809265137, 'logits/rejected': -6.5, 'epoch': 0.72}
 24%|██▍       | 1090/4545 [1:10:50<3:37:13,  3.77s/it] 24%|██▍       | 1091/4545 [1:10:53<3:32:18,  3.69s/it] 24%|██▍       | 1092/4545 [1:10:55<3:02:01,  3.16s/it] 24%|██▍       | 1093/4545 [1:10:59<3:14:44,  3.38s/it] 24%|██▍       | 1094/4545 [1:11:03<3:15:47,  3.40s/it] 24%|██▍       | 1095/4545 [1:11:06<3:24:18,  3.55s/it] 24%|██▍       | 1096/4545 [1:11:09<3:13:31,  3.37s/it] 24%|██▍       | 1097/4545 [1:11:14<3:26:45,  3.60s/it] 24%|██▍       | 1098/4545 [1:11:18<3:35:05,  3.74s/it] 24%|██▍       | 1099/4545 [1:11:22<3:37:50,  3.79s/it] 24%|██▍       | 1100/4545 [1:11:26<3:43:17,  3.89s/it]                                                       {'loss': 0.557, 'grad_norm': 23.05126190185547, 'learning_rate': 7.25891677675033e-08, 'rewards/chosen': 0.6874023675918579, 'rewards/rejected': 0.081817626953125, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.6050659418106079, 'logps/chosen': -253.89999389648438, 'logps/rejected': -126.94999694824219, 'logits/chosen': -6.400000095367432, 'logits/rejected': -6.643750190734863, 'epoch': 0.73}
 24%|██▍       | 1100/4545 [1:11:26<3:43:17,  3.89s/it] 24%|██▍       | 1101/4545 [1:11:30<3:44:21,  3.91s/it] 24%|██▍       | 1102/4545 [1:11:34<3:44:16,  3.91s/it] 24%|██▍       | 1103/4545 [1:11:37<3:34:43,  3.74s/it] 24%|██▍       | 1104/4545 [1:11:41<3:37:10,  3.79s/it] 24%|██▍       | 1105/4545 [1:11:45<3:42:04,  3.87s/it] 24%|██▍       | 1106/4545 [1:11:49<3:42:44,  3.89s/it] 24%|██▍       | 1107/4545 [1:11:53<3:48:28,  3.99s/it] 24%|██▍       | 1108/4545 [1:11:56<3:23:47,  3.56s/it] 24%|██▍       | 1109/4545 [1:11:59<3:29:44,  3.66s/it] 24%|██▍       | 1110/4545 [1:12:03<3:20:13,  3.50s/it]                                                       {'loss': 0.5458, 'grad_norm': 22.29608154296875, 'learning_rate': 7.324966974900924e-08, 'rewards/chosen': 0.813720703125, 'rewards/rejected': 0.12355957180261612, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.690869152545929, 'logps/chosen': -304.625, 'logps/rejected': -164.52499389648438, 'logits/chosen': -6.221875190734863, 'logits/rejected': -6.540625095367432, 'epoch': 0.73}
 24%|██▍       | 1110/4545 [1:12:03<3:20:13,  3.50s/it] 24%|██▍       | 1111/4545 [1:12:05<3:03:31,  3.21s/it] 24%|██▍       | 1112/4545 [1:12:09<3:17:45,  3.46s/it] 24%|██▍       | 1113/4545 [1:12:13<3:22:01,  3.53s/it] 25%|██▍       | 1114/4545 [1:12:17<3:28:20,  3.64s/it] 25%|██▍       | 1115/4545 [1:12:21<3:37:58,  3.81s/it] 25%|██▍       | 1116/4545 [1:12:24<3:28:11,  3.64s/it] 25%|██▍       | 1117/4545 [1:12:26<3:01:59,  3.19s/it] 25%|██▍       | 1118/4545 [1:12:31<3:19:23,  3.49s/it] 25%|██▍       | 1119/4545 [1:12:34<3:24:18,  3.58s/it] 25%|██▍       | 1120/4545 [1:12:38<3:27:14,  3.63s/it]                                                       {'loss': 0.5389, 'grad_norm': 18.50773811340332, 'learning_rate': 7.391017173051519e-08, 'rewards/chosen': 0.768261730670929, 'rewards/rejected': 0.05778198316693306, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.710498034954071, 'logps/chosen': -260.9750061035156, 'logps/rejected': -133.97500610351562, 'logits/chosen': -6.443749904632568, 'logits/rejected': -6.678124904632568, 'epoch': 0.74}
 25%|██▍       | 1120/4545 [1:12:38<3:27:14,  3.63s/it] 25%|██▍       | 1121/4545 [1:12:42<3:36:17,  3.79s/it] 25%|██▍       | 1122/4545 [1:12:46<3:40:44,  3.87s/it] 25%|██▍       | 1123/4545 [1:12:50<3:39:54,  3.86s/it] 25%|██▍       | 1124/4545 [1:12:54<3:40:30,  3.87s/it] 25%|██▍       | 1125/4545 [1:12:57<3:31:26,  3.71s/it] 25%|██▍       | 1126/4545 [1:13:01<3:35:29,  3.78s/it] 25%|██▍       | 1127/4545 [1:13:05<3:30:19,  3.69s/it] 25%|██▍       | 1128/4545 [1:13:08<3:20:06,  3.51s/it] 25%|██▍       | 1129/4545 [1:13:12<3:29:34,  3.68s/it] 25%|██▍       | 1130/4545 [1:13:14<2:59:41,  3.16s/it]                                                       {'loss': 0.5513, 'grad_norm': 16.572729110717773, 'learning_rate': 7.457067371202114e-08, 'rewards/chosen': 0.6612304449081421, 'rewards/rejected': 0.021462250500917435, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 0.639355480670929, 'logps/chosen': -211.4499969482422, 'logps/rejected': -106.17500305175781, 'logits/chosen': -6.412499904632568, 'logits/rejected': -6.481249809265137, 'epoch': 0.75}
 25%|██▍       | 1130/4545 [1:13:14<2:59:41,  3.16s/it] 25%|██▍       | 1131/4545 [1:13:18<3:08:21,  3.31s/it] 25%|██▍       | 1132/4545 [1:13:20<3:01:12,  3.19s/it] 25%|██▍       | 1133/4545 [1:13:24<3:11:56,  3.38s/it] 25%|██▍       | 1134/4545 [1:13:27<3:07:05,  3.29s/it] 25%|██▍       | 1135/4545 [1:13:31<3:17:42,  3.48s/it] 25%|██▍       | 1136/4545 [1:13:34<3:13:20,  3.40s/it] 25%|██▌       | 1137/4545 [1:13:38<3:11:06,  3.36s/it] 25%|██▌       | 1138/4545 [1:13:42<3:20:22,  3.53s/it] 25%|██▌       | 1139/4545 [1:13:45<3:14:45,  3.43s/it] 25%|██▌       | 1140/4545 [1:13:48<3:15:19,  3.44s/it]                                                       {'loss': 0.5971, 'grad_norm': 34.14693069458008, 'learning_rate': 7.523117569352708e-08, 'rewards/chosen': 0.480224609375, 'rewards/rejected': 0.09188232570886612, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3885742127895355, 'logps/chosen': -160.1999969482422, 'logps/rejected': -112.80000305175781, 'logits/chosen': -6.331250190734863, 'logits/rejected': -6.387499809265137, 'epoch': 0.75}
 25%|██▌       | 1140/4545 [1:13:48<3:15:19,  3.44s/it] 25%|██▌       | 1141/4545 [1:13:52<3:23:30,  3.59s/it] 25%|██▌       | 1142/4545 [1:13:55<3:15:03,  3.44s/it] 25%|██▌       | 1143/4545 [1:13:59<3:15:03,  3.44s/it] 25%|██▌       | 1144/4545 [1:14:03<3:23:14,  3.59s/it] 25%|██▌       | 1145/4545 [1:14:07<3:28:36,  3.68s/it] 25%|██▌       | 1146/4545 [1:14:11<3:32:33,  3.75s/it] 25%|██▌       | 1147/4545 [1:14:14<3:21:33,  3.56s/it] 25%|██▌       | 1148/4545 [1:14:17<3:11:27,  3.38s/it] 25%|██▌       | 1149/4545 [1:14:20<3:13:39,  3.42s/it] 25%|██▌       | 1150/4545 [1:14:24<3:14:43,  3.44s/it]                                                       {'loss': 0.5423, 'grad_norm': 15.59387493133545, 'learning_rate': 7.589167767503302e-08, 'rewards/chosen': 0.898730456829071, 'rewards/rejected': 0.09226684272289276, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 0.808300793170929, 'logps/chosen': -299.1000061035156, 'logps/rejected': -170.0500030517578, 'logits/chosen': -6.256249904632568, 'logits/rejected': -6.278124809265137, 'epoch': 0.76}
 25%|██▌       | 1150/4545 [1:14:24<3:14:43,  3.44s/it] 25%|██▌       | 1151/4545 [1:14:28<3:23:51,  3.60s/it] 25%|██▌       | 1152/4545 [1:14:32<3:28:52,  3.69s/it] 25%|██▌       | 1153/4545 [1:14:35<3:32:04,  3.75s/it] 25%|██▌       | 1154/4545 [1:14:37<2:53:25,  3.07s/it] 25%|██▌       | 1155/4545 [1:14:41<3:07:49,  3.32s/it] 25%|██▌       | 1156/4545 [1:14:45<3:14:21,  3.44s/it] 25%|██▌       | 1157/4545 [1:14:49<3:23:57,  3.61s/it] 25%|██▌       | 1158/4545 [1:14:52<3:28:21,  3.69s/it] 26%|██▌       | 1159/4545 [1:14:56<3:31:58,  3.76s/it] 26%|██▌       | 1160/4545 [1:14:59<3:18:25,  3.52s/it]                                                       {'loss': 0.5367, 'grad_norm': 16.510953903198242, 'learning_rate': 7.655217965653897e-08, 'rewards/chosen': 0.938769519329071, 'rewards/rejected': 0.07745361328125, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 0.86083984375, 'logps/chosen': -279.9750061035156, 'logps/rejected': -132.77499389648438, 'logits/chosen': -6.375, 'logits/rejected': -6.743750095367432, 'epoch': 0.77}
 26%|██▌       | 1160/4545 [1:14:59<3:18:25,  3.52s/it] 26%|██▌       | 1161/4545 [1:15:03<3:24:52,  3.63s/it] 26%|██▌       | 1162/4545 [1:15:07<3:30:05,  3.73s/it] 26%|██▌       | 1163/4545 [1:15:11<3:33:24,  3.79s/it] 26%|██▌       | 1164/4545 [1:15:15<3:38:16,  3.87s/it] 26%|██▌       | 1165/4545 [1:15:19<3:38:01,  3.87s/it] 26%|██▌       | 1166/4545 [1:15:21<3:11:58,  3.41s/it] 26%|██▌       | 1167/4545 [1:15:25<3:21:54,  3.59s/it] 26%|██▌       | 1168/4545 [1:15:29<3:29:23,  3.72s/it] 26%|██▌       | 1169/4545 [1:15:33<3:26:02,  3.66s/it] 26%|██▌       | 1170/4545 [1:15:37<3:34:44,  3.82s/it]                                                       {'loss': 0.5274, 'grad_norm': 23.72372055053711, 'learning_rate': 7.72126816380449e-08, 'rewards/chosen': 0.892773449420929, 'rewards/rejected': -0.01958007737994194, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.9125000238418579, 'logps/chosen': -334.6000061035156, 'logps/rejected': -136.22500610351562, 'logits/chosen': -6.15625, 'logits/rejected': -6.503125190734863, 'epoch': 0.77}
 26%|██▌       | 1170/4545 [1:15:37<3:34:44,  3.82s/it] 26%|██▌       | 1171/4545 [1:15:40<3:19:35,  3.55s/it] 26%|██▌       | 1172/4545 [1:15:44<3:25:29,  3.66s/it] 26%|██▌       | 1173/4545 [1:15:47<3:19:40,  3.55s/it] 26%|██▌       | 1174/4545 [1:15:51<3:25:24,  3.66s/it] 26%|██▌       | 1175/4545 [1:15:55<3:28:49,  3.72s/it] 26%|██▌       | 1176/4545 [1:15:59<3:31:12,  3.76s/it] 26%|██▌       | 1177/4545 [1:16:02<3:27:13,  3.69s/it] 26%|██▌       | 1178/4545 [1:16:06<3:30:44,  3.76s/it] 26%|██▌       | 1179/4545 [1:16:10<3:38:14,  3.89s/it] 26%|██▌       | 1180/4545 [1:16:15<3:43:15,  3.98s/it]                                                       {'loss': 0.5268, 'grad_norm': 22.625444412231445, 'learning_rate': 7.787318361955085e-08, 'rewards/chosen': 1.0, 'rewards/rejected': 0.11867675930261612, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.8790038824081421, 'logps/chosen': -310.6499938964844, 'logps/rejected': -182.8000030517578, 'logits/chosen': -6.384375095367432, 'logits/rejected': -6.634375095367432, 'epoch': 0.78}
 26%|██▌       | 1180/4545 [1:16:15<3:43:15,  3.98s/it] 26%|██▌       | 1181/4545 [1:16:19<3:44:46,  4.01s/it] 26%|██▌       | 1182/4545 [1:16:23<3:43:03,  3.98s/it] 26%|██▌       | 1183/4545 [1:16:27<3:47:09,  4.05s/it] 26%|██▌       | 1184/4545 [1:16:31<3:44:39,  4.01s/it] 26%|██▌       | 1185/4545 [1:16:34<3:23:30,  3.63s/it] 26%|██▌       | 1186/4545 [1:16:37<3:28:34,  3.73s/it] 26%|██▌       | 1187/4545 [1:16:41<3:31:57,  3.79s/it] 26%|██▌       | 1188/4545 [1:16:45<3:34:06,  3.83s/it] 26%|██▌       | 1189/4545 [1:16:49<3:26:32,  3.69s/it] 26%|██▌       | 1190/4545 [1:16:53<3:30:28,  3.76s/it]                                                       {'loss': 0.5103, 'grad_norm': 22.60673713684082, 'learning_rate': 7.853368560105679e-08, 'rewards/chosen': 0.9205077886581421, 'rewards/rejected': 0.0897216796875, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 0.831835925579071, 'logps/chosen': -293.8999938964844, 'logps/rejected': -196.6999969482422, 'logits/chosen': -6.331250190734863, 'logits/rejected': -6.740624904632568, 'epoch': 0.79}
 26%|██▌       | 1190/4545 [1:16:53<3:30:28,  3.76s/it] 26%|██▌       | 1191/4545 [1:16:56<3:22:06,  3.62s/it] 26%|██▌       | 1192/4545 [1:17:00<3:31:02,  3.78s/it] 26%|██▌       | 1193/4545 [1:17:04<3:28:48,  3.74s/it] 26%|██▋       | 1194/4545 [1:17:08<3:30:49,  3.77s/it] 26%|██▋       | 1195/4545 [1:17:11<3:32:48,  3.81s/it] 26%|██▋       | 1196/4545 [1:17:15<3:34:04,  3.84s/it] 26%|██▋       | 1197/4545 [1:17:19<3:35:05,  3.85s/it] 26%|██▋       | 1198/4545 [1:17:22<3:19:44,  3.58s/it] 26%|██▋       | 1199/4545 [1:17:25<3:09:21,  3.40s/it] 26%|██▋       | 1200/4545 [1:17:29<3:22:31,  3.63s/it]                                                       {'loss': 0.549, 'grad_norm': 30.281803131103516, 'learning_rate': 7.919418758256274e-08, 'rewards/chosen': 0.7890625, 'rewards/rejected': 0.08133850246667862, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.705859363079071, 'logps/chosen': -259.29998779296875, 'logps/rejected': -147.1999969482422, 'logits/chosen': -6.371874809265137, 'logits/rejected': -6.315625190734863, 'epoch': 0.79}
 26%|██▋       | 1200/4545 [1:17:29<3:22:31,  3.63s/it] 26%|██▋       | 1201/4545 [1:17:32<3:11:05,  3.43s/it] 26%|██▋       | 1202/4545 [1:17:36<3:17:34,  3.55s/it] 26%|██▋       | 1203/4545 [1:17:40<3:27:28,  3.72s/it] 26%|██▋       | 1204/4545 [1:17:44<3:26:27,  3.71s/it] 27%|██▋       | 1205/4545 [1:17:48<3:27:54,  3.73s/it] 27%|██▋       | 1206/4545 [1:17:51<3:19:48,  3.59s/it] 27%|██▋       | 1207/4545 [1:17:55<3:24:13,  3.67s/it] 27%|██▋       | 1208/4545 [1:17:59<3:27:57,  3.74s/it] 27%|██▋       | 1209/4545 [1:18:03<3:33:31,  3.84s/it] 27%|██▋       | 1210/4545 [1:18:07<3:34:35,  3.86s/it]                                                       {'loss': 0.5056, 'grad_norm': 18.77528190612793, 'learning_rate': 7.985468956406869e-08, 'rewards/chosen': 0.75048828125, 'rewards/rejected': 0.02967529371380806, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.721923828125, 'logps/chosen': -223.5, 'logps/rejected': -129.8000030517578, 'logits/chosen': -6.290625095367432, 'logits/rejected': -6.650000095367432, 'epoch': 0.8}
 27%|██▋       | 1210/4545 [1:18:07<3:34:35,  3.86s/it] 27%|██▋       | 1211/4545 [1:18:11<3:35:23,  3.88s/it] 27%|██▋       | 1212/4545 [1:18:15<3:35:45,  3.88s/it] 27%|██▋       | 1213/4545 [1:18:18<3:35:59,  3.89s/it] 27%|██▋       | 1214/4545 [1:18:23<3:39:57,  3.96s/it] 27%|██▋       | 1215/4545 [1:18:26<3:27:26,  3.74s/it] 27%|██▋       | 1216/4545 [1:18:29<3:26:09,  3.72s/it] 27%|██▋       | 1217/4545 [1:18:34<3:32:11,  3.83s/it] 27%|██▋       | 1218/4545 [1:18:38<3:38:44,  3.94s/it] 27%|██▋       | 1219/4545 [1:18:42<3:38:21,  3.94s/it] 27%|██▋       | 1220/4545 [1:18:46<3:37:41,  3.93s/it]                                                       {'loss': 0.5365, 'grad_norm': 13.688304901123047, 'learning_rate': 8.051519154557463e-08, 'rewards/chosen': 0.981249988079071, 'rewards/rejected': 0.12438621371984482, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 0.85546875, 'logps/chosen': -329.95001220703125, 'logps/rejected': -183.35000610351562, 'logits/chosen': -6.184374809265137, 'logits/rejected': -6.253125190734863, 'epoch': 0.81}
 27%|██▋       | 1220/4545 [1:18:46<3:37:41,  3.93s/it] 27%|██▋       | 1221/4545 [1:18:49<3:30:05,  3.79s/it] 27%|██▋       | 1222/4545 [1:18:53<3:25:53,  3.72s/it] 27%|██▋       | 1223/4545 [1:18:56<3:28:48,  3.77s/it] 27%|██▋       | 1224/4545 [1:19:00<3:30:57,  3.81s/it] 27%|██▋       | 1225/4545 [1:19:04<3:23:11,  3.67s/it] 27%|██▋       | 1226/4545 [1:19:08<3:27:04,  3.74s/it] 27%|██▋       | 1227/4545 [1:19:12<3:29:50,  3.79s/it] 27%|██▋       | 1228/4545 [1:19:16<3:33:44,  3.87s/it] 27%|██▋       | 1229/4545 [1:19:19<3:33:12,  3.86s/it] 27%|██▋       | 1230/4545 [1:19:23<3:27:30,  3.76s/it]                                                       {'loss': 0.4924, 'grad_norm': 18.415496826171875, 'learning_rate': 8.117569352708058e-08, 'rewards/chosen': 1.1921875476837158, 'rewards/rejected': 0.2076416015625, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 0.9849609136581421, 'logps/chosen': -342.29998779296875, 'logps/rejected': -248.3249969482422, 'logits/chosen': -6.078125, 'logits/rejected': -6.3125, 'epoch': 0.81}
 27%|██▋       | 1230/4545 [1:19:23<3:27:30,  3.76s/it] 27%|██▋       | 1231/4545 [1:19:27<3:29:53,  3.80s/it] 27%|██▋       | 1232/4545 [1:19:31<3:32:01,  3.84s/it] 27%|██▋       | 1233/4545 [1:19:35<3:30:58,  3.82s/it] 27%|██▋       | 1234/4545 [1:19:39<3:36:40,  3.93s/it] 27%|██▋       | 1235/4545 [1:19:42<3:20:23,  3.63s/it] 27%|██▋       | 1236/4545 [1:19:46<3:24:45,  3.71s/it] 27%|██▋       | 1237/4545 [1:19:50<3:28:13,  3.78s/it] 27%|██▋       | 1238/4545 [1:19:53<3:30:09,  3.81s/it] 27%|██▋       | 1239/4545 [1:19:57<3:31:33,  3.84s/it] 27%|██▋       | 1240/4545 [1:20:01<3:32:28,  3.86s/it]                                                       {'loss': 0.5339, 'grad_norm': 41.407012939453125, 'learning_rate': 8.183619550858652e-08, 'rewards/chosen': 1.359765648841858, 'rewards/rejected': 0.19617919623851776, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.165624976158142, 'logps/chosen': -426.5, 'logps/rejected': -218.14999389648438, 'logits/chosen': -6.262499809265137, 'logits/rejected': -6.300000190734863, 'epoch': 0.82}
 27%|██▋       | 1240/4545 [1:20:01<3:32:28,  3.86s/it] 27%|██▋       | 1241/4545 [1:20:05<3:30:48,  3.83s/it] 27%|██▋       | 1242/4545 [1:20:09<3:32:09,  3.85s/it] 27%|██▋       | 1243/4545 [1:20:13<3:32:49,  3.87s/it] 27%|██▋       | 1244/4545 [1:20:17<3:38:43,  3.98s/it] 27%|██▋       | 1245/4545 [1:20:21<3:38:09,  3.97s/it] 27%|██▋       | 1246/4545 [1:20:25<3:37:50,  3.96s/it] 27%|██▋       | 1247/4545 [1:20:28<3:31:35,  3.85s/it] 27%|██▋       | 1248/4545 [1:20:32<3:32:31,  3.87s/it] 27%|██▋       | 1249/4545 [1:20:36<3:36:00,  3.93s/it] 28%|██▊       | 1250/4545 [1:20:40<3:35:34,  3.93s/it]                                                       {'loss': 0.5857, 'grad_norm': 35.412574768066406, 'learning_rate': 8.249669749009247e-08, 'rewards/chosen': 0.7281249761581421, 'rewards/rejected': 0.06540527194738388, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 0.662792980670929, 'logps/chosen': -225.35000610351562, 'logps/rejected': -147.14999389648438, 'logits/chosen': -6.353125095367432, 'logits/rejected': -6.443749904632568, 'epoch': 0.83}
 28%|██▊       | 1250/4545 [1:20:40<3:35:34,  3.93s/it] 28%|██▊       | 1251/4545 [1:20:44<3:28:38,  3.80s/it] 28%|██▊       | 1252/4545 [1:20:47<3:22:49,  3.70s/it] 28%|██▊       | 1253/4545 [1:20:51<3:24:19,  3.72s/it] 28%|██▊       | 1254/4545 [1:20:55<3:25:28,  3.75s/it] 28%|██▊       | 1255/4545 [1:20:59<3:27:21,  3.78s/it] 28%|██▊       | 1256/4545 [1:21:03<3:29:14,  3.82s/it] 28%|██▊       | 1257/4545 [1:21:07<3:35:37,  3.93s/it] 28%|██▊       | 1258/4545 [1:21:11<3:39:45,  4.01s/it] 28%|██▊       | 1259/4545 [1:21:15<3:39:51,  4.01s/it] 28%|██▊       | 1260/4545 [1:21:18<3:13:45,  3.54s/it]                                                       {'loss': 0.5795, 'grad_norm': 22.864896774291992, 'learning_rate': 8.315719947159842e-08, 'rewards/chosen': 0.614941418170929, 'rewards/rejected': 0.01569824293255806, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.5990234613418579, 'logps/chosen': -196.14999389648438, 'logps/rejected': -133.22500610351562, 'logits/chosen': -6.428124904632568, 'logits/rejected': -6.462500095367432, 'epoch': 0.83}
 28%|██▊       | 1260/4545 [1:21:18<3:13:45,  3.54s/it] 28%|██▊       | 1261/4545 [1:21:21<3:20:06,  3.66s/it] 28%|██▊       | 1262/4545 [1:21:25<3:23:58,  3.73s/it] 28%|██▊       | 1263/4545 [1:21:29<3:17:57,  3.62s/it] 28%|██▊       | 1264/4545 [1:21:33<3:22:27,  3.70s/it] 28%|██▊       | 1265/4545 [1:21:36<3:24:40,  3.74s/it] 28%|██▊       | 1266/4545 [1:21:40<3:25:08,  3.75s/it] 28%|██▊       | 1267/4545 [1:21:43<3:09:42,  3.47s/it] 28%|██▊       | 1268/4545 [1:21:47<3:16:39,  3.60s/it] 28%|██▊       | 1269/4545 [1:21:50<3:15:07,  3.57s/it] 28%|██▊       | 1270/4545 [1:21:55<3:22:37,  3.71s/it]                                                       {'loss': 0.5303, 'grad_norm': 22.312381744384766, 'learning_rate': 8.381770145310434e-08, 'rewards/chosen': 0.933789074420929, 'rewards/rejected': 0.08399657905101776, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 0.8497070074081421, 'logps/chosen': -297.0, 'logps/rejected': -132.125, 'logits/chosen': -6.262499809265137, 'logits/rejected': -6.456250190734863, 'epoch': 0.84}
 28%|██▊       | 1270/4545 [1:21:55<3:22:37,  3.71s/it] 28%|██▊       | 1271/4545 [1:21:59<3:30:49,  3.86s/it] 28%|██▊       | 1272/4545 [1:22:02<3:16:01,  3.59s/it] 28%|██▊       | 1273/4545 [1:22:06<3:21:15,  3.69s/it] 28%|██▊       | 1274/4545 [1:22:10<3:24:52,  3.76s/it] 28%|██▊       | 1275/4545 [1:22:13<3:14:05,  3.56s/it] 28%|██▊       | 1276/4545 [1:22:16<3:06:09,  3.42s/it] 28%|██▊       | 1277/4545 [1:22:20<3:14:31,  3.57s/it] 28%|██▊       | 1278/4545 [1:22:24<3:22:46,  3.72s/it] 28%|██▊       | 1279/4545 [1:22:27<3:12:44,  3.54s/it] 28%|██▊       | 1280/4545 [1:22:31<3:18:42,  3.65s/it]                                                       {'loss': 0.4699, 'grad_norm': 13.60217571258545, 'learning_rate': 8.44782034346103e-08, 'rewards/chosen': 1.2101562023162842, 'rewards/rejected': 0.12221679836511612, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.086523413658142, 'logps/chosen': -347.5, 'logps/rejected': -178.77499389648438, 'logits/chosen': -6.181250095367432, 'logits/rejected': -6.515625, 'epoch': 0.84}
 28%|██▊       | 1280/4545 [1:22:31<3:18:42,  3.65s/it] 28%|██▊       | 1281/4545 [1:22:35<3:20:18,  3.68s/it] 28%|██▊       | 1282/4545 [1:22:38<3:23:11,  3.74s/it] 28%|██▊       | 1283/4545 [1:22:41<3:10:30,  3.50s/it] 28%|██▊       | 1284/4545 [1:22:45<3:10:22,  3.50s/it] 28%|██▊       | 1285/4545 [1:22:49<3:15:27,  3.60s/it] 28%|██▊       | 1286/4545 [1:22:53<3:20:55,  3.70s/it] 28%|██▊       | 1287/4545 [1:22:57<3:24:23,  3.76s/it] 28%|██▊       | 1288/4545 [1:23:00<3:26:31,  3.80s/it] 28%|██▊       | 1289/4545 [1:23:04<3:27:52,  3.83s/it] 28%|██▊       | 1290/4545 [1:23:08<3:33:35,  3.94s/it]                                                       {'loss': 0.5199, 'grad_norm': 16.90302848815918, 'learning_rate': 8.513870541611625e-08, 'rewards/chosen': 1.0808594226837158, 'rewards/rejected': -0.49799805879592896, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.581640601158142, 'logps/chosen': -337.125, 'logps/rejected': -177.72500610351562, 'logits/chosen': -6.315625190734863, 'logits/rejected': -6.387499809265137, 'epoch': 0.85}
 28%|██▊       | 1290/4545 [1:23:08<3:33:35,  3.94s/it] 28%|██▊       | 1291/4545 [1:23:13<3:35:46,  3.98s/it] 28%|██▊       | 1292/4545 [1:23:16<3:28:18,  3.84s/it] 28%|██▊       | 1293/4545 [1:23:20<3:28:38,  3.85s/it] 28%|██▊       | 1294/4545 [1:23:24<3:29:59,  3.88s/it] 28%|██▊       | 1295/4545 [1:23:28<3:30:29,  3.89s/it] 29%|██▊       | 1296/4545 [1:23:31<3:20:54,  3.71s/it] 29%|██▊       | 1297/4545 [1:23:34<3:12:54,  3.56s/it] 29%|██▊       | 1298/4545 [1:23:38<3:17:43,  3.65s/it] 29%|██▊       | 1299/4545 [1:23:41<2:57:02,  3.27s/it] 29%|██▊       | 1300/4545 [1:23:45<3:12:40,  3.56s/it]                                                       {'loss': 0.5098, 'grad_norm': 27.258207321166992, 'learning_rate': 8.579920739762218e-08, 'rewards/chosen': 0.800585925579071, 'rewards/rejected': -0.07005691528320312, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.8701171875, 'logps/chosen': -226.89999389648438, 'logps/rejected': -89.0250015258789, 'logits/chosen': -6.440625190734863, 'logits/rejected': -6.699999809265137, 'epoch': 0.86}
 29%|██▊       | 1300/4545 [1:23:45<3:12:40,  3.56s/it] 29%|██▊       | 1301/4545 [1:23:49<3:23:20,  3.76s/it] 29%|██▊       | 1302/4545 [1:23:53<3:25:49,  3.81s/it] 29%|██▊       | 1303/4545 [1:23:56<3:16:02,  3.63s/it] 29%|██▊       | 1304/4545 [1:24:00<3:20:24,  3.71s/it] 29%|██▊       | 1305/4545 [1:24:04<3:23:23,  3.77s/it] 29%|██▊       | 1306/4545 [1:24:08<3:23:06,  3.76s/it] 29%|██▉       | 1307/4545 [1:24:12<3:27:51,  3.85s/it] 29%|██▉       | 1308/4545 [1:24:14<3:07:36,  3.48s/it] 29%|██▉       | 1309/4545 [1:24:18<3:05:46,  3.44s/it] 29%|██▉       | 1310/4545 [1:24:21<2:56:38,  3.28s/it]                                                       {'loss': 0.5197, 'grad_norm': 71.8920669555664, 'learning_rate': 8.645970937912813e-08, 'rewards/chosen': 0.7728515863418579, 'rewards/rejected': -0.04833984375, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.8207031488418579, 'logps/chosen': -222.14999389648438, 'logps/rejected': -129.25, 'logits/chosen': -6.428124904632568, 'logits/rejected': -6.456250190734863, 'epoch': 0.86}
 29%|██▉       | 1310/4545 [1:24:21<2:56:38,  3.28s/it] 29%|██▉       | 1311/4545 [1:24:25<3:07:11,  3.47s/it] 29%|██▉       | 1312/4545 [1:24:28<3:11:34,  3.56s/it] 29%|██▉       | 1313/4545 [1:24:31<2:58:38,  3.32s/it] 29%|██▉       | 1314/4545 [1:24:35<3:08:13,  3.50s/it] 29%|██▉       | 1315/4545 [1:24:38<3:07:28,  3.48s/it] 29%|██▉       | 1316/4545 [1:24:42<3:09:57,  3.53s/it] 29%|██▉       | 1317/4545 [1:24:46<3:18:41,  3.69s/it] 29%|██▉       | 1318/4545 [1:24:50<3:24:43,  3.81s/it] 29%|██▉       | 1319/4545 [1:24:54<3:25:00,  3.81s/it] 29%|██▉       | 1320/4545 [1:24:58<3:19:44,  3.72s/it]                                                       {'loss': 0.5518, 'grad_norm': 20.911115646362305, 'learning_rate': 8.712021136063407e-08, 'rewards/chosen': 0.7798827886581421, 'rewards/rejected': 0.0118408203125, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.768359363079071, 'logps/chosen': -237.8000030517578, 'logps/rejected': -144.22500610351562, 'logits/chosen': -6.371874809265137, 'logits/rejected': -6.478125095367432, 'epoch': 0.87}
 29%|██▉       | 1320/4545 [1:24:58<3:19:44,  3.72s/it] 29%|██▉       | 1321/4545 [1:25:01<3:23:21,  3.78s/it] 29%|██▉       | 1322/4545 [1:25:06<3:27:30,  3.86s/it] 29%|██▉       | 1323/4545 [1:25:09<3:18:48,  3.70s/it] 29%|██▉       | 1324/4545 [1:25:12<3:15:41,  3.65s/it] 29%|██▉       | 1325/4545 [1:25:16<3:14:42,  3.63s/it] 29%|██▉       | 1326/4545 [1:25:20<3:19:24,  3.72s/it] 29%|██▉       | 1327/4545 [1:25:23<3:12:48,  3.60s/it] 29%|██▉       | 1328/4545 [1:25:27<3:19:09,  3.71s/it] 29%|██▉       | 1329/4545 [1:25:31<3:22:23,  3.78s/it] 29%|██▉       | 1330/4545 [1:25:33<2:54:54,  3.26s/it]                                                       {'loss': 0.5559, 'grad_norm': 15.694223403930664, 'learning_rate': 8.778071334214002e-08, 'rewards/chosen': 0.638964831829071, 'rewards/rejected': 0.03510742262005806, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.6044921875, 'logps/chosen': -180.0, 'logps/rejected': -129.14999389648438, 'logits/chosen': -6.40625, 'logits/rejected': -6.609375, 'epoch': 0.88}
 29%|██▉       | 1330/4545 [1:25:33<2:54:54,  3.26s/it] 29%|██▉       | 1331/4545 [1:25:37<3:05:18,  3.46s/it] 29%|██▉       | 1332/4545 [1:25:41<3:13:23,  3.61s/it] 29%|██▉       | 1333/4545 [1:25:45<3:18:24,  3.71s/it] 29%|██▉       | 1334/4545 [1:25:49<3:21:20,  3.76s/it] 29%|██▉       | 1335/4545 [1:25:53<3:23:44,  3.81s/it] 29%|██▉       | 1336/4545 [1:25:57<3:25:15,  3.84s/it] 29%|██▉       | 1337/4545 [1:26:01<3:29:37,  3.92s/it] 29%|██▉       | 1338/4545 [1:26:04<3:24:30,  3.83s/it] 29%|██▉       | 1339/4545 [1:26:08<3:25:56,  3.85s/it] 29%|██▉       | 1340/4545 [1:26:12<3:26:59,  3.88s/it]                                                       {'loss': 0.4774, 'grad_norm': 25.59160804748535, 'learning_rate': 8.844121532364597e-08, 'rewards/chosen': 1.3527343273162842, 'rewards/rejected': 0.14632567763328552, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.2078125476837158, 'logps/chosen': -401.0, 'logps/rejected': -195.25, 'logits/chosen': -6.140625, 'logits/rejected': -6.634375095367432, 'epoch': 0.88}
 29%|██▉       | 1340/4545 [1:26:12<3:26:59,  3.88s/it] 30%|██▉       | 1341/4545 [1:26:15<3:14:28,  3.64s/it] 30%|██▉       | 1342/4545 [1:26:19<3:06:48,  3.50s/it] 30%|██▉       | 1343/4545 [1:26:22<3:04:55,  3.47s/it] 30%|██▉       | 1344/4545 [1:26:26<3:14:43,  3.65s/it] 30%|██▉       | 1345/4545 [1:26:30<3:17:29,  3.70s/it] 30%|██▉       | 1346/4545 [1:26:34<3:23:34,  3.82s/it] 30%|██▉       | 1347/4545 [1:26:38<3:24:44,  3.84s/it] 30%|██▉       | 1348/4545 [1:26:42<3:25:32,  3.86s/it] 30%|██▉       | 1349/4545 [1:26:46<3:26:15,  3.87s/it] 30%|██▉       | 1350/4545 [1:26:49<3:26:43,  3.88s/it]                                                       {'loss': 0.5115, 'grad_norm': 23.353862762451172, 'learning_rate': 8.910171730515191e-08, 'rewards/chosen': 1.29931640625, 'rewards/rejected': 0.11962890625, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.1804687976837158, 'logps/chosen': -378.6000061035156, 'logps/rejected': -207.89999389648438, 'logits/chosen': -6.243750095367432, 'logits/rejected': -6.4375, 'epoch': 0.89}
 30%|██▉       | 1350/4545 [1:26:49<3:26:43,  3.88s/it] 30%|██▉       | 1351/4545 [1:26:54<3:31:40,  3.98s/it] 30%|██▉       | 1352/4545 [1:26:56<3:07:37,  3.53s/it] 30%|██▉       | 1353/4545 [1:26:59<3:03:43,  3.45s/it] 30%|██▉       | 1354/4545 [1:27:04<3:14:10,  3.65s/it] 30%|██▉       | 1355/4545 [1:27:07<3:18:30,  3.73s/it] 30%|██▉       | 1356/4545 [1:27:11<3:17:51,  3.72s/it] 30%|██▉       | 1357/4545 [1:27:15<3:25:02,  3.86s/it] 30%|██▉       | 1358/4545 [1:27:19<3:17:59,  3.73s/it] 30%|██▉       | 1359/4545 [1:27:23<3:21:06,  3.79s/it] 30%|██▉       | 1360/4545 [1:27:27<3:25:12,  3.87s/it]                                                       {'loss': 0.5354, 'grad_norm': 19.944547653198242, 'learning_rate': 8.976221928665786e-08, 'rewards/chosen': 1.240234375, 'rewards/rejected': 0.21923828125, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 1.0205078125, 'logps/chosen': -355.95001220703125, 'logps/rejected': -191.6750030517578, 'logits/chosen': -6.315625190734863, 'logits/rejected': -6.506249904632568, 'epoch': 0.9}
 30%|██▉       | 1360/4545 [1:27:27<3:25:12,  3.87s/it] 30%|██▉       | 1361/4545 [1:27:31<3:26:11,  3.89s/it] 30%|██▉       | 1362/4545 [1:27:33<3:04:46,  3.48s/it] 30%|██▉       | 1363/4545 [1:27:37<3:11:43,  3.62s/it] 30%|███       | 1364/4545 [1:27:41<3:19:14,  3.76s/it] 30%|███       | 1365/4545 [1:27:45<3:21:26,  3.80s/it] 30%|███       | 1366/4545 [1:27:49<3:25:09,  3.87s/it] 30%|███       | 1367/4545 [1:27:52<3:10:08,  3.59s/it] 30%|███       | 1368/4545 [1:27:56<3:10:43,  3.60s/it] 30%|███       | 1369/4545 [1:28:00<3:14:26,  3.67s/it] 30%|███       | 1370/4545 [1:28:03<3:17:25,  3.73s/it]                                                       {'loss': 0.5308, 'grad_norm': 18.33160972595215, 'learning_rate': 9.042272126816381e-08, 'rewards/chosen': 0.8384765386581421, 'rewards/rejected': -0.04094238206744194, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.8795120120048523, 'logps/chosen': -223.5, 'logps/rejected': -121.2249984741211, 'logits/chosen': -6.496874809265137, 'logits/rejected': -6.46875, 'epoch': 0.9}
 30%|███       | 1370/4545 [1:28:03<3:17:25,  3.73s/it] 30%|███       | 1371/4545 [1:28:07<3:20:21,  3.79s/it] 30%|███       | 1372/4545 [1:28:11<3:13:52,  3.67s/it] 30%|███       | 1373/4545 [1:28:15<3:22:03,  3.82s/it] 30%|███       | 1374/4545 [1:28:17<3:01:00,  3.42s/it] 30%|███       | 1375/4545 [1:28:21<3:09:14,  3.58s/it] 30%|███       | 1376/4545 [1:28:24<2:59:25,  3.40s/it] 30%|███       | 1377/4545 [1:28:28<2:58:22,  3.38s/it] 30%|███       | 1378/4545 [1:28:31<3:02:00,  3.45s/it] 30%|███       | 1379/4545 [1:28:35<3:09:09,  3.58s/it] 30%|███       | 1380/4545 [1:28:39<3:14:47,  3.69s/it]                                                       {'loss': 0.5065, 'grad_norm': 17.620988845825195, 'learning_rate': 9.108322324966975e-08, 'rewards/chosen': 1.058203101158142, 'rewards/rejected': -0.008496093563735485, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.06640625, 'logps/chosen': -277.95001220703125, 'logps/rejected': -110.875, 'logits/chosen': -6.40625, 'logits/rejected': -6.565625190734863, 'epoch': 0.91}
 30%|███       | 1380/4545 [1:28:39<3:14:47,  3.69s/it] 30%|███       | 1381/4545 [1:28:43<3:18:11,  3.76s/it] 30%|███       | 1382/4545 [1:28:47<3:15:36,  3.71s/it] 30%|███       | 1383/4545 [1:28:51<3:18:46,  3.77s/it] 30%|███       | 1384/4545 [1:28:55<3:21:43,  3.83s/it] 30%|███       | 1385/4545 [1:28:58<3:22:47,  3.85s/it] 30%|███       | 1386/4545 [1:29:03<3:26:36,  3.92s/it] 31%|███       | 1387/4545 [1:29:06<3:26:19,  3.92s/it] 31%|███       | 1388/4545 [1:29:10<3:24:56,  3.89s/it] 31%|███       | 1389/4545 [1:29:14<3:25:09,  3.90s/it] 31%|███       | 1390/4545 [1:29:18<3:25:24,  3.91s/it]                                                       {'loss': 0.482, 'grad_norm': 15.599223136901855, 'learning_rate': 9.17437252311757e-08, 'rewards/chosen': 1.5919921398162842, 'rewards/rejected': 0.20505371689796448, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.388671875, 'logps/chosen': -455.1000061035156, 'logps/rejected': -243.3000030517578, 'logits/chosen': -6.212500095367432, 'logits/rejected': -6.453125, 'epoch': 0.92}
 31%|███       | 1390/4545 [1:29:18<3:25:24,  3.91s/it] 31%|███       | 1391/4545 [1:29:22<3:25:20,  3.91s/it] 31%|███       | 1392/4545 [1:29:26<3:24:03,  3.88s/it] 31%|███       | 1393/4545 [1:29:30<3:24:10,  3.89s/it] 31%|███       | 1394/4545 [1:29:34<3:22:33,  3.86s/it] 31%|███       | 1395/4545 [1:29:37<3:21:55,  3.85s/it] 31%|███       | 1396/4545 [1:29:41<3:22:51,  3.87s/it] 31%|███       | 1397/4545 [1:29:45<3:23:48,  3.88s/it] 31%|███       | 1398/4545 [1:29:49<3:26:24,  3.94s/it] 31%|███       | 1399/4545 [1:29:53<3:21:34,  3.84s/it] 31%|███       | 1400/4545 [1:29:57<3:25:41,  3.92s/it]                                                       {'loss': 0.5406, 'grad_norm': 15.955059051513672, 'learning_rate': 9.240422721268162e-08, 'rewards/chosen': 0.9326171875, 'rewards/rejected': 0.0050048828125, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.927539050579071, 'logps/chosen': -231.9499969482422, 'logps/rejected': -110.69999694824219, 'logits/chosen': -6.471875190734863, 'logits/rejected': -6.653124809265137, 'epoch': 0.92}
 31%|███       | 1400/4545 [1:29:57<3:25:41,  3.92s/it] 31%|███       | 1401/4545 [1:30:01<3:20:12,  3.82s/it] 31%|███       | 1402/4545 [1:30:04<3:21:14,  3.84s/it] 31%|███       | 1403/4545 [1:30:08<3:15:33,  3.73s/it] 31%|███       | 1404/4545 [1:30:12<3:17:53,  3.78s/it] 31%|███       | 1405/4545 [1:30:16<3:19:55,  3.82s/it] 31%|███       | 1406/4545 [1:30:20<3:26:04,  3.94s/it] 31%|███       | 1407/4545 [1:30:24<3:21:32,  3.85s/it] 31%|███       | 1408/4545 [1:30:28<3:22:30,  3.87s/it] 31%|███       | 1409/4545 [1:30:31<3:15:58,  3.75s/it] 31%|███       | 1410/4545 [1:30:34<3:08:01,  3.60s/it]                                                       {'loss': 0.4846, 'grad_norm': 19.345401763916016, 'learning_rate': 9.306472919418757e-08, 'rewards/chosen': 0.729296863079071, 'rewards/rejected': -0.18500976264476776, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 0.912890613079071, 'logps/chosen': -176.25, 'logps/rejected': -89.7750015258789, 'logits/chosen': -6.546875, 'logits/rejected': -6.690625190734863, 'epoch': 0.93}
 31%|███       | 1410/4545 [1:30:34<3:08:01,  3.60s/it] 31%|███       | 1411/4545 [1:30:38<3:05:50,  3.56s/it] 31%|███       | 1412/4545 [1:30:42<3:11:30,  3.67s/it] 31%|███       | 1413/4545 [1:30:45<3:06:33,  3.57s/it] 31%|███       | 1414/4545 [1:30:48<3:02:11,  3.49s/it] 31%|███       | 1415/4545 [1:30:52<3:09:03,  3.62s/it] 31%|███       | 1416/4545 [1:30:56<3:14:56,  3.74s/it] 31%|███       | 1417/4545 [1:31:00<3:08:45,  3.62s/it] 31%|███       | 1418/4545 [1:31:03<3:00:09,  3.46s/it] 31%|███       | 1419/4545 [1:31:07<3:06:57,  3.59s/it] 31%|███       | 1420/4545 [1:31:09<2:50:27,  3.27s/it]                                                       {'loss': 0.5309, 'grad_norm': 16.272396087646484, 'learning_rate': 9.372523117569352e-08, 'rewards/chosen': 0.8228515386581421, 'rewards/rejected': 0.03398437425494194, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.7894531488418579, 'logps/chosen': -230.4250030517578, 'logps/rejected': -141.0500030517578, 'logits/chosen': -6.540625095367432, 'logits/rejected': -6.471875190734863, 'epoch': 0.94}
 31%|███       | 1420/4545 [1:31:09<2:50:27,  3.27s/it] 31%|███▏      | 1421/4545 [1:31:13<3:00:27,  3.47s/it] 31%|███▏      | 1422/4545 [1:31:17<3:05:59,  3.57s/it] 31%|███▏      | 1423/4545 [1:31:20<3:07:42,  3.61s/it] 31%|███▏      | 1424/4545 [1:31:24<3:13:04,  3.71s/it] 31%|███▏      | 1425/4545 [1:31:28<3:04:21,  3.55s/it] 31%|███▏      | 1426/4545 [1:31:32<3:09:55,  3.65s/it] 31%|███▏      | 1427/4545 [1:31:35<3:12:21,  3.70s/it] 31%|███▏      | 1428/4545 [1:31:39<3:15:48,  3.77s/it] 31%|███▏      | 1429/4545 [1:31:42<3:01:05,  3.49s/it] 31%|███▏      | 1430/4545 [1:31:45<2:47:11,  3.22s/it]                                                       {'loss': 0.5397, 'grad_norm': 23.06352424621582, 'learning_rate': 9.438573315719946e-08, 'rewards/chosen': 0.765332043170929, 'rewards/rejected': 0.0034240721724927425, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7613281011581421, 'logps/chosen': -204.02499389648438, 'logps/rejected': -157.14999389648438, 'logits/chosen': -6.5, 'logits/rejected': -6.493750095367432, 'epoch': 0.94}
 31%|███▏      | 1430/4545 [1:31:45<2:47:11,  3.22s/it] 31%|███▏      | 1431/4545 [1:31:49<2:59:12,  3.45s/it] 32%|███▏      | 1432/4545 [1:31:53<3:06:39,  3.60s/it] 32%|███▏      | 1433/4545 [1:31:57<3:11:33,  3.69s/it] 32%|███▏      | 1434/4545 [1:32:00<3:15:07,  3.76s/it] 32%|███▏      | 1435/4545 [1:32:05<3:21:23,  3.89s/it] 32%|███▏      | 1436/4545 [1:32:09<3:21:51,  3.90s/it] 32%|███▏      | 1437/4545 [1:32:12<3:22:09,  3.90s/it] 32%|███▏      | 1438/4545 [1:32:16<3:20:39,  3.87s/it] 32%|███▏      | 1439/4545 [1:32:20<3:23:20,  3.93s/it] 32%|███▏      | 1440/4545 [1:32:23<3:05:19,  3.58s/it]                                                       {'loss': 0.4794, 'grad_norm': 17.18311882019043, 'learning_rate': 9.504623513870541e-08, 'rewards/chosen': 1.095703125, 'rewards/rejected': -0.012847900390625, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.109765648841858, 'logps/chosen': -285.79998779296875, 'logps/rejected': -149.52499389648438, 'logits/chosen': -6.387499809265137, 'logits/rejected': -6.506249904632568, 'epoch': 0.95}
 32%|███▏      | 1440/4545 [1:32:23<3:05:19,  3.58s/it] 32%|███▏      | 1441/4545 [1:32:27<3:03:24,  3.55s/it] 32%|███▏      | 1442/4545 [1:32:30<3:08:18,  3.64s/it] 32%|███▏      | 1443/4545 [1:32:34<3:13:32,  3.74s/it] 32%|███▏      | 1444/4545 [1:32:38<3:16:05,  3.79s/it] 32%|███▏      | 1445/4545 [1:32:42<3:11:00,  3.70s/it] 32%|███▏      | 1446/4545 [1:32:45<3:03:38,  3.56s/it] 32%|███▏      | 1447/4545 [1:32:47<2:39:49,  3.10s/it] 32%|███▏      | 1448/4545 [1:32:51<2:52:18,  3.34s/it] 32%|███▏      | 1449/4545 [1:32:54<2:48:32,  3.27s/it] 32%|███▏      | 1450/4545 [1:32:58<2:59:40,  3.48s/it]                                                       {'loss': 0.4412, 'grad_norm': 24.15694236755371, 'learning_rate': 9.570673712021135e-08, 'rewards/chosen': 1.1904296875, 'rewards/rejected': -0.01352539099752903, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.202734351158142, 'logps/chosen': -304.20001220703125, 'logps/rejected': -181.9499969482422, 'logits/chosen': -6.334374904632568, 'logits/rejected': -6.493750095367432, 'epoch': 0.96}
 32%|███▏      | 1450/4545 [1:32:58<2:59:40,  3.48s/it] 32%|███▏      | 1451/4545 [1:33:00<2:42:07,  3.14s/it] 32%|███▏      | 1452/4545 [1:33:03<2:29:50,  2.91s/it] 32%|███▏      | 1453/4545 [1:33:06<2:33:40,  2.98s/it] 32%|███▏      | 1454/4545 [1:33:10<2:44:41,  3.20s/it] 32%|███▏      | 1455/4545 [1:33:14<2:57:16,  3.44s/it] 32%|███▏      | 1456/4545 [1:33:17<2:54:49,  3.40s/it] 32%|███▏      | 1457/4545 [1:33:21<3:02:49,  3.55s/it] 32%|███▏      | 1458/4545 [1:33:24<2:56:30,  3.43s/it] 32%|███▏      | 1459/4545 [1:33:28<3:04:03,  3.58s/it] 32%|███▏      | 1460/4545 [1:33:32<3:08:59,  3.68s/it]                                                       {'loss': 0.5242, 'grad_norm': 16.497468948364258, 'learning_rate': 9.63672391017173e-08, 'rewards/chosen': 0.9559570550918579, 'rewards/rejected': -0.008740234188735485, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.9647461175918579, 'logps/chosen': -241.6999969482422, 'logps/rejected': -151.0500030517578, 'logits/chosen': -6.453125, 'logits/rejected': -6.634375095367432, 'epoch': 0.96}
 32%|███▏      | 1460/4545 [1:33:32<3:08:59,  3.68s/it] 32%|███▏      | 1461/4545 [1:33:36<3:12:30,  3.75s/it] 32%|███▏      | 1462/4545 [1:33:39<3:12:11,  3.74s/it] 32%|███▏      | 1463/4545 [1:33:43<3:12:36,  3.75s/it] 32%|███▏      | 1464/4545 [1:33:47<3:15:17,  3.80s/it] 32%|███▏      | 1465/4545 [1:33:51<3:13:05,  3.76s/it] 32%|███▏      | 1466/4545 [1:33:54<3:12:04,  3.74s/it] 32%|███▏      | 1467/4545 [1:33:58<3:14:19,  3.79s/it] 32%|███▏      | 1468/4545 [1:34:03<3:20:32,  3.91s/it] 32%|███▏      | 1469/4545 [1:34:06<3:18:04,  3.86s/it] 32%|███▏      | 1470/4545 [1:34:10<3:17:15,  3.85s/it]                                                       {'loss': 0.5199, 'grad_norm': 19.649580001831055, 'learning_rate': 9.702774108322325e-08, 'rewards/chosen': 0.7466796636581421, 'rewards/rejected': -0.06562499701976776, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8125976324081421, 'logps/chosen': -202.9499969482422, 'logps/rejected': -133.72500610351562, 'logits/chosen': -6.456250190734863, 'logits/rejected': -6.584374904632568, 'epoch': 0.97}
 32%|███▏      | 1470/4545 [1:34:10<3:17:15,  3.85s/it] 32%|███▏      | 1471/4545 [1:34:14<3:17:30,  3.86s/it] 32%|███▏      | 1472/4545 [1:34:18<3:21:12,  3.93s/it] 32%|███▏      | 1473/4545 [1:34:22<3:13:20,  3.78s/it] 32%|███▏      | 1474/4545 [1:34:25<3:02:46,  3.57s/it] 32%|███▏      | 1475/4545 [1:34:28<3:01:08,  3.54s/it] 32%|███▏      | 1476/4545 [1:34:32<3:06:45,  3.65s/it] 32%|███▏      | 1477/4545 [1:34:36<3:11:01,  3.74s/it] 33%|███▎      | 1478/4545 [1:34:39<3:01:34,  3.55s/it] 33%|███▎      | 1479/4545 [1:34:43<3:06:52,  3.66s/it] 33%|███▎      | 1480/4545 [1:34:47<3:06:06,  3.64s/it]                                                       {'loss': 0.4689, 'grad_norm': 20.540069580078125, 'learning_rate': 9.768824306472919e-08, 'rewards/chosen': 1.449804663658142, 'rewards/rejected': -0.0024658204056322575, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.450585961341858, 'logps/chosen': -380.70001220703125, 'logps/rejected': -183.4499969482422, 'logits/chosen': -6.503125190734863, 'logits/rejected': -6.665625095367432, 'epoch': 0.98}
 33%|███▎      | 1480/4545 [1:34:47<3:06:06,  3.64s/it] 33%|███▎      | 1481/4545 [1:34:50<3:10:02,  3.72s/it] 33%|███▎      | 1482/4545 [1:34:53<2:49:00,  3.31s/it] 33%|███▎      | 1483/4545 [1:34:57<2:57:57,  3.49s/it] 33%|███▎      | 1484/4545 [1:35:01<3:09:07,  3.71s/it] 33%|███▎      | 1485/4545 [1:35:05<3:12:03,  3.77s/it] 33%|███▎      | 1486/4545 [1:35:09<3:14:10,  3.81s/it] 33%|███▎      | 1487/4545 [1:35:12<3:12:41,  3.78s/it] 33%|███▎      | 1488/4545 [1:35:16<3:06:40,  3.66s/it] 33%|███▎      | 1489/4545 [1:35:20<3:12:34,  3.78s/it] 33%|███▎      | 1490/4545 [1:35:24<3:18:13,  3.89s/it]                                                       {'loss': 0.4935, 'grad_norm': 18.703760147094727, 'learning_rate': 9.834874504623514e-08, 'rewards/chosen': 1.1384766101837158, 'rewards/rejected': -0.04188232496380806, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.181640625, 'logps/chosen': -288.75, 'logps/rejected': -138.0500030517578, 'logits/chosen': -6.362500190734863, 'logits/rejected': -6.46875, 'epoch': 0.98}
 33%|███▎      | 1490/4545 [1:35:24<3:18:13,  3.89s/it] 33%|███▎      | 1491/4545 [1:35:28<3:18:20,  3.90s/it] 33%|███▎      | 1492/4545 [1:35:32<3:22:59,  3.99s/it] 33%|███▎      | 1493/4545 [1:35:35<3:01:38,  3.57s/it] 33%|███▎      | 1494/4545 [1:35:38<2:58:39,  3.51s/it] 33%|███▎      | 1495/4545 [1:35:42<3:02:42,  3.59s/it] 33%|███▎      | 1496/4545 [1:35:45<2:57:23,  3.49s/it] 33%|███▎      | 1497/4545 [1:35:49<3:03:05,  3.60s/it] 33%|███▎      | 1498/4545 [1:35:52<2:54:45,  3.44s/it] 33%|███▎      | 1499/4545 [1:35:56<3:07:14,  3.69s/it] 33%|███▎      | 1500/4545 [1:36:01<3:14:36,  3.83s/it]                                                       {'loss': 0.507, 'grad_norm': 20.026325225830078, 'learning_rate': 9.900924702774109e-08, 'rewards/chosen': 0.855273425579071, 'rewards/rejected': -0.11697997897863388, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.9727538824081421, 'logps/chosen': -224.75, 'logps/rejected': -102.0, 'logits/chosen': -6.606249809265137, 'logits/rejected': -6.665625095367432, 'epoch': 0.99}
 33%|███▎      | 1500/4545 [1:36:01<3:14:36,  3.83s/it] 33%|███▎      | 1501/4545 [1:36:05<3:16:10,  3.87s/it] 33%|███▎      | 1502/4545 [1:36:08<3:16:49,  3.88s/it] 33%|███▎      | 1503/4545 [1:36:12<3:10:46,  3.76s/it] 33%|███▎      | 1504/4545 [1:36:16<3:12:55,  3.81s/it] 33%|███▎      | 1505/4545 [1:36:20<3:14:23,  3.84s/it] 33%|███▎      | 1506/4545 [1:36:23<3:13:06,  3.81s/it] 33%|███▎      | 1507/4545 [1:36:27<3:06:14,  3.68s/it] 33%|███▎      | 1508/4545 [1:36:30<2:54:50,  3.45s/it] 33%|███▎      | 1509/4545 [1:36:34<3:02:01,  3.60s/it] 33%|███▎      | 1510/4545 [1:36:38<3:10:26,  3.76s/it]                                                       {'loss': 0.4934, 'grad_norm': 21.890522003173828, 'learning_rate': 9.966974900924703e-08, 'rewards/chosen': 1.578027367591858, 'rewards/rejected': 0.25537109375, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.320947289466858, 'logps/chosen': -398.6000061035156, 'logps/rejected': -186.72500610351562, 'logits/chosen': -6.203125, 'logits/rejected': -6.371874809265137, 'epoch': 1.0}
 33%|███▎      | 1510/4545 [1:36:38<3:10:26,  3.76s/it] 33%|███▎      | 1511/4545 [1:36:42<3:10:59,  3.78s/it] 33%|███▎      | 1512/4545 [1:36:46<3:12:52,  3.82s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.08s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.16s/it][A
 47%|████▋     | 28/60 [00:36<00:35,  1.10s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.13s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.30s/it][A
 52%|█████▏    | 31/60 [00:40<00:40,  1.38s/it][A
 53%|█████▎    | 32/60 [00:42<00:39,  1.41s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.39s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.22s/it][A
 58%|█████▊    | 35/60 [00:45<00:32,  1.30s/it][A
 60%|██████    | 36/60 [00:47<00:32,  1.35s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.12s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.26s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.24s/it][A
 67%|██████▋   | 40/60 [00:51<00:22,  1.11s/it][A
 68%|██████▊   | 41/60 [00:52<00:23,  1.22s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.32s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:57<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:01<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:09<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A                                                       
                                               [A{'eval_loss': 0.3998053967952728, 'eval_runtime': 80.6835, 'eval_samples_per_second': 11.812, 'eval_steps_per_second': 0.744, 'eval_rewards/chosen': 1.3608561754226685, 'eval_rewards/rejected': 0.0497996024787426, 'eval_rewards/accuracies': 0.9059028029441833, 'eval_rewards/margins': 1.3117350339889526, 'eval_logps/chosen': -364.2749938964844, 'eval_logps/rejected': -151.4583282470703, 'eval_logits/chosen': -6.191145896911621, 'eval_logits/rejected': -6.902604103088379, 'epoch': 1.0}
 33%|███▎      | 1512/4545 [1:38:06<3:12:52,  3.82s/it]
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 33%|███▎      | 1513/4545 [1:38:21<26:23:41, 31.34s/it] 33%|███▎      | 1514/4545 [1:38:25<19:31:05, 23.18s/it] 33%|███▎      | 1515/4545 [1:38:29<14:38:27, 17.40s/it] 33%|███▎      | 1516/4545 [1:38:33<11:13:13, 13.34s/it] 33%|███▎      | 1517/4545 [1:38:36<8:36:14, 10.23s/it]  33%|███▎      | 1518/4545 [1:38:40<6:56:02,  8.25s/it] 33%|███▎      | 1519/4545 [1:38:44<5:50:05,  6.94s/it] 33%|███▎      | 1520/4545 [1:38:48<5:06:45,  6.08s/it]                                                       {'loss': 0.4701, 'grad_norm': 15.149170875549316, 'learning_rate': 9.999939570440647e-08, 'rewards/chosen': 2.20703125, 'rewards/rejected': 0.06098632887005806, 'rewards/accuracies': 0.7729166746139526, 'rewards/margins': 2.142578125, 'logps/chosen': -580.9000244140625, 'logps/rejected': -195.35000610351562, 'logits/chosen': -6.096875190734863, 'logits/rejected': -6.409375190734863, 'epoch': 1.0}
 33%|███▎      | 1520/4545 [1:38:48<5:06:45,  6.08s/it] 33%|███▎      | 1521/4545 [1:38:52<4:35:56,  5.47s/it] 33%|███▎      | 1522/4545 [1:38:56<4:11:58,  5.00s/it] 34%|███▎      | 1523/4545 [1:38:59<3:55:21,  4.67s/it] 34%|███▎      | 1524/4545 [1:39:03<3:43:41,  4.44s/it] 34%|███▎      | 1525/4545 [1:39:07<3:35:34,  4.28s/it] 34%|███▎      | 1526/4545 [1:39:11<3:30:01,  4.17s/it] 34%|███▎      | 1527/4545 [1:39:14<3:15:24,  3.88s/it] 34%|███▎      | 1528/4545 [1:39:18<3:15:30,  3.89s/it] 34%|███▎      | 1529/4545 [1:39:22<3:07:27,  3.73s/it] 34%|███▎      | 1530/4545 [1:39:24<2:52:11,  3.43s/it]                                                       {'loss': 0.4957, 'grad_norm': 23.492916107177734, 'learning_rate': 9.999456143703726e-08, 'rewards/chosen': 1.6627929210662842, 'rewards/rejected': 0.03805389255285263, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.622460961341858, 'logps/chosen': -457.54998779296875, 'logps/rejected': -195.85000610351562, 'logits/chosen': -6.356249809265137, 'logits/rejected': -6.381249904632568, 'epoch': 1.01}
 34%|███▎      | 1530/4545 [1:39:24<2:52:11,  3.43s/it] 34%|███▎      | 1531/4545 [1:39:28<3:01:01,  3.60s/it] 34%|███▎      | 1532/4545 [1:39:32<2:57:04,  3.53s/it] 34%|███▎      | 1533/4545 [1:39:36<3:07:38,  3.74s/it] 34%|███▍      | 1534/4545 [1:39:40<3:09:33,  3.78s/it] 34%|███▍      | 1535/4545 [1:39:43<2:55:54,  3.51s/it] 34%|███▍      | 1536/4545 [1:39:45<2:35:49,  3.11s/it] 34%|███▍      | 1537/4545 [1:39:49<2:49:55,  3.39s/it] 34%|███▍      | 1538/4545 [1:39:52<2:46:26,  3.32s/it] 34%|███▍      | 1539/4545 [1:39:56<2:50:14,  3.40s/it] 34%|███▍      | 1540/4545 [1:40:00<2:58:05,  3.56s/it]                                                       {'loss': 0.4496, 'grad_norm': 16.132030487060547, 'learning_rate': 9.998489342164231e-08, 'rewards/chosen': 1.109765648841858, 'rewards/rejected': -0.12517090141773224, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.2365233898162842, 'logps/chosen': -254.875, 'logps/rejected': -152.10000610351562, 'logits/chosen': -6.587500095367432, 'logits/rejected': -6.856249809265137, 'epoch': 1.02}
 34%|███▍      | 1540/4545 [1:40:00<2:58:05,  3.56s/it] 34%|███▍      | 1541/4545 [1:40:04<3:03:28,  3.66s/it] 34%|███▍      | 1542/4545 [1:40:07<3:07:14,  3.74s/it] 34%|███▍      | 1543/4545 [1:40:11<3:02:32,  3.65s/it] 34%|███▍      | 1544/4545 [1:40:15<3:05:46,  3.71s/it] 34%|███▍      | 1545/4545 [1:40:19<3:08:40,  3.77s/it] 34%|███▍      | 1546/4545 [1:40:23<3:10:24,  3.81s/it] 34%|███▍      | 1547/4545 [1:40:26<3:11:39,  3.84s/it] 34%|███▍      | 1548/4545 [1:40:31<3:17:09,  3.95s/it] 34%|███▍      | 1549/4545 [1:40:34<3:13:55,  3.88s/it] 34%|███▍      | 1550/4545 [1:40:38<3:16:49,  3.94s/it]                                                       {'loss': 0.4332, 'grad_norm': 16.659488677978516, 'learning_rate': 9.99703926968527e-08, 'rewards/chosen': 1.2781250476837158, 'rewards/rejected': -0.0320281982421875, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.3113281726837158, 'logps/chosen': -311.1499938964844, 'logps/rejected': -169.875, 'logits/chosen': -6.465624809265137, 'logits/rejected': -6.565625190734863, 'epoch': 1.02}
 34%|███▍      | 1550/4545 [1:40:38<3:16:49,  3.94s/it] 34%|███▍      | 1551/4545 [1:40:43<3:20:39,  4.02s/it] 34%|███▍      | 1552/4545 [1:40:46<3:10:51,  3.83s/it] 34%|███▍      | 1553/4545 [1:40:49<2:58:21,  3.58s/it] 34%|███▍      | 1554/4545 [1:40:53<3:04:40,  3.70s/it] 34%|███▍      | 1555/4545 [1:40:57<3:07:45,  3.77s/it] 34%|███▍      | 1556/4545 [1:41:01<3:09:45,  3.81s/it] 34%|███▍      | 1557/4545 [1:41:05<3:16:05,  3.94s/it] 34%|███▍      | 1558/4545 [1:41:07<2:47:47,  3.37s/it] 34%|███▍      | 1559/4545 [1:41:11<2:49:27,  3.40s/it] 34%|███▍      | 1560/4545 [1:41:14<2:53:40,  3.49s/it]                                                       {'loss': 0.4388, 'grad_norm': 16.975765228271484, 'learning_rate': 9.995106082047558e-08, 'rewards/chosen': 1.487890601158142, 'rewards/rejected': 0.04277343675494194, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.4464843273162842, 'logps/chosen': -354.75, 'logps/rejected': -194.89999389648438, 'logits/chosen': -6.409375190734863, 'logits/rejected': -6.565625190734863, 'epoch': 1.03}
 34%|███▍      | 1560/4545 [1:41:14<2:53:40,  3.49s/it] 34%|███▍      | 1561/4545 [1:41:17<2:45:59,  3.34s/it] 34%|███▍      | 1562/4545 [1:41:22<2:59:14,  3.61s/it] 34%|███▍      | 1563/4545 [1:41:26<3:05:23,  3.73s/it] 34%|███▍      | 1564/4545 [1:41:28<2:48:20,  3.39s/it] 34%|███▍      | 1565/4545 [1:41:32<2:55:48,  3.54s/it] 34%|███▍      | 1566/4545 [1:41:36<3:01:52,  3.66s/it] 34%|███▍      | 1567/4545 [1:41:40<3:06:38,  3.76s/it] 34%|███▍      | 1568/4545 [1:41:44<3:08:44,  3.80s/it] 35%|███▍      | 1569/4545 [1:41:47<3:04:39,  3.72s/it] 35%|███▍      | 1570/4545 [1:41:50<2:52:11,  3.47s/it]                                                       {'loss': 0.5152, 'grad_norm': 23.92498779296875, 'learning_rate': 9.992689986932682e-08, 'rewards/chosen': 1.090429663658142, 'rewards/rejected': 0.018483733758330345, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 1.0714843273162842, 'logps/chosen': -291.70001220703125, 'logps/rejected': -157.8000030517578, 'logits/chosen': -6.628125190734863, 'logits/rejected': -6.603125095367432, 'epoch': 1.04}
 35%|███▍      | 1570/4545 [1:41:50<2:52:11,  3.47s/it] 35%|███▍      | 1571/4545 [1:41:54<2:54:58,  3.53s/it] 35%|███▍      | 1572/4545 [1:41:58<3:01:35,  3.66s/it] 35%|███▍      | 1573/4545 [1:42:02<3:07:51,  3.79s/it] 35%|███▍      | 1574/4545 [1:42:05<2:57:39,  3.59s/it] 35%|███▍      | 1575/4545 [1:42:08<2:50:44,  3.45s/it] 35%|███▍      | 1576/4545 [1:42:12<2:48:09,  3.40s/it] 35%|███▍      | 1577/4545 [1:42:15<2:43:58,  3.31s/it] 35%|███▍      | 1578/4545 [1:42:19<2:53:11,  3.50s/it] 35%|███▍      | 1579/4545 [1:42:22<2:49:07,  3.42s/it] 35%|███▍      | 1580/4545 [1:42:26<2:58:37,  3.61s/it]                                                       {'loss': 0.4633, 'grad_norm': 15.4862060546875, 'learning_rate': 9.98979124390079e-08, 'rewards/chosen': 0.7598632574081421, 'rewards/rejected': -0.2508300840854645, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.0109374523162842, 'logps/chosen': -184.9499969482422, 'logps/rejected': -96.0, 'logits/chosen': -6.803124904632568, 'logits/rejected': -6.824999809265137, 'epoch': 1.04}
 35%|███▍      | 1580/4545 [1:42:26<2:58:37,  3.61s/it] 35%|███▍      | 1581/4545 [1:42:29<2:47:30,  3.39s/it] 35%|███▍      | 1582/4545 [1:42:32<2:50:11,  3.45s/it] 35%|███▍      | 1583/4545 [1:42:36<2:57:58,  3.61s/it] 35%|███▍      | 1584/4545 [1:42:41<3:06:58,  3.79s/it] 35%|███▍      | 1585/4545 [1:42:44<3:08:31,  3.82s/it] 35%|███▍      | 1586/4545 [1:42:47<2:43:49,  3.32s/it] 35%|███▍      | 1587/4545 [1:42:51<2:56:26,  3.58s/it] 35%|███▍      | 1588/4545 [1:42:55<3:04:51,  3.75s/it] 35%|███▍      | 1589/4545 [1:42:59<3:10:28,  3.87s/it] 35%|███▍      | 1590/4545 [1:43:03<3:05:18,  3.76s/it]                                                       {'loss': 0.4351, 'grad_norm': 14.422926902770996, 'learning_rate': 9.986410164362702e-08, 'rewards/chosen': 0.708203136920929, 'rewards/rejected': -0.3241943418979645, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.0322265625, 'logps/chosen': -170.0749969482422, 'logps/rejected': -91.1500015258789, 'logits/chosen': -6.625, 'logits/rejected': -6.793749809265137, 'epoch': 1.05}
 35%|███▍      | 1590/4545 [1:43:03<3:05:18,  3.76s/it] 35%|███▌      | 1591/4545 [1:43:07<3:07:16,  3.80s/it] 35%|███▌      | 1592/4545 [1:43:10<2:58:45,  3.63s/it] 35%|███▌      | 1593/4545 [1:43:14<3:02:48,  3.72s/it] 35%|███▌      | 1594/4545 [1:43:17<2:51:42,  3.49s/it] 35%|███▌      | 1595/4545 [1:43:19<2:41:20,  3.28s/it] 35%|███▌      | 1596/4545 [1:43:23<2:50:49,  3.48s/it] 35%|███▌      | 1597/4545 [1:43:27<2:52:02,  3.50s/it] 35%|███▌      | 1598/4545 [1:43:31<2:57:50,  3.62s/it] 35%|███▌      | 1599/4545 [1:43:35<3:05:44,  3.78s/it] 35%|███▌      | 1600/4545 [1:43:39<3:12:08,  3.91s/it]                                                       {'loss': 0.4736, 'grad_norm': 15.237957000732422, 'learning_rate': 9.982547111546467e-08, 'rewards/chosen': 0.9585937261581421, 'rewards/rejected': -0.22304686903953552, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.1828124523162842, 'logps/chosen': -231.60000610351562, 'logps/rejected': -145.35000610351562, 'logits/chosen': -6.818749904632568, 'logits/rejected': -6.534375190734863, 'epoch': 1.06}
 35%|███▌      | 1600/4545 [1:43:39<3:12:08,  3.91s/it] 35%|███▌      | 1601/4545 [1:43:43<3:07:56,  3.83s/it] 35%|███▌      | 1602/4545 [1:43:47<3:09:01,  3.85s/it] 35%|███▌      | 1603/4545 [1:43:51<3:12:30,  3.93s/it] 35%|███▌      | 1604/4545 [1:43:55<3:16:32,  4.01s/it] 35%|███▌      | 1605/4545 [1:43:58<3:05:45,  3.79s/it] 35%|███▌      | 1606/4545 [1:44:02<3:07:39,  3.83s/it] 35%|███▌      | 1607/4545 [1:44:06<3:08:49,  3.86s/it] 35%|███▌      | 1608/4545 [1:44:10<3:09:22,  3.87s/it] 35%|███▌      | 1609/4545 [1:44:13<2:53:32,  3.55s/it] 35%|███▌      | 1610/4545 [1:44:16<2:51:17,  3.50s/it]                                                       {'loss': 0.4709, 'grad_norm': 23.7676944732666, 'learning_rate': 9.978202500458325e-08, 'rewards/chosen': 1.5076172351837158, 'rewards/rejected': -0.06684570014476776, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.5750000476837158, 'logps/chosen': -364.375, 'logps/rejected': -165.125, 'logits/chosen': -6.349999904632568, 'logits/rejected': -6.425000190734863, 'epoch': 1.06}
 35%|███▌      | 1610/4545 [1:44:16<2:51:17,  3.50s/it] 35%|███▌      | 1611/4545 [1:44:20<2:57:56,  3.64s/it] 35%|███▌      | 1612/4545 [1:44:24<3:04:45,  3.78s/it] 35%|███▌      | 1613/4545 [1:44:28<3:01:21,  3.71s/it] 36%|███▌      | 1614/4545 [1:44:32<3:04:25,  3.78s/it] 36%|███▌      | 1615/4545 [1:44:36<3:06:19,  3.82s/it] 36%|███▌      | 1616/4545 [1:44:38<2:49:07,  3.46s/it] 36%|███▌      | 1617/4545 [1:44:42<2:54:59,  3.59s/it] 36%|███▌      | 1618/4545 [1:44:46<3:01:43,  3.73s/it] 36%|███▌      | 1619/4545 [1:44:50<3:01:07,  3.71s/it] 36%|███▌      | 1620/4545 [1:44:53<2:58:34,  3.66s/it]                                                       {'loss': 0.4131, 'grad_norm': 24.600996017456055, 'learning_rate': 9.973376797838135e-08, 'rewards/chosen': 1.516992211341858, 'rewards/rejected': 0.02525634691119194, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 1.490625023841858, 'logps/chosen': -387.04998779296875, 'logps/rejected': -224.6750030517578, 'logits/chosen': -6.356249809265137, 'logits/rejected': -6.506249904632568, 'epoch': 1.07}
 36%|███▌      | 1620/4545 [1:44:53<2:58:34,  3.66s/it] 36%|███▌      | 1621/4545 [1:44:58<3:06:00,  3.82s/it] 36%|███▌      | 1622/4545 [1:45:02<3:07:26,  3.85s/it] 36%|███▌      | 1623/4545 [1:45:05<3:03:51,  3.78s/it] 36%|███▌      | 1624/4545 [1:45:09<3:09:40,  3.90s/it] 36%|███▌      | 1625/4545 [1:45:13<3:11:03,  3.93s/it] 36%|███▌      | 1626/4545 [1:45:17<3:10:25,  3.91s/it] 36%|███▌      | 1627/4545 [1:45:21<3:04:44,  3.80s/it] 36%|███▌      | 1628/4545 [1:45:23<2:41:48,  3.33s/it] 36%|███▌      | 1629/4545 [1:45:27<2:49:33,  3.49s/it] 36%|███▌      | 1630/4545 [1:45:30<2:51:23,  3.53s/it]                                                       {'loss': 0.4746, 'grad_norm': 15.059452056884766, 'learning_rate': 9.968070522109233e-08, 'rewards/chosen': 0.8653320074081421, 'rewards/rejected': -0.26611328125, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.1306641101837158, 'logps/chosen': -236.1999969482422, 'logps/rejected': -102.80000305175781, 'logits/chosen': -6.621874809265137, 'logits/rejected': -6.743750095367432, 'epoch': 1.08}
 36%|███▌      | 1630/4545 [1:45:30<2:51:23,  3.53s/it] 36%|███▌      | 1631/4545 [1:45:34<2:46:18,  3.42s/it] 36%|███▌      | 1632/4545 [1:45:37<2:48:41,  3.47s/it] 36%|███▌      | 1633/4545 [1:45:41<2:52:43,  3.56s/it] 36%|███▌      | 1634/4545 [1:45:45<2:57:50,  3.67s/it] 36%|███▌      | 1635/4545 [1:45:49<3:01:19,  3.74s/it] 36%|███▌      | 1636/4545 [1:45:53<3:03:43,  3.79s/it] 36%|███▌      | 1637/4545 [1:45:57<3:08:54,  3.90s/it] 36%|███▌      | 1638/4545 [1:46:01<3:09:21,  3.91s/it] 36%|███▌      | 1639/4545 [1:46:04<3:04:52,  3.82s/it] 36%|███▌      | 1640/4545 [1:46:07<2:49:31,  3.50s/it]                                                       {'loss': 0.4464, 'grad_norm': 15.808417320251465, 'learning_rate': 9.96228424332273e-08, 'rewards/chosen': 1.004296898841858, 'rewards/rejected': -0.16787108778953552, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.1728515625, 'logps/chosen': -242.8000030517578, 'logps/rejected': -143.89999389648438, 'logits/chosen': -6.528124809265137, 'logits/rejected': -6.559374809265137, 'epoch': 1.08}
 36%|███▌      | 1640/4545 [1:46:07<2:49:31,  3.50s/it] 36%|███▌      | 1641/4545 [1:46:10<2:42:23,  3.36s/it] 36%|███▌      | 1642/4545 [1:46:14<2:52:16,  3.56s/it] 36%|███▌      | 1643/4545 [1:46:17<2:42:14,  3.35s/it] 36%|███▌      | 1644/4545 [1:46:21<2:50:03,  3.52s/it] 36%|███▌      | 1645/4545 [1:46:25<2:52:32,  3.57s/it] 36%|███▌      | 1646/4545 [1:46:29<3:01:21,  3.75s/it] 36%|███▌      | 1647/4545 [1:46:33<3:01:27,  3.76s/it] 36%|███▋      | 1648/4545 [1:46:35<2:45:21,  3.42s/it] 36%|███▋      | 1649/4545 [1:46:39<2:48:47,  3.50s/it] 36%|███▋      | 1650/4545 [1:46:41<2:28:06,  3.07s/it]                                                       {'loss': 0.513, 'grad_norm': 12.360222816467285, 'learning_rate': 9.956018583096278e-08, 'rewards/chosen': 0.66845703125, 'rewards/rejected': -0.18239745497703552, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.850781261920929, 'logps/chosen': -169.72500610351562, 'logps/rejected': -105.17500305175781, 'logits/chosen': -6.724999904632568, 'logits/rejected': -6.381249904632568, 'epoch': 1.09}
 36%|███▋      | 1650/4545 [1:46:41<2:28:06,  3.07s/it] 36%|███▋      | 1651/4545 [1:46:45<2:41:32,  3.35s/it] 36%|███▋      | 1652/4545 [1:46:49<2:51:57,  3.57s/it] 36%|███▋      | 1653/4545 [1:46:53<2:56:48,  3.67s/it] 36%|███▋      | 1654/4545 [1:46:57<2:54:11,  3.62s/it] 36%|███▋      | 1655/4545 [1:47:00<2:58:20,  3.70s/it] 36%|███▋      | 1656/4545 [1:47:04<2:55:21,  3.64s/it] 36%|███▋      | 1657/4545 [1:47:08<2:59:04,  3.72s/it] 36%|███▋      | 1658/4545 [1:47:12<3:01:34,  3.77s/it] 37%|███▋      | 1659/4545 [1:47:15<2:50:24,  3.54s/it] 37%|███▋      | 1660/4545 [1:47:19<2:57:44,  3.70s/it]                                                       {'loss': 0.4552, 'grad_norm': 22.24663543701172, 'learning_rate': 9.949274214547291e-08, 'rewards/chosen': 1.390039086341858, 'rewards/rejected': -0.07001952826976776, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.4597656726837158, 'logps/chosen': -323.04998779296875, 'logps/rejected': -149.9499969482422, 'logits/chosen': -6.675000190734863, 'logits/rejected': -6.628125190734863, 'epoch': 1.1}
 37%|███▋      | 1660/4545 [1:47:19<2:57:44,  3.70s/it] 37%|███▋      | 1661/4545 [1:47:23<3:03:20,  3.81s/it] 37%|███▋      | 1662/4545 [1:47:27<3:04:35,  3.84s/it] 37%|███▋      | 1663/4545 [1:47:30<2:57:52,  3.70s/it] 37%|███▋      | 1664/4545 [1:47:34<3:00:48,  3.77s/it] 37%|███▋      | 1665/4545 [1:47:37<2:50:08,  3.54s/it] 37%|███▋      | 1666/4545 [1:47:41<2:55:49,  3.66s/it] 37%|███▋      | 1667/4545 [1:47:45<2:55:02,  3.65s/it] 37%|███▋      | 1668/4545 [1:47:48<2:53:02,  3.61s/it] 37%|███▋      | 1669/4545 [1:47:52<3:01:12,  3.78s/it] 37%|███▋      | 1670/4545 [1:47:56<3:03:10,  3.82s/it]                                                       {'loss': 0.4231, 'grad_norm': 12.629303932189941, 'learning_rate': 9.942051862220628e-08, 'rewards/chosen': 1.05322265625, 'rewards/rejected': -0.2501220703125, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.304296851158142, 'logps/chosen': -259.5, 'logps/rejected': -143.875, 'logits/chosen': -6.668749809265137, 'logits/rejected': -6.615624904632568, 'epoch': 1.1}
 37%|███▋      | 1670/4545 [1:47:56<3:03:10,  3.82s/it] 37%|███▋      | 1671/4545 [1:48:00<3:04:43,  3.86s/it] 37%|███▋      | 1672/4545 [1:48:04<3:05:35,  3.88s/it] 37%|███▋      | 1673/4545 [1:48:08<3:09:58,  3.97s/it] 37%|███▋      | 1674/4545 [1:48:12<3:01:00,  3.78s/it] 37%|███▋      | 1675/4545 [1:48:16<3:02:56,  3.82s/it] 37%|███▋      | 1676/4545 [1:48:19<2:51:16,  3.58s/it] 37%|███▋      | 1677/4545 [1:48:22<2:53:10,  3.62s/it] 37%|███▋      | 1678/4545 [1:48:26<2:57:33,  3.72s/it] 37%|███▋      | 1679/4545 [1:48:30<3:00:46,  3.78s/it] 37%|███▋      | 1680/4545 [1:48:34<2:56:38,  3.70s/it]                                                       {'loss': 0.436, 'grad_norm': 14.93587589263916, 'learning_rate': 9.934352302010754e-08, 'rewards/chosen': 1.2410156726837158, 'rewards/rejected': -0.28980714082717896, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.530859351158142, 'logps/chosen': -314.6000061035156, 'logps/rejected': -122.5, 'logits/chosen': -6.578125, 'logits/rejected': -6.806250095367432, 'epoch': 1.11}
 37%|███▋      | 1680/4545 [1:48:34<2:56:38,  3.70s/it] 37%|███▋      | 1681/4545 [1:48:37<2:55:36,  3.68s/it] 37%|███▋      | 1682/4545 [1:48:40<2:42:19,  3.40s/it] 37%|███▋      | 1683/4545 [1:48:43<2:38:37,  3.33s/it] 37%|███▋      | 1684/4545 [1:48:46<2:35:32,  3.26s/it] 37%|███▋      | 1685/4545 [1:48:50<2:44:56,  3.46s/it] 37%|███▋      | 1686/4545 [1:48:54<2:51:37,  3.60s/it] 37%|███▋      | 1687/4545 [1:48:58<2:56:15,  3.70s/it] 37%|███▋      | 1688/4545 [1:49:02<2:59:11,  3.76s/it] 37%|███▋      | 1689/4545 [1:49:06<3:00:59,  3.80s/it] 37%|███▋      | 1690/4545 [1:49:10<3:02:30,  3.84s/it]                                                       {'loss': 0.4511, 'grad_norm': 25.740806579589844, 'learning_rate': 9.926176361078394e-08, 'rewards/chosen': 1.161523461341858, 'rewards/rejected': -0.11762695014476776, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.280859351158142, 'logps/chosen': -277.95001220703125, 'logps/rejected': -153.39999389648438, 'logits/chosen': -6.559374809265137, 'logits/rejected': -6.78125, 'epoch': 1.12}
 37%|███▋      | 1690/4545 [1:49:10<3:02:30,  3.84s/it] 37%|███▋      | 1691/4545 [1:49:14<3:03:39,  3.86s/it] 37%|███▋      | 1692/4545 [1:49:18<3:04:20,  3.88s/it] 37%|███▋      | 1693/4545 [1:49:22<3:05:05,  3.89s/it] 37%|███▋      | 1694/4545 [1:49:25<2:56:55,  3.72s/it] 37%|███▋      | 1695/4545 [1:49:28<2:51:01,  3.60s/it] 37%|███▋      | 1696/4545 [1:49:32<2:55:14,  3.69s/it] 37%|███▋      | 1697/4545 [1:49:36<2:58:25,  3.76s/it] 37%|███▋      | 1698/4545 [1:49:40<3:00:15,  3.80s/it] 37%|███▋      | 1699/4545 [1:49:44<2:57:22,  3.74s/it] 37%|███▋      | 1700/4545 [1:49:48<3:03:38,  3.87s/it]                                                       {'loss': 0.4263, 'grad_norm': 14.100639343261719, 'learning_rate': 9.917524917761663e-08, 'rewards/chosen': 1.5369141101837158, 'rewards/rejected': -0.08154296875, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.6171875, 'logps/chosen': -350.0249938964844, 'logps/rejected': -179.5500030517578, 'logits/chosen': -6.415625095367432, 'logits/rejected': -6.59375, 'epoch': 1.12}
 37%|███▋      | 1700/4545 [1:49:48<3:03:38,  3.87s/it] 37%|███▋      | 1701/4545 [1:49:52<3:02:05,  3.84s/it] 37%|███▋      | 1702/4545 [1:49:54<2:48:31,  3.56s/it] 37%|███▋      | 1703/4545 [1:49:58<2:53:43,  3.67s/it] 37%|███▋      | 1704/4545 [1:50:02<2:57:17,  3.74s/it] 38%|███▊      | 1705/4545 [1:50:06<2:59:22,  3.79s/it] 38%|███▊      | 1706/4545 [1:50:10<3:01:00,  3.83s/it] 38%|███▊      | 1707/4545 [1:50:14<3:02:22,  3.86s/it] 38%|███▊      | 1708/4545 [1:50:18<3:05:06,  3.91s/it] 38%|███▊      | 1709/4545 [1:50:22<3:01:56,  3.85s/it] 38%|███▊      | 1710/4545 [1:50:26<3:04:57,  3.91s/it]                                                       {'loss': 0.4522, 'grad_norm': 15.46066665649414, 'learning_rate': 9.908398901481712e-08, 'rewards/chosen': 1.5807616710662842, 'rewards/rejected': 0.03271484375, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.548437476158142, 'logps/chosen': -373.6499938964844, 'logps/rejected': -222.0500030517578, 'logits/chosen': -6.521874904632568, 'logits/rejected': -6.5, 'epoch': 1.13}
 38%|███▊      | 1710/4545 [1:50:26<3:04:57,  3.91s/it] 38%|███▊      | 1711/4545 [1:50:28<2:46:39,  3.53s/it] 38%|███▊      | 1712/4545 [1:50:32<2:49:08,  3.58s/it] 38%|███▊      | 1713/4545 [1:50:36<2:57:29,  3.76s/it] 38%|███▊      | 1714/4545 [1:50:40<2:59:23,  3.80s/it] 38%|███▊      | 1715/4545 [1:50:44<3:04:41,  3.92s/it] 38%|███▊      | 1716/4545 [1:50:48<3:04:16,  3.91s/it] 38%|███▊      | 1717/4545 [1:50:52<2:58:02,  3.78s/it] 38%|███▊      | 1718/4545 [1:50:55<2:53:39,  3.69s/it] 38%|███▊      | 1719/4545 [1:50:58<2:45:48,  3.52s/it] 38%|███▊      | 1720/4545 [1:51:02<2:51:12,  3.64s/it]                                                       {'loss': 0.4168, 'grad_norm': 20.82891273498535, 'learning_rate': 9.898799292642878e-08, 'rewards/chosen': 1.0294921398162842, 'rewards/rejected': -0.36027830839157104, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.391015648841858, 'logps/chosen': -205.39999389648438, 'logps/rejected': -122.4000015258789, 'logits/chosen': -6.765625, 'logits/rejected': -6.696875095367432, 'epoch': 1.14}
 38%|███▊      | 1720/4545 [1:51:02<2:51:12,  3.64s/it] 38%|███▊      | 1721/4545 [1:51:06<2:58:47,  3.80s/it] 38%|███▊      | 1722/4545 [1:51:10<3:00:29,  3.84s/it] 38%|███▊      | 1723/4545 [1:51:14<3:01:35,  3.86s/it] 38%|███▊      | 1724/4545 [1:51:17<2:48:36,  3.59s/it] 38%|███▊      | 1725/4545 [1:51:21<2:52:00,  3.66s/it] 38%|███▊      | 1726/4545 [1:51:25<2:53:03,  3.68s/it] 38%|███▊      | 1727/4545 [1:51:28<2:46:29,  3.54s/it] 38%|███▊      | 1728/4545 [1:51:32<2:51:00,  3.64s/it] 38%|███▊      | 1729/4545 [1:51:36<2:54:45,  3.72s/it] 38%|███▊      | 1730/4545 [1:51:40<2:57:20,  3.78s/it]                                                       {'loss': 0.4891, 'grad_norm': 16.709129333496094, 'learning_rate': 9.888727122527362e-08, 'rewards/chosen': 1.649804711341858, 'rewards/rejected': -0.022369384765625, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 1.671484351158142, 'logps/chosen': -391.3500061035156, 'logps/rejected': -194.89999389648438, 'logits/chosen': -6.690625190734863, 'logits/rejected': -6.512499809265137, 'epoch': 1.14}
 38%|███▊      | 1730/4545 [1:51:40<2:57:20,  3.78s/it] 38%|███▊      | 1731/4545 [1:51:43<2:54:52,  3.73s/it] 38%|███▊      | 1732/4545 [1:51:47<2:56:21,  3.76s/it] 38%|███▊      | 1733/4545 [1:51:51<2:58:26,  3.81s/it] 38%|███▊      | 1734/4545 [1:51:55<2:59:32,  3.83s/it] 38%|███▊      | 1735/4545 [1:51:59<2:59:59,  3.84s/it] 38%|███▊      | 1736/4545 [1:52:03<3:04:40,  3.94s/it] 38%|███▊      | 1737/4545 [1:52:07<3:03:56,  3.93s/it] 38%|███▊      | 1738/4545 [1:52:10<2:58:17,  3.81s/it] 38%|███▊      | 1739/4545 [1:52:13<2:45:46,  3.54s/it] 38%|███▊      | 1740/4545 [1:52:17<2:50:19,  3.64s/it]                                                       {'loss': 0.438, 'grad_norm': 16.31500816345215, 'learning_rate': 9.878183473184433e-08, 'rewards/chosen': 1.2048828601837158, 'rewards/rejected': -0.15048828721046448, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.3562500476837158, 'logps/chosen': -284.6000061035156, 'logps/rejected': -183.60000610351562, 'logits/chosen': -6.696875095367432, 'logits/rejected': -6.71875, 'epoch': 1.15}
 38%|███▊      | 1740/4545 [1:52:17<2:50:19,  3.64s/it] 38%|███▊      | 1741/4545 [1:52:21<2:58:04,  3.81s/it] 38%|███▊      | 1742/4545 [1:52:24<2:39:07,  3.41s/it] 38%|███▊      | 1743/4545 [1:52:27<2:37:05,  3.36s/it] 38%|███▊      | 1744/4545 [1:52:30<2:25:59,  3.13s/it] 38%|███▊      | 1745/4545 [1:52:34<2:38:00,  3.39s/it] 38%|███▊      | 1746/4545 [1:52:37<2:42:32,  3.48s/it] 38%|███▊      | 1747/4545 [1:52:41<2:48:19,  3.61s/it] 38%|███▊      | 1748/4545 [1:52:45<2:52:26,  3.70s/it] 38%|███▊      | 1749/4545 [1:52:49<2:47:16,  3.59s/it] 39%|███▊      | 1750/4545 [1:52:52<2:41:39,  3.47s/it]                                                       {'loss': 0.4192, 'grad_norm': 20.283918380737305, 'learning_rate': 9.86716947731419e-08, 'rewards/chosen': 0.9173828363418579, 'rewards/rejected': -0.345458984375, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.263281226158142, 'logps/chosen': -210.6999969482422, 'logps/rejected': -158.1999969482422, 'logits/chosen': -6.865624904632568, 'logits/rejected': -6.78125, 'epoch': 1.16}
 39%|███▊      | 1750/4545 [1:52:52<2:41:39,  3.47s/it] 39%|███▊      | 1751/4545 [1:52:55<2:34:55,  3.33s/it] 39%|███▊      | 1752/4545 [1:52:59<2:44:27,  3.53s/it] 39%|███▊      | 1753/4545 [1:53:03<2:49:44,  3.65s/it] 39%|███▊      | 1754/4545 [1:53:07<2:52:11,  3.70s/it] 39%|███▊      | 1755/4545 [1:53:11<2:58:33,  3.84s/it] 39%|███▊      | 1756/4545 [1:53:15<2:59:30,  3.86s/it] 39%|███▊      | 1757/4545 [1:53:18<2:54:53,  3.76s/it] 39%|███▊      | 1758/4545 [1:53:21<2:40:26,  3.45s/it] 39%|███▊      | 1759/4545 [1:53:24<2:40:08,  3.45s/it] 39%|███▊      | 1760/4545 [1:53:27<2:36:04,  3.36s/it]                                                       {'loss': 0.4041, 'grad_norm': 10.027313232421875, 'learning_rate': 9.855686318145876e-08, 'rewards/chosen': 0.8013671636581421, 'rewards/rejected': -0.484375, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.284765601158142, 'logps/chosen': -187.5, 'logps/rejected': -97.44999694824219, 'logits/chosen': -6.775000095367432, 'logits/rejected': -6.706250190734863, 'epoch': 1.16}
 39%|███▊      | 1760/4545 [1:53:27<2:36:04,  3.36s/it] 39%|███▊      | 1761/4545 [1:53:31<2:41:50,  3.49s/it] 39%|███▉      | 1762/4545 [1:53:35<2:51:57,  3.71s/it] 39%|███▉      | 1763/4545 [1:53:39<2:55:36,  3.79s/it] 39%|███▉      | 1764/4545 [1:53:43<2:57:18,  3.83s/it] 39%|███▉      | 1765/4545 [1:53:47<2:49:49,  3.67s/it] 39%|███▉      | 1766/4545 [1:53:51<2:53:09,  3.74s/it] 39%|███▉      | 1767/4545 [1:53:54<2:48:16,  3.63s/it] 39%|███▉      | 1768/4545 [1:53:58<2:52:02,  3.72s/it] 39%|███▉      | 1769/4545 [1:54:02<2:54:44,  3.78s/it] 39%|███▉      | 1770/4545 [1:54:05<2:47:16,  3.62s/it]                                                       {'loss': 0.4106, 'grad_norm': 16.52292251586914, 'learning_rate': 9.843735229310759e-08, 'rewards/chosen': 1.20263671875, 'rewards/rejected': -0.20302733778953552, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.405371069908142, 'logps/chosen': -278.1499938964844, 'logps/rejected': -160.6750030517578, 'logits/chosen': -6.762499809265137, 'logits/rejected': -6.790625095367432, 'epoch': 1.17}
 39%|███▉      | 1770/4545 [1:54:05<2:47:16,  3.62s/it] 39%|███▉      | 1771/4545 [1:54:09<2:51:15,  3.70s/it] 39%|███▉      | 1772/4545 [1:54:13<2:49:12,  3.66s/it] 39%|███▉      | 1773/4545 [1:54:17<2:55:40,  3.80s/it] 39%|███▉      | 1774/4545 [1:54:21<2:57:39,  3.85s/it] 39%|███▉      | 1775/4545 [1:54:25<3:02:58,  3.96s/it] 39%|███▉      | 1776/4545 [1:54:29<3:02:04,  3.95s/it] 39%|███▉      | 1777/4545 [1:54:32<2:51:49,  3.72s/it] 39%|███▉      | 1778/4545 [1:54:36<2:58:52,  3.88s/it] 39%|███▉      | 1779/4545 [1:54:39<2:46:40,  3.62s/it] 39%|███▉      | 1780/4545 [1:54:43<2:50:46,  3.71s/it]                                                       {'loss': 0.3735, 'grad_norm': 15.673609733581543, 'learning_rate': 9.83131749470961e-08, 'rewards/chosen': 1.0519530773162842, 'rewards/rejected': -0.4021972715854645, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 1.4539062976837158, 'logps/chosen': -242.75, 'logps/rejected': -141.0749969482422, 'logits/chosen': -6.768750190734863, 'logits/rejected': -6.84375, 'epoch': 1.17}
 39%|███▉      | 1780/4545 [1:54:43<2:50:46,  3.71s/it] 39%|███▉      | 1781/4545 [1:54:47<2:53:40,  3.77s/it] 39%|███▉      | 1782/4545 [1:54:51<2:55:30,  3.81s/it] 39%|███▉      | 1783/4545 [1:54:55<2:56:49,  3.84s/it] 39%|███▉      | 1784/4545 [1:54:59<2:57:38,  3.86s/it] 39%|███▉      | 1785/4545 [1:55:03<3:00:34,  3.93s/it] 39%|███▉      | 1786/4545 [1:55:07<3:00:12,  3.92s/it] 39%|███▉      | 1787/4545 [1:55:10<2:48:36,  3.67s/it] 39%|███▉      | 1788/4545 [1:55:14<2:56:25,  3.84s/it] 39%|███▉      | 1789/4545 [1:55:18<2:57:41,  3.87s/it] 39%|███▉      | 1790/4545 [1:55:22<3:01:40,  3.96s/it]                                                       {'loss': 0.4278, 'grad_norm': 16.071090698242188, 'learning_rate': 9.81843444837477e-08, 'rewards/chosen': 1.7626953125, 'rewards/rejected': -0.15996094048023224, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.922265648841858, 'logps/chosen': -363.1499938964844, 'logps/rejected': -183.75, 'logits/chosen': -6.703125, 'logits/rejected': -6.671875, 'epoch': 1.18}
 39%|███▉      | 1790/4545 [1:55:22<3:01:40,  3.96s/it] 39%|███▉      | 1791/4545 [1:55:26<3:03:35,  4.00s/it] 39%|███▉      | 1792/4545 [1:55:30<3:02:10,  3.97s/it] 39%|███▉      | 1793/4545 [1:55:34<3:04:48,  4.03s/it] 39%|███▉      | 1794/4545 [1:55:38<3:03:07,  3.99s/it] 39%|███▉      | 1795/4545 [1:55:42<3:00:50,  3.95s/it] 40%|███▉      | 1796/4545 [1:55:46<3:04:00,  4.02s/it] 40%|███▉      | 1797/4545 [1:55:50<3:02:25,  3.98s/it] 40%|███▉      | 1798/4545 [1:55:54<3:01:26,  3.96s/it] 40%|███▉      | 1799/4545 [1:55:58<3:00:41,  3.95s/it] 40%|███▉      | 1800/4545 [1:56:02<2:55:11,  3.83s/it]                                                       {'loss': 0.4267, 'grad_norm': 26.9536190032959, 'learning_rate': 9.805087474326836e-08, 'rewards/chosen': 1.151953101158142, 'rewards/rejected': -0.20097656548023224, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.3523437976837158, 'logps/chosen': -293.5, 'logps/rejected': -158.14999389648438, 'logits/chosen': -6.71875, 'logits/rejected': -6.496874809265137, 'epoch': 1.19}
 40%|███▉      | 1800/4545 [1:56:02<2:55:11,  3.83s/it] 40%|███▉      | 1801/4545 [1:56:05<2:56:10,  3.85s/it] 40%|███▉      | 1802/4545 [1:56:09<2:56:49,  3.87s/it] 40%|███▉      | 1803/4545 [1:56:13<2:59:46,  3.93s/it] 40%|███▉      | 1804/4545 [1:56:17<2:55:20,  3.84s/it] 40%|███▉      | 1805/4545 [1:56:21<2:58:19,  3.91s/it] 40%|███▉      | 1806/4545 [1:56:25<2:55:07,  3.84s/it] 40%|███▉      | 1807/4545 [1:56:28<2:47:19,  3.67s/it] 40%|███▉      | 1808/4545 [1:56:31<2:37:34,  3.45s/it] 40%|███▉      | 1809/4545 [1:56:35<2:46:08,  3.64s/it] 40%|███▉      | 1810/4545 [1:56:38<2:40:52,  3.53s/it]                                                       {'loss': 0.4369, 'grad_norm': 22.9226131439209, 'learning_rate': 9.791278006425974e-08, 'rewards/chosen': 0.966796875, 'rewards/rejected': -0.4209960997104645, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.387304663658142, 'logps/chosen': -212.85000610351562, 'logps/rejected': -118.875, 'logits/chosen': -6.837500095367432, 'logits/rejected': -6.806250095367432, 'epoch': 1.19}
 40%|███▉      | 1810/4545 [1:56:38<2:40:52,  3.53s/it] 40%|███▉      | 1811/4545 [1:56:42<2:46:03,  3.64s/it] 40%|███▉      | 1812/4545 [1:56:46<2:49:23,  3.72s/it] 40%|███▉      | 1813/4545 [1:56:50<2:52:11,  3.78s/it] 40%|███▉      | 1814/4545 [1:56:54<2:53:57,  3.82s/it] 40%|███▉      | 1815/4545 [1:56:58<2:55:16,  3.85s/it] 40%|███▉      | 1816/4545 [1:57:02<2:55:52,  3.87s/it] 40%|███▉      | 1817/4545 [1:57:06<2:59:05,  3.94s/it] 40%|████      | 1818/4545 [1:57:10<2:55:34,  3.86s/it] 40%|████      | 1819/4545 [1:57:14<3:00:23,  3.97s/it] 40%|████      | 1820/4545 [1:57:18<2:59:23,  3.95s/it]                                                       {'loss': 0.3849, 'grad_norm': 26.817745208740234, 'learning_rate': 9.777007528217889e-08, 'rewards/chosen': 2.044921875, 'rewards/rejected': -0.13020019233226776, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.1773438453674316, 'logps/chosen': -446.0, 'logps/rejected': -232.375, 'logits/chosen': -6.574999809265137, 'logits/rejected': -6.612500190734863, 'epoch': 1.2}
 40%|████      | 1820/4545 [1:57:18<2:59:23,  3.95s/it] 40%|████      | 1821/4545 [1:57:22<2:59:12,  3.95s/it] 40%|████      | 1822/4545 [1:57:26<2:59:32,  3.96s/it] 40%|████      | 1823/4545 [1:57:30<2:58:45,  3.94s/it] 40%|████      | 1824/4545 [1:57:33<2:47:45,  3.70s/it] 40%|████      | 1825/4545 [1:57:37<2:50:45,  3.77s/it] 40%|████      | 1826/4545 [1:57:39<2:37:30,  3.48s/it] 40%|████      | 1827/4545 [1:57:44<2:47:25,  3.70s/it] 40%|████      | 1828/4545 [1:57:48<2:54:45,  3.86s/it] 40%|████      | 1829/4545 [1:57:51<2:47:39,  3.70s/it] 40%|████      | 1830/4545 [1:57:54<2:31:05,  3.34s/it]                                                       {'loss': 0.4225, 'grad_norm': 11.599515914916992, 'learning_rate': 9.762277572774435e-08, 'rewards/chosen': 1.258203148841858, 'rewards/rejected': -0.17226561903953552, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.4304687976837158, 'logps/chosen': -269.1499938964844, 'logps/rejected': -169.3249969482422, 'logits/chosen': -6.671875, 'logits/rejected': -6.743750095367432, 'epoch': 1.21}
 40%|████      | 1830/4545 [1:57:54<2:31:05,  3.34s/it] 40%|████      | 1831/4545 [1:57:58<2:39:16,  3.52s/it] 40%|████      | 1832/4545 [1:58:02<2:49:02,  3.74s/it] 40%|████      | 1833/4545 [1:58:06<2:49:53,  3.76s/it] 40%|████      | 1834/4545 [1:58:09<2:50:00,  3.76s/it] 40%|████      | 1835/4545 [1:58:13<2:41:21,  3.57s/it] 40%|████      | 1836/4545 [1:58:16<2:45:40,  3.67s/it] 40%|████      | 1837/4545 [1:58:21<2:51:27,  3.80s/it] 40%|████      | 1838/4545 [1:58:24<2:47:12,  3.71s/it] 40%|████      | 1839/4545 [1:58:26<2:29:08,  3.31s/it] 40%|████      | 1840/4545 [1:58:31<2:40:46,  3.57s/it]                                                       {'loss': 0.4421, 'grad_norm': 25.31974220275879, 'learning_rate': 9.74708972252893e-08, 'rewards/chosen': 0.911328136920929, 'rewards/rejected': -0.41856688261032104, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.3289062976837158, 'logps/chosen': -217.60000610351562, 'logps/rejected': -129.1999969482422, 'logits/chosen': -6.881249904632568, 'logits/rejected': -6.787499904632568, 'epoch': 1.21}
 40%|████      | 1840/4545 [1:58:31<2:40:46,  3.57s/it] 41%|████      | 1841/4545 [1:58:35<2:48:07,  3.73s/it] 41%|████      | 1842/4545 [1:58:39<2:50:39,  3.79s/it] 41%|████      | 1843/4545 [1:58:43<2:52:12,  3.82s/it] 41%|████      | 1844/4545 [1:58:45<2:38:56,  3.53s/it] 41%|████      | 1845/4545 [1:58:49<2:40:54,  3.58s/it] 41%|████      | 1846/4545 [1:58:52<2:28:00,  3.29s/it] 41%|████      | 1847/4545 [1:58:56<2:37:56,  3.51s/it] 41%|████      | 1848/4545 [1:59:00<2:43:17,  3.63s/it] 41%|████      | 1849/4545 [1:59:04<2:46:49,  3.71s/it] 41%|████      | 1850/4545 [1:59:07<2:49:05,  3.76s/it]                                                       {'loss': 0.4025, 'grad_norm': 21.43474769592285, 'learning_rate': 9.731445609106147e-08, 'rewards/chosen': 1.468652367591858, 'rewards/rejected': -0.3074951171875, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.7726562023162842, 'logps/chosen': -318.8999938964844, 'logps/rejected': -179.35000610351562, 'logits/chosen': -6.862500190734863, 'logits/rejected': -6.824999809265137, 'epoch': 1.22}
 41%|████      | 1850/4545 [1:59:07<2:49:05,  3.76s/it] 41%|████      | 1851/4545 [1:59:11<2:50:59,  3.81s/it] 41%|████      | 1852/4545 [1:59:15<2:48:37,  3.76s/it] 41%|████      | 1853/4545 [1:59:19<2:50:35,  3.80s/it] 41%|████      | 1854/4545 [1:59:23<2:52:00,  3.84s/it] 41%|████      | 1855/4545 [1:59:27<2:52:54,  3.86s/it] 41%|████      | 1856/4545 [1:59:31<2:53:33,  3.87s/it] 41%|████      | 1857/4545 [1:59:35<2:53:24,  3.87s/it] 41%|████      | 1858/4545 [1:59:39<2:55:18,  3.91s/it] 41%|████      | 1859/4545 [1:59:41<2:41:28,  3.61s/it] 41%|████      | 1860/4545 [1:59:45<2:45:36,  3.70s/it]                                                       {'loss': 0.3941, 'grad_norm': 20.400846481323242, 'learning_rate': 9.715346913147034e-08, 'rewards/chosen': 1.822509765625, 'rewards/rejected': -0.20327147841453552, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.0269532203674316, 'logps/chosen': -399.54998779296875, 'logps/rejected': -233.8000030517578, 'logits/chosen': -6.537499904632568, 'logits/rejected': -6.665625095367432, 'epoch': 1.23}
 41%|████      | 1860/4545 [1:59:45<2:45:36,  3.70s/it] 41%|████      | 1861/4545 [1:59:49<2:47:50,  3.75s/it] 41%|████      | 1862/4545 [1:59:53<2:49:22,  3.79s/it] 41%|████      | 1863/4545 [1:59:57<2:46:35,  3.73s/it] 41%|████      | 1864/4545 [2:00:01<2:48:50,  3.78s/it] 41%|████      | 1865/4545 [2:00:05<2:54:44,  3.91s/it] 41%|████      | 1866/4545 [2:00:09<2:54:35,  3.91s/it] 41%|████      | 1867/4545 [2:00:12<2:45:12,  3.70s/it] 41%|████      | 1868/4545 [2:00:16<2:48:20,  3.77s/it] 41%|████      | 1869/4545 [2:00:20<2:50:07,  3.81s/it] 41%|████      | 1870/4545 [2:00:24<2:51:17,  3.84s/it]                                                       {'loss': 0.4214, 'grad_norm': 16.974931716918945, 'learning_rate': 9.698795364128163e-08, 'rewards/chosen': 1.8505859375, 'rewards/rejected': -0.13833007216453552, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.9871094226837158, 'logps/chosen': -383.6000061035156, 'logps/rejected': -207.89999389648438, 'logits/chosen': -6.618750095367432, 'logits/rejected': -6.678124904632568, 'epoch': 1.23}
 41%|████      | 1870/4545 [2:00:24<2:51:17,  3.84s/it] 41%|████      | 1871/4545 [2:00:27<2:50:55,  3.84s/it] 41%|████      | 1872/4545 [2:00:31<2:47:58,  3.77s/it] 41%|████      | 1873/4545 [2:00:33<2:28:34,  3.34s/it] 41%|████      | 1874/4545 [2:00:37<2:37:35,  3.54s/it] 41%|████▏     | 1875/4545 [2:00:41<2:40:10,  3.60s/it] 41%|████▏     | 1876/4545 [2:00:44<2:28:25,  3.34s/it] 41%|████▏     | 1877/4545 [2:00:48<2:35:52,  3.51s/it] 41%|████▏     | 1878/4545 [2:00:52<2:41:05,  3.62s/it] 41%|████▏     | 1879/4545 [2:00:55<2:41:06,  3.63s/it] 41%|████▏     | 1880/4545 [2:00:59<2:44:45,  3.71s/it]                                                       {'loss': 0.3745, 'grad_norm': 10.657448768615723, 'learning_rate': 9.681792740175927e-08, 'rewards/chosen': 0.9781249761581421, 'rewards/rejected': -0.6435546875, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 1.6222655773162842, 'logps/chosen': -217.0500030517578, 'logps/rejected': -84.9000015258789, 'logits/chosen': -6.96875, 'logits/rejected': -6.971875190734863, 'epoch': 1.24}
 41%|████▏     | 1880/4545 [2:00:59<2:44:45,  3.71s/it] 41%|████▏     | 1881/4545 [2:01:02<2:36:28,  3.52s/it] 41%|████▏     | 1882/4545 [2:01:06<2:43:50,  3.69s/it] 41%|████▏     | 1883/4545 [2:01:10<2:39:18,  3.59s/it] 41%|████▏     | 1884/4545 [2:01:14<2:43:40,  3.69s/it] 41%|████▏     | 1885/4545 [2:01:18<2:48:37,  3.80s/it] 41%|████▏     | 1886/4545 [2:01:22<2:50:00,  3.84s/it] 42%|████▏     | 1887/4545 [2:01:26<2:50:49,  3.86s/it] 42%|████▏     | 1888/4545 [2:01:29<2:45:40,  3.74s/it] 42%|████▏     | 1889/4545 [2:01:33<2:44:45,  3.72s/it] 42%|████▏     | 1890/4545 [2:01:36<2:32:58,  3.46s/it]                                                       {'loss': 0.4614, 'grad_norm': 24.254058837890625, 'learning_rate': 9.66434086787553e-08, 'rewards/chosen': 1.021386742591858, 'rewards/rejected': -0.31767576932907104, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.3380858898162842, 'logps/chosen': -232.25, 'logps/rejected': -177.35000610351562, 'logits/chosen': -6.940625190734863, 'logits/rejected': -6.8125, 'epoch': 1.25}
 42%|████▏     | 1890/4545 [2:01:36<2:32:58,  3.46s/it] 42%|████▏     | 1891/4545 [2:01:40<2:41:27,  3.65s/it] 42%|████▏     | 1892/4545 [2:01:44<2:45:01,  3.73s/it] 42%|████▏     | 1893/4545 [2:01:47<2:47:18,  3.79s/it] 42%|████▏     | 1894/4545 [2:01:51<2:43:05,  3.69s/it] 42%|████▏     | 1895/4545 [2:01:54<2:38:43,  3.59s/it] 42%|████▏     | 1896/4545 [2:01:58<2:45:11,  3.74s/it] 42%|████▏     | 1897/4545 [2:02:01<2:27:21,  3.34s/it] 42%|████▏     | 1898/4545 [2:02:05<2:34:42,  3.51s/it] 42%|████▏     | 1899/4545 [2:02:09<2:43:04,  3.70s/it] 42%|████▏     | 1900/4545 [2:02:13<2:45:42,  3.76s/it]                                                       {'loss': 0.3382, 'grad_norm': 12.468388557434082, 'learning_rate': 9.64644162207474e-08, 'rewards/chosen': 1.9358398914337158, 'rewards/rejected': -0.19179686903953552, 'rewards/accuracies': 0.90625, 'rewards/margins': 2.125, 'logps/chosen': -400.54998779296875, 'logps/rejected': -240.0, 'logits/chosen': -6.603125095367432, 'logits/rejected': -6.65625, 'epoch': 1.25}
 42%|████▏     | 1900/4545 [2:02:13<2:45:42,  3.76s/it] 42%|████▏     | 1901/4545 [2:02:17<2:49:14,  3.84s/it] 42%|████▏     | 1902/4545 [2:02:21<2:53:33,  3.94s/it] 42%|████▏     | 1903/4545 [2:02:25<2:55:53,  3.99s/it] 42%|████▏     | 1904/4545 [2:02:29<2:50:57,  3.88s/it] 42%|████▏     | 1905/4545 [2:02:33<2:53:31,  3.94s/it] 42%|████▏     | 1906/4545 [2:02:37<2:53:02,  3.93s/it] 42%|████▏     | 1907/4545 [2:02:40<2:47:31,  3.81s/it] 42%|████▏     | 1908/4545 [2:02:44<2:52:45,  3.93s/it] 42%|████▏     | 1909/4545 [2:02:48<2:52:14,  3.92s/it] 42%|████▏     | 1910/4545 [2:02:52<2:52:09,  3.92s/it]                                                       {'loss': 0.3821, 'grad_norm': 19.120014190673828, 'learning_rate': 9.628096925682491e-08, 'rewards/chosen': 1.4326171875, 'rewards/rejected': -0.5363830327987671, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.9718749523162842, 'logps/chosen': -324.20001220703125, 'logps/rejected': -164.8000030517578, 'logits/chosen': -6.925000190734863, 'logits/rejected': -6.728125095367432, 'epoch': 1.26}
 42%|████▏     | 1910/4545 [2:02:52<2:52:09,  3.92s/it] 42%|████▏     | 1911/4545 [2:02:56<2:52:09,  3.92s/it] 42%|████▏     | 1912/4545 [2:03:00<2:44:52,  3.76s/it] 42%|████▏     | 1913/4545 [2:03:03<2:46:41,  3.80s/it] 42%|████▏     | 1914/4545 [2:03:07<2:48:05,  3.83s/it] 42%|████▏     | 1915/4545 [2:03:11<2:48:56,  3.85s/it] 42%|████▏     | 1916/4545 [2:03:15<2:47:19,  3.82s/it] 42%|████▏     | 1917/4545 [2:03:19<2:48:23,  3.84s/it] 42%|████▏     | 1918/4545 [2:03:23<2:49:12,  3.86s/it] 42%|████▏     | 1919/4545 [2:03:26<2:39:27,  3.64s/it] 42%|████▏     | 1920/4545 [2:03:30<2:42:40,  3.72s/it]                                                       {'loss': 0.3772, 'grad_norm': 24.016632080078125, 'learning_rate': 9.609308749462294e-08, 'rewards/chosen': 1.4421875476837158, 'rewards/rejected': -0.3375000059604645, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.778906226158142, 'logps/chosen': -312.0, 'logps/rejected': -184.8000030517578, 'logits/chosen': -6.834374904632568, 'logits/rejected': -6.784375190734863, 'epoch': 1.27}
 42%|████▏     | 1920/4545 [2:03:30<2:42:40,  3.72s/it] 42%|████▏     | 1921/4545 [2:03:34<2:49:28,  3.88s/it] 42%|████▏     | 1922/4545 [2:03:38<2:47:52,  3.84s/it] 42%|████▏     | 1923/4545 [2:03:42<2:46:58,  3.82s/it] 42%|████▏     | 1924/4545 [2:03:46<2:51:37,  3.93s/it] 42%|████▏     | 1925/4545 [2:03:50<2:51:10,  3.92s/it] 42%|████▏     | 1926/4545 [2:03:53<2:48:58,  3.87s/it] 42%|████▏     | 1927/4545 [2:03:57<2:45:14,  3.79s/it] 42%|████▏     | 1928/4545 [2:04:00<2:39:13,  3.65s/it] 42%|████▏     | 1929/4545 [2:04:04<2:42:46,  3.73s/it] 42%|████▏     | 1930/4545 [2:04:07<2:33:44,  3.53s/it]                                                       {'loss': 0.4513, 'grad_norm': 14.722688674926758, 'learning_rate': 9.590079111820528e-08, 'rewards/chosen': 0.676562488079071, 'rewards/rejected': -0.6109374761581421, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.287109375, 'logps/chosen': -185.0500030517578, 'logps/rejected': -115.375, 'logits/chosen': -6.909375190734863, 'logits/rejected': -6.78125, 'epoch': 1.27}
 42%|████▏     | 1930/4545 [2:04:07<2:33:44,  3.53s/it] 42%|████▏     | 1931/4545 [2:04:11<2:33:38,  3.53s/it] 43%|████▎     | 1932/4545 [2:04:15<2:38:24,  3.64s/it] 43%|████▎     | 1933/4545 [2:04:18<2:26:55,  3.37s/it] 43%|████▎     | 1934/4545 [2:04:22<2:35:40,  3.58s/it] 43%|████▎     | 1935/4545 [2:04:26<2:40:05,  3.68s/it] 43%|████▎     | 1936/4545 [2:04:29<2:42:18,  3.73s/it] 43%|████▎     | 1937/4545 [2:04:33<2:43:04,  3.75s/it] 43%|████▎     | 1938/4545 [2:04:37<2:45:13,  3.80s/it] 43%|████▎     | 1939/4545 [2:04:41<2:48:39,  3.88s/it] 43%|████▎     | 1940/4545 [2:04:45<2:49:01,  3.89s/it]                                                       {'loss': 0.395, 'grad_norm': 26.60600471496582, 'learning_rate': 9.570410078589592e-08, 'rewards/chosen': 1.329687476158142, 'rewards/rejected': -1.806884765625, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 3.137500047683716, 'logps/chosen': -289.8500061035156, 'logps/rejected': -194.75, 'logits/chosen': -6.815625190734863, 'logits/rejected': -6.634375095367432, 'epoch': 1.28}
 43%|████▎     | 1940/4545 [2:04:45<2:49:01,  3.89s/it] 43%|████▎     | 1941/4545 [2:04:49<2:53:33,  4.00s/it] 43%|████▎     | 1942/4545 [2:04:53<2:52:16,  3.97s/it] 43%|████▎     | 1943/4545 [2:04:57<2:52:02,  3.97s/it] 43%|████▎     | 1944/4545 [2:05:01<2:50:42,  3.94s/it] 43%|████▎     | 1945/4545 [2:05:04<2:39:58,  3.69s/it] 43%|████▎     | 1946/4545 [2:05:08<2:42:52,  3.76s/it] 43%|████▎     | 1947/4545 [2:05:11<2:31:56,  3.51s/it] 43%|████▎     | 1948/4545 [2:05:14<2:22:06,  3.28s/it] 43%|████▎     | 1949/4545 [2:05:18<2:30:24,  3.48s/it] 43%|████▎     | 1950/4545 [2:05:22<2:38:32,  3.67s/it]                                                       {'loss': 0.4142, 'grad_norm': 31.53096580505371, 'learning_rate': 9.55030376280599e-08, 'rewards/chosen': 0.7821548581123352, 'rewards/rejected': -0.4830078184604645, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.265039086341858, 'logps/chosen': -198.35000610351562, 'logps/rejected': -146.8249969482422, 'logits/chosen': -7.078125, 'logits/rejected': -6.837500095367432, 'epoch': 1.29}
 43%|████▎     | 1950/4545 [2:05:22<2:38:32,  3.67s/it] 43%|████▎     | 1951/4545 [2:05:26<2:41:45,  3.74s/it] 43%|████▎     | 1952/4545 [2:05:30<2:43:47,  3.79s/it] 43%|████▎     | 1953/4545 [2:05:33<2:42:19,  3.76s/it] 43%|████▎     | 1954/4545 [2:05:37<2:44:22,  3.81s/it] 43%|████▎     | 1955/4545 [2:05:41<2:48:33,  3.90s/it] 43%|████▎     | 1956/4545 [2:05:45<2:48:33,  3.91s/it] 43%|████▎     | 1957/4545 [2:05:49<2:48:23,  3.90s/it] 43%|████▎     | 1958/4545 [2:05:51<2:27:14,  3.41s/it] 43%|████▎     | 1959/4545 [2:05:54<2:12:59,  3.09s/it] 43%|████▎     | 1960/4545 [2:05:57<2:17:58,  3.20s/it]                                                       {'loss': 0.4157, 'grad_norm': 22.537076950073242, 'learning_rate': 9.52976232448331e-08, 'rewards/chosen': 1.2902343273162842, 'rewards/rejected': -0.47761231660842896, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.76953125, 'logps/chosen': -301.45001220703125, 'logps/rejected': -146.0500030517578, 'logits/chosen': -6.949999809265137, 'logits/rejected': -6.962500095367432, 'epoch': 1.29}
 43%|████▎     | 1960/4545 [2:05:57<2:17:58,  3.20s/it] 43%|████▎     | 1961/4545 [2:06:02<2:32:30,  3.54s/it] 43%|████▎     | 1962/4545 [2:06:04<2:20:49,  3.27s/it] 43%|████▎     | 1963/4545 [2:06:08<2:27:34,  3.43s/it] 43%|████▎     | 1964/4545 [2:06:12<2:34:29,  3.59s/it] 43%|████▎     | 1965/4545 [2:06:15<2:32:19,  3.54s/it] 43%|████▎     | 1966/4545 [2:06:19<2:33:27,  3.57s/it] 43%|████▎     | 1967/4545 [2:06:23<2:37:38,  3.67s/it] 43%|████▎     | 1968/4545 [2:06:27<2:40:29,  3.74s/it] 43%|████▎     | 1969/4545 [2:06:31<2:45:02,  3.84s/it] 43%|████▎     | 1970/4545 [2:06:35<2:42:49,  3.79s/it]                                                       {'loss': 0.3885, 'grad_norm': 24.113628387451172, 'learning_rate': 9.508787970380187e-08, 'rewards/chosen': 0.942675769329071, 'rewards/rejected': -0.84326171875, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.788671851158142, 'logps/chosen': -226.5, 'logps/rejected': -103.2750015258789, 'logits/chosen': -6.893750190734863, 'logits/rejected': -6.684374809265137, 'epoch': 1.3}
 43%|████▎     | 1970/4545 [2:06:35<2:42:49,  3.79s/it] 43%|████▎     | 1971/4545 [2:06:38<2:40:55,  3.75s/it] 43%|████▎     | 1972/4545 [2:06:41<2:32:46,  3.56s/it] 43%|████▎     | 1973/4545 [2:06:45<2:37:17,  3.67s/it] 43%|████▎     | 1974/4545 [2:06:49<2:40:14,  3.74s/it] 43%|████▎     | 1975/4545 [2:06:53<2:39:36,  3.73s/it] 43%|████▎     | 1976/4545 [2:06:57<2:45:09,  3.86s/it] 43%|████▎     | 1977/4545 [2:07:01<2:44:24,  3.84s/it] 44%|████▎     | 1978/4545 [2:07:05<2:45:13,  3.86s/it] 44%|████▎     | 1979/4545 [2:07:09<2:47:45,  3.92s/it] 44%|████▎     | 1980/4545 [2:07:13<2:47:33,  3.92s/it]                                                       {'loss': 0.409, 'grad_norm': 12.705231666564941, 'learning_rate': 9.487382953763224e-08, 'rewards/chosen': 1.1707031726837158, 'rewards/rejected': -0.4637695252895355, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.6359374523162842, 'logps/chosen': -238.0500030517578, 'logps/rejected': -145.25, 'logits/chosen': -6.840624809265137, 'logits/rejected': -6.806250095367432, 'epoch': 1.31}
 44%|████▎     | 1980/4545 [2:07:13<2:47:33,  3.92s/it] 44%|████▎     | 1981/4545 [2:07:16<2:39:06,  3.72s/it] 44%|████▎     | 1982/4545 [2:07:20<2:42:54,  3.81s/it] 44%|████▎     | 1983/4545 [2:07:24<2:43:12,  3.82s/it] 44%|████▎     | 1984/4545 [2:07:27<2:38:39,  3.72s/it] 44%|████▎     | 1985/4545 [2:07:31<2:41:01,  3.77s/it] 44%|████▎     | 1986/4545 [2:07:35<2:42:35,  3.81s/it] 44%|████▎     | 1987/4545 [2:07:39<2:47:31,  3.93s/it] 44%|████▎     | 1988/4545 [2:07:43<2:48:06,  3.94s/it] 44%|████▍     | 1989/4545 [2:07:47<2:43:55,  3.85s/it] 44%|████▍     | 1990/4545 [2:07:51<2:44:51,  3.87s/it]                                                       {'loss': 0.4266, 'grad_norm': 14.896347045898438, 'learning_rate': 9.465549574164936e-08, 'rewards/chosen': 1.027856469154358, 'rewards/rejected': -0.580859363079071, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.6076171398162842, 'logps/chosen': -241.9499969482422, 'logps/rejected': -142.14999389648438, 'logits/chosen': -6.959374904632568, 'logits/rejected': -6.971875190734863, 'epoch': 1.31}
 44%|████▍     | 1990/4545 [2:07:51<2:44:51,  3.87s/it] 44%|████▍     | 1991/4545 [2:07:55<2:45:47,  3.89s/it] 44%|████▍     | 1992/4545 [2:07:59<2:45:38,  3.89s/it] 44%|████▍     | 1993/4545 [2:08:03<2:45:29,  3.89s/it] 44%|████▍     | 1994/4545 [2:08:07<2:45:34,  3.89s/it] 44%|████▍     | 1995/4545 [2:08:11<2:47:20,  3.94s/it] 44%|████▍     | 1996/4545 [2:08:14<2:43:22,  3.85s/it] 44%|████▍     | 1997/4545 [2:08:18<2:41:30,  3.80s/it] 44%|████▍     | 1998/4545 [2:08:22<2:42:44,  3.83s/it] 44%|████▍     | 1999/4545 [2:08:25<2:36:52,  3.70s/it] 44%|████▍     | 2000/4545 [2:08:29<2:35:41,  3.67s/it]                                                       {'loss': 0.4437, 'grad_norm': 47.630767822265625, 'learning_rate': 9.443290177136699e-08, 'rewards/chosen': 1.419531226158142, 'rewards/rejected': -0.10004882514476776, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.5222656726837158, 'logps/chosen': -338.70001220703125, 'logps/rejected': -243.8000030517578, 'logits/chosen': -6.940625190734863, 'logits/rejected': -6.699999809265137, 'epoch': 1.32}
 44%|████▍     | 2000/4545 [2:08:29<2:35:41,  3.67s/it] 44%|████▍     | 2001/4545 [2:08:32<2:28:38,  3.51s/it] 44%|████▍     | 2002/4545 [2:08:36<2:34:52,  3.65s/it] 44%|████▍     | 2003/4545 [2:08:40<2:37:25,  3.72s/it] 44%|████▍     | 2004/4545 [2:08:43<2:37:10,  3.71s/it] 44%|████▍     | 2005/4545 [2:08:47<2:38:37,  3.75s/it] 44%|████▍     | 2006/4545 [2:08:51<2:40:44,  3.80s/it] 44%|████▍     | 2007/4545 [2:08:55<2:42:02,  3.83s/it] 44%|████▍     | 2008/4545 [2:08:59<2:42:37,  3.85s/it] 44%|████▍     | 2009/4545 [2:09:03<2:43:30,  3.87s/it] 44%|████▍     | 2010/4545 [2:09:07<2:44:28,  3.89s/it]                                                       {'loss': 0.4568, 'grad_norm': 20.961097717285156, 'learning_rate': 9.42060715399677e-08, 'rewards/chosen': 1.4744141101837158, 'rewards/rejected': -0.3521972596645355, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.826562523841858, 'logps/chosen': -340.6000061035156, 'logps/rejected': -195.6750030517578, 'logits/chosen': -7.025000095367432, 'logits/rejected': -6.784375190734863, 'epoch': 1.33}
 44%|████▍     | 2010/4545 [2:09:07<2:44:28,  3.89s/it] 44%|████▍     | 2011/4545 [2:09:11<2:44:31,  3.90s/it] 44%|████▍     | 2012/4545 [2:09:14<2:39:26,  3.78s/it] 44%|████▍     | 2013/4545 [2:09:17<2:27:16,  3.49s/it] 44%|████▍     | 2014/4545 [2:09:21<2:32:35,  3.62s/it] 44%|████▍     | 2015/4545 [2:09:25<2:36:09,  3.70s/it] 44%|████▍     | 2016/4545 [2:09:29<2:38:35,  3.76s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                       
                                               [A{'eval_loss': 0.3943427503108978, 'eval_runtime': 80.3261, 'eval_samples_per_second': 11.864, 'eval_steps_per_second': 0.747, 'eval_rewards/chosen': 1.4996154308319092, 'eval_rewards/rejected': -0.24382731318473816, 'eval_rewards/accuracies': 0.8339120149612427, 'eval_rewards/margins': 1.7448608875274658, 'eval_logps/chosen': -362.76666259765625, 'eval_logps/rejected': -154.3854217529297, 'eval_logits/chosen': -6.662499904632568, 'eval_logits/rejected': -7.243750095367432, 'epoch': 1.33}
 44%|████▍     | 2016/4545 [2:10:49<2:38:35,  3.76s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 44%|████▍     | 2017/4545 [2:11:04<21:51:34, 31.13s/it] 44%|████▍     | 2018/4545 [2:11:07<16:03:57, 22.89s/it] 44%|████▍     | 2019/4545 [2:11:12<12:06:55, 17.27s/it] 44%|████▍     | 2020/4545 [2:11:16<9:19:15, 13.29s/it]                                                        {'loss': 0.3771, 'grad_norm': 23.469463348388672, 'learning_rate': 9.397502941573402e-08, 'rewards/chosen': 1.285974144935608, 'rewards/rejected': -0.6289032101631165, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.9152343273162842, 'logps/chosen': -307.75, 'logps/rejected': -160.22500610351562, 'logits/chosen': -7.084374904632568, 'logits/rejected': -7.053124904632568, 'epoch': 1.33}
 44%|████▍     | 2020/4545 [2:11:16<9:19:15, 13.29s/it] 44%|████▍     | 2021/4545 [2:11:20<7:20:33, 10.47s/it] 44%|████▍     | 2022/4545 [2:11:23<5:56:56,  8.49s/it] 45%|████▍     | 2023/4545 [2:11:27<4:53:11,  6.98s/it] 45%|████▍     | 2024/4545 [2:11:31<4:17:56,  6.14s/it] 45%|████▍     | 2025/4545 [2:11:35<3:51:22,  5.51s/it] 45%|████▍     | 2026/4545 [2:11:39<3:26:04,  4.91s/it] 45%|████▍     | 2027/4545 [2:11:43<3:16:09,  4.67s/it] 45%|████▍     | 2028/4545 [2:11:45<2:52:03,  4.10s/it] 45%|████▍     | 2029/4545 [2:11:50<2:52:52,  4.12s/it] 45%|████▍     | 2030/4545 [2:11:53<2:46:30,  3.97s/it]                                                       {'loss': 0.3401, 'grad_norm': 15.553338050842285, 'learning_rate': 9.37398002194304e-08, 'rewards/chosen': 1.5388672351837158, 'rewards/rejected': -0.482421875, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.0218749046325684, 'logps/chosen': -321.0, 'logps/rejected': -202.75, 'logits/chosen': -7.175000190734863, 'logits/rejected': -7.009375095367432, 'epoch': 1.34}
 45%|████▍     | 2030/4545 [2:11:53<2:46:30,  3.97s/it] 45%|████▍     | 2031/4545 [2:11:57<2:47:53,  4.01s/it] 45%|████▍     | 2032/4545 [2:12:01<2:46:39,  3.98s/it] 45%|████▍     | 2033/4545 [2:12:05<2:46:47,  3.98s/it] 45%|████▍     | 2034/4545 [2:12:09<2:45:43,  3.96s/it] 45%|████▍     | 2035/4545 [2:12:13<2:45:11,  3.95s/it] 45%|████▍     | 2036/4545 [2:12:17<2:44:40,  3.94s/it] 45%|████▍     | 2037/4545 [2:12:21<2:44:07,  3.93s/it] 45%|████▍     | 2038/4545 [2:12:24<2:38:18,  3.79s/it] 45%|████▍     | 2039/4545 [2:12:28<2:39:50,  3.83s/it] 45%|████▍     | 2040/4545 [2:12:32<2:43:47,  3.92s/it]                                                       {'loss': 0.3693, 'grad_norm': 14.00024127960205, 'learning_rate': 9.350040922163682e-08, 'rewards/chosen': 1.70703125, 'rewards/rejected': -0.3027587831020355, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.006640672683716, 'logps/chosen': -345.54998779296875, 'logps/rejected': -189.6999969482422, 'logits/chosen': -6.853125095367432, 'logits/rejected': -6.909375190734863, 'epoch': 1.35}
 45%|████▍     | 2040/4545 [2:12:32<2:43:47,  3.92s/it] 45%|████▍     | 2041/4545 [2:12:36<2:40:31,  3.85s/it] 45%|████▍     | 2042/4545 [2:12:40<2:44:33,  3.94s/it] 45%|████▍     | 2043/4545 [2:12:44<2:44:13,  3.94s/it] 45%|████▍     | 2044/4545 [2:12:48<2:43:45,  3.93s/it] 45%|████▍     | 2045/4545 [2:12:52<2:42:51,  3.91s/it] 45%|████▌     | 2046/4545 [2:12:55<2:35:52,  3.74s/it] 45%|████▌     | 2047/4545 [2:12:59<2:38:52,  3.82s/it] 45%|████▌     | 2048/4545 [2:13:03<2:41:29,  3.88s/it] 45%|████▌     | 2049/4545 [2:13:06<2:27:46,  3.55s/it] 45%|████▌     | 2050/4545 [2:13:10<2:27:20,  3.54s/it]                                                       {'loss': 0.3516, 'grad_norm': 19.634119033813477, 'learning_rate': 9.325688214003396e-08, 'rewards/chosen': 1.1018555164337158, 'rewards/rejected': -0.7762451171875, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 1.876562476158142, 'logps/chosen': -240.10000610351562, 'logps/rejected': -158.75, 'logits/chosen': -7.028124809265137, 'logits/rejected': -6.818749904632568, 'epoch': 1.35}
 45%|████▌     | 2050/4545 [2:13:10<2:27:20,  3.54s/it] 45%|████▌     | 2051/4545 [2:13:13<2:31:12,  3.64s/it] 45%|████▌     | 2052/4545 [2:13:17<2:32:40,  3.67s/it] 45%|████▌     | 2053/4545 [2:13:21<2:35:30,  3.74s/it] 45%|████▌     | 2054/4545 [2:13:25<2:37:32,  3.79s/it] 45%|████▌     | 2055/4545 [2:13:29<2:38:54,  3.83s/it] 45%|████▌     | 2056/4545 [2:13:32<2:26:10,  3.52s/it] 45%|████▌     | 2057/4545 [2:13:36<2:30:41,  3.63s/it] 45%|████▌     | 2058/4545 [2:13:40<2:34:11,  3.72s/it] 45%|████▌     | 2059/4545 [2:13:43<2:36:34,  3.78s/it] 45%|████▌     | 2060/4545 [2:13:46<2:22:19,  3.44s/it]                                                       {'loss': 0.3586, 'grad_norm': 25.8372802734375, 'learning_rate': 9.300924513664032e-08, 'rewards/chosen': 1.8913085460662842, 'rewards/rejected': -0.652880847454071, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.5425782203674316, 'logps/chosen': -396.3999938964844, 'logps/rejected': -164.35000610351562, 'logits/chosen': -6.865624904632568, 'logits/rejected': -6.650000095367432, 'epoch': 1.36}
 45%|████▌     | 2060/4545 [2:13:46<2:22:19,  3.44s/it] 45%|████▌     | 2061/4545 [2:13:50<2:28:28,  3.59s/it] 45%|████▌     | 2062/4545 [2:13:54<2:32:27,  3.68s/it] 45%|████▌     | 2063/4545 [2:13:58<2:35:08,  3.75s/it] 45%|████▌     | 2064/4545 [2:14:02<2:37:18,  3.80s/it] 45%|████▌     | 2065/4545 [2:14:05<2:31:25,  3.66s/it] 45%|████▌     | 2066/4545 [2:14:08<2:26:50,  3.55s/it] 45%|████▌     | 2067/4545 [2:14:13<2:34:51,  3.75s/it] 46%|████▌     | 2068/4545 [2:14:17<2:36:55,  3.80s/it] 46%|████▌     | 2069/4545 [2:14:21<2:40:02,  3.88s/it] 46%|████▌     | 2070/4545 [2:14:25<2:40:05,  3.88s/it]                                                       {'loss': 0.4113, 'grad_norm': 26.34291648864746, 'learning_rate': 9.275752481500174e-08, 'rewards/chosen': 0.8265136480331421, 'rewards/rejected': -0.581250011920929, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.407812476158142, 'logps/chosen': -204.25, 'logps/rejected': -165.3000030517578, 'logits/chosen': -7.178124904632568, 'logits/rejected': -7.0, 'epoch': 1.37}
 46%|████▌     | 2070/4545 [2:14:25<2:40:05,  3.88s/it] 46%|████▌     | 2071/4545 [2:14:28<2:41:09,  3.91s/it] 46%|████▌     | 2072/4545 [2:14:32<2:35:33,  3.77s/it] 46%|████▌     | 2073/4545 [2:14:36<2:37:19,  3.82s/it] 46%|████▌     | 2074/4545 [2:14:39<2:28:26,  3.60s/it] 46%|████▌     | 2075/4545 [2:14:43<2:31:03,  3.67s/it] 46%|████▌     | 2076/4545 [2:14:46<2:28:27,  3.61s/it] 46%|████▌     | 2077/4545 [2:14:50<2:31:13,  3.68s/it] 46%|████▌     | 2078/4545 [2:14:54<2:33:55,  3.74s/it] 46%|████▌     | 2079/4545 [2:14:58<2:32:17,  3.71s/it] 46%|████▌     | 2080/4545 [2:15:01<2:22:25,  3.47s/it]                                                       {'loss': 0.3809, 'grad_norm': 15.819389343261719, 'learning_rate': 9.250174821733328e-08, 'rewards/chosen': 0.624890148639679, 'rewards/rejected': -0.898120105266571, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.5234375, 'logps/chosen': -152.4499969482422, 'logps/rejected': -111.67500305175781, 'logits/chosen': -7.099999904632568, 'logits/rejected': -6.978125095367432, 'epoch': 1.37}
 46%|████▌     | 2080/4545 [2:15:01<2:22:25,  3.47s/it] 46%|████▌     | 2081/4545 [2:15:03<2:09:27,  3.15s/it] 46%|████▌     | 2082/4545 [2:15:06<2:12:12,  3.22s/it] 46%|████▌     | 2083/4545 [2:15:10<2:21:00,  3.44s/it] 46%|████▌     | 2084/4545 [2:15:14<2:27:05,  3.59s/it] 46%|████▌     | 2085/4545 [2:15:18<2:34:13,  3.76s/it] 46%|████▌     | 2086/4545 [2:15:22<2:35:50,  3.80s/it] 46%|████▌     | 2087/4545 [2:15:26<2:36:59,  3.83s/it] 46%|████▌     | 2088/4545 [2:15:30<2:38:18,  3.87s/it] 46%|████▌     | 2089/4545 [2:15:34<2:37:31,  3.85s/it] 46%|████▌     | 2090/4545 [2:15:38<2:34:33,  3.78s/it]                                                       {'loss': 0.3932, 'grad_norm': 15.358348846435547, 'learning_rate': 9.224194282161415e-08, 'rewards/chosen': 1.4728515148162842, 'rewards/rejected': -0.5272461175918579, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.0003905296325684, 'logps/chosen': -327.0, 'logps/rejected': -230.6999969482422, 'logits/chosen': -6.987500190734863, 'logits/rejected': -6.824999809265137, 'epoch': 1.38}
 46%|████▌     | 2090/4545 [2:15:38<2:34:33,  3.78s/it] 46%|████▌     | 2091/4545 [2:15:41<2:32:57,  3.74s/it] 46%|████▌     | 2092/4545 [2:15:45<2:28:50,  3.64s/it] 46%|████▌     | 2093/4545 [2:15:49<2:32:04,  3.72s/it] 46%|████▌     | 2094/4545 [2:15:53<2:37:27,  3.85s/it] 46%|████▌     | 2095/4545 [2:15:56<2:34:16,  3.78s/it] 46%|████▌     | 2096/4545 [2:16:00<2:35:48,  3.82s/it] 46%|████▌     | 2097/4545 [2:16:04<2:37:02,  3.85s/it] 46%|████▌     | 2098/4545 [2:16:08<2:37:41,  3.87s/it] 46%|████▌     | 2099/4545 [2:16:12<2:38:26,  3.89s/it] 46%|████▌     | 2100/4545 [2:16:16<2:38:33,  3.89s/it]                                                       {'loss': 0.3911, 'grad_norm': 9.892836570739746, 'learning_rate': 9.197813653863578e-08, 'rewards/chosen': 1.8596680164337158, 'rewards/rejected': -0.33349609375, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.192187547683716, 'logps/chosen': -397.79998779296875, 'logps/rejected': -208.5, 'logits/chosen': -6.746874809265137, 'logits/rejected': -6.806250095367432, 'epoch': 1.39}
 46%|████▌     | 2100/4545 [2:16:16<2:38:33,  3.89s/it] 46%|████▌     | 2101/4545 [2:16:20<2:41:02,  3.95s/it] 46%|████▌     | 2102/4545 [2:16:24<2:40:11,  3.93s/it] 46%|████▋     | 2103/4545 [2:16:28<2:39:39,  3.92s/it] 46%|████▋     | 2104/4545 [2:16:32<2:39:24,  3.92s/it] 46%|████▋     | 2105/4545 [2:16:36<2:39:16,  3.92s/it] 46%|████▋     | 2106/4545 [2:16:39<2:39:15,  3.92s/it] 46%|████▋     | 2107/4545 [2:16:44<2:41:12,  3.97s/it] 46%|████▋     | 2108/4545 [2:16:47<2:39:55,  3.94s/it] 46%|████▋     | 2109/4545 [2:16:51<2:39:28,  3.93s/it] 46%|████▋     | 2110/4545 [2:16:55<2:39:14,  3.92s/it]                                                       {'loss': 0.3367, 'grad_norm': 36.493675231933594, 'learning_rate': 9.171035770900328e-08, 'rewards/chosen': 2.383984327316284, 'rewards/rejected': -0.41874998807907104, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.799999952316284, 'logps/chosen': -502.04998779296875, 'logps/rejected': -269.6000061035156, 'logits/chosen': -6.84375, 'logits/rejected': -6.896874904632568, 'epoch': 1.39}
 46%|████▋     | 2110/4545 [2:16:55<2:39:14,  3.92s/it] 46%|████▋     | 2111/4545 [2:16:59<2:41:37,  3.98s/it] 46%|████▋     | 2112/4545 [2:17:03<2:32:42,  3.77s/it] 46%|████▋     | 2113/4545 [2:17:07<2:34:10,  3.80s/it] 47%|████▋     | 2114/4545 [2:17:10<2:35:16,  3.83s/it] 47%|████▋     | 2115/4545 [2:17:14<2:36:16,  3.86s/it] 47%|████▋     | 2116/4545 [2:17:18<2:36:59,  3.88s/it] 47%|████▋     | 2117/4545 [2:17:22<2:30:26,  3.72s/it] 47%|████▋     | 2118/4545 [2:17:26<2:33:45,  3.80s/it] 47%|████▋     | 2119/4545 [2:17:30<2:38:18,  3.92s/it] 47%|████▋     | 2120/4545 [2:17:33<2:32:42,  3.78s/it]                                                       {'loss': 0.3901, 'grad_norm': 18.835956573486328, 'learning_rate': 9.143863510009096e-08, 'rewards/chosen': 1.939599633216858, 'rewards/rejected': -0.3980712890625, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.3343749046325684, 'logps/chosen': -394.0, 'logps/rejected': -213.9499969482422, 'logits/chosen': -7.065625190734863, 'logits/rejected': -6.878125190734863, 'epoch': 1.4}
 47%|████▋     | 2120/4545 [2:17:33<2:32:42,  3.78s/it] 47%|████▋     | 2121/4545 [2:17:37<2:34:27,  3.82s/it] 47%|████▋     | 2122/4545 [2:17:41<2:35:26,  3.85s/it] 47%|████▋     | 2123/4545 [2:17:44<2:29:37,  3.71s/it] 47%|████▋     | 2124/4545 [2:17:49<2:34:16,  3.82s/it] 47%|████▋     | 2125/4545 [2:17:53<2:36:31,  3.88s/it] 47%|████▋     | 2126/4545 [2:17:56<2:26:40,  3.64s/it] 47%|████▋     | 2127/4545 [2:18:00<2:29:48,  3.72s/it] 47%|████▋     | 2128/4545 [2:18:03<2:32:29,  3.79s/it] 47%|████▋     | 2129/4545 [2:18:07<2:34:05,  3.83s/it] 47%|████▋     | 2130/4545 [2:18:11<2:35:06,  3.85s/it]                                                       {'loss': 0.373, 'grad_norm': 17.141054153442383, 'learning_rate': 9.116299790295174e-08, 'rewards/chosen': 1.5128905773162842, 'rewards/rejected': -0.9092773199081421, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.4214844703674316, 'logps/chosen': -341.67498779296875, 'logps/rejected': -147.1999969482422, 'logits/chosen': -6.956250190734863, 'logits/rejected': -6.787499904632568, 'epoch': 1.41}
 47%|████▋     | 2130/4545 [2:18:11<2:35:06,  3.85s/it] 47%|████▋     | 2131/4545 [2:18:15<2:36:06,  3.88s/it] 47%|████▋     | 2132/4545 [2:18:19<2:33:02,  3.81s/it] 47%|████▋     | 2133/4545 [2:18:23<2:34:17,  3.84s/it] 47%|████▋     | 2134/4545 [2:18:27<2:35:07,  3.86s/it] 47%|████▋     | 2135/4545 [2:18:31<2:35:32,  3.87s/it] 47%|████▋     | 2136/4545 [2:18:35<2:36:02,  3.89s/it] 47%|████▋     | 2137/4545 [2:18:38<2:35:04,  3.86s/it] 47%|████▋     | 2138/4545 [2:18:42<2:35:27,  3.88s/it] 47%|████▋     | 2139/4545 [2:18:45<2:26:19,  3.65s/it] 47%|████▋     | 2140/4545 [2:18:49<2:29:17,  3.72s/it]                                                       {'loss': 0.3451, 'grad_norm': 13.003250122070312, 'learning_rate': 9.088347572918121e-08, 'rewards/chosen': 2.368640184402466, 'rewards/rejected': -0.3863281309604645, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.7578125, 'logps/chosen': -491.5, 'logps/rejected': -244.60000610351562, 'logits/chosen': -6.849999904632568, 'logits/rejected': -6.909375190734863, 'epoch': 1.41}
 47%|████▋     | 2140/4545 [2:18:49<2:29:17,  3.72s/it] 47%|████▋     | 2141/4545 [2:18:53<2:31:35,  3.78s/it] 47%|████▋     | 2142/4545 [2:18:57<2:32:50,  3.82s/it] 47%|████▋     | 2143/4545 [2:19:00<2:21:10,  3.53s/it] 47%|████▋     | 2144/4545 [2:19:03<2:11:16,  3.28s/it] 47%|████▋     | 2145/4545 [2:19:07<2:18:26,  3.46s/it] 47%|████▋     | 2146/4545 [2:19:10<2:23:34,  3.59s/it] 47%|████▋     | 2147/4545 [2:19:14<2:26:28,  3.66s/it] 47%|████▋     | 2148/4545 [2:19:18<2:29:20,  3.74s/it] 47%|████▋     | 2149/4545 [2:19:22<2:24:34,  3.62s/it] 47%|████▋     | 2150/4545 [2:19:25<2:27:44,  3.70s/it]                                                       {'loss': 0.3283, 'grad_norm': 24.532718658447266, 'learning_rate': 9.060009860773648e-08, 'rewards/chosen': 0.956835925579071, 'rewards/rejected': -1.056054711341858, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.01171875, 'logps/chosen': -218.35000610351562, 'logps/rejected': -113.1500015258789, 'logits/chosen': -7.109375, 'logits/rejected': -6.871874809265137, 'epoch': 1.42}
 47%|████▋     | 2150/4545 [2:19:25<2:27:44,  3.70s/it] 47%|████▋     | 2151/4545 [2:19:30<2:33:10,  3.84s/it] 47%|████▋     | 2152/4545 [2:19:33<2:33:51,  3.86s/it] 47%|████▋     | 2153/4545 [2:19:37<2:34:17,  3.87s/it] 47%|████▋     | 2154/4545 [2:19:40<2:25:11,  3.64s/it] 47%|████▋     | 2155/4545 [2:19:44<2:28:13,  3.72s/it] 47%|████▋     | 2156/4545 [2:19:47<2:11:03,  3.29s/it] 47%|████▋     | 2157/4545 [2:19:51<2:20:29,  3.53s/it] 47%|████▋     | 2158/4545 [2:19:55<2:24:45,  3.64s/it] 48%|████▊     | 2159/4545 [2:19:58<2:15:23,  3.40s/it] 48%|████▊     | 2160/4545 [2:20:01<2:21:54,  3.57s/it]                                                       {'loss': 0.3961, 'grad_norm': 18.126811981201172, 'learning_rate': 9.031289698171017e-08, 'rewards/chosen': 1.539209008216858, 'rewards/rejected': -0.641308605670929, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.17578125, 'logps/chosen': -350.95001220703125, 'logps/rejected': -154.52499389648438, 'logits/chosen': -6.846875190734863, 'logits/rejected': -6.699999809265137, 'epoch': 1.43}
 48%|████▊     | 2160/4545 [2:20:01<2:21:54,  3.57s/it] 48%|████▊     | 2161/4545 [2:20:05<2:23:08,  3.60s/it] 48%|████▊     | 2162/4545 [2:20:09<2:27:07,  3.70s/it] 48%|████▊     | 2163/4545 [2:20:13<2:32:11,  3.83s/it] 48%|████▊     | 2164/4545 [2:20:17<2:33:06,  3.86s/it] 48%|████▊     | 2165/4545 [2:20:21<2:36:29,  3.95s/it] 48%|████▊     | 2166/4545 [2:20:25<2:35:28,  3.92s/it] 48%|████▊     | 2167/4545 [2:20:28<2:22:19,  3.59s/it] 48%|████▊     | 2168/4545 [2:20:32<2:26:11,  3.69s/it] 48%|████▊     | 2169/4545 [2:20:36<2:28:36,  3.75s/it] 48%|████▊     | 2170/4545 [2:20:39<2:26:21,  3.70s/it]                                                       {'loss': 0.3746, 'grad_norm': 13.034614562988281, 'learning_rate': 9.002190170505995e-08, 'rewards/chosen': 1.228515625, 'rewards/rejected': -0.8384765386581421, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.065234422683716, 'logps/chosen': -271.3500061035156, 'logps/rejected': -126.7750015258789, 'logits/chosen': -7.231249809265137, 'logits/rejected': -7.262499809265137, 'epoch': 1.43}
 48%|████▊     | 2170/4545 [2:20:39<2:26:21,  3.70s/it] 48%|████▊     | 2171/4545 [2:20:43<2:28:44,  3.76s/it] 48%|████▊     | 2172/4545 [2:20:47<2:33:54,  3.89s/it] 48%|████▊     | 2173/4545 [2:20:51<2:29:13,  3.77s/it] 48%|████▊     | 2174/4545 [2:20:55<2:30:50,  3.82s/it] 48%|████▊     | 2175/4545 [2:20:58<2:23:51,  3.64s/it] 48%|████▊     | 2176/4545 [2:21:02<2:28:52,  3.77s/it] 48%|████▊     | 2177/4545 [2:21:06<2:30:16,  3.81s/it] 48%|████▊     | 2178/4545 [2:21:10<2:31:34,  3.84s/it] 48%|████▊     | 2179/4545 [2:21:13<2:20:39,  3.57s/it] 48%|████▊     | 2180/4545 [2:21:17<2:24:38,  3.67s/it]                                                       {'loss': 0.3277, 'grad_norm': 8.434924125671387, 'learning_rate': 8.972714403929383e-08, 'rewards/chosen': 1.5908019542694092, 'rewards/rejected': -0.940234363079071, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.528125047683716, 'logps/chosen': -328.75, 'logps/rejected': -143.85000610351562, 'logits/chosen': -7.143750190734863, 'logits/rejected': -6.959374904632568, 'epoch': 1.44}
 48%|████▊     | 2180/4545 [2:21:17<2:24:38,  3.67s/it] 48%|████▊     | 2181/4545 [2:21:21<2:27:23,  3.74s/it] 48%|████▊     | 2182/4545 [2:21:24<2:25:46,  3.70s/it] 48%|████▊     | 2183/4545 [2:21:28<2:29:45,  3.80s/it] 48%|████▊     | 2184/4545 [2:21:32<2:30:29,  3.82s/it] 48%|████▊     | 2185/4545 [2:21:37<2:35:12,  3.95s/it] 48%|████▊     | 2186/4545 [2:21:40<2:35:22,  3.95s/it] 48%|████▊     | 2187/4545 [2:21:44<2:34:38,  3.93s/it] 48%|████▊     | 2188/4545 [2:21:48<2:28:05,  3.77s/it] 48%|████▊     | 2189/4545 [2:21:51<2:26:08,  3.72s/it] 48%|████▊     | 2190/4545 [2:21:55<2:21:48,  3.61s/it]                                                       {'loss': 0.331, 'grad_norm': 27.52468490600586, 'learning_rate': 8.942865565011183e-08, 'rewards/chosen': 1.1614258289337158, 'rewards/rejected': -0.884692370891571, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.046875, 'logps/chosen': -241.0500030517578, 'logps/rejected': -170.9499969482422, 'logits/chosen': -7.243750095367432, 'logits/rejected': -6.959374904632568, 'epoch': 1.45}
 48%|████▊     | 2190/4545 [2:21:55<2:21:48,  3.61s/it] 48%|████▊     | 2191/4545 [2:21:59<2:25:13,  3.70s/it] 48%|████▊     | 2192/4545 [2:22:03<2:27:28,  3.76s/it] 48%|████▊     | 2193/4545 [2:22:06<2:28:47,  3.80s/it] 48%|████▊     | 2194/4545 [2:22:11<2:32:22,  3.89s/it] 48%|████▊     | 2195/4545 [2:22:14<2:32:19,  3.89s/it] 48%|████▊     | 2196/4545 [2:22:18<2:31:52,  3.88s/it] 48%|████▊     | 2197/4545 [2:22:22<2:32:13,  3.89s/it] 48%|████▊     | 2198/4545 [2:22:26<2:32:33,  3.90s/it] 48%|████▊     | 2199/4545 [2:22:30<2:29:45,  3.83s/it] 48%|████▊     | 2200/4545 [2:22:34<2:30:54,  3.86s/it]                                                       {'loss': 0.3052, 'grad_norm': 15.038726806640625, 'learning_rate': 8.912646860400415e-08, 'rewards/chosen': 2.0003905296325684, 'rewards/rejected': -0.688427746295929, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.6898436546325684, 'logps/chosen': -429.8500061035156, 'logps/rejected': -239.0500030517578, 'logits/chosen': -6.684374809265137, 'logits/rejected': -6.609375, 'epoch': 1.45}
 48%|████▊     | 2200/4545 [2:22:34<2:30:54,  3.86s/it] 48%|████▊     | 2201/4545 [2:22:37<2:23:22,  3.67s/it] 48%|████▊     | 2202/4545 [2:22:40<2:19:35,  3.57s/it] 48%|████▊     | 2203/4545 [2:22:43<2:12:52,  3.40s/it] 48%|████▊     | 2204/4545 [2:22:47<2:17:32,  3.53s/it] 49%|████▊     | 2205/4545 [2:22:51<2:25:26,  3.73s/it] 49%|████▊     | 2206/4545 [2:22:55<2:23:47,  3.69s/it] 49%|████▊     | 2207/4545 [2:22:59<2:26:11,  3.75s/it] 49%|████▊     | 2208/4545 [2:23:03<2:31:14,  3.88s/it] 49%|████▊     | 2209/4545 [2:23:07<2:31:32,  3.89s/it] 49%|████▊     | 2210/4545 [2:23:11<2:31:33,  3.89s/it]                                                       {'loss': 0.3975, 'grad_norm': 26.459121704101562, 'learning_rate': 8.882061536480616e-08, 'rewards/chosen': 0.8335937261581421, 'rewards/rejected': -1.01171875, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.84765625, 'logps/chosen': -230.0749969482422, 'logps/rejected': -133.5, 'logits/chosen': -7.256249904632568, 'logits/rejected': -6.965624809265137, 'epoch': 1.46}
 49%|████▊     | 2210/4545 [2:23:11<2:31:33,  3.89s/it] 49%|████▊     | 2211/4545 [2:23:15<2:31:48,  3.90s/it] 49%|████▊     | 2212/4545 [2:23:19<2:31:56,  3.91s/it] 49%|████▊     | 2213/4545 [2:23:23<2:32:20,  3.92s/it] 49%|████▊     | 2214/4545 [2:23:26<2:31:10,  3.89s/it] 49%|████▊     | 2215/4545 [2:23:30<2:25:48,  3.75s/it] 49%|████▉     | 2216/4545 [2:23:34<2:27:30,  3.80s/it] 49%|████▉     | 2217/4545 [2:23:38<2:30:43,  3.88s/it] 49%|████▉     | 2218/4545 [2:23:42<2:30:53,  3.89s/it] 49%|████▉     | 2219/4545 [2:23:46<2:30:59,  3.89s/it] 49%|████▉     | 2220/4545 [2:23:50<2:31:17,  3.90s/it]                                                       {'loss': 0.3793, 'grad_norm': 13.01369857788086, 'learning_rate': 8.851112879021102e-08, 'rewards/chosen': 1.46630859375, 'rewards/rejected': -0.8924316167831421, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.356250047683716, 'logps/chosen': -319.1499938964844, 'logps/rejected': -173.89999389648438, 'logits/chosen': -7.03125, 'logits/rejected': -6.974999904632568, 'epoch': 1.47}
 49%|████▉     | 2220/4545 [2:23:50<2:31:17,  3.90s/it] 49%|████▉     | 2221/4545 [2:23:53<2:28:14,  3.83s/it] 49%|████▉     | 2222/4545 [2:23:57<2:25:20,  3.75s/it] 49%|████▉     | 2223/4545 [2:24:01<2:27:00,  3.80s/it] 49%|████▉     | 2224/4545 [2:24:05<2:28:06,  3.83s/it] 49%|████▉     | 2225/4545 [2:24:08<2:28:52,  3.85s/it] 49%|████▉     | 2226/4545 [2:24:12<2:29:26,  3.87s/it] 49%|████▉     | 2227/4545 [2:24:16<2:26:55,  3.80s/it] 49%|████▉     | 2228/4545 [2:24:20<2:28:02,  3.83s/it] 49%|████▉     | 2229/4545 [2:24:23<2:14:20,  3.48s/it] 49%|████▉     | 2230/4545 [2:24:27<2:19:10,  3.61s/it]                                                       {'loss': 0.3536, 'grad_norm': 25.750852584838867, 'learning_rate': 8.81980421282396e-08, 'rewards/chosen': 1.7937500476837158, 'rewards/rejected': -0.687695324420929, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.483593702316284, 'logps/chosen': -381.1499938964844, 'logps/rejected': -211.77499389648438, 'logits/chosen': -6.931250095367432, 'logits/rejected': -6.671875, 'epoch': 1.47}
 49%|████▉     | 2230/4545 [2:24:27<2:19:10,  3.61s/it] 49%|████▉     | 2231/4545 [2:24:30<2:22:51,  3.70s/it] 49%|████▉     | 2232/4545 [2:24:34<2:23:05,  3.71s/it] 49%|████▉     | 2233/4545 [2:24:38<2:26:21,  3.80s/it] 49%|████▉     | 2234/4545 [2:24:42<2:27:42,  3.83s/it] 49%|████▉     | 2235/4545 [2:24:45<2:19:46,  3.63s/it] 49%|████▉     | 2236/4545 [2:24:49<2:26:54,  3.82s/it] 49%|████▉     | 2237/4545 [2:24:53<2:27:46,  3.84s/it] 49%|████▉     | 2238/4545 [2:24:57<2:28:26,  3.86s/it] 49%|████▉     | 2239/4545 [2:25:01<2:28:56,  3.88s/it] 49%|████▉     | 2240/4545 [2:25:04<2:14:15,  3.49s/it]                                                       {'loss': 0.3046, 'grad_norm': 14.88627815246582, 'learning_rate': 8.788138901366876e-08, 'rewards/chosen': 1.680078148841858, 'rewards/rejected': -0.8109375238418579, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 2.4921875, 'logps/chosen': -317.6000061035156, 'logps/rejected': -163.0, 'logits/chosen': -7.081250190734863, 'logits/rejected': -6.962500095367432, 'epoch': 1.48}
 49%|████▉     | 2240/4545 [2:25:04<2:14:15,  3.49s/it] 49%|████▉     | 2241/4545 [2:25:08<2:18:57,  3.62s/it] 49%|████▉     | 2242/4545 [2:25:11<2:14:57,  3.52s/it] 49%|████▉     | 2243/4545 [2:25:15<2:16:40,  3.56s/it] 49%|████▉     | 2244/4545 [2:25:17<2:04:05,  3.24s/it] 49%|████▉     | 2245/4545 [2:25:21<2:13:12,  3.48s/it] 49%|████▉     | 2246/4545 [2:25:25<2:19:34,  3.64s/it] 49%|████▉     | 2247/4545 [2:25:29<2:22:36,  3.72s/it] 49%|████▉     | 2248/4545 [2:25:33<2:24:35,  3.78s/it] 49%|████▉     | 2249/4545 [2:25:37<2:27:16,  3.85s/it] 50%|████▉     | 2250/4545 [2:25:41<2:31:28,  3.96s/it]                                                       {'loss': 0.3437, 'grad_norm': 15.905123710632324, 'learning_rate': 8.7561203464418e-08, 'rewards/chosen': 1.366308569908142, 'rewards/rejected': -0.959179699420929, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3257813453674316, 'logps/chosen': -290.20001220703125, 'logps/rejected': -174.5, 'logits/chosen': -7.090624809265137, 'logits/rejected': -6.949999809265137, 'epoch': 1.49}
 50%|████▉     | 2250/4545 [2:25:41<2:31:28,  3.96s/it] 50%|████▉     | 2251/4545 [2:25:45<2:32:43,  3.99s/it] 50%|████▉     | 2252/4545 [2:25:49<2:31:12,  3.96s/it] 50%|████▉     | 2253/4545 [2:25:53<2:24:06,  3.77s/it] 50%|████▉     | 2254/4545 [2:25:56<2:25:33,  3.81s/it] 50%|████▉     | 2255/4545 [2:26:00<2:17:39,  3.61s/it] 50%|████▉     | 2256/4545 [2:26:03<2:21:01,  3.70s/it] 50%|████▉     | 2257/4545 [2:26:08<2:25:15,  3.81s/it] 50%|████▉     | 2258/4545 [2:26:11<2:25:22,  3.81s/it] 50%|████▉     | 2259/4545 [2:26:15<2:26:21,  3.84s/it] 50%|████▉     | 2260/4545 [2:26:19<2:26:53,  3.86s/it]                                                       {'loss': 0.3584, 'grad_norm': 19.648208618164062, 'learning_rate': 8.723751987789482e-08, 'rewards/chosen': 1.325585961341858, 'rewards/rejected': -0.859130859375, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.186718702316284, 'logps/chosen': -299.1000061035156, 'logps/rejected': -182.0500030517578, 'logits/chosen': -7.221875190734863, 'logits/rejected': -6.987500190734863, 'epoch': 1.49}
 50%|████▉     | 2260/4545 [2:26:19<2:26:53,  3.86s/it] 50%|████▉     | 2261/4545 [2:26:22<2:17:03,  3.60s/it] 50%|████▉     | 2262/4545 [2:26:26<2:20:12,  3.69s/it] 50%|████▉     | 2263/4545 [2:26:30<2:26:36,  3.85s/it] 50%|████▉     | 2264/4545 [2:26:34<2:28:42,  3.91s/it] 50%|████▉     | 2265/4545 [2:26:38<2:25:24,  3.83s/it] 50%|████▉     | 2266/4545 [2:26:42<2:25:08,  3.82s/it] 50%|████▉     | 2267/4545 [2:26:46<2:26:18,  3.85s/it] 50%|████▉     | 2268/4545 [2:26:49<2:13:55,  3.53s/it] 50%|████▉     | 2269/4545 [2:26:53<2:21:08,  3.72s/it] 50%|████▉     | 2270/4545 [2:26:56<2:19:50,  3.69s/it]                                                       {'loss': 0.3343, 'grad_norm': 18.24173355102539, 'learning_rate': 8.691037302729957e-08, 'rewards/chosen': 0.609082043170929, 'rewards/rejected': -1.2775390148162842, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.885156273841858, 'logps/chosen': -171.4499969482422, 'logps/rejected': -115.2249984741211, 'logits/chosen': -7.331250190734863, 'logits/rejected': -7.112500190734863, 'epoch': 1.5}
 50%|████▉     | 2270/4545 [2:26:56<2:19:50,  3.69s/it] 50%|████▉     | 2271/4545 [2:27:00<2:24:49,  3.82s/it] 50%|████▉     | 2272/4545 [2:27:03<2:11:35,  3.47s/it] 50%|█████     | 2273/4545 [2:27:07<2:14:56,  3.56s/it] 50%|█████     | 2274/4545 [2:27:10<2:09:49,  3.43s/it] 50%|█████     | 2275/4545 [2:27:14<2:16:52,  3.62s/it] 50%|█████     | 2276/4545 [2:27:17<2:13:51,  3.54s/it] 50%|█████     | 2277/4545 [2:27:21<2:17:52,  3.65s/it] 50%|█████     | 2278/4545 [2:27:25<2:17:55,  3.65s/it] 50%|█████     | 2279/4545 [2:27:29<2:21:41,  3.75s/it] 50%|█████     | 2280/4545 [2:27:33<2:23:26,  3.80s/it]                                                       {'loss': 0.4196, 'grad_norm': 15.124360084533691, 'learning_rate': 8.657979805788957e-08, 'rewards/chosen': 0.7358154058456421, 'rewards/rejected': -1.0734374523162842, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.8097655773162842, 'logps/chosen': -208.0500030517578, 'logps/rejected': -102.5250015258789, 'logits/chosen': -7.271874904632568, 'logits/rejected': -7.153124809265137, 'epoch': 1.5}
 50%|█████     | 2280/4545 [2:27:33<2:23:26,  3.80s/it] 50%|█████     | 2281/4545 [2:27:37<2:24:40,  3.83s/it] 50%|█████     | 2282/4545 [2:27:40<2:17:54,  3.66s/it] 50%|█████     | 2283/4545 [2:27:44<2:20:46,  3.73s/it] 50%|█████     | 2284/4545 [2:27:48<2:22:41,  3.79s/it] 50%|█████     | 2285/4545 [2:27:51<2:18:11,  3.67s/it] 50%|█████     | 2286/4545 [2:27:55<2:20:38,  3.74s/it] 50%|█████     | 2287/4545 [2:27:59<2:22:45,  3.79s/it] 50%|█████     | 2288/4545 [2:28:03<2:24:03,  3.83s/it] 50%|█████     | 2289/4545 [2:28:07<2:25:00,  3.86s/it] 50%|█████     | 2290/4545 [2:28:11<2:25:47,  3.88s/it]                                                       {'loss': 0.3304, 'grad_norm': 24.995220184326172, 'learning_rate': 8.624583048320373e-08, 'rewards/chosen': 2.150927782058716, 'rewards/rejected': -0.8207031488418579, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.9671874046325684, 'logps/chosen': -432.70001220703125, 'logps/rejected': -235.60000610351562, 'logits/chosen': -7.099999904632568, 'logits/rejected': -6.974999904632568, 'epoch': 1.51}
 50%|█████     | 2290/4545 [2:28:11<2:25:47,  3.88s/it] 50%|█████     | 2291/4545 [2:28:14<2:21:16,  3.76s/it] 50%|█████     | 2292/4545 [2:28:18<2:17:45,  3.67s/it] 50%|█████     | 2293/4545 [2:28:22<2:23:04,  3.81s/it] 50%|█████     | 2294/4545 [2:28:26<2:24:38,  3.86s/it] 50%|█████     | 2295/4545 [2:28:30<2:25:19,  3.88s/it] 51%|█████     | 2296/4545 [2:28:34<2:25:24,  3.88s/it] 51%|█████     | 2297/4545 [2:28:37<2:22:25,  3.80s/it] 51%|█████     | 2298/4545 [2:28:41<2:25:56,  3.90s/it] 51%|█████     | 2299/4545 [2:28:45<2:25:54,  3.90s/it] 51%|█████     | 2300/4545 [2:28:49<2:28:15,  3.96s/it]                                                       {'loss': 0.3173, 'grad_norm': 26.753597259521484, 'learning_rate': 8.590850618124714e-08, 'rewards/chosen': 1.8898437023162842, 'rewards/rejected': -0.946582019329071, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.8304686546325684, 'logps/chosen': -399.5, 'logps/rejected': -200.625, 'logits/chosen': -7.106249809265137, 'logits/rejected': -6.943749904632568, 'epoch': 1.52}
 51%|█████     | 2300/4545 [2:28:49<2:28:15,  3.96s/it] 51%|█████     | 2301/4545 [2:28:54<2:29:50,  4.01s/it] 51%|█████     | 2302/4545 [2:28:57<2:28:44,  3.98s/it] 51%|█████     | 2303/4545 [2:29:01<2:27:02,  3.94s/it] 51%|█████     | 2304/4545 [2:29:04<2:18:53,  3.72s/it] 51%|█████     | 2305/4545 [2:29:08<2:17:34,  3.69s/it] 51%|█████     | 2306/4545 [2:29:11<2:14:03,  3.59s/it] 51%|█████     | 2307/4545 [2:29:15<2:17:54,  3.70s/it] 51%|█████     | 2308/4545 [2:29:19<2:19:47,  3.75s/it] 51%|█████     | 2309/4545 [2:29:23<2:19:18,  3.74s/it] 51%|█████     | 2310/4545 [2:29:26<2:14:22,  3.61s/it]                                                       {'loss': 0.4134, 'grad_norm': 24.524320602416992, 'learning_rate': 8.556786139063679e-08, 'rewards/chosen': 1.346704125404358, 'rewards/rejected': -0.6488281488418579, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.995703101158142, 'logps/chosen': -293.375, 'logps/rejected': -185.10000610351562, 'logits/chosen': -7.256249904632568, 'logits/rejected': -6.928124904632568, 'epoch': 1.52}
 51%|█████     | 2310/4545 [2:29:26<2:14:22,  3.61s/it] 51%|█████     | 2311/4545 [2:29:30<2:17:41,  3.70s/it] 51%|█████     | 2312/4545 [2:29:34<2:19:49,  3.76s/it] 51%|█████     | 2313/4545 [2:29:38<2:21:19,  3.80s/it] 51%|█████     | 2314/4545 [2:29:42<2:18:26,  3.72s/it] 51%|█████     | 2315/4545 [2:29:46<2:23:45,  3.87s/it] 51%|█████     | 2316/4545 [2:29:50<2:24:03,  3.88s/it] 51%|█████     | 2317/4545 [2:29:53<2:19:39,  3.76s/it] 51%|█████     | 2318/4545 [2:29:57<2:21:19,  3.81s/it] 51%|█████     | 2319/4545 [2:30:01<2:25:30,  3.92s/it] 51%|█████     | 2320/4545 [2:30:05<2:26:24,  3.95s/it]                                                       {'loss': 0.3537, 'grad_norm': 20.324970245361328, 'learning_rate': 8.522393270670845e-08, 'rewards/chosen': 2.0420899391174316, 'rewards/rejected': -0.7416015863418579, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.785937547683716, 'logps/chosen': -424.20001220703125, 'logps/rejected': -254.5500030517578, 'logits/chosen': -7.078125, 'logits/rejected': -6.765625, 'epoch': 1.53}
 51%|█████     | 2320/4545 [2:30:05<2:26:24,  3.95s/it] 51%|█████     | 2321/4545 [2:30:09<2:22:00,  3.83s/it] 51%|█████     | 2322/4545 [2:30:13<2:22:48,  3.85s/it] 51%|█████     | 2323/4545 [2:30:17<2:23:28,  3.87s/it] 51%|█████     | 2324/4545 [2:30:21<2:23:50,  3.89s/it] 51%|█████     | 2325/4545 [2:30:24<2:24:11,  3.90s/it] 51%|█████     | 2326/4545 [2:30:29<2:27:29,  3.99s/it] 51%|█████     | 2327/4545 [2:30:33<2:26:41,  3.97s/it] 51%|█████     | 2328/4545 [2:30:36<2:25:59,  3.95s/it] 51%|█████     | 2329/4545 [2:30:41<2:27:53,  4.00s/it] 51%|█████▏    | 2330/4545 [2:30:45<2:26:35,  3.97s/it]                                                       {'loss': 0.3439, 'grad_norm': 16.74676513671875, 'learning_rate': 8.48767570775853e-08, 'rewards/chosen': 2.284716844558716, 'rewards/rejected': -0.7430664300918579, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.03125, 'logps/chosen': -484.8500061035156, 'logps/rejected': -251.9499969482422, 'logits/chosen': -6.831250190734863, 'logits/rejected': -6.746874809265137, 'epoch': 1.54}
 51%|█████▏    | 2330/4545 [2:30:45<2:26:35,  3.97s/it] 51%|█████▏    | 2331/4545 [2:30:48<2:26:04,  3.96s/it] 51%|█████▏    | 2332/4545 [2:30:52<2:24:59,  3.93s/it] 51%|█████▏    | 2333/4545 [2:30:56<2:26:42,  3.98s/it] 51%|█████▏    | 2334/4545 [2:30:59<2:16:46,  3.71s/it] 51%|█████▏    | 2335/4545 [2:31:03<2:18:55,  3.77s/it] 51%|█████▏    | 2336/4545 [2:31:07<2:15:17,  3.67s/it] 51%|█████▏    | 2337/4545 [2:31:09<2:01:01,  3.29s/it] 51%|█████▏    | 2338/4545 [2:31:13<2:09:07,  3.51s/it] 51%|█████▏    | 2339/4545 [2:31:17<2:14:20,  3.65s/it] 51%|█████▏    | 2340/4545 [2:31:21<2:17:06,  3.73s/it]                                                       {'loss': 0.3063, 'grad_norm': 20.296842575073242, 'learning_rate': 8.452637180020848e-08, 'rewards/chosen': 1.3251953125, 'rewards/rejected': -1.097753882408142, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.4195313453674316, 'logps/chosen': -281.1499938964844, 'logps/rejected': -178.0749969482422, 'logits/chosen': -7.337500095367432, 'logits/rejected': -7.084374904632568, 'epoch': 1.54}
 51%|█████▏    | 2340/4545 [2:31:21<2:17:06,  3.73s/it] 52%|█████▏    | 2341/4545 [2:31:25<2:18:58,  3.78s/it] 52%|█████▏    | 2342/4545 [2:31:29<2:22:08,  3.87s/it] 52%|█████▏    | 2343/4545 [2:31:33<2:24:21,  3.93s/it] 52%|█████▏    | 2344/4545 [2:31:37<2:24:01,  3.93s/it] 52%|█████▏    | 2345/4545 [2:31:41<2:23:54,  3.92s/it] 52%|█████▏    | 2346/4545 [2:31:45<2:23:34,  3.92s/it] 52%|█████▏    | 2347/4545 [2:31:49<2:25:25,  3.97s/it] 52%|█████▏    | 2348/4545 [2:31:53<2:25:04,  3.96s/it] 52%|█████▏    | 2349/4545 [2:31:57<2:24:31,  3.95s/it] 52%|█████▏    | 2350/4545 [2:32:01<2:21:13,  3.86s/it]                                                       {'loss': 0.3152, 'grad_norm': 26.404312133789062, 'learning_rate': 8.417281451633048e-08, 'rewards/chosen': 1.660253882408142, 'rewards/rejected': -0.953320324420929, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.612499952316284, 'logps/chosen': -355.70001220703125, 'logps/rejected': -218.5500030517578, 'logits/chosen': -7.140625, 'logits/rejected': -6.759375095367432, 'epoch': 1.55}
 52%|█████▏    | 2350/4545 [2:32:01<2:21:13,  3.86s/it] 52%|█████▏    | 2351/4545 [2:32:04<2:21:40,  3.87s/it] 52%|█████▏    | 2352/4545 [2:32:08<2:19:39,  3.82s/it] 52%|█████▏    | 2353/4545 [2:32:11<2:08:49,  3.53s/it] 52%|█████▏    | 2354/4545 [2:32:15<2:15:50,  3.72s/it] 52%|█████▏    | 2355/4545 [2:32:19<2:17:13,  3.76s/it] 52%|█████▏    | 2356/4545 [2:32:23<2:21:37,  3.88s/it] 52%|█████▏    | 2357/4545 [2:32:26<2:08:53,  3.53s/it] 52%|█████▏    | 2358/4545 [2:32:29<2:08:42,  3.53s/it] 52%|█████▏    | 2359/4545 [2:32:33<2:12:39,  3.64s/it] 52%|█████▏    | 2360/4545 [2:32:36<2:04:10,  3.41s/it]                                                       {'loss': 0.3501, 'grad_norm': 17.932090759277344, 'learning_rate': 8.381612320847114e-08, 'rewards/chosen': 0.5057617425918579, 'rewards/rejected': -1.441796898841858, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 1.947265625, 'logps/chosen': -157.5, 'logps/rejected': -116.9749984741211, 'logits/chosen': -7.412499904632568, 'logits/rejected': -7.0625, 'epoch': 1.56}
 52%|█████▏    | 2360/4545 [2:32:36<2:04:10,  3.41s/it] 52%|█████▏    | 2361/4545 [2:32:40<2:09:47,  3.57s/it] 52%|█████▏    | 2362/4545 [2:32:44<2:13:17,  3.66s/it] 52%|█████▏    | 2363/4545 [2:32:47<2:07:13,  3.50s/it] 52%|█████▏    | 2364/4545 [2:32:51<2:11:33,  3.62s/it] 52%|█████▏    | 2365/4545 [2:32:54<2:05:05,  3.44s/it] 52%|█████▏    | 2366/4545 [2:32:58<2:13:20,  3.67s/it] 52%|█████▏    | 2367/4545 [2:33:01<2:02:28,  3.37s/it] 52%|█████▏    | 2368/4545 [2:33:05<2:08:11,  3.53s/it] 52%|█████▏    | 2369/4545 [2:33:09<2:12:21,  3.65s/it] 52%|█████▏    | 2370/4545 [2:33:11<1:59:28,  3.30s/it]                                                       {'loss': 0.3694, 'grad_norm': 11.141157150268555, 'learning_rate': 8.345633619583724e-08, 'rewards/chosen': 1.1003906726837158, 'rewards/rejected': -0.8589111566543579, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.958593726158142, 'logps/chosen': -238.10000610351562, 'logps/rejected': -170.8000030517578, 'logits/chosen': -7.356249809265137, 'logits/rejected': -7.150000095367432, 'epoch': 1.56}
 52%|█████▏    | 2370/4545 [2:33:11<1:59:28,  3.30s/it] 52%|█████▏    | 2371/4545 [2:33:15<2:06:15,  3.48s/it] 52%|█████▏    | 2372/4545 [2:33:19<2:12:56,  3.67s/it] 52%|█████▏    | 2373/4545 [2:33:23<2:14:21,  3.71s/it] 52%|█████▏    | 2374/4545 [2:33:26<2:04:51,  3.45s/it] 52%|█████▏    | 2375/4545 [2:33:29<2:02:20,  3.38s/it] 52%|█████▏    | 2376/4545 [2:33:33<2:09:29,  3.58s/it] 52%|█████▏    | 2377/4545 [2:33:37<2:14:39,  3.73s/it] 52%|█████▏    | 2378/4545 [2:33:41<2:19:10,  3.85s/it] 52%|█████▏    | 2379/4545 [2:33:45<2:18:08,  3.83s/it] 52%|█████▏    | 2380/4545 [2:33:49<2:19:07,  3.86s/it]                                                       {'loss': 0.2715, 'grad_norm': 29.103260040283203, 'learning_rate': 8.309349213020597e-08, 'rewards/chosen': 0.86474609375, 'rewards/rejected': -1.832421898841858, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 2.694531202316284, 'logps/chosen': -229.8000030517578, 'logps/rejected': -147.39999389648438, 'logits/chosen': -7.153124809265137, 'logits/rejected': -7.025000095367432, 'epoch': 1.57}
 52%|█████▏    | 2380/4545 [2:33:49<2:19:07,  3.86s/it] 52%|█████▏    | 2381/4545 [2:33:52<2:08:54,  3.57s/it] 52%|█████▏    | 2382/4545 [2:33:56<2:12:32,  3.68s/it] 52%|█████▏    | 2383/4545 [2:34:00<2:17:01,  3.80s/it] 52%|█████▏    | 2384/4545 [2:34:04<2:20:34,  3.90s/it] 52%|█████▏    | 2385/4545 [2:34:07<2:12:44,  3.69s/it] 52%|█████▏    | 2386/4545 [2:34:11<2:08:36,  3.57s/it] 53%|█████▎    | 2387/4545 [2:34:15<2:12:29,  3.68s/it] 53%|█████▎    | 2388/4545 [2:34:19<2:14:50,  3.75s/it] 53%|█████▎    | 2389/4545 [2:34:22<2:16:19,  3.79s/it] 53%|█████▎    | 2390/4545 [2:34:26<2:15:12,  3.76s/it]                                                       {'loss': 0.3566, 'grad_norm': 26.279172897338867, 'learning_rate': 8.272762999177247e-08, 'rewards/chosen': 1.4292480945587158, 'rewards/rejected': -0.9429687261581421, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.3726563453674316, 'logps/chosen': -300.5, 'logps/rejected': -220.5, 'logits/chosen': -7.206250190734863, 'logits/rejected': -7.140625, 'epoch': 1.58}
 53%|█████▎    | 2390/4545 [2:34:26<2:15:12,  3.76s/it] 53%|█████▎    | 2391/4545 [2:34:30<2:13:20,  3.71s/it] 53%|█████▎    | 2392/4545 [2:34:33<2:11:22,  3.66s/it] 53%|█████▎    | 2393/4545 [2:34:37<2:09:55,  3.62s/it] 53%|█████▎    | 2394/4545 [2:34:41<2:14:45,  3.76s/it] 53%|█████▎    | 2395/4545 [2:34:45<2:16:17,  3.80s/it] 53%|█████▎    | 2396/4545 [2:34:48<2:09:51,  3.63s/it] 53%|█████▎    | 2397/4545 [2:34:51<2:08:09,  3.58s/it] 53%|█████▎    | 2398/4545 [2:34:55<2:04:46,  3.49s/it] 53%|█████▎    | 2399/4545 [2:34:59<2:09:22,  3.62s/it] 53%|█████▎    | 2400/4545 [2:35:03<2:15:47,  3.80s/it]                                                       {'loss': 0.3242, 'grad_norm': 22.778059005737305, 'learning_rate': 8.23587890849623e-08, 'rewards/chosen': 1.0493652820587158, 'rewards/rejected': -1.2940185070037842, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.3453125953674316, 'logps/chosen': -241.0500030517578, 'logps/rejected': -150.875, 'logits/chosen': -7.328125, 'logits/rejected': -7.284375190734863, 'epoch': 1.58}
 53%|█████▎    | 2400/4545 [2:35:03<2:15:47,  3.80s/it] 53%|█████▎    | 2401/4545 [2:35:07<2:17:39,  3.85s/it] 53%|█████▎    | 2402/4545 [2:35:11<2:18:17,  3.87s/it] 53%|█████▎    | 2403/4545 [2:35:15<2:18:31,  3.88s/it] 53%|█████▎    | 2404/4545 [2:35:19<2:18:45,  3.89s/it] 53%|█████▎    | 2405/4545 [2:35:22<2:18:51,  3.89s/it] 53%|█████▎    | 2406/4545 [2:35:26<2:18:19,  3.88s/it] 53%|█████▎    | 2407/4545 [2:35:29<2:08:40,  3.61s/it] 53%|█████▎    | 2408/4545 [2:35:33<2:10:41,  3.67s/it] 53%|█████▎    | 2409/4545 [2:35:37<2:16:26,  3.83s/it] 53%|█████▎    | 2410/4545 [2:35:41<2:17:13,  3.86s/it]                                                       {'loss': 0.2719, 'grad_norm': 9.31467056274414, 'learning_rate': 8.198700903420888e-08, 'rewards/chosen': 1.720361351966858, 'rewards/rejected': -1.543603539466858, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.2632813453674316, 'logps/chosen': -349.54998779296875, 'logps/rejected': -204.3000030517578, 'logits/chosen': -7.324999809265137, 'logits/rejected': -7.025000095367432, 'epoch': 1.59}
 53%|█████▎    | 2410/4545 [2:35:41<2:17:13,  3.86s/it] 53%|█████▎    | 2411/4545 [2:35:45<2:16:57,  3.85s/it] 53%|█████▎    | 2412/4545 [2:35:49<2:17:22,  3.86s/it] 53%|█████▎    | 2413/4545 [2:35:53<2:17:40,  3.87s/it] 53%|█████▎    | 2414/4545 [2:35:57<2:20:37,  3.96s/it] 53%|█████▎    | 2415/4545 [2:36:01<2:19:01,  3.92s/it] 53%|█████▎    | 2416/4545 [2:36:04<2:15:59,  3.83s/it] 53%|█████▎    | 2417/4545 [2:36:09<2:18:40,  3.91s/it] 53%|█████▎    | 2418/4545 [2:36:12<2:18:32,  3.91s/it] 53%|█████▎    | 2419/4545 [2:36:16<2:10:35,  3.69s/it] 53%|█████▎    | 2420/4545 [2:36:19<2:04:33,  3.52s/it]                                                       {'loss': 0.3303, 'grad_norm': 16.048025131225586, 'learning_rate': 8.161232977969675e-08, 'rewards/chosen': 0.7804199457168579, 'rewards/rejected': -1.165624976158142, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9460937976837158, 'logps/chosen': -209.5500030517578, 'logps/rejected': -143.3000030517578, 'logits/chosen': -7.434374809265137, 'logits/rejected': -7.106249809265137, 'epoch': 1.6}
 53%|█████▎    | 2420/4545 [2:36:19<2:04:33,  3.52s/it] 53%|█████▎    | 2421/4545 [2:36:22<2:06:37,  3.58s/it] 53%|█████▎    | 2422/4545 [2:36:26<2:10:04,  3.68s/it] 53%|█████▎    | 2423/4545 [2:36:30<2:12:32,  3.75s/it] 53%|█████▎    | 2424/4545 [2:36:34<2:14:07,  3.79s/it] 53%|█████▎    | 2425/4545 [2:36:37<2:04:28,  3.52s/it] 53%|█████▎    | 2426/4545 [2:36:41<2:09:32,  3.67s/it] 53%|█████▎    | 2427/4545 [2:36:45<2:12:00,  3.74s/it] 53%|█████▎    | 2428/4545 [2:36:48<1:59:40,  3.39s/it] 53%|█████▎    | 2429/4545 [2:36:52<2:05:22,  3.56s/it] 53%|█████▎    | 2430/4545 [2:36:55<2:05:45,  3.57s/it]                                                       {'loss': 0.3469, 'grad_norm': 25.846267700195312, 'learning_rate': 8.123479157307072e-08, 'rewards/chosen': 1.2890625, 'rewards/rejected': -0.9847656488418579, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.27734375, 'logps/chosen': -275.8999938964844, 'logps/rejected': -161.60000610351562, 'logits/chosen': -7.290625095367432, 'logits/rejected': -7.15625, 'epoch': 1.6}
 53%|█████▎    | 2430/4545 [2:36:55<2:05:45,  3.57s/it] 53%|█████▎    | 2431/4545 [2:36:59<2:09:22,  3.67s/it] 54%|█████▎    | 2432/4545 [2:37:03<2:11:46,  3.74s/it] 54%|█████▎    | 2433/4545 [2:37:07<2:10:08,  3.70s/it] 54%|█████▎    | 2434/4545 [2:37:11<2:13:40,  3.80s/it] 54%|█████▎    | 2435/4545 [2:37:14<2:05:23,  3.57s/it] 54%|█████▎    | 2436/4545 [2:37:16<1:57:27,  3.34s/it] 54%|█████▎    | 2437/4545 [2:37:20<2:03:20,  3.51s/it] 54%|█████▎    | 2438/4545 [2:37:24<2:06:03,  3.59s/it] 54%|█████▎    | 2439/4545 [2:37:28<2:06:50,  3.61s/it] 54%|█████▎    | 2440/4545 [2:37:32<2:09:21,  3.69s/it]                                                       {'loss': 0.4208, 'grad_norm': 18.442520141601562, 'learning_rate': 8.085443497311178e-08, 'rewards/chosen': 0.7335205078125, 'rewards/rejected': -1.233007788658142, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.966406226158142, 'logps/chosen': -189.8249969482422, 'logps/rejected': -150.27499389648438, 'logits/chosen': -7.556250095367432, 'logits/rejected': -7.309374809265137, 'epoch': 1.61}
 54%|█████▎    | 2440/4545 [2:37:32<2:09:21,  3.69s/it] 54%|█████▎    | 2441/4545 [2:37:36<2:11:57,  3.76s/it] 54%|█████▎    | 2442/4545 [2:37:39<2:10:45,  3.73s/it] 54%|█████▍    | 2443/4545 [2:37:43<2:12:56,  3.79s/it] 54%|█████▍    | 2444/4545 [2:37:47<2:10:46,  3.73s/it] 54%|█████▍    | 2445/4545 [2:37:51<2:12:25,  3.78s/it] 54%|█████▍    | 2446/4545 [2:37:54<2:12:45,  3.79s/it] 54%|█████▍    | 2447/4545 [2:37:58<2:14:09,  3.84s/it] 54%|█████▍    | 2448/4545 [2:38:02<2:16:28,  3.90s/it] 54%|█████▍    | 2449/4545 [2:38:06<2:16:32,  3.91s/it] 54%|█████▍    | 2450/4545 [2:38:10<2:16:22,  3.91s/it]                                                       {'loss': 0.3588, 'grad_norm': 12.225866317749023, 'learning_rate': 8.047130084137973e-08, 'rewards/chosen': 1.4563720226287842, 'rewards/rejected': -1.0697479248046875, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.526562452316284, 'logps/chosen': -333.25, 'logps/rejected': -219.1999969482422, 'logits/chosen': -7.300000190734863, 'logits/rejected': -7.121874809265137, 'epoch': 1.62}
 54%|█████▍    | 2450/4545 [2:38:10<2:16:22,  3.91s/it] 54%|█████▍    | 2451/4545 [2:38:14<2:10:18,  3.73s/it] 54%|█████▍    | 2452/4545 [2:38:17<2:06:37,  3.63s/it] 54%|█████▍    | 2453/4545 [2:38:21<2:11:22,  3.77s/it] 54%|█████▍    | 2454/4545 [2:38:25<2:12:39,  3.81s/it] 54%|█████▍    | 2455/4545 [2:38:29<2:13:45,  3.84s/it] 54%|█████▍    | 2456/4545 [2:38:33<2:14:43,  3.87s/it] 54%|█████▍    | 2457/4545 [2:38:37<2:14:53,  3.88s/it] 54%|█████▍    | 2458/4545 [2:38:41<2:15:25,  3.89s/it] 54%|█████▍    | 2459/4545 [2:38:45<2:16:20,  3.92s/it] 54%|█████▍    | 2460/4545 [2:38:49<2:18:01,  3.97s/it]                                                       {'loss': 0.3789, 'grad_norm': 19.472816467285156, 'learning_rate': 8.008543033782354e-08, 'rewards/chosen': 1.757665991783142, 'rewards/rejected': -0.8408203125, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.600781202316284, 'logps/chosen': -384.45001220703125, 'logps/rejected': -222.1999969482422, 'logits/chosen': -7.053124904632568, 'logits/rejected': -7.112500190734863, 'epoch': 1.62}
 54%|█████▍    | 2460/4545 [2:38:49<2:18:01,  3.97s/it] 54%|█████▍    | 2461/4545 [2:38:52<2:15:08,  3.89s/it] 54%|█████▍    | 2462/4545 [2:38:55<1:58:52,  3.42s/it] 54%|█████▍    | 2463/4545 [2:38:59<2:03:55,  3.57s/it] 54%|█████▍    | 2464/4545 [2:39:03<2:08:16,  3.70s/it] 54%|█████▍    | 2465/4545 [2:39:06<2:04:15,  3.58s/it] 54%|█████▍    | 2466/4545 [2:39:10<2:04:57,  3.61s/it] 54%|█████▍    | 2467/4545 [2:39:14<2:11:38,  3.80s/it] 54%|█████▍    | 2468/4545 [2:39:18<2:14:17,  3.88s/it] 54%|█████▍    | 2469/4545 [2:39:22<2:14:24,  3.88s/it] 54%|█████▍    | 2470/4545 [2:39:26<2:11:53,  3.81s/it]                                                       {'loss': 0.3131, 'grad_norm': 19.88862419128418, 'learning_rate': 7.969686491635956e-08, 'rewards/chosen': 0.7401183843612671, 'rewards/rejected': -1.572656273841858, 'rewards/accuracies': 0.875, 'rewards/margins': 2.311718702316284, 'logps/chosen': -206.8000030517578, 'logps/rejected': -157.5, 'logits/chosen': -7.309374809265137, 'logits/rejected': -7.074999809265137, 'epoch': 1.63}
 54%|█████▍    | 2470/4545 [2:39:26<2:11:53,  3.81s/it] 54%|█████▍    | 2471/4545 [2:39:29<2:12:45,  3.84s/it] 54%|█████▍    | 2472/4545 [2:39:33<2:13:39,  3.87s/it] 54%|█████▍    | 2473/4545 [2:39:37<2:13:16,  3.86s/it] 54%|█████▍    | 2474/4545 [2:39:41<2:12:21,  3.83s/it] 54%|█████▍    | 2475/4545 [2:39:45<2:13:20,  3.86s/it] 54%|█████▍    | 2476/4545 [2:39:48<2:07:32,  3.70s/it] 54%|█████▍    | 2477/4545 [2:39:52<2:04:28,  3.61s/it] 55%|█████▍    | 2478/4545 [2:39:55<2:04:29,  3.61s/it] 55%|█████▍    | 2479/4545 [2:39:59<2:02:45,  3.57s/it] 55%|█████▍    | 2480/4545 [2:40:03<2:09:14,  3.76s/it]                                                       {'loss': 0.4142, 'grad_norm': 20.82682991027832, 'learning_rate': 7.930564632041805e-08, 'rewards/chosen': 0.534252941608429, 'rewards/rejected': -1.1171875, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.6515624523162842, 'logps/chosen': -150.85000610351562, 'logps/rejected': -109.625, 'logits/chosen': -7.481249809265137, 'logits/rejected': -7.246874809265137, 'epoch': 1.64}
 55%|█████▍    | 2480/4545 [2:40:03<2:09:14,  3.76s/it] 55%|█████▍    | 2481/4545 [2:40:07<2:13:12,  3.87s/it] 55%|█████▍    | 2482/4545 [2:40:11<2:11:40,  3.83s/it] 55%|█████▍    | 2483/4545 [2:40:15<2:12:01,  3.84s/it] 55%|█████▍    | 2484/4545 [2:40:19<2:12:38,  3.86s/it] 55%|█████▍    | 2485/4545 [2:40:22<2:12:55,  3.87s/it] 55%|█████▍    | 2486/4545 [2:40:25<1:58:20,  3.45s/it] 55%|█████▍    | 2487/4545 [2:40:28<1:57:35,  3.43s/it] 55%|█████▍    | 2488/4545 [2:40:31<1:53:49,  3.32s/it] 55%|█████▍    | 2489/4545 [2:40:35<1:57:48,  3.44s/it] 55%|█████▍    | 2490/4545 [2:40:38<1:55:49,  3.38s/it]                                                       {'loss': 0.4011, 'grad_norm': 20.119882583618164, 'learning_rate': 7.891181657845882e-08, 'rewards/chosen': 0.840563952922821, 'rewards/rejected': -1.5219237804412842, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.3636717796325684, 'logps/chosen': -225.0, 'logps/rejected': -143.5, 'logits/chosen': -7.462500095367432, 'logits/rejected': -7.334374904632568, 'epoch': 1.64}
 55%|█████▍    | 2490/4545 [2:40:38<1:55:49,  3.38s/it] 55%|█████▍    | 2491/4545 [2:40:42<2:01:48,  3.56s/it] 55%|█████▍    | 2492/4545 [2:40:46<2:02:20,  3.58s/it] 55%|█████▍    | 2493/4545 [2:40:50<2:05:22,  3.67s/it] 55%|█████▍    | 2494/4545 [2:40:53<2:05:03,  3.66s/it] 55%|█████▍    | 2495/4545 [2:40:57<2:07:33,  3.73s/it] 55%|█████▍    | 2496/4545 [2:41:01<2:09:33,  3.79s/it] 55%|█████▍    | 2497/4545 [2:41:06<2:13:55,  3.92s/it] 55%|█████▍    | 2498/4545 [2:41:09<2:07:53,  3.75s/it] 55%|█████▍    | 2499/4545 [2:41:13<2:09:27,  3.80s/it] 55%|█████▌    | 2500/4545 [2:41:17<2:09:33,  3.80s/it]                                                       {'loss': 0.3974, 'grad_norm': 19.1829833984375, 'learning_rate': 7.851541799945603e-08, 'rewards/chosen': 0.8175048828125, 'rewards/rejected': -1.1526367664337158, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 1.96875, 'logps/chosen': -202.0749969482422, 'logps/rejected': -164.4499969482422, 'logits/chosen': -7.493750095367432, 'logits/rejected': -7.209374904632568, 'epoch': 1.65}
 55%|█████▌    | 2500/4545 [2:41:17<2:09:33,  3.80s/it] 55%|█████▌    | 2501/4545 [2:41:20<2:06:30,  3.71s/it] 55%|█████▌    | 2502/4545 [2:41:24<2:08:44,  3.78s/it] 55%|█████▌    | 2503/4545 [2:41:27<2:00:07,  3.53s/it] 55%|█████▌    | 2504/4545 [2:41:31<2:06:52,  3.73s/it] 55%|█████▌    | 2505/4545 [2:41:35<2:08:36,  3.78s/it] 55%|█████▌    | 2506/4545 [2:41:39<2:09:58,  3.82s/it] 55%|█████▌    | 2507/4545 [2:41:43<2:10:47,  3.85s/it] 55%|█████▌    | 2508/4545 [2:41:47<2:11:08,  3.86s/it] 55%|█████▌    | 2509/4545 [2:41:50<2:03:55,  3.65s/it] 55%|█████▌    | 2510/4545 [2:41:52<1:48:21,  3.19s/it]                                                       {'loss': 0.2861, 'grad_norm': 13.396988868713379, 'learning_rate': 7.811649316835297e-08, 'rewards/chosen': 1.9104492664337158, 'rewards/rejected': -1.402929663658142, 'rewards/accuracies': 0.875, 'rewards/margins': 3.315624952316284, 'logps/chosen': -370.29998779296875, 'logps/rejected': -164.75, 'logits/chosen': -7.128125190734863, 'logits/rejected': -6.996874809265137, 'epoch': 1.66}
 55%|█████▌    | 2510/4545 [2:41:52<1:48:21,  3.19s/it] 55%|█████▌    | 2511/4545 [2:41:55<1:47:43,  3.18s/it] 55%|█████▌    | 2512/4545 [2:41:59<1:57:21,  3.46s/it] 55%|█████▌    | 2513/4545 [2:42:03<2:01:40,  3.59s/it] 55%|█████▌    | 2514/4545 [2:42:07<2:07:14,  3.76s/it] 55%|█████▌    | 2515/4545 [2:42:11<2:09:31,  3.83s/it] 55%|█████▌    | 2516/4545 [2:42:15<2:10:05,  3.85s/it] 55%|█████▌    | 2517/4545 [2:42:19<2:05:43,  3.72s/it] 55%|█████▌    | 2518/4545 [2:42:23<2:07:35,  3.78s/it] 55%|█████▌    | 2519/4545 [2:42:27<2:08:56,  3.82s/it] 55%|█████▌    | 2520/4545 [2:42:30<2:04:43,  3.70s/it]                                                       {'loss': 0.2898, 'grad_norm': 16.877063751220703, 'learning_rate': 7.771508494148728e-08, 'rewards/chosen': 1.7985351085662842, 'rewards/rejected': -1.4296875, 'rewards/accuracies': 0.875, 'rewards/margins': 3.2289061546325684, 'logps/chosen': -389.8500061035156, 'logps/rejected': -188.89999389648438, 'logits/chosen': -7.168749809265137, 'logits/rejected': -6.96875, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [2:42:30<2:04:43,  3.70s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.11s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                       
                                               [A{'eval_loss': 0.4149360656738281, 'eval_runtime': 80.3158, 'eval_samples_per_second': 11.866, 'eval_steps_per_second': 0.747, 'eval_rewards/chosen': 1.5030111074447632, 'eval_rewards/rejected': -0.7520344853401184, 'eval_rewards/accuracies': 0.8026620149612427, 'eval_rewards/margins': 2.2536091804504395, 'eval_logps/chosen': -362.5666809082031, 'eval_logps/rejected': -159.53334045410156, 'eval_logits/chosen': -7.103125095367432, 'eval_logits/rejected': -7.576562404632568, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [2:43:50<2:04:43,  3.70s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 55%|█████▌    | 2521/4545 [2:44:05<17:28:05, 31.07s/it] 55%|█████▌    | 2522/4545 [2:44:09<12:52:53, 22.92s/it] 56%|█████▌    | 2523/4545 [2:44:13<9:40:20, 17.22s/it]  56%|█████▌    | 2524/4545 [2:44:16<7:22:38, 13.14s/it] 56%|█████▌    | 2525/4545 [2:44:19<5:38:42, 10.06s/it] 56%|█████▌    | 2526/4545 [2:44:23<4:39:37,  8.31s/it] 56%|█████▌    | 2527/4545 [2:44:27<3:48:35,  6.80s/it] 56%|█████▌    | 2528/4545 [2:44:30<3:15:08,  5.80s/it] 56%|█████▌    | 2529/4545 [2:44:34<2:57:02,  5.27s/it] 56%|█████▌    | 2530/4545 [2:44:38<2:43:05,  4.86s/it]                                                       {'loss': 0.3869, 'grad_norm': 23.127273559570312, 'learning_rate': 7.731123644198677e-08, 'rewards/chosen': 1.206536889076233, 'rewards/rejected': -1.4031250476837158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.6109375953674316, 'logps/chosen': -290.29998779296875, 'logps/rejected': -204.02499389648438, 'logits/chosen': -7.40625, 'logits/rejected': -7.356249809265137, 'epoch': 1.67}
 56%|█████▌    | 2530/4545 [2:44:38<2:43:05,  4.86s/it] 56%|█████▌    | 2531/4545 [2:44:42<2:33:31,  4.57s/it] 56%|█████▌    | 2532/4545 [2:44:46<2:26:48,  4.38s/it] 56%|█████▌    | 2533/4545 [2:44:50<2:20:11,  4.18s/it] 56%|█████▌    | 2534/4545 [2:44:54<2:19:10,  4.15s/it] 56%|█████▌    | 2535/4545 [2:44:56<2:03:03,  3.67s/it] 56%|█████▌    | 2536/4545 [2:45:00<2:05:41,  3.75s/it] 56%|█████▌    | 2537/4545 [2:45:04<2:07:44,  3.82s/it] 56%|█████▌    | 2538/4545 [2:45:07<1:55:03,  3.44s/it] 56%|█████▌    | 2539/4545 [2:45:11<2:00:20,  3.60s/it] 56%|█████▌    | 2540/4545 [2:45:13<1:50:13,  3.30s/it]                                                       {'loss': 0.3941, 'grad_norm': 21.256601333618164, 'learning_rate': 7.690499105513678e-08, 'rewards/chosen': 1.76806640625, 'rewards/rejected': -0.9955078363418579, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.760937452316284, 'logps/chosen': -346.95001220703125, 'logps/rejected': -174.47500610351562, 'logits/chosen': -7.431250095367432, 'logits/rejected': -7.065625190734863, 'epoch': 1.68}
 56%|█████▌    | 2540/4545 [2:45:13<1:50:13,  3.30s/it] 56%|█████▌    | 2541/4545 [2:45:17<1:56:23,  3.48s/it] 56%|█████▌    | 2542/4545 [2:45:20<1:46:06,  3.18s/it] 56%|█████▌    | 2543/4545 [2:45:24<1:55:07,  3.45s/it] 56%|█████▌    | 2544/4545 [2:45:28<2:01:09,  3.63s/it] 56%|█████▌    | 2545/4545 [2:45:32<2:04:00,  3.72s/it] 56%|█████▌    | 2546/4545 [2:45:34<1:51:47,  3.36s/it] 56%|█████▌    | 2547/4545 [2:45:38<1:59:14,  3.58s/it] 56%|█████▌    | 2548/4545 [2:45:42<2:02:18,  3.67s/it] 56%|█████▌    | 2549/4545 [2:45:46<2:04:35,  3.75s/it] 56%|█████▌    | 2550/4545 [2:45:50<2:05:18,  3.77s/it]                                                       {'loss': 0.3426, 'grad_norm': 17.332496643066406, 'learning_rate': 7.649639242371933e-08, 'rewards/chosen': 0.9471679925918579, 'rewards/rejected': -1.312109351158142, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.2578125, 'logps/chosen': -224.0, 'logps/rejected': -143.60000610351562, 'logits/chosen': -7.471875190734863, 'logits/rejected': -7.224999904632568, 'epoch': 1.68}
 56%|█████▌    | 2550/4545 [2:45:50<2:05:18,  3.77s/it] 56%|█████▌    | 2551/4545 [2:45:54<2:06:53,  3.82s/it] 56%|█████▌    | 2552/4545 [2:45:58<2:10:17,  3.92s/it] 56%|█████▌    | 2553/4545 [2:46:02<2:11:40,  3.97s/it] 56%|█████▌    | 2554/4545 [2:46:06<2:11:04,  3.95s/it] 56%|█████▌    | 2555/4545 [2:46:10<2:10:31,  3.94s/it] 56%|█████▌    | 2556/4545 [2:46:14<2:09:35,  3.91s/it] 56%|█████▋    | 2557/4545 [2:46:18<2:09:32,  3.91s/it] 56%|█████▋    | 2558/4545 [2:46:22<2:10:06,  3.93s/it] 56%|█████▋    | 2559/4545 [2:46:25<2:03:45,  3.74s/it] 56%|█████▋    | 2560/4545 [2:46:29<2:02:54,  3.72s/it]                                                       {'loss': 0.3614, 'grad_norm': 19.274169921875, 'learning_rate': 7.608548444332458e-08, 'rewards/chosen': 1.5606689453125, 'rewards/rejected': -1.161108374595642, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.72265625, 'logps/chosen': -350.75, 'logps/rejected': -209.1999969482422, 'logits/chosen': -7.231249809265137, 'logits/rejected': -7.050000190734863, 'epoch': 1.69}
 56%|█████▋    | 2560/4545 [2:46:29<2:02:54,  3.72s/it] 56%|█████▋    | 2561/4545 [2:46:31<1:50:56,  3.35s/it] 56%|█████▋    | 2562/4545 [2:46:35<1:57:06,  3.54s/it] 56%|█████▋    | 2563/4545 [2:46:37<1:41:07,  3.06s/it] 56%|█████▋    | 2564/4545 [2:46:41<1:51:56,  3.39s/it] 56%|█████▋    | 2565/4545 [2:46:45<1:57:29,  3.56s/it] 56%|█████▋    | 2566/4545 [2:46:49<1:56:16,  3.53s/it] 56%|█████▋    | 2567/4545 [2:46:52<1:58:15,  3.59s/it] 57%|█████▋    | 2568/4545 [2:46:56<1:58:56,  3.61s/it] 57%|█████▋    | 2569/4545 [2:47:00<2:00:02,  3.64s/it] 57%|█████▋    | 2570/4545 [2:47:03<1:51:54,  3.40s/it]                                                       {'loss': 0.3146, 'grad_norm': 29.434354782104492, 'learning_rate': 7.567231125763512e-08, 'rewards/chosen': 0.7300323247909546, 'rewards/rejected': -1.8239257335662842, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 2.553906202316284, 'logps/chosen': -160.5749969482422, 'logps/rejected': -131.85000610351562, 'logits/chosen': -7.590624809265137, 'logits/rejected': -7.134375095367432, 'epoch': 1.7}
 57%|█████▋    | 2570/4545 [2:47:03<1:51:54,  3.40s/it] 57%|█████▋    | 2571/4545 [2:47:06<1:55:04,  3.50s/it] 57%|█████▋    | 2572/4545 [2:47:10<1:56:32,  3.54s/it] 57%|█████▋    | 2573/4545 [2:47:13<1:54:16,  3.48s/it] 57%|█████▋    | 2574/4545 [2:47:17<2:00:31,  3.67s/it] 57%|█████▋    | 2575/4545 [2:47:21<2:02:52,  3.74s/it] 57%|█████▋    | 2576/4545 [2:47:25<2:02:52,  3.74s/it] 57%|█████▋    | 2577/4545 [2:47:29<2:04:22,  3.79s/it] 57%|█████▋    | 2578/4545 [2:47:33<2:05:06,  3.82s/it] 57%|█████▋    | 2579/4545 [2:47:37<2:04:34,  3.80s/it] 57%|█████▋    | 2580/4545 [2:47:41<2:05:36,  3.84s/it]                                                       {'loss': 0.2685, 'grad_norm': 14.712851524353027, 'learning_rate': 7.52569172536837e-08, 'rewards/chosen': 1.14501953125, 'rewards/rejected': -2.2342772483825684, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.3765625953674316, 'logps/chosen': -257.5, 'logps/rejected': -147.5749969482422, 'logits/chosen': -7.546875, 'logits/rejected': -7.353125095367432, 'epoch': 1.7}
 57%|█████▋    | 2580/4545 [2:47:41<2:05:36,  3.84s/it] 57%|█████▋    | 2581/4545 [2:47:45<2:09:14,  3.95s/it] 57%|█████▋    | 2582/4545 [2:47:49<2:08:36,  3.93s/it] 57%|█████▋    | 2583/4545 [2:47:53<2:08:19,  3.92s/it] 57%|█████▋    | 2584/4545 [2:47:56<2:04:37,  3.81s/it] 57%|█████▋    | 2585/4545 [2:48:00<2:03:22,  3.78s/it] 57%|█████▋    | 2586/4545 [2:48:04<2:04:42,  3.82s/it] 57%|█████▋    | 2587/4545 [2:48:07<1:56:57,  3.58s/it] 57%|█████▋    | 2588/4545 [2:48:11<2:00:02,  3.68s/it] 57%|█████▋    | 2589/4545 [2:48:15<2:03:41,  3.79s/it] 57%|█████▋    | 2590/4545 [2:48:19<2:04:39,  3.83s/it]                                                       {'loss': 0.3329, 'grad_norm': 11.533467292785645, 'learning_rate': 7.48393470570846e-08, 'rewards/chosen': 1.303613305091858, 'rewards/rejected': -1.6476562023162842, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.9507813453674316, 'logps/chosen': -278.75, 'logps/rejected': -142.39999389648438, 'logits/chosen': -7.368750095367432, 'logits/rejected': -7.162499904632568, 'epoch': 1.71}
 57%|█████▋    | 2590/4545 [2:48:19<2:04:39,  3.83s/it] 57%|█████▋    | 2591/4545 [2:48:22<2:03:19,  3.79s/it] 57%|█████▋    | 2592/4545 [2:48:26<2:04:40,  3.83s/it] 57%|█████▋    | 2593/4545 [2:48:29<1:57:55,  3.62s/it] 57%|█████▋    | 2594/4545 [2:48:33<2:00:34,  3.71s/it] 57%|█████▋    | 2595/4545 [2:48:37<2:04:06,  3.82s/it] 57%|█████▋    | 2596/4545 [2:48:41<2:05:03,  3.85s/it] 57%|█████▋    | 2597/4545 [2:48:45<2:01:45,  3.75s/it] 57%|█████▋    | 2598/4545 [2:48:49<2:03:14,  3.80s/it] 57%|█████▋    | 2599/4545 [2:48:53<2:05:38,  3.87s/it] 57%|█████▋    | 2600/4545 [2:48:57<2:06:01,  3.89s/it]                                                       {'loss': 0.3191, 'grad_norm': 65.78598022460938, 'learning_rate': 7.441964552723977e-08, 'rewards/chosen': 2.172607421875, 'rewards/rejected': -1.445410132408142, 'rewards/accuracies': 0.875, 'rewards/margins': 3.616406202316284, 'logps/chosen': -445.3999938964844, 'logps/rejected': -250.0, 'logits/chosen': -7.121874809265137, 'logits/rejected': -6.993750095367432, 'epoch': 1.72}
 57%|█████▋    | 2600/4545 [2:48:57<2:06:01,  3.89s/it] 57%|█████▋    | 2601/4545 [2:49:01<2:08:12,  3.96s/it] 57%|█████▋    | 2602/4545 [2:49:04<2:05:20,  3.87s/it] 57%|█████▋    | 2603/4545 [2:49:08<2:02:10,  3.77s/it] 57%|█████▋    | 2604/4545 [2:49:12<2:03:28,  3.82s/it] 57%|█████▋    | 2605/4545 [2:49:16<2:05:28,  3.88s/it] 57%|█████▋    | 2606/4545 [2:49:20<2:05:56,  3.90s/it] 57%|█████▋    | 2607/4545 [2:49:24<2:05:56,  3.90s/it] 57%|█████▋    | 2608/4545 [2:49:26<1:52:01,  3.47s/it] 57%|█████▋    | 2609/4545 [2:49:30<1:54:19,  3.54s/it] 57%|█████▋    | 2610/4545 [2:49:34<1:57:56,  3.66s/it]                                                       {'loss': 0.3341, 'grad_norm': 20.977548599243164, 'learning_rate': 7.399785775251933e-08, 'rewards/chosen': 0.612744152545929, 'rewards/rejected': -1.6433594226837158, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.2554688453674316, 'logps/chosen': -169.14999389648438, 'logps/rejected': -162.25, 'logits/chosen': -7.559374809265137, 'logits/rejected': -7.284375190734863, 'epoch': 1.72}
 57%|█████▋    | 2610/4545 [2:49:34<1:57:56,  3.66s/it] 57%|█████▋    | 2611/4545 [2:49:38<2:00:21,  3.73s/it] 57%|█████▋    | 2612/4545 [2:49:42<2:01:50,  3.78s/it] 57%|█████▋    | 2613/4545 [2:49:46<2:05:59,  3.91s/it] 58%|█████▊    | 2614/4545 [2:49:50<2:07:53,  3.97s/it] 58%|█████▊    | 2615/4545 [2:49:54<2:07:08,  3.95s/it] 58%|█████▊    | 2616/4545 [2:49:58<2:06:43,  3.94s/it] 58%|█████▊    | 2617/4545 [2:50:01<1:59:41,  3.72s/it] 58%|█████▊    | 2618/4545 [2:50:05<2:01:19,  3.78s/it] 58%|█████▊    | 2619/4545 [2:50:09<1:59:34,  3.72s/it] 58%|█████▊    | 2620/4545 [2:50:11<1:50:10,  3.43s/it]                                                       {'loss': 0.3094, 'grad_norm': 16.416013717651367, 'learning_rate': 7.357402904541789e-08, 'rewards/chosen': 1.84716796875, 'rewards/rejected': -1.0734131336212158, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.9195313453674316, 'logps/chosen': -347.625, 'logps/rejected': -211.75, 'logits/chosen': -7.465624809265137, 'logits/rejected': -6.987500190734863, 'epoch': 1.73}
 58%|█████▊    | 2620/4545 [2:50:11<1:50:10,  3.43s/it] 58%|█████▊    | 2621/4545 [2:50:15<1:48:02,  3.37s/it] 58%|█████▊    | 2622/4545 [2:50:19<1:54:20,  3.57s/it] 58%|█████▊    | 2623/4545 [2:50:22<1:51:57,  3.50s/it] 58%|█████▊    | 2624/4545 [2:50:26<1:57:33,  3.67s/it] 58%|█████▊    | 2625/4545 [2:50:30<1:59:42,  3.74s/it] 58%|█████▊    | 2626/4545 [2:50:34<2:01:21,  3.79s/it] 58%|█████▊    | 2627/4545 [2:50:38<2:04:30,  3.90s/it] 58%|█████▊    | 2628/4545 [2:50:40<1:49:58,  3.44s/it] 58%|█████▊    | 2629/4545 [2:50:44<1:47:49,  3.38s/it] 58%|█████▊    | 2630/4545 [2:50:47<1:49:03,  3.42s/it]                                                       {'loss': 0.3569, 'grad_norm': 72.42621612548828, 'learning_rate': 7.314820493768666e-08, 'rewards/chosen': 1.3275878429412842, 'rewards/rejected': -1.517578125, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 2.83984375, 'logps/chosen': -312.45001220703125, 'logps/rejected': -168.3000030517578, 'logits/chosen': -7.415625095367432, 'logits/rejected': -7.012499809265137, 'epoch': 1.74}
 58%|█████▊    | 2630/4545 [2:50:47<1:49:03,  3.42s/it] 58%|█████▊    | 2631/4545 [2:50:51<1:53:23,  3.55s/it] 58%|█████▊    | 2632/4545 [2:50:55<1:59:17,  3.74s/it] 58%|█████▊    | 2633/4545 [2:50:59<2:00:09,  3.77s/it] 58%|█████▊    | 2634/4545 [2:51:03<2:01:03,  3.80s/it] 58%|█████▊    | 2635/4545 [2:51:07<2:04:45,  3.92s/it] 58%|█████▊    | 2636/4545 [2:51:10<2:00:03,  3.77s/it] 58%|█████▊    | 2637/4545 [2:51:15<2:04:03,  3.90s/it] 58%|█████▊    | 2638/4545 [2:51:19<2:03:58,  3.90s/it] 58%|█████▊    | 2639/4545 [2:51:22<2:03:52,  3.90s/it] 58%|█████▊    | 2640/4545 [2:51:26<2:03:52,  3.90s/it]                                                       {'loss': 0.3351, 'grad_norm': 19.05561637878418, 'learning_rate': 7.272043117544196e-08, 'rewards/chosen': 1.421142578125, 'rewards/rejected': -1.465673804283142, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.883984327316284, 'logps/chosen': -307.1000061035156, 'logps/rejected': -155.64999389648438, 'logits/chosen': -7.340624809265137, 'logits/rejected': -6.956250190734863, 'epoch': 1.74}
 58%|█████▊    | 2640/4545 [2:51:26<2:03:52,  3.90s/it] 58%|█████▊    | 2641/4545 [2:51:30<2:03:57,  3.91s/it] 58%|█████▊    | 2642/4545 [2:51:34<2:03:48,  3.90s/it] 58%|█████▊    | 2643/4545 [2:51:38<2:01:24,  3.83s/it] 58%|█████▊    | 2644/4545 [2:51:41<1:56:08,  3.67s/it] 58%|█████▊    | 2645/4545 [2:51:45<1:58:28,  3.74s/it] 58%|█████▊    | 2646/4545 [2:51:49<2:00:03,  3.79s/it] 58%|█████▊    | 2647/4545 [2:51:53<2:01:14,  3.83s/it] 58%|█████▊    | 2648/4545 [2:51:57<2:02:02,  3.86s/it] 58%|█████▊    | 2649/4545 [2:52:01<2:02:25,  3.87s/it] 58%|█████▊    | 2650/4545 [2:52:05<2:02:50,  3.89s/it]                                                       {'loss': 0.2566, 'grad_norm': 11.69781494140625, 'learning_rate': 7.229075371425066e-08, 'rewards/chosen': 2.072070360183716, 'rewards/rejected': -1.579833984375, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 3.6484375, 'logps/chosen': -382.79998779296875, 'logps/rejected': -202.9499969482422, 'logits/chosen': -7.206250190734863, 'logits/rejected': -7.196875095367432, 'epoch': 1.75}
 58%|█████▊    | 2650/4545 [2:52:05<2:02:50,  3.89s/it] 58%|█████▊    | 2651/4545 [2:52:08<2:01:23,  3.85s/it] 58%|█████▊    | 2652/4545 [2:52:12<2:01:56,  3.87s/it] 58%|█████▊    | 2653/4545 [2:52:16<2:04:37,  3.95s/it] 58%|█████▊    | 2654/4545 [2:52:20<2:04:04,  3.94s/it] 58%|█████▊    | 2655/4545 [2:52:24<2:02:11,  3.88s/it] 58%|█████▊    | 2656/4545 [2:52:28<2:04:30,  3.95s/it] 58%|█████▊    | 2657/4545 [2:52:32<2:00:57,  3.84s/it] 58%|█████▊    | 2658/4545 [2:52:36<2:01:21,  3.86s/it] 59%|█████▊    | 2659/4545 [2:52:39<2:00:08,  3.82s/it] 59%|█████▊    | 2660/4545 [2:52:43<2:00:45,  3.84s/it]                                                       {'loss': 0.3359, 'grad_norm': 18.094650268554688, 'learning_rate': 7.185921871419329e-08, 'rewards/chosen': 1.4777343273162842, 'rewards/rejected': -1.819921851158142, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.2984375953674316, 'logps/chosen': -348.1000061035156, 'logps/rejected': -197.5500030517578, 'logits/chosen': -7.346875190734863, 'logits/rejected': -7.0625, 'epoch': 1.76}
 59%|█████▊    | 2660/4545 [2:52:43<2:00:45,  3.84s/it] 59%|█████▊    | 2661/4545 [2:52:47<1:56:13,  3.70s/it] 59%|█████▊    | 2662/4545 [2:52:51<1:57:33,  3.75s/it] 59%|█████▊    | 2663/4545 [2:52:54<1:57:12,  3.74s/it] 59%|█████▊    | 2664/4545 [2:52:58<1:58:40,  3.79s/it] 59%|█████▊    | 2665/4545 [2:53:02<1:57:04,  3.74s/it] 59%|█████▊    | 2666/4545 [2:53:06<2:00:36,  3.85s/it] 59%|█████▊    | 2667/4545 [2:53:10<2:03:06,  3.93s/it] 59%|█████▊    | 2668/4545 [2:53:14<2:04:37,  3.98s/it] 59%|█████▊    | 2669/4545 [2:53:18<2:04:25,  3.98s/it] 59%|█████▊    | 2670/4545 [2:53:20<1:47:26,  3.44s/it]                                                       {'loss': 0.39, 'grad_norm': 23.439159393310547, 'learning_rate': 7.142587253490512e-08, 'rewards/chosen': 1.243896484375, 'rewards/rejected': -1.549414038658142, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 2.7890625, 'logps/chosen': -306.54998779296875, 'logps/rejected': -184.85000610351562, 'logits/chosen': -7.525000095367432, 'logits/rejected': -7.340624809265137, 'epoch': 1.76}
 59%|█████▊    | 2670/4545 [2:53:20<1:47:26,  3.44s/it] 59%|█████▉    | 2671/4545 [2:53:23<1:41:13,  3.24s/it] 59%|█████▉    | 2672/4545 [2:53:27<1:47:19,  3.44s/it] 59%|█████▉    | 2673/4545 [2:53:31<1:49:45,  3.52s/it] 59%|█████▉    | 2674/4545 [2:53:35<1:53:14,  3.63s/it] 59%|█████▉    | 2675/4545 [2:53:38<1:55:40,  3.71s/it] 59%|█████▉    | 2676/4545 [2:53:42<1:57:30,  3.77s/it] 59%|█████▉    | 2677/4545 [2:53:46<1:56:50,  3.75s/it] 59%|█████▉    | 2678/4545 [2:53:50<1:58:11,  3.80s/it] 59%|█████▉    | 2679/4545 [2:53:54<1:57:09,  3.77s/it] 59%|█████▉    | 2680/4545 [2:53:58<1:58:31,  3.81s/it]                                                       {'loss': 0.3075, 'grad_norm': 23.918964385986328, 'learning_rate': 7.099076173059557e-08, 'rewards/chosen': 1.5120849609375, 'rewards/rejected': -1.5398437976837158, 'rewards/accuracies': 0.875, 'rewards/margins': 3.0531249046325684, 'logps/chosen': -318.6000061035156, 'logps/rejected': -200.4499969482422, 'logits/chosen': -7.290625095367432, 'logits/rejected': -6.903124809265137, 'epoch': 1.77}
 59%|█████▉    | 2680/4545 [2:53:58<1:58:31,  3.81s/it] 59%|█████▉    | 2681/4545 [2:54:02<1:59:30,  3.85s/it] 59%|█████▉    | 2682/4545 [2:54:06<2:01:07,  3.90s/it] 59%|█████▉    | 2683/4545 [2:54:10<2:02:26,  3.95s/it] 59%|█████▉    | 2684/4545 [2:54:14<2:02:44,  3.96s/it] 59%|█████▉    | 2685/4545 [2:54:18<2:03:34,  3.99s/it] 59%|█████▉    | 2686/4545 [2:54:22<2:05:37,  4.05s/it] 59%|█████▉    | 2687/4545 [2:54:26<2:06:25,  4.08s/it] 59%|█████▉    | 2688/4545 [2:54:30<2:04:27,  4.02s/it] 59%|█████▉    | 2689/4545 [2:54:32<1:50:40,  3.58s/it] 59%|█████▉    | 2690/4545 [2:54:36<1:53:44,  3.68s/it]                                                       {'loss': 0.3737, 'grad_norm': 23.792348861694336, 'learning_rate': 7.055393304504711e-08, 'rewards/chosen': 1.6066405773162842, 'rewards/rejected': -1.199121117591858, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.8046875, 'logps/chosen': -331.1499938964844, 'logps/rejected': -212.75, 'logits/chosen': -7.440625190734863, 'logits/rejected': -7.240624904632568, 'epoch': 1.78}
 59%|█████▉    | 2690/4545 [2:54:36<1:53:44,  3.68s/it] 59%|█████▉    | 2691/4545 [2:54:40<1:56:12,  3.76s/it] 59%|█████▉    | 2692/4545 [2:54:44<1:57:24,  3.80s/it] 59%|█████▉    | 2693/4545 [2:54:48<1:58:24,  3.84s/it] 59%|█████▉    | 2694/4545 [2:54:52<1:57:32,  3.81s/it] 59%|█████▉    | 2695/4545 [2:54:55<1:55:44,  3.75s/it] 59%|█████▉    | 2696/4545 [2:54:58<1:44:07,  3.38s/it] 59%|█████▉    | 2697/4545 [2:55:02<1:49:51,  3.57s/it] 59%|█████▉    | 2698/4545 [2:55:06<1:53:02,  3.67s/it] 59%|█████▉    | 2699/4545 [2:55:09<1:44:59,  3.41s/it] 59%|█████▉    | 2700/4545 [2:55:13<1:50:57,  3.61s/it]                                                       {'loss': 0.3255, 'grad_norm': 19.660341262817383, 'learning_rate': 7.011543340659352e-08, 'rewards/chosen': 1.2357391119003296, 'rewards/rejected': -1.583593726158142, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.8218750953674316, 'logps/chosen': -270.0, 'logps/rejected': -152.5, 'logits/chosen': -7.543749809265137, 'logits/rejected': -7.303124904632568, 'epoch': 1.78}
 59%|█████▉    | 2700/4545 [2:55:13<1:50:57,  3.61s/it] 59%|█████▉    | 2701/4545 [2:55:16<1:48:17,  3.52s/it] 59%|█████▉    | 2702/4545 [2:55:19<1:43:35,  3.37s/it] 59%|█████▉    | 2703/4545 [2:55:23<1:51:38,  3.64s/it] 59%|█████▉    | 2704/4545 [2:55:27<1:54:07,  3.72s/it] 60%|█████▉    | 2705/4545 [2:55:31<1:55:54,  3.78s/it] 60%|█████▉    | 2706/4545 [2:55:35<1:56:04,  3.79s/it] 60%|█████▉    | 2707/4545 [2:55:39<1:57:25,  3.83s/it] 60%|█████▉    | 2708/4545 [2:55:43<1:59:18,  3.90s/it] 60%|█████▉    | 2709/4545 [2:55:47<1:56:19,  3.80s/it] 60%|█████▉    | 2710/4545 [2:55:50<1:53:58,  3.73s/it]                                                       {'loss': 0.304, 'grad_norm': 16.53453826904297, 'learning_rate': 6.967530992307832e-08, 'rewards/chosen': 0.9209839105606079, 'rewards/rejected': -1.971435546875, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.8921875953674316, 'logps/chosen': -220.89999389648438, 'logps/rejected': -150.625, 'logits/chosen': -7.568749904632568, 'logits/rejected': -7.403124809265137, 'epoch': 1.79}
 60%|█████▉    | 2710/4545 [2:55:50<1:53:58,  3.73s/it] 60%|█████▉    | 2711/4545 [2:55:54<1:55:13,  3.77s/it] 60%|█████▉    | 2712/4545 [2:55:57<1:52:20,  3.68s/it] 60%|█████▉    | 2713/4545 [2:56:01<1:54:12,  3.74s/it] 60%|█████▉    | 2714/4545 [2:56:05<1:55:44,  3.79s/it] 60%|█████▉    | 2715/4545 [2:56:09<1:55:41,  3.79s/it] 60%|█████▉    | 2716/4545 [2:56:12<1:48:07,  3.55s/it] 60%|█████▉    | 2717/4545 [2:56:16<1:51:23,  3.66s/it] 60%|█████▉    | 2718/4545 [2:56:20<1:53:14,  3.72s/it] 60%|█████▉    | 2719/4545 [2:56:24<1:54:06,  3.75s/it] 60%|█████▉    | 2720/4545 [2:56:28<1:55:56,  3.81s/it]                                                       {'loss': 0.3753, 'grad_norm': 17.471710205078125, 'learning_rate': 6.923360987679416e-08, 'rewards/chosen': 0.924267590045929, 'rewards/rejected': -1.6056640148162842, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.5289063453674316, 'logps/chosen': -230.0, 'logps/rejected': -139.27499389648438, 'logits/chosen': -7.471875190734863, 'logits/rejected': -7.262499809265137, 'epoch': 1.8}
 60%|█████▉    | 2720/4545 [2:56:28<1:55:56,  3.81s/it] 60%|█████▉    | 2721/4545 [2:56:29<1:38:04,  3.23s/it] 60%|█████▉    | 2722/4545 [2:56:33<1:45:11,  3.46s/it] 60%|█████▉    | 2723/4545 [2:56:37<1:49:08,  3.59s/it] 60%|█████▉    | 2724/4545 [2:56:41<1:48:16,  3.57s/it] 60%|█████▉    | 2725/4545 [2:56:45<1:48:57,  3.59s/it] 60%|█████▉    | 2726/4545 [2:56:49<1:54:18,  3.77s/it] 60%|██████    | 2727/4545 [2:56:53<1:55:33,  3.81s/it] 60%|██████    | 2728/4545 [2:56:56<1:53:55,  3.76s/it] 60%|██████    | 2729/4545 [2:57:00<1:50:50,  3.66s/it] 60%|██████    | 2730/4545 [2:57:04<1:52:59,  3.74s/it]                                                       {'loss': 0.2946, 'grad_norm': 18.45846939086914, 'learning_rate': 6.879038071940315e-08, 'rewards/chosen': 1.059362769126892, 'rewards/rejected': -1.705346703529358, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.76171875, 'logps/chosen': -223.0500030517578, 'logps/rejected': -145.875, 'logits/chosen': -7.746874809265137, 'logits/rejected': -7.540625095367432, 'epoch': 1.8}
 60%|██████    | 2730/4545 [2:57:04<1:52:59,  3.74s/it] 60%|██████    | 2731/4545 [2:57:08<1:54:28,  3.79s/it] 60%|██████    | 2732/4545 [2:57:11<1:55:27,  3.82s/it] 60%|██████    | 2733/4545 [2:57:15<1:54:44,  3.80s/it] 60%|██████    | 2734/4545 [2:57:19<1:51:51,  3.71s/it] 60%|██████    | 2735/4545 [2:57:23<1:55:05,  3.82s/it] 60%|██████    | 2736/4545 [2:57:27<1:55:49,  3.84s/it] 60%|██████    | 2737/4545 [2:57:30<1:50:06,  3.65s/it] 60%|██████    | 2738/4545 [2:57:34<1:53:29,  3.77s/it] 60%|██████    | 2739/4545 [2:57:38<1:54:49,  3.81s/it] 60%|██████    | 2740/4545 [2:57:42<1:55:38,  3.84s/it]                                                       {'loss': 0.3099, 'grad_norm': 19.317398071289062, 'learning_rate': 6.834567006683921e-08, 'rewards/chosen': 1.5710937976837158, 'rewards/rejected': -1.3576171398162842, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.92578125, 'logps/chosen': -312.75, 'logps/rejected': -161.85000610351562, 'logits/chosen': -7.578125, 'logits/rejected': -7.503125190734863, 'epoch': 1.81}
 60%|██████    | 2740/4545 [2:57:42<1:55:38,  3.84s/it] 60%|██████    | 2741/4545 [2:57:45<1:52:57,  3.76s/it] 60%|██████    | 2742/4545 [2:57:49<1:54:12,  3.80s/it] 60%|██████    | 2743/4545 [2:57:53<1:55:14,  3.84s/it] 60%|██████    | 2744/4545 [2:57:56<1:47:26,  3.58s/it] 60%|██████    | 2745/4545 [2:58:00<1:47:36,  3.59s/it] 60%|██████    | 2746/4545 [2:58:04<1:51:46,  3.73s/it] 60%|██████    | 2747/4545 [2:58:07<1:51:07,  3.71s/it] 60%|██████    | 2748/4545 [2:58:11<1:49:20,  3.65s/it] 60%|██████    | 2749/4545 [2:58:14<1:45:50,  3.54s/it] 61%|██████    | 2750/4545 [2:58:18<1:49:20,  3.66s/it]                                                       {'loss': 0.3375, 'grad_norm': 11.579920768737793, 'learning_rate': 6.789952569419271e-08, 'rewards/chosen': 0.572314441204071, 'rewards/rejected': -1.695703148841858, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.268749952316284, 'logps/chosen': -164.75, 'logps/rejected': -134.39999389648438, 'logits/chosen': -7.662499904632568, 'logits/rejected': -7.362500190734863, 'epoch': 1.82}
 61%|██████    | 2750/4545 [2:58:18<1:49:20,  3.66s/it] 61%|██████    | 2751/4545 [2:58:22<1:54:20,  3.82s/it] 61%|██████    | 2752/4545 [2:58:26<1:50:54,  3.71s/it] 61%|██████    | 2753/4545 [2:58:29<1:45:39,  3.54s/it] 61%|██████    | 2754/4545 [2:58:33<1:48:53,  3.65s/it] 61%|██████    | 2755/4545 [2:58:36<1:42:28,  3.43s/it] 61%|██████    | 2756/4545 [2:58:39<1:42:56,  3.45s/it] 61%|██████    | 2757/4545 [2:58:43<1:49:09,  3.66s/it] 61%|██████    | 2758/4545 [2:58:47<1:51:14,  3.74s/it] 61%|██████    | 2759/4545 [2:58:51<1:54:35,  3.85s/it] 61%|██████    | 2760/4545 [2:58:56<1:56:52,  3.93s/it]                                                       {'loss': 0.374, 'grad_norm': 19.5084171295166, 'learning_rate': 6.745199553057802e-08, 'rewards/chosen': 0.8651367425918579, 'rewards/rejected': -1.745703101158142, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.610156297683716, 'logps/chosen': -211.89999389648438, 'logps/rejected': -152.6999969482422, 'logits/chosen': -7.606249809265137, 'logits/rejected': -7.331250190734863, 'epoch': 1.82}
 61%|██████    | 2760/4545 [2:58:56<1:56:52,  3.93s/it] 61%|██████    | 2761/4545 [2:58:59<1:56:31,  3.92s/it] 61%|██████    | 2762/4545 [2:59:03<1:56:17,  3.91s/it] 61%|██████    | 2763/4545 [2:59:07<1:50:03,  3.71s/it] 61%|██████    | 2764/4545 [2:59:10<1:51:51,  3.77s/it] 61%|██████    | 2765/4545 [2:59:14<1:49:54,  3.70s/it] 61%|██████    | 2766/4545 [2:59:18<1:47:57,  3.64s/it] 61%|██████    | 2767/4545 [2:59:22<1:53:05,  3.82s/it] 61%|██████    | 2768/4545 [2:59:26<1:53:47,  3.84s/it] 61%|██████    | 2769/4545 [2:59:30<1:55:28,  3.90s/it] 61%|██████    | 2770/4545 [2:59:34<1:55:39,  3.91s/it]                                                       {'loss': 0.3466, 'grad_norm': 24.146745681762695, 'learning_rate': 6.700312765398448e-08, 'rewards/chosen': 1.7203857898712158, 'rewards/rejected': -1.451562523841858, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 3.168750047683716, 'logps/chosen': -337.20001220703125, 'logps/rejected': -229.0, 'logits/chosen': -7.403124809265137, 'logits/rejected': -7.168749809265137, 'epoch': 1.83}
 61%|██████    | 2770/4545 [2:59:34<1:55:39,  3.91s/it] 61%|██████    | 2771/4545 [2:59:38<1:55:44,  3.91s/it] 61%|██████    | 2772/4545 [2:59:41<1:55:52,  3.92s/it] 61%|██████    | 2773/4545 [2:59:45<1:49:46,  3.72s/it] 61%|██████    | 2774/4545 [2:59:49<1:51:34,  3.78s/it] 61%|██████    | 2775/4545 [2:59:53<1:52:40,  3.82s/it] 61%|██████    | 2776/4545 [2:59:56<1:51:25,  3.78s/it] 61%|██████    | 2777/4545 [3:00:00<1:47:53,  3.66s/it] 61%|██████    | 2778/4545 [3:00:04<1:49:58,  3.73s/it] 61%|██████    | 2779/4545 [3:00:07<1:48:55,  3.70s/it] 61%|██████    | 2780/4545 [3:00:11<1:49:28,  3.72s/it]                                                       {'loss': 0.3243, 'grad_norm': 11.563276290893555, 'learning_rate': 6.655297028611137e-08, 'rewards/chosen': 1.047387719154358, 'rewards/rejected': -1.8806641101837158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.9281249046325684, 'logps/chosen': -263.70001220703125, 'logps/rejected': -181.0, 'logits/chosen': -7.640625, 'logits/rejected': -7.262499809265137, 'epoch': 1.83}
 61%|██████    | 2780/4545 [3:00:11<1:49:28,  3.72s/it] 61%|██████    | 2781/4545 [3:00:15<1:51:59,  3.81s/it] 61%|██████    | 2782/4545 [3:00:19<1:52:57,  3.84s/it] 61%|██████    | 2783/4545 [3:00:22<1:50:12,  3.75s/it] 61%|██████▏   | 2784/4545 [3:00:27<1:53:37,  3.87s/it] 61%|██████▏   | 2785/4545 [3:00:30<1:53:48,  3.88s/it] 61%|██████▏   | 2786/4545 [3:00:35<1:55:45,  3.95s/it] 61%|██████▏   | 2787/4545 [3:00:38<1:55:21,  3.94s/it] 61%|██████▏   | 2788/4545 [3:00:41<1:46:57,  3.65s/it] 61%|██████▏   | 2789/4545 [3:00:45<1:50:19,  3.77s/it] 61%|██████▏   | 2790/4545 [3:00:49<1:51:35,  3.82s/it]                                                       {'loss': 0.3836, 'grad_norm': 16.345678329467773, 'learning_rate': 6.610157178718757e-08, 'rewards/chosen': 1.0464324951171875, 'rewards/rejected': -1.4617187976837158, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.5101561546325684, 'logps/chosen': -249.14999389648438, 'logps/rejected': -173.89999389648438, 'logits/chosen': -7.534375190734863, 'logits/rejected': -7.203125, 'epoch': 1.84}
 61%|██████▏   | 2790/4545 [3:00:49<1:51:35,  3.82s/it] 61%|██████▏   | 2791/4545 [3:00:53<1:52:27,  3.85s/it] 61%|██████▏   | 2792/4545 [3:00:58<1:55:44,  3.96s/it] 61%|██████▏   | 2793/4545 [3:01:01<1:53:47,  3.90s/it] 61%|██████▏   | 2794/4545 [3:01:05<1:53:49,  3.90s/it] 61%|██████▏   | 2795/4545 [3:01:09<1:49:56,  3.77s/it] 62%|██████▏   | 2796/4545 [3:01:13<1:50:33,  3.79s/it] 62%|██████▏   | 2797/4545 [3:01:16<1:47:29,  3.69s/it] 62%|██████▏   | 2798/4545 [3:01:20<1:50:49,  3.81s/it] 62%|██████▏   | 2799/4545 [3:01:24<1:53:29,  3.90s/it] 62%|██████▏   | 2800/4545 [3:01:27<1:40:40,  3.46s/it]                                                       {'loss': 0.3505, 'grad_norm': 9.147770881652832, 'learning_rate': 6.564898065077612e-08, 'rewards/chosen': 1.0576171875, 'rewards/rejected': -1.61328125, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.671875, 'logps/chosen': -250.39999389648438, 'logps/rejected': -171.14999389648438, 'logits/chosen': -7.503125190734863, 'logits/rejected': -7.150000095367432, 'epoch': 1.85}
 62%|██████▏   | 2800/4545 [3:01:27<1:40:40,  3.46s/it] 62%|██████▏   | 2801/4545 [3:01:30<1:43:05,  3.55s/it] 62%|██████▏   | 2802/4545 [3:01:33<1:36:06,  3.31s/it] 62%|██████▏   | 2803/4545 [3:01:36<1:33:30,  3.22s/it] 62%|██████▏   | 2804/4545 [3:01:39<1:32:44,  3.20s/it] 62%|██████▏   | 2805/4545 [3:01:43<1:33:53,  3.24s/it] 62%|██████▏   | 2806/4545 [3:01:47<1:40:21,  3.46s/it] 62%|██████▏   | 2807/4545 [3:01:50<1:36:13,  3.32s/it] 62%|██████▏   | 2808/4545 [3:01:54<1:42:30,  3.54s/it] 62%|██████▏   | 2809/4545 [3:01:58<1:45:41,  3.65s/it] 62%|██████▏   | 2810/4545 [3:02:00<1:36:14,  3.33s/it]                                                       {'loss': 0.3401, 'grad_norm': 11.824419975280762, 'learning_rate': 6.519524549856472e-08, 'rewards/chosen': 0.4447830319404602, 'rewards/rejected': -1.8718750476837158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.31640625, 'logps/chosen': -135.39999389648438, 'logps/rejected': -99.05000305175781, 'logits/chosen': -7.868750095367432, 'logits/rejected': -7.675000190734863, 'epoch': 1.85}
 62%|██████▏   | 2810/4545 [3:02:00<1:36:14,  3.33s/it] 62%|██████▏   | 2811/4545 [3:02:04<1:36:37,  3.34s/it] 62%|██████▏   | 2812/4545 [3:02:07<1:42:01,  3.53s/it] 62%|██████▏   | 2813/4545 [3:02:11<1:43:40,  3.59s/it] 62%|██████▏   | 2814/4545 [3:02:15<1:48:38,  3.77s/it] 62%|██████▏   | 2815/4545 [3:02:19<1:49:04,  3.78s/it] 62%|██████▏   | 2816/4545 [3:02:23<1:50:08,  3.82s/it] 62%|██████▏   | 2817/4545 [3:02:27<1:51:15,  3.86s/it] 62%|██████▏   | 2818/4545 [3:02:31<1:52:41,  3.92s/it] 62%|██████▏   | 2819/4545 [3:02:35<1:54:11,  3.97s/it] 62%|██████▏   | 2820/4545 [3:02:39<1:48:43,  3.78s/it]                                                       {'loss': 0.3284, 'grad_norm': 14.17911434173584, 'learning_rate': 6.474041507514215e-08, 'rewards/chosen': 1.1984374523162842, 'rewards/rejected': -1.728906273841858, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.92578125, 'logps/chosen': -275.29998779296875, 'logps/rejected': -171.9250030517578, 'logits/chosen': -7.565625190734863, 'logits/rejected': -7.262499809265137, 'epoch': 1.86}
 62%|██████▏   | 2820/4545 [3:02:39<1:48:43,  3.78s/it] 62%|██████▏   | 2821/4545 [3:02:43<1:50:14,  3.84s/it] 62%|██████▏   | 2822/4545 [3:02:45<1:42:25,  3.57s/it] 62%|██████▏   | 2823/4545 [3:02:47<1:29:01,  3.10s/it] 62%|██████▏   | 2824/4545 [3:02:51<1:29:30,  3.12s/it] 62%|██████▏   | 2825/4545 [3:02:55<1:38:11,  3.43s/it] 62%|██████▏   | 2826/4545 [3:02:59<1:42:57,  3.59s/it] 62%|██████▏   | 2827/4545 [3:03:02<1:37:35,  3.41s/it] 62%|██████▏   | 2828/4545 [3:03:06<1:41:50,  3.56s/it] 62%|██████▏   | 2829/4545 [3:03:09<1:44:17,  3.65s/it] 62%|██████▏   | 2830/4545 [3:03:13<1:46:24,  3.72s/it]                                                       {'loss': 0.352, 'grad_norm': 11.606328964233398, 'learning_rate': 6.42845382427618e-08, 'rewards/chosen': 1.3590209484100342, 'rewards/rejected': -1.869140625, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.2328124046325684, 'logps/chosen': -305.1499938964844, 'logps/rejected': -154.3000030517578, 'logits/chosen': -7.543749809265137, 'logits/rejected': -7.190625190734863, 'epoch': 1.87}
 62%|██████▏   | 2830/4545 [3:03:13<1:46:24,  3.72s/it] 62%|██████▏   | 2831/4545 [3:03:17<1:47:55,  3.78s/it] 62%|██████▏   | 2832/4545 [3:03:20<1:42:42,  3.60s/it] 62%|██████▏   | 2833/4545 [3:03:24<1:45:12,  3.69s/it] 62%|██████▏   | 2834/4545 [3:03:27<1:38:40,  3.46s/it] 62%|██████▏   | 2835/4545 [3:03:31<1:36:54,  3.40s/it] 62%|██████▏   | 2836/4545 [3:03:34<1:33:03,  3.27s/it] 62%|██████▏   | 2837/4545 [3:03:36<1:25:04,  2.99s/it] 62%|██████▏   | 2838/4545 [3:03:40<1:33:06,  3.27s/it] 62%|██████▏   | 2839/4545 [3:03:44<1:37:17,  3.42s/it] 62%|██████▏   | 2840/4545 [3:03:47<1:41:20,  3.57s/it]                                                       {'loss': 0.3659, 'grad_norm': 37.288272857666016, 'learning_rate': 6.382766397609233e-08, 'rewards/chosen': 0.553021252155304, 'rewards/rejected': -1.9025390148162842, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.453906297683716, 'logps/chosen': -173.85000610351562, 'logps/rejected': -143.9250030517578, 'logits/chosen': -7.728125095367432, 'logits/rejected': -7.521874904632568, 'epoch': 1.87}
 62%|██████▏   | 2840/4545 [3:03:47<1:41:20,  3.57s/it] 63%|██████▎   | 2841/4545 [3:03:51<1:44:28,  3.68s/it] 63%|██████▎   | 2842/4545 [3:03:55<1:42:58,  3.63s/it] 63%|██████▎   | 2843/4545 [3:03:59<1:44:27,  3.68s/it] 63%|██████▎   | 2844/4545 [3:04:03<1:46:21,  3.75s/it] 63%|██████▎   | 2845/4545 [3:04:06<1:45:17,  3.72s/it] 63%|██████▎   | 2846/4545 [3:04:10<1:46:52,  3.77s/it] 63%|██████▎   | 2847/4545 [3:04:14<1:50:06,  3.89s/it] 63%|██████▎   | 2848/4545 [3:04:18<1:51:27,  3.94s/it] 63%|██████▎   | 2849/4545 [3:04:22<1:51:02,  3.93s/it] 63%|██████▎   | 2850/4545 [3:04:26<1:50:41,  3.92s/it]                                                       {'loss': 0.2939, 'grad_norm': 22.47393798828125, 'learning_rate': 6.336984135695638e-08, 'rewards/chosen': 1.3549087047576904, 'rewards/rejected': -2.0321288108825684, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.387500047683716, 'logps/chosen': -280.8999938964844, 'logps/rejected': -189.4499969482422, 'logits/chosen': -7.609375, 'logits/rejected': -7.365624904632568, 'epoch': 1.88}
 63%|██████▎   | 2850/4545 [3:04:26<1:50:41,  3.92s/it] 63%|██████▎   | 2851/4545 [3:04:30<1:50:31,  3.91s/it] 63%|██████▎   | 2852/4545 [3:04:34<1:50:19,  3.91s/it] 63%|██████▎   | 2853/4545 [3:04:38<1:50:07,  3.91s/it] 63%|██████▎   | 2854/4545 [3:04:42<1:50:01,  3.90s/it] 63%|██████▎   | 2855/4545 [3:04:45<1:42:38,  3.64s/it] 63%|██████▎   | 2856/4545 [3:04:48<1:36:41,  3.43s/it] 63%|██████▎   | 2857/4545 [3:04:52<1:40:41,  3.58s/it] 63%|██████▎   | 2858/4545 [3:04:56<1:43:31,  3.68s/it] 63%|██████▎   | 2859/4545 [3:05:00<1:47:22,  3.82s/it] 63%|██████▎   | 2860/4545 [3:05:03<1:44:16,  3.71s/it]                                                       {'loss': 0.3013, 'grad_norm': 17.501039505004883, 'learning_rate': 6.291111956905776e-08, 'rewards/chosen': 1.684472680091858, 'rewards/rejected': -1.617578148841858, 'rewards/accuracies': 0.875, 'rewards/margins': 3.2992186546325684, 'logps/chosen': -326.75, 'logps/rejected': -179.4499969482422, 'logits/chosen': -7.46875, 'logits/rejected': -7.162499904632568, 'epoch': 1.89}
 63%|██████▎   | 2860/4545 [3:05:03<1:44:16,  3.71s/it] 63%|██████▎   | 2861/4545 [3:05:07<1:46:09,  3.78s/it] 63%|██████▎   | 2862/4545 [3:05:10<1:41:17,  3.61s/it] 63%|██████▎   | 2863/4545 [3:05:14<1:45:01,  3.75s/it] 63%|██████▎   | 2864/4545 [3:05:18<1:46:22,  3.80s/it] 63%|██████▎   | 2865/4545 [3:05:22<1:46:12,  3.79s/it] 63%|██████▎   | 2866/4545 [3:05:25<1:40:21,  3.59s/it] 63%|██████▎   | 2867/4545 [3:05:29<1:40:32,  3.60s/it] 63%|██████▎   | 2868/4545 [3:05:32<1:40:20,  3.59s/it] 63%|██████▎   | 2869/4545 [3:05:36<1:39:30,  3.56s/it] 63%|██████▎   | 2870/4545 [3:05:40<1:42:22,  3.67s/it]                                                       {'loss': 0.3172, 'grad_norm': 23.659584045410156, 'learning_rate': 6.245154789269756e-08, 'rewards/chosen': 1.7991211414337158, 'rewards/rejected': -2.0884156227111816, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.8882813453674316, 'logps/chosen': -375.70001220703125, 'logps/rejected': -219.10000610351562, 'logits/chosen': -7.303124904632568, 'logits/rejected': -7.068749904632568, 'epoch': 1.89}
 63%|██████▎   | 2870/4545 [3:05:40<1:42:22,  3.67s/it] 63%|██████▎   | 2871/4545 [3:05:44<1:46:23,  3.81s/it] 63%|██████▎   | 2872/4545 [3:05:48<1:45:12,  3.77s/it] 63%|██████▎   | 2873/4545 [3:05:52<1:47:27,  3.86s/it] 63%|██████▎   | 2874/4545 [3:05:56<1:48:47,  3.91s/it] 63%|██████▎   | 2875/4545 [3:05:59<1:47:06,  3.85s/it] 63%|██████▎   | 2876/4545 [3:06:02<1:39:28,  3.58s/it] 63%|██████▎   | 2877/4545 [3:06:06<1:38:37,  3.55s/it] 63%|██████▎   | 2878/4545 [3:06:10<1:44:16,  3.75s/it] 63%|██████▎   | 2879/4545 [3:06:14<1:47:06,  3.86s/it] 63%|██████▎   | 2880/4545 [3:06:18<1:48:09,  3.90s/it]                                                       {'loss': 0.3662, 'grad_norm': 22.379802703857422, 'learning_rate': 6.199117569948011e-08, 'rewards/chosen': 0.7613769769668579, 'rewards/rejected': -1.597436547279358, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.360156297683716, 'logps/chosen': -209.1999969482422, 'logps/rejected': -118.07499694824219, 'logits/chosen': -7.612500190734863, 'logits/rejected': -7.300000190734863, 'epoch': 1.9}
 63%|██████▎   | 2880/4545 [3:06:18<1:48:09,  3.90s/it] 63%|██████▎   | 2881/4545 [3:06:22<1:46:10,  3.83s/it] 63%|██████▎   | 2882/4545 [3:06:25<1:44:17,  3.76s/it] 63%|██████▎   | 2883/4545 [3:06:29<1:40:30,  3.63s/it] 63%|██████▎   | 2884/4545 [3:06:33<1:42:43,  3.71s/it] 63%|██████▎   | 2885/4545 [3:06:37<1:46:53,  3.86s/it] 63%|██████▎   | 2886/4545 [3:06:41<1:49:33,  3.96s/it] 64%|██████▎   | 2887/4545 [3:06:45<1:49:07,  3.95s/it] 64%|██████▎   | 2888/4545 [3:06:48<1:41:44,  3.68s/it] 64%|██████▎   | 2889/4545 [3:06:52<1:43:11,  3.74s/it] 64%|██████▎   | 2890/4545 [3:06:56<1:43:55,  3.77s/it]                                                       {'loss': 0.3109, 'grad_norm': 23.65797996520996, 'learning_rate': 6.153005244700894e-08, 'rewards/chosen': 1.0984375476837158, 'rewards/rejected': -1.676660180091858, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.7757811546325684, 'logps/chosen': -250.4499969482422, 'logps/rejected': -179.60000610351562, 'logits/chosen': -7.521874904632568, 'logits/rejected': -7.231249809265137, 'epoch': 1.91}
 64%|██████▎   | 2890/4545 [3:06:56<1:43:55,  3.77s/it] 64%|██████▎   | 2891/4545 [3:06:59<1:42:53,  3.73s/it] 64%|██████▎   | 2892/4545 [3:07:02<1:35:05,  3.45s/it] 64%|██████▎   | 2893/4545 [3:07:06<1:38:48,  3.59s/it] 64%|██████▎   | 2894/4545 [3:07:10<1:40:56,  3.67s/it] 64%|██████▎   | 2895/4545 [3:07:14<1:42:43,  3.74s/it] 64%|██████▎   | 2896/4545 [3:07:18<1:44:13,  3.79s/it] 64%|██████▎   | 2897/4545 [3:07:22<1:44:45,  3.81s/it] 64%|██████▍   | 2898/4545 [3:07:26<1:45:26,  3.84s/it] 64%|██████▍   | 2899/4545 [3:07:30<1:45:59,  3.86s/it] 64%|██████▍   | 2900/4545 [3:07:33<1:46:22,  3.88s/it]                                                       {'loss': 0.3497, 'grad_norm': 9.906067848205566, 'learning_rate': 6.106822767357355e-08, 'rewards/chosen': 2.1436524391174316, 'rewards/rejected': -1.5437500476837158, 'rewards/accuracies': 0.8125, 'rewards/margins': 3.6820311546325684, 'logps/chosen': -397.95001220703125, 'logps/rejected': -193.3000030517578, 'logits/chosen': -7.296875, 'logits/rejected': -7.165625095367432, 'epoch': 1.91}
 64%|██████▍   | 2900/4545 [3:07:33<1:46:22,  3.88s/it] 64%|██████▍   | 2901/4545 [3:07:37<1:43:28,  3.78s/it] 64%|██████▍   | 2902/4545 [3:07:40<1:40:59,  3.69s/it] 64%|██████▍   | 2903/4545 [3:07:44<1:42:10,  3.73s/it] 64%|██████▍   | 2904/4545 [3:07:48<1:42:23,  3.74s/it] 64%|██████▍   | 2905/4545 [3:07:52<1:40:20,  3.67s/it] 64%|██████▍   | 2906/4545 [3:07:55<1:42:12,  3.74s/it] 64%|██████▍   | 2907/4545 [3:07:59<1:43:34,  3.79s/it] 64%|██████▍   | 2908/4545 [3:08:03<1:44:16,  3.82s/it] 64%|██████▍   | 2909/4545 [3:08:07<1:39:59,  3.67s/it] 64%|██████▍   | 2910/4545 [3:08:10<1:38:46,  3.62s/it]                                                       {'loss': 0.3107, 'grad_norm': 13.664536476135254, 'learning_rate': 6.060575099282757e-08, 'rewards/chosen': 0.907910168170929, 'rewards/rejected': -1.7087891101837158, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 2.616406202316284, 'logps/chosen': -210.60000610351562, 'logps/rejected': -155.35000610351562, 'logits/chosen': -7.734375, 'logits/rejected': -7.428124904632568, 'epoch': 1.92}
 64%|██████▍   | 2910/4545 [3:08:10<1:38:46,  3.62s/it] 64%|██████▍   | 2911/4545 [3:08:14<1:42:58,  3.78s/it] 64%|██████▍   | 2912/4545 [3:08:18<1:44:48,  3.85s/it] 64%|██████▍   | 2913/4545 [3:08:22<1:45:07,  3.86s/it] 64%|██████▍   | 2914/4545 [3:08:26<1:47:49,  3.97s/it] 64%|██████▍   | 2915/4545 [3:08:30<1:46:26,  3.92s/it] 64%|██████▍   | 2916/4545 [3:08:34<1:45:02,  3.87s/it] 64%|██████▍   | 2917/4545 [3:08:38<1:45:18,  3.88s/it] 64%|██████▍   | 2918/4545 [3:08:42<1:47:07,  3.95s/it] 64%|██████▍   | 2919/4545 [3:08:46<1:46:00,  3.91s/it] 64%|██████▍   | 2920/4545 [3:08:50<1:45:48,  3.91s/it]                                                       {'loss': 0.319, 'grad_norm': 16.564781188964844, 'learning_rate': 6.01426720884588e-08, 'rewards/chosen': 1.70068359375, 'rewards/rejected': -1.773046851158142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.4789061546325684, 'logps/chosen': -323.1499938964844, 'logps/rejected': -206.25, 'logits/chosen': -7.471875190734863, 'logits/rejected': -7.090624809265137, 'epoch': 1.93}
 64%|██████▍   | 2920/4545 [3:08:50<1:45:48,  3.91s/it] 64%|██████▍   | 2921/4545 [3:08:53<1:44:37,  3.87s/it] 64%|██████▍   | 2922/4545 [3:08:56<1:33:36,  3.46s/it] 64%|██████▍   | 2923/4545 [3:08:58<1:22:42,  3.06s/it] 64%|██████▍   | 2924/4545 [3:09:02<1:29:22,  3.31s/it] 64%|██████▍   | 2925/4545 [3:09:06<1:36:04,  3.56s/it] 64%|██████▍   | 2926/4545 [3:09:10<1:36:19,  3.57s/it] 64%|██████▍   | 2927/4545 [3:09:14<1:39:02,  3.67s/it] 64%|██████▍   | 2928/4545 [3:09:18<1:43:10,  3.83s/it] 64%|██████▍   | 2929/4545 [3:09:22<1:43:41,  3.85s/it] 64%|██████▍   | 2930/4545 [3:09:25<1:40:19,  3.73s/it]                                                       {'loss': 0.3425, 'grad_norm': 15.121557235717773, 'learning_rate': 5.967904070885169e-08, 'rewards/chosen': 1.1547362804412842, 'rewards/rejected': -1.655859351158142, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.8109374046325684, 'logps/chosen': -241.0500030517578, 'logps/rejected': -169.52499389648438, 'logits/chosen': -7.565625190734863, 'logits/rejected': -7.284375190734863, 'epoch': 1.93}
 64%|██████▍   | 2930/4545 [3:09:25<1:40:19,  3.73s/it] 64%|██████▍   | 2931/4545 [3:09:28<1:32:19,  3.43s/it] 65%|██████▍   | 2932/4545 [3:09:32<1:36:13,  3.58s/it] 65%|██████▍   | 2933/4545 [3:09:36<1:37:07,  3.62s/it] 65%|██████▍   | 2934/4545 [3:09:39<1:38:12,  3.66s/it] 65%|██████▍   | 2935/4545 [3:09:43<1:40:14,  3.74s/it] 65%|██████▍   | 2936/4545 [3:09:47<1:39:06,  3.70s/it] 65%|██████▍   | 2937/4545 [3:09:50<1:38:31,  3.68s/it] 65%|██████▍   | 2938/4545 [3:09:54<1:38:14,  3.67s/it] 65%|██████▍   | 2939/4545 [3:09:58<1:41:39,  3.80s/it] 65%|██████▍   | 2940/4545 [3:10:02<1:43:58,  3.89s/it]                                                       {'loss': 0.3412, 'grad_norm': 22.013826370239258, 'learning_rate': 5.9214906661742837e-08, 'rewards/chosen': 0.48687744140625, 'rewards/rejected': -2.278125047683716, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.764843702316284, 'logps/chosen': -170.35000610351562, 'logps/rejected': -141.85000610351562, 'logits/chosen': -7.734375, 'logits/rejected': -7.246874809265137, 'epoch': 1.94}
 65%|██████▍   | 2940/4545 [3:10:02<1:43:58,  3.89s/it] 65%|██████▍   | 2941/4545 [3:10:06<1:42:10,  3.82s/it] 65%|██████▍   | 2942/4545 [3:10:09<1:38:00,  3.67s/it] 65%|██████▍   | 2943/4545 [3:10:13<1:42:04,  3.82s/it] 65%|██████▍   | 2944/4545 [3:10:16<1:33:22,  3.50s/it] 65%|██████▍   | 2945/4545 [3:10:20<1:38:42,  3.70s/it] 65%|██████▍   | 2946/4545 [3:10:24<1:42:01,  3.83s/it] 65%|██████▍   | 2947/4545 [3:10:28<1:42:37,  3.85s/it] 65%|██████▍   | 2948/4545 [3:10:32<1:44:34,  3.93s/it] 65%|██████▍   | 2949/4545 [3:10:35<1:34:21,  3.55s/it] 65%|██████▍   | 2950/4545 [3:10:38<1:29:21,  3.36s/it]                                                       {'loss': 0.2433, 'grad_norm': 7.279449462890625, 'learning_rate': 5.875031980887026e-08, 'rewards/chosen': 0.9085143804550171, 'rewards/rejected': -2.428906202316284, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.3375000953674316, 'logps/chosen': -204.4499969482422, 'logps/rejected': -131.1999969482422, 'logits/chosen': -7.765625, 'logits/rejected': -7.365624904632568, 'epoch': 1.95}
 65%|██████▍   | 2950/4545 [3:10:38<1:29:21,  3.36s/it] 65%|██████▍   | 2951/4545 [3:10:42<1:33:43,  3.53s/it] 65%|██████▍   | 2952/4545 [3:10:44<1:24:40,  3.19s/it] 65%|██████▍   | 2953/4545 [3:10:49<1:32:43,  3.49s/it] 65%|██████▍   | 2954/4545 [3:10:53<1:35:59,  3.62s/it] 65%|██████▌   | 2955/4545 [3:10:56<1:38:13,  3.71s/it] 65%|██████▌   | 2956/4545 [3:10:59<1:30:51,  3.43s/it] 65%|██████▌   | 2957/4545 [3:11:03<1:34:36,  3.57s/it] 65%|██████▌   | 2958/4545 [3:11:07<1:39:14,  3.75s/it] 65%|██████▌   | 2959/4545 [3:11:11<1:41:26,  3.84s/it] 65%|██████▌   | 2960/4545 [3:11:13<1:27:57,  3.33s/it]                                                       {'loss': 0.3421, 'grad_norm': 17.052112579345703, 'learning_rate': 5.8285330060616697e-08, 'rewards/chosen': 1.314843773841858, 'rewards/rejected': -1.5109374523162842, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.827343702316284, 'logps/chosen': -304.04998779296875, 'logps/rejected': -201.27499389648438, 'logits/chosen': -7.431250095367432, 'logits/rejected': -7.125, 'epoch': 1.95}
 65%|██████▌   | 2960/4545 [3:11:13<1:27:57,  3.33s/it] 65%|██████▌   | 2961/4545 [3:11:18<1:34:23,  3.58s/it] 65%|██████▌   | 2962/4545 [3:11:22<1:36:58,  3.68s/it] 65%|██████▌   | 2963/4545 [3:11:26<1:40:20,  3.81s/it] 65%|██████▌   | 2964/4545 [3:11:29<1:37:39,  3.71s/it] 65%|██████▌   | 2965/4545 [3:11:33<1:39:14,  3.77s/it] 65%|██████▌   | 2966/4545 [3:11:37<1:39:58,  3.80s/it] 65%|██████▌   | 2967/4545 [3:11:40<1:36:09,  3.66s/it] 65%|██████▌   | 2968/4545 [3:11:44<1:38:03,  3.73s/it] 65%|██████▌   | 2969/4545 [3:11:48<1:40:53,  3.84s/it] 65%|██████▌   | 2970/4545 [3:11:52<1:41:44,  3.88s/it]                                                       {'loss': 0.3115, 'grad_norm': 10.60103988647461, 'learning_rate': 5.7819987370647824e-08, 'rewards/chosen': 1.6196014881134033, 'rewards/rejected': -2.2294921875, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.8492188453674316, 'logps/chosen': -338.25, 'logps/rejected': -177.8000030517578, 'logits/chosen': -7.503125190734863, 'logits/rejected': -7.09375, 'epoch': 1.96}
 65%|██████▌   | 2970/4545 [3:11:52<1:41:44,  3.88s/it] 65%|██████▌   | 2971/4545 [3:11:56<1:42:06,  3.89s/it] 65%|██████▌   | 2972/4545 [3:12:00<1:39:54,  3.81s/it] 65%|██████▌   | 2973/4545 [3:12:04<1:43:10,  3.94s/it] 65%|██████▌   | 2974/4545 [3:12:08<1:42:24,  3.91s/it] 65%|██████▌   | 2975/4545 [3:12:12<1:42:59,  3.94s/it] 65%|██████▌   | 2976/4545 [3:12:16<1:42:39,  3.93s/it] 66%|██████▌   | 2977/4545 [3:12:20<1:42:43,  3.93s/it] 66%|██████▌   | 2978/4545 [3:12:24<1:44:01,  3.98s/it] 66%|██████▌   | 2979/4545 [3:12:28<1:44:45,  4.01s/it] 66%|██████▌   | 2980/4545 [3:12:32<1:43:57,  3.99s/it]                                                       {'loss': 0.3466, 'grad_norm': 9.05953598022461, 'learning_rate': 5.735434173054562e-08, 'rewards/chosen': 1.810546875, 'rewards/rejected': -1.602929711341858, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.4156250953674316, 'logps/chosen': -397.07501220703125, 'logps/rejected': -227.10000610351562, 'logits/chosen': -7.5625, 'logits/rejected': -7.349999904632568, 'epoch': 1.97}
 66%|██████▌   | 2980/4545 [3:12:32<1:43:57,  3.99s/it] 66%|██████▌   | 2981/4545 [3:12:35<1:38:06,  3.76s/it] 66%|██████▌   | 2982/4545 [3:12:39<1:39:26,  3.82s/it] 66%|██████▌   | 2983/4545 [3:12:42<1:37:05,  3.73s/it] 66%|██████▌   | 2984/4545 [3:12:46<1:38:01,  3.77s/it] 66%|██████▌   | 2985/4545 [3:12:50<1:35:01,  3.65s/it] 66%|██████▌   | 2986/4545 [3:12:54<1:37:15,  3.74s/it] 66%|██████▌   | 2987/4545 [3:12:58<1:38:40,  3.80s/it] 66%|██████▌   | 2988/4545 [3:13:01<1:36:06,  3.70s/it] 66%|██████▌   | 2989/4545 [3:13:05<1:39:29,  3.84s/it] 66%|██████▌   | 2990/4545 [3:13:09<1:40:24,  3.87s/it]                                                       {'loss': 0.3103, 'grad_norm': 11.503599166870117, 'learning_rate': 5.688844316443797e-08, 'rewards/chosen': 1.0730469226837158, 'rewards/rejected': -2.6410155296325684, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.7164063453674316, 'logps/chosen': -280.3999938964844, 'logps/rejected': -154.60000610351562, 'logits/chosen': -7.559374809265137, 'logits/rejected': -7.212500095367432, 'epoch': 1.97}
 66%|██████▌   | 2990/4545 [3:13:09<1:40:24,  3.87s/it] 66%|██████▌   | 2991/4545 [3:13:13<1:40:41,  3.89s/it] 66%|██████▌   | 2992/4545 [3:13:17<1:43:14,  3.99s/it] 66%|██████▌   | 2993/4545 [3:13:22<1:44:56,  4.06s/it] 66%|██████▌   | 2994/4545 [3:13:25<1:43:42,  4.01s/it] 66%|██████▌   | 2995/4545 [3:13:29<1:42:52,  3.98s/it] 66%|██████▌   | 2996/4545 [3:13:32<1:34:23,  3.66s/it] 66%|██████▌   | 2997/4545 [3:13:36<1:36:16,  3.73s/it] 66%|██████▌   | 2998/4545 [3:13:40<1:35:32,  3.71s/it] 66%|██████▌   | 2999/4545 [3:13:44<1:37:10,  3.77s/it] 66%|██████▌   | 3000/4545 [3:13:47<1:35:46,  3.72s/it]                                                       {'loss': 0.3077, 'grad_norm': 22.41351890563965, 'learning_rate': 5.642234172362442e-08, 'rewards/chosen': 1.488037109375, 'rewards/rejected': -2.2953124046325684, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.7828125953674316, 'logps/chosen': -356.8999938964844, 'logps/rejected': -208.1999969482422, 'logits/chosen': -7.606249809265137, 'logits/rejected': -7.265625, 'epoch': 1.98}
 66%|██████▌   | 3000/4545 [3:13:47<1:35:46,  3.72s/it] 66%|██████▌   | 3001/4545 [3:13:51<1:36:59,  3.77s/it] 66%|██████▌   | 3002/4545 [3:13:55<1:35:43,  3.72s/it] 66%|██████▌   | 3003/4545 [3:13:59<1:37:07,  3.78s/it] 66%|██████▌   | 3004/4545 [3:14:03<1:37:54,  3.81s/it] 66%|██████▌   | 3005/4545 [3:14:07<1:40:52,  3.93s/it] 66%|██████▌   | 3006/4545 [3:14:10<1:37:28,  3.80s/it] 66%|██████▌   | 3007/4545 [3:14:14<1:37:03,  3.79s/it] 66%|██████▌   | 3008/4545 [3:14:18<1:38:12,  3.83s/it] 66%|██████▌   | 3009/4545 [3:14:21<1:32:12,  3.60s/it] 66%|██████▌   | 3010/4545 [3:14:25<1:31:02,  3.56s/it]                                                       {'loss': 0.3093, 'grad_norm': 18.873926162719727, 'learning_rate': 5.595608748119933e-08, 'rewards/chosen': 1.4351074695587158, 'rewards/rejected': -2.024829149246216, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.4593749046325684, 'logps/chosen': -331.8999938964844, 'logps/rejected': -171.8000030517578, 'logits/chosen': -7.443749904632568, 'logits/rejected': -7.224999904632568, 'epoch': 1.99}
 66%|██████▌   | 3010/4545 [3:14:25<1:31:02,  3.56s/it] 66%|██████▌   | 3011/4545 [3:14:28<1:30:47,  3.55s/it] 66%|██████▋   | 3012/4545 [3:14:32<1:33:28,  3.66s/it] 66%|██████▋   | 3013/4545 [3:14:36<1:34:05,  3.68s/it] 66%|██████▋   | 3014/4545 [3:14:40<1:35:47,  3.75s/it] 66%|██████▋   | 3015/4545 [3:14:44<1:37:03,  3.81s/it] 66%|██████▋   | 3016/4545 [3:14:48<1:38:47,  3.88s/it] 66%|██████▋   | 3017/4545 [3:14:50<1:27:18,  3.43s/it] 66%|██████▋   | 3018/4545 [3:14:54<1:30:52,  3.57s/it] 66%|██████▋   | 3019/4545 [3:14:58<1:33:21,  3.67s/it] 66%|██████▋   | 3020/4545 [3:15:01<1:29:04,  3.50s/it]                                                       {'loss': 0.2798, 'grad_norm': 8.410280227661133, 'learning_rate': 5.548973052667244e-08, 'rewards/chosen': 1.173858642578125, 'rewards/rejected': -2.0765624046325684, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 3.2476563453674316, 'logps/chosen': -237.39999389648438, 'logps/rejected': -126.19999694824219, 'logits/chosen': -7.75, 'logits/rejected': -7.390625, 'epoch': 1.99}
 66%|██████▋   | 3020/4545 [3:15:01<1:29:04,  3.50s/it] 66%|██████▋   | 3021/4545 [3:15:05<1:31:02,  3.58s/it] 66%|██████▋   | 3022/4545 [3:15:08<1:29:37,  3.53s/it] 67%|██████▋   | 3023/4545 [3:15:12<1:32:34,  3.65s/it] 67%|██████▋   | 3024/4545 [3:15:16<1:35:51,  3.78s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.11s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A                                                       
                                               [A{'eval_loss': 0.42232951521873474, 'eval_runtime': 80.3062, 'eval_samples_per_second': 11.867, 'eval_steps_per_second': 0.747, 'eval_rewards/chosen': 1.4789327383041382, 'eval_rewards/rejected': -1.2622721195220947, 'eval_rewards/accuracies': 0.7964120507240295, 'eval_rewards/margins': 2.7399699687957764, 'eval_logps/chosen': -362.82501220703125, 'eval_logps/rejected': -164.63333129882812, 'eval_logits/chosen': -7.3260416984558105, 'eval_logits/rejected': -7.731770992279053, 'epoch': 2.0}
 67%|██████▋   | 3024/4545 [3:16:36<1:35:51,  3.78s/it]
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 67%|██████▋   | 3025/4545 [3:16:50<13:01:54, 30.86s/it] 67%|██████▋   | 3026/4545 [3:16:54<9:36:03, 22.75s/it]  67%|██████▋   | 3027/4545 [3:16:58<7:12:32, 17.10s/it] 67%|██████▋   | 3028/4545 [3:17:02<5:31:25, 13.11s/it] 67%|██████▋   | 3029/4545 [3:17:06<4:21:33, 10.35s/it] 67%|██████▋   | 3030/4545 [3:17:10<3:32:36,  8.42s/it]                                                       {'loss': 0.3133, 'grad_norm': 12.738144874572754, 'learning_rate': 5.5023320960587824e-08, 'rewards/chosen': 2.8567872047424316, 'rewards/rejected': -1.9094727039337158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.753125190734863, 'logps/chosen': -565.1500244140625, 'logps/rejected': -326.6000061035156, 'logits/chosen': -7.180468559265137, 'logits/rejected': -7.0, 'epoch': 2.0}
 67%|██████▋   | 3030/4545 [3:17:10<3:32:36,  8.42s/it] 67%|██████▋   | 3031/4545 [3:17:13<2:53:53,  6.89s/it] 67%|██████▋   | 3032/4545 [3:17:17<2:31:10,  6.00s/it] 67%|██████▋   | 3033/4545 [3:17:20<2:13:47,  5.31s/it] 67%|██████▋   | 3034/4545 [3:17:24<1:58:17,  4.70s/it] 67%|██████▋   | 3035/4545 [3:17:27<1:49:25,  4.35s/it] 67%|██████▋   | 3036/4545 [3:17:31<1:45:56,  4.21s/it] 67%|██████▋   | 3037/4545 [3:17:35<1:43:37,  4.12s/it] 67%|██████▋   | 3038/4545 [3:17:39<1:41:56,  4.06s/it] 67%|██████▋   | 3039/4545 [3:17:43<1:40:08,  3.99s/it] 67%|██████▋   | 3040/4545 [3:17:46<1:36:13,  3.84s/it]                                                       {'loss': 0.2504, 'grad_norm': 15.553606033325195, 'learning_rate': 5.4556908889141596e-08, 'rewards/chosen': 0.952441394329071, 'rewards/rejected': -2.1875, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.1390624046325684, 'logps/chosen': -254.5, 'logps/rejected': -163.9499969482422, 'logits/chosen': -7.653124809265137, 'logits/rejected': -7.324999809265137, 'epoch': 2.01}
 67%|██████▋   | 3040/4545 [3:17:46<1:36:13,  3.84s/it] 67%|██████▋   | 3041/4545 [3:17:50<1:33:39,  3.74s/it] 67%|██████▋   | 3042/4545 [3:17:54<1:36:26,  3.85s/it] 67%|██████▋   | 3043/4545 [3:17:58<1:38:08,  3.92s/it] 67%|██████▋   | 3044/4545 [3:18:00<1:26:30,  3.46s/it] 67%|██████▋   | 3045/4545 [3:18:04<1:30:01,  3.60s/it] 67%|██████▋   | 3046/4545 [3:18:07<1:24:06,  3.37s/it] 67%|██████▋   | 3047/4545 [3:18:11<1:28:24,  3.54s/it] 67%|██████▋   | 3048/4545 [3:18:15<1:30:05,  3.61s/it] 67%|██████▋   | 3049/4545 [3:18:19<1:32:16,  3.70s/it] 67%|██████▋   | 3050/4545 [3:18:22<1:26:35,  3.48s/it]                                                       {'loss': 0.3151, 'grad_norm': 17.099292755126953, 'learning_rate': 5.4090544418799e-08, 'rewards/chosen': 1.615258812904358, 'rewards/rejected': -1.968011498451233, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.5796875953674316, 'logps/chosen': -342.5, 'logps/rejected': -154.9499969482422, 'logits/chosen': -7.559374809265137, 'logits/rejected': -7.368750095367432, 'epoch': 2.01}
 67%|██████▋   | 3050/4545 [3:18:22<1:26:35,  3.48s/it] 67%|██████▋   | 3051/4545 [3:18:26<1:29:48,  3.61s/it] 67%|██████▋   | 3052/4545 [3:18:30<1:32:00,  3.70s/it] 67%|██████▋   | 3053/4545 [3:18:34<1:34:47,  3.81s/it] 67%|██████▋   | 3054/4545 [3:18:38<1:35:42,  3.85s/it] 67%|██████▋   | 3055/4545 [3:18:41<1:36:04,  3.87s/it] 67%|██████▋   | 3056/4545 [3:18:46<1:38:13,  3.96s/it] 67%|██████▋   | 3057/4545 [3:18:50<1:37:53,  3.95s/it] 67%|██████▋   | 3058/4545 [3:18:53<1:37:35,  3.94s/it] 67%|██████▋   | 3059/4545 [3:18:57<1:37:16,  3.93s/it] 67%|██████▋   | 3060/4545 [3:19:01<1:33:24,  3.77s/it]                                                       {'loss': 0.3167, 'grad_norm': 15.77118968963623, 'learning_rate': 5.362427765091152e-08, 'rewards/chosen': 1.3745605945587158, 'rewards/rejected': -2.1539063453674316, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.53125, 'logps/chosen': -296.20001220703125, 'logps/rejected': -190.35000610351562, 'logits/chosen': -7.518750190734863, 'logits/rejected': -7.065625190734863, 'epoch': 2.02}
 67%|██████▋   | 3060/4545 [3:19:01<1:33:24,  3.77s/it] 67%|██████▋   | 3061/4545 [3:19:05<1:34:27,  3.82s/it] 67%|██████▋   | 3062/4545 [3:19:09<1:35:04,  3.85s/it] 67%|██████▋   | 3063/4545 [3:19:13<1:35:34,  3.87s/it] 67%|██████▋   | 3064/4545 [3:19:16<1:34:08,  3.81s/it] 67%|██████▋   | 3065/4545 [3:19:20<1:36:43,  3.92s/it] 67%|██████▋   | 3066/4545 [3:19:24<1:32:34,  3.76s/it] 67%|██████▋   | 3067/4545 [3:19:28<1:33:09,  3.78s/it] 68%|██████▊   | 3068/4545 [3:19:32<1:35:05,  3.86s/it] 68%|██████▊   | 3069/4545 [3:19:35<1:32:20,  3.75s/it] 68%|██████▊   | 3070/4545 [3:19:38<1:26:17,  3.51s/it]                                                       {'loss': 0.3221, 'grad_norm': 12.66498851776123, 'learning_rate': 5.315815867633456e-08, 'rewards/chosen': 0.591259777545929, 'rewards/rejected': -2.2953124046325684, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.883593797683716, 'logps/chosen': -172.5, 'logps/rejected': -113.8499984741211, 'logits/chosen': -7.793749809265137, 'logits/rejected': -7.525000095367432, 'epoch': 2.03}
 68%|██████▊   | 3070/4545 [3:19:38<1:26:17,  3.51s/it] 68%|██████▊   | 3071/4545 [3:19:42<1:31:06,  3.71s/it] 68%|██████▊   | 3072/4545 [3:19:46<1:32:36,  3.77s/it] 68%|██████▊   | 3073/4545 [3:19:50<1:35:15,  3.88s/it] 68%|██████▊   | 3074/4545 [3:19:54<1:31:25,  3.73s/it] 68%|██████▊   | 3075/4545 [3:19:58<1:32:49,  3.79s/it] 68%|██████▊   | 3076/4545 [3:20:02<1:33:44,  3.83s/it] 68%|██████▊   | 3077/4545 [3:20:05<1:34:14,  3.85s/it] 68%|██████▊   | 3078/4545 [3:20:09<1:32:41,  3.79s/it] 68%|██████▊   | 3079/4545 [3:20:13<1:33:25,  3.82s/it] 68%|██████▊   | 3080/4545 [3:20:16<1:24:39,  3.47s/it]                                                       {'loss': 0.2324, 'grad_norm': 13.591584205627441, 'learning_rate': 5.269223757004607e-08, 'rewards/chosen': 1.2599670886993408, 'rewards/rejected': -2.637500047683716, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.893749952316284, 'logps/chosen': -279.6499938964844, 'logps/rejected': -202.3000030517578, 'logits/chosen': -7.509375095367432, 'logits/rejected': -7.137499809265137, 'epoch': 2.03}
 68%|██████▊   | 3080/4545 [3:20:16<1:24:39,  3.47s/it] 68%|██████▊   | 3081/4545 [3:20:20<1:28:44,  3.64s/it] 68%|██████▊   | 3082/4545 [3:20:24<1:30:05,  3.69s/it] 68%|██████▊   | 3083/4545 [3:20:28<1:32:50,  3.81s/it] 68%|██████▊   | 3084/4545 [3:20:32<1:33:36,  3.84s/it] 68%|██████▊   | 3085/4545 [3:20:35<1:33:26,  3.84s/it] 68%|██████▊   | 3086/4545 [3:20:38<1:23:21,  3.43s/it] 68%|██████▊   | 3087/4545 [3:20:42<1:26:58,  3.58s/it] 68%|██████▊   | 3088/4545 [3:20:46<1:29:14,  3.68s/it] 68%|██████▊   | 3089/4545 [3:20:50<1:30:50,  3.74s/it] 68%|██████▊   | 3090/4545 [3:20:53<1:31:58,  3.79s/it]                                                       {'loss': 0.3532, 'grad_norm': 19.90513038635254, 'learning_rate': 5.2226564385767115e-08, 'rewards/chosen': 1.3427002429962158, 'rewards/rejected': -1.7822265625, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.1226563453674316, 'logps/chosen': -309.25, 'logps/rejected': -167.85000610351562, 'logits/chosen': -7.559374809265137, 'logits/rejected': -7.268750190734863, 'epoch': 2.04}
 68%|██████▊   | 3090/4545 [3:20:53<1:31:58,  3.79s/it] 68%|██████▊   | 3091/4545 [3:20:57<1:28:32,  3.65s/it] 68%|██████▊   | 3092/4545 [3:21:00<1:27:53,  3.63s/it] 68%|██████▊   | 3093/4545 [3:21:04<1:30:15,  3.73s/it] 68%|██████▊   | 3094/4545 [3:21:08<1:31:40,  3.79s/it] 68%|██████▊   | 3095/4545 [3:21:11<1:21:50,  3.39s/it] 68%|██████▊   | 3096/4545 [3:21:15<1:26:31,  3.58s/it] 68%|██████▊   | 3097/4545 [3:21:19<1:29:31,  3.71s/it] 68%|██████▊   | 3098/4545 [3:21:23<1:30:59,  3.77s/it] 68%|██████▊   | 3099/4545 [3:21:27<1:31:58,  3.82s/it] 68%|██████▊   | 3100/4545 [3:21:30<1:32:30,  3.84s/it]                                                       {'loss': 0.3985, 'grad_norm': 13.546547889709473, 'learning_rate': 5.17611891505846e-08, 'rewards/chosen': 1.740087866783142, 'rewards/rejected': -1.602929711341858, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.344531297683716, 'logps/chosen': -341.8999938964844, 'logps/rejected': -222.4499969482422, 'logits/chosen': -7.640625, 'logits/rejected': -7.040625095367432, 'epoch': 2.05}
 68%|██████▊   | 3100/4545 [3:21:31<1:32:30,  3.84s/it] 68%|██████▊   | 3101/4545 [3:21:34<1:29:37,  3.72s/it] 68%|██████▊   | 3102/4545 [3:21:38<1:31:04,  3.79s/it] 68%|██████▊   | 3103/4545 [3:21:42<1:31:53,  3.82s/it] 68%|██████▊   | 3104/4545 [3:21:46<1:34:38,  3.94s/it] 68%|██████▊   | 3105/4545 [3:21:48<1:23:18,  3.47s/it] 68%|██████▊   | 3106/4545 [3:21:52<1:27:21,  3.64s/it] 68%|██████▊   | 3107/4545 [3:21:56<1:23:18,  3.48s/it] 68%|██████▊   | 3108/4545 [3:21:59<1:26:28,  3.61s/it] 68%|██████▊   | 3109/4545 [3:22:03<1:29:29,  3.74s/it] 68%|██████▊   | 3110/4545 [3:22:07<1:30:38,  3.79s/it]                                                       {'loss': 0.3473, 'grad_norm': 16.46965789794922, 'learning_rate': 5.129616185957687e-08, 'rewards/chosen': 1.4130859375, 'rewards/rejected': -1.7468750476837158, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.1585936546325684, 'logps/chosen': -281.29998779296875, 'logps/rejected': -152.1999969482422, 'logits/chosen': -7.746874809265137, 'logits/rejected': -7.4375, 'epoch': 2.05}
 68%|██████▊   | 3110/4545 [3:22:07<1:30:38,  3.79s/it] 68%|██████▊   | 3111/4545 [3:22:11<1:31:28,  3.83s/it] 68%|██████▊   | 3112/4545 [3:22:16<1:34:18,  3.95s/it] 68%|██████▊   | 3113/4545 [3:22:19<1:27:47,  3.68s/it] 69%|██████▊   | 3114/4545 [3:22:22<1:29:21,  3.75s/it] 69%|██████▊   | 3115/4545 [3:22:26<1:30:33,  3.80s/it] 69%|██████▊   | 3116/4545 [3:22:30<1:31:14,  3.83s/it] 69%|██████▊   | 3117/4545 [3:22:34<1:32:46,  3.90s/it] 69%|██████▊   | 3118/4545 [3:22:38<1:32:44,  3.90s/it] 69%|██████▊   | 3119/4545 [3:22:42<1:32:47,  3.90s/it] 69%|██████▊   | 3120/4545 [3:22:46<1:29:41,  3.78s/it]                                                       {'loss': 0.2667, 'grad_norm': 10.6889066696167, 'learning_rate': 5.083153247044277e-08, 'rewards/chosen': 2.5400633811950684, 'rewards/rejected': -1.91015625, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.454687595367432, 'logps/chosen': -479.6499938964844, 'logps/rejected': -266.20001220703125, 'logits/chosen': -7.284375190734863, 'logits/rejected': -7.018750190734863, 'epoch': 2.06}
 69%|██████▊   | 3120/4545 [3:22:46<1:29:41,  3.78s/it] 69%|██████▊   | 3121/4545 [3:22:50<1:30:46,  3.82s/it] 69%|██████▊   | 3122/4545 [3:22:54<1:33:20,  3.94s/it] 69%|██████▊   | 3123/4545 [3:22:58<1:33:07,  3.93s/it] 69%|██████▊   | 3124/4545 [3:23:00<1:24:28,  3.57s/it] 69%|██████▉   | 3125/4545 [3:23:04<1:26:58,  3.68s/it] 69%|██████▉   | 3126/4545 [3:23:07<1:21:02,  3.43s/it] 69%|██████▉   | 3127/4545 [3:23:11<1:24:19,  3.57s/it] 69%|██████▉   | 3128/4545 [3:23:15<1:26:45,  3.67s/it] 69%|██████▉   | 3129/4545 [3:23:17<1:18:01,  3.31s/it] 69%|██████▉   | 3130/4545 [3:23:21<1:20:40,  3.42s/it]                                                       {'loss': 0.3107, 'grad_norm': 23.733728408813477, 'learning_rate': 5.0367350898134686e-08, 'rewards/chosen': 1.329833984375, 'rewards/rejected': -1.3669922351837158, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.692187547683716, 'logps/chosen': -275.2250061035156, 'logps/rejected': -210.5500030517578, 'logits/chosen': -7.731249809265137, 'logits/rejected': -7.349999904632568, 'epoch': 2.07}
 69%|██████▉   | 3130/4545 [3:23:21<1:20:40,  3.42s/it] 69%|██████▉   | 3131/4545 [3:23:24<1:18:21,  3.32s/it] 69%|██████▉   | 3132/4545 [3:23:28<1:24:44,  3.60s/it] 69%|██████▉   | 3133/4545 [3:23:31<1:20:00,  3.40s/it] 69%|██████▉   | 3134/4545 [3:23:35<1:23:39,  3.56s/it] 69%|██████▉   | 3135/4545 [3:23:39<1:26:02,  3.66s/it] 69%|██████▉   | 3136/4545 [3:23:43<1:28:26,  3.77s/it] 69%|██████▉   | 3137/4545 [3:23:47<1:31:08,  3.88s/it] 69%|██████▉   | 3138/4545 [3:23:50<1:23:39,  3.57s/it] 69%|██████▉   | 3139/4545 [3:23:54<1:24:03,  3.59s/it] 69%|██████▉   | 3140/4545 [3:23:58<1:26:31,  3.70s/it]                                                       {'loss': 0.3159, 'grad_norm': 19.9337215423584, 'learning_rate': 4.990366700949626e-08, 'rewards/chosen': 1.1126708984375, 'rewards/rejected': -1.826171875, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.942187547683716, 'logps/chosen': -252.5500030517578, 'logps/rejected': -189.9499969482422, 'logits/chosen': -7.743750095367432, 'logits/rejected': -7.296875, 'epoch': 2.07}
 69%|██████▉   | 3140/4545 [3:23:58<1:26:31,  3.70s/it] 69%|██████▉   | 3141/4545 [3:24:02<1:28:03,  3.76s/it] 69%|██████▉   | 3142/4545 [3:24:06<1:29:01,  3.81s/it] 69%|██████▉   | 3143/4545 [3:24:08<1:20:50,  3.46s/it] 69%|██████▉   | 3144/4545 [3:24:12<1:21:50,  3.50s/it] 69%|██████▉   | 3145/4545 [3:24:16<1:25:10,  3.65s/it] 69%|██████▉   | 3146/4545 [3:24:20<1:26:57,  3.73s/it] 69%|██████▉   | 3147/4545 [3:24:24<1:28:29,  3.80s/it] 69%|██████▉   | 3148/4545 [3:24:28<1:29:14,  3.83s/it] 69%|██████▉   | 3149/4545 [3:24:30<1:20:20,  3.45s/it] 69%|██████▉   | 3150/4545 [3:24:34<1:23:32,  3.59s/it]                                                       {'loss': 0.3429, 'grad_norm': 24.364723205566406, 'learning_rate': 4.944053061790515e-08, 'rewards/chosen': 1.612768530845642, 'rewards/rejected': -1.707128882408142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.3179688453674316, 'logps/chosen': -335.70001220703125, 'logps/rejected': -180.625, 'logits/chosen': -7.443749904632568, 'logits/rejected': -7.150000095367432, 'epoch': 2.08}
 69%|██████▉   | 3150/4545 [3:24:34<1:23:32,  3.59s/it] 69%|██████▉   | 3151/4545 [3:24:38<1:26:45,  3.73s/it] 69%|██████▉   | 3152/4545 [3:24:42<1:27:56,  3.79s/it] 69%|██████▉   | 3153/4545 [3:24:46<1:30:04,  3.88s/it] 69%|██████▉   | 3154/4545 [3:24:50<1:30:22,  3.90s/it] 69%|██████▉   | 3155/4545 [3:24:54<1:29:31,  3.86s/it] 69%|██████▉   | 3156/4545 [3:24:56<1:19:29,  3.43s/it] 69%|██████▉   | 3157/4545 [3:25:00<1:20:26,  3.48s/it] 69%|██████▉   | 3158/4545 [3:25:04<1:24:55,  3.67s/it] 70%|██████▉   | 3159/4545 [3:25:07<1:22:29,  3.57s/it] 70%|██████▉   | 3160/4545 [3:25:11<1:24:47,  3.67s/it]                                                       {'loss': 0.3004, 'grad_norm': 22.049442291259766, 'learning_rate': 4.8977991477921596e-08, 'rewards/chosen': 1.3987305164337158, 'rewards/rejected': -1.741308569908142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.135937452316284, 'logps/chosen': -288.2749938964844, 'logps/rejected': -235.60000610351562, 'logits/chosen': -7.449999809265137, 'logits/rejected': -7.015625, 'epoch': 2.09}
 70%|██████▉   | 3160/4545 [3:25:11<1:24:47,  3.67s/it] 70%|██████▉   | 3161/4545 [3:25:15<1:23:35,  3.62s/it] 70%|██████▉   | 3162/4545 [3:25:19<1:25:27,  3.71s/it] 70%|██████▉   | 3163/4545 [3:25:23<1:26:16,  3.75s/it] 70%|██████▉   | 3164/4545 [3:25:26<1:24:12,  3.66s/it] 70%|██████▉   | 3165/4545 [3:25:30<1:22:31,  3.59s/it] 70%|██████▉   | 3166/4545 [3:25:33<1:24:56,  3.70s/it] 70%|██████▉   | 3167/4545 [3:25:37<1:26:17,  3.76s/it] 70%|██████▉   | 3168/4545 [3:25:41<1:26:52,  3.79s/it] 70%|██████▉   | 3169/4545 [3:25:45<1:27:14,  3.80s/it] 70%|██████▉   | 3170/4545 [3:25:49<1:27:56,  3.84s/it]                                                       {'loss': 0.2715, 'grad_norm': 9.860247611999512, 'learning_rate': 4.851609927994337e-08, 'rewards/chosen': 1.0541260242462158, 'rewards/rejected': -2.780078172683716, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.8343749046325684, 'logps/chosen': -263.75, 'logps/rejected': -178.3000030517578, 'logits/chosen': -7.675000190734863, 'logits/rejected': -7.181250095367432, 'epoch': 2.09}
 70%|██████▉   | 3170/4545 [3:25:49<1:27:56,  3.84s/it] 70%|██████▉   | 3171/4545 [3:25:52<1:24:18,  3.68s/it] 70%|██████▉   | 3172/4545 [3:25:56<1:26:12,  3.77s/it] 70%|██████▉   | 3173/4545 [3:26:01<1:31:21,  4.00s/it] 70%|██████▉   | 3174/4545 [3:26:05<1:30:47,  3.97s/it] 70%|██████▉   | 3175/4545 [3:26:08<1:27:28,  3.83s/it] 70%|██████▉   | 3176/4545 [3:26:12<1:27:53,  3.85s/it] 70%|██████▉   | 3177/4545 [3:26:16<1:28:20,  3.87s/it] 70%|██████▉   | 3178/4545 [3:26:20<1:28:32,  3.89s/it] 70%|██████▉   | 3179/4545 [3:26:24<1:28:40,  3.89s/it] 70%|██████▉   | 3180/4545 [3:26:28<1:28:49,  3.90s/it]                                                       {'loss': 0.3106, 'grad_norm': 9.73586368560791, 'learning_rate': 4.805490364486749e-08, 'rewards/chosen': 2.413647413253784, 'rewards/rejected': -1.610742211341858, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.026562690734863, 'logps/chosen': -444.29998779296875, 'logps/rejected': -217.3000030517578, 'logits/chosen': -7.306250095367432, 'logits/rejected': -7.337500095367432, 'epoch': 2.1}
 70%|██████▉   | 3180/4545 [3:26:28<1:28:49,  3.90s/it] 70%|██████▉   | 3181/4545 [3:26:32<1:30:06,  3.96s/it] 70%|███████   | 3182/4545 [3:26:36<1:29:34,  3.94s/it] 70%|███████   | 3183/4545 [3:26:40<1:29:22,  3.94s/it] 70%|███████   | 3184/4545 [3:26:44<1:29:06,  3.93s/it] 70%|███████   | 3185/4545 [3:26:48<1:28:56,  3.92s/it] 70%|███████   | 3186/4545 [3:26:51<1:26:09,  3.80s/it] 70%|███████   | 3187/4545 [3:26:54<1:22:29,  3.64s/it] 70%|███████   | 3188/4545 [3:26:58<1:24:54,  3.75s/it] 70%|███████   | 3189/4545 [3:27:02<1:27:16,  3.86s/it] 70%|███████   | 3190/4545 [3:27:06<1:27:29,  3.87s/it]                                                       {'loss': 0.2793, 'grad_norm': 12.940966606140137, 'learning_rate': 4.759445411875952e-08, 'rewards/chosen': 1.4919922351837158, 'rewards/rejected': -2.1929688453674316, 'rewards/accuracies': 0.875, 'rewards/margins': 3.6812500953674316, 'logps/chosen': -279.3500061035156, 'logps/rejected': -167.5, 'logits/chosen': -7.665625095367432, 'logits/rejected': -7.440625190734863, 'epoch': 2.11}
 70%|███████   | 3190/4545 [3:27:06<1:27:29,  3.87s/it] 70%|███████   | 3191/4545 [3:27:11<1:31:21,  4.05s/it] 70%|███████   | 3192/4545 [3:27:15<1:31:46,  4.07s/it] 70%|███████   | 3193/4545 [3:27:18<1:24:15,  3.74s/it] 70%|███████   | 3194/4545 [3:27:22<1:26:52,  3.86s/it] 70%|███████   | 3195/4545 [3:27:26<1:27:22,  3.88s/it] 70%|███████   | 3196/4545 [3:27:30<1:27:41,  3.90s/it] 70%|███████   | 3197/4545 [3:27:34<1:27:36,  3.90s/it] 70%|███████   | 3198/4545 [3:27:37<1:25:42,  3.82s/it] 70%|███████   | 3199/4545 [3:27:41<1:26:14,  3.84s/it] 70%|███████   | 3200/4545 [3:27:45<1:27:57,  3.92s/it]                                                       {'loss': 0.294, 'grad_norm': 21.07426643371582, 'learning_rate': 4.713480016753083e-08, 'rewards/chosen': 2.122424364089966, 'rewards/rejected': -1.2752685546875, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.401562452316284, 'logps/chosen': -409.75, 'logps/rejected': -243.8000030517578, 'logits/chosen': -7.390625, 'logits/rejected': -7.356249809265137, 'epoch': 2.11}
 70%|███████   | 3200/4545 [3:27:45<1:27:57,  3.92s/it] 70%|███████   | 3201/4545 [3:27:49<1:27:55,  3.93s/it] 70%|███████   | 3202/4545 [3:27:53<1:24:50,  3.79s/it] 70%|███████   | 3203/4545 [3:27:57<1:25:58,  3.84s/it] 70%|███████   | 3204/4545 [3:28:00<1:19:54,  3.58s/it] 71%|███████   | 3205/4545 [3:28:02<1:10:36,  3.16s/it] 71%|███████   | 3206/4545 [3:28:06<1:17:41,  3.48s/it] 71%|███████   | 3207/4545 [3:28:09<1:16:05,  3.41s/it] 71%|███████   | 3208/4545 [3:28:12<1:12:28,  3.25s/it] 71%|███████   | 3209/4545 [3:28:15<1:11:37,  3.22s/it] 71%|███████   | 3210/4545 [3:28:19<1:14:19,  3.34s/it]                                                       {'loss': 0.2902, 'grad_norm': 18.63271713256836, 'learning_rate': 4.6675991171624454e-08, 'rewards/chosen': 0.9044739007949829, 'rewards/rejected': -2.7046875953674316, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.6109375953674316, 'logps/chosen': -209.375, 'logps/rejected': -128.60000610351562, 'logits/chosen': -7.75, 'logits/rejected': -7.381249904632568, 'epoch': 2.12}
 71%|███████   | 3210/4545 [3:28:19<1:14:19,  3.34s/it] 71%|███████   | 3211/4545 [3:28:23<1:19:03,  3.56s/it] 71%|███████   | 3212/4545 [3:28:27<1:21:17,  3.66s/it] 71%|███████   | 3213/4545 [3:28:31<1:23:10,  3.75s/it] 71%|███████   | 3214/4545 [3:28:35<1:24:17,  3.80s/it] 71%|███████   | 3215/4545 [3:28:39<1:26:02,  3.88s/it] 71%|███████   | 3216/4545 [3:28:42<1:20:24,  3.63s/it] 71%|███████   | 3217/4545 [3:28:46<1:22:12,  3.71s/it] 71%|███████   | 3218/4545 [3:28:50<1:23:25,  3.77s/it] 71%|███████   | 3219/4545 [3:28:54<1:24:13,  3.81s/it] 71%|███████   | 3220/4545 [3:28:58<1:24:21,  3.82s/it]                                                       {'loss': 0.3405, 'grad_norm': 22.660125732421875, 'learning_rate': 4.6218076420710275e-08, 'rewards/chosen': 1.989343285560608, 'rewards/rejected': -1.9905273914337158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.9828124046325684, 'logps/chosen': -400.54998779296875, 'logps/rejected': -219.14999389648438, 'logits/chosen': -7.449999809265137, 'logits/rejected': -7.400000095367432, 'epoch': 2.13}
 71%|███████   | 3220/4545 [3:28:58<1:24:21,  3.82s/it] 71%|███████   | 3221/4545 [3:29:01<1:24:51,  3.85s/it] 71%|███████   | 3222/4545 [3:29:04<1:16:51,  3.49s/it] 71%|███████   | 3223/4545 [3:29:08<1:19:21,  3.60s/it] 71%|███████   | 3224/4545 [3:29:12<1:22:18,  3.74s/it] 71%|███████   | 3225/4545 [3:29:15<1:16:55,  3.50s/it] 71%|███████   | 3226/4545 [3:29:18<1:14:40,  3.40s/it] 71%|███████   | 3227/4545 [3:29:22<1:17:54,  3.55s/it] 71%|███████   | 3228/4545 [3:29:26<1:22:07,  3.74s/it] 71%|███████   | 3229/4545 [3:29:30<1:20:37,  3.68s/it] 71%|███████   | 3230/4545 [3:29:34<1:22:04,  3.75s/it]                                                       {'loss': 0.3405, 'grad_norm': 25.032176971435547, 'learning_rate': 4.576110510838973e-08, 'rewards/chosen': 0.855090320110321, 'rewards/rejected': -2.805468797683716, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.663281202316284, 'logps/chosen': -252.14999389648438, 'logps/rejected': -169.10000610351562, 'logits/chosen': -7.650000095367432, 'logits/rejected': -7.237500190734863, 'epoch': 2.13}
 71%|███████   | 3230/4545 [3:29:34<1:22:04,  3.75s/it] 71%|███████   | 3231/4545 [3:29:37<1:21:14,  3.71s/it] 71%|███████   | 3232/4545 [3:29:41<1:20:46,  3.69s/it] 71%|███████   | 3233/4545 [3:29:45<1:22:07,  3.76s/it] 71%|███████   | 3234/4545 [3:29:49<1:24:09,  3.85s/it] 71%|███████   | 3235/4545 [3:29:53<1:26:15,  3.95s/it] 71%|███████   | 3236/4545 [3:29:57<1:25:52,  3.94s/it] 71%|███████   | 3237/4545 [3:30:01<1:25:46,  3.93s/it] 71%|███████   | 3238/4545 [3:30:05<1:25:42,  3.93s/it] 71%|███████▏  | 3239/4545 [3:30:09<1:24:26,  3.88s/it] 71%|███████▏  | 3240/4545 [3:30:12<1:18:53,  3.63s/it]                                                       {'loss': 0.3017, 'grad_norm': 17.141679763793945, 'learning_rate': 4.530512632691106e-08, 'rewards/chosen': 1.2837417125701904, 'rewards/rejected': -2.7796874046325684, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.059374809265137, 'logps/chosen': -258.75, 'logps/rejected': -141.75, 'logits/chosen': -7.878125190734863, 'logits/rejected': -7.4375, 'epoch': 2.14}
 71%|███████▏  | 3240/4545 [3:30:12<1:18:53,  3.63s/it] 71%|███████▏  | 3241/4545 [3:30:16<1:22:44,  3.81s/it] 71%|███████▏  | 3242/4545 [3:30:20<1:23:18,  3.84s/it] 71%|███████▏  | 3243/4545 [3:30:23<1:22:04,  3.78s/it] 71%|███████▏  | 3244/4545 [3:30:27<1:23:05,  3.83s/it] 71%|███████▏  | 3245/4545 [3:30:31<1:23:36,  3.86s/it] 71%|███████▏  | 3246/4545 [3:30:35<1:19:09,  3.66s/it] 71%|███████▏  | 3247/4545 [3:30:38<1:16:11,  3.52s/it] 71%|███████▏  | 3248/4545 [3:30:42<1:18:00,  3.61s/it] 71%|███████▏  | 3249/4545 [3:30:45<1:19:53,  3.70s/it] 72%|███████▏  | 3250/4545 [3:30:49<1:17:49,  3.61s/it]                                                       {'loss': 0.301, 'grad_norm': 20.717086791992188, 'learning_rate': 4.4850189061895284e-08, 'rewards/chosen': 1.5119140148162842, 'rewards/rejected': -1.9890625476837158, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.50390625, 'logps/chosen': -319.54998779296875, 'logps/rejected': -189.0500030517578, 'logits/chosen': -7.556250095367432, 'logits/rejected': -7.487500190734863, 'epoch': 2.15}
 72%|███████▏  | 3250/4545 [3:30:49<1:17:49,  3.61s/it] 72%|███████▏  | 3251/4545 [3:30:53<1:21:06,  3.76s/it] 72%|███████▏  | 3252/4545 [3:30:57<1:23:12,  3.86s/it] 72%|███████▏  | 3253/4545 [3:31:01<1:20:59,  3.76s/it] 72%|███████▏  | 3254/4545 [3:31:05<1:22:55,  3.85s/it] 72%|███████▏  | 3255/4545 [3:31:09<1:24:54,  3.95s/it] 72%|███████▏  | 3256/4545 [3:31:12<1:19:17,  3.69s/it] 72%|███████▏  | 3257/4545 [3:31:16<1:20:03,  3.73s/it] 72%|███████▏  | 3258/4545 [3:31:20<1:21:17,  3.79s/it] 72%|███████▏  | 3259/4545 [3:31:24<1:22:00,  3.83s/it] 72%|███████▏  | 3260/4545 [3:31:27<1:22:07,  3.83s/it]                                                       {'loss': 0.3478, 'grad_norm': 22.36494255065918, 'learning_rate': 4.439634218707371e-08, 'rewards/chosen': 0.994921863079071, 'rewards/rejected': -2.093554735183716, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.0859375, 'logps/chosen': -248.0500030517578, 'logps/rejected': -178.14999389648438, 'logits/chosen': -7.650000095367432, 'logits/rejected': -7.540625095367432, 'epoch': 2.15}
 72%|███████▏  | 3260/4545 [3:31:27<1:22:07,  3.83s/it] 72%|███████▏  | 3261/4545 [3:31:31<1:22:36,  3.86s/it] 72%|███████▏  | 3262/4545 [3:31:35<1:22:59,  3.88s/it] 72%|███████▏  | 3263/4545 [3:31:39<1:21:39,  3.82s/it] 72%|███████▏  | 3264/4545 [3:31:42<1:18:24,  3.67s/it] 72%|███████▏  | 3265/4545 [3:31:46<1:19:38,  3.73s/it] 72%|███████▏  | 3266/4545 [3:31:50<1:21:30,  3.82s/it] 72%|███████▏  | 3267/4545 [3:31:54<1:21:56,  3.85s/it] 72%|███████▏  | 3268/4545 [3:31:57<1:14:56,  3.52s/it] 72%|███████▏  | 3269/4545 [3:32:01<1:17:51,  3.66s/it] 72%|███████▏  | 3270/4545 [3:32:05<1:21:24,  3.83s/it]                                                       {'loss': 0.3133, 'grad_norm': 11.188979148864746, 'learning_rate': 4.394363445903749e-08, 'rewards/chosen': 1.69189453125, 'rewards/rejected': -1.040429711341858, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.729687452316284, 'logps/chosen': -327.45001220703125, 'logps/rejected': -257.57501220703125, 'logits/chosen': -7.743750095367432, 'logits/rejected': -7.446875095367432, 'epoch': 2.16}
 72%|███████▏  | 3270/4545 [3:32:05<1:21:24,  3.83s/it] 72%|███████▏  | 3271/4545 [3:32:09<1:21:53,  3.86s/it] 72%|███████▏  | 3272/4545 [3:32:12<1:18:00,  3.68s/it] 72%|███████▏  | 3273/4545 [3:32:16<1:19:19,  3.74s/it] 72%|███████▏  | 3274/4545 [3:32:19<1:13:05,  3.45s/it] 72%|███████▏  | 3275/4545 [3:32:22<1:12:15,  3.41s/it] 72%|███████▏  | 3276/4545 [3:32:26<1:16:40,  3.63s/it] 72%|███████▏  | 3277/4545 [3:32:30<1:16:13,  3.61s/it] 72%|███████▏  | 3278/4545 [3:32:34<1:18:05,  3.70s/it] 72%|███████▏  | 3279/4545 [3:32:38<1:19:28,  3.77s/it] 72%|███████▏  | 3280/4545 [3:32:41<1:13:18,  3.48s/it]                                                       {'loss': 0.3538, 'grad_norm': 20.7515926361084, 'learning_rate': 4.3492114511999646e-08, 'rewards/chosen': 0.972973644733429, 'rewards/rejected': -2.028125047683716, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.9976563453674316, 'logps/chosen': -236.14999389648438, 'logps/rejected': -131.75, 'logits/chosen': -7.878125190734863, 'logits/rejected': -7.518750190734863, 'epoch': 2.17}
 72%|███████▏  | 3280/4545 [3:32:41<1:13:18,  3.48s/it] 72%|███████▏  | 3281/4545 [3:32:44<1:14:08,  3.52s/it] 72%|███████▏  | 3282/4545 [3:32:47<1:07:26,  3.20s/it] 72%|███████▏  | 3283/4545 [3:32:51<1:12:28,  3.45s/it] 72%|███████▏  | 3284/4545 [3:32:55<1:15:36,  3.60s/it] 72%|███████▏  | 3285/4545 [3:32:58<1:13:05,  3.48s/it] 72%|███████▏  | 3286/4545 [3:33:02<1:16:41,  3.65s/it] 72%|███████▏  | 3287/4545 [3:33:05<1:10:10,  3.35s/it] 72%|███████▏  | 3288/4545 [3:33:08<1:13:38,  3.52s/it] 72%|███████▏  | 3289/4545 [3:33:11<1:09:22,  3.31s/it] 72%|███████▏  | 3290/4545 [3:33:15<1:13:46,  3.53s/it]                                                       {'loss': 0.3118, 'grad_norm': 22.943777084350586, 'learning_rate': 4.304183085257038e-08, 'rewards/chosen': 0.748034656047821, 'rewards/rejected': -2.2046875953674316, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.953125, 'logps/chosen': -198.64999389648438, 'logps/rejected': -136.25, 'logits/chosen': -7.671875, 'logits/rejected': -7.328125, 'epoch': 2.17}
 72%|███████▏  | 3290/4545 [3:33:15<1:13:46,  3.53s/it] 72%|███████▏  | 3291/4545 [3:33:19<1:14:24,  3.56s/it] 72%|███████▏  | 3292/4545 [3:33:23<1:15:34,  3.62s/it] 72%|███████▏  | 3293/4545 [3:33:26<1:14:48,  3.58s/it] 72%|███████▏  | 3294/4545 [3:33:30<1:16:59,  3.69s/it] 72%|███████▏  | 3295/4545 [3:33:34<1:18:13,  3.75s/it] 73%|███████▎  | 3296/4545 [3:33:38<1:19:04,  3.80s/it] 73%|███████▎  | 3297/4545 [3:33:42<1:20:11,  3.86s/it] 73%|███████▎  | 3298/4545 [3:33:46<1:20:25,  3.87s/it] 73%|███████▎  | 3299/4545 [3:33:49<1:13:46,  3.55s/it] 73%|███████▎  | 3300/4545 [3:33:53<1:15:48,  3.65s/it]                                                       {'loss': 0.3132, 'grad_norm': 19.035566329956055, 'learning_rate': 4.2592831854546016e-08, 'rewards/chosen': 0.9934021234512329, 'rewards/rejected': -2.317187547683716, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.311328172683716, 'logps/chosen': -243.5500030517578, 'logps/rejected': -118.0, 'logits/chosen': -7.684374809265137, 'logits/rejected': -7.349999904632568, 'epoch': 2.18}
 73%|███████▎  | 3300/4545 [3:33:53<1:15:48,  3.65s/it] 73%|███████▎  | 3301/4545 [3:33:56<1:15:53,  3.66s/it] 73%|███████▎  | 3302/4545 [3:33:59<1:13:16,  3.54s/it] 73%|███████▎  | 3303/4545 [3:34:04<1:16:51,  3.71s/it] 73%|███████▎  | 3304/4545 [3:34:07<1:13:56,  3.58s/it] 73%|███████▎  | 3305/4545 [3:34:11<1:15:37,  3.66s/it] 73%|███████▎  | 3306/4545 [3:34:15<1:17:02,  3.73s/it] 73%|███████▎  | 3307/4545 [3:34:18<1:17:58,  3.78s/it] 73%|███████▎  | 3308/4545 [3:34:22<1:18:54,  3.83s/it] 73%|███████▎  | 3309/4545 [3:34:27<1:20:58,  3.93s/it] 73%|███████▎  | 3310/4545 [3:34:30<1:19:24,  3.86s/it]                                                       {'loss': 0.3124, 'grad_norm': 15.754232406616211, 'learning_rate': 4.214516575371218e-08, 'rewards/chosen': 1.19232177734375, 'rewards/rejected': -2.5679688453674316, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.7593750953674316, 'logps/chosen': -283.25, 'logps/rejected': -166.52499389648438, 'logits/chosen': -7.775000095367432, 'logits/rejected': -7.365624904632568, 'epoch': 2.18}
 73%|███████▎  | 3310/4545 [3:34:31<1:19:24,  3.86s/it] 73%|███████▎  | 3311/4545 [3:34:34<1:19:47,  3.88s/it] 73%|███████▎  | 3312/4545 [3:34:38<1:19:54,  3.89s/it] 73%|███████▎  | 3313/4545 [3:34:42<1:21:58,  3.99s/it] 73%|███████▎  | 3314/4545 [3:34:46<1:20:18,  3.91s/it] 73%|███████▎  | 3315/4545 [3:34:50<1:20:14,  3.91s/it] 73%|███████▎  | 3316/4545 [3:34:54<1:21:19,  3.97s/it] 73%|███████▎  | 3317/4545 [3:34:57<1:12:54,  3.56s/it] 73%|███████▎  | 3318/4545 [3:35:00<1:13:59,  3.62s/it] 73%|███████▎  | 3319/4545 [3:35:04<1:13:21,  3.59s/it] 73%|███████▎  | 3320/4545 [3:35:08<1:16:22,  3.74s/it]                                                       {'loss': 0.3119, 'grad_norm': 39.90990447998047, 'learning_rate': 4.169888064266188e-08, 'rewards/chosen': 1.721337914466858, 'rewards/rejected': -2.113818407058716, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.8343749046325684, 'logps/chosen': -347.75, 'logps/rejected': -200.0, 'logits/chosen': -7.456250190734863, 'logits/rejected': -7.1875, 'epoch': 2.19}
 73%|███████▎  | 3320/4545 [3:35:08<1:16:22,  3.74s/it] 73%|███████▎  | 3321/4545 [3:35:12<1:14:52,  3.67s/it] 73%|███████▎  | 3322/4545 [3:35:15<1:12:26,  3.55s/it] 73%|███████▎  | 3323/4545 [3:35:19<1:14:33,  3.66s/it] 73%|███████▎  | 3324/4545 [3:35:23<1:16:29,  3.76s/it] 73%|███████▎  | 3325/4545 [3:35:25<1:09:42,  3.43s/it] 73%|███████▎  | 3326/4545 [3:35:29<1:12:35,  3.57s/it] 73%|███████▎  | 3327/4545 [3:35:33<1:14:23,  3.66s/it] 73%|███████▎  | 3328/4545 [3:35:37<1:14:21,  3.67s/it] 73%|███████▎  | 3329/4545 [3:35:41<1:15:56,  3.75s/it] 73%|███████▎  | 3330/4545 [3:35:45<1:16:40,  3.79s/it]                                                       {'loss': 0.3235, 'grad_norm': 13.351654052734375, 'learning_rate': 4.1254024465628934e-08, 'rewards/chosen': 0.7735961675643921, 'rewards/rejected': -1.7311522960662842, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.5023436546325684, 'logps/chosen': -208.5, 'logps/rejected': -146.10000610351562, 'logits/chosen': -7.881249904632568, 'logits/rejected': -7.574999809265137, 'epoch': 2.2}
 73%|███████▎  | 3330/4545 [3:35:45<1:16:40,  3.79s/it] 73%|███████▎  | 3331/4545 [3:35:49<1:17:17,  3.82s/it] 73%|███████▎  | 3332/4545 [3:35:53<1:17:48,  3.85s/it] 73%|███████▎  | 3333/4545 [3:35:56<1:16:13,  3.77s/it] 73%|███████▎  | 3334/4545 [3:35:59<1:10:13,  3.48s/it] 73%|███████▎  | 3335/4545 [3:36:02<1:06:23,  3.29s/it] 73%|███████▎  | 3336/4545 [3:36:04<1:02:03,  3.08s/it] 73%|███████▎  | 3337/4545 [3:36:07<1:00:57,  3.03s/it] 73%|███████▎  | 3338/4545 [3:36:11<1:06:12,  3.29s/it] 73%|███████▎  | 3339/4545 [3:36:14<1:05:56,  3.28s/it] 73%|███████▎  | 3340/4545 [3:36:17<59:35,  2.97s/it]                                                       {'loss': 0.3481, 'grad_norm': 11.621498107910156, 'learning_rate': 4.081064501333738e-08, 'rewards/chosen': 0.5772247314453125, 'rewards/rejected': -2.522656202316284, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.102343797683716, 'logps/chosen': -154.625, 'logps/rejected': -115.4000015258789, 'logits/chosen': -7.884375095367432, 'logits/rejected': -7.446875095367432, 'epoch': 2.2}
 73%|███████▎  | 3340/4545 [3:36:17<59:35,  2.97s/it] 74%|███████▎  | 3341/4545 [3:36:21<1:05:24,  3.26s/it] 74%|███████▎  | 3342/4545 [3:36:25<1:12:30,  3.62s/it] 74%|███████▎  | 3343/4545 [3:36:29<1:14:52,  3.74s/it] 74%|███████▎  | 3344/4545 [3:36:33<1:15:50,  3.79s/it] 74%|███████▎  | 3345/4545 [3:36:36<1:12:38,  3.63s/it] 74%|███████▎  | 3346/4545 [3:36:40<1:14:49,  3.74s/it] 74%|███████▎  | 3347/4545 [3:36:44<1:15:00,  3.76s/it] 74%|███████▎  | 3348/4545 [3:36:48<1:16:37,  3.84s/it] 74%|███████▎  | 3349/4545 [3:36:52<1:15:08,  3.77s/it] 74%|███████▎  | 3350/4545 [3:36:55<1:13:39,  3.70s/it]                                                       {'loss': 0.3717, 'grad_norm': 25.683330535888672, 'learning_rate': 4.036878991786724e-08, 'rewards/chosen': 0.717437744140625, 'rewards/rejected': -2.323046922683716, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.0414061546325684, 'logps/chosen': -223.10000610351562, 'logps/rejected': -167.39999389648438, 'logits/chosen': -7.671875, 'logits/rejected': -7.324999809265137, 'epoch': 2.21}
 74%|███████▎  | 3350/4545 [3:36:55<1:13:39,  3.70s/it] 74%|███████▎  | 3351/4545 [3:36:59<1:11:54,  3.61s/it] 74%|███████▍  | 3352/4545 [3:37:02<1:11:28,  3.59s/it] 74%|███████▍  | 3353/4545 [3:37:06<1:11:25,  3.60s/it] 74%|███████▍  | 3354/4545 [3:37:10<1:13:01,  3.68s/it] 74%|███████▍  | 3355/4545 [3:37:13<1:12:27,  3.65s/it] 74%|███████▍  | 3356/4545 [3:37:17<1:13:59,  3.73s/it] 74%|███████▍  | 3357/4545 [3:37:21<1:14:59,  3.79s/it] 74%|███████▍  | 3358/4545 [3:37:25<1:15:41,  3.83s/it] 74%|███████▍  | 3359/4545 [3:37:29<1:16:12,  3.86s/it] 74%|███████▍  | 3360/4545 [3:37:33<1:16:29,  3.87s/it]                                                       {'loss': 0.3951, 'grad_norm': 17.906524658203125, 'learning_rate': 3.9928506647537505e-08, 'rewards/chosen': 1.740136742591858, 'rewards/rejected': -2.052807569503784, 'rewards/accuracies': 0.875, 'rewards/margins': 3.7914061546325684, 'logps/chosen': -369.1499938964844, 'logps/rejected': -220.4499969482422, 'logits/chosen': -7.578125, 'logits/rejected': -7.409375190734863, 'epoch': 2.22}
 74%|███████▍  | 3360/4545 [3:37:33<1:16:29,  3.87s/it] 74%|███████▍  | 3361/4545 [3:37:37<1:16:45,  3.89s/it] 74%|███████▍  | 3362/4545 [3:37:40<1:14:07,  3.76s/it] 74%|███████▍  | 3363/4545 [3:37:44<1:14:25,  3.78s/it] 74%|███████▍  | 3364/4545 [3:37:48<1:15:21,  3.83s/it] 74%|███████▍  | 3365/4545 [3:37:52<1:15:13,  3.82s/it] 74%|███████▍  | 3366/4545 [3:37:56<1:14:59,  3.82s/it] 74%|███████▍  | 3367/4545 [3:38:00<1:16:42,  3.91s/it] 74%|███████▍  | 3368/4545 [3:38:02<1:09:00,  3.52s/it] 74%|███████▍  | 3369/4545 [3:38:06<1:11:17,  3.64s/it] 74%|███████▍  | 3370/4545 [3:38:10<1:12:47,  3.72s/it]                                                       {'loss': 0.2592, 'grad_norm': 13.894999504089355, 'learning_rate': 3.9489842501806645e-08, 'rewards/chosen': 1.24859619140625, 'rewards/rejected': -2.3539061546325684, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.5992188453674316, 'logps/chosen': -274.8999938964844, 'logps/rejected': -170.14999389648438, 'logits/chosen': -7.734375, 'logits/rejected': -7.340624809265137, 'epoch': 2.22}
 74%|███████▍  | 3370/4545 [3:38:10<1:12:47,  3.72s/it] 74%|███████▍  | 3371/4545 [3:38:13<1:10:36,  3.61s/it] 74%|███████▍  | 3372/4545 [3:38:17<1:12:19,  3.70s/it] 74%|███████▍  | 3373/4545 [3:38:21<1:11:02,  3.64s/it] 74%|███████▍  | 3374/4545 [3:38:25<1:13:25,  3.76s/it] 74%|███████▍  | 3375/4545 [3:38:29<1:14:11,  3.81s/it] 74%|███████▍  | 3376/4545 [3:38:32<1:09:06,  3.55s/it] 74%|███████▍  | 3377/4545 [3:38:36<1:10:16,  3.61s/it] 74%|███████▍  | 3378/4545 [3:38:39<1:08:11,  3.51s/it] 74%|███████▍  | 3379/4545 [3:38:43<1:12:16,  3.72s/it] 74%|███████▍  | 3380/4545 [3:38:46<1:10:31,  3.63s/it]                                                       {'loss': 0.3566, 'grad_norm': 28.044273376464844, 'learning_rate': 3.905284460619117e-08, 'rewards/chosen': 1.1796875, 'rewards/rejected': -1.9421875476837158, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.12109375, 'logps/chosen': -268.04998779296875, 'logps/rejected': -209.4499969482422, 'logits/chosen': -7.806250095367432, 'logits/rejected': -7.265625, 'epoch': 2.23}
 74%|███████▍  | 3380/4545 [3:38:46<1:10:31,  3.63s/it] 74%|███████▍  | 3381/4545 [3:38:50<1:10:23,  3.63s/it] 74%|███████▍  | 3382/4545 [3:38:54<1:12:03,  3.72s/it] 74%|███████▍  | 3383/4545 [3:38:58<1:10:54,  3.66s/it] 74%|███████▍  | 3384/4545 [3:39:02<1:13:49,  3.82s/it] 74%|███████▍  | 3385/4545 [3:39:06<1:14:56,  3.88s/it] 74%|███████▍  | 3386/4545 [3:39:10<1:16:28,  3.96s/it] 75%|███████▍  | 3387/4545 [3:39:14<1:16:04,  3.94s/it] 75%|███████▍  | 3388/4545 [3:39:18<1:17:24,  4.01s/it] 75%|███████▍  | 3389/4545 [3:39:22<1:18:27,  4.07s/it] 75%|███████▍  | 3390/4545 [3:39:26<1:17:15,  4.01s/it]                                                       {'loss': 0.3015, 'grad_norm': 28.03887367248535, 'learning_rate': 3.8617559907203015e-08, 'rewards/chosen': 1.300390601158142, 'rewards/rejected': -2.4468750953674316, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.7515625953674316, 'logps/chosen': -305.25, 'logps/rejected': -218.85000610351562, 'logits/chosen': -7.653124809265137, 'logits/rejected': -7.309374809265137, 'epoch': 2.24}
 75%|███████▍  | 3390/4545 [3:39:26<1:17:15,  4.01s/it] 75%|███████▍  | 3391/4545 [3:39:30<1:16:37,  3.98s/it] 75%|███████▍  | 3392/4545 [3:39:34<1:18:04,  4.06s/it] 75%|███████▍  | 3393/4545 [3:39:38<1:14:48,  3.90s/it] 75%|███████▍  | 3394/4545 [3:39:42<1:14:48,  3.90s/it] 75%|███████▍  | 3395/4545 [3:39:45<1:14:29,  3.89s/it] 75%|███████▍  | 3396/4545 [3:39:49<1:10:38,  3.69s/it] 75%|███████▍  | 3397/4545 [3:39:53<1:11:58,  3.76s/it] 75%|███████▍  | 3398/4545 [3:39:55<1:06:11,  3.46s/it] 75%|███████▍  | 3399/4545 [3:39:59<1:05:55,  3.45s/it] 75%|███████▍  | 3400/4545 [3:40:02<1:05:15,  3.42s/it]                                                       {'loss': 0.2644, 'grad_norm': 12.945883750915527, 'learning_rate': 3.818403516730604e-08, 'rewards/chosen': 1.2900298833847046, 'rewards/rejected': -2.6039061546325684, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.895312547683716, 'logps/chosen': -264.75, 'logps/rejected': -202.39999389648438, 'logits/chosen': -7.962500095367432, 'logits/rejected': -7.353125095367432, 'epoch': 2.24}
 75%|███████▍  | 3400/4545 [3:40:02<1:05:15,  3.42s/it] 75%|███████▍  | 3401/4545 [3:40:06<1:09:36,  3.65s/it] 75%|███████▍  | 3402/4545 [3:40:10<1:11:03,  3.73s/it] 75%|███████▍  | 3403/4545 [3:40:14<1:13:07,  3.84s/it] 75%|███████▍  | 3404/4545 [3:40:19<1:15:10,  3.95s/it] 75%|███████▍  | 3405/4545 [3:40:22<1:12:32,  3.82s/it] 75%|███████▍  | 3406/4545 [3:40:25<1:05:02,  3.43s/it] 75%|███████▍  | 3407/4545 [3:40:28<1:02:47,  3.31s/it] 75%|███████▍  | 3408/4545 [3:40:32<1:06:19,  3.50s/it] 75%|███████▌  | 3409/4545 [3:40:35<1:08:00,  3.59s/it] 75%|███████▌  | 3410/4545 [3:40:39<1:08:58,  3.65s/it]                                                       {'loss': 0.2936, 'grad_norm': 26.133832931518555, 'learning_rate': 3.775231695989244e-08, 'rewards/chosen': 0.564208984375, 'rewards/rejected': -3.0023436546325684, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.565624952316284, 'logps/chosen': -220.35000610351562, 'logps/rejected': -128.25, 'logits/chosen': -7.768750190734863, 'logits/rejected': -7.387499809265137, 'epoch': 2.25}
 75%|███████▌  | 3410/4545 [3:40:39<1:08:58,  3.65s/it] 75%|███████▌  | 3411/4545 [3:40:43<1:10:09,  3.71s/it] 75%|███████▌  | 3412/4545 [3:40:47<1:10:30,  3.73s/it] 75%|███████▌  | 3413/4545 [3:40:51<1:11:38,  3.80s/it] 75%|███████▌  | 3414/4545 [3:40:54<1:07:15,  3.57s/it] 75%|███████▌  | 3415/4545 [3:40:58<1:08:03,  3.61s/it] 75%|███████▌  | 3416/4545 [3:41:01<1:09:39,  3.70s/it] 75%|███████▌  | 3417/4545 [3:41:05<1:10:46,  3.76s/it] 75%|███████▌  | 3418/4545 [3:41:09<1:11:00,  3.78s/it] 75%|███████▌  | 3419/4545 [3:41:13<1:11:18,  3.80s/it] 75%|███████▌  | 3420/4545 [3:41:16<1:09:34,  3.71s/it]                                                       {'loss': 0.2889, 'grad_norm': 23.190271377563477, 'learning_rate': 3.732245166427933e-08, 'rewards/chosen': 0.980297863483429, 'rewards/rejected': -2.5757813453674316, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.5546875, 'logps/chosen': -241.39999389648438, 'logps/rejected': -171.75, 'logits/chosen': -7.803124904632568, 'logits/rejected': -7.46875, 'epoch': 2.26}
 75%|███████▌  | 3420/4545 [3:41:16<1:09:34,  3.71s/it] 75%|███████▌  | 3421/4545 [3:41:21<1:11:33,  3.82s/it] 75%|███████▌  | 3422/4545 [3:41:25<1:13:44,  3.94s/it] 75%|███████▌  | 3423/4545 [3:41:28<1:07:43,  3.62s/it] 75%|███████▌  | 3424/4545 [3:41:32<1:10:57,  3.80s/it] 75%|███████▌  | 3425/4545 [3:41:36<1:11:53,  3.85s/it] 75%|███████▌  | 3426/4545 [3:41:40<1:11:19,  3.82s/it] 75%|███████▌  | 3427/4545 [3:41:43<1:11:10,  3.82s/it] 75%|███████▌  | 3428/4545 [3:41:47<1:11:33,  3.84s/it] 75%|███████▌  | 3429/4545 [3:41:51<1:12:16,  3.89s/it] 75%|███████▌  | 3430/4545 [3:41:55<1:12:22,  3.89s/it]                                                       {'loss': 0.2881, 'grad_norm': 14.525726318359375, 'learning_rate': 3.6894485460726186e-08, 'rewards/chosen': 1.10693359375, 'rewards/rejected': -2.283984422683716, 'rewards/accuracies': 0.875, 'rewards/margins': 3.391406297683716, 'logps/chosen': -285.75, 'logps/rejected': -182.5500030517578, 'logits/chosen': -7.699999809265137, 'logits/rejected': -7.259375095367432, 'epoch': 2.26}
 75%|███████▌  | 3430/4545 [3:41:55<1:12:22,  3.89s/it] 75%|███████▌  | 3431/4545 [3:41:58<1:03:55,  3.44s/it] 76%|███████▌  | 3432/4545 [3:42:00<58:05,  3.13s/it]   76%|███████▌  | 3433/4545 [3:42:04<1:02:12,  3.36s/it] 76%|███████▌  | 3434/4545 [3:42:08<1:05:15,  3.52s/it] 76%|███████▌  | 3435/4545 [3:42:11<1:05:23,  3.53s/it] 76%|███████▌  | 3436/4545 [3:42:15<1:07:22,  3.64s/it] 76%|███████▌  | 3437/4545 [3:42:19<1:08:47,  3.73s/it] 76%|███████▌  | 3438/4545 [3:42:23<1:09:43,  3.78s/it] 76%|███████▌  | 3439/4545 [3:42:27<1:11:52,  3.90s/it] 76%|███████▌  | 3440/4545 [3:42:31<1:09:39,  3.78s/it]                                                       {'loss': 0.2552, 'grad_norm': 18.784263610839844, 'learning_rate': 3.646846432547387e-08, 'rewards/chosen': 1.0243651866912842, 'rewards/rejected': -2.513671875, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.5374999046325684, 'logps/chosen': -221.64999389648438, 'logps/rejected': -117.5, 'logits/chosen': -7.803124904632568, 'logits/rejected': -7.409375190734863, 'epoch': 2.27}
 76%|███████▌  | 3440/4545 [3:42:31<1:09:39,  3.78s/it] 76%|███████▌  | 3441/4545 [3:42:35<1:10:17,  3.82s/it] 76%|███████▌  | 3442/4545 [3:42:39<1:10:43,  3.85s/it] 76%|███████▌  | 3443/4545 [3:42:43<1:10:59,  3.87s/it] 76%|███████▌  | 3444/4545 [3:42:46<1:11:10,  3.88s/it] 76%|███████▌  | 3445/4545 [3:42:51<1:12:24,  3.95s/it] 76%|███████▌  | 3446/4545 [3:42:54<1:12:04,  3.93s/it] 76%|███████▌  | 3447/4545 [3:42:58<1:10:28,  3.85s/it] 76%|███████▌  | 3448/4545 [3:43:02<1:11:36,  3.92s/it] 76%|███████▌  | 3449/4545 [3:43:06<1:11:28,  3.91s/it] 76%|███████▌  | 3450/4545 [3:43:10<1:11:19,  3.91s/it]                                                       {'loss': 0.2945, 'grad_norm': 16.736146926879883, 'learning_rate': 3.6044434025805224e-08, 'rewards/chosen': 1.4314453601837158, 'rewards/rejected': -2.2433228492736816, 'rewards/accuracies': 0.875, 'rewards/margins': 3.6734375953674316, 'logps/chosen': -300.75, 'logps/rejected': -167.39999389648438, 'logits/chosen': -7.643750190734863, 'logits/rejected': -7.246874809265137, 'epoch': 2.28}
 76%|███████▌  | 3450/4545 [3:43:10<1:11:19,  3.91s/it] 76%|███████▌  | 3451/4545 [3:43:14<1:11:20,  3.91s/it] 76%|███████▌  | 3452/4545 [3:43:17<1:04:42,  3.55s/it] 76%|███████▌  | 3453/4545 [3:43:20<1:01:37,  3.39s/it] 76%|███████▌  | 3454/4545 [3:43:23<1:04:20,  3.54s/it] 76%|███████▌  | 3455/4545 [3:43:27<1:05:56,  3.63s/it] 76%|███████▌  | 3456/4545 [3:43:31<1:07:25,  3.71s/it] 76%|███████▌  | 3457/4545 [3:43:35<1:09:53,  3.85s/it] 76%|███████▌  | 3458/4545 [3:43:39<1:10:06,  3.87s/it] 76%|███████▌  | 3459/4545 [3:43:44<1:11:43,  3.96s/it] 76%|███████▌  | 3460/4545 [3:43:47<1:07:41,  3.74s/it]                                                       {'loss': 0.3252, 'grad_norm': 18.479148864746094, 'learning_rate': 3.562244011512845e-08, 'rewards/chosen': 1.572930932044983, 'rewards/rejected': -1.7106444835662842, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.2828125953674316, 'logps/chosen': -322.8999938964844, 'logps/rejected': -173.0500030517578, 'logits/chosen': -7.684374809265137, 'logits/rejected': -7.40625, 'epoch': 2.28}
 76%|███████▌  | 3460/4545 [3:43:47<1:07:41,  3.74s/it] 76%|███████▌  | 3461/4545 [3:43:51<1:08:38,  3.80s/it] 76%|███████▌  | 3462/4545 [3:43:54<1:06:15,  3.67s/it] 76%|███████▌  | 3463/4545 [3:43:58<1:08:23,  3.79s/it] 76%|███████▌  | 3464/4545 [3:44:02<1:08:57,  3.83s/it] 76%|███████▌  | 3465/4545 [3:44:06<1:10:40,  3.93s/it] 76%|███████▋  | 3466/4545 [3:44:09<1:06:53,  3.72s/it] 76%|███████▋  | 3467/4545 [3:44:13<1:07:53,  3.78s/it] 76%|███████▋  | 3468/4545 [3:44:17<1:05:53,  3.67s/it] 76%|███████▋  | 3469/4545 [3:44:21<1:07:43,  3.78s/it] 76%|███████▋  | 3470/4545 [3:44:25<1:08:25,  3.82s/it]                                                       {'loss': 0.2946, 'grad_norm': 19.552778244018555, 'learning_rate': 3.520252792808328e-08, 'rewards/chosen': 1.312402367591858, 'rewards/rejected': -2.3792967796325684, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.6953125, 'logps/chosen': -240.9499969482422, 'logps/rejected': -175.9499969482422, 'logits/chosen': -7.887499809265137, 'logits/rejected': -7.425000190734863, 'epoch': 2.29}
 76%|███████▋  | 3470/4545 [3:44:25<1:08:25,  3.82s/it] 76%|███████▋  | 3471/4545 [3:44:29<1:10:22,  3.93s/it] 76%|███████▋  | 3472/4545 [3:44:33<1:10:07,  3.92s/it] 76%|███████▋  | 3473/4545 [3:44:36<1:06:57,  3.75s/it] 76%|███████▋  | 3474/4545 [3:44:40<1:07:45,  3.80s/it] 76%|███████▋  | 3475/4545 [3:44:43<1:04:48,  3.63s/it] 76%|███████▋  | 3476/4545 [3:44:47<1:06:13,  3.72s/it] 77%|███████▋  | 3477/4545 [3:44:51<1:07:12,  3.78s/it] 77%|███████▋  | 3478/4545 [3:44:55<1:07:55,  3.82s/it] 77%|███████▋  | 3479/4545 [3:44:59<1:08:13,  3.84s/it] 77%|███████▋  | 3480/4545 [3:45:03<1:08:40,  3.87s/it]                                                       {'loss': 0.2655, 'grad_norm': 11.668437004089355, 'learning_rate': 3.4784742575670736e-08, 'rewards/chosen': 2.2684569358825684, 'rewards/rejected': -2.0462889671325684, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.317187309265137, 'logps/chosen': -467.70001220703125, 'logps/rejected': -195.5, 'logits/chosen': -7.646874904632568, 'logits/rejected': -7.368750095367432, 'epoch': 2.3}
 77%|███████▋  | 3480/4545 [3:45:03<1:08:40,  3.87s/it] 77%|███████▋  | 3481/4545 [3:45:07<1:08:49,  3.88s/it] 77%|███████▋  | 3482/4545 [3:45:11<1:08:54,  3.89s/it] 77%|███████▋  | 3483/4545 [3:45:15<1:08:57,  3.90s/it] 77%|███████▋  | 3484/4545 [3:45:18<1:07:36,  3.82s/it] 77%|███████▋  | 3485/4545 [3:45:22<1:08:10,  3.86s/it] 77%|███████▋  | 3486/4545 [3:45:26<1:06:08,  3.75s/it] 77%|███████▋  | 3487/4545 [3:45:29<1:04:01,  3.63s/it] 77%|███████▋  | 3488/4545 [3:45:33<1:04:19,  3.65s/it] 77%|███████▋  | 3489/4545 [3:45:37<1:05:41,  3.73s/it] 77%|███████▋  | 3490/4545 [3:45:41<1:08:16,  3.88s/it]                                                       {'loss': 0.2959, 'grad_norm': 78.23616790771484, 'learning_rate': 3.436912894040672e-08, 'rewards/chosen': 1.716650366783142, 'rewards/rejected': -2.363476514816284, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.082812309265137, 'logps/chosen': -357.0, 'logps/rejected': -198.3000030517578, 'logits/chosen': -7.456250190734863, 'logits/rejected': -7.275000095367432, 'epoch': 2.3}
 77%|███████▋  | 3490/4545 [3:45:41<1:08:16,  3.88s/it] 77%|███████▋  | 3491/4545 [3:45:45<1:08:26,  3.90s/it] 77%|███████▋  | 3492/4545 [3:45:48<1:04:39,  3.68s/it] 77%|███████▋  | 3493/4545 [3:45:52<1:06:47,  3.81s/it] 77%|███████▋  | 3494/4545 [3:45:54<59:00,  3.37s/it]   77%|███████▋  | 3495/4545 [3:45:58<59:06,  3.38s/it] 77%|███████▋  | 3496/4545 [3:46:02<1:01:50,  3.54s/it] 77%|███████▋  | 3497/4545 [3:46:06<1:04:35,  3.70s/it] 77%|███████▋  | 3498/4545 [3:46:10<1:05:25,  3.75s/it] 77%|███████▋  | 3499/4545 [3:46:14<1:06:02,  3.79s/it] 77%|███████▋  | 3500/4545 [3:46:17<1:05:11,  3.74s/it]                                                       {'loss': 0.3536, 'grad_norm': 28.41325569152832, 'learning_rate': 3.395573167150054e-08, 'rewards/chosen': 1.3017089366912842, 'rewards/rejected': -1.861914038658142, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 3.1617188453674316, 'logps/chosen': -265.1000061035156, 'logps/rejected': -159.35000610351562, 'logits/chosen': -7.893750190734863, 'logits/rejected': -7.568749904632568, 'epoch': 2.31}
 77%|███████▋  | 3500/4545 [3:46:17<1:05:11,  3.74s/it] 77%|███████▋  | 3501/4545 [3:46:21<1:06:29,  3.82s/it] 77%|███████▋  | 3502/4545 [3:46:25<1:07:42,  3.90s/it] 77%|███████▋  | 3503/4545 [3:46:29<1:07:47,  3.90s/it] 77%|███████▋  | 3504/4545 [3:46:32<1:01:08,  3.52s/it] 77%|███████▋  | 3505/4545 [3:46:36<1:01:59,  3.58s/it] 77%|███████▋  | 3506/4545 [3:46:38<56:48,  3.28s/it]   77%|███████▋  | 3507/4545 [3:46:42<1:01:08,  3.53s/it] 77%|███████▋  | 3508/4545 [3:46:46<1:02:57,  3.64s/it] 77%|███████▋  | 3509/4545 [3:46:50<1:04:19,  3.73s/it] 77%|███████▋  | 3510/4545 [3:46:54<1:03:14,  3.67s/it]                                                       {'loss': 0.3077, 'grad_norm': 14.13648796081543, 'learning_rate': 3.354459518005807e-08, 'rewards/chosen': 1.817907691001892, 'rewards/rejected': -2.188671827316284, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.004687309265137, 'logps/chosen': -349.3500061035156, 'logps/rejected': -231.4250030517578, 'logits/chosen': -7.646874904632568, 'logits/rejected': -7.28125, 'epoch': 2.32}
 77%|███████▋  | 3510/4545 [3:46:54<1:03:14,  3.67s/it] 77%|███████▋  | 3511/4545 [3:46:58<1:05:55,  3.83s/it] 77%|███████▋  | 3512/4545 [3:47:02<1:06:22,  3.86s/it] 77%|███████▋  | 3513/4545 [3:47:06<1:06:39,  3.88s/it] 77%|███████▋  | 3514/4545 [3:47:10<1:06:54,  3.89s/it] 77%|███████▋  | 3515/4545 [3:47:13<1:04:51,  3.78s/it] 77%|███████▋  | 3516/4545 [3:47:17<1:05:29,  3.82s/it] 77%|███████▋  | 3517/4545 [3:47:21<1:06:00,  3.85s/it] 77%|███████▋  | 3518/4545 [3:47:25<1:05:05,  3.80s/it] 77%|███████▋  | 3519/4545 [3:47:27<59:57,  3.51s/it]   77%|███████▋  | 3520/4545 [3:47:31<1:02:07,  3.64s/it]                                                       {'loss': 0.267, 'grad_norm': 20.47852897644043, 'learning_rate': 3.3135763634310754e-08, 'rewards/chosen': 2.7109375, 'rewards/rejected': -1.6383788585662842, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.345312595367432, 'logps/chosen': -448.70001220703125, 'logps/rejected': -271.5, 'logits/chosen': -7.490624904632568, 'logits/rejected': -7.209374904632568, 'epoch': 2.32}
 77%|███████▋  | 3520/4545 [3:47:31<1:02:07,  3.64s/it] 77%|███████▋  | 3521/4545 [3:47:35<1:02:53,  3.68s/it] 77%|███████▋  | 3522/4545 [3:47:39<1:03:52,  3.75s/it] 78%|███████▊  | 3523/4545 [3:47:43<1:03:49,  3.75s/it] 78%|███████▊  | 3524/4545 [3:47:47<1:04:34,  3.79s/it] 78%|███████▊  | 3525/4545 [3:47:50<1:03:51,  3.76s/it] 78%|███████▊  | 3526/4545 [3:47:54<1:01:49,  3.64s/it] 78%|███████▊  | 3527/4545 [3:47:56<56:59,  3.36s/it]   78%|███████▊  | 3528/4545 [3:48:00<59:40,  3.52s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.27s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.26s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.41180235147476196, 'eval_runtime': 80.3372, 'eval_samples_per_second': 11.863, 'eval_steps_per_second': 0.747, 'eval_rewards/chosen': 1.517645239830017, 'eval_rewards/rejected': -1.5970377922058105, 'eval_rewards/accuracies': 0.808680534362793, 'eval_rewards/margins': 3.1161417961120605, 'eval_logps/chosen': -362.3333435058594, 'eval_logps/rejected': -167.89999389648438, 'eval_logits/chosen': -7.422916889190674, 'eval_logits/rejected': -7.785937309265137, 'epoch': 2.33}
 78%|███████▊  | 3528/4545 [3:49:21<59:40,  3.52s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 78%|███████▊  | 3529/4545 [3:49:35<8:43:11, 30.90s/it] 78%|███████▊  | 3530/4545 [3:49:39<6:26:37, 22.85s/it]                                                       {'loss': 0.2875, 'grad_norm': 17.69581413269043, 'learning_rate': 3.2729280954870655e-08, 'rewards/chosen': 0.942614734172821, 'rewards/rejected': -2.37109375, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.311328172683716, 'logps/chosen': -233.5500030517578, 'logps/rejected': -144.3249969482422, 'logits/chosen': -7.709374904632568, 'logits/rejected': -7.474999904632568, 'epoch': 2.33}
 78%|███████▊  | 3530/4545 [3:49:39<6:26:37, 22.85s/it] 78%|███████▊  | 3531/4545 [3:49:43<4:48:54, 17.09s/it] 78%|███████▊  | 3532/4545 [3:49:47<3:42:54, 13.20s/it] 78%|███████▊  | 3533/4545 [3:49:51<2:54:12, 10.33s/it] 78%|███████▊  | 3534/4545 [3:49:54<2:21:01,  8.37s/it] 78%|███████▊  | 3535/4545 [3:49:58<1:58:21,  7.03s/it] 78%|███████▊  | 3536/4545 [3:50:02<1:40:26,  5.97s/it] 78%|███████▊  | 3537/4545 [3:50:06<1:28:50,  5.29s/it] 78%|███████▊  | 3538/4545 [3:50:08<1:15:37,  4.51s/it] 78%|███████▊  | 3539/4545 [3:50:12<1:11:27,  4.26s/it] 78%|███████▊  | 3540/4545 [3:50:16<1:08:24,  4.08s/it]                                                       {'loss': 0.2773, 'grad_norm': 12.372817039489746, 'learning_rate': 3.232519081001205e-08, 'rewards/chosen': 0.3547912538051605, 'rewards/rejected': -2.626171827316284, 'rewards/accuracies': 0.90625, 'rewards/margins': 2.979687452316284, 'logps/chosen': -140.3000030517578, 'logps/rejected': -120.6500015258789, 'logits/chosen': -7.925000190734863, 'logits/rejected': -7.471875190734863, 'epoch': 2.34}
 78%|███████▊  | 3540/4545 [3:50:16<1:08:24,  4.08s/it] 78%|███████▊  | 3541/4545 [3:50:20<1:08:53,  4.12s/it] 78%|███████▊  | 3542/4545 [3:50:24<1:09:04,  4.13s/it] 78%|███████▊  | 3543/4545 [3:50:28<1:07:53,  4.07s/it] 78%|███████▊  | 3544/4545 [3:50:32<1:06:00,  3.96s/it] 78%|███████▊  | 3545/4545 [3:50:35<1:05:41,  3.94s/it] 78%|███████▊  | 3546/4545 [3:50:39<1:05:31,  3.94s/it] 78%|███████▊  | 3547/4545 [3:50:43<1:05:17,  3.93s/it] 78%|███████▊  | 3548/4545 [3:50:46<1:00:38,  3.65s/it] 78%|███████▊  | 3549/4545 [3:50:50<1:01:31,  3.71s/it] 78%|███████▊  | 3550/4545 [3:50:54<1:02:32,  3.77s/it]                                                       {'loss': 0.3114, 'grad_norm': 15.286121368408203, 'learning_rate': 3.1923536610980124e-08, 'rewards/chosen': 1.288977026939392, 'rewards/rejected': -2.180859327316284, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.4671874046325684, 'logps/chosen': -271.6000061035156, 'logps/rejected': -179.0500030517578, 'logits/chosen': -7.715624809265137, 'logits/rejected': -7.296875, 'epoch': 2.34}
 78%|███████▊  | 3550/4545 [3:50:54<1:02:32,  3.77s/it] 78%|███████▊  | 3551/4545 [3:50:58<1:03:53,  3.86s/it] 78%|███████▊  | 3552/4545 [3:51:02<1:04:15,  3.88s/it] 78%|███████▊  | 3553/4545 [3:51:06<1:04:26,  3.90s/it] 78%|███████▊  | 3554/4545 [3:51:10<1:03:48,  3.86s/it] 78%|███████▊  | 3555/4545 [3:51:14<1:04:06,  3.89s/it] 78%|███████▊  | 3556/4545 [3:51:18<1:04:39,  3.92s/it] 78%|███████▊  | 3557/4545 [3:51:21<1:03:11,  3.84s/it] 78%|███████▊  | 3558/4545 [3:51:25<1:03:28,  3.86s/it] 78%|███████▊  | 3559/4545 [3:51:28<1:00:12,  3.66s/it] 78%|███████▊  | 3560/4545 [3:51:32<1:00:41,  3.70s/it]                                                       {'loss': 0.3102, 'grad_norm': 16.27233123779297, 'learning_rate': 3.1524361507327403e-08, 'rewards/chosen': 1.700292944908142, 'rewards/rejected': -2.4371094703674316, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.142187595367432, 'logps/chosen': -348.54998779296875, 'logps/rejected': -205.64999389648438, 'logits/chosen': -7.525000095367432, 'logits/rejected': -7.328125, 'epoch': 2.35}
 78%|███████▊  | 3560/4545 [3:51:32<1:00:41,  3.70s/it] 78%|███████▊  | 3561/4545 [3:51:36<59:46,  3.65s/it]   78%|███████▊  | 3562/4545 [3:51:40<1:00:32,  3.70s/it] 78%|███████▊  | 3563/4545 [3:51:43<59:36,  3.64s/it]   78%|███████▊  | 3564/4545 [3:51:47<1:00:52,  3.72s/it] 78%|███████▊  | 3565/4545 [3:51:51<1:01:42,  3.78s/it] 78%|███████▊  | 3566/4545 [3:51:55<1:01:55,  3.79s/it] 78%|███████▊  | 3567/4545 [3:51:59<1:02:05,  3.81s/it] 79%|███████▊  | 3568/4545 [3:52:03<1:03:48,  3.92s/it] 79%|███████▊  | 3569/4545 [3:52:07<1:03:45,  3.92s/it] 79%|███████▊  | 3570/4545 [3:52:11<1:03:39,  3.92s/it]                                                       {'loss': 0.3178, 'grad_norm': 12.739502906799316, 'learning_rate': 3.1127708382278184e-08, 'rewards/chosen': 1.1371338367462158, 'rewards/rejected': -2.332324266433716, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.4710936546325684, 'logps/chosen': -248.625, 'logps/rejected': -151.64999389648438, 'logits/chosen': -7.778124809265137, 'logits/rejected': -7.265625, 'epoch': 2.36}
 79%|███████▊  | 3570/4545 [3:52:11<1:03:39,  3.92s/it] 79%|███████▊  | 3571/4545 [3:52:15<1:03:35,  3.92s/it] 79%|███████▊  | 3572/4545 [3:52:18<1:03:24,  3.91s/it] 79%|███████▊  | 3573/4545 [3:52:22<1:03:27,  3.92s/it] 79%|███████▊  | 3574/4545 [3:52:26<1:03:25,  3.92s/it] 79%|███████▊  | 3575/4545 [3:52:30<1:02:10,  3.85s/it] 79%|███████▊  | 3576/4545 [3:52:33<59:46,  3.70s/it]   79%|███████▊  | 3577/4545 [3:52:36<54:20,  3.37s/it] 79%|███████▊  | 3578/4545 [3:52:40<58:36,  3.64s/it] 79%|███████▊  | 3579/4545 [3:52:44<59:58,  3.73s/it] 79%|███████▉  | 3580/4545 [3:52:48<1:00:48,  3.78s/it]                                                       {'loss': 0.3213, 'grad_norm': 18.733898162841797, 'learning_rate': 3.0733619848121514e-08, 'rewards/chosen': 1.7255859375, 'rewards/rejected': -1.910058617591858, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.6343750953674316, 'logps/chosen': -352.5, 'logps/rejected': -218.8000030517578, 'logits/chosen': -7.646874904632568, 'logits/rejected': -7.284375190734863, 'epoch': 2.36}
 79%|███████▉  | 3580/4545 [3:52:48<1:00:48,  3.78s/it] 79%|███████▉  | 3581/4545 [3:52:52<1:01:26,  3.82s/it] 79%|███████▉  | 3582/4545 [3:52:56<1:01:52,  3.85s/it] 79%|███████▉  | 3583/4545 [3:53:00<1:01:38,  3.84s/it] 79%|███████▉  | 3584/4545 [3:53:03<1:00:48,  3.80s/it] 79%|███████▉  | 3585/4545 [3:53:07<1:01:19,  3.83s/it] 79%|███████▉  | 3586/4545 [3:53:11<1:00:16,  3.77s/it] 79%|███████▉  | 3587/4545 [3:53:15<1:00:54,  3.81s/it] 79%|███████▉  | 3588/4545 [3:53:18<58:14,  3.65s/it]   79%|███████▉  | 3589/4545 [3:53:22<59:19,  3.72s/it] 79%|███████▉  | 3590/4545 [3:53:26<1:01:09,  3.84s/it]                                                       {'loss': 0.2896, 'grad_norm': 13.958690643310547, 'learning_rate': 3.0342138241633584e-08, 'rewards/chosen': 1.4987304210662842, 'rewards/rejected': -2.477734327316284, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.9703125953674316, 'logps/chosen': -313.29998779296875, 'logps/rejected': -197.5, 'logits/chosen': -7.578125, 'logits/rejected': -7.290625095367432, 'epoch': 2.37}
 79%|███████▉  | 3590/4545 [3:53:26<1:01:09,  3.84s/it] 79%|███████▉  | 3591/4545 [3:53:30<1:01:26,  3.86s/it] 79%|███████▉  | 3592/4545 [3:53:34<1:01:40,  3.88s/it] 79%|███████▉  | 3593/4545 [3:53:38<1:02:09,  3.92s/it] 79%|███████▉  | 3594/4545 [3:53:42<1:03:36,  4.01s/it] 79%|███████▉  | 3595/4545 [3:53:46<1:02:45,  3.96s/it] 79%|███████▉  | 3596/4545 [3:53:50<1:02:28,  3.95s/it] 79%|███████▉  | 3597/4545 [3:53:54<1:01:32,  3.90s/it] 79%|███████▉  | 3598/4545 [3:53:58<1:01:32,  3.90s/it] 79%|███████▉  | 3599/4545 [3:54:02<1:02:14,  3.95s/it] 79%|███████▉  | 3600/4545 [3:54:06<1:03:16,  4.02s/it]                                                       {'loss': 0.3382, 'grad_norm': 13.23178768157959, 'learning_rate': 2.995330561952924e-08, 'rewards/chosen': 0.9969482421875, 'rewards/rejected': -2.8861327171325684, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.885937452316284, 'logps/chosen': -314.5, 'logps/rejected': -198.60000610351562, 'logits/chosen': -7.574999809265137, 'logits/rejected': -7.368750095367432, 'epoch': 2.38}
 79%|███████▉  | 3600/4545 [3:54:06<1:03:16,  4.02s/it] 79%|███████▉  | 3601/4545 [3:54:10<1:03:46,  4.05s/it] 79%|███████▉  | 3602/4545 [3:54:13<1:00:50,  3.87s/it] 79%|███████▉  | 3603/4545 [3:54:17<1:00:44,  3.87s/it] 79%|███████▉  | 3604/4545 [3:54:21<1:00:50,  3.88s/it] 79%|███████▉  | 3605/4545 [3:54:25<1:00:54,  3.89s/it] 79%|███████▉  | 3606/4545 [3:54:29<1:00:58,  3.90s/it] 79%|███████▉  | 3607/4545 [3:54:33<1:01:47,  3.95s/it] 79%|███████▉  | 3608/4545 [3:54:37<1:01:28,  3.94s/it] 79%|███████▉  | 3609/4545 [3:54:41<1:02:12,  3.99s/it] 79%|███████▉  | 3610/4545 [3:54:45<1:01:43,  3.96s/it]                                                       {'loss': 0.3354, 'grad_norm': 20.18701171875, 'learning_rate': 2.9567163753944058e-08, 'rewards/chosen': 1.114160180091858, 'rewards/rejected': -2.5552735328674316, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.6703124046325684, 'logps/chosen': -281.3999938964844, 'logps/rejected': -148.97500610351562, 'logits/chosen': -7.662499904632568, 'logits/rejected': -7.334374904632568, 'epoch': 2.38}
 79%|███████▉  | 3610/4545 [3:54:45<1:01:43,  3.96s/it] 79%|███████▉  | 3611/4545 [3:54:49<1:00:25,  3.88s/it] 79%|███████▉  | 3612/4545 [3:54:53<1:00:18,  3.88s/it] 79%|███████▉  | 3613/4545 [3:54:56<59:12,  3.81s/it]   80%|███████▉  | 3614/4545 [3:55:00<59:34,  3.84s/it] 80%|███████▉  | 3615/4545 [3:55:04<59:49,  3.86s/it] 80%|███████▉  | 3616/4545 [3:55:07<57:19,  3.70s/it] 80%|███████▉  | 3617/4545 [3:55:11<58:17,  3.77s/it] 80%|███████▉  | 3618/4545 [3:55:15<58:49,  3.81s/it] 80%|███████▉  | 3619/4545 [3:55:19<59:18,  3.84s/it] 80%|███████▉  | 3620/4545 [3:55:23<57:29,  3.73s/it]                                                     {'loss': 0.3081, 'grad_norm': 12.491497039794922, 'learning_rate': 2.9183754127946682e-08, 'rewards/chosen': 1.219506859779358, 'rewards/rejected': -2.659960985183716, 'rewards/accuracies': 0.875, 'rewards/margins': 3.878124952316284, 'logps/chosen': -279.95001220703125, 'logps/rejected': -181.0500030517578, 'logits/chosen': -7.606249809265137, 'logits/rejected': -7.190625190734863, 'epoch': 2.39}
 80%|███████▉  | 3620/4545 [3:55:23<57:29,  3.73s/it] 80%|███████▉  | 3621/4545 [3:55:27<58:56,  3.83s/it] 80%|███████▉  | 3622/4545 [3:55:31<1:00:29,  3.93s/it] 80%|███████▉  | 3623/4545 [3:55:33<54:32,  3.55s/it]   80%|███████▉  | 3624/4545 [3:55:37<56:05,  3.65s/it] 80%|███████▉  | 3625/4545 [3:55:41<56:47,  3.70s/it] 80%|███████▉  | 3626/4545 [3:55:45<57:45,  3.77s/it] 80%|███████▉  | 3627/4545 [3:55:49<57:51,  3.78s/it] 80%|███████▉  | 3628/4545 [3:55:53<59:06,  3.87s/it] 80%|███████▉  | 3629/4545 [3:55:56<53:47,  3.52s/it] 80%|███████▉  | 3630/4545 [3:56:00<55:29,  3.64s/it]                                                     {'loss': 0.3119, 'grad_norm': 19.197063446044922, 'learning_rate': 2.88031179310823e-08, 'rewards/chosen': 2.030444383621216, 'rewards/rejected': -2.5635743141174316, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.6015625, 'logps/chosen': -412.3500061035156, 'logps/rejected': -234.27499389648438, 'logits/chosen': -7.421875, 'logits/rejected': -7.231249809265137, 'epoch': 2.4}
 80%|███████▉  | 3630/4545 [3:56:00<55:29,  3.64s/it] 80%|███████▉  | 3631/4545 [3:56:03<56:08,  3.69s/it] 80%|███████▉  | 3632/4545 [3:56:08<57:57,  3.81s/it] 80%|███████▉  | 3633/4545 [3:56:11<56:58,  3.75s/it] 80%|███████▉  | 3634/4545 [3:56:15<57:43,  3.80s/it] 80%|███████▉  | 3635/4545 [3:56:19<58:06,  3.83s/it] 80%|████████  | 3636/4545 [3:56:23<58:26,  3.86s/it] 80%|████████  | 3637/4545 [3:56:26<56:58,  3.77s/it] 80%|████████  | 3638/4545 [3:56:30<57:35,  3.81s/it] 80%|████████  | 3639/4545 [3:56:34<57:14,  3.79s/it] 80%|████████  | 3640/4545 [3:56:38<57:41,  3.82s/it]                                                     {'loss': 0.2912, 'grad_norm': 26.7407283782959, 'learning_rate': 2.8425296054947735e-08, 'rewards/chosen': 2.369677782058716, 'rewards/rejected': -1.8859374523162842, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.254687309265137, 'logps/chosen': -419.1499938964844, 'logps/rejected': -186.35000610351562, 'logits/chosen': -7.534375190734863, 'logits/rejected': -7.365624904632568, 'epoch': 2.4}
 80%|████████  | 3640/4545 [3:56:38<57:41,  3.82s/it] 80%|████████  | 3641/4545 [3:56:42<59:04,  3.92s/it] 80%|████████  | 3642/4545 [3:56:45<55:05,  3.66s/it] 80%|████████  | 3643/4545 [3:56:49<56:09,  3.74s/it] 80%|████████  | 3644/4545 [3:56:53<56:51,  3.79s/it] 80%|████████  | 3645/4545 [3:56:56<52:56,  3.53s/it] 80%|████████  | 3646/4545 [3:57:00<53:28,  3.57s/it] 80%|████████  | 3647/4545 [3:57:03<53:38,  3.58s/it] 80%|████████  | 3648/4545 [3:57:06<50:35,  3.38s/it] 80%|████████  | 3649/4545 [3:57:10<52:51,  3.54s/it] 80%|████████  | 3650/4545 [3:57:14<54:28,  3.65s/it]                                                     {'loss': 0.2797, 'grad_norm': 26.966533660888672, 'learning_rate': 2.8050329088798453e-08, 'rewards/chosen': 0.868090808391571, 'rewards/rejected': -2.6546874046325684, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.526562452316284, 'logps/chosen': -220.10000610351562, 'logps/rejected': -139.10000610351562, 'logits/chosen': -7.809374809265137, 'logits/rejected': -7.178124904632568, 'epoch': 2.41}
 80%|████████  | 3650/4545 [3:57:14<54:28,  3.65s/it] 80%|████████  | 3651/4545 [3:57:17<52:04,  3.50s/it] 80%|████████  | 3652/4545 [3:57:21<53:52,  3.62s/it] 80%|████████  | 3653/4545 [3:57:25<55:05,  3.71s/it] 80%|████████  | 3654/4545 [3:57:29<56:13,  3.79s/it] 80%|████████  | 3655/4545 [3:57:33<56:42,  3.82s/it] 80%|████████  | 3656/4545 [3:57:37<57:05,  3.85s/it] 80%|████████  | 3657/4545 [3:57:41<58:41,  3.97s/it] 80%|████████  | 3658/4545 [3:57:45<58:19,  3.95s/it] 81%|████████  | 3659/4545 [3:57:49<58:05,  3.93s/it] 81%|████████  | 3660/4545 [3:57:53<57:44,  3.91s/it]                                                     {'loss': 0.2965, 'grad_norm': 12.057286262512207, 'learning_rate': 2.7678257315188e-08, 'rewards/chosen': 2.039599657058716, 'rewards/rejected': -2.099316358566284, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.137499809265137, 'logps/chosen': -368.54998779296875, 'logps/rejected': -224.89999389648438, 'logits/chosen': -7.484375, 'logits/rejected': -7.228125095367432, 'epoch': 2.42}
 81%|████████  | 3660/4545 [3:57:53<57:44,  3.91s/it] 81%|████████  | 3661/4545 [3:57:57<58:35,  3.98s/it] 81%|████████  | 3662/4545 [3:58:01<58:42,  3.99s/it] 81%|████████  | 3663/4545 [3:58:05<58:16,  3.96s/it] 81%|████████  | 3664/4545 [3:58:09<58:49,  4.01s/it] 81%|████████  | 3665/4545 [3:58:12<54:23,  3.71s/it] 81%|████████  | 3666/4545 [3:58:16<55:13,  3.77s/it] 81%|████████  | 3667/4545 [3:58:19<54:21,  3.71s/it] 81%|████████  | 3668/4545 [3:58:23<55:14,  3.78s/it] 81%|████████  | 3669/4545 [3:58:27<55:50,  3.82s/it] 81%|████████  | 3670/4545 [3:58:31<56:10,  3.85s/it]                                                     {'loss': 0.2249, 'grad_norm': 13.273097038269043, 'learning_rate': 2.730912070564064e-08, 'rewards/chosen': 1.902075171470642, 'rewards/rejected': -2.405078172683716, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.309374809265137, 'logps/chosen': -373.95001220703125, 'logps/rejected': -220.10000610351562, 'logits/chosen': -7.743750095367432, 'logits/rejected': -7.268750190734863, 'epoch': 2.42}
 81%|████████  | 3670/4545 [3:58:31<56:10,  3.85s/it] 81%|████████  | 3671/4545 [3:58:35<56:16,  3.86s/it] 81%|████████  | 3672/4545 [3:58:38<54:03,  3.72s/it] 81%|████████  | 3673/4545 [3:58:42<53:01,  3.65s/it] 81%|████████  | 3674/4545 [3:58:46<54:06,  3.73s/it] 81%|████████  | 3675/4545 [3:58:50<54:56,  3.79s/it] 81%|████████  | 3676/4545 [3:58:54<55:27,  3.83s/it] 81%|████████  | 3677/4545 [3:58:57<55:49,  3.86s/it] 81%|████████  | 3678/4545 [3:59:01<56:20,  3.90s/it] 81%|████████  | 3679/4545 [3:59:05<56:18,  3.90s/it] 81%|████████  | 3680/4545 [3:59:09<55:22,  3.84s/it]                                                     {'loss': 0.2809, 'grad_norm': 10.048270225524902, 'learning_rate': 2.6942958916356994e-08, 'rewards/chosen': 1.672021508216858, 'rewards/rejected': -1.883691430091858, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.5562500953674316, 'logps/chosen': -319.1000061035156, 'logps/rejected': -259.75, 'logits/chosen': -7.618750095367432, 'logits/rejected': -7.356249809265137, 'epoch': 2.43}
 81%|████████  | 3680/4545 [3:59:09<55:22,  3.84s/it] 81%|████████  | 3681/4545 [3:59:12<50:33,  3.51s/it] 81%|████████  | 3682/4545 [3:59:16<52:19,  3.64s/it] 81%|████████  | 3683/4545 [3:59:20<53:35,  3.73s/it] 81%|████████  | 3684/4545 [3:59:24<54:16,  3.78s/it] 81%|████████  | 3685/4545 [3:59:26<49:14,  3.44s/it] 81%|████████  | 3686/4545 [3:59:30<52:41,  3.68s/it] 81%|████████  | 3687/4545 [3:59:34<53:39,  3.75s/it] 81%|████████  | 3688/4545 [3:59:38<54:27,  3.81s/it] 81%|████████  | 3689/4545 [3:59:42<54:51,  3.84s/it] 81%|████████  | 3690/4545 [3:59:46<55:08,  3.87s/it]                                                     {'loss': 0.2464, 'grad_norm': 28.536033630371094, 'learning_rate': 2.6579811283953978e-08, 'rewards/chosen': 2.430908203125, 'rewards/rejected': -2.4091796875, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.839062690734863, 'logps/chosen': -452.1499938964844, 'logps/rejected': -255.75, 'logits/chosen': -7.653124809265137, 'logits/rejected': -7.143750190734863, 'epoch': 2.44}
 81%|████████  | 3690/4545 [3:59:46<55:08,  3.87s/it] 81%|████████  | 3691/4545 [3:59:50<54:10,  3.81s/it] 81%|████████  | 3692/4545 [3:59:54<54:38,  3.84s/it] 81%|████████▏ | 3693/4545 [3:59:58<54:58,  3.87s/it] 81%|████████▏ | 3694/4545 [4:00:01<52:22,  3.69s/it] 81%|████████▏ | 3695/4545 [4:00:05<53:21,  3.77s/it] 81%|████████▏ | 3696/4545 [4:00:09<53:57,  3.81s/it] 81%|████████▏ | 3697/4545 [4:00:12<48:54,  3.46s/it] 81%|████████▏ | 3698/4545 [4:00:16<52:05,  3.69s/it] 81%|████████▏ | 3699/4545 [4:00:19<50:09,  3.56s/it] 81%|████████▏ | 3700/4545 [4:00:23<51:34,  3.66s/it]                                                     {'loss': 0.3108, 'grad_norm': 10.39417552947998, 'learning_rate': 2.621971682123883e-08, 'rewards/chosen': 1.2200195789337158, 'rewards/rejected': -2.169140577316284, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.390625, 'logps/chosen': -257.1000061035156, 'logps/rejected': -201.3000030517578, 'logits/chosen': -7.690625190734863, 'logits/rejected': -7.474999904632568, 'epoch': 2.44}
 81%|████████▏ | 3700/4545 [4:00:23<51:34,  3.66s/it] 81%|████████▏ | 3701/4545 [4:00:27<52:05,  3.70s/it] 81%|████████▏ | 3702/4545 [4:00:31<52:59,  3.77s/it] 81%|████████▏ | 3703/4545 [4:00:35<53:31,  3.81s/it] 81%|████████▏ | 3704/4545 [4:00:38<53:54,  3.85s/it] 82%|████████▏ | 3705/4545 [4:00:43<54:49,  3.92s/it] 82%|████████▏ | 3706/4545 [4:00:46<54:44,  3.91s/it] 82%|████████▏ | 3707/4545 [4:00:50<53:59,  3.87s/it] 82%|████████▏ | 3708/4545 [4:00:54<53:26,  3.83s/it] 82%|████████▏ | 3709/4545 [4:00:58<53:56,  3.87s/it] 82%|████████▏ | 3710/4545 [4:01:02<53:44,  3.86s/it]                                                     {'loss': 0.3183, 'grad_norm': 27.14238929748535, 'learning_rate': 2.5862714213017923e-08, 'rewards/chosen': 0.959765613079071, 'rewards/rejected': -1.8025391101837158, 'rewards/accuracies': 0.875, 'rewards/margins': 2.76171875, 'logps/chosen': -240.85000610351562, 'logps/rejected': -204.14999389648438, 'logits/chosen': -7.878125190734863, 'logits/rejected': -7.449999809265137, 'epoch': 2.45}
 82%|████████▏ | 3710/4545 [4:01:02<53:44,  3.86s/it] 82%|████████▏ | 3711/4545 [4:01:06<54:28,  3.92s/it] 82%|████████▏ | 3712/4545 [4:01:10<55:44,  4.02s/it] 82%|████████▏ | 3713/4545 [4:01:14<55:13,  3.98s/it] 82%|████████▏ | 3714/4545 [4:01:17<52:53,  3.82s/it] 82%|████████▏ | 3715/4545 [4:01:21<53:20,  3.86s/it] 82%|████████▏ | 3716/4545 [4:01:25<52:19,  3.79s/it] 82%|████████▏ | 3717/4545 [4:01:29<53:19,  3.86s/it] 82%|████████▏ | 3718/4545 [4:01:33<53:03,  3.85s/it] 82%|████████▏ | 3719/4545 [4:01:37<53:25,  3.88s/it] 82%|████████▏ | 3720/4545 [4:01:40<51:47,  3.77s/it]                                                     {'loss': 0.3593, 'grad_norm': 12.155230522155762, 'learning_rate': 2.550884181194095e-08, 'rewards/chosen': 0.72119140625, 'rewards/rejected': -2.213085889816284, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.9351563453674316, 'logps/chosen': -235.39999389648438, 'logps/rejected': -158.35000610351562, 'logits/chosen': -7.690625190734863, 'logits/rejected': -7.449999809265137, 'epoch': 2.46}
 82%|████████▏ | 3720/4545 [4:01:40<51:47,  3.77s/it] 82%|████████▏ | 3721/4545 [4:01:43<48:21,  3.52s/it] 82%|████████▏ | 3722/4545 [4:01:47<50:22,  3.67s/it] 82%|████████▏ | 3723/4545 [4:01:51<51:22,  3.75s/it] 82%|████████▏ | 3724/4545 [4:01:55<52:51,  3.86s/it] 82%|████████▏ | 3725/4545 [4:01:58<48:32,  3.55s/it] 82%|████████▏ | 3726/4545 [4:02:02<51:14,  3.75s/it] 82%|████████▏ | 3727/4545 [4:02:06<51:59,  3.81s/it] 82%|████████▏ | 3728/4545 [4:02:10<53:25,  3.92s/it] 82%|████████▏ | 3729/4545 [4:02:15<54:37,  4.02s/it] 82%|████████▏ | 3730/4545 [4:02:18<51:42,  3.81s/it]                                                     {'loss': 0.2617, 'grad_norm': 13.54975414276123, 'learning_rate': 2.5158137634380684e-08, 'rewards/chosen': 2.319409132003784, 'rewards/rejected': -1.915624976158142, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.235547065734863, 'logps/chosen': -382.45001220703125, 'logps/rejected': -208.5500030517578, 'logits/chosen': -7.818749904632568, 'logits/rejected': -7.359375, 'epoch': 2.46}
 82%|████████▏ | 3730/4545 [4:02:18<51:42,  3.81s/it] 82%|████████▏ | 3731/4545 [4:02:22<51:59,  3.83s/it] 82%|████████▏ | 3732/4545 [4:02:25<50:06,  3.70s/it] 82%|████████▏ | 3733/4545 [4:02:29<50:58,  3.77s/it] 82%|████████▏ | 3734/4545 [4:02:33<52:47,  3.91s/it] 82%|████████▏ | 3735/4545 [4:02:37<50:23,  3.73s/it] 82%|████████▏ | 3736/4545 [4:02:41<51:04,  3.79s/it] 82%|████████▏ | 3737/4545 [4:02:44<49:17,  3.66s/it] 82%|████████▏ | 3738/4545 [4:02:48<50:15,  3.74s/it] 82%|████████▏ | 3739/4545 [4:02:52<50:57,  3.79s/it] 82%|████████▏ | 3740/4545 [4:02:56<51:23,  3.83s/it]                                                     {'loss': 0.2844, 'grad_norm': 18.13577651977539, 'learning_rate': 2.4810639356348882e-08, 'rewards/chosen': 1.181298851966858, 'rewards/rejected': -2.327343702316284, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 3.5023436546325684, 'logps/chosen': -256.8999938964844, 'logps/rejected': -183.64999389648438, 'logits/chosen': -7.771874904632568, 'logits/rejected': -7.534375190734863, 'epoch': 2.47}
 82%|████████▏ | 3740/4545 [4:02:56<51:23,  3.83s/it] 82%|████████▏ | 3741/4545 [4:03:00<52:12,  3.90s/it] 82%|████████▏ | 3742/4545 [4:03:04<52:12,  3.90s/it] 82%|████████▏ | 3743/4545 [4:03:07<50:32,  3.78s/it] 82%|████████▏ | 3744/4545 [4:03:11<51:02,  3.82s/it] 82%|████████▏ | 3745/4545 [4:03:15<52:28,  3.94s/it] 82%|████████▏ | 3746/4545 [4:03:20<53:32,  4.02s/it] 82%|████████▏ | 3747/4545 [4:03:23<52:33,  3.95s/it] 82%|████████▏ | 3748/4545 [4:03:27<52:00,  3.92s/it] 82%|████████▏ | 3749/4545 [4:03:31<52:04,  3.93s/it] 83%|████████▎ | 3750/4545 [4:03:35<52:15,  3.94s/it]                                                     {'loss': 0.2835, 'grad_norm': 10.73089599609375, 'learning_rate': 2.4466384309448795e-08, 'rewards/chosen': 0.9706360101699829, 'rewards/rejected': -2.9839844703674316, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.953125, 'logps/chosen': -256.54998779296875, 'logps/rejected': -167.60000610351562, 'logits/chosen': -7.796875, 'logits/rejected': -7.365624904632568, 'epoch': 2.48}
 83%|████████▎ | 3750/4545 [4:03:35<52:15,  3.94s/it] 83%|████████▎ | 3751/4545 [4:03:39<51:27,  3.89s/it] 83%|████████▎ | 3752/4545 [4:03:43<52:11,  3.95s/it] 83%|████████▎ | 3753/4545 [4:03:47<50:22,  3.82s/it] 83%|████████▎ | 3754/4545 [4:03:50<50:41,  3.84s/it] 83%|████████▎ | 3755/4545 [4:03:54<51:01,  3.88s/it] 83%|████████▎ | 3756/4545 [4:03:59<51:50,  3.94s/it] 83%|████████▎ | 3757/4545 [4:04:01<48:00,  3.66s/it] 83%|████████▎ | 3758/4545 [4:04:06<49:42,  3.79s/it] 83%|████████▎ | 3759/4545 [4:04:10<51:22,  3.92s/it] 83%|████████▎ | 3760/4545 [4:04:13<50:01,  3.82s/it]                                                     {'loss': 0.2796, 'grad_norm': 13.985435485839844, 'learning_rate': 2.4125409476864618e-08, 'rewards/chosen': 0.5746825933456421, 'rewards/rejected': -3.003124952316284, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.573437452316284, 'logps/chosen': -180.5500030517578, 'logps/rejected': -157.39999389648438, 'logits/chosen': -7.890625, 'logits/rejected': -7.618750095367432, 'epoch': 2.48}
 83%|████████▎ | 3760/4545 [4:04:13<50:01,  3.82s/it] 83%|████████▎ | 3761/4545 [4:04:17<50:21,  3.85s/it] 83%|████████▎ | 3762/4545 [4:04:19<41:52,  3.21s/it] 83%|████████▎ | 3763/4545 [4:04:23<45:55,  3.52s/it] 83%|████████▎ | 3764/4545 [4:04:26<44:22,  3.41s/it] 83%|████████▎ | 3765/4545 [4:04:29<39:36,  3.05s/it] 83%|████████▎ | 3766/4545 [4:04:33<43:01,  3.31s/it] 83%|████████▎ | 3767/4545 [4:04:37<46:00,  3.55s/it] 83%|████████▎ | 3768/4545 [4:04:41<48:25,  3.74s/it] 83%|████████▎ | 3769/4545 [4:04:44<47:27,  3.67s/it] 83%|████████▎ | 3770/4545 [4:04:48<48:50,  3.78s/it]                                                     {'loss': 0.2939, 'grad_norm': 17.30669593811035, 'learning_rate': 2.378775148938838e-08, 'rewards/chosen': 1.332373023033142, 'rewards/rejected': -2.1820311546325684, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.510937452316284, 'logps/chosen': -270.42498779296875, 'logps/rejected': -202.25, 'logits/chosen': -7.993750095367432, 'logits/rejected': -7.706250190734863, 'epoch': 2.49}
 83%|████████▎ | 3770/4545 [4:04:48<48:50,  3.78s/it] 83%|████████▎ | 3771/4545 [4:04:52<49:17,  3.82s/it] 83%|████████▎ | 3772/4545 [4:04:57<50:45,  3.94s/it] 83%|████████▎ | 3773/4545 [4:05:00<48:18,  3.75s/it] 83%|████████▎ | 3774/4545 [4:05:04<48:47,  3.80s/it] 83%|████████▎ | 3775/4545 [4:05:08<50:02,  3.90s/it] 83%|████████▎ | 3776/4545 [4:05:12<50:01,  3.90s/it] 83%|████████▎ | 3777/4545 [4:05:15<48:57,  3.82s/it] 83%|████████▎ | 3778/4545 [4:05:20<49:44,  3.89s/it] 83%|████████▎ | 3779/4545 [4:05:23<49:45,  3.90s/it] 83%|████████▎ | 3780/4545 [4:05:27<49:40,  3.90s/it]                                                     {'loss': 0.2641, 'grad_norm': 13.618844985961914, 'learning_rate': 2.3453446621484804e-08, 'rewards/chosen': 0.8089843988418579, 'rewards/rejected': -2.5152344703674316, 'rewards/accuracies': 0.875, 'rewards/margins': 3.3179688453674316, 'logps/chosen': -231.14999389648438, 'logps/rejected': -169.64999389648438, 'logits/chosen': -7.740624904632568, 'logits/rejected': -7.34375, 'epoch': 2.5}
 83%|████████▎ | 3780/4545 [4:05:27<49:40,  3.90s/it] 83%|████████▎ | 3781/4545 [4:05:31<49:43,  3.91s/it] 83%|████████▎ | 3782/4545 [4:05:34<44:34,  3.50s/it] 83%|████████▎ | 3783/4545 [4:05:38<46:13,  3.64s/it] 83%|████████▎ | 3784/4545 [4:05:41<45:30,  3.59s/it] 83%|████████▎ | 3785/4545 [4:05:45<46:41,  3.69s/it] 83%|████████▎ | 3786/4545 [4:05:49<48:21,  3.82s/it] 83%|████████▎ | 3787/4545 [4:05:52<43:57,  3.48s/it] 83%|████████▎ | 3788/4545 [4:05:56<44:39,  3.54s/it] 83%|████████▎ | 3789/4545 [4:05:59<43:31,  3.45s/it] 83%|████████▎ | 3790/4545 [4:06:03<44:14,  3.52s/it]                                                     {'loss': 0.2843, 'grad_norm': 20.302404403686523, 'learning_rate': 2.312253078739427e-08, 'rewards/chosen': 0.774127185344696, 'rewards/rejected': -2.890625, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.6664061546325684, 'logps/chosen': -239.0, 'logps/rejected': -190.8000030517578, 'logits/chosen': -7.859375, 'logits/rejected': -7.306250095367432, 'epoch': 2.5}
 83%|████████▎ | 3790/4545 [4:06:03<44:14,  3.52s/it] 83%|████████▎ | 3791/4545 [4:06:06<45:43,  3.64s/it] 83%|████████▎ | 3792/4545 [4:06:10<46:09,  3.68s/it] 83%|████████▎ | 3793/4545 [4:06:14<45:28,  3.63s/it] 83%|████████▎ | 3794/4545 [4:06:17<44:57,  3.59s/it] 83%|████████▎ | 3795/4545 [4:06:21<46:17,  3.70s/it] 84%|████████▎ | 3796/4545 [4:06:25<46:18,  3.71s/it] 84%|████████▎ | 3797/4545 [4:06:29<46:49,  3.76s/it] 84%|████████▎ | 3798/4545 [4:06:33<47:59,  3.85s/it] 84%|████████▎ | 3799/4545 [4:06:37<47:35,  3.83s/it] 84%|████████▎ | 3800/4545 [4:06:40<45:19,  3.65s/it]                                                     {'loss': 0.3071, 'grad_norm': 28.801918029785156, 'learning_rate': 2.2795039537274573e-08, 'rewards/chosen': 0.49189454317092896, 'rewards/rejected': -2.484375, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.979687452316284, 'logps/chosen': -130.5500030517578, 'logps/rejected': -122.3499984741211, 'logits/chosen': -8.199999809265137, 'logits/rejected': -7.78125, 'epoch': 2.51}
 84%|████████▎ | 3800/4545 [4:06:40<45:19,  3.65s/it] 84%|████████▎ | 3801/4545 [4:06:44<46:45,  3.77s/it] 84%|████████▎ | 3802/4545 [4:06:48<47:12,  3.81s/it] 84%|████████▎ | 3803/4545 [4:06:51<44:57,  3.64s/it] 84%|████████▎ | 3804/4545 [4:06:55<47:00,  3.81s/it] 84%|████████▎ | 3805/4545 [4:06:58<44:42,  3.62s/it] 84%|████████▎ | 3806/4545 [4:07:02<45:22,  3.68s/it] 84%|████████▍ | 3807/4545 [4:07:06<44:49,  3.64s/it] 84%|████████▍ | 3808/4545 [4:07:10<46:04,  3.75s/it] 84%|████████▍ | 3809/4545 [4:07:14<47:28,  3.87s/it] 84%|████████▍ | 3810/4545 [4:07:17<44:01,  3.59s/it]                                                     {'loss': 0.2751, 'grad_norm': 12.254016876220703, 'learning_rate': 2.247100805338182e-08, 'rewards/chosen': 0.5743774175643921, 'rewards/rejected': -3.3031249046325684, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.878124952316284, 'logps/chosen': -192.35000610351562, 'logps/rejected': -141.64999389648438, 'logits/chosen': -7.796875, 'logits/rejected': -7.443749904632568, 'epoch': 2.51}
 84%|████████▍ | 3810/4545 [4:07:17<44:01,  3.59s/it] 84%|████████▍ | 3811/4545 [4:07:21<45:10,  3.69s/it] 84%|████████▍ | 3812/4545 [4:07:25<45:54,  3.76s/it] 84%|████████▍ | 3813/4545 [4:07:28<42:15,  3.46s/it] 84%|████████▍ | 3814/4545 [4:07:31<42:31,  3.49s/it] 84%|████████▍ | 3815/4545 [4:07:35<44:10,  3.63s/it] 84%|████████▍ | 3816/4545 [4:07:39<45:18,  3.73s/it] 84%|████████▍ | 3817/4545 [4:07:43<45:52,  3.78s/it] 84%|████████▍ | 3818/4545 [4:07:46<44:16,  3.65s/it] 84%|████████▍ | 3819/4545 [4:07:50<45:10,  3.73s/it] 84%|████████▍ | 3820/4545 [4:07:54<45:46,  3.79s/it]                                                     {'loss': 0.3357, 'grad_norm': 21.350915908813477, 'learning_rate': 2.215047114629079e-08, 'rewards/chosen': 2.382495164871216, 'rewards/rejected': -1.721289038658142, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.10546875, 'logps/chosen': -456.0, 'logps/rejected': -255.60000610351562, 'logits/chosen': -7.5, 'logits/rejected': -7.418749809265137, 'epoch': 2.52}
 84%|████████▍ | 3820/4545 [4:07:54<45:46,  3.79s/it] 84%|████████▍ | 3821/4545 [4:07:58<46:09,  3.82s/it] 84%|████████▍ | 3822/4545 [4:08:02<44:52,  3.72s/it] 84%|████████▍ | 3823/4545 [4:08:06<46:23,  3.85s/it] 84%|████████▍ | 3824/4545 [4:08:10<46:32,  3.87s/it] 84%|████████▍ | 3825/4545 [4:08:14<47:14,  3.94s/it] 84%|████████▍ | 3826/4545 [4:08:17<44:25,  3.71s/it] 84%|████████▍ | 3827/4545 [4:08:21<45:55,  3.84s/it] 84%|████████▍ | 3828/4545 [4:08:24<42:49,  3.58s/it] 84%|████████▍ | 3829/4545 [4:08:28<44:14,  3.71s/it] 84%|████████▍ | 3830/4545 [4:08:32<44:47,  3.76s/it]                                                     {'loss': 0.2413, 'grad_norm': 13.002248764038086, 'learning_rate': 2.1833463251155264e-08, 'rewards/chosen': 0.806445300579071, 'rewards/rejected': -3.448437452316284, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.262499809265137, 'logps/chosen': -238.35000610351562, 'logps/rejected': -180.35000610351562, 'logits/chosen': -7.78125, 'logits/rejected': -7.331250190734863, 'epoch': 2.53}
 84%|████████▍ | 3830/4545 [4:08:32<44:47,  3.76s/it] 84%|████████▍ | 3831/4545 [4:08:36<45:20,  3.81s/it] 84%|████████▍ | 3832/4545 [4:08:38<40:53,  3.44s/it] 84%|████████▍ | 3833/4545 [4:08:42<41:31,  3.50s/it] 84%|████████▍ | 3834/4545 [4:08:46<42:56,  3.62s/it] 84%|████████▍ | 3835/4545 [4:08:50<43:55,  3.71s/it] 84%|████████▍ | 3836/4545 [4:08:54<44:35,  3.77s/it] 84%|████████▍ | 3837/4545 [4:08:58<45:06,  3.82s/it] 84%|████████▍ | 3838/4545 [4:09:01<43:56,  3.73s/it] 84%|████████▍ | 3839/4545 [4:09:04<41:43,  3.55s/it] 84%|████████▍ | 3840/4545 [4:09:08<43:27,  3.70s/it]                                                     {'loss': 0.2797, 'grad_norm': 26.073745727539062, 'learning_rate': 2.1520018424008645e-08, 'rewards/chosen': 1.511474609375, 'rewards/rejected': -2.104687452316284, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.6187500953674316, 'logps/chosen': -288.32501220703125, 'logps/rejected': -218.75, 'logits/chosen': -7.824999809265137, 'logits/rejected': -7.443749904632568, 'epoch': 2.53}
 84%|████████▍ | 3840/4545 [4:09:08<43:27,  3.70s/it] 85%|████████▍ | 3841/4545 [4:09:12<44:07,  3.76s/it] 85%|████████▍ | 3842/4545 [4:09:16<43:48,  3.74s/it] 85%|████████▍ | 3843/4545 [4:09:20<44:20,  3.79s/it] 85%|████████▍ | 3844/4545 [4:09:24<44:43,  3.83s/it] 85%|████████▍ | 3845/4545 [4:09:28<44:09,  3.78s/it] 85%|████████▍ | 3846/4545 [4:09:31<44:33,  3.83s/it] 85%|████████▍ | 3847/4545 [4:09:36<45:59,  3.95s/it] 85%|████████▍ | 3848/4545 [4:09:39<43:29,  3.74s/it] 85%|████████▍ | 3849/4545 [4:09:43<43:38,  3.76s/it] 85%|████████▍ | 3850/4545 [4:09:47<43:59,  3.80s/it]                                                     {'loss': 0.2532, 'grad_norm': 29.40311050415039, 'learning_rate': 2.1210170338105325e-08, 'rewards/chosen': 0.955798327922821, 'rewards/rejected': -2.6968750953674316, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 3.6546874046325684, 'logps/chosen': -233.10000610351562, 'logps/rejected': -134.60000610351562, 'logits/chosen': -7.878125190734863, 'logits/rejected': -7.4375, 'epoch': 2.54}
 85%|████████▍ | 3850/4545 [4:09:47<43:59,  3.80s/it] 85%|████████▍ | 3851/4545 [4:09:51<44:20,  3.83s/it] 85%|████████▍ | 3852/4545 [4:09:55<45:30,  3.94s/it] 85%|████████▍ | 3853/4545 [4:09:58<43:52,  3.80s/it] 85%|████████▍ | 3854/4545 [4:10:02<43:57,  3.82s/it] 85%|████████▍ | 3855/4545 [4:10:06<43:49,  3.81s/it] 85%|████████▍ | 3856/4545 [4:10:09<41:40,  3.63s/it] 85%|████████▍ | 3857/4545 [4:10:13<42:59,  3.75s/it] 85%|████████▍ | 3858/4545 [4:10:17<43:55,  3.84s/it] 85%|████████▍ | 3859/4545 [4:10:20<42:16,  3.70s/it] 85%|████████▍ | 3860/4545 [4:10:24<42:37,  3.73s/it]                                                     {'loss': 0.2935, 'grad_norm': 20.247812271118164, 'learning_rate': 2.0903952280303228e-08, 'rewards/chosen': 1.1053466796875, 'rewards/rejected': -2.7261719703674316, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.8335938453674316, 'logps/chosen': -242.6999969482422, 'logps/rejected': -180.52499389648438, 'logits/chosen': -7.696875095367432, 'logits/rejected': -7.143750190734863, 'epoch': 2.55}
 85%|████████▍ | 3860/4545 [4:10:24<42:37,  3.73s/it] 85%|████████▍ | 3861/4545 [4:10:29<44:07,  3.87s/it] 85%|████████▍ | 3862/4545 [4:10:32<44:10,  3.88s/it] 85%|████████▍ | 3863/4545 [4:10:36<44:16,  3.90s/it] 85%|████████▌ | 3864/4545 [4:10:39<40:27,  3.56s/it] 85%|████████▌ | 3865/4545 [4:10:43<40:33,  3.58s/it] 85%|████████▌ | 3866/4545 [4:10:46<37:48,  3.34s/it] 85%|████████▌ | 3867/4545 [4:10:50<39:55,  3.53s/it] 85%|████████▌ | 3868/4545 [4:10:53<41:05,  3.64s/it] 85%|████████▌ | 3869/4545 [4:10:57<42:00,  3.73s/it] 85%|████████▌ | 3870/4545 [4:11:01<40:12,  3.57s/it]                                                     {'loss': 0.2971, 'grad_norm': 9.83475399017334, 'learning_rate': 2.0601397147487793e-08, 'rewards/chosen': 1.210351586341858, 'rewards/rejected': -2.2679686546325684, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.4781250953674316, 'logps/chosen': -286.04998779296875, 'logps/rejected': -166.1999969482422, 'logits/chosen': -7.840624809265137, 'logits/rejected': -7.540625095367432, 'epoch': 2.55}
 85%|████████▌ | 3870/4545 [4:11:01<40:12,  3.57s/it] 85%|████████▌ | 3871/4545 [4:11:04<38:42,  3.45s/it] 85%|████████▌ | 3872/4545 [4:11:08<40:17,  3.59s/it] 85%|████████▌ | 3873/4545 [4:11:12<42:07,  3.76s/it] 85%|████████▌ | 3874/4545 [4:11:14<38:16,  3.42s/it] 85%|████████▌ | 3875/4545 [4:11:18<39:50,  3.57s/it] 85%|████████▌ | 3876/4545 [4:11:22<41:36,  3.73s/it] 85%|████████▌ | 3877/4545 [4:11:26<42:08,  3.78s/it] 85%|████████▌ | 3878/4545 [4:11:30<42:32,  3.83s/it] 85%|████████▌ | 3879/4545 [4:11:34<42:17,  3.81s/it] 85%|████████▌ | 3880/4545 [4:11:38<42:50,  3.86s/it]                                                     {'loss': 0.3185, 'grad_norm': 25.211246490478516, 'learning_rate': 2.0302537443037818e-08, 'rewards/chosen': 1.7144286632537842, 'rewards/rejected': -1.652380347251892, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.3648438453674316, 'logps/chosen': -345.20001220703125, 'logps/rejected': -186.89999389648438, 'logits/chosen': -7.706250190734863, 'logits/rejected': -7.431250095367432, 'epoch': 2.56}
 85%|████████▌ | 3880/4545 [4:11:38<42:50,  3.86s/it] 85%|████████▌ | 3881/4545 [4:11:40<36:59,  3.34s/it] 85%|████████▌ | 3882/4545 [4:11:43<36:38,  3.32s/it] 85%|████████▌ | 3883/4545 [4:11:47<37:40,  3.41s/it] 85%|████████▌ | 3884/4545 [4:11:51<39:57,  3.63s/it] 85%|████████▌ | 3885/4545 [4:11:54<37:19,  3.39s/it] 86%|████████▌ | 3886/4545 [4:11:58<39:01,  3.55s/it] 86%|████████▌ | 3887/4545 [4:12:02<40:12,  3.67s/it] 86%|████████▌ | 3888/4545 [4:12:06<40:58,  3.74s/it] 86%|████████▌ | 3889/4545 [4:12:10<41:32,  3.80s/it] 86%|████████▌ | 3890/4545 [4:12:13<38:21,  3.51s/it]                                                     {'loss': 0.2995, 'grad_norm': 10.494492530822754, 'learning_rate': 2.0007405273333765e-08, 'rewards/chosen': 1.7181274890899658, 'rewards/rejected': -3.001171827316284, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.723437309265137, 'logps/chosen': -359.79998779296875, 'logps/rejected': -209.35000610351562, 'logits/chosen': -7.637499809265137, 'logits/rejected': -7.371874809265137, 'epoch': 2.57}
 86%|████████▌ | 3890/4545 [4:12:13<38:21,  3.51s/it] 86%|████████▌ | 3891/4545 [4:12:16<38:33,  3.54s/it] 86%|████████▌ | 3892/4545 [4:12:18<33:00,  3.03s/it] 86%|████████▌ | 3893/4545 [4:12:22<35:54,  3.30s/it] 86%|████████▌ | 3894/4545 [4:12:25<33:44,  3.11s/it] 86%|████████▌ | 3895/4545 [4:12:29<36:25,  3.36s/it] 86%|████████▌ | 3896/4545 [4:12:32<35:22,  3.27s/it] 86%|████████▌ | 3897/4545 [4:12:35<37:06,  3.44s/it] 86%|████████▌ | 3898/4545 [4:12:39<38:38,  3.58s/it] 86%|████████▌ | 3899/4545 [4:12:43<38:22,  3.56s/it] 86%|████████▌ | 3900/4545 [4:12:47<40:04,  3.73s/it]                                                     {'loss': 0.2784, 'grad_norm': 39.532630920410156, 'learning_rate': 1.9716032344308464e-08, 'rewards/chosen': 0.888378918170929, 'rewards/rejected': -2.6109375953674316, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.5, 'logps/chosen': -207.375, 'logps/rejected': -157.22500610351562, 'logits/chosen': -7.956250190734863, 'logits/rejected': -7.603125095367432, 'epoch': 2.57}
 86%|████████▌ | 3900/4545 [4:12:47<40:04,  3.73s/it] 86%|████████▌ | 3901/4545 [4:12:51<40:39,  3.79s/it] 86%|████████▌ | 3902/4545 [4:12:54<38:25,  3.59s/it] 86%|████████▌ | 3903/4545 [4:12:58<39:58,  3.74s/it] 86%|████████▌ | 3904/4545 [4:13:02<40:28,  3.79s/it] 86%|████████▌ | 3905/4545 [4:13:06<41:50,  3.92s/it] 86%|████████▌ | 3906/4545 [4:13:10<41:25,  3.89s/it] 86%|████████▌ | 3907/4545 [4:13:14<41:28,  3.90s/it] 86%|████████▌ | 3908/4545 [4:13:18<40:08,  3.78s/it] 86%|████████▌ | 3909/4545 [4:13:21<39:41,  3.74s/it] 86%|████████▌ | 3910/4545 [4:13:25<38:59,  3.68s/it]                                                     {'loss': 0.3142, 'grad_norm': 25.440311431884766, 'learning_rate': 1.9428449958040967e-08, 'rewards/chosen': 0.957592785358429, 'rewards/rejected': -3.223437547683716, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.181250095367432, 'logps/chosen': -255.10000610351562, 'logps/rejected': -185.8000030517578, 'logits/chosen': -7.971875190734863, 'logits/rejected': -7.490624904632568, 'epoch': 2.58}
 86%|████████▌ | 3910/4545 [4:13:25<38:59,  3.68s/it] 86%|████████▌ | 3911/4545 [4:13:29<40:19,  3.82s/it] 86%|████████▌ | 3912/4545 [4:13:33<39:52,  3.78s/it] 86%|████████▌ | 3913/4545 [4:13:36<40:16,  3.82s/it] 86%|████████▌ | 3914/4545 [4:13:40<40:28,  3.85s/it] 86%|████████▌ | 3915/4545 [4:13:44<38:34,  3.67s/it] 86%|████████▌ | 3916/4545 [4:13:47<38:59,  3.72s/it] 86%|████████▌ | 3917/4545 [4:13:51<39:01,  3.73s/it] 86%|████████▌ | 3918/4545 [4:13:55<37:37,  3.60s/it] 86%|████████▌ | 3919/4545 [4:13:58<37:51,  3.63s/it] 86%|████████▌ | 3920/4545 [4:14:02<38:42,  3.72s/it]                                                     {'loss': 0.3063, 'grad_norm': 17.24327850341797, 'learning_rate': 1.914468900939386e-08, 'rewards/chosen': 1.096563696861267, 'rewards/rejected': -4.585156440734863, 'rewards/accuracies': 0.875, 'rewards/margins': 5.688281059265137, 'logps/chosen': -295.54998779296875, 'logps/rejected': -205.1999969482422, 'logits/chosen': -7.775000095367432, 'logits/rejected': -7.506249904632568, 'epoch': 2.59}
 86%|████████▌ | 3920/4545 [4:14:02<38:42,  3.72s/it] 86%|████████▋ | 3921/4545 [4:14:06<39:16,  3.78s/it] 86%|████████▋ | 3922/4545 [4:14:09<37:28,  3.61s/it] 86%|████████▋ | 3923/4545 [4:14:13<38:53,  3.75s/it] 86%|████████▋ | 3924/4545 [4:14:17<38:52,  3.76s/it] 86%|████████▋ | 3925/4545 [4:14:21<37:40,  3.65s/it] 86%|████████▋ | 3926/4545 [4:14:25<39:03,  3.79s/it] 86%|████████▋ | 3927/4545 [4:14:29<39:22,  3.82s/it] 86%|████████▋ | 3928/4545 [4:14:32<39:19,  3.82s/it] 86%|████████▋ | 3929/4545 [4:14:36<39:30,  3.85s/it] 86%|████████▋ | 3930/4545 [4:14:40<39:37,  3.87s/it]                                                     {'loss': 0.2998, 'grad_norm': 13.887596130371094, 'learning_rate': 1.886477998269418e-08, 'rewards/chosen': 1.580480933189392, 'rewards/rejected': -2.620898485183716, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.202343940734863, 'logps/chosen': -317.1000061035156, 'logps/rejected': -220.25, 'logits/chosen': -7.568749904632568, 'logits/rejected': -7.168749809265137, 'epoch': 2.59}
 86%|████████▋ | 3930/4545 [4:14:40<39:37,  3.87s/it] 86%|████████▋ | 3931/4545 [4:14:43<36:54,  3.61s/it] 87%|████████▋ | 3932/4545 [4:14:47<37:47,  3.70s/it] 87%|████████▋ | 3933/4545 [4:14:51<37:19,  3.66s/it] 87%|████████▋ | 3934/4545 [4:14:55<38:01,  3.73s/it] 87%|████████▋ | 3935/4545 [4:14:59<39:26,  3.88s/it] 87%|████████▋ | 3936/4545 [4:15:03<39:27,  3.89s/it] 87%|████████▋ | 3937/4545 [4:15:07<40:04,  3.96s/it] 87%|████████▋ | 3938/4545 [4:15:10<39:05,  3.86s/it] 87%|████████▋ | 3939/4545 [4:15:15<39:39,  3.93s/it] 87%|████████▋ | 3940/4545 [4:15:18<38:11,  3.79s/it]                                                     {'loss': 0.2979, 'grad_norm': 18.58845329284668, 'learning_rate': 1.8588752948458475e-08, 'rewards/chosen': 1.131005883216858, 'rewards/rejected': -2.5999999046325684, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.737499952316284, 'logps/chosen': -278.04998779296875, 'logps/rejected': -176.75, 'logits/chosen': -7.740624904632568, 'logits/rejected': -7.384375095367432, 'epoch': 2.6}
 87%|████████▋ | 3940/4545 [4:15:18<38:11,  3.79s/it] 87%|████████▋ | 3941/4545 [4:15:22<38:32,  3.83s/it] 87%|████████▋ | 3942/4545 [4:15:26<39:10,  3.90s/it] 87%|████████▋ | 3943/4545 [4:15:30<38:24,  3.83s/it] 87%|████████▋ | 3944/4545 [4:15:34<38:39,  3.86s/it] 87%|████████▋ | 3945/4545 [4:15:37<37:52,  3.79s/it] 87%|████████▋ | 3946/4545 [4:15:41<38:19,  3.84s/it] 87%|████████▋ | 3947/4545 [4:15:45<38:51,  3.90s/it] 87%|████████▋ | 3948/4545 [4:15:49<38:39,  3.89s/it] 87%|████████▋ | 3949/4545 [4:15:53<38:43,  3.90s/it] 87%|████████▋ | 3950/4545 [4:15:57<38:34,  3.89s/it]                                                     {'loss': 0.2713, 'grad_norm': 14.477381706237793, 'learning_rate': 1.8316637560162394e-08, 'rewards/chosen': 1.3188354969024658, 'rewards/rejected': -2.31640625, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.6382813453674316, 'logps/chosen': -298.6000061035156, 'logps/rejected': -224.14999389648438, 'logits/chosen': -7.634375095367432, 'logits/rejected': -7.246874809265137, 'epoch': 2.61}
 87%|████████▋ | 3950/4545 [4:15:57<38:34,  3.89s/it] 87%|████████▋ | 3951/4545 [4:16:01<38:21,  3.87s/it] 87%|████████▋ | 3952/4545 [4:16:05<38:26,  3.89s/it] 87%|████████▋ | 3953/4545 [4:16:09<38:47,  3.93s/it] 87%|████████▋ | 3954/4545 [4:16:12<35:39,  3.62s/it] 87%|████████▋ | 3955/4545 [4:16:15<36:27,  3.71s/it] 87%|████████▋ | 3956/4545 [4:16:19<35:52,  3.65s/it] 87%|████████▋ | 3957/4545 [4:16:23<37:20,  3.81s/it] 87%|████████▋ | 3958/4545 [4:16:27<37:36,  3.84s/it] 87%|████████▋ | 3959/4545 [4:16:31<37:50,  3.87s/it] 87%|████████▋ | 3960/4545 [4:16:35<38:22,  3.94s/it]                                                     {'loss': 0.2676, 'grad_norm': 16.85092544555664, 'learning_rate': 1.8048463051055013e-08, 'rewards/chosen': 1.583886742591858, 'rewards/rejected': -2.5992188453674316, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.178906440734863, 'logps/chosen': -301.6499938964844, 'logps/rejected': -195.4499969482422, 'logits/chosen': -7.821875095367432, 'logits/rejected': -7.246874809265137, 'epoch': 2.61}
 87%|████████▋ | 3960/4545 [4:16:35<38:22,  3.94s/it] 87%|████████▋ | 3961/4545 [4:16:39<38:18,  3.94s/it] 87%|████████▋ | 3962/4545 [4:16:43<38:39,  3.98s/it] 87%|████████▋ | 3963/4545 [4:16:47<38:34,  3.98s/it] 87%|████████▋ | 3964/4545 [4:16:51<37:33,  3.88s/it] 87%|████████▋ | 3965/4545 [4:16:54<36:16,  3.75s/it] 87%|████████▋ | 3966/4545 [4:16:57<34:48,  3.61s/it] 87%|████████▋ | 3967/4545 [4:17:02<36:23,  3.78s/it] 87%|████████▋ | 3968/4545 [4:17:05<35:06,  3.65s/it] 87%|████████▋ | 3969/4545 [4:17:08<34:34,  3.60s/it] 87%|████████▋ | 3970/4545 [4:17:11<32:32,  3.40s/it]                                                     {'loss': 0.2624, 'grad_norm': 12.744564056396484, 'learning_rate': 1.778425823101828e-08, 'rewards/chosen': 0.680615246295929, 'rewards/rejected': -3.299999952316284, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.981250047683716, 'logps/chosen': -199.0, 'logps/rejected': -161.3000030517578, 'logits/chosen': -7.893750190734863, 'logits/rejected': -7.378125190734863, 'epoch': 2.62}
 87%|████████▋ | 3970/4545 [4:17:11<32:32,  3.40s/it] 87%|████████▋ | 3971/4545 [4:17:15<34:25,  3.60s/it] 87%|████████▋ | 3972/4545 [4:17:19<33:43,  3.53s/it] 87%|████████▋ | 3973/4545 [4:17:23<34:46,  3.65s/it] 87%|████████▋ | 3974/4545 [4:17:26<34:46,  3.65s/it] 87%|████████▋ | 3975/4545 [4:17:31<36:11,  3.81s/it] 87%|████████▋ | 3976/4545 [4:17:35<36:25,  3.84s/it] 88%|████████▊ | 3977/4545 [4:17:38<36:35,  3.87s/it] 88%|████████▊ | 3978/4545 [4:17:42<36:38,  3.88s/it] 88%|████████▊ | 3979/4545 [4:17:45<34:24,  3.65s/it] 88%|████████▊ | 3980/4545 [4:17:49<35:09,  3.73s/it]                                                     {'loss': 0.2703, 'grad_norm': 18.145572662353516, 'learning_rate': 1.7524051483472048e-08, 'rewards/chosen': 1.4845702648162842, 'rewards/rejected': -2.446093797683716, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.9312500953674316, 'logps/chosen': -297.8500061035156, 'logps/rejected': -173.5, 'logits/chosen': -7.746874809265137, 'logits/rejected': -7.546875, 'epoch': 2.63}
 88%|████████▊ | 3980/4545 [4:17:49<35:09,  3.73s/it] 88%|████████▊ | 3981/4545 [4:17:53<35:37,  3.79s/it] 88%|████████▊ | 3982/4545 [4:17:57<36:23,  3.88s/it] 88%|████████▊ | 3983/4545 [4:18:01<36:27,  3.89s/it] 88%|████████▊ | 3984/4545 [4:18:05<34:51,  3.73s/it] 88%|████████▊ | 3985/4545 [4:18:09<35:17,  3.78s/it] 88%|████████▊ | 3986/4545 [4:18:13<35:44,  3.84s/it] 88%|████████▊ | 3987/4545 [4:18:16<35:54,  3.86s/it] 88%|████████▊ | 3988/4545 [4:18:21<36:50,  3.97s/it] 88%|████████▊ | 3989/4545 [4:18:25<37:30,  4.05s/it] 88%|████████▊ | 3990/4545 [4:18:28<33:53,  3.66s/it]                                                     {'loss': 0.3321, 'grad_norm': 18.9178466796875, 'learning_rate': 1.726787076232476e-08, 'rewards/chosen': 1.2790038585662842, 'rewards/rejected': -3.0611815452575684, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 4.340624809265137, 'logps/chosen': -295.04998779296875, 'logps/rejected': -201.4499969482422, 'logits/chosen': -7.865624904632568, 'logits/rejected': -7.456250190734863, 'epoch': 2.63}
 88%|████████▊ | 3990/4545 [4:18:28<33:53,  3.66s/it] 88%|████████▊ | 3991/4545 [4:18:31<33:50,  3.66s/it] 88%|████████▊ | 3992/4545 [4:18:35<34:19,  3.72s/it] 88%|████████▊ | 3993/4545 [4:18:38<31:58,  3.47s/it] 88%|████████▊ | 3994/4545 [4:18:42<33:25,  3.64s/it] 88%|████████▊ | 3995/4545 [4:18:46<34:07,  3.72s/it] 88%|████████▊ | 3996/4545 [4:18:50<34:33,  3.78s/it] 88%|████████▊ | 3997/4545 [4:18:53<33:23,  3.66s/it] 88%|████████▊ | 3998/4545 [4:18:57<34:01,  3.73s/it] 88%|████████▊ | 3999/4545 [4:19:01<34:22,  3.78s/it] 88%|████████▊ | 4000/4545 [4:19:05<35:24,  3.90s/it]                                                     {'loss': 0.243, 'grad_norm': 13.7102689743042, 'learning_rate': 1.7015743588970472e-08, 'rewards/chosen': 1.199072241783142, 'rewards/rejected': -3.31640625, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.521874904632568, 'logps/chosen': -274.25, 'logps/rejected': -177.85000610351562, 'logits/chosen': -7.931250095367432, 'logits/rejected': -7.415625095367432, 'epoch': 2.64}
 88%|████████▊ | 4000/4545 [4:19:05<35:24,  3.90s/it] 88%|████████▊ | 4001/4545 [4:19:08<33:14,  3.67s/it] 88%|████████▊ | 4002/4545 [4:19:12<33:40,  3.72s/it] 88%|████████▊ | 4003/4545 [4:19:16<34:08,  3.78s/it] 88%|████████▊ | 4004/4545 [4:19:19<32:11,  3.57s/it] 88%|████████▊ | 4005/4545 [4:19:23<33:03,  3.67s/it] 88%|████████▊ | 4006/4545 [4:19:27<34:18,  3.82s/it] 88%|████████▊ | 4007/4545 [4:19:30<32:27,  3.62s/it] 88%|████████▊ | 4008/4545 [4:19:34<33:13,  3.71s/it] 88%|████████▊ | 4009/4545 [4:19:38<33:41,  3.77s/it] 88%|████████▊ | 4010/4545 [4:19:42<34:30,  3.87s/it]                                                     {'loss': 0.2811, 'grad_norm': 16.956214904785156, 'learning_rate': 1.6767697049332196e-08, 'rewards/chosen': 1.114013671875, 'rewards/rejected': -2.3988280296325684, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.516406297683716, 'logps/chosen': -244.0749969482422, 'logps/rejected': -117.0, 'logits/chosen': -7.918749809265137, 'logits/rejected': -7.581250190734863, 'epoch': 2.65}
 88%|████████▊ | 4010/4545 [4:19:42<34:30,  3.87s/it] 88%|████████▊ | 4011/4545 [4:19:47<35:18,  3.97s/it] 88%|████████▊ | 4012/4545 [4:19:51<35:05,  3.95s/it] 88%|████████▊ | 4013/4545 [4:19:53<31:14,  3.52s/it] 88%|████████▊ | 4014/4545 [4:19:57<31:41,  3.58s/it] 88%|████████▊ | 4015/4545 [4:20:00<31:42,  3.59s/it] 88%|████████▊ | 4016/4545 [4:20:04<32:18,  3.66s/it] 88%|████████▊ | 4017/4545 [4:20:08<32:55,  3.74s/it] 88%|████████▊ | 4018/4545 [4:20:12<33:21,  3.80s/it] 88%|████████▊ | 4019/4545 [4:20:16<34:05,  3.89s/it] 88%|████████▊ | 4020/4545 [4:20:19<31:43,  3.63s/it]                                                     {'loss': 0.249, 'grad_norm': 22.749961853027344, 'learning_rate': 1.6523757790952032e-08, 'rewards/chosen': 1.0015869140625, 'rewards/rejected': -3.2144532203674316, 'rewards/accuracies': 0.875, 'rewards/margins': 4.21875, 'logps/chosen': -241.85000610351562, 'logps/rejected': -193.85000610351562, 'logits/chosen': -7.84375, 'logits/rejected': -7.503125190734863, 'epoch': 2.65}
 88%|████████▊ | 4020/4545 [4:20:19<31:43,  3.63s/it] 88%|████████▊ | 4021/4545 [4:20:23<32:26,  3.72s/it] 88%|████████▊ | 4022/4545 [4:20:27<32:53,  3.77s/it] 89%|████████▊ | 4023/4545 [4:20:31<33:44,  3.88s/it] 89%|████████▊ | 4024/4545 [4:20:34<30:27,  3.51s/it] 89%|████████▊ | 4025/4545 [4:20:38<31:27,  3.63s/it] 89%|████████▊ | 4026/4545 [4:20:40<29:07,  3.37s/it] 89%|████████▊ | 4027/4545 [4:20:44<29:56,  3.47s/it] 89%|████████▊ | 4028/4545 [4:20:47<28:40,  3.33s/it] 89%|████████▊ | 4029/4545 [4:20:51<30:07,  3.50s/it] 89%|████████▊ | 4030/4545 [4:20:55<31:58,  3.72s/it]                                                     {'loss': 0.3164, 'grad_norm': 18.278478622436523, 'learning_rate': 1.6283952020128504e-08, 'rewards/chosen': 1.1527893543243408, 'rewards/rejected': -2.653027296066284, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.80859375, 'logps/chosen': -280.6499938964844, 'logps/rejected': -171.35000610351562, 'logits/chosen': -7.818749904632568, 'logits/rejected': -7.521874904632568, 'epoch': 2.66}
 89%|████████▊ | 4030/4545 [4:20:55<31:58,  3.72s/it] 89%|████████▊ | 4031/4545 [4:20:59<32:26,  3.79s/it] 89%|████████▊ | 4032/4545 [4:21:02<30:46,  3.60s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.38s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.45s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.51s/it][A                                                     
                                               [A{'eval_loss': 0.41098570823669434, 'eval_runtime': 80.3996, 'eval_samples_per_second': 11.853, 'eval_steps_per_second': 0.746, 'eval_rewards/chosen': 1.520953893661499, 'eval_rewards/rejected': -1.8222330808639526, 'eval_rewards/accuracies': 0.8076388835906982, 'eval_rewards/margins': 3.3438720703125, 'eval_logps/chosen': -362.1666564941406, 'eval_logps/rejected': -170.2708282470703, 'eval_logits/chosen': -7.493229389190674, 'eval_logits/rejected': -7.832291603088379, 'epoch': 2.66}
 89%|████████▊ | 4032/4545 [4:22:23<30:46,  3.60s/it]
100%|██████████| 60/60 [01:18<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 89%|████████▊ | 4033/4545 [4:22:37<4:24:35, 31.01s/it] 89%|████████▉ | 4034/4545 [4:22:41<3:14:45, 22.87s/it] 89%|████████▉ | 4035/4545 [4:22:45<2:25:20, 17.10s/it] 89%|████████▉ | 4036/4545 [4:22:48<1:50:28, 13.02s/it] 89%|████████▉ | 4037/4545 [4:22:52<1:27:10, 10.30s/it] 89%|████████▉ | 4038/4545 [4:22:56<1:08:58,  8.16s/it] 89%|████████▉ | 4039/4545 [4:22:59<58:04,  6.89s/it]   89%|████████▉ | 4040/4545 [4:23:03<50:26,  5.99s/it]                                                     {'loss': 0.3136, 'grad_norm': 12.751527786254883, 'learning_rate': 1.6048305499101194e-08, 'rewards/chosen': 0.9378662109375, 'rewards/rejected': -2.641406297683716, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.581249952316284, 'logps/chosen': -230.10000610351562, 'logps/rejected': -132.5, 'logits/chosen': -7.953125, 'logits/rejected': -7.546875, 'epoch': 2.67}
 89%|████████▉ | 4040/4545 [4:23:03<50:26,  5.99s/it] 89%|████████▉ | 4041/4545 [4:23:07<45:09,  5.38s/it] 89%|████████▉ | 4042/4545 [4:23:11<40:50,  4.87s/it] 89%|████████▉ | 4043/4545 [4:23:13<34:28,  4.12s/it] 89%|████████▉ | 4044/4545 [4:23:17<34:06,  4.08s/it] 89%|████████▉ | 4045/4545 [4:23:21<33:41,  4.04s/it] 89%|████████▉ | 4046/4545 [4:23:25<33:07,  3.98s/it] 89%|████████▉ | 4047/4545 [4:23:29<32:56,  3.97s/it] 89%|████████▉ | 4048/4545 [4:23:33<32:32,  3.93s/it] 89%|████████▉ | 4049/4545 [4:23:36<29:39,  3.59s/it] 89%|████████▉ | 4050/4545 [4:23:39<30:02,  3.64s/it]                                                     {'loss': 0.2624, 'grad_norm': 30.190357208251953, 'learning_rate': 1.5816843543283102e-08, 'rewards/chosen': 1.174658179283142, 'rewards/rejected': -2.500781297683716, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.674999952316284, 'logps/chosen': -235.5, 'logps/rejected': -181.1999969482422, 'logits/chosen': -7.96875, 'logits/rejected': -7.474999904632568, 'epoch': 2.67}
 89%|████████▉ | 4050/4545 [4:23:39<30:02,  3.64s/it] 89%|████████▉ | 4051/4545 [4:23:43<30:40,  3.73s/it] 89%|████████▉ | 4052/4545 [4:23:47<29:23,  3.58s/it] 89%|████████▉ | 4053/4545 [4:23:51<30:26,  3.71s/it] 89%|████████▉ | 4054/4545 [4:23:55<31:38,  3.87s/it] 89%|████████▉ | 4055/4545 [4:23:59<31:39,  3.88s/it] 89%|████████▉ | 4056/4545 [4:24:03<31:42,  3.89s/it] 89%|████████▉ | 4057/4545 [4:24:07<31:42,  3.90s/it] 89%|████████▉ | 4058/4545 [4:24:10<29:58,  3.69s/it] 89%|████████▉ | 4059/4545 [4:24:13<29:21,  3.62s/it] 89%|████████▉ | 4060/4545 [4:24:17<29:58,  3.71s/it]                                                     {'loss': 0.3166, 'grad_norm': 36.89301300048828, 'learning_rate': 1.558959101854105e-08, 'rewards/chosen': 1.7952759265899658, 'rewards/rejected': -2.7128663063049316, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.509375095367432, 'logps/chosen': -369.5, 'logps/rejected': -189.8000030517578, 'logits/chosen': -7.771874904632568, 'logits/rejected': -7.465624809265137, 'epoch': 2.68}
 89%|████████▉ | 4060/4545 [4:24:17<29:58,  3.71s/it] 89%|████████▉ | 4061/4545 [4:24:21<30:38,  3.80s/it] 89%|████████▉ | 4062/4545 [4:24:25<30:50,  3.83s/it] 89%|████████▉ | 4063/4545 [4:24:27<27:19,  3.40s/it] 89%|████████▉ | 4064/4545 [4:24:32<28:48,  3.59s/it] 89%|████████▉ | 4065/4545 [4:24:35<29:38,  3.71s/it] 89%|████████▉ | 4066/4545 [4:24:40<30:33,  3.83s/it] 89%|████████▉ | 4067/4545 [4:24:43<28:18,  3.55s/it] 90%|████████▉ | 4068/4545 [4:24:46<29:04,  3.66s/it] 90%|████████▉ | 4069/4545 [4:24:48<25:09,  3.17s/it] 90%|████████▉ | 4070/4545 [4:24:52<26:55,  3.40s/it]                                                     {'loss': 0.2615, 'grad_norm': 10.43830680847168, 'learning_rate': 1.5366572338524305e-08, 'rewards/chosen': 1.327294945716858, 'rewards/rejected': -2.7203125953674316, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.042187690734863, 'logps/chosen': -260.6000061035156, 'logps/rejected': -160.25, 'logits/chosen': -7.778124809265137, 'logits/rejected': -7.309374809265137, 'epoch': 2.69}
 90%|████████▉ | 4070/4545 [4:24:52<26:55,  3.40s/it] 90%|████████▉ | 4071/4545 [4:24:56<28:26,  3.60s/it] 90%|████████▉ | 4072/4545 [4:25:00<29:08,  3.70s/it] 90%|████████▉ | 4073/4545 [4:25:04<28:04,  3.57s/it] 90%|████████▉ | 4074/4545 [4:25:08<28:50,  3.67s/it] 90%|████████▉ | 4075/4545 [4:25:12<29:22,  3.75s/it] 90%|████████▉ | 4076/4545 [4:25:16<30:09,  3.86s/it] 90%|████████▉ | 4077/4545 [4:25:20<30:39,  3.93s/it] 90%|████████▉ | 4078/4545 [4:25:22<27:45,  3.57s/it] 90%|████████▉ | 4079/4545 [4:25:26<28:30,  3.67s/it] 90%|████████▉ | 4080/4545 [4:25:30<28:33,  3.69s/it]                                                     {'loss': 0.2776, 'grad_norm': 16.23769187927246, 'learning_rate': 1.51478114620419e-08, 'rewards/chosen': 2.0975098609924316, 'rewards/rejected': -2.319140672683716, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.41796875, 'logps/chosen': -387.8500061035156, 'logps/rejected': -197.5, 'logits/chosen': -7.515625, 'logits/rejected': -7.184374809265137, 'epoch': 2.69}
 90%|████████▉ | 4080/4545 [4:25:30<28:33,  3.69s/it] 90%|████████▉ | 4081/4545 [4:25:34<29:28,  3.81s/it] 90%|████████▉ | 4082/4545 [4:25:38<29:30,  3.82s/it] 90%|████████▉ | 4083/4545 [4:25:42<30:12,  3.92s/it] 90%|████████▉ | 4084/4545 [4:25:45<27:41,  3.60s/it] 90%|████████▉ | 4085/4545 [4:25:49<28:19,  3.70s/it] 90%|████████▉ | 4086/4545 [4:25:53<28:08,  3.68s/it] 90%|████████▉ | 4087/4545 [4:25:57<28:38,  3.75s/it] 90%|████████▉ | 4088/4545 [4:26:00<28:55,  3.80s/it] 90%|████████▉ | 4089/4545 [4:26:04<29:08,  3.83s/it] 90%|████████▉ | 4090/4545 [4:26:08<28:30,  3.76s/it]                                                     {'loss': 0.3135, 'grad_norm': 18.13672637939453, 'learning_rate': 1.4933331890488704e-08, 'rewards/chosen': 1.8030608892440796, 'rewards/rejected': -2.637500047683716, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 4.4375, 'logps/chosen': -353.70001220703125, 'logps/rejected': -207.39999389648438, 'logits/chosen': -7.756249904632568, 'logits/rejected': -7.496874809265137, 'epoch': 2.7}
 90%|████████▉ | 4090/4545 [4:26:08<28:30,  3.76s/it] 90%|█████████ | 4091/4545 [4:26:12<28:27,  3.76s/it] 90%|█████████ | 4092/4545 [4:26:16<28:44,  3.81s/it] 90%|█████████ | 4093/4545 [4:26:19<28:50,  3.83s/it] 90%|█████████ | 4094/4545 [4:26:23<28:04,  3.74s/it] 90%|█████████ | 4095/4545 [4:26:27<28:26,  3.79s/it] 90%|█████████ | 4096/4545 [4:26:30<26:38,  3.56s/it] 90%|█████████ | 4097/4545 [4:26:34<27:23,  3.67s/it] 90%|█████████ | 4098/4545 [4:26:37<26:10,  3.51s/it] 90%|█████████ | 4099/4545 [4:26:41<26:58,  3.63s/it] 90%|█████████ | 4100/4545 [4:26:45<27:56,  3.77s/it]                                                     {'loss': 0.363, 'grad_norm': 19.99479866027832, 'learning_rate': 1.4723156665320644e-08, 'rewards/chosen': 1.8424263000488281, 'rewards/rejected': -2.391796827316284, 'rewards/accuracies': 0.8125, 'rewards/margins': 4.235547065734863, 'logps/chosen': -368.25, 'logps/rejected': -190.64999389648438, 'logits/chosen': -7.653124809265137, 'logits/rejected': -7.415625095367432, 'epoch': 2.71}
 90%|█████████ | 4100/4545 [4:26:45<27:56,  3.77s/it] 90%|█████████ | 4101/4545 [4:26:49<28:13,  3.81s/it] 90%|█████████ | 4102/4545 [4:26:53<28:27,  3.85s/it] 90%|█████████ | 4103/4545 [4:26:57<28:25,  3.86s/it] 90%|█████████ | 4104/4545 [4:27:01<28:31,  3.88s/it] 90%|█████████ | 4105/4545 [4:27:05<28:55,  3.94s/it] 90%|█████████ | 4106/4545 [4:27:09<29:29,  4.03s/it] 90%|█████████ | 4107/4545 [4:27:13<29:05,  3.98s/it] 90%|█████████ | 4108/4545 [4:27:17<29:13,  4.01s/it] 90%|█████████ | 4109/4545 [4:27:21<29:14,  4.02s/it] 90%|█████████ | 4110/4545 [4:27:25<28:51,  3.98s/it]                                                     {'loss': 0.2888, 'grad_norm': 12.981630325317383, 'learning_rate': 1.4517308365579442e-08, 'rewards/chosen': 1.353613257408142, 'rewards/rejected': -2.772656202316284, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.125, 'logps/chosen': -296.70001220703125, 'logps/rejected': -187.35000610351562, 'logits/chosen': -7.912499904632568, 'logits/rejected': -7.559374809265137, 'epoch': 2.71}
 90%|█████████ | 4110/4545 [4:27:25<28:51,  3.98s/it] 90%|█████████ | 4111/4545 [4:27:29<28:39,  3.96s/it] 90%|█████████ | 4112/4545 [4:27:33<28:16,  3.92s/it] 90%|█████████ | 4113/4545 [4:27:37<28:36,  3.97s/it] 91%|█████████ | 4114/4545 [4:27:40<27:51,  3.88s/it] 91%|█████████ | 4115/4545 [4:27:44<26:32,  3.70s/it] 91%|█████████ | 4116/4545 [4:27:47<25:44,  3.60s/it] 91%|█████████ | 4117/4545 [4:27:51<26:20,  3.69s/it] 91%|█████████ | 4118/4545 [4:27:55<26:45,  3.76s/it] 91%|█████████ | 4119/4545 [4:27:59<26:31,  3.74s/it] 91%|█████████ | 4120/4545 [4:28:02<26:50,  3.79s/it]                                                     {'loss': 0.2542, 'grad_norm': 8.314430236816406, 'learning_rate': 1.4315809105466942e-08, 'rewards/chosen': 1.0013916492462158, 'rewards/rejected': -2.774609327316284, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.7734375, 'logps/chosen': -210.5, 'logps/rejected': -140.10000610351562, 'logits/chosen': -7.987500190734863, 'logits/rejected': -7.415625095367432, 'epoch': 2.72}
 91%|█████████ | 4120/4545 [4:28:02<26:50,  3.79s/it] 91%|█████████ | 4121/4545 [4:28:06<27:03,  3.83s/it] 91%|█████████ | 4122/4545 [4:28:11<27:41,  3.93s/it] 91%|█████████ | 4123/4545 [4:28:14<26:24,  3.76s/it] 91%|█████████ | 4124/4545 [4:28:18<26:44,  3.81s/it] 91%|█████████ | 4125/4545 [4:28:21<26:20,  3.76s/it] 91%|█████████ | 4126/4545 [4:28:25<26:35,  3.81s/it] 91%|█████████ | 4127/4545 [4:28:29<26:11,  3.76s/it] 91%|█████████ | 4128/4545 [4:28:33<26:39,  3.83s/it] 91%|█████████ | 4129/4545 [4:28:37<26:46,  3.86s/it] 91%|█████████ | 4130/4545 [4:28:41<26:54,  3.89s/it]                                                     {'loss': 0.2755, 'grad_norm': 21.185550689697266, 'learning_rate': 1.4118680531969333e-08, 'rewards/chosen': 0.98675537109375, 'rewards/rejected': -3.53125, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.521093845367432, 'logps/chosen': -279.45001220703125, 'logps/rejected': -164.5500030517578, 'logits/chosen': -7.681250095367432, 'logits/rejected': -7.384375095367432, 'epoch': 2.73}
 91%|█████████ | 4130/4545 [4:28:41<26:54,  3.89s/it] 91%|█████████ | 4131/4545 [4:28:45<27:30,  3.99s/it] 91%|█████████ | 4132/4545 [4:28:49<27:53,  4.05s/it] 91%|█████████ | 4133/4545 [4:28:53<27:57,  4.07s/it] 91%|█████████ | 4134/4545 [4:28:56<25:41,  3.75s/it] 91%|█████████ | 4135/4545 [4:29:00<25:45,  3.77s/it] 91%|█████████ | 4136/4545 [4:29:04<25:45,  3.78s/it] 91%|█████████ | 4137/4545 [4:29:06<22:52,  3.36s/it] 91%|█████████ | 4138/4545 [4:29:11<24:20,  3.59s/it] 91%|█████████ | 4139/4545 [4:29:15<25:01,  3.70s/it] 91%|█████████ | 4140/4545 [4:29:18<24:09,  3.58s/it]                                                     {'loss': 0.2326, 'grad_norm': 7.422369956970215, 'learning_rate': 1.3925943822531674e-08, 'rewards/chosen': 0.3571884036064148, 'rewards/rejected': -3.62109375, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.9820313453674316, 'logps/chosen': -140.0500030517578, 'logps/rejected': -120.69999694824219, 'logits/chosen': -8.074999809265137, 'logits/rejected': -7.362500190734863, 'epoch': 2.73}
 91%|█████████ | 4140/4545 [4:29:18<24:09,  3.58s/it] 91%|█████████ | 4141/4545 [4:29:21<23:00,  3.42s/it] 91%|█████████ | 4142/4545 [4:29:25<24:09,  3.60s/it] 91%|█████████ | 4143/4545 [4:29:28<22:26,  3.35s/it] 91%|█████████ | 4144/4545 [4:29:31<23:07,  3.46s/it] 91%|█████████ | 4145/4545 [4:29:35<23:41,  3.55s/it] 91%|█████████ | 4146/4545 [4:29:39<24:51,  3.74s/it] 91%|█████████ | 4147/4545 [4:29:42<23:27,  3.54s/it] 91%|█████████▏| 4148/4545 [4:29:47<24:41,  3.73s/it] 91%|█████████▏| 4149/4545 [4:29:49<22:41,  3.44s/it] 91%|█████████▏| 4150/4545 [4:29:53<24:05,  3.66s/it]                                                     {'loss': 0.2713, 'grad_norm': 6.565703392028809, 'learning_rate': 1.373761968278282e-08, 'rewards/chosen': 1.2807738780975342, 'rewards/rejected': -3.055468797683716, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 4.334374904632568, 'logps/chosen': -286.25, 'logps/rejected': -149.25, 'logits/chosen': -7.699999809265137, 'logits/rejected': -7.3125, 'epoch': 2.74}
 91%|█████████▏| 4150/4545 [4:29:54<24:05,  3.66s/it] 91%|█████████▏| 4151/4545 [4:29:57<24:32,  3.74s/it] 91%|█████████▏| 4152/4545 [4:30:02<25:21,  3.87s/it] 91%|█████████▏| 4153/4545 [4:30:06<25:22,  3.88s/it] 91%|█████████▏| 4154/4545 [4:30:09<24:56,  3.83s/it] 91%|█████████▏| 4155/4545 [4:30:11<21:51,  3.36s/it] 91%|█████████▏| 4156/4545 [4:30:15<22:54,  3.53s/it] 91%|█████████▏| 4157/4545 [4:30:19<23:46,  3.68s/it] 91%|█████████▏| 4158/4545 [4:30:23<24:11,  3.75s/it] 92%|█████████▏| 4159/4545 [4:30:27<23:10,  3.60s/it] 92%|█████████▏| 4160/4545 [4:30:31<23:43,  3.70s/it]                                                     {'loss': 0.2752, 'grad_norm': 7.148650646209717, 'learning_rate': 1.3553728344310958e-08, 'rewards/chosen': 1.382714867591858, 'rewards/rejected': -2.2554688453674316, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.635937452316284, 'logps/chosen': -267.0249938964844, 'logps/rejected': -211.25, 'logits/chosen': -7.946875095367432, 'logits/rejected': -7.362500190734863, 'epoch': 2.75}
 92%|█████████▏| 4160/4545 [4:30:31<23:43,  3.70s/it] 92%|█████████▏| 4161/4545 [4:30:34<22:39,  3.54s/it] 92%|█████████▏| 4162/4545 [4:30:36<20:45,  3.25s/it] 92%|█████████▏| 4163/4545 [4:30:40<22:09,  3.48s/it] 92%|█████████▏| 4164/4545 [4:30:44<22:50,  3.60s/it] 92%|█████████▏| 4165/4545 [4:30:48<23:24,  3.70s/it] 92%|█████████▏| 4166/4545 [4:30:52<23:47,  3.77s/it] 92%|█████████▏| 4167/4545 [4:30:55<23:02,  3.66s/it] 92%|█████████▏| 4168/4545 [4:30:59<23:26,  3.73s/it] 92%|█████████▏| 4169/4545 [4:31:03<23:01,  3.67s/it] 92%|█████████▏| 4170/4545 [4:31:07<23:19,  3.73s/it]                                                     {'loss': 0.3115, 'grad_norm': 11.258358001708984, 'learning_rate': 1.3374289562490212e-08, 'rewards/chosen': 1.121484398841858, 'rewards/rejected': -2.490234375, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.6109375953674316, 'logps/chosen': -245.4499969482422, 'logps/rejected': -188.4499969482422, 'logits/chosen': -7.884375095367432, 'logits/rejected': -7.4375, 'epoch': 2.75}
 92%|█████████▏| 4170/4545 [4:31:07<23:19,  3.73s/it] 92%|█████████▏| 4171/4545 [4:31:10<23:11,  3.72s/it] 92%|█████████▏| 4172/4545 [4:31:14<23:32,  3.79s/it] 92%|█████████▏| 4173/4545 [4:31:17<21:07,  3.41s/it] 92%|█████████▏| 4174/4545 [4:31:21<22:09,  3.58s/it] 92%|█████████▏| 4175/4545 [4:31:24<21:26,  3.48s/it] 92%|█████████▏| 4176/4545 [4:31:28<22:10,  3.61s/it] 92%|█████████▏| 4177/4545 [4:31:31<21:15,  3.47s/it] 92%|█████████▏| 4178/4545 [4:31:35<21:45,  3.56s/it] 92%|█████████▏| 4179/4545 [4:31:37<19:46,  3.24s/it] 92%|█████████▏| 4180/4545 [4:31:41<19:43,  3.24s/it]                                                     {'loss': 0.3104, 'grad_norm': 14.880839347839355, 'learning_rate': 1.3199322614358294e-08, 'rewards/chosen': 1.386199951171875, 'rewards/rejected': -2.723437547683716, 'rewards/accuracies': 0.8125, 'rewards/margins': 4.107812404632568, 'logps/chosen': -294.0, 'logps/rejected': -171.6750030517578, 'logits/chosen': -7.768750190734863, 'logits/rejected': -7.481249809265137, 'epoch': 2.76}
 92%|█████████▏| 4180/4545 [4:31:41<19:43,  3.24s/it] 92%|█████████▏| 4181/4545 [4:31:44<19:50,  3.27s/it] 92%|█████████▏| 4182/4545 [4:31:48<20:57,  3.46s/it] 92%|█████████▏| 4183/4545 [4:31:52<21:44,  3.60s/it] 92%|█████████▏| 4184/4545 [4:31:56<22:13,  3.69s/it] 92%|█████████▏| 4185/4545 [4:32:00<22:28,  3.75s/it] 92%|█████████▏| 4186/4545 [4:32:04<22:44,  3.80s/it] 92%|█████████▏| 4187/4545 [4:32:08<23:30,  3.94s/it] 92%|█████████▏| 4188/4545 [4:32:12<23:23,  3.93s/it] 92%|█████████▏| 4189/4545 [4:32:16<23:16,  3.92s/it] 92%|█████████▏| 4190/4545 [4:32:19<22:45,  3.85s/it]                                                     {'loss': 0.3547, 'grad_norm': 29.968843460083008, 'learning_rate': 1.3028846296545564e-08, 'rewards/chosen': 1.9917480945587158, 'rewards/rejected': -2.2230467796325684, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.215624809265137, 'logps/chosen': -394.25, 'logps/rejected': -271.6499938964844, 'logits/chosen': -7.581250190734863, 'logits/rejected': -7.231249809265137, 'epoch': 2.77}
 92%|█████████▏| 4190/4545 [4:32:19<22:45,  3.85s/it] 92%|█████████▏| 4191/4545 [4:32:23<22:21,  3.79s/it] 92%|█████████▏| 4192/4545 [4:32:26<20:22,  3.46s/it] 92%|█████████▏| 4193/4545 [4:32:29<20:10,  3.44s/it] 92%|█████████▏| 4194/4545 [4:32:33<20:48,  3.56s/it] 92%|█████████▏| 4195/4545 [4:32:37<21:26,  3.68s/it] 92%|█████████▏| 4196/4545 [4:32:41<21:27,  3.69s/it] 92%|█████████▏| 4197/4545 [4:32:44<21:49,  3.76s/it] 92%|█████████▏| 4198/4545 [4:32:47<20:21,  3.52s/it] 92%|█████████▏| 4199/4545 [4:32:51<20:59,  3.64s/it] 92%|█████████▏| 4200/4545 [4:32:55<21:18,  3.71s/it]                                                     {'loss': 0.2641, 'grad_norm': 13.673418998718262, 'learning_rate': 1.2862878923255766e-08, 'rewards/chosen': 0.7529052495956421, 'rewards/rejected': -3.375, 'rewards/accuracies': 0.875, 'rewards/margins': 4.1328125, 'logps/chosen': -237.89999389648438, 'logps/rejected': -141.3000030517578, 'logits/chosen': -7.893750190734863, 'logits/rejected': -7.456250190734863, 'epoch': 2.77}
 92%|█████████▏| 4200/4545 [4:32:55<21:18,  3.71s/it] 92%|█████████▏| 4201/4545 [4:32:59<21:15,  3.71s/it] 92%|█████████▏| 4202/4545 [4:33:03<21:33,  3.77s/it] 92%|█████████▏| 4203/4545 [4:33:07<21:44,  3.82s/it] 92%|█████████▏| 4204/4545 [4:33:10<21:27,  3.78s/it] 93%|█████████▎| 4205/4545 [4:33:14<21:40,  3.82s/it] 93%|█████████▎| 4206/4545 [4:33:18<21:44,  3.85s/it] 93%|█████████▎| 4207/4545 [4:33:22<21:38,  3.84s/it] 93%|█████████▎| 4208/4545 [4:33:26<21:43,  3.87s/it] 93%|█████████▎| 4209/4545 [4:33:30<21:43,  3.88s/it] 93%|█████████▎| 4210/4545 [4:33:34<21:24,  3.83s/it]                                                     {'loss': 0.3378, 'grad_norm': 33.044620513916016, 'learning_rate': 1.2701438324298467e-08, 'rewards/chosen': 2.1761474609375, 'rewards/rejected': -1.623437523841858, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.799999952316284, 'logps/chosen': -413.25, 'logps/rejected': -227.6999969482422, 'logits/chosen': -7.565625190734863, 'logits/rejected': -7.496874809265137, 'epoch': 2.78}
 93%|█████████▎| 4210/4545 [4:33:34<21:24,  3.83s/it] 93%|█████████▎| 4211/4545 [4:33:38<21:36,  3.88s/it] 93%|█████████▎| 4212/4545 [4:33:41<20:59,  3.78s/it] 93%|█████████▎| 4213/4545 [4:33:45<20:53,  3.77s/it] 93%|█████████▎| 4214/4545 [4:33:48<19:38,  3.56s/it] 93%|█████████▎| 4215/4545 [4:33:52<20:11,  3.67s/it] 93%|█████████▎| 4216/4545 [4:33:55<19:48,  3.61s/it] 93%|█████████▎| 4217/4545 [4:33:59<20:09,  3.69s/it] 93%|█████████▎| 4218/4545 [4:34:03<19:43,  3.62s/it] 93%|█████████▎| 4219/4545 [4:34:06<18:27,  3.40s/it] 93%|█████████▎| 4220/4545 [4:34:10<19:16,  3.56s/it]                                                     {'loss': 0.3241, 'grad_norm': 27.377567291259766, 'learning_rate': 1.2544541843173678e-08, 'rewards/chosen': 0.7284911870956421, 'rewards/rejected': -2.987499952316284, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.7203125953674316, 'logps/chosen': -179.39999389648438, 'logps/rejected': -135.0, 'logits/chosen': -8.006250381469727, 'logits/rejected': -7.40625, 'epoch': 2.79}
 93%|█████████▎| 4220/4545 [4:34:10<19:16,  3.56s/it] 93%|█████████▎| 4221/4545 [4:34:14<19:48,  3.67s/it] 93%|█████████▎| 4222/4545 [4:34:18<20:29,  3.81s/it] 93%|█████████▎| 4223/4545 [4:34:22<20:41,  3.86s/it] 93%|█████████▎| 4224/4545 [4:34:26<20:45,  3.88s/it] 93%|█████████▎| 4225/4545 [4:34:29<20:45,  3.89s/it] 93%|█████████▎| 4226/4545 [4:34:33<20:47,  3.91s/it] 93%|█████████▎| 4227/4545 [4:34:37<20:21,  3.84s/it] 93%|█████████▎| 4228/4545 [4:34:41<20:21,  3.85s/it] 93%|█████████▎| 4229/4545 [4:34:45<20:23,  3.87s/it] 93%|█████████▎| 4230/4545 [4:34:48<19:33,  3.72s/it]                                                     {'loss': 0.2877, 'grad_norm': 36.41217803955078, 'learning_rate': 1.2392206335208627e-08, 'rewards/chosen': 0.8904083371162415, 'rewards/rejected': -3.1031250953674316, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.9921875, 'logps/chosen': -230.64999389648438, 'logps/rejected': -152.1750030517578, 'logits/chosen': -7.865624904632568, 'logits/rejected': -7.328125, 'epoch': 2.79}
 93%|█████████▎| 4230/4545 [4:34:48<19:33,  3.72s/it] 93%|█████████▎| 4231/4545 [4:34:52<19:49,  3.79s/it] 93%|█████████▎| 4232/4545 [4:34:56<20:09,  3.86s/it] 93%|█████████▎| 4233/4545 [4:35:00<20:09,  3.88s/it] 93%|█████████▎| 4234/4545 [4:35:04<20:35,  3.97s/it] 93%|█████████▎| 4235/4545 [4:35:08<20:26,  3.96s/it] 93%|█████████▎| 4236/4545 [4:35:12<20:17,  3.94s/it] 93%|█████████▎| 4237/4545 [4:35:16<19:30,  3.80s/it] 93%|█████████▎| 4238/4545 [4:35:20<19:41,  3.85s/it] 93%|█████████▎| 4239/4545 [4:35:22<17:55,  3.51s/it] 93%|█████████▎| 4240/4545 [4:35:27<18:54,  3.72s/it]                                                     {'loss': 0.3288, 'grad_norm': 31.251317977905273, 'learning_rate': 1.2244448165746961e-08, 'rewards/chosen': 1.156225562095642, 'rewards/rejected': -2.952343702316284, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 4.109375, 'logps/chosen': -277.79998779296875, 'logps/rejected': -200.35000610351562, 'logits/chosen': -7.790625095367432, 'logits/rejected': -7.387499809265137, 'epoch': 2.8}
 93%|█████████▎| 4240/4545 [4:35:27<18:54,  3.72s/it] 93%|█████████▎| 4241/4545 [4:35:30<18:47,  3.71s/it] 93%|█████████▎| 4242/4545 [4:35:34<18:38,  3.69s/it] 93%|█████████▎| 4243/4545 [4:35:38<18:56,  3.76s/it] 93%|█████████▎| 4244/4545 [4:35:42<19:06,  3.81s/it] 93%|█████████▎| 4245/4545 [4:35:46<19:33,  3.91s/it] 93%|█████████▎| 4246/4545 [4:35:50<19:29,  3.91s/it] 93%|█████████▎| 4247/4545 [4:35:54<19:25,  3.91s/it] 93%|█████████▎| 4248/4545 [4:35:57<18:59,  3.84s/it] 93%|█████████▎| 4249/4545 [4:36:01<19:17,  3.91s/it] 94%|█████████▎| 4250/4545 [4:36:05<19:13,  3.91s/it]                                                     {'loss': 0.2504, 'grad_norm': 17.61684799194336, 'learning_rate': 1.210128320839068e-08, 'rewards/chosen': 2.7698395252227783, 'rewards/rejected': -2.1700196266174316, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.939062595367432, 'logps/chosen': -478.75, 'logps/rejected': -244.14999389648438, 'logits/chosen': -7.65625, 'logits/rejected': -7.331250190734863, 'epoch': 2.81}
 94%|█████████▎| 4250/4545 [4:36:05<19:13,  3.91s/it] 94%|█████████▎| 4251/4545 [4:36:09<19:25,  3.96s/it] 94%|█████████▎| 4252/4545 [4:36:13<19:17,  3.95s/it] 94%|█████████▎| 4253/4545 [4:36:17<19:10,  3.94s/it] 94%|█████████▎| 4254/4545 [4:36:21<19:25,  4.00s/it] 94%|█████████▎| 4255/4545 [4:36:25<18:50,  3.90s/it] 94%|█████████▎| 4256/4545 [4:36:29<18:50,  3.91s/it] 94%|█████████▎| 4257/4545 [4:36:33<18:14,  3.80s/it] 94%|█████████▎| 4258/4545 [4:36:36<18:14,  3.81s/it] 94%|█████████▎| 4259/4545 [4:36:40<18:20,  3.85s/it] 94%|█████████▎| 4260/4545 [4:36:43<16:06,  3.39s/it]                                                     {'loss': 0.2821, 'grad_norm': 11.586894989013672, 'learning_rate': 1.196272684329479e-08, 'rewards/chosen': 1.391210913658142, 'rewards/rejected': -2.277905225753784, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.672656297683716, 'logps/chosen': -289.29998779296875, 'logps/rejected': -189.10000610351562, 'logits/chosen': -7.868750095367432, 'logits/rejected': -7.446875095367432, 'epoch': 2.81}
 94%|█████████▎| 4260/4545 [4:36:43<16:06,  3.39s/it] 94%|█████████▍| 4261/4545 [4:36:47<17:13,  3.64s/it] 94%|█████████▍| 4262/4545 [4:36:51<17:33,  3.72s/it] 94%|█████████▍| 4263/4545 [4:36:54<17:07,  3.64s/it] 94%|█████████▍| 4264/4545 [4:36:58<17:28,  3.73s/it] 94%|█████████▍| 4265/4545 [4:37:01<16:43,  3.58s/it] 94%|█████████▍| 4266/4545 [4:37:06<17:33,  3.78s/it] 94%|█████████▍| 4267/4545 [4:37:10<17:42,  3.82s/it] 94%|█████████▍| 4268/4545 [4:37:14<17:47,  3.86s/it] 94%|█████████▍| 4269/4545 [4:37:17<17:14,  3.75s/it] 94%|█████████▍| 4270/4545 [4:37:21<17:50,  3.89s/it]                                                     {'loss': 0.3237, 'grad_norm': 21.96576499938965, 'learning_rate': 1.1828793955515074e-08, 'rewards/chosen': 1.6734405755996704, 'rewards/rejected': -1.7664062976837158, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.442187547683716, 'logps/chosen': -321.1499938964844, 'logps/rejected': -217.1750030517578, 'logits/chosen': -7.709374904632568, 'logits/rejected': -7.306250095367432, 'epoch': 2.82}
 94%|█████████▍| 4270/4545 [4:37:21<17:50,  3.89s/it] 94%|█████████▍| 4271/4545 [4:37:25<17:49,  3.90s/it] 94%|█████████▍| 4272/4545 [4:37:28<16:09,  3.55s/it] 94%|█████████▍| 4273/4545 [4:37:31<15:49,  3.49s/it] 94%|█████████▍| 4274/4545 [4:37:34<15:20,  3.40s/it] 94%|█████████▍| 4275/4545 [4:37:38<16:00,  3.56s/it] 94%|█████████▍| 4276/4545 [4:37:42<16:07,  3.60s/it] 94%|█████████▍| 4277/4545 [4:37:44<13:45,  3.08s/it] 94%|█████████▍| 4278/4545 [4:37:48<14:49,  3.33s/it] 94%|█████████▍| 4279/4545 [4:37:51<14:42,  3.32s/it] 94%|█████████▍| 4280/4545 [4:37:55<15:28,  3.51s/it]                                                     {'loss': 0.2343, 'grad_norm': 18.090496063232422, 'learning_rate': 1.1699498933408943e-08, 'rewards/chosen': 1.1664917469024658, 'rewards/rejected': -2.7484374046325684, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 3.910937547683716, 'logps/chosen': -230.64999389648438, 'logps/rejected': -150.5500030517578, 'logits/chosen': -7.887499809265137, 'logits/rejected': -7.425000190734863, 'epoch': 2.83}
 94%|█████████▍| 4280/4545 [4:37:55<15:28,  3.51s/it] 94%|█████████▍| 4281/4545 [4:37:59<15:58,  3.63s/it] 94%|█████████▍| 4282/4545 [4:38:03<16:24,  3.74s/it] 94%|█████████▍| 4283/4545 [4:38:07<16:34,  3.79s/it] 94%|█████████▍| 4284/4545 [4:38:10<15:41,  3.61s/it] 94%|█████████▍| 4285/4545 [4:38:14<16:00,  3.70s/it] 94%|█████████▍| 4286/4545 [4:38:17<15:29,  3.59s/it] 94%|█████████▍| 4287/4545 [4:38:20<14:50,  3.45s/it] 94%|█████████▍| 4288/4545 [4:38:24<15:23,  3.59s/it] 94%|█████████▍| 4289/4545 [4:38:28<15:48,  3.70s/it] 94%|█████████▍| 4290/4545 [4:38:32<16:11,  3.81s/it]                                                     {'loss': 0.2781, 'grad_norm': 31.239011764526367, 'learning_rate': 1.1574855667089744e-08, 'rewards/chosen': 1.164306640625, 'rewards/rejected': -2.8375000953674316, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 4.005468845367432, 'logps/chosen': -266.29998779296875, 'logps/rejected': -159.6999969482422, 'logits/chosen': -7.884375095367432, 'logits/rejected': -7.553124904632568, 'epoch': 2.83}
 94%|█████████▍| 4290/4545 [4:38:32<16:11,  3.81s/it] 94%|█████████▍| 4291/4545 [4:38:36<16:17,  3.85s/it] 94%|█████████▍| 4292/4545 [4:38:40<15:26,  3.66s/it] 94%|█████████▍| 4293/4545 [4:38:44<15:43,  3.74s/it] 94%|█████████▍| 4294/4545 [4:38:47<15:17,  3.65s/it] 94%|█████████▍| 4295/4545 [4:38:51<15:32,  3.73s/it] 95%|█████████▍| 4296/4545 [4:38:54<14:14,  3.43s/it] 95%|█████████▍| 4297/4545 [4:38:58<15:00,  3.63s/it] 95%|█████████▍| 4298/4545 [4:39:02<15:19,  3.72s/it] 95%|█████████▍| 4299/4545 [4:39:05<15:15,  3.72s/it] 95%|█████████▍| 4300/4545 [4:39:10<15:45,  3.86s/it]                                                     {'loss': 0.2759, 'grad_norm': 11.905817031860352, 'learning_rate': 1.1454877546934497e-08, 'rewards/chosen': 0.4565673768520355, 'rewards/rejected': -3.1468749046325684, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.604687452316284, 'logps/chosen': -208.25, 'logps/rejected': -152.89999389648438, 'logits/chosen': -7.800000190734863, 'logits/rejected': -7.490624904632568, 'epoch': 2.84}
 95%|█████████▍| 4300/4545 [4:39:10<15:45,  3.86s/it] 95%|█████████▍| 4301/4545 [4:39:13<15:47,  3.88s/it] 95%|█████████▍| 4302/4545 [4:39:17<15:43,  3.88s/it] 95%|█████████▍| 4303/4545 [4:39:21<15:42,  3.89s/it] 95%|█████████▍| 4304/4545 [4:39:25<15:45,  3.92s/it] 95%|█████████▍| 4305/4545 [4:39:29<15:37,  3.91s/it] 95%|█████████▍| 4306/4545 [4:39:33<15:36,  3.92s/it] 95%|█████████▍| 4307/4545 [4:39:37<15:33,  3.92s/it] 95%|█████████▍| 4308/4545 [4:39:39<13:42,  3.47s/it] 95%|█████████▍| 4309/4545 [4:39:43<14:11,  3.61s/it] 95%|█████████▍| 4310/4545 [4:39:47<13:49,  3.53s/it]                                                     {'loss': 0.2942, 'grad_norm': 23.357637405395508, 'learning_rate': 1.133957746214545e-08, 'rewards/chosen': 1.817773461341858, 'rewards/rejected': -2.5621094703674316, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.377343654632568, 'logps/chosen': -384.8999938964844, 'logps/rejected': -205.39999389648438, 'logits/chosen': -7.503125190734863, 'logits/rejected': -7.256249904632568, 'epoch': 2.84}
 95%|█████████▍| 4310/4545 [4:39:47<13:49,  3.53s/it] 95%|█████████▍| 4311/4545 [4:39:51<14:33,  3.73s/it] 95%|█████████▍| 4312/4545 [4:39:53<13:01,  3.35s/it] 95%|█████████▍| 4313/4545 [4:39:57<13:36,  3.52s/it] 95%|█████████▍| 4314/4545 [4:40:01<14:18,  3.72s/it] 95%|█████████▍| 4315/4545 [4:40:05<14:29,  3.78s/it] 95%|█████████▍| 4316/4545 [4:40:09<13:50,  3.63s/it] 95%|█████████▍| 4317/4545 [4:40:13<14:09,  3.72s/it] 95%|█████████▌| 4318/4545 [4:40:16<13:59,  3.70s/it] 95%|█████████▌| 4319/4545 [4:40:20<14:11,  3.77s/it] 95%|█████████▌| 4320/4545 [4:40:23<12:36,  3.36s/it]                                                     {'loss': 0.3603, 'grad_norm': 29.93014144897461, 'learning_rate': 1.1228967799365325e-08, 'rewards/chosen': 1.875244140625, 'rewards/rejected': -1.4132812023162842, 'rewards/accuracies': 0.8125, 'rewards/margins': 3.2890625, 'logps/chosen': -346.3999938964844, 'logps/rejected': -234.25, 'logits/chosen': -7.731249809265137, 'logits/rejected': -7.484375, 'epoch': 2.85}
 95%|█████████▌| 4320/4545 [4:40:23<12:36,  3.36s/it] 95%|█████████▌| 4321/4545 [4:40:27<13:17,  3.56s/it] 95%|█████████▌| 4322/4545 [4:40:31<13:40,  3.68s/it] 95%|█████████▌| 4323/4545 [4:40:35<13:52,  3.75s/it] 95%|█████████▌| 4324/4545 [4:40:39<14:18,  3.88s/it] 95%|█████████▌| 4325/4545 [4:40:42<13:34,  3.70s/it] 95%|█████████▌| 4326/4545 [4:40:45<13:07,  3.60s/it] 95%|█████████▌| 4327/4545 [4:40:49<13:11,  3.63s/it] 95%|█████████▌| 4328/4545 [4:40:53<13:27,  3.72s/it] 95%|█████████▌| 4329/4545 [4:40:57<13:35,  3.78s/it] 95%|█████████▌| 4330/4545 [4:41:01<13:42,  3.82s/it]                                                     {'loss': 0.3223, 'grad_norm': 12.044281005859375, 'learning_rate': 1.1123060441346647e-08, 'rewards/chosen': 1.0531829595565796, 'rewards/rejected': -2.477343797683716, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.532031297683716, 'logps/chosen': -229.85000610351562, 'logps/rejected': -178.14999389648438, 'logits/chosen': -7.946875095367432, 'logits/rejected': -7.540625095367432, 'epoch': 2.86}
 95%|█████████▌| 4330/4545 [4:41:01<13:42,  3.82s/it] 95%|█████████▌| 4331/4545 [4:41:03<12:09,  3.41s/it] 95%|█████████▌| 4332/4545 [4:41:07<12:51,  3.62s/it] 95%|█████████▌| 4333/4545 [4:41:11<13:07,  3.72s/it] 95%|█████████▌| 4334/4545 [4:41:14<11:43,  3.34s/it] 95%|█████████▌| 4335/4545 [4:41:17<12:03,  3.45s/it] 95%|█████████▌| 4336/4545 [4:41:21<12:33,  3.61s/it] 95%|█████████▌| 4337/4545 [4:41:25<12:49,  3.70s/it] 95%|█████████▌| 4338/4545 [4:41:28<12:01,  3.48s/it] 95%|█████████▌| 4339/4545 [4:41:31<11:29,  3.35s/it] 95%|█████████▌| 4340/4545 [4:41:35<12:06,  3.54s/it]                                                     {'loss': 0.378, 'grad_norm': 19.048059463500977, 'learning_rate': 1.1021866765675219e-08, 'rewards/chosen': 1.513220191001892, 'rewards/rejected': -2.743359327316284, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 4.256249904632568, 'logps/chosen': -318.54998779296875, 'logps/rejected': -209.4499969482422, 'logits/chosen': -7.893750190734863, 'logits/rejected': -7.390625, 'epoch': 2.86}
 95%|█████████▌| 4340/4545 [4:41:35<12:06,  3.54s/it] 96%|█████████▌| 4341/4545 [4:41:39<12:21,  3.64s/it] 96%|█████████▌| 4342/4545 [4:41:43<12:37,  3.73s/it] 96%|█████████▌| 4343/4545 [4:41:47<12:10,  3.62s/it] 96%|█████████▌| 4344/4545 [4:41:50<12:25,  3.71s/it] 96%|█████████▌| 4345/4545 [4:41:54<12:23,  3.72s/it] 96%|█████████▌| 4346/4545 [4:41:58<12:30,  3.77s/it] 96%|█████████▌| 4347/4545 [4:42:02<12:42,  3.85s/it] 96%|█████████▌| 4348/4545 [4:42:06<12:41,  3.86s/it] 96%|█████████▌| 4349/4545 [4:42:10<12:39,  3.88s/it] 96%|█████████▌| 4350/4545 [4:42:14<12:39,  3.89s/it]                                                     {'loss': 0.3004, 'grad_norm': 17.558574676513672, 'learning_rate': 1.0925397643547785e-08, 'rewards/chosen': 1.5411376953125, 'rewards/rejected': -2.8460936546325684, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.385937690734863, 'logps/chosen': -321.04998779296875, 'logps/rejected': -190.39999389648438, 'logits/chosen': -7.771874904632568, 'logits/rejected': -7.371874809265137, 'epoch': 2.87}
 96%|█████████▌| 4350/4545 [4:42:14<12:39,  3.89s/it] 96%|█████████▌| 4351/4545 [4:42:17<12:03,  3.73s/it] 96%|█████████▌| 4352/4545 [4:42:20<11:18,  3.51s/it] 96%|█████████▌| 4353/4545 [4:42:24<11:37,  3.63s/it] 96%|█████████▌| 4354/4545 [4:42:28<12:03,  3.79s/it] 96%|█████████▌| 4355/4545 [4:42:31<10:38,  3.36s/it] 96%|█████████▌| 4356/4545 [4:42:34<10:09,  3.23s/it] 96%|█████████▌| 4357/4545 [4:42:37<10:23,  3.32s/it] 96%|█████████▌| 4358/4545 [4:42:40<10:10,  3.27s/it] 96%|█████████▌| 4359/4545 [4:42:44<10:25,  3.36s/it] 96%|█████████▌| 4360/4545 [4:42:48<11:01,  3.58s/it]                                                     {'loss': 0.2721, 'grad_norm': 9.47694206237793, 'learning_rate': 1.083366343860416e-08, 'rewards/chosen': 0.9384765625, 'rewards/rejected': -2.150390625, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.0914063453674316, 'logps/chosen': -207.0500030517578, 'logps/rejected': -181.60000610351562, 'logits/chosen': -7.962500095367432, 'logits/rejected': -7.571875095367432, 'epoch': 2.88}
 96%|█████████▌| 4360/4545 [4:42:48<11:01,  3.58s/it] 96%|█████████▌| 4361/4545 [4:42:52<11:18,  3.69s/it] 96%|█████████▌| 4362/4545 [4:42:56<11:26,  3.75s/it] 96%|█████████▌| 4363/4545 [4:42:58<10:23,  3.42s/it] 96%|█████████▌| 4364/4545 [4:43:02<10:36,  3.52s/it] 96%|█████████▌| 4365/4545 [4:43:06<11:01,  3.67s/it] 96%|█████████▌| 4366/4545 [4:43:10<11:00,  3.69s/it] 96%|█████████▌| 4367/4545 [4:43:14<11:09,  3.76s/it] 96%|█████████▌| 4368/4545 [4:43:18<11:12,  3.80s/it] 96%|█████████▌| 4369/4545 [4:43:21<10:26,  3.56s/it] 96%|█████████▌| 4370/4545 [4:43:25<10:42,  3.67s/it]                                                     {'loss': 0.3059, 'grad_norm': 41.199398040771484, 'learning_rate': 1.0746674005813887e-08, 'rewards/chosen': 1.340185523033142, 'rewards/rejected': -2.271191358566284, 'rewards/accuracies': 0.875, 'rewards/margins': 3.609375, 'logps/chosen': -279.5, 'logps/rejected': -165.14999389648438, 'logits/chosen': -7.821875095367432, 'logits/rejected': -7.465624809265137, 'epoch': 2.88}
 96%|█████████▌| 4370/4545 [4:43:25<10:42,  3.67s/it] 96%|█████████▌| 4371/4545 [4:43:29<10:52,  3.75s/it] 96%|█████████▌| 4372/4545 [4:43:32<10:44,  3.73s/it] 96%|█████████▌| 4373/4545 [4:43:36<11:05,  3.87s/it] 96%|█████████▌| 4374/4545 [4:43:40<10:56,  3.84s/it] 96%|█████████▋| 4375/4545 [4:43:44<10:56,  3.86s/it] 96%|█████████▋| 4376/4545 [4:43:48<10:41,  3.80s/it] 96%|█████████▋| 4377/4545 [4:43:52<10:51,  3.88s/it] 96%|█████████▋| 4378/4545 [4:43:56<10:49,  3.89s/it] 96%|█████████▋| 4379/4545 [4:44:00<10:47,  3.90s/it] 96%|█████████▋| 4380/4545 [4:44:02<09:38,  3.51s/it]                                                     {'loss': 0.288, 'grad_norm': 19.241281509399414, 'learning_rate': 1.0664438690417481e-08, 'rewards/chosen': 1.487634301185608, 'rewards/rejected': -2.3037109375, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.7914061546325684, 'logps/chosen': -310.29998779296875, 'logps/rejected': -206.1999969482422, 'logits/chosen': -7.743750095367432, 'logits/rejected': -7.503125190734863, 'epoch': 2.89}
 96%|█████████▋| 4380/4545 [4:44:02<09:38,  3.51s/it] 96%|█████████▋| 4381/4545 [4:44:06<09:48,  3.59s/it] 96%|█████████▋| 4382/4545 [4:44:10<10:06,  3.72s/it] 96%|█████████▋| 4383/4545 [4:44:14<10:12,  3.78s/it] 96%|█████████▋| 4384/4545 [4:44:18<10:31,  3.92s/it] 96%|█████████▋| 4385/4545 [4:44:22<10:27,  3.92s/it] 97%|█████████▋| 4386/4545 [4:44:26<10:23,  3.92s/it] 97%|█████████▋| 4387/4545 [4:44:30<10:17,  3.91s/it] 97%|█████████▋| 4388/4545 [4:44:34<10:02,  3.84s/it] 97%|█████████▋| 4389/4545 [4:44:37<09:38,  3.71s/it] 97%|█████████▋| 4390/4545 [4:44:41<09:44,  3.77s/it]                                                     {'loss': 0.2971, 'grad_norm': 18.259185791015625, 'learning_rate': 1.0586966326922517e-08, 'rewards/chosen': 2.1854004859924316, 'rewards/rejected': -2.7640624046325684, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.953906059265137, 'logps/chosen': -393.8999938964844, 'logps/rejected': -203.6999969482422, 'logits/chosen': -7.693749904632568, 'logits/rejected': -7.253125190734863, 'epoch': 2.9}
 97%|█████████▋| 4390/4545 [4:44:41<09:44,  3.77s/it] 97%|█████████▋| 4391/4545 [4:44:44<09:03,  3.53s/it] 97%|█████████▋| 4392/4545 [4:44:48<09:04,  3.56s/it] 97%|█████████▋| 4393/4545 [4:44:51<09:17,  3.67s/it] 97%|█████████▋| 4394/4545 [4:44:55<09:25,  3.75s/it] 97%|█████████▋| 4395/4545 [4:44:58<08:46,  3.51s/it] 97%|█████████▋| 4396/4545 [4:45:03<09:16,  3.73s/it] 97%|█████████▋| 4397/4545 [4:45:07<09:19,  3.78s/it] 97%|█████████▋| 4398/4545 [4:45:10<08:58,  3.67s/it] 97%|█████████▋| 4399/4545 [4:45:14<09:03,  3.72s/it] 97%|█████████▋| 4400/4545 [4:45:18<09:04,  3.75s/it]                                                     {'loss': 0.262, 'grad_norm': 23.937047958374023, 'learning_rate': 1.051426523815451e-08, 'rewards/chosen': 0.8766723871231079, 'rewards/rejected': -2.8671875, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.73828125, 'logps/chosen': -233.5, 'logps/rejected': -153.64999389648438, 'logits/chosen': -7.831250190734863, 'logits/rejected': -7.334374904632568, 'epoch': 2.9}
 97%|█████████▋| 4400/4545 [4:45:18<09:04,  3.75s/it] 97%|█████████▋| 4401/4545 [4:45:21<09:02,  3.77s/it] 97%|█████████▋| 4402/4545 [4:45:25<09:06,  3.82s/it] 97%|█████████▋| 4403/4545 [4:45:30<09:16,  3.92s/it] 97%|█████████▋| 4404/4545 [4:45:32<08:24,  3.58s/it] 97%|█████████▋| 4405/4545 [4:45:36<08:30,  3.65s/it] 97%|█████████▋| 4406/4545 [4:45:40<08:39,  3.74s/it] 97%|█████████▋| 4407/4545 [4:45:44<08:38,  3.76s/it] 97%|█████████▋| 4408/4545 [4:45:48<08:41,  3.81s/it] 97%|█████████▋| 4409/4545 [4:45:52<08:42,  3.84s/it] 97%|█████████▋| 4410/4545 [4:45:56<08:54,  3.96s/it]                                                     {'loss': 0.258, 'grad_norm': 15.459403991699219, 'learning_rate': 1.04463432343628e-08, 'rewards/chosen': 1.2502120733261108, 'rewards/rejected': -2.896484375, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.140625, 'logps/chosen': -299.5, 'logps/rejected': -168.5500030517578, 'logits/chosen': -7.731249809265137, 'logits/rejected': -7.474999904632568, 'epoch': 2.91}
 97%|█████████▋| 4410/4545 [4:45:56<08:54,  3.96s/it] 97%|█████████▋| 4411/4545 [4:45:59<08:31,  3.82s/it] 97%|█████████▋| 4412/4545 [4:46:02<07:46,  3.51s/it] 97%|█████████▋| 4413/4545 [4:46:05<07:22,  3.35s/it] 97%|█████████▋| 4414/4545 [4:46:09<07:45,  3.56s/it] 97%|█████████▋| 4415/4545 [4:46:13<07:57,  3.68s/it] 97%|█████████▋| 4416/4545 [4:46:16<07:34,  3.52s/it] 97%|█████████▋| 4417/4545 [4:46:20<07:35,  3.56s/it] 97%|█████████▋| 4418/4545 [4:46:24<07:46,  3.68s/it] 97%|█████████▋| 4419/4545 [4:46:28<07:52,  3.75s/it] 97%|█████████▋| 4420/4545 [4:46:32<07:55,  3.80s/it]                                                     {'loss': 0.2264, 'grad_norm': 15.148118019104004, 'learning_rate': 1.0383207612381542e-08, 'rewards/chosen': 1.3523743152618408, 'rewards/rejected': -3.1890625953674316, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.5390625, 'logps/chosen': -277.25, 'logps/rejected': -148.3000030517578, 'logits/chosen': -7.737500190734863, 'logits/rejected': -7.318749904632568, 'epoch': 2.92}
 97%|█████████▋| 4420/4545 [4:46:32<07:55,  3.80s/it] 97%|█████████▋| 4421/4545 [4:46:36<08:03,  3.90s/it] 97%|█████████▋| 4422/4545 [4:46:40<08:00,  3.90s/it] 97%|█████████▋| 4423/4545 [4:46:42<07:09,  3.52s/it] 97%|█████████▋| 4424/4545 [4:46:47<07:25,  3.68s/it] 97%|█████████▋| 4425/4545 [4:46:50<07:29,  3.75s/it] 97%|█████████▋| 4426/4545 [4:46:54<07:32,  3.80s/it] 97%|█████████▋| 4427/4545 [4:46:58<07:32,  3.83s/it] 97%|█████████▋| 4428/4545 [4:47:01<06:52,  3.52s/it] 97%|█████████▋| 4429/4545 [4:47:05<07:13,  3.74s/it] 97%|█████████▋| 4430/4545 [4:47:09<07:10,  3.75s/it]                                                     {'loss': 0.3393, 'grad_norm': 18.353504180908203, 'learning_rate': 1.0324865154845744e-08, 'rewards/chosen': 1.7575194835662842, 'rewards/rejected': -2.700000047683716, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.458593845367432, 'logps/chosen': -369.95001220703125, 'logps/rejected': -244.5500030517578, 'logits/chosen': -7.696875095367432, 'logits/rejected': -7.59375, 'epoch': 2.92}
 97%|█████████▋| 4430/4545 [4:47:09<07:10,  3.75s/it] 97%|█████████▋| 4431/4545 [4:47:13<07:13,  3.80s/it] 98%|█████████▊| 4432/4545 [4:47:17<07:11,  3.82s/it] 98%|█████████▊| 4433/4545 [4:47:21<07:13,  3.87s/it] 98%|█████████▊| 4434/4545 [4:47:25<07:11,  3.89s/it] 98%|█████████▊| 4435/4545 [4:47:29<07:08,  3.90s/it] 98%|█████████▊| 4436/4545 [4:47:33<07:05,  3.90s/it] 98%|█████████▊| 4437/4545 [4:47:37<07:07,  3.95s/it] 98%|█████████▊| 4438/4545 [4:47:41<07:07,  4.00s/it] 98%|█████████▊| 4439/4545 [4:47:45<07:01,  3.98s/it] 98%|█████████▊| 4440/4545 [4:47:49<07:03,  4.03s/it]                                                     {'loss': 0.2701, 'grad_norm': 16.330577850341797, 'learning_rate': 1.0271322129462656e-08, 'rewards/chosen': 2.273730516433716, 'rewards/rejected': -1.983789086341858, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.259375095367432, 'logps/chosen': -407.6499938964844, 'logps/rejected': -290.5, 'logits/chosen': -7.550000190734863, 'logits/rejected': -7.371874809265137, 'epoch': 2.93}
 98%|█████████▊| 4440/4545 [4:47:49<07:03,  4.03s/it] 98%|█████████▊| 4441/4545 [4:47:53<06:48,  3.93s/it] 98%|█████████▊| 4442/4545 [4:47:56<06:40,  3.89s/it] 98%|█████████▊| 4443/4545 [4:48:00<06:25,  3.78s/it] 98%|█████████▊| 4444/4545 [4:48:04<06:33,  3.89s/it] 98%|█████████▊| 4445/4545 [4:48:08<06:29,  3.90s/it] 98%|█████████▊| 4446/4545 [4:48:12<06:28,  3.92s/it] 98%|█████████▊| 4447/4545 [4:48:15<05:47,  3.55s/it] 98%|█████████▊| 4448/4545 [4:48:18<05:53,  3.64s/it] 98%|█████████▊| 4449/4545 [4:48:22<05:41,  3.56s/it] 98%|█████████▊| 4450/4545 [4:48:26<05:49,  3.68s/it]                                                     {'loss': 0.3802, 'grad_norm': 22.301990509033203, 'learning_rate': 1.0222584288338424e-08, 'rewards/chosen': 0.853564441204071, 'rewards/rejected': -2.72265625, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 3.5765624046325684, 'logps/chosen': -229.3000030517578, 'logps/rejected': -148.9499969482422, 'logits/chosen': -7.981249809265137, 'logits/rejected': -7.571875095367432, 'epoch': 2.94}
 98%|█████████▊| 4450/4545 [4:48:26<05:49,  3.68s/it] 98%|█████████▊| 4451/4545 [4:48:30<05:59,  3.83s/it] 98%|█████████▊| 4452/4545 [4:48:33<05:30,  3.55s/it] 98%|█████████▊| 4453/4545 [4:48:37<05:36,  3.66s/it] 98%|█████████▊| 4454/4545 [4:48:41<05:39,  3.73s/it] 98%|█████████▊| 4455/4545 [4:48:45<05:41,  3.80s/it] 98%|█████████▊| 4456/4545 [4:48:49<05:41,  3.83s/it] 98%|█████████▊| 4457/4545 [4:48:52<05:28,  3.73s/it] 98%|█████████▊| 4458/4545 [4:48:56<05:38,  3.89s/it] 98%|█████████▊| 4459/4545 [4:49:00<05:35,  3.90s/it] 98%|█████████▊| 4460/4545 [4:49:04<05:30,  3.89s/it]                                                     {'loss': 0.3046, 'grad_norm': 18.250080108642578, 'learning_rate': 1.0178656867360132e-08, 'rewards/chosen': 1.722412109375, 'rewards/rejected': -2.2345213890075684, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.953125, 'logps/chosen': -337.79998779296875, 'logps/rejected': -229.14999389648438, 'logits/chosen': -7.928124904632568, 'logits/rejected': -7.409375190734863, 'epoch': 2.94}
 98%|█████████▊| 4460/4545 [4:49:04<05:30,  3.89s/it] 98%|█████████▊| 4461/4545 [4:49:08<05:28,  3.91s/it] 98%|█████████▊| 4462/4545 [4:49:12<05:25,  3.92s/it] 98%|█████████▊| 4463/4545 [4:49:16<05:28,  4.01s/it] 98%|█████████▊| 4464/4545 [4:49:20<05:08,  3.81s/it] 98%|█████████▊| 4465/4545 [4:49:23<04:57,  3.72s/it] 98%|█████████▊| 4466/4545 [4:49:27<04:54,  3.73s/it] 98%|█████████▊| 4467/4545 [4:49:30<04:47,  3.69s/it] 98%|█████████▊| 4468/4545 [4:49:34<04:53,  3.81s/it] 98%|█████████▊| 4469/4545 [4:49:38<04:51,  3.83s/it] 98%|█████████▊| 4470/4545 [4:49:42<04:49,  3.86s/it]                                                     {'loss': 0.2389, 'grad_norm': 11.803092002868652, 'learning_rate': 1.0139544585633334e-08, 'rewards/chosen': 1.565789818763733, 'rewards/rejected': -3.3675780296325684, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.930468559265137, 'logps/chosen': -342.25, 'logps/rejected': -196.3000030517578, 'logits/chosen': -7.778124809265137, 'logits/rejected': -7.400000095367432, 'epoch': 2.95}
 98%|█████████▊| 4470/4545 [4:49:42<04:49,  3.86s/it] 98%|█████████▊| 4471/4545 [4:49:46<04:46,  3.87s/it] 98%|█████████▊| 4472/4545 [4:49:50<04:43,  3.88s/it] 98%|█████████▊| 4473/4545 [4:49:53<04:23,  3.66s/it] 98%|█████████▊| 4474/4545 [4:49:57<04:25,  3.74s/it] 98%|█████████▊| 4475/4545 [4:50:01<04:25,  3.79s/it] 98%|█████████▊| 4476/4545 [4:50:04<04:01,  3.49s/it] 99%|█████████▊| 4477/4545 [4:50:07<03:45,  3.31s/it] 99%|█████████▊| 4478/4545 [4:50:11<03:51,  3.46s/it] 99%|█████████▊| 4479/4545 [4:50:15<03:59,  3.63s/it] 99%|█████████▊| 4480/4545 [4:50:18<03:43,  3.43s/it]                                                     {'loss': 0.3279, 'grad_norm': 13.952925682067871, 'learning_rate': 1.0105251644975057e-08, 'rewards/chosen': 1.2603271007537842, 'rewards/rejected': -2.4339842796325684, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.6976561546325684, 'logps/chosen': -273.29998779296875, 'logps/rejected': -218.14999389648438, 'logits/chosen': -7.643750190734863, 'logits/rejected': -7.21875, 'epoch': 2.96}
 99%|█████████▊| 4480/4545 [4:50:18<03:43,  3.43s/it] 99%|█████████▊| 4481/4545 [4:50:21<03:48,  3.58s/it] 99%|█████████▊| 4482/4545 [4:50:25<03:51,  3.68s/it] 99%|█████████▊| 4483/4545 [4:50:29<03:52,  3.75s/it] 99%|█████████▊| 4484/4545 [4:50:33<03:51,  3.79s/it] 99%|█████████▊| 4485/4545 [4:50:37<03:50,  3.84s/it] 99%|█████████▊| 4486/4545 [4:50:41<03:50,  3.90s/it] 99%|█████████▊| 4487/4545 [4:50:44<03:35,  3.71s/it] 99%|█████████▊| 4488/4545 [4:50:49<03:40,  3.87s/it] 99%|█████████▉| 4489/4545 [4:50:52<03:27,  3.71s/it] 99%|█████████▉| 4490/4545 [4:50:56<03:30,  3.83s/it]                                                     {'loss': 0.3094, 'grad_norm': 18.85895538330078, 'learning_rate': 1.0075781729462413e-08, 'rewards/chosen': 1.409643530845642, 'rewards/rejected': -2.952343702316284, 'rewards/accuracies': 0.875, 'rewards/margins': 4.364062309265137, 'logps/chosen': -321.29998779296875, 'logps/rejected': -188.0, 'logits/chosen': -7.768750190734863, 'logits/rejected': -7.143750190734863, 'epoch': 2.96}
 99%|█████████▉| 4490/4545 [4:50:56<03:30,  3.83s/it] 99%|█████████▉| 4491/4545 [4:51:00<03:27,  3.85s/it] 99%|█████████▉| 4492/4545 [4:51:03<03:07,  3.53s/it] 99%|█████████▉| 4493/4545 [4:51:07<03:06,  3.59s/it] 99%|█████████▉| 4494/4545 [4:51:09<02:52,  3.37s/it] 99%|█████████▉| 4495/4545 [4:51:13<02:56,  3.54s/it] 99%|█████████▉| 4496/4545 [4:51:17<02:54,  3.57s/it] 99%|█████████▉| 4497/4545 [4:51:21<02:56,  3.67s/it] 99%|█████████▉| 4498/4545 [4:51:25<02:56,  3.76s/it] 99%|█████████▉| 4499/4545 [4:51:29<02:54,  3.80s/it] 99%|█████████▉| 4500/4545 [4:51:32<02:43,  3.62s/it]                                                     {'loss': 0.2995, 'grad_norm': 21.553770065307617, 'learning_rate': 1.0051138005036843e-08, 'rewards/chosen': 1.49224853515625, 'rewards/rejected': -2.8460936546325684, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.342187404632568, 'logps/chosen': -342.04998779296875, 'logps/rejected': -165.85000610351562, 'logits/chosen': -7.637499809265137, 'logits/rejected': -7.456250190734863, 'epoch': 2.97}
 99%|█████████▉| 4500/4545 [4:51:32<02:43,  3.62s/it] 99%|█████████▉| 4501/4545 [4:51:35<02:34,  3.51s/it] 99%|█████████▉| 4502/4545 [4:51:38<02:24,  3.35s/it] 99%|█████████▉| 4503/4545 [4:51:41<02:17,  3.27s/it] 99%|█████████▉| 4504/4545 [4:51:45<02:22,  3.46s/it] 99%|█████████▉| 4505/4545 [4:51:49<02:23,  3.60s/it] 99%|█████████▉| 4506/4545 [4:51:52<02:11,  3.37s/it] 99%|█████████▉| 4507/4545 [4:51:56<02:13,  3.52s/it] 99%|█████████▉| 4508/4545 [4:52:00<02:14,  3.64s/it] 99%|█████████▉| 4509/4545 [4:52:04<02:15,  3.75s/it] 99%|█████████▉| 4510/4545 [4:52:08<02:14,  3.84s/it]                                                     {'loss': 0.2797, 'grad_norm': 20.525943756103516, 'learning_rate': 1.0031323119163944e-08, 'rewards/chosen': 1.439794898033142, 'rewards/rejected': -2.6532225608825684, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.1015625, 'logps/chosen': -300.3999938964844, 'logps/rejected': -169.9499969482422, 'logits/chosen': -7.759375095367432, 'logits/rejected': -7.46875, 'epoch': 2.98}
 99%|█████████▉| 4510/4545 [4:52:08<02:14,  3.84s/it] 99%|█████████▉| 4511/4545 [4:52:12<02:14,  3.96s/it] 99%|█████████▉| 4512/4545 [4:52:16<02:10,  3.94s/it] 99%|█████████▉| 4513/4545 [4:52:20<02:06,  3.94s/it] 99%|█████████▉| 4514/4545 [4:52:23<01:57,  3.78s/it] 99%|█████████▉| 4515/4545 [4:52:27<01:56,  3.90s/it] 99%|█████████▉| 4516/4545 [4:52:31<01:53,  3.93s/it] 99%|█████████▉| 4517/4545 [4:52:34<01:40,  3.58s/it] 99%|█████████▉| 4518/4545 [4:52:38<01:35,  3.53s/it] 99%|█████████▉| 4519/4545 [4:52:42<01:34,  3.65s/it] 99%|█████████▉| 4520/4545 [4:52:45<01:27,  3.49s/it]                                                     {'loss': 0.3032, 'grad_norm': 25.1420955657959, 'learning_rate': 1.001633920054912e-08, 'rewards/chosen': 0.955761730670929, 'rewards/rejected': -2.2699217796325684, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.225781202316284, 'logps/chosen': -248.14999389648438, 'logps/rejected': -196.3000030517578, 'logits/chosen': -7.943749904632568, 'logits/rejected': -7.537499904632568, 'epoch': 2.98}
 99%|█████████▉| 4520/4545 [4:52:45<01:27,  3.49s/it] 99%|█████████▉| 4521/4545 [4:52:48<01:21,  3.38s/it] 99%|█████████▉| 4522/4545 [4:52:52<01:23,  3.61s/it]100%|█████████▉| 4523/4545 [4:52:55<01:17,  3.51s/it]100%|█████████▉| 4524/4545 [4:52:59<01:18,  3.73s/it]100%|█████████▉| 4525/4545 [4:53:03<01:15,  3.79s/it]100%|█████████▉| 4526/4545 [4:53:07<01:12,  3.83s/it]100%|█████████▉| 4527/4545 [4:53:11<01:09,  3.84s/it]100%|█████████▉| 4528/4545 [4:53:15<01:06,  3.92s/it]100%|█████████▉| 4529/4545 [4:53:19<01:02,  3.92s/it]100%|█████████▉| 4530/4545 [4:53:23<00:58,  3.92s/it]                                                     {'loss': 0.3178, 'grad_norm': 25.715803146362305, 'learning_rate': 1.0006187858908838e-08, 'rewards/chosen': 1.510839819908142, 'rewards/rejected': -2.6216797828674316, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.134375095367432, 'logps/chosen': -323.45001220703125, 'logps/rejected': -180.9499969482422, 'logits/chosen': -7.846875190734863, 'logits/rejected': -7.331250190734863, 'epoch': 2.99}
100%|█████████▉| 4530/4545 [4:53:23<00:58,  3.92s/it]100%|█████████▉| 4531/4545 [4:53:27<00:54,  3.92s/it]100%|█████████▉| 4532/4545 [4:53:31<00:51,  3.94s/it]100%|█████████▉| 4533/4545 [4:53:35<00:47,  3.93s/it]100%|█████████▉| 4534/4545 [4:53:39<00:43,  3.92s/it]100%|█████████▉| 4535/4545 [4:53:43<00:39,  3.92s/it]100%|█████████▉| 4536/4545 [4:53:47<00:36,  4.00s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.4076147973537445, 'eval_runtime': 80.3918, 'eval_samples_per_second': 11.854, 'eval_steps_per_second': 0.746, 'eval_rewards/chosen': 1.5216501951217651, 'eval_rewards/rejected': -1.9171223640441895, 'eval_rewards/accuracies': 0.8065971732139587, 'eval_rewards/margins': 3.4370198249816895, 'eval_logps/chosen': -362.1916809082031, 'eval_logps/rejected': -171.14999389648438, 'eval_logits/chosen': -7.514583110809326, 'eval_logits/rejected': -7.839583396911621, 'epoch': 2.99}
100%|█████████▉| 4536/4545 [4:55:07<00:36,  4.00s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 4537/4545 [4:55:22<04:10, 31.31s/it]100%|█████████▉| 4538/4545 [4:55:26<02:42, 23.15s/it]100%|█████████▉| 4539/4545 [4:55:30<01:44, 17.38s/it]100%|█████████▉| 4540/4545 [4:55:34<01:07, 13.42s/it]                                                     {'loss': 0.3033, 'grad_norm': 19.691884994506836, 'learning_rate': 1.000087018479775e-08, 'rewards/chosen': 0.838183581829071, 'rewards/rejected': -2.883593797683716, 'rewards/accuracies': 0.875, 'rewards/margins': 3.7210936546325684, 'logps/chosen': -226.85000610351562, 'logps/rejected': -175.35000610351562, 'logits/chosen': -7.881249904632568, 'logits/rejected': -7.384375095367432, 'epoch': 3.0}
100%|█████████▉| 4540/4545 [4:55:34<01:07, 13.42s/it]100%|█████████▉| 4541/4545 [4:55:38<00:42, 10.57s/it]100%|█████████▉| 4542/4545 [4:55:42<00:25,  8.66s/it]100%|█████████▉| 4543/4545 [4:55:46<00:14,  7.24s/it]100%|█████████▉| 4544/4545 [4:55:50<00:06,  6.24s/it]100%|██████████| 4545/4545 [4:55:54<00:00,  5.38s/it]                                                     {'train_runtime': 17781.6441, 'train_samples_per_second': 4.087, 'train_steps_per_second': 0.256, 'train_loss': 0.4289804062565299, 'epoch': 3.0}
100%|██████████| 4545/4545 [4:56:12<00:00,  5.38s/it]100%|██████████| 4545/4545 [4:56:12<00:00,  3.91s/it]
Training complete
Saving model
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mDPO_r-64_lr-1e-07_e-3_b-0.1_63057121[0m at: [34mhttps://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/t5qe9bxf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250612_005945-t5qe9bxf/logs[0m
[rank0]:[W612 05:56:03.638564047 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 0 ---
