cpu-bind=MASK - gn01, task  0  0 [3235127]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 3
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn01
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 3     --machine_rank 0     --main_process_ip gn01     --main_process_port 29500     --num_processes 12     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_63111141     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train_curriculum.py"     --rank=64 --learning_rate=4e-7 --total_epochs=3 --beta=0.1 --curriculum_stage=1
-------------------------------------------
[2025-06-12 18:27:17,612] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0612 18:27:19.477000 3235178 torch/distributed/run.py:792] 
W0612 18:27:19.477000 3235178 torch/distributed/run.py:792] *****************************************
W0612 18:27:19.477000 3235178 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0612 18:27:19.477000 3235178 torch/distributed/run.py:792] *****************************************
[2025-06-12 18:27:57,712] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 18:27:57,724] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 18:27:57,735] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 18:27:57,744] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[load_data_curriculum.py]: Training data of type 'bad_lang_examples':    3489
[load_data_curriculum.py]: Training data of type 'short_examples':       699
[load_data_curriculum.py]: Training data of type 'choose_examples':      13379
[load_data_curriculum.py]: Training data of type 'bad_format_examples':  3148
[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *
[load_data_curriculum.py]: Evaluation data size: 953
[load_data_curriculum.py]: Curriculum stage 0 training data size: 4890
[load_data_curriculum.py]: Curriculum stage 1 training data size: 6689
[load_data_curriculum.py]: Curriculum stage 2 training data size: 6690
[load_data.py]: Training data of type 'bad_lang_examples':    5343
[load_data.py]: Training data of type 'short_examples':       699
[load_data.py]: Training data of type 'choose_examples':      13379
[load_data.py]: Training data of type 'bad_format_examples':  4806
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.1, curriculum_stage=1)
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.1, curriculum_stage=1)
4e-07
4e-07
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.1, curriculum_stage=1)
4e-07
[2025-06-12 18:28:03,943] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 18:28:03,954] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 18:28:04,030] [INFO] [comm.py:658:init_distributed] cdb=None
[load_data.py]: Number of training examples: 24227
[load_data.py]: Number of validation examples: 953
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.1, curriculum_stage=1)
4e-07
World size: 12
Setting gradient accumulation steps to: 1
Created datasets
Train dataset size: 6689
Validation dataset size: 953
Steps per epoch: 418
Evaluate each 209 steps
[2025-06-12 18:28:05,569] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 18:28:05,574] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
Loading model from:Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s] Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/trained_models/Curriculum_DPO_models/GaMS-9B-DPO-Curriculum-0
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:01, 20.56s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:02, 20.99s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:03, 21.03s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:02, 20.83s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:44<00:45, 22.57s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:44<00:45, 22.74s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:45, 22.81s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:45<00:45, 22.89s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:08<00:23, 23.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:08<00:23, 23.03s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:08<00:23, 23.10s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:08<00:22, 22.99s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:26<00:00, 21.28s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.76s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.44s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.38s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.44s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.85s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.80s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.85s/it]
Loaded model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07MTotal Parameters: 9457.78M
Total Parameters: 9457.78M

Percentage of Trainable Params: 2.2846%Trainable Parameters (LoRA): 216.07M
Trainable Parameters (LoRA): 216.07M

Percentage of Trainable Params: 2.2846%
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
[rank2]:[W612 18:29:36.039107349 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W612 18:29:36.526452600 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W612 18:29:36.606349373 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Extracting prompt in train dataset:   9%|▊         | 574/6689 [00:00<00:01, 5700.44 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1160/6689 [00:00<00:01, 3843.03 examples/s]Extracting prompt in train dataset:  24%|██▍       | 1592/6689 [00:00<00:01, 4012.69 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2126/6689 [00:00<00:01, 4460.46 examples/s]Extracting prompt in train dataset:  43%|████▎     | 2880/6689 [00:00<00:00, 4686.40 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 3460/6689 [00:00<00:00, 4098.15 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 3977/6689 [00:00<00:00, 4337.93 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 4490/6689 [00:01<00:00, 4526.05 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 5070/6689 [00:01<00:00, 4278.06 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 5520/6689 [00:01<00:00, 4314.01 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 6020/6689 [00:01<00:00, 4485.43 examples/s]Extracting prompt in train dataset: 100%|██████████| 6689/6689 [00:01<00:00, 4608.24 examples/s]Extracting prompt in train dataset: 100%|██████████| 6689/6689 [00:01<00:00, 4357.51 examples/s]
Applying chat template to train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Applying chat template to train dataset:   4%|▍         | 301/6689 [00:00<00:02, 2982.94 examples/s]Applying chat template to train dataset:  11%|█         | 715/6689 [00:00<00:02, 2824.13 examples/s]Applying chat template to train dataset:  15%|█▌        | 1021/6689 [00:00<00:01, 2913.23 examples/s]Applying chat template to train dataset:  21%|██        | 1418/6689 [00:00<00:01, 2789.54 examples/s]Applying chat template to train dataset:  27%|██▋       | 1802/6689 [00:00<00:01, 2696.65 examples/s]Applying chat template to train dataset:  33%|███▎      | 2186/6689 [00:00<00:01, 2644.70 examples/s]Applying chat template to train dataset:  37%|███▋      | 2490/6689 [00:00<00:01, 2742.08 examples/s]Applying chat template to train dataset:  42%|████▏     | 2780/6689 [00:01<00:01, 2782.89 examples/s]Applying chat template to train dataset:  46%|████▌     | 3074/6689 [00:01<00:01, 2824.26 examples/s]Applying chat template to train dataset:  52%|█████▏    | 3482/6689 [00:01<00:01, 2778.68 examples/s]Applying chat template to train dataset:  58%|█████▊    | 3861/6689 [00:01<00:01, 2689.15 examples/s]Applying chat template to train dataset:  62%|██████▏   | 4167/6689 [00:01<00:00, 2779.27 examples/s]Applying chat template to train dataset:  67%|██████▋   | 4470/6689 [00:01<00:00, 2840.96 examples/s]Applying chat template to train dataset:  72%|███████▏  | 4793/6689 [00:01<00:00, 2231.09 examples/s]Applying chat template to train dataset:  75%|███████▌  | 5044/6689 [00:01<00:00, 2292.98 examples/s]Applying chat template to train dataset:  80%|███████▉  | 5335/6689 [00:02<00:00, 2443.17 examples/s]Applying chat template to train dataset:  84%|████████▎ | 5602/6689 [00:02<00:00, 2496.59 examples/s]Applying chat template to train dataset:  88%|████████▊ | 5871/6689 [00:02<00:00, 2542.58 examples/s]Applying chat template to train dataset:  94%|█████████▎| 6263/6689 [00:02<00:00, 2567.24 examples/s]Applying chat template to train dataset:  98%|█████████▊| 6565/6689 [00:02<00:00, 2682.98 examples/s]Applying chat template to train dataset: 100%|██████████| 6689/6689 [00:02<00:00, 2630.06 examples/s]
Tokenizing train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Tokenizing train dataset:   2%|▏         | 101/6689 [00:00<00:06, 1000.43 examples/s]Tokenizing train dataset:   3%|▎         | 210/6689 [00:00<00:06, 1044.18 examples/s]Tokenizing train dataset:   5%|▍         | 325/6689 [00:00<00:10, 623.20 examples/s] Tokenizing train dataset:   6%|▋         | 420/6689 [00:00<00:08, 708.05 examples/s]Tokenizing train dataset:   8%|▊         | 525/6689 [00:00<00:12, 506.26 examples/s]Tokenizing train dataset:   9%|▉         | 622/6689 [00:00<00:10, 596.07 examples/s]Tokenizing train dataset:  11%|█         | 745/6689 [00:01<00:09, 659.86 examples/s]Tokenizing train dataset:  13%|█▎        | 859/6689 [00:01<00:08, 684.92 examples/s]Tokenizing train dataset:  14%|█▍        | 940/6689 [00:01<00:09, 576.91 examples/s]Tokenizing train dataset:  15%|█▌        | 1027/6689 [00:01<00:10, 552.50 examples/s]Tokenizing train dataset:  17%|█▋        | 1106/6689 [00:01<00:09, 598.04 examples/s]Tokenizing train dataset:  18%|█▊        | 1182/6689 [00:01<00:09, 551.85 examples/s]Tokenizing train dataset:  19%|█▉        | 1256/6689 [00:02<00:09, 590.73 examples/s]Tokenizing train dataset:  20%|█▉        | 1320/6689 [00:02<00:08, 599.88 examples/s]Tokenizing train dataset:  21%|██        | 1389/6689 [00:02<00:08, 620.67 examples/s]Tokenizing train dataset:  22%|██▏       | 1465/6689 [00:02<00:09, 571.21 examples/s]Tokenizing train dataset:  23%|██▎       | 1540/6689 [00:02<00:11, 463.04 examples/s]Tokenizing train dataset:  24%|██▍       | 1593/6689 [00:02<00:10, 476.16 examples/s]Tokenizing train dataset:  25%|██▍       | 1657/6689 [00:02<00:09, 509.67 examples/s]Tokenizing train dataset:  26%|██▌       | 1727/6689 [00:03<00:10, 451.68 examples/s]Tokenizing train dataset:  27%|██▋       | 1798/6689 [00:03<00:12, 407.08 examples/s]Tokenizing train dataset:  28%|██▊       | 1868/6689 [00:03<00:11, 417.58 examples/s]Tokenizing train dataset:  29%|██▉       | 1935/6689 [00:03<00:10, 468.14 examples/s]Tokenizing train dataset:  30%|███       | 2014/6689 [00:03<00:09, 481.01 examples/s]Tokenizing train dataset:  31%|███       | 2086/6689 [00:03<00:10, 424.97 examples/s]Tokenizing train dataset:  32%|███▏      | 2136/6689 [00:03<00:10, 435.93 examples/s]Tokenizing train dataset:  33%|███▎      | 2197/6689 [00:04<00:09, 471.62 examples/s]Tokenizing train dataset:  34%|███▎      | 2252/6689 [00:04<00:09, 489.93 examples/s]Tokenizing train dataset:  35%|███▍      | 2331/6689 [00:04<00:08, 496.58 examples/s]Tokenizing train dataset:  36%|███▌      | 2397/6689 [00:04<00:09, 472.81 examples/s]Tokenizing train dataset:  37%|███▋      | 2459/6689 [00:04<00:09, 451.49 examples/s]Tokenizing train dataset:  38%|███▊      | 2512/6689 [00:04<00:08, 465.79 examples/s]Tokenizing train dataset:  39%|███▊      | 2580/6689 [00:04<00:08, 457.45 examples/s]Tokenizing train dataset:  39%|███▉      | 2637/6689 [00:05<00:08, 481.36 examples/s]Tokenizing train dataset:  40%|████      | 2701/6689 [00:05<00:08, 458.87 examples/s]Tokenizing train dataset:  41%|████      | 2753/6689 [00:05<00:10, 382.46 examples/s]Tokenizing train dataset:  42%|████▏     | 2814/6689 [00:05<00:10, 383.13 examples/s]Tokenizing train dataset:  43%|████▎     | 2858/6689 [00:05<00:09, 394.20 examples/s]Tokenizing train dataset:  43%|████▎     | 2905/6689 [00:05<00:09, 408.43 examples/s]Tokenizing train dataset:  44%|████▍     | 2961/6689 [00:05<00:10, 352.22 examples/s]Tokenizing train dataset:  45%|████▍     | 3005/6689 [00:06<00:10, 367.51 examples/s]Tokenizing train dataset:  46%|████▌     | 3065/6689 [00:06<00:09, 373.97 examples/s]Tokenizing train dataset:  46%|████▋     | 3110/6689 [00:06<00:09, 389.92 examples/s]Tokenizing train dataset:  47%|████▋     | 3161/6689 [00:06<00:08, 415.02 examples/s]Tokenizing train dataset:  48%|████▊     | 3214/6689 [00:06<00:07, 442.70 examples/s]Tokenizing train dataset:  49%|████▉     | 3278/6689 [00:06<00:07, 435.19 examples/s]Tokenizing train dataset:  50%|████▉     | 3329/6689 [00:06<00:08, 376.35 examples/s]Tokenizing train dataset:  50%|█████     | 3377/6689 [00:06<00:08, 397.68 examples/s]Tokenizing train dataset:  51%|█████▏    | 3444/6689 [00:07<00:07, 411.90 examples/s]Tokenizing train dataset:  52%|█████▏    | 3507/6689 [00:07<00:09, 352.10 examples/s]Tokenizing train dataset:  53%|█████▎    | 3546/6689 [00:07<00:08, 357.76 examples/s]Tokenizing train dataset:  54%|█████▎    | 3591/6689 [00:07<00:09, 331.60 examples/s]Tokenizing train dataset:  55%|█████▍    | 3649/6689 [00:07<00:09, 314.94 examples/s]Tokenizing train dataset:  55%|█████▌    | 3683/6689 [00:07<00:09, 317.40 examples/s]Tokenizing train dataset:  56%|█████▌    | 3740/6689 [00:08<00:08, 334.46 examples/s]Tokenizing train dataset:  57%|█████▋    | 3789/6689 [00:08<00:07, 367.73 examples/s]Tokenizing train dataset:  57%|█████▋    | 3846/6689 [00:08<00:07, 361.43 examples/s]Tokenizing train dataset:  58%|█████▊    | 3890/6689 [00:08<00:07, 375.01 examples/s]Tokenizing train dataset:  59%|█████▉    | 3942/6689 [00:08<00:08, 311.03 examples/s]Tokenizing train dataset:  59%|█████▉    | 3976/6689 [00:08<00:08, 316.43 examples/s]Tokenizing train dataset:  60%|██████    | 4016/6689 [00:08<00:07, 335.52 examples/s]Tokenizing train dataset:  61%|██████    | 4057/6689 [00:08<00:07, 347.84 examples/s]Tokenizing train dataset:  62%|██████▏   | 4115/6689 [00:09<00:09, 260.02 examples/s]Tokenizing train dataset:  62%|██████▏   | 4151/6689 [00:09<00:09, 278.86 examples/s]Tokenizing train dataset:  63%|██████▎   | 4190/6689 [00:09<00:08, 301.56 examples/s]Tokenizing train dataset:  64%|██████▎   | 4251/6689 [00:09<00:07, 330.74 examples/s]Tokenizing train dataset:  64%|██████▍   | 4300/6689 [00:09<00:08, 265.96 examples/s]Tokenizing train dataset:  65%|██████▌   | 4354/6689 [00:10<00:09, 242.70 examples/s]Tokenizing train dataset:  66%|██████▌   | 4390/6689 [00:10<00:08, 261.22 examples/s]Tokenizing train dataset:  66%|██████▋   | 4440/6689 [00:10<00:07, 306.18 examples/s]Tokenizing train dataset:  67%|██████▋   | 4492/6689 [00:10<00:09, 238.05 examples/s]Tokenizing train dataset:  68%|██████▊   | 4535/6689 [00:10<00:07, 270.60 examples/s]Tokenizing train dataset:  69%|██████▊   | 4586/6689 [00:10<00:07, 285.60 examples/s]Tokenizing train dataset:  69%|██████▉   | 4640/6689 [00:11<00:06, 303.97 examples/s]Tokenizing train dataset:  70%|███████   | 4688/6689 [00:11<00:05, 339.88 examples/s]Tokenizing train dataset:  71%|███████   | 4741/6689 [00:11<00:05, 380.41 examples/s]Tokenizing train dataset:  72%|███████▏  | 4798/6689 [00:11<00:05, 368.98 examples/s]Tokenizing train dataset:  72%|███████▏  | 4846/6689 [00:11<00:05, 338.76 examples/s]Tokenizing train dataset:  73%|███████▎  | 4906/6689 [00:11<00:05, 350.11 examples/s]Tokenizing train dataset:  74%|███████▍  | 4948/6689 [00:11<00:04, 362.48 examples/s]Tokenizing train dataset:  75%|███████▍  | 4998/6689 [00:12<00:04, 393.48 examples/s]Tokenizing train dataset:  75%|███████▌  | 5046/6689 [00:12<00:06, 263.39 examples/s]Tokenizing train dataset:  76%|███████▋  | 5104/6689 [00:12<00:05, 293.71 examples/s]Tokenizing train dataset:  77%|███████▋  | 5154/6689 [00:12<00:04, 329.56 examples/s]Tokenizing train dataset:  78%|███████▊  | 5206/6689 [00:12<00:04, 321.52 examples/s]Tokenizing train dataset:  79%|███████▊  | 5264/6689 [00:12<00:04, 311.46 examples/s]Tokenizing train dataset:  79%|███████▉  | 5311/6689 [00:13<00:04, 339.54 examples/s]Tokenizing train dataset:  80%|████████  | 5363/6689 [00:13<00:03, 341.13 examples/s]Tokenizing train dataset:  81%|████████  | 5404/6689 [00:13<00:03, 353.94 examples/s]Tokenizing train dataset:  82%|████████▏ | 5465/6689 [00:13<00:03, 368.20 examples/s]Tokenizing train dataset:  82%|████████▏ | 5516/6689 [00:13<00:02, 400.13 examples/s]Tokenizing train dataset:  83%|████████▎ | 5563/6689 [00:13<00:02, 414.77 examples/s]Tokenizing train dataset:  84%|████████▍ | 5615/6689 [00:13<00:03, 323.49 examples/s]Tokenizing train dataset:  85%|████████▍ | 5668/6689 [00:14<00:03, 314.26 examples/s]Tokenizing train dataset:  86%|████████▌ | 5720/6689 [00:14<00:03, 317.21 examples/s]Tokenizing train dataset:  86%|████████▋ | 5770/6689 [00:14<00:03, 297.75 examples/s]Tokenizing train dataset:  87%|████████▋ | 5813/6689 [00:14<00:02, 322.35 examples/s]Tokenizing train dataset:  88%|████████▊ | 5860/6689 [00:14<00:02, 276.54 examples/s]Tokenizing train dataset:  88%|████████▊ | 5906/6689 [00:14<00:02, 278.57 examples/s]Tokenizing train dataset:  89%|████████▉ | 5943/6689 [00:15<00:02, 296.38 examples/s]Tokenizing train dataset:  89%|████████▉ | 5982/6689 [00:15<00:02, 316.86 examples/s]Tokenizing train dataset:  90%|█████████ | 6030/6689 [00:15<00:02, 273.95 examples/s]Tokenizing train dataset:  91%|█████████ | 6072/6689 [00:15<00:02, 303.41 examples/s]Tokenizing train dataset:  92%|█████████▏| 6125/6689 [00:15<00:01, 314.22 examples/s]Tokenizing train dataset:  92%|█████████▏| 6175/6689 [00:15<00:01, 352.43 examples/s]Tokenizing train dataset:  93%|█████████▎| 6232/6689 [00:15<00:01, 323.20 examples/s]Tokenizing train dataset:  94%|█████████▍| 6285/6689 [00:16<00:01, 366.83 examples/s]Tokenizing train dataset:  95%|█████████▍| 6331/6689 [00:16<00:01, 301.51 examples/s]Tokenizing train dataset:  95%|█████████▌| 6376/6689 [00:16<00:01, 258.62 examples/s]Tokenizing train dataset:  96%|█████████▌| 6406/6689 [00:16<00:01, 265.53 examples/s]Tokenizing train dataset:  96%|█████████▋| 6440/6689 [00:16<00:00, 278.23 examples/s]Tokenizing train dataset:  97%|█████████▋| 6493/6689 [00:16<00:00, 245.68 examples/s]Tokenizing train dataset:  98%|█████████▊| 6550/6689 [00:17<00:00, 279.70 examples/s]Tokenizing train dataset:  99%|█████████▊| 6592/6689 [00:17<00:00, 307.06 examples/s]Tokenizing train dataset:  99%|█████████▉| 6650/6689 [00:17<00:00, 328.39 examples/s]Tokenizing train dataset: 100%|██████████| 6689/6689 [00:17<00:00, 382.66 examples/s]
[rank0]:[W612 18:29:59.495518459 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  61%|██████    | 580/953 [00:00<00:00, 5649.79 examples/s]Extracting prompt in train dataset:   9%|▉         | 589/6689 [00:00<00:01, 5818.22 examples/s]Extracting prompt in train dataset:   9%|▊         | 580/6689 [00:00<00:01, 5711.51 examples/s]Extracting prompt in train dataset:   9%|▊         | 580/6689 [00:00<00:01, 5696.27 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1188/6689 [00:00<00:01, 3783.24 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1180/6689 [00:00<00:02, 2612.00 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1836.67 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1170/6689 [00:00<00:02, 1841.46 examples/s]Extracting prompt in train dataset:  26%|██▋       | 1772/6689 [00:00<00:02, 2390.52 examples/s]
Extracting prompt in train dataset:  26%|██▋       | 1769/6689 [00:00<00:02, 2218.67 examples/s]Extracting prompt in train dataset:  26%|██▋       | 1758/6689 [00:00<00:02, 2307.77 examples/s]Extracting prompt in train dataset:  35%|███▍      | 2340/6689 [00:00<00:01, 2766.27 examples/s]Extracting prompt in train dataset:  35%|███▍      | 2320/6689 [00:00<00:01, 2864.94 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2197/6689 [00:00<00:01, 2727.65 examples/s]Extracting prompt in train dataset:  42%|████▏     | 2840/6689 [00:00<00:01, 3230.42 examples/s]Extracting prompt in train dataset:  41%|████      | 2759/6689 [00:00<00:01, 3198.90 examples/s]Extracting prompt in train dataset:  41%|████      | 2748/6689 [00:00<00:01, 3352.08 examples/s]Extracting prompt in train dataset:  51%|█████     | 3400/6689 [00:01<00:00, 3771.60 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  49%|████▊     | 3246/6689 [00:01<00:00, 3743.00 examples/s]Extracting prompt in train dataset:  51%|█████     | 3380/6689 [00:01<00:00, 3492.64 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 3860/6689 [00:01<00:00, 3962.75 examples/s]Applying chat template to eval dataset:  33%|███▎      | 313/953 [00:00<00:00, 3101.28 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 3950/6689 [00:01<00:00, 4058.10 examples/s]Extracting prompt in train dataset:  60%|██████    | 4045/6689 [00:01<00:00, 3786.17 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 4570/6689 [00:01<00:00, 4220.23 examples/s]Applying chat template to eval dataset:  67%|██████▋   | 640/953 [00:00<00:00, 1983.85 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 4533/6689 [00:01<00:00, 3683.47 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 4640/6689 [00:01<00:00, 3611.66 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 5160/6689 [00:01<00:00, 3889.06 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1867.03 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1768.94 examples/s]
Extracting prompt in train dataset:  77%|███████▋  | 5120/6689 [00:01<00:00, 3301.40 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 5230/6689 [00:01<00:00, 2995.95 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 5750/6689 [00:01<00:00, 3036.69 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 5707/6689 [00:01<00:00, 2618.18 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 5830/6689 [00:01<00:00, 2554.44 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 6303/6689 [00:02<00:00, 2517.08 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 6152/6689 [00:02<00:00, 2919.89 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 6346/6689 [00:02<00:00, 2968.85 examples/s]Extracting prompt in train dataset: 100%|██████████| 6689/6689 [00:02<00:00, 3138.63 examples/s]
Extracting prompt in train dataset:  99%|█████████▉| 6612/6689 [00:02<00:00, 3234.99 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset: 100%|██████████| 6689/6689 [00:02<00:00, 3055.94 examples/s]
Extracting prompt in train dataset: 100%|██████████| 6689/6689 [00:02<00:00, 3021.48 examples/s]
Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 324.31 examples/s]Applying chat template to train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:05, 156.97 examples/s]Applying chat template to train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Applying chat template to train dataset:   4%|▍         | 297/6689 [00:00<00:02, 2937.49 examples/s]Applying chat template to train dataset:   4%|▍         | 296/6689 [00:00<00:02, 2923.28 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:05, 140.83 examples/s]Applying chat template to train dataset:   4%|▍         | 293/6689 [00:00<00:02, 2903.10 examples/s]Applying chat template to train dataset:   9%|▉         | 622/6689 [00:00<00:04, 1362.49 examples/s]Applying chat template to train dataset:   9%|▉         | 620/6689 [00:00<00:04, 1357.42 examples/s]Tokenizing eval dataset:  14%|█▍        | 137/953 [00:01<00:06, 116.60 examples/s]Applying chat template to train dataset:   9%|▉         | 613/6689 [00:00<00:03, 1977.62 examples/s]Applying chat template to train dataset:  13%|█▎        | 893/6689 [00:00<00:03, 1722.52 examples/s]Applying chat template to train dataset:  13%|█▎        | 845/6689 [00:00<00:03, 1595.17 examples/s]Tokenizing eval dataset:  16%|█▌        | 153/953 [00:01<00:06, 121.59 examples/s]Applying chat template to train dataset:  14%|█▍        | 960/6689 [00:00<00:02, 2123.89 examples/s]Applying chat template to train dataset:  18%|█▊        | 1219/6689 [00:00<00:02, 1849.05 examples/s]Tokenizing eval dataset:  18%|█▊        | 167/953 [00:01<00:06, 113.82 examples/s]Applying chat template to train dataset:  17%|█▋        | 1165/6689 [00:00<00:03, 1579.42 examples/s]Applying chat template to train dataset:  21%|██▏       | 1435/6689 [00:00<00:02, 1925.97 examples/s]Applying chat template to train dataset:  19%|█▉        | 1300/6689 [00:00<00:02, 2171.40 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:01<00:06, 112.39 examples/s]Applying chat template to train dataset:  22%|██▏       | 1493/6689 [00:01<00:03, 1405.38 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:01<00:07, 98.98 examples/s] Applying chat template to train dataset:  26%|██▋       | 1757/6689 [00:01<00:03, 1415.08 examples/s]Applying chat template to train dataset:  24%|██▍       | 1620/6689 [00:00<00:03, 1592.02 examples/s]Applying chat template to train dataset:  25%|██▌       | 1700/6689 [00:01<00:03, 1530.45 examples/s]Tokenizing eval dataset:  23%|██▎       | 216/953 [00:01<00:05, 123.01 examples/s]Applying chat template to train dataset:  31%|███       | 2061/6689 [00:01<00:02, 1723.48 examples/s]Applying chat template to train dataset:  29%|██▊       | 1921/6689 [00:00<00:02, 1875.02 examples/s]Applying chat template to train dataset:  30%|███       | 2020/6689 [00:01<00:02, 1561.47 examples/s]Tokenizing eval dataset:  26%|██▌       | 245/953 [00:01<00:05, 130.95 examples/s]Applying chat template to train dataset:  36%|███▌      | 2381/6689 [00:01<00:03, 1334.77 examples/s]Applying chat template to train dataset:  33%|███▎      | 2237/6689 [00:01<00:03, 1159.34 examples/s]Tokenizing eval dataset:  29%|██▉       | 280/953 [00:02<00:07, 90.51 examples/s] Applying chat template to train dataset:  35%|███▌      | 2342/6689 [00:01<00:04, 952.10 examples/s] Applying chat template to train dataset:  40%|████      | 2700/6689 [00:02<00:03, 1034.57 examples/s]Applying chat template to train dataset:  38%|███▊      | 2550/6689 [00:01<00:03, 1095.83 examples/s]Tokenizing eval dataset:  35%|███▍      | 332/953 [00:02<00:04, 146.60 examples/s]Applying chat template to train dataset:  38%|███▊      | 2564/6689 [00:01<00:03, 1112.55 examples/s]Applying chat template to train dataset:  44%|████▎     | 2921/6689 [00:02<00:03, 1187.12 examples/s]Applying chat template to train dataset:  41%|████▏     | 2762/6689 [00:01<00:03, 1234.61 examples/s]Tokenizing eval dataset:  39%|███▉      | 374/953 [00:02<00:03, 189.46 examples/s]Tokenizing eval dataset:  43%|████▎     | 408/953 [00:02<00:02, 213.62 examples/s]Applying chat template to train dataset:  43%|████▎     | 2871/6689 [00:02<00:03, 1186.05 examples/s]Applying chat template to train dataset:  48%|████▊     | 3240/6689 [00:02<00:02, 1351.45 examples/s]Applying chat template to train dataset:  46%|████▌     | 3079/6689 [00:02<00:02, 1407.92 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:02<00:01, 293.45 examples/s]Applying chat template to train dataset:  45%|████▌     | 3041/6689 [00:02<00:02, 1265.14 examples/s]Applying chat template to train dataset:  53%|█████▎    | 3560/6689 [00:02<00:02, 1420.15 examples/s]Applying chat template to train dataset:  51%|█████     | 3396/6689 [00:02<00:02, 1413.99 examples/s]Tokenizing eval dataset:  56%|█████▌    | 534/953 [00:03<00:01, 258.62 examples/s]Applying chat template to train dataset:  48%|████▊     | 3201/6689 [00:02<00:03, 925.24 examples/s] Applying chat template to train dataset:  58%|█████▊    | 3875/6689 [00:02<00:02, 1310.17 examples/s]Applying chat template to train dataset:  55%|█████▌    | 3710/6689 [00:02<00:02, 1205.96 examples/s]Tokenizing eval dataset:  60%|█████▉    | 568/953 [00:03<00:02, 187.97 examples/s]Applying chat template to train dataset:  50%|█████     | 3363/6689 [00:03<00:05, 653.39 examples/s]Applying chat template to train dataset:  60%|██████    | 4036/6689 [00:03<00:02, 895.59 examples/s] Applying chat template to train dataset:  58%|█████▊    | 3869/6689 [00:02<00:03, 928.44 examples/s] Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:03<00:01, 187.68 examples/s]Applying chat template to train dataset:  54%|█████▍    | 3630/6689 [00:03<00:03, 898.10 examples/s]Applying chat template to train dataset:  64%|██████▍   | 4313/6689 [00:03<00:02, 1136.67 examples/s]Applying chat template to train dataset:  62%|██████▏   | 4141/6689 [00:03<00:02, 1167.04 examples/s]Tokenizing eval dataset:  69%|██████▉   | 662/953 [00:03<00:01, 242.58 examples/s]Applying chat template to train dataset:  58%|█████▊    | 3849/6689 [00:03<00:02, 1088.85 examples/s]Applying chat template to train dataset:  69%|██████▉   | 4632/6689 [00:03<00:01, 1314.86 examples/s]Applying chat template to train dataset:  67%|██████▋   | 4459/6689 [00:03<00:01, 1326.72 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:04<00:00, 261.19 examples/s]Applying chat template to train dataset:  62%|██████▏   | 4175/6689 [00:03<00:01, 1349.00 examples/s]Applying chat template to train dataset:  74%|███████▍  | 4952/6689 [00:03<00:01, 1481.26 examples/s]Applying chat template to train dataset:  71%|███████▏  | 4775/6689 [00:03<00:01, 1503.23 examples/s]Tokenizing eval dataset:  82%|████████▏ | 780/953 [00:04<00:00, 237.11 examples/s]Applying chat template to train dataset:  67%|██████▋   | 4494/6689 [00:03<00:02, 1091.60 examples/s]Applying chat template to train dataset:  79%|███████▉  | 5273/6689 [00:03<00:01, 1216.81 examples/s]Applying chat template to train dataset:  76%|███████▌  | 5097/6689 [00:03<00:01, 1217.72 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:04<00:00, 231.78 examples/s]Applying chat template to train dataset:  70%|██████▉   | 4653/6689 [00:04<00:02, 992.29 examples/s] Applying chat template to train dataset:  81%|████████  | 5431/6689 [00:04<00:01, 1014.87 examples/s]Applying chat template to train dataset:  79%|███████▊  | 5252/6689 [00:04<00:01, 993.34 examples/s] Applying chat template to train dataset:  72%|███████▏  | 4810/6689 [00:04<00:02, 918.34 examples/s]Applying chat template to train dataset:  84%|████████▎ | 5590/6689 [00:04<00:01, 1046.26 examples/s]Tokenizing eval dataset:  92%|█████████▏| 881/953 [00:04<00:00, 192.45 examples/s]Applying chat template to train dataset:  81%|████████  | 5410/6689 [00:04<00:01, 1058.51 examples/s]Applying chat template to train dataset:  74%|███████▍  | 4970/6689 [00:04<00:01, 925.31 examples/s]Applying chat template to train dataset:  86%|████████▌ | 5750/6689 [00:04<00:00, 975.66 examples/s] Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:05<00:00, 153.49 examples/s]Applying chat template to train dataset:  83%|████████▎ | 5571/6689 [00:04<00:01, 818.76 examples/s] Applying chat template to train dataset:  77%|███████▋  | 5131/6689 [00:04<00:01, 872.20 examples/s]Applying chat template to train dataset:  88%|████████▊ | 5906/6689 [00:04<00:00, 966.52 examples/s]Tokenizing eval dataset: 100%|█████████▉| 950/953 [00:05<00:00, 188.09 examples/s]Applying chat template to train dataset:  87%|████████▋ | 5797/6689 [00:04<00:00, 1027.21 examples/s]Applying chat template to train dataset:  79%|███████▉  | 5291/6689 [00:04<00:01, 743.97 examples/s]Applying chat template to train dataset:  91%|█████████ | 6060/6689 [00:05<00:00, 744.96 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 167.53 examples/s]Applying chat template to train dataset:  89%|████████▉ | 5954/6689 [00:04<00:00, 822.04 examples/s] 
Applying chat template to train dataset:  82%|████████▏ | 5453/6689 [00:05<00:01, 823.37 examples/s]Applying chat template to train dataset:  93%|█████████▎| 6215/6689 [00:05<00:00, 857.69 examples/s]Applying chat template to train dataset:  91%|█████████▏| 6112/6689 [00:05<00:00, 933.49 examples/s]Applying chat template to train dataset:  84%|████████▍ | 5613/6689 [00:05<00:01, 912.62 examples/s]Applying chat template to train dataset:  95%|█████████▌| 6355/6689 [00:05<00:00, 816.00 examples/s]Applying chat template to train dataset:  94%|█████████▎| 6260/6689 [00:05<00:00, 914.06 examples/s]Applying chat template to train dataset:  86%|████████▋ | 5774/6689 [00:05<00:00, 980.83 examples/s]Applying chat template to train dataset:  98%|█████████▊| 6565/6689 [00:05<00:00, 1042.34 examples/s]Applying chat template to train dataset:  96%|█████████▌| 6418/6689 [00:05<00:00, 988.89 examples/s]Applying chat template to train dataset:  89%|████████▊ | 5936/6689 [00:05<00:00, 1076.60 examples/s]Applying chat template to train dataset:  98%|█████████▊| 6575/6689 [00:05<00:00, 1015.23 examples/s]Applying chat template to train dataset: 100%|██████████| 6689/6689 [00:05<00:00, 1173.31 examples/s]
Applying chat template to train dataset:  91%|█████████ | 6097/6689 [00:05<00:00, 1010.02 examples/s]Applying chat template to train dataset: 100%|██████████| 6689/6689 [00:05<00:00, 1196.76 examples/s]
Applying chat template to train dataset:  93%|█████████▎| 6249/6689 [00:05<00:00, 1115.87 examples/s]Applying chat template to train dataset:  95%|█████████▌| 6385/6689 [00:05<00:00, 1077.91 examples/s]Applying chat template to train dataset:  98%|█████████▊| 6548/6689 [00:06<00:00, 1107.06 examples/s]Tokenizing train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Applying chat template to train dataset: 100%|██████████| 6689/6689 [00:06<00:00, 872.32 examples/s] Tokenizing train dataset:   2%|▏         | 109/6689 [00:00<00:06, 1078.17 examples/s]Applying chat template to train dataset: 100%|██████████| 6689/6689 [00:06<00:00, 1041.29 examples/s]Tokenizing train dataset:   2%|▏         | 109/6689 [00:00<00:06, 1081.80 examples/s]
Tokenizing train dataset:   4%|▍         | 261/6689 [00:00<00:06, 1028.66 examples/s]Tokenizing train dataset:   3%|▎         | 233/6689 [00:00<00:08, 766.12 examples/s] Tokenizing train dataset:   6%|▌         | 376/6689 [00:00<00:07, 871.58 examples/s] Tokenizing train dataset:   5%|▍         | 334/6689 [00:00<00:07, 845.35 examples/s]Tokenizing train dataset:   8%|▊         | 506/6689 [00:00<00:07, 864.82 examples/s]Tokenizing train dataset:   7%|▋         | 465/6689 [00:00<00:07, 850.49 examples/s]Tokenizing train dataset:   0%|          | 0/6689 [00:00<?, ? examples/s]Tokenizing train dataset:   9%|▉         | 613/6689 [00:00<00:11, 547.61 examples/s]Tokenizing train dataset:   9%|▊         | 576/6689 [00:01<00:13, 446.11 examples/s]Tokenizing train dataset:   1%|▏         | 100/6689 [00:00<00:06, 978.79 examples/s]Tokenizing train dataset:  11%|█         | 710/6689 [00:01<00:18, 324.31 examples/s]Tokenizing train dataset:  10%|█         | 675/6689 [00:01<00:19, 304.12 examples/s]Tokenizing train dataset:   3%|▎         | 217/6689 [00:00<00:15, 413.08 examples/s]Tokenizing train dataset:  11%|█▏        | 766/6689 [00:01<00:21, 273.55 examples/s]Tokenizing train dataset:   4%|▍         | 276/6689 [00:00<00:17, 363.92 examples/s]Tokenizing train dataset:  12%|█▏        | 778/6689 [00:01<00:18, 318.23 examples/s]Tokenizing train dataset:  12%|█▏        | 808/6689 [00:02<00:23, 254.57 examples/s]Tokenizing train dataset:   5%|▍         | 334/6689 [00:01<00:23, 265.07 examples/s]Tokenizing train dataset:  12%|█▏        | 827/6689 [00:02<00:24, 238.73 examples/s]Tokenizing train dataset:  13%|█▎        | 858/6689 [00:02<00:26, 220.61 examples/s]Tokenizing train dataset:   6%|▌         | 383/6689 [00:01<00:24, 255.64 examples/s]Tokenizing train dataset:  13%|█▎        | 875/6689 [00:02<00:21, 264.55 examples/s]Tokenizing train dataset:  14%|█▎        | 913/6689 [00:02<00:22, 261.60 examples/s]Tokenizing train dataset:   6%|▋         | 434/6689 [00:01<00:21, 284.48 examples/s]Tokenizing train dataset:  14%|█▎        | 919/6689 [00:02<00:20, 276.73 examples/s]Tokenizing train dataset:  14%|█▍        | 955/6689 [00:02<00:21, 263.94 examples/s]Tokenizing train dataset:   7%|▋         | 486/6689 [00:01<00:21, 294.13 examples/s]Tokenizing train dataset:  15%|█▍        | 970/6689 [00:02<00:20, 281.99 examples/s]Tokenizing train dataset:  15%|█▍        | 1003/6689 [00:03<00:27, 209.97 examples/s]Tokenizing train dataset:   8%|▊         | 538/6689 [00:01<00:26, 229.83 examples/s]Tokenizing train dataset:  15%|█▌        | 1011/6689 [00:03<00:26, 214.42 examples/s]Tokenizing train dataset:  16%|█▌        | 1042/6689 [00:03<00:24, 230.64 examples/s]Tokenizing train dataset:   9%|▉         | 630/6689 [00:01<00:17, 337.69 examples/s]Tokenizing train dataset:  16%|█▋        | 1090/6689 [00:03<00:18, 296.20 examples/s]Tokenizing train dataset:  17%|█▋        | 1125/6689 [00:03<00:16, 329.79 examples/s]Tokenizing train dataset:  11%|█         | 709/6689 [00:02<00:14, 419.85 examples/s]Tokenizing train dataset:  17%|█▋        | 1143/6689 [00:03<00:16, 335.63 examples/s]Tokenizing train dataset:  18%|█▊        | 1211/6689 [00:03<00:13, 391.37 examples/s]Tokenizing train dataset:  12%|█▏        | 801/6689 [00:02<00:13, 452.13 examples/s]Tokenizing train dataset:  18%|█▊        | 1225/6689 [00:03<00:15, 364.27 examples/s]Tokenizing train dataset:  19%|█▉        | 1295/6689 [00:03<00:12, 435.23 examples/s]Tokenizing train dataset:  13%|█▎        | 887/6689 [00:02<00:12, 460.92 examples/s]Tokenizing train dataset:  20%|█▉        | 1305/6689 [00:03<00:14, 375.00 examples/s]Tokenizing train dataset:  20%|██        | 1371/6689 [00:03<00:12, 427.74 examples/s]Tokenizing train dataset:  14%|█▍        | 963/6689 [00:02<00:11, 519.14 examples/s]Tokenizing train dataset:  21%|██        | 1383/6689 [00:03<00:15, 340.81 examples/s]Tokenizing train dataset:  22%|██▏       | 1449/6689 [00:04<00:14, 359.49 examples/s]Tokenizing train dataset:  16%|█▌        | 1044/6689 [00:02<00:15, 374.63 examples/s]Tokenizing train dataset:  22%|██▏       | 1456/6689 [00:04<00:14, 364.85 examples/s]Tokenizing train dataset:  23%|██▎       | 1526/6689 [00:04<00:14, 358.66 examples/s]Tokenizing train dataset:  23%|██▎       | 1522/6689 [00:04<00:12, 415.09 examples/s]Tokenizing train dataset:  17%|█▋        | 1131/6689 [00:03<00:13, 413.91 examples/s]Tokenizing train dataset:  24%|██▍       | 1595/6689 [00:04<00:14, 345.43 examples/s]Tokenizing train dataset:  24%|██▍       | 1595/6689 [00:04<00:14, 355.75 examples/s]Tokenizing train dataset:  18%|█▊        | 1204/6689 [00:03<00:16, 332.65 examples/s]Tokenizing train dataset:  25%|██▍       | 1665/6689 [00:04<00:13, 362.38 examples/s]Tokenizing train dataset:  25%|██▍       | 1656/6689 [00:04<00:12, 399.20 examples/s]Tokenizing train dataset:  19%|█▉        | 1256/6689 [00:03<00:15, 360.06 examples/s]Tokenizing train dataset:  25%|██▌       | 1704/6689 [00:04<00:14, 353.37 examples/s]Tokenizing train dataset:  20%|█▉        | 1314/6689 [00:03<00:13, 398.66 examples/s]Tokenizing train dataset:  26%|██▌       | 1728/6689 [00:04<00:12, 395.98 examples/s]Tokenizing train dataset:  20%|██        | 1368/6689 [00:03<00:12, 425.26 examples/s]Tokenizing train dataset:  26%|██▋       | 1770/6689 [00:04<00:13, 360.82 examples/s]Tokenizing train dataset:  27%|██▋       | 1795/6689 [00:04<00:10, 446.24 examples/s]Tokenizing train dataset:  27%|██▋       | 1808/6689 [00:05<00:15, 322.08 examples/s]Tokenizing train dataset:  22%|██▏       | 1440/6689 [00:03<00:13, 386.64 examples/s]Tokenizing train dataset:  28%|██▊       | 1866/6689 [00:05<00:12, 392.06 examples/s]Tokenizing train dataset:  28%|██▊       | 1863/6689 [00:05<00:13, 366.74 examples/s]Tokenizing train dataset:  22%|██▏       | 1503/6689 [00:04<00:11, 434.41 examples/s]Tokenizing train dataset:  28%|██▊       | 1905/6689 [00:05<00:12, 376.37 examples/s]Tokenizing train dataset:  23%|██▎       | 1560/6689 [00:04<00:11, 460.25 examples/s]Tokenizing train dataset:  29%|██▉       | 1945/6689 [00:05<00:11, 409.53 examples/s]Tokenizing train dataset:  29%|██▉       | 1959/6689 [00:05<00:11, 410.16 examples/s]Tokenizing train dataset:  24%|██▍       | 1622/6689 [00:04<00:10, 494.90 examples/s]Tokenizing train dataset:  30%|██▉       | 2003/6689 [00:05<00:10, 441.38 examples/s]Tokenizing train dataset:  30%|███       | 2029/6689 [00:05<00:10, 427.00 examples/s]Tokenizing train dataset:  25%|██▌       | 1704/6689 [00:04<00:09, 510.62 examples/s]Tokenizing train dataset:  31%|███       | 2071/6689 [00:05<00:11, 415.54 examples/s]Tokenizing train dataset:  32%|███▏      | 2108/6689 [00:05<00:10, 450.98 examples/s]Tokenizing train dataset:  26%|██▋       | 1764/6689 [00:04<00:11, 425.00 examples/s]Tokenizing train dataset:  32%|███▏      | 2144/6689 [00:05<00:11, 408.28 examples/s]Tokenizing train dataset:  32%|███▏      | 2169/6689 [00:05<00:09, 483.64 examples/s]Tokenizing train dataset:  27%|██▋       | 1820/6689 [00:04<00:10, 450.53 examples/s]Tokenizing train dataset:  33%|███▎      | 2204/6689 [00:05<00:10, 442.71 examples/s]Tokenizing train dataset:  34%|███▎      | 2250/6689 [00:05<00:08, 497.53 examples/s]Tokenizing train dataset:  28%|██▊       | 1879/6689 [00:04<00:09, 482.44 examples/s]Tokenizing train dataset:  34%|███▍      | 2259/6689 [00:05<00:09, 463.90 examples/s]Tokenizing train dataset:  29%|██▉       | 1934/6689 [00:04<00:09, 497.90 examples/s]Tokenizing train dataset:  35%|███▍      | 2322/6689 [00:06<00:08, 490.60 examples/s]Tokenizing train dataset:  35%|███▍      | 2319/6689 [00:06<00:08, 493.22 examples/s]Tokenizing train dataset:  36%|███▌      | 2378/6689 [00:06<00:08, 505.95 examples/s]Tokenizing train dataset:  35%|███▌      | 2372/6689 [00:06<00:08, 497.50 examples/s]Tokenizing train dataset:  30%|███       | 2011/6689 [00:05<00:09, 497.05 examples/s]Tokenizing train dataset:  36%|███▋      | 2440/6689 [00:06<00:11, 371.42 examples/s]Tokenizing train dataset:  36%|███▋      | 2438/6689 [00:06<00:12, 345.73 examples/s]Tokenizing train dataset:  31%|███       | 2078/6689 [00:05<00:12, 368.13 examples/s]Tokenizing train dataset:  37%|███▋      | 2500/6689 [00:06<00:11, 373.23 examples/s]Tokenizing train dataset:  37%|███▋      | 2508/6689 [00:06<00:11, 372.91 examples/s]Tokenizing train dataset:  32%|███▏      | 2144/6689 [00:05<00:12, 372.10 examples/s]Tokenizing train dataset:  38%|███▊      | 2571/6689 [00:06<00:09, 423.10 examples/s]Tokenizing train dataset:  38%|███▊      | 2574/6689 [00:06<00:10, 404.78 examples/s]Tokenizing train dataset:  33%|███▎      | 2190/6689 [00:05<00:11, 386.65 examples/s]Tokenizing train dataset:  39%|███▉      | 2633/6689 [00:06<00:08, 463.80 examples/s]Tokenizing train dataset:  39%|███▉      | 2632/6689 [00:06<00:09, 438.65 examples/s]Tokenizing train dataset:  34%|███▎      | 2249/6689 [00:05<00:11, 384.90 examples/s]Tokenizing train dataset:  40%|████      | 2697/6689 [00:07<00:10, 385.00 examples/s]Tokenizing train dataset:  40%|████      | 2695/6689 [00:07<00:13, 294.96 examples/s]Tokenizing train dataset:  35%|███▍      | 2313/6689 [00:06<00:20, 213.49 examples/s]Tokenizing train dataset:  41%|████      | 2750/6689 [00:07<00:20, 189.82 examples/s]Tokenizing train dataset:  41%|████      | 2747/6689 [00:07<00:24, 163.30 examples/s]Tokenizing train dataset:  35%|███▌      | 2349/6689 [00:06<00:27, 155.75 examples/s]Tokenizing train dataset:  42%|████▏     | 2780/6689 [00:08<00:22, 173.85 examples/s]Tokenizing train dataset:  36%|███▌      | 2381/6689 [00:06<00:25, 169.67 examples/s]Tokenizing train dataset:  42%|████▏     | 2813/6689 [00:08<00:21, 181.62 examples/s]Tokenizing train dataset:  42%|████▏     | 2840/6689 [00:08<00:16, 226.52 examples/s]Tokenizing train dataset:  36%|███▋      | 2435/6689 [00:07<00:19, 218.95 examples/s]Tokenizing train dataset:  43%|████▎     | 2868/6689 [00:08<00:17, 222.70 examples/s]Tokenizing train dataset:  43%|████▎     | 2893/6689 [00:08<00:13, 271.82 examples/s]Tokenizing train dataset:  37%|███▋      | 2480/6689 [00:07<00:16, 254.39 examples/s]Tokenizing train dataset:  44%|████▍     | 2930/6689 [00:08<00:14, 257.27 examples/s]Tokenizing train dataset:  44%|████▍     | 2956/6689 [00:08<00:12, 304.46 examples/s]Tokenizing train dataset:  38%|███▊      | 2543/6689 [00:07<00:18, 228.87 examples/s]Tokenizing train dataset:  45%|████▍     | 2988/6689 [00:08<00:15, 243.71 examples/s]Tokenizing train dataset:  45%|████▌     | 3014/6689 [00:08<00:12, 291.29 examples/s]Tokenizing train dataset:  39%|███▊      | 2591/6689 [00:07<00:15, 267.84 examples/s]Tokenizing train dataset:  45%|████▌     | 3030/6689 [00:08<00:13, 268.73 examples/s]Tokenizing train dataset:  46%|████▌     | 3073/6689 [00:08<00:12, 279.46 examples/s]Tokenizing train dataset:  39%|███▉      | 2629/6689 [00:07<00:19, 208.03 examples/s]Tokenizing train dataset:  46%|████▌     | 3088/6689 [00:09<00:21, 169.17 examples/s]Tokenizing train dataset:  47%|████▋     | 3134/6689 [00:09<00:18, 195.15 examples/s]Tokenizing train dataset:  40%|████      | 2687/6689 [00:08<00:22, 175.98 examples/s]Tokenizing train dataset:  47%|████▋     | 3120/6689 [00:09<00:22, 162.12 examples/s]Tokenizing train dataset:  47%|████▋     | 3162/6689 [00:09<00:19, 182.83 examples/s]Tokenizing train dataset:  41%|████      | 2712/6689 [00:08<00:23, 165.84 examples/s]Tokenizing train dataset:  47%|████▋     | 3161/6689 [00:09<00:18, 192.21 examples/s]Tokenizing train dataset:  48%|████▊     | 3201/6689 [00:09<00:16, 209.98 examples/s]Tokenizing train dataset:  41%|████      | 2750/6689 [00:08<00:20, 196.08 examples/s]Tokenizing train dataset:  48%|████▊     | 3219/6689 [00:09<00:13, 250.04 examples/s]Tokenizing train dataset:  49%|████▊     | 3247/6689 [00:09<00:13, 249.53 examples/s]Tokenizing train dataset:  42%|████▏     | 2794/6689 [00:08<00:16, 236.57 examples/s]Tokenizing train dataset:  49%|████▉     | 3284/6689 [00:09<00:12, 270.51 examples/s]Tokenizing train dataset:  49%|████▉     | 3277/6689 [00:09<00:12, 282.19 examples/s]Tokenizing train dataset:  42%|████▏     | 2840/6689 [00:08<00:13, 278.57 examples/s]Tokenizing train dataset:  50%|████▉     | 3334/6689 [00:10<00:12, 259.43 examples/s]Tokenizing train dataset:  50%|████▉     | 3329/6689 [00:10<00:13, 246.51 examples/s]Tokenizing train dataset:  43%|████▎     | 2897/6689 [00:09<00:19, 191.58 examples/s]Tokenizing train dataset:  50%|█████     | 3369/6689 [00:10<00:17, 191.49 examples/s]Tokenizing train dataset:  50%|█████     | 3363/6689 [00:10<00:15, 210.11 examples/s]Tokenizing train dataset:  44%|████▍     | 2944/6689 [00:09<00:16, 231.21 examples/s]Tokenizing train dataset:  51%|█████     | 3406/6689 [00:10<00:15, 214.71 examples/s]Tokenizing train dataset:  51%|█████     | 3396/6689 [00:10<00:14, 228.56 examples/s]Tokenizing train dataset:  45%|████▍     | 2988/6689 [00:09<00:13, 266.76 examples/s]Tokenizing train dataset:  52%|█████▏    | 3447/6689 [00:10<00:12, 250.39 examples/s]Tokenizing train dataset:  51%|█████     | 3428/6689 [00:10<00:13, 244.00 examples/s]Tokenizing train dataset:  45%|████▌     | 3029/6689 [00:09<00:12, 293.78 examples/s]Tokenizing train dataset:  52%|█████▏    | 3501/6689 [00:10<00:10, 310.28 examples/s]Tokenizing train dataset:  52%|█████▏    | 3481/6689 [00:10<00:10, 302.32 examples/s]Tokenizing train dataset:  53%|█████▎    | 3548/6689 [00:10<00:09, 345.85 examples/s]Tokenizing train dataset:  53%|█████▎    | 3533/6689 [00:10<00:09, 349.52 examples/s]Tokenizing train dataset:  46%|████▌     | 3083/6689 [00:09<00:11, 305.64 examples/s]Tokenizing train dataset:  54%|█████▍    | 3604/6689 [00:11<00:08, 352.66 examples/s]Tokenizing train dataset:  47%|████▋     | 3141/6689 [00:09<00:10, 328.33 examples/s]Tokenizing train dataset:  54%|█████▎    | 3588/6689 [00:11<00:08, 351.72 examples/s]Tokenizing train dataset:  55%|█████▍    | 3661/6689 [00:11<00:08, 356.35 examples/s]Tokenizing train dataset:  48%|████▊     | 3198/6689 [00:10<00:10, 341.09 examples/s]Tokenizing train dataset:  55%|█████▍    | 3647/6689 [00:11<00:08, 348.31 examples/s]Tokenizing train dataset:  55%|█████▌    | 3709/6689 [00:11<00:07, 382.89 examples/s]Tokenizing train dataset:  49%|████▊     | 3248/6689 [00:10<00:10, 315.06 examples/s]Tokenizing train dataset:  56%|█████▌    | 3757/6689 [00:11<00:07, 403.19 examples/s]Tokenizing train dataset:  55%|█████▌    | 3700/6689 [00:11<00:09, 331.33 examples/s]Tokenizing train dataset:  49%|████▉     | 3292/6689 [00:10<00:09, 340.40 examples/s]Tokenizing train dataset:  57%|█████▋    | 3816/6689 [00:11<00:07, 387.69 examples/s]Tokenizing train dataset:  56%|█████▌    | 3752/6689 [00:11<00:09, 302.32 examples/s]Tokenizing train dataset:  50%|█████     | 3356/6689 [00:10<00:09, 361.81 examples/s]Tokenizing train dataset:  58%|█████▊    | 3875/6689 [00:11<00:07, 386.15 examples/s]Tokenizing train dataset:  57%|█████▋    | 3813/6689 [00:11<00:09, 299.62 examples/s]Tokenizing train dataset:  51%|█████     | 3420/6689 [00:10<00:09, 343.05 examples/s]Tokenizing train dataset:  59%|█████▉    | 3930/6689 [00:12<00:09, 276.27 examples/s]Tokenizing train dataset:  58%|█████▊    | 3868/6689 [00:12<00:10, 265.78 examples/s]Tokenizing train dataset:  52%|█████▏    | 3478/6689 [00:10<00:10, 298.60 examples/s]Tokenizing train dataset:  59%|█████▉    | 3967/6689 [00:12<00:09, 292.11 examples/s]Tokenizing train dataset:  59%|█████▊    | 3914/6689 [00:12<00:09, 295.44 examples/s]Tokenizing train dataset:  53%|█████▎    | 3531/6689 [00:11<00:09, 340.15 examples/s]Tokenizing train dataset:  60%|█████▉    | 4006/6689 [00:12<00:08, 310.94 examples/s]Tokenizing train dataset:  59%|█████▉    | 3947/6689 [00:12<00:09, 300.31 examples/s]Tokenizing train dataset:  53%|█████▎    | 3576/6689 [00:11<00:09, 312.48 examples/s]Tokenizing train dataset:  60%|█████▉    | 3981/6689 [00:12<00:08, 306.60 examples/s]Tokenizing train dataset:  61%|██████    | 4060/6689 [00:12<00:08, 321.34 examples/s]Tokenizing train dataset:  54%|█████▍    | 3620/6689 [00:11<00:09, 335.17 examples/s]Tokenizing train dataset:  60%|██████    | 4026/6689 [00:12<00:07, 336.95 examples/s]Tokenizing train dataset:  62%|██████▏   | 4115/6689 [00:12<00:06, 371.52 examples/s]Tokenizing train dataset:  55%|█████▍    | 3660/6689 [00:11<00:08, 345.94 examples/s]Tokenizing train dataset:  61%|██████    | 4091/6689 [00:12<00:07, 361.95 examples/s]Tokenizing train dataset:  62%|██████▏   | 4172/6689 [00:12<00:07, 332.91 examples/s]Tokenizing train dataset:  62%|██████▏   | 4139/6689 [00:12<00:06, 389.08 examples/s]Tokenizing train dataset:  55%|█████▌    | 3710/6689 [00:11<00:09, 321.72 examples/s]Tokenizing train dataset:  63%|██████▎   | 4185/6689 [00:12<00:06, 406.37 examples/s]Tokenizing train dataset:  63%|██████▎   | 4232/6689 [00:12<00:07, 348.61 examples/s]Tokenizing train dataset:  56%|█████▌    | 3750/6689 [00:11<00:08, 336.67 examples/s]Tokenizing train dataset:  63%|██████▎   | 4244/6689 [00:13<00:06, 372.61 examples/s]Tokenizing train dataset:  64%|██████▍   | 4287/6689 [00:13<00:08, 286.18 examples/s]Tokenizing train dataset:  57%|█████▋    | 3807/6689 [00:12<00:10, 268.58 examples/s]Tokenizing train dataset:  64%|██████▍   | 4298/6689 [00:13<00:07, 341.10 examples/s]Tokenizing train dataset:  65%|██████▍   | 4334/6689 [00:13<00:08, 268.75 examples/s]Tokenizing train dataset:  58%|█████▊    | 3858/6689 [00:12<00:11, 250.79 examples/s]Tokenizing train dataset:  65%|██████▌   | 4369/6689 [00:13<00:08, 280.35 examples/s]Tokenizing train dataset:  65%|██████▌   | 4351/6689 [00:13<00:08, 285.12 examples/s]Tokenizing train dataset:  58%|█████▊    | 3899/6689 [00:12<00:10, 278.25 examples/s]Tokenizing train dataset:  66%|██████▌   | 4420/6689 [00:13<00:07, 286.62 examples/s]Tokenizing train dataset:  66%|██████▌   | 4408/6689 [00:13<00:07, 291.43 examples/s]Tokenizing train dataset:  67%|██████▋   | 4451/6689 [00:13<00:08, 274.75 examples/s]Tokenizing train dataset:  59%|█████▉    | 3949/6689 [00:12<00:11, 240.78 examples/s]Tokenizing train dataset:  67%|██████▋   | 4460/6689 [00:13<00:08, 262.19 examples/s]Tokenizing train dataset:  67%|██████▋   | 4504/6689 [00:13<00:08, 270.50 examples/s]Tokenizing train dataset:  60%|█████▉    | 3990/6689 [00:12<00:12, 217.60 examples/s]Tokenizing train dataset:  67%|██████▋   | 4489/6689 [00:14<00:08, 245.95 examples/s]Tokenizing train dataset:  68%|██████▊   | 4533/6689 [00:14<00:10, 196.29 examples/s]Tokenizing train dataset:  60%|██████    | 4016/6689 [00:13<00:16, 158.27 examples/s]Tokenizing train dataset:  68%|██████▊   | 4520/6689 [00:14<00:12, 180.45 examples/s]Tokenizing train dataset:  68%|██████▊   | 4557/6689 [00:14<00:11, 189.33 examples/s]Tokenizing train dataset:  61%|██████    | 4049/6689 [00:13<00:14, 182.30 examples/s]Tokenizing train dataset:  69%|██████▉   | 4600/6689 [00:14<00:08, 232.52 examples/s]Tokenizing train dataset:  68%|██████▊   | 4567/6689 [00:14<00:09, 223.64 examples/s]Tokenizing train dataset:  61%|██████    | 4076/6689 [00:13<00:13, 195.00 examples/s]Tokenizing train dataset:  69%|██████▉   | 4630/6689 [00:14<00:08, 246.24 examples/s]Tokenizing train dataset:  69%|██████▊   | 4595/6689 [00:14<00:09, 218.51 examples/s]Tokenizing train dataset:  61%|██████▏   | 4108/6689 [00:13<00:11, 217.61 examples/s]Tokenizing train dataset:  70%|██████▉   | 4660/6689 [00:14<00:07, 255.66 examples/s]Tokenizing train dataset:  69%|██████▉   | 4644/6689 [00:14<00:08, 242.61 examples/s]Tokenizing train dataset:  62%|██████▏   | 4136/6689 [00:13<00:12, 210.41 examples/s]Tokenizing train dataset:  71%|███████   | 4718/6689 [00:14<00:07, 277.53 examples/s]Tokenizing train dataset:  62%|██████▏   | 4166/6689 [00:13<00:11, 228.15 examples/s]Tokenizing train dataset:  70%|███████   | 4701/6689 [00:14<00:07, 274.87 examples/s]Tokenizing train dataset:  71%|███████▏  | 4770/6689 [00:15<00:05, 329.67 examples/s]Tokenizing train dataset:  71%|███████   | 4735/6689 [00:15<00:06, 284.56 examples/s]Tokenizing train dataset:  63%|██████▎   | 4219/6689 [00:13<00:09, 260.48 examples/s]Tokenizing train dataset:  72%|███████▏  | 4823/6689 [00:15<00:05, 328.46 examples/s]Tokenizing train dataset:  72%|███████▏  | 4792/6689 [00:15<00:05, 345.43 examples/s]Tokenizing train dataset:  64%|██████▍   | 4265/6689 [00:14<00:07, 304.38 examples/s]Tokenizing train dataset:  73%|███████▎  | 4870/6689 [00:15<00:05, 360.99 examples/s]Tokenizing train dataset:  72%|███████▏  | 4833/6689 [00:15<00:05, 358.20 examples/s]Tokenizing train dataset:  64%|██████▍   | 4310/6689 [00:14<00:09, 253.01 examples/s]Tokenizing train dataset:  65%|██████▍   | 4346/6689 [00:14<00:08, 274.04 examples/s]Tokenizing train dataset:  74%|███████▎  | 4920/6689 [00:15<00:06, 274.28 examples/s]Tokenizing train dataset:  73%|███████▎  | 4885/6689 [00:15<00:06, 273.58 examples/s]Tokenizing train dataset:  66%|██████▌   | 4392/6689 [00:14<00:07, 314.54 examples/s]Tokenizing train dataset:  74%|███████▍  | 4969/6689 [00:15<00:05, 315.26 examples/s]Tokenizing train dataset:  74%|███████▎  | 4920/6689 [00:15<00:06, 287.68 examples/s]Tokenizing train dataset:  66%|██████▋   | 4445/6689 [00:14<00:07, 307.41 examples/s]Tokenizing train dataset:  75%|███████▌  | 5028/6689 [00:15<00:05, 314.79 examples/s]Tokenizing train dataset:  74%|███████▍  | 4975/6689 [00:15<00:05, 291.40 examples/s]Tokenizing train dataset:  67%|██████▋   | 4490/6689 [00:14<00:06, 337.32 examples/s]Tokenizing train dataset:  76%|███████▌  | 5069/6689 [00:15<00:04, 330.59 examples/s]Tokenizing train dataset:  75%|███████▌  | 5027/6689 [00:15<00:04, 339.17 examples/s]Tokenizing train dataset:  68%|██████▊   | 4540/6689 [00:14<00:06, 320.97 examples/s]Tokenizing train dataset:  77%|███████▋  | 5121/6689 [00:16<00:05, 307.28 examples/s]Tokenizing train dataset:  76%|███████▌  | 5074/6689 [00:16<00:05, 307.59 examples/s]Tokenizing train dataset:  68%|██████▊   | 4576/6689 [00:15<00:06, 326.72 examples/s]Tokenizing train dataset:  77%|███████▋  | 5173/6689 [00:16<00:04, 351.19 examples/s]Tokenizing train dataset:  77%|███████▋  | 5122/6689 [00:16<00:05, 272.03 examples/s]Tokenizing train dataset:  77%|███████▋  | 5155/6689 [00:16<00:06, 251.83 examples/s]Tokenizing train dataset:  69%|██████▉   | 4622/6689 [00:15<00:09, 224.37 examples/s]Tokenizing train dataset:  78%|███████▊  | 5231/6689 [00:16<00:05, 266.06 examples/s]Tokenizing train dataset:  78%|███████▊  | 5203/6689 [00:16<00:05, 294.91 examples/s]Tokenizing train dataset:  70%|██████▉   | 4666/6689 [00:15<00:07, 259.48 examples/s]Tokenizing train dataset:  79%|███████▉  | 5276/6689 [00:16<00:04, 297.40 examples/s]Tokenizing train dataset:  78%|███████▊  | 5248/6689 [00:16<00:04, 326.77 examples/s]Tokenizing train dataset:  70%|███████   | 4710/6689 [00:15<00:06, 294.20 examples/s]Tokenizing train dataset:  79%|███████▉  | 5317/6689 [00:16<00:04, 319.29 examples/s]Tokenizing train dataset:  79%|███████▉  | 5306/6689 [00:16<00:04, 341.48 examples/s]Tokenizing train dataset:  71%|███████▏  | 4772/6689 [00:15<00:05, 326.58 examples/s]Tokenizing train dataset:  80%|████████  | 5367/6689 [00:16<00:04, 298.06 examples/s]Tokenizing train dataset:  80%|████████  | 5356/6689 [00:17<00:04, 298.79 examples/s]Tokenizing train dataset:  72%|███████▏  | 4820/6689 [00:15<00:06, 293.54 examples/s]Tokenizing train dataset:  81%|████████  | 5390/6689 [00:17<00:04, 306.04 examples/s]Tokenizing train dataset:  81%|████████  | 5412/6689 [00:17<00:05, 245.93 examples/s]Tokenizing train dataset:  73%|███████▎  | 4877/6689 [00:16<00:05, 314.97 examples/s]Tokenizing train dataset:  81%|████████▏ | 5442/6689 [00:17<00:04, 254.95 examples/s]Tokenizing train dataset:  81%|████████▏ | 5435/6689 [00:17<00:04, 301.11 examples/s]Tokenizing train dataset:  74%|███████▎  | 4923/6689 [00:16<00:06, 260.26 examples/s]Tokenizing train dataset:  82%|████████▏ | 5498/6689 [00:17<00:06, 197.64 examples/s]Tokenizing train dataset:  82%|████████▏ | 5492/6689 [00:17<00:05, 210.92 examples/s]Tokenizing train dataset:  74%|███████▍  | 4973/6689 [00:16<00:07, 227.49 examples/s]Tokenizing train dataset:  83%|████████▎ | 5537/6689 [00:17<00:05, 225.10 examples/s]Tokenizing train dataset:  83%|████████▎ | 5538/6689 [00:17<00:04, 248.49 examples/s]Tokenizing train dataset:  75%|███████▍  | 5006/6689 [00:16<00:07, 239.44 examples/s]Tokenizing train dataset:  83%|████████▎ | 5566/6689 [00:17<00:04, 232.42 examples/s]Tokenizing train dataset:  83%|████████▎ | 5585/6689 [00:17<00:03, 288.29 examples/s]Tokenizing train dataset:  75%|███████▌  | 5048/6689 [00:16<00:07, 231.44 examples/s]Tokenizing train dataset:  84%|████████▍ | 5621/6689 [00:18<00:04, 248.39 examples/s]Tokenizing train dataset:  84%|████████▍ | 5641/6689 [00:18<00:03, 307.11 examples/s]Tokenizing train dataset:  76%|███████▌  | 5099/6689 [00:17<00:06, 255.14 examples/s]Tokenizing train dataset:  85%|████████▍ | 5672/6689 [00:18<00:03, 268.31 examples/s]Tokenizing train dataset:  85%|████████▌ | 5695/6689 [00:18<00:03, 293.40 examples/s]Tokenizing train dataset:  85%|████████▌ | 5705/6689 [00:18<00:03, 278.18 examples/s]Tokenizing train dataset:  77%|███████▋  | 5151/6689 [00:17<00:05, 278.13 examples/s]Tokenizing train dataset:  86%|████████▌ | 5730/6689 [00:18<00:03, 302.80 examples/s]Tokenizing train dataset:  86%|████████▌ | 5740/6689 [00:18<00:03, 292.54 examples/s]Tokenizing train dataset:  78%|███████▊  | 5202/6689 [00:17<00:05, 285.82 examples/s]Tokenizing train dataset:  86%|████████▋ | 5783/6689 [00:18<00:02, 304.95 examples/s]Tokenizing train dataset:  87%|████████▋ | 5792/6689 [00:18<00:03, 255.26 examples/s]Tokenizing train dataset:  79%|███████▊  | 5260/6689 [00:17<00:04, 303.98 examples/s]Tokenizing train dataset:  87%|████████▋ | 5830/6689 [00:18<00:02, 291.85 examples/s]Tokenizing train dataset:  87%|████████▋ | 5830/6689 [00:18<00:03, 279.10 examples/s]Tokenizing train dataset:  79%|███████▉  | 5299/6689 [00:17<00:04, 320.01 examples/s]Tokenizing train dataset:  88%|████████▊ | 5872/6689 [00:18<00:02, 313.94 examples/s]Tokenizing train dataset:  80%|███████▉  | 5338/6689 [00:17<00:04, 334.97 examples/s]Tokenizing train dataset:  88%|████████▊ | 5882/6689 [00:19<00:02, 297.56 examples/s]Tokenizing train dataset:  88%|████████▊ | 5913/6689 [00:19<00:02, 334.29 examples/s]Tokenizing train dataset:  80%|████████  | 5380/6689 [00:18<00:05, 230.98 examples/s]Tokenizing train dataset:  89%|████████▊ | 5934/6689 [00:19<00:03, 229.39 examples/s]Tokenizing train dataset:  89%|████████▉ | 5971/6689 [00:19<00:03, 214.85 examples/s]Tokenizing train dataset:  81%|████████  | 5420/6689 [00:18<00:06, 182.53 examples/s]Tokenizing train dataset:  89%|████████▉ | 5967/6689 [00:19<00:04, 166.75 examples/s]Tokenizing train dataset:  81%|████████▏ | 5450/6689 [00:18<00:06, 188.33 examples/s]Tokenizing train dataset:  90%|████████▉ | 6020/6689 [00:19<00:03, 184.31 examples/s]Tokenizing train dataset:  90%|████████▉ | 6005/6689 [00:19<00:03, 196.91 examples/s]Tokenizing train dataset:  82%|████████▏ | 5476/6689 [00:18<00:06, 194.72 examples/s]Tokenizing train dataset:  90%|█████████ | 6048/6689 [00:19<00:03, 183.94 examples/s]Tokenizing train dataset:  82%|████████▏ | 5501/6689 [00:18<00:07, 167.55 examples/s]Tokenizing train dataset:  91%|█████████ | 6058/6689 [00:20<00:03, 181.02 examples/s]Tokenizing train dataset:  91%|█████████ | 6077/6689 [00:20<00:03, 174.15 examples/s]Tokenizing train dataset:  83%|████████▎ | 5546/6689 [00:19<00:05, 218.69 examples/s]Tokenizing train dataset:  91%|█████████ | 6085/6689 [00:20<00:03, 185.36 examples/s]Tokenizing train dataset:  91%|█████████ | 6100/6689 [00:20<00:03, 165.04 examples/s]Tokenizing train dataset:  91%|█████████▏| 6112/6689 [00:20<00:02, 193.04 examples/s]Tokenizing train dataset:  84%|████████▎ | 5590/6689 [00:19<00:05, 215.75 examples/s]Tokenizing train dataset:  92%|█████████▏| 6131/6689 [00:20<00:03, 185.89 examples/s]Tokenizing train dataset:  92%|█████████▏| 6172/6689 [00:20<00:01, 268.80 examples/s]Tokenizing train dataset:  84%|████████▍ | 5638/6689 [00:19<00:03, 264.22 examples/s]Tokenizing train dataset:  92%|█████████▏| 6167/6689 [00:20<00:02, 218.23 examples/s]Tokenizing train dataset:  93%|█████████▎| 6235/6689 [00:20<00:01, 310.29 examples/s]Tokenizing train dataset:  93%|█████████▎| 6196/6689 [00:20<00:02, 219.93 examples/s]Tokenizing train dataset:  85%|████████▌ | 5688/6689 [00:19<00:03, 277.88 examples/s]Tokenizing train dataset:  94%|█████████▍| 6287/6689 [00:20<00:01, 352.94 examples/s]Tokenizing train dataset:  94%|█████████▎| 6255/6689 [00:20<00:01, 300.85 examples/s]Tokenizing train dataset:  86%|████████▌ | 5729/6689 [00:19<00:03, 301.85 examples/s]Tokenizing train dataset:  95%|█████████▍| 6340/6689 [00:20<00:01, 345.08 examples/s]Tokenizing train dataset:  94%|█████████▍| 6306/6689 [00:20<00:01, 304.88 examples/s]Tokenizing train dataset:  86%|████████▋ | 5779/6689 [00:19<00:03, 255.01 examples/s]Tokenizing train dataset:  95%|█████████▌| 6385/6689 [00:21<00:01, 278.47 examples/s]Tokenizing train dataset:  95%|█████████▌| 6355/6689 [00:21<00:01, 251.58 examples/s]Tokenizing train dataset:  87%|████████▋ | 5826/6689 [00:20<00:03, 256.76 examples/s]Tokenizing train dataset:  96%|█████████▌| 6424/6689 [00:21<00:00, 299.92 examples/s]Tokenizing train dataset:  95%|█████████▌| 6385/6689 [00:21<00:01, 260.61 examples/s]Tokenizing train dataset:  88%|████████▊ | 5866/6689 [00:20<00:02, 282.31 examples/s]Tokenizing train dataset:  97%|█████████▋| 6475/6689 [00:21<00:00, 302.08 examples/s]Tokenizing train dataset:  96%|█████████▌| 6432/6689 [00:21<00:00, 273.21 examples/s]Tokenizing train dataset:  88%|████████▊ | 5910/6689 [00:20<00:02, 274.34 examples/s]Tokenizing train dataset:  98%|█████████▊| 6537/6689 [00:21<00:00, 332.56 examples/s]Tokenizing train dataset:  89%|████████▉ | 5946/6689 [00:20<00:02, 290.03 examples/s]Tokenizing train dataset:  97%|█████████▋| 6486/6689 [00:21<00:00, 288.06 examples/s]Tokenizing train dataset:  89%|████████▉ | 5978/6689 [00:20<00:02, 294.49 examples/s]Tokenizing train dataset:  99%|█████████▊| 6589/6689 [00:21<00:00, 327.21 examples/s]Tokenizing train dataset:  98%|█████████▊| 6543/6689 [00:21<00:00, 311.92 examples/s]Tokenizing train dataset:  90%|████████▉ | 6013/6689 [00:20<00:02, 301.42 examples/s]Tokenizing train dataset:  99%|█████████▉| 6639/6689 [00:21<00:00, 363.12 examples/s]Tokenizing train dataset:  98%|█████████▊| 6577/6689 [00:21<00:00, 317.19 examples/s]Tokenizing train dataset:  91%|█████████ | 6056/6689 [00:20<00:01, 330.28 examples/s]Tokenizing train dataset: 100%|█████████▉| 6682/6689 [00:21<00:00, 376.40 examples/s]Tokenizing train dataset:  99%|█████████▉| 6623/6689 [00:21<00:00, 349.92 examples/s]Tokenizing train dataset:  91%|█████████▏| 6109/6689 [00:20<00:01, 336.02 examples/s]Tokenizing train dataset: 100%|██████████| 6689/6689 [00:22<00:00, 302.08 examples/s]
Tokenizing train dataset: 100%|█████████▉| 6673/6689 [00:22<00:00, 288.60 examples/s]Tokenizing train dataset:  92%|█████████▏| 6175/6689 [00:21<00:01, 359.02 examples/s]Tokenizing train dataset: 100%|██████████| 6689/6689 [00:22<00:00, 300.26 examples/s]
Tokenizing train dataset:  93%|█████████▎| 6214/6689 [00:21<00:01, 363.71 examples/s]Tokenizing train dataset:  94%|█████████▍| 6275/6689 [00:21<00:01, 343.93 examples/s]Tokenizing train dataset:  94%|█████████▍| 6317/6689 [00:21<00:01, 357.41 examples/s]Tokenizing train dataset:  95%|█████████▌| 6358/6689 [00:21<00:00, 367.73 examples/s]Tokenizing train dataset:  96%|█████████▌| 6413/6689 [00:21<00:00, 360.81 examples/s]Tokenizing train dataset:  96%|█████████▋| 6454/6689 [00:21<00:00, 369.67 examples/s]Tokenizing train dataset:  97%|█████████▋| 6507/6689 [00:22<00:00, 360.57 examples/s]Tokenizing train dataset:  98%|█████████▊| 6549/6689 [00:22<00:00, 372.64 examples/s]Tokenizing train dataset:  99%|█████████▉| 6610/6689 [00:22<00:00, 378.94 examples/s]Tokenizing train dataset:  99%|█████████▉| 6653/6689 [00:22<00:00, 388.82 examples/s]Tokenizing train dataset: 100%|██████████| 6689/6689 [00:22<00:00, 297.20 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Extracting prompt in eval dataset:  59%|█████▉    | 563/953 [00:00<00:00, 5593.28 examples/s]Set up DPO trainer
Extracting prompt in eval dataset:  59%|█████▉    | 562/953 [00:00<00:00, 5584.73 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 563/953 [00:00<00:00, 5590.50 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4499.22 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2973.59 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3020.15 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  28%|██▊       | 266/953 [00:00<00:00, 2631.91 examples/s]Applying chat template to eval dataset:  28%|██▊       | 267/953 [00:00<00:00, 2638.53 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  69%|██████▉   | 660/953 [00:00<00:00, 2609.57 examples/s]Applying chat template to eval dataset:  62%|██████▏   | 592/953 [00:00<00:00, 2309.18 examples/s]Applying chat template to eval dataset:  26%|██▋       | 251/953 [00:00<00:00, 2481.16 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2446.45 examples/s]Applying chat template to eval dataset:  98%|█████████▊| 934/953 [00:00<00:00, 2290.51 examples/s]Applying chat template to eval dataset:  54%|█████▎    | 510/953 [00:00<00:00, 942.44 examples/s] Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 960.67 examples/s] 
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 968.68 examples/s] 
Applying chat template to eval dataset:  81%|████████  | 771/953 [00:00<00:00, 761.58 examples/s]Applying chat template to eval dataset:  95%|█████████▌| 908/953 [00:01<00:00, 820.64 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:01<00:00, 877.15 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 265.79 examples/s]Tokenizing eval dataset:   3%|▎         | 29/953 [00:00<00:03, 283.11 examples/s]Tokenizing eval dataset:   6%|▌         | 54/953 [00:00<00:06, 146.05 examples/s]Tokenizing eval dataset:   7%|▋         | 67/953 [00:00<00:05, 154.80 examples/s]Tokenizing eval dataset:   8%|▊         | 73/953 [00:00<00:05, 153.88 examples/s]Tokenizing eval dataset:   9%|▉         | 87/953 [00:00<00:05, 164.68 examples/s]Tokenizing eval dataset:  10%|▉         | 93/953 [00:00<00:05, 165.96 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:  11%|█▏        | 109/953 [00:00<00:04, 177.12 examples/s]Tokenizing eval dataset:   3%|▎         | 25/953 [00:00<00:03, 234.30 examples/s]Tokenizing eval dataset:  13%|█▎        | 121/953 [00:00<00:04, 169.19 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:00<00:04, 181.07 examples/s]Tokenizing eval dataset:  16%|█▌        | 148/953 [00:00<00:04, 170.10 examples/s]Tokenizing eval dataset:   6%|▌         | 54/953 [00:00<00:04, 198.58 examples/s]Tokenizing eval dataset:  17%|█▋        | 161/953 [00:01<00:05, 132.35 examples/s]Tokenizing eval dataset:  18%|█▊        | 174/953 [00:01<00:06, 113.04 examples/s]Tokenizing eval dataset:   9%|▉         | 85/953 [00:00<00:07, 115.24 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:06, 126.27 examples/s]Tokenizing eval dataset:  20%|██        | 195/953 [00:01<00:05, 128.71 examples/s]Tokenizing eval dataset:  12%|█▏        | 112/953 [00:00<00:06, 124.92 examples/s]Tokenizing eval dataset:  23%|██▎       | 215/953 [00:01<00:05, 130.79 examples/s]Tokenizing eval dataset:  26%|██▌       | 249/953 [00:01<00:04, 168.82 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:01<00:04, 144.13 examples/s]Tokenizing eval dataset:  15%|█▍        | 139/953 [00:01<00:06, 133.18 examples/s]Tokenizing eval dataset:  32%|███▏      | 303/953 [00:01<00:02, 245.14 examples/s]Tokenizing eval dataset:  30%|███       | 287/953 [00:01<00:03, 211.76 examples/s]Tokenizing eval dataset:  17%|█▋        | 159/953 [00:01<00:05, 145.83 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:01<00:02, 257.83 examples/s]Tokenizing eval dataset:  33%|███▎      | 319/953 [00:01<00:02, 228.36 examples/s]Tokenizing eval dataset:  19%|█▉        | 182/953 [00:01<00:05, 146.50 examples/s]Tokenizing eval dataset:  37%|███▋      | 351/953 [00:01<00:02, 227.16 examples/s]Tokenizing eval dataset:  22%|██▏       | 205/953 [00:01<00:04, 160.85 examples/s]Tokenizing eval dataset:  42%|████▏     | 400/953 [00:01<00:01, 281.76 examples/s]Tokenizing eval dataset:  41%|████      | 392/953 [00:02<00:02, 266.27 examples/s]Tokenizing eval dataset:  46%|████▌     | 438/953 [00:02<00:01, 279.20 examples/s]Tokenizing eval dataset:  45%|████▌     | 432/953 [00:02<00:01, 297.99 examples/s]Tokenizing eval dataset:  26%|██▌       | 250/953 [00:01<00:03, 188.76 examples/s]Tokenizing eval dataset:  51%|█████▏    | 489/953 [00:02<00:01, 328.11 examples/s]Tokenizing eval dataset:  52%|█████▏    | 494/953 [00:02<00:01, 374.91 examples/s]Tokenizing eval dataset:  30%|██▉       | 284/953 [00:01<00:03, 196.61 examples/s]Tokenizing eval dataset:  59%|█████▊    | 558/953 [00:02<00:01, 340.53 examples/s]Tokenizing eval dataset:  33%|███▎      | 312/953 [00:01<00:03, 183.74 examples/s]Tokenizing eval dataset:  63%|██████▎   | 597/953 [00:02<00:01, 347.82 examples/s]Tokenizing eval dataset:  59%|█████▉    | 562/953 [00:02<00:01, 301.32 examples/s]Tokenizing eval dataset:  36%|███▋      | 346/953 [00:02<00:03, 197.36 examples/s]Tokenizing eval dataset:  69%|██████▉   | 660/953 [00:02<00:00, 328.05 examples/s]Tokenizing eval dataset:  66%|██████▌   | 628/953 [00:02<00:01, 309.13 examples/s]Tokenizing eval dataset:  40%|████      | 383/953 [00:02<00:02, 232.94 examples/s]Tokenizing eval dataset:  75%|███████▌  | 717/953 [00:02<00:00, 376.35 examples/s]Tokenizing eval dataset:  70%|███████   | 669/953 [00:02<00:00, 327.56 examples/s]Tokenizing eval dataset:  45%|████▌     | 431/953 [00:02<00:01, 286.84 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:02<00:01, 251.24 examples/s]Tokenizing eval dataset:  81%|████████  | 774/953 [00:03<00:00, 322.46 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:03<00:00, 297.98 examples/s]Tokenizing eval dataset:  55%|█████▍    | 522/953 [00:02<00:01, 311.85 examples/s]Tokenizing eval dataset:  86%|████████▋ | 824/953 [00:03<00:00, 320.59 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:03<00:00, 284.21 examples/s]Tokenizing eval dataset:  59%|█████▊    | 558/953 [00:02<00:01, 280.43 examples/s]Tokenizing eval dataset:  92%|█████████▏| 875/953 [00:03<00:00, 318.11 examples/s]Tokenizing eval dataset:  87%|████████▋ | 833/953 [00:03<00:00, 258.20 examples/s]Tokenizing eval dataset:  65%|██████▌   | 620/953 [00:02<00:01, 283.91 examples/s]Tokenizing eval dataset:  97%|█████████▋| 924/953 [00:03<00:00, 318.95 examples/s]Tokenizing eval dataset:  92%|█████████▏| 878/953 [00:03<00:00, 288.97 examples/s]Tokenizing eval dataset:  70%|██████▉   | 665/953 [00:03<00:00, 317.61 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 259.85 examples/s]
Tokenizing eval dataset:  96%|█████████▌| 914/953 [00:03<00:00, 301.78 examples/s]Tokenizing eval dataset:  73%|███████▎  | 700/953 [00:03<00:00, 321.33 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 306.51 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 244.43 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  79%|███████▊  | 750/953 [00:03<00:00, 316.23 examples/s]Tokenizing eval dataset:  84%|████████▎ | 796/953 [00:03<00:00, 346.64 examples/s]Tokenizing eval dataset:  89%|████████▉ | 848/953 [00:03<00:00, 268.22 examples/s]Tokenizing eval dataset:  95%|█████████▍| 904/953 [00:03<00:00, 293.25 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:03<00:00, 308.63 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:04<00:00, 236.37 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.708237648010254 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...

Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.8423056602478027 seconds
Time to load cpu_adam op: 2.869985342025757 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.5101749897003174 seconds
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250612_183107-fn0pla4p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Curriculum-1-DPO_r-64_lr-4e-07_e-3_b-0.1
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/fn0pla4p
  0%|          | 0/1674 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/1674 [00:15<7:04:03, 15.21s/it]  0%|          | 2/1674 [00:18<3:40:16,  7.90s/it]  0%|          | 3/1674 [00:20<2:34:13,  5.54s/it]  0%|          | 4/1674 [00:24<2:11:39,  4.73s/it]  0%|          | 5/1674 [00:27<1:55:26,  4.15s/it]  0%|          | 6/1674 [00:29<1:39:00,  3.56s/it]  0%|          | 7/1674 [00:33<1:44:57,  3.78s/it]  0%|          | 8/1674 [00:36<1:30:53,  3.27s/it]  1%|          | 9/1674 [00:38<1:24:58,  3.06s/it]  1%|          | 10/1674 [00:41<1:22:31,  2.98s/it]                                                   {'loss': 0.6955, 'grad_norm': 33.89420700073242, 'learning_rate': 4.30622009569378e-09, 'rewards/chosen': -0.0051437378861010075, 'rewards/rejected': -0.0011442810064181685, 'rewards/accuracies': 0.32500001788139343, 'rewards/margins': -0.003997802734375, 'logps/chosen': -115.5999984741211, 'logps/rejected': -127.3499984741211, 'logits/chosen': -6.159375190734863, 'logits/rejected': -6.096875190734863, 'epoch': 0.02}
  1%|          | 10/1674 [00:41<1:22:31,  2.98s/it]  1%|          | 11/1674 [00:45<1:32:00,  3.32s/it]  1%|          | 12/1674 [00:49<1:33:48,  3.39s/it]  1%|          | 13/1674 [00:51<1:21:47,  2.95s/it]  1%|          | 14/1674 [00:54<1:28:03,  3.18s/it]  1%|          | 15/1674 [00:57<1:20:57,  2.93s/it]  1%|          | 16/1674 [00:59<1:15:41,  2.74s/it]  1%|          | 17/1674 [01:01<1:13:05,  2.65s/it]  1%|          | 18/1674 [01:05<1:21:48,  2.96s/it]  1%|          | 19/1674 [01:09<1:26:47,  3.15s/it]  1%|          | 20/1674 [01:12<1:25:23,  3.10s/it]                                                   {'loss': 0.6944, 'grad_norm': 29.504640579223633, 'learning_rate': 9.09090909090909e-09, 'rewards/chosen': 0.0042205811478197575, 'rewards/rejected': 0.0052505494095385075, 'rewards/accuracies': 0.4166666567325592, 'rewards/margins': -0.0010009765392169356, 'logps/chosen': -85.125, 'logps/rejected': -89.88749694824219, 'logits/chosen': -6.012499809265137, 'logits/rejected': -6.203125, 'epoch': 0.04}
  1%|          | 20/1674 [01:12<1:25:23,  3.10s/it]  1%|▏         | 21/1674 [01:15<1:30:32,  3.29s/it]  1%|▏         | 22/1674 [01:17<1:19:15,  2.88s/it]  1%|▏         | 23/1674 [01:21<1:25:40,  3.11s/it]  1%|▏         | 24/1674 [01:23<1:19:28,  2.89s/it]  1%|▏         | 25/1674 [01:26<1:14:31,  2.71s/it]  2%|▏         | 26/1674 [01:29<1:16:10,  2.77s/it]  2%|▏         | 27/1674 [01:31<1:17:06,  2.81s/it]  2%|▏         | 28/1674 [01:34<1:17:54,  2.84s/it]  2%|▏         | 29/1674 [01:37<1:13:34,  2.68s/it]  2%|▏         | 30/1674 [01:41<1:25:29,  3.12s/it]                                                   {'loss': 0.6874, 'grad_norm': 26.89952850341797, 'learning_rate': 1.3875598086124401e-08, 'rewards/chosen': 0.0007465362432412803, 'rewards/rejected': -0.00998840294778347, 'rewards/accuracies': 0.46666663885116577, 'rewards/margins': 0.01076355017721653, 'logps/chosen': -68.19999694824219, 'logps/rejected': -89.5, 'logits/chosen': -6.084374904632568, 'logits/rejected': -5.956250190734863, 'epoch': 0.05}
  2%|▏         | 30/1674 [01:41<1:25:29,  3.12s/it]  2%|▏         | 31/1674 [01:45<1:32:14,  3.37s/it]  2%|▏         | 32/1674 [01:47<1:20:15,  2.93s/it]  2%|▏         | 33/1674 [01:49<1:11:49,  2.63s/it]  2%|▏         | 34/1674 [01:52<1:17:47,  2.85s/it]  2%|▏         | 35/1674 [01:55<1:19:43,  2.92s/it]  2%|▏         | 36/1674 [01:57<1:13:27,  2.69s/it]  2%|▏         | 37/1674 [02:01<1:23:31,  3.06s/it]  2%|▏         | 38/1674 [02:04<1:19:59,  2.93s/it]  2%|▏         | 39/1674 [02:07<1:18:35,  2.88s/it]  2%|▏         | 40/1674 [02:11<1:29:04,  3.27s/it]                                                   {'loss': 0.6966, 'grad_norm': 34.744285583496094, 'learning_rate': 1.8660287081339712e-08, 'rewards/chosen': -0.01052932720631361, 'rewards/rejected': -0.0038406371604651213, 'rewards/accuracies': 0.3999999761581421, 'rewards/margins': -0.006701147649437189, 'logps/chosen': -121.2249984741211, 'logps/rejected': -119.4749984741211, 'logits/chosen': -5.865624904632568, 'logits/rejected': -5.990624904632568, 'epoch': 0.07}
  2%|▏         | 40/1674 [02:11<1:29:04,  3.27s/it]  2%|▏         | 41/1674 [02:12<1:15:36,  2.78s/it]  3%|▎         | 42/1674 [02:15<1:15:30,  2.78s/it]  3%|▎         | 43/1674 [02:18<1:19:07,  2.91s/it]  3%|▎         | 44/1674 [02:22<1:24:08,  3.10s/it]  3%|▎         | 45/1674 [02:26<1:32:56,  3.42s/it]  3%|▎         | 46/1674 [02:29<1:31:42,  3.38s/it]  3%|▎         | 47/1674 [02:32<1:24:53,  3.13s/it]  3%|▎         | 48/1674 [02:34<1:14:38,  2.75s/it]  3%|▎         | 49/1674 [02:36<1:14:16,  2.74s/it]  3%|▎         | 50/1674 [02:40<1:20:37,  2.98s/it]                                                   {'loss': 0.6959, 'grad_norm': 22.678955078125, 'learning_rate': 2.3444976076555025e-08, 'rewards/chosen': 0.00817947369068861, 'rewards/rejected': 0.01036148052662611, 'rewards/accuracies': 0.40833336114883423, 'rewards/margins': -0.002140045166015625, 'logps/chosen': -72.69999694824219, 'logps/rejected': -77.0, 'logits/chosen': -6.087500095367432, 'logits/rejected': -6.081250190734863, 'epoch': 0.09}
  3%|▎         | 50/1674 [02:40<1:20:37,  2.98s/it]  3%|▎         | 51/1674 [02:44<1:24:57,  3.14s/it]  3%|▎         | 52/1674 [02:47<1:25:21,  3.16s/it]  3%|▎         | 53/1674 [02:50<1:24:12,  3.12s/it]  3%|▎         | 54/1674 [02:52<1:20:05,  2.97s/it]  3%|▎         | 55/1674 [02:56<1:24:07,  3.12s/it]  3%|▎         | 56/1674 [02:59<1:24:00,  3.12s/it]  3%|▎         | 57/1674 [03:01<1:19:02,  2.93s/it]  3%|▎         | 58/1674 [03:04<1:18:04,  2.90s/it]  4%|▎         | 59/1674 [03:07<1:14:48,  2.78s/it]  4%|▎         | 60/1674 [03:10<1:17:44,  2.89s/it]                                                   {'loss': 0.702, 'grad_norm': 28.63726806640625, 'learning_rate': 2.822966507177033e-08, 'rewards/chosen': -0.0067268372513353825, 'rewards/rejected': 0.01054992713034153, 'rewards/accuracies': 0.366666704416275, 'rewards/margins': -0.017284393310546875, 'logps/chosen': -82.4000015258789, 'logps/rejected': -92.17500305175781, 'logits/chosen': -6.309374809265137, 'logits/rejected': -6.324999809265137, 'epoch': 0.11}
  4%|▎         | 60/1674 [03:10<1:17:44,  2.89s/it]  4%|▎         | 61/1674 [03:12<1:13:20,  2.73s/it]  4%|▎         | 62/1674 [03:15<1:16:25,  2.84s/it]  4%|▍         | 63/1674 [03:18<1:13:02,  2.72s/it]  4%|▍         | 64/1674 [03:21<1:13:41,  2.75s/it]  4%|▍         | 65/1674 [03:23<1:06:41,  2.49s/it]  4%|▍         | 66/1674 [03:26<1:18:21,  2.92s/it]  4%|▍         | 67/1674 [03:29<1:15:11,  2.81s/it]  4%|▍         | 68/1674 [03:33<1:23:16,  3.11s/it]  4%|▍         | 69/1674 [03:37<1:31:08,  3.41s/it]  4%|▍         | 70/1674 [03:41<1:35:47,  3.58s/it]                                                   {'loss': 0.7021, 'grad_norm': 27.0100154876709, 'learning_rate': 3.301435406698564e-08, 'rewards/chosen': -0.01355133019387722, 'rewards/rejected': 0.001049041748046875, 'rewards/accuracies': 0.3500000238418579, 'rewards/margins': -0.01457316242158413, 'logps/chosen': -108.94999694824219, 'logps/rejected': -123.30000305175781, 'logits/chosen': -5.965624809265137, 'logits/rejected': -5.809374809265137, 'epoch': 0.13}
  4%|▍         | 70/1674 [03:41<1:35:47,  3.58s/it]  4%|▍         | 71/1674 [03:45<1:36:02,  3.59s/it]  4%|▍         | 72/1674 [03:48<1:37:00,  3.63s/it]  4%|▍         | 73/1674 [03:52<1:40:32,  3.77s/it]  4%|▍         | 74/1674 [03:56<1:40:29,  3.77s/it]  4%|▍         | 75/1674 [03:59<1:29:57,  3.38s/it]  5%|▍         | 76/1674 [04:01<1:22:46,  3.11s/it]  5%|▍         | 77/1674 [04:05<1:26:09,  3.24s/it]  5%|▍         | 78/1674 [04:07<1:23:11,  3.13s/it]  5%|▍         | 79/1674 [04:09<1:09:40,  2.62s/it]  5%|▍         | 80/1674 [04:12<1:17:02,  2.90s/it]                                                   {'loss': 0.6956, 'grad_norm': 40.37334060668945, 'learning_rate': 3.7799043062200955e-08, 'rewards/chosen': -0.0002574920654296875, 'rewards/rejected': 0.0037025450728833675, 'rewards/accuracies': 0.40000003576278687, 'rewards/margins': -0.00400543212890625, 'logps/chosen': -75.1624984741211, 'logps/rejected': -94.63749694824219, 'logits/chosen': -6.056250095367432, 'logits/rejected': -5.978125095367432, 'epoch': 0.14}
  5%|▍         | 80/1674 [04:13<1:17:02,  2.90s/it]  5%|▍         | 81/1674 [04:16<1:20:28,  3.03s/it]  5%|▍         | 82/1674 [04:18<1:13:24,  2.77s/it]  5%|▍         | 83/1674 [04:21<1:16:16,  2.88s/it]  5%|▌         | 84/1674 [04:24<1:15:25,  2.85s/it]  5%|▌         | 85/1674 [04:28<1:26:37,  3.27s/it]  5%|▌         | 86/1674 [04:30<1:16:03,  2.87s/it]  5%|▌         | 87/1674 [04:33<1:18:59,  2.99s/it]  5%|▌         | 88/1674 [04:35<1:08:00,  2.57s/it]  5%|▌         | 89/1674 [04:39<1:18:58,  2.99s/it]  5%|▌         | 90/1674 [04:43<1:26:57,  3.29s/it]                                                   {'loss': 0.6898, 'grad_norm': 73.0661849975586, 'learning_rate': 4.258373205741627e-08, 'rewards/chosen': -0.0027267455589026213, 'rewards/rejected': -0.007657242007553577, 'rewards/accuracies': 0.5083333253860474, 'rewards/margins': 0.0049423216842114925, 'logps/chosen': -136.375, 'logps/rejected': -134.0, 'logits/chosen': -6.112500190734863, 'logits/rejected': -5.987500190734863, 'epoch': 0.16}
  5%|▌         | 90/1674 [04:43<1:26:57,  3.29s/it]  5%|▌         | 91/1674 [04:46<1:27:29,  3.32s/it]  5%|▌         | 92/1674 [04:50<1:27:50,  3.33s/it]  6%|▌         | 93/1674 [04:52<1:22:22,  3.13s/it]  6%|▌         | 94/1674 [04:55<1:18:34,  2.98s/it]  6%|▌         | 95/1674 [04:58<1:20:50,  3.07s/it]  6%|▌         | 96/1674 [05:02<1:26:25,  3.29s/it]  6%|▌         | 97/1674 [05:05<1:26:21,  3.29s/it]  6%|▌         | 98/1674 [05:08<1:20:50,  3.08s/it]  6%|▌         | 99/1674 [05:12<1:28:33,  3.37s/it]  6%|▌         | 100/1674 [05:14<1:22:15,  3.14s/it]                                                    {'loss': 0.6936, 'grad_norm': 25.721023559570312, 'learning_rate': 4.736842105263157e-08, 'rewards/chosen': -0.0030876160599291325, 'rewards/rejected': -0.0062240599654614925, 'rewards/accuracies': 0.4583333432674408, 'rewards/margins': 0.0031497955787926912, 'logps/chosen': -85.67500305175781, 'logps/rejected': -92.8499984741211, 'logits/chosen': -6.128125190734863, 'logits/rejected': -6.165625095367432, 'epoch': 0.18}
  6%|▌         | 100/1674 [05:15<1:22:15,  3.14s/it]  6%|▌         | 101/1674 [05:19<1:29:21,  3.41s/it]  6%|▌         | 102/1674 [05:20<1:17:10,  2.95s/it]  6%|▌         | 103/1674 [05:24<1:21:33,  3.11s/it]  6%|▌         | 104/1674 [05:28<1:28:14,  3.37s/it]  6%|▋         | 105/1674 [05:32<1:32:42,  3.55s/it]  6%|▋         | 106/1674 [05:35<1:26:39,  3.32s/it]  6%|▋         | 107/1674 [05:38<1:23:46,  3.21s/it]  6%|▋         | 108/1674 [05:40<1:19:35,  3.05s/it]  7%|▋         | 109/1674 [05:43<1:15:06,  2.88s/it]  7%|▋         | 110/1674 [05:46<1:16:06,  2.92s/it]                                                    {'loss': 0.6893, 'grad_norm': 22.22701072692871, 'learning_rate': 5.2153110047846885e-08, 'rewards/chosen': 0.012418365105986595, 'rewards/rejected': 0.00014419555373024195, 'rewards/accuracies': 0.533333420753479, 'rewards/margins': 0.012287139892578125, 'logps/chosen': -76.57499694824219, 'logps/rejected': -101.82499694824219, 'logits/chosen': -6.115624904632568, 'logits/rejected': -6.009375095367432, 'epoch': 0.2}
  7%|▋         | 110/1674 [05:46<1:16:06,  2.92s/it]  7%|▋         | 111/1674 [05:48<1:12:50,  2.80s/it]  7%|▋         | 112/1674 [05:50<1:05:42,  2.52s/it]  7%|▋         | 113/1674 [05:53<1:07:24,  2.59s/it]  7%|▋         | 114/1674 [05:56<1:13:51,  2.84s/it]  7%|▋         | 115/1674 [06:00<1:17:20,  2.98s/it]  7%|▋         | 116/1674 [06:02<1:12:20,  2.79s/it]  7%|▋         | 117/1674 [06:06<1:20:21,  3.10s/it]  7%|▋         | 118/1674 [06:08<1:14:55,  2.89s/it]  7%|▋         | 119/1674 [06:10<1:09:09,  2.67s/it]  7%|▋         | 120/1674 [06:13<1:06:20,  2.56s/it]                                                    {'loss': 0.6973, 'grad_norm': 29.731201171875, 'learning_rate': 5.69377990430622e-08, 'rewards/chosen': -0.00675125140696764, 'rewards/rejected': 0.001129150390625, 'rewards/accuracies': 0.44166669249534607, 'rewards/margins': -0.007907104678452015, 'logps/chosen': -78.44999694824219, 'logps/rejected': -87.05000305175781, 'logits/chosen': -6.171875, 'logits/rejected': -6.034375190734863, 'epoch': 0.22}
  7%|▋         | 120/1674 [06:13<1:06:20,  2.56s/it]  7%|▋         | 121/1674 [06:15<1:05:36,  2.53s/it]  7%|▋         | 122/1674 [06:19<1:16:51,  2.97s/it]  7%|▋         | 123/1674 [06:23<1:21:48,  3.17s/it]  7%|▋         | 124/1674 [06:25<1:18:00,  3.02s/it]  7%|▋         | 125/1674 [06:29<1:19:47,  3.09s/it]  8%|▊         | 126/1674 [06:31<1:16:22,  2.96s/it]  8%|▊         | 127/1674 [06:35<1:18:28,  3.04s/it]  8%|▊         | 128/1674 [06:37<1:12:32,  2.82s/it]  8%|▊         | 129/1674 [06:39<1:08:47,  2.67s/it]  8%|▊         | 130/1674 [06:43<1:18:55,  3.07s/it]                                                    {'loss': 0.6962, 'grad_norm': 30.00435447692871, 'learning_rate': 6.172248803827751e-08, 'rewards/chosen': 0.003040313720703125, 'rewards/rejected': 0.01041259802877903, 'rewards/accuracies': 0.4416666626930237, 'rewards/margins': -0.007382201962172985, 'logps/chosen': -85.0999984741211, 'logps/rejected': -85.2249984741211, 'logits/chosen': -6.268750190734863, 'logits/rejected': -6.206250190734863, 'epoch': 0.23}
  8%|▊         | 130/1674 [06:43<1:18:55,  3.07s/it]  8%|▊         | 131/1674 [06:46<1:13:15,  2.85s/it]  8%|▊         | 132/1674 [06:49<1:20:52,  3.15s/it]  8%|▊         | 133/1674 [06:52<1:19:47,  3.11s/it]  8%|▊         | 134/1674 [06:56<1:23:31,  3.25s/it]  8%|▊         | 135/1674 [06:59<1:19:59,  3.12s/it]  8%|▊         | 136/1674 [07:02<1:21:47,  3.19s/it]  8%|▊         | 137/1674 [07:06<1:27:27,  3.41s/it]  8%|▊         | 138/1674 [07:08<1:18:41,  3.07s/it]  8%|▊         | 139/1674 [07:10<1:11:08,  2.78s/it]  8%|▊         | 140/1674 [07:13<1:09:52,  2.73s/it]                                                    {'loss': 0.6889, 'grad_norm': 30.36310386657715, 'learning_rate': 6.650717703349283e-08, 'rewards/chosen': 0.0077301026321947575, 'rewards/rejected': -0.0034000396262854338, 'rewards/accuracies': 0.5, 'rewards/margins': 0.01114654541015625, 'logps/chosen': -70.19999694824219, 'logps/rejected': -86.0, 'logits/chosen': -6.21875, 'logits/rejected': -6.159375190734863, 'epoch': 0.25}
  8%|▊         | 140/1674 [07:13<1:09:52,  2.73s/it]  8%|▊         | 141/1674 [07:16<1:14:14,  2.91s/it]  8%|▊         | 142/1674 [07:18<1:07:12,  2.63s/it]  9%|▊         | 143/1674 [07:22<1:11:24,  2.80s/it]  9%|▊         | 144/1674 [07:25<1:19:56,  3.14s/it]  9%|▊         | 145/1674 [07:28<1:12:45,  2.86s/it]  9%|▊         | 146/1674 [07:29<1:04:02,  2.51s/it]  9%|▉         | 147/1674 [07:31<59:36,  2.34s/it]    9%|▉         | 148/1674 [07:33<58:06,  2.28s/it]  9%|▉         | 149/1674 [07:36<1:02:14,  2.45s/it]  9%|▉         | 150/1674 [07:38<58:54,  2.32s/it]                                                    {'loss': 0.6952, 'grad_norm': 25.77048683166504, 'learning_rate': 7.129186602870812e-08, 'rewards/chosen': -0.0004486083926167339, 'rewards/rejected': 0.005810546688735485, 'rewards/accuracies': 0.36666667461395264, 'rewards/margins': -0.0062732696533203125, 'logps/chosen': -111.5, 'logps/rejected': -112.19999694824219, 'logits/chosen': -6.128125190734863, 'logits/rejected': -5.893750190734863, 'epoch': 0.27}
  9%|▉         | 150/1674 [07:38<58:54,  2.32s/it]  9%|▉         | 151/1674 [07:42<1:10:01,  2.76s/it]  9%|▉         | 152/1674 [07:45<1:14:20,  2.93s/it]  9%|▉         | 153/1674 [07:48<1:11:31,  2.82s/it]  9%|▉         | 154/1674 [07:51<1:09:59,  2.76s/it]  9%|▉         | 155/1674 [07:54<1:11:43,  2.83s/it]  9%|▉         | 156/1674 [07:56<1:10:35,  2.79s/it]  9%|▉         | 157/1674 [07:58<1:02:48,  2.48s/it]  9%|▉         | 158/1674 [08:02<1:15:48,  3.00s/it]  9%|▉         | 159/1674 [08:06<1:17:30,  3.07s/it] 10%|▉         | 160/1674 [08:08<1:16:05,  3.02s/it]                                                    {'loss': 0.6861, 'grad_norm': 20.82726287841797, 'learning_rate': 7.607655502392344e-08, 'rewards/chosen': 0.005197656340897083, 'rewards/rejected': -0.010427093133330345, 'rewards/accuracies': 0.5083333849906921, 'rewards/margins': 0.01563110388815403, 'logps/chosen': -121.2750015258789, 'logps/rejected': -128.5749969482422, 'logits/chosen': -6.006249904632568, 'logits/rejected': -6.012499809265137, 'epoch': 0.29}
 10%|▉         | 160/1674 [08:09<1:16:05,  3.02s/it] 10%|▉         | 161/1674 [08:13<1:25:31,  3.39s/it] 10%|▉         | 162/1674 [08:14<1:10:16,  2.79s/it] 10%|▉         | 163/1674 [08:18<1:20:12,  3.19s/it] 10%|▉         | 164/1674 [08:21<1:19:50,  3.17s/it] 10%|▉         | 165/1674 [08:26<1:28:41,  3.53s/it] 10%|▉         | 166/1674 [08:30<1:32:56,  3.70s/it] 10%|▉         | 167/1674 [08:32<1:20:01,  3.19s/it] 10%|█         | 168/1674 [08:36<1:27:49,  3.50s/it] 10%|█         | 169/1674 [08:40<1:32:24,  3.68s/it] 10%|█         | 170/1674 [08:43<1:28:06,  3.51s/it]                                                    {'loss': 0.7008, 'grad_norm': 36.620574951171875, 'learning_rate': 8.086124401913875e-08, 'rewards/chosen': 0.0068801878951489925, 'rewards/rejected': 0.013272094540297985, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -0.0063842772506177425, 'logps/chosen': -199.72500610351562, 'logps/rejected': -194.9250030517578, 'logits/chosen': -5.931250095367432, 'logits/rejected': -5.915625095367432, 'epoch': 0.3}
 10%|█         | 170/1674 [08:43<1:28:06,  3.51s/it] 10%|█         | 171/1674 [08:46<1:19:47,  3.19s/it] 10%|█         | 172/1674 [08:50<1:27:04,  3.48s/it] 10%|█         | 173/1674 [08:53<1:26:40,  3.46s/it] 10%|█         | 174/1674 [08:57<1:26:04,  3.44s/it] 10%|█         | 175/1674 [09:00<1:22:37,  3.31s/it] 11%|█         | 176/1674 [09:03<1:25:59,  3.44s/it] 11%|█         | 177/1674 [09:06<1:20:34,  3.23s/it] 11%|█         | 178/1674 [09:10<1:22:54,  3.33s/it] 11%|█         | 179/1674 [09:14<1:27:50,  3.53s/it] 11%|█         | 180/1674 [09:16<1:21:38,  3.28s/it]                                                    {'loss': 0.6839, 'grad_norm': 26.26816749572754, 'learning_rate': 8.564593301435407e-08, 'rewards/chosen': 0.012255859561264515, 'rewards/rejected': -0.00905609130859375, 'rewards/accuracies': 0.6083332896232605, 'rewards/margins': 0.0213165283203125, 'logps/chosen': -78.80000305175781, 'logps/rejected': -90.0999984741211, 'logits/chosen': -6.171875, 'logits/rejected': -6.003125190734863, 'epoch': 0.32}
 11%|█         | 180/1674 [09:17<1:21:38,  3.28s/it] 11%|█         | 181/1674 [09:19<1:15:26,  3.03s/it] 11%|█         | 182/1674 [09:21<1:10:52,  2.85s/it] 11%|█         | 183/1674 [09:25<1:18:14,  3.15s/it] 11%|█         | 184/1674 [09:29<1:21:12,  3.27s/it] 11%|█         | 185/1674 [09:32<1:21:16,  3.28s/it] 11%|█         | 186/1674 [09:35<1:16:53,  3.10s/it] 11%|█         | 187/1674 [09:37<1:13:10,  2.95s/it] 11%|█         | 188/1674 [09:41<1:20:31,  3.25s/it] 11%|█▏        | 189/1674 [09:45<1:21:17,  3.28s/it] 11%|█▏        | 190/1674 [09:47<1:13:43,  2.98s/it]                                                    {'loss': 0.6836, 'grad_norm': 32.79470443725586, 'learning_rate': 9.043062200956937e-08, 'rewards/chosen': 0.035915374755859375, 'rewards/rejected': 0.001617431640625, 'rewards/accuracies': 0.5250000357627869, 'rewards/margins': 0.03419928625226021, 'logps/chosen': -129.0749969482422, 'logps/rejected': -128.02499389648438, 'logits/chosen': -6.018750190734863, 'logits/rejected': -6.053124904632568, 'epoch': 0.34}
 11%|█▏        | 190/1674 [09:47<1:13:43,  2.98s/it] 11%|█▏        | 191/1674 [09:50<1:14:17,  3.01s/it] 11%|█▏        | 192/1674 [09:53<1:11:28,  2.89s/it] 12%|█▏        | 193/1674 [09:56<1:17:10,  3.13s/it] 12%|█▏        | 194/1674 [10:00<1:19:16,  3.21s/it] 12%|█▏        | 195/1674 [10:02<1:16:49,  3.12s/it] 12%|█▏        | 196/1674 [10:06<1:20:57,  3.29s/it] 12%|█▏        | 197/1674 [10:10<1:25:30,  3.47s/it] 12%|█▏        | 198/1674 [10:12<1:15:58,  3.09s/it] 12%|█▏        | 199/1674 [10:15<1:11:23,  2.90s/it] 12%|█▏        | 200/1674 [10:18<1:10:34,  2.87s/it]                                                    {'loss': 0.6894, 'grad_norm': 25.47293472290039, 'learning_rate': 9.521531100478468e-08, 'rewards/chosen': 0.01390914898365736, 'rewards/rejected': -0.0005027771112509072, 'rewards/accuracies': 0.5583333373069763, 'rewards/margins': 0.014431762509047985, 'logps/chosen': -76.8499984741211, 'logps/rejected': -82.5, 'logits/chosen': -6.137499809265137, 'logits/rejected': -6.021874904632568, 'epoch': 0.36}
 12%|█▏        | 200/1674 [10:18<1:10:34,  2.87s/it] 12%|█▏        | 201/1674 [10:21<1:18:20,  3.19s/it] 12%|█▏        | 202/1674 [10:23<1:09:08,  2.82s/it] 12%|█▏        | 203/1674 [10:25<1:02:55,  2.57s/it] 12%|█▏        | 204/1674 [10:28<1:03:41,  2.60s/it] 12%|█▏        | 205/1674 [10:31<1:05:20,  2.67s/it] 12%|█▏        | 206/1674 [10:35<1:13:56,  3.02s/it] 12%|█▏        | 207/1674 [10:38<1:13:43,  3.02s/it] 12%|█▏        | 208/1674 [10:41<1:13:47,  3.02s/it] 12%|█▏        | 209/1674 [10:44<1:14:08,  3.04s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:56,  1.38it/s][A
  4%|▍         | 3/80 [00:03<01:22,  1.08s/it][A
  5%|▌         | 4/80 [00:04<01:35,  1.26s/it][A
  6%|▋         | 5/80 [00:06<01:44,  1.40s/it][A
  8%|▊         | 6/80 [00:07<01:47,  1.45s/it][A
  9%|▉         | 7/80 [00:09<01:51,  1.53s/it][A
 10%|█         | 8/80 [00:11<01:52,  1.57s/it][A
 11%|█▏        | 9/80 [00:13<01:54,  1.62s/it][A
 12%|█▎        | 10/80 [00:14<01:55,  1.65s/it][A
 14%|█▍        | 11/80 [00:16<01:56,  1.68s/it][A
 15%|█▌        | 12/80 [00:17<01:51,  1.65s/it][A
 16%|█▋        | 13/80 [00:19<01:48,  1.63s/it][A
 18%|█▊        | 14/80 [00:21<01:49,  1.66s/it][A
 19%|█▉        | 15/80 [00:22<01:47,  1.65s/it][A
 20%|██        | 16/80 [00:24<01:44,  1.63s/it][A
 21%|██▏       | 17/80 [00:26<01:42,  1.62s/it][A
 22%|██▎       | 18/80 [00:27<01:39,  1.61s/it][A
 24%|██▍       | 19/80 [00:28<01:29,  1.46s/it][A
 25%|██▌       | 20/80 [00:30<01:24,  1.40s/it][A
 26%|██▋       | 21/80 [00:30<01:07,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:06,  1.15s/it][A
 29%|██▉       | 23/80 [00:32<01:04,  1.14s/it][A
 30%|███       | 24/80 [00:33<00:52,  1.06it/s][A
 31%|███▏      | 25/80 [00:34<00:55,  1.01s/it][A
 32%|███▎      | 26/80 [00:35<00:58,  1.09s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.03it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.03it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.09s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.04it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.16s/it][A
 42%|████▎     | 34/80 [00:44<00:57,  1.24s/it][A
 44%|████▍     | 35/80 [00:45<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.06it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.23it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:49,  1.23s/it][A
 51%|█████▏    | 41/80 [00:51<00:40,  1.04s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.20s/it][A
 54%|█████▍    | 43/80 [00:54<00:46,  1.27s/it][A
 55%|█████▌    | 44/80 [00:55<00:45,  1.25s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.07it/s][A
 59%|█████▉    | 47/80 [00:58<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:38,  1.19s/it][A
 61%|██████▏   | 49/80 [01:00<00:31,  1.01s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.19it/s][A
 64%|██████▍   | 51/80 [01:02<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:04<00:26,  1.03it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.18s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:10<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.21s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.01s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.17s/it][A
 78%|███████▊  | 62/80 [01:15<00:23,  1.33s/it][A
 79%|███████▉  | 63/80 [01:16<00:21,  1.25s/it][A
 80%|████████  | 64/80 [01:17<00:18,  1.13s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.24s/it][A
 82%|████████▎ | 66/80 [01:20<00:18,  1.34s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.44s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:27<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:30<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:32<00:06,  1.28s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.37s/it][A
 96%|█████████▋| 77/80 [01:35<00:04,  1.37s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.13s/it][A
 99%|█████████▉| 79/80 [01:37<00:01,  1.27s/it][A
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A                                                    
                                               [A{'eval_loss': 0.6756746172904968, 'eval_runtime': 100.7202, 'eval_samples_per_second': 9.462, 'eval_steps_per_second': 0.794, 'eval_rewards/chosen': 0.04578389972448349, 'eval_rewards/rejected': -0.00707664480432868, 'eval_rewards/accuracies': 0.6620833873748779, 'eval_rewards/margins': 0.05286521837115288, 'eval_logps/chosen': -358.2250061035156, 'eval_logps/rejected': -154.61874389648438, 'eval_logits/chosen': -5.600781440734863, 'eval_logits/rejected': -6.175390720367432, 'epoch': 0.37}
 12%|█▏        | 209/1674 [12:25<1:14:08,  3.04s/it]
100%|██████████| 80/80 [01:39<00:00,  1.37s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 13%|█▎        | 210/1674 [12:40<14:59:38, 36.87s/it]                                                     {'loss': 0.6849, 'grad_norm': 32.67736053466797, 'learning_rate': 1e-07, 'rewards/chosen': 0.012576294131577015, 'rewards/rejected': -0.00286102294921875, 'rewards/accuracies': 0.6083333492279053, 'rewards/margins': 0.01541748084127903, 'logps/chosen': -81.0, 'logps/rejected': -88.5875015258789, 'logits/chosen': -5.981249809265137, 'logits/rejected': -6.065625190734863, 'epoch': 0.38}
 13%|█▎        | 210/1674 [12:40<14:59:38, 36.87s/it] 13%|█▎        | 211/1674 [12:43<10:50:24, 26.67s/it] 13%|█▎        | 212/1674 [12:44<7:48:42, 19.24s/it]  13%|█▎        | 213/1674 [12:47<5:48:00, 14.29s/it] 13%|█▎        | 214/1674 [12:51<4:29:11, 11.06s/it] 13%|█▎        | 215/1674 [12:53<3:25:27,  8.45s/it] 13%|█▎        | 216/1674 [12:56<2:47:10,  6.88s/it] 13%|█▎        | 217/1674 [12:59<2:17:42,  5.67s/it] 13%|█▎        | 218/1674 [13:03<2:03:38,  5.10s/it] 13%|█▎        | 219/1674 [13:06<1:52:17,  4.63s/it] 13%|█▎        | 220/1674 [13:09<1:35:52,  3.96s/it]                                                    {'loss': 0.6751, 'grad_norm': 24.41734504699707, 'learning_rate': 1.0478468899521531e-07, 'rewards/chosen': 0.02281799353659153, 'rewards/rejected': -0.01489105261862278, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.03773803636431694, 'logps/chosen': -79.7249984741211, 'logps/rejected': -87.875, 'logits/chosen': -6.456250190734863, 'logits/rejected': -6.375, 'epoch': 0.39}
 13%|█▎        | 220/1674 [13:09<1:35:52,  3.96s/it] 13%|█▎        | 221/1674 [13:11<1:24:29,  3.49s/it] 13%|█▎        | 222/1674 [13:15<1:28:03,  3.64s/it] 13%|█▎        | 223/1674 [13:17<1:15:34,  3.13s/it] 13%|█▎        | 224/1674 [13:19<1:06:53,  2.77s/it] 13%|█▎        | 225/1674 [13:22<1:06:24,  2.75s/it] 14%|█▎        | 226/1674 [13:24<1:05:49,  2.73s/it] 14%|█▎        | 227/1674 [13:27<1:04:12,  2.66s/it] 14%|█▎        | 228/1674 [13:30<1:08:03,  2.82s/it] 14%|█▎        | 229/1674 [13:32<1:03:58,  2.66s/it] 14%|█▎        | 230/1674 [13:34<59:05,  2.46s/it]                                                    {'loss': 0.6682, 'grad_norm': 23.443187713623047, 'learning_rate': 1.0956937799043062e-07, 'rewards/chosen': 0.03348999097943306, 'rewards/rejected': -0.021881103515625, 'rewards/accuracies': 0.7166666984558105, 'rewards/margins': 0.055419921875, 'logps/chosen': -65.69999694824219, 'logps/rejected': -70.5250015258789, 'logits/chosen': -6.265625, 'logits/rejected': -6.259375095367432, 'epoch': 0.41}
 14%|█▎        | 230/1674 [13:35<59:05,  2.46s/it] 14%|█▍        | 231/1674 [13:39<1:13:41,  3.06s/it] 14%|█▍        | 232/1674 [13:41<1:07:34,  2.81s/it] 14%|█▍        | 233/1674 [13:45<1:15:44,  3.15s/it] 14%|█▍        | 234/1674 [13:49<1:19:32,  3.31s/it] 14%|█▍        | 235/1674 [13:51<1:13:43,  3.07s/it] 14%|█▍        | 236/1674 [13:54<1:10:03,  2.92s/it] 14%|█▍        | 237/1674 [13:57<1:11:38,  2.99s/it] 14%|█▍        | 238/1674 [13:59<1:03:10,  2.64s/it] 14%|█▍        | 239/1674 [14:03<1:12:12,  3.02s/it] 14%|█▍        | 240/1674 [14:07<1:18:34,  3.29s/it]                                                    {'loss': 0.6849, 'grad_norm': 27.9267578125, 'learning_rate': 1.1435406698564594e-07, 'rewards/chosen': 0.022182215005159378, 'rewards/rejected': 0.0009796142112463713, 'rewards/accuracies': 0.6166666746139526, 'rewards/margins': 0.02127685584127903, 'logps/chosen': -88.30000305175781, 'logps/rejected': -112.5250015258789, 'logits/chosen': -6.043749809265137, 'logits/rejected': -6.118750095367432, 'epoch': 0.43}
 14%|█▍        | 240/1674 [14:07<1:18:34,  3.29s/it] 14%|█▍        | 241/1674 [14:09<1:12:13,  3.02s/it] 14%|█▍        | 242/1674 [14:11<1:07:44,  2.84s/it] 15%|█▍        | 243/1674 [14:14<1:07:08,  2.82s/it] 15%|█▍        | 244/1674 [14:18<1:15:00,  3.15s/it] 15%|█▍        | 245/1674 [14:21<1:15:49,  3.18s/it] 15%|█▍        | 246/1674 [14:24<1:09:56,  2.94s/it] 15%|█▍        | 247/1674 [14:27<1:12:12,  3.04s/it] 15%|█▍        | 248/1674 [14:30<1:12:59,  3.07s/it] 15%|█▍        | 249/1674 [14:34<1:15:00,  3.16s/it] 15%|█▍        | 250/1674 [14:36<1:12:45,  3.07s/it]                                                    {'loss': 0.674, 'grad_norm': 25.49393653869629, 'learning_rate': 1.1913875598086124e-07, 'rewards/chosen': 0.01767272874712944, 'rewards/rejected': -0.02584228478372097, 'rewards/accuracies': 0.6416667103767395, 'rewards/margins': 0.04345703125, 'logps/chosen': -85.875, 'logps/rejected': -101.80000305175781, 'logits/chosen': -6.090624809265137, 'logits/rejected': -6.103125095367432, 'epoch': 0.45}
 15%|█▍        | 250/1674 [14:37<1:12:45,  3.07s/it] 15%|█▍        | 251/1674 [14:40<1:16:59,  3.25s/it] 15%|█▌        | 252/1674 [14:43<1:12:30,  3.06s/it] 15%|█▌        | 253/1674 [14:46<1:14:35,  3.15s/it] 15%|█▌        | 254/1674 [14:49<1:16:27,  3.23s/it] 15%|█▌        | 255/1674 [14:51<1:06:02,  2.79s/it] 15%|█▌        | 256/1674 [14:55<1:10:30,  2.98s/it] 15%|█▌        | 257/1674 [14:57<1:09:16,  2.93s/it] 15%|█▌        | 258/1674 [15:00<1:09:20,  2.94s/it] 15%|█▌        | 259/1674 [15:04<1:11:35,  3.04s/it] 16%|█▌        | 260/1674 [15:08<1:16:58,  3.27s/it]                                                    {'loss': 0.6764, 'grad_norm': 70.05364227294922, 'learning_rate': 1.2392344497607655e-07, 'rewards/chosen': 0.02508392371237278, 'rewards/rejected': -0.01889343187212944, 'rewards/accuracies': 0.5666667222976685, 'rewards/margins': 0.0439910888671875, 'logps/chosen': -80.94999694824219, 'logps/rejected': -108.125, 'logits/chosen': -6.128125190734863, 'logits/rejected': -6.059374809265137, 'epoch': 0.47}
 16%|█▌        | 260/1674 [15:08<1:16:58,  3.27s/it] 16%|█▌        | 261/1674 [15:11<1:15:54,  3.22s/it] 16%|█▌        | 262/1674 [15:13<1:09:44,  2.96s/it] 16%|█▌        | 263/1674 [15:16<1:12:42,  3.09s/it] 16%|█▌        | 264/1674 [15:19<1:06:29,  2.83s/it] 16%|█▌        | 265/1674 [15:22<1:08:53,  2.93s/it] 16%|█▌        | 266/1674 [15:24<1:04:58,  2.77s/it] 16%|█▌        | 267/1674 [15:27<1:03:47,  2.72s/it] 16%|█▌        | 268/1674 [15:30<1:07:24,  2.88s/it] 16%|█▌        | 269/1674 [15:33<1:09:05,  2.95s/it] 16%|█▌        | 270/1674 [15:37<1:14:52,  3.20s/it]                                                    {'loss': 0.6635, 'grad_norm': 23.531360626220703, 'learning_rate': 1.2870813397129186e-07, 'rewards/chosen': 0.03717346116900444, 'rewards/rejected': -0.029724502936005592, 'rewards/accuracies': 0.6916666626930237, 'rewards/margins': 0.06677551567554474, 'logps/chosen': -73.55000305175781, 'logps/rejected': -87.19999694824219, 'logits/chosen': -6.328125, 'logits/rejected': -6.224999904632568, 'epoch': 0.48}
 16%|█▌        | 270/1674 [15:37<1:14:52,  3.20s/it] 16%|█▌        | 271/1674 [15:39<1:10:31,  3.02s/it] 16%|█▌        | 272/1674 [15:42<1:08:08,  2.92s/it] 16%|█▋        | 273/1674 [15:44<1:02:45,  2.69s/it] 16%|█▋        | 274/1674 [15:47<1:04:24,  2.76s/it] 16%|█▋        | 275/1674 [15:51<1:12:48,  3.12s/it] 16%|█▋        | 276/1674 [15:55<1:15:50,  3.26s/it] 17%|█▋        | 277/1674 [15:57<1:11:34,  3.07s/it] 17%|█▋        | 278/1674 [16:01<1:14:12,  3.19s/it] 17%|█▋        | 279/1674 [16:04<1:14:33,  3.21s/it] 17%|█▋        | 280/1674 [16:08<1:17:39,  3.34s/it]                                                    {'loss': 0.664, 'grad_norm': 27.455955505371094, 'learning_rate': 1.3349282296650716e-07, 'rewards/chosen': 0.03448486328125, 'rewards/rejected': -0.02997741661965847, 'rewards/accuracies': 0.658333420753479, 'rewards/margins': 0.06442070007324219, 'logps/chosen': -77.55000305175781, 'logps/rejected': -95.4000015258789, 'logits/chosen': -6.137499809265137, 'logits/rejected': -5.746874809265137, 'epoch': 0.5}
 17%|█▋        | 280/1674 [16:08<1:17:39,  3.34s/it] 17%|█▋        | 281/1674 [16:09<1:05:29,  2.82s/it] 17%|█▋        | 282/1674 [16:13<1:11:52,  3.10s/it] 17%|█▋        | 283/1674 [16:16<1:08:48,  2.97s/it] 17%|█▋        | 284/1674 [16:19<1:10:46,  3.06s/it] 17%|█▋        | 285/1674 [16:22<1:10:26,  3.04s/it] 17%|█▋        | 286/1674 [16:25<1:10:32,  3.05s/it] 17%|█▋        | 287/1674 [16:29<1:16:49,  3.32s/it] 17%|█▋        | 288/1674 [16:33<1:17:40,  3.36s/it] 17%|█▋        | 289/1674 [16:34<1:06:29,  2.88s/it] 17%|█▋        | 290/1674 [16:37<1:04:54,  2.81s/it]                                                    {'loss': 0.6728, 'grad_norm': 22.769386291503906, 'learning_rate': 1.382775119617225e-07, 'rewards/chosen': 0.05686035007238388, 'rewards/rejected': -0.00823364220559597, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.06504058837890625, 'logps/chosen': -121.17500305175781, 'logps/rejected': -126.1500015258789, 'logits/chosen': -6.096875190734863, 'logits/rejected': -6.059374809265137, 'epoch': 0.52}
 17%|█▋        | 290/1674 [16:37<1:04:54,  2.81s/it] 17%|█▋        | 291/1674 [16:41<1:12:45,  3.16s/it] 17%|█▋        | 292/1674 [16:44<1:09:18,  3.01s/it] 18%|█▊        | 293/1674 [16:46<1:02:01,  2.69s/it] 18%|█▊        | 294/1674 [16:47<53:10,  2.31s/it]   18%|█▊        | 295/1674 [16:50<59:04,  2.57s/it] 18%|█▊        | 296/1674 [16:54<1:06:33,  2.90s/it] 18%|█▊        | 297/1674 [16:57<1:11:46,  3.13s/it] 18%|█▊        | 298/1674 [17:01<1:15:44,  3.30s/it] 18%|█▊        | 299/1674 [17:04<1:12:17,  3.15s/it] 18%|█▊        | 300/1674 [17:06<1:04:08,  2.80s/it]                                                    {'loss': 0.6459, 'grad_norm': 26.391298294067383, 'learning_rate': 1.430622009569378e-07, 'rewards/chosen': 0.0594940185546875, 'rewards/rejected': -0.04566345363855362, 'rewards/accuracies': 0.7166666984558105, 'rewards/margins': 0.10507812350988388, 'logps/chosen': -93.82499694824219, 'logps/rejected': -104.07499694824219, 'logits/chosen': -6.090624809265137, 'logits/rejected': -6.059374809265137, 'epoch': 0.54}
 18%|█▊        | 300/1674 [17:06<1:04:08,  2.80s/it] 18%|█▊        | 301/1674 [17:09<1:04:25,  2.82s/it] 18%|█▊        | 302/1674 [17:13<1:12:29,  3.17s/it] 18%|█▊        | 303/1674 [17:17<1:19:38,  3.49s/it] 18%|█▊        | 304/1674 [17:19<1:10:14,  3.08s/it] 18%|█▊        | 305/1674 [17:21<1:02:42,  2.75s/it] 18%|█▊        | 306/1674 [17:24<1:01:09,  2.68s/it] 18%|█▊        | 307/1674 [17:27<1:05:10,  2.86s/it] 18%|█▊        | 308/1674 [17:30<1:06:27,  2.92s/it] 18%|█▊        | 309/1674 [17:33<1:04:46,  2.85s/it] 19%|█▊        | 310/1674 [17:36<1:06:55,  2.94s/it]                                                    {'loss': 0.6481, 'grad_norm': 26.98174285888672, 'learning_rate': 1.478468899521531e-07, 'rewards/chosen': 0.05997314304113388, 'rewards/rejected': -0.04362792894244194, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.10344543308019638, 'logps/chosen': -97.7249984741211, 'logps/rejected': -117.0250015258789, 'logits/chosen': -6.1875, 'logits/rejected': -5.981249809265137, 'epoch': 0.56}
 19%|█▊        | 310/1674 [17:36<1:06:55,  2.94s/it] 19%|█▊        | 311/1674 [17:39<1:07:05,  2.95s/it] 19%|█▊        | 312/1674 [17:41<1:01:54,  2.73s/it] 19%|█▊        | 313/1674 [17:45<1:08:53,  3.04s/it] 19%|█▉        | 314/1674 [17:49<1:16:48,  3.39s/it] 19%|█▉        | 315/1674 [17:51<1:08:00,  3.00s/it] 19%|█▉        | 316/1674 [17:55<1:13:02,  3.23s/it] 19%|█▉        | 317/1674 [17:59<1:16:31,  3.38s/it] 19%|█▉        | 318/1674 [18:01<1:09:56,  3.09s/it] 19%|█▉        | 319/1674 [18:04<1:11:43,  3.18s/it] 19%|█▉        | 320/1674 [18:07<1:06:54,  2.96s/it]                                                    {'loss': 0.6568, 'grad_norm': 23.39686393737793, 'learning_rate': 1.526315789473684e-07, 'rewards/chosen': 0.06136016920208931, 'rewards/rejected': -0.02939453162252903, 'rewards/accuracies': 0.6416667103767395, 'rewards/margins': 0.090789794921875, 'logps/chosen': -80.92500305175781, 'logps/rejected': -101.5, 'logits/chosen': -6.331250190734863, 'logits/rejected': -6.018750190734863, 'epoch': 0.57}
 19%|█▉        | 320/1674 [18:07<1:06:54,  2.96s/it] 19%|█▉        | 321/1674 [18:10<1:05:51,  2.92s/it] 19%|█▉        | 322/1674 [18:14<1:13:15,  3.25s/it] 19%|█▉        | 323/1674 [18:17<1:15:56,  3.37s/it] 19%|█▉        | 324/1674 [18:20<1:10:54,  3.15s/it] 19%|█▉        | 325/1674 [18:24<1:15:30,  3.36s/it] 19%|█▉        | 326/1674 [18:27<1:14:12,  3.30s/it] 20%|█▉        | 327/1674 [18:29<1:04:51,  2.89s/it] 20%|█▉        | 328/1674 [18:32<1:02:57,  2.81s/it] 20%|█▉        | 329/1674 [18:36<1:12:25,  3.23s/it] 20%|█▉        | 330/1674 [18:39<1:09:13,  3.09s/it]                                                    {'loss': 0.6273, 'grad_norm': 22.48898696899414, 'learning_rate': 1.5741626794258374e-07, 'rewards/chosen': 0.09309081733226776, 'rewards/rejected': -0.06183166429400444, 'rewards/accuracies': 0.7416666746139526, 'rewards/margins': 0.15480956435203552, 'logps/chosen': -72.875, 'logps/rejected': -85.375, 'logits/chosen': -6.165625095367432, 'logits/rejected': -6.153124809265137, 'epoch': 0.59}
 20%|█▉        | 330/1674 [18:39<1:09:13,  3.09s/it] 20%|█▉        | 331/1674 [18:41<1:02:37,  2.80s/it] 20%|█▉        | 332/1674 [18:45<1:09:54,  3.13s/it] 20%|█▉        | 333/1674 [18:46<1:00:48,  2.72s/it] 20%|█▉        | 334/1674 [18:49<58:54,  2.64s/it]   20%|██        | 335/1674 [18:52<1:05:20,  2.93s/it] 20%|██        | 336/1674 [18:56<1:10:57,  3.18s/it] 20%|██        | 337/1674 [18:59<1:06:56,  3.00s/it] 20%|██        | 338/1674 [19:01<1:05:16,  2.93s/it] 20%|██        | 339/1674 [19:05<1:07:53,  3.05s/it] 20%|██        | 340/1674 [19:07<1:03:21,  2.85s/it]                                                    {'loss': 0.6209, 'grad_norm': 62.91293716430664, 'learning_rate': 1.6220095693779902e-07, 'rewards/chosen': 0.07985839992761612, 'rewards/rejected': -0.08489990234375, 'rewards/accuracies': 0.7666667103767395, 'rewards/margins': 0.1650390625, 'logps/chosen': -75.9749984741211, 'logps/rejected': -82.42500305175781, 'logits/chosen': -6.140625, 'logits/rejected': -6.025000095367432, 'epoch': 0.61}
 20%|██        | 340/1674 [19:07<1:03:21,  2.85s/it] 20%|██        | 341/1674 [19:10<1:00:47,  2.74s/it] 20%|██        | 342/1674 [19:14<1:08:37,  3.09s/it] 20%|██        | 343/1674 [19:17<1:12:49,  3.28s/it] 21%|██        | 344/1674 [19:21<1:12:06,  3.25s/it] 21%|██        | 345/1674 [19:23<1:09:21,  3.13s/it] 21%|██        | 346/1674 [19:27<1:10:19,  3.18s/it] 21%|██        | 347/1674 [19:29<1:06:00,  2.98s/it] 21%|██        | 348/1674 [19:32<1:04:22,  2.91s/it] 21%|██        | 349/1674 [19:34<56:53,  2.58s/it]   21%|██        | 350/1674 [19:37<1:01:21,  2.78s/it]                                                    {'loss': 0.6331, 'grad_norm': 25.452045440673828, 'learning_rate': 1.6698564593301433e-07, 'rewards/chosen': 0.09207763522863388, 'rewards/rejected': -0.05800781399011612, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.15023192763328552, 'logps/chosen': -74.875, 'logps/rejected': -83.25, 'logits/chosen': -6.056250095367432, 'logits/rejected': -5.921875, 'epoch': 0.63}
 21%|██        | 350/1674 [19:37<1:01:21,  2.78s/it] 21%|██        | 351/1674 [19:41<1:10:30,  3.20s/it] 21%|██        | 352/1674 [19:44<1:11:08,  3.23s/it] 21%|██        | 353/1674 [19:49<1:17:39,  3.53s/it] 21%|██        | 354/1674 [19:52<1:13:42,  3.35s/it] 21%|██        | 355/1674 [19:54<1:07:07,  3.05s/it] 21%|██▏       | 356/1674 [19:57<1:07:52,  3.09s/it] 21%|██▏       | 357/1674 [19:59<1:01:39,  2.81s/it] 21%|██▏       | 358/1674 [20:03<1:07:04,  3.06s/it] 21%|██▏       | 359/1674 [20:06<1:09:18,  3.16s/it] 22%|██▏       | 360/1674 [20:09<1:07:55,  3.10s/it]                                                    {'loss': 0.6143, 'grad_norm': 29.643957138061523, 'learning_rate': 1.7177033492822966e-07, 'rewards/chosen': 0.10517577826976776, 'rewards/rejected': -0.09459228813648224, 'rewards/accuracies': 0.7500000596046448, 'rewards/margins': 0.19936522841453552, 'logps/chosen': -71.9000015258789, 'logps/rejected': -93.625, 'logits/chosen': -6.059374809265137, 'logits/rejected': -5.918749809265137, 'epoch': 0.65}
 22%|██▏       | 360/1674 [20:09<1:07:55,  3.10s/it] 22%|██▏       | 361/1674 [20:13<1:13:49,  3.37s/it] 22%|██▏       | 362/1674 [20:15<1:05:06,  2.98s/it] 22%|██▏       | 363/1674 [20:19<1:08:46,  3.15s/it] 22%|██▏       | 364/1674 [20:22<1:11:33,  3.28s/it] 22%|██▏       | 365/1674 [20:25<1:05:35,  3.01s/it] 22%|██▏       | 366/1674 [20:28<1:04:43,  2.97s/it] 22%|██▏       | 367/1674 [20:32<1:09:58,  3.21s/it] 22%|██▏       | 368/1674 [20:35<1:10:10,  3.22s/it] 22%|██▏       | 369/1674 [20:38<1:12:07,  3.32s/it] 22%|██▏       | 370/1674 [20:41<1:05:54,  3.03s/it]                                                    {'loss': 0.6359, 'grad_norm': 21.824586868286133, 'learning_rate': 1.7655502392344497e-07, 'rewards/chosen': 0.08102340996265411, 'rewards/rejected': -0.06400146335363388, 'rewards/accuracies': 0.6333333253860474, 'rewards/margins': 0.14510497450828552, 'logps/chosen': -78.1500015258789, 'logps/rejected': -98.7249984741211, 'logits/chosen': -6.1875, 'logits/rejected': -6.096875190734863, 'epoch': 0.66}
 22%|██▏       | 370/1674 [20:41<1:05:54,  3.03s/it] 22%|██▏       | 371/1674 [20:44<1:09:03,  3.18s/it] 22%|██▏       | 372/1674 [20:47<1:04:25,  2.97s/it] 22%|██▏       | 373/1674 [20:50<1:09:00,  3.18s/it] 22%|██▏       | 374/1674 [20:52<1:02:04,  2.86s/it] 22%|██▏       | 375/1674 [20:54<55:36,  2.57s/it]   22%|██▏       | 376/1674 [20:57<53:25,  2.47s/it] 23%|██▎       | 377/1674 [20:59<50:01,  2.31s/it] 23%|██▎       | 378/1674 [21:02<56:52,  2.63s/it] 23%|██▎       | 379/1674 [21:04<54:43,  2.54s/it] 23%|██▎       | 380/1674 [21:07<54:26,  2.52s/it]                                                  {'loss': 0.5943, 'grad_norm': 20.482757568359375, 'learning_rate': 1.8133971291866027e-07, 'rewards/chosen': 0.12437744438648224, 'rewards/rejected': -0.12929420173168182, 'rewards/accuracies': 0.7583333253860474, 'rewards/margins': 0.2536377012729645, 'logps/chosen': -80.30000305175781, 'logps/rejected': -81.125, 'logits/chosen': -6.171875, 'logits/rejected': -6.0625, 'epoch': 0.68}
 23%|██▎       | 380/1674 [21:07<54:26,  2.52s/it] 23%|██▎       | 381/1674 [21:11<1:03:48,  2.96s/it] 23%|██▎       | 382/1674 [21:14<1:05:54,  3.06s/it] 23%|██▎       | 383/1674 [21:18<1:09:50,  3.25s/it] 23%|██▎       | 384/1674 [21:21<1:12:15,  3.36s/it] 23%|██▎       | 385/1674 [21:25<1:14:24,  3.46s/it] 23%|██▎       | 386/1674 [21:27<1:04:15,  2.99s/it] 23%|██▎       | 387/1674 [21:29<1:00:08,  2.80s/it] 23%|██▎       | 388/1674 [21:32<57:15,  2.67s/it]   23%|██▎       | 389/1674 [21:35<1:00:47,  2.84s/it] 23%|██▎       | 390/1674 [21:38<1:01:01,  2.85s/it]                                                    {'loss': 0.6031, 'grad_norm': 20.647310256958008, 'learning_rate': 1.861244019138756e-07, 'rewards/chosen': 0.15219727158546448, 'rewards/rejected': -0.10852966457605362, 'rewards/accuracies': 0.7416666746139526, 'rewards/margins': 0.2606445252895355, 'logps/chosen': -82.44999694824219, 'logps/rejected': -103.5999984741211, 'logits/chosen': -6.337500095367432, 'logits/rejected': -6.231249809265137, 'epoch': 0.7}
 23%|██▎       | 390/1674 [21:38<1:01:01,  2.85s/it] 23%|██▎       | 391/1674 [21:40<1:00:02,  2.81s/it] 23%|██▎       | 392/1674 [21:43<57:22,  2.69s/it]   23%|██▎       | 393/1674 [21:46<1:01:32,  2.88s/it] 24%|██▎       | 394/1674 [21:49<1:00:12,  2.82s/it] 24%|██▎       | 395/1674 [21:53<1:05:49,  3.09s/it] 24%|██▎       | 396/1674 [21:55<1:01:59,  2.91s/it] 24%|██▎       | 397/1674 [21:59<1:05:46,  3.09s/it] 24%|██▍       | 398/1674 [22:02<1:09:36,  3.27s/it] 24%|██▍       | 399/1674 [22:05<1:04:41,  3.04s/it] 24%|██▍       | 400/1674 [22:09<1:12:09,  3.40s/it]                                                    {'loss': 0.6098, 'grad_norm': 19.742151260375977, 'learning_rate': 1.909090909090909e-07, 'rewards/chosen': 0.13063354790210724, 'rewards/rejected': -0.10718383640050888, 'rewards/accuracies': 0.7083333730697632, 'rewards/margins': 0.23753508925437927, 'logps/chosen': -76.42500305175781, 'logps/rejected': -90.55000305175781, 'logits/chosen': -6.046875, 'logits/rejected': -5.831250190734863, 'epoch': 0.72}
 24%|██▍       | 400/1674 [22:09<1:12:09,  3.40s/it] 24%|██▍       | 401/1674 [22:12<1:06:32,  3.14s/it] 24%|██▍       | 402/1674 [22:16<1:13:36,  3.47s/it] 24%|██▍       | 403/1674 [22:18<1:08:29,  3.23s/it] 24%|██▍       | 404/1674 [22:22<1:10:57,  3.35s/it] 24%|██▍       | 405/1674 [22:25<1:06:25,  3.14s/it] 24%|██▍       | 406/1674 [22:29<1:13:03,  3.46s/it] 24%|██▍       | 407/1674 [22:32<1:07:20,  3.19s/it] 24%|██▍       | 408/1674 [22:33<59:36,  2.83s/it]   24%|██▍       | 409/1674 [22:38<1:07:20,  3.19s/it] 24%|██▍       | 410/1674 [22:40<1:03:07,  3.00s/it]                                                    {'loss': 0.5938, 'grad_norm': 34.811134338378906, 'learning_rate': 1.9569377990430622e-07, 'rewards/chosen': 0.143310546875, 'rewards/rejected': -0.12465820461511612, 'rewards/accuracies': 0.7166666984558105, 'rewards/margins': 0.2677856385707855, 'logps/chosen': -77.67500305175781, 'logps/rejected': -82.67500305175781, 'logits/chosen': -6.168749809265137, 'logits/rejected': -5.981249809265137, 'epoch': 0.73}
 24%|██▍       | 410/1674 [22:40<1:03:07,  3.00s/it] 25%|██▍       | 411/1674 [22:44<1:09:13,  3.29s/it] 25%|██▍       | 412/1674 [22:48<1:10:14,  3.34s/it] 25%|██▍       | 413/1674 [22:51<1:08:09,  3.24s/it] 25%|██▍       | 414/1674 [22:54<1:08:01,  3.24s/it] 25%|██▍       | 415/1674 [22:57<1:04:59,  3.10s/it] 25%|██▍       | 416/1674 [23:01<1:11:02,  3.39s/it] 25%|██▍       | 417/1674 [23:05<1:16:19,  3.64s/it] 25%|██▍       | 418/1674 [23:07<1:09:16,  3.31s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:56,  1.37it/s][A
  4%|▍         | 3/80 [00:03<01:23,  1.08s/it][A
  5%|▌         | 4/80 [00:04<01:35,  1.26s/it][A
  6%|▋         | 5/80 [00:06<01:47,  1.44s/it][A
  8%|▊         | 6/80 [00:07<01:49,  1.48s/it][A
  9%|▉         | 7/80 [00:09<01:51,  1.53s/it][A
 10%|█         | 8/80 [00:11<01:52,  1.56s/it][A
 11%|█▏        | 9/80 [00:12<01:52,  1.58s/it][A
 12%|█▎        | 10/80 [00:14<01:53,  1.62s/it][A
 14%|█▍        | 11/80 [00:16<01:56,  1.70s/it][A
 15%|█▌        | 12/80 [00:17<01:52,  1.66s/it][A
 16%|█▋        | 13/80 [00:19<01:49,  1.63s/it][A
 18%|█▊        | 14/80 [00:21<01:49,  1.66s/it][A
 19%|█▉        | 15/80 [00:22<01:46,  1.64s/it][A
 20%|██        | 16/80 [00:24<01:43,  1.62s/it][A
 21%|██▏       | 17/80 [00:26<01:41,  1.62s/it][A
 22%|██▎       | 18/80 [00:27<01:43,  1.67s/it][A
 24%|██▍       | 19/80 [00:28<01:31,  1.51s/it][A
 25%|██▌       | 20/80 [00:30<01:26,  1.44s/it][A
 26%|██▋       | 21/80 [00:30<01:09,  1.17s/it][A
 28%|██▊       | 22/80 [00:31<01:07,  1.16s/it][A
 29%|██▉       | 23/80 [00:33<01:05,  1.14s/it][A
 30%|███       | 24/80 [00:33<00:52,  1.06it/s][A
 31%|███▏      | 25/80 [00:34<00:55,  1.01s/it][A
 32%|███▎      | 26/80 [00:35<00:58,  1.09s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.03it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.02it/s][A
 36%|███▋      | 29/80 [00:39<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:40<00:54,  1.09s/it][A
 39%|███▉      | 31/80 [00:41<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:46,  1.04it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.16s/it][A
 42%|████▎     | 34/80 [00:44<00:57,  1.25s/it][A
 44%|████▍     | 35/80 [00:45<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:46<00:41,  1.06it/s][A
 46%|████▋     | 37/80 [00:47<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.22it/s][A
 49%|████▉     | 39/80 [00:49<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:49,  1.24s/it][A
 51%|█████▏    | 41/80 [00:51<00:40,  1.05s/it][A
 52%|█████▎    | 42/80 [00:53<00:45,  1.21s/it][A
 54%|█████▍    | 43/80 [00:54<00:47,  1.28s/it][A
 55%|█████▌    | 44/80 [00:55<00:45,  1.27s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.14s/it][A
 57%|█████▊    | 46/80 [00:57<00:32,  1.04it/s][A
 59%|█████▉    | 47/80 [00:58<00:36,  1.11s/it][A
 60%|██████    | 48/80 [01:00<00:38,  1.21s/it][A
 61%|██████▏   | 49/80 [01:00<00:31,  1.03s/it][A
 62%|██████▎   | 50/80 [01:01<00:25,  1.16it/s][A
 64%|██████▍   | 51/80 [01:02<00:31,  1.08s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.10s/it][A
 66%|██████▋   | 53/80 [01:04<00:26,  1.01it/s][A
 68%|██████▊   | 54/80 [01:06<00:29,  1.13s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.04s/it][A
 70%|███████   | 56/80 [01:08<00:28,  1.20s/it][A
 71%|███████▏  | 57/80 [01:09<00:23,  1.03s/it][A
 72%|███████▎  | 58/80 [01:10<00:25,  1.16s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.22s/it][A
 75%|███████▌  | 60/80 [01:12<00:20,  1.02s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.17s/it][A
 78%|███████▊  | 62/80 [01:15<00:23,  1.33s/it][A
 79%|███████▉  | 63/80 [01:16<00:21,  1.26s/it][A
 80%|████████  | 64/80 [01:17<00:18,  1.14s/it][A
 81%|████████▏ | 65/80 [01:19<00:18,  1.25s/it][A
 82%|████████▎ | 66/80 [01:20<00:18,  1.34s/it][A
 84%|████████▍ | 67/80 [01:22<00:18,  1.44s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:25<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:26<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:27<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:29<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:31<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:32<00:06,  1.27s/it][A
 95%|█████████▌| 76/80 [01:34<00:05,  1.36s/it][A
 96%|█████████▋| 77/80 [01:35<00:04,  1.36s/it][A
 98%|█████████▊| 78/80 [01:36<00:02,  1.12s/it][A
 99%|█████████▉| 79/80 [01:37<00:01,  1.26s/it][A
100%|██████████| 80/80 [01:39<00:00,  1.37s/it][A                                                    
                                               [A{'eval_loss': 0.5519304871559143, 'eval_runtime': 101.1518, 'eval_samples_per_second': 9.421, 'eval_steps_per_second': 0.791, 'eval_rewards/chosen': 0.23508301377296448, 'eval_rewards/rejected': -0.13604798913002014, 'eval_rewards/accuracies': 0.8352084159851074, 'eval_rewards/margins': 0.3710207939147949, 'eval_logps/chosen': -356.5093688964844, 'eval_logps/rejected': -155.84219360351562, 'eval_logits/chosen': -5.661523342132568, 'eval_logits/rejected': -6.158593654632568, 'epoch': 0.75}
 25%|██▍       | 418/1674 [24:49<1:09:16,  3.31s/it]
100%|██████████| 80/80 [01:39<00:00,  1.37s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 25%|██▌       | 419/1674 [25:03<12:57:00, 37.15s/it] 25%|██▌       | 420/1674 [25:06<9:21:15, 26.85s/it]                                                     {'loss': 0.595, 'grad_norm': 27.17286491394043, 'learning_rate': 2.0047846889952155e-07, 'rewards/chosen': 0.12998047471046448, 'rewards/rejected': -0.14243164658546448, 'rewards/accuracies': 0.7416667342185974, 'rewards/margins': 0.27216798067092896, 'logps/chosen': -97.375, 'logps/rejected': -117.5250015258789, 'logits/chosen': -6.209374904632568, 'logits/rejected': -5.987500190734863, 'epoch': 0.75}
 25%|██▌       | 420/1674 [25:06<9:21:15, 26.85s/it] 25%|██▌       | 421/1674 [25:09<6:48:22, 19.56s/it] 25%|██▌       | 422/1674 [25:10<4:55:44, 14.17s/it] 25%|██▌       | 423/1674 [25:13<3:40:38, 10.58s/it] 25%|██▌       | 424/1674 [25:16<2:54:16,  8.36s/it] 25%|██▌       | 425/1674 [25:19<2:19:01,  6.68s/it] 25%|██▌       | 426/1674 [25:22<1:56:30,  5.60s/it] 26%|██▌       | 427/1674 [25:25<1:40:47,  4.85s/it] 26%|██▌       | 428/1674 [25:28<1:30:15,  4.35s/it] 26%|██▌       | 429/1674 [25:31<1:22:35,  3.98s/it] 26%|██▌       | 430/1674 [25:34<1:15:18,  3.63s/it]                                                    {'loss': 0.5592, 'grad_norm': 18.719785690307617, 'learning_rate': 2.0526315789473685e-07, 'rewards/chosen': 0.17381592094898224, 'rewards/rejected': -0.17740479111671448, 'rewards/accuracies': 0.7833333015441895, 'rewards/margins': 0.3509765565395355, 'logps/chosen': -77.19999694824219, 'logps/rejected': -76.9749984741211, 'logits/chosen': -6.318749904632568, 'logits/rejected': -6.106249809265137, 'epoch': 0.77}
 26%|██▌       | 430/1674 [25:34<1:15:18,  3.63s/it] 26%|██▌       | 431/1674 [25:37<1:10:56,  3.42s/it] 26%|██▌       | 432/1674 [25:39<1:05:48,  3.18s/it] 26%|██▌       | 433/1674 [25:44<1:11:45,  3.47s/it] 26%|██▌       | 434/1674 [25:48<1:14:40,  3.61s/it] 26%|██▌       | 435/1674 [25:50<1:10:29,  3.41s/it] 26%|██▌       | 436/1674 [25:54<1:10:15,  3.40s/it] 26%|██▌       | 437/1674 [25:57<1:07:02,  3.25s/it] 26%|██▌       | 438/1674 [26:00<1:08:10,  3.31s/it] 26%|██▌       | 439/1674 [26:04<1:11:22,  3.47s/it] 26%|██▋       | 440/1674 [26:07<1:10:35,  3.43s/it]                                                    {'loss': 0.545, 'grad_norm': 36.83852767944336, 'learning_rate': 2.1004784688995216e-07, 'rewards/chosen': 0.20429687201976776, 'rewards/rejected': -0.19252929091453552, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.39697265625, 'logps/chosen': -118.44999694824219, 'logps/rejected': -123.125, 'logits/chosen': -6.021874904632568, 'logits/rejected': -5.987500190734863, 'epoch': 0.79}
 26%|██▋       | 440/1674 [26:07<1:10:35,  3.43s/it] 26%|██▋       | 441/1674 [26:10<1:06:14,  3.22s/it] 26%|██▋       | 442/1674 [26:14<1:09:20,  3.38s/it] 26%|██▋       | 443/1674 [26:16<1:03:37,  3.10s/it] 27%|██▋       | 444/1674 [26:19<1:02:03,  3.03s/it] 27%|██▋       | 445/1674 [26:23<1:06:08,  3.23s/it] 27%|██▋       | 446/1674 [26:25<1:00:32,  2.96s/it] 27%|██▋       | 447/1674 [26:29<1:03:01,  3.08s/it] 27%|██▋       | 448/1674 [26:32<1:06:12,  3.24s/it] 27%|██▋       | 449/1674 [26:35<1:00:53,  2.98s/it] 27%|██▋       | 450/1674 [26:37<59:01,  2.89s/it]                                                    {'loss': 0.5753, 'grad_norm': 23.520124435424805, 'learning_rate': 2.1483253588516747e-07, 'rewards/chosen': 0.17348632216453552, 'rewards/rejected': -0.17714843153953552, 'rewards/accuracies': 0.7166666984558105, 'rewards/margins': 0.3505859375, 'logps/chosen': -70.7249984741211, 'logps/rejected': -83.5250015258789, 'logits/chosen': -6.34375, 'logits/rejected': -6.096875190734863, 'epoch': 0.81}
 27%|██▋       | 450/1674 [26:38<59:01,  2.89s/it] 27%|██▋       | 451/1674 [26:40<59:51,  2.94s/it] 27%|██▋       | 452/1674 [26:44<1:07:15,  3.30s/it] 27%|██▋       | 453/1674 [26:48<1:10:24,  3.46s/it] 27%|██▋       | 454/1674 [26:51<1:06:26,  3.27s/it] 27%|██▋       | 455/1674 [26:55<1:11:41,  3.53s/it] 27%|██▋       | 456/1674 [26:59<1:15:12,  3.70s/it] 27%|██▋       | 457/1674 [27:01<1:05:36,  3.23s/it] 27%|██▋       | 458/1674 [27:06<1:10:25,  3.47s/it] 27%|██▋       | 459/1674 [27:09<1:10:47,  3.50s/it] 27%|██▋       | 460/1674 [27:13<1:11:36,  3.54s/it]                                                    {'loss': 0.5502, 'grad_norm': 27.116220474243164, 'learning_rate': 2.1961722488038274e-07, 'rewards/chosen': 0.20034179091453552, 'rewards/rejected': -0.23056641221046448, 'rewards/accuracies': 0.75, 'rewards/margins': 0.43115234375, 'logps/chosen': -85.30000305175781, 'logps/rejected': -104.125, 'logits/chosen': -6.412499904632568, 'logits/rejected': -6.234375, 'epoch': 0.82}
 27%|██▋       | 460/1674 [27:13<1:11:36,  3.54s/it] 28%|██▊       | 461/1674 [27:15<1:06:49,  3.31s/it] 28%|██▊       | 462/1674 [27:19<1:07:54,  3.36s/it] 28%|██▊       | 463/1674 [27:21<1:01:15,  3.03s/it] 28%|██▊       | 464/1674 [27:25<1:05:16,  3.24s/it] 28%|██▊       | 465/1674 [27:29<1:10:36,  3.50s/it] 28%|██▊       | 466/1674 [27:33<1:11:01,  3.53s/it] 28%|██▊       | 467/1674 [27:35<1:02:52,  3.13s/it] 28%|██▊       | 468/1674 [27:39<1:07:43,  3.37s/it] 28%|██▊       | 469/1674 [27:42<1:09:15,  3.45s/it] 28%|██▊       | 470/1674 [27:46<1:12:04,  3.59s/it]                                                    {'loss': 0.5684, 'grad_norm': 24.422399520874023, 'learning_rate': 2.2440191387559805e-07, 'rewards/chosen': 0.20843505859375, 'rewards/rejected': -0.15931396186351776, 'rewards/accuracies': 0.7333333492279053, 'rewards/margins': 0.367919921875, 'logps/chosen': -136.9250030517578, 'logps/rejected': -154.875, 'logits/chosen': -6.300000190734863, 'logits/rejected': -6.021874904632568, 'epoch': 0.84}
 28%|██▊       | 470/1674 [27:46<1:12:04,  3.59s/it] 28%|██▊       | 471/1674 [27:48<1:02:56,  3.14s/it] 28%|██▊       | 472/1674 [27:50<53:16,  2.66s/it]   28%|██▊       | 473/1674 [27:54<1:02:23,  3.12s/it] 28%|██▊       | 474/1674 [27:57<59:02,  2.95s/it]   28%|██▊       | 475/1674 [27:59<54:59,  2.75s/it] 28%|██▊       | 476/1674 [28:02<56:00,  2.80s/it] 28%|██▊       | 477/1674 [28:04<54:03,  2.71s/it] 29%|██▊       | 478/1674 [28:07<55:01,  2.76s/it] 29%|██▊       | 479/1674 [28:09<50:58,  2.56s/it] 29%|██▊       | 480/1674 [28:13<57:58,  2.91s/it]                                                  {'loss': 0.5701, 'grad_norm': 18.841251373291016, 'learning_rate': 2.2918660287081338e-07, 'rewards/chosen': 0.16580811142921448, 'rewards/rejected': -0.22119140625, 'rewards/accuracies': 0.7416666746139526, 'rewards/margins': 0.3873046934604645, 'logps/chosen': -70.0999984741211, 'logps/rejected': -85.25, 'logits/chosen': -6.293749809265137, 'logits/rejected': -6.165625095367432, 'epoch': 0.86}
 29%|██▊       | 480/1674 [28:13<57:58,  2.91s/it] 29%|██▊       | 481/1674 [28:16<59:02,  2.97s/it] 29%|██▉       | 482/1674 [28:20<1:02:14,  3.13s/it] 29%|██▉       | 483/1674 [28:22<55:40,  2.80s/it]   29%|██▉       | 484/1674 [28:25<57:41,  2.91s/it] 29%|██▉       | 485/1674 [28:27<54:42,  2.76s/it] 29%|██▉       | 486/1674 [28:30<53:38,  2.71s/it] 29%|██▉       | 487/1674 [28:34<1:01:59,  3.13s/it] 29%|██▉       | 488/1674 [28:38<1:07:41,  3.42s/it] 29%|██▉       | 489/1674 [28:40<55:44,  2.82s/it]   29%|██▉       | 490/1674 [28:41<50:24,  2.55s/it]                                                  {'loss': 0.5086, 'grad_norm': 17.696592330932617, 'learning_rate': 2.339712918660287e-07, 'rewards/chosen': 0.2759765684604645, 'rewards/rejected': -0.2591796815395355, 'rewards/accuracies': 0.76666659116745, 'rewards/margins': 0.534960925579071, 'logps/chosen': -86.375, 'logps/rejected': -82.125, 'logits/chosen': -6.059374809265137, 'logits/rejected': -5.996874809265137, 'epoch': 0.88}
 29%|██▉       | 490/1674 [28:42<50:24,  2.55s/it] 29%|██▉       | 491/1674 [28:45<54:28,  2.76s/it] 29%|██▉       | 492/1674 [28:47<52:31,  2.67s/it] 29%|██▉       | 493/1674 [28:50<54:34,  2.77s/it] 30%|██▉       | 494/1674 [28:52<51:04,  2.60s/it] 30%|██▉       | 495/1674 [28:55<53:23,  2.72s/it] 30%|██▉       | 496/1674 [28:58<50:53,  2.59s/it] 30%|██▉       | 497/1674 [29:00<50:54,  2.59s/it] 30%|██▉       | 498/1674 [29:02<47:09,  2.41s/it] 30%|██▉       | 499/1674 [29:06<55:21,  2.83s/it] 30%|██▉       | 500/1674 [29:10<1:01:58,  3.17s/it]                                                    {'loss': 0.5336, 'grad_norm': 20.689451217651367, 'learning_rate': 2.38755980861244e-07, 'rewards/chosen': 0.21323242783546448, 'rewards/rejected': -0.2723144590854645, 'rewards/accuracies': 0.8166667222976685, 'rewards/margins': 0.48603516817092896, 'logps/chosen': -76.0, 'logps/rejected': -88.92500305175781, 'logits/chosen': -6.184374809265137, 'logits/rejected': -6.037499904632568, 'epoch': 0.9}
 30%|██▉       | 500/1674 [29:10<1:01:58,  3.17s/it] 30%|██▉       | 501/1674 [29:13<1:02:06,  3.18s/it] 30%|██▉       | 502/1674 [29:16<57:37,  2.95s/it]   30%|███       | 503/1674 [29:19<1:01:00,  3.13s/it] 30%|███       | 504/1674 [29:22<56:53,  2.92s/it]   30%|███       | 505/1674 [29:25<1:02:15,  3.20s/it] 30%|███       | 506/1674 [29:29<1:02:02,  3.19s/it] 30%|███       | 507/1674 [29:32<1:06:00,  3.39s/it] 30%|███       | 508/1674 [29:36<1:04:19,  3.31s/it] 30%|███       | 509/1674 [29:39<1:06:11,  3.41s/it] 30%|███       | 510/1674 [29:43<1:08:00,  3.51s/it]                                                    {'loss': 0.5073, 'grad_norm': 20.718523025512695, 'learning_rate': 2.435406698564593e-07, 'rewards/chosen': 0.25288087129592896, 'rewards/rejected': -0.2886962890625, 'rewards/accuracies': 0.85833340883255, 'rewards/margins': 0.5414794683456421, 'logps/chosen': -70.57499694824219, 'logps/rejected': -90.05000305175781, 'logits/chosen': -6.415625095367432, 'logits/rejected': -6.215624809265137, 'epoch': 0.91}
 30%|███       | 510/1674 [29:43<1:08:00,  3.51s/it] 31%|███       | 511/1674 [29:45<1:01:14,  3.16s/it] 31%|███       | 512/1674 [29:48<1:00:23,  3.12s/it] 31%|███       | 513/1674 [29:51<58:16,  3.01s/it]   31%|███       | 514/1674 [29:55<1:01:17,  3.17s/it] 31%|███       | 515/1674 [29:57<58:49,  3.04s/it]   31%|███       | 516/1674 [29:59<50:26,  2.61s/it] 31%|███       | 517/1674 [30:01<47:33,  2.47s/it] 31%|███       | 518/1674 [30:03<46:14,  2.40s/it] 31%|███       | 519/1674 [30:06<49:16,  2.56s/it] 31%|███       | 520/1674 [30:09<51:16,  2.67s/it]                                                  {'loss': 0.4651, 'grad_norm': 17.907968521118164, 'learning_rate': 2.4832535885167463e-07, 'rewards/chosen': 0.3226562440395355, 'rewards/rejected': -0.34111326932907104, 'rewards/accuracies': 0.8583332896232605, 'rewards/margins': 0.6644531488418579, 'logps/chosen': -69.05000305175781, 'logps/rejected': -77.69999694824219, 'logits/chosen': -6.421875, 'logits/rejected': -6.334374904632568, 'epoch': 0.93}
 31%|███       | 520/1674 [30:09<51:16,  2.67s/it] 31%|███       | 521/1674 [30:11<48:34,  2.53s/it] 31%|███       | 522/1674 [30:15<53:50,  2.80s/it] 31%|███       | 523/1674 [30:19<58:58,  3.07s/it] 31%|███▏      | 524/1674 [30:22<1:03:40,  3.32s/it] 31%|███▏      | 525/1674 [30:25<1:01:25,  3.21s/it] 31%|███▏      | 526/1674 [30:28<57:22,  3.00s/it]   31%|███▏      | 527/1674 [30:31<55:56,  2.93s/it] 32%|███▏      | 528/1674 [30:32<47:36,  2.49s/it] 32%|███▏      | 529/1674 [30:36<54:16,  2.84s/it] 32%|███▏      | 530/1674 [30:39<54:00,  2.83s/it]                                                  {'loss': 0.5156, 'grad_norm': 19.422100067138672, 'learning_rate': 2.5311004784688994e-07, 'rewards/chosen': 0.23875732719898224, 'rewards/rejected': -0.3021484315395355, 'rewards/accuracies': 0.7416666746139526, 'rewards/margins': 0.5411132574081421, 'logps/chosen': -73.6500015258789, 'logps/rejected': -86.375, 'logits/chosen': -6.546875, 'logits/rejected': -6.240624904632568, 'epoch': 0.95}
 32%|███▏      | 530/1674 [30:39<54:00,  2.83s/it] 32%|███▏      | 531/1674 [30:43<1:00:38,  3.18s/it] 32%|███▏      | 532/1674 [30:46<1:00:26,  3.18s/it] 32%|███▏      | 533/1674 [30:49<1:00:07,  3.16s/it] 32%|███▏      | 534/1674 [30:52<56:58,  3.00s/it]   32%|███▏      | 535/1674 [30:53<48:58,  2.58s/it] 32%|███▏      | 536/1674 [30:55<45:37,  2.41s/it] 32%|███▏      | 537/1674 [30:59<53:07,  2.80s/it] 32%|███▏      | 538/1674 [31:03<58:22,  3.08s/it] 32%|███▏      | 539/1674 [31:07<1:03:57,  3.38s/it] 32%|███▏      | 540/1674 [31:09<59:33,  3.15s/it]                                                    {'loss': 0.5118, 'grad_norm': 19.98967933654785, 'learning_rate': 2.5789473684210524e-07, 'rewards/chosen': 0.23245850205421448, 'rewards/rejected': -0.361328125, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.59375, 'logps/chosen': -71.625, 'logps/rejected': -78.30000305175781, 'logits/chosen': -6.334374904632568, 'logits/rejected': -6.193749904632568, 'epoch': 0.97}
 32%|███▏      | 540/1674 [31:09<59:33,  3.15s/it] 32%|███▏      | 541/1674 [31:12<56:30,  2.99s/it] 32%|███▏      | 542/1674 [31:15<56:01,  2.97s/it] 32%|███▏      | 543/1674 [31:19<1:01:16,  3.25s/it] 32%|███▏      | 544/1674 [31:23<1:04:10,  3.41s/it] 33%|███▎      | 545/1674 [31:26<1:04:12,  3.41s/it] 33%|███▎      | 546/1674 [31:30<1:08:42,  3.65s/it] 33%|███▎      | 547/1674 [31:33<1:01:19,  3.26s/it] 33%|███▎      | 548/1674 [31:36<1:00:02,  3.20s/it] 33%|███▎      | 549/1674 [31:39<58:48,  3.14s/it]   33%|███▎      | 550/1674 [31:42<58:52,  3.14s/it]                                                  {'loss': 0.5192, 'grad_norm': 25.139320373535156, 'learning_rate': 2.6267942583732055e-07, 'rewards/chosen': 0.20913085341453552, 'rewards/rejected': -0.3792968690395355, 'rewards/accuracies': 0.7916666269302368, 'rewards/margins': 0.588085949420929, 'logps/chosen': -76.375, 'logps/rejected': -97.3499984741211, 'logits/chosen': -6.371874809265137, 'logits/rejected': -6.131249904632568, 'epoch': 0.99}
 33%|███▎      | 550/1674 [31:42<58:52,  3.14s/it] 33%|███▎      | 551/1674 [31:45<1:00:50,  3.25s/it] 33%|███▎      | 552/1674 [31:48<56:21,  3.01s/it]   33%|███▎      | 553/1674 [31:51<58:13,  3.12s/it] 33%|███▎      | 554/1674 [31:54<54:58,  2.94s/it] 33%|███▎      | 555/1674 [31:58<1:00:30,  3.24s/it] 33%|███▎      | 556/1674 [32:00<57:57,  3.11s/it]   33%|███▎      | 557/1674 [32:03<57:11,  3.07s/it] 33%|███▎      | 558/1674 [32:05<51:54,  2.79s/it] 33%|███▎      | 559/1674 [32:08<49:07,  2.64s/it] 33%|███▎      | 560/1674 [32:12<56:25,  3.04s/it]                                                  {'loss': 0.5305, 'grad_norm': 118.9254150390625, 'learning_rate': 2.6746411483253585e-07, 'rewards/chosen': 0.27202147245407104, 'rewards/rejected': -0.35957032442092896, 'rewards/accuracies': 0.7383333444595337, 'rewards/margins': 0.6322265863418579, 'logps/chosen': -145.35000610351562, 'logps/rejected': -150.8000030517578, 'logits/chosen': -6.243750095367432, 'logits/rejected': -6.078125, 'epoch': 1.0}
 33%|███▎      | 560/1674 [32:12<56:25,  3.04s/it] 34%|███▎      | 561/1674 [32:14<52:53,  2.85s/it] 34%|███▎      | 562/1674 [32:17<54:34,  2.94s/it] 34%|███▎      | 563/1674 [32:20<55:18,  2.99s/it] 34%|███▎      | 564/1674 [32:24<56:57,  3.08s/it] 34%|███▍      | 565/1674 [32:28<1:03:13,  3.42s/it] 34%|███▍      | 566/1674 [32:31<58:48,  3.18s/it]   34%|███▍      | 567/1674 [32:33<56:01,  3.04s/it] 34%|███▍      | 568/1674 [32:35<48:42,  2.64s/it] 34%|███▍      | 569/1674 [32:37<47:07,  2.56s/it] 34%|███▍      | 570/1674 [32:41<54:35,  2.97s/it]                                                  {'loss': 0.4786, 'grad_norm': 27.52703285217285, 'learning_rate': 2.722488038277512e-07, 'rewards/chosen': 0.26557618379592896, 'rewards/rejected': -0.4261718690395355, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6919921636581421, 'logps/chosen': -74.75, 'logps/rejected': -87.125, 'logits/chosen': -6.518750190734863, 'logits/rejected': -6.306250095367432, 'epoch': 1.02}
 34%|███▍      | 570/1674 [32:41<54:35,  2.97s/it] 34%|███▍      | 571/1674 [32:45<58:46,  3.20s/it] 34%|███▍      | 572/1674 [32:48<57:01,  3.10s/it] 34%|███▍      | 573/1674 [32:51<54:40,  2.98s/it] 34%|███▍      | 574/1674 [32:55<1:01:29,  3.35s/it] 34%|███▍      | 575/1674 [32:59<1:05:09,  3.56s/it] 34%|███▍      | 576/1674 [33:01<59:52,  3.27s/it]   34%|███▍      | 577/1674 [33:05<1:01:17,  3.35s/it] 35%|███▍      | 578/1674 [33:07<55:11,  3.02s/it]   35%|███▍      | 579/1674 [33:12<1:02:24,  3.42s/it] 35%|███▍      | 580/1674 [33:15<1:05:00,  3.57s/it]                                                    {'loss': 0.4754, 'grad_norm': 18.824031829833984, 'learning_rate': 2.770334928229665e-07, 'rewards/chosen': 0.2811035215854645, 'rewards/rejected': -0.48466795682907104, 'rewards/accuracies': 0.8083332777023315, 'rewards/margins': 0.765625, 'logps/chosen': -88.44999694824219, 'logps/rejected': -108.9000015258789, 'logits/chosen': -6.512499809265137, 'logits/rejected': -6.337500095367432, 'epoch': 1.04}
 35%|███▍      | 580/1674 [33:16<1:05:00,  3.57s/it] 35%|███▍      | 581/1674 [33:18<1:00:18,  3.31s/it] 35%|███▍      | 582/1674 [33:20<54:52,  3.02s/it]   35%|███▍      | 583/1674 [33:23<52:19,  2.88s/it] 35%|███▍      | 584/1674 [33:25<49:43,  2.74s/it] 35%|███▍      | 585/1674 [33:28<50:08,  2.76s/it] 35%|███▌      | 586/1674 [33:32<54:01,  2.98s/it] 35%|███▌      | 587/1674 [33:34<52:17,  2.89s/it] 35%|███▌      | 588/1674 [33:37<51:36,  2.85s/it] 35%|███▌      | 589/1674 [33:40<52:06,  2.88s/it] 35%|███▌      | 590/1674 [33:44<54:55,  3.04s/it]                                                  {'loss': 0.4911, 'grad_norm': 43.32090377807617, 'learning_rate': 2.818181818181818e-07, 'rewards/chosen': 0.23969726264476776, 'rewards/rejected': -0.44853514432907104, 'rewards/accuracies': 0.783333420753479, 'rewards/margins': 0.689135730266571, 'logps/chosen': -67.6500015258789, 'logps/rejected': -79.5250015258789, 'logits/chosen': -6.418749809265137, 'logits/rejected': -6.190625190734863, 'epoch': 1.06}
 35%|███▌      | 590/1674 [33:44<54:55,  3.04s/it] 35%|███▌      | 591/1674 [33:47<56:53,  3.15s/it] 35%|███▌      | 592/1674 [33:48<47:35,  2.64s/it] 35%|███▌      | 593/1674 [33:52<50:21,  2.79s/it] 35%|███▌      | 594/1674 [33:54<47:23,  2.63s/it] 36%|███▌      | 595/1674 [33:56<46:28,  2.58s/it] 36%|███▌      | 596/1674 [33:59<45:10,  2.51s/it] 36%|███▌      | 597/1674 [34:02<52:05,  2.90s/it] 36%|███▌      | 598/1674 [34:06<53:56,  3.01s/it] 36%|███▌      | 599/1674 [34:08<50:06,  2.80s/it] 36%|███▌      | 600/1674 [34:11<52:32,  2.94s/it]                                                  {'loss': 0.4403, 'grad_norm': 32.127403259277344, 'learning_rate': 2.8660287081339713e-07, 'rewards/chosen': 0.33305662870407104, 'rewards/rejected': -0.5210937261581421, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8543945550918579, 'logps/chosen': -66.0, 'logps/rejected': -80.69999694824219, 'logits/chosen': -6.681250095367432, 'logits/rejected': -6.378125190734863, 'epoch': 1.08}
 36%|███▌      | 600/1674 [34:11<52:32,  2.94s/it] 36%|███▌      | 601/1674 [34:14<52:15,  2.92s/it] 36%|███▌      | 602/1674 [34:17<49:20,  2.76s/it] 36%|███▌      | 603/1674 [34:21<55:50,  3.13s/it] 36%|███▌      | 604/1674 [34:23<50:30,  2.83s/it] 36%|███▌      | 605/1674 [34:24<43:43,  2.45s/it] 36%|███▌      | 606/1674 [34:28<52:48,  2.97s/it] 36%|███▋      | 607/1674 [34:31<50:43,  2.85s/it] 36%|███▋      | 608/1674 [34:34<49:30,  2.79s/it] 36%|███▋      | 609/1674 [34:36<45:19,  2.55s/it] 36%|███▋      | 610/1674 [34:40<52:37,  2.97s/it]                                                  {'loss': 0.4366, 'grad_norm': 66.81704711914062, 'learning_rate': 2.9138755980861244e-07, 'rewards/chosen': 0.3643798828125, 'rewards/rejected': -0.521533191204071, 'rewards/accuracies': 0.8166667222976685, 'rewards/margins': 0.8871093988418579, 'logps/chosen': -154.5500030517578, 'logps/rejected': -160.1750030517578, 'logits/chosen': -6.609375, 'logits/rejected': -6.474999904632568, 'epoch': 1.09}
 36%|███▋      | 610/1674 [34:40<52:37,  2.97s/it] 36%|███▋      | 611/1674 [34:43<53:41,  3.03s/it] 37%|███▋      | 612/1674 [34:46<55:20,  3.13s/it] 37%|███▋      | 613/1674 [34:49<55:25,  3.13s/it] 37%|███▋      | 614/1674 [34:53<59:41,  3.38s/it] 37%|███▋      | 615/1674 [34:56<55:27,  3.14s/it] 37%|███▋      | 616/1674 [34:59<57:55,  3.29s/it] 37%|███▋      | 617/1674 [35:02<51:50,  2.94s/it] 37%|███▋      | 618/1674 [35:05<56:19,  3.20s/it] 37%|███▋      | 619/1674 [35:07<47:59,  2.73s/it] 37%|███▋      | 620/1674 [35:10<48:10,  2.74s/it]                                                  {'loss': 0.4508, 'grad_norm': 20.913562774658203, 'learning_rate': 2.9617224880382774e-07, 'rewards/chosen': 0.28173828125, 'rewards/rejected': -0.5874999761581421, 'rewards/accuracies': 0.7916666865348816, 'rewards/margins': 0.870312511920929, 'logps/chosen': -72.42500305175781, 'logps/rejected': -91.3499984741211, 'logits/chosen': -6.6875, 'logits/rejected': -6.287499904632568, 'epoch': 1.11}
 37%|███▋      | 620/1674 [35:10<48:10,  2.74s/it] 37%|███▋      | 621/1674 [35:14<54:18,  3.09s/it] 37%|███▋      | 622/1674 [35:16<52:47,  3.01s/it] 37%|███▋      | 623/1674 [35:19<48:28,  2.77s/it] 37%|███▋      | 624/1674 [35:20<43:26,  2.48s/it] 37%|███▋      | 625/1674 [35:23<43:23,  2.48s/it] 37%|███▋      | 626/1674 [35:26<47:24,  2.71s/it] 37%|███▋      | 627/1674 [35:30<52:17,  3.00s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:57,  1.35it/s][A
  4%|▍         | 3/80 [00:03<01:23,  1.09s/it][A
  5%|▌         | 4/80 [00:04<01:36,  1.26s/it][A
  6%|▋         | 5/80 [00:06<01:45,  1.40s/it][A
  8%|▊         | 6/80 [00:07<01:47,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:51,  1.53s/it][A
 10%|█         | 8/80 [00:11<01:52,  1.57s/it][A
 11%|█▏        | 9/80 [00:12<01:54,  1.61s/it][A
 12%|█▎        | 10/80 [00:14<01:54,  1.64s/it][A
 14%|█▍        | 11/80 [00:16<01:53,  1.65s/it][A
 15%|█▌        | 12/80 [00:17<01:50,  1.62s/it][A
 16%|█▋        | 13/80 [00:19<01:47,  1.61s/it][A
 18%|█▊        | 14/80 [00:21<01:48,  1.64s/it][A
 19%|█▉        | 15/80 [00:22<01:45,  1.63s/it][A
 20%|██        | 16/80 [00:24<01:43,  1.61s/it][A
 21%|██▏       | 17/80 [00:25<01:41,  1.61s/it][A
 22%|██▎       | 18/80 [00:27<01:40,  1.62s/it][A
 24%|██▍       | 19/80 [00:28<01:29,  1.47s/it][A
 25%|██▌       | 20/80 [00:29<01:24,  1.41s/it][A
 26%|██▋       | 21/80 [00:30<01:07,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:05,  1.13s/it][A
 29%|██▉       | 23/80 [00:32<01:03,  1.12s/it][A
 30%|███       | 24/80 [00:33<00:51,  1.08it/s][A
 31%|███▏      | 25/80 [00:34<00:54,  1.00it/s][A
 32%|███▎      | 26/80 [00:35<00:58,  1.08s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.04it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.03it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.09s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.05it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.16s/it][A
 42%|████▎     | 34/80 [00:44<00:56,  1.24s/it][A
 44%|████▍     | 35/80 [00:44<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.07it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.23it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:48,  1.21s/it][A
 51%|█████▏    | 41/80 [00:50<00:39,  1.02s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.18s/it][A
 54%|█████▍    | 43/80 [00:53<00:46,  1.26s/it][A
 55%|█████▌    | 44/80 [00:55<00:44,  1.25s/it][A
 56%|█████▋    | 45/80 [00:55<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.08it/s][A
 59%|█████▉    | 47/80 [00:57<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:37,  1.19s/it][A
 61%|██████▏   | 49/80 [00:59<00:31,  1.00s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.19it/s][A
 64%|██████▍   | 51/80 [01:01<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:03<00:26,  1.03it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:05<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.18s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:09<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.21s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.01s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.16s/it][A
 78%|███████▊  | 62/80 [01:14<00:23,  1.32s/it][A
 79%|███████▉  | 63/80 [01:15<00:21,  1.25s/it][A
 80%|████████  | 64/80 [01:16<00:17,  1.12s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.23s/it][A
 82%|████████▎ | 66/80 [01:19<00:18,  1.33s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.44s/it][A
 85%|████████▌ | 68/80 [01:22<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:26<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:28<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:30<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:31<00:06,  1.27s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.36s/it][A
 96%|█████████▋| 77/80 [01:34<00:04,  1.36s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.12s/it][A
 99%|█████████▉| 79/80 [01:36<00:01,  1.26s/it][A
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A                                                  
                                               [A{'eval_loss': 0.4945473074913025, 'eval_runtime': 100.186, 'eval_samples_per_second': 9.512, 'eval_steps_per_second': 0.799, 'eval_rewards/chosen': 0.26933804154396057, 'eval_rewards/rejected': -0.46195220947265625, 'eval_rewards/accuracies': 0.7687500715255737, 'eval_rewards/margins': 0.7318252325057983, 'eval_logps/chosen': -356.234375, 'eval_logps/rejected': -159.17813110351562, 'eval_logits/chosen': -6.158007621765137, 'eval_logits/rejected': -6.533593654632568, 'epoch': 1.12}
 37%|███▋      | 627/1674 [37:10<52:17,  3.00s/it]
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 38%|███▊      | 628/1674 [37:28<10:56:20, 37.65s/it] 38%|███▊      | 629/1674 [37:31<7:50:44, 27.03s/it]  38%|███▊      | 630/1674 [37:35<5:51:06, 20.18s/it]                                                    {'loss': 0.4974, 'grad_norm': 31.64543342590332, 'learning_rate': 3.0095693779904305e-07, 'rewards/chosen': 0.20620116591453552, 'rewards/rejected': -0.596972644329071, 'rewards/accuracies': 0.7750000953674316, 'rewards/margins': 0.802746593952179, 'logps/chosen': -81.80000305175781, 'logps/rejected': -104.0999984741211, 'logits/chosen': -6.643750190734863, 'logits/rejected': -6.362500190734863, 'epoch': 1.13}
 38%|███▊      | 630/1674 [37:35<5:51:06, 20.18s/it] 38%|███▊      | 631/1674 [37:37<4:18:34, 14.88s/it] 38%|███▊      | 632/1674 [37:41<3:17:44, 11.39s/it] 38%|███▊      | 633/1674 [37:44<2:35:53,  8.99s/it] 38%|███▊      | 634/1674 [37:48<2:09:04,  7.45s/it] 38%|███▊      | 635/1674 [37:51<1:46:11,  6.13s/it] 38%|███▊      | 636/1674 [37:53<1:26:53,  5.02s/it] 38%|███▊      | 637/1674 [37:56<1:13:52,  4.27s/it] 38%|███▊      | 638/1674 [37:59<1:08:23,  3.96s/it] 38%|███▊      | 639/1674 [38:03<1:05:51,  3.82s/it] 38%|███▊      | 640/1674 [38:06<1:05:33,  3.80s/it]                                                    {'loss': 0.4307, 'grad_norm': 19.915258407592773, 'learning_rate': 3.0574162679425835e-07, 'rewards/chosen': 0.3253417909145355, 'rewards/rejected': -0.600781261920929, 'rewards/accuracies': 0.8166666030883789, 'rewards/margins': 0.9263671636581421, 'logps/chosen': -74.25, 'logps/rejected': -103.5999984741211, 'logits/chosen': -6.909375190734863, 'logits/rejected': -6.46875, 'epoch': 1.15}
 38%|███▊      | 640/1674 [38:06<1:05:33,  3.80s/it] 38%|███▊      | 641/1674 [38:10<1:07:12,  3.90s/it] 38%|███▊      | 642/1674 [38:14<1:05:56,  3.83s/it] 38%|███▊      | 643/1674 [38:16<56:41,  3.30s/it]   38%|███▊      | 644/1674 [38:19<54:08,  3.15s/it] 39%|███▊      | 645/1674 [38:22<55:12,  3.22s/it] 39%|███▊      | 646/1674 [38:25<51:00,  2.98s/it] 39%|███▊      | 647/1674 [38:27<47:50,  2.79s/it] 39%|███▊      | 648/1674 [38:29<44:13,  2.59s/it] 39%|███▉      | 649/1674 [38:33<49:04,  2.87s/it] 39%|███▉      | 650/1674 [38:36<49:59,  2.93s/it]                                                  {'loss': 0.3626, 'grad_norm': 15.355107307434082, 'learning_rate': 3.1052631578947366e-07, 'rewards/chosen': 0.3326171934604645, 'rewards/rejected': -0.7865234613418579, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 1.119531273841858, 'logps/chosen': -71.9000015258789, 'logps/rejected': -80.07499694824219, 'logits/chosen': -6.753125190734863, 'logits/rejected': -6.734375, 'epoch': 1.16}
 39%|███▉      | 650/1674 [38:36<49:59,  2.93s/it] 39%|███▉      | 651/1674 [38:38<45:23,  2.66s/it] 39%|███▉      | 652/1674 [38:42<50:19,  2.95s/it] 39%|███▉      | 653/1674 [38:43<45:10,  2.65s/it] 39%|███▉      | 654/1674 [38:46<44:15,  2.60s/it] 39%|███▉      | 655/1674 [38:49<44:16,  2.61s/it] 39%|███▉      | 656/1674 [38:51<42:45,  2.52s/it] 39%|███▉      | 657/1674 [38:54<46:12,  2.73s/it] 39%|███▉      | 658/1674 [38:57<44:55,  2.65s/it] 39%|███▉      | 659/1674 [38:59<44:25,  2.63s/it] 39%|███▉      | 660/1674 [39:02<45:08,  2.67s/it]                                                  {'loss': 0.4503, 'grad_norm': 28.0135555267334, 'learning_rate': 3.1531100478468896e-07, 'rewards/chosen': 0.2421875, 'rewards/rejected': -0.6158202886581421, 'rewards/accuracies': 0.8416666984558105, 'rewards/margins': 0.8580077886581421, 'logps/chosen': -76.0, 'logps/rejected': -90.3499984741211, 'logits/chosen': -6.978125095367432, 'logits/rejected': -6.690625190734863, 'epoch': 1.18}
 39%|███▉      | 660/1674 [39:02<45:08,  2.67s/it] 39%|███▉      | 661/1674 [39:04<39:46,  2.36s/it] 40%|███▉      | 662/1674 [39:06<39:40,  2.35s/it] 40%|███▉      | 663/1674 [39:10<46:11,  2.74s/it] 40%|███▉      | 664/1674 [39:13<48:40,  2.89s/it] 40%|███▉      | 665/1674 [39:17<53:50,  3.20s/it] 40%|███▉      | 666/1674 [39:20<54:10,  3.22s/it] 40%|███▉      | 667/1674 [39:22<46:43,  2.78s/it] 40%|███▉      | 668/1674 [39:26<53:05,  3.17s/it] 40%|███▉      | 669/1674 [39:28<47:42,  2.85s/it] 40%|████      | 670/1674 [39:31<50:55,  3.04s/it]                                                  {'loss': 0.378, 'grad_norm': 14.683916091918945, 'learning_rate': 3.2009569377990427e-07, 'rewards/chosen': 0.35498046875, 'rewards/rejected': -0.7796875238418579, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.1339843273162842, 'logps/chosen': -115.80000305175781, 'logps/rejected': -127.55000305175781, 'logits/chosen': -6.75, 'logits/rejected': -6.4375, 'epoch': 1.2}
 40%|████      | 670/1674 [39:32<50:55,  3.04s/it] 40%|████      | 671/1674 [39:35<51:47,  3.10s/it] 40%|████      | 672/1674 [39:37<48:20,  2.90s/it] 40%|████      | 673/1674 [39:41<51:15,  3.07s/it] 40%|████      | 674/1674 [39:44<50:45,  3.05s/it] 40%|████      | 675/1674 [39:46<49:35,  2.98s/it] 40%|████      | 676/1674 [39:51<55:52,  3.36s/it] 40%|████      | 677/1674 [39:54<54:03,  3.25s/it] 41%|████      | 678/1674 [39:56<51:06,  3.08s/it] 41%|████      | 679/1674 [40:00<56:37,  3.41s/it] 41%|████      | 680/1674 [40:03<52:03,  3.14s/it]                                                  {'loss': 0.4635, 'grad_norm': 35.0091438293457, 'learning_rate': 3.248803827751196e-07, 'rewards/chosen': 0.17282715439796448, 'rewards/rejected': -0.7060546875, 'rewards/accuracies': 0.8083332777023315, 'rewards/margins': 0.8785156011581421, 'logps/chosen': -77.3499984741211, 'logps/rejected': -122.05000305175781, 'logits/chosen': -7.043749809265137, 'logits/rejected': -6.418749809265137, 'epoch': 1.22}
 41%|████      | 680/1674 [40:03<52:03,  3.14s/it] 41%|████      | 681/1674 [40:06<49:38,  3.00s/it] 41%|████      | 682/1674 [40:10<56:31,  3.42s/it] 41%|████      | 683/1674 [40:12<51:31,  3.12s/it] 41%|████      | 684/1674 [40:16<53:26,  3.24s/it] 41%|████      | 685/1674 [40:19<50:29,  3.06s/it] 41%|████      | 686/1674 [40:21<47:04,  2.86s/it] 41%|████      | 687/1674 [40:23<44:23,  2.70s/it] 41%|████      | 688/1674 [40:27<47:05,  2.87s/it] 41%|████      | 689/1674 [40:31<52:44,  3.21s/it] 41%|████      | 690/1674 [40:33<50:22,  3.07s/it]                                                  {'loss': 0.4038, 'grad_norm': 17.02577018737793, 'learning_rate': 3.2966507177033493e-07, 'rewards/chosen': 0.23051758110523224, 'rewards/rejected': -0.837890625, 'rewards/accuracies': 0.8333333134651184, 'rewards/margins': 1.068359375, 'logps/chosen': -75.57499694824219, 'logps/rejected': -90.4749984741211, 'logits/chosen': -6.993750095367432, 'logits/rejected': -6.946875095367432, 'epoch': 1.24}
 41%|████      | 690/1674 [40:33<50:22,  3.07s/it] 41%|████▏     | 691/1674 [40:37<55:03,  3.36s/it] 41%|████▏     | 692/1674 [40:41<56:22,  3.44s/it] 41%|████▏     | 693/1674 [40:45<57:38,  3.53s/it] 41%|████▏     | 694/1674 [40:48<56:58,  3.49s/it] 42%|████▏     | 695/1674 [40:51<56:04,  3.44s/it] 42%|████▏     | 696/1674 [40:55<57:04,  3.50s/it] 42%|████▏     | 697/1674 [40:57<48:23,  2.97s/it] 42%|████▏     | 698/1674 [41:00<48:08,  2.96s/it] 42%|████▏     | 699/1674 [41:03<49:23,  3.04s/it] 42%|████▏     | 700/1674 [41:06<49:09,  3.03s/it]                                                  {'loss': 0.4347, 'grad_norm': 17.31833839416504, 'learning_rate': 3.3444976076555024e-07, 'rewards/chosen': 0.11276855319738388, 'rewards/rejected': -0.82421875, 'rewards/accuracies': 0.8249999284744263, 'rewards/margins': 0.936718761920929, 'logps/chosen': -73.5999984741211, 'logps/rejected': -102.32499694824219, 'logits/chosen': -7.071875095367432, 'logits/rejected': -6.703125, 'epoch': 1.25}
 42%|████▏     | 700/1674 [41:06<49:09,  3.03s/it] 42%|████▏     | 701/1674 [41:09<49:58,  3.08s/it] 42%|████▏     | 702/1674 [41:12<49:07,  3.03s/it] 42%|████▏     | 703/1674 [41:15<47:03,  2.91s/it] 42%|████▏     | 704/1674 [41:18<50:09,  3.10s/it] 42%|████▏     | 705/1674 [41:20<42:32,  2.63s/it] 42%|████▏     | 706/1674 [41:22<42:03,  2.61s/it] 42%|████▏     | 707/1674 [41:25<40:50,  2.53s/it] 42%|████▏     | 708/1674 [41:27<38:28,  2.39s/it] 42%|████▏     | 709/1674 [41:30<43:36,  2.71s/it] 42%|████▏     | 710/1674 [41:34<49:17,  3.07s/it]                                                  {'loss': 0.4004, 'grad_norm': 19.197982788085938, 'learning_rate': 3.3923444976076555e-07, 'rewards/chosen': 0.17239990830421448, 'rewards/rejected': -0.846484363079071, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.01953125, 'logps/chosen': -78.19999694824219, 'logps/rejected': -96.125, 'logits/chosen': -6.865624904632568, 'logits/rejected': -6.625, 'epoch': 1.27}
 42%|████▏     | 710/1674 [41:34<49:17,  3.07s/it] 42%|████▏     | 711/1674 [41:37<45:58,  2.86s/it] 43%|████▎     | 712/1674 [41:40<49:13,  3.07s/it] 43%|████▎     | 713/1674 [41:43<49:09,  3.07s/it] 43%|████▎     | 714/1674 [41:47<50:44,  3.17s/it] 43%|████▎     | 715/1674 [41:48<44:10,  2.76s/it] 43%|████▎     | 716/1674 [41:53<51:11,  3.21s/it] 43%|████▎     | 717/1674 [41:56<50:28,  3.16s/it] 43%|████▎     | 718/1674 [41:59<50:51,  3.19s/it] 43%|████▎     | 719/1674 [42:01<46:36,  2.93s/it] 43%|████▎     | 720/1674 [42:04<45:26,  2.86s/it]                                                  {'loss': 0.4008, 'grad_norm': 21.726978302001953, 'learning_rate': 3.4401913875598085e-07, 'rewards/chosen': 0.21147461235523224, 'rewards/rejected': -0.8843749761581421, 'rewards/accuracies': 0.8333333134651184, 'rewards/margins': 1.096289038658142, 'logps/chosen': -76.0, 'logps/rejected': -108.3499984741211, 'logits/chosen': -7.1875, 'logits/rejected': -6.796875, 'epoch': 1.29}
 43%|████▎     | 720/1674 [42:04<45:26,  2.86s/it] 43%|████▎     | 721/1674 [42:06<43:35,  2.74s/it] 43%|████▎     | 722/1674 [42:09<43:19,  2.73s/it] 43%|████▎     | 723/1674 [42:11<40:05,  2.53s/it] 43%|████▎     | 724/1674 [42:13<38:02,  2.40s/it] 43%|████▎     | 725/1674 [42:16<37:47,  2.39s/it] 43%|████▎     | 726/1674 [42:20<44:48,  2.84s/it] 43%|████▎     | 727/1674 [42:23<49:01,  3.11s/it] 43%|████▎     | 728/1674 [42:26<49:10,  3.12s/it] 44%|████▎     | 729/1674 [42:28<43:33,  2.77s/it] 44%|████▎     | 730/1674 [42:31<40:37,  2.58s/it]                                                  {'loss': 0.4348, 'grad_norm': 35.304962158203125, 'learning_rate': 3.4880382775119616e-07, 'rewards/chosen': 0.21135254204273224, 'rewards/rejected': -0.885546863079071, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.097265601158142, 'logps/chosen': -68.875, 'logps/rejected': -83.6500015258789, 'logits/chosen': -7.203125, 'logits/rejected': -6.953125, 'epoch': 1.31}
 44%|████▎     | 730/1674 [42:31<40:37,  2.58s/it] 44%|████▎     | 731/1674 [42:34<46:17,  2.95s/it] 44%|████▎     | 732/1674 [42:38<47:35,  3.03s/it] 44%|████▍     | 733/1674 [42:40<43:12,  2.75s/it] 44%|████▍     | 734/1674 [42:43<47:10,  3.01s/it] 44%|████▍     | 735/1674 [42:46<45:29,  2.91s/it] 44%|████▍     | 736/1674 [42:49<47:16,  3.02s/it] 44%|████▍     | 737/1674 [42:52<46:03,  2.95s/it] 44%|████▍     | 738/1674 [42:55<44:41,  2.87s/it] 44%|████▍     | 739/1674 [42:58<48:10,  3.09s/it] 44%|████▍     | 740/1674 [43:02<51:39,  3.32s/it]                                                  {'loss': 0.4906, 'grad_norm': 30.747194290161133, 'learning_rate': 3.5358851674641146e-07, 'rewards/chosen': -0.02996826171875, 'rewards/rejected': -0.9281250238418579, 'rewards/accuracies': 0.7916666865348816, 'rewards/margins': 0.897656261920929, 'logps/chosen': -89.44999694824219, 'logps/rejected': -108.69999694824219, 'logits/chosen': -7.112500190734863, 'logits/rejected': -6.631249904632568, 'epoch': 1.33}
 44%|████▍     | 740/1674 [43:02<51:39,  3.32s/it] 44%|████▍     | 741/1674 [43:06<53:17,  3.43s/it] 44%|████▍     | 742/1674 [43:09<52:59,  3.41s/it] 44%|████▍     | 743/1674 [43:11<47:35,  3.07s/it] 44%|████▍     | 744/1674 [43:15<47:57,  3.09s/it] 45%|████▍     | 745/1674 [43:18<50:01,  3.23s/it] 45%|████▍     | 746/1674 [43:22<51:59,  3.36s/it] 45%|████▍     | 747/1674 [43:25<52:02,  3.37s/it] 45%|████▍     | 748/1674 [43:28<49:08,  3.18s/it] 45%|████▍     | 749/1674 [43:31<48:37,  3.15s/it] 45%|████▍     | 750/1674 [43:33<42:21,  2.75s/it]                                                  {'loss': 0.3751, 'grad_norm': 10.910343170166016, 'learning_rate': 3.5837320574162677e-07, 'rewards/chosen': 0.2591796815395355, 'rewards/rejected': -1.004296898841858, 'rewards/accuracies': 0.85833340883255, 'rewards/margins': 1.263769507408142, 'logps/chosen': -74.44999694824219, 'logps/rejected': -119.6500015258789, 'logits/chosen': -7.349999904632568, 'logits/rejected': -6.925000190734863, 'epoch': 1.34}
 45%|████▍     | 750/1674 [43:33<42:21,  2.75s/it] 45%|████▍     | 751/1674 [43:36<44:03,  2.86s/it] 45%|████▍     | 752/1674 [43:38<41:25,  2.70s/it] 45%|████▍     | 753/1674 [43:41<42:14,  2.75s/it] 45%|████▌     | 754/1674 [43:45<45:07,  2.94s/it] 45%|████▌     | 755/1674 [43:47<43:09,  2.82s/it] 45%|████▌     | 756/1674 [43:51<49:19,  3.22s/it] 45%|████▌     | 757/1674 [43:55<51:34,  3.37s/it] 45%|████▌     | 758/1674 [43:59<54:58,  3.60s/it] 45%|████▌     | 759/1674 [44:02<52:36,  3.45s/it] 45%|████▌     | 760/1674 [44:06<52:26,  3.44s/it]                                                  {'loss': 0.4271, 'grad_norm': 37.621009826660156, 'learning_rate': 3.6315789473684213e-07, 'rewards/chosen': 0.10986328125, 'rewards/rejected': -1.001562476158142, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.1124999523162842, 'logps/chosen': -80.57499694824219, 'logps/rejected': -107.6500015258789, 'logits/chosen': -7.446875095367432, 'logits/rejected': -7.050000190734863, 'epoch': 1.36}
 45%|████▌     | 760/1674 [44:06<52:26,  3.44s/it] 45%|████▌     | 761/1674 [44:09<51:32,  3.39s/it] 46%|████▌     | 762/1674 [44:13<52:46,  3.47s/it] 46%|████▌     | 763/1674 [44:16<53:13,  3.51s/it] 46%|████▌     | 764/1674 [44:19<51:05,  3.37s/it] 46%|████▌     | 765/1674 [44:21<46:00,  3.04s/it] 46%|████▌     | 766/1674 [44:25<48:11,  3.18s/it] 46%|████▌     | 767/1674 [44:27<43:30,  2.88s/it] 46%|████▌     | 768/1674 [44:31<45:47,  3.03s/it] 46%|████▌     | 769/1674 [44:33<42:28,  2.82s/it] 46%|████▌     | 770/1674 [44:37<46:22,  3.08s/it]                                                  {'loss': 0.3522, 'grad_norm': 26.29414939880371, 'learning_rate': 3.6794258373205743e-07, 'rewards/chosen': 0.15993042290210724, 'rewards/rejected': -1.148828148841858, 'rewards/accuracies': 0.8416666984558105, 'rewards/margins': 1.3078124523162842, 'logps/chosen': -74.0999984741211, 'logps/rejected': -100.8499984741211, 'logits/chosen': -7.378125190734863, 'logits/rejected': -7.090624809265137, 'epoch': 1.38}
 46%|████▌     | 770/1674 [44:37<46:22,  3.08s/it] 46%|████▌     | 771/1674 [44:39<43:27,  2.89s/it] 46%|████▌     | 772/1674 [44:43<47:23,  3.15s/it] 46%|████▌     | 773/1674 [44:46<48:49,  3.25s/it] 46%|████▌     | 774/1674 [44:50<51:05,  3.41s/it] 46%|████▋     | 775/1674 [44:53<48:45,  3.25s/it] 46%|████▋     | 776/1674 [44:57<50:16,  3.36s/it] 46%|████▋     | 777/1674 [45:00<48:38,  3.25s/it] 46%|████▋     | 778/1674 [45:01<42:38,  2.86s/it] 47%|████▋     | 779/1674 [45:03<36:46,  2.47s/it] 47%|████▋     | 780/1674 [45:06<39:50,  2.67s/it]                                                  {'loss': 0.3636, 'grad_norm': 20.687814712524414, 'learning_rate': 3.727272727272727e-07, 'rewards/chosen': 0.13158568739891052, 'rewards/rejected': -1.2527344226837158, 'rewards/accuracies': 0.8583332896232605, 'rewards/margins': 1.385156273841858, 'logps/chosen': -76.05000305175781, 'logps/rejected': -106.75, 'logits/chosen': -7.515625, 'logits/rejected': -7.053124904632568, 'epoch': 1.4}
 47%|████▋     | 780/1674 [45:06<39:50,  2.67s/it] 47%|████▋     | 781/1674 [45:09<38:36,  2.59s/it] 47%|████▋     | 782/1674 [45:11<39:44,  2.67s/it] 47%|████▋     | 783/1674 [45:15<44:09,  2.97s/it] 47%|████▋     | 784/1674 [45:17<41:22,  2.79s/it] 47%|████▋     | 785/1674 [45:20<41:12,  2.78s/it] 47%|████▋     | 786/1674 [45:23<41:11,  2.78s/it] 47%|████▋     | 787/1674 [45:26<41:31,  2.81s/it] 47%|████▋     | 788/1674 [45:28<37:49,  2.56s/it] 47%|████▋     | 789/1674 [45:31<41:19,  2.80s/it] 47%|████▋     | 790/1674 [45:34<39:41,  2.69s/it]                                                  {'loss': 0.3258, 'grad_norm': 9.684356689453125, 'learning_rate': 3.77511961722488e-07, 'rewards/chosen': 0.17219237983226776, 'rewards/rejected': -1.3097655773162842, 'rewards/accuracies': 0.8583332896232605, 'rewards/margins': 1.48046875, 'logps/chosen': -70.5, 'logps/rejected': -107.07499694824219, 'logits/chosen': -7.368750095367432, 'logits/rejected': -6.981249809265137, 'epoch': 1.42}
 47%|████▋     | 790/1674 [45:34<39:41,  2.69s/it] 47%|████▋     | 791/1674 [45:36<37:17,  2.53s/it] 47%|████▋     | 792/1674 [45:38<36:42,  2.50s/it] 47%|████▋     | 793/1674 [45:42<44:00,  3.00s/it] 47%|████▋     | 794/1674 [45:45<43:14,  2.95s/it] 47%|████▋     | 795/1674 [45:47<39:28,  2.69s/it] 48%|████▊     | 796/1674 [45:51<44:07,  3.02s/it] 48%|████▊     | 797/1674 [45:53<40:29,  2.77s/it] 48%|████▊     | 798/1674 [45:56<40:24,  2.77s/it] 48%|████▊     | 799/1674 [45:59<41:38,  2.86s/it] 48%|████▊     | 800/1674 [46:02<41:09,  2.83s/it]                                                  {'loss': 0.3934, 'grad_norm': 26.397624969482422, 'learning_rate': 3.822966507177033e-07, 'rewards/chosen': -0.02474365197122097, 'rewards/rejected': -1.353515625, 'rewards/accuracies': 0.8333333730697632, 'rewards/margins': 1.3292968273162842, 'logps/chosen': -76.7750015258789, 'logps/rejected': -95.5, 'logits/chosen': -7.459374904632568, 'logits/rejected': -7.021874904632568, 'epoch': 1.43}
 48%|████▊     | 800/1674 [46:02<41:09,  2.83s/it] 48%|████▊     | 801/1674 [46:06<45:36,  3.13s/it] 48%|████▊     | 802/1674 [46:09<45:46,  3.15s/it] 48%|████▊     | 803/1674 [46:11<42:51,  2.95s/it] 48%|████▊     | 804/1674 [46:13<37:27,  2.58s/it] 48%|████▊     | 805/1674 [46:16<36:42,  2.53s/it] 48%|████▊     | 806/1674 [46:19<42:18,  2.92s/it] 48%|████▊     | 807/1674 [46:23<47:08,  3.26s/it] 48%|████▊     | 808/1674 [46:26<44:43,  3.10s/it] 48%|████▊     | 809/1674 [46:29<42:33,  2.95s/it] 48%|████▊     | 810/1674 [46:32<43:56,  3.05s/it]                                                  {'loss': 0.3811, 'grad_norm': 15.785771369934082, 'learning_rate': 3.8708133971291866e-07, 'rewards/chosen': 0.12842407822608948, 'rewards/rejected': -1.189843773841858, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.3171875476837158, 'logps/chosen': -71.6500015258789, 'logps/rejected': -88.6500015258789, 'logits/chosen': -7.550000190734863, 'logits/rejected': -7.193749904632568, 'epoch': 1.45}
 48%|████▊     | 810/1674 [46:32<43:56,  3.05s/it] 48%|████▊     | 811/1674 [46:35<41:27,  2.88s/it] 49%|████▊     | 812/1674 [46:38<44:57,  3.13s/it] 49%|████▊     | 813/1674 [46:40<40:38,  2.83s/it] 49%|████▊     | 814/1674 [46:44<44:55,  3.13s/it] 49%|████▊     | 815/1674 [46:48<47:29,  3.32s/it] 49%|████▊     | 816/1674 [46:52<48:47,  3.41s/it] 49%|████▉     | 817/1674 [46:53<40:57,  2.87s/it] 49%|████▉     | 818/1674 [46:57<43:01,  3.02s/it] 49%|████▉     | 819/1674 [46:59<41:19,  2.90s/it] 49%|████▉     | 820/1674 [47:02<39:23,  2.77s/it]                                                  {'loss': 0.3737, 'grad_norm': 13.167166709899902, 'learning_rate': 3.9186602870813396e-07, 'rewards/chosen': 0.01334228552877903, 'rewards/rejected': -1.4523437023162842, 'rewards/accuracies': 0.8333333134651184, 'rewards/margins': 1.4656250476837158, 'logps/chosen': -88.69999694824219, 'logps/rejected': -98.125, 'logits/chosen': -7.506249904632568, 'logits/rejected': -7.268750190734863, 'epoch': 1.47}
 49%|████▉     | 820/1674 [47:02<39:23,  2.77s/it] 49%|████▉     | 821/1674 [47:04<37:56,  2.67s/it] 49%|████▉     | 822/1674 [47:08<42:47,  3.01s/it] 49%|████▉     | 823/1674 [47:12<45:44,  3.23s/it] 49%|████▉     | 824/1674 [47:15<44:34,  3.15s/it] 49%|████▉     | 825/1674 [47:16<38:25,  2.72s/it] 49%|████▉     | 826/1674 [47:20<40:47,  2.89s/it] 49%|████▉     | 827/1674 [47:23<41:35,  2.95s/it] 49%|████▉     | 828/1674 [47:26<44:10,  3.13s/it] 50%|████▉     | 829/1674 [47:30<47:42,  3.39s/it] 50%|████▉     | 830/1674 [47:33<44:24,  3.16s/it]                                                  {'loss': 0.4156, 'grad_norm': 34.75086975097656, 'learning_rate': 3.9665071770334927e-07, 'rewards/chosen': 0.09125366061925888, 'rewards/rejected': -1.157812476158142, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.248046875, 'logps/chosen': -95.94999694824219, 'logps/rejected': -126.9000015258789, 'logits/chosen': -7.431250095367432, 'logits/rejected': -7.128125190734863, 'epoch': 1.49}
 50%|████▉     | 830/1674 [47:33<44:24,  3.16s/it] 50%|████▉     | 831/1674 [47:35<40:13,  2.86s/it] 50%|████▉     | 832/1674 [47:39<43:16,  3.08s/it] 50%|████▉     | 833/1674 [47:41<42:03,  3.00s/it] 50%|████▉     | 834/1674 [47:45<42:46,  3.06s/it] 50%|████▉     | 835/1674 [47:49<46:26,  3.32s/it] 50%|████▉     | 836/1674 [47:51<42:19,  3.03s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:53,  1.45it/s][A
  4%|▍         | 3/80 [00:02<01:21,  1.06s/it][A
  5%|▌         | 4/80 [00:04<01:34,  1.24s/it][A
  6%|▋         | 5/80 [00:06<01:44,  1.39s/it][A
  8%|▊         | 6/80 [00:07<01:47,  1.45s/it][A
  9%|▉         | 7/80 [00:09<01:49,  1.50s/it][A
 10%|█         | 8/80 [00:11<01:51,  1.55s/it][A
 11%|█▏        | 9/80 [00:12<01:52,  1.58s/it][A
 12%|█▎        | 10/80 [00:14<01:53,  1.62s/it][A
 14%|█▍        | 11/80 [00:16<01:53,  1.64s/it][A
 15%|█▌        | 12/80 [00:17<01:49,  1.61s/it][A
 16%|█▋        | 13/80 [00:19<01:47,  1.60s/it][A
 18%|█▊        | 14/80 [00:20<01:48,  1.64s/it][A
 19%|█▉        | 15/80 [00:22<01:46,  1.64s/it][A
 20%|██        | 16/80 [00:24<01:43,  1.62s/it][A
 21%|██▏       | 17/80 [00:25<01:41,  1.62s/it][A
 22%|██▎       | 18/80 [00:27<01:40,  1.62s/it][A
 24%|██▍       | 19/80 [00:28<01:29,  1.47s/it][A
 25%|██▌       | 20/80 [00:29<01:24,  1.41s/it][A
 26%|██▋       | 21/80 [00:30<01:07,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:05,  1.13s/it][A
 29%|██▉       | 23/80 [00:32<01:03,  1.11s/it][A
 30%|███       | 24/80 [00:32<00:51,  1.08it/s][A
 31%|███▏      | 25/80 [00:34<00:54,  1.00it/s][A
 32%|███▎      | 26/80 [00:35<00:58,  1.08s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.04it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.03it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.09s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.06it/s][A
 41%|████▏     | 33/80 [00:42<00:54,  1.15s/it][A
 42%|████▎     | 34/80 [00:44<00:56,  1.24s/it][A
 44%|████▍     | 35/80 [00:44<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.07it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:46<00:34,  1.23it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:48,  1.21s/it][A
 51%|█████▏    | 41/80 [00:50<00:39,  1.02s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.19s/it][A
 54%|█████▍    | 43/80 [00:53<00:46,  1.26s/it][A
 55%|█████▌    | 44/80 [00:54<00:44,  1.25s/it][A
 56%|█████▋    | 45/80 [00:55<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.08it/s][A
 59%|█████▉    | 47/80 [00:57<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:37,  1.19s/it][A
 61%|██████▏   | 49/80 [00:59<00:31,  1.00s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.19it/s][A
 64%|██████▍   | 51/80 [01:01<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:02<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:03<00:26,  1.03it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:05<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.18s/it][A
 71%|███████▏  | 57/80 [01:07<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:09<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:10<00:25,  1.21s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.01s/it][A
 76%|███████▋  | 61/80 [01:12<00:22,  1.16s/it][A
 78%|███████▊  | 62/80 [01:14<00:23,  1.32s/it][A
 79%|███████▉  | 63/80 [01:15<00:21,  1.25s/it][A
 80%|████████  | 64/80 [01:16<00:18,  1.16s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.25s/it][A
 82%|████████▎ | 66/80 [01:19<00:18,  1.34s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.45s/it][A
 85%|████████▌ | 68/80 [01:22<00:17,  1.48s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:26<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:28<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:30<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:31<00:06,  1.27s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.36s/it][A
 96%|█████████▋| 77/80 [01:34<00:04,  1.37s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.13s/it][A
 99%|█████████▉| 79/80 [01:36<00:01,  1.26s/it][A
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A                                                  
                                               [A{'eval_loss': 0.6115893125534058, 'eval_runtime': 100.1978, 'eval_samples_per_second': 9.511, 'eval_steps_per_second': 0.798, 'eval_rewards/chosen': -0.227447509765625, 'eval_rewards/rejected': -1.1193420886993408, 'eval_rewards/accuracies': 0.7124999761581421, 'eval_rewards/margins': 0.8926857113838196, 'eval_logps/chosen': -361.05938720703125, 'eval_logps/rejected': -165.70938110351562, 'eval_logits/chosen': -7.026562690734863, 'eval_logits/rejected': -7.285546779632568, 'epoch': 1.5}
 50%|████▉     | 836/1674 [49:31<42:19,  3.03s/it]
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 50%|█████     | 837/1674 [49:48<8:41:07, 37.36s/it] 50%|█████     | 838/1674 [49:52<6:18:07, 27.14s/it] 50%|█████     | 839/1674 [49:56<4:40:44, 20.17s/it] 50%|█████     | 840/1674 [49:58<3:28:14, 14.98s/it]                                                    {'loss': 0.4405, 'grad_norm': 19.68077850341797, 'learning_rate': 3.999886160717668e-07, 'rewards/chosen': -0.06212463229894638, 'rewards/rejected': -1.34765625, 'rewards/accuracies': 0.8166666030883789, 'rewards/margins': 1.284814476966858, 'logps/chosen': -130.60000610351562, 'logps/rejected': -144.47500610351562, 'logits/chosen': -7.540625095367432, 'logits/rejected': -7.103125095367432, 'epoch': 1.51}
 50%|█████     | 840/1674 [49:59<3:28:14, 14.98s/it] 50%|█████     | 841/1674 [50:02<2:42:03, 11.67s/it] 50%|█████     | 842/1674 [50:05<2:02:01,  8.80s/it] 50%|█████     | 843/1674 [50:06<1:32:19,  6.67s/it] 50%|█████     | 844/1674 [50:08<1:13:16,  5.30s/it] 50%|█████     | 845/1674 [50:10<1:00:06,  4.35s/it] 51%|█████     | 846/1674 [50:14<58:38,  4.25s/it]   51%|█████     | 847/1674 [50:17<52:33,  3.81s/it] 51%|█████     | 848/1674 [50:21<50:16,  3.65s/it] 51%|█████     | 849/1674 [50:23<46:54,  3.41s/it] 51%|█████     | 850/1674 [50:27<46:46,  3.41s/it]                                                  {'loss': 0.343, 'grad_norm': 14.560600280761719, 'learning_rate': 3.997862751802525e-07, 'rewards/chosen': 0.1298828125, 'rewards/rejected': -1.4324219226837158, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 1.562109351158142, 'logps/chosen': -108.875, 'logps/rejected': -131.72500610351562, 'logits/chosen': -7.599999904632568, 'logits/rejected': -7.21875, 'epoch': 1.52}
 51%|█████     | 850/1674 [50:27<46:46,  3.41s/it] 51%|█████     | 851/1674 [50:31<49:17,  3.59s/it] 51%|█████     | 852/1674 [50:33<44:54,  3.28s/it] 51%|█████     | 853/1674 [50:37<45:44,  3.34s/it] 51%|█████     | 854/1674 [50:40<44:40,  3.27s/it] 51%|█████     | 855/1674 [50:44<47:23,  3.47s/it] 51%|█████     | 856/1674 [50:46<40:19,  2.96s/it] 51%|█████     | 857/1674 [50:49<43:13,  3.17s/it] 51%|█████▏    | 858/1674 [50:52<39:33,  2.91s/it] 51%|█████▏    | 859/1674 [50:54<39:06,  2.88s/it] 51%|█████▏    | 860/1674 [50:57<39:21,  2.90s/it]                                                  {'loss': 0.341, 'grad_norm': 13.38436222076416, 'learning_rate': 3.9933128540846355e-07, 'rewards/chosen': 0.09331054985523224, 'rewards/rejected': -1.5183594226837158, 'rewards/accuracies': 0.7916666269302368, 'rewards/margins': 1.610937476158142, 'logps/chosen': -124.1500015258789, 'logps/rejected': -142.375, 'logits/chosen': -7.528124809265137, 'logits/rejected': -7.368750095367432, 'epoch': 1.54}
 51%|█████▏    | 860/1674 [50:58<39:21,  2.90s/it] 51%|█████▏    | 861/1674 [51:01<41:57,  3.10s/it] 51%|█████▏    | 862/1674 [51:05<45:53,  3.39s/it] 52%|█████▏    | 863/1674 [51:09<48:47,  3.61s/it] 52%|█████▏    | 864/1674 [51:12<44:58,  3.33s/it] 52%|█████▏    | 865/1674 [51:14<39:25,  2.92s/it] 52%|█████▏    | 866/1674 [51:16<34:51,  2.59s/it] 52%|█████▏    | 867/1674 [51:17<31:47,  2.36s/it] 52%|█████▏    | 868/1674 [51:21<37:52,  2.82s/it] 52%|█████▏    | 869/1674 [51:24<36:09,  2.70s/it] 52%|█████▏    | 870/1674 [51:26<34:15,  2.56s/it]                                                  {'loss': 0.3124, 'grad_norm': 10.739717483520508, 'learning_rate': 3.98624286141449e-07, 'rewards/chosen': 0.08054199069738388, 'rewards/rejected': -1.631250023841858, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 1.712499976158142, 'logps/chosen': -81.4000015258789, 'logps/rejected': -100.75, 'logits/chosen': -7.790625095367432, 'logits/rejected': -7.449999809265137, 'epoch': 1.56}
 52%|█████▏    | 870/1674 [51:26<34:15,  2.56s/it] 52%|█████▏    | 871/1674 [51:30<39:25,  2.95s/it] 52%|█████▏    | 872/1674 [51:32<37:22,  2.80s/it] 52%|█████▏    | 873/1674 [51:34<32:16,  2.42s/it] 52%|█████▏    | 874/1674 [51:36<29:53,  2.24s/it] 52%|█████▏    | 875/1674 [51:39<34:51,  2.62s/it] 52%|█████▏    | 876/1674 [51:42<37:50,  2.84s/it] 52%|█████▏    | 877/1674 [51:46<38:58,  2.93s/it] 52%|█████▏    | 878/1674 [51:50<42:56,  3.24s/it] 53%|█████▎    | 879/1674 [51:53<44:49,  3.38s/it] 53%|█████▎    | 880/1674 [51:56<42:38,  3.22s/it]                                                  {'loss': 0.4017, 'grad_norm': 15.208357810974121, 'learning_rate': 3.9766627090651214e-07, 'rewards/chosen': -0.06337890774011612, 'rewards/rejected': -1.607812523841858, 'rewards/accuracies': 0.7999999523162842, 'rewards/margins': 1.5437500476837158, 'logps/chosen': -71.9000015258789, 'logps/rejected': -101.57499694824219, 'logits/chosen': -7.909375190734863, 'logits/rejected': -7.293749809265137, 'epoch': 1.58}
 53%|█████▎    | 880/1674 [51:56<42:38,  3.22s/it] 53%|█████▎    | 881/1674 [52:00<44:07,  3.34s/it] 53%|█████▎    | 882/1674 [52:03<44:05,  3.34s/it] 53%|█████▎    | 883/1674 [52:06<40:53,  3.10s/it] 53%|█████▎    | 884/1674 [52:09<40:06,  3.05s/it] 53%|█████▎    | 885/1674 [52:11<36:56,  2.81s/it] 53%|█████▎    | 886/1674 [52:13<36:15,  2.76s/it] 53%|█████▎    | 887/1674 [52:17<37:25,  2.85s/it] 53%|█████▎    | 888/1674 [52:19<37:07,  2.83s/it] 53%|█████▎    | 889/1674 [52:21<33:28,  2.56s/it] 53%|█████▎    | 890/1674 [52:24<32:33,  2.49s/it]                                                  {'loss': 0.3501, 'grad_norm': 12.743982315063477, 'learning_rate': 3.964585859770332e-07, 'rewards/chosen': 0.04629363864660263, 'rewards/rejected': -1.541406273841858, 'rewards/accuracies': 0.8666666150093079, 'rewards/margins': 1.5871093273162842, 'logps/chosen': -62.67499923706055, 'logps/rejected': -84.5, 'logits/chosen': -7.90625, 'logits/rejected': -7.471875190734863, 'epoch': 1.59}
 53%|█████▎    | 890/1674 [52:24<32:33,  2.49s/it] 53%|█████▎    | 891/1674 [52:27<37:53,  2.90s/it] 53%|█████▎    | 892/1674 [52:31<41:49,  3.21s/it] 53%|█████▎    | 893/1674 [52:34<38:03,  2.92s/it] 53%|█████▎    | 894/1674 [52:36<35:38,  2.74s/it] 53%|█████▎    | 895/1674 [52:40<40:25,  3.11s/it] 54%|█████▎    | 896/1674 [52:43<41:53,  3.23s/it] 54%|█████▎    | 897/1674 [52:46<38:33,  2.98s/it] 54%|█████▎    | 898/1674 [52:48<36:28,  2.82s/it] 54%|█████▎    | 899/1674 [52:50<31:44,  2.46s/it] 54%|█████▍    | 900/1674 [52:54<37:53,  2.94s/it]                                                  {'loss': 0.3421, 'grad_norm': 12.225056648254395, 'learning_rate': 3.9500292848058676e-07, 'rewards/chosen': -0.00634765625, 'rewards/rejected': -1.610937476158142, 'rewards/accuracies': 0.85833340883255, 'rewards/margins': 1.6046874523162842, 'logps/chosen': -74.6500015258789, 'logps/rejected': -97.44999694824219, 'logits/chosen': -7.846875190734863, 'logits/rejected': -7.418749809265137, 'epoch': 1.61}
 54%|█████▍    | 900/1674 [52:54<37:53,  2.94s/it] 54%|█████▍    | 901/1674 [52:56<34:09,  2.65s/it] 54%|█████▍    | 902/1674 [52:58<31:16,  2.43s/it] 54%|█████▍    | 903/1674 [53:01<33:28,  2.61s/it] 54%|█████▍    | 904/1674 [53:03<32:32,  2.54s/it] 54%|█████▍    | 905/1674 [53:07<35:37,  2.78s/it] 54%|█████▍    | 906/1674 [53:09<33:10,  2.59s/it] 54%|█████▍    | 907/1674 [53:11<31:07,  2.43s/it] 54%|█████▍    | 908/1674 [53:14<32:53,  2.58s/it] 54%|█████▍    | 909/1674 [53:17<34:07,  2.68s/it] 54%|█████▍    | 910/1674 [53:19<31:11,  2.45s/it]                                                  {'loss': 0.3328, 'grad_norm': 10.76741886138916, 'learning_rate': 3.933013440140138e-07, 'rewards/chosen': 0.04423828050494194, 'rewards/rejected': -1.7109375, 'rewards/accuracies': 0.875, 'rewards/margins': 1.755859375, 'logps/chosen': -71.7249984741211, 'logps/rejected': -75.05000305175781, 'logits/chosen': -7.940625190734863, 'logits/rejected': -7.603125095367432, 'epoch': 1.63}
 54%|█████▍    | 910/1674 [53:19<31:11,  2.45s/it] 54%|█████▍    | 911/1674 [53:21<30:04,  2.36s/it] 54%|█████▍    | 912/1674 [53:24<35:29,  2.79s/it] 55%|█████▍    | 913/1674 [53:27<35:17,  2.78s/it] 55%|█████▍    | 914/1674 [53:31<37:36,  2.97s/it] 55%|█████▍    | 915/1674 [53:33<35:01,  2.77s/it] 55%|█████▍    | 916/1674 [53:36<37:45,  2.99s/it] 55%|█████▍    | 917/1674 [53:39<34:12,  2.71s/it] 55%|█████▍    | 918/1674 [53:41<35:00,  2.78s/it] 55%|█████▍    | 919/1674 [53:46<40:03,  3.18s/it] 55%|█████▍    | 920/1674 [53:48<35:22,  2.82s/it]                                                  {'loss': 0.333, 'grad_norm': 11.127667427062988, 'learning_rate': 3.913562237687985e-07, 'rewards/chosen': -0.02070312574505806, 'rewards/rejected': -1.765625, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 1.744531273841858, 'logps/chosen': -84.69999694824219, 'logps/rejected': -114.8499984741211, 'logits/chosen': -8.0, 'logits/rejected': -7.671875, 'epoch': 1.65}
 55%|█████▍    | 920/1674 [53:48<35:22,  2.82s/it] 55%|█████▌    | 921/1674 [53:51<36:00,  2.87s/it] 55%|█████▌    | 922/1674 [53:53<35:16,  2.81s/it] 55%|█████▌    | 923/1674 [53:56<33:32,  2.68s/it] 55%|█████▌    | 924/1674 [53:59<34:58,  2.80s/it] 55%|█████▌    | 925/1674 [54:01<34:54,  2.80s/it] 55%|█████▌    | 926/1674 [54:04<34:14,  2.75s/it] 55%|█████▌    | 927/1674 [54:07<35:40,  2.87s/it] 55%|█████▌    | 928/1674 [54:11<39:49,  3.20s/it] 55%|█████▌    | 929/1674 [54:15<40:17,  3.24s/it] 56%|█████▌    | 930/1674 [54:18<42:16,  3.41s/it]                                                  {'loss': 0.3049, 'grad_norm': 8.53117561340332, 'learning_rate': 3.891703011707901e-07, 'rewards/chosen': -0.06072998046875, 'rewards/rejected': -1.9445312023162842, 'rewards/accuracies': 0.8333333730697632, 'rewards/margins': 1.8859374523162842, 'logps/chosen': -78.42500305175781, 'logps/rejected': -116.42500305175781, 'logits/chosen': -8.040624618530273, 'logits/rejected': -7.521874904632568, 'epoch': 1.67}
 56%|█████▌    | 930/1674 [54:18<42:16,  3.41s/it] 56%|█████▌    | 931/1674 [54:20<35:44,  2.89s/it] 56%|█████▌    | 932/1674 [54:24<39:40,  3.21s/it] 56%|█████▌    | 933/1674 [54:28<42:33,  3.45s/it] 56%|█████▌    | 934/1674 [54:30<38:47,  3.14s/it] 56%|█████▌    | 935/1674 [54:32<32:16,  2.62s/it] 56%|█████▌    | 936/1674 [54:34<32:29,  2.64s/it] 56%|█████▌    | 937/1674 [54:36<29:55,  2.44s/it] 56%|█████▌    | 938/1674 [54:38<27:32,  2.25s/it] 56%|█████▌    | 939/1674 [54:40<26:38,  2.17s/it] 56%|█████▌    | 940/1674 [54:42<25:39,  2.10s/it]                                                  {'loss': 0.3282, 'grad_norm': 9.21084213256836, 'learning_rate': 3.8674664803899275e-07, 'rewards/chosen': -0.12772217392921448, 'rewards/rejected': -1.9226562976837158, 'rewards/accuracies': 0.8249999284744263, 'rewards/margins': 1.794531226158142, 'logps/chosen': -77.17500305175781, 'logps/rejected': -103.9749984741211, 'logits/chosen': -7.828125, 'logits/rejected': -7.425000190734863, 'epoch': 1.68}
 56%|█████▌    | 940/1674 [54:42<25:39,  2.10s/it] 56%|█████▌    | 941/1674 [54:46<32:57,  2.70s/it] 56%|█████▋    | 942/1674 [54:49<31:48,  2.61s/it] 56%|█████▋    | 943/1674 [54:50<28:26,  2.33s/it] 56%|█████▋    | 944/1674 [54:53<30:55,  2.54s/it] 56%|█████▋    | 945/1674 [54:58<37:04,  3.05s/it] 57%|█████▋    | 946/1674 [55:01<36:20,  3.00s/it] 57%|█████▋    | 947/1674 [55:03<35:06,  2.90s/it] 57%|█████▋    | 948/1674 [55:07<36:50,  3.04s/it] 57%|█████▋    | 949/1674 [55:10<37:31,  3.11s/it] 57%|█████▋    | 950/1674 [55:12<35:26,  2.94s/it]                                                  {'loss': 0.2799, 'grad_norm': 19.96923065185547, 'learning_rate': 3.8408867026881923e-07, 'rewards/chosen': 0.06154174730181694, 'rewards/rejected': -2.018749952316284, 'rewards/accuracies': 0.8583332896232605, 'rewards/margins': 2.0796875953674316, 'logps/chosen': -76.25, 'logps/rejected': -108.94999694824219, 'logits/chosen': -8.003125190734863, 'logits/rejected': -7.615624904632568, 'epoch': 1.7}
 57%|█████▋    | 950/1674 [55:12<35:26,  2.94s/it] 57%|█████▋    | 951/1674 [55:15<33:52,  2.81s/it] 57%|█████▋    | 952/1674 [55:18<35:12,  2.93s/it] 57%|█████▋    | 953/1674 [55:22<37:44,  3.14s/it] 57%|█████▋    | 954/1674 [55:26<40:57,  3.41s/it] 57%|█████▋    | 955/1674 [55:29<38:37,  3.22s/it] 57%|█████▋    | 956/1674 [55:32<40:22,  3.37s/it] 57%|█████▋    | 957/1674 [55:35<37:37,  3.15s/it] 57%|█████▋    | 958/1674 [55:37<35:11,  2.95s/it] 57%|█████▋    | 959/1674 [55:40<34:27,  2.89s/it] 57%|█████▋    | 960/1674 [55:43<35:23,  2.97s/it]                                                  {'loss': 0.3192, 'grad_norm': 12.487523078918457, 'learning_rate': 3.812001030458767e-07, 'rewards/chosen': -0.05584106594324112, 'rewards/rejected': -1.908593773841858, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8523437976837158, 'logps/chosen': -76.67500305175781, 'logps/rejected': -101.69999694824219, 'logits/chosen': -7.878125190734863, 'logits/rejected': -7.465624809265137, 'epoch': 1.72}
 57%|█████▋    | 960/1674 [55:43<35:23,  2.97s/it] 57%|█████▋    | 961/1674 [55:47<38:51,  3.27s/it] 57%|█████▋    | 962/1674 [55:49<34:25,  2.90s/it] 58%|█████▊    | 963/1674 [55:52<32:45,  2.76s/it] 58%|█████▊    | 964/1674 [55:55<32:53,  2.78s/it] 58%|█████▊    | 965/1674 [55:58<33:41,  2.85s/it] 58%|█████▊    | 966/1674 [56:01<36:02,  3.05s/it] 58%|█████▊    | 967/1674 [56:05<39:26,  3.35s/it] 58%|█████▊    | 968/1674 [56:09<41:26,  3.52s/it] 58%|█████▊    | 969/1674 [56:12<38:53,  3.31s/it] 58%|█████▊    | 970/1674 [56:14<35:40,  3.04s/it]                                                  {'loss': 0.3855, 'grad_norm': 14.645118713378906, 'learning_rate': 3.7808500559700963e-07, 'rewards/chosen': -0.20564575493335724, 'rewards/rejected': -2.05078125, 'rewards/accuracies': 0.841666579246521, 'rewards/margins': 1.845703125, 'logps/chosen': -81.17500305175781, 'logps/rejected': -101.9000015258789, 'logits/chosen': -7.962500095367432, 'logits/rejected': -7.478125095367432, 'epoch': 1.74}
 58%|█████▊    | 970/1674 [56:14<35:40,  3.04s/it] 58%|█████▊    | 971/1674 [56:16<31:33,  2.69s/it] 58%|█████▊    | 972/1674 [56:19<31:44,  2.71s/it] 58%|█████▊    | 973/1674 [56:22<32:14,  2.76s/it] 58%|█████▊    | 974/1674 [56:25<34:42,  2.98s/it] 58%|█████▊    | 975/1674 [56:29<38:41,  3.32s/it] 58%|█████▊    | 976/1674 [56:32<34:58,  3.01s/it] 58%|█████▊    | 977/1674 [56:35<35:38,  3.07s/it] 58%|█████▊    | 978/1674 [56:37<31:56,  2.75s/it] 58%|█████▊    | 979/1674 [56:40<32:13,  2.78s/it] 59%|█████▊    | 980/1674 [56:42<30:41,  2.65s/it]                                                  {'loss': 0.3022, 'grad_norm': 33.647552490234375, 'learning_rate': 3.74747755485976e-07, 'rewards/chosen': -0.14150390028953552, 'rewards/rejected': -2.098437547683716, 'rewards/accuracies': 0.89166659116745, 'rewards/margins': 1.9578125476837158, 'logps/chosen': -78.7249984741211, 'logps/rejected': -111.375, 'logits/chosen': -8.103124618530273, 'logits/rejected': -7.481249809265137, 'epoch': 1.76}
 59%|█████▊    | 980/1674 [56:42<30:41,  2.65s/it] 59%|█████▊    | 981/1674 [56:44<27:39,  2.39s/it] 59%|█████▊    | 982/1674 [56:48<32:58,  2.86s/it] 59%|█████▊    | 983/1674 [56:51<32:34,  2.83s/it] 59%|█████▉    | 984/1674 [56:53<30:19,  2.64s/it] 59%|█████▉    | 985/1674 [56:56<33:26,  2.91s/it] 59%|█████▉    | 986/1674 [57:00<36:27,  3.18s/it] 59%|█████▉    | 987/1674 [57:03<35:43,  3.12s/it] 59%|█████▉    | 988/1674 [57:07<38:29,  3.37s/it] 59%|█████▉    | 989/1674 [57:10<35:58,  3.15s/it] 59%|█████▉    | 990/1674 [57:12<32:38,  2.86s/it]                                                  {'loss': 0.3842, 'grad_norm': 14.237981796264648, 'learning_rate': 3.7119304246177304e-07, 'rewards/chosen': -0.17355957627296448, 'rewards/rejected': -1.9406249523162842, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.767187476158142, 'logps/chosen': -80.6500015258789, 'logps/rejected': -106.0999984741211, 'logits/chosen': -7.940625190734863, 'logits/rejected': -7.599999904632568, 'epoch': 1.77}
 59%|█████▉    | 990/1674 [57:12<32:38,  2.86s/it] 59%|█████▉    | 991/1674 [57:16<35:30,  3.12s/it] 59%|█████▉    | 992/1674 [57:18<33:36,  2.96s/it] 59%|█████▉    | 993/1674 [57:22<34:50,  3.07s/it] 59%|█████▉    | 994/1674 [57:25<36:03,  3.18s/it] 59%|█████▉    | 995/1674 [57:28<36:17,  3.21s/it] 59%|█████▉    | 996/1674 [57:32<38:47,  3.43s/it] 60%|█████▉    | 997/1674 [57:36<40:27,  3.59s/it] 60%|█████▉    | 998/1674 [57:38<36:10,  3.21s/it] 60%|█████▉    | 999/1674 [57:42<36:10,  3.22s/it] 60%|█████▉    | 1000/1674 [57:46<38:30,  3.43s/it]                                                   {'loss': 0.3049, 'grad_norm': 65.48314666748047, 'learning_rate': 3.674258618682576e-07, 'rewards/chosen': 0.03873290866613388, 'rewards/rejected': -1.975000023841858, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 2.0101561546325684, 'logps/chosen': -170.125, 'logps/rejected': -201.5500030517578, 'logits/chosen': -7.940625190734863, 'logits/rejected': -7.393750190734863, 'epoch': 1.79}
 60%|█████▉    | 1000/1674 [57:46<38:30,  3.43s/it] 60%|█████▉    | 1001/1674 [57:48<35:14,  3.14s/it] 60%|█████▉    | 1002/1674 [57:52<36:53,  3.29s/it] 60%|█████▉    | 1003/1674 [57:54<34:04,  3.05s/it] 60%|█████▉    | 1004/1674 [57:58<36:05,  3.23s/it] 60%|██████    | 1005/1674 [58:02<38:40,  3.47s/it] 60%|██████    | 1006/1674 [58:06<41:20,  3.71s/it] 60%|██████    | 1007/1674 [58:10<40:08,  3.61s/it] 60%|██████    | 1008/1674 [58:13<38:15,  3.45s/it] 60%|██████    | 1009/1674 [58:16<37:53,  3.42s/it] 60%|██████    | 1010/1674 [58:18<34:39,  3.13s/it]                                                   {'loss': 0.3523, 'grad_norm': 11.435298919677734, 'learning_rate': 3.634515076243219e-07, 'rewards/chosen': -0.1588134765625, 'rewards/rejected': -2.0414061546325684, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.881250023841858, 'logps/chosen': -83.9000015258789, 'logps/rejected': -113.0, 'logits/chosen': -8.131250381469727, 'logits/rejected': -7.675000190734863, 'epoch': 1.81}
 60%|██████    | 1010/1674 [58:19<34:39,  3.13s/it] 60%|██████    | 1011/1674 [58:22<37:29,  3.39s/it] 60%|██████    | 1012/1674 [58:27<41:50,  3.79s/it] 61%|██████    | 1013/1674 [58:31<42:11,  3.83s/it] 61%|██████    | 1014/1674 [58:34<39:58,  3.63s/it] 61%|██████    | 1015/1674 [58:38<38:45,  3.53s/it] 61%|██████    | 1016/1674 [58:41<37:03,  3.38s/it] 61%|██████    | 1017/1674 [58:43<35:10,  3.21s/it] 61%|██████    | 1018/1674 [58:47<36:13,  3.31s/it] 61%|██████    | 1019/1674 [58:50<35:10,  3.22s/it] 61%|██████    | 1020/1674 [58:54<36:19,  3.33s/it]                                                   {'loss': 0.3049, 'grad_norm': 19.388744354248047, 'learning_rate': 3.592755647844899e-07, 'rewards/chosen': -0.15969237685203552, 'rewards/rejected': -2.28125, 'rewards/accuracies': 0.8583332896232605, 'rewards/margins': 2.122265577316284, 'logps/chosen': -110.69999694824219, 'logps/rejected': -155.25, 'logits/chosen': -7.990624904632568, 'logits/rejected': -7.490624904632568, 'epoch': 1.83}
 61%|██████    | 1020/1674 [58:54<36:19,  3.33s/it] 61%|██████    | 1021/1674 [58:56<33:33,  3.08s/it] 61%|██████    | 1022/1674 [58:58<30:32,  2.81s/it] 61%|██████    | 1023/1674 [59:01<29:20,  2.70s/it] 61%|██████    | 1024/1674 [59:03<29:28,  2.72s/it] 61%|██████    | 1025/1674 [59:06<29:32,  2.73s/it] 61%|██████▏   | 1026/1674 [59:10<32:39,  3.02s/it] 61%|██████▏   | 1027/1674 [59:13<32:51,  3.05s/it] 61%|██████▏   | 1028/1674 [59:17<35:04,  3.26s/it] 61%|██████▏   | 1029/1674 [59:20<35:08,  3.27s/it] 62%|██████▏   | 1030/1674 [59:22<29:32,  2.75s/it]                                                   {'loss': 0.317, 'grad_norm': 18.558279037475586, 'learning_rate': 3.5490390169038855e-07, 'rewards/chosen': -0.1695556640625, 'rewards/rejected': -2.2125000953674316, 'rewards/accuracies': 0.8333333730697632, 'rewards/margins': 2.043750047683716, 'logps/chosen': -74.9749984741211, 'logps/rejected': -100.5999984741211, 'logits/chosen': -8.146875381469727, 'logits/rejected': -7.709374904632568, 'epoch': 1.85}
 62%|██████▏   | 1030/1674 [59:22<29:32,  2.75s/it] 62%|██████▏   | 1031/1674 [59:26<33:57,  3.17s/it] 62%|██████▏   | 1032/1674 [59:28<30:34,  2.86s/it] 62%|██████▏   | 1033/1674 [59:31<32:08,  3.01s/it] 62%|██████▏   | 1034/1674 [59:34<32:04,  3.01s/it] 62%|██████▏   | 1035/1674 [59:38<34:39,  3.25s/it] 62%|██████▏   | 1036/1674 [59:42<37:44,  3.55s/it] 62%|██████▏   | 1037/1674 [59:45<33:46,  3.18s/it] 62%|██████▏   | 1038/1674 [59:48<35:46,  3.38s/it] 62%|██████▏   | 1039/1674 [59:51<31:59,  3.02s/it] 62%|██████▏   | 1040/1674 [59:53<30:52,  2.92s/it]                                                   {'loss': 0.3714, 'grad_norm': 25.434839248657227, 'learning_rate': 3.5034266172412277e-07, 'rewards/chosen': -0.3262939453125, 'rewards/rejected': -2.285937547683716, 'rewards/accuracies': 0.8333333730697632, 'rewards/margins': 1.9578125476837158, 'logps/chosen': -87.32499694824219, 'logps/rejected': -106.30000305175781, 'logits/chosen': -8.193750381469727, 'logits/rejected': -7.771874904632568, 'epoch': 1.86}
 62%|██████▏   | 1040/1674 [59:53<30:52,  2.92s/it] 62%|██████▏   | 1041/1674 [59:56<31:25,  2.98s/it] 62%|██████▏   | 1042/1674 [1:00:00<34:01,  3.23s/it] 62%|██████▏   | 1043/1674 [1:00:04<36:14,  3.45s/it] 62%|██████▏   | 1044/1674 [1:00:08<35:39,  3.40s/it] 62%|██████▏   | 1045/1674 [1:00:12<38:08,  3.64s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:57,  1.35it/s][A
  4%|▍         | 3/80 [00:03<01:23,  1.09s/it][A
  5%|▌         | 4/80 [00:04<01:35,  1.26s/it][A
  6%|▋         | 5/80 [00:06<01:44,  1.40s/it][A
  8%|▊         | 6/80 [00:07<01:47,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:50,  1.51s/it][A
 10%|█         | 8/80 [00:11<01:51,  1.55s/it][A
 11%|█▏        | 9/80 [00:12<01:51,  1.57s/it][A
 12%|█▎        | 10/80 [00:14<01:52,  1.61s/it][A
 14%|█▍        | 11/80 [00:16<01:55,  1.68s/it][A
 15%|█▌        | 12/80 [00:17<01:51,  1.64s/it][A
 16%|█▋        | 13/80 [00:19<01:48,  1.62s/it][A
 18%|█▊        | 14/80 [00:21<01:49,  1.65s/it][A
 19%|█▉        | 15/80 [00:22<01:47,  1.65s/it][A
 20%|██        | 16/80 [00:24<01:44,  1.63s/it][A
 21%|██▏       | 17/80 [00:25<01:42,  1.62s/it][A
 22%|██▎       | 18/80 [00:27<01:40,  1.62s/it][A
 24%|██▍       | 19/80 [00:28<01:29,  1.47s/it][A
 25%|██▌       | 20/80 [00:29<01:24,  1.41s/it][A
 26%|██▋       | 21/80 [00:30<01:07,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:06,  1.14s/it][A
 29%|██▉       | 23/80 [00:32<01:04,  1.13s/it][A
 30%|███       | 24/80 [00:33<00:52,  1.07it/s][A
 31%|███▏      | 25/80 [00:34<00:55,  1.01s/it][A
 32%|███▎      | 26/80 [00:35<00:58,  1.08s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.03it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.03it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.09s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.06it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.15s/it][A
 42%|████▎     | 34/80 [00:44<00:56,  1.24s/it][A
 44%|████▍     | 35/80 [00:45<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.07it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.23it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:48,  1.22s/it][A
 51%|█████▏    | 41/80 [00:50<00:39,  1.03s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.19s/it][A
 54%|█████▍    | 43/80 [00:54<00:46,  1.26s/it][A
 55%|█████▌    | 44/80 [00:55<00:44,  1.25s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.08it/s][A
 59%|█████▉    | 47/80 [00:57<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:37,  1.19s/it][A
 61%|██████▏   | 49/80 [00:59<00:31,  1.00s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.19it/s][A
 64%|██████▍   | 51/80 [01:01<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:03<00:26,  1.03it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.18s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:09<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.21s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.01s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.16s/it][A
 78%|███████▊  | 62/80 [01:14<00:23,  1.33s/it][A
 79%|███████▉  | 63/80 [01:15<00:21,  1.25s/it][A
 80%|████████  | 64/80 [01:16<00:18,  1.13s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.25s/it][A
 82%|████████▎ | 66/80 [01:19<00:18,  1.34s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.44s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:26<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:30<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:31<00:06,  1.27s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.36s/it][A
 96%|█████████▋| 77/80 [01:34<00:04,  1.36s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.13s/it][A
 99%|█████████▉| 79/80 [01:36<00:01,  1.26s/it][A
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A                                                     
                                               [A{'eval_loss': 0.5949355959892273, 'eval_runtime': 100.3165, 'eval_samples_per_second': 9.5, 'eval_steps_per_second': 0.797, 'eval_rewards/chosen': -0.5253143310546875, 'eval_rewards/rejected': -2.2436280250549316, 'eval_rewards/accuracies': 0.7597917318344116, 'eval_rewards/margins': 1.7180992364883423, 'eval_logps/chosen': -364.19061279296875, 'eval_logps/rejected': -176.97500610351562, 'eval_logits/chosen': -7.529296875, 'eval_logits/rejected': -7.641797065734863, 'epoch': 1.87}
 62%|██████▏   | 1045/1674 [1:01:52<38:08,  3.64s/it]
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 62%|██████▏   | 1046/1674 [1:02:06<6:26:55, 36.97s/it] 63%|██████▎   | 1047/1674 [1:02:10<4:42:43, 27.05s/it] 63%|██████▎   | 1048/1674 [1:02:14<3:27:56, 19.93s/it] 63%|██████▎   | 1049/1674 [1:02:17<2:36:47, 15.05s/it] 63%|██████▎   | 1050/1674 [1:02:21<2:00:37, 11.60s/it]                                                       {'loss': 0.3539, 'grad_norm': 9.319506645202637, 'learning_rate': 3.455982546751438e-07, 'rewards/chosen': -0.2839599549770355, 'rewards/rejected': -2.36328125, 'rewards/accuracies': 0.8333333134651184, 'rewards/margins': 2.0796875953674316, 'logps/chosen': -117.4000015258789, 'logps/rejected': -174.9499969482422, 'logits/chosen': -8.056249618530273, 'logits/rejected': -7.478125095367432, 'epoch': 1.88}
 63%|██████▎   | 1050/1674 [1:02:21<2:00:37, 11.60s/it] 63%|██████▎   | 1051/1674 [1:02:24<1:32:46,  8.93s/it] 63%|██████▎   | 1052/1674 [1:02:28<1:17:07,  7.44s/it] 63%|██████▎   | 1053/1674 [1:02:31<1:04:52,  6.27s/it] 63%|██████▎   | 1054/1674 [1:02:35<57:28,  5.56s/it]   63%|██████▎   | 1055/1674 [1:02:38<48:23,  4.69s/it] 63%|██████▎   | 1056/1674 [1:02:41<45:13,  4.39s/it] 63%|██████▎   | 1057/1674 [1:02:44<38:16,  3.72s/it] 63%|██████▎   | 1058/1674 [1:02:47<36:09,  3.52s/it] 63%|██████▎   | 1059/1674 [1:02:50<35:19,  3.45s/it] 63%|██████▎   | 1060/1674 [1:02:54<37:44,  3.69s/it]                                                     {'loss': 0.3246, 'grad_norm': 35.39012145996094, 'learning_rate': 3.4067734773274244e-07, 'rewards/chosen': -0.17684631049633026, 'rewards/rejected': -2.2593750953674316, 'rewards/accuracies': 0.9083333015441895, 'rewards/margins': 2.0843749046325684, 'logps/chosen': -134.85000610351562, 'logps/rejected': -140.5, 'logits/chosen': -7.909375190734863, 'logits/rejected': -7.493750095367432, 'epoch': 1.9}
 63%|██████▎   | 1060/1674 [1:02:54<37:44,  3.69s/it] 63%|██████▎   | 1061/1674 [1:02:57<34:00,  3.33s/it] 63%|██████▎   | 1062/1674 [1:03:01<36:28,  3.58s/it] 64%|██████▎   | 1063/1674 [1:03:02<29:23,  2.89s/it] 64%|██████▎   | 1064/1674 [1:03:05<28:40,  2.82s/it] 64%|██████▎   | 1065/1674 [1:03:07<28:32,  2.81s/it] 64%|██████▎   | 1066/1674 [1:03:10<26:24,  2.61s/it] 64%|██████▎   | 1067/1674 [1:03:13<27:43,  2.74s/it] 64%|██████▍   | 1068/1674 [1:03:15<26:49,  2.66s/it] 64%|██████▍   | 1069/1674 [1:03:18<28:47,  2.86s/it] 64%|██████▍   | 1070/1674 [1:03:21<28:48,  2.86s/it]                                                     {'loss': 0.412, 'grad_norm': 23.6235294342041, 'learning_rate': 3.3558685611682446e-07, 'rewards/chosen': -0.31763917207717896, 'rewards/rejected': -2.1171875, 'rewards/accuracies': 0.8416666984558105, 'rewards/margins': 1.8009765148162842, 'logps/chosen': -81.375, 'logps/rejected': -96.5999984741211, 'logits/chosen': -7.934374809265137, 'logits/rejected': -7.5, 'epoch': 1.92}
 64%|██████▍   | 1070/1674 [1:03:21<28:48,  2.86s/it] 64%|██████▍   | 1071/1674 [1:03:24<29:14,  2.91s/it] 64%|██████▍   | 1072/1674 [1:03:27<29:30,  2.94s/it] 64%|██████▍   | 1073/1674 [1:03:29<25:24,  2.54s/it] 64%|██████▍   | 1074/1674 [1:03:33<30:05,  3.01s/it] 64%|██████▍   | 1075/1674 [1:03:35<27:27,  2.75s/it] 64%|██████▍   | 1076/1674 [1:03:38<27:05,  2.72s/it] 64%|██████▍   | 1077/1674 [1:03:41<27:31,  2.77s/it] 64%|██████▍   | 1078/1674 [1:03:44<28:43,  2.89s/it] 64%|██████▍   | 1079/1674 [1:03:47<28:55,  2.92s/it] 65%|██████▍   | 1080/1674 [1:03:50<28:25,  2.87s/it]                                                     {'loss': 0.3244, 'grad_norm': 30.897783279418945, 'learning_rate': 3.3033393336013606e-07, 'rewards/chosen': -0.398193359375, 'rewards/rejected': -2.4515624046325684, 'rewards/accuracies': 0.85833340883255, 'rewards/margins': 2.0531249046325684, 'logps/chosen': -81.69999694824219, 'logps/rejected': -123.80000305175781, 'logits/chosen': -8.324999809265137, 'logits/rejected': -7.771874904632568, 'epoch': 1.94}
 65%|██████▍   | 1080/1674 [1:03:50<28:25,  2.87s/it] 65%|██████▍   | 1081/1674 [1:03:53<28:30,  2.89s/it] 65%|██████▍   | 1082/1674 [1:03:55<27:04,  2.74s/it] 65%|██████▍   | 1083/1674 [1:03:58<26:51,  2.73s/it] 65%|██████▍   | 1084/1674 [1:04:00<26:28,  2.69s/it] 65%|██████▍   | 1085/1674 [1:04:04<29:45,  3.03s/it] 65%|██████▍   | 1086/1674 [1:04:08<32:04,  3.27s/it] 65%|██████▍   | 1087/1674 [1:04:11<32:34,  3.33s/it] 65%|██████▍   | 1088/1674 [1:04:15<34:08,  3.50s/it] 65%|██████▌   | 1089/1674 [1:04:19<35:22,  3.63s/it] 65%|██████▌   | 1090/1674 [1:04:22<33:02,  3.40s/it]                                                     {'loss': 0.3084, 'grad_norm': 30.64626693725586, 'learning_rate': 3.24925961255594e-07, 'rewards/chosen': -0.2856689393520355, 'rewards/rejected': -2.5453124046325684, 'rewards/accuracies': 0.875, 'rewards/margins': 2.258593797683716, 'logps/chosen': -108.69999694824219, 'logps/rejected': -139.5500030517578, 'logits/chosen': -8.309374809265137, 'logits/rejected': -7.853125095367432, 'epoch': 1.95}
 65%|██████▌   | 1090/1674 [1:04:22<33:02,  3.40s/it] 65%|██████▌   | 1091/1674 [1:04:25<32:38,  3.36s/it] 65%|██████▌   | 1092/1674 [1:04:29<34:36,  3.57s/it] 65%|██████▌   | 1093/1674 [1:04:32<31:00,  3.20s/it] 65%|██████▌   | 1094/1674 [1:04:36<33:01,  3.42s/it] 65%|██████▌   | 1095/1674 [1:04:39<31:30,  3.26s/it] 65%|██████▌   | 1096/1674 [1:04:41<30:15,  3.14s/it] 66%|██████▌   | 1097/1674 [1:04:44<27:49,  2.89s/it] 66%|██████▌   | 1098/1674 [1:04:46<27:11,  2.83s/it] 66%|██████▌   | 1099/1674 [1:04:50<29:42,  3.10s/it] 66%|██████▌   | 1100/1674 [1:04:53<29:25,  3.08s/it]                                                     {'loss': 0.3565, 'grad_norm': 24.346593856811523, 'learning_rate': 3.193705394828479e-07, 'rewards/chosen': -0.2401123046875, 'rewards/rejected': -2.590625047683716, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3499999046325684, 'logps/chosen': -161.14999389648438, 'logps/rejected': -178.10000610351562, 'logits/chosen': -8.203125, 'logits/rejected': -7.696875095367432, 'epoch': 1.97}
 66%|██████▌   | 1100/1674 [1:04:53<29:25,  3.08s/it] 66%|██████▌   | 1101/1674 [1:04:56<28:18,  2.96s/it] 66%|██████▌   | 1102/1674 [1:04:58<26:50,  2.82s/it] 66%|██████▌   | 1103/1674 [1:05:01<25:42,  2.70s/it] 66%|██████▌   | 1104/1674 [1:05:04<28:17,  2.98s/it] 66%|██████▌   | 1105/1674 [1:05:07<28:14,  2.98s/it] 66%|██████▌   | 1106/1674 [1:05:11<30:59,  3.27s/it] 66%|██████▌   | 1107/1674 [1:05:16<33:45,  3.57s/it] 66%|██████▌   | 1108/1674 [1:05:18<30:12,  3.20s/it] 66%|██████▌   | 1109/1674 [1:05:21<28:56,  3.07s/it] 66%|██████▋   | 1110/1674 [1:05:24<28:35,  3.04s/it]                                                     {'loss': 0.3165, 'grad_norm': 13.423439025878906, 'learning_rate': 3.1367547492865207e-07, 'rewards/chosen': -0.18789061903953552, 'rewards/rejected': -2.4058594703674316, 'rewards/accuracies': 0.8666666746139526, 'rewards/margins': 2.217968702316284, 'logps/chosen': -123.92500305175781, 'logps/rejected': -151.5, 'logits/chosen': -8.228124618530273, 'logits/rejected': -7.684374809265137, 'epoch': 1.99}
 66%|██████▋   | 1110/1674 [1:05:24<28:35,  3.04s/it] 66%|██████▋   | 1111/1674 [1:05:26<26:48,  2.86s/it] 66%|██████▋   | 1112/1674 [1:05:30<28:35,  3.05s/it] 66%|██████▋   | 1113/1674 [1:05:32<26:59,  2.89s/it] 67%|██████▋   | 1114/1674 [1:05:36<28:45,  3.08s/it] 67%|██████▋   | 1115/1674 [1:05:38<27:24,  2.94s/it] 67%|██████▋   | 1116/1674 [1:05:42<29:56,  3.22s/it] 67%|██████▋   | 1117/1674 [1:05:46<32:42,  3.52s/it] 67%|██████▋   | 1118/1674 [1:05:49<28:48,  3.11s/it] 67%|██████▋   | 1119/1674 [1:05:51<26:56,  2.91s/it] 67%|██████▋   | 1120/1674 [1:05:54<26:45,  2.90s/it]                                                     {'loss': 0.3011, 'grad_norm': 14.078383445739746, 'learning_rate': 3.0784877071605527e-07, 'rewards/chosen': -0.3030029237270355, 'rewards/rejected': -2.475781202316284, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.172656297683716, 'logps/chosen': -88.0250015258789, 'logps/rejected': -115.8499984741211, 'logits/chosen': -8.240625381469727, 'logits/rejected': -7.746874809265137, 'epoch': 2.01}
 67%|██████▋   | 1120/1674 [1:05:54<26:45,  2.90s/it] 67%|██████▋   | 1121/1674 [1:05:57<26:12,  2.84s/it] 67%|██████▋   | 1122/1674 [1:05:59<25:55,  2.82s/it] 67%|██████▋   | 1123/1674 [1:06:02<24:45,  2.70s/it] 67%|██████▋   | 1124/1674 [1:06:05<26:32,  2.89s/it] 67%|██████▋   | 1125/1674 [1:06:07<24:39,  2.70s/it] 67%|██████▋   | 1126/1674 [1:06:11<27:45,  3.04s/it] 67%|██████▋   | 1127/1674 [1:06:15<30:34,  3.35s/it] 67%|██████▋   | 1128/1674 [1:06:19<30:54,  3.40s/it] 67%|██████▋   | 1129/1674 [1:06:21<28:51,  3.18s/it] 68%|██████▊   | 1130/1674 [1:06:24<28:34,  3.15s/it]                                                     {'loss': 0.274, 'grad_norm': 27.502721786499023, 'learning_rate': 3.0189861495782366e-07, 'rewards/chosen': -0.13770751655101776, 'rewards/rejected': -2.356250047683716, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.2164063453674316, 'logps/chosen': -121.42500305175781, 'logps/rejected': -146.0, 'logits/chosen': -8.193750381469727, 'logits/rejected': -7.693749904632568, 'epoch': 2.03}
 68%|██████▊   | 1130/1674 [1:06:25<28:34,  3.15s/it] 68%|██████▊   | 1131/1674 [1:06:28<28:38,  3.16s/it] 68%|██████▊   | 1132/1674 [1:06:31<29:01,  3.21s/it] 68%|██████▊   | 1133/1674 [1:06:34<28:04,  3.11s/it] 68%|██████▊   | 1134/1674 [1:06:36<26:30,  2.95s/it] 68%|██████▊   | 1135/1674 [1:06:39<26:39,  2.97s/it] 68%|██████▊   | 1136/1674 [1:06:43<27:06,  3.02s/it] 68%|██████▊   | 1137/1674 [1:06:45<25:29,  2.85s/it] 68%|██████▊   | 1138/1674 [1:06:48<24:29,  2.74s/it] 68%|██████▊   | 1139/1674 [1:06:49<21:23,  2.40s/it] 68%|██████▊   | 1140/1674 [1:06:52<23:33,  2.65s/it]                                                     {'loss': 0.2541, 'grad_norm': 15.609650611877441, 'learning_rate': 2.9583336924990374e-07, 'rewards/chosen': -0.440185546875, 'rewards/rejected': -2.7796874046325684, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.340625047683716, 'logps/chosen': -85.94999694824219, 'logps/rejected': -113.25, 'logits/chosen': -8.024999618530273, 'logits/rejected': -7.668749809265137, 'epoch': 2.04}
 68%|██████▊   | 1140/1674 [1:06:52<23:33,  2.65s/it] 68%|██████▊   | 1141/1674 [1:06:55<24:37,  2.77s/it] 68%|██████▊   | 1142/1674 [1:06:57<22:14,  2.51s/it] 68%|██████▊   | 1143/1674 [1:07:00<22:51,  2.58s/it] 68%|██████▊   | 1144/1674 [1:07:04<25:40,  2.91s/it] 68%|██████▊   | 1145/1674 [1:07:07<26:36,  3.02s/it] 68%|██████▊   | 1146/1674 [1:07:10<27:01,  3.07s/it] 69%|██████▊   | 1147/1674 [1:07:14<28:12,  3.21s/it] 69%|██████▊   | 1148/1674 [1:07:18<30:24,  3.47s/it] 69%|██████▊   | 1149/1674 [1:07:21<28:44,  3.28s/it] 69%|██████▊   | 1150/1674 [1:07:23<25:50,  2.96s/it]                                                     {'loss': 0.301, 'grad_norm': 25.72165870666504, 'learning_rate': 2.896615569210933e-07, 'rewards/chosen': -0.3401588499546051, 'rewards/rejected': -2.5374999046325684, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1976561546325684, 'logps/chosen': -81.1500015258789, 'logps/rejected': -114.75, 'logits/chosen': -8.309374809265137, 'logits/rejected': -7.853125095367432, 'epoch': 2.06}
 69%|██████▊   | 1150/1674 [1:07:23<25:50,  2.96s/it] 69%|██████▉   | 1151/1674 [1:07:26<26:44,  3.07s/it] 69%|██████▉   | 1152/1674 [1:07:30<28:58,  3.33s/it] 69%|██████▉   | 1153/1674 [1:07:33<28:10,  3.25s/it] 69%|██████▉   | 1154/1674 [1:07:37<28:46,  3.32s/it] 69%|██████▉   | 1155/1674 [1:07:40<28:32,  3.30s/it] 69%|██████▉   | 1156/1674 [1:07:43<28:04,  3.25s/it] 69%|██████▉   | 1157/1674 [1:07:46<26:05,  3.03s/it] 69%|██████▉   | 1158/1674 [1:07:49<26:17,  3.06s/it] 69%|██████▉   | 1159/1674 [1:07:52<27:48,  3.24s/it] 69%|██████▉   | 1160/1674 [1:07:55<25:10,  2.94s/it]                                                     {'loss': 0.3518, 'grad_norm': 18.895599365234375, 'learning_rate': 2.833918510554339e-07, 'rewards/chosen': -0.04954833909869194, 'rewards/rejected': -2.5562500953674316, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.5093750953674316, 'logps/chosen': -120.4749984741211, 'logps/rejected': -139.5500030517578, 'logits/chosen': -7.987500190734863, 'logits/rejected': -7.5625, 'epoch': 2.08}
 69%|██████▉   | 1160/1674 [1:07:55<25:10,  2.94s/it] 69%|██████▉   | 1161/1674 [1:07:57<24:32,  2.87s/it] 69%|██████▉   | 1162/1674 [1:08:01<26:33,  3.11s/it] 69%|██████▉   | 1163/1674 [1:08:05<27:52,  3.27s/it] 70%|██████▉   | 1164/1674 [1:08:07<25:42,  3.03s/it] 70%|██████▉   | 1165/1674 [1:08:10<25:39,  3.02s/it] 70%|██████▉   | 1166/1674 [1:08:13<26:19,  3.11s/it] 70%|██████▉   | 1167/1674 [1:08:16<25:11,  2.98s/it] 70%|██████▉   | 1168/1674 [1:08:19<24:18,  2.88s/it] 70%|██████▉   | 1169/1674 [1:08:21<21:50,  2.59s/it] 70%|██████▉   | 1170/1674 [1:08:22<19:06,  2.27s/it]                                                     {'loss': 0.3259, 'grad_norm': 10.289830207824707, 'learning_rate': 2.770330623041558e-07, 'rewards/chosen': -0.3969970643520355, 'rewards/rejected': -2.6265625953674316, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.225781202316284, 'logps/chosen': -77.0250015258789, 'logps/rejected': -99.32499694824219, 'logits/chosen': -8.387499809265137, 'logits/rejected': -7.887499809265137, 'epoch': 2.1}
 70%|██████▉   | 1170/1674 [1:08:22<19:06,  2.27s/it] 70%|██████▉   | 1171/1674 [1:08:25<21:06,  2.52s/it] 70%|███████   | 1172/1674 [1:08:28<22:18,  2.67s/it] 70%|███████   | 1173/1674 [1:08:32<25:03,  3.00s/it] 70%|███████   | 1174/1674 [1:08:36<28:05,  3.37s/it] 70%|███████   | 1175/1674 [1:08:39<26:20,  3.17s/it] 70%|███████   | 1176/1674 [1:08:43<27:40,  3.33s/it] 70%|███████   | 1177/1674 [1:08:46<28:25,  3.43s/it] 70%|███████   | 1178/1674 [1:08:49<25:16,  3.06s/it] 70%|███████   | 1179/1674 [1:08:52<25:19,  3.07s/it] 70%|███████   | 1180/1674 [1:08:54<22:59,  2.79s/it]                                                     {'loss': 0.3219, 'grad_norm': 17.449848175048828, 'learning_rate': 2.7059412650430375e-07, 'rewards/chosen': -0.3799072206020355, 'rewards/rejected': -2.7734375, 'rewards/accuracies': 0.8666666746139526, 'rewards/margins': 2.391406297683716, 'logps/chosen': -89.32499694824219, 'logps/rejected': -126.0, 'logits/chosen': -8.443750381469727, 'logits/rejected': -7.856249809265137, 'epoch': 2.11}
 70%|███████   | 1180/1674 [1:08:54<22:59,  2.79s/it] 71%|███████   | 1181/1674 [1:08:56<22:13,  2.70s/it] 71%|███████   | 1182/1674 [1:08:59<22:42,  2.77s/it] 71%|███████   | 1183/1674 [1:09:02<22:08,  2.71s/it] 71%|███████   | 1184/1674 [1:09:04<19:41,  2.41s/it] 71%|███████   | 1185/1674 [1:09:06<19:27,  2.39s/it] 71%|███████   | 1186/1674 [1:09:08<18:16,  2.25s/it] 71%|███████   | 1187/1674 [1:09:11<19:30,  2.40s/it] 71%|███████   | 1188/1674 [1:09:14<21:56,  2.71s/it] 71%|███████   | 1189/1674 [1:09:18<24:17,  3.00s/it] 71%|███████   | 1190/1674 [1:09:21<26:10,  3.24s/it]                                                     {'loss': 0.2347, 'grad_norm': 16.349565505981445, 'learning_rate': 2.640840921214427e-07, 'rewards/chosen': -0.14758911728858948, 'rewards/rejected': -2.6890625953674316, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.542187452316284, 'logps/chosen': -76.375, 'logps/rejected': -114.05000305175781, 'logits/chosen': -8.418749809265137, 'logits/rejected': -7.853125095367432, 'epoch': 2.13}
 71%|███████   | 1190/1674 [1:09:22<26:10,  3.24s/it] 71%|███████   | 1191/1674 [1:09:24<23:38,  2.94s/it] 71%|███████   | 1192/1674 [1:09:28<25:43,  3.20s/it] 71%|███████▏  | 1193/1674 [1:09:30<24:49,  3.10s/it] 71%|███████▏  | 1194/1674 [1:09:33<24:10,  3.02s/it] 71%|███████▏  | 1195/1674 [1:09:37<26:37,  3.33s/it] 71%|███████▏  | 1196/1674 [1:09:39<23:34,  2.96s/it] 72%|███████▏  | 1197/1674 [1:09:43<26:14,  3.30s/it] 72%|███████▏  | 1198/1674 [1:09:47<27:18,  3.44s/it] 72%|███████▏  | 1199/1674 [1:09:50<25:42,  3.25s/it] 72%|███████▏  | 1200/1674 [1:09:52<22:07,  2.80s/it]                                                     {'loss': 0.2528, 'grad_norm': 13.704120635986328, 'learning_rate': 2.5751210753408884e-07, 'rewards/chosen': -0.24558106064796448, 'rewards/rejected': -2.854687452316284, 'rewards/accuracies': 0.9416667222976685, 'rewards/margins': 2.608593702316284, 'logps/chosen': -116.9749984741211, 'logps/rejected': -157.5, 'logits/chosen': -8.309374809265137, 'logits/rejected': -7.675000190734863, 'epoch': 2.15}
 72%|███████▏  | 1200/1674 [1:09:52<22:07,  2.80s/it] 72%|███████▏  | 1201/1674 [1:09:55<24:07,  3.06s/it] 72%|███████▏  | 1202/1674 [1:09:58<23:54,  3.04s/it] 72%|███████▏  | 1203/1674 [1:10:02<24:07,  3.07s/it] 72%|███████▏  | 1204/1674 [1:10:05<25:26,  3.25s/it] 72%|███████▏  | 1205/1674 [1:10:08<23:45,  3.04s/it] 72%|███████▏  | 1206/1674 [1:10:12<26:09,  3.35s/it] 72%|███████▏  | 1207/1674 [1:10:14<22:55,  2.94s/it] 72%|███████▏  | 1208/1674 [1:10:17<23:11,  2.99s/it] 72%|███████▏  | 1209/1674 [1:10:20<23:46,  3.07s/it] 72%|███████▏  | 1210/1674 [1:10:24<26:19,  3.40s/it]                                                     {'loss': 0.3204, 'grad_norm': 16.25696563720703, 'learning_rate': 2.508874081777365e-07, 'rewards/chosen': -0.460845947265625, 'rewards/rejected': -2.7984375953674316, 'rewards/accuracies': 0.8833333253860474, 'rewards/margins': 2.3375000953674316, 'logps/chosen': -85.19999694824219, 'logps/rejected': -129.5, 'logits/chosen': -8.1875, 'logits/rejected': -7.693749904632568, 'epoch': 2.17}
 72%|███████▏  | 1210/1674 [1:10:25<26:19,  3.40s/it] 72%|███████▏  | 1211/1674 [1:10:28<26:59,  3.50s/it] 72%|███████▏  | 1212/1674 [1:10:31<24:45,  3.22s/it] 72%|███████▏  | 1213/1674 [1:10:35<26:19,  3.43s/it] 73%|███████▎  | 1214/1674 [1:10:38<27:07,  3.54s/it] 73%|███████▎  | 1215/1674 [1:10:41<25:14,  3.30s/it] 73%|███████▎  | 1216/1674 [1:10:44<23:07,  3.03s/it] 73%|███████▎  | 1217/1674 [1:10:46<22:28,  2.95s/it] 73%|███████▎  | 1218/1674 [1:10:49<20:48,  2.74s/it] 73%|███████▎  | 1219/1674 [1:10:52<21:34,  2.85s/it] 73%|███████▎  | 1220/1674 [1:10:56<23:50,  3.15s/it]                                                     {'loss': 0.3219, 'grad_norm': 23.077743530273438, 'learning_rate': 2.442193035665455e-07, 'rewards/chosen': -0.563061535358429, 'rewards/rejected': -2.6117186546325684, 'rewards/accuracies': 0.85833340883255, 'rewards/margins': 2.0484375953674316, 'logps/chosen': -83.42500305175781, 'logps/rejected': -114.25, 'logits/chosen': -8.328125, 'logits/rejected': -7.949999809265137, 'epoch': 2.19}
 73%|███████▎  | 1220/1674 [1:10:56<23:50,  3.15s/it] 73%|███████▎  | 1221/1674 [1:11:00<25:42,  3.41s/it] 73%|███████▎  | 1222/1674 [1:11:03<25:07,  3.34s/it] 73%|███████▎  | 1223/1674 [1:11:05<22:37,  3.01s/it] 73%|███████▎  | 1224/1674 [1:11:08<22:30,  3.00s/it] 73%|███████▎  | 1225/1674 [1:11:10<21:14,  2.84s/it] 73%|███████▎  | 1226/1674 [1:11:12<19:26,  2.60s/it] 73%|███████▎  | 1227/1674 [1:11:16<20:41,  2.78s/it] 73%|███████▎  | 1228/1674 [1:11:20<23:36,  3.18s/it] 73%|███████▎  | 1229/1674 [1:11:21<20:03,  2.70s/it] 73%|███████▎  | 1230/1674 [1:11:23<18:02,  2.44s/it]                                                     {'loss': 0.2939, 'grad_norm': 20.00901985168457, 'learning_rate': 2.375171642109281e-07, 'rewards/chosen': -0.17236328125, 'rewards/rejected': -2.54296875, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 2.366406202316284, 'logps/chosen': -120.0999984741211, 'logps/rejected': -143.5749969482422, 'logits/chosen': -8.246874809265137, 'logits/rejected': -7.9375, 'epoch': 2.2}
 73%|███████▎  | 1230/1674 [1:11:23<18:02,  2.44s/it] 74%|███████▎  | 1231/1674 [1:11:27<20:08,  2.73s/it] 74%|███████▎  | 1232/1674 [1:11:29<19:39,  2.67s/it] 74%|███████▎  | 1233/1674 [1:11:33<22:06,  3.01s/it] 74%|███████▎  | 1234/1674 [1:11:36<22:41,  3.09s/it] 74%|███████▍  | 1235/1674 [1:11:38<20:39,  2.82s/it] 74%|███████▍  | 1236/1674 [1:11:42<21:23,  2.93s/it] 74%|███████▍  | 1237/1674 [1:11:44<20:38,  2.83s/it] 74%|███████▍  | 1238/1674 [1:11:47<21:09,  2.91s/it] 74%|███████▍  | 1239/1674 [1:11:51<23:34,  3.25s/it] 74%|███████▍  | 1240/1674 [1:11:54<22:06,  3.06s/it]                                                     {'loss': 0.2204, 'grad_norm': 21.94107437133789, 'learning_rate': 2.307904084494197e-07, 'rewards/chosen': -0.24346694350242615, 'rewards/rejected': -2.9625000953674316, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 2.719531297683716, 'logps/chosen': -80.07499694824219, 'logps/rejected': -116.6500015258789, 'logits/chosen': -8.556249618530273, 'logits/rejected': -8.125, 'epoch': 2.22}
 74%|███████▍  | 1240/1674 [1:11:54<22:06,  3.06s/it] 74%|███████▍  | 1241/1674 [1:11:57<22:10,  3.07s/it] 74%|███████▍  | 1242/1674 [1:12:00<22:47,  3.17s/it] 74%|███████▍  | 1243/1674 [1:12:04<23:45,  3.31s/it] 74%|███████▍  | 1244/1674 [1:12:08<24:21,  3.40s/it] 74%|███████▍  | 1245/1674 [1:12:10<23:05,  3.23s/it] 74%|███████▍  | 1246/1674 [1:12:14<23:51,  3.34s/it] 74%|███████▍  | 1247/1674 [1:12:18<25:40,  3.61s/it] 75%|███████▍  | 1248/1674 [1:12:21<23:19,  3.29s/it] 75%|███████▍  | 1249/1674 [1:12:25<24:35,  3.47s/it] 75%|███████▍  | 1250/1674 [1:12:28<25:03,  3.55s/it]                                                     {'loss': 0.2907, 'grad_norm': 25.296659469604492, 'learning_rate': 2.240484892133373e-07, 'rewards/chosen': -0.4705566465854645, 'rewards/rejected': -3.0296874046325684, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 2.557812452316284, 'logps/chosen': -96.69999694824219, 'logps/rejected': -133.4499969482422, 'logits/chosen': -8.556249618530273, 'logits/rejected': -8.118749618530273, 'epoch': 2.24}
 75%|███████▍  | 1250/1674 [1:12:29<25:03,  3.55s/it] 75%|███████▍  | 1251/1674 [1:12:32<24:57,  3.54s/it] 75%|███████▍  | 1252/1674 [1:12:36<24:57,  3.55s/it] 75%|███████▍  | 1253/1674 [1:12:39<24:36,  3.51s/it] 75%|███████▍  | 1254/1674 [1:12:42<23:16,  3.33s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:59,  1.31it/s][A
  4%|▍         | 3/80 [00:03<01:24,  1.10s/it][A
  5%|▌         | 4/80 [00:04<01:36,  1.27s/it][A
  6%|▋         | 5/80 [00:06<01:45,  1.40s/it][A
  8%|▊         | 6/80 [00:07<01:47,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:49,  1.50s/it][A
 10%|█         | 8/80 [00:11<01:51,  1.54s/it][A
 11%|█▏        | 9/80 [00:12<01:51,  1.56s/it][A
 12%|█▎        | 10/80 [00:14<01:52,  1.61s/it][A
 14%|█▍        | 11/80 [00:16<01:52,  1.63s/it][A
 15%|█▌        | 12/80 [00:17<01:49,  1.61s/it][A
 16%|█▋        | 13/80 [00:19<01:46,  1.60s/it][A
 18%|█▊        | 14/80 [00:20<01:47,  1.64s/it][A
 19%|█▉        | 15/80 [00:22<01:45,  1.63s/it][A
 20%|██        | 16/80 [00:24<01:42,  1.61s/it][A
 21%|██▏       | 17/80 [00:25<01:41,  1.61s/it][A
 22%|██▎       | 18/80 [00:27<01:39,  1.60s/it][A
 24%|██▍       | 19/80 [00:28<01:28,  1.46s/it][A
 25%|██▌       | 20/80 [00:29<01:23,  1.40s/it][A
 26%|██▋       | 21/80 [00:30<01:07,  1.14s/it][A
 28%|██▊       | 22/80 [00:31<01:05,  1.13s/it][A
 29%|██▉       | 23/80 [00:32<01:04,  1.14s/it][A
 30%|███       | 24/80 [00:33<00:52,  1.06it/s][A
 31%|███▏      | 25/80 [00:34<00:55,  1.01s/it][A
 32%|███▎      | 26/80 [00:35<00:58,  1.09s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.03it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.03it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.09s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:49,  1.03s/it][A
 41%|████▏     | 33/80 [00:43<00:56,  1.21s/it][A
 42%|████▎     | 34/80 [00:44<00:58,  1.28s/it][A
 44%|████▍     | 35/80 [00:45<00:46,  1.04s/it][A
 45%|████▌     | 36/80 [00:45<00:42,  1.04it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.06it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.21it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:49,  1.24s/it][A
 51%|█████▏    | 41/80 [00:51<00:40,  1.04s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.20s/it][A
 54%|█████▍    | 43/80 [00:54<00:47,  1.27s/it][A
 55%|█████▌    | 44/80 [00:55<00:45,  1.26s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.06it/s][A
 59%|█████▉    | 47/80 [00:58<00:35,  1.09s/it][A
 60%|██████    | 48/80 [00:59<00:38,  1.19s/it][A
 61%|██████▏   | 49/80 [01:00<00:31,  1.03s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.16it/s][A
 64%|██████▍   | 51/80 [01:02<00:31,  1.07s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.09s/it][A
 66%|██████▋   | 53/80 [01:04<00:26,  1.02it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.19s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:09<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:11<00:26,  1.28s/it][A
 75%|███████▌  | 60/80 [01:12<00:21,  1.06s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.20s/it][A
 78%|███████▊  | 62/80 [01:15<00:24,  1.35s/it][A
 79%|███████▉  | 63/80 [01:16<00:21,  1.27s/it][A
 80%|████████  | 64/80 [01:17<00:18,  1.14s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.26s/it][A
 82%|████████▎ | 66/80 [01:20<00:18,  1.35s/it][A
 84%|████████▍ | 67/80 [01:22<00:18,  1.45s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.48s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:27<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:31<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:32<00:06,  1.27s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.36s/it][A
 96%|█████████▋| 77/80 [01:35<00:04,  1.35s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.12s/it][A
 99%|█████████▉| 79/80 [01:37<00:01,  1.26s/it][A
100%|██████████| 80/80 [01:39<00:00,  1.37s/it][A                                                     
                                               [A{'eval_loss': 0.57628333568573, 'eval_runtime': 100.8305, 'eval_samples_per_second': 9.452, 'eval_steps_per_second': 0.793, 'eval_rewards/chosen': -0.5221588015556335, 'eval_rewards/rejected': -2.8593506813049316, 'eval_rewards/accuracies': 0.7775000333786011, 'eval_rewards/margins': 2.336617946624756, 'eval_logps/chosen': -364.0062561035156, 'eval_logps/rejected': -183.04061889648438, 'eval_logits/chosen': -7.767578125, 'eval_logits/rejected': -7.822656154632568, 'epoch': 2.25}
 75%|███████▍  | 1254/1674 [1:14:23<23:16,  3.33s/it]
100%|██████████| 80/80 [01:39<00:00,  1.37s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 75%|███████▍  | 1255/1674 [1:14:40<4:23:25, 37.72s/it] 75%|███████▌  | 1256/1674 [1:14:43<3:09:30, 27.20s/it] 75%|███████▌  | 1257/1674 [1:14:46<2:19:08, 20.02s/it] 75%|███████▌  | 1258/1674 [1:14:50<1:45:07, 15.16s/it] 75%|███████▌  | 1259/1674 [1:14:52<1:19:11, 11.45s/it] 75%|███████▌  | 1260/1674 [1:14:55<1:00:18,  8.74s/it]                                                       {'loss': 0.2825, 'grad_norm': 29.422687530517578, 'learning_rate': 2.1730088074282623e-07, 'rewards/chosen': -0.26502686738967896, 'rewards/rejected': -3.004687547683716, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 2.7398438453674316, 'logps/chosen': -77.0, 'logps/rejected': -130.60000610351562, 'logits/chosen': -8.509374618530273, 'logits/rejected': -7.865624904632568, 'epoch': 2.26}
 75%|███████▌  | 1260/1674 [1:14:55<1:00:18,  8.74s/it] 75%|███████▌  | 1261/1674 [1:14:58<48:11,  7.00s/it]   75%|███████▌  | 1262/1674 [1:15:02<42:31,  6.19s/it] 75%|███████▌  | 1263/1674 [1:15:05<35:19,  5.16s/it] 76%|███████▌  | 1264/1674 [1:15:09<33:05,  4.84s/it] 76%|███████▌  | 1265/1674 [1:15:11<27:58,  4.10s/it] 76%|███████▌  | 1266/1674 [1:15:14<24:04,  3.54s/it] 76%|███████▌  | 1267/1674 [1:15:16<22:32,  3.32s/it] 76%|███████▌  | 1268/1674 [1:15:20<22:54,  3.39s/it] 76%|███████▌  | 1269/1674 [1:15:22<19:54,  2.95s/it] 76%|███████▌  | 1270/1674 [1:15:25<19:48,  2.94s/it]                                                     {'loss': 0.3389, 'grad_norm': 17.485185623168945, 'learning_rate': 2.1055706527296197e-07, 'rewards/chosen': -0.37604981660842896, 'rewards/rejected': -2.6578125953674316, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.2796874046325684, 'logps/chosen': -72.05000305175781, 'logps/rejected': -94.69999694824219, 'logits/chosen': -8.587499618530273, 'logits/rejected': -8.125, 'epoch': 2.28}
 76%|███████▌  | 1270/1674 [1:15:25<19:48,  2.94s/it] 76%|███████▌  | 1271/1674 [1:15:27<19:04,  2.84s/it] 76%|███████▌  | 1272/1674 [1:15:30<19:14,  2.87s/it] 76%|███████▌  | 1273/1674 [1:15:32<17:08,  2.56s/it] 76%|███████▌  | 1274/1674 [1:15:36<18:58,  2.85s/it] 76%|███████▌  | 1275/1674 [1:15:38<17:21,  2.61s/it] 76%|███████▌  | 1276/1674 [1:15:41<18:38,  2.81s/it] 76%|███████▋  | 1277/1674 [1:15:43<17:36,  2.66s/it] 76%|███████▋  | 1278/1674 [1:15:46<18:37,  2.82s/it] 76%|███████▋  | 1279/1674 [1:15:50<20:27,  3.11s/it] 76%|███████▋  | 1280/1674 [1:15:53<20:28,  3.12s/it]                                                     {'loss': 0.3355, 'grad_norm': 16.485488891601562, 'learning_rate': 2.0382651970861696e-07, 'rewards/chosen': -0.5508788824081421, 'rewards/rejected': -2.6734375953674316, 'rewards/accuracies': 0.8666666150093079, 'rewards/margins': 2.121875047683716, 'logps/chosen': -81.17500305175781, 'logps/rejected': -117.25, 'logits/chosen': -8.725000381469727, 'logits/rejected': -8.078125, 'epoch': 2.29}
 76%|███████▋  | 1280/1674 [1:15:54<20:28,  3.12s/it] 77%|███████▋  | 1281/1674 [1:15:57<21:03,  3.22s/it] 77%|███████▋  | 1282/1674 [1:15:59<19:12,  2.94s/it] 77%|███████▋  | 1283/1674 [1:16:03<20:36,  3.16s/it] 77%|███████▋  | 1284/1674 [1:16:07<21:56,  3.38s/it] 77%|███████▋  | 1285/1674 [1:16:10<22:22,  3.45s/it] 77%|███████▋  | 1286/1674 [1:16:12<19:47,  3.06s/it] 77%|███████▋  | 1287/1674 [1:16:15<18:58,  2.94s/it] 77%|███████▋  | 1288/1674 [1:16:18<17:58,  2.79s/it] 77%|███████▋  | 1289/1674 [1:16:21<18:22,  2.86s/it] 77%|███████▋  | 1290/1674 [1:16:25<20:25,  3.19s/it]                                                     {'loss': 0.2905, 'grad_norm': 27.581314086914062, 'learning_rate': 1.9711870230681758e-07, 'rewards/chosen': -0.33784180879592896, 'rewards/rejected': -2.765625, 'rewards/accuracies': 0.8666666746139526, 'rewards/margins': 2.430468797683716, 'logps/chosen': -127.19999694824219, 'logps/rejected': -148.27499389648438, 'logits/chosen': -8.375, 'logits/rejected': -8.003125190734863, 'epoch': 2.31}
 77%|███████▋  | 1290/1674 [1:16:25<20:25,  3.19s/it] 77%|███████▋  | 1291/1674 [1:16:27<18:49,  2.95s/it] 77%|███████▋  | 1292/1674 [1:16:30<19:50,  3.12s/it] 77%|███████▋  | 1293/1674 [1:16:34<19:54,  3.13s/it] 77%|███████▋  | 1294/1674 [1:16:37<19:51,  3.14s/it] 77%|███████▋  | 1295/1674 [1:16:39<17:21,  2.75s/it] 77%|███████▋  | 1296/1674 [1:16:41<16:02,  2.55s/it] 77%|███████▋  | 1297/1674 [1:16:44<17:22,  2.77s/it] 78%|███████▊  | 1298/1674 [1:16:48<19:45,  3.15s/it] 78%|███████▊  | 1299/1674 [1:16:51<18:46,  3.01s/it] 78%|███████▊  | 1300/1674 [1:16:54<18:52,  3.03s/it]                                                     {'loss': 0.3151, 'grad_norm': 13.972728729248047, 'learning_rate': 1.9044303938530657e-07, 'rewards/chosen': -0.35649412870407104, 'rewards/rejected': -2.871875047683716, 'rewards/accuracies': 0.8666666746139526, 'rewards/margins': 2.5171875953674316, 'logps/chosen': -79.2750015258789, 'logps/rejected': -115.75, 'logits/chosen': -8.4375, 'logits/rejected': -7.890625, 'epoch': 2.33}
 78%|███████▊  | 1300/1674 [1:16:54<18:52,  3.03s/it] 78%|███████▊  | 1301/1674 [1:16:57<19:42,  3.17s/it] 78%|███████▊  | 1302/1674 [1:17:01<21:04,  3.40s/it] 78%|███████▊  | 1303/1674 [1:17:05<20:57,  3.39s/it] 78%|███████▊  | 1304/1674 [1:17:08<21:11,  3.44s/it] 78%|███████▊  | 1305/1674 [1:17:11<20:50,  3.39s/it] 78%|███████▊  | 1306/1674 [1:17:14<19:22,  3.16s/it] 78%|███████▊  | 1307/1674 [1:17:16<17:49,  2.91s/it] 78%|███████▊  | 1308/1674 [1:17:20<19:25,  3.18s/it] 78%|███████▊  | 1309/1674 [1:17:24<21:20,  3.51s/it] 78%|███████▊  | 1310/1674 [1:17:27<19:48,  3.26s/it]                                                     {'loss': 0.2382, 'grad_norm': 20.786096572875977, 'learning_rate': 1.8380891207598918e-07, 'rewards/chosen': -0.4165100157260895, 'rewards/rejected': -3.276562452316284, 'rewards/accuracies': 0.875, 'rewards/margins': 2.862499952316284, 'logps/chosen': -77.75, 'logps/rejected': -114.57499694824219, 'logits/chosen': -8.428125381469727, 'logits/rejected': -8.090624809265137, 'epoch': 2.35}
 78%|███████▊  | 1310/1674 [1:17:27<19:48,  3.26s/it] 78%|███████▊  | 1311/1674 [1:17:30<19:23,  3.21s/it] 78%|███████▊  | 1312/1674 [1:17:33<19:17,  3.20s/it] 78%|███████▊  | 1313/1674 [1:17:37<19:14,  3.20s/it] 78%|███████▊  | 1314/1674 [1:17:40<20:07,  3.35s/it] 79%|███████▊  | 1315/1674 [1:17:42<18:02,  3.01s/it] 79%|███████▊  | 1316/1674 [1:17:44<15:51,  2.66s/it] 79%|███████▊  | 1317/1674 [1:17:48<17:02,  2.86s/it] 79%|███████▊  | 1318/1674 [1:17:50<16:25,  2.77s/it] 79%|███████▉  | 1319/1674 [1:17:53<16:23,  2.77s/it] 79%|███████▉  | 1320/1674 [1:17:55<15:33,  2.64s/it]                                                     {'loss': 0.243, 'grad_norm': 40.178253173828125, 'learning_rate': 1.7722564314187741e-07, 'rewards/chosen': -0.2619262635707855, 'rewards/rejected': -2.8531250953674316, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 2.5882811546325684, 'logps/chosen': -80.44999694824219, 'logps/rejected': -103.19999694824219, 'logits/chosen': -8.262499809265137, 'logits/rejected': -7.765625, 'epoch': 2.37}
 79%|███████▉  | 1320/1674 [1:17:55<15:33,  2.64s/it] 79%|███████▉  | 1321/1674 [1:17:59<16:37,  2.83s/it] 79%|███████▉  | 1322/1674 [1:18:02<17:53,  3.05s/it] 79%|███████▉  | 1323/1674 [1:18:05<17:48,  3.04s/it] 79%|███████▉  | 1324/1674 [1:18:08<16:55,  2.90s/it] 79%|███████▉  | 1325/1674 [1:18:10<15:14,  2.62s/it] 79%|███████▉  | 1326/1674 [1:18:12<14:38,  2.52s/it] 79%|███████▉  | 1327/1674 [1:18:15<16:01,  2.77s/it] 79%|███████▉  | 1328/1674 [1:18:18<16:02,  2.78s/it] 79%|███████▉  | 1329/1674 [1:18:21<15:55,  2.77s/it] 79%|███████▉  | 1330/1674 [1:18:24<16:32,  2.88s/it]                                                     {'loss': 0.2962, 'grad_norm': 31.746835708618164, 'learning_rate': 1.707024838760584e-07, 'rewards/chosen': -0.4892578125, 'rewards/rejected': -2.9124999046325684, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.4203124046325684, 'logps/chosen': -91.25, 'logps/rejected': -124.5, 'logits/chosen': -8.550000190734863, 'logits/rejected': -8.028124809265137, 'epoch': 2.38}
 79%|███████▉  | 1330/1674 [1:18:24<16:32,  2.88s/it] 80%|███████▉  | 1331/1674 [1:18:26<14:15,  2.49s/it] 80%|███████▉  | 1332/1674 [1:18:28<14:25,  2.53s/it] 80%|███████▉  | 1333/1674 [1:18:31<15:13,  2.68s/it] 80%|███████▉  | 1334/1674 [1:18:35<17:19,  3.06s/it] 80%|███████▉  | 1335/1674 [1:18:37<15:23,  2.72s/it] 80%|███████▉  | 1336/1674 [1:18:41<17:58,  3.19s/it] 80%|███████▉  | 1337/1674 [1:18:44<17:35,  3.13s/it] 80%|███████▉  | 1338/1674 [1:18:49<19:25,  3.47s/it] 80%|███████▉  | 1339/1674 [1:18:51<16:46,  3.01s/it] 80%|████████  | 1340/1674 [1:18:53<15:40,  2.82s/it]                                                     {'loss': 0.2818, 'grad_norm': 34.34219741821289, 'learning_rate': 1.6424860110109803e-07, 'rewards/chosen': -0.3474365174770355, 'rewards/rejected': -3.104687452316284, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.758593797683716, 'logps/chosen': -81.2249984741211, 'logps/rejected': -122.125, 'logits/chosen': -8.524999618530273, 'logits/rejected': -7.990624904632568, 'epoch': 2.4}
 80%|████████  | 1340/1674 [1:18:53<15:40,  2.82s/it] 80%|████████  | 1341/1674 [1:18:56<15:58,  2.88s/it] 80%|████████  | 1342/1674 [1:19:00<16:59,  3.07s/it] 80%|████████  | 1343/1674 [1:19:02<16:21,  2.96s/it] 80%|████████  | 1344/1674 [1:19:06<17:47,  3.24s/it] 80%|████████  | 1345/1674 [1:19:10<19:06,  3.48s/it] 80%|████████  | 1346/1674 [1:19:13<17:07,  3.13s/it] 80%|████████  | 1347/1674 [1:19:14<14:27,  2.65s/it] 81%|████████  | 1348/1674 [1:19:17<14:38,  2.69s/it] 81%|████████  | 1349/1674 [1:19:19<14:12,  2.62s/it] 81%|████████  | 1350/1674 [1:19:22<14:53,  2.76s/it]                                                     {'loss': 0.2504, 'grad_norm': 23.90167236328125, 'learning_rate': 1.578730642871485e-07, 'rewards/chosen': -0.5277343988418579, 'rewards/rejected': -3.03125, 'rewards/accuracies': 0.9083333015441895, 'rewards/margins': 2.503124952316284, 'logps/chosen': -81.69999694824219, 'logps/rejected': -125.3499984741211, 'logits/chosen': -8.415624618530273, 'logits/rejected': -7.918749809265137, 'epoch': 2.42}
 81%|████████  | 1350/1674 [1:19:22<14:53,  2.76s/it] 81%|████████  | 1351/1674 [1:19:26<15:52,  2.95s/it] 81%|████████  | 1352/1674 [1:19:29<16:52,  3.14s/it] 81%|████████  | 1353/1674 [1:19:31<14:55,  2.79s/it] 81%|████████  | 1354/1674 [1:19:35<15:34,  2.92s/it] 81%|████████  | 1355/1674 [1:19:39<17:45,  3.34s/it] 81%|████████  | 1356/1674 [1:19:42<17:11,  3.24s/it] 81%|████████  | 1357/1674 [1:19:45<16:51,  3.19s/it] 81%|████████  | 1358/1674 [1:19:48<16:32,  3.14s/it] 81%|████████  | 1359/1674 [1:19:51<15:43,  3.00s/it] 81%|████████  | 1360/1674 [1:19:53<14:04,  2.69s/it]                                                     {'loss': 0.3078, 'grad_norm': 18.45948028564453, 'learning_rate': 1.515848328068626e-07, 'rewards/chosen': -0.47661131620407104, 'rewards/rejected': -3.0703125, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.5953125953674316, 'logps/chosen': -84.1500015258789, 'logps/rejected': -128.64999389648438, 'logits/chosen': -8.5, 'logits/rejected': -8.043749809265137, 'epoch': 2.44}
 81%|████████  | 1360/1674 [1:19:53<14:04,  2.69s/it] 81%|████████▏ | 1361/1674 [1:19:57<16:02,  3.07s/it] 81%|████████▏ | 1362/1674 [1:19:59<15:07,  2.91s/it] 81%|████████▏ | 1363/1674 [1:20:02<15:09,  2.92s/it] 81%|████████▏ | 1364/1674 [1:20:05<15:07,  2.93s/it] 82%|████████▏ | 1365/1674 [1:20:07<14:13,  2.76s/it] 82%|████████▏ | 1366/1674 [1:20:09<12:36,  2.46s/it] 82%|████████▏ | 1367/1674 [1:20:13<14:49,  2.90s/it] 82%|████████▏ | 1368/1674 [1:20:16<14:43,  2.89s/it] 82%|████████▏ | 1369/1674 [1:20:19<15:19,  3.02s/it] 82%|████████▏ | 1370/1674 [1:20:23<16:39,  3.29s/it]                                                     {'loss': 0.2359, 'grad_norm': 7.1456427574157715, 'learning_rate': 1.4539274334502514e-07, 'rewards/chosen': -0.10302734375, 'rewards/rejected': -2.73046875, 'rewards/accuracies': 0.9416667222976685, 'rewards/margins': 2.6273436546325684, 'logps/chosen': -134.3000030517578, 'logps/rejected': -174.6999969482422, 'logits/chosen': -8.259374618530273, 'logits/rejected': -7.734375, 'epoch': 2.46}
 82%|████████▏ | 1370/1674 [1:20:23<16:39,  3.29s/it] 82%|████████▏ | 1371/1674 [1:20:26<15:24,  3.05s/it] 82%|████████▏ | 1372/1674 [1:20:29<16:31,  3.28s/it] 82%|████████▏ | 1373/1674 [1:20:32<15:21,  3.06s/it] 82%|████████▏ | 1374/1674 [1:20:34<13:35,  2.72s/it] 82%|████████▏ | 1375/1674 [1:20:37<14:32,  2.92s/it] 82%|████████▏ | 1376/1674 [1:20:39<13:21,  2.69s/it] 82%|████████▏ | 1377/1674 [1:20:43<14:13,  2.87s/it] 82%|████████▏ | 1378/1674 [1:20:46<15:16,  3.10s/it] 82%|████████▏ | 1379/1674 [1:20:49<14:30,  2.95s/it] 82%|████████▏ | 1380/1674 [1:20:51<12:54,  2.63s/it]                                                     {'loss': 0.1694, 'grad_norm': 9.452693939208984, 'learning_rate': 1.3930549748059442e-07, 'rewards/chosen': -0.21312256157398224, 'rewards/rejected': -3.192187547683716, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 2.979687452316284, 'logps/chosen': -68.7750015258789, 'logps/rejected': -107.0999984741211, 'logits/chosen': -8.618749618530273, 'logits/rejected': -8.050000190734863, 'epoch': 2.47}
 82%|████████▏ | 1380/1674 [1:20:51<12:54,  2.63s/it] 82%|████████▏ | 1381/1674 [1:20:54<13:13,  2.71s/it] 83%|████████▎ | 1382/1674 [1:20:57<13:38,  2.80s/it] 83%|████████▎ | 1383/1674 [1:20:59<12:51,  2.65s/it] 83%|████████▎ | 1384/1674 [1:21:00<10:57,  2.27s/it] 83%|████████▎ | 1385/1674 [1:21:04<12:31,  2.60s/it] 83%|████████▎ | 1386/1674 [1:21:08<14:25,  3.00s/it] 83%|████████▎ | 1387/1674 [1:21:11<14:26,  3.02s/it] 83%|████████▎ | 1388/1674 [1:21:13<13:42,  2.87s/it] 83%|████████▎ | 1389/1674 [1:21:17<14:19,  3.02s/it] 83%|████████▎ | 1390/1674 [1:21:19<13:45,  2.91s/it]                                                     {'loss': 0.309, 'grad_norm': 19.52445411682129, 'learning_rate': 1.3333164945860414e-07, 'rewards/chosen': -0.36572265625, 'rewards/rejected': -2.8734374046325684, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.5078125, 'logps/chosen': -123.75, 'logps/rejected': -163.9250030517578, 'logits/chosen': -8.509374618530273, 'logits/rejected': -7.949999809265137, 'epoch': 2.49}
 83%|████████▎ | 1390/1674 [1:21:19<13:45,  2.91s/it] 83%|████████▎ | 1391/1674 [1:21:23<14:04,  2.98s/it] 83%|████████▎ | 1392/1674 [1:21:26<14:11,  3.02s/it] 83%|████████▎ | 1393/1674 [1:21:29<15:00,  3.20s/it] 83%|████████▎ | 1394/1674 [1:21:33<15:43,  3.37s/it] 83%|████████▎ | 1395/1674 [1:21:35<13:45,  2.96s/it] 83%|████████▎ | 1396/1674 [1:21:39<14:57,  3.23s/it] 83%|████████▎ | 1397/1674 [1:21:41<12:41,  2.75s/it] 84%|████████▎ | 1398/1674 [1:21:43<12:55,  2.81s/it] 84%|████████▎ | 1399/1674 [1:21:45<11:07,  2.43s/it] 84%|████████▎ | 1400/1674 [1:21:47<11:04,  2.43s/it]                                                     {'loss': 0.2482, 'grad_norm': 8.191408157348633, 'learning_rate': 1.2747959416911016e-07, 'rewards/chosen': -0.42503660917282104, 'rewards/rejected': -2.989062547683716, 'rewards/accuracies': 0.8583332896232605, 'rewards/margins': 2.5625, 'logps/chosen': -74.80000305175781, 'logps/rejected': -121.8499984741211, 'logits/chosen': -8.6875, 'logits/rejected': -8.074999809265137, 'epoch': 2.51}
 84%|████████▎ | 1400/1674 [1:21:47<11:04,  2.43s/it] 84%|████████▎ | 1401/1674 [1:21:50<10:42,  2.35s/it] 84%|████████▍ | 1402/1674 [1:21:53<12:04,  2.66s/it] 84%|████████▍ | 1403/1674 [1:21:55<11:42,  2.59s/it] 84%|████████▍ | 1404/1674 [1:22:00<13:42,  3.05s/it] 84%|████████▍ | 1405/1674 [1:22:03<13:48,  3.08s/it] 84%|████████▍ | 1406/1674 [1:22:07<14:53,  3.33s/it] 84%|████████▍ | 1407/1674 [1:22:09<13:07,  2.95s/it] 84%|████████▍ | 1408/1674 [1:22:11<11:42,  2.64s/it] 84%|████████▍ | 1409/1674 [1:22:13<11:31,  2.61s/it] 84%|████████▍ | 1410/1674 [1:22:16<12:11,  2.77s/it]                                                     {'loss': 0.2968, 'grad_norm': 21.64219093322754, 'learning_rate': 1.2175755535007427e-07, 'rewards/chosen': -0.4222412109375, 'rewards/rejected': -2.721874952316284, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.297656297683716, 'logps/chosen': -95.0250015258789, 'logps/rejected': -115.8499984741211, 'logits/chosen': -8.503125190734863, 'logits/rejected': -8.040624618530273, 'epoch': 2.53}
 84%|████████▍ | 1410/1674 [1:22:16<12:11,  2.77s/it] 84%|████████▍ | 1411/1674 [1:22:20<13:24,  3.06s/it] 84%|████████▍ | 1412/1674 [1:22:23<13:28,  3.09s/it] 84%|████████▍ | 1413/1674 [1:22:25<12:21,  2.84s/it] 84%|████████▍ | 1414/1674 [1:22:28<11:41,  2.70s/it] 85%|████████▍ | 1415/1674 [1:22:31<12:48,  2.97s/it] 85%|████████▍ | 1416/1674 [1:22:35<13:27,  3.13s/it] 85%|████████▍ | 1417/1674 [1:22:37<12:08,  2.83s/it] 85%|████████▍ | 1418/1674 [1:22:41<13:07,  3.08s/it] 85%|████████▍ | 1419/1674 [1:22:45<14:10,  3.33s/it] 85%|████████▍ | 1420/1674 [1:22:47<13:11,  3.12s/it]                                                     {'loss': 0.3028, 'grad_norm': 26.601165771484375, 'learning_rate': 1.1617357403076342e-07, 'rewards/chosen': -0.6077911257743835, 'rewards/rejected': -3.0390625, 'rewards/accuracies': 0.875, 'rewards/margins': 2.43359375, 'logps/chosen': -87.4000015258789, 'logps/rejected': -120.55000305175781, 'logits/chosen': -8.600000381469727, 'logits/rejected': -8.140625, 'epoch': 2.54}
 85%|████████▍ | 1420/1674 [1:22:47<13:11,  3.12s/it] 85%|████████▍ | 1421/1674 [1:22:50<12:25,  2.95s/it] 85%|████████▍ | 1422/1674 [1:22:53<13:17,  3.16s/it] 85%|████████▌ | 1423/1674 [1:22:57<13:14,  3.17s/it] 85%|████████▌ | 1424/1674 [1:23:01<14:12,  3.41s/it] 85%|████████▌ | 1425/1674 [1:23:05<14:49,  3.57s/it] 85%|████████▌ | 1426/1674 [1:23:07<13:14,  3.20s/it] 85%|████████▌ | 1427/1674 [1:23:10<13:25,  3.26s/it] 85%|████████▌ | 1428/1674 [1:23:14<14:21,  3.50s/it] 85%|████████▌ | 1429/1674 [1:23:16<12:36,  3.09s/it] 85%|████████▌ | 1430/1674 [1:23:20<12:36,  3.10s/it]                                                     {'loss': 0.2272, 'grad_norm': 18.884899139404297, 'learning_rate': 1.107354972319047e-07, 'rewards/chosen': -0.5335937738418579, 'rewards/rejected': -3.385937452316284, 'rewards/accuracies': 0.8833333253860474, 'rewards/margins': 2.846874952316284, 'logps/chosen': -134.85000610351562, 'logps/rejected': -193.8000030517578, 'logits/chosen': -8.293749809265137, 'logits/rejected': -7.659375190734863, 'epoch': 2.56}
 85%|████████▌ | 1430/1674 [1:23:20<12:36,  3.10s/it] 85%|████████▌ | 1431/1674 [1:23:22<12:16,  3.03s/it] 86%|████████▌ | 1432/1674 [1:23:26<13:09,  3.26s/it] 86%|████████▌ | 1433/1674 [1:23:30<13:31,  3.37s/it] 86%|████████▌ | 1434/1674 [1:23:32<12:22,  3.09s/it] 86%|████████▌ | 1435/1674 [1:23:35<11:24,  2.87s/it] 86%|████████▌ | 1436/1674 [1:23:38<11:50,  2.98s/it] 86%|████████▌ | 1437/1674 [1:23:41<11:35,  2.94s/it] 86%|████████▌ | 1438/1674 [1:23:44<11:22,  2.89s/it] 86%|████████▌ | 1439/1674 [1:23:46<11:03,  2.82s/it] 86%|████████▌ | 1440/1674 [1:23:49<11:17,  2.90s/it]                                                     {'loss': 0.2384, 'grad_norm': 22.38853645324707, 'learning_rate': 1.0545096693847553e-07, 'rewards/chosen': -0.35637205839157104, 'rewards/rejected': -2.901562452316284, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.547656297683716, 'logps/chosen': -81.69999694824219, 'logps/rejected': -115.75, 'logits/chosen': -8.618749618530273, 'logits/rejected': -8.100000381469727, 'epoch': 2.58}
 86%|████████▌ | 1440/1674 [1:23:49<11:17,  2.90s/it] 86%|████████▌ | 1441/1674 [1:23:53<12:30,  3.22s/it] 86%|████████▌ | 1442/1674 [1:23:57<12:29,  3.23s/it] 86%|████████▌ | 1443/1674 [1:23:59<11:56,  3.10s/it] 86%|████████▋ | 1444/1674 [1:24:02<11:02,  2.88s/it] 86%|████████▋ | 1445/1674 [1:24:05<11:44,  3.08s/it] 86%|████████▋ | 1446/1674 [1:24:09<12:19,  3.24s/it] 86%|████████▋ | 1447/1674 [1:24:12<11:39,  3.08s/it] 86%|████████▋ | 1448/1674 [1:24:15<12:33,  3.34s/it] 87%|████████▋ | 1449/1674 [1:24:17<10:57,  2.92s/it] 87%|████████▋ | 1450/1674 [1:24:21<11:56,  3.20s/it]                                                     {'loss': 0.2388, 'grad_norm': 17.646913528442383, 'learning_rate': 1.003274093606251e-07, 'rewards/chosen': -0.092041015625, 'rewards/rejected': -3.0101561546325684, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.917187452316284, 'logps/chosen': -140.64999389648438, 'logps/rejected': -174.5500030517578, 'logits/chosen': -8.537500381469727, 'logits/rejected': -7.893750190734863, 'epoch': 2.6}
 87%|████████▋ | 1450/1674 [1:24:21<11:56,  3.20s/it] 87%|████████▋ | 1451/1674 [1:24:25<12:37,  3.40s/it] 87%|████████▋ | 1452/1674 [1:24:28<11:43,  3.17s/it] 87%|████████▋ | 1453/1674 [1:24:32<12:16,  3.33s/it] 87%|████████▋ | 1454/1674 [1:24:34<11:49,  3.22s/it] 87%|████████▋ | 1455/1674 [1:24:36<10:01,  2.74s/it] 87%|████████▋ | 1456/1674 [1:24:40<10:50,  2.99s/it] 87%|████████▋ | 1457/1674 [1:24:43<11:24,  3.15s/it] 87%|████████▋ | 1458/1674 [1:24:46<10:33,  2.93s/it] 87%|████████▋ | 1459/1674 [1:24:48<10:23,  2.90s/it] 87%|████████▋ | 1460/1674 [1:24:53<11:50,  3.32s/it]                                                     {'loss': 0.3796, 'grad_norm': 32.3282356262207, 'learning_rate': 9.537202449781819e-08, 'rewards/chosen': -0.6115967035293579, 'rewards/rejected': -2.9359374046325684, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.3265624046325684, 'logps/chosen': -95.07499694824219, 'logps/rejected': -113.5250015258789, 'logits/chosen': -8.481249809265137, 'logits/rejected': -8.037500381469727, 'epoch': 2.62}
 87%|████████▋ | 1460/1674 [1:24:53<11:50,  3.32s/it] 87%|████████▋ | 1461/1674 [1:24:56<12:14,  3.45s/it] 87%|████████▋ | 1462/1674 [1:25:00<12:23,  3.51s/it] 87%|████████▋ | 1463/1674 [1:25:02<10:16,  2.92s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:59,  1.31it/s][A
  4%|▍         | 3/80 [00:03<01:24,  1.10s/it][A
  5%|▌         | 4/80 [00:04<01:36,  1.27s/it][A
  6%|▋         | 5/80 [00:06<01:45,  1.40s/it][A
  8%|▊         | 6/80 [00:07<01:47,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:50,  1.51s/it][A
 10%|█         | 8/80 [00:11<01:52,  1.56s/it][A
 11%|█▏        | 9/80 [00:12<01:51,  1.57s/it][A
 12%|█▎        | 10/80 [00:14<01:52,  1.61s/it][A
 14%|█▍        | 11/80 [00:16<01:52,  1.63s/it][A
 15%|█▌        | 12/80 [00:17<01:49,  1.61s/it][A
 16%|█▋        | 13/80 [00:19<01:47,  1.60s/it][A
 18%|█▊        | 14/80 [00:21<01:48,  1.64s/it][A
 19%|█▉        | 15/80 [00:22<01:46,  1.63s/it][A
 20%|██        | 16/80 [00:24<01:43,  1.62s/it][A
 21%|██▏       | 17/80 [00:25<01:41,  1.61s/it][A
 22%|██▎       | 18/80 [00:27<01:40,  1.61s/it][A
 24%|██▍       | 19/80 [00:28<01:29,  1.46s/it][A
 25%|██▌       | 20/80 [00:29<01:24,  1.41s/it][A
 26%|██▋       | 21/80 [00:30<01:07,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:05,  1.14s/it][A
 29%|██▉       | 23/80 [00:32<01:04,  1.13s/it][A
 30%|███       | 24/80 [00:33<00:52,  1.07it/s][A
 31%|███▏      | 25/80 [00:34<00:55,  1.01s/it][A
 32%|███▎      | 26/80 [00:35<00:58,  1.09s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.03it/s][A
 35%|███▌      | 28/80 [00:37<00:51,  1.02it/s][A
 36%|███▋      | 29/80 [00:38<00:55,  1.08s/it][A
 38%|███▊      | 30/80 [00:39<00:55,  1.10s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.10s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.05it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.16s/it][A
 42%|████▎     | 34/80 [00:44<00:57,  1.25s/it][A
 44%|████▍     | 35/80 [00:44<00:45,  1.02s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.05it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.06it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.21it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.02s/it][A
 50%|█████     | 40/80 [00:50<00:49,  1.23s/it][A
 51%|█████▏    | 41/80 [00:51<00:40,  1.04s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.20s/it][A
 54%|█████▍    | 43/80 [00:54<00:47,  1.28s/it][A
 55%|█████▌    | 44/80 [00:55<00:45,  1.26s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.13s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.06it/s][A
 59%|█████▉    | 47/80 [00:58<00:35,  1.09s/it][A
 60%|██████    | 48/80 [00:59<00:38,  1.19s/it][A
 61%|██████▏   | 49/80 [01:00<00:31,  1.01s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.18it/s][A
 64%|██████▍   | 51/80 [01:02<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:03<00:26,  1.03it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.18s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:09<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.21s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.01s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.16s/it][A
 78%|███████▊  | 62/80 [01:14<00:23,  1.32s/it][A
 79%|███████▉  | 63/80 [01:16<00:21,  1.25s/it][A
 80%|████████  | 64/80 [01:16<00:17,  1.12s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.23s/it][A
 82%|████████▎ | 66/80 [01:19<00:18,  1.33s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.43s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:26<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:30<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:31<00:06,  1.26s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.35s/it][A
 96%|█████████▋| 77/80 [01:34<00:04,  1.35s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.12s/it][A
 99%|█████████▉| 79/80 [01:36<00:01,  1.25s/it][A
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A                                                     
                                               [A{'eval_loss': 0.6028540134429932, 'eval_runtime': 100.2626, 'eval_samples_per_second': 9.505, 'eval_steps_per_second': 0.798, 'eval_rewards/chosen': -0.7182708978652954, 'eval_rewards/rejected': -3.1982178688049316, 'eval_rewards/accuracies': 0.768125057220459, 'eval_rewards/margins': 2.478053331375122, 'eval_logps/chosen': -365.93438720703125, 'eval_logps/rejected': -186.45938110351562, 'eval_logits/chosen': -7.931250095367432, 'eval_logits/rejected': -7.965234279632568, 'epoch': 2.62}
 87%|████████▋ | 1463/1674 [1:26:42<10:16,  2.92s/it]
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 87%|████████▋ | 1464/1674 [1:26:58<2:09:34, 37.02s/it] 88%|████████▊ | 1465/1674 [1:27:01<1:33:25, 26.82s/it] 88%|████████▊ | 1466/1674 [1:27:03<1:06:51, 19.29s/it] 88%|████████▊ | 1467/1674 [1:27:06<49:26, 14.33s/it]   88%|████████▊ | 1468/1674 [1:27:09<38:04, 11.09s/it] 88%|████████▊ | 1469/1674 [1:27:12<29:24,  8.61s/it] 88%|████████▊ | 1470/1674 [1:27:16<24:37,  7.24s/it]                                                     {'loss': 0.3298, 'grad_norm': 22.99723243713379, 'learning_rate': 9.059177602086694e-08, 'rewards/chosen': -0.392578125, 'rewards/rejected': -2.690624952316284, 'rewards/accuracies': 0.8166667222976685, 'rewards/margins': 2.2953124046325684, 'logps/chosen': -136.27499389648438, 'logps/rejected': -154.22500610351562, 'logits/chosen': -8.521875381469727, 'logits/rejected': -8.043749809265137, 'epoch': 2.63}
 88%|████████▊ | 1470/1674 [1:27:16<24:37,  7.24s/it] 88%|████████▊ | 1471/1674 [1:27:19<19:54,  5.88s/it] 88%|████████▊ | 1472/1674 [1:27:22<16:42,  4.96s/it] 88%|████████▊ | 1473/1674 [1:27:23<13:16,  3.96s/it] 88%|████████▊ | 1474/1674 [1:27:26<12:05,  3.63s/it] 88%|████████▊ | 1475/1674 [1:27:30<12:15,  3.70s/it] 88%|████████▊ | 1476/1674 [1:27:34<12:39,  3.84s/it] 88%|████████▊ | 1477/1674 [1:27:37<11:34,  3.53s/it] 88%|████████▊ | 1478/1674 [1:27:41<11:56,  3.66s/it] 88%|████████▊ | 1479/1674 [1:27:43<10:27,  3.22s/it] 88%|████████▊ | 1480/1674 [1:27:47<11:06,  3.44s/it]                                                     {'loss': 0.3087, 'grad_norm': 37.19317626953125, 'learning_rate': 8.599338148606947e-08, 'rewards/chosen': -0.44121092557907104, 'rewards/rejected': -3.0, 'rewards/accuracies': 0.9083333015441895, 'rewards/margins': 2.5601563453674316, 'logps/chosen': -138.8249969482422, 'logps/rejected': -158.75, 'logits/chosen': -8.459375381469727, 'logits/rejected': -8.212499618530273, 'epoch': 2.65}
 88%|████████▊ | 1480/1674 [1:27:47<11:06,  3.44s/it] 88%|████████▊ | 1481/1674 [1:27:51<11:19,  3.52s/it] 89%|████████▊ | 1482/1674 [1:27:54<11:24,  3.56s/it] 89%|████████▊ | 1483/1674 [1:27:58<11:26,  3.59s/it] 89%|████████▊ | 1484/1674 [1:28:02<11:29,  3.63s/it] 89%|████████▊ | 1485/1674 [1:28:06<11:43,  3.72s/it] 89%|████████▉ | 1486/1674 [1:28:09<11:30,  3.67s/it] 89%|████████▉ | 1487/1674 [1:28:13<11:00,  3.53s/it] 89%|████████▉ | 1488/1674 [1:28:17<11:43,  3.78s/it] 89%|████████▉ | 1489/1674 [1:28:21<11:42,  3.79s/it] 89%|████████▉ | 1490/1674 [1:28:24<11:15,  3.67s/it]                                                     {'loss': 0.2556, 'grad_norm': 24.181785583496094, 'learning_rate': 8.158330289520597e-08, 'rewards/chosen': -0.3462890684604645, 'rewards/rejected': -3.0765624046325684, 'rewards/accuracies': 0.8833333253860474, 'rewards/margins': 2.7265625, 'logps/chosen': -117.75, 'logps/rejected': -171.1999969482422, 'logits/chosen': -8.524999618530273, 'logits/rejected': -7.962500095367432, 'epoch': 2.67}
 89%|████████▉ | 1490/1674 [1:28:24<11:15,  3.67s/it] 89%|████████▉ | 1491/1674 [1:28:26<09:41,  3.18s/it] 89%|████████▉ | 1492/1674 [1:28:30<10:17,  3.39s/it] 89%|████████▉ | 1493/1674 [1:28:33<09:32,  3.16s/it] 89%|████████▉ | 1494/1674 [1:28:37<10:13,  3.41s/it] 89%|████████▉ | 1495/1674 [1:28:41<10:45,  3.60s/it] 89%|████████▉ | 1496/1674 [1:28:43<09:15,  3.12s/it] 89%|████████▉ | 1497/1674 [1:28:46<09:02,  3.07s/it] 89%|████████▉ | 1498/1674 [1:28:47<07:33,  2.58s/it] 90%|████████▉ | 1499/1674 [1:28:50<07:33,  2.59s/it] 90%|████████▉ | 1500/1674 [1:28:53<07:56,  2.74s/it]                                                     {'loss': 0.3121, 'grad_norm': 15.374448776245117, 'learning_rate': 7.736773761465935e-08, 'rewards/chosen': -0.29789429903030396, 'rewards/rejected': -2.98046875, 'rewards/accuracies': 0.8833333253860474, 'rewards/margins': 2.684375047683716, 'logps/chosen': -107.19999694824219, 'logps/rejected': -132.85000610351562, 'logits/chosen': -8.5625, 'logits/rejected': -7.965624809265137, 'epoch': 2.69}
 90%|████████▉ | 1500/1674 [1:28:53<07:56,  2.74s/it] 90%|████████▉ | 1501/1674 [1:28:55<07:41,  2.67s/it] 90%|████████▉ | 1502/1674 [1:28:59<08:44,  3.05s/it] 90%|████████▉ | 1503/1674 [1:29:03<08:54,  3.12s/it] 90%|████████▉ | 1504/1674 [1:29:06<09:25,  3.33s/it] 90%|████████▉ | 1505/1674 [1:29:08<08:15,  2.93s/it] 90%|████████▉ | 1506/1674 [1:29:11<08:22,  2.99s/it] 90%|█████████ | 1507/1674 [1:29:14<08:00,  2.88s/it] 90%|█████████ | 1508/1674 [1:29:17<07:55,  2.87s/it] 90%|█████████ | 1509/1674 [1:29:19<07:26,  2.71s/it] 90%|█████████ | 1510/1674 [1:29:23<07:56,  2.91s/it]                                                     {'loss': 0.2026, 'grad_norm': 21.586454391479492, 'learning_rate': 7.33526096664207e-08, 'rewards/chosen': -0.4544433653354645, 'rewards/rejected': -3.1343750953674316, 'rewards/accuracies': 0.9166666269302368, 'rewards/margins': 2.6781249046325684, 'logps/chosen': -80.5250015258789, 'logps/rejected': -120.69999694824219, 'logits/chosen': -8.534375190734863, 'logits/rejected': -8.018750190734863, 'epoch': 2.71}
 90%|█████████ | 1510/1674 [1:29:23<07:56,  2.91s/it] 90%|█████████ | 1511/1674 [1:29:25<07:40,  2.83s/it] 90%|█████████ | 1512/1674 [1:29:29<08:13,  3.05s/it] 90%|█████████ | 1513/1674 [1:29:33<08:44,  3.26s/it] 90%|█████████ | 1514/1674 [1:29:35<07:37,  2.86s/it] 91%|█████████ | 1515/1674 [1:29:37<07:07,  2.69s/it] 91%|█████████ | 1516/1674 [1:29:40<07:07,  2.70s/it] 91%|█████████ | 1517/1674 [1:29:42<07:12,  2.75s/it] 91%|█████████ | 1518/1674 [1:29:45<06:41,  2.57s/it] 91%|█████████ | 1519/1674 [1:29:47<06:34,  2.55s/it] 91%|█████████ | 1520/1674 [1:29:51<07:17,  2.84s/it]                                                     {'loss': 0.2086, 'grad_norm': 22.362064361572266, 'learning_rate': 6.954356140321827e-08, 'rewards/chosen': -0.34912109375, 'rewards/rejected': -3.03125, 'rewards/accuracies': 0.9083333015441895, 'rewards/margins': 2.6859374046325684, 'logps/chosen': -68.5250015258789, 'logps/rejected': -106.80000305175781, 'logits/chosen': -8.606249809265137, 'logits/rejected': -8.143750190734863, 'epoch': 2.72}
 91%|█████████ | 1520/1674 [1:29:51<07:17,  2.84s/it] 91%|█████████ | 1521/1674 [1:29:53<06:47,  2.66s/it] 91%|█████████ | 1522/1674 [1:29:56<07:13,  2.85s/it] 91%|█████████ | 1523/1674 [1:29:58<06:38,  2.64s/it] 91%|█████████ | 1524/1674 [1:30:00<06:07,  2.45s/it] 91%|█████████ | 1525/1674 [1:30:03<06:16,  2.53s/it] 91%|█████████ | 1526/1674 [1:30:05<06:08,  2.49s/it] 91%|█████████ | 1527/1674 [1:30:09<06:34,  2.69s/it] 91%|█████████▏| 1528/1674 [1:30:12<07:20,  3.02s/it] 91%|█████████▏| 1529/1674 [1:30:15<07:04,  2.93s/it] 91%|█████████▏| 1530/1674 [1:30:19<07:31,  3.13s/it]                                                     {'loss': 0.2625, 'grad_norm': 38.23186111450195, 'learning_rate': 6.594594557946923e-08, 'rewards/chosen': -0.6021568179130554, 'rewards/rejected': -3.2203125953674316, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.620312452316284, 'logps/chosen': -89.5, 'logps/rejected': -118.75, 'logits/chosen': -8.574999809265137, 'logits/rejected': -8.09375, 'epoch': 2.74}
 91%|█████████▏| 1530/1674 [1:30:19<07:31,  3.13s/it] 91%|█████████▏| 1531/1674 [1:30:21<07:13,  3.03s/it] 92%|█████████▏| 1532/1674 [1:30:24<06:56,  2.93s/it] 92%|█████████▏| 1533/1674 [1:30:26<06:28,  2.76s/it] 92%|█████████▏| 1534/1674 [1:30:28<05:36,  2.40s/it] 92%|█████████▏| 1535/1674 [1:30:30<05:07,  2.21s/it] 92%|█████████▏| 1536/1674 [1:30:33<05:57,  2.59s/it] 92%|█████████▏| 1537/1674 [1:30:36<06:02,  2.65s/it] 92%|█████████▏| 1538/1674 [1:30:40<06:31,  2.88s/it] 92%|█████████▏| 1539/1674 [1:30:42<06:13,  2.77s/it] 92%|█████████▏| 1540/1674 [1:30:46<06:46,  3.04s/it]                                                     {'loss': 0.2474, 'grad_norm': 19.49152374267578, 'learning_rate': 6.256481782919585e-08, 'rewards/chosen': -0.4853759706020355, 'rewards/rejected': -2.9906249046325684, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.507031202316284, 'logps/chosen': -84.55000305175781, 'logps/rejected': -107.1500015258789, 'logits/chosen': -8.493749618530273, 'logits/rejected': -8.228124618530273, 'epoch': 2.76}
 92%|█████████▏| 1540/1674 [1:30:46<06:46,  3.04s/it] 92%|█████████▏| 1541/1674 [1:30:48<06:31,  2.94s/it] 92%|█████████▏| 1542/1674 [1:30:52<07:03,  3.21s/it] 92%|█████████▏| 1543/1674 [1:30:54<06:13,  2.85s/it] 92%|█████████▏| 1544/1674 [1:30:56<05:38,  2.60s/it] 92%|█████████▏| 1545/1674 [1:30:59<05:30,  2.56s/it] 92%|█████████▏| 1546/1674 [1:31:02<06:03,  2.84s/it] 92%|█████████▏| 1547/1674 [1:31:05<06:13,  2.94s/it] 92%|█████████▏| 1548/1674 [1:31:09<06:33,  3.12s/it] 93%|█████████▎| 1549/1674 [1:31:12<06:18,  3.03s/it] 93%|█████████▎| 1550/1674 [1:31:16<06:52,  3.32s/it]                                                     {'loss': 0.2926, 'grad_norm': 26.73536491394043, 'learning_rate': 5.940492956147703e-08, 'rewards/chosen': -0.6781250238418579, 'rewards/rejected': -3.237499952316284, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 2.557812452316284, 'logps/chosen': -81.2249984741211, 'logps/rejected': -123.8499984741211, 'logits/chosen': -8.649999618530273, 'logits/rejected': -8.159375190734863, 'epoch': 2.78}
 93%|█████████▎| 1550/1674 [1:31:16<06:52,  3.32s/it] 93%|█████████▎| 1551/1674 [1:31:20<07:10,  3.50s/it] 93%|█████████▎| 1552/1674 [1:31:22<06:18,  3.10s/it] 93%|█████████▎| 1553/1674 [1:31:26<06:39,  3.30s/it] 93%|█████████▎| 1554/1674 [1:31:28<05:52,  2.93s/it] 93%|█████████▎| 1555/1674 [1:31:31<05:44,  2.90s/it] 93%|█████████▎| 1556/1674 [1:31:34<05:58,  3.04s/it] 93%|█████████▎| 1557/1674 [1:31:37<06:04,  3.12s/it] 93%|█████████▎| 1558/1674 [1:31:41<06:22,  3.30s/it] 93%|█████████▎| 1559/1674 [1:31:45<06:36,  3.45s/it] 93%|█████████▎| 1560/1674 [1:31:49<06:48,  3.59s/it]                                                     {'loss': 0.3415, 'grad_norm': 4.954658508300781, 'learning_rate': 5.647072128341958e-08, 'rewards/chosen': -0.559277355670929, 'rewards/rejected': -3.114062547683716, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.553906202316284, 'logps/chosen': -96.0250015258789, 'logps/rejected': -116.4749984741211, 'logits/chosen': -8.556249618530273, 'logits/rejected': -8.181249618530273, 'epoch': 2.8}
 93%|█████████▎| 1560/1674 [1:31:49<06:48,  3.59s/it] 93%|█████████▎| 1561/1674 [1:31:53<07:04,  3.75s/it] 93%|█████████▎| 1562/1674 [1:31:56<06:49,  3.66s/it] 93%|█████████▎| 1563/1674 [1:32:00<07:02,  3.81s/it] 93%|█████████▎| 1564/1674 [1:32:03<06:27,  3.52s/it] 93%|█████████▎| 1565/1674 [1:32:05<05:33,  3.06s/it] 94%|█████████▎| 1566/1674 [1:32:07<04:56,  2.74s/it] 94%|█████████▎| 1567/1674 [1:32:11<05:21,  3.00s/it] 94%|█████████▎| 1568/1674 [1:32:13<05:03,  2.86s/it] 94%|█████████▎| 1569/1674 [1:32:17<05:34,  3.19s/it] 94%|█████████▍| 1570/1674 [1:32:19<04:58,  2.87s/it]                                                     {'loss': 0.1812, 'grad_norm': 23.35257339477539, 'learning_rate': 5.3766316360031203e-08, 'rewards/chosen': -0.21430663764476776, 'rewards/rejected': -2.9937500953674316, 'rewards/accuracies': 0.9500001072883606, 'rewards/margins': 2.7835936546325684, 'logps/chosen': -98.4749984741211, 'logps/rejected': -132.0, 'logits/chosen': -8.600000381469727, 'logits/rejected': -7.965624809265137, 'epoch': 2.81}
 94%|█████████▍| 1570/1674 [1:32:20<04:58,  2.87s/it] 94%|█████████▍| 1571/1674 [1:32:21<04:30,  2.62s/it] 94%|█████████▍| 1572/1674 [1:32:24<04:23,  2.58s/it] 94%|█████████▍| 1573/1674 [1:32:28<05:01,  2.98s/it] 94%|█████████▍| 1574/1674 [1:32:32<05:26,  3.27s/it] 94%|█████████▍| 1575/1674 [1:32:36<05:49,  3.53s/it] 94%|█████████▍| 1576/1674 [1:32:38<05:10,  3.16s/it] 94%|█████████▍| 1577/1674 [1:32:41<04:41,  2.90s/it] 94%|█████████▍| 1578/1674 [1:32:44<04:45,  2.97s/it] 94%|█████████▍| 1579/1674 [1:32:46<04:32,  2.87s/it] 94%|█████████▍| 1580/1674 [1:32:50<04:46,  3.05s/it]                                                     {'loss': 0.2781, 'grad_norm': 16.811113357543945, 'learning_rate': 5.129551521976516e-08, 'rewards/chosen': -0.36027830839157104, 'rewards/rejected': -2.973437547683716, 'rewards/accuracies': 0.8666666150093079, 'rewards/margins': 2.6171875, 'logps/chosen': -99.1500015258789, 'logps/rejected': -121.9000015258789, 'logits/chosen': -8.5, 'logits/rejected': -8.059374809265137, 'epoch': 2.83}
 94%|█████████▍| 1580/1674 [1:32:50<04:46,  3.05s/it] 94%|█████████▍| 1581/1674 [1:32:54<05:09,  3.33s/it] 95%|█████████▍| 1582/1674 [1:32:55<04:21,  2.84s/it] 95%|█████████▍| 1583/1674 [1:33:00<05:01,  3.31s/it] 95%|█████████▍| 1584/1674 [1:33:03<04:44,  3.16s/it] 95%|█████████▍| 1585/1674 [1:33:07<05:07,  3.46s/it] 95%|█████████▍| 1586/1674 [1:33:09<04:41,  3.20s/it] 95%|█████████▍| 1587/1674 [1:33:13<04:39,  3.21s/it] 95%|█████████▍| 1588/1674 [1:33:16<04:49,  3.37s/it] 95%|█████████▍| 1589/1674 [1:33:19<04:28,  3.16s/it] 95%|█████████▍| 1590/1674 [1:33:22<04:17,  3.07s/it]                                                     {'loss': 0.3369, 'grad_norm': 21.653278350830078, 'learning_rate': 4.9061790013879084e-08, 'rewards/chosen': -0.7730652093887329, 'rewards/rejected': -3.089062452316284, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.31640625, 'logps/chosen': -120.19999694824219, 'logps/rejected': -154.5500030517578, 'logits/chosen': -8.59375, 'logits/rejected': -8.118749618530273, 'epoch': 2.85}
 95%|█████████▍| 1590/1674 [1:33:22<04:17,  3.07s/it] 95%|█████████▌| 1591/1674 [1:33:24<03:57,  2.87s/it] 95%|█████████▌| 1592/1674 [1:33:27<03:42,  2.71s/it] 95%|█████████▌| 1593/1674 [1:33:30<03:46,  2.80s/it] 95%|█████████▌| 1594/1674 [1:33:32<03:43,  2.79s/it] 95%|█████████▌| 1595/1674 [1:33:36<03:58,  3.02s/it] 95%|█████████▌| 1596/1674 [1:33:40<04:08,  3.18s/it] 95%|█████████▌| 1597/1674 [1:33:44<04:29,  3.50s/it] 95%|█████████▌| 1598/1674 [1:33:47<04:19,  3.42s/it] 96%|█████████▌| 1599/1674 [1:33:48<03:31,  2.82s/it] 96%|█████████▌| 1600/1674 [1:33:50<02:54,  2.36s/it]                                                     {'loss': 0.1973, 'grad_norm': 4.7989397048950195, 'learning_rate': 4.7068279737112914e-08, 'rewards/chosen': -0.3453125059604645, 'rewards/rejected': -3.075000047683716, 'rewards/accuracies': 0.9249998927116394, 'rewards/margins': 2.729687452316284, 'logps/chosen': -78.625, 'logps/rejected': -107.55000305175781, 'logits/chosen': -8.53125, 'logits/rejected': -7.943749904632568, 'epoch': 2.87}
 96%|█████████▌| 1600/1674 [1:33:50<02:54,  2.36s/it] 96%|█████████▌| 1601/1674 [1:33:53<03:11,  2.63s/it] 96%|█████████▌| 1602/1674 [1:33:57<03:43,  3.11s/it] 96%|█████████▌| 1603/1674 [1:34:01<03:49,  3.23s/it] 96%|█████████▌| 1604/1674 [1:34:04<03:55,  3.37s/it] 96%|█████████▌| 1605/1674 [1:34:07<03:34,  3.10s/it] 96%|█████████▌| 1606/1674 [1:34:09<03:19,  2.94s/it] 96%|█████████▌| 1607/1674 [1:34:13<03:22,  3.02s/it] 96%|█████████▌| 1608/1674 [1:34:15<03:08,  2.85s/it] 96%|█████████▌| 1609/1674 [1:34:19<03:25,  3.16s/it] 96%|█████████▌| 1610/1674 [1:34:22<03:25,  3.22s/it]                                                     {'loss': 0.2846, 'grad_norm': 9.215038299560547, 'learning_rate': 4.5317785816542994e-08, 'rewards/chosen': -0.6138671636581421, 'rewards/rejected': -3.284374952316284, 'rewards/accuracies': 0.908333420753479, 'rewards/margins': 2.6695313453674316, 'logps/chosen': -82.17500305175781, 'logps/rejected': -129.1999969482422, 'logits/chosen': -8.743749618530273, 'logits/rejected': -8.196874618530273, 'epoch': 2.89}
 96%|█████████▌| 1610/1674 [1:34:23<03:25,  3.22s/it] 96%|█████████▌| 1611/1674 [1:34:26<03:37,  3.45s/it] 96%|█████████▋| 1612/1674 [1:34:30<03:42,  3.60s/it] 96%|█████████▋| 1613/1674 [1:34:33<03:19,  3.27s/it] 96%|█████████▋| 1614/1674 [1:34:36<03:15,  3.26s/it] 96%|█████████▋| 1615/1674 [1:34:39<03:03,  3.10s/it] 97%|█████████▋| 1616/1674 [1:34:42<02:58,  3.08s/it] 97%|█████████▋| 1617/1674 [1:34:44<02:46,  2.92s/it] 97%|█████████▋| 1618/1674 [1:34:47<02:41,  2.89s/it] 97%|█████████▋| 1619/1674 [1:34:50<02:44,  3.00s/it] 97%|█████████▋| 1620/1674 [1:34:53<02:36,  2.90s/it]                                                     {'loss': 0.2967, 'grad_norm': 41.72792053222656, 'learning_rate': 4.3812768174810874e-08, 'rewards/chosen': -0.56915283203125, 'rewards/rejected': -3.364062547683716, 'rewards/accuracies': 0.8833333253860474, 'rewards/margins': 2.796093702316284, 'logps/chosen': -91.05000305175781, 'logps/rejected': -136.5500030517578, 'logits/chosen': -8.574999809265137, 'logits/rejected': -7.96875, 'epoch': 2.9}
 97%|█████████▋| 1620/1674 [1:34:53<02:36,  2.90s/it] 97%|█████████▋| 1621/1674 [1:34:56<02:34,  2.92s/it] 97%|█████████▋| 1622/1674 [1:35:00<02:44,  3.17s/it] 97%|█████████▋| 1623/1674 [1:35:04<02:53,  3.41s/it] 97%|█████████▋| 1624/1674 [1:35:06<02:35,  3.11s/it] 97%|█████████▋| 1625/1674 [1:35:08<02:17,  2.81s/it] 97%|█████████▋| 1626/1674 [1:35:11<02:15,  2.81s/it] 97%|█████████▋| 1627/1674 [1:35:14<02:10,  2.77s/it] 97%|█████████▋| 1628/1674 [1:35:16<02:06,  2.75s/it] 97%|█████████▋| 1629/1674 [1:35:20<02:17,  3.05s/it] 97%|█████████▋| 1630/1674 [1:35:22<01:53,  2.58s/it]                                                     {'loss': 0.2338, 'grad_norm': 15.289563179016113, 'learning_rate': 4.255534177325942e-08, 'rewards/chosen': -0.4656738340854645, 'rewards/rejected': -2.940624952316284, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 2.4749999046325684, 'logps/chosen': -81.05000305175781, 'logps/rejected': -111.5999984741211, 'logits/chosen': -8.518750190734863, 'logits/rejected': -8.125, 'epoch': 2.92}
 97%|█████████▋| 1630/1674 [1:35:22<01:53,  2.58s/it] 97%|█████████▋| 1631/1674 [1:35:24<01:50,  2.57s/it] 97%|█████████▋| 1632/1674 [1:35:27<01:52,  2.67s/it] 98%|█████████▊| 1633/1674 [1:35:30<01:46,  2.59s/it] 98%|█████████▊| 1634/1674 [1:35:32<01:40,  2.52s/it] 98%|█████████▊| 1635/1674 [1:35:36<01:54,  2.93s/it] 98%|█████████▊| 1636/1674 [1:35:39<01:54,  3.02s/it] 98%|█████████▊| 1637/1674 [1:35:41<01:43,  2.81s/it] 98%|█████████▊| 1638/1674 [1:35:45<01:47,  2.98s/it] 98%|█████████▊| 1639/1674 [1:35:48<01:51,  3.20s/it] 98%|█████████▊| 1640/1674 [1:35:52<01:48,  3.18s/it]                                                     {'loss': 0.3409, 'grad_norm': 27.012407302856445, 'learning_rate': 4.154727363983366e-08, 'rewards/chosen': -0.7474609613418579, 'rewards/rejected': -3.120312452316284, 'rewards/accuracies': 0.8416666984558105, 'rewards/margins': 2.374218702316284, 'logps/chosen': -80.07499694824219, 'logps/rejected': -123.69999694824219, 'logits/chosen': -8.493749618530273, 'logits/rejected': -8.040624618530273, 'epoch': 2.94}
 98%|█████████▊| 1640/1674 [1:35:52<01:48,  3.18s/it] 98%|█████████▊| 1641/1674 [1:35:54<01:38,  2.98s/it] 98%|█████████▊| 1642/1674 [1:35:58<01:40,  3.13s/it] 98%|█████████▊| 1643/1674 [1:36:02<01:44,  3.39s/it] 98%|█████████▊| 1644/1674 [1:36:05<01:41,  3.38s/it] 98%|█████████▊| 1645/1674 [1:36:09<01:43,  3.58s/it] 98%|█████████▊| 1646/1674 [1:36:13<01:44,  3.75s/it] 98%|█████████▊| 1647/1674 [1:36:15<01:29,  3.32s/it] 98%|█████████▊| 1648/1674 [1:36:18<01:21,  3.15s/it] 99%|█████████▊| 1649/1674 [1:36:22<01:25,  3.43s/it] 99%|█████████▊| 1650/1674 [1:36:26<01:21,  3.41s/it]                                                     {'loss': 0.2561, 'grad_norm': 20.087032318115234, 'learning_rate': 4.078998038592338e-08, 'rewards/chosen': -0.5761474370956421, 'rewards/rejected': -3.129687547683716, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.554394483566284, 'logps/chosen': -80.4000015258789, 'logps/rejected': -118.5, 'logits/chosen': -8.399999618530273, 'logits/rejected': -7.834374904632568, 'epoch': 2.96}
 99%|█████████▊| 1650/1674 [1:36:26<01:21,  3.41s/it] 99%|█████████▊| 1651/1674 [1:36:29<01:17,  3.36s/it] 99%|█████████▊| 1652/1674 [1:36:32<01:10,  3.20s/it] 99%|█████████▊| 1653/1674 [1:36:34<01:01,  2.94s/it] 99%|█████████▉| 1654/1674 [1:36:35<00:49,  2.49s/it] 99%|█████████▉| 1655/1674 [1:36:38<00:48,  2.57s/it] 99%|█████████▉| 1656/1674 [1:36:41<00:45,  2.50s/it] 99%|█████████▉| 1657/1674 [1:36:43<00:44,  2.60s/it] 99%|█████████▉| 1658/1674 [1:36:46<00:41,  2.60s/it] 99%|█████████▉| 1659/1674 [1:36:49<00:41,  2.80s/it] 99%|█████████▉| 1660/1674 [1:36:52<00:39,  2.83s/it]                                                     {'loss': 0.3089, 'grad_norm': 42.82542037963867, 'learning_rate': 4.028452621563679e-08, 'rewards/chosen': -0.6703857183456421, 'rewards/rejected': -3.2359375953674316, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 2.5648436546325684, 'logps/chosen': -78.5, 'logps/rejected': -111.9749984741211, 'logits/chosen': -8.581250190734863, 'logits/rejected': -8.09375, 'epoch': 2.97}
 99%|█████████▉| 1660/1674 [1:36:52<00:39,  2.83s/it] 99%|█████████▉| 1661/1674 [1:36:56<00:41,  3.23s/it] 99%|█████████▉| 1662/1674 [1:36:59<00:37,  3.17s/it] 99%|█████████▉| 1663/1674 [1:37:02<00:34,  3.16s/it] 99%|█████████▉| 1664/1674 [1:37:06<00:33,  3.37s/it] 99%|█████████▉| 1665/1674 [1:37:10<00:31,  3.54s/it]100%|█████████▉| 1666/1674 [1:37:13<00:27,  3.43s/it]100%|█████████▉| 1667/1674 [1:37:16<00:23,  3.29s/it]100%|█████████▉| 1668/1674 [1:37:19<00:17,  2.99s/it]100%|█████████▉| 1669/1674 [1:37:21<00:14,  2.84s/it]100%|█████████▉| 1670/1674 [1:37:25<00:12,  3.00s/it]                                                     {'loss': 0.2685, 'grad_norm': 26.62924575805664, 'learning_rate': 4.003162143030262e-08, 'rewards/chosen': -0.661425769329071, 'rewards/rejected': -3.035937547683716, 'rewards/accuracies': 0.8833333253860474, 'rewards/margins': 2.3734374046325684, 'logps/chosen': -84.05000305175781, 'logps/rejected': -132.85000610351562, 'logits/chosen': -8.59375, 'logits/rejected': -8.065625190734863, 'epoch': 2.99}
100%|█████████▉| 1670/1674 [1:37:25<00:12,  3.00s/it]100%|█████████▉| 1671/1674 [1:37:29<00:10,  3.38s/it]100%|█████████▉| 1672/1674 [1:37:31<00:05,  2.98s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:57,  1.36it/s][A
  4%|▍         | 3/80 [00:03<01:23,  1.09s/it][A
  5%|▌         | 4/80 [00:04<01:35,  1.26s/it][A
  6%|▋         | 5/80 [00:06<01:45,  1.41s/it][A
  8%|▊         | 6/80 [00:07<01:48,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:53,  1.56s/it][A
 10%|█         | 8/80 [00:11<01:54,  1.58s/it][A
 11%|█▏        | 9/80 [00:12<01:53,  1.60s/it][A
 12%|█▎        | 10/80 [00:14<01:54,  1.63s/it][A
 14%|█▍        | 11/80 [00:16<01:55,  1.67s/it][A
 15%|█▌        | 12/80 [00:17<01:51,  1.64s/it][A
 16%|█▋        | 13/80 [00:19<01:48,  1.62s/it][A
 18%|█▊        | 14/80 [00:21<01:48,  1.65s/it][A
 19%|█▉        | 15/80 [00:22<01:47,  1.66s/it][A
 20%|██        | 16/80 [00:24<01:44,  1.63s/it][A
 21%|██▏       | 17/80 [00:26<01:42,  1.62s/it][A
 22%|██▎       | 18/80 [00:27<01:42,  1.65s/it][A
 24%|██▍       | 19/80 [00:28<01:30,  1.49s/it][A
 25%|██▌       | 20/80 [00:30<01:25,  1.42s/it][A
 26%|██▋       | 21/80 [00:30<01:08,  1.16s/it][A
 28%|██▊       | 22/80 [00:32<01:08,  1.19s/it][A
 29%|██▉       | 23/80 [00:33<01:08,  1.20s/it][A
 30%|███       | 24/80 [00:33<00:54,  1.02it/s][A
 31%|███▏      | 25/80 [00:34<00:57,  1.04s/it][A
 32%|███▎      | 26/80 [00:36<00:59,  1.11s/it][A
 34%|███▍      | 27/80 [00:36<00:52,  1.02it/s][A
 35%|███▌      | 28/80 [00:37<00:51,  1.01it/s][A
 36%|███▋      | 29/80 [00:39<00:55,  1.09s/it][A
 38%|███▊      | 30/80 [00:40<00:55,  1.10s/it][A
 39%|███▉      | 31/80 [00:41<00:53,  1.10s/it][A
 40%|████      | 32/80 [00:42<00:45,  1.05it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.16s/it][A
 42%|████▎     | 34/80 [00:45<00:57,  1.24s/it][A
 44%|████▍     | 35/80 [00:45<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:46<00:41,  1.06it/s][A
 46%|████▋     | 37/80 [00:47<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.23it/s][A
 49%|████▉     | 39/80 [00:49<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:48,  1.22s/it][A
 51%|█████▏    | 41/80 [00:51<00:40,  1.03s/it][A
 52%|█████▎    | 42/80 [00:53<00:45,  1.19s/it][A
 54%|█████▍    | 43/80 [00:54<00:46,  1.26s/it][A
 55%|█████▌    | 44/80 [00:55<00:44,  1.25s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:57<00:31,  1.07it/s][A
 59%|█████▉    | 47/80 [00:58<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:38,  1.19s/it][A
 61%|██████▏   | 49/80 [01:00<00:31,  1.01s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.18it/s][A
 64%|██████▍   | 51/80 [01:02<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:04<00:26,  1.02it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:08<00:28,  1.18s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:10<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.23s/it][A
 75%|███████▌  | 60/80 [01:12<00:20,  1.04s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.18s/it][A
 78%|███████▊  | 62/80 [01:15<00:24,  1.34s/it][A
 79%|███████▉  | 63/80 [01:16<00:21,  1.26s/it][A
 80%|████████  | 64/80 [01:17<00:18,  1.17s/it][A
 81%|████████▏ | 65/80 [01:19<00:19,  1.29s/it][A
 82%|████████▎ | 66/80 [01:20<00:19,  1.37s/it][A
 84%|████████▍ | 67/80 [01:22<00:19,  1.46s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.49s/it][A
 86%|████████▋ | 69/80 [01:25<00:15,  1.39s/it][A
 88%|████████▊ | 70/80 [01:26<00:13,  1.35s/it][A
 89%|████████▉ | 71/80 [01:27<00:12,  1.34s/it][A
 90%|█████████ | 72/80 [01:29<00:11,  1.41s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.21s/it][A
 92%|█████████▎| 74/80 [01:31<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:32<00:06,  1.30s/it][A
 95%|█████████▌| 76/80 [01:34<00:05,  1.38s/it][A
 96%|█████████▋| 77/80 [01:36<00:04,  1.49s/it][A
 98%|█████████▊| 78/80 [01:36<00:02,  1.21s/it][A
 99%|█████████▉| 79/80 [01:38<00:01,  1.32s/it][A
100%|██████████| 80/80 [01:39<00:00,  1.41s/it][A                                                     
                                               [A{'eval_loss': 0.5930575132369995, 'eval_runtime': 101.7007, 'eval_samples_per_second': 9.371, 'eval_steps_per_second': 0.787, 'eval_rewards/chosen': -0.778216540813446, 'eval_rewards/rejected': -3.409472703933716, 'eval_rewards/accuracies': 0.7733333706855774, 'eval_rewards/margins': 2.6306564807891846, 'eval_logps/chosen': -366.5843811035156, 'eval_logps/rejected': -188.5812530517578, 'eval_logits/chosen': -7.972265720367432, 'eval_logits/rejected': -7.988671779632568, 'epoch': 3.0}
100%|█████████▉| 1672/1674 [1:39:13<00:05,  2.98s/it]
100%|██████████| 80/80 [01:40<00:00,  1.41s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 1673/1674 [1:39:28<00:37, 37.10s/it]100%|██████████| 1674/1674 [1:39:31<00:00, 27.07s/it]                                                     {'train_runtime': 5998.1315, 'train_samples_per_second': 3.346, 'train_steps_per_second': 0.279, 'train_loss': 0.43022906466909067, 'epoch': 3.0}
100%|██████████| 1674/1674 [1:39:52<00:00, 27.07s/it]100%|██████████| 1674/1674 [1:39:52<00:00,  3.58s/it]
Training complete
Saving model
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mCurriculum-1-DPO_r-64_lr-4e-07_e-3_b-0.1[0m at: [34mhttps://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/fn0pla4p[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250612_183107-fn0pla4p/logs[0m
[rank0]:[W612 20:11:52.305415201 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 0 ---
