cpu-bind=MASK - gn16, task  0  0 [3669213]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 4
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn16
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 4     --machine_rank 0     --main_process_ip gn16     --main_process_port 29500     --num_processes 16     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_63026307     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=1e-6 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-06-11 19:02:46,325] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0611 19:02:48.195000 3669285 torch/distributed/run.py:792] 
W0611 19:02:48.195000 3669285 torch/distributed/run.py:792] *****************************************
W0611 19:02:48.195000 3669285 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0611 19:02:48.195000 3669285 torch/distributed/run.py:792] *****************************************
[2025-06-11 19:02:53,897] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-11 19:02:53,917] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-11 19:02:53,944] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-11 19:02:53,962] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[load_data.py]: Training data of type 'bad_lang_examples':    5343
[load_data.py]: Training data of type 'short_examples':       699
[load_data.py]: Training data of type 'choose_examples':      13379
[load_data.py]: Training data of type 'bad_format_examples':  4806
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.2)
1e-06
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.2)
1e-06
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.2)
1e-06
[load_data.py]: Number of training examples: 24227
[load_data.py]: Number of validation examples: 953
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.2)
1e-06
World size: 16
Setting gradient accumulation steps to: 1
[2025-06-11 19:02:59,093] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-11 19:02:59,099] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-11 19:02:59,106] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Train dataset size: 24227
Validation dataset size: 953
Steps per epoch: 1514
Evaluate each 504 steps
[2025-06-11 19:02:59,110] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-11 19:02:59,110] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.46s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:20, 26.89s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:20, 26.89s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:20, 26.89s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:51, 25.51s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:51, 25.78s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:51, 25.70s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:51, 25.70s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:20<00:27, 27.10s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:20<00:27, 27.31s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:20<00:27, 27.27s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:20<00:27, 27.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:33<00:00, 21.70s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:33<00:00, 23.50s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:34<00:00, 21.75s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:34<00:00, 21.72s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:34<00:00, 21.76s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:34<00:00, 23.53s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:34<00:00, 23.53s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:34<00:00, 23.53s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
[rank3]:[W611 19:04:38.020902067 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 530/24227 [00:00<00:04, 5246.18 examples/s]Extracting prompt in train dataset:   4%|▍         | 1090/24227 [00:00<00:04, 5424.09 examples/s]Extracting prompt in train dataset:   7%|▋         | 1634/24227 [00:00<00:04, 5428.76 examples/s]Extracting prompt in train dataset:   9%|▉         | 2200/24227 [00:00<00:04, 5505.24 examples/s]Extracting prompt in train dataset:  11%|█▏        | 2766/24227 [00:00<00:03, 5559.30 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3580/24227 [00:00<00:03, 5472.00 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4150/24227 [00:00<00:03, 5524.79 examples/s]Extracting prompt in train dataset:  19%|█▉        | 4720/24227 [00:00<00:03, 5562.98 examples/s][rank1]:[W611 19:04:39.990035530 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W611 19:04:39.022652285 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:  22%|██▏       | 5290/24227 [00:00<00:03, 5586.94 examples/s]Extracting prompt in train dataset:  25%|██▌       | 6110/24227 [00:01<00:03, 5415.12 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6690/24227 [00:01<00:03, 5502.82 examples/s]Extracting prompt in train dataset:  30%|███       | 7270/24227 [00:01<00:03, 5568.39 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7853/24227 [00:01<00:02, 5627.63 examples/s]Extracting prompt in train dataset:  35%|███▍      | 8430/24227 [00:01<00:02, 5664.19 examples/s]Extracting prompt in train dataset:  37%|███▋      | 9020/24227 [00:01<00:02, 5730.77 examples/s]Extracting prompt in train dataset:  40%|███▉      | 9610/24227 [00:01<00:02, 5772.12 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10200/24227 [00:01<00:02, 5800.51 examples/s]Extracting prompt in train dataset:  46%|████▌     | 11070/24227 [00:01<00:02, 5775.15 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11650/24227 [00:02<00:02, 5757.64 examples/s]Extracting prompt in train dataset:  51%|█████     | 12240/24227 [00:02<00:02, 5779.65 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12830/24227 [00:02<00:01, 5806.59 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 13420/24227 [00:02<00:01, 5820.90 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 14020/24227 [00:02<00:01, 5841.37 examples/s]Extracting prompt in train dataset:  60%|██████    | 14615/24227 [00:02<00:01, 5854.78 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 15376/24227 [00:02<00:01, 5453.14 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 15951/24227 [00:02<00:01, 5531.15 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 16530/24227 [00:02<00:01, 5584.79 examples/s]Extracting prompt in train dataset:  71%|███████   | 17128/24227 [00:03<00:01, 5680.45 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17717/24227 [00:03<00:01, 5734.92 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 18310/24227 [00:03<00:01, 5769.61 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 18900/24227 [00:03<00:00, 5805.50 examples/s]Extracting prompt in train dataset:  80%|████████  | 19500/24227 [00:03<00:00, 5832.16 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 20103/24227 [00:03<00:00, 5888.11 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 20702/24227 [00:03<00:00, 5916.36 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21590/24227 [00:03<00:00, 5912.39 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22191/24227 [00:03<00:00, 5934.97 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 22791/24227 [00:03<00:00, 5951.65 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 23391/24227 [00:04<00:00, 5962.92 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 23992/24227 [00:04<00:00, 5971.57 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:04<00:00, 5675.99 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 281/24227 [00:00<00:08, 2778.64 examples/s]Applying chat template to train dataset:   2%|▏         | 587/24227 [00:00<00:08, 2940.63 examples/s]Applying chat template to train dataset:   4%|▎         | 890/24227 [00:00<00:07, 2972.59 examples/s]Applying chat template to train dataset:   5%|▍         | 1198/24227 [00:00<00:07, 3009.79 examples/s]Applying chat template to train dataset:   6%|▌         | 1501/24227 [00:00<00:07, 3014.26 examples/s]Applying chat template to train dataset:   7%|▋         | 1811/24227 [00:00<00:07, 3041.91 examples/s]Applying chat template to train dataset:   9%|▉         | 2120/24227 [00:00<00:07, 3053.02 examples/s]Applying chat template to train dataset:  10%|█         | 2430/24227 [00:00<00:07, 3063.85 examples/s]Applying chat template to train dataset:  11%|█▏        | 2739/24227 [00:00<00:06, 3070.99 examples/s]Applying chat template to train dataset:  13%|█▎        | 3183/24227 [00:01<00:06, 3021.20 examples/s]Applying chat template to train dataset:  14%|█▍        | 3490/24227 [00:01<00:06, 3030.66 examples/s]Applying chat template to train dataset:  16%|█▌        | 3800/24227 [00:01<00:06, 3047.79 examples/s]Applying chat template to train dataset:  17%|█▋        | 4110/24227 [00:01<00:06, 3056.77 examples/s]Applying chat template to train dataset:  18%|█▊        | 4420/24227 [00:01<00:06, 3063.68 examples/s]Applying chat template to train dataset:  20%|█▉        | 4730/24227 [00:01<00:06, 3067.14 examples/s]Applying chat template to train dataset:  21%|██        | 5039/24227 [00:01<00:06, 3071.21 examples/s]Applying chat template to train dataset:  23%|██▎       | 5500/24227 [00:01<00:06, 3068.62 examples/s]Applying chat template to train dataset:  24%|██▍       | 5923/24227 [00:01<00:06, 2976.47 examples/s]Applying chat template to train dataset:  26%|██▌       | 6234/24227 [00:02<00:06, 2598.17 examples/s]Applying chat template to train dataset:  27%|██▋       | 6543/24227 [00:02<00:06, 2714.18 examples/s]Applying chat template to train dataset:  28%|██▊       | 6854/24227 [00:02<00:06, 2812.36 examples/s]Applying chat template to train dataset:  30%|██▉       | 7165/24227 [00:02<00:05, 2886.22 examples/s]Applying chat template to train dataset:  31%|███       | 7476/24227 [00:02<00:05, 2944.71 examples/s]Applying chat template to train dataset:  32%|███▏      | 7790/24227 [00:02<00:05, 2996.17 examples/s]Applying chat template to train dataset:  33%|███▎      | 8110/24227 [00:02<00:05, 3048.07 examples/s]Applying chat template to train dataset:  35%|███▍      | 8430/24227 [00:02<00:05, 3084.14 examples/s]Applying chat template to train dataset:  36%|███▌      | 8750/24227 [00:02<00:04, 3110.02 examples/s]Applying chat template to train dataset:  37%|███▋      | 9070/24227 [00:03<00:04, 3130.95 examples/s]Applying chat template to train dataset:  39%|███▉      | 9388/24227 [00:03<00:04, 3144.59 examples/s]Applying chat template to train dataset:  40%|████      | 9706/24227 [00:03<00:04, 3153.28 examples/s]Applying chat template to train dataset:  41%|████▏     | 10024/24227 [00:03<00:04, 3159.90 examples/s]Applying chat template to train dataset:  43%|████▎     | 10486/24227 [00:03<00:04, 3126.50 examples/s]Applying chat template to train dataset:  45%|████▌     | 10950/24227 [00:03<00:04, 3109.27 examples/s]Applying chat template to train dataset:  47%|████▋     | 11415/24227 [00:03<00:04, 3102.60 examples/s]Applying chat template to train dataset:  49%|████▉     | 11880/24227 [00:03<00:03, 3096.08 examples/s]Applying chat template to train dataset:  50%|█████     | 12197/24227 [00:04<00:03, 3112.59 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12513/24227 [00:04<00:03, 3122.72 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12830/24227 [00:04<00:03, 3128.97 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13147/24227 [00:04<00:03, 3135.79 examples/s]Applying chat template to train dataset:  56%|█████▌    | 13620/24227 [00:04<00:03, 3135.13 examples/s]Applying chat template to train dataset:  58%|█████▊    | 13940/24227 [00:04<00:03, 3143.79 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14258/24227 [00:04<00:03, 3149.48 examples/s]Applying chat template to train dataset:  61%|██████    | 14731/24227 [00:04<00:03, 3148.09 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15120/24227 [00:04<00:03, 2956.43 examples/s]Applying chat template to train dataset:  64%|██████▎   | 15430/24227 [00:05<00:02, 2988.12 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15741/24227 [00:05<00:02, 3016.42 examples/s]Applying chat template to train dataset:  66%|██████▌   | 16050/24227 [00:05<00:02, 3034.57 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16360/24227 [00:05<00:02, 3050.82 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16675/24227 [00:05<00:02, 3075.94 examples/s]Applying chat template to train dataset:  70%|███████   | 16993/24227 [00:05<00:02, 3103.47 examples/s]Applying chat template to train dataset:  71%|███████▏  | 17310/24227 [00:05<00:02, 3121.49 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17627/24227 [00:05<00:02, 3131.67 examples/s]Applying chat template to train dataset:  74%|███████▍  | 17942/24227 [00:05<00:02, 3135.56 examples/s]Applying chat template to train dataset:  75%|███████▌  | 18260/24227 [00:05<00:01, 3145.12 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18578/24227 [00:06<00:01, 3154.56 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18895/24227 [00:06<00:01, 3157.55 examples/s]Applying chat template to train dataset:  79%|███████▉  | 19212/24227 [00:06<00:01, 3158.63 examples/s]Applying chat template to train dataset:  81%|████████  | 19530/24227 [00:06<00:01, 3161.56 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19851/24227 [00:06<00:01, 3172.58 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20174/24227 [00:06<00:01, 3187.67 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20495/24227 [00:06<00:01, 3191.18 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20816/24227 [00:06<00:01, 3195.23 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21138/24227 [00:06<00:00, 3198.93 examples/s]Applying chat template to train dataset:  89%|████████▊ | 21460/24227 [00:06<00:00, 3199.33 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21781/24227 [00:07<00:00, 3198.05 examples/s]Applying chat template to train dataset:  91%|█████████ | 22103/24227 [00:07<00:00, 2765.02 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22425/24227 [00:07<00:00, 2885.07 examples/s]Applying chat template to train dataset:  94%|█████████▍| 22746/24227 [00:07<00:00, 2973.01 examples/s]Applying chat template to train dataset:  95%|█████████▌| 23068/24227 [00:07<00:00, 3040.59 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23389/24227 [00:07<00:00, 3086.64 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23711/24227 [00:07<00:00, 3119.04 examples/s]Applying chat template to train dataset:  99%|█████████▉| 24032/24227 [00:07<00:00, 3142.54 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:07<00:00, 3058.06 examples/s]
Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/24227 [00:00<01:01, 390.23 examples/s]Tokenizing train dataset:   0%|          | 88/24227 [00:00<01:12, 333.73 examples/s]Tokenizing train dataset:   1%|          | 130/24227 [00:00<01:19, 304.72 examples/s]Tokenizing train dataset:   1%|          | 163/24227 [00:00<01:17, 308.52 examples/s]Tokenizing train dataset:   1%|          | 207/24227 [00:00<01:20, 298.89 examples/s]Tokenizing train dataset:   1%|          | 243/24227 [00:00<01:16, 313.20 examples/s]Tokenizing train dataset:   1%|          | 277/24227 [00:00<01:15, 318.45 examples/s]Tokenizing train dataset:   1%|▏         | 325/24227 [00:01<01:15, 316.40 examples/s]Tokenizing train dataset:   2%|▏         | 370/24227 [00:01<01:17, 306.66 examples/s]Tokenizing train dataset:   2%|▏         | 402/24227 [00:01<01:18, 303.72 examples/s]Tokenizing train dataset:   2%|▏         | 434/24227 [00:01<01:17, 306.12 examples/s]Tokenizing train dataset:   2%|▏         | 480/24227 [00:01<01:19, 298.10 examples/s]Tokenizing train dataset:   2%|▏         | 527/24227 [00:01<01:19, 297.12 examples/s]Tokenizing train dataset:   2%|▏         | 560/24227 [00:01<01:18, 302.21 examples/s]Tokenizing train dataset:   2%|▏         | 603/24227 [00:01<01:20, 293.07 examples/s]Tokenizing train dataset:   3%|▎         | 640/24227 [00:02<01:16, 309.63 examples/s]Tokenizing train dataset:   3%|▎         | 686/24227 [00:02<01:17, 302.65 examples/s]Tokenizing train dataset:   3%|▎         | 732/24227 [00:02<01:17, 302.47 examples/s]Tokenizing train dataset:   3%|▎         | 763/24227 [00:02<01:17, 301.61 examples/s]Tokenizing train dataset:   3%|▎         | 805/24227 [00:02<01:20, 289.35 examples/s]Tokenizing train dataset:   4%|▎         | 850/24227 [00:02<01:22, 282.65 examples/s]Tokenizing train dataset:   4%|▎         | 880/24227 [00:02<01:21, 285.88 examples/s]Tokenizing train dataset:   4%|▍         | 917/24227 [00:03<01:17, 301.92 examples/s]Tokenizing train dataset:   4%|▍         | 948/24227 [00:03<01:18, 297.10 examples/s]Tokenizing train dataset:   4%|▍         | 990/24227 [00:03<01:20, 287.54 examples/s]Tokenizing train dataset:   4%|▍         | 1030/24227 [00:03<01:23, 277.42 examples/s]Tokenizing train dataset:   4%|▍         | 1061/24227 [00:03<01:21, 283.68 examples/s]Tokenizing train dataset:   5%|▍         | 1095/24227 [00:03<01:17, 296.82 examples/s]Tokenizing train dataset:   5%|▍         | 1136/24227 [00:03<01:21, 282.46 examples/s]Tokenizing train dataset:   5%|▍         | 1170/24227 [00:03<01:29, 256.99 examples/s]Tokenizing train dataset:   5%|▍         | 1207/24227 [00:04<01:23, 277.17 examples/s]Tokenizing train dataset:   5%|▌         | 1240/24227 [00:04<01:19, 288.38 examples/s]Tokenizing train dataset:   5%|▌         | 1273/24227 [00:04<01:18, 293.41 examples/s]Tokenizing train dataset:   5%|▌         | 1306/24227 [00:04<01:16, 299.91 examples/s]Tokenizing train dataset:   6%|▌         | 1337/24227 [00:04<01:15, 301.42 examples/s]Tokenizing train dataset:   6%|▌         | 1376/24227 [00:04<01:20, 283.02 examples/s]Tokenizing train dataset:   6%|▌         | 1407/24227 [00:04<01:19, 288.78 examples/s]Tokenizing train dataset:   6%|▌         | 1452/24227 [00:04<01:19, 287.36 examples/s]Tokenizing train dataset:   6%|▌         | 1495/24227 [00:05<01:20, 282.28 examples/s]Tokenizing train dataset:   6%|▋         | 1526/24227 [00:05<01:19, 285.64 examples/s]Tokenizing train dataset:   6%|▋         | 1557/24227 [00:05<01:18, 287.79 examples/s]Tokenizing train dataset:   7%|▋         | 1600/24227 [00:05<01:19, 284.97 examples/s]Tokenizing train dataset:   7%|▋         | 1634/24227 [00:05<01:16, 296.20 examples/s]Tokenizing train dataset:   7%|▋         | 1668/24227 [00:05<01:13, 306.02 examples/s]Tokenizing train dataset:   7%|▋         | 1703/24227 [00:05<01:11, 316.00 examples/s]Tokenizing train dataset:   7%|▋         | 1738/24227 [00:05<01:09, 323.06 examples/s]Tokenizing train dataset:   7%|▋         | 1771/24227 [00:05<01:10, 320.20 examples/s]Tokenizing train dataset:   8%|▊         | 1818/24227 [00:06<01:11, 311.43 examples/s]Tokenizing train dataset:   8%|▊         | 1861/24227 [00:06<01:15, 297.38 examples/s]Tokenizing train dataset:   8%|▊         | 1900/24227 [00:06<01:19, 280.06 examples/s]Tokenizing train dataset:   8%|▊         | 1937/24227 [00:06<01:23, 268.27 examples/s]Tokenizing train dataset:   8%|▊         | 1980/24227 [00:06<01:21, 272.70 examples/s]Tokenizing train dataset:   8%|▊         | 2011/24227 [00:06<01:19, 279.84 examples/s]Tokenizing train dataset:   8%|▊         | 2043/24227 [00:06<01:17, 287.01 examples/s]Tokenizing train dataset:   9%|▊         | 2079/24227 [00:07<01:12, 304.30 examples/s]Tokenizing train dataset:   9%|▊         | 2111/24227 [00:07<01:12, 306.01 examples/s]Tokenizing train dataset:   9%|▉         | 2143/24227 [00:07<01:12, 306.42 examples/s]Tokenizing train dataset:   9%|▉         | 2188/24227 [00:07<01:14, 297.49 examples/s]Tokenizing train dataset:   9%|▉         | 2234/24227 [00:07<01:14, 296.94 examples/s]Tokenizing train dataset:   9%|▉         | 2267/24227 [00:07<01:12, 302.18 examples/s]Tokenizing train dataset:   9%|▉         | 2298/24227 [00:07<01:13, 298.18 examples/s]Tokenizing train dataset:  10%|▉         | 2339/24227 [00:07<01:16, 286.12 examples/s]Tokenizing train dataset:  10%|▉         | 2369/24227 [00:08<01:15, 288.11 examples/s]Tokenizing train dataset:  10%|▉         | 2413/24227 [00:08<01:16, 284.87 examples/s]Tokenizing train dataset:  10%|█         | 2444/24227 [00:08<01:15, 288.70 examples/s]Tokenizing train dataset:  10%|█         | 2490/24227 [00:08<01:14, 291.85 examples/s]Tokenizing train dataset:  10%|█         | 2524/24227 [00:08<01:21, 264.81 examples/s]Tokenizing train dataset:  11%|█         | 2556/24227 [00:08<01:18, 275.80 examples/s]Tokenizing train dataset:  11%|█         | 2591/24227 [00:08<01:14, 289.12 examples/s]Tokenizing train dataset:  11%|█         | 2624/24227 [00:08<01:12, 298.43 examples/s]Tokenizing train dataset:  11%|█         | 2661/24227 [00:09<01:18, 276.39 examples/s]Tokenizing train dataset:  11%|█         | 2695/24227 [00:09<01:14, 288.08 examples/s]Tokenizing train dataset:  11%|█▏        | 2727/24227 [00:09<01:13, 292.13 examples/s]Tokenizing train dataset:  11%|█▏        | 2769/24227 [00:09<01:15, 285.52 examples/s]Tokenizing train dataset:  12%|█▏        | 2800/24227 [00:09<01:13, 291.48 examples/s]Tokenizing train dataset:  12%|█▏        | 2830/24227 [00:09<01:14, 288.32 examples/s]Tokenizing train dataset:  12%|█▏        | 2860/24227 [00:09<01:14, 287.33 examples/s]Tokenizing train dataset:  12%|█▏        | 2889/24227 [00:09<01:14, 286.65 examples/s]Tokenizing train dataset:  12%|█▏        | 2919/24227 [00:09<01:14, 286.70 examples/s]Tokenizing train dataset:  12%|█▏        | 2951/24227 [00:10<01:12, 294.44 examples/s]Tokenizing train dataset:  12%|█▏        | 2982/24227 [00:10<01:12, 294.52 examples/s]Tokenizing train dataset:  12%|█▏        | 3013/24227 [00:10<01:11, 296.14 examples/s]Tokenizing train dataset:  13%|█▎        | 3056/24227 [00:10<01:13, 286.15 examples/s]Tokenizing train dataset:  13%|█▎        | 3086/24227 [00:10<01:14, 285.26 examples/s]Tokenizing train dataset:  13%|█▎        | 3119/24227 [00:10<01:12, 290.10 examples/s]Tokenizing train dataset:  13%|█▎        | 3158/24227 [00:10<01:16, 277.08 examples/s]Tokenizing train dataset:  13%|█▎        | 3192/24227 [00:10<01:11, 292.22 examples/s]Tokenizing train dataset:  13%|█▎        | 3238/24227 [00:11<01:12, 289.74 examples/s]Tokenizing train dataset:  13%|█▎        | 3270/24227 [00:11<01:10, 295.63 examples/s]Tokenizing train dataset:  14%|█▎        | 3300/24227 [00:11<01:10, 294.84 examples/s]Tokenizing train dataset:  14%|█▍        | 3344/24227 [00:11<01:11, 292.55 examples/s]Tokenizing train dataset:  14%|█▍        | 3384/24227 [00:11<01:14, 280.42 examples/s]Tokenizing train dataset:  14%|█▍        | 3424/24227 [00:11<01:16, 272.81 examples/s]Tokenizing train dataset:  14%|█▍        | 3460/24227 [00:11<01:20, 258.22 examples/s]Tokenizing train dataset:  14%|█▍        | 3502/24227 [00:12<01:19, 260.90 examples/s]Tokenizing train dataset:  15%|█▍        | 3539/24227 [00:12<01:13, 281.67 examples/s]Tokenizing train dataset:  15%|█▍        | 3577/24227 [00:12<01:08, 301.85 examples/s]Tokenizing train dataset:  15%|█▍        | 3623/24227 [00:12<01:08, 298.66 examples/s]Tokenizing train dataset:  15%|█▌        | 3655/24227 [00:12<01:08, 301.26 examples/s]Tokenizing train dataset:  15%|█▌        | 3686/24227 [00:12<01:07, 302.24 examples/s]Tokenizing train dataset:  15%|█▌        | 3727/24227 [00:12<01:10, 290.37 examples/s]Tokenizing train dataset:  16%|█▌        | 3760/24227 [00:12<01:08, 296.90 examples/s]Tokenizing train dataset:  16%|█▌        | 3791/24227 [00:12<01:08, 297.13 examples/s]Tokenizing train dataset:  16%|█▌        | 3828/24227 [00:13<01:04, 314.26 examples/s]Tokenizing train dataset:  16%|█▌        | 3874/24227 [00:13<01:06, 308.14 examples/s]Tokenizing train dataset:  16%|█▌        | 3916/24227 [00:13<01:08, 295.71 examples/s]Tokenizing train dataset:  16%|█▋        | 3959/24227 [00:13<01:09, 289.84 examples/s]Tokenizing train dataset:  17%|█▋        | 4003/24227 [00:13<01:09, 289.48 examples/s]Tokenizing train dataset:  17%|█▋        | 4033/24227 [00:13<01:09, 288.67 examples/s]Tokenizing train dataset:  17%|█▋        | 4063/24227 [00:13<01:10, 287.80 examples/s]Tokenizing train dataset:  17%|█▋        | 4097/24227 [00:14<01:07, 298.37 examples/s]Tokenizing train dataset:  17%|█▋        | 4144/24227 [00:14<01:06, 301.48 examples/s]Tokenizing train dataset:  17%|█▋        | 4195/24227 [00:14<01:04, 310.56 examples/s]Tokenizing train dataset:  18%|█▊        | 4241/24227 [00:14<01:05, 304.89 examples/s]Tokenizing train dataset:  18%|█▊        | 4285/24227 [00:14<01:06, 299.36 examples/s]Tokenizing train dataset:  18%|█▊        | 4326/24227 [00:14<01:09, 288.21 examples/s]Tokenizing train dataset:  18%|█▊        | 4358/24227 [00:14<01:07, 293.02 examples/s]Tokenizing train dataset:  18%|█▊        | 4389/24227 [00:14<01:07, 293.33 examples/s]Tokenizing train dataset:  18%|█▊        | 4422/24227 [00:15<01:06, 298.48 examples/s]Tokenizing train dataset:  18%|█▊        | 4454/24227 [00:15<01:05, 301.69 examples/s]Tokenizing train dataset:  19%|█▊        | 4497/24227 [00:15<01:06, 294.83 examples/s]Tokenizing train dataset:  19%|█▊        | 4538/24227 [00:15<01:08, 285.87 examples/s]Tokenizing train dataset:  19%|█▉        | 4568/24227 [00:15<01:08, 288.46 examples/s]Tokenizing train dataset:  19%|█▉        | 4600/24227 [00:15<01:06, 293.15 examples/s]Tokenizing train dataset:  19%|█▉        | 4642/24227 [00:15<01:08, 287.36 examples/s]Tokenizing train dataset:  19%|█▉        | 4672/24227 [00:15<01:07, 287.87 examples/s]Tokenizing train dataset:  19%|█▉        | 4714/24227 [00:16<01:09, 280.94 examples/s]Tokenizing train dataset:  20%|█▉        | 4747/24227 [00:16<01:07, 290.07 examples/s]Tokenizing train dataset:  20%|█▉        | 4790/24227 [00:16<01:08, 284.38 examples/s]Tokenizing train dataset:  20%|█▉        | 4819/24227 [00:16<01:08, 283.72 examples/s]Tokenizing train dataset:  20%|██        | 4860/24227 [00:16<01:10, 273.37 examples/s]Tokenizing train dataset:  20%|██        | 4889/24227 [00:16<01:10, 275.44 examples/s]Tokenizing train dataset:  20%|██        | 4917/24227 [00:16<01:10, 274.68 examples/s]Tokenizing train dataset:  20%|██        | 4949/24227 [00:16<01:07, 285.23 examples/s]Tokenizing train dataset:  21%|██        | 4990/24227 [00:17<01:10, 274.24 examples/s]Tokenizing train dataset:  21%|██        | 5022/24227 [00:17<01:07, 282.86 examples/s]Tokenizing train dataset:  21%|██        | 5057/24227 [00:17<01:05, 293.52 examples/s]Tokenizing train dataset:  21%|██        | 5100/24227 [00:17<01:07, 283.73 examples/s]Tokenizing train dataset:  21%|██        | 5131/24227 [00:17<01:06, 286.48 examples/s]Tokenizing train dataset:  21%|██▏       | 5175/24227 [00:17<01:08, 278.84 examples/s]Tokenizing train dataset:  21%|██▏       | 5204/24227 [00:17<01:07, 281.47 examples/s]Tokenizing train dataset:  22%|██▏       | 5237/24227 [00:17<01:05, 288.53 examples/s]Tokenizing train dataset:  22%|██▏       | 5277/24227 [00:18<01:08, 275.86 examples/s]Tokenizing train dataset:  22%|██▏       | 5313/24227 [00:18<01:12, 262.47 examples/s]Tokenizing train dataset:  22%|██▏       | 5359/24227 [00:18<01:08, 275.03 examples/s]Tokenizing train dataset:  22%|██▏       | 5395/24227 [00:18<01:04, 292.15 examples/s]Tokenizing train dataset:  22%|██▏       | 5428/24227 [00:18<01:02, 298.83 examples/s]Tokenizing train dataset:  23%|██▎       | 5459/24227 [00:18<01:02, 299.24 examples/s]Tokenizing train dataset:  23%|██▎       | 5490/24227 [00:18<01:03, 296.64 examples/s]Tokenizing train dataset:  23%|██▎       | 5522/24227 [00:18<01:02, 300.86 examples/s]Tokenizing train dataset:  23%|██▎       | 5564/24227 [00:19<01:04, 289.06 examples/s]Tokenizing train dataset:  23%|██▎       | 5607/24227 [00:19<00:57, 324.38 examples/s]Tokenizing train dataset:  23%|██▎       | 5655/24227 [00:19<00:58, 319.81 examples/s]Tokenizing train dataset:  23%|██▎       | 5693/24227 [00:19<00:56, 328.34 examples/s]Tokenizing train dataset:  24%|██▎       | 5740/24227 [00:19<00:58, 316.82 examples/s]Tokenizing train dataset:  24%|██▍       | 5779/24227 [00:19<01:02, 294.79 examples/s]Tokenizing train dataset:  24%|██▍       | 5828/24227 [00:19<01:00, 302.76 examples/s]Tokenizing train dataset:  24%|██▍       | 5867/24227 [00:20<00:57, 319.48 examples/s]Tokenizing train dataset:  24%|██▍       | 5910/24227 [00:20<01:00, 301.83 examples/s]Tokenizing train dataset:  25%|██▍       | 5944/24227 [00:20<00:59, 306.26 examples/s]Tokenizing train dataset:  25%|██▍       | 5990/24227 [00:20<01:01, 294.20 examples/s]Tokenizing train dataset:  25%|██▍       | 6035/24227 [00:20<01:02, 291.38 examples/s]Tokenizing train dataset:  25%|██▌       | 6071/24227 [00:20<00:59, 303.55 examples/s]Tokenizing train dataset:  25%|██▌       | 6105/24227 [00:20<00:58, 311.74 examples/s]Tokenizing train dataset:  25%|██▌       | 6144/24227 [00:20<00:54, 329.79 examples/s]Tokenizing train dataset:  26%|██▌       | 6179/24227 [00:21<00:54, 329.39 examples/s]Tokenizing train dataset:  26%|██▌       | 6214/24227 [00:21<00:54, 330.43 examples/s]Tokenizing train dataset:  26%|██▌       | 6250/24227 [00:21<00:54, 331.68 examples/s]Tokenizing train dataset:  26%|██▌       | 6291/24227 [00:21<00:51, 348.43 examples/s]Tokenizing train dataset:  26%|██▌       | 6328/24227 [00:21<00:51, 349.71 examples/s]Tokenizing train dataset:  26%|██▋       | 6369/24227 [00:21<00:49, 359.63 examples/s]Tokenizing train dataset:  27%|██▋       | 6422/24227 [00:21<00:50, 352.23 examples/s]Tokenizing train dataset:  27%|██▋       | 6460/24227 [00:21<00:49, 358.55 examples/s]Tokenizing train dataset:  27%|██▋       | 6512/24227 [00:21<00:50, 353.04 examples/s]Tokenizing train dataset:  27%|██▋       | 6565/24227 [00:22<00:50, 350.90 examples/s]Tokenizing train dataset:  27%|██▋       | 6620/24227 [00:22<00:50, 351.35 examples/s]Tokenizing train dataset:  27%|██▋       | 6661/24227 [00:22<00:48, 361.92 examples/s]Tokenizing train dataset:  28%|██▊       | 6713/24227 [00:22<00:49, 354.36 examples/s]Tokenizing train dataset:  28%|██▊       | 6749/24227 [00:22<00:49, 352.31 examples/s]Tokenizing train dataset:  28%|██▊       | 6802/24227 [00:22<00:49, 349.19 examples/s]Tokenizing train dataset:  28%|██▊       | 6838/24227 [00:22<00:49, 347.95 examples/s]Tokenizing train dataset:  28%|██▊       | 6875/24227 [00:23<00:49, 351.41 examples/s]Tokenizing train dataset:  29%|██▊       | 6917/24227 [00:23<00:47, 367.46 examples/s]Tokenizing train dataset:  29%|██▊       | 6958/24227 [00:23<00:45, 375.85 examples/s]Tokenizing train dataset:  29%|██▉       | 7011/24227 [00:23<00:47, 364.93 examples/s]Tokenizing train dataset:  29%|██▉       | 7060/24227 [00:23<00:49, 349.77 examples/s]Tokenizing train dataset:  29%|██▉       | 7100/24227 [00:23<00:47, 358.61 examples/s]Tokenizing train dataset:  30%|██▉       | 7152/24227 [00:23<00:48, 349.80 examples/s]Tokenizing train dataset:  30%|██▉       | 7207/24227 [00:23<00:48, 351.68 examples/s]Tokenizing train dataset:  30%|██▉       | 7244/24227 [00:24<00:48, 352.28 examples/s]Tokenizing train dataset:  30%|███       | 7281/24227 [00:24<00:48, 351.48 examples/s]Tokenizing train dataset:  30%|███       | 7332/24227 [00:24<00:48, 346.53 examples/s]Tokenizing train dataset:  30%|███       | 7367/24227 [00:24<00:48, 347.13 examples/s]Tokenizing train dataset:  31%|███       | 7405/24227 [00:24<00:48, 350.06 examples/s]Tokenizing train dataset:  31%|███       | 7460/24227 [00:24<00:47, 349.76 examples/s]Tokenizing train dataset:  31%|███       | 7498/24227 [00:24<00:47, 354.09 examples/s]Tokenizing train dataset:  31%|███       | 7536/24227 [00:24<00:46, 356.86 examples/s]Tokenizing train dataset:  31%|███▏      | 7583/24227 [00:25<00:49, 338.05 examples/s]Tokenizing train dataset:  32%|███▏      | 7634/24227 [00:25<00:49, 333.30 examples/s]Tokenizing train dataset:  32%|███▏      | 7699/24227 [00:25<00:45, 362.07 examples/s]Tokenizing train dataset:  32%|███▏      | 7766/24227 [00:25<00:38, 430.96 examples/s]Tokenizing train dataset:  32%|███▏      | 7831/24227 [00:25<00:33, 484.48 examples/s]Tokenizing train dataset:  33%|███▎      | 7901/24227 [00:25<00:30, 539.48 examples/s]Tokenizing train dataset:  33%|███▎      | 7978/24227 [00:25<00:27, 599.18 examples/s]Tokenizing train dataset:  33%|███▎      | 8041/24227 [00:25<00:26, 603.97 examples/s]Tokenizing train dataset:  33%|███▎      | 8110/24227 [00:25<00:25, 621.87 examples/s]Tokenizing train dataset:  34%|███▍      | 8206/24227 [00:26<00:25, 626.93 examples/s]Tokenizing train dataset:  34%|███▍      | 8284/24227 [00:26<00:24, 664.14 examples/s]Tokenizing train dataset:  35%|███▍      | 8360/24227 [00:26<00:23, 685.27 examples/s]Tokenizing train dataset:  35%|███▍      | 8457/24227 [00:26<00:23, 660.69 examples/s]Tokenizing train dataset:  35%|███▌      | 8528/24227 [00:26<00:23, 667.69 examples/s]Tokenizing train dataset:  36%|███▌      | 8609/24227 [00:26<00:22, 702.96 examples/s]Tokenizing train dataset:  36%|███▌      | 8681/24227 [00:26<00:22, 699.91 examples/s]Tokenizing train dataset:  36%|███▌      | 8757/24227 [00:26<00:21, 714.72 examples/s]Tokenizing train dataset:  37%|███▋      | 8851/24227 [00:27<00:22, 677.16 examples/s]Tokenizing train dataset:  37%|███▋      | 8921/24227 [00:27<00:22, 678.85 examples/s]Tokenizing train dataset:  37%|███▋      | 8996/24227 [00:27<00:21, 693.90 examples/s]Tokenizing train dataset:  37%|███▋      | 9074/24227 [00:27<00:21, 714.96 examples/s]Tokenizing train dataset:  38%|███▊      | 9165/24227 [00:27<00:22, 673.52 examples/s]Tokenizing train dataset:  38%|███▊      | 9237/24227 [00:27<00:22, 679.46 examples/s]Tokenizing train dataset:  38%|███▊      | 9312/24227 [00:27<00:21, 697.29 examples/s]Tokenizing train dataset:  39%|███▉      | 9412/24227 [00:27<00:21, 679.84 examples/s]Tokenizing train dataset:  39%|███▉      | 9484/24227 [00:27<00:21, 689.93 examples/s]Tokenizing train dataset:  40%|███▉      | 9578/24227 [00:28<00:22, 662.72 examples/s]Tokenizing train dataset:  40%|███▉      | 9680/24227 [00:28<00:21, 664.21 examples/s]Tokenizing train dataset:  40%|████      | 9749/24227 [00:28<00:21, 665.12 examples/s]Tokenizing train dataset:  41%|████      | 9842/24227 [00:28<00:22, 644.32 examples/s]Tokenizing train dataset:  41%|████      | 9909/24227 [00:28<00:22, 644.10 examples/s]Tokenizing train dataset:  41%|████      | 9990/24227 [00:28<00:20, 683.69 examples/s]Tokenizing train dataset:  42%|████▏     | 10086/24227 [00:28<00:21, 664.24 examples/s]Tokenizing train dataset:  42%|████▏     | 10158/24227 [00:28<00:20, 675.38 examples/s]Tokenizing train dataset:  42%|████▏     | 10231/24227 [00:29<00:26, 538.21 examples/s]Tokenizing train dataset:  43%|████▎     | 10303/24227 [00:29<00:29, 466.28 examples/s]Tokenizing train dataset:  43%|████▎     | 10361/24227 [00:29<00:31, 438.51 examples/s]Tokenizing train dataset:  43%|████▎     | 10416/24227 [00:29<00:33, 415.26 examples/s]Tokenizing train dataset:  43%|████▎     | 10476/24227 [00:29<00:33, 406.64 examples/s]Tokenizing train dataset:  43%|████▎     | 10529/24227 [00:29<00:35, 385.73 examples/s]Tokenizing train dataset:  44%|████▎     | 10587/24227 [00:30<00:42, 322.01 examples/s]Tokenizing train dataset:  44%|████▍     | 10622/24227 [00:30<00:41, 326.32 examples/s]Tokenizing train dataset:  44%|████▍     | 10657/24227 [00:30<00:41, 329.72 examples/s]Tokenizing train dataset:  44%|████▍     | 10708/24227 [00:30<00:41, 327.01 examples/s]Tokenizing train dataset:  44%|████▍     | 10749/24227 [00:30<00:39, 343.51 examples/s]Tokenizing train dataset:  45%|████▍     | 10803/24227 [00:30<00:39, 342.64 examples/s]Tokenizing train dataset:  45%|████▍     | 10840/24227 [00:30<00:38, 345.27 examples/s]Tokenizing train dataset:  45%|████▍     | 10893/24227 [00:31<00:38, 345.46 examples/s]Tokenizing train dataset:  45%|████▌     | 10944/24227 [00:31<00:39, 340.06 examples/s]Tokenizing train dataset:  45%|████▌     | 10987/24227 [00:31<00:37, 355.35 examples/s]Tokenizing train dataset:  46%|████▌     | 11044/24227 [00:31<00:36, 362.11 examples/s]Tokenizing train dataset:  46%|████▌     | 11082/24227 [00:31<00:35, 365.25 examples/s]Tokenizing train dataset:  46%|████▌     | 11134/24227 [00:31<00:36, 356.63 examples/s]Tokenizing train dataset:  46%|████▌     | 11190/24227 [00:31<00:36, 355.94 examples/s]Tokenizing train dataset:  46%|████▋     | 11229/24227 [00:32<00:36, 359.13 examples/s]Tokenizing train dataset:  47%|████▋     | 11281/24227 [00:32<00:36, 350.58 examples/s]Tokenizing train dataset:  47%|████▋     | 11320/24227 [00:32<00:36, 353.46 examples/s]Tokenizing train dataset:  47%|████▋     | 11360/24227 [00:32<00:35, 361.55 examples/s]Tokenizing train dataset:  47%|████▋     | 11402/24227 [00:32<00:38, 332.07 examples/s]Tokenizing train dataset:  47%|████▋     | 11438/24227 [00:32<00:37, 337.86 examples/s]Tokenizing train dataset:  47%|████▋     | 11475/24227 [00:32<00:37, 344.22 examples/s]Tokenizing train dataset:  48%|████▊     | 11515/24227 [00:32<00:35, 356.69 examples/s]Tokenizing train dataset:  48%|████▊     | 11566/24227 [00:33<00:36, 346.55 examples/s]Tokenizing train dataset:  48%|████▊     | 11605/24227 [00:33<00:35, 353.66 examples/s]Tokenizing train dataset:  48%|████▊     | 11641/24227 [00:33<00:35, 353.78 examples/s]Tokenizing train dataset:  48%|████▊     | 11694/24227 [00:33<00:36, 347.04 examples/s]Tokenizing train dataset:  48%|████▊     | 11730/24227 [00:33<00:35, 348.36 examples/s]Tokenizing train dataset:  49%|████▊     | 11782/24227 [00:33<00:36, 344.49 examples/s]Tokenizing train dataset:  49%|████▉     | 11831/24227 [00:33<00:41, 298.40 examples/s]Tokenizing train dataset:  49%|████▉     | 11892/24227 [00:33<00:33, 364.65 examples/s]Tokenizing train dataset:  49%|████▉     | 11960/24227 [00:34<00:28, 436.82 examples/s]Tokenizing train dataset:  50%|████▉     | 12038/24227 [00:34<00:23, 521.91 examples/s]Tokenizing train dataset:  50%|████▉     | 12104/24227 [00:34<00:21, 556.14 examples/s]Tokenizing train dataset:  50%|█████     | 12176/24227 [00:34<00:20, 599.24 examples/s]Tokenizing train dataset:  51%|█████     | 12247/24227 [00:34<00:19, 629.21 examples/s]Tokenizing train dataset:  51%|█████     | 12319/24227 [00:34<00:18, 649.06 examples/s]Tokenizing train dataset:  51%|█████     | 12390/24227 [00:34<00:17, 660.21 examples/s]Tokenizing train dataset:  52%|█████▏    | 12488/24227 [00:34<00:18, 651.24 examples/s]Tokenizing train dataset:  52%|█████▏    | 12558/24227 [00:34<00:17, 661.14 examples/s]Tokenizing train dataset:  52%|█████▏    | 12660/24227 [00:35<00:17, 664.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 12731/24227 [00:35<00:17, 673.73 examples/s]Tokenizing train dataset:  53%|█████▎    | 12805/24227 [00:35<00:16, 688.10 examples/s]Tokenizing train dataset:  53%|█████▎    | 12907/24227 [00:35<00:16, 682.00 examples/s]Tokenizing train dataset:  54%|█████▎    | 13007/24227 [00:35<00:16, 669.02 examples/s]Tokenizing train dataset:  54%|█████▍    | 13079/24227 [00:35<00:16, 679.82 examples/s]Tokenizing train dataset:  54%|█████▍    | 13176/24227 [00:35<00:16, 663.88 examples/s]Tokenizing train dataset:  55%|█████▍    | 13266/24227 [00:36<00:17, 636.80 examples/s]Tokenizing train dataset:  55%|█████▌    | 13358/24227 [00:36<00:17, 622.17 examples/s]Tokenizing train dataset:  56%|█████▌    | 13454/24227 [00:36<00:17, 626.49 examples/s]Tokenizing train dataset:  56%|█████▌    | 13527/24227 [00:36<00:16, 645.93 examples/s]Tokenizing train dataset:  56%|█████▌    | 13598/24227 [00:36<00:16, 658.63 examples/s]Tokenizing train dataset:  56%|█████▋    | 13672/24227 [00:36<00:15, 676.03 examples/s]Tokenizing train dataset:  57%|█████▋    | 13750/24227 [00:36<00:15, 696.79 examples/s]Tokenizing train dataset:  57%|█████▋    | 13825/24227 [00:36<00:14, 708.70 examples/s]Tokenizing train dataset:  57%|█████▋    | 13904/24227 [00:36<00:14, 727.96 examples/s]Tokenizing train dataset:  58%|█████▊    | 13998/24227 [00:37<00:14, 683.07 examples/s]Tokenizing train dataset:  58%|█████▊    | 14088/24227 [00:37<00:15, 652.64 examples/s]Tokenizing train dataset:  58%|█████▊    | 14170/24227 [00:37<00:14, 692.06 examples/s]Tokenizing train dataset:  59%|█████▉    | 14270/24227 [00:37<00:14, 676.63 examples/s]Tokenizing train dataset:  59%|█████▉    | 14341/24227 [00:37<00:14, 681.73 examples/s]Tokenizing train dataset:  60%|█████▉    | 14441/24227 [00:37<00:14, 666.89 examples/s]Tokenizing train dataset:  60%|██████    | 14537/24227 [00:37<00:14, 651.81 examples/s]Tokenizing train dataset:  60%|██████    | 14605/24227 [00:38<00:14, 652.84 examples/s]Tokenizing train dataset:  61%|██████    | 14675/24227 [00:38<00:14, 663.83 examples/s]Tokenizing train dataset:  61%|██████    | 14758/24227 [00:38<00:15, 618.03 examples/s]Tokenizing train dataset:  61%|██████    | 14824/24227 [00:38<00:16, 556.05 examples/s]Tokenizing train dataset:  62%|██████▏   | 14900/24227 [00:38<00:19, 484.47 examples/s]Tokenizing train dataset:  62%|██████▏   | 14952/24227 [00:38<00:21, 439.24 examples/s]Tokenizing train dataset:  62%|██████▏   | 15009/24227 [00:38<00:22, 415.23 examples/s]Tokenizing train dataset:  62%|██████▏   | 15069/24227 [00:39<00:22, 405.60 examples/s]Tokenizing train dataset:  62%|██████▏   | 15124/24227 [00:39<00:23, 391.44 examples/s]Tokenizing train dataset:  63%|██████▎   | 15183/24227 [00:39<00:23, 390.11 examples/s]Tokenizing train dataset:  63%|██████▎   | 15234/24227 [00:39<00:24, 373.84 examples/s]Tokenizing train dataset:  63%|██████▎   | 15272/24227 [00:39<00:23, 373.67 examples/s]Tokenizing train dataset:  63%|██████▎   | 15325/24227 [00:39<00:24, 363.44 examples/s]Tokenizing train dataset:  63%|██████▎   | 15380/24227 [00:39<00:24, 359.60 examples/s]Tokenizing train dataset:  64%|██████▎   | 15436/24227 [00:40<00:24, 360.30 examples/s]Tokenizing train dataset:  64%|██████▍   | 15488/24227 [00:40<00:24, 353.33 examples/s]Tokenizing train dataset:  64%|██████▍   | 15524/24227 [00:40<00:24, 352.60 examples/s]Tokenizing train dataset:  64%|██████▍   | 15560/24227 [00:40<00:24, 348.31 examples/s]Tokenizing train dataset:  64%|██████▍   | 15602/24227 [00:40<00:23, 363.32 examples/s]Tokenizing train dataset:  65%|██████▍   | 15655/24227 [00:40<00:24, 357.01 examples/s]Tokenizing train dataset:  65%|██████▍   | 15693/24227 [00:40<00:23, 362.01 examples/s]Tokenizing train dataset:  65%|██████▍   | 15733/24227 [00:40<00:22, 370.38 examples/s]Tokenizing train dataset:  65%|██████▌   | 15786/24227 [00:41<00:23, 361.52 examples/s]Tokenizing train dataset:  65%|██████▌   | 15826/24227 [00:41<00:22, 368.45 examples/s]Tokenizing train dataset:  66%|██████▌   | 15877/24227 [00:41<00:23, 356.98 examples/s]Tokenizing train dataset:  66%|██████▌   | 15916/24227 [00:41<00:22, 364.37 examples/s]Tokenizing train dataset:  66%|██████▌   | 15966/24227 [00:41<00:23, 352.45 examples/s]Tokenizing train dataset:  66%|██████▌   | 16022/24227 [00:41<00:23, 354.03 examples/s]Tokenizing train dataset:  66%|██████▋   | 16061/24227 [00:41<00:22, 356.42 examples/s]Tokenizing train dataset:  66%|██████▋   | 16098/24227 [00:41<00:22, 358.82 examples/s]Tokenizing train dataset:  67%|██████▋   | 16140/24227 [00:42<00:21, 368.25 examples/s]Tokenizing train dataset:  67%|██████▋   | 16180/24227 [00:42<00:21, 371.95 examples/s]Tokenizing train dataset:  67%|██████▋   | 16218/24227 [00:42<00:21, 367.38 examples/s]Tokenizing train dataset:  67%|██████▋   | 16272/24227 [00:42<00:22, 359.67 examples/s]Tokenizing train dataset:  67%|██████▋   | 16324/24227 [00:42<00:22, 348.32 examples/s]Tokenizing train dataset:  68%|██████▊   | 16376/24227 [00:42<00:22, 344.64 examples/s]Tokenizing train dataset:  68%|██████▊   | 16426/24227 [00:42<00:23, 336.62 examples/s]Tokenizing train dataset:  68%|██████▊   | 16477/24227 [00:43<00:23, 334.45 examples/s]Tokenizing train dataset:  68%|██████▊   | 16549/24227 [00:43<00:18, 420.60 examples/s]Tokenizing train dataset:  69%|██████▊   | 16622/24227 [00:43<00:15, 492.88 examples/s]Tokenizing train dataset:  69%|██████▉   | 16684/24227 [00:43<00:14, 521.98 examples/s]Tokenizing train dataset:  69%|██████▉   | 16754/24227 [00:43<00:13, 567.49 examples/s]Tokenizing train dataset:  69%|██████▉   | 16828/24227 [00:43<00:12, 608.30 examples/s]Tokenizing train dataset:  70%|██████▉   | 16899/24227 [00:43<00:11, 632.11 examples/s]Tokenizing train dataset:  70%|███████   | 17000/24227 [00:43<00:11, 640.29 examples/s]Tokenizing train dataset:  70%|███████   | 17069/24227 [00:43<00:10, 652.07 examples/s]Tokenizing train dataset:  71%|███████   | 17148/24227 [00:44<00:10, 684.48 examples/s]Tokenizing train dataset:  71%|███████   | 17223/24227 [00:44<00:10, 698.40 examples/s]Tokenizing train dataset:  71%|███████▏  | 17294/24227 [00:44<00:09, 698.53 examples/s]Tokenizing train dataset:  72%|███████▏  | 17368/24227 [00:44<00:09, 705.33 examples/s]Tokenizing train dataset:  72%|███████▏  | 17464/24227 [00:44<00:10, 676.13 examples/s]Tokenizing train dataset:  72%|███████▏  | 17553/24227 [00:44<00:10, 642.63 examples/s]Tokenizing train dataset:  73%|███████▎  | 17646/24227 [00:44<00:10, 631.39 examples/s]Tokenizing train dataset:  73%|███████▎  | 17717/24227 [00:44<00:10, 646.07 examples/s]Tokenizing train dataset:  73%|███████▎  | 17788/24227 [00:45<00:09, 661.33 examples/s]Tokenizing train dataset:  74%|███████▍  | 17881/24227 [00:45<00:09, 644.37 examples/s]Tokenizing train dataset:  74%|███████▍  | 17980/24227 [00:45<00:09, 640.92 examples/s]Tokenizing train dataset:  75%|███████▍  | 18056/24227 [00:45<00:09, 665.64 examples/s]Tokenizing train dataset:  75%|███████▍  | 18130/24227 [00:45<00:08, 681.54 examples/s]Tokenizing train dataset:  75%|███████▌  | 18204/24227 [00:45<00:08, 691.30 examples/s]Tokenizing train dataset:  75%|███████▌  | 18278/24227 [00:45<00:08, 703.47 examples/s]Tokenizing train dataset:  76%|███████▌  | 18354/24227 [00:45<00:08, 717.52 examples/s]Tokenizing train dataset:  76%|███████▌  | 18457/24227 [00:45<00:08, 702.76 examples/s]Tokenizing train dataset:  77%|███████▋  | 18552/24227 [00:46<00:08, 672.29 examples/s]Tokenizing train dataset:  77%|███████▋  | 18660/24227 [00:46<00:08, 683.54 examples/s]Tokenizing train dataset:  77%|███████▋  | 18735/24227 [00:46<00:07, 695.45 examples/s]Tokenizing train dataset:  78%|███████▊  | 18812/24227 [00:46<00:07, 712.15 examples/s]Tokenizing train dataset:  78%|███████▊  | 18891/24227 [00:46<00:07, 728.04 examples/s]Tokenizing train dataset:  78%|███████▊  | 18990/24227 [00:46<00:07, 699.18 examples/s]Tokenizing train dataset:  79%|███████▉  | 19085/24227 [00:46<00:07, 670.62 examples/s]Tokenizing train dataset:  79%|███████▉  | 19160/24227 [00:46<00:07, 686.79 examples/s]Tokenizing train dataset:  79%|███████▉  | 19239/24227 [00:47<00:07, 711.13 examples/s]Tokenizing train dataset:  80%|███████▉  | 19330/24227 [00:47<00:07, 666.96 examples/s]Tokenizing train dataset:  80%|████████  | 19411/24227 [00:47<00:07, 621.44 examples/s]Tokenizing train dataset:  81%|████████  | 19525/24227 [00:47<00:06, 744.82 examples/s]Tokenizing train dataset:  81%|████████  | 19653/24227 [00:47<00:05, 879.03 examples/s]Tokenizing train dataset:  82%|████████▏ | 19776/24227 [00:47<00:04, 972.20 examples/s]Tokenizing train dataset:  82%|████████▏ | 19894/24227 [00:47<00:04, 1027.12 examples/s]Tokenizing train dataset:  83%|████████▎ | 20021/24227 [00:47<00:03, 1093.52 examples/s]Tokenizing train dataset:  83%|████████▎ | 20144/24227 [00:48<00:03, 1129.48 examples/s]Tokenizing train dataset:  84%|████████▎ | 20266/24227 [00:48<00:03, 1152.95 examples/s]Tokenizing train dataset:  84%|████████▍ | 20386/24227 [00:48<00:03, 1166.01 examples/s]Tokenizing train dataset:  85%|████████▍ | 20560/24227 [00:48<00:03, 1158.87 examples/s]Tokenizing train dataset:  86%|████████▌ | 20735/24227 [00:48<00:03, 1160.47 examples/s]Tokenizing train dataset:  86%|████████▋ | 20910/24227 [00:48<00:02, 1157.80 examples/s]Tokenizing train dataset:  87%|████████▋ | 21029/24227 [00:48<00:02, 1164.13 examples/s]Tokenizing train dataset:  87%|████████▋ | 21148/24227 [00:48<00:02, 1167.50 examples/s]Tokenizing train dataset:  88%|████████▊ | 21273/24227 [00:48<00:02, 1186.37 examples/s]Tokenizing train dataset:  89%|████████▊ | 21454/24227 [00:49<00:02, 1190.60 examples/s]Tokenizing train dataset:  89%|████████▉ | 21629/24227 [00:49<00:02, 1178.87 examples/s]Tokenizing train dataset:  90%|█████████ | 21808/24227 [00:49<00:02, 1180.17 examples/s]Tokenizing train dataset:  91%|█████████ | 21929/24227 [00:49<00:01, 1183.85 examples/s]Tokenizing train dataset:  91%|█████████ | 22105/24227 [00:49<00:01, 1177.24 examples/s]Tokenizing train dataset:  92%|█████████▏| 22224/24227 [00:49<00:01, 1174.89 examples/s]Tokenizing train dataset:  92%|█████████▏| 22397/24227 [00:49<00:01, 1165.24 examples/s]Tokenizing train dataset:  93%|█████████▎| 22516/24227 [00:50<00:01, 1170.54 examples/s]Tokenizing train dataset:  93%|█████████▎| 22635/24227 [00:50<00:01, 1173.26 examples/s]Tokenizing train dataset:  94%|█████████▍| 22755/24227 [00:50<00:01, 1178.20 examples/s]Tokenizing train dataset:  94%|█████████▍| 22878/24227 [00:50<00:01, 1188.75 examples/s]Tokenizing train dataset:  95%|█████████▍| 22999/24227 [00:50<00:01, 1193.35 examples/s]Tokenizing train dataset:  95%|█████████▌| 23122/24227 [00:50<00:00, 1200.71 examples/s]Tokenizing train dataset:  96%|█████████▌| 23302/24227 [00:50<00:00, 1197.65 examples/s]Tokenizing train dataset:  97%|█████████▋| 23422/24227 [00:50<00:00, 1196.89 examples/s]Tokenizing train dataset:  97%|█████████▋| 23543/24227 [00:50<00:00, 1198.47 examples/s]Tokenizing train dataset:  98%|█████████▊| 23717/24227 [00:51<00:00, 1180.75 examples/s]Tokenizing train dataset:  98%|█████████▊| 23840/24227 [00:51<00:00, 1186.42 examples/s]Tokenizing train dataset:  99%|█████████▉| 24017/24227 [00:51<00:00, 1180.22 examples/s]Tokenizing train dataset: 100%|█████████▉| 24139/24227 [00:51<00:00, 1187.79 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [00:51<00:00, 470.55 examples/s] 
[rank0]:[W611 19:05:42.712825957 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 527/24227 [00:00<00:04, 5191.45 examples/s]Extracting prompt in eval dataset:  60%|█████▉    | 570/953 [00:00<00:00, 5608.59 examples/s]Extracting prompt in train dataset:   2%|▏         | 529/24227 [00:00<00:04, 5207.66 examples/s]Extracting prompt in train dataset:   2%|▏         | 530/24227 [00:00<00:04, 5202.46 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5615.67 examples/s]
Extracting prompt in train dataset:   4%|▍         | 1072/24227 [00:00<00:04, 5342.11 examples/s]Extracting prompt in train dataset:   4%|▍         | 1081/24227 [00:00<00:04, 5359.89 examples/s]Extracting prompt in train dataset:   5%|▍         | 1098/24227 [00:00<00:04, 5456.85 examples/s]Extracting prompt in train dataset:   7%|▋         | 1610/24227 [00:00<00:04, 5352.55 examples/s]Extracting prompt in train dataset:   7%|▋         | 1620/24227 [00:00<00:04, 5366.57 examples/s]Extracting prompt in train dataset:   7%|▋         | 1648/24227 [00:00<00:04, 5461.59 examples/s]Extracting prompt in train dataset:   9%|▉         | 2170/24227 [00:00<00:04, 5426.78 examples/s]Extracting prompt in train dataset:   9%|▉         | 2180/24227 [00:00<00:04, 5436.87 examples/s]Extracting prompt in train dataset:   9%|▉         | 2210/24227 [00:00<00:04, 5501.14 examples/s]Extracting prompt in train dataset:  11%|█▏        | 2731/24227 [00:00<00:03, 5480.10 examples/s]Extracting prompt in train dataset:  11%|█▏        | 2740/24227 [00:00<00:03, 5487.85 examples/s]Extracting prompt in train dataset:  11%|█▏        | 2780/24227 [00:00<00:03, 5556.14 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  32%|███▏      | 303/953 [00:00<00:00, 3003.19 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3531/24227 [00:00<00:03, 5410.67 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3560/24227 [00:00<00:03, 5447.33 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3605/24227 [00:00<00:03, 5500.73 examples/s]Applying chat template to eval dataset:  65%|██████▌   | 620/953 [00:00<00:00, 3095.53 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4097/24227 [00:00<00:03, 5482.29 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4140/24227 [00:00<00:03, 5539.36 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4180/24227 [00:00<00:03, 5549.11 examples/s]Applying chat template to eval dataset:  99%|█████████▊| 939/953 [00:00<00:00, 3128.71 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3089.94 examples/s]
Extracting prompt in train dataset:  19%|█▉        | 4660/24227 [00:00<00:03, 5508.92 examples/s]Extracting prompt in train dataset:  19%|█▉        | 4720/24227 [00:00<00:03, 5595.55 examples/s]Extracting prompt in train dataset:  20%|█▉        | 4750/24227 [00:00<00:03, 5583.62 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5223/24227 [00:00<00:03, 5543.91 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5300/24227 [00:00<00:03, 5639.66 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5320/24227 [00:00<00:03, 5603.30 examples/s]Extracting prompt in train dataset:  25%|██▍       | 5976/24227 [00:01<00:03, 5334.01 examples/s]Extracting prompt in train dataset:  25%|██▌       | 6110/24227 [00:01<00:03, 5402.46 examples/s]Extracting prompt in train dataset:  25%|██▌       | 6110/24227 [00:01<00:03, 5418.56 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  27%|██▋       | 6550/24227 [00:01<00:03, 5419.58 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6690/24227 [00:01<00:03, 5503.08 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6699/24227 [00:01<00:03, 5542.79 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 318.48 examples/s]Extracting prompt in train dataset:  29%|██▉       | 7120/24227 [00:01<00:03, 5490.83 examples/s]Extracting prompt in train dataset:  30%|███       | 7270/24227 [00:01<00:03, 5570.04 examples/s]Extracting prompt in train dataset:  30%|███       | 7280/24227 [00:01<00:03, 5600.96 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7690/24227 [00:01<00:02, 5542.23 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7855/24227 [00:01<00:02, 5641.56 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7870/24227 [00:01<00:02, 5678.69 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:03, 287.76 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8278/24227 [00:01<00:02, 5639.28 examples/s]Extracting prompt in train dataset:  35%|███▍      | 8450/24227 [00:01<00:02, 5707.40 examples/s]Extracting prompt in train dataset:  35%|███▍      | 8472/24227 [00:01<00:02, 5773.03 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8865/24227 [00:01<00:02, 5694.00 examples/s]Tokenizing eval dataset:  12%|█▏        | 118/953 [00:00<00:03, 275.22 examples/s]Extracting prompt in train dataset:  37%|███▋      | 9050/24227 [00:01<00:02, 5769.32 examples/s]Extracting prompt in train dataset:  37%|███▋      | 9071/24227 [00:01<00:02, 5835.34 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9450/24227 [00:01<00:02, 5729.09 examples/s]Extracting prompt in train dataset:  40%|███▉      | 9670/24227 [00:01<00:02, 5875.50 examples/s]Extracting prompt in train dataset:  40%|███▉      | 9650/24227 [00:01<00:02, 5811.09 examples/s]Tokenizing eval dataset:  17%|█▋        | 158/953 [00:00<00:02, 265.95 examples/s]Extracting prompt in train dataset:  41%|████▏     | 10038/24227 [00:01<00:02, 5772.61 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10270/24227 [00:01<00:02, 5895.15 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10249/24227 [00:01<00:02, 5848.67 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:00<00:03, 251.78 examples/s]Extracting prompt in train dataset:  45%|████▍     | 10900/24227 [00:01<00:02, 5739.26 examples/s]Extracting prompt in train dataset:  46%|████▌     | 11112/24227 [00:01<00:02, 5809.54 examples/s]Extracting prompt in train dataset:  46%|████▌     | 11150/24227 [00:01<00:02, 5868.71 examples/s]Tokenizing eval dataset:  24%|██▍       | 230/953 [00:00<00:02, 274.79 examples/s]Extracting prompt in train dataset:  47%|████▋     | 11480/24227 [00:02<00:02, 5723.97 examples/s]Extracting prompt in train dataset:  50%|████▉     | 12030/24227 [00:02<00:02, 5860.75 examples/s]Extracting prompt in train dataset:  49%|████▉     | 11985/24227 [00:02<00:02, 5804.54 examples/s]Tokenizing eval dataset:  31%|███       | 295/953 [00:00<00:01, 370.07 examples/s]Extracting prompt in train dataset:  50%|████▉     | 12057/24227 [00:02<00:02, 5735.28 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 12579/24227 [00:02<00:01, 5831.45 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 12630/24227 [00:02<00:01, 5883.76 examples/s]Tokenizing eval dataset:  38%|███▊      | 358/953 [00:01<00:01, 438.87 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 12644/24227 [00:02<00:02, 5755.89 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 13230/24227 [00:02<00:01, 5905.64 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 13170/24227 [00:02<00:01, 5838.35 examples/s]Tokenizing eval dataset:  44%|████▍     | 420/953 [00:01<00:01, 484.67 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 13229/24227 [00:02<00:01, 5782.51 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13831/24227 [00:02<00:01, 5927.43 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13770/24227 [00:02<00:01, 5860.64 examples/s]Tokenizing eval dataset:  51%|█████     | 488/953 [00:01<00:00, 537.73 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13817/24227 [00:02<00:01, 5798.91 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 14430/24227 [00:02<00:01, 5937.80 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 14370/24227 [00:02<00:01, 5874.60 examples/s]Tokenizing eval dataset:  58%|█████▊    | 554/953 [00:01<00:00, 571.57 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 14400/24227 [00:02<00:01, 5795.71 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 14960/24227 [00:02<00:01, 5865.03 examples/s]Tokenizing eval dataset:  65%|██████▍   | 616/953 [00:01<00:00, 581.43 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 15155/24227 [00:02<00:01, 5514.15 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 15114/24227 [00:02<00:01, 5395.60 examples/s]Tokenizing eval dataset:  71%|███████   | 677/953 [00:01<00:00, 589.14 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 15740/24227 [00:02<00:01, 5589.64 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 15670/24227 [00:02<00:01, 5425.67 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 15690/24227 [00:02<00:01, 5475.00 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 16322/24227 [00:02<00:01, 5651.44 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 16250/24227 [00:02<00:01, 5514.60 examples/s]Tokenizing eval dataset:  80%|███████▉  | 759/953 [00:01<00:00, 567.48 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 16270/24227 [00:02<00:01, 5540.87 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 16920/24227 [00:02<00:01, 5727.06 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 16840/24227 [00:02<00:01, 5606.24 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 16855/24227 [00:03<00:01, 5617.11 examples/s]Tokenizing eval dataset:  87%|████████▋ | 832/953 [00:01<00:00, 536.38 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 17520/24227 [00:03<00:01, 5799.60 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 17440/24227 [00:03<00:01, 5692.52 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 17440/24227 [00:03<00:01, 5672.39 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 18120/24227 [00:03<00:01, 5851.86 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 18040/24227 [00:03<00:01, 5752.47 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:02<00:00, 520.42 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 18029/24227 [00:03<00:01, 5733.74 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18720/24227 [00:03<00:00, 5891.47 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18640/24227 [00:03<00:00, 5800.54 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 450.97 examples/s]
Extracting prompt in train dataset:  77%|███████▋  | 18611/24227 [00:03<00:00, 5746.73 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 19320/24227 [00:03<00:00, 5913.29 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 19240/24227 [00:03<00:00, 5833.04 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 19200/24227 [00:03<00:00, 5775.55 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19846/24227 [00:03<00:00, 5883.95 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19790/24227 [00:03<00:00, 5810.80 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 20210/24227 [00:03<00:00, 5911.55 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 20450/24227 [00:03<00:00, 5914.65 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 20390/24227 [00:03<00:00, 5852.52 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 20810/24227 [00:03<00:00, 5913.46 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 21056/24227 [00:03<00:00, 5956.12 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 20990/24227 [00:03<00:00, 5880.33 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 21410/24227 [00:03<00:00, 5917.75 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21660/24227 [00:03<00:00, 5965.97 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21590/24227 [00:03<00:00, 5899.65 examples/s]Extracting prompt in train dataset:  91%|█████████ | 22010/24227 [00:03<00:00, 5919.74 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22266/24227 [00:03<00:00, 5993.32 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22190/24227 [00:03<00:00, 5909.54 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 22630/24227 [00:03<00:00, 5969.12 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 22870/24227 [00:03<00:00, 5989.33 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 22790/24227 [00:04<00:00, 5915.56 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 23240/24227 [00:04<00:00, 5997.95 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 23472/24227 [00:04<00:00, 5997.91 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 23390/24227 [00:04<00:00, 5922.71 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 23860/24227 [00:04<00:00, 6027.72 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 24080/24227 [00:04<00:00, 6007.52 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:04<00:00, 5734.89 examples/s]
Extracting prompt in train dataset:  99%|█████████▉| 23990/24227 [00:04<00:00, 5928.04 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:04<00:00, 5712.32 examples/s]
Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:04<00:00, 5641.98 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 286/24227 [00:00<00:08, 2827.41 examples/s]Applying chat template to train dataset:   1%|          | 281/24227 [00:00<00:08, 2764.41 examples/s]Applying chat template to train dataset:   1%|          | 279/24227 [00:00<00:08, 2766.89 examples/s]Applying chat template to train dataset:   2%|▏         | 597/24227 [00:00<00:07, 2978.50 examples/s]Applying chat template to train dataset:   2%|▏         | 588/24227 [00:00<00:08, 2935.16 examples/s]Applying chat template to train dataset:   2%|▏         | 580/24227 [00:00<00:08, 2905.99 examples/s]Applying chat template to train dataset:   4%|▎         | 903/24227 [00:00<00:07, 3013.59 examples/s]Applying chat template to train dataset:   4%|▎         | 890/24227 [00:00<00:07, 2967.13 examples/s]Applying chat template to train dataset:   4%|▎         | 881/24227 [00:00<00:07, 2944.19 examples/s]Applying chat template to train dataset:   5%|▌         | 1214/24227 [00:00<00:07, 3049.74 examples/s]Applying chat template to train dataset:   5%|▍         | 1198/24227 [00:00<00:07, 3006.89 examples/s]Applying chat template to train dataset:   5%|▍         | 1186/24227 [00:00<00:07, 2983.59 examples/s]Applying chat template to train dataset:   6%|▋         | 1521/24227 [00:00<00:07, 3051.84 examples/s]Applying chat template to train dataset:   6%|▌         | 1501/24227 [00:00<00:07, 3012.28 examples/s]Applying chat template to train dataset:   6%|▌         | 1486/24227 [00:00<00:07, 2986.34 examples/s]Applying chat template to train dataset:   8%|▊         | 1838/24227 [00:00<00:07, 3089.99 examples/s]Applying chat template to train dataset:   7%|▋         | 1810/24227 [00:00<00:07, 3035.67 examples/s]Applying chat template to train dataset:   7%|▋         | 1792/24227 [00:00<00:07, 3009.95 examples/s]Applying chat template to train dataset:   9%|▉         | 2150/24227 [00:00<00:07, 3095.62 examples/s]Applying chat template to train dataset:   9%|▊         | 2119/24227 [00:00<00:07, 3051.51 examples/s]Applying chat template to train dataset:   9%|▊         | 2098/24227 [00:00<00:07, 3023.41 examples/s]Applying chat template to train dataset:  10%|█         | 2463/24227 [00:00<00:07, 3102.12 examples/s]Applying chat template to train dataset:  10%|█         | 2429/24227 [00:00<00:07, 3063.64 examples/s]Applying chat template to train dataset:  10%|▉         | 2404/24227 [00:00<00:07, 3031.36 examples/s]Applying chat template to train dataset:  11%|█▏        | 2777/24227 [00:00<00:06, 3107.43 examples/s]Applying chat template to train dataset:  11%|█▏        | 2738/24227 [00:00<00:07, 3069.64 examples/s]Applying chat template to train dataset:  11%|█▏        | 2730/24227 [00:00<00:08, 2679.09 examples/s]Applying chat template to train dataset:  13%|█▎        | 3197/24227 [00:01<00:07, 2976.26 examples/s]Applying chat template to train dataset:  13%|█▎        | 3180/24227 [00:01<00:06, 3016.95 examples/s]Applying chat template to train dataset:  12%|█▏        | 3016/24227 [00:01<00:07, 2727.21 examples/s]Applying chat template to train dataset:  14%|█▍        | 3506/24227 [00:01<00:06, 3003.92 examples/s]Applying chat template to train dataset:  14%|█▍        | 3485/24227 [00:01<00:06, 3025.07 examples/s]Applying chat template to train dataset:  14%|█▎        | 3320/24227 [00:01<00:07, 2813.02 examples/s]Applying chat template to train dataset:  16%|█▌        | 3819/24227 [00:01<00:06, 3037.34 examples/s]Applying chat template to train dataset:  16%|█▌        | 3795/24227 [00:01<00:06, 3040.75 examples/s]Applying chat template to train dataset:  15%|█▍        | 3625/24227 [00:01<00:07, 2879.33 examples/s]Applying chat template to train dataset:  17%|█▋        | 4130/24227 [00:01<00:06, 3052.35 examples/s]Applying chat template to train dataset:  17%|█▋        | 4102/24227 [00:01<00:06, 3046.97 examples/s]Applying chat template to train dataset:  16%|█▌        | 3930/24227 [00:01<00:06, 2927.23 examples/s]Applying chat template to train dataset:  18%|█▊        | 4442/24227 [00:01<00:06, 3070.53 examples/s]Applying chat template to train dataset:  18%|█▊        | 4410/24227 [00:01<00:06, 3054.68 examples/s]Applying chat template to train dataset:  17%|█▋        | 4237/24227 [00:01<00:06, 2966.23 examples/s]Applying chat template to train dataset:  20%|█▉        | 4752/24227 [00:01<00:06, 3077.06 examples/s]Applying chat template to train dataset:  19%|█▉        | 4718/24227 [00:01<00:06, 3058.87 examples/s]Applying chat template to train dataset:  19%|█▉        | 4543/24227 [00:01<00:06, 2987.60 examples/s]Applying chat template to train dataset:  21%|██        | 5062/24227 [00:01<00:06, 3080.54 examples/s]Applying chat template to train dataset:  21%|██▏       | 5176/24227 [00:01<00:06, 3054.82 examples/s]Applying chat template to train dataset:  20%|██        | 4847/24227 [00:01<00:06, 3000.78 examples/s]Applying chat template to train dataset:  23%|██▎       | 5527/24227 [00:01<00:06, 3085.68 examples/s]Applying chat template to train dataset:  23%|██▎       | 5482/24227 [00:01<00:06, 3053.92 examples/s]Applying chat template to train dataset:  21%|██▏       | 5153/24227 [00:01<00:06, 3011.29 examples/s]Applying chat template to train dataset:  23%|██▎       | 5459/24227 [00:01<00:06, 3021.40 examples/s]Applying chat template to train dataset:  25%|██▍       | 5955/24227 [00:01<00:06, 2995.26 examples/s]Applying chat template to train dataset:  24%|██▍       | 5901/24227 [00:01<00:06, 2954.12 examples/s]Applying chat template to train dataset:  26%|██▌       | 6268/24227 [00:02<00:05, 3027.22 examples/s]Applying chat template to train dataset:  26%|██▌       | 6210/24227 [00:02<00:06, 2987.92 examples/s]Applying chat template to train dataset:  24%|██▍       | 5875/24227 [00:02<00:06, 2922.69 examples/s]Applying chat template to train dataset:  27%|██▋       | 6580/24227 [00:02<00:05, 3049.67 examples/s]Applying chat template to train dataset:  27%|██▋       | 6520/24227 [00:02<00:05, 3015.31 examples/s]Applying chat template to train dataset:  26%|██▌       | 6180/24227 [00:02<00:06, 2956.12 examples/s]Applying chat template to train dataset:  28%|██▊       | 6894/24227 [00:02<00:05, 3070.21 examples/s]Applying chat template to train dataset:  28%|██▊       | 6830/24227 [00:02<00:05, 3035.48 examples/s]Applying chat template to train dataset:  27%|██▋       | 6489/24227 [00:02<00:05, 2991.28 examples/s]Applying chat template to train dataset:  30%|██▉       | 7208/24227 [00:02<00:05, 3086.61 examples/s]Applying chat template to train dataset:  29%|██▉       | 7140/24227 [00:02<00:05, 3050.17 examples/s]Applying chat template to train dataset:  28%|██▊       | 6796/24227 [00:02<00:05, 3011.54 examples/s]Applying chat template to train dataset:  31%|███       | 7520/24227 [00:02<00:05, 3091.92 examples/s]Applying chat template to train dataset:  31%|███       | 7450/24227 [00:02<00:05, 3060.62 examples/s]Applying chat template to train dataset:  29%|██▉       | 7104/24227 [00:02<00:05, 3027.33 examples/s]Applying chat template to train dataset:  32%|███▏      | 7838/24227 [00:02<00:05, 3115.46 examples/s]Applying chat template to train dataset:  32%|███▏      | 7761/24227 [00:02<00:05, 3071.06 examples/s]Applying chat template to train dataset:  31%|███       | 7410/24227 [00:02<00:05, 3034.94 examples/s]Applying chat template to train dataset:  34%|███▎      | 8158/24227 [00:02<00:05, 3138.84 examples/s]Applying chat template to train dataset:  33%|███▎      | 8079/24227 [00:02<00:05, 3100.19 examples/s]Applying chat template to train dataset:  32%|███▏      | 7718/24227 [00:02<00:05, 3045.52 examples/s]Applying chat template to train dataset:  35%|███▍      | 8478/24227 [00:02<00:04, 3155.79 examples/s]Applying chat template to train dataset:  35%|███▍      | 8396/24227 [00:02<00:05, 3117.09 examples/s]Applying chat template to train dataset:  33%|███▎      | 8033/24227 [00:02<00:05, 3073.27 examples/s]Applying chat template to train dataset:  36%|███▋      | 8799/24227 [00:02<00:04, 3169.01 examples/s]Applying chat template to train dataset:  36%|███▌      | 8713/24227 [00:02<00:04, 3130.24 examples/s]Applying chat template to train dataset:  34%|███▍      | 8348/24227 [00:02<00:05, 3094.16 examples/s]Applying chat template to train dataset:  38%|███▊      | 9120/24227 [00:02<00:04, 3175.97 examples/s]Applying chat template to train dataset:  37%|███▋      | 9030/24227 [00:02<00:04, 3139.04 examples/s]Applying chat template to train dataset:  36%|███▌      | 8663/24227 [00:02<00:05, 3108.75 examples/s]Applying chat template to train dataset:  39%|███▉      | 9441/24227 [00:03<00:04, 3182.23 examples/s]Applying chat template to train dataset:  39%|███▊      | 9347/24227 [00:03<00:04, 3146.59 examples/s]Applying chat template to train dataset:  37%|███▋      | 8979/24227 [00:03<00:04, 3120.86 examples/s]Applying chat template to train dataset:  40%|████      | 9762/24227 [00:03<00:04, 3186.50 examples/s]Applying chat template to train dataset:  40%|███▉      | 9663/24227 [00:03<00:04, 3147.88 examples/s]Applying chat template to train dataset:  38%|███▊      | 9293/24227 [00:03<00:04, 3125.40 examples/s]Applying chat template to train dataset:  42%|████▏     | 10082/24227 [00:03<00:04, 3186.74 examples/s]Applying chat template to train dataset:  41%|████      | 9980/24227 [00:03<00:04, 3150.94 examples/s]Applying chat template to train dataset:  40%|███▉      | 9608/24227 [00:03<00:04, 3130.16 examples/s]Applying chat template to train dataset:  41%|████      | 9922/24227 [00:03<00:04, 3130.61 examples/s]Applying chat template to train dataset:  44%|████▎     | 10550/24227 [00:03<00:04, 3153.74 examples/s]Applying chat template to train dataset:  43%|████▎     | 10443/24227 [00:03<00:04, 3118.79 examples/s]Applying chat template to train dataset:  42%|████▏     | 10237/24227 [00:03<00:04, 3132.56 examples/s]Applying chat template to train dataset:  45%|████▍     | 10870/24227 [00:03<00:04, 3161.91 examples/s]Applying chat template to train dataset:  44%|████▍     | 10759/24227 [00:03<00:04, 3125.57 examples/s]Applying chat template to train dataset:  46%|████▌     | 11191/24227 [00:03<00:04, 3172.66 examples/s]Applying chat template to train dataset:  46%|████▌     | 11073/24227 [00:03<00:04, 3128.76 examples/s]Applying chat template to train dataset:  44%|████▍     | 10701/24227 [00:03<00:04, 3114.20 examples/s]Applying chat template to train dataset:  48%|████▊     | 11510/24227 [00:03<00:04, 3176.26 examples/s]Applying chat template to train dataset:  47%|████▋     | 11389/24227 [00:03<00:04, 3134.57 examples/s]Applying chat template to train dataset:  46%|████▌     | 11164/24227 [00:03<00:04, 3099.54 examples/s]Applying chat template to train dataset:  49%|████▉     | 11988/24227 [00:03<00:03, 3175.22 examples/s]Applying chat template to train dataset:  49%|████▉     | 11855/24227 [00:03<00:03, 3116.56 examples/s]Applying chat template to train dataset:  48%|████▊     | 11626/24227 [00:03<00:04, 3090.22 examples/s]Applying chat template to train dataset:  51%|█████     | 12310/24227 [00:03<00:03, 3181.49 examples/s]Applying chat template to train dataset:  50%|█████     | 12173/24227 [00:03<00:03, 3130.47 examples/s]Applying chat template to train dataset:  49%|████▉     | 11938/24227 [00:03<00:03, 3091.51 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12631/24227 [00:04<00:03, 3186.28 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12490/24227 [00:04<00:03, 3139.63 examples/s]Applying chat template to train dataset:  51%|█████     | 12253/24227 [00:04<00:03, 3103.79 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12953/24227 [00:04<00:03, 3193.47 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12809/24227 [00:04<00:03, 3151.29 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12570/24227 [00:04<00:03, 3114.67 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13126/24227 [00:04<00:03, 3152.48 examples/s]Applying chat template to train dataset:  55%|█████▌    | 13432/24227 [00:04<00:03, 3191.49 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12886/24227 [00:04<00:03, 3126.34 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13753/24227 [00:04<00:03, 3192.80 examples/s]Applying chat template to train dataset:  56%|█████▌    | 13600/24227 [00:04<00:03, 3152.14 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13200/24227 [00:04<00:03, 3125.34 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14073/24227 [00:04<00:03, 3192.29 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13918/24227 [00:04<00:03, 3158.52 examples/s]Applying chat template to train dataset:  56%|█████▌    | 13514/24227 [00:04<00:03, 3127.67 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14395/24227 [00:04<00:03, 3196.86 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13830/24227 [00:04<00:03, 3129.50 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14392/24227 [00:04<00:03, 3156.05 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14144/24227 [00:04<00:03, 3131.49 examples/s]Applying chat template to train dataset:  61%|██████▏   | 14870/24227 [00:04<00:02, 3183.42 examples/s]Applying chat template to train dataset:  61%|██████    | 14709/24227 [00:04<00:03, 3156.64 examples/s]Applying chat template to train dataset:  60%|█████▉    | 14458/24227 [00:04<00:03, 3131.18 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15276/24227 [00:04<00:03, 2980.96 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15120/24227 [00:04<00:03, 2943.36 examples/s]Applying chat template to train dataset:  62%|██████▏   | 14924/24227 [00:04<00:02, 3117.99 examples/s]Applying chat template to train dataset:  64%|██████▍   | 15590/24227 [00:05<00:02, 3014.85 examples/s]Applying chat template to train dataset:  64%|██████▎   | 15430/24227 [00:05<00:02, 2977.05 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15905/24227 [00:05<00:02, 3048.08 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15306/24227 [00:05<00:03, 2911.38 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15741/24227 [00:05<00:02, 3011.41 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16219/24227 [00:05<00:02, 3070.98 examples/s]Applying chat template to train dataset:  64%|██████▍   | 15616/24227 [00:05<00:02, 2954.24 examples/s]Applying chat template to train dataset:  66%|██████▋   | 16052/24227 [00:05<00:02, 3036.06 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16531/24227 [00:05<00:02, 3081.70 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15925/24227 [00:05<00:02, 2986.99 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16361/24227 [00:05<00:02, 3050.87 examples/s]Applying chat template to train dataset:  70%|██████▉   | 16851/24227 [00:05<00:02, 3114.64 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16235/24227 [00:05<00:02, 3011.63 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16676/24227 [00:05<00:02, 3076.86 examples/s]Applying chat template to train dataset:  71%|███████   | 17173/24227 [00:05<00:02, 3141.86 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16543/24227 [00:05<00:02, 3026.48 examples/s]Applying chat template to train dataset:  70%|███████   | 16993/24227 [00:05<00:02, 3100.22 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17493/24227 [00:05<00:02, 3154.84 examples/s]Applying chat template to train dataset:  70%|██████▉   | 16858/24227 [00:05<00:02, 3057.58 examples/s]Applying chat template to train dataset:  71%|███████▏  | 17310/24227 [00:05<00:02, 3117.11 examples/s]Applying chat template to train dataset:  74%|███████▎  | 17812/24227 [00:05<00:02, 3162.90 examples/s]Applying chat template to train dataset:  71%|███████   | 17171/24227 [00:05<00:02, 3076.32 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17629/24227 [00:05<00:02, 3131.44 examples/s]Applying chat template to train dataset:  75%|███████▍  | 18133/24227 [00:05<00:01, 3175.21 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17489/24227 [00:05<00:02, 3099.61 examples/s]Applying chat template to train dataset:  74%|███████▍  | 17946/24227 [00:05<00:02, 3139.90 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18454/24227 [00:05<00:01, 3185.22 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17803/24227 [00:05<00:02, 3108.13 examples/s]Applying chat template to train dataset:  75%|███████▌  | 18264/24227 [00:05<00:01, 3148.59 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18774/24227 [00:06<00:01, 3187.72 examples/s]Applying chat template to train dataset:  75%|███████▍  | 18119/24227 [00:05<00:01, 3118.18 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18581/24227 [00:06<00:01, 3153.62 examples/s]Applying chat template to train dataset:  79%|███████▉  | 19096/24227 [00:06<00:02, 2477.24 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18900/24227 [00:06<00:02, 2539.31 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18436/24227 [00:06<00:02, 2503.83 examples/s]Applying chat template to train dataset:  80%|████████  | 19417/24227 [00:06<00:01, 2657.72 examples/s]Applying chat template to train dataset:  79%|███████▉  | 19217/24227 [00:06<00:01, 2698.64 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18750/24227 [00:06<00:02, 2662.87 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19750/24227 [00:06<00:01, 2831.77 examples/s]Applying chat template to train dataset:  81%|████████  | 19534/24227 [00:06<00:01, 2822.97 examples/s]Applying chat template to train dataset:  79%|███████▊  | 19066/24227 [00:06<00:01, 2791.75 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19856/24227 [00:06<00:01, 2929.68 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20085/24227 [00:06<00:01, 2969.04 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19380/24227 [00:06<00:01, 2883.80 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20179/24227 [00:06<00:01, 3012.75 examples/s]Applying chat template to train dataset:  84%|████████▍ | 20414/24227 [00:06<00:01, 3055.53 examples/s]Applying chat template to train dataset:  81%|████████▏ | 19700/24227 [00:06<00:01, 2968.69 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20501/24227 [00:06<00:01, 3069.15 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20740/24227 [00:06<00:01, 3109.68 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20020/24227 [00:06<00:01, 3031.22 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20824/24227 [00:06<00:01, 3115.22 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21067/24227 [00:06<00:01, 3154.43 examples/s]Applying chat template to train dataset:  84%|████████▍ | 20341/24227 [00:06<00:01, 3080.25 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21147/24227 [00:06<00:00, 3146.01 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21394/24227 [00:06<00:00, 3181.60 examples/s]Applying chat template to train dataset:  85%|████████▌ | 20660/24227 [00:06<00:01, 3110.92 examples/s]Applying chat template to train dataset:  89%|████████▊ | 21469/24227 [00:07<00:00, 3165.75 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21720/24227 [00:07<00:00, 3199.89 examples/s]Applying chat template to train dataset:  87%|████████▋ | 20980/24227 [00:06<00:01, 3130.71 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21792/24227 [00:07<00:00, 3178.14 examples/s]Applying chat template to train dataset:  91%|█████████ | 22046/24227 [00:07<00:00, 3217.18 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21300/24227 [00:07<00:00, 3146.77 examples/s]Applying chat template to train dataset:  91%|█████████▏| 22114/24227 [00:07<00:00, 3186.22 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22370/24227 [00:07<00:00, 3222.57 examples/s]Applying chat template to train dataset:  89%|████████▉ | 21620/24227 [00:07<00:00, 3155.16 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22438/24227 [00:07<00:00, 3198.74 examples/s]Applying chat template to train dataset:  94%|█████████▎| 22698/24227 [00:07<00:00, 3236.82 examples/s]Applying chat template to train dataset:  91%|█████████ | 21941/24227 [00:07<00:00, 3167.07 examples/s]Applying chat template to train dataset:  95%|█████████▌| 23032/24227 [00:07<00:00, 3265.06 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22260/24227 [00:07<00:00, 3171.53 examples/s]Applying chat template to train dataset:  95%|█████████▍| 22913/24227 [00:07<00:00, 3183.83 examples/s]Applying chat template to train dataset:  96%|█████████▋| 23369/24227 [00:07<00:00, 3293.80 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22580/24227 [00:07<00:00, 3178.47 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23234/24227 [00:07<00:00, 3188.57 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23703/24227 [00:07<00:00, 3306.64 examples/s]Applying chat template to train dataset:  95%|█████████▍| 22908/24227 [00:07<00:00, 3206.27 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23556/24227 [00:07<00:00, 3195.68 examples/s]Applying chat template to train dataset:  99%|█████████▉| 24039/24227 [00:07<00:00, 3319.92 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23234/24227 [00:07<00:00, 3220.00 examples/s]Applying chat template to train dataset:  99%|█████████▊| 23879/24227 [00:07<00:00, 3203.62 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:07<00:00, 3105.66 examples/s]
Applying chat template to train dataset:  97%|█████████▋| 23561/24227 [00:07<00:00, 3231.37 examples/s]Applying chat template to train dataset: 100%|█████████▉| 24201/24227 [00:07<00:00, 3205.35 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:07<00:00, 3070.52 examples/s]
Applying chat template to train dataset:  99%|█████████▊| 23889/24227 [00:07<00:00, 3242.96 examples/s]Applying chat template to train dataset: 100%|█████████▉| 24215/24227 [00:07<00:00, 3247.43 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:07<00:00, 3034.91 examples/s]
Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 403.25 examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 407.68 examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 90/24227 [00:00<01:11, 336.16 examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 405.83 examples/s]Tokenizing train dataset:   0%|          | 90/24227 [00:00<01:11, 338.73 examples/s]Tokenizing train dataset:   1%|          | 136/24227 [00:00<01:16, 316.99 examples/s]Tokenizing train dataset:   0%|          | 90/24227 [00:00<01:11, 337.37 examples/s]Tokenizing train dataset:   1%|          | 138/24227 [00:00<01:15, 319.81 examples/s]Tokenizing train dataset:   1%|          | 180/24227 [00:00<01:19, 303.73 examples/s]Tokenizing train dataset:   1%|          | 138/24227 [00:00<01:15, 319.11 examples/s]Tokenizing train dataset:   1%|          | 182/24227 [00:00<01:19, 303.46 examples/s]Tokenizing train dataset:   1%|          | 214/24227 [00:00<01:17, 309.90 examples/s]Tokenizing train dataset:   1%|          | 217/24227 [00:00<01:16, 312.39 examples/s]Tokenizing train dataset:   1%|          | 250/24227 [00:00<01:16, 314.44 examples/s]Tokenizing train dataset:   1%|          | 182/24227 [00:00<01:19, 301.56 examples/s]Tokenizing train dataset:   1%|          | 250/24227 [00:00<01:16, 315.26 examples/s]Tokenizing train dataset:   1%|          | 288/24227 [00:00<01:12, 328.60 examples/s]Tokenizing train dataset:   1%|          | 217/24227 [00:00<01:17, 310.54 examples/s]Tokenizing train dataset:   1%|          | 288/24227 [00:00<01:12, 329.70 examples/s]Tokenizing train dataset:   1%|          | 250/24227 [00:00<01:16, 313.68 examples/s]Tokenizing train dataset:   1%|▏         | 336/24227 [00:01<01:14, 321.49 examples/s]Tokenizing train dataset:   1%|          | 287/24227 [00:00<01:12, 329.30 examples/s]Tokenizing train dataset:   1%|▏         | 336/24227 [00:01<01:14, 322.20 examples/s]Tokenizing train dataset:   2%|▏         | 385/24227 [00:01<01:14, 319.48 examples/s]Tokenizing train dataset:   2%|▏         | 385/24227 [00:01<01:14, 320.15 examples/s]Tokenizing train dataset:   1%|▏         | 336/24227 [00:01<01:14, 320.42 examples/s]Tokenizing train dataset:   2%|▏         | 432/24227 [00:01<01:16, 312.39 examples/s]Tokenizing train dataset:   2%|▏         | 385/24227 [00:01<01:14, 318.27 examples/s]Tokenizing train dataset:   2%|▏         | 432/24227 [00:01<01:16, 312.99 examples/s]Tokenizing train dataset:   2%|▏         | 478/24227 [00:01<01:17, 305.35 examples/s]Tokenizing train dataset:   2%|▏         | 432/24227 [00:01<01:16, 311.69 examples/s]Tokenizing train dataset:   2%|▏         | 478/24227 [00:01<01:17, 306.02 examples/s]Tokenizing train dataset:   2%|▏         | 524/24227 [00:01<01:18, 302.01 examples/s]Tokenizing train dataset:   2%|▏         | 524/24227 [00:01<01:18, 302.87 examples/s]Tokenizing train dataset:   2%|▏         | 478/24227 [00:01<01:17, 304.79 examples/s]Tokenizing train dataset:   2%|▏         | 557/24227 [00:01<01:17, 306.52 examples/s]Tokenizing train dataset:   2%|▏         | 557/24227 [00:01<01:17, 307.02 examples/s]Tokenizing train dataset:   2%|▏         | 588/24227 [00:01<01:17, 304.01 examples/s]Tokenizing train dataset:   2%|▏         | 524/24227 [00:01<01:18, 301.69 examples/s]Tokenizing train dataset:   2%|▏         | 600/24227 [00:01<01:19, 298.48 examples/s]Tokenizing train dataset:   2%|▏         | 557/24227 [00:01<01:17, 306.31 examples/s]Tokenizing train dataset:   3%|▎         | 638/24227 [00:02<01:15, 311.68 examples/s]Tokenizing train dataset:   3%|▎         | 638/24227 [00:02<01:15, 313.60 examples/s]Tokenizing train dataset:   2%|▏         | 588/24227 [00:01<01:17, 303.80 examples/s]Tokenizing train dataset:   3%|▎         | 685/24227 [00:02<01:16, 307.33 examples/s]Tokenizing train dataset:   3%|▎         | 685/24227 [00:02<01:16, 309.04 examples/s]Tokenizing train dataset:   3%|▎         | 638/24227 [00:02<01:15, 311.67 examples/s]Tokenizing train dataset:   3%|▎         | 735/24227 [00:02<01:16, 308.89 examples/s]Tokenizing train dataset:   3%|▎         | 685/24227 [00:02<01:16, 307.72 examples/s]Tokenizing train dataset:   3%|▎         | 735/24227 [00:02<01:15, 310.44 examples/s]Tokenizing train dataset:   3%|▎         | 766/24227 [00:02<01:16, 307.70 examples/s]Tokenizing train dataset:   3%|▎         | 735/24227 [00:02<01:16, 308.96 examples/s]Tokenizing train dataset:   3%|▎         | 780/24227 [00:02<01:17, 301.16 examples/s]Tokenizing train dataset:   3%|▎         | 808/24227 [00:02<01:19, 294.24 examples/s]Tokenizing train dataset:   3%|▎         | 766/24227 [00:02<01:16, 307.72 examples/s]Tokenizing train dataset:   3%|▎         | 838/24227 [00:02<01:20, 291.89 examples/s]Tokenizing train dataset:   3%|▎         | 824/24227 [00:02<01:19, 293.02 examples/s]Tokenizing train dataset:   3%|▎         | 808/24227 [00:02<01:19, 294.17 examples/s]Tokenizing train dataset:   4%|▎         | 854/24227 [00:02<01:20, 291.42 examples/s]Tokenizing train dataset:   4%|▎         | 885/24227 [00:02<01:19, 294.68 examples/s]Tokenizing train dataset:   4%|▎         | 890/24227 [00:02<01:16, 304.67 examples/s]Tokenizing train dataset:   4%|▍         | 920/24227 [00:02<01:17, 300.29 examples/s]Tokenizing train dataset:   4%|▎         | 851/24227 [00:02<01:21, 288.01 examples/s]Tokenizing train dataset:   4%|▎         | 885/24227 [00:02<01:18, 295.78 examples/s]Tokenizing train dataset:   4%|▍         | 931/24227 [00:03<01:20, 290.07 examples/s]Tokenizing train dataset:   4%|▍         | 967/24227 [00:03<01:17, 299.03 examples/s]Tokenizing train dataset:   4%|▍         | 961/24227 [00:03<01:20, 290.36 examples/s]Tokenizing train dataset:   4%|▍         | 920/24227 [00:02<01:17, 300.93 examples/s]Tokenizing train dataset:   4%|▍         | 1009/24227 [00:03<01:21, 286.29 examples/s]Tokenizing train dataset:   4%|▍         | 951/24227 [00:03<01:17, 301.55 examples/s]Tokenizing train dataset:   4%|▍         | 1003/24227 [00:03<01:22, 282.34 examples/s]Tokenizing train dataset:   4%|▍         | 1050/24227 [00:03<01:22, 280.40 examples/s]Tokenizing train dataset:   4%|▍         | 994/24227 [00:03<01:19, 291.53 examples/s]Tokenizing train dataset:   4%|▍         | 1044/24227 [00:03<01:23, 278.01 examples/s]Tokenizing train dataset:   4%|▍         | 1084/24227 [00:03<01:19, 291.94 examples/s]Tokenizing train dataset:   4%|▍         | 1078/24227 [00:03<01:19, 291.05 examples/s]Tokenizing train dataset:   4%|▍         | 1036/24227 [00:03<01:21, 284.72 examples/s]Tokenizing train dataset:   5%|▍         | 1117/24227 [00:03<01:17, 298.84 examples/s]Tokenizing train dataset:   5%|▍         | 1111/24227 [00:03<01:17, 297.49 examples/s]Tokenizing train dataset:   4%|▍         | 1068/24227 [00:03<01:20, 288.24 examples/s]Tokenizing train dataset:   5%|▍         | 1158/24227 [00:03<01:20, 285.15 examples/s]Tokenizing train dataset:   5%|▍         | 1103/24227 [00:03<01:17, 299.84 examples/s]Tokenizing train dataset:   5%|▍         | 1152/24227 [00:03<01:20, 286.04 examples/s]Tokenizing train dataset:   5%|▍         | 1190/24227 [00:03<01:19, 290.17 examples/s]Tokenizing train dataset:   5%|▍         | 1183/24227 [00:03<01:19, 288.43 examples/s]Tokenizing train dataset:   5%|▍         | 1145/24227 [00:03<01:19, 288.95 examples/s]Tokenizing train dataset:   5%|▌         | 1222/24227 [00:04<01:18, 292.66 examples/s]Tokenizing train dataset:   5%|▌         | 1217/24227 [00:04<01:17, 298.54 examples/s]Tokenizing train dataset:   5%|▌         | 1257/24227 [00:04<01:14, 307.10 examples/s]Tokenizing train dataset:   5%|▍         | 1193/24227 [00:03<01:18, 293.15 examples/s]Tokenizing train dataset:   5%|▌         | 1251/24227 [00:04<01:15, 305.79 examples/s]Tokenizing train dataset:   5%|▌         | 1224/24227 [00:04<01:17, 295.66 examples/s]Tokenizing train dataset:   5%|▌         | 1307/24227 [00:04<01:13, 310.84 examples/s]Tokenizing train dataset:   5%|▌         | 1285/24227 [00:04<01:15, 305.59 examples/s]Tokenizing train dataset:   5%|▌         | 1259/24227 [00:04<01:14, 307.69 examples/s]Tokenizing train dataset:   6%|▌         | 1340/24227 [00:04<01:14, 308.97 examples/s]Tokenizing train dataset:   5%|▌         | 1320/24227 [00:04<01:13, 310.06 examples/s]Tokenizing train dataset:   5%|▌         | 1308/24227 [00:04<01:13, 311.07 examples/s]Tokenizing train dataset:   6%|▌         | 1352/24227 [00:04<01:14, 308.44 examples/s]Tokenizing train dataset:   6%|▌         | 1382/24227 [00:04<01:17, 295.52 examples/s]Tokenizing train dataset:   6%|▌         | 1340/24227 [00:04<01:14, 309.00 examples/s]Tokenizing train dataset:   6%|▌         | 1412/24227 [00:04<01:17, 295.65 examples/s]Tokenizing train dataset:   6%|▌         | 1395/24227 [00:04<01:17, 296.11 examples/s]Tokenizing train dataset:   6%|▌         | 1382/24227 [00:04<01:17, 295.57 examples/s]Tokenizing train dataset:   6%|▌         | 1427/24227 [00:04<01:16, 298.36 examples/s]Tokenizing train dataset:   6%|▌         | 1457/24227 [00:04<01:17, 293.32 examples/s]Tokenizing train dataset:   6%|▌         | 1412/24227 [00:04<01:17, 295.73 examples/s]Tokenizing train dataset:   6%|▌         | 1487/24227 [00:04<01:18, 291.28 examples/s]Tokenizing train dataset:   6%|▌         | 1472/24227 [00:04<01:17, 294.75 examples/s]Tokenizing train dataset:   6%|▌         | 1457/24227 [00:04<01:17, 293.32 examples/s]Tokenizing train dataset:   6%|▋         | 1532/24227 [00:05<01:17, 292.94 examples/s]Tokenizing train dataset:   6%|▌         | 1514/24227 [00:05<01:19, 285.14 examples/s]Tokenizing train dataset:   6%|▌         | 1487/24227 [00:04<01:18, 291.14 examples/s]Tokenizing train dataset:   6%|▋         | 1563/24227 [00:05<01:16, 294.34 examples/s]Tokenizing train dataset:   6%|▋         | 1548/24227 [00:05<01:16, 295.92 examples/s]Tokenizing train dataset:   6%|▋         | 1532/24227 [00:05<01:17, 292.40 examples/s]Tokenizing train dataset:   7%|▋         | 1610/24227 [00:05<01:16, 293.75 examples/s]Tokenizing train dataset:   7%|▋         | 1591/24227 [00:05<01:18, 290.14 examples/s]Tokenizing train dataset:   6%|▋         | 1563/24227 [00:05<01:17, 293.81 examples/s]Tokenizing train dataset:   7%|▋         | 1644/24227 [00:05<01:14, 301.69 examples/s]Tokenizing train dataset:   7%|▋         | 1627/24227 [00:05<01:15, 299.59 examples/s]Tokenizing train dataset:   7%|▋         | 1678/24227 [00:05<01:13, 307.14 examples/s]Tokenizing train dataset:   7%|▋         | 1610/24227 [00:05<01:17, 293.58 examples/s]Tokenizing train dataset:   7%|▋         | 1661/24227 [00:05<01:13, 307.01 examples/s]Tokenizing train dataset:   7%|▋         | 1714/24227 [00:05<01:10, 318.99 examples/s]Tokenizing train dataset:   7%|▋         | 1644/24227 [00:05<01:14, 301.94 examples/s]Tokenizing train dataset:   7%|▋         | 1701/24227 [00:05<01:09, 326.22 examples/s]Tokenizing train dataset:   7%|▋         | 1750/24227 [00:05<01:08, 326.87 examples/s]Tokenizing train dataset:   7%|▋         | 1678/24227 [00:05<01:13, 307.26 examples/s]Tokenizing train dataset:   7%|▋         | 1751/24227 [00:05<01:09, 323.78 examples/s]Tokenizing train dataset:   7%|▋         | 1786/24227 [00:05<01:07, 332.89 examples/s]Tokenizing train dataset:   7%|▋         | 1713/24227 [00:05<01:10, 317.82 examples/s]Tokenizing train dataset:   7%|▋         | 1788/24227 [00:05<01:07, 333.07 examples/s]Tokenizing train dataset:   7%|▋         | 1750/24227 [00:05<01:08, 326.15 examples/s]Tokenizing train dataset:   8%|▊         | 1829/24227 [00:06<01:12, 307.53 examples/s]Tokenizing train dataset:   7%|▋         | 1786/24227 [00:05<01:07, 331.92 examples/s]Tokenizing train dataset:   8%|▊         | 1829/24227 [00:06<01:12, 307.50 examples/s]Tokenizing train dataset:   8%|▊         | 1874/24227 [00:06<01:13, 302.20 examples/s]Tokenizing train dataset:   8%|▊         | 1829/24227 [00:06<01:13, 306.74 examples/s]Tokenizing train dataset:   8%|▊         | 1874/24227 [00:06<01:13, 302.21 examples/s]Tokenizing train dataset:   8%|▊         | 1910/24227 [00:06<01:20, 278.42 examples/s]Tokenizing train dataset:   8%|▊         | 1874/24227 [00:06<01:14, 301.39 examples/s]Tokenizing train dataset:   8%|▊         | 1910/24227 [00:06<01:20, 278.73 examples/s]Tokenizing train dataset:   8%|▊         | 1953/24227 [00:06<01:20, 277.36 examples/s]Tokenizing train dataset:   8%|▊         | 1910/24227 [00:06<01:20, 277.57 examples/s]Tokenizing train dataset:   8%|▊         | 1953/24227 [00:06<01:20, 277.87 examples/s]Tokenizing train dataset:   8%|▊         | 1997/24227 [00:06<01:19, 279.42 examples/s]Tokenizing train dataset:   8%|▊         | 1953/24227 [00:06<01:20, 276.59 examples/s]Tokenizing train dataset:   8%|▊         | 1997/24227 [00:06<01:19, 279.88 examples/s]Tokenizing train dataset:   8%|▊         | 2030/24227 [00:06<01:16, 288.36 examples/s]Tokenizing train dataset:   8%|▊         | 2030/24227 [00:06<01:16, 288.58 examples/s]Tokenizing train dataset:   9%|▊         | 2067/24227 [00:06<01:12, 307.72 examples/s]Tokenizing train dataset:   8%|▊         | 1997/24227 [00:06<01:19, 279.06 examples/s]Tokenizing train dataset:   9%|▊         | 2067/24227 [00:06<01:12, 307.77 examples/s]Tokenizing train dataset:   9%|▊         | 2100/24227 [00:06<01:11, 308.98 examples/s]Tokenizing train dataset:   8%|▊         | 2030/24227 [00:06<01:17, 288.02 examples/s]Tokenizing train dataset:   9%|▊         | 2100/24227 [00:06<01:11, 309.72 examples/s]Tokenizing train dataset:   9%|▊         | 2067/24227 [00:06<01:12, 307.49 examples/s]Tokenizing train dataset:   9%|▉         | 2146/24227 [00:07<01:12, 305.02 examples/s]Tokenizing train dataset:   9%|▊         | 2100/24227 [00:06<01:11, 309.23 examples/s]Tokenizing train dataset:   9%|▉         | 2146/24227 [00:07<01:12, 306.11 examples/s]Tokenizing train dataset:   9%|▉         | 2190/24227 [00:07<01:13, 298.00 examples/s]Tokenizing train dataset:   9%|▉         | 2146/24227 [00:07<01:12, 305.31 examples/s]Tokenizing train dataset:   9%|▉         | 2190/24227 [00:07<01:13, 298.84 examples/s]Tokenizing train dataset:   9%|▉         | 2240/24227 [00:07<01:12, 303.17 examples/s]Tokenizing train dataset:   9%|▉         | 2190/24227 [00:07<01:14, 295.48 examples/s]Tokenizing train dataset:   9%|▉         | 2239/24227 [00:07<01:12, 303.42 examples/s]Tokenizing train dataset:   9%|▉         | 2272/24227 [00:07<01:11, 305.20 examples/s]Tokenizing train dataset:   9%|▉         | 2272/24227 [00:07<01:11, 306.36 examples/s]Tokenizing train dataset:   9%|▉         | 2240/24227 [00:07<01:13, 301.05 examples/s]Tokenizing train dataset:  10%|▉         | 2318/24227 [00:07<01:13, 299.74 examples/s]Tokenizing train dataset:   9%|▉         | 2273/24227 [00:07<01:11, 305.31 examples/s]Tokenizing train dataset:  10%|▉         | 2319/24227 [00:07<01:12, 301.75 examples/s]Tokenizing train dataset:  10%|▉         | 2360/24227 [00:07<01:15, 288.28 examples/s]Tokenizing train dataset:  10%|▉         | 2319/24227 [00:07<01:12, 302.05 examples/s]Tokenizing train dataset:  10%|▉         | 2360/24227 [00:07<01:15, 290.17 examples/s]Tokenizing train dataset:  10%|▉         | 2390/24227 [00:07<01:16, 285.38 examples/s]Tokenizing train dataset:  10%|▉         | 2390/24227 [00:07<01:16, 286.82 examples/s]Tokenizing train dataset:  10%|█         | 2423/24227 [00:08<01:14, 291.27 examples/s]Tokenizing train dataset:  10%|▉         | 2360/24227 [00:07<01:15, 290.35 examples/s]Tokenizing train dataset:  10%|█         | 2423/24227 [00:08<01:14, 292.81 examples/s]Tokenizing train dataset:  10%|█         | 2456/24227 [00:08<01:23, 261.32 examples/s]Tokenizing train dataset:  10%|▉         | 2400/24227 [00:07<01:17, 279.99 examples/s]Tokenizing train dataset:  10%|█         | 2462/24227 [00:08<01:18, 278.70 examples/s]Tokenizing train dataset:  10%|█         | 2491/24227 [00:08<01:17, 279.19 examples/s]Tokenizing train dataset:  10%|█         | 2431/24227 [00:08<01:16, 284.05 examples/s]Tokenizing train dataset:  10%|█         | 2497/24227 [00:08<01:15, 288.94 examples/s]Tokenizing train dataset:  10%|█         | 2524/24227 [00:08<01:24, 256.56 examples/s]Tokenizing train dataset:  10%|█         | 2475/24227 [00:08<01:16, 285.84 examples/s]Tokenizing train dataset:  10%|█         | 2530/24227 [00:08<01:22, 263.32 examples/s]Tokenizing train dataset:  11%|█         | 2558/24227 [00:08<01:19, 271.89 examples/s]Tokenizing train dataset:  10%|█         | 2513/24227 [00:08<01:19, 273.48 examples/s]Tokenizing train dataset:  11%|█         | 2567/24227 [00:08<01:15, 286.37 examples/s]Tokenizing train dataset:  11%|█         | 2592/24227 [00:08<01:15, 287.61 examples/s]Tokenizing train dataset:  11%|█         | 2602/24227 [00:08<01:11, 302.16 examples/s]Tokenizing train dataset:  11%|█         | 2626/24227 [00:08<01:12, 299.31 examples/s]Tokenizing train dataset:  11%|█         | 2558/24227 [00:08<01:17, 279.40 examples/s]Tokenizing train dataset:  11%|█         | 2659/24227 [00:08<01:10, 304.23 examples/s]Tokenizing train dataset:  11%|█         | 2592/24227 [00:08<01:14, 291.76 examples/s]Tokenizing train dataset:  11%|█         | 2649/24227 [00:08<01:11, 303.50 examples/s]Tokenizing train dataset:  11%|█         | 2692/24227 [00:08<01:09, 310.95 examples/s]Tokenizing train dataset:  11%|█         | 2626/24227 [00:08<01:11, 302.35 examples/s]Tokenizing train dataset:  11%|█         | 2683/24227 [00:08<01:09, 308.22 examples/s]Tokenizing train dataset:  11%|█         | 2725/24227 [00:09<01:08, 312.00 examples/s]Tokenizing train dataset:  11%|█         | 2659/24227 [00:08<01:10, 305.89 examples/s]Tokenizing train dataset:  11%|█         | 2718/24227 [00:09<01:07, 317.60 examples/s]Tokenizing train dataset:  11%|█         | 2692/24227 [00:08<01:09, 311.08 examples/s]Tokenizing train dataset:  11%|█▏        | 2767/24227 [00:09<01:12, 297.85 examples/s]Tokenizing train dataset:  11%|█▏        | 2761/24227 [00:09<01:11, 301.77 examples/s]Tokenizing train dataset:  11%|█         | 2725/24227 [00:09<01:09, 311.43 examples/s]Tokenizing train dataset:  12%|█▏        | 2800/24227 [00:09<01:10, 302.82 examples/s]Tokenizing train dataset:  12%|█▏        | 2793/24227 [00:09<01:10, 303.33 examples/s]Tokenizing train dataset:  11%|█▏        | 2767/24227 [00:09<01:12, 297.66 examples/s]Tokenizing train dataset:  12%|█▏        | 2845/24227 [00:09<01:12, 295.34 examples/s]Tokenizing train dataset:  12%|█▏        | 2839/24227 [00:09<01:11, 298.40 examples/s]Tokenizing train dataset:  12%|█▏        | 2800/24227 [00:09<01:10, 302.23 examples/s]Tokenizing train dataset:  12%|█▏        | 2875/24227 [00:09<01:12, 295.57 examples/s]Tokenizing train dataset:  12%|█▏        | 2881/24227 [00:09<01:13, 291.06 examples/s]Tokenizing train dataset:  12%|█▏        | 2906/24227 [00:09<01:11, 297.14 examples/s]Tokenizing train dataset:  12%|█▏        | 2845/24227 [00:09<01:12, 295.18 examples/s]Tokenizing train dataset:  12%|█▏        | 2915/24227 [00:09<01:11, 296.01 examples/s]Tokenizing train dataset:  12%|█▏        | 2937/24227 [00:09<01:11, 296.41 examples/s]Tokenizing train dataset:  12%|█▏        | 2876/24227 [00:09<01:12, 295.84 examples/s]Tokenizing train dataset:  12%|█▏        | 2950/24227 [00:09<01:10, 301.46 examples/s]Tokenizing train dataset:  12%|█▏        | 2967/24227 [00:09<01:12, 295.23 examples/s]Tokenizing train dataset:  12%|█▏        | 2907/24227 [00:09<01:12, 295.36 examples/s]Tokenizing train dataset:  12%|█▏        | 2998/24227 [00:10<01:11, 297.28 examples/s]Tokenizing train dataset:  12%|█▏        | 2938/24227 [00:09<01:11, 296.33 examples/s]Tokenizing train dataset:  12%|█▏        | 2994/24227 [00:09<01:11, 297.16 examples/s]Tokenizing train dataset:  13%|█▎        | 3029/24227 [00:10<01:11, 296.12 examples/s]Tokenizing train dataset:  12%|█▏        | 2969/24227 [00:09<01:11, 299.19 examples/s]Tokenizing train dataset:  12%|█▏        | 3026/24227 [00:10<01:10, 300.30 examples/s]Tokenizing train dataset:  13%|█▎        | 3071/24227 [00:10<01:13, 286.31 examples/s]Tokenizing train dataset:  12%|█▏        | 3015/24227 [00:10<01:11, 296.40 examples/s]Tokenizing train dataset:  13%|█▎        | 3069/24227 [00:10<01:12, 291.77 examples/s]Tokenizing train dataset:  13%|█▎        | 3102/24227 [00:10<01:12, 291.98 examples/s]Tokenizing train dataset:  13%|█▎        | 3048/24227 [00:10<01:11, 297.26 examples/s]Tokenizing train dataset:  13%|█▎        | 3102/24227 [00:10<01:12, 293.06 examples/s]Tokenizing train dataset:  13%|█▎        | 3133/24227 [00:10<01:12, 291.87 examples/s]Tokenizing train dataset:  13%|█▎        | 3133/24227 [00:10<01:11, 293.08 examples/s]Tokenizing train dataset:  13%|█▎        | 3090/24227 [00:10<01:13, 285.70 examples/s]Tokenizing train dataset:  13%|█▎        | 3178/24227 [00:10<01:12, 289.57 examples/s]Tokenizing train dataset:  13%|█▎        | 3122/24227 [00:10<01:12, 291.65 examples/s]Tokenizing train dataset:  13%|█▎        | 3178/24227 [00:10<01:12, 290.81 examples/s]Tokenizing train dataset:  13%|█▎        | 3210/24227 [00:10<01:11, 292.71 examples/s]Tokenizing train dataset:  13%|█▎        | 3210/24227 [00:10<01:11, 293.83 examples/s]Tokenizing train dataset:  13%|█▎        | 3167/24227 [00:10<01:12, 290.76 examples/s]Tokenizing train dataset:  13%|█▎        | 3242/24227 [00:10<01:10, 296.14 examples/s]Tokenizing train dataset:  13%|█▎        | 3242/24227 [00:10<01:10, 296.79 examples/s]Tokenizing train dataset:  13%|█▎        | 3200/24227 [00:10<01:10, 297.07 examples/s]Tokenizing train dataset:  14%|█▎        | 3274/24227 [00:10<01:10, 297.50 examples/s]Tokenizing train dataset:  14%|█▎        | 3274/24227 [00:10<01:10, 298.49 examples/s]Tokenizing train dataset:  13%|█▎        | 3230/24227 [00:10<01:11, 293.79 examples/s]Tokenizing train dataset:  14%|█▎        | 3306/24227 [00:11<01:09, 302.98 examples/s]Tokenizing train dataset:  14%|█▎        | 3307/24227 [00:11<01:08, 303.54 examples/s]Tokenizing train dataset:  13%|█▎        | 3264/24227 [00:10<01:08, 303.94 examples/s]Tokenizing train dataset:  14%|█▍        | 3352/24227 [00:11<01:09, 299.86 examples/s]Tokenizing train dataset:  14%|█▎        | 3295/24227 [00:10<01:09, 302.39 examples/s]Tokenizing train dataset:  14%|█▍        | 3353/24227 [00:11<01:09, 300.74 examples/s]Tokenizing train dataset:  14%|█▍        | 3390/24227 [00:11<01:15, 277.50 examples/s]Tokenizing train dataset:  14%|█▍        | 3340/24227 [00:11<01:11, 292.52 examples/s]Tokenizing train dataset:  14%|█▍        | 3390/24227 [00:11<01:14, 278.95 examples/s]Tokenizing train dataset:  14%|█▍        | 3419/24227 [00:11<01:14, 278.24 examples/s]Tokenizing train dataset:  14%|█▍        | 3371/24227 [00:11<01:11, 289.70 examples/s]Tokenizing train dataset:  14%|█▍        | 3419/24227 [00:11<01:14, 279.68 examples/s]Tokenizing train dataset:  14%|█▍        | 3456/24227 [00:11<01:19, 262.72 examples/s]Tokenizing train dataset:  14%|█▍        | 3410/24227 [00:11<01:15, 276.40 examples/s]Tokenizing train dataset:  14%|█▍        | 3456/24227 [00:11<01:18, 263.83 examples/s]Tokenizing train dataset:  14%|█▍        | 3490/24227 [00:11<01:23, 247.49 examples/s]Tokenizing train dataset:  14%|█▍        | 3449/24227 [00:11<01:17, 267.48 examples/s]Tokenizing train dataset:  14%|█▍        | 3490/24227 [00:11<01:23, 248.42 examples/s]Tokenizing train dataset:  15%|█▍        | 3535/24227 [00:11<01:10, 291.60 examples/s]Tokenizing train dataset:  15%|█▍        | 3535/24227 [00:11<01:10, 292.44 examples/s]Tokenizing train dataset:  14%|█▍        | 3483/24227 [00:11<01:23, 249.66 examples/s]Tokenizing train dataset:  15%|█▍        | 3572/24227 [00:12<01:07, 306.50 examples/s]Tokenizing train dataset:  15%|█▍        | 3572/24227 [00:11<01:07, 307.37 examples/s]Tokenizing train dataset:  15%|█▍        | 3527/24227 [00:11<01:10, 291.82 examples/s]Tokenizing train dataset:  15%|█▍        | 3617/24227 [00:12<01:08, 302.00 examples/s]Tokenizing train dataset:  15%|█▍        | 3559/24227 [00:11<01:09, 295.33 examples/s]Tokenizing train dataset:  15%|█▍        | 3619/24227 [00:12<01:07, 305.56 examples/s]Tokenizing train dataset:  15%|█▌        | 3651/24227 [00:12<01:06, 308.71 examples/s]Tokenizing train dataset:  15%|█▍        | 3592/24227 [00:12<01:08, 301.45 examples/s]Tokenizing train dataset:  15%|█▌        | 3652/24227 [00:12<01:06, 308.96 examples/s]Tokenizing train dataset:  15%|█▌        | 3683/24227 [00:12<01:06, 307.34 examples/s]Tokenizing train dataset:  15%|█▌        | 3684/24227 [00:12<01:06, 307.58 examples/s]Tokenizing train dataset:  15%|█▌        | 3640/24227 [00:12<01:07, 304.90 examples/s]Tokenizing train dataset:  15%|█▌        | 3725/24227 [00:12<01:09, 294.81 examples/s]Tokenizing train dataset:  15%|█▌        | 3674/24227 [00:12<01:05, 312.23 examples/s]Tokenizing train dataset:  15%|█▌        | 3727/24227 [00:12<01:09, 295.95 examples/s]Tokenizing train dataset:  16%|█▌        | 3759/24227 [00:12<01:07, 301.43 examples/s]Tokenizing train dataset:  15%|█▌        | 3714/24227 [00:12<01:10, 292.71 examples/s]Tokenizing train dataset:  16%|█▌        | 3773/24227 [00:12<01:09, 294.22 examples/s]Tokenizing train dataset:  16%|█▌        | 3804/24227 [00:12<01:08, 297.65 examples/s]Tokenizing train dataset:  16%|█▌        | 3805/24227 [00:12<01:08, 298.82 examples/s]Tokenizing train dataset:  16%|█▌        | 3760/24227 [00:12<01:09, 293.44 examples/s]Tokenizing train dataset:  16%|█▌        | 3838/24227 [00:12<01:06, 305.40 examples/s]Tokenizing train dataset:  16%|█▌        | 3839/24227 [00:12<01:06, 306.33 examples/s]Tokenizing train dataset:  16%|█▌        | 3791/24227 [00:12<01:09, 295.66 examples/s]Tokenizing train dataset:  16%|█▌        | 3871/24227 [00:12<01:05, 309.38 examples/s]Tokenizing train dataset:  16%|█▌        | 3872/24227 [00:12<01:06, 307.79 examples/s]Tokenizing train dataset:  16%|█▌        | 3830/24227 [00:12<01:05, 311.31 examples/s]Tokenizing train dataset:  16%|█▌        | 3914/24227 [00:13<01:08, 295.53 examples/s]Tokenizing train dataset:  16%|█▌        | 3863/24227 [00:12<01:05, 313.25 examples/s]Tokenizing train dataset:  16%|█▌        | 3916/24227 [00:13<01:08, 297.34 examples/s]Tokenizing train dataset:  16%|█▋        | 3959/24227 [00:13<01:09, 291.04 examples/s]Tokenizing train dataset:  16%|█▌        | 3902/24227 [00:13<01:10, 289.71 examples/s]Tokenizing train dataset:  16%|█▋        | 3959/24227 [00:13<01:09, 290.30 examples/s]Tokenizing train dataset:  16%|█▋        | 3990/24227 [00:13<01:10, 287.60 examples/s]Tokenizing train dataset:  16%|█▋        | 3990/24227 [00:13<01:10, 287.32 examples/s]Tokenizing train dataset:  16%|█▋        | 3941/24227 [00:13<01:13, 276.61 examples/s]Tokenizing train dataset:  17%|█▋        | 4021/24227 [00:13<01:09, 288.81 examples/s]Tokenizing train dataset:  17%|█▋        | 4021/24227 [00:13<01:09, 289.16 examples/s]Tokenizing train dataset:  16%|█▋        | 3975/24227 [00:13<01:10, 287.75 examples/s]Tokenizing train dataset:  17%|█▋        | 4051/24227 [00:13<01:09, 289.84 examples/s]Tokenizing train dataset:  17%|█▋        | 4051/24227 [00:13<01:09, 290.66 examples/s]Tokenizing train dataset:  17%|█▋        | 4007/24227 [00:13<01:10, 288.52 examples/s]Tokenizing train dataset:  17%|█▋        | 4084/24227 [00:13<01:07, 296.73 examples/s]Tokenizing train dataset:  17%|█▋        | 4084/24227 [00:13<01:07, 297.95 examples/s]Tokenizing train dataset:  17%|█▋        | 4038/24227 [00:13<01:09, 291.70 examples/s]Tokenizing train dataset:  17%|█▋        | 4117/24227 [00:13<01:06, 301.87 examples/s]Tokenizing train dataset:  17%|█▋        | 4117/24227 [00:13<01:06, 302.98 examples/s]Tokenizing train dataset:  17%|█▋        | 4150/24227 [00:13<01:05, 304.86 examples/s]Tokenizing train dataset:  17%|█▋        | 4084/24227 [00:13<01:08, 293.61 examples/s]Tokenizing train dataset:  17%|█▋        | 4150/24227 [00:13<01:05, 306.29 examples/s]Tokenizing train dataset:  17%|█▋        | 4185/24227 [00:14<01:04, 313.04 examples/s]Tokenizing train dataset:  17%|█▋        | 4117/24227 [00:13<01:07, 298.95 examples/s]Tokenizing train dataset:  17%|█▋        | 4185/24227 [00:13<01:03, 314.18 examples/s]Tokenizing train dataset:  17%|█▋        | 4218/24227 [00:14<01:03, 313.34 examples/s]Tokenizing train dataset:  17%|█▋        | 4150/24227 [00:13<01:06, 302.49 examples/s]Tokenizing train dataset:  17%|█▋        | 4218/24227 [00:14<01:03, 314.85 examples/s]Tokenizing train dataset:  17%|█▋        | 4185/24227 [00:14<01:04, 311.14 examples/s]Tokenizing train dataset:  18%|█▊        | 4262/24227 [00:14<01:05, 304.12 examples/s]Tokenizing train dataset:  18%|█▊        | 4262/24227 [00:14<01:05, 305.49 examples/s]Tokenizing train dataset:  17%|█▋        | 4218/24227 [00:14<01:04, 312.42 examples/s]Tokenizing train dataset:  18%|█▊        | 4306/24227 [00:14<01:07, 297.16 examples/s]Tokenizing train dataset:  18%|█▊        | 4306/24227 [00:14<01:06, 298.62 examples/s]Tokenizing train dataset:  18%|█▊        | 4262/24227 [00:14<01:05, 304.04 examples/s]Tokenizing train dataset:  18%|█▊        | 4340/24227 [00:14<01:06, 300.46 examples/s]Tokenizing train dataset:  18%|█▊        | 4340/24227 [00:14<01:05, 301.84 examples/s]Tokenizing train dataset:  18%|█▊        | 4306/24227 [00:14<01:07, 297.04 examples/s]Tokenizing train dataset:  18%|█▊        | 4384/24227 [00:14<01:07, 293.36 examples/s]Tokenizing train dataset:  18%|█▊        | 4384/24227 [00:14<01:07, 294.69 examples/s]Tokenizing train dataset:  18%|█▊        | 4340/24227 [00:14<01:06, 300.31 examples/s]Tokenizing train dataset:  18%|█▊        | 4419/24227 [00:14<01:04, 306.05 examples/s]Tokenizing train dataset:  18%|█▊        | 4419/24227 [00:14<01:04, 307.01 examples/s]Tokenizing train dataset:  18%|█▊        | 4384/24227 [00:14<01:07, 293.13 examples/s]Tokenizing train dataset:  18%|█▊        | 4466/24227 [00:14<01:05, 303.60 examples/s]Tokenizing train dataset:  18%|█▊        | 4466/24227 [00:14<01:04, 304.67 examples/s]Tokenizing train dataset:  18%|█▊        | 4419/24227 [00:14<01:04, 305.59 examples/s]Tokenizing train dataset:  19%|█▊        | 4497/24227 [00:15<01:05, 299.84 examples/s]Tokenizing train dataset:  19%|█▊        | 4510/24227 [00:15<01:06, 296.36 examples/s]Tokenizing train dataset:  18%|█▊        | 4466/24227 [00:14<01:05, 303.32 examples/s]Tokenizing train dataset:  19%|█▊        | 4539/24227 [00:15<01:07, 292.40 examples/s]Tokenizing train dataset:  19%|█▉        | 4556/24227 [00:15<01:06, 294.57 examples/s]Tokenizing train dataset:  19%|█▊        | 4510/24227 [00:15<01:06, 296.31 examples/s]Tokenizing train dataset:  19%|█▉        | 4570/24227 [00:15<01:07, 291.07 examples/s]Tokenizing train dataset:  19%|█▉        | 4602/24227 [00:15<01:06, 295.17 examples/s]Tokenizing train dataset:  19%|█▉        | 4603/24227 [00:15<01:05, 299.91 examples/s]Tokenizing train dataset:  19%|█▉        | 4556/24227 [00:15<01:06, 294.40 examples/s]Tokenizing train dataset:  19%|█▉        | 4647/24227 [00:15<01:07, 290.73 examples/s]Tokenizing train dataset:  19%|█▉        | 4647/24227 [00:15<01:07, 292.02 examples/s]Tokenizing train dataset:  19%|█▉        | 4602/24227 [00:15<01:06, 295.23 examples/s]Tokenizing train dataset:  19%|█▉        | 4677/24227 [00:15<01:07, 288.98 examples/s]Tokenizing train dataset:  19%|█▉        | 4677/24227 [00:15<01:07, 290.05 examples/s]Tokenizing train dataset:  19%|█▉        | 4647/24227 [00:15<01:07, 290.80 examples/s]Tokenizing train dataset:  19%|█▉        | 4707/24227 [00:15<01:07, 289.02 examples/s]Tokenizing train dataset:  19%|█▉        | 4720/24227 [00:15<01:08, 285.93 examples/s]Tokenizing train dataset:  19%|█▉        | 4677/24227 [00:15<01:07, 289.04 examples/s]Tokenizing train dataset:  20%|█▉        | 4739/24227 [00:15<01:06, 294.52 examples/s]Tokenizing train dataset:  20%|█▉        | 4753/24227 [00:15<01:06, 294.19 examples/s]Tokenizing train dataset:  19%|█▉        | 4706/24227 [00:15<01:07, 288.21 examples/s]Tokenizing train dataset:  20%|█▉        | 4769/24227 [00:15<01:06, 293.09 examples/s]Tokenizing train dataset:  20%|█▉        | 4795/24227 [00:16<01:07, 286.32 examples/s]Tokenizing train dataset:  20%|█▉        | 4736/24227 [00:15<01:07, 288.17 examples/s]Tokenizing train dataset:  20%|█▉        | 4814/24227 [00:16<01:06, 293.73 examples/s]Tokenizing train dataset:  20%|█▉        | 4767/24227 [00:16<01:06, 291.75 examples/s]Tokenizing train dataset:  20%|█▉        | 4836/24227 [00:16<01:09, 279.78 examples/s]Tokenizing train dataset:  20%|██        | 4853/24227 [00:16<01:10, 276.31 examples/s]Tokenizing train dataset:  20%|██        | 4865/24227 [00:16<01:09, 277.58 examples/s]Tokenizing train dataset:  20%|█▉        | 4812/24227 [00:16<01:06, 289.93 examples/s]Tokenizing train dataset:  20%|██        | 4895/24227 [00:16<01:08, 281.95 examples/s]Tokenizing train dataset:  20%|██        | 4897/24227 [00:16<01:09, 278.69 examples/s]Tokenizing train dataset:  20%|██        | 4851/24227 [00:16<01:10, 276.07 examples/s]Tokenizing train dataset:  20%|██        | 4924/24227 [00:16<01:09, 279.54 examples/s]Tokenizing train dataset:  20%|██        | 4927/24227 [00:16<01:09, 277.26 examples/s]Tokenizing train dataset:  20%|██        | 4879/24227 [00:16<01:10, 274.15 examples/s]Tokenizing train dataset:  20%|██        | 4964/24227 [00:16<01:11, 268.57 examples/s]Tokenizing train dataset:  20%|██        | 4910/24227 [00:16<01:08, 281.39 examples/s]Tokenizing train dataset:  21%|██        | 4967/24227 [00:16<01:11, 269.42 examples/s]Tokenizing train dataset:  21%|██        | 4998/24227 [00:16<01:07, 283.87 examples/s]Tokenizing train dataset:  20%|██        | 4941/24227 [00:16<01:07, 284.69 examples/s]Tokenizing train dataset:  21%|██        | 5000/24227 [00:16<01:08, 278.80 examples/s]Tokenizing train dataset:  21%|██        | 5032/24227 [00:16<01:04, 295.52 examples/s]Tokenizing train dataset:  21%|██        | 5039/24227 [00:16<01:04, 298.65 examples/s]Tokenizing train dataset:  21%|██        | 4980/24227 [00:16<01:11, 270.23 examples/s]Tokenizing train dataset:  21%|██        | 5063/24227 [00:17<01:04, 297.28 examples/s]Tokenizing train dataset:  21%|██        | 5070/24227 [00:17<01:05, 293.06 examples/s]Tokenizing train dataset:  21%|██        | 5014/24227 [00:16<01:08, 282.15 examples/s]Tokenizing train dataset:  21%|██        | 5104/24227 [00:17<01:06, 285.92 examples/s]Tokenizing train dataset:  21%|██        | 5100/24227 [00:17<01:06, 289.73 examples/s]Tokenizing train dataset:  21%|██        | 5050/24227 [00:17<01:04, 298.35 examples/s]Tokenizing train dataset:  21%|██        | 5137/24227 [00:17<01:05, 291.43 examples/s]Tokenizing train dataset:  21%|██        | 5131/24227 [00:17<01:05, 292.64 examples/s]Tokenizing train dataset:  21%|██        | 5093/24227 [00:17<01:06, 289.60 examples/s]Tokenizing train dataset:  21%|██▏       | 5180/24227 [00:17<01:06, 284.97 examples/s]Tokenizing train dataset:  21%|██▏       | 5175/24227 [00:17<01:07, 284.20 examples/s]Tokenizing train dataset:  21%|██        | 5138/24227 [00:17<01:05, 289.97 examples/s]Tokenizing train dataset:  22%|██▏       | 5210/24227 [00:17<01:06, 284.91 examples/s]Tokenizing train dataset:  21%|██▏       | 5206/24227 [00:17<01:06, 285.81 examples/s]Tokenizing train dataset:  22%|██▏       | 5242/24227 [00:17<01:05, 291.06 examples/s]Tokenizing train dataset:  22%|██▏       | 5239/24227 [00:17<01:04, 295.90 examples/s]Tokenizing train dataset:  21%|██▏       | 5181/24227 [00:17<01:07, 283.02 examples/s]Tokenizing train dataset:  22%|██▏       | 5211/24227 [00:17<01:06, 286.37 examples/s]Tokenizing train dataset:  22%|██▏       | 5283/24227 [00:17<01:08, 277.68 examples/s]Tokenizing train dataset:  22%|██▏       | 5278/24227 [00:17<01:07, 280.89 examples/s]Tokenizing train dataset:  22%|██▏       | 5242/24227 [00:17<01:05, 290.77 examples/s]Tokenizing train dataset:  22%|██▏       | 5320/24227 [00:18<01:12, 260.32 examples/s]Tokenizing train dataset:  22%|██▏       | 5315/24227 [00:17<01:11, 264.24 examples/s]Tokenizing train dataset:  22%|██▏       | 5283/24227 [00:17<01:08, 277.90 examples/s]Tokenizing train dataset:  22%|██▏       | 5351/24227 [00:18<01:09, 269.98 examples/s]Tokenizing train dataset:  22%|██▏       | 5344/24227 [00:18<01:10, 268.51 examples/s]Tokenizing train dataset:  22%|██▏       | 5391/24227 [00:18<01:02, 301.76 examples/s]Tokenizing train dataset:  22%|██▏       | 5385/24227 [00:18<01:02, 302.27 examples/s]Tokenizing train dataset:  22%|██▏       | 5320/24227 [00:18<01:12, 260.90 examples/s]Tokenizing train dataset:  22%|██▏       | 5423/24227 [00:18<01:01, 304.38 examples/s]Tokenizing train dataset:  22%|██▏       | 5351/24227 [00:18<01:09, 270.23 examples/s]Tokenizing train dataset:  22%|██▏       | 5433/24227 [00:18<01:01, 306.66 examples/s]Tokenizing train dataset:  22%|██▏       | 5390/24227 [00:18<01:03, 294.49 examples/s]Tokenizing train dataset:  23%|██▎       | 5460/24227 [00:18<01:07, 279.94 examples/s]Tokenizing train dataset:  23%|██▎       | 5480/24227 [00:18<01:02, 302.08 examples/s]Tokenizing train dataset:  22%|██▏       | 5422/24227 [00:18<01:02, 299.39 examples/s]Tokenizing train dataset:  23%|██▎       | 5492/24227 [00:18<01:05, 287.28 examples/s]Tokenizing train dataset:  23%|██▎       | 5514/24227 [00:18<01:00, 308.08 examples/s]Tokenizing train dataset:  23%|██▎       | 5453/24227 [00:18<01:02, 300.53 examples/s]Tokenizing train dataset:  23%|██▎       | 5524/24227 [00:18<01:03, 293.98 examples/s]Tokenizing train dataset:  23%|██▎       | 5486/24227 [00:18<01:01, 304.63 examples/s]Tokenizing train dataset:  23%|██▎       | 5556/24227 [00:18<01:03, 295.77 examples/s]Tokenizing train dataset:  23%|██▎       | 5567/24227 [00:18<01:04, 289.97 examples/s]Tokenizing train dataset:  23%|██▎       | 5518/24227 [00:18<01:00, 307.77 examples/s]Tokenizing train dataset:  23%|██▎       | 5599/24227 [00:18<00:56, 326.86 examples/s]Tokenizing train dataset:  23%|██▎       | 5610/24227 [00:18<00:57, 322.22 examples/s]Tokenizing train dataset:  23%|██▎       | 5562/24227 [00:18<01:03, 294.70 examples/s]Tokenizing train dataset:  23%|██▎       | 5649/24227 [00:18<00:57, 324.95 examples/s]Tokenizing train dataset:  23%|██▎       | 5662/24227 [00:19<00:56, 327.42 examples/s]Tokenizing train dataset:  23%|██▎       | 5606/24227 [00:18<00:56, 329.40 examples/s]Tokenizing train dataset:  23%|██▎       | 5687/24227 [00:19<00:55, 333.96 examples/s]Tokenizing train dataset:  24%|██▎       | 5697/24227 [00:19<00:56, 329.93 examples/s]Tokenizing train dataset:  23%|██▎       | 5654/24227 [00:19<00:57, 325.12 examples/s]Tokenizing train dataset:  24%|██▎       | 5732/24227 [00:19<00:57, 319.80 examples/s]Tokenizing train dataset:  24%|██▎       | 5744/24227 [00:19<00:58, 316.82 examples/s]Tokenizing train dataset:  23%|██▎       | 5691/24227 [00:19<00:55, 332.27 examples/s]Tokenizing train dataset:  24%|██▍       | 5773/24227 [00:19<01:01, 299.61 examples/s]Tokenizing train dataset:  24%|██▍       | 5785/24227 [00:19<01:01, 299.60 examples/s]Tokenizing train dataset:  24%|██▎       | 5738/24227 [00:19<00:57, 321.51 examples/s]Tokenizing train dataset:  24%|██▍       | 5817/24227 [00:19<01:00, 302.74 examples/s]Tokenizing train dataset:  24%|██▍       | 5826/24227 [00:19<00:59, 309.01 examples/s]Tokenizing train dataset:  24%|██▍       | 5777/24227 [00:19<01:01, 298.76 examples/s]Tokenizing train dataset:  24%|██▍       | 5857/24227 [00:19<00:56, 322.97 examples/s]Tokenizing train dataset:  24%|██▍       | 5863/24227 [00:19<00:57, 321.84 examples/s]Tokenizing train dataset:  24%|██▍       | 5891/24227 [00:19<00:56, 322.82 examples/s]Tokenizing train dataset:  24%|██▍       | 5896/24227 [00:19<00:57, 321.29 examples/s]Tokenizing train dataset:  24%|██▍       | 5828/24227 [00:19<00:59, 307.79 examples/s]Tokenizing train dataset:  24%|██▍       | 5868/24227 [00:19<00:56, 324.78 examples/s]Tokenizing train dataset:  25%|██▍       | 5936/24227 [00:19<00:58, 311.19 examples/s]Tokenizing train dataset:  25%|██▍       | 5941/24227 [00:19<00:59, 309.35 examples/s]Tokenizing train dataset:  24%|██▍       | 5911/24227 [00:19<00:59, 305.55 examples/s]Tokenizing train dataset:  25%|██▍       | 5979/24227 [00:20<01:01, 298.70 examples/s]Tokenizing train dataset:  25%|██▍       | 5985/24227 [00:20<01:00, 301.89 examples/s]Tokenizing train dataset:  25%|██▍       | 5946/24227 [00:19<00:59, 309.80 examples/s]Tokenizing train dataset:  25%|██▍       | 6023/24227 [00:20<01:02, 290.59 examples/s]Tokenizing train dataset:  25%|██▍       | 6028/24227 [00:20<01:01, 293.85 examples/s]Tokenizing train dataset:  25%|██▍       | 5990/24227 [00:20<01:00, 299.49 examples/s]Tokenizing train dataset:  25%|██▌       | 6058/24227 [00:20<01:00, 302.40 examples/s]Tokenizing train dataset:  25%|██▌       | 6064/24227 [00:20<00:59, 306.02 examples/s]Tokenizing train dataset:  25%|██▌       | 6096/24227 [00:20<00:56, 320.49 examples/s]Tokenizing train dataset:  25%|██▌       | 6100/24227 [00:20<00:57, 317.08 examples/s]Tokenizing train dataset:  25%|██▍       | 6035/24227 [00:20<01:01, 296.76 examples/s]Tokenizing train dataset:  25%|██▌       | 6133/24227 [00:20<00:54, 328.98 examples/s]Tokenizing train dataset:  25%|██▌       | 6140/24227 [00:20<00:53, 335.92 examples/s]Tokenizing train dataset:  25%|██▌       | 6071/24227 [00:20<00:58, 309.12 examples/s]Tokenizing train dataset:  25%|██▌       | 6169/24227 [00:20<00:53, 334.53 examples/s]Tokenizing train dataset:  25%|██▌       | 6175/24227 [00:20<00:53, 337.16 examples/s]Tokenizing train dataset:  25%|██▌       | 6108/24227 [00:20<00:56, 318.73 examples/s]Tokenizing train dataset:  26%|██▌       | 6204/24227 [00:20<00:53, 334.92 examples/s]Tokenizing train dataset:  26%|██▌       | 6210/24227 [00:20<00:53, 337.53 examples/s]Tokenizing train dataset:  25%|██▌       | 6147/24227 [00:20<00:53, 335.79 examples/s]Tokenizing train dataset:  26%|██▌       | 6239/24227 [00:20<00:53, 336.57 examples/s]Tokenizing train dataset:  26%|██▌       | 6245/24227 [00:20<00:53, 336.47 examples/s]Tokenizing train dataset:  26%|██▌       | 6198/24227 [00:20<00:54, 333.21 examples/s]Tokenizing train dataset:  26%|██▌       | 6280/24227 [00:21<00:50, 356.25 examples/s]Tokenizing train dataset:  26%|██▌       | 6286/24227 [00:20<00:50, 355.53 examples/s]Tokenizing train dataset:  26%|██▌       | 6232/24227 [00:20<00:54, 331.55 examples/s]Tokenizing train dataset:  26%|██▌       | 6316/24227 [00:21<00:50, 354.83 examples/s]Tokenizing train dataset:  26%|██▌       | 6322/24227 [00:21<00:50, 354.75 examples/s]Tokenizing train dataset:  26%|██▌       | 6276/24227 [00:20<00:50, 355.77 examples/s]Tokenizing train dataset:  26%|██▌       | 6356/24227 [00:21<00:48, 365.80 examples/s]Tokenizing train dataset:  26%|██▋       | 6363/24227 [00:21<00:48, 367.61 examples/s]Tokenizing train dataset:  26%|██▌       | 6332/24227 [00:21<00:50, 357.47 examples/s]Tokenizing train dataset:  26%|██▋       | 6411/24227 [00:21<00:49, 360.44 examples/s]Tokenizing train dataset:  26%|██▋       | 6418/24227 [00:21<00:48, 365.62 examples/s]Tokenizing train dataset:  26%|██▋       | 6371/24227 [00:21<00:48, 365.19 examples/s]Tokenizing train dataset:  27%|██▋       | 6456/24227 [00:21<00:48, 368.89 examples/s]Tokenizing train dataset:  27%|██▋       | 6450/24227 [00:21<00:48, 362.98 examples/s]Tokenizing train dataset:  26%|██▋       | 6408/24227 [00:21<00:49, 360.79 examples/s]Tokenizing train dataset:  27%|██▋       | 6488/24227 [00:21<00:49, 361.56 examples/s]Tokenizing train dataset:  27%|██▋       | 6510/24227 [00:21<00:49, 360.78 examples/s]Tokenizing train dataset:  27%|██▋       | 6446/24227 [00:21<00:48, 364.34 examples/s]Tokenizing train dataset:  27%|██▋       | 6541/24227 [00:21<00:49, 356.15 examples/s]Tokenizing train dataset:  27%|██▋       | 6565/24227 [00:21<00:49, 359.83 examples/s]Tokenizing train dataset:  27%|██▋       | 6502/24227 [00:21<00:48, 364.66 examples/s]Tokenizing train dataset:  27%|██▋       | 6578/24227 [00:21<00:49, 358.02 examples/s]Tokenizing train dataset:  27%|██▋       | 6621/24227 [00:21<00:48, 359.89 examples/s]Tokenizing train dataset:  27%|██▋       | 6616/24227 [00:21<00:48, 359.58 examples/s]Tokenizing train dataset:  27%|██▋       | 6554/24227 [00:21<00:49, 355.82 examples/s]Tokenizing train dataset:  27%|██▋       | 6656/24227 [00:22<00:47, 369.26 examples/s]Tokenizing train dataset:  28%|██▊       | 6663/24227 [00:21<00:47, 369.33 examples/s]Tokenizing train dataset:  27%|██▋       | 6607/24227 [00:21<00:49, 353.15 examples/s]Tokenizing train dataset:  28%|██▊       | 6709/24227 [00:22<00:48, 360.24 examples/s]Tokenizing train dataset:  28%|██▊       | 6719/24227 [00:22<00:48, 364.45 examples/s]Tokenizing train dataset:  27%|██▋       | 6649/24227 [00:22<00:48, 363.77 examples/s]Tokenizing train dataset:  28%|██▊       | 6747/24227 [00:22<00:48, 358.93 examples/s]Tokenizing train dataset:  28%|██▊       | 6687/24227 [00:22<00:48, 365.12 examples/s]Tokenizing train dataset:  28%|██▊       | 6772/24227 [00:22<00:48, 356.52 examples/s]Tokenizing train dataset:  28%|██▊       | 6800/24227 [00:22<00:49, 355.48 examples/s]Tokenizing train dataset:  28%|██▊       | 6813/24227 [00:22<00:47, 363.00 examples/s]Tokenizing train dataset:  28%|██▊       | 6742/24227 [00:22<00:48, 359.38 examples/s]Tokenizing train dataset:  28%|██▊       | 6838/24227 [00:22<00:48, 357.07 examples/s]Tokenizing train dataset:  28%|██▊       | 6866/24227 [00:22<00:48, 355.03 examples/s]Tokenizing train dataset:  28%|██▊       | 6796/24227 [00:22<00:49, 355.23 examples/s]Tokenizing train dataset:  28%|██▊       | 6876/24227 [00:22<00:48, 361.23 examples/s]Tokenizing train dataset:  29%|██▊       | 6910/24227 [00:22<00:46, 370.50 examples/s]Tokenizing train dataset:  28%|██▊       | 6834/24227 [00:22<00:48, 358.94 examples/s]Tokenizing train dataset:  29%|██▊       | 6919/24227 [00:22<00:46, 376.10 examples/s]Tokenizing train dataset:  29%|██▊       | 6952/24227 [00:22<00:45, 380.88 examples/s]Tokenizing train dataset:  29%|██▊       | 6961/24227 [00:22<00:45, 382.42 examples/s]Tokenizing train dataset:  28%|██▊       | 6893/24227 [00:22<00:47, 367.96 examples/s]Tokenizing train dataset:  29%|██▉       | 7010/24227 [00:22<00:45, 376.13 examples/s]Tokenizing train dataset:  29%|██▊       | 6930/24227 [00:22<00:47, 365.98 examples/s]Tokenizing train dataset:  29%|██▉       | 7016/24227 [00:23<00:46, 374.04 examples/s]Tokenizing train dataset:  29%|██▉       | 6972/24227 [00:22<00:45, 375.87 examples/s]Tokenizing train dataset:  29%|██▉       | 7061/24227 [00:23<00:47, 360.92 examples/s]Tokenizing train dataset:  29%|██▉       | 7070/24227 [00:23<00:47, 364.85 examples/s]Tokenizing train dataset:  29%|██▉       | 7010/24227 [00:22<00:45, 376.49 examples/s]Tokenizing train dataset:  29%|██▉       | 7101/24227 [00:23<00:46, 368.43 examples/s]Tokenizing train dataset:  29%|██▉       | 7108/24227 [00:23<00:46, 364.44 examples/s]Tokenizing train dataset:  29%|██▉       | 7061/24227 [00:23<00:47, 359.17 examples/s]Tokenizing train dataset:  30%|██▉       | 7155/24227 [00:23<00:47, 363.05 examples/s]Tokenizing train dataset:  30%|██▉       | 7162/24227 [00:23<00:47, 360.48 examples/s]Tokenizing train dataset:  29%|██▉       | 7101/24227 [00:23<00:46, 367.52 examples/s]Tokenizing train dataset:  29%|██▉       | 7140/24227 [00:23<00:52, 325.27 examples/s]Tokenizing train dataset:  30%|██▉       | 7210/24227 [00:23<00:58, 290.79 examples/s]Tokenizing train dataset:  30%|██▉       | 7217/24227 [00:23<00:54, 309.97 examples/s]Tokenizing train dataset:  30%|██▉       | 7179/24227 [00:23<00:50, 338.86 examples/s]Tokenizing train dataset:  30%|██▉       | 7256/24227 [00:23<00:52, 325.94 examples/s]Tokenizing train dataset:  30%|██▉       | 7249/24227 [00:23<00:55, 308.33 examples/s]Tokenizing train dataset:  30%|██▉       | 7215/24227 [00:23<00:49, 341.44 examples/s]Tokenizing train dataset:  30%|███       | 7284/24227 [00:23<00:53, 315.77 examples/s]Tokenizing train dataset:  30%|███       | 7308/24227 [00:23<00:51, 330.61 examples/s]Tokenizing train dataset:  30%|██▉       | 7252/24227 [00:23<00:48, 346.45 examples/s]Tokenizing train dataset:  30%|███       | 7319/24227 [00:23<00:52, 322.24 examples/s]Tokenizing train dataset:  30%|███       | 7345/24227 [00:24<00:49, 339.05 examples/s]Tokenizing train dataset:  30%|███       | 7288/24227 [00:23<00:48, 346.99 examples/s]Tokenizing train dataset:  30%|███       | 7358/24227 [00:23<00:50, 336.47 examples/s]Tokenizing train dataset:  31%|███       | 7400/24227 [00:24<00:48, 344.26 examples/s]Tokenizing train dataset:  31%|███       | 7395/24227 [00:24<00:48, 343.81 examples/s]Tokenizing train dataset:  30%|███       | 7342/24227 [00:23<00:48, 350.40 examples/s]Tokenizing train dataset:  30%|███       | 7378/24227 [00:24<00:48, 350.86 examples/s]Tokenizing train dataset:  31%|███       | 7453/24227 [00:24<00:49, 342.03 examples/s]Tokenizing train dataset:  31%|███       | 7449/24227 [00:24<00:48, 343.33 examples/s]Tokenizing train dataset:  31%|███       | 7493/24227 [00:24<00:47, 353.48 examples/s]Tokenizing train dataset:  31%|███       | 7488/24227 [00:24<00:47, 352.12 examples/s]Tokenizing train dataset:  31%|███       | 7429/24227 [00:24<00:49, 342.20 examples/s]Tokenizing train dataset:  31%|███       | 7469/24227 [00:24<00:47, 353.63 examples/s]Tokenizing train dataset:  31%|███       | 7545/24227 [00:24<00:48, 342.92 examples/s]Tokenizing train dataset:  31%|███       | 7542/24227 [00:24<00:47, 347.69 examples/s]Tokenizing train dataset:  31%|███       | 7505/24227 [00:24<00:47, 351.01 examples/s]Tokenizing train dataset:  31%|███▏      | 7594/24227 [00:24<00:49, 334.66 examples/s]Tokenizing train dataset:  31%|███▏      | 7592/24227 [00:24<00:49, 336.44 examples/s]Tokenizing train dataset:  31%|███       | 7545/24227 [00:24<00:46, 355.27 examples/s]Tokenizing train dataset:  31%|███▏      | 7630/24227 [00:24<00:49, 335.06 examples/s]Tokenizing train dataset:  31%|███▏      | 7628/24227 [00:24<00:49, 338.29 examples/s]Tokenizing train dataset:  31%|███▏      | 7593/24227 [00:24<00:48, 341.76 examples/s]Tokenizing train dataset:  32%|███▏      | 7688/24227 [00:25<00:47, 349.02 examples/s]Tokenizing train dataset:  32%|███▏      | 7684/24227 [00:24<00:47, 346.55 examples/s]Tokenizing train dataset:  31%|███▏      | 7628/24227 [00:24<00:48, 341.96 examples/s]Tokenizing train dataset:  32%|███▏      | 7754/24227 [00:25<00:39, 421.61 examples/s]Tokenizing train dataset:  32%|███▏      | 7754/24227 [00:25<00:38, 424.81 examples/s]Tokenizing train dataset:  32%|███▏      | 7684/24227 [00:24<00:47, 349.00 examples/s]Tokenizing train dataset:  32%|███▏      | 7819/24227 [00:25<00:34, 475.49 examples/s]Tokenizing train dataset:  32%|███▏      | 7819/24227 [00:25<00:34, 478.64 examples/s]Tokenizing train dataset:  32%|███▏      | 7754/24227 [00:25<00:38, 429.77 examples/s]Tokenizing train dataset:  33%|███▎      | 7892/24227 [00:25<00:30, 540.26 examples/s]Tokenizing train dataset:  33%|███▎      | 7892/24227 [00:25<00:30, 543.35 examples/s]Tokenizing train dataset:  32%|███▏      | 7819/24227 [00:25<00:33, 483.23 examples/s]Tokenizing train dataset:  33%|███▎      | 7968/24227 [00:25<00:27, 596.81 examples/s]Tokenizing train dataset:  33%|███▎      | 7968/24227 [00:25<00:27, 600.23 examples/s]Tokenizing train dataset:  33%|███▎      | 7892/24227 [00:25<00:29, 547.06 examples/s]Tokenizing train dataset:  33%|███▎      | 8037/24227 [00:25<00:26, 621.93 examples/s]Tokenizing train dataset:  33%|███▎      | 8038/24227 [00:25<00:25, 622.70 examples/s]Tokenizing train dataset:  33%|███▎      | 7968/24227 [00:25<00:26, 603.30 examples/s]Tokenizing train dataset:  33%|███▎      | 8104/24227 [00:25<00:25, 633.55 examples/s]Tokenizing train dataset:  33%|███▎      | 8106/24227 [00:25<00:25, 636.94 examples/s]Tokenizing train dataset:  33%|███▎      | 8037/24227 [00:25<00:25, 626.67 examples/s]Tokenizing train dataset:  34%|███▍      | 8200/24227 [00:25<00:25, 629.02 examples/s]Tokenizing train dataset:  34%|███▍      | 8202/24227 [00:25<00:25, 634.65 examples/s]Tokenizing train dataset:  33%|███▎      | 8104/24227 [00:25<00:25, 636.46 examples/s]Tokenizing train dataset:  34%|███▍      | 8280/24227 [00:25<00:23, 671.36 examples/s]Tokenizing train dataset:  34%|███▍      | 8283/24227 [00:25<00:23, 678.53 examples/s]Tokenizing train dataset:  34%|███▍      | 8200/24227 [00:25<00:25, 629.57 examples/s]Tokenizing train dataset:  34%|███▍      | 8355/24227 [00:25<00:23, 689.81 examples/s]Tokenizing train dataset:  35%|███▍      | 8360/24227 [00:25<00:22, 697.89 examples/s]Tokenizing train dataset:  34%|███▍      | 8280/24227 [00:25<00:23, 672.18 examples/s]Tokenizing train dataset:  35%|███▍      | 8453/24227 [00:26<00:23, 672.56 examples/s]Tokenizing train dataset:  35%|███▍      | 8457/24227 [00:26<00:23, 671.99 examples/s]Tokenizing train dataset:  34%|███▍      | 8355/24227 [00:25<00:22, 690.47 examples/s]Tokenizing train dataset:  35%|███▌      | 8529/24227 [00:26<00:23, 675.98 examples/s]Tokenizing train dataset:  35%|███▌      | 8554/24227 [00:26<00:23, 671.20 examples/s]Tokenizing train dataset:  35%|███▍      | 8454/24227 [00:26<00:23, 670.70 examples/s]Tokenizing train dataset:  36%|███▌      | 8614/24227 [00:26<00:21, 719.76 examples/s]Tokenizing train dataset:  36%|███▌      | 8641/24227 [00:26<00:21, 717.20 examples/s]Tokenizing train dataset:  35%|███▌      | 8527/24227 [00:26<00:23, 682.07 examples/s]Tokenizing train dataset:  36%|███▌      | 8717/24227 [00:26<00:21, 725.03 examples/s]Tokenizing train dataset:  36%|███▌      | 8727/24227 [00:26<00:21, 729.03 examples/s]Tokenizing train dataset:  36%|███▌      | 8607/24227 [00:26<00:22, 709.33 examples/s]Tokenizing train dataset:  36%|███▌      | 8680/24227 [00:26<00:21, 712.08 examples/s]Tokenizing train dataset:  36%|███▋      | 8816/24227 [00:26<00:22, 696.35 examples/s]Tokenizing train dataset:  36%|███▋      | 8827/24227 [00:26<00:21, 702.62 examples/s]Tokenizing train dataset:  36%|███▌      | 8754/24227 [00:26<00:21, 717.55 examples/s]Tokenizing train dataset:  37%|███▋      | 8917/24227 [00:26<00:22, 686.28 examples/s]Tokenizing train dataset:  37%|███▋      | 8930/24227 [00:26<00:22, 692.32 examples/s]Tokenizing train dataset:  37%|███▋      | 8851/24227 [00:26<00:22, 683.55 examples/s]Tokenizing train dataset:  37%|███▋      | 8992/24227 [00:26<00:21, 700.27 examples/s]Tokenizing train dataset:  37%|███▋      | 9004/24227 [00:26<00:21, 698.18 examples/s]Tokenizing train dataset:  37%|███▋      | 8921/24227 [00:26<00:22, 685.99 examples/s]Tokenizing train dataset:  37%|███▋      | 9069/24227 [00:27<00:21, 716.80 examples/s]Tokenizing train dataset:  37%|███▋      | 9084/24227 [00:26<00:21, 714.64 examples/s]Tokenizing train dataset:  37%|███▋      | 8996/24227 [00:26<00:21, 701.18 examples/s]Tokenizing train dataset:  38%|███▊      | 9163/24227 [00:27<00:22, 678.81 examples/s]Tokenizing train dataset:  37%|███▋      | 9074/24227 [00:26<00:20, 722.75 examples/s]Tokenizing train dataset:  38%|███▊      | 9182/24227 [00:27<00:21, 691.60 examples/s]Tokenizing train dataset:  38%|███▊      | 9233/24227 [00:27<00:21, 682.30 examples/s]Tokenizing train dataset:  38%|███▊      | 9256/24227 [00:27<00:21, 702.41 examples/s]Tokenizing train dataset:  38%|███▊      | 9166/24227 [00:27<00:22, 680.05 examples/s]Tokenizing train dataset:  38%|███▊      | 9311/24227 [00:27<00:21, 705.29 examples/s]Tokenizing train dataset:  39%|███▊      | 9329/24227 [00:27<00:21, 707.91 examples/s]Tokenizing train dataset:  38%|███▊      | 9238/24227 [00:27<00:21, 687.65 examples/s]Tokenizing train dataset:  39%|███▉      | 9413/24227 [00:27<00:21, 689.57 examples/s]Tokenizing train dataset:  38%|███▊      | 9315/24227 [00:27<00:21, 708.26 examples/s]Tokenizing train dataset:  39%|███▉      | 9434/24227 [00:27<00:21, 699.89 examples/s]Tokenizing train dataset:  39%|███▉      | 9486/24227 [00:27<00:21, 697.04 examples/s]Tokenizing train dataset:  39%|███▉      | 9416/24227 [00:27<00:21, 691.55 examples/s]Tokenizing train dataset:  39%|███▉      | 9539/24227 [00:27<00:21, 698.31 examples/s]Tokenizing train dataset:  40%|███▉      | 9581/24227 [00:27<00:21, 672.78 examples/s]Tokenizing train dataset:  39%|███▉      | 9487/24227 [00:27<00:21, 694.32 examples/s]Tokenizing train dataset:  40%|███▉      | 9631/24227 [00:27<00:21, 669.13 examples/s]Tokenizing train dataset:  40%|███▉      | 9683/24227 [00:27<00:21, 668.57 examples/s]Tokenizing train dataset:  40%|████      | 9700/24227 [00:27<00:21, 671.31 examples/s]Tokenizing train dataset:  40%|███▉      | 9584/24227 [00:27<00:21, 671.31 examples/s]Tokenizing train dataset:  40%|████      | 9752/24227 [00:28<00:21, 672.65 examples/s]Tokenizing train dataset:  40%|████      | 9770/24227 [00:27<00:21, 675.92 examples/s]Tokenizing train dataset:  40%|███▉      | 9686/24227 [00:27<00:21, 669.35 examples/s]Tokenizing train dataset:  41%|████      | 9846/24227 [00:28<00:22, 653.24 examples/s]Tokenizing train dataset:  41%|████      | 9860/24227 [00:28<00:22, 643.28 examples/s]Tokenizing train dataset:  40%|████      | 9755/24227 [00:27<00:21, 666.26 examples/s]Tokenizing train dataset:  41%|████      | 9912/24227 [00:28<00:21, 653.55 examples/s]Tokenizing train dataset:  41%|████      | 9930/24227 [00:28<00:21, 651.85 examples/s]Tokenizing train dataset:  41%|████      | 9850/24227 [00:28<00:22, 649.40 examples/s]Tokenizing train dataset:  41%|████▏     | 9994/24227 [00:28<00:20, 695.38 examples/s]Tokenizing train dataset:  41%|████▏     | 10015/24227 [00:28<00:20, 701.46 examples/s]Tokenizing train dataset:  41%|████      | 9920/24227 [00:28<00:21, 659.41 examples/s]Tokenizing train dataset:  42%|████▏     | 10090/24227 [00:28<00:21, 670.65 examples/s]Tokenizing train dataset:  42%|████▏     | 10113/24227 [00:28<00:20, 681.08 examples/s]Tokenizing train dataset:  41%|████▏     | 9999/24227 [00:28<00:20, 692.03 examples/s]Tokenizing train dataset:  42%|████▏     | 10163/24227 [00:28<00:23, 606.45 examples/s]Tokenizing train dataset:  42%|████▏     | 10086/24227 [00:28<00:21, 645.42 examples/s]Tokenizing train dataset:  42%|████▏     | 10200/24227 [00:28<00:24, 569.63 examples/s]Tokenizing train dataset:  42%|████▏     | 10159/24227 [00:28<00:21, 660.66 examples/s]Tokenizing train dataset:  42%|████▏     | 10241/24227 [00:28<00:27, 517.93 examples/s]Tokenizing train dataset:  42%|████▏     | 10261/24227 [00:28<00:27, 515.76 examples/s]Tokenizing train dataset:  42%|████▏     | 10232/24227 [00:28<00:26, 534.04 examples/s]Tokenizing train dataset:  43%|████▎     | 10309/24227 [00:29<00:30, 450.46 examples/s]Tokenizing train dataset:  43%|████▎     | 10333/24227 [00:29<00:30, 453.28 examples/s]Tokenizing train dataset:  43%|████▎     | 10304/24227 [00:28<00:29, 465.06 examples/s]Tokenizing train dataset:  43%|████▎     | 10368/24227 [00:29<00:32, 432.35 examples/s]Tokenizing train dataset:  43%|████▎     | 10391/24227 [00:29<00:32, 430.13 examples/s]Tokenizing train dataset:  43%|████▎     | 10362/24227 [00:29<00:31, 440.10 examples/s]Tokenizing train dataset:  43%|████▎     | 10423/24227 [00:29<00:33, 411.00 examples/s]Tokenizing train dataset:  43%|████▎     | 10452/24227 [00:29<00:32, 421.46 examples/s]Tokenizing train dataset:  43%|████▎     | 10416/24227 [00:29<00:33, 415.74 examples/s]Tokenizing train dataset:  43%|████▎     | 10483/24227 [00:29<00:34, 401.69 examples/s]Tokenizing train dataset:  43%|████▎     | 10504/24227 [00:29<00:34, 398.72 examples/s]Tokenizing train dataset:  43%|████▎     | 10476/24227 [00:29<00:33, 407.91 examples/s]Tokenizing train dataset:  44%|████▎     | 10539/24227 [00:29<00:35, 385.64 examples/s]Tokenizing train dataset:  44%|████▎     | 10560/24227 [00:29<00:35, 386.73 examples/s]Tokenizing train dataset:  43%|████▎     | 10529/24227 [00:29<00:35, 387.75 examples/s]Tokenizing train dataset:  44%|████▎     | 10593/24227 [00:29<00:36, 374.51 examples/s]Tokenizing train dataset:  44%|████▍     | 10615/24227 [00:29<00:36, 376.68 examples/s]Tokenizing train dataset:  44%|████▎     | 10584/24227 [00:29<00:36, 378.14 examples/s]Tokenizing train dataset:  44%|████▍     | 10648/24227 [00:30<00:36, 369.75 examples/s]Tokenizing train dataset:  44%|████▍     | 10670/24227 [00:29<00:36, 368.33 examples/s]Tokenizing train dataset:  44%|████▍     | 10639/24227 [00:29<00:36, 371.16 examples/s]Tokenizing train dataset:  44%|████▍     | 10698/24227 [00:30<00:37, 356.39 examples/s]Tokenizing train dataset:  44%|████▍     | 10725/24227 [00:30<00:36, 366.41 examples/s]Tokenizing train dataset:  44%|████▍     | 10740/24227 [00:30<00:36, 366.63 examples/s]Tokenizing train dataset:  44%|████▍     | 10691/24227 [00:30<00:37, 357.12 examples/s]Tokenizing train dataset:  44%|████▍     | 10777/24227 [00:30<00:37, 356.76 examples/s]Tokenizing train dataset:  44%|████▍     | 10732/24227 [00:30<00:36, 367.97 examples/s]Tokenizing train dataset:  45%|████▍     | 10790/24227 [00:30<00:37, 354.24 examples/s]Tokenizing train dataset:  45%|████▍     | 10819/24227 [00:30<00:36, 366.43 examples/s]Tokenizing train dataset:  45%|████▍     | 10830/24227 [00:30<00:36, 362.51 examples/s]Tokenizing train dataset:  45%|████▍     | 10783/24227 [00:30<00:37, 355.33 examples/s]Tokenizing train dataset:  45%|████▍     | 10870/24227 [00:30<00:37, 353.53 examples/s]Tokenizing train dataset:  45%|████▍     | 10824/24227 [00:30<00:36, 365.01 examples/s]Tokenizing train dataset:  45%|████▍     | 10880/24227 [00:30<00:38, 349.10 examples/s]Tokenizing train dataset:  45%|████▌     | 10921/24227 [00:30<00:38, 347.60 examples/s]Tokenizing train dataset:  45%|████▍     | 10874/24227 [00:30<00:38, 349.64 examples/s]Tokenizing train dataset:  45%|████▌     | 10933/24227 [00:30<00:38, 347.68 examples/s]Tokenizing train dataset:  45%|████▌     | 10958/24227 [00:30<00:37, 352.40 examples/s]Tokenizing train dataset:  45%|████▌     | 10910/24227 [00:30<00:38, 347.03 examples/s]Tokenizing train dataset:  45%|████▌     | 10973/24227 [00:30<00:37, 356.19 examples/s]Tokenizing train dataset:  45%|████▌     | 10999/24227 [00:30<00:36, 362.90 examples/s]Tokenizing train dataset:  45%|████▌     | 10948/24227 [00:30<00:37, 351.42 examples/s]Tokenizing train dataset:  45%|████▌     | 11012/24227 [00:31<00:36, 361.59 examples/s]Tokenizing train dataset:  46%|████▌     | 11042/24227 [00:30<00:35, 376.25 examples/s]Tokenizing train dataset:  45%|████▌     | 10989/24227 [00:30<00:36, 365.23 examples/s]Tokenizing train dataset:  46%|████▌     | 11053/24227 [00:31<00:35, 373.68 examples/s]Tokenizing train dataset:  46%|████▌     | 11082/24227 [00:31<00:34, 378.02 examples/s]Tokenizing train dataset:  46%|████▌     | 11091/24227 [00:31<00:35, 373.37 examples/s]Tokenizing train dataset:  46%|████▌     | 11049/24227 [00:31<00:35, 376.04 examples/s]Tokenizing train dataset:  46%|████▌     | 11135/24227 [00:31<00:35, 365.25 examples/s]Tokenizing train dataset:  46%|████▌     | 11147/24227 [00:31<00:35, 368.46 examples/s]Tokenizing train dataset:  46%|████▌     | 11102/24227 [00:31<00:35, 364.85 examples/s]Tokenizing train dataset:  46%|████▌     | 11191/24227 [00:31<00:35, 364.59 examples/s]Tokenizing train dataset:  46%|████▌     | 11140/24227 [00:31<00:35, 366.90 examples/s]Tokenizing train dataset:  46%|████▌     | 11201/24227 [00:31<00:36, 361.67 examples/s]Tokenizing train dataset:  46%|████▋     | 11229/24227 [00:31<00:35, 366.24 examples/s]Tokenizing train dataset:  46%|████▌     | 11177/24227 [00:31<00:36, 362.06 examples/s]Tokenizing train dataset:  46%|████▋     | 11239/24227 [00:31<00:35, 362.79 examples/s]Tokenizing train dataset:  46%|████▋     | 11214/24227 [00:31<00:35, 361.84 examples/s]Tokenizing train dataset:  47%|████▋     | 11282/24227 [00:31<00:36, 357.25 examples/s]Tokenizing train dataset:  47%|████▋     | 11292/24227 [00:31<00:36, 353.57 examples/s]Tokenizing train dataset:  47%|████▋     | 11321/24227 [00:31<00:35, 359.98 examples/s]Tokenizing train dataset:  47%|████▋     | 11268/24227 [00:31<00:36, 355.74 examples/s]Tokenizing train dataset:  47%|████▋     | 11330/24227 [00:31<00:36, 357.88 examples/s]Tokenizing train dataset:  47%|████▋     | 11361/24227 [00:31<00:35, 367.56 examples/s]Tokenizing train dataset:  47%|████▋     | 11367/24227 [00:32<00:35, 357.38 examples/s]Tokenizing train dataset:  47%|████▋     | 11323/24227 [00:31<00:36, 355.84 examples/s]Tokenizing train dataset:  47%|████▋     | 11405/24227 [00:32<00:37, 337.75 examples/s]Tokenizing train dataset:  47%|████▋     | 11363/24227 [00:31<00:35, 362.09 examples/s]Tokenizing train dataset:  47%|████▋     | 11412/24227 [00:32<00:38, 334.82 examples/s]Tokenizing train dataset:  47%|████▋     | 11442/24227 [00:32<00:37, 344.04 examples/s]Tokenizing train dataset:  47%|████▋     | 11452/24227 [00:32<00:36, 348.69 examples/s]Tokenizing train dataset:  47%|████▋     | 11481/24227 [00:32<00:36, 353.97 examples/s]Tokenizing train dataset:  47%|████▋     | 11409/24227 [00:32<00:37, 337.58 examples/s]Tokenizing train dataset:  47%|████▋     | 11493/24227 [00:32<00:35, 358.54 examples/s]Tokenizing train dataset:  47%|████▋     | 11446/24227 [00:32<00:37, 344.65 examples/s]Tokenizing train dataset:  48%|████▊     | 11520/24227 [00:32<00:35, 358.48 examples/s]Tokenizing train dataset:  47%|████▋     | 11487/24227 [00:32<00:35, 359.45 examples/s]Tokenizing train dataset:  48%|████▊     | 11545/24227 [00:32<00:36, 349.92 examples/s]Tokenizing train dataset:  48%|████▊     | 11574/24227 [00:32<00:35, 356.51 examples/s]Tokenizing train dataset:  48%|████▊     | 11584/24227 [00:32<00:35, 355.98 examples/s]Tokenizing train dataset:  48%|████▊     | 11540/24227 [00:32<00:36, 350.96 examples/s]Tokenizing train dataset:  48%|████▊     | 11610/24227 [00:32<00:35, 352.80 examples/s]Tokenizing train dataset:  48%|████▊     | 11578/24227 [00:32<00:35, 354.88 examples/s]Tokenizing train dataset:  48%|████▊     | 11649/24227 [00:32<00:34, 360.43 examples/s]Tokenizing train dataset:  48%|████▊     | 11640/24227 [00:32<00:35, 355.27 examples/s]Tokenizing train dataset:  48%|████▊     | 11631/24227 [00:32<00:35, 351.41 examples/s]Tokenizing train dataset:  48%|████▊     | 11700/24227 [00:32<00:36, 347.75 examples/s]Tokenizing train dataset:  48%|████▊     | 11692/24227 [00:32<00:35, 348.72 examples/s]Tokenizing train dataset:  48%|████▊     | 11668/24227 [00:32<00:35, 349.72 examples/s]Tokenizing train dataset:  48%|████▊     | 11738/24227 [00:32<00:35, 352.09 examples/s]Tokenizing train dataset:  48%|████▊     | 11730/24227 [00:33<00:35, 349.85 examples/s]Tokenizing train dataset:  48%|████▊     | 11705/24227 [00:32<00:35, 353.87 examples/s]Tokenizing train dataset:  49%|████▊     | 11790/24227 [00:33<00:36, 344.09 examples/s]Tokenizing train dataset:  49%|████▊     | 11782/24227 [00:33<00:35, 346.31 examples/s]Tokenizing train dataset:  49%|████▊     | 11759/24227 [00:33<00:35, 351.01 examples/s]Tokenizing train dataset:  49%|████▉     | 11831/24227 [00:33<00:41, 299.66 examples/s]Tokenizing train dataset:  49%|████▉     | 11831/24227 [00:33<00:41, 300.40 examples/s]Tokenizing train dataset:  49%|████▊     | 11800/24227 [00:33<00:40, 305.72 examples/s]Tokenizing train dataset:  49%|████▉     | 11892/24227 [00:33<00:33, 369.38 examples/s]Tokenizing train dataset:  49%|████▉     | 11892/24227 [00:33<00:33, 365.13 examples/s]Tokenizing train dataset:  49%|████▉     | 11960/24227 [00:33<00:27, 444.39 examples/s]Tokenizing train dataset:  49%|████▉     | 11860/24227 [00:33<00:37, 333.77 examples/s]Tokenizing train dataset:  49%|████▉     | 11960/24227 [00:33<00:28, 436.88 examples/s]Tokenizing train dataset:  50%|████▉     | 12040/24227 [00:33<00:22, 533.68 examples/s]Tokenizing train dataset:  49%|████▉     | 11930/24227 [00:33<00:29, 414.96 examples/s]Tokenizing train dataset:  50%|████▉     | 12098/24227 [00:33<00:22, 544.78 examples/s]Tokenizing train dataset:  50%|████▉     | 12040/24227 [00:33<00:26, 458.45 examples/s]Tokenizing train dataset:  50%|████▉     | 11998/24227 [00:33<00:25, 478.07 examples/s]Tokenizing train dataset:  50%|█████     | 12170/24227 [00:33<00:20, 592.11 examples/s]Tokenizing train dataset:  50%|████▉     | 12108/24227 [00:33<00:23, 508.98 examples/s]Tokenizing train dataset:  50%|████▉     | 12074/24227 [00:33<00:22, 548.53 examples/s]Tokenizing train dataset:  51%|█████     | 12244/24227 [00:33<00:19, 630.37 examples/s]Tokenizing train dataset:  50%|█████     | 12180/24227 [00:34<00:21, 560.10 examples/s]Tokenizing train dataset:  50%|█████     | 12142/24227 [00:33<00:20, 581.50 examples/s]Tokenizing train dataset:  51%|█████     | 12319/24227 [00:34<00:18, 655.44 examples/s]Tokenizing train dataset:  51%|█████     | 12258/24227 [00:34<00:19, 614.46 examples/s]Tokenizing train dataset:  50%|█████     | 12218/24227 [00:33<00:19, 627.42 examples/s]Tokenizing train dataset:  51%|█████     | 12390/24227 [00:34<00:17, 668.67 examples/s]Tokenizing train dataset:  51%|█████     | 12327/24227 [00:34<00:18, 629.05 examples/s]Tokenizing train dataset:  51%|█████     | 12290/24227 [00:34<00:18, 647.49 examples/s]Tokenizing train dataset:  51%|█████     | 12399/24227 [00:34<00:18, 641.05 examples/s]Tokenizing train dataset:  51%|█████     | 12364/24227 [00:34<00:17, 667.43 examples/s]Tokenizing train dataset:  52%|█████▏    | 12490/24227 [00:34<00:17, 663.10 examples/s]Tokenizing train dataset:  51%|█████▏    | 12465/24227 [00:34<00:18, 641.11 examples/s]Tokenizing train dataset:  52%|█████▏    | 12561/24227 [00:34<00:17, 668.82 examples/s]Tokenizing train dataset:  51%|█████▏    | 12463/24227 [00:34<00:17, 657.14 examples/s]Tokenizing train dataset:  52%|█████▏    | 12532/24227 [00:34<00:18, 648.27 examples/s]Tokenizing train dataset:  52%|█████▏    | 12532/24227 [00:34<00:17, 657.43 examples/s]Tokenizing train dataset:  52%|█████▏    | 12670/24227 [00:34<00:16, 681.34 examples/s]Tokenizing train dataset:  52%|█████▏    | 12605/24227 [00:34<00:17, 659.86 examples/s]Tokenizing train dataset:  53%|█████▎    | 12741/24227 [00:34<00:16, 686.33 examples/s]Tokenizing train dataset:  52%|█████▏    | 12605/24227 [00:34<00:17, 665.90 examples/s]Tokenizing train dataset:  52%|█████▏    | 12684/24227 [00:34<00:16, 686.89 examples/s]Tokenizing train dataset:  52%|█████▏    | 12682/24227 [00:34<00:16, 693.78 examples/s]Tokenizing train dataset:  53%|█████▎    | 12820/24227 [00:34<00:16, 708.97 examples/s]Tokenizing train dataset:  53%|█████▎    | 12791/24227 [00:34<00:16, 693.34 examples/s]Tokenizing train dataset:  53%|█████▎    | 12920/24227 [00:34<00:16, 691.56 examples/s]Tokenizing train dataset:  53%|█████▎    | 12787/24227 [00:34<00:16, 691.72 examples/s]Tokenizing train dataset:  53%|█████▎    | 12862/24227 [00:34<00:16, 692.35 examples/s]Tokenizing train dataset:  53%|█████▎    | 12860/24227 [00:34<00:16, 699.28 examples/s]Tokenizing train dataset:  53%|█████▎    | 12936/24227 [00:35<00:16, 698.35 examples/s]Tokenizing train dataset:  54%|█████▎    | 13021/24227 [00:35<00:16, 679.13 examples/s]Tokenizing train dataset:  54%|█████▎    | 12964/24227 [00:34<00:16, 692.00 examples/s]Tokenizing train dataset:  54%|█████▍    | 13093/24227 [00:35<00:16, 684.74 examples/s]Tokenizing train dataset:  54%|█████▍    | 13034/24227 [00:35<00:16, 675.83 examples/s]Tokenizing train dataset:  54%|█████▍    | 13104/24227 [00:35<00:16, 673.88 examples/s]Tokenizing train dataset:  54%|█████▍    | 13068/24227 [00:35<00:16, 686.77 examples/s]Tokenizing train dataset:  54%|█████▍    | 13193/24227 [00:35<00:16, 671.00 examples/s]Tokenizing train dataset:  54%|█████▍    | 13172/24227 [00:35<00:16, 673.23 examples/s]Tokenizing train dataset:  54%|█████▍    | 13162/24227 [00:35<00:16, 663.81 examples/s]Tokenizing train dataset:  55%|█████▍    | 13282/24227 [00:35<00:17, 638.55 examples/s]Tokenizing train dataset:  55%|█████▍    | 13262/24227 [00:35<00:16, 645.02 examples/s]Tokenizing train dataset:  55%|█████▌    | 13348/24227 [00:35<00:16, 641.73 examples/s]Tokenizing train dataset:  55%|█████▍    | 13255/24227 [00:35<00:17, 643.49 examples/s]Tokenizing train dataset:  55%|█████▌    | 13355/24227 [00:35<00:17, 630.52 examples/s]Tokenizing train dataset:  55%|█████▌    | 13444/24227 [00:35<00:16, 634.58 examples/s]Tokenizing train dataset:  55%|█████▌    | 13349/24227 [00:35<00:17, 637.04 examples/s]Tokenizing train dataset:  56%|█████▌    | 13519/24227 [00:35<00:16, 660.23 examples/s]Tokenizing train dataset:  56%|█████▌    | 13452/24227 [00:35<00:17, 632.65 examples/s]Tokenizing train dataset:  55%|█████▌    | 13444/24227 [00:35<00:17, 631.53 examples/s]Tokenizing train dataset:  56%|█████▌    | 13590/24227 [00:35<00:15, 672.78 examples/s]Tokenizing train dataset:  56%|█████▌    | 13527/24227 [00:36<00:16, 655.13 examples/s]Tokenizing train dataset:  56%|█████▌    | 13518/24227 [00:35<00:16, 654.02 examples/s]Tokenizing train dataset:  56%|█████▋    | 13664/24227 [00:35<00:15, 688.98 examples/s]Tokenizing train dataset:  56%|█████▌    | 13599/24227 [00:36<00:15, 670.68 examples/s]Tokenizing train dataset:  56%|█████▌    | 13590/24227 [00:35<00:15, 667.43 examples/s]Tokenizing train dataset:  57%|█████▋    | 13743/24227 [00:36<00:14, 711.55 examples/s]Tokenizing train dataset:  56%|█████▋    | 13672/24227 [00:36<00:15, 685.78 examples/s]Tokenizing train dataset:  56%|█████▋    | 13664/24227 [00:36<00:15, 682.99 examples/s]Tokenizing train dataset:  57%|█████▋    | 13817/24227 [00:36<00:14, 718.60 examples/s]Tokenizing train dataset:  57%|█████▋    | 13750/24227 [00:36<00:14, 705.83 examples/s]Tokenizing train dataset:  57%|█████▋    | 13743/24227 [00:36<00:14, 705.44 examples/s]Tokenizing train dataset:  57%|█████▋    | 13897/24227 [00:36<00:13, 740.29 examples/s]Tokenizing train dataset:  57%|█████▋    | 13826/24227 [00:36<00:14, 719.37 examples/s]Tokenizing train dataset:  57%|█████▋    | 13817/24227 [00:36<00:14, 712.28 examples/s]Tokenizing train dataset:  57%|█████▋    | 13905/24227 [00:36<00:14, 736.78 examples/s]Tokenizing train dataset:  58%|█████▊    | 13991/24227 [00:36<00:14, 691.94 examples/s]Tokenizing train dataset:  57%|█████▋    | 13896/24227 [00:36<00:14, 733.12 examples/s]Tokenizing train dataset:  58%|█████▊    | 13998/24227 [00:36<00:14, 690.47 examples/s]Tokenizing train dataset:  58%|█████▊    | 14088/24227 [00:36<00:15, 664.99 examples/s]Tokenizing train dataset:  58%|█████▊    | 13990/24227 [00:36<00:14, 688.74 examples/s]Tokenizing train dataset:  58%|█████▊    | 14171/24227 [00:36<00:14, 697.82 examples/s]Tokenizing train dataset:  58%|█████▊    | 14092/24227 [00:36<00:15, 661.37 examples/s]Tokenizing train dataset:  58%|█████▊    | 14083/24227 [00:36<00:15, 661.27 examples/s]Tokenizing train dataset:  58%|█████▊    | 14172/24227 [00:36<00:14, 693.89 examples/s]Tokenizing train dataset:  59%|█████▉    | 14276/24227 [00:36<00:14, 691.62 examples/s]Tokenizing train dataset:  58%|█████▊    | 14165/24227 [00:36<00:14, 698.17 examples/s]Tokenizing train dataset:  59%|█████▉    | 14348/24227 [00:36<00:14, 696.24 examples/s]Tokenizing train dataset:  59%|█████▉    | 14276/24227 [00:37<00:14, 686.39 examples/s]Tokenizing train dataset:  59%|█████▉    | 14270/24227 [00:36<00:14, 686.92 examples/s]Tokenizing train dataset:  59%|█████▉    | 14348/24227 [00:37<00:14, 691.54 examples/s]Tokenizing train dataset:  60%|█████▉    | 14449/24227 [00:37<00:14, 682.84 examples/s]Tokenizing train dataset:  59%|█████▉    | 14343/24227 [00:37<00:14, 694.34 examples/s]Tokenizing train dataset:  60%|█████▉    | 14449/24227 [00:37<00:14, 678.27 examples/s]Tokenizing train dataset:  60%|██████    | 14548/24227 [00:37<00:14, 664.80 examples/s]Tokenizing train dataset:  60%|█████▉    | 14441/24227 [00:37<00:14, 674.69 examples/s]Tokenizing train dataset:  60%|██████    | 14619/24227 [00:37<00:14, 668.17 examples/s]Tokenizing train dataset:  60%|██████    | 14548/24227 [00:37<00:14, 660.80 examples/s]Tokenizing train dataset:  60%|██████    | 14538/24227 [00:37<00:14, 659.08 examples/s]Tokenizing train dataset:  61%|██████    | 14690/24227 [00:37<00:14, 674.42 examples/s]Tokenizing train dataset:  60%|██████    | 14619/24227 [00:37<00:14, 664.22 examples/s]Tokenizing train dataset:  60%|██████    | 14606/24227 [00:37<00:14, 662.24 examples/s]Tokenizing train dataset:  61%|██████    | 14690/24227 [00:37<00:14, 671.37 examples/s]Tokenizing train dataset:  61%|██████    | 14773/24227 [00:37<00:15, 627.24 examples/s]Tokenizing train dataset:  61%|██████    | 14677/24227 [00:37<00:14, 672.86 examples/s]Tokenizing train dataset:  61%|██████    | 14772/24227 [00:37<00:15, 623.00 examples/s]Tokenizing train dataset:  61%|██████    | 14759/24227 [00:37<00:15, 624.92 examples/s]Tokenizing train dataset:  61%|██████▏   | 14855/24227 [00:37<00:17, 534.91 examples/s]Tokenizing train dataset:  61%|██████▏   | 14855/24227 [00:38<00:17, 532.62 examples/s]Tokenizing train dataset:  61%|██████    | 14826/24227 [00:37<00:16, 558.20 examples/s]Tokenizing train dataset:  62%|██████▏   | 14913/24227 [00:38<00:19, 488.08 examples/s]Tokenizing train dataset:  62%|██████▏   | 14913/24227 [00:38<00:19, 485.68 examples/s]Tokenizing train dataset:  62%|██████▏   | 14964/24227 [00:38<00:20, 441.12 examples/s]Tokenizing train dataset:  62%|██████▏   | 14903/24227 [00:38<00:19, 488.74 examples/s]Tokenizing train dataset:  62%|██████▏   | 14964/24227 [00:38<00:21, 438.79 examples/s]Tokenizing train dataset:  62%|██████▏   | 15021/24227 [00:38<00:21, 420.19 examples/s]Tokenizing train dataset:  62%|██████▏   | 14955/24227 [00:38<00:20, 443.30 examples/s]Tokenizing train dataset:  62%|██████▏   | 15021/24227 [00:38<00:22, 418.28 examples/s]Tokenizing train dataset:  62%|██████▏   | 15080/24227 [00:38<00:22, 408.10 examples/s]Tokenizing train dataset:  62%|██████▏   | 15012/24227 [00:38<00:21, 419.49 examples/s]Tokenizing train dataset:  62%|██████▏   | 15080/24227 [00:38<00:22, 406.29 examples/s]Tokenizing train dataset:  62%|██████▏   | 15138/24227 [00:38<00:22, 397.32 examples/s]Tokenizing train dataset:  62%|██████▏   | 15071/24227 [00:38<00:22, 407.40 examples/s]Tokenizing train dataset:  62%|██████▏   | 15138/24227 [00:38<00:22, 395.66 examples/s]Tokenizing train dataset:  63%|██████▎   | 15196/24227 [00:38<00:23, 389.95 examples/s]Tokenizing train dataset:  62%|██████▏   | 15130/24227 [00:38<00:23, 394.73 examples/s]Tokenizing train dataset:  63%|██████▎   | 15196/24227 [00:39<00:23, 388.25 examples/s]Tokenizing train dataset:  63%|██████▎   | 15172/24227 [00:38<00:22, 397.35 examples/s]Tokenizing train dataset:  63%|██████▎   | 15252/24227 [00:38<00:23, 382.01 examples/s]Tokenizing train dataset:  63%|██████▎   | 15252/24227 [00:39<00:23, 380.02 examples/s]Tokenizing train dataset:  63%|██████▎   | 15226/24227 [00:38<00:23, 382.58 examples/s]Tokenizing train dataset:  63%|██████▎   | 15309/24227 [00:39<00:23, 378.42 examples/s]Tokenizing train dataset:  63%|██████▎   | 15309/24227 [00:39<00:23, 376.30 examples/s]Tokenizing train dataset:  63%|██████▎   | 15281/24227 [00:39<00:23, 374.90 examples/s]Tokenizing train dataset:  63%|██████▎   | 15360/24227 [00:39<00:24, 364.12 examples/s]Tokenizing train dataset:  64%|██████▎   | 15400/24227 [00:39<00:23, 367.88 examples/s]Tokenizing train dataset:  63%|██████▎   | 15360/24227 [00:39<00:24, 362.70 examples/s]Tokenizing train dataset:  63%|██████▎   | 15337/24227 [00:39<00:23, 373.27 examples/s]Tokenizing train dataset:  64%|██████▎   | 15400/24227 [00:39<00:24, 366.21 examples/s]Tokenizing train dataset:  64%|██████▍   | 15454/24227 [00:39<00:24, 359.42 examples/s]Tokenizing train dataset:  64%|██████▎   | 15389/24227 [00:39<00:24, 360.91 examples/s]Tokenizing train dataset:  64%|██████▎   | 15437/24227 [00:39<00:24, 363.40 examples/s]Tokenizing train dataset:  64%|██████▍   | 15491/24227 [00:39<00:24, 359.31 examples/s]Tokenizing train dataset:  64%|██████▎   | 15427/24227 [00:39<00:24, 362.11 examples/s]Tokenizing train dataset:  64%|██████▍   | 15490/24227 [00:39<00:24, 355.59 examples/s]Tokenizing train dataset:  64%|██████▍   | 15464/24227 [00:39<00:24, 362.71 examples/s]Tokenizing train dataset:  64%|██████▍   | 15546/24227 [00:39<00:24, 359.50 examples/s]Tokenizing train dataset:  64%|██████▍   | 15526/24227 [00:39<00:24, 354.12 examples/s]Tokenizing train dataset:  64%|██████▍   | 15586/24227 [00:39<00:23, 367.10 examples/s]Tokenizing train dataset:  64%|██████▍   | 15520/24227 [00:39<00:24, 355.55 examples/s]Tokenizing train dataset:  64%|██████▍   | 15562/24227 [00:40<00:24, 354.46 examples/s]Tokenizing train dataset:  64%|██████▍   | 15556/24227 [00:39<00:24, 355.21 examples/s]Tokenizing train dataset:  65%|██████▍   | 15641/24227 [00:40<00:23, 360.05 examples/s]Tokenizing train dataset:  64%|██████▍   | 15603/24227 [00:40<00:23, 367.06 examples/s]Tokenizing train dataset:  64%|██████▍   | 15597/24227 [00:39<00:23, 363.52 examples/s]Tokenizing train dataset:  65%|██████▍   | 15680/24227 [00:40<00:23, 360.08 examples/s]Tokenizing train dataset:  65%|██████▍   | 15658/24227 [00:40<00:23, 360.95 examples/s]Tokenizing train dataset:  65%|██████▍   | 15725/24227 [00:40<00:22, 378.59 examples/s]Tokenizing train dataset:  65%|██████▍   | 15652/24227 [00:40<00:23, 361.34 examples/s]Tokenizing train dataset:  65%|██████▍   | 15704/24227 [00:40<00:25, 340.87 examples/s]Tokenizing train dataset:  65%|██████▌   | 15764/24227 [00:40<00:25, 334.51 examples/s]Tokenizing train dataset:  65%|██████▍   | 15690/24227 [00:40<00:28, 302.20 examples/s]Tokenizing train dataset:  65%|██████▍   | 15743/24227 [00:40<00:38, 220.01 examples/s]Tokenizing train dataset:  65%|██████▌   | 15801/24227 [00:40<00:41, 202.37 examples/s]Tokenizing train dataset:  65%|██████▍   | 15733/24227 [00:40<00:39, 215.56 examples/s]Tokenizing train dataset:  65%|██████▌   | 15783/24227 [00:40<00:37, 224.46 examples/s]Tokenizing train dataset:  65%|██████▌   | 15838/24227 [00:41<00:44, 188.15 examples/s]Tokenizing train dataset:  65%|██████▌   | 15771/24227 [00:40<00:43, 195.82 examples/s]Tokenizing train dataset:  65%|██████▌   | 15823/24227 [00:41<00:42, 197.15 examples/s]Tokenizing train dataset:  65%|██████▌   | 15801/24227 [00:40<00:39, 212.35 examples/s]Tokenizing train dataset:  66%|██████▌   | 15880/24227 [00:41<00:40, 206.83 examples/s]Tokenizing train dataset:  65%|██████▌   | 15857/24227 [00:41<00:45, 184.42 examples/s]Tokenizing train dataset:  65%|██████▌   | 15838/24227 [00:41<00:43, 194.49 examples/s]Tokenizing train dataset:  66%|██████▌   | 15920/24227 [00:41<00:43, 190.93 examples/s]Tokenizing train dataset:  66%|██████▌   | 15897/24227 [00:41<00:41, 201.25 examples/s]Tokenizing train dataset:  66%|██████▌   | 15876/24227 [00:41<00:46, 180.12 examples/s]Tokenizing train dataset:  66%|██████▌   | 15958/24227 [00:41<00:46, 178.16 examples/s]Tokenizing train dataset:  66%|██████▌   | 15936/24227 [00:41<00:48, 170.18 examples/s]Tokenizing train dataset:  66%|██████▌   | 15897/24227 [00:41<00:54, 153.15 examples/s]Tokenizing train dataset:  66%|██████▌   | 15992/24227 [00:41<00:52, 157.61 examples/s]Tokenizing train dataset:  66%|██████▌   | 15917/24227 [00:41<00:54, 153.18 examples/s]Tokenizing train dataset:  66%|██████▌   | 15969/24227 [00:42<00:46, 178.32 examples/s]Tokenizing train dataset:  66%|██████▌   | 16012/24227 [00:42<00:51, 159.27 examples/s]Tokenizing train dataset:  66%|██████▌   | 15937/24227 [00:41<00:51, 160.78 examples/s]Tokenizing train dataset:  66%|██████▌   | 15990/24227 [00:42<00:45, 181.88 examples/s]Tokenizing train dataset:  66%|██████▌   | 16032/24227 [00:42<00:52, 156.56 examples/s]Tokenizing train dataset:  66%|██████▌   | 16011/24227 [00:42<00:53, 152.94 examples/s]Tokenizing train dataset:  66%|██████▌   | 15970/24227 [00:42<00:54, 152.68 examples/s]Tokenizing train dataset:  66%|██████▋   | 16052/24227 [00:42<00:54, 149.64 examples/s]Tokenizing train dataset:  66%|██████▌   | 16032/24227 [00:42<00:55, 148.87 examples/s]Tokenizing train dataset:  66%|██████▌   | 15988/24227 [00:42<00:59, 138.22 examples/s]Tokenizing train dataset:  66%|██████▋   | 16070/24227 [00:42<00:56, 144.68 examples/s]Tokenizing train dataset:  66%|██████▋   | 16055/24227 [00:42<00:50, 162.97 examples/s]Tokenizing train dataset:  66%|██████▌   | 16011/24227 [00:42<00:53, 154.00 examples/s]Tokenizing train dataset:  66%|██████▋   | 16090/24227 [00:42<00:53, 153.33 examples/s]Tokenizing train dataset:  66%|██████▋   | 16084/24227 [00:42<00:42, 189.52 examples/s]Tokenizing train dataset:  66%|██████▌   | 16032/24227 [00:42<01:00, 135.36 examples/s]Tokenizing train dataset:  67%|██████▋   | 16113/24227 [00:42<00:59, 135.33 examples/s]Tokenizing train dataset:  67%|██████▋   | 16128/24227 [00:43<00:58, 138.95 examples/s]Tokenizing train dataset:  66%|██████▋   | 16052/24227 [00:42<01:21, 100.35 examples/s]Tokenizing train dataset:  67%|██████▋   | 16134/24227 [00:43<01:18, 102.71 examples/s]Tokenizing train dataset:  67%|██████▋   | 16162/24227 [00:43<00:47, 169.24 examples/s]Tokenizing train dataset:  66%|██████▋   | 16070/24227 [00:43<01:16, 106.04 examples/s]Tokenizing train dataset:  67%|██████▋   | 16157/24227 [00:43<01:18, 102.50 examples/s]Tokenizing train dataset:  67%|██████▋   | 16200/24227 [00:43<00:57, 140.06 examples/s]Tokenizing train dataset:  66%|██████▋   | 16090/24227 [00:43<01:32, 88.32 examples/s] Tokenizing train dataset:  67%|██████▋   | 16176/24227 [00:43<01:38, 81.90 examples/s] Tokenizing train dataset:  67%|██████▋   | 16220/24227 [00:43<01:01, 130.90 examples/s]Tokenizing train dataset:  67%|██████▋   | 16113/24227 [00:43<01:30, 89.34 examples/s]Tokenizing train dataset:  67%|██████▋   | 16196/24227 [00:43<01:26, 93.00 examples/s]Tokenizing train dataset:  67%|██████▋   | 16240/24227 [00:43<00:58, 136.73 examples/s]Tokenizing train dataset:  67%|██████▋   | 16134/24227 [00:43<01:35, 84.90 examples/s]Tokenizing train dataset:  67%|██████▋   | 16215/24227 [00:44<01:41, 79.32 examples/s]Tokenizing train dataset:  67%|██████▋   | 16260/24227 [00:44<01:21, 97.21 examples/s] Tokenizing train dataset:  67%|██████▋   | 16157/24227 [00:44<01:24, 95.20 examples/s]Tokenizing train dataset:  67%|██████▋   | 16234/24227 [00:44<01:25, 93.04 examples/s]Tokenizing train dataset:  67%|██████▋   | 16280/24227 [00:44<01:13, 108.62 examples/s]Tokenizing train dataset:  67%|██████▋   | 16176/24227 [00:44<01:15, 106.72 examples/s]Tokenizing train dataset:  67%|██████▋   | 16252/24227 [00:44<01:19, 100.82 examples/s]Tokenizing train dataset:  67%|██████▋   | 16299/24227 [00:44<01:06, 119.25 examples/s]Tokenizing train dataset:  67%|██████▋   | 16196/24227 [00:44<01:15, 105.88 examples/s]Tokenizing train dataset:  67%|██████▋   | 16273/24227 [00:44<01:17, 102.85 examples/s]Tokenizing train dataset:  67%|██████▋   | 16318/24227 [00:44<01:05, 120.59 examples/s]Tokenizing train dataset:  67%|██████▋   | 16226/24227 [00:44<00:57, 140.17 examples/s]Tokenizing train dataset:  67%|██████▋   | 16300/24227 [00:44<01:00, 131.54 examples/s]Tokenizing train dataset:  67%|██████▋   | 16345/24227 [00:44<00:52, 149.38 examples/s]Tokenizing train dataset:  67%|██████▋   | 16246/24227 [00:44<00:52, 151.36 examples/s]Tokenizing train dataset:  67%|██████▋   | 16337/24227 [00:44<00:44, 178.14 examples/s]Tokenizing train dataset:  68%|██████▊   | 16376/24227 [00:44<00:42, 182.99 examples/s]Tokenizing train dataset:  67%|██████▋   | 16275/24227 [00:44<00:43, 180.99 examples/s]Tokenizing train dataset:  68%|██████▊   | 16365/24227 [00:44<00:39, 199.07 examples/s]Tokenizing train dataset:  68%|██████▊   | 16410/24227 [00:45<00:49, 157.60 examples/s]Tokenizing train dataset:  67%|██████▋   | 16310/24227 [00:45<00:50, 156.25 examples/s]Tokenizing train dataset:  68%|██████▊   | 16400/24227 [00:45<00:45, 173.26 examples/s]Tokenizing train dataset:  68%|██████▊   | 16431/24227 [00:45<00:46, 166.51 examples/s]Tokenizing train dataset:  67%|██████▋   | 16336/24227 [00:45<00:45, 175.14 examples/s]Tokenizing train dataset:  68%|██████▊   | 16435/24227 [00:45<00:42, 184.80 examples/s]Tokenizing train dataset:  68%|██████▊   | 16465/24227 [00:45<00:55, 140.04 examples/s]Tokenizing train dataset:  68%|██████▊   | 16370/24227 [00:45<00:51, 151.86 examples/s]Tokenizing train dataset:  68%|██████▊   | 16470/24227 [00:45<00:44, 175.87 examples/s]Tokenizing train dataset:  68%|██████▊   | 16490/24227 [00:45<00:49, 157.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 16500/24227 [00:45<00:40, 189.11 examples/s]Tokenizing train dataset:  68%|██████▊   | 16405/24227 [00:45<00:47, 164.26 examples/s]Tokenizing train dataset:  68%|██████▊   | 16554/24227 [00:45<00:30, 252.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 16576/24227 [00:45<00:25, 305.19 examples/s]Tokenizing train dataset:  69%|██████▊   | 16596/24227 [00:46<00:31, 241.23 examples/s]Tokenizing train dataset:  68%|██████▊   | 16440/24227 [00:45<00:46, 165.86 examples/s]Tokenizing train dataset:  69%|██████▊   | 16640/24227 [00:46<00:26, 281.88 examples/s]Tokenizing train dataset:  69%|██████▊   | 16640/24227 [00:46<00:25, 293.49 examples/s]Tokenizing train dataset:  68%|██████▊   | 16468/24227 [00:45<00:41, 184.94 examples/s]Tokenizing train dataset:  69%|██████▉   | 16695/24227 [00:46<00:21, 342.58 examples/s]Tokenizing train dataset:  69%|██████▉   | 16695/24227 [00:46<00:21, 344.10 examples/s]Tokenizing train dataset:  68%|██████▊   | 16522/24227 [00:46<00:30, 256.37 examples/s]Tokenizing train dataset:  69%|██████▉   | 16752/24227 [00:46<00:18, 394.04 examples/s]Tokenizing train dataset:  69%|██████▉   | 16748/24227 [00:46<00:19, 381.95 examples/s]Tokenizing train dataset:  68%|██████▊   | 16580/24227 [00:46<00:23, 326.61 examples/s]Tokenizing train dataset:  69%|██████▉   | 16819/24227 [00:46<00:16, 462.25 examples/s]Tokenizing train dataset:  69%|██████▉   | 16814/24227 [00:46<00:16, 445.64 examples/s]Tokenizing train dataset:  69%|██████▊   | 16638/24227 [00:46<00:19, 384.90 examples/s]Tokenizing train dataset:  70%|██████▉   | 16890/24227 [00:46<00:18, 398.47 examples/s]Tokenizing train dataset:  70%|██████▉   | 16885/24227 [00:46<00:20, 364.27 examples/s]Tokenizing train dataset:  69%|██████▉   | 16710/24227 [00:46<00:26, 278.72 examples/s]Tokenizing train dataset:  70%|██████▉   | 16957/24227 [00:46<00:18, 393.79 examples/s]Tokenizing train dataset:  70%|██████▉   | 16952/24227 [00:46<00:24, 301.98 examples/s]Tokenizing train dataset:  69%|██████▉   | 16780/24227 [00:46<00:26, 279.72 examples/s]Tokenizing train dataset:  70%|███████   | 17035/24227 [00:47<00:19, 361.63 examples/s]Tokenizing train dataset:  70%|███████   | 17015/24227 [00:47<00:20, 357.68 examples/s]Tokenizing train dataset:  69%|██████▉   | 16825/24227 [00:46<00:24, 307.36 examples/s]Tokenizing train dataset:  71%|███████   | 17109/24227 [00:47<00:18, 393.78 examples/s]Tokenizing train dataset:  71%|███████   | 17100/24227 [00:47<00:17, 409.92 examples/s]Tokenizing train dataset:  70%|██████▉   | 16866/24227 [00:47<00:22, 325.13 examples/s]Tokenizing train dataset:  71%|███████   | 17185/24227 [00:47<00:15, 463.56 examples/s]Tokenizing train dataset:  71%|███████   | 17152/24227 [00:47<00:16, 430.32 examples/s]Tokenizing train dataset:  70%|██████▉   | 16920/24227 [00:47<00:19, 370.13 examples/s]Tokenizing train dataset:  71%|███████   | 17260/24227 [00:47<00:15, 461.82 examples/s]Tokenizing train dataset:  71%|███████   | 17230/24227 [00:47<00:15, 455.67 examples/s]Tokenizing train dataset:  70%|███████   | 16999/24227 [00:47<00:17, 416.16 examples/s]Tokenizing train dataset:  71%|███████▏  | 17310/24227 [00:47<00:14, 466.27 examples/s]Tokenizing train dataset:  71%|███████▏  | 17308/24227 [00:47<00:15, 437.34 examples/s]Tokenizing train dataset:  70%|███████   | 17071/24227 [00:47<00:19, 364.77 examples/s]Tokenizing train dataset:  72%|███████▏  | 17388/24227 [00:47<00:14, 459.55 examples/s]Tokenizing train dataset:  71%|███████   | 17140/24227 [00:47<00:16, 427.36 examples/s]Tokenizing train dataset:  72%|███████▏  | 17383/24227 [00:47<00:15, 437.30 examples/s]Tokenizing train dataset:  72%|███████▏  | 17455/24227 [00:47<00:15, 434.73 examples/s]Tokenizing train dataset:  72%|███████▏  | 17434/24227 [00:47<00:15, 451.44 examples/s]Tokenizing train dataset:  71%|███████   | 17208/24227 [00:47<00:14, 478.61 examples/s]Tokenizing train dataset:  72%|███████▏  | 17516/24227 [00:48<00:16, 414.42 examples/s]Tokenizing train dataset:  72%|███████▏  | 17497/24227 [00:48<00:20, 334.43 examples/s]Tokenizing train dataset:  71%|███████▏  | 17283/24227 [00:48<00:20, 337.79 examples/s]Tokenizing train dataset:  72%|███████▏  | 17547/24227 [00:48<00:18, 362.65 examples/s]Tokenizing train dataset:  73%|███████▎  | 17574/24227 [00:48<00:20, 328.55 examples/s]Tokenizing train dataset:  72%|███████▏  | 17356/24227 [00:48<00:19, 359.55 examples/s]Tokenizing train dataset:  73%|███████▎  | 17603/24227 [00:48<00:19, 348.41 examples/s]Tokenizing train dataset:  73%|███████▎  | 17640/24227 [00:48<00:21, 301.97 examples/s]Tokenizing train dataset:  72%|███████▏  | 17429/24227 [00:48<00:17, 388.25 examples/s]Tokenizing train dataset:  73%|███████▎  | 17679/24227 [00:48<00:18, 354.74 examples/s]Tokenizing train dataset:  73%|███████▎  | 17679/24227 [00:48<00:22, 289.54 examples/s]Tokenizing train dataset:  72%|███████▏  | 17492/24227 [00:48<00:19, 338.40 examples/s]Tokenizing train dataset:  73%|███████▎  | 17755/24227 [00:48<00:19, 338.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 17717/24227 [00:49<00:27, 233.98 examples/s]Tokenizing train dataset:  74%|███████▎  | 17810/24227 [00:49<00:17, 374.62 examples/s]Tokenizing train dataset:  72%|███████▏  | 17555/24227 [00:48<00:20, 323.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 17755/24227 [00:49<00:29, 216.30 examples/s]Tokenizing train dataset:  74%|███████▍  | 17877/24227 [00:49<00:19, 332.29 examples/s]Tokenizing train dataset:  73%|███████▎  | 17612/24227 [00:49<00:22, 287.97 examples/s]Tokenizing train dataset:  73%|███████▎  | 17790/24227 [00:49<00:29, 221.74 examples/s]Tokenizing train dataset:  74%|███████▍  | 17921/24227 [00:49<00:17, 351.51 examples/s]Tokenizing train dataset:  73%|███████▎  | 17653/24227 [00:49<00:21, 306.92 examples/s]Tokenizing train dataset:  74%|███████▎  | 17849/24227 [00:49<00:22, 286.44 examples/s]Tokenizing train dataset:  74%|███████▍  | 17995/24227 [00:49<00:17, 354.37 examples/s]Tokenizing train dataset:  73%|███████▎  | 17727/24227 [00:49<00:19, 328.84 examples/s]Tokenizing train dataset:  74%|███████▍  | 17910/24227 [00:49<00:19, 316.01 examples/s]Tokenizing train dataset:  75%|███████▍  | 18066/24227 [00:49<00:14, 421.61 examples/s]Tokenizing train dataset:  73%|███████▎  | 17788/24227 [00:49<00:17, 378.65 examples/s]Tokenizing train dataset:  74%|███████▍  | 17946/24227 [00:49<00:24, 260.65 examples/s]Tokenizing train dataset:  75%|███████▍  | 18137/24227 [00:50<00:18, 329.27 examples/s]Tokenizing train dataset:  74%|███████▎  | 17854/24227 [00:49<00:24, 261.05 examples/s]Tokenizing train dataset:  74%|███████▍  | 17983/24227 [00:50<00:33, 188.40 examples/s]Tokenizing train dataset:  75%|███████▌  | 18216/24227 [00:50<00:18, 324.81 examples/s]Tokenizing train dataset:  74%|███████▍  | 17920/24227 [00:50<00:21, 296.85 examples/s]Tokenizing train dataset:  74%|███████▍  | 18020/24227 [00:50<00:29, 210.09 examples/s]Tokenizing train dataset:  75%|███████▌  | 18288/24227 [00:50<00:15, 388.06 examples/s]Tokenizing train dataset:  74%|███████▍  | 17980/24227 [00:50<00:17, 347.07 examples/s]Tokenizing train dataset:  75%|███████▍  | 18061/24227 [00:50<00:25, 242.12 examples/s]Tokenizing train dataset:  76%|███████▌  | 18348/24227 [00:50<00:13, 426.88 examples/s]Tokenizing train dataset:  74%|███████▍  | 18031/24227 [00:50<00:16, 376.89 examples/s]Tokenizing train dataset:  75%|███████▍  | 18121/24227 [00:50<00:19, 312.37 examples/s]Tokenizing train dataset:  76%|███████▌  | 18419/24227 [00:50<00:13, 421.98 examples/s]Tokenizing train dataset:  75%|███████▍  | 18111/24227 [00:50<00:16, 364.36 examples/s]Tokenizing train dataset:  76%|███████▌  | 18467/24227 [00:50<00:13, 433.12 examples/s]Tokenizing train dataset:  75%|███████▌  | 18193/24227 [00:50<00:19, 316.27 examples/s]Tokenizing train dataset:  75%|███████▌  | 18172/24227 [00:50<00:14, 409.69 examples/s]Tokenizing train dataset:  75%|███████▌  | 18239/24227 [00:50<00:18, 321.32 examples/s]Tokenizing train dataset:  76%|███████▋  | 18528/24227 [00:50<00:13, 410.63 examples/s]Tokenizing train dataset:  75%|███████▌  | 18240/24227 [00:50<00:12, 467.14 examples/s]Tokenizing train dataset:  76%|███████▌  | 18311/24227 [00:51<00:16, 357.34 examples/s]Tokenizing train dataset:  77%|███████▋  | 18600/24227 [00:51<00:14, 390.50 examples/s]Tokenizing train dataset:  76%|███████▌  | 18314/24227 [00:51<00:14, 403.86 examples/s]Tokenizing train dataset:  76%|███████▌  | 18352/24227 [00:51<00:18, 313.61 examples/s]Tokenizing train dataset:  77%|███████▋  | 18681/24227 [00:51<00:15, 348.04 examples/s]Tokenizing train dataset:  76%|███████▌  | 18387/24227 [00:51<00:22, 260.81 examples/s]Tokenizing train dataset:  76%|███████▌  | 18389/24227 [00:51<00:17, 341.91 examples/s]Tokenizing train dataset:  77%|███████▋  | 18755/24227 [00:51<00:16, 329.55 examples/s]Tokenizing train dataset:  76%|███████▌  | 18423/24227 [00:51<00:28, 207.07 examples/s]Tokenizing train dataset:  78%|███████▊  | 18796/24227 [00:51<00:16, 331.90 examples/s]Tokenizing train dataset:  76%|███████▌  | 18462/24227 [00:51<00:20, 285.13 examples/s]Tokenizing train dataset:  76%|███████▌  | 18459/24227 [00:51<00:26, 214.24 examples/s]Tokenizing train dataset:  78%|███████▊  | 18836/24227 [00:51<00:17, 301.84 examples/s]Tokenizing train dataset:  76%|███████▋  | 18500/24227 [00:51<00:21, 271.97 examples/s]Tokenizing train dataset:  76%|███████▋  | 18499/24227 [00:52<00:23, 244.62 examples/s]Tokenizing train dataset:  78%|███████▊  | 18879/24227 [00:52<00:17, 307.81 examples/s]Tokenizing train dataset:  78%|███████▊  | 18915/24227 [00:52<00:17, 300.98 examples/s]Tokenizing train dataset:  77%|███████▋  | 18561/24227 [00:52<00:22, 255.76 examples/s]Tokenizing train dataset:  77%|███████▋  | 18559/24227 [00:52<00:23, 240.57 examples/s]Tokenizing train dataset:  78%|███████▊  | 18948/24227 [00:52<00:19, 271.83 examples/s]Tokenizing train dataset:  77%|███████▋  | 18594/24227 [00:52<00:25, 218.02 examples/s]Tokenizing train dataset:  77%|███████▋  | 18593/24227 [00:52<00:30, 183.23 examples/s]Tokenizing train dataset:  78%|███████▊  | 18980/24227 [00:52<00:23, 222.18 examples/s]Tokenizing train dataset:  77%|███████▋  | 18633/24227 [00:52<00:26, 213.07 examples/s]Tokenizing train dataset:  77%|███████▋  | 18632/24227 [00:52<00:30, 185.15 examples/s]Tokenizing train dataset:  78%|███████▊  | 19010/24227 [00:52<00:26, 199.01 examples/s]Tokenizing train dataset:  77%|███████▋  | 18678/24227 [00:52<00:22, 246.44 examples/s]Tokenizing train dataset:  77%|███████▋  | 18700/24227 [00:52<00:21, 262.13 examples/s]Tokenizing train dataset:  79%|███████▊  | 19066/24227 [00:52<00:19, 266.18 examples/s]Tokenizing train dataset:  77%|███████▋  | 18735/24227 [00:52<00:18, 303.83 examples/s]Tokenizing train dataset:  77%|███████▋  | 18738/24227 [00:53<00:20, 263.55 examples/s]Tokenizing train dataset:  79%|███████▉  | 19105/24227 [00:53<00:19, 262.17 examples/s]Tokenizing train dataset:  77%|███████▋  | 18774/24227 [00:52<00:18, 291.25 examples/s]Tokenizing train dataset:  78%|███████▊  | 18809/24227 [00:53<00:15, 351.02 examples/s]Tokenizing train dataset:  79%|███████▉  | 19144/24227 [00:53<00:19, 265.75 examples/s]Tokenizing train dataset:  78%|███████▊  | 18816/24227 [00:53<00:18, 293.83 examples/s]Tokenizing train dataset:  78%|███████▊  | 18875/24227 [00:53<00:12, 417.85 examples/s]Tokenizing train dataset:  79%|███████▉  | 19183/24227 [00:53<00:17, 283.83 examples/s]Tokenizing train dataset:  78%|███████▊  | 18853/24227 [00:53<00:18, 290.54 examples/s]Tokenizing train dataset:  78%|███████▊  | 18943/24227 [00:53<00:12, 427.75 examples/s]Tokenizing train dataset:  79%|███████▉  | 19253/24227 [00:53<00:13, 377.64 examples/s]Tokenizing train dataset:  78%|███████▊  | 18896/24227 [00:53<00:16, 318.54 examples/s]Tokenizing train dataset:  78%|███████▊  | 18931/24227 [00:53<00:16, 323.34 examples/s]Tokenizing train dataset:  78%|███████▊  | 19012/24227 [00:53<00:11, 435.38 examples/s]Tokenizing train dataset:  80%|███████▉  | 19318/24227 [00:53<00:12, 389.35 examples/s]Tokenizing train dataset:  78%|███████▊  | 18982/24227 [00:53<00:14, 369.71 examples/s]Tokenizing train dataset:  80%|███████▉  | 19364/24227 [00:53<00:12, 405.11 examples/s]Tokenizing train dataset:  79%|███████▉  | 19092/24227 [00:53<00:11, 462.36 examples/s]Tokenizing train dataset:  79%|███████▊  | 19021/24227 [00:53<00:13, 373.29 examples/s]Tokenizing train dataset:  80%|████████  | 19421/24227 [00:53<00:12, 378.93 examples/s]Tokenizing train dataset:  79%|███████▉  | 19087/24227 [00:53<00:11, 446.50 examples/s]Tokenizing train dataset:  79%|███████▉  | 19171/24227 [00:53<00:10, 478.28 examples/s]Tokenizing train dataset:  81%|████████  | 19524/24227 [00:53<00:08, 530.45 examples/s]Tokenizing train dataset:  79%|███████▉  | 19148/24227 [00:53<00:10, 490.50 examples/s]Tokenizing train dataset:  79%|███████▉  | 19233/24227 [00:54<00:09, 508.80 examples/s]Tokenizing train dataset:  81%|████████  | 19639/24227 [00:54<00:06, 684.02 examples/s]Tokenizing train dataset:  79%|███████▉  | 19214/24227 [00:53<00:09, 535.02 examples/s]Tokenizing train dataset:  80%|███████▉  | 19287/24227 [00:54<00:09, 512.25 examples/s]Tokenizing train dataset:  82%|████████▏ | 19765/24227 [00:54<00:06, 688.96 examples/s]Tokenizing train dataset:  80%|███████▉  | 19284/24227 [00:54<00:10, 472.45 examples/s]Tokenizing train dataset:  80%|███████▉  | 19343/24227 [00:54<00:11, 430.19 examples/s]Tokenizing train dataset:  82%|████████▏ | 19897/24227 [00:54<00:05, 747.70 examples/s]Tokenizing train dataset:  80%|███████▉  | 19341/24227 [00:54<00:11, 434.90 examples/s]Tokenizing train dataset:  80%|████████  | 19402/24227 [00:54<00:12, 399.89 examples/s]Tokenizing train dataset:  83%|████████▎ | 20000/24227 [00:54<00:05, 811.97 examples/s]Tokenizing train dataset:  80%|████████  | 19449/24227 [00:54<00:14, 340.47 examples/s]Tokenizing train dataset:  80%|████████  | 19400/24227 [00:54<00:14, 335.79 examples/s]Tokenizing train dataset:  83%|████████▎ | 20129/24227 [00:54<00:05, 725.27 examples/s]Tokenizing train dataset:  81%|████████  | 19551/24227 [00:54<00:09, 478.52 examples/s]Tokenizing train dataset:  80%|████████  | 19441/24227 [00:54<00:14, 340.67 examples/s]Tokenizing train dataset:  83%|████████▎ | 20214/24227 [00:54<00:05, 749.35 examples/s]Tokenizing train dataset:  81%|████████  | 19655/24227 [00:54<00:07, 604.16 examples/s]Tokenizing train dataset:  81%|████████  | 19506/24227 [00:54<00:11, 404.83 examples/s]Tokenizing train dataset:  81%|████████▏ | 19736/24227 [00:55<00:06, 653.24 examples/s]Tokenizing train dataset:  84%|████████▍ | 20336/24227 [00:54<00:05, 766.03 examples/s]Tokenizing train dataset:  81%|████████  | 19569/24227 [00:54<00:11, 411.57 examples/s]Tokenizing train dataset:  82%|████████▏ | 19860/24227 [00:55<00:06, 687.42 examples/s]Tokenizing train dataset:  84%|████████▍ | 20464/24227 [00:55<00:04, 790.66 examples/s]Tokenizing train dataset:  81%|████████  | 19638/24227 [00:54<00:09, 461.28 examples/s]Tokenizing train dataset:  82%|████████▏ | 19935/24227 [00:55<00:06, 700.67 examples/s]Tokenizing train dataset:  85%|████████▍ | 20547/24227 [00:55<00:04, 799.09 examples/s]Tokenizing train dataset:  81%|████████▏ | 19703/24227 [00:55<00:13, 338.78 examples/s]Tokenizing train dataset:  83%|████████▎ | 20065/24227 [00:55<00:08, 469.31 examples/s]Tokenizing train dataset:  82%|████████▏ | 19764/24227 [00:55<00:14, 304.91 examples/s]Tokenizing train dataset:  83%|████████▎ | 20133/24227 [00:55<00:08, 502.90 examples/s]Tokenizing train dataset:  85%|████████▌ | 20664/24227 [00:55<00:08, 434.79 examples/s]Tokenizing train dataset:  82%|████████▏ | 19875/24227 [00:55<00:09, 443.87 examples/s]Tokenizing train dataset:  83%|████████▎ | 20214/24227 [00:55<00:07, 561.52 examples/s]Tokenizing train dataset:  86%|████████▌ | 20730/24227 [00:56<00:09, 364.03 examples/s]Tokenizing train dataset:  82%|████████▏ | 19935/24227 [00:55<00:13, 326.35 examples/s]Tokenizing train dataset:  84%|████████▍ | 20335/24227 [00:56<00:09, 421.51 examples/s]Tokenizing train dataset:  86%|████████▌ | 20790/24227 [00:56<00:09, 347.91 examples/s]Tokenizing train dataset:  83%|████████▎ | 20002/24227 [00:56<00:11, 380.35 examples/s]Tokenizing train dataset:  84%|████████▍ | 20398/24227 [00:56<00:08, 451.18 examples/s]Tokenizing train dataset:  86%|████████▌ | 20850/24227 [00:56<00:08, 382.25 examples/s]Tokenizing train dataset:  83%|████████▎ | 20066/24227 [00:56<00:10, 411.07 examples/s]Tokenizing train dataset:  85%|████████▍ | 20474/24227 [00:56<00:07, 506.00 examples/s]Tokenizing train dataset:  86%|████████▋ | 20912/24227 [00:56<00:07, 422.76 examples/s]Tokenizing train dataset:  83%|████████▎ | 20134/24227 [00:56<00:08, 465.21 examples/s]Tokenizing train dataset:  87%|████████▋ | 20972/24227 [00:56<00:08, 367.27 examples/s]Tokenizing train dataset:  83%|████████▎ | 20199/24227 [00:56<00:09, 404.96 examples/s]Tokenizing train dataset:  85%|████████▍ | 20590/24227 [00:56<00:07, 483.39 examples/s]Tokenizing train dataset:  87%|████████▋ | 21036/24227 [00:56<00:08, 396.68 examples/s]Tokenizing train dataset:  84%|████████▎ | 20260/24227 [00:56<00:11, 357.53 examples/s]Tokenizing train dataset:  85%|████████▌ | 20650/24227 [00:56<00:08, 415.01 examples/s]Tokenizing train dataset:  87%|████████▋ | 21097/24227 [00:56<00:08, 364.36 examples/s]Tokenizing train dataset:  84%|████████▍ | 20321/24227 [00:56<00:09, 391.66 examples/s]Tokenizing train dataset:  86%|████████▌ | 20715/24227 [00:57<00:08, 435.18 examples/s]Tokenizing train dataset:  87%|████████▋ | 21159/24227 [00:57<00:09, 320.40 examples/s]Tokenizing train dataset:  84%|████████▍ | 20383/24227 [00:57<00:13, 287.07 examples/s]Tokenizing train dataset:  86%|████████▌ | 20773/24227 [00:57<00:10, 317.32 examples/s]Tokenizing train dataset:  88%|████████▊ | 21225/24227 [00:57<00:08, 342.09 examples/s]Tokenizing train dataset:  84%|████████▍ | 20443/24227 [00:57<00:12, 314.61 examples/s]Tokenizing train dataset:  86%|████████▌ | 20831/24227 [00:57<00:10, 323.06 examples/s]Tokenizing train dataset:  88%|████████▊ | 21290/24227 [00:57<00:08, 362.45 examples/s]Tokenizing train dataset:  85%|████████▍ | 20520/24227 [00:57<00:09, 394.07 examples/s]Tokenizing train dataset:  86%|████████▋ | 20932/24227 [00:57<00:07, 438.98 examples/s]Tokenizing train dataset:  88%|████████▊ | 21406/24227 [00:57<00:05, 515.06 examples/s]Tokenizing train dataset:  85%|████████▍ | 20590/24227 [00:57<00:07, 454.65 examples/s]Tokenizing train dataset:  87%|████████▋ | 21020/24227 [00:57<00:06, 523.70 examples/s]Tokenizing train dataset:  89%|████████▊ | 21482/24227 [00:57<00:04, 565.20 examples/s]Tokenizing train dataset:  85%|████████▌ | 20650/24227 [00:57<00:08, 444.88 examples/s]Tokenizing train dataset:  86%|████████▌ | 20715/24227 [00:57<00:10, 347.65 examples/s]Tokenizing train dataset:  87%|████████▋ | 21142/24227 [00:58<00:07, 402.28 examples/s]Tokenizing train dataset:  89%|████████▉ | 21603/24227 [00:58<00:06, 409.98 examples/s]Tokenizing train dataset:  86%|████████▌ | 20774/24227 [00:58<00:10, 341.67 examples/s]Tokenizing train dataset:  88%|████████▊ | 21205/24227 [00:58<00:07, 380.22 examples/s]Tokenizing train dataset:  89%|████████▉ | 21660/24227 [00:58<00:06, 389.05 examples/s]Tokenizing train dataset:  86%|████████▌ | 20863/24227 [00:58<00:07, 443.81 examples/s]Tokenizing train dataset:  88%|████████▊ | 21320/24227 [00:58<00:05, 504.64 examples/s]Tokenizing train dataset:  90%|████████▉ | 21775/24227 [00:58<00:04, 517.70 examples/s]Tokenizing train dataset:  86%|████████▋ | 20924/24227 [00:58<00:07, 415.61 examples/s]Tokenizing train dataset:  89%|████████▊ | 21448/24227 [00:58<00:05, 487.04 examples/s]Tokenizing train dataset:  90%|█████████ | 21901/24227 [00:58<00:04, 465.95 examples/s]Tokenizing train dataset:  87%|████████▋ | 20982/24227 [00:58<00:09, 348.58 examples/s]Tokenizing train dataset:  89%|████████▉ | 21569/24227 [00:59<00:05, 454.44 examples/s]Tokenizing train dataset:  91%|█████████ | 22020/24227 [00:59<00:05, 440.56 examples/s]Tokenizing train dataset:  87%|████████▋ | 21046/24227 [00:58<00:10, 301.35 examples/s]Tokenizing train dataset:  89%|████████▉ | 21628/24227 [00:59<00:05, 452.06 examples/s]Tokenizing train dataset:  91%|█████████ | 22086/24227 [00:59<00:04, 435.70 examples/s]Tokenizing train dataset:  87%|████████▋ | 21108/24227 [00:59<00:10, 307.77 examples/s]Tokenizing train dataset:  90%|████████▉ | 21685/24227 [00:59<00:06, 414.49 examples/s]Tokenizing train dataset:  91%|█████████▏| 22145/24227 [00:59<00:05, 397.82 examples/s]Tokenizing train dataset:  87%|████████▋ | 21170/24227 [00:59<00:09, 339.26 examples/s]Tokenizing train dataset:  90%|████████▉ | 21750/24227 [00:59<00:05, 455.03 examples/s]Tokenizing train dataset:  92%|█████████▏| 22208/24227 [00:59<00:05, 400.48 examples/s]Tokenizing train dataset:  88%|████████▊ | 21234/24227 [00:59<00:08, 354.92 examples/s]Tokenizing train dataset:  90%|█████████ | 21816/24227 [00:59<00:05, 436.68 examples/s]Tokenizing train dataset:  92%|█████████▏| 22317/24227 [00:59<00:03, 524.42 examples/s]Tokenizing train dataset:  88%|████████▊ | 21298/24227 [00:59<00:07, 403.51 examples/s]Tokenizing train dataset:  90%|█████████ | 21879/24227 [00:59<00:04, 475.04 examples/s]Tokenizing train dataset:  88%|████████▊ | 21360/24227 [00:59<00:06, 439.77 examples/s]Tokenizing train dataset:  91%|█████████ | 21941/24227 [00:59<00:04, 495.97 examples/s]Tokenizing train dataset:  93%|█████████▎| 22439/24227 [00:59<00:03, 570.44 examples/s]Tokenizing train dataset:  89%|████████▊ | 21444/24227 [00:59<00:05, 531.09 examples/s]Tokenizing train dataset:  91%|█████████ | 22023/24227 [01:00<00:03, 571.56 examples/s]Tokenizing train dataset:  93%|█████████▎| 22538/24227 [00:59<00:02, 653.92 examples/s]Tokenizing train dataset:  89%|████████▉ | 21550/24227 [00:59<00:04, 659.56 examples/s]Tokenizing train dataset:  91%|█████████ | 22089/24227 [01:00<00:03, 563.70 examples/s]Tokenizing train dataset:  89%|████████▉ | 21647/24227 [00:59<00:03, 739.24 examples/s]Tokenizing train dataset:  94%|█████████▎| 22661/24227 [01:00<00:02, 691.07 examples/s]Tokenizing train dataset:  92%|█████████▏| 22173/24227 [01:00<00:03, 632.48 examples/s]Tokenizing train dataset:  90%|████████▉ | 21769/24227 [01:00<00:03, 676.99 examples/s]Tokenizing train dataset:  94%|█████████▍| 22787/24227 [01:00<00:02, 625.27 examples/s]Tokenizing train dataset:  92%|█████████▏| 22292/24227 [01:00<00:03, 547.99 examples/s]Tokenizing train dataset:  90%|█████████ | 21893/24227 [01:00<00:03, 717.95 examples/s]Tokenizing train dataset:  92%|█████████▏| 22361/24227 [01:00<00:03, 577.30 examples/s]Tokenizing train dataset:  95%|█████████▍| 22915/24227 [01:00<00:01, 666.16 examples/s]Tokenizing train dataset:  91%|█████████ | 22012/24227 [01:00<00:03, 733.35 examples/s]Tokenizing train dataset:  93%|█████████▎| 22485/24227 [01:00<00:03, 496.50 examples/s]Tokenizing train dataset:  95%|█████████▌| 23038/24227 [01:00<00:02, 516.64 examples/s]Tokenizing train dataset:  93%|█████████▎| 22542/24227 [01:01<00:03, 433.19 examples/s]Tokenizing train dataset:  91%|█████████▏| 22135/24227 [01:00<00:04, 516.52 examples/s]Tokenizing train dataset:  95%|█████████▌| 23102/24227 [01:01<00:02, 505.42 examples/s]Tokenizing train dataset:  93%|█████████▎| 22605/24227 [01:01<00:03, 467.64 examples/s]Tokenizing train dataset:  96%|█████████▌| 23165/24227 [01:01<00:02, 497.67 examples/s]Tokenizing train dataset:  92%|█████████▏| 22255/24227 [01:01<00:03, 574.10 examples/s]Tokenizing train dataset:  94%|█████████▎| 22665/24227 [01:01<00:03, 448.66 examples/s]Tokenizing train dataset:  96%|█████████▌| 23227/24227 [01:01<00:01, 511.86 examples/s]Tokenizing train dataset:  92%|█████████▏| 22375/24227 [01:01<00:02, 627.64 examples/s]Tokenizing train dataset:  94%|█████████▍| 22730/24227 [01:01<00:03, 489.38 examples/s]Tokenizing train dataset:  96%|█████████▌| 23290/24227 [01:01<00:01, 532.85 examples/s]Tokenizing train dataset:  93%|█████████▎| 22464/24227 [01:01<00:02, 674.01 examples/s]Tokenizing train dataset:  94%|█████████▍| 22794/24227 [01:01<00:03, 465.80 examples/s]Tokenizing train dataset:  96%|█████████▋| 23354/24227 [01:01<00:01, 496.24 examples/s]Tokenizing train dataset:  93%|█████████▎| 22580/24227 [01:01<00:02, 699.75 examples/s]Tokenizing train dataset:  94%|█████████▍| 22856/24227 [01:01<00:02, 499.45 examples/s]Tokenizing train dataset:  97%|█████████▋| 23418/24227 [01:01<00:01, 528.16 examples/s]Tokenizing train dataset:  94%|█████████▎| 22698/24227 [01:01<00:01, 799.91 examples/s]Tokenizing train dataset:  95%|█████████▍| 22922/24227 [01:01<00:02, 537.89 examples/s]Tokenizing train dataset:  97%|█████████▋| 23481/24227 [01:01<00:01, 545.43 examples/s]Tokenizing train dataset:  95%|█████████▌| 23019/24227 [01:01<00:01, 648.42 examples/s]Tokenizing train dataset:  97%|█████████▋| 23583/24227 [01:01<00:00, 666.12 examples/s]Tokenizing train dataset:  94%|█████████▍| 22830/24227 [01:01<00:01, 823.05 examples/s]Tokenizing train dataset:  96%|█████████▌| 23145/24227 [01:02<00:01, 703.25 examples/s]Tokenizing train dataset:  98%|█████████▊| 23701/24227 [01:01<00:00, 686.86 examples/s]Tokenizing train dataset:  95%|█████████▍| 22955/24227 [01:01<00:01, 760.62 examples/s]Tokenizing train dataset:  96%|█████████▌| 23268/24227 [01:02<00:01, 726.58 examples/s]Tokenizing train dataset:  98%|█████████▊| 23824/24227 [01:02<00:00, 663.69 examples/s]Tokenizing train dataset:  95%|█████████▌| 23080/24227 [01:02<00:01, 753.81 examples/s]Tokenizing train dataset:  96%|█████████▋| 23373/24227 [01:02<00:01, 801.80 examples/s]Tokenizing train dataset:  99%|█████████▊| 23912/24227 [01:02<00:00, 710.40 examples/s]Tokenizing train dataset:  96%|█████████▌| 23207/24227 [01:02<00:01, 745.56 examples/s]Tokenizing train dataset:  99%|█████████▉| 24016/24227 [01:02<00:00, 787.53 examples/s]Tokenizing train dataset:  97%|█████████▋| 23498/24227 [01:02<00:00, 790.96 examples/s]Tokenizing train dataset:  96%|█████████▌| 23290/24227 [01:02<00:01, 760.41 examples/s]Tokenizing train dataset:  99%|█████████▉| 24105/24227 [01:02<00:00, 813.34 examples/s]Tokenizing train dataset:  97%|█████████▋| 23620/24227 [01:02<00:00, 730.50 examples/s]Tokenizing train dataset:  97%|█████████▋| 23413/24227 [01:02<00:01, 731.02 examples/s]Tokenizing train dataset:  97%|█████████▋| 23502/24227 [01:02<00:00, 764.23 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:02<00:00, 627.08 examples/s]Tokenizing train dataset:  98%|█████████▊| 23740/24227 [01:02<00:00, 701.82 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:02<00:00, 385.56 examples/s]
Tokenizing train dataset:  98%|█████████▊| 23627/24227 [01:02<00:00, 784.69 examples/s]Tokenizing train dataset:  99%|█████████▊| 23866/24227 [01:03<00:00, 731.58 examples/s]Tokenizing train dataset:  98%|█████████▊| 23723/24227 [01:02<00:00, 824.27 examples/s]Tokenizing train dataset:  99%|█████████▉| 23981/24227 [01:03<00:00, 818.65 examples/s]Tokenizing train dataset:  98%|█████████▊| 23849/24227 [01:02<00:00, 930.42 examples/s]Tokenizing train dataset:  99%|█████████▉| 24101/24227 [01:03<00:00, 904.25 examples/s]Tokenizing train dataset:  99%|█████████▉| 23965/24227 [01:03<00:00, 988.81 examples/s]Tokenizing train dataset: 100%|█████████▉| 24225/24227 [01:03<00:00, 986.60 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:03<00:00, 382.46 examples/s]
Tokenizing train dataset:  99%|█████████▉| 24086/24227 [01:03<00:00, 1045.90 examples/s]Tokenizing train dataset: 100%|█████████▉| 24210/24227 [01:03<00:00, 1096.31 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:03<00:00, 382.84 examples/s] 
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  58%|█████▊    | 548/953 [00:00<00:00, 5441.50 examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 552/953 [00:00<00:00, 5434.34 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5498.36 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5510.38 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5435.83 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5423.27 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  27%|██▋       | 262/953 [00:00<00:00, 2591.98 examples/s]Applying chat template to eval dataset:  28%|██▊       | 271/953 [00:00<00:00, 2679.59 examples/s]Applying chat template to eval dataset:  28%|██▊       | 265/953 [00:00<00:00, 2600.08 examples/s]Applying chat template to eval dataset:  56%|█████▌    | 534/953 [00:00<00:00, 2662.50 examples/s]Applying chat template to eval dataset:  58%|█████▊    | 554/953 [00:00<00:00, 2760.03 examples/s]Applying chat template to eval dataset:  56%|█████▋    | 538/953 [00:00<00:00, 2670.21 examples/s]Applying chat template to eval dataset:  86%|████████▌ | 817/953 [00:00<00:00, 2734.58 examples/s]Applying chat template to eval dataset:  88%|████████▊ | 842/953 [00:00<00:00, 2809.42 examples/s]Applying chat template to eval dataset:  85%|████████▌ | 814/953 [00:00<00:00, 2708.16 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2776.75 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2693.29 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2670.60 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 30/953 [00:00<00:03, 286.16 examples/s]Tokenizing eval dataset:   3%|▎         | 30/953 [00:00<00:03, 285.00 examples/s]Tokenizing eval dataset:   3%|▎         | 30/953 [00:00<00:03, 284.64 examples/s]Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:03, 253.78 examples/s]Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:03, 253.45 examples/s]Tokenizing eval dataset:   7%|▋         | 66/953 [00:00<00:03, 251.83 examples/s]Tokenizing eval dataset:  10%|█         | 96/953 [00:00<00:03, 255.39 examples/s]Tokenizing eval dataset:  10%|▉         | 95/953 [00:00<00:03, 256.32 examples/s]Tokenizing eval dataset:  10%|▉         | 93/953 [00:00<00:03, 254.80 examples/s]Tokenizing eval dataset:  14%|█▍        | 133/953 [00:00<00:03, 246.66 examples/s]Tokenizing eval dataset:  14%|█▎        | 130/953 [00:00<00:03, 242.57 examples/s]Tokenizing eval dataset:  13%|█▎        | 128/953 [00:00<00:03, 241.12 examples/s]Tokenizing eval dataset:  17%|█▋        | 165/953 [00:00<00:03, 235.45 examples/s]Tokenizing eval dataset:  18%|█▊        | 168/953 [00:00<00:03, 235.63 examples/s]Tokenizing eval dataset:  17%|█▋        | 163/953 [00:00<00:03, 234.72 examples/s]Tokenizing eval dataset:  21%|██        | 197/953 [00:00<00:03, 224.76 examples/s]Tokenizing eval dataset:  21%|██        | 201/953 [00:00<00:03, 227.54 examples/s]Tokenizing eval dataset:  21%|██        | 196/953 [00:00<00:03, 224.13 examples/s]Tokenizing eval dataset:  24%|██▎       | 226/953 [00:00<00:03, 239.47 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:00<00:02, 259.40 examples/s]Tokenizing eval dataset:  24%|██▎       | 226/953 [00:00<00:03, 239.29 examples/s]Tokenizing eval dataset:  30%|██▉       | 284/953 [00:01<00:02, 325.49 examples/s]Tokenizing eval dataset:  31%|███▏      | 300/953 [00:01<00:01, 348.91 examples/s]Tokenizing eval dataset:  30%|██▉       | 284/953 [00:01<00:02, 325.50 examples/s]Tokenizing eval dataset:  36%|███▌      | 340/953 [00:01<00:01, 384.71 examples/s]Tokenizing eval dataset:  37%|███▋      | 356/953 [00:01<00:01, 402.39 examples/s]Tokenizing eval dataset:  36%|███▌      | 341/953 [00:01<00:01, 388.25 examples/s]Tokenizing eval dataset:  41%|████      | 392/953 [00:01<00:01, 421.00 examples/s]Tokenizing eval dataset:  43%|████▎     | 408/953 [00:01<00:01, 432.09 examples/s]Tokenizing eval dataset:  41%|████      | 391/953 [00:01<00:01, 418.43 examples/s]Tokenizing eval dataset:  48%|████▊     | 457/953 [00:01<00:01, 483.80 examples/s]Tokenizing eval dataset:  49%|████▉     | 470/953 [00:01<00:00, 483.01 examples/s]Tokenizing eval dataset:  48%|████▊     | 455/953 [00:01<00:01, 479.71 examples/s]Tokenizing eval dataset:  53%|█████▎    | 508/953 [00:01<00:00, 486.16 examples/s]Tokenizing eval dataset:  55%|█████▌    | 525/953 [00:01<00:00, 500.92 examples/s]Tokenizing eval dataset:  53%|█████▎    | 506/953 [00:01<00:00, 486.94 examples/s]Tokenizing eval dataset:  59%|█████▉    | 564/953 [00:01<00:00, 505.24 examples/s]Tokenizing eval dataset:  61%|██████▏   | 585/953 [00:01<00:00, 521.43 examples/s]Tokenizing eval dataset:  59%|█████▉    | 562/953 [00:01<00:00, 502.55 examples/s]Tokenizing eval dataset:  65%|██████▌   | 620/953 [00:01<00:00, 517.89 examples/s]Tokenizing eval dataset:  68%|██████▊   | 644/953 [00:01<00:00, 533.98 examples/s]Tokenizing eval dataset:  65%|██████▍   | 617/953 [00:01<00:00, 514.90 examples/s]Tokenizing eval dataset:  71%|███████   | 673/953 [00:01<00:00, 519.38 examples/s]Tokenizing eval dataset:  70%|███████   | 670/953 [00:01<00:00, 514.14 examples/s]Tokenizing eval dataset:  76%|███████▌  | 725/953 [00:01<00:00, 530.39 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 527.83 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 530.80 examples/s]Tokenizing eval dataset:  82%|████████▏ | 780/953 [00:01<00:00, 529.32 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:02<00:00, 511.18 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:02<00:00, 512.80 examples/s]Tokenizing eval dataset:  89%|████████▉ | 852/953 [00:02<00:00, 509.51 examples/s]Tokenizing eval dataset:  90%|█████████ | 858/953 [00:02<00:00, 509.12 examples/s]Tokenizing eval dataset:  95%|█████████▍| 904/953 [00:02<00:00, 506.43 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:02<00:00, 505.61 examples/s]Tokenizing eval dataset:  98%|█████████▊| 937/953 [00:02<00:00, 507.32 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 415.76 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  98%|█████████▊| 937/953 [00:02<00:00, 507.63 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 411.18 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 410.42 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4826676845550537 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3890929222106934 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3588504791259766 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3341379165649414 seconds
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250611_190735-9zh88oos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-1e-06_e-3_b-0.2_63026307
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/9zh88oos
  0%|          | 0/4545 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/4545 [00:16<21:04:07, 16.69s/it]  0%|          | 2/4545 [00:20<11:30:58,  9.13s/it]  0%|          | 3/4545 [00:24<8:29:19,  6.73s/it]   0%|          | 4/4545 [00:27<6:55:11,  5.49s/it]  0%|          | 5/4545 [00:31<6:10:51,  4.90s/it]  0%|          | 6/4545 [00:36<5:52:27,  4.66s/it]  0%|          | 7/4545 [00:40<5:38:05,  4.47s/it]  0%|          | 8/4545 [00:43<5:22:29,  4.26s/it]  0%|          | 9/4545 [00:47<5:13:11,  4.14s/it]  0%|          | 10/4545 [00:51<5:02:10,  4.00s/it]                                                   {'loss': 0.747, 'grad_norm': 66.72050476074219, 'learning_rate': 5.9445178335535e-09, 'rewards/chosen': -0.058611296117305756, 'rewards/rejected': -0.01488494873046875, 'rewards/accuracies': 0.2874999940395355, 'rewards/margins': -0.04392700269818306, 'logps/chosen': -448.6000061035156, 'logps/rejected': -256.5249938964844, 'logits/chosen': -6.065625190734863, 'logits/rejected': -6.168749809265137, 'epoch': 0.01}
  0%|          | 10/4545 [00:51<5:02:10,  4.00s/it]  0%|          | 11/4545 [00:55<5:04:59,  4.04s/it]  0%|          | 12/4545 [00:59<5:01:04,  3.99s/it]  0%|          | 13/4545 [01:01<4:20:12,  3.44s/it]  0%|          | 14/4545 [01:04<4:16:28,  3.40s/it]  0%|          | 15/4545 [01:08<4:26:26,  3.53s/it]  0%|          | 16/4545 [01:12<4:21:47,  3.47s/it]  0%|          | 17/4545 [01:15<4:30:46,  3.59s/it]  0%|          | 18/4545 [01:20<4:43:12,  3.75s/it]  0%|          | 19/4545 [01:23<4:23:40,  3.50s/it]  0%|          | 20/4545 [01:26<4:31:22,  3.60s/it]                                                   {'loss': 0.6995, 'grad_norm': 49.61537551879883, 'learning_rate': 1.2549537648612946e-08, 'rewards/chosen': -0.0029129027388989925, 'rewards/rejected': 0.0066009522415697575, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.009509277530014515, 'logps/chosen': -254.89999389648438, 'logps/rejected': -121.0999984741211, 'logits/chosen': -6.278124809265137, 'logits/rejected': -6.668749809265137, 'epoch': 0.01}
  0%|          | 20/4545 [01:26<4:31:22,  3.60s/it]  0%|          | 21/4545 [01:29<4:19:26,  3.44s/it]  0%|          | 22/4545 [01:33<4:29:10,  3.57s/it]  1%|          | 23/4545 [01:37<4:35:55,  3.66s/it]  1%|          | 24/4545 [01:40<4:22:33,  3.48s/it]  1%|          | 25/4545 [01:44<4:30:37,  3.59s/it]  1%|          | 26/4545 [01:47<4:25:50,  3.53s/it]  1%|          | 27/4545 [01:51<4:33:54,  3.64s/it]  1%|          | 28/4545 [01:55<4:38:32,  3.70s/it]  1%|          | 29/4545 [01:59<4:42:30,  3.75s/it]  1%|          | 30/4545 [02:03<4:51:53,  3.88s/it]                                                   {'loss': 0.6929, 'grad_norm': 85.03448486328125, 'learning_rate': 1.915455746367239e-08, 'rewards/chosen': 0.00969543494284153, 'rewards/rejected': 0.00617561349645257, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 0.00347900390625, 'logps/chosen': -283.1000061035156, 'logps/rejected': -142.35000610351562, 'logits/chosen': -6.190625190734863, 'logits/rejected': -6.546875, 'epoch': 0.02}
  1%|          | 30/4545 [02:03<4:51:53,  3.88s/it]  1%|          | 31/4545 [02:07<4:54:42,  3.92s/it]  1%|          | 32/4545 [02:11<4:55:18,  3.93s/it]  1%|          | 33/4545 [02:15<4:54:12,  3.91s/it]  1%|          | 34/4545 [02:19<4:59:14,  3.98s/it]  1%|          | 35/4545 [02:23<4:56:38,  3.95s/it]  1%|          | 36/4545 [02:27<4:48:39,  3.84s/it]  1%|          | 37/4545 [02:30<4:43:07,  3.77s/it]  1%|          | 38/4545 [02:34<4:40:37,  3.74s/it]  1%|          | 39/4545 [02:38<4:43:58,  3.78s/it]  1%|          | 40/4545 [02:42<4:45:14,  3.80s/it]                                                   {'loss': 0.7107, 'grad_norm': 341.3675537109375, 'learning_rate': 2.5759577278731833e-08, 'rewards/chosen': -0.01038360595703125, 'rewards/rejected': 0.01364746131002903, 'rewards/accuracies': 0.39375001192092896, 'rewards/margins': -0.02403564378619194, 'logps/chosen': -416.20001220703125, 'logps/rejected': -175.3000030517578, 'logits/chosen': -6.265625, 'logits/rejected': -6.559374809265137, 'epoch': 0.03}
  1%|          | 40/4545 [02:42<4:45:14,  3.80s/it]  1%|          | 41/4545 [02:45<4:37:34,  3.70s/it]  1%|          | 42/4545 [02:49<4:42:00,  3.76s/it]  1%|          | 43/4545 [02:53<4:45:08,  3.80s/it]  1%|          | 44/4545 [02:57<4:50:10,  3.87s/it]  1%|          | 45/4545 [03:01<4:55:05,  3.93s/it]  1%|          | 46/4545 [03:05<4:55:29,  3.94s/it]  1%|          | 47/4545 [03:09<4:46:49,  3.83s/it]  1%|          | 48/4545 [03:12<4:48:04,  3.84s/it]  1%|          | 49/4545 [03:16<4:48:43,  3.85s/it]  1%|          | 50/4545 [03:20<4:49:17,  3.86s/it]                                                   {'loss': 0.7221, 'grad_norm': 381.1331787109375, 'learning_rate': 3.236459709379128e-08, 'rewards/chosen': 0.0058197020553052425, 'rewards/rejected': 0.0072845458053052425, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -0.0014526366721838713, 'logps/chosen': -366.3999938964844, 'logps/rejected': -201.0, 'logits/chosen': -6.296875, 'logits/rejected': -6.481249809265137, 'epoch': 0.03}
  1%|          | 50/4545 [03:20<4:49:17,  3.86s/it]  1%|          | 51/4545 [03:24<4:45:16,  3.81s/it]  1%|          | 52/4545 [03:28<4:43:43,  3.79s/it]  1%|          | 53/4545 [03:31<4:38:41,  3.72s/it]  1%|          | 54/4545 [03:35<4:46:38,  3.83s/it]  1%|          | 55/4545 [03:39<4:47:28,  3.84s/it]  1%|          | 56/4545 [03:43<4:44:54,  3.81s/it]  1%|▏         | 57/4545 [03:47<4:46:24,  3.83s/it]  1%|▏         | 58/4545 [03:50<4:42:41,  3.78s/it]  1%|▏         | 59/4545 [03:54<4:26:46,  3.57s/it]  1%|▏         | 60/4545 [03:57<4:33:22,  3.66s/it]                                                   {'loss': 0.6965, 'grad_norm': 83.10525512695312, 'learning_rate': 3.896961690885073e-08, 'rewards/chosen': -0.0009788513416424394, 'rewards/rejected': -0.0018432617653161287, 'rewards/accuracies': 0.3812499940395355, 'rewards/margins': 0.0008666992071084678, 'logps/chosen': -227.35000610351562, 'logps/rejected': -122.6500015258789, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.590624809265137, 'epoch': 0.04}
  1%|▏         | 60/4545 [03:57<4:33:22,  3.66s/it]  1%|▏         | 61/4545 [04:01<4:23:16,  3.52s/it]  1%|▏         | 62/4545 [04:04<4:25:54,  3.56s/it]  1%|▏         | 63/4545 [04:08<4:32:55,  3.65s/it]  1%|▏         | 64/4545 [04:12<4:39:00,  3.74s/it]  1%|▏         | 65/4545 [04:15<4:17:03,  3.44s/it]  1%|▏         | 66/4545 [04:18<4:19:33,  3.48s/it]  1%|▏         | 67/4545 [04:22<4:31:39,  3.64s/it]  1%|▏         | 68/4545 [04:26<4:31:28,  3.64s/it]  2%|▏         | 69/4545 [04:30<4:36:54,  3.71s/it]  2%|▏         | 70/4545 [04:33<4:34:34,  3.68s/it]                                                   {'loss': 0.6871, 'grad_norm': 108.34973907470703, 'learning_rate': 4.557463672391017e-08, 'rewards/chosen': 0.01671295240521431, 'rewards/rejected': -0.019014740362763405, 'rewards/accuracies': 0.48124998807907104, 'rewards/margins': 0.03578491136431694, 'logps/chosen': -316.04998779296875, 'logps/rejected': -155.1750030517578, 'logits/chosen': -6.15625, 'logits/rejected': -6.556250095367432, 'epoch': 0.05}
  2%|▏         | 70/4545 [04:34<4:34:34,  3.68s/it]  2%|▏         | 71/4545 [04:38<4:48:24,  3.87s/it]  2%|▏         | 72/4545 [04:41<4:30:05,  3.62s/it]  2%|▏         | 73/4545 [04:45<4:41:05,  3.77s/it]  2%|▏         | 74/4545 [04:49<4:47:22,  3.86s/it]  2%|▏         | 75/4545 [04:53<4:47:52,  3.86s/it]  2%|▏         | 76/4545 [04:57<4:41:55,  3.78s/it]  2%|▏         | 77/4545 [05:00<4:45:34,  3.84s/it]  2%|▏         | 78/4545 [05:04<4:47:30,  3.86s/it]  2%|▏         | 79/4545 [05:08<4:47:45,  3.87s/it]  2%|▏         | 80/4545 [05:12<4:48:06,  3.87s/it]                                                   {'loss': 0.7483, 'grad_norm': 345.1416931152344, 'learning_rate': 5.2179656538969616e-08, 'rewards/chosen': 0.019289398565888405, 'rewards/rejected': 0.06916503608226776, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.05005493015050888, 'logps/chosen': -352.54998779296875, 'logps/rejected': -216.39999389648438, 'logits/chosen': -6.237500190734863, 'logits/rejected': -6.418749809265137, 'epoch': 0.05}
  2%|▏         | 80/4545 [05:12<4:48:06,  3.87s/it]  2%|▏         | 81/4545 [05:16<4:47:22,  3.86s/it]  2%|▏         | 82/4545 [05:20<4:42:08,  3.79s/it]  2%|▏         | 83/4545 [05:23<4:41:45,  3.79s/it]  2%|▏         | 84/4545 [05:26<4:21:43,  3.52s/it]  2%|▏         | 85/4545 [05:30<4:33:37,  3.68s/it]  2%|▏         | 86/4545 [05:34<4:41:01,  3.78s/it]  2%|▏         | 87/4545 [05:38<4:43:05,  3.81s/it]  2%|▏         | 88/4545 [05:42<4:44:33,  3.83s/it]  2%|▏         | 89/4545 [05:45<4:28:23,  3.61s/it]  2%|▏         | 90/4545 [05:49<4:22:06,  3.53s/it]                                                   {'loss': 0.7177, 'grad_norm': 57.10733413696289, 'learning_rate': 5.878467635402906e-08, 'rewards/chosen': 0.028304290026426315, 'rewards/rejected': 0.020206069573760033, 'rewards/accuracies': 0.38749998807907104, 'rewards/margins': 0.008135223761200905, 'logps/chosen': -322.25, 'logps/rejected': -167.25, 'logits/chosen': -6.371874809265137, 'logits/rejected': -6.646874904632568, 'epoch': 0.06}
  2%|▏         | 90/4545 [05:49<4:22:06,  3.53s/it]  2%|▏         | 91/4545 [05:52<4:31:00,  3.65s/it]  2%|▏         | 92/4545 [05:56<4:37:22,  3.74s/it]  2%|▏         | 93/4545 [06:00<4:40:28,  3.78s/it]  2%|▏         | 94/4545 [06:04<4:42:49,  3.81s/it]  2%|▏         | 95/4545 [06:08<4:43:08,  3.82s/it]  2%|▏         | 96/4545 [06:12<4:43:46,  3.83s/it]  2%|▏         | 97/4545 [06:16<4:44:48,  3.84s/it]  2%|▏         | 98/4545 [06:19<4:31:50,  3.67s/it]  2%|▏         | 99/4545 [06:22<4:19:59,  3.51s/it]  2%|▏         | 100/4545 [06:25<4:16:01,  3.46s/it]                                                    {'loss': 0.68, 'grad_norm': 46.64662170410156, 'learning_rate': 6.53896961690885e-08, 'rewards/chosen': 0.05765991285443306, 'rewards/rejected': -0.02143096923828125, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 0.07904052734375, 'logps/chosen': -329.8999938964844, 'logps/rejected': -159.77499389648438, 'logits/chosen': -6.300000190734863, 'logits/rejected': -6.671875, 'epoch': 0.07}
  2%|▏         | 100/4545 [06:26<4:16:01,  3.46s/it]  2%|▏         | 101/4545 [06:29<4:25:56,  3.59s/it]  2%|▏         | 102/4545 [06:33<4:30:52,  3.66s/it]  2%|▏         | 103/4545 [06:36<4:08:49,  3.36s/it]  2%|▏         | 104/4545 [06:40<4:14:49,  3.44s/it]  2%|▏         | 105/4545 [06:43<4:14:53,  3.44s/it]  2%|▏         | 106/4545 [06:47<4:19:55,  3.51s/it]  2%|▏         | 107/4545 [06:51<4:28:20,  3.63s/it]  2%|▏         | 108/4545 [06:54<4:28:43,  3.63s/it]  2%|▏         | 109/4545 [06:58<4:33:55,  3.71s/it]  2%|▏         | 110/4545 [07:02<4:43:40,  3.84s/it]                                                    {'loss': 0.6861, 'grad_norm': 255.44903564453125, 'learning_rate': 7.199471598414796e-08, 'rewards/chosen': 0.05770416185259819, 'rewards/rejected': 0.0003784179571084678, 'rewards/accuracies': 0.5, 'rewards/margins': 0.05737457424402237, 'logps/chosen': -220.9499969482422, 'logps/rejected': -128.35000610351562, 'logits/chosen': -6.318749904632568, 'logits/rejected': -6.637499809265137, 'epoch': 0.07}
  2%|▏         | 110/4545 [07:03<4:43:40,  3.84s/it]  2%|▏         | 111/4545 [07:07<4:54:15,  3.98s/it]  2%|▏         | 112/4545 [07:10<4:51:53,  3.95s/it]  2%|▏         | 113/4545 [07:14<4:50:02,  3.93s/it]  3%|▎         | 114/4545 [07:18<4:47:57,  3.90s/it]  3%|▎         | 115/4545 [07:22<4:48:29,  3.91s/it]  3%|▎         | 116/4545 [07:26<4:48:16,  3.91s/it]  3%|▎         | 117/4545 [07:30<4:54:11,  3.99s/it]  3%|▎         | 118/4545 [07:34<4:58:27,  4.04s/it]  3%|▎         | 119/4545 [07:38<4:53:12,  3.97s/it]  3%|▎         | 120/4545 [07:42<4:44:59,  3.86s/it]                                                    {'loss': 0.7047, 'grad_norm': 50.849639892578125, 'learning_rate': 7.85997357992074e-08, 'rewards/chosen': 0.07825317233800888, 'rewards/rejected': 0.02977294847369194, 'rewards/accuracies': 0.375, 'rewards/margins': 0.04832763597369194, 'logps/chosen': -429.75, 'logps/rejected': -149.35000610351562, 'logits/chosen': -6.118750095367432, 'logits/rejected': -6.650000095367432, 'epoch': 0.08}
  3%|▎         | 120/4545 [07:42<4:44:59,  3.86s/it]  3%|▎         | 121/4545 [07:46<4:46:11,  3.88s/it]  3%|▎         | 122/4545 [07:49<4:46:11,  3.88s/it]  3%|▎         | 123/4545 [07:53<4:45:46,  3.88s/it]  3%|▎         | 124/4545 [07:57<4:39:29,  3.79s/it]  3%|▎         | 125/4545 [08:01<4:45:37,  3.88s/it]  3%|▎         | 126/4545 [08:05<4:46:51,  3.89s/it]  3%|▎         | 127/4545 [08:09<4:40:21,  3.81s/it]  3%|▎         | 128/4545 [08:12<4:41:17,  3.82s/it]  3%|▎         | 129/4545 [08:16<4:42:29,  3.84s/it]  3%|▎         | 130/4545 [08:20<4:43:35,  3.85s/it]                                                    {'loss': 0.6601, 'grad_norm': 48.96699523925781, 'learning_rate': 8.520475561426684e-08, 'rewards/chosen': 0.2895263731479645, 'rewards/rejected': 0.01021728478372097, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2794555723667145, 'logps/chosen': -397.54998779296875, 'logps/rejected': -263.79998779296875, 'logits/chosen': -6.162499904632568, 'logits/rejected': -6.371874809265137, 'epoch': 0.09}
  3%|▎         | 130/4545 [08:20<4:43:35,  3.85s/it]  3%|▎         | 131/4545 [08:24<4:44:47,  3.87s/it]  3%|▎         | 132/4545 [08:28<4:36:31,  3.76s/it]  3%|▎         | 133/4545 [08:31<4:19:42,  3.53s/it]  3%|▎         | 134/4545 [08:34<4:19:37,  3.53s/it]  3%|▎         | 135/4545 [08:37<3:54:33,  3.19s/it]  3%|▎         | 136/4545 [08:40<3:51:39,  3.15s/it]  3%|▎         | 137/4545 [08:44<4:15:39,  3.48s/it]  3%|▎         | 138/4545 [08:48<4:24:16,  3.60s/it]  3%|▎         | 139/4545 [08:51<4:26:38,  3.63s/it]  3%|▎         | 140/4545 [08:55<4:32:16,  3.71s/it]                                                    {'loss': 0.67, 'grad_norm': 52.00218963623047, 'learning_rate': 9.180977542932629e-08, 'rewards/chosen': 0.30503541231155396, 'rewards/rejected': 0.065704345703125, 'rewards/accuracies': 0.4937500059604645, 'rewards/margins': 0.23930053412914276, 'logps/chosen': -324.29998779296875, 'logps/rejected': -180.5749969482422, 'logits/chosen': -6.415625095367432, 'logits/rejected': -6.78125, 'epoch': 0.09}
  3%|▎         | 140/4545 [08:55<4:32:16,  3.71s/it]  3%|▎         | 141/4545 [08:59<4:37:01,  3.77s/it]  3%|▎         | 142/4545 [09:03<4:42:18,  3.85s/it]  3%|▎         | 143/4545 [09:07<4:45:04,  3.89s/it]  3%|▎         | 144/4545 [09:11<4:44:54,  3.88s/it]  3%|▎         | 145/4545 [09:15<4:44:51,  3.88s/it]  3%|▎         | 146/4545 [09:18<4:35:00,  3.75s/it]  3%|▎         | 147/4545 [09:22<4:30:42,  3.69s/it]  3%|▎         | 148/4545 [09:26<4:33:39,  3.73s/it]  3%|▎         | 149/4545 [09:30<4:36:44,  3.78s/it]  3%|▎         | 150/4545 [09:33<4:20:31,  3.56s/it]                                                    {'loss': 0.6547, 'grad_norm': 34.319828033447266, 'learning_rate': 9.841479524438573e-08, 'rewards/chosen': 0.31779783964157104, 'rewards/rejected': 0.0266571044921875, 'rewards/accuracies': 0.612500011920929, 'rewards/margins': 0.29136961698532104, 'logps/chosen': -281.75, 'logps/rejected': -116.7750015258789, 'logits/chosen': -6.334374904632568, 'logits/rejected': -6.681250095367432, 'epoch': 0.1}
  3%|▎         | 150/4545 [09:33<4:20:31,  3.56s/it]  3%|▎         | 151/4545 [09:36<4:13:48,  3.47s/it]  3%|▎         | 152/4545 [09:40<4:20:04,  3.55s/it]  3%|▎         | 153/4545 [09:44<4:27:24,  3.65s/it]  3%|▎         | 154/4545 [09:47<4:26:20,  3.64s/it]  3%|▎         | 155/4545 [09:51<4:31:54,  3.72s/it]  3%|▎         | 156/4545 [09:55<4:31:57,  3.72s/it]  3%|▎         | 157/4545 [09:59<4:32:28,  3.73s/it]  3%|▎         | 158/4545 [10:02<4:31:10,  3.71s/it]  3%|▎         | 159/4545 [10:06<4:41:12,  3.85s/it]  4%|▎         | 160/4545 [10:10<4:42:10,  3.86s/it]                                                    {'loss': 0.7095, 'grad_norm': 141.9628143310547, 'learning_rate': 1.0501981505944517e-07, 'rewards/chosen': 0.25923460721969604, 'rewards/rejected': 0.09824371337890625, 'rewards/accuracies': 0.48750001192092896, 'rewards/margins': 0.16059570014476776, 'logps/chosen': -294.20001220703125, 'logps/rejected': -159.14999389648438, 'logits/chosen': -6.1875, 'logits/rejected': -6.612500190734863, 'epoch': 0.11}
  4%|▎         | 160/4545 [10:10<4:42:10,  3.86s/it]  4%|▎         | 161/4545 [10:14<4:48:01,  3.94s/it]  4%|▎         | 162/4545 [10:18<4:46:12,  3.92s/it]  4%|▎         | 163/4545 [10:22<4:49:24,  3.96s/it]  4%|▎         | 164/4545 [10:26<4:47:30,  3.94s/it]  4%|▎         | 165/4545 [10:30<4:36:18,  3.79s/it]  4%|▎         | 166/4545 [10:34<4:38:27,  3.82s/it]  4%|▎         | 167/4545 [10:37<4:39:55,  3.84s/it]  4%|▎         | 168/4545 [10:41<4:40:55,  3.85s/it]  4%|▎         | 169/4545 [10:45<4:41:19,  3.86s/it]  4%|▎         | 170/4545 [10:49<4:41:57,  3.87s/it]                                                    {'loss': 0.6288, 'grad_norm': 49.20329284667969, 'learning_rate': 1.1162483487450462e-07, 'rewards/chosen': 0.621508777141571, 'rewards/rejected': 0.11251220852136612, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.508221447467804, 'logps/chosen': -461.8500061035156, 'logps/rejected': -206.125, 'logits/chosen': -6.034375190734863, 'logits/rejected': -6.681250095367432, 'epoch': 0.11}
  4%|▎         | 170/4545 [10:49<4:41:57,  3.87s/it]  4%|▍         | 171/4545 [10:52<4:20:31,  3.57s/it]  4%|▍         | 172/4545 [10:56<4:32:09,  3.73s/it]  4%|▍         | 173/4545 [11:00<4:35:29,  3.78s/it]  4%|▍         | 174/4545 [11:04<4:40:54,  3.86s/it]  4%|▍         | 175/4545 [11:07<4:26:40,  3.66s/it]  4%|▍         | 176/4545 [11:11<4:30:28,  3.71s/it]  4%|▍         | 177/4545 [11:14<4:09:22,  3.43s/it]  4%|▍         | 178/4545 [11:18<4:20:49,  3.58s/it]  4%|▍         | 179/4545 [11:21<4:12:42,  3.47s/it]  4%|▍         | 180/4545 [11:25<4:21:36,  3.60s/it]                                                    {'loss': 0.6612, 'grad_norm': 45.939186096191406, 'learning_rate': 1.1822985468956406e-07, 'rewards/chosen': 0.35230714082717896, 'rewards/rejected': 0.03582763671875, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.3160156309604645, 'logps/chosen': -282.70001220703125, 'logps/rejected': -181.77499389648438, 'logits/chosen': -6.315625190734863, 'logits/rejected': -6.568749904632568, 'epoch': 0.12}
  4%|▍         | 180/4545 [11:25<4:21:36,  3.60s/it]  4%|▍         | 181/4545 [11:29<4:28:11,  3.69s/it]  4%|▍         | 182/4545 [11:32<4:18:17,  3.55s/it]  4%|▍         | 183/4545 [11:36<4:21:49,  3.60s/it]  4%|▍         | 184/4545 [11:40<4:28:00,  3.69s/it]  4%|▍         | 185/4545 [11:44<4:32:15,  3.75s/it]  4%|▍         | 186/4545 [11:47<4:28:18,  3.69s/it]  4%|▍         | 187/4545 [11:51<4:32:38,  3.75s/it]  4%|▍         | 188/4545 [11:54<4:17:48,  3.55s/it]  4%|▍         | 189/4545 [11:57<4:10:40,  3.45s/it]  4%|▍         | 190/4545 [12:00<4:02:25,  3.34s/it]                                                    {'loss': 0.6697, 'grad_norm': 50.29981994628906, 'learning_rate': 1.248348745046235e-07, 'rewards/chosen': 0.39592283964157104, 'rewards/rejected': 0.14892883598804474, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.2469482421875, 'logps/chosen': -300.20001220703125, 'logps/rejected': -155.10000610351562, 'logits/chosen': -6.290625095367432, 'logits/rejected': -6.706250190734863, 'epoch': 0.13}
  4%|▍         | 190/4545 [12:01<4:02:25,  3.34s/it]  4%|▍         | 191/4545 [12:04<4:16:13,  3.53s/it]  4%|▍         | 192/4545 [12:08<4:17:22,  3.55s/it]  4%|▍         | 193/4545 [12:11<4:00:18,  3.31s/it]  4%|▍         | 194/4545 [12:13<3:48:16,  3.15s/it]  4%|▍         | 195/4545 [12:17<4:03:21,  3.36s/it]  4%|▍         | 196/4545 [12:21<4:12:56,  3.49s/it]  4%|▍         | 197/4545 [12:25<4:29:29,  3.72s/it]  4%|▍         | 198/4545 [12:29<4:33:15,  3.77s/it]  4%|▍         | 199/4545 [12:33<4:34:36,  3.79s/it]  4%|▍         | 200/4545 [12:37<4:36:39,  3.82s/it]                                                    {'loss': 0.6871, 'grad_norm': 506.91986083984375, 'learning_rate': 1.3143989431968294e-07, 'rewards/chosen': 0.6264892816543579, 'rewards/rejected': 0.24086913466453552, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.3849243223667145, 'logps/chosen': -353.3999938964844, 'logps/rejected': -240.3249969482422, 'logits/chosen': -6.15625, 'logits/rejected': -6.565625190734863, 'epoch': 0.13}
  4%|▍         | 200/4545 [12:37<4:36:39,  3.82s/it]  4%|▍         | 201/4545 [12:41<4:39:26,  3.86s/it]  4%|▍         | 202/4545 [12:45<4:37:59,  3.84s/it]  4%|▍         | 203/4545 [12:48<4:35:30,  3.81s/it]  4%|▍         | 204/4545 [12:53<4:43:10,  3.91s/it]  5%|▍         | 205/4545 [12:56<4:40:23,  3.88s/it]  5%|▍         | 206/4545 [13:00<4:40:32,  3.88s/it]  5%|▍         | 207/4545 [13:04<4:40:11,  3.88s/it]  5%|▍         | 208/4545 [13:08<4:31:06,  3.75s/it]  5%|▍         | 209/4545 [13:12<4:37:24,  3.84s/it]  5%|▍         | 210/4545 [13:16<4:44:29,  3.94s/it]                                                    {'loss': 0.6543, 'grad_norm': 47.72700881958008, 'learning_rate': 1.380449141347424e-07, 'rewards/chosen': 0.45427244901657104, 'rewards/rejected': 0.06352539360523224, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.3913940489292145, 'logps/chosen': -293.79998779296875, 'logps/rejected': -194.60000610351562, 'logits/chosen': -6.234375, 'logits/rejected': -6.512499809265137, 'epoch': 0.14}
  5%|▍         | 210/4545 [13:16<4:44:29,  3.94s/it]  5%|▍         | 211/4545 [13:20<4:46:09,  3.96s/it]  5%|▍         | 212/4545 [13:24<4:47:23,  3.98s/it]  5%|▍         | 213/4545 [13:28<4:45:24,  3.95s/it]  5%|▍         | 214/4545 [13:32<4:42:19,  3.91s/it]  5%|▍         | 215/4545 [13:35<4:39:47,  3.88s/it]  5%|▍         | 216/4545 [13:39<4:39:58,  3.88s/it]  5%|▍         | 217/4545 [13:43<4:38:57,  3.87s/it]  5%|▍         | 218/4545 [13:47<4:38:58,  3.87s/it]  5%|▍         | 219/4545 [13:50<4:25:23,  3.68s/it]  5%|▍         | 220/4545 [13:54<4:34:19,  3.81s/it]                                                    {'loss': 0.648, 'grad_norm': 43.4775505065918, 'learning_rate': 1.4464993394980185e-07, 'rewards/chosen': 0.717333972454071, 'rewards/rejected': 0.15644530951976776, 'rewards/accuracies': 0.606249988079071, 'rewards/margins': 0.5607452392578125, 'logps/chosen': -323.04998779296875, 'logps/rejected': -181.5500030517578, 'logits/chosen': -6.25, 'logits/rejected': -6.565625190734863, 'epoch': 0.15}
  5%|▍         | 220/4545 [13:54<4:34:19,  3.81s/it]  5%|▍         | 221/4545 [13:58<4:28:04,  3.72s/it]  5%|▍         | 222/4545 [14:02<4:39:10,  3.87s/it]  5%|▍         | 223/4545 [14:06<4:39:29,  3.88s/it]  5%|▍         | 224/4545 [14:10<4:39:32,  3.88s/it]  5%|▍         | 225/4545 [14:14<4:45:40,  3.97s/it]  5%|▍         | 226/4545 [14:17<4:15:00,  3.54s/it]  5%|▍         | 227/4545 [14:20<4:22:25,  3.65s/it]  5%|▌         | 228/4545 [14:24<4:21:37,  3.64s/it]  5%|▌         | 229/4545 [14:27<4:11:39,  3.50s/it]  5%|▌         | 230/4545 [14:31<4:20:17,  3.62s/it]                                                    {'loss': 0.6561, 'grad_norm': 32.900028228759766, 'learning_rate': 1.5125495376486128e-07, 'rewards/chosen': 0.9856933355331421, 'rewards/rejected': 0.22036132216453552, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.7647811770439148, 'logps/chosen': -483.3999938964844, 'logps/rejected': -243.02499389648438, 'logits/chosen': -6.028124809265137, 'logits/rejected': -6.28125, 'epoch': 0.15}
  5%|▌         | 230/4545 [14:31<4:20:17,  3.62s/it]  5%|▌         | 231/4545 [14:35<4:34:13,  3.81s/it]  5%|▌         | 232/4545 [14:39<4:40:10,  3.90s/it]  5%|▌         | 233/4545 [14:43<4:32:44,  3.80s/it]  5%|▌         | 234/4545 [14:47<4:35:21,  3.83s/it]  5%|▌         | 235/4545 [14:51<4:39:48,  3.90s/it]  5%|▌         | 236/4545 [14:54<4:27:47,  3.73s/it]  5%|▌         | 237/4545 [14:58<4:32:05,  3.79s/it]  5%|▌         | 238/4545 [15:01<3:58:27,  3.32s/it]  5%|▌         | 239/4545 [15:05<4:12:41,  3.52s/it]  5%|▌         | 240/4545 [15:08<4:20:43,  3.63s/it]                                                    {'loss': 0.5991, 'grad_norm': 42.19855499267578, 'learning_rate': 1.5785997357992073e-07, 'rewards/chosen': 0.6214355230331421, 'rewards/rejected': 0.064849853515625, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.5565735101699829, 'logps/chosen': -295.3500061035156, 'logps/rejected': -136.9499969482422, 'logits/chosen': -6.268750190734863, 'logits/rejected': -6.550000190734863, 'epoch': 0.16}
  5%|▌         | 240/4545 [15:09<4:20:43,  3.63s/it]  5%|▌         | 241/4545 [15:12<4:13:16,  3.53s/it]  5%|▌         | 242/4545 [15:16<4:26:37,  3.72s/it]  5%|▌         | 243/4545 [15:19<4:12:36,  3.52s/it]  5%|▌         | 244/4545 [15:23<4:19:30,  3.62s/it]  5%|▌         | 245/4545 [15:27<4:25:06,  3.70s/it]  5%|▌         | 246/4545 [15:30<4:28:19,  3.74s/it]  5%|▌         | 247/4545 [15:34<4:32:46,  3.81s/it]  5%|▌         | 248/4545 [15:38<4:34:35,  3.83s/it]  5%|▌         | 249/4545 [15:42<4:35:01,  3.84s/it]  6%|▌         | 250/4545 [15:46<4:42:30,  3.95s/it]                                                    {'loss': 0.6246, 'grad_norm': 35.985809326171875, 'learning_rate': 1.6446499339498018e-07, 'rewards/chosen': 0.98779296875, 'rewards/rejected': 0.15399780869483948, 'rewards/accuracies': 0.706250011920929, 'rewards/margins': 0.832763671875, 'logps/chosen': -391.3999938964844, 'logps/rejected': -171.85000610351562, 'logits/chosen': -6.090624809265137, 'logits/rejected': -6.284375190734863, 'epoch': 0.17}
  6%|▌         | 250/4545 [15:47<4:42:30,  3.95s/it]  6%|▌         | 251/4545 [15:50<4:40:01,  3.91s/it]  6%|▌         | 252/4545 [15:54<4:39:32,  3.91s/it]  6%|▌         | 253/4545 [15:57<4:23:55,  3.69s/it]  6%|▌         | 254/4545 [16:01<4:27:26,  3.74s/it]  6%|▌         | 255/4545 [16:05<4:28:18,  3.75s/it]  6%|▌         | 256/4545 [16:09<4:37:09,  3.88s/it]  6%|▌         | 257/4545 [16:13<4:41:14,  3.94s/it]  6%|▌         | 258/4545 [16:17<4:31:45,  3.80s/it]  6%|▌         | 259/4545 [16:19<3:52:05,  3.25s/it]  6%|▌         | 260/4545 [16:23<4:10:27,  3.51s/it]                                                    {'loss': 0.6184, 'grad_norm': 45.3682746887207, 'learning_rate': 1.710700132100396e-07, 'rewards/chosen': 0.489990234375, 'rewards/rejected': 0.07760467380285263, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.412353515625, 'logps/chosen': -210.10000610351562, 'logps/rejected': -104.69999694824219, 'logits/chosen': -6.4375, 'logits/rejected': -6.693749904632568, 'epoch': 0.17}
  6%|▌         | 260/4545 [16:23<4:10:27,  3.51s/it]  6%|▌         | 261/4545 [16:26<4:13:52,  3.56s/it]  6%|▌         | 262/4545 [16:30<4:20:12,  3.65s/it]  6%|▌         | 263/4545 [16:34<4:29:08,  3.77s/it]  6%|▌         | 264/4545 [16:38<4:17:18,  3.61s/it]  6%|▌         | 265/4545 [16:41<4:23:26,  3.69s/it]  6%|▌         | 266/4545 [16:45<4:27:35,  3.75s/it]  6%|▌         | 267/4545 [16:49<4:30:31,  3.79s/it]  6%|▌         | 268/4545 [16:52<4:18:36,  3.63s/it]  6%|▌         | 269/4545 [16:56<4:24:20,  3.71s/it]  6%|▌         | 270/4545 [17:00<4:28:09,  3.76s/it]                                                    {'loss': 0.5853, 'grad_norm': 44.60466003417969, 'learning_rate': 1.7767503302509906e-07, 'rewards/chosen': 1.2204101085662842, 'rewards/rejected': 0.27446287870407104, 'rewards/accuracies': 0.75, 'rewards/margins': 0.947314441204071, 'logps/chosen': -458.1499938964844, 'logps/rejected': -258.5249938964844, 'logits/chosen': -6.165625095367432, 'logits/rejected': -6.328125, 'epoch': 0.18}
  6%|▌         | 270/4545 [17:00<4:28:09,  3.76s/it]  6%|▌         | 271/4545 [17:04<4:32:16,  3.82s/it]  6%|▌         | 272/4545 [17:08<4:28:55,  3.78s/it]  6%|▌         | 273/4545 [17:12<4:31:02,  3.81s/it]  6%|▌         | 274/4545 [17:16<4:33:45,  3.85s/it]  6%|▌         | 275/4545 [17:19<4:15:44,  3.59s/it]  6%|▌         | 276/4545 [17:23<4:30:02,  3.80s/it]  6%|▌         | 277/4545 [17:27<4:34:51,  3.86s/it]  6%|▌         | 278/4545 [17:31<4:35:36,  3.88s/it]  6%|▌         | 279/4545 [17:34<4:25:13,  3.73s/it]  6%|▌         | 280/4545 [17:38<4:28:59,  3.78s/it]                                                    {'loss': 0.5744, 'grad_norm': 59.81767272949219, 'learning_rate': 1.8428005284015852e-07, 'rewards/chosen': 1.1569335460662842, 'rewards/rejected': 0.24611206352710724, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9092346429824829, 'logps/chosen': -387.54998779296875, 'logps/rejected': -170.35000610351562, 'logits/chosen': -6.309374809265137, 'logits/rejected': -6.581250190734863, 'epoch': 0.18}
  6%|▌         | 280/4545 [17:38<4:28:59,  3.78s/it]  6%|▌         | 281/4545 [17:42<4:39:01,  3.93s/it]  6%|▌         | 282/4545 [17:45<4:15:58,  3.60s/it]  6%|▌         | 283/4545 [17:49<4:07:30,  3.48s/it]  6%|▌         | 284/4545 [17:53<4:19:49,  3.66s/it]  6%|▋         | 285/4545 [17:56<4:24:22,  3.72s/it]  6%|▋         | 286/4545 [17:59<4:09:14,  3.51s/it]  6%|▋         | 287/4545 [18:02<3:53:01,  3.28s/it]  6%|▋         | 288/4545 [18:06<4:00:44,  3.39s/it]  6%|▋         | 289/4545 [18:10<4:14:28,  3.59s/it]  6%|▋         | 290/4545 [18:14<4:20:49,  3.68s/it]                                                    {'loss': 0.5554, 'grad_norm': 103.40806579589844, 'learning_rate': 1.9088507265521794e-07, 'rewards/chosen': 1.205468773841858, 'rewards/rejected': 0.3540283143520355, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.851367175579071, 'logps/chosen': -373.8999938964844, 'logps/rejected': -225.8249969482422, 'logits/chosen': -6.065625190734863, 'logits/rejected': -6.449999809265137, 'epoch': 0.19}
  6%|▋         | 290/4545 [18:14<4:20:49,  3.68s/it]  6%|▋         | 291/4545 [18:17<4:19:08,  3.65s/it]  6%|▋         | 292/4545 [18:21<4:23:55,  3.72s/it]  6%|▋         | 293/4545 [18:25<4:30:44,  3.82s/it]  6%|▋         | 294/4545 [18:29<4:32:42,  3.85s/it]  6%|▋         | 295/4545 [18:33<4:25:16,  3.74s/it]  7%|▋         | 296/4545 [18:37<4:29:23,  3.80s/it]  7%|▋         | 297/4545 [18:41<4:30:14,  3.82s/it]  7%|▋         | 298/4545 [18:43<4:07:08,  3.49s/it]  7%|▋         | 299/4545 [18:48<4:24:33,  3.74s/it]  7%|▋         | 300/4545 [18:51<4:13:19,  3.58s/it]                                                    {'loss': 0.6103, 'grad_norm': 56.76252365112305, 'learning_rate': 1.974900924702774e-07, 'rewards/chosen': 0.8973633050918579, 'rewards/rejected': 0.24624022841453552, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.6505126953125, 'logps/chosen': -279.8999938964844, 'logps/rejected': -148.3000030517578, 'logits/chosen': -6.212500095367432, 'logits/rejected': -6.434374809265137, 'epoch': 0.2}
  7%|▋         | 300/4545 [18:51<4:13:19,  3.58s/it]  7%|▋         | 301/4545 [18:54<4:07:21,  3.50s/it]  7%|▋         | 302/4545 [18:58<4:20:02,  3.68s/it]  7%|▋         | 303/4545 [19:01<3:58:39,  3.38s/it]  7%|▋         | 304/4545 [19:05<4:05:33,  3.47s/it]  7%|▋         | 305/4545 [19:09<4:16:04,  3.62s/it]  7%|▋         | 306/4545 [19:12<4:21:40,  3.70s/it]  7%|▋         | 307/4545 [19:16<4:24:45,  3.75s/it]  7%|▋         | 308/4545 [19:20<4:26:59,  3.78s/it]  7%|▋         | 309/4545 [19:24<4:30:00,  3.82s/it]  7%|▋         | 310/4545 [19:28<4:32:43,  3.86s/it]                                                    {'loss': 0.5775, 'grad_norm': 44.432952880859375, 'learning_rate': 2.0409511228533685e-07, 'rewards/chosen': 1.8660156726837158, 'rewards/rejected': 0.4927001893520355, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.374609351158142, 'logps/chosen': -473.75, 'logps/rejected': -261.04998779296875, 'logits/chosen': -6.068749904632568, 'logits/rejected': -6.159375190734863, 'epoch': 0.2}
  7%|▋         | 310/4545 [19:28<4:32:43,  3.86s/it]  7%|▋         | 311/4545 [19:32<4:33:45,  3.88s/it]  7%|▋         | 312/4545 [19:35<4:15:58,  3.63s/it]  7%|▋         | 313/4545 [19:39<4:21:22,  3.71s/it]  7%|▋         | 314/4545 [19:43<4:25:37,  3.77s/it]  7%|▋         | 315/4545 [19:47<4:28:25,  3.81s/it]  7%|▋         | 316/4545 [19:50<4:28:06,  3.80s/it]  7%|▋         | 317/4545 [19:53<3:59:18,  3.40s/it]  7%|▋         | 318/4545 [19:57<4:11:29,  3.57s/it]  7%|▋         | 319/4545 [20:01<4:19:52,  3.69s/it]  7%|▋         | 320/4545 [20:05<4:23:44,  3.75s/it]                                                    {'loss': 0.5556, 'grad_norm': 54.771846771240234, 'learning_rate': 2.107001321003963e-07, 'rewards/chosen': 1.017968773841858, 'rewards/rejected': 0.20635986328125, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 0.8125, 'logps/chosen': -285.6499938964844, 'logps/rejected': -168.02499389648438, 'logits/chosen': -6.346875190734863, 'logits/rejected': -6.671875, 'epoch': 0.21}
  7%|▋         | 320/4545 [20:05<4:23:44,  3.75s/it]  7%|▋         | 321/4545 [20:08<4:13:10,  3.60s/it]  7%|▋         | 322/4545 [20:12<4:21:56,  3.72s/it]  7%|▋         | 323/4545 [20:16<4:31:46,  3.86s/it]  7%|▋         | 324/4545 [20:20<4:24:36,  3.76s/it]  7%|▋         | 325/4545 [20:23<4:21:37,  3.72s/it]  7%|▋         | 326/4545 [20:27<4:25:07,  3.77s/it]  7%|▋         | 327/4545 [20:31<4:30:25,  3.85s/it]  7%|▋         | 328/4545 [20:35<4:32:10,  3.87s/it]  7%|▋         | 329/4545 [20:39<4:32:36,  3.88s/it]  7%|▋         | 330/4545 [20:43<4:29:39,  3.84s/it]                                                    {'loss': 0.6108, 'grad_norm': 39.36732482910156, 'learning_rate': 2.1730515191545573e-07, 'rewards/chosen': 0.8541015386581421, 'rewards/rejected': 0.20765380561351776, 'rewards/accuracies': 0.706250011920929, 'rewards/margins': 0.644824206829071, 'logps/chosen': -222.89999389648438, 'logps/rejected': -146.35000610351562, 'logits/chosen': -6.390625, 'logits/rejected': -6.371874809265137, 'epoch': 0.22}
  7%|▋         | 330/4545 [20:43<4:29:39,  3.84s/it]  7%|▋         | 331/4545 [20:46<4:16:26,  3.65s/it]  7%|▋         | 332/4545 [20:50<4:24:14,  3.76s/it]  7%|▋         | 333/4545 [20:54<4:17:38,  3.67s/it]  7%|▋         | 334/4545 [20:58<4:26:08,  3.79s/it]  7%|▋         | 335/4545 [21:01<4:15:29,  3.64s/it]  7%|▋         | 336/4545 [21:04<4:05:46,  3.50s/it]  7%|▋         | 337/4545 [21:08<4:18:54,  3.69s/it]  7%|▋         | 338/4545 [21:11<4:06:35,  3.52s/it]  7%|▋         | 339/4545 [21:15<4:14:23,  3.63s/it]  7%|▋         | 340/4545 [21:19<4:19:45,  3.71s/it]                                                    {'loss': 0.569, 'grad_norm': 48.58868408203125, 'learning_rate': 2.2391017173051518e-07, 'rewards/chosen': 0.784960925579071, 'rewards/rejected': 0.21668091416358948, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.5679687261581421, 'logps/chosen': -175.0, 'logps/rejected': -113.3499984741211, 'logits/chosen': -6.453125, 'logits/rejected': -6.734375, 'epoch': 0.22}
  7%|▋         | 340/4545 [21:19<4:19:45,  3.71s/it]  8%|▊         | 341/4545 [21:23<4:24:49,  3.78s/it]  8%|▊         | 342/4545 [21:27<4:27:01,  3.81s/it]  8%|▊         | 343/4545 [21:31<4:29:29,  3.85s/it]  8%|▊         | 344/4545 [21:34<4:23:27,  3.76s/it]  8%|▊         | 345/4545 [21:37<4:04:02,  3.49s/it]  8%|▊         | 346/4545 [21:41<4:11:59,  3.60s/it]  8%|▊         | 347/4545 [21:45<4:22:50,  3.76s/it]  8%|▊         | 348/4545 [21:49<4:28:48,  3.84s/it]  8%|▊         | 349/4545 [21:53<4:29:57,  3.86s/it]  8%|▊         | 350/4545 [21:57<4:29:39,  3.86s/it]                                                    {'loss': 0.5449, 'grad_norm': 36.76318359375, 'learning_rate': 2.3051519154557464e-07, 'rewards/chosen': 1.558203101158142, 'rewards/rejected': 0.3197570741176605, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 1.237890601158142, 'logps/chosen': -392.8999938964844, 'logps/rejected': -193.0, 'logits/chosen': -6.150000095367432, 'logits/rejected': -6.268750190734863, 'epoch': 0.23}
  8%|▊         | 350/4545 [21:57<4:29:39,  3.86s/it]  8%|▊         | 351/4545 [22:01<4:30:33,  3.87s/it]  8%|▊         | 352/4545 [22:03<4:02:45,  3.47s/it]  8%|▊         | 353/4545 [22:07<4:10:23,  3.58s/it]  8%|▊         | 354/4545 [22:11<4:19:17,  3.71s/it]  8%|▊         | 355/4545 [22:15<4:23:26,  3.77s/it]  8%|▊         | 356/4545 [22:19<4:29:32,  3.86s/it]  8%|▊         | 357/4545 [22:23<4:18:20,  3.70s/it]  8%|▊         | 358/4545 [22:25<3:49:55,  3.29s/it]  8%|▊         | 359/4545 [22:29<4:06:01,  3.53s/it]  8%|▊         | 360/4545 [22:33<4:14:36,  3.65s/it]                                                    {'loss': 0.5124, 'grad_norm': 69.37612915039062, 'learning_rate': 2.3712021136063406e-07, 'rewards/chosen': 1.438085913658142, 'rewards/rejected': 0.23795166611671448, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.200585961341858, 'logps/chosen': -324.1000061035156, 'logps/rejected': -171.375, 'logits/chosen': -6.290625095367432, 'logits/rejected': -6.493750095367432, 'epoch': 0.24}
  8%|▊         | 360/4545 [22:33<4:14:36,  3.65s/it]  8%|▊         | 361/4545 [22:36<4:06:53,  3.54s/it]  8%|▊         | 362/4545 [22:40<4:14:36,  3.65s/it]  8%|▊         | 363/4545 [22:44<4:18:37,  3.71s/it]  8%|▊         | 364/4545 [22:47<4:06:18,  3.53s/it]  8%|▊         | 365/4545 [22:51<4:15:13,  3.66s/it]  8%|▊         | 366/4545 [22:55<4:20:03,  3.73s/it]  8%|▊         | 367/4545 [22:59<4:27:00,  3.83s/it]  8%|▊         | 368/4545 [23:03<4:28:15,  3.85s/it]  8%|▊         | 369/4545 [23:07<4:28:58,  3.86s/it]  8%|▊         | 370/4545 [23:11<4:29:43,  3.88s/it]                                                    {'loss': 0.5041, 'grad_norm': 47.21735763549805, 'learning_rate': 2.437252311756935e-07, 'rewards/chosen': 2.205859422683716, 'rewards/rejected': 0.4228149354457855, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.7841796875, 'logps/chosen': -482.6499938964844, 'logps/rejected': -242.1999969482422, 'logits/chosen': -6.231249809265137, 'logits/rejected': -6.515625, 'epoch': 0.24}
  8%|▊         | 370/4545 [23:11<4:29:43,  3.88s/it]  8%|▊         | 371/4545 [23:14<4:18:15,  3.71s/it]  8%|▊         | 372/4545 [23:18<4:27:48,  3.85s/it]  8%|▊         | 373/4545 [23:22<4:28:22,  3.86s/it]  8%|▊         | 374/4545 [23:26<4:23:49,  3.80s/it]  8%|▊         | 375/4545 [23:29<4:03:02,  3.50s/it]  8%|▊         | 376/4545 [23:32<4:10:10,  3.60s/it]  8%|▊         | 377/4545 [23:36<4:15:35,  3.68s/it]  8%|▊         | 378/4545 [23:40<4:17:57,  3.71s/it]  8%|▊         | 379/4545 [23:42<3:29:18,  3.01s/it]  8%|▊         | 380/4545 [23:45<3:41:18,  3.19s/it]                                                    {'loss': 0.5466, 'grad_norm': 28.728647232055664, 'learning_rate': 2.5033025099075294e-07, 'rewards/chosen': 0.9013671875, 'rewards/rejected': 0.180999755859375, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.7220703363418579, 'logps/chosen': -205.47500610351562, 'logps/rejected': -136.0, 'logits/chosen': -6.40625, 'logits/rejected': -6.556250095367432, 'epoch': 0.25}
  8%|▊         | 380/4545 [23:45<3:41:18,  3.19s/it]  8%|▊         | 381/4545 [23:48<3:36:50,  3.12s/it]  8%|▊         | 382/4545 [23:52<3:51:43,  3.34s/it]  8%|▊         | 383/4545 [23:56<4:03:07,  3.50s/it]  8%|▊         | 384/4545 [24:00<4:11:23,  3.63s/it]  8%|▊         | 385/4545 [24:03<4:14:26,  3.67s/it]  8%|▊         | 386/4545 [24:07<4:18:43,  3.73s/it]  9%|▊         | 387/4545 [24:12<4:27:05,  3.85s/it]  9%|▊         | 388/4545 [24:15<4:27:27,  3.86s/it]  9%|▊         | 389/4545 [24:19<4:27:41,  3.86s/it]  9%|▊         | 390/4545 [24:23<4:28:02,  3.87s/it]                                                    {'loss': 0.5069, 'grad_norm': 30.493452072143555, 'learning_rate': 2.569352708058124e-07, 'rewards/chosen': 1.793359398841858, 'rewards/rejected': 0.31383055448532104, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.479248046875, 'logps/chosen': -369.04998779296875, 'logps/rejected': -190.3249969482422, 'logits/chosen': -6.287499904632568, 'logits/rejected': -6.515625, 'epoch': 0.26}
  9%|▊         | 390/4545 [24:23<4:28:02,  3.87s/it]  9%|▊         | 391/4545 [24:27<4:30:36,  3.91s/it]  9%|▊         | 392/4545 [24:31<4:36:15,  3.99s/it]  9%|▊         | 393/4545 [24:35<4:34:00,  3.96s/it]  9%|▊         | 394/4545 [24:39<4:27:13,  3.86s/it]  9%|▊         | 395/4545 [24:42<4:17:58,  3.73s/it]  9%|▊         | 396/4545 [24:46<4:22:10,  3.79s/it]  9%|▊         | 397/4545 [24:50<4:25:55,  3.85s/it]  9%|▉         | 398/4545 [24:54<4:22:47,  3.80s/it]  9%|▉         | 399/4545 [24:58<4:24:31,  3.83s/it]  9%|▉         | 400/4545 [25:02<4:26:11,  3.85s/it]                                                    {'loss': 0.4742, 'grad_norm': 39.784149169921875, 'learning_rate': 2.6354029062087185e-07, 'rewards/chosen': 1.5564453601837158, 'rewards/rejected': 0.06585083156824112, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.4914062023162842, 'logps/chosen': -296.25, 'logps/rejected': -166.3000030517578, 'logits/chosen': -6.371874809265137, 'logits/rejected': -6.65625, 'epoch': 0.26}
  9%|▉         | 400/4545 [25:02<4:26:11,  3.85s/it]  9%|▉         | 401/4545 [25:05<4:12:50,  3.66s/it]  9%|▉         | 402/4545 [25:09<4:23:16,  3.81s/it]  9%|▉         | 403/4545 [25:13<4:24:51,  3.84s/it]  9%|▉         | 404/4545 [25:17<4:25:51,  3.85s/it]  9%|▉         | 405/4545 [25:19<3:52:58,  3.38s/it]  9%|▉         | 406/4545 [25:22<3:42:23,  3.22s/it]  9%|▉         | 407/4545 [25:25<3:32:17,  3.08s/it]  9%|▉         | 408/4545 [25:29<3:51:10,  3.35s/it]  9%|▉         | 409/4545 [25:32<3:53:26,  3.39s/it]  9%|▉         | 410/4545 [25:36<3:57:06,  3.44s/it]                                                    {'loss': 0.5058, 'grad_norm': 24.40729522705078, 'learning_rate': 2.7014531043593133e-07, 'rewards/chosen': 0.9750000238418579, 'rewards/rejected': -0.03094482421875, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.0066406726837158, 'logps/chosen': -195.35000610351562, 'logps/rejected': -128.5749969482422, 'logits/chosen': -6.390625, 'logits/rejected': -6.5625, 'epoch': 0.27}
  9%|▉         | 410/4545 [25:36<3:57:06,  3.44s/it]  9%|▉         | 411/4545 [25:40<4:07:29,  3.59s/it]  9%|▉         | 412/4545 [25:44<4:12:51,  3.67s/it]  9%|▉         | 413/4545 [25:47<4:04:49,  3.56s/it]  9%|▉         | 414/4545 [25:51<4:14:40,  3.70s/it]  9%|▉         | 415/4545 [25:54<3:53:34,  3.39s/it]  9%|▉         | 416/4545 [25:56<3:40:19,  3.20s/it]  9%|▉         | 417/4545 [26:00<3:54:30,  3.41s/it]  9%|▉         | 418/4545 [26:03<3:43:51,  3.25s/it]  9%|▉         | 419/4545 [26:07<3:56:33,  3.44s/it]  9%|▉         | 420/4545 [26:10<3:48:58,  3.33s/it]                                                    {'loss': 0.5063, 'grad_norm': 51.35235595703125, 'learning_rate': 2.7675033025099076e-07, 'rewards/chosen': 1.342187523841858, 'rewards/rejected': 0.03781585767865181, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3029296398162842, 'logps/chosen': -264.45001220703125, 'logps/rejected': -144.4250030517578, 'logits/chosen': -6.340624809265137, 'logits/rejected': -6.556250095367432, 'epoch': 0.28}
  9%|▉         | 420/4545 [26:11<3:48:58,  3.33s/it]  9%|▉         | 421/4545 [26:14<4:01:39,  3.52s/it]  9%|▉         | 422/4545 [26:18<4:09:15,  3.63s/it]  9%|▉         | 423/4545 [26:21<3:59:50,  3.49s/it]  9%|▉         | 424/4545 [26:25<4:01:18,  3.51s/it]  9%|▉         | 425/4545 [26:28<4:02:44,  3.54s/it]  9%|▉         | 426/4545 [26:32<4:09:47,  3.64s/it]  9%|▉         | 427/4545 [26:36<4:16:33,  3.74s/it]  9%|▉         | 428/4545 [26:38<3:38:26,  3.18s/it]  9%|▉         | 429/4545 [26:41<3:41:43,  3.23s/it]  9%|▉         | 430/4545 [26:45<3:58:16,  3.47s/it]                                                    {'loss': 0.5051, 'grad_norm': 70.92908477783203, 'learning_rate': 2.833553500660502e-07, 'rewards/chosen': 1.303125023841858, 'rewards/rejected': 0.02089843712747097, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 1.28125, 'logps/chosen': -278.17498779296875, 'logps/rejected': -120.30000305175781, 'logits/chosen': -6.278124809265137, 'logits/rejected': -6.543749809265137, 'epoch': 0.28}
  9%|▉         | 430/4545 [26:46<3:58:16,  3.47s/it]  9%|▉         | 431/4545 [26:50<4:13:04,  3.69s/it] 10%|▉         | 432/4545 [26:53<4:16:22,  3.74s/it] 10%|▉         | 433/4545 [26:57<4:22:43,  3.83s/it] 10%|▉         | 434/4545 [27:02<4:29:21,  3.93s/it] 10%|▉         | 435/4545 [27:04<4:08:13,  3.62s/it] 10%|▉         | 436/4545 [27:08<4:14:45,  3.72s/it] 10%|▉         | 437/4545 [27:13<4:23:30,  3.85s/it] 10%|▉         | 438/4545 [27:16<4:08:15,  3.63s/it] 10%|▉         | 439/4545 [27:19<3:52:15,  3.39s/it] 10%|▉         | 440/4545 [27:22<4:03:36,  3.56s/it]                                                    {'loss': 0.535, 'grad_norm': 58.365562438964844, 'learning_rate': 2.899603698811096e-07, 'rewards/chosen': 1.0830566883087158, 'rewards/rejected': 0.19527587294578552, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.88873291015625, 'logps/chosen': -209.52499389648438, 'logps/rejected': -163.25, 'logits/chosen': -6.428124904632568, 'logits/rejected': -6.543749809265137, 'epoch': 0.29}
 10%|▉         | 440/4545 [27:23<4:03:36,  3.56s/it] 10%|▉         | 441/4545 [27:26<4:09:59,  3.65s/it] 10%|▉         | 442/4545 [27:30<4:02:05,  3.54s/it] 10%|▉         | 443/4545 [27:34<4:12:14,  3.69s/it] 10%|▉         | 444/4545 [27:38<4:15:29,  3.74s/it] 10%|▉         | 445/4545 [27:40<3:55:16,  3.44s/it] 10%|▉         | 446/4545 [27:44<4:09:42,  3.66s/it] 10%|▉         | 447/4545 [27:47<3:45:37,  3.30s/it] 10%|▉         | 448/4545 [27:51<3:57:45,  3.48s/it] 10%|▉         | 449/4545 [27:55<4:06:40,  3.61s/it] 10%|▉         | 450/4545 [27:59<4:12:35,  3.70s/it]                                                    {'loss': 0.4102, 'grad_norm': 19.168384552001953, 'learning_rate': 2.965653896961691e-07, 'rewards/chosen': 1.906835913658142, 'rewards/rejected': -0.02979736402630806, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.9367187023162842, 'logps/chosen': -355.0249938964844, 'logps/rejected': -181.4250030517578, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.5625, 'epoch': 0.3}
 10%|▉         | 450/4545 [27:59<4:12:35,  3.70s/it] 10%|▉         | 451/4545 [28:03<4:22:09,  3.84s/it] 10%|▉         | 452/4545 [28:07<4:22:56,  3.85s/it] 10%|▉         | 453/4545 [28:11<4:25:46,  3.90s/it] 10%|▉         | 454/4545 [28:15<4:25:40,  3.90s/it] 10%|█         | 455/4545 [28:18<4:24:36,  3.88s/it] 10%|█         | 456/4545 [28:22<4:19:04,  3.80s/it] 10%|█         | 457/4545 [28:26<4:21:12,  3.83s/it] 10%|█         | 458/4545 [28:30<4:22:14,  3.85s/it] 10%|█         | 459/4545 [28:34<4:23:54,  3.88s/it] 10%|█         | 460/4545 [28:37<4:18:34,  3.80s/it]                                                    {'loss': 0.4849, 'grad_norm': 71.2275619506836, 'learning_rate': 3.031704095112285e-07, 'rewards/chosen': 2.6187500953674316, 'rewards/rejected': 0.3654541075229645, 'rewards/accuracies': 0.78125, 'rewards/margins': 2.250195264816284, 'logps/chosen': -528.0999755859375, 'logps/rejected': -278.54998779296875, 'logits/chosen': -6.234375, 'logits/rejected': -6.387499809265137, 'epoch': 0.3}
 10%|█         | 460/4545 [28:38<4:18:34,  3.80s/it] 10%|█         | 461/4545 [28:41<4:23:18,  3.87s/it] 10%|█         | 462/4545 [28:45<4:27:24,  3.93s/it] 10%|█         | 463/4545 [28:49<4:26:20,  3.91s/it] 10%|█         | 464/4545 [28:53<4:11:32,  3.70s/it] 10%|█         | 465/4545 [28:56<4:15:46,  3.76s/it] 10%|█         | 466/4545 [28:59<3:56:41,  3.48s/it] 10%|█         | 467/4545 [29:03<4:04:50,  3.60s/it] 10%|█         | 468/4545 [29:07<4:10:57,  3.69s/it] 10%|█         | 469/4545 [29:11<4:14:50,  3.75s/it] 10%|█         | 470/4545 [29:13<3:49:26,  3.38s/it]                                                    {'loss': 0.4255, 'grad_norm': 37.64488983154297, 'learning_rate': 3.09775429326288e-07, 'rewards/chosen': 1.0666015148162842, 'rewards/rejected': -0.30155640840530396, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.3654296398162842, 'logps/chosen': -203.5500030517578, 'logps/rejected': -101.5250015258789, 'logits/chosen': -6.5, 'logits/rejected': -6.443749904632568, 'epoch': 0.31}
 10%|█         | 470/4545 [29:14<3:49:26,  3.38s/it] 10%|█         | 471/4545 [29:18<4:03:44,  3.59s/it] 10%|█         | 472/4545 [29:22<4:15:28,  3.76s/it] 10%|█         | 473/4545 [29:26<4:19:46,  3.83s/it] 10%|█         | 474/4545 [29:29<4:18:46,  3.81s/it] 10%|█         | 475/4545 [29:33<4:19:49,  3.83s/it] 10%|█         | 476/4545 [29:37<4:23:23,  3.88s/it] 10%|█         | 477/4545 [29:41<4:23:30,  3.89s/it] 11%|█         | 478/4545 [29:45<4:17:55,  3.81s/it] 11%|█         | 479/4545 [29:48<4:08:05,  3.66s/it] 11%|█         | 480/4545 [29:52<4:13:04,  3.74s/it]                                                    {'loss': 0.4222, 'grad_norm': 22.186452865600586, 'learning_rate': 3.163804491413474e-07, 'rewards/chosen': 1.3738281726837158, 'rewards/rejected': -0.24370117485523224, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.616796851158142, 'logps/chosen': -268.54998779296875, 'logps/rejected': -162.85000610351562, 'logits/chosen': -6.478125095367432, 'logits/rejected': -6.662499904632568, 'epoch': 0.32}
 11%|█         | 480/4545 [29:52<4:13:04,  3.74s/it] 11%|█         | 481/4545 [29:56<4:18:24,  3.82s/it] 11%|█         | 482/4545 [30:00<4:19:53,  3.84s/it] 11%|█         | 483/4545 [30:04<4:18:39,  3.82s/it] 11%|█         | 484/4545 [30:08<4:22:15,  3.87s/it] 11%|█         | 485/4545 [30:12<4:26:01,  3.93s/it] 11%|█         | 486/4545 [30:15<4:19:52,  3.84s/it] 11%|█         | 487/4545 [30:18<3:52:46,  3.44s/it] 11%|█         | 488/4545 [30:22<4:05:16,  3.63s/it] 11%|█         | 489/4545 [30:26<4:11:39,  3.72s/it] 11%|█         | 490/4545 [30:30<4:14:27,  3.77s/it]                                                    {'loss': 0.4644, 'grad_norm': 53.26318359375, 'learning_rate': 3.229854689564069e-07, 'rewards/chosen': 1.3230469226837158, 'rewards/rejected': -0.2099609375, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.5320312976837158, 'logps/chosen': -256.1000061035156, 'logps/rejected': -113.57499694824219, 'logits/chosen': -6.599999904632568, 'logits/rejected': -6.646874904632568, 'epoch': 0.32}
 11%|█         | 490/4545 [30:30<4:14:27,  3.77s/it] 11%|█         | 491/4545 [30:33<3:52:55,  3.45s/it] 11%|█         | 492/4545 [30:37<4:04:32,  3.62s/it] 11%|█         | 493/4545 [30:41<4:14:21,  3.77s/it] 11%|█         | 494/4545 [30:45<4:19:38,  3.85s/it] 11%|█         | 495/4545 [30:48<4:16:54,  3.81s/it] 11%|█         | 496/4545 [30:52<4:09:49,  3.70s/it] 11%|█         | 497/4545 [30:56<4:11:19,  3.73s/it] 11%|█         | 498/4545 [31:00<4:14:36,  3.77s/it] 11%|█         | 499/4545 [31:03<4:14:12,  3.77s/it] 11%|█         | 500/4545 [31:07<4:18:32,  3.84s/it]                                                    {'loss': 0.4324, 'grad_norm': 67.94123840332031, 'learning_rate': 3.295904887714663e-07, 'rewards/chosen': 1.203125, 'rewards/rejected': -0.36808472871780396, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.571874976158142, 'logps/chosen': -226.75, 'logps/rejected': -106.1500015258789, 'logits/chosen': -6.628125190734863, 'logits/rejected': -6.790625095367432, 'epoch': 0.33}
 11%|█         | 500/4545 [31:08<4:18:32,  3.84s/it] 11%|█         | 501/4545 [31:11<4:13:36,  3.76s/it] 11%|█         | 502/4545 [31:15<4:16:25,  3.81s/it] 11%|█         | 503/4545 [31:18<4:08:29,  3.69s/it] 11%|█         | 504/4545 [31:22<4:12:27,  3.75s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:43,  1.35it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.09s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.63s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.62s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.52s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.10s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.26s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.34s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.45s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.44s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.48s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.52s/it][A                                                    
                                               [A{'eval_loss': 0.42969033122062683, 'eval_runtime': 80.7843, 'eval_samples_per_second': 11.797, 'eval_steps_per_second': 0.743, 'eval_rewards/chosen': 1.8185546398162842, 'eval_rewards/rejected': 0.10978342592716217, 'eval_rewards/accuracies': 0.805555522441864, 'eval_rewards/margins': 1.7084187269210815, 'eval_logps/chosen': -368.48333740234375, 'eval_logps/rejected': -151.37083435058594, 'eval_logits/chosen': -6.328385353088379, 'eval_logits/rejected': -7.105729103088379, 'epoch': 0.33}
 11%|█         | 504/4545 [32:43<4:12:27,  3.75s/it]
100%|██████████| 60/60 [01:19<00:00,  1.52s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 11%|█         | 505/4545 [32:59<35:40:06, 31.78s/it] 11%|█         | 506/4545 [33:02<25:58:21, 23.15s/it] 11%|█         | 507/4545 [33:06<19:28:19, 17.36s/it] 11%|█         | 508/4545 [33:10<14:55:23, 13.31s/it] 11%|█         | 509/4545 [33:13<11:31:24, 10.28s/it] 11%|█         | 510/4545 [33:17<9:22:12,  8.36s/it]                                                     {'loss': 0.3933, 'grad_norm': 27.713804244995117, 'learning_rate': 3.3619550858652576e-07, 'rewards/chosen': 2.068359375, 'rewards/rejected': -0.0064453124068677425, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.075390577316284, 'logps/chosen': -380.67498779296875, 'logps/rejected': -220.5, 'logits/chosen': -6.456250190734863, 'logits/rejected': -6.728125095367432, 'epoch': 0.34}
 11%|█         | 510/4545 [33:17<9:22:12,  8.36s/it] 11%|█         | 511/4545 [33:21<7:58:09,  7.11s/it] 11%|█▏        | 512/4545 [33:25<6:47:57,  6.07s/it] 11%|█▏        | 513/4545 [33:29<6:04:15,  5.42s/it] 11%|█▏        | 514/4545 [33:33<5:33:05,  4.96s/it] 11%|█▏        | 515/4545 [33:36<4:54:45,  4.39s/it] 11%|█▏        | 516/4545 [33:40<4:42:29,  4.21s/it] 11%|█▏        | 517/4545 [33:43<4:20:14,  3.88s/it] 11%|█▏        | 518/4545 [33:46<4:11:56,  3.75s/it] 11%|█▏        | 519/4545 [33:50<4:15:19,  3.81s/it] 11%|█▏        | 520/4545 [33:54<4:17:17,  3.84s/it]                                                    {'loss': 0.4086, 'grad_norm': 51.5799446105957, 'learning_rate': 3.428005284015852e-07, 'rewards/chosen': 1.640625, 'rewards/rejected': -0.32017213106155396, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.964453101158142, 'logps/chosen': -291.0, 'logps/rejected': -136.77499389648438, 'logits/chosen': -6.621874809265137, 'logits/rejected': -6.709374904632568, 'epoch': 0.34}
 11%|█▏        | 520/4545 [33:54<4:17:17,  3.84s/it] 11%|█▏        | 521/4545 [33:58<4:19:02,  3.86s/it] 11%|█▏        | 522/4545 [34:02<4:27:09,  3.98s/it] 12%|█▏        | 523/4545 [34:06<4:25:41,  3.96s/it] 12%|█▏        | 524/4545 [34:10<4:24:07,  3.94s/it] 12%|█▏        | 525/4545 [34:14<4:18:01,  3.85s/it] 12%|█▏        | 526/4545 [34:18<4:22:32,  3.92s/it] 12%|█▏        | 527/4545 [34:22<4:22:33,  3.92s/it] 12%|█▏        | 528/4545 [34:26<4:27:10,  3.99s/it] 12%|█▏        | 529/4545 [34:29<4:16:12,  3.83s/it] 12%|█▏        | 530/4545 [34:33<4:22:07,  3.92s/it]                                                    {'loss': 0.3611, 'grad_norm': 53.57295227050781, 'learning_rate': 3.4940554821664466e-07, 'rewards/chosen': 1.410546898841858, 'rewards/rejected': -0.47832030057907104, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.8894531726837158, 'logps/chosen': -257.54998779296875, 'logps/rejected': -131.3000030517578, 'logits/chosen': -6.631249904632568, 'logits/rejected': -6.790625095367432, 'epoch': 0.35}
 12%|█▏        | 530/4545 [34:34<4:22:07,  3.92s/it] 12%|█▏        | 531/4545 [34:37<4:23:12,  3.93s/it] 12%|█▏        | 532/4545 [34:41<4:21:14,  3.91s/it] 12%|█▏        | 533/4545 [34:44<4:04:59,  3.66s/it] 12%|█▏        | 534/4545 [34:48<4:14:02,  3.80s/it] 12%|█▏        | 535/4545 [34:52<4:15:35,  3.82s/it] 12%|█▏        | 536/4545 [34:56<4:16:43,  3.84s/it] 12%|█▏        | 537/4545 [34:59<3:56:33,  3.54s/it] 12%|█▏        | 538/4545 [35:03<3:59:24,  3.58s/it] 12%|█▏        | 539/4545 [35:07<4:05:24,  3.68s/it] 12%|█▏        | 540/4545 [35:10<4:09:17,  3.73s/it]                                                    {'loss': 0.4098, 'grad_norm': 28.372207641601562, 'learning_rate': 3.560105680317041e-07, 'rewards/chosen': 1.332617163658142, 'rewards/rejected': -0.2275390625, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.560156226158142, 'logps/chosen': -218.1999969482422, 'logps/rejected': -143.22500610351562, 'logits/chosen': -6.696875095367432, 'logits/rejected': -6.628125190734863, 'epoch': 0.36}
 12%|█▏        | 540/4545 [35:11<4:09:17,  3.73s/it] 12%|█▏        | 541/4545 [35:15<4:22:35,  3.93s/it] 12%|█▏        | 542/4545 [35:19<4:25:25,  3.98s/it] 12%|█▏        | 543/4545 [35:23<4:19:20,  3.89s/it] 12%|█▏        | 544/4545 [35:26<4:18:58,  3.88s/it] 12%|█▏        | 545/4545 [35:31<4:24:36,  3.97s/it] 12%|█▏        | 546/4545 [35:35<4:22:48,  3.94s/it] 12%|█▏        | 547/4545 [35:38<4:21:50,  3.93s/it] 12%|█▏        | 548/4545 [35:42<4:12:05,  3.78s/it] 12%|█▏        | 549/4545 [35:45<4:06:31,  3.70s/it] 12%|█▏        | 550/4545 [35:49<4:10:10,  3.76s/it]                                                    {'loss': 0.4062, 'grad_norm': 81.43440246582031, 'learning_rate': 3.6261558784676357e-07, 'rewards/chosen': 1.7712891101837158, 'rewards/rejected': -0.3173828125, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.091015577316284, 'logps/chosen': -327.8999938964844, 'logps/rejected': -186.4499969482422, 'logits/chosen': -6.5, 'logits/rejected': -6.599999904632568, 'epoch': 0.36}
 12%|█▏        | 550/4545 [35:50<4:10:10,  3.76s/it] 12%|█▏        | 551/4545 [35:53<4:13:23,  3.81s/it] 12%|█▏        | 552/4545 [35:57<4:14:16,  3.82s/it] 12%|█▏        | 553/4545 [36:01<4:15:38,  3.84s/it] 12%|█▏        | 554/4545 [36:04<4:05:27,  3.69s/it] 12%|█▏        | 555/4545 [36:08<4:09:49,  3.76s/it] 12%|█▏        | 556/4545 [36:12<4:13:09,  3.81s/it] 12%|█▏        | 557/4545 [36:15<3:47:16,  3.42s/it] 12%|█▏        | 558/4545 [36:19<4:00:17,  3.62s/it] 12%|█▏        | 559/4545 [36:22<3:48:29,  3.44s/it] 12%|█▏        | 560/4545 [36:26<3:57:03,  3.57s/it]                                                    {'loss': 0.412, 'grad_norm': 43.0576286315918, 'learning_rate': 3.6922060766182294e-07, 'rewards/chosen': 1.8699219226837158, 'rewards/rejected': -0.24079589545726776, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.112109422683716, 'logps/chosen': -328.25, 'logps/rejected': -206.4499969482422, 'logits/chosen': -6.621874809265137, 'logits/rejected': -6.65625, 'epoch': 0.37}
 12%|█▏        | 560/4545 [36:26<3:57:03,  3.57s/it] 12%|█▏        | 561/4545 [36:29<4:01:52,  3.64s/it] 12%|█▏        | 562/4545 [36:33<4:05:48,  3.70s/it] 12%|█▏        | 563/4545 [36:36<3:52:04,  3.50s/it] 12%|█▏        | 564/4545 [36:40<3:49:38,  3.46s/it] 12%|█▏        | 565/4545 [36:44<3:59:27,  3.61s/it] 12%|█▏        | 566/4545 [36:47<4:04:07,  3.68s/it] 12%|█▏        | 567/4545 [36:51<4:04:57,  3.69s/it] 12%|█▏        | 568/4545 [36:55<4:08:43,  3.75s/it] 13%|█▎        | 569/4545 [36:59<4:07:19,  3.73s/it] 13%|█▎        | 570/4545 [37:03<4:14:55,  3.85s/it]                                                    {'loss': 0.3808, 'grad_norm': 27.83976936340332, 'learning_rate': 3.758256274768824e-07, 'rewards/chosen': 1.609375, 'rewards/rejected': -0.2579589784145355, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.866796851158142, 'logps/chosen': -259.95001220703125, 'logps/rejected': -178.5749969482422, 'logits/chosen': -6.868750095367432, 'logits/rejected': -6.887499809265137, 'epoch': 0.38}
 13%|█▎        | 570/4545 [37:03<4:14:55,  3.85s/it] 13%|█▎        | 571/4545 [37:07<4:17:25,  3.89s/it] 13%|█▎        | 572/4545 [37:11<4:16:29,  3.87s/it] 13%|█▎        | 573/4545 [37:15<4:23:12,  3.98s/it] 13%|█▎        | 574/4545 [37:19<4:25:34,  4.01s/it] 13%|█▎        | 575/4545 [37:23<4:23:29,  3.98s/it] 13%|█▎        | 576/4545 [37:27<4:20:28,  3.94s/it] 13%|█▎        | 577/4545 [37:31<4:19:20,  3.92s/it] 13%|█▎        | 578/4545 [37:34<4:12:57,  3.83s/it] 13%|█▎        | 579/4545 [37:37<3:54:31,  3.55s/it] 13%|█▎        | 580/4545 [37:41<4:04:26,  3.70s/it]                                                    {'loss': 0.3629, 'grad_norm': 28.189855575561523, 'learning_rate': 3.8243064729194185e-07, 'rewards/chosen': 1.7947266101837158, 'rewards/rejected': -0.3440918028354645, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.139843702316284, 'logps/chosen': -304.04998779296875, 'logps/rejected': -183.89999389648438, 'logits/chosen': -6.75, 'logits/rejected': -6.793749809265137, 'epoch': 0.38}
 13%|█▎        | 580/4545 [37:41<4:04:26,  3.70s/it] 13%|█▎        | 581/4545 [37:44<3:54:59,  3.56s/it] 13%|█▎        | 582/4545 [37:48<4:01:46,  3.66s/it] 13%|█▎        | 583/4545 [37:51<3:43:31,  3.39s/it] 13%|█▎        | 584/4545 [37:55<3:54:23,  3.55s/it] 13%|█▎        | 585/4545 [37:58<3:52:12,  3.52s/it] 13%|█▎        | 586/4545 [38:02<3:59:42,  3.63s/it] 13%|█▎        | 587/4545 [38:06<4:09:28,  3.78s/it] 13%|█▎        | 588/4545 [38:10<4:11:47,  3.82s/it] 13%|█▎        | 589/4545 [38:13<3:50:40,  3.50s/it] 13%|█▎        | 590/4545 [38:17<3:52:57,  3.53s/it]                                                    {'loss': 0.3825, 'grad_norm': 31.477352142333984, 'learning_rate': 3.8903566710700133e-07, 'rewards/chosen': 1.8274414539337158, 'rewards/rejected': -0.39667969942092896, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.223828077316284, 'logps/chosen': -316.04998779296875, 'logps/rejected': -201.6999969482422, 'logits/chosen': -6.721875190734863, 'logits/rejected': -6.856249809265137, 'epoch': 0.39}
 13%|█▎        | 590/4545 [38:17<3:52:57,  3.53s/it] 13%|█▎        | 591/4545 [38:21<4:01:01,  3.66s/it] 13%|█▎        | 592/4545 [38:24<3:54:52,  3.57s/it] 13%|█▎        | 593/4545 [38:27<3:52:23,  3.53s/it] 13%|█▎        | 594/4545 [38:31<3:59:26,  3.64s/it] 13%|█▎        | 595/4545 [38:35<4:02:15,  3.68s/it] 13%|█▎        | 596/4545 [38:39<4:06:21,  3.74s/it] 13%|█▎        | 597/4545 [38:43<4:15:28,  3.88s/it] 13%|█▎        | 598/4545 [38:46<3:59:25,  3.64s/it] 13%|█▎        | 599/4545 [38:51<4:10:08,  3.80s/it] 13%|█▎        | 600/4545 [38:54<3:55:52,  3.59s/it]                                                    {'loss': 0.3355, 'grad_norm': 41.82727813720703, 'learning_rate': 3.9564068692206076e-07, 'rewards/chosen': 1.8660156726837158, 'rewards/rejected': -0.40673828125, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.272656202316284, 'logps/chosen': -297.1499938964844, 'logps/rejected': -191.47500610351562, 'logits/chosen': -6.887499809265137, 'logits/rejected': -6.868750095367432, 'epoch': 0.4}
 13%|█▎        | 600/4545 [38:54<3:55:52,  3.59s/it] 13%|█▎        | 601/4545 [38:57<3:53:59,  3.56s/it] 13%|█▎        | 602/4545 [39:00<3:51:05,  3.52s/it] 13%|█▎        | 603/4545 [39:04<3:57:28,  3.61s/it] 13%|█▎        | 604/4545 [39:08<3:50:56,  3.52s/it] 13%|█▎        | 605/4545 [39:12<4:04:44,  3.73s/it] 13%|█▎        | 606/4545 [39:15<3:55:33,  3.59s/it] 13%|█▎        | 607/4545 [39:19<4:05:02,  3.73s/it] 13%|█▎        | 608/4545 [39:23<4:08:23,  3.79s/it] 13%|█▎        | 609/4545 [39:27<4:10:20,  3.82s/it] 13%|█▎        | 610/4545 [39:31<4:12:45,  3.85s/it]                                                    {'loss': 0.3441, 'grad_norm': 40.54502868652344, 'learning_rate': 4.0224570673712024e-07, 'rewards/chosen': 2.639843702316284, 'rewards/rejected': -0.431915283203125, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.0687499046325684, 'logps/chosen': -370.1499938964844, 'logps/rejected': -189.14999389648438, 'logits/chosen': -6.634375095367432, 'logits/rejected': -6.724999904632568, 'epoch': 0.4}
 13%|█▎        | 610/4545 [39:31<4:12:45,  3.85s/it] 13%|█▎        | 611/4545 [39:35<4:19:20,  3.96s/it] 13%|█▎        | 612/4545 [39:38<3:57:59,  3.63s/it] 13%|█▎        | 613/4545 [39:42<4:02:39,  3.70s/it] 14%|█▎        | 614/4545 [39:46<4:06:40,  3.77s/it] 14%|█▎        | 615/4545 [39:49<3:48:38,  3.49s/it] 14%|█▎        | 616/4545 [39:52<3:49:10,  3.50s/it] 14%|█▎        | 617/4545 [39:56<3:57:43,  3.63s/it] 14%|█▎        | 618/4545 [39:59<3:43:54,  3.42s/it] 14%|█▎        | 619/4545 [40:03<3:53:07,  3.56s/it] 14%|█▎        | 620/4545 [40:06<3:36:52,  3.32s/it]                                                    {'loss': 0.3548, 'grad_norm': 25.518339157104492, 'learning_rate': 4.088507265521796e-07, 'rewards/chosen': 1.5402343273162842, 'rewards/rejected': -0.856640636920929, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.3968749046325684, 'logps/chosen': -218.9499969482422, 'logps/rejected': -119.0999984741211, 'logits/chosen': -6.974999904632568, 'logits/rejected': -6.784375190734863, 'epoch': 0.41}
 14%|█▎        | 620/4545 [40:06<3:36:52,  3.32s/it] 14%|█▎        | 621/4545 [40:10<3:48:50,  3.50s/it] 14%|█▎        | 622/4545 [40:13<3:57:12,  3.63s/it] 14%|█▎        | 623/4545 [40:17<3:57:10,  3.63s/it] 14%|█▎        | 624/4545 [40:21<4:00:44,  3.68s/it] 14%|█▍        | 625/4545 [40:25<4:05:12,  3.75s/it] 14%|█▍        | 626/4545 [40:29<4:08:21,  3.80s/it] 14%|█▍        | 627/4545 [40:32<4:02:26,  3.71s/it] 14%|█▍        | 628/4545 [40:36<4:04:23,  3.74s/it] 14%|█▍        | 629/4545 [40:40<4:07:12,  3.79s/it] 14%|█▍        | 630/4545 [40:44<4:09:03,  3.82s/it]                                                    {'loss': 0.2506, 'grad_norm': 24.298994064331055, 'learning_rate': 4.154557463672391e-07, 'rewards/chosen': 2.0171875953674316, 'rewards/rejected': -0.698046863079071, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 2.71875, 'logps/chosen': -274.0, 'logps/rejected': -155.8249969482422, 'logits/chosen': -6.762499809265137, 'logits/rejected': -6.793749809265137, 'epoch': 0.42}
 14%|█▍        | 630/4545 [40:44<4:09:03,  3.82s/it] 14%|█▍        | 631/4545 [40:48<4:17:43,  3.95s/it] 14%|█▍        | 632/4545 [40:52<4:15:40,  3.92s/it] 14%|█▍        | 633/4545 [40:56<4:09:50,  3.83s/it] 14%|█▍        | 634/4545 [41:00<4:16:13,  3.93s/it] 14%|█▍        | 635/4545 [41:04<4:19:48,  3.99s/it] 14%|█▍        | 636/4545 [41:08<4:20:52,  4.00s/it] 14%|█▍        | 637/4545 [41:12<4:22:16,  4.03s/it] 14%|█▍        | 638/4545 [41:16<4:19:32,  3.99s/it] 14%|█▍        | 639/4545 [41:20<4:13:02,  3.89s/it] 14%|█▍        | 640/4545 [41:23<4:08:14,  3.81s/it]                                                    {'loss': 0.281, 'grad_norm': 16.172765731811523, 'learning_rate': 4.220607661822985e-07, 'rewards/chosen': 1.4363281726837158, 'rewards/rejected': -0.960034191608429, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 2.3960938453674316, 'logps/chosen': -194.14999389648438, 'logps/rejected': -139.60000610351562, 'logits/chosen': -6.965624809265137, 'logits/rejected': -6.946875095367432, 'epoch': 0.42}
 14%|█▍        | 640/4545 [41:23<4:08:14,  3.81s/it] 14%|█▍        | 641/4545 [41:27<4:13:30,  3.90s/it] 14%|█▍        | 642/4545 [41:31<4:13:25,  3.90s/it] 14%|█▍        | 643/4545 [41:35<4:13:30,  3.90s/it] 14%|█▍        | 644/4545 [41:39<4:11:52,  3.87s/it] 14%|█▍        | 645/4545 [41:43<4:12:05,  3.88s/it] 14%|█▍        | 646/4545 [41:47<4:12:18,  3.88s/it] 14%|█▍        | 647/4545 [41:50<3:57:37,  3.66s/it] 14%|█▍        | 648/4545 [41:54<4:02:15,  3.73s/it] 14%|█▍        | 649/4545 [41:58<4:07:26,  3.81s/it] 14%|█▍        | 650/4545 [42:02<4:08:42,  3.83s/it]                                                    {'loss': 0.3759, 'grad_norm': 24.403650283813477, 'learning_rate': 4.28665785997358e-07, 'rewards/chosen': 3.020312547683716, 'rewards/rejected': -0.4217285215854645, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 3.4398436546325684, 'logps/chosen': -427.04998779296875, 'logps/rejected': -232.85000610351562, 'logits/chosen': -6.693749904632568, 'logits/rejected': -6.803124904632568, 'epoch': 0.43}
 14%|█▍        | 650/4545 [42:02<4:08:42,  3.83s/it] 14%|█▍        | 651/4545 [42:06<4:10:38,  3.86s/it] 14%|█▍        | 652/4545 [42:09<4:06:03,  3.79s/it] 14%|█▍        | 653/4545 [42:13<4:08:30,  3.83s/it] 14%|█▍        | 654/4545 [42:17<4:08:53,  3.84s/it] 14%|█▍        | 655/4545 [42:20<4:00:27,  3.71s/it] 14%|█▍        | 656/4545 [42:24<3:59:25,  3.69s/it] 14%|█▍        | 657/4545 [42:28<4:10:19,  3.86s/it] 14%|█▍        | 658/4545 [42:31<3:45:18,  3.48s/it] 14%|█▍        | 659/4545 [42:35<3:52:19,  3.59s/it] 15%|█▍        | 660/4545 [42:39<3:58:12,  3.68s/it]                                                    {'loss': 0.3332, 'grad_norm': 17.447265625, 'learning_rate': 4.352708058124174e-07, 'rewards/chosen': 2.013867139816284, 'rewards/rejected': -0.921826183795929, 'rewards/accuracies': 0.875, 'rewards/margins': 2.9351563453674316, 'logps/chosen': -306.3500061035156, 'logps/rejected': -148.39999389648438, 'logits/chosen': -6.903124809265137, 'logits/rejected': -6.834374904632568, 'epoch': 0.44}
 15%|█▍        | 660/4545 [42:39<3:58:12,  3.68s/it] 15%|█▍        | 661/4545 [42:43<4:07:57,  3.83s/it] 15%|█▍        | 662/4545 [42:47<4:14:23,  3.93s/it] 15%|█▍        | 663/4545 [42:51<4:08:02,  3.83s/it] 15%|█▍        | 664/4545 [42:54<4:01:04,  3.73s/it] 15%|█▍        | 665/4545 [42:57<3:55:28,  3.64s/it] 15%|█▍        | 666/4545 [43:01<4:00:11,  3.72s/it] 15%|█▍        | 667/4545 [43:05<4:02:39,  3.75s/it] 15%|█▍        | 668/4545 [43:09<3:56:13,  3.66s/it] 15%|█▍        | 669/4545 [43:13<4:00:54,  3.73s/it] 15%|█▍        | 670/4545 [43:16<4:05:18,  3.80s/it]                                                    {'loss': 0.3755, 'grad_norm': 57.76000213623047, 'learning_rate': 4.418758256274769e-07, 'rewards/chosen': 0.787841796875, 'rewards/rejected': -1.23046875, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.020312547683716, 'logps/chosen': -147.39999389648438, 'logps/rejected': -101.32499694824219, 'logits/chosen': -7.134375095367432, 'logits/rejected': -6.996874809265137, 'epoch': 0.44}
 15%|█▍        | 670/4545 [43:17<4:05:18,  3.80s/it] 15%|█▍        | 671/4545 [43:20<4:07:59,  3.84s/it] 15%|█▍        | 672/4545 [43:24<4:12:01,  3.90s/it] 15%|█▍        | 673/4545 [43:28<4:01:08,  3.74s/it] 15%|█▍        | 674/4545 [43:32<4:04:10,  3.78s/it] 15%|█▍        | 675/4545 [43:36<4:04:56,  3.80s/it] 15%|█▍        | 676/4545 [43:39<4:06:16,  3.82s/it] 15%|█▍        | 677/4545 [43:42<3:42:37,  3.45s/it] 15%|█▍        | 678/4545 [43:46<3:51:52,  3.60s/it] 15%|█▍        | 679/4545 [43:50<4:01:08,  3.74s/it] 15%|█▍        | 680/4545 [43:54<4:03:48,  3.78s/it]                                                    {'loss': 0.3159, 'grad_norm': 27.057077407836914, 'learning_rate': 4.484808454425363e-07, 'rewards/chosen': 2.5199217796325684, 'rewards/rejected': -1.007177710533142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.52734375, 'logps/chosen': -361.45001220703125, 'logps/rejected': -169.125, 'logits/chosen': -6.940625190734863, 'logits/rejected': -6.834374904632568, 'epoch': 0.45}
 15%|█▍        | 680/4545 [43:54<4:03:48,  3.78s/it] 15%|█▍        | 681/4545 [43:58<4:12:32,  3.92s/it] 15%|█▌        | 682/4545 [44:02<4:08:56,  3.87s/it] 15%|█▌        | 683/4545 [44:06<4:10:23,  3.89s/it] 15%|█▌        | 684/4545 [44:10<4:15:12,  3.97s/it] 15%|█▌        | 685/4545 [44:14<4:13:33,  3.94s/it] 15%|█▌        | 686/4545 [44:18<4:11:47,  3.91s/it] 15%|█▌        | 687/4545 [44:21<4:06:50,  3.84s/it] 15%|█▌        | 688/4545 [44:25<4:07:45,  3.85s/it] 15%|█▌        | 689/4545 [44:29<4:00:44,  3.75s/it] 15%|█▌        | 690/4545 [44:33<4:02:49,  3.78s/it]                                                    {'loss': 0.3668, 'grad_norm': 53.06663131713867, 'learning_rate': 4.5508586525759576e-07, 'rewards/chosen': 2.210693359375, 'rewards/rejected': -0.7679687738418579, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.981250047683716, 'logps/chosen': -326.95001220703125, 'logps/rejected': -154.125, 'logits/chosen': -6.965624809265137, 'logits/rejected': -7.034375190734863, 'epoch': 0.46}
 15%|█▌        | 690/4545 [44:33<4:02:49,  3.78s/it] 15%|█▌        | 691/4545 [44:37<4:10:28,  3.90s/it] 15%|█▌        | 692/4545 [44:39<3:42:57,  3.47s/it] 15%|█▌        | 693/4545 [44:43<3:53:52,  3.64s/it] 15%|█▌        | 694/4545 [44:47<3:45:27,  3.51s/it] 15%|█▌        | 695/4545 [44:51<3:58:27,  3.72s/it] 15%|█▌        | 696/4545 [44:55<4:01:39,  3.77s/it] 15%|█▌        | 697/4545 [44:58<3:58:34,  3.72s/it] 15%|█▌        | 698/4545 [45:02<4:01:37,  3.77s/it] 15%|█▌        | 699/4545 [45:06<4:03:48,  3.80s/it] 15%|█▌        | 700/4545 [45:10<4:03:31,  3.80s/it]                                                    {'loss': 0.3179, 'grad_norm': 18.0189208984375, 'learning_rate': 4.616908850726552e-07, 'rewards/chosen': 1.970117211341858, 'rewards/rejected': -1.09375, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.061718702316284, 'logps/chosen': -261.8500061035156, 'logps/rejected': -162.14999389648438, 'logits/chosen': -7.006249904632568, 'logits/rejected': -6.831250190734863, 'epoch': 0.46}
 15%|█▌        | 700/4545 [45:10<4:03:31,  3.80s/it] 15%|█▌        | 701/4545 [45:14<4:05:26,  3.83s/it] 15%|█▌        | 702/4545 [45:18<4:06:29,  3.85s/it] 15%|█▌        | 703/4545 [45:22<4:12:24,  3.94s/it] 15%|█▌        | 704/4545 [45:25<3:53:16,  3.64s/it] 16%|█▌        | 705/4545 [45:28<3:54:31,  3.66s/it] 16%|█▌        | 706/4545 [45:32<3:59:54,  3.75s/it] 16%|█▌        | 707/4545 [45:36<4:02:22,  3.79s/it] 16%|█▌        | 708/4545 [45:40<4:04:08,  3.82s/it] 16%|█▌        | 709/4545 [45:43<3:52:02,  3.63s/it] 16%|█▌        | 710/4545 [45:47<3:56:19,  3.70s/it]                                                    {'loss': 0.2877, 'grad_norm': 24.557960510253906, 'learning_rate': 4.6829590488771467e-07, 'rewards/chosen': 1.6990234851837158, 'rewards/rejected': -1.460546851158142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.155468702316284, 'logps/chosen': -228.9499969482422, 'logps/rejected': -107.0250015258789, 'logits/chosen': -6.953125, 'logits/rejected': -6.993750095367432, 'epoch': 0.47}
 16%|█▌        | 710/4545 [45:47<3:56:19,  3.70s/it] 16%|█▌        | 711/4545 [45:50<3:38:35,  3.42s/it] 16%|█▌        | 712/4545 [45:54<3:47:23,  3.56s/it] 16%|█▌        | 713/4545 [45:58<3:52:43,  3.64s/it] 16%|█▌        | 714/4545 [46:02<3:58:24,  3.73s/it] 16%|█▌        | 715/4545 [46:05<3:59:35,  3.75s/it] 16%|█▌        | 716/4545 [46:09<3:51:49,  3.63s/it] 16%|█▌        | 717/4545 [46:13<3:56:00,  3.70s/it] 16%|█▌        | 718/4545 [46:17<4:04:54,  3.84s/it] 16%|█▌        | 719/4545 [46:20<3:46:28,  3.55s/it] 16%|█▌        | 720/4545 [46:24<3:57:45,  3.73s/it]                                                    {'loss': 0.3612, 'grad_norm': 25.438894271850586, 'learning_rate': 4.749009247027741e-07, 'rewards/chosen': 2.189160108566284, 'rewards/rejected': -0.8646484613418579, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.057812452316284, 'logps/chosen': -283.6000061035156, 'logps/rejected': -214.02499389648438, 'logits/chosen': -6.809374809265137, 'logits/rejected': -6.909375190734863, 'epoch': 0.48}
 16%|█▌        | 720/4545 [46:24<3:57:45,  3.73s/it] 16%|█▌        | 721/4545 [46:28<4:01:39,  3.79s/it] 16%|█▌        | 722/4545 [46:31<3:55:14,  3.69s/it] 16%|█▌        | 723/4545 [46:35<3:59:17,  3.76s/it] 16%|█▌        | 724/4545 [46:39<4:01:38,  3.79s/it] 16%|█▌        | 725/4545 [46:43<4:02:45,  3.81s/it] 16%|█▌        | 726/4545 [46:47<4:04:20,  3.84s/it] 16%|█▌        | 727/4545 [46:49<3:35:25,  3.39s/it] 16%|█▌        | 728/4545 [46:51<3:06:41,  2.93s/it] 16%|█▌        | 729/4545 [46:54<3:03:28,  2.88s/it] 16%|█▌        | 730/4545 [46:58<3:23:06,  3.19s/it]                                                    {'loss': 0.3756, 'grad_norm': 46.425926208496094, 'learning_rate': 4.815059445178335e-07, 'rewards/chosen': 2.272753953933716, 'rewards/rejected': -1.0089843273162842, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.280468702316284, 'logps/chosen': -294.7749938964844, 'logps/rejected': -153.0749969482422, 'logits/chosen': -7.043749809265137, 'logits/rejected': -6.865624904632568, 'epoch': 0.48}
 16%|█▌        | 730/4545 [46:58<3:23:06,  3.19s/it] 16%|█▌        | 731/4545 [47:00<3:10:50,  3.00s/it] 16%|█▌        | 732/4545 [47:04<3:28:58,  3.29s/it] 16%|█▌        | 733/4545 [47:08<3:40:31,  3.47s/it] 16%|█▌        | 734/4545 [47:12<3:48:24,  3.60s/it] 16%|█▌        | 735/4545 [47:16<4:00:12,  3.78s/it] 16%|█▌        | 736/4545 [47:20<4:03:09,  3.83s/it] 16%|█▌        | 737/4545 [47:24<4:04:11,  3.85s/it] 16%|█▌        | 738/4545 [47:28<4:08:51,  3.92s/it] 16%|█▋        | 739/4545 [47:31<3:55:50,  3.72s/it] 16%|█▋        | 740/4545 [47:35<4:04:35,  3.86s/it]                                                    {'loss': 0.3533, 'grad_norm': 9.623108863830566, 'learning_rate': 4.881109643328929e-07, 'rewards/chosen': 2.4033203125, 'rewards/rejected': -1.0921630859375, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 3.4945311546325684, 'logps/chosen': -323.79998779296875, 'logps/rejected': -203.02499389648438, 'logits/chosen': -6.806250095367432, 'logits/rejected': -6.724999904632568, 'epoch': 0.49}
 16%|█▋        | 740/4545 [47:36<4:04:35,  3.86s/it] 16%|█▋        | 741/4545 [47:39<4:05:45,  3.88s/it] 16%|█▋        | 742/4545 [47:43<3:55:24,  3.71s/it] 16%|█▋        | 743/4545 [47:46<3:50:41,  3.64s/it] 16%|█▋        | 744/4545 [47:50<3:55:06,  3.71s/it] 16%|█▋        | 745/4545 [47:53<3:48:43,  3.61s/it] 16%|█▋        | 746/4545 [47:58<4:02:09,  3.82s/it] 16%|█▋        | 747/4545 [48:02<4:02:40,  3.83s/it] 16%|█▋        | 748/4545 [48:05<3:48:58,  3.62s/it] 16%|█▋        | 749/4545 [48:09<3:54:39,  3.71s/it] 17%|█▋        | 750/4545 [48:13<3:58:03,  3.76s/it]                                                    {'loss': 0.3026, 'grad_norm': 21.004417419433594, 'learning_rate': 4.947159841479524e-07, 'rewards/chosen': 1.41064453125, 'rewards/rejected': -1.618749976158142, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.0257811546325684, 'logps/chosen': -209.5500030517578, 'logps/rejected': -117.30000305175781, 'logits/chosen': -7.068749904632568, 'logits/rejected': -6.996874809265137, 'epoch': 0.5}
 17%|█▋        | 750/4545 [48:13<3:58:03,  3.76s/it] 17%|█▋        | 751/4545 [48:17<4:02:29,  3.83s/it] 17%|█▋        | 752/4545 [48:20<4:02:07,  3.83s/it] 17%|█▋        | 753/4545 [48:25<4:08:12,  3.93s/it] 17%|█▋        | 754/4545 [48:28<3:57:05,  3.75s/it] 17%|█▋        | 755/4545 [48:32<3:59:07,  3.79s/it] 17%|█▋        | 756/4545 [48:36<4:07:53,  3.93s/it] 17%|█▋        | 757/4545 [48:40<4:07:16,  3.92s/it] 17%|█▋        | 758/4545 [48:44<4:07:34,  3.92s/it] 17%|█▋        | 759/4545 [48:48<4:03:44,  3.86s/it] 17%|█▋        | 760/4545 [48:51<3:59:18,  3.79s/it]                                                    {'loss': 0.2597, 'grad_norm': 24.515573501586914, 'learning_rate': 5.013210039630119e-07, 'rewards/chosen': 3.5902342796325684, 'rewards/rejected': -1.237451195716858, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.832812309265137, 'logps/chosen': -419.8500061035156, 'logps/rejected': -230.4250030517578, 'logits/chosen': -6.793749809265137, 'logits/rejected': -6.884375095367432, 'epoch': 0.5}
 17%|█▋        | 760/4545 [48:51<3:59:18,  3.79s/it] 17%|█▋        | 761/4545 [48:55<4:03:22,  3.86s/it] 17%|█▋        | 762/4545 [48:59<4:04:12,  3.87s/it] 17%|█▋        | 763/4545 [49:02<3:53:30,  3.70s/it] 17%|█▋        | 764/4545 [49:06<3:54:57,  3.73s/it] 17%|█▋        | 765/4545 [49:09<3:36:01,  3.43s/it] 17%|█▋        | 766/4545 [49:13<3:46:15,  3.59s/it] 17%|█▋        | 767/4545 [49:17<3:51:06,  3.67s/it] 17%|█▋        | 768/4545 [49:21<3:59:11,  3.80s/it] 17%|█▋        | 769/4545 [49:24<3:44:53,  3.57s/it] 17%|█▋        | 770/4545 [49:27<3:35:48,  3.43s/it]                                                    {'loss': 0.2268, 'grad_norm': 6.098006725311279, 'learning_rate': 5.079260237780713e-07, 'rewards/chosen': 1.8018310070037842, 'rewards/rejected': -1.750390648841858, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 3.5562500953674316, 'logps/chosen': -242.5, 'logps/rejected': -160.9499969482422, 'logits/chosen': -7.140625, 'logits/rejected': -6.934374809265137, 'epoch': 0.51}
 17%|█▋        | 770/4545 [49:27<3:35:48,  3.43s/it] 17%|█▋        | 771/4545 [49:29<3:16:48,  3.13s/it] 17%|█▋        | 772/4545 [49:34<3:36:44,  3.45s/it] 17%|█▋        | 773/4545 [49:36<3:16:35,  3.13s/it] 17%|█▋        | 774/4545 [49:40<3:27:05,  3.30s/it] 17%|█▋        | 775/4545 [49:44<3:43:01,  3.55s/it] 17%|█▋        | 776/4545 [49:48<3:49:26,  3.65s/it] 17%|█▋        | 777/4545 [49:51<3:42:00,  3.54s/it] 17%|█▋        | 778/4545 [49:54<3:41:34,  3.53s/it] 17%|█▋        | 779/4545 [49:59<3:54:42,  3.74s/it] 17%|█▋        | 780/4545 [50:03<3:56:45,  3.77s/it]                                                    {'loss': 0.3618, 'grad_norm': 56.87715530395508, 'learning_rate': 5.145310435931308e-07, 'rewards/chosen': 1.8903319835662842, 'rewards/rejected': -1.650390625, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.5445313453674316, 'logps/chosen': -258.04998779296875, 'logps/rejected': -160.02499389648438, 'logits/chosen': -7.037499904632568, 'logits/rejected': -6.928124904632568, 'epoch': 0.51}
 17%|█▋        | 780/4545 [50:03<3:56:45,  3.77s/it] 17%|█▋        | 781/4545 [50:05<3:39:57,  3.51s/it] 17%|█▋        | 782/4545 [50:09<3:49:47,  3.66s/it] 17%|█▋        | 783/4545 [50:14<4:00:04,  3.83s/it] 17%|█▋        | 784/4545 [50:17<3:52:50,  3.71s/it] 17%|█▋        | 785/4545 [50:21<3:55:30,  3.76s/it] 17%|█▋        | 786/4545 [50:25<3:57:26,  3.79s/it] 17%|█▋        | 787/4545 [50:29<3:59:15,  3.82s/it] 17%|█▋        | 788/4545 [50:33<4:00:48,  3.85s/it] 17%|█▋        | 789/4545 [50:36<3:48:31,  3.65s/it] 17%|█▋        | 790/4545 [50:38<3:25:50,  3.29s/it]                                                    {'loss': 0.3757, 'grad_norm': 22.42398452758789, 'learning_rate': 5.211360634081902e-07, 'rewards/chosen': 1.6422851085662842, 'rewards/rejected': -1.8701171875, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.514843702316284, 'logps/chosen': -235.9499969482422, 'logps/rejected': -112.55000305175781, 'logits/chosen': -7.037499904632568, 'logits/rejected': -7.115624904632568, 'epoch': 0.52}
 17%|█▋        | 790/4545 [50:38<3:25:50,  3.29s/it] 17%|█▋        | 791/4545 [50:41<3:22:08,  3.23s/it] 17%|█▋        | 792/4545 [50:45<3:38:03,  3.49s/it] 17%|█▋        | 793/4545 [50:50<3:49:32,  3.67s/it] 17%|█▋        | 794/4545 [50:54<3:58:37,  3.82s/it] 17%|█▋        | 795/4545 [50:58<4:03:20,  3.89s/it] 18%|█▊        | 796/4545 [51:02<4:02:05,  3.87s/it] 18%|█▊        | 797/4545 [51:06<4:02:10,  3.88s/it] 18%|█▊        | 798/4545 [51:09<4:02:15,  3.88s/it] 18%|█▊        | 799/4545 [51:13<4:01:04,  3.86s/it] 18%|█▊        | 800/4545 [51:17<4:01:14,  3.87s/it]                                                    {'loss': 0.2816, 'grad_norm': 19.026514053344727, 'learning_rate': 5.277410832232496e-07, 'rewards/chosen': 2.294189453125, 'rewards/rejected': -2.078906297683716, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.370312690734863, 'logps/chosen': -311.1000061035156, 'logps/rejected': -159.625, 'logits/chosen': -7.074999809265137, 'logits/rejected': -6.903124809265137, 'epoch': 0.53}
 18%|█▊        | 800/4545 [51:17<4:01:14,  3.87s/it] 18%|█▊        | 801/4545 [51:21<4:01:12,  3.87s/it] 18%|█▊        | 802/4545 [51:24<3:54:39,  3.76s/it] 18%|█▊        | 803/4545 [51:28<3:51:11,  3.71s/it] 18%|█▊        | 804/4545 [51:32<3:59:35,  3.84s/it] 18%|█▊        | 805/4545 [51:36<4:00:40,  3.86s/it] 18%|█▊        | 806/4545 [51:39<3:51:07,  3.71s/it] 18%|█▊        | 807/4545 [51:43<3:54:29,  3.76s/it] 18%|█▊        | 808/4545 [51:47<3:56:51,  3.80s/it] 18%|█▊        | 809/4545 [51:51<3:48:29,  3.67s/it] 18%|█▊        | 810/4545 [51:55<3:52:31,  3.74s/it]                                                    {'loss': 0.3232, 'grad_norm': 18.493913650512695, 'learning_rate': 5.34346103038309e-07, 'rewards/chosen': 1.5603516101837158, 'rewards/rejected': -1.6121094226837158, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 3.1703124046325684, 'logps/chosen': -220.375, 'logps/rejected': -161.375, 'logits/chosen': -7.050000190734863, 'logits/rejected': -6.756249904632568, 'epoch': 0.53}
 18%|█▊        | 810/4545 [51:55<3:52:31,  3.74s/it] 18%|█▊        | 811/4545 [51:58<3:57:05,  3.81s/it] 18%|█▊        | 812/4545 [52:02<3:58:39,  3.84s/it] 18%|█▊        | 813/4545 [52:06<3:59:03,  3.84s/it] 18%|█▊        | 814/4545 [52:10<3:49:45,  3.69s/it] 18%|█▊        | 815/4545 [52:14<3:53:55,  3.76s/it] 18%|█▊        | 816/4545 [52:17<3:55:56,  3.80s/it] 18%|█▊        | 817/4545 [52:20<3:29:27,  3.37s/it] 18%|█▊        | 818/4545 [52:24<3:42:54,  3.59s/it] 18%|█▊        | 819/4545 [52:28<3:52:21,  3.74s/it] 18%|█▊        | 820/4545 [52:32<3:55:48,  3.80s/it]                                                    {'loss': 0.2816, 'grad_norm': 48.06949996948242, 'learning_rate': 5.409511228533686e-07, 'rewards/chosen': 3.2548828125, 'rewards/rejected': -1.871679663658142, 'rewards/accuracies': 0.875, 'rewards/margins': 5.12890625, 'logps/chosen': -408.25, 'logps/rejected': -207.39999389648438, 'logits/chosen': -6.778124809265137, 'logits/rejected': -6.746874809265137, 'epoch': 0.54}
 18%|█▊        | 820/4545 [52:32<3:55:48,  3.80s/it] 18%|█▊        | 821/4545 [52:36<4:02:25,  3.91s/it] 18%|█▊        | 822/4545 [52:40<4:05:47,  3.96s/it] 18%|█▊        | 823/4545 [52:44<4:07:04,  3.98s/it] 18%|█▊        | 824/4545 [52:47<3:49:57,  3.71s/it] 18%|█▊        | 825/4545 [52:51<3:52:20,  3.75s/it] 18%|█▊        | 826/4545 [52:54<3:41:08,  3.57s/it] 18%|█▊        | 827/4545 [52:58<3:50:02,  3.71s/it] 18%|█▊        | 828/4545 [53:02<3:52:53,  3.76s/it] 18%|█▊        | 829/4545 [53:06<4:00:34,  3.88s/it] 18%|█▊        | 830/4545 [53:10<3:51:56,  3.75s/it]                                                    {'loss': 0.3104, 'grad_norm': 25.495615005493164, 'learning_rate': 5.47556142668428e-07, 'rewards/chosen': 2.0696043968200684, 'rewards/rejected': -2.3890624046325684, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.449999809265137, 'logps/chosen': -297.75, 'logps/rejected': -171.89999389648438, 'logits/chosen': -7.003125190734863, 'logits/rejected': -6.984375, 'epoch': 0.55}
 18%|█▊        | 830/4545 [53:10<3:51:56,  3.75s/it] 18%|█▊        | 831/4545 [53:14<3:59:41,  3.87s/it] 18%|█▊        | 832/4545 [53:17<3:51:35,  3.74s/it] 18%|█▊        | 833/4545 [53:21<3:54:19,  3.79s/it] 18%|█▊        | 834/4545 [53:25<4:01:10,  3.90s/it] 18%|█▊        | 835/4545 [53:29<3:56:43,  3.83s/it] 18%|█▊        | 836/4545 [53:32<3:32:04,  3.43s/it] 18%|█▊        | 837/4545 [53:35<3:25:56,  3.33s/it] 18%|█▊        | 838/4545 [53:39<3:36:12,  3.50s/it] 18%|█▊        | 839/4545 [53:42<3:30:22,  3.41s/it] 18%|█▊        | 840/4545 [53:45<3:32:07,  3.44s/it]                                                    {'loss': 0.3238, 'grad_norm': 60.49509811401367, 'learning_rate': 5.541611624834874e-07, 'rewards/chosen': 1.7659180164337158, 'rewards/rejected': -1.9910156726837158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.758984327316284, 'logps/chosen': -251.1999969482422, 'logps/rejected': -146.22500610351562, 'logits/chosen': -7.193749904632568, 'logits/rejected': -7.059374809265137, 'epoch': 0.55}
 18%|█▊        | 840/4545 [53:45<3:32:07,  3.44s/it] 19%|█▊        | 841/4545 [53:49<3:41:56,  3.60s/it] 19%|█▊        | 842/4545 [53:51<3:12:21,  3.12s/it] 19%|█▊        | 843/4545 [53:55<3:28:06,  3.37s/it] 19%|█▊        | 844/4545 [53:59<3:28:51,  3.39s/it] 19%|█▊        | 845/4545 [54:03<3:38:09,  3.54s/it] 19%|█▊        | 846/4545 [54:07<3:47:08,  3.68s/it] 19%|█▊        | 847/4545 [54:10<3:38:10,  3.54s/it] 19%|█▊        | 848/4545 [54:14<3:47:52,  3.70s/it] 19%|█▊        | 849/4545 [54:18<3:53:24,  3.79s/it] 19%|█▊        | 850/4545 [54:21<3:47:31,  3.69s/it]                                                    {'loss': 0.3361, 'grad_norm': 26.504749298095703, 'learning_rate': 5.607661822985469e-07, 'rewards/chosen': 1.34326171875, 'rewards/rejected': -2.5414061546325684, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.885937452316284, 'logps/chosen': -251.39999389648438, 'logps/rejected': -147.77499389648438, 'logits/chosen': -7.115624904632568, 'logits/rejected': -6.796875, 'epoch': 0.56}
 19%|█▊        | 850/4545 [54:21<3:47:31,  3.69s/it] 19%|█▊        | 851/4545 [54:25<3:40:56,  3.59s/it] 19%|█▊        | 852/4545 [54:29<3:46:20,  3.68s/it] 19%|█▉        | 853/4545 [54:32<3:43:56,  3.64s/it] 19%|█▉        | 854/4545 [54:35<3:34:10,  3.48s/it] 19%|█▉        | 855/4545 [54:39<3:42:05,  3.61s/it] 19%|█▉        | 856/4545 [54:43<3:38:34,  3.56s/it] 19%|█▉        | 857/4545 [54:46<3:45:29,  3.67s/it] 19%|█▉        | 858/4545 [54:50<3:51:16,  3.76s/it] 19%|█▉        | 859/4545 [54:54<3:42:49,  3.63s/it] 19%|█▉        | 860/4545 [54:57<3:40:44,  3.59s/it]                                                    {'loss': 0.3472, 'grad_norm': 50.685035705566406, 'learning_rate': 5.673712021136064e-07, 'rewards/chosen': 1.707910180091858, 'rewards/rejected': -2.182812452316284, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.8921875953674316, 'logps/chosen': -228.14999389648438, 'logps/rejected': -120.19999694824219, 'logits/chosen': -7.215624809265137, 'logits/rejected': -6.996874809265137, 'epoch': 0.57}
 19%|█▉        | 860/4545 [54:57<3:40:44,  3.59s/it] 19%|█▉        | 861/4545 [55:01<3:47:05,  3.70s/it] 19%|█▉        | 862/4545 [55:05<3:48:12,  3.72s/it] 19%|█▉        | 863/4545 [55:09<3:55:17,  3.83s/it] 19%|█▉        | 864/4545 [55:13<3:56:22,  3.85s/it] 19%|█▉        | 865/4545 [55:16<3:46:44,  3.70s/it] 19%|█▉        | 866/4545 [55:20<3:48:00,  3.72s/it] 19%|█▉        | 867/4545 [55:24<3:50:08,  3.75s/it] 19%|█▉        | 868/4545 [55:28<3:54:51,  3.83s/it] 19%|█▉        | 869/4545 [55:31<3:41:46,  3.62s/it] 19%|█▉        | 870/4545 [55:35<3:46:51,  3.70s/it]                                                    {'loss': 0.2687, 'grad_norm': 21.784976959228516, 'learning_rate': 5.739762219286658e-07, 'rewards/chosen': 1.64501953125, 'rewards/rejected': -2.2593750953674316, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.901562452316284, 'logps/chosen': -247.0, 'logps/rejected': -128.52499389648438, 'logits/chosen': -7.221875190734863, 'logits/rejected': -7.15625, 'epoch': 0.57}
 19%|█▉        | 870/4545 [55:35<3:46:51,  3.70s/it] 19%|█▉        | 871/4545 [55:38<3:44:05,  3.66s/it] 19%|█▉        | 872/4545 [55:42<3:35:15,  3.52s/it] 19%|█▉        | 873/4545 [55:45<3:28:11,  3.40s/it] 19%|█▉        | 874/4545 [55:49<3:39:25,  3.59s/it] 19%|█▉        | 875/4545 [55:52<3:24:01,  3.34s/it] 19%|█▉        | 876/4545 [55:55<3:34:09,  3.50s/it] 19%|█▉        | 877/4545 [55:59<3:42:26,  3.64s/it] 19%|█▉        | 878/4545 [56:03<3:41:26,  3.62s/it] 19%|█▉        | 879/4545 [56:07<3:46:18,  3.70s/it] 19%|█▉        | 880/4545 [56:11<3:44:50,  3.68s/it]                                                    {'loss': 0.4008, 'grad_norm': 27.743513107299805, 'learning_rate': 5.805812417437252e-07, 'rewards/chosen': 2.062304735183716, 'rewards/rejected': -2.1458983421325684, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.206250190734863, 'logps/chosen': -296.6499938964844, 'logps/rejected': -159.1999969482422, 'logits/chosen': -7.056250095367432, 'logits/rejected': -7.0, 'epoch': 0.58}
 19%|█▉        | 880/4545 [56:11<3:44:50,  3.68s/it] 19%|█▉        | 881/4545 [56:15<3:54:51,  3.85s/it] 19%|█▉        | 882/4545 [56:19<3:55:21,  3.86s/it] 19%|█▉        | 883/4545 [56:22<3:54:51,  3.85s/it] 19%|█▉        | 884/4545 [56:26<3:47:31,  3.73s/it] 19%|█▉        | 885/4545 [56:29<3:36:08,  3.54s/it] 19%|█▉        | 886/4545 [56:33<3:41:05,  3.63s/it] 20%|█▉        | 887/4545 [56:37<3:43:09,  3.66s/it] 20%|█▉        | 888/4545 [56:40<3:30:16,  3.45s/it] 20%|█▉        | 889/4545 [56:43<3:38:58,  3.59s/it] 20%|█▉        | 890/4545 [56:48<3:49:37,  3.77s/it]                                                    {'loss': 0.2562, 'grad_norm': 46.50406265258789, 'learning_rate': 5.871862615587847e-07, 'rewards/chosen': 1.6730468273162842, 'rewards/rejected': -2.76171875, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.435937404632568, 'logps/chosen': -241.89999389648438, 'logps/rejected': -132.625, 'logits/chosen': -7.199999809265137, 'logits/rejected': -6.896874904632568, 'epoch': 0.59}
 20%|█▉        | 890/4545 [56:48<3:49:37,  3.77s/it] 20%|█▉        | 891/4545 [56:52<3:52:10,  3.81s/it] 20%|█▉        | 892/4545 [56:55<3:53:28,  3.83s/it] 20%|█▉        | 893/4545 [56:59<3:46:37,  3.72s/it] 20%|█▉        | 894/4545 [57:02<3:40:49,  3.63s/it] 20%|█▉        | 895/4545 [57:06<3:45:39,  3.71s/it] 20%|█▉        | 896/4545 [57:10<3:48:12,  3.75s/it] 20%|█▉        | 897/4545 [57:14<3:50:39,  3.79s/it] 20%|█▉        | 898/4545 [57:18<3:55:29,  3.87s/it] 20%|█▉        | 899/4545 [57:22<3:54:41,  3.86s/it] 20%|█▉        | 900/4545 [57:26<3:55:23,  3.87s/it]                                                    {'loss': 0.3048, 'grad_norm': 115.55949401855469, 'learning_rate': 5.937912813738441e-07, 'rewards/chosen': 3.272595167160034, 'rewards/rejected': -2.081738233566284, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 5.354687690734863, 'logps/chosen': -462.1499938964844, 'logps/rejected': -261.8500061035156, 'logits/chosen': -6.921875, 'logits/rejected': -6.831250190734863, 'epoch': 0.59}
 20%|█▉        | 900/4545 [57:26<3:55:23,  3.87s/it] 20%|█▉        | 901/4545 [57:29<3:46:05,  3.72s/it] 20%|█▉        | 902/4545 [57:33<3:48:27,  3.76s/it] 20%|█▉        | 903/4545 [57:37<3:47:36,  3.75s/it] 20%|█▉        | 904/4545 [57:40<3:36:33,  3.57s/it] 20%|█▉        | 905/4545 [57:44<3:41:40,  3.65s/it] 20%|█▉        | 906/4545 [57:48<3:45:53,  3.72s/it] 20%|█▉        | 907/4545 [57:52<3:54:02,  3.86s/it] 20%|█▉        | 908/4545 [57:56<3:54:37,  3.87s/it] 20%|██        | 909/4545 [58:00<3:55:08,  3.88s/it] 20%|██        | 910/4545 [58:03<3:44:55,  3.71s/it]                                                    {'loss': 0.3716, 'grad_norm': 52.65057373046875, 'learning_rate': 6.003963011889035e-07, 'rewards/chosen': 1.500097632408142, 'rewards/rejected': -1.736718773841858, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 3.2328124046325684, 'logps/chosen': -245.5, 'logps/rejected': -165.1999969482422, 'logits/chosen': -7.034375190734863, 'logits/rejected': -7.099999904632568, 'epoch': 0.6}
 20%|██        | 910/4545 [58:03<3:44:55,  3.71s/it] 20%|██        | 911/4545 [58:07<3:50:42,  3.81s/it] 20%|██        | 912/4545 [58:11<3:53:55,  3.86s/it] 20%|██        | 913/4545 [58:15<3:54:34,  3.88s/it] 20%|██        | 914/4545 [58:19<3:54:39,  3.88s/it] 20%|██        | 915/4545 [58:22<3:45:38,  3.73s/it] 20%|██        | 916/4545 [58:26<3:48:27,  3.78s/it] 20%|██        | 917/4545 [58:30<3:49:41,  3.80s/it] 20%|██        | 918/4545 [58:32<3:16:10,  3.25s/it] 20%|██        | 919/4545 [58:35<3:22:39,  3.35s/it] 20%|██        | 920/4545 [58:39<3:32:18,  3.51s/it]                                                    {'loss': 0.3329, 'grad_norm': 37.672889709472656, 'learning_rate': 6.070013210039629e-07, 'rewards/chosen': 3.245776414871216, 'rewards/rejected': -1.953466773033142, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.196875095367432, 'logps/chosen': -402.25, 'logps/rejected': -194.85000610351562, 'logits/chosen': -6.96875, 'logits/rejected': -6.887499809265137, 'epoch': 0.61}
 20%|██        | 920/4545 [58:39<3:32:18,  3.51s/it] 20%|██        | 921/4545 [58:43<3:27:41,  3.44s/it] 20%|██        | 922/4545 [58:45<3:18:52,  3.29s/it] 20%|██        | 923/4545 [58:49<3:30:13,  3.48s/it] 20%|██        | 924/4545 [58:53<3:37:54,  3.61s/it] 20%|██        | 925/4545 [58:57<3:46:27,  3.75s/it] 20%|██        | 926/4545 [59:02<3:54:37,  3.89s/it] 20%|██        | 927/4545 [59:05<3:41:28,  3.67s/it] 20%|██        | 928/4545 [59:09<3:45:15,  3.74s/it] 20%|██        | 929/4545 [59:12<3:42:44,  3.70s/it] 20%|██        | 930/4545 [59:16<3:48:40,  3.80s/it]                                                    {'loss': 0.3242, 'grad_norm': 64.21347045898438, 'learning_rate': 6.136063408190224e-07, 'rewards/chosen': 1.5828125476837158, 'rewards/rejected': -2.4437499046325684, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.029687404632568, 'logps/chosen': -254.6750030517578, 'logps/rejected': -145.39999389648438, 'logits/chosen': -7.21875, 'logits/rejected': -7.165625095367432, 'epoch': 0.61}
 20%|██        | 930/4545 [59:16<3:48:40,  3.80s/it] 20%|██        | 931/4545 [59:20<3:55:44,  3.91s/it] 21%|██        | 932/4545 [59:24<3:46:57,  3.77s/it] 21%|██        | 933/4545 [59:27<3:35:07,  3.57s/it] 21%|██        | 934/4545 [59:30<3:30:46,  3.50s/it] 21%|██        | 935/4545 [59:35<3:42:15,  3.69s/it] 21%|██        | 936/4545 [59:37<3:17:12,  3.28s/it] 21%|██        | 937/4545 [59:41<3:30:58,  3.51s/it] 21%|██        | 938/4545 [59:45<3:39:27,  3.65s/it] 21%|██        | 939/4545 [59:49<3:42:36,  3.70s/it] 21%|██        | 940/4545 [59:53<3:51:07,  3.85s/it]                                                    {'loss': 0.2999, 'grad_norm': 33.82612228393555, 'learning_rate': 6.202113606340819e-07, 'rewards/chosen': 1.4447753429412842, 'rewards/rejected': -2.252734422683716, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.700000047683716, 'logps/chosen': -200.8000030517578, 'logps/rejected': -123.375, 'logits/chosen': -7.384375095367432, 'logits/rejected': -7.171875, 'epoch': 0.62}
 21%|██        | 940/4545 [59:53<3:51:07,  3.85s/it] 21%|██        | 941/4545 [59:57<3:58:46,  3.98s/it] 21%|██        | 942/4545 [1:00:01<3:57:10,  3.95s/it] 21%|██        | 943/4545 [1:00:05<3:52:18,  3.87s/it] 21%|██        | 944/4545 [1:00:07<3:25:20,  3.42s/it] 21%|██        | 945/4545 [1:00:10<3:24:38,  3.41s/it] 21%|██        | 946/4545 [1:00:14<3:27:16,  3.46s/it] 21%|██        | 947/4545 [1:00:18<3:35:15,  3.59s/it] 21%|██        | 948/4545 [1:00:21<3:29:33,  3.50s/it] 21%|██        | 949/4545 [1:00:25<3:36:22,  3.61s/it] 21%|██        | 950/4545 [1:00:29<3:41:28,  3.70s/it]                                                      {'loss': 0.3233, 'grad_norm': 25.785558700561523, 'learning_rate': 6.268163804491413e-07, 'rewards/chosen': 1.467919945716858, 'rewards/rejected': -2.793750047683716, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 4.263281345367432, 'logps/chosen': -215.4499969482422, 'logps/rejected': -144.3249969482422, 'logits/chosen': -7.193749904632568, 'logits/rejected': -6.900000095367432, 'epoch': 0.63}
 21%|██        | 950/4545 [1:00:29<3:41:28,  3.70s/it] 21%|██        | 951/4545 [1:00:31<3:18:25,  3.31s/it] 21%|██        | 952/4545 [1:00:34<3:13:04,  3.22s/it] 21%|██        | 953/4545 [1:00:38<3:25:03,  3.43s/it] 21%|██        | 954/4545 [1:00:42<3:35:19,  3.60s/it] 21%|██        | 955/4545 [1:00:46<3:43:32,  3.74s/it] 21%|██        | 956/4545 [1:00:50<3:46:15,  3.78s/it] 21%|██        | 957/4545 [1:00:54<3:48:23,  3.82s/it] 21%|██        | 958/4545 [1:00:58<3:49:35,  3.84s/it] 21%|██        | 959/4545 [1:01:02<3:50:33,  3.86s/it] 21%|██        | 960/4545 [1:01:06<3:45:47,  3.78s/it]                                                      {'loss': 0.2011, 'grad_norm': 51.6458854675293, 'learning_rate': 6.334214002642008e-07, 'rewards/chosen': 3.5687499046325684, 'rewards/rejected': -2.151562452316284, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 5.714062690734863, 'logps/chosen': -445.17498779296875, 'logps/rejected': -228.10000610351562, 'logits/chosen': -6.962500095367432, 'logits/rejected': -6.971875190734863, 'epoch': 0.63}
 21%|██        | 960/4545 [1:01:06<3:45:47,  3.78s/it] 21%|██        | 961/4545 [1:01:09<3:45:09,  3.77s/it] 21%|██        | 962/4545 [1:01:13<3:51:59,  3.88s/it] 21%|██        | 963/4545 [1:01:17<3:47:02,  3.80s/it] 21%|██        | 964/4545 [1:01:21<3:48:29,  3.83s/it] 21%|██        | 965/4545 [1:01:25<3:50:05,  3.86s/it] 21%|██▏       | 966/4545 [1:01:29<3:49:53,  3.85s/it] 21%|██▏       | 967/4545 [1:01:33<3:49:43,  3.85s/it] 21%|██▏       | 968/4545 [1:01:36<3:50:32,  3.87s/it] 21%|██▏       | 969/4545 [1:01:40<3:50:48,  3.87s/it] 21%|██▏       | 970/4545 [1:01:44<3:41:35,  3.72s/it]                                                      {'loss': 0.299, 'grad_norm': 63.19771194458008, 'learning_rate': 6.400264200792602e-07, 'rewards/chosen': 2.6036133766174316, 'rewards/rejected': -2.707812547683716, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.314062595367432, 'logps/chosen': -369.29998779296875, 'logps/rejected': -182.0, 'logits/chosen': -7.096875190734863, 'logits/rejected': -7.065625190734863, 'epoch': 0.64}
 21%|██▏       | 970/4545 [1:01:44<3:41:35,  3.72s/it] 21%|██▏       | 971/4545 [1:01:47<3:29:54,  3.52s/it] 21%|██▏       | 972/4545 [1:01:51<3:41:08,  3.71s/it] 21%|██▏       | 973/4545 [1:01:55<3:44:56,  3.78s/it] 21%|██▏       | 974/4545 [1:01:59<3:46:56,  3.81s/it] 21%|██▏       | 975/4545 [1:02:03<3:48:17,  3.84s/it] 21%|██▏       | 976/4545 [1:02:07<3:54:56,  3.95s/it] 21%|██▏       | 977/4545 [1:02:11<3:52:30,  3.91s/it] 22%|██▏       | 978/4545 [1:02:13<3:29:31,  3.52s/it] 22%|██▏       | 979/4545 [1:02:17<3:36:20,  3.64s/it] 22%|██▏       | 980/4545 [1:02:21<3:47:03,  3.82s/it]                                                      {'loss': 0.2688, 'grad_norm': 17.435640335083008, 'learning_rate': 6.466314398943197e-07, 'rewards/chosen': 2.9326171875, 'rewards/rejected': -2.4906249046325684, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.418749809265137, 'logps/chosen': -366.5, 'logps/rejected': -208.60000610351562, 'logits/chosen': -7.256249904632568, 'logits/rejected': -7.025000095367432, 'epoch': 0.65}
 22%|██▏       | 980/4545 [1:02:22<3:47:03,  3.82s/it] 22%|██▏       | 981/4545 [1:02:25<3:48:22,  3.84s/it] 22%|██▏       | 982/4545 [1:02:30<3:54:28,  3.95s/it] 22%|██▏       | 983/4545 [1:02:32<3:21:28,  3.39s/it] 22%|██▏       | 984/4545 [1:02:36<3:30:08,  3.54s/it] 22%|██▏       | 985/4545 [1:02:38<3:18:58,  3.35s/it] 22%|██▏       | 986/4545 [1:02:41<3:05:09,  3.12s/it] 22%|██▏       | 987/4545 [1:02:44<3:09:12,  3.19s/it] 22%|██▏       | 988/4545 [1:02:48<3:20:49,  3.39s/it] 22%|██▏       | 989/4545 [1:02:51<3:10:06,  3.21s/it] 22%|██▏       | 990/4545 [1:02:55<3:23:07,  3.43s/it]                                                      {'loss': 0.2737, 'grad_norm': 47.28120040893555, 'learning_rate': 6.532364597093791e-07, 'rewards/chosen': 0.6493164300918579, 'rewards/rejected': -3.25, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.9046874046325684, 'logps/chosen': -142.5749969482422, 'logps/rejected': -96.7249984741211, 'logits/chosen': -7.356249809265137, 'logits/rejected': -6.856249809265137, 'epoch': 0.65}
 22%|██▏       | 990/4545 [1:02:55<3:23:07,  3.43s/it] 22%|██▏       | 991/4545 [1:02:59<3:40:46,  3.73s/it] 22%|██▏       | 992/4545 [1:03:02<3:23:50,  3.44s/it] 22%|██▏       | 993/4545 [1:03:06<3:27:43,  3.51s/it] 22%|██▏       | 994/4545 [1:03:10<3:35:05,  3.63s/it] 22%|██▏       | 995/4545 [1:03:13<3:27:53,  3.51s/it] 22%|██▏       | 996/4545 [1:03:15<3:04:42,  3.12s/it] 22%|██▏       | 997/4545 [1:03:19<3:23:22,  3.44s/it] 22%|██▏       | 998/4545 [1:03:23<3:34:00,  3.62s/it] 22%|██▏       | 999/4545 [1:03:28<3:42:10,  3.76s/it] 22%|██▏       | 1000/4545 [1:03:31<3:41:06,  3.74s/it]                                                       {'loss': 0.3328, 'grad_norm': 50.851802825927734, 'learning_rate': 6.598414795244386e-07, 'rewards/chosen': 0.734570324420929, 'rewards/rejected': -3.4937500953674316, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.23046875, 'logps/chosen': -157.0749969482422, 'logps/rejected': -107.94999694824219, 'logits/chosen': -7.393750190734863, 'logits/rejected': -7.053124904632568, 'epoch': 0.66}
 22%|██▏       | 1000/4545 [1:03:31<3:41:06,  3.74s/it] 22%|██▏       | 1001/4545 [1:03:35<3:41:25,  3.75s/it] 22%|██▏       | 1002/4545 [1:03:39<3:48:00,  3.86s/it] 22%|██▏       | 1003/4545 [1:03:43<3:47:13,  3.85s/it] 22%|██▏       | 1004/4545 [1:03:47<3:42:47,  3.77s/it] 22%|██▏       | 1005/4545 [1:03:49<3:23:55,  3.46s/it] 22%|██▏       | 1006/4545 [1:03:53<3:37:44,  3.69s/it] 22%|██▏       | 1007/4545 [1:03:57<3:34:05,  3.63s/it] 22%|██▏       | 1008/4545 [1:04:01<3:36:33,  3.67s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:43,  1.35it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.09s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:07<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:19,  1.65s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.64s/it][A
 23%|██▎       | 14/60 [00:21<01:16,  1.67s/it][A
 25%|██▌       | 15/60 [00:22<01:09,  1.55s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.41s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.30s/it][A
 30%|███       | 18/60 [00:25<00:46,  1.10s/it][A
 32%|███▏      | 19/60 [00:26<00:47,  1.15s/it][A
 33%|███▎      | 20/60 [00:27<00:40,  1.00s/it][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.08s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:41<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.36s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:01<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.36s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.42s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.41s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.46s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A                                                       
                                               [A{'eval_loss': 0.37625810503959656, 'eval_runtime': 80.9884, 'eval_samples_per_second': 11.767, 'eval_steps_per_second': 0.741, 'eval_rewards/chosen': 2.344583034515381, 'eval_rewards/rejected': -1.942285180091858, 'eval_rewards/accuracies': 0.8332176208496094, 'eval_rewards/margins': 4.283398628234863, 'eval_logps/chosen': -365.8666687011719, 'eval_logps/rejected': -161.74166870117188, 'eval_logits/chosen': -6.9276041984558105, 'eval_logits/rejected': -7.3848958015441895, 'epoch': 0.67}
 22%|██▏       | 1008/4545 [1:05:22<3:36:33,  3.67s/it]
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 22%|██▏       | 1009/4545 [1:05:39<31:27:49, 32.03s/it] 22%|██▏       | 1010/4545 [1:05:43<23:09:37, 23.59s/it]                                                        {'loss': 0.2901, 'grad_norm': 46.07782745361328, 'learning_rate': 6.66446499339498e-07, 'rewards/chosen': 0.855273425579071, 'rewards/rejected': -3.484375, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.340624809265137, 'logps/chosen': -183.4499969482422, 'logps/rejected': -121.125, 'logits/chosen': -7.296875, 'logits/rejected': -7.090624809265137, 'epoch': 0.67}
 22%|██▏       | 1010/4545 [1:05:43<23:09:37, 23.59s/it] 22%|██▏       | 1011/4545 [1:05:47<17:20:42, 17.67s/it] 22%|██▏       | 1012/4545 [1:05:51<13:16:54, 13.53s/it] 22%|██▏       | 1013/4545 [1:05:54<10:26:13, 10.64s/it] 22%|██▏       | 1014/4545 [1:05:58<8:26:12,  8.60s/it]  22%|██▏       | 1015/4545 [1:06:02<7:02:48,  7.19s/it] 22%|██▏       | 1016/4545 [1:06:06<6:04:28,  6.20s/it] 22%|██▏       | 1017/4545 [1:06:10<5:22:24,  5.48s/it] 22%|██▏       | 1018/4545 [1:06:12<4:27:01,  4.54s/it] 22%|██▏       | 1019/4545 [1:06:16<4:19:44,  4.42s/it] 22%|██▏       | 1020/4545 [1:06:19<3:56:00,  4.02s/it]                                                       {'loss': 0.3637, 'grad_norm': 45.980010986328125, 'learning_rate': 6.730515191545574e-07, 'rewards/chosen': 2.4156737327575684, 'rewards/rejected': -2.4507813453674316, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 4.864062309265137, 'logps/chosen': -304.0, 'logps/rejected': -194.0500030517578, 'logits/chosen': -7.324999809265137, 'logits/rejected': -7.118750095367432, 'epoch': 0.67}
 22%|██▏       | 1020/4545 [1:06:20<3:56:00,  4.02s/it] 22%|██▏       | 1021/4545 [1:06:22<3:23:16,  3.46s/it] 22%|██▏       | 1022/4545 [1:06:24<3:12:05,  3.27s/it] 23%|██▎       | 1023/4545 [1:06:28<3:16:09,  3.34s/it] 23%|██▎       | 1024/4545 [1:06:32<3:28:49,  3.56s/it] 23%|██▎       | 1025/4545 [1:06:36<3:34:27,  3.66s/it] 23%|██▎       | 1026/4545 [1:06:40<3:38:32,  3.73s/it] 23%|██▎       | 1027/4545 [1:06:43<3:34:45,  3.66s/it] 23%|██▎       | 1028/4545 [1:06:47<3:34:29,  3.66s/it] 23%|██▎       | 1029/4545 [1:06:51<3:41:52,  3.79s/it] 23%|██▎       | 1030/4545 [1:06:55<3:43:22,  3.81s/it]                                                       {'loss': 0.3465, 'grad_norm': 49.87372589111328, 'learning_rate': 6.796565389696169e-07, 'rewards/chosen': 1.0654418468475342, 'rewards/rejected': -3.164843797683716, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.234375, 'logps/chosen': -201.3000030517578, 'logps/rejected': -140.6750030517578, 'logits/chosen': -7.599999904632568, 'logits/rejected': -7.215624809265137, 'epoch': 0.68}
 23%|██▎       | 1030/4545 [1:06:55<3:43:22,  3.81s/it] 23%|██▎       | 1031/4545 [1:06:58<3:34:10,  3.66s/it] 23%|██▎       | 1032/4545 [1:07:02<3:32:44,  3.63s/it] 23%|██▎       | 1033/4545 [1:07:06<3:38:46,  3.74s/it] 23%|██▎       | 1034/4545 [1:07:09<3:24:06,  3.49s/it] 23%|██▎       | 1035/4545 [1:07:13<3:33:25,  3.65s/it] 23%|██▎       | 1036/4545 [1:07:16<3:25:05,  3.51s/it] 23%|██▎       | 1037/4545 [1:07:19<3:21:47,  3.45s/it] 23%|██▎       | 1038/4545 [1:07:22<3:08:40,  3.23s/it] 23%|██▎       | 1039/4545 [1:07:26<3:20:13,  3.43s/it] 23%|██▎       | 1040/4545 [1:07:29<3:15:47,  3.35s/it]                                                       {'loss': 0.2392, 'grad_norm': 51.394107818603516, 'learning_rate': 6.862615587846763e-07, 'rewards/chosen': 1.3295189142227173, 'rewards/rejected': -3.9124999046325684, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 5.237500190734863, 'logps/chosen': -180.8000030517578, 'logps/rejected': -128.9499969482422, 'logits/chosen': -7.53125, 'logits/rejected': -7.115624904632568, 'epoch': 0.69}
 23%|██▎       | 1040/4545 [1:07:29<3:15:47,  3.35s/it] 23%|██▎       | 1041/4545 [1:07:33<3:26:20,  3.53s/it] 23%|██▎       | 1042/4545 [1:07:36<3:26:43,  3.54s/it] 23%|██▎       | 1043/4545 [1:07:40<3:22:10,  3.46s/it] 23%|██▎       | 1044/4545 [1:07:44<3:28:13,  3.57s/it] 23%|██▎       | 1045/4545 [1:07:48<3:34:28,  3.68s/it] 23%|██▎       | 1046/4545 [1:07:51<3:37:31,  3.73s/it] 23%|██▎       | 1047/4545 [1:07:55<3:40:08,  3.78s/it] 23%|██▎       | 1048/4545 [1:07:59<3:42:32,  3.82s/it] 23%|██▎       | 1049/4545 [1:08:02<3:33:28,  3.66s/it] 23%|██▎       | 1050/4545 [1:08:06<3:37:19,  3.73s/it]                                                       {'loss': 0.2231, 'grad_norm': 18.557607650756836, 'learning_rate': 6.928665785997357e-07, 'rewards/chosen': 2.7967286109924316, 'rewards/rejected': -3.4515624046325684, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 6.253125190734863, 'logps/chosen': -341.29998779296875, 'logps/rejected': -184.25, 'logits/chosen': -7.259375095367432, 'logits/rejected': -7.084374904632568, 'epoch': 0.69}
 23%|██▎       | 1050/4545 [1:08:06<3:37:19,  3.73s/it] 23%|██▎       | 1051/4545 [1:08:10<3:41:10,  3.80s/it] 23%|██▎       | 1052/4545 [1:08:14<3:41:46,  3.81s/it] 23%|██▎       | 1053/4545 [1:08:18<3:37:34,  3.74s/it] 23%|██▎       | 1054/4545 [1:08:21<3:30:33,  3.62s/it] 23%|██▎       | 1055/4545 [1:08:25<3:31:33,  3.64s/it] 23%|██▎       | 1056/4545 [1:08:29<3:33:48,  3.68s/it] 23%|██▎       | 1057/4545 [1:08:32<3:37:33,  3.74s/it] 23%|██▎       | 1058/4545 [1:08:35<3:24:00,  3.51s/it] 23%|██▎       | 1059/4545 [1:08:39<3:30:52,  3.63s/it] 23%|██▎       | 1060/4545 [1:08:43<3:36:38,  3.73s/it]                                                       {'loss': 0.3789, 'grad_norm': 57.134037017822266, 'learning_rate': 6.994715984147952e-07, 'rewards/chosen': 2.034994602203369, 'rewards/rejected': -2.781445264816284, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.8203125, 'logps/chosen': -284.17498779296875, 'logps/rejected': -178.875, 'logits/chosen': -7.434374809265137, 'logits/rejected': -7.025000095367432, 'epoch': 0.7}
 23%|██▎       | 1060/4545 [1:08:43<3:36:38,  3.73s/it] 23%|██▎       | 1061/4545 [1:08:47<3:39:11,  3.77s/it] 23%|██▎       | 1062/4545 [1:08:51<3:45:35,  3.89s/it] 23%|██▎       | 1063/4545 [1:08:55<3:37:06,  3.74s/it] 23%|██▎       | 1064/4545 [1:08:59<3:39:26,  3.78s/it] 23%|██▎       | 1065/4545 [1:09:03<3:44:51,  3.88s/it] 23%|██▎       | 1066/4545 [1:09:07<3:48:54,  3.95s/it] 23%|██▎       | 1067/4545 [1:09:10<3:34:36,  3.70s/it] 23%|██▎       | 1068/4545 [1:09:14<3:33:29,  3.68s/it] 24%|██▎       | 1069/4545 [1:09:17<3:30:28,  3.63s/it] 24%|██▎       | 1070/4545 [1:09:20<3:25:34,  3.55s/it]                                                       {'loss': 0.2844, 'grad_norm': 26.627079010009766, 'learning_rate': 7.060766182298547e-07, 'rewards/chosen': 1.023095726966858, 'rewards/rejected': -3.582812547683716, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.603125095367432, 'logps/chosen': -189.85000610351562, 'logps/rejected': -116.07499694824219, 'logits/chosen': -7.34375, 'logits/rejected': -7.199999809265137, 'epoch': 0.71}
 24%|██▎       | 1070/4545 [1:09:20<3:25:34,  3.55s/it] 24%|██▎       | 1071/4545 [1:09:24<3:32:05,  3.66s/it] 24%|██▎       | 1072/4545 [1:09:28<3:36:26,  3.74s/it] 24%|██▎       | 1073/4545 [1:09:32<3:38:52,  3.78s/it] 24%|██▎       | 1074/4545 [1:09:36<3:40:36,  3.81s/it] 24%|██▎       | 1075/4545 [1:09:40<3:44:05,  3.87s/it] 24%|██▎       | 1076/4545 [1:09:43<3:27:37,  3.59s/it] 24%|██▎       | 1077/4545 [1:09:47<3:32:36,  3.68s/it] 24%|██▎       | 1078/4545 [1:09:51<3:36:38,  3.75s/it] 24%|██▎       | 1079/4545 [1:09:55<3:39:02,  3.79s/it] 24%|██▍       | 1080/4545 [1:09:59<3:40:44,  3.82s/it]                                                       {'loss': 0.3529, 'grad_norm': 38.14762496948242, 'learning_rate': 7.126816380449141e-07, 'rewards/chosen': 3.601605176925659, 'rewards/rejected': -1.9484374523162842, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 5.551562309265137, 'logps/chosen': -449.07501220703125, 'logps/rejected': -229.8000030517578, 'logits/chosen': -6.840624809265137, 'logits/rejected': -6.699999809265137, 'epoch': 0.71}
 24%|██▍       | 1080/4545 [1:09:59<3:40:44,  3.82s/it] 24%|██▍       | 1081/4545 [1:10:02<3:42:08,  3.85s/it] 24%|██▍       | 1082/4545 [1:10:06<3:43:11,  3.87s/it] 24%|██▍       | 1083/4545 [1:10:09<3:29:51,  3.64s/it] 24%|██▍       | 1084/4545 [1:10:13<3:36:43,  3.76s/it] 24%|██▍       | 1085/4545 [1:10:17<3:32:07,  3.68s/it] 24%|██▍       | 1086/4545 [1:10:20<3:14:37,  3.38s/it] 24%|██▍       | 1087/4545 [1:10:23<3:06:29,  3.24s/it] 24%|██▍       | 1088/4545 [1:10:26<3:17:54,  3.44s/it] 24%|██▍       | 1089/4545 [1:10:30<3:25:05,  3.56s/it] 24%|██▍       | 1090/4545 [1:10:34<3:33:56,  3.72s/it]                                                       {'loss': 0.24, 'grad_norm': 53.03557205200195, 'learning_rate': 7.192866578599735e-07, 'rewards/chosen': 1.6480224132537842, 'rewards/rejected': -3.6312499046325684, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 5.276562690734863, 'logps/chosen': -243.3249969482422, 'logps/rejected': -131.14999389648438, 'logits/chosen': -7.409375190734863, 'logits/rejected': -7.118750095367432, 'epoch': 0.72}
 24%|██▍       | 1090/4545 [1:10:35<3:33:56,  3.72s/it] 24%|██▍       | 1091/4545 [1:10:38<3:29:43,  3.64s/it] 24%|██▍       | 1092/4545 [1:10:40<2:59:43,  3.12s/it] 24%|██▍       | 1093/4545 [1:10:44<3:12:57,  3.35s/it] 24%|██▍       | 1094/4545 [1:10:47<3:14:27,  3.38s/it] 24%|██▍       | 1095/4545 [1:10:51<3:22:22,  3.52s/it] 24%|██▍       | 1096/4545 [1:10:54<3:12:02,  3.34s/it] 24%|██▍       | 1097/4545 [1:10:58<3:24:48,  3.56s/it] 24%|██▍       | 1098/4545 [1:11:02<3:33:00,  3.71s/it] 24%|██▍       | 1099/4545 [1:11:06<3:35:26,  3.75s/it] 24%|██▍       | 1100/4545 [1:11:10<3:41:25,  3.86s/it]                                                       {'loss': 0.3274, 'grad_norm': 30.75234031677246, 'learning_rate': 7.25891677675033e-07, 'rewards/chosen': 1.541894555091858, 'rewards/rejected': -3.6324219703674316, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 5.168749809265137, 'logps/chosen': -253.3249969482422, 'logps/rejected': -145.875, 'logits/chosen': -7.478125095367432, 'logits/rejected': -7.303124904632568, 'epoch': 0.73}
 24%|██▍       | 1100/4545 [1:11:10<3:41:25,  3.86s/it] 24%|██▍       | 1101/4545 [1:11:14<3:43:21,  3.89s/it] 24%|██▍       | 1102/4545 [1:11:18<3:43:10,  3.89s/it] 24%|██▍       | 1103/4545 [1:11:21<3:32:53,  3.71s/it] 24%|██▍       | 1104/4545 [1:11:25<3:35:06,  3.75s/it] 24%|██▍       | 1105/4545 [1:11:29<3:40:35,  3.85s/it] 24%|██▍       | 1106/4545 [1:11:33<3:41:38,  3.87s/it] 24%|██▍       | 1107/4545 [1:11:37<3:47:13,  3.97s/it] 24%|██▍       | 1108/4545 [1:11:40<3:21:54,  3.52s/it] 24%|██▍       | 1109/4545 [1:11:43<3:27:21,  3.62s/it] 24%|██▍       | 1110/4545 [1:11:47<3:18:53,  3.47s/it]                                                       {'loss': 0.3364, 'grad_norm': 25.61241912841797, 'learning_rate': 7.324966974900925e-07, 'rewards/chosen': 2.255908250808716, 'rewards/rejected': -3.039990186691284, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 5.290625095367432, 'logps/chosen': -301.17498779296875, 'logps/rejected': -180.9499969482422, 'logits/chosen': -7.209374904632568, 'logits/rejected': -7.099999904632568, 'epoch': 0.73}
 24%|██▍       | 1110/4545 [1:11:47<3:18:53,  3.47s/it] 24%|██▍       | 1111/4545 [1:11:49<3:02:47,  3.19s/it] 24%|██▍       | 1112/4545 [1:11:53<3:14:47,  3.40s/it] 24%|██▍       | 1113/4545 [1:11:57<3:20:09,  3.50s/it] 25%|██▍       | 1114/4545 [1:12:01<3:26:53,  3.62s/it] 25%|██▍       | 1115/4545 [1:12:05<3:37:01,  3.80s/it] 25%|██▍       | 1116/4545 [1:12:08<3:27:08,  3.62s/it] 25%|██▍       | 1117/4545 [1:12:10<3:03:24,  3.21s/it] 25%|██▍       | 1118/4545 [1:12:15<3:19:58,  3.50s/it] 25%|██▍       | 1119/4545 [1:12:18<3:26:29,  3.62s/it] 25%|██▍       | 1120/4545 [1:12:22<3:28:29,  3.65s/it]                                                       {'loss': 0.2227, 'grad_norm': 56.294647216796875, 'learning_rate': 7.391017173051519e-07, 'rewards/chosen': 2.171875, 'rewards/rejected': -3.1875, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.356249809265137, 'logps/chosen': -258.2250061035156, 'logps/rejected': -150.25, 'logits/chosen': -7.412499904632568, 'logits/rejected': -7.199999809265137, 'epoch': 0.74}
 25%|██▍       | 1120/4545 [1:12:22<3:28:29,  3.65s/it] 25%|██▍       | 1121/4545 [1:12:26<3:37:02,  3.80s/it] 25%|██▍       | 1122/4545 [1:12:30<3:40:45,  3.87s/it] 25%|██▍       | 1123/4545 [1:12:34<3:39:43,  3.85s/it] 25%|██▍       | 1124/4545 [1:12:38<3:40:13,  3.86s/it] 25%|██▍       | 1125/4545 [1:12:41<3:30:42,  3.70s/it] 25%|██▍       | 1126/4545 [1:12:45<3:33:54,  3.75s/it] 25%|██▍       | 1127/4545 [1:12:49<3:28:20,  3.66s/it] 25%|██▍       | 1128/4545 [1:12:52<3:20:56,  3.53s/it] 25%|██▍       | 1129/4545 [1:12:56<3:29:23,  3.68s/it] 25%|██▍       | 1130/4545 [1:12:58<2:59:03,  3.15s/it]                                                       {'loss': 0.2183, 'grad_norm': 23.474323272705078, 'learning_rate': 7.457067371202113e-07, 'rewards/chosen': 1.6544921398162842, 'rewards/rejected': -3.526562452316284, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 5.185937404632568, 'logps/chosen': -209.97500610351562, 'logps/rejected': -123.9749984741211, 'logits/chosen': -7.421875, 'logits/rejected': -7.040625095367432, 'epoch': 0.75}
 25%|██▍       | 1130/4545 [1:12:58<2:59:03,  3.15s/it] 25%|██▍       | 1131/4545 [1:13:02<3:08:40,  3.32s/it] 25%|██▍       | 1132/4545 [1:13:04<3:00:45,  3.18s/it] 25%|██▍       | 1133/4545 [1:13:08<3:11:35,  3.37s/it] 25%|██▍       | 1134/4545 [1:13:11<3:06:39,  3.28s/it] 25%|██▍       | 1135/4545 [1:13:15<3:16:54,  3.46s/it] 25%|██▍       | 1136/4545 [1:13:18<3:12:43,  3.39s/it] 25%|██▌       | 1137/4545 [1:13:22<3:09:25,  3.34s/it] 25%|██▌       | 1138/4545 [1:13:26<3:20:33,  3.53s/it] 25%|██▌       | 1139/4545 [1:13:29<3:16:06,  3.45s/it] 25%|██▌       | 1140/4545 [1:13:32<3:15:54,  3.45s/it]                                                       {'loss': 0.3169, 'grad_norm': 56.272911071777344, 'learning_rate': 7.523117569352709e-07, 'rewards/chosen': 0.9833984375, 'rewards/rejected': -3.3570313453674316, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.340624809265137, 'logps/chosen': -160.35000610351562, 'logps/rejected': -130.5, 'logits/chosen': -7.409375190734863, 'logits/rejected': -7.056250095367432, 'epoch': 0.75}
 25%|██▌       | 1140/4545 [1:13:32<3:15:54,  3.45s/it] 25%|██▌       | 1141/4545 [1:13:36<3:24:10,  3.60s/it] 25%|██▌       | 1142/4545 [1:13:39<3:14:32,  3.43s/it] 25%|██▌       | 1143/4545 [1:13:43<3:12:08,  3.39s/it] 25%|██▌       | 1144/4545 [1:13:46<3:20:25,  3.54s/it] 25%|██▌       | 1145/4545 [1:13:50<3:28:23,  3.68s/it] 25%|██▌       | 1146/4545 [1:13:54<3:31:50,  3.74s/it] 25%|██▌       | 1147/4545 [1:13:57<3:20:22,  3.54s/it] 25%|██▌       | 1148/4545 [1:14:00<3:11:40,  3.39s/it] 25%|██▌       | 1149/4545 [1:14:04<3:13:39,  3.42s/it] 25%|██▌       | 1150/4545 [1:14:07<3:14:08,  3.43s/it]                                                       {'loss': 0.2488, 'grad_norm': 31.008563995361328, 'learning_rate': 7.589167767503302e-07, 'rewards/chosen': 2.7225584983825684, 'rewards/rejected': -3.2132811546325684, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.9375, 'logps/chosen': -294.5, 'logps/rejected': -186.8000030517578, 'logits/chosen': -7.287499904632568, 'logits/rejected': -6.884375095367432, 'epoch': 0.76}
 25%|██▌       | 1150/4545 [1:14:08<3:14:08,  3.43s/it] 25%|██▌       | 1151/4545 [1:14:11<3:23:02,  3.59s/it] 25%|██▌       | 1152/4545 [1:14:15<3:28:06,  3.68s/it] 25%|██▌       | 1153/4545 [1:14:19<3:31:35,  3.74s/it] 25%|██▌       | 1154/4545 [1:14:21<2:52:43,  3.06s/it] 25%|██▌       | 1155/4545 [1:14:24<3:06:19,  3.30s/it] 25%|██▌       | 1156/4545 [1:14:28<3:13:39,  3.43s/it] 25%|██▌       | 1157/4545 [1:14:32<3:22:07,  3.58s/it] 25%|██▌       | 1158/4545 [1:14:36<3:27:07,  3.67s/it] 26%|██▌       | 1159/4545 [1:14:40<3:30:46,  3.74s/it] 26%|██▌       | 1160/4545 [1:14:43<3:17:53,  3.51s/it]                                                       {'loss': 0.271, 'grad_norm': 14.678214073181152, 'learning_rate': 7.655217965653896e-07, 'rewards/chosen': 2.530932664871216, 'rewards/rejected': -4.027734279632568, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.557812690734863, 'logps/chosen': -276.3500061035156, 'logps/rejected': -153.5749969482422, 'logits/chosen': -7.381249904632568, 'logits/rejected': -7.25, 'epoch': 0.77}
 26%|██▌       | 1160/4545 [1:14:43<3:17:53,  3.51s/it] 26%|██▌       | 1161/4545 [1:14:47<3:24:36,  3.63s/it] 26%|██▌       | 1162/4545 [1:14:51<3:29:59,  3.72s/it] 26%|██▌       | 1163/4545 [1:14:55<3:32:45,  3.77s/it] 26%|██▌       | 1164/4545 [1:14:59<3:37:18,  3.86s/it] 26%|██▌       | 1165/4545 [1:15:03<3:37:41,  3.86s/it] 26%|██▌       | 1166/4545 [1:15:05<3:11:13,  3.40s/it] 26%|██▌       | 1167/4545 [1:15:09<3:18:57,  3.53s/it] 26%|██▌       | 1168/4545 [1:15:13<3:26:14,  3.66s/it] 26%|██▌       | 1169/4545 [1:15:16<3:23:54,  3.62s/it] 26%|██▌       | 1170/4545 [1:15:20<3:33:10,  3.79s/it]                                                       {'loss': 0.2998, 'grad_norm': 21.55890655517578, 'learning_rate': 7.72126816380449e-07, 'rewards/chosen': 2.272839307785034, 'rewards/rejected': -4.452343940734863, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.723437309265137, 'logps/chosen': -332.04998779296875, 'logps/rejected': -158.125, 'logits/chosen': -7.243750095367432, 'logits/rejected': -7.128125190734863, 'epoch': 0.77}
 26%|██▌       | 1170/4545 [1:15:20<3:33:10,  3.79s/it] 26%|██▌       | 1171/4545 [1:15:23<3:18:59,  3.54s/it] 26%|██▌       | 1172/4545 [1:15:27<3:24:30,  3.64s/it] 26%|██▌       | 1173/4545 [1:15:30<3:17:46,  3.52s/it] 26%|██▌       | 1174/4545 [1:15:34<3:23:53,  3.63s/it] 26%|██▌       | 1175/4545 [1:15:38<3:26:50,  3.68s/it] 26%|██▌       | 1176/4545 [1:15:42<3:30:14,  3.74s/it] 26%|██▌       | 1177/4545 [1:15:46<3:25:38,  3.66s/it] 26%|██▌       | 1178/4545 [1:15:49<3:29:11,  3.73s/it] 26%|██▌       | 1179/4545 [1:15:54<3:36:39,  3.86s/it] 26%|██▌       | 1180/4545 [1:15:58<3:41:34,  3.95s/it]                                                       {'loss': 0.2545, 'grad_norm': 15.849017143249512, 'learning_rate': 7.787318361955086e-07, 'rewards/chosen': 2.500683546066284, 'rewards/rejected': -3.461718797683716, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.967187404632568, 'logps/chosen': -308.29998779296875, 'logps/rejected': -201.39999389648438, 'logits/chosen': -7.471875190734863, 'logits/rejected': -7.228125095367432, 'epoch': 0.78}
 26%|██▌       | 1180/4545 [1:15:58<3:41:34,  3.95s/it] 26%|██▌       | 1181/4545 [1:16:02<3:44:29,  4.00s/it] 26%|██▌       | 1182/4545 [1:16:06<3:41:50,  3.96s/it] 26%|██▌       | 1183/4545 [1:16:10<3:46:23,  4.04s/it] 26%|██▌       | 1184/4545 [1:16:14<3:43:10,  3.98s/it] 26%|██▌       | 1185/4545 [1:16:17<3:21:53,  3.61s/it] 26%|██▌       | 1186/4545 [1:16:20<3:26:02,  3.68s/it] 26%|██▌       | 1187/4545 [1:16:24<3:29:36,  3.75s/it] 26%|██▌       | 1188/4545 [1:16:28<3:31:43,  3.78s/it] 26%|██▌       | 1189/4545 [1:16:31<3:23:36,  3.64s/it] 26%|██▌       | 1190/4545 [1:16:35<3:28:05,  3.72s/it]                                                       {'loss': 0.2321, 'grad_norm': 22.286828994750977, 'learning_rate': 7.85336856010568e-07, 'rewards/chosen': 2.550097703933716, 'rewards/rejected': -4.241015434265137, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 6.787499904632568, 'logps/chosen': -290.75, 'logps/rejected': -218.85000610351562, 'logits/chosen': -7.353125095367432, 'logits/rejected': -7.228125095367432, 'epoch': 0.79}
 26%|██▌       | 1190/4545 [1:16:35<3:28:05,  3.72s/it] 26%|██▌       | 1191/4545 [1:16:39<3:20:19,  3.58s/it] 26%|██▌       | 1192/4545 [1:16:43<3:28:32,  3.73s/it] 26%|██▌       | 1193/4545 [1:16:46<3:27:01,  3.71s/it] 26%|██▋       | 1194/4545 [1:16:50<3:28:26,  3.73s/it] 26%|██▋       | 1195/4545 [1:16:54<3:30:49,  3.78s/it] 26%|██▋       | 1196/4545 [1:16:58<3:32:36,  3.81s/it] 26%|██▋       | 1197/4545 [1:17:02<3:33:17,  3.82s/it] 26%|██▋       | 1198/4545 [1:17:05<3:17:58,  3.55s/it] 26%|██▋       | 1199/4545 [1:17:08<3:08:52,  3.39s/it] 26%|██▋       | 1200/4545 [1:17:12<3:22:31,  3.63s/it]                                                       {'loss': 0.2381, 'grad_norm': 52.728111267089844, 'learning_rate': 7.919418758256274e-07, 'rewards/chosen': 1.92578125, 'rewards/rejected': -4.036718845367432, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 5.964062690734863, 'logps/chosen': -257.3999938964844, 'logps/rejected': -168.3000030517578, 'logits/chosen': -7.418749809265137, 'logits/rejected': -6.837500095367432, 'epoch': 0.79}
 26%|██▋       | 1200/4545 [1:17:12<3:22:31,  3.63s/it] 26%|██▋       | 1201/4545 [1:17:15<3:08:51,  3.39s/it] 26%|██▋       | 1202/4545 [1:17:18<3:15:44,  3.51s/it] 26%|██▋       | 1203/4545 [1:17:23<3:25:11,  3.68s/it] 26%|██▋       | 1204/4545 [1:17:26<3:23:48,  3.66s/it] 27%|██▋       | 1205/4545 [1:17:30<3:26:37,  3.71s/it] 27%|██▋       | 1206/4545 [1:17:33<3:17:57,  3.56s/it] 27%|██▋       | 1207/4545 [1:17:37<3:22:30,  3.64s/it] 27%|██▋       | 1208/4545 [1:17:41<3:26:48,  3.72s/it] 27%|██▋       | 1209/4545 [1:17:45<3:32:24,  3.82s/it] 27%|██▋       | 1210/4545 [1:17:49<3:32:47,  3.83s/it]                                                       {'loss': 0.2683, 'grad_norm': 20.86703109741211, 'learning_rate': 7.985468956406869e-07, 'rewards/chosen': 1.088647484779358, 'rewards/rejected': -5.595312595367432, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 6.676562309265137, 'logps/chosen': -225.4499969482422, 'logps/rejected': -158.10000610351562, 'logits/chosen': -7.431250095367432, 'logits/rejected': -7.162499904632568, 'epoch': 0.8}
 27%|██▋       | 1210/4545 [1:17:49<3:32:47,  3.83s/it] 27%|██▋       | 1211/4545 [1:17:53<3:36:50,  3.90s/it] 27%|██▋       | 1212/4545 [1:17:57<3:36:21,  3.89s/it] 27%|██▋       | 1213/4545 [1:18:01<3:36:08,  3.89s/it] 27%|██▋       | 1214/4545 [1:18:05<3:39:46,  3.96s/it] 27%|██▋       | 1215/4545 [1:18:08<3:28:18,  3.75s/it] 27%|██▋       | 1216/4545 [1:18:12<3:25:54,  3.71s/it] 27%|██▋       | 1217/4545 [1:18:16<3:29:39,  3.78s/it] 27%|██▋       | 1218/4545 [1:18:20<3:36:44,  3.91s/it] 27%|██▋       | 1219/4545 [1:18:24<3:36:18,  3.90s/it] 27%|██▋       | 1220/4545 [1:18:28<3:35:49,  3.89s/it]                                                       {'loss': 0.2347, 'grad_norm': 10.951648712158203, 'learning_rate': 8.051519154557464e-07, 'rewards/chosen': 2.7738280296325684, 'rewards/rejected': -3.5933594703674316, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 6.362500190734863, 'logps/chosen': -325.6000061035156, 'logps/rejected': -202.6750030517578, 'logits/chosen': -7.340624809265137, 'logits/rejected': -6.974999904632568, 'epoch': 0.81}
 27%|██▋       | 1220/4545 [1:18:28<3:35:49,  3.89s/it] 27%|██▋       | 1221/4545 [1:18:31<3:29:32,  3.78s/it] 27%|██▋       | 1222/4545 [1:18:35<3:25:15,  3.71s/it] 27%|██▋       | 1223/4545 [1:18:39<3:27:47,  3.75s/it] 27%|██▋       | 1224/4545 [1:18:42<3:29:20,  3.78s/it] 27%|██▋       | 1225/4545 [1:18:46<3:21:22,  3.64s/it] 27%|██▋       | 1226/4545 [1:18:50<3:25:26,  3.71s/it] 27%|██▋       | 1227/4545 [1:18:53<3:28:09,  3.76s/it] 27%|██▋       | 1228/4545 [1:18:57<3:33:00,  3.85s/it] 27%|██▋       | 1229/4545 [1:19:01<3:31:39,  3.83s/it] 27%|██▋       | 1230/4545 [1:19:05<3:26:37,  3.74s/it]                                                       {'loss': 0.2059, 'grad_norm': 22.975753784179688, 'learning_rate': 8.117569352708058e-07, 'rewards/chosen': 3.3765625953674316, 'rewards/rejected': -3.866406202316284, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 7.237500190734863, 'logps/chosen': -337.04998779296875, 'logps/rejected': -270.2749938964844, 'logits/chosen': -7.303124904632568, 'logits/rejected': -7.021874904632568, 'epoch': 0.81}
 27%|██▋       | 1230/4545 [1:19:05<3:26:37,  3.74s/it] 27%|██▋       | 1231/4545 [1:19:09<3:28:55,  3.78s/it] 27%|██▋       | 1232/4545 [1:19:13<3:30:47,  3.82s/it] 27%|██▋       | 1233/4545 [1:19:16<3:29:25,  3.79s/it] 27%|██▋       | 1234/4545 [1:19:20<3:35:23,  3.90s/it] 27%|██▋       | 1235/4545 [1:19:23<3:18:39,  3.60s/it] 27%|██▋       | 1236/4545 [1:19:27<3:23:21,  3.69s/it] 27%|██▋       | 1237/4545 [1:19:31<3:25:51,  3.73s/it] 27%|██▋       | 1238/4545 [1:19:35<3:28:15,  3.78s/it] 27%|██▋       | 1239/4545 [1:19:39<3:29:33,  3.80s/it] 27%|██▋       | 1240/4545 [1:19:43<3:30:57,  3.83s/it]                                                       {'loss': 0.2914, 'grad_norm': 43.20127868652344, 'learning_rate': 8.183619550858652e-07, 'rewards/chosen': 3.608593702316284, 'rewards/rejected': -3.9124999046325684, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 7.525000095367432, 'logps/chosen': -422.25, 'logps/rejected': -239.75, 'logits/chosen': -7.449999809265137, 'logits/rejected': -7.012499809265137, 'epoch': 0.82}
 27%|██▋       | 1240/4545 [1:19:43<3:30:57,  3.83s/it] 27%|██▋       | 1241/4545 [1:19:47<3:30:13,  3.82s/it] 27%|██▋       | 1242/4545 [1:19:50<3:32:17,  3.86s/it] 27%|██▋       | 1243/4545 [1:19:54<3:32:56,  3.87s/it] 27%|██▋       | 1244/4545 [1:19:59<3:37:49,  3.96s/it] 27%|██▋       | 1245/4545 [1:20:02<3:36:48,  3.94s/it] 27%|██▋       | 1246/4545 [1:20:06<3:35:49,  3.93s/it] 27%|██▋       | 1247/4545 [1:20:10<3:29:58,  3.82s/it] 27%|██▋       | 1248/4545 [1:20:14<3:31:11,  3.84s/it] 27%|██▋       | 1249/4545 [1:20:18<3:34:49,  3.91s/it] 28%|██▊       | 1250/4545 [1:20:22<3:33:46,  3.89s/it]                                                       {'loss': 0.2743, 'grad_norm': 37.522254943847656, 'learning_rate': 8.249669749009247e-07, 'rewards/chosen': 1.456787109375, 'rewards/rejected': -4.082812309265137, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 5.540625095367432, 'logps/chosen': -225.4499969482422, 'logps/rejected': -168.25, 'logits/chosen': -7.615624904632568, 'logits/rejected': -7.228125095367432, 'epoch': 0.83}
 28%|██▊       | 1250/4545 [1:20:22<3:33:46,  3.89s/it] 28%|██▊       | 1251/4545 [1:20:25<3:26:43,  3.77s/it] 28%|██▊       | 1252/4545 [1:20:29<3:21:47,  3.68s/it] 28%|██▊       | 1253/4545 [1:20:32<3:23:02,  3.70s/it] 28%|██▊       | 1254/4545 [1:20:36<3:24:44,  3.73s/it] 28%|██▊       | 1255/4545 [1:20:40<3:26:37,  3.77s/it] 28%|██▊       | 1256/4545 [1:20:44<3:27:42,  3.79s/it] 28%|██▊       | 1257/4545 [1:20:48<3:33:34,  3.90s/it] 28%|██▊       | 1258/4545 [1:20:52<3:38:53,  4.00s/it] 28%|██▊       | 1259/4545 [1:20:56<3:38:15,  3.99s/it] 28%|██▊       | 1260/4545 [1:20:59<3:12:11,  3.51s/it]                                                       {'loss': 0.3512, 'grad_norm': 39.215431213378906, 'learning_rate': 8.315719947159842e-07, 'rewards/chosen': 0.7039550542831421, 'rewards/rejected': -4.875, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.574999809265137, 'logps/chosen': -198.64999389648438, 'logps/rejected': -157.6999969482422, 'logits/chosen': -7.640625, 'logits/rejected': -7.293749809265137, 'epoch': 0.83}
 28%|██▊       | 1260/4545 [1:20:59<3:12:11,  3.51s/it] 28%|██▊       | 1261/4545 [1:21:03<3:19:11,  3.64s/it] 28%|██▊       | 1262/4545 [1:21:06<3:22:25,  3.70s/it] 28%|██▊       | 1263/4545 [1:21:10<3:17:09,  3.60s/it] 28%|██▊       | 1264/4545 [1:21:14<3:21:05,  3.68s/it] 28%|██▊       | 1265/4545 [1:21:17<3:22:44,  3.71s/it] 28%|██▊       | 1266/4545 [1:21:21<3:24:17,  3.74s/it] 28%|██▊       | 1267/4545 [1:21:24<3:09:22,  3.47s/it] 28%|██▊       | 1268/4545 [1:21:28<3:15:40,  3.58s/it] 28%|██▊       | 1269/4545 [1:21:32<3:16:11,  3.59s/it] 28%|██▊       | 1270/4545 [1:21:36<3:23:11,  3.72s/it]                                                       {'loss': 0.2779, 'grad_norm': 27.95047950744629, 'learning_rate': 8.381770145310435e-07, 'rewards/chosen': 2.0603270530700684, 'rewards/rejected': -3.590625047683716, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.653124809265137, 'logps/chosen': -296.1499938964844, 'logps/rejected': -151.0500030517578, 'logits/chosen': -7.453125, 'logits/rejected': -7.190625190734863, 'epoch': 0.84}
 28%|██▊       | 1270/4545 [1:21:36<3:23:11,  3.72s/it] 28%|██▊       | 1271/4545 [1:21:40<3:31:58,  3.88s/it] 28%|██▊       | 1272/4545 [1:21:43<3:16:16,  3.60s/it] 28%|██▊       | 1273/4545 [1:21:47<3:21:04,  3.69s/it] 28%|██▊       | 1274/4545 [1:21:51<3:24:19,  3.75s/it] 28%|██▊       | 1275/4545 [1:21:54<3:13:28,  3.55s/it] 28%|██▊       | 1276/4545 [1:21:57<3:04:27,  3.39s/it] 28%|██▊       | 1277/4545 [1:22:01<3:12:26,  3.53s/it] 28%|██▊       | 1278/4545 [1:22:05<3:21:32,  3.70s/it] 28%|██▊       | 1279/4545 [1:22:08<3:11:07,  3.51s/it] 28%|██▊       | 1280/4545 [1:22:12<3:17:33,  3.63s/it]                                                       {'loss': 0.2412, 'grad_norm': 24.741729736328125, 'learning_rate': 8.44782034346103e-07, 'rewards/chosen': 3.168164014816284, 'rewards/rejected': -4.038281440734863, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 7.207812309265137, 'logps/chosen': -343.45001220703125, 'logps/rejected': -200.0500030517578, 'logits/chosen': -7.309374809265137, 'logits/rejected': -7.084374904632568, 'epoch': 0.84}
 28%|██▊       | 1280/4545 [1:22:12<3:17:33,  3.63s/it] 28%|██▊       | 1281/4545 [1:22:15<3:19:01,  3.66s/it] 28%|██▊       | 1282/4545 [1:22:19<3:22:54,  3.73s/it] 28%|██▊       | 1283/4545 [1:22:22<3:10:03,  3.50s/it] 28%|██▊       | 1284/4545 [1:22:26<3:09:35,  3.49s/it] 28%|██▊       | 1285/4545 [1:22:29<3:14:11,  3.57s/it] 28%|██▊       | 1286/4545 [1:22:33<3:19:23,  3.67s/it] 28%|██▊       | 1287/4545 [1:22:37<3:22:53,  3.74s/it] 28%|██▊       | 1288/4545 [1:22:41<3:24:34,  3.77s/it] 28%|██▊       | 1289/4545 [1:22:45<3:26:27,  3.80s/it] 28%|██▊       | 1290/4545 [1:22:49<3:31:45,  3.90s/it]                                                       {'loss': 0.2524, 'grad_norm': 34.989349365234375, 'learning_rate': 8.513870541611624e-07, 'rewards/chosen': 3.0341796875, 'rewards/rejected': -8.185937881469727, 'rewards/accuracies': 0.875, 'rewards/margins': 11.234375, 'logps/chosen': -332.6499938964844, 'logps/rejected': -214.0, 'logits/chosen': -7.346875190734863, 'logits/rejected': -6.934374809265137, 'epoch': 0.85}
 28%|██▊       | 1290/4545 [1:22:49<3:31:45,  3.90s/it] 28%|██▊       | 1291/4545 [1:22:53<3:34:07,  3.95s/it] 28%|██▊       | 1292/4545 [1:22:57<3:26:49,  3.81s/it] 28%|██▊       | 1293/4545 [1:23:01<3:27:51,  3.83s/it] 28%|██▊       | 1294/4545 [1:23:05<3:30:25,  3.88s/it] 28%|██▊       | 1295/4545 [1:23:08<3:30:03,  3.88s/it] 29%|██▊       | 1296/4545 [1:23:12<3:19:44,  3.69s/it] 29%|██▊       | 1297/4545 [1:23:15<3:11:29,  3.54s/it] 29%|██▊       | 1298/4545 [1:23:19<3:15:40,  3.62s/it] 29%|██▊       | 1299/4545 [1:23:21<2:55:21,  3.24s/it] 29%|██▊       | 1300/4545 [1:23:25<3:10:46,  3.53s/it]                                                       {'loss': 0.3055, 'grad_norm': 34.75383758544922, 'learning_rate': 8.579920739762219e-07, 'rewards/chosen': 1.627197265625, 'rewards/rejected': -5.137499809265137, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 6.759375095367432, 'logps/chosen': -226.89999389648438, 'logps/rejected': -114.0250015258789, 'logits/chosen': -7.528124809265137, 'logits/rejected': -7.246874809265137, 'epoch': 0.86}
 29%|██▊       | 1300/4545 [1:23:25<3:10:46,  3.53s/it] 29%|██▊       | 1301/4545 [1:23:29<3:21:24,  3.73s/it] 29%|██▊       | 1302/4545 [1:23:33<3:23:57,  3.77s/it] 29%|██▊       | 1303/4545 [1:23:36<3:14:44,  3.60s/it] 29%|██▊       | 1304/4545 [1:23:40<3:19:32,  3.69s/it] 29%|██▊       | 1305/4545 [1:23:44<3:22:47,  3.76s/it] 29%|██▊       | 1306/4545 [1:23:48<3:22:29,  3.75s/it] 29%|██▉       | 1307/4545 [1:23:52<3:27:32,  3.85s/it] 29%|██▉       | 1308/4545 [1:23:55<3:07:02,  3.47s/it] 29%|██▉       | 1309/4545 [1:23:58<3:04:30,  3.42s/it] 29%|██▉       | 1310/4545 [1:24:01<2:55:02,  3.25s/it]                                                       {'loss': 0.2229, 'grad_norm': 30.550052642822266, 'learning_rate': 8.645970937912813e-07, 'rewards/chosen': 2.0826172828674316, 'rewards/rejected': -4.75, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 6.832812309265137, 'logps/chosen': -219.64999389648438, 'logps/rejected': -152.5500030517578, 'logits/chosen': -7.574999809265137, 'logits/rejected': -7.106249809265137, 'epoch': 0.86}
 29%|██▉       | 1310/4545 [1:24:01<2:55:02,  3.25s/it] 29%|██▉       | 1311/4545 [1:24:05<3:07:09,  3.47s/it] 29%|██▉       | 1312/4545 [1:24:09<3:11:26,  3.55s/it] 29%|██▉       | 1313/4545 [1:24:11<2:57:41,  3.30s/it] 29%|██▉       | 1314/4545 [1:24:15<3:08:14,  3.50s/it] 29%|██▉       | 1315/4545 [1:24:19<3:06:35,  3.47s/it] 29%|██▉       | 1316/4545 [1:24:22<3:08:52,  3.51s/it] 29%|██▉       | 1317/4545 [1:24:26<3:17:33,  3.67s/it] 29%|██▉       | 1318/4545 [1:24:30<3:23:19,  3.78s/it] 29%|██▉       | 1319/4545 [1:24:34<3:23:27,  3.78s/it] 29%|██▉       | 1320/4545 [1:24:38<3:18:24,  3.69s/it]                                                       {'loss': 0.3737, 'grad_norm': 26.128929138183594, 'learning_rate': 8.712021136063408e-07, 'rewards/chosen': 1.9939453601837158, 'rewards/rejected': -3.9703125953674316, 'rewards/accuracies': 0.875, 'rewards/margins': 5.967187404632568, 'logps/chosen': -235.75, 'logps/rejected': -164.10000610351562, 'logits/chosen': -7.474999904632568, 'logits/rejected': -7.125, 'epoch': 0.87}
 29%|██▉       | 1320/4545 [1:24:38<3:18:24,  3.69s/it] 29%|██▉       | 1321/4545 [1:24:41<3:22:31,  3.77s/it] 29%|██▉       | 1322/4545 [1:24:46<3:27:20,  3.86s/it] 29%|██▉       | 1323/4545 [1:24:49<3:18:34,  3.70s/it] 29%|██▉       | 1324/4545 [1:24:52<3:15:06,  3.63s/it] 29%|██▉       | 1325/4545 [1:24:56<3:14:09,  3.62s/it] 29%|██▉       | 1326/4545 [1:25:00<3:18:35,  3.70s/it] 29%|██▉       | 1327/4545 [1:25:03<3:12:02,  3.58s/it] 29%|██▉       | 1328/4545 [1:25:07<3:18:31,  3.70s/it] 29%|██▉       | 1329/4545 [1:25:11<3:21:25,  3.76s/it] 29%|██▉       | 1330/4545 [1:25:13<2:55:09,  3.27s/it]                                                       {'loss': 0.2609, 'grad_norm': 19.65089225769043, 'learning_rate': 8.778071334214002e-07, 'rewards/chosen': 1.3158782720565796, 'rewards/rejected': -3.2554688453674316, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 4.568749904632568, 'logps/chosen': -179.9499969482422, 'logps/rejected': -146.0500030517578, 'logits/chosen': -7.481249809265137, 'logits/rejected': -7.324999809265137, 'epoch': 0.88}
 29%|██▉       | 1330/4545 [1:25:13<2:55:09,  3.27s/it] 29%|██▉       | 1331/4545 [1:25:17<3:06:21,  3.48s/it] 29%|██▉       | 1332/4545 [1:25:21<3:14:01,  3.62s/it] 29%|██▉       | 1333/4545 [1:25:25<3:18:51,  3.71s/it] 29%|██▉       | 1334/4545 [1:25:29<3:21:19,  3.76s/it] 29%|██▉       | 1335/4545 [1:25:33<3:23:19,  3.80s/it] 29%|██▉       | 1336/4545 [1:25:37<3:24:49,  3.83s/it] 29%|██▉       | 1337/4545 [1:25:41<3:28:48,  3.91s/it] 29%|██▉       | 1338/4545 [1:25:44<3:23:17,  3.80s/it] 29%|██▉       | 1339/4545 [1:25:48<3:24:43,  3.83s/it] 29%|██▉       | 1340/4545 [1:25:52<3:25:52,  3.85s/it]                                                       {'loss': 0.2292, 'grad_norm': 42.121612548828125, 'learning_rate': 8.844121532364597e-07, 'rewards/chosen': 3.78826904296875, 'rewards/rejected': -5.1328125, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.909375190734863, 'logps/chosen': -395.70001220703125, 'logps/rejected': -222.39999389648438, 'logits/chosen': -7.171875, 'logits/rejected': -7.128125190734863, 'epoch': 0.88}
 29%|██▉       | 1340/4545 [1:25:52<3:25:52,  3.85s/it] 30%|██▉       | 1341/4545 [1:25:55<3:13:59,  3.63s/it] 30%|██▉       | 1342/4545 [1:25:58<3:05:34,  3.48s/it] 30%|██▉       | 1343/4545 [1:26:02<3:06:03,  3.49s/it] 30%|██▉       | 1344/4545 [1:26:06<3:15:34,  3.67s/it] 30%|██▉       | 1345/4545 [1:26:10<3:17:06,  3.70s/it] 30%|██▉       | 1346/4545 [1:26:14<3:22:25,  3.80s/it] 30%|██▉       | 1347/4545 [1:26:18<3:23:38,  3.82s/it] 30%|██▉       | 1348/4545 [1:26:22<3:24:55,  3.85s/it] 30%|██▉       | 1349/4545 [1:26:25<3:25:46,  3.86s/it] 30%|██▉       | 1350/4545 [1:26:29<3:25:41,  3.86s/it]                                                       {'loss': 0.336, 'grad_norm': 31.48981475830078, 'learning_rate': 8.910171730515191e-07, 'rewards/chosen': 3.7966065406799316, 'rewards/rejected': -3.3968749046325684, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 7.185937404632568, 'logps/chosen': -372.6000061035156, 'logps/rejected': -225.85000610351562, 'logits/chosen': -7.271874904632568, 'logits/rejected': -7.037499904632568, 'epoch': 0.89}
 30%|██▉       | 1350/4545 [1:26:29<3:25:41,  3.86s/it] 30%|██▉       | 1351/4545 [1:26:33<3:31:04,  3.97s/it] 30%|██▉       | 1352/4545 [1:26:36<3:07:06,  3.52s/it] 30%|██▉       | 1353/4545 [1:26:39<3:04:33,  3.47s/it] 30%|██▉       | 1354/4545 [1:26:44<3:17:40,  3.72s/it] 30%|██▉       | 1355/4545 [1:26:47<3:20:13,  3.77s/it] 30%|██▉       | 1356/4545 [1:26:51<3:18:41,  3.74s/it] 30%|██▉       | 1357/4545 [1:26:55<3:24:30,  3.85s/it] 30%|██▉       | 1358/4545 [1:26:59<3:16:32,  3.70s/it] 30%|██▉       | 1359/4545 [1:27:03<3:19:24,  3.76s/it] 30%|██▉       | 1360/4545 [1:27:07<3:23:09,  3.83s/it]                                                       {'loss': 0.2934, 'grad_norm': 19.548175811767578, 'learning_rate': 8.976221928665786e-07, 'rewards/chosen': 3.4749755859375, 'rewards/rejected': -3.982421875, 'rewards/accuracies': 0.875, 'rewards/margins': 7.456250190734863, 'logps/chosen': -351.54998779296875, 'logps/rejected': -213.89999389648438, 'logits/chosen': -7.268750190734863, 'logits/rejected': -7.015625, 'epoch': 0.9}
 30%|██▉       | 1360/4545 [1:27:07<3:23:09,  3.83s/it] 30%|██▉       | 1361/4545 [1:27:10<3:25:04,  3.86s/it] 30%|██▉       | 1362/4545 [1:27:13<3:02:40,  3.44s/it] 30%|██▉       | 1363/4545 [1:27:17<3:09:33,  3.57s/it] 30%|███       | 1364/4545 [1:27:21<3:18:04,  3.74s/it] 30%|███       | 1365/4545 [1:27:25<3:20:29,  3.78s/it] 30%|███       | 1366/4545 [1:27:29<3:23:53,  3.85s/it] 30%|███       | 1367/4545 [1:27:32<3:09:22,  3.58s/it] 30%|███       | 1368/4545 [1:27:35<3:10:57,  3.61s/it] 30%|███       | 1369/4545 [1:27:39<3:13:48,  3.66s/it] 30%|███       | 1370/4545 [1:27:43<3:16:54,  3.72s/it]                                                       {'loss': 0.2763, 'grad_norm': 31.514968872070312, 'learning_rate': 9.04227212681638e-07, 'rewards/chosen': 2.332080125808716, 'rewards/rejected': -3.923046827316284, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 6.256249904632568, 'logps/chosen': -219.9499969482422, 'logps/rejected': -140.39999389648438, 'logits/chosen': -7.490624904632568, 'logits/rejected': -7.103125095367432, 'epoch': 0.9}
 30%|███       | 1370/4545 [1:27:43<3:16:54,  3.72s/it] 30%|███       | 1371/4545 [1:27:47<3:20:10,  3.78s/it] 30%|███       | 1372/4545 [1:27:50<3:12:50,  3.65s/it] 30%|███       | 1373/4545 [1:27:54<3:20:50,  3.80s/it] 30%|███       | 1374/4545 [1:27:57<2:59:20,  3.39s/it] 30%|███       | 1375/4545 [1:28:01<3:07:35,  3.55s/it] 30%|███       | 1376/4545 [1:28:04<2:58:08,  3.37s/it] 30%|███       | 1377/4545 [1:28:07<2:55:37,  3.33s/it] 30%|███       | 1378/4545 [1:28:11<2:59:46,  3.41s/it] 30%|███       | 1379/4545 [1:28:14<3:07:07,  3.55s/it] 30%|███       | 1380/4545 [1:28:18<3:12:25,  3.65s/it]                                                       {'loss': 0.2129, 'grad_norm': 12.510041236877441, 'learning_rate': 9.108322324966975e-07, 'rewards/chosen': 3.145703077316284, 'rewards/rejected': -4.71875, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 7.862500190734863, 'logps/chosen': -273.17498779296875, 'logps/rejected': -134.39999389648438, 'logits/chosen': -7.400000095367432, 'logits/rejected': -7.046875, 'epoch': 0.91}
 30%|███       | 1380/4545 [1:28:19<3:12:25,  3.65s/it] 30%|███       | 1381/4545 [1:28:22<3:16:53,  3.73s/it] 30%|███       | 1382/4545 [1:28:26<3:14:23,  3.69s/it] 30%|███       | 1383/4545 [1:28:30<3:17:03,  3.74s/it] 30%|███       | 1384/4545 [1:28:34<3:19:42,  3.79s/it] 30%|███       | 1385/4545 [1:28:38<3:21:21,  3.82s/it] 30%|███       | 1386/4545 [1:28:42<3:25:52,  3.91s/it] 31%|███       | 1387/4545 [1:28:46<3:25:18,  3.90s/it] 31%|███       | 1388/4545 [1:28:49<3:23:25,  3.87s/it] 31%|███       | 1389/4545 [1:28:53<3:23:14,  3.86s/it] 31%|███       | 1390/4545 [1:28:57<3:23:27,  3.87s/it]                                                       {'loss': 0.2437, 'grad_norm': 28.42140769958496, 'learning_rate': 9.17437252311757e-07, 'rewards/chosen': 4.885937690734863, 'rewards/rejected': -3.663281202316284, 'rewards/accuracies': 0.875, 'rewards/margins': 8.548437118530273, 'logps/chosen': -446.25, 'logps/rejected': -264.04998779296875, 'logits/chosen': -7.190625190734863, 'logits/rejected': -6.925000190734863, 'epoch': 0.92}
 31%|███       | 1390/4545 [1:28:57<3:23:27,  3.87s/it] 31%|███       | 1391/4545 [1:29:01<3:24:56,  3.90s/it] 31%|███       | 1392/4545 [1:29:05<3:22:52,  3.86s/it] 31%|███       | 1393/4545 [1:29:09<3:23:26,  3.87s/it] 31%|███       | 1394/4545 [1:29:12<3:21:07,  3.83s/it] 31%|███       | 1395/4545 [1:29:16<3:20:29,  3.82s/it] 31%|███       | 1396/4545 [1:29:20<3:21:16,  3.83s/it] 31%|███       | 1397/4545 [1:29:24<3:22:26,  3.86s/it] 31%|███       | 1398/4545 [1:29:28<3:25:43,  3.92s/it] 31%|███       | 1399/4545 [1:29:32<3:21:41,  3.85s/it] 31%|███       | 1400/4545 [1:29:36<3:25:51,  3.93s/it]                                                       {'loss': 0.2663, 'grad_norm': 25.376853942871094, 'learning_rate': 9.240422721268163e-07, 'rewards/chosen': 1.9799072742462158, 'rewards/rejected': -5.174218654632568, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 7.159375190734863, 'logps/chosen': -230.85000610351562, 'logps/rejected': -136.8000030517578, 'logits/chosen': -7.581250190734863, 'logits/rejected': -7.181250095367432, 'epoch': 0.92}
 31%|███       | 1400/4545 [1:29:36<3:25:51,  3.93s/it] 31%|███       | 1401/4545 [1:29:39<3:20:46,  3.83s/it] 31%|███       | 1402/4545 [1:29:43<3:21:52,  3.85s/it] 31%|███       | 1403/4545 [1:29:47<3:16:06,  3.74s/it] 31%|███       | 1404/4545 [1:29:51<3:18:30,  3.79s/it] 31%|███       | 1405/4545 [1:29:55<3:20:05,  3.82s/it] 31%|███       | 1406/4545 [1:29:59<3:26:29,  3.95s/it] 31%|███       | 1407/4545 [1:30:03<3:21:52,  3.86s/it] 31%|███       | 1408/4545 [1:30:06<3:22:15,  3.87s/it] 31%|███       | 1409/4545 [1:30:10<3:15:51,  3.75s/it] 31%|███       | 1410/4545 [1:30:13<3:09:23,  3.62s/it]                                                       {'loss': 0.198, 'grad_norm': 27.679006576538086, 'learning_rate': 9.306472919418757e-07, 'rewards/chosen': 0.9515655636787415, 'rewards/rejected': -6.196875095367432, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 7.150000095367432, 'logps/chosen': -179.14999389648438, 'logps/rejected': -119.0999984741211, 'logits/chosen': -7.615624904632568, 'logits/rejected': -7.203125, 'epoch': 0.93}
 31%|███       | 1410/4545 [1:30:13<3:09:23,  3.62s/it] 31%|███       | 1411/4545 [1:30:17<3:04:50,  3.54s/it] 31%|███       | 1412/4545 [1:30:21<3:10:41,  3.65s/it] 31%|███       | 1413/4545 [1:30:24<3:07:28,  3.59s/it] 31%|███       | 1414/4545 [1:30:27<3:02:31,  3.50s/it] 31%|███       | 1415/4545 [1:30:31<3:08:35,  3.62s/it] 31%|███       | 1416/4545 [1:30:35<3:13:50,  3.72s/it] 31%|███       | 1417/4545 [1:30:38<3:07:43,  3.60s/it] 31%|███       | 1418/4545 [1:30:42<2:59:38,  3.45s/it] 31%|███       | 1419/4545 [1:30:45<3:07:01,  3.59s/it] 31%|███       | 1420/4545 [1:30:48<2:50:02,  3.26s/it]                                                       {'loss': 0.2684, 'grad_norm': 40.439361572265625, 'learning_rate': 9.372523117569352e-07, 'rewards/chosen': 1.8581116199493408, 'rewards/rejected': -4.2421875, 'rewards/accuracies': 0.875, 'rewards/margins': 6.106249809265137, 'logps/chosen': -229.25, 'logps/rejected': -162.5, 'logits/chosen': -7.625, 'logits/rejected': -7.168749809265137, 'epoch': 0.94}
 31%|███       | 1420/4545 [1:30:48<2:50:02,  3.26s/it] 31%|███▏      | 1421/4545 [1:30:52<3:00:34,  3.47s/it] 31%|███▏      | 1422/4545 [1:30:56<3:05:45,  3.57s/it] 31%|███▏      | 1423/4545 [1:30:59<3:06:34,  3.59s/it] 31%|███▏      | 1424/4545 [1:31:03<3:11:35,  3.68s/it] 31%|███▏      | 1425/4545 [1:31:06<3:02:55,  3.52s/it] 31%|███▏      | 1426/4545 [1:31:10<3:07:58,  3.62s/it] 31%|███▏      | 1427/4545 [1:31:14<3:10:53,  3.67s/it] 31%|███▏      | 1428/4545 [1:31:18<3:14:58,  3.75s/it] 31%|███▏      | 1429/4545 [1:31:21<3:00:12,  3.47s/it] 31%|███▏      | 1430/4545 [1:31:23<2:46:40,  3.21s/it]                                                       {'loss': 0.2994, 'grad_norm': 30.244844436645508, 'learning_rate': 9.438573315719947e-07, 'rewards/chosen': 1.885034203529358, 'rewards/rejected': -3.7630858421325684, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 5.645312309265137, 'logps/chosen': -201.97500610351562, 'logps/rejected': -175.9499969482422, 'logits/chosen': -7.590624809265137, 'logits/rejected': -7.15625, 'epoch': 0.94}
 31%|███▏      | 1430/4545 [1:31:23<2:46:40,  3.21s/it] 31%|███▏      | 1431/4545 [1:31:27<2:59:33,  3.46s/it] 32%|███▏      | 1432/4545 [1:31:31<3:06:22,  3.59s/it] 32%|███▏      | 1433/4545 [1:31:35<3:10:53,  3.68s/it] 32%|███▏      | 1434/4545 [1:31:39<3:14:09,  3.74s/it] 32%|███▏      | 1435/4545 [1:31:43<3:20:54,  3.88s/it] 32%|███▏      | 1436/4545 [1:31:47<3:21:00,  3.88s/it] 32%|███▏      | 1437/4545 [1:31:51<3:22:07,  3.90s/it] 32%|███▏      | 1438/4545 [1:31:55<3:19:50,  3.86s/it] 32%|███▏      | 1439/4545 [1:31:59<3:23:21,  3.93s/it] 32%|███▏      | 1440/4545 [1:32:02<3:04:53,  3.57s/it]                                                       {'loss': 0.3255, 'grad_norm': 40.14778137207031, 'learning_rate': 9.504623513870541e-07, 'rewards/chosen': 3.101855516433716, 'rewards/rejected': -3.202343702316284, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 6.303124904632568, 'logps/chosen': -281.1000061035156, 'logps/rejected': -165.25, 'logits/chosen': -7.487500190734863, 'logits/rejected': -7.259375095367432, 'epoch': 0.95}
 32%|███▏      | 1440/4545 [1:32:02<3:04:53,  3.57s/it] 32%|███▏      | 1441/4545 [1:32:05<3:03:41,  3.55s/it] 32%|███▏      | 1442/4545 [1:32:09<3:09:10,  3.66s/it] 32%|███▏      | 1443/4545 [1:32:13<3:13:52,  3.75s/it] 32%|███▏      | 1444/4545 [1:32:17<3:16:21,  3.80s/it] 32%|███▏      | 1445/4545 [1:32:20<3:11:22,  3.70s/it] 32%|███▏      | 1446/4545 [1:32:24<3:03:30,  3.55s/it] 32%|███▏      | 1447/4545 [1:32:26<2:38:47,  3.08s/it] 32%|███▏      | 1448/4545 [1:32:30<2:51:49,  3.33s/it] 32%|███▏      | 1449/4545 [1:32:33<2:48:02,  3.26s/it] 32%|███▏      | 1450/4545 [1:32:37<2:59:06,  3.47s/it]                                                       {'loss': 0.272, 'grad_norm': 7.471816539764404, 'learning_rate': 9.570673712021135e-07, 'rewards/chosen': 3.810009717941284, 'rewards/rejected': -3.547656297683716, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 7.360937595367432, 'logps/chosen': -296.8500061035156, 'logps/rejected': -199.5500030517578, 'logits/chosen': -7.396874904632568, 'logits/rejected': -7.074999809265137, 'epoch': 0.96}
 32%|███▏      | 1450/4545 [1:32:37<2:59:06,  3.47s/it] 32%|███▏      | 1451/4545 [1:32:39<2:42:50,  3.16s/it] 32%|███▏      | 1452/4545 [1:32:41<2:30:04,  2.91s/it] 32%|███▏      | 1453/4545 [1:32:45<2:34:01,  2.99s/it] 32%|███▏      | 1454/4545 [1:32:48<2:44:18,  3.19s/it] 32%|███▏      | 1455/4545 [1:32:52<2:55:52,  3.41s/it] 32%|███▏      | 1456/4545 [1:32:55<2:54:05,  3.38s/it] 32%|███▏      | 1457/4545 [1:32:59<3:01:55,  3.53s/it] 32%|███▏      | 1458/4545 [1:33:02<2:55:16,  3.41s/it] 32%|███▏      | 1459/4545 [1:33:06<3:02:35,  3.55s/it] 32%|███▏      | 1460/4545 [1:33:10<3:08:12,  3.66s/it]                                                       {'loss': 0.2984, 'grad_norm': 39.23434066772461, 'learning_rate': 9.63672391017173e-07, 'rewards/chosen': 2.818066358566284, 'rewards/rejected': -4.392187595367432, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 7.221875190734863, 'logps/chosen': -236.9250030517578, 'logps/rejected': -173.14999389648438, 'logits/chosen': -7.481249809265137, 'logits/rejected': -7.181250095367432, 'epoch': 0.96}
 32%|███▏      | 1460/4545 [1:33:10<3:08:12,  3.66s/it] 32%|███▏      | 1461/4545 [1:33:14<3:12:47,  3.75s/it] 32%|███▏      | 1462/4545 [1:33:18<3:08:39,  3.67s/it] 32%|███▏      | 1463/4545 [1:33:21<3:09:23,  3.69s/it] 32%|███▏      | 1464/4545 [1:33:25<3:12:09,  3.74s/it] 32%|███▏      | 1465/4545 [1:33:29<3:10:55,  3.72s/it] 32%|███▏      | 1466/4545 [1:33:33<3:10:10,  3.71s/it] 32%|███▏      | 1467/4545 [1:33:37<3:13:04,  3.76s/it] 32%|███▏      | 1468/4545 [1:33:41<3:19:41,  3.89s/it] 32%|███▏      | 1469/4545 [1:33:44<3:17:04,  3.84s/it] 32%|███▏      | 1470/4545 [1:33:48<3:17:51,  3.86s/it]                                                       {'loss': 0.3567, 'grad_norm': 24.129249572753906, 'learning_rate': 9.702774108322324e-07, 'rewards/chosen': 1.883691430091858, 'rewards/rejected': -4.196093559265137, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 6.077343940734863, 'logps/chosen': -200.85000610351562, 'logps/rejected': -154.0500030517578, 'logits/chosen': -7.546875, 'logits/rejected': -7.21875, 'epoch': 0.97}
 32%|███▏      | 1470/4545 [1:33:49<3:17:51,  3.86s/it] 32%|███▏      | 1471/4545 [1:33:52<3:18:56,  3.88s/it] 32%|███▏      | 1472/4545 [1:33:56<3:22:43,  3.96s/it] 32%|███▏      | 1473/4545 [1:34:00<3:14:14,  3.79s/it] 32%|███▏      | 1474/4545 [1:34:03<3:04:55,  3.61s/it] 32%|███▏      | 1475/4545 [1:34:07<3:03:19,  3.58s/it] 32%|███▏      | 1476/4545 [1:34:10<3:08:57,  3.69s/it] 32%|███▏      | 1477/4545 [1:34:14<3:13:07,  3.78s/it] 33%|███▎      | 1478/4545 [1:34:18<3:03:10,  3.58s/it] 33%|███▎      | 1479/4545 [1:34:22<3:08:03,  3.68s/it] 33%|███▎      | 1480/4545 [1:34:25<3:08:54,  3.70s/it]                                                       {'loss': 0.2943, 'grad_norm': 21.219255447387695, 'learning_rate': 9.76882430647292e-07, 'rewards/chosen': 4.54052734375, 'rewards/rejected': -4.016797065734863, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 8.556249618530273, 'logps/chosen': -372.6000061035156, 'logps/rejected': -203.6999969482422, 'logits/chosen': -7.534375190734863, 'logits/rejected': -7.287499904632568, 'epoch': 0.98}
 33%|███▎      | 1480/4545 [1:34:25<3:08:54,  3.70s/it] 33%|███▎      | 1481/4545 [1:34:29<3:12:35,  3.77s/it] 33%|███▎      | 1482/4545 [1:34:32<2:52:19,  3.38s/it] 33%|███▎      | 1483/4545 [1:34:36<3:00:19,  3.53s/it] 33%|███▎      | 1484/4545 [1:34:40<3:09:51,  3.72s/it] 33%|███▎      | 1485/4545 [1:34:44<3:12:57,  3.78s/it] 33%|███▎      | 1486/4545 [1:34:47<3:14:10,  3.81s/it] 33%|███▎      | 1487/4545 [1:34:51<3:12:27,  3.78s/it] 33%|███▎      | 1488/4545 [1:34:55<3:06:19,  3.66s/it] 33%|███▎      | 1489/4545 [1:34:59<3:11:43,  3.76s/it] 33%|███▎      | 1490/4545 [1:35:03<3:17:21,  3.88s/it]                                                       {'loss': 0.2846, 'grad_norm': 27.00374984741211, 'learning_rate': 9.834874504623514e-07, 'rewards/chosen': 3.438671827316284, 'rewards/rejected': -3.7281250953674316, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 7.167187690734863, 'logps/chosen': -283.1000061035156, 'logps/rejected': -156.3000030517578, 'logits/chosen': -7.387499809265137, 'logits/rejected': -7.106249809265137, 'epoch': 0.98}
 33%|███▎      | 1490/4545 [1:35:03<3:17:21,  3.88s/it] 33%|███▎      | 1491/4545 [1:35:07<3:18:59,  3.91s/it] 33%|███▎      | 1492/4545 [1:35:11<3:23:28,  4.00s/it] 33%|███▎      | 1493/4545 [1:35:14<3:02:03,  3.58s/it] 33%|███▎      | 1494/4545 [1:35:17<3:01:03,  3.56s/it] 33%|███▎      | 1495/4545 [1:35:21<3:05:18,  3.65s/it] 33%|███▎      | 1496/4545 [1:35:24<3:00:36,  3.55s/it] 33%|███▎      | 1497/4545 [1:35:28<3:05:20,  3.65s/it] 33%|███▎      | 1498/4545 [1:35:31<2:55:27,  3.45s/it] 33%|███▎      | 1499/4545 [1:35:35<3:06:38,  3.68s/it] 33%|███▎      | 1500/4545 [1:35:39<3:13:47,  3.82s/it]                                                       {'loss': 0.2419, 'grad_norm': 38.90285110473633, 'learning_rate': 9.900924702774108e-07, 'rewards/chosen': 2.0443787574768066, 'rewards/rejected': -5.675000190734863, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 7.715624809265137, 'logps/chosen': -222.89999389648438, 'logps/rejected': -129.1999969482422, 'logits/chosen': -7.603125095367432, 'logits/rejected': -7.203125, 'epoch': 0.99}
 33%|███▎      | 1500/4545 [1:35:40<3:13:47,  3.82s/it] 33%|███▎      | 1501/4545 [1:35:43<3:15:16,  3.85s/it] 33%|███▎      | 1502/4545 [1:35:47<3:15:46,  3.86s/it] 33%|███▎      | 1503/4545 [1:35:51<3:10:23,  3.76s/it] 33%|███▎      | 1504/4545 [1:35:55<3:12:43,  3.80s/it] 33%|███▎      | 1505/4545 [1:35:59<3:13:52,  3.83s/it] 33%|███▎      | 1506/4545 [1:36:02<3:12:46,  3.81s/it] 33%|███▎      | 1507/4545 [1:36:06<3:06:00,  3.67s/it] 33%|███▎      | 1508/4545 [1:36:09<2:54:40,  3.45s/it] 33%|███▎      | 1509/4545 [1:36:13<3:01:34,  3.59s/it] 33%|███▎      | 1510/4545 [1:36:17<3:09:40,  3.75s/it]                                                       {'loss': 0.2671, 'grad_norm': 27.408193588256836, 'learning_rate': 9.966974900924703e-07, 'rewards/chosen': 5.3447265625, 'rewards/rejected': -2.008593797683716, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 7.349999904632568, 'logps/chosen': -387.70001220703125, 'logps/rejected': -199.3000030517578, 'logits/chosen': -7.237500190734863, 'logits/rejected': -7.137499809265137, 'epoch': 1.0}
 33%|███▎      | 1510/4545 [1:36:17<3:09:40,  3.75s/it] 33%|███▎      | 1511/4545 [1:36:21<3:12:23,  3.80s/it] 33%|███▎      | 1512/4545 [1:36:24<3:13:13,  3.82s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:43,  1.32it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.63s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.62s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.52s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.10s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.26s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:26,  1.14s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.27s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.23s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.10s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.35s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.45s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.33s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.40s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.43s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.48s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.52s/it][A                                                       
                                               [A{'eval_loss': 0.38264715671539307, 'eval_runtime': 81.0522, 'eval_samples_per_second': 11.758, 'eval_steps_per_second': 0.74, 'eval_rewards/chosen': 3.9777159690856934, 'eval_rewards/rejected': -3.1737630367279053, 'eval_rewards/accuracies': 0.8300926089286804, 'eval_rewards/margins': 7.1484375, 'eval_logps/chosen': -357.67498779296875, 'eval_logps/rejected': -167.875, 'eval_logits/chosen': -7.201562404632568, 'eval_logits/rejected': -7.550520896911621, 'epoch': 1.0}
 33%|███▎      | 1512/4545 [1:37:46<3:13:13,  3.82s/it]
100%|██████████| 60/60 [01:19<00:00,  1.52s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 33%|███▎      | 1513/4545 [1:38:02<27:00:06, 32.06s/it] 33%|███▎      | 1514/4545 [1:38:07<19:57:15, 23.70s/it] 33%|███▎      | 1515/4545 [1:38:10<14:56:36, 17.75s/it] 33%|███▎      | 1516/4545 [1:38:14<11:26:12, 13.59s/it] 33%|███▎      | 1517/4545 [1:38:17<8:44:34, 10.39s/it]  33%|███▎      | 1518/4545 [1:38:21<7:02:39,  8.38s/it] 33%|███▎      | 1519/4545 [1:38:25<5:55:15,  7.04s/it] 33%|███▎      | 1520/4545 [1:38:29<5:09:49,  6.15s/it]                                                       {'loss': 0.2153, 'grad_norm': 45.53779602050781, 'learning_rate': 9.999939570440647e-07, 'rewards/chosen': 7.698974609375, 'rewards/rejected': -3.1064453125, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 10.810937881469727, 'logps/chosen': -565.4500122070312, 'logps/rejected': -211.39999389648438, 'logits/chosen': -7.084374904632568, 'logits/rejected': -7.012499809265137, 'epoch': 1.0}
 33%|███▎      | 1520/4545 [1:38:29<5:09:49,  6.15s/it] 33%|███▎      | 1521/4545 [1:38:33<4:39:19,  5.54s/it] 33%|███▎      | 1522/4545 [1:38:37<4:13:36,  5.03s/it] 34%|███▎      | 1523/4545 [1:38:41<3:57:24,  4.71s/it] 34%|███▎      | 1524/4545 [1:38:45<3:44:41,  4.46s/it] 34%|███▎      | 1525/4545 [1:38:49<3:36:17,  4.30s/it] 34%|███▎      | 1526/4545 [1:38:53<3:30:21,  4.18s/it] 34%|███▎      | 1527/4545 [1:38:56<3:15:46,  3.89s/it] 34%|███▎      | 1528/4545 [1:39:00<3:15:39,  3.89s/it] 34%|███▎      | 1529/4545 [1:39:03<3:07:30,  3.73s/it] 34%|███▎      | 1530/4545 [1:39:06<2:54:33,  3.47s/it]                                                       {'loss': 0.2343, 'grad_norm': 26.444108963012695, 'learning_rate': 9.999456143703726e-07, 'rewards/chosen': 5.954150199890137, 'rewards/rejected': -3.7890625, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 9.739062309265137, 'logps/chosen': -444.54998779296875, 'logps/rejected': -215.3000030517578, 'logits/chosen': -7.284375190734863, 'logits/rejected': -6.90625, 'epoch': 1.01}
 34%|███▎      | 1530/4545 [1:39:06<2:54:33,  3.47s/it] 34%|███▎      | 1531/4545 [1:39:10<3:03:52,  3.66s/it] 34%|███▎      | 1532/4545 [1:39:17<3:48:06,  4.54s/it] 34%|███▎      | 1533/4545 [1:39:21<3:43:06,  4.44s/it] 34%|███▍      | 1534/4545 [1:39:25<3:34:40,  4.28s/it] 34%|███▍      | 1535/4545 [1:39:28<3:13:22,  3.85s/it] 34%|███▍      | 1536/4545 [1:39:30<2:48:00,  3.35s/it] 34%|███▍      | 1537/4545 [1:39:34<2:58:19,  3.56s/it] 34%|███▍      | 1538/4545 [1:39:37<2:52:21,  3.44s/it] 34%|███▍      | 1539/4545 [1:39:41<2:54:20,  3.48s/it] 34%|███▍      | 1540/4545 [1:39:44<3:00:27,  3.60s/it]                                                       {'loss': 0.1649, 'grad_norm': 21.622528076171875, 'learning_rate': 9.99848934216423e-07, 'rewards/chosen': 2.8194000720977783, 'rewards/rejected': -5.872656345367432, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.6875, 'logps/chosen': -252.1750030517578, 'logps/rejected': -180.3000030517578, 'logits/chosen': -7.587500095367432, 'logits/rejected': -7.40625, 'epoch': 1.02}
 34%|███▍      | 1540/4545 [1:39:45<3:00:27,  3.60s/it] 34%|███▍      | 1541/4545 [1:39:48<3:05:51,  3.71s/it] 34%|███▍      | 1542/4545 [1:39:52<3:08:20,  3.76s/it] 34%|███▍      | 1543/4545 [1:39:56<3:02:39,  3.65s/it] 34%|███▍      | 1544/4545 [1:39:59<3:04:45,  3.69s/it] 34%|███▍      | 1545/4545 [1:40:03<3:07:40,  3.75s/it] 34%|███▍      | 1546/4545 [1:40:07<3:09:38,  3.79s/it] 34%|███▍      | 1547/4545 [1:40:11<3:11:02,  3.82s/it] 34%|███▍      | 1548/4545 [1:40:15<3:16:32,  3.93s/it] 34%|███▍      | 1549/4545 [1:40:19<3:13:49,  3.88s/it] 34%|███▍      | 1550/4545 [1:40:23<3:18:12,  3.97s/it]                                                       {'loss': 0.1587, 'grad_norm': 25.708032608032227, 'learning_rate': 9.99703926968527e-07, 'rewards/chosen': 4.044116020202637, 'rewards/rejected': -4.8359375, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.862500190734863, 'logps/chosen': -303.95001220703125, 'logps/rejected': -193.47500610351562, 'logits/chosen': -7.487500190734863, 'logits/rejected': -7.153124809265137, 'epoch': 1.02}
 34%|███▍      | 1550/4545 [1:40:23<3:18:12,  3.97s/it] 34%|███▍      | 1551/4545 [1:40:28<3:22:24,  4.06s/it] 34%|███▍      | 1552/4545 [1:40:31<3:12:41,  3.86s/it] 34%|███▍      | 1553/4545 [1:40:34<2:59:19,  3.60s/it] 34%|███▍      | 1554/4545 [1:40:38<3:05:18,  3.72s/it] 34%|███▍      | 1555/4545 [1:40:42<3:08:40,  3.79s/it] 34%|███▍      | 1556/4545 [1:40:46<3:09:27,  3.80s/it] 34%|███▍      | 1557/4545 [1:40:50<3:16:29,  3.95s/it] 34%|███▍      | 1558/4545 [1:40:52<2:48:28,  3.38s/it] 34%|███▍      | 1559/4545 [1:40:55<2:47:58,  3.38s/it] 34%|███▍      | 1560/4545 [1:40:59<2:53:23,  3.49s/it]                                                       {'loss': 0.1777, 'grad_norm': 16.31848907470703, 'learning_rate': 9.995106082047557e-07, 'rewards/chosen': 4.816992282867432, 'rewards/rejected': -5.1884765625, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.993749618530273, 'logps/chosen': -345.8500061035156, 'logps/rejected': -221.125, 'logits/chosen': -7.371874809265137, 'logits/rejected': -7.121874809265137, 'epoch': 1.03}
 34%|███▍      | 1560/4545 [1:40:59<2:53:23,  3.49s/it] 34%|███▍      | 1561/4545 [1:41:02<2:47:19,  3.36s/it] 34%|███▍      | 1562/4545 [1:41:06<2:59:45,  3.62s/it] 34%|███▍      | 1563/4545 [1:41:10<3:05:59,  3.74s/it] 34%|███▍      | 1564/4545 [1:41:13<2:48:55,  3.40s/it] 34%|███▍      | 1565/4545 [1:41:17<2:56:13,  3.55s/it] 34%|███▍      | 1566/4545 [1:41:21<3:01:35,  3.66s/it] 34%|███▍      | 1567/4545 [1:41:25<3:06:10,  3.75s/it] 34%|███▍      | 1568/4545 [1:41:29<3:09:32,  3.82s/it] 35%|███▍      | 1569/4545 [1:41:32<3:04:47,  3.73s/it] 35%|███▍      | 1570/4545 [1:41:35<2:52:29,  3.48s/it]                                                       {'loss': 0.2092, 'grad_norm': 38.97560119628906, 'learning_rate': 9.992689986932682e-07, 'rewards/chosen': 3.2757811546325684, 'rewards/rejected': -5.55859375, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 8.834375381469727, 'logps/chosen': -286.3500061035156, 'logps/rejected': -186.0, 'logits/chosen': -7.609375, 'logits/rejected': -7.215624809265137, 'epoch': 1.04}
 35%|███▍      | 1570/4545 [1:41:36<2:52:29,  3.48s/it] 35%|███▍      | 1571/4545 [1:41:39<2:57:03,  3.57s/it] 35%|███▍      | 1572/4545 [1:41:43<3:02:41,  3.69s/it] 35%|███▍      | 1573/4545 [1:41:47<3:08:08,  3.80s/it] 35%|███▍      | 1574/4545 [1:41:50<2:57:34,  3.59s/it] 35%|███▍      | 1575/4545 [1:41:53<2:51:53,  3.47s/it] 35%|███▍      | 1576/4545 [1:41:57<2:50:42,  3.45s/it] 35%|███▍      | 1577/4545 [1:42:00<2:45:04,  3.34s/it] 35%|███▍      | 1578/4545 [1:42:04<2:53:52,  3.52s/it] 35%|███▍      | 1579/4545 [1:42:07<2:50:51,  3.46s/it] 35%|███▍      | 1580/4545 [1:42:11<3:00:22,  3.65s/it]                                                       {'loss': 0.1192, 'grad_norm': 11.526875495910645, 'learning_rate': 9.98979124390079e-07, 'rewards/chosen': 1.5513184070587158, 'rewards/rejected': -7.060156345367432, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 8.612500190734863, 'logps/chosen': -184.60000610351562, 'logps/rejected': -128.75, 'logits/chosen': -7.915625095367432, 'logits/rejected': -7.453125, 'epoch': 1.04}
 35%|███▍      | 1580/4545 [1:42:11<3:00:22,  3.65s/it] 35%|███▍      | 1581/4545 [1:42:14<2:48:51,  3.42s/it] 35%|███▍      | 1582/4545 [1:42:18<2:52:13,  3.49s/it] 35%|███▍      | 1583/4545 [1:42:22<2:59:24,  3.63s/it] 35%|███▍      | 1584/4545 [1:42:26<3:06:58,  3.79s/it] 35%|███▍      | 1585/4545 [1:42:30<3:07:46,  3.81s/it] 35%|███▍      | 1586/4545 [1:42:32<2:43:19,  3.31s/it] 35%|███▍      | 1587/4545 [1:42:36<2:54:34,  3.54s/it] 35%|███▍      | 1588/4545 [1:42:40<3:03:47,  3.73s/it] 35%|███▍      | 1589/4545 [1:42:44<3:09:36,  3.85s/it] 35%|███▍      | 1590/4545 [1:42:48<3:04:08,  3.74s/it]                                                       {'loss': 0.1413, 'grad_norm': 15.75522232055664, 'learning_rate': 9.986410164362702e-07, 'rewards/chosen': 1.270751953125, 'rewards/rejected': -8.368749618530273, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 9.639062881469727, 'logps/chosen': -170.85000610351562, 'logps/rejected': -129.75, 'logits/chosen': -7.731249809265137, 'logits/rejected': -7.340624809265137, 'epoch': 1.05}
 35%|███▍      | 1590/4545 [1:42:48<3:04:08,  3.74s/it] 35%|███▌      | 1591/4545 [1:42:52<3:07:52,  3.82s/it] 35%|███▌      | 1592/4545 [1:42:55<2:59:10,  3.64s/it] 35%|███▌      | 1593/4545 [1:42:59<3:02:32,  3.71s/it] 35%|███▌      | 1594/4545 [1:43:02<2:53:08,  3.52s/it] 35%|███▌      | 1595/4545 [1:43:05<2:45:25,  3.36s/it] 35%|███▌      | 1596/4545 [1:43:09<2:55:14,  3.57s/it] 35%|███▌      | 1597/4545 [1:43:13<2:56:03,  3.58s/it] 35%|███▌      | 1598/4545 [1:43:16<3:00:25,  3.67s/it] 35%|███▌      | 1599/4545 [1:43:21<3:06:58,  3.81s/it] 35%|███▌      | 1600/4545 [1:43:25<3:12:42,  3.93s/it]                                                       {'loss': 0.2047, 'grad_norm': 10.471288681030273, 'learning_rate': 9.982547111546466e-07, 'rewards/chosen': 2.489086866378784, 'rewards/rejected': -7.453125, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 9.943750381469727, 'logps/chosen': -228.85000610351562, 'logps/rejected': -180.3000030517578, 'logits/chosen': -7.978125095367432, 'logits/rejected': -7.278124809265137, 'epoch': 1.06}
 35%|███▌      | 1600/4545 [1:43:25<3:12:42,  3.93s/it] 35%|███▌      | 1601/4545 [1:43:29<3:11:27,  3.90s/it] 35%|███▌      | 1602/4545 [1:43:32<3:10:43,  3.89s/it] 35%|███▌      | 1603/4545 [1:43:36<3:12:55,  3.93s/it] 35%|███▌      | 1604/4545 [1:43:41<3:16:44,  4.01s/it] 35%|███▌      | 1605/4545 [1:43:44<3:06:31,  3.81s/it] 35%|███▌      | 1606/4545 [1:43:48<3:09:31,  3.87s/it] 35%|███▌      | 1607/4545 [1:43:52<3:09:35,  3.87s/it] 35%|███▌      | 1608/4545 [1:43:56<3:09:11,  3.87s/it] 35%|███▌      | 1609/4545 [1:43:58<2:52:52,  3.53s/it] 35%|███▌      | 1610/4545 [1:44:02<2:49:01,  3.46s/it]                                                       {'loss': 0.1721, 'grad_norm': 53.806983947753906, 'learning_rate': 9.978202500458325e-07, 'rewards/chosen': 4.579687595367432, 'rewards/rejected': -5.862500190734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 10.4375, 'logps/chosen': -356.70001220703125, 'logps/rejected': -193.85000610351562, 'logits/chosen': -7.59375, 'logits/rejected': -7.300000190734863, 'epoch': 1.06}
 35%|███▌      | 1610/4545 [1:44:02<2:49:01,  3.46s/it] 35%|███▌      | 1611/4545 [1:44:06<2:58:06,  3.64s/it] 35%|███▌      | 1612/4545 [1:44:10<3:04:37,  3.78s/it] 35%|███▌      | 1613/4545 [1:44:13<3:00:56,  3.70s/it] 36%|███▌      | 1614/4545 [1:44:17<3:04:32,  3.78s/it] 36%|███▌      | 1615/4545 [1:44:21<3:06:16,  3.81s/it] 36%|███▌      | 1616/4545 [1:44:24<2:47:36,  3.43s/it] 36%|███▌      | 1617/4545 [1:44:28<2:54:18,  3.57s/it] 36%|███▌      | 1618/4545 [1:44:32<3:01:00,  3.71s/it] 36%|███▌      | 1619/4545 [1:44:35<3:00:28,  3.70s/it] 36%|███▌      | 1620/4545 [1:44:39<2:58:02,  3.65s/it]                                                       {'loss': 0.1774, 'grad_norm': 35.1639404296875, 'learning_rate': 9.973376797838135e-07, 'rewards/chosen': 4.240624904632568, 'rewards/rejected': -5.876562595367432, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 10.115625381469727, 'logps/chosen': -381.1000061035156, 'logps/rejected': -254.75, 'logits/chosen': -7.587500095367432, 'logits/rejected': -7.328125, 'epoch': 1.07}
 36%|███▌      | 1620/4545 [1:44:39<2:58:02,  3.65s/it] 36%|███▌      | 1621/4545 [1:44:43<3:06:10,  3.82s/it] 36%|███▌      | 1622/4545 [1:44:47<3:07:00,  3.84s/it] 36%|███▌      | 1623/4545 [1:44:51<3:02:43,  3.75s/it] 36%|███▌      | 1624/4545 [1:44:55<3:08:51,  3.88s/it] 36%|███▌      | 1625/4545 [1:44:59<3:09:57,  3.90s/it] 36%|███▌      | 1626/4545 [1:45:03<3:09:42,  3.90s/it] 36%|███▌      | 1627/4545 [1:45:06<3:04:16,  3.79s/it] 36%|███▌      | 1628/4545 [1:45:08<2:41:29,  3.32s/it] 36%|███▌      | 1629/4545 [1:45:12<2:49:46,  3.49s/it] 36%|███▌      | 1630/4545 [1:45:16<2:52:50,  3.56s/it]                                                       {'loss': 0.2483, 'grad_norm': 6.953137397766113, 'learning_rate': 9.968070522109234e-07, 'rewards/chosen': 1.6906249523162842, 'rewards/rejected': -8.496874809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 10.203125, 'logps/chosen': -236.60000610351562, 'logps/rejected': -142.6999969482422, 'logits/chosen': -7.881249904632568, 'logits/rejected': -7.556250095367432, 'epoch': 1.08}
 36%|███▌      | 1630/4545 [1:45:16<2:52:50,  3.56s/it] 36%|███▌      | 1631/4545 [1:45:19<2:47:04,  3.44s/it] 36%|███▌      | 1632/4545 [1:45:23<2:50:17,  3.51s/it] 36%|███▌      | 1633/4545 [1:45:27<2:53:51,  3.58s/it] 36%|███▌      | 1634/4545 [1:45:31<2:58:21,  3.68s/it] 36%|███▌      | 1635/4545 [1:45:34<3:00:53,  3.73s/it] 36%|███▌      | 1636/4545 [1:45:38<3:03:00,  3.77s/it] 36%|███▌      | 1637/4545 [1:45:42<3:07:43,  3.87s/it] 36%|███▌      | 1638/4545 [1:45:46<3:08:18,  3.89s/it] 36%|███▌      | 1639/4545 [1:45:50<3:03:24,  3.79s/it] 36%|███▌      | 1640/4545 [1:45:53<2:48:36,  3.48s/it]                                                       {'loss': 0.2171, 'grad_norm': 25.681865692138672, 'learning_rate': 9.962284243322729e-07, 'rewards/chosen': 2.04638671875, 'rewards/rejected': -7.009375095367432, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 9.065625190734863, 'logps/chosen': -242.60000610351562, 'logps/rejected': -177.14999389648438, 'logits/chosen': -7.6875, 'logits/rejected': -7.3125, 'epoch': 1.08}
 36%|███▌      | 1640/4545 [1:45:53<2:48:36,  3.48s/it] 36%|███▌      | 1641/4545 [1:45:56<2:42:33,  3.36s/it] 36%|███▌      | 1642/4545 [1:46:00<2:52:50,  3.57s/it] 36%|███▌      | 1643/4545 [1:46:03<2:44:48,  3.41s/it] 36%|███▌      | 1644/4545 [1:46:07<2:51:45,  3.55s/it] 36%|███▌      | 1645/4545 [1:46:10<2:53:20,  3.59s/it] 36%|███▌      | 1646/4545 [1:46:14<3:01:07,  3.75s/it] 36%|███▌      | 1647/4545 [1:46:18<3:01:21,  3.75s/it] 36%|███▋      | 1648/4545 [1:46:21<2:45:30,  3.43s/it] 36%|███▋      | 1649/4545 [1:46:25<2:49:17,  3.51s/it] 36%|███▋      | 1650/4545 [1:46:27<2:28:09,  3.07s/it]                                                       {'loss': 0.2241, 'grad_norm': 15.95190715789795, 'learning_rate': 9.956018583096278e-07, 'rewards/chosen': 1.329644799232483, 'rewards/rejected': -5.845312595367432, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.178124904632568, 'logps/chosen': -169.47500610351562, 'logps/rejected': -132.72500610351562, 'logits/chosen': -7.690625190734863, 'logits/rejected': -7.025000095367432, 'epoch': 1.09}
 36%|███▋      | 1650/4545 [1:46:27<2:28:09,  3.07s/it] 36%|███▋      | 1651/4545 [1:46:31<2:41:22,  3.35s/it] 36%|███▋      | 1652/4545 [1:46:35<2:51:29,  3.56s/it] 36%|███▋      | 1653/4545 [1:46:38<2:55:36,  3.64s/it] 36%|███▋      | 1654/4545 [1:46:42<2:52:37,  3.58s/it] 36%|███▋      | 1655/4545 [1:46:46<2:57:19,  3.68s/it] 36%|███▋      | 1656/4545 [1:46:49<2:54:41,  3.63s/it] 36%|███▋      | 1657/4545 [1:46:53<2:58:44,  3.71s/it] 36%|███▋      | 1658/4545 [1:46:57<3:01:14,  3.77s/it] 37%|███▋      | 1659/4545 [1:47:00<2:49:50,  3.53s/it] 37%|███▋      | 1660/4545 [1:47:04<2:56:50,  3.68s/it]                                                       {'loss': 0.2512, 'grad_norm': 48.22471237182617, 'learning_rate': 9.949274214547293e-07, 'rewards/chosen': 3.94677734375, 'rewards/rejected': -7.444140434265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 11.393750190734863, 'logps/chosen': -317.29998779296875, 'logps/rejected': -186.64999389648438, 'logits/chosen': -7.525000095367432, 'logits/rejected': -7.084374904632568, 'epoch': 1.1}
 37%|███▋      | 1660/4545 [1:47:04<2:56:50,  3.68s/it] 37%|███▋      | 1661/4545 [1:47:08<3:03:09,  3.81s/it] 37%|███▋      | 1662/4545 [1:47:12<3:03:42,  3.82s/it] 37%|███▋      | 1663/4545 [1:47:15<2:56:27,  3.67s/it] 37%|███▋      | 1664/4545 [1:47:19<3:01:11,  3.77s/it] 37%|███▋      | 1665/4545 [1:47:22<2:49:26,  3.53s/it] 37%|███▋      | 1666/4545 [1:47:26<2:55:07,  3.65s/it] 37%|███▋      | 1667/4545 [1:47:30<2:54:30,  3.64s/it] 37%|███▋      | 1668/4545 [1:47:33<2:52:32,  3.60s/it] 37%|███▋      | 1669/4545 [1:47:38<2:59:38,  3.75s/it] 37%|███▋      | 1670/4545 [1:47:41<3:02:00,  3.80s/it]                                                       {'loss': 0.1803, 'grad_norm': 20.080720901489258, 'learning_rate': 9.942051862220627e-07, 'rewards/chosen': 2.6005859375, 'rewards/rejected': -7.3984375, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 9.996874809265137, 'logps/chosen': -257.3999938964844, 'logps/rejected': -178.75, 'logits/chosen': -7.609375, 'logits/rejected': -7.121874809265137, 'epoch': 1.1}
 37%|███▋      | 1670/4545 [1:47:42<3:02:00,  3.80s/it] 37%|███▋      | 1671/4545 [1:47:46<3:05:09,  3.87s/it] 37%|███▋      | 1672/4545 [1:47:49<3:05:40,  3.88s/it] 37%|███▋      | 1673/4545 [1:47:54<3:10:36,  3.98s/it] 37%|███▋      | 1674/4545 [1:47:57<3:00:43,  3.78s/it] 37%|███▋      | 1675/4545 [1:48:01<3:02:17,  3.81s/it] 37%|███▋      | 1676/4545 [1:48:04<2:52:52,  3.62s/it] 37%|███▋      | 1677/4545 [1:48:08<2:53:58,  3.64s/it] 37%|███▋      | 1678/4545 [1:48:12<2:58:01,  3.73s/it] 37%|███▋      | 1679/4545 [1:48:16<3:00:42,  3.78s/it] 37%|███▋      | 1680/4545 [1:48:19<2:55:53,  3.68s/it]                                                       {'loss': 0.1968, 'grad_norm': 62.783164978027344, 'learning_rate': 9.934352302010752e-07, 'rewards/chosen': 2.940624952316284, 'rewards/rejected': -11.104687690734863, 'rewards/accuracies': 0.9375, 'rewards/margins': 14.040624618530273, 'logps/chosen': -312.6499938964844, 'logps/rejected': -175.14999389648438, 'logits/chosen': -7.503125190734863, 'logits/rejected': -7.184374809265137, 'epoch': 1.11}
 37%|███▋      | 1680/4545 [1:48:19<2:55:53,  3.68s/it] 37%|███▋      | 1681/4545 [1:48:23<2:55:24,  3.67s/it] 37%|███▋      | 1682/4545 [1:48:25<2:41:52,  3.39s/it] 37%|███▋      | 1683/4545 [1:48:29<2:38:13,  3.32s/it] 37%|███▋      | 1684/4545 [1:48:32<2:34:47,  3.25s/it] 37%|███▋      | 1685/4545 [1:48:36<2:46:00,  3.48s/it] 37%|███▋      | 1686/4545 [1:48:40<2:51:54,  3.61s/it] 37%|███▋      | 1687/4545 [1:48:43<2:55:59,  3.69s/it] 37%|███▋      | 1688/4545 [1:48:47<3:00:10,  3.78s/it] 37%|███▋      | 1689/4545 [1:48:51<3:01:49,  3.82s/it] 37%|███▋      | 1690/4545 [1:48:55<3:02:53,  3.84s/it]                                                       {'loss': 0.1979, 'grad_norm': 65.27462005615234, 'learning_rate': 9.926176361078394e-07, 'rewards/chosen': 2.986523389816284, 'rewards/rejected': -6.349023342132568, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.328125, 'logps/chosen': -274.70001220703125, 'logps/rejected': -183.75, 'logits/chosen': -7.578125, 'logits/rejected': -7.331250190734863, 'epoch': 1.12}
 37%|███▋      | 1690/4545 [1:48:56<3:02:53,  3.84s/it] 37%|███▋      | 1691/4545 [1:48:59<3:04:36,  3.88s/it] 37%|███▋      | 1692/4545 [1:49:03<3:05:05,  3.89s/it] 37%|███▋      | 1693/4545 [1:49:07<3:05:05,  3.89s/it] 37%|███▋      | 1694/4545 [1:49:10<2:56:24,  3.71s/it] 37%|███▋      | 1695/4545 [1:49:14<2:50:57,  3.60s/it] 37%|███▋      | 1696/4545 [1:49:17<2:54:27,  3.67s/it] 37%|███▋      | 1697/4545 [1:49:21<2:57:48,  3.75s/it] 37%|███▋      | 1698/4545 [1:49:25<2:59:53,  3.79s/it] 37%|███▋      | 1699/4545 [1:49:29<2:56:18,  3.72s/it] 37%|███▋      | 1700/4545 [1:49:33<3:02:11,  3.84s/it]                                                       {'loss': 0.2146, 'grad_norm': 13.469023704528809, 'learning_rate': 9.917524917761663e-07, 'rewards/chosen': 4.376611232757568, 'rewards/rejected': -5.917187690734863, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 10.293749809265137, 'logps/chosen': -343.1000061035156, 'logps/rejected': -208.39999389648438, 'logits/chosen': -7.409375190734863, 'logits/rejected': -7.178124904632568, 'epoch': 1.12}
 37%|███▋      | 1700/4545 [1:49:33<3:02:11,  3.84s/it] 37%|███▋      | 1701/4545 [1:49:37<3:01:45,  3.83s/it] 37%|███▋      | 1702/4545 [1:49:40<2:47:52,  3.54s/it] 37%|███▋      | 1703/4545 [1:49:44<2:52:49,  3.65s/it] 37%|███▋      | 1704/4545 [1:49:47<2:55:33,  3.71s/it] 38%|███▊      | 1705/4545 [1:49:51<2:58:09,  3.76s/it] 38%|███▊      | 1706/4545 [1:49:55<3:00:00,  3.80s/it] 38%|███▊      | 1707/4545 [1:49:59<3:01:09,  3.83s/it] 38%|███▊      | 1708/4545 [1:50:03<3:03:45,  3.89s/it] 38%|███▊      | 1709/4545 [1:50:07<3:01:01,  3.83s/it] 38%|███▊      | 1710/4545 [1:50:11<3:04:49,  3.91s/it]                                                       {'loss': 0.1402, 'grad_norm': 10.011984825134277, 'learning_rate': 9.908398901481712e-07, 'rewards/chosen': 4.6044921875, 'rewards/rejected': -6.510156154632568, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 11.110937118530273, 'logps/chosen': -366.95001220703125, 'logps/rejected': -255.0, 'logits/chosen': -7.496874809265137, 'logits/rejected': -7.059374809265137, 'epoch': 1.13}
 38%|███▊      | 1710/4545 [1:50:11<3:04:49,  3.91s/it] 38%|███▊      | 1711/4545 [1:50:14<2:48:35,  3.57s/it] 38%|███▊      | 1712/4545 [1:50:17<2:49:25,  3.59s/it] 38%|███▊      | 1713/4545 [1:50:21<2:57:36,  3.76s/it] 38%|███▊      | 1714/4545 [1:50:25<2:59:16,  3.80s/it] 38%|███▊      | 1715/4545 [1:50:30<3:04:42,  3.92s/it] 38%|███▊      | 1716/4545 [1:50:33<3:04:22,  3.91s/it] 38%|███▊      | 1717/4545 [1:50:37<2:57:38,  3.77s/it] 38%|███▊      | 1718/4545 [1:50:40<2:52:43,  3.67s/it] 38%|███▊      | 1719/4545 [1:50:44<2:46:32,  3.54s/it] 38%|███▊      | 1720/4545 [1:50:47<2:50:52,  3.63s/it]                                                       {'loss': 0.1664, 'grad_norm': 44.236175537109375, 'learning_rate': 9.898799292642878e-07, 'rewards/chosen': 2.0538697242736816, 'rewards/rejected': -7.464062690734863, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.521875381469727, 'logps/chosen': -205.39999389648438, 'logps/rejected': -156.10000610351562, 'logits/chosen': -7.806250095367432, 'logits/rejected': -7.321875095367432, 'epoch': 1.14}
 38%|███▊      | 1720/4545 [1:50:48<2:50:52,  3.63s/it] 38%|███▊      | 1721/4545 [1:50:52<3:00:55,  3.84s/it] 38%|███▊      | 1722/4545 [1:50:56<3:01:42,  3.86s/it] 38%|███▊      | 1723/4545 [1:51:00<3:02:24,  3.88s/it] 38%|███▊      | 1724/4545 [1:51:02<2:49:06,  3.60s/it] 38%|███▊      | 1725/4545 [1:51:06<2:52:50,  3.68s/it] 38%|███▊      | 1726/4545 [1:51:10<2:53:35,  3.69s/it] 38%|███▊      | 1727/4545 [1:51:13<2:47:00,  3.56s/it] 38%|███▊      | 1728/4545 [1:51:17<2:51:35,  3.65s/it] 38%|███▊      | 1729/4545 [1:51:21<2:55:21,  3.74s/it] 38%|███▊      | 1730/4545 [1:51:25<2:57:29,  3.78s/it]                                                       {'loss': 0.2104, 'grad_norm': 59.609046936035156, 'learning_rate': 9.88872712252736e-07, 'rewards/chosen': 5.010424613952637, 'rewards/rejected': -7.84765625, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 12.859375, 'logps/chosen': -382.8999938964844, 'logps/rejected': -234.0500030517578, 'logits/chosen': -7.681250095367432, 'logits/rejected': -7.137499809265137, 'epoch': 1.14}
 38%|███▊      | 1730/4545 [1:51:25<2:57:29,  3.78s/it] 38%|███▊      | 1731/4545 [1:51:29<2:55:54,  3.75s/it] 38%|███▊      | 1732/4545 [1:51:33<2:57:15,  3.78s/it] 38%|███▊      | 1733/4545 [1:51:36<2:58:40,  3.81s/it] 38%|███▊      | 1734/4545 [1:51:40<2:59:45,  3.84s/it] 38%|███▊      | 1735/4545 [1:51:44<3:00:29,  3.85s/it] 38%|███▊      | 1736/4545 [1:51:48<3:04:21,  3.94s/it] 38%|███▊      | 1737/4545 [1:51:52<3:03:39,  3.92s/it] 38%|███▊      | 1738/4545 [1:51:56<2:57:12,  3.79s/it] 38%|███▊      | 1739/4545 [1:51:59<2:44:35,  3.52s/it] 38%|███▊      | 1740/4545 [1:52:02<2:48:33,  3.61s/it]                                                       {'loss': 0.1932, 'grad_norm': 19.654977798461914, 'learning_rate': 9.878183473184434e-07, 'rewards/chosen': 3.252002000808716, 'rewards/rejected': -6.439062595367432, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.696874618530273, 'logps/chosen': -280.25, 'logps/rejected': -214.1999969482422, 'logits/chosen': -7.75, 'logits/rejected': -7.400000095367432, 'epoch': 1.15}
 38%|███▊      | 1740/4545 [1:52:03<2:48:33,  3.61s/it] 38%|███▊      | 1741/4545 [1:52:07<2:58:17,  3.82s/it] 38%|███▊      | 1742/4545 [1:52:09<2:39:08,  3.41s/it] 38%|███▊      | 1743/4545 [1:52:12<2:37:33,  3.37s/it] 38%|███▊      | 1744/4545 [1:52:15<2:26:13,  3.13s/it] 38%|███▊      | 1745/4545 [1:52:19<2:38:19,  3.39s/it] 38%|███▊      | 1746/4545 [1:52:23<2:42:25,  3.48s/it] 38%|███▊      | 1747/4545 [1:52:27<2:47:24,  3.59s/it] 38%|███▊      | 1748/4545 [1:52:30<2:50:58,  3.67s/it] 38%|███▊      | 1749/4545 [1:52:34<2:45:36,  3.55s/it] 39%|███▊      | 1750/4545 [1:52:37<2:40:19,  3.44s/it]                                                       {'loss': 0.1795, 'grad_norm': 22.749319076538086, 'learning_rate': 9.86716947731419e-07, 'rewards/chosen': 2.0622315406799316, 'rewards/rejected': -8.366406440734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 10.431249618530273, 'logps/chosen': -209.5749969482422, 'logps/rejected': -196.5500030517578, 'logits/chosen': -7.921875, 'logits/rejected': -7.393750190734863, 'epoch': 1.16}
 39%|███▊      | 1750/4545 [1:52:37<2:40:19,  3.44s/it] 39%|███▊      | 1751/4545 [1:52:40<2:34:02,  3.31s/it] 39%|███▊      | 1752/4545 [1:52:44<2:43:31,  3.51s/it] 39%|███▊      | 1753/4545 [1:52:48<2:49:27,  3.64s/it] 39%|███▊      | 1754/4545 [1:52:52<2:51:30,  3.69s/it] 39%|███▊      | 1755/4545 [1:52:56<2:57:29,  3.82s/it] 39%|███▊      | 1756/4545 [1:53:00<3:00:11,  3.88s/it] 39%|███▊      | 1757/4545 [1:53:03<2:54:50,  3.76s/it] 39%|███▊      | 1758/4545 [1:53:06<2:41:29,  3.48s/it] 39%|███▊      | 1759/4545 [1:53:09<2:40:55,  3.47s/it] 39%|███▊      | 1760/4545 [1:53:13<2:36:10,  3.36s/it]                                                       {'loss': 0.1851, 'grad_norm': 6.830183029174805, 'learning_rate': 9.855686318145875e-07, 'rewards/chosen': 1.72100830078125, 'rewards/rejected': -6.8828125, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.612500190734863, 'logps/chosen': -186.4499969482422, 'logps/rejected': -126.9000015258789, 'logits/chosen': -7.828125, 'logits/rejected': -7.340624809265137, 'epoch': 1.16}
 39%|███▊      | 1760/4545 [1:53:13<2:36:10,  3.36s/it] 39%|███▊      | 1761/4545 [1:53:16<2:43:05,  3.52s/it] 39%|███▉      | 1762/4545 [1:53:21<2:52:52,  3.73s/it] 39%|███▉      | 1763/4545 [1:53:25<2:55:43,  3.79s/it] 39%|███▉      | 1764/4545 [1:53:28<2:56:31,  3.81s/it] 39%|███▉      | 1765/4545 [1:53:32<2:48:49,  3.64s/it] 39%|███▉      | 1766/4545 [1:53:36<2:51:42,  3.71s/it] 39%|███▉      | 1767/4545 [1:53:39<2:47:22,  3.62s/it] 39%|███▉      | 1768/4545 [1:53:43<2:52:28,  3.73s/it] 39%|███▉      | 1769/4545 [1:53:47<2:55:18,  3.79s/it] 39%|███▉      | 1770/4545 [1:53:50<2:47:36,  3.62s/it]                                                       {'loss': 0.1914, 'grad_norm': 14.064172744750977, 'learning_rate': 9.84373522931076e-07, 'rewards/chosen': 2.873242139816284, 'rewards/rejected': -6.007031440734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.881250381469727, 'logps/chosen': -276.1499938964844, 'logps/rejected': -188.5, 'logits/chosen': -7.699999809265137, 'logits/rejected': -7.331250190734863, 'epoch': 1.17}
 39%|███▉      | 1770/4545 [1:53:50<2:47:36,  3.62s/it] 39%|███▉      | 1771/4545 [1:53:54<2:51:24,  3.71s/it] 39%|███▉      | 1772/4545 [1:53:58<2:49:29,  3.67s/it] 39%|███▉      | 1773/4545 [1:54:02<2:55:24,  3.80s/it] 39%|███▉      | 1774/4545 [1:54:06<2:57:29,  3.84s/it] 39%|███▉      | 1775/4545 [1:54:10<3:02:56,  3.96s/it] 39%|███▉      | 1776/4545 [1:54:14<3:01:50,  3.94s/it] 39%|███▉      | 1777/4545 [1:54:17<2:51:39,  3.72s/it] 39%|███▉      | 1778/4545 [1:54:21<2:57:47,  3.86s/it] 39%|███▉      | 1779/4545 [1:54:24<2:45:47,  3.60s/it] 39%|███▉      | 1780/4545 [1:54:28<2:50:25,  3.70s/it]                                                       {'loss': 0.2249, 'grad_norm': 41.06005096435547, 'learning_rate': 9.83131749470961e-07, 'rewards/chosen': 2.2900390625, 'rewards/rejected': -10.024999618530273, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 12.296875, 'logps/chosen': -241.4499969482422, 'logps/rejected': -187.0500030517578, 'logits/chosen': -7.703125, 'logits/rejected': -7.306250095367432, 'epoch': 1.17}
 39%|███▉      | 1780/4545 [1:54:28<2:50:25,  3.70s/it] 39%|███▉      | 1781/4545 [1:54:32<2:53:44,  3.77s/it] 39%|███▉      | 1782/4545 [1:54:36<2:55:31,  3.81s/it] 39%|███▉      | 1783/4545 [1:54:40<2:56:42,  3.84s/it] 39%|███▉      | 1784/4545 [1:54:44<2:57:34,  3.86s/it] 39%|███▉      | 1785/4545 [1:54:48<3:00:14,  3.92s/it] 39%|███▉      | 1786/4545 [1:54:52<2:59:57,  3.91s/it] 39%|███▉      | 1787/4545 [1:54:55<2:47:40,  3.65s/it] 39%|███▉      | 1788/4545 [1:54:59<2:55:37,  3.82s/it] 39%|███▉      | 1789/4545 [1:55:03<2:56:38,  3.85s/it] 39%|███▉      | 1790/4545 [1:55:07<3:00:04,  3.92s/it]                                                       {'loss': 0.2262, 'grad_norm': 22.084148406982422, 'learning_rate': 9.81843444837477e-07, 'rewards/chosen': 4.762158393859863, 'rewards/rejected': -6.642968654632568, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.403124809265137, 'logps/chosen': -356.8500061035156, 'logps/rejected': -215.3000030517578, 'logits/chosen': -7.615624904632568, 'logits/rejected': -7.259375095367432, 'epoch': 1.18}
 39%|███▉      | 1790/4545 [1:55:07<3:00:04,  3.92s/it] 39%|███▉      | 1791/4545 [1:55:11<3:02:47,  3.98s/it] 39%|███▉      | 1792/4545 [1:55:15<3:01:34,  3.96s/it] 39%|███▉      | 1793/4545 [1:55:19<3:04:29,  4.02s/it] 39%|███▉      | 1794/4545 [1:55:23<3:02:11,  3.97s/it] 39%|███▉      | 1795/4545 [1:55:27<2:59:49,  3.92s/it] 40%|███▉      | 1796/4545 [1:55:31<3:02:33,  3.98s/it] 40%|███▉      | 1797/4545 [1:55:35<3:01:22,  3.96s/it] 40%|███▉      | 1798/4545 [1:55:39<3:00:06,  3.93s/it] 40%|███▉      | 1799/4545 [1:55:43<2:58:55,  3.91s/it] 40%|███▉      | 1800/4545 [1:55:46<2:54:14,  3.81s/it]                                                       {'loss': 0.1923, 'grad_norm': 27.1151180267334, 'learning_rate': 9.805087474326835e-07, 'rewards/chosen': 2.3536620140075684, 'rewards/rejected': -8.324999809265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 10.684374809265137, 'logps/chosen': -293.54998779296875, 'logps/rejected': -197.75, 'logits/chosen': -7.668749809265137, 'logits/rejected': -7.068749904632568, 'epoch': 1.19}
 40%|███▉      | 1800/4545 [1:55:46<2:54:14,  3.81s/it] 40%|███▉      | 1801/4545 [1:55:50<2:56:02,  3.85s/it] 40%|███▉      | 1802/4545 [1:55:54<2:56:10,  3.85s/it] 40%|███▉      | 1803/4545 [1:55:58<2:58:28,  3.91s/it] 40%|███▉      | 1804/4545 [1:56:02<2:54:10,  3.81s/it] 40%|███▉      | 1805/4545 [1:56:06<2:57:21,  3.88s/it] 40%|███▉      | 1806/4545 [1:56:09<2:54:40,  3.83s/it] 40%|███▉      | 1807/4545 [1:56:13<2:46:59,  3.66s/it] 40%|███▉      | 1808/4545 [1:56:16<2:36:10,  3.42s/it] 40%|███▉      | 1809/4545 [1:56:20<2:44:38,  3.61s/it] 40%|███▉      | 1810/4545 [1:56:23<2:40:08,  3.51s/it]                                                       {'loss': 0.1578, 'grad_norm': 28.158220291137695, 'learning_rate': 9.791278006425974e-07, 'rewards/chosen': 1.6452147960662842, 'rewards/rejected': -8.204687118530273, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 9.845312118530273, 'logps/chosen': -214.5500030517578, 'logps/rejected': -155.6999969482422, 'logits/chosen': -7.853125095367432, 'logits/rejected': -7.484375, 'epoch': 1.19}
 40%|███▉      | 1810/4545 [1:56:23<2:40:08,  3.51s/it] 40%|███▉      | 1811/4545 [1:56:27<2:44:55,  3.62s/it] 40%|███▉      | 1812/4545 [1:56:31<2:48:37,  3.70s/it] 40%|███▉      | 1813/4545 [1:56:34<2:51:09,  3.76s/it] 40%|███▉      | 1814/4545 [1:56:38<2:53:54,  3.82s/it] 40%|███▉      | 1815/4545 [1:56:42<2:56:00,  3.87s/it] 40%|███▉      | 1816/4545 [1:56:46<2:56:21,  3.88s/it] 40%|███▉      | 1817/4545 [1:56:50<2:59:23,  3.95s/it] 40%|████      | 1818/4545 [1:56:54<2:55:30,  3.86s/it] 40%|████      | 1819/4545 [1:56:58<3:00:14,  3.97s/it] 40%|████      | 1820/4545 [1:57:02<2:58:34,  3.93s/it]                                                       {'loss': 0.191, 'grad_norm': 20.44403076171875, 'learning_rate': 9.777007528217888e-07, 'rewards/chosen': 5.56658935546875, 'rewards/rejected': -8.528124809265137, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 14.09375, 'logps/chosen': -438.3999938964844, 'logps/rejected': -274.1499938964844, 'logits/chosen': -7.484375, 'logits/rejected': -7.137499809265137, 'epoch': 1.2}
 40%|████      | 1820/4545 [1:57:02<2:58:34,  3.93s/it] 40%|████      | 1821/4545 [1:57:06<2:58:54,  3.94s/it] 40%|████      | 1822/4545 [1:57:10<2:59:19,  3.95s/it] 40%|████      | 1823/4545 [1:57:14<2:57:46,  3.92s/it] 40%|████      | 1824/4545 [1:57:17<2:46:31,  3.67s/it] 40%|████      | 1825/4545 [1:57:21<2:49:22,  3.74s/it] 40%|████      | 1826/4545 [1:57:24<2:35:55,  3.44s/it] 40%|████      | 1827/4545 [1:57:28<2:45:56,  3.66s/it] 40%|████      | 1828/4545 [1:57:32<2:53:28,  3.83s/it] 40%|████      | 1829/4545 [1:57:35<2:46:20,  3.67s/it] 40%|████      | 1830/4545 [1:57:38<2:30:25,  3.32s/it]                                                       {'loss': 0.19, 'grad_norm': 27.330114364624023, 'learning_rate': 9.762277572774434e-07, 'rewards/chosen': 2.825732469558716, 'rewards/rejected': -5.465624809265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.290624618530273, 'logps/chosen': -267.54998779296875, 'logps/rejected': -195.10000610351562, 'logits/chosen': -7.596875190734863, 'logits/rejected': -7.375, 'epoch': 1.21}
 40%|████      | 1830/4545 [1:57:38<2:30:25,  3.32s/it] 40%|████      | 1831/4545 [1:57:42<2:38:01,  3.49s/it] 40%|████      | 1832/4545 [1:57:46<2:47:50,  3.71s/it] 40%|████      | 1833/4545 [1:57:50<2:48:39,  3.73s/it] 40%|████      | 1834/4545 [1:57:54<2:48:36,  3.73s/it] 40%|████      | 1835/4545 [1:57:57<2:39:59,  3.54s/it] 40%|████      | 1836/4545 [1:58:00<2:43:58,  3.63s/it] 40%|████      | 1837/4545 [1:58:05<2:50:03,  3.77s/it] 40%|████      | 1838/4545 [1:58:08<2:45:52,  3.68s/it] 40%|████      | 1839/4545 [1:58:10<2:26:57,  3.26s/it] 40%|████      | 1840/4545 [1:58:15<2:39:44,  3.54s/it]                                                       {'loss': 0.2306, 'grad_norm': 17.943344116210938, 'learning_rate': 9.74708972252893e-07, 'rewards/chosen': 1.623632788658142, 'rewards/rejected': -8.110937118530273, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.71875, 'logps/chosen': -218.1999969482422, 'logps/rejected': -165.39999389648438, 'logits/chosen': -7.690625190734863, 'logits/rejected': -7.212500095367432, 'epoch': 1.21}
 40%|████      | 1840/4545 [1:58:15<2:39:44,  3.54s/it] 41%|████      | 1841/4545 [1:58:19<2:47:05,  3.71s/it] 41%|████      | 1842/4545 [1:58:22<2:49:32,  3.76s/it] 41%|████      | 1843/4545 [1:58:26<2:51:06,  3.80s/it] 41%|████      | 1844/4545 [1:58:29<2:38:03,  3.51s/it] 41%|████      | 1845/4545 [1:58:33<2:39:55,  3.55s/it] 41%|████      | 1846/4545 [1:58:35<2:26:54,  3.27s/it] 41%|████      | 1847/4545 [1:58:39<2:35:32,  3.46s/it] 41%|████      | 1848/4545 [1:58:43<2:43:23,  3.64s/it] 41%|████      | 1849/4545 [1:58:47<2:46:47,  3.71s/it] 41%|████      | 1850/4545 [1:58:51<2:48:15,  3.75s/it]                                                       {'loss': 0.165, 'grad_norm': 43.927059173583984, 'learning_rate': 9.731445609106147e-07, 'rewards/chosen': 3.723828077316284, 'rewards/rejected': -6.2890625, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 10.015625, 'logps/chosen': -315.3999938964844, 'logps/rejected': -207.4499969482422, 'logits/chosen': -7.696875095367432, 'logits/rejected': -7.309374809265137, 'epoch': 1.22}
 41%|████      | 1850/4545 [1:58:51<2:48:15,  3.75s/it] 41%|████      | 1851/4545 [1:58:55<2:51:06,  3.81s/it] 41%|████      | 1852/4545 [1:58:59<2:48:27,  3.75s/it] 41%|████      | 1853/4545 [1:59:03<2:49:43,  3.78s/it] 41%|████      | 1854/4545 [1:59:07<2:52:25,  3.84s/it] 41%|████      | 1855/4545 [1:59:10<2:53:15,  3.86s/it] 41%|████      | 1856/4545 [1:59:14<2:53:03,  3.86s/it] 41%|████      | 1857/4545 [1:59:18<2:53:19,  3.87s/it] 41%|████      | 1858/4545 [1:59:22<2:54:30,  3.90s/it] 41%|████      | 1859/4545 [1:59:25<2:40:52,  3.59s/it] 41%|████      | 1860/4545 [1:59:29<2:44:55,  3.69s/it]                                                       {'loss': 0.2178, 'grad_norm': 39.51692581176758, 'learning_rate': 9.715346913147035e-07, 'rewards/chosen': 4.599609375, 'rewards/rejected': -7.724999904632568, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 12.331250190734863, 'logps/chosen': -394.75, 'logps/rejected': -270.1000061035156, 'logits/chosen': -7.4375, 'logits/rejected': -7.196875095367432, 'epoch': 1.23}
 41%|████      | 1860/4545 [1:59:29<2:44:55,  3.69s/it] 41%|████      | 1861/4545 [1:59:33<2:47:49,  3.75s/it] 41%|████      | 1862/4545 [1:59:37<2:49:40,  3.79s/it] 41%|████      | 1863/4545 [1:59:40<2:46:38,  3.73s/it] 41%|████      | 1864/4545 [1:59:44<2:48:45,  3.78s/it] 41%|████      | 1865/4545 [1:59:48<2:54:40,  3.91s/it] 41%|████      | 1866/4545 [1:59:52<2:54:27,  3.91s/it] 41%|████      | 1867/4545 [1:59:56<2:44:31,  3.69s/it] 41%|████      | 1868/4545 [1:59:59<2:47:09,  3.75s/it] 41%|████      | 1869/4545 [2:00:03<2:48:56,  3.79s/it] 41%|████      | 1870/4545 [2:00:07<2:50:17,  3.82s/it]                                                       {'loss': 0.1595, 'grad_norm': 17.77254295349121, 'learning_rate': 9.698795364128162e-07, 'rewards/chosen': 5.163964748382568, 'rewards/rejected': -6.364062309265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 11.515625, 'logps/chosen': -376.3999938964844, 'logps/rejected': -238.60000610351562, 'logits/chosen': -7.612500190734863, 'logits/rejected': -7.3125, 'epoch': 1.23}
 41%|████      | 1870/4545 [2:00:07<2:50:17,  3.82s/it] 41%|████      | 1871/4545 [2:00:11<2:53:02,  3.88s/it] 41%|████      | 1872/4545 [2:00:15<2:49:08,  3.80s/it] 41%|████      | 1873/4545 [2:00:17<2:30:03,  3.37s/it] 41%|████      | 1874/4545 [2:00:21<2:40:19,  3.60s/it] 41%|████▏     | 1875/4545 [2:00:25<2:41:47,  3.64s/it] 41%|████▏     | 1876/4545 [2:00:28<2:29:32,  3.36s/it] 41%|████▏     | 1877/4545 [2:00:32<2:36:18,  3.52s/it] 41%|████▏     | 1878/4545 [2:00:36<2:41:17,  3.63s/it] 41%|████▏     | 1879/4545 [2:00:39<2:41:11,  3.63s/it] 41%|████▏     | 1880/4545 [2:00:43<2:44:40,  3.71s/it]                                                       {'loss': 0.2634, 'grad_norm': 26.92953872680664, 'learning_rate': 9.681792740175928e-07, 'rewards/chosen': 1.6612151861190796, 'rewards/rejected': -8.746874809265137, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 10.404687881469727, 'logps/chosen': -218.4250030517578, 'logps/rejected': -122.19999694824219, 'logits/chosen': -8.009374618530273, 'logits/rejected': -7.565625190734863, 'epoch': 1.24}
 41%|████▏     | 1880/4545 [2:00:43<2:44:40,  3.71s/it] 41%|████▏     | 1881/4545 [2:00:46<2:36:41,  3.53s/it] 41%|████▏     | 1882/4545 [2:00:50<2:43:34,  3.69s/it] 41%|████▏     | 1883/4545 [2:00:53<2:38:16,  3.57s/it] 41%|████▏     | 1884/4545 [2:00:57<2:42:29,  3.66s/it] 41%|████▏     | 1885/4545 [2:01:01<2:48:04,  3.79s/it] 41%|████▏     | 1886/4545 [2:01:05<2:49:42,  3.83s/it] 42%|████▏     | 1887/4545 [2:01:09<2:50:03,  3.84s/it] 42%|████▏     | 1888/4545 [2:01:13<2:45:00,  3.73s/it] 42%|████▏     | 1889/4545 [2:01:16<2:44:23,  3.71s/it] 42%|████▏     | 1890/4545 [2:01:19<2:32:04,  3.44s/it]                                                       {'loss': 0.2148, 'grad_norm': 18.420183181762695, 'learning_rate': 9.66434086787553e-07, 'rewards/chosen': 2.2074217796325684, 'rewards/rejected': -7.315039157867432, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 9.528124809265137, 'logps/chosen': -231.6999969482422, 'logps/rejected': -210.75, 'logits/chosen': -7.990624904632568, 'logits/rejected': -7.525000095367432, 'epoch': 1.25}
 42%|████▏     | 1890/4545 [2:01:19<2:32:04,  3.44s/it] 42%|████▏     | 1891/4545 [2:01:23<2:41:18,  3.65s/it] 42%|████▏     | 1892/4545 [2:01:27<2:44:43,  3.73s/it] 42%|████▏     | 1893/4545 [2:01:31<2:46:50,  3.77s/it] 42%|████▏     | 1894/4545 [2:01:35<2:42:50,  3.69s/it] 42%|████▏     | 1895/4545 [2:01:38<2:38:22,  3.59s/it] 42%|████▏     | 1896/4545 [2:01:42<2:44:39,  3.73s/it] 42%|████▏     | 1897/4545 [2:01:44<2:27:07,  3.33s/it] 42%|████▏     | 1898/4545 [2:01:48<2:35:27,  3.52s/it] 42%|████▏     | 1899/4545 [2:01:52<2:40:32,  3.64s/it] 42%|████▏     | 1900/4545 [2:01:56<2:43:53,  3.72s/it]                                                       {'loss': 0.1586, 'grad_norm': 16.838790893554688, 'learning_rate': 9.64644162207474e-07, 'rewards/chosen': 5.074804782867432, 'rewards/rejected': -6.478125095367432, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 11.546875, 'logps/chosen': -394.29998779296875, 'logps/rejected': -270.04998779296875, 'logits/chosen': -7.665625095367432, 'logits/rejected': -7.359375, 'epoch': 1.25}
 42%|████▏     | 1900/4545 [2:01:56<2:43:53,  3.72s/it] 42%|████▏     | 1901/4545 [2:02:00<2:49:10,  3.84s/it] 42%|████▏     | 1902/4545 [2:02:04<2:53:13,  3.93s/it] 42%|████▏     | 1903/4545 [2:02:09<2:54:46,  3.97s/it] 42%|████▏     | 1904/4545 [2:02:12<2:50:25,  3.87s/it] 42%|████▏     | 1905/4545 [2:02:16<2:52:39,  3.92s/it] 42%|████▏     | 1906/4545 [2:02:20<2:51:52,  3.91s/it] 42%|████▏     | 1907/4545 [2:02:24<2:46:04,  3.78s/it] 42%|████▏     | 1908/4545 [2:02:28<2:51:03,  3.89s/it] 42%|████▏     | 1909/4545 [2:02:32<2:51:05,  3.89s/it] 42%|████▏     | 1910/4545 [2:02:36<2:51:31,  3.91s/it]                                                       {'loss': 0.1722, 'grad_norm': 40.46992492675781, 'learning_rate': 9.628096925682491e-07, 'rewards/chosen': 3.0774872303009033, 'rewards/rejected': -9.510937690734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 12.600000381469727, 'logps/chosen': -323.6000061035156, 'logps/rejected': -207.0, 'logits/chosen': -7.9375, 'logits/rejected': -7.290625095367432, 'epoch': 1.26}
 42%|████▏     | 1910/4545 [2:02:36<2:51:31,  3.91s/it] 42%|████▏     | 1911/4545 [2:02:40<2:53:07,  3.94s/it] 42%|████▏     | 1912/4545 [2:02:43<2:45:35,  3.77s/it] 42%|████▏     | 1913/4545 [2:02:47<2:47:04,  3.81s/it] 42%|████▏     | 1914/4545 [2:02:51<2:48:13,  3.84s/it] 42%|████▏     | 1915/4545 [2:02:55<2:48:20,  3.84s/it] 42%|████▏     | 1916/4545 [2:02:58<2:46:49,  3.81s/it] 42%|████▏     | 1917/4545 [2:03:02<2:48:01,  3.84s/it] 42%|████▏     | 1918/4545 [2:03:06<2:49:38,  3.87s/it] 42%|████▏     | 1919/4545 [2:03:09<2:39:50,  3.65s/it] 42%|████▏     | 1920/4545 [2:03:13<2:42:58,  3.73s/it]                                                       {'loss': 0.1625, 'grad_norm': 36.5245246887207, 'learning_rate': 9.609308749462294e-07, 'rewards/chosen': 3.418652296066284, 'rewards/rejected': -8.387499809265137, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 11.795312881469727, 'logps/chosen': -309.45001220703125, 'logps/rejected': -223.5, 'logits/chosen': -7.84375, 'logits/rejected': -7.456250190734863, 'epoch': 1.27}
 42%|████▏     | 1920/4545 [2:03:13<2:42:58,  3.73s/it] 42%|████▏     | 1921/4545 [2:03:18<2:50:11,  3.89s/it] 42%|████▏     | 1922/4545 [2:03:21<2:48:23,  3.85s/it] 42%|████▏     | 1923/4545 [2:03:25<2:47:18,  3.83s/it] 42%|████▏     | 1924/4545 [2:03:29<2:51:06,  3.92s/it] 42%|████▏     | 1925/4545 [2:03:33<2:50:45,  3.91s/it] 42%|████▏     | 1926/4545 [2:03:37<2:48:15,  3.85s/it] 42%|████▏     | 1927/4545 [2:03:40<2:43:34,  3.75s/it] 42%|████▏     | 1928/4545 [2:03:44<2:37:37,  3.61s/it] 42%|████▏     | 1929/4545 [2:03:47<2:41:10,  3.70s/it] 42%|████▏     | 1930/4545 [2:03:51<2:32:37,  3.50s/it]                                                       {'loss': 0.2567, 'grad_norm': 16.326274871826172, 'learning_rate': 9.590079111820526e-07, 'rewards/chosen': 0.759692370891571, 'rewards/rejected': -9.383837699890137, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 10.146875381469727, 'logps/chosen': -187.89999389648438, 'logps/rejected': -156.1999969482422, 'logits/chosen': -7.953125, 'logits/rejected': -7.471875190734863, 'epoch': 1.27}
 42%|████▏     | 1930/4545 [2:03:51<2:32:37,  3.50s/it] 42%|████▏     | 1931/4545 [2:03:54<2:33:29,  3.52s/it] 43%|████▎     | 1932/4545 [2:03:58<2:38:43,  3.64s/it] 43%|████▎     | 1933/4545 [2:04:01<2:26:28,  3.36s/it] 43%|████▎     | 1934/4545 [2:04:05<2:34:48,  3.56s/it] 43%|████▎     | 1935/4545 [2:04:09<2:39:14,  3.66s/it] 43%|████▎     | 1936/4545 [2:04:12<2:41:37,  3.72s/it] 43%|████▎     | 1937/4545 [2:04:16<2:42:40,  3.74s/it] 43%|████▎     | 1938/4545 [2:04:20<2:44:24,  3.78s/it] 43%|████▎     | 1939/4545 [2:04:24<2:47:49,  3.86s/it] 43%|████▎     | 1940/4545 [2:04:28<2:47:38,  3.86s/it]                                                       {'loss': 0.1525, 'grad_norm': 17.327367782592773, 'learning_rate': 9.570410078589593e-07, 'rewards/chosen': 3.118945360183716, 'rewards/rejected': -15.628125190734863, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 18.721874237060547, 'logps/chosen': -288.04998779296875, 'logps/rejected': -255.14999389648438, 'logits/chosen': -7.875, 'logits/rejected': -7.3125, 'epoch': 1.28}
 43%|████▎     | 1940/4545 [2:04:28<2:47:38,  3.86s/it] 43%|████▎     | 1941/4545 [2:04:32<2:53:08,  3.99s/it] 43%|████▎     | 1942/4545 [2:04:36<2:51:58,  3.96s/it] 43%|████▎     | 1943/4545 [2:04:40<2:51:20,  3.95s/it] 43%|████▎     | 1944/4545 [2:04:44<2:50:30,  3.93s/it] 43%|████▎     | 1945/4545 [2:04:47<2:39:45,  3.69s/it] 43%|████▎     | 1946/4545 [2:04:51<2:42:38,  3.75s/it] 43%|████▎     | 1947/4545 [2:04:54<2:31:15,  3.49s/it] 43%|████▎     | 1948/4545 [2:04:57<2:21:33,  3.27s/it] 43%|████▎     | 1949/4545 [2:05:01<2:30:10,  3.47s/it] 43%|████▎     | 1950/4545 [2:05:05<2:37:44,  3.65s/it]                                                       {'loss': 0.221, 'grad_norm': 56.71551513671875, 'learning_rate': 9.55030376280599e-07, 'rewards/chosen': 1.182470679283142, 'rewards/rejected': -8.184374809265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.371874809265137, 'logps/chosen': -200.3000030517578, 'logps/rejected': -182.9499969482422, 'logits/chosen': -8.096875190734863, 'logits/rejected': -7.493750095367432, 'epoch': 1.29}
 43%|████▎     | 1950/4545 [2:05:05<2:37:44,  3.65s/it] 43%|████▎     | 1951/4545 [2:05:09<2:42:19,  3.75s/it] 43%|████▎     | 1952/4545 [2:05:13<2:43:35,  3.79s/it] 43%|████▎     | 1953/4545 [2:05:16<2:42:09,  3.75s/it] 43%|████▎     | 1954/4545 [2:05:20<2:43:47,  3.79s/it] 43%|████▎     | 1955/4545 [2:05:24<2:48:24,  3.90s/it] 43%|████▎     | 1956/4545 [2:05:28<2:48:22,  3.90s/it] 43%|████▎     | 1957/4545 [2:05:32<2:48:12,  3.90s/it] 43%|████▎     | 1958/4545 [2:05:34<2:26:50,  3.41s/it] 43%|████▎     | 1959/4545 [2:05:37<2:12:12,  3.07s/it] 43%|████▎     | 1960/4545 [2:05:40<2:17:25,  3.19s/it]                                                       {'loss': 0.2149, 'grad_norm': 38.66912078857422, 'learning_rate': 9.52976232448331e-07, 'rewards/chosen': 3.2145018577575684, 'rewards/rejected': -9.048437118530273, 'rewards/accuracies': 0.90625, 'rewards/margins': 12.265625, 'logps/chosen': -298.0, 'logps/rejected': -186.39999389648438, 'logits/chosen': -7.974999904632568, 'logits/rejected': -7.603125095367432, 'epoch': 1.29}
 43%|████▎     | 1960/4545 [2:05:40<2:17:25,  3.19s/it] 43%|████▎     | 1961/4545 [2:05:45<2:34:05,  3.58s/it] 43%|████▎     | 1962/4545 [2:05:47<2:21:43,  3.29s/it] 43%|████▎     | 1963/4545 [2:05:51<2:28:10,  3.44s/it] 43%|████▎     | 1964/4545 [2:05:55<2:33:17,  3.56s/it] 43%|████▎     | 1965/4545 [2:05:58<2:31:42,  3.53s/it] 43%|████▎     | 1966/4545 [2:06:02<2:33:03,  3.56s/it] 43%|████▎     | 1967/4545 [2:06:06<2:37:03,  3.66s/it] 43%|████▎     | 1968/4545 [2:06:10<2:40:05,  3.73s/it] 43%|████▎     | 1969/4545 [2:06:14<2:44:35,  3.83s/it] 43%|████▎     | 1970/4545 [2:06:17<2:42:28,  3.79s/it]                                                       {'loss': 0.1372, 'grad_norm': 35.326698303222656, 'learning_rate': 9.508787970380187e-07, 'rewards/chosen': 1.683068871498108, 'rewards/rejected': -10.306249618530273, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 12.0, 'logps/chosen': -227.4250030517578, 'logps/rejected': -146.4499969482422, 'logits/chosen': -7.940625190734863, 'logits/rejected': -7.390625, 'epoch': 1.3}
 43%|████▎     | 1970/4545 [2:06:18<2:42:28,  3.79s/it] 43%|████▎     | 1971/4545 [2:06:21<2:41:01,  3.75s/it] 43%|████▎     | 1972/4545 [2:06:24<2:32:43,  3.56s/it] 43%|████▎     | 1973/4545 [2:06:28<2:36:52,  3.66s/it] 43%|████▎     | 1974/4545 [2:06:32<2:39:53,  3.73s/it] 43%|████▎     | 1975/4545 [2:06:36<2:39:29,  3.72s/it] 43%|████▎     | 1976/4545 [2:06:40<2:44:19,  3.84s/it] 43%|████▎     | 1977/4545 [2:06:44<2:43:39,  3.82s/it] 44%|████▎     | 1978/4545 [2:06:48<2:44:38,  3.85s/it] 44%|████▎     | 1979/4545 [2:06:52<2:47:29,  3.92s/it] 44%|████▎     | 1980/4545 [2:06:56<2:48:07,  3.93s/it]                                                       {'loss': 0.1228, 'grad_norm': 20.536773681640625, 'learning_rate': 9.487382953763225e-07, 'rewards/chosen': 2.1893067359924316, 'rewards/rejected': -9.7109375, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.899999618530273, 'logps/chosen': -238.64999389648438, 'logps/rejected': -189.25, 'logits/chosen': -7.856249809265137, 'logits/rejected': -7.449999809265137, 'epoch': 1.31}
 44%|████▎     | 1980/4545 [2:06:56<2:48:07,  3.93s/it] 44%|████▎     | 1981/4545 [2:06:59<2:39:53,  3.74s/it] 44%|████▎     | 1982/4545 [2:07:03<2:43:34,  3.83s/it] 44%|████▎     | 1983/4545 [2:07:07<2:43:36,  3.83s/it] 44%|████▎     | 1984/4545 [2:07:10<2:39:01,  3.73s/it] 44%|████▎     | 1985/4545 [2:07:14<2:40:42,  3.77s/it] 44%|████▎     | 1986/4545 [2:07:18<2:41:41,  3.79s/it] 44%|████▎     | 1987/4545 [2:07:22<2:46:28,  3.90s/it] 44%|████▎     | 1988/4545 [2:07:26<2:47:22,  3.93s/it] 44%|████▍     | 1989/4545 [2:07:30<2:43:12,  3.83s/it] 44%|████▍     | 1990/4545 [2:07:34<2:44:21,  3.86s/it]                                                       {'loss': 0.2562, 'grad_norm': 13.884852409362793, 'learning_rate': 9.465549574164936e-07, 'rewards/chosen': 2.0840821266174316, 'rewards/rejected': -7.559374809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 9.654687881469727, 'logps/chosen': -242.3000030517578, 'logps/rejected': -174.10000610351562, 'logits/chosen': -7.896874904632568, 'logits/rejected': -7.590624809265137, 'epoch': 1.31}
 44%|████▍     | 1990/4545 [2:07:34<2:44:21,  3.86s/it] 44%|████▍     | 1991/4545 [2:07:38<2:45:15,  3.88s/it] 44%|████▍     | 1992/4545 [2:07:41<2:45:24,  3.89s/it] 44%|████▍     | 1993/4545 [2:07:45<2:45:29,  3.89s/it] 44%|████▍     | 1994/4545 [2:07:49<2:45:07,  3.88s/it] 44%|████▍     | 1995/4545 [2:07:53<2:47:16,  3.94s/it] 44%|████▍     | 1996/4545 [2:07:57<2:42:40,  3.83s/it] 44%|████▍     | 1997/4545 [2:08:01<2:41:03,  3.79s/it] 44%|████▍     | 1998/4545 [2:08:05<2:42:17,  3.82s/it] 44%|████▍     | 1999/4545 [2:08:08<2:36:35,  3.69s/it] 44%|████▍     | 2000/4545 [2:08:11<2:35:14,  3.66s/it]                                                       {'loss': 0.1849, 'grad_norm': 38.9542121887207, 'learning_rate': 9.443290177136697e-07, 'rewards/chosen': 3.48095703125, 'rewards/rejected': -5.824951171875, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.300000190734863, 'logps/chosen': -335.20001220703125, 'logps/rejected': -271.8500061035156, 'logits/chosen': -7.762499809265137, 'logits/rejected': -7.324999809265137, 'epoch': 1.32}
 44%|████▍     | 2000/4545 [2:08:12<2:35:14,  3.66s/it] 44%|████▍     | 2001/4545 [2:08:15<2:29:37,  3.53s/it] 44%|████▍     | 2002/4545 [2:08:19<2:35:39,  3.67s/it] 44%|████▍     | 2003/4545 [2:08:23<2:37:19,  3.71s/it] 44%|████▍     | 2004/4545 [2:08:26<2:36:44,  3.70s/it] 44%|████▍     | 2005/4545 [2:08:30<2:37:58,  3.73s/it] 44%|████▍     | 2006/4545 [2:08:34<2:40:12,  3.79s/it] 44%|████▍     | 2007/4545 [2:08:38<2:41:26,  3.82s/it] 44%|████▍     | 2008/4545 [2:08:42<2:41:46,  3.83s/it] 44%|████▍     | 2009/4545 [2:08:46<2:42:36,  3.85s/it] 44%|████▍     | 2010/4545 [2:08:49<2:43:45,  3.88s/it]                                                       {'loss': 0.22, 'grad_norm': 17.016862869262695, 'learning_rate': 9.42060715399677e-07, 'rewards/chosen': 3.3156495094299316, 'rewards/rejected': -7.995312690734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 11.323437690734863, 'logps/chosen': -339.1000061035156, 'logps/rejected': -232.0500030517578, 'logits/chosen': -7.900000095367432, 'logits/rejected': -7.356249809265137, 'epoch': 1.33}
 44%|████▍     | 2010/4545 [2:08:50<2:43:45,  3.88s/it] 44%|████▍     | 2011/4545 [2:08:53<2:44:39,  3.90s/it] 44%|████▍     | 2012/4545 [2:08:57<2:38:55,  3.76s/it] 44%|████▍     | 2013/4545 [2:09:00<2:28:07,  3.51s/it] 44%|████▍     | 2014/4545 [2:09:04<2:34:44,  3.67s/it] 44%|████▍     | 2015/4545 [2:09:08<2:37:36,  3.74s/it] 44%|████▍     | 2016/4545 [2:09:12<2:39:29,  3.78s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:44,  1.32it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:14,  1.33s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:23,  1.57s/it][A
 13%|█▎        | 8/60 [00:11<01:24,  1.62s/it][A
 15%|█▌        | 9/60 [00:13<01:22,  1.63s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.61s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.65s/it][A
 20%|██        | 12/60 [00:18<01:21,  1.70s/it][A
 22%|██▏       | 13/60 [00:19<01:18,  1.67s/it][A
 23%|██▎       | 14/60 [00:21<01:16,  1.67s/it][A
 25%|██▌       | 15/60 [00:22<01:09,  1.55s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.40s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.30s/it][A
 30%|███       | 18/60 [00:25<00:46,  1.10s/it][A
 32%|███▏      | 19/60 [00:26<00:47,  1.15s/it][A
 33%|███▎      | 20/60 [00:27<00:40,  1.00s/it][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.09s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:35<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:41<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:44<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:46<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:48<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:53<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:57<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.26s/it][A
 78%|███████▊  | 47/60 [01:01<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:02<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.33s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:08<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:09<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:13<00:05,  1.32s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.40s/it][A
 97%|█████████▋| 58/60 [01:16<00:02,  1.38s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.45s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A                                                       
                                               [A{'eval_loss': 0.37087199091911316, 'eval_runtime': 80.9909, 'eval_samples_per_second': 11.767, 'eval_steps_per_second': 0.741, 'eval_rewards/chosen': 3.0792276859283447, 'eval_rewards/rejected': -7.097835063934326, 'eval_rewards/accuracies': 0.8384259343147278, 'eval_rewards/margins': 10.172916412353516, 'eval_logps/chosen': -362.29998779296875, 'eval_logps/rejected': -187.55833435058594, 'eval_logits/chosen': -7.473437309265137, 'eval_logits/rejected': -7.7010416984558105, 'epoch': 1.33}
 44%|████▍     | 2016/4545 [2:10:33<2:39:29,  3.78s/it]
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 44%|████▍     | 2017/4545 [2:10:49<22:25:17, 31.93s/it] 44%|████▍     | 2018/4545 [2:10:53<16:27:04, 23.44s/it] 44%|████▍     | 2019/4545 [2:10:57<12:22:38, 17.64s/it] 44%|████▍     | 2020/4545 [2:11:01<9:31:32, 13.58s/it]                                                        {'loss': 0.1349, 'grad_norm': 44.84842300415039, 'learning_rate': 9.397502941573402e-07, 'rewards/chosen': 2.812695264816284, 'rewards/rejected': -9.643750190734863, 'rewards/accuracies': 0.9375, 'rewards/margins': 12.456250190734863, 'logps/chosen': -306.8500061035156, 'logps/rejected': -202.3000030517578, 'logits/chosen': -7.893750190734863, 'logits/rejected': -7.534375190734863, 'epoch': 1.33}
 44%|████▍     | 2020/4545 [2:11:01<9:31:32, 13.58s/it] 44%|████▍     | 2021/4545 [2:11:05<7:29:12, 10.68s/it] 44%|████▍     | 2022/4545 [2:11:09<6:02:38,  8.62s/it] 45%|████▍     | 2023/4545 [2:11:12<4:56:57,  7.06s/it] 45%|████▍     | 2024/4545 [2:11:16<4:20:37,  6.20s/it] 45%|████▍     | 2025/4545 [2:11:20<3:52:29,  5.54s/it] 45%|████▍     | 2026/4545 [2:11:24<3:26:12,  4.91s/it] 45%|████▍     | 2027/4545 [2:11:28<3:19:01,  4.74s/it] 45%|████▍     | 2028/4545 [2:11:31<2:52:29,  4.11s/it] 45%|████▍     | 2029/4545 [2:11:35<2:52:47,  4.12s/it] 45%|████▍     | 2030/4545 [2:11:39<2:46:16,  3.97s/it]                                                       {'loss': 0.0836, 'grad_norm': 22.629695892333984, 'learning_rate': 9.373980021943041e-07, 'rewards/chosen': 3.2061524391174316, 'rewards/rejected': -10.014062881469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.212499618530273, 'logps/chosen': -319.75, 'logps/rejected': -248.3000030517578, 'logits/chosen': -7.962500095367432, 'logits/rejected': -7.534375190734863, 'epoch': 1.34}
 45%|████▍     | 2030/4545 [2:11:39<2:46:16,  3.97s/it] 45%|████▍     | 2031/4545 [2:11:43<2:47:33,  4.00s/it] 45%|████▍     | 2032/4545 [2:11:47<2:46:26,  3.97s/it] 45%|████▍     | 2033/4545 [2:11:51<2:46:00,  3.97s/it] 45%|████▍     | 2034/4545 [2:11:54<2:45:31,  3.96s/it] 45%|████▍     | 2035/4545 [2:11:58<2:44:56,  3.94s/it] 45%|████▍     | 2036/4545 [2:12:02<2:45:38,  3.96s/it] 45%|████▍     | 2037/4545 [2:12:06<2:44:40,  3.94s/it] 45%|████▍     | 2038/4545 [2:12:10<2:38:39,  3.80s/it] 45%|████▍     | 2039/4545 [2:12:14<2:39:50,  3.83s/it] 45%|████▍     | 2040/4545 [2:12:18<2:43:05,  3.91s/it]                                                       {'loss': 0.2886, 'grad_norm': 20.596017837524414, 'learning_rate': 9.350040922163682e-07, 'rewards/chosen': 3.5543549060821533, 'rewards/rejected': -7.814453125, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 11.362500190734863, 'logps/chosen': -344.29998779296875, 'logps/rejected': -225.75, 'logits/chosen': -7.784375190734863, 'logits/rejected': -7.550000190734863, 'epoch': 1.35}
 45%|████▍     | 2040/4545 [2:12:18<2:43:05,  3.91s/it] 45%|████▍     | 2041/4545 [2:12:21<2:39:38,  3.83s/it] 45%|████▍     | 2042/4545 [2:12:26<2:43:40,  3.92s/it] 45%|████▍     | 2043/4545 [2:12:29<2:43:16,  3.92s/it] 45%|████▍     | 2044/4545 [2:12:33<2:42:59,  3.91s/it] 45%|████▍     | 2045/4545 [2:12:37<2:42:16,  3.89s/it] 45%|████▌     | 2046/4545 [2:12:41<2:35:29,  3.73s/it] 45%|████▌     | 2047/4545 [2:12:44<2:38:27,  3.81s/it] 45%|████▌     | 2048/4545 [2:12:49<2:40:59,  3.87s/it] 45%|████▌     | 2049/4545 [2:12:51<2:27:23,  3.54s/it] 45%|████▌     | 2050/4545 [2:12:55<2:27:40,  3.55s/it]                                                       {'loss': 0.1353, 'grad_norm': 22.652360916137695, 'learning_rate': 9.325688214003396e-07, 'rewards/chosen': 1.828515648841858, 'rewards/rejected': -10.595312118530273, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 12.418749809265137, 'logps/chosen': -241.9499969482422, 'logps/rejected': -203.89999389648438, 'logits/chosen': -7.931250095367432, 'logits/rejected': -7.349999904632568, 'epoch': 1.35}
 45%|████▌     | 2050/4545 [2:12:55<2:27:40,  3.55s/it] 45%|████▌     | 2051/4545 [2:12:59<2:30:44,  3.63s/it] 45%|████▌     | 2052/4545 [2:13:02<2:32:13,  3.66s/it] 45%|████▌     | 2053/4545 [2:13:06<2:34:58,  3.73s/it] 45%|████▌     | 2054/4545 [2:13:10<2:36:59,  3.78s/it] 45%|████▌     | 2055/4545 [2:13:14<2:38:32,  3.82s/it] 45%|████▌     | 2056/4545 [2:13:17<2:26:03,  3.52s/it] 45%|████▌     | 2057/4545 [2:13:21<2:30:55,  3.64s/it] 45%|████▌     | 2058/4545 [2:13:25<2:34:00,  3.72s/it] 45%|████▌     | 2059/4545 [2:13:29<2:36:11,  3.77s/it] 45%|████▌     | 2060/4545 [2:13:31<2:21:33,  3.42s/it]                                                       {'loss': 0.1554, 'grad_norm': 46.995391845703125, 'learning_rate': 9.300924513664032e-07, 'rewards/chosen': 4.18701171875, 'rewards/rejected': -9.918749809265137, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 14.09375, 'logps/chosen': -394.1499938964844, 'logps/rejected': -207.60000610351562, 'logits/chosen': -7.762499809265137, 'logits/rejected': -7.271874904632568, 'epoch': 1.36}
 45%|████▌     | 2060/4545 [2:13:31<2:21:33,  3.42s/it] 45%|████▌     | 2061/4545 [2:13:35<2:28:40,  3.59s/it] 45%|████▌     | 2062/4545 [2:13:39<2:32:37,  3.69s/it] 45%|████▌     | 2063/4545 [2:13:43<2:35:15,  3.75s/it] 45%|████▌     | 2064/4545 [2:13:47<2:37:29,  3.81s/it] 45%|████▌     | 2065/4545 [2:13:50<2:31:12,  3.66s/it] 45%|████▌     | 2066/4545 [2:13:54<2:26:34,  3.55s/it] 45%|████▌     | 2067/4545 [2:13:58<2:34:36,  3.74s/it] 46%|████▌     | 2068/4545 [2:14:02<2:36:28,  3.79s/it] 46%|████▌     | 2069/4545 [2:14:06<2:39:31,  3.87s/it] 46%|████▌     | 2070/4545 [2:14:10<2:39:47,  3.87s/it]                                                       {'loss': 0.1888, 'grad_norm': 48.20225524902344, 'learning_rate': 9.275752481500174e-07, 'rewards/chosen': 0.896484375, 'rewards/rejected': -9.828125, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 10.743749618530273, 'logps/chosen': -208.3000030517578, 'logps/rejected': -208.75, 'logits/chosen': -8.131250381469727, 'logits/rejected': -7.621874809265137, 'epoch': 1.37}
 46%|████▌     | 2070/4545 [2:14:10<2:39:47,  3.87s/it] 46%|████▌     | 2071/4545 [2:14:14<2:40:57,  3.90s/it] 46%|████▌     | 2072/4545 [2:14:17<2:34:51,  3.76s/it] 46%|████▌     | 2073/4545 [2:14:21<2:36:27,  3.80s/it] 46%|████▌     | 2074/4545 [2:14:24<2:28:38,  3.61s/it] 46%|████▌     | 2075/4545 [2:14:28<2:30:49,  3.66s/it] 46%|████▌     | 2076/4545 [2:14:31<2:26:37,  3.56s/it] 46%|████▌     | 2077/4545 [2:14:35<2:29:34,  3.64s/it] 46%|████▌     | 2078/4545 [2:14:39<2:32:07,  3.70s/it] 46%|████▌     | 2079/4545 [2:14:42<2:31:04,  3.68s/it] 46%|████▌     | 2080/4545 [2:14:45<2:21:33,  3.45s/it]                                                       {'loss': 0.2156, 'grad_norm': 27.253629684448242, 'learning_rate': 9.250174821733327e-07, 'rewards/chosen': 0.112060546875, 'rewards/rejected': -10.896875381469727, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 11.0, 'logps/chosen': -158.0500030517578, 'logps/rejected': -157.10000610351562, 'logits/chosen': -8.050000190734863, 'logits/rejected': -7.612500190734863, 'epoch': 1.37}
 46%|████▌     | 2080/4545 [2:14:46<2:21:33,  3.45s/it] 46%|████▌     | 2081/4545 [2:14:48<2:10:15,  3.17s/it] 46%|████▌     | 2082/4545 [2:14:51<2:12:13,  3.22s/it] 46%|████▌     | 2083/4545 [2:14:55<2:21:16,  3.44s/it] 46%|████▌     | 2084/4545 [2:14:59<2:26:43,  3.58s/it] 46%|████▌     | 2085/4545 [2:15:03<2:34:05,  3.76s/it] 46%|████▌     | 2086/4545 [2:15:07<2:35:43,  3.80s/it] 46%|████▌     | 2087/4545 [2:15:11<2:36:57,  3.83s/it] 46%|████▌     | 2088/4545 [2:15:15<2:38:00,  3.86s/it] 46%|████▌     | 2089/4545 [2:15:19<2:36:49,  3.83s/it] 46%|████▌     | 2090/4545 [2:15:22<2:34:11,  3.77s/it]                                                       {'loss': 0.2167, 'grad_norm': 21.175182342529297, 'learning_rate': 9.224194282161415e-07, 'rewards/chosen': 3.108154296875, 'rewards/rejected': -7.659375190734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 10.765625, 'logps/chosen': -326.375, 'logps/rejected': -263.75, 'logits/chosen': -7.831250190734863, 'logits/rejected': -7.459374904632568, 'epoch': 1.38}
 46%|████▌     | 2090/4545 [2:15:22<2:34:11,  3.77s/it] 46%|████▌     | 2091/4545 [2:15:26<2:33:15,  3.75s/it] 46%|████▌     | 2092/4545 [2:15:29<2:28:29,  3.63s/it] 46%|████▌     | 2093/4545 [2:15:33<2:32:13,  3.72s/it] 46%|████▌     | 2094/4545 [2:15:38<2:37:35,  3.86s/it] 46%|████▌     | 2095/4545 [2:15:41<2:34:36,  3.79s/it] 46%|████▌     | 2096/4545 [2:15:45<2:35:56,  3.82s/it] 46%|████▌     | 2097/4545 [2:15:49<2:36:46,  3.84s/it] 46%|████▌     | 2098/4545 [2:15:53<2:37:26,  3.86s/it] 46%|████▌     | 2099/4545 [2:15:57<2:38:02,  3.88s/it] 46%|████▌     | 2100/4545 [2:16:01<2:38:19,  3.89s/it]                                                       {'loss': 0.1778, 'grad_norm': 7.53825569152832, 'learning_rate': 9.197813653863578e-07, 'rewards/chosen': 4.434618949890137, 'rewards/rejected': -6.457812309265137, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 10.912500381469727, 'logps/chosen': -393.8999938964844, 'logps/rejected': -237.64999389648438, 'logits/chosen': -7.650000095367432, 'logits/rejected': -7.465624809265137, 'epoch': 1.39}
 46%|████▌     | 2100/4545 [2:16:01<2:38:19,  3.89s/it] 46%|████▌     | 2101/4545 [2:16:05<2:41:11,  3.96s/it] 46%|████▌     | 2102/4545 [2:16:09<2:40:25,  3.94s/it] 46%|████▋     | 2103/4545 [2:16:13<2:39:45,  3.93s/it] 46%|████▋     | 2104/4545 [2:16:16<2:38:51,  3.90s/it] 46%|████▋     | 2105/4545 [2:16:20<2:38:55,  3.91s/it] 46%|████▋     | 2106/4545 [2:16:24<2:39:05,  3.91s/it] 46%|████▋     | 2107/4545 [2:16:28<2:40:50,  3.96s/it] 46%|████▋     | 2108/4545 [2:16:32<2:41:16,  3.97s/it] 46%|████▋     | 2109/4545 [2:16:36<2:40:16,  3.95s/it] 46%|████▋     | 2110/4545 [2:16:40<2:39:30,  3.93s/it]                                                       {'loss': 0.1827, 'grad_norm': 45.69725799560547, 'learning_rate': 9.171035770900329e-07, 'rewards/chosen': 5.373437404632568, 'rewards/rejected': -7.728125095367432, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 13.106249809265137, 'logps/chosen': -499.3999938964844, 'logps/rejected': -304.1000061035156, 'logits/chosen': -7.696875095367432, 'logits/rejected': -7.465624809265137, 'epoch': 1.39}
 46%|████▋     | 2110/4545 [2:16:40<2:39:30,  3.93s/it] 46%|████▋     | 2111/4545 [2:16:44<2:42:39,  4.01s/it] 46%|████▋     | 2112/4545 [2:16:48<2:33:23,  3.78s/it] 46%|████▋     | 2113/4545 [2:16:52<2:34:47,  3.82s/it] 47%|████▋     | 2114/4545 [2:16:55<2:35:47,  3.85s/it] 47%|████▋     | 2115/4545 [2:16:59<2:36:19,  3.86s/it] 47%|████▋     | 2116/4545 [2:17:03<2:36:47,  3.87s/it] 47%|████▋     | 2117/4545 [2:17:07<2:30:11,  3.71s/it] 47%|████▋     | 2118/4545 [2:17:11<2:33:40,  3.80s/it] 47%|████▋     | 2119/4545 [2:17:15<2:37:36,  3.90s/it] 47%|████▋     | 2120/4545 [2:17:18<2:32:25,  3.77s/it]                                                       {'loss': 0.2055, 'grad_norm': 42.90048599243164, 'learning_rate': 9.143863510009096e-07, 'rewards/chosen': 4.174170017242432, 'rewards/rejected': -8.040624618530273, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 12.228124618530273, 'logps/chosen': -392.95001220703125, 'logps/rejected': -250.1999969482422, 'logits/chosen': -7.868750095367432, 'logits/rejected': -7.484375, 'epoch': 1.4}
 47%|████▋     | 2120/4545 [2:17:18<2:32:25,  3.77s/it] 47%|████▋     | 2121/4545 [2:17:22<2:34:26,  3.82s/it] 47%|████▋     | 2122/4545 [2:17:26<2:34:53,  3.84s/it] 47%|████▋     | 2123/4545 [2:17:29<2:29:21,  3.70s/it] 47%|████▋     | 2124/4545 [2:17:33<2:33:59,  3.82s/it] 47%|████▋     | 2125/4545 [2:17:37<2:36:13,  3.87s/it] 47%|████▋     | 2126/4545 [2:17:40<2:26:15,  3.63s/it] 47%|████▋     | 2127/4545 [2:17:44<2:29:17,  3.70s/it] 47%|████▋     | 2128/4545 [2:17:48<2:31:17,  3.76s/it] 47%|████▋     | 2129/4545 [2:17:52<2:32:56,  3.80s/it] 47%|████▋     | 2130/4545 [2:17:56<2:34:04,  3.83s/it]                                                       {'loss': 0.2786, 'grad_norm': 16.438343048095703, 'learning_rate': 9.116299790295174e-07, 'rewards/chosen': 2.840283155441284, 'rewards/rejected': -9.853124618530273, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 12.693750381469727, 'logps/chosen': -342.5249938964844, 'logps/rejected': -187.5500030517578, 'logits/chosen': -7.815625190734863, 'logits/rejected': -7.356249809265137, 'epoch': 1.41}
 47%|████▋     | 2130/4545 [2:17:56<2:34:04,  3.83s/it] 47%|████▋     | 2131/4545 [2:18:00<2:36:10,  3.88s/it] 47%|████▋     | 2132/4545 [2:18:04<2:32:50,  3.80s/it] 47%|████▋     | 2133/4545 [2:18:08<2:33:47,  3.83s/it] 47%|████▋     | 2134/4545 [2:18:11<2:34:24,  3.84s/it] 47%|████▋     | 2135/4545 [2:18:15<2:34:55,  3.86s/it] 47%|████▋     | 2136/4545 [2:18:19<2:35:08,  3.86s/it] 47%|████▋     | 2137/4545 [2:18:23<2:35:05,  3.86s/it] 47%|████▋     | 2138/4545 [2:18:27<2:35:28,  3.88s/it] 47%|████▋     | 2139/4545 [2:18:30<2:25:43,  3.63s/it] 47%|████▋     | 2140/4545 [2:18:34<2:28:25,  3.70s/it]                                                       {'loss': 0.1691, 'grad_norm': 16.180164337158203, 'learning_rate': 9.088347572918121e-07, 'rewards/chosen': 5.629492282867432, 'rewards/rejected': -7.717968940734863, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 13.334375381469727, 'logps/chosen': -486.79998779296875, 'logps/rejected': -279.8999938964844, 'logits/chosen': -7.640625, 'logits/rejected': -7.425000190734863, 'epoch': 1.41}
 47%|████▋     | 2140/4545 [2:18:34<2:28:25,  3.70s/it] 47%|████▋     | 2141/4545 [2:18:38<2:31:07,  3.77s/it] 47%|████▋     | 2142/4545 [2:18:42<2:32:29,  3.81s/it] 47%|████▋     | 2143/4545 [2:18:45<2:20:28,  3.51s/it] 47%|████▋     | 2144/4545 [2:18:47<2:10:48,  3.27s/it] 47%|████▋     | 2145/4545 [2:18:51<2:18:26,  3.46s/it] 47%|████▋     | 2146/4545 [2:18:55<2:23:29,  3.59s/it] 47%|████▋     | 2147/4545 [2:18:59<2:26:23,  3.66s/it] 47%|████▋     | 2148/4545 [2:19:03<2:29:19,  3.74s/it] 47%|████▋     | 2149/4545 [2:19:06<2:24:21,  3.61s/it] 47%|████▋     | 2150/4545 [2:19:10<2:27:43,  3.70s/it]                                                       {'loss': 0.1193, 'grad_norm': 22.401159286499023, 'learning_rate': 9.060009860773649e-07, 'rewards/chosen': 1.49853515625, 'rewards/rejected': -9.903124809265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.399999618530273, 'logps/chosen': -220.3000030517578, 'logps/rejected': -152.0, 'logits/chosen': -7.915625095367432, 'logits/rejected': -7.324999809265137, 'epoch': 1.42}
 47%|████▋     | 2150/4545 [2:19:10<2:27:43,  3.70s/it] 47%|████▋     | 2151/4545 [2:19:14<2:33:53,  3.86s/it] 47%|████▋     | 2152/4545 [2:19:18<2:34:16,  3.87s/it] 47%|████▋     | 2153/4545 [2:19:22<2:34:21,  3.87s/it] 47%|████▋     | 2154/4545 [2:19:25<2:24:49,  3.63s/it] 47%|████▋     | 2155/4545 [2:19:29<2:29:05,  3.74s/it] 47%|████▋     | 2156/4545 [2:19:31<2:11:14,  3.30s/it] 47%|████▋     | 2157/4545 [2:19:35<2:19:55,  3.52s/it] 47%|████▋     | 2158/4545 [2:19:39<2:25:02,  3.65s/it] 48%|████▊     | 2159/4545 [2:19:42<2:15:41,  3.41s/it] 48%|████▊     | 2160/4545 [2:19:46<2:21:36,  3.56s/it]                                                       {'loss': 0.2183, 'grad_norm': 64.42680358886719, 'learning_rate': 9.031289698171017e-07, 'rewards/chosen': 3.7914061546325684, 'rewards/rejected': -7.8828125, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.665624618530273, 'logps/chosen': -347.54998779296875, 'logps/rejected': -187.35000610351562, 'logits/chosen': -7.618750095367432, 'logits/rejected': -7.231249809265137, 'epoch': 1.43}
 48%|████▊     | 2160/4545 [2:19:46<2:21:36,  3.56s/it] 48%|████▊     | 2161/4545 [2:19:50<2:20:41,  3.54s/it] 48%|████▊     | 2162/4545 [2:19:53<2:24:49,  3.65s/it] 48%|████▊     | 2163/4545 [2:19:58<2:30:20,  3.79s/it] 48%|████▊     | 2164/4545 [2:20:02<2:31:36,  3.82s/it] 48%|████▊     | 2165/4545 [2:20:06<2:34:54,  3.91s/it] 48%|████▊     | 2166/4545 [2:20:09<2:34:29,  3.90s/it] 48%|████▊     | 2167/4545 [2:20:12<2:21:21,  3.57s/it] 48%|████▊     | 2168/4545 [2:20:16<2:25:20,  3.67s/it] 48%|████▊     | 2169/4545 [2:20:20<2:27:32,  3.73s/it] 48%|████▊     | 2170/4545 [2:20:24<2:25:14,  3.67s/it]                                                       {'loss': 0.2671, 'grad_norm': 32.67748260498047, 'learning_rate': 9.002190170505994e-07, 'rewards/chosen': 2.447582960128784, 'rewards/rejected': -8.953125, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 11.415624618530273, 'logps/chosen': -271.3500061035156, 'logps/rejected': -163.35000610351562, 'logits/chosen': -8.068750381469727, 'logits/rejected': -7.737500190734863, 'epoch': 1.43}
 48%|████▊     | 2170/4545 [2:20:24<2:25:14,  3.67s/it] 48%|████▊     | 2171/4545 [2:20:28<2:28:32,  3.75s/it] 48%|████▊     | 2172/4545 [2:20:32<2:33:45,  3.89s/it] 48%|████▊     | 2173/4545 [2:20:35<2:28:35,  3.76s/it] 48%|████▊     | 2174/4545 [2:20:39<2:29:55,  3.79s/it] 48%|████▊     | 2175/4545 [2:20:42<2:23:00,  3.62s/it] 48%|████▊     | 2176/4545 [2:20:46<2:27:36,  3.74s/it] 48%|████▊     | 2177/4545 [2:20:50<2:29:14,  3.78s/it] 48%|████▊     | 2178/4545 [2:20:54<2:30:32,  3.82s/it] 48%|████▊     | 2179/4545 [2:20:57<2:20:02,  3.55s/it] 48%|████▊     | 2180/4545 [2:21:01<2:24:03,  3.65s/it]                                                       {'loss': 0.1496, 'grad_norm': 5.512001037597656, 'learning_rate': 8.972714403929383e-07, 'rewards/chosen': 3.27783203125, 'rewards/rejected': -9.128125190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 12.399999618530273, 'logps/chosen': -327.54998779296875, 'logps/rejected': -180.25, 'logits/chosen': -8.0, 'logits/rejected': -7.534375190734863, 'epoch': 1.44}
 48%|████▊     | 2180/4545 [2:21:01<2:24:03,  3.65s/it] 48%|████▊     | 2181/4545 [2:21:05<2:27:10,  3.74s/it] 48%|████▊     | 2182/4545 [2:21:08<2:25:49,  3.70s/it] 48%|████▊     | 2183/4545 [2:21:13<2:29:49,  3.81s/it] 48%|████▊     | 2184/4545 [2:21:16<2:30:37,  3.83s/it] 48%|████▊     | 2185/4545 [2:21:21<2:34:45,  3.93s/it] 48%|████▊     | 2186/4545 [2:21:25<2:34:44,  3.94s/it] 48%|████▊     | 2187/4545 [2:21:28<2:34:13,  3.92s/it] 48%|████▊     | 2188/4545 [2:21:32<2:27:36,  3.76s/it] 48%|████▊     | 2189/4545 [2:21:35<2:25:12,  3.70s/it] 48%|████▊     | 2190/4545 [2:21:39<2:20:43,  3.59s/it]                                                       {'loss': 0.1723, 'grad_norm': 15.54272174835205, 'learning_rate': 8.942865565011182e-07, 'rewards/chosen': 2.0404295921325684, 'rewards/rejected': -10.667187690734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 12.715624809265137, 'logps/chosen': -242.3000030517578, 'logps/rejected': -215.25, 'logits/chosen': -7.928124904632568, 'logits/rejected': -7.368750095367432, 'epoch': 1.45}
 48%|████▊     | 2190/4545 [2:21:39<2:20:43,  3.59s/it] 48%|████▊     | 2191/4545 [2:21:43<2:24:50,  3.69s/it] 48%|████▊     | 2192/4545 [2:21:46<2:27:09,  3.75s/it] 48%|████▊     | 2193/4545 [2:21:50<2:28:02,  3.78s/it] 48%|████▊     | 2194/4545 [2:21:54<2:31:53,  3.88s/it] 48%|████▊     | 2195/4545 [2:21:58<2:32:10,  3.89s/it] 48%|████▊     | 2196/4545 [2:22:02<2:32:14,  3.89s/it] 48%|████▊     | 2197/4545 [2:22:06<2:33:08,  3.91s/it] 48%|████▊     | 2198/4545 [2:22:10<2:33:46,  3.93s/it] 48%|████▊     | 2199/4545 [2:22:14<2:30:33,  3.85s/it] 48%|████▊     | 2200/4545 [2:22:18<2:30:41,  3.86s/it]                                                       {'loss': 0.2007, 'grad_norm': 17.931055068969727, 'learning_rate': 8.912646860400414e-07, 'rewards/chosen': 4.276953220367432, 'rewards/rejected': -11.5625, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 15.834375381469727, 'logps/chosen': -428.25, 'logps/rejected': -290.1000061035156, 'logits/chosen': -7.384375095367432, 'logits/rejected': -7.025000095367432, 'epoch': 1.45}
 48%|████▊     | 2200/4545 [2:22:18<2:30:41,  3.86s/it] 48%|████▊     | 2201/4545 [2:22:21<2:24:27,  3.70s/it] 48%|████▊     | 2202/4545 [2:22:24<2:20:06,  3.59s/it] 48%|████▊     | 2203/4545 [2:22:27<2:12:48,  3.40s/it] 48%|████▊     | 2204/4545 [2:22:31<2:16:21,  3.49s/it] 49%|████▊     | 2205/4545 [2:22:35<2:24:15,  3.70s/it] 49%|████▊     | 2206/4545 [2:22:39<2:22:38,  3.66s/it] 49%|████▊     | 2207/4545 [2:22:43<2:25:12,  3.73s/it] 49%|████▊     | 2208/4545 [2:22:47<2:29:44,  3.84s/it] 49%|████▊     | 2209/4545 [2:22:51<2:29:46,  3.85s/it] 49%|████▊     | 2210/4545 [2:22:55<2:29:57,  3.85s/it]                                                       {'loss': 0.2119, 'grad_norm': 56.48328399658203, 'learning_rate': 8.882061536480616e-07, 'rewards/chosen': 1.24432373046875, 'rewards/rejected': -11.640625, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 12.865625381469727, 'logps/chosen': -232.0500030517578, 'logps/rejected': -181.5500030517578, 'logits/chosen': -7.987500190734863, 'logits/rejected': -7.390625, 'epoch': 1.46}
 49%|████▊     | 2210/4545 [2:22:55<2:29:57,  3.85s/it] 49%|████▊     | 2211/4545 [2:22:58<2:31:13,  3.89s/it] 49%|████▊     | 2212/4545 [2:23:02<2:31:42,  3.90s/it] 49%|████▊     | 2213/4545 [2:23:06<2:32:19,  3.92s/it] 49%|████▊     | 2214/4545 [2:23:10<2:30:47,  3.88s/it] 49%|████▊     | 2215/4545 [2:23:14<2:25:33,  3.75s/it] 49%|████▉     | 2216/4545 [2:23:18<2:27:16,  3.79s/it] 49%|████▉     | 2217/4545 [2:23:22<2:30:32,  3.88s/it] 49%|████▉     | 2218/4545 [2:23:25<2:30:46,  3.89s/it] 49%|████▉     | 2219/4545 [2:23:29<2:30:41,  3.89s/it] 49%|████▉     | 2220/4545 [2:23:33<2:30:40,  3.89s/it]                                                       {'loss': 0.1922, 'grad_norm': 15.524822235107422, 'learning_rate': 8.851112879021102e-07, 'rewards/chosen': 3.031445264816284, 'rewards/rejected': -10.004687309265137, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 13.040624618530273, 'logps/chosen': -318.54998779296875, 'logps/rejected': -215.10000610351562, 'logits/chosen': -7.796875, 'logits/rejected': -7.449999809265137, 'epoch': 1.47}
 49%|████▉     | 2220/4545 [2:23:34<2:30:40,  3.89s/it] 49%|████▉     | 2221/4545 [2:23:37<2:28:03,  3.82s/it] 49%|████▉     | 2222/4545 [2:23:40<2:24:51,  3.74s/it] 49%|████▉     | 2223/4545 [2:23:44<2:26:22,  3.78s/it] 49%|████▉     | 2224/4545 [2:23:48<2:27:46,  3.82s/it] 49%|████▉     | 2225/4545 [2:23:52<2:28:41,  3.85s/it] 49%|████▉     | 2226/4545 [2:23:56<2:29:21,  3.86s/it] 49%|████▉     | 2227/4545 [2:24:00<2:26:54,  3.80s/it] 49%|████▉     | 2228/4545 [2:24:04<2:27:57,  3.83s/it] 49%|████▉     | 2229/4545 [2:24:06<2:14:38,  3.49s/it] 49%|████▉     | 2230/4545 [2:24:10<2:19:04,  3.60s/it]                                                       {'loss': 0.1241, 'grad_norm': 27.75214958190918, 'learning_rate': 8.819804212823959e-07, 'rewards/chosen': 3.792773485183716, 'rewards/rejected': -11.353124618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 15.146875381469727, 'logps/chosen': -379.6499938964844, 'logps/rejected': -261.79998779296875, 'logits/chosen': -7.618750095367432, 'logits/rejected': -7.037499904632568, 'epoch': 1.47}
 49%|████▉     | 2230/4545 [2:24:10<2:19:04,  3.60s/it] 49%|████▉     | 2231/4545 [2:24:14<2:22:46,  3.70s/it] 49%|████▉     | 2232/4545 [2:24:18<2:22:33,  3.70s/it] 49%|████▉     | 2233/4545 [2:24:22<2:25:43,  3.78s/it] 49%|████▉     | 2234/4545 [2:24:26<2:26:54,  3.81s/it] 49%|████▉     | 2235/4545 [2:24:29<2:18:32,  3.60s/it] 49%|████▉     | 2236/4545 [2:24:33<2:25:56,  3.79s/it] 49%|████▉     | 2237/4545 [2:24:37<2:27:05,  3.82s/it] 49%|████▉     | 2238/4545 [2:24:41<2:27:42,  3.84s/it] 49%|████▉     | 2239/4545 [2:24:45<2:28:07,  3.85s/it] 49%|████▉     | 2240/4545 [2:24:47<2:13:41,  3.48s/it]                                                       {'loss': 0.1125, 'grad_norm': 19.60847282409668, 'learning_rate': 8.788138901366877e-07, 'rewards/chosen': 3.4168944358825684, 'rewards/rejected': -8.7421875, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 12.159375190734863, 'logps/chosen': -317.0, 'logps/rejected': -198.4499969482422, 'logits/chosen': -7.778124809265137, 'logits/rejected': -7.403124809265137, 'epoch': 1.48}
 49%|████▉     | 2240/4545 [2:24:47<2:13:41,  3.48s/it] 49%|████▉     | 2241/4545 [2:24:51<2:18:24,  3.60s/it] 49%|████▉     | 2242/4545 [2:24:55<2:15:13,  3.52s/it] 49%|████▉     | 2243/4545 [2:24:58<2:16:21,  3.55s/it] 49%|████▉     | 2244/4545 [2:25:01<2:03:34,  3.22s/it] 49%|████▉     | 2245/4545 [2:25:05<2:12:28,  3.46s/it] 49%|████▉     | 2246/4545 [2:25:08<2:17:09,  3.58s/it] 49%|████▉     | 2247/4545 [2:25:12<2:20:35,  3.67s/it] 49%|████▉     | 2248/4545 [2:25:16<2:22:35,  3.72s/it] 49%|████▉     | 2249/4545 [2:25:20<2:25:13,  3.80s/it] 50%|████▉     | 2250/4545 [2:25:24<2:29:59,  3.92s/it]                                                       {'loss': 0.1832, 'grad_norm': 33.61560821533203, 'learning_rate': 8.7561203464418e-07, 'rewards/chosen': 2.4085936546325684, 'rewards/rejected': -11.889843940734863, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 14.318750381469727, 'logps/chosen': -291.95001220703125, 'logps/rejected': -224.39999389648438, 'logits/chosen': -7.71875, 'logits/rejected': -7.290625095367432, 'epoch': 1.49}
 50%|████▉     | 2250/4545 [2:25:24<2:29:59,  3.92s/it] 50%|████▉     | 2251/4545 [2:25:28<2:32:02,  3.98s/it] 50%|████▉     | 2252/4545 [2:25:32<2:31:04,  3.95s/it] 50%|████▉     | 2253/4545 [2:25:36<2:23:34,  3.76s/it] 50%|████▉     | 2254/4545 [2:25:40<2:25:09,  3.80s/it] 50%|████▉     | 2255/4545 [2:25:43<2:17:45,  3.61s/it] 50%|████▉     | 2256/4545 [2:25:47<2:21:09,  3.70s/it] 50%|████▉     | 2257/4545 [2:25:51<2:25:00,  3.80s/it] 50%|████▉     | 2258/4545 [2:25:55<2:24:55,  3.80s/it] 50%|████▉     | 2259/4545 [2:25:58<2:25:59,  3.83s/it] 50%|████▉     | 2260/4545 [2:26:02<2:26:41,  3.85s/it]                                                       {'loss': 0.1918, 'grad_norm': 17.653606414794922, 'learning_rate': 8.723751987789483e-07, 'rewards/chosen': 2.439624071121216, 'rewards/rejected': -9.100000381469727, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 11.524999618530273, 'logps/chosen': -300.25, 'logps/rejected': -218.85000610351562, 'logits/chosen': -7.815625190734863, 'logits/rejected': -7.390625, 'epoch': 1.49}
 50%|████▉     | 2260/4545 [2:26:03<2:26:41,  3.85s/it] 50%|████▉     | 2261/4545 [2:26:05<2:17:31,  3.61s/it] 50%|████▉     | 2262/4545 [2:26:09<2:20:06,  3.68s/it] 50%|████▉     | 2263/4545 [2:26:13<2:26:11,  3.84s/it] 50%|████▉     | 2264/4545 [2:26:17<2:28:22,  3.90s/it] 50%|████▉     | 2265/4545 [2:26:21<2:24:41,  3.81s/it] 50%|████▉     | 2266/4545 [2:26:25<2:24:37,  3.81s/it] 50%|████▉     | 2267/4545 [2:26:29<2:26:00,  3.85s/it] 50%|████▉     | 2268/4545 [2:26:32<2:13:27,  3.52s/it] 50%|████▉     | 2269/4545 [2:26:36<2:20:47,  3.71s/it] 50%|████▉     | 2270/4545 [2:26:39<2:19:22,  3.68s/it]                                                       {'loss': 0.1647, 'grad_norm': 44.62479019165039, 'learning_rate': 8.691037302729957e-07, 'rewards/chosen': 0.3866210877895355, 'rewards/rejected': -12.100000381469727, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 12.4921875, 'logps/chosen': -175.8000030517578, 'logps/rejected': -163.0500030517578, 'logits/chosen': -7.915625095367432, 'logits/rejected': -7.440625190734863, 'epoch': 1.5}
 50%|████▉     | 2270/4545 [2:26:39<2:19:22,  3.68s/it] 50%|████▉     | 2271/4545 [2:26:43<2:24:52,  3.82s/it] 50%|████▉     | 2272/4545 [2:26:46<2:11:27,  3.47s/it] 50%|█████     | 2273/4545 [2:26:50<2:14:36,  3.56s/it] 50%|█████     | 2274/4545 [2:26:53<2:09:36,  3.42s/it] 50%|█████     | 2275/4545 [2:26:57<2:17:15,  3.63s/it] 50%|█████     | 2276/4545 [2:27:00<2:13:39,  3.53s/it] 50%|█████     | 2277/4545 [2:27:04<2:17:48,  3.65s/it] 50%|█████     | 2278/4545 [2:27:08<2:17:31,  3.64s/it] 50%|█████     | 2279/4545 [2:27:12<2:21:27,  3.75s/it] 50%|█████     | 2280/4545 [2:27:16<2:23:15,  3.79s/it]                                                       {'loss': 0.293, 'grad_norm': 26.15851593017578, 'learning_rate': 8.657979805788958e-07, 'rewards/chosen': 0.809368908405304, 'rewards/rejected': -8.784375190734863, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 9.596875190734863, 'logps/chosen': -211.4499969482422, 'logps/rejected': -135.6999969482422, 'logits/chosen': -7.831250190734863, 'logits/rejected': -7.474999904632568, 'epoch': 1.5}
 50%|█████     | 2280/4545 [2:27:16<2:23:15,  3.79s/it] 50%|█████     | 2281/4545 [2:27:20<2:24:40,  3.83s/it] 50%|█████     | 2282/4545 [2:27:23<2:18:14,  3.67s/it] 50%|█████     | 2283/4545 [2:27:27<2:20:56,  3.74s/it] 50%|█████     | 2284/4545 [2:27:31<2:22:28,  3.78s/it] 50%|█████     | 2285/4545 [2:27:34<2:17:52,  3.66s/it] 50%|█████     | 2286/4545 [2:27:38<2:20:21,  3.73s/it] 50%|█████     | 2287/4545 [2:27:42<2:22:27,  3.79s/it] 50%|█████     | 2288/4545 [2:27:46<2:23:36,  3.82s/it] 50%|█████     | 2289/4545 [2:27:50<2:24:34,  3.85s/it] 50%|█████     | 2290/4545 [2:27:54<2:25:22,  3.87s/it]                                                       {'loss': 0.1696, 'grad_norm': 21.96993637084961, 'learning_rate': 8.624583048320373e-07, 'rewards/chosen': 4.878515720367432, 'rewards/rejected': -9.746874809265137, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 14.618749618530273, 'logps/chosen': -429.6000061035156, 'logps/rejected': -275.8999938964844, 'logits/chosen': -7.646874904632568, 'logits/rejected': -7.28125, 'epoch': 1.51}
 50%|█████     | 2290/4545 [2:27:54<2:25:22,  3.87s/it] 50%|█████     | 2291/4545 [2:27:57<2:21:41,  3.77s/it] 50%|█████     | 2292/4545 [2:28:01<2:17:56,  3.67s/it] 50%|█████     | 2293/4545 [2:28:05<2:23:15,  3.82s/it] 50%|█████     | 2294/4545 [2:28:09<2:24:54,  3.86s/it] 50%|█████     | 2295/4545 [2:28:13<2:25:45,  3.89s/it] 51%|█████     | 2296/4545 [2:28:17<2:25:18,  3.88s/it] 51%|█████     | 2297/4545 [2:28:20<2:22:18,  3.80s/it] 51%|█████     | 2298/4545 [2:28:24<2:25:19,  3.88s/it] 51%|█████     | 2299/4545 [2:28:28<2:24:51,  3.87s/it] 51%|█████     | 2300/4545 [2:28:32<2:29:08,  3.99s/it]                                                       {'loss': 0.1689, 'grad_norm': 21.955028533935547, 'learning_rate': 8.590850618124714e-07, 'rewards/chosen': 3.9012694358825684, 'rewards/rejected': -10.6796875, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 14.581250190734863, 'logps/chosen': -399.04998779296875, 'logps/rejected': -244.25, 'logits/chosen': -7.599999904632568, 'logits/rejected': -7.15625, 'epoch': 1.52}
 51%|█████     | 2300/4545 [2:28:33<2:29:08,  3.99s/it] 51%|█████     | 2301/4545 [2:28:37<2:31:13,  4.04s/it] 51%|█████     | 2302/4545 [2:28:41<2:30:29,  4.03s/it] 51%|█████     | 2303/4545 [2:28:44<2:28:00,  3.96s/it] 51%|█████     | 2304/4545 [2:28:48<2:19:15,  3.73s/it] 51%|█████     | 2305/4545 [2:28:51<2:17:24,  3.68s/it] 51%|█████     | 2306/4545 [2:28:55<2:14:58,  3.62s/it] 51%|█████     | 2307/4545 [2:28:59<2:18:08,  3.70s/it] 51%|█████     | 2308/4545 [2:29:02<2:20:06,  3.76s/it] 51%|█████     | 2309/4545 [2:29:06<2:18:56,  3.73s/it] 51%|█████     | 2310/4545 [2:29:09<2:14:13,  3.60s/it]                                                       {'loss': 0.267, 'grad_norm': 43.976627349853516, 'learning_rate': 8.556786139063679e-07, 'rewards/chosen': 2.853808641433716, 'rewards/rejected': -8.392969131469727, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 11.246874809265137, 'logps/chosen': -292.7749938964844, 'logps/rejected': -220.75, 'logits/chosen': -7.8125, 'logits/rejected': -7.262499809265137, 'epoch': 1.52}
 51%|█████     | 2310/4545 [2:29:10<2:14:13,  3.60s/it] 51%|█████     | 2311/4545 [2:29:13<2:17:31,  3.69s/it] 51%|█████     | 2312/4545 [2:29:17<2:19:54,  3.76s/it] 51%|█████     | 2313/4545 [2:29:21<2:20:54,  3.79s/it] 51%|█████     | 2314/4545 [2:29:25<2:17:42,  3.70s/it] 51%|█████     | 2315/4545 [2:29:29<2:22:40,  3.84s/it] 51%|█████     | 2316/4545 [2:29:33<2:23:13,  3.86s/it] 51%|█████     | 2317/4545 [2:29:36<2:18:29,  3.73s/it] 51%|█████     | 2318/4545 [2:29:40<2:20:16,  3.78s/it] 51%|█████     | 2319/4545 [2:29:44<2:24:07,  3.88s/it] 51%|█████     | 2320/4545 [2:29:48<2:25:29,  3.92s/it]                                                       {'loss': 0.2024, 'grad_norm': 34.029991149902344, 'learning_rate': 8.522393270670846e-07, 'rewards/chosen': 4.905444145202637, 'rewards/rejected': -8.857812881469727, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 13.765625, 'logps/chosen': -420.20001220703125, 'logps/rejected': -291.3999938964844, 'logits/chosen': -7.659375190734863, 'logits/rejected': -7.171875, 'epoch': 1.53}
 51%|█████     | 2320/4545 [2:29:48<2:25:29,  3.92s/it] 51%|█████     | 2321/4545 [2:29:52<2:22:03,  3.83s/it] 51%|█████     | 2322/4545 [2:29:56<2:22:41,  3.85s/it] 51%|█████     | 2323/4545 [2:30:00<2:23:12,  3.87s/it] 51%|█████     | 2324/4545 [2:30:03<2:23:04,  3.87s/it] 51%|█████     | 2325/4545 [2:30:07<2:23:52,  3.89s/it] 51%|█████     | 2326/4545 [2:30:12<2:27:04,  3.98s/it] 51%|█████     | 2327/4545 [2:30:15<2:26:10,  3.95s/it] 51%|█████     | 2328/4545 [2:30:19<2:25:58,  3.95s/it] 51%|█████     | 2329/4545 [2:30:24<2:28:06,  4.01s/it] 51%|█████▏    | 2330/4545 [2:30:27<2:26:51,  3.98s/it]                                                       {'loss': 0.1856, 'grad_norm': 7.6567277908325195, 'learning_rate': 8.487675707758529e-07, 'rewards/chosen': 5.556860446929932, 'rewards/rejected': -8.598437309265137, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 14.146875381469727, 'logps/chosen': -479.75, 'logps/rejected': -287.3500061035156, 'logits/chosen': -7.481249809265137, 'logits/rejected': -7.165625095367432, 'epoch': 1.54}
 51%|█████▏    | 2330/4545 [2:30:28<2:26:51,  3.98s/it] 51%|█████▏    | 2331/4545 [2:30:31<2:26:13,  3.96s/it] 51%|█████▏    | 2332/4545 [2:30:35<2:25:03,  3.93s/it] 51%|█████▏    | 2333/4545 [2:30:39<2:26:07,  3.96s/it] 51%|█████▏    | 2334/4545 [2:30:42<2:16:22,  3.70s/it] 51%|█████▏    | 2335/4545 [2:30:46<2:18:31,  3.76s/it] 51%|█████▏    | 2336/4545 [2:30:49<2:12:48,  3.61s/it] 51%|█████▏    | 2337/4545 [2:30:52<1:57:59,  3.21s/it] 51%|█████▏    | 2338/4545 [2:30:56<2:06:53,  3.45s/it] 51%|█████▏    | 2339/4545 [2:31:00<2:13:11,  3.62s/it] 51%|█████▏    | 2340/4545 [2:31:04<2:16:10,  3.71s/it]                                                       {'loss': 0.1267, 'grad_norm': 5.900589942932129, 'learning_rate': 8.452637180020848e-07, 'rewards/chosen': 2.770703077316284, 'rewards/rejected': -11.138280868530273, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 13.909375190734863, 'logps/chosen': -280.5, 'logps/rejected': -222.85000610351562, 'logits/chosen': -8.109375, 'logits/rejected': -7.599999904632568, 'epoch': 1.54}
 51%|█████▏    | 2340/4545 [2:31:04<2:16:10,  3.71s/it] 52%|█████▏    | 2341/4545 [2:31:08<2:19:25,  3.80s/it] 52%|█████▏    | 2342/4545 [2:31:12<2:22:11,  3.87s/it] 52%|█████▏    | 2343/4545 [2:31:16<2:23:58,  3.92s/it] 52%|█████▏    | 2344/4545 [2:31:20<2:23:32,  3.91s/it] 52%|█████▏    | 2345/4545 [2:31:24<2:23:21,  3.91s/it] 52%|█████▏    | 2346/4545 [2:31:27<2:23:08,  3.91s/it] 52%|█████▏    | 2347/4545 [2:31:32<2:25:01,  3.96s/it] 52%|█████▏    | 2348/4545 [2:31:35<2:24:42,  3.95s/it] 52%|█████▏    | 2349/4545 [2:31:39<2:24:56,  3.96s/it] 52%|█████▏    | 2350/4545 [2:31:43<2:21:33,  3.87s/it]                                                       {'loss': 0.1314, 'grad_norm': 30.3287410736084, 'learning_rate': 8.417281451633048e-07, 'rewards/chosen': 3.422119140625, 'rewards/rejected': -10.509374618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 13.956250190734863, 'logps/chosen': -354.79998779296875, 'logps/rejected': -261.45001220703125, 'logits/chosen': -7.918749809265137, 'logits/rejected': -7.303124904632568, 'epoch': 1.55}
 52%|█████▏    | 2350/4545 [2:31:43<2:21:33,  3.87s/it] 52%|█████▏    | 2351/4545 [2:31:47<2:21:44,  3.88s/it] 52%|█████▏    | 2352/4545 [2:31:51<2:19:41,  3.82s/it] 52%|█████▏    | 2353/4545 [2:31:54<2:09:04,  3.53s/it] 52%|█████▏    | 2354/4545 [2:31:58<2:16:00,  3.72s/it] 52%|█████▏    | 2355/4545 [2:32:02<2:16:56,  3.75s/it] 52%|█████▏    | 2356/4545 [2:32:06<2:21:32,  3.88s/it] 52%|█████▏    | 2357/4545 [2:32:08<2:08:33,  3.53s/it] 52%|█████▏    | 2358/4545 [2:32:12<2:08:19,  3.52s/it] 52%|█████▏    | 2359/4545 [2:32:16<2:12:32,  3.64s/it] 52%|█████▏    | 2360/4545 [2:32:19<2:03:57,  3.40s/it]                                                       {'loss': 0.1397, 'grad_norm': 3.8062198162078857, 'learning_rate': 8.381612320847113e-07, 'rewards/chosen': 0.4891357421875, 'rewards/rejected': -11.384374618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 11.878125190734863, 'logps/chosen': -160.0, 'logps/rejected': -159.5500030517578, 'logits/chosen': -8.190625190734863, 'logits/rejected': -7.59375, 'epoch': 1.56}
 52%|█████▏    | 2360/4545 [2:32:19<2:03:57,  3.40s/it] 52%|█████▏    | 2361/4545 [2:32:23<2:10:04,  3.57s/it] 52%|█████▏    | 2362/4545 [2:32:27<2:13:21,  3.67s/it] 52%|█████▏    | 2363/4545 [2:32:30<2:06:29,  3.48s/it] 52%|█████▏    | 2364/4545 [2:32:33<2:11:00,  3.60s/it] 52%|█████▏    | 2365/4545 [2:32:37<2:05:19,  3.45s/it] 52%|█████▏    | 2366/4545 [2:32:41<2:13:03,  3.66s/it] 52%|█████▏    | 2367/4545 [2:32:43<2:00:03,  3.31s/it] 52%|█████▏    | 2368/4545 [2:32:47<2:06:35,  3.49s/it] 52%|█████▏    | 2369/4545 [2:32:51<2:11:05,  3.61s/it] 52%|█████▏    | 2370/4545 [2:32:53<1:57:57,  3.25s/it]                                                       {'loss': 0.1844, 'grad_norm': 16.567516326904297, 'learning_rate': 8.345633619583724e-07, 'rewards/chosen': 2.0864624977111816, 'rewards/rejected': -8.987500190734863, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 11.074999809265137, 'logps/chosen': -238.3000030517578, 'logps/rejected': -207.10000610351562, 'logits/chosen': -8.165624618530273, 'logits/rejected': -7.671875, 'epoch': 1.56}
 52%|█████▏    | 2370/4545 [2:32:54<1:57:57,  3.25s/it] 52%|█████▏    | 2371/4545 [2:32:57<2:06:20,  3.49s/it] 52%|█████▏    | 2372/4545 [2:33:02<2:12:57,  3.67s/it] 52%|█████▏    | 2373/4545 [2:33:05<2:14:21,  3.71s/it] 52%|█████▏    | 2374/4545 [2:33:08<2:04:37,  3.44s/it] 52%|█████▏    | 2375/4545 [2:33:12<2:03:53,  3.43s/it] 52%|█████▏    | 2376/4545 [2:33:16<2:09:30,  3.58s/it] 52%|█████▏    | 2377/4545 [2:33:20<2:14:18,  3.72s/it] 52%|█████▏    | 2378/4545 [2:33:24<2:18:52,  3.85s/it] 52%|█████▏    | 2379/4545 [2:33:27<2:17:30,  3.81s/it] 52%|█████▏    | 2380/4545 [2:33:31<2:18:21,  3.83s/it]                                                       {'loss': 0.1054, 'grad_norm': 18.37832260131836, 'learning_rate': 8.309349213020597e-07, 'rewards/chosen': 1.2641112804412842, 'rewards/rejected': -15.540624618530273, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 16.828125, 'logps/chosen': -232.39999389648438, 'logps/rejected': -206.64999389648438, 'logits/chosen': -7.946875095367432, 'logits/rejected': -7.371874809265137, 'epoch': 1.57}
 52%|█████▏    | 2380/4545 [2:33:32<2:18:21,  3.83s/it] 52%|█████▏    | 2381/4545 [2:33:34<2:08:42,  3.57s/it] 52%|█████▏    | 2382/4545 [2:33:38<2:13:58,  3.72s/it] 52%|█████▏    | 2383/4545 [2:33:42<2:18:02,  3.83s/it] 52%|█████▏    | 2384/4545 [2:33:47<2:20:40,  3.91s/it] 52%|█████▏    | 2385/4545 [2:33:50<2:12:38,  3.68s/it] 52%|█████▏    | 2386/4545 [2:33:53<2:08:33,  3.57s/it] 53%|█████▎    | 2387/4545 [2:33:57<2:12:49,  3.69s/it] 53%|█████▎    | 2388/4545 [2:34:01<2:15:03,  3.76s/it] 53%|█████▎    | 2389/4545 [2:34:05<2:16:07,  3.79s/it] 53%|█████▎    | 2390/4545 [2:34:08<2:15:02,  3.76s/it]                                                       {'loss': 0.1534, 'grad_norm': 75.23397827148438, 'learning_rate': 8.272762999177247e-07, 'rewards/chosen': 3.311230421066284, 'rewards/rejected': -9.852685928344727, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 13.149999618530273, 'logps/chosen': -298.20001220703125, 'logps/rejected': -260.1499938964844, 'logits/chosen': -7.974999904632568, 'logits/rejected': -7.643750190734863, 'epoch': 1.58}
 53%|█████▎    | 2390/4545 [2:34:09<2:15:02,  3.76s/it] 53%|█████▎    | 2391/4545 [2:34:12<2:13:02,  3.71s/it] 53%|█████▎    | 2392/4545 [2:34:16<2:10:53,  3.65s/it] 53%|█████▎    | 2393/4545 [2:34:19<2:09:03,  3.60s/it] 53%|█████▎    | 2394/4545 [2:34:23<2:14:02,  3.74s/it] 53%|█████▎    | 2395/4545 [2:34:27<2:16:05,  3.80s/it] 53%|█████▎    | 2396/4545 [2:34:30<2:09:51,  3.63s/it] 53%|█████▎    | 2397/4545 [2:34:34<2:07:24,  3.56s/it] 53%|█████▎    | 2398/4545 [2:34:37<2:01:34,  3.40s/it] 53%|█████▎    | 2399/4545 [2:34:41<2:07:08,  3.55s/it] 53%|█████▎    | 2400/4545 [2:34:45<2:14:22,  3.76s/it]                                                       {'loss': 0.1223, 'grad_norm': 37.87465286254883, 'learning_rate': 8.23587890849623e-07, 'rewards/chosen': 2.0884766578674316, 'rewards/rejected': -10.592187881469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 12.671875, 'logps/chosen': -241.375, 'logps/rejected': -191.0500030517578, 'logits/chosen': -8.181249618530273, 'logits/rejected': -7.831250190734863, 'epoch': 1.58}
 53%|█████▎    | 2400/4545 [2:34:45<2:14:22,  3.76s/it] 53%|█████▎    | 2401/4545 [2:34:49<2:17:01,  3.83s/it] 53%|█████▎    | 2402/4545 [2:34:53<2:17:33,  3.85s/it] 53%|█████▎    | 2403/4545 [2:34:57<2:17:58,  3.86s/it] 53%|█████▎    | 2404/4545 [2:35:01<2:18:26,  3.88s/it] 53%|█████▎    | 2405/4545 [2:35:04<2:18:20,  3.88s/it] 53%|█████▎    | 2406/4545 [2:35:08<2:17:32,  3.86s/it] 53%|█████▎    | 2407/4545 [2:35:11<2:08:14,  3.60s/it] 53%|█████▎    | 2408/4545 [2:35:15<2:10:21,  3.66s/it] 53%|█████▎    | 2409/4545 [2:35:19<2:15:44,  3.81s/it] 53%|█████▎    | 2410/4545 [2:35:23<2:16:33,  3.84s/it]                                                       {'loss': 0.1276, 'grad_norm': 34.33855438232422, 'learning_rate': 8.198700903420888e-07, 'rewards/chosen': 3.7813963890075684, 'rewards/rejected': -14.035937309265137, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 17.787500381469727, 'logps/chosen': -347.5, 'logps/rejected': -259.1000061035156, 'logits/chosen': -8.118749618530273, 'logits/rejected': -7.5, 'epoch': 1.59}
 53%|█████▎    | 2410/4545 [2:35:23<2:16:33,  3.84s/it] 53%|█████▎    | 2411/4545 [2:35:27<2:16:32,  3.84s/it] 53%|█████▎    | 2412/4545 [2:35:31<2:17:07,  3.86s/it] 53%|█████▎    | 2413/4545 [2:35:35<2:17:27,  3.87s/it] 53%|█████▎    | 2414/4545 [2:35:39<2:20:49,  3.97s/it] 53%|█████▎    | 2415/4545 [2:35:43<2:18:54,  3.91s/it] 53%|█████▎    | 2416/4545 [2:35:46<2:15:42,  3.82s/it] 53%|█████▎    | 2417/4545 [2:35:50<2:18:23,  3.90s/it] 53%|█████▎    | 2418/4545 [2:35:54<2:17:53,  3.89s/it] 53%|█████▎    | 2419/4545 [2:35:57<2:10:22,  3.68s/it] 53%|█████▎    | 2420/4545 [2:36:01<2:04:46,  3.52s/it]                                                       {'loss': 0.2247, 'grad_norm': 18.9764404296875, 'learning_rate': 8.161232977969674e-07, 'rewards/chosen': 1.148828148841858, 'rewards/rejected': -10.0390625, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 11.181249618530273, 'logps/chosen': -211.5, 'logps/rejected': -181.75, 'logits/chosen': -8.184374809265137, 'logits/rejected': -7.621874809265137, 'epoch': 1.6}
 53%|█████▎    | 2420/4545 [2:36:01<2:04:46,  3.52s/it] 53%|█████▎    | 2421/4545 [2:36:04<2:06:28,  3.57s/it] 53%|█████▎    | 2422/4545 [2:36:08<2:11:16,  3.71s/it] 53%|█████▎    | 2423/4545 [2:36:12<2:13:43,  3.78s/it] 53%|█████▎    | 2424/4545 [2:36:16<2:14:42,  3.81s/it] 53%|█████▎    | 2425/4545 [2:36:19<2:04:47,  3.53s/it] 53%|█████▎    | 2426/4545 [2:36:23<2:09:42,  3.67s/it] 53%|█████▎    | 2427/4545 [2:36:27<2:11:56,  3.74s/it] 53%|█████▎    | 2428/4545 [2:36:29<1:59:18,  3.38s/it] 53%|█████▎    | 2429/4545 [2:36:33<2:04:50,  3.54s/it] 53%|█████▎    | 2430/4545 [2:36:37<2:04:58,  3.55s/it]                                                       {'loss': 0.1582, 'grad_norm': 17.003036499023438, 'learning_rate': 8.123479157307073e-07, 'rewards/chosen': 2.827435255050659, 'rewards/rejected': -8.081250190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 10.912500381469727, 'logps/chosen': -274.45001220703125, 'logps/rejected': -192.3000030517578, 'logits/chosen': -8.056249618530273, 'logits/rejected': -7.690625190734863, 'epoch': 1.6}
 53%|█████▎    | 2430/4545 [2:36:37<2:04:58,  3.55s/it] 53%|█████▎    | 2431/4545 [2:36:41<2:08:35,  3.65s/it] 54%|█████▎    | 2432/4545 [2:36:45<2:10:42,  3.71s/it] 54%|█████▎    | 2433/4545 [2:36:48<2:09:01,  3.67s/it] 54%|█████▎    | 2434/4545 [2:36:52<2:12:53,  3.78s/it] 54%|█████▎    | 2435/4545 [2:36:55<2:04:35,  3.54s/it] 54%|█████▎    | 2436/4545 [2:36:58<1:56:17,  3.31s/it] 54%|█████▎    | 2437/4545 [2:37:02<2:02:41,  3.49s/it] 54%|█████▎    | 2438/4545 [2:37:06<2:06:18,  3.60s/it] 54%|█████▎    | 2439/4545 [2:37:09<2:06:47,  3.61s/it] 54%|█████▎    | 2440/4545 [2:37:13<2:09:36,  3.69s/it]                                                       {'loss': 0.3089, 'grad_norm': 10.231484413146973, 'learning_rate': 8.085443497311178e-07, 'rewards/chosen': 1.2230621576309204, 'rewards/rejected': -10.003125190734863, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 11.228124618530273, 'logps/chosen': -191.1999969482422, 'logps/rejected': -187.89999389648438, 'logits/chosen': -8.225000381469727, 'logits/rejected': -7.765625, 'epoch': 1.61}
 54%|█████▎    | 2440/4545 [2:37:14<2:09:36,  3.69s/it] 54%|█████▎    | 2441/4545 [2:37:17<2:13:15,  3.80s/it] 54%|█████▎    | 2442/4545 [2:37:21<2:11:14,  3.74s/it] 54%|█████▍    | 2443/4545 [2:37:25<2:12:55,  3.79s/it] 54%|█████▍    | 2444/4545 [2:37:28<2:10:33,  3.73s/it] 54%|█████▍    | 2445/4545 [2:37:32<2:11:47,  3.77s/it] 54%|█████▍    | 2446/4545 [2:37:36<2:12:19,  3.78s/it] 54%|█████▍    | 2447/4545 [2:37:40<2:13:22,  3.81s/it] 54%|█████▍    | 2448/4545 [2:37:44<2:15:56,  3.89s/it] 54%|█████▍    | 2449/4545 [2:37:48<2:16:00,  3.89s/it] 54%|█████▍    | 2450/4545 [2:37:52<2:15:54,  3.89s/it]                                                       {'loss': 0.1612, 'grad_norm': 31.1423397064209, 'learning_rate': 8.047130084137973e-07, 'rewards/chosen': 3.328076124191284, 'rewards/rejected': -9.934374809265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 13.256250381469727, 'logps/chosen': -330.75, 'logps/rejected': -258.04998779296875, 'logits/chosen': -7.918749809265137, 'logits/rejected': -7.496874809265137, 'epoch': 1.62}
 54%|█████▍    | 2450/4545 [2:37:52<2:15:54,  3.89s/it] 54%|█████▍    | 2451/4545 [2:37:55<2:10:10,  3.73s/it] 54%|█████▍    | 2452/4545 [2:37:59<2:06:18,  3.62s/it] 54%|█████▍    | 2453/4545 [2:38:03<2:11:11,  3.76s/it] 54%|█████▍    | 2454/4545 [2:38:07<2:12:35,  3.80s/it] 54%|█████▍    | 2455/4545 [2:38:11<2:13:26,  3.83s/it] 54%|█████▍    | 2456/4545 [2:38:14<2:14:03,  3.85s/it] 54%|█████▍    | 2457/4545 [2:38:18<2:13:45,  3.84s/it] 54%|█████▍    | 2458/4545 [2:38:22<2:14:22,  3.86s/it] 54%|█████▍    | 2459/4545 [2:38:26<2:15:53,  3.91s/it] 54%|█████▍    | 2460/4545 [2:38:30<2:16:54,  3.94s/it]                                                       {'loss': 0.2489, 'grad_norm': 68.51329803466797, 'learning_rate': 8.008543033782354e-07, 'rewards/chosen': 4.227343559265137, 'rewards/rejected': -8.4921875, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 12.715624809265137, 'logps/chosen': -380.79998779296875, 'logps/rejected': -256.25, 'logits/chosen': -7.665625095367432, 'logits/rejected': -7.484375, 'epoch': 1.62}
 54%|█████▍    | 2460/4545 [2:38:30<2:16:54,  3.94s/it] 54%|█████▍    | 2461/4545 [2:38:34<2:14:40,  3.88s/it] 54%|█████▍    | 2462/4545 [2:38:36<1:58:07,  3.40s/it] 54%|█████▍    | 2463/4545 [2:38:40<2:03:11,  3.55s/it] 54%|█████▍    | 2464/4545 [2:38:44<2:06:47,  3.66s/it] 54%|█████▍    | 2465/4545 [2:38:47<2:02:52,  3.54s/it] 54%|█████▍    | 2466/4545 [2:38:51<2:03:40,  3.57s/it] 54%|█████▍    | 2467/4545 [2:38:55<2:09:57,  3.75s/it] 54%|█████▍    | 2468/4545 [2:38:59<2:12:38,  3.83s/it] 54%|█████▍    | 2469/4545 [2:39:03<2:13:14,  3.85s/it] 54%|█████▍    | 2470/4545 [2:39:07<2:11:03,  3.79s/it]                                                       {'loss': 0.1695, 'grad_norm': 44.42247772216797, 'learning_rate': 7.969686491635957e-07, 'rewards/chosen': 1.394433617591858, 'rewards/rejected': -10.771875381469727, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 12.15625, 'logps/chosen': -207.14999389648438, 'logps/rejected': -195.8000030517578, 'logits/chosen': -7.878125190734863, 'logits/rejected': -7.412499904632568, 'epoch': 1.63}
 54%|█████▍    | 2470/4545 [2:39:07<2:11:03,  3.79s/it] 54%|█████▍    | 2471/4545 [2:39:11<2:12:16,  3.83s/it] 54%|█████▍    | 2472/4545 [2:39:14<2:12:46,  3.84s/it] 54%|█████▍    | 2473/4545 [2:39:18<2:12:04,  3.82s/it] 54%|█████▍    | 2474/4545 [2:39:22<2:11:03,  3.80s/it] 54%|█████▍    | 2475/4545 [2:39:26<2:12:21,  3.84s/it] 54%|█████▍    | 2476/4545 [2:39:29<2:07:01,  3.68s/it] 54%|█████▍    | 2477/4545 [2:39:33<2:03:43,  3.59s/it] 55%|█████▍    | 2478/4545 [2:39:36<2:03:28,  3.58s/it] 55%|█████▍    | 2479/4545 [2:39:40<2:02:19,  3.55s/it] 55%|█████▍    | 2480/4545 [2:39:44<2:08:43,  3.74s/it]                                                       {'loss': 0.2184, 'grad_norm': 32.434898376464844, 'learning_rate': 7.930564632041805e-07, 'rewards/chosen': 0.835034191608429, 'rewards/rejected': -7.678124904632568, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 8.512499809265137, 'logps/chosen': -152.10000610351562, 'logps/rejected': -136.8000030517578, 'logits/chosen': -8.0625, 'logits/rejected': -7.640625, 'epoch': 1.64}
 55%|█████▍    | 2480/4545 [2:39:44<2:08:43,  3.74s/it] 55%|█████▍    | 2481/4545 [2:39:48<2:13:27,  3.88s/it] 55%|█████▍    | 2482/4545 [2:39:52<2:11:56,  3.84s/it] 55%|█████▍    | 2483/4545 [2:39:56<2:12:05,  3.84s/it] 55%|█████▍    | 2484/4545 [2:40:00<2:12:44,  3.86s/it] 55%|█████▍    | 2485/4545 [2:40:03<2:13:02,  3.87s/it] 55%|█████▍    | 2486/4545 [2:40:06<1:59:08,  3.47s/it] 55%|█████▍    | 2487/4545 [2:40:09<1:58:25,  3.45s/it] 55%|█████▍    | 2488/4545 [2:40:12<1:54:08,  3.33s/it] 55%|█████▍    | 2489/4545 [2:40:16<1:58:37,  3.46s/it] 55%|█████▍    | 2490/4545 [2:40:19<1:55:06,  3.36s/it]                                                       {'loss': 0.2549, 'grad_norm': 25.662376403808594, 'learning_rate': 7.891181657845882e-07, 'rewards/chosen': 1.38671875, 'rewards/rejected': -11.809374809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 13.203125, 'logps/chosen': -226.35000610351562, 'logps/rejected': -187.35000610351562, 'logits/chosen': -8.015625, 'logits/rejected': -7.634375095367432, 'epoch': 1.64}
 55%|█████▍    | 2490/4545 [2:40:19<1:55:06,  3.36s/it] 55%|█████▍    | 2491/4545 [2:40:23<2:01:00,  3.53s/it] 55%|█████▍    | 2492/4545 [2:40:27<2:01:31,  3.55s/it] 55%|█████▍    | 2493/4545 [2:40:31<2:04:21,  3.64s/it] 55%|█████▍    | 2494/4545 [2:40:34<2:04:17,  3.64s/it] 55%|█████▍    | 2495/4545 [2:40:38<2:06:30,  3.70s/it] 55%|█████▍    | 2496/4545 [2:40:42<2:08:34,  3.77s/it] 55%|█████▍    | 2497/4545 [2:40:46<2:13:13,  3.90s/it] 55%|█████▍    | 2498/4545 [2:40:50<2:07:26,  3.74s/it] 55%|█████▍    | 2499/4545 [2:40:54<2:09:03,  3.78s/it] 55%|█████▌    | 2500/4545 [2:40:57<2:08:55,  3.78s/it]                                                       {'loss': 0.2985, 'grad_norm': 34.884254455566406, 'learning_rate': 7.851541799945603e-07, 'rewards/chosen': 1.344824194908142, 'rewards/rejected': -8.506250381469727, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 9.856249809265137, 'logps/chosen': -203.6999969482422, 'logps/rejected': -195.35000610351562, 'logits/chosen': -7.9375, 'logits/rejected': -7.453125, 'epoch': 1.65}
 55%|█████▌    | 2500/4545 [2:40:57<2:08:55,  3.78s/it] 55%|█████▌    | 2501/4545 [2:41:01<2:05:53,  3.70s/it] 55%|█████▌    | 2502/4545 [2:41:05<2:08:14,  3.77s/it] 55%|█████▌    | 2503/4545 [2:41:08<1:59:25,  3.51s/it] 55%|█████▌    | 2504/4545 [2:41:12<2:06:23,  3.72s/it] 55%|█████▌    | 2505/4545 [2:41:16<2:08:00,  3.76s/it] 55%|█████▌    | 2506/4545 [2:41:20<2:09:24,  3.81s/it] 55%|█████▌    | 2507/4545 [2:41:24<2:09:57,  3.83s/it] 55%|█████▌    | 2508/4545 [2:41:27<2:10:16,  3.84s/it] 55%|█████▌    | 2509/4545 [2:41:30<2:02:54,  3.62s/it] 55%|█████▌    | 2510/4545 [2:41:33<1:47:21,  3.17s/it]                                                       {'loss': 0.1367, 'grad_norm': 20.244951248168945, 'learning_rate': 7.811649316835297e-07, 'rewards/chosen': 4.467577934265137, 'rewards/rejected': -9.6953125, 'rewards/accuracies': 0.9375, 'rewards/margins': 14.15625, 'logps/chosen': -367.6000061035156, 'logps/rejected': -199.14999389648438, 'logits/chosen': -7.703125, 'logits/rejected': -7.365624904632568, 'epoch': 1.66}
 55%|█████▌    | 2510/4545 [2:41:33<1:47:21,  3.17s/it] 55%|█████▌    | 2511/4545 [2:41:36<1:49:32,  3.23s/it] 55%|█████▌    | 2512/4545 [2:41:40<1:59:07,  3.52s/it] 55%|█████▌    | 2513/4545 [2:41:44<2:02:53,  3.63s/it] 55%|█████▌    | 2514/4545 [2:41:48<2:07:36,  3.77s/it] 55%|█████▌    | 2515/4545 [2:41:52<2:09:21,  3.82s/it] 55%|█████▌    | 2516/4545 [2:41:56<2:09:59,  3.84s/it] 55%|█████▌    | 2517/4545 [2:41:59<2:06:30,  3.74s/it] 55%|█████▌    | 2518/4545 [2:42:03<2:07:46,  3.78s/it] 55%|█████▌    | 2519/4545 [2:42:07<2:09:01,  3.82s/it] 55%|█████▌    | 2520/4545 [2:42:11<2:04:50,  3.70s/it]                                                       {'loss': 0.1329, 'grad_norm': 30.759836196899414, 'learning_rate': 7.771508494148728e-07, 'rewards/chosen': 4.130639553070068, 'rewards/rejected': -12.112500190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 16.246875762939453, 'logps/chosen': -386.8500061035156, 'logps/rejected': -235.39999389648438, 'logits/chosen': -7.706250190734863, 'logits/rejected': -7.293749809265137, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [2:42:11<2:04:50,  3.70s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:36,  1.58it/s][A
  5%|▌         | 3/60 [00:02<00:58,  1.03s/it][A
  7%|▋         | 4/60 [00:04<01:10,  1.27s/it][A
  8%|▊         | 5/60 [00:06<01:15,  1.37s/it][A
 10%|█         | 6/60 [00:07<01:18,  1.46s/it][A
 12%|█▏        | 7/60 [00:09<01:19,  1.51s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:12<01:22,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.65s/it][A
 25%|██▌       | 15/60 [00:22<01:09,  1.54s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.39s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:46,  1.10s/it][A
 32%|███▏      | 19/60 [00:26<00:47,  1.16s/it][A
 33%|███▎      | 20/60 [00:27<00:40,  1.01s/it][A
 35%|███▌      | 21/60 [00:28<00:39,  1.01s/it][A
 37%|███▋      | 22/60 [00:29<00:41,  1.10s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.12s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.10s/it][A
 42%|████▏     | 25/60 [00:33<00:44,  1.26s/it][A
 43%|████▎     | 26/60 [00:34<00:45,  1.32s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.17s/it][A
 47%|████▋     | 28/60 [00:36<00:35,  1.10s/it][A
 48%|████▊     | 29/60 [00:37<00:35,  1.13s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.30s/it][A
 52%|█████▏    | 31/60 [00:40<00:40,  1.38s/it][A
 53%|█████▎    | 32/60 [00:42<00:39,  1.40s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.38s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.22s/it][A
 58%|█████▊    | 35/60 [00:46<00:32,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.26s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.40s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.46s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A                                                       
                                               [A{'eval_loss': 0.3632671535015106, 'eval_runtime': 80.9857, 'eval_samples_per_second': 11.768, 'eval_steps_per_second': 0.741, 'eval_rewards/chosen': 3.2430684566497803, 'eval_rewards/rejected': -8.471354484558105, 'eval_rewards/accuracies': 0.8521990180015564, 'eval_rewards/margins': 11.713769912719727, 'eval_logps/chosen': -361.3166809082031, 'eval_logps/rejected': -194.40415954589844, 'eval_logits/chosen': -7.666666507720947, 'eval_logits/rejected': -7.845312595367432, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [2:43:32<2:04:50,  3.70s/it]
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 55%|█████▌    | 2521/4545 [2:43:49<18:00:12, 32.02s/it] 55%|█████▌    | 2522/4545 [2:43:53<13:14:57, 23.58s/it] 56%|█████▌    | 2523/4545 [2:43:57<9:55:41, 17.68s/it]  56%|█████▌    | 2524/4545 [2:44:00<7:33:35, 13.47s/it] 56%|█████▌    | 2525/4545 [2:44:03<5:45:41, 10.27s/it] 56%|█████▌    | 2526/4545 [2:44:07<4:44:37,  8.46s/it] 56%|█████▌    | 2527/4545 [2:44:11<3:52:53,  6.92s/it] 56%|█████▌    | 2528/4545 [2:44:14<3:16:58,  5.86s/it] 56%|█████▌    | 2529/4545 [2:44:18<2:58:28,  5.31s/it] 56%|█████▌    | 2530/4545 [2:44:22<2:44:01,  4.88s/it]                                                       {'loss': 0.1815, 'grad_norm': 33.46284484863281, 'learning_rate': 7.731123644198677e-07, 'rewards/chosen': 2.652539014816284, 'rewards/rejected': -11.775976181030273, 'rewards/accuracies': 0.9375, 'rewards/margins': 14.431249618530273, 'logps/chosen': -289.17498779296875, 'logps/rejected': -248.77499389648438, 'logits/chosen': -7.9375, 'logits/rejected': -7.612500190734863, 'epoch': 1.67}
 56%|█████▌    | 2530/4545 [2:44:22<2:44:01,  4.88s/it] 56%|█████▌    | 2531/4545 [2:44:26<2:34:20,  4.60s/it] 56%|█████▌    | 2532/4545 [2:44:30<2:28:09,  4.42s/it] 56%|█████▌    | 2533/4545 [2:44:34<2:21:07,  4.21s/it] 56%|█████▌    | 2534/4545 [2:44:38<2:19:24,  4.16s/it] 56%|█████▌    | 2535/4545 [2:44:40<2:02:42,  3.66s/it] 56%|█████▌    | 2536/4545 [2:44:44<2:05:03,  3.73s/it] 56%|█████▌    | 2537/4545 [2:44:48<2:06:30,  3.78s/it] 56%|█████▌    | 2538/4545 [2:44:51<1:54:55,  3.44s/it] 56%|█████▌    | 2539/4545 [2:44:55<2:00:24,  3.60s/it] 56%|█████▌    | 2540/4545 [2:44:57<1:49:55,  3.29s/it]                                                       {'loss': 0.3206, 'grad_norm': 49.6837272644043, 'learning_rate': 7.690499105513678e-07, 'rewards/chosen': 3.990954637527466, 'rewards/rejected': -8.09375, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 12.087499618530273, 'logps/chosen': -344.8999938964844, 'logps/rejected': -205.10000610351562, 'logits/chosen': -7.996874809265137, 'logits/rejected': -7.515625, 'epoch': 1.68}
 56%|█████▌    | 2540/4545 [2:44:57<1:49:55,  3.29s/it] 56%|█████▌    | 2541/4545 [2:45:01<1:57:58,  3.53s/it] 56%|█████▌    | 2542/4545 [2:45:04<1:46:53,  3.20s/it] 56%|█████▌    | 2543/4545 [2:45:08<1:54:59,  3.45s/it] 56%|█████▌    | 2544/4545 [2:45:12<2:00:28,  3.61s/it] 56%|█████▌    | 2545/4545 [2:45:16<2:03:20,  3.70s/it] 56%|█████▌    | 2546/4545 [2:45:18<1:51:54,  3.36s/it] 56%|█████▌    | 2547/4545 [2:45:22<1:59:24,  3.59s/it] 56%|█████▌    | 2548/4545 [2:45:26<2:02:32,  3.68s/it] 56%|█████▌    | 2549/4545 [2:45:30<2:04:40,  3.75s/it] 56%|█████▌    | 2550/4545 [2:45:34<2:05:13,  3.77s/it]                                                       {'loss': 0.1778, 'grad_norm': 40.93476104736328, 'learning_rate': 7.649639242371933e-07, 'rewards/chosen': 1.9557616710662842, 'rewards/rejected': -9.196874618530273, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 11.162500381469727, 'logps/chosen': -223.39999389648438, 'logps/rejected': -176.25, 'logits/chosen': -8.034375190734863, 'logits/rejected': -7.574999809265137, 'epoch': 1.68}
 56%|█████▌    | 2550/4545 [2:45:34<2:05:13,  3.77s/it] 56%|█████▌    | 2551/4545 [2:45:38<2:06:49,  3.82s/it] 56%|█████▌    | 2552/4545 [2:45:42<2:09:43,  3.91s/it] 56%|█████▌    | 2553/4545 [2:45:46<2:11:29,  3.96s/it] 56%|█████▌    | 2554/4545 [2:45:50<2:10:54,  3.95s/it] 56%|█████▌    | 2555/4545 [2:45:54<2:10:31,  3.94s/it] 56%|█████▌    | 2556/4545 [2:45:58<2:09:34,  3.91s/it] 56%|█████▋    | 2557/4545 [2:46:02<2:09:36,  3.91s/it] 56%|█████▋    | 2558/4545 [2:46:06<2:10:18,  3.93s/it] 56%|█████▋    | 2559/4545 [2:46:09<2:03:51,  3.74s/it] 56%|█████▋    | 2560/4545 [2:46:12<2:03:06,  3.72s/it]                                                       {'loss': 0.309, 'grad_norm': 49.52008819580078, 'learning_rate': 7.608548444332459e-07, 'rewards/chosen': 3.3140625953674316, 'rewards/rejected': -7.390625, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 10.693750381469727, 'logps/chosen': -350.25, 'logps/rejected': -234.4499969482422, 'logits/chosen': -7.71875, 'logits/rejected': -7.390625, 'epoch': 1.69}
 56%|█████▋    | 2560/4545 [2:46:13<2:03:06,  3.72s/it] 56%|█████▋    | 2561/4545 [2:46:15<1:51:59,  3.39s/it] 56%|█████▋    | 2562/4545 [2:46:19<1:58:50,  3.60s/it] 56%|█████▋    | 2563/4545 [2:46:21<1:42:19,  3.10s/it] 56%|█████▋    | 2564/4545 [2:46:25<1:51:22,  3.37s/it] 56%|█████▋    | 2565/4545 [2:46:29<1:58:07,  3.58s/it] 56%|█████▋    | 2566/4545 [2:46:33<1:56:19,  3.53s/it] 56%|█████▋    | 2567/4545 [2:46:36<1:57:45,  3.57s/it] 57%|█████▋    | 2568/4545 [2:46:40<1:58:32,  3.60s/it] 57%|█████▋    | 2569/4545 [2:46:44<1:59:57,  3.64s/it] 57%|█████▋    | 2570/4545 [2:46:47<1:53:39,  3.45s/it]                                                       {'loss': 0.1395, 'grad_norm': 19.448150634765625, 'learning_rate': 7.567231125763513e-07, 'rewards/chosen': 1.237335205078125, 'rewards/rejected': -10.050000190734863, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 11.290624618530273, 'logps/chosen': -161.9250030517578, 'logps/rejected': -163.6999969482422, 'logits/chosen': -8.050000190734863, 'logits/rejected': -7.400000095367432, 'epoch': 1.7}
 57%|█████▋    | 2570/4545 [2:46:47<1:53:39,  3.45s/it] 57%|█████▋    | 2571/4545 [2:46:50<1:54:49,  3.49s/it] 57%|█████▋    | 2572/4545 [2:46:54<1:55:37,  3.52s/it] 57%|█████▋    | 2573/4545 [2:46:57<1:53:33,  3.45s/it] 57%|█████▋    | 2574/4545 [2:47:01<1:59:54,  3.65s/it] 57%|█████▋    | 2575/4545 [2:47:05<2:02:04,  3.72s/it] 57%|█████▋    | 2576/4545 [2:47:09<2:02:24,  3.73s/it] 57%|█████▋    | 2577/4545 [2:47:13<2:03:34,  3.77s/it] 57%|█████▋    | 2578/4545 [2:47:17<2:04:42,  3.80s/it] 57%|█████▋    | 2579/4545 [2:47:20<2:04:19,  3.79s/it] 57%|█████▋    | 2580/4545 [2:47:24<2:05:18,  3.83s/it]                                                       {'loss': 0.1487, 'grad_norm': 31.545246124267578, 'learning_rate': 7.52569172536837e-07, 'rewards/chosen': 2.094043016433716, 'rewards/rejected': -16.875, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 18.987499237060547, 'logps/chosen': -258.75, 'logps/rejected': -209.8000030517578, 'logits/chosen': -8.046875, 'logits/rejected': -7.640625, 'epoch': 1.7}
 57%|█████▋    | 2580/4545 [2:47:25<2:05:18,  3.83s/it] 57%|█████▋    | 2581/4545 [2:47:29<2:09:50,  3.97s/it] 57%|█████▋    | 2582/4545 [2:47:32<2:08:57,  3.94s/it] 57%|█████▋    | 2583/4545 [2:47:36<2:08:09,  3.92s/it] 57%|█████▋    | 2584/4545 [2:47:40<2:04:23,  3.81s/it] 57%|█████▋    | 2585/4545 [2:47:44<2:03:30,  3.78s/it] 57%|█████▋    | 2586/4545 [2:47:48<2:04:38,  3.82s/it] 57%|█████▋    | 2587/4545 [2:47:51<1:56:47,  3.58s/it] 57%|█████▋    | 2588/4545 [2:47:54<1:59:52,  3.68s/it] 57%|█████▋    | 2589/4545 [2:47:59<2:03:46,  3.80s/it] 57%|█████▋    | 2590/4545 [2:48:02<2:05:09,  3.84s/it]                                                       {'loss': 0.2872, 'grad_norm': 20.869224548339844, 'learning_rate': 7.48393470570846e-07, 'rewards/chosen': 2.182421922683716, 'rewards/rejected': -10.828125, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 13.006250381469727, 'logps/chosen': -281.25, 'logps/rejected': -180.3000030517578, 'logits/chosen': -7.849999904632568, 'logits/rejected': -7.449999809265137, 'epoch': 1.71}
 57%|█████▋    | 2590/4545 [2:48:03<2:05:09,  3.84s/it] 57%|█████▋    | 2591/4545 [2:48:06<2:03:49,  3.80s/it] 57%|█████▋    | 2592/4545 [2:48:10<2:04:53,  3.84s/it] 57%|█████▋    | 2593/4545 [2:48:13<1:58:00,  3.63s/it] 57%|█████▋    | 2594/4545 [2:48:17<2:00:30,  3.71s/it] 57%|█████▋    | 2595/4545 [2:48:21<2:04:06,  3.82s/it] 57%|█████▋    | 2596/4545 [2:48:25<2:04:48,  3.84s/it] 57%|█████▋    | 2597/4545 [2:48:29<2:01:33,  3.74s/it] 57%|█████▋    | 2598/4545 [2:48:33<2:03:25,  3.80s/it] 57%|█████▋    | 2599/4545 [2:48:37<2:05:09,  3.86s/it] 57%|█████▋    | 2600/4545 [2:48:40<2:05:49,  3.88s/it]                                                       {'loss': 0.146, 'grad_norm': 39.901248931884766, 'learning_rate': 7.441964552723977e-07, 'rewards/chosen': 5.135790824890137, 'rewards/rejected': -11.962499618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 17.121875762939453, 'logps/chosen': -441.54998779296875, 'logps/rejected': -295.6499938964844, 'logits/chosen': -7.515625, 'logits/rejected': -7.178124904632568, 'epoch': 1.72}
 57%|█████▋    | 2600/4545 [2:48:41<2:05:49,  3.88s/it] 57%|█████▋    | 2601/4545 [2:48:45<2:08:22,  3.96s/it] 57%|█████▋    | 2602/4545 [2:48:48<2:05:02,  3.86s/it] 57%|█████▋    | 2603/4545 [2:48:52<2:01:29,  3.75s/it] 57%|█████▋    | 2604/4545 [2:48:56<2:02:25,  3.78s/it] 57%|█████▋    | 2605/4545 [2:49:00<2:04:35,  3.85s/it] 57%|█████▋    | 2606/4545 [2:49:04<2:05:11,  3.87s/it] 57%|█████▋    | 2607/4545 [2:49:07<2:04:59,  3.87s/it] 57%|█████▋    | 2608/4545 [2:49:10<1:52:16,  3.48s/it] 57%|█████▋    | 2609/4545 [2:49:14<1:54:22,  3.54s/it] 57%|█████▋    | 2610/4545 [2:49:18<1:59:00,  3.69s/it]                                                       {'loss': 0.2025, 'grad_norm': 25.48260498046875, 'learning_rate': 7.399785775251933e-07, 'rewards/chosen': 0.697949230670929, 'rewards/rejected': -10.0703125, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 10.774999618530273, 'logps/chosen': -171.75, 'logps/rejected': -196.3000030517578, 'logits/chosen': -7.959374904632568, 'logits/rejected': -7.528124809265137, 'epoch': 1.72}
 57%|█████▋    | 2610/4545 [2:49:18<1:59:00,  3.69s/it] 57%|█████▋    | 2611/4545 [2:49:22<2:01:32,  3.77s/it] 57%|█████▋    | 2612/4545 [2:49:26<2:02:42,  3.81s/it] 57%|█████▋    | 2613/4545 [2:49:30<2:06:26,  3.93s/it] 58%|█████▊    | 2614/4545 [2:49:34<2:08:24,  3.99s/it] 58%|█████▊    | 2615/4545 [2:49:38<2:07:33,  3.97s/it] 58%|█████▊    | 2616/4545 [2:49:42<2:06:51,  3.95s/it] 58%|█████▊    | 2617/4545 [2:49:45<1:59:43,  3.73s/it] 58%|█████▊    | 2618/4545 [2:49:49<2:01:22,  3.78s/it] 58%|█████▊    | 2619/4545 [2:49:52<1:59:12,  3.71s/it] 58%|█████▊    | 2620/4545 [2:49:55<1:51:01,  3.46s/it]                                                       {'loss': 0.1532, 'grad_norm': 28.093997955322266, 'learning_rate': 7.357402904541789e-07, 'rewards/chosen': 4.394021511077881, 'rewards/rejected': -6.640625, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.050000190734863, 'logps/chosen': -343.9750061035156, 'logps/rejected': -234.4499969482422, 'logits/chosen': -7.853125095367432, 'logits/rejected': -7.3125, 'epoch': 1.73}
 58%|█████▊    | 2620/4545 [2:49:56<1:51:01,  3.46s/it] 58%|█████▊    | 2621/4545 [2:49:59<1:49:23,  3.41s/it] 58%|█████▊    | 2622/4545 [2:50:03<1:54:31,  3.57s/it] 58%|█████▊    | 2623/4545 [2:50:06<1:51:57,  3.50s/it] 58%|█████▊    | 2624/4545 [2:50:10<1:59:21,  3.73s/it] 58%|█████▊    | 2625/4545 [2:50:14<2:00:40,  3.77s/it] 58%|█████▊    | 2626/4545 [2:50:18<2:02:01,  3.82s/it] 58%|█████▊    | 2627/4545 [2:50:22<2:04:49,  3.91s/it] 58%|█████▊    | 2628/4545 [2:50:24<1:50:08,  3.45s/it] 58%|█████▊    | 2629/4545 [2:50:28<1:47:41,  3.37s/it] 58%|█████▊    | 2630/4545 [2:50:31<1:48:52,  3.41s/it]                                                       {'loss': 0.1911, 'grad_norm': 24.7930965423584, 'learning_rate': 7.314820493768667e-07, 'rewards/chosen': 2.3783202171325684, 'rewards/rejected': -11.925000190734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 14.300000190734863, 'logps/chosen': -313.8999938964844, 'logps/rejected': -212.85000610351562, 'logits/chosen': -7.803124904632568, 'logits/rejected': -7.268750190734863, 'epoch': 1.74}
 58%|█████▊    | 2630/4545 [2:50:31<1:48:52,  3.41s/it] 58%|█████▊    | 2631/4545 [2:50:35<1:53:49,  3.57s/it] 58%|█████▊    | 2632/4545 [2:50:39<1:59:02,  3.73s/it] 58%|█████▊    | 2633/4545 [2:50:43<1:59:31,  3.75s/it] 58%|█████▊    | 2634/4545 [2:50:47<2:00:54,  3.80s/it] 58%|█████▊    | 2635/4545 [2:50:51<2:04:45,  3.92s/it] 58%|█████▊    | 2636/4545 [2:50:54<1:59:43,  3.76s/it] 58%|█████▊    | 2637/4545 [2:50:59<2:03:54,  3.90s/it] 58%|█████▊    | 2638/4545 [2:51:03<2:03:45,  3.89s/it] 58%|█████▊    | 2639/4545 [2:51:06<2:03:14,  3.88s/it] 58%|█████▊    | 2640/4545 [2:51:10<2:03:21,  3.89s/it]                                                       {'loss': 0.1571, 'grad_norm': 21.878637313842773, 'learning_rate': 7.272043117544195e-07, 'rewards/chosen': 3.0355467796325684, 'rewards/rejected': -10.685937881469727, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 13.712499618530273, 'logps/chosen': -306.3500061035156, 'logps/rejected': -194.3000030517578, 'logits/chosen': -7.809374809265137, 'logits/rejected': -7.265625, 'epoch': 1.74}
 58%|█████▊    | 2640/4545 [2:51:11<2:03:21,  3.89s/it] 58%|█████▊    | 2641/4545 [2:51:14<2:06:22,  3.98s/it] 58%|█████▊    | 2642/4545 [2:51:18<2:05:14,  3.95s/it] 58%|█████▊    | 2643/4545 [2:51:22<2:02:14,  3.86s/it] 58%|█████▊    | 2644/4545 [2:51:25<1:56:33,  3.68s/it] 58%|█████▊    | 2645/4545 [2:51:29<1:58:41,  3.75s/it] 58%|█████▊    | 2646/4545 [2:51:33<2:00:12,  3.80s/it] 58%|█████▊    | 2647/4545 [2:51:37<2:01:10,  3.83s/it] 58%|█████▊    | 2648/4545 [2:51:41<2:01:46,  3.85s/it] 58%|█████▊    | 2649/4545 [2:51:45<2:02:15,  3.87s/it] 58%|█████▊    | 2650/4545 [2:51:49<2:02:23,  3.88s/it]                                                       {'loss': 0.0956, 'grad_norm': 29.710845947265625, 'learning_rate': 7.229075371425066e-07, 'rewards/chosen': 5.010156154632568, 'rewards/rejected': -11.892969131469727, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 16.912500381469727, 'logps/chosen': -377.95001220703125, 'logps/rejected': -246.3000030517578, 'logits/chosen': -7.746874809265137, 'logits/rejected': -7.521874904632568, 'epoch': 1.75}
 58%|█████▊    | 2650/4545 [2:51:49<2:02:23,  3.88s/it] 58%|█████▊    | 2651/4545 [2:51:53<2:01:44,  3.86s/it] 58%|█████▊    | 2652/4545 [2:51:56<2:02:02,  3.87s/it] 58%|█████▊    | 2653/4545 [2:52:01<2:04:25,  3.95s/it] 58%|█████▊    | 2654/4545 [2:52:04<2:04:06,  3.94s/it] 58%|█████▊    | 2655/4545 [2:52:08<2:02:12,  3.88s/it] 58%|█████▊    | 2656/4545 [2:52:12<2:05:04,  3.97s/it] 58%|█████▊    | 2657/4545 [2:52:16<2:00:56,  3.84s/it] 58%|█████▊    | 2658/4545 [2:52:20<2:01:11,  3.85s/it] 59%|█████▊    | 2659/4545 [2:52:24<1:59:50,  3.81s/it] 59%|█████▊    | 2660/4545 [2:52:27<2:00:26,  3.83s/it]                                                       {'loss': 0.1529, 'grad_norm': 6.610660076141357, 'learning_rate': 7.185921871419329e-07, 'rewards/chosen': 2.929248094558716, 'rewards/rejected': -14.393750190734863, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 17.309375762939453, 'logps/chosen': -347.8999938964844, 'logps/rejected': -250.8000030517578, 'logits/chosen': -7.815625190734863, 'logits/rejected': -7.387499809265137, 'epoch': 1.76}
 59%|█████▊    | 2660/4545 [2:52:28<2:00:26,  3.83s/it] 59%|█████▊    | 2661/4545 [2:52:31<1:56:55,  3.72s/it] 59%|█████▊    | 2662/4545 [2:52:35<1:58:01,  3.76s/it] 59%|█████▊    | 2663/4545 [2:52:38<1:57:15,  3.74s/it] 59%|█████▊    | 2664/4545 [2:52:42<1:58:41,  3.79s/it] 59%|█████▊    | 2665/4545 [2:52:46<1:57:06,  3.74s/it] 59%|█████▊    | 2666/4545 [2:52:50<2:00:33,  3.85s/it] 59%|█████▊    | 2667/4545 [2:52:54<2:02:47,  3.92s/it] 59%|█████▊    | 2668/4545 [2:52:58<2:04:29,  3.98s/it] 59%|█████▊    | 2669/4545 [2:53:02<2:04:25,  3.98s/it] 59%|█████▊    | 2670/4545 [2:53:04<1:47:38,  3.44s/it]                                                       {'loss': 0.2501, 'grad_norm': 37.90862274169922, 'learning_rate': 7.142587253490511e-07, 'rewards/chosen': 1.90869140625, 'rewards/rejected': -11.587499618530273, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 13.493749618530273, 'logps/chosen': -308.75, 'logps/rejected': -227.5500030517578, 'logits/chosen': -8.071874618530273, 'logits/rejected': -7.684374809265137, 'epoch': 1.76}
 59%|█████▊    | 2670/4545 [2:53:05<1:47:38,  3.44s/it] 59%|█████▉    | 2671/4545 [2:53:07<1:42:13,  3.27s/it] 59%|█████▉    | 2672/4545 [2:53:11<1:47:55,  3.46s/it] 59%|█████▉    | 2673/4545 [2:53:15<1:50:08,  3.53s/it] 59%|█████▉    | 2674/4545 [2:53:19<1:53:40,  3.65s/it] 59%|█████▉    | 2675/4545 [2:53:23<1:56:06,  3.73s/it] 59%|█████▉    | 2676/4545 [2:53:27<1:57:47,  3.78s/it] 59%|█████▉    | 2677/4545 [2:53:30<1:57:09,  3.76s/it] 59%|█████▉    | 2678/4545 [2:53:34<1:58:31,  3.81s/it] 59%|█████▉    | 2679/4545 [2:53:38<1:57:11,  3.77s/it] 59%|█████▉    | 2680/4545 [2:53:42<1:58:22,  3.81s/it]                                                       {'loss': 0.1524, 'grad_norm': 42.34480285644531, 'learning_rate': 7.099076173059557e-07, 'rewards/chosen': 3.31298828125, 'rewards/rejected': -12.248827934265137, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 15.556249618530273, 'logps/chosen': -317.45001220703125, 'logps/rejected': -246.35000610351562, 'logits/chosen': -7.878125190734863, 'logits/rejected': -7.331250190734863, 'epoch': 1.77}
 59%|█████▉    | 2680/4545 [2:53:42<1:58:22,  3.81s/it] 59%|█████▉    | 2681/4545 [2:53:46<1:59:41,  3.85s/it] 59%|█████▉    | 2682/4545 [2:53:50<2:01:17,  3.91s/it] 59%|█████▉    | 2683/4545 [2:53:54<2:02:21,  3.94s/it] 59%|█████▉    | 2684/4545 [2:53:58<2:03:53,  3.99s/it] 59%|█████▉    | 2685/4545 [2:54:02<2:04:03,  4.00s/it] 59%|█████▉    | 2686/4545 [2:54:06<2:06:40,  4.09s/it] 59%|█████▉    | 2687/4545 [2:54:10<2:07:29,  4.12s/it] 59%|█████▉    | 2688/4545 [2:54:14<2:05:26,  4.05s/it] 59%|█████▉    | 2689/4545 [2:54:17<1:51:33,  3.61s/it] 59%|█████▉    | 2690/4545 [2:54:21<1:54:51,  3.71s/it]                                                       {'loss': 0.2489, 'grad_norm': 38.64493179321289, 'learning_rate': 7.055393304504711e-07, 'rewards/chosen': 3.520312547683716, 'rewards/rejected': -10.084375381469727, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 13.618749618530273, 'logps/chosen': -329.75, 'logps/rejected': -251.1999969482422, 'logits/chosen': -8.084375381469727, 'logits/rejected': -7.6875, 'epoch': 1.78}
 59%|█████▉    | 2690/4545 [2:54:21<1:54:51,  3.71s/it] 59%|█████▉    | 2691/4545 [2:54:25<1:58:44,  3.84s/it] 59%|█████▉    | 2692/4545 [2:54:29<1:58:52,  3.85s/it] 59%|█████▉    | 2693/4545 [2:54:33<1:59:12,  3.86s/it] 59%|█████▉    | 2694/4545 [2:54:37<1:58:10,  3.83s/it] 59%|█████▉    | 2695/4545 [2:54:40<1:55:44,  3.75s/it] 59%|█████▉    | 2696/4545 [2:54:43<1:45:17,  3.42s/it] 59%|█████▉    | 2697/4545 [2:54:47<1:49:18,  3.55s/it] 59%|█████▉    | 2698/4545 [2:54:51<1:52:31,  3.66s/it] 59%|█████▉    | 2699/4545 [2:54:53<1:45:34,  3.43s/it] 59%|█████▉    | 2700/4545 [2:54:57<1:51:15,  3.62s/it]                                                       {'loss': 0.2498, 'grad_norm': 15.216946601867676, 'learning_rate': 7.011543340659352e-07, 'rewards/chosen': 2.212890625, 'rewards/rejected': -10.634374618530273, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 12.862500190734863, 'logps/chosen': -271.0, 'logps/rejected': -189.75, 'logits/chosen': -8.162500381469727, 'logits/rejected': -7.787499904632568, 'epoch': 1.78}
 59%|█████▉    | 2700/4545 [2:54:58<1:51:15,  3.62s/it] 59%|█████▉    | 2701/4545 [2:55:01<1:48:32,  3.53s/it] 59%|█████▉    | 2702/4545 [2:55:04<1:44:28,  3.40s/it] 59%|█████▉    | 2703/4545 [2:55:08<1:51:53,  3.64s/it] 59%|█████▉    | 2704/4545 [2:55:12<1:54:11,  3.72s/it] 60%|█████▉    | 2705/4545 [2:55:16<1:55:45,  3.77s/it] 60%|█████▉    | 2706/4545 [2:55:20<1:55:41,  3.77s/it] 60%|█████▉    | 2707/4545 [2:55:24<1:56:55,  3.82s/it] 60%|█████▉    | 2708/4545 [2:55:28<1:59:03,  3.89s/it] 60%|█████▉    | 2709/4545 [2:55:31<1:56:21,  3.80s/it] 60%|█████▉    | 2710/4545 [2:55:35<1:53:53,  3.72s/it]                                                       {'loss': 0.1681, 'grad_norm': 31.142505645751953, 'learning_rate': 6.967530992307832e-07, 'rewards/chosen': 1.491430640220642, 'rewards/rejected': -10.421875, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 11.925000190734863, 'logps/chosen': -222.64999389648438, 'logps/rejected': -182.89999389648438, 'logits/chosen': -8.162500381469727, 'logits/rejected': -7.8125, 'epoch': 1.79}
 60%|█████▉    | 2710/4545 [2:55:35<1:53:53,  3.72s/it] 60%|█████▉    | 2711/4545 [2:55:39<1:56:06,  3.80s/it] 60%|█████▉    | 2712/4545 [2:55:42<1:52:53,  3.70s/it] 60%|█████▉    | 2713/4545 [2:55:46<1:55:25,  3.78s/it] 60%|█████▉    | 2714/4545 [2:55:50<1:56:39,  3.82s/it] 60%|█████▉    | 2715/4545 [2:55:54<1:55:59,  3.80s/it] 60%|█████▉    | 2716/4545 [2:55:57<1:48:11,  3.55s/it] 60%|█████▉    | 2717/4545 [2:56:01<1:51:25,  3.66s/it] 60%|█████▉    | 2718/4545 [2:56:05<1:53:27,  3.73s/it] 60%|█████▉    | 2719/4545 [2:56:08<1:53:55,  3.74s/it] 60%|█████▉    | 2720/4545 [2:56:12<1:55:41,  3.80s/it]                                                       {'loss': 0.269, 'grad_norm': 25.920934677124023, 'learning_rate': 6.923360987679417e-07, 'rewards/chosen': 1.6707031726837158, 'rewards/rejected': -9.387499809265137, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 11.078125, 'logps/chosen': -231.10000610351562, 'logps/rejected': -170.35000610351562, 'logits/chosen': -8.024999618530273, 'logits/rejected': -7.628125190734863, 'epoch': 1.8}
 60%|█████▉    | 2720/4545 [2:56:13<1:55:41,  3.80s/it] 60%|█████▉    | 2721/4545 [2:56:14<1:36:52,  3.19s/it] 60%|█████▉    | 2722/4545 [2:56:18<1:44:13,  3.43s/it] 60%|█████▉    | 2723/4545 [2:56:22<1:48:16,  3.57s/it] 60%|█████▉    | 2724/4545 [2:56:25<1:47:25,  3.54s/it] 60%|█████▉    | 2725/4545 [2:56:29<1:47:55,  3.56s/it] 60%|█████▉    | 2726/4545 [2:56:33<1:53:35,  3.75s/it] 60%|██████    | 2727/4545 [2:56:37<1:54:53,  3.79s/it] 60%|██████    | 2728/4545 [2:56:41<1:53:28,  3.75s/it] 60%|██████    | 2729/4545 [2:56:44<1:50:14,  3.64s/it] 60%|██████    | 2730/4545 [2:56:48<1:52:29,  3.72s/it]                                                       {'loss': 0.1978, 'grad_norm': 15.095955848693848, 'learning_rate': 6.879038071940314e-07, 'rewards/chosen': 2.107836961746216, 'rewards/rejected': -9.831250190734863, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 11.949999809265137, 'logps/chosen': -223.125, 'logps/rejected': -178.0500030517578, 'logits/chosen': -8.206250190734863, 'logits/rejected': -7.84375, 'epoch': 1.8}
 60%|██████    | 2730/4545 [2:56:48<1:52:29,  3.72s/it] 60%|██████    | 2731/4545 [2:56:52<1:54:28,  3.79s/it] 60%|██████    | 2732/4545 [2:56:56<1:55:13,  3.81s/it] 60%|██████    | 2733/4545 [2:57:00<1:54:13,  3.78s/it] 60%|██████    | 2734/4545 [2:57:03<1:51:34,  3.70s/it] 60%|██████    | 2735/4545 [2:57:07<1:54:23,  3.79s/it] 60%|██████    | 2736/4545 [2:57:11<1:55:20,  3.83s/it] 60%|██████    | 2737/4545 [2:57:14<1:49:34,  3.64s/it] 60%|██████    | 2738/4545 [2:57:18<1:52:59,  3.75s/it] 60%|██████    | 2739/4545 [2:57:22<1:54:18,  3.80s/it] 60%|██████    | 2740/4545 [2:57:26<1:54:52,  3.82s/it]                                                       {'loss': 0.2515, 'grad_norm': 25.19117546081543, 'learning_rate': 6.834567006683922e-07, 'rewards/chosen': 3.56982421875, 'rewards/rejected': -7.467187404632568, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 11.046875, 'logps/chosen': -310.3999938964844, 'logps/rejected': -185.85000610351562, 'logits/chosen': -7.971875190734863, 'logits/rejected': -7.768750190734863, 'epoch': 1.81}
 60%|██████    | 2740/4545 [2:57:26<1:54:52,  3.82s/it] 60%|██████    | 2741/4545 [2:57:30<1:53:21,  3.77s/it] 60%|██████    | 2742/4545 [2:57:34<1:54:13,  3.80s/it] 60%|██████    | 2743/4545 [2:57:37<1:54:44,  3.82s/it] 60%|██████    | 2744/4545 [2:57:40<1:46:46,  3.56s/it] 60%|██████    | 2745/4545 [2:57:44<1:47:09,  3.57s/it] 60%|██████    | 2746/4545 [2:57:48<1:51:01,  3.70s/it] 60%|██████    | 2747/4545 [2:57:52<1:51:04,  3.71s/it] 60%|██████    | 2748/4545 [2:57:55<1:49:11,  3.65s/it] 60%|██████    | 2749/4545 [2:57:58<1:45:33,  3.53s/it] 61%|██████    | 2750/4545 [2:58:02<1:50:10,  3.68s/it]                                                       {'loss': 0.2262, 'grad_norm': 41.69378662109375, 'learning_rate': 6.789952569419271e-07, 'rewards/chosen': 0.888476550579071, 'rewards/rejected': -8.600000381469727, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.481249809265137, 'logps/chosen': -165.9499969482422, 'logps/rejected': -160.39999389648438, 'logits/chosen': -8.100000381469727, 'logits/rejected': -7.665625095367432, 'epoch': 1.82}
 61%|██████    | 2750/4545 [2:58:03<1:50:10,  3.68s/it] 61%|██████    | 2751/4545 [2:58:07<1:55:17,  3.86s/it] 61%|██████    | 2752/4545 [2:58:10<1:51:32,  3.73s/it] 61%|██████    | 2753/4545 [2:58:13<1:45:59,  3.55s/it] 61%|██████    | 2754/4545 [2:58:17<1:48:57,  3.65s/it] 61%|██████    | 2755/4545 [2:58:20<1:42:17,  3.43s/it] 61%|██████    | 2756/4545 [2:58:24<1:43:18,  3.47s/it] 61%|██████    | 2757/4545 [2:58:28<1:48:32,  3.64s/it] 61%|██████    | 2758/4545 [2:58:32<1:50:38,  3.71s/it] 61%|██████    | 2759/4545 [2:58:36<1:53:55,  3.83s/it] 61%|██████    | 2760/4545 [2:58:40<1:56:00,  3.90s/it]                                                       {'loss': 0.3567, 'grad_norm': 51.33140182495117, 'learning_rate': 6.745199553057802e-07, 'rewards/chosen': 1.6774413585662842, 'rewards/rejected': -10.196874618530273, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 11.876562118530273, 'logps/chosen': -212.14999389648438, 'logps/rejected': -186.1999969482422, 'logits/chosen': -8.018750190734863, 'logits/rejected': -7.565625190734863, 'epoch': 1.82}
 61%|██████    | 2760/4545 [2:58:40<1:56:00,  3.90s/it] 61%|██████    | 2761/4545 [2:58:44<1:56:36,  3.92s/it] 61%|██████    | 2762/4545 [2:58:48<1:56:12,  3.91s/it] 61%|██████    | 2763/4545 [2:58:51<1:49:44,  3.69s/it] 61%|██████    | 2764/4545 [2:58:55<1:51:24,  3.75s/it] 61%|██████    | 2765/4545 [2:58:58<1:49:28,  3.69s/it] 61%|██████    | 2766/4545 [2:59:02<1:47:29,  3.63s/it] 61%|██████    | 2767/4545 [2:59:06<1:52:39,  3.80s/it] 61%|██████    | 2768/4545 [2:59:10<1:53:39,  3.84s/it] 61%|██████    | 2769/4545 [2:59:14<1:54:59,  3.88s/it] 61%|██████    | 2770/4545 [2:59:18<1:55:03,  3.89s/it]                                                       {'loss': 0.1645, 'grad_norm': 21.01011848449707, 'learning_rate': 6.700312765398448e-07, 'rewards/chosen': 4.147363185882568, 'rewards/rejected': -8.135156631469727, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 12.284375190734863, 'logps/chosen': -334.0, 'logps/rejected': -254.89999389648438, 'logits/chosen': -7.865624904632568, 'logits/rejected': -7.521874904632568, 'epoch': 1.83}
 61%|██████    | 2770/4545 [2:59:18<1:55:03,  3.89s/it] 61%|██████    | 2771/4545 [2:59:22<1:55:36,  3.91s/it] 61%|██████    | 2772/4545 [2:59:26<1:56:16,  3.93s/it] 61%|██████    | 2773/4545 [2:59:29<1:49:47,  3.72s/it] 61%|██████    | 2774/4545 [2:59:33<1:51:09,  3.77s/it] 61%|██████    | 2775/4545 [2:59:37<1:52:06,  3.80s/it] 61%|██████    | 2776/4545 [2:59:40<1:50:57,  3.76s/it] 61%|██████    | 2777/4545 [2:59:44<1:47:22,  3.64s/it] 61%|██████    | 2778/4545 [2:59:48<1:49:15,  3.71s/it] 61%|██████    | 2779/4545 [2:59:51<1:48:34,  3.69s/it] 61%|██████    | 2780/4545 [2:59:55<1:49:07,  3.71s/it]                                                       {'loss': 0.2012, 'grad_norm': 15.420294761657715, 'learning_rate': 6.655297028611137e-07, 'rewards/chosen': 1.892602562904358, 'rewards/rejected': -9.699999809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 11.600000381469727, 'logps/chosen': -264.29998779296875, 'logps/rejected': -210.9499969482422, 'logits/chosen': -8.050000190734863, 'logits/rejected': -7.5625, 'epoch': 1.83}
 61%|██████    | 2780/4545 [2:59:55<1:49:07,  3.71s/it] 61%|██████    | 2781/4545 [2:59:59<1:51:59,  3.81s/it] 61%|██████    | 2782/4545 [3:00:03<1:52:44,  3.84s/it] 61%|██████    | 2783/4545 [3:00:06<1:49:48,  3.74s/it] 61%|██████▏   | 2784/4545 [3:00:11<1:53:07,  3.85s/it] 61%|██████▏   | 2785/4545 [3:00:14<1:53:32,  3.87s/it] 61%|██████▏   | 2786/4545 [3:00:19<1:55:30,  3.94s/it] 61%|██████▏   | 2787/4545 [3:00:22<1:54:46,  3.92s/it] 61%|██████▏   | 2788/4545 [3:00:25<1:46:31,  3.64s/it] 61%|██████▏   | 2789/4545 [3:00:29<1:49:45,  3.75s/it] 61%|██████▏   | 2790/4545 [3:00:33<1:50:54,  3.79s/it]                                                       {'loss': 0.1885, 'grad_norm': 60.318634033203125, 'learning_rate': 6.610157178718756e-07, 'rewards/chosen': 1.859277367591858, 'rewards/rejected': -9.09375, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 10.9609375, 'logps/chosen': -250.4499969482422, 'logps/rejected': -204.60000610351562, 'logits/chosen': -7.971875190734863, 'logits/rejected': -7.5, 'epoch': 1.84}
 61%|██████▏   | 2790/4545 [3:00:33<1:50:54,  3.79s/it] 61%|██████▏   | 2791/4545 [3:00:37<1:52:14,  3.84s/it] 61%|██████▏   | 2792/4545 [3:00:41<1:55:22,  3.95s/it] 61%|██████▏   | 2793/4545 [3:00:45<1:53:19,  3.88s/it] 61%|██████▏   | 2794/4545 [3:00:49<1:53:18,  3.88s/it] 61%|██████▏   | 2795/4545 [3:00:53<1:49:41,  3.76s/it] 62%|██████▏   | 2796/4545 [3:00:56<1:50:40,  3.80s/it] 62%|██████▏   | 2797/4545 [3:01:00<1:47:31,  3.69s/it] 62%|██████▏   | 2798/4545 [3:01:04<1:50:47,  3.80s/it] 62%|██████▏   | 2799/4545 [3:01:08<1:53:18,  3.89s/it] 62%|██████▏   | 2800/4545 [3:01:10<1:40:28,  3.45s/it]                                                       {'loss': 0.2135, 'grad_norm': 14.169820785522461, 'learning_rate': 6.564898065077612e-07, 'rewards/chosen': 1.6396484375, 'rewards/rejected': -8.71875, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 10.34375, 'logps/chosen': -252.85000610351562, 'logps/rejected': -198.39999389648438, 'logits/chosen': -7.875, 'logits/rejected': -7.453125, 'epoch': 1.85}
 62%|██████▏   | 2800/4545 [3:01:11<1:40:28,  3.45s/it] 62%|██████▏   | 2801/4545 [3:01:14<1:43:51,  3.57s/it] 62%|██████▏   | 2802/4545 [3:01:17<1:36:23,  3.32s/it] 62%|██████▏   | 2803/4545 [3:01:20<1:33:30,  3.22s/it] 62%|██████▏   | 2804/4545 [3:01:23<1:32:16,  3.18s/it] 62%|██████▏   | 2805/4545 [3:01:26<1:33:29,  3.22s/it] 62%|██████▏   | 2806/4545 [3:01:31<1:40:49,  3.48s/it] 62%|██████▏   | 2807/4545 [3:01:33<1:36:08,  3.32s/it] 62%|██████▏   | 2808/4545 [3:01:38<1:42:17,  3.53s/it] 62%|██████▏   | 2809/4545 [3:01:41<1:45:13,  3.64s/it] 62%|██████▏   | 2810/4545 [3:01:44<1:35:51,  3.32s/it]                                                       {'loss': 0.1643, 'grad_norm': 17.559118270874023, 'learning_rate': 6.519524549856472e-07, 'rewards/chosen': 0.3171020448207855, 'rewards/rejected': -9.149999618530273, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 9.46875, 'logps/chosen': -138.25, 'logps/rejected': -126.1500015258789, 'logits/chosen': -8.287500381469727, 'logits/rejected': -7.956250190734863, 'epoch': 1.85}
 62%|██████▏   | 2810/4545 [3:01:44<1:35:51,  3.32s/it] 62%|██████▏   | 2811/4545 [3:01:48<1:39:15,  3.43s/it] 62%|██████▏   | 2812/4545 [3:01:52<1:43:03,  3.57s/it] 62%|██████▏   | 2813/4545 [3:01:55<1:44:29,  3.62s/it] 62%|██████▏   | 2814/4545 [3:01:59<1:49:04,  3.78s/it] 62%|██████▏   | 2815/4545 [3:02:03<1:49:40,  3.80s/it] 62%|██████▏   | 2816/4545 [3:02:07<1:51:15,  3.86s/it] 62%|██████▏   | 2817/4545 [3:02:11<1:51:50,  3.88s/it] 62%|██████▏   | 2818/4545 [3:02:15<1:52:56,  3.92s/it] 62%|██████▏   | 2819/4545 [3:02:19<1:54:25,  3.98s/it] 62%|██████▏   | 2820/4545 [3:02:23<1:48:42,  3.78s/it]                                                       {'loss': 0.2537, 'grad_norm': 25.746599197387695, 'learning_rate': 6.474041507514215e-07, 'rewards/chosen': 2.239062547683716, 'rewards/rejected': -9.834375381469727, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 12.078125, 'logps/chosen': -276.0, 'logps/rejected': -204.0500030517578, 'logits/chosen': -7.934374809265137, 'logits/rejected': -7.515625, 'epoch': 1.86}
 62%|██████▏   | 2820/4545 [3:02:23<1:48:42,  3.78s/it] 62%|██████▏   | 2821/4545 [3:02:27<1:51:11,  3.87s/it] 62%|██████▏   | 2822/4545 [3:02:30<1:43:02,  3.59s/it] 62%|██████▏   | 2823/4545 [3:02:32<1:29:10,  3.11s/it] 62%|██████▏   | 2824/4545 [3:02:35<1:29:32,  3.12s/it] 62%|██████▏   | 2825/4545 [3:02:39<1:38:08,  3.42s/it] 62%|██████▏   | 2826/4545 [3:02:43<1:42:38,  3.58s/it] 62%|██████▏   | 2827/4545 [3:02:46<1:37:15,  3.40s/it] 62%|██████▏   | 2828/4545 [3:02:50<1:41:24,  3.54s/it] 62%|██████▏   | 2829/4545 [3:02:54<1:43:43,  3.63s/it] 62%|██████▏   | 2830/4545 [3:02:57<1:45:56,  3.71s/it]                                                       {'loss': 0.2108, 'grad_norm': 12.744311332702637, 'learning_rate': 6.42845382427618e-07, 'rewards/chosen': 2.5953125953674316, 'rewards/rejected': -11.396875381469727, 'rewards/accuracies': 0.90625, 'rewards/margins': 13.978124618530273, 'logps/chosen': -305.6499938964844, 'logps/rejected': -192.64999389648438, 'logits/chosen': -8.050000190734863, 'logits/rejected': -7.578125, 'epoch': 1.87}
 62%|██████▏   | 2830/4545 [3:02:58<1:45:56,  3.71s/it] 62%|██████▏   | 2831/4545 [3:03:01<1:47:31,  3.76s/it] 62%|██████▏   | 2832/4545 [3:03:04<1:41:57,  3.57s/it] 62%|██████▏   | 2833/4545 [3:03:08<1:44:24,  3.66s/it] 62%|██████▏   | 2834/4545 [3:03:11<1:38:06,  3.44s/it] 62%|██████▏   | 2835/4545 [3:03:15<1:37:28,  3.42s/it] 62%|██████▏   | 2836/4545 [3:03:18<1:33:28,  3.28s/it] 62%|██████▏   | 2837/4545 [3:03:20<1:25:11,  2.99s/it] 62%|██████▏   | 2838/4545 [3:03:24<1:32:58,  3.27s/it] 62%|██████▏   | 2839/4545 [3:03:28<1:37:09,  3.42s/it] 62%|██████▏   | 2840/4545 [3:03:32<1:41:11,  3.56s/it]                                                       {'loss': 0.167, 'grad_norm': 49.24442672729492, 'learning_rate': 6.382766397609233e-07, 'rewards/chosen': 0.3316406309604645, 'rewards/rejected': -9.78125, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 10.112500190734863, 'logps/chosen': -177.64999389648438, 'logps/rejected': -173.85000610351562, 'logits/chosen': -8.21875, 'logits/rejected': -7.875, 'epoch': 1.87}
 62%|██████▏   | 2840/4545 [3:03:32<1:41:11,  3.56s/it] 63%|██████▎   | 2841/4545 [3:03:35<1:44:45,  3.69s/it] 63%|██████▎   | 2842/4545 [3:03:39<1:43:22,  3.64s/it] 63%|██████▎   | 2843/4545 [3:03:43<1:44:20,  3.68s/it] 63%|██████▎   | 2844/4545 [3:03:47<1:47:03,  3.78s/it] 63%|██████▎   | 2845/4545 [3:03:50<1:45:27,  3.72s/it] 63%|██████▎   | 2846/4545 [3:03:54<1:46:38,  3.77s/it] 63%|██████▎   | 2847/4545 [3:03:58<1:49:53,  3.88s/it] 63%|██████▎   | 2848/4545 [3:04:02<1:51:22,  3.94s/it] 63%|██████▎   | 2849/4545 [3:04:06<1:50:48,  3.92s/it] 63%|██████▎   | 2850/4545 [3:04:10<1:50:22,  3.91s/it]                                                       {'loss': 0.1568, 'grad_norm': 41.53618621826172, 'learning_rate': 6.336984135695637e-07, 'rewards/chosen': 2.7640624046325684, 'rewards/rejected': -11.45703125, 'rewards/accuracies': 0.9375, 'rewards/margins': 14.237500190734863, 'logps/chosen': -280.0, 'logps/rejected': -226.4499969482422, 'logits/chosen': -8.106249809265137, 'logits/rejected': -7.675000190734863, 'epoch': 1.88}
 63%|██████▎   | 2850/4545 [3:04:10<1:50:22,  3.91s/it] 63%|██████▎   | 2851/4545 [3:04:14<1:50:16,  3.91s/it] 63%|██████▎   | 2852/4545 [3:04:18<1:49:58,  3.90s/it] 63%|██████▎   | 2853/4545 [3:04:22<1:49:46,  3.89s/it] 63%|██████▎   | 2854/4545 [3:04:26<1:49:34,  3.89s/it] 63%|██████▎   | 2855/4545 [3:04:29<1:42:01,  3.62s/it] 63%|██████▎   | 2856/4545 [3:04:32<1:34:52,  3.37s/it] 63%|██████▎   | 2857/4545 [3:04:36<1:40:31,  3.57s/it] 63%|██████▎   | 2858/4545 [3:04:39<1:43:10,  3.67s/it] 63%|██████▎   | 2859/4545 [3:04:44<1:47:01,  3.81s/it] 63%|██████▎   | 2860/4545 [3:04:47<1:43:51,  3.70s/it]                                                       {'loss': 0.1917, 'grad_norm': 34.635963439941406, 'learning_rate': 6.291111956905776e-07, 'rewards/chosen': 3.6480469703674316, 'rewards/rejected': -9.86328125, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 13.509374618530273, 'logps/chosen': -325.79998779296875, 'logps/rejected': -212.5, 'logits/chosen': -8.084375381469727, 'logits/rejected': -7.671875, 'epoch': 1.89}
 63%|██████▎   | 2860/4545 [3:04:47<1:43:51,  3.70s/it] 63%|██████▎   | 2861/4545 [3:04:51<1:46:05,  3.78s/it] 63%|██████▎   | 2862/4545 [3:04:54<1:40:58,  3.60s/it] 63%|██████▎   | 2863/4545 [3:04:58<1:44:31,  3.73s/it] 63%|██████▎   | 2864/4545 [3:05:02<1:45:55,  3.78s/it] 63%|██████▎   | 2865/4545 [3:05:06<1:45:43,  3.78s/it] 63%|██████▎   | 2866/4545 [3:05:09<1:39:35,  3.56s/it] 63%|██████▎   | 2867/4545 [3:05:12<1:38:52,  3.54s/it] 63%|██████▎   | 2868/4545 [3:05:16<1:39:04,  3.54s/it] 63%|██████▎   | 2869/4545 [3:05:20<1:38:42,  3.53s/it] 63%|██████▎   | 2870/4545 [3:05:23<1:41:49,  3.65s/it]                                                       {'loss': 0.1544, 'grad_norm': 29.1960391998291, 'learning_rate': 6.245154789269756e-07, 'rewards/chosen': 3.7445311546325684, 'rewards/rejected': -12.857812881469727, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 16.615625381469727, 'logps/chosen': -375.0, 'logps/rejected': -262.6499938964844, 'logits/chosen': -7.853125095367432, 'logits/rejected': -7.503125190734863, 'epoch': 1.89}
 63%|██████▎   | 2870/4545 [3:05:24<1:41:49,  3.65s/it] 63%|██████▎   | 2871/4545 [3:05:28<1:45:53,  3.80s/it] 63%|██████▎   | 2872/4545 [3:05:31<1:44:49,  3.76s/it] 63%|██████▎   | 2873/4545 [3:05:35<1:47:12,  3.85s/it] 63%|██████▎   | 2874/4545 [3:05:39<1:48:29,  3.90s/it] 63%|██████▎   | 2875/4545 [3:05:43<1:47:02,  3.85s/it] 63%|██████▎   | 2876/4545 [3:05:46<1:39:29,  3.58s/it] 63%|██████▎   | 2877/4545 [3:05:49<1:38:47,  3.55s/it] 63%|██████▎   | 2878/4545 [3:05:54<1:44:10,  3.75s/it] 63%|██████▎   | 2879/4545 [3:05:58<1:47:03,  3.86s/it] 63%|██████▎   | 2880/4545 [3:06:02<1:48:03,  3.89s/it]                                                       {'loss': 0.2166, 'grad_norm': 53.3909797668457, 'learning_rate': 6.199117569948011e-07, 'rewards/chosen': 1.0861327648162842, 'rewards/rejected': -8.819531440734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 9.915624618530273, 'logps/chosen': -210.89999389648438, 'logps/rejected': -146.35000610351562, 'logits/chosen': -8.112500190734863, 'logits/rejected': -7.703125, 'epoch': 1.9}
 63%|██████▎   | 2880/4545 [3:06:02<1:48:03,  3.89s/it] 63%|██████▎   | 2881/4545 [3:06:06<1:46:34,  3.84s/it] 63%|██████▎   | 2882/4545 [3:06:09<1:44:18,  3.76s/it] 63%|██████▎   | 2883/4545 [3:06:12<1:40:23,  3.62s/it] 63%|██████▎   | 2884/4545 [3:06:16<1:42:26,  3.70s/it] 63%|██████▎   | 2885/4545 [3:06:20<1:46:34,  3.85s/it] 63%|██████▎   | 2886/4545 [3:06:25<1:49:04,  3.94s/it] 64%|██████▎   | 2887/4545 [3:06:29<1:49:21,  3.96s/it] 64%|██████▎   | 2888/4545 [3:06:32<1:42:01,  3.69s/it] 64%|██████▎   | 2889/4545 [3:06:36<1:43:31,  3.75s/it] 64%|██████▎   | 2890/4545 [3:06:39<1:44:04,  3.77s/it]                                                       {'loss': 0.1664, 'grad_norm': 12.437145233154297, 'learning_rate': 6.153005244700894e-07, 'rewards/chosen': 1.9857909679412842, 'rewards/rejected': -10.239941596984863, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 12.240625381469727, 'logps/chosen': -251.25, 'logps/rejected': -213.9499969482422, 'logits/chosen': -8.034375190734863, 'logits/rejected': -7.587500095367432, 'epoch': 1.91}
 64%|██████▎   | 2890/4545 [3:06:40<1:44:04,  3.77s/it] 64%|██████▎   | 2891/4545 [3:06:43<1:43:34,  3.76s/it] 64%|██████▎   | 2892/4545 [3:06:46<1:36:01,  3.49s/it] 64%|██████▎   | 2893/4545 [3:06:50<1:39:25,  3.61s/it] 64%|██████▎   | 2894/4545 [3:06:54<1:40:36,  3.66s/it] 64%|██████▎   | 2895/4545 [3:06:58<1:42:21,  3.72s/it] 64%|██████▎   | 2896/4545 [3:07:01<1:43:41,  3.77s/it] 64%|██████▎   | 2897/4545 [3:07:05<1:44:36,  3.81s/it] 64%|██████▍   | 2898/4545 [3:07:09<1:44:49,  3.82s/it] 64%|██████▍   | 2899/4545 [3:07:13<1:45:08,  3.83s/it] 64%|██████▍   | 2900/4545 [3:07:17<1:45:32,  3.85s/it]                                                       {'loss': 0.2041, 'grad_norm': 8.63672924041748, 'learning_rate': 6.106822767357355e-07, 'rewards/chosen': 4.904296875, 'rewards/rejected': -9.168749809265137, 'rewards/accuracies': 0.90625, 'rewards/margins': 14.0625, 'logps/chosen': -395.1499938964844, 'logps/rejected': -223.8000030517578, 'logits/chosen': -7.787499904632568, 'logits/rejected': -7.503125190734863, 'epoch': 1.91}
 64%|██████▍   | 2900/4545 [3:07:17<1:45:32,  3.85s/it] 64%|██████▍   | 2901/4545 [3:07:20<1:42:54,  3.76s/it] 64%|██████▍   | 2902/4545 [3:07:24<1:40:42,  3.68s/it] 64%|██████▍   | 2903/4545 [3:07:28<1:42:02,  3.73s/it] 64%|██████▍   | 2904/4545 [3:07:32<1:42:19,  3.74s/it] 64%|██████▍   | 2905/4545 [3:07:35<1:40:14,  3.67s/it] 64%|██████▍   | 2906/4545 [3:07:39<1:42:10,  3.74s/it] 64%|██████▍   | 2907/4545 [3:07:43<1:42:56,  3.77s/it] 64%|██████▍   | 2908/4545 [3:07:47<1:43:47,  3.80s/it] 64%|██████▍   | 2909/4545 [3:07:50<1:39:58,  3.67s/it] 64%|██████▍   | 2910/4545 [3:07:53<1:38:17,  3.61s/it]                                                       {'loss': 0.127, 'grad_norm': 12.517494201660156, 'learning_rate': 6.060575099282756e-07, 'rewards/chosen': 1.503759741783142, 'rewards/rejected': -8.653124809265137, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 10.137499809265137, 'logps/chosen': -212.10000610351562, 'logps/rejected': -181.60000610351562, 'logits/chosen': -8.203125, 'logits/rejected': -7.8125, 'epoch': 1.92}
 64%|██████▍   | 2910/4545 [3:07:54<1:38:17,  3.61s/it] 64%|██████▍   | 2911/4545 [3:07:58<1:43:57,  3.82s/it] 64%|██████▍   | 2912/4545 [3:08:02<1:45:22,  3.87s/it] 64%|██████▍   | 2913/4545 [3:08:06<1:45:22,  3.87s/it] 64%|██████▍   | 2914/4545 [3:08:10<1:47:54,  3.97s/it] 64%|██████▍   | 2915/4545 [3:08:14<1:46:20,  3.91s/it] 64%|██████▍   | 2916/4545 [3:08:17<1:44:41,  3.86s/it] 64%|██████▍   | 2917/4545 [3:08:21<1:44:52,  3.87s/it] 64%|██████▍   | 2918/4545 [3:08:25<1:46:12,  3.92s/it] 64%|██████▍   | 2919/4545 [3:08:29<1:45:02,  3.88s/it] 64%|██████▍   | 2920/4545 [3:08:33<1:44:48,  3.87s/it]                                                       {'loss': 0.1494, 'grad_norm': 12.805011749267578, 'learning_rate': 6.01426720884588e-07, 'rewards/chosen': 4.07568359375, 'rewards/rejected': -9.514062881469727, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 13.578125, 'logps/chosen': -320.25, 'logps/rejected': -236.0500030517578, 'logits/chosen': -8.0625, 'logits/rejected': -7.5625, 'epoch': 1.93}
 64%|██████▍   | 2920/4545 [3:08:33<1:44:48,  3.87s/it] 64%|██████▍   | 2921/4545 [3:08:37<1:44:55,  3.88s/it] 64%|██████▍   | 2922/4545 [3:08:39<1:33:59,  3.47s/it] 64%|██████▍   | 2923/4545 [3:08:41<1:22:50,  3.06s/it] 64%|██████▍   | 2924/4545 [3:08:45<1:29:26,  3.31s/it] 64%|██████▍   | 2925/4545 [3:08:50<1:36:29,  3.57s/it] 64%|██████▍   | 2926/4545 [3:08:53<1:36:42,  3.58s/it] 64%|██████▍   | 2927/4545 [3:08:57<1:39:03,  3.67s/it] 64%|██████▍   | 2928/4545 [3:09:01<1:42:58,  3.82s/it] 64%|██████▍   | 2929/4545 [3:09:05<1:43:12,  3.83s/it] 64%|██████▍   | 2930/4545 [3:09:09<1:39:57,  3.71s/it]                                                       {'loss': 0.2597, 'grad_norm': 6.7047648429870605, 'learning_rate': 5.967904070885168e-07, 'rewards/chosen': 2.278369188308716, 'rewards/rejected': -9.887499809265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 12.165624618530273, 'logps/chosen': -241.4250030517578, 'logps/rejected': -202.3000030517578, 'logits/chosen': -8.256250381469727, 'logits/rejected': -7.846875190734863, 'epoch': 1.93}
 64%|██████▍   | 2930/4545 [3:09:09<1:39:57,  3.71s/it] 64%|██████▍   | 2931/4545 [3:09:11<1:32:55,  3.45s/it] 65%|██████▍   | 2932/4545 [3:09:15<1:37:20,  3.62s/it] 65%|██████▍   | 2933/4545 [3:09:19<1:37:20,  3.62s/it] 65%|██████▍   | 2934/4545 [3:09:23<1:37:47,  3.64s/it] 65%|██████▍   | 2935/4545 [3:09:27<1:39:48,  3.72s/it] 65%|██████▍   | 2936/4545 [3:09:30<1:38:44,  3.68s/it] 65%|██████▍   | 2937/4545 [3:09:34<1:38:02,  3.66s/it] 65%|██████▍   | 2938/4545 [3:09:37<1:37:22,  3.64s/it] 65%|██████▍   | 2939/4545 [3:09:41<1:40:29,  3.75s/it] 65%|██████▍   | 2940/4545 [3:09:45<1:42:55,  3.85s/it]                                                       {'loss': 0.1508, 'grad_norm': 5.3783860206604, 'learning_rate': 5.921490666174284e-07, 'rewards/chosen': 0.33417969942092896, 'rewards/rejected': -12.653124809265137, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 12.987500190734863, 'logps/chosen': -173.8000030517578, 'logps/rejected': -182.10000610351562, 'logits/chosen': -8.443750381469727, 'logits/rejected': -7.8125, 'epoch': 1.94}
 65%|██████▍   | 2940/4545 [3:09:46<1:42:55,  3.85s/it] 65%|██████▍   | 2941/4545 [3:09:49<1:41:58,  3.81s/it] 65%|██████▍   | 2942/4545 [3:09:52<1:37:36,  3.65s/it] 65%|██████▍   | 2943/4545 [3:09:57<1:41:31,  3.80s/it] 65%|██████▍   | 2944/4545 [3:09:59<1:33:35,  3.51s/it] 65%|██████▍   | 2945/4545 [3:10:04<1:38:27,  3.69s/it] 65%|██████▍   | 2946/4545 [3:10:08<1:41:41,  3.82s/it] 65%|██████▍   | 2947/4545 [3:10:12<1:42:17,  3.84s/it] 65%|██████▍   | 2948/4545 [3:10:16<1:44:17,  3.92s/it] 65%|██████▍   | 2949/4545 [3:10:18<1:34:29,  3.55s/it] 65%|██████▍   | 2950/4545 [3:10:21<1:29:05,  3.35s/it]                                                       {'loss': 0.0842, 'grad_norm': 1.6842297315597534, 'learning_rate': 5.875031980887026e-07, 'rewards/chosen': 1.384423851966858, 'rewards/rejected': -13.681249618530273, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 15.065625190734863, 'logps/chosen': -206.60000610351562, 'logps/rejected': -175.3000030517578, 'logits/chosen': -8.425000190734863, 'logits/rejected': -7.884375095367432, 'epoch': 1.95}
 65%|██████▍   | 2950/4545 [3:10:22<1:29:05,  3.35s/it] 65%|██████▍   | 2951/4545 [3:10:25<1:35:14,  3.58s/it] 65%|██████▍   | 2952/4545 [3:10:28<1:25:27,  3.22s/it] 65%|██████▍   | 2953/4545 [3:10:32<1:32:53,  3.50s/it] 65%|██████▍   | 2954/4545 [3:10:36<1:36:10,  3.63s/it] 65%|██████▌   | 2955/4545 [3:10:40<1:38:22,  3.71s/it] 65%|██████▌   | 2956/4545 [3:10:42<1:30:45,  3.43s/it] 65%|██████▌   | 2957/4545 [3:10:46<1:34:58,  3.59s/it] 65%|██████▌   | 2958/4545 [3:10:51<1:39:22,  3.76s/it] 65%|██████▌   | 2959/4545 [3:10:55<1:41:05,  3.82s/it] 65%|██████▌   | 2960/4545 [3:10:57<1:27:35,  3.32s/it]                                                       {'loss': 0.1712, 'grad_norm': 11.974237442016602, 'learning_rate': 5.82853300606167e-07, 'rewards/chosen': 2.8988280296325684, 'rewards/rejected': -8.743749618530273, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.637499809265137, 'logps/chosen': -302.6000061035156, 'logps/rejected': -229.9499969482422, 'logits/chosen': -8.159375190734863, 'logits/rejected': -7.731249809265137, 'epoch': 1.95}
 65%|██████▌   | 2960/4545 [3:10:57<1:27:35,  3.32s/it] 65%|██████▌   | 2961/4545 [3:11:01<1:32:10,  3.49s/it] 65%|██████▌   | 2962/4545 [3:11:05<1:37:10,  3.68s/it] 65%|██████▌   | 2963/4545 [3:11:09<1:40:27,  3.81s/it] 65%|██████▌   | 2964/4545 [3:11:12<1:37:25,  3.70s/it] 65%|██████▌   | 2965/4545 [3:11:16<1:39:30,  3.78s/it] 65%|██████▌   | 2966/4545 [3:11:20<1:40:39,  3.82s/it] 65%|██████▌   | 2967/4545 [3:11:23<1:36:05,  3.65s/it] 65%|██████▌   | 2968/4545 [3:11:27<1:37:52,  3.72s/it] 65%|██████▌   | 2969/4545 [3:11:31<1:40:33,  3.83s/it] 65%|██████▌   | 2970/4545 [3:11:35<1:41:15,  3.86s/it]                                                       {'loss': 0.152, 'grad_norm': 12.164650917053223, 'learning_rate': 5.781998737064783e-07, 'rewards/chosen': 3.3866209983825684, 'rewards/rejected': -11.801562309265137, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 15.184374809265137, 'logps/chosen': -337.1000061035156, 'logps/rejected': -214.60000610351562, 'logits/chosen': -8.259374618530273, 'logits/rejected': -7.706250190734863, 'epoch': 1.96}
 65%|██████▌   | 2970/4545 [3:11:36<1:41:15,  3.86s/it] 65%|██████▌   | 2971/4545 [3:11:39<1:42:05,  3.89s/it] 65%|██████▌   | 2972/4545 [3:11:43<1:39:26,  3.79s/it] 65%|██████▌   | 2973/4545 [3:11:47<1:42:17,  3.90s/it] 65%|██████▌   | 2974/4545 [3:11:51<1:41:35,  3.88s/it] 65%|██████▌   | 2975/4545 [3:11:55<1:41:55,  3.90s/it] 65%|██████▌   | 2976/4545 [3:11:59<1:41:47,  3.89s/it] 66%|██████▌   | 2977/4545 [3:12:03<1:42:24,  3.92s/it] 66%|██████▌   | 2978/4545 [3:12:07<1:43:42,  3.97s/it] 66%|██████▌   | 2979/4545 [3:12:11<1:44:26,  4.00s/it] 66%|██████▌   | 2980/4545 [3:12:15<1:43:32,  3.97s/it]                                                       {'loss': 0.2564, 'grad_norm': 3.406477451324463, 'learning_rate': 5.735434173054562e-07, 'rewards/chosen': 3.648242235183716, 'rewards/rejected': -11.360937118530273, 'rewards/accuracies': 0.9375, 'rewards/margins': 14.981249809265137, 'logps/chosen': -396.45001220703125, 'logps/rejected': -267.8999938964844, 'logits/chosen': -8.306249618530273, 'logits/rejected': -7.912499904632568, 'epoch': 1.97}
 66%|██████▌   | 2980/4545 [3:12:15<1:43:32,  3.97s/it] 66%|██████▌   | 2981/4545 [3:12:18<1:37:46,  3.75s/it] 66%|██████▌   | 2982/4545 [3:12:22<1:38:42,  3.79s/it] 66%|██████▌   | 2983/4545 [3:12:25<1:36:24,  3.70s/it] 66%|██████▌   | 2984/4545 [3:12:29<1:37:16,  3.74s/it] 66%|██████▌   | 2985/4545 [3:12:33<1:34:58,  3.65s/it] 66%|██████▌   | 2986/4545 [3:12:37<1:37:41,  3.76s/it] 66%|██████▌   | 2987/4545 [3:12:41<1:38:39,  3.80s/it] 66%|██████▌   | 2988/4545 [3:12:44<1:35:59,  3.70s/it] 66%|██████▌   | 2989/4545 [3:12:48<1:39:18,  3.83s/it] 66%|██████▌   | 2990/4545 [3:12:52<1:40:08,  3.86s/it]                                                       {'loss': 0.1167, 'grad_norm': 10.429692268371582, 'learning_rate': 5.688844316443797e-07, 'rewards/chosen': 2.066210985183716, 'rewards/rejected': -15.9375, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 18.012500762939453, 'logps/chosen': -281.0, 'logps/rejected': -207.6999969482422, 'logits/chosen': -8.296875, 'logits/rejected': -7.743750095367432, 'epoch': 1.97}
 66%|██████▌   | 2990/4545 [3:12:52<1:40:08,  3.86s/it] 66%|██████▌   | 2991/4545 [3:12:56<1:41:54,  3.93s/it] 66%|██████▌   | 2992/4545 [3:13:00<1:43:51,  4.01s/it] 66%|██████▌   | 2993/4545 [3:13:05<1:45:09,  4.07s/it] 66%|██████▌   | 2994/4545 [3:13:08<1:43:41,  4.01s/it] 66%|██████▌   | 2995/4545 [3:13:12<1:42:39,  3.97s/it] 66%|██████▌   | 2996/4545 [3:13:15<1:33:52,  3.64s/it] 66%|██████▌   | 2997/4545 [3:13:19<1:35:48,  3.71s/it] 66%|██████▌   | 2998/4545 [3:13:23<1:34:48,  3.68s/it] 66%|██████▌   | 2999/4545 [3:13:27<1:36:17,  3.74s/it] 66%|██████▌   | 3000/4545 [3:13:30<1:34:50,  3.68s/it]                                                       {'loss': 0.1452, 'grad_norm': 6.773470878601074, 'learning_rate': 5.642234172362442e-07, 'rewards/chosen': 2.8232421875, 'rewards/rejected': -13.337499618530273, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 16.15625, 'logps/chosen': -356.8500061035156, 'logps/rejected': -251.60000610351562, 'logits/chosen': -8.287500381469727, 'logits/rejected': -7.75, 'epoch': 1.98}
 66%|██████▌   | 3000/4545 [3:13:30<1:34:50,  3.68s/it] 66%|██████▌   | 3001/4545 [3:13:34<1:36:51,  3.76s/it] 66%|██████▌   | 3002/4545 [3:13:38<1:35:35,  3.72s/it] 66%|██████▌   | 3003/4545 [3:13:42<1:36:47,  3.77s/it] 66%|██████▌   | 3004/4545 [3:13:45<1:37:40,  3.80s/it] 66%|██████▌   | 3005/4545 [3:13:50<1:40:30,  3.92s/it] 66%|██████▌   | 3006/4545 [3:13:53<1:36:52,  3.78s/it] 66%|██████▌   | 3007/4545 [3:13:57<1:36:30,  3.77s/it] 66%|██████▌   | 3008/4545 [3:14:01<1:37:24,  3.80s/it] 66%|██████▌   | 3009/4545 [3:14:04<1:31:45,  3.58s/it] 66%|██████▌   | 3010/4545 [3:14:07<1:30:48,  3.55s/it]                                                       {'loss': 0.1466, 'grad_norm': 14.785605430603027, 'learning_rate': 5.595608748119934e-07, 'rewards/chosen': 3.0888671875, 'rewards/rejected': -11.409375190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 14.493749618530273, 'logps/chosen': -330.6000061035156, 'logps/rejected': -208.75, 'logits/chosen': -8.134374618530273, 'logits/rejected': -7.690625190734863, 'epoch': 1.99}
 66%|██████▌   | 3010/4545 [3:14:07<1:30:48,  3.55s/it] 66%|██████▌   | 3011/4545 [3:14:11<1:31:14,  3.57s/it] 66%|██████▋   | 3012/4545 [3:14:15<1:33:29,  3.66s/it] 66%|██████▋   | 3013/4545 [3:14:18<1:34:09,  3.69s/it] 66%|██████▋   | 3014/4545 [3:14:22<1:35:40,  3.75s/it] 66%|██████▋   | 3015/4545 [3:14:26<1:36:50,  3.80s/it] 66%|██████▋   | 3016/4545 [3:14:30<1:38:42,  3.87s/it] 66%|██████▋   | 3017/4545 [3:14:33<1:26:27,  3.39s/it] 66%|██████▋   | 3018/4545 [3:14:37<1:31:03,  3.58s/it] 66%|██████▋   | 3019/4545 [3:14:40<1:33:12,  3.66s/it] 66%|██████▋   | 3020/4545 [3:14:44<1:28:49,  3.49s/it]                                                       {'loss': 0.1047, 'grad_norm': 10.473708152770996, 'learning_rate': 5.548973052667244e-07, 'rewards/chosen': 2.066113233566284, 'rewards/rejected': -9.981249809265137, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 12.040624618530273, 'logps/chosen': -238.6999969482422, 'logps/rejected': -155.35000610351562, 'logits/chosen': -8.449999809265137, 'logits/rejected': -7.956250190734863, 'epoch': 1.99}
 66%|██████▋   | 3020/4545 [3:14:44<1:28:49,  3.49s/it] 66%|██████▋   | 3021/4545 [3:14:47<1:31:13,  3.59s/it] 66%|██████▋   | 3022/4545 [3:14:51<1:29:50,  3.54s/it] 67%|██████▋   | 3023/4545 [3:14:55<1:32:34,  3.65s/it] 67%|██████▋   | 3024/4545 [3:14:59<1:35:43,  3.78s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:44,  1.30it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.11s/it][A
  7%|▋         | 4/60 [00:04<01:16,  1.36s/it][A
  8%|▊         | 5/60 [00:06<01:18,  1.43s/it][A
 10%|█         | 6/60 [00:08<01:21,  1.50s/it][A
 12%|█▏        | 7/60 [00:10<01:26,  1.64s/it][A
 13%|█▎        | 8/60 [00:11<01:26,  1.66s/it][A
 15%|█▌        | 9/60 [00:13<01:24,  1.66s/it][A
 17%|█▋        | 10/60 [00:15<01:21,  1.63s/it][A
 18%|█▊        | 11/60 [00:16<01:21,  1.66s/it][A
 20%|██        | 12/60 [00:18<01:19,  1.66s/it][A
 22%|██▏       | 13/60 [00:19<01:17,  1.64s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.64s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.53s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.39s/it][A
 28%|██▊       | 17/60 [00:25<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:31<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:32<00:40,  1.12s/it][A
 42%|████▏     | 25/60 [00:33<00:44,  1.27s/it][A
 43%|████▎     | 26/60 [00:35<00:44,  1.32s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.16s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.09s/it][A
 48%|████▊     | 29/60 [00:38<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:41<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:44<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:46<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:48<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:50<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:51<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:53<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:57<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:58<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:01<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:02<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:07<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:08<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:09<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:13<00:05,  1.33s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.41s/it][A
 97%|█████████▋| 58/60 [01:16<00:02,  1.41s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.47s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A                                                       
                                               [A{'eval_loss': 0.4166503846645355, 'eval_runtime': 81.2977, 'eval_samples_per_second': 11.722, 'eval_steps_per_second': 0.738, 'eval_rewards/chosen': 2.924933910369873, 'eval_rewards/rejected': -9.261083602905273, 'eval_rewards/accuracies': 0.8332176208496094, 'eval_rewards/margins': 12.188769340515137, 'eval_logps/chosen': -363.0083312988281, 'eval_logps/rejected': -198.3249969482422, 'eval_logits/chosen': -8.088021278381348, 'eval_logits/rejected': -8.266666412353516, 'epoch': 2.0}
 67%|██████▋   | 3024/4545 [3:16:20<1:35:43,  3.78s/it]
100%|██████████| 60/60 [01:19<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 67%|██████▋   | 3025/4545 [3:16:37<13:32:23, 32.07s/it] 67%|██████▋   | 3026/4545 [3:16:41<9:56:56, 23.58s/it]  67%|██████▋   | 3027/4545 [3:16:44<7:26:55, 17.66s/it] 67%|██████▋   | 3028/4545 [3:16:48<5:40:59, 13.49s/it] 67%|██████▋   | 3029/4545 [3:16:52<4:28:06, 10.61s/it] 67%|██████▋   | 3030/4545 [3:16:56<3:37:00,  8.59s/it]                                                       {'loss': 0.1734, 'grad_norm': 5.473563194274902, 'learning_rate': 5.502332096058782e-07, 'rewards/chosen': 7.132031440734863, 'rewards/rejected': -14.979687690734863, 'rewards/accuracies': 0.9375, 'rewards/margins': 22.103124618530273, 'logps/chosen': -558.0, 'logps/rejected': -383.20001220703125, 'logits/chosen': -7.875, 'logits/rejected': -7.574999809265137, 'epoch': 2.0}
 67%|██████▋   | 3030/4545 [3:16:56<3:37:00,  8.59s/it] 67%|██████▋   | 3031/4545 [3:16:59<2:57:01,  7.02s/it] 67%|██████▋   | 3032/4545 [3:17:03<2:33:05,  6.07s/it] 67%|██████▋   | 3033/4545 [3:17:07<2:14:53,  5.35s/it] 67%|██████▋   | 3034/4545 [3:17:10<1:58:53,  4.72s/it] 67%|██████▋   | 3035/4545 [3:17:14<1:49:39,  4.36s/it] 67%|██████▋   | 3036/4545 [3:17:18<1:45:58,  4.21s/it] 67%|██████▋   | 3037/4545 [3:17:21<1:43:07,  4.10s/it] 67%|██████▋   | 3038/4545 [3:17:25<1:41:20,  4.04s/it] 67%|██████▋   | 3039/4545 [3:17:29<1:39:23,  3.96s/it] 67%|██████▋   | 3040/4545 [3:17:32<1:35:11,  3.79s/it]                                                       {'loss': 0.0567, 'grad_norm': 3.2379791736602783, 'learning_rate': 5.45569088891416e-07, 'rewards/chosen': 1.876953125, 'rewards/rejected': -11.543749809265137, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 13.418749809265137, 'logps/chosen': -254.5500030517578, 'logps/rejected': -199.89999389648438, 'logits/chosen': -8.399999618530273, 'logits/rejected': -7.925000190734863, 'epoch': 2.01}
 67%|██████▋   | 3040/4545 [3:17:33<1:35:11,  3.79s/it] 67%|██████▋   | 3041/4545 [3:17:36<1:33:03,  3.71s/it] 67%|██████▋   | 3042/4545 [3:17:40<1:35:55,  3.83s/it] 67%|██████▋   | 3043/4545 [3:17:44<1:37:36,  3.90s/it] 67%|██████▋   | 3044/4545 [3:17:46<1:25:52,  3.43s/it] 67%|██████▋   | 3045/4545 [3:17:50<1:29:34,  3.58s/it] 67%|██████▋   | 3046/4545 [3:17:53<1:23:34,  3.35s/it] 67%|██████▋   | 3047/4545 [3:17:57<1:27:34,  3.51s/it] 67%|██████▋   | 3048/4545 [3:18:01<1:29:40,  3.59s/it] 67%|██████▋   | 3049/4545 [3:18:05<1:31:25,  3.67s/it] 67%|██████▋   | 3050/4545 [3:18:08<1:25:48,  3.44s/it]                                                       {'loss': 0.0582, 'grad_norm': 13.489027976989746, 'learning_rate': 5.4090544418799e-07, 'rewards/chosen': 3.328418016433716, 'rewards/rejected': -11.318750381469727, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 14.643750190734863, 'logps/chosen': -341.54998779296875, 'logps/rejected': -191.9499969482422, 'logits/chosen': -8.40625, 'logits/rejected': -7.921875, 'epoch': 2.01}
 67%|██████▋   | 3050/4545 [3:18:08<1:25:48,  3.44s/it] 67%|██████▋   | 3051/4545 [3:18:12<1:30:11,  3.62s/it] 67%|██████▋   | 3052/4545 [3:18:16<1:32:21,  3.71s/it] 67%|██████▋   | 3053/4545 [3:18:20<1:35:00,  3.82s/it] 67%|██████▋   | 3054/4545 [3:18:24<1:35:16,  3.83s/it] 67%|██████▋   | 3055/4545 [3:18:27<1:35:20,  3.84s/it] 67%|██████▋   | 3056/4545 [3:18:31<1:37:12,  3.92s/it] 67%|██████▋   | 3057/4545 [3:18:35<1:36:53,  3.91s/it] 67%|██████▋   | 3058/4545 [3:18:39<1:36:39,  3.90s/it] 67%|██████▋   | 3059/4545 [3:18:43<1:36:26,  3.89s/it] 67%|██████▋   | 3060/4545 [3:18:47<1:32:35,  3.74s/it]                                                       {'loss': 0.1254, 'grad_norm': 21.70515251159668, 'learning_rate': 5.362427765091152e-07, 'rewards/chosen': 3.0528931617736816, 'rewards/rejected': -12.159375190734863, 'rewards/accuracies': 0.96875, 'rewards/margins': 15.225000381469727, 'logps/chosen': -294.45001220703125, 'logps/rejected': -229.6999969482422, 'logits/chosen': -8.253125190734863, 'logits/rejected': -7.665625095367432, 'epoch': 2.02}
 67%|██████▋   | 3060/4545 [3:18:47<1:32:35,  3.74s/it] 67%|██████▋   | 3061/4545 [3:18:50<1:34:17,  3.81s/it] 67%|██████▋   | 3062/4545 [3:18:54<1:34:24,  3.82s/it] 67%|██████▋   | 3063/4545 [3:18:58<1:34:54,  3.84s/it] 67%|██████▋   | 3064/4545 [3:19:02<1:33:11,  3.78s/it] 67%|██████▋   | 3065/4545 [3:19:06<1:35:48,  3.88s/it] 67%|██████▋   | 3066/4545 [3:19:09<1:31:49,  3.72s/it] 67%|██████▋   | 3067/4545 [3:19:13<1:32:27,  3.75s/it] 68%|██████▊   | 3068/4545 [3:19:17<1:34:29,  3.84s/it] 68%|██████▊   | 3069/4545 [3:19:21<1:31:42,  3.73s/it] 68%|██████▊   | 3070/4545 [3:19:23<1:24:58,  3.46s/it]                                                       {'loss': 0.1315, 'grad_norm': 17.475954055786133, 'learning_rate': 5.315815867633456e-07, 'rewards/chosen': 0.82000732421875, 'rewards/rejected': -13.209375381469727, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 14.03125, 'logps/chosen': -174.5500030517578, 'logps/rejected': -157.0, 'logits/chosen': -8.503125190734863, 'logits/rejected': -7.996874809265137, 'epoch': 2.03}
 68%|██████▊   | 3070/4545 [3:19:24<1:24:58,  3.46s/it] 68%|██████▊   | 3071/4545 [3:19:28<1:30:11,  3.67s/it] 68%|██████▊   | 3072/4545 [3:19:32<1:31:35,  3.73s/it] 68%|██████▊   | 3073/4545 [3:19:36<1:34:10,  3.84s/it] 68%|██████▊   | 3074/4545 [3:19:39<1:30:04,  3.67s/it] 68%|██████▊   | 3075/4545 [3:19:43<1:31:32,  3.74s/it] 68%|██████▊   | 3076/4545 [3:19:47<1:32:35,  3.78s/it] 68%|██████▊   | 3077/4545 [3:19:51<1:33:15,  3.81s/it] 68%|██████▊   | 3078/4545 [3:19:54<1:32:08,  3.77s/it] 68%|██████▊   | 3079/4545 [3:19:58<1:32:41,  3.79s/it] 68%|██████▊   | 3080/4545 [3:20:01<1:23:55,  3.44s/it]                                                       {'loss': 0.0817, 'grad_norm': 11.458822250366211, 'learning_rate': 5.269223757004607e-07, 'rewards/chosen': 2.4278807640075684, 'rewards/rejected': -14.350000381469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.756250381469727, 'logps/chosen': -280.04998779296875, 'logps/rejected': -247.75, 'logits/chosen': -8.259374618530273, 'logits/rejected': -7.740624904632568, 'epoch': 2.03}
 68%|██████▊   | 3080/4545 [3:20:01<1:23:55,  3.44s/it] 68%|██████▊   | 3081/4545 [3:20:05<1:28:26,  3.62s/it] 68%|██████▊   | 3082/4545 [3:20:09<1:30:06,  3.70s/it] 68%|██████▊   | 3083/4545 [3:20:13<1:32:43,  3.81s/it] 68%|██████▊   | 3084/4545 [3:20:17<1:33:20,  3.83s/it] 68%|██████▊   | 3085/4545 [3:20:20<1:33:05,  3.83s/it] 68%|██████▊   | 3086/4545 [3:20:23<1:22:08,  3.38s/it] 68%|██████▊   | 3087/4545 [3:20:27<1:26:47,  3.57s/it] 68%|██████▊   | 3088/4545 [3:20:31<1:29:17,  3.68s/it] 68%|██████▊   | 3089/4545 [3:20:35<1:30:39,  3.74s/it] 68%|██████▊   | 3090/4545 [3:20:38<1:31:40,  3.78s/it]                                                       {'loss': 0.12, 'grad_norm': 22.125782012939453, 'learning_rate': 5.222656438576711e-07, 'rewards/chosen': 2.965380907058716, 'rewards/rejected': -10.953125, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.903124809265137, 'logps/chosen': -307.25, 'logps/rejected': -205.0500030517578, 'logits/chosen': -8.371874809265137, 'logits/rejected': -7.884375095367432, 'epoch': 2.04}
 68%|██████▊   | 3090/4545 [3:20:38<1:31:40,  3.78s/it] 68%|██████▊   | 3091/4545 [3:20:42<1:28:18,  3.64s/it] 68%|██████▊   | 3092/4545 [3:20:45<1:27:30,  3.61s/it] 68%|██████▊   | 3093/4545 [3:20:49<1:29:53,  3.71s/it] 68%|██████▊   | 3094/4545 [3:20:53<1:31:02,  3.76s/it] 68%|██████▊   | 3095/4545 [3:20:56<1:22:02,  3.39s/it] 68%|██████▊   | 3096/4545 [3:20:59<1:25:21,  3.53s/it] 68%|██████▊   | 3097/4545 [3:21:03<1:28:36,  3.67s/it] 68%|██████▊   | 3098/4545 [3:21:07<1:30:06,  3.74s/it] 68%|██████▊   | 3099/4545 [3:21:11<1:31:12,  3.78s/it] 68%|██████▊   | 3100/4545 [3:21:15<1:31:53,  3.82s/it]                                                       {'loss': 0.2712, 'grad_norm': 40.015403747558594, 'learning_rate': 5.176118915058459e-07, 'rewards/chosen': 3.8047852516174316, 'rewards/rejected': -9.756250381469727, 'rewards/accuracies': 0.9375, 'rewards/margins': 13.5625, 'logps/chosen': -340.54998779296875, 'logps/rejected': -255.4499969482422, 'logits/chosen': -8.462499618530273, 'logits/rejected': -7.753125190734863, 'epoch': 2.05}
 68%|██████▊   | 3100/4545 [3:21:15<1:31:53,  3.82s/it] 68%|██████▊   | 3101/4545 [3:21:19<1:29:21,  3.71s/it] 68%|██████▊   | 3102/4545 [3:21:23<1:30:36,  3.77s/it] 68%|██████▊   | 3103/4545 [3:21:26<1:31:40,  3.81s/it] 68%|██████▊   | 3104/4545 [3:21:31<1:34:21,  3.93s/it] 68%|██████▊   | 3105/4545 [3:21:33<1:22:57,  3.46s/it] 68%|██████▊   | 3106/4545 [3:21:37<1:26:57,  3.63s/it] 68%|██████▊   | 3107/4545 [3:21:40<1:22:56,  3.46s/it] 68%|██████▊   | 3108/4545 [3:21:44<1:25:59,  3.59s/it] 68%|██████▊   | 3109/4545 [3:21:48<1:28:59,  3.72s/it] 68%|██████▊   | 3110/4545 [3:21:52<1:30:05,  3.77s/it]                                                       {'loss': 0.1016, 'grad_norm': 12.420320510864258, 'learning_rate': 5.129616185957687e-07, 'rewards/chosen': 2.7957520484924316, 'rewards/rejected': -9.612500190734863, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 12.403124809265137, 'logps/chosen': -281.04998779296875, 'logps/rejected': -182.5500030517578, 'logits/chosen': -8.571874618530273, 'logits/rejected': -8.056249618530273, 'epoch': 2.05}
 68%|██████▊   | 3110/4545 [3:21:52<1:30:05,  3.77s/it] 68%|██████▊   | 3111/4545 [3:21:56<1:31:02,  3.81s/it] 68%|██████▊   | 3112/4545 [3:22:00<1:33:52,  3.93s/it] 68%|██████▊   | 3113/4545 [3:22:03<1:27:04,  3.65s/it] 69%|██████▊   | 3114/4545 [3:22:07<1:28:38,  3.72s/it] 69%|██████▊   | 3115/4545 [3:22:11<1:29:52,  3.77s/it] 69%|██████▊   | 3116/4545 [3:22:15<1:30:37,  3.81s/it] 69%|██████▊   | 3117/4545 [3:22:19<1:31:54,  3.86s/it] 69%|██████▊   | 3118/4545 [3:22:23<1:32:02,  3.87s/it] 69%|██████▊   | 3119/4545 [3:22:26<1:32:05,  3.87s/it] 69%|██████▊   | 3120/4545 [3:22:30<1:29:29,  3.77s/it]                                                       {'loss': 0.0884, 'grad_norm': 7.648540019989014, 'learning_rate': 5.083153247044277e-07, 'rewards/chosen': 5.564306735992432, 'rewards/rejected': -10.621484756469727, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 16.162500381469727, 'logps/chosen': -476.75, 'logps/rejected': -300.20001220703125, 'logits/chosen': -8.034375190734863, 'logits/rejected': -7.646874904632568, 'epoch': 2.06}
 69%|██████▊   | 3120/4545 [3:22:30<1:29:29,  3.77s/it] 69%|██████▊   | 3121/4545 [3:22:34<1:31:22,  3.85s/it] 69%|██████▊   | 3122/4545 [3:22:38<1:33:20,  3.94s/it] 69%|██████▊   | 3123/4545 [3:22:42<1:32:36,  3.91s/it] 69%|██████▊   | 3124/4545 [3:22:45<1:24:00,  3.55s/it] 69%|██████▉   | 3125/4545 [3:22:49<1:26:38,  3.66s/it] 69%|██████▉   | 3126/4545 [3:22:51<1:20:34,  3.41s/it] 69%|██████▉   | 3127/4545 [3:22:55<1:23:51,  3.55s/it] 69%|██████▉   | 3128/4545 [3:22:59<1:26:26,  3.66s/it] 69%|██████▉   | 3129/4545 [3:23:02<1:17:48,  3.30s/it] 69%|██████▉   | 3130/4545 [3:23:05<1:19:51,  3.39s/it]                                                       {'loss': 0.0816, 'grad_norm': 7.466947555541992, 'learning_rate': 5.036735089813468e-07, 'rewards/chosen': 2.8894104957580566, 'rewards/rejected': -7.354687690734863, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 10.243749618530273, 'logps/chosen': -273.9750061035156, 'logps/rejected': -233.6999969482422, 'logits/chosen': -8.509374618530273, 'logits/rejected': -8.021875381469727, 'epoch': 2.07}
 69%|██████▉   | 3130/4545 [3:23:05<1:19:51,  3.39s/it] 69%|██████▉   | 3131/4545 [3:23:08<1:18:23,  3.33s/it] 69%|██████▉   | 3132/4545 [3:23:13<1:24:37,  3.59s/it] 69%|██████▉   | 3133/4545 [3:23:15<1:18:43,  3.35s/it] 69%|██████▉   | 3134/4545 [3:23:19<1:22:31,  3.51s/it] 69%|██████▉   | 3135/4545 [3:23:23<1:25:17,  3.63s/it] 69%|██████▉   | 3136/4545 [3:23:27<1:28:15,  3.76s/it] 69%|██████▉   | 3137/4545 [3:23:31<1:30:46,  3.87s/it] 69%|██████▉   | 3138/4545 [3:23:34<1:23:06,  3.54s/it] 69%|██████▉   | 3139/4545 [3:23:38<1:23:39,  3.57s/it] 69%|██████▉   | 3140/4545 [3:23:42<1:27:18,  3.73s/it]                                                       {'loss': 0.0875, 'grad_norm': 4.362761974334717, 'learning_rate': 4.990366700949626e-07, 'rewards/chosen': 2.036328077316284, 'rewards/rejected': -12.202783584594727, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 14.225000381469727, 'logps/chosen': -253.875, 'logps/rejected': -232.35000610351562, 'logits/chosen': -8.509374618530273, 'logits/rejected': -7.912499904632568, 'epoch': 2.07}
 69%|██████▉   | 3140/4545 [3:23:42<1:27:18,  3.73s/it] 69%|██████▉   | 3141/4545 [3:23:46<1:28:43,  3.79s/it] 69%|██████▉   | 3142/4545 [3:23:50<1:29:20,  3.82s/it] 69%|██████▉   | 3143/4545 [3:23:52<1:20:50,  3.46s/it] 69%|██████▉   | 3144/4545 [3:23:56<1:21:46,  3.50s/it] 69%|██████▉   | 3145/4545 [3:24:00<1:23:53,  3.60s/it] 69%|██████▉   | 3146/4545 [3:24:04<1:25:56,  3.69s/it] 69%|██████▉   | 3147/4545 [3:24:08<1:27:19,  3.75s/it] 69%|██████▉   | 3148/4545 [3:24:11<1:28:13,  3.79s/it] 69%|██████▉   | 3149/4545 [3:24:14<1:19:35,  3.42s/it] 69%|██████▉   | 3150/4545 [3:24:18<1:23:13,  3.58s/it]                                                       {'loss': 0.143, 'grad_norm': 10.265650749206543, 'learning_rate': 4.944053061790515e-07, 'rewards/chosen': 3.5897459983825684, 'rewards/rejected': -8.206250190734863, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 11.806249618530273, 'logps/chosen': -334.1499938964844, 'logps/rejected': -204.35000610351562, 'logits/chosen': -8.303125381469727, 'logits/rejected': -7.871874809265137, 'epoch': 2.08}
 69%|██████▉   | 3150/4545 [3:24:18<1:23:13,  3.58s/it] 69%|██████▉   | 3151/4545 [3:24:22<1:26:53,  3.74s/it] 69%|██████▉   | 3152/4545 [3:24:26<1:28:27,  3.81s/it] 69%|██████▉   | 3153/4545 [3:24:30<1:30:16,  3.89s/it] 69%|██████▉   | 3154/4545 [3:24:34<1:30:13,  3.89s/it] 69%|██████▉   | 3155/4545 [3:24:38<1:29:25,  3.86s/it] 69%|██████▉   | 3156/4545 [3:24:40<1:20:08,  3.46s/it] 69%|██████▉   | 3157/4545 [3:24:44<1:19:08,  3.42s/it] 69%|██████▉   | 3158/4545 [3:24:48<1:23:31,  3.61s/it] 70%|██████▉   | 3159/4545 [3:24:51<1:21:31,  3.53s/it] 70%|██████▉   | 3160/4545 [3:24:55<1:23:40,  3.62s/it]                                                       {'loss': 0.0925, 'grad_norm': 15.562641143798828, 'learning_rate': 4.89779914779216e-07, 'rewards/chosen': 2.9588379859924316, 'rewards/rejected': -9.296875, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 12.234375, 'logps/chosen': -287.0, 'logps/rejected': -264.3500061035156, 'logits/chosen': -8.375, 'logits/rejected': -7.821875095367432, 'epoch': 2.09}
 70%|██████▉   | 3160/4545 [3:24:55<1:23:40,  3.62s/it] 70%|██████▉   | 3161/4545 [3:24:58<1:23:04,  3.60s/it] 70%|██████▉   | 3162/4545 [3:25:02<1:24:57,  3.69s/it] 70%|██████▉   | 3163/4545 [3:25:06<1:25:39,  3.72s/it] 70%|██████▉   | 3164/4545 [3:25:10<1:23:24,  3.62s/it] 70%|██████▉   | 3165/4545 [3:25:13<1:21:48,  3.56s/it] 70%|██████▉   | 3166/4545 [3:25:17<1:24:05,  3.66s/it] 70%|██████▉   | 3167/4545 [3:25:21<1:25:19,  3.72s/it] 70%|██████▉   | 3168/4545 [3:25:25<1:26:03,  3.75s/it] 70%|██████▉   | 3169/4545 [3:25:28<1:26:23,  3.77s/it] 70%|██████▉   | 3170/4545 [3:25:32<1:27:33,  3.82s/it]                                                       {'loss': 0.0647, 'grad_norm': 22.823209762573242, 'learning_rate': 4.851609927994337e-07, 'rewards/chosen': 1.914648413658142, 'rewards/rejected': -14.137499809265137, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 16.037500381469727, 'logps/chosen': -265.0, 'logps/rejected': -221.25, 'logits/chosen': -8.534375190734863, 'logits/rejected': -7.893750190734863, 'epoch': 2.09}
 70%|██████▉   | 3170/4545 [3:25:33<1:27:33,  3.82s/it] 70%|██████▉   | 3171/4545 [3:25:36<1:24:42,  3.70s/it] 70%|██████▉   | 3172/4545 [3:25:40<1:26:18,  3.77s/it] 70%|██████▉   | 3173/4545 [3:25:44<1:29:18,  3.91s/it] 70%|██████▉   | 3174/4545 [3:25:48<1:29:09,  3.90s/it] 70%|██████▉   | 3175/4545 [3:25:51<1:26:17,  3.78s/it] 70%|██████▉   | 3176/4545 [3:25:55<1:26:54,  3.81s/it] 70%|██████▉   | 3177/4545 [3:25:59<1:27:21,  3.83s/it] 70%|██████▉   | 3178/4545 [3:26:03<1:27:36,  3.85s/it] 70%|██████▉   | 3179/4545 [3:26:07<1:27:44,  3.85s/it] 70%|██████▉   | 3180/4545 [3:26:11<1:27:44,  3.86s/it]                                                       {'loss': 0.1045, 'grad_norm': 5.0917887687683105, 'learning_rate': 4.805490364486749e-07, 'rewards/chosen': 5.73583984375, 'rewards/rejected': -8.88671875, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 14.631250381469727, 'logps/chosen': -440.1000061035156, 'logps/rejected': -245.64999389648438, 'logits/chosen': -8.162500381469727, 'logits/rejected': -8.037500381469727, 'epoch': 2.1}
 70%|██████▉   | 3180/4545 [3:26:11<1:27:44,  3.86s/it] 70%|██████▉   | 3181/4545 [3:26:15<1:29:42,  3.95s/it] 70%|███████   | 3182/4545 [3:26:19<1:29:12,  3.93s/it] 70%|███████   | 3183/4545 [3:26:23<1:28:56,  3.92s/it] 70%|███████   | 3184/4545 [3:26:26<1:28:40,  3.91s/it] 70%|███████   | 3185/4545 [3:26:30<1:28:42,  3.91s/it] 70%|███████   | 3186/4545 [3:26:34<1:25:45,  3.79s/it] 70%|███████   | 3187/4545 [3:26:37<1:21:48,  3.61s/it] 70%|███████   | 3188/4545 [3:26:41<1:24:23,  3.73s/it] 70%|███████   | 3189/4545 [3:26:45<1:26:41,  3.84s/it] 70%|███████   | 3190/4545 [3:26:49<1:27:09,  3.86s/it]                                                       {'loss': 0.0976, 'grad_norm': 2.914971113204956, 'learning_rate': 4.759445411875952e-07, 'rewards/chosen': 3.336682081222534, 'rewards/rejected': -13.40625, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.71875, 'logps/chosen': -278.04998779296875, 'logps/rejected': -212.25, 'logits/chosen': -8.587499618530273, 'logits/rejected': -8.171875, 'epoch': 2.11}
 70%|███████   | 3190/4545 [3:26:49<1:27:09,  3.86s/it] 70%|███████   | 3191/4545 [3:26:53<1:30:09,  4.00s/it] 70%|███████   | 3192/4545 [3:26:57<1:30:42,  4.02s/it] 70%|███████   | 3193/4545 [3:27:00<1:23:33,  3.71s/it] 70%|███████   | 3194/4545 [3:27:05<1:26:12,  3.83s/it] 70%|███████   | 3195/4545 [3:27:09<1:27:00,  3.87s/it] 70%|███████   | 3196/4545 [3:27:12<1:27:30,  3.89s/it] 70%|███████   | 3197/4545 [3:27:16<1:27:10,  3.88s/it] 70%|███████   | 3198/4545 [3:27:20<1:25:10,  3.79s/it] 70%|███████   | 3199/4545 [3:27:24<1:25:42,  3.82s/it] 70%|███████   | 3200/4545 [3:27:28<1:27:19,  3.90s/it]                                                       {'loss': 0.05, 'grad_norm': 3.4865238666534424, 'learning_rate': 4.713480016753083e-07, 'rewards/chosen': 4.98095703125, 'rewards/rejected': -7.78125, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 12.753125190734863, 'logps/chosen': -406.54998779296875, 'logps/rejected': -269.6000061035156, 'logits/chosen': -8.256250381469727, 'logits/rejected': -8.090624809265137, 'epoch': 2.11}
 70%|███████   | 3200/4545 [3:27:28<1:27:19,  3.90s/it] 70%|███████   | 3201/4545 [3:27:32<1:27:45,  3.92s/it] 70%|███████   | 3202/4545 [3:27:35<1:24:29,  3.77s/it] 70%|███████   | 3203/4545 [3:27:39<1:25:22,  3.82s/it] 70%|███████   | 3204/4545 [3:27:42<1:19:52,  3.57s/it] 71%|███████   | 3205/4545 [3:27:44<1:10:24,  3.15s/it] 71%|███████   | 3206/4545 [3:27:49<1:17:28,  3.47s/it] 71%|███████   | 3207/4545 [3:27:52<1:15:49,  3.40s/it] 71%|███████   | 3208/4545 [3:27:55<1:11:56,  3.23s/it] 71%|███████   | 3209/4545 [3:27:58<1:10:54,  3.18s/it] 71%|███████   | 3210/4545 [3:28:01<1:13:42,  3.31s/it]                                                       {'loss': 0.0689, 'grad_norm': 7.363521099090576, 'learning_rate': 4.667599117162445e-07, 'rewards/chosen': 1.478906273841858, 'rewards/rejected': -15.162500381469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.65625, 'logps/chosen': -211.125, 'logps/rejected': -177.4499969482422, 'logits/chosen': -8.756250381469727, 'logits/rejected': -8.106249809265137, 'epoch': 2.12}
 71%|███████   | 3210/4545 [3:28:02<1:13:42,  3.31s/it] 71%|███████   | 3211/4545 [3:28:05<1:18:20,  3.52s/it] 71%|███████   | 3212/4545 [3:28:09<1:20:41,  3.63s/it] 71%|███████   | 3213/4545 [3:28:13<1:22:25,  3.71s/it] 71%|███████   | 3214/4545 [3:28:17<1:23:30,  3.76s/it] 71%|███████   | 3215/4545 [3:28:21<1:25:16,  3.85s/it] 71%|███████   | 3216/4545 [3:28:24<1:20:43,  3.64s/it] 71%|███████   | 3217/4545 [3:28:28<1:22:19,  3.72s/it] 71%|███████   | 3218/4545 [3:28:32<1:23:06,  3.76s/it] 71%|███████   | 3219/4545 [3:28:36<1:23:48,  3.79s/it] 71%|███████   | 3220/4545 [3:28:40<1:23:52,  3.80s/it]                                                       {'loss': 0.0774, 'grad_norm': 34.90501022338867, 'learning_rate': 4.621807642071027e-07, 'rewards/chosen': 4.138171195983887, 'rewards/rejected': -16.362499237060547, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 20.493749618530273, 'logps/chosen': -399.6000061035156, 'logps/rejected': -280.8999938964844, 'logits/chosen': -8.340624809265137, 'logits/rejected': -8.071874618530273, 'epoch': 2.13}
 71%|███████   | 3220/4545 [3:28:40<1:23:52,  3.80s/it] 71%|███████   | 3221/4545 [3:28:44<1:25:05,  3.86s/it] 71%|███████   | 3222/4545 [3:28:46<1:17:12,  3.50s/it] 71%|███████   | 3223/4545 [3:28:50<1:19:23,  3.60s/it] 71%|███████   | 3224/4545 [3:28:54<1:22:11,  3.73s/it] 71%|███████   | 3225/4545 [3:28:57<1:16:52,  3.49s/it] 71%|███████   | 3226/4545 [3:29:00<1:13:34,  3.35s/it] 71%|███████   | 3227/4545 [3:29:04<1:16:58,  3.50s/it] 71%|███████   | 3228/4545 [3:29:08<1:21:21,  3.71s/it] 71%|███████   | 3229/4545 [3:29:12<1:20:00,  3.65s/it] 71%|███████   | 3230/4545 [3:29:16<1:21:33,  3.72s/it]                                                       {'loss': 0.1093, 'grad_norm': 19.390544891357422, 'learning_rate': 4.576110510838973e-07, 'rewards/chosen': 1.498046875, 'rewards/rejected': -16.458984375, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 17.943750381469727, 'logps/chosen': -253.5500030517578, 'logps/rejected': -223.39999389648438, 'logits/chosen': -8.53125, 'logits/rejected': -7.931250095367432, 'epoch': 2.13}
 71%|███████   | 3230/4545 [3:29:16<1:21:33,  3.72s/it] 71%|███████   | 3231/4545 [3:29:19<1:21:05,  3.70s/it] 71%|███████   | 3232/4545 [3:29:23<1:20:15,  3.67s/it] 71%|███████   | 3233/4545 [3:29:27<1:21:37,  3.73s/it] 71%|███████   | 3234/4545 [3:29:31<1:23:48,  3.84s/it] 71%|███████   | 3235/4545 [3:29:35<1:25:41,  3.92s/it] 71%|███████   | 3236/4545 [3:29:39<1:25:18,  3.91s/it] 71%|███████   | 3237/4545 [3:29:43<1:25:19,  3.91s/it] 71%|███████   | 3238/4545 [3:29:47<1:25:07,  3.91s/it] 71%|███████▏  | 3239/4545 [3:29:50<1:23:34,  3.84s/it] 71%|███████▏  | 3240/4545 [3:29:53<1:18:24,  3.61s/it]                                                       {'loss': 0.0818, 'grad_norm': 14.959320068359375, 'learning_rate': 4.530512632691106e-07, 'rewards/chosen': 2.2533202171325684, 'rewards/rejected': -15.403124809265137, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 17.637500762939453, 'logps/chosen': -259.95001220703125, 'logps/rejected': -190.89999389648438, 'logits/chosen': -8.65625, 'logits/rejected': -8.024999618530273, 'epoch': 2.14}
 71%|███████▏  | 3240/4545 [3:29:54<1:18:24,  3.61s/it] 71%|███████▏  | 3241/4545 [3:29:58<1:22:52,  3.81s/it] 71%|███████▏  | 3242/4545 [3:30:02<1:23:14,  3.83s/it] 71%|███████▏  | 3243/4545 [3:30:05<1:21:45,  3.77s/it] 71%|███████▏  | 3244/4545 [3:30:09<1:22:29,  3.80s/it] 71%|███████▏  | 3245/4545 [3:30:13<1:23:00,  3.83s/it] 71%|███████▏  | 3246/4545 [3:30:16<1:18:14,  3.61s/it] 71%|███████▏  | 3247/4545 [3:30:19<1:15:17,  3.48s/it] 71%|███████▏  | 3248/4545 [3:30:23<1:17:33,  3.59s/it] 71%|███████▏  | 3249/4545 [3:30:27<1:19:48,  3.70s/it] 72%|███████▏  | 3250/4545 [3:30:30<1:17:37,  3.60s/it]                                                       {'loss': 0.1331, 'grad_norm': 26.95221710205078, 'learning_rate': 4.485018906189528e-07, 'rewards/chosen': 3.2598633766174316, 'rewards/rejected': -11.925000190734863, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 15.178125381469727, 'logps/chosen': -318.3500061035156, 'logps/rejected': -228.8000030517578, 'logits/chosen': -8.381250381469727, 'logits/rejected': -8.0625, 'epoch': 2.15}
 72%|███████▏  | 3250/4545 [3:30:31<1:17:37,  3.60s/it] 72%|███████▏  | 3251/4545 [3:30:35<1:21:19,  3.77s/it] 72%|███████▏  | 3252/4545 [3:30:39<1:23:02,  3.85s/it] 72%|███████▏  | 3253/4545 [3:30:42<1:20:47,  3.75s/it] 72%|███████▏  | 3254/4545 [3:30:46<1:22:37,  3.84s/it] 72%|███████▏  | 3255/4545 [3:30:50<1:24:32,  3.93s/it] 72%|███████▏  | 3256/4545 [3:30:53<1:18:45,  3.67s/it] 72%|███████▏  | 3257/4545 [3:30:57<1:19:26,  3.70s/it] 72%|███████▏  | 3258/4545 [3:31:01<1:20:42,  3.76s/it] 72%|███████▏  | 3259/4545 [3:31:05<1:21:09,  3.79s/it] 72%|███████▏  | 3260/4545 [3:31:09<1:21:40,  3.81s/it]                                                       {'loss': 0.1316, 'grad_norm': 23.061477661132812, 'learning_rate': 4.439634218707371e-07, 'rewards/chosen': 1.5144774913787842, 'rewards/rejected': -12.378125190734863, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 13.899999618530273, 'logps/chosen': -250.1999969482422, 'logps/rejected': -219.14999389648438, 'logits/chosen': -8.46875, 'logits/rejected': -8.146875381469727, 'epoch': 2.15}
 72%|███████▏  | 3260/4545 [3:31:09<1:21:40,  3.81s/it] 72%|███████▏  | 3261/4545 [3:31:13<1:22:21,  3.85s/it] 72%|███████▏  | 3262/4545 [3:31:17<1:22:37,  3.86s/it] 72%|███████▏  | 3263/4545 [3:31:20<1:21:17,  3.80s/it] 72%|███████▏  | 3264/4545 [3:31:24<1:18:00,  3.65s/it] 72%|███████▏  | 3265/4545 [3:31:27<1:19:07,  3.71s/it] 72%|███████▏  | 3266/4545 [3:31:31<1:20:58,  3.80s/it] 72%|███████▏  | 3267/4545 [3:31:35<1:21:25,  3.82s/it] 72%|███████▏  | 3268/4545 [3:31:38<1:14:25,  3.50s/it] 72%|███████▏  | 3269/4545 [3:31:42<1:17:17,  3.63s/it] 72%|███████▏  | 3270/4545 [3:31:46<1:20:33,  3.79s/it]                                                       {'loss': 0.0883, 'grad_norm': 9.062789916992188, 'learning_rate': 4.394363445903749e-07, 'rewards/chosen': 3.595752000808716, 'rewards/rejected': -7.942968845367432, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 11.537500381469727, 'logps/chosen': -326.5, 'logps/rejected': -286.95001220703125, 'logits/chosen': -8.596875190734863, 'logits/rejected': -8.15625, 'epoch': 2.16}
 72%|███████▏  | 3270/4545 [3:31:46<1:20:33,  3.79s/it] 72%|███████▏  | 3271/4545 [3:31:50<1:21:30,  3.84s/it] 72%|███████▏  | 3272/4545 [3:31:53<1:17:22,  3.65s/it] 72%|███████▏  | 3273/4545 [3:31:57<1:18:47,  3.72s/it] 72%|███████▏  | 3274/4545 [3:32:00<1:11:36,  3.38s/it] 72%|███████▏  | 3275/4545 [3:32:03<1:10:29,  3.33s/it] 72%|███████▏  | 3276/4545 [3:32:07<1:15:37,  3.58s/it] 72%|███████▏  | 3277/4545 [3:32:11<1:15:21,  3.57s/it] 72%|███████▏  | 3278/4545 [3:32:14<1:17:05,  3.65s/it] 72%|███████▏  | 3279/4545 [3:32:18<1:18:35,  3.72s/it] 72%|███████▏  | 3280/4545 [3:32:21<1:12:20,  3.43s/it]                                                       {'loss': 0.1063, 'grad_norm': 4.4121551513671875, 'learning_rate': 4.3492114511999646e-07, 'rewards/chosen': 1.9681396484375, 'rewards/rejected': -10.587499618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.584375381469727, 'logps/chosen': -236.125, 'logps/rejected': -164.39999389648438, 'logits/chosen': -8.78125, 'logits/rejected': -8.237500190734863, 'epoch': 2.17}
 72%|███████▏  | 3280/4545 [3:32:21<1:12:20,  3.43s/it] 72%|███████▏  | 3281/4545 [3:32:25<1:14:17,  3.53s/it] 72%|███████▏  | 3282/4545 [3:32:27<1:07:17,  3.20s/it] 72%|███████▏  | 3283/4545 [3:32:31<1:11:42,  3.41s/it] 72%|███████▏  | 3284/4545 [3:32:35<1:14:35,  3.55s/it] 72%|███████▏  | 3285/4545 [3:32:38<1:11:59,  3.43s/it] 72%|███████▏  | 3286/4545 [3:32:42<1:15:25,  3.59s/it] 72%|███████▏  | 3287/4545 [3:32:45<1:08:32,  3.27s/it] 72%|███████▏  | 3288/4545 [3:32:49<1:12:52,  3.48s/it] 72%|███████▏  | 3289/4545 [3:32:52<1:08:36,  3.28s/it] 72%|███████▏  | 3290/4545 [3:32:56<1:13:02,  3.49s/it]                                                       {'loss': 0.0728, 'grad_norm': 24.44363784790039, 'learning_rate': 4.304183085257038e-07, 'rewards/chosen': 1.185400366783142, 'rewards/rejected': -13.143750190734863, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 14.350000381469727, 'logps/chosen': -200.35000610351562, 'logps/rejected': -180.0500030517578, 'logits/chosen': -8.615625381469727, 'logits/rejected': -8.09375, 'epoch': 2.17}
 72%|███████▏  | 3290/4545 [3:32:56<1:13:02,  3.49s/it] 72%|███████▏  | 3291/4545 [3:32:59<1:14:00,  3.54s/it] 72%|███████▏  | 3292/4545 [3:33:03<1:15:12,  3.60s/it] 72%|███████▏  | 3293/4545 [3:33:06<1:14:09,  3.55s/it] 72%|███████▏  | 3294/4545 [3:33:10<1:16:29,  3.67s/it] 72%|███████▏  | 3295/4545 [3:33:14<1:17:29,  3.72s/it] 73%|███████▎  | 3296/4545 [3:33:18<1:18:30,  3.77s/it] 73%|███████▎  | 3297/4545 [3:33:22<1:19:23,  3.82s/it] 73%|███████▎  | 3298/4545 [3:33:26<1:19:31,  3.83s/it] 73%|███████▎  | 3299/4545 [3:33:29<1:12:57,  3.51s/it] 73%|███████▎  | 3300/4545 [3:33:32<1:15:19,  3.63s/it]                                                       {'loss': 0.0712, 'grad_norm': 18.898927688598633, 'learning_rate': 4.259283185454602e-07, 'rewards/chosen': 1.851953148841858, 'rewards/rejected': -12.737500190734863, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 14.571874618530273, 'logps/chosen': -244.35000610351562, 'logps/rejected': -158.4499969482422, 'logits/chosen': -8.643750190734863, 'logits/rejected': -8.128125190734863, 'epoch': 2.18}
 73%|███████▎  | 3300/4545 [3:33:33<1:15:19,  3.63s/it] 73%|███████▎  | 3301/4545 [3:33:36<1:15:06,  3.62s/it] 73%|███████▎  | 3302/4545 [3:33:39<1:12:41,  3.51s/it] 73%|███████▎  | 3303/4545 [3:33:43<1:16:19,  3.69s/it] 73%|███████▎  | 3304/4545 [3:33:47<1:13:20,  3.55s/it] 73%|███████▎  | 3305/4545 [3:33:50<1:14:51,  3.62s/it] 73%|███████▎  | 3306/4545 [3:33:54<1:16:20,  3.70s/it] 73%|███████▎  | 3307/4545 [3:33:58<1:17:21,  3.75s/it] 73%|███████▎  | 3308/4545 [3:34:02<1:18:09,  3.79s/it] 73%|███████▎  | 3309/4545 [3:34:06<1:20:04,  3.89s/it] 73%|███████▎  | 3310/4545 [3:34:10<1:18:23,  3.81s/it]                                                       {'loss': 0.0649, 'grad_norm': 12.105565071105957, 'learning_rate': 4.2145165753712173e-07, 'rewards/chosen': 2.3744139671325684, 'rewards/rejected': -13.778124809265137, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 16.15625, 'logps/chosen': -283.04998779296875, 'logps/rejected': -209.75, 'logits/chosen': -8.612500190734863, 'logits/rejected': -7.96875, 'epoch': 2.18}
 73%|███████▎  | 3310/4545 [3:34:10<1:18:23,  3.81s/it] 73%|███████▎  | 3311/4545 [3:34:14<1:19:08,  3.85s/it] 73%|███████▎  | 3312/4545 [3:34:18<1:19:17,  3.86s/it] 73%|███████▎  | 3313/4545 [3:34:22<1:21:21,  3.96s/it] 73%|███████▎  | 3314/4545 [3:34:26<1:19:52,  3.89s/it] 73%|███████▎  | 3315/4545 [3:34:29<1:19:41,  3.89s/it] 73%|███████▎  | 3316/4545 [3:34:34<1:21:21,  3.97s/it] 73%|███████▎  | 3317/4545 [3:34:36<1:12:52,  3.56s/it] 73%|███████▎  | 3318/4545 [3:34:40<1:13:59,  3.62s/it] 73%|███████▎  | 3319/4545 [3:34:43<1:13:00,  3.57s/it] 73%|███████▎  | 3320/4545 [3:34:48<1:16:01,  3.72s/it]                                                       {'loss': 0.113, 'grad_norm': 41.993289947509766, 'learning_rate': 4.169888064266188e-07, 'rewards/chosen': 3.703418016433716, 'rewards/rejected': -13.4453125, 'rewards/accuracies': 0.9375, 'rewards/margins': 17.137500762939453, 'logps/chosen': -346.3999938964844, 'logps/rejected': -246.10000610351562, 'logits/chosen': -8.243749618530273, 'logits/rejected': -7.778124809265137, 'epoch': 2.19}
 73%|███████▎  | 3320/4545 [3:34:48<1:16:01,  3.72s/it] 73%|███████▎  | 3321/4545 [3:34:51<1:14:26,  3.65s/it] 73%|███████▎  | 3322/4545 [3:34:54<1:11:52,  3.53s/it] 73%|███████▎  | 3323/4545 [3:34:58<1:13:59,  3.63s/it] 73%|███████▎  | 3324/4545 [3:35:02<1:15:52,  3.73s/it] 73%|███████▎  | 3325/4545 [3:35:05<1:08:54,  3.39s/it] 73%|███████▎  | 3326/4545 [3:35:08<1:11:36,  3.52s/it] 73%|███████▎  | 3327/4545 [3:35:12<1:13:25,  3.62s/it] 73%|███████▎  | 3328/4545 [3:35:16<1:13:37,  3.63s/it] 73%|███████▎  | 3329/4545 [3:35:20<1:15:17,  3.71s/it] 73%|███████▎  | 3330/4545 [3:35:24<1:16:00,  3.75s/it]                                                       {'loss': 0.0814, 'grad_norm': 8.263089179992676, 'learning_rate': 4.1254024465628933e-07, 'rewards/chosen': 1.29345703125, 'rewards/rejected': -12.17578125, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.459375381469727, 'logps/chosen': -210.0, 'logps/rejected': -190.0, 'logits/chosen': -8.637499809265137, 'logits/rejected': -8.196874618530273, 'epoch': 2.2}
 73%|███████▎  | 3330/4545 [3:35:24<1:16:00,  3.75s/it] 73%|███████▎  | 3331/4545 [3:35:28<1:17:01,  3.81s/it] 73%|███████▎  | 3332/4545 [3:35:32<1:17:21,  3.83s/it] 73%|███████▎  | 3333/4545 [3:35:35<1:15:47,  3.75s/it] 73%|███████▎  | 3334/4545 [3:35:38<1:09:30,  3.44s/it] 73%|███████▎  | 3335/4545 [3:35:41<1:05:44,  3.26s/it] 73%|███████▎  | 3336/4545 [3:35:43<1:01:24,  3.05s/it] 73%|███████▎  | 3337/4545 [3:35:46<1:00:16,  2.99s/it] 73%|███████▎  | 3338/4545 [3:35:50<1:05:40,  3.26s/it] 73%|███████▎  | 3339/4545 [3:35:53<1:05:13,  3.24s/it] 73%|███████▎  | 3340/4545 [3:35:55<58:46,  2.93s/it]                                                       {'loss': 0.1419, 'grad_norm': 8.207938194274902, 'learning_rate': 4.0810645013337376e-07, 'rewards/chosen': 0.70733642578125, 'rewards/rejected': -12.884374618530273, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 13.584375381469727, 'logps/chosen': -156.77499389648438, 'logps/rejected': -154.5500030517578, 'logits/chosen': -8.649999618530273, 'logits/rejected': -8.034375190734863, 'epoch': 2.2}
 73%|███████▎  | 3340/4545 [3:35:56<58:46,  2.93s/it] 74%|███████▎  | 3341/4545 [3:35:59<1:05:25,  3.26s/it] 74%|███████▎  | 3342/4545 [3:36:03<1:10:18,  3.51s/it] 74%|███████▎  | 3343/4545 [3:36:07<1:13:09,  3.65s/it] 74%|███████▎  | 3344/4545 [3:36:11<1:14:13,  3.71s/it] 74%|███████▎  | 3345/4545 [3:36:15<1:11:31,  3.58s/it] 74%|███████▎  | 3346/4545 [3:36:19<1:13:39,  3.69s/it] 74%|███████▎  | 3347/4545 [3:36:22<1:14:07,  3.71s/it] 74%|███████▎  | 3348/4545 [3:36:26<1:15:50,  3.80s/it] 74%|███████▎  | 3349/4545 [3:36:30<1:14:22,  3.73s/it] 74%|███████▎  | 3350/4545 [3:36:33<1:13:14,  3.68s/it]                                                       {'loss': 0.0698, 'grad_norm': 30.586328506469727, 'learning_rate': 4.0368789917867243e-07, 'rewards/chosen': 1.613378882408142, 'rewards/rejected': -12.459375381469727, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 14.053125381469727, 'logps/chosen': -222.1999969482422, 'logps/rejected': -206.6999969482422, 'logits/chosen': -8.409375190734863, 'logits/rejected': -7.943749904632568, 'epoch': 2.21}
 74%|███████▎  | 3350/4545 [3:36:34<1:13:14,  3.68s/it] 74%|███████▎  | 3351/4545 [3:36:37<1:11:44,  3.61s/it] 74%|███████▍  | 3352/4545 [3:36:40<1:11:26,  3.59s/it] 74%|███████▍  | 3353/4545 [3:36:44<1:11:24,  3.59s/it] 74%|███████▍  | 3354/4545 [3:36:48<1:13:01,  3.68s/it] 74%|███████▍  | 3355/4545 [3:36:51<1:12:15,  3.64s/it] 74%|███████▍  | 3356/4545 [3:36:55<1:13:40,  3.72s/it] 74%|███████▍  | 3357/4545 [3:36:59<1:14:32,  3.76s/it] 74%|███████▍  | 3358/4545 [3:37:03<1:15:10,  3.80s/it] 74%|███████▍  | 3359/4545 [3:37:07<1:15:37,  3.83s/it] 74%|███████▍  | 3360/4545 [3:37:11<1:15:55,  3.84s/it]                                                       {'loss': 0.2604, 'grad_norm': 0.6540831327438354, 'learning_rate': 3.992850664753751e-07, 'rewards/chosen': 3.899218797683716, 'rewards/rejected': -12.729687690734863, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.649999618530273, 'logps/chosen': -366.79998779296875, 'logps/rejected': -263.70001220703125, 'logits/chosen': -8.228124618530273, 'logits/rejected': -7.875, 'epoch': 2.22}
 74%|███████▍  | 3360/4545 [3:37:11<1:15:55,  3.84s/it] 74%|███████▍  | 3361/4545 [3:37:15<1:16:21,  3.87s/it] 74%|███████▍  | 3362/4545 [3:37:18<1:13:54,  3.75s/it] 74%|███████▍  | 3363/4545 [3:37:22<1:14:03,  3.76s/it] 74%|███████▍  | 3364/4545 [3:37:26<1:14:41,  3.79s/it] 74%|███████▍  | 3365/4545 [3:37:30<1:14:37,  3.79s/it] 74%|███████▍  | 3366/4545 [3:37:34<1:14:25,  3.79s/it] 74%|███████▍  | 3367/4545 [3:37:38<1:16:23,  3.89s/it] 74%|███████▍  | 3368/4545 [3:37:40<1:08:37,  3.50s/it] 74%|███████▍  | 3369/4545 [3:37:44<1:10:55,  3.62s/it] 74%|███████▍  | 3370/4545 [3:37:48<1:12:40,  3.71s/it]                                                       {'loss': 0.0985, 'grad_norm': 22.609128952026367, 'learning_rate': 3.948984250180665e-07, 'rewards/chosen': 2.560253858566284, 'rewards/rejected': -11.993749618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 14.543749809265137, 'logps/chosen': -275.1499938964844, 'logps/rejected': -206.60000610351562, 'logits/chosen': -8.346875190734863, 'logits/rejected': -7.828125, 'epoch': 2.22}
 74%|███████▍  | 3370/4545 [3:37:48<1:12:40,  3.71s/it] 74%|███████▍  | 3371/4545 [3:37:52<1:11:09,  3.64s/it] 74%|███████▍  | 3372/4545 [3:37:55<1:12:23,  3.70s/it] 74%|███████▍  | 3373/4545 [3:37:59<1:10:46,  3.62s/it] 74%|███████▍  | 3374/4545 [3:38:03<1:13:19,  3.76s/it] 74%|███████▍  | 3375/4545 [3:38:07<1:13:47,  3.78s/it] 74%|███████▍  | 3376/4545 [3:38:10<1:08:31,  3.52s/it] 74%|███████▍  | 3377/4545 [3:38:13<1:09:39,  3.58s/it] 74%|███████▍  | 3378/4545 [3:38:17<1:07:41,  3.48s/it] 74%|███████▍  | 3379/4545 [3:38:21<1:11:43,  3.69s/it] 74%|███████▍  | 3380/4545 [3:38:24<1:10:08,  3.61s/it]                                                       {'loss': 0.0706, 'grad_norm': 30.43058204650879, 'learning_rate': 3.905284460619117e-07, 'rewards/chosen': 2.4673829078674316, 'rewards/rejected': -11.878125190734863, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 14.318750381469727, 'logps/chosen': -267.20001220703125, 'logps/rejected': -249.10000610351562, 'logits/chosen': -8.399999618530273, 'logits/rejected': -7.728125095367432, 'epoch': 2.23}
 74%|███████▍  | 3380/4545 [3:38:25<1:10:08,  3.61s/it] 74%|███████▍  | 3381/4545 [3:38:28<1:12:39,  3.74s/it] 74%|███████▍  | 3382/4545 [3:38:32<1:13:25,  3.79s/it] 74%|███████▍  | 3383/4545 [3:38:36<1:11:45,  3.71s/it] 74%|███████▍  | 3384/4545 [3:38:40<1:14:01,  3.83s/it] 74%|███████▍  | 3385/4545 [3:38:44<1:15:09,  3.89s/it] 74%|███████▍  | 3386/4545 [3:38:48<1:16:13,  3.95s/it] 75%|███████▍  | 3387/4545 [3:38:52<1:15:35,  3.92s/it] 75%|███████▍  | 3388/4545 [3:38:56<1:16:40,  3.98s/it] 75%|███████▍  | 3389/4545 [3:39:00<1:17:38,  4.03s/it] 75%|███████▍  | 3390/4545 [3:39:04<1:16:37,  3.98s/it]                                                       {'loss': 0.0711, 'grad_norm': 30.176708221435547, 'learning_rate': 3.861755990720301e-07, 'rewards/chosen': 2.1758790016174316, 'rewards/rejected': -13.259374618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 15.449999809265137, 'logps/chosen': -307.6000061035156, 'logps/rejected': -260.70001220703125, 'logits/chosen': -8.309374809265137, 'logits/rejected': -7.800000190734863, 'epoch': 2.24}
 75%|███████▍  | 3390/4545 [3:39:04<1:16:37,  3.98s/it] 75%|███████▍  | 3391/4545 [3:39:08<1:16:24,  3.97s/it] 75%|███████▍  | 3392/4545 [3:39:12<1:17:32,  4.04s/it] 75%|███████▍  | 3393/4545 [3:39:15<1:14:15,  3.87s/it] 75%|███████▍  | 3394/4545 [3:39:19<1:14:19,  3.87s/it] 75%|███████▍  | 3395/4545 [3:39:23<1:13:52,  3.85s/it] 75%|███████▍  | 3396/4545 [3:39:26<1:09:50,  3.65s/it] 75%|███████▍  | 3397/4545 [3:39:30<1:11:09,  3.72s/it] 75%|███████▍  | 3398/4545 [3:39:33<1:06:17,  3.47s/it] 75%|███████▍  | 3399/4545 [3:39:36<1:05:43,  3.44s/it] 75%|███████▍  | 3400/4545 [3:39:40<1:04:58,  3.40s/it]                                                       {'loss': 0.0675, 'grad_norm': 5.149589538574219, 'learning_rate': 3.818403516730604e-07, 'rewards/chosen': 2.1302733421325684, 'rewards/rejected': -12.199999809265137, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 14.34375, 'logps/chosen': -267.20001220703125, 'logps/rejected': -237.4499969482422, 'logits/chosen': -8.671875, 'logits/rejected': -7.940625190734863, 'epoch': 2.24}
 75%|███████▍  | 3400/4545 [3:39:40<1:04:58,  3.40s/it] 75%|███████▍  | 3401/4545 [3:39:44<1:10:12,  3.68s/it] 75%|███████▍  | 3402/4545 [3:39:48<1:11:42,  3.76s/it] 75%|███████▍  | 3403/4545 [3:39:52<1:13:43,  3.87s/it] 75%|███████▍  | 3404/4545 [3:39:56<1:15:30,  3.97s/it] 75%|███████▍  | 3405/4545 [3:40:00<1:12:26,  3.81s/it] 75%|███████▍  | 3406/4545 [3:40:02<1:04:18,  3.39s/it] 75%|███████▍  | 3407/4545 [3:40:05<1:02:05,  3.27s/it] 75%|███████▍  | 3408/4545 [3:40:09<1:05:54,  3.48s/it] 75%|███████▌  | 3409/4545 [3:40:13<1:07:28,  3.56s/it] 75%|███████▌  | 3410/4545 [3:40:17<1:08:20,  3.61s/it]                                                       {'loss': 0.1136, 'grad_norm': 8.541452407836914, 'learning_rate': 3.7752316959892436e-07, 'rewards/chosen': 0.582080066204071, 'rewards/rejected': -16.121875762939453, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.728124618530273, 'logps/chosen': -223.25, 'logps/rejected': -178.89999389648438, 'logits/chosen': -8.5625, 'logits/rejected': -8.065625190734863, 'epoch': 2.25}
 75%|███████▌  | 3410/4545 [3:40:17<1:08:20,  3.61s/it] 75%|███████▌  | 3411/4545 [3:40:21<1:09:53,  3.70s/it] 75%|███████▌  | 3412/4545 [3:40:24<1:10:03,  3.71s/it] 75%|███████▌  | 3413/4545 [3:40:28<1:11:03,  3.77s/it] 75%|███████▌  | 3414/4545 [3:40:31<1:06:26,  3.53s/it] 75%|███████▌  | 3415/4545 [3:40:35<1:07:15,  3.57s/it] 75%|███████▌  | 3416/4545 [3:40:39<1:09:02,  3.67s/it] 75%|███████▌  | 3417/4545 [3:40:43<1:10:14,  3.74s/it] 75%|███████▌  | 3418/4545 [3:40:46<1:10:17,  3.74s/it] 75%|███████▌  | 3419/4545 [3:40:50<1:10:44,  3.77s/it] 75%|███████▌  | 3420/4545 [3:40:54<1:08:46,  3.67s/it]                                                       {'loss': 0.0758, 'grad_norm': 2.6186811923980713, 'learning_rate': 3.732245166427933e-07, 'rewards/chosen': 1.643945336341858, 'rewards/rejected': -14.393750190734863, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 16.043750762939453, 'logps/chosen': -242.85000610351562, 'logps/rejected': -217.9499969482422, 'logits/chosen': -8.5625, 'logits/rejected': -8.071874618530273, 'epoch': 2.26}
 75%|███████▌  | 3420/4545 [3:40:54<1:08:46,  3.67s/it] 75%|███████▌  | 3421/4545 [3:40:58<1:11:52,  3.84s/it] 75%|███████▌  | 3422/4545 [3:41:02<1:13:47,  3.94s/it] 75%|███████▌  | 3423/4545 [3:41:05<1:07:34,  3.61s/it] 75%|███████▌  | 3424/4545 [3:41:09<1:10:44,  3.79s/it] 75%|███████▌  | 3425/4545 [3:41:13<1:11:31,  3.83s/it] 75%|███████▌  | 3426/4545 [3:41:17<1:10:59,  3.81s/it] 75%|███████▌  | 3427/4545 [3:41:21<1:10:49,  3.80s/it] 75%|███████▌  | 3428/4545 [3:41:25<1:11:11,  3.82s/it] 75%|███████▌  | 3429/4545 [3:41:28<1:11:46,  3.86s/it] 75%|███████▌  | 3430/4545 [3:41:32<1:11:50,  3.87s/it]                                                       {'loss': 0.0941, 'grad_norm': 5.7561140060424805, 'learning_rate': 3.689448546072619e-07, 'rewards/chosen': 1.8203125, 'rewards/rejected': -11.087499618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 12.90625, 'logps/chosen': -287.75, 'logps/rejected': -215.0, 'logits/chosen': -8.425000190734863, 'logits/rejected': -7.865624904632568, 'epoch': 2.26}
 75%|███████▌  | 3430/4545 [3:41:33<1:11:50,  3.87s/it] 75%|███████▌  | 3431/4545 [3:41:35<1:03:44,  3.43s/it] 76%|███████▌  | 3432/4545 [3:41:37<57:49,  3.12s/it]   76%|███████▌  | 3433/4545 [3:41:41<1:01:52,  3.34s/it] 76%|███████▌  | 3434/4545 [3:41:45<1:04:48,  3.50s/it] 76%|███████▌  | 3435/4545 [3:41:48<1:04:45,  3.50s/it] 76%|███████▌  | 3436/4545 [3:41:52<1:06:35,  3.60s/it] 76%|███████▌  | 3437/4545 [3:41:56<1:07:55,  3.68s/it] 76%|███████▌  | 3438/4545 [3:42:00<1:08:56,  3.74s/it] 76%|███████▌  | 3439/4545 [3:42:04<1:11:10,  3.86s/it] 76%|███████▌  | 3440/4545 [3:42:08<1:08:45,  3.73s/it]                                                       {'loss': 0.0791, 'grad_norm': 23.07113265991211, 'learning_rate': 3.646846432547387e-07, 'rewards/chosen': 1.850341796875, 'rewards/rejected': -11.853124618530273, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 13.712499618530273, 'logps/chosen': -222.5, 'logps/rejected': -151.5, 'logits/chosen': -8.521875381469727, 'logits/rejected': -8.003125190734863, 'epoch': 2.27}
 76%|███████▌  | 3440/4545 [3:42:08<1:08:45,  3.73s/it] 76%|███████▌  | 3441/4545 [3:42:11<1:09:34,  3.78s/it] 76%|███████▌  | 3442/4545 [3:42:15<1:09:55,  3.80s/it] 76%|███████▌  | 3443/4545 [3:42:19<1:10:03,  3.81s/it] 76%|███████▌  | 3444/4545 [3:42:23<1:10:21,  3.83s/it] 76%|███████▌  | 3445/4545 [3:42:27<1:11:27,  3.90s/it] 76%|███████▌  | 3446/4545 [3:42:31<1:11:02,  3.88s/it] 76%|███████▌  | 3447/4545 [3:42:34<1:09:23,  3.79s/it] 76%|███████▌  | 3448/4545 [3:42:39<1:10:44,  3.87s/it] 76%|███████▌  | 3449/4545 [3:42:42<1:10:42,  3.87s/it] 76%|███████▌  | 3450/4545 [3:42:46<1:10:41,  3.87s/it]                                                       {'loss': 0.0572, 'grad_norm': 19.53300666809082, 'learning_rate': 3.604443402580523e-07, 'rewards/chosen': 2.9359374046325684, 'rewards/rejected': -11.784375190734863, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 14.712499618530273, 'logps/chosen': -300.20001220703125, 'logps/rejected': -204.10000610351562, 'logits/chosen': -8.3125, 'logits/rejected': -7.759375095367432, 'epoch': 2.28}
 76%|███████▌  | 3450/4545 [3:42:46<1:10:41,  3.87s/it] 76%|███████▌  | 3451/4545 [3:42:50<1:10:54,  3.89s/it] 76%|███████▌  | 3452/4545 [3:42:53<1:04:10,  3.52s/it] 76%|███████▌  | 3453/4545 [3:42:56<1:01:09,  3.36s/it] 76%|███████▌  | 3454/4545 [3:43:00<1:03:53,  3.51s/it] 76%|███████▌  | 3455/4545 [3:43:04<1:05:19,  3.60s/it] 76%|███████▌  | 3456/4545 [3:43:07<1:06:48,  3.68s/it] 76%|███████▌  | 3457/4545 [3:43:12<1:09:23,  3.83s/it] 76%|███████▌  | 3458/4545 [3:43:15<1:09:41,  3.85s/it] 76%|███████▌  | 3459/4545 [3:43:20<1:11:16,  3.94s/it] 76%|███████▌  | 3460/4545 [3:43:23<1:07:04,  3.71s/it]                                                       {'loss': 0.0735, 'grad_norm': 12.275291442871094, 'learning_rate': 3.562244011512845e-07, 'rewards/chosen': 3.369824171066284, 'rewards/rejected': -10.015625, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 13.371874809265137, 'logps/chosen': -321.6000061035156, 'logps/rejected': -205.75, 'logits/chosen': -8.346875190734863, 'logits/rejected': -7.925000190734863, 'epoch': 2.28}
 76%|███████▌  | 3460/4545 [3:43:23<1:07:04,  3.71s/it] 76%|███████▌  | 3461/4545 [3:43:27<1:08:06,  3.77s/it] 76%|███████▌  | 3462/4545 [3:43:30<1:05:53,  3.65s/it] 76%|███████▌  | 3463/4545 [3:43:34<1:08:06,  3.78s/it] 76%|███████▌  | 3464/4545 [3:43:38<1:08:37,  3.81s/it] 76%|███████▌  | 3465/4545 [3:43:42<1:10:17,  3.91s/it] 76%|███████▋  | 3466/4545 [3:43:45<1:06:28,  3.70s/it] 76%|███████▋  | 3467/4545 [3:43:49<1:07:24,  3.75s/it] 76%|███████▋  | 3468/4545 [3:43:53<1:05:27,  3.65s/it] 76%|███████▋  | 3469/4545 [3:43:57<1:07:16,  3.75s/it] 76%|███████▋  | 3470/4545 [3:44:01<1:08:15,  3.81s/it]                                                       {'loss': 0.0621, 'grad_norm': 8.3672513961792, 'learning_rate': 3.520252792808328e-07, 'rewards/chosen': 2.462695360183716, 'rewards/rejected': -13.440625190734863, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 15.90625, 'logps/chosen': -241.64999389648438, 'logps/rejected': -219.10000610351562, 'logits/chosen': -8.600000381469727, 'logits/rejected': -8.046875, 'epoch': 2.29}
 76%|███████▋  | 3470/4545 [3:44:01<1:08:15,  3.81s/it] 76%|███████▋  | 3471/4545 [3:44:05<1:10:15,  3.93s/it] 76%|███████▋  | 3472/4545 [3:44:09<1:09:54,  3.91s/it] 76%|███████▋  | 3473/4545 [3:44:12<1:06:10,  3.70s/it] 76%|███████▋  | 3474/4545 [3:44:16<1:07:02,  3.76s/it] 76%|███████▋  | 3475/4545 [3:44:19<1:04:07,  3.60s/it] 76%|███████▋  | 3476/4545 [3:44:23<1:05:24,  3.67s/it] 77%|███████▋  | 3477/4545 [3:44:27<1:06:28,  3.73s/it] 77%|███████▋  | 3478/4545 [3:44:31<1:07:14,  3.78s/it] 77%|███████▋  | 3479/4545 [3:44:34<1:07:41,  3.81s/it] 77%|███████▋  | 3480/4545 [3:44:38<1:08:04,  3.83s/it]                                                       {'loss': 0.0844, 'grad_norm': 14.020122528076172, 'learning_rate': 3.478474257567073e-07, 'rewards/chosen': 4.91015625, 'rewards/rejected': -13.353124618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 18.243749618530273, 'logps/chosen': -466.3999938964844, 'logps/rejected': -242.0, 'logits/chosen': -8.362500190734863, 'logits/rejected': -7.896874904632568, 'epoch': 2.3}
 77%|███████▋  | 3480/4545 [3:44:38<1:08:04,  3.83s/it] 77%|███████▋  | 3481/4545 [3:44:42<1:08:20,  3.85s/it] 77%|███████▋  | 3482/4545 [3:44:46<1:08:27,  3.86s/it] 77%|███████▋  | 3483/4545 [3:44:50<1:08:45,  3.88s/it] 77%|███████▋  | 3484/4545 [3:44:54<1:07:34,  3.82s/it] 77%|███████▋  | 3485/4545 [3:44:58<1:08:12,  3.86s/it] 77%|███████▋  | 3486/4545 [3:45:01<1:05:58,  3.74s/it] 77%|███████▋  | 3487/4545 [3:45:04<1:03:45,  3.62s/it] 77%|███████▋  | 3488/4545 [3:45:08<1:03:10,  3.59s/it] 77%|███████▋  | 3489/4545 [3:45:12<1:04:46,  3.68s/it] 77%|███████▋  | 3490/4545 [3:45:16<1:07:27,  3.84s/it]                                                       {'loss': 0.0642, 'grad_norm': 21.28474235534668, 'learning_rate': 3.436912894040672e-07, 'rewards/chosen': 3.7464842796325684, 'rewards/rejected': -12.634374618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 16.393749237060547, 'logps/chosen': -355.3500061035156, 'logps/rejected': -237.75, 'logits/chosen': -8.225000381469727, 'logits/rejected': -7.865624904632568, 'epoch': 2.3}
 77%|███████▋  | 3490/4545 [3:45:16<1:07:27,  3.84s/it] 77%|███████▋  | 3491/4545 [3:45:20<1:07:51,  3.86s/it] 77%|███████▋  | 3492/4545 [3:45:23<1:03:57,  3.64s/it] 77%|███████▋  | 3493/4545 [3:45:27<1:06:19,  3.78s/it] 77%|███████▋  | 3494/4545 [3:45:30<59:13,  3.38s/it]   77%|███████▋  | 3495/4545 [3:45:33<59:01,  3.37s/it] 77%|███████▋  | 3496/4545 [3:45:37<1:01:54,  3.54s/it] 77%|███████▋  | 3497/4545 [3:45:41<1:04:42,  3.70s/it] 77%|███████▋  | 3498/4545 [3:45:45<1:05:34,  3.76s/it] 77%|███████▋  | 3499/4545 [3:45:49<1:05:49,  3.78s/it] 77%|███████▋  | 3500/4545 [3:45:52<1:04:54,  3.73s/it]                                                       {'loss': 0.0978, 'grad_norm': 9.088017463684082, 'learning_rate': 3.395573167150054e-07, 'rewards/chosen': 2.673828125, 'rewards/rejected': -9.879687309265137, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 12.556249618530273, 'logps/chosen': -264.75, 'logps/rejected': -190.0, 'logits/chosen': -8.706250190734863, 'logits/rejected': -8.278124809265137, 'epoch': 2.31}
 77%|███████▋  | 3500/4545 [3:45:52<1:04:54,  3.73s/it] 77%|███████▋  | 3501/4545 [3:45:56<1:06:25,  3.82s/it] 77%|███████▋  | 3502/4545 [3:46:00<1:07:36,  3.89s/it] 77%|███████▋  | 3503/4545 [3:46:04<1:07:30,  3.89s/it] 77%|███████▋  | 3504/4545 [3:46:07<1:01:00,  3.52s/it] 77%|███████▋  | 3505/4545 [3:46:11<1:01:37,  3.55s/it] 77%|███████▋  | 3506/4545 [3:46:13<56:30,  3.26s/it]   77%|███████▋  | 3507/4545 [3:46:17<1:01:17,  3.54s/it] 77%|███████▋  | 3508/4545 [3:46:21<1:02:56,  3.64s/it] 77%|███████▋  | 3509/4545 [3:46:25<1:04:06,  3.71s/it] 77%|███████▋  | 3510/4545 [3:46:29<1:02:45,  3.64s/it]                                                       {'loss': 0.1273, 'grad_norm': 8.950772285461426, 'learning_rate': 3.354459518005807e-07, 'rewards/chosen': 3.8060545921325684, 'rewards/rejected': -11.670312881469727, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 15.487500190734863, 'logps/chosen': -348.6000061035156, 'logps/rejected': -267.54998779296875, 'logits/chosen': -8.475000381469727, 'logits/rejected': -7.956250190734863, 'epoch': 2.32}
 77%|███████▋  | 3510/4545 [3:46:29<1:02:45,  3.64s/it] 77%|███████▋  | 3511/4545 [3:46:33<1:05:34,  3.81s/it] 77%|███████▋  | 3512/4545 [3:46:37<1:05:56,  3.83s/it] 77%|███████▋  | 3513/4545 [3:46:41<1:06:07,  3.84s/it] 77%|███████▋  | 3514/4545 [3:46:44<1:06:17,  3.86s/it] 77%|███████▋  | 3515/4545 [3:46:48<1:04:17,  3.75s/it] 77%|███████▋  | 3516/4545 [3:46:52<1:04:58,  3.79s/it] 77%|███████▋  | 3517/4545 [3:46:56<1:05:27,  3.82s/it] 77%|███████▋  | 3518/4545 [3:46:59<1:04:36,  3.77s/it] 77%|███████▋  | 3519/4545 [3:47:02<59:27,  3.48s/it]   77%|███████▋  | 3520/4545 [3:47:06<1:01:27,  3.60s/it]                                                       {'loss': 0.0837, 'grad_norm': 31.14345932006836, 'learning_rate': 3.3135763634310755e-07, 'rewards/chosen': 6.065039157867432, 'rewards/rejected': -9.0234375, 'rewards/accuracies': 0.96875, 'rewards/margins': 15.103124618530273, 'logps/chosen': -445.54998779296875, 'logps/rejected': -299.8999938964844, 'logits/chosen': -8.375, 'logits/rejected': -7.987500190734863, 'epoch': 2.32}
 77%|███████▋  | 3520/4545 [3:47:06<1:01:27,  3.60s/it] 77%|███████▋  | 3521/4545 [3:47:10<1:02:39,  3.67s/it] 77%|███████▋  | 3522/4545 [3:47:14<1:03:38,  3.73s/it] 78%|███████▊  | 3523/4545 [3:47:17<1:03:12,  3.71s/it] 78%|███████▊  | 3524/4545 [3:47:21<1:04:04,  3.77s/it] 78%|███████▊  | 3525/4545 [3:47:25<1:03:16,  3.72s/it] 78%|███████▊  | 3526/4545 [3:47:28<1:01:19,  3.61s/it] 78%|███████▊  | 3527/4545 [3:47:31<56:12,  3.31s/it]   78%|███████▊  | 3528/4545 [3:47:35<59:21,  3.50s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:44,  1.31it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.53s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.64s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.53s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.39s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.09s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.31s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.09s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.32s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.40s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.46s/it][A
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.42017289996147156, 'eval_runtime': 80.8602, 'eval_samples_per_second': 11.786, 'eval_steps_per_second': 0.742, 'eval_rewards/chosen': 2.9109904766082764, 'eval_rewards/rejected': -9.760970115661621, 'eval_rewards/accuracies': 0.8363426327705383, 'eval_rewards/margins': 12.676285743713379, 'eval_logps/chosen': -363.1583251953125, 'eval_logps/rejected': -200.76666259765625, 'eval_logits/chosen': -8.225521087646484, 'eval_logits/rejected': -8.383333206176758, 'epoch': 2.33}
 78%|███████▊  | 3528/4545 [3:48:56<59:21,  3.50s/it]
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 78%|███████▊  | 3529/4545 [3:49:12<8:55:54, 31.65s/it] 78%|███████▊  | 3530/4545 [3:49:16<6:35:26, 23.38s/it]                                                       {'loss': 0.0763, 'grad_norm': 2.7111454010009766, 'learning_rate': 3.2729280954870655e-07, 'rewards/chosen': 1.55224609375, 'rewards/rejected': -12.318750381469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.890625, 'logps/chosen': -235.10000610351562, 'logps/rejected': -182.25, 'logits/chosen': -8.543749809265137, 'logits/rejected': -8.100000381469727, 'epoch': 2.33}
 78%|███████▊  | 3530/4545 [3:49:17<6:35:26, 23.38s/it] 78%|███████▊  | 3531/4545 [3:49:20<4:55:02, 17.46s/it] 78%|███████▊  | 3532/4545 [3:49:24<3:47:20, 13.47s/it] 78%|███████▊  | 3533/4545 [3:49:28<2:57:08, 10.50s/it] 78%|███████▊  | 3534/4545 [3:49:31<2:22:44,  8.47s/it] 78%|███████▊  | 3535/4545 [3:49:35<1:59:15,  7.08s/it] 78%|███████▊  | 3536/4545 [3:49:39<1:40:51,  6.00s/it] 78%|███████▊  | 3537/4545 [3:49:42<1:28:54,  5.29s/it] 78%|███████▊  | 3538/4545 [3:49:45<1:14:43,  4.45s/it] 78%|███████▊  | 3539/4545 [3:49:49<1:11:08,  4.24s/it] 78%|███████▊  | 3540/4545 [3:49:52<1:07:16,  4.02s/it]                                                       {'loss': 0.0449, 'grad_norm': 9.968040466308594, 'learning_rate': 3.232519081001205e-07, 'rewards/chosen': 0.19023437798023224, 'rewards/rejected': -13.565625190734863, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 13.759374618530273, 'logps/chosen': -142.89999389648438, 'logps/rejected': -162.3000030517578, 'logits/chosen': -8.668749809265137, 'logits/rejected': -8.112500190734863, 'epoch': 2.34}
 78%|███████▊  | 3540/4545 [3:49:52<1:07:16,  4.02s/it] 78%|███████▊  | 3541/4545 [3:49:56<1:08:33,  4.10s/it] 78%|███████▊  | 3542/4545 [3:50:01<1:08:38,  4.11s/it] 78%|███████▊  | 3543/4545 [3:50:04<1:07:18,  4.03s/it] 78%|███████▊  | 3544/4545 [3:50:08<1:05:27,  3.92s/it] 78%|███████▊  | 3545/4545 [3:50:12<1:05:08,  3.91s/it] 78%|███████▊  | 3546/4545 [3:50:16<1:04:57,  3.90s/it] 78%|███████▊  | 3547/4545 [3:50:20<1:04:45,  3.89s/it] 78%|███████▊  | 3548/4545 [3:50:23<1:00:03,  3.61s/it] 78%|███████▊  | 3549/4545 [3:50:26<1:01:02,  3.68s/it] 78%|███████▊  | 3550/4545 [3:50:30<1:02:37,  3.78s/it]                                                       {'loss': 0.1252, 'grad_norm': 9.846750259399414, 'learning_rate': 3.192353661098012e-07, 'rewards/chosen': 2.679492235183716, 'rewards/rejected': -10.951562881469727, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 13.628125190734863, 'logps/chosen': -271.3500061035156, 'logps/rejected': -212.3000030517578, 'logits/chosen': -8.559374809265137, 'logits/rejected': -7.993750095367432, 'epoch': 2.34}
 78%|███████▊  | 3550/4545 [3:50:31<1:02:37,  3.78s/it] 78%|███████▊  | 3551/4545 [3:50:34<1:03:11,  3.81s/it] 78%|███████▊  | 3552/4545 [3:50:38<1:03:28,  3.84s/it] 78%|███████▊  | 3553/4545 [3:50:42<1:04:42,  3.91s/it] 78%|███████▊  | 3554/4545 [3:50:46<1:03:38,  3.85s/it] 78%|███████▊  | 3555/4545 [3:50:50<1:03:41,  3.86s/it] 78%|███████▊  | 3556/4545 [3:50:54<1:04:01,  3.88s/it] 78%|███████▊  | 3557/4545 [3:50:57<1:02:35,  3.80s/it] 78%|███████▊  | 3558/4545 [3:51:01<1:02:57,  3.83s/it] 78%|███████▊  | 3559/4545 [3:51:05<59:32,  3.62s/it]   78%|███████▊  | 3560/4545 [3:51:08<1:00:02,  3.66s/it]                                                       {'loss': 0.1771, 'grad_norm': 13.723273277282715, 'learning_rate': 3.15243615073274e-07, 'rewards/chosen': 3.553466796875, 'rewards/rejected': -14.074999809265137, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 17.59375, 'logps/chosen': -348.04998779296875, 'logps/rejected': -251.8000030517578, 'logits/chosen': -8.337499618530273, 'logits/rejected': -7.940625190734863, 'epoch': 2.35}
 78%|███████▊  | 3560/4545 [3:51:08<1:00:02,  3.66s/it] 78%|███████▊  | 3561/4545 [3:51:12<59:29,  3.63s/it]   78%|███████▊  | 3562/4545 [3:51:16<1:00:09,  3.67s/it] 78%|███████▊  | 3563/4545 [3:51:19<59:08,  3.61s/it]   78%|███████▊  | 3564/4545 [3:51:23<1:00:12,  3.68s/it] 78%|███████▊  | 3565/4545 [3:51:27<1:00:55,  3.73s/it] 78%|███████▊  | 3566/4545 [3:51:31<1:01:16,  3.76s/it] 78%|███████▊  | 3567/4545 [3:51:34<1:01:33,  3.78s/it] 79%|███████▊  | 3568/4545 [3:51:39<1:03:17,  3.89s/it] 79%|███████▊  | 3569/4545 [3:51:42<1:03:29,  3.90s/it] 79%|███████▊  | 3570/4545 [3:51:46<1:03:22,  3.90s/it]                                                       {'loss': 0.0787, 'grad_norm': 7.566664695739746, 'learning_rate': 3.1127708382278184e-07, 'rewards/chosen': 2.2056641578674316, 'rewards/rejected': -11.590624809265137, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 13.787500381469727, 'logps/chosen': -249.3000030517578, 'logps/rejected': -186.10000610351562, 'logits/chosen': -8.559374809265137, 'logits/rejected': -7.956250190734863, 'epoch': 2.36}
 79%|███████▊  | 3570/4545 [3:51:46<1:03:22,  3.90s/it] 79%|███████▊  | 3571/4545 [3:51:50<1:03:35,  3.92s/it] 79%|███████▊  | 3572/4545 [3:51:54<1:03:23,  3.91s/it] 79%|███████▊  | 3573/4545 [3:51:58<1:03:18,  3.91s/it] 79%|███████▊  | 3574/4545 [3:52:02<1:03:26,  3.92s/it] 79%|███████▊  | 3575/4545 [3:52:06<1:02:10,  3.85s/it] 79%|███████▊  | 3576/4545 [3:52:09<59:34,  3.69s/it]   79%|███████▊  | 3577/4545 [3:52:12<54:05,  3.35s/it] 79%|███████▊  | 3578/4545 [3:52:16<57:53,  3.59s/it] 79%|███████▊  | 3579/4545 [3:52:20<59:03,  3.67s/it] 79%|███████▉  | 3580/4545 [3:52:24<1:00:05,  3.74s/it]                                                       {'loss': 0.1493, 'grad_norm': 92.8088607788086, 'learning_rate': 3.0733619848121516e-07, 'rewards/chosen': 3.5228514671325684, 'rewards/rejected': -10.792187690734863, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 14.3125, 'logps/chosen': -352.29998779296875, 'logps/rejected': -253.5500030517578, 'logits/chosen': -8.493749618530273, 'logits/rejected': -8.006250381469727, 'epoch': 2.36}
 79%|███████▉  | 3580/4545 [3:52:24<1:00:05,  3.74s/it] 79%|███████▉  | 3581/4545 [3:52:28<1:01:10,  3.81s/it] 79%|███████▉  | 3582/4545 [3:52:31<1:01:31,  3.83s/it] 79%|███████▉  | 3583/4545 [3:52:35<1:01:14,  3.82s/it] 79%|███████▉  | 3584/4545 [3:52:39<1:00:26,  3.77s/it] 79%|███████▉  | 3585/4545 [3:52:43<1:00:54,  3.81s/it] 79%|███████▉  | 3586/4545 [3:52:46<59:43,  3.74s/it]   79%|███████▉  | 3587/4545 [3:52:50<1:00:18,  3.78s/it] 79%|███████▉  | 3588/4545 [3:52:53<57:34,  3.61s/it]   79%|███████▉  | 3589/4545 [3:52:57<58:44,  3.69s/it] 79%|███████▉  | 3590/4545 [3:53:01<1:00:32,  3.80s/it]                                                       {'loss': 0.1734, 'grad_norm': 40.531742095947266, 'learning_rate': 3.0342138241633584e-07, 'rewards/chosen': 2.706249952316284, 'rewards/rejected': -12.935937881469727, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 15.640625, 'logps/chosen': -314.45001220703125, 'logps/rejected': -237.25, 'logits/chosen': -8.453125, 'logits/rejected': -8.0, 'epoch': 2.37}
 79%|███████▉  | 3590/4545 [3:53:02<1:00:32,  3.80s/it] 79%|███████▉  | 3591/4545 [3:53:05<1:01:28,  3.87s/it] 79%|███████▉  | 3592/4545 [3:53:09<1:01:31,  3.87s/it] 79%|███████▉  | 3593/4545 [3:53:13<1:01:52,  3.90s/it] 79%|███████▉  | 3594/4545 [3:53:17<1:03:04,  3.98s/it] 79%|███████▉  | 3595/4545 [3:53:21<1:02:14,  3.93s/it] 79%|███████▉  | 3596/4545 [3:53:25<1:01:46,  3.91s/it] 79%|███████▉  | 3597/4545 [3:53:29<1:01:02,  3.86s/it] 79%|███████▉  | 3598/4545 [3:53:33<1:01:07,  3.87s/it] 79%|███████▉  | 3599/4545 [3:53:37<1:01:57,  3.93s/it] 79%|███████▉  | 3600/4545 [3:53:41<1:02:58,  4.00s/it]                                                       {'loss': 0.083, 'grad_norm': 6.286630153656006, 'learning_rate': 2.995330561952924e-07, 'rewards/chosen': 1.3894531726837158, 'rewards/rejected': -15.090624809265137, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 16.5, 'logps/chosen': -317.6000061035156, 'logps/rejected': -245.10000610351562, 'logits/chosen': -8.446874618530273, 'logits/rejected': -8.040624618530273, 'epoch': 2.38}
 79%|███████▉  | 3600/4545 [3:53:41<1:02:58,  4.00s/it] 79%|███████▉  | 3601/4545 [3:53:45<1:03:34,  4.04s/it] 79%|███████▉  | 3602/4545 [3:53:48<1:00:35,  3.85s/it] 79%|███████▉  | 3603/4545 [3:53:52<1:00:13,  3.84s/it] 79%|███████▉  | 3604/4545 [3:53:56<1:00:17,  3.84s/it] 79%|███████▉  | 3605/4545 [3:54:00<1:00:22,  3.85s/it] 79%|███████▉  | 3606/4545 [3:54:04<1:00:28,  3.86s/it] 79%|███████▉  | 3607/4545 [3:54:08<1:01:15,  3.92s/it] 79%|███████▉  | 3608/4545 [3:54:12<1:00:57,  3.90s/it] 79%|███████▉  | 3609/4545 [3:54:16<1:01:46,  3.96s/it] 79%|███████▉  | 3610/4545 [3:54:20<1:01:20,  3.94s/it]                                                       {'loss': 0.0788, 'grad_norm': 14.239398002624512, 'learning_rate': 2.9567163753944056e-07, 'rewards/chosen': 2.070491075515747, 'rewards/rejected': -13.668749809265137, 'rewards/accuracies': 0.96875, 'rewards/margins': 15.71875, 'logps/chosen': -282.5, 'logps/rejected': -191.4499969482422, 'logits/chosen': -8.53125, 'logits/rejected': -8.021875381469727, 'epoch': 2.38}
 79%|███████▉  | 3610/4545 [3:54:20<1:01:20,  3.94s/it] 79%|███████▉  | 3611/4545 [3:54:24<1:00:22,  3.88s/it] 79%|███████▉  | 3612/4545 [3:54:27<59:54,  3.85s/it]   79%|███████▉  | 3613/4545 [3:54:31<58:45,  3.78s/it] 80%|███████▉  | 3614/4545 [3:54:35<59:04,  3.81s/it] 80%|███████▉  | 3615/4545 [3:54:39<59:25,  3.83s/it] 80%|███████▉  | 3616/4545 [3:54:42<56:44,  3.66s/it] 80%|███████▉  | 3617/4545 [3:54:46<57:34,  3.72s/it] 80%|███████▉  | 3618/4545 [3:54:50<58:09,  3.76s/it] 80%|███████▉  | 3619/4545 [3:54:54<58:41,  3.80s/it] 80%|███████▉  | 3620/4545 [3:54:57<56:51,  3.69s/it]                                                     {'loss': 0.0924, 'grad_norm': 8.969230651855469, 'learning_rate': 2.918375412794668e-07, 'rewards/chosen': 2.4699034690856934, 'rewards/rejected': -14.354687690734863, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 16.815624237060547, 'logps/chosen': -279.3999938964844, 'logps/rejected': -226.0500030517578, 'logits/chosen': -8.418749809265137, 'logits/rejected': -7.853125095367432, 'epoch': 2.39}
 80%|███████▉  | 3620/4545 [3:54:57<56:51,  3.69s/it] 80%|███████▉  | 3621/4545 [3:55:01<58:42,  3.81s/it] 80%|███████▉  | 3622/4545 [3:55:05<1:00:15,  3.92s/it] 80%|███████▉  | 3623/4545 [3:55:08<54:33,  3.55s/it]   80%|███████▉  | 3624/4545 [3:55:12<56:01,  3.65s/it] 80%|███████▉  | 3625/4545 [3:55:16<56:15,  3.67s/it] 80%|███████▉  | 3626/4545 [3:55:19<57:24,  3.75s/it] 80%|███████▉  | 3627/4545 [3:55:23<57:24,  3.75s/it] 80%|███████▉  | 3628/4545 [3:55:27<58:29,  3.83s/it] 80%|███████▉  | 3629/4545 [3:55:30<53:25,  3.50s/it] 80%|███████▉  | 3630/4545 [3:55:34<54:57,  3.60s/it]                                                     {'loss': 0.1337, 'grad_norm': 2.6844820976257324, 'learning_rate': 2.88031179310823e-07, 'rewards/chosen': 4.659472465515137, 'rewards/rejected': -14.103124618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 18.756250381469727, 'logps/chosen': -409.1000061035156, 'logps/rejected': -279.45001220703125, 'logits/chosen': -8.175000190734863, 'logits/rejected': -7.875, 'epoch': 2.4}
 80%|███████▉  | 3630/4545 [3:55:34<54:57,  3.60s/it] 80%|███████▉  | 3631/4545 [3:55:38<56:23,  3.70s/it] 80%|███████▉  | 3632/4545 [3:55:42<58:07,  3.82s/it] 80%|███████▉  | 3633/4545 [3:55:45<56:56,  3.75s/it] 80%|███████▉  | 3634/4545 [3:55:49<57:43,  3.80s/it] 80%|███████▉  | 3635/4545 [3:55:53<58:04,  3.83s/it] 80%|████████  | 3636/4545 [3:55:57<58:34,  3.87s/it] 80%|████████  | 3637/4545 [3:56:01<56:46,  3.75s/it] 80%|████████  | 3638/4545 [3:56:05<57:20,  3.79s/it] 80%|████████  | 3639/4545 [3:56:08<57:06,  3.78s/it] 80%|████████  | 3640/4545 [3:56:12<57:27,  3.81s/it]                                                     {'loss': 0.082, 'grad_norm': 10.253220558166504, 'learning_rate': 2.842529605494773e-07, 'rewards/chosen': 5.084130764007568, 'rewards/rejected': -9.796093940734863, 'rewards/accuracies': 0.96875, 'rewards/margins': 14.881250381469727, 'logps/chosen': -416.95001220703125, 'logps/rejected': -216.5, 'logits/chosen': -8.362500190734863, 'logits/rejected': -8.024999618530273, 'epoch': 2.4}
 80%|████████  | 3640/4545 [3:56:12<57:27,  3.81s/it] 80%|████████  | 3641/4545 [3:56:16<59:07,  3.92s/it] 80%|████████  | 3642/4545 [3:56:19<54:59,  3.65s/it] 80%|████████  | 3643/4545 [3:56:23<56:22,  3.75s/it] 80%|████████  | 3644/4545 [3:56:27<56:54,  3.79s/it] 80%|████████  | 3645/4545 [3:56:30<53:00,  3.53s/it] 80%|████████  | 3646/4545 [3:56:34<53:22,  3.56s/it] 80%|████████  | 3647/4545 [3:56:37<52:58,  3.54s/it] 80%|████████  | 3648/4545 [3:56:40<49:47,  3.33s/it] 80%|████████  | 3649/4545 [3:56:44<52:14,  3.50s/it] 80%|████████  | 3650/4545 [3:56:48<54:08,  3.63s/it]                                                     {'loss': 0.091, 'grad_norm': 7.161474227905273, 'learning_rate': 2.8050329088798453e-07, 'rewards/chosen': 1.278906226158142, 'rewards/rejected': -14.737500190734863, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.049999237060547, 'logps/chosen': -222.35000610351562, 'logps/rejected': -186.1999969482422, 'logits/chosen': -8.643750190734863, 'logits/rejected': -7.934374809265137, 'epoch': 2.41}
 80%|████████  | 3650/4545 [3:56:48<54:08,  3.63s/it] 80%|████████  | 3651/4545 [3:56:51<51:44,  3.47s/it] 80%|████████  | 3652/4545 [3:56:55<53:19,  3.58s/it] 80%|████████  | 3653/4545 [3:56:59<54:29,  3.66s/it] 80%|████████  | 3654/4545 [3:57:03<55:43,  3.75s/it] 80%|████████  | 3655/4545 [3:57:07<56:14,  3.79s/it] 80%|████████  | 3656/4545 [3:57:11<56:37,  3.82s/it] 80%|████████  | 3657/4545 [3:57:15<58:10,  3.93s/it] 80%|████████  | 3658/4545 [3:57:19<57:57,  3.92s/it] 81%|████████  | 3659/4545 [3:57:22<57:34,  3.90s/it] 81%|████████  | 3660/4545 [3:57:26<57:25,  3.89s/it]                                                     {'loss': 0.0449, 'grad_norm': 8.120923042297363, 'learning_rate': 2.7678257315188003e-07, 'rewards/chosen': 4.314843654632568, 'rewards/rejected': -11.896875381469727, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 16.206249237060547, 'logps/chosen': -367.20001220703125, 'logps/rejected': -263.3999938964844, 'logits/chosen': -8.34375, 'logits/rejected': -7.940625190734863, 'epoch': 2.42}
 81%|████████  | 3660/4545 [3:57:26<57:25,  3.89s/it] 81%|████████  | 3661/4545 [3:57:30<58:14,  3.95s/it] 81%|████████  | 3662/4545 [3:57:34<58:19,  3.96s/it] 81%|████████  | 3663/4545 [3:57:38<57:53,  3.94s/it] 81%|████████  | 3664/4545 [3:57:42<58:27,  3.98s/it] 81%|████████  | 3665/4545 [3:57:45<54:02,  3.68s/it] 81%|████████  | 3666/4545 [3:57:49<54:50,  3.74s/it] 81%|████████  | 3667/4545 [3:57:53<53:47,  3.68s/it] 81%|████████  | 3668/4545 [3:57:57<54:41,  3.74s/it] 81%|████████  | 3669/4545 [3:58:01<55:17,  3.79s/it] 81%|████████  | 3670/4545 [3:58:04<55:44,  3.82s/it]                                                     {'loss': 0.0699, 'grad_norm': 7.046972274780273, 'learning_rate': 2.730912070564064e-07, 'rewards/chosen': 4.003027439117432, 'rewards/rejected': -13.3125, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 17.28125, 'logps/chosen': -372.70001220703125, 'logps/rejected': -262.75, 'logits/chosen': -8.618749618530273, 'logits/rejected': -7.96875, 'epoch': 2.42}
 81%|████████  | 3670/4545 [3:58:05<55:44,  3.82s/it] 81%|████████  | 3671/4545 [3:58:08<56:16,  3.86s/it] 81%|████████  | 3672/4545 [3:58:12<53:58,  3.71s/it] 81%|████████  | 3673/4545 [3:58:15<52:32,  3.62s/it] 81%|████████  | 3674/4545 [3:58:19<53:51,  3.71s/it] 81%|████████  | 3675/4545 [3:58:23<54:36,  3.77s/it] 81%|████████  | 3676/4545 [3:58:27<55:04,  3.80s/it] 81%|████████  | 3677/4545 [3:58:31<55:22,  3.83s/it] 81%|████████  | 3678/4545 [3:58:35<55:43,  3.86s/it] 81%|████████  | 3679/4545 [3:58:39<55:46,  3.86s/it] 81%|████████  | 3680/4545 [3:58:42<54:42,  3.79s/it]                                                     {'loss': 0.064, 'grad_norm': 7.87877082824707, 'learning_rate': 2.6942958916356994e-07, 'rewards/chosen': 3.3428711891174316, 'rewards/rejected': -11.024999618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 14.340624809265137, 'logps/chosen': -319.1499938964844, 'logps/rejected': -295.75, 'logits/chosen': -8.521875381469727, 'logits/rejected': -8.084375381469727, 'epoch': 2.43}
 81%|████████  | 3680/4545 [3:58:42<54:42,  3.79s/it] 81%|████████  | 3681/4545 [3:58:45<50:17,  3.49s/it] 81%|████████  | 3682/4545 [3:58:49<51:53,  3.61s/it] 81%|████████  | 3683/4545 [3:58:53<53:11,  3.70s/it] 81%|████████  | 3684/4545 [3:58:57<54:03,  3.77s/it] 81%|████████  | 3685/4545 [3:58:59<48:57,  3.42s/it] 81%|████████  | 3686/4545 [3:59:04<52:21,  3.66s/it] 81%|████████  | 3687/4545 [3:59:07<53:09,  3.72s/it] 81%|████████  | 3688/4545 [3:59:11<54:00,  3.78s/it] 81%|████████  | 3689/4545 [3:59:15<54:22,  3.81s/it] 81%|████████  | 3690/4545 [3:59:19<54:29,  3.82s/it]                                                     {'loss': 0.0752, 'grad_norm': 31.324771881103516, 'learning_rate': 2.6579811283953977e-07, 'rewards/chosen': 5.16796875, 'rewards/rejected': -11.815625190734863, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 16.981250762939453, 'logps/chosen': -450.8500061035156, 'logps/rejected': -291.0, 'logits/chosen': -8.550000190734863, 'logits/rejected': -7.896874904632568, 'epoch': 2.44}
 81%|████████  | 3690/4545 [3:59:19<54:29,  3.82s/it] 81%|████████  | 3691/4545 [3:59:23<53:51,  3.78s/it] 81%|████████  | 3692/4545 [3:59:27<54:17,  3.82s/it] 81%|████████▏ | 3693/4545 [3:59:31<54:35,  3.84s/it] 81%|████████▏ | 3694/4545 [3:59:34<51:50,  3.65s/it] 81%|████████▏ | 3695/4545 [3:59:38<52:51,  3.73s/it] 81%|████████▏ | 3696/4545 [3:59:42<53:27,  3.78s/it] 81%|████████▏ | 3697/4545 [3:59:44<48:28,  3.43s/it] 81%|████████▏ | 3698/4545 [3:59:48<51:41,  3.66s/it] 81%|████████▏ | 3699/4545 [3:59:52<49:15,  3.49s/it] 81%|████████▏ | 3700/4545 [3:59:55<50:43,  3.60s/it]                                                     {'loss': 0.1215, 'grad_norm': 4.917971611022949, 'learning_rate': 2.6219716821238827e-07, 'rewards/chosen': 2.373584032058716, 'rewards/rejected': -10.2265625, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 12.581250190734863, 'logps/chosen': -257.75, 'logps/rejected': -230.75, 'logits/chosen': -8.637499809265137, 'logits/rejected': -8.225000381469727, 'epoch': 2.44}
 81%|████████▏ | 3700/4545 [3:59:56<50:43,  3.60s/it] 81%|████████▏ | 3701/4545 [3:59:59<52:09,  3.71s/it] 81%|████████▏ | 3702/4545 [4:00:03<52:39,  3.75s/it] 81%|████████▏ | 3703/4545 [4:00:07<53:13,  3.79s/it] 81%|████████▏ | 3704/4545 [4:00:11<53:33,  3.82s/it] 82%|████████▏ | 3705/4545 [4:00:15<54:30,  3.89s/it] 82%|████████▏ | 3706/4545 [4:00:19<54:23,  3.89s/it] 82%|████████▏ | 3707/4545 [4:00:23<53:35,  3.84s/it] 82%|████████▏ | 3708/4545 [4:00:26<52:57,  3.80s/it] 82%|████████▏ | 3709/4545 [4:00:30<53:26,  3.84s/it] 82%|████████▏ | 3710/4545 [4:00:34<53:21,  3.83s/it]                                                     {'loss': 0.0733, 'grad_norm': 17.96445655822754, 'learning_rate': 2.586271421301792e-07, 'rewards/chosen': 1.7073242664337158, 'rewards/rejected': -10.993749618530273, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 12.703125, 'logps/chosen': -242.0, 'logps/rejected': -241.14999389648438, 'logits/chosen': -8.746874809265137, 'logits/rejected': -8.21875, 'epoch': 2.45}
 82%|████████▏ | 3710/4545 [4:00:34<53:21,  3.83s/it] 82%|████████▏ | 3711/4545 [4:00:38<54:36,  3.93s/it] 82%|████████▏ | 3712/4545 [4:00:42<55:32,  4.00s/it] 82%|████████▏ | 3713/4545 [4:00:46<55:03,  3.97s/it] 82%|████████▏ | 3714/4545 [4:00:50<52:40,  3.80s/it] 82%|████████▏ | 3715/4545 [4:00:54<53:36,  3.87s/it] 82%|████████▏ | 3716/4545 [4:00:57<52:25,  3.79s/it] 82%|████████▏ | 3717/4545 [4:01:01<53:18,  3.86s/it] 82%|████████▏ | 3718/4545 [4:01:05<52:48,  3.83s/it] 82%|████████▏ | 3719/4545 [4:01:09<52:59,  3.85s/it] 82%|████████▏ | 3720/4545 [4:01:12<51:17,  3.73s/it]                                                     {'loss': 0.0811, 'grad_norm': 5.472442150115967, 'learning_rate': 2.550884181194095e-07, 'rewards/chosen': 1.158203125, 'rewards/rejected': -11.065625190734863, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 12.225000381469727, 'logps/chosen': -236.64999389648438, 'logps/rejected': -191.5500030517578, 'logits/chosen': -8.612500190734863, 'logits/rejected': -8.221875190734863, 'epoch': 2.46}
 82%|████████▏ | 3720/4545 [4:01:13<51:17,  3.73s/it] 82%|████████▏ | 3721/4545 [4:01:16<48:50,  3.56s/it] 82%|████████▏ | 3722/4545 [4:01:19<50:06,  3.65s/it] 82%|████████▏ | 3723/4545 [4:01:23<50:57,  3.72s/it] 82%|████████▏ | 3724/4545 [4:01:27<52:31,  3.84s/it] 82%|████████▏ | 3725/4545 [4:01:30<48:11,  3.53s/it] 82%|████████▏ | 3726/4545 [4:01:34<50:40,  3.71s/it] 82%|████████▏ | 3727/4545 [4:01:38<51:28,  3.78s/it] 82%|████████▏ | 3728/4545 [4:01:42<52:48,  3.88s/it] 82%|████████▏ | 3729/4545 [4:01:47<54:03,  3.97s/it] 82%|████████▏ | 3730/4545 [4:01:50<51:03,  3.76s/it]                                                     {'loss': 0.0418, 'grad_norm': 2.671509027481079, 'learning_rate': 2.515813763438068e-07, 'rewards/chosen': 5.291455268859863, 'rewards/rejected': -9.728124618530273, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 15.034375190734863, 'logps/chosen': -379.0, 'logps/rejected': -238.0, 'logits/chosen': -8.668749809265137, 'logits/rejected': -8.065625190734863, 'epoch': 2.46}
 82%|████████▏ | 3730/4545 [4:01:50<51:03,  3.76s/it] 82%|████████▏ | 3731/4545 [4:01:54<52:04,  3.84s/it] 82%|████████▏ | 3732/4545 [4:01:57<50:05,  3.70s/it] 82%|████████▏ | 3733/4545 [4:02:01<50:48,  3.75s/it] 82%|████████▏ | 3734/4545 [4:02:05<52:36,  3.89s/it] 82%|████████▏ | 3735/4545 [4:02:09<50:12,  3.72s/it] 82%|████████▏ | 3736/4545 [4:02:13<51:14,  3.80s/it] 82%|████████▏ | 3737/4545 [4:02:16<49:19,  3.66s/it] 82%|████████▏ | 3738/4545 [4:02:20<50:10,  3.73s/it] 82%|████████▏ | 3739/4545 [4:02:24<50:43,  3.78s/it] 82%|████████▏ | 3740/4545 [4:02:28<51:16,  3.82s/it]                                                     {'loss': 0.1192, 'grad_norm': 12.854063987731934, 'learning_rate': 2.4810639356348883e-07, 'rewards/chosen': 2.3921875953674316, 'rewards/rejected': -12.878125190734863, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 15.271875381469727, 'logps/chosen': -256.79998779296875, 'logps/rejected': -224.5, 'logits/chosen': -8.675000190734863, 'logits/rejected': -8.246874809265137, 'epoch': 2.47}
 82%|████████▏ | 3740/4545 [4:02:28<51:16,  3.82s/it] 82%|████████▏ | 3741/4545 [4:02:32<52:43,  3.93s/it] 82%|████████▏ | 3742/4545 [4:02:36<52:19,  3.91s/it] 82%|████████▏ | 3743/4545 [4:02:39<50:23,  3.77s/it] 82%|████████▏ | 3744/4545 [4:02:43<50:46,  3.80s/it] 82%|████████▏ | 3745/4545 [4:02:47<52:11,  3.91s/it] 82%|████████▏ | 3746/4545 [4:02:51<53:13,  4.00s/it] 82%|████████▏ | 3747/4545 [4:02:55<52:13,  3.93s/it] 82%|████████▏ | 3748/4545 [4:02:59<51:42,  3.89s/it] 82%|████████▏ | 3749/4545 [4:03:03<52:34,  3.96s/it] 83%|████████▎ | 3750/4545 [4:03:07<52:20,  3.95s/it]                                                     {'loss': 0.0639, 'grad_norm': 3.4807512760162354, 'learning_rate': 2.4466384309448794e-07, 'rewards/chosen': 1.599609375, 'rewards/rejected': -14.965624809265137, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 16.568750381469727, 'logps/chosen': -258.5, 'logps/rejected': -212.6999969482422, 'logits/chosen': -8.709375381469727, 'logits/rejected': -8.112500190734863, 'epoch': 2.48}
 83%|████████▎ | 3750/4545 [4:03:07<52:20,  3.95s/it] 83%|████████▎ | 3751/4545 [4:03:11<52:04,  3.94s/it] 83%|████████▎ | 3752/4545 [4:03:15<52:29,  3.97s/it] 83%|████████▎ | 3753/4545 [4:03:19<50:30,  3.83s/it] 83%|████████▎ | 3754/4545 [4:03:22<50:32,  3.83s/it] 83%|████████▎ | 3755/4545 [4:03:26<50:39,  3.85s/it] 83%|████████▎ | 3756/4545 [4:03:30<51:16,  3.90s/it] 83%|████████▎ | 3757/4545 [4:03:33<47:30,  3.62s/it] 83%|████████▎ | 3758/4545 [4:03:37<49:08,  3.75s/it] 83%|████████▎ | 3759/4545 [4:03:42<50:52,  3.88s/it] 83%|████████▎ | 3760/4545 [4:03:45<49:25,  3.78s/it]                                                     {'loss': 0.0894, 'grad_norm': 14.707531929016113, 'learning_rate': 2.412540947686462e-07, 'rewards/chosen': 0.37431639432907104, 'rewards/rejected': -13.837499618530273, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 14.209375381469727, 'logps/chosen': -184.5, 'logps/rejected': -196.60000610351562, 'logits/chosen': -8.831250190734863, 'logits/rejected': -8.353124618530273, 'epoch': 2.48}
 83%|████████▎ | 3760/4545 [4:03:45<49:25,  3.78s/it] 83%|████████▎ | 3761/4545 [4:03:49<50:02,  3.83s/it] 83%|████████▎ | 3762/4545 [4:03:51<41:30,  3.18s/it] 83%|████████▎ | 3763/4545 [4:03:55<45:07,  3.46s/it] 83%|████████▎ | 3764/4545 [4:03:58<43:42,  3.36s/it] 83%|████████▎ | 3765/4545 [4:04:00<39:00,  3.00s/it] 83%|████████▎ | 3766/4545 [4:04:04<42:26,  3.27s/it] 83%|████████▎ | 3767/4545 [4:04:08<45:18,  3.49s/it] 83%|████████▎ | 3768/4545 [4:04:12<47:49,  3.69s/it] 83%|████████▎ | 3769/4545 [4:04:16<46:53,  3.63s/it] 83%|████████▎ | 3770/4545 [4:04:20<48:28,  3.75s/it]                                                     {'loss': 0.1, 'grad_norm': 12.353102684020996, 'learning_rate': 2.3787751489388381e-07, 'rewards/chosen': 2.566162109375, 'rewards/rejected': -11.854687690734863, 'rewards/accuracies': 0.96875, 'rewards/margins': 14.403124809265137, 'logps/chosen': -270.45001220703125, 'logps/rejected': -239.6999969482422, 'logits/chosen': -8.962499618530273, 'logits/rejected': -8.481249809265137, 'epoch': 2.49}
 83%|████████▎ | 3770/4545 [4:04:20<48:28,  3.75s/it] 83%|████████▎ | 3771/4545 [4:04:24<49:07,  3.81s/it] 83%|████████▎ | 3772/4545 [4:04:28<50:48,  3.94s/it] 83%|████████▎ | 3773/4545 [4:04:31<47:33,  3.70s/it] 83%|████████▎ | 3774/4545 [4:04:35<48:16,  3.76s/it] 83%|████████▎ | 3775/4545 [4:04:39<49:32,  3.86s/it] 83%|████████▎ | 3776/4545 [4:04:43<49:34,  3.87s/it] 83%|████████▎ | 3777/4545 [4:04:46<48:36,  3.80s/it] 83%|████████▎ | 3778/4545 [4:04:51<49:33,  3.88s/it] 83%|████████▎ | 3779/4545 [4:04:54<49:22,  3.87s/it] 83%|████████▎ | 3780/4545 [4:04:58<49:17,  3.87s/it]                                                     {'loss': 0.0558, 'grad_norm': 9.39806079864502, 'learning_rate': 2.3453446621484805e-07, 'rewards/chosen': 1.390625, 'rewards/rejected': -11.600000381469727, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 13.012499809265137, 'logps/chosen': -232.4499969482422, 'logps/rejected': -202.35000610351562, 'logits/chosen': -8.6875, 'logits/rejected': -8.137499809265137, 'epoch': 2.5}
 83%|████████▎ | 3780/4545 [4:04:58<49:17,  3.87s/it] 83%|████████▎ | 3781/4545 [4:05:02<49:18,  3.87s/it] 83%|████████▎ | 3782/4545 [4:05:05<44:37,  3.51s/it] 83%|████████▎ | 3783/4545 [4:05:09<46:13,  3.64s/it] 83%|████████▎ | 3784/4545 [4:05:12<45:30,  3.59s/it] 83%|████████▎ | 3785/4545 [4:05:16<46:35,  3.68s/it] 83%|████████▎ | 3786/4545 [4:05:20<48:10,  3.81s/it] 83%|████████▎ | 3787/4545 [4:05:23<43:41,  3.46s/it] 83%|████████▎ | 3788/4545 [4:05:27<44:19,  3.51s/it] 83%|████████▎ | 3789/4545 [4:05:30<43:04,  3.42s/it] 83%|████████▎ | 3790/4545 [4:05:33<43:51,  3.49s/it]                                                     {'loss': 0.0738, 'grad_norm': 20.838512420654297, 'learning_rate': 2.3122530787394272e-07, 'rewards/chosen': 1.1771240234375, 'rewards/rejected': -14.571874618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 15.753125190734863, 'logps/chosen': -240.75, 'logps/rejected': -234.6999969482422, 'logits/chosen': -8.762499809265137, 'logits/rejected': -8.118749618530273, 'epoch': 2.5}
 83%|████████▎ | 3790/4545 [4:05:33<43:51,  3.49s/it] 83%|████████▎ | 3791/4545 [4:05:37<45:20,  3.61s/it] 83%|████████▎ | 3792/4545 [4:05:41<45:53,  3.66s/it] 83%|████████▎ | 3793/4545 [4:05:45<45:34,  3.64s/it] 83%|████████▎ | 3794/4545 [4:05:48<44:52,  3.59s/it] 83%|████████▎ | 3795/4545 [4:05:52<45:58,  3.68s/it] 84%|████████▎ | 3796/4545 [4:05:56<45:54,  3.68s/it] 84%|████████▎ | 3797/4545 [4:05:59<46:27,  3.73s/it] 84%|████████▎ | 3798/4545 [4:06:04<47:39,  3.83s/it] 84%|████████▎ | 3799/4545 [4:06:07<47:08,  3.79s/it] 84%|████████▎ | 3800/4545 [4:06:10<44:53,  3.62s/it]                                                     {'loss': 0.072, 'grad_norm': 36.24384307861328, 'learning_rate': 2.2795039537274575e-07, 'rewards/chosen': 0.14956054091453552, 'rewards/rejected': -12.971875190734863, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 13.121874809265137, 'logps/chosen': -134.89999389648438, 'logps/rejected': -162.3000030517578, 'logits/chosen': -9.193750381469727, 'logits/rejected': -8.625, 'epoch': 2.51}
 84%|████████▎ | 3800/4545 [4:06:11<44:53,  3.62s/it] 84%|████████▎ | 3801/4545 [4:06:15<46:31,  3.75s/it] 84%|████████▎ | 3802/4545 [4:06:18<46:53,  3.79s/it] 84%|████████▎ | 3803/4545 [4:06:22<44:39,  3.61s/it] 84%|████████▎ | 3804/4545 [4:06:26<46:31,  3.77s/it] 84%|████████▎ | 3805/4545 [4:06:29<44:16,  3.59s/it] 84%|████████▎ | 3806/4545 [4:06:33<44:58,  3.65s/it] 84%|████████▍ | 3807/4545 [4:06:36<44:24,  3.61s/it] 84%|████████▍ | 3808/4545 [4:06:40<45:42,  3.72s/it] 84%|████████▍ | 3809/4545 [4:06:44<46:56,  3.83s/it] 84%|████████▍ | 3810/4545 [4:06:47<43:32,  3.55s/it]                                                     {'loss': 0.083, 'grad_norm': 5.344334125518799, 'learning_rate': 2.247100805338182e-07, 'rewards/chosen': 0.18710938096046448, 'rewards/rejected': -15.915624618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.125, 'logps/chosen': -197.1999969482422, 'logps/rejected': -188.25, 'logits/chosen': -8.78125, 'logits/rejected': -8.234375, 'epoch': 2.51}
 84%|████████▍ | 3810/4545 [4:06:47<43:32,  3.55s/it] 84%|████████▍ | 3811/4545 [4:06:51<44:49,  3.66s/it] 84%|████████▍ | 3812/4545 [4:06:55<45:56,  3.76s/it] 84%|████████▍ | 3813/4545 [4:06:58<42:13,  3.46s/it] 84%|████████▍ | 3814/4545 [4:07:01<42:09,  3.46s/it] 84%|████████▍ | 3815/4545 [4:07:05<43:50,  3.60s/it] 84%|████████▍ | 3816/4545 [4:07:09<44:56,  3.70s/it] 84%|████████▍ | 3817/4545 [4:07:13<45:30,  3.75s/it] 84%|████████▍ | 3818/4545 [4:07:16<43:55,  3.62s/it] 84%|████████▍ | 3819/4545 [4:07:20<44:52,  3.71s/it] 84%|████████▍ | 3820/4545 [4:07:24<45:25,  3.76s/it]                                                     {'loss': 0.089, 'grad_norm': 27.58228302001953, 'learning_rate': 2.215047114629079e-07, 'rewards/chosen': 5.143359184265137, 'rewards/rejected': -10.329687118530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 15.487500190734863, 'logps/chosen': -454.45001220703125, 'logps/rejected': -289.70001220703125, 'logits/chosen': -8.456250190734863, 'logits/rejected': -8.203125, 'epoch': 2.52}
 84%|████████▍ | 3820/4545 [4:07:24<45:25,  3.76s/it] 84%|████████▍ | 3821/4545 [4:07:28<45:53,  3.80s/it] 84%|████████▍ | 3822/4545 [4:07:32<44:31,  3.69s/it] 84%|████████▍ | 3823/4545 [4:07:36<45:58,  3.82s/it] 84%|████████▍ | 3824/4545 [4:07:40<46:10,  3.84s/it] 84%|████████▍ | 3825/4545 [4:07:44<46:50,  3.90s/it] 84%|████████▍ | 3826/4545 [4:07:47<44:04,  3.68s/it] 84%|████████▍ | 3827/4545 [4:07:51<45:49,  3.83s/it] 84%|████████▍ | 3828/4545 [4:07:54<42:41,  3.57s/it] 84%|████████▍ | 3829/4545 [4:07:58<43:55,  3.68s/it] 84%|████████▍ | 3830/4545 [4:08:02<44:19,  3.72s/it]                                                     {'loss': 0.0563, 'grad_norm': 2.721296787261963, 'learning_rate': 2.1833463251155265e-07, 'rewards/chosen': 1.0549805164337158, 'rewards/rejected': -17.912500381469727, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 18.962499618530273, 'logps/chosen': -240.89999389648438, 'logps/rejected': -235.6999969482422, 'logits/chosen': -8.712499618530273, 'logits/rejected': -8.106249809265137, 'epoch': 2.53}
 84%|████████▍ | 3830/4545 [4:08:02<44:19,  3.72s/it] 84%|████████▍ | 3831/4545 [4:08:06<44:57,  3.78s/it] 84%|████████▍ | 3832/4545 [4:08:08<40:32,  3.41s/it] 84%|████████▍ | 3833/4545 [4:08:12<40:40,  3.43s/it] 84%|████████▍ | 3834/4545 [4:08:15<42:17,  3.57s/it] 84%|████████▍ | 3835/4545 [4:08:19<43:19,  3.66s/it] 84%|████████▍ | 3836/4545 [4:08:23<43:54,  3.72s/it] 84%|████████▍ | 3837/4545 [4:08:27<44:27,  3.77s/it] 84%|████████▍ | 3838/4545 [4:08:31<43:19,  3.68s/it] 84%|████████▍ | 3839/4545 [4:08:34<41:07,  3.49s/it] 84%|████████▍ | 3840/4545 [4:08:38<42:53,  3.65s/it]                                                     {'loss': 0.0718, 'grad_norm': 12.10751724243164, 'learning_rate': 2.1520018424008646e-07, 'rewards/chosen': 2.82421875, 'rewards/rejected': -11.986719131469727, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 14.831250190734863, 'logps/chosen': -288.92498779296875, 'logps/rejected': -257.6000061035156, 'logits/chosen': -8.834375381469727, 'logits/rejected': -8.262499809265137, 'epoch': 2.53}
 84%|████████▍ | 3840/4545 [4:08:38<42:53,  3.65s/it] 85%|████████▍ | 3841/4545 [4:08:41<43:34,  3.71s/it] 85%|████████▍ | 3842/4545 [4:08:45<43:27,  3.71s/it] 85%|████████▍ | 3843/4545 [4:08:49<44:00,  3.76s/it] 85%|████████▍ | 3844/4545 [4:08:53<44:23,  3.80s/it] 85%|████████▍ | 3845/4545 [4:08:57<43:49,  3.76s/it] 85%|████████▍ | 3846/4545 [4:09:00<44:12,  3.80s/it] 85%|████████▍ | 3847/4545 [4:09:05<45:36,  3.92s/it] 85%|████████▍ | 3848/4545 [4:09:08<43:00,  3.70s/it] 85%|████████▍ | 3849/4545 [4:09:12<43:14,  3.73s/it] 85%|████████▍ | 3850/4545 [4:09:16<43:35,  3.76s/it]                                                     {'loss': 0.0593, 'grad_norm': 49.60609817504883, 'learning_rate': 2.1210170338105324e-07, 'rewards/chosen': 1.4357421398162842, 'rewards/rejected': -12.387499809265137, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.837499618530273, 'logps/chosen': -235.39999389648438, 'logps/rejected': -169.75, 'logits/chosen': -8.881250381469727, 'logits/rejected': -8.328125, 'epoch': 2.54}
 85%|████████▍ | 3850/4545 [4:09:16<43:35,  3.76s/it] 85%|████████▍ | 3851/4545 [4:09:19<44:03,  3.81s/it] 85%|████████▍ | 3852/4545 [4:09:24<45:15,  3.92s/it] 85%|████████▍ | 3853/4545 [4:09:27<43:35,  3.78s/it] 85%|████████▍ | 3854/4545 [4:09:31<43:43,  3.80s/it] 85%|████████▍ | 3855/4545 [4:09:35<43:28,  3.78s/it] 85%|████████▍ | 3856/4545 [4:09:38<41:20,  3.60s/it] 85%|████████▍ | 3857/4545 [4:09:42<42:41,  3.72s/it] 85%|████████▍ | 3858/4545 [4:09:46<43:32,  3.80s/it] 85%|████████▍ | 3859/4545 [4:09:49<41:44,  3.65s/it] 85%|████████▍ | 3860/4545 [4:09:53<42:13,  3.70s/it]                                                     {'loss': 0.0923, 'grad_norm': 22.9914608001709, 'learning_rate': 2.0903952280303227e-07, 'rewards/chosen': 1.622656226158142, 'rewards/rejected': -14.512499809265137, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 16.125, 'logps/chosen': -245.0500030517578, 'logps/rejected': -225.9499969482422, 'logits/chosen': -8.743749618530273, 'logits/rejected': -8.009374618530273, 'epoch': 2.55}
 85%|████████▍ | 3860/4545 [4:09:53<42:13,  3.70s/it] 85%|████████▍ | 3861/4545 [4:09:57<43:53,  3.85s/it] 85%|████████▍ | 3862/4545 [4:10:01<43:56,  3.86s/it] 85%|████████▍ | 3863/4545 [4:10:05<43:59,  3.87s/it] 85%|████████▌ | 3864/4545 [4:10:08<40:20,  3.55s/it] 85%|████████▌ | 3865/4545 [4:10:11<39:55,  3.52s/it] 85%|████████▌ | 3866/4545 [4:10:14<37:10,  3.28s/it] 85%|████████▌ | 3867/4545 [4:10:18<38:59,  3.45s/it] 85%|████████▌ | 3868/4545 [4:10:22<40:20,  3.58s/it] 85%|████████▌ | 3869/4545 [4:10:25<41:20,  3.67s/it] 85%|████████▌ | 3870/4545 [4:10:29<39:38,  3.52s/it]                                                     {'loss': 0.0623, 'grad_norm': 18.074413299560547, 'learning_rate': 2.060139714748779e-07, 'rewards/chosen': 2.0598998069763184, 'rewards/rejected': -11.790624618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 13.84375, 'logps/chosen': -288.04998779296875, 'logps/rejected': -202.39999389648438, 'logits/chosen': -8.868749618530273, 'logits/rejected': -8.446874618530273, 'epoch': 2.55}
 85%|████████▌ | 3870/4545 [4:10:29<39:38,  3.52s/it] 85%|████████▌ | 3871/4545 [4:10:32<38:17,  3.41s/it] 85%|████████▌ | 3872/4545 [4:10:36<39:49,  3.55s/it] 85%|████████▌ | 3873/4545 [4:10:40<41:32,  3.71s/it] 85%|████████▌ | 3874/4545 [4:10:42<37:42,  3.37s/it] 85%|████████▌ | 3875/4545 [4:10:46<39:22,  3.53s/it] 85%|████████▌ | 3876/4545 [4:10:50<41:03,  3.68s/it] 85%|████████▌ | 3877/4545 [4:10:54<41:30,  3.73s/it] 85%|████████▌ | 3878/4545 [4:10:58<42:02,  3.78s/it] 85%|████████▌ | 3879/4545 [4:11:02<41:42,  3.76s/it] 85%|████████▌ | 3880/4545 [4:11:06<42:20,  3.82s/it]                                                     {'loss': 0.0921, 'grad_norm': 31.28498649597168, 'learning_rate': 2.0302537443037817e-07, 'rewards/chosen': 3.3091797828674316, 'rewards/rejected': -10.618749618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 13.925000190734863, 'logps/chosen': -346.20001220703125, 'logps/rejected': -223.39999389648438, 'logits/chosen': -8.743749618530273, 'logits/rejected': -8.278124809265137, 'epoch': 2.56}
 85%|████████▌ | 3880/4545 [4:11:06<42:20,  3.82s/it] 85%|████████▌ | 3881/4545 [4:11:08<36:12,  3.27s/it] 85%|████████▌ | 3882/4545 [4:11:11<35:57,  3.25s/it] 85%|████████▌ | 3883/4545 [4:11:15<37:05,  3.36s/it] 85%|████████▌ | 3884/4545 [4:11:19<39:21,  3.57s/it] 85%|████████▌ | 3885/4545 [4:11:21<36:40,  3.33s/it] 86%|████████▌ | 3886/4545 [4:11:25<38:25,  3.50s/it] 86%|████████▌ | 3887/4545 [4:11:29<39:30,  3.60s/it] 86%|████████▌ | 3888/4545 [4:11:33<40:21,  3.69s/it] 86%|████████▌ | 3889/4545 [4:11:37<40:57,  3.75s/it] 86%|████████▌ | 3890/4545 [4:11:40<37:45,  3.46s/it]                                                     {'loss': 0.0569, 'grad_norm': 7.382761478424072, 'learning_rate': 2.0007405273333767e-07, 'rewards/chosen': 3.161328077316284, 'rewards/rejected': -15.301562309265137, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 18.450000762939453, 'logps/chosen': -361.3500061035156, 'logps/rejected': -255.89999389648438, 'logits/chosen': -8.640625, 'logits/rejected': -8.225000381469727, 'epoch': 2.57}
 86%|████████▌ | 3890/4545 [4:11:40<37:45,  3.46s/it] 86%|████████▌ | 3891/4545 [4:11:43<38:14,  3.51s/it] 86%|████████▌ | 3892/4545 [4:11:45<32:36,  3.00s/it] 86%|████████▌ | 3893/4545 [4:11:49<35:27,  3.26s/it] 86%|████████▌ | 3894/4545 [4:11:52<33:18,  3.07s/it] 86%|████████▌ | 3895/4545 [4:11:56<36:10,  3.34s/it] 86%|████████▌ | 3896/4545 [4:11:59<35:41,  3.30s/it] 86%|████████▌ | 3897/4545 [4:12:03<37:15,  3.45s/it] 86%|████████▌ | 3898/4545 [4:12:06<38:33,  3.58s/it] 86%|████████▌ | 3899/4545 [4:12:10<38:07,  3.54s/it] 86%|████████▌ | 3900/4545 [4:12:14<39:40,  3.69s/it]                                                     {'loss': 0.0906, 'grad_norm': 9.495967864990234, 'learning_rate': 1.9716032344308464e-07, 'rewards/chosen': 1.3683593273162842, 'rewards/rejected': -13.262499809265137, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 14.631250381469727, 'logps/chosen': -209.27499389648438, 'logps/rejected': -197.39999389648438, 'logits/chosen': -8.943750381469727, 'logits/rejected': -8.4375, 'epoch': 2.57}
 86%|████████▌ | 3900/4545 [4:12:14<39:40,  3.69s/it] 86%|████████▌ | 3901/4545 [4:12:18<40:32,  3.78s/it] 86%|████████▌ | 3902/4545 [4:12:21<38:11,  3.56s/it] 86%|████████▌ | 3903/4545 [4:12:25<39:31,  3.69s/it] 86%|████████▌ | 3904/4545 [4:12:29<40:01,  3.75s/it] 86%|████████▌ | 3905/4545 [4:12:33<41:23,  3.88s/it] 86%|████████▌ | 3906/4545 [4:12:37<41:04,  3.86s/it] 86%|████████▌ | 3907/4545 [4:12:41<41:05,  3.86s/it] 86%|████████▌ | 3908/4545 [4:12:44<39:40,  3.74s/it] 86%|████████▌ | 3909/4545 [4:12:48<39:09,  3.69s/it] 86%|████████▌ | 3910/4545 [4:12:51<38:33,  3.64s/it]                                                     {'loss': 0.1412, 'grad_norm': 19.158245086669922, 'learning_rate': 1.9428449958040966e-07, 'rewards/chosen': 1.201171875, 'rewards/rejected': -15.309374809265137, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 16.512500762939453, 'logps/chosen': -258.29998779296875, 'logps/rejected': -229.89999389648438, 'logits/chosen': -8.912500381469727, 'logits/rejected': -8.296875, 'epoch': 2.58}
 86%|████████▌ | 3910/4545 [4:12:51<38:33,  3.64s/it] 86%|████████▌ | 3911/4545 [4:12:55<40:09,  3.80s/it] 86%|████████▌ | 3912/4545 [4:12:59<39:40,  3.76s/it] 86%|████████▌ | 3913/4545 [4:13:03<39:58,  3.80s/it] 86%|████████▌ | 3914/4545 [4:13:07<40:10,  3.82s/it] 86%|████████▌ | 3915/4545 [4:13:10<38:14,  3.64s/it] 86%|████████▌ | 3916/4545 [4:13:14<38:40,  3.69s/it] 86%|████████▌ | 3917/4545 [4:13:18<38:43,  3.70s/it] 86%|████████▌ | 3918/4545 [4:13:21<37:16,  3.57s/it] 86%|████████▌ | 3919/4545 [4:13:25<37:30,  3.60s/it] 86%|████████▌ | 3920/4545 [4:13:28<38:21,  3.68s/it]                                                     {'loss': 0.0903, 'grad_norm': 22.651107788085938, 'learning_rate': 1.914468900939386e-07, 'rewards/chosen': 1.8796875476837158, 'rewards/rejected': -18.596874237060547, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 20.440624237060547, 'logps/chosen': -297.04998779296875, 'logps/rejected': -252.4499969482422, 'logits/chosen': -8.65625, 'logits/rejected': -8.228124618530273, 'epoch': 2.59}
 86%|████████▌ | 3920/4545 [4:13:29<38:21,  3.68s/it] 86%|████████▋ | 3921/4545 [4:13:33<39:34,  3.81s/it] 86%|████████▋ | 3922/4545 [4:13:36<37:38,  3.63s/it] 86%|████████▋ | 3923/4545 [4:13:40<38:56,  3.76s/it] 86%|████████▋ | 3924/4545 [4:13:44<38:55,  3.76s/it] 86%|████████▋ | 3925/4545 [4:13:47<37:34,  3.64s/it] 86%|████████▋ | 3926/4545 [4:13:51<38:55,  3.77s/it] 86%|████████▋ | 3927/4545 [4:13:55<39:11,  3.81s/it] 86%|████████▋ | 3928/4545 [4:13:59<39:07,  3.80s/it] 86%|████████▋ | 3929/4545 [4:14:03<39:17,  3.83s/it] 86%|████████▋ | 3930/4545 [4:14:06<39:25,  3.85s/it]                                                     {'loss': 0.0943, 'grad_norm': 4.30933952331543, 'learning_rate': 1.886477998269418e-07, 'rewards/chosen': 2.6195311546325684, 'rewards/rejected': -15.173437118530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 17.809375762939453, 'logps/chosen': -320.29998779296875, 'logps/rejected': -270.04998779296875, 'logits/chosen': -8.515625, 'logits/rejected': -7.971875190734863, 'epoch': 2.59}
 86%|████████▋ | 3930/4545 [4:14:07<39:25,  3.85s/it] 86%|████████▋ | 3931/4545 [4:14:09<36:43,  3.59s/it] 87%|████████▋ | 3932/4545 [4:14:13<37:42,  3.69s/it] 87%|████████▋ | 3933/4545 [4:14:17<37:19,  3.66s/it] 87%|████████▋ | 3934/4545 [4:14:21<37:54,  3.72s/it] 87%|████████▋ | 3935/4545 [4:14:25<39:16,  3.86s/it] 87%|████████▋ | 3936/4545 [4:14:29<39:17,  3.87s/it] 87%|████████▋ | 3937/4545 [4:14:33<39:45,  3.92s/it] 87%|████████▋ | 3938/4545 [4:14:37<38:52,  3.84s/it] 87%|████████▋ | 3939/4545 [4:14:41<39:33,  3.92s/it] 87%|████████▋ | 3940/4545 [4:14:44<38:08,  3.78s/it]                                                     {'loss': 0.0552, 'grad_norm': 1.9986292123794556, 'learning_rate': 1.8588752948458476e-07, 'rewards/chosen': 1.7742187976837158, 'rewards/rejected': -13.318750381469727, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 15.087499618530273, 'logps/chosen': -280.45001220703125, 'logps/rejected': -217.1999969482422, 'logits/chosen': -8.725000381469727, 'logits/rejected': -8.253125190734863, 'epoch': 2.6}
 87%|████████▋ | 3940/4545 [4:14:44<38:08,  3.78s/it] 87%|████████▋ | 3941/4545 [4:14:48<38:24,  3.81s/it] 87%|████████▋ | 3942/4545 [4:14:52<39:05,  3.89s/it] 87%|████████▋ | 3943/4545 [4:14:56<38:15,  3.81s/it] 87%|████████▋ | 3944/4545 [4:15:00<38:25,  3.84s/it] 87%|████████▋ | 3945/4545 [4:15:03<37:33,  3.76s/it] 87%|████████▋ | 3946/4545 [4:15:07<38:06,  3.82s/it] 87%|████████▋ | 3947/4545 [4:15:11<38:43,  3.89s/it] 87%|████████▋ | 3948/4545 [4:15:15<38:26,  3.86s/it] 87%|████████▋ | 3949/4545 [4:15:19<38:25,  3.87s/it] 87%|████████▋ | 3950/4545 [4:15:23<38:23,  3.87s/it]                                                     {'loss': 0.053, 'grad_norm': 9.722192764282227, 'learning_rate': 1.8316637560162394e-07, 'rewards/chosen': 2.460742235183716, 'rewards/rejected': -12.296875, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 14.737500190734863, 'logps/chosen': -299.6000061035156, 'logps/rejected': -262.6000061035156, 'logits/chosen': -8.5625, 'logits/rejected': -8.053125381469727, 'epoch': 2.61}
 87%|████████▋ | 3950/4545 [4:15:23<38:23,  3.87s/it] 87%|████████▋ | 3951/4545 [4:15:27<38:38,  3.90s/it] 87%|████████▋ | 3952/4545 [4:15:31<38:34,  3.90s/it] 87%|████████▋ | 3953/4545 [4:15:35<38:44,  3.93s/it] 87%|████████▋ | 3954/4545 [4:15:37<35:27,  3.60s/it] 87%|████████▋ | 3955/4545 [4:15:41<36:13,  3.68s/it] 87%|████████▋ | 3956/4545 [4:15:45<35:38,  3.63s/it] 87%|████████▋ | 3957/4545 [4:15:49<37:09,  3.79s/it] 87%|████████▋ | 3958/4545 [4:15:53<37:24,  3.82s/it] 87%|████████▋ | 3959/4545 [4:15:57<37:33,  3.85s/it] 87%|████████▋ | 3960/4545 [4:16:01<38:00,  3.90s/it]                                                     {'loss': 0.121, 'grad_norm': 47.48203659057617, 'learning_rate': 1.8048463051055014e-07, 'rewards/chosen': 2.86376953125, 'rewards/rejected': -14.243749618530273, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 17.106250762939453, 'logps/chosen': -302.45001220703125, 'logps/rejected': -240.5, 'logits/chosen': -8.756250381469727, 'logits/rejected': -8.043749809265137, 'epoch': 2.61}
 87%|████████▋ | 3960/4545 [4:16:01<38:00,  3.90s/it] 87%|████████▋ | 3961/4545 [4:16:05<38:03,  3.91s/it] 87%|████████▋ | 3962/4545 [4:16:09<38:23,  3.95s/it] 87%|████████▋ | 3963/4545 [4:16:13<38:10,  3.94s/it] 87%|████████▋ | 3964/4545 [4:16:16<37:04,  3.83s/it] 87%|████████▋ | 3965/4545 [4:16:20<35:47,  3.70s/it] 87%|████████▋ | 3966/4545 [4:16:23<34:37,  3.59s/it] 87%|████████▋ | 3967/4545 [4:16:27<36:03,  3.74s/it] 87%|████████▋ | 3968/4545 [4:16:30<34:46,  3.62s/it] 87%|████████▋ | 3969/4545 [4:16:34<34:10,  3.56s/it] 87%|████████▋ | 3970/4545 [4:16:37<32:13,  3.36s/it]                                                     {'loss': 0.0639, 'grad_norm': 2.9249911308288574, 'learning_rate': 1.7784258231018278e-07, 'rewards/chosen': 0.6390625238418579, 'rewards/rejected': -17.709375381469727, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 18.362499237060547, 'logps/chosen': -202.4499969482422, 'logps/rejected': -216.6999969482422, 'logits/chosen': -8.793749809265137, 'logits/rejected': -8.159375190734863, 'epoch': 2.62}
 87%|████████▋ | 3970/4545 [4:16:37<32:13,  3.36s/it] 87%|████████▋ | 3971/4545 [4:16:41<34:21,  3.59s/it] 87%|████████▋ | 3972/4545 [4:16:44<33:37,  3.52s/it] 87%|████████▋ | 3973/4545 [4:16:48<34:43,  3.64s/it] 87%|████████▋ | 3974/4545 [4:16:52<34:37,  3.64s/it] 87%|████████▋ | 3975/4545 [4:16:56<36:00,  3.79s/it] 87%|████████▋ | 3976/4545 [4:17:00<36:06,  3.81s/it] 88%|████████▊ | 3977/4545 [4:17:04<36:08,  3.82s/it] 88%|████████▊ | 3978/4545 [4:17:08<36:15,  3.84s/it] 88%|████████▊ | 3979/4545 [4:17:11<34:04,  3.61s/it] 88%|████████▊ | 3980/4545 [4:17:15<34:47,  3.70s/it]                                                     {'loss': 0.0848, 'grad_norm': 36.816768646240234, 'learning_rate': 1.7524051483472046e-07, 'rewards/chosen': 2.8930420875549316, 'rewards/rejected': -12.21875, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 15.112500190734863, 'logps/chosen': -298.25, 'logps/rejected': -210.10000610351562, 'logits/chosen': -8.706250190734863, 'logits/rejected': -8.346875190734863, 'epoch': 2.63}
 88%|████████▊ | 3980/4545 [4:17:15<34:47,  3.70s/it] 88%|████████▊ | 3981/4545 [4:17:18<35:27,  3.77s/it] 88%|████████▊ | 3982/4545 [4:17:23<36:16,  3.87s/it] 88%|████████▊ | 3983/4545 [4:17:26<36:15,  3.87s/it] 88%|████████▊ | 3984/4545 [4:17:30<34:39,  3.71s/it] 88%|████████▊ | 3985/4545 [4:17:34<35:04,  3.76s/it] 88%|████████▊ | 3986/4545 [4:17:38<35:31,  3.81s/it] 88%|████████▊ | 3987/4545 [4:17:41<35:38,  3.83s/it] 88%|████████▊ | 3988/4545 [4:17:46<36:36,  3.94s/it] 88%|████████▊ | 3989/4545 [4:17:50<37:19,  4.03s/it] 88%|████████▊ | 3990/4545 [4:17:53<33:44,  3.65s/it]                                                     {'loss': 0.0876, 'grad_norm': 9.285757064819336, 'learning_rate': 1.726787076232476e-07, 'rewards/chosen': 2.362255811691284, 'rewards/rejected': -14.651562690734863, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 17.0, 'logps/chosen': -296.3500061035156, 'logps/rejected': -243.89999389648438, 'logits/chosen': -8.806249618530273, 'logits/rejected': -8.293749809265137, 'epoch': 2.63}
 88%|████████▊ | 3990/4545 [4:17:53<33:44,  3.65s/it] 88%|████████▊ | 3991/4545 [4:17:56<33:50,  3.66s/it] 88%|████████▊ | 3992/4545 [4:18:00<34:16,  3.72s/it] 88%|████████▊ | 3993/4545 [4:18:03<31:49,  3.46s/it] 88%|████████▊ | 3994/4545 [4:18:07<33:15,  3.62s/it] 88%|████████▊ | 3995/4545 [4:18:11<33:54,  3.70s/it] 88%|████████▊ | 3996/4545 [4:18:15<34:19,  3.75s/it] 88%|████████▊ | 3997/4545 [4:18:18<33:04,  3.62s/it] 88%|████████▊ | 3998/4545 [4:18:22<33:44,  3.70s/it] 88%|████████▊ | 3999/4545 [4:18:26<34:13,  3.76s/it] 88%|████████▊ | 4000/4545 [4:18:30<35:14,  3.88s/it]                                                     {'loss': 0.0388, 'grad_norm': 5.218099594116211, 'learning_rate': 1.7015743588970472e-07, 'rewards/chosen': 1.6627929210662842, 'rewards/rejected': -16.1875, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 17.837499618530273, 'logps/chosen': -278.20001220703125, 'logps/rejected': -225.60000610351562, 'logits/chosen': -8.90625, 'logits/rejected': -8.231249809265137, 'epoch': 2.64}
 88%|████████▊ | 4000/4545 [4:18:30<35:14,  3.88s/it] 88%|████████▊ | 4001/4545 [4:18:33<33:26,  3.69s/it] 88%|████████▊ | 4002/4545 [4:18:37<33:51,  3.74s/it] 88%|████████▊ | 4003/4545 [4:18:41<34:03,  3.77s/it] 88%|████████▊ | 4004/4545 [4:18:44<32:08,  3.56s/it] 88%|████████▊ | 4005/4545 [4:18:48<32:55,  3.66s/it] 88%|████████▊ | 4006/4545 [4:18:52<34:13,  3.81s/it] 88%|████████▊ | 4007/4545 [4:18:55<32:17,  3.60s/it] 88%|████████▊ | 4008/4545 [4:18:59<32:59,  3.69s/it] 88%|████████▊ | 4009/4545 [4:19:03<33:22,  3.74s/it] 88%|████████▊ | 4010/4545 [4:19:07<34:09,  3.83s/it]                                                     {'loss': 0.0572, 'grad_norm': 27.969968795776367, 'learning_rate': 1.6767697049332196e-07, 'rewards/chosen': 1.7824218273162842, 'rewards/rejected': -11.96875, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 13.759374618530273, 'logps/chosen': -246.5749969482422, 'logps/rejected': -152.60000610351562, 'logits/chosen': -9.0, 'logits/rejected': -8.496874809265137, 'epoch': 2.65}
 88%|████████▊ | 4010/4545 [4:19:07<34:09,  3.83s/it] 88%|████████▊ | 4011/4545 [4:19:11<35:16,  3.96s/it] 88%|████████▊ | 4012/4545 [4:19:15<34:59,  3.94s/it] 88%|████████▊ | 4013/4545 [4:19:18<31:05,  3.51s/it] 88%|████████▊ | 4014/4545 [4:19:21<31:41,  3.58s/it] 88%|████████▊ | 4015/4545 [4:19:25<31:38,  3.58s/it] 88%|████████▊ | 4016/4545 [4:19:29<32:09,  3.65s/it] 88%|████████▊ | 4017/4545 [4:19:33<32:44,  3.72s/it] 88%|████████▊ | 4018/4545 [4:19:37<33:06,  3.77s/it] 88%|████████▊ | 4019/4545 [4:19:41<33:43,  3.85s/it] 88%|████████▊ | 4020/4545 [4:19:44<31:23,  3.59s/it]                                                     {'loss': 0.0489, 'grad_norm': 5.506863117218018, 'learning_rate': 1.652375779095203e-07, 'rewards/chosen': 1.1652343273162842, 'rewards/rejected': -19.265625, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 20.428125381469727, 'logps/chosen': -246.3000030517578, 'logps/rejected': -258.1000061035156, 'logits/chosen': -8.806249618530273, 'logits/rejected': -8.253125190734863, 'epoch': 2.65}
 88%|████████▊ | 4020/4545 [4:19:44<31:23,  3.59s/it] 88%|████████▊ | 4021/4545 [4:19:48<32:18,  3.70s/it] 88%|████████▊ | 4022/4545 [4:19:51<32:47,  3.76s/it] 89%|████████▊ | 4023/4545 [4:19:56<33:28,  3.85s/it] 89%|████████▊ | 4024/4545 [4:19:58<30:12,  3.48s/it] 89%|████████▊ | 4025/4545 [4:20:02<31:04,  3.59s/it] 89%|████████▊ | 4026/4545 [4:20:05<28:44,  3.32s/it] 89%|████████▊ | 4027/4545 [4:20:08<29:31,  3.42s/it] 89%|████████▊ | 4028/4545 [4:20:11<28:25,  3.30s/it] 89%|████████▊ | 4029/4545 [4:20:15<29:50,  3.47s/it] 89%|████████▊ | 4030/4545 [4:20:19<31:35,  3.68s/it]                                                     {'loss': 0.0673, 'grad_norm': 26.880146026611328, 'learning_rate': 1.6283952020128505e-07, 'rewards/chosen': 1.9363281726837158, 'rewards/rejected': -12.793749809265137, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 14.725000381469727, 'logps/chosen': -282.8500061035156, 'logps/rejected': -208.35000610351562, 'logits/chosen': -8.8125, 'logits/rejected': -8.365625381469727, 'epoch': 2.66}
 89%|████████▊ | 4030/4545 [4:20:20<31:35,  3.68s/it] 89%|████████▊ | 4031/4545 [4:20:23<32:13,  3.76s/it] 89%|████████▊ | 4032/4545 [4:20:26<30:34,  3.58s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:43,  1.35it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.09s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.53s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:12<01:22,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.63s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.52s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.08s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.15s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.25s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.40s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.45s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.42355138063430786, 'eval_runtime': 80.6149, 'eval_samples_per_second': 11.822, 'eval_steps_per_second': 0.744, 'eval_rewards/chosen': 2.5047974586486816, 'eval_rewards/rejected': -12.231127738952637, 'eval_rewards/accuracies': 0.8373842835426331, 'eval_rewards/margins': 14.728971481323242, 'eval_logps/chosen': -365.2916564941406, 'eval_logps/rejected': -213.1458282470703, 'eval_logits/chosen': -8.468229293823242, 'eval_logits/rejected': -8.593229293823242, 'epoch': 2.66}
 89%|████████▊ | 4032/4545 [4:21:47<30:34,  3.58s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 89%|████████▊ | 4033/4545 [4:22:03<4:28:29, 31.46s/it] 89%|████████▉ | 4034/4545 [4:22:07<3:17:22, 23.18s/it] 89%|████████▉ | 4035/4545 [4:22:10<2:27:03, 17.30s/it] 89%|████████▉ | 4036/4545 [4:22:14<1:51:32, 13.15s/it] 89%|████████▉ | 4037/4545 [4:22:18<1:27:49, 10.37s/it] 89%|████████▉ | 4038/4545 [4:22:21<1:09:22,  8.21s/it] 89%|████████▉ | 4039/4545 [4:22:25<58:16,  6.91s/it]   89%|████████▉ | 4040/4545 [4:22:29<50:25,  5.99s/it]                                                     {'loss': 0.1085, 'grad_norm': 18.12477684020996, 'learning_rate': 1.6048305499101196e-07, 'rewards/chosen': 1.162500023841858, 'rewards/rejected': -13.578125, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 14.734375, 'logps/chosen': -233.85000610351562, 'logps/rejected': -173.89999389648438, 'logits/chosen': -8.956250190734863, 'logits/rejected': -8.403124809265137, 'epoch': 2.67}
 89%|████████▉ | 4040/4545 [4:22:29<50:25,  5.99s/it] 89%|████████▉ | 4041/4545 [4:22:33<45:07,  5.37s/it] 89%|████████▉ | 4042/4545 [4:22:36<40:42,  4.86s/it] 89%|████████▉ | 4043/4545 [4:22:39<34:45,  4.16s/it] 89%|████████▉ | 4044/4545 [4:22:43<34:19,  4.11s/it] 89%|████████▉ | 4045/4545 [4:22:47<33:40,  4.04s/it] 89%|████████▉ | 4046/4545 [4:22:50<33:00,  3.97s/it] 89%|████████▉ | 4047/4545 [4:22:54<32:45,  3.95s/it] 89%|████████▉ | 4048/4545 [4:22:58<32:20,  3.90s/it] 89%|████████▉ | 4049/4545 [4:23:01<29:35,  3.58s/it] 89%|████████▉ | 4050/4545 [4:23:05<29:40,  3.60s/it]                                                     {'loss': 0.0557, 'grad_norm': 9.852312088012695, 'learning_rate': 1.58168435432831e-07, 'rewards/chosen': 1.8722655773162842, 'rewards/rejected': -12.28125, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 14.168749809265137, 'logps/chosen': -237.89999389648438, 'logps/rejected': -217.6999969482422, 'logits/chosen': -8.9375, 'logits/rejected': -8.359375, 'epoch': 2.67}
 89%|████████▉ | 4050/4545 [4:23:05<29:40,  3.60s/it] 89%|████████▉ | 4051/4545 [4:23:09<30:46,  3.74s/it] 89%|████████▉ | 4052/4545 [4:23:12<29:28,  3.59s/it] 89%|████████▉ | 4053/4545 [4:23:16<30:34,  3.73s/it] 89%|████████▉ | 4054/4545 [4:23:20<31:33,  3.86s/it] 89%|████████▉ | 4055/4545 [4:23:24<31:34,  3.87s/it] 89%|████████▉ | 4056/4545 [4:23:28<31:32,  3.87s/it] 89%|████████▉ | 4057/4545 [4:23:32<31:28,  3.87s/it] 89%|████████▉ | 4058/4545 [4:23:35<29:48,  3.67s/it] 89%|████████▉ | 4059/4545 [4:23:38<29:09,  3.60s/it] 89%|████████▉ | 4060/4545 [4:23:42<29:47,  3.69s/it]                                                     {'loss': 0.0827, 'grad_norm': 27.237977981567383, 'learning_rate': 1.558959101854105e-07, 'rewards/chosen': 3.515820264816284, 'rewards/rejected': -14.628125190734863, 'rewards/accuracies': 0.96875, 'rewards/margins': 18.143749237060547, 'logps/chosen': -370.0, 'logps/rejected': -235.6999969482422, 'logits/chosen': -8.793749809265137, 'logits/rejected': -8.3125, 'epoch': 2.68}
 89%|████████▉ | 4060/4545 [4:23:42<29:47,  3.69s/it] 89%|████████▉ | 4061/4545 [4:23:46<30:37,  3.80s/it] 89%|████████▉ | 4062/4545 [4:23:50<30:39,  3.81s/it] 89%|████████▉ | 4063/4545 [4:23:53<27:03,  3.37s/it] 89%|████████▉ | 4064/4545 [4:23:57<28:28,  3.55s/it] 89%|████████▉ | 4065/4545 [4:24:00<29:13,  3.65s/it] 89%|████████▉ | 4066/4545 [4:24:04<30:09,  3.78s/it] 89%|████████▉ | 4067/4545 [4:24:07<27:57,  3.51s/it] 90%|████████▉ | 4068/4545 [4:24:11<28:48,  3.62s/it] 90%|████████▉ | 4069/4545 [4:24:13<24:50,  3.13s/it] 90%|████████▉ | 4070/4545 [4:24:17<26:55,  3.40s/it]                                                     {'loss': 0.0763, 'grad_norm': 10.273574829101562, 'learning_rate': 1.5366572338524305e-07, 'rewards/chosen': 2.229687452316284, 'rewards/rejected': -12.759374618530273, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 14.981249809265137, 'logps/chosen': -262.45001220703125, 'logps/rejected': -196.60000610351562, 'logits/chosen': -8.831250190734863, 'logits/rejected': -8.221875190734863, 'epoch': 2.69}
 90%|████████▉ | 4070/4545 [4:24:17<26:55,  3.40s/it] 90%|████████▉ | 4071/4545 [4:24:21<28:21,  3.59s/it] 90%|████████▉ | 4072/4545 [4:24:25<29:00,  3.68s/it] 90%|████████▉ | 4073/4545 [4:24:28<27:55,  3.55s/it] 90%|████████▉ | 4074/4545 [4:24:32<28:31,  3.63s/it] 90%|████████▉ | 4075/4545 [4:24:36<29:02,  3.71s/it] 90%|████████▉ | 4076/4545 [4:24:40<29:47,  3.81s/it] 90%|████████▉ | 4077/4545 [4:24:44<30:27,  3.91s/it] 90%|████████▉ | 4078/4545 [4:24:47<27:30,  3.53s/it] 90%|████████▉ | 4079/4545 [4:24:51<28:14,  3.64s/it] 90%|████████▉ | 4080/4545 [4:24:55<28:23,  3.66s/it]                                                     {'loss': 0.0752, 'grad_norm': 12.509684562683105, 'learning_rate': 1.5147811462041901e-07, 'rewards/chosen': 4.25390625, 'rewards/rejected': -12.946874618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 17.212499618530273, 'logps/chosen': -387.5, 'logps/rejected': -239.10000610351562, 'logits/chosen': -8.5, 'logits/rejected': -7.996874809265137, 'epoch': 2.69}
 90%|████████▉ | 4080/4545 [4:24:55<28:23,  3.66s/it] 90%|████████▉ | 4081/4545 [4:24:59<29:17,  3.79s/it] 90%|████████▉ | 4082/4545 [4:25:02<29:16,  3.79s/it] 90%|████████▉ | 4083/4545 [4:25:07<29:58,  3.89s/it] 90%|████████▉ | 4084/4545 [4:25:09<27:29,  3.58s/it] 90%|████████▉ | 4085/4545 [4:25:13<28:01,  3.66s/it] 90%|████████▉ | 4086/4545 [4:25:17<27:53,  3.65s/it] 90%|████████▉ | 4087/4545 [4:25:21<28:22,  3.72s/it] 90%|████████▉ | 4088/4545 [4:25:25<28:41,  3.77s/it] 90%|████████▉ | 4089/4545 [4:25:29<28:52,  3.80s/it] 90%|████████▉ | 4090/4545 [4:25:32<28:15,  3.73s/it]                                                     {'loss': 0.1132, 'grad_norm': 5.391350269317627, 'learning_rate': 1.4933331890488704e-07, 'rewards/chosen': 3.657421827316284, 'rewards/rejected': -14.539843559265137, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 18.212499618530273, 'logps/chosen': -353.20001220703125, 'logps/rejected': -253.5500030517578, 'logits/chosen': -8.731249809265137, 'logits/rejected': -8.303125381469727, 'epoch': 2.7}
 90%|████████▉ | 4090/4545 [4:25:32<28:15,  3.73s/it] 90%|█████████ | 4091/4545 [4:25:36<28:26,  3.76s/it] 90%|█████████ | 4092/4545 [4:25:40<28:41,  3.80s/it] 90%|█████████ | 4093/4545 [4:25:44<28:50,  3.83s/it] 90%|█████████ | 4094/4545 [4:25:47<28:02,  3.73s/it] 90%|█████████ | 4095/4545 [4:25:51<28:21,  3.78s/it] 90%|█████████ | 4096/4545 [4:25:54<26:32,  3.55s/it] 90%|█████████ | 4097/4545 [4:25:58<27:14,  3.65s/it] 90%|█████████ | 4098/4545 [4:26:01<26:07,  3.51s/it] 90%|█████████ | 4099/4545 [4:26:05<26:46,  3.60s/it] 90%|█████████ | 4100/4545 [4:26:09<27:43,  3.74s/it]                                                     {'loss': 0.1888, 'grad_norm': 15.329017639160156, 'learning_rate': 1.4723156665320644e-07, 'rewards/chosen': 3.415234327316284, 'rewards/rejected': -13.246874809265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 16.681249618530273, 'logps/chosen': -369.29998779296875, 'logps/rejected': -232.89999389648438, 'logits/chosen': -8.668749809265137, 'logits/rejected': -8.306249618530273, 'epoch': 2.71}
 90%|█████████ | 4100/4545 [4:26:09<27:43,  3.74s/it] 90%|█████████ | 4101/4545 [4:26:13<28:05,  3.80s/it] 90%|█████████ | 4102/4545 [4:26:17<28:15,  3.83s/it] 90%|█████████ | 4103/4545 [4:26:21<28:19,  3.85s/it] 90%|█████████ | 4104/4545 [4:26:25<28:24,  3.87s/it] 90%|█████████ | 4105/4545 [4:26:29<28:51,  3.94s/it] 90%|█████████ | 4106/4545 [4:26:33<29:22,  4.02s/it] 90%|█████████ | 4107/4545 [4:26:37<29:01,  3.98s/it] 90%|█████████ | 4108/4545 [4:26:41<29:00,  3.98s/it] 90%|█████████ | 4109/4545 [4:26:45<28:55,  3.98s/it] 90%|█████████ | 4110/4545 [4:26:49<28:37,  3.95s/it]                                                     {'loss': 0.0823, 'grad_norm': 15.188606262207031, 'learning_rate': 1.451730836557944e-07, 'rewards/chosen': 2.3101563453674316, 'rewards/rejected': -14.875, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 17.168750762939453, 'logps/chosen': -298.8500061035156, 'logps/rejected': -233.89999389648438, 'logits/chosen': -8.893750190734863, 'logits/rejected': -8.371874809265137, 'epoch': 2.71}
 90%|█████████ | 4110/4545 [4:26:49<28:37,  3.95s/it] 90%|█████████ | 4111/4545 [4:26:53<28:26,  3.93s/it] 90%|█████████ | 4112/4545 [4:26:56<27:56,  3.87s/it] 90%|█████████ | 4113/4545 [4:27:00<28:16,  3.93s/it] 91%|█████████ | 4114/4545 [4:27:04<27:32,  3.84s/it] 91%|█████████ | 4115/4545 [4:27:07<26:20,  3.68s/it] 91%|█████████ | 4116/4545 [4:27:11<25:43,  3.60s/it] 91%|█████████ | 4117/4545 [4:27:15<26:10,  3.67s/it] 91%|█████████ | 4118/4545 [4:27:18<26:33,  3.73s/it] 91%|█████████ | 4119/4545 [4:27:22<26:19,  3.71s/it] 91%|█████████ | 4120/4545 [4:27:26<26:39,  3.76s/it]                                                     {'loss': 0.0739, 'grad_norm': 7.912461280822754, 'learning_rate': 1.4315809105466942e-07, 'rewards/chosen': 1.42529296875, 'rewards/rejected': -12.940625190734863, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 14.362500190734863, 'logps/chosen': -213.1750030517578, 'logps/rejected': -177.14999389648438, 'logits/chosen': -8.993749618530273, 'logits/rejected': -8.256250381469727, 'epoch': 2.72}
 91%|█████████ | 4120/4545 [4:27:26<26:39,  3.76s/it] 91%|█████████ | 4121/4545 [4:27:30<26:54,  3.81s/it] 91%|█████████ | 4122/4545 [4:27:34<27:28,  3.90s/it] 91%|█████████ | 4123/4545 [4:27:37<26:15,  3.73s/it] 91%|█████████ | 4124/4545 [4:27:41<26:33,  3.78s/it] 91%|█████████ | 4125/4545 [4:27:45<26:07,  3.73s/it] 91%|█████████ | 4126/4545 [4:27:49<26:18,  3.77s/it] 91%|█████████ | 4127/4545 [4:27:52<25:52,  3.71s/it] 91%|█████████ | 4128/4545 [4:27:56<26:20,  3.79s/it] 91%|█████████ | 4129/4545 [4:28:00<26:32,  3.83s/it] 91%|█████████ | 4130/4545 [4:28:04<26:50,  3.88s/it]                                                     {'loss': 0.0697, 'grad_norm': 10.370229721069336, 'learning_rate': 1.4118680531969333e-07, 'rewards/chosen': 1.278710961341858, 'rewards/rejected': -20.806249618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 22.068750381469727, 'logps/chosen': -282.75, 'logps/rejected': -233.25, 'logits/chosen': -8.731249809265137, 'logits/rejected': -8.196874618530273, 'epoch': 2.73}
 91%|█████████ | 4130/4545 [4:28:04<26:50,  3.88s/it] 91%|█████████ | 4131/4545 [4:28:09<27:49,  4.03s/it] 91%|█████████ | 4132/4545 [4:28:13<28:02,  4.07s/it] 91%|█████████ | 4133/4545 [4:28:17<27:56,  4.07s/it] 91%|█████████ | 4134/4545 [4:28:20<25:37,  3.74s/it] 91%|█████████ | 4135/4545 [4:28:24<25:38,  3.75s/it] 91%|█████████ | 4136/4545 [4:28:27<25:30,  3.74s/it] 91%|█████████ | 4137/4545 [4:28:30<22:21,  3.29s/it] 91%|█████████ | 4138/4545 [4:28:34<23:56,  3.53s/it] 91%|█████████ | 4139/4545 [4:28:38<24:43,  3.66s/it] 91%|█████████ | 4140/4545 [4:28:41<23:51,  3.53s/it]                                                     {'loss': 0.0931, 'grad_norm': 12.237424850463867, 'learning_rate': 1.3925943822531674e-07, 'rewards/chosen': -0.05146484449505806, 'rewards/rejected': -17.40625, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 17.353124618530273, 'logps/chosen': -143.8000030517578, 'logps/rejected': -171.6999969482422, 'logits/chosen': -9.125, 'logits/rejected': -8.256250381469727, 'epoch': 2.73}
 91%|█████████ | 4140/4545 [4:28:41<23:51,  3.53s/it] 91%|█████████ | 4141/4545 [4:28:44<22:45,  3.38s/it] 91%|█████████ | 4142/4545 [4:28:48<23:49,  3.55s/it] 91%|█████████ | 4143/4545 [4:28:51<22:10,  3.31s/it] 91%|█████████ | 4144/4545 [4:28:54<22:35,  3.38s/it] 91%|█████████ | 4145/4545 [4:28:58<23:19,  3.50s/it] 91%|█████████ | 4146/4545 [4:29:02<24:36,  3.70s/it] 91%|█████████ | 4147/4545 [4:29:05<23:15,  3.51s/it] 91%|█████████▏| 4148/4545 [4:29:09<24:30,  3.70s/it] 91%|█████████▏| 4149/4545 [4:29:12<22:37,  3.43s/it] 91%|█████████▏| 4150/4545 [4:29:16<24:01,  3.65s/it]                                                     {'loss': 0.1157, 'grad_norm': 3.6203105449676514, 'learning_rate': 1.373761968278282e-07, 'rewards/chosen': 1.8742187023162842, 'rewards/rejected': -16.725000381469727, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 18.581249237060547, 'logps/chosen': -290.1499938964844, 'logps/rejected': -202.3000030517578, 'logits/chosen': -8.6875, 'logits/rejected': -8.068750381469727, 'epoch': 2.74}
 91%|█████████▏| 4150/4545 [4:29:16<24:01,  3.65s/it] 91%|█████████▏| 4151/4545 [4:29:20<24:35,  3.75s/it] 91%|█████████▏| 4152/4545 [4:29:24<25:18,  3.86s/it] 91%|█████████▏| 4153/4545 [4:29:28<25:17,  3.87s/it] 91%|█████████▏| 4154/4545 [4:29:32<24:48,  3.81s/it] 91%|█████████▏| 4155/4545 [4:29:34<21:25,  3.30s/it] 91%|█████████▏| 4156/4545 [4:29:38<22:32,  3.48s/it] 91%|█████████▏| 4157/4545 [4:29:42<23:11,  3.59s/it] 91%|█████████▏| 4158/4545 [4:29:46<23:37,  3.66s/it] 92%|█████████▏| 4159/4545 [4:29:49<22:40,  3.52s/it] 92%|█████████▏| 4160/4545 [4:29:53<23:17,  3.63s/it]                                                     {'loss': 0.0563, 'grad_norm': 2.8876569271087646, 'learning_rate': 1.355372834431096e-07, 'rewards/chosen': 2.645800828933716, 'rewards/rejected': -12.209375381469727, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 14.862500190734863, 'logps/chosen': -267.54998779296875, 'logps/rejected': -249.75, 'logits/chosen': -9.006250381469727, 'logits/rejected': -8.274999618530273, 'epoch': 2.75}
 92%|█████████▏| 4160/4545 [4:29:53<23:17,  3.63s/it] 92%|█████████▏| 4161/4545 [4:29:56<22:26,  3.51s/it] 92%|█████████▏| 4162/4545 [4:29:59<20:48,  3.26s/it] 92%|█████████▏| 4163/4545 [4:30:03<22:33,  3.54s/it] 92%|█████████▏| 4164/4545 [4:30:07<23:05,  3.64s/it] 92%|█████████▏| 4165/4545 [4:30:10<23:25,  3.70s/it] 92%|█████████▏| 4166/4545 [4:30:14<23:48,  3.77s/it] 92%|█████████▏| 4167/4545 [4:30:18<22:56,  3.64s/it] 92%|█████████▏| 4168/4545 [4:30:22<23:21,  3.72s/it] 92%|█████████▏| 4169/4545 [4:30:25<22:53,  3.65s/it] 92%|█████████▏| 4170/4545 [4:30:29<23:05,  3.70s/it]                                                     {'loss': 0.0859, 'grad_norm': 20.186115264892578, 'learning_rate': 1.3374289562490213e-07, 'rewards/chosen': 1.744531273841858, 'rewards/rejected': -13.428125381469727, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 15.149999618530273, 'logps/chosen': -248.0500030517578, 'logps/rejected': -230.89999389648438, 'logits/chosen': -8.887499809265137, 'logits/rejected': -8.306249618530273, 'epoch': 2.75}
 92%|█████████▏| 4170/4545 [4:30:29<23:05,  3.70s/it] 92%|█████████▏| 4171/4545 [4:30:33<23:09,  3.72s/it] 92%|█████████▏| 4172/4545 [4:30:37<23:32,  3.79s/it] 92%|█████████▏| 4173/4545 [4:30:39<21:07,  3.41s/it] 92%|█████████▏| 4174/4545 [4:30:43<22:02,  3.57s/it] 92%|█████████▏| 4175/4545 [4:30:46<21:07,  3.43s/it] 92%|█████████▏| 4176/4545 [4:30:50<21:53,  3.56s/it] 92%|█████████▏| 4177/4545 [4:30:53<21:03,  3.43s/it] 92%|█████████▏| 4178/4545 [4:30:57<21:34,  3.53s/it] 92%|█████████▏| 4179/4545 [4:30:59<19:36,  3.22s/it] 92%|█████████▏| 4180/4545 [4:31:03<19:34,  3.22s/it]                                                     {'loss': 0.0934, 'grad_norm': 12.949087142944336, 'learning_rate': 1.3199322614358295e-07, 'rewards/chosen': 2.473925828933716, 'rewards/rejected': -16.7890625, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 19.231250762939453, 'logps/chosen': -295.0, 'logps/rejected': -228.35000610351562, 'logits/chosen': -8.806249618530273, 'logits/rejected': -8.365625381469727, 'epoch': 2.76}
 92%|█████████▏| 4180/4545 [4:31:03<19:34,  3.22s/it] 92%|█████████▏| 4181/4545 [4:31:06<19:45,  3.26s/it] 92%|█████████▏| 4182/4545 [4:31:10<20:53,  3.45s/it] 92%|█████████▏| 4183/4545 [4:31:14<21:38,  3.59s/it] 92%|█████████▏| 4184/4545 [4:31:18<22:07,  3.68s/it] 92%|█████████▏| 4185/4545 [4:31:21<22:18,  3.72s/it] 92%|█████████▏| 4186/4545 [4:31:25<22:32,  3.77s/it] 92%|█████████▏| 4187/4545 [4:31:30<23:16,  3.90s/it] 92%|█████████▏| 4188/4545 [4:31:33<23:05,  3.88s/it] 92%|█████████▏| 4189/4545 [4:31:37<23:00,  3.88s/it] 92%|█████████▏| 4190/4545 [4:31:41<22:35,  3.82s/it]                                                     {'loss': 0.0636, 'grad_norm': 14.195334434509277, 'learning_rate': 1.3028846296545566e-07, 'rewards/chosen': 3.9242186546325684, 'rewards/rejected': -12.262499809265137, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 16.1875, 'logps/chosen': -394.20001220703125, 'logps/rejected': -310.70001220703125, 'logits/chosen': -8.587499618530273, 'logits/rejected': -8.096875190734863, 'epoch': 2.77}
 92%|█████████▏| 4190/4545 [4:31:41<22:35,  3.82s/it] 92%|█████████▏| 4191/4545 [4:31:45<22:14,  3.77s/it] 92%|█████████▏| 4192/4545 [4:31:47<20:23,  3.47s/it] 92%|█████████▏| 4193/4545 [4:31:51<20:17,  3.46s/it] 92%|█████████▏| 4194/4545 [4:31:54<20:28,  3.50s/it] 92%|█████████▏| 4195/4545 [4:31:58<21:06,  3.62s/it] 92%|█████████▏| 4196/4545 [4:32:02<21:07,  3.63s/it] 92%|█████████▏| 4197/4545 [4:32:06<21:31,  3.71s/it] 92%|█████████▏| 4198/4545 [4:32:09<20:28,  3.54s/it] 92%|█████████▏| 4199/4545 [4:32:13<21:02,  3.65s/it] 92%|█████████▏| 4200/4545 [4:32:17<21:16,  3.70s/it]                                                     {'loss': 0.0471, 'grad_norm': 9.219902038574219, 'learning_rate': 1.2862878923255764e-07, 'rewards/chosen': 1.0754883289337158, 'rewards/rejected': -16.03125, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 17.09375, 'logps/chosen': -240.1999969482422, 'logps/rejected': -187.6999969482422, 'logits/chosen': -8.918749809265137, 'logits/rejected': -8.259374618530273, 'epoch': 2.77}
 92%|█████████▏| 4200/4545 [4:32:17<21:16,  3.70s/it] 92%|█████████▏| 4201/4545 [4:32:20<21:16,  3.71s/it] 92%|█████████▏| 4202/4545 [4:32:24<21:37,  3.78s/it] 92%|█████████▏| 4203/4545 [4:32:28<21:45,  3.82s/it] 92%|█████████▏| 4204/4545 [4:32:32<21:25,  3.77s/it] 93%|█████████▎| 4205/4545 [4:32:36<21:34,  3.81s/it] 93%|█████████▎| 4206/4545 [4:32:40<21:39,  3.83s/it] 93%|█████████▎| 4207/4545 [4:32:44<21:27,  3.81s/it] 93%|█████████▎| 4208/4545 [4:32:47<21:37,  3.85s/it] 93%|█████████▎| 4209/4545 [4:32:51<21:33,  3.85s/it] 93%|█████████▎| 4210/4545 [4:32:55<21:16,  3.81s/it]                                                     {'loss': 0.0802, 'grad_norm': 39.7774658203125, 'learning_rate': 1.2701438324298465e-07, 'rewards/chosen': 4.680761814117432, 'rewards/rejected': -9.487109184265137, 'rewards/accuracies': 0.96875, 'rewards/margins': 14.168749809265137, 'logps/chosen': -411.54998779296875, 'logps/rejected': -258.8500061035156, 'logits/chosen': -8.524999618530273, 'logits/rejected': -8.284375190734863, 'epoch': 2.78}
 93%|█████████▎| 4210/4545 [4:32:55<21:16,  3.81s/it] 93%|█████████▎| 4211/4545 [4:32:59<21:44,  3.91s/it] 93%|█████████▎| 4212/4545 [4:33:03<21:01,  3.79s/it] 93%|█████████▎| 4213/4545 [4:33:06<20:52,  3.77s/it] 93%|█████████▎| 4214/4545 [4:33:09<19:36,  3.55s/it] 93%|█████████▎| 4215/4545 [4:33:13<20:19,  3.70s/it] 93%|█████████▎| 4216/4545 [4:33:17<19:47,  3.61s/it] 93%|█████████▎| 4217/4545 [4:33:21<20:06,  3.68s/it] 93%|█████████▎| 4218/4545 [4:33:24<19:34,  3.59s/it] 93%|█████████▎| 4219/4545 [4:33:27<18:25,  3.39s/it] 93%|█████████▎| 4220/4545 [4:33:31<19:09,  3.54s/it]                                                     {'loss': 0.0886, 'grad_norm': 31.27797508239746, 'learning_rate': 1.2544541843173677e-07, 'rewards/chosen': 0.6337890625, 'rewards/rejected': -13.887499809265137, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 14.524999618530273, 'logps/chosen': -183.5, 'logps/rejected': -174.4499969482422, 'logits/chosen': -8.96875, 'logits/rejected': -8.21875, 'epoch': 2.79}
 93%|█████████▎| 4220/4545 [4:33:31<19:09,  3.54s/it] 93%|█████████▎| 4221/4545 [4:33:35<19:46,  3.66s/it] 93%|█████████▎| 4222/4545 [4:33:39<20:26,  3.80s/it] 93%|█████████▎| 4223/4545 [4:33:43<20:34,  3.83s/it] 93%|█████████▎| 4224/4545 [4:33:47<20:36,  3.85s/it] 93%|█████████▎| 4225/4545 [4:33:51<20:36,  3.86s/it] 93%|█████████▎| 4226/4545 [4:33:55<20:36,  3.88s/it] 93%|█████████▎| 4227/4545 [4:33:58<20:09,  3.80s/it] 93%|█████████▎| 4228/4545 [4:34:02<20:12,  3.83s/it] 93%|█████████▎| 4229/4545 [4:34:06<20:10,  3.83s/it] 93%|█████████▎| 4230/4545 [4:34:09<19:21,  3.69s/it]                                                     {'loss': 0.1259, 'grad_norm': 93.40579223632812, 'learning_rate': 1.2392206335208627e-07, 'rewards/chosen': 1.154687523841858, 'rewards/rejected': -14.893750190734863, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 16.068750381469727, 'logps/chosen': -234.1999969482422, 'logps/rejected': -195.64999389648438, 'logits/chosen': -8.837499618530273, 'logits/rejected': -8.165624618530273, 'epoch': 2.79}
 93%|█████████▎| 4230/4545 [4:34:09<19:21,  3.69s/it] 93%|█████████▎| 4231/4545 [4:34:13<19:43,  3.77s/it] 93%|█████████▎| 4232/4545 [4:34:17<19:57,  3.83s/it] 93%|█████████▎| 4233/4545 [4:34:21<20:00,  3.85s/it] 93%|█████████▎| 4234/4545 [4:34:25<20:21,  3.93s/it] 93%|█████████▎| 4235/4545 [4:34:29<20:19,  3.94s/it] 93%|█████████▎| 4236/4545 [4:34:33<20:12,  3.92s/it] 93%|█████████▎| 4237/4545 [4:34:37<19:25,  3.78s/it] 93%|█████████▎| 4238/4545 [4:34:41<19:37,  3.84s/it] 93%|█████████▎| 4239/4545 [4:34:43<17:44,  3.48s/it] 93%|█████████▎| 4240/4545 [4:34:47<18:44,  3.69s/it]                                                     {'loss': 0.0918, 'grad_norm': 10.627440452575684, 'learning_rate': 1.224444816574696e-07, 'rewards/chosen': 2.040332078933716, 'rewards/rejected': -13.946874618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 15.981249809265137, 'logps/chosen': -279.04998779296875, 'logps/rejected': -240.8000030517578, 'logits/chosen': -8.75, 'logits/rejected': -8.206250190734863, 'epoch': 2.8}
 93%|█████████▎| 4240/4545 [4:34:48<18:44,  3.69s/it] 93%|█████████▎| 4241/4545 [4:34:51<18:43,  3.70s/it] 93%|█████████▎| 4242/4545 [4:34:55<18:31,  3.67s/it] 93%|█████████▎| 4243/4545 [4:34:59<18:51,  3.75s/it] 93%|█████████▎| 4244/4545 [4:35:02<19:00,  3.79s/it] 93%|█████████▎| 4245/4545 [4:35:07<19:26,  3.89s/it] 93%|█████████▎| 4246/4545 [4:35:10<19:22,  3.89s/it] 93%|█████████▎| 4247/4545 [4:35:14<19:16,  3.88s/it] 93%|█████████▎| 4248/4545 [4:35:18<18:48,  3.80s/it] 93%|█████████▎| 4249/4545 [4:35:22<19:06,  3.87s/it] 94%|█████████▎| 4250/4545 [4:35:26<18:59,  3.86s/it]                                                     {'loss': 0.032, 'grad_norm': 12.237065315246582, 'learning_rate': 1.210128320839068e-07, 'rewards/chosen': 5.633984565734863, 'rewards/rejected': -12.668749809265137, 'rewards/accuracies': 1.0, 'rewards/margins': 18.293750762939453, 'logps/chosen': -478.04998779296875, 'logps/rejected': -285.75, 'logits/chosen': -8.524999618530273, 'logits/rejected': -8.071874618530273, 'epoch': 2.81}
 94%|█████████▎| 4250/4545 [4:35:26<18:59,  3.86s/it] 94%|█████████▎| 4251/4545 [4:35:30<19:15,  3.93s/it] 94%|█████████▎| 4252/4545 [4:35:34<19:06,  3.91s/it] 94%|█████████▎| 4253/4545 [4:35:38<18:58,  3.90s/it] 94%|█████████▎| 4254/4545 [4:35:42<19:12,  3.96s/it] 94%|█████████▎| 4255/4545 [4:35:45<18:37,  3.86s/it] 94%|█████████▎| 4256/4545 [4:35:49<18:41,  3.88s/it] 94%|█████████▎| 4257/4545 [4:35:53<18:02,  3.76s/it] 94%|█████████▎| 4258/4545 [4:35:57<18:05,  3.78s/it] 94%|█████████▎| 4259/4545 [4:36:01<18:11,  3.82s/it] 94%|█████████▎| 4260/4545 [4:36:03<16:07,  3.39s/it]                                                     {'loss': 0.1231, 'grad_norm': 12.62523078918457, 'learning_rate': 1.196272684329479e-07, 'rewards/chosen': 2.171679735183716, 'rewards/rejected': -12.745312690734863, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 14.9375, 'logps/chosen': -292.07501220703125, 'logps/rejected': -230.3000030517578, 'logits/chosen': -8.815625190734863, 'logits/rejected': -8.253125190734863, 'epoch': 2.81}
 94%|█████████▎| 4260/4545 [4:36:03<16:07,  3.39s/it] 94%|█████████▍| 4261/4545 [4:36:07<17:31,  3.70s/it] 94%|█████████▍| 4262/4545 [4:36:11<17:42,  3.76s/it] 94%|█████████▍| 4263/4545 [4:36:15<17:12,  3.66s/it] 94%|█████████▍| 4264/4545 [4:36:19<17:29,  3.73s/it] 94%|█████████▍| 4265/4545 [4:36:22<16:42,  3.58s/it] 94%|█████████▍| 4266/4545 [4:36:26<17:32,  3.77s/it] 94%|█████████▍| 4267/4545 [4:36:30<17:44,  3.83s/it] 94%|█████████▍| 4268/4545 [4:36:34<17:45,  3.85s/it] 94%|█████████▍| 4269/4545 [4:36:37<17:14,  3.75s/it] 94%|█████████▍| 4270/4545 [4:36:42<17:44,  3.87s/it]                                                     {'loss': 0.1048, 'grad_norm': 35.72478103637695, 'learning_rate': 1.1828793955515074e-07, 'rewards/chosen': 3.24462890625, 'rewards/rejected': -11.022656440734863, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 14.28125, 'logps/chosen': -321.79998779296875, 'logps/rejected': -254.8000030517578, 'logits/chosen': -8.668749809265137, 'logits/rejected': -8.125, 'epoch': 2.82}
 94%|█████████▍| 4270/4545 [4:36:42<17:44,  3.87s/it] 94%|█████████▍| 4271/4545 [4:36:46<17:51,  3.91s/it] 94%|█████████▍| 4272/4545 [4:36:48<16:22,  3.60s/it] 94%|█████████▍| 4273/4545 [4:36:52<16:03,  3.54s/it] 94%|█████████▍| 4274/4545 [4:36:55<15:28,  3.43s/it] 94%|█████████▍| 4275/4545 [4:36:59<16:03,  3.57s/it] 94%|█████████▍| 4276/4545 [4:37:03<16:06,  3.59s/it] 94%|█████████▍| 4277/4545 [4:37:04<13:40,  3.06s/it] 94%|█████████▍| 4278/4545 [4:37:08<14:45,  3.32s/it] 94%|█████████▍| 4279/4545 [4:37:12<14:38,  3.30s/it] 94%|█████████▍| 4280/4545 [4:37:15<15:21,  3.48s/it]                                                     {'loss': 0.0672, 'grad_norm': 3.455904245376587, 'learning_rate': 1.1699498933408943e-07, 'rewards/chosen': 1.91015625, 'rewards/rejected': -13.618749618530273, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 15.53125, 'logps/chosen': -232.77499389648438, 'logps/rejected': -191.1999969482422, 'logits/chosen': -8.887499809265137, 'logits/rejected': -8.296875, 'epoch': 2.83}
 94%|█████████▍| 4280/4545 [4:37:16<15:21,  3.48s/it] 94%|█████████▍| 4281/4545 [4:37:20<16:17,  3.70s/it] 94%|█████████▍| 4282/4545 [4:37:24<16:33,  3.78s/it] 94%|█████████▍| 4283/4545 [4:37:27<16:37,  3.81s/it] 94%|█████████▍| 4284/4545 [4:37:31<15:47,  3.63s/it] 94%|█████████▍| 4285/4545 [4:37:35<16:03,  3.71s/it] 94%|█████████▍| 4286/4545 [4:37:38<15:26,  3.58s/it] 94%|█████████▍| 4287/4545 [4:37:41<14:42,  3.42s/it] 94%|█████████▍| 4288/4545 [4:37:45<15:13,  3.56s/it] 94%|█████████▍| 4289/4545 [4:37:49<15:33,  3.65s/it] 94%|█████████▍| 4290/4545 [4:37:53<15:56,  3.75s/it]                                                     {'loss': 0.0828, 'grad_norm': 19.767135620117188, 'learning_rate': 1.1574855667089743e-07, 'rewards/chosen': 1.4910156726837158, 'rewards/rejected': -15.481249809265137, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 16.962499618530273, 'logps/chosen': -270.54998779296875, 'logps/rejected': -208.75, 'logits/chosen': -8.824999809265137, 'logits/rejected': -8.300000190734863, 'epoch': 2.83}
 94%|█████████▍| 4290/4545 [4:37:53<15:56,  3.75s/it] 94%|█████████▍| 4291/4545 [4:37:57<16:09,  3.82s/it] 94%|█████████▍| 4292/4545 [4:38:00<15:22,  3.65s/it] 94%|█████████▍| 4293/4545 [4:38:04<15:40,  3.73s/it] 94%|█████████▍| 4294/4545 [4:38:07<15:15,  3.65s/it] 94%|█████████▍| 4295/4545 [4:38:11<15:27,  3.71s/it] 95%|█████████▍| 4296/4545 [4:38:14<13:50,  3.34s/it] 95%|█████████▍| 4297/4545 [4:38:18<14:50,  3.59s/it] 95%|█████████▍| 4298/4545 [4:38:22<15:09,  3.68s/it] 95%|█████████▍| 4299/4545 [4:38:25<15:04,  3.68s/it] 95%|█████████▍| 4300/4545 [4:38:29<15:36,  3.82s/it]                                                     {'loss': 0.0515, 'grad_norm': 35.76664352416992, 'learning_rate': 1.1454877546934496e-07, 'rewards/chosen': 0.01230468787252903, 'rewards/rejected': -15.253125190734863, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 15.274999618530273, 'logps/chosen': -212.75, 'logps/rejected': -197.8000030517578, 'logits/chosen': -8.712499618530273, 'logits/rejected': -8.271875381469727, 'epoch': 2.84}
 95%|█████████▍| 4300/4545 [4:38:30<15:36,  3.82s/it] 95%|█████████▍| 4301/4545 [4:38:33<15:42,  3.86s/it] 95%|█████████▍| 4302/4545 [4:38:37<15:40,  3.87s/it] 95%|█████████▍| 4303/4545 [4:38:41<15:36,  3.87s/it] 95%|█████████▍| 4304/4545 [4:38:45<15:40,  3.90s/it] 95%|█████████▍| 4305/4545 [4:38:49<15:29,  3.87s/it] 95%|█████████▍| 4306/4545 [4:38:53<15:29,  3.89s/it] 95%|█████████▍| 4307/4545 [4:38:57<15:23,  3.88s/it] 95%|█████████▍| 4308/4545 [4:38:59<13:25,  3.40s/it] 95%|█████████▍| 4309/4545 [4:39:03<13:57,  3.55s/it] 95%|█████████▍| 4310/4545 [4:39:06<13:36,  3.47s/it]                                                     {'loss': 0.1076, 'grad_norm': 9.047296524047852, 'learning_rate': 1.133957746214545e-07, 'rewards/chosen': 3.5435547828674316, 'rewards/rejected': -13.768750190734863, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 17.315624237060547, 'logps/chosen': -384.8999938964844, 'logps/rejected': -248.60000610351562, 'logits/chosen': -8.459375381469727, 'logits/rejected': -8.015625, 'epoch': 2.84}
 95%|█████████▍| 4310/4545 [4:39:06<13:36,  3.47s/it] 95%|█████████▍| 4311/4545 [4:39:10<14:29,  3.71s/it] 95%|█████████▍| 4312/4545 [4:39:13<12:49,  3.30s/it] 95%|█████████▍| 4313/4545 [4:39:17<13:24,  3.47s/it] 95%|█████████▍| 4314/4545 [4:39:21<14:09,  3.68s/it] 95%|█████████▍| 4315/4545 [4:39:25<14:25,  3.76s/it] 95%|█████████▍| 4316/4545 [4:39:28<13:46,  3.61s/it] 95%|█████████▍| 4317/4545 [4:39:32<14:02,  3.69s/it] 95%|█████████▌| 4318/4545 [4:39:36<13:53,  3.67s/it] 95%|█████████▌| 4319/4545 [4:39:39<14:04,  3.74s/it] 95%|█████████▌| 4320/4545 [4:39:42<12:28,  3.33s/it]                                                     {'loss': 0.144, 'grad_norm': 30.35747718811035, 'learning_rate': 1.1228967799365324e-07, 'rewards/chosen': 3.8597655296325684, 'rewards/rejected': -8.959375381469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 12.806249618530273, 'logps/chosen': -345.75, 'logps/rejected': -264.8999938964844, 'logits/chosen': -8.721875190734863, 'logits/rejected': -8.309374809265137, 'epoch': 2.85}
 95%|█████████▌| 4320/4545 [4:39:42<12:28,  3.33s/it] 95%|█████████▌| 4321/4545 [4:39:46<13:05,  3.51s/it] 95%|█████████▌| 4322/4545 [4:39:50<13:40,  3.68s/it] 95%|█████████▌| 4323/4545 [4:39:54<13:50,  3.74s/it] 95%|█████████▌| 4324/4545 [4:39:58<14:15,  3.87s/it] 95%|█████████▌| 4325/4545 [4:40:01<13:31,  3.69s/it] 95%|█████████▌| 4326/4545 [4:40:04<13:02,  3.57s/it] 95%|█████████▌| 4327/4545 [4:40:08<13:12,  3.64s/it] 95%|█████████▌| 4328/4545 [4:40:12<13:25,  3.71s/it] 95%|█████████▌| 4329/4545 [4:40:16<13:31,  3.76s/it] 95%|█████████▌| 4330/4545 [4:40:20<13:35,  3.79s/it]                                                     {'loss': 0.1466, 'grad_norm': 14.852583885192871, 'learning_rate': 1.1123060441346646e-07, 'rewards/chosen': 1.4900391101837158, 'rewards/rejected': -13.884374618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 15.381250381469727, 'logps/chosen': -233.10000610351562, 'logps/rejected': -222.8000030517578, 'logits/chosen': -8.90625, 'logits/rejected': -8.334375381469727, 'epoch': 2.86}
 95%|█████████▌| 4330/4545 [4:40:20<13:35,  3.79s/it] 95%|█████████▌| 4331/4545 [4:40:22<12:11,  3.42s/it] 95%|█████████▌| 4332/4545 [4:40:27<12:52,  3.62s/it] 95%|█████████▌| 4333/4545 [4:40:31<13:12,  3.74s/it] 95%|█████████▌| 4334/4545 [4:40:33<11:42,  3.33s/it] 95%|█████████▌| 4335/4545 [4:40:37<12:07,  3.46s/it] 95%|█████████▌| 4336/4545 [4:40:41<12:34,  3.61s/it] 95%|█████████▌| 4337/4545 [4:40:45<12:51,  3.71s/it] 95%|█████████▌| 4338/4545 [4:40:48<12:00,  3.48s/it] 95%|█████████▌| 4339/4545 [4:40:50<11:23,  3.32s/it] 95%|█████████▌| 4340/4545 [4:40:54<12:03,  3.53s/it]                                                     {'loss': 0.0992, 'grad_norm': 23.361469268798828, 'learning_rate': 1.1021866765675218e-07, 'rewards/chosen': 2.5269532203674316, 'rewards/rejected': -13.512499809265137, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 16.043750762939453, 'logps/chosen': -321.3999938964844, 'logps/rejected': -249.3000030517578, 'logits/chosen': -8.881250381469727, 'logits/rejected': -8.240625381469727, 'epoch': 2.86}
 95%|█████████▌| 4340/4545 [4:40:55<12:03,  3.53s/it] 96%|█████████▌| 4341/4545 [4:40:58<12:21,  3.64s/it] 96%|█████████▌| 4342/4545 [4:41:02<12:39,  3.74s/it] 96%|█████████▌| 4343/4545 [4:41:06<12:08,  3.60s/it] 96%|█████████▌| 4344/4545 [4:41:10<12:21,  3.69s/it] 96%|█████████▌| 4345/4545 [4:41:13<12:21,  3.71s/it] 96%|█████████▌| 4346/4545 [4:41:17<12:29,  3.77s/it] 96%|█████████▌| 4347/4545 [4:41:21<12:37,  3.83s/it] 96%|█████████▌| 4348/4545 [4:41:25<12:38,  3.85s/it] 96%|█████████▌| 4349/4545 [4:41:29<12:34,  3.85s/it] 96%|█████████▌| 4350/4545 [4:41:33<12:32,  3.86s/it]                                                     {'loss': 0.1438, 'grad_norm': 51.547576904296875, 'learning_rate': 1.0925397643547785e-07, 'rewards/chosen': 2.9730467796325684, 'rewards/rejected': -16.950000762939453, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 19.90625, 'logps/chosen': -321.6000061035156, 'logps/rejected': -246.6999969482422, 'logits/chosen': -8.762499809265137, 'logits/rejected': -8.165624618530273, 'epoch': 2.87}
 96%|█████████▌| 4350/4545 [4:41:33<12:32,  3.86s/it] 96%|█████████▌| 4351/4545 [4:41:36<12:01,  3.72s/it] 96%|█████████▌| 4352/4545 [4:41:39<11:23,  3.54s/it] 96%|█████████▌| 4353/4545 [4:41:43<11:40,  3.65s/it] 96%|█████████▌| 4354/4545 [4:41:47<12:02,  3.78s/it] 96%|█████████▌| 4355/4545 [4:41:50<10:40,  3.37s/it] 96%|█████████▌| 4356/4545 [4:41:53<10:06,  3.21s/it] 96%|█████████▌| 4357/4545 [4:41:56<10:19,  3.29s/it] 96%|█████████▌| 4358/4545 [4:41:59<10:04,  3.23s/it] 96%|█████████▌| 4359/4545 [4:42:03<10:15,  3.31s/it] 96%|█████████▌| 4360/4545 [4:42:06<10:42,  3.47s/it]                                                     {'loss': 0.0988, 'grad_norm': 3.2488269805908203, 'learning_rate': 1.083366343860416e-07, 'rewards/chosen': 1.1697266101837158, 'rewards/rejected': -11.324999809265137, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.509374618530273, 'logps/chosen': -210.8249969482422, 'logps/rejected': -216.8000030517578, 'logits/chosen': -9.015625, 'logits/rejected': -8.506250381469727, 'epoch': 2.88}
 96%|█████████▌| 4360/4545 [4:42:07<10:42,  3.47s/it] 96%|█████████▌| 4361/4545 [4:42:10<11:07,  3.63s/it] 96%|█████████▌| 4362/4545 [4:42:14<11:18,  3.71s/it] 96%|█████████▌| 4363/4545 [4:42:17<10:13,  3.37s/it] 96%|█████████▌| 4364/4545 [4:42:21<10:29,  3.48s/it] 96%|█████████▌| 4365/4545 [4:42:24<10:45,  3.58s/it] 96%|█████████▌| 4366/4545 [4:42:28<10:48,  3.62s/it] 96%|█████████▌| 4367/4545 [4:42:32<10:58,  3.70s/it] 96%|█████████▌| 4368/4545 [4:42:36<11:04,  3.75s/it] 96%|█████████▌| 4369/4545 [4:42:39<10:19,  3.52s/it] 96%|█████████▌| 4370/4545 [4:42:43<10:34,  3.63s/it]                                                     {'loss': 0.134, 'grad_norm': 80.6524429321289, 'learning_rate': 1.0746674005813887e-07, 'rewards/chosen': 2.06787109375, 'rewards/rejected': -11.990625381469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 14.0625, 'logps/chosen': -282.1000061035156, 'logps/rejected': -202.10000610351562, 'logits/chosen': -8.756250381469727, 'logits/rejected': -8.321874618530273, 'epoch': 2.88}
 96%|█████████▌| 4370/4545 [4:42:43<10:34,  3.63s/it] 96%|█████████▌| 4371/4545 [4:42:47<10:51,  3.74s/it] 96%|█████████▌| 4372/4545 [4:42:50<10:40,  3.70s/it] 96%|█████████▌| 4373/4545 [4:42:55<11:00,  3.84s/it] 96%|█████████▌| 4374/4545 [4:42:58<10:49,  3.80s/it] 96%|█████████▋| 4375/4545 [4:43:02<10:49,  3.82s/it] 96%|█████████▋| 4376/4545 [4:43:06<10:34,  3.75s/it] 96%|█████████▋| 4377/4545 [4:43:10<10:43,  3.83s/it] 96%|█████████▋| 4378/4545 [4:43:14<10:42,  3.85s/it] 96%|█████████▋| 4379/4545 [4:43:18<10:39,  3.85s/it] 96%|█████████▋| 4380/4545 [4:43:20<09:30,  3.46s/it]                                                     {'loss': 0.0612, 'grad_norm': 16.38957405090332, 'learning_rate': 1.066443869041748e-07, 'rewards/chosen': 2.660595655441284, 'rewards/rejected': -13.556249618530273, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 16.225000381469727, 'logps/chosen': -311.8500061035156, 'logps/rejected': -251.10000610351562, 'logits/chosen': -8.725000381469727, 'logits/rejected': -8.287500381469727, 'epoch': 2.89}
 96%|█████████▋| 4380/4545 [4:43:20<09:30,  3.46s/it] 96%|█████████▋| 4381/4545 [4:43:24<09:42,  3.55s/it] 96%|█████████▋| 4382/4545 [4:43:28<09:55,  3.65s/it] 96%|█████████▋| 4383/4545 [4:43:32<10:03,  3.72s/it] 96%|█████████▋| 4384/4545 [4:43:36<10:23,  3.87s/it] 96%|█████████▋| 4385/4545 [4:43:40<10:19,  3.87s/it] 97%|█████████▋| 4386/4545 [4:43:44<10:21,  3.91s/it] 97%|█████████▋| 4387/4545 [4:43:48<10:16,  3.90s/it] 97%|█████████▋| 4388/4545 [4:43:51<09:58,  3.81s/it] 97%|█████████▋| 4389/4545 [4:43:55<09:36,  3.70s/it] 97%|█████████▋| 4390/4545 [4:43:59<09:41,  3.75s/it]                                                     {'loss': 0.0603, 'grad_norm': 3.044755697250366, 'learning_rate': 1.0586966326922516e-07, 'rewards/chosen': 4.640380859375, 'rewards/rejected': -14.3828125, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 19.049999237060547, 'logps/chosen': -392.95001220703125, 'logps/rejected': -248.0500030517578, 'logits/chosen': -8.756250381469727, 'logits/rejected': -8.199999809265137, 'epoch': 2.9}
 97%|█████████▋| 4390/4545 [4:43:59<09:41,  3.75s/it] 97%|█████████▋| 4391/4545 [4:44:01<09:02,  3.52s/it] 97%|█████████▋| 4392/4545 [4:44:05<09:04,  3.56s/it] 97%|█████████▋| 4393/4545 [4:44:09<09:18,  3.68s/it] 97%|█████████▋| 4394/4545 [4:44:13<09:25,  3.74s/it] 97%|█████████▋| 4395/4545 [4:44:16<08:43,  3.49s/it] 97%|█████████▋| 4396/4545 [4:44:20<09:12,  3.71s/it] 97%|█████████▋| 4397/4545 [4:44:24<09:17,  3.77s/it] 97%|█████████▋| 4398/4545 [4:44:27<08:55,  3.64s/it] 97%|█████████▋| 4399/4545 [4:44:31<09:00,  3.70s/it] 97%|█████████▋| 4400/4545 [4:44:35<09:00,  3.73s/it]                                                     {'loss': 0.0393, 'grad_norm': 8.4496488571167, 'learning_rate': 1.051426523815451e-07, 'rewards/chosen': 1.218359351158142, 'rewards/rejected': -14.193750381469727, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 15.399999618530273, 'logps/chosen': -236.5, 'logps/rejected': -195.60000610351562, 'logits/chosen': -8.815625190734863, 'logits/rejected': -8.181249618530273, 'epoch': 2.9}
 97%|█████████▋| 4400/4545 [4:44:35<09:00,  3.73s/it] 97%|█████████▋| 4401/4545 [4:44:39<09:00,  3.75s/it] 97%|█████████▋| 4402/4545 [4:44:43<09:04,  3.81s/it] 97%|█████████▋| 4403/4545 [4:44:47<09:14,  3.91s/it] 97%|█████████▋| 4404/4545 [4:44:50<08:20,  3.55s/it] 97%|█████████▋| 4405/4545 [4:44:53<08:26,  3.62s/it] 97%|█████████▋| 4406/4545 [4:44:57<08:34,  3.70s/it] 97%|█████████▋| 4407/4545 [4:45:01<08:33,  3.72s/it] 97%|█████████▋| 4408/4545 [4:45:05<08:34,  3.76s/it] 97%|█████████▋| 4409/4545 [4:45:09<08:35,  3.79s/it] 97%|█████████▋| 4410/4545 [4:45:13<08:49,  3.92s/it]                                                     {'loss': 0.0713, 'grad_norm': 2.719337224960327, 'learning_rate': 1.0446343234362801e-07, 'rewards/chosen': 1.9363281726837158, 'rewards/rejected': -14.515625, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 16.456249237060547, 'logps/chosen': -301.79998779296875, 'logps/rejected': -212.5500030517578, 'logits/chosen': -8.662500381469727, 'logits/rejected': -8.25, 'epoch': 2.91}
 97%|█████████▋| 4410/4545 [4:45:13<08:49,  3.92s/it] 97%|█████████▋| 4411/4545 [4:45:16<08:29,  3.80s/it] 97%|█████████▋| 4412/4545 [4:45:19<07:44,  3.49s/it] 97%|█████████▋| 4413/4545 [4:45:22<07:20,  3.33s/it] 97%|█████████▋| 4414/4545 [4:45:26<07:39,  3.51s/it] 97%|█████████▋| 4415/4545 [4:45:30<07:53,  3.64s/it] 97%|█████████▋| 4416/4545 [4:45:33<07:28,  3.48s/it] 97%|█████████▋| 4417/4545 [4:45:37<07:29,  3.51s/it] 97%|█████████▋| 4418/4545 [4:45:41<07:38,  3.61s/it] 97%|█████████▋| 4419/4545 [4:45:45<07:46,  3.70s/it] 97%|█████████▋| 4420/4545 [4:45:48<07:50,  3.76s/it]                                                     {'loss': 0.0473, 'grad_norm': 5.642820835113525, 'learning_rate': 1.0383207612381542e-07, 'rewards/chosen': 2.31689453125, 'rewards/rejected': -15.181249618530273, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 17.493749618530273, 'logps/chosen': -279.3999938964844, 'logps/rejected': -192.35000610351562, 'logits/chosen': -8.737500190734863, 'logits/rejected': -8.168749809265137, 'epoch': 2.92}
 97%|█████████▋| 4420/4545 [4:45:49<07:50,  3.76s/it] 97%|█████████▋| 4421/4545 [4:45:53<08:01,  3.89s/it] 97%|█████████▋| 4422/4545 [4:45:56<07:56,  3.88s/it] 97%|█████████▋| 4423/4545 [4:45:59<07:05,  3.49s/it] 97%|█████████▋| 4424/4545 [4:46:03<07:21,  3.65s/it] 97%|█████████▋| 4425/4545 [4:46:07<07:26,  3.72s/it] 97%|█████████▋| 4426/4545 [4:46:11<07:28,  3.77s/it] 97%|█████████▋| 4427/4545 [4:46:15<07:29,  3.81s/it] 97%|█████████▋| 4428/4545 [4:46:18<06:53,  3.53s/it] 97%|█████████▋| 4429/4545 [4:46:22<07:12,  3.73s/it] 97%|█████████▋| 4430/4545 [4:46:26<07:09,  3.74s/it]                                                     {'loss': 0.1378, 'grad_norm': 38.71597671508789, 'learning_rate': 1.0324865154845744e-07, 'rewards/chosen': 3.314990282058716, 'rewards/rejected': -15.140625, 'rewards/accuracies': 0.9375, 'rewards/margins': 18.459375381469727, 'logps/chosen': -371.0, 'logps/rejected': -293.1499938964844, 'logits/chosen': -8.534375190734863, 'logits/rejected': -8.246874809265137, 'epoch': 2.92}
 97%|█████████▋| 4430/4545 [4:46:26<07:09,  3.74s/it] 97%|█████████▋| 4431/4545 [4:46:30<07:13,  3.80s/it] 98%|█████████▊| 4432/4545 [4:46:33<07:11,  3.82s/it] 98%|█████████▊| 4433/4545 [4:46:37<07:11,  3.85s/it] 98%|█████████▊| 4434/4545 [4:46:41<07:08,  3.86s/it] 98%|█████████▊| 4435/4545 [4:46:45<07:05,  3.87s/it] 98%|█████████▊| 4436/4545 [4:46:49<07:02,  3.88s/it] 98%|█████████▊| 4437/4545 [4:46:53<07:04,  3.93s/it] 98%|█████████▊| 4438/4545 [4:46:57<07:03,  3.96s/it] 98%|█████████▊| 4439/4545 [4:47:01<06:59,  3.96s/it] 98%|█████████▊| 4440/4545 [4:47:05<07:02,  4.02s/it]                                                     {'loss': 0.0598, 'grad_norm': 9.245841026306152, 'learning_rate': 1.0271322129462656e-07, 'rewards/chosen': 4.662621974945068, 'rewards/rejected': -12.059374809265137, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 16.71875, 'logps/chosen': -406.75, 'logps/rejected': -330.79998779296875, 'logits/chosen': -8.512499809265137, 'logits/rejected': -8.15625, 'epoch': 2.93}
 98%|█████████▊| 4440/4545 [4:47:05<07:02,  4.02s/it] 98%|█████████▊| 4441/4545 [4:47:09<06:47,  3.92s/it] 98%|█████████▊| 4442/4545 [4:47:13<06:37,  3.86s/it] 98%|█████████▊| 4443/4545 [4:47:16<06:22,  3.75s/it] 98%|█████████▊| 4444/4545 [4:47:20<06:29,  3.85s/it] 98%|█████████▊| 4445/4545 [4:47:24<06:26,  3.86s/it] 98%|█████████▊| 4446/4545 [4:47:28<06:25,  3.89s/it] 98%|█████████▊| 4447/4545 [4:47:31<05:44,  3.52s/it] 98%|█████████▊| 4448/4545 [4:47:35<05:52,  3.63s/it] 98%|█████████▊| 4449/4545 [4:47:38<05:39,  3.54s/it] 98%|█████████▊| 4450/4545 [4:47:42<05:45,  3.64s/it]                                                     {'loss': 0.1447, 'grad_norm': 31.907608032226562, 'learning_rate': 1.0222584288338423e-07, 'rewards/chosen': 1.057226538658142, 'rewards/rejected': -14.196874618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 15.253125190734863, 'logps/chosen': -232.64999389648438, 'logps/rejected': -192.75, 'logits/chosen': -8.993749618530273, 'logits/rejected': -8.40625, 'epoch': 2.94}
 98%|█████████▊| 4450/4545 [4:47:42<05:45,  3.64s/it] 98%|█████████▊| 4451/4545 [4:47:46<05:57,  3.80s/it] 98%|█████████▊| 4452/4545 [4:47:49<05:26,  3.52s/it] 98%|█████████▊| 4453/4545 [4:47:53<05:33,  3.63s/it] 98%|█████████▊| 4454/4545 [4:47:57<05:37,  3.70s/it] 98%|█████████▊| 4455/4545 [4:48:00<05:38,  3.76s/it] 98%|█████████▊| 4456/4545 [4:48:04<05:39,  3.82s/it] 98%|█████████▊| 4457/4545 [4:48:08<05:25,  3.70s/it] 98%|█████████▊| 4458/4545 [4:48:12<05:35,  3.86s/it] 98%|█████████▊| 4459/4545 [4:48:16<05:32,  3.87s/it] 98%|█████████▊| 4460/4545 [4:48:20<05:28,  3.86s/it]                                                     {'loss': 0.122, 'grad_norm': 30.034914016723633, 'learning_rate': 1.0178656867360131e-07, 'rewards/chosen': 3.581249952316284, 'rewards/rejected': -13.215624809265137, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 16.803125381469727, 'logps/chosen': -337.25, 'logps/rejected': -273.29998779296875, 'logits/chosen': -8.90625, 'logits/rejected': -8.274999618530273, 'epoch': 2.94}
 98%|█████████▊| 4460/4545 [4:48:20<05:28,  3.86s/it] 98%|█████████▊| 4461/4545 [4:48:24<05:27,  3.89s/it] 98%|█████████▊| 4462/4545 [4:48:28<05:23,  3.90s/it] 98%|█████████▊| 4463/4545 [4:48:32<05:26,  3.98s/it] 98%|█████████▊| 4464/4545 [4:48:35<05:06,  3.78s/it] 98%|█████████▊| 4465/4545 [4:48:39<04:54,  3.68s/it] 98%|█████████▊| 4466/4545 [4:48:42<04:52,  3.70s/it] 98%|█████████▊| 4467/4545 [4:48:46<04:44,  3.65s/it] 98%|█████████▊| 4468/4545 [4:48:50<04:49,  3.77s/it] 98%|█████████▊| 4469/4545 [4:48:54<04:48,  3.80s/it] 98%|█████████▊| 4470/4545 [4:48:58<04:46,  3.83s/it]                                                     {'loss': 0.0553, 'grad_norm': 11.075420379638672, 'learning_rate': 1.0139544585633334e-07, 'rewards/chosen': 2.6156249046325684, 'rewards/rejected': -18.509374618530273, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 21.131250381469727, 'logps/chosen': -344.1000061035156, 'logps/rejected': -255.60000610351562, 'logits/chosen': -8.712499618530273, 'logits/rejected': -8.193750381469727, 'epoch': 2.95}
 98%|█████████▊| 4470/4545 [4:48:58<04:46,  3.83s/it] 98%|█████████▊| 4471/4545 [4:49:02<04:45,  3.85s/it] 98%|█████████▊| 4472/4545 [4:49:05<04:40,  3.85s/it] 98%|█████████▊| 4473/4545 [4:49:09<04:21,  3.63s/it] 98%|█████████▊| 4474/4545 [4:49:12<04:23,  3.71s/it] 98%|█████████▊| 4475/4545 [4:49:16<04:22,  3.75s/it] 98%|█████████▊| 4476/4545 [4:49:19<03:57,  3.45s/it] 99%|█████████▊| 4477/4545 [4:49:22<03:42,  3.27s/it] 99%|█████████▊| 4478/4545 [4:49:26<03:48,  3.40s/it] 99%|█████████▊| 4479/4545 [4:49:30<03:56,  3.59s/it] 99%|█████████▊| 4480/4545 [4:49:33<03:40,  3.39s/it]                                                     {'loss': 0.1798, 'grad_norm': 30.44175148010254, 'learning_rate': 1.0105251644975056e-07, 'rewards/chosen': 2.189453125, 'rewards/rejected': -13.046875, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 15.25, 'logps/chosen': -274.8500061035156, 'logps/rejected': -259.04998779296875, 'logits/chosen': -8.634374618530273, 'logits/rejected': -8.065625190734863, 'epoch': 2.96}
 99%|█████████▊| 4480/4545 [4:49:33<03:40,  3.39s/it] 99%|█████████▊| 4481/4545 [4:49:36<03:46,  3.54s/it] 99%|█████████▊| 4482/4545 [4:49:40<03:49,  3.64s/it] 99%|█████████▊| 4483/4545 [4:49:44<03:49,  3.71s/it] 99%|█████████▊| 4484/4545 [4:49:48<03:48,  3.75s/it] 99%|█████████▊| 4485/4545 [4:49:52<03:46,  3.78s/it] 99%|█████████▊| 4486/4545 [4:49:56<03:48,  3.87s/it] 99%|█████████▊| 4487/4545 [4:49:59<03:33,  3.69s/it] 99%|█████████▊| 4488/4545 [4:50:03<03:38,  3.84s/it] 99%|█████████▉| 4489/4545 [4:50:07<03:26,  3.69s/it] 99%|█████████▉| 4490/4545 [4:50:11<03:29,  3.81s/it]                                                     {'loss': 0.0769, 'grad_norm': 6.7961106300354, 'learning_rate': 1.0075781729462414e-07, 'rewards/chosen': 2.3828125, 'rewards/rejected': -14.318750381469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.706249237060547, 'logps/chosen': -323.125, 'logps/rejected': -229.9499969482422, 'logits/chosen': -8.675000190734863, 'logits/rejected': -7.915625095367432, 'epoch': 2.96}
 99%|█████████▉| 4490/4545 [4:50:11<03:29,  3.81s/it] 99%|█████████▉| 4491/4545 [4:50:15<03:27,  3.84s/it] 99%|█████████▉| 4492/4545 [4:50:18<03:06,  3.52s/it] 99%|█████████▉| 4493/4545 [4:50:21<03:05,  3.57s/it] 99%|█████████▉| 4494/4545 [4:50:24<02:50,  3.34s/it] 99%|█████████▉| 4495/4545 [4:50:28<02:55,  3.52s/it] 99%|█████████▉| 4496/4545 [4:50:32<02:53,  3.54s/it] 99%|█████████▉| 4497/4545 [4:50:35<02:54,  3.64s/it] 99%|█████████▉| 4498/4545 [4:50:39<02:55,  3.74s/it] 99%|█████████▉| 4499/4545 [4:50:43<02:54,  3.78s/it] 99%|█████████▉| 4500/4545 [4:50:46<02:42,  3.60s/it]                                                     {'loss': 0.0682, 'grad_norm': 14.9230375289917, 'learning_rate': 1.0051138005036842e-07, 'rewards/chosen': 2.7376952171325684, 'rewards/rejected': -16.359375, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 19.09375, 'logps/chosen': -343.3999938964844, 'logps/rejected': -219.10000610351562, 'logits/chosen': -8.606249809265137, 'logits/rejected': -8.175000190734863, 'epoch': 2.97}
 99%|█████████▉| 4500/4545 [4:50:47<02:42,  3.60s/it] 99%|█████████▉| 4501/4545 [4:50:50<02:32,  3.47s/it] 99%|█████████▉| 4502/4545 [4:50:53<02:23,  3.33s/it] 99%|█████████▉| 4503/4545 [4:50:56<02:16,  3.25s/it] 99%|█████████▉| 4504/4545 [4:50:59<02:19,  3.40s/it] 99%|█████████▉| 4505/4545 [4:51:03<02:21,  3.54s/it] 99%|█████████▉| 4506/4545 [4:51:06<02:09,  3.33s/it] 99%|█████████▉| 4507/4545 [4:51:10<02:13,  3.52s/it] 99%|█████████▉| 4508/4545 [4:51:14<02:14,  3.63s/it] 99%|█████████▉| 4509/4545 [4:51:18<02:14,  3.74s/it] 99%|█████████▉| 4510/4545 [4:51:22<02:13,  3.81s/it]                                                     {'loss': 0.0749, 'grad_norm': 8.653276443481445, 'learning_rate': 1.0031323119163944e-07, 'rewards/chosen': 2.4361329078674316, 'rewards/rejected': -13.485937118530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 15.912500381469727, 'logps/chosen': -302.95001220703125, 'logps/rejected': -210.64999389648438, 'logits/chosen': -8.71875, 'logits/rejected': -8.262499809265137, 'epoch': 2.98}
 99%|█████████▉| 4510/4545 [4:51:22<02:13,  3.81s/it] 99%|█████████▉| 4511/4545 [4:51:26<02:14,  3.94s/it] 99%|█████████▉| 4512/4545 [4:51:30<02:09,  3.91s/it] 99%|█████████▉| 4513/4545 [4:51:34<02:05,  3.91s/it] 99%|█████████▉| 4514/4545 [4:51:37<01:56,  3.75s/it] 99%|█████████▉| 4515/4545 [4:51:41<01:56,  3.87s/it] 99%|█████████▉| 4516/4545 [4:51:45<01:52,  3.89s/it] 99%|█████████▉| 4517/4545 [4:51:48<01:39,  3.56s/it] 99%|█████████▉| 4518/4545 [4:51:51<01:33,  3.45s/it] 99%|█████████▉| 4519/4545 [4:51:55<01:34,  3.62s/it] 99%|█████████▉| 4520/4545 [4:51:58<01:25,  3.44s/it]                                                     {'loss': 0.0978, 'grad_norm': 15.1165771484375, 'learning_rate': 1.001633920054912e-07, 'rewards/chosen': 1.421875, 'rewards/rejected': -12.462499618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.875, 'logps/chosen': -250.39999389648438, 'logps/rejected': -235.8000030517578, 'logits/chosen': -8.918749809265137, 'logits/rejected': -8.34375, 'epoch': 2.98}
 99%|█████████▉| 4520/4545 [4:51:59<01:25,  3.44s/it] 99%|█████████▉| 4521/4545 [4:52:01<01:19,  3.32s/it] 99%|█████████▉| 4522/4545 [4:52:05<01:21,  3.53s/it]100%|█████████▉| 4523/4545 [4:52:09<01:16,  3.46s/it]100%|█████████▉| 4524/4545 [4:52:13<01:17,  3.69s/it]100%|█████████▉| 4525/4545 [4:52:17<01:15,  3.75s/it]100%|█████████▉| 4526/4545 [4:52:21<01:11,  3.79s/it]100%|█████████▉| 4527/4545 [4:52:25<01:08,  3.79s/it]100%|█████████▉| 4528/4545 [4:52:29<01:05,  3.88s/it]100%|█████████▉| 4529/4545 [4:52:33<01:02,  3.88s/it]100%|█████████▉| 4530/4545 [4:52:36<00:58,  3.88s/it]                                                     {'loss': 0.141, 'grad_norm': 64.78083801269531, 'learning_rate': 1.0006187858908838e-07, 'rewards/chosen': 2.6156249046325684, 'rewards/rejected': -15.071874618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 17.674999237060547, 'logps/chosen': -325.8999938964844, 'logps/rejected': -230.1999969482422, 'logits/chosen': -8.831250190734863, 'logits/rejected': -8.178125381469727, 'epoch': 2.99}
100%|█████████▉| 4530/4545 [4:52:36<00:58,  3.88s/it]100%|█████████▉| 4531/4545 [4:52:40<00:54,  3.90s/it]100%|█████████▉| 4532/4545 [4:52:44<00:51,  3.92s/it]100%|█████████▉| 4533/4545 [4:52:48<00:46,  3.90s/it]100%|█████████▉| 4534/4545 [4:52:52<00:42,  3.90s/it]100%|█████████▉| 4535/4545 [4:52:56<00:38,  3.89s/it]100%|█████████▉| 4536/4545 [4:53:00<00:35,  3.97s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:43,  1.35it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.09s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.47s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:13<01:21,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:19,  1.66s/it][A
 22%|██▏       | 13/60 [00:19<01:17,  1.65s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.64s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.53s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.39s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.11s/it][A
 42%|████▏     | 25/60 [00:33<00:44,  1.27s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.32s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.16s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.09s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:05<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.39s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.4115230441093445, 'eval_runtime': 80.7049, 'eval_samples_per_second': 11.808, 'eval_steps_per_second': 0.743, 'eval_rewards/chosen': 2.5486531257629395, 'eval_rewards/rejected': -11.986897468566895, 'eval_rewards/accuracies': 0.8394676446914673, 'eval_rewards/margins': 14.536653518676758, 'eval_logps/chosen': -365.1166687011719, 'eval_logps/rejected': -211.92916870117188, 'eval_logits/chosen': -8.492708206176758, 'eval_logits/rejected': -8.613541603088379, 'epoch': 2.99}
100%|█████████▉| 4536/4545 [4:54:21<00:35,  3.97s/it]
100%|██████████| 60/60 [01:19<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 4537/4545 [4:54:37<04:14, 31.79s/it]100%|█████████▉| 4538/4545 [4:54:41<02:44, 23.49s/it]100%|█████████▉| 4539/4545 [4:54:45<01:45, 17.60s/it]100%|█████████▉| 4540/4545 [4:54:49<01:07, 13.58s/it]                                                     {'loss': 0.0466, 'grad_norm': 7.410425186157227, 'learning_rate': 1.000087018479775e-07, 'rewards/chosen': 1.2332031726837158, 'rewards/rejected': -14.956250190734863, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 16.1875, 'logps/chosen': -228.9499969482422, 'logps/rejected': -221.1999969482422, 'logits/chosen': -8.856249809265137, 'logits/rejected': -8.193750381469727, 'epoch': 3.0}
100%|█████████▉| 4540/4545 [4:54:49<01:07, 13.58s/it]100%|█████████▉| 4541/4545 [4:54:53<00:42, 10.67s/it]100%|█████████▉| 4542/4545 [4:54:57<00:26,  8.73s/it]100%|█████████▉| 4543/4545 [4:55:01<00:14,  7.28s/it]100%|█████████▉| 4544/4545 [4:55:05<00:06,  6.26s/it]100%|██████████| 4545/4545 [4:55:08<00:00,  5.37s/it]                                                     {'train_runtime': 17734.9824, 'train_samples_per_second': 4.098, 'train_steps_per_second': 0.256, 'train_loss': 0.22741530490721545, 'epoch': 3.0}
100%|██████████| 4545/4545 [4:55:28<00:00,  5.37s/it]100%|██████████| 4545/4545 [4:55:28<00:00,  3.90s/it]
Training complete
Saving model
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mDPO_r-64_lr-1e-06_e-3_b-0.2_63026307[0m at: [34mhttps://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/9zh88oos[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250611_190735-9zh88oos/logs[0m
[rank0]:[W612 00:03:39.484170307 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 0 ---
