cpu-bind=MASK - gn05, task  0  0 [2448382]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 4
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn05
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 4     --machine_rank 0     --main_process_ip gn05     --main_process_port 29500     --num_processes 16     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62717633     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=4e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-06-07 19:21:25,129] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0607 19:21:27.063000 2448431 torch/distributed/run.py:792] 
W0607 19:21:27.063000 2448431 torch/distributed/run.py:792] *****************************************
W0607 19:21:27.063000 2448431 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0607 19:21:27.063000 2448431 torch/distributed/run.py:792] *****************************************
[2025-06-07 19:21:32,406] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-07 19:21:32,437] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-07 19:21:32,454] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-07 19:21:32,464] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Training data of type 'bad_lang_examples':    Training data of type 'bad_lang_examples':    Training data of type 'bad_lang_examples':    Training data of type 'bad_lang_examples':    5343
5343
5343
5343
Training data of type 'short_examples':       Training data of type 'short_examples':       Training data of type 'short_examples':       Training data of type 'short_examples':       699
699
699
699
Training data of type 'choose_examples':      Training data of type 'choose_examples':      Training data of type 'choose_examples':      Training data of type 'choose_examples':      13379
13379
13379
13379
Training data of type 'bad_format_examples':  Training data of type 'bad_format_examples':  Training data of type 'bad_format_examples':  Training data of type 'bad_format_examples':  4806
4806
4806
4806
Created datasets
Created datasets
Created datasets
Number of training examples: Number of training examples: Number of training examples: 24227
2422724227
Number of validation examples: Created datasets

Number of validation examples:Number of validation examples: 953
Number of training examples:  953953
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
24227

Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
4e-07
Number of validation examples: Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
4e-07
953
4e-07
World size: Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
16
4e-07
Setting gradient accumulation steps to: 1
[2025-06-07 19:21:40,906] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-07 19:21:41,101] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-07 19:21:41,317] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Train dataset size: 24227
Validation dataset size: 953
Steps per epoch: 1514
Evaluate each 504 steps
[2025-06-07 19:21:42,133] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-07 19:21:42,169] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.60s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:21, 27.21s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:21, 27.22s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:21, 27.18s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.74s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.85s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.84s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.85s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:24<00:28, 28.65s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:25<00:28, 28.68s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:25<00:28, 28.68s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:25<00:28, 28.68s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:45<00:00, 25.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:45<00:00, 26.38s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:45<00:00, 25.47s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:45<00:00, 25.47s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:45<00:00, 25.47s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:45<00:00, 26.43s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:45<00:00, 26.44s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:45<00:00, 26.44s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loaded model
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78MUsing LoRA and set up the model
Total Parameters: 9457.78M

Trainable Parameters (LoRA): 216.07MTotal Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M

Percentage of Trainable Params: 2.2846%Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%

Percentage of Trainable Params: 2.2846%
[rank1]:[W607 19:23:32.316228842 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W607 19:23:32.356228912 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
[rank2]:[W607 19:23:32.402192697 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 526/24227 [00:00<00:04, 5224.26 examples/s]Extracting prompt in train dataset:   5%|▌         | 1238/24227 [00:00<00:04, 4887.64 examples/s]Extracting prompt in train dataset:   7%|▋         | 1780/24227 [00:01<00:16, 1360.55 examples/s]Extracting prompt in train dataset:   9%|▉         | 2280/24227 [00:01<00:11, 1831.06 examples/s]Extracting prompt in train dataset:  12%|█▏        | 2801/24227 [00:01<00:09, 2359.93 examples/s]Extracting prompt in train dataset:  14%|█▎        | 3290/24227 [00:01<00:07, 2815.50 examples/s]Extracting prompt in train dataset:  16%|█▌        | 3870/24227 [00:01<00:06, 3035.57 examples/s]Extracting prompt in train dataset:  18%|█▊        | 4290/24227 [00:01<00:06, 3269.45 examples/s]Extracting prompt in train dataset:  20%|█▉        | 4740/24227 [00:01<00:05, 3534.79 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5317/24227 [00:01<00:05, 3520.90 examples/s]Extracting prompt in train dataset:  25%|██▍       | 5984/24227 [00:02<00:04, 3803.29 examples/s]Extracting prompt in train dataset:  27%|██▋       | 6471/24227 [00:02<00:04, 4040.97 examples/s]Extracting prompt in train dataset:  29%|██▉       | 6990/24227 [00:02<00:03, 4310.24 examples/s]Extracting prompt in train dataset:  31%|███       | 7540/24227 [00:02<00:03, 4608.99 examples/s]Extracting prompt in train dataset:  33%|███▎      | 8090/24227 [00:02<00:03, 4835.87 examples/s]Extracting prompt in train dataset:  36%|███▋      | 8790/24227 [00:02<00:03, 4766.59 examples/s]Extracting prompt in train dataset:  38%|███▊      | 9326/24227 [00:02<00:03, 4918.13 examples/s]Extracting prompt in train dataset:  41%|████      | 9901/24227 [00:02<00:03, 3996.29 examples/s]Extracting prompt in train dataset:  43%|████▎     | 10490/24227 [00:03<00:03, 3964.66 examples/s]Extracting prompt in train dataset:  46%|████▌     | 11050/24227 [00:03<00:03, 4329.89 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11750/24227 [00:03<00:02, 4438.38 examples/s]Extracting prompt in train dataset:  51%|█████     | 12350/24227 [00:03<00:02, 4175.11 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12840/24227 [00:03<00:02, 4331.53 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 13310/24227 [00:03<00:02, 4415.86 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13840/24227 [00:03<00:02, 4627.22 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 14410/24227 [00:03<00:02, 4905.06 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 15090/24227 [00:04<00:01, 4635.57 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 15615/24227 [00:04<00:01, 4789.76 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 16149/24227 [00:04<00:01, 4934.54 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 16880/24227 [00:04<00:01, 4905.63 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17600/24227 [00:04<00:01, 4848.58 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 18140/24227 [00:04<00:01, 4964.86 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18670/24227 [00:04<00:01, 5037.06 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 19240/24227 [00:04<00:00, 5204.04 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19815/24227 [00:04<00:00, 5341.13 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 20440/24227 [00:05<00:00, 4886.77 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 20987/24227 [00:05<00:00, 5034.73 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21555/24227 [00:05<00:00, 5202.49 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22349/24227 [00:05<00:00, 5230.56 examples/s]Extracting prompt in train dataset:  95%|█████████▌| 23080/24227 [00:05<00:00, 5085.20 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 23770/24227 [00:05<00:00, 4916.92 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:05<00:00, 4107.29 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 287/24227 [00:00<00:08, 2840.60 examples/s]Applying chat template to train dataset:   2%|▏         | 581/24227 [00:00<00:08, 2894.21 examples/s]Applying chat template to train dataset:   4%|▍         | 1030/24227 [00:00<00:07, 2937.81 examples/s]Applying chat template to train dataset:   6%|▌         | 1337/24227 [00:00<00:07, 2983.06 examples/s]Applying chat template to train dataset:   7%|▋         | 1751/24227 [00:00<00:07, 2883.42 examples/s]Applying chat template to train dataset:   8%|▊         | 2041/24227 [00:00<00:07, 2882.71 examples/s]Applying chat template to train dataset:  10%|█         | 2492/24227 [00:00<00:07, 2928.62 examples/s]Applying chat template to train dataset:  12%|█▏        | 2804/24227 [00:00<00:07, 2976.94 examples/s]Applying chat template to train dataset:  13%|█▎        | 3212/24227 [00:01<00:07, 2880.61 examples/s]Applying chat template to train dataset:  15%|█▍        | 3562/24227 [00:01<00:07, 2691.85 examples/s]Applying chat template to train dataset:  16%|█▌        | 3860/24227 [00:01<00:07, 2759.64 examples/s]Applying chat template to train dataset:  17%|█▋        | 4155/24227 [00:01<00:07, 2807.64 examples/s]Applying chat template to train dataset:  19%|█▉        | 4573/24227 [00:01<00:07, 2798.80 examples/s]Applying chat template to train dataset:  21%|██        | 5010/24227 [00:01<00:06, 2833.41 examples/s]Applying chat template to train dataset:  22%|██▏       | 5430/24227 [00:01<00:06, 2818.01 examples/s]Applying chat template to train dataset:  24%|██▍       | 5820/24227 [00:02<00:06, 2743.81 examples/s]Applying chat template to train dataset:  25%|██▌       | 6100/24227 [00:02<00:06, 2750.60 examples/s]Applying chat template to train dataset:  26%|██▋       | 6410/24227 [00:02<00:06, 2835.16 examples/s]Applying chat template to train dataset:  28%|██▊       | 6766/24227 [00:02<00:06, 2672.62 examples/s]Applying chat template to train dataset:  29%|██▉       | 7130/24227 [00:02<00:06, 2588.56 examples/s]Applying chat template to train dataset:  31%|███       | 7434/24227 [00:02<00:06, 2695.13 examples/s]Applying chat template to train dataset:  32%|███▏      | 7746/24227 [00:02<00:05, 2801.98 examples/s]Applying chat template to train dataset:  33%|███▎      | 8069/24227 [00:02<00:05, 2911.19 examples/s]Applying chat template to train dataset:  35%|███▍      | 8451/24227 [00:03<00:05, 2776.21 examples/s]Applying chat template to train dataset:  37%|███▋      | 8888/24227 [00:03<00:05, 2820.50 examples/s]Applying chat template to train dataset:  38%|███▊      | 9175/24227 [00:03<00:05, 2830.85 examples/s]Applying chat template to train dataset:  40%|███▉      | 9610/24227 [00:03<00:05, 2849.01 examples/s]Applying chat template to train dataset:  41%|████      | 9906/24227 [00:03<00:04, 2874.95 examples/s]Applying chat template to train dataset:  42%|████▏     | 10210/24227 [00:03<00:04, 2915.79 examples/s]Applying chat template to train dataset:  43%|████▎     | 10512/24227 [00:03<00:04, 2940.39 examples/s]Applying chat template to train dataset:  45%|████▌     | 10937/24227 [00:03<00:04, 2896.67 examples/s]Applying chat template to train dataset:  47%|████▋     | 11324/24227 [00:04<00:04, 2783.62 examples/s]Applying chat template to train dataset:  48%|████▊     | 11615/24227 [00:04<00:04, 2812.85 examples/s]Applying chat template to train dataset:  49%|████▉     | 11919/24227 [00:04<00:04, 2869.97 examples/s]Applying chat template to train dataset:  51%|█████     | 12330/24227 [00:04<00:04, 2820.82 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12640/24227 [00:04<00:04, 2888.90 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12953/24227 [00:04<00:03, 2952.01 examples/s]Applying chat template to train dataset:  55%|█████▍    | 13270/24227 [00:04<00:03, 3009.62 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13737/24227 [00:04<00:03, 3044.81 examples/s]Applying chat template to train dataset:  59%|█████▊    | 14210/24227 [00:04<00:03, 3075.89 examples/s]Applying chat template to train dataset:  60%|██████    | 14657/24227 [00:05<00:03, 3037.23 examples/s]Applying chat template to train dataset:  62%|██████▏   | 14969/24227 [00:05<00:03, 3054.38 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15279/24227 [00:05<00:03, 2689.59 examples/s]Applying chat template to train dataset:  64%|██████▍   | 15555/24227 [00:05<00:03, 2704.97 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15983/24227 [00:05<00:02, 2751.88 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16415/24227 [00:05<00:02, 2792.57 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16743/24227 [00:05<00:03, 2487.38 examples/s]Applying chat template to train dataset:  70%|███████   | 17050/24227 [00:06<00:02, 2615.24 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17359/24227 [00:06<00:02, 2729.43 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17670/24227 [00:06<00:02, 2822.79 examples/s]Applying chat template to train dataset:  75%|███████▍  | 18121/24227 [00:06<00:02, 2883.48 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18550/24227 [00:06<00:01, 2873.03 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18969/24227 [00:06<00:01, 2845.01 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19282/24227 [00:06<00:01, 2910.03 examples/s]Applying chat template to train dataset:  81%|████████  | 19600/24227 [00:06<00:01, 2975.85 examples/s]Applying chat template to train dataset:  83%|████████▎ | 19988/24227 [00:07<00:01, 2836.56 examples/s]Applying chat template to train dataset:  84%|████████▍ | 20420/24227 [00:07<00:01, 2846.19 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20845/24227 [00:07<00:01, 2838.29 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21150/24227 [00:07<00:01, 2883.30 examples/s]Applying chat template to train dataset:  89%|████████▊ | 21460/24227 [00:07<00:00, 2935.71 examples/s]Applying chat template to train dataset:  90%|█████████ | 21878/24227 [00:07<00:00, 2881.84 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22337/24227 [00:07<00:00, 2937.71 examples/s]Applying chat template to train dataset:  94%|█████████▍| 22780/24227 [00:08<00:00, 2939.13 examples/s]Applying chat template to train dataset:  95%|█████████▌| 23105/24227 [00:08<00:00, 3008.85 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23551/24227 [00:08<00:00, 2991.50 examples/s]Applying chat template to train dataset:  99%|█████████▉| 23945/24227 [00:08<00:00, 2871.24 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:08<00:00, 2844.34 examples/s]
Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/24227 [00:00<01:01, 393.97 examples/s]Tokenizing train dataset:   0%|          | 88/24227 [00:00<01:13, 330.26 examples/s]Tokenizing train dataset:   1%|          | 129/24227 [00:00<01:21, 297.27 examples/s]Tokenizing train dataset:   1%|          | 163/24227 [00:00<01:34, 254.42 examples/s]Tokenizing train dataset:   1%|          | 199/24227 [00:00<01:37, 245.89 examples/s]Tokenizing train dataset:   1%|          | 233/24227 [00:00<01:30, 264.83 examples/s]Tokenizing train dataset:   1%|          | 264/24227 [00:00<01:27, 275.24 examples/s]Tokenizing train dataset:   1%|          | 298/24227 [00:01<01:22, 289.88 examples/s]Tokenizing train dataset:   1%|▏         | 338/24227 [00:01<01:25, 279.54 examples/s]Tokenizing train dataset:   2%|▏         | 384/24227 [00:01<01:23, 284.12 examples/s]Tokenizing train dataset:   2%|▏         | 426/24227 [00:01<01:25, 278.30 examples/s]Tokenizing train dataset:   2%|▏         | 462/24227 [00:01<01:30, 263.17 examples/s]Tokenizing train dataset:   2%|▏         | 503/24227 [00:01<01:29, 264.68 examples/s]Tokenizing train dataset:   2%|▏         | 530/24227 [00:01<01:30, 262.57 examples/s]Tokenizing train dataset:   2%|▏         | 560/24227 [00:02<01:28, 268.03 examples/s]Tokenizing train dataset:   2%|▏         | 599/24227 [00:02<01:30, 260.79 examples/s]Tokenizing train dataset:   3%|▎         | 634/24227 [00:02<01:24, 280.05 examples/s]Tokenizing train dataset:   3%|▎         | 668/24227 [00:02<01:30, 259.22 examples/s]Tokenizing train dataset:   3%|▎         | 695/24227 [00:02<01:30, 260.10 examples/s]Tokenizing train dataset:   3%|▎         | 740/24227 [00:02<01:26, 270.01 examples/s]Tokenizing train dataset:   3%|▎         | 779/24227 [00:02<01:29, 263.19 examples/s]Tokenizing train dataset:   3%|▎         | 820/24227 [00:03<01:29, 261.71 examples/s]Tokenizing train dataset:   4%|▎         | 848/24227 [00:03<01:28, 263.91 examples/s]Tokenizing train dataset:   4%|▎         | 878/24227 [00:03<01:27, 267.62 examples/s]Tokenizing train dataset:   4%|▍         | 910/24227 [00:03<01:23, 279.48 examples/s]Tokenizing train dataset:   4%|▍         | 948/24227 [00:03<01:27, 267.07 examples/s]Tokenizing train dataset:   4%|▍         | 985/24227 [00:03<01:29, 258.89 examples/s]Tokenizing train dataset:   4%|▍         | 1024/24227 [00:03<01:29, 258.08 examples/s]Tokenizing train dataset:   4%|▍         | 1054/24227 [00:04<01:49, 211.08 examples/s]Tokenizing train dataset:   4%|▍         | 1085/24227 [00:04<01:41, 228.51 examples/s]Tokenizing train dataset:   5%|▍         | 1121/24227 [00:04<01:41, 227.45 examples/s]Tokenizing train dataset:   5%|▍         | 1145/24227 [00:04<01:40, 229.70 examples/s]Tokenizing train dataset:   5%|▍         | 1170/24227 [00:04<01:38, 233.40 examples/s]Tokenizing train dataset:   5%|▍         | 1203/24227 [00:04<01:30, 255.02 examples/s]Tokenizing train dataset:   5%|▌         | 1249/24227 [00:04<01:26, 267.03 examples/s]Tokenizing train dataset:   5%|▌         | 1277/24227 [00:04<01:25, 267.22 examples/s]Tokenizing train dataset:   5%|▌         | 1307/24227 [00:04<01:24, 270.78 examples/s]Tokenizing train dataset:   6%|▌         | 1345/24227 [00:05<01:28, 260.02 examples/s]Tokenizing train dataset:   6%|▌         | 1386/24227 [00:05<01:28, 259.24 examples/s]Tokenizing train dataset:   6%|▌         | 1427/24227 [00:05<01:27, 261.01 examples/s]Tokenizing train dataset:   6%|▌         | 1458/24227 [00:05<01:33, 242.52 examples/s]Tokenizing train dataset:   6%|▌         | 1492/24227 [00:05<01:36, 234.41 examples/s]Tokenizing train dataset:   6%|▋         | 1516/24227 [00:05<01:36, 234.40 examples/s]Tokenizing train dataset:   6%|▋         | 1543/24227 [00:05<01:34, 240.86 examples/s]Tokenizing train dataset:   7%|▋         | 1578/24227 [00:06<01:36, 235.52 examples/s]Tokenizing train dataset:   7%|▋         | 1619/24227 [00:06<01:33, 243.00 examples/s]Tokenizing train dataset:   7%|▋         | 1651/24227 [00:06<01:26, 260.15 examples/s]Tokenizing train dataset:   7%|▋         | 1700/24227 [00:06<01:22, 273.18 examples/s]Tokenizing train dataset:   7%|▋         | 1732/24227 [00:06<01:20, 278.08 examples/s]Tokenizing train dataset:   7%|▋         | 1777/24227 [00:06<01:19, 282.91 examples/s]Tokenizing train dataset:   7%|▋         | 1815/24227 [00:06<01:23, 269.11 examples/s]Tokenizing train dataset:   8%|▊         | 1856/24227 [00:07<01:23, 266.89 examples/s]Tokenizing train dataset:   8%|▊         | 1884/24227 [00:07<01:33, 237.88 examples/s]Tokenizing train dataset:   8%|▊         | 1920/24227 [00:07<01:34, 236.35 examples/s]Tokenizing train dataset:   8%|▊         | 1957/24227 [00:07<01:35, 234.36 examples/s]Tokenizing train dataset:   8%|▊         | 1994/24227 [00:07<01:34, 234.40 examples/s]Tokenizing train dataset:   8%|▊         | 2022/24227 [00:07<01:31, 241.74 examples/s]Tokenizing train dataset:   9%|▊         | 2060/24227 [00:08<01:32, 240.53 examples/s]Tokenizing train dataset:   9%|▊         | 2087/24227 [00:08<01:30, 244.54 examples/s]Tokenizing train dataset:   9%|▊         | 2115/24227 [00:08<01:28, 249.96 examples/s]Tokenizing train dataset:   9%|▉         | 2144/24227 [00:08<01:25, 257.43 examples/s]Tokenizing train dataset:   9%|▉         | 2178/24227 [00:08<01:30, 242.56 examples/s]Tokenizing train dataset:   9%|▉         | 2209/24227 [00:08<01:35, 229.52 examples/s]Tokenizing train dataset:   9%|▉         | 2240/24227 [00:08<01:29, 244.72 examples/s]Tokenizing train dataset:   9%|▉         | 2272/24227 [00:08<01:24, 259.67 examples/s]Tokenizing train dataset:   9%|▉         | 2300/24227 [00:08<01:24, 260.85 examples/s]Tokenizing train dataset:  10%|▉         | 2327/24227 [00:09<01:23, 261.47 examples/s]Tokenizing train dataset:  10%|▉         | 2369/24227 [00:09<01:24, 260.14 examples/s]Tokenizing train dataset:  10%|▉         | 2410/24227 [00:09<01:23, 261.09 examples/s]Tokenizing train dataset:  10%|█         | 2446/24227 [00:09<01:26, 252.89 examples/s]Tokenizing train dataset:  10%|█         | 2491/24227 [00:09<01:21, 265.31 examples/s]Tokenizing train dataset:  10%|█         | 2526/24227 [00:09<01:38, 220.91 examples/s]Tokenizing train dataset:  11%|█         | 2550/24227 [00:10<01:37, 223.24 examples/s]Tokenizing train dataset:  11%|█         | 2585/24227 [00:10<01:36, 224.47 examples/s]Tokenizing train dataset:  11%|█         | 2622/24227 [00:10<01:34, 229.34 examples/s]Tokenizing train dataset:  11%|█         | 2648/24227 [00:10<01:32, 233.93 examples/s]Tokenizing train dataset:  11%|█         | 2674/24227 [00:10<01:30, 238.58 examples/s]Tokenizing train dataset:  11%|█         | 2709/24227 [00:10<01:21, 265.63 examples/s]Tokenizing train dataset:  11%|█▏        | 2750/24227 [00:10<01:21, 263.03 examples/s]Tokenizing train dataset:  11%|█▏        | 2779/24227 [00:10<01:41, 212.10 examples/s]Tokenizing train dataset:  12%|█▏        | 2805/24227 [00:11<01:37, 219.99 examples/s]Tokenizing train dataset:  12%|█▏        | 2833/24227 [00:11<01:32, 230.08 examples/s]Tokenizing train dataset:  12%|█▏        | 2858/24227 [00:11<01:31, 232.73 examples/s]Tokenizing train dataset:  12%|█▏        | 2889/24227 [00:11<01:38, 217.15 examples/s]Tokenizing train dataset:  12%|█▏        | 2915/24227 [00:11<01:35, 223.25 examples/s]Tokenizing train dataset:  12%|█▏        | 2946/24227 [00:11<01:28, 241.74 examples/s]Tokenizing train dataset:  12%|█▏        | 2976/24227 [00:11<01:24, 252.24 examples/s]Tokenizing train dataset:  12%|█▏        | 3014/24227 [00:11<01:25, 248.56 examples/s]Tokenizing train dataset:  13%|█▎        | 3040/24227 [00:12<01:25, 248.59 examples/s]Tokenizing train dataset:  13%|█▎        | 3076/24227 [00:12<01:27, 241.27 examples/s]Tokenizing train dataset:  13%|█▎        | 3106/24227 [00:12<01:24, 251.22 examples/s]Tokenizing train dataset:  13%|█▎        | 3135/24227 [00:12<01:21, 258.83 examples/s]Tokenizing train dataset:  13%|█▎        | 3178/24227 [00:12<01:20, 261.98 examples/s]Tokenizing train dataset:  13%|█▎        | 3216/24227 [00:12<01:21, 258.30 examples/s]Tokenizing train dataset:  13%|█▎        | 3246/24227 [00:12<01:18, 265.91 examples/s]Tokenizing train dataset:  14%|█▎        | 3274/24227 [00:12<01:18, 267.44 examples/s]Tokenizing train dataset:  14%|█▎        | 3304/24227 [00:13<01:16, 275.23 examples/s]Tokenizing train dataset:  14%|█▍        | 3342/24227 [00:13<01:19, 262.20 examples/s]Tokenizing train dataset:  14%|█▍        | 3380/24227 [00:13<01:22, 251.85 examples/s]Tokenizing train dataset:  14%|█▍        | 3407/24227 [00:13<01:22, 253.09 examples/s]Tokenizing train dataset:  14%|█▍        | 3440/24227 [00:13<01:26, 239.43 examples/s]Tokenizing train dataset:  14%|█▍        | 3473/24227 [00:13<01:31, 227.51 examples/s]Tokenizing train dataset:  14%|█▍        | 3501/24227 [00:13<01:27, 237.41 examples/s]Tokenizing train dataset:  15%|█▍        | 3535/24227 [00:13<01:19, 261.12 examples/s]Tokenizing train dataset:  15%|█▍        | 3569/24227 [00:14<01:13, 279.63 examples/s]Tokenizing train dataset:  15%|█▍        | 3610/24227 [00:14<01:15, 273.30 examples/s]Tokenizing train dataset:  15%|█▌        | 3653/24227 [00:14<01:15, 273.22 examples/s]Tokenizing train dataset:  15%|█▌        | 3694/24227 [00:14<01:15, 270.81 examples/s]Tokenizing train dataset:  15%|█▌        | 3725/24227 [00:14<01:22, 248.73 examples/s]Tokenizing train dataset:  16%|█▌        | 3767/24227 [00:14<01:20, 255.46 examples/s]Tokenizing train dataset:  16%|█▌        | 3796/24227 [00:14<01:18, 260.10 examples/s]Tokenizing train dataset:  16%|█▌        | 3830/24227 [00:15<01:14, 275.11 examples/s]Tokenizing train dataset:  16%|█▌        | 3860/24227 [00:15<01:13, 277.63 examples/s]Tokenizing train dataset:  16%|█▌        | 3906/24227 [00:15<01:23, 244.52 examples/s]Tokenizing train dataset:  16%|█▌        | 3933/24227 [00:15<01:33, 217.82 examples/s]Tokenizing train dataset:  16%|█▋        | 3971/24227 [00:15<01:30, 224.93 examples/s]Tokenizing train dataset:  17%|█▋        | 3998/24227 [00:15<01:27, 232.25 examples/s]Tokenizing train dataset:  17%|█▋        | 4039/24227 [00:16<01:23, 242.09 examples/s]Tokenizing train dataset:  17%|█▋        | 4065/24227 [00:16<01:22, 245.13 examples/s]Tokenizing train dataset:  17%|█▋        | 4097/24227 [00:16<01:17, 260.54 examples/s]Tokenizing train dataset:  17%|█▋        | 4124/24227 [00:16<01:17, 260.43 examples/s]Tokenizing train dataset:  17%|█▋        | 4164/24227 [00:16<01:16, 260.93 examples/s]Tokenizing train dataset:  17%|█▋        | 4196/24227 [00:16<01:13, 273.06 examples/s]Tokenizing train dataset:  17%|█▋        | 4237/24227 [00:16<01:14, 268.67 examples/s]Tokenizing train dataset:  18%|█▊        | 4280/24227 [00:16<01:13, 271.74 examples/s]Tokenizing train dataset:  18%|█▊        | 4319/24227 [00:17<01:15, 263.63 examples/s]Tokenizing train dataset:  18%|█▊        | 4350/24227 [00:17<01:13, 271.02 examples/s]Tokenizing train dataset:  18%|█▊        | 4394/24227 [00:17<01:12, 274.14 examples/s]Tokenizing train dataset:  18%|█▊        | 4439/24227 [00:17<01:11, 278.12 examples/s]Tokenizing train dataset:  18%|█▊        | 4481/24227 [00:17<01:12, 271.57 examples/s]Tokenizing train dataset:  19%|█▊        | 4515/24227 [00:17<01:17, 254.96 examples/s]Tokenizing train dataset:  19%|█▉        | 4551/24227 [00:17<01:19, 247.12 examples/s]Tokenizing train dataset:  19%|█▉        | 4591/24227 [00:18<01:18, 248.99 examples/s]Tokenizing train dataset:  19%|█▉        | 4627/24227 [00:18<01:20, 242.75 examples/s]Tokenizing train dataset:  19%|█▉        | 4654/24227 [00:18<01:19, 245.98 examples/s]Tokenizing train dataset:  19%|█▉        | 4692/24227 [00:18<01:19, 246.89 examples/s]Tokenizing train dataset:  20%|█▉        | 4730/24227 [00:18<01:19, 245.73 examples/s]Tokenizing train dataset:  20%|█▉        | 4758/24227 [00:18<01:18, 248.51 examples/s]Tokenizing train dataset:  20%|█▉        | 4796/24227 [00:18<01:18, 247.09 examples/s]Tokenizing train dataset:  20%|█▉        | 4825/24227 [00:19<01:28, 218.14 examples/s]Tokenizing train dataset:  20%|██        | 4860/24227 [00:19<01:27, 220.16 examples/s]Tokenizing train dataset:  20%|██        | 4890/24227 [00:19<01:34, 204.47 examples/s]Tokenizing train dataset:  20%|██        | 4913/24227 [00:19<01:32, 207.72 examples/s]Tokenizing train dataset:  20%|██        | 4942/24227 [00:19<01:25, 224.46 examples/s]Tokenizing train dataset:  21%|██        | 4980/24227 [00:19<01:24, 227.73 examples/s]Tokenizing train dataset:  21%|██        | 5006/24227 [00:19<01:21, 234.97 examples/s]Tokenizing train dataset:  21%|██        | 5040/24227 [00:20<01:15, 255.32 examples/s]Tokenizing train dataset:  21%|██        | 5072/24227 [00:20<01:24, 227.32 examples/s]Tokenizing train dataset:  21%|██        | 5097/24227 [00:20<01:22, 231.72 examples/s]Tokenizing train dataset:  21%|██        | 5132/24227 [00:20<01:23, 229.74 examples/s]Tokenizing train dataset:  21%|██▏       | 5160/24227 [00:20<01:44, 182.55 examples/s]Tokenizing train dataset:  21%|██▏       | 5186/24227 [00:20<01:36, 197.26 examples/s]Tokenizing train dataset:  22%|██▏       | 5211/24227 [00:20<01:31, 208.03 examples/s]Tokenizing train dataset:  22%|██▏       | 5248/24227 [00:21<01:28, 214.81 examples/s]Tokenizing train dataset:  22%|██▏       | 5277/24227 [00:21<01:31, 207.21 examples/s]Tokenizing train dataset:  22%|██▏       | 5300/24227 [00:21<01:30, 208.07 examples/s]Tokenizing train dataset:  22%|██▏       | 5330/24227 [00:21<01:32, 203.37 examples/s]Tokenizing train dataset:  22%|██▏       | 5358/24227 [00:21<01:25, 220.94 examples/s]Tokenizing train dataset:  22%|██▏       | 5381/24227 [00:21<01:38, 191.85 examples/s]Tokenizing train dataset:  22%|██▏       | 5405/24227 [00:21<01:33, 200.92 examples/s]Tokenizing train dataset:  22%|██▏       | 5436/24227 [00:21<01:23, 225.95 examples/s]Tokenizing train dataset:  23%|██▎       | 5460/24227 [00:22<01:22, 227.99 examples/s]Tokenizing train dataset:  23%|██▎       | 5488/24227 [00:22<01:17, 240.62 examples/s]Tokenizing train dataset:  23%|██▎       | 5517/24227 [00:22<01:14, 252.27 examples/s]Tokenizing train dataset:  23%|██▎       | 5556/24227 [00:22<01:14, 251.51 examples/s]Tokenizing train dataset:  23%|██▎       | 5596/24227 [00:22<01:05, 285.01 examples/s]Tokenizing train dataset:  23%|██▎       | 5638/24227 [00:22<01:06, 279.78 examples/s]Tokenizing train dataset:  23%|██▎       | 5675/24227 [00:22<01:02, 297.26 examples/s]Tokenizing train dataset:  24%|██▎       | 5720/24227 [00:22<01:02, 293.85 examples/s]Tokenizing train dataset:  24%|██▍       | 5760/24227 [00:23<01:06, 278.16 examples/s]Tokenizing train dataset:  24%|██▍       | 5797/24227 [00:23<01:09, 264.37 examples/s]Tokenizing train dataset:  24%|██▍       | 5832/24227 [00:23<01:05, 282.46 examples/s]Tokenizing train dataset:  24%|██▍       | 5870/24227 [00:23<01:00, 301.11 examples/s]Tokenizing train dataset:  24%|██▍       | 5909/24227 [00:23<01:05, 281.34 examples/s]Tokenizing train dataset:  25%|██▍       | 5941/24227 [00:23<01:03, 286.06 examples/s]Tokenizing train dataset:  25%|██▍       | 5981/24227 [00:23<01:06, 274.76 examples/s]Tokenizing train dataset:  25%|██▍       | 6020/24227 [00:24<01:08, 265.15 examples/s]Tokenizing train dataset:  25%|██▍       | 6052/24227 [00:24<01:06, 274.95 examples/s]Tokenizing train dataset:  25%|██▌       | 6087/24227 [00:24<01:02, 292.32 examples/s]Tokenizing train dataset:  25%|██▌       | 6121/24227 [00:24<00:59, 302.89 examples/s]Tokenizing train dataset:  25%|██▌       | 6157/24227 [00:24<00:57, 315.09 examples/s]Tokenizing train dataset:  26%|██▌       | 6204/24227 [00:24<00:57, 312.13 examples/s]Tokenizing train dataset:  26%|██▌       | 6239/24227 [00:24<01:04, 281.06 examples/s]Tokenizing train dataset:  26%|██▌       | 6285/24227 [00:24<01:02, 286.53 examples/s]Tokenizing train dataset:  26%|██▌       | 6318/24227 [00:25<01:01, 292.22 examples/s]Tokenizing train dataset:  26%|██▌       | 6355/24227 [00:25<00:57, 309.81 examples/s]Tokenizing train dataset:  26%|██▋       | 6406/24227 [00:25<00:56, 317.91 examples/s]Tokenizing train dataset:  27%|██▋       | 6442/24227 [00:25<00:54, 326.47 examples/s]Tokenizing train dataset:  27%|██▋       | 6485/24227 [00:25<00:57, 309.80 examples/s]Tokenizing train dataset:  27%|██▋       | 6517/24227 [00:25<00:56, 311.12 examples/s]Tokenizing train dataset:  27%|██▋       | 6550/24227 [00:25<00:56, 311.70 examples/s]Tokenizing train dataset:  27%|██▋       | 6582/24227 [00:25<00:56, 313.18 examples/s]Tokenizing train dataset:  27%|██▋       | 6614/24227 [00:25<00:56, 313.38 examples/s]Tokenizing train dataset:  28%|██▊       | 6666/24227 [00:26<00:54, 321.97 examples/s]Tokenizing train dataset:  28%|██▊       | 6716/24227 [00:26<00:54, 321.85 examples/s]Tokenizing train dataset:  28%|██▊       | 6762/24227 [00:26<00:55, 311.93 examples/s]Tokenizing train dataset:  28%|██▊       | 6794/24227 [00:26<00:55, 312.11 examples/s]Tokenizing train dataset:  28%|██▊       | 6829/24227 [00:26<00:54, 318.77 examples/s]Tokenizing train dataset:  28%|██▊       | 6874/24227 [00:26<00:56, 308.25 examples/s]Tokenizing train dataset:  29%|██▊       | 6921/24227 [00:26<00:56, 308.86 examples/s]Tokenizing train dataset:  29%|██▉       | 6971/24227 [00:27<00:55, 311.48 examples/s]Tokenizing train dataset:  29%|██▉       | 7010/24227 [00:27<01:00, 285.97 examples/s]Tokenizing train dataset:  29%|██▉       | 7040/24227 [00:27<01:00, 285.42 examples/s]Tokenizing train dataset:  29%|██▉       | 7084/24227 [00:27<00:59, 286.17 examples/s]Tokenizing train dataset:  29%|██▉       | 7118/24227 [00:27<00:57, 298.00 examples/s]Tokenizing train dataset:  30%|██▉       | 7162/24227 [00:27<00:58, 292.55 examples/s]Tokenizing train dataset:  30%|██▉       | 7203/24227 [00:27<00:59, 283.95 examples/s]Tokenizing train dataset:  30%|██▉       | 7239/24227 [00:28<00:56, 300.80 examples/s]Tokenizing train dataset:  30%|███       | 7286/24227 [00:28<00:56, 300.64 examples/s]Tokenizing train dataset:  30%|███       | 7319/24227 [00:28<00:55, 305.01 examples/s]Tokenizing train dataset:  30%|███       | 7356/24227 [00:28<00:52, 319.59 examples/s]Tokenizing train dataset:  31%|███       | 7390/24227 [00:28<00:52, 322.09 examples/s]Tokenizing train dataset:  31%|███       | 7440/24227 [00:28<00:51, 323.45 examples/s]Tokenizing train dataset:  31%|███       | 7476/24227 [00:28<00:50, 330.28 examples/s]Tokenizing train dataset:  31%|███       | 7520/24227 [00:28<00:53, 311.48 examples/s]Tokenizing train dataset:  31%|███       | 7567/24227 [00:29<00:54, 307.81 examples/s]Tokenizing train dataset:  31%|███▏      | 7613/24227 [00:29<00:54, 302.87 examples/s]Tokenizing train dataset:  32%|███▏      | 7647/24227 [00:29<00:59, 278.07 examples/s]Tokenizing train dataset:  32%|███▏      | 7699/24227 [00:29<00:59, 279.90 examples/s]Tokenizing train dataset:  32%|███▏      | 7765/24227 [00:29<00:46, 357.28 examples/s]Tokenizing train dataset:  32%|███▏      | 7818/24227 [00:29<00:41, 392.10 examples/s]Tokenizing train dataset:  33%|███▎      | 7896/24227 [00:29<00:37, 430.71 examples/s]Tokenizing train dataset:  33%|███▎      | 7957/24227 [00:30<00:34, 472.61 examples/s]Tokenizing train dataset:  33%|███▎      | 8021/24227 [00:30<00:31, 511.68 examples/s]Tokenizing train dataset:  33%|███▎      | 8080/24227 [00:30<00:30, 529.55 examples/s]Tokenizing train dataset:  34%|███▎      | 8154/24227 [00:30<00:31, 511.28 examples/s]Tokenizing train dataset:  34%|███▍      | 8211/24227 [00:30<00:30, 523.04 examples/s]Tokenizing train dataset:  34%|███▍      | 8280/24227 [00:30<00:28, 565.07 examples/s]Tokenizing train dataset:  34%|███▍      | 8343/24227 [00:30<00:27, 581.08 examples/s]Tokenizing train dataset:  35%|███▍      | 8427/24227 [00:30<00:27, 567.54 examples/s]Tokenizing train dataset:  35%|███▌      | 8487/24227 [00:30<00:27, 573.09 examples/s]Tokenizing train dataset:  35%|███▌      | 8585/24227 [00:31<00:26, 597.71 examples/s]Tokenizing train dataset:  36%|███▌      | 8680/24227 [00:31<00:25, 603.63 examples/s]Tokenizing train dataset:  36%|███▌      | 8770/24227 [00:31<00:25, 597.53 examples/s]Tokenizing train dataset:  37%|███▋      | 8851/24227 [00:31<00:26, 578.43 examples/s]Tokenizing train dataset:  37%|███▋      | 8918/24227 [00:31<00:25, 598.19 examples/s]Tokenizing train dataset:  37%|███▋      | 8992/24227 [00:31<00:24, 627.06 examples/s]Tokenizing train dataset:  37%|███▋      | 9085/24227 [00:31<00:24, 621.23 examples/s]Tokenizing train dataset:  38%|███▊      | 9168/24227 [00:32<00:25, 596.15 examples/s]Tokenizing train dataset:  38%|███▊      | 9241/24227 [00:32<00:28, 532.38 examples/s]Tokenizing train dataset:  38%|███▊      | 9306/24227 [00:32<00:26, 553.09 examples/s]Tokenizing train dataset:  39%|███▉      | 9391/24227 [00:32<00:26, 552.96 examples/s]Tokenizing train dataset:  39%|███▉      | 9448/24227 [00:32<00:26, 554.58 examples/s]Tokenizing train dataset:  39%|███▉      | 9508/24227 [00:32<00:26, 564.88 examples/s]Tokenizing train dataset:  40%|███▉      | 9590/24227 [00:32<00:26, 550.01 examples/s]Tokenizing train dataset:  40%|███▉      | 9666/24227 [00:33<00:27, 530.50 examples/s]Tokenizing train dataset:  40%|████      | 9739/24227 [00:33<00:28, 514.53 examples/s]Tokenizing train dataset:  40%|████      | 9800/24227 [00:33<00:27, 531.11 examples/s]Tokenizing train dataset:  41%|████      | 9870/24227 [00:33<00:28, 504.41 examples/s]Tokenizing train dataset:  41%|████      | 9941/24227 [00:33<00:25, 549.67 examples/s]Tokenizing train dataset:  41%|████▏     | 10000/24227 [00:33<00:25, 558.35 examples/s]Tokenizing train dataset:  42%|████▏     | 10081/24227 [00:33<00:25, 550.76 examples/s]Tokenizing train dataset:  42%|████▏     | 10144/24227 [00:33<00:24, 569.16 examples/s]Tokenizing train dataset:  42%|████▏     | 10222/24227 [00:34<00:28, 485.82 examples/s]Tokenizing train dataset:  42%|████▏     | 10275/24227 [00:34<00:31, 442.80 examples/s]Tokenizing train dataset:  43%|████▎     | 10325/24227 [00:34<00:34, 402.00 examples/s]Tokenizing train dataset:  43%|████▎     | 10379/24227 [00:34<00:35, 385.21 examples/s]Tokenizing train dataset:  43%|████▎     | 10422/24227 [00:34<00:39, 349.54 examples/s]Tokenizing train dataset:  43%|████▎     | 10468/24227 [00:34<00:41, 335.28 examples/s]Tokenizing train dataset:  43%|████▎     | 10504/24227 [00:34<00:40, 335.02 examples/s]Tokenizing train dataset:  44%|████▎     | 10539/24227 [00:35<00:40, 335.43 examples/s]Tokenizing train dataset:  44%|████▎     | 10576/24227 [00:35<00:45, 302.24 examples/s]Tokenizing train dataset:  44%|████▍     | 10622/24227 [00:35<00:45, 301.17 examples/s]Tokenizing train dataset:  44%|████▍     | 10667/24227 [00:35<00:45, 296.84 examples/s]Tokenizing train dataset:  44%|████▍     | 10717/24227 [00:35<00:44, 305.82 examples/s]Tokenizing train dataset:  44%|████▍     | 10751/24227 [00:35<00:43, 311.79 examples/s]Tokenizing train dataset:  45%|████▍     | 10790/24227 [00:35<00:45, 292.74 examples/s]Tokenizing train dataset:  45%|████▍     | 10829/24227 [00:36<00:42, 312.56 examples/s]Tokenizing train dataset:  45%|████▍     | 10874/24227 [00:36<00:43, 305.32 examples/s]Tokenizing train dataset:  45%|████▌     | 10908/24227 [00:36<00:42, 310.52 examples/s]Tokenizing train dataset:  45%|████▌     | 10946/24227 [00:36<00:46, 283.03 examples/s]Tokenizing train dataset:  45%|████▌     | 10987/24227 [00:36<00:42, 308.98 examples/s]Tokenizing train dataset:  45%|████▌     | 11020/24227 [00:36<00:42, 310.94 examples/s]Tokenizing train dataset:  46%|████▌     | 11056/24227 [00:36<00:40, 323.37 examples/s]Tokenizing train dataset:  46%|████▌     | 11091/24227 [00:36<00:40, 327.13 examples/s]Tokenizing train dataset:  46%|████▌     | 11138/24227 [00:37<00:40, 320.52 examples/s]Tokenizing train dataset:  46%|████▌     | 11172/24227 [00:37<00:40, 323.34 examples/s]Tokenizing train dataset:  46%|████▋     | 11206/24227 [00:37<00:39, 327.07 examples/s]Tokenizing train dataset:  46%|████▋     | 11249/24227 [00:37<00:42, 305.67 examples/s]Tokenizing train dataset:  47%|████▋     | 11297/24227 [00:37<00:42, 306.42 examples/s]Tokenizing train dataset:  47%|████▋     | 11332/24227 [00:37<00:41, 313.76 examples/s]Tokenizing train dataset:  47%|████▋     | 11367/24227 [00:37<00:40, 319.79 examples/s]Tokenizing train dataset:  47%|████▋     | 11409/24227 [00:37<00:42, 300.74 examples/s]Tokenizing train dataset:  47%|████▋     | 11457/24227 [00:38<00:42, 302.79 examples/s]Tokenizing train dataset:  47%|████▋     | 11495/24227 [00:38<00:40, 316.14 examples/s]Tokenizing train dataset:  48%|████▊     | 11542/24227 [00:38<00:40, 311.25 examples/s]Tokenizing train dataset:  48%|████▊     | 11584/24227 [00:38<00:42, 297.63 examples/s]Tokenizing train dataset:  48%|████▊     | 11631/24227 [00:38<00:41, 301.57 examples/s]Tokenizing train dataset:  48%|████▊     | 11662/24227 [00:38<00:41, 300.39 examples/s]Tokenizing train dataset:  48%|████▊     | 11711/24227 [00:38<00:41, 305.13 examples/s]Tokenizing train dataset:  48%|████▊     | 11744/24227 [00:39<00:40, 310.09 examples/s]Tokenizing train dataset:  49%|████▊     | 11779/24227 [00:39<00:39, 314.25 examples/s]Tokenizing train dataset:  49%|████▉     | 11816/24227 [00:39<00:47, 263.76 examples/s]Tokenizing train dataset:  49%|████▉     | 11871/24227 [00:39<00:41, 294.54 examples/s]Tokenizing train dataset:  49%|████▉     | 11930/24227 [00:39<00:34, 360.53 examples/s]Tokenizing train dataset:  49%|████▉     | 11988/24227 [00:39<00:29, 412.45 examples/s]Tokenizing train dataset:  50%|████▉     | 12058/24227 [00:39<00:30, 400.07 examples/s]Tokenizing train dataset:  50%|█████     | 12122/24227 [00:39<00:26, 454.05 examples/s]Tokenizing train dataset:  50%|█████     | 12186/24227 [00:40<00:24, 497.44 examples/s]Tokenizing train dataset:  51%|█████     | 12249/24227 [00:40<00:22, 529.92 examples/s]Tokenizing train dataset:  51%|█████     | 12307/24227 [00:40<00:22, 541.19 examples/s]Tokenizing train dataset:  51%|█████     | 12390/24227 [00:40<00:21, 541.08 examples/s]Tokenizing train dataset:  51%|█████▏    | 12475/24227 [00:40<00:21, 546.82 examples/s]Tokenizing train dataset:  52%|█████▏    | 12538/24227 [00:40<00:20, 564.53 examples/s]Tokenizing train dataset:  52%|█████▏    | 12622/24227 [00:40<00:20, 560.94 examples/s]Tokenizing train dataset:  52%|█████▏    | 12691/24227 [00:40<00:19, 590.90 examples/s]Tokenizing train dataset:  53%|█████▎    | 12755/24227 [00:41<00:19, 602.40 examples/s]Tokenizing train dataset:  53%|█████▎    | 12827/24227 [00:41<00:18, 629.21 examples/s]Tokenizing train dataset:  53%|█████▎    | 12911/24227 [00:41<00:18, 600.42 examples/s]Tokenizing train dataset:  54%|█████▎    | 13002/24227 [00:41<00:18, 601.19 examples/s]Tokenizing train dataset:  54%|█████▍    | 13088/24227 [00:41<00:18, 590.04 examples/s]Tokenizing train dataset:  54%|█████▍    | 13150/24227 [00:41<00:18, 592.77 examples/s]Tokenizing train dataset:  55%|█████▍    | 13235/24227 [00:41<00:18, 580.26 examples/s]Tokenizing train dataset:  55%|█████▍    | 13312/24227 [00:41<00:19, 554.56 examples/s]Tokenizing train dataset:  55%|█████▌    | 13370/24227 [00:42<00:19, 559.02 examples/s]Tokenizing train dataset:  55%|█████▌    | 13430/24227 [00:42<00:19, 565.86 examples/s]Tokenizing train dataset:  56%|█████▌    | 13499/24227 [00:42<00:18, 595.18 examples/s]Tokenizing train dataset:  56%|█████▌    | 13572/24227 [00:42<00:20, 515.82 examples/s]Tokenizing train dataset:  56%|█████▋    | 13643/24227 [00:42<00:18, 559.51 examples/s]Tokenizing train dataset:  57%|█████▋    | 13703/24227 [00:42<00:18, 567.65 examples/s]Tokenizing train dataset:  57%|█████▋    | 13788/24227 [00:42<00:18, 563.31 examples/s]Tokenizing train dataset:  57%|█████▋    | 13859/24227 [00:42<00:17, 596.44 examples/s]Tokenizing train dataset:  58%|█████▊    | 13938/24227 [00:43<00:18, 569.34 examples/s]Tokenizing train dataset:  58%|█████▊    | 14022/24227 [00:43<00:18, 561.83 examples/s]Tokenizing train dataset:  58%|█████▊    | 14083/24227 [00:43<00:17, 572.53 examples/s]Tokenizing train dataset:  58%|█████▊    | 14159/24227 [00:43<00:16, 618.06 examples/s]Tokenizing train dataset:  59%|█████▊    | 14226/24227 [00:43<00:15, 629.62 examples/s]Tokenizing train dataset:  59%|█████▉    | 14292/24227 [00:43<00:15, 634.68 examples/s]Tokenizing train dataset:  59%|█████▉    | 14368/24227 [00:43<00:16, 583.16 examples/s]Tokenizing train dataset:  60%|█████▉    | 14428/24227 [00:43<00:16, 581.41 examples/s]Tokenizing train dataset:  60%|█████▉    | 14491/24227 [00:44<00:16, 588.48 examples/s]Tokenizing train dataset:  60%|██████    | 14554/24227 [00:44<00:16, 595.85 examples/s]Tokenizing train dataset:  60%|██████    | 14619/24227 [00:44<00:15, 603.33 examples/s]Tokenizing train dataset:  61%|██████    | 14696/24227 [00:44<00:17, 560.34 examples/s]Tokenizing train dataset:  61%|██████    | 14779/24227 [00:44<00:17, 552.53 examples/s]Tokenizing train dataset:  61%|██████    | 14837/24227 [00:44<00:18, 496.07 examples/s]Tokenizing train dataset:  61%|██████▏   | 14893/24227 [00:44<00:20, 450.46 examples/s]Tokenizing train dataset:  62%|██████▏   | 14944/24227 [00:44<00:22, 410.33 examples/s]Tokenizing train dataset:  62%|██████▏   | 14990/24227 [00:45<00:24, 375.48 examples/s]Tokenizing train dataset:  62%|██████▏   | 15030/24227 [00:45<00:24, 374.94 examples/s]Tokenizing train dataset:  62%|██████▏   | 15083/24227 [00:45<00:25, 364.00 examples/s]Tokenizing train dataset:  62%|██████▏   | 15138/24227 [00:45<00:25, 362.90 examples/s]Tokenizing train dataset:  63%|██████▎   | 15177/24227 [00:45<00:24, 366.13 examples/s]Tokenizing train dataset:  63%|██████▎   | 15228/24227 [00:45<00:25, 351.54 examples/s]Tokenizing train dataset:  63%|██████▎   | 15281/24227 [00:45<00:25, 347.16 examples/s]Tokenizing train dataset:  63%|██████▎   | 15336/24227 [00:46<00:25, 350.19 examples/s]Tokenizing train dataset:  64%|██████▎   | 15385/24227 [00:46<00:26, 338.41 examples/s]Tokenizing train dataset:  64%|██████▎   | 15437/24227 [00:46<00:26, 337.06 examples/s]Tokenizing train dataset:  64%|██████▍   | 15480/24227 [00:46<00:27, 318.73 examples/s]Tokenizing train dataset:  64%|██████▍   | 15518/24227 [00:46<00:26, 327.91 examples/s]Tokenizing train dataset:  64%|██████▍   | 15570/24227 [00:46<00:26, 328.44 examples/s]Tokenizing train dataset:  64%|██████▍   | 15617/24227 [00:47<00:26, 320.61 examples/s]Tokenizing train dataset:  65%|██████▍   | 15664/24227 [00:47<00:27, 317.14 examples/s]Tokenizing train dataset:  65%|██████▍   | 15703/24227 [00:47<00:25, 329.82 examples/s]Tokenizing train dataset:  65%|██████▍   | 15740/24227 [00:47<00:25, 336.43 examples/s]Tokenizing train dataset:  65%|██████▌   | 15788/24227 [00:47<00:26, 322.08 examples/s]Tokenizing train dataset:  65%|██████▌   | 15826/24227 [00:47<00:25, 332.78 examples/s]Tokenizing train dataset:  66%|██████▌   | 15874/24227 [00:47<00:25, 325.03 examples/s]Tokenizing train dataset:  66%|██████▌   | 15912/24227 [00:47<00:24, 336.01 examples/s]Tokenizing train dataset:  66%|██████▌   | 15960/24227 [00:48<00:25, 325.99 examples/s]Tokenizing train dataset:  66%|██████▌   | 16011/24227 [00:48<00:25, 326.47 examples/s]Tokenizing train dataset:  66%|██████▌   | 16049/24227 [00:48<00:24, 336.71 examples/s]Tokenizing train dataset:  66%|██████▋   | 16103/24227 [00:48<00:23, 340.22 examples/s]Tokenizing train dataset:  67%|██████▋   | 16142/24227 [00:48<00:23, 347.96 examples/s]Tokenizing train dataset:  67%|██████▋   | 16178/24227 [00:48<00:23, 349.93 examples/s]Tokenizing train dataset:  67%|██████▋   | 16230/24227 [00:48<00:23, 344.85 examples/s]Tokenizing train dataset:  67%|██████▋   | 16279/24227 [00:48<00:23, 335.91 examples/s]Tokenizing train dataset:  67%|██████▋   | 16330/24227 [00:49<00:23, 334.14 examples/s]Tokenizing train dataset:  68%|██████▊   | 16380/24227 [00:49<00:23, 328.18 examples/s]Tokenizing train dataset:  68%|██████▊   | 16427/24227 [00:49<00:24, 321.04 examples/s]Tokenizing train dataset:  68%|██████▊   | 16470/24227 [00:49<00:25, 307.19 examples/s]Tokenizing train dataset:  68%|██████▊   | 16536/24227 [00:49<00:20, 381.73 examples/s]Tokenizing train dataset:  69%|██████▊   | 16601/24227 [00:49<00:17, 444.48 examples/s]Tokenizing train dataset:  69%|██████▊   | 16652/24227 [00:49<00:16, 458.04 examples/s]Tokenizing train dataset:  69%|██████▉   | 16717/24227 [00:50<00:14, 507.05 examples/s]Tokenizing train dataset:  69%|██████▉   | 16781/24227 [00:50<00:13, 541.15 examples/s]Tokenizing train dataset:  70%|██████▉   | 16850/24227 [00:50<00:12, 575.89 examples/s]Tokenizing train dataset:  70%|██████▉   | 16912/24227 [00:50<00:12, 582.12 examples/s]Tokenizing train dataset:  70%|███████   | 16974/24227 [00:50<00:12, 589.38 examples/s]Tokenizing train dataset:  70%|███████   | 17035/24227 [00:50<00:12, 591.35 examples/s]Tokenizing train dataset:  71%|███████   | 17100/24227 [00:50<00:11, 600.81 examples/s]Tokenizing train dataset:  71%|███████   | 17171/24227 [00:50<00:11, 624.86 examples/s]Tokenizing train dataset:  71%|███████   | 17250/24227 [00:50<00:10, 662.56 examples/s]Tokenizing train dataset:  71%|███████▏  | 17318/24227 [00:50<00:10, 665.41 examples/s]Tokenizing train dataset:  72%|███████▏  | 17389/24227 [00:51<00:10, 676.92 examples/s]Tokenizing train dataset:  72%|███████▏  | 17475/24227 [00:51<00:10, 628.20 examples/s]Tokenizing train dataset:  72%|███████▏  | 17550/24227 [00:51<00:11, 577.64 examples/s]Tokenizing train dataset:  73%|███████▎  | 17616/24227 [00:51<00:12, 528.17 examples/s]Tokenizing train dataset:  73%|███████▎  | 17686/24227 [00:51<00:11, 567.03 examples/s]Tokenizing train dataset:  73%|███████▎  | 17753/24227 [00:51<00:10, 590.49 examples/s]Tokenizing train dataset:  74%|███████▎  | 17816/24227 [00:51<00:10, 597.16 examples/s]Tokenizing train dataset:  74%|███████▍  | 17898/24227 [00:51<00:11, 573.40 examples/s]Tokenizing train dataset:  74%|███████▍  | 17961/24227 [00:52<00:10, 586.78 examples/s]Tokenizing train dataset:  74%|███████▍  | 18030/24227 [00:52<00:10, 607.79 examples/s]Tokenizing train dataset:  75%|███████▍  | 18094/24227 [00:52<00:09, 616.04 examples/s]Tokenizing train dataset:  75%|███████▌  | 18188/24227 [00:52<00:09, 616.30 examples/s]Tokenizing train dataset:  75%|███████▌  | 18259/24227 [00:52<00:09, 639.59 examples/s]Tokenizing train dataset:  76%|███████▌  | 18336/24227 [00:52<00:08, 669.51 examples/s]Tokenizing train dataset:  76%|███████▌  | 18432/24227 [00:52<00:08, 653.84 examples/s]Tokenizing train dataset:  76%|███████▋  | 18502/24227 [00:52<00:08, 659.22 examples/s]Tokenizing train dataset:  77%|███████▋  | 18594/24227 [00:53<00:08, 637.85 examples/s]Tokenizing train dataset:  77%|███████▋  | 18669/24227 [00:53<00:08, 664.38 examples/s]Tokenizing train dataset:  77%|███████▋  | 18769/24227 [00:53<00:08, 663.45 examples/s]Tokenizing train dataset:  78%|███████▊  | 18840/24227 [00:53<00:08, 672.42 examples/s]Tokenizing train dataset:  78%|███████▊  | 18927/24227 [00:53<00:08, 636.86 examples/s]Tokenizing train dataset:  78%|███████▊  | 19014/24227 [00:53<00:08, 616.35 examples/s]Tokenizing train dataset:  79%|███████▉  | 19080/24227 [00:53<00:08, 623.90 examples/s]Tokenizing train dataset:  79%|███████▉  | 19150/24227 [00:53<00:07, 640.77 examples/s]Tokenizing train dataset:  79%|███████▉  | 19220/24227 [00:54<00:07, 655.70 examples/s]Tokenizing train dataset:  80%|███████▉  | 19315/24227 [00:54<00:07, 642.00 examples/s]Tokenizing train dataset:  80%|████████  | 19389/24227 [00:54<00:08, 590.14 examples/s]Tokenizing train dataset:  80%|████████  | 19469/24227 [00:54<00:07, 640.10 examples/s]Tokenizing train dataset:  81%|████████  | 19564/24227 [00:54<00:06, 719.67 examples/s]Tokenizing train dataset:  81%|████████▏ | 19686/24227 [00:54<00:05, 853.24 examples/s]Tokenizing train dataset:  82%|████████▏ | 19803/24227 [00:54<00:04, 939.88 examples/s]Tokenizing train dataset:  82%|████████▏ | 19940/24227 [00:54<00:04, 923.30 examples/s]Tokenizing train dataset:  83%|████████▎ | 20055/24227 [00:54<00:04, 979.41 examples/s]Tokenizing train dataset:  83%|████████▎ | 20162/24227 [00:55<00:04, 1002.12 examples/s]Tokenizing train dataset:  84%|████████▎ | 20278/24227 [00:55<00:03, 1040.85 examples/s]Tokenizing train dataset:  84%|████████▍ | 20426/24227 [00:55<00:03, 1018.82 examples/s]Tokenizing train dataset:  85%|████████▍ | 20539/24227 [00:55<00:03, 1043.50 examples/s]Tokenizing train dataset:  85%|████████▌ | 20709/24227 [00:55<00:03, 1073.61 examples/s]Tokenizing train dataset:  86%|████████▌ | 20878/24227 [00:55<00:03, 1089.54 examples/s]Tokenizing train dataset:  87%|████████▋ | 20990/24227 [00:55<00:02, 1094.51 examples/s]Tokenizing train dataset:  87%|████████▋ | 21141/24227 [00:55<00:02, 1063.49 examples/s]Tokenizing train dataset:  88%|████████▊ | 21251/24227 [00:56<00:02, 1071.87 examples/s]Tokenizing train dataset:  88%|████████▊ | 21363/24227 [00:56<00:02, 1083.23 examples/s]Tokenizing train dataset:  89%|████████▊ | 21478/24227 [00:56<00:02, 1099.20 examples/s]Tokenizing train dataset:  89%|████████▉ | 21593/24227 [00:56<00:02, 1111.36 examples/s]Tokenizing train dataset:  90%|████████▉ | 21747/24227 [00:56<00:02, 1077.19 examples/s]Tokenizing train dataset:  90%|█████████ | 21903/24227 [00:56<00:02, 1061.71 examples/s]Tokenizing train dataset:  91%|█████████ | 22059/24227 [00:56<00:02, 1052.45 examples/s]Tokenizing train dataset:  91%|█████████▏| 22167/24227 [00:56<00:01, 1058.35 examples/s]Tokenizing train dataset:  92%|█████████▏| 22274/24227 [00:57<00:01, 1058.73 examples/s]Tokenizing train dataset:  93%|█████████▎| 22420/24227 [00:57<00:01, 1022.00 examples/s]Tokenizing train dataset:  93%|█████████▎| 22530/24227 [00:57<00:01, 1040.32 examples/s]Tokenizing train dataset:  94%|█████████▎| 22678/24227 [00:57<00:01, 1020.01 examples/s]Tokenizing train dataset:  94%|█████████▍| 22821/24227 [00:57<00:01, 991.17 examples/s] Tokenizing train dataset:  95%|█████████▍| 22941/24227 [00:57<00:01, 1037.86 examples/s]Tokenizing train dataset:  95%|█████████▌| 23080/24227 [00:57<00:01, 994.70 examples/s] Tokenizing train dataset:  96%|█████████▌| 23189/24227 [00:57<00:01, 1017.00 examples/s]Tokenizing train dataset:  96%|█████████▋| 23334/24227 [00:58<00:00, 994.23 examples/s] Tokenizing train dataset:  97%|█████████▋| 23447/24227 [00:58<00:00, 1026.04 examples/s]Tokenizing train dataset:  97%|█████████▋| 23570/24227 [00:58<00:00, 931.03 examples/s] Tokenizing train dataset:  98%|█████████▊| 23680/24227 [00:58<00:00, 971.61 examples/s]Tokenizing train dataset:  98%|█████████▊| 23790/24227 [00:58<00:00, 1000.56 examples/s]Tokenizing train dataset:  99%|█████████▊| 23899/24227 [00:58<00:00, 1022.22 examples/s]Tokenizing train dataset:  99%|█████████▉| 24062/24227 [00:58<00:00, 1041.93 examples/s]Tokenizing train dataset: 100%|█████████▉| 24186/24227 [00:58<00:00, 920.63 examples/s] Tokenizing train dataset: 100%|██████████| 24227/24227 [00:59<00:00, 409.97 examples/s]
[rank0]:[W607 19:24:47.342935439 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 533/24227 [00:00<00:04, 5243.94 examples/s]Extracting prompt in train dataset:   2%|▏         | 538/24227 [00:00<00:04, 5315.35 examples/s]Extracting prompt in train dataset:   2%|▏         | 540/24227 [00:00<00:04, 5272.81 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5490.32 examples/s]Extracting prompt in train dataset:   4%|▍         | 1060/24227 [00:00<00:04, 5223.13 examples/s]Extracting prompt in train dataset:   5%|▍         | 1183/24227 [00:00<00:04, 4623.04 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3875.32 examples/s]
Extracting prompt in train dataset:   5%|▍         | 1110/24227 [00:00<00:05, 4131.15 examples/s]Extracting prompt in train dataset:   7%|▋         | 1800/24227 [00:00<00:04, 5049.11 examples/s]Extracting prompt in train dataset:   7%|▋         | 1700/24227 [00:00<00:04, 4740.05 examples/s]Extracting prompt in train dataset:   7%|▋         | 1620/24227 [00:00<00:05, 4474.61 examples/s]Extracting prompt in train dataset:  10%|▉         | 2350/24227 [00:00<00:04, 5182.35 examples/s]Extracting prompt in train dataset:   9%|▉         | 2163/24227 [00:00<00:04, 4810.81 examples/s]Extracting prompt in train dataset:  10%|█         | 2430/24227 [00:00<00:04, 4771.86 examples/s]Extracting prompt in train dataset:  11%|█         | 2695/24227 [00:00<00:04, 4979.37 examples/s]Extracting prompt in train dataset:  13%|█▎        | 3050/24227 [00:00<00:04, 4948.24 examples/s]Extracting prompt in train dataset:  12%|█▏        | 2940/24227 [00:00<00:04, 4854.74 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  14%|█▍        | 3456/24227 [00:00<00:04, 5013.58 examples/s]Extracting prompt in train dataset:  15%|█▌        | 3641/24227 [00:00<00:04, 4550.11 examples/s]Applying chat template to eval dataset:  33%|███▎      | 310/953 [00:00<00:00, 3063.06 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3581/24227 [00:00<00:04, 4625.28 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4030/24227 [00:00<00:04, 4536.85 examples/s]Extracting prompt in train dataset:  18%|█▊        | 4250/24227 [00:00<00:04, 4363.23 examples/s]Applying chat template to eval dataset:  73%|███████▎  | 695/953 [00:00<00:00, 2720.35 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4236/24227 [00:00<00:04, 4532.39 examples/s]Extracting prompt in train dataset:  19%|█▉        | 4560/24227 [00:00<00:04, 4730.90 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2368.52 examples/s]
Extracting prompt in train dataset:  20%|█▉        | 4830/24227 [00:01<00:04, 3941.42 examples/s]Extracting prompt in train dataset:  20%|█▉        | 4810/24227 [00:01<00:04, 4078.06 examples/s]Extracting prompt in train dataset:  21%|██        | 5120/24227 [00:01<00:03, 4951.60 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5380/24227 [00:01<00:04, 4287.01 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5330/24227 [00:01<00:04, 4338.86 examples/s]Extracting prompt in train dataset:  24%|██▍       | 5822/24227 [00:01<00:03, 4848.68 examples/s]Extracting prompt in train dataset:  24%|██▍       | 5822/24227 [00:01<00:04, 4414.07 examples/s]Extracting prompt in train dataset:  25%|██▌       | 6110/24227 [00:01<00:04, 4464.70 examples/s]Extracting prompt in train dataset:  26%|██▋       | 6380/24227 [00:01<00:03, 5028.31 examples/s]Extracting prompt in train dataset:  27%|██▋       | 6660/24227 [00:01<00:03, 4690.33 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  27%|██▋       | 6560/24227 [00:01<00:03, 4572.21 examples/s]Extracting prompt in train dataset:  30%|██▉       | 7186/24227 [00:01<00:03, 5141.82 examples/s]Extracting prompt in train dataset:  30%|██▉       | 7210/24227 [00:01<00:03, 4877.62 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 318.09 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7750/24227 [00:01<00:03, 5262.05 examples/s]Extracting prompt in train dataset:  30%|██▉       | 7239/24227 [00:01<00:03, 4553.06 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7760/24227 [00:01<00:03, 5041.43 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8311/24227 [00:01<00:02, 5341.49 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7790/24227 [00:01<00:03, 4770.18 examples/s]Tokenizing eval dataset:   8%|▊         | 73/953 [00:00<00:03, 271.24 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8319/24227 [00:01<00:03, 5191.70 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8915/24227 [00:01<00:03, 4777.28 examples/s]Extracting prompt in train dataset:  35%|███▍      | 8397/24227 [00:01<00:03, 4448.11 examples/s]Tokenizing eval dataset:  11%|█         | 103/953 [00:00<00:03, 231.22 examples/s]Extracting prompt in train dataset:  37%|███▋      | 9038/24227 [00:01<00:03, 5040.14 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9449/24227 [00:01<00:03, 4908.99 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8880/24227 [00:01<00:03, 4535.72 examples/s]Extracting prompt in train dataset:  40%|███▉      | 9572/24227 [00:01<00:02, 5116.02 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:00<00:03, 232.41 examples/s]Extracting prompt in train dataset:  41%|████▏     | 10000/24227 [00:02<00:02, 5055.08 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9410/24227 [00:02<00:03, 4723.62 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10123/24227 [00:02<00:02, 5214.94 examples/s]Tokenizing eval dataset:  17%|█▋        | 164/953 [00:00<00:03, 233.27 examples/s]Extracting prompt in train dataset:  43%|████▎     | 10537/24227 [00:02<00:02, 5140.64 examples/s]Extracting prompt in train dataset:  41%|████      | 9958/24227 [00:02<00:02, 4924.76 examples/s]Extracting prompt in train dataset:  45%|████▍     | 10889/24227 [00:02<00:02, 5165.19 examples/s]Tokenizing eval dataset:  20%|██        | 195/953 [00:00<00:03, 220.72 examples/s]Extracting prompt in train dataset:  47%|████▋     | 11320/24227 [00:02<00:02, 5160.65 examples/s]Extracting prompt in train dataset:  44%|████▍     | 10740/24227 [00:02<00:02, 5010.94 examples/s]Tokenizing eval dataset:  24%|██▎       | 226/953 [00:00<00:03, 240.33 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11684/24227 [00:02<00:02, 5203.83 examples/s]Extracting prompt in train dataset:  50%|████▉     | 12091/24227 [00:02<00:02, 5152.30 examples/s]Extracting prompt in train dataset:  47%|████▋     | 11507/24227 [00:02<00:02, 5041.61 examples/s]Tokenizing eval dataset:  29%|██▉       | 274/953 [00:01<00:02, 300.23 examples/s]Extracting prompt in train dataset:  51%|█████     | 12394/24227 [00:02<00:02, 5040.65 examples/s]Tokenizing eval dataset:  32%|███▏      | 308/953 [00:01<00:02, 310.11 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12760/24227 [00:02<00:02, 4921.39 examples/s]Extracting prompt in train dataset:  50%|████▉     | 12100/24227 [00:02<00:02, 4666.42 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 13152/24227 [00:02<00:02, 5039.84 examples/s]Tokenizing eval dataset:  37%|███▋      | 348/953 [00:01<00:01, 333.70 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 13457/24227 [00:02<00:02, 4832.04 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12774/24227 [00:02<00:02, 4610.25 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13721/24227 [00:02<00:02, 5178.84 examples/s]Tokenizing eval dataset:  42%|████▏     | 397/953 [00:01<00:01, 376.82 examples/s]Extracting prompt in train dataset:  59%|█████▊    | 14202/24227 [00:02<00:02, 4872.99 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 13500/24227 [00:02<00:02, 4678.54 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 14471/24227 [00:02<00:01, 5115.33 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:01<00:01, 402.75 examples/s]Extracting prompt in train dataset:  61%|██████    | 14820/24227 [00:03<00:02, 4626.94 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 14109/24227 [00:03<00:02, 4369.64 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 15066/24227 [00:03<00:01, 4700.49 examples/s]Tokenizing eval dataset:  56%|█████▌    | 531/953 [00:01<00:01, 393.55 examples/s]Extracting prompt in train dataset:  60%|██████    | 14634/24227 [00:03<00:02, 4559.71 examples/s]Extracting prompt in train dataset:  64%|██████▎   | 15420/24227 [00:03<00:01, 4426.37 examples/s]Tokenizing eval dataset:  60%|██████    | 576/953 [00:01<00:00, 406.75 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 15790/24227 [00:03<00:01, 4283.29 examples/s]Tokenizing eval dataset:  66%|██████▌   | 630/953 [00:01<00:00, 438.49 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 15380/24227 [00:03<00:01, 4541.61 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 16139/24227 [00:03<00:01, 4525.28 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 16267/24227 [00:03<00:01, 4376.62 examples/s]Tokenizing eval dataset:  72%|███████▏  | 685/953 [00:01<00:00, 467.50 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 15920/24227 [00:03<00:01, 4734.27 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 16690/24227 [00:03<00:01, 4733.13 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 16920/24227 [00:03<00:01, 4353.89 examples/s]Tokenizing eval dataset:  78%|███████▊  | 739/953 [00:02<00:00, 426.76 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 16516/24227 [00:03<00:01, 4111.71 examples/s]Extracting prompt in train dataset:  71%|███████▏  | 17291/24227 [00:03<00:01, 4240.17 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 17465/24227 [00:03<00:01, 4603.92 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:02<00:00, 437.05 examples/s]Extracting prompt in train dataset:  70%|███████   | 17052/24227 [00:03<00:01, 4389.44 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17771/24227 [00:03<00:01, 4365.80 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 17991/24227 [00:03<00:01, 4762.86 examples/s]Tokenizing eval dataset:  89%|████████▉ | 851/953 [00:02<00:00, 431.58 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17701/24227 [00:03<00:01, 4360.07 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 18375/24227 [00:03<00:01, 4237.81 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18640/24227 [00:03<00:01, 4601.34 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:02<00:00, 409.27 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 18280/24227 [00:03<00:01, 4685.46 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 18976/24227 [00:04<00:01, 3980.29 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 19242/24227 [00:04<00:01, 3830.90 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 341.74 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 325.12 examples/s]
Extracting prompt in train dataset:  78%|███████▊  | 18886/24227 [00:04<00:01, 2764.74 examples/s]Extracting prompt in train dataset:  81%|████████  | 19580/24227 [00:04<00:01, 2763.13 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19850/24227 [00:04<00:01, 2893.45 examples/s]Extracting prompt in train dataset:  80%|████████  | 19472/24227 [00:04<00:01, 3270.31 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 20150/24227 [00:04<00:01, 3247.74 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 20330/24227 [00:04<00:01, 3210.26 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19950/24227 [00:04<00:01, 3548.20 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 20770/24227 [00:04<00:01, 3444.58 examples/s]Extracting prompt in train dataset:  86%|████████▋ | 20950/24227 [00:04<00:00, 3441.58 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 20540/24227 [00:04<00:00, 4046.97 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 21300/24227 [00:04<00:00, 3810.57 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21570/24227 [00:04<00:00, 3493.88 examples/s]Extracting prompt in train dataset:  90%|█████████ | 21830/24227 [00:04<00:00, 4127.40 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 21160/24227 [00:04<00:00, 3783.99 examples/s]Extracting prompt in train dataset:  91%|█████████▏| 22151/24227 [00:04<00:00, 3959.79 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 22450/24227 [00:05<00:00, 3935.32 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 22690/24227 [00:05<00:00, 4264.07 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 21780/24227 [00:05<00:00, 3651.14 examples/s]Extracting prompt in train dataset:  95%|█████████▌| 23030/24227 [00:05<00:00, 4347.38 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 23280/24227 [00:05<00:00, 4644.91 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22380/24227 [00:05<00:00, 4126.91 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 23730/24227 [00:05<00:00, 4425.78 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 23940/24227 [00:05<00:00, 4549.12 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 23000/24227 [00:05<00:00, 4118.79 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:05<00:00, 4535.72 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:05<00:00, 4445.58 examples/s]
Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:05<00:00, 4449.73 examples/s]
Extracting prompt in train dataset:  98%|█████████▊| 23690/24227 [00:05<00:00, 4246.97 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:05<00:00, 4316.81 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 285/24227 [00:00<00:08, 2823.68 examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 711/24227 [00:00<00:08, 2828.68 examples/s]Applying chat template to train dataset:   1%|          | 288/24227 [00:00<00:08, 2843.41 examples/s]Applying chat template to train dataset:   1%|          | 287/24227 [00:00<00:08, 2849.97 examples/s]Applying chat template to train dataset:   4%|▍         | 1024/24227 [00:00<00:09, 2379.78 examples/s]Applying chat template to train dataset:   3%|▎         | 610/24227 [00:00<00:10, 2337.41 examples/s]Applying chat template to train dataset:   3%|▎         | 640/24227 [00:00<00:09, 2505.76 examples/s]Applying chat template to train dataset:   5%|▌         | 1325/24227 [00:00<00:08, 2573.16 examples/s]Applying chat template to train dataset:   4%|▍         | 917/24227 [00:00<00:08, 2619.47 examples/s]Applying chat template to train dataset:   4%|▍         | 914/24227 [00:00<00:08, 2594.19 examples/s]Applying chat template to train dataset:   7%|▋         | 1622/24227 [00:00<00:08, 2693.17 examples/s]Applying chat template to train dataset:   5%|▌         | 1227/24227 [00:00<00:08, 2788.47 examples/s]Applying chat template to train dataset:   5%|▌         | 1212/24227 [00:00<00:08, 2730.08 examples/s]Applying chat template to train dataset:   8%|▊         | 1926/24227 [00:00<00:07, 2796.73 examples/s]Applying chat template to train dataset:   7%|▋         | 1615/24227 [00:00<00:08, 2697.89 examples/s]Applying chat template to train dataset:   7%|▋         | 1634/24227 [00:00<00:08, 2762.41 examples/s]Applying chat template to train dataset:  10%|▉         | 2366/24227 [00:00<00:07, 2847.97 examples/s]Applying chat template to train dataset:   8%|▊         | 1912/24227 [00:00<00:08, 2775.04 examples/s]Applying chat template to train dataset:   8%|▊         | 1950/24227 [00:00<00:08, 2483.12 examples/s]Applying chat template to train dataset:  11%|█         | 2658/24227 [00:00<00:07, 2865.02 examples/s]Applying chat template to train dataset:   9%|▉         | 2209/24227 [00:00<00:07, 2829.66 examples/s]Applying chat template to train dataset:   9%|▉         | 2256/24227 [00:00<00:08, 2634.43 examples/s]Applying chat template to train dataset:  10%|█         | 2512/24227 [00:00<00:07, 2883.73 examples/s]Applying chat template to train dataset:  13%|█▎        | 3098/24227 [00:01<00:07, 2887.32 examples/s]Applying chat template to train dataset:  12%|█▏        | 2810/24227 [00:01<00:07, 2858.37 examples/s]Applying chat template to train dataset:  11%|█         | 2681/24227 [00:01<00:07, 2704.14 examples/s]Applying chat template to train dataset:  14%|█▍        | 3467/24227 [00:01<00:07, 2737.65 examples/s]Applying chat template to train dataset:  12%|█▏        | 2967/24227 [00:01<00:07, 2701.27 examples/s]Applying chat template to train dataset:  13%|█▎        | 3240/24227 [00:01<00:07, 2856.21 examples/s]Applying chat template to train dataset:  13%|█▎        | 3254/24227 [00:01<00:07, 2744.01 examples/s]Applying chat template to train dataset:  16%|█▌        | 3881/24227 [00:01<00:07, 2739.87 examples/s]Applying chat template to train dataset:  15%|█▌        | 3653/24227 [00:01<00:07, 2816.63 examples/s]Applying chat template to train dataset:  17%|█▋        | 4175/24227 [00:01<00:07, 2786.87 examples/s]Applying chat template to train dataset:  15%|█▌        | 3660/24227 [00:01<00:07, 2727.12 examples/s]Applying chat template to train dataset:  16%|█▋        | 3959/24227 [00:01<00:07, 2876.93 examples/s]Applying chat template to train dataset:  18%|█▊        | 4467/24227 [00:01<00:07, 2818.38 examples/s]Applying chat template to train dataset:  16%|█▋        | 3955/24227 [00:01<00:07, 2782.29 examples/s]Applying chat template to train dataset:  18%|█▊        | 4260/24227 [00:01<00:06, 2908.72 examples/s]Applying chat template to train dataset:  20%|█▉        | 4790/24227 [00:01<00:07, 2566.73 examples/s]Applying chat template to train dataset:  18%|█▊        | 4319/24227 [00:01<00:07, 2652.94 examples/s]Applying chat template to train dataset:  19%|█▉        | 4672/24227 [00:01<00:06, 2846.12 examples/s]Applying chat template to train dataset:  21%|██        | 5066/24227 [00:01<00:07, 2611.90 examples/s]Applying chat template to train dataset:  19%|█▉        | 4615/24227 [00:01<00:07, 2728.37 examples/s]Applying chat template to train dataset:  21%|██        | 5067/24227 [00:01<00:06, 2771.37 examples/s]Applying chat template to train dataset:  20%|██        | 4919/24227 [00:01<00:06, 2803.89 examples/s]Applying chat template to train dataset:  23%|██▎       | 5479/24227 [00:02<00:07, 2653.66 examples/s]Applying chat template to train dataset:  23%|██▎       | 5478/24227 [00:01<00:06, 2758.09 examples/s]Applying chat template to train dataset:  22%|██▏       | 5294/24227 [00:01<00:07, 2692.32 examples/s]Applying chat template to train dataset:  24%|██▍       | 5865/24227 [00:02<00:07, 2556.99 examples/s]Applying chat template to train dataset:  24%|██▍       | 5867/24227 [00:02<00:06, 2688.38 examples/s]Applying chat template to train dataset:  25%|██▌       | 6161/24227 [00:02<00:06, 2647.46 examples/s]Applying chat template to train dataset:  24%|██▎       | 5708/24227 [00:02<00:06, 2705.85 examples/s]Applying chat template to train dataset:  25%|██▌       | 6151/24227 [00:02<00:06, 2721.82 examples/s]Applying chat template to train dataset:  27%|██▋       | 6437/24227 [00:02<00:06, 2673.20 examples/s]Applying chat template to train dataset:  25%|██▌       | 6085/24227 [00:02<00:06, 2640.83 examples/s]Applying chat template to train dataset:  27%|██▋       | 6434/24227 [00:02<00:06, 2747.30 examples/s]Applying chat template to train dataset:  28%|██▊       | 6763/24227 [00:02<00:07, 2413.66 examples/s]Applying chat template to train dataset:  26%|██▌       | 6354/24227 [00:02<00:06, 2650.92 examples/s]Applying chat template to train dataset:  28%|██▊       | 6741/24227 [00:02<00:06, 2830.14 examples/s]Applying chat template to train dataset:  29%|██▉       | 7037/24227 [00:02<00:06, 2862.18 examples/s]Applying chat template to train dataset:  30%|██▉       | 7163/24227 [00:02<00:06, 2491.90 examples/s]Applying chat template to train dataset:  28%|██▊       | 6727/24227 [00:02<00:06, 2592.87 examples/s]Applying chat template to train dataset:  30%|███       | 7330/24227 [00:02<00:05, 2878.56 examples/s]Applying chat template to train dataset:  31%|███       | 7430/24227 [00:02<00:06, 2530.89 examples/s]Applying chat template to train dataset:  29%|██▉       | 7120/24227 [00:02<00:06, 2595.92 examples/s]Applying chat template to train dataset:  32%|███▏      | 7640/24227 [00:02<00:05, 2937.63 examples/s]Applying chat template to train dataset:  32%|███▏      | 7744/24227 [00:02<00:06, 2681.22 examples/s]Applying chat template to train dataset:  31%|███       | 7521/24227 [00:02<00:06, 2618.14 examples/s]Applying chat template to train dataset:  33%|███▎      | 7978/24227 [00:02<00:06, 2672.73 examples/s]Applying chat template to train dataset:  34%|███▎      | 8121/24227 [00:03<00:06, 2619.05 examples/s]Applying chat template to train dataset:  34%|███▍      | 8291/24227 [00:02<00:05, 2792.79 examples/s]Applying chat template to train dataset:  35%|███▍      | 8440/24227 [00:03<00:05, 2759.48 examples/s]Applying chat template to train dataset:  33%|███▎      | 7948/24227 [00:02<00:06, 2683.67 examples/s]Applying chat template to train dataset:  36%|███▌      | 8742/24227 [00:03<00:05, 2867.19 examples/s]Applying chat template to train dataset:  36%|███▌      | 8775/24227 [00:03<00:07, 2050.96 examples/s]Applying chat template to train dataset:  34%|███▍      | 8282/24227 [00:03<00:07, 2057.90 examples/s]Applying chat template to train dataset:  38%|███▊      | 9121/24227 [00:03<00:05, 2748.52 examples/s]Applying chat template to train dataset:  38%|███▊      | 9092/24227 [00:03<00:06, 2283.61 examples/s]Applying chat template to train dataset:  35%|███▌      | 8581/24227 [00:03<00:07, 2234.59 examples/s]Applying chat template to train dataset:  39%|███▉      | 9404/24227 [00:03<00:05, 2767.47 examples/s]Applying chat template to train dataset:  39%|███▉      | 9391/24227 [00:03<00:06, 2444.95 examples/s]Applying chat template to train dataset:  37%|███▋      | 8891/24227 [00:03<00:06, 2419.15 examples/s]Applying chat template to train dataset:  41%|████      | 9848/24227 [00:03<00:05, 2828.31 examples/s]Applying chat template to train dataset:  40%|████      | 9697/24227 [00:03<00:05, 2595.95 examples/s]Applying chat template to train dataset:  38%|███▊      | 9192/24227 [00:03<00:05, 2555.11 examples/s]Applying chat template to train dataset:  41%|████▏     | 10014/24227 [00:03<00:05, 2743.35 examples/s]Applying chat template to train dataset:  39%|███▉      | 9513/24227 [00:03<00:05, 2718.16 examples/s]Applying chat template to train dataset:  42%|████▏     | 10290/24227 [00:03<00:04, 2858.11 examples/s]Applying chat template to train dataset:  43%|████▎     | 10411/24227 [00:03<00:05, 2707.74 examples/s]Applying chat template to train dataset:  41%|████      | 9899/24227 [00:03<00:05, 2666.20 examples/s]Applying chat template to train dataset:  44%|████▍     | 10717/24227 [00:03<00:04, 2851.61 examples/s]Applying chat template to train dataset:  44%|████▍     | 10720/24227 [00:04<00:04, 2800.13 examples/s]Applying chat template to train dataset:  42%|████▏     | 10214/24227 [00:03<00:05, 2785.17 examples/s]Applying chat template to train dataset:  46%|████▌     | 11030/24227 [00:03<00:04, 2911.06 examples/s]Applying chat template to train dataset:  46%|████▌     | 11030/24227 [00:04<00:04, 2875.84 examples/s]Applying chat template to train dataset:  44%|████▍     | 10640/24227 [00:04<00:04, 2796.80 examples/s]Applying chat template to train dataset:  47%|████▋     | 11486/24227 [00:04<00:04, 2952.78 examples/s]Applying chat template to train dataset:  47%|████▋     | 11443/24227 [00:04<00:04, 2827.55 examples/s]Applying chat template to train dataset:  46%|████▌     | 11081/24227 [00:04<00:04, 2840.70 examples/s]Applying chat template to train dataset:  49%|████▉     | 11939/24227 [00:04<00:04, 2968.87 examples/s]Applying chat template to train dataset:  49%|████▉     | 11887/24227 [00:04<00:04, 2869.76 examples/s]Applying chat template to train dataset:  47%|████▋     | 11372/24227 [00:04<00:04, 2855.49 examples/s]Applying chat template to train dataset:  51%|█████     | 12260/24227 [00:04<00:03, 3020.45 examples/s]Applying chat template to train dataset:  50%|█████     | 12220/24227 [00:04<00:04, 2609.10 examples/s]Applying chat template to train dataset:  48%|████▊     | 11697/24227 [00:04<00:05, 2392.14 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12596/24227 [00:04<00:04, 2588.50 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12538/24227 [00:04<00:04, 2740.94 examples/s]Applying chat template to train dataset:  50%|████▉     | 11995/24227 [00:04<00:04, 2524.75 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12903/24227 [00:04<00:04, 2696.74 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12857/24227 [00:04<00:03, 2849.03 examples/s]Applying chat template to train dataset:  51%|█████     | 12312/24227 [00:04<00:04, 2681.30 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13203/24227 [00:04<00:03, 2768.53 examples/s]Applying chat template to train dataset:  55%|█████▍    | 13293/24227 [00:04<00:03, 2867.06 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12739/24227 [00:04<00:04, 2734.13 examples/s]Applying chat template to train dataset:  56%|█████▌    | 13620/24227 [00:04<00:03, 2771.01 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13026/24227 [00:04<00:04, 2766.89 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13708/24227 [00:05<00:03, 2831.15 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14020/24227 [00:05<00:03, 2734.51 examples/s]Applying chat template to train dataset:  55%|█████▌    | 13330/24227 [00:05<00:03, 2835.90 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14013/24227 [00:05<00:03, 2881.43 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14314/24227 [00:05<00:03, 2782.25 examples/s]Applying chat template to train dataset:  56%|█████▋    | 13629/24227 [00:05<00:03, 2875.89 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14310/24227 [00:05<00:03, 2900.57 examples/s]Applying chat template to train dataset:  60%|██████    | 14625/24227 [00:05<00:03, 2864.26 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13926/24227 [00:05<00:03, 2899.60 examples/s]Applying chat template to train dataset:  62%|██████▏   | 14920/24227 [00:05<00:03, 2883.76 examples/s]Applying chat template to train dataset:  61%|██████    | 14765/24227 [00:05<00:03, 2941.93 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14365/24227 [00:05<00:03, 2907.31 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15300/24227 [00:05<00:03, 2754.63 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15120/24227 [00:05<00:03, 2741.10 examples/s]Applying chat template to train dataset:  61%|██████    | 14766/24227 [00:05<00:03, 2823.50 examples/s]Applying chat template to train dataset:  64%|██████▍   | 15591/24227 [00:05<00:03, 2793.49 examples/s]Applying chat template to train dataset:  64%|██████▍   | 15555/24227 [00:05<00:03, 2790.45 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15061/24227 [00:05<00:03, 2853.64 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15891/24227 [00:05<00:02, 2845.61 examples/s]Applying chat template to train dataset:  65%|██████▌   | 15860/24227 [00:05<00:02, 2845.72 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16281/24227 [00:05<00:02, 2754.34 examples/s]Applying chat template to train dataset:  64%|██████▎   | 15438/24227 [00:05<00:03, 2662.63 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16293/24227 [00:06<00:02, 2855.51 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16585/24227 [00:05<00:02, 2823.76 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15711/24227 [00:05<00:03, 2676.03 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16591/24227 [00:06<00:02, 2883.27 examples/s]Applying chat template to train dataset:  70%|██████▉   | 16885/24227 [00:06<00:02, 2868.35 examples/s]Applying chat template to train dataset:  70%|██████▉   | 16888/24227 [00:06<00:02, 2905.24 examples/s]Applying chat template to train dataset:  66%|██████▋   | 16105/24227 [00:06<00:03, 2655.96 examples/s]Applying chat template to train dataset:  71%|███████▏  | 17321/24227 [00:06<00:02, 2878.69 examples/s]Applying chat template to train dataset:  71%|███████▏  | 17298/24227 [00:06<00:02, 2838.49 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16484/24227 [00:06<00:02, 2611.14 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17639/24227 [00:06<00:02, 2954.19 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17612/24227 [00:06<00:02, 2912.50 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16772/24227 [00:06<00:02, 2673.70 examples/s]Applying chat template to train dataset:  74%|███████▍  | 17942/24227 [00:06<00:02, 2971.47 examples/s]Applying chat template to train dataset:  74%|███████▍  | 17913/24227 [00:06<00:02, 2937.04 examples/s]Applying chat template to train dataset:  71%|███████   | 17193/24227 [00:06<00:02, 2716.84 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18330/24227 [00:06<00:02, 2824.65 examples/s]Applying chat template to train dataset:  75%|███████▌  | 18277/24227 [00:06<00:02, 2749.37 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17527/24227 [00:06<00:02, 2552.94 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18767/24227 [00:06<00:01, 2852.51 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18599/24227 [00:06<00:01, 2868.10 examples/s]Applying chat template to train dataset:  74%|███████▎  | 17810/24227 [00:06<00:02, 2617.14 examples/s]Applying chat template to train dataset:  79%|███████▉  | 19088/24227 [00:06<00:01, 2939.64 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18918/24227 [00:06<00:01, 2952.17 examples/s]Applying chat template to train dataset:  75%|███████▌  | 18191/24227 [00:06<00:02, 2589.34 examples/s]Applying chat template to train dataset:  80%|████████  | 19502/24227 [00:06<00:01, 2874.18 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19324/24227 [00:07<00:01, 2858.50 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19828/24227 [00:07<00:01, 2966.49 examples/s]Applying chat template to train dataset:  81%|████████  | 19650/24227 [00:07<00:01, 2958.59 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18590/24227 [00:07<00:02, 2608.71 examples/s]Applying chat template to train dataset:  84%|████████▎ | 20260/24227 [00:07<00:01, 2932.14 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20073/24227 [00:07<00:01, 2907.12 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18976/24227 [00:07<00:02, 2594.09 examples/s]Applying chat template to train dataset:  85%|████████▌ | 20684/24227 [00:07<00:01, 2894.31 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20496/24227 [00:07<00:01, 2875.62 examples/s]Applying chat template to train dataset:  80%|████████  | 19382/24227 [00:07<00:01, 2627.28 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21001/24227 [00:07<00:01, 2958.36 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20810/24227 [00:07<00:01, 2938.46 examples/s]Applying chat template to train dataset:  81%|████████  | 19674/24227 [00:07<00:01, 2691.06 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21312/24227 [00:07<00:00, 2995.76 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21115/24227 [00:07<00:01, 2964.59 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19961/24227 [00:07<00:01, 2734.11 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21732/24227 [00:07<00:00, 2923.00 examples/s]Applying chat template to train dataset:  89%|████████▊ | 21488/24227 [00:07<00:00, 2791.96 examples/s]Applying chat template to train dataset:  84%|████████▍ | 20315/24227 [00:07<00:01, 2602.39 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21774/24227 [00:07<00:00, 2807.33 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20592/24227 [00:07<00:01, 2642.43 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22190/24227 [00:07<00:00, 2965.18 examples/s]Applying chat template to train dataset:  91%|█████████ | 22100/24227 [00:08<00:00, 2920.04 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20890/24227 [00:07<00:01, 2726.44 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22502/24227 [00:07<00:00, 3002.32 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22419/24227 [00:08<00:00, 2990.63 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21202/24227 [00:07<00:01, 2829.46 examples/s]Applying chat template to train dataset:  94%|█████████▍| 22820/24227 [00:08<00:00, 3041.15 examples/s]Applying chat template to train dataset:  94%|█████████▍| 22848/24227 [00:08<00:00, 2939.21 examples/s]Applying chat template to train dataset:  89%|████████▉ | 21593/24227 [00:08<00:00, 2744.70 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23267/24227 [00:08<00:00, 3017.32 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23263/24227 [00:08<00:00, 2877.46 examples/s]Applying chat template to train dataset:  91%|█████████ | 21935/24227 [00:08<00:00, 2548.36 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23720/24227 [00:08<00:00, 3011.97 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23584/24227 [00:08<00:00, 2957.45 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22263/24227 [00:08<00:00, 2725.60 examples/s]Applying chat template to train dataset:  99%|█████████▉| 24036/24227 [00:08<00:00, 3045.38 examples/s]Applying chat template to train dataset:  99%|█████████▊| 23910/24227 [00:08<00:00, 3032.06 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:08<00:00, 2848.87 examples/s]
Applying chat template to train dataset:  94%|█████████▎| 22679/24227 [00:08<00:00, 2739.38 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:08<00:00, 2986.58 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:08<00:00, 2760.25 examples/s]
Applying chat template to train dataset:  95%|█████████▍| 23003/24227 [00:08<00:00, 2860.84 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23303/24227 [00:08<00:00, 2893.74 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23767/24227 [00:08<00:00, 2962.85 examples/s]Applying chat template to train dataset:  99%|█████████▉| 24092/24227 [00:08<00:00, 3032.85 examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:09<00:00, 2683.69 examples/s]
Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/24227 [00:00<00:59, 405.71 examples/s]Tokenizing train dataset:   0%|          | 41/24227 [00:00<01:03, 383.37 examples/s]Tokenizing train dataset:   0%|          | 85/24227 [00:00<01:16, 315.86 examples/s]Tokenizing train dataset:   0%|          | 83/24227 [00:00<01:19, 301.91 examples/s]Tokenizing train dataset:   1%|          | 123/24227 [00:00<01:25, 281.66 examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 118/24227 [00:00<01:31, 262.28 examples/s]Tokenizing train dataset:   1%|          | 153/24227 [00:00<01:24, 283.52 examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 406.23 examples/s]Tokenizing train dataset:   1%|          | 150/24227 [00:00<01:57, 205.31 examples/s]Tokenizing train dataset:   1%|          | 182/24227 [00:00<01:56, 206.82 examples/s]Tokenizing train dataset:   0%|          | 90/24227 [00:00<01:12, 333.96 examples/s]Tokenizing train dataset:   1%|          | 211/24227 [00:00<01:46, 226.35 examples/s]Tokenizing train dataset:   1%|          | 181/24227 [00:00<01:58, 202.57 examples/s]Tokenizing train dataset:   1%|          | 244/24227 [00:00<01:36, 248.65 examples/s]Tokenizing train dataset:   1%|          | 136/24227 [00:00<01:17, 311.63 examples/s]Tokenizing train dataset:   1%|          | 212/24227 [00:00<01:47, 223.93 examples/s]Tokenizing train dataset:   1%|          | 272/24227 [00:01<01:34, 254.61 examples/s]Tokenizing train dataset:   1%|          | 240/24227 [00:01<01:42, 234.19 examples/s]Tokenizing train dataset:   1%|          | 174/24227 [00:00<01:25, 282.56 examples/s]Tokenizing train dataset:   1%|          | 300/24227 [00:01<01:32, 258.84 examples/s]Tokenizing train dataset:   1%|          | 270/24227 [00:01<01:37, 246.57 examples/s]Tokenizing train dataset:   1%|          | 204/24227 [00:00<01:24, 284.57 examples/s]Tokenizing train dataset:   1%|          | 299/24227 [00:01<01:33, 254.85 examples/s]Tokenizing train dataset:   1%|▏         | 341/24227 [00:01<01:31, 259.98 examples/s]Tokenizing train dataset:   1%|          | 247/24227 [00:00<01:24, 283.70 examples/s]Tokenizing train dataset:   1%|▏         | 328/24227 [00:01<01:31, 261.69 examples/s]Tokenizing train dataset:   2%|▏         | 369/24227 [00:01<01:30, 264.21 examples/s]Tokenizing train dataset:   1%|          | 278/24227 [00:00<01:22, 289.92 examples/s]Tokenizing train dataset:   2%|▏         | 399/24227 [00:01<01:27, 271.25 examples/s]Tokenizing train dataset:   2%|▏         | 367/24227 [00:01<01:32, 256.81 examples/s]Tokenizing train dataset:   1%|▏         | 309/24227 [00:01<01:21, 293.35 examples/s]Tokenizing train dataset:   2%|▏         | 428/24227 [00:01<01:26, 274.11 examples/s]Tokenizing train dataset:   2%|▏         | 397/24227 [00:01<01:30, 263.18 examples/s]Tokenizing train dataset:   1%|▏         | 350/24227 [00:01<01:24, 283.21 examples/s]Tokenizing train dataset:   2%|▏         | 427/24227 [00:01<01:27, 271.18 examples/s]Tokenizing train dataset:   2%|▏         | 470/24227 [00:01<01:26, 273.27 examples/s]Tokenizing train dataset:   2%|▏         | 387/24227 [00:01<01:49, 218.56 examples/s]Tokenizing train dataset:   2%|▏         | 501/24227 [00:02<01:56, 203.62 examples/s]Tokenizing train dataset:   2%|▏         | 470/24227 [00:02<01:59, 199.56 examples/s]Tokenizing train dataset:   2%|▏         | 416/24227 [00:01<01:42, 231.51 examples/s]Tokenizing train dataset:   2%|▏         | 528/24227 [00:02<01:50, 215.02 examples/s]Tokenizing train dataset:   2%|▏         | 505/24227 [00:02<01:56, 203.72 examples/s]Tokenizing train dataset:   2%|▏         | 557/24227 [00:02<01:43, 227.86 examples/s]Tokenizing train dataset:   2%|▏         | 456/24227 [00:01<01:39, 238.87 examples/s]Tokenizing train dataset:   2%|▏         | 535/24227 [00:02<01:46, 221.69 examples/s]Tokenizing train dataset:   2%|▏         | 596/24227 [00:02<01:40, 234.85 examples/s]Tokenizing train dataset:   2%|▏         | 487/24227 [00:01<01:48, 219.56 examples/s]Tokenizing train dataset:   2%|▏         | 562/24227 [00:02<01:42, 231.36 examples/s]Tokenizing train dataset:   3%|▎         | 636/24227 [00:02<01:38, 239.61 examples/s]Tokenizing train dataset:   2%|▏         | 525/24227 [00:02<01:43, 228.42 examples/s]Tokenizing train dataset:   2%|▏         | 599/24227 [00:02<01:40, 234.29 examples/s]Tokenizing train dataset:   3%|▎         | 665/24227 [00:02<01:35, 246.46 examples/s]Tokenizing train dataset:   2%|▏         | 549/24227 [00:02<01:42, 230.27 examples/s]Tokenizing train dataset:   3%|▎         | 625/24227 [00:02<01:39, 236.37 examples/s]Tokenizing train dataset:   2%|▏         | 577/24227 [00:02<01:38, 239.65 examples/s]Tokenizing train dataset:   3%|▎         | 656/24227 [00:02<01:33, 250.91 examples/s]Tokenizing train dataset:   3%|▎         | 703/24227 [00:02<01:36, 244.01 examples/s]Tokenizing train dataset:   3%|▎         | 733/24227 [00:02<01:32, 254.83 examples/s]Tokenizing train dataset:   3%|▎         | 617/24227 [00:02<01:35, 247.51 examples/s]Tokenizing train dataset:   3%|▎         | 695/24227 [00:02<01:34, 248.03 examples/s]Tokenizing train dataset:   3%|▎         | 761/24227 [00:03<01:30, 258.03 examples/s]Tokenizing train dataset:   3%|▎         | 650/24227 [00:02<01:29, 264.06 examples/s]Tokenizing train dataset:   3%|▎         | 739/24227 [00:03<01:31, 256.61 examples/s]Tokenizing train dataset:   3%|▎         | 799/24227 [00:03<01:33, 251.45 examples/s]Tokenizing train dataset:   3%|▎         | 689/24227 [00:02<01:31, 256.44 examples/s]Tokenizing train dataset:   3%|▎         | 774/24227 [00:03<01:35, 244.57 examples/s]Tokenizing train dataset:   3%|▎         | 840/24227 [00:03<01:32, 252.31 examples/s]Tokenizing train dataset:   3%|▎         | 735/24227 [00:02<01:27, 268.40 examples/s]Tokenizing train dataset:   3%|▎         | 812/24227 [00:03<01:36, 242.76 examples/s]Tokenizing train dataset:   4%|▎         | 867/24227 [00:03<01:32, 251.26 examples/s]Tokenizing train dataset:   3%|▎         | 774/24227 [00:02<01:29, 263.22 examples/s]Tokenizing train dataset:   3%|▎         | 840/24227 [00:03<01:46, 220.13 examples/s]Tokenizing train dataset:   4%|▎         | 907/24227 [00:03<01:33, 249.79 examples/s]Tokenizing train dataset:   3%|▎         | 806/24227 [00:03<01:35, 246.39 examples/s]Tokenizing train dataset:   4%|▎         | 867/24227 [00:03<01:42, 228.67 examples/s]Tokenizing train dataset:   3%|▎         | 834/24227 [00:03<01:34, 248.55 examples/s]Tokenizing train dataset:   4%|▍         | 942/24227 [00:03<01:36, 241.46 examples/s]Tokenizing train dataset:   4%|▎         | 903/24227 [00:03<01:30, 256.36 examples/s]Tokenizing train dataset:   4%|▎         | 863/24227 [00:03<01:31, 255.17 examples/s]Tokenizing train dataset:   4%|▍         | 971/24227 [00:03<01:33, 249.27 examples/s]Tokenizing train dataset:   4%|▍         | 940/24227 [00:03<01:33, 249.59 examples/s]Tokenizing train dataset:   4%|▎         | 899/24227 [00:03<01:23, 279.14 examples/s]Tokenizing train dataset:   4%|▍         | 1011/24227 [00:04<01:32, 249.97 examples/s]Tokenizing train dataset:   4%|▍         | 966/24227 [00:04<01:33, 248.03 examples/s]Tokenizing train dataset:   4%|▍         | 1038/24227 [00:04<01:31, 252.19 examples/s]Tokenizing train dataset:   4%|▍         | 930/24227 [00:03<01:36, 241.22 examples/s]Tokenizing train dataset:   4%|▍         | 1000/24227 [00:04<01:37, 237.19 examples/s]Tokenizing train dataset:   4%|▍         | 1068/24227 [00:04<01:28, 262.40 examples/s]Tokenizing train dataset:   4%|▍         | 956/24227 [00:03<01:35, 243.74 examples/s]Tokenizing train dataset:   4%|▍         | 1026/24227 [00:04<01:37, 238.95 examples/s]Tokenizing train dataset:   5%|▍         | 1100/24227 [00:04<01:23, 275.60 examples/s]Tokenizing train dataset:   4%|▍         | 983/24227 [00:03<01:33, 247.34 examples/s]Tokenizing train dataset:   4%|▍         | 1061/24227 [00:04<01:38, 234.08 examples/s]Tokenizing train dataset:   5%|▍         | 1133/24227 [00:04<01:30, 254.99 examples/s]Tokenizing train dataset:   4%|▍         | 1021/24227 [00:03<01:34, 244.64 examples/s]Tokenizing train dataset:   5%|▍         | 1091/24227 [00:04<01:33, 248.40 examples/s]Tokenizing train dataset:   5%|▍         | 1160/24227 [00:04<01:30, 254.47 examples/s]Tokenizing train dataset:   4%|▍         | 1062/24227 [00:04<01:33, 247.21 examples/s]Tokenizing train dataset:   5%|▍         | 1117/24227 [00:04<01:33, 247.33 examples/s]Tokenizing train dataset:   5%|▍         | 1203/24227 [00:04<01:28, 260.58 examples/s]Tokenizing train dataset:   5%|▍         | 1094/24227 [00:04<01:28, 261.96 examples/s]Tokenizing train dataset:   5%|▍         | 1151/24227 [00:04<01:38, 233.71 examples/s]Tokenizing train dataset:   5%|▌         | 1239/24227 [00:04<01:37, 236.25 examples/s]Tokenizing train dataset:   5%|▍         | 1124/24227 [00:04<01:42, 224.94 examples/s]Tokenizing train dataset:   5%|▍         | 1191/24227 [00:04<01:35, 241.06 examples/s]Tokenizing train dataset:   5%|▌         | 1273/24227 [00:05<01:42, 223.74 examples/s]Tokenizing train dataset:   5%|▍         | 1153/24227 [00:04<01:49, 210.54 examples/s]Tokenizing train dataset:   5%|▌         | 1218/24227 [00:05<01:33, 245.45 examples/s]Tokenizing train dataset:   5%|▌         | 1298/24227 [00:05<01:40, 227.10 examples/s]Tokenizing train dataset:   5%|▌         | 1246/24227 [00:05<01:31, 250.55 examples/s]Tokenizing train dataset:   5%|▍         | 1193/24227 [00:04<01:43, 223.31 examples/s]Tokenizing train dataset:   5%|▌         | 1326/24227 [00:05<01:36, 238.00 examples/s]Tokenizing train dataset:   5%|▌         | 1222/24227 [00:04<01:37, 235.55 examples/s]Tokenizing train dataset:   5%|▌         | 1283/24227 [00:05<01:33, 244.13 examples/s]Tokenizing train dataset:   6%|▌         | 1354/24227 [00:05<01:33, 245.42 examples/s]Tokenizing train dataset:   5%|▌         | 1252/24227 [00:04<01:32, 248.70 examples/s]Tokenizing train dataset:   5%|▌         | 1310/24227 [00:05<01:32, 248.57 examples/s]Tokenizing train dataset:   6%|▌         | 1381/24227 [00:05<01:32, 247.20 examples/s]Tokenizing train dataset:   5%|▌         | 1280/24227 [00:05<01:30, 253.78 examples/s]Tokenizing train dataset:   6%|▌         | 1337/24227 [00:05<01:31, 249.99 examples/s]Tokenizing train dataset:   6%|▌         | 1407/24227 [00:05<01:32, 247.95 examples/s]Tokenizing train dataset:   5%|▌         | 1312/24227 [00:05<01:25, 267.75 examples/s]Tokenizing train dataset:   6%|▌         | 1435/24227 [00:05<01:29, 254.80 examples/s]Tokenizing train dataset:   6%|▌         | 1370/24227 [00:05<01:37, 233.88 examples/s]Tokenizing train dataset:   6%|▌         | 1463/24227 [00:05<01:27, 258.99 examples/s]Tokenizing train dataset:   6%|▌         | 1348/24227 [00:05<01:31, 250.44 examples/s]Tokenizing train dataset:   6%|▌         | 1400/24227 [00:05<01:33, 245.16 examples/s]Tokenizing train dataset:   6%|▌         | 1492/24227 [00:05<01:26, 262.57 examples/s]Tokenizing train dataset:   6%|▌         | 1428/24227 [00:05<01:30, 252.83 examples/s]Tokenizing train dataset:   6%|▌         | 1390/24227 [00:05<01:30, 251.13 examples/s]Tokenizing train dataset:   6%|▌         | 1456/24227 [00:06<01:29, 253.74 examples/s]Tokenizing train dataset:   6%|▋         | 1538/24227 [00:06<01:22, 274.78 examples/s]Tokenizing train dataset:   6%|▌         | 1421/24227 [00:05<01:26, 262.77 examples/s]Tokenizing train dataset:   6%|▋         | 1567/24227 [00:06<01:21, 276.73 examples/s]Tokenizing train dataset:   6%|▌         | 1449/24227 [00:05<01:26, 263.11 examples/s]Tokenizing train dataset:   6%|▌         | 1494/24227 [00:06<01:31, 247.71 examples/s]Tokenizing train dataset:   7%|▋         | 1596/24227 [00:06<01:22, 273.38 examples/s]Tokenizing train dataset:   6%|▌         | 1476/24227 [00:05<01:26, 262.77 examples/s]Tokenizing train dataset:   6%|▋         | 1537/24227 [00:06<01:29, 254.43 examples/s]Tokenizing train dataset:   7%|▋         | 1640/24227 [00:06<01:21, 277.38 examples/s]Tokenizing train dataset:   6%|▋         | 1515/24227 [00:05<01:27, 258.68 examples/s]Tokenizing train dataset:   6%|▋         | 1573/24227 [00:06<01:32, 245.33 examples/s]Tokenizing train dataset:   7%|▋         | 1670/24227 [00:06<01:21, 276.46 examples/s]Tokenizing train dataset:   6%|▋         | 1547/24227 [00:06<01:24, 268.85 examples/s]Tokenizing train dataset:   7%|▋         | 1600/24227 [00:06<01:31, 247.68 examples/s]Tokenizing train dataset:   7%|▋         | 1707/24227 [00:06<01:14, 300.76 examples/s]Tokenizing train dataset:   7%|▋         | 1590/24227 [00:06<01:24, 269.48 examples/s]Tokenizing train dataset:   7%|▋         | 1632/24227 [00:06<01:26, 261.42 examples/s]Tokenizing train dataset:   7%|▋         | 1739/24227 [00:06<01:13, 304.51 examples/s]Tokenizing train dataset:   7%|▋         | 1621/24227 [00:06<01:21, 277.48 examples/s]Tokenizing train dataset:   7%|▋         | 1671/24227 [00:06<01:27, 259.11 examples/s]Tokenizing train dataset:   7%|▋         | 1788/24227 [00:06<01:12, 309.30 examples/s]Tokenizing train dataset:   7%|▋         | 1654/24227 [00:06<01:18, 288.84 examples/s]Tokenizing train dataset:   7%|▋         | 1705/24227 [00:06<01:21, 277.83 examples/s]Tokenizing train dataset:   7%|▋         | 1685/24227 [00:06<01:17, 291.05 examples/s]Tokenizing train dataset:   8%|▊         | 1828/24227 [00:07<01:17, 287.57 examples/s]Tokenizing train dataset:   7%|▋         | 1750/24227 [00:07<01:19, 284.12 examples/s]Tokenizing train dataset:   7%|▋         | 1721/24227 [00:06<01:13, 304.91 examples/s]Tokenizing train dataset:   8%|▊         | 1858/24227 [00:07<01:18, 285.81 examples/s]Tokenizing train dataset:   7%|▋         | 1763/24227 [00:06<01:17, 291.61 examples/s]Tokenizing train dataset:   7%|▋         | 1793/24227 [00:07<01:19, 280.63 examples/s]Tokenizing train dataset:   8%|▊         | 1896/24227 [00:07<01:22, 269.60 examples/s]Tokenizing train dataset:   7%|▋         | 1794/24227 [00:06<01:16, 293.41 examples/s]Tokenizing train dataset:   8%|▊         | 1829/24227 [00:07<01:25, 262.19 examples/s]Tokenizing train dataset:   8%|▊         | 1932/24227 [00:07<01:26, 257.29 examples/s]Tokenizing train dataset:   8%|▊         | 1834/24227 [00:07<01:20, 279.63 examples/s]Tokenizing train dataset:   8%|▊         | 1864/24227 [00:07<01:29, 250.66 examples/s]Tokenizing train dataset:   8%|▊         | 1964/24227 [00:07<01:31, 242.53 examples/s]Tokenizing train dataset:   8%|▊         | 1866/24227 [00:07<01:17, 288.06 examples/s]Tokenizing train dataset:   8%|▊         | 1992/24227 [00:07<01:29, 249.00 examples/s]Tokenizing train dataset:   8%|▊         | 1898/24227 [00:07<01:32, 240.68 examples/s]Tokenizing train dataset:   8%|▊         | 1900/24227 [00:07<01:25, 261.93 examples/s]Tokenizing train dataset:   8%|▊         | 2025/24227 [00:07<01:23, 265.23 examples/s]Tokenizing train dataset:   8%|▊         | 1932/24227 [00:07<01:35, 232.42 examples/s]Tokenizing train dataset:   8%|▊         | 2056/24227 [00:08<01:20, 274.37 examples/s]Tokenizing train dataset:   8%|▊         | 1936/24227 [00:07<01:28, 251.62 examples/s]Tokenizing train dataset:   8%|▊         | 1958/24227 [00:08<01:34, 236.66 examples/s]Tokenizing train dataset:   8%|▊         | 1962/24227 [00:07<01:28, 250.96 examples/s]Tokenizing train dataset:   9%|▊         | 2096/24227 [00:08<01:22, 268.49 examples/s]Tokenizing train dataset:   8%|▊         | 1989/24227 [00:07<01:27, 255.26 examples/s]Tokenizing train dataset:   8%|▊         | 1988/24227 [00:08<01:39, 222.45 examples/s]Tokenizing train dataset:   9%|▉         | 2126/24227 [00:08<01:21, 272.06 examples/s]Tokenizing train dataset:   8%|▊         | 2015/24227 [00:07<01:27, 254.52 examples/s]Tokenizing train dataset:   8%|▊         | 2013/24227 [00:08<01:38, 226.20 examples/s]Tokenizing train dataset:   9%|▉         | 2168/24227 [00:08<01:21, 269.47 examples/s]Tokenizing train dataset:   8%|▊         | 2042/24227 [00:07<01:27, 253.21 examples/s]Tokenizing train dataset:   8%|▊         | 2036/24227 [00:08<01:38, 226.34 examples/s]Tokenizing train dataset:   9%|▉         | 2196/24227 [00:08<01:21, 269.91 examples/s]Tokenizing train dataset:   9%|▊         | 2073/24227 [00:07<01:22, 268.77 examples/s]Tokenizing train dataset:   9%|▊         | 2065/24227 [00:08<01:32, 239.06 examples/s]Tokenizing train dataset:   9%|▊         | 2106/24227 [00:08<01:18, 283.16 examples/s]Tokenizing train dataset:   9%|▊         | 2094/24227 [00:08<01:28, 250.09 examples/s]Tokenizing train dataset:   9%|▉         | 2243/24227 [00:08<01:18, 279.58 examples/s]Tokenizing train dataset:   9%|▉         | 2135/24227 [00:08<01:18, 280.47 examples/s]Tokenizing train dataset:   9%|▉         | 2126/24227 [00:08<01:23, 264.06 examples/s]Tokenizing train dataset:   9%|▉         | 2272/24227 [00:08<01:18, 279.60 examples/s]Tokenizing train dataset:   9%|▉         | 2178/24227 [00:08<01:19, 277.06 examples/s]Tokenizing train dataset:   9%|▉         | 2166/24227 [00:08<01:24, 261.47 examples/s]Tokenizing train dataset:  10%|▉         | 2305/24227 [00:08<01:25, 255.47 examples/s]Tokenizing train dataset:   9%|▉         | 2194/24227 [00:08<01:23, 262.35 examples/s]Tokenizing train dataset:   9%|▉         | 2220/24227 [00:08<01:20, 272.80 examples/s]Tokenizing train dataset:  10%|▉         | 2336/24227 [00:09<01:34, 231.80 examples/s]Tokenizing train dataset:   9%|▉         | 2255/24227 [00:08<01:16, 287.76 examples/s]Tokenizing train dataset:   9%|▉         | 2239/24227 [00:09<01:21, 268.22 examples/s]Tokenizing train dataset:  10%|▉         | 2360/24227 [00:09<01:34, 231.22 examples/s]Tokenizing train dataset:   9%|▉         | 2267/24227 [00:09<01:22, 266.65 examples/s]Tokenizing train dataset:   9%|▉         | 2296/24227 [00:08<01:18, 280.45 examples/s]Tokenizing train dataset:  10%|▉         | 2395/24227 [00:09<01:35, 229.05 examples/s]Tokenizing train dataset:   9%|▉         | 2297/24227 [00:09<01:42, 213.73 examples/s]Tokenizing train dataset:  10%|▉         | 2327/24227 [00:08<01:33, 234.93 examples/s]Tokenizing train dataset:  10%|█         | 2429/24227 [00:09<01:36, 225.22 examples/s]Tokenizing train dataset:  10%|▉         | 2322/24227 [00:09<01:38, 221.42 examples/s]Tokenizing train dataset:  10%|▉         | 2352/24227 [00:09<01:32, 236.30 examples/s]Tokenizing train dataset:  10%|█         | 2463/24227 [00:09<01:38, 221.48 examples/s]Tokenizing train dataset:  10%|▉         | 2380/24227 [00:09<01:29, 242.99 examples/s]Tokenizing train dataset:  10%|▉         | 2360/24227 [00:09<01:36, 227.38 examples/s]Tokenizing train dataset:  10%|█         | 2494/24227 [00:09<01:31, 238.63 examples/s]Tokenizing train dataset:  10%|▉         | 2406/24227 [00:09<01:30, 241.41 examples/s]Tokenizing train dataset:  10%|▉         | 2385/24227 [00:09<01:34, 230.24 examples/s]Tokenizing train dataset:  10%|█         | 2437/24227 [00:09<01:24, 258.52 examples/s]Tokenizing train dataset:  10%|█         | 2526/24227 [00:09<01:35, 226.93 examples/s]Tokenizing train dataset:  10%|▉         | 2413/24227 [00:09<01:30, 241.09 examples/s]Tokenizing train dataset:  11%|█         | 2555/24227 [00:10<01:30, 238.65 examples/s]Tokenizing train dataset:  10%|█         | 2443/24227 [00:10<01:26, 253.15 examples/s]Tokenizing train dataset:  10%|█         | 2477/24227 [00:09<01:24, 258.67 examples/s]Tokenizing train dataset:  11%|█         | 2591/24227 [00:10<01:36, 224.86 examples/s]Tokenizing train dataset:  10%|█         | 2470/24227 [00:10<01:51, 195.49 examples/s]Tokenizing train dataset:  10%|█         | 2514/24227 [00:09<02:02, 176.82 examples/s]Tokenizing train dataset:  11%|█         | 2626/24227 [00:10<02:15, 159.00 examples/s]Tokenizing train dataset:  10%|█         | 2500/24227 [00:10<02:37, 138.12 examples/s]Tokenizing train dataset:  11%|█         | 2545/24227 [00:10<02:22, 151.91 examples/s]Tokenizing train dataset:  11%|█         | 2660/24227 [00:10<02:23, 150.50 examples/s]Tokenizing train dataset:  10%|█         | 2523/24227 [00:11<05:57, 60.74 examples/s] Tokenizing train dataset:  11%|█         | 2579/24227 [00:11<04:52, 74.13 examples/s] Tokenizing train dataset:  11%|█         | 2695/24227 [00:11<05:05, 70.39 examples/s] Tokenizing train dataset:  10%|█         | 2538/24227 [00:11<06:22, 56.68 examples/s]Tokenizing train dataset:  11%|█         | 2600/24227 [00:11<05:06, 70.45 examples/s]Tokenizing train dataset:  11%|█         | 2713/24227 [00:12<04:48, 74.48 examples/s]Tokenizing train dataset:  11%|█         | 2556/24227 [00:12<05:26, 66.38 examples/s]Tokenizing train dataset:  11%|█         | 2627/24227 [00:11<04:04, 88.46 examples/s]Tokenizing train dataset:  11%|█▏        | 2728/24227 [00:12<04:41, 76.40 examples/s]Tokenizing train dataset:  11%|█         | 2573/24227 [00:12<08:34, 42.07 examples/s]Tokenizing train dataset:  11%|█         | 2647/24227 [00:13<11:15, 31.95 examples/s]Tokenizing train dataset:  11%|█▏        | 2744/24227 [00:14<13:00, 27.53 examples/s]Tokenizing train dataset:  11%|█         | 2592/24227 [00:14<13:07, 27.49 examples/s]Tokenizing train dataset:  11%|█         | 2664/24227 [00:13<09:29, 37.87 examples/s]Tokenizing train dataset:  11%|█▏        | 2766/24227 [00:14<09:38, 37.12 examples/s]Tokenizing train dataset:  11%|█         | 2619/24227 [00:14<08:48, 40.90 examples/s]Tokenizing train dataset:  11%|█         | 2689/24227 [00:13<06:58, 51.50 examples/s]Tokenizing train dataset:  11%|█▏        | 2782/24227 [00:14<07:53, 45.25 examples/s]Tokenizing train dataset:  11%|█         | 2640/24227 [00:14<06:45, 53.26 examples/s]Tokenizing train dataset:  11%|█         | 2718/24227 [00:13<05:00, 71.49 examples/s]Tokenizing train dataset:  12%|█▏        | 2815/24227 [00:14<05:07, 69.58 examples/s]Tokenizing train dataset:  11%|█         | 2665/24227 [00:14<05:00, 71.81 examples/s]Tokenizing train dataset:  11%|█▏        | 2744/24227 [00:14<03:55, 91.10 examples/s]Tokenizing train dataset:  12%|█▏        | 2839/24227 [00:14<04:03, 87.81 examples/s]Tokenizing train dataset:  11%|█         | 2695/24227 [00:14<03:37, 98.81 examples/s]Tokenizing train dataset:  11%|█▏        | 2769/24227 [00:14<03:12, 111.33 examples/s]Tokenizing train dataset:  11%|█         | 2723/24227 [00:14<02:53, 124.18 examples/s]Tokenizing train dataset:  12%|█▏        | 2870/24227 [00:14<03:14, 109.86 examples/s]Tokenizing train dataset:  12%|█▏        | 2800/24227 [00:14<02:31, 141.56 examples/s]Tokenizing train dataset:  11%|█▏        | 2750/24227 [00:14<02:25, 147.56 examples/s]Tokenizing train dataset:  12%|█▏        | 2899/24227 [00:14<02:36, 136.26 examples/s]Tokenizing train dataset:  12%|█▏        | 2827/24227 [00:14<02:11, 163.08 examples/s]Tokenizing train dataset:  11%|█▏        | 2776/24227 [00:14<02:08, 166.43 examples/s]Tokenizing train dataset:  12%|█▏        | 2925/24227 [00:15<02:14, 157.92 examples/s]Tokenizing train dataset:  12%|█▏        | 2861/24227 [00:14<02:01, 176.35 examples/s]Tokenizing train dataset:  12%|█▏        | 2810/24227 [00:15<01:57, 181.97 examples/s]Tokenizing train dataset:  12%|█▏        | 2960/24227 [00:15<01:59, 177.85 examples/s]Tokenizing train dataset:  12%|█▏        | 2889/24227 [00:14<01:48, 197.30 examples/s]Tokenizing train dataset:  12%|█▏        | 2836/24227 [00:15<01:47, 198.49 examples/s]Tokenizing train dataset:  12%|█▏        | 2989/24227 [00:15<01:46, 199.06 examples/s]Tokenizing train dataset:  12%|█▏        | 2861/24227 [00:15<01:42, 209.31 examples/s]Tokenizing train dataset:  12%|█▏        | 2920/24227 [00:14<01:52, 189.50 examples/s]Tokenizing train dataset:  12%|█▏        | 3022/24227 [00:15<01:44, 203.11 examples/s]Tokenizing train dataset:  12%|█▏        | 2888/24227 [00:15<01:35, 222.29 examples/s]Tokenizing train dataset:  12%|█▏        | 2950/24227 [00:14<01:40, 212.43 examples/s]Tokenizing train dataset:  13%|█▎        | 3049/24227 [00:15<01:38, 215.86 examples/s]Tokenizing train dataset:  12%|█▏        | 2915/24227 [00:15<01:32, 230.30 examples/s]Tokenizing train dataset:  12%|█▏        | 2976/24227 [00:15<01:36, 220.81 examples/s]Tokenizing train dataset:  12%|█▏        | 2942/24227 [00:15<01:29, 237.81 examples/s]Tokenizing train dataset:  13%|█▎        | 3088/24227 [00:15<01:33, 225.91 examples/s]Tokenizing train dataset:  12%|█▏        | 3012/24227 [00:15<01:33, 226.65 examples/s]Tokenizing train dataset:  12%|█▏        | 2970/24227 [00:15<01:25, 247.54 examples/s]Tokenizing train dataset:  13%|█▎        | 3119/24227 [00:15<01:26, 242.76 examples/s]Tokenizing train dataset:  13%|█▎        | 3048/24227 [00:15<01:31, 230.21 examples/s]Tokenizing train dataset:  12%|█▏        | 3004/24227 [00:15<01:29, 237.01 examples/s]Tokenizing train dataset:  13%|█▎        | 3148/24227 [00:15<01:34, 223.10 examples/s]Tokenizing train dataset:  13%|█▎        | 3087/24227 [00:15<01:29, 236.85 examples/s]Tokenizing train dataset:  13%|█▎        | 3030/24227 [00:15<01:28, 239.24 examples/s]Tokenizing train dataset:  13%|█▎        | 3176/24227 [00:16<01:29, 234.16 examples/s]Tokenizing train dataset:  13%|█▎        | 3119/24227 [00:15<01:23, 251.43 examples/s]Tokenizing train dataset:  13%|█▎        | 3057/24227 [00:16<01:26, 244.97 examples/s]Tokenizing train dataset:  13%|█▎        | 3206/24227 [00:16<01:24, 248.63 examples/s]Tokenizing train dataset:  13%|█▎        | 3157/24227 [00:15<01:24, 248.24 examples/s]Tokenizing train dataset:  13%|█▎        | 3091/24227 [00:16<01:29, 236.58 examples/s]Tokenizing train dataset:  13%|█▎        | 3239/24227 [00:16<01:29, 235.35 examples/s]Tokenizing train dataset:  13%|█▎        | 3188/24227 [00:15<01:21, 258.22 examples/s]Tokenizing train dataset:  13%|█▎        | 3264/24227 [00:16<01:28, 235.99 examples/s]Tokenizing train dataset:  13%|█▎        | 3127/24227 [00:16<01:30, 232.81 examples/s]Tokenizing train dataset:  14%|█▎        | 3292/24227 [00:16<01:25, 244.98 examples/s]Tokenizing train dataset:  13%|█▎        | 3230/24227 [00:16<01:20, 260.89 examples/s]Tokenizing train dataset:  13%|█▎        | 3167/24227 [00:16<01:27, 240.73 examples/s]Tokenizing train dataset:  14%|█▎        | 3321/24227 [00:16<01:46, 195.57 examples/s]Tokenizing train dataset:  13%|█▎        | 3266/24227 [00:16<01:28, 237.68 examples/s]Tokenizing train dataset:  13%|█▎        | 3204/24227 [00:16<01:28, 237.60 examples/s]Tokenizing train dataset:  14%|█▍        | 3353/24227 [00:16<01:46, 195.97 examples/s]Tokenizing train dataset:  14%|█▎        | 3299/24227 [00:16<01:33, 224.59 examples/s]Tokenizing train dataset:  13%|█▎        | 3238/24227 [00:16<01:30, 231.70 examples/s]Tokenizing train dataset:  14%|█▍        | 3380/24227 [00:17<01:50, 187.88 examples/s]Tokenizing train dataset:  14%|█▎        | 3329/24227 [00:16<01:36, 215.87 examples/s]Tokenizing train dataset:  13%|█▎        | 3270/24227 [00:17<01:37, 214.44 examples/s]Tokenizing train dataset:  14%|█▎        | 3295/24227 [00:17<01:35, 219.23 examples/s]Tokenizing train dataset:  14%|█▍        | 3410/24227 [00:17<01:50, 189.05 examples/s]Tokenizing train dataset:  14%|█▍        | 3363/24227 [00:16<01:36, 216.44 examples/s]Tokenizing train dataset:  14%|█▍        | 3430/24227 [00:17<01:51, 186.83 examples/s]Tokenizing train dataset:  14%|█▎        | 3330/24227 [00:17<01:35, 219.86 examples/s]Tokenizing train dataset:  14%|█▍        | 3390/24227 [00:16<01:42, 204.18 examples/s]Tokenizing train dataset:  14%|█▍        | 3451/24227 [00:17<01:49, 189.26 examples/s]Tokenizing train dataset:  14%|█▍        | 3357/24227 [00:17<01:31, 229.16 examples/s]Tokenizing train dataset:  14%|█▍        | 3415/24227 [00:16<01:38, 210.76 examples/s]Tokenizing train dataset:  14%|█▍        | 3472/24227 [00:17<01:48, 191.58 examples/s]Tokenizing train dataset:  14%|█▍        | 3438/24227 [00:17<01:37, 213.47 examples/s]Tokenizing train dataset:  14%|█▍        | 3390/24227 [00:17<01:34, 221.57 examples/s]Tokenizing train dataset:  15%|█▍        | 3513/24227 [00:17<01:34, 218.78 examples/s]Tokenizing train dataset:  14%|█▍        | 3416/24227 [00:17<01:30, 229.59 examples/s]Tokenizing train dataset:  14%|█▍        | 3470/24227 [00:17<01:38, 209.99 examples/s]Tokenizing train dataset:  15%|█▍        | 3537/24227 [00:17<01:33, 222.34 examples/s]Tokenizing train dataset:  15%|█▍        | 3570/24227 [00:17<01:22, 249.90 examples/s]Tokenizing train dataset:  14%|█▍        | 3443/24227 [00:17<01:38, 210.18 examples/s]Tokenizing train dataset:  14%|█▍        | 3511/24227 [00:17<01:32, 225.01 examples/s]Tokenizing train dataset:  15%|█▍        | 3597/24227 [00:17<01:21, 252.86 examples/s]Tokenizing train dataset:  15%|█▍        | 3543/24227 [00:17<01:25, 242.13 examples/s]Tokenizing train dataset:  14%|█▍        | 3472/24227 [00:17<01:41, 203.92 examples/s]Tokenizing train dataset:  15%|█▍        | 3629/24227 [00:18<01:16, 269.73 examples/s]Tokenizing train dataset:  15%|█▍        | 3580/24227 [00:17<01:16, 270.00 examples/s]Tokenizing train dataset:  15%|█▍        | 3518/24227 [00:18<01:28, 232.94 examples/s]Tokenizing train dataset:  15%|█▍        | 3610/24227 [00:17<01:15, 271.52 examples/s]Tokenizing train dataset:  15%|█▌        | 3673/24227 [00:18<01:15, 273.59 examples/s]Tokenizing train dataset:  15%|█▍        | 3547/24227 [00:18<01:24, 243.69 examples/s]Tokenizing train dataset:  15%|█▌        | 3642/24227 [00:17<01:12, 282.69 examples/s]Tokenizing train dataset:  15%|█▍        | 3575/24227 [00:18<01:22, 251.12 examples/s]Tokenizing train dataset:  15%|█▌        | 3713/24227 [00:18<01:16, 268.41 examples/s]Tokenizing train dataset:  15%|█▌        | 3676/24227 [00:17<01:09, 294.94 examples/s]Tokenizing train dataset:  15%|█▍        | 3610/24227 [00:18<01:25, 240.19 examples/s]Tokenizing train dataset:  15%|█▌        | 3741/24227 [00:18<01:26, 238.02 examples/s]Tokenizing train dataset:  15%|█▌        | 3719/24227 [00:18<01:20, 255.76 examples/s]Tokenizing train dataset:  15%|█▌        | 3636/24227 [00:18<01:24, 242.46 examples/s]Tokenizing train dataset:  16%|█▌        | 3771/24227 [00:18<01:22, 249.02 examples/s]Tokenizing train dataset:  16%|█▌        | 3800/24227 [00:18<01:19, 257.58 examples/s]Tokenizing train dataset:  15%|█▌        | 3669/24227 [00:18<01:19, 258.58 examples/s]Tokenizing train dataset:  16%|█▌        | 3768/24227 [00:18<01:14, 274.76 examples/s]Tokenizing train dataset:  16%|█▌        | 3832/24227 [00:18<01:14, 273.03 examples/s]Tokenizing train dataset:  15%|█▌        | 3704/24227 [00:18<01:23, 246.94 examples/s]Tokenizing train dataset:  16%|█▌        | 3811/24227 [00:18<01:13, 276.31 examples/s]Tokenizing train dataset:  16%|█▌        | 3860/24227 [00:18<01:14, 271.81 examples/s]Tokenizing train dataset:  15%|█▌        | 3738/24227 [00:19<01:27, 235.32 examples/s]Tokenizing train dataset:  16%|█▌        | 3852/24227 [00:18<01:14, 272.56 examples/s]Tokenizing train dataset:  16%|█▌        | 3898/24227 [00:19<01:18, 257.54 examples/s]Tokenizing train dataset:  16%|█▌        | 3772/24227 [00:19<01:20, 255.59 examples/s]Tokenizing train dataset:  16%|█▌        | 3895/24227 [00:18<01:14, 273.37 examples/s]Tokenizing train dataset:  16%|█▌        | 3933/24227 [00:19<01:23, 242.16 examples/s]Tokenizing train dataset:  16%|█▌        | 3808/24227 [00:19<01:22, 247.11 examples/s]Tokenizing train dataset:  16%|█▋        | 3959/24227 [00:19<01:22, 246.12 examples/s]Tokenizing train dataset:  16%|█▌        | 3933/24227 [00:18<01:17, 262.20 examples/s]Tokenizing train dataset:  16%|█▌        | 3837/24227 [00:19<01:19, 255.37 examples/s]Tokenizing train dataset:  16%|█▋        | 3987/24227 [00:19<01:20, 252.15 examples/s]Tokenizing train dataset:  16%|█▋        | 3962/24227 [00:18<01:15, 267.11 examples/s]Tokenizing train dataset:  16%|█▌        | 3866/24227 [00:19<01:18, 259.42 examples/s]Tokenizing train dataset:  17%|█▋        | 4018/24227 [00:19<01:17, 261.62 examples/s]Tokenizing train dataset:  16%|█▋        | 3990/24227 [00:19<01:16, 266.26 examples/s]Tokenizing train dataset:  17%|█▋        | 4045/24227 [00:19<01:16, 262.37 examples/s]Tokenizing train dataset:  16%|█▌        | 3904/24227 [00:19<01:20, 253.35 examples/s]Tokenizing train dataset:  17%|█▋        | 4018/24227 [00:19<01:15, 267.07 examples/s]Tokenizing train dataset:  17%|█▋        | 4088/24227 [00:19<01:15, 267.28 examples/s]Tokenizing train dataset:  16%|█▌        | 3936/24227 [00:19<01:26, 233.76 examples/s]Tokenizing train dataset:  17%|█▋        | 4058/24227 [00:19<01:16, 264.48 examples/s]Tokenizing train dataset:  17%|█▋        | 4118/24227 [00:19<01:13, 275.35 examples/s]Tokenizing train dataset:  16%|█▋        | 3963/24227 [00:19<01:24, 238.93 examples/s]Tokenizing train dataset:  17%|█▋        | 4100/24227 [00:19<01:15, 267.32 examples/s]Tokenizing train dataset:  17%|█▋        | 4146/24227 [00:20<01:13, 272.16 examples/s]Tokenizing train dataset:  17%|█▋        | 4001/24227 [00:20<01:24, 240.62 examples/s]Tokenizing train dataset:  17%|█▋        | 4130/24227 [00:19<01:14, 270.97 examples/s]Tokenizing train dataset:  17%|█▋        | 4175/24227 [00:20<01:12, 275.40 examples/s]Tokenizing train dataset:  17%|█▋        | 4040/24227 [00:20<01:22, 243.70 examples/s]Tokenizing train dataset:  17%|█▋        | 4166/24227 [00:19<01:17, 257.59 examples/s]Tokenizing train dataset:  17%|█▋        | 4211/24227 [00:20<01:16, 260.92 examples/s]Tokenizing train dataset:  17%|█▋        | 4194/24227 [00:19<01:17, 258.31 examples/s]Tokenizing train dataset:  17%|█▋        | 4079/24227 [00:20<01:22, 244.38 examples/s]Tokenizing train dataset:  18%|█▊        | 4252/24227 [00:20<01:16, 262.79 examples/s]Tokenizing train dataset:  17%|█▋        | 4235/24227 [00:20<01:16, 261.11 examples/s]Tokenizing train dataset:  17%|█▋        | 4111/24227 [00:20<01:18, 256.96 examples/s]Tokenizing train dataset:  18%|█▊        | 4281/24227 [00:20<01:14, 266.79 examples/s]Tokenizing train dataset:  18%|█▊        | 4309/24227 [00:20<01:14, 268.52 examples/s]Tokenizing train dataset:  18%|█▊        | 4275/24227 [00:20<01:16, 261.32 examples/s]Tokenizing train dataset:  17%|█▋        | 4151/24227 [00:20<01:18, 257.10 examples/s]Tokenizing train dataset:  18%|█▊        | 4340/24227 [00:20<01:12, 275.01 examples/s]Tokenizing train dataset:  18%|█▊        | 4314/24227 [00:20<01:17, 255.63 examples/s]Tokenizing train dataset:  17%|█▋        | 4194/24227 [00:20<01:16, 262.48 examples/s]Tokenizing train dataset:  18%|█▊        | 4381/24227 [00:20<01:13, 271.08 examples/s]Tokenizing train dataset:  18%|█▊        | 4347/24227 [00:20<01:13, 269.91 examples/s]Tokenizing train dataset:  17%|█▋        | 4230/24227 [00:20<01:19, 250.40 examples/s]Tokenizing train dataset:  18%|█▊        | 4418/24227 [00:21<01:27, 225.32 examples/s]Tokenizing train dataset:  18%|█▊        | 4259/24227 [00:21<01:35, 209.53 examples/s]Tokenizing train dataset:  18%|█▊        | 4390/24227 [00:20<01:36, 206.33 examples/s]Tokenizing train dataset:  18%|█▊        | 4449/24227 [00:21<01:22, 240.93 examples/s]Tokenizing train dataset:  18%|█▊        | 4289/24227 [00:21<01:28, 224.75 examples/s]Tokenizing train dataset:  18%|█▊        | 4422/24227 [00:20<01:27, 226.57 examples/s]Tokenizing train dataset:  19%|█▊        | 4488/24227 [00:21<01:21, 242.72 examples/s]Tokenizing train dataset:  18%|█▊        | 4324/24227 [00:21<01:28, 225.95 examples/s]Tokenizing train dataset:  19%|█▊        | 4517/24227 [00:21<01:17, 252.74 examples/s]Tokenizing train dataset:  18%|█▊        | 4457/24227 [00:21<01:27, 224.71 examples/s]Tokenizing train dataset:  18%|█▊        | 4350/24227 [00:21<01:26, 230.80 examples/s]Tokenizing train dataset:  19%|█▉        | 4553/24227 [00:21<01:20, 245.60 examples/s]Tokenizing train dataset:  19%|█▊        | 4487/24227 [00:21<01:31, 215.86 examples/s]Tokenizing train dataset:  18%|█▊        | 4376/24227 [00:21<01:24, 234.10 examples/s]Tokenizing train dataset:  18%|█▊        | 4405/24227 [00:21<01:20, 247.63 examples/s]Tokenizing train dataset:  19%|█▉        | 4597/24227 [00:21<01:16, 256.23 examples/s]Tokenizing train dataset:  19%|█▊        | 4525/24227 [00:21<01:28, 222.07 examples/s]Tokenizing train dataset:  18%|█▊        | 4435/24227 [00:21<01:17, 256.96 examples/s]Tokenizing train dataset:  19%|█▉        | 4627/24227 [00:22<01:32, 211.60 examples/s]Tokenizing train dataset:  19%|█▉        | 4556/24227 [00:21<01:47, 183.53 examples/s]Tokenizing train dataset:  18%|█▊        | 4465/24227 [00:22<01:31, 216.37 examples/s]Tokenizing train dataset:  19%|█▉        | 4656/24227 [00:22<01:26, 225.38 examples/s]Tokenizing train dataset:  19%|█▉        | 4591/24227 [00:21<01:41, 193.94 examples/s]Tokenizing train dataset:  19%|█▊        | 4500/24227 [00:22<01:31, 214.83 examples/s]Tokenizing train dataset:  19%|█▉        | 4693/24227 [00:22<01:25, 227.55 examples/s]Tokenizing train dataset:  19%|█▉        | 4620/24227 [00:21<01:32, 211.37 examples/s]Tokenizing train dataset:  19%|█▊        | 4527/24227 [00:22<01:27, 225.81 examples/s]Tokenizing train dataset:  19%|█▉        | 4647/24227 [00:21<01:29, 219.08 examples/s]Tokenizing train dataset:  19%|█▉        | 4555/24227 [00:22<01:23, 235.97 examples/s]Tokenizing train dataset:  20%|█▉        | 4725/24227 [00:22<01:29, 218.82 examples/s]Tokenizing train dataset:  19%|█▉        | 4674/24227 [00:22<01:25, 228.29 examples/s]Tokenizing train dataset:  20%|█▉        | 4755/24227 [00:22<01:22, 235.34 examples/s]Tokenizing train dataset:  19%|█▉        | 4597/24227 [00:22<01:19, 245.67 examples/s]Tokenizing train dataset:  19%|█▉        | 4699/24227 [00:22<01:24, 231.01 examples/s]Tokenizing train dataset:  20%|█▉        | 4791/24227 [00:22<01:23, 233.44 examples/s]Tokenizing train dataset:  20%|█▉        | 4725/24227 [00:22<01:22, 236.32 examples/s]Tokenizing train dataset:  19%|█▉        | 4636/24227 [00:22<01:19, 246.19 examples/s]Tokenizing train dataset:  20%|█▉        | 4819/24227 [00:22<01:20, 241.07 examples/s]Tokenizing train dataset:  20%|█▉        | 4752/24227 [00:22<01:20, 241.04 examples/s]Tokenizing train dataset:  19%|█▉        | 4662/24227 [00:22<01:19, 245.02 examples/s]Tokenizing train dataset:  20%|█▉        | 4778/24227 [00:22<01:20, 241.98 examples/s]Tokenizing train dataset:  20%|██        | 4848/24227 [00:23<01:27, 222.26 examples/s]Tokenizing train dataset:  19%|█▉        | 4695/24227 [00:23<01:23, 232.64 examples/s]Tokenizing train dataset:  20%|█▉        | 4814/24227 [00:22<01:21, 238.17 examples/s]Tokenizing train dataset:  20%|██        | 4882/24227 [00:23<01:27, 220.80 examples/s]Tokenizing train dataset:  19%|█▉        | 4722/24227 [00:23<01:35, 205.01 examples/s]Tokenizing train dataset:  20%|██        | 4909/24227 [00:23<01:23, 230.96 examples/s]Tokenizing train dataset:  20%|██        | 4848/24227 [00:22<01:23, 230.83 examples/s]Tokenizing train dataset:  20%|█▉        | 4752/24227 [00:23<01:26, 224.71 examples/s]Tokenizing train dataset:  20%|██        | 4936/24227 [00:23<01:21, 236.08 examples/s]Tokenizing train dataset:  20%|█▉        | 4776/24227 [00:23<01:25, 226.79 examples/s]Tokenizing train dataset:  20%|██        | 4887/24227 [00:22<01:21, 238.24 examples/s]Tokenizing train dataset:  21%|██        | 4971/24227 [00:23<01:24, 229.14 examples/s]Tokenizing train dataset:  20%|█▉        | 4800/24227 [00:23<01:25, 227.00 examples/s]Tokenizing train dataset:  20%|██        | 4914/24227 [00:23<01:19, 242.60 examples/s]Tokenizing train dataset:  20%|██        | 4939/24227 [00:23<01:19, 241.34 examples/s]Tokenizing train dataset:  21%|██        | 5009/24227 [00:23<01:21, 235.29 examples/s]Tokenizing train dataset:  20%|█▉        | 4830/24227 [00:23<01:30, 214.50 examples/s]Tokenizing train dataset:  21%|██        | 5039/24227 [00:23<01:17, 247.62 examples/s]Tokenizing train dataset:  20%|██        | 4964/24227 [00:23<01:24, 227.42 examples/s]Tokenizing train dataset:  20%|██        | 4856/24227 [00:23<01:26, 223.64 examples/s]Tokenizing train dataset:  21%|██        | 5065/24227 [00:23<01:17, 248.76 examples/s]Tokenizing train dataset:  21%|██        | 4988/24227 [00:23<01:23, 229.11 examples/s]Tokenizing train dataset:  20%|██        | 4892/24227 [00:23<01:26, 223.73 examples/s]Tokenizing train dataset:  21%|██        | 5091/24227 [00:24<01:17, 248.00 examples/s]Tokenizing train dataset:  21%|██        | 5018/24227 [00:23<01:19, 242.66 examples/s]Tokenizing train dataset:  20%|██        | 4916/24227 [00:24<01:25, 225.35 examples/s]Tokenizing train dataset:  21%|██        | 5119/24227 [00:24<01:15, 254.14 examples/s]Tokenizing train dataset:  21%|██        | 5050/24227 [00:23<01:13, 261.87 examples/s]Tokenizing train dataset:  20%|██        | 4941/24227 [00:24<01:24, 228.86 examples/s]Tokenizing train dataset:  21%|██        | 5146/24227 [00:24<01:14, 255.27 examples/s]Tokenizing train dataset:  21%|██        | 5077/24227 [00:23<01:13, 259.52 examples/s]Tokenizing train dataset:  21%|██        | 4978/24227 [00:24<01:27, 219.20 examples/s]Tokenizing train dataset:  21%|██▏       | 5182/24227 [00:24<01:17, 245.56 examples/s]Tokenizing train dataset:  21%|██        | 5119/24227 [00:23<01:13, 259.95 examples/s]Tokenizing train dataset:  21%|██        | 5008/24227 [00:24<01:21, 235.54 examples/s]Tokenizing train dataset:  22%|██▏       | 5211/24227 [00:24<01:14, 256.85 examples/s]Tokenizing train dataset:  21%|██▏       | 5155/24227 [00:24<01:16, 250.71 examples/s]Tokenizing train dataset:  22%|██▏       | 5239/24227 [00:24<01:12, 261.30 examples/s]Tokenizing train dataset:  21%|██        | 5040/24227 [00:24<01:15, 252.79 examples/s]Tokenizing train dataset:  21%|██▏       | 5192/24227 [00:24<01:17, 244.23 examples/s]Tokenizing train dataset:  22%|██▏       | 5271/24227 [00:24<01:18, 242.32 examples/s]Tokenizing train dataset:  21%|██        | 5077/24227 [00:24<01:17, 246.70 examples/s]Tokenizing train dataset:  22%|██▏       | 5219/24227 [00:24<01:16, 247.23 examples/s]Tokenizing train dataset:  22%|██▏       | 5300/24227 [00:24<01:25, 221.65 examples/s]Tokenizing train dataset:  21%|██        | 5107/24227 [00:24<01:23, 228.48 examples/s]Tokenizing train dataset:  22%|██▏       | 5255/24227 [00:24<01:18, 242.15 examples/s]Tokenizing train dataset:  21%|██        | 5135/24227 [00:24<01:20, 238.48 examples/s]Tokenizing train dataset:  22%|██▏       | 5336/24227 [00:25<01:24, 224.48 examples/s]Tokenizing train dataset:  21%|██▏       | 5160/24227 [00:25<01:20, 237.46 examples/s]Tokenizing train dataset:  22%|██▏       | 5291/24227 [00:24<01:19, 238.46 examples/s]Tokenizing train dataset:  22%|██▏       | 5377/24227 [00:25<01:10, 267.14 examples/s]Tokenizing train dataset:  21%|██▏       | 5186/24227 [00:25<01:19, 239.07 examples/s]Tokenizing train dataset:  22%|██▏       | 5326/24227 [00:24<01:20, 234.70 examples/s]Tokenizing train dataset:  22%|██▏       | 5423/24227 [00:25<01:08, 275.49 examples/s]Tokenizing train dataset:  22%|██▏       | 5213/24227 [00:25<01:17, 246.33 examples/s]Tokenizing train dataset:  22%|██▏       | 5351/24227 [00:24<01:20, 235.25 examples/s]Tokenizing train dataset:  23%|██▎       | 5456/24227 [00:25<01:13, 255.01 examples/s]Tokenizing train dataset:  22%|██▏       | 5390/24227 [00:24<01:09, 269.51 examples/s]Tokenizing train dataset:  22%|██▏       | 5244/24227 [00:25<01:26, 218.41 examples/s]Tokenizing train dataset:  23%|██▎       | 5486/24227 [00:25<01:11, 263.12 examples/s]Tokenizing train dataset:  22%|██▏       | 5418/24227 [00:25<01:09, 271.33 examples/s]Tokenizing train dataset:  22%|██▏       | 5267/24227 [00:25<01:26, 218.28 examples/s]Tokenizing train dataset:  23%|██▎       | 5518/24227 [00:25<01:08, 273.55 examples/s]Tokenizing train dataset:  22%|██▏       | 5450/24227 [00:25<01:06, 280.29 examples/s]Tokenizing train dataset:  22%|██▏       | 5300/24227 [00:25<01:29, 212.25 examples/s]Tokenizing train dataset:  23%|██▎       | 5480/24227 [00:25<01:06, 282.59 examples/s]Tokenizing train dataset:  23%|██▎       | 5560/24227 [00:25<01:08, 270.60 examples/s]Tokenizing train dataset:  22%|██▏       | 5335/24227 [00:25<01:28, 214.12 examples/s]Tokenizing train dataset:  23%|██▎       | 5602/24227 [00:25<01:01, 303.49 examples/s]Tokenizing train dataset:  23%|██▎       | 5520/24227 [00:25<01:08, 272.19 examples/s]Tokenizing train dataset:  22%|██▏       | 5378/24227 [00:26<01:29, 210.75 examples/s]Tokenizing train dataset:  23%|██▎       | 5634/24227 [00:26<01:21, 227.34 examples/s]Tokenizing train dataset:  23%|██▎       | 5549/24227 [00:25<01:31, 204.42 examples/s]Tokenizing train dataset:  22%|██▏       | 5400/24227 [00:26<01:28, 211.78 examples/s]Tokenizing train dataset:  23%|██▎       | 5675/24227 [00:26<01:19, 232.29 examples/s]Tokenizing train dataset:  23%|██▎       | 5588/24227 [00:25<01:28, 211.16 examples/s]Tokenizing train dataset:  22%|██▏       | 5440/24227 [00:26<01:23, 224.76 examples/s]Tokenizing train dataset:  24%|██▎       | 5704/24227 [00:26<01:16, 242.81 examples/s]Tokenizing train dataset:  23%|██▎       | 5614/24227 [00:25<01:24, 220.31 examples/s]Tokenizing train dataset:  23%|██▎       | 5470/24227 [00:26<01:35, 197.04 examples/s]Tokenizing train dataset:  24%|██▎       | 5737/24227 [00:26<01:20, 229.63 examples/s]Tokenizing train dataset:  23%|██▎       | 5652/24227 [00:26<01:21, 229.28 examples/s]Tokenizing train dataset:  23%|██▎       | 5497/24227 [00:26<01:28, 210.81 examples/s]Tokenizing train dataset:  24%|██▍       | 5762/24227 [00:26<01:20, 228.99 examples/s]Tokenizing train dataset:  23%|██▎       | 5686/24227 [00:26<01:13, 253.47 examples/s]Tokenizing train dataset:  23%|██▎       | 5526/24227 [00:26<01:22, 227.45 examples/s]Tokenizing train dataset:  24%|██▍       | 5791/24227 [00:26<01:29, 205.67 examples/s]Tokenizing train dataset:  24%|██▎       | 5717/24227 [00:26<01:26, 213.69 examples/s]Tokenizing train dataset:  23%|██▎       | 5555/24227 [00:26<01:28, 210.52 examples/s]Tokenizing train dataset:  24%|██▍       | 5827/24227 [00:27<01:26, 212.67 examples/s]Tokenizing train dataset:  24%|██▎       | 5753/24227 [00:26<01:24, 218.51 examples/s]Tokenizing train dataset:  23%|██▎       | 5596/24227 [00:27<01:21, 228.16 examples/s]Tokenizing train dataset:  24%|██▍       | 5858/24227 [00:27<01:18, 232.86 examples/s]Tokenizing train dataset:  23%|██▎       | 5625/24227 [00:27<01:17, 240.00 examples/s]Tokenizing train dataset:  24%|██▍       | 5791/24227 [00:26<01:21, 226.37 examples/s]Tokenizing train dataset:  24%|██▍       | 5888/24227 [00:27<01:15, 244.02 examples/s]Tokenizing train dataset:  23%|██▎       | 5661/24227 [00:27<01:18, 237.93 examples/s]Tokenizing train dataset:  24%|██▍       | 5831/24227 [00:26<01:18, 233.71 examples/s]Tokenizing train dataset:  24%|██▍       | 5921/24227 [00:27<01:17, 235.06 examples/s]Tokenizing train dataset:  23%|██▎       | 5692/24227 [00:27<01:13, 252.72 examples/s]Tokenizing train dataset:  24%|██▍       | 5869/24227 [00:26<01:09, 262.64 examples/s]Tokenizing train dataset:  25%|██▍       | 5951/24227 [00:27<01:13, 247.45 examples/s]Tokenizing train dataset:  24%|██▎       | 5719/24227 [00:27<01:12, 255.03 examples/s]Tokenizing train dataset:  24%|██▍       | 5898/24227 [00:27<01:08, 266.52 examples/s]Tokenizing train dataset:  25%|██▍       | 5990/24227 [00:27<01:13, 248.92 examples/s]Tokenizing train dataset:  24%|██▎       | 5748/24227 [00:27<01:11, 259.67 examples/s]Tokenizing train dataset:  25%|██▍       | 5940/24227 [00:27<01:08, 268.07 examples/s]Tokenizing train dataset:  25%|██▍       | 6028/24227 [00:27<01:14, 243.95 examples/s]Tokenizing train dataset:  24%|██▍       | 5788/24227 [00:27<01:23, 220.51 examples/s]Tokenizing train dataset:  25%|██▍       | 5977/24227 [00:27<01:10, 258.71 examples/s]Tokenizing train dataset:  25%|██▌       | 6058/24227 [00:27<01:11, 255.63 examples/s]Tokenizing train dataset:  25%|██▌       | 6087/24227 [00:28<01:08, 263.13 examples/s]Tokenizing train dataset:  25%|██▍       | 6011/24227 [00:27<01:14, 245.54 examples/s]Tokenizing train dataset:  24%|██▍       | 5831/24227 [00:28<01:17, 236.13 examples/s]Tokenizing train dataset:  25%|██▌       | 6116/24227 [00:28<01:08, 265.79 examples/s]Tokenizing train dataset:  25%|██▍       | 6044/24227 [00:27<01:17, 235.10 examples/s]Tokenizing train dataset:  24%|██▍       | 5870/24227 [00:28<01:17, 236.49 examples/s]Tokenizing train dataset:  25%|██▌       | 6152/24227 [00:28<01:02, 287.32 examples/s]Tokenizing train dataset:  25%|██▌       | 6082/24227 [00:27<01:08, 266.13 examples/s]Tokenizing train dataset:  24%|██▍       | 5905/24227 [00:28<01:19, 231.71 examples/s]Tokenizing train dataset:  26%|██▌       | 6196/24227 [00:28<01:02, 286.28 examples/s]Tokenizing train dataset:  25%|██▌       | 6116/24227 [00:27<01:04, 280.84 examples/s]Tokenizing train dataset:  24%|██▍       | 5934/24227 [00:28<01:15, 242.91 examples/s]Tokenizing train dataset:  26%|██▌       | 6227/24227 [00:28<01:01, 291.13 examples/s]Tokenizing train dataset:  25%|██▌       | 6151/24227 [00:27<01:00, 296.69 examples/s]Tokenizing train dataset:  25%|██▍       | 5966/24227 [00:28<01:19, 230.66 examples/s]Tokenizing train dataset:  26%|██▌       | 6270/24227 [00:28<01:02, 285.13 examples/s]Tokenizing train dataset:  26%|██▌       | 6193/24227 [00:28<01:02, 288.79 examples/s]Tokenizing train dataset:  26%|██▌       | 6301/24227 [00:28<01:01, 289.15 examples/s]Tokenizing train dataset:  26%|██▌       | 6226/24227 [00:28<01:00, 295.22 examples/s]Tokenizing train dataset:  25%|██▍       | 6000/24227 [00:28<01:20, 227.56 examples/s]Tokenizing train dataset:  26%|██▌       | 6338/24227 [00:28<00:58, 306.50 examples/s]Tokenizing train dataset:  26%|██▌       | 6276/24227 [00:28<00:59, 302.68 examples/s]Tokenizing train dataset:  25%|██▍       | 6036/24227 [00:28<01:19, 227.98 examples/s]Tokenizing train dataset:  26%|██▋       | 6375/24227 [00:28<00:56, 317.87 examples/s]Tokenizing train dataset:  25%|██▌       | 6070/24227 [00:29<01:12, 249.09 examples/s]Tokenizing train dataset:  26%|██▌       | 6327/24227 [00:28<00:57, 313.63 examples/s]Tokenizing train dataset:  26%|██▋       | 6420/24227 [00:29<00:58, 305.75 examples/s]Tokenizing train dataset:  25%|██▌       | 6098/24227 [00:29<01:12, 251.19 examples/s]Tokenizing train dataset:  26%|██▋       | 6360/24227 [00:28<00:56, 314.07 examples/s]Tokenizing train dataset:  27%|██▋       | 6458/24227 [00:29<00:55, 322.40 examples/s]Tokenizing train dataset:  25%|██▌       | 6131/24227 [00:29<01:07, 268.58 examples/s]Tokenizing train dataset:  26%|██▋       | 6400/24227 [00:28<01:00, 293.50 examples/s]Tokenizing train dataset:  25%|██▌       | 6161/24227 [00:29<01:06, 273.62 examples/s]Tokenizing train dataset:  27%|██▋       | 6506/24227 [00:29<00:55, 318.59 examples/s]Tokenizing train dataset:  27%|██▋       | 6437/24227 [00:28<00:57, 310.43 examples/s]Tokenizing train dataset:  26%|██▌       | 6193/24227 [00:29<01:03, 282.28 examples/s]Tokenizing train dataset:  27%|██▋       | 6555/24227 [00:29<00:55, 317.74 examples/s]Tokenizing train dataset:  26%|██▌       | 6223/24227 [00:29<01:03, 284.82 examples/s]Tokenizing train dataset:  27%|██▋       | 6485/24227 [00:29<00:57, 310.25 examples/s]Tokenizing train dataset:  27%|██▋       | 6607/24227 [00:29<00:54, 323.36 examples/s]Tokenizing train dataset:  26%|██▌       | 6261/24227 [00:29<01:09, 259.48 examples/s]Tokenizing train dataset:  27%|██▋       | 6520/24227 [00:29<01:02, 283.56 examples/s]Tokenizing train dataset:  27%|██▋       | 6644/24227 [00:29<00:52, 332.90 examples/s]Tokenizing train dataset:  26%|██▌       | 6299/24227 [00:29<01:03, 283.94 examples/s]Tokenizing train dataset:  27%|██▋       | 6551/24227 [00:29<01:01, 286.30 examples/s]Tokenizing train dataset:  28%|██▊       | 6680/24227 [00:29<00:52, 336.39 examples/s]Tokenizing train dataset:  26%|██▌       | 6331/24227 [00:29<01:01, 293.13 examples/s]Tokenizing train dataset:  27%|██▋       | 6585/24227 [00:29<01:06, 263.34 examples/s]Tokenizing train dataset:  28%|██▊       | 6728/24227 [00:30<00:53, 324.34 examples/s]Tokenizing train dataset:  26%|██▋       | 6369/24227 [00:30<00:57, 310.94 examples/s]Tokenizing train dataset:  27%|██▋       | 6621/24227 [00:29<01:02, 283.18 examples/s]Tokenizing train dataset:  28%|██▊       | 6777/24227 [00:30<00:54, 318.93 examples/s]Tokenizing train dataset:  26%|██▋       | 6419/24227 [00:30<00:56, 314.23 examples/s]Tokenizing train dataset:  28%|██▊       | 6664/24227 [00:29<01:10, 247.76 examples/s]Tokenizing train dataset:  28%|██▊       | 6819/24227 [00:30<00:57, 305.36 examples/s]Tokenizing train dataset:  27%|██▋       | 6460/24227 [00:30<00:59, 298.10 examples/s]Tokenizing train dataset:  28%|██▊       | 6700/24227 [00:29<01:12, 241.92 examples/s]Tokenizing train dataset:  28%|██▊       | 6858/24227 [00:30<01:01, 284.70 examples/s]Tokenizing train dataset:  27%|██▋       | 6504/24227 [00:30<01:00, 293.64 examples/s]Tokenizing train dataset:  28%|██▊       | 6740/24227 [00:30<01:14, 235.16 examples/s]Tokenizing train dataset:  28%|██▊       | 6904/24227 [00:30<01:02, 275.02 examples/s]Tokenizing train dataset:  27%|██▋       | 6539/24227 [00:30<01:11, 247.11 examples/s]Tokenizing train dataset:  28%|██▊       | 6769/24227 [00:30<01:11, 245.16 examples/s]Tokenizing train dataset:  29%|██▊       | 6940/24227 [00:30<00:59, 291.08 examples/s]Tokenizing train dataset:  27%|██▋       | 6568/24227 [00:30<01:09, 252.68 examples/s]Tokenizing train dataset:  29%|██▉       | 6978/24227 [00:30<00:56, 306.97 examples/s]Tokenizing train dataset:  28%|██▊       | 6817/24227 [00:30<01:05, 264.08 examples/s]Tokenizing train dataset:  27%|██▋       | 6611/24227 [00:30<01:07, 262.42 examples/s]Tokenizing train dataset:  29%|██▉       | 7012/24227 [00:31<00:55, 312.69 examples/s]Tokenizing train dataset:  28%|██▊       | 6862/24227 [00:30<01:03, 273.33 examples/s]Tokenizing train dataset:  27%|██▋       | 6653/24227 [00:31<01:08, 255.13 examples/s]Tokenizing train dataset:  29%|██▉       | 7047/24227 [00:31<01:00, 283.31 examples/s]Tokenizing train dataset:  28%|██▊       | 6901/24227 [00:30<00:58, 297.96 examples/s]Tokenizing train dataset:  29%|██▉       | 7090/24227 [00:31<01:00, 282.99 examples/s]Tokenizing train dataset:  28%|██▊       | 6695/24227 [00:31<01:07, 259.86 examples/s]Tokenizing train dataset:  29%|██▊       | 6949/24227 [00:30<00:56, 303.54 examples/s]Tokenizing train dataset:  29%|██▉       | 7134/24227 [00:31<01:00, 283.72 examples/s]Tokenizing train dataset:  28%|██▊       | 6732/24227 [00:31<01:09, 251.46 examples/s]Tokenizing train dataset:  29%|██▉       | 6993/24227 [00:30<00:57, 297.22 examples/s]Tokenizing train dataset:  30%|██▉       | 7177/24227 [00:31<01:00, 282.68 examples/s]Tokenizing train dataset:  28%|██▊       | 6770/24227 [00:31<01:10, 249.13 examples/s]Tokenizing train dataset:  29%|██▉       | 7037/24227 [00:31<00:59, 291.12 examples/s]Tokenizing train dataset:  30%|██▉       | 7221/24227 [00:31<01:00, 282.68 examples/s]Tokenizing train dataset:  28%|██▊       | 6810/24227 [00:31<01:09, 250.55 examples/s]Tokenizing train dataset:  29%|██▉       | 7075/24227 [00:31<01:02, 275.95 examples/s]Tokenizing train dataset:  30%|██▉       | 7250/24227 [00:31<01:00, 282.94 examples/s]Tokenizing train dataset:  28%|██▊       | 6844/24227 [00:31<01:19, 217.44 examples/s]Tokenizing train dataset:  29%|██▉       | 7114/24227 [00:31<01:11, 240.02 examples/s]Tokenizing train dataset:  30%|███       | 7290/24227 [00:32<01:01, 274.40 examples/s]Tokenizing train dataset:  28%|██▊       | 6869/24227 [00:32<01:17, 222.99 examples/s]Tokenizing train dataset:  29%|██▉       | 7144/24227 [00:31<01:08, 250.15 examples/s]Tokenizing train dataset:  30%|███       | 7320/24227 [00:32<01:00, 279.19 examples/s]Tokenizing train dataset:  29%|██▊       | 6909/24227 [00:32<01:06, 260.91 examples/s]Tokenizing train dataset:  30%|██▉       | 7180/24227 [00:31<01:02, 270.73 examples/s]Tokenizing train dataset:  30%|███       | 7353/24227 [00:32<00:58, 289.33 examples/s]Tokenizing train dataset:  29%|██▊       | 6941/24227 [00:32<01:03, 271.74 examples/s]Tokenizing train dataset:  30%|██▉       | 7217/24227 [00:31<01:05, 260.52 examples/s]Tokenizing train dataset:  31%|███       | 7390/24227 [00:32<01:09, 241.47 examples/s]Tokenizing train dataset:  29%|██▉       | 6980/24227 [00:32<01:05, 263.74 examples/s]Tokenizing train dataset:  30%|██▉       | 7252/24227 [00:31<01:01, 277.71 examples/s]Tokenizing train dataset:  31%|███       | 7421/24227 [00:32<01:05, 254.93 examples/s]Tokenizing train dataset:  29%|██▉       | 7016/24227 [00:32<01:00, 285.29 examples/s]Tokenizing train dataset:  30%|███       | 7286/24227 [00:32<00:58, 290.72 examples/s]Tokenizing train dataset:  31%|███       | 7467/24227 [00:32<01:02, 269.53 examples/s]Tokenizing train dataset:  29%|██▉       | 7056/24227 [00:32<01:02, 274.37 examples/s]Tokenizing train dataset:  30%|███       | 7334/24227 [00:32<00:56, 296.38 examples/s]Tokenizing train dataset:  31%|███       | 7497/24227 [00:32<01:01, 273.71 examples/s]Tokenizing train dataset:  29%|██▉       | 7096/24227 [00:32<01:06, 259.28 examples/s]Tokenizing train dataset:  31%|███       | 7528/24227 [00:32<00:59, 281.38 examples/s]Tokenizing train dataset:  30%|███       | 7370/24227 [00:32<01:02, 269.73 examples/s]Tokenizing train dataset:  29%|██▉       | 7128/24227 [00:32<01:03, 268.77 examples/s]Tokenizing train dataset:  31%|███       | 7560/24227 [00:33<00:57, 290.24 examples/s]Tokenizing train dataset:  31%|███       | 7402/24227 [00:32<01:00, 278.18 examples/s]Tokenizing train dataset:  30%|██▉       | 7167/24227 [00:33<01:05, 262.41 examples/s]Tokenizing train dataset:  31%|███▏      | 7594/24227 [00:33<01:03, 262.49 examples/s]Tokenizing train dataset:  31%|███       | 7436/24227 [00:32<01:28, 189.08 examples/s]Tokenizing train dataset:  30%|██▉       | 7201/24227 [00:33<01:15, 226.04 examples/s]Tokenizing train dataset:  31%|███▏      | 7630/24227 [00:33<01:12, 229.18 examples/s]Tokenizing train dataset:  31%|███       | 7473/24227 [00:32<01:15, 221.30 examples/s]Tokenizing train dataset:  30%|██▉       | 7233/24227 [00:33<01:09, 244.07 examples/s]Tokenizing train dataset:  32%|███▏      | 7657/24227 [00:33<01:09, 237.72 examples/s]Tokenizing train dataset:  31%|███       | 7503/24227 [00:33<01:10, 237.45 examples/s]Tokenizing train dataset:  30%|██▉       | 7261/24227 [00:33<01:07, 251.63 examples/s]Tokenizing train dataset:  32%|███▏      | 7695/24227 [00:33<01:01, 270.11 examples/s]Tokenizing train dataset:  31%|███       | 7542/24227 [00:33<01:02, 267.09 examples/s]Tokenizing train dataset:  30%|███       | 7295/24227 [00:33<01:02, 269.57 examples/s]Tokenizing train dataset:  32%|███▏      | 7759/24227 [00:33<00:45, 362.73 examples/s]Tokenizing train dataset:  30%|███       | 7328/24227 [00:33<01:00, 280.91 examples/s]Tokenizing train dataset:  32%|███▏      | 7819/24227 [00:33<00:38, 423.31 examples/s]Tokenizing train dataset:  31%|███▏      | 7589/24227 [00:33<00:59, 278.24 examples/s]Tokenizing train dataset:  32%|███▏      | 7870/24227 [00:33<00:36, 443.45 examples/s]Tokenizing train dataset:  30%|███       | 7360/24227 [00:33<00:58, 287.61 examples/s]Tokenizing train dataset:  31%|███▏      | 7626/24227 [00:33<01:02, 267.00 examples/s]Tokenizing train dataset:  33%|███▎      | 7936/24227 [00:34<00:32, 499.84 examples/s]Tokenizing train dataset:  31%|███       | 7400/24227 [00:34<01:01, 271.94 examples/s]Tokenizing train dataset:  32%|███▏      | 7658/24227 [00:33<01:06, 247.68 examples/s]Tokenizing train dataset:  33%|███▎      | 8011/24227 [00:34<00:33, 488.27 examples/s]Tokenizing train dataset:  31%|███       | 7448/24227 [00:34<00:58, 285.04 examples/s]Tokenizing train dataset:  32%|███▏      | 7711/24227 [00:33<00:53, 310.31 examples/s]Tokenizing train dataset:  33%|███▎      | 8067/24227 [00:34<00:32, 498.95 examples/s]Tokenizing train dataset:  32%|███▏      | 7755/24227 [00:33<00:48, 340.83 examples/s]Tokenizing train dataset:  34%|███▎      | 8134/24227 [00:34<00:29, 537.82 examples/s]Tokenizing train dataset:  31%|███       | 7488/24227 [00:34<01:01, 273.16 examples/s]Tokenizing train dataset:  32%|███▏      | 7804/24227 [00:33<00:44, 371.86 examples/s]Tokenizing train dataset:  34%|███▍      | 8190/24227 [00:34<00:29, 536.49 examples/s]Tokenizing train dataset:  31%|███       | 7530/24227 [00:34<01:01, 272.27 examples/s]Tokenizing train dataset:  32%|███▏      | 7855/24227 [00:34<00:40, 403.02 examples/s]Tokenizing train dataset:  34%|███▍      | 8275/24227 [00:34<00:29, 544.95 examples/s]Tokenizing train dataset:  31%|███       | 7559/24227 [00:34<01:00, 275.32 examples/s]Tokenizing train dataset:  33%|███▎      | 7919/24227 [00:34<00:35, 465.05 examples/s]Tokenizing train dataset:  33%|███▎      | 7979/24227 [00:34<00:32, 499.24 examples/s]Tokenizing train dataset:  35%|███▍      | 8362/24227 [00:34<00:28, 550.31 examples/s]Tokenizing train dataset:  31%|███▏      | 7594/24227 [00:34<01:04, 258.41 examples/s]Tokenizing train dataset:  33%|███▎      | 8044/24227 [00:34<00:35, 456.06 examples/s]Tokenizing train dataset:  35%|███▍      | 8432/24227 [00:34<00:30, 518.91 examples/s]Tokenizing train dataset:  32%|███▏      | 7632/24227 [00:34<01:05, 252.58 examples/s]Tokenizing train dataset:  33%|███▎      | 8111/24227 [00:34<00:31, 508.51 examples/s]Tokenizing train dataset:  35%|███▌      | 8491/24227 [00:35<00:29, 533.65 examples/s]Tokenizing train dataset:  32%|███▏      | 7680/24227 [00:35<01:00, 271.79 examples/s]Tokenizing train dataset:  34%|███▎      | 8176/24227 [00:34<00:33, 474.60 examples/s]Tokenizing train dataset:  32%|███▏      | 7721/24227 [00:35<00:54, 302.60 examples/s]Tokenizing train dataset:  35%|███▌      | 8560/24227 [00:35<00:32, 479.57 examples/s]Tokenizing train dataset:  34%|███▍      | 8229/24227 [00:34<00:32, 488.02 examples/s]Tokenizing train dataset:  32%|███▏      | 7759/24227 [00:35<00:52, 314.71 examples/s]Tokenizing train dataset:  36%|███▌      | 8610/24227 [00:35<00:32, 474.12 examples/s]Tokenizing train dataset:  32%|███▏      | 7805/24227 [00:35<00:46, 350.40 examples/s]Tokenizing train dataset:  36%|███▌      | 8673/24227 [00:35<00:30, 510.98 examples/s]Tokenizing train dataset:  34%|███▍      | 8306/24227 [00:34<00:32, 491.91 examples/s]Tokenizing train dataset:  32%|███▏      | 7854/24227 [00:35<00:42, 382.99 examples/s]Tokenizing train dataset:  36%|███▌      | 8732/24227 [00:35<00:29, 530.45 examples/s]Tokenizing train dataset:  35%|███▍      | 8367/24227 [00:35<00:30, 515.89 examples/s]Tokenizing train dataset:  33%|███▎      | 7911/24227 [00:35<00:37, 431.65 examples/s]Tokenizing train dataset:  36%|███▋      | 8821/24227 [00:35<00:28, 548.13 examples/s]Tokenizing train dataset:  35%|███▍      | 8447/24227 [00:35<00:30, 517.98 examples/s]Tokenizing train dataset:  33%|███▎      | 7975/24227 [00:35<00:33, 488.94 examples/s]Tokenizing train dataset:  37%|███▋      | 8881/24227 [00:35<00:27, 560.00 examples/s]Tokenizing train dataset:  35%|███▌      | 8512/24227 [00:35<00:28, 548.65 examples/s]Tokenizing train dataset:  33%|███▎      | 8042/24227 [00:35<00:34, 470.66 examples/s]Tokenizing train dataset:  37%|███▋      | 8950/24227 [00:35<00:25, 590.99 examples/s]Tokenizing train dataset:  35%|███▌      | 8571/24227 [00:35<00:28, 558.32 examples/s]Tokenizing train dataset:  33%|███▎      | 8106/24227 [00:35<00:31, 510.58 examples/s]Tokenizing train dataset:  37%|███▋      | 9013/24227 [00:35<00:25, 600.01 examples/s]Tokenizing train dataset:  36%|███▌      | 8635/24227 [00:35<00:26, 577.52 examples/s]Tokenizing train dataset:  34%|███▎      | 8167/24227 [00:36<00:34, 463.33 examples/s]Tokenizing train dataset:  38%|███▊      | 9090/24227 [00:36<00:28, 527.30 examples/s]Tokenizing train dataset:  36%|███▌      | 8712/24227 [00:35<00:30, 515.37 examples/s]Tokenizing train dataset:  34%|███▍      | 8240/24227 [00:36<00:30, 527.94 examples/s]Tokenizing train dataset:  38%|███▊      | 9162/24227 [00:36<00:29, 510.61 examples/s]Tokenizing train dataset:  36%|███▋      | 8791/24227 [00:35<00:30, 514.41 examples/s]Tokenizing train dataset:  34%|███▍      | 8303/24227 [00:36<00:28, 554.29 examples/s]Tokenizing train dataset:  38%|███▊      | 9238/24227 [00:36<00:29, 504.76 examples/s]Tokenizing train dataset:  37%|███▋      | 8860/24227 [00:35<00:31, 492.45 examples/s]Tokenizing train dataset:  35%|███▍      | 8376/24227 [00:36<00:30, 513.11 examples/s]Tokenizing train dataset:  38%|███▊      | 9307/24227 [00:36<00:27, 547.15 examples/s]Tokenizing train dataset:  37%|███▋      | 8928/24227 [00:36<00:28, 532.75 examples/s]Tokenizing train dataset:  35%|███▍      | 8436/24227 [00:36<00:29, 534.09 examples/s]Tokenizing train dataset:  39%|███▊      | 9370/24227 [00:36<00:26, 565.07 examples/s]Tokenizing train dataset:  37%|███▋      | 8996/24227 [00:36<00:26, 566.69 examples/s]Tokenizing train dataset:  35%|███▌      | 8506/24227 [00:36<00:27, 575.65 examples/s]Tokenizing train dataset:  39%|███▉      | 9439/24227 [00:36<00:24, 591.95 examples/s]Tokenizing train dataset:  37%|███▋      | 9065/24227 [00:36<00:25, 598.23 examples/s]Tokenizing train dataset:  36%|███▌      | 8615/24227 [00:36<00:24, 628.05 examples/s]Tokenizing train dataset:  39%|███▉      | 9502/24227 [00:36<00:24, 599.72 examples/s]Tokenizing train dataset:  38%|███▊      | 9160/24227 [00:36<00:25, 602.21 examples/s]Tokenizing train dataset:  36%|███▌      | 8681/24227 [00:36<00:24, 635.16 examples/s]Tokenizing train dataset:  40%|███▉      | 9590/24227 [00:37<00:24, 590.48 examples/s]Tokenizing train dataset:  38%|███▊      | 9251/24227 [00:36<00:25, 599.01 examples/s]Tokenizing train dataset:  36%|███▌      | 8768/24227 [00:37<00:25, 612.09 examples/s]Tokenizing train dataset:  40%|███▉      | 9656/24227 [00:37<00:24, 606.47 examples/s]Tokenizing train dataset:  40%|████      | 9720/24227 [00:37<00:23, 609.19 examples/s]Tokenizing train dataset:  39%|███▊      | 9338/24227 [00:36<00:25, 589.38 examples/s]Tokenizing train dataset:  36%|███▋      | 8840/24227 [00:37<00:27, 562.95 examples/s]Tokenizing train dataset:  40%|████      | 9805/24227 [00:37<00:24, 589.92 examples/s]Tokenizing train dataset:  39%|███▉      | 9421/24227 [00:36<00:25, 576.56 examples/s]Tokenizing train dataset:  37%|███▋      | 8921/24227 [00:37<00:27, 553.44 examples/s]Tokenizing train dataset:  41%|████      | 9880/24227 [00:37<00:25, 552.56 examples/s]Tokenizing train dataset:  39%|███▉      | 9506/24227 [00:37<00:25, 569.50 examples/s]Tokenizing train dataset:  37%|███▋      | 8997/24227 [00:37<00:28, 538.56 examples/s]Tokenizing train dataset:  41%|████      | 9950/24227 [00:37<00:24, 584.66 examples/s]Tokenizing train dataset:  40%|███▉      | 9576/24227 [00:37<00:27, 534.15 examples/s]Tokenizing train dataset:  37%|███▋      | 9076/24227 [00:37<00:29, 517.41 examples/s]Tokenizing train dataset:  41%|████▏     | 10020/24227 [00:37<00:23, 612.89 examples/s]Tokenizing train dataset:  40%|███▉      | 9664/24227 [00:37<00:26, 549.25 examples/s]Tokenizing train dataset:  38%|███▊      | 9136/24227 [00:37<00:33, 445.71 examples/s]Tokenizing train dataset:  42%|████▏     | 10087/24227 [00:37<00:28, 502.20 examples/s]Tokenizing train dataset:  40%|████      | 9744/24227 [00:37<00:26, 536.56 examples/s]Tokenizing train dataset:  38%|███▊      | 9209/24227 [00:38<00:33, 454.70 examples/s]Tokenizing train dataset:  42%|████▏     | 10163/24227 [00:38<00:28, 497.85 examples/s]Tokenizing train dataset:  40%|████      | 9800/24227 [00:37<00:26, 535.60 examples/s]Tokenizing train dataset:  38%|███▊      | 9281/24227 [00:38<00:29, 506.70 examples/s]Tokenizing train dataset:  41%|████      | 9881/24227 [00:37<00:26, 536.42 examples/s]Tokenizing train dataset:  39%|███▊      | 9342/24227 [00:38<00:28, 528.28 examples/s]Tokenizing train dataset:  42%|████▏     | 10231/24227 [00:38<00:32, 432.94 examples/s]Tokenizing train dataset:  41%|████      | 9948/24227 [00:37<00:25, 566.91 examples/s]Tokenizing train dataset:  39%|███▉      | 9432/24227 [00:38<00:27, 544.40 examples/s]Tokenizing train dataset:  42%|████▏     | 10285/24227 [00:38<00:34, 409.67 examples/s]Tokenizing train dataset:  41%|████▏     | 10012/24227 [00:37<00:24, 581.34 examples/s]Tokenizing train dataset:  39%|███▉      | 9516/24227 [00:38<00:26, 545.56 examples/s]Tokenizing train dataset:  43%|████▎     | 10332/24227 [00:38<00:36, 379.21 examples/s]Tokenizing train dataset:  42%|████▏     | 10102/24227 [00:38<00:24, 583.96 examples/s]Tokenizing train dataset:  40%|███▉      | 9581/24227 [00:38<00:28, 508.43 examples/s]Tokenizing train dataset:  43%|████▎     | 10374/24227 [00:38<00:39, 347.43 examples/s]Tokenizing train dataset:  42%|████▏     | 10166/24227 [00:38<00:26, 523.30 examples/s]Tokenizing train dataset:  40%|███▉      | 9644/24227 [00:38<00:27, 533.32 examples/s]Tokenizing train dataset:  43%|████▎     | 10425/24227 [00:38<00:40, 343.67 examples/s]Tokenizing train dataset:  40%|████      | 9710/24227 [00:38<00:25, 563.22 examples/s]Tokenizing train dataset:  42%|████▏     | 10238/24227 [00:38<00:30, 455.22 examples/s]Tokenizing train dataset:  43%|████▎     | 10464/24227 [00:39<00:39, 350.28 examples/s]Tokenizing train dataset:  40%|████      | 9801/24227 [00:39<00:25, 576.31 examples/s]Tokenizing train dataset:  42%|████▏     | 10287/24227 [00:38<00:33, 411.88 examples/s]Tokenizing train dataset:  43%|████▎     | 10506/24227 [00:39<00:42, 324.83 examples/s]Tokenizing train dataset:  41%|████      | 9870/24227 [00:39<00:26, 536.46 examples/s]Tokenizing train dataset:  43%|████▎     | 10335/24227 [00:38<00:36, 382.62 examples/s]Tokenizing train dataset:  44%|████▎     | 10558/24227 [00:39<00:41, 327.09 examples/s]Tokenizing train dataset:  41%|████      | 9927/24227 [00:39<00:26, 540.38 examples/s]Tokenizing train dataset:  41%|████▏     | 9994/24227 [00:39<00:24, 572.05 examples/s]Tokenizing train dataset:  43%|████▎     | 10389/24227 [00:38<00:37, 372.48 examples/s]Tokenizing train dataset:  44%|████▍     | 10609/24227 [00:39<00:41, 329.58 examples/s]Tokenizing train dataset:  42%|████▏     | 10080/24227 [00:39<00:25, 564.02 examples/s]Tokenizing train dataset:  43%|████▎     | 10441/24227 [00:39<00:38, 360.12 examples/s]Tokenizing train dataset:  44%|████▍     | 10660/24227 [00:39<00:41, 328.06 examples/s]Tokenizing train dataset:  42%|████▏     | 10162/24227 [00:39<00:25, 555.66 examples/s]Tokenizing train dataset:  43%|████▎     | 10491/24227 [00:39<00:39, 350.44 examples/s]Tokenizing train dataset:  44%|████▍     | 10710/24227 [00:39<00:41, 324.19 examples/s]Tokenizing train dataset:  44%|████▎     | 10543/24227 [00:39<00:39, 346.22 examples/s]Tokenizing train dataset:  42%|████▏     | 10233/24227 [00:39<00:29, 472.97 examples/s]Tokenizing train dataset:  44%|████▍     | 10751/24227 [00:40<00:51, 262.04 examples/s]Tokenizing train dataset:  44%|████▎     | 10584/24227 [00:39<00:42, 323.13 examples/s]Tokenizing train dataset:  42%|████▏     | 10285/24227 [00:40<00:32, 426.98 examples/s]Tokenizing train dataset:  45%|████▍     | 10784/24227 [00:40<00:49, 273.88 examples/s]Tokenizing train dataset:  44%|████▍     | 10626/24227 [00:39<00:44, 308.06 examples/s]Tokenizing train dataset:  43%|████▎     | 10338/24227 [00:40<00:38, 363.71 examples/s]Tokenizing train dataset:  45%|████▍     | 10826/24227 [00:40<00:52, 255.03 examples/s]Tokenizing train dataset:  44%|████▍     | 10671/24227 [00:39<00:44, 303.89 examples/s]Tokenizing train dataset:  43%|████▎     | 10389/24227 [00:40<00:38, 355.76 examples/s]Tokenizing train dataset:  45%|████▍     | 10866/24227 [00:40<00:52, 254.58 examples/s]Tokenizing train dataset:  44%|████▍     | 10721/24227 [00:40<00:43, 311.01 examples/s]Tokenizing train dataset:  43%|████▎     | 10428/24227 [00:40<00:43, 319.06 examples/s]Tokenizing train dataset:  45%|████▌     | 10903/24227 [00:40<01:04, 206.16 examples/s]Tokenizing train dataset:  44%|████▍     | 10758/24227 [00:40<00:56, 237.06 examples/s]Tokenizing train dataset:  43%|████▎     | 10468/24227 [00:40<00:48, 284.02 examples/s]Tokenizing train dataset:  45%|████▌     | 10940/24227 [00:40<01:02, 213.49 examples/s]Tokenizing train dataset:  45%|████▍     | 10794/24227 [00:40<00:57, 233.99 examples/s]Tokenizing train dataset:  43%|████▎     | 10512/24227 [00:40<00:48, 283.39 examples/s]Tokenizing train dataset:  45%|████▌     | 10976/24227 [00:41<00:55, 240.34 examples/s]Tokenizing train dataset:  45%|████▍     | 10828/24227 [00:40<00:53, 252.72 examples/s]Tokenizing train dataset:  44%|████▎     | 10546/24227 [00:41<00:46, 292.69 examples/s]Tokenizing train dataset:  45%|████▌     | 11010/24227 [00:41<00:50, 260.69 examples/s]Tokenizing train dataset:  45%|████▍     | 10858/24227 [00:40<00:51, 259.48 examples/s]Tokenizing train dataset:  46%|████▌     | 11052/24227 [00:41<00:44, 292.88 examples/s]Tokenizing train dataset:  44%|████▎     | 10593/24227 [00:41<00:46, 293.71 examples/s]Tokenizing train dataset:  45%|████▍     | 10890/24227 [00:40<00:49, 271.38 examples/s]Tokenizing train dataset:  46%|████▌     | 11085/24227 [00:41<00:43, 300.92 examples/s]Tokenizing train dataset:  44%|████▍     | 10633/24227 [00:41<00:47, 284.10 examples/s]Tokenizing train dataset:  45%|████▌     | 10922/24227 [00:40<00:59, 222.33 examples/s]Tokenizing train dataset:  46%|████▌     | 11118/24227 [00:41<00:52, 251.50 examples/s]Tokenizing train dataset:  44%|████▍     | 10672/24227 [00:41<00:49, 274.43 examples/s]Tokenizing train dataset:  45%|████▌     | 10948/24227 [00:41<00:58, 227.67 examples/s]Tokenizing train dataset:  46%|████▌     | 11149/24227 [00:41<00:49, 263.56 examples/s]Tokenizing train dataset:  44%|████▍     | 10700/24227 [00:41<00:49, 272.43 examples/s]Tokenizing train dataset:  45%|████▌     | 10982/24227 [00:41<00:52, 253.01 examples/s]Tokenizing train dataset:  44%|████▍     | 10732/24227 [00:41<00:47, 281.41 examples/s]Tokenizing train dataset:  46%|████▌     | 11187/24227 [00:41<00:52, 248.39 examples/s]Tokenizing train dataset:  45%|████▌     | 11014/24227 [00:41<00:49, 267.02 examples/s]Tokenizing train dataset:  44%|████▍     | 10763/24227 [00:41<00:46, 286.48 examples/s]Tokenizing train dataset:  46%|████▋     | 11216/24227 [00:41<00:50, 255.53 examples/s]Tokenizing train dataset:  46%|████▌     | 11057/24227 [00:41<00:50, 261.32 examples/s]Tokenizing train dataset:  45%|████▍     | 10795/24227 [00:41<00:45, 292.17 examples/s]Tokenizing train dataset:  46%|████▋     | 11244/24227 [00:42<00:50, 259.41 examples/s]Tokenizing train dataset:  46%|████▌     | 11096/24227 [00:41<00:53, 247.09 examples/s]Tokenizing train dataset:  45%|████▍     | 10836/24227 [00:42<00:51, 259.32 examples/s]Tokenizing train dataset:  47%|████▋     | 11280/24227 [00:42<00:55, 234.07 examples/s]Tokenizing train dataset:  46%|████▌     | 11133/24227 [00:41<00:59, 221.50 examples/s]Tokenizing train dataset:  45%|████▍     | 10870/24227 [00:42<00:59, 225.14 examples/s]Tokenizing train dataset:  47%|████▋     | 11320/24227 [00:42<00:57, 222.67 examples/s]Tokenizing train dataset:  46%|████▌     | 11167/24227 [00:41<00:53, 242.09 examples/s]Tokenizing train dataset:  45%|████▌     | 10904/24227 [00:42<00:53, 247.52 examples/s]Tokenizing train dataset:  47%|████▋     | 11358/24227 [00:42<00:50, 254.39 examples/s]Tokenizing train dataset:  46%|████▌     | 11203/24227 [00:42<00:48, 267.72 examples/s]Tokenizing train dataset:  45%|████▌     | 10940/24227 [00:42<01:04, 206.40 examples/s]Tokenizing train dataset:  47%|████▋     | 11388/24227 [00:43<01:47, 119.70 examples/s]Tokenizing train dataset:  46%|████▋     | 11240/24227 [00:42<01:36, 134.85 examples/s]Tokenizing train dataset:  45%|████▌     | 10982/24227 [00:43<01:28, 149.68 examples/s]Tokenizing train dataset:  47%|████▋     | 11417/24227 [00:43<01:30, 141.09 examples/s]Tokenizing train dataset:  47%|████▋     | 11273/24227 [00:42<01:20, 161.22 examples/s]Tokenizing train dataset:  45%|████▌     | 11015/24227 [00:43<01:15, 175.49 examples/s]Tokenizing train dataset:  47%|████▋     | 11454/24227 [00:43<01:12, 175.65 examples/s]Tokenizing train dataset:  47%|████▋     | 11306/24227 [00:42<01:08, 188.57 examples/s]Tokenizing train dataset:  46%|████▌     | 11053/24227 [00:43<01:03, 208.40 examples/s]Tokenizing train dataset:  47%|████▋     | 11491/24227 [00:43<01:00, 209.98 examples/s]Tokenizing train dataset:  47%|████▋     | 11342/24227 [00:42<00:58, 220.28 examples/s]Tokenizing train dataset:  46%|████▌     | 11088/24227 [00:43<00:56, 233.95 examples/s]Tokenizing train dataset:  48%|████▊     | 11532/24227 [00:43<00:56, 226.56 examples/s]Tokenizing train dataset:  47%|████▋     | 11379/24227 [00:43<00:56, 226.19 examples/s]Tokenizing train dataset:  46%|████▌     | 11127/24227 [00:43<00:54, 239.13 examples/s]Tokenizing train dataset:  48%|████▊     | 11565/24227 [00:43<00:51, 247.16 examples/s]Tokenizing train dataset:  46%|████▌     | 11160/24227 [00:43<00:50, 258.26 examples/s]Tokenizing train dataset:  47%|████▋     | 11416/24227 [00:43<00:55, 229.43 examples/s]Tokenizing train dataset:  48%|████▊     | 11595/24227 [00:43<00:49, 256.24 examples/s]Tokenizing train dataset:  46%|████▌     | 11193/24227 [00:43<00:47, 274.33 examples/s]Tokenizing train dataset:  47%|████▋     | 11450/24227 [00:43<00:50, 251.05 examples/s]Tokenizing train dataset:  48%|████▊     | 11628/24227 [00:43<00:46, 272.89 examples/s]Tokenizing train dataset:  46%|████▋     | 11224/24227 [00:43<00:46, 279.48 examples/s]Tokenizing train dataset:  47%|████▋     | 11485/24227 [00:43<00:47, 271.09 examples/s]Tokenizing train dataset:  48%|████▊     | 11671/24227 [00:44<00:45, 274.11 examples/s]Tokenizing train dataset:  48%|████▊     | 11517/24227 [00:43<00:45, 280.16 examples/s]Tokenizing train dataset:  47%|████▋     | 11269/24227 [00:44<00:45, 282.25 examples/s]Tokenizing train dataset:  48%|████▊     | 11719/24227 [00:44<00:43, 286.78 examples/s]Tokenizing train dataset:  48%|████▊     | 11551/24227 [00:43<00:48, 259.60 examples/s]Tokenizing train dataset:  47%|████▋     | 11305/24227 [00:44<00:50, 254.36 examples/s]Tokenizing train dataset:  48%|████▊     | 11750/24227 [00:44<00:43, 284.78 examples/s]Tokenizing train dataset:  48%|████▊     | 11590/24227 [00:43<00:44, 285.14 examples/s]Tokenizing train dataset:  47%|████▋     | 11340/24227 [00:44<00:47, 273.39 examples/s]Tokenizing train dataset:  49%|████▊     | 11782/24227 [00:44<00:43, 288.85 examples/s]Tokenizing train dataset:  47%|████▋     | 11370/24227 [00:44<00:46, 276.39 examples/s]Tokenizing train dataset:  48%|████▊     | 11641/24227 [00:43<00:42, 298.12 examples/s]Tokenizing train dataset:  49%|████▉     | 11816/24227 [00:44<00:47, 258.73 examples/s]Tokenizing train dataset:  47%|████▋     | 11401/24227 [00:44<00:51, 249.44 examples/s]Tokenizing train dataset:  48%|████▊     | 11675/24227 [00:44<00:47, 263.03 examples/s]Tokenizing train dataset:  49%|████▉     | 11853/24227 [00:44<00:43, 284.25 examples/s]Tokenizing train dataset:  47%|████▋     | 11432/24227 [00:44<00:48, 261.36 examples/s]Tokenizing train dataset:  48%|████▊     | 11707/24227 [00:44<00:45, 274.49 examples/s]Tokenizing train dataset:  49%|████▉     | 11900/24227 [00:44<00:37, 326.70 examples/s]Tokenizing train dataset:  48%|████▊     | 11740/24227 [00:44<00:44, 283.52 examples/s]Tokenizing train dataset:  47%|████▋     | 11475/24227 [00:44<00:47, 268.46 examples/s]Tokenizing train dataset:  49%|████▉     | 11960/24227 [00:44<00:30, 397.67 examples/s]Tokenizing train dataset:  49%|████▊     | 11771/24227 [00:44<00:43, 289.05 examples/s]Tokenizing train dataset:  47%|████▋     | 11503/24227 [00:44<00:47, 269.35 examples/s]Tokenizing train dataset:  50%|████▉     | 12003/24227 [00:44<00:30, 405.35 examples/s]Tokenizing train dataset:  48%|████▊     | 11533/24227 [00:45<00:46, 275.36 examples/s]Tokenizing train dataset:  50%|████▉     | 12055/24227 [00:45<00:27, 434.92 examples/s]Tokenizing train dataset:  49%|████▉     | 11816/24227 [00:44<00:48, 256.23 examples/s]Tokenizing train dataset:  48%|████▊     | 11570/24227 [00:45<00:49, 255.05 examples/s]Tokenizing train dataset:  50%|█████     | 12126/24227 [00:45<00:28, 425.49 examples/s]Tokenizing train dataset:  49%|████▉     | 11851/24227 [00:44<00:44, 276.77 examples/s]Tokenizing train dataset:  48%|████▊     | 11606/24227 [00:45<00:45, 277.16 examples/s]Tokenizing train dataset:  50%|█████     | 12199/24227 [00:45<00:24, 501.14 examples/s]Tokenizing train dataset:  49%|████▉     | 11908/24227 [00:44<00:35, 347.27 examples/s]Tokenizing train dataset:  49%|████▉     | 11981/24227 [00:44<00:27, 440.00 examples/s]Tokenizing train dataset:  51%|█████     | 12282/24227 [00:45<00:23, 516.82 examples/s]Tokenizing train dataset:  48%|████▊     | 11650/24227 [00:45<00:44, 279.70 examples/s]Tokenizing train dataset:  50%|████▉     | 12040/24227 [00:45<00:25, 476.97 examples/s]Tokenizing train dataset:  51%|█████     | 12335/24227 [00:45<00:22, 519.24 examples/s]Tokenizing train dataset:  48%|████▊     | 11690/24227 [00:45<00:46, 270.13 examples/s]Tokenizing train dataset:  50%|████▉     | 12094/24227 [00:45<00:24, 493.18 examples/s]Tokenizing train dataset:  51%|█████     | 12399/24227 [00:45<00:21, 546.76 examples/s]Tokenizing train dataset:  48%|████▊     | 11718/24227 [00:45<00:46, 268.71 examples/s]Tokenizing train dataset:  50%|█████     | 12157/24227 [00:45<00:22, 528.98 examples/s]Tokenizing train dataset:  52%|█████▏    | 12486/24227 [00:45<00:21, 556.15 examples/s]Tokenizing train dataset:  49%|████▊     | 11759/24227 [00:45<00:46, 268.97 examples/s]Tokenizing train dataset:  51%|█████     | 12249/24227 [00:45<00:21, 557.01 examples/s]Tokenizing train dataset:  52%|█████▏    | 12561/24227 [00:46<00:21, 533.48 examples/s]Tokenizing train dataset:  49%|████▊     | 11790/24227 [00:45<00:45, 275.07 examples/s]Tokenizing train dataset:  51%|█████     | 12315/24227 [00:45<00:20, 580.89 examples/s]Tokenizing train dataset:  52%|█████▏    | 12625/24227 [00:46<00:20, 556.06 examples/s]Tokenizing train dataset:  51%|█████     | 12403/24227 [00:45<00:20, 581.75 examples/s]Tokenizing train dataset:  52%|█████▏    | 12697/24227 [00:46<00:19, 596.49 examples/s]Tokenizing train dataset:  49%|████▉     | 11830/24227 [00:46<00:52, 237.59 examples/s]Tokenizing train dataset:  51%|█████▏    | 12465/24227 [00:45<00:20, 587.84 examples/s]Tokenizing train dataset:  53%|█████▎    | 12766/24227 [00:46<00:18, 617.93 examples/s]Tokenizing train dataset:  49%|████▉     | 11879/24227 [00:46<00:42, 291.35 examples/s]Tokenizing train dataset:  49%|████▉     | 11917/24227 [00:46<00:40, 305.10 examples/s]Tokenizing train dataset:  52%|█████▏    | 12536/24227 [00:45<00:22, 517.85 examples/s]Tokenizing train dataset:  53%|█████▎    | 12845/24227 [00:46<00:20, 556.17 examples/s]Tokenizing train dataset:  49%|████▉     | 11985/24227 [00:46<00:31, 393.17 examples/s]Tokenizing train dataset:  52%|█████▏    | 12605/24227 [00:46<00:21, 552.34 examples/s]Tokenizing train dataset:  53%|█████▎    | 12937/24227 [00:46<00:19, 567.55 examples/s]Tokenizing train dataset:  50%|████▉     | 12055/24227 [00:46<00:25, 470.89 examples/s]Tokenizing train dataset:  52%|█████▏    | 12672/24227 [00:46<00:19, 580.54 examples/s]Tokenizing train dataset:  50%|█████     | 12120/24227 [00:46<00:23, 516.77 examples/s]Tokenizing train dataset:  53%|█████▎    | 12733/24227 [00:46<00:19, 586.75 examples/s]Tokenizing train dataset:  54%|█████▍    | 13024/24227 [00:46<00:19, 565.99 examples/s]Tokenizing train dataset:  50%|█████     | 12198/24227 [00:46<00:24, 493.64 examples/s]Tokenizing train dataset:  53%|█████▎    | 12809/24227 [00:46<00:22, 515.83 examples/s]Tokenizing train dataset:  54%|█████▍    | 13097/24227 [00:47<00:21, 506.71 examples/s]Tokenizing train dataset:  51%|█████     | 12255/24227 [00:46<00:23, 511.64 examples/s]Tokenizing train dataset:  53%|█████▎    | 12867/24227 [00:46<00:21, 526.52 examples/s]Tokenizing train dataset:  54%|█████▍    | 13153/24227 [00:47<00:21, 514.32 examples/s]Tokenizing train dataset:  51%|█████     | 12319/24227 [00:47<00:21, 541.37 examples/s]Tokenizing train dataset:  53%|█████▎    | 12930/24227 [00:46<00:20, 550.75 examples/s]Tokenizing train dataset:  55%|█████▍    | 13217/24227 [00:47<00:20, 540.21 examples/s]Tokenizing train dataset:  51%|█████     | 12387/24227 [00:47<00:20, 577.39 examples/s]Tokenizing train dataset:  54%|█████▎    | 13022/24227 [00:46<00:19, 568.00 examples/s]Tokenizing train dataset:  51%|█████▏    | 12448/24227 [00:47<00:20, 578.37 examples/s]Tokenizing train dataset:  55%|█████▍    | 13301/24227 [00:47<00:20, 541.47 examples/s]Tokenizing train dataset:  54%|█████▍    | 13080/24227 [00:46<00:19, 566.66 examples/s]Tokenizing train dataset:  52%|█████▏    | 12538/24227 [00:47<00:20, 583.40 examples/s]Tokenizing train dataset:  55%|█████▌    | 13367/24227 [00:47<00:21, 507.04 examples/s]Tokenizing train dataset:  54%|█████▍    | 13173/24227 [00:47<00:19, 580.13 examples/s]Tokenizing train dataset:  52%|█████▏    | 12609/24227 [00:47<00:22, 514.98 examples/s]Tokenizing train dataset:  55%|█████▌    | 13440/24227 [00:47<00:22, 471.81 examples/s]Tokenizing train dataset:  55%|█████▍    | 13235/24227 [00:47<00:21, 521.17 examples/s]Tokenizing train dataset:  52%|█████▏    | 12681/24227 [00:47<00:20, 561.41 examples/s]Tokenizing train dataset:  56%|█████▌    | 13503/24227 [00:47<00:21, 505.07 examples/s]Tokenizing train dataset:  56%|█████▌    | 13558/24227 [00:47<00:20, 513.70 examples/s]Tokenizing train dataset:  55%|█████▍    | 13314/24227 [00:47<00:20, 520.58 examples/s]Tokenizing train dataset:  53%|█████▎    | 12775/24227 [00:47<00:19, 582.68 examples/s]Tokenizing train dataset:  56%|█████▋    | 13629/24227 [00:48<00:18, 559.08 examples/s]Tokenizing train dataset:  55%|█████▌    | 13376/24227 [00:47<00:19, 542.76 examples/s]Tokenizing train dataset:  53%|█████▎    | 12846/24227 [00:47<00:18, 611.04 examples/s]Tokenizing train dataset:  57%|█████▋    | 13701/24227 [00:48<00:17, 599.86 examples/s]Tokenizing train dataset:  56%|█████▌    | 13459/24227 [00:47<00:19, 544.32 examples/s]Tokenizing train dataset:  53%|█████▎    | 12944/24227 [00:48<00:18, 622.76 examples/s]Tokenizing train dataset:  57%|█████▋    | 13770/24227 [00:48<00:16, 622.63 examples/s]Tokenizing train dataset:  56%|█████▌    | 13520/24227 [00:47<00:19, 555.38 examples/s]Tokenizing train dataset:  54%|█████▍    | 13034/24227 [00:48<00:18, 609.23 examples/s]Tokenizing train dataset:  57%|█████▋    | 13863/24227 [00:48<00:16, 617.60 examples/s]Tokenizing train dataset:  56%|█████▌    | 13590/24227 [00:47<00:18, 586.26 examples/s]Tokenizing train dataset:  57%|█████▋    | 13926/24227 [00:48<00:16, 616.38 examples/s]Tokenizing train dataset:  54%|█████▍    | 13124/24227 [00:48<00:18, 599.46 examples/s]Tokenizing train dataset:  56%|█████▋    | 13673/24227 [00:47<00:18, 573.46 examples/s]Tokenizing train dataset:  54%|█████▍    | 13189/24227 [00:48<00:18, 609.77 examples/s]Tokenizing train dataset:  58%|█████▊    | 13997/24227 [00:48<00:18, 562.97 examples/s]Tokenizing train dataset:  57%|█████▋    | 13741/24227 [00:48<00:17, 597.12 examples/s]Tokenizing train dataset:  58%|█████▊    | 14056/24227 [00:48<00:17, 566.28 examples/s]Tokenizing train dataset:  57%|█████▋    | 13805/24227 [00:48<00:17, 603.40 examples/s]Tokenizing train dataset:  55%|█████▍    | 13273/24227 [00:48<00:18, 587.32 examples/s]Tokenizing train dataset:  58%|█████▊    | 14132/24227 [00:48<00:18, 540.37 examples/s]Tokenizing train dataset:  57%|█████▋    | 13889/24227 [00:48<00:17, 580.90 examples/s]Tokenizing train dataset:  55%|█████▌    | 13351/24227 [00:48<00:19, 563.47 examples/s]Tokenizing train dataset:  59%|█████▊    | 14203/24227 [00:48<00:17, 577.04 examples/s]Tokenizing train dataset:  58%|█████▊    | 13950/24227 [00:48<00:17, 582.36 examples/s]Tokenizing train dataset:  55%|█████▌    | 13444/24227 [00:49<00:18, 572.15 examples/s]Tokenizing train dataset:  59%|█████▉    | 14274/24227 [00:49<00:21, 465.69 examples/s]Tokenizing train dataset:  58%|█████▊    | 14011/24227 [00:48<00:23, 442.77 examples/s]Tokenizing train dataset:  56%|█████▌    | 13520/24227 [00:49<00:20, 522.84 examples/s]Tokenizing train dataset:  59%|█████▉    | 14348/24227 [00:49<00:21, 462.50 examples/s]Tokenizing train dataset:  58%|█████▊    | 14076/24227 [00:48<00:23, 427.35 examples/s]Tokenizing train dataset:  56%|█████▌    | 13593/24227 [00:49<00:26, 406.35 examples/s]Tokenizing train dataset:  59%|█████▉    | 14410/24227 [00:49<00:24, 403.29 examples/s]Tokenizing train dataset:  58%|█████▊    | 14155/24227 [00:49<00:24, 416.01 examples/s]Tokenizing train dataset:  56%|█████▋    | 13660/24227 [00:49<00:23, 451.99 examples/s]Tokenizing train dataset:  60%|█████▉    | 14470/24227 [00:49<00:22, 441.63 examples/s]Tokenizing train dataset:  59%|█████▊    | 14216/24227 [00:49<00:22, 453.03 examples/s]Tokenizing train dataset:  57%|█████▋    | 13740/24227 [00:49<00:20, 520.29 examples/s]Tokenizing train dataset:  60%|█████▉    | 14520/24227 [00:49<00:21, 451.18 examples/s]Tokenizing train dataset:  59%|█████▉    | 14271/24227 [00:49<00:21, 471.69 examples/s]Tokenizing train dataset:  57%|█████▋    | 13810/24227 [00:49<00:18, 555.89 examples/s]Tokenizing train dataset:  60%|██████    | 14576/24227 [00:49<00:20, 476.28 examples/s]Tokenizing train dataset:  59%|█████▉    | 14341/24227 [00:49<00:18, 524.02 examples/s]Tokenizing train dataset:  60%|██████    | 14630/24227 [00:49<00:19, 490.24 examples/s]Tokenizing train dataset:  57%|█████▋    | 13899/24227 [00:49<00:18, 564.66 examples/s]Tokenizing train dataset:  60%|█████▉    | 14420/24227 [00:49<00:18, 519.63 examples/s]Tokenizing train dataset:  61%|██████    | 14692/24227 [00:50<00:18, 523.10 examples/s]Tokenizing train dataset:  60%|█████▉    | 14488/24227 [00:49<00:17, 557.07 examples/s]Tokenizing train dataset:  58%|█████▊    | 13980/24227 [00:50<00:18, 554.62 examples/s]Tokenizing train dataset:  61%|██████    | 14770/24227 [00:50<00:18, 517.21 examples/s]Tokenizing train dataset:  60%|██████    | 14548/24227 [00:49<00:17, 562.98 examples/s]Tokenizing train dataset:  58%|█████▊    | 14067/24227 [00:50<00:18, 557.31 examples/s]Tokenizing train dataset:  61%|██████    | 14826/24227 [00:50<00:20, 466.17 examples/s]Tokenizing train dataset:  60%|██████    | 14626/24227 [00:49<00:17, 541.79 examples/s]Tokenizing train dataset:  58%|█████▊    | 14140/24227 [00:50<00:16, 595.98 examples/s]Tokenizing train dataset:  61%|██████    | 14690/24227 [00:49<00:16, 561.73 examples/s]Tokenizing train dataset:  59%|█████▊    | 14208/24227 [00:50<00:16, 611.81 examples/s]Tokenizing train dataset:  61%|██████▏   | 14880/24227 [00:50<00:21, 426.85 examples/s]Tokenizing train dataset:  61%|██████    | 14763/24227 [00:50<00:17, 533.52 examples/s]Tokenizing train dataset:  59%|█████▉    | 14305/24227 [00:50<00:16, 616.71 examples/s]Tokenizing train dataset:  62%|██████▏   | 14939/24227 [00:50<00:25, 362.46 examples/s]Tokenizing train dataset:  59%|█████▉    | 14378/24227 [00:50<00:17, 568.88 examples/s]Tokenizing train dataset:  61%|██████    | 14835/24227 [00:50<00:20, 455.05 examples/s]Tokenizing train dataset:  62%|██████▏   | 14992/24227 [00:50<00:28, 323.51 examples/s]Tokenizing train dataset:  60%|█████▉    | 14472/24227 [00:50<00:16, 584.61 examples/s]Tokenizing train dataset:  61%|██████▏   | 14887/24227 [00:50<00:22, 421.90 examples/s]Tokenizing train dataset:  62%|██████▏   | 15031/24227 [00:51<00:27, 335.16 examples/s]Tokenizing train dataset:  60%|██████    | 14561/24227 [00:51<00:16, 583.58 examples/s]Tokenizing train dataset:  62%|██████▏   | 14940/24227 [00:50<00:23, 396.45 examples/s]Tokenizing train dataset:  62%|██████▏   | 15070/24227 [00:51<00:26, 343.88 examples/s]Tokenizing train dataset:  60%|██████    | 14634/24227 [00:51<00:17, 542.56 examples/s]Tokenizing train dataset:  62%|██████▏   | 14992/24227 [00:51<00:44, 205.34 examples/s]Tokenizing train dataset:  62%|██████▏   | 15109/24227 [00:51<01:02, 144.82 examples/s]Tokenizing train dataset:  61%|██████    | 14695/24227 [00:51<00:36, 258.62 examples/s]Tokenizing train dataset:  62%|██████▏   | 15036/24227 [00:51<00:42, 217.95 examples/s]Tokenizing train dataset:  63%|██████▎   | 15156/24227 [00:52<00:52, 173.03 examples/s]Tokenizing train dataset:  61%|██████    | 14759/24227 [00:51<00:32, 287.36 examples/s]Tokenizing train dataset:  62%|██████▏   | 15079/24227 [00:51<00:39, 231.07 examples/s]Tokenizing train dataset:  63%|██████▎   | 15196/24227 [00:52<00:48, 187.65 examples/s]Tokenizing train dataset:  61%|██████    | 14807/24227 [00:52<00:36, 256.88 examples/s]Tokenizing train dataset:  62%|██████▏   | 15118/24227 [00:51<00:46, 195.61 examples/s]Tokenizing train dataset:  63%|██████▎   | 15232/24227 [00:52<00:46, 195.24 examples/s]Tokenizing train dataset:  61%|██████▏   | 14848/24227 [00:52<00:38, 245.07 examples/s]Tokenizing train dataset:  63%|██████▎   | 15159/24227 [00:51<00:43, 207.39 examples/s]Tokenizing train dataset:  63%|██████▎   | 15271/24227 [00:52<00:43, 205.01 examples/s]Tokenizing train dataset:  61%|██████▏   | 14882/24227 [00:52<00:36, 258.20 examples/s]Tokenizing train dataset:  63%|██████▎   | 15193/24227 [00:52<00:39, 228.27 examples/s]Tokenizing train dataset:  63%|██████▎   | 15304/24227 [00:52<00:39, 226.91 examples/s]Tokenizing train dataset:  62%|██████▏   | 14915/24227 [00:52<00:34, 269.99 examples/s]Tokenizing train dataset:  63%|██████▎   | 15234/24227 [00:52<00:37, 238.48 examples/s]Tokenizing train dataset:  63%|██████▎   | 15341/24227 [00:52<00:40, 221.00 examples/s]Tokenizing train dataset:  62%|██████▏   | 14951/24227 [00:52<00:35, 259.56 examples/s]Tokenizing train dataset:  63%|██████▎   | 15262/24227 [00:52<00:36, 245.83 examples/s]Tokenizing train dataset:  63%|██████▎   | 15379/24227 [00:52<00:40, 221.06 examples/s]Tokenizing train dataset:  63%|██████▎   | 15291/24227 [00:52<00:35, 254.12 examples/s]Tokenizing train dataset:  62%|██████▏   | 14996/24227 [00:52<00:34, 269.18 examples/s]Tokenizing train dataset:  64%|██████▎   | 15413/24227 [00:53<00:36, 243.79 examples/s]Tokenizing train dataset:  63%|██████▎   | 15329/24227 [00:52<00:35, 250.58 examples/s]Tokenizing train dataset:  62%|██████▏   | 15040/24227 [00:53<00:33, 274.05 examples/s]Tokenizing train dataset:  64%|██████▎   | 15441/24227 [00:53<00:35, 248.64 examples/s]Tokenizing train dataset:  63%|██████▎   | 15356/24227 [00:52<00:35, 252.68 examples/s]Tokenizing train dataset:  62%|██████▏   | 15082/24227 [00:53<00:33, 273.23 examples/s]Tokenizing train dataset:  64%|██████▍   | 15479/24227 [00:53<00:37, 236.13 examples/s]Tokenizing train dataset:  64%|██████▎   | 15394/24227 [00:52<00:40, 217.82 examples/s]Tokenizing train dataset:  62%|██████▏   | 15120/24227 [00:53<00:39, 229.31 examples/s]Tokenizing train dataset:  64%|██████▍   | 15520/24227 [00:53<00:44, 194.55 examples/s]Tokenizing train dataset:  64%|██████▎   | 15432/24227 [00:53<00:43, 202.51 examples/s]Tokenizing train dataset:  63%|██████▎   | 15161/24227 [00:53<00:42, 213.61 examples/s]Tokenizing train dataset:  64%|██████▍   | 15558/24227 [00:53<00:44, 194.96 examples/s]Tokenizing train dataset:  63%|██████▎   | 15192/24227 [00:53<00:39, 230.19 examples/s]Tokenizing train dataset:  64%|██████▍   | 15469/24227 [00:53<00:45, 193.80 examples/s]Tokenizing train dataset:  64%|██████▍   | 15591/24227 [00:53<00:39, 218.94 examples/s]Tokenizing train dataset:  63%|██████▎   | 15221/24227 [00:53<00:37, 241.90 examples/s]Tokenizing train dataset:  64%|██████▍   | 15498/24227 [00:53<00:41, 210.35 examples/s]Tokenizing train dataset:  63%|██████▎   | 15250/24227 [00:54<00:35, 251.69 examples/s]Tokenizing train dataset:  64%|██████▍   | 15626/24227 [00:54<00:39, 218.33 examples/s]Tokenizing train dataset:  64%|██████▍   | 15540/24227 [00:53<00:38, 224.85 examples/s]Tokenizing train dataset:  63%|██████▎   | 15281/24227 [00:54<00:33, 264.79 examples/s]Tokenizing train dataset:  65%|██████▍   | 15653/24227 [00:54<00:37, 226.37 examples/s]Tokenizing train dataset:  63%|██████▎   | 15309/24227 [00:54<00:33, 265.22 examples/s]Tokenizing train dataset:  65%|██████▍   | 15682/24227 [00:54<00:35, 239.59 examples/s]Tokenizing train dataset:  64%|██████▍   | 15580/24227 [00:53<00:37, 231.59 examples/s]Tokenizing train dataset:  63%|██████▎   | 15347/24227 [00:54<00:37, 236.54 examples/s]Tokenizing train dataset:  65%|██████▍   | 15727/24227 [00:54<00:36, 231.27 examples/s]Tokenizing train dataset:  64%|██████▍   | 15617/24227 [00:53<00:41, 209.78 examples/s]Tokenizing train dataset:  63%|██████▎   | 15377/24227 [00:54<00:35, 248.59 examples/s]Tokenizing train dataset:  65%|██████▌   | 15763/24227 [00:54<00:32, 256.68 examples/s]Tokenizing train dataset:  65%|██████▍   | 15648/24227 [00:54<00:37, 228.06 examples/s]Tokenizing train dataset:  64%|██████▎   | 15413/24227 [00:54<00:32, 273.12 examples/s]Tokenizing train dataset:  65%|██████▌   | 15798/24227 [00:54<00:30, 274.80 examples/s]Tokenizing train dataset:  65%|██████▍   | 15688/24227 [00:54<00:35, 238.40 examples/s]Tokenizing train dataset:  65%|██████▌   | 15834/24227 [00:54<00:28, 293.92 examples/s]Tokenizing train dataset:  64%|██████▍   | 15460/24227 [00:54<00:30, 283.02 examples/s]Tokenizing train dataset:  65%|██████▍   | 15728/24227 [00:54<00:31, 272.32 examples/s]Tokenizing train dataset:  66%|██████▌   | 15880/24227 [00:54<00:28, 294.80 examples/s]Tokenizing train dataset:  65%|██████▌   | 15760/24227 [00:54<00:30, 279.70 examples/s]Tokenizing train dataset:  64%|██████▍   | 15500/24227 [00:54<00:31, 274.52 examples/s]Tokenizing train dataset:  66%|██████▌   | 15911/24227 [00:55<00:28, 295.73 examples/s]Tokenizing train dataset:  65%|██████▌   | 15805/24227 [00:54<00:29, 282.47 examples/s]Tokenizing train dataset:  64%|██████▍   | 15543/24227 [00:55<00:31, 276.58 examples/s]Tokenizing train dataset:  66%|██████▌   | 15943/24227 [00:55<00:27, 299.98 examples/s]Tokenizing train dataset:  65%|██████▌   | 15838/24227 [00:54<00:28, 290.73 examples/s]Tokenizing train dataset:  64%|██████▍   | 15580/24227 [00:55<00:29, 297.03 examples/s]Tokenizing train dataset:  66%|██████▌   | 15985/24227 [00:55<00:28, 289.88 examples/s]Tokenizing train dataset:  66%|██████▌   | 15880/24227 [00:54<00:29, 283.84 examples/s]Tokenizing train dataset:  64%|██████▍   | 15620/24227 [00:55<00:30, 283.70 examples/s]Tokenizing train dataset:  66%|██████▌   | 16020/24227 [00:55<00:27, 302.50 examples/s]Tokenizing train dataset:  66%|██████▌   | 15914/24227 [00:54<00:28, 294.34 examples/s]Tokenizing train dataset:  66%|██████▋   | 16057/24227 [00:55<00:25, 317.30 examples/s]Tokenizing train dataset:  65%|██████▍   | 15667/24227 [00:55<00:29, 292.19 examples/s]Tokenizing train dataset:  66%|██████▌   | 15948/24227 [00:55<00:27, 301.43 examples/s]Tokenizing train dataset:  65%|██████▍   | 15697/24227 [00:55<00:29, 292.65 examples/s]Tokenizing train dataset:  66%|██████▋   | 16103/24227 [00:55<00:26, 306.77 examples/s]Tokenizing train dataset:  65%|██████▍   | 15730/24227 [00:55<00:28, 298.35 examples/s]Tokenizing train dataset:  66%|██████▌   | 15995/24227 [00:55<00:27, 296.99 examples/s]Tokenizing train dataset:  67%|██████▋   | 16140/24227 [00:55<00:25, 320.42 examples/s]Tokenizing train dataset:  65%|██████▌   | 15766/24227 [00:55<00:26, 313.39 examples/s]Tokenizing train dataset:  66%|██████▌   | 16031/24227 [00:55<00:26, 310.04 examples/s]Tokenizing train dataset:  67%|██████▋   | 16178/24227 [00:55<00:24, 333.95 examples/s]Tokenizing train dataset:  65%|██████▌   | 15800/24227 [00:55<00:26, 316.57 examples/s]Tokenizing train dataset:  66%|██████▋   | 16066/24227 [00:55<00:25, 318.59 examples/s]Tokenizing train dataset:  67%|██████▋   | 16220/24227 [00:56<00:26, 307.30 examples/s]Tokenizing train dataset:  65%|██████▌   | 15849/24227 [00:56<00:26, 318.59 examples/s]Tokenizing train dataset:  67%|██████▋   | 16120/24227 [00:55<00:24, 328.71 examples/s]Tokenizing train dataset:  67%|██████▋   | 16252/24227 [00:56<00:25, 307.77 examples/s]Tokenizing train dataset:  66%|██████▌   | 15902/24227 [00:56<00:25, 324.88 examples/s]Tokenizing train dataset:  67%|██████▋   | 16164/24227 [00:55<00:25, 313.48 examples/s]Tokenizing train dataset:  67%|██████▋   | 16297/24227 [00:56<00:26, 300.85 examples/s]Tokenizing train dataset:  67%|██████▋   | 16196/24227 [00:55<00:25, 314.36 examples/s]Tokenizing train dataset:  67%|██████▋   | 16330/24227 [00:56<00:25, 306.24 examples/s]Tokenizing train dataset:  66%|██████▌   | 15952/24227 [00:56<00:25, 320.97 examples/s]Tokenizing train dataset:  67%|██████▋   | 16230/24227 [00:55<00:25, 317.02 examples/s]Tokenizing train dataset:  68%|██████▊   | 16362/24227 [00:56<00:25, 306.73 examples/s]Tokenizing train dataset:  66%|██████▌   | 16001/24227 [00:56<00:25, 318.58 examples/s]Tokenizing train dataset:  67%|██████▋   | 16263/24227 [00:56<00:24, 319.24 examples/s]Tokenizing train dataset:  68%|██████▊   | 16409/24227 [00:56<00:25, 307.43 examples/s]Tokenizing train dataset:  66%|██████▌   | 16036/24227 [00:56<00:25, 324.35 examples/s]Tokenizing train dataset:  67%|██████▋   | 16306/24227 [00:56<00:26, 303.84 examples/s]Tokenizing train dataset:  68%|██████▊   | 16453/24227 [00:56<00:25, 299.29 examples/s]Tokenizing train dataset:  66%|██████▋   | 16087/24227 [00:56<00:24, 326.81 examples/s]Tokenizing train dataset:  67%|██████▋   | 16352/24227 [00:56<00:26, 301.90 examples/s]Tokenizing train dataset:  68%|██████▊   | 16491/24227 [00:56<00:24, 316.27 examples/s]Tokenizing train dataset:  67%|██████▋   | 16122/24227 [00:56<00:24, 329.43 examples/s]Tokenizing train dataset:  68%|██████▊   | 16570/24227 [00:57<00:17, 434.84 examples/s]Tokenizing train dataset:  67%|██████▋   | 16162/24227 [00:57<00:23, 342.98 examples/s]Tokenizing train dataset:  68%|██████▊   | 16392/24227 [00:56<00:27, 287.26 examples/s]Tokenizing train dataset:  69%|██████▊   | 16634/24227 [00:57<00:15, 482.54 examples/s]Tokenizing train dataset:  68%|██████▊   | 16435/24227 [00:56<00:27, 285.58 examples/s]Tokenizing train dataset:  67%|██████▋   | 16213/24227 [00:57<00:23, 338.36 examples/s]Tokenizing train dataset:  69%|██████▉   | 16688/24227 [00:57<00:15, 489.96 examples/s]Tokenizing train dataset:  68%|██████▊   | 16468/24227 [00:56<00:26, 292.14 examples/s]Tokenizing train dataset:  67%|██████▋   | 16250/24227 [00:57<00:26, 304.80 examples/s]Tokenizing train dataset:  69%|██████▉   | 16773/24227 [00:57<00:14, 514.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 16510/24227 [00:56<00:24, 321.50 examples/s]Tokenizing train dataset:  67%|██████▋   | 16285/24227 [00:57<00:25, 314.97 examples/s]Tokenizing train dataset:  69%|██████▉   | 16834/24227 [00:57<00:13, 537.38 examples/s]Tokenizing train dataset:  68%|██████▊   | 16586/24227 [00:56<00:17, 433.53 examples/s]Tokenizing train dataset:  70%|██████▉   | 16900/24227 [00:57<00:12, 568.37 examples/s]Tokenizing train dataset:  69%|██████▊   | 16645/24227 [00:57<00:16, 472.58 examples/s]Tokenizing train dataset:  67%|██████▋   | 16336/24227 [00:57<00:24, 320.05 examples/s]Tokenizing train dataset:  70%|███████   | 16963/24227 [00:57<00:14, 486.38 examples/s]Tokenizing train dataset:  69%|██████▉   | 16714/24227 [00:57<00:16, 449.44 examples/s]Tokenizing train dataset:  68%|██████▊   | 16370/24227 [00:57<00:28, 277.58 examples/s]Tokenizing train dataset:  70%|███████   | 17036/24227 [00:57<00:13, 542.34 examples/s]Tokenizing train dataset:  69%|██████▉   | 16784/24227 [00:57<00:14, 506.11 examples/s]Tokenizing train dataset:  68%|██████▊   | 16401/24227 [00:57<00:27, 281.46 examples/s]Tokenizing train dataset:  69%|██████▉   | 16837/24227 [00:57<00:14, 511.19 examples/s]Tokenizing train dataset:  71%|███████   | 17131/24227 [00:58<00:12, 571.11 examples/s]Tokenizing train dataset:  68%|██████▊   | 16441/24227 [00:58<00:28, 274.49 examples/s]Tokenizing train dataset:  70%|██████▉   | 16895/24227 [00:57<00:13, 528.54 examples/s]Tokenizing train dataset:  71%|███████   | 17198/24227 [00:58<00:11, 593.29 examples/s]Tokenizing train dataset:  68%|██████▊   | 16471/24227 [00:58<00:27, 280.29 examples/s]Tokenizing train dataset:  70%|██████▉   | 16950/24227 [00:57<00:13, 532.37 examples/s]Tokenizing train dataset:  71%|███████▏  | 17271/24227 [00:58<00:11, 624.42 examples/s]Tokenizing train dataset:  68%|██████▊   | 16536/24227 [00:58<00:20, 370.57 examples/s]Tokenizing train dataset:  70%|███████   | 17020/24227 [00:57<00:12, 574.84 examples/s]Tokenizing train dataset:  68%|██████▊   | 16581/24227 [00:58<00:19, 390.65 examples/s]Tokenizing train dataset:  72%|███████▏  | 17342/24227 [00:58<00:12, 560.46 examples/s]Tokenizing train dataset:  71%|███████   | 17088/24227 [00:57<00:11, 596.96 examples/s]Tokenizing train dataset:  72%|███████▏  | 17408/24227 [00:58<00:11, 584.66 examples/s]Tokenizing train dataset:  69%|██████▊   | 16650/24227 [00:58<00:18, 413.53 examples/s]Tokenizing train dataset:  71%|███████   | 17168/24227 [00:58<00:12, 550.28 examples/s]Tokenizing train dataset:  69%|██████▉   | 16714/24227 [00:58<00:16, 468.72 examples/s]Tokenizing train dataset:  72%|███████▏  | 17492/24227 [00:58<00:11, 570.29 examples/s]Tokenizing train dataset:  71%|███████   | 17228/24227 [00:58<00:12, 559.59 examples/s]Tokenizing train dataset:  69%|██████▉   | 16784/24227 [00:58<00:14, 525.71 examples/s]Tokenizing train dataset:  72%|███████▏  | 17551/24227 [00:58<00:11, 569.14 examples/s]Tokenizing train dataset:  70%|██████▉   | 16855/24227 [00:58<00:12, 569.03 examples/s]Tokenizing train dataset:  71%|███████▏  | 17310/24227 [00:58<00:12, 553.87 examples/s]Tokenizing train dataset:  73%|███████▎  | 17641/24227 [00:58<00:11, 578.44 examples/s]Tokenizing train dataset:  70%|██████▉   | 16923/24227 [00:58<00:12, 595.67 examples/s]Tokenizing train dataset:  72%|███████▏  | 17382/24227 [00:58<00:11, 593.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 17738/24227 [00:59<00:10, 596.30 examples/s]Tokenizing train dataset:  70%|███████   | 17020/24227 [00:59<00:11, 606.12 examples/s]Tokenizing train dataset:  72%|███████▏  | 17463/24227 [00:58<00:11, 569.58 examples/s]Tokenizing train dataset:  74%|███████▎  | 17808/24227 [00:59<00:11, 553.88 examples/s]Tokenizing train dataset:  71%|███████   | 17103/24227 [00:59<00:12, 584.61 examples/s]Tokenizing train dataset:  72%|███████▏  | 17528/24227 [00:58<00:12, 520.98 examples/s]Tokenizing train dataset:  74%|███████▍  | 17870/24227 [00:59<00:11, 564.59 examples/s]Tokenizing train dataset:  71%|███████   | 17178/24227 [00:59<00:11, 623.09 examples/s]Tokenizing train dataset:  73%|███████▎  | 17600/24227 [00:58<00:13, 498.55 examples/s]Tokenizing train dataset:  74%|███████▍  | 17929/24227 [00:59<00:11, 569.45 examples/s]Tokenizing train dataset:  71%|███████   | 17251/24227 [00:59<00:10, 649.74 examples/s]Tokenizing train dataset:  73%|███████▎  | 17673/24227 [00:59<00:14, 444.61 examples/s]Tokenizing train dataset:  74%|███████▍  | 18004/24227 [00:59<00:12, 499.75 examples/s]Tokenizing train dataset:  72%|███████▏  | 17325/24227 [00:59<00:18, 372.71 examples/s]Tokenizing train dataset:  73%|███████▎  | 17748/24227 [00:59<00:16, 393.84 examples/s]Tokenizing train dataset:  75%|███████▍  | 18080/24227 [00:59<00:14, 420.89 examples/s]Tokenizing train dataset:  72%|███████▏  | 17383/24227 [00:59<00:16, 408.48 examples/s]Tokenizing train dataset:  73%|███████▎  | 17803/24227 [00:59<00:15, 419.84 examples/s]Tokenizing train dataset:  75%|███████▍  | 18141/24227 [00:59<00:13, 456.72 examples/s]Tokenizing train dataset:  72%|███████▏  | 17447/24227 [00:59<00:14, 452.94 examples/s]Tokenizing train dataset:  74%|███████▎  | 17867/24227 [00:59<00:13, 464.26 examples/s]Tokenizing train dataset:  75%|███████▌  | 18215/24227 [01:00<00:11, 518.44 examples/s]Tokenizing train dataset:  72%|███████▏  | 17516/24227 [01:00<00:15, 446.52 examples/s]Tokenizing train dataset:  74%|███████▍  | 17927/24227 [00:59<00:14, 442.56 examples/s]Tokenizing train dataset:  75%|███████▌  | 18290/24227 [01:00<00:12, 490.83 examples/s]Tokenizing train dataset:  74%|███████▍  | 17992/24227 [00:59<00:12, 487.88 examples/s]Tokenizing train dataset:  73%|███████▎  | 17571/24227 [01:00<00:14, 466.39 examples/s]Tokenizing train dataset:  76%|███████▌  | 18366/24227 [01:00<00:10, 550.07 examples/s]Tokenizing train dataset:  74%|███████▍  | 18045/24227 [00:59<00:12, 496.00 examples/s]Tokenizing train dataset:  73%|███████▎  | 17641/24227 [01:00<00:14, 463.59 examples/s]Tokenizing train dataset:  76%|███████▌  | 18454/24227 [01:00<00:10, 558.40 examples/s]Tokenizing train dataset:  75%|███████▍  | 18114/24227 [00:59<00:11, 542.82 examples/s]Tokenizing train dataset:  73%|███████▎  | 17698/24227 [01:00<00:13, 486.93 examples/s]Tokenizing train dataset:  75%|███████▌  | 18174/24227 [01:00<00:10, 555.28 examples/s]Tokenizing train dataset:  77%|███████▋  | 18540/24227 [01:00<00:10, 557.85 examples/s]Tokenizing train dataset:  73%|███████▎  | 17764/24227 [01:00<00:12, 527.22 examples/s]Tokenizing train dataset:  75%|███████▌  | 18251/24227 [01:00<00:09, 610.26 examples/s]Tokenizing train dataset:  77%|███████▋  | 18601/24227 [01:00<00:09, 567.37 examples/s]Tokenizing train dataset:  74%|███████▎  | 17826/24227 [01:00<00:11, 548.35 examples/s]Tokenizing train dataset:  76%|███████▌  | 18318/24227 [01:00<00:09, 625.07 examples/s]Tokenizing train dataset:  77%|███████▋  | 18680/24227 [01:00<00:09, 613.32 examples/s]Tokenizing train dataset:  74%|███████▍  | 17885/24227 [01:00<00:11, 558.06 examples/s]Tokenizing train dataset:  76%|███████▌  | 18389/24227 [01:00<00:09, 639.00 examples/s]Tokenizing train dataset:  78%|███████▊  | 18783/24227 [01:01<00:08, 633.69 examples/s]Tokenizing train dataset:  74%|███████▍  | 17977/24227 [01:00<00:10, 576.73 examples/s]Tokenizing train dataset:  76%|███████▋  | 18479/24227 [01:00<00:09, 620.70 examples/s]Tokenizing train dataset:  78%|███████▊  | 18864/24227 [01:01<00:09, 538.74 examples/s]Tokenizing train dataset:  75%|███████▍  | 18055/24227 [01:01<00:12, 501.71 examples/s]Tokenizing train dataset:  77%|███████▋  | 18543/24227 [01:00<00:10, 546.34 examples/s]Tokenizing train dataset:  78%|███████▊  | 18929/24227 [01:01<00:09, 562.60 examples/s]Tokenizing train dataset:  75%|███████▍  | 18123/24227 [01:01<00:11, 540.80 examples/s]Tokenizing train dataset:  77%|███████▋  | 18600/24227 [01:00<00:10, 548.81 examples/s]Tokenizing train dataset:  75%|███████▌  | 18181/24227 [01:01<00:10, 549.68 examples/s]Tokenizing train dataset:  77%|███████▋  | 18680/24227 [01:00<00:09, 602.63 examples/s]Tokenizing train dataset:  78%|███████▊  | 19010/24227 [01:01<00:09, 551.75 examples/s]Tokenizing train dataset:  75%|███████▌  | 18257/24227 [01:01<00:09, 601.07 examples/s]Tokenizing train dataset:  77%|███████▋  | 18744/24227 [01:01<00:09, 606.22 examples/s]Tokenizing train dataset:  79%|███████▉  | 19099/24227 [01:01<00:09, 561.81 examples/s]Tokenizing train dataset:  76%|███████▌  | 18323/24227 [01:01<00:09, 616.69 examples/s]Tokenizing train dataset:  78%|███████▊  | 18824/24227 [01:01<00:08, 658.08 examples/s]Tokenizing train dataset:  79%|███████▉  | 19171/24227 [01:01<00:08, 596.73 examples/s]Tokenizing train dataset:  76%|███████▌  | 18390/24227 [01:01<00:09, 625.93 examples/s]Tokenizing train dataset:  78%|███████▊  | 18925/24227 [01:01<00:08, 658.27 examples/s]Tokenizing train dataset:  79%|███████▉  | 19237/24227 [01:01<00:08, 610.50 examples/s]Tokenizing train dataset:  76%|███████▌  | 18454/24227 [01:01<00:09, 624.10 examples/s]Tokenizing train dataset:  78%|███████▊  | 19011/24227 [01:01<00:08, 625.29 examples/s]Tokenizing train dataset:  80%|███████▉  | 19326/24227 [01:01<00:08, 598.57 examples/s]Tokenizing train dataset:  77%|███████▋  | 18547/24227 [01:01<00:09, 620.68 examples/s]Tokenizing train dataset:  77%|███████▋  | 18610/24227 [01:02<00:09, 622.06 examples/s]Tokenizing train dataset:  79%|███████▉  | 19112/24227 [01:01<00:08, 637.46 examples/s]Tokenizing train dataset:  80%|████████  | 19402/24227 [01:02<00:08, 566.10 examples/s]Tokenizing train dataset:  77%|███████▋  | 18686/24227 [01:02<00:08, 657.40 examples/s]Tokenizing train dataset:  79%|███████▉  | 19179/24227 [01:01<00:07, 643.67 examples/s]Tokenizing train dataset:  81%|████████  | 19515/24227 [01:02<00:07, 624.53 examples/s]Tokenizing train dataset:  77%|███████▋  | 18755/24227 [01:02<00:08, 658.24 examples/s]Tokenizing train dataset:  79%|███████▉  | 19258/24227 [01:01<00:08, 601.43 examples/s]Tokenizing train dataset:  81%|████████  | 19617/24227 [01:02<00:06, 714.82 examples/s]Tokenizing train dataset:  78%|███████▊  | 18850/24227 [01:02<00:08, 646.29 examples/s]Tokenizing train dataset:  81%|████████▏ | 19724/24227 [01:02<00:05, 801.46 examples/s]Tokenizing train dataset:  80%|███████▉  | 19334/24227 [01:01<00:08, 568.91 examples/s]Tokenizing train dataset:  78%|███████▊  | 18926/24227 [01:02<00:07, 666.32 examples/s]Tokenizing train dataset:  82%|████████▏ | 19810/24227 [01:02<00:05, 812.72 examples/s]Tokenizing train dataset:  80%|████████  | 19392/24227 [01:02<00:08, 564.60 examples/s]Tokenizing train dataset:  82%|████████▏ | 19900/24227 [01:02<00:05, 833.32 examples/s]Tokenizing train dataset:  78%|███████▊  | 19013/24227 [01:02<00:08, 632.49 examples/s]Tokenizing train dataset:  80%|████████  | 19484/24227 [01:02<00:08, 567.80 examples/s]Tokenizing train dataset:  83%|████████▎ | 20007/24227 [01:02<00:04, 897.37 examples/s]Tokenizing train dataset:  79%|███████▉  | 19114/24227 [01:02<00:07, 642.13 examples/s]Tokenizing train dataset:  81%|████████  | 19605/24227 [01:02<00:06, 719.11 examples/s]Tokenizing train dataset:  83%|████████▎ | 20125/24227 [01:02<00:04, 976.46 examples/s]Tokenizing train dataset:  79%|███████▉  | 19184/24227 [01:02<00:07, 654.70 examples/s]Tokenizing train dataset:  81%|████████▏ | 19721/24227 [01:02<00:05, 827.44 examples/s]Tokenizing train dataset:  84%|████████▎ | 20234/24227 [01:02<00:03, 1005.24 examples/s]Tokenizing train dataset:  82%|████████▏ | 19833/24227 [01:02<00:04, 903.53 examples/s]Tokenizing train dataset:  84%|████████▍ | 20344/24227 [01:03<00:03, 1031.49 examples/s]Tokenizing train dataset:  80%|███████▉  | 19274/24227 [01:03<00:07, 634.16 examples/s]Tokenizing train dataset:  82%|████████▏ | 19950/24227 [01:02<00:04, 975.36 examples/s]Tokenizing train dataset:  84%|████████▍ | 20457/24227 [01:03<00:03, 1057.82 examples/s]Tokenizing train dataset:  80%|███████▉  | 19352/24227 [01:03<00:08, 590.12 examples/s]Tokenizing train dataset:  83%|████████▎ | 20068/24227 [01:02<00:04, 1030.06 examples/s]Tokenizing train dataset:  85%|████████▌ | 20606/24227 [01:03<00:03, 1026.33 examples/s]Tokenizing train dataset:  83%|████████▎ | 20190/24227 [01:02<00:03, 1080.81 examples/s]Tokenizing train dataset:  80%|████████  | 19454/24227 [01:03<00:07, 615.38 examples/s]Tokenizing train dataset:  84%|████████▍ | 20303/24227 [01:02<00:03, 1094.01 examples/s]Tokenizing train dataset:  86%|████████▌ | 20764/24227 [01:03<00:03, 1030.84 examples/s]Tokenizing train dataset:  81%|████████  | 19568/24227 [01:03<00:06, 733.87 examples/s]Tokenizing train dataset:  84%|████████▍ | 20417/24227 [01:03<00:03, 1104.77 examples/s]Tokenizing train dataset:  81%|████████  | 19658/24227 [01:03<00:05, 773.52 examples/s]Tokenizing train dataset:  86%|████████▌ | 20890/24227 [01:03<00:03, 963.62 examples/s] Tokenizing train dataset:  85%|████████▍ | 20536/24227 [01:03<00:04, 842.80 examples/s] Tokenizing train dataset:  82%|████████▏ | 19786/24227 [01:03<00:06, 712.71 examples/s]Tokenizing train dataset:  87%|████████▋ | 21012/24227 [01:03<00:03, 863.35 examples/s]Tokenizing train dataset:  85%|████████▌ | 20638/24227 [01:03<00:04, 884.11 examples/s]Tokenizing train dataset:  82%|████████▏ | 19903/24227 [01:03<00:05, 814.20 examples/s]Tokenizing train dataset:  87%|████████▋ | 21128/24227 [01:03<00:03, 928.15 examples/s]Tokenizing train dataset:  86%|████████▌ | 20754/24227 [01:03<00:03, 953.09 examples/s]Tokenizing train dataset:  83%|████████▎ | 20010/24227 [01:03<00:04, 874.43 examples/s]Tokenizing train dataset:  88%|████████▊ | 21280/24227 [01:04<00:03, 952.01 examples/s]Tokenizing train dataset:  86%|████████▌ | 20865/24227 [01:03<00:03, 993.18 examples/s]Tokenizing train dataset:  83%|████████▎ | 20130/24227 [01:04<00:04, 956.94 examples/s]Tokenizing train dataset:  87%|████████▋ | 20972/24227 [01:03<00:03, 1011.80 examples/s]Tokenizing train dataset:  84%|████████▎ | 20240/24227 [01:04<00:04, 989.47 examples/s]Tokenizing train dataset:  88%|████████▊ | 21430/24227 [01:04<00:02, 964.97 examples/s]Tokenizing train dataset:  87%|████████▋ | 21138/24227 [01:03<00:02, 1045.76 examples/s]Tokenizing train dataset:  84%|████████▍ | 20393/24227 [01:04<00:03, 996.51 examples/s]Tokenizing train dataset:  89%|████████▉ | 21573/24227 [01:04<00:02, 959.65 examples/s]Tokenizing train dataset:  85%|████████▍ | 20508/24227 [01:04<00:03, 1031.48 examples/s]Tokenizing train dataset:  89%|████████▉ | 21673/24227 [01:04<00:02, 967.53 examples/s]Tokenizing train dataset:  88%|████████▊ | 21302/24227 [01:03<00:02, 1059.38 examples/s]Tokenizing train dataset:  85%|████████▌ | 20663/24227 [01:04<00:03, 1030.67 examples/s]Tokenizing train dataset:  90%|█████████ | 21832/24227 [01:04<00:02, 994.03 examples/s]Tokenizing train dataset:  89%|████████▊ | 21460/24227 [01:04<00:02, 1052.41 examples/s]Tokenizing train dataset:  86%|████████▌ | 20778/24227 [01:04<00:03, 1058.07 examples/s]Tokenizing train dataset:  91%|█████████ | 21942/24227 [01:04<00:02, 1014.91 examples/s]Tokenizing train dataset:  89%|████████▉ | 21575/24227 [01:04<00:02, 1074.71 examples/s]Tokenizing train dataset:  86%|████████▋ | 20899/24227 [01:04<00:03, 871.77 examples/s] Tokenizing train dataset:  91%|█████████ | 22063/24227 [01:04<00:02, 840.25 examples/s] Tokenizing train dataset:  90%|████████▉ | 21690/24227 [01:04<00:03, 783.35 examples/s] Tokenizing train dataset:  87%|████████▋ | 21011/24227 [01:04<00:03, 925.38 examples/s]Tokenizing train dataset:  92%|█████████▏| 22168/24227 [01:05<00:02, 883.24 examples/s]Tokenizing train dataset:  90%|█████████ | 21819/24227 [01:04<00:03, 779.48 examples/s]Tokenizing train dataset:  87%|████████▋ | 21133/24227 [01:05<00:03, 837.45 examples/s]Tokenizing train dataset:  92%|█████████▏| 22287/24227 [01:05<00:02, 809.36 examples/s]Tokenizing train dataset:  91%|█████████ | 21935/24227 [01:04<00:02, 856.70 examples/s]Tokenizing train dataset:  88%|████████▊ | 21240/24227 [01:05<00:03, 887.50 examples/s]Tokenizing train dataset:  92%|█████████▏| 22380/24227 [01:05<00:02, 835.63 examples/s]Tokenizing train dataset:  91%|█████████ | 22033/24227 [01:04<00:02, 880.45 examples/s]Tokenizing train dataset:  88%|████████▊ | 21345/24227 [01:05<00:03, 925.04 examples/s]Tokenizing train dataset:  93%|█████████▎| 22488/24227 [01:05<00:01, 893.31 examples/s]Tokenizing train dataset:  91%|█████████▏| 22139/24227 [01:04<00:02, 923.25 examples/s]Tokenizing train dataset:  89%|████████▊ | 21447/24227 [01:05<00:02, 948.87 examples/s]Tokenizing train dataset:  93%|█████████▎| 22642/24227 [01:05<00:01, 935.54 examples/s]Tokenizing train dataset:  92%|█████████▏| 22261/24227 [01:05<00:02, 859.29 examples/s]Tokenizing train dataset:  89%|████████▉ | 21570/24227 [01:05<00:03, 702.88 examples/s]Tokenizing train dataset:  94%|█████████▍| 22768/24227 [01:05<00:01, 784.19 examples/s]Tokenizing train dataset:  92%|█████████▏| 22391/24227 [01:05<00:02, 858.15 examples/s]Tokenizing train dataset:  89%|████████▉ | 21679/24227 [01:05<00:03, 782.05 examples/s]Tokenizing train dataset:  94%|█████████▍| 22888/24227 [01:05<00:01, 871.80 examples/s]Tokenizing train dataset:  93%|█████████▎| 22506/24227 [01:05<00:01, 926.07 examples/s]Tokenizing train dataset:  90%|████████▉ | 21792/24227 [01:05<00:02, 859.99 examples/s]Tokenizing train dataset:  95%|█████████▌| 23020/24227 [01:06<00:01, 870.38 examples/s]Tokenizing train dataset:  93%|█████████▎| 22640/24227 [01:05<00:01, 911.58 examples/s]Tokenizing train dataset:  90%|█████████ | 21904/24227 [01:06<00:02, 922.81 examples/s]Tokenizing train dataset:  96%|█████████▌| 23173/24227 [01:06<00:01, 913.15 examples/s]Tokenizing train dataset:  94%|█████████▍| 22797/24227 [01:05<00:01, 952.35 examples/s]Tokenizing train dataset:  91%|█████████ | 22053/24227 [01:06<00:02, 942.83 examples/s]Tokenizing train dataset:  96%|█████████▌| 23273/24227 [01:06<00:01, 931.59 examples/s]Tokenizing train dataset:  91%|█████████▏| 22159/24227 [01:06<00:02, 969.36 examples/s]Tokenizing train dataset:  95%|█████████▍| 22952/24227 [01:05<00:01, 974.39 examples/s]Tokenizing train dataset:  97%|█████████▋| 23388/24227 [01:06<00:00, 980.98 examples/s]Tokenizing train dataset:  92%|█████████▏| 22280/24227 [01:06<00:02, 893.28 examples/s]Tokenizing train dataset:  95%|█████████▌| 23079/24227 [01:05<00:01, 932.53 examples/s]Tokenizing train dataset:  97%|█████████▋| 23541/24227 [01:06<00:00, 989.33 examples/s]Tokenizing train dataset:  92%|█████████▏| 22390/24227 [01:06<00:01, 941.08 examples/s]Tokenizing train dataset:  96%|█████████▌| 23190/24227 [01:06<00:01, 970.52 examples/s]Tokenizing train dataset:  98%|█████████▊| 23647/24227 [01:06<00:00, 1005.28 examples/s]Tokenizing train dataset:  93%|█████████▎| 22498/24227 [01:06<00:01, 976.56 examples/s]Tokenizing train dataset:  96%|█████████▌| 23303/24227 [01:06<00:00, 1005.22 examples/s]Tokenizing train dataset:  98%|█████████▊| 23809/24227 [01:06<00:00, 1029.46 examples/s]Tokenizing train dataset:  94%|█████████▎| 22656/24227 [01:06<00:01, 1001.81 examples/s]Tokenizing train dataset:  97%|█████████▋| 23454/24227 [01:06<00:00, 999.50 examples/s] Tokenizing train dataset:  99%|█████████▊| 23921/24227 [01:06<00:00, 1050.54 examples/s]Tokenizing train dataset:  94%|█████████▍| 22771/24227 [01:06<00:01, 1037.87 examples/s]Tokenizing train dataset:  97%|█████████▋| 23558/24227 [01:06<00:00, 1008.14 examples/s]Tokenizing train dataset:  99%|█████████▉| 24032/24227 [01:07<00:00, 1063.65 examples/s]Tokenizing train dataset:  95%|█████████▍| 22930/24227 [01:07<00:01, 1042.14 examples/s]Tokenizing train dataset: 100%|█████████▉| 24150/24227 [01:07<00:00, 1087.87 examples/s]Tokenizing train dataset:  98%|█████████▊| 23709/24227 [01:06<00:00, 1004.24 examples/s]Tokenizing train dataset:  95%|█████████▌| 23070/24227 [01:07<00:01, 1000.91 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:07<00:00, 360.04 examples/s] 
Tokenizing train dataset:  98%|█████████▊| 23836/24227 [01:06<00:00, 846.65 examples/s] Tokenizing train dataset:  96%|█████████▌| 23173/24227 [01:07<00:01, 1004.56 examples/s]Tokenizing train dataset:  99%|█████████▉| 23946/24227 [01:06<00:00, 901.19 examples/s]Tokenizing train dataset:  96%|█████████▌| 23276/24227 [01:07<00:00, 1009.64 examples/s]Tokenizing train dataset:  99%|█████████▉| 24060/24227 [01:06<00:00, 952.99 examples/s]Tokenizing train dataset:  97%|█████████▋| 23394/24227 [01:07<00:00, 1052.74 examples/s]Tokenizing train dataset: 100%|█████████▉| 24170/24227 [01:07<00:00, 987.43 examples/s]Tokenizing train dataset:  97%|█████████▋| 23504/24227 [01:07<00:00, 1062.43 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:07<00:00, 360.58 examples/s]
Tokenizing train dataset:  98%|█████████▊| 23668/24227 [01:07<00:00, 1069.92 examples/s]Tokenizing train dataset:  98%|█████████▊| 23776/24227 [01:07<00:00, 1067.77 examples/s]Tokenizing train dataset:  99%|█████████▊| 23921/24227 [01:07<00:00, 1027.60 examples/s]Tokenizing train dataset:  99%|█████████▉| 24035/24227 [01:08<00:00, 1052.12 examples/s]Tokenizing train dataset: 100%|█████████▉| 24162/24227 [01:08<00:00, 947.06 examples/s] Tokenizing train dataset: 100%|██████████| 24227/24227 [01:08<00:00, 354.42 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5443.33 examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5432.03 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5483.44 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5509.40 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5488.35 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5471.86 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  33%|███▎      | 310/953 [00:00<00:00, 3066.04 examples/s]Applying chat template to eval dataset:  32%|███▏      | 308/953 [00:00<00:00, 3048.05 examples/s]Applying chat template to eval dataset:  33%|███▎      | 310/953 [00:00<00:00, 3060.20 examples/s]Applying chat template to eval dataset:  67%|██████▋   | 635/953 [00:00<00:00, 3166.38 examples/s]Applying chat template to eval dataset:  66%|██████▌   | 627/953 [00:00<00:00, 3126.58 examples/s]Applying chat template to eval dataset:  67%|██████▋   | 640/953 [00:00<00:00, 3185.72 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3155.48 examples/s]
Applying chat template to eval dataset:  99%|█████████▉| 946/953 [00:00<00:00, 3155.11 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3157.12 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2788.56 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 24/953 [00:00<00:03, 234.09 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 319.54 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 319.56 examples/s]Tokenizing eval dataset:   5%|▌         | 52/953 [00:00<00:04, 196.62 examples/s]Tokenizing eval dataset:   8%|▊         | 73/953 [00:00<00:03, 270.94 examples/s]Tokenizing eval dataset:   7%|▋         | 66/953 [00:00<00:03, 243.71 examples/s]Tokenizing eval dataset:  10%|▉         | 93/953 [00:00<00:03, 249.40 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:04, 186.83 examples/s]Tokenizing eval dataset:  12%|█▏        | 114/953 [00:00<00:03, 262.05 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:00<00:04, 184.75 examples/s]Tokenizing eval dataset:  13%|█▎        | 126/953 [00:00<00:03, 230.10 examples/s]Tokenizing eval dataset:  15%|█▌        | 143/953 [00:00<00:03, 229.78 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:04, 183.70 examples/s]Tokenizing eval dataset:  17%|█▋        | 159/953 [00:00<00:03, 221.69 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:00<00:04, 183.95 examples/s]Tokenizing eval dataset:  18%|█▊        | 173/953 [00:00<00:03, 214.80 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:04, 181.27 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:00<00:03, 204.43 examples/s]Tokenizing eval dataset:  21%|██        | 201/953 [00:00<00:03, 202.15 examples/s]Tokenizing eval dataset:  22%|██▏       | 208/953 [00:00<00:03, 207.27 examples/s]Tokenizing eval dataset:  20%|█▉        | 187/953 [00:01<00:04, 178.15 examples/s]Tokenizing eval dataset:  24%|██▍       | 231/953 [00:01<00:03, 222.99 examples/s]Tokenizing eval dataset:  26%|██▌       | 248/953 [00:01<00:02, 254.71 examples/s]Tokenizing eval dataset:  22%|██▏       | 205/953 [00:01<00:04, 176.35 examples/s]Tokenizing eval dataset:  29%|██▉       | 274/953 [00:01<00:02, 273.69 examples/s]Tokenizing eval dataset:  31%|███▏      | 300/953 [00:01<00:02, 324.97 examples/s]Tokenizing eval dataset:  32%|███▏      | 309/953 [00:01<00:02, 292.76 examples/s]Tokenizing eval dataset:  24%|██▎       | 226/953 [00:01<00:03, 183.66 examples/s]Tokenizing eval dataset:  37%|███▋      | 351/953 [00:01<00:01, 371.71 examples/s]Tokenizing eval dataset:  27%|██▋       | 256/953 [00:01<00:03, 214.76 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:01<00:01, 343.53 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:01<00:01, 387.32 examples/s]Tokenizing eval dataset:  32%|███▏      | 302/953 [00:01<00:02, 282.62 examples/s]Tokenizing eval dataset:  43%|████▎     | 409/953 [00:01<00:01, 382.32 examples/s]Tokenizing eval dataset:  47%|████▋     | 448/953 [00:01<00:01, 423.66 examples/s]Tokenizing eval dataset:  36%|███▌      | 340/953 [00:01<00:01, 306.80 examples/s]Tokenizing eval dataset:  48%|████▊     | 462/953 [00:01<00:01, 422.70 examples/s]Tokenizing eval dataset:  40%|███▉      | 380/953 [00:01<00:01, 330.76 examples/s]Tokenizing eval dataset:  54%|█████▍    | 515/953 [00:01<00:01, 428.73 examples/s]Tokenizing eval dataset:  55%|█████▌    | 527/953 [00:01<00:01, 423.32 examples/s]Tokenizing eval dataset:  44%|████▍     | 423/953 [00:01<00:01, 355.88 examples/s]Tokenizing eval dataset:  60%|█████▉    | 570/953 [00:01<00:00, 406.16 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:01<00:01, 379.77 examples/s]Tokenizing eval dataset:  61%|██████▏   | 585/953 [00:01<00:00, 396.40 examples/s]Tokenizing eval dataset:  65%|██████▍   | 618/953 [00:01<00:00, 421.73 examples/s]Tokenizing eval dataset:  54%|█████▎    | 512/953 [00:01<00:01, 393.44 examples/s]Tokenizing eval dataset:  68%|██████▊   | 650/953 [00:01<00:00, 402.80 examples/s]Tokenizing eval dataset:  70%|███████   | 668/953 [00:01<00:00, 434.51 examples/s]Tokenizing eval dataset:  59%|█████▉    | 560/953 [00:02<00:00, 416.61 examples/s]Tokenizing eval dataset:  73%|███████▎  | 697/953 [00:02<00:00, 414.15 examples/s]Tokenizing eval dataset:  64%|██████▍   | 613/953 [00:02<00:00, 448.98 examples/s]Tokenizing eval dataset:  77%|███████▋  | 733/953 [00:02<00:00, 431.41 examples/s]Tokenizing eval dataset:  70%|███████   | 670/953 [00:02<00:00, 482.46 examples/s]Tokenizing eval dataset:  80%|███████▉  | 759/953 [00:02<00:00, 410.81 examples/s]Tokenizing eval dataset:  83%|████████▎ | 795/953 [00:02<00:00, 423.90 examples/s]Tokenizing eval dataset:  76%|███████▌  | 726/953 [00:02<00:00, 502.20 examples/s]Tokenizing eval dataset:  84%|████████▍ | 804/953 [00:02<00:00, 417.54 examples/s]Tokenizing eval dataset:  88%|████████▊ | 840/953 [00:02<00:00, 428.75 examples/s]Tokenizing eval dataset:  89%|████████▉ | 850/953 [00:02<00:00, 423.84 examples/s]Tokenizing eval dataset:  83%|████████▎ | 789/953 [00:02<00:00, 467.43 examples/s]Tokenizing eval dataset:  93%|█████████▎| 887/953 [00:02<00:00, 437.00 examples/s]Tokenizing eval dataset:  96%|█████████▌| 913/953 [00:02<00:00, 420.70 examples/s]Tokenizing eval dataset:  90%|████████▉ | 856/953 [00:02<00:00, 454.49 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 433.07 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 360.09 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 351.58 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:02<00:00, 460.95 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 332.19 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.7828428745269775 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.6007442474365234 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combinationLoading extension module cpu_adam...

Time to load cpu_adam op: 2.6311662197113037 seconds
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.681068181991577 seconds
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250607_192807-16c6leh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-4e-07_e-3_b-0.2_62717633
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/16c6leh6
  0%|          | 0/4545 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/4545 [00:11<14:28:17, 11.47s/it]  0%|          | 2/4545 [00:15<8:50:02,  7.00s/it]   0%|          | 3/4545 [00:19<7:01:59,  5.57s/it]  0%|          | 4/4545 [00:22<6:01:47,  4.78s/it]  0%|          | 5/4545 [00:26<5:37:35,  4.46s/it]  0%|          | 6/4545 [00:30<5:31:01,  4.38s/it]  0%|          | 7/4545 [00:34<5:23:52,  4.28s/it]  0%|          | 8/4545 [00:38<5:12:57,  4.14s/it]  0%|          | 9/4545 [00:42<5:07:28,  4.07s/it]  0%|          | 10/4545 [00:46<4:58:54,  3.95s/it]                                                   {'loss': 0.7374, 'grad_norm': 60.89891815185547, 'learning_rate': 2.3778071334214e-09, 'rewards/chosen': -0.05753784254193306, 'rewards/rejected': -0.0015518188010901213, 'rewards/accuracies': 0.23749999701976776, 'rewards/margins': -0.05585326999425888, 'logps/chosen': -448.6499938964844, 'logps/rejected': -256.7749938964844, 'logits/chosen': -6.0625, 'logits/rejected': -6.165625095367432, 'epoch': 0.01}
  0%|          | 10/4545 [00:46<4:58:54,  3.95s/it]  0%|          | 11/4545 [00:50<5:04:53,  4.03s/it]  0%|          | 12/4545 [00:54<5:01:39,  3.99s/it]  0%|          | 13/4545 [00:56<4:19:35,  3.44s/it]  0%|          | 14/4545 [01:00<4:17:03,  3.40s/it]  0%|          | 15/4545 [01:03<4:27:08,  3.54s/it]  0%|          | 16/4545 [01:07<4:23:04,  3.49s/it]  0%|          | 17/4545 [01:11<4:32:11,  3.61s/it]  0%|          | 18/4545 [01:15<4:44:53,  3.78s/it]  0%|          | 19/4545 [01:18<4:25:31,  3.52s/it]  0%|          | 20/4545 [01:22<4:33:34,  3.63s/it]                                                   {'loss': 0.7108, 'grad_norm': 53.53396224975586, 'learning_rate': 5.019815059445178e-09, 'rewards/chosen': 0.0084686279296875, 'rewards/rejected': 0.014401244930922985, 'rewards/accuracies': 0.39375001192092896, 'rewards/margins': -0.0059265135787427425, 'logps/chosen': -254.85000610351562, 'logps/rejected': -121.07499694824219, 'logits/chosen': -6.28125, 'logits/rejected': -6.671875, 'epoch': 0.01}
  0%|          | 20/4545 [01:22<4:33:34,  3.63s/it]  0%|          | 21/4545 [01:25<4:22:47,  3.49s/it]  0%|          | 22/4545 [01:29<4:31:44,  3.60s/it]  1%|          | 23/4545 [01:33<4:38:34,  3.70s/it]  1%|          | 24/4545 [01:36<4:25:03,  3.52s/it]  1%|          | 25/4545 [01:39<4:32:41,  3.62s/it]  1%|          | 26/4545 [01:43<4:26:53,  3.54s/it]  1%|          | 27/4545 [01:47<4:34:53,  3.65s/it]  1%|          | 28/4545 [01:51<4:39:24,  3.71s/it]  1%|          | 29/4545 [01:54<4:43:11,  3.76s/it]  1%|          | 30/4545 [01:59<4:53:00,  3.89s/it]                                                   {'loss': 0.7057, 'grad_norm': 51.2675666809082, 'learning_rate': 7.661822985468955e-09, 'rewards/chosen': -0.01331481896340847, 'rewards/rejected': -0.0050750733353197575, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.008152770809829235, 'logps/chosen': -283.20001220703125, 'logps/rejected': -142.39999389648438, 'logits/chosen': -6.193749904632568, 'logits/rejected': -6.546875, 'epoch': 0.02}
  1%|          | 30/4545 [01:59<4:53:00,  3.89s/it]  1%|          | 31/4545 [02:03<4:56:27,  3.94s/it]  1%|          | 32/4545 [02:07<4:57:00,  3.95s/it]  1%|          | 33/4545 [02:11<4:56:07,  3.94s/it]  1%|          | 34/4545 [02:15<5:01:31,  4.01s/it]  1%|          | 35/4545 [02:19<4:59:12,  3.98s/it]  1%|          | 36/4545 [02:22<4:50:49,  3.87s/it]  1%|          | 37/4545 [02:26<4:43:28,  3.77s/it]  1%|          | 38/4545 [02:30<4:41:23,  3.75s/it]  1%|          | 39/4545 [02:33<4:44:18,  3.79s/it]  1%|          | 40/4545 [02:37<4:45:43,  3.81s/it]                                                   {'loss': 0.7911, 'grad_norm': 625.924560546875, 'learning_rate': 1.0303830911492733e-08, 'rewards/chosen': -0.04633178561925888, 'rewards/rejected': 0.02414550818502903, 'rewards/accuracies': 0.375, 'rewards/margins': -0.07018432766199112, 'logps/chosen': -416.6499938964844, 'logps/rejected': -175.10000610351562, 'logits/chosen': -6.268750190734863, 'logits/rejected': -6.5625, 'epoch': 0.03}
  1%|          | 40/4545 [02:37<4:45:43,  3.81s/it]  1%|          | 41/4545 [02:41<4:38:00,  3.70s/it]  1%|          | 42/4545 [02:45<4:42:54,  3.77s/it]  1%|          | 43/4545 [02:49<4:46:16,  3.82s/it]  1%|          | 44/4545 [02:53<4:51:45,  3.89s/it]  1%|          | 45/4545 [02:57<4:56:22,  3.95s/it]  1%|          | 46/4545 [03:01<4:55:15,  3.94s/it]  1%|          | 47/4545 [03:04<4:46:48,  3.83s/it]  1%|          | 48/4545 [03:08<4:48:33,  3.85s/it]  1%|          | 49/4545 [03:12<4:50:04,  3.87s/it]  1%|          | 50/4545 [03:16<4:50:27,  3.88s/it]                                                   {'loss': 0.7379, 'grad_norm': 376.1247863769531, 'learning_rate': 1.2945838837516512e-08, 'rewards/chosen': -0.034000396728515625, 'rewards/rejected': -0.014892578125, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': -0.01921386644244194, 'logps/chosen': -366.79998779296875, 'logps/rejected': -201.10000610351562, 'logits/chosen': -6.290625095367432, 'logits/rejected': -6.46875, 'epoch': 0.03}
  1%|          | 50/4545 [03:16<4:50:27,  3.88s/it]  1%|          | 51/4545 [03:20<4:47:30,  3.84s/it]  1%|          | 52/4545 [03:23<4:45:54,  3.82s/it]  1%|          | 53/4545 [03:27<4:40:28,  3.75s/it]  1%|          | 54/4545 [03:31<4:48:30,  3.85s/it]  1%|          | 55/4545 [03:35<4:49:16,  3.87s/it]  1%|          | 56/4545 [03:39<4:47:11,  3.84s/it]  1%|▏         | 57/4545 [03:43<4:48:24,  3.86s/it]  1%|▏         | 58/4545 [03:46<4:44:32,  3.80s/it]  1%|▏         | 59/4545 [03:49<4:28:36,  3.59s/it]  1%|▏         | 60/4545 [03:53<4:34:54,  3.68s/it]                                                   {'loss': 0.7021, 'grad_norm': 77.28325653076172, 'learning_rate': 1.5587846763540292e-08, 'rewards/chosen': -0.0011768341064453125, 'rewards/rejected': 0.01597290113568306, 'rewards/accuracies': 0.4437499940395355, 'rewards/margins': -0.01722106896340847, 'logps/chosen': -227.35000610351562, 'logps/rejected': -122.4749984741211, 'logits/chosen': -6.384375095367432, 'logits/rejected': -6.590624809265137, 'epoch': 0.04}
  1%|▏         | 60/4545 [03:54<4:34:54,  3.68s/it]  1%|▏         | 61/4545 [03:57<4:23:37,  3.53s/it]  1%|▏         | 62/4545 [04:00<4:26:38,  3.57s/it]  1%|▏         | 63/4545 [04:04<4:33:51,  3.67s/it]  1%|▏         | 64/4545 [04:08<4:40:25,  3.75s/it]  1%|▏         | 65/4545 [04:11<4:18:37,  3.46s/it]  1%|▏         | 66/4545 [04:14<4:21:00,  3.50s/it]  1%|▏         | 67/4545 [04:18<4:32:10,  3.65s/it]  1%|▏         | 68/4545 [04:22<4:32:20,  3.65s/it]  2%|▏         | 69/4545 [04:26<4:37:23,  3.72s/it]  2%|▏         | 70/4545 [04:30<4:35:30,  3.69s/it]                                                   {'loss': 0.6789, 'grad_norm': 70.47431182861328, 'learning_rate': 1.8229854689564068e-08, 'rewards/chosen': 0.0015853882068768144, 'rewards/rejected': -0.05510558933019638, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.0567626953125, 'logps/chosen': -316.1499938964844, 'logps/rejected': -155.27499389648438, 'logits/chosen': -6.165625095367432, 'logits/rejected': -6.556250095367432, 'epoch': 0.05}
  2%|▏         | 70/4545 [04:30<4:35:30,  3.69s/it]  2%|▏         | 71/4545 [04:34<4:44:27,  3.81s/it]  2%|▏         | 72/4545 [04:37<4:28:18,  3.60s/it]  2%|▏         | 73/4545 [04:41<4:40:16,  3.76s/it]  2%|▏         | 74/4545 [04:45<4:46:41,  3.85s/it]  2%|▏         | 75/4545 [04:49<4:47:34,  3.86s/it]  2%|▏         | 76/4545 [04:52<4:42:13,  3.79s/it]  2%|▏         | 77/4545 [04:56<4:46:14,  3.84s/it]  2%|▏         | 78/4545 [05:00<4:48:31,  3.88s/it]  2%|▏         | 79/4545 [05:04<4:48:43,  3.88s/it]  2%|▏         | 80/4545 [05:08<4:48:40,  3.88s/it]                                                   {'loss': 0.7275, 'grad_norm': 339.7402648925781, 'learning_rate': 2.0871862615587847e-08, 'rewards/chosen': 0.00121307373046875, 'rewards/rejected': 4.882812572759576e-05, 'rewards/accuracies': 0.40625, 'rewards/margins': 0.0010517120826989412, 'logps/chosen': -352.75, 'logps/rejected': -216.77499389648438, 'logits/chosen': -6.237500190734863, 'logits/rejected': -6.428124904632568, 'epoch': 0.05}
  2%|▏         | 80/4545 [05:08<4:48:40,  3.88s/it]  2%|▏         | 81/4545 [05:12<4:48:08,  3.87s/it]  2%|▏         | 82/4545 [05:16<4:43:12,  3.81s/it]  2%|▏         | 83/4545 [05:19<4:42:46,  3.80s/it]  2%|▏         | 84/4545 [05:22<4:21:46,  3.52s/it]  2%|▏         | 85/4545 [05:26<4:34:27,  3.69s/it]  2%|▏         | 86/4545 [05:30<4:41:40,  3.79s/it]  2%|▏         | 87/4545 [05:34<4:44:08,  3.82s/it]  2%|▏         | 88/4545 [05:38<4:45:22,  3.84s/it]  2%|▏         | 89/4545 [05:41<4:28:56,  3.62s/it]  2%|▏         | 90/4545 [05:45<4:21:55,  3.53s/it]                                                   {'loss': 0.7252, 'grad_norm': 57.8846435546875, 'learning_rate': 2.3513870541611623e-08, 'rewards/chosen': -0.02165680006146431, 'rewards/rejected': 0.02965850755572319, 'rewards/accuracies': 0.39375001192092896, 'rewards/margins': -0.05139312893152237, 'logps/chosen': -322.25, 'logps/rejected': -167.25, 'logits/chosen': -6.368750095367432, 'logits/rejected': -6.650000095367432, 'epoch': 0.06}
  2%|▏         | 90/4545 [05:45<4:21:55,  3.53s/it]  2%|▏         | 91/4545 [05:49<4:32:22,  3.67s/it]  2%|▏         | 92/4545 [05:53<4:37:08,  3.73s/it]  2%|▏         | 93/4545 [05:56<4:40:42,  3.78s/it]  2%|▏         | 94/4545 [06:00<4:42:50,  3.81s/it]  2%|▏         | 95/4545 [06:04<4:43:45,  3.83s/it]  2%|▏         | 96/4545 [06:08<4:44:37,  3.84s/it]  2%|▏         | 97/4545 [06:12<4:45:51,  3.86s/it]  2%|▏         | 98/4545 [06:15<4:32:29,  3.68s/it]  2%|▏         | 99/4545 [06:18<4:16:33,  3.46s/it]  2%|▏         | 100/4545 [06:22<4:16:43,  3.47s/it]                                                    {'loss': 0.7045, 'grad_norm': 42.9362678527832, 'learning_rate': 2.61558784676354e-08, 'rewards/chosen': -0.0050369263626635075, 'rewards/rejected': 0.001232147216796875, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.00621795654296875, 'logps/chosen': -330.3999938964844, 'logps/rejected': -159.6750030517578, 'logits/chosen': -6.3125, 'logits/rejected': -6.675000190734863, 'epoch': 0.07}
  2%|▏         | 100/4545 [06:22<4:16:43,  3.47s/it]  2%|▏         | 101/4545 [06:25<4:24:52,  3.58s/it]  2%|▏         | 102/4545 [06:29<4:33:28,  3.69s/it]  2%|▏         | 103/4545 [06:32<4:10:56,  3.39s/it]  2%|▏         | 104/4545 [06:36<4:15:36,  3.45s/it]  2%|▏         | 105/4545 [06:39<4:16:36,  3.47s/it]  2%|▏         | 106/4545 [06:43<4:21:32,  3.54s/it]  2%|▏         | 107/4545 [06:47<4:29:51,  3.65s/it]  2%|▏         | 108/4545 [06:50<4:28:19,  3.63s/it]  2%|▏         | 109/4545 [06:54<4:34:28,  3.71s/it]  2%|▏         | 110/4545 [06:58<4:44:42,  3.85s/it]                                                    {'loss': 0.6948, 'grad_norm': 547.7035522460938, 'learning_rate': 2.8797886393659182e-08, 'rewards/chosen': 0.0016998291248455644, 'rewards/rejected': -0.0026679993607103825, 'rewards/accuracies': 0.4437499940395355, 'rewards/margins': 0.00433425884693861, 'logps/chosen': -221.39999389648438, 'logps/rejected': -128.4499969482422, 'logits/chosen': -6.318749904632568, 'logits/rejected': -6.646874904632568, 'epoch': 0.07}
  2%|▏         | 110/4545 [06:59<4:44:42,  3.85s/it]  2%|▏         | 111/4545 [07:02<4:47:52,  3.90s/it]  2%|▏         | 112/4545 [07:06<4:47:25,  3.89s/it]  2%|▏         | 113/4545 [07:10<4:47:31,  3.89s/it]  3%|▎         | 114/4545 [07:14<4:46:45,  3.88s/it]  3%|▎         | 115/4545 [07:18<4:47:17,  3.89s/it]  3%|▎         | 116/4545 [07:22<4:46:59,  3.89s/it]  3%|▎         | 117/4545 [07:26<4:53:25,  3.98s/it]  3%|▎         | 118/4545 [07:30<4:58:05,  4.04s/it]  3%|▎         | 119/4545 [07:34<4:53:53,  3.98s/it]  3%|▎         | 120/4545 [07:38<4:45:35,  3.87s/it]                                                    {'loss': 0.6967, 'grad_norm': 50.614967346191406, 'learning_rate': 3.143989431968296e-08, 'rewards/chosen': 0.0055297850631177425, 'rewards/rejected': 0.01071777381002903, 'rewards/accuracies': 0.4375, 'rewards/margins': -0.005207824520766735, 'logps/chosen': -429.8500061035156, 'logps/rejected': -149.5, 'logits/chosen': -6.118750095367432, 'logits/rejected': -6.65625, 'epoch': 0.08}
  3%|▎         | 120/4545 [07:38<4:45:35,  3.87s/it]  3%|▎         | 121/4545 [07:42<4:47:10,  3.89s/it]  3%|▎         | 122/4545 [07:46<4:47:40,  3.90s/it]  3%|▎         | 123/4545 [07:50<4:47:46,  3.90s/it]  3%|▎         | 124/4545 [07:53<4:41:17,  3.82s/it]  3%|▎         | 125/4545 [07:57<4:47:45,  3.91s/it]  3%|▎         | 126/4545 [08:01<4:48:19,  3.91s/it]  3%|▎         | 127/4545 [08:05<4:41:47,  3.83s/it]  3%|▎         | 128/4545 [08:09<4:42:38,  3.84s/it]  3%|▎         | 129/4545 [08:13<4:43:48,  3.86s/it]  3%|▎         | 130/4545 [08:16<4:44:25,  3.87s/it]                                                    {'loss': 0.6848, 'grad_norm': 39.02923583984375, 'learning_rate': 3.408190224570674e-08, 'rewards/chosen': 0.08013916015625, 'rewards/rejected': -0.03523864597082138, 'rewards/accuracies': 0.4312500059604645, 'rewards/margins': 0.11544189602136612, 'logps/chosen': -398.6499938964844, 'logps/rejected': -264.25, 'logits/chosen': -6.171875, 'logits/rejected': -6.381249904632568, 'epoch': 0.09}
  3%|▎         | 130/4545 [08:17<4:44:25,  3.87s/it]  3%|▎         | 131/4545 [08:20<4:46:17,  3.89s/it]  3%|▎         | 132/4545 [08:24<4:38:17,  3.78s/it]  3%|▎         | 133/4545 [08:27<4:24:01,  3.59s/it]  3%|▎         | 134/4545 [08:31<4:21:42,  3.56s/it]  3%|▎         | 135/4545 [08:33<3:56:29,  3.22s/it]  3%|▎         | 136/4545 [08:36<3:53:45,  3.18s/it]  3%|▎         | 137/4545 [08:40<4:12:06,  3.43s/it]  3%|▎         | 138/4545 [08:44<4:22:32,  3.57s/it]  3%|▎         | 139/4545 [08:48<4:25:53,  3.62s/it]  3%|▎         | 140/4545 [08:52<4:31:36,  3.70s/it]                                                    {'loss': 0.7084, 'grad_norm': 623.8947143554688, 'learning_rate': 3.672391017173051e-08, 'rewards/chosen': 0.07795409858226776, 'rewards/rejected': 0.03005218505859375, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 0.04773407056927681, 'logps/chosen': -325.20001220703125, 'logps/rejected': -180.72500610351562, 'logits/chosen': -6.421875, 'logits/rejected': -6.775000095367432, 'epoch': 0.09}
  3%|▎         | 140/4545 [08:52<4:31:36,  3.70s/it]  3%|▎         | 141/4545 [08:56<4:37:06,  3.78s/it]  3%|▎         | 142/4545 [09:00<4:41:50,  3.84s/it]  3%|▎         | 143/4545 [09:03<4:43:17,  3.86s/it]  3%|▎         | 144/4545 [09:07<4:44:17,  3.88s/it]  3%|▎         | 145/4545 [09:11<4:45:03,  3.89s/it]  3%|▎         | 146/4545 [09:15<4:35:45,  3.76s/it]  3%|▎         | 147/4545 [09:18<4:32:00,  3.71s/it]  3%|▎         | 148/4545 [09:22<4:34:59,  3.75s/it]  3%|▎         | 149/4545 [09:26<4:38:17,  3.80s/it]  3%|▎         | 150/4545 [09:29<4:22:38,  3.59s/it]                                                    {'loss': 0.7046, 'grad_norm': 35.90163040161133, 'learning_rate': 3.936591809775429e-08, 'rewards/chosen': 0.03713073581457138, 'rewards/rejected': 0.011798095889389515, 'rewards/accuracies': 0.4312500059604645, 'rewards/margins': 0.02525939978659153, 'logps/chosen': -282.8999938964844, 'logps/rejected': -116.9000015258789, 'logits/chosen': -6.346875190734863, 'logits/rejected': -6.6875, 'epoch': 0.1}
  3%|▎         | 150/4545 [09:29<4:22:38,  3.59s/it]  3%|▎         | 151/4545 [09:32<4:10:45,  3.42s/it]  3%|▎         | 152/4545 [09:36<4:15:06,  3.48s/it]  3%|▎         | 153/4545 [09:40<4:24:27,  3.61s/it]  3%|▎         | 154/4545 [09:43<4:24:03,  3.61s/it]  3%|▎         | 155/4545 [09:47<4:30:25,  3.70s/it]  3%|▎         | 156/4545 [09:51<4:30:58,  3.70s/it]  3%|▎         | 157/4545 [09:55<4:31:40,  3.71s/it]  3%|▎         | 158/4545 [09:58<4:31:06,  3.71s/it]  3%|▎         | 159/4545 [10:03<4:40:11,  3.83s/it]  4%|▎         | 160/4545 [10:06<4:41:55,  3.86s/it]                                                    {'loss': 0.725, 'grad_norm': 224.4608154296875, 'learning_rate': 4.2007926023778065e-08, 'rewards/chosen': 0.05188598483800888, 'rewards/rejected': 0.034149933606386185, 'rewards/accuracies': 0.4124999940395355, 'rewards/margins': 0.01791992224752903, 'logps/chosen': -295.29998779296875, 'logps/rejected': -159.5749969482422, 'logits/chosen': -6.203125, 'logits/rejected': -6.615624904632568, 'epoch': 0.11}
  4%|▎         | 160/4545 [10:07<4:41:55,  3.86s/it]  4%|▎         | 161/4545 [10:11<4:49:17,  3.96s/it]  4%|▎         | 162/4545 [10:15<4:47:52,  3.94s/it]  4%|▎         | 163/4545 [10:19<4:51:01,  3.98s/it]  4%|▎         | 164/4545 [10:23<4:48:37,  3.95s/it]  4%|▎         | 165/4545 [10:26<4:37:12,  3.80s/it]  4%|▎         | 166/4545 [10:30<4:39:26,  3.83s/it]  4%|▎         | 167/4545 [10:34<4:40:44,  3.85s/it]  4%|▎         | 168/4545 [10:38<4:41:38,  3.86s/it]  4%|▎         | 169/4545 [10:42<4:41:36,  3.86s/it]  4%|▎         | 170/4545 [10:45<4:42:16,  3.87s/it]                                                    {'loss': 0.7364, 'grad_norm': 48.73978042602539, 'learning_rate': 4.464993394980185e-08, 'rewards/chosen': 0.18583831191062927, 'rewards/rejected': 0.056240081787109375, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.129638671875, 'logps/chosen': -464.25, 'logps/rejected': -206.3249969482422, 'logits/chosen': -6.050000190734863, 'logits/rejected': -6.699999809265137, 'epoch': 0.11}
  4%|▎         | 170/4545 [10:46<4:42:16,  3.87s/it]  4%|▍         | 171/4545 [10:48<4:20:24,  3.57s/it]  4%|▍         | 172/4545 [10:52<4:32:39,  3.74s/it]  4%|▍         | 173/4545 [10:56<4:37:04,  3.80s/it]  4%|▍         | 174/4545 [11:00<4:41:52,  3.87s/it]  4%|▍         | 175/4545 [11:04<4:27:46,  3.68s/it]  4%|▍         | 176/4545 [11:08<4:32:04,  3.74s/it]  4%|▍         | 177/4545 [11:10<4:09:51,  3.43s/it]  4%|▍         | 178/4545 [11:14<4:21:10,  3.59s/it]  4%|▍         | 179/4545 [11:17<4:13:08,  3.48s/it]  4%|▍         | 180/4545 [11:21<4:22:17,  3.61s/it]                                                    {'loss': 0.6767, 'grad_norm': 48.877906799316406, 'learning_rate': 4.7291941875825624e-08, 'rewards/chosen': 0.14388427138328552, 'rewards/rejected': 0.030914306640625, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.11270980536937714, 'logps/chosen': -283.8500061035156, 'logps/rejected': -181.875, 'logits/chosen': -6.337500095367432, 'logits/rejected': -6.59375, 'epoch': 0.12}
  4%|▍         | 180/4545 [11:21<4:22:17,  3.61s/it]  4%|▍         | 181/4545 [11:25<4:29:11,  3.70s/it]  4%|▍         | 182/4545 [11:29<4:20:08,  3.58s/it]  4%|▍         | 183/4545 [11:32<4:24:00,  3.63s/it]  4%|▍         | 184/4545 [11:36<4:29:49,  3.71s/it]  4%|▍         | 185/4545 [11:40<4:33:18,  3.76s/it]  4%|▍         | 186/4545 [11:44<4:28:56,  3.70s/it]  4%|▍         | 187/4545 [11:48<4:33:00,  3.76s/it]  4%|▍         | 188/4545 [11:51<4:17:58,  3.55s/it]  4%|▍         | 189/4545 [11:54<4:09:13,  3.43s/it]  4%|▍         | 190/4545 [11:57<4:01:43,  3.33s/it]                                                    {'loss': 0.7588, 'grad_norm': 50.55908966064453, 'learning_rate': 4.99339498018494e-08, 'rewards/chosen': 0.13698729872703552, 'rewards/rejected': 0.04048805311322212, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.09676666557788849, 'logps/chosen': -301.3999938964844, 'logps/rejected': -155.6999969482422, 'logits/chosen': -6.306250095367432, 'logits/rejected': -6.734375, 'epoch': 0.13}
  4%|▍         | 190/4545 [11:57<4:01:43,  3.33s/it]  4%|▍         | 191/4545 [12:01<4:19:00,  3.57s/it]  4%|▍         | 192/4545 [12:05<4:20:23,  3.59s/it]  4%|▍         | 193/4545 [12:07<4:02:59,  3.35s/it]  4%|▍         | 194/4545 [12:10<3:50:40,  3.18s/it]  4%|▍         | 195/4545 [12:14<4:05:24,  3.38s/it]  4%|▍         | 196/4545 [12:18<4:14:01,  3.50s/it]  4%|▍         | 197/4545 [12:22<4:29:35,  3.72s/it]  4%|▍         | 198/4545 [12:26<4:33:11,  3.77s/it]  4%|▍         | 199/4545 [12:30<4:34:58,  3.80s/it]  4%|▍         | 200/4545 [12:34<4:37:33,  3.83s/it]                                                    {'loss': 0.7574, 'grad_norm': 512.3890991210938, 'learning_rate': 5.2575957727873176e-08, 'rewards/chosen': 0.19168701767921448, 'rewards/rejected': 0.13201598823070526, 'rewards/accuracies': 0.512499988079071, 'rewards/margins': 0.059906005859375, 'logps/chosen': -355.2250061035156, 'logps/rejected': -240.97500610351562, 'logits/chosen': -6.171875, 'logits/rejected': -6.590624809265137, 'epoch': 0.13}
  4%|▍         | 200/4545 [12:34<4:37:33,  3.83s/it]  4%|▍         | 201/4545 [12:38<4:40:17,  3.87s/it]  4%|▍         | 202/4545 [12:41<4:38:52,  3.85s/it]  4%|▍         | 203/4545 [12:45<4:36:41,  3.82s/it]  4%|▍         | 204/4545 [12:49<4:44:26,  3.93s/it]  5%|▍         | 205/4545 [12:53<4:41:21,  3.89s/it]  5%|▍         | 206/4545 [12:57<4:41:34,  3.89s/it]  5%|▍         | 207/4545 [13:01<4:41:19,  3.89s/it]  5%|▍         | 208/4545 [13:04<4:32:36,  3.77s/it]  5%|▍         | 209/4545 [13:09<4:38:42,  3.86s/it]  5%|▍         | 210/4545 [13:13<4:45:38,  3.95s/it]                                                    {'loss': 0.6735, 'grad_norm': 47.441505432128906, 'learning_rate': 5.521796565389696e-08, 'rewards/chosen': 0.22111205756664276, 'rewards/rejected': 0.02451324462890625, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.19632606208324432, 'logps/chosen': -295.1499938964844, 'logps/rejected': -194.64999389648438, 'logits/chosen': -6.25, 'logits/rejected': -6.537499904632568, 'epoch': 0.14}
  5%|▍         | 210/4545 [13:13<4:45:38,  3.95s/it]  5%|▍         | 211/4545 [13:17<4:46:08,  3.96s/it]  5%|▍         | 212/4545 [13:21<4:47:44,  3.98s/it]  5%|▍         | 213/4545 [13:25<4:45:39,  3.96s/it]  5%|▍         | 214/4545 [13:28<4:42:37,  3.92s/it]  5%|▍         | 215/4545 [13:32<4:39:59,  3.88s/it]  5%|▍         | 216/4545 [13:36<4:40:32,  3.89s/it]  5%|▍         | 217/4545 [13:40<4:39:49,  3.88s/it]  5%|▍         | 218/4545 [13:44<4:40:08,  3.88s/it]  5%|▍         | 219/4545 [13:47<4:25:52,  3.69s/it]  5%|▍         | 220/4545 [13:51<4:34:05,  3.80s/it]                                                    {'loss': 0.6863, 'grad_norm': 51.00857925415039, 'learning_rate': 5.785997357992074e-08, 'rewards/chosen': 0.25138625502586365, 'rewards/rejected': 0.088531494140625, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': 0.16264954209327698, 'logps/chosen': -325.54998779296875, 'logps/rejected': -181.8000030517578, 'logits/chosen': -6.262499809265137, 'logits/rejected': -6.590624809265137, 'epoch': 0.15}
  5%|▍         | 220/4545 [13:51<4:34:05,  3.80s/it]  5%|▍         | 221/4545 [13:55<4:28:05,  3.72s/it]  5%|▍         | 222/4545 [13:59<4:38:07,  3.86s/it]  5%|▍         | 223/4545 [14:03<4:39:10,  3.88s/it]  5%|▍         | 224/4545 [14:07<4:39:29,  3.88s/it]  5%|▍         | 225/4545 [14:11<4:45:24,  3.96s/it]  5%|▍         | 226/4545 [14:13<4:14:31,  3.54s/it]  5%|▍         | 227/4545 [14:17<4:22:42,  3.65s/it]  5%|▌         | 228/4545 [14:21<4:22:00,  3.64s/it]  5%|▌         | 229/4545 [14:24<4:11:43,  3.50s/it]  5%|▌         | 230/4545 [14:28<4:20:21,  3.62s/it]                                                    {'loss': 0.6963, 'grad_norm': 41.30814743041992, 'learning_rate': 6.050198150594451e-08, 'rewards/chosen': 0.28303831815719604, 'rewards/rejected': 0.04164848476648331, 'rewards/accuracies': 0.48124998807907104, 'rewards/margins': 0.24132689833641052, 'logps/chosen': -487.29998779296875, 'logps/rejected': -244.1750030517578, 'logits/chosen': -6.043749809265137, 'logits/rejected': -6.306250095367432, 'epoch': 0.15}
  5%|▌         | 230/4545 [14:28<4:20:21,  3.62s/it]  5%|▌         | 231/4545 [14:32<4:32:51,  3.79s/it]  5%|▌         | 232/4545 [14:36<4:39:26,  3.89s/it]  5%|▌         | 233/4545 [14:40<4:32:25,  3.79s/it]  5%|▌         | 234/4545 [14:44<4:35:27,  3.83s/it]  5%|▌         | 235/4545 [14:48<4:40:53,  3.91s/it]  5%|▌         | 236/4545 [14:51<4:29:19,  3.75s/it]  5%|▌         | 237/4545 [14:55<4:33:02,  3.80s/it]  5%|▌         | 238/4545 [14:57<3:59:23,  3.33s/it]  5%|▌         | 239/4545 [15:01<4:12:28,  3.52s/it]  5%|▌         | 240/4545 [15:05<4:20:40,  3.63s/it]                                                    {'loss': 0.6634, 'grad_norm': 47.09383773803711, 'learning_rate': 6.314398943196829e-08, 'rewards/chosen': 0.23215332627296448, 'rewards/rejected': 0.01659240759909153, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.21523436903953552, 'logps/chosen': -297.29998779296875, 'logps/rejected': -137.25, 'logits/chosen': -6.28125, 'logits/rejected': -6.578125, 'epoch': 0.16}
  5%|▌         | 240/4545 [15:05<4:20:40,  3.63s/it]  5%|▌         | 241/4545 [15:09<4:11:47,  3.51s/it]  5%|▌         | 242/4545 [15:13<4:25:41,  3.70s/it]  5%|▌         | 243/4545 [15:16<4:12:54,  3.53s/it]  5%|▌         | 244/4545 [15:20<4:20:02,  3.63s/it]  5%|▌         | 245/4545 [15:24<4:26:32,  3.72s/it]  5%|▌         | 246/4545 [15:27<4:29:28,  3.76s/it]  5%|▌         | 247/4545 [15:31<4:32:50,  3.81s/it]  5%|▌         | 248/4545 [15:35<4:34:36,  3.83s/it]  5%|▌         | 249/4545 [15:39<4:34:49,  3.84s/it]  6%|▌         | 250/4545 [15:43<4:42:45,  3.95s/it]                                                    {'loss': 0.6529, 'grad_norm': 37.78996658325195, 'learning_rate': 6.578599735799208e-08, 'rewards/chosen': 0.4383544921875, 'rewards/rejected': 0.05387573316693306, 'rewards/accuracies': 0.581250011920929, 'rewards/margins': 0.38365477323532104, 'logps/chosen': -394.0, 'logps/rejected': -172.47500610351562, 'logits/chosen': -6.115624904632568, 'logits/rejected': -6.315625190734863, 'epoch': 0.17}
  6%|▌         | 250/4545 [15:43<4:42:45,  3.95s/it]  6%|▌         | 251/4545 [15:47<4:40:08,  3.91s/it]  6%|▌         | 252/4545 [15:51<4:39:34,  3.91s/it]  6%|▌         | 253/4545 [15:54<4:24:15,  3.69s/it]  6%|▌         | 254/4545 [15:58<4:28:08,  3.75s/it]  6%|▌         | 255/4545 [16:02<4:28:55,  3.76s/it]  6%|▌         | 256/4545 [16:06<4:38:42,  3.90s/it]  6%|▌         | 257/4545 [16:10<4:42:16,  3.95s/it]  6%|▌         | 258/4545 [16:14<4:32:19,  3.81s/it]  6%|▌         | 259/4545 [16:16<3:52:59,  3.26s/it]  6%|▌         | 260/4545 [16:20<4:13:43,  3.55s/it]                                                    {'loss': 0.6742, 'grad_norm': 303.9525451660156, 'learning_rate': 6.842800528401584e-08, 'rewards/chosen': 0.21103210747241974, 'rewards/rejected': 0.04423217847943306, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.16706542670726776, 'logps/chosen': -211.39999389648438, 'logps/rejected': -104.8499984741211, 'logits/chosen': -6.456250190734863, 'logits/rejected': -6.724999904632568, 'epoch': 0.17}
  6%|▌         | 260/4545 [16:20<4:13:43,  3.55s/it]  6%|▌         | 261/4545 [16:24<4:21:43,  3.67s/it]  6%|▌         | 262/4545 [16:28<4:25:42,  3.72s/it]  6%|▌         | 263/4545 [16:32<4:33:05,  3.83s/it]  6%|▌         | 264/4545 [16:35<4:20:14,  3.65s/it]  6%|▌         | 265/4545 [16:39<4:25:43,  3.73s/it]  6%|▌         | 266/4545 [16:43<4:29:20,  3.78s/it]  6%|▌         | 267/4545 [16:47<4:32:15,  3.82s/it]  6%|▌         | 268/4545 [16:50<4:20:34,  3.66s/it]  6%|▌         | 269/4545 [16:54<4:26:15,  3.74s/it]  6%|▌         | 270/4545 [16:58<4:29:58,  3.79s/it]                                                    {'loss': 0.6511, 'grad_norm': 48.499752044677734, 'learning_rate': 7.107001321003963e-08, 'rewards/chosen': 0.602978527545929, 'rewards/rejected': 0.15612182021141052, 'rewards/accuracies': 0.6187499761581421, 'rewards/margins': 0.4468017518520355, 'logps/chosen': -461.45001220703125, 'logps/rejected': -259.3999938964844, 'logits/chosen': -6.190625190734863, 'logits/rejected': -6.371874809265137, 'epoch': 0.18}
  6%|▌         | 270/4545 [16:58<4:29:58,  3.79s/it]  6%|▌         | 271/4545 [17:02<4:31:50,  3.82s/it]  6%|▌         | 272/4545 [17:05<4:28:54,  3.78s/it]  6%|▌         | 273/4545 [17:09<4:31:29,  3.81s/it]  6%|▌         | 274/4545 [17:13<4:34:27,  3.86s/it]  6%|▌         | 275/4545 [17:16<4:16:42,  3.61s/it]  6%|▌         | 276/4545 [17:21<4:34:33,  3.86s/it]  6%|▌         | 277/4545 [17:25<4:35:44,  3.88s/it]  6%|▌         | 278/4545 [17:29<4:36:13,  3.88s/it]  6%|▌         | 279/4545 [17:32<4:26:11,  3.74s/it]  6%|▌         | 280/4545 [17:36<4:30:15,  3.80s/it]                                                    {'loss': 0.6485, 'grad_norm': 64.82344818115234, 'learning_rate': 7.37120211360634e-08, 'rewards/chosen': 0.5333923101425171, 'rewards/rejected': 0.16497421264648438, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.3687805235385895, 'logps/chosen': -389.75, 'logps/rejected': -170.85000610351562, 'logits/chosen': -6.337500095367432, 'logits/rejected': -6.634375095367432, 'epoch': 0.18}
  6%|▌         | 280/4545 [17:36<4:30:15,  3.80s/it]  6%|▌         | 281/4545 [17:40<4:37:40,  3.91s/it]  6%|▌         | 282/4545 [17:43<4:14:58,  3.59s/it]  6%|▌         | 283/4545 [17:46<4:06:18,  3.47s/it]  6%|▌         | 284/4545 [17:50<4:16:05,  3.61s/it]  6%|▋         | 285/4545 [17:54<4:22:06,  3.69s/it]  6%|▋         | 286/4545 [17:57<4:08:09,  3.50s/it]  6%|▋         | 287/4545 [18:00<3:54:19,  3.30s/it]  6%|▋         | 288/4545 [18:03<4:01:33,  3.40s/it]  6%|▋         | 289/4545 [18:07<4:11:23,  3.54s/it]  6%|▋         | 290/4545 [18:11<4:19:13,  3.66s/it]                                                    {'loss': 0.6322, 'grad_norm': 108.74579620361328, 'learning_rate': 7.635402906208718e-08, 'rewards/chosen': 0.6414550542831421, 'rewards/rejected': 0.17201538383960724, 'rewards/accuracies': 0.612500011920929, 'rewards/margins': 0.46934205293655396, 'logps/chosen': -376.25, 'logps/rejected': -226.6999969482422, 'logits/chosen': -6.084374904632568, 'logits/rejected': -6.503125190734863, 'epoch': 0.19}
  6%|▋         | 290/4545 [18:11<4:19:13,  3.66s/it]  6%|▋         | 291/4545 [18:15<4:15:35,  3.60s/it]  6%|▋         | 292/4545 [18:19<4:21:51,  3.69s/it]  6%|▋         | 293/4545 [18:23<4:29:29,  3.80s/it]  6%|▋         | 294/4545 [18:27<4:30:53,  3.82s/it]  6%|▋         | 295/4545 [18:30<4:23:45,  3.72s/it]  7%|▋         | 296/4545 [18:34<4:27:26,  3.78s/it]  7%|▋         | 297/4545 [18:38<4:29:01,  3.80s/it]  7%|▋         | 298/4545 [18:41<4:06:26,  3.48s/it]  7%|▋         | 299/4545 [18:45<4:22:25,  3.71s/it]  7%|▋         | 300/4545 [18:48<4:14:20,  3.59s/it]                                                    {'loss': 0.7006, 'grad_norm': 48.478271484375, 'learning_rate': 7.899603698811096e-08, 'rewards/chosen': 0.4306884706020355, 'rewards/rejected': 0.1658225953578949, 'rewards/accuracies': 0.581250011920929, 'rewards/margins': 0.2652831971645355, 'logps/chosen': -282.29998779296875, 'logps/rejected': -148.75, 'logits/chosen': -6.215624809265137, 'logits/rejected': -6.474999904632568, 'epoch': 0.2}
  7%|▋         | 300/4545 [18:48<4:14:20,  3.59s/it]  7%|▋         | 301/4545 [18:51<4:07:11,  3.49s/it]  7%|▋         | 302/4545 [18:55<4:20:06,  3.68s/it]  7%|▋         | 303/4545 [18:58<4:00:25,  3.40s/it]  7%|▋         | 304/4545 [19:02<4:07:10,  3.50s/it]  7%|▋         | 305/4545 [19:06<4:16:40,  3.63s/it]  7%|▋         | 306/4545 [19:10<4:22:27,  3.71s/it]  7%|▋         | 307/4545 [19:14<4:25:49,  3.76s/it]  7%|▋         | 308/4545 [19:18<4:27:54,  3.79s/it]  7%|▋         | 309/4545 [19:21<4:30:34,  3.83s/it]  7%|▋         | 310/4545 [19:25<4:33:37,  3.88s/it]                                                    {'loss': 0.6325, 'grad_norm': 59.551551818847656, 'learning_rate': 8.163804491413475e-08, 'rewards/chosen': 1.0491454601287842, 'rewards/rejected': 0.26747435331344604, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.7805420160293579, 'logps/chosen': -478.25, 'logps/rejected': -262.57501220703125, 'logits/chosen': -6.071875095367432, 'logits/rejected': -6.196875095367432, 'epoch': 0.2}
  7%|▋         | 310/4545 [19:25<4:33:37,  3.88s/it]  7%|▋         | 311/4545 [19:29<4:33:38,  3.88s/it]  7%|▋         | 312/4545 [19:32<4:16:07,  3.63s/it]  7%|▋         | 313/4545 [19:36<4:22:10,  3.72s/it]  7%|▋         | 314/4545 [19:40<4:26:18,  3.78s/it]  7%|▋         | 315/4545 [19:44<4:29:03,  3.82s/it]  7%|▋         | 316/4545 [19:48<4:28:55,  3.82s/it]  7%|▋         | 317/4545 [19:50<3:59:30,  3.40s/it]  7%|▋         | 318/4545 [19:54<4:09:57,  3.55s/it]  7%|▋         | 319/4545 [19:58<4:17:53,  3.66s/it]  7%|▋         | 320/4545 [20:02<4:23:00,  3.73s/it]                                                    {'loss': 0.6382, 'grad_norm': 47.654144287109375, 'learning_rate': 8.428005284015852e-08, 'rewards/chosen': 0.3888916075229645, 'rewards/rejected': 0.10345115512609482, 'rewards/accuracies': 0.65625, 'rewards/margins': 0.2849365174770355, 'logps/chosen': -288.8500061035156, 'logps/rejected': -168.72500610351562, 'logits/chosen': -6.337500095367432, 'logits/rejected': -6.6875, 'epoch': 0.21}
  7%|▋         | 320/4545 [20:02<4:23:00,  3.73s/it]  7%|▋         | 321/4545 [20:05<4:13:07,  3.60s/it]  7%|▋         | 322/4545 [20:09<4:21:13,  3.71s/it]  7%|▋         | 323/4545 [20:14<4:31:57,  3.86s/it]  7%|▋         | 324/4545 [20:17<4:25:53,  3.78s/it]  7%|▋         | 325/4545 [20:21<4:23:01,  3.74s/it]  7%|▋         | 326/4545 [20:25<4:26:30,  3.79s/it]  7%|▋         | 327/4545 [20:29<4:31:42,  3.87s/it]  7%|▋         | 328/4545 [20:33<4:32:43,  3.88s/it]  7%|▋         | 329/4545 [20:37<4:32:40,  3.88s/it]  7%|▋         | 330/4545 [20:40<4:29:55,  3.84s/it]                                                    {'loss': 0.6749, 'grad_norm': 112.23616027832031, 'learning_rate': 8.69220607661823e-08, 'rewards/chosen': 0.383544921875, 'rewards/rejected': 0.14289550483226776, 'rewards/accuracies': 0.6187499761581421, 'rewards/margins': 0.24017333984375, 'logps/chosen': -225.64999389648438, 'logps/rejected': -146.6999969482422, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.387499809265137, 'epoch': 0.22}
  7%|▋         | 330/4545 [20:40<4:29:55,  3.84s/it]  7%|▋         | 331/4545 [20:43<4:16:29,  3.65s/it]  7%|▋         | 332/4545 [20:48<4:24:36,  3.77s/it]  7%|▋         | 333/4545 [20:51<4:18:44,  3.69s/it]  7%|▋         | 334/4545 [20:55<4:26:47,  3.80s/it]  7%|▋         | 335/4545 [20:58<4:16:25,  3.65s/it]  7%|▋         | 336/4545 [21:02<4:06:37,  3.52s/it]  7%|▋         | 337/4545 [21:06<4:18:59,  3.69s/it]  7%|▋         | 338/4545 [21:09<4:06:29,  3.52s/it]  7%|▋         | 339/4545 [21:13<4:14:21,  3.63s/it]  7%|▋         | 340/4545 [21:17<4:20:21,  3.72s/it]                                                    {'loss': 0.6431, 'grad_norm': 55.33588790893555, 'learning_rate': 8.956406869220607e-08, 'rewards/chosen': 0.3299560546875, 'rewards/rejected': 0.11841430515050888, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.21125487983226776, 'logps/chosen': -177.39999389648438, 'logps/rejected': -113.88749694824219, 'logits/chosen': -6.4375, 'logits/rejected': -6.765625, 'epoch': 0.22}
  7%|▋         | 340/4545 [21:17<4:20:21,  3.72s/it]  8%|▊         | 341/4545 [21:21<4:24:34,  3.78s/it]  8%|▊         | 342/4545 [21:24<4:27:16,  3.82s/it]  8%|▊         | 343/4545 [21:28<4:30:00,  3.86s/it]  8%|▊         | 344/4545 [21:32<4:24:19,  3.78s/it]  8%|▊         | 345/4545 [21:35<4:04:32,  3.49s/it]  8%|▊         | 346/4545 [21:39<4:12:31,  3.61s/it]  8%|▊         | 347/4545 [21:43<4:23:24,  3.76s/it]  8%|▊         | 348/4545 [21:47<4:29:39,  3.86s/it]  8%|▊         | 349/4545 [21:51<4:30:54,  3.87s/it]  8%|▊         | 350/4545 [21:55<4:30:33,  3.87s/it]                                                    {'loss': 0.635, 'grad_norm': 37.61077880859375, 'learning_rate': 9.220607661822985e-08, 'rewards/chosen': 0.855236828327179, 'rewards/rejected': 0.23004150390625, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6250244379043579, 'logps/chosen': -396.6000061035156, 'logps/rejected': -193.8000030517578, 'logits/chosen': -6.109375, 'logits/rejected': -6.265625, 'epoch': 0.23}
  8%|▊         | 350/4545 [21:55<4:30:33,  3.87s/it]  8%|▊         | 351/4545 [21:59<4:30:57,  3.88s/it]  8%|▊         | 352/4545 [22:01<4:03:30,  3.48s/it]  8%|▊         | 353/4545 [22:05<4:13:34,  3.63s/it]  8%|▊         | 354/4545 [22:09<4:19:41,  3.72s/it]  8%|▊         | 355/4545 [22:13<4:24:03,  3.78s/it]  8%|▊         | 356/4545 [22:17<4:30:32,  3.87s/it]  8%|▊         | 357/4545 [22:20<4:19:45,  3.72s/it]  8%|▊         | 358/4545 [22:23<3:50:15,  3.30s/it]  8%|▊         | 359/4545 [22:27<4:03:49,  3.49s/it]  8%|▊         | 360/4545 [22:31<4:11:21,  3.60s/it]                                                    {'loss': 0.629, 'grad_norm': 56.86992263793945, 'learning_rate': 9.484808454425363e-08, 'rewards/chosen': 0.786181628704071, 'rewards/rejected': 0.14471435546875, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.6422363519668579, 'logps/chosen': -327.0, 'logps/rejected': -171.85000610351562, 'logits/chosen': -6.25, 'logits/rejected': -6.509375095367432, 'epoch': 0.24}
  8%|▊         | 360/4545 [22:31<4:11:21,  3.60s/it]  8%|▊         | 361/4545 [22:34<4:04:50,  3.51s/it]  8%|▊         | 362/4545 [22:38<4:13:21,  3.63s/it]  8%|▊         | 363/4545 [22:42<4:18:14,  3.71s/it]  8%|▊         | 364/4545 [22:45<4:06:22,  3.54s/it]  8%|▊         | 365/4545 [22:49<4:14:11,  3.65s/it]  8%|▊         | 366/4545 [22:53<4:19:00,  3.72s/it]  8%|▊         | 367/4545 [22:57<4:26:18,  3.82s/it]  8%|▊         | 368/4545 [23:00<4:27:28,  3.84s/it]  8%|▊         | 369/4545 [23:04<4:28:36,  3.86s/it]  8%|▊         | 370/4545 [23:08<4:29:33,  3.87s/it]                                                    {'loss': 0.6211, 'grad_norm': 46.586936950683594, 'learning_rate': 9.74900924702774e-08, 'rewards/chosen': 1.1269042491912842, 'rewards/rejected': 0.28388673067092896, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.8428100347518921, 'logps/chosen': -488.45001220703125, 'logps/rejected': -242.8000030517578, 'logits/chosen': -6.175000190734863, 'logits/rejected': -6.525000095367432, 'epoch': 0.24}
  8%|▊         | 370/4545 [23:08<4:29:33,  3.87s/it]  8%|▊         | 371/4545 [23:12<4:17:01,  3.69s/it]  8%|▊         | 372/4545 [23:16<4:27:17,  3.84s/it]  8%|▊         | 373/4545 [23:20<4:28:29,  3.86s/it]  8%|▊         | 374/4545 [23:23<4:23:58,  3.80s/it]  8%|▊         | 375/4545 [23:26<4:05:04,  3.53s/it]  8%|▊         | 376/4545 [23:30<4:12:10,  3.63s/it]  8%|▊         | 377/4545 [23:34<4:17:03,  3.70s/it]  8%|▊         | 378/4545 [23:38<4:19:01,  3.73s/it]  8%|▊         | 379/4545 [23:39<3:30:21,  3.03s/it]  8%|▊         | 380/4545 [23:43<3:42:19,  3.20s/it]                                                    {'loss': 0.636, 'grad_norm': 30.62021827697754, 'learning_rate': 1.0013210039630118e-07, 'rewards/chosen': 0.40070801973342896, 'rewards/rejected': 0.13386917114257812, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.26636964082717896, 'logps/chosen': -208.0749969482422, 'logps/rejected': -136.14999389648438, 'logits/chosen': -6.346875190734863, 'logits/rejected': -6.571875095367432, 'epoch': 0.25}
  8%|▊         | 380/4545 [23:43<3:42:19,  3.20s/it]  8%|▊         | 381/4545 [23:46<3:37:34,  3.14s/it]  8%|▊         | 382/4545 [23:50<3:52:42,  3.35s/it]  8%|▊         | 383/4545 [23:54<4:06:03,  3.55s/it]  8%|▊         | 384/4545 [23:57<4:13:33,  3.66s/it]  8%|▊         | 385/4545 [24:01<4:16:44,  3.70s/it]  8%|▊         | 386/4545 [24:05<4:21:31,  3.77s/it]  9%|▊         | 387/4545 [24:09<4:28:28,  3.87s/it]  9%|▊         | 388/4545 [24:13<4:28:46,  3.88s/it]  9%|▊         | 389/4545 [24:17<4:29:30,  3.89s/it]  9%|▊         | 390/4545 [24:21<4:29:56,  3.90s/it]                                                    {'loss': 0.6019, 'grad_norm': 47.51727294921875, 'learning_rate': 1.0277410832232495e-07, 'rewards/chosen': 1.031640648841858, 'rewards/rejected': 0.2645935118198395, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.7661377191543579, 'logps/chosen': -373.25, 'logps/rejected': -190.27499389648438, 'logits/chosen': -6.209374904632568, 'logits/rejected': -6.515625, 'epoch': 0.26}
  9%|▊         | 390/4545 [24:21<4:29:56,  3.90s/it]  9%|▊         | 391/4545 [24:25<4:31:40,  3.92s/it]  9%|▊         | 392/4545 [24:29<4:36:40,  4.00s/it]  9%|▊         | 393/4545 [24:33<4:34:48,  3.97s/it]  9%|▊         | 394/4545 [24:37<4:27:45,  3.87s/it]  9%|▊         | 395/4545 [24:40<4:18:18,  3.73s/it]  9%|▊         | 396/4545 [24:44<4:22:59,  3.80s/it]  9%|▊         | 397/4545 [24:48<4:27:13,  3.87s/it]  9%|▉         | 398/4545 [24:52<4:23:40,  3.81s/it]  9%|▉         | 399/4545 [24:56<4:25:49,  3.85s/it]  9%|▉         | 400/4545 [25:00<4:27:39,  3.87s/it]                                                    {'loss': 0.5949, 'grad_norm': 42.07378387451172, 'learning_rate': 1.0541611624834874e-07, 'rewards/chosen': 0.8671875, 'rewards/rejected': 0.19038085639476776, 'rewards/accuracies': 0.75, 'rewards/margins': 0.67822265625, 'logps/chosen': -299.95001220703125, 'logps/rejected': -165.47500610351562, 'logits/chosen': -6.287499904632568, 'logits/rejected': -6.668749809265137, 'epoch': 0.26}
  9%|▉         | 400/4545 [25:00<4:27:39,  3.87s/it]  9%|▉         | 401/4545 [25:03<4:11:47,  3.65s/it]  9%|▉         | 402/4545 [25:07<4:23:16,  3.81s/it]  9%|▉         | 403/4545 [25:11<4:25:12,  3.84s/it]  9%|▉         | 404/4545 [25:15<4:26:10,  3.86s/it]  9%|▉         | 405/4545 [25:17<3:53:45,  3.39s/it]  9%|▉         | 406/4545 [25:20<3:43:26,  3.24s/it]  9%|▉         | 407/4545 [25:23<3:33:34,  3.10s/it]  9%|▉         | 408/4545 [25:27<3:52:15,  3.37s/it]  9%|▉         | 409/4545 [25:30<3:53:57,  3.39s/it]  9%|▉         | 410/4545 [25:34<3:57:51,  3.45s/it]                                                    {'loss': 0.6279, 'grad_norm': 33.8117561340332, 'learning_rate': 1.0805812417437252e-07, 'rewards/chosen': 0.509082019329071, 'rewards/rejected': 0.09950866550207138, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.40864259004592896, 'logps/chosen': -197.75, 'logps/rejected': -128.0749969482422, 'logits/chosen': -6.28125, 'logits/rejected': -6.543749809265137, 'epoch': 0.27}
  9%|▉         | 410/4545 [25:34<3:57:51,  3.45s/it]  9%|▉         | 411/4545 [25:38<4:06:30,  3.58s/it]  9%|▉         | 412/4545 [25:42<4:12:44,  3.67s/it]  9%|▉         | 413/4545 [25:45<4:05:14,  3.56s/it]  9%|▉         | 414/4545 [25:49<4:15:08,  3.71s/it]  9%|▉         | 415/4545 [25:51<3:50:37,  3.35s/it]  9%|▉         | 416/4545 [25:54<3:38:55,  3.18s/it]  9%|▉         | 417/4545 [25:58<3:53:57,  3.40s/it]  9%|▉         | 418/4545 [26:01<3:43:34,  3.25s/it]  9%|▉         | 419/4545 [26:05<3:55:53,  3.43s/it]  9%|▉         | 420/4545 [26:08<3:49:00,  3.33s/it]                                                    {'loss': 0.6156, 'grad_norm': 45.64840316772461, 'learning_rate': 1.1070013210039631e-07, 'rewards/chosen': 0.7283691167831421, 'rewards/rejected': 0.16963501274585724, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.558544933795929, 'logps/chosen': -267.29998779296875, 'logps/rejected': -143.72500610351562, 'logits/chosen': -6.21875, 'logits/rejected': -6.525000095367432, 'epoch': 0.28}
  9%|▉         | 420/4545 [26:08<3:49:00,  3.33s/it]  9%|▉         | 421/4545 [26:12<4:01:07,  3.51s/it]  9%|▉         | 422/4545 [26:16<4:09:15,  3.63s/it]  9%|▉         | 423/4545 [26:19<4:00:04,  3.49s/it]  9%|▉         | 424/4545 [26:23<4:01:52,  3.52s/it]  9%|▉         | 425/4545 [26:26<4:03:41,  3.55s/it]  9%|▉         | 426/4545 [26:30<4:11:03,  3.66s/it]  9%|▉         | 427/4545 [26:34<4:17:22,  3.75s/it]  9%|▉         | 428/4545 [26:36<3:39:28,  3.20s/it]  9%|▉         | 429/4545 [26:39<3:42:51,  3.25s/it]  9%|▉         | 430/4545 [26:43<3:58:37,  3.48s/it]                                                    {'loss': 0.6026, 'grad_norm': 55.59117126464844, 'learning_rate': 1.1334214002642006e-07, 'rewards/chosen': 0.703125, 'rewards/rejected': 0.14027099311351776, 'rewards/accuracies': 0.6937500238418579, 'rewards/margins': 0.56298828125, 'logps/chosen': -280.8999938964844, 'logps/rejected': -119.8499984741211, 'logits/chosen': -6.121874809265137, 'logits/rejected': -6.474999904632568, 'epoch': 0.28}
  9%|▉         | 430/4545 [26:43<3:58:37,  3.48s/it]  9%|▉         | 431/4545 [26:48<4:13:17,  3.69s/it] 10%|▉         | 432/4545 [26:51<4:16:38,  3.74s/it] 10%|▉         | 433/4545 [26:55<4:22:34,  3.83s/it] 10%|▉         | 434/4545 [27:00<4:29:12,  3.93s/it] 10%|▉         | 435/4545 [27:03<4:08:38,  3.63s/it] 10%|▉         | 436/4545 [27:06<4:14:43,  3.72s/it] 10%|▉         | 437/4545 [27:11<4:23:23,  3.85s/it] 10%|▉         | 438/4545 [27:14<4:08:15,  3.63s/it] 10%|▉         | 439/4545 [27:17<3:54:22,  3.42s/it] 10%|▉         | 440/4545 [27:21<4:03:25,  3.56s/it]                                                    {'loss': 0.6537, 'grad_norm': 63.77311706542969, 'learning_rate': 1.1598414795244385e-07, 'rewards/chosen': 0.5464324951171875, 'rewards/rejected': 0.28714293241500854, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.2599853575229645, 'logps/chosen': -212.39999389648438, 'logps/rejected': -162.9499969482422, 'logits/chosen': -6.265625, 'logits/rejected': -6.46875, 'epoch': 0.29}
 10%|▉         | 440/4545 [27:21<4:03:25,  3.56s/it] 10%|▉         | 441/4545 [27:24<4:10:27,  3.66s/it] 10%|▉         | 442/4545 [27:28<4:02:41,  3.55s/it] 10%|▉         | 443/4545 [27:32<4:14:07,  3.72s/it] 10%|▉         | 444/4545 [27:36<4:17:10,  3.76s/it] 10%|▉         | 445/4545 [27:38<3:55:04,  3.44s/it] 10%|▉         | 446/4545 [27:43<4:09:45,  3.66s/it] 10%|▉         | 447/4545 [27:45<3:45:38,  3.30s/it] 10%|▉         | 448/4545 [27:49<3:57:49,  3.48s/it] 10%|▉         | 449/4545 [27:53<4:08:45,  3.64s/it] 10%|▉         | 450/4545 [27:57<4:14:05,  3.72s/it]                                                    {'loss': 0.5565, 'grad_norm': 24.093341827392578, 'learning_rate': 1.1862615587846762e-07, 'rewards/chosen': 1.196679711341858, 'rewards/rejected': 0.18613585829734802, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.01025390625, 'logps/chosen': -358.2250061035156, 'logps/rejected': -180.3000030517578, 'logits/chosen': -6.184374809265137, 'logits/rejected': -6.478125095367432, 'epoch': 0.3}
 10%|▉         | 450/4545 [27:57<4:14:05,  3.72s/it] 10%|▉         | 451/4545 [28:01<4:20:13,  3.81s/it] 10%|▉         | 452/4545 [28:05<4:21:58,  3.84s/it] 10%|▉         | 453/4545 [28:09<4:23:33,  3.86s/it] 10%|▉         | 454/4545 [28:13<4:24:24,  3.88s/it] 10%|█         | 455/4545 [28:17<4:24:07,  3.87s/it] 10%|█         | 456/4545 [28:20<4:19:15,  3.80s/it] 10%|█         | 457/4545 [28:24<4:21:47,  3.84s/it] 10%|█         | 458/4545 [28:28<4:22:46,  3.86s/it] 10%|█         | 459/4545 [28:32<4:24:33,  3.88s/it] 10%|█         | 460/4545 [28:36<4:18:30,  3.80s/it]                                                    {'loss': 0.6021, 'grad_norm': 71.74864196777344, 'learning_rate': 1.212681638044914e-07, 'rewards/chosen': 1.6298828125, 'rewards/rejected': 0.3653320372104645, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 1.2638428211212158, 'logps/chosen': -533.7999877929688, 'logps/rejected': -278.8999938964844, 'logits/chosen': -6.050000190734863, 'logits/rejected': -6.293749809265137, 'epoch': 0.3}
 10%|█         | 460/4545 [28:36<4:18:30,  3.80s/it] 10%|█         | 461/4545 [28:39<4:21:03,  3.84s/it] 10%|█         | 462/4545 [28:44<4:26:16,  3.91s/it] 10%|█         | 463/4545 [28:47<4:25:45,  3.91s/it] 10%|█         | 464/4545 [28:51<4:10:51,  3.69s/it] 10%|█         | 465/4545 [28:55<4:14:59,  3.75s/it] 10%|█         | 466/4545 [28:57<3:57:47,  3.50s/it] 10%|█         | 467/4545 [29:01<4:05:55,  3.62s/it] 10%|█         | 468/4545 [29:05<4:12:01,  3.71s/it] 10%|█         | 469/4545 [29:09<4:15:57,  3.77s/it] 10%|█         | 470/4545 [29:12<3:48:55,  3.37s/it]                                                    {'loss': 0.5797, 'grad_norm': 38.76357650756836, 'learning_rate': 1.239101717305152e-07, 'rewards/chosen': 0.673632800579071, 'rewards/rejected': 0.020751953125, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.6529296636581421, 'logps/chosen': -205.60000610351562, 'logps/rejected': -100.0250015258789, 'logits/chosen': -6.271874904632568, 'logits/rejected': -6.321875095367432, 'epoch': 0.31}
 10%|█         | 470/4545 [29:12<3:48:55,  3.37s/it] 10%|█         | 471/4545 [29:15<3:59:20,  3.52s/it] 10%|█         | 472/4545 [29:20<4:13:05,  3.73s/it] 10%|█         | 473/4545 [29:24<4:18:04,  3.80s/it] 10%|█         | 474/4545 [29:27<4:17:44,  3.80s/it] 10%|█         | 475/4545 [29:31<4:19:46,  3.83s/it] 10%|█         | 476/4545 [29:35<4:23:18,  3.88s/it] 10%|█         | 477/4545 [29:39<4:23:45,  3.89s/it] 11%|█         | 478/4545 [29:43<4:18:29,  3.81s/it] 11%|█         | 479/4545 [29:46<4:08:00,  3.66s/it] 11%|█         | 480/4545 [29:50<4:13:02,  3.73s/it]                                                    {'loss': 0.5674, 'grad_norm': 32.30470657348633, 'learning_rate': 1.2655217965653896e-07, 'rewards/chosen': 0.887011706829071, 'rewards/rejected': 0.12498168647289276, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.7613281011581421, 'logps/chosen': -270.5, 'logps/rejected': -161.02499389648438, 'logits/chosen': -6.234375, 'logits/rejected': -6.53125, 'epoch': 0.32}
 11%|█         | 480/4545 [29:50<4:13:02,  3.73s/it] 11%|█         | 481/4545 [29:54<4:19:24,  3.83s/it] 11%|█         | 482/4545 [29:58<4:21:06,  3.86s/it] 11%|█         | 483/4545 [30:02<4:19:22,  3.83s/it] 11%|█         | 484/4545 [30:06<4:23:14,  3.89s/it] 11%|█         | 485/4545 [30:10<4:27:15,  3.95s/it] 11%|█         | 486/4545 [30:14<4:21:21,  3.86s/it] 11%|█         | 487/4545 [30:16<3:55:31,  3.48s/it] 11%|█         | 488/4545 [30:20<4:06:14,  3.64s/it] 11%|█         | 489/4545 [30:24<4:13:04,  3.74s/it] 11%|█         | 490/4545 [30:28<4:16:00,  3.79s/it]                                                    {'loss': 0.583, 'grad_norm': 59.74074172973633, 'learning_rate': 1.2919418758256274e-07, 'rewards/chosen': 0.8900390863418579, 'rewards/rejected': 0.14958496391773224, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.7401367425918579, 'logps/chosen': -258.04998779296875, 'logps/rejected': -111.9000015258789, 'logits/chosen': -6.331250190734863, 'logits/rejected': -6.493750095367432, 'epoch': 0.32}
 11%|█         | 490/4545 [30:28<4:16:00,  3.79s/it] 11%|█         | 491/4545 [30:31<3:50:20,  3.41s/it] 11%|█         | 492/4545 [30:35<4:02:41,  3.59s/it] 11%|█         | 493/4545 [30:39<4:12:21,  3.74s/it] 11%|█         | 494/4545 [30:43<4:18:29,  3.83s/it] 11%|█         | 495/4545 [30:46<4:16:18,  3.80s/it] 11%|█         | 496/4545 [30:50<4:09:38,  3.70s/it] 11%|█         | 497/4545 [30:54<4:11:39,  3.73s/it] 11%|█         | 498/4545 [30:58<4:15:26,  3.79s/it] 11%|█         | 499/4545 [31:01<4:15:14,  3.79s/it] 11%|█         | 500/4545 [31:05<4:18:57,  3.84s/it]                                                    {'loss': 0.5644, 'grad_norm': 44.18592071533203, 'learning_rate': 1.3183619550858652e-07, 'rewards/chosen': 0.766796886920929, 'rewards/rejected': 0.08046264946460724, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 0.685351550579071, 'logps/chosen': -228.6999969482422, 'logps/rejected': -104.07499694824219, 'logits/chosen': -6.328125, 'logits/rejected': -6.646874904632568, 'epoch': 0.33}
 11%|█         | 500/4545 [31:06<4:18:57,  3.84s/it] 11%|█         | 501/4545 [31:09<4:13:52,  3.77s/it] 11%|█         | 502/4545 [31:13<4:16:10,  3.80s/it] 11%|█         | 503/4545 [31:16<4:07:46,  3.68s/it] 11%|█         | 504/4545 [31:20<4:12:34,  3.75s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:42,  1.35it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.09s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.53s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.63s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.61s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.09s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.36s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.08s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.38s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.32s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.39s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.45s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                    
                                               [A{'eval_loss': 0.46952763199806213, 'eval_runtime': 80.5435, 'eval_samples_per_second': 11.832, 'eval_steps_per_second': 0.745, 'eval_rewards/chosen': 1.2728190422058105, 'eval_rewards/rejected': 0.24689871072769165, 'eval_rewards/accuracies': 0.8811342716217041, 'eval_rewards/margins': 1.0252034664154053, 'eval_logps/chosen': -371.4333190917969, 'eval_logps/rejected': -150.68124389648438, 'eval_logits/chosen': -6.0291666984558105, 'eval_logits/rejected': -6.899479389190674, 'epoch': 0.33}
 11%|█         | 504/4545 [32:41<4:12:34,  3.75s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 11%|█         | 505/4545 [32:57<35:22:57, 31.53s/it] 11%|█         | 506/4545 [33:00<25:46:56, 22.98s/it] 11%|█         | 507/4545 [33:03<19:20:41, 17.25s/it] 11%|█         | 508/4545 [33:07<14:50:23, 13.23s/it] 11%|█         | 509/4545 [33:11<11:28:14, 10.23s/it] 11%|█         | 510/4545 [33:14<9:20:25,  8.33s/it]                                                     {'loss': 0.5606, 'grad_norm': 35.16158676147461, 'learning_rate': 1.344782034346103e-07, 'rewards/chosen': 1.299414038658142, 'rewards/rejected': 0.40581053495407104, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 0.89453125, 'logps/chosen': -384.6000061035156, 'logps/rejected': -218.4250030517578, 'logits/chosen': -6.159375190734863, 'logits/rejected': -6.587500095367432, 'epoch': 0.34}
 11%|█         | 510/4545 [33:15<9:20:25,  8.33s/it] 11%|█         | 511/4545 [33:19<7:56:38,  7.09s/it] 11%|█▏        | 512/4545 [33:22<6:47:26,  6.06s/it] 11%|█▏        | 513/4545 [33:26<6:04:32,  5.42s/it] 11%|█▏        | 514/4545 [33:30<5:34:03,  4.97s/it] 11%|█▏        | 515/4545 [33:33<4:55:51,  4.40s/it] 11%|█▏        | 516/4545 [33:37<4:44:03,  4.23s/it] 11%|█▏        | 517/4545 [33:40<4:19:04,  3.86s/it] 11%|█▏        | 518/4545 [33:44<4:13:24,  3.78s/it] 11%|█▏        | 519/4545 [33:48<4:16:53,  3.83s/it] 11%|█▏        | 520/4545 [33:52<4:19:09,  3.86s/it]                                                    {'loss': 0.5272, 'grad_norm': 48.21589660644531, 'learning_rate': 1.3712021136063407e-07, 'rewards/chosen': 1.1355469226837158, 'rewards/rejected': 0.15642090141773224, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.98046875, 'logps/chosen': -293.1000061035156, 'logps/rejected': -134.4250030517578, 'logits/chosen': -6.318749904632568, 'logits/rejected': -6.550000190734863, 'epoch': 0.34}
 11%|█▏        | 520/4545 [33:52<4:19:09,  3.86s/it] 11%|█▏        | 521/4545 [33:56<4:21:17,  3.90s/it] 11%|█▏        | 522/4545 [34:00<4:29:09,  4.01s/it] 12%|█▏        | 523/4545 [34:04<4:27:18,  3.99s/it] 12%|█▏        | 524/4545 [34:08<4:26:09,  3.97s/it] 12%|█▏        | 525/4545 [34:11<4:20:01,  3.88s/it] 12%|█▏        | 526/4545 [34:15<4:24:46,  3.95s/it] 12%|█▏        | 527/4545 [34:19<4:24:26,  3.95s/it] 12%|█▏        | 528/4545 [34:24<4:29:02,  4.02s/it] 12%|█▏        | 529/4545 [34:27<4:18:05,  3.86s/it] 12%|█▏        | 530/4545 [34:31<4:22:53,  3.93s/it]                                                    {'loss': 0.533, 'grad_norm': 62.263038635253906, 'learning_rate': 1.3976221928665784e-07, 'rewards/chosen': 0.9579101800918579, 'rewards/rejected': 0.12216491997241974, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.836230456829071, 'logps/chosen': -259.95001220703125, 'logps/rejected': -128.27499389648438, 'logits/chosen': -6.315625190734863, 'logits/rejected': -6.662499904632568, 'epoch': 0.35}
 12%|█▏        | 530/4545 [34:31<4:22:53,  3.93s/it] 12%|█▏        | 531/4545 [34:35<4:23:51,  3.94s/it] 12%|█▏        | 532/4545 [34:39<4:22:10,  3.92s/it] 12%|█▏        | 533/4545 [34:42<4:05:45,  3.68s/it] 12%|█▏        | 534/4545 [34:46<4:14:59,  3.81s/it] 12%|█▏        | 535/4545 [34:50<4:17:11,  3.85s/it] 12%|█▏        | 536/4545 [34:54<4:18:26,  3.87s/it] 12%|█▏        | 537/4545 [34:57<3:58:16,  3.57s/it] 12%|█▏        | 538/4545 [35:01<3:59:52,  3.59s/it] 12%|█▏        | 539/4545 [35:05<4:06:21,  3.69s/it] 12%|█▏        | 540/4545 [35:08<4:10:20,  3.75s/it]                                                    {'loss': 0.5552, 'grad_norm': 27.518543243408203, 'learning_rate': 1.4240422721268165e-07, 'rewards/chosen': 0.8622070550918579, 'rewards/rejected': 0.18437500298023224, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.679028332233429, 'logps/chosen': -220.39999389648438, 'logps/rejected': -141.3000030517578, 'logits/chosen': -6.384375095367432, 'logits/rejected': -6.465624809265137, 'epoch': 0.36}
 12%|█▏        | 540/4545 [35:08<4:10:20,  3.75s/it] 12%|█▏        | 541/4545 [35:12<4:14:26,  3.81s/it] 12%|█▏        | 542/4545 [35:16<4:15:38,  3.83s/it] 12%|█▏        | 543/4545 [35:20<4:12:53,  3.79s/it] 12%|█▏        | 544/4545 [35:24<4:15:31,  3.83s/it] 12%|█▏        | 545/4545 [35:28<4:22:38,  3.94s/it] 12%|█▏        | 546/4545 [35:32<4:22:16,  3.94s/it] 12%|█▏        | 547/4545 [35:36<4:21:43,  3.93s/it] 12%|█▏        | 548/4545 [35:39<4:12:18,  3.79s/it] 12%|█▏        | 549/4545 [35:43<4:06:55,  3.71s/it] 12%|█▏        | 550/4545 [35:47<4:10:57,  3.77s/it]                                                    {'loss': 0.5231, 'grad_norm': 78.53776550292969, 'learning_rate': 1.4504623513870542e-07, 'rewards/chosen': 1.265039086341858, 'rewards/rejected': 0.17197266221046448, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.0910155773162842, 'logps/chosen': -330.6499938964844, 'logps/rejected': -184.125, 'logits/chosen': -6.181250095367432, 'logits/rejected': -6.471875190734863, 'epoch': 0.36}
 12%|█▏        | 550/4545 [35:47<4:10:57,  3.77s/it] 12%|█▏        | 551/4545 [35:51<4:14:33,  3.82s/it] 12%|█▏        | 552/4545 [35:55<4:15:32,  3.84s/it] 12%|█▏        | 553/4545 [35:59<4:16:59,  3.86s/it] 12%|█▏        | 554/4545 [36:02<4:06:56,  3.71s/it] 12%|█▏        | 555/4545 [36:06<4:11:08,  3.78s/it] 12%|█▏        | 556/4545 [36:10<4:14:08,  3.82s/it] 12%|█▏        | 557/4545 [36:12<3:48:42,  3.44s/it] 12%|█▏        | 558/4545 [36:16<3:58:46,  3.59s/it] 12%|█▏        | 559/4545 [36:20<3:53:27,  3.51s/it] 12%|█▏        | 560/4545 [36:23<3:59:58,  3.61s/it]                                                    {'loss': 0.5543, 'grad_norm': 47.0493049621582, 'learning_rate': 1.4768824306472917e-07, 'rewards/chosen': 1.1990234851837158, 'rewards/rejected': 0.33665162324905396, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.8642578125, 'logps/chosen': -331.29998779296875, 'logps/rejected': -203.60000610351562, 'logits/chosen': -6.278124809265137, 'logits/rejected': -6.503125190734863, 'epoch': 0.37}
 12%|█▏        | 560/4545 [36:24<3:59:58,  3.61s/it] 12%|█▏        | 561/4545 [36:27<4:06:34,  3.71s/it] 12%|█▏        | 562/4545 [36:31<4:09:40,  3.76s/it] 12%|█▏        | 563/4545 [36:34<3:55:22,  3.55s/it] 12%|█▏        | 564/4545 [36:38<3:51:26,  3.49s/it] 12%|█▏        | 565/4545 [36:42<4:02:04,  3.65s/it] 12%|█▏        | 566/4545 [36:46<4:06:23,  3.72s/it] 12%|█▏        | 567/4545 [36:49<4:07:00,  3.73s/it] 12%|█▏        | 568/4545 [36:53<4:10:32,  3.78s/it] 13%|█▎        | 569/4545 [36:57<4:09:09,  3.76s/it] 13%|█▎        | 570/4545 [37:01<4:14:22,  3.84s/it]                                                    {'loss': 0.5463, 'grad_norm': 30.398590087890625, 'learning_rate': 1.5033025099075295e-07, 'rewards/chosen': 1.1150391101837158, 'rewards/rejected': 0.2708740234375, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.845898449420929, 'logps/chosen': -262.45001220703125, 'logps/rejected': -175.8249969482422, 'logits/chosen': -6.503125190734863, 'logits/rejected': -6.668749809265137, 'epoch': 0.38}
 13%|█▎        | 570/4545 [37:01<4:14:22,  3.84s/it] 13%|█▎        | 571/4545 [37:05<4:16:16,  3.87s/it] 13%|█▎        | 572/4545 [37:09<4:16:51,  3.88s/it] 13%|█▎        | 573/4545 [37:13<4:23:34,  3.98s/it] 13%|█▎        | 574/4545 [37:17<4:26:05,  4.02s/it] 13%|█▎        | 575/4545 [37:21<4:24:13,  3.99s/it] 13%|█▎        | 576/4545 [37:25<4:21:33,  3.95s/it] 13%|█▎        | 577/4545 [37:29<4:20:46,  3.94s/it] 13%|█▎        | 578/4545 [37:32<4:09:24,  3.77s/it] 13%|█▎        | 579/4545 [37:35<3:52:22,  3.52s/it] 13%|█▎        | 580/4545 [37:39<4:05:06,  3.71s/it]                                                    {'loss': 0.5076, 'grad_norm': 29.33940887451172, 'learning_rate': 1.5297225891677675e-07, 'rewards/chosen': 1.280664086341858, 'rewards/rejected': 0.27714842557907104, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.00390625, 'logps/chosen': -306.3500061035156, 'logps/rejected': -180.6750030517578, 'logits/chosen': -6.353125095367432, 'logits/rejected': -6.596875190734863, 'epoch': 0.38}
 13%|█▎        | 580/4545 [37:39<4:05:06,  3.71s/it] 13%|█▎        | 581/4545 [37:42<3:54:56,  3.56s/it] 13%|█▎        | 582/4545 [37:46<4:02:09,  3.67s/it] 13%|█▎        | 583/4545 [37:49<3:46:04,  3.42s/it] 13%|█▎        | 584/4545 [37:53<3:55:19,  3.56s/it] 13%|█▎        | 585/4545 [37:57<3:51:39,  3.51s/it] 13%|█▎        | 586/4545 [38:00<3:59:26,  3.63s/it] 13%|█▎        | 587/4545 [38:05<4:09:40,  3.78s/it] 13%|█▎        | 588/4545 [38:09<4:12:22,  3.83s/it] 13%|█▎        | 589/4545 [38:11<3:51:35,  3.51s/it] 13%|█▎        | 590/4545 [38:15<3:53:18,  3.54s/it]                                                    {'loss': 0.5397, 'grad_norm': 40.108489990234375, 'learning_rate': 1.5561426684280053e-07, 'rewards/chosen': 1.338964819908142, 'rewards/rejected': 0.2892089784145355, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.050878882408142, 'logps/chosen': -318.54998779296875, 'logps/rejected': -198.3000030517578, 'logits/chosen': -6.284375190734863, 'logits/rejected': -6.606249809265137, 'epoch': 0.39}
 13%|█▎        | 590/4545 [38:15<3:53:18,  3.54s/it] 13%|█▎        | 591/4545 [38:19<4:04:34,  3.71s/it] 13%|█▎        | 592/4545 [38:22<3:57:53,  3.61s/it] 13%|█▎        | 593/4545 [38:26<3:54:10,  3.56s/it] 13%|█▎        | 594/4545 [38:30<4:02:01,  3.68s/it] 13%|█▎        | 595/4545 [38:34<4:03:50,  3.70s/it] 13%|█▎        | 596/4545 [38:37<4:08:06,  3.77s/it] 13%|█▎        | 597/4545 [38:42<4:17:21,  3.91s/it] 13%|█▎        | 598/4545 [38:45<4:01:29,  3.67s/it] 13%|█▎        | 599/4545 [38:49<4:12:10,  3.83s/it] 13%|█▎        | 600/4545 [38:52<3:58:59,  3.63s/it]                                                    {'loss': 0.4798, 'grad_norm': 40.916481018066406, 'learning_rate': 1.582562747688243e-07, 'rewards/chosen': 1.433203101158142, 'rewards/rejected': 0.2992919981479645, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.1328125, 'logps/chosen': -299.29998779296875, 'logps/rejected': -187.9499969482422, 'logits/chosen': -6.434374809265137, 'logits/rejected': -6.631249904632568, 'epoch': 0.4}
 13%|█▎        | 600/4545 [38:52<3:58:59,  3.63s/it] 13%|█▎        | 601/4545 [38:56<3:57:05,  3.61s/it] 13%|█▎        | 602/4545 [38:59<3:52:42,  3.54s/it] 13%|█▎        | 603/4545 [39:03<3:59:13,  3.64s/it] 13%|█▎        | 604/4545 [39:06<3:52:55,  3.55s/it] 13%|█▎        | 605/4545 [39:11<4:06:05,  3.75s/it] 13%|█▎        | 606/4545 [39:14<3:56:54,  3.61s/it] 13%|█▎        | 607/4545 [39:18<4:06:13,  3.75s/it] 13%|█▎        | 608/4545 [39:22<4:09:12,  3.80s/it] 13%|█▎        | 609/4545 [39:26<4:11:34,  3.83s/it] 13%|█▎        | 610/4545 [39:30<4:13:55,  3.87s/it]                                                    {'loss': 0.4878, 'grad_norm': 42.681724548339844, 'learning_rate': 1.6089828269484808e-07, 'rewards/chosen': 1.8054687976837158, 'rewards/rejected': 0.2697997987270355, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.534570336341858, 'logps/chosen': -374.5, 'logps/rejected': -185.5749969482422, 'logits/chosen': -6.168749809265137, 'logits/rejected': -6.449999809265137, 'epoch': 0.4}
 13%|█▎        | 610/4545 [39:30<4:13:55,  3.87s/it] 13%|█▎        | 611/4545 [39:34<4:19:04,  3.95s/it] 13%|█▎        | 612/4545 [39:37<3:58:10,  3.63s/it] 13%|█▎        | 613/4545 [39:41<4:02:33,  3.70s/it] 14%|█▎        | 614/4545 [39:44<4:06:19,  3.76s/it] 14%|█▎        | 615/4545 [39:47<3:49:05,  3.50s/it] 14%|█▎        | 616/4545 [39:51<3:50:10,  3.52s/it] 14%|█▎        | 617/4545 [39:55<3:55:47,  3.60s/it] 14%|█▎        | 618/4545 [39:58<3:42:49,  3.40s/it] 14%|█▎        | 619/4545 [40:02<3:52:32,  3.55s/it] 14%|█▎        | 620/4545 [40:04<3:34:01,  3.27s/it]                                                    {'loss': 0.5389, 'grad_norm': 43.16702651977539, 'learning_rate': 1.6354029062087186e-07, 'rewards/chosen': 1.086328148841858, 'rewards/rejected': 0.04299316555261612, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.0408203601837158, 'logps/chosen': -220.9499969482422, 'logps/rejected': -114.6500015258789, 'logits/chosen': -6.525000095367432, 'logits/rejected': -6.515625, 'epoch': 0.41}
 14%|█▎        | 620/4545 [40:04<3:34:01,  3.27s/it] 14%|█▎        | 621/4545 [40:08<3:46:57,  3.47s/it] 14%|█▎        | 622/4545 [40:12<3:55:12,  3.60s/it] 14%|█▎        | 623/4545 [40:16<3:56:20,  3.62s/it] 14%|█▎        | 624/4545 [40:19<4:00:25,  3.68s/it] 14%|█▍        | 625/4545 [40:23<4:05:16,  3.75s/it] 14%|█▍        | 626/4545 [40:27<4:08:54,  3.81s/it] 14%|█▍        | 627/4545 [40:31<4:02:46,  3.72s/it] 14%|█▍        | 628/4545 [40:35<4:04:29,  3.75s/it] 14%|█▍        | 629/4545 [40:39<4:07:42,  3.80s/it] 14%|█▍        | 630/4545 [40:42<4:09:56,  3.83s/it]                                                    {'loss': 0.452, 'grad_norm': 66.23971557617188, 'learning_rate': 1.6618229854689563e-07, 'rewards/chosen': 1.3708984851837158, 'rewards/rejected': 0.1749267578125, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.1953125, 'logps/chosen': -277.54998779296875, 'logps/rejected': -151.5500030517578, 'logits/chosen': -6.28125, 'logits/rejected': -6.534375190734863, 'epoch': 0.42}
 14%|█▍        | 630/4545 [40:43<4:09:56,  3.83s/it] 14%|█▍        | 631/4545 [40:47<4:19:21,  3.98s/it] 14%|█▍        | 632/4545 [40:51<4:17:08,  3.94s/it] 14%|█▍        | 633/4545 [40:54<4:11:36,  3.86s/it] 14%|█▍        | 634/4545 [40:59<4:17:43,  3.95s/it] 14%|█▍        | 635/4545 [41:03<4:20:48,  4.00s/it] 14%|█▍        | 636/4545 [41:07<4:21:56,  4.02s/it] 14%|█▍        | 637/4545 [41:11<4:23:16,  4.04s/it] 14%|█▍        | 638/4545 [41:15<4:20:50,  4.01s/it] 14%|█▍        | 639/4545 [41:18<4:13:56,  3.90s/it] 14%|█▍        | 640/4545 [41:22<4:09:17,  3.83s/it]                                                    {'loss': 0.4383, 'grad_norm': 19.47817039489746, 'learning_rate': 1.688243064729194e-07, 'rewards/chosen': 1.0031249523162842, 'rewards/rejected': -0.0018066406482830644, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.005273461341858, 'logps/chosen': -196.10000610351562, 'logps/rejected': -135.0, 'logits/chosen': -6.478125095367432, 'logits/rejected': -6.715624809265137, 'epoch': 0.42}
 14%|█▍        | 640/4545 [41:22<4:09:17,  3.83s/it] 14%|█▍        | 641/4545 [41:26<4:14:54,  3.92s/it] 14%|█▍        | 642/4545 [41:30<4:14:48,  3.92s/it] 14%|█▍        | 643/4545 [41:34<4:14:26,  3.91s/it] 14%|█▍        | 644/4545 [41:38<4:13:14,  3.89s/it] 14%|█▍        | 645/4545 [41:42<4:13:43,  3.90s/it] 14%|█▍        | 646/4545 [41:46<4:13:56,  3.91s/it] 14%|█▍        | 647/4545 [41:49<3:58:13,  3.67s/it] 14%|█▍        | 648/4545 [41:53<4:02:40,  3.74s/it] 14%|█▍        | 649/4545 [41:57<4:06:59,  3.80s/it] 14%|█▍        | 650/4545 [42:01<4:08:58,  3.84s/it]                                                    {'loss': 0.4638, 'grad_norm': 28.10456085205078, 'learning_rate': 1.7146631439894318e-07, 'rewards/chosen': 2.1214842796325684, 'rewards/rejected': 0.30170899629592896, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 1.8203125, 'logps/chosen': -431.79998779296875, 'logps/rejected': -229.10000610351562, 'logits/chosen': -6.221875190734863, 'logits/rejected': -6.493750095367432, 'epoch': 0.43}
 14%|█▍        | 650/4545 [42:01<4:08:58,  3.84s/it] 14%|█▍        | 651/4545 [42:05<4:11:30,  3.88s/it] 14%|█▍        | 652/4545 [42:08<4:06:56,  3.81s/it] 14%|█▍        | 653/4545 [42:12<4:09:24,  3.84s/it] 14%|█▍        | 654/4545 [42:16<4:09:53,  3.85s/it] 14%|█▍        | 655/4545 [42:19<4:01:11,  3.72s/it] 14%|█▍        | 656/4545 [42:23<3:59:56,  3.70s/it] 14%|█▍        | 657/4545 [42:28<4:15:51,  3.95s/it] 14%|█▍        | 658/4545 [42:30<3:48:33,  3.53s/it] 14%|█▍        | 659/4545 [42:34<3:55:11,  3.63s/it] 15%|█▍        | 660/4545 [42:38<4:01:51,  3.74s/it]                                                    {'loss': 0.484, 'grad_norm': 23.379350662231445, 'learning_rate': 1.7410832232496696e-07, 'rewards/chosen': 1.5675780773162842, 'rewards/rejected': 0.06997070461511612, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.4963867664337158, 'logps/chosen': -308.54998779296875, 'logps/rejected': -143.35000610351562, 'logits/chosen': -6.415625095367432, 'logits/rejected': -6.571875095367432, 'epoch': 0.44}
 15%|█▍        | 660/4545 [42:38<4:01:51,  3.74s/it] 15%|█▍        | 661/4545 [42:42<4:08:08,  3.83s/it] 15%|█▍        | 662/4545 [42:46<4:14:35,  3.93s/it] 15%|█▍        | 663/4545 [42:50<4:08:32,  3.84s/it] 15%|█▍        | 664/4545 [42:53<4:02:04,  3.74s/it] 15%|█▍        | 665/4545 [42:57<3:56:38,  3.66s/it] 15%|█▍        | 666/4545 [43:01<4:00:29,  3.72s/it] 15%|█▍        | 667/4545 [43:05<4:03:18,  3.76s/it] 15%|█▍        | 668/4545 [43:08<3:56:53,  3.67s/it] 15%|█▍        | 669/4545 [43:12<4:01:34,  3.74s/it] 15%|█▍        | 670/4545 [43:16<4:06:25,  3.82s/it]                                                    {'loss': 0.5139, 'grad_norm': 46.1487922668457, 'learning_rate': 1.7675033025099076e-07, 'rewards/chosen': 0.755664050579071, 'rewards/rejected': -0.08341064304113388, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8388671875, 'logps/chosen': -147.5, 'logps/rejected': -95.55000305175781, 'logits/chosen': -6.599999904632568, 'logits/rejected': -6.678124904632568, 'epoch': 0.44}
 15%|█▍        | 670/4545 [43:16<4:06:25,  3.82s/it] 15%|█▍        | 671/4545 [43:20<4:08:37,  3.85s/it] 15%|█▍        | 672/4545 [43:24<4:13:04,  3.92s/it] 15%|█▍        | 673/4545 [43:27<4:01:57,  3.75s/it] 15%|█▍        | 674/4545 [43:31<4:05:02,  3.80s/it] 15%|█▍        | 675/4545 [43:35<4:06:08,  3.82s/it] 15%|█▍        | 676/4545 [43:39<4:07:24,  3.84s/it] 15%|█▍        | 677/4545 [43:41<3:41:35,  3.44s/it] 15%|█▍        | 678/4545 [43:45<3:50:44,  3.58s/it] 15%|█▍        | 679/4545 [43:49<4:00:41,  3.74s/it] 15%|█▍        | 680/4545 [43:53<4:04:05,  3.79s/it]                                                    {'loss': 0.465, 'grad_norm': 29.88945198059082, 'learning_rate': 1.793923381770145e-07, 'rewards/chosen': 1.7683594226837158, 'rewards/rejected': 0.0584716796875, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.7097656726837158, 'logps/chosen': -364.6499938964844, 'logps/rejected': -163.9250030517578, 'logits/chosen': -6.440625190734863, 'logits/rejected': -6.568749904632568, 'epoch': 0.45}
 15%|█▍        | 680/4545 [43:53<4:04:05,  3.79s/it] 15%|█▍        | 681/4545 [43:58<4:12:38,  3.92s/it] 15%|█▌        | 682/4545 [44:01<4:09:23,  3.87s/it] 15%|█▌        | 683/4545 [44:05<4:10:30,  3.89s/it] 15%|█▌        | 684/4545 [44:09<4:15:42,  3.97s/it] 15%|█▌        | 685/4545 [44:13<4:14:31,  3.96s/it] 15%|█▌        | 686/4545 [44:17<4:12:50,  3.93s/it] 15%|█▌        | 687/4545 [44:21<4:08:26,  3.86s/it] 15%|█▌        | 688/4545 [44:25<4:09:16,  3.88s/it] 15%|█▌        | 689/4545 [44:28<4:01:56,  3.76s/it] 15%|█▌        | 690/4545 [44:32<4:04:03,  3.80s/it]                                                    {'loss': 0.475, 'grad_norm': 45.05255889892578, 'learning_rate': 1.820343461030383e-07, 'rewards/chosen': 1.711523413658142, 'rewards/rejected': 0.1876220703125, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.5222656726837158, 'logps/chosen': -329.70001220703125, 'logps/rejected': -149.25, 'logits/chosen': -6.431250095367432, 'logits/rejected': -6.731249809265137, 'epoch': 0.46}
 15%|█▌        | 690/4545 [44:32<4:04:03,  3.80s/it] 15%|█▌        | 691/4545 [44:36<4:10:22,  3.90s/it] 15%|█▌        | 692/4545 [44:39<3:43:30,  3.48s/it] 15%|█▌        | 693/4545 [44:43<3:54:06,  3.65s/it] 15%|█▌        | 694/4545 [44:46<3:47:54,  3.55s/it] 15%|█▌        | 695/4545 [44:50<3:59:58,  3.74s/it] 15%|█▌        | 696/4545 [44:54<4:02:57,  3.79s/it] 15%|█▌        | 697/4545 [44:58<3:59:17,  3.73s/it] 15%|█▌        | 698/4545 [45:02<4:03:02,  3.79s/it] 15%|█▌        | 699/4545 [45:06<4:05:24,  3.83s/it] 15%|█▌        | 700/4545 [45:10<4:04:53,  3.82s/it]                                                    {'loss': 0.4368, 'grad_norm': 38.24861145019531, 'learning_rate': 1.8467635402906206e-07, 'rewards/chosen': 1.415429711341858, 'rewards/rejected': 0.075836181640625, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.3390624523162842, 'logps/chosen': -264.8999938964844, 'logps/rejected': -156.27499389648438, 'logits/chosen': -6.506249904632568, 'logits/rejected': -6.537499904632568, 'epoch': 0.46}
 15%|█▌        | 700/4545 [45:10<4:04:53,  3.82s/it] 15%|█▌        | 701/4545 [45:13<4:06:50,  3.85s/it] 15%|█▌        | 702/4545 [45:17<4:07:52,  3.87s/it] 15%|█▌        | 703/4545 [45:22<4:14:00,  3.97s/it] 15%|█▌        | 704/4545 [45:25<3:54:49,  3.67s/it] 16%|█▌        | 705/4545 [45:28<3:56:23,  3.69s/it] 16%|█▌        | 706/4545 [45:32<4:00:29,  3.76s/it] 16%|█▌        | 707/4545 [45:36<4:03:12,  3.80s/it] 16%|█▌        | 708/4545 [45:40<4:05:32,  3.84s/it] 16%|█▌        | 709/4545 [45:43<3:53:07,  3.65s/it] 16%|█▌        | 710/4545 [45:47<3:57:31,  3.72s/it]                                                    {'loss': 0.4306, 'grad_norm': 32.05332946777344, 'learning_rate': 1.8731836195508587e-07, 'rewards/chosen': 1.3044922351837158, 'rewards/rejected': -0.11726073920726776, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.420312523841858, 'logps/chosen': -230.5500030517578, 'logps/rejected': -100.32499694824219, 'logits/chosen': -6.465624809265137, 'logits/rejected': -6.775000095367432, 'epoch': 0.47}
 16%|█▌        | 710/4545 [45:47<3:57:31,  3.72s/it] 16%|█▌        | 711/4545 [45:50<3:36:41,  3.39s/it] 16%|█▌        | 712/4545 [45:54<3:46:53,  3.55s/it] 16%|█▌        | 713/4545 [45:58<3:52:53,  3.65s/it] 16%|█▌        | 714/4545 [46:01<3:58:28,  3.74s/it] 16%|█▌        | 715/4545 [46:05<4:00:19,  3.76s/it] 16%|█▌        | 716/4545 [46:09<3:52:06,  3.64s/it] 16%|█▌        | 717/4545 [46:12<3:56:30,  3.71s/it] 16%|█▌        | 718/4545 [46:17<4:05:29,  3.85s/it] 16%|█▌        | 719/4545 [46:20<3:46:50,  3.56s/it] 16%|█▌        | 720/4545 [46:24<3:58:30,  3.74s/it]                                                    {'loss': 0.4843, 'grad_norm': 21.653675079345703, 'learning_rate': 1.8996036988110964e-07, 'rewards/chosen': 1.5744140148162842, 'rewards/rejected': 0.26478272676467896, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.310644507408142, 'logps/chosen': -286.20001220703125, 'logps/rejected': -208.64999389648438, 'logits/chosen': -6.331250190734863, 'logits/rejected': -6.65625, 'epoch': 0.48}
 16%|█▌        | 720/4545 [46:24<3:58:30,  3.74s/it] 16%|█▌        | 721/4545 [46:28<4:02:40,  3.81s/it] 16%|█▌        | 722/4545 [46:31<3:56:38,  3.71s/it] 16%|█▌        | 723/4545 [46:35<4:00:55,  3.78s/it] 16%|█▌        | 724/4545 [46:39<4:03:26,  3.82s/it] 16%|█▌        | 725/4545 [46:43<4:04:26,  3.84s/it] 16%|█▌        | 726/4545 [46:47<4:05:54,  3.86s/it] 16%|█▌        | 727/4545 [46:49<3:38:14,  3.43s/it] 16%|█▌        | 728/4545 [46:51<3:09:04,  2.97s/it] 16%|█▌        | 729/4545 [46:54<3:05:25,  2.92s/it] 16%|█▌        | 730/4545 [46:58<3:24:23,  3.21s/it]                                                    {'loss': 0.4951, 'grad_norm': 363.62860107421875, 'learning_rate': 1.9260237780713342e-07, 'rewards/chosen': 1.634374976158142, 'rewards/rejected': 0.06425781548023224, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 1.570898413658142, 'logps/chosen': -297.95001220703125, 'logps/rejected': -147.875, 'logits/chosen': -6.543749809265137, 'logits/rejected': -6.543749809265137, 'epoch': 0.48}
 16%|█▌        | 730/4545 [46:58<3:24:23,  3.21s/it] 16%|█▌        | 731/4545 [47:00<3:12:17,  3.02s/it] 16%|█▌        | 732/4545 [47:04<3:29:09,  3.29s/it] 16%|█▌        | 733/4545 [47:08<3:41:11,  3.48s/it] 16%|█▌        | 734/4545 [47:12<3:49:16,  3.61s/it] 16%|█▌        | 735/4545 [47:16<4:00:49,  3.79s/it] 16%|█▌        | 736/4545 [47:20<4:04:04,  3.84s/it] 16%|█▌        | 737/4545 [47:24<4:05:09,  3.86s/it] 16%|█▌        | 738/4545 [47:28<4:09:20,  3.93s/it] 16%|█▋        | 739/4545 [47:32<3:56:54,  3.73s/it] 16%|█▋        | 740/4545 [47:36<4:05:33,  3.87s/it]                                                    {'loss': 0.463, 'grad_norm': 18.666120529174805, 'learning_rate': 1.9524438573315717e-07, 'rewards/chosen': 1.7414062023162842, 'rewards/rejected': 0.16289062798023224, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.5822265148162842, 'logps/chosen': -327.1499938964844, 'logps/rejected': -196.8874969482422, 'logits/chosen': -6.318749904632568, 'logits/rejected': -6.490624904632568, 'epoch': 0.49}
 16%|█▋        | 740/4545 [47:36<4:05:33,  3.87s/it] 16%|█▋        | 741/4545 [47:40<4:06:46,  3.89s/it] 16%|█▋        | 742/4545 [47:43<3:55:53,  3.72s/it] 16%|█▋        | 743/4545 [47:47<3:51:18,  3.65s/it] 16%|█▋        | 744/4545 [47:50<3:55:58,  3.72s/it] 16%|█▋        | 745/4545 [47:54<3:50:00,  3.63s/it] 16%|█▋        | 746/4545 [47:58<4:00:18,  3.80s/it] 16%|█▋        | 747/4545 [48:02<4:01:46,  3.82s/it] 16%|█▋        | 748/4545 [48:05<3:48:37,  3.61s/it] 16%|█▋        | 749/4545 [48:09<3:54:55,  3.71s/it] 17%|█▋        | 750/4545 [48:13<3:58:29,  3.77s/it]                                                    {'loss': 0.4495, 'grad_norm': 40.98805236816406, 'learning_rate': 1.9788639365918097e-07, 'rewards/chosen': 1.107031226158142, 'rewards/rejected': -0.20048674941062927, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.3093750476837158, 'logps/chosen': -210.89999389648438, 'logps/rejected': -110.25, 'logits/chosen': -6.565625190734863, 'logits/rejected': -6.71875, 'epoch': 0.5}
 17%|█▋        | 750/4545 [48:13<3:58:29,  3.77s/it] 17%|█▋        | 751/4545 [48:17<4:02:07,  3.83s/it] 17%|█▋        | 752/4545 [48:21<4:02:25,  3.83s/it] 17%|█▋        | 753/4545 [48:25<4:09:02,  3.94s/it] 17%|█▋        | 754/4545 [48:28<3:57:52,  3.76s/it] 17%|█▋        | 755/4545 [48:32<4:00:03,  3.80s/it] 17%|█▋        | 756/4545 [48:36<4:09:36,  3.95s/it] 17%|█▋        | 757/4545 [48:40<4:08:11,  3.93s/it] 17%|█▋        | 758/4545 [48:44<4:07:58,  3.93s/it] 17%|█▋        | 759/4545 [48:48<4:04:26,  3.87s/it] 17%|█▋        | 760/4545 [48:52<3:59:55,  3.80s/it]                                                    {'loss': 0.3874, 'grad_norm': 30.29201316833496, 'learning_rate': 2.0052840158520477e-07, 'rewards/chosen': 2.5875000953674316, 'rewards/rejected': 0.17646484076976776, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.412890672683716, 'logps/chosen': -424.70001220703125, 'logps/rejected': -223.25, 'logits/chosen': -6.306250095367432, 'logits/rejected': -6.665625095367432, 'epoch': 0.5}
 17%|█▋        | 760/4545 [48:52<3:59:55,  3.80s/it] 17%|█▋        | 761/4545 [48:56<4:03:43,  3.86s/it] 17%|█▋        | 762/4545 [49:00<4:04:19,  3.88s/it] 17%|█▋        | 763/4545 [49:03<3:53:12,  3.70s/it] 17%|█▋        | 764/4545 [49:07<3:55:03,  3.73s/it] 17%|█▋        | 765/4545 [49:10<3:41:50,  3.52s/it] 17%|█▋        | 766/4545 [49:14<3:49:48,  3.65s/it] 17%|█▋        | 767/4545 [49:17<3:53:48,  3.71s/it] 17%|█▋        | 768/4545 [49:22<4:01:19,  3.83s/it] 17%|█▋        | 769/4545 [49:25<3:46:43,  3.60s/it] 17%|█▋        | 770/4545 [49:28<3:36:24,  3.44s/it]                                                    {'loss': 0.3923, 'grad_norm': 19.16841697692871, 'learning_rate': 2.0317040951122855e-07, 'rewards/chosen': 1.44921875, 'rewards/rejected': -0.1612548828125, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 1.610742211341858, 'logps/chosen': -244.0, 'logps/rejected': -152.9499969482422, 'logits/chosen': -6.659375190734863, 'logits/rejected': -6.706250190734863, 'epoch': 0.51}
 17%|█▋        | 770/4545 [49:28<3:36:24,  3.44s/it] 17%|█▋        | 771/4545 [49:30<3:17:40,  3.14s/it] 17%|█▋        | 772/4545 [49:34<3:37:07,  3.45s/it] 17%|█▋        | 773/4545 [49:37<3:17:04,  3.13s/it] 17%|█▋        | 774/4545 [49:40<3:26:35,  3.29s/it] 17%|█▋        | 775/4545 [49:45<3:42:35,  3.54s/it] 17%|█▋        | 776/4545 [49:48<3:49:28,  3.65s/it] 17%|█▋        | 777/4545 [49:52<3:42:04,  3.54s/it] 17%|█▋        | 778/4545 [49:55<3:44:05,  3.57s/it] 17%|█▋        | 779/4545 [50:00<3:56:50,  3.77s/it] 17%|█▋        | 780/4545 [50:03<3:58:49,  3.81s/it]                                                    {'loss': 0.4389, 'grad_norm': 38.17165756225586, 'learning_rate': 2.0581241743725227e-07, 'rewards/chosen': 1.5177733898162842, 'rewards/rejected': -0.15971679985523224, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.673828125, 'logps/chosen': -259.8500061035156, 'logps/rejected': -152.64999389648438, 'logits/chosen': -6.493750095367432, 'logits/rejected': -6.637499809265137, 'epoch': 0.51}
 17%|█▋        | 780/4545 [50:04<3:58:49,  3.81s/it] 17%|█▋        | 781/4545 [50:06<3:41:15,  3.53s/it] 17%|█▋        | 782/4545 [50:10<3:50:54,  3.68s/it] 17%|█▋        | 783/4545 [50:15<4:01:47,  3.86s/it] 17%|█▋        | 784/4545 [50:18<3:54:28,  3.74s/it] 17%|█▋        | 785/4545 [50:22<3:56:55,  3.78s/it] 17%|█▋        | 786/4545 [50:26<3:59:02,  3.82s/it] 17%|█▋        | 787/4545 [50:30<4:00:49,  3.84s/it] 17%|█▋        | 788/4545 [50:34<4:02:22,  3.87s/it] 17%|█▋        | 789/4545 [50:37<3:50:14,  3.68s/it] 17%|█▋        | 790/4545 [50:39<3:27:31,  3.32s/it]                                                    {'loss': 0.4514, 'grad_norm': 29.98091697692871, 'learning_rate': 2.0845442536327607e-07, 'rewards/chosen': 1.4132812023162842, 'rewards/rejected': -0.27491456270217896, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.688867211341858, 'logps/chosen': -237.0, 'logps/rejected': -104.55000305175781, 'logits/chosen': -6.5, 'logits/rejected': -6.84375, 'epoch': 0.52}
 17%|█▋        | 790/4545 [50:40<3:27:31,  3.32s/it] 17%|█▋        | 791/4545 [50:43<3:23:26,  3.25s/it] 17%|█▋        | 792/4545 [50:47<3:38:58,  3.50s/it] 17%|█▋        | 793/4545 [50:51<3:50:31,  3.69s/it] 17%|█▋        | 794/4545 [50:55<3:59:45,  3.84s/it] 17%|█▋        | 795/4545 [50:59<4:04:27,  3.91s/it] 18%|█▊        | 796/4545 [51:03<4:03:17,  3.89s/it] 18%|█▊        | 797/4545 [51:07<4:03:20,  3.90s/it] 18%|█▊        | 798/4545 [51:11<4:03:42,  3.90s/it] 18%|█▊        | 799/4545 [51:15<4:02:40,  3.89s/it] 18%|█▊        | 800/4545 [51:18<4:03:09,  3.90s/it]                                                    {'loss': 0.3861, 'grad_norm': 25.43881607055664, 'learning_rate': 2.1109643328929985e-07, 'rewards/chosen': 1.8269531726837158, 'rewards/rejected': -0.26044923067092896, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.0863280296325684, 'logps/chosen': -313.45001220703125, 'logps/rejected': -150.27499389648438, 'logits/chosen': -6.553124904632568, 'logits/rejected': -6.659375190734863, 'epoch': 0.53}
 18%|█▊        | 800/4545 [51:19<4:03:09,  3.90s/it] 18%|█▊        | 801/4545 [51:22<4:03:23,  3.90s/it] 18%|█▊        | 802/4545 [51:26<3:56:05,  3.78s/it] 18%|█▊        | 803/4545 [51:29<3:52:13,  3.72s/it] 18%|█▊        | 804/4545 [51:34<4:00:40,  3.86s/it] 18%|█▊        | 805/4545 [51:38<4:01:34,  3.88s/it] 18%|█▊        | 806/4545 [51:41<3:51:49,  3.72s/it] 18%|█▊        | 807/4545 [51:45<3:55:22,  3.78s/it] 18%|█▊        | 808/4545 [51:49<3:57:41,  3.82s/it] 18%|█▊        | 809/4545 [51:52<3:49:38,  3.69s/it] 18%|█▊        | 810/4545 [51:56<3:53:50,  3.76s/it]                                                    {'loss': 0.4852, 'grad_norm': 22.970043182373047, 'learning_rate': 2.1373844121532363e-07, 'rewards/chosen': 1.3015625476837158, 'rewards/rejected': -0.05937499925494194, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.360937476158142, 'logps/chosen': -221.64999389648438, 'logps/rejected': -153.6999969482422, 'logits/chosen': -6.546875, 'logits/rejected': -6.506249904632568, 'epoch': 0.53}
 18%|█▊        | 810/4545 [51:56<3:53:50,  3.76s/it] 18%|█▊        | 811/4545 [52:00<3:57:27,  3.82s/it] 18%|█▊        | 812/4545 [52:04<3:59:08,  3.84s/it] 18%|█▊        | 813/4545 [52:08<3:59:44,  3.85s/it] 18%|█▊        | 814/4545 [52:11<3:50:50,  3.71s/it] 18%|█▊        | 815/4545 [52:15<3:55:07,  3.78s/it] 18%|█▊        | 816/4545 [52:19<3:57:25,  3.82s/it] 18%|█▊        | 817/4545 [52:21<3:31:14,  3.40s/it] 18%|█▊        | 818/4545 [52:25<3:42:20,  3.58s/it] 18%|█▊        | 819/4545 [52:30<3:57:50,  3.83s/it] 18%|█▊        | 820/4545 [52:34<4:00:28,  3.87s/it]                                                    {'loss': 0.4093, 'grad_norm': 54.57381057739258, 'learning_rate': 2.163804491413474e-07, 'rewards/chosen': 2.5648436546325684, 'rewards/rejected': -0.11054687201976776, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.673046827316284, 'logps/chosen': -412.1499938964844, 'logps/rejected': -198.5, 'logits/chosen': -6.290625095367432, 'logits/rejected': -6.546875, 'epoch': 0.54}
 18%|█▊        | 820/4545 [52:34<4:00:28,  3.87s/it] 18%|█▊        | 821/4545 [52:38<4:06:07,  3.97s/it] 18%|█▊        | 822/4545 [52:42<4:08:46,  4.01s/it] 18%|█▊        | 823/4545 [52:46<4:09:37,  4.02s/it] 18%|█▊        | 824/4545 [52:49<3:52:16,  3.75s/it] 18%|█▊        | 825/4545 [52:53<3:54:29,  3.78s/it] 18%|█▊        | 826/4545 [52:56<3:41:42,  3.58s/it] 18%|█▊        | 827/4545 [53:00<3:51:03,  3.73s/it] 18%|█▊        | 828/4545 [53:04<3:54:47,  3.79s/it] 18%|█▊        | 829/4545 [53:08<4:02:10,  3.91s/it] 18%|█▊        | 830/4545 [53:12<3:53:46,  3.78s/it]                                                    {'loss': 0.4063, 'grad_norm': 28.497421264648438, 'learning_rate': 2.1902245706737118e-07, 'rewards/chosen': 1.7878906726837158, 'rewards/rejected': -0.18476562201976776, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.9753906726837158, 'logps/chosen': -298.8999938964844, 'logps/rejected': -160.5500030517578, 'logits/chosen': -6.5, 'logits/rejected': -6.756249904632568, 'epoch': 0.55}
 18%|█▊        | 830/4545 [53:12<3:53:46,  3.78s/it] 18%|█▊        | 831/4545 [53:16<4:00:32,  3.89s/it] 18%|█▊        | 832/4545 [53:20<3:52:38,  3.76s/it] 18%|█▊        | 833/4545 [53:23<3:55:21,  3.80s/it] 18%|█▊        | 834/4545 [53:28<4:02:16,  3.92s/it] 18%|█▊        | 835/4545 [53:31<3:57:49,  3.85s/it] 18%|█▊        | 836/4545 [53:34<3:31:10,  3.42s/it] 18%|█▊        | 837/4545 [53:37<3:25:56,  3.33s/it] 18%|█▊        | 838/4545 [53:41<3:36:27,  3.50s/it] 18%|█▊        | 839/4545 [53:44<3:32:03,  3.43s/it] 18%|█▊        | 840/4545 [53:48<3:33:56,  3.46s/it]                                                    {'loss': 0.4591, 'grad_norm': 55.92835235595703, 'learning_rate': 2.2166446499339498e-07, 'rewards/chosen': 1.489648461341858, 'rewards/rejected': -0.23593750596046448, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.722070336341858, 'logps/chosen': -252.1999969482422, 'logps/rejected': -137.39999389648438, 'logits/chosen': -6.650000095367432, 'logits/rejected': -6.765625, 'epoch': 0.55}
 18%|█▊        | 840/4545 [53:48<3:33:56,  3.46s/it] 19%|█▊        | 841/4545 [53:51<3:42:32,  3.60s/it] 19%|█▊        | 842/4545 [53:54<3:15:14,  3.16s/it] 19%|█▊        | 843/4545 [53:58<3:30:47,  3.42s/it] 19%|█▊        | 844/4545 [54:01<3:33:14,  3.46s/it] 19%|█▊        | 845/4545 [54:05<3:41:11,  3.59s/it] 19%|█▊        | 846/4545 [54:09<3:49:38,  3.72s/it] 19%|█▊        | 847/4545 [54:12<3:40:23,  3.58s/it] 19%|█▊        | 848/4545 [54:16<3:49:44,  3.73s/it] 19%|█▊        | 849/4545 [54:20<3:55:13,  3.82s/it] 19%|█▊        | 850/4545 [54:24<3:49:10,  3.72s/it]                                                    {'loss': 0.436, 'grad_norm': 54.04332733154297, 'learning_rate': 2.2430647291941876e-07, 'rewards/chosen': 1.2951171398162842, 'rewards/rejected': -0.35712891817092896, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.6535155773162842, 'logps/chosen': -251.60000610351562, 'logps/rejected': -136.6999969482422, 'logits/chosen': -6.646874904632568, 'logits/rejected': -6.590624809265137, 'epoch': 0.56}
 19%|█▊        | 850/4545 [54:24<3:49:10,  3.72s/it] 19%|█▊        | 851/4545 [54:27<3:42:28,  3.61s/it] 19%|█▊        | 852/4545 [54:31<3:48:01,  3.70s/it] 19%|█▉        | 853/4545 [54:35<3:45:34,  3.67s/it] 19%|█▉        | 854/4545 [54:38<3:35:49,  3.51s/it] 19%|█▉        | 855/4545 [54:42<3:42:56,  3.63s/it] 19%|█▉        | 856/4545 [54:45<3:37:21,  3.54s/it] 19%|█▉        | 857/4545 [54:49<3:44:45,  3.66s/it] 19%|█▉        | 858/4545 [54:53<3:51:24,  3.77s/it] 19%|█▉        | 859/4545 [54:56<3:43:12,  3.63s/it] 19%|█▉        | 860/4545 [55:00<3:41:06,  3.60s/it]                                                    {'loss': 0.4344, 'grad_norm': 43.87296676635742, 'learning_rate': 2.2694848084544253e-07, 'rewards/chosen': 1.4921875, 'rewards/rejected': -0.40422362089157104, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.8957030773162842, 'logps/chosen': -229.25, 'logps/rejected': -111.1500015258789, 'logits/chosen': -6.737500190734863, 'logits/rejected': -6.715624809265137, 'epoch': 0.57}
 19%|█▉        | 860/4545 [55:00<3:41:06,  3.60s/it] 19%|█▉        | 861/4545 [55:04<3:46:53,  3.70s/it] 19%|█▉        | 862/4545 [55:08<3:48:35,  3.72s/it] 19%|█▉        | 863/4545 [55:12<3:55:54,  3.84s/it] 19%|█▉        | 864/4545 [55:16<3:56:57,  3.86s/it] 19%|█▉        | 865/4545 [55:19<3:47:29,  3.71s/it] 19%|█▉        | 866/4545 [55:23<3:49:35,  3.74s/it] 19%|█▉        | 867/4545 [55:27<3:51:11,  3.77s/it] 19%|█▉        | 868/4545 [55:31<3:56:54,  3.87s/it] 19%|█▉        | 869/4545 [55:34<3:43:42,  3.65s/it] 19%|█▉        | 870/4545 [55:38<3:48:05,  3.72s/it]                                                    {'loss': 0.3609, 'grad_norm': 25.550762176513672, 'learning_rate': 2.295904887714663e-07, 'rewards/chosen': 1.4755859375, 'rewards/rejected': -0.4739746153354645, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9500000476837158, 'logps/chosen': -247.8000030517578, 'logps/rejected': -119.55000305175781, 'logits/chosen': -6.75, 'logits/rejected': -6.956250190734863, 'epoch': 0.57}
 19%|█▉        | 870/4545 [55:38<3:48:05,  3.72s/it] 19%|█▉        | 871/4545 [55:41<3:45:04,  3.68s/it] 19%|█▉        | 872/4545 [55:45<3:36:21,  3.53s/it] 19%|█▉        | 873/4545 [55:48<3:29:12,  3.42s/it] 19%|█▉        | 874/4545 [55:52<3:39:58,  3.60s/it] 19%|█▉        | 875/4545 [55:55<3:24:08,  3.34s/it] 19%|█▉        | 876/4545 [55:58<3:35:08,  3.52s/it] 19%|█▉        | 877/4545 [56:02<3:42:32,  3.64s/it] 19%|█▉        | 878/4545 [56:06<3:42:30,  3.64s/it] 19%|█▉        | 879/4545 [56:10<3:47:53,  3.73s/it] 19%|█▉        | 880/4545 [56:14<3:46:12,  3.70s/it]                                                    {'loss': 0.4472, 'grad_norm': 25.633495330810547, 'learning_rate': 2.322324966974901e-07, 'rewards/chosen': 1.771875023841858, 'rewards/rejected': -0.2762207090854645, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.0492186546325684, 'logps/chosen': -297.70001220703125, 'logps/rejected': -149.625, 'logits/chosen': -6.59375, 'logits/rejected': -6.809374809265137, 'epoch': 0.58}
 19%|█▉        | 880/4545 [56:14<3:46:12,  3.70s/it] 19%|█▉        | 881/4545 [56:18<3:55:00,  3.85s/it] 19%|█▉        | 882/4545 [56:22<3:56:03,  3.87s/it] 19%|█▉        | 883/4545 [56:26<3:56:01,  3.87s/it] 19%|█▉        | 884/4545 [56:29<3:48:42,  3.75s/it] 19%|█▉        | 885/4545 [56:32<3:37:12,  3.56s/it] 19%|█▉        | 886/4545 [56:36<3:42:11,  3.64s/it] 20%|█▉        | 887/4545 [56:40<3:44:19,  3.68s/it] 20%|█▉        | 888/4545 [56:43<3:31:26,  3.47s/it] 20%|█▉        | 889/4545 [56:47<3:39:49,  3.61s/it] 20%|█▉        | 890/4545 [56:51<3:50:43,  3.79s/it]                                                    {'loss': 0.3582, 'grad_norm': 53.02347946166992, 'learning_rate': 2.348745046235139e-07, 'rewards/chosen': 1.516210913658142, 'rewards/rejected': -0.563427746295929, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.077343702316284, 'logps/chosen': -243.0, 'logps/rejected': -121.69999694824219, 'logits/chosen': -6.71875, 'logits/rejected': -6.671875, 'epoch': 0.59}
 20%|█▉        | 890/4545 [56:51<3:50:43,  3.79s/it] 20%|█▉        | 891/4545 [56:55<3:53:44,  3.84s/it] 20%|█▉        | 892/4545 [56:59<3:55:00,  3.86s/it] 20%|█▉        | 893/4545 [57:02<3:47:54,  3.74s/it] 20%|█▉        | 894/4545 [57:06<3:41:54,  3.65s/it] 20%|█▉        | 895/4545 [57:10<3:46:33,  3.72s/it] 20%|█▉        | 896/4545 [57:13<3:49:00,  3.77s/it] 20%|█▉        | 897/4545 [57:17<3:51:37,  3.81s/it] 20%|█▉        | 898/4545 [57:21<3:56:31,  3.89s/it] 20%|█▉        | 899/4545 [57:25<3:55:50,  3.88s/it] 20%|█▉        | 900/4545 [57:29<3:56:27,  3.89s/it]                                                    {'loss': 0.3968, 'grad_norm': 113.14895629882812, 'learning_rate': 2.375165125495376e-07, 'rewards/chosen': 2.6480469703674316, 'rewards/rejected': -0.04022216796875, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.684375047683716, 'logps/chosen': -465.54998779296875, 'logps/rejected': -251.75, 'logits/chosen': -6.471875190734863, 'logits/rejected': -6.634375095367432, 'epoch': 0.59}
 20%|█▉        | 900/4545 [57:29<3:56:27,  3.89s/it] 20%|█▉        | 901/4545 [57:33<3:47:36,  3.75s/it] 20%|█▉        | 902/4545 [57:36<3:49:56,  3.79s/it] 20%|█▉        | 903/4545 [57:40<3:48:57,  3.77s/it] 20%|█▉        | 904/4545 [57:43<3:37:46,  3.59s/it] 20%|█▉        | 905/4545 [57:47<3:42:45,  3.67s/it] 20%|█▉        | 906/4545 [57:51<3:47:14,  3.75s/it] 20%|█▉        | 907/4545 [57:55<3:55:25,  3.88s/it] 20%|█▉        | 908/4545 [57:59<3:55:34,  3.89s/it] 20%|██        | 909/4545 [58:03<3:56:04,  3.90s/it] 20%|██        | 910/4545 [58:06<3:45:30,  3.72s/it]                                                    {'loss': 0.467, 'grad_norm': 55.31561279296875, 'learning_rate': 2.401585204755614e-07, 'rewards/chosen': 1.4259765148162842, 'rewards/rejected': -0.12158203125, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.5457031726837158, 'logps/chosen': -245.89999389648438, 'logps/rejected': -157.1999969482422, 'logits/chosen': -6.603125095367432, 'logits/rejected': -6.859375, 'epoch': 0.6}
 20%|██        | 910/4545 [58:07<3:45:30,  3.72s/it] 20%|██        | 911/4545 [58:11<3:51:58,  3.83s/it] 20%|██        | 912/4545 [58:15<3:55:11,  3.88s/it] 20%|██        | 913/4545 [58:18<3:55:48,  3.90s/it] 20%|██        | 914/4545 [58:22<3:55:54,  3.90s/it] 20%|██        | 915/4545 [58:26<3:46:50,  3.75s/it] 20%|██        | 916/4545 [58:30<3:49:50,  3.80s/it] 20%|██        | 917/4545 [58:34<3:51:03,  3.82s/it] 20%|██        | 918/4545 [58:36<3:17:26,  3.27s/it] 20%|██        | 919/4545 [58:39<3:24:10,  3.38s/it] 20%|██        | 920/4545 [58:43<3:35:51,  3.57s/it]                                                    {'loss': 0.4001, 'grad_norm': 37.221710205078125, 'learning_rate': 2.428005284015852e-07, 'rewards/chosen': 2.4892578125, 'rewards/rejected': -0.24130859971046448, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.7347655296325684, 'logps/chosen': -406.1000061035156, 'logps/rejected': -186.0, 'logits/chosen': -6.537499904632568, 'logits/rejected': -6.684374809265137, 'epoch': 0.61}
 20%|██        | 920/4545 [58:43<3:35:51,  3.57s/it] 20%|██        | 921/4545 [58:47<3:31:01,  3.49s/it] 20%|██        | 922/4545 [58:49<3:20:55,  3.33s/it] 20%|██        | 923/4545 [58:53<3:31:02,  3.50s/it] 20%|██        | 924/4545 [58:57<3:38:57,  3.63s/it] 20%|██        | 925/4545 [59:01<3:47:37,  3.77s/it] 20%|██        | 926/4545 [59:06<3:55:48,  3.91s/it] 20%|██        | 927/4545 [59:09<3:42:47,  3.69s/it] 20%|██        | 928/4545 [59:13<3:47:26,  3.77s/it] 20%|██        | 929/4545 [59:16<3:44:01,  3.72s/it] 20%|██        | 930/4545 [59:20<3:50:15,  3.82s/it]                                                    {'loss': 0.3715, 'grad_norm': 75.196533203125, 'learning_rate': 2.4544253632760894e-07, 'rewards/chosen': 1.4572265148162842, 'rewards/rejected': -0.6737304925918579, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.130078077316284, 'logps/chosen': -255.39999389648438, 'logps/rejected': -136.52499389648438, 'logits/chosen': -6.778124809265137, 'logits/rejected': -6.993750095367432, 'epoch': 0.61}
 20%|██        | 930/4545 [59:21<3:50:15,  3.82s/it] 20%|██        | 931/4545 [59:25<3:57:25,  3.94s/it] 21%|██        | 932/4545 [59:28<3:48:36,  3.80s/it] 21%|██        | 933/4545 [59:31<3:36:09,  3.59s/it] 21%|██        | 934/4545 [59:35<3:30:24,  3.50s/it] 21%|██        | 935/4545 [59:39<3:41:49,  3.69s/it] 21%|██        | 936/4545 [59:41<3:16:47,  3.27s/it] 21%|██        | 937/4545 [59:45<3:29:16,  3.48s/it] 21%|██        | 938/4545 [59:49<3:36:45,  3.61s/it] 21%|██        | 939/4545 [59:53<3:40:14,  3.66s/it] 21%|██        | 940/4545 [59:57<3:49:49,  3.83s/it]                                                    {'loss': 0.3867, 'grad_norm': 36.85692596435547, 'learning_rate': 2.4808454425363274e-07, 'rewards/chosen': 1.2275390625, 'rewards/rejected': -0.509570300579071, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.734375, 'logps/chosen': -201.85000610351562, 'logps/rejected': -114.7249984741211, 'logits/chosen': -6.978125095367432, 'logits/rejected': -7.034375190734863, 'epoch': 0.62}
 21%|██        | 940/4545 [59:57<3:49:49,  3.83s/it] 21%|██        | 941/4545 [1:00:01<3:58:05,  3.96s/it] 21%|██        | 942/4545 [1:00:05<3:57:17,  3.95s/it] 21%|██        | 943/4545 [1:00:09<3:52:49,  3.88s/it] 21%|██        | 944/4545 [1:00:11<3:25:06,  3.42s/it] 21%|██        | 945/4545 [1:00:14<3:24:52,  3.41s/it] 21%|██        | 946/4545 [1:00:18<3:27:57,  3.47s/it] 21%|██        | 947/4545 [1:00:22<3:36:15,  3.61s/it] 21%|██        | 948/4545 [1:00:25<3:30:20,  3.51s/it] 21%|██        | 949/4545 [1:00:29<3:37:38,  3.63s/it] 21%|██        | 950/4545 [1:00:33<3:42:36,  3.72s/it]                                                      {'loss': 0.4055, 'grad_norm': 28.533416748046875, 'learning_rate': 2.5072655217965654e-07, 'rewards/chosen': 1.414648413658142, 'rewards/rejected': -0.577343761920929, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.992578148841858, 'logps/chosen': -215.6750030517578, 'logps/rejected': -133.4499969482422, 'logits/chosen': -6.815625190734863, 'logits/rejected': -6.771874904632568, 'epoch': 0.63}
 21%|██        | 950/4545 [1:00:33<3:42:36,  3.72s/it] 21%|██        | 951/4545 [1:00:36<3:20:33,  3.35s/it] 21%|██        | 952/4545 [1:00:39<3:15:34,  3.27s/it] 21%|██        | 953/4545 [1:00:43<3:26:38,  3.45s/it] 21%|██        | 954/4545 [1:00:47<3:36:54,  3.62s/it] 21%|██        | 955/4545 [1:00:50<3:41:26,  3.70s/it] 21%|██        | 956/4545 [1:00:54<3:45:18,  3.77s/it] 21%|██        | 957/4545 [1:00:58<3:47:32,  3.81s/it] 21%|██        | 958/4545 [1:01:02<3:49:21,  3.84s/it] 21%|██        | 959/4545 [1:01:06<3:50:35,  3.86s/it] 21%|██        | 960/4545 [1:01:10<3:45:47,  3.78s/it]                                                      {'loss': 0.3212, 'grad_norm': 65.3248519897461, 'learning_rate': 2.533685601056803e-07, 'rewards/chosen': 2.8013672828674316, 'rewards/rejected': -0.3166747987270355, 'rewards/accuracies': 0.875, 'rewards/margins': 3.116406202316284, 'logps/chosen': -448.8999938964844, 'logps/rejected': -218.5, 'logits/chosen': -6.584374904632568, 'logits/rejected': -6.834374904632568, 'epoch': 0.63}
 21%|██        | 960/4545 [1:01:10<3:45:47,  3.78s/it] 21%|██        | 961/4545 [1:01:13<3:44:56,  3.77s/it] 21%|██        | 962/4545 [1:01:18<3:52:22,  3.89s/it] 21%|██        | 963/4545 [1:01:21<3:47:15,  3.81s/it] 21%|██        | 964/4545 [1:01:25<3:49:10,  3.84s/it] 21%|██        | 965/4545 [1:01:29<3:50:50,  3.87s/it] 21%|██▏       | 966/4545 [1:01:33<3:50:35,  3.87s/it] 21%|██▏       | 967/4545 [1:01:37<3:50:24,  3.86s/it] 21%|██▏       | 968/4545 [1:01:41<3:50:58,  3.87s/it] 21%|██▏       | 969/4545 [1:01:45<3:51:09,  3.88s/it] 21%|██▏       | 970/4545 [1:01:48<3:42:01,  3.73s/it]                                                      {'loss': 0.368, 'grad_norm': 40.75324249267578, 'learning_rate': 2.560105680317041e-07, 'rewards/chosen': 2.1566405296325684, 'rewards/rejected': -0.4498657286167145, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.60546875, 'logps/chosen': -371.5, 'logps/rejected': -170.5500030517578, 'logits/chosen': -6.684374809265137, 'logits/rejected': -6.915625095367432, 'epoch': 0.64}
 21%|██▏       | 970/4545 [1:01:48<3:42:01,  3.73s/it] 21%|██▏       | 971/4545 [1:01:51<3:29:59,  3.53s/it] 21%|██▏       | 972/4545 [1:01:55<3:41:34,  3.72s/it] 21%|██▏       | 973/4545 [1:01:59<3:45:20,  3.79s/it] 21%|██▏       | 974/4545 [1:02:03<3:47:13,  3.82s/it] 21%|██▏       | 975/4545 [1:02:07<3:48:36,  3.84s/it] 21%|██▏       | 976/4545 [1:02:11<3:54:58,  3.95s/it] 21%|██▏       | 977/4545 [1:02:15<3:52:52,  3.92s/it] 22%|██▏       | 978/4545 [1:02:18<3:30:06,  3.53s/it] 22%|██▏       | 979/4545 [1:02:22<3:38:08,  3.67s/it] 22%|██▏       | 980/4545 [1:02:26<3:46:10,  3.81s/it]                                                      {'loss': 0.349, 'grad_norm': 25.823339462280273, 'learning_rate': 2.5865257595772785e-07, 'rewards/chosen': 2.3804688453674316, 'rewards/rejected': -0.46098631620407104, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.83984375, 'logps/chosen': -369.5, 'logps/rejected': -198.35000610351562, 'logits/chosen': -6.818749904632568, 'logits/rejected': -6.868750095367432, 'epoch': 0.65}
 22%|██▏       | 980/4545 [1:02:26<3:46:10,  3.81s/it] 22%|██▏       | 981/4545 [1:02:30<3:48:17,  3.84s/it] 22%|██▏       | 982/4545 [1:02:34<3:54:36,  3.95s/it] 22%|██▏       | 983/4545 [1:02:36<3:25:18,  3.46s/it] 22%|██▏       | 984/4545 [1:02:40<3:32:13,  3.58s/it] 22%|██▏       | 985/4545 [1:02:43<3:20:32,  3.38s/it] 22%|██▏       | 986/4545 [1:02:46<3:07:19,  3.16s/it] 22%|██▏       | 987/4545 [1:02:49<3:10:46,  3.22s/it] 22%|██▏       | 988/4545 [1:02:53<3:23:54,  3.44s/it] 22%|██▏       | 989/4545 [1:02:56<3:11:10,  3.23s/it] 22%|██▏       | 990/4545 [1:03:00<3:23:28,  3.43s/it]                                                      {'loss': 0.3491, 'grad_norm': 42.150962829589844, 'learning_rate': 2.6129458388375165e-07, 'rewards/chosen': 0.8500000238418579, 'rewards/rejected': -0.950488269329071, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 1.8039062023162842, 'logps/chosen': -141.8249969482422, 'logps/rejected': -85.2249984741211, 'logits/chosen': -6.934374809265137, 'logits/rejected': -6.681250095367432, 'epoch': 0.65}
 22%|██▏       | 990/4545 [1:03:00<3:23:28,  3.43s/it] 22%|██▏       | 991/4545 [1:03:04<3:35:57,  3.65s/it] 22%|██▏       | 992/4545 [1:03:06<3:20:52,  3.39s/it] 22%|██▏       | 993/4545 [1:03:10<3:25:36,  3.47s/it] 22%|██▏       | 994/4545 [1:03:14<3:33:38,  3.61s/it] 22%|██▏       | 995/4545 [1:03:17<3:27:18,  3.50s/it] 22%|██▏       | 996/4545 [1:03:20<3:04:37,  3.12s/it] 22%|██▏       | 997/4545 [1:03:24<3:26:05,  3.49s/it] 22%|██▏       | 998/4545 [1:03:28<3:36:02,  3.65s/it] 22%|██▏       | 999/4545 [1:03:32<3:43:50,  3.79s/it] 22%|██▏       | 1000/4545 [1:03:36<3:41:52,  3.76s/it]                                                       {'loss': 0.3883, 'grad_norm': 53.74627685546875, 'learning_rate': 2.6393659180977545e-07, 'rewards/chosen': 0.94183349609375, 'rewards/rejected': -0.907421886920929, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 1.8507812023162842, 'logps/chosen': -155.72500610351562, 'logps/rejected': -95.05000305175781, 'logits/chosen': -6.984375, 'logits/rejected': -6.909375190734863, 'epoch': 0.66}
 22%|██▏       | 1000/4545 [1:03:36<3:41:52,  3.76s/it] 22%|██▏       | 1001/4545 [1:03:40<3:42:43,  3.77s/it] 22%|██▏       | 1002/4545 [1:03:44<3:48:11,  3.86s/it] 22%|██▏       | 1003/4545 [1:03:47<3:47:24,  3.85s/it] 22%|██▏       | 1004/4545 [1:03:51<3:43:18,  3.78s/it] 22%|██▏       | 1005/4545 [1:03:54<3:24:56,  3.47s/it] 22%|██▏       | 1006/4545 [1:03:58<3:38:47,  3.71s/it] 22%|██▏       | 1007/4545 [1:04:01<3:33:21,  3.62s/it] 22%|██▏       | 1008/4545 [1:04:05<3:35:56,  3.66s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:43,  1.33it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.40s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.53s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:19,  1.66s/it][A
 22%|██▏       | 13/60 [00:19<01:17,  1.64s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.64s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.53s/it][A
 27%|██▋       | 16/60 [00:23<01:01,  1.39s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:39,  1.09s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.25s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.08s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.38s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.38s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A                                                       
                                               [A{'eval_loss': 0.4178331792354584, 'eval_runtime': 80.6297, 'eval_samples_per_second': 11.819, 'eval_steps_per_second': 0.744, 'eval_rewards/chosen': 2.093869924545288, 'eval_rewards/rejected': -0.11596158146858215, 'eval_rewards/accuracies': 0.7993055582046509, 'eval_rewards/margins': 2.208280324935913, 'eval_logps/chosen': -367.0083312988281, 'eval_logps/rejected': -152.71041870117188, 'eval_logits/chosen': -6.527083396911621, 'eval_logits/rejected': -7.234895706176758, 'epoch': 0.67}
 22%|██▏       | 1008/4545 [1:05:26<3:35:56,  3.66s/it]
100%|██████████| 60/60 [01:19<00:00,  1.49s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 22%|██▏       | 1009/4545 [1:05:42<30:54:45, 31.47s/it] 22%|██▏       | 1010/4545 [1:05:45<22:47:12, 23.21s/it]                                                        {'loss': 0.3485, 'grad_norm': 41.51900100708008, 'learning_rate': 2.665785997357992e-07, 'rewards/chosen': 1.0341796875, 'rewards/rejected': -1.0710937976837158, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.1039061546325684, 'logps/chosen': -182.60000610351562, 'logps/rejected': -109.1500015258789, 'logits/chosen': -6.90625, 'logits/rejected': -6.96875, 'epoch': 0.67}
 22%|██▏       | 1010/4545 [1:05:46<22:47:12, 23.21s/it] 22%|██▏       | 1011/4545 [1:05:49<17:06:07, 17.42s/it] 22%|██▏       | 1012/4545 [1:05:53<13:07:15, 13.37s/it] 22%|██▏       | 1013/4545 [1:05:57<10:19:56, 10.53s/it] 22%|██▏       | 1014/4545 [1:06:01<8:22:08,  8.53s/it]  22%|██▏       | 1015/4545 [1:06:05<7:00:17,  7.14s/it] 22%|██▏       | 1016/4545 [1:06:09<6:03:19,  6.18s/it] 22%|██▏       | 1017/4545 [1:06:13<5:22:18,  5.48s/it] 22%|██▏       | 1018/4545 [1:06:15<4:27:11,  4.55s/it] 22%|██▏       | 1019/4545 [1:06:19<4:18:43,  4.40s/it] 22%|██▏       | 1020/4545 [1:06:22<3:57:21,  4.04s/it]                                                       {'loss': 0.3967, 'grad_norm': 60.733734130859375, 'learning_rate': 2.6922060766182295e-07, 'rewards/chosen': 2.029980421066284, 'rewards/rejected': -0.4931640625, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.524218797683716, 'logps/chosen': -305.25, 'logps/rejected': -184.22500610351562, 'logits/chosen': -6.918749809265137, 'logits/rejected': -6.900000095367432, 'epoch': 0.67}
 22%|██▏       | 1020/4545 [1:06:23<3:57:21,  4.04s/it] 22%|██▏       | 1021/4545 [1:06:24<3:22:15,  3.44s/it] 22%|██▏       | 1022/4545 [1:06:27<3:11:49,  3.27s/it] 23%|██▎       | 1023/4545 [1:06:31<3:16:35,  3.35s/it] 23%|██▎       | 1024/4545 [1:06:35<3:29:23,  3.57s/it] 23%|██▎       | 1025/4545 [1:06:39<3:35:33,  3.67s/it] 23%|██▎       | 1026/4545 [1:06:43<3:39:12,  3.74s/it] 23%|██▎       | 1027/4545 [1:06:46<3:35:45,  3.68s/it] 23%|██▎       | 1028/4545 [1:06:50<3:35:29,  3.68s/it] 23%|██▎       | 1029/4545 [1:06:54<3:42:46,  3.80s/it] 23%|██▎       | 1030/4545 [1:06:58<3:44:52,  3.84s/it]                                                       {'loss': 0.3807, 'grad_norm': 45.77372360229492, 'learning_rate': 2.7186261558784675e-07, 'rewards/chosen': 1.178125023841858, 'rewards/rejected': -0.8973144292831421, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.077343702316284, 'logps/chosen': -200.75, 'logps/rejected': -129.4250030517578, 'logits/chosen': -7.131249904632568, 'logits/rejected': -6.990624904632568, 'epoch': 0.68}
 23%|██▎       | 1030/4545 [1:06:58<3:44:52,  3.84s/it] 23%|██▎       | 1031/4545 [1:07:01<3:35:40,  3.68s/it] 23%|██▎       | 1032/4545 [1:07:05<3:34:41,  3.67s/it] 23%|██▎       | 1033/4545 [1:07:09<3:38:53,  3.74s/it] 23%|██▎       | 1034/4545 [1:07:12<3:24:43,  3.50s/it] 23%|██▎       | 1035/4545 [1:07:16<3:34:49,  3.67s/it] 23%|██▎       | 1036/4545 [1:07:19<3:29:29,  3.58s/it] 23%|██▎       | 1037/4545 [1:07:23<3:25:28,  3.51s/it] 23%|██▎       | 1038/4545 [1:07:25<3:11:50,  3.28s/it] 23%|██▎       | 1039/4545 [1:07:29<3:24:32,  3.50s/it] 23%|██▎       | 1040/4545 [1:07:33<3:19:22,  3.41s/it]                                                       {'loss': 0.3067, 'grad_norm': 43.21998596191406, 'learning_rate': 2.745046235138705e-07, 'rewards/chosen': 1.3102538585662842, 'rewards/rejected': -1.0724608898162842, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.3843750953674316, 'logps/chosen': -181.0, 'logps/rejected': -114.67500305175781, 'logits/chosen': -7.009375095367432, 'logits/rejected': -6.840624809265137, 'epoch': 0.69}
 23%|██▎       | 1040/4545 [1:07:33<3:19:22,  3.41s/it] 23%|██▎       | 1041/4545 [1:07:36<3:28:49,  3.58s/it] 23%|██▎       | 1042/4545 [1:07:40<3:31:12,  3.62s/it] 23%|██▎       | 1043/4545 [1:07:44<3:25:52,  3.53s/it] 23%|██▎       | 1044/4545 [1:07:47<3:31:15,  3.62s/it] 23%|██▎       | 1045/4545 [1:07:51<3:36:54,  3.72s/it] 23%|██▎       | 1046/4545 [1:07:55<3:39:53,  3.77s/it] 23%|██▎       | 1047/4545 [1:07:59<3:42:16,  3.81s/it] 23%|██▎       | 1048/4545 [1:08:03<3:45:58,  3.88s/it] 23%|██▎       | 1049/4545 [1:08:07<3:37:36,  3.73s/it] 23%|██▎       | 1050/4545 [1:08:10<3:40:19,  3.78s/it]                                                       {'loss': 0.2805, 'grad_norm': 18.256797790527344, 'learning_rate': 2.771466314398943e-07, 'rewards/chosen': 2.3544921875, 'rewards/rejected': -0.8335937261581421, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.184375047683716, 'logps/chosen': -343.25, 'logps/rejected': -171.0749969482422, 'logits/chosen': -6.78125, 'logits/rejected': -6.890625, 'epoch': 0.69}
 23%|██▎       | 1050/4545 [1:08:11<3:40:19,  3.78s/it] 23%|██▎       | 1051/4545 [1:08:14<3:44:18,  3.85s/it] 23%|██▎       | 1052/4545 [1:08:18<3:44:27,  3.86s/it] 23%|██▎       | 1053/4545 [1:08:22<3:39:31,  3.77s/it] 23%|██▎       | 1054/4545 [1:08:25<3:32:25,  3.65s/it] 23%|██▎       | 1055/4545 [1:08:29<3:32:33,  3.65s/it] 23%|██▎       | 1056/4545 [1:08:33<3:34:52,  3.70s/it] 23%|██▎       | 1057/4545 [1:08:37<3:38:17,  3.76s/it] 23%|██▎       | 1058/4545 [1:08:40<3:24:50,  3.52s/it] 23%|██▎       | 1059/4545 [1:08:44<3:31:39,  3.64s/it] 23%|██▎       | 1060/4545 [1:08:48<3:37:32,  3.75s/it]                                                       {'loss': 0.3892, 'grad_norm': 49.61104965209961, 'learning_rate': 2.7978863936591805e-07, 'rewards/chosen': 1.7849609851837158, 'rewards/rejected': -0.6763671636581421, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.4625000953674316, 'logps/chosen': -285.1000061035156, 'logps/rejected': -168.35000610351562, 'logits/chosen': -6.974999904632568, 'logits/rejected': -6.787499904632568, 'epoch': 0.7}
 23%|██▎       | 1060/4545 [1:08:48<3:37:32,  3.75s/it] 23%|██▎       | 1061/4545 [1:08:51<3:40:39,  3.80s/it] 23%|██▎       | 1062/4545 [1:08:56<3:47:13,  3.91s/it] 23%|██▎       | 1063/4545 [1:08:59<3:38:45,  3.77s/it] 23%|██▎       | 1064/4545 [1:09:03<3:41:10,  3.81s/it] 23%|██▎       | 1065/4545 [1:09:07<3:46:01,  3.90s/it] 23%|██▎       | 1066/4545 [1:09:11<3:50:25,  3.97s/it] 23%|██▎       | 1067/4545 [1:09:14<3:36:01,  3.73s/it] 23%|██▎       | 1068/4545 [1:09:18<3:34:58,  3.71s/it] 24%|██▎       | 1069/4545 [1:09:22<3:32:38,  3.67s/it] 24%|██▎       | 1070/4545 [1:09:25<3:27:16,  3.58s/it]                                                       {'loss': 0.3412, 'grad_norm': 25.854333877563477, 'learning_rate': 2.8243064729194186e-07, 'rewards/chosen': 1.1461913585662842, 'rewards/rejected': -1.0642578601837158, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.214062452316284, 'logps/chosen': -189.35000610351562, 'logps/rejected': -103.5250015258789, 'logits/chosen': -6.881249904632568, 'logits/rejected': -6.990624904632568, 'epoch': 0.71}
 24%|██▎       | 1070/4545 [1:09:25<3:27:16,  3.58s/it] 24%|██▎       | 1071/4545 [1:09:29<3:32:59,  3.68s/it] 24%|██▎       | 1072/4545 [1:09:33<3:37:43,  3.76s/it] 24%|██▎       | 1073/4545 [1:09:37<3:40:14,  3.81s/it] 24%|██▎       | 1074/4545 [1:09:41<3:42:09,  3.84s/it] 24%|██▎       | 1075/4545 [1:09:45<3:45:28,  3.90s/it] 24%|██▎       | 1076/4545 [1:09:48<3:28:46,  3.61s/it] 24%|██▎       | 1077/4545 [1:09:52<3:34:09,  3.71s/it] 24%|██▎       | 1078/4545 [1:09:55<3:37:47,  3.77s/it] 24%|██▎       | 1079/4545 [1:09:59<3:40:17,  3.81s/it] 24%|██▍       | 1080/4545 [1:10:03<3:41:52,  3.84s/it]                                                       {'loss': 0.4101, 'grad_norm': 46.95330810546875, 'learning_rate': 2.8507265521796566e-07, 'rewards/chosen': 2.93359375, 'rewards/rejected': -0.149444580078125, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 3.08203125, 'logps/chosen': -452.125, 'logps/rejected': -220.64999389648438, 'logits/chosen': -6.453125, 'logits/rejected': -6.484375, 'epoch': 0.71}
 24%|██▍       | 1080/4545 [1:10:04<3:41:52,  3.84s/it] 24%|██▍       | 1081/4545 [1:10:07<3:44:19,  3.89s/it] 24%|██▍       | 1082/4545 [1:10:11<3:44:52,  3.90s/it] 24%|██▍       | 1083/4545 [1:10:14<3:31:23,  3.66s/it] 24%|██▍       | 1084/4545 [1:10:18<3:38:32,  3.79s/it] 24%|██▍       | 1085/4545 [1:10:22<3:34:56,  3.73s/it] 24%|██▍       | 1086/4545 [1:10:25<3:17:05,  3.42s/it] 24%|██▍       | 1087/4545 [1:10:28<3:08:57,  3.28s/it] 24%|██▍       | 1088/4545 [1:10:32<3:21:42,  3.50s/it] 24%|██▍       | 1089/4545 [1:10:35<3:27:17,  3.60s/it] 24%|██▍       | 1090/4545 [1:10:40<3:36:03,  3.75s/it]                                                       {'loss': 0.3104, 'grad_norm': 53.26528549194336, 'learning_rate': 2.877146631439894e-07, 'rewards/chosen': 1.600000023841858, 'rewards/rejected': -1.1980469226837158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.7953124046325684, 'logps/chosen': -243.5, 'logps/rejected': -118.9000015258789, 'logits/chosen': -6.996874809265137, 'logits/rejected': -6.928124904632568, 'epoch': 0.72}
 24%|██▍       | 1090/4545 [1:10:40<3:36:03,  3.75s/it] 24%|██▍       | 1091/4545 [1:10:43<3:31:59,  3.68s/it] 24%|██▍       | 1092/4545 [1:10:45<3:04:24,  3.20s/it] 24%|██▍       | 1093/4545 [1:10:49<3:16:19,  3.41s/it] 24%|██▍       | 1094/4545 [1:10:53<3:18:17,  3.45s/it] 24%|██▍       | 1095/4545 [1:10:56<3:25:13,  3.57s/it] 24%|██▍       | 1096/4545 [1:10:59<3:14:31,  3.38s/it] 24%|██▍       | 1097/4545 [1:11:04<3:26:54,  3.60s/it] 24%|██▍       | 1098/4545 [1:11:08<3:35:04,  3.74s/it] 24%|██▍       | 1099/4545 [1:11:12<3:37:19,  3.78s/it] 24%|██▍       | 1100/4545 [1:11:16<3:42:47,  3.88s/it]                                                       {'loss': 0.3674, 'grad_norm': 26.165048599243164, 'learning_rate': 2.903566710700132e-07, 'rewards/chosen': 1.5742714405059814, 'rewards/rejected': -0.9791625738143921, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.5589842796325684, 'logps/chosen': -253.27499389648438, 'logps/rejected': -132.4375, 'logits/chosen': -7.040625095367432, 'logits/rejected': -7.109375, 'epoch': 0.73}
 24%|██▍       | 1100/4545 [1:11:16<3:42:47,  3.88s/it] 24%|██▍       | 1101/4545 [1:11:20<3:44:32,  3.91s/it] 24%|██▍       | 1102/4545 [1:11:24<3:44:25,  3.91s/it] 24%|██▍       | 1103/4545 [1:11:27<3:34:06,  3.73s/it] 24%|██▍       | 1104/4545 [1:11:31<3:39:02,  3.82s/it] 24%|██▍       | 1105/4545 [1:11:35<3:43:53,  3.91s/it] 24%|██▍       | 1106/4545 [1:11:39<3:43:52,  3.91s/it] 24%|██▍       | 1107/4545 [1:11:43<3:49:30,  4.01s/it] 24%|██▍       | 1108/4545 [1:11:46<3:24:14,  3.57s/it] 24%|██▍       | 1109/4545 [1:11:50<3:29:29,  3.66s/it] 24%|██▍       | 1110/4545 [1:11:53<3:20:50,  3.51s/it]                                                       {'loss': 0.3528, 'grad_norm': 25.1993350982666, 'learning_rate': 2.9299867899603696e-07, 'rewards/chosen': 2.022265672683716, 'rewards/rejected': -0.683642566204071, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.706249952316284, 'logps/chosen': -302.70001220703125, 'logps/rejected': -169.1999969482422, 'logits/chosen': -6.856249809265137, 'logits/rejected': -6.962500095367432, 'epoch': 0.73}
 24%|██▍       | 1110/4545 [1:11:53<3:20:50,  3.51s/it] 24%|██▍       | 1111/4545 [1:11:55<3:05:32,  3.24s/it] 24%|██▍       | 1112/4545 [1:11:59<3:17:04,  3.44s/it] 24%|██▍       | 1113/4545 [1:12:03<3:21:23,  3.52s/it] 25%|██▍       | 1114/4545 [1:12:07<3:27:53,  3.64s/it] 25%|██▍       | 1115/4545 [1:12:11<3:37:36,  3.81s/it] 25%|██▍       | 1116/4545 [1:12:14<3:28:07,  3.64s/it] 25%|██▍       | 1117/4545 [1:12:16<3:03:39,  3.21s/it] 25%|██▍       | 1118/4545 [1:12:21<3:20:40,  3.51s/it] 25%|██▍       | 1119/4545 [1:12:25<3:26:00,  3.61s/it] 25%|██▍       | 1120/4545 [1:12:28<3:28:50,  3.66s/it]                                                       {'loss': 0.277, 'grad_norm': 49.16072082519531, 'learning_rate': 2.9564068692206076e-07, 'rewards/chosen': 1.9001953601837158, 'rewards/rejected': -1.075781226158142, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 2.973437547683716, 'logps/chosen': -259.3999938964844, 'logps/rejected': -139.97500610351562, 'logits/chosen': -7.084374904632568, 'logits/rejected': -7.078125, 'epoch': 0.74}
 25%|██▍       | 1120/4545 [1:12:28<3:28:50,  3.66s/it] 25%|██▍       | 1121/4545 [1:12:33<3:38:01,  3.82s/it] 25%|██▍       | 1122/4545 [1:12:37<3:41:43,  3.89s/it] 25%|██▍       | 1123/4545 [1:12:40<3:40:35,  3.87s/it] 25%|██▍       | 1124/4545 [1:12:44<3:41:32,  3.89s/it] 25%|██▍       | 1125/4545 [1:12:48<3:31:56,  3.72s/it] 25%|██▍       | 1126/4545 [1:12:52<3:35:32,  3.78s/it] 25%|██▍       | 1127/4545 [1:12:55<3:30:20,  3.69s/it] 25%|██▍       | 1128/4545 [1:12:58<3:20:29,  3.52s/it] 25%|██▍       | 1129/4545 [1:13:02<3:29:50,  3.69s/it] 25%|██▍       | 1130/4545 [1:13:04<2:59:54,  3.16s/it]                                                       {'loss': 0.2824, 'grad_norm': 27.874361038208008, 'learning_rate': 2.9828269484808457e-07, 'rewards/chosen': 1.561914086341858, 'rewards/rejected': -1.139257788658142, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.702343702316284, 'logps/chosen': -209.89999389648438, 'logps/rejected': -112.0250015258789, 'logits/chosen': -7.056250095367432, 'logits/rejected': -6.887499809265137, 'epoch': 0.75}
 25%|██▍       | 1130/4545 [1:13:04<2:59:54,  3.16s/it] 25%|██▍       | 1131/4545 [1:13:08<3:08:02,  3.30s/it] 25%|██▍       | 1132/4545 [1:13:11<3:01:13,  3.19s/it] 25%|██▍       | 1133/4545 [1:13:15<3:11:55,  3.38s/it] 25%|██▍       | 1134/4545 [1:13:18<3:09:26,  3.33s/it] 25%|██▍       | 1135/4545 [1:13:22<3:19:12,  3.51s/it] 25%|██▍       | 1136/4545 [1:13:25<3:15:16,  3.44s/it] 25%|██▌       | 1137/4545 [1:13:28<3:11:53,  3.38s/it] 25%|██▌       | 1138/4545 [1:13:32<3:20:52,  3.54s/it] 25%|██▌       | 1139/4545 [1:13:35<3:14:43,  3.43s/it] 25%|██▌       | 1140/4545 [1:13:39<3:15:10,  3.44s/it]                                                       {'loss': 0.3831, 'grad_norm': 53.067752838134766, 'learning_rate': 3.009247027741083e-07, 'rewards/chosen': 1.0480468273162842, 'rewards/rejected': -1.128515601158142, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.17578125, 'logps/chosen': -159.85000610351562, 'logps/rejected': -119.4000015258789, 'logits/chosen': -7.009375095367432, 'logits/rejected': -6.849999904632568, 'epoch': 0.75}
 25%|██▌       | 1140/4545 [1:13:39<3:15:10,  3.44s/it] 25%|██▌       | 1141/4545 [1:13:43<3:24:42,  3.61s/it] 25%|██▌       | 1142/4545 [1:13:46<3:16:15,  3.46s/it] 25%|██▌       | 1143/4545 [1:13:49<3:13:47,  3.42s/it] 25%|██▌       | 1144/4545 [1:13:53<3:22:08,  3.57s/it] 25%|██▌       | 1145/4545 [1:13:57<3:28:10,  3.67s/it] 25%|██▌       | 1146/4545 [1:14:01<3:32:13,  3.75s/it] 25%|██▌       | 1147/4545 [1:14:04<3:21:08,  3.55s/it] 25%|██▌       | 1148/4545 [1:14:07<3:10:04,  3.36s/it] 25%|██▌       | 1149/4545 [1:14:11<3:13:55,  3.43s/it] 25%|██▌       | 1150/4545 [1:14:14<3:18:07,  3.50s/it]                                                       {'loss': 0.3013, 'grad_norm': 29.64271354675293, 'learning_rate': 3.0356671070013206e-07, 'rewards/chosen': 2.1884765625, 'rewards/rejected': -0.9633544683456421, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.1460938453674316, 'logps/chosen': -297.3999938964844, 'logps/rejected': -175.52499389648438, 'logits/chosen': -6.909375190734863, 'logits/rejected': -6.696875095367432, 'epoch': 0.76}
 25%|██▌       | 1150/4545 [1:14:14<3:18:07,  3.50s/it] 25%|██▌       | 1151/4545 [1:14:18<3:26:21,  3.65s/it] 25%|██▌       | 1152/4545 [1:14:22<3:30:53,  3.73s/it] 25%|██▌       | 1153/4545 [1:14:26<3:33:50,  3.78s/it] 25%|██▌       | 1154/4545 [1:14:27<2:54:31,  3.09s/it] 25%|██▌       | 1155/4545 [1:14:31<3:07:59,  3.33s/it] 25%|██▌       | 1156/4545 [1:14:35<3:15:21,  3.46s/it] 25%|██▌       | 1157/4545 [1:14:39<3:23:54,  3.61s/it] 25%|██▌       | 1158/4545 [1:14:43<3:29:17,  3.71s/it] 26%|██▌       | 1159/4545 [1:14:47<3:32:50,  3.77s/it] 26%|██▌       | 1160/4545 [1:14:50<3:19:24,  3.53s/it]                                                       {'loss': 0.3151, 'grad_norm': 24.611431121826172, 'learning_rate': 3.0620871862615587e-07, 'rewards/chosen': 2.258007764816284, 'rewards/rejected': -1.2593262195587158, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.518749952316284, 'logps/chosen': -277.95001220703125, 'logps/rejected': -139.875, 'logits/chosen': -7.009375095367432, 'logits/rejected': -7.128125190734863, 'epoch': 0.77}
 26%|██▌       | 1160/4545 [1:14:50<3:19:24,  3.53s/it] 26%|██▌       | 1161/4545 [1:14:54<3:26:25,  3.66s/it] 26%|██▌       | 1162/4545 [1:14:58<3:31:05,  3.74s/it] 26%|██▌       | 1163/4545 [1:15:02<3:33:56,  3.80s/it] 26%|██▌       | 1164/4545 [1:15:06<3:38:24,  3.88s/it] 26%|██▌       | 1165/4545 [1:15:10<3:38:54,  3.89s/it] 26%|██▌       | 1166/4545 [1:15:12<3:13:42,  3.44s/it] 26%|██▌       | 1167/4545 [1:15:16<3:21:06,  3.57s/it] 26%|██▌       | 1168/4545 [1:15:20<3:29:05,  3.71s/it] 26%|██▌       | 1169/4545 [1:15:24<3:25:48,  3.66s/it] 26%|██▌       | 1170/4545 [1:15:28<3:34:54,  3.82s/it]                                                       {'loss': 0.3215, 'grad_norm': 28.85146141052246, 'learning_rate': 3.088507265521796e-07, 'rewards/chosen': 2.113085985183716, 'rewards/rejected': -1.3154296875, 'rewards/accuracies': 0.8125, 'rewards/margins': 3.432812452316284, 'logps/chosen': -332.70001220703125, 'logps/rejected': -142.25, 'logits/chosen': -6.828125, 'logits/rejected': -6.943749904632568, 'epoch': 0.77}
 26%|██▌       | 1170/4545 [1:15:28<3:34:54,  3.82s/it] 26%|██▌       | 1171/4545 [1:15:31<3:20:20,  3.56s/it] 26%|██▌       | 1172/4545 [1:15:35<3:26:08,  3.67s/it] 26%|██▌       | 1173/4545 [1:15:38<3:20:33,  3.57s/it] 26%|██▌       | 1174/4545 [1:15:42<3:26:07,  3.67s/it] 26%|██▌       | 1175/4545 [1:15:46<3:28:49,  3.72s/it] 26%|██▌       | 1176/4545 [1:15:50<3:31:57,  3.77s/it] 26%|██▌       | 1177/4545 [1:15:53<3:27:17,  3.69s/it] 26%|██▌       | 1178/4545 [1:15:57<3:30:48,  3.76s/it] 26%|██▌       | 1179/4545 [1:16:01<3:38:18,  3.89s/it] 26%|██▌       | 1180/4545 [1:16:05<3:43:11,  3.98s/it]                                                       {'loss': 0.3131, 'grad_norm': 15.880952835083008, 'learning_rate': 3.114927344782034e-07, 'rewards/chosen': 2.2999024391174316, 'rewards/rejected': -1.0156981945037842, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.3125, 'logps/chosen': -309.0, 'logps/rejected': -189.0500030517578, 'logits/chosen': -7.065625190734863, 'logits/rejected': -7.059374809265137, 'epoch': 0.78}
 26%|██▌       | 1180/4545 [1:16:06<3:43:11,  3.98s/it] 26%|██▌       | 1181/4545 [1:16:10<3:45:07,  4.02s/it] 26%|██▌       | 1182/4545 [1:16:13<3:42:37,  3.97s/it] 26%|██▌       | 1183/4545 [1:16:18<3:46:44,  4.05s/it] 26%|██▌       | 1184/4545 [1:16:21<3:43:49,  4.00s/it] 26%|██▌       | 1185/4545 [1:16:24<3:22:59,  3.62s/it] 26%|██▌       | 1186/4545 [1:16:28<3:27:09,  3.70s/it] 26%|██▌       | 1187/4545 [1:16:32<3:30:30,  3.76s/it] 26%|██▌       | 1188/4545 [1:16:36<3:33:16,  3.81s/it] 26%|██▌       | 1189/4545 [1:16:39<3:25:08,  3.67s/it] 26%|██▌       | 1190/4545 [1:16:43<3:29:08,  3.74s/it]                                                       {'loss': 0.303, 'grad_norm': 30.146774291992188, 'learning_rate': 3.1413474240422717e-07, 'rewards/chosen': 2.080078125, 'rewards/rejected': -1.164648413658142, 'rewards/accuracies': 0.875, 'rewards/margins': 3.2406249046325684, 'logps/chosen': -293.1499938964844, 'logps/rejected': -203.39999389648438, 'logits/chosen': -6.984375, 'logits/rejected': -7.128125190734863, 'epoch': 0.79}
 26%|██▌       | 1190/4545 [1:16:43<3:29:08,  3.74s/it] 26%|██▌       | 1191/4545 [1:16:46<3:21:39,  3.61s/it] 26%|██▌       | 1192/4545 [1:16:51<3:30:10,  3.76s/it] 26%|██▌       | 1193/4545 [1:16:54<3:28:16,  3.73s/it] 26%|██▋       | 1194/4545 [1:16:58<3:30:01,  3.76s/it] 26%|██▋       | 1195/4545 [1:17:02<3:32:37,  3.81s/it] 26%|██▋       | 1196/4545 [1:17:06<3:34:15,  3.84s/it] 26%|██▋       | 1197/4545 [1:17:10<3:34:45,  3.85s/it] 26%|██▋       | 1198/4545 [1:17:13<3:19:22,  3.57s/it] 26%|██▋       | 1199/4545 [1:17:16<3:08:49,  3.39s/it] 26%|██▋       | 1200/4545 [1:17:20<3:22:48,  3.64s/it]                                                       {'loss': 0.3107, 'grad_norm': 62.95515441894531, 'learning_rate': 3.1677675033025097e-07, 'rewards/chosen': 1.709375023841858, 'rewards/rejected': -1.265649437904358, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.9710936546325684, 'logps/chosen': -258.29998779296875, 'logps/rejected': -154.35000610351562, 'logits/chosen': -7.053124904632568, 'logits/rejected': -6.703125, 'epoch': 0.79}
 26%|██▋       | 1200/4545 [1:17:20<3:22:48,  3.64s/it] 26%|██▋       | 1201/4545 [1:17:23<3:08:48,  3.39s/it] 26%|██▋       | 1202/4545 [1:17:27<3:15:52,  3.52s/it] 26%|██▋       | 1203/4545 [1:17:31<3:25:34,  3.69s/it] 26%|██▋       | 1204/4545 [1:17:34<3:25:10,  3.68s/it] 27%|██▋       | 1205/4545 [1:17:38<3:27:50,  3.73s/it] 27%|██▋       | 1206/4545 [1:17:41<3:19:03,  3.58s/it] 27%|██▋       | 1207/4545 [1:17:45<3:23:30,  3.66s/it] 27%|██▋       | 1208/4545 [1:17:49<3:27:20,  3.73s/it] 27%|██▋       | 1209/4545 [1:17:53<3:33:37,  3.84s/it] 27%|██▋       | 1210/4545 [1:17:57<3:34:14,  3.85s/it]                                                       {'loss': 0.3045, 'grad_norm': 21.42169189453125, 'learning_rate': 3.1941875825627477e-07, 'rewards/chosen': 1.3263671398162842, 'rewards/rejected': -1.6505615711212158, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.9765625, 'logps/chosen': -224.0500030517578, 'logps/rejected': -138.35000610351562, 'logits/chosen': -6.981249809265137, 'logits/rejected': -7.037499904632568, 'epoch': 0.8}
 27%|██▋       | 1210/4545 [1:17:57<3:34:14,  3.85s/it] 27%|██▋       | 1211/4545 [1:18:01<3:35:34,  3.88s/it] 27%|██▋       | 1212/4545 [1:18:05<3:36:15,  3.89s/it] 27%|██▋       | 1213/4545 [1:18:09<3:36:29,  3.90s/it] 27%|██▋       | 1214/4545 [1:18:13<3:40:52,  3.98s/it] 27%|██▋       | 1215/4545 [1:18:16<3:28:36,  3.76s/it] 27%|██▋       | 1216/4545 [1:18:20<3:26:25,  3.72s/it] 27%|██▋       | 1217/4545 [1:18:24<3:30:10,  3.79s/it] 27%|██▋       | 1218/4545 [1:18:28<3:37:48,  3.93s/it] 27%|██▋       | 1219/4545 [1:18:32<3:37:35,  3.93s/it] 27%|██▋       | 1220/4545 [1:18:36<3:37:32,  3.93s/it]                                                       {'loss': 0.2733, 'grad_norm': 14.538016319274902, 'learning_rate': 3.220607661822985e-07, 'rewards/chosen': 2.3017578125, 'rewards/rejected': -1.108789086341858, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.414843797683716, 'logps/chosen': -328.25, 'logps/rejected': -190.27499389648438, 'logits/chosen': -6.887499809265137, 'logits/rejected': -6.712500095367432, 'epoch': 0.81}
 27%|██▋       | 1220/4545 [1:18:36<3:37:32,  3.93s/it] 27%|██▋       | 1221/4545 [1:18:39<3:30:57,  3.81s/it] 27%|██▋       | 1222/4545 [1:18:43<3:26:36,  3.73s/it] 27%|██▋       | 1223/4545 [1:18:47<3:29:00,  3.78s/it] 27%|██▋       | 1224/4545 [1:18:51<3:30:39,  3.81s/it] 27%|██▋       | 1225/4545 [1:18:54<3:22:49,  3.67s/it] 27%|██▋       | 1226/4545 [1:18:58<3:26:57,  3.74s/it] 27%|██▋       | 1227/4545 [1:19:02<3:29:57,  3.80s/it] 27%|██▋       | 1228/4545 [1:19:06<3:34:38,  3.88s/it] 27%|██▋       | 1229/4545 [1:19:10<3:33:19,  3.86s/it] 27%|██▋       | 1230/4545 [1:19:13<3:28:15,  3.77s/it]                                                       {'loss': 0.2534, 'grad_norm': 24.64786720275879, 'learning_rate': 3.247027741083223e-07, 'rewards/chosen': 2.775390625, 'rewards/rejected': -0.9027343988418579, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.676562547683716, 'logps/chosen': -340.6499938964844, 'logps/rejected': -255.125, 'logits/chosen': -6.803124904632568, 'logits/rejected': -6.803124904632568, 'epoch': 0.81}
 27%|██▋       | 1230/4545 [1:19:14<3:28:15,  3.77s/it] 27%|██▋       | 1231/4545 [1:19:17<3:30:46,  3.82s/it] 27%|██▋       | 1232/4545 [1:19:21<3:32:27,  3.85s/it] 27%|██▋       | 1233/4545 [1:19:25<3:30:35,  3.82s/it] 27%|██▋       | 1234/4545 [1:19:29<3:36:07,  3.92s/it] 27%|██▋       | 1235/4545 [1:19:32<3:19:27,  3.62s/it] 27%|██▋       | 1236/4545 [1:19:36<3:24:06,  3.70s/it] 27%|██▋       | 1237/4545 [1:19:40<3:26:57,  3.75s/it] 27%|██▋       | 1238/4545 [1:19:44<3:29:46,  3.81s/it] 27%|██▋       | 1239/4545 [1:19:48<3:30:53,  3.83s/it] 27%|██▋       | 1240/4545 [1:19:52<3:32:26,  3.86s/it]                                                       {'loss': 0.3321, 'grad_norm': 47.01708221435547, 'learning_rate': 3.273447820343461e-07, 'rewards/chosen': 3.2027344703674316, 'rewards/rejected': -0.9239257574081421, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.126562595367432, 'logps/chosen': -424.1000061035156, 'logps/rejected': -224.60000610351562, 'logits/chosen': -6.96875, 'logits/rejected': -6.778124809265137, 'epoch': 0.82}
 27%|██▋       | 1240/4545 [1:19:52<3:32:26,  3.86s/it] 27%|██▋       | 1241/4545 [1:19:55<3:30:57,  3.83s/it] 27%|██▋       | 1242/4545 [1:19:59<3:33:00,  3.87s/it] 27%|██▋       | 1243/4545 [1:20:03<3:33:53,  3.89s/it] 27%|██▋       | 1244/4545 [1:20:07<3:38:54,  3.98s/it] 27%|██▋       | 1245/4545 [1:20:11<3:37:59,  3.96s/it] 27%|██▋       | 1246/4545 [1:20:15<3:37:12,  3.95s/it] 27%|██▋       | 1247/4545 [1:20:19<3:30:57,  3.84s/it] 27%|██▋       | 1248/4545 [1:20:23<3:31:49,  3.86s/it] 27%|██▋       | 1249/4545 [1:20:27<3:35:47,  3.93s/it] 28%|██▊       | 1250/4545 [1:20:31<3:34:26,  3.90s/it]                                                       {'loss': 0.3691, 'grad_norm': 75.76982116699219, 'learning_rate': 3.299867899603699e-07, 'rewards/chosen': 1.468115210533142, 'rewards/rejected': -1.446679711341858, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.9164061546325684, 'logps/chosen': -225.39999389648438, 'logps/rejected': -155.25, 'logits/chosen': -7.112500190734863, 'logits/rejected': -6.971875190734863, 'epoch': 0.83}
 28%|██▊       | 1250/4545 [1:20:31<3:34:26,  3.90s/it] 28%|██▊       | 1251/4545 [1:20:34<3:27:28,  3.78s/it] 28%|██▊       | 1252/4545 [1:20:38<3:22:46,  3.69s/it] 28%|██▊       | 1253/4545 [1:20:41<3:23:58,  3.72s/it] 28%|██▊       | 1254/4545 [1:20:45<3:26:05,  3.76s/it] 28%|██▊       | 1255/4545 [1:20:49<3:28:08,  3.80s/it] 28%|██▊       | 1256/4545 [1:20:53<3:29:19,  3.82s/it] 28%|██▊       | 1257/4545 [1:20:57<3:34:59,  3.92s/it] 28%|██▊       | 1258/4545 [1:21:01<3:40:15,  4.02s/it] 28%|██▊       | 1259/4545 [1:21:05<3:39:39,  4.01s/it] 28%|██▊       | 1260/4545 [1:21:08<3:13:32,  3.53s/it]                                                       {'loss': 0.3807, 'grad_norm': 44.45343780517578, 'learning_rate': 3.326287978863937e-07, 'rewards/chosen': 0.984570324420929, 'rewards/rejected': -1.544921875, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.528125047683716, 'logps/chosen': -197.14999389648438, 'logps/rejected': -141.0, 'logits/chosen': -7.190625190734863, 'logits/rejected': -7.046875, 'epoch': 0.83}
 28%|██▊       | 1260/4545 [1:21:08<3:13:32,  3.53s/it] 28%|██▊       | 1261/4545 [1:21:12<3:19:58,  3.65s/it] 28%|██▊       | 1262/4545 [1:21:16<3:25:16,  3.75s/it] 28%|██▊       | 1263/4545 [1:21:19<3:19:34,  3.65s/it] 28%|██▊       | 1264/4545 [1:21:23<3:23:20,  3.72s/it] 28%|██▊       | 1265/4545 [1:21:27<3:24:47,  3.75s/it] 28%|██▊       | 1266/4545 [1:21:31<3:25:47,  3.77s/it] 28%|██▊       | 1267/4545 [1:21:34<3:11:05,  3.50s/it] 28%|██▊       | 1268/4545 [1:21:37<3:17:15,  3.61s/it] 28%|██▊       | 1269/4545 [1:21:41<3:15:49,  3.59s/it] 28%|██▊       | 1270/4545 [1:21:45<3:22:55,  3.72s/it]                                                       {'loss': 0.3623, 'grad_norm': 45.26712417602539, 'learning_rate': 3.352708058124174e-07, 'rewards/chosen': 1.9064452648162842, 'rewards/rejected': -1.1095702648162842, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.015625, 'logps/chosen': -297.25, 'logps/rejected': -138.625, 'logits/chosen': -7.025000095367432, 'logits/rejected': -6.984375, 'epoch': 0.84}
 28%|██▊       | 1270/4545 [1:21:45<3:22:55,  3.72s/it] 28%|██▊       | 1271/4545 [1:21:49<3:31:35,  3.88s/it] 28%|██▊       | 1272/4545 [1:21:52<3:16:26,  3.60s/it] 28%|██▊       | 1273/4545 [1:21:56<3:21:26,  3.69s/it] 28%|██▊       | 1274/4545 [1:22:00<3:24:56,  3.76s/it] 28%|██▊       | 1275/4545 [1:22:03<3:14:10,  3.56s/it] 28%|██▊       | 1276/4545 [1:22:06<3:05:10,  3.40s/it] 28%|██▊       | 1277/4545 [1:22:10<3:13:42,  3.56s/it] 28%|██▊       | 1278/4545 [1:22:14<3:23:19,  3.73s/it] 28%|██▊       | 1279/4545 [1:22:17<3:12:52,  3.54s/it] 28%|██▊       | 1280/4545 [1:22:21<3:18:36,  3.65s/it]                                                       {'loss': 0.2816, 'grad_norm': 25.094419479370117, 'learning_rate': 3.379128137384412e-07, 'rewards/chosen': 2.49609375, 'rewards/rejected': -1.1749999523162842, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.672656297683716, 'logps/chosen': -346.79998779296875, 'logps/rejected': -185.8249969482422, 'logits/chosen': -6.90625, 'logits/rejected': -6.984375, 'epoch': 0.84}
 28%|██▊       | 1280/4545 [1:22:21<3:18:36,  3.65s/it] 28%|██▊       | 1281/4545 [1:22:25<3:20:10,  3.68s/it] 28%|██▊       | 1282/4545 [1:22:29<3:23:49,  3.75s/it] 28%|██▊       | 1283/4545 [1:22:32<3:11:08,  3.52s/it] 28%|██▊       | 1284/4545 [1:22:35<3:11:10,  3.52s/it] 28%|██▊       | 1285/4545 [1:22:39<3:15:00,  3.59s/it] 28%|██▊       | 1286/4545 [1:22:43<3:20:05,  3.68s/it] 28%|██▊       | 1287/4545 [1:22:47<3:23:43,  3.75s/it] 28%|██▊       | 1288/4545 [1:22:51<3:25:41,  3.79s/it] 28%|██▊       | 1289/4545 [1:22:55<3:27:49,  3.83s/it] 28%|██▊       | 1290/4545 [1:22:59<3:33:08,  3.93s/it]                                                       {'loss': 0.289, 'grad_norm': 26.61065673828125, 'learning_rate': 3.40554821664465e-07, 'rewards/chosen': 2.294830322265625, 'rewards/rejected': -4.009765625, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 6.30078125, 'logps/chosen': -336.2749938964844, 'logps/rejected': -192.77499389648438, 'logits/chosen': -6.990624904632568, 'logits/rejected': -6.840624809265137, 'epoch': 0.85}
 28%|██▊       | 1290/4545 [1:22:59<3:33:08,  3.93s/it] 28%|██▊       | 1291/4545 [1:23:03<3:36:24,  3.99s/it] 28%|██▊       | 1292/4545 [1:23:07<3:29:05,  3.86s/it] 28%|██▊       | 1293/4545 [1:23:11<3:29:57,  3.87s/it] 28%|██▊       | 1294/4545 [1:23:14<3:31:26,  3.90s/it] 28%|██▊       | 1295/4545 [1:23:18<3:31:24,  3.90s/it] 29%|██▊       | 1296/4545 [1:23:22<3:21:06,  3.71s/it] 29%|██▊       | 1297/4545 [1:23:25<3:12:46,  3.56s/it] 29%|██▊       | 1298/4545 [1:23:29<3:16:10,  3.62s/it] 29%|██▊       | 1299/4545 [1:23:31<2:55:48,  3.25s/it] 29%|██▊       | 1300/4545 [1:23:35<3:12:10,  3.55s/it]                                                       {'loss': 0.334, 'grad_norm': 39.535614013671875, 'learning_rate': 3.4319682959048873e-07, 'rewards/chosen': 1.446679711341858, 'rewards/rejected': -1.8425781726837158, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.2874999046325684, 'logps/chosen': -227.5500030517578, 'logps/rejected': -97.4749984741211, 'logits/chosen': -7.121874809265137, 'logits/rejected': -7.112500190734863, 'epoch': 0.86}
 29%|██▊       | 1300/4545 [1:23:35<3:12:10,  3.55s/it] 29%|██▊       | 1301/4545 [1:23:39<3:23:06,  3.76s/it] 29%|██▊       | 1302/4545 [1:23:43<3:25:38,  3.80s/it] 29%|██▊       | 1303/4545 [1:23:47<3:16:22,  3.63s/it] 29%|██▊       | 1304/4545 [1:23:51<3:20:35,  3.71s/it] 29%|██▊       | 1305/4545 [1:23:54<3:23:32,  3.77s/it] 29%|██▊       | 1306/4545 [1:23:58<3:23:36,  3.77s/it] 29%|██▉       | 1307/4545 [1:24:02<3:29:17,  3.88s/it] 29%|██▉       | 1308/4545 [1:24:05<3:08:14,  3.49s/it] 29%|██▉       | 1309/4545 [1:24:08<3:05:48,  3.45s/it] 29%|██▉       | 1310/4545 [1:24:11<2:56:23,  3.27s/it]                                                       {'loss': 0.2617, 'grad_norm': 30.809799194335938, 'learning_rate': 3.4583883751651253e-07, 'rewards/chosen': 1.626220703125, 'rewards/rejected': -1.7937500476837158, 'rewards/accuracies': 0.875, 'rewards/margins': 3.4203124046325684, 'logps/chosen': -222.0749969482422, 'logps/rejected': -137.52499389648438, 'logits/chosen': -7.153124809265137, 'logits/rejected': -6.887499809265137, 'epoch': 0.86}
 29%|██▉       | 1310/4545 [1:24:11<2:56:23,  3.27s/it] 29%|██▉       | 1311/4545 [1:24:15<3:08:55,  3.51s/it] 29%|██▉       | 1312/4545 [1:24:19<3:13:14,  3.59s/it] 29%|██▉       | 1313/4545 [1:24:22<2:59:13,  3.33s/it] 29%|██▉       | 1314/4545 [1:24:26<3:08:59,  3.51s/it] 29%|██▉       | 1315/4545 [1:24:29<3:07:17,  3.48s/it] 29%|██▉       | 1316/4545 [1:24:33<3:09:56,  3.53s/it] 29%|██▉       | 1317/4545 [1:24:37<3:18:15,  3.68s/it] 29%|██▉       | 1318/4545 [1:24:41<3:24:17,  3.80s/it] 29%|██▉       | 1319/4545 [1:24:45<3:24:54,  3.81s/it] 29%|██▉       | 1320/4545 [1:24:48<3:19:55,  3.72s/it]                                                       {'loss': 0.3867, 'grad_norm': 32.274715423583984, 'learning_rate': 3.484808454425363e-07, 'rewards/chosen': 1.6701171398162842, 'rewards/rejected': -1.5750000476837158, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.2437500953674316, 'logps/chosen': -237.25, 'logps/rejected': -152.125, 'logits/chosen': -7.087500095367432, 'logits/rejected': -6.959374904632568, 'epoch': 0.87}
 29%|██▉       | 1320/4545 [1:24:48<3:19:55,  3.72s/it] 29%|██▉       | 1321/4545 [1:24:52<3:24:42,  3.81s/it] 29%|██▉       | 1322/4545 [1:24:56<3:29:26,  3.90s/it] 29%|██▉       | 1323/4545 [1:25:00<3:20:25,  3.73s/it] 29%|██▉       | 1324/4545 [1:25:03<3:16:53,  3.67s/it] 29%|██▉       | 1325/4545 [1:25:07<3:15:59,  3.65s/it] 29%|██▉       | 1326/4545 [1:25:11<3:20:15,  3.73s/it] 29%|██▉       | 1327/4545 [1:25:14<3:13:17,  3.60s/it] 29%|██▉       | 1328/4545 [1:25:18<3:19:51,  3.73s/it] 29%|██▉       | 1329/4545 [1:25:22<3:22:40,  3.78s/it] 29%|██▉       | 1330/4545 [1:25:24<2:54:38,  3.26s/it]                                                       {'loss': 0.3268, 'grad_norm': 24.301671981811523, 'learning_rate': 3.511228533685601e-07, 'rewards/chosen': 1.2173340320587158, 'rewards/rejected': -1.3201172351837158, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.5374999046325684, 'logps/chosen': -180.35000610351562, 'logps/rejected': -136.3000030517578, 'logits/chosen': -7.109375, 'logits/rejected': -7.128125190734863, 'epoch': 0.88}
 29%|██▉       | 1330/4545 [1:25:24<2:54:38,  3.26s/it] 29%|██▉       | 1331/4545 [1:25:28<3:08:59,  3.53s/it] 29%|██▉       | 1332/4545 [1:25:32<3:14:54,  3.64s/it] 29%|██▉       | 1333/4545 [1:25:36<3:19:36,  3.73s/it] 29%|██▉       | 1334/4545 [1:25:40<3:22:36,  3.79s/it] 29%|██▉       | 1335/4545 [1:25:44<3:24:32,  3.82s/it] 29%|██▉       | 1336/4545 [1:25:48<3:26:04,  3.85s/it] 29%|██▉       | 1337/4545 [1:25:52<3:30:10,  3.93s/it] 29%|██▉       | 1338/4545 [1:25:55<3:24:40,  3.83s/it] 29%|██▉       | 1339/4545 [1:25:59<3:26:00,  3.86s/it] 29%|██▉       | 1340/4545 [1:26:03<3:26:46,  3.87s/it]                                                       {'loss': 0.2552, 'grad_norm': 35.15916061401367, 'learning_rate': 3.537648612945839e-07, 'rewards/chosen': 2.7669920921325684, 'rewards/rejected': -1.627343773841858, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.393750190734863, 'logps/chosen': -400.6000061035156, 'logps/rejected': -204.77499389648438, 'logits/chosen': -6.828125, 'logits/rejected': -7.040625095367432, 'epoch': 0.88}
 29%|██▉       | 1340/4545 [1:26:03<3:26:46,  3.87s/it] 30%|██▉       | 1341/4545 [1:26:06<3:15:43,  3.67s/it] 30%|██▉       | 1342/4545 [1:26:10<3:07:02,  3.50s/it] 30%|██▉       | 1343/4545 [1:26:13<3:04:54,  3.46s/it] 30%|██▉       | 1344/4545 [1:26:17<3:14:37,  3.65s/it] 30%|██▉       | 1345/4545 [1:26:21<3:16:58,  3.69s/it] 30%|██▉       | 1346/4545 [1:26:25<3:22:33,  3.80s/it] 30%|██▉       | 1347/4545 [1:26:29<3:24:23,  3.83s/it] 30%|██▉       | 1348/4545 [1:26:33<3:25:17,  3.85s/it] 30%|██▉       | 1349/4545 [1:26:37<3:25:59,  3.87s/it] 30%|██▉       | 1350/4545 [1:26:40<3:26:06,  3.87s/it]                                                       {'loss': 0.368, 'grad_norm': 32.73604202270508, 'learning_rate': 3.5640686922060764e-07, 'rewards/chosen': 2.8412108421325684, 'rewards/rejected': -1.0830566883087158, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 3.9242186546325684, 'logps/chosen': -377.8500061035156, 'logps/rejected': -214.5, 'logits/chosen': -6.921875, 'logits/rejected': -6.875, 'epoch': 0.89}
 30%|██▉       | 1350/4545 [1:26:40<3:26:06,  3.87s/it] 30%|██▉       | 1351/4545 [1:26:45<3:31:04,  3.97s/it] 30%|██▉       | 1352/4545 [1:26:47<3:07:27,  3.52s/it] 30%|██▉       | 1353/4545 [1:26:50<3:03:01,  3.44s/it] 30%|██▉       | 1354/4545 [1:26:54<3:13:05,  3.63s/it] 30%|██▉       | 1355/4545 [1:26:58<3:17:31,  3.72s/it] 30%|██▉       | 1356/4545 [1:27:02<3:16:36,  3.70s/it] 30%|██▉       | 1357/4545 [1:27:06<3:23:17,  3.83s/it] 30%|██▉       | 1358/4545 [1:27:09<3:16:01,  3.69s/it] 30%|██▉       | 1359/4545 [1:27:13<3:19:32,  3.76s/it] 30%|██▉       | 1360/4545 [1:27:17<3:23:38,  3.84s/it]                                                       {'loss': 0.3556, 'grad_norm': 22.05915069580078, 'learning_rate': 3.5904887714663144e-07, 'rewards/chosen': 2.6349120140075684, 'rewards/rejected': -0.941210925579071, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.5726561546325684, 'logps/chosen': -355.79998779296875, 'logps/rejected': -198.9499969482422, 'logits/chosen': -6.96875, 'logits/rejected': -6.912499904632568, 'epoch': 0.9}
 30%|██▉       | 1360/4545 [1:27:17<3:23:38,  3.84s/it] 30%|██▉       | 1361/4545 [1:27:21<3:25:18,  3.87s/it] 30%|██▉       | 1362/4545 [1:27:24<3:03:18,  3.46s/it] 30%|██▉       | 1363/4545 [1:27:28<3:11:49,  3.62s/it] 30%|███       | 1364/4545 [1:27:32<3:19:26,  3.76s/it] 30%|███       | 1365/4545 [1:27:36<3:21:59,  3.81s/it] 30%|███       | 1366/4545 [1:27:40<3:25:15,  3.87s/it] 30%|███       | 1367/4545 [1:27:43<3:10:09,  3.59s/it] 30%|███       | 1368/4545 [1:27:46<3:11:30,  3.62s/it] 30%|███       | 1369/4545 [1:27:50<3:14:24,  3.67s/it] 30%|███       | 1370/4545 [1:27:54<3:17:46,  3.74s/it]                                                       {'loss': 0.3128, 'grad_norm': 41.19095993041992, 'learning_rate': 3.6169088507265524e-07, 'rewards/chosen': 1.842187523841858, 'rewards/rejected': -1.601660132408142, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.4429688453674316, 'logps/chosen': -222.6999969482422, 'logps/rejected': -128.6999969482422, 'logits/chosen': -7.175000190734863, 'logits/rejected': -6.928124904632568, 'epoch': 0.9}
 30%|███       | 1370/4545 [1:27:54<3:17:46,  3.74s/it] 30%|███       | 1371/4545 [1:27:58<3:20:13,  3.79s/it] 30%|███       | 1372/4545 [1:28:01<3:13:22,  3.66s/it] 30%|███       | 1373/4545 [1:28:06<3:21:36,  3.81s/it] 30%|███       | 1374/4545 [1:28:08<2:58:28,  3.38s/it] 30%|███       | 1375/4545 [1:28:12<3:07:14,  3.54s/it] 30%|███       | 1376/4545 [1:28:15<2:58:02,  3.37s/it] 30%|███       | 1377/4545 [1:28:18<2:55:02,  3.32s/it] 30%|███       | 1378/4545 [1:28:22<2:58:12,  3.38s/it] 30%|███       | 1379/4545 [1:28:25<3:05:47,  3.52s/it] 30%|███       | 1380/4545 [1:28:29<3:11:57,  3.64s/it]                                                       {'loss': 0.2626, 'grad_norm': 21.835128784179688, 'learning_rate': 3.64332892998679e-07, 'rewards/chosen': 2.403515577316284, 'rewards/rejected': -1.6652343273162842, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.0625, 'logps/chosen': -276.42498779296875, 'logps/rejected': -119.1500015258789, 'logits/chosen': -7.065625190734863, 'logits/rejected': -6.953125, 'epoch': 0.91}
 30%|███       | 1380/4545 [1:28:29<3:11:57,  3.64s/it] 30%|███       | 1381/4545 [1:28:33<3:15:56,  3.72s/it] 30%|███       | 1382/4545 [1:28:37<3:14:05,  3.68s/it] 30%|███       | 1383/4545 [1:28:41<3:17:07,  3.74s/it] 30%|███       | 1384/4545 [1:28:45<3:19:57,  3.80s/it] 30%|███       | 1385/4545 [1:28:49<3:21:32,  3.83s/it] 30%|███       | 1386/4545 [1:28:53<3:26:12,  3.92s/it] 31%|███       | 1387/4545 [1:28:57<3:26:02,  3.91s/it] 31%|███       | 1388/4545 [1:29:00<3:24:07,  3.88s/it] 31%|███       | 1389/4545 [1:29:04<3:24:01,  3.88s/it] 31%|███       | 1390/4545 [1:29:08<3:24:36,  3.89s/it]                                                       {'loss': 0.2757, 'grad_norm': 31.195730209350586, 'learning_rate': 3.669749009247028e-07, 'rewards/chosen': 3.748339891433716, 'rewards/rejected': -0.835644543170929, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.576562404632568, 'logps/chosen': -452.75, 'logps/rejected': -249.60000610351562, 'logits/chosen': -6.837500095367432, 'logits/rejected': -6.800000190734863, 'epoch': 0.92}
 31%|███       | 1390/4545 [1:29:08<3:24:36,  3.89s/it] 31%|███       | 1391/4545 [1:29:12<3:24:13,  3.89s/it] 31%|███       | 1392/4545 [1:29:16<3:22:21,  3.85s/it] 31%|███       | 1393/4545 [1:29:20<3:22:57,  3.86s/it] 31%|███       | 1394/4545 [1:29:23<3:21:02,  3.83s/it] 31%|███       | 1395/4545 [1:29:27<3:20:38,  3.82s/it] 31%|███       | 1396/4545 [1:29:31<3:21:54,  3.85s/it] 31%|███       | 1397/4545 [1:29:35<3:22:28,  3.86s/it] 31%|███       | 1398/4545 [1:29:39<3:25:38,  3.92s/it] 31%|███       | 1399/4545 [1:29:43<3:20:37,  3.83s/it] 31%|███       | 1400/4545 [1:29:47<3:25:14,  3.92s/it]                                                       {'loss': 0.3103, 'grad_norm': 31.27823257446289, 'learning_rate': 3.696169088507265e-07, 'rewards/chosen': 1.8318359851837158, 'rewards/rejected': -1.7502930164337158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.581249952316284, 'logps/chosen': -232.35000610351562, 'logps/rejected': -119.625, 'logits/chosen': -7.178124904632568, 'logits/rejected': -7.043749809265137, 'epoch': 0.92}
 31%|███       | 1400/4545 [1:29:47<3:25:14,  3.92s/it] 31%|███       | 1401/4545 [1:29:50<3:20:12,  3.82s/it] 31%|███       | 1402/4545 [1:29:54<3:21:34,  3.85s/it] 31%|███       | 1403/4545 [1:29:58<3:16:07,  3.75s/it] 31%|███       | 1404/4545 [1:30:02<3:18:11,  3.79s/it] 31%|███       | 1405/4545 [1:30:06<3:19:44,  3.82s/it] 31%|███       | 1406/4545 [1:30:10<3:26:22,  3.94s/it] 31%|███       | 1407/4545 [1:30:14<3:22:05,  3.86s/it] 31%|███       | 1408/4545 [1:30:17<3:22:37,  3.88s/it] 31%|███       | 1409/4545 [1:30:21<3:16:21,  3.76s/it] 31%|███       | 1410/4545 [1:30:24<3:08:13,  3.60s/it]                                                       {'loss': 0.2495, 'grad_norm': 29.75383949279785, 'learning_rate': 3.722589167767503e-07, 'rewards/chosen': 1.20068359375, 'rewards/rejected': -2.392578125, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.589062452316284, 'logps/chosen': -177.72500610351562, 'logps/rejected': -100.0, 'logits/chosen': -7.237500190734863, 'logits/rejected': -7.081250190734863, 'epoch': 0.93}
 31%|███       | 1410/4545 [1:30:24<3:08:13,  3.60s/it] 31%|███       | 1411/4545 [1:30:28<3:07:19,  3.59s/it] 31%|███       | 1412/4545 [1:30:32<3:12:44,  3.69s/it] 31%|███       | 1413/4545 [1:30:35<3:07:07,  3.58s/it] 31%|███       | 1414/4545 [1:30:38<3:03:59,  3.53s/it] 31%|███       | 1415/4545 [1:30:42<3:09:53,  3.64s/it] 31%|███       | 1416/4545 [1:30:46<3:14:57,  3.74s/it] 31%|███       | 1417/4545 [1:30:50<3:08:24,  3.61s/it] 31%|███       | 1418/4545 [1:30:53<3:00:04,  3.46s/it] 31%|███       | 1419/4545 [1:30:57<3:06:24,  3.58s/it] 31%|███       | 1420/4545 [1:30:59<2:50:02,  3.26s/it]                                                       {'loss': 0.3067, 'grad_norm': 50.67376708984375, 'learning_rate': 3.749009247027741e-07, 'rewards/chosen': 1.652612328529358, 'rewards/rejected': -1.4609375, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.1109375953674316, 'logps/chosen': -230.39999389648438, 'logps/rejected': -148.6999969482422, 'logits/chosen': -7.234375, 'logits/rejected': -6.9375, 'epoch': 0.94}
 31%|███       | 1420/4545 [1:30:59<2:50:02,  3.26s/it] 31%|███▏      | 1421/4545 [1:31:03<3:00:34,  3.47s/it] 31%|███▏      | 1422/4545 [1:31:07<3:06:01,  3.57s/it] 31%|███▏      | 1423/4545 [1:31:10<3:07:10,  3.60s/it] 31%|███▏      | 1424/4545 [1:31:14<3:12:02,  3.69s/it] 31%|███▏      | 1425/4545 [1:31:18<3:03:31,  3.53s/it] 31%|███▏      | 1426/4545 [1:31:21<3:08:34,  3.63s/it] 31%|███▏      | 1427/4545 [1:31:25<3:11:24,  3.68s/it] 31%|███▏      | 1428/4545 [1:31:29<3:14:55,  3.75s/it] 31%|███▏      | 1429/4545 [1:31:32<3:00:34,  3.48s/it] 31%|███▏      | 1430/4545 [1:31:35<2:47:04,  3.22s/it]                                                       {'loss': 0.2903, 'grad_norm': 28.249374389648438, 'learning_rate': 3.7754293262879785e-07, 'rewards/chosen': 1.6298828125, 'rewards/rejected': -1.524804711341858, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.151562452316284, 'logps/chosen': -203.5749969482422, 'logps/rejected': -164.6999969482422, 'logits/chosen': -7.209374904632568, 'logits/rejected': -6.940625190734863, 'epoch': 0.94}
 31%|███▏      | 1430/4545 [1:31:35<2:47:04,  3.22s/it] 31%|███▏      | 1431/4545 [1:31:39<2:58:46,  3.44s/it] 32%|███▏      | 1432/4545 [1:31:43<3:06:53,  3.60s/it] 32%|███▏      | 1433/4545 [1:31:46<3:11:37,  3.69s/it] 32%|███▏      | 1434/4545 [1:31:50<3:14:48,  3.76s/it] 32%|███▏      | 1435/4545 [1:31:55<3:21:22,  3.88s/it] 32%|███▏      | 1436/4545 [1:31:58<3:21:35,  3.89s/it] 32%|███▏      | 1437/4545 [1:32:02<3:21:43,  3.89s/it] 32%|███▏      | 1438/4545 [1:32:06<3:19:47,  3.86s/it] 32%|███▏      | 1439/4545 [1:32:10<3:23:47,  3.94s/it] 32%|███▏      | 1440/4545 [1:32:13<3:05:35,  3.59s/it]                                                       {'loss': 0.3416, 'grad_norm': 41.02518081665039, 'learning_rate': 3.8018494055482165e-07, 'rewards/chosen': 2.3541016578674316, 'rewards/rejected': -1.384301781654358, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.737499952316284, 'logps/chosen': -284.6000061035156, 'logps/rejected': -156.25, 'logits/chosen': -7.090624809265137, 'logits/rejected': -7.0, 'epoch': 0.95}
 32%|███▏      | 1440/4545 [1:32:13<3:05:35,  3.59s/it] 32%|███▏      | 1441/4545 [1:32:17<3:05:07,  3.58s/it] 32%|███▏      | 1442/4545 [1:32:20<3:10:20,  3.68s/it] 32%|███▏      | 1443/4545 [1:32:24<3:14:54,  3.77s/it] 32%|███▏      | 1444/4545 [1:32:28<3:16:58,  3.81s/it] 32%|███▏      | 1445/4545 [1:32:32<3:12:12,  3.72s/it] 32%|███▏      | 1446/4545 [1:32:35<3:04:29,  3.57s/it] 32%|███▏      | 1447/4545 [1:32:37<2:39:47,  3.09s/it] 32%|███▏      | 1448/4545 [1:32:41<2:53:37,  3.36s/it] 32%|███▏      | 1449/4545 [1:32:44<2:49:45,  3.29s/it] 32%|███▏      | 1450/4545 [1:32:48<3:00:27,  3.50s/it]                                                       {'loss': 0.2732, 'grad_norm': 9.138275146484375, 'learning_rate': 3.828269484808454e-07, 'rewards/chosen': 2.748828172683716, 'rewards/rejected': -1.4246094226837158, 'rewards/accuracies': 0.875, 'rewards/margins': 4.178906440734863, 'logps/chosen': -301.79998779296875, 'logps/rejected': -189.10000610351562, 'logits/chosen': -7.028124809265137, 'logits/rejected': -6.925000190734863, 'epoch': 0.96}
 32%|███▏      | 1450/4545 [1:32:48<3:00:27,  3.50s/it] 32%|███▏      | 1451/4545 [1:32:51<2:42:36,  3.15s/it] 32%|███▏      | 1452/4545 [1:32:53<2:30:12,  2.91s/it] 32%|███▏      | 1453/4545 [1:32:56<2:34:12,  2.99s/it] 32%|███▏      | 1454/4545 [1:33:00<2:44:51,  3.20s/it] 32%|███▏      | 1455/4545 [1:33:04<2:56:42,  3.43s/it] 32%|███▏      | 1456/4545 [1:33:07<2:54:55,  3.40s/it] 32%|███▏      | 1457/4545 [1:33:11<3:02:33,  3.55s/it] 32%|███▏      | 1458/4545 [1:33:14<2:56:20,  3.43s/it] 32%|███▏      | 1459/4545 [1:33:18<3:03:50,  3.57s/it] 32%|███▏      | 1460/4545 [1:33:22<3:08:49,  3.67s/it]                                                       {'loss': 0.3178, 'grad_norm': 41.503963470458984, 'learning_rate': 3.854689564068692e-07, 'rewards/chosen': 2.048144578933716, 'rewards/rejected': -1.82794189453125, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.879687547683716, 'logps/chosen': -241.10000610351562, 'logps/rejected': -160.22500610351562, 'logits/chosen': -7.143750190734863, 'logits/rejected': -7.050000190734863, 'epoch': 0.96}
 32%|███▏      | 1460/4545 [1:33:22<3:08:49,  3.67s/it] 32%|███▏      | 1461/4545 [1:33:26<3:11:53,  3.73s/it] 32%|███▏      | 1462/4545 [1:33:29<3:08:46,  3.67s/it] 32%|███▏      | 1463/4545 [1:33:33<3:09:46,  3.69s/it] 32%|███▏      | 1464/4545 [1:33:37<3:12:47,  3.75s/it] 32%|███▏      | 1465/4545 [1:33:41<3:11:32,  3.73s/it] 32%|███▏      | 1466/4545 [1:33:44<3:11:10,  3.73s/it] 32%|███▏      | 1467/4545 [1:33:48<3:13:54,  3.78s/it] 32%|███▏      | 1468/4545 [1:33:52<3:20:18,  3.91s/it] 32%|███▏      | 1469/4545 [1:33:56<3:17:42,  3.86s/it] 32%|███▏      | 1470/4545 [1:34:00<3:16:51,  3.84s/it]                                                       {'loss': 0.3787, 'grad_norm': 28.709379196166992, 'learning_rate': 3.88110964332893e-07, 'rewards/chosen': 1.4416015148162842, 'rewards/rejected': -1.8757812976837158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.3148436546325684, 'logps/chosen': -203.3000030517578, 'logps/rejected': -142.47500610351562, 'logits/chosen': -7.150000095367432, 'logits/rejected': -7.018750190734863, 'epoch': 0.97}
 32%|███▏      | 1470/4545 [1:34:00<3:16:51,  3.84s/it] 32%|███▏      | 1471/4545 [1:34:04<3:17:43,  3.86s/it] 32%|███▏      | 1472/4545 [1:34:08<3:21:09,  3.93s/it] 32%|███▏      | 1473/4545 [1:34:11<3:12:55,  3.77s/it] 32%|███▏      | 1474/4545 [1:34:14<3:02:31,  3.57s/it] 32%|███▏      | 1475/4545 [1:34:18<3:02:29,  3.57s/it] 32%|███▏      | 1476/4545 [1:34:22<3:07:33,  3.67s/it] 32%|███▏      | 1477/4545 [1:34:26<3:12:14,  3.76s/it] 33%|███▎      | 1478/4545 [1:34:29<3:02:43,  3.57s/it] 33%|███▎      | 1479/4545 [1:34:33<3:07:32,  3.67s/it] 33%|███▎      | 1480/4545 [1:34:37<3:06:25,  3.65s/it]                                                       {'loss': 0.2895, 'grad_norm': 21.692913055419922, 'learning_rate': 3.9075297225891675e-07, 'rewards/chosen': 3.248339891433716, 'rewards/rejected': -1.427313208580017, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 4.673437595367432, 'logps/chosen': -379.45001220703125, 'logps/rejected': -190.39999389648438, 'logits/chosen': -7.162499904632568, 'logits/rejected': -7.087500095367432, 'epoch': 0.98}
 33%|███▎      | 1480/4545 [1:34:37<3:06:25,  3.65s/it] 33%|███▎      | 1481/4545 [1:34:40<3:10:34,  3.73s/it] 33%|███▎      | 1482/4545 [1:34:43<2:51:18,  3.36s/it] 33%|███▎      | 1483/4545 [1:34:47<2:59:54,  3.53s/it] 33%|███▎      | 1484/4545 [1:34:51<3:10:02,  3.73s/it] 33%|███▎      | 1485/4545 [1:34:55<3:12:27,  3.77s/it] 33%|███▎      | 1486/4545 [1:34:59<3:14:03,  3.81s/it] 33%|███▎      | 1487/4545 [1:35:03<3:12:44,  3.78s/it] 33%|███▎      | 1488/4545 [1:35:06<3:06:45,  3.67s/it] 33%|███▎      | 1489/4545 [1:35:10<3:11:54,  3.77s/it] 33%|███▎      | 1490/4545 [1:35:14<3:17:37,  3.88s/it]                                                       {'loss': 0.2953, 'grad_norm': 32.4564323425293, 'learning_rate': 3.9339498018494056e-07, 'rewards/chosen': 2.544726610183716, 'rewards/rejected': -1.6843750476837158, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.23046875, 'logps/chosen': -287.29998779296875, 'logps/rejected': -146.14999389648438, 'logits/chosen': -7.025000095367432, 'logits/rejected': -6.915625095367432, 'epoch': 0.98}
 33%|███▎      | 1490/4545 [1:35:14<3:17:37,  3.88s/it] 33%|███▎      | 1491/4545 [1:35:18<3:17:40,  3.88s/it] 33%|███▎      | 1492/4545 [1:35:22<3:22:09,  3.97s/it] 33%|███▎      | 1493/4545 [1:35:25<3:01:02,  3.56s/it] 33%|███▎      | 1494/4545 [1:35:28<2:58:36,  3.51s/it] 33%|███▎      | 1495/4545 [1:35:32<3:04:50,  3.64s/it] 33%|███▎      | 1496/4545 [1:35:35<2:58:45,  3.52s/it] 33%|███▎      | 1497/4545 [1:35:39<3:03:51,  3.62s/it] 33%|███▎      | 1498/4545 [1:35:42<2:54:57,  3.45s/it] 33%|███▎      | 1499/4545 [1:35:46<3:06:20,  3.67s/it] 33%|███▎      | 1500/4545 [1:35:51<3:13:49,  3.82s/it]                                                       {'loss': 0.2723, 'grad_norm': 36.20528793334961, 'learning_rate': 3.9603698811096436e-07, 'rewards/chosen': 1.6522948741912842, 'rewards/rejected': -2.31640625, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.9664063453674316, 'logps/chosen': -225.14999389648438, 'logps/rejected': -112.4000015258789, 'logits/chosen': -7.262499809265137, 'logits/rejected': -7.065625190734863, 'epoch': 0.99}
 33%|███▎      | 1500/4545 [1:35:51<3:13:49,  3.82s/it] 33%|███▎      | 1501/4545 [1:35:54<3:14:18,  3.83s/it] 33%|███▎      | 1502/4545 [1:35:58<3:15:29,  3.85s/it] 33%|███▎      | 1503/4545 [1:36:02<3:09:30,  3.74s/it] 33%|███▎      | 1504/4545 [1:36:06<3:12:15,  3.79s/it] 33%|███▎      | 1505/4545 [1:36:10<3:14:11,  3.83s/it] 33%|███▎      | 1506/4545 [1:36:13<3:13:09,  3.81s/it] 33%|███▎      | 1507/4545 [1:36:17<3:06:35,  3.69s/it] 33%|███▎      | 1508/4545 [1:36:20<2:55:51,  3.47s/it] 33%|███▎      | 1509/4545 [1:36:24<3:02:29,  3.61s/it] 33%|███▎      | 1510/4545 [1:36:28<3:11:11,  3.78s/it]                                                       {'loss': 0.2982, 'grad_norm': 31.964351654052734, 'learning_rate': 3.986789960369881e-07, 'rewards/chosen': 3.760449171066284, 'rewards/rejected': -0.5562499761581421, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.317968845367432, 'logps/chosen': -395.29998779296875, 'logps/rejected': -191.85000610351562, 'logits/chosen': -6.849999904632568, 'logits/rejected': -6.887499809265137, 'epoch': 1.0}
 33%|███▎      | 1510/4545 [1:36:28<3:11:11,  3.78s/it] 33%|███▎      | 1511/4545 [1:36:32<3:11:57,  3.80s/it] 33%|███▎      | 1512/4545 [1:36:36<3:13:06,  3.82s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.51s/it][A
 13%|█▎        | 8/60 [00:11<01:21,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:19,  1.63s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.27s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.13s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [00:58<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:16<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A                                                       
                                               [A{'eval_loss': 0.39176806807518005, 'eval_runtime': 80.1978, 'eval_samples_per_second': 11.883, 'eval_steps_per_second': 0.748, 'eval_rewards/chosen': 2.8619954586029053, 'eval_rewards/rejected': -0.646191418170929, 'eval_rewards/accuracies': 0.812615692615509, 'eval_rewards/margins': 3.505871534347534, 'eval_logps/chosen': -363.48333740234375, 'eval_logps/rejected': -155.21249389648438, 'eval_logits/chosen': -6.833593845367432, 'eval_logits/rejected': -7.385937690734863, 'epoch': 1.0}
 33%|███▎      | 1512/4545 [1:37:56<3:13:06,  3.82s/it]
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 33%|███▎      | 1513/4545 [1:38:15<27:17:19, 32.40s/it] 33%|███▎      | 1514/4545 [1:38:19<20:08:39, 23.93s/it] 33%|███▎      | 1515/4545 [1:38:23<15:04:54, 17.92s/it] 33%|███▎      | 1516/4545 [1:38:27<11:32:22, 13.71s/it] 33%|███▎      | 1517/4545 [1:38:30<8:49:23, 10.49s/it]  33%|███▎      | 1518/4545 [1:38:33<7:05:03,  8.43s/it] 33%|███▎      | 1519/4545 [1:38:37<5:57:06,  7.08s/it] 33%|███▎      | 1520/4545 [1:38:41<5:11:00,  6.17s/it]                                                       {'loss': 0.2797, 'grad_norm': 56.3154296875, 'learning_rate': 3.9999758281762587e-07, 'rewards/chosen': 5.074120998382568, 'rewards/rejected': -0.9820801019668579, 'rewards/accuracies': 0.86041659116745, 'rewards/margins': 6.057031154632568, 'logps/chosen': -578.3499755859375, 'logps/rejected': -200.89999389648438, 'logits/chosen': -6.737500190734863, 'logits/rejected': -6.828125, 'epoch': 1.0}
 33%|███▎      | 1520/4545 [1:38:41<5:11:00,  6.17s/it] 33%|███▎      | 1521/4545 [1:38:45<4:40:34,  5.57s/it] 33%|███▎      | 1522/4545 [1:38:49<4:14:55,  5.06s/it] 34%|███▎      | 1523/4545 [1:38:53<3:57:20,  4.71s/it] 34%|███▎      | 1524/4545 [1:38:57<3:45:15,  4.47s/it] 34%|███▎      | 1525/4545 [1:39:01<3:36:26,  4.30s/it] 34%|███▎      | 1526/4545 [1:39:05<3:30:18,  4.18s/it] 34%|███▎      | 1527/4545 [1:39:08<3:16:05,  3.90s/it] 34%|███▎      | 1528/4545 [1:39:12<3:16:02,  3.90s/it] 34%|███▎      | 1529/4545 [1:39:15<3:07:26,  3.73s/it] 34%|███▎      | 1530/4545 [1:39:18<2:52:53,  3.44s/it]                                                       {'loss': 0.2866, 'grad_norm': 30.4206600189209, 'learning_rate': 3.9997824574814905e-07, 'rewards/chosen': 4.156445503234863, 'rewards/rejected': -1.183984398841858, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.342187404632568, 'logps/chosen': -453.0, 'logps/rejected': -202.3000030517578, 'logits/chosen': -6.959374904632568, 'logits/rejected': -6.756249904632568, 'epoch': 1.01}
 34%|███▎      | 1530/4545 [1:39:18<2:52:53,  3.44s/it] 34%|███▎      | 1531/4545 [1:39:22<2:59:45,  3.58s/it] 34%|███▎      | 1532/4545 [1:39:25<2:57:26,  3.53s/it] 34%|███▎      | 1533/4545 [1:39:30<3:07:38,  3.74s/it] 34%|███▍      | 1534/4545 [1:39:34<3:10:14,  3.79s/it] 34%|███▍      | 1535/4545 [1:39:36<2:56:36,  3.52s/it] 34%|███▍      | 1536/4545 [1:39:39<2:36:18,  3.12s/it] 34%|███▍      | 1537/4545 [1:39:43<2:50:32,  3.40s/it] 34%|███▍      | 1538/4545 [1:39:46<2:46:56,  3.33s/it] 34%|███▍      | 1539/4545 [1:39:49<2:50:57,  3.41s/it] 34%|███▍      | 1540/4545 [1:39:53<2:58:39,  3.57s/it]                                                       {'loss': 0.2124, 'grad_norm': 16.825607299804688, 'learning_rate': 3.9993957368656923e-07, 'rewards/chosen': 2.247363328933716, 'rewards/rejected': -2.1860594749450684, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.436718940734863, 'logps/chosen': -255.0, 'logps/rejected': -161.8000030517578, 'logits/chosen': -7.231249809265137, 'logits/rejected': -7.253125190734863, 'epoch': 1.02}
 34%|███▍      | 1540/4545 [1:39:53<2:58:39,  3.57s/it] 34%|███▍      | 1541/4545 [1:39:57<3:03:23,  3.66s/it] 34%|███▍      | 1542/4545 [1:40:01<3:07:11,  3.74s/it] 34%|███▍      | 1543/4545 [1:40:05<3:02:27,  3.65s/it] 34%|███▍      | 1544/4545 [1:40:08<3:04:52,  3.70s/it] 34%|███▍      | 1545/4545 [1:40:12<3:08:22,  3.77s/it] 34%|███▍      | 1546/4545 [1:40:16<3:10:24,  3.81s/it] 34%|███▍      | 1547/4545 [1:40:20<3:11:50,  3.84s/it] 34%|███▍      | 1548/4545 [1:40:24<3:17:06,  3.95s/it] 34%|███▍      | 1549/4545 [1:40:28<3:14:29,  3.90s/it] 34%|███▍      | 1550/4545 [1:40:32<3:16:51,  3.94s/it]                                                       {'loss': 0.2359, 'grad_norm': 28.57815933227539, 'learning_rate': 3.998815707874108e-07, 'rewards/chosen': 2.988476514816284, 'rewards/rejected': -1.554296851158142, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 4.551562309265137, 'logps/chosen': -308.8999938964844, 'logps/rejected': -177.14999389648438, 'logits/chosen': -7.134375095367432, 'logits/rejected': -6.993750095367432, 'epoch': 1.02}
 34%|███▍      | 1550/4545 [1:40:32<3:16:51,  3.94s/it] 34%|███▍      | 1551/4545 [1:40:36<3:20:27,  4.02s/it] 34%|███▍      | 1552/4545 [1:40:40<3:10:39,  3.82s/it] 34%|███▍      | 1553/4545 [1:40:43<2:58:01,  3.57s/it] 34%|███▍      | 1554/4545 [1:40:47<3:03:03,  3.67s/it] 34%|███▍      | 1555/4545 [1:40:51<3:06:26,  3.74s/it] 34%|███▍      | 1556/4545 [1:40:54<3:08:00,  3.77s/it] 34%|███▍      | 1557/4545 [1:40:59<3:14:48,  3.91s/it] 34%|███▍      | 1558/4545 [1:41:01<2:45:17,  3.32s/it] 34%|███▍      | 1559/4545 [1:41:04<2:45:44,  3.33s/it] 34%|███▍      | 1560/4545 [1:41:08<2:51:18,  3.44s/it]                                                       {'loss': 0.2488, 'grad_norm': 14.330520629882812, 'learning_rate': 3.998042432819023e-07, 'rewards/chosen': 3.5599608421325684, 'rewards/rejected': -1.445410132408142, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 5.010937690734863, 'logps/chosen': -351.8500061035156, 'logps/rejected': -202.5500030517578, 'logits/chosen': -7.046875, 'logits/rejected': -6.990624904632568, 'epoch': 1.03}
 34%|███▍      | 1560/4545 [1:41:08<2:51:18,  3.44s/it] 34%|███▍      | 1561/4545 [1:41:11<2:45:29,  3.33s/it] 34%|███▍      | 1562/4545 [1:41:15<2:58:37,  3.59s/it] 34%|███▍      | 1563/4545 [1:41:19<3:05:13,  3.73s/it] 34%|███▍      | 1564/4545 [1:41:22<2:48:08,  3.38s/it] 34%|███▍      | 1565/4545 [1:41:25<2:55:47,  3.54s/it] 34%|███▍      | 1566/4545 [1:41:29<3:01:04,  3.65s/it] 34%|███▍      | 1567/4545 [1:41:33<3:06:30,  3.76s/it] 34%|███▍      | 1568/4545 [1:41:37<3:08:37,  3.80s/it] 35%|███▍      | 1569/4545 [1:41:41<3:04:54,  3.73s/it] 35%|███▍      | 1570/4545 [1:41:44<2:51:55,  3.47s/it]                                                       {'loss': 0.3097, 'grad_norm': 35.421302795410156, 'learning_rate': 3.997075994773073e-07, 'rewards/chosen': 2.43798828125, 'rewards/rejected': -1.8322265148162842, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.2734375, 'logps/chosen': -290.54998779296875, 'logps/rejected': -167.25, 'logits/chosen': -7.256249904632568, 'logits/rejected': -7.053124904632568, 'epoch': 1.04}
 35%|███▍      | 1570/4545 [1:41:44<2:51:55,  3.47s/it] 35%|███▍      | 1571/4545 [1:41:47<2:55:10,  3.53s/it] 35%|███▍      | 1572/4545 [1:41:51<3:01:55,  3.67s/it] 35%|███▍      | 1573/4545 [1:41:55<3:07:44,  3.79s/it] 35%|███▍      | 1574/4545 [1:41:59<2:57:17,  3.58s/it] 35%|███▍      | 1575/4545 [1:42:01<2:48:19,  3.40s/it] 35%|███▍      | 1576/4545 [1:42:05<2:46:17,  3.36s/it] 35%|███▍      | 1577/4545 [1:42:08<2:42:10,  3.28s/it] 35%|███▍      | 1578/4545 [1:42:12<2:51:09,  3.46s/it] 35%|███▍      | 1579/4545 [1:42:15<2:47:54,  3.40s/it] 35%|███▍      | 1580/4545 [1:42:19<2:57:32,  3.59s/it]                                                       {'loss': 0.2083, 'grad_norm': 45.241783142089844, 'learning_rate': 3.995916497560316e-07, 'rewards/chosen': 1.3330078125, 'rewards/rejected': -2.7769532203674316, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.114062309265137, 'logps/chosen': -185.64999389648438, 'logps/rejected': -107.42500305175781, 'logits/chosen': -7.487500190734863, 'logits/rejected': -7.262499809265137, 'epoch': 1.04}
 35%|███▍      | 1580/4545 [1:42:19<2:57:32,  3.59s/it] 35%|███▍      | 1581/4545 [1:42:22<2:47:38,  3.39s/it] 35%|███▍      | 1582/4545 [1:42:26<2:50:55,  3.46s/it] 35%|███▍      | 1583/4545 [1:42:30<2:58:21,  3.61s/it] 35%|███▍      | 1584/4545 [1:42:34<3:06:25,  3.78s/it] 35%|███▍      | 1585/4545 [1:42:38<3:07:45,  3.81s/it] 35%|███▍      | 1586/4545 [1:42:40<2:43:22,  3.31s/it] 35%|███▍      | 1587/4545 [1:42:44<2:55:32,  3.56s/it] 35%|███▍      | 1588/4545 [1:42:48<3:02:13,  3.70s/it] 35%|███▍      | 1589/4545 [1:42:52<3:08:54,  3.83s/it] 35%|███▍      | 1590/4545 [1:42:56<3:04:01,  3.74s/it]                                                       {'loss': 0.2081, 'grad_norm': 19.801082611083984, 'learning_rate': 3.994564065745081e-07, 'rewards/chosen': 1.214013695716858, 'rewards/rejected': -3.0335936546325684, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 4.248437404632568, 'logps/chosen': -170.97500610351562, 'logps/rejected': -103.05000305175781, 'logits/chosen': -7.300000190734863, 'logits/rejected': -7.165625095367432, 'epoch': 1.05}
 35%|███▍      | 1590/4545 [1:42:56<3:04:01,  3.74s/it] 35%|███▌      | 1591/4545 [1:42:59<3:06:13,  3.78s/it] 35%|███▌      | 1592/4545 [1:43:03<2:58:24,  3.62s/it] 35%|███▌      | 1593/4545 [1:43:07<3:02:36,  3.71s/it] 35%|███▌      | 1594/4545 [1:43:10<2:52:52,  3.51s/it] 35%|███▌      | 1595/4545 [1:43:12<2:42:32,  3.31s/it] 35%|███▌      | 1596/4545 [1:43:16<2:52:31,  3.51s/it] 35%|███▌      | 1597/4545 [1:43:20<2:54:23,  3.55s/it] 35%|███▌      | 1598/4545 [1:43:24<2:59:24,  3.65s/it] 35%|███▌      | 1599/4545 [1:43:28<3:06:28,  3.80s/it] 35%|███▌      | 1600/4545 [1:43:32<3:12:59,  3.93s/it]                                                       {'loss': 0.2741, 'grad_norm': 18.09563636779785, 'learning_rate': 3.993018844618587e-07, 'rewards/chosen': 1.972070336341858, 'rewards/rejected': -2.845703125, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.818749904632568, 'logps/chosen': -231.25, 'logps/rejected': -157.22500610351562, 'logits/chosen': -7.481249809265137, 'logits/rejected': -6.96875, 'epoch': 1.06}
 35%|███▌      | 1600/4545 [1:43:32<3:12:59,  3.93s/it] 35%|███▌      | 1601/4545 [1:43:36<3:08:55,  3.85s/it] 35%|███▌      | 1602/4545 [1:43:40<3:09:03,  3.85s/it] 35%|███▌      | 1603/4545 [1:43:44<3:11:56,  3.91s/it] 35%|███▌      | 1604/4545 [1:43:48<3:16:34,  4.01s/it] 35%|███▌      | 1605/4545 [1:43:51<3:05:43,  3.79s/it] 35%|███▌      | 1606/4545 [1:43:55<3:07:23,  3.83s/it] 35%|███▌      | 1607/4545 [1:43:59<3:08:35,  3.85s/it] 35%|███▌      | 1608/4545 [1:44:03<3:08:49,  3.86s/it] 35%|███▌      | 1609/4545 [1:44:06<2:52:56,  3.53s/it] 35%|███▌      | 1610/4545 [1:44:09<2:50:31,  3.49s/it]                                                       {'loss': 0.238, 'grad_norm': 45.79044723510742, 'learning_rate': 3.99128100018333e-07, 'rewards/chosen': 3.427539110183716, 'rewards/rejected': -2.041796922683716, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 5.464062690734863, 'logps/chosen': -362.95001220703125, 'logps/rejected': -174.77499389648438, 'logits/chosen': -7.012499809265137, 'logits/rejected': -6.862500190734863, 'epoch': 1.06}
 35%|███▌      | 1610/4545 [1:44:09<2:50:31,  3.49s/it] 35%|███▌      | 1611/4545 [1:44:13<2:57:03,  3.62s/it] 35%|███▌      | 1612/4545 [1:44:17<3:04:04,  3.77s/it] 35%|███▌      | 1613/4545 [1:44:21<3:00:27,  3.69s/it] 36%|███▌      | 1614/4545 [1:44:25<3:03:40,  3.76s/it] 36%|███▌      | 1615/4545 [1:44:29<3:05:38,  3.80s/it] 36%|███▌      | 1616/4545 [1:44:31<2:48:40,  3.46s/it] 36%|███▌      | 1617/4545 [1:44:35<2:55:35,  3.60s/it] 36%|███▌      | 1618/4545 [1:44:39<3:01:31,  3.72s/it] 36%|███▌      | 1619/4545 [1:44:43<3:00:39,  3.70s/it] 36%|███▌      | 1620/4545 [1:44:46<2:57:57,  3.65s/it]                                                       {'loss': 0.246, 'grad_norm': 32.81559753417969, 'learning_rate': 3.989350719135254e-07, 'rewards/chosen': 3.259692430496216, 'rewards/rejected': -1.732031226158142, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 4.989062309265137, 'logps/chosen': -385.70001220703125, 'logps/rejected': -233.85000610351562, 'logits/chosen': -7.018750190734863, 'logits/rejected': -6.940625190734863, 'epoch': 1.07}
 36%|███▌      | 1620/4545 [1:44:46<2:57:57,  3.65s/it] 36%|███▌      | 1621/4545 [1:44:51<3:05:58,  3.82s/it] 36%|███▌      | 1622/4545 [1:44:55<3:07:24,  3.85s/it] 36%|███▌      | 1623/4545 [1:44:58<3:03:29,  3.77s/it] 36%|███▌      | 1624/4545 [1:45:02<3:09:35,  3.89s/it] 36%|███▌      | 1625/4545 [1:45:06<3:10:46,  3.92s/it] 36%|███▌      | 1626/4545 [1:45:10<3:10:26,  3.91s/it] 36%|███▌      | 1627/4545 [1:45:14<3:05:03,  3.81s/it] 36%|███▌      | 1628/4545 [1:45:16<2:43:40,  3.37s/it] 36%|███▌      | 1629/4545 [1:45:20<2:49:02,  3.48s/it] 36%|███▌      | 1630/4545 [1:45:24<2:51:58,  3.54s/it]                                                       {'loss': 0.3118, 'grad_norm': 15.895217895507812, 'learning_rate': 3.9872282088436934e-07, 'rewards/chosen': 1.47021484375, 'rewards/rejected': -2.9593749046325684, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.431250095367432, 'logps/chosen': -237.75, 'logps/rejected': -114.94999694824219, 'logits/chosen': -7.318749904632568, 'logits/rejected': -7.206250190734863, 'epoch': 1.08}
 36%|███▌      | 1630/4545 [1:45:24<2:51:58,  3.54s/it] 36%|███▌      | 1631/4545 [1:45:27<2:46:40,  3.43s/it] 36%|███▌      | 1632/4545 [1:45:30<2:48:41,  3.47s/it] 36%|███▌      | 1633/4545 [1:45:34<2:52:33,  3.56s/it] 36%|███▌      | 1634/4545 [1:45:38<2:57:45,  3.66s/it] 36%|███▌      | 1635/4545 [1:45:42<3:00:35,  3.72s/it] 36%|███▌      | 1636/4545 [1:45:46<3:02:55,  3.77s/it] 36%|███▌      | 1637/4545 [1:45:50<3:08:01,  3.88s/it] 36%|███▌      | 1638/4545 [1:45:54<3:08:07,  3.88s/it] 36%|███▌      | 1639/4545 [1:45:57<3:03:36,  3.79s/it] 36%|███▌      | 1640/4545 [1:46:00<2:50:37,  3.52s/it]                                                       {'loss': 0.302, 'grad_norm': 35.179378509521484, 'learning_rate': 3.984913697329092e-07, 'rewards/chosen': 1.8253905773162842, 'rewards/rejected': -2.5484375953674316, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.376562595367432, 'logps/chosen': -244.10000610351562, 'logps/rejected': -155.02499389648438, 'logits/chosen': -7.212500095367432, 'logits/rejected': -6.996874809265137, 'epoch': 1.08}
 36%|███▌      | 1640/4545 [1:46:00<2:50:37,  3.52s/it] 36%|███▌      | 1641/4545 [1:46:03<2:43:19,  3.37s/it] 36%|███▌      | 1642/4545 [1:46:07<2:53:01,  3.58s/it] 36%|███▌      | 1643/4545 [1:46:10<2:45:46,  3.43s/it] 36%|███▌      | 1644/4545 [1:46:14<2:52:27,  3.57s/it] 36%|███▌      | 1645/4545 [1:46:18<2:54:13,  3.60s/it] 36%|███▌      | 1646/4545 [1:46:22<3:01:49,  3.76s/it] 36%|███▌      | 1647/4545 [1:46:26<3:01:41,  3.76s/it] 36%|███▋      | 1648/4545 [1:46:29<2:45:37,  3.43s/it] 36%|███▋      | 1649/4545 [1:46:32<2:50:59,  3.54s/it] 36%|███▋      | 1650/4545 [1:46:34<2:29:33,  3.10s/it]                                                       {'loss': 0.3065, 'grad_norm': 20.496723175048828, 'learning_rate': 3.9824074332385113e-07, 'rewards/chosen': 1.1901123523712158, 'rewards/rejected': -2.465527296066284, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.659374952316284, 'logps/chosen': -170.1999969482422, 'logps/rejected': -115.875, 'logits/chosen': -7.331250190734863, 'logits/rejected': -6.806250095367432, 'epoch': 1.09}
 36%|███▋      | 1650/4545 [1:46:34<2:29:33,  3.10s/it] 36%|███▋      | 1651/4545 [1:46:38<2:43:57,  3.40s/it] 36%|███▋      | 1652/4545 [1:46:43<2:53:02,  3.59s/it] 36%|███▋      | 1653/4545 [1:46:46<2:56:55,  3.67s/it] 36%|███▋      | 1654/4545 [1:46:50<2:53:49,  3.61s/it] 36%|███▋      | 1655/4545 [1:46:54<2:57:53,  3.69s/it] 36%|███▋      | 1656/4545 [1:46:57<2:55:27,  3.64s/it] 36%|███▋      | 1657/4545 [1:47:01<2:59:03,  3.72s/it] 36%|███▋      | 1658/4545 [1:47:05<3:01:57,  3.78s/it] 37%|███▋      | 1659/4545 [1:47:08<2:50:31,  3.55s/it] 37%|███▋      | 1660/4545 [1:47:12<2:57:45,  3.70s/it]                                                       {'loss': 0.3113, 'grad_norm': 51.63820266723633, 'learning_rate': 3.9797096858189165e-07, 'rewards/chosen': 2.8521485328674316, 'rewards/rejected': -2.3597655296325684, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 5.215624809265137, 'logps/chosen': -322.54998779296875, 'logps/rejected': -161.1750030517578, 'logits/chosen': -7.25, 'logits/rejected': -6.974999904632568, 'epoch': 1.1}
 37%|███▋      | 1660/4545 [1:47:12<2:57:45,  3.70s/it] 37%|███▋      | 1661/4545 [1:47:16<3:03:32,  3.82s/it] 37%|███▋      | 1662/4545 [1:47:20<3:04:19,  3.84s/it] 37%|███▋      | 1663/4545 [1:47:23<2:57:01,  3.69s/it] 37%|███▋      | 1664/4545 [1:47:27<3:00:20,  3.76s/it] 37%|███▋      | 1665/4545 [1:47:30<2:49:14,  3.53s/it] 37%|███▋      | 1666/4545 [1:47:34<2:54:58,  3.65s/it] 37%|███▋      | 1667/4545 [1:47:38<2:54:32,  3.64s/it] 37%|███▋      | 1668/4545 [1:47:41<2:52:10,  3.59s/it] 37%|███▋      | 1669/4545 [1:47:46<2:59:50,  3.75s/it] 37%|███▋      | 1670/4545 [1:47:49<3:01:58,  3.80s/it]                                                       {'loss': 0.2267, 'grad_norm': 27.39483642578125, 'learning_rate': 3.976820744888251e-07, 'rewards/chosen': 2.087939500808716, 'rewards/rejected': -2.616406202316284, 'rewards/accuracies': 0.875, 'rewards/margins': 4.706250190734863, 'logps/chosen': -259.95001220703125, 'logps/rejected': -154.5749969482422, 'logits/chosen': -7.259375095367432, 'logits/rejected': -6.978125095367432, 'epoch': 1.1}
 37%|███▋      | 1670/4545 [1:47:49<3:01:58,  3.80s/it] 37%|███▋      | 1671/4545 [1:47:53<3:03:36,  3.83s/it] 37%|███▋      | 1672/4545 [1:47:57<3:04:37,  3.86s/it] 37%|███▋      | 1673/4545 [1:48:01<3:09:10,  3.95s/it] 37%|███▋      | 1674/4545 [1:48:05<3:00:06,  3.76s/it] 37%|███▋      | 1675/4545 [1:48:09<3:02:03,  3.81s/it] 37%|███▋      | 1676/4545 [1:48:12<2:51:07,  3.58s/it] 37%|███▋      | 1677/4545 [1:48:15<2:53:01,  3.62s/it] 37%|███▋      | 1678/4545 [1:48:19<2:57:24,  3.71s/it] 37%|███▋      | 1679/4545 [1:48:23<3:00:40,  3.78s/it] 37%|███▋      | 1680/4545 [1:48:27<2:56:09,  3.69s/it]                                                       {'loss': 0.2653, 'grad_norm': 27.897735595703125, 'learning_rate': 3.9737409208043016e-07, 'rewards/chosen': 2.3960938453674316, 'rewards/rejected': -3.2874999046325684, 'rewards/accuracies': 0.875, 'rewards/margins': 5.685937404632568, 'logps/chosen': -315.6499938964844, 'logps/rejected': -136.14999389648438, 'logits/chosen': -7.150000095367432, 'logits/rejected': -7.068749904632568, 'epoch': 1.11}
 37%|███▋      | 1680/4545 [1:48:27<2:56:09,  3.69s/it] 37%|███▋      | 1681/4545 [1:48:30<2:55:39,  3.68s/it] 37%|███▋      | 1682/4545 [1:48:33<2:40:29,  3.36s/it] 37%|███▋      | 1683/4545 [1:48:36<2:37:18,  3.30s/it] 37%|███▋      | 1684/4545 [1:48:39<2:34:35,  3.24s/it] 37%|███▋      | 1685/4545 [1:48:43<2:43:57,  3.44s/it] 37%|███▋      | 1686/4545 [1:48:47<2:50:38,  3.58s/it] 37%|███▋      | 1687/4545 [1:48:51<2:55:00,  3.67s/it] 37%|███▋      | 1688/4545 [1:48:55<2:58:15,  3.74s/it] 37%|███▋      | 1689/4545 [1:48:59<3:00:35,  3.79s/it] 37%|███▋      | 1690/4545 [1:49:03<3:01:54,  3.82s/it]                                                       {'loss': 0.2777, 'grad_norm': 70.98075103759766, 'learning_rate': 3.9704705444313575e-07, 'rewards/chosen': 2.4007811546325684, 'rewards/rejected': -2.162304639816284, 'rewards/accuracies': 0.875, 'rewards/margins': 4.565625190734863, 'logps/chosen': -277.95001220703125, 'logps/rejected': -163.10000610351562, 'logits/chosen': -7.140625, 'logits/rejected': -7.115624904632568, 'epoch': 1.12}
 37%|███▋      | 1690/4545 [1:49:03<3:01:54,  3.82s/it] 37%|███▋      | 1691/4545 [1:49:07<3:03:07,  3.85s/it] 37%|███▋      | 1692/4545 [1:49:11<3:04:15,  3.88s/it] 37%|███▋      | 1693/4545 [1:49:14<3:04:11,  3.87s/it] 37%|███▋      | 1694/4545 [1:49:18<2:56:12,  3.71s/it] 37%|███▋      | 1695/4545 [1:49:21<2:50:30,  3.59s/it] 37%|███▋      | 1696/4545 [1:49:25<2:54:29,  3.67s/it] 37%|███▋      | 1697/4545 [1:49:29<2:57:41,  3.74s/it] 37%|███▋      | 1698/4545 [1:49:33<3:00:05,  3.80s/it] 37%|███▋      | 1699/4545 [1:49:36<2:56:32,  3.72s/it] 37%|███▋      | 1700/4545 [1:49:40<3:02:34,  3.85s/it]                                                       {'loss': 0.2613, 'grad_norm': 18.549497604370117, 'learning_rate': 3.967009967104665e-07, 'rewards/chosen': 3.2900390625, 'rewards/rejected': -1.925390601158142, 'rewards/accuracies': 0.875, 'rewards/margins': 5.220312595367432, 'logps/chosen': -349.0, 'logps/rejected': -188.14999389648438, 'logits/chosen': -6.974999904632568, 'logits/rejected': -6.921875, 'epoch': 1.12}
 37%|███▋      | 1700/4545 [1:49:40<3:02:34,  3.85s/it] 37%|███▋      | 1701/4545 [1:49:44<3:01:28,  3.83s/it] 37%|███▋      | 1702/4545 [1:49:47<2:47:46,  3.54s/it] 37%|███▋      | 1703/4545 [1:49:51<2:53:20,  3.66s/it] 37%|███▋      | 1704/4545 [1:49:55<2:56:23,  3.73s/it] 38%|███▊      | 1705/4545 [1:49:59<2:58:54,  3.78s/it] 38%|███▊      | 1706/4545 [1:50:03<3:00:33,  3.82s/it] 38%|███▊      | 1707/4545 [1:50:07<3:02:03,  3.85s/it] 38%|███▊      | 1708/4545 [1:50:11<3:04:12,  3.90s/it] 38%|███▊      | 1709/4545 [1:50:14<3:00:59,  3.83s/it] 38%|███▊      | 1710/4545 [1:50:18<3:04:57,  3.91s/it]                                                       {'loss': 0.2595, 'grad_norm': 18.50548553466797, 'learning_rate': 3.963359560592685e-07, 'rewards/chosen': 3.453076124191284, 'rewards/rejected': -1.990234375, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.440625190734863, 'logps/chosen': -372.20001220703125, 'logps/rejected': -232.6999969482422, 'logits/chosen': -7.056250095367432, 'logits/rejected': -6.800000190734863, 'epoch': 1.13}
 38%|███▊      | 1710/4545 [1:50:18<3:04:57,  3.91s/it] 38%|███▊      | 1711/4545 [1:50:21<2:46:17,  3.52s/it] 38%|███▊      | 1712/4545 [1:50:25<2:48:05,  3.56s/it] 38%|███▊      | 1713/4545 [1:50:29<2:56:19,  3.74s/it] 38%|███▊      | 1714/4545 [1:50:33<2:58:39,  3.79s/it] 38%|███▊      | 1715/4545 [1:50:37<3:04:23,  3.91s/it] 38%|███▊      | 1716/4545 [1:50:41<3:04:09,  3.91s/it] 38%|███▊      | 1717/4545 [1:50:44<2:57:34,  3.77s/it] 38%|███▊      | 1718/4545 [1:50:48<2:53:14,  3.68s/it] 38%|███▊      | 1719/4545 [1:50:51<2:45:27,  3.51s/it] 38%|███▊      | 1720/4545 [1:50:55<2:50:20,  3.62s/it]                                                       {'loss': 0.2556, 'grad_norm': 58.76544189453125, 'learning_rate': 3.9595197170571513e-07, 'rewards/chosen': 1.904687523841858, 'rewards/rejected': -2.956787109375, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.857812404632568, 'logps/chosen': -206.1999969482422, 'logps/rejected': -133.5500030517578, 'logits/chosen': -7.334374904632568, 'logits/rejected': -7.050000190734863, 'epoch': 1.14}
 38%|███▊      | 1720/4545 [1:50:55<2:50:20,  3.62s/it] 38%|███▊      | 1721/4545 [1:50:59<2:58:16,  3.79s/it] 38%|███▊      | 1722/4545 [1:51:03<2:59:55,  3.82s/it] 38%|███▊      | 1723/4545 [1:51:07<3:01:00,  3.85s/it] 38%|███▊      | 1724/4545 [1:51:10<2:48:10,  3.58s/it] 38%|███▊      | 1725/4545 [1:51:14<2:52:24,  3.67s/it] 38%|███▊      | 1726/4545 [1:51:17<2:53:34,  3.69s/it] 38%|███▊      | 1727/4545 [1:51:21<2:46:40,  3.55s/it] 38%|███▊      | 1728/4545 [1:51:24<2:51:23,  3.65s/it] 38%|███▊      | 1729/4545 [1:51:28<2:54:58,  3.73s/it] 38%|███▊      | 1730/4545 [1:51:32<2:57:36,  3.79s/it]                                                       {'loss': 0.281, 'grad_norm': 54.28730392456055, 'learning_rate': 3.955490849010945e-07, 'rewards/chosen': 3.58648681640625, 'rewards/rejected': -2.2845702171325684, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 5.884375095367432, 'logps/chosen': -389.95001220703125, 'logps/rejected': -206.25, 'logits/chosen': -7.224999904632568, 'logits/rejected': -6.846875190734863, 'epoch': 1.14}
 38%|███▊      | 1730/4545 [1:51:32<2:57:36,  3.79s/it] 38%|███▊      | 1731/4545 [1:51:36<2:55:23,  3.74s/it] 38%|███▊      | 1732/4545 [1:51:40<2:57:05,  3.78s/it] 38%|███▊      | 1733/4545 [1:51:44<2:58:54,  3.82s/it] 38%|███▊      | 1734/4545 [1:51:48<2:59:39,  3.83s/it] 38%|███▊      | 1735/4545 [1:51:51<3:00:42,  3.86s/it] 38%|███▊      | 1736/4545 [1:51:56<3:04:32,  3.94s/it] 38%|███▊      | 1737/4545 [1:51:59<3:03:39,  3.92s/it] 38%|███▊      | 1738/4545 [1:52:03<2:57:42,  3.80s/it] 38%|███▊      | 1739/4545 [1:52:06<2:46:23,  3.56s/it] 38%|███▊      | 1740/4545 [1:52:10<2:50:12,  3.64s/it]                                                       {'loss': 0.2258, 'grad_norm': 21.631591796875, 'learning_rate': 3.951273389273773e-07, 'rewards/chosen': 2.488085985183716, 'rewards/rejected': -2.5341796875, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.017187595367432, 'logps/chosen': -283.92498779296875, 'logps/rejected': -194.8000030517578, 'logits/chosen': -7.243750095367432, 'logits/rejected': -7.068749904632568, 'epoch': 1.15}
 38%|███▊      | 1740/4545 [1:52:10<2:50:12,  3.64s/it] 38%|███▊      | 1741/4545 [1:52:14<2:58:26,  3.82s/it] 38%|███▊      | 1742/4545 [1:52:17<2:39:32,  3.42s/it] 38%|███▊      | 1743/4545 [1:52:20<2:38:39,  3.40s/it] 38%|███▊      | 1744/4545 [1:52:22<2:27:17,  3.15s/it] 38%|███▊      | 1745/4545 [1:52:26<2:37:14,  3.37s/it] 38%|███▊      | 1746/4545 [1:52:30<2:42:16,  3.48s/it] 38%|███▊      | 1747/4545 [1:52:34<2:47:34,  3.59s/it] 38%|███▊      | 1748/4545 [1:52:38<2:51:15,  3.67s/it] 38%|███▊      | 1749/4545 [1:52:41<2:45:45,  3.56s/it] 39%|███▊      | 1750/4545 [1:52:44<2:40:54,  3.45s/it]                                                       {'loss': 0.2612, 'grad_norm': 44.01115036010742, 'learning_rate': 3.946867790925676e-07, 'rewards/chosen': 1.7267577648162842, 'rewards/rejected': -3.409374952316284, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 5.135937690734863, 'logps/chosen': -211.3249969482422, 'logps/rejected': -171.8000030517578, 'logits/chosen': -7.425000190734863, 'logits/rejected': -7.109375, 'epoch': 1.16}
 39%|███▊      | 1750/4545 [1:52:44<2:40:54,  3.45s/it] 39%|███▊      | 1751/4545 [1:52:47<2:34:03,  3.31s/it] 39%|███▊      | 1752/4545 [1:52:51<2:44:52,  3.54s/it] 39%|███▊      | 1753/4545 [1:52:55<2:49:50,  3.65s/it] 39%|███▊      | 1754/4545 [1:52:59<2:52:12,  3.70s/it] 39%|███▊      | 1755/4545 [1:53:03<2:58:26,  3.84s/it] 39%|███▊      | 1756/4545 [1:53:07<2:59:14,  3.86s/it] 39%|███▊      | 1757/4545 [1:53:11<2:54:23,  3.75s/it] 39%|███▊      | 1758/4545 [1:53:13<2:41:16,  3.47s/it] 39%|███▊      | 1759/4545 [1:53:17<2:40:32,  3.46s/it] 39%|███▊      | 1760/4545 [1:53:20<2:36:01,  3.36s/it]                                                       {'loss': 0.2504, 'grad_norm': 8.697746276855469, 'learning_rate': 3.9422745272583505e-07, 'rewards/chosen': 1.5610229969024658, 'rewards/rejected': -3.1373047828674316, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.701562404632568, 'logps/chosen': -187.5500030517578, 'logps/rejected': -108.30000305175781, 'logits/chosen': -7.3125, 'logits/rejected': -7.003125190734863, 'epoch': 1.16}
 39%|███▊      | 1760/4545 [1:53:20<2:36:01,  3.36s/it] 39%|███▊      | 1761/4545 [1:53:24<2:43:18,  3.52s/it] 39%|███▉      | 1762/4545 [1:53:28<2:53:26,  3.74s/it] 39%|███▉      | 1763/4545 [1:53:32<2:56:03,  3.80s/it] 39%|███▉      | 1764/4545 [1:53:36<2:56:57,  3.82s/it] 39%|███▉      | 1765/4545 [1:53:39<2:49:26,  3.66s/it] 39%|███▉      | 1766/4545 [1:53:43<2:52:08,  3.72s/it] 39%|███▉      | 1767/4545 [1:53:46<2:47:23,  3.62s/it] 39%|███▉      | 1768/4545 [1:53:50<2:51:21,  3.70s/it] 39%|███▉      | 1769/4545 [1:53:54<2:54:07,  3.76s/it] 39%|███▉      | 1770/4545 [1:53:58<2:46:45,  3.61s/it]                                                       {'loss': 0.2519, 'grad_norm': 19.641374588012695, 'learning_rate': 3.9374940917243035e-07, 'rewards/chosen': 2.3125977516174316, 'rewards/rejected': -2.311328172683716, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.623437404632568, 'logps/chosen': -278.8999938964844, 'logps/rejected': -170.14999389648438, 'logits/chosen': -7.246874809265137, 'logits/rejected': -7.059374809265137, 'epoch': 1.17}
 39%|███▉      | 1770/4545 [1:53:58<2:46:45,  3.61s/it] 39%|███▉      | 1771/4545 [1:54:01<2:50:16,  3.68s/it] 39%|███▉      | 1772/4545 [1:54:05<2:49:04,  3.66s/it] 39%|███▉      | 1773/4545 [1:54:09<2:55:21,  3.80s/it] 39%|███▉      | 1774/4545 [1:54:13<2:57:45,  3.85s/it] 39%|███▉      | 1775/4545 [1:54:17<3:02:54,  3.96s/it] 39%|███▉      | 1776/4545 [1:54:21<3:02:21,  3.95s/it] 39%|███▉      | 1777/4545 [1:54:24<2:51:55,  3.73s/it] 39%|███▉      | 1778/4545 [1:54:29<2:58:10,  3.86s/it] 39%|███▉      | 1779/4545 [1:54:32<2:45:57,  3.60s/it] 39%|███▉      | 1780/4545 [1:54:35<2:50:10,  3.69s/it]                                                       {'loss': 0.2441, 'grad_norm': 36.844417572021484, 'learning_rate': 3.932526997883844e-07, 'rewards/chosen': 1.9478851556777954, 'rewards/rejected': -3.877734422683716, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 5.828125, 'logps/chosen': -242.89999389648438, 'logps/rejected': -156.3000030517578, 'logits/chosen': -7.231249809265137, 'logits/rejected': -7.034375190734863, 'epoch': 1.17}
 39%|███▉      | 1780/4545 [1:54:36<2:50:10,  3.69s/it] 39%|███▉      | 1781/4545 [1:54:39<2:53:06,  3.76s/it] 39%|███▉      | 1782/4545 [1:54:43<2:54:56,  3.80s/it] 39%|███▉      | 1783/4545 [1:54:47<2:56:20,  3.83s/it] 39%|███▉      | 1784/4545 [1:54:51<2:57:05,  3.85s/it] 39%|███▉      | 1785/4545 [1:54:55<3:00:11,  3.92s/it] 39%|███▉      | 1786/4545 [1:54:59<2:59:52,  3.91s/it] 39%|███▉      | 1787/4545 [1:55:02<2:48:08,  3.66s/it] 39%|███▉      | 1788/4545 [1:55:06<2:57:41,  3.87s/it] 39%|███▉      | 1789/4545 [1:55:10<2:58:32,  3.89s/it] 39%|███▉      | 1790/4545 [1:55:15<3:01:48,  3.96s/it]                                                       {'loss': 0.2811, 'grad_norm': 29.011730194091797, 'learning_rate': 3.927373779349908e-07, 'rewards/chosen': 3.801953077316284, 'rewards/rejected': -2.560302734375, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 6.362500190734863, 'logps/chosen': -361.1499938964844, 'logps/rejected': -195.39999389648438, 'logits/chosen': -7.159375190734863, 'logits/rejected': -6.9375, 'epoch': 1.18}
 39%|███▉      | 1790/4545 [1:55:15<3:01:48,  3.96s/it] 39%|███▉      | 1791/4545 [1:55:19<3:02:58,  3.99s/it] 39%|███▉      | 1792/4545 [1:55:23<3:01:47,  3.96s/it] 39%|███▉      | 1793/4545 [1:55:27<3:04:31,  4.02s/it] 39%|███▉      | 1794/4545 [1:55:31<3:02:33,  3.98s/it] 39%|███▉      | 1795/4545 [1:55:34<3:00:31,  3.94s/it] 40%|███▉      | 1796/4545 [1:55:39<3:03:08,  4.00s/it] 40%|███▉      | 1797/4545 [1:55:42<3:01:40,  3.97s/it] 40%|███▉      | 1798/4545 [1:55:46<3:00:44,  3.95s/it] 40%|███▉      | 1799/4545 [1:55:50<2:59:47,  3.93s/it] 40%|███▉      | 1800/4545 [1:55:54<2:55:00,  3.83s/it]                                                       {'loss': 0.2607, 'grad_norm': 34.22380828857422, 'learning_rate': 3.922034989730734e-07, 'rewards/chosen': 2.2667236328125, 'rewards/rejected': -3.0316405296325684, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 5.290625095367432, 'logps/chosen': -293.75, 'logps/rejected': -171.39999389648438, 'logits/chosen': -7.181250095367432, 'logits/rejected': -6.734375, 'epoch': 1.19}
 40%|███▉      | 1800/4545 [1:55:54<2:55:00,  3.83s/it] 40%|███▉      | 1801/4545 [1:55:58<2:56:01,  3.85s/it] 40%|███▉      | 1802/4545 [1:56:02<2:56:22,  3.86s/it] 40%|███▉      | 1803/4545 [1:56:06<2:58:58,  3.92s/it] 40%|███▉      | 1804/4545 [1:56:09<2:55:05,  3.83s/it] 40%|███▉      | 1805/4545 [1:56:13<2:58:26,  3.91s/it] 40%|███▉      | 1806/4545 [1:56:17<2:55:08,  3.84s/it] 40%|███▉      | 1807/4545 [1:56:20<2:47:18,  3.67s/it] 40%|███▉      | 1808/4545 [1:56:23<2:36:23,  3.43s/it] 40%|███▉      | 1809/4545 [1:56:27<2:46:55,  3.66s/it] 40%|███▉      | 1810/4545 [1:56:31<2:41:24,  3.54s/it]                                                       {'loss': 0.2467, 'grad_norm': 39.03783416748047, 'learning_rate': 3.9165112025703895e-07, 'rewards/chosen': 1.68798828125, 'rewards/rejected': -3.408984422683716, 'rewards/accuracies': 0.875, 'rewards/margins': 5.092187404632568, 'logps/chosen': -214.0500030517578, 'logps/rejected': -131.6999969482422, 'logits/chosen': -7.324999809265137, 'logits/rejected': -7.099999904632568, 'epoch': 1.19}
 40%|███▉      | 1810/4545 [1:56:31<2:41:24,  3.54s/it] 40%|███▉      | 1811/4545 [1:56:35<2:45:51,  3.64s/it] 40%|███▉      | 1812/4545 [1:56:38<2:49:33,  3.72s/it] 40%|███▉      | 1813/4545 [1:56:42<2:52:02,  3.78s/it] 40%|███▉      | 1814/4545 [1:56:46<2:53:49,  3.82s/it] 40%|███▉      | 1815/4545 [1:56:50<2:55:05,  3.85s/it] 40%|███▉      | 1816/4545 [1:56:54<2:55:34,  3.86s/it] 40%|███▉      | 1817/4545 [1:56:58<2:58:54,  3.94s/it] 40%|████      | 1818/4545 [1:57:02<2:55:39,  3.86s/it] 40%|████      | 1819/4545 [1:57:06<3:00:19,  3.97s/it] 40%|████      | 1820/4545 [1:57:10<2:58:48,  3.94s/it]                                                       {'loss': 0.2503, 'grad_norm': 30.317211151123047, 'learning_rate': 3.9108030112871556e-07, 'rewards/chosen': 4.425000190734863, 'rewards/rejected': -2.6898436546325684, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 7.118750095367432, 'logps/chosen': -444.1000061035156, 'logps/rejected': -244.9499969482422, 'logits/chosen': -7.025000095367432, 'logits/rejected': -6.834374904632568, 'epoch': 1.2}
 40%|████      | 1820/4545 [1:57:10<2:58:48,  3.94s/it] 40%|████      | 1821/4545 [1:57:14<2:58:57,  3.94s/it] 40%|████      | 1822/4545 [1:57:18<2:59:15,  3.95s/it] 40%|████      | 1823/4545 [1:57:22<2:58:10,  3.93s/it] 40%|████      | 1824/4545 [1:57:25<2:47:04,  3.68s/it] 40%|████      | 1825/4545 [1:57:29<2:50:07,  3.75s/it] 40%|████      | 1826/4545 [1:57:32<2:38:07,  3.49s/it] 40%|████      | 1827/4545 [1:57:36<2:47:30,  3.70s/it] 40%|████      | 1828/4545 [1:57:40<2:54:15,  3.85s/it] 40%|████      | 1829/4545 [1:57:43<2:47:25,  3.70s/it] 40%|████      | 1830/4545 [1:57:46<2:32:04,  3.36s/it]                                                       {'loss': 0.2564, 'grad_norm': 27.58877182006836, 'learning_rate': 3.904911029109774e-07, 'rewards/chosen': 2.447265625, 'rewards/rejected': -2.5093750953674316, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.959374904632568, 'logps/chosen': -269.54998779296875, 'logps/rejected': -180.14999389648438, 'logits/chosen': -7.137499809265137, 'logits/rejected': -7.043749809265137, 'epoch': 1.21}
 40%|████      | 1830/4545 [1:57:46<2:32:04,  3.36s/it] 40%|████      | 1831/4545 [1:57:50<2:41:08,  3.56s/it] 40%|████      | 1832/4545 [1:57:54<2:50:11,  3.76s/it] 40%|████      | 1833/4545 [1:57:58<2:51:57,  3.80s/it] 40%|████      | 1834/4545 [1:58:02<2:50:38,  3.78s/it] 40%|████      | 1835/4545 [1:58:05<2:41:37,  3.58s/it] 40%|████      | 1836/4545 [1:58:09<2:45:28,  3.67s/it] 40%|████      | 1837/4545 [1:58:13<2:51:30,  3.80s/it] 40%|████      | 1838/4545 [1:58:16<2:47:02,  3.70s/it] 40%|████      | 1839/4545 [1:58:19<2:27:50,  3.28s/it] 40%|████      | 1840/4545 [1:58:23<2:39:16,  3.53s/it]                                                       {'loss': 0.2954, 'grad_norm': 33.88302993774414, 'learning_rate': 3.898835889011572e-07, 'rewards/chosen': 1.5431640148162842, 'rewards/rejected': -3.2281250953674316, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.764062404632568, 'logps/chosen': -218.89999389648438, 'logps/rejected': -141.1750030517578, 'logits/chosen': -7.300000190734863, 'logits/rejected': -7.0, 'epoch': 1.21}
 40%|████      | 1840/4545 [1:58:23<2:39:16,  3.53s/it] 41%|████      | 1841/4545 [1:58:27<2:45:32,  3.67s/it] 41%|████      | 1842/4545 [1:58:31<2:48:38,  3.74s/it] 41%|████      | 1843/4545 [1:58:35<2:51:09,  3.80s/it] 41%|████      | 1844/4545 [1:58:37<2:38:12,  3.51s/it] 41%|████      | 1845/4545 [1:58:41<2:39:57,  3.55s/it] 41%|████      | 1846/4545 [1:58:44<2:27:24,  3.28s/it] 41%|████      | 1847/4545 [1:58:48<2:36:30,  3.48s/it] 41%|████      | 1848/4545 [1:58:52<2:42:27,  3.61s/it] 41%|████      | 1849/4545 [1:58:56<2:46:08,  3.70s/it] 41%|████      | 1850/4545 [1:58:59<2:48:07,  3.74s/it]                                                       {'loss': 0.2422, 'grad_norm': 42.62162780761719, 'learning_rate': 3.892578243642459e-07, 'rewards/chosen': 2.981341600418091, 'rewards/rejected': -2.866015672683716, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 5.849999904632568, 'logps/chosen': -319.1000061035156, 'logps/rejected': -190.3000030517578, 'logits/chosen': -7.271874904632568, 'logits/rejected': -7.021874904632568, 'epoch': 1.22}
 41%|████      | 1850/4545 [1:58:59<2:48:07,  3.74s/it] 41%|████      | 1851/4545 [1:59:03<2:50:31,  3.80s/it] 41%|████      | 1852/4545 [1:59:07<2:48:32,  3.76s/it] 41%|████      | 1853/4545 [1:59:11<2:50:05,  3.79s/it] 41%|████      | 1854/4545 [1:59:15<2:51:38,  3.83s/it] 41%|████      | 1855/4545 [1:59:19<2:52:55,  3.86s/it] 41%|████      | 1856/4545 [1:59:23<2:53:14,  3.87s/it] 41%|████      | 1857/4545 [1:59:26<2:53:51,  3.88s/it] 41%|████      | 1858/4545 [1:59:30<2:55:04,  3.91s/it] 41%|████      | 1859/4545 [1:59:33<2:41:16,  3.60s/it] 41%|████      | 1860/4545 [1:59:37<2:45:18,  3.69s/it]                                                       {'loss': 0.268, 'grad_norm': 43.463897705078125, 'learning_rate': 3.8861387652588137e-07, 'rewards/chosen': 3.782031297683716, 'rewards/rejected': -3.123046875, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 6.909375190734863, 'logps/chosen': -398.6499938964844, 'logps/rejected': -247.1999969482422, 'logits/chosen': -6.949999809265137, 'logits/rejected': -6.853125095367432, 'epoch': 1.23}
 41%|████      | 1860/4545 [1:59:37<2:45:18,  3.69s/it] 41%|████      | 1861/4545 [1:59:41<2:47:47,  3.75s/it] 41%|████      | 1862/4545 [1:59:45<2:49:59,  3.80s/it] 41%|████      | 1863/4545 [1:59:49<2:47:09,  3.74s/it] 41%|████      | 1864/4545 [1:59:53<2:49:18,  3.79s/it] 41%|████      | 1865/4545 [1:59:57<2:54:53,  3.92s/it] 41%|████      | 1866/4545 [2:00:01<2:54:46,  3.91s/it] 41%|████      | 1867/4545 [2:00:04<2:44:56,  3.70s/it] 41%|████      | 1868/4545 [2:00:08<2:47:55,  3.76s/it] 41%|████      | 1869/4545 [2:00:12<2:50:05,  3.81s/it] 41%|████      | 1870/4545 [2:00:16<2:51:23,  3.84s/it]                                                       {'loss': 0.2215, 'grad_norm': 14.569368362426758, 'learning_rate': 3.879518145651265e-07, 'rewards/chosen': 4.072796821594238, 'rewards/rejected': -2.49609375, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 6.564062595367432, 'logps/chosen': -382.1499938964844, 'logps/rejected': -218.8000030517578, 'logits/chosen': -7.059374809265137, 'logits/rejected': -6.931250095367432, 'epoch': 1.23}
 41%|████      | 1870/4545 [2:00:16<2:51:23,  3.84s/it] 41%|████      | 1871/4545 [2:00:19<2:50:55,  3.84s/it] 41%|████      | 1872/4545 [2:00:23<2:47:51,  3.77s/it] 41%|████      | 1873/4545 [2:00:25<2:28:24,  3.33s/it] 41%|████      | 1874/4545 [2:00:30<2:41:02,  3.62s/it] 41%|████▏     | 1875/4545 [2:00:33<2:42:31,  3.65s/it] 41%|████▏     | 1876/4545 [2:00:36<2:29:57,  3.37s/it] 41%|████▏     | 1877/4545 [2:00:40<2:36:53,  3.53s/it] 41%|████▏     | 1878/4545 [2:00:44<2:41:44,  3.64s/it] 41%|████▏     | 1879/4545 [2:00:48<2:41:29,  3.63s/it] 41%|████▏     | 1880/4545 [2:00:51<2:45:07,  3.72s/it]                                                       {'loss': 0.2706, 'grad_norm': 25.98920249938965, 'learning_rate': 3.8727170960703707e-07, 'rewards/chosen': 1.688818335533142, 'rewards/rejected': -3.9703125953674316, 'rewards/accuracies': 0.875, 'rewards/margins': 5.65625, 'logps/chosen': -218.14999389648438, 'logps/rejected': -98.30000305175781, 'logits/chosen': -7.40625, 'logits/rejected': -7.184374809265137, 'epoch': 1.24}
 41%|████▏     | 1880/4545 [2:00:51<2:45:07,  3.72s/it] 41%|████▏     | 1881/4545 [2:00:55<2:36:36,  3.53s/it] 41%|████▏     | 1882/4545 [2:00:59<2:43:45,  3.69s/it] 41%|████▏     | 1883/4545 [2:01:02<2:38:44,  3.58s/it] 41%|████▏     | 1884/4545 [2:01:06<2:43:00,  3.68s/it] 41%|████▏     | 1885/4545 [2:01:10<2:48:31,  3.80s/it] 41%|████▏     | 1886/4545 [2:01:14<2:49:47,  3.83s/it] 42%|████▏     | 1887/4545 [2:01:18<2:50:17,  3.84s/it] 42%|████▏     | 1888/4545 [2:01:21<2:45:12,  3.73s/it] 42%|████▏     | 1889/4545 [2:01:25<2:44:45,  3.72s/it] 42%|████▏     | 1890/4545 [2:01:28<2:34:26,  3.49s/it]                                                       {'loss': 0.2792, 'grad_norm': 21.466175079345703, 'learning_rate': 3.865736347150212e-07, 'rewards/chosen': 1.944921851158142, 'rewards/rejected': -3.3203125, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 5.264062404632568, 'logps/chosen': -233.0500030517578, 'logps/rejected': -190.8000030517578, 'logits/chosen': -7.387499809265137, 'logits/rejected': -7.059374809265137, 'epoch': 1.25}
 42%|████▏     | 1890/4545 [2:01:28<2:34:26,  3.49s/it] 42%|████▏     | 1891/4545 [2:01:32<2:42:25,  3.67s/it] 42%|████▏     | 1892/4545 [2:01:36<2:45:39,  3.75s/it] 42%|████▏     | 1893/4545 [2:01:40<2:47:57,  3.80s/it] 42%|████▏     | 1894/4545 [2:01:43<2:43:52,  3.71s/it] 42%|████▏     | 1895/4545 [2:01:47<2:38:51,  3.60s/it] 42%|████▏     | 1896/4545 [2:01:51<2:44:49,  3.73s/it] 42%|████▏     | 1897/4545 [2:01:53<2:26:57,  3.33s/it] 42%|████▏     | 1898/4545 [2:01:57<2:34:21,  3.50s/it] 42%|████▏     | 1899/4545 [2:02:01<2:39:59,  3.63s/it] 42%|████▏     | 1900/4545 [2:02:05<2:43:55,  3.72s/it]                                                       {'loss': 0.1954, 'grad_norm': 15.569828987121582, 'learning_rate': 3.858576648829896e-07, 'rewards/chosen': 4.123974800109863, 'rewards/rejected': -2.614062547683716, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.748437404632568, 'logps/chosen': -398.1499938964844, 'logps/rejected': -251.0500030517578, 'logits/chosen': -7.043749809265137, 'logits/rejected': -6.903124809265137, 'epoch': 1.25}
 42%|████▏     | 1900/4545 [2:02:05<2:43:55,  3.72s/it] 42%|████▏     | 1901/4545 [2:02:09<2:47:56,  3.81s/it] 42%|████▏     | 1902/4545 [2:02:13<2:52:54,  3.93s/it] 42%|████▏     | 1903/4545 [2:02:17<2:54:46,  3.97s/it] 42%|████▏     | 1904/4545 [2:02:21<2:50:01,  3.86s/it] 42%|████▏     | 1905/4545 [2:02:25<2:52:40,  3.92s/it] 42%|████▏     | 1906/4545 [2:02:29<2:52:23,  3.92s/it] 42%|████▏     | 1907/4545 [2:02:32<2:46:56,  3.80s/it] 42%|████▏     | 1908/4545 [2:02:36<2:52:09,  3.92s/it] 42%|████▏     | 1909/4545 [2:02:40<2:52:04,  3.92s/it] 42%|████▏     | 1910/4545 [2:02:44<2:52:19,  3.92s/it]                                                       {'loss': 0.2099, 'grad_norm': 34.44021987915039, 'learning_rate': 3.8512387702729964e-07, 'rewards/chosen': 2.7747559547424316, 'rewards/rejected': -3.910937547683716, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.690625190734863, 'logps/chosen': -324.79998779296875, 'logps/rejected': -178.85000610351562, 'logits/chosen': -7.324999809265137, 'logits/rejected': -6.884375095367432, 'epoch': 1.26}
 42%|████▏     | 1910/4545 [2:02:44<2:52:19,  3.92s/it] 42%|████▏     | 1911/4545 [2:02:48<2:52:05,  3.92s/it] 42%|████▏     | 1912/4545 [2:02:51<2:44:47,  3.76s/it] 42%|████▏     | 1913/4545 [2:02:55<2:46:56,  3.81s/it] 42%|████▏     | 1914/4545 [2:02:59<2:48:23,  3.84s/it] 42%|████▏     | 1915/4545 [2:03:03<2:48:48,  3.85s/it] 42%|████▏     | 1916/4545 [2:03:07<2:47:19,  3.82s/it] 42%|████▏     | 1917/4545 [2:03:11<2:48:06,  3.84s/it] 42%|████▏     | 1918/4545 [2:03:15<2:49:08,  3.86s/it] 42%|████▏     | 1919/4545 [2:03:18<2:39:37,  3.65s/it] 42%|████▏     | 1920/4545 [2:03:22<2:43:09,  3.73s/it]                                                       {'loss': 0.2253, 'grad_norm': 44.7755012512207, 'learning_rate': 3.8437234997849176e-07, 'rewards/chosen': 2.922168016433716, 'rewards/rejected': -2.9830079078674316, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.904687404632568, 'logps/chosen': -311.6000061035156, 'logps/rejected': -196.3000030517578, 'logits/chosen': -7.234375, 'logits/rejected': -7.012499809265137, 'epoch': 1.27}
 42%|████▏     | 1920/4545 [2:03:22<2:43:09,  3.73s/it] 42%|████▏     | 1921/4545 [2:03:26<2:49:36,  3.88s/it] 42%|████▏     | 1922/4545 [2:03:30<2:47:59,  3.84s/it] 42%|████▏     | 1923/4545 [2:03:34<2:47:06,  3.82s/it] 42%|████▏     | 1924/4545 [2:03:38<2:51:14,  3.92s/it] 42%|████▏     | 1925/4545 [2:03:42<2:50:48,  3.91s/it] 42%|████▏     | 1926/4545 [2:03:45<2:48:33,  3.86s/it] 42%|████▏     | 1927/4545 [2:03:49<2:44:06,  3.76s/it] 42%|████▏     | 1928/4545 [2:03:52<2:38:25,  3.63s/it] 42%|████▏     | 1929/4545 [2:03:56<2:41:59,  3.72s/it] 42%|████▏     | 1930/4545 [2:03:59<2:33:57,  3.53s/it]                                                       {'loss': 0.367, 'grad_norm': 29.207603454589844, 'learning_rate': 3.836031644728211e-07, 'rewards/chosen': 1.0052001476287842, 'rewards/rejected': -4.064062595367432, 'rewards/accuracies': 0.8125, 'rewards/margins': 5.0703125, 'logps/chosen': -186.64999389648438, 'logps/rejected': -129.6999969482422, 'logits/chosen': -7.315625190734863, 'logits/rejected': -6.978125095367432, 'epoch': 1.27}
 42%|████▏     | 1930/4545 [2:03:59<2:33:57,  3.53s/it] 42%|████▏     | 1931/4545 [2:04:03<2:34:04,  3.54s/it] 43%|████▎     | 1932/4545 [2:04:07<2:38:42,  3.64s/it] 43%|████▎     | 1933/4545 [2:04:09<2:27:32,  3.39s/it] 43%|████▎     | 1934/4545 [2:04:14<2:35:44,  3.58s/it] 43%|████▎     | 1935/4545 [2:04:17<2:40:06,  3.68s/it] 43%|████▎     | 1936/4545 [2:04:21<2:42:29,  3.74s/it] 43%|████▎     | 1937/4545 [2:04:25<2:43:23,  3.76s/it] 43%|████▎     | 1938/4545 [2:04:29<2:45:22,  3.81s/it] 43%|████▎     | 1939/4545 [2:04:33<2:48:52,  3.89s/it] 43%|████▎     | 1940/4545 [2:04:37<2:48:45,  3.89s/it]                                                       {'loss': 0.2134, 'grad_norm': 27.268495559692383, 'learning_rate': 3.828164031435837e-07, 'rewards/chosen': 2.777539014816284, 'rewards/rejected': -7.537499904632568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 10.314062118530273, 'logps/chosen': -289.54998779296875, 'logps/rejected': -214.64999389648438, 'logits/chosen': -7.206250190734863, 'logits/rejected': -6.809374809265137, 'epoch': 1.28}
 43%|████▎     | 1940/4545 [2:04:37<2:48:45,  3.89s/it] 43%|████▎     | 1941/4545 [2:04:41<2:53:11,  3.99s/it] 43%|████▎     | 1942/4545 [2:04:45<2:51:55,  3.96s/it] 43%|████▎     | 1943/4545 [2:04:49<2:51:27,  3.95s/it] 43%|████▎     | 1944/4545 [2:04:53<2:50:54,  3.94s/it] 43%|████▎     | 1945/4545 [2:04:56<2:40:00,  3.69s/it] 43%|████▎     | 1946/4545 [2:05:00<2:42:43,  3.76s/it] 43%|████▎     | 1947/4545 [2:05:03<2:30:17,  3.47s/it] 43%|████▎     | 1948/4545 [2:05:06<2:21:06,  3.26s/it] 43%|████▎     | 1949/4545 [2:05:09<2:29:34,  3.46s/it] 43%|████▎     | 1950/4545 [2:05:14<2:37:59,  3.65s/it]                                                       {'loss': 0.3059, 'grad_norm': 61.25419616699219, 'learning_rate': 3.820121505122396e-07, 'rewards/chosen': 1.338134765625, 'rewards/rejected': -3.2249999046325684, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.565625190734863, 'logps/chosen': -199.5500030517578, 'logps/rejected': -158.0, 'logits/chosen': -7.4375, 'logits/rejected': -6.996874809265137, 'epoch': 1.29}
 43%|████▎     | 1950/4545 [2:05:14<2:37:59,  3.65s/it] 43%|████▎     | 1951/4545 [2:05:17<2:41:16,  3.73s/it] 43%|████▎     | 1952/4545 [2:05:21<2:43:07,  3.77s/it] 43%|████▎     | 1953/4545 [2:05:25<2:42:10,  3.75s/it] 43%|████▎     | 1954/4545 [2:05:29<2:44:05,  3.80s/it] 43%|████▎     | 1955/4545 [2:05:33<2:48:56,  3.91s/it] 43%|████▎     | 1956/4545 [2:05:37<2:48:41,  3.91s/it] 43%|████▎     | 1957/4545 [2:05:41<2:48:35,  3.91s/it] 43%|████▎     | 1958/4545 [2:05:43<2:27:28,  3.42s/it] 43%|████▎     | 1959/4545 [2:05:46<2:12:58,  3.09s/it] 43%|████▎     | 1960/4545 [2:05:49<2:17:51,  3.20s/it]                                                       {'loss': 0.279, 'grad_norm': 40.36460876464844, 'learning_rate': 3.811904929793324e-07, 'rewards/chosen': 2.841503858566284, 'rewards/rejected': -3.80078125, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 6.6484375, 'logps/chosen': -300.04998779296875, 'logps/rejected': -160.64999389648438, 'logits/chosen': -7.309374809265137, 'logits/rejected': -7.099999904632568, 'epoch': 1.29}
 43%|████▎     | 1960/4545 [2:05:49<2:17:51,  3.20s/it] 43%|████▎     | 1961/4545 [2:05:53<2:32:12,  3.53s/it] 43%|████▎     | 1962/4545 [2:05:56<2:20:59,  3.27s/it] 43%|████▎     | 1963/4545 [2:06:00<2:28:01,  3.44s/it] 43%|████▎     | 1964/4545 [2:06:04<2:34:00,  3.58s/it] 43%|████▎     | 1965/4545 [2:06:07<2:32:23,  3.54s/it] 43%|████▎     | 1966/4545 [2:06:11<2:33:25,  3.57s/it] 43%|████▎     | 1967/4545 [2:06:15<2:37:38,  3.67s/it] 43%|████▎     | 1968/4545 [2:06:19<2:40:40,  3.74s/it] 43%|████▎     | 1969/4545 [2:06:23<2:45:31,  3.86s/it] 43%|████▎     | 1970/4545 [2:06:26<2:43:24,  3.81s/it]                                                       {'loss': 0.219, 'grad_norm': 50.198768615722656, 'learning_rate': 3.8035151881520747e-07, 'rewards/chosen': 1.833551049232483, 'rewards/rejected': -4.86328125, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.698437690734863, 'logps/chosen': -226.8249969482422, 'logps/rejected': -119.0999984741211, 'logits/chosen': -7.256249904632568, 'logits/rejected': -6.84375, 'epoch': 1.3}
 43%|████▎     | 1970/4545 [2:06:26<2:43:24,  3.81s/it] 43%|████▎     | 1971/4545 [2:06:30<2:41:08,  3.76s/it] 43%|████▎     | 1972/4545 [2:06:33<2:32:56,  3.57s/it] 43%|████▎     | 1973/4545 [2:06:37<2:37:19,  3.67s/it] 43%|████▎     | 1974/4545 [2:06:41<2:40:24,  3.74s/it] 43%|████▎     | 1975/4545 [2:06:45<2:39:22,  3.72s/it] 43%|████▎     | 1976/4545 [2:06:49<2:44:26,  3.84s/it] 43%|████▎     | 1977/4545 [2:06:53<2:43:46,  3.83s/it] 44%|████▎     | 1978/4545 [2:06:57<2:44:38,  3.85s/it] 44%|████▎     | 1979/4545 [2:07:01<2:47:19,  3.91s/it] 44%|████▎     | 1980/4545 [2:07:04<2:47:12,  3.91s/it]                                                       {'loss': 0.2109, 'grad_norm': 18.134889602661133, 'learning_rate': 3.7949531815052896e-07, 'rewards/chosen': 2.2172608375549316, 'rewards/rejected': -3.9551758766174316, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 6.171875, 'logps/chosen': -238.39999389648438, 'logps/rejected': -160.25, 'logits/chosen': -7.206250190734863, 'logits/rejected': -6.965624809265137, 'epoch': 1.31}
 44%|████▎     | 1980/4545 [2:07:04<2:47:12,  3.91s/it] 44%|████▎     | 1981/4545 [2:07:08<2:38:31,  3.71s/it] 44%|████▎     | 1982/4545 [2:07:12<2:42:48,  3.81s/it] 44%|████▎     | 1983/4545 [2:07:16<2:43:03,  3.82s/it] 44%|████▎     | 1984/4545 [2:07:19<2:38:46,  3.72s/it] 44%|████▎     | 1985/4545 [2:07:23<2:40:41,  3.77s/it] 44%|████▎     | 1986/4545 [2:07:27<2:41:59,  3.80s/it] 44%|████▎     | 1987/4545 [2:07:31<2:47:04,  3.92s/it] 44%|████▎     | 1988/4545 [2:07:35<2:47:37,  3.93s/it] 44%|████▍     | 1989/4545 [2:07:39<2:43:22,  3.84s/it] 44%|████▍     | 1990/4545 [2:07:43<2:44:02,  3.85s/it]                                                       {'loss': 0.299, 'grad_norm': 21.05035400390625, 'learning_rate': 3.7862198296659745e-07, 'rewards/chosen': 2.0138916969299316, 'rewards/rejected': -3.53515625, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.546093940734863, 'logps/chosen': -242.10000610351562, 'logps/rejected': -154.0500030517578, 'logits/chosen': -7.293749809265137, 'logits/rejected': -7.143750190734863, 'epoch': 1.31}
 44%|████▍     | 1990/4545 [2:07:43<2:44:02,  3.85s/it] 44%|████▍     | 1991/4545 [2:07:46<2:44:47,  3.87s/it] 44%|████▍     | 1992/4545 [2:07:50<2:45:14,  3.88s/it] 44%|████▍     | 1993/4545 [2:07:54<2:45:34,  3.89s/it] 44%|████▍     | 1994/4545 [2:07:58<2:45:20,  3.89s/it] 44%|████▍     | 1995/4545 [2:08:02<2:47:45,  3.95s/it] 44%|████▍     | 1996/4545 [2:08:06<2:43:21,  3.85s/it] 44%|████▍     | 1997/4545 [2:08:10<2:41:17,  3.80s/it] 44%|████▍     | 1998/4545 [2:08:13<2:42:47,  3.83s/it] 44%|████▍     | 1999/4545 [2:08:17<2:37:01,  3.70s/it] 44%|████▍     | 2000/4545 [2:08:20<2:35:59,  3.68s/it]                                                       {'loss': 0.2642, 'grad_norm': 38.31892395019531, 'learning_rate': 3.7773160708546794e-07, 'rewards/chosen': 3.049511671066284, 'rewards/rejected': -2.2738280296325684, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 5.329687595367432, 'logps/chosen': -337.8500061035156, 'logps/rejected': -254.35000610351562, 'logits/chosen': -7.268750190734863, 'logits/rejected': -6.90625, 'epoch': 1.32}
 44%|████▍     | 2000/4545 [2:08:20<2:35:59,  3.68s/it] 44%|████▍     | 2001/4545 [2:08:24<2:28:19,  3.50s/it] 44%|████▍     | 2002/4545 [2:08:28<2:35:00,  3.66s/it] 44%|████▍     | 2003/4545 [2:08:31<2:36:58,  3.70s/it] 44%|████▍     | 2004/4545 [2:08:35<2:36:46,  3.70s/it] 44%|████▍     | 2005/4545 [2:08:39<2:38:11,  3.74s/it] 44%|████▍     | 2006/4545 [2:08:43<2:40:09,  3.78s/it] 44%|████▍     | 2007/4545 [2:08:47<2:41:47,  3.83s/it] 44%|████▍     | 2008/4545 [2:08:51<2:42:17,  3.84s/it] 44%|████▍     | 2009/4545 [2:08:54<2:43:05,  3.86s/it] 44%|████▍     | 2010/4545 [2:08:58<2:43:46,  3.88s/it]                                                       {'loss': 0.3076, 'grad_norm': 16.432241439819336, 'learning_rate': 3.768242861598708e-07, 'rewards/chosen': 3.094921827316284, 'rewards/rejected': -3.391796827316284, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 6.487500190734863, 'logps/chosen': -339.6499938964844, 'logps/rejected': -209.35000610351562, 'logits/chosen': -7.390625, 'logits/rejected': -6.956250190734863, 'epoch': 1.33}
 44%|████▍     | 2010/4545 [2:08:58<2:43:46,  3.88s/it] 44%|████▍     | 2011/4545 [2:09:02<2:44:10,  3.89s/it] 44%|████▍     | 2012/4545 [2:09:06<2:38:36,  3.76s/it] 44%|████▍     | 2013/4545 [2:09:09<2:27:03,  3.48s/it] 44%|████▍     | 2014/4545 [2:09:12<2:32:08,  3.61s/it] 44%|████▍     | 2015/4545 [2:09:16<2:36:09,  3.70s/it] 44%|████▍     | 2016/4545 [2:09:20<2:38:47,  3.77s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.51s/it][A
 13%|█▎        | 8/60 [00:11<01:21,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:19,  1.63s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.61s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.27s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.13s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:41<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:58<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:02<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.38s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:13<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:16<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A                                                       
                                               [A{'eval_loss': 0.3843514323234558, 'eval_runtime': 80.1785, 'eval_samples_per_second': 11.886, 'eval_steps_per_second': 0.748, 'eval_rewards/chosen': 2.909228563308716, 'eval_rewards/rejected': -2.577897071838379, 'eval_rewards/accuracies': 0.8269675970077515, 'eval_rewards/margins': 5.486848831176758, 'eval_logps/chosen': -363.0833435058594, 'eval_logps/rejected': -164.8958282470703, 'eval_logits/chosen': -7.011979103088379, 'eval_logits/rejected': -7.4296875, 'epoch': 1.33}
 44%|████▍     | 2016/4545 [2:10:41<2:38:47,  3.77s/it]
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 44%|████▍     | 2017/4545 [2:10:59<22:35:27, 32.17s/it] 44%|████▍     | 2018/4545 [2:11:02<16:34:17, 23.61s/it] 44%|████▍     | 2019/4545 [2:11:07<12:28:08, 17.77s/it] 44%|████▍     | 2020/4545 [2:11:11<9:33:53, 13.64s/it]                                                        {'loss': 0.1986, 'grad_norm': 49.8984489440918, 'learning_rate': 3.759001176629361e-07, 'rewards/chosen': 2.7374024391174316, 'rewards/rejected': -4.228906154632568, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.970312595367432, 'logps/chosen': -307.25, 'logps/rejected': -175.1999969482422, 'logits/chosen': -7.409375190734863, 'logits/rejected': -7.165625095367432, 'epoch': 1.33}
 44%|████▍     | 2020/4545 [2:11:11<9:33:53, 13.64s/it] 44%|████▍     | 2021/4545 [2:11:14<7:30:48, 10.72s/it] 44%|████▍     | 2022/4545 [2:11:18<6:03:47,  8.65s/it] 45%|████▍     | 2023/4545 [2:11:22<4:58:03,  7.09s/it] 45%|████▍     | 2024/4545 [2:11:26<4:21:19,  6.22s/it] 45%|████▍     | 2025/4545 [2:11:30<3:53:19,  5.56s/it] 45%|████▍     | 2026/4545 [2:11:33<3:27:19,  4.94s/it] 45%|████▍     | 2027/4545 [2:11:38<3:17:06,  4.70s/it] 45%|████▍     | 2028/4545 [2:11:40<2:52:02,  4.10s/it] 45%|████▍     | 2029/4545 [2:11:44<2:53:08,  4.13s/it] 45%|████▍     | 2030/4545 [2:11:48<2:46:27,  3.97s/it]                                                       {'loss': 0.1311, 'grad_norm': 19.405933380126953, 'learning_rate': 3.749592008777216e-07, 'rewards/chosen': 3.0565428733825684, 'rewards/rejected': -3.9546875953674316, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 7.009375095367432, 'logps/chosen': -320.6000061035156, 'logps/rejected': -218.10000610351562, 'logits/chosen': -7.493750095367432, 'logits/rejected': -7.171875, 'epoch': 1.34}
 45%|████▍     | 2030/4545 [2:11:48<2:46:27,  3.97s/it] 45%|████▍     | 2031/4545 [2:11:52<2:47:21,  3.99s/it] 45%|████▍     | 2032/4545 [2:11:56<2:46:15,  3.97s/it] 45%|████▍     | 2033/4545 [2:12:00<2:46:11,  3.97s/it] 45%|████▍     | 2034/4545 [2:12:04<2:45:18,  3.95s/it] 45%|████▍     | 2035/4545 [2:12:08<2:44:44,  3.94s/it] 45%|████▍     | 2036/4545 [2:12:12<2:44:12,  3.93s/it] 45%|████▍     | 2037/4545 [2:12:16<2:43:47,  3.92s/it] 45%|████▍     | 2038/4545 [2:12:19<2:38:13,  3.79s/it] 45%|████▍     | 2039/4545 [2:12:23<2:39:45,  3.82s/it] 45%|████▍     | 2040/4545 [2:12:27<2:43:15,  3.91s/it]                                                       {'loss': 0.309, 'grad_norm': 21.376548767089844, 'learning_rate': 3.740016368865473e-07, 'rewards/chosen': 3.288281202316284, 'rewards/rejected': -3.1304688453674316, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 6.417187690734863, 'logps/chosen': -345.25, 'logps/rejected': -202.0, 'logits/chosen': -7.209374904632568, 'logits/rejected': -7.106249809265137, 'epoch': 1.35}
 45%|████▍     | 2040/4545 [2:12:27<2:43:15,  3.91s/it] 45%|████▍     | 2041/4545 [2:12:31<2:39:51,  3.83s/it] 45%|████▍     | 2042/4545 [2:12:35<2:44:16,  3.94s/it] 45%|████▍     | 2043/4545 [2:12:39<2:43:47,  3.93s/it] 45%|████▍     | 2044/4545 [2:12:43<2:43:38,  3.93s/it] 45%|████▍     | 2045/4545 [2:12:47<2:42:51,  3.91s/it] 45%|████▌     | 2046/4545 [2:12:50<2:36:04,  3.75s/it] 45%|████▌     | 2047/4545 [2:12:54<2:39:11,  3.82s/it] 45%|████▌     | 2048/4545 [2:12:58<2:41:18,  3.88s/it] 45%|████▌     | 2049/4545 [2:13:01<2:27:51,  3.55s/it] 45%|████▌     | 2050/4545 [2:13:04<2:27:15,  3.54s/it]                                                       {'loss': 0.2025, 'grad_norm': 25.08820152282715, 'learning_rate': 3.730275285601358e-07, 'rewards/chosen': 2.0525145530700684, 'rewards/rejected': -4.768750190734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.823437690734863, 'logps/chosen': -240.72500610351562, 'logps/rejected': -174.8000030517578, 'logits/chosen': -7.368750095367432, 'logits/rejected': -6.940625190734863, 'epoch': 1.35}
 45%|████▌     | 2050/4545 [2:13:04<2:27:15,  3.54s/it] 45%|████▌     | 2051/4545 [2:13:08<2:30:01,  3.61s/it] 45%|████▌     | 2052/4545 [2:13:12<2:31:48,  3.65s/it] 45%|████▌     | 2053/4545 [2:13:16<2:34:45,  3.73s/it] 45%|████▌     | 2054/4545 [2:13:20<2:37:01,  3.78s/it] 45%|████▌     | 2055/4545 [2:13:24<2:38:26,  3.82s/it] 45%|████▌     | 2056/4545 [2:13:26<2:26:15,  3.53s/it] 45%|████▌     | 2057/4545 [2:13:30<2:30:45,  3.64s/it] 45%|████▌     | 2058/4545 [2:13:34<2:34:11,  3.72s/it] 45%|████▌     | 2059/4545 [2:13:38<2:36:29,  3.78s/it] 45%|████▌     | 2060/4545 [2:13:41<2:22:10,  3.43s/it]                                                       {'loss': 0.1983, 'grad_norm': 40.65410232543945, 'learning_rate': 3.720369805465613e-07, 'rewards/chosen': 3.8956055641174316, 'rewards/rejected': -4.789843559265137, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.678125381469727, 'logps/chosen': -396.45001220703125, 'logps/rejected': -181.72500610351562, 'logits/chosen': -7.203125, 'logits/rejected': -6.824999809265137, 'epoch': 1.36}
 45%|████▌     | 2060/4545 [2:13:41<2:22:10,  3.43s/it] 45%|████▌     | 2061/4545 [2:13:45<2:28:07,  3.58s/it] 45%|████▌     | 2062/4545 [2:13:49<2:32:11,  3.68s/it] 45%|████▌     | 2063/4545 [2:13:52<2:35:02,  3.75s/it] 45%|████▌     | 2064/4545 [2:13:56<2:37:25,  3.81s/it] 45%|████▌     | 2065/4545 [2:14:00<2:31:44,  3.67s/it] 45%|████▌     | 2066/4545 [2:14:03<2:26:54,  3.56s/it] 45%|████▌     | 2067/4545 [2:14:07<2:34:52,  3.75s/it] 46%|████▌     | 2068/4545 [2:14:11<2:36:47,  3.80s/it] 46%|████▌     | 2069/4545 [2:14:15<2:40:11,  3.88s/it] 46%|████▌     | 2070/4545 [2:14:19<2:40:21,  3.89s/it]                                                       {'loss': 0.261, 'grad_norm': 45.844139099121094, 'learning_rate': 3.71030099260007e-07, 'rewards/chosen': 1.309350609779358, 'rewards/rejected': -4.012890815734863, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.3203125, 'logps/chosen': -206.1999969482422, 'logps/rejected': -179.64999389648438, 'logits/chosen': -7.525000095367432, 'logits/rejected': -7.159375190734863, 'epoch': 1.37}
 46%|████▌     | 2070/4545 [2:14:19<2:40:21,  3.89s/it] 46%|████▌     | 2071/4545 [2:14:23<2:41:09,  3.91s/it] 46%|████▌     | 2072/4545 [2:14:27<2:35:14,  3.77s/it] 46%|████▌     | 2073/4545 [2:14:30<2:36:58,  3.81s/it] 46%|████▌     | 2074/4545 [2:14:34<2:28:10,  3.60s/it] 46%|████▌     | 2075/4545 [2:14:37<2:30:36,  3.66s/it] 46%|████▌     | 2076/4545 [2:14:41<2:26:28,  3.56s/it] 46%|████▌     | 2077/4545 [2:14:45<2:29:51,  3.64s/it] 46%|████▌     | 2078/4545 [2:14:48<2:32:36,  3.71s/it] 46%|████▌     | 2079/4545 [2:14:52<2:31:18,  3.68s/it] 46%|████▌     | 2080/4545 [2:14:55<2:21:49,  3.45s/it]                                                       {'loss': 0.264, 'grad_norm': 26.168933868408203, 'learning_rate': 3.700069928693331e-07, 'rewards/chosen': 0.7562011480331421, 'rewards/rejected': -4.925000190734863, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 5.684374809265137, 'logps/chosen': -154.89999389648438, 'logps/rejected': -127.3499984741211, 'logits/chosen': -7.443749904632568, 'logits/rejected': -7.146874904632568, 'epoch': 1.37}
 46%|████▌     | 2080/4545 [2:14:55<2:21:49,  3.45s/it] 46%|████▌     | 2081/4545 [2:14:57<2:09:03,  3.14s/it] 46%|████▌     | 2082/4545 [2:15:01<2:11:59,  3.22s/it] 46%|████▌     | 2083/4545 [2:15:05<2:21:53,  3.46s/it] 46%|████▌     | 2084/4545 [2:15:09<2:27:14,  3.59s/it] 46%|████▌     | 2085/4545 [2:15:13<2:34:34,  3.77s/it] 46%|████▌     | 2086/4545 [2:15:17<2:36:23,  3.82s/it] 46%|████▌     | 2087/4545 [2:15:21<2:37:38,  3.85s/it] 46%|████▌     | 2088/4545 [2:15:25<2:37:57,  3.86s/it] 46%|████▌     | 2089/4545 [2:15:28<2:37:20,  3.84s/it] 46%|████▌     | 2090/4545 [2:15:32<2:34:47,  3.78s/it]                                                       {'loss': 0.2563, 'grad_norm': 20.076011657714844, 'learning_rate': 3.689677712864566e-07, 'rewards/chosen': 3.113085985183716, 'rewards/rejected': -3.3187499046325684, 'rewards/accuracies': 0.875, 'rewards/margins': 6.4296875, 'logps/chosen': -326.29998779296875, 'logps/rejected': -241.6999969482422, 'logits/chosen': -7.293749809265137, 'logits/rejected': -7.025000095367432, 'epoch': 1.38}
 46%|████▌     | 2090/4545 [2:15:32<2:34:47,  3.78s/it] 46%|████▌     | 2091/4545 [2:15:36<2:33:10,  3.74s/it] 46%|████▌     | 2092/4545 [2:15:39<2:28:30,  3.63s/it] 46%|████▌     | 2093/4545 [2:15:43<2:31:38,  3.71s/it] 46%|████▌     | 2094/4545 [2:15:47<2:37:02,  3.84s/it] 46%|████▌     | 2095/4545 [2:15:51<2:33:54,  3.77s/it] 46%|████▌     | 2096/4545 [2:15:55<2:35:31,  3.81s/it] 46%|████▌     | 2097/4545 [2:15:59<2:36:38,  3.84s/it] 46%|████▌     | 2098/4545 [2:16:02<2:37:31,  3.86s/it] 46%|████▌     | 2099/4545 [2:16:06<2:37:57,  3.87s/it] 46%|████▌     | 2100/4545 [2:16:10<2:38:06,  3.88s/it]                                                       {'loss': 0.2415, 'grad_norm': 9.135571479797363, 'learning_rate': 3.679125461545431e-07, 'rewards/chosen': 4.025146484375, 'rewards/rejected': -2.805859327316284, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.829687595367432, 'logps/chosen': -396.0, 'logps/rejected': -219.3000030517578, 'logits/chosen': -7.078125, 'logits/rejected': -6.990624904632568, 'epoch': 1.39}
 46%|████▌     | 2100/4545 [2:16:10<2:38:06,  3.88s/it] 46%|████▌     | 2101/4545 [2:16:14<2:40:35,  3.94s/it] 46%|████▌     | 2102/4545 [2:16:18<2:40:09,  3.93s/it] 46%|████▋     | 2103/4545 [2:16:22<2:39:52,  3.93s/it] 46%|████▋     | 2104/4545 [2:16:26<2:39:03,  3.91s/it] 46%|████▋     | 2105/4545 [2:16:30<2:38:52,  3.91s/it] 46%|████▋     | 2106/4545 [2:16:34<2:38:36,  3.90s/it] 46%|████▋     | 2107/4545 [2:16:38<2:40:54,  3.96s/it] 46%|████▋     | 2108/4545 [2:16:42<2:40:08,  3.94s/it] 46%|████▋     | 2109/4545 [2:16:46<2:39:45,  3.93s/it] 46%|████▋     | 2110/4545 [2:16:50<2:39:18,  3.93s/it]                                                       {'loss': 0.2258, 'grad_norm': 41.53525924682617, 'learning_rate': 3.668414308360131e-07, 'rewards/chosen': 5.00390625, 'rewards/rejected': -3.429882764816284, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.4375, 'logps/chosen': -500.8999938964844, 'logps/rejected': -282.6000061035156, 'logits/chosen': -7.162499904632568, 'logits/rejected': -7.025000095367432, 'epoch': 1.39}
 46%|████▋     | 2110/4545 [2:16:50<2:39:18,  3.93s/it] 46%|████▋     | 2111/4545 [2:16:54<2:42:16,  4.00s/it] 46%|████▋     | 2112/4545 [2:16:57<2:33:04,  3.77s/it] 46%|████▋     | 2113/4545 [2:17:01<2:34:23,  3.81s/it] 47%|████▋     | 2114/4545 [2:17:05<2:35:25,  3.84s/it] 47%|████▋     | 2115/4545 [2:17:09<2:36:17,  3.86s/it] 47%|████▋     | 2116/4545 [2:17:13<2:36:54,  3.88s/it] 47%|████▋     | 2117/4545 [2:17:16<2:30:36,  3.72s/it] 47%|████▋     | 2118/4545 [2:17:20<2:33:56,  3.81s/it] 47%|████▋     | 2119/4545 [2:17:24<2:37:59,  3.91s/it] 47%|████▋     | 2120/4545 [2:17:28<2:32:55,  3.78s/it]                                                       {'loss': 0.271, 'grad_norm': 45.95002365112305, 'learning_rate': 3.6575454040036384e-07, 'rewards/chosen': 3.9317626953125, 'rewards/rejected': -3.2674803733825684, 'rewards/accuracies': 0.875, 'rewards/margins': 7.199999809265137, 'logps/chosen': -394.1000061035156, 'logps/rejected': -226.4499969482422, 'logits/chosen': -7.353125095367432, 'logits/rejected': -7.056250095367432, 'epoch': 1.4}
 47%|████▋     | 2120/4545 [2:17:28<2:32:55,  3.78s/it] 47%|████▋     | 2121/4545 [2:17:32<2:34:38,  3.83s/it] 47%|████▋     | 2122/4545 [2:17:35<2:35:11,  3.84s/it] 47%|████▋     | 2123/4545 [2:17:39<2:29:41,  3.71s/it] 47%|████▋     | 2124/4545 [2:17:43<2:34:17,  3.82s/it] 47%|████▋     | 2125/4545 [2:17:47<2:36:25,  3.88s/it] 47%|████▋     | 2126/4545 [2:17:50<2:26:48,  3.64s/it] 47%|████▋     | 2127/4545 [2:17:54<2:30:07,  3.73s/it] 47%|████▋     | 2128/4545 [2:17:58<2:32:07,  3.78s/it] 47%|████▋     | 2129/4545 [2:18:02<2:33:27,  3.81s/it] 47%|████▋     | 2130/4545 [2:18:06<2:34:32,  3.84s/it]                                                       {'loss': 0.2985, 'grad_norm': 38.70602798461914, 'learning_rate': 3.6465199161180697e-07, 'rewards/chosen': 2.7752442359924316, 'rewards/rejected': -4.705468654632568, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 7.467187404632568, 'logps/chosen': -342.79998779296875, 'logps/rejected': -161.8000030517578, 'logits/chosen': -7.284375190734863, 'logits/rejected': -6.940625190734863, 'epoch': 1.41}
 47%|████▋     | 2130/4545 [2:18:06<2:34:32,  3.84s/it] 47%|████▋     | 2131/4545 [2:18:10<2:35:09,  3.86s/it] 47%|████▋     | 2132/4545 [2:18:13<2:32:08,  3.78s/it] 47%|████▋     | 2133/4545 [2:18:17<2:33:33,  3.82s/it] 47%|████▋     | 2134/4545 [2:18:21<2:34:42,  3.85s/it] 47%|████▋     | 2135/4545 [2:18:25<2:35:32,  3.87s/it] 47%|████▋     | 2136/4545 [2:18:29<2:36:00,  3.89s/it] 47%|████▋     | 2137/4545 [2:18:33<2:34:50,  3.86s/it] 47%|████▋     | 2138/4545 [2:18:37<2:35:35,  3.88s/it] 47%|████▋     | 2139/4545 [2:18:40<2:26:02,  3.64s/it] 47%|████▋     | 2140/4545 [2:18:44<2:28:44,  3.71s/it]                                                       {'loss': 0.2325, 'grad_norm': 21.790647506713867, 'learning_rate': 3.6353390291672485e-07, 'rewards/chosen': 4.876562595367432, 'rewards/rejected': -3.251171827316284, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.120312690734863, 'logps/chosen': -490.0, 'logps/rejected': -257.1499938964844, 'logits/chosen': -7.165625095367432, 'logits/rejected': -7.065625190734863, 'epoch': 1.41}
 47%|████▋     | 2140/4545 [2:18:44<2:28:44,  3.71s/it] 47%|████▋     | 2141/4545 [2:18:47<2:30:59,  3.77s/it] 47%|████▋     | 2142/4545 [2:18:51<2:32:33,  3.81s/it] 47%|████▋     | 2143/4545 [2:18:54<2:20:44,  3.52s/it] 47%|████▋     | 2144/4545 [2:18:57<2:11:05,  3.28s/it] 47%|████▋     | 2145/4545 [2:19:01<2:18:10,  3.45s/it] 47%|████▋     | 2146/4545 [2:19:05<2:23:50,  3.60s/it] 47%|████▋     | 2147/4545 [2:19:09<2:26:42,  3.67s/it] 47%|████▋     | 2148/4545 [2:19:12<2:29:25,  3.74s/it] 47%|████▋     | 2149/4545 [2:19:16<2:24:35,  3.62s/it] 47%|████▋     | 2150/4545 [2:19:20<2:28:01,  3.71s/it]                                                       {'loss': 0.1949, 'grad_norm': 28.760631561279297, 'learning_rate': 3.624003944309459e-07, 'rewards/chosen': 1.529943823814392, 'rewards/rejected': -5.069531440734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.603125095367432, 'logps/chosen': -220.25, 'logps/rejected': -127.9749984741211, 'logits/chosen': -7.425000190734863, 'logits/rejected': -6.987500190734863, 'epoch': 1.42}
 47%|████▋     | 2150/4545 [2:19:20<2:28:01,  3.71s/it] 47%|████▋     | 2151/4545 [2:19:24<2:33:34,  3.85s/it] 47%|████▋     | 2152/4545 [2:19:28<2:34:27,  3.87s/it] 47%|████▋     | 2153/4545 [2:19:32<2:34:23,  3.87s/it] 47%|████▋     | 2154/4545 [2:19:35<2:24:58,  3.64s/it] 47%|████▋     | 2155/4545 [2:19:39<2:28:06,  3.72s/it] 47%|████▋     | 2156/4545 [2:19:41<2:10:46,  3.28s/it] 47%|████▋     | 2157/4545 [2:19:45<2:19:42,  3.51s/it] 47%|████▋     | 2158/4545 [2:19:49<2:24:23,  3.63s/it] 48%|████▊     | 2159/4545 [2:19:52<2:15:18,  3.40s/it] 48%|████▊     | 2160/4545 [2:19:56<2:21:28,  3.56s/it]                                                       {'loss': 0.3085, 'grad_norm': 36.529327392578125, 'learning_rate': 3.612515879268407e-07, 'rewards/chosen': 3.2206878662109375, 'rewards/rejected': -3.696093797683716, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 6.920312404632568, 'logps/chosen': -349.8500061035156, 'logps/rejected': -166.64999389648438, 'logits/chosen': -7.128125190734863, 'logits/rejected': -6.846875190734863, 'epoch': 1.43}
 48%|████▊     | 2160/4545 [2:19:56<2:21:28,  3.56s/it] 48%|████▊     | 2161/4545 [2:19:59<2:20:30,  3.54s/it] 48%|████▊     | 2162/4545 [2:20:03<2:24:46,  3.65s/it] 48%|████▊     | 2163/4545 [2:20:07<2:30:18,  3.79s/it] 48%|████▊     | 2164/4545 [2:20:11<2:31:35,  3.82s/it] 48%|████▊     | 2165/4545 [2:20:15<2:35:08,  3.91s/it] 48%|████▊     | 2166/4545 [2:20:19<2:34:28,  3.90s/it] 48%|████▊     | 2167/4545 [2:20:22<2:21:36,  3.57s/it] 48%|████▊     | 2168/4545 [2:20:26<2:25:43,  3.68s/it] 48%|████▊     | 2169/4545 [2:20:30<2:28:02,  3.74s/it] 48%|████▊     | 2170/4545 [2:20:33<2:25:45,  3.68s/it]                                                       {'loss': 0.3155, 'grad_norm': 27.148818969726562, 'learning_rate': 3.600876068202398e-07, 'rewards/chosen': 2.392382860183716, 'rewards/rejected': -4.203125, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 6.589062690734863, 'logps/chosen': -271.8500061035156, 'logps/rejected': -139.5, 'logits/chosen': -7.484375, 'logits/rejected': -7.34375, 'epoch': 1.43}
 48%|████▊     | 2170/4545 [2:20:33<2:25:45,  3.68s/it] 48%|████▊     | 2171/4545 [2:20:37<2:28:44,  3.76s/it] 48%|████▊     | 2172/4545 [2:20:41<2:34:04,  3.90s/it] 48%|████▊     | 2173/4545 [2:20:45<2:29:02,  3.77s/it] 48%|████▊     | 2174/4545 [2:20:49<2:30:33,  3.81s/it] 48%|████▊     | 2175/4545 [2:20:52<2:25:20,  3.68s/it] 48%|████▊     | 2176/4545 [2:20:56<2:29:22,  3.78s/it] 48%|████▊     | 2177/4545 [2:21:00<2:30:44,  3.82s/it] 48%|████▊     | 2178/4545 [2:21:04<2:31:42,  3.85s/it] 48%|████▊     | 2179/4545 [2:21:07<2:20:49,  3.57s/it] 48%|████▊     | 2180/4545 [2:21:11<2:24:42,  3.67s/it]                                                       {'loss': 0.1995, 'grad_norm': 9.336057662963867, 'learning_rate': 3.589085761571753e-07, 'rewards/chosen': 3.212176561355591, 'rewards/rejected': -4.362500190734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 7.584374904632568, 'logps/chosen': -327.45001220703125, 'logps/rejected': -156.25, 'logits/chosen': -7.400000095367432, 'logits/rejected': -7.068749904632568, 'epoch': 1.44}
 48%|████▊     | 2180/4545 [2:21:11<2:24:42,  3.67s/it] 48%|████▊     | 2181/4545 [2:21:15<2:27:42,  3.75s/it] 48%|████▊     | 2182/4545 [2:21:18<2:26:13,  3.71s/it] 48%|████▊     | 2183/4545 [2:21:22<2:30:11,  3.82s/it] 48%|████▊     | 2184/4545 [2:21:26<2:31:13,  3.84s/it] 48%|████▊     | 2185/4545 [2:21:31<2:35:18,  3.95s/it] 48%|████▊     | 2186/4545 [2:21:34<2:35:13,  3.95s/it] 48%|████▊     | 2187/4545 [2:21:38<2:34:40,  3.94s/it] 48%|████▊     | 2188/4545 [2:21:42<2:27:57,  3.77s/it] 48%|████▊     | 2189/4545 [2:21:45<2:25:41,  3.71s/it] 48%|████▊     | 2190/4545 [2:21:49<2:21:22,  3.60s/it]                                                       {'loss': 0.2301, 'grad_norm': 17.29457664489746, 'learning_rate': 3.5771462260044734e-07, 'rewards/chosen': 2.201953172683716, 'rewards/rejected': -4.599999904632568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 6.803124904632568, 'logps/chosen': -241.35000610351562, 'logps/rejected': -184.9499969482422, 'logits/chosen': -7.474999904632568, 'logits/rejected': -7.021874904632568, 'epoch': 1.45}
 48%|████▊     | 2190/4545 [2:21:49<2:21:22,  3.60s/it] 48%|████▊     | 2191/4545 [2:21:53<2:24:54,  3.69s/it] 48%|████▊     | 2192/4545 [2:21:57<2:27:28,  3.76s/it] 48%|████▊     | 2193/4545 [2:22:00<2:28:14,  3.78s/it] 48%|████▊     | 2194/4545 [2:22:04<2:31:56,  3.88s/it] 48%|████▊     | 2195/4545 [2:22:08<2:32:07,  3.88s/it] 48%|████▊     | 2196/4545 [2:22:12<2:32:12,  3.89s/it] 48%|████▊     | 2197/4545 [2:22:16<2:32:16,  3.89s/it] 48%|████▊     | 2198/4545 [2:22:20<2:32:24,  3.90s/it] 48%|████▊     | 2199/4545 [2:22:24<2:29:42,  3.83s/it] 48%|████▊     | 2200/4545 [2:22:28<2:30:08,  3.84s/it]                                                       {'loss': 0.2168, 'grad_norm': 25.891090393066406, 'learning_rate': 3.565058744160166e-07, 'rewards/chosen': 4.158984184265137, 'rewards/rejected': -4.9296875, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 9.096875190734863, 'logps/chosen': -429.29998779296875, 'logps/rejected': -256.79998779296875, 'logits/chosen': -6.893750190734863, 'logits/rejected': -6.637499809265137, 'epoch': 1.45}
 48%|████▊     | 2200/4545 [2:22:28<2:30:08,  3.84s/it] 48%|████▊     | 2201/4545 [2:22:31<2:22:43,  3.65s/it] 48%|████▊     | 2202/4545 [2:22:34<2:18:46,  3.55s/it] 48%|████▊     | 2203/4545 [2:22:37<2:12:46,  3.40s/it] 48%|████▊     | 2204/4545 [2:22:41<2:15:53,  3.48s/it] 49%|████▊     | 2205/4545 [2:22:45<2:24:14,  3.70s/it] 49%|████▊     | 2206/4545 [2:22:49<2:22:53,  3.67s/it] 49%|████▊     | 2207/4545 [2:22:53<2:25:36,  3.74s/it] 49%|████▊     | 2208/4545 [2:22:57<2:30:25,  3.86s/it] 49%|████▊     | 2209/4545 [2:23:01<2:30:30,  3.87s/it] 49%|████▊     | 2210/4545 [2:23:04<2:30:32,  3.87s/it]                                                       {'loss': 0.2849, 'grad_norm': 48.91133499145508, 'learning_rate': 3.5528246145922465e-07, 'rewards/chosen': 1.43115234375, 'rewards/rejected': -5.432812690734863, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 6.860937595367432, 'logps/chosen': -230.9250030517578, 'logps/rejected': -150.5500030517578, 'logits/chosen': -7.456250190734863, 'logits/rejected': -6.993750095367432, 'epoch': 1.46}
 49%|████▊     | 2210/4545 [2:23:04<2:30:32,  3.87s/it] 49%|████▊     | 2211/4545 [2:23:08<2:30:59,  3.88s/it] 49%|████▊     | 2212/4545 [2:23:12<2:31:16,  3.89s/it] 49%|████▊     | 2213/4545 [2:23:16<2:32:06,  3.91s/it] 49%|████▊     | 2214/4545 [2:23:20<2:30:41,  3.88s/it] 49%|████▊     | 2215/4545 [2:23:23<2:25:37,  3.75s/it] 49%|████▉     | 2216/4545 [2:23:27<2:27:24,  3.80s/it] 49%|████▉     | 2217/4545 [2:23:31<2:30:33,  3.88s/it] 49%|████▉     | 2218/4545 [2:23:35<2:30:36,  3.88s/it] 49%|████▉     | 2219/4545 [2:23:39<2:30:44,  3.89s/it] 49%|████▉     | 2220/4545 [2:23:43<2:30:55,  3.89s/it]                                                       {'loss': 0.2676, 'grad_norm': 14.821534156799316, 'learning_rate': 3.5404451516084407e-07, 'rewards/chosen': 3.0736327171325684, 'rewards/rejected': -4.806640625, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 7.896874904632568, 'logps/chosen': -317.95001220703125, 'logps/rejected': -189.0, 'logits/chosen': -7.25, 'logits/rejected': -7.040625095367432, 'epoch': 1.47}
 49%|████▉     | 2220/4545 [2:23:43<2:30:55,  3.89s/it] 49%|████▉     | 2221/4545 [2:23:47<2:28:15,  3.83s/it] 49%|████▉     | 2222/4545 [2:23:50<2:25:02,  3.75s/it] 49%|████▉     | 2223/4545 [2:23:54<2:26:44,  3.79s/it] 49%|████▉     | 2224/4545 [2:23:58<2:28:04,  3.83s/it] 49%|████▉     | 2225/4545 [2:24:02<2:29:04,  3.86s/it] 49%|████▉     | 2226/4545 [2:24:06<2:29:26,  3.87s/it] 49%|████▉     | 2227/4545 [2:24:10<2:26:46,  3.80s/it] 49%|████▉     | 2228/4545 [2:24:14<2:27:54,  3.83s/it] 49%|████▉     | 2229/4545 [2:24:16<2:14:19,  3.48s/it] 49%|████▉     | 2230/4545 [2:24:20<2:19:25,  3.61s/it]                                                       {'loss': 0.2022, 'grad_norm': 55.19499588012695, 'learning_rate': 3.527921685129584e-07, 'rewards/chosen': 3.766308546066284, 'rewards/rejected': -4.702734470367432, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 8.482812881469727, 'logps/chosen': -379.8999938964844, 'logps/rejected': -228.60000610351562, 'logits/chosen': -7.159375190734863, 'logits/rejected': -6.699999809265137, 'epoch': 1.47}
 49%|████▉     | 2230/4545 [2:24:20<2:19:25,  3.61s/it] 49%|████▉     | 2231/4545 [2:24:24<2:22:23,  3.69s/it] 49%|████▉     | 2232/4545 [2:24:28<2:22:11,  3.69s/it] 49%|████▉     | 2233/4545 [2:24:32<2:25:36,  3.78s/it] 49%|████▉     | 2234/4545 [2:24:36<2:27:02,  3.82s/it] 49%|████▉     | 2235/4545 [2:24:39<2:18:55,  3.61s/it] 49%|████▉     | 2236/4545 [2:24:43<2:26:10,  3.80s/it] 49%|████▉     | 2237/4545 [2:24:47<2:27:26,  3.83s/it] 49%|████▉     | 2238/4545 [2:24:51<2:28:15,  3.86s/it] 49%|████▉     | 2239/4545 [2:24:55<2:28:55,  3.87s/it] 49%|████▉     | 2240/4545 [2:24:57<2:15:16,  3.52s/it]                                                       {'loss': 0.154, 'grad_norm': 22.756433486938477, 'learning_rate': 3.51525556054675e-07, 'rewards/chosen': 3.5541014671325684, 'rewards/rejected': -4.014843940734863, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 7.564062595367432, 'logps/chosen': -316.54998779296875, 'logps/rejected': -175.0, 'logits/chosen': -7.300000190734863, 'logits/rejected': -7.043749809265137, 'epoch': 1.48}
 49%|████▉     | 2240/4545 [2:24:57<2:15:16,  3.52s/it] 49%|████▉     | 2241/4545 [2:25:01<2:19:11,  3.62s/it] 49%|████▉     | 2242/4545 [2:25:04<2:14:26,  3.50s/it] 49%|████▉     | 2243/4545 [2:25:08<2:15:41,  3.54s/it] 49%|████▉     | 2244/4545 [2:25:11<2:03:12,  3.21s/it] 49%|████▉     | 2245/4545 [2:25:14<2:10:56,  3.42s/it] 49%|████▉     | 2246/4545 [2:25:18<2:17:36,  3.59s/it] 49%|████▉     | 2247/4545 [2:25:22<2:21:11,  3.69s/it] 49%|████▉     | 2248/4545 [2:25:26<2:23:17,  3.74s/it] 49%|████▉     | 2249/4545 [2:25:30<2:25:54,  3.81s/it] 50%|████▉     | 2250/4545 [2:25:34<2:30:45,  3.94s/it]                                                       {'loss': 0.2561, 'grad_norm': 24.924375534057617, 'learning_rate': 3.50244813857672e-07, 'rewards/chosen': 2.616503953933716, 'rewards/rejected': -5.363085746765137, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 7.978125095367432, 'logps/chosen': -290.8500061035156, 'logps/rejected': -191.85000610351562, 'logits/chosen': -7.303124904632568, 'logits/rejected': -6.993750095367432, 'epoch': 1.49}
 50%|████▉     | 2250/4545 [2:25:34<2:30:45,  3.94s/it] 50%|████▉     | 2251/4545 [2:25:39<2:32:19,  3.98s/it] 50%|████▉     | 2252/4545 [2:25:42<2:31:29,  3.96s/it] 50%|████▉     | 2253/4545 [2:25:46<2:24:03,  3.77s/it] 50%|████▉     | 2254/4545 [2:25:50<2:25:41,  3.82s/it] 50%|████▉     | 2255/4545 [2:25:53<2:18:20,  3.62s/it] 50%|████▉     | 2256/4545 [2:25:57<2:21:07,  3.70s/it] 50%|████▉     | 2257/4545 [2:26:01<2:25:15,  3.81s/it] 50%|████▉     | 2258/4545 [2:26:05<2:25:21,  3.81s/it] 50%|████▉     | 2259/4545 [2:26:09<2:26:26,  3.84s/it] 50%|████▉     | 2260/4545 [2:26:12<2:26:56,  3.86s/it]                                                       {'loss': 0.2511, 'grad_norm': 16.420536041259766, 'learning_rate': 3.489500795115793e-07, 'rewards/chosen': 2.577929735183716, 'rewards/rejected': -4.387499809265137, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 6.959374904632568, 'logps/chosen': -299.6499938964844, 'logps/rejected': -195.5, 'logits/chosen': -7.412499904632568, 'logits/rejected': -7.056250095367432, 'epoch': 1.49}
 50%|████▉     | 2260/4545 [2:26:12<2:26:56,  3.86s/it] 50%|████▉     | 2261/4545 [2:26:15<2:16:59,  3.60s/it] 50%|████▉     | 2262/4545 [2:26:19<2:19:55,  3.68s/it] 50%|████▉     | 2263/4545 [2:26:24<2:26:12,  3.84s/it] 50%|████▉     | 2264/4545 [2:26:28<2:28:21,  3.90s/it] 50%|████▉     | 2265/4545 [2:26:31<2:24:53,  3.81s/it] 50%|████▉     | 2266/4545 [2:26:35<2:24:53,  3.81s/it] 50%|████▉     | 2267/4545 [2:26:39<2:26:14,  3.85s/it] 50%|████▉     | 2268/4545 [2:26:42<2:13:47,  3.53s/it] 50%|████▉     | 2269/4545 [2:26:46<2:21:18,  3.73s/it] 50%|████▉     | 2270/4545 [2:26:49<2:19:58,  3.69s/it]                                                       {'loss': 0.2068, 'grad_norm': 38.6682014465332, 'learning_rate': 3.476414921091983e-07, 'rewards/chosen': 0.844677746295929, 'rewards/rejected': -5.984375, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.8359375, 'logps/chosen': -173.5500030517578, 'logps/rejected': -132.5, 'logits/chosen': -7.518750190734863, 'logits/rejected': -7.140625, 'epoch': 1.5}
 50%|████▉     | 2270/4545 [2:26:49<2:19:58,  3.69s/it] 50%|████▉     | 2271/4545 [2:26:54<2:24:37,  3.82s/it] 50%|████▉     | 2272/4545 [2:26:56<2:11:24,  3.47s/it] 50%|█████     | 2273/4545 [2:27:00<2:14:49,  3.56s/it] 50%|█████     | 2274/4545 [2:27:03<2:09:58,  3.43s/it] 50%|█████     | 2275/4545 [2:27:07<2:16:56,  3.62s/it] 50%|█████     | 2276/4545 [2:27:11<2:13:39,  3.53s/it] 50%|█████     | 2277/4545 [2:27:14<2:17:35,  3.64s/it] 50%|█████     | 2278/4545 [2:27:18<2:17:47,  3.65s/it] 50%|█████     | 2279/4545 [2:27:22<2:21:27,  3.75s/it] 50%|█████     | 2280/4545 [2:27:26<2:22:57,  3.79s/it]                                                       {'loss': 0.3818, 'grad_norm': 25.059457778930664, 'learning_rate': 3.463191922315583e-07, 'rewards/chosen': 1.1503417491912842, 'rewards/rejected': -4.672656059265137, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 5.817187309265137, 'logps/chosen': -209.8000030517578, 'logps/rejected': -115.25, 'logits/chosen': -7.449999809265137, 'logits/rejected': -7.199999809265137, 'epoch': 1.5}
 50%|█████     | 2280/4545 [2:27:26<2:22:57,  3.79s/it] 50%|█████     | 2281/4545 [2:27:30<2:24:23,  3.83s/it] 50%|█████     | 2282/4545 [2:27:33<2:17:35,  3.65s/it] 50%|█████     | 2283/4545 [2:27:37<2:20:40,  3.73s/it] 50%|█████     | 2284/4545 [2:27:41<2:22:51,  3.79s/it] 50%|█████     | 2285/4545 [2:27:44<2:18:09,  3.67s/it] 50%|█████     | 2286/4545 [2:27:48<2:20:57,  3.74s/it] 50%|█████     | 2287/4545 [2:27:52<2:23:05,  3.80s/it] 50%|█████     | 2288/4545 [2:27:56<2:24:15,  3.83s/it] 50%|█████     | 2289/4545 [2:28:00<2:25:01,  3.86s/it] 50%|█████     | 2290/4545 [2:28:04<2:25:26,  3.87s/it]                                                       {'loss': 0.2326, 'grad_norm': 25.470869064331055, 'learning_rate': 3.449833219328149e-07, 'rewards/chosen': 4.569872856140137, 'rewards/rejected': -4.537499904632568, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 9.109375, 'logps/chosen': -430.70001220703125, 'logps/rejected': -249.9499969482422, 'logits/chosen': -7.25, 'logits/rejected': -7.0, 'epoch': 1.51}
 50%|█████     | 2290/4545 [2:28:04<2:25:26,  3.87s/it] 50%|█████     | 2291/4545 [2:28:07<2:20:40,  3.74s/it] 50%|█████     | 2292/4545 [2:28:11<2:17:11,  3.65s/it] 50%|█████     | 2293/4545 [2:28:15<2:22:45,  3.80s/it] 50%|█████     | 2294/4545 [2:28:19<2:24:16,  3.85s/it] 50%|█████     | 2295/4545 [2:28:23<2:24:48,  3.86s/it] 51%|█████     | 2296/4545 [2:28:27<2:24:51,  3.86s/it] 51%|█████     | 2297/4545 [2:28:30<2:21:58,  3.79s/it] 51%|█████     | 2298/4545 [2:28:34<2:25:08,  3.88s/it] 51%|█████     | 2299/4545 [2:28:38<2:25:09,  3.88s/it] 51%|█████     | 2300/4545 [2:28:42<2:27:31,  3.94s/it]                                                       {'loss': 0.223, 'grad_norm': 32.806758880615234, 'learning_rate': 3.436340247249886e-07, 'rewards/chosen': 3.831787109375, 'rewards/rejected': -4.931836128234863, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.753125190734863, 'logps/chosen': -399.04998779296875, 'logps/rejected': -215.8000030517578, 'logits/chosen': -7.224999904632568, 'logits/rejected': -6.918749809265137, 'epoch': 1.52}
 51%|█████     | 2300/4545 [2:28:42<2:27:31,  3.94s/it] 51%|█████     | 2301/4545 [2:28:46<2:29:10,  3.99s/it] 51%|█████     | 2302/4545 [2:28:50<2:28:11,  3.96s/it] 51%|█████     | 2303/4545 [2:28:54<2:26:34,  3.92s/it] 51%|█████     | 2304/4545 [2:28:57<2:18:27,  3.71s/it] 51%|█████     | 2305/4545 [2:29:01<2:16:56,  3.67s/it] 51%|█████     | 2306/4545 [2:29:04<2:14:10,  3.60s/it] 51%|█████     | 2307/4545 [2:29:08<2:17:36,  3.69s/it] 51%|█████     | 2308/4545 [2:29:12<2:19:43,  3.75s/it] 51%|█████     | 2309/4545 [2:29:16<2:18:55,  3.73s/it] 51%|█████     | 2310/4545 [2:29:19<2:14:14,  3.60s/it]                                                       {'loss': 0.3641, 'grad_norm': 40.04753112792969, 'learning_rate': 3.4227144556254715e-07, 'rewards/chosen': 2.736132860183716, 'rewards/rejected': -3.596874952316284, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 6.328125, 'logps/chosen': -292.8999938964844, 'logps/rejected': -196.8000030517578, 'logits/chosen': -7.393750190734863, 'logits/rejected': -6.940625190734863, 'epoch': 1.52}
 51%|█████     | 2310/4545 [2:29:19<2:14:14,  3.60s/it] 51%|█████     | 2311/4545 [2:29:23<2:17:07,  3.68s/it] 51%|█████     | 2312/4545 [2:29:27<2:19:26,  3.75s/it] 51%|█████     | 2313/4545 [2:29:31<2:20:43,  3.78s/it] 51%|█████     | 2314/4545 [2:29:34<2:17:49,  3.71s/it] 51%|█████     | 2315/4545 [2:29:39<2:23:00,  3.85s/it] 51%|█████     | 2316/4545 [2:29:42<2:23:30,  3.86s/it] 51%|█████     | 2317/4545 [2:29:46<2:18:49,  3.74s/it] 51%|█████     | 2318/4545 [2:29:50<2:20:52,  3.80s/it] 51%|█████     | 2319/4545 [2:29:54<2:24:44,  3.90s/it] 51%|█████     | 2320/4545 [2:29:58<2:25:47,  3.93s/it]                                                       {'loss': 0.2528, 'grad_norm': 31.213090896606445, 'learning_rate': 3.408957308268338e-07, 'rewards/chosen': 4.555859565734863, 'rewards/rejected': -4.0, 'rewards/accuracies': 0.875, 'rewards/margins': 8.557812690734863, 'logps/chosen': -422.3999938964844, 'logps/rejected': -267.3500061035156, 'logits/chosen': -7.212500095367432, 'logits/rejected': -6.803124904632568, 'epoch': 1.53}
 51%|█████     | 2320/4545 [2:29:58<2:25:47,  3.93s/it] 51%|█████     | 2321/4545 [2:30:01<2:21:28,  3.82s/it] 51%|█████     | 2322/4545 [2:30:05<2:22:20,  3.84s/it] 51%|█████     | 2323/4545 [2:30:09<2:23:07,  3.86s/it] 51%|█████     | 2324/4545 [2:30:13<2:23:11,  3.87s/it] 51%|█████     | 2325/4545 [2:30:17<2:23:56,  3.89s/it] 51%|█████     | 2326/4545 [2:30:21<2:26:58,  3.97s/it] 51%|█████     | 2327/4545 [2:30:25<2:26:33,  3.96s/it] 51%|█████     | 2328/4545 [2:30:29<2:25:41,  3.94s/it] 51%|█████     | 2329/4545 [2:30:33<2:29:34,  4.05s/it] 51%|█████▏    | 2330/4545 [2:30:37<2:27:57,  4.01s/it]                                                       {'loss': 0.2419, 'grad_norm': 17.528528213500977, 'learning_rate': 3.395070283103412e-07, 'rewards/chosen': 5.022607326507568, 'rewards/rejected': -4.169531345367432, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 9.193750381469727, 'logps/chosen': -481.54998779296875, 'logps/rejected': -265.3999938964844, 'logits/chosen': -6.965624809265137, 'logits/rejected': -6.746874809265137, 'epoch': 1.54}
 51%|█████▏    | 2330/4545 [2:30:37<2:27:57,  4.01s/it] 51%|█████▏    | 2331/4545 [2:30:41<2:26:52,  3.98s/it] 51%|█████▏    | 2332/4545 [2:30:45<2:25:29,  3.94s/it] 51%|█████▏    | 2333/4545 [2:30:49<2:26:40,  3.98s/it] 51%|█████▏    | 2334/4545 [2:30:52<2:16:44,  3.71s/it] 51%|█████▏    | 2335/4545 [2:30:56<2:18:48,  3.77s/it] 51%|█████▏    | 2336/4545 [2:30:59<2:12:57,  3.61s/it] 51%|█████▏    | 2337/4545 [2:31:02<1:58:15,  3.21s/it] 51%|█████▏    | 2338/4545 [2:31:06<2:07:08,  3.46s/it] 51%|█████▏    | 2339/4545 [2:31:10<2:12:15,  3.60s/it] 51%|█████▏    | 2340/4545 [2:31:14<2:15:41,  3.69s/it]                                                       {'loss': 0.1907, 'grad_norm': 39.270957946777344, 'learning_rate': 3.3810548720083394e-07, 'rewards/chosen': 2.695019483566284, 'rewards/rejected': -5.008984565734863, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 7.701562404632568, 'logps/chosen': -281.04998779296875, 'logps/rejected': -192.1999969482422, 'logits/chosen': -7.496874809265137, 'logits/rejected': -7.118750095367432, 'epoch': 1.54}
 51%|█████▏    | 2340/4545 [2:31:14<2:15:41,  3.69s/it] 52%|█████▏    | 2341/4545 [2:31:17<2:17:53,  3.75s/it] 52%|█████▏    | 2342/4545 [2:31:22<2:21:24,  3.85s/it] 52%|█████▏    | 2343/4545 [2:31:26<2:23:47,  3.92s/it] 52%|█████▏    | 2344/4545 [2:31:30<2:23:38,  3.92s/it] 52%|█████▏    | 2345/4545 [2:31:33<2:23:32,  3.91s/it] 52%|█████▏    | 2346/4545 [2:31:37<2:23:34,  3.92s/it] 52%|█████▏    | 2347/4545 [2:31:41<2:25:33,  3.97s/it] 52%|█████▏    | 2348/4545 [2:31:45<2:25:17,  3.97s/it] 52%|█████▏    | 2349/4545 [2:31:49<2:24:34,  3.95s/it] 52%|█████▏    | 2350/4545 [2:31:53<2:21:15,  3.86s/it]                                                       {'loss': 0.1913, 'grad_norm': 54.862998962402344, 'learning_rate': 3.366912580653219e-07, 'rewards/chosen': 3.319580078125, 'rewards/rejected': -5.030908107757568, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.359375, 'logps/chosen': -355.45001220703125, 'logps/rejected': -234.10000610351562, 'logits/chosen': -7.309374809265137, 'logits/rejected': -6.806250095367432, 'epoch': 1.55}
 52%|█████▏    | 2350/4545 [2:31:53<2:21:15,  3.86s/it] 52%|█████▏    | 2351/4545 [2:31:57<2:21:21,  3.87s/it] 52%|█████▏    | 2352/4545 [2:32:01<2:19:25,  3.81s/it] 52%|█████▏    | 2353/4545 [2:32:03<2:08:23,  3.51s/it] 52%|█████▏    | 2354/4545 [2:32:08<2:15:41,  3.72s/it] 52%|█████▏    | 2355/4545 [2:32:11<2:16:51,  3.75s/it] 52%|█████▏    | 2356/4545 [2:32:16<2:21:34,  3.88s/it] 52%|█████▏    | 2357/4545 [2:32:18<2:08:37,  3.53s/it] 52%|█████▏    | 2358/4545 [2:32:22<2:09:18,  3.55s/it] 52%|█████▏    | 2359/4545 [2:32:26<2:13:01,  3.65s/it] 52%|█████▏    | 2360/4545 [2:32:28<2:03:06,  3.38s/it]                                                       {'loss': 0.2155, 'grad_norm': 11.866226196289062, 'learning_rate': 3.3526449283388455e-07, 'rewards/chosen': 0.7958984375, 'rewards/rejected': -6.171875, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 6.967187404632568, 'logps/chosen': -158.4499969482422, 'logps/rejected': -133.39999389648438, 'logits/chosen': -7.578125, 'logits/rejected': -7.09375, 'epoch': 1.56}
 52%|█████▏    | 2360/4545 [2:32:29<2:03:06,  3.38s/it] 52%|█████▏    | 2361/4545 [2:32:32<2:09:01,  3.54s/it] 52%|█████▏    | 2362/4545 [2:32:36<2:12:45,  3.65s/it] 52%|█████▏    | 2363/4545 [2:32:39<2:06:20,  3.47s/it] 52%|█████▏    | 2364/4545 [2:32:43<2:10:39,  3.59s/it] 52%|█████▏    | 2365/4545 [2:32:46<2:05:44,  3.46s/it] 52%|█████▏    | 2366/4545 [2:32:51<2:13:13,  3.67s/it] 52%|█████▏    | 2367/4545 [2:32:53<1:58:59,  3.28s/it] 52%|█████▏    | 2368/4545 [2:32:57<2:06:21,  3.48s/it] 52%|█████▏    | 2369/4545 [2:33:01<2:12:23,  3.65s/it] 52%|█████▏    | 2370/4545 [2:33:03<1:59:04,  3.28s/it]                                                       {'loss': 0.2242, 'grad_norm': 11.729334831237793, 'learning_rate': 3.3382534478334895e-07, 'rewards/chosen': 2.231372117996216, 'rewards/rejected': -4.421093940734863, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 6.653124809265137, 'logps/chosen': -237.60000610351562, 'logps/rejected': -184.39999389648438, 'logits/chosen': -7.525000095367432, 'logits/rejected': -7.190625190734863, 'epoch': 1.56}
 52%|█████▏    | 2370/4545 [2:33:03<1:59:04,  3.28s/it] 52%|█████▏    | 2371/4545 [2:33:07<2:06:47,  3.50s/it] 52%|█████▏    | 2372/4545 [2:33:11<2:13:04,  3.67s/it] 52%|█████▏    | 2373/4545 [2:33:15<2:14:21,  3.71s/it] 52%|█████▏    | 2374/4545 [2:33:18<2:04:48,  3.45s/it] 52%|█████▏    | 2375/4545 [2:33:22<2:04:42,  3.45s/it] 52%|█████▏    | 2376/4545 [2:33:25<2:09:44,  3.59s/it] 52%|█████▏    | 2377/4545 [2:33:29<2:14:44,  3.73s/it] 52%|█████▏    | 2378/4545 [2:33:34<2:18:53,  3.85s/it] 52%|█████▏    | 2379/4545 [2:33:37<2:17:38,  3.81s/it] 52%|█████▏    | 2380/4545 [2:33:41<2:18:37,  3.84s/it]                                                       {'loss': 0.1646, 'grad_norm': 23.014142990112305, 'learning_rate': 3.323739685208239e-07, 'rewards/chosen': 1.546875, 'rewards/rejected': -7.8359375, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.379687309265137, 'logps/chosen': -231.10000610351562, 'logps/rejected': -168.35000610351562, 'logits/chosen': -7.328125, 'logits/rejected': -6.987500190734863, 'epoch': 1.57}
 52%|█████▏    | 2380/4545 [2:33:41<2:18:37,  3.84s/it] 52%|█████▏    | 2381/4545 [2:33:44<2:08:36,  3.57s/it] 52%|█████▏    | 2382/4545 [2:33:48<2:12:07,  3.66s/it] 52%|█████▏    | 2383/4545 [2:33:52<2:16:29,  3.79s/it] 52%|█████▏    | 2384/4545 [2:33:56<2:19:47,  3.88s/it] 52%|█████▏    | 2385/4545 [2:33:59<2:12:08,  3.67s/it] 52%|█████▏    | 2386/4545 [2:34:03<2:08:18,  3.57s/it] 53%|█████▎    | 2387/4545 [2:34:07<2:12:16,  3.68s/it] 53%|█████▎    | 2388/4545 [2:34:11<2:14:23,  3.74s/it] 53%|█████▎    | 2389/4545 [2:34:14<2:15:38,  3.77s/it] 53%|█████▎    | 2390/4545 [2:34:18<2:14:54,  3.76s/it]                                                       {'loss': 0.2348, 'grad_norm': 61.8569450378418, 'learning_rate': 3.309105199670899e-07, 'rewards/chosen': 3.145703077316284, 'rewards/rejected': -4.5546875, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 7.6875, 'logps/chosen': -299.1499938964844, 'logps/rejected': -233.9499969482422, 'logits/chosen': -7.349999904632568, 'logits/rejected': -7.150000095367432, 'epoch': 1.58}
 53%|█████▎    | 2390/4545 [2:34:18<2:14:54,  3.76s/it] 53%|█████▎    | 2391/4545 [2:34:22<2:12:36,  3.69s/it] 53%|█████▎    | 2392/4545 [2:34:25<2:10:49,  3.65s/it] 53%|█████▎    | 2393/4545 [2:34:29<2:09:05,  3.60s/it] 53%|█████▎    | 2394/4545 [2:34:33<2:14:05,  3.74s/it] 53%|█████▎    | 2395/4545 [2:34:37<2:15:45,  3.79s/it] 53%|█████▎    | 2396/4545 [2:34:40<2:09:33,  3.62s/it] 53%|█████▎    | 2397/4545 [2:34:43<2:07:22,  3.56s/it] 53%|█████▎    | 2398/4545 [2:34:46<2:02:22,  3.42s/it] 53%|█████▎    | 2399/4545 [2:34:50<2:08:15,  3.59s/it] 53%|█████▎    | 2400/4545 [2:34:55<2:15:14,  3.78s/it]                                                       {'loss': 0.2243, 'grad_norm': 46.38265609741211, 'learning_rate': 3.294351563398492e-07, 'rewards/chosen': 2.2041015625, 'rewards/rejected': -5.549218654632568, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 7.7578125, 'logps/chosen': -240.9499969482422, 'logps/rejected': -165.64999389648438, 'logits/chosen': -7.493750095367432, 'logits/rejected': -7.287499904632568, 'epoch': 1.58}
 53%|█████▎    | 2400/4545 [2:34:55<2:15:14,  3.78s/it] 53%|█████▎    | 2401/4545 [2:34:59<2:17:06,  3.84s/it] 53%|█████▎    | 2402/4545 [2:35:03<2:17:51,  3.86s/it] 53%|█████▎    | 2403/4545 [2:35:06<2:18:28,  3.88s/it] 53%|█████▎    | 2404/4545 [2:35:10<2:18:47,  3.89s/it] 53%|█████▎    | 2405/4545 [2:35:14<2:19:00,  3.90s/it] 53%|█████▎    | 2406/4545 [2:35:18<2:18:05,  3.87s/it] 53%|█████▎    | 2407/4545 [2:35:21<2:09:00,  3.62s/it] 53%|█████▎    | 2408/4545 [2:35:25<2:11:16,  3.69s/it] 53%|█████▎    | 2409/4545 [2:35:29<2:16:12,  3.83s/it] 53%|█████▎    | 2410/4545 [2:35:33<2:17:00,  3.85s/it]                                                       {'loss': 0.1712, 'grad_norm': 26.669448852539062, 'learning_rate': 3.279480361368355e-07, 'rewards/chosen': 3.6664795875549316, 'rewards/rejected': -6.81640625, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 10.478124618530273, 'logps/chosen': -347.95001220703125, 'logps/rejected': -223.0, 'logits/chosen': -7.481249809265137, 'logits/rejected': -7.018750190734863, 'epoch': 1.59}
 53%|█████▎    | 2410/4545 [2:35:33<2:17:00,  3.85s/it] 53%|█████▎    | 2411/4545 [2:35:37<2:17:00,  3.85s/it] 53%|█████▎    | 2412/4545 [2:35:41<2:17:40,  3.87s/it] 53%|█████▎    | 2413/4545 [2:35:45<2:17:51,  3.88s/it] 53%|█████▎    | 2414/4545 [2:35:49<2:21:19,  3.98s/it] 53%|█████▎    | 2415/4545 [2:35:53<2:19:35,  3.93s/it] 53%|█████▎    | 2416/4545 [2:35:56<2:16:35,  3.85s/it] 53%|█████▎    | 2417/4545 [2:36:00<2:18:51,  3.92s/it] 53%|█████▎    | 2418/4545 [2:36:04<2:18:20,  3.90s/it] 53%|█████▎    | 2419/4545 [2:36:08<2:10:55,  3.70s/it] 53%|█████▎    | 2420/4545 [2:36:11<2:04:46,  3.52s/it]                                                       {'loss': 0.2793, 'grad_norm': 22.141212463378906, 'learning_rate': 3.26449319118787e-07, 'rewards/chosen': 1.4485595226287842, 'rewards/rejected': -5.004492282867432, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 6.453125, 'logps/chosen': -210.3000030517578, 'logps/rejected': -156.60000610351562, 'logits/chosen': -7.587500095367432, 'logits/rejected': -7.162499904632568, 'epoch': 1.6}
 53%|█████▎    | 2420/4545 [2:36:11<2:04:46,  3.52s/it] 53%|█████▎    | 2421/4545 [2:36:14<2:07:31,  3.60s/it] 53%|█████▎    | 2422/4545 [2:36:18<2:10:34,  3.69s/it] 53%|█████▎    | 2423/4545 [2:36:22<2:12:53,  3.76s/it] 53%|█████▎    | 2424/4545 [2:36:26<2:14:30,  3.81s/it] 53%|█████▎    | 2425/4545 [2:36:29<2:04:34,  3.53s/it] 53%|█████▎    | 2426/4545 [2:36:33<2:09:45,  3.67s/it] 53%|█████▎    | 2427/4545 [2:36:37<2:12:07,  3.74s/it] 53%|█████▎    | 2428/4545 [2:36:40<1:59:45,  3.39s/it] 53%|█████▎    | 2429/4545 [2:36:43<2:05:35,  3.56s/it] 53%|█████▎    | 2430/4545 [2:36:47<2:06:29,  3.59s/it]                                                       {'loss': 0.241, 'grad_norm': 30.50579261779785, 'learning_rate': 3.249391662922829e-07, 'rewards/chosen': 2.795605421066284, 'rewards/rejected': -3.893749952316284, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 6.681250095367432, 'logps/chosen': -274.70001220703125, 'logps/rejected': -171.25, 'logits/chosen': -7.456250190734863, 'logits/rejected': -7.234375, 'epoch': 1.6}
 53%|█████▎    | 2430/4545 [2:36:47<2:06:29,  3.59s/it] 53%|█████▎    | 2431/4545 [2:36:51<2:09:25,  3.67s/it] 54%|█████▎    | 2432/4545 [2:36:55<2:11:26,  3.73s/it] 54%|█████▎    | 2433/4545 [2:36:58<2:09:43,  3.69s/it] 54%|█████▎    | 2434/4545 [2:37:03<2:13:28,  3.79s/it] 54%|█████▎    | 2435/4545 [2:37:06<2:05:17,  3.56s/it] 54%|█████▎    | 2436/4545 [2:37:08<1:58:09,  3.36s/it] 54%|█████▎    | 2437/4545 [2:37:12<2:05:30,  3.57s/it] 54%|█████▎    | 2438/4545 [2:37:16<2:07:42,  3.64s/it] 54%|█████▎    | 2439/4545 [2:37:20<2:07:59,  3.65s/it] 54%|█████▎    | 2440/4545 [2:37:24<2:10:06,  3.71s/it]                                                       {'loss': 0.3074, 'grad_norm': 22.640975952148438, 'learning_rate': 3.234177398924471e-07, 'rewards/chosen': 1.4493834972381592, 'rewards/rejected': -5.118261814117432, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 6.578125, 'logps/chosen': -189.9499969482422, 'logps/rejected': -163.4499969482422, 'logits/chosen': -7.703125, 'logits/rejected': -7.353125095367432, 'epoch': 1.61}
 54%|█████▎    | 2440/4545 [2:37:24<2:10:06,  3.71s/it] 54%|█████▎    | 2441/4545 [2:37:28<2:12:45,  3.79s/it] 54%|█████▎    | 2442/4545 [2:37:31<2:10:54,  3.73s/it] 54%|█████▍    | 2443/4545 [2:37:35<2:12:36,  3.79s/it] 54%|█████▍    | 2444/4545 [2:37:39<2:10:22,  3.72s/it] 54%|█████▍    | 2445/4545 [2:37:43<2:11:51,  3.77s/it] 54%|█████▍    | 2446/4545 [2:37:47<2:12:37,  3.79s/it] 54%|█████▍    | 2447/4545 [2:37:50<2:13:49,  3.83s/it] 54%|█████▍    | 2448/4545 [2:37:55<2:16:31,  3.91s/it] 54%|█████▍    | 2449/4545 [2:37:58<2:16:23,  3.90s/it] 54%|█████▍    | 2450/4545 [2:38:02<2:16:22,  3.91s/it]                                                       {'loss': 0.2326, 'grad_norm': 24.541040420532227, 'learning_rate': 3.218852033655189e-07, 'rewards/chosen': 3.1668701171875, 'rewards/rejected': -4.892968654632568, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 8.051562309265137, 'logps/chosen': -331.5, 'logps/rejected': -232.75, 'logits/chosen': -7.446875095367432, 'logits/rejected': -7.143750190734863, 'epoch': 1.62}
 54%|█████▍    | 2450/4545 [2:38:02<2:16:22,  3.91s/it] 54%|█████▍    | 2451/4545 [2:38:06<2:10:15,  3.73s/it] 54%|█████▍    | 2452/4545 [2:38:09<2:06:33,  3.63s/it] 54%|█████▍    | 2453/4545 [2:38:13<2:11:22,  3.77s/it] 54%|█████▍    | 2454/4545 [2:38:17<2:12:34,  3.80s/it] 54%|█████▍    | 2455/4545 [2:38:21<2:13:40,  3.84s/it] 54%|█████▍    | 2456/4545 [2:38:25<2:14:26,  3.86s/it] 54%|█████▍    | 2457/4545 [2:38:29<2:14:13,  3.86s/it] 54%|█████▍    | 2458/4545 [2:38:33<2:14:36,  3.87s/it] 54%|█████▍    | 2459/4545 [2:38:37<2:15:57,  3.91s/it] 54%|█████▍    | 2460/4545 [2:38:41<2:17:02,  3.94s/it]                                                       {'loss': 0.3184, 'grad_norm': 131.35366821289062, 'learning_rate': 3.203417213512942e-07, 'rewards/chosen': 3.99072265625, 'rewards/rejected': -3.921875, 'rewards/accuracies': 0.84375, 'rewards/margins': 7.90625, 'logps/chosen': -381.75, 'logps/rejected': -233.14999389648438, 'logits/chosen': -7.175000190734863, 'logits/rejected': -7.131249904632568, 'epoch': 1.62}
 54%|█████▍    | 2460/4545 [2:38:41<2:17:02,  3.94s/it] 54%|█████▍    | 2461/4545 [2:38:44<2:14:10,  3.86s/it] 54%|█████▍    | 2462/4545 [2:38:47<2:00:07,  3.46s/it] 54%|█████▍    | 2463/4545 [2:38:51<2:05:56,  3.63s/it] 54%|█████▍    | 2464/4545 [2:38:55<2:08:54,  3.72s/it] 54%|█████▍    | 2465/4545 [2:38:58<2:04:50,  3.60s/it] 54%|█████▍    | 2466/4545 [2:39:02<2:05:11,  3.61s/it] 54%|█████▍    | 2467/4545 [2:39:06<2:11:05,  3.79s/it] 54%|█████▍    | 2468/4545 [2:39:10<2:13:36,  3.86s/it] 54%|█████▍    | 2469/4545 [2:39:14<2:13:57,  3.87s/it] 54%|█████▍    | 2470/4545 [2:39:18<2:11:23,  3.80s/it]                                                       {'loss': 0.2401, 'grad_norm': 44.20267868041992, 'learning_rate': 3.1878745966543825e-07, 'rewards/chosen': 1.4713866710662842, 'rewards/rejected': -5.915625095367432, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 7.379687309265137, 'logps/chosen': -206.75, 'logps/rejected': -171.3000030517578, 'logits/chosen': -7.403124809265137, 'logits/rejected': -7.053124904632568, 'epoch': 1.63}
 54%|█████▍    | 2470/4545 [2:39:18<2:11:23,  3.80s/it] 54%|█████▍    | 2471/4545 [2:39:21<2:12:00,  3.82s/it] 54%|█████▍    | 2472/4545 [2:39:25<2:12:47,  3.84s/it] 54%|█████▍    | 2473/4545 [2:39:29<2:12:17,  3.83s/it] 54%|█████▍    | 2474/4545 [2:39:33<2:11:25,  3.81s/it] 54%|█████▍    | 2475/4545 [2:39:37<2:12:42,  3.85s/it] 54%|█████▍    | 2476/4545 [2:39:40<2:07:25,  3.70s/it] 54%|█████▍    | 2477/4545 [2:39:44<2:04:02,  3.60s/it] 55%|█████▍    | 2478/4545 [2:39:47<2:04:08,  3.60s/it] 55%|█████▍    | 2479/4545 [2:39:51<2:02:36,  3.56s/it] 55%|█████▍    | 2480/4545 [2:39:55<2:10:18,  3.79s/it]                                                       {'loss': 0.3247, 'grad_norm': 39.97241973876953, 'learning_rate': 3.172225852816722e-07, 'rewards/chosen': 1.086889624595642, 'rewards/rejected': -4.077343940734863, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 5.165625095367432, 'logps/chosen': -150.89999389648438, 'logps/rejected': -118.75, 'logits/chosen': -7.571875095367432, 'logits/rejected': -7.240624904632568, 'epoch': 1.64}
 55%|█████▍    | 2480/4545 [2:39:55<2:10:18,  3.79s/it] 55%|█████▍    | 2481/4545 [2:39:59<2:16:28,  3.97s/it] 55%|█████▍    | 2482/4545 [2:40:03<2:13:50,  3.89s/it] 55%|█████▍    | 2483/4545 [2:40:07<2:13:30,  3.88s/it] 55%|█████▍    | 2484/4545 [2:40:11<2:13:36,  3.89s/it] 55%|█████▍    | 2485/4545 [2:40:15<2:13:42,  3.89s/it] 55%|█████▍    | 2486/4545 [2:40:17<1:58:48,  3.46s/it] 55%|█████▍    | 2487/4545 [2:40:21<1:59:44,  3.49s/it] 55%|█████▍    | 2488/4545 [2:40:24<1:55:19,  3.36s/it] 55%|█████▍    | 2489/4545 [2:40:27<1:57:20,  3.42s/it] 55%|█████▍    | 2490/4545 [2:40:30<1:54:14,  3.34s/it]                                                       {'loss': 0.3508, 'grad_norm': 31.456439971923828, 'learning_rate': 3.1564726631383527e-07, 'rewards/chosen': 1.6694824695587158, 'rewards/rejected': -6.145312309265137, 'rewards/accuracies': 0.84375, 'rewards/margins': 7.807812690734863, 'logps/chosen': -224.89999389648438, 'logps/rejected': -158.85000610351562, 'logits/chosen': -7.53125, 'logits/rejected': -7.271874904632568, 'epoch': 1.64}
 55%|█████▍    | 2490/4545 [2:40:30<1:54:14,  3.34s/it] 55%|█████▍    | 2491/4545 [2:40:34<2:00:17,  3.51s/it] 55%|█████▍    | 2492/4545 [2:40:38<2:01:27,  3.55s/it] 55%|█████▍    | 2493/4545 [2:40:42<2:04:25,  3.64s/it] 55%|█████▍    | 2494/4545 [2:40:46<2:04:17,  3.64s/it] 55%|█████▍    | 2495/4545 [2:40:49<2:06:31,  3.70s/it] 55%|█████▍    | 2496/4545 [2:40:53<2:08:45,  3.77s/it] 55%|█████▍    | 2497/4545 [2:40:58<2:13:20,  3.91s/it] 55%|█████▍    | 2498/4545 [2:41:01<2:07:27,  3.74s/it] 55%|█████▍    | 2499/4545 [2:41:05<2:09:08,  3.79s/it] 55%|█████▌    | 2500/4545 [2:41:09<2:09:08,  3.79s/it]                                                       {'loss': 0.3426, 'grad_norm': 23.60494613647461, 'learning_rate': 3.140616719978241e-07, 'rewards/chosen': 1.6703002452850342, 'rewards/rejected': -4.239843845367432, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 5.909375190734863, 'logps/chosen': -201.8249969482422, 'logps/rejected': -174.1999969482422, 'logits/chosen': -7.525000095367432, 'logits/rejected': -7.15625, 'epoch': 1.65}
 55%|█████▌    | 2500/4545 [2:41:09<2:09:08,  3.79s/it] 55%|█████▌    | 2501/4545 [2:41:12<2:05:52,  3.69s/it] 55%|█████▌    | 2502/4545 [2:41:16<2:08:18,  3.77s/it] 55%|█████▌    | 2503/4545 [2:41:19<1:59:12,  3.50s/it] 55%|█████▌    | 2504/4545 [2:41:23<2:06:00,  3.70s/it] 55%|█████▌    | 2505/4545 [2:41:27<2:08:09,  3.77s/it] 55%|█████▌    | 2506/4545 [2:41:31<2:09:31,  3.81s/it] 55%|█████▌    | 2507/4545 [2:41:35<2:10:08,  3.83s/it] 55%|█████▌    | 2508/4545 [2:41:39<2:10:27,  3.84s/it] 55%|█████▌    | 2509/4545 [2:41:42<2:03:16,  3.63s/it] 55%|█████▌    | 2510/4545 [2:41:44<1:47:51,  3.18s/it]                                                       {'loss': 0.1961, 'grad_norm': 24.55293083190918, 'learning_rate': 3.124659726734119e-07, 'rewards/chosen': 4.295239448547363, 'rewards/rejected': -4.854687690734863, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.134374618530273, 'logps/chosen': -368.5, 'logps/rejected': -175.0500030517578, 'logits/chosen': -7.181250095367432, 'logits/rejected': -6.956250190734863, 'epoch': 1.66}
 55%|█████▌    | 2510/4545 [2:41:44<1:47:51,  3.18s/it] 55%|█████▌    | 2511/4545 [2:41:47<1:47:10,  3.16s/it] 55%|█████▌    | 2512/4545 [2:41:51<1:56:53,  3.45s/it] 55%|█████▌    | 2513/4545 [2:41:55<2:01:19,  3.58s/it] 55%|█████▌    | 2514/4545 [2:41:59<2:06:29,  3.74s/it] 55%|█████▌    | 2515/4545 [2:42:03<2:08:29,  3.80s/it] 55%|█████▌    | 2516/4545 [2:42:07<2:09:26,  3.83s/it] 55%|█████▌    | 2517/4545 [2:42:10<2:05:14,  3.71s/it] 55%|█████▌    | 2518/4545 [2:42:14<2:07:13,  3.77s/it] 55%|█████▌    | 2519/4545 [2:42:18<2:08:23,  3.80s/it] 55%|█████▌    | 2520/4545 [2:42:22<2:04:38,  3.69s/it]                                                       {'loss': 0.1808, 'grad_norm': 22.124731063842773, 'learning_rate': 3.108603397659491e-07, 'rewards/chosen': 4.046191215515137, 'rewards/rejected': -5.631249904632568, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 9.671875, 'logps/chosen': -386.6499938964844, 'logps/rejected': -203.0500030517578, 'logits/chosen': -7.206250190734863, 'logits/rejected': -6.903124809265137, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [2:42:22<2:04:38,  3.69s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.51s/it][A
 13%|█▎        | 8/60 [00:11<01:21,  1.57s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:19,  1.63s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.61s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:20<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.27s/it][A
 30%|███       | 18/60 [00:24<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.13s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:32<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.29s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:38<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:41<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.36s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:46<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.08s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:58<00:17,  1.26s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:02<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.38s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.30s/it][A
 95%|█████████▌| 57/60 [01:13<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.36s/it][A
 98%|█████████▊| 59/60 [01:16<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.48s/it][A                                                       
                                               [A{'eval_loss': 0.37367022037506104, 'eval_runtime': 80.0671, 'eval_samples_per_second': 11.903, 'eval_steps_per_second': 0.749, 'eval_rewards/chosen': 3.264176845550537, 'eval_rewards/rejected': -3.7417969703674316, 'eval_rewards/accuracies': 0.8353009819984436, 'eval_rewards/margins': 7.009016990661621, 'eval_logps/chosen': -361.2166748046875, 'eval_logps/rejected': -170.71665954589844, 'eval_logits/chosen': -7.145833492279053, 'eval_logits/rejected': -7.4942708015441895, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [2:43:42<2:04:38,  3.69s/it]
100%|██████████| 60/60 [01:18<00:00,  1.48s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 55%|█████▌    | 2521/4545 [2:43:59<17:50:25, 31.73s/it] 55%|█████▌    | 2522/4545 [2:44:03<13:08:07, 23.38s/it] 56%|█████▌    | 2523/4545 [2:44:07<9:51:02, 17.54s/it]  56%|█████▌    | 2524/4545 [2:44:10<7:30:40, 13.38s/it] 56%|█████▌    | 2525/4545 [2:44:13<5:43:27, 10.20s/it] 56%|█████▌    | 2526/4545 [2:44:17<4:42:54,  8.41s/it] 56%|█████▌    | 2527/4545 [2:44:21<3:51:40,  6.89s/it] 56%|█████▌    | 2528/4545 [2:44:24<3:16:20,  5.84s/it] 56%|█████▌    | 2529/4545 [2:44:28<2:58:21,  5.31s/it] 56%|█████▌    | 2530/4545 [2:44:32<2:44:08,  4.89s/it]                                                       {'loss': 0.2725, 'grad_norm': 31.3830623626709, 'learning_rate': 3.092449457679471e-07, 'rewards/chosen': 2.7000489234924316, 'rewards/rejected': -5.8203125, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 8.520312309265137, 'logps/chosen': -288.54998779296875, 'logps/rejected': -218.5749969482422, 'logits/chosen': -7.434374809265137, 'logits/rejected': -7.237500190734863, 'epoch': 1.67}
 56%|█████▌    | 2530/4545 [2:44:32<2:44:08,  4.89s/it] 56%|█████▌    | 2531/4545 [2:44:36<2:33:57,  4.59s/it] 56%|█████▌    | 2532/4545 [2:44:40<2:27:05,  4.38s/it] 56%|█████▌    | 2533/4545 [2:44:43<2:20:26,  4.19s/it] 56%|█████▌    | 2534/4545 [2:44:48<2:19:00,  4.15s/it] 56%|█████▌    | 2535/4545 [2:44:50<2:02:32,  3.66s/it] 56%|█████▌    | 2536/4545 [2:44:54<2:05:02,  3.73s/it] 56%|█████▌    | 2537/4545 [2:44:58<2:06:29,  3.78s/it] 56%|█████▌    | 2538/4545 [2:45:00<1:53:55,  3.41s/it] 56%|█████▌    | 2539/4545 [2:45:04<1:59:32,  3.58s/it] 56%|█████▌    | 2540/4545 [2:45:07<1:49:31,  3.28s/it]                                                       {'loss': 0.3963, 'grad_norm': 46.286136627197266, 'learning_rate': 3.0761996422054713e-07, 'rewards/chosen': 3.8903746604919434, 'rewards/rejected': -4.086328029632568, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 7.973437309265137, 'logps/chosen': -344.8500061035156, 'logps/rejected': -184.9499969482422, 'logits/chosen': -7.462500095367432, 'logits/rejected': -7.037499904632568, 'epoch': 1.68}
 56%|█████▌    | 2540/4545 [2:45:07<1:49:31,  3.28s/it] 56%|█████▌    | 2541/4545 [2:45:11<1:55:45,  3.47s/it] 56%|█████▌    | 2542/4545 [2:45:13<1:45:33,  3.16s/it] 56%|█████▌    | 2543/4545 [2:45:17<1:54:10,  3.42s/it] 56%|█████▌    | 2544/4545 [2:45:21<2:00:08,  3.60s/it] 56%|█████▌    | 2545/4545 [2:45:25<2:03:10,  3.70s/it] 56%|█████▌    | 2546/4545 [2:45:28<1:51:28,  3.35s/it] 56%|█████▌    | 2547/4545 [2:45:32<1:59:05,  3.58s/it] 56%|█████▌    | 2548/4545 [2:45:36<2:02:29,  3.68s/it] 56%|█████▌    | 2549/4545 [2:45:40<2:04:41,  3.75s/it] 56%|█████▌    | 2550/4545 [2:45:44<2:05:04,  3.76s/it]                                                       {'loss': 0.233, 'grad_norm': 37.97633361816406, 'learning_rate': 3.059855696948773e-07, 'rewards/chosen': 2.067089796066284, 'rewards/rejected': -4.710546970367432, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.771874904632568, 'logps/chosen': -223.14999389648438, 'logps/rejected': -153.9499969482422, 'logits/chosen': -7.503125190734863, 'logits/rejected': -7.153124809265137, 'epoch': 1.68}
 56%|█████▌    | 2550/4545 [2:45:44<2:05:04,  3.76s/it] 56%|█████▌    | 2551/4545 [2:45:47<2:06:37,  3.81s/it] 56%|█████▌    | 2552/4545 [2:45:52<2:09:45,  3.91s/it] 56%|█████▌    | 2553/4545 [2:45:56<2:11:51,  3.97s/it] 56%|█████▌    | 2554/4545 [2:46:00<2:11:11,  3.95s/it] 56%|█████▌    | 2555/4545 [2:46:04<2:10:36,  3.94s/it] 56%|█████▌    | 2556/4545 [2:46:07<2:09:32,  3.91s/it] 56%|█████▋    | 2557/4545 [2:46:11<2:09:26,  3.91s/it] 56%|█████▋    | 2558/4545 [2:46:15<2:10:03,  3.93s/it] 56%|█████▋    | 2559/4545 [2:46:19<2:03:57,  3.74s/it] 56%|█████▋    | 2560/4545 [2:46:22<2:03:02,  3.72s/it]                                                       {'loss': 0.3225, 'grad_norm': 32.94082260131836, 'learning_rate': 3.0434193777329833e-07, 'rewards/chosen': 3.2188477516174316, 'rewards/rejected': -4.130859375, 'rewards/accuracies': 0.84375, 'rewards/margins': 7.354687690734863, 'logps/chosen': -350.6499938964844, 'logps/rejected': -218.10000610351562, 'logits/chosen': -7.275000095367432, 'logits/rejected': -7.021874904632568, 'epoch': 1.69}
 56%|█████▋    | 2560/4545 [2:46:22<2:03:02,  3.72s/it] 56%|█████▋    | 2561/4545 [2:46:25<1:51:45,  3.38s/it] 56%|█████▋    | 2562/4545 [2:46:29<1:57:04,  3.54s/it] 56%|█████▋    | 2563/4545 [2:46:31<1:41:15,  3.07s/it] 56%|█████▋    | 2564/4545 [2:46:35<1:52:03,  3.39s/it] 56%|█████▋    | 2565/4545 [2:46:39<1:57:10,  3.55s/it] 56%|█████▋    | 2566/4545 [2:46:42<1:55:52,  3.51s/it] 56%|█████▋    | 2567/4545 [2:46:46<1:57:48,  3.57s/it] 57%|█████▋    | 2568/4545 [2:46:50<1:58:22,  3.59s/it] 57%|█████▋    | 2569/4545 [2:46:53<1:59:53,  3.64s/it] 57%|█████▋    | 2570/4545 [2:46:56<1:51:59,  3.40s/it]                                                       {'loss': 0.1986, 'grad_norm': 22.141382217407227, 'learning_rate': 3.026892450305405e-07, 'rewards/chosen': 1.53155517578125, 'rewards/rejected': -6.005468845367432, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.535937309265137, 'logps/chosen': -160.3249969482422, 'logps/rejected': -143.6999969482422, 'logits/chosen': -7.612500190734863, 'logits/rejected': -7.056250095367432, 'epoch': 1.7}
 57%|█████▋    | 2570/4545 [2:46:56<1:51:59,  3.40s/it] 57%|█████▋    | 2571/4545 [2:47:00<1:53:31,  3.45s/it] 57%|█████▋    | 2572/4545 [2:47:03<1:55:03,  3.50s/it] 57%|█████▋    | 2573/4545 [2:47:07<1:53:22,  3.45s/it] 57%|█████▋    | 2574/4545 [2:47:11<2:00:15,  3.66s/it] 57%|█████▋    | 2575/4545 [2:47:15<2:02:45,  3.74s/it] 57%|█████▋    | 2576/4545 [2:47:18<2:02:55,  3.75s/it] 57%|█████▋    | 2577/4545 [2:47:22<2:04:05,  3.78s/it] 57%|█████▋    | 2578/4545 [2:47:26<2:04:48,  3.81s/it] 57%|█████▋    | 2579/4545 [2:47:30<2:04:16,  3.79s/it] 57%|█████▋    | 2580/4545 [2:47:34<2:05:17,  3.83s/it]                                                       {'loss': 0.1726, 'grad_norm': 27.66341209411621, 'learning_rate': 3.010276690147348e-07, 'rewards/chosen': 2.3203125, 'rewards/rejected': -9.059374809265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.381250381469727, 'logps/chosen': -258.1000061035156, 'logps/rejected': -170.5500030517578, 'logits/chosen': -7.578125, 'logits/rejected': -7.271874904632568, 'epoch': 1.7}
 57%|█████▋    | 2580/4545 [2:47:34<2:05:17,  3.83s/it] 57%|█████▋    | 2581/4545 [2:47:38<2:08:55,  3.94s/it] 57%|█████▋    | 2582/4545 [2:47:42<2:08:38,  3.93s/it] 57%|█████▋    | 2583/4545 [2:47:46<2:08:06,  3.92s/it] 57%|█████▋    | 2584/4545 [2:47:49<2:04:29,  3.81s/it] 57%|█████▋    | 2585/4545 [2:47:53<2:03:14,  3.77s/it] 57%|█████▋    | 2586/4545 [2:47:57<2:04:32,  3.81s/it] 57%|█████▋    | 2587/4545 [2:48:00<1:56:34,  3.57s/it] 57%|█████▋    | 2588/4545 [2:48:04<1:59:39,  3.67s/it] 57%|█████▋    | 2589/4545 [2:48:08<2:03:57,  3.80s/it] 57%|█████▋    | 2590/4545 [2:48:12<2:04:51,  3.83s/it]                                                       {'loss': 0.2842, 'grad_norm': 17.615215301513672, 'learning_rate': 2.993573882283384e-07, 'rewards/chosen': 2.487597703933716, 'rewards/rejected': -5.703125, 'rewards/accuracies': 0.875, 'rewards/margins': 8.1875, 'logps/chosen': -279.3500061035156, 'logps/rejected': -154.4499969482422, 'logits/chosen': -7.371874809265137, 'logits/rejected': -7.068749904632568, 'epoch': 1.71}
 57%|█████▋    | 2590/4545 [2:48:12<2:04:51,  3.83s/it] 57%|█████▋    | 2591/4545 [2:48:16<2:03:17,  3.79s/it] 57%|█████▋    | 2592/4545 [2:48:20<2:04:54,  3.84s/it] 57%|█████▋    | 2593/4545 [2:48:23<1:58:07,  3.63s/it] 57%|█████▋    | 2594/4545 [2:48:27<2:00:47,  3.71s/it] 57%|█████▋    | 2595/4545 [2:48:31<2:04:16,  3.82s/it] 57%|█████▋    | 2596/4545 [2:48:35<2:05:10,  3.85s/it] 57%|█████▋    | 2597/4545 [2:48:38<2:01:49,  3.75s/it] 57%|█████▋    | 2598/4545 [2:48:42<2:02:50,  3.79s/it] 57%|█████▋    | 2599/4545 [2:48:46<2:05:00,  3.85s/it] 57%|█████▋    | 2600/4545 [2:48:50<2:05:31,  3.87s/it]                                                       {'loss': 0.227, 'grad_norm': 75.63334655761719, 'learning_rate': 2.976785821089591e-07, 'rewards/chosen': 4.7305908203125, 'rewards/rejected': -5.83203125, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 10.553125381469727, 'logps/chosen': -443.95001220703125, 'logps/rejected': -265.5, 'logits/chosen': -7.115624904632568, 'logits/rejected': -6.878125190734863, 'epoch': 1.72}
 57%|█████▋    | 2600/4545 [2:48:50<2:05:31,  3.87s/it] 57%|█████▋    | 2601/4545 [2:48:54<2:07:53,  3.95s/it] 57%|█████▋    | 2602/4545 [2:48:58<2:04:50,  3.86s/it] 57%|█████▋    | 2603/4545 [2:49:01<2:01:42,  3.76s/it] 57%|█████▋    | 2604/4545 [2:49:05<2:02:44,  3.79s/it] 57%|█████▋    | 2605/4545 [2:49:09<2:04:43,  3.86s/it] 57%|█████▋    | 2606/4545 [2:49:13<2:05:25,  3.88s/it] 57%|█████▋    | 2607/4545 [2:49:17<2:05:22,  3.88s/it] 57%|█████▋    | 2608/4545 [2:49:20<1:52:43,  3.49s/it] 57%|█████▋    | 2609/4545 [2:49:23<1:54:57,  3.56s/it] 57%|█████▋    | 2610/4545 [2:49:27<1:59:16,  3.70s/it]                                                       {'loss': 0.2594, 'grad_norm': 43.08415603637695, 'learning_rate': 2.959914310100773e-07, 'rewards/chosen': 1.0263671875, 'rewards/rejected': -5.6627197265625, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 6.693749904632568, 'logps/chosen': -170.3000030517578, 'logps/rejected': -174.35000610351562, 'logits/chosen': -7.553124904632568, 'logits/rejected': -7.184374809265137, 'epoch': 1.72}
 57%|█████▋    | 2610/4545 [2:49:27<1:59:16,  3.70s/it] 57%|█████▋    | 2611/4545 [2:49:31<2:01:09,  3.76s/it] 57%|█████▋    | 2612/4545 [2:49:35<2:02:35,  3.81s/it] 57%|█████▋    | 2613/4545 [2:49:39<2:06:31,  3.93s/it] 58%|█████▊    | 2614/4545 [2:49:43<2:08:15,  3.99s/it] 58%|█████▊    | 2615/4545 [2:49:47<2:07:20,  3.96s/it] 58%|█████▊    | 2616/4545 [2:49:51<2:06:49,  3.94s/it] 58%|█████▊    | 2617/4545 [2:49:54<1:59:59,  3.73s/it] 58%|█████▊    | 2618/4545 [2:49:58<2:01:24,  3.78s/it] 58%|█████▊    | 2619/4545 [2:50:02<1:59:21,  3.72s/it] 58%|█████▊    | 2620/4545 [2:50:05<1:50:04,  3.43s/it]                                                       {'loss': 0.2193, 'grad_norm': 32.76704025268555, 'learning_rate': 2.9429611618167155e-07, 'rewards/chosen': 4.117968559265137, 'rewards/rejected': -3.517578125, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 7.643750190734863, 'logps/chosen': -345.8999938964844, 'logps/rejected': -218.9499969482422, 'logits/chosen': -7.434374809265137, 'logits/rejected': -6.934374809265137, 'epoch': 1.73}
 58%|█████▊    | 2620/4545 [2:50:05<1:50:04,  3.43s/it] 58%|█████▊    | 2621/4545 [2:50:08<1:49:07,  3.40s/it] 58%|█████▊    | 2622/4545 [2:50:12<1:55:43,  3.61s/it] 58%|█████▊    | 2623/4545 [2:50:15<1:52:47,  3.52s/it] 58%|█████▊    | 2624/4545 [2:50:20<1:59:51,  3.74s/it] 58%|█████▊    | 2625/4545 [2:50:24<2:01:29,  3.80s/it] 58%|█████▊    | 2626/4545 [2:50:28<2:02:29,  3.83s/it] 58%|█████▊    | 2627/4545 [2:50:32<2:05:15,  3.92s/it] 58%|█████▊    | 2628/4545 [2:50:34<1:50:24,  3.46s/it] 58%|█████▊    | 2629/4545 [2:50:37<1:49:06,  3.42s/it] 58%|█████▊    | 2630/4545 [2:50:41<1:49:51,  3.44s/it]                                                       {'loss': 0.2385, 'grad_norm': 35.4724006652832, 'learning_rate': 2.9259281975074665e-07, 'rewards/chosen': 2.4567551612854004, 'rewards/rejected': -5.871874809265137, 'rewards/accuracies': 0.875, 'rewards/margins': 8.334375381469727, 'logps/chosen': -313.67498779296875, 'logps/rejected': -182.5, 'logits/chosen': -7.384375095367432, 'logits/rejected': -6.90625, 'epoch': 1.74}
 58%|█████▊    | 2630/4545 [2:50:41<1:49:51,  3.44s/it] 58%|█████▊    | 2631/4545 [2:50:45<1:54:15,  3.58s/it] 58%|█████▊    | 2632/4545 [2:50:49<1:59:37,  3.75s/it] 58%|█████▊    | 2633/4545 [2:50:53<2:00:10,  3.77s/it] 58%|█████▊    | 2634/4545 [2:50:57<2:01:40,  3.82s/it] 58%|█████▊    | 2635/4545 [2:51:01<2:05:12,  3.93s/it] 58%|█████▊    | 2636/4545 [2:51:04<2:00:10,  3.78s/it] 58%|█████▊    | 2637/4545 [2:51:09<2:04:36,  3.92s/it] 58%|█████▊    | 2638/4545 [2:51:12<2:04:48,  3.93s/it] 58%|█████▊    | 2639/4545 [2:51:16<2:04:17,  3.91s/it] 58%|█████▊    | 2640/4545 [2:51:20<2:04:13,  3.91s/it]                                                       {'loss': 0.2495, 'grad_norm': 53.8803596496582, 'learning_rate': 2.9088172470176783e-07, 'rewards/chosen': 2.9198241233825684, 'rewards/rejected': -5.418749809265137, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.342187881469727, 'logps/chosen': -306.6000061035156, 'logps/rejected': -168.1999969482422, 'logits/chosen': -7.318749904632568, 'logits/rejected': -6.856249809265137, 'epoch': 1.74}
 58%|█████▊    | 2640/4545 [2:51:20<2:04:13,  3.91s/it] 58%|█████▊    | 2641/4545 [2:51:24<2:04:14,  3.92s/it] 58%|█████▊    | 2642/4545 [2:51:28<2:04:23,  3.92s/it] 58%|█████▊    | 2643/4545 [2:51:32<2:01:54,  3.85s/it] 58%|█████▊    | 2644/4545 [2:51:35<1:56:29,  3.68s/it] 58%|█████▊    | 2645/4545 [2:51:39<1:58:40,  3.75s/it] 58%|█████▊    | 2646/4545 [2:51:43<2:00:14,  3.80s/it] 58%|█████▊    | 2647/4545 [2:51:47<2:01:16,  3.83s/it] 58%|█████▊    | 2648/4545 [2:51:51<2:01:59,  3.86s/it] 58%|█████▊    | 2649/4545 [2:51:55<2:02:17,  3.87s/it] 58%|█████▊    | 2650/4545 [2:51:59<2:02:39,  3.88s/it]                                                       {'loss': 0.1361, 'grad_norm': 21.569307327270508, 'learning_rate': 2.8916301485700264e-07, 'rewards/chosen': 4.429931640625, 'rewards/rejected': -5.967577934265137, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 10.396875381469727, 'logps/chosen': -380.8500061035156, 'logps/rejected': -216.8000030517578, 'logits/chosen': -7.209374904632568, 'logits/rejected': -7.115624904632568, 'epoch': 1.75}
 58%|█████▊    | 2650/4545 [2:51:59<2:02:39,  3.88s/it] 58%|█████▊    | 2651/4545 [2:52:02<2:01:40,  3.85s/it] 58%|█████▊    | 2652/4545 [2:52:06<2:02:16,  3.88s/it] 58%|█████▊    | 2653/4545 [2:52:10<2:04:47,  3.96s/it] 58%|█████▊    | 2654/4545 [2:52:14<2:04:08,  3.94s/it] 58%|█████▊    | 2655/4545 [2:52:18<2:02:14,  3.88s/it] 58%|█████▊    | 2656/4545 [2:52:22<2:04:26,  3.95s/it] 58%|█████▊    | 2657/4545 [2:52:26<2:00:41,  3.84s/it] 58%|█████▊    | 2658/4545 [2:52:30<2:03:42,  3.93s/it] 59%|█████▊    | 2659/4545 [2:52:34<2:02:01,  3.88s/it] 59%|█████▊    | 2660/4545 [2:52:38<2:02:19,  3.89s/it]                                                       {'loss': 0.2164, 'grad_norm': 15.331094741821289, 'learning_rate': 2.8743687485677317e-07, 'rewards/chosen': 2.939257860183716, 'rewards/rejected': -7.3515625, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 10.287500381469727, 'logps/chosen': -347.75, 'logps/rejected': -215.64999389648438, 'logits/chosen': -7.334374904632568, 'logits/rejected': -6.974999904632568, 'epoch': 1.76}
 59%|█████▊    | 2660/4545 [2:52:38<2:02:19,  3.89s/it] 59%|█████▊    | 2661/4545 [2:52:41<1:57:19,  3.74s/it] 59%|█████▊    | 2662/4545 [2:52:45<1:58:19,  3.77s/it] 59%|█████▊    | 2663/4545 [2:52:48<1:57:44,  3.75s/it] 59%|█████▊    | 2664/4545 [2:52:52<1:59:06,  3.80s/it] 59%|█████▊    | 2665/4545 [2:52:56<1:57:20,  3.74s/it] 59%|█████▊    | 2666/4545 [2:53:00<2:01:02,  3.87s/it] 59%|█████▊    | 2667/4545 [2:53:04<2:03:24,  3.94s/it] 59%|█████▊    | 2668/4545 [2:53:08<2:04:47,  3.99s/it] 59%|█████▊    | 2669/4545 [2:53:12<2:04:42,  3.99s/it] 59%|█████▊    | 2670/4545 [2:53:15<1:47:44,  3.45s/it]                                                       {'loss': 0.2947, 'grad_norm': 36.84555435180664, 'learning_rate': 2.857034901396205e-07, 'rewards/chosen': 2.2650389671325684, 'rewards/rejected': -5.987500190734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.25, 'logps/chosen': -307.1499938964844, 'logps/rejected': -199.10000610351562, 'logits/chosen': -7.534375190734863, 'logits/rejected': -7.243750095367432, 'epoch': 1.76}
 59%|█████▊    | 2670/4545 [2:53:15<1:47:44,  3.45s/it] 59%|█████▉    | 2671/4545 [2:53:17<1:41:16,  3.24s/it] 59%|█████▉    | 2672/4545 [2:53:21<1:47:35,  3.45s/it] 59%|█████▉    | 2673/4545 [2:53:25<1:50:10,  3.53s/it] 59%|█████▉    | 2674/4545 [2:53:29<1:53:35,  3.64s/it] 59%|█████▉    | 2675/4545 [2:53:33<1:56:00,  3.72s/it] 59%|█████▉    | 2676/4545 [2:53:37<1:57:35,  3.77s/it] 59%|█████▉    | 2677/4545 [2:53:40<1:57:08,  3.76s/it] 59%|█████▉    | 2678/4545 [2:53:44<1:58:36,  3.81s/it] 59%|█████▉    | 2679/4545 [2:53:48<1:57:17,  3.77s/it] 59%|█████▉    | 2680/4545 [2:53:52<1:58:34,  3.81s/it]                                                       {'loss': 0.2203, 'grad_norm': 48.5618896484375, 'learning_rate': 2.839630469223823e-07, 'rewards/chosen': 3.13671875, 'rewards/rejected': -6.158984184265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 9.309374809265137, 'logps/chosen': -317.8999938964844, 'logps/rejected': -216.1999969482422, 'logits/chosen': -7.300000190734863, 'logits/rejected': -6.828125, 'epoch': 1.77}
 59%|█████▉    | 2680/4545 [2:53:52<1:58:34,  3.81s/it] 59%|█████▉    | 2681/4545 [2:53:56<1:59:32,  3.85s/it] 59%|█████▉    | 2682/4545 [2:54:00<2:01:20,  3.91s/it] 59%|█████▉    | 2683/4545 [2:54:04<2:02:42,  3.95s/it] 59%|█████▉    | 2684/4545 [2:54:08<2:02:51,  3.96s/it] 59%|█████▉    | 2685/4545 [2:54:12<2:03:20,  3.98s/it] 59%|█████▉    | 2686/4545 [2:54:16<2:05:29,  4.05s/it] 59%|█████▉    | 2687/4545 [2:54:20<2:06:50,  4.10s/it] 59%|█████▉    | 2688/4545 [2:54:24<2:04:48,  4.03s/it] 59%|█████▉    | 2689/4545 [2:54:27<1:50:56,  3.59s/it] 59%|█████▉    | 2690/4545 [2:54:31<1:54:00,  3.69s/it]                                                       {'loss': 0.324, 'grad_norm': 51.564029693603516, 'learning_rate': 2.8221573218018844e-07, 'rewards/chosen': 3.449810743331909, 'rewards/rejected': -4.843359470367432, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 8.293749809265137, 'logps/chosen': -330.0, 'logps/rejected': -225.0500030517578, 'logits/chosen': -7.456250190734863, 'logits/rejected': -7.171875, 'epoch': 1.78}
 59%|█████▉    | 2690/4545 [2:54:31<1:54:00,  3.69s/it] 59%|█████▉    | 2691/4545 [2:54:35<1:55:59,  3.75s/it] 59%|█████▉    | 2692/4545 [2:54:39<1:57:05,  3.79s/it] 59%|█████▉    | 2693/4545 [2:54:42<1:58:06,  3.83s/it] 59%|█████▉    | 2694/4545 [2:54:46<1:57:29,  3.81s/it] 59%|█████▉    | 2695/4545 [2:54:50<1:55:30,  3.75s/it] 59%|█████▉    | 2696/4545 [2:54:52<1:44:14,  3.38s/it] 59%|█████▉    | 2697/4545 [2:54:56<1:48:59,  3.54s/it] 59%|█████▉    | 2698/4545 [2:55:00<1:52:55,  3.67s/it] 59%|█████▉    | 2699/4545 [2:55:03<1:44:48,  3.41s/it] 59%|█████▉    | 2700/4545 [2:55:07<1:50:49,  3.60s/it]                                                       {'loss': 0.2893, 'grad_norm': 16.266637802124023, 'learning_rate': 2.804617336263741e-07, 'rewards/chosen': 2.3829102516174316, 'rewards/rejected': -5.357812404632568, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 7.737500190734863, 'logps/chosen': -270.25, 'logps/rejected': -163.60000610351562, 'logits/chosen': -7.550000190734863, 'logits/rejected': -7.256249904632568, 'epoch': 1.78}
 59%|█████▉    | 2700/4545 [2:55:07<1:50:49,  3.60s/it] 59%|█████▉    | 2701/4545 [2:55:10<1:47:44,  3.51s/it] 59%|█████▉    | 2702/4545 [2:55:13<1:43:01,  3.35s/it] 59%|█████▉    | 2703/4545 [2:55:18<1:51:56,  3.65s/it] 59%|█████▉    | 2704/4545 [2:55:22<1:54:15,  3.72s/it] 60%|█████▉    | 2705/4545 [2:55:26<1:56:00,  3.78s/it] 60%|█████▉    | 2706/4545 [2:55:29<1:56:05,  3.79s/it] 60%|█████▉    | 2707/4545 [2:55:33<1:57:04,  3.82s/it] 60%|█████▉    | 2708/4545 [2:55:37<1:59:01,  3.89s/it] 60%|█████▉    | 2709/4545 [2:55:41<1:56:42,  3.81s/it] 60%|█████▉    | 2710/4545 [2:55:44<1:54:16,  3.74s/it]                                                       {'loss': 0.2264, 'grad_norm': 45.7699089050293, 'learning_rate': 2.787012396923133e-07, 'rewards/chosen': 1.7895019054412842, 'rewards/rejected': -6.125, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.90625, 'logps/chosen': -221.25, 'logps/rejected': -161.64999389648438, 'logits/chosen': -7.559374809265137, 'logits/rejected': -7.300000190734863, 'epoch': 1.79}
 60%|█████▉    | 2710/4545 [2:55:44<1:54:16,  3.74s/it] 60%|█████▉    | 2711/4545 [2:55:48<1:55:46,  3.79s/it] 60%|█████▉    | 2712/4545 [2:55:52<1:52:59,  3.70s/it] 60%|█████▉    | 2713/4545 [2:55:56<1:54:44,  3.76s/it] 60%|█████▉    | 2714/4545 [2:56:00<1:56:09,  3.81s/it] 60%|█████▉    | 2715/4545 [2:56:03<1:55:37,  3.79s/it] 60%|█████▉    | 2716/4545 [2:56:06<1:48:02,  3.54s/it] 60%|█████▉    | 2717/4545 [2:56:10<1:51:14,  3.65s/it] 60%|█████▉    | 2718/4545 [2:56:14<1:53:30,  3.73s/it] 60%|█████▉    | 2719/4545 [2:56:18<1:54:01,  3.75s/it] 60%|█████▉    | 2720/4545 [2:56:22<1:55:47,  3.81s/it]                                                       {'loss': 0.2941, 'grad_norm': 31.363779067993164, 'learning_rate': 2.7693443950717664e-07, 'rewards/chosen': 1.8564453125, 'rewards/rejected': -5.05859375, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.918749809265137, 'logps/chosen': -230.0500030517578, 'logps/rejected': -148.39999389648438, 'logits/chosen': -7.446875095367432, 'logits/rejected': -7.15625, 'epoch': 1.8}
 60%|█████▉    | 2720/4545 [2:56:22<1:55:47,  3.81s/it] 60%|█████▉    | 2721/4545 [2:56:24<1:36:43,  3.18s/it] 60%|█████▉    | 2722/4545 [2:56:28<1:44:44,  3.45s/it] 60%|█████▉    | 2723/4545 [2:56:32<1:48:57,  3.59s/it] 60%|█████▉    | 2724/4545 [2:56:35<1:48:18,  3.57s/it] 60%|█████▉    | 2725/4545 [2:56:39<1:48:53,  3.59s/it] 60%|█████▉    | 2726/4545 [2:56:43<1:54:09,  3.77s/it] 60%|██████    | 2727/4545 [2:56:47<1:55:21,  3.81s/it] 60%|██████    | 2728/4545 [2:56:51<1:53:39,  3.75s/it] 60%|██████    | 2729/4545 [2:56:54<1:50:27,  3.65s/it] 60%|██████    | 2730/4545 [2:56:58<1:52:39,  3.72s/it]                                                       {'loss': 0.2199, 'grad_norm': 29.749494552612305, 'learning_rate': 2.751615228776126e-07, 'rewards/chosen': 2.1761231422424316, 'rewards/rejected': -5.578125, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 7.756249904632568, 'logps/chosen': -222.5749969482422, 'logps/rejected': -156.77499389648438, 'logits/chosen': -7.690625190734863, 'logits/rejected': -7.425000190734863, 'epoch': 1.8}
 60%|██████    | 2730/4545 [2:56:58<1:52:39,  3.72s/it] 60%|██████    | 2731/4545 [2:57:02<1:54:23,  3.78s/it] 60%|██████    | 2732/4545 [2:57:06<1:55:30,  3.82s/it] 60%|██████    | 2733/4545 [2:57:09<1:54:48,  3.80s/it] 60%|██████    | 2734/4545 [2:57:13<1:52:15,  3.72s/it] 60%|██████    | 2735/4545 [2:57:17<1:55:08,  3.82s/it] 60%|██████    | 2736/4545 [2:57:21<1:55:47,  3.84s/it] 60%|██████    | 2737/4545 [2:57:24<1:49:47,  3.64s/it] 60%|██████    | 2738/4545 [2:57:28<1:53:26,  3.77s/it] 60%|██████    | 2739/4545 [2:57:32<1:54:50,  3.82s/it] 60%|██████    | 2740/4545 [2:57:36<1:55:14,  3.83s/it]                                                       {'loss': 0.2543, 'grad_norm': 31.05331802368164, 'learning_rate': 2.7338268026735685e-07, 'rewards/chosen': 3.38427734375, 'rewards/rejected': -4.176465034484863, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 7.568749904632568, 'logps/chosen': -311.6499938964844, 'logps/rejected': -169.1999969482422, 'logits/chosen': -7.493750095367432, 'logits/rejected': -7.34375, 'epoch': 1.81}
 60%|██████    | 2740/4545 [2:57:36<1:55:14,  3.83s/it] 60%|██████    | 2741/4545 [2:57:39<1:52:38,  3.75s/it] 60%|██████    | 2742/4545 [2:57:43<1:53:50,  3.79s/it] 60%|██████    | 2743/4545 [2:57:47<1:54:37,  3.82s/it] 60%|██████    | 2744/4545 [2:57:50<1:46:50,  3.56s/it] 60%|██████    | 2745/4545 [2:57:54<1:47:03,  3.57s/it] 60%|██████    | 2746/4545 [2:57:58<1:51:08,  3.71s/it] 60%|██████    | 2747/4545 [2:58:01<1:50:41,  3.69s/it] 60%|██████    | 2748/4545 [2:58:05<1:49:00,  3.64s/it] 60%|██████    | 2749/4545 [2:58:08<1:45:51,  3.54s/it] 61%|██████    | 2750/4545 [2:58:12<1:49:26,  3.66s/it]                                                       {'loss': 0.2476, 'grad_norm': 35.81027603149414, 'learning_rate': 2.7159810277677084e-07, 'rewards/chosen': 1.073632836341858, 'rewards/rejected': -5.135937690734863, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 6.215624809265137, 'logps/chosen': -165.25, 'logps/rejected': -143.1999969482422, 'logits/chosen': -7.590624809265137, 'logits/rejected': -7.240624904632568, 'epoch': 1.82}
 61%|██████    | 2750/4545 [2:58:12<1:49:26,  3.66s/it] 61%|██████    | 2751/4545 [2:58:16<1:54:45,  3.84s/it] 61%|██████    | 2752/4545 [2:58:20<1:51:30,  3.73s/it] 61%|██████    | 2753/4545 [2:58:23<1:46:02,  3.55s/it] 61%|██████    | 2754/4545 [2:58:27<1:48:54,  3.65s/it] 61%|██████    | 2755/4545 [2:58:30<1:43:11,  3.46s/it] 61%|██████    | 2756/4545 [2:58:33<1:43:31,  3.47s/it] 61%|██████    | 2757/4545 [2:58:38<1:49:03,  3.66s/it] 61%|██████    | 2758/4545 [2:58:42<1:51:25,  3.74s/it] 61%|██████    | 2759/4545 [2:58:46<1:54:48,  3.86s/it] 61%|██████    | 2760/4545 [2:58:50<1:56:37,  3.92s/it]                                                       {'loss': 0.3659, 'grad_norm': 50.686344146728516, 'learning_rate': 2.698079821223121e-07, 'rewards/chosen': 1.715234398841858, 'rewards/rejected': -5.623437404632568, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.354687690734863, 'logps/chosen': -212.14999389648438, 'logps/rejected': -163.1999969482422, 'logits/chosen': -7.515625, 'logits/rejected': -7.162499904632568, 'epoch': 1.82}
 61%|██████    | 2760/4545 [2:58:50<1:56:37,  3.92s/it] 61%|██████    | 2761/4545 [2:58:54<1:56:34,  3.92s/it] 61%|██████    | 2762/4545 [2:58:58<1:56:20,  3.92s/it] 61%|██████    | 2763/4545 [2:59:01<1:50:08,  3.71s/it] 61%|██████    | 2764/4545 [2:59:05<1:51:55,  3.77s/it] 61%|██████    | 2765/4545 [2:59:08<1:50:00,  3.71s/it] 61%|██████    | 2766/4545 [2:59:12<1:48:06,  3.65s/it] 61%|██████    | 2767/4545 [2:59:16<1:53:29,  3.83s/it] 61%|██████    | 2768/4545 [2:59:20<1:54:12,  3.86s/it] 61%|██████    | 2769/4545 [2:59:24<1:55:29,  3.90s/it] 61%|██████    | 2770/4545 [2:59:28<1:55:35,  3.91s/it]                                                       {'loss': 0.2134, 'grad_norm': 21.114063262939453, 'learning_rate': 2.6801251061593793e-07, 'rewards/chosen': 3.876757860183716, 'rewards/rejected': -4.7403564453125, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.603124618530273, 'logps/chosen': -335.0, 'logps/rejected': -238.14999389648438, 'logits/chosen': -7.315625190734863, 'logits/rejected': -7.028124809265137, 'epoch': 1.83}
 61%|██████    | 2770/4545 [2:59:28<1:55:35,  3.91s/it] 61%|██████    | 2771/4545 [2:59:32<1:55:15,  3.90s/it] 61%|██████    | 2772/4545 [2:59:36<1:55:20,  3.90s/it] 61%|██████    | 2773/4545 [2:59:39<1:49:16,  3.70s/it] 61%|██████    | 2774/4545 [2:59:43<1:51:08,  3.77s/it] 61%|██████    | 2775/4545 [2:59:47<1:52:11,  3.80s/it] 61%|██████    | 2776/4545 [2:59:50<1:51:08,  3.77s/it] 61%|██████    | 2777/4545 [2:59:54<1:47:40,  3.65s/it] 61%|██████    | 2778/4545 [2:59:58<1:49:27,  3.72s/it] 61%|██████    | 2779/4545 [3:00:01<1:48:42,  3.69s/it] 61%|██████    | 2780/4545 [3:00:05<1:49:31,  3.72s/it]                                                       {'loss': 0.2289, 'grad_norm': 16.14501953125, 'learning_rate': 2.662118811444455e-07, 'rewards/chosen': 2.163378953933716, 'rewards/rejected': -5.701562404632568, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 7.868750095367432, 'logps/chosen': -263.5, 'logps/rejected': -190.75, 'logits/chosen': -7.543749809265137, 'logits/rejected': -7.103125095367432, 'epoch': 1.83}
 61%|██████    | 2780/4545 [3:00:05<1:49:31,  3.72s/it] 61%|██████    | 2781/4545 [3:00:09<1:52:12,  3.82s/it] 61%|██████    | 2782/4545 [3:00:13<1:52:58,  3.84s/it] 61%|██████    | 2783/4545 [3:00:17<1:50:13,  3.75s/it] 61%|██████▏   | 2784/4545 [3:00:21<1:53:44,  3.88s/it] 61%|██████▏   | 2785/4545 [3:00:25<1:54:04,  3.89s/it] 61%|██████▏   | 2786/4545 [3:00:29<1:56:07,  3.96s/it] 61%|██████▏   | 2787/4545 [3:00:33<1:55:16,  3.93s/it] 61%|██████▏   | 2788/4545 [3:00:36<1:46:58,  3.65s/it] 61%|██████▏   | 2789/4545 [3:00:40<1:50:01,  3.76s/it] 61%|██████▏   | 2790/4545 [3:00:44<1:51:22,  3.81s/it]                                                       {'loss': 0.2708, 'grad_norm': 36.32455825805664, 'learning_rate': 2.6440628714875026e-07, 'rewards/chosen': 2.1293396949768066, 'rewards/rejected': -4.875, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 6.998437404632568, 'logps/chosen': -249.14999389648438, 'logps/rejected': -183.6999969482422, 'logits/chosen': -7.434374809265137, 'logits/rejected': -7.046875, 'epoch': 1.84}
 61%|██████▏   | 2790/4545 [3:00:44<1:51:22,  3.81s/it] 61%|██████▏   | 2791/4545 [3:00:47<1:52:15,  3.84s/it] 61%|██████▏   | 2792/4545 [3:00:52<1:55:19,  3.95s/it] 61%|██████▏   | 2793/4545 [3:00:55<1:53:32,  3.89s/it] 61%|██████▏   | 2794/4545 [3:00:59<1:53:45,  3.90s/it] 61%|██████▏   | 2795/4545 [3:01:03<1:50:14,  3.78s/it] 62%|██████▏   | 2796/4545 [3:01:07<1:51:08,  3.81s/it] 62%|██████▏   | 2797/4545 [3:01:10<1:47:48,  3.70s/it] 62%|██████▏   | 2798/4545 [3:01:14<1:51:07,  3.82s/it] 62%|██████▏   | 2799/4545 [3:01:18<1:53:35,  3.90s/it] 62%|██████▏   | 2800/4545 [3:01:21<1:40:53,  3.47s/it]                                                       {'loss': 0.2771, 'grad_norm': 17.27517318725586, 'learning_rate': 2.6259592260310446e-07, 'rewards/chosen': 1.9331543445587158, 'rewards/rejected': -4.868750095367432, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 6.803124904632568, 'logps/chosen': -251.25, 'logps/rejected': -178.9499969482422, 'logits/chosen': -7.412499904632568, 'logits/rejected': -7.03125, 'epoch': 1.85}
 62%|██████▏   | 2800/4545 [3:01:21<1:40:53,  3.47s/it] 62%|██████▏   | 2801/4545 [3:01:25<1:43:45,  3.57s/it] 62%|██████▏   | 2802/4545 [3:01:27<1:36:16,  3.31s/it] 62%|██████▏   | 2803/4545 [3:01:30<1:33:49,  3.23s/it] 62%|██████▏   | 2804/4545 [3:01:33<1:32:49,  3.20s/it] 62%|██████▏   | 2805/4545 [3:01:37<1:33:59,  3.24s/it] 62%|██████▏   | 2806/4545 [3:01:41<1:40:20,  3.46s/it] 62%|██████▏   | 2807/4545 [3:01:44<1:36:03,  3.32s/it] 62%|██████▏   | 2808/4545 [3:01:48<1:42:31,  3.54s/it] 62%|██████▏   | 2809/4545 [3:01:52<1:45:44,  3.65s/it] 62%|██████▏   | 2810/4545 [3:01:54<1:36:30,  3.34s/it]                                                       {'loss': 0.2333, 'grad_norm': 15.730563163757324, 'learning_rate': 2.6078098199425886e-07, 'rewards/chosen': 0.826171875, 'rewards/rejected': -5.478125095367432, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 6.301562309265137, 'logps/chosen': -135.6999969482422, 'logps/rejected': -107.75, 'logits/chosen': -7.778124809265137, 'logits/rejected': -7.53125, 'epoch': 1.85}
 62%|██████▏   | 2810/4545 [3:01:54<1:36:30,  3.34s/it] 62%|██████▏   | 2811/4545 [3:01:58<1:36:52,  3.35s/it] 62%|██████▏   | 2812/4545 [3:02:02<1:41:39,  3.52s/it] 62%|██████▏   | 2813/4545 [3:02:05<1:43:48,  3.60s/it] 62%|██████▏   | 2814/4545 [3:02:10<1:49:00,  3.78s/it] 62%|██████▏   | 2815/4545 [3:02:14<1:49:50,  3.81s/it] 62%|██████▏   | 2816/4545 [3:02:17<1:50:43,  3.84s/it] 62%|██████▏   | 2817/4545 [3:02:21<1:51:50,  3.88s/it] 62%|██████▏   | 2818/4545 [3:02:25<1:53:01,  3.93s/it] 62%|██████▏   | 2819/4545 [3:02:30<1:54:23,  3.98s/it] 62%|██████▏   | 2820/4545 [3:02:33<1:49:03,  3.79s/it]                                                       {'loss': 0.2874, 'grad_norm': 25.733156204223633, 'learning_rate': 2.589616603005686e-07, 'rewards/chosen': 2.403613328933716, 'rewards/rejected': -5.276562690734863, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 7.673437595367432, 'logps/chosen': -275.20001220703125, 'logps/rejected': -181.0, 'logits/chosen': -7.449999809265137, 'logits/rejected': -7.096875190734863, 'epoch': 1.86}
 62%|██████▏   | 2820/4545 [3:02:33<1:49:03,  3.79s/it] 62%|██████▏   | 2821/4545 [3:02:37<1:50:40,  3.85s/it] 62%|██████▏   | 2822/4545 [3:02:40<1:42:13,  3.56s/it] 62%|██████▏   | 2823/4545 [3:02:42<1:30:09,  3.14s/it] 62%|██████▏   | 2824/4545 [3:02:45<1:30:16,  3.15s/it] 62%|██████▏   | 2825/4545 [3:02:49<1:38:54,  3.45s/it] 62%|██████▏   | 2826/4545 [3:02:53<1:43:40,  3.62s/it] 62%|██████▏   | 2827/4545 [3:02:56<1:38:10,  3.43s/it] 62%|██████▏   | 2828/4545 [3:03:00<1:42:08,  3.57s/it] 62%|██████▏   | 2829/4545 [3:03:04<1:44:28,  3.65s/it] 62%|██████▏   | 2830/4545 [3:03:08<1:46:28,  3.72s/it]                                                       {'loss': 0.2624, 'grad_norm': 16.745506286621094, 'learning_rate': 2.571381529710472e-07, 'rewards/chosen': 2.7226319313049316, 'rewards/rejected': -5.948437690734863, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 8.662500381469727, 'logps/chosen': -305.04998779296875, 'logps/rejected': -165.3000030517578, 'logits/chosen': -7.456250190734863, 'logits/rejected': -7.056250095367432, 'epoch': 1.87}
 62%|██████▏   | 2830/4545 [3:03:08<1:46:28,  3.72s/it] 62%|██████▏   | 2831/4545 [3:03:12<1:47:45,  3.77s/it] 62%|██████▏   | 2832/4545 [3:03:15<1:42:20,  3.58s/it] 62%|██████▏   | 2833/4545 [3:03:19<1:44:40,  3.67s/it] 62%|██████▏   | 2834/4545 [3:03:22<1:38:52,  3.47s/it] 62%|██████▏   | 2835/4545 [3:03:25<1:37:12,  3.41s/it] 62%|██████▏   | 2836/4545 [3:03:28<1:33:34,  3.28s/it] 62%|██████▏   | 2837/4545 [3:03:30<1:25:32,  3.00s/it] 62%|██████▏   | 2838/4545 [3:03:34<1:33:11,  3.28s/it] 62%|██████▏   | 2839/4545 [3:03:38<1:37:40,  3.43s/it] 62%|██████▏   | 2840/4545 [3:03:42<1:41:52,  3.59s/it]                                                       {'loss': 0.2469, 'grad_norm': 54.82395553588867, 'learning_rate': 2.553106559043693e-07, 'rewards/chosen': 0.914013683795929, 'rewards/rejected': -5.6015625, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.517187595367432, 'logps/chosen': -174.89999389648438, 'logps/rejected': -152.9499969482422, 'logits/chosen': -7.643750190734863, 'logits/rejected': -7.378125190734863, 'epoch': 1.87}
 62%|██████▏   | 2840/4545 [3:03:42<1:41:52,  3.59s/it] 63%|██████▎   | 2841/4545 [3:03:46<1:44:56,  3.69s/it] 63%|██████▎   | 2842/4545 [3:03:49<1:43:16,  3.64s/it] 63%|██████▎   | 2843/4545 [3:03:53<1:44:20,  3.68s/it] 63%|██████▎   | 2844/4545 [3:03:57<1:46:19,  3.75s/it] 63%|██████▎   | 2845/4545 [3:04:01<1:45:08,  3.71s/it] 63%|██████▎   | 2846/4545 [3:04:05<1:46:27,  3.76s/it] 63%|██████▎   | 2847/4545 [3:04:09<1:50:05,  3.89s/it] 63%|██████▎   | 2848/4545 [3:04:13<1:51:30,  3.94s/it] 63%|██████▎   | 2849/4545 [3:04:17<1:51:21,  3.94s/it] 63%|██████▎   | 2850/4545 [3:04:21<1:51:12,  3.94s/it]                                                       {'loss': 0.2219, 'grad_norm': 33.39047622680664, 'learning_rate': 2.5347936542782553e-07, 'rewards/chosen': 2.8175292015075684, 'rewards/rejected': -6.046582221984863, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.868749618530273, 'logps/chosen': -280.1499938964844, 'logps/rejected': -199.1999969482422, 'logits/chosen': -7.506249904632568, 'logits/rejected': -7.206250190734863, 'epoch': 1.88}
 63%|██████▎   | 2850/4545 [3:04:21<1:51:12,  3.94s/it] 63%|██████▎   | 2851/4545 [3:04:25<1:50:35,  3.92s/it] 63%|██████▎   | 2852/4545 [3:04:29<1:50:33,  3.92s/it] 63%|██████▎   | 2853/4545 [3:04:32<1:50:22,  3.91s/it] 63%|██████▎   | 2854/4545 [3:04:36<1:50:29,  3.92s/it] 63%|██████▎   | 2855/4545 [3:04:39<1:42:45,  3.65s/it] 63%|██████▎   | 2856/4545 [3:04:42<1:36:57,  3.44s/it] 63%|██████▎   | 2857/4545 [3:04:46<1:40:45,  3.58s/it] 63%|██████▎   | 2858/4545 [3:04:50<1:43:34,  3.68s/it] 63%|██████▎   | 2859/4545 [3:04:54<1:47:38,  3.83s/it] 63%|██████▎   | 2860/4545 [3:04:58<1:44:40,  3.73s/it]                                                       {'loss': 0.2594, 'grad_norm': 28.79140853881836, 'learning_rate': 2.5164447827623104e-07, 'rewards/chosen': 3.479687452316284, 'rewards/rejected': -5.200390815734863, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 8.681249618530273, 'logps/chosen': -326.1499938964844, 'logps/rejected': -189.3249969482422, 'logits/chosen': -7.393750190734863, 'logits/rejected': -7.053124904632568, 'epoch': 1.89}
 63%|██████▎   | 2860/4545 [3:04:58<1:44:40,  3.73s/it] 63%|██████▎   | 2861/4545 [3:05:02<1:46:01,  3.78s/it] 63%|██████▎   | 2862/4545 [3:05:05<1:41:15,  3.61s/it] 63%|██████▎   | 2863/4545 [3:05:09<1:44:40,  3.73s/it] 63%|██████▎   | 2864/4545 [3:05:13<1:46:13,  3.79s/it] 63%|██████▎   | 2865/4545 [3:05:17<1:46:06,  3.79s/it] 63%|██████▎   | 2866/4545 [3:05:20<1:40:13,  3.58s/it] 63%|██████▎   | 2867/4545 [3:05:23<1:39:25,  3.55s/it] 63%|██████▎   | 2868/4545 [3:05:27<1:40:19,  3.59s/it] 63%|██████▎   | 2869/4545 [3:05:31<1:39:37,  3.57s/it] 63%|██████▎   | 2870/4545 [3:05:34<1:42:32,  3.67s/it]                                                       {'loss': 0.2176, 'grad_norm': 35.52376937866211, 'learning_rate': 2.4980619157079024e-07, 'rewards/chosen': 3.5917410850524902, 'rewards/rejected': -6.7178955078125, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 10.317187309265137, 'logps/chosen': -375.29998779296875, 'logps/rejected': -231.75, 'logits/chosen': -7.224999904632568, 'logits/rejected': -6.953125, 'epoch': 1.89}
 63%|██████▎   | 2870/4545 [3:05:34<1:42:32,  3.67s/it] 63%|██████▎   | 2871/4545 [3:05:39<1:46:05,  3.80s/it] 63%|██████▎   | 2872/4545 [3:05:42<1:45:05,  3.77s/it] 63%|██████▎   | 2873/4545 [3:05:46<1:47:27,  3.86s/it] 63%|██████▎   | 2874/4545 [3:05:50<1:49:04,  3.92s/it] 63%|██████▎   | 2875/4545 [3:05:54<1:47:40,  3.87s/it] 63%|██████▎   | 2876/4545 [3:05:57<1:39:51,  3.59s/it] 63%|██████▎   | 2877/4545 [3:06:01<1:39:18,  3.57s/it] 63%|██████▎   | 2878/4545 [3:06:05<1:44:46,  3.77s/it] 63%|██████▎   | 2879/4545 [3:06:09<1:47:32,  3.87s/it] 63%|██████▎   | 2880/4545 [3:06:13<1:48:26,  3.91s/it]                                                       {'loss': 0.2819, 'grad_norm': 52.62688446044922, 'learning_rate': 2.4796470279792046e-07, 'rewards/chosen': 1.4337890148162842, 'rewards/rejected': -4.75, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 6.196875095367432, 'logps/chosen': -209.60000610351562, 'logps/rejected': -125.80000305175781, 'logits/chosen': -7.484375, 'logits/rejected': -7.150000095367432, 'epoch': 1.9}
 63%|██████▎   | 2880/4545 [3:06:13<1:48:26,  3.91s/it] 63%|██████▎   | 2881/4545 [3:06:17<1:46:21,  3.84s/it] 63%|██████▎   | 2882/4545 [3:06:20<1:44:26,  3.77s/it] 63%|██████▎   | 2883/4545 [3:06:24<1:40:48,  3.64s/it] 63%|██████▎   | 2884/4545 [3:06:27<1:43:06,  3.72s/it] 63%|██████▎   | 2885/4545 [3:06:32<1:47:11,  3.87s/it] 63%|██████▎   | 2886/4545 [3:06:36<1:49:56,  3.98s/it] 64%|██████▎   | 2887/4545 [3:06:40<1:49:15,  3.95s/it] 64%|██████▎   | 2888/4545 [3:06:43<1:42:03,  3.70s/it] 64%|██████▎   | 2889/4545 [3:06:47<1:43:52,  3.76s/it] 64%|██████▎   | 2890/4545 [3:06:51<1:44:31,  3.79s/it]                                                       {'loss': 0.2225, 'grad_norm': 24.780385971069336, 'learning_rate': 2.461202097880358e-07, 'rewards/chosen': 2.235644578933716, 'rewards/rejected': -5.542187690734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 7.770312309265137, 'logps/chosen': -250.14999389648438, 'logps/rejected': -190.5, 'logits/chosen': -7.425000190734863, 'logits/rejected': -7.090624809265137, 'epoch': 1.91}
 64%|██████▎   | 2890/4545 [3:06:51<1:44:31,  3.79s/it] 64%|██████▎   | 2891/4545 [3:06:54<1:42:51,  3.73s/it] 64%|██████▎   | 2892/4545 [3:06:57<1:35:08,  3.45s/it] 64%|██████▎   | 2893/4545 [3:07:01<1:38:50,  3.59s/it] 64%|██████▎   | 2894/4545 [3:07:05<1:40:20,  3.65s/it] 64%|██████▎   | 2895/4545 [3:07:09<1:42:28,  3.73s/it] 64%|██████▎   | 2896/4545 [3:07:13<1:43:54,  3.78s/it] 64%|██████▎   | 2897/4545 [3:07:16<1:44:53,  3.82s/it] 64%|██████▍   | 2898/4545 [3:07:20<1:45:23,  3.84s/it] 64%|██████▍   | 2899/4545 [3:07:24<1:45:39,  3.85s/it] 64%|██████▍   | 2900/4545 [3:07:28<1:46:11,  3.87s/it]                                                       {'loss': 0.2413, 'grad_norm': 11.798683166503906, 'learning_rate': 2.442729106942942e-07, 'rewards/chosen': 4.635986328125, 'rewards/rejected': -4.774218559265137, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 9.403124809265137, 'logps/chosen': -396.25, 'logps/rejected': -201.8000030517578, 'logits/chosen': -7.190625190734863, 'logits/rejected': -7.025000095367432, 'epoch': 1.91}
 64%|██████▍   | 2900/4545 [3:07:28<1:46:11,  3.87s/it] 64%|██████▍   | 2901/4545 [3:07:32<1:43:32,  3.78s/it] 64%|██████▍   | 2902/4545 [3:07:35<1:41:23,  3.70s/it] 64%|██████▍   | 2903/4545 [3:07:39<1:42:26,  3.74s/it] 64%|██████▍   | 2904/4545 [3:07:43<1:42:49,  3.76s/it] 64%|██████▍   | 2905/4545 [3:07:46<1:40:46,  3.69s/it] 64%|██████▍   | 2906/4545 [3:07:50<1:42:25,  3.75s/it] 64%|██████▍   | 2907/4545 [3:07:54<1:43:27,  3.79s/it] 64%|██████▍   | 2908/4545 [3:07:58<1:44:06,  3.82s/it] 64%|██████▍   | 2909/4545 [3:08:01<1:39:48,  3.66s/it] 64%|██████▍   | 2910/4545 [3:08:05<1:38:23,  3.61s/it]                                                       {'loss': 0.1979, 'grad_norm': 20.892438888549805, 'learning_rate': 2.4242300397131027e-07, 'rewards/chosen': 1.748046875, 'rewards/rejected': -4.840624809265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.576562404632568, 'logps/chosen': -211.14999389648438, 'logps/rejected': -162.5500030517578, 'logits/chosen': -7.599999904632568, 'logits/rejected': -7.293749809265137, 'epoch': 1.92}
 64%|██████▍   | 2910/4545 [3:08:05<1:38:23,  3.61s/it] 64%|██████▍   | 2911/4545 [3:08:09<1:42:25,  3.76s/it] 64%|██████▍   | 2912/4545 [3:08:13<1:44:28,  3.84s/it] 64%|██████▍   | 2913/4545 [3:08:17<1:44:59,  3.86s/it] 64%|██████▍   | 2914/4545 [3:08:21<1:47:45,  3.96s/it] 64%|██████▍   | 2915/4545 [3:08:25<1:46:39,  3.93s/it] 64%|██████▍   | 2916/4545 [3:08:29<1:44:58,  3.87s/it] 64%|██████▍   | 2917/4545 [3:08:33<1:45:21,  3.88s/it] 64%|██████▍   | 2918/4545 [3:08:37<1:46:54,  3.94s/it] 64%|██████▍   | 2919/4545 [3:08:40<1:45:29,  3.89s/it] 64%|██████▍   | 2920/4545 [3:08:44<1:45:20,  3.89s/it]                                                       {'loss': 0.2201, 'grad_norm': 34.45762252807617, 'learning_rate': 2.405706883538352e-07, 'rewards/chosen': 3.72119140625, 'rewards/rejected': -5.352148532867432, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 9.073437690734863, 'logps/chosen': -321.6499938964844, 'logps/rejected': -215.10000610351562, 'logits/chosen': -7.362500190734863, 'logits/rejected': -6.940625190734863, 'epoch': 1.93}
 64%|██████▍   | 2920/4545 [3:08:44<1:45:20,  3.89s/it] 64%|██████▍   | 2921/4545 [3:08:48<1:44:16,  3.85s/it] 64%|██████▍   | 2922/4545 [3:08:51<1:33:11,  3.45s/it] 64%|██████▍   | 2923/4545 [3:08:53<1:22:36,  3.06s/it] 64%|██████▍   | 2924/4545 [3:08:57<1:29:32,  3.31s/it] 64%|██████▍   | 2925/4545 [3:09:01<1:35:37,  3.54s/it] 64%|██████▍   | 2926/4545 [3:09:04<1:36:20,  3.57s/it] 64%|██████▍   | 2927/4545 [3:09:08<1:39:06,  3.68s/it] 64%|██████▍   | 2928/4545 [3:09:12<1:43:04,  3.82s/it] 64%|██████▍   | 2929/4545 [3:09:16<1:43:21,  3.84s/it] 64%|██████▍   | 2930/4545 [3:09:20<1:40:18,  3.73s/it]                                                       {'loss': 0.3123, 'grad_norm': 23.379627227783203, 'learning_rate': 2.3871616283540674e-07, 'rewards/chosen': 2.4400391578674316, 'rewards/rejected': -4.989062309265137, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 7.423437595367432, 'logps/chosen': -240.47500610351562, 'logps/rejected': -178.0749969482422, 'logits/chosen': -7.471875190734863, 'logits/rejected': -7.175000190734863, 'epoch': 1.93}
 64%|██████▍   | 2930/4545 [3:09:20<1:40:18,  3.73s/it] 64%|██████▍   | 2931/4545 [3:09:23<1:32:14,  3.43s/it] 65%|██████▍   | 2932/4545 [3:09:26<1:36:01,  3.57s/it] 65%|██████▍   | 2933/4545 [3:09:30<1:36:45,  3.60s/it] 65%|██████▍   | 2934/4545 [3:09:34<1:37:30,  3.63s/it] 65%|██████▍   | 2935/4545 [3:09:38<1:39:43,  3.72s/it] 65%|██████▍   | 2936/4545 [3:09:41<1:38:54,  3.69s/it] 65%|██████▍   | 2937/4545 [3:09:45<1:38:23,  3.67s/it] 65%|██████▍   | 2938/4545 [3:09:49<1:37:38,  3.65s/it] 65%|██████▍   | 2939/4545 [3:09:53<1:40:57,  3.77s/it] 65%|██████▍   | 2940/4545 [3:09:57<1:43:37,  3.87s/it]                                                       {'loss': 0.2547, 'grad_norm': 41.93587875366211, 'learning_rate': 2.3685962664697135e-07, 'rewards/chosen': 0.6963135004043579, 'rewards/rejected': -6.9453125, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 7.643750190734863, 'logps/chosen': -171.75, 'logps/rejected': -153.64999389648438, 'logits/chosen': -7.65625, 'logits/rejected': -7.143750190734863, 'epoch': 1.94}
 65%|██████▍   | 2940/4545 [3:09:57<1:43:37,  3.87s/it] 65%|██████▍   | 2941/4545 [3:10:00<1:41:52,  3.81s/it] 65%|██████▍   | 2942/4545 [3:10:04<1:37:56,  3.67s/it] 65%|██████▍   | 2943/4545 [3:10:08<1:42:09,  3.83s/it] 65%|██████▍   | 2944/4545 [3:10:11<1:32:40,  3.47s/it] 65%|██████▍   | 2945/4545 [3:10:15<1:37:59,  3.67s/it] 65%|██████▍   | 2946/4545 [3:10:19<1:41:25,  3.81s/it] 65%|██████▍   | 2947/4545 [3:10:23<1:42:18,  3.84s/it] 65%|██████▍   | 2948/4545 [3:10:27<1:44:13,  3.92s/it] 65%|██████▍   | 2949/4545 [3:10:29<1:34:00,  3.53s/it] 65%|██████▍   | 2950/4545 [3:10:32<1:28:50,  3.34s/it]                                                       {'loss': 0.1371, 'grad_norm': 3.665952444076538, 'learning_rate': 2.3500127923548104e-07, 'rewards/chosen': 1.677709937095642, 'rewards/rejected': -7.279687404632568, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 8.942187309265137, 'logps/chosen': -204.64999389648438, 'logps/rejected': -143.25, 'logits/chosen': -7.640625, 'logits/rejected': -7.206250190734863, 'epoch': 1.95}
 65%|██████▍   | 2950/4545 [3:10:32<1:28:50,  3.34s/it] 65%|██████▍   | 2951/4545 [3:10:36<1:33:29,  3.52s/it] 65%|██████▍   | 2952/4545 [3:10:39<1:24:25,  3.18s/it] 65%|██████▍   | 2953/4545 [3:10:43<1:32:12,  3.48s/it] 65%|██████▍   | 2954/4545 [3:10:47<1:35:39,  3.61s/it] 65%|██████▌   | 2955/4545 [3:10:51<1:37:54,  3.69s/it] 65%|██████▌   | 2956/4545 [3:10:53<1:30:45,  3.43s/it] 65%|██████▌   | 2957/4545 [3:10:57<1:34:28,  3.57s/it] 65%|██████▌   | 2958/4545 [3:11:02<1:39:13,  3.75s/it] 65%|██████▌   | 2959/4545 [3:11:06<1:41:13,  3.83s/it] 65%|██████▌   | 2960/4545 [3:11:08<1:28:23,  3.35s/it]                                                       {'loss': 0.2637, 'grad_norm': 33.40393829345703, 'learning_rate': 2.3314132024246679e-07, 'rewards/chosen': 2.8131103515625, 'rewards/rejected': -4.621874809265137, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 7.442187309265137, 'logps/chosen': -303.0, 'logps/rejected': -209.3000030517578, 'logits/chosen': -7.346875190734863, 'logits/rejected': -7.021874904632568, 'epoch': 1.95}
 65%|██████▌   | 2960/4545 [3:11:08<1:28:23,  3.35s/it] 65%|██████▌   | 2961/4545 [3:11:12<1:32:38,  3.51s/it] 65%|██████▌   | 2962/4545 [3:11:16<1:36:10,  3.65s/it] 65%|██████▌   | 2963/4545 [3:11:20<1:39:43,  3.78s/it] 65%|██████▌   | 2964/4545 [3:11:23<1:37:03,  3.68s/it] 65%|██████▌   | 2965/4545 [3:11:27<1:38:52,  3.75s/it] 65%|██████▌   | 2966/4545 [3:11:31<1:39:41,  3.79s/it] 65%|██████▌   | 2967/4545 [3:11:34<1:35:39,  3.64s/it] 65%|██████▌   | 2968/4545 [3:11:38<1:37:44,  3.72s/it] 65%|██████▌   | 2969/4545 [3:11:42<1:40:36,  3.83s/it] 65%|██████▌   | 2970/4545 [3:11:46<1:41:24,  3.86s/it]                                                       {'loss': 0.228, 'grad_norm': 18.55586814880371, 'learning_rate': 2.312799494825913e-07, 'rewards/chosen': 3.3526368141174316, 'rewards/rejected': -6.658105373382568, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.009374618530273, 'logps/chosen': -337.8500061035156, 'logps/rejected': -188.9499969482422, 'logits/chosen': -7.459374904632568, 'logits/rejected': -6.990624904632568, 'epoch': 1.96}
 65%|██████▌   | 2970/4545 [3:11:46<1:41:24,  3.86s/it] 65%|██████▌   | 2971/4545 [3:11:50<1:41:43,  3.88s/it] 65%|██████▌   | 2972/4545 [3:11:54<1:39:22,  3.79s/it] 65%|██████▌   | 2973/4545 [3:11:58<1:42:27,  3.91s/it] 65%|██████▌   | 2974/4545 [3:12:02<1:41:55,  3.89s/it] 65%|██████▌   | 2975/4545 [3:12:06<1:42:18,  3.91s/it] 65%|██████▌   | 2976/4545 [3:12:10<1:42:07,  3.91s/it] 66%|██████▌   | 2977/4545 [3:12:14<1:42:17,  3.91s/it] 66%|██████▌   | 2978/4545 [3:12:18<1:43:54,  3.98s/it] 66%|██████▌   | 2979/4545 [3:12:22<1:44:42,  4.01s/it] 66%|██████▌   | 2980/4545 [3:12:26<1:43:55,  3.98s/it]                                                       {'loss': 0.2906, 'grad_norm': 10.18781852722168, 'learning_rate': 2.2941736692218248e-07, 'rewards/chosen': 3.6832032203674316, 'rewards/rejected': -5.614111423492432, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 9.293749809265137, 'logps/chosen': -396.8500061035156, 'logps/rejected': -239.14999389648438, 'logits/chosen': -7.496874809265137, 'logits/rejected': -7.221875190734863, 'epoch': 1.97}
 66%|██████▌   | 2980/4545 [3:12:26<1:43:55,  3.98s/it] 66%|██████▌   | 2981/4545 [3:12:29<1:37:57,  3.76s/it] 66%|██████▌   | 2982/4545 [3:12:33<1:39:04,  3.80s/it] 66%|██████▌   | 2983/4545 [3:12:36<1:37:02,  3.73s/it] 66%|██████▌   | 2984/4545 [3:12:40<1:37:56,  3.76s/it] 66%|██████▌   | 2985/4545 [3:12:44<1:34:53,  3.65s/it] 66%|██████▌   | 2986/4545 [3:12:47<1:36:48,  3.73s/it] 66%|██████▌   | 2987/4545 [3:12:51<1:38:15,  3.78s/it] 66%|██████▌   | 2988/4545 [3:12:55<1:35:57,  3.70s/it] 66%|██████▌   | 2989/4545 [3:12:59<1:39:17,  3.83s/it] 66%|██████▌   | 2990/4545 [3:13:03<1:40:09,  3.86s/it]                                                       {'loss': 0.2088, 'grad_norm': 11.83511734008789, 'learning_rate': 2.275537726577519e-07, 'rewards/chosen': 2.297802686691284, 'rewards/rejected': -8.3359375, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 10.643750190734863, 'logps/chosen': -279.6000061035156, 'logps/rejected': -169.64999389648438, 'logits/chosen': -7.496874809265137, 'logits/rejected': -7.068749904632568, 'epoch': 1.97}
 66%|██████▌   | 2990/4545 [3:13:03<1:40:09,  3.86s/it] 66%|██████▌   | 2991/4545 [3:13:07<1:40:23,  3.88s/it] 66%|██████▌   | 2992/4545 [3:13:11<1:42:50,  3.97s/it] 66%|██████▌   | 2993/4545 [3:13:15<1:44:39,  4.05s/it] 66%|██████▌   | 2994/4545 [3:13:19<1:43:22,  4.00s/it] 66%|██████▌   | 2995/4545 [3:13:23<1:42:35,  3.97s/it] 66%|██████▌   | 2996/4545 [3:13:26<1:33:54,  3.64s/it] 66%|██████▌   | 2997/4545 [3:13:30<1:35:53,  3.72s/it] 66%|██████▌   | 2998/4545 [3:13:34<1:35:31,  3.71s/it] 66%|██████▌   | 2999/4545 [3:13:37<1:36:59,  3.76s/it] 66%|██████▌   | 3000/4545 [3:13:41<1:35:34,  3.71s/it]                                                       {'loss': 0.1827, 'grad_norm': 20.054840087890625, 'learning_rate': 2.256893668944977e-07, 'rewards/chosen': 3.1429686546325684, 'rewards/rejected': -6.940625190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 10.071874618530273, 'logps/chosen': -355.95001220703125, 'logps/rejected': -219.85000610351562, 'logits/chosen': -7.506249904632568, 'logits/rejected': -7.109375, 'epoch': 1.98}
 66%|██████▌   | 3000/4545 [3:13:41<1:35:34,  3.71s/it] 66%|██████▌   | 3001/4545 [3:13:45<1:36:57,  3.77s/it] 66%|██████▌   | 3002/4545 [3:13:49<1:35:53,  3.73s/it] 66%|██████▌   | 3003/4545 [3:13:52<1:36:50,  3.77s/it] 66%|██████▌   | 3004/4545 [3:13:56<1:37:49,  3.81s/it] 66%|██████▌   | 3005/4545 [3:14:01<1:40:31,  3.92s/it] 66%|██████▌   | 3006/4545 [3:14:04<1:36:57,  3.78s/it] 66%|██████▌   | 3007/4545 [3:14:08<1:36:35,  3.77s/it] 66%|██████▌   | 3008/4545 [3:14:12<1:37:39,  3.81s/it] 66%|██████▌   | 3009/4545 [3:14:15<1:32:07,  3.60s/it] 66%|██████▌   | 3010/4545 [3:14:18<1:31:28,  3.58s/it]                                                       {'loss': 0.1992, 'grad_norm': 26.545148849487305, 'learning_rate': 2.2382434992479732e-07, 'rewards/chosen': 3.145825147628784, 'rewards/rejected': -5.947265625, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 9.096875190734863, 'logps/chosen': -330.25, 'logps/rejected': -181.5, 'logits/chosen': -7.371874809265137, 'logits/rejected': -7.081250190734863, 'epoch': 1.99}
 66%|██████▌   | 3010/4545 [3:14:18<1:31:28,  3.58s/it] 66%|██████▌   | 3011/4545 [3:14:22<1:31:00,  3.56s/it] 66%|██████▋   | 3012/4545 [3:14:26<1:33:36,  3.66s/it] 66%|██████▋   | 3013/4545 [3:14:29<1:34:26,  3.70s/it] 66%|██████▋   | 3014/4545 [3:14:33<1:36:04,  3.77s/it] 66%|██████▋   | 3015/4545 [3:14:37<1:37:03,  3.81s/it] 66%|██████▋   | 3016/4545 [3:14:41<1:39:11,  3.89s/it] 66%|██████▋   | 3017/4545 [3:14:44<1:26:54,  3.41s/it] 66%|██████▋   | 3018/4545 [3:14:48<1:31:15,  3.59s/it] 66%|██████▋   | 3019/4545 [3:14:52<1:33:57,  3.69s/it] 66%|██████▋   | 3020/4545 [3:14:55<1:29:23,  3.52s/it]                                                       {'loss': 0.1761, 'grad_norm': 11.598113059997559, 'learning_rate': 2.2195892210668977e-07, 'rewards/chosen': 2.3384766578674316, 'rewards/rejected': -5.71875, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.0546875, 'logps/chosen': -237.39999389648438, 'logps/rejected': -134.14999389648438, 'logits/chosen': -7.668749809265137, 'logits/rejected': -7.284375190734863, 'epoch': 1.99}
 66%|██████▋   | 3020/4545 [3:14:55<1:29:23,  3.52s/it] 66%|██████▋   | 3021/4545 [3:14:58<1:31:08,  3.59s/it] 66%|██████▋   | 3022/4545 [3:15:02<1:29:59,  3.55s/it] 67%|██████▋   | 3023/4545 [3:15:06<1:32:40,  3.65s/it] 67%|██████▋   | 3024/4545 [3:15:10<1:35:54,  3.78s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.51s/it][A
 13%|█▎        | 8/60 [00:11<01:21,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:19,  1.63s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.61s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:20<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.27s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.13s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:32<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.29s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:38<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:41<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.36s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:46<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.08s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:58<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:02<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.38s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:13<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:16<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A                                                       
                                               [A{'eval_loss': 0.40523865818977356, 'eval_runtime': 80.1394, 'eval_samples_per_second': 11.892, 'eval_steps_per_second': 0.749, 'eval_rewards/chosen': 3.168408155441284, 'eval_rewards/rejected': -4.225195407867432, 'eval_rewards/accuracies': 0.8146990537643433, 'eval_rewards/margins': 7.3902668952941895, 'eval_logps/chosen': -361.70001220703125, 'eval_logps/rejected': -173.0625, 'eval_logits/chosen': -7.279687404632568, 'eval_logits/rejected': -7.613541603088379, 'epoch': 2.0}
 67%|██████▋   | 3024/4545 [3:16:30<1:35:54,  3.78s/it]
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 67%|██████▋   | 3025/4545 [3:16:44<13:03:21, 30.92s/it] 67%|██████▋   | 3026/4545 [3:16:48<9:37:30, 22.81s/it]  67%|██████▋   | 3027/4545 [3:16:52<7:13:43, 17.14s/it] 67%|██████▋   | 3028/4545 [3:16:56<5:32:03, 13.13s/it] 67%|██████▋   | 3029/4545 [3:17:00<4:22:01, 10.37s/it] 67%|██████▋   | 3030/4545 [3:17:04<3:33:00,  8.44s/it]                                                       {'loss': 0.2414, 'grad_norm': 20.773757934570312, 'learning_rate': 2.200932838423513e-07, 'rewards/chosen': 6.338281154632568, 'rewards/rejected': -8.441625595092773, 'rewards/accuracies': 0.90625, 'rewards/margins': 14.790624618530273, 'logps/chosen': -563.2000122070312, 'logps/rejected': -349.95001220703125, 'logits/chosen': -7.126562595367432, 'logits/rejected': -6.90625, 'epoch': 2.0}
 67%|██████▋   | 3030/4545 [3:17:04<3:33:00,  8.44s/it] 67%|██████▋   | 3031/4545 [3:17:07<2:54:15,  6.91s/it] 67%|██████▋   | 3032/4545 [3:17:11<2:31:24,  6.00s/it] 67%|██████▋   | 3033/4545 [3:17:14<2:13:47,  5.31s/it] 67%|██████▋   | 3034/4545 [3:17:18<1:58:12,  4.69s/it] 67%|██████▋   | 3035/4545 [3:17:21<1:49:26,  4.35s/it] 67%|██████▋   | 3036/4545 [3:17:25<1:46:05,  4.22s/it] 67%|██████▋   | 3037/4545 [3:17:29<1:43:22,  4.11s/it] 67%|██████▋   | 3038/4545 [3:17:33<1:41:55,  4.06s/it] 67%|██████▋   | 3039/4545 [3:17:37<1:39:56,  3.98s/it] 67%|██████▋   | 3040/4545 [3:17:40<1:35:50,  3.82s/it]                                                       {'loss': 0.1473, 'grad_norm': 15.942813873291016, 'learning_rate': 2.1822763555656638e-07, 'rewards/chosen': 2.117382764816284, 'rewards/rejected': -5.939062595367432, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.053125381469727, 'logps/chosen': -253.4499969482422, 'logps/rejected': -171.85000610351562, 'logits/chosen': -7.587500095367432, 'logits/rejected': -7.196875095367432, 'epoch': 2.01}
 67%|██████▋   | 3040/4545 [3:17:40<1:35:50,  3.82s/it] 67%|██████▋   | 3041/4545 [3:17:44<1:33:31,  3.73s/it] 67%|██████▋   | 3042/4545 [3:17:48<1:36:15,  3.84s/it] 67%|██████▋   | 3043/4545 [3:17:52<1:38:04,  3.92s/it] 67%|██████▋   | 3044/4545 [3:17:54<1:26:23,  3.45s/it] 67%|██████▋   | 3045/4545 [3:17:58<1:29:27,  3.58s/it] 67%|██████▋   | 3046/4545 [3:18:01<1:23:40,  3.35s/it] 67%|██████▋   | 3047/4545 [3:18:05<1:27:52,  3.52s/it] 67%|██████▋   | 3048/4545 [3:18:09<1:29:38,  3.59s/it] 67%|██████▋   | 3049/4545 [3:18:13<1:31:41,  3.68s/it] 67%|██████▋   | 3050/4545 [3:18:16<1:26:11,  3.46s/it]                                                       {'loss': 0.2008, 'grad_norm': 35.07418441772461, 'learning_rate': 2.16362177675196e-07, 'rewards/chosen': 3.50250244140625, 'rewards/rejected': -5.575390815734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 9.064062118530273, 'logps/chosen': -341.3999938964844, 'logps/rejected': -163.10000610351562, 'logits/chosen': -7.506249904632568, 'logits/rejected': -7.25, 'epoch': 2.01}
 67%|██████▋   | 3050/4545 [3:18:16<1:26:11,  3.46s/it] 67%|██████▋   | 3051/4545 [3:18:19<1:29:23,  3.59s/it] 67%|██████▋   | 3052/4545 [3:18:23<1:31:47,  3.69s/it] 67%|██████▋   | 3053/4545 [3:18:27<1:34:35,  3.80s/it] 67%|██████▋   | 3054/4545 [3:18:31<1:35:13,  3.83s/it] 67%|██████▋   | 3055/4545 [3:18:35<1:35:26,  3.84s/it] 67%|██████▋   | 3056/4545 [3:18:39<1:37:33,  3.93s/it] 67%|██████▋   | 3057/4545 [3:18:43<1:37:16,  3.92s/it] 67%|██████▋   | 3058/4545 [3:18:47<1:37:13,  3.92s/it] 67%|██████▋   | 3059/4545 [3:18:51<1:37:04,  3.92s/it] 67%|██████▋   | 3060/4545 [3:18:54<1:33:06,  3.76s/it]                                                       {'loss': 0.1857, 'grad_norm': 21.133502960205078, 'learning_rate': 2.1449711060364607e-07, 'rewards/chosen': 3.116894483566284, 'rewards/rejected': -6.421875, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.518750190734863, 'logps/chosen': -294.3500061035156, 'logps/rejected': -200.85000610351562, 'logits/chosen': -7.4375, 'logits/rejected': -6.962500095367432, 'epoch': 2.02}
 67%|██████▋   | 3060/4545 [3:18:54<1:33:06,  3.76s/it] 67%|██████▋   | 3061/4545 [3:18:58<1:34:16,  3.81s/it] 67%|██████▋   | 3062/4545 [3:19:02<1:34:41,  3.83s/it] 67%|██████▋   | 3063/4545 [3:19:06<1:35:18,  3.86s/it] 67%|██████▋   | 3064/4545 [3:19:10<1:33:41,  3.80s/it] 67%|██████▋   | 3065/4545 [3:19:14<1:36:22,  3.91s/it] 67%|██████▋   | 3066/4545 [3:19:17<1:32:27,  3.75s/it] 67%|██████▋   | 3067/4545 [3:19:21<1:33:07,  3.78s/it] 68%|██████▊   | 3068/4545 [3:19:25<1:35:05,  3.86s/it] 68%|██████▊   | 3069/4545 [3:19:29<1:32:17,  3.75s/it] 68%|██████▊   | 3070/4545 [3:19:32<1:25:43,  3.49s/it]                                                       {'loss': 0.2211, 'grad_norm': 24.46234130859375, 'learning_rate': 2.1263263470533825e-07, 'rewards/chosen': 1.2759277820587158, 'rewards/rejected': -6.770312309265137, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 8.034375190734863, 'logps/chosen': -172.0500030517578, 'logps/rejected': -124.8499984741211, 'logits/chosen': -7.6875, 'logits/rejected': -7.349999904632568, 'epoch': 2.03}
 68%|██████▊   | 3070/4545 [3:19:32<1:25:43,  3.49s/it] 68%|██████▊   | 3071/4545 [3:19:36<1:30:40,  3.69s/it] 68%|██████▊   | 3072/4545 [3:19:40<1:32:09,  3.75s/it] 68%|██████▊   | 3073/4545 [3:19:44<1:34:43,  3.86s/it] 68%|██████▊   | 3074/4545 [3:19:47<1:30:43,  3.70s/it] 68%|██████▊   | 3075/4545 [3:19:51<1:32:08,  3.76s/it] 68%|██████▊   | 3076/4545 [3:19:55<1:33:14,  3.81s/it] 68%|██████▊   | 3077/4545 [3:19:59<1:33:47,  3.83s/it] 68%|██████▊   | 3078/4545 [3:20:03<1:32:44,  3.79s/it] 68%|██████▊   | 3079/4545 [3:20:06<1:33:12,  3.81s/it] 68%|██████▊   | 3080/4545 [3:20:09<1:24:39,  3.47s/it]                                                       {'loss': 0.1452, 'grad_norm': 21.151018142700195, 'learning_rate': 2.107689502801843e-07, 'rewards/chosen': 2.583984375, 'rewards/rejected': -7.356249809265137, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 9.940625190734863, 'logps/chosen': -279.75, 'logps/rejected': -212.60000610351562, 'logits/chosen': -7.409375190734863, 'logits/rejected': -7.012499809265137, 'epoch': 2.03}
 68%|██████▊   | 3080/4545 [3:20:09<1:24:39,  3.47s/it] 68%|██████▊   | 3081/4545 [3:20:13<1:28:37,  3.63s/it] 68%|██████▊   | 3082/4545 [3:20:17<1:29:56,  3.69s/it] 68%|██████▊   | 3083/4545 [3:20:21<1:32:50,  3.81s/it] 68%|██████▊   | 3084/4545 [3:20:25<1:33:30,  3.84s/it] 68%|██████▊   | 3085/4545 [3:20:29<1:33:20,  3.84s/it] 68%|██████▊   | 3086/4545 [3:20:31<1:23:13,  3.42s/it] 68%|██████▊   | 3087/4545 [3:20:35<1:26:39,  3.57s/it] 68%|██████▊   | 3088/4545 [3:20:39<1:29:11,  3.67s/it] 68%|██████▊   | 3089/4545 [3:20:43<1:30:45,  3.74s/it] 68%|██████▊   | 3090/4545 [3:20:47<1:31:44,  3.78s/it]                                                       {'loss': 0.2688, 'grad_norm': 33.1155891418457, 'learning_rate': 2.0890625754306846e-07, 'rewards/chosen': 3.10498046875, 'rewards/rejected': -5.357812404632568, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 8.459375381469727, 'logps/chosen': -306.95001220703125, 'logps/rejected': -177.0, 'logits/chosen': -7.478125095367432, 'logits/rejected': -7.153124809265137, 'epoch': 2.04}
 68%|██████▊   | 3090/4545 [3:20:47<1:31:44,  3.78s/it] 68%|██████▊   | 3091/4545 [3:20:50<1:28:28,  3.65s/it] 68%|██████▊   | 3092/4545 [3:20:54<1:27:59,  3.63s/it] 68%|██████▊   | 3093/4545 [3:20:58<1:30:13,  3.73s/it] 68%|██████▊   | 3094/4545 [3:21:02<1:31:33,  3.79s/it] 68%|██████▊   | 3095/4545 [3:21:04<1:21:56,  3.39s/it] 68%|██████▊   | 3096/4545 [3:21:08<1:25:25,  3.54s/it] 68%|██████▊   | 3097/4545 [3:21:12<1:29:11,  3.70s/it] 68%|██████▊   | 3098/4545 [3:21:16<1:30:42,  3.76s/it] 68%|██████▊   | 3099/4545 [3:21:20<1:31:45,  3.81s/it] 68%|██████▊   | 3100/4545 [3:21:24<1:32:28,  3.84s/it]                                                       {'loss': 0.3799, 'grad_norm': 35.41291427612305, 'learning_rate': 2.070447566023384e-07, 'rewards/chosen': 3.93115234375, 'rewards/rejected': -4.823925971984863, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.737500190734863, 'logps/chosen': -339.8999938964844, 'logps/rejected': -230.85000610351562, 'logits/chosen': -7.565625190734863, 'logits/rejected': -6.946875095367432, 'epoch': 2.05}
 68%|██████▊   | 3100/4545 [3:21:24<1:32:28,  3.84s/it] 68%|██████▊   | 3101/4545 [3:21:27<1:29:42,  3.73s/it] 68%|██████▊   | 3102/4545 [3:21:31<1:31:08,  3.79s/it] 68%|██████▊   | 3103/4545 [3:21:35<1:31:51,  3.82s/it] 68%|██████▊   | 3104/4545 [3:21:39<1:34:46,  3.95s/it] 68%|██████▊   | 3105/4545 [3:21:42<1:23:23,  3.47s/it] 68%|██████▊   | 3106/4545 [3:21:46<1:27:18,  3.64s/it] 68%|██████▊   | 3107/4545 [3:21:49<1:23:15,  3.47s/it] 68%|██████▊   | 3108/4545 [3:21:53<1:26:17,  3.60s/it] 68%|██████▊   | 3109/4545 [3:21:57<1:29:22,  3.73s/it] 68%|██████▊   | 3110/4545 [3:22:01<1:30:41,  3.79s/it]                                                       {'loss': 0.2239, 'grad_norm': 34.997291564941406, 'learning_rate': 2.0518464743830748e-07, 'rewards/chosen': 3.1128907203674316, 'rewards/rejected': -4.982812404632568, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 8.090624809265137, 'logps/chosen': -279.29998779296875, 'logps/rejected': -159.6999969482422, 'logits/chosen': -7.6875, 'logits/rejected': -7.315625190734863, 'epoch': 2.05}
 68%|██████▊   | 3110/4545 [3:22:01<1:30:41,  3.79s/it] 68%|██████▊   | 3111/4545 [3:22:05<1:31:10,  3.81s/it] 68%|██████▊   | 3112/4545 [3:22:09<1:34:09,  3.94s/it] 68%|██████▊   | 3113/4545 [3:22:12<1:27:29,  3.67s/it] 69%|██████▊   | 3114/4545 [3:22:16<1:29:19,  3.75s/it] 69%|██████▊   | 3115/4545 [3:22:20<1:30:33,  3.80s/it] 69%|██████▊   | 3116/4545 [3:22:24<1:31:23,  3.84s/it] 69%|██████▊   | 3117/4545 [3:22:28<1:32:40,  3.89s/it] 69%|██████▊   | 3118/4545 [3:22:32<1:32:41,  3.90s/it] 69%|██████▊   | 3119/4545 [3:22:35<1:32:42,  3.90s/it] 69%|██████▊   | 3120/4545 [3:22:39<1:29:57,  3.79s/it]                                                       {'loss': 0.1729, 'grad_norm': 16.837631225585938, 'learning_rate': 2.033261298817711e-07, 'rewards/chosen': 5.595205783843994, 'rewards/rejected': -5.465624809265137, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 11.059374809265137, 'logps/chosen': -476.20001220703125, 'logps/rejected': -274.3999938964844, 'logits/chosen': -7.196875095367432, 'logits/rejected': -6.915625095367432, 'epoch': 2.06}
 69%|██████▊   | 3120/4545 [3:22:39<1:29:57,  3.79s/it] 69%|██████▊   | 3121/4545 [3:22:43<1:30:51,  3.83s/it] 69%|██████▊   | 3122/4545 [3:22:47<1:33:05,  3.93s/it] 69%|██████▊   | 3123/4545 [3:22:51<1:32:50,  3.92s/it] 69%|██████▊   | 3124/4545 [3:22:54<1:24:21,  3.56s/it] 69%|██████▉   | 3125/4545 [3:22:58<1:27:02,  3.68s/it] 69%|██████▉   | 3126/4545 [3:23:00<1:21:06,  3.43s/it] 69%|██████▉   | 3127/4545 [3:23:04<1:24:26,  3.57s/it] 69%|██████▉   | 3128/4545 [3:23:08<1:26:42,  3.67s/it] 69%|██████▉   | 3129/4545 [3:23:11<1:17:44,  3.29s/it] 69%|██████▉   | 3130/4545 [3:23:14<1:19:48,  3.38s/it]                                                       {'loss': 0.1809, 'grad_norm': 23.487895965576172, 'learning_rate': 2.0146940359253874e-07, 'rewards/chosen': 2.938525438308716, 'rewards/rejected': -3.784374952316284, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 6.729687690734863, 'logps/chosen': -273.67498779296875, 'logps/rejected': -215.85000610351562, 'logits/chosen': -7.628125190734863, 'logits/rejected': -7.240624904632568, 'epoch': 2.07}
 69%|██████▉   | 3130/4545 [3:23:14<1:19:48,  3.38s/it] 69%|██████▉   | 3131/4545 [3:23:17<1:18:03,  3.31s/it] 69%|██████▉   | 3132/4545 [3:23:22<1:24:32,  3.59s/it] 69%|██████▉   | 3133/4545 [3:23:24<1:18:47,  3.35s/it] 69%|██████▉   | 3134/4545 [3:23:28<1:22:45,  3.52s/it] 69%|██████▉   | 3135/4545 [3:23:32<1:25:26,  3.64s/it] 69%|██████▉   | 3136/4545 [3:23:36<1:28:02,  3.75s/it] 69%|██████▉   | 3137/4545 [3:23:40<1:30:47,  3.87s/it] 69%|██████▉   | 3138/4545 [3:23:43<1:23:10,  3.55s/it] 69%|██████▉   | 3139/4545 [3:23:47<1:24:45,  3.62s/it] 69%|██████▉   | 3140/4545 [3:23:51<1:26:18,  3.69s/it]                                                       {'loss': 0.1822, 'grad_norm': 24.074853897094727, 'learning_rate': 1.9961466803798505e-07, 'rewards/chosen': 2.41748046875, 'rewards/rejected': -5.30078125, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 7.704687595367432, 'logps/chosen': -251.8249969482422, 'logps/rejected': -197.8000030517578, 'logits/chosen': -7.643750190734863, 'logits/rejected': -7.171875, 'epoch': 2.07}
 69%|██████▉   | 3140/4545 [3:23:51<1:26:18,  3.69s/it] 69%|██████▉   | 3141/4545 [3:23:55<1:27:46,  3.75s/it] 69%|██████▉   | 3142/4545 [3:23:59<1:28:56,  3.80s/it] 69%|██████▉   | 3143/4545 [3:24:01<1:20:43,  3.45s/it] 69%|██████▉   | 3144/4545 [3:24:05<1:22:14,  3.52s/it] 69%|██████▉   | 3145/4545 [3:24:09<1:24:29,  3.62s/it] 69%|██████▉   | 3146/4545 [3:24:13<1:26:21,  3.70s/it] 69%|██████▉   | 3147/4545 [3:24:17<1:27:52,  3.77s/it] 69%|██████▉   | 3148/4545 [3:24:21<1:28:48,  3.81s/it] 69%|██████▉   | 3149/4545 [3:24:23<1:19:53,  3.43s/it] 69%|██████▉   | 3150/4545 [3:24:27<1:22:58,  3.57s/it]                                                       {'loss': 0.268, 'grad_norm': 30.065784454345703, 'learning_rate': 1.977621224716206e-07, 'rewards/chosen': 3.6192870140075684, 'rewards/rejected': -4.425000190734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.035937309265137, 'logps/chosen': -334.0, 'logps/rejected': -185.89999389648438, 'logits/chosen': -7.362500190734863, 'logits/rejected': -7.034375190734863, 'epoch': 2.08}
 69%|██████▉   | 3150/4545 [3:24:27<1:22:58,  3.57s/it] 69%|██████▉   | 3151/4545 [3:24:31<1:26:18,  3.71s/it] 69%|██████▉   | 3152/4545 [3:24:35<1:27:36,  3.77s/it] 69%|██████▉   | 3153/4545 [3:24:39<1:29:52,  3.87s/it] 69%|██████▉   | 3154/4545 [3:24:43<1:29:59,  3.88s/it] 69%|██████▉   | 3155/4545 [3:24:47<1:29:30,  3.86s/it] 69%|██████▉   | 3156/4545 [3:24:49<1:19:43,  3.44s/it] 69%|██████▉   | 3157/4545 [3:24:53<1:19:02,  3.42s/it] 69%|██████▉   | 3158/4545 [3:24:57<1:23:04,  3.59s/it] 70%|██████▉   | 3159/4545 [3:25:00<1:21:11,  3.51s/it] 70%|██████▉   | 3160/4545 [3:25:04<1:23:39,  3.62s/it]                                                       {'loss': 0.1875, 'grad_norm': 36.09231948852539, 'learning_rate': 1.9591196591168638e-07, 'rewards/chosen': 3.0989747047424316, 'rewards/rejected': -4.842968940734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 7.932812690734863, 'logps/chosen': -286.20001220703125, 'logps/rejected': -242.3000030517578, 'logits/chosen': -7.371874809265137, 'logits/rejected': -6.915625095367432, 'epoch': 2.09}
 70%|██████▉   | 3160/4545 [3:25:04<1:23:39,  3.62s/it] 70%|██████▉   | 3161/4545 [3:25:07<1:22:54,  3.59s/it] 70%|██████▉   | 3162/4545 [3:25:11<1:25:00,  3.69s/it] 70%|██████▉   | 3163/4545 [3:25:15<1:25:52,  3.73s/it] 70%|██████▉   | 3164/4545 [3:25:19<1:23:43,  3.64s/it] 70%|██████▉   | 3165/4545 [3:25:22<1:22:06,  3.57s/it] 70%|██████▉   | 3166/4545 [3:25:26<1:24:30,  3.68s/it] 70%|██████▉   | 3167/4545 [3:25:30<1:25:43,  3.73s/it] 70%|██████▉   | 3168/4545 [3:25:34<1:26:34,  3.77s/it] 70%|██████▉   | 3169/4545 [3:25:37<1:26:41,  3.78s/it] 70%|██████▉   | 3170/4545 [3:25:41<1:27:30,  3.82s/it]                                                       {'loss': 0.1428, 'grad_norm': 19.179536819458008, 'learning_rate': 1.9406439711977347e-07, 'rewards/chosen': 2.258758544921875, 'rewards/rejected': -7.610937595367432, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.875, 'logps/chosen': -263.04998779296875, 'logps/rejected': -188.6999969482422, 'logits/chosen': -7.59375, 'logits/rejected': -7.056250095367432, 'epoch': 2.09}
 70%|██████▉   | 3170/4545 [3:25:41<1:27:30,  3.82s/it] 70%|██████▉   | 3171/4545 [3:25:45<1:24:01,  3.67s/it] 70%|██████▉   | 3172/4545 [3:25:49<1:26:06,  3.76s/it] 70%|██████▉   | 3173/4545 [3:25:53<1:29:48,  3.93s/it] 70%|██████▉   | 3174/4545 [3:25:57<1:29:37,  3.92s/it] 70%|██████▉   | 3175/4545 [3:26:00<1:26:41,  3.80s/it] 70%|██████▉   | 3176/4545 [3:26:04<1:27:20,  3.83s/it] 70%|██████▉   | 3177/4545 [3:26:08<1:27:47,  3.85s/it] 70%|██████▉   | 3178/4545 [3:26:12<1:28:05,  3.87s/it] 70%|██████▉   | 3179/4545 [3:26:16<1:28:19,  3.88s/it] 70%|██████▉   | 3180/4545 [3:26:20<1:28:28,  3.89s/it]                                                       {'loss': 0.2156, 'grad_norm': 10.5960693359375, 'learning_rate': 1.9221961457946997e-07, 'rewards/chosen': 5.307299613952637, 'rewards/rejected': -4.644140720367432, 'rewards/accuracies': 0.875, 'rewards/margins': 9.949999809265137, 'logps/chosen': -442.3500061035156, 'logps/rejected': -224.25, 'logits/chosen': -7.240624904632568, 'logits/rejected': -7.234375, 'epoch': 2.1}
 70%|██████▉   | 3180/4545 [3:26:20<1:28:28,  3.89s/it] 70%|██████▉   | 3181/4545 [3:26:24<1:29:44,  3.95s/it] 70%|███████   | 3182/4545 [3:26:28<1:29:55,  3.96s/it] 70%|███████   | 3183/4545 [3:26:32<1:29:29,  3.94s/it] 70%|███████   | 3184/4545 [3:26:36<1:29:07,  3.93s/it] 70%|███████   | 3185/4545 [3:26:40<1:28:54,  3.92s/it] 70%|███████   | 3186/4545 [3:26:43<1:25:59,  3.80s/it] 70%|███████   | 3187/4545 [3:26:46<1:22:12,  3.63s/it] 70%|███████   | 3188/4545 [3:26:50<1:24:47,  3.75s/it] 70%|███████   | 3189/4545 [3:26:54<1:26:59,  3.85s/it] 70%|███████   | 3190/4545 [3:26:58<1:27:38,  3.88s/it]                                                       {'loss': 0.1886, 'grad_norm': 18.051246643066406, 'learning_rate': 1.9037781647503808e-07, 'rewards/chosen': 3.263476610183716, 'rewards/rejected': -5.887499809265137, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 9.146875381469727, 'logps/chosen': -277.95001220703125, 'logps/rejected': -174.9499969482422, 'logits/chosen': -7.615624904632568, 'logits/rejected': -7.328125, 'epoch': 2.11}
 70%|███████   | 3190/4545 [3:26:58<1:27:38,  3.88s/it] 70%|███████   | 3191/4545 [3:27:03<1:30:20,  4.00s/it] 70%|███████   | 3192/4545 [3:27:07<1:30:52,  4.03s/it] 70%|███████   | 3193/4545 [3:27:10<1:23:55,  3.72s/it] 70%|███████   | 3194/4545 [3:27:14<1:26:35,  3.85s/it] 70%|███████   | 3195/4545 [3:27:18<1:27:28,  3.89s/it] 70%|███████   | 3196/4545 [3:27:22<1:27:29,  3.89s/it] 70%|███████   | 3197/4545 [3:27:26<1:27:22,  3.89s/it] 70%|███████   | 3198/4545 [3:27:29<1:25:35,  3.81s/it] 70%|███████   | 3199/4545 [3:27:33<1:26:14,  3.84s/it] 70%|███████   | 3200/4545 [3:27:37<1:27:52,  3.92s/it]                                                       {'loss': 0.155, 'grad_norm': 9.079606056213379, 'learning_rate': 1.8853920067012332e-07, 'rewards/chosen': 4.665087699890137, 'rewards/rejected': -3.7203125953674316, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.378125190734863, 'logps/chosen': -408.04998779296875, 'logps/rejected': -249.39999389648438, 'logits/chosen': -7.3125, 'logits/rejected': -7.240624904632568, 'epoch': 2.11}
 70%|███████   | 3200/4545 [3:27:37<1:27:52,  3.92s/it] 70%|███████   | 3201/4545 [3:27:41<1:27:45,  3.92s/it] 70%|███████   | 3202/4545 [3:27:45<1:24:43,  3.78s/it] 70%|███████   | 3203/4545 [3:27:49<1:25:42,  3.83s/it] 70%|███████   | 3204/4545 [3:27:52<1:19:47,  3.57s/it] 71%|███████   | 3205/4545 [3:27:54<1:10:31,  3.16s/it] 71%|███████   | 3206/4545 [3:27:58<1:17:33,  3.48s/it] 71%|███████   | 3207/4545 [3:28:01<1:17:03,  3.46s/it] 71%|███████   | 3208/4545 [3:28:04<1:13:03,  3.28s/it] 71%|███████   | 3209/4545 [3:28:07<1:11:51,  3.23s/it] 71%|███████   | 3210/4545 [3:28:11<1:14:36,  3.35s/it]                                                       {'loss': 0.1763, 'grad_norm': 16.785348892211914, 'learning_rate': 1.8670396468649781e-07, 'rewards/chosen': 1.995019555091858, 'rewards/rejected': -7.490624904632568, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.481249809265137, 'logps/chosen': -208.8000030517578, 'logps/rejected': -139.0, 'logits/chosen': -7.709374904632568, 'logits/rejected': -7.265625, 'epoch': 2.12}
 71%|███████   | 3210/4545 [3:28:11<1:14:36,  3.35s/it] 71%|███████   | 3211/4545 [3:28:15<1:19:01,  3.55s/it] 71%|███████   | 3212/4545 [3:28:19<1:21:21,  3.66s/it] 71%|███████   | 3213/4545 [3:28:23<1:23:08,  3.75s/it] 71%|███████   | 3214/4545 [3:28:27<1:24:16,  3.80s/it] 71%|███████   | 3215/4545 [3:28:31<1:26:06,  3.88s/it] 71%|███████   | 3216/4545 [3:28:34<1:21:33,  3.68s/it] 71%|███████   | 3217/4545 [3:28:38<1:23:00,  3.75s/it] 71%|███████   | 3218/4545 [3:28:42<1:23:47,  3.79s/it] 71%|███████   | 3219/4545 [3:28:46<1:24:30,  3.82s/it] 71%|███████   | 3220/4545 [3:28:50<1:24:22,  3.82s/it]                                                       {'loss': 0.2061, 'grad_norm': 31.344722747802734, 'learning_rate': 1.848723056828411e-07, 'rewards/chosen': 4.228515625, 'rewards/rejected': -6.678906440734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 10.90625, 'logps/chosen': -399.79998779296875, 'logps/rejected': -232.4499969482422, 'logits/chosen': -7.387499809265137, 'logits/rejected': -7.284375190734863, 'epoch': 2.13}
 71%|███████   | 3220/4545 [3:28:50<1:24:22,  3.82s/it] 71%|███████   | 3221/4545 [3:28:54<1:24:55,  3.85s/it] 71%|███████   | 3222/4545 [3:28:56<1:16:56,  3.49s/it] 71%|███████   | 3223/4545 [3:29:00<1:19:54,  3.63s/it] 71%|███████   | 3224/4545 [3:29:04<1:22:39,  3.75s/it] 71%|███████   | 3225/4545 [3:29:07<1:17:23,  3.52s/it] 71%|███████   | 3226/4545 [3:29:10<1:14:43,  3.40s/it] 71%|███████   | 3227/4545 [3:29:14<1:18:07,  3.56s/it] 71%|███████   | 3228/4545 [3:29:19<1:22:23,  3.75s/it] 71%|███████   | 3229/4545 [3:29:22<1:21:00,  3.69s/it] 71%|███████   | 3230/4545 [3:29:26<1:22:17,  3.75s/it]                                                       {'loss': 0.1977, 'grad_norm': 33.39433670043945, 'learning_rate': 1.8304442043355892e-07, 'rewards/chosen': 1.856542944908142, 'rewards/rejected': -8.144140243530273, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 10.004687309265137, 'logps/chosen': -251.39999389648438, 'logps/rejected': -181.9499969482422, 'logits/chosen': -7.599999904632568, 'logits/rejected': -7.118750095367432, 'epoch': 2.13}
 71%|███████   | 3230/4545 [3:29:26<1:22:17,  3.75s/it] 71%|███████   | 3231/4545 [3:29:30<1:21:26,  3.72s/it] 71%|███████   | 3232/4545 [3:29:33<1:20:38,  3.68s/it] 71%|███████   | 3233/4545 [3:29:37<1:22:01,  3.75s/it] 71%|███████   | 3234/4545 [3:29:41<1:24:04,  3.85s/it] 71%|███████   | 3235/4545 [3:29:45<1:26:02,  3.94s/it] 71%|███████   | 3236/4545 [3:29:49<1:25:44,  3.93s/it] 71%|███████   | 3237/4545 [3:29:53<1:25:35,  3.93s/it] 71%|███████   | 3238/4545 [3:29:57<1:25:20,  3.92s/it] 71%|███████▏  | 3239/4545 [3:30:01<1:24:00,  3.86s/it] 71%|███████▏  | 3240/4545 [3:30:04<1:18:49,  3.62s/it]                                                       {'loss': 0.1672, 'grad_norm': 22.12047004699707, 'learning_rate': 1.8122050530764423e-07, 'rewards/chosen': 2.532858371734619, 'rewards/rejected': -7.752734184265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.290624618530273, 'logps/chosen': -258.8999938964844, 'logps/rejected': -152.64999389648438, 'logits/chosen': -7.778124809265137, 'logits/rejected': -7.321875095367432, 'epoch': 2.14}
 71%|███████▏  | 3240/4545 [3:30:04<1:18:49,  3.62s/it] 71%|███████▏  | 3241/4545 [3:30:08<1:22:37,  3.80s/it] 71%|███████▏  | 3242/4545 [3:30:12<1:23:19,  3.84s/it] 71%|███████▏  | 3243/4545 [3:30:16<1:21:51,  3.77s/it] 71%|███████▏  | 3244/4545 [3:30:20<1:22:43,  3.81s/it] 71%|███████▏  | 3245/4545 [3:30:23<1:23:18,  3.85s/it] 71%|███████▏  | 3246/4545 [3:30:27<1:18:41,  3.63s/it] 71%|███████▏  | 3247/4545 [3:30:30<1:16:37,  3.54s/it] 71%|███████▏  | 3248/4545 [3:30:34<1:18:11,  3.62s/it] 71%|███████▏  | 3249/4545 [3:30:38<1:20:00,  3.70s/it] 72%|███████▏  | 3250/4545 [3:30:41<1:17:52,  3.61s/it]                                                       {'loss': 0.194, 'grad_norm': 32.184173583984375, 'learning_rate': 1.7940075624758113e-07, 'rewards/chosen': 3.3589844703674316, 'rewards/rejected': -5.740624904632568, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.106249809265137, 'logps/chosen': -318.20001220703125, 'logps/rejected': -198.0500030517578, 'logits/chosen': -7.471875190734863, 'logits/rejected': -7.324999809265137, 'epoch': 2.15}
 72%|███████▏  | 3250/4545 [3:30:41<1:17:52,  3.61s/it] 72%|███████▏  | 3251/4545 [3:30:45<1:21:12,  3.77s/it] 72%|███████▏  | 3252/4545 [3:30:49<1:22:58,  3.85s/it] 72%|███████▏  | 3253/4545 [3:30:53<1:20:54,  3.76s/it] 72%|███████▏  | 3254/4545 [3:30:57<1:22:36,  3.84s/it] 72%|███████▏  | 3255/4545 [3:31:01<1:24:48,  3.94s/it] 72%|███████▏  | 3256/4545 [3:31:04<1:19:05,  3.68s/it] 72%|███████▏  | 3257/4545 [3:31:08<1:19:44,  3.71s/it] 72%|███████▏  | 3258/4545 [3:31:12<1:20:59,  3.78s/it] 72%|███████▏  | 3259/4545 [3:31:16<1:21:29,  3.80s/it] 72%|███████▏  | 3260/4545 [3:31:19<1:22:03,  3.83s/it]                                                       {'loss': 0.2424, 'grad_norm': 40.468971252441406, 'learning_rate': 1.7758536874829484e-07, 'rewards/chosen': 2.0576171875, 'rewards/rejected': -5.935156345367432, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 7.985937595367432, 'logps/chosen': -247.8000030517578, 'logps/rejected': -187.0500030517578, 'logits/chosen': -7.603125095367432, 'logits/rejected': -7.425000190734863, 'epoch': 2.15}
 72%|███████▏  | 3260/4545 [3:31:19<1:22:03,  3.83s/it] 72%|███████▏  | 3261/4545 [3:31:23<1:22:28,  3.85s/it] 72%|███████▏  | 3262/4545 [3:31:27<1:22:50,  3.87s/it] 72%|███████▏  | 3263/4545 [3:31:31<1:21:36,  3.82s/it] 72%|███████▏  | 3264/4545 [3:31:34<1:18:18,  3.67s/it] 72%|███████▏  | 3265/4545 [3:31:38<1:19:38,  3.73s/it] 72%|███████▏  | 3266/4545 [3:31:42<1:21:37,  3.83s/it] 72%|███████▏  | 3267/4545 [3:31:46<1:22:03,  3.85s/it] 72%|███████▏  | 3268/4545 [3:31:49<1:14:59,  3.52s/it] 72%|███████▏  | 3269/4545 [3:31:53<1:17:45,  3.66s/it] 72%|███████▏  | 3270/4545 [3:31:57<1:21:06,  3.82s/it]                                                       {'loss': 0.1949, 'grad_norm': 16.079431533813477, 'learning_rate': 1.7577453783614996e-07, 'rewards/chosen': 3.6321778297424316, 'rewards/rejected': -3.0064454078674316, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 6.637499809265137, 'logps/chosen': -326.54998779296875, 'logps/rejected': -262.95001220703125, 'logits/chosen': -7.665625095367432, 'logits/rejected': -7.340624809265137, 'epoch': 2.16}
 72%|███████▏  | 3270/4545 [3:31:57<1:21:06,  3.82s/it] 72%|███████▏  | 3271/4545 [3:32:01<1:21:37,  3.84s/it] 72%|███████▏  | 3272/4545 [3:32:04<1:17:41,  3.66s/it] 72%|███████▏  | 3273/4545 [3:32:08<1:19:10,  3.73s/it] 72%|███████▏  | 3274/4545 [3:32:11<1:12:47,  3.44s/it] 72%|███████▏  | 3275/4545 [3:32:14<1:11:30,  3.38s/it] 72%|███████▏  | 3276/4545 [3:32:18<1:15:55,  3.59s/it] 72%|███████▏  | 3277/4545 [3:32:22<1:15:47,  3.59s/it] 72%|███████▏  | 3278/4545 [3:32:26<1:17:33,  3.67s/it] 72%|███████▏  | 3279/4545 [3:32:30<1:18:59,  3.74s/it] 72%|███████▏  | 3280/4545 [3:32:32<1:12:58,  3.46s/it]                                                       {'loss': 0.2233, 'grad_norm': 21.328489303588867, 'learning_rate': 1.7396845804799858e-07, 'rewards/chosen': 2.2958984375, 'rewards/rejected': -5.432812690734863, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 7.734375, 'logps/chosen': -234.72500610351562, 'logps/rejected': -138.39999389648438, 'logits/chosen': -7.787499904632568, 'logits/rejected': -7.403124809265137, 'epoch': 2.17}
 72%|███████▏  | 3280/4545 [3:32:32<1:12:58,  3.46s/it] 72%|███████▏  | 3281/4545 [3:32:36<1:13:55,  3.51s/it] 72%|███████▏  | 3282/4545 [3:32:38<1:07:10,  3.19s/it] 72%|███████▏  | 3283/4545 [3:32:42<1:12:11,  3.43s/it] 72%|███████▏  | 3284/4545 [3:32:46<1:15:46,  3.61s/it] 72%|███████▏  | 3285/4545 [3:32:50<1:13:03,  3.48s/it] 72%|███████▏  | 3286/4545 [3:32:54<1:16:26,  3.64s/it] 72%|███████▏  | 3287/4545 [3:32:56<1:10:05,  3.34s/it] 72%|███████▏  | 3288/4545 [3:33:00<1:13:17,  3.50s/it] 72%|███████▏  | 3289/4545 [3:33:03<1:09:04,  3.30s/it] 72%|███████▏  | 3290/4545 [3:33:07<1:13:40,  3.52s/it]                                                       {'loss': 0.1523, 'grad_norm': 37.519412994384766, 'learning_rate': 1.7216732341028152e-07, 'rewards/chosen': 1.5869140625, 'rewards/rejected': -6.4140625, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 7.989062309265137, 'logps/chosen': -198.10000610351562, 'logps/rejected': -146.35000610351562, 'logits/chosen': -7.615624904632568, 'logits/rejected': -7.243750095367432, 'epoch': 2.17}
 72%|███████▏  | 3290/4545 [3:33:07<1:13:40,  3.52s/it] 72%|███████▏  | 3291/4545 [3:33:11<1:14:12,  3.55s/it] 72%|███████▏  | 3292/4545 [3:33:14<1:15:28,  3.61s/it] 72%|███████▏  | 3293/4545 [3:33:18<1:14:27,  3.57s/it] 72%|███████▏  | 3294/4545 [3:33:22<1:16:44,  3.68s/it] 72%|███████▏  | 3295/4545 [3:33:26<1:17:50,  3.74s/it] 73%|███████▎  | 3296/4545 [3:33:30<1:18:46,  3.78s/it] 73%|███████▎  | 3297/4545 [3:33:34<1:19:49,  3.84s/it] 73%|███████▎  | 3298/4545 [3:33:37<1:19:55,  3.85s/it] 73%|███████▎  | 3299/4545 [3:33:40<1:13:17,  3.53s/it] 73%|███████▎  | 3300/4545 [3:33:44<1:15:38,  3.65s/it]                                                       {'loss': 0.1818, 'grad_norm': 38.42424011230469, 'learning_rate': 1.7037132741818406e-07, 'rewards/chosen': 2.0821776390075684, 'rewards/rejected': -6.245312690734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.324999809265137, 'logps/chosen': -243.0, 'logps/rejected': -126.0, 'logits/chosen': -7.631249904632568, 'logits/rejected': -7.262499809265137, 'epoch': 2.18}
 73%|███████▎  | 3300/4545 [3:33:44<1:15:38,  3.65s/it] 73%|███████▎  | 3301/4545 [3:33:48<1:14:58,  3.62s/it] 73%|███████▎  | 3302/4545 [3:33:51<1:12:51,  3.52s/it] 73%|███████▎  | 3303/4545 [3:33:55<1:16:27,  3.69s/it] 73%|███████▎  | 3304/4545 [3:33:58<1:13:42,  3.56s/it] 73%|███████▎  | 3305/4545 [3:34:02<1:15:17,  3.64s/it] 73%|███████▎  | 3306/4545 [3:34:06<1:16:55,  3.73s/it] 73%|███████▎  | 3307/4545 [3:34:10<1:17:58,  3.78s/it] 73%|███████▎  | 3308/4545 [3:34:14<1:18:51,  3.83s/it] 73%|███████▎  | 3309/4545 [3:34:18<1:20:39,  3.92s/it] 73%|███████▎  | 3310/4545 [3:34:22<1:19:00,  3.84s/it]                                                       {'loss': 0.1614, 'grad_norm': 28.915115356445312, 'learning_rate': 1.6858066301484871e-07, 'rewards/chosen': 2.5916504859924316, 'rewards/rejected': -7.196875095367432, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.793749809265137, 'logps/chosen': -282.3999938964844, 'logps/rejected': -176.9499969482422, 'logits/chosen': -7.703125, 'logits/rejected': -7.209374904632568, 'epoch': 2.18}
 73%|███████▎  | 3310/4545 [3:34:22<1:19:00,  3.84s/it] 73%|███████▎  | 3311/4545 [3:34:26<1:19:25,  3.86s/it] 73%|███████▎  | 3312/4545 [3:34:29<1:19:40,  3.88s/it] 73%|███████▎  | 3313/4545 [3:34:34<1:21:49,  3.98s/it] 73%|███████▎  | 3314/4545 [3:34:37<1:20:08,  3.91s/it] 73%|███████▎  | 3315/4545 [3:34:41<1:20:08,  3.91s/it] 73%|███████▎  | 3316/4545 [3:34:45<1:21:12,  3.96s/it] 73%|███████▎  | 3317/4545 [3:34:48<1:12:48,  3.56s/it] 73%|███████▎  | 3318/4545 [3:34:52<1:13:49,  3.61s/it] 73%|███████▎  | 3319/4545 [3:34:56<1:14:32,  3.65s/it] 73%|███████▎  | 3320/4545 [3:35:00<1:17:04,  3.77s/it]                                                       {'loss': 0.1934, 'grad_norm': 55.686439514160156, 'learning_rate': 1.6679552257064752e-07, 'rewards/chosen': 3.608813524246216, 'rewards/rejected': -6.465624809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 10.067187309265137, 'logps/chosen': -347.25, 'logps/rejected': -211.1999969482422, 'logits/chosen': -7.365624904632568, 'logits/rejected': -7.03125, 'epoch': 2.19}
 73%|███████▎  | 3320/4545 [3:35:00<1:17:04,  3.77s/it] 73%|███████▎  | 3321/4545 [3:35:03<1:15:06,  3.68s/it] 73%|███████▎  | 3322/4545 [3:35:06<1:12:30,  3.56s/it] 73%|███████▎  | 3323/4545 [3:35:10<1:14:33,  3.66s/it] 73%|███████▎  | 3324/4545 [3:35:14<1:16:25,  3.76s/it] 73%|███████▎  | 3325/4545 [3:35:17<1:09:31,  3.42s/it] 73%|███████▎  | 3326/4545 [3:35:21<1:12:14,  3.56s/it] 73%|███████▎  | 3327/4545 [3:35:25<1:14:05,  3.65s/it] 73%|███████▎  | 3328/4545 [3:35:28<1:14:09,  3.66s/it] 73%|███████▎  | 3329/4545 [3:35:32<1:15:48,  3.74s/it] 73%|███████▎  | 3330/4545 [3:35:36<1:16:31,  3.78s/it]                                                       {'loss': 0.1977, 'grad_norm': 20.576250076293945, 'learning_rate': 1.6501609786251574e-07, 'rewards/chosen': 1.633398413658142, 'rewards/rejected': -5.032031059265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 6.668749809265137, 'logps/chosen': -207.8000030517578, 'logps/rejected': -154.22500610351562, 'logits/chosen': -7.765625, 'logits/rejected': -7.443749904632568, 'epoch': 2.2}
 73%|███████▎  | 3330/4545 [3:35:36<1:16:31,  3.78s/it] 73%|███████▎  | 3331/4545 [3:35:40<1:16:56,  3.80s/it] 73%|███████▎  | 3332/4545 [3:35:44<1:17:32,  3.84s/it] 73%|███████▎  | 3333/4545 [3:35:47<1:16:06,  3.77s/it] 73%|███████▎  | 3334/4545 [3:35:50<1:09:51,  3.46s/it] 73%|███████▎  | 3335/4545 [3:35:53<1:06:08,  3.28s/it] 73%|███████▎  | 3336/4545 [3:35:56<1:01:54,  3.07s/it] 73%|███████▎  | 3337/4545 [3:35:59<1:00:43,  3.02s/it] 73%|███████▎  | 3338/4545 [3:36:02<1:05:58,  3.28s/it] 73%|███████▎  | 3339/4545 [3:36:06<1:06:30,  3.31s/it] 73%|███████▎  | 3340/4545 [3:36:08<59:52,  2.98s/it]                                                       {'loss': 0.2324, 'grad_norm': 15.176508903503418, 'learning_rate': 1.632425800533495e-07, 'rewards/chosen': 1.237695336341858, 'rewards/rejected': -6.479687690734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 7.714062690734863, 'logps/chosen': -154.39999389648438, 'logps/rejected': -122.55000305175781, 'logits/chosen': -7.75, 'logits/rejected': -7.293749809265137, 'epoch': 2.2}
 73%|███████▎  | 3340/4545 [3:36:08<59:52,  2.98s/it] 74%|███████▎  | 3341/4545 [3:36:12<1:05:34,  3.27s/it] 74%|███████▎  | 3342/4545 [3:36:16<1:10:20,  3.51s/it] 74%|███████▎  | 3343/4545 [3:36:20<1:13:27,  3.67s/it] 74%|███████▎  | 3344/4545 [3:36:24<1:14:39,  3.73s/it] 74%|███████▎  | 3345/4545 [3:36:27<1:13:14,  3.66s/it] 74%|███████▎  | 3346/4545 [3:36:31<1:15:04,  3.76s/it] 74%|███████▎  | 3347/4545 [3:36:35<1:15:06,  3.76s/it] 74%|███████▎  | 3348/4545 [3:36:39<1:16:50,  3.85s/it] 74%|███████▎  | 3349/4545 [3:36:43<1:15:09,  3.77s/it] 74%|███████▎  | 3350/4545 [3:36:46<1:13:51,  3.71s/it]                                                       {'loss': 0.2108, 'grad_norm': 40.72344207763672, 'learning_rate': 1.6147515967146896e-07, 'rewards/chosen': 1.775048851966858, 'rewards/rejected': -6.5234375, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.303125381469727, 'logps/chosen': -221.25, 'logps/rejected': -176.8000030517578, 'logits/chosen': -7.553124904632568, 'logits/rejected': -7.159375190734863, 'epoch': 2.21}
 74%|███████▎  | 3350/4545 [3:36:46<1:13:51,  3.71s/it] 74%|███████▎  | 3351/4545 [3:36:50<1:12:01,  3.62s/it] 74%|███████▍  | 3352/4545 [3:36:53<1:11:57,  3.62s/it] 74%|███████▍  | 3353/4545 [3:36:57<1:12:01,  3.63s/it] 74%|███████▍  | 3354/4545 [3:37:01<1:13:41,  3.71s/it] 74%|███████▍  | 3355/4545 [3:37:05<1:13:00,  3.68s/it] 74%|███████▍  | 3356/4545 [3:37:09<1:14:28,  3.76s/it] 74%|███████▍  | 3357/4545 [3:37:12<1:15:19,  3.80s/it] 74%|███████▍  | 3358/4545 [3:37:16<1:15:49,  3.83s/it] 74%|███████▍  | 3359/4545 [3:37:20<1:16:15,  3.86s/it] 74%|███████▍  | 3360/4545 [3:37:24<1:16:24,  3.87s/it]                                                       {'loss': 0.3061, 'grad_norm': 3.2599997520446777, 'learning_rate': 1.5971402659015002e-07, 'rewards/chosen': 3.7837891578674316, 'rewards/rejected': -6.075390815734863, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.853124618530273, 'logps/chosen': -367.75, 'logps/rejected': -230.5500030517578, 'logits/chosen': -7.431250095367432, 'logits/rejected': -7.224999904632568, 'epoch': 2.22}
 74%|███████▍  | 3360/4545 [3:37:24<1:16:24,  3.87s/it] 74%|███████▍  | 3361/4545 [3:37:28<1:16:29,  3.88s/it] 74%|███████▍  | 3362/4545 [3:37:31<1:13:54,  3.75s/it] 74%|███████▍  | 3363/4545 [3:37:35<1:14:13,  3.77s/it] 74%|███████▍  | 3364/4545 [3:37:39<1:14:57,  3.81s/it] 74%|███████▍  | 3365/4545 [3:37:43<1:14:52,  3.81s/it] 74%|███████▍  | 3366/4545 [3:37:47<1:14:47,  3.81s/it] 74%|███████▍  | 3367/4545 [3:37:51<1:16:30,  3.90s/it] 74%|███████▍  | 3368/4545 [3:37:54<1:08:47,  3.51s/it] 74%|███████▍  | 3369/4545 [3:37:57<1:11:10,  3.63s/it] 74%|███████▍  | 3370/4545 [3:38:01<1:12:41,  3.71s/it]                                                       {'loss': 0.1923, 'grad_norm': 21.54132080078125, 'learning_rate': 1.5795937000722658e-07, 'rewards/chosen': 2.6327147483825684, 'rewards/rejected': -6.201562404632568, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.840624809265137, 'logps/chosen': -274.6499938964844, 'logps/rejected': -177.4499969482422, 'logits/chosen': -7.553124904632568, 'logits/rejected': -7.153124809265137, 'epoch': 2.22}
 74%|███████▍  | 3370/4545 [3:38:01<1:12:41,  3.71s/it] 74%|███████▍  | 3371/4545 [3:38:05<1:10:21,  3.60s/it] 74%|███████▍  | 3372/4545 [3:38:09<1:11:59,  3.68s/it] 74%|███████▍  | 3373/4545 [3:38:12<1:10:33,  3.61s/it] 74%|███████▍  | 3374/4545 [3:38:16<1:13:22,  3.76s/it] 74%|███████▍  | 3375/4545 [3:38:20<1:14:00,  3.79s/it] 74%|███████▍  | 3376/4545 [3:38:23<1:08:49,  3.53s/it] 74%|███████▍  | 3377/4545 [3:38:27<1:09:58,  3.59s/it] 74%|███████▍  | 3378/4545 [3:38:30<1:08:13,  3.51s/it] 74%|███████▍  | 3379/4545 [3:38:34<1:12:12,  3.72s/it] 74%|███████▍  | 3380/4545 [3:38:38<1:10:36,  3.64s/it]                                                       {'loss': 0.2032, 'grad_norm': 41.802459716796875, 'learning_rate': 1.5621137842476467e-07, 'rewards/chosen': 2.61669921875, 'rewards/rejected': -5.460156440734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.0859375, 'logps/chosen': -266.54998779296875, 'logps/rejected': -217.35000610351562, 'logits/chosen': -7.609375, 'logits/rejected': -7.0625, 'epoch': 2.23}
 74%|███████▍  | 3380/4545 [3:38:38<1:10:36,  3.64s/it] 74%|███████▍  | 3381/4545 [3:38:41<1:10:24,  3.63s/it] 74%|███████▍  | 3382/4545 [3:38:45<1:12:00,  3.71s/it] 74%|███████▍  | 3383/4545 [3:38:49<1:10:49,  3.66s/it] 74%|███████▍  | 3384/4545 [3:38:53<1:13:39,  3.81s/it] 74%|███████▍  | 3385/4545 [3:38:57<1:15:05,  3.88s/it] 74%|███████▍  | 3386/4545 [3:39:01<1:16:24,  3.96s/it] 75%|███████▍  | 3387/4545 [3:39:05<1:15:53,  3.93s/it] 75%|███████▍  | 3388/4545 [3:39:09<1:17:05,  4.00s/it] 75%|███████▍  | 3389/4545 [3:39:13<1:17:58,  4.05s/it] 75%|███████▍  | 3390/4545 [3:39:17<1:17:02,  4.00s/it]                                                       {'loss': 0.1747, 'grad_norm': 34.566104888916016, 'learning_rate': 1.5447023962881206e-07, 'rewards/chosen': 2.692187547683716, 'rewards/rejected': -6.659375190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.359375, 'logps/chosen': -304.79998779296875, 'logps/rejected': -227.75, 'logits/chosen': -7.506249904632568, 'logits/rejected': -7.134375095367432, 'epoch': 2.24}
 75%|███████▍  | 3390/4545 [3:39:17<1:17:02,  4.00s/it] 75%|███████▍  | 3391/4545 [3:39:21<1:16:31,  3.98s/it] 75%|███████▍  | 3392/4545 [3:39:25<1:17:49,  4.05s/it] 75%|███████▍  | 3393/4545 [3:39:29<1:14:37,  3.89s/it] 75%|███████▍  | 3394/4545 [3:39:33<1:14:37,  3.89s/it] 75%|███████▍  | 3395/4545 [3:39:36<1:14:09,  3.87s/it] 75%|███████▍  | 3396/4545 [3:39:40<1:10:13,  3.67s/it] 75%|███████▍  | 3397/4545 [3:39:44<1:11:28,  3.74s/it] 75%|███████▍  | 3398/4545 [3:39:47<1:07:01,  3.51s/it] 75%|███████▍  | 3399/4545 [3:39:50<1:05:44,  3.44s/it] 75%|███████▍  | 3400/4545 [3:39:53<1:05:18,  3.42s/it]                                                       {'loss': 0.1511, 'grad_norm': 10.52541732788086, 'learning_rate': 1.5273614066922417e-07, 'rewards/chosen': 2.5882568359375, 'rewards/rejected': -6.485156059265137, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 9.074999809265137, 'logps/chosen': -264.95001220703125, 'logps/rejected': -208.6999969482422, 'logits/chosen': -7.803124904632568, 'logits/rejected': -7.196875095367432, 'epoch': 2.24}
 75%|███████▍  | 3400/4545 [3:39:53<1:05:18,  3.42s/it] 75%|███████▍  | 3401/4545 [3:39:57<1:09:39,  3.65s/it] 75%|███████▍  | 3402/4545 [3:40:01<1:11:06,  3.73s/it] 75%|███████▍  | 3403/4545 [3:40:05<1:13:05,  3.84s/it] 75%|███████▍  | 3404/4545 [3:40:10<1:15:03,  3.95s/it] 75%|███████▍  | 3405/4545 [3:40:13<1:12:18,  3.81s/it] 75%|███████▍  | 3406/4545 [3:40:15<1:03:56,  3.37s/it] 75%|███████▍  | 3407/4545 [3:40:18<1:01:55,  3.27s/it] 75%|███████▍  | 3408/4545 [3:40:22<1:05:32,  3.46s/it] 75%|███████▌  | 3409/4545 [3:40:26<1:07:27,  3.56s/it] 75%|███████▌  | 3410/4545 [3:40:30<1:08:30,  3.62s/it]                                                       {'loss': 0.2202, 'grad_norm': 42.473873138427734, 'learning_rate': 1.5100926783956975e-07, 'rewards/chosen': 1.2141234874725342, 'rewards/rejected': -8.207812309265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 9.40625, 'logps/chosen': -219.97500610351562, 'logps/rejected': -139.3000030517578, 'logits/chosen': -7.637499809265137, 'logits/rejected': -7.240624904632568, 'epoch': 2.25}
 75%|███████▌  | 3410/4545 [3:40:30<1:08:30,  3.62s/it] 75%|███████▌  | 3411/4545 [3:40:34<1:09:33,  3.68s/it] 75%|███████▌  | 3412/4545 [3:40:37<1:10:03,  3.71s/it] 75%|███████▌  | 3413/4545 [3:40:41<1:11:07,  3.77s/it] 75%|███████▌  | 3414/4545 [3:40:44<1:06:43,  3.54s/it] 75%|███████▌  | 3415/4545 [3:40:48<1:07:38,  3.59s/it] 75%|███████▌  | 3416/4545 [3:40:52<1:09:17,  3.68s/it] 75%|███████▌  | 3417/4545 [3:40:56<1:10:26,  3.75s/it] 75%|███████▌  | 3418/4545 [3:41:00<1:10:37,  3.76s/it] 75%|███████▌  | 3419/4545 [3:41:04<1:11:00,  3.78s/it] 75%|███████▌  | 3420/4545 [3:41:07<1:09:09,  3.69s/it]                                                       {'loss': 0.1697, 'grad_norm': 48.522212982177734, 'learning_rate': 1.4928980665711733e-07, 'rewards/chosen': 2.12158203125, 'rewards/rejected': -7.321875095367432, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 9.443750381469727, 'logps/chosen': -240.60000610351562, 'logps/rejected': -182.64999389648438, 'logits/chosen': -7.675000190734863, 'logits/rejected': -7.28125, 'epoch': 2.26}
 75%|███████▌  | 3420/4545 [3:41:07<1:09:09,  3.69s/it] 75%|███████▌  | 3421/4545 [3:41:11<1:11:15,  3.80s/it] 75%|███████▌  | 3422/4545 [3:41:15<1:13:29,  3.93s/it] 75%|███████▌  | 3423/4545 [3:41:18<1:07:24,  3.60s/it] 75%|███████▌  | 3424/4545 [3:41:22<1:10:52,  3.79s/it] 75%|███████▌  | 3425/4545 [3:41:26<1:12:27,  3.88s/it] 75%|███████▌  | 3426/4545 [3:41:30<1:11:46,  3.85s/it] 75%|███████▌  | 3427/4545 [3:41:34<1:11:10,  3.82s/it] 75%|███████▌  | 3428/4545 [3:41:38<1:11:39,  3.85s/it] 75%|███████▌  | 3429/4545 [3:41:42<1:12:16,  3.89s/it] 75%|███████▌  | 3430/4545 [3:41:46<1:12:30,  3.90s/it]                                                       {'loss': 0.1707, 'grad_norm': 20.833765029907227, 'learning_rate': 1.4757794184290474e-07, 'rewards/chosen': 2.3161988258361816, 'rewards/rejected': -5.709374904632568, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.028124809265137, 'logps/chosen': -285.20001220703125, 'logps/rejected': -188.0500030517578, 'logits/chosen': -7.5625, 'logits/rejected': -7.134375095367432, 'epoch': 2.26}
 75%|███████▌  | 3430/4545 [3:41:46<1:12:30,  3.90s/it] 75%|███████▌  | 3431/4545 [3:41:48<1:04:05,  3.45s/it] 76%|███████▌  | 3432/4545 [3:41:51<58:17,  3.14s/it]   76%|███████▌  | 3433/4545 [3:41:55<1:02:58,  3.40s/it] 76%|███████▌  | 3434/4545 [3:41:59<1:05:51,  3.56s/it] 76%|███████▌  | 3435/4545 [3:42:02<1:05:40,  3.55s/it] 76%|███████▌  | 3436/4545 [3:42:06<1:07:26,  3.65s/it] 76%|███████▌  | 3437/4545 [3:42:10<1:08:39,  3.72s/it] 76%|███████▌  | 3438/4545 [3:42:14<1:09:45,  3.78s/it] 76%|███████▌  | 3439/4545 [3:42:18<1:11:53,  3.90s/it] 76%|███████▌  | 3440/4545 [3:42:21<1:09:23,  3.77s/it]                                                       {'loss': 0.167, 'grad_norm': 30.559185028076172, 'learning_rate': 1.4587385730189547e-07, 'rewards/chosen': 2.1197266578674316, 'rewards/rejected': -6.373437404632568, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.493749618530273, 'logps/chosen': -221.1999969482422, 'logps/rejected': -124.25, 'logits/chosen': -7.681250095367432, 'logits/rejected': -7.271874904632568, 'epoch': 2.27}
 76%|███████▌  | 3440/4545 [3:42:21<1:09:23,  3.77s/it] 76%|███████▌  | 3441/4545 [3:42:25<1:10:10,  3.81s/it] 76%|███████▌  | 3442/4545 [3:42:29<1:10:27,  3.83s/it] 76%|███████▌  | 3443/4545 [3:42:33<1:10:38,  3.85s/it] 76%|███████▌  | 3444/4545 [3:42:37<1:10:57,  3.87s/it] 76%|███████▌  | 3445/4545 [3:42:41<1:12:02,  3.93s/it] 76%|███████▌  | 3446/4545 [3:42:45<1:11:39,  3.91s/it] 76%|███████▌  | 3447/4545 [3:42:49<1:10:00,  3.83s/it] 76%|███████▌  | 3448/4545 [3:42:53<1:11:23,  3.90s/it] 76%|███████▌  | 3449/4545 [3:42:57<1:11:21,  3.91s/it] 76%|███████▌  | 3450/4545 [3:43:00<1:11:17,  3.91s/it]                                                       {'loss': 0.1745, 'grad_norm': 27.4340763092041, 'learning_rate': 1.441777361032209e-07, 'rewards/chosen': 3.0748047828674316, 'rewards/rejected': -5.952734470367432, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 9.021875381469727, 'logps/chosen': -299.6499938964844, 'logps/rejected': -174.85000610351562, 'logits/chosen': -7.509375095367432, 'logits/rejected': -7.071875095367432, 'epoch': 2.28}
 76%|███████▌  | 3450/4545 [3:43:00<1:11:17,  3.91s/it] 76%|███████▌  | 3451/4545 [3:43:04<1:11:15,  3.91s/it] 76%|███████▌  | 3452/4545 [3:43:07<1:04:41,  3.55s/it] 76%|███████▌  | 3453/4545 [3:43:10<1:01:34,  3.38s/it] 76%|███████▌  | 3454/4545 [3:43:14<1:04:18,  3.54s/it] 76%|███████▌  | 3455/4545 [3:43:18<1:05:45,  3.62s/it] 76%|███████▌  | 3456/4545 [3:43:22<1:07:16,  3.71s/it] 76%|███████▌  | 3457/4545 [3:43:26<1:09:44,  3.85s/it] 76%|███████▌  | 3458/4545 [3:43:30<1:09:57,  3.86s/it] 76%|███████▌  | 3459/4545 [3:43:34<1:11:36,  3.96s/it] 76%|███████▌  | 3460/4545 [3:43:37<1:07:29,  3.73s/it]                                                       {'loss': 0.1894, 'grad_norm': 20.643821716308594, 'learning_rate': 1.424897604605138e-07, 'rewards/chosen': 3.481536865234375, 'rewards/rejected': -4.521874904632568, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.009374618530273, 'logps/chosen': -320.8500061035156, 'logps/rejected': -178.5, 'logits/chosen': -7.540625095367432, 'logits/rejected': -7.243750095367432, 'epoch': 2.28}
 76%|███████▌  | 3460/4545 [3:43:37<1:07:29,  3.73s/it] 76%|███████▌  | 3461/4545 [3:43:41<1:08:25,  3.79s/it] 76%|███████▌  | 3462/4545 [3:43:44<1:06:07,  3.66s/it] 76%|███████▌  | 3463/4545 [3:43:49<1:08:22,  3.79s/it] 76%|███████▌  | 3464/4545 [3:43:52<1:08:51,  3.82s/it] 76%|███████▌  | 3465/4545 [3:43:57<1:10:31,  3.92s/it] 76%|███████▋  | 3466/4545 [3:44:00<1:06:48,  3.71s/it] 76%|███████▋  | 3467/4545 [3:44:04<1:07:47,  3.77s/it] 76%|███████▋  | 3468/4545 [3:44:07<1:05:51,  3.67s/it] 76%|███████▋  | 3469/4545 [3:44:11<1:07:49,  3.78s/it] 76%|███████▋  | 3470/4545 [3:44:15<1:08:28,  3.82s/it]                                                       {'loss': 0.1444, 'grad_norm': 22.798112869262695, 'learning_rate': 1.4081011171233312e-07, 'rewards/chosen': 2.795947313308716, 'rewards/rejected': -6.415625095367432, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 9.215624809265137, 'logps/chosen': -240.25, 'logps/rejected': -184.10000610351562, 'logits/chosen': -7.746874809265137, 'logits/rejected': -7.262499809265137, 'epoch': 2.29}
 76%|███████▋  | 3470/4545 [3:44:15<1:08:28,  3.82s/it] 76%|███████▋  | 3471/4545 [3:44:19<1:10:21,  3.93s/it] 76%|███████▋  | 3472/4545 [3:44:23<1:10:08,  3.92s/it] 76%|███████▋  | 3473/4545 [3:44:26<1:06:31,  3.72s/it] 76%|███████▋  | 3474/4545 [3:44:30<1:07:32,  3.78s/it] 76%|███████▋  | 3475/4545 [3:44:34<1:04:36,  3.62s/it] 76%|███████▋  | 3476/4545 [3:44:38<1:05:56,  3.70s/it] 77%|███████▋  | 3477/4545 [3:44:41<1:06:58,  3.76s/it] 77%|███████▋  | 3478/4545 [3:44:45<1:07:41,  3.81s/it] 77%|███████▋  | 3479/4545 [3:44:49<1:08:15,  3.84s/it] 77%|███████▋  | 3480/4545 [3:44:53<1:08:32,  3.86s/it]                                                       {'loss': 0.1687, 'grad_norm': 14.71484661102295, 'learning_rate': 1.3913897030268295e-07, 'rewards/chosen': 4.900195121765137, 'rewards/rejected': -6.403124809265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 11.321874618530273, 'logps/chosen': -465.8500061035156, 'logps/rejected': -207.14999389648438, 'logits/chosen': -7.496874809265137, 'logits/rejected': -7.171875, 'epoch': 2.3}
 77%|███████▋  | 3480/4545 [3:44:53<1:08:32,  3.86s/it] 77%|███████▋  | 3481/4545 [3:44:57<1:08:35,  3.87s/it] 77%|███████▋  | 3482/4545 [3:45:01<1:08:42,  3.88s/it] 77%|███████▋  | 3483/4545 [3:45:05<1:08:47,  3.89s/it] 77%|███████▋  | 3484/4545 [3:45:09<1:07:51,  3.84s/it] 77%|███████▋  | 3485/4545 [3:45:13<1:08:29,  3.88s/it] 77%|███████▋  | 3486/4545 [3:45:16<1:06:17,  3.76s/it] 77%|███████▋  | 3487/4545 [3:45:19<1:04:03,  3.63s/it] 77%|███████▋  | 3488/4545 [3:45:23<1:03:42,  3.62s/it] 77%|███████▋  | 3489/4545 [3:45:27<1:05:10,  3.70s/it] 77%|███████▋  | 3490/4545 [3:45:31<1:07:48,  3.86s/it]                                                       {'loss': 0.1603, 'grad_norm': 23.75940704345703, 'learning_rate': 1.3747651576162687e-07, 'rewards/chosen': 3.7746825218200684, 'rewards/rejected': -6.078515529632568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 9.856249809265137, 'logps/chosen': -355.6000061035156, 'logps/rejected': -205.0500030517578, 'logits/chosen': -7.349999904632568, 'logits/rejected': -7.137499809265137, 'epoch': 2.3}
 77%|███████▋  | 3490/4545 [3:45:31<1:07:48,  3.86s/it] 77%|███████▋  | 3491/4545 [3:45:35<1:08:05,  3.88s/it] 77%|███████▋  | 3492/4545 [3:45:38<1:04:17,  3.66s/it] 77%|███████▋  | 3493/4545 [3:45:42<1:07:15,  3.84s/it] 77%|███████▋  | 3494/4545 [3:45:45<59:21,  3.39s/it]   77%|███████▋  | 3495/4545 [3:45:48<59:37,  3.41s/it] 77%|███████▋  | 3496/4545 [3:45:52<1:02:03,  3.55s/it] 77%|███████▋  | 3497/4545 [3:45:56<1:05:01,  3.72s/it] 77%|███████▋  | 3498/4545 [3:46:00<1:06:15,  3.80s/it] 77%|███████▋  | 3499/4545 [3:46:04<1:06:26,  3.81s/it] 77%|███████▋  | 3500/4545 [3:46:08<1:05:23,  3.76s/it]                                                       {'loss': 0.2095, 'grad_norm': 25.038618087768555, 'learning_rate': 1.3582292668600217e-07, 'rewards/chosen': 2.957568407058716, 'rewards/rejected': -4.8515625, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 7.815625190734863, 'logps/chosen': -262.95001220703125, 'logps/rejected': -164.6999969482422, 'logits/chosen': -7.778124809265137, 'logits/rejected': -7.431250095367432, 'epoch': 2.31}
 77%|███████▋  | 3500/4545 [3:46:08<1:05:23,  3.76s/it] 77%|███████▋  | 3501/4545 [3:46:12<1:06:38,  3.83s/it] 77%|███████▋  | 3502/4545 [3:46:16<1:07:51,  3.90s/it] 77%|███████▋  | 3503/4545 [3:46:20<1:07:50,  3.91s/it] 77%|███████▋  | 3504/4545 [3:46:22<1:01:24,  3.54s/it] 77%|███████▋  | 3505/4545 [3:46:26<1:02:28,  3.60s/it] 77%|███████▋  | 3506/4545 [3:46:29<57:08,  3.30s/it]   77%|███████▋  | 3507/4545 [3:46:33<1:01:19,  3.54s/it] 77%|███████▋  | 3508/4545 [3:46:37<1:03:10,  3.66s/it] 77%|███████▋  | 3509/4545 [3:46:41<1:04:25,  3.73s/it] 77%|███████▋  | 3510/4545 [3:46:44<1:03:09,  3.66s/it]                                                       {'loss': 0.2174, 'grad_norm': 16.27205467224121, 'learning_rate': 1.3417838072023227e-07, 'rewards/chosen': 3.9905762672424316, 'rewards/rejected': -5.706250190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.703125, 'logps/chosen': -347.3999938964844, 'logps/rejected': -238.0, 'logits/chosen': -7.521874904632568, 'logits/rejected': -7.140625, 'epoch': 2.32}
 77%|███████▋  | 3510/4545 [3:46:44<1:03:09,  3.66s/it] 77%|███████▋  | 3511/4545 [3:46:48<1:05:42,  3.81s/it] 77%|███████▋  | 3512/4545 [3:46:52<1:06:08,  3.84s/it] 77%|███████▋  | 3513/4545 [3:46:56<1:06:27,  3.86s/it] 77%|███████▋  | 3514/4545 [3:47:00<1:06:39,  3.88s/it] 77%|███████▋  | 3515/4545 [3:47:04<1:04:41,  3.77s/it] 77%|███████▋  | 3516/4545 [3:47:07<1:05:22,  3.81s/it] 77%|███████▋  | 3517/4545 [3:47:11<1:05:52,  3.84s/it] 77%|███████▋  | 3518/4545 [3:47:15<1:05:02,  3.80s/it] 77%|███████▋  | 3519/4545 [3:47:18<59:54,  3.50s/it]   77%|███████▋  | 3520/4545 [3:47:22<1:01:56,  3.63s/it]                                                       {'loss': 0.1673, 'grad_norm': 36.115577697753906, 'learning_rate': 1.3254305453724302e-07, 'rewards/chosen': 5.841406345367432, 'rewards/rejected': -4.037499904632568, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 9.890625, 'logps/chosen': -447.1499938964844, 'logps/rejected': -275.3500061035156, 'logits/chosen': -7.412499904632568, 'logits/rejected': -7.112500190734863, 'epoch': 2.32}
 77%|███████▋  | 3520/4545 [3:47:22<1:01:56,  3.63s/it] 77%|███████▋  | 3521/4545 [3:47:26<1:02:39,  3.67s/it] 77%|███████▋  | 3522/4545 [3:47:29<1:03:48,  3.74s/it] 78%|███████▊  | 3523/4545 [3:47:33<1:03:29,  3.73s/it] 78%|███████▊  | 3524/4545 [3:47:37<1:04:21,  3.78s/it] 78%|███████▊  | 3525/4545 [3:47:41<1:03:34,  3.74s/it] 78%|███████▊  | 3526/4545 [3:47:44<1:01:32,  3.62s/it] 78%|███████▊  | 3527/4545 [3:47:47<56:42,  3.34s/it]   78%|███████▊  | 3528/4545 [3:47:51<59:56,  3.54s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.51s/it][A
 13%|█▎        | 8/60 [00:11<01:21,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:19,  1.63s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.61s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.27s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.13s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.29s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:38<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:41<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.36s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:46<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.08s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.30s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:58<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:02<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.38s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.30s/it][A
 95%|█████████▌| 57/60 [01:13<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:16<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A                                                     
                                               [A{'eval_loss': 0.39504310488700867, 'eval_runtime': 80.1189, 'eval_samples_per_second': 11.895, 'eval_steps_per_second': 0.749, 'eval_rewards/chosen': 3.2880208492279053, 'eval_rewards/rejected': -4.516341209411621, 'eval_rewards/accuracies': 0.8334490656852722, 'eval_rewards/margins': 7.809179782867432, 'eval_logps/chosen': -361.29998779296875, 'eval_logps/rejected': -174.5208282470703, 'eval_logits/chosen': -7.332812309265137, 'eval_logits/rejected': -7.6427083015441895, 'epoch': 2.33}
 78%|███████▊  | 3528/4545 [3:49:11<59:56,  3.54s/it]
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 78%|███████▊  | 3529/4545 [3:49:26<8:44:33, 30.98s/it] 78%|███████▊  | 3530/4545 [3:49:30<6:27:35, 22.91s/it]                                                       {'loss': 0.1751, 'grad_norm': 10.507104873657227, 'learning_rate': 1.3091712381948262e-07, 'rewards/chosen': 2.0121092796325684, 'rewards/rejected': -5.9375, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 7.954687595367432, 'logps/chosen': -233.1999969482422, 'logps/rejected': -150.1999969482422, 'logits/chosen': -7.609375, 'logits/rejected': -7.318749904632568, 'epoch': 2.33}
 78%|███████▊  | 3530/4545 [3:49:30<6:27:35, 22.91s/it] 78%|███████▊  | 3531/4545 [3:49:33<4:49:21, 17.12s/it] 78%|███████▊  | 3532/4545 [3:49:38<3:43:09, 13.22s/it] 78%|███████▊  | 3533/4545 [3:49:41<2:54:15, 10.33s/it] 78%|███████▊  | 3534/4545 [3:49:45<2:20:51,  8.36s/it] 78%|███████▊  | 3535/4545 [3:49:49<1:58:01,  7.01s/it] 78%|███████▊  | 3536/4545 [3:49:52<1:40:07,  5.95s/it] 78%|███████▊  | 3537/4545 [3:49:56<1:28:28,  5.27s/it] 78%|███████▊  | 3538/4545 [3:49:58<1:14:35,  4.44s/it] 78%|███████▊  | 3539/4545 [3:50:02<1:10:25,  4.20s/it] 78%|███████▊  | 3540/4545 [3:50:06<1:06:52,  3.99s/it]                                                       {'loss': 0.1449, 'grad_norm': 16.564119338989258, 'learning_rate': 1.293007632400482e-07, 'rewards/chosen': 0.684399425983429, 'rewards/rejected': -6.670312404632568, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 7.3671875, 'logps/chosen': -140.35000610351562, 'logps/rejected': -127.75, 'logits/chosen': -7.793749809265137, 'logits/rejected': -7.346875190734863, 'epoch': 2.34}
 78%|███████▊  | 3540/4545 [3:50:06<1:06:52,  3.99s/it] 78%|███████▊  | 3541/4545 [3:50:10<1:07:50,  4.05s/it] 78%|███████▊  | 3542/4545 [3:50:14<1:08:23,  4.09s/it] 78%|███████▊  | 3543/4545 [3:50:18<1:07:15,  4.03s/it] 78%|███████▊  | 3544/4545 [3:50:22<1:05:39,  3.94s/it] 78%|███████▊  | 3545/4545 [3:50:25<1:05:14,  3.91s/it] 78%|███████▊  | 3546/4545 [3:50:29<1:05:11,  3.92s/it] 78%|███████▊  | 3547/4545 [3:50:33<1:05:08,  3.92s/it] 78%|███████▊  | 3548/4545 [3:50:36<1:00:25,  3.64s/it] 78%|███████▊  | 3549/4545 [3:50:40<1:01:19,  3.69s/it] 78%|███████▊  | 3550/4545 [3:50:44<1:02:15,  3.75s/it]                                                       {'loss': 0.2144, 'grad_norm': 21.469417572021484, 'learning_rate': 1.276941464439205e-07, 'rewards/chosen': 2.8524413108825684, 'rewards/rejected': -5.639843940734863, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.5, 'logps/chosen': -270.20001220703125, 'logps/rejected': -185.5, 'logits/chosen': -7.618750095367432, 'logits/rejected': -7.175000190734863, 'epoch': 2.34}
 78%|███████▊  | 3550/4545 [3:50:44<1:02:15,  3.75s/it] 78%|███████▊  | 3551/4545 [3:50:48<1:02:50,  3.79s/it] 78%|███████▊  | 3552/4545 [3:50:52<1:03:22,  3.83s/it] 78%|███████▊  | 3553/4545 [3:50:56<1:03:43,  3.85s/it] 78%|███████▊  | 3554/4545 [3:50:59<1:03:01,  3.82s/it] 78%|███████▊  | 3555/4545 [3:51:03<1:03:23,  3.84s/it] 78%|███████▊  | 3556/4545 [3:51:07<1:03:58,  3.88s/it] 78%|███████▊  | 3557/4545 [3:51:11<1:02:38,  3.80s/it] 78%|███████▊  | 3558/4545 [3:51:15<1:03:07,  3.84s/it] 78%|███████▊  | 3559/4545 [3:51:18<59:45,  3.64s/it]   78%|███████▊  | 3560/4545 [3:51:22<1:00:18,  3.67s/it]                                                       {'loss': 0.2624, 'grad_norm': 11.332097053527832, 'learning_rate': 1.2609744602930961e-07, 'rewards/chosen': 3.6556153297424316, 'rewards/rejected': -6.575781345367432, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.215624809265137, 'logps/chosen': -347.79998779296875, 'logps/rejected': -214.5500030517578, 'logits/chosen': -7.425000190734863, 'logits/rejected': -7.196875095367432, 'epoch': 2.35}
 78%|███████▊  | 3560/4545 [3:51:22<1:00:18,  3.67s/it] 78%|███████▊  | 3561/4545 [3:51:25<59:18,  3.62s/it]   78%|███████▊  | 3562/4545 [3:51:29<1:00:10,  3.67s/it] 78%|███████▊  | 3563/4545 [3:51:33<59:18,  3.62s/it]   78%|███████▊  | 3564/4545 [3:51:36<1:00:30,  3.70s/it] 78%|███████▊  | 3565/4545 [3:51:40<1:01:17,  3.75s/it] 78%|███████▊  | 3566/4545 [3:51:44<1:01:37,  3.78s/it] 78%|███████▊  | 3567/4545 [3:51:48<1:01:58,  3.80s/it] 79%|███████▊  | 3568/4545 [3:51:52<1:03:39,  3.91s/it] 79%|███████▊  | 3569/4545 [3:51:56<1:03:37,  3.91s/it] 79%|███████▊  | 3570/4545 [3:52:00<1:03:37,  3.92s/it]                                                       {'loss': 0.1765, 'grad_norm': 16.86170196533203, 'learning_rate': 1.2451083352911273e-07, 'rewards/chosen': 2.4217772483825684, 'rewards/rejected': -6.251367092132568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 8.670312881469727, 'logps/chosen': -247.97500610351562, 'logps/rejected': -159.5, 'logits/chosen': -7.650000095367432, 'logits/rejected': -7.128125190734863, 'epoch': 2.36}
 79%|███████▊  | 3570/4545 [3:52:00<1:03:37,  3.92s/it] 79%|███████▊  | 3571/4545 [3:52:04<1:03:35,  3.92s/it] 79%|███████▊  | 3572/4545 [3:52:08<1:03:34,  3.92s/it] 79%|███████▊  | 3573/4545 [3:52:12<1:03:43,  3.93s/it] 79%|███████▊  | 3574/4545 [3:52:16<1:04:21,  3.98s/it] 79%|███████▊  | 3575/4545 [3:52:20<1:02:51,  3.89s/it] 79%|███████▊  | 3576/4545 [3:52:23<1:00:10,  3.73s/it] 79%|███████▊  | 3577/4545 [3:52:26<55:13,  3.42s/it]   79%|███████▊  | 3578/4545 [3:52:30<57:46,  3.58s/it] 79%|███████▊  | 3579/4545 [3:52:34<59:14,  3.68s/it] 79%|███████▉  | 3580/4545 [3:52:37<1:00:11,  3.74s/it]                                                       {'loss': 0.2015, 'grad_norm': 16.57024383544922, 'learning_rate': 1.2293447939248605e-07, 'rewards/chosen': 3.748242139816284, 'rewards/rejected': -5.067187309265137, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.818750381469727, 'logps/chosen': -350.8500061035156, 'logps/rejected': -225.0, 'logits/chosen': -7.565625190734863, 'logits/rejected': -7.162499904632568, 'epoch': 2.36}
 79%|███████▉  | 3580/4545 [3:52:37<1:00:11,  3.74s/it] 79%|███████▉  | 3581/4545 [3:52:41<1:00:52,  3.79s/it] 79%|███████▉  | 3582/4545 [3:52:45<1:01:22,  3.82s/it] 79%|███████▉  | 3583/4545 [3:52:49<1:01:17,  3.82s/it] 79%|███████▉  | 3584/4545 [3:52:53<1:00:36,  3.78s/it] 79%|███████▉  | 3585/4545 [3:52:57<1:01:07,  3.82s/it] 79%|███████▉  | 3586/4545 [3:53:00<1:00:01,  3.76s/it] 79%|███████▉  | 3587/4545 [3:53:04<1:00:41,  3.80s/it] 79%|███████▉  | 3588/4545 [3:53:07<57:57,  3.63s/it]   79%|███████▉  | 3589/4545 [3:53:11<59:14,  3.72s/it] 79%|███████▉  | 3590/4545 [3:53:15<1:01:03,  3.84s/it]                                                       {'loss': 0.2743, 'grad_norm': 32.98676681518555, 'learning_rate': 1.2136855296653434e-07, 'rewards/chosen': 3.278271436691284, 'rewards/rejected': -6.262499809265137, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 9.550000190734863, 'logps/chosen': -311.1000061035156, 'logps/rejected': -203.6999969482422, 'logits/chosen': -7.496874809265137, 'logits/rejected': -7.184374809265137, 'epoch': 2.37}
 79%|███████▉  | 3590/4545 [3:53:15<1:01:03,  3.84s/it] 79%|███████▉  | 3591/4545 [3:53:19<1:01:19,  3.86s/it] 79%|███████▉  | 3592/4545 [3:53:23<1:01:33,  3.88s/it] 79%|███████▉  | 3593/4545 [3:53:27<1:02:02,  3.91s/it] 79%|███████▉  | 3594/4545 [3:53:31<1:03:19,  4.00s/it] 79%|███████▉  | 3595/4545 [3:53:35<1:02:39,  3.96s/it] 79%|███████▉  | 3596/4545 [3:53:39<1:02:12,  3.93s/it] 79%|███████▉  | 3597/4545 [3:53:43<1:01:35,  3.90s/it] 79%|███████▉  | 3598/4545 [3:53:47<1:01:30,  3.90s/it] 79%|███████▉  | 3599/4545 [3:53:51<1:02:29,  3.96s/it] 79%|███████▉  | 3600/4545 [3:53:55<1:03:22,  4.02s/it]                                                       {'loss': 0.276, 'grad_norm': 11.858083724975586, 'learning_rate': 1.1981322247811696e-07, 'rewards/chosen': 2.119921922683716, 'rewards/rejected': -7.51953125, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 9.649999618530273, 'logps/chosen': -313.70001220703125, 'logps/rejected': -207.10000610351562, 'logits/chosen': -7.493750095367432, 'logits/rejected': -7.224999904632568, 'epoch': 2.38}
 79%|███████▉  | 3600/4545 [3:53:55<1:03:22,  4.02s/it] 79%|███████▉  | 3601/4545 [3:53:59<1:03:44,  4.05s/it] 79%|███████▉  | 3602/4545 [3:54:03<1:00:51,  3.87s/it] 79%|███████▉  | 3603/4545 [3:54:07<1:00:34,  3.86s/it] 79%|███████▉  | 3604/4545 [3:54:10<1:00:42,  3.87s/it] 79%|███████▉  | 3605/4545 [3:54:14<1:00:44,  3.88s/it] 79%|███████▉  | 3606/4545 [3:54:18<1:00:45,  3.88s/it] 79%|███████▉  | 3607/4545 [3:54:22<1:01:36,  3.94s/it] 79%|███████▉  | 3608/4545 [3:54:26<1:01:21,  3.93s/it] 79%|███████▉  | 3609/4545 [3:54:30<1:02:06,  3.98s/it] 79%|███████▉  | 3610/4545 [3:54:34<1:01:44,  3.96s/it]                                                       {'loss': 0.2156, 'grad_norm': 40.442108154296875, 'learning_rate': 1.1826865501577623e-07, 'rewards/chosen': 2.4769530296325684, 'rewards/rejected': -6.692187309265137, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.171875, 'logps/chosen': -280.1000061035156, 'logps/rejected': -156.5500030517578, 'logits/chosen': -7.574999809265137, 'logits/rejected': -7.212500095367432, 'epoch': 2.38}
 79%|███████▉  | 3610/4545 [3:54:34<1:01:44,  3.96s/it] 79%|███████▉  | 3611/4545 [3:54:38<1:00:21,  3.88s/it] 79%|███████▉  | 3612/4545 [3:54:42<1:00:04,  3.86s/it] 79%|███████▉  | 3613/4545 [3:54:45<58:54,  3.79s/it]   80%|███████▉  | 3614/4545 [3:54:49<59:26,  3.83s/it] 80%|███████▉  | 3615/4545 [3:54:53<59:39,  3.85s/it] 80%|███████▉  | 3616/4545 [3:54:56<57:03,  3.68s/it] 80%|███████▉  | 3617/4545 [3:55:00<57:55,  3.74s/it] 80%|███████▉  | 3618/4545 [3:55:04<58:36,  3.79s/it] 80%|███████▉  | 3619/4545 [3:55:08<59:03,  3.83s/it] 80%|███████▉  | 3620/4545 [3:55:12<57:17,  3.72s/it]                                                     {'loss': 0.1829, 'grad_norm': 16.246009826660156, 'learning_rate': 1.1673501651178673e-07, 'rewards/chosen': 2.629638671875, 'rewards/rejected': -7.296093940734863, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 9.915624618530273, 'logps/chosen': -278.95001220703125, 'logps/rejected': -190.6999969482422, 'logits/chosen': -7.509375095367432, 'logits/rejected': -7.059374809265137, 'epoch': 2.39}
 80%|███████▉  | 3620/4545 [3:55:12<57:17,  3.72s/it] 80%|███████▉  | 3621/4545 [3:55:16<58:52,  3.82s/it] 80%|███████▉  | 3622/4545 [3:55:20<1:00:27,  3.93s/it] 80%|███████▉  | 3623/4545 [3:55:23<54:30,  3.55s/it]   80%|███████▉  | 3624/4545 [3:55:26<56:05,  3.65s/it] 80%|███████▉  | 3625/4545 [3:55:30<56:29,  3.68s/it] 80%|███████▉  | 3626/4545 [3:55:34<57:27,  3.75s/it] 80%|███████▉  | 3627/4545 [3:55:38<57:29,  3.76s/it] 80%|███████▉  | 3628/4545 [3:55:42<58:39,  3.84s/it] 80%|███████▉  | 3629/4545 [3:55:45<53:27,  3.50s/it] 80%|███████▉  | 3630/4545 [3:55:48<55:03,  3.61s/it]                                                     {'loss': 0.2332, 'grad_norm': 18.680757522583008, 'learning_rate': 1.152124717243292e-07, 'rewards/chosen': 4.487634181976318, 'rewards/rejected': -6.951074123382568, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.431249618530273, 'logps/chosen': -410.70001220703125, 'logps/rejected': -243.5749969482422, 'logits/chosen': -7.293749809265137, 'logits/rejected': -7.099999904632568, 'epoch': 2.4}
 80%|███████▉  | 3630/4545 [3:55:48<55:03,  3.61s/it] 80%|███████▉  | 3631/4545 [3:55:52<55:52,  3.67s/it] 80%|███████▉  | 3632/4545 [3:55:56<57:45,  3.80s/it] 80%|███████▉  | 3633/4545 [3:56:00<56:51,  3.74s/it] 80%|███████▉  | 3634/4545 [3:56:04<57:35,  3.79s/it] 80%|███████▉  | 3635/4545 [3:56:08<58:04,  3.83s/it] 80%|████████  | 3636/4545 [3:56:12<58:28,  3.86s/it] 80%|████████  | 3637/4545 [3:56:15<56:48,  3.75s/it] 80%|████████  | 3638/4545 [3:56:19<57:29,  3.80s/it] 80%|████████  | 3639/4545 [3:56:23<57:21,  3.80s/it] 80%|████████  | 3640/4545 [3:56:27<57:49,  3.83s/it]                                                     {'loss': 0.1522, 'grad_norm': 34.21636962890625, 'learning_rate': 1.1370118421979094e-07, 'rewards/chosen': 5.108202934265137, 'rewards/rejected': -4.784570217132568, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 9.893750190734863, 'logps/chosen': -417.0, 'logps/rejected': -191.25, 'logits/chosen': -7.415625095367432, 'logits/rejected': -7.234375, 'epoch': 2.4}
 80%|████████  | 3640/4545 [3:56:27<57:49,  3.83s/it] 80%|████████  | 3641/4545 [3:56:31<59:12,  3.93s/it] 80%|████████  | 3642/4545 [3:56:34<55:17,  3.67s/it] 80%|████████  | 3643/4545 [3:56:38<56:15,  3.74s/it] 80%|████████  | 3644/4545 [3:56:42<56:54,  3.79s/it] 80%|████████  | 3645/4545 [3:56:45<52:57,  3.53s/it] 80%|████████  | 3646/4545 [3:56:49<53:31,  3.57s/it] 80%|████████  | 3647/4545 [3:56:52<53:11,  3.55s/it] 80%|████████  | 3648/4545 [3:56:55<49:51,  3.33s/it] 80%|████████  | 3649/4545 [3:56:59<52:56,  3.55s/it] 80%|████████  | 3650/4545 [3:57:03<54:24,  3.65s/it]                                                     {'loss': 0.1679, 'grad_norm': 16.467252731323242, 'learning_rate': 1.1220131635519381e-07, 'rewards/chosen': 1.7931640148162842, 'rewards/rejected': -6.949999809265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.746874809265137, 'logps/chosen': -219.9499969482422, 'logps/rejected': -147.25, 'logits/chosen': -7.696875095367432, 'logits/rejected': -7.084374904632568, 'epoch': 2.41}
 80%|████████  | 3650/4545 [3:57:03<54:24,  3.65s/it] 80%|████████  | 3651/4545 [3:57:06<51:59,  3.49s/it] 80%|████████  | 3652/4545 [3:57:10<53:40,  3.61s/it] 80%|████████  | 3653/4545 [3:57:14<54:45,  3.68s/it] 80%|████████  | 3654/4545 [3:57:18<55:56,  3.77s/it] 80%|████████  | 3655/4545 [3:57:21<56:26,  3.81s/it] 80%|████████  | 3656/4545 [3:57:25<56:54,  3.84s/it] 80%|████████  | 3657/4545 [3:57:30<58:26,  3.95s/it] 80%|████████  | 3658/4545 [3:57:34<58:07,  3.93s/it] 81%|████████  | 3659/4545 [3:57:37<57:46,  3.91s/it] 81%|████████  | 3660/4545 [3:57:41<57:44,  3.91s/it]                                                     {'loss': 0.1907, 'grad_norm': 16.897777557373047, 'learning_rate': 1.10713029260752e-07, 'rewards/chosen': 4.330859184265137, 'rewards/rejected': -5.518750190734863, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.850000381469727, 'logps/chosen': -367.20001220703125, 'logps/rejected': -231.5, 'logits/chosen': -7.387499809265137, 'logits/rejected': -7.109375, 'epoch': 2.42}
 81%|████████  | 3660/4545 [3:57:41<57:44,  3.91s/it] 81%|████████  | 3661/4545 [3:57:45<58:23,  3.96s/it] 81%|████████  | 3662/4545 [3:57:49<58:38,  3.98s/it] 81%|████████  | 3663/4545 [3:57:53<58:17,  3.97s/it] 81%|████████  | 3664/4545 [3:57:57<58:56,  4.01s/it] 81%|████████  | 3665/4545 [3:58:00<54:32,  3.72s/it] 81%|████████  | 3666/4545 [3:58:04<55:17,  3.77s/it] 81%|████████  | 3667/4545 [3:58:08<54:23,  3.72s/it] 81%|████████  | 3668/4545 [3:58:12<55:18,  3.78s/it] 81%|████████  | 3669/4545 [3:58:16<55:49,  3.82s/it] 81%|████████  | 3670/4545 [3:58:20<56:09,  3.85s/it]                                                     {'loss': 0.1501, 'grad_norm': 18.349390029907227, 'learning_rate': 1.0923648282256256e-07, 'rewards/chosen': 4.00311279296875, 'rewards/rejected': -6.239062309265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 10.246874809265137, 'logps/chosen': -372.79998779296875, 'logps/rejected': -227.39999389648438, 'logits/chosen': -7.621874809265137, 'logits/rejected': -7.131249904632568, 'epoch': 2.42}
 81%|████████  | 3670/4545 [3:58:20<56:09,  3.85s/it] 81%|████████  | 3671/4545 [3:58:24<56:17,  3.86s/it] 81%|████████  | 3672/4545 [3:58:27<54:05,  3.72s/it] 81%|████████  | 3673/4545 [3:58:30<52:47,  3.63s/it] 81%|████████  | 3674/4545 [3:58:34<54:25,  3.75s/it] 81%|████████  | 3675/4545 [3:58:38<55:03,  3.80s/it] 81%|████████  | 3676/4545 [3:58:42<55:31,  3.83s/it] 81%|████████  | 3677/4545 [3:58:46<55:50,  3.86s/it] 81%|████████  | 3678/4545 [3:58:50<56:13,  3.89s/it] 81%|████████  | 3679/4545 [3:58:54<56:13,  3.90s/it] 81%|████████  | 3680/4545 [3:58:58<55:08,  3.83s/it]                                                     {'loss': 0.1518, 'grad_norm': 15.122668266296387, 'learning_rate': 1.0777183566542798e-07, 'rewards/chosen': 3.5335450172424316, 'rewards/rejected': -5.19287109375, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.734375, 'logps/chosen': -318.3500061035156, 'logps/rejected': -266.54998779296875, 'logits/chosen': -7.506249904632568, 'logits/rejected': -7.234375, 'epoch': 2.43}
 81%|████████  | 3680/4545 [3:58:58<55:08,  3.83s/it] 81%|████████  | 3681/4545 [3:59:00<50:09,  3.48s/it] 81%|████████  | 3682/4545 [3:59:04<51:59,  3.61s/it] 81%|████████  | 3683/4545 [3:59:08<53:22,  3.72s/it] 81%|████████  | 3684/4545 [3:59:12<54:03,  3.77s/it] 81%|████████  | 3685/4545 [3:59:15<49:05,  3.43s/it] 81%|████████  | 3686/4545 [3:59:19<52:32,  3.67s/it] 81%|████████  | 3687/4545 [3:59:23<53:20,  3.73s/it] 81%|████████  | 3688/4545 [3:59:27<54:19,  3.80s/it] 81%|████████  | 3689/4545 [3:59:31<54:41,  3.83s/it] 81%|████████  | 3690/4545 [3:59:35<54:50,  3.85s/it]                                                     {'loss': 0.1502, 'grad_norm': 43.57139587402344, 'learning_rate': 1.0631924513581591e-07, 'rewards/chosen': 5.275671482086182, 'rewards/rejected': -5.925000190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 11.203125, 'logps/chosen': -450.20001220703125, 'logps/rejected': -261.25, 'logits/chosen': -7.518750190734863, 'logits/rejected': -7.012499809265137, 'epoch': 2.44}
 81%|████████  | 3690/4545 [3:59:35<54:50,  3.85s/it] 81%|████████  | 3691/4545 [3:59:38<53:48,  3.78s/it] 81%|████████  | 3692/4545 [3:59:42<54:24,  3.83s/it] 81%|████████▏ | 3693/4545 [3:59:46<54:49,  3.86s/it] 81%|████████▏ | 3694/4545 [3:59:49<52:07,  3.67s/it] 81%|████████▏ | 3695/4545 [3:59:53<53:09,  3.75s/it] 81%|████████▏ | 3696/4545 [3:59:57<53:47,  3.80s/it] 81%|████████▏ | 3697/4545 [4:00:00<48:47,  3.45s/it] 81%|████████▏ | 3698/4545 [4:00:04<52:00,  3.68s/it] 81%|████████▏ | 3699/4545 [4:00:07<49:30,  3.51s/it] 81%|████████▏ | 3700/4545 [4:00:11<50:56,  3.62s/it]                                                     {'loss': 0.2247, 'grad_norm': 9.089162826538086, 'learning_rate': 1.0487886728495532e-07, 'rewards/chosen': 2.602294921875, 'rewards/rejected': -5.1875, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 7.787499904632568, 'logps/chosen': -256.6499938964844, 'logps/rejected': -205.6999969482422, 'logits/chosen': -7.599999904632568, 'logits/rejected': -7.356249809265137, 'epoch': 2.44}
 81%|████████▏ | 3700/4545 [4:00:11<50:56,  3.62s/it] 81%|████████▏ | 3701/4545 [4:00:15<51:29,  3.66s/it] 81%|████████▏ | 3702/4545 [4:00:19<52:18,  3.72s/it] 81%|████████▏ | 3703/4545 [4:00:23<52:59,  3.78s/it] 81%|████████▏ | 3704/4545 [4:00:27<53:31,  3.82s/it] 82%|████████▏ | 3705/4545 [4:00:31<54:39,  3.90s/it] 82%|████████▏ | 3706/4545 [4:00:35<54:36,  3.91s/it] 82%|████████▏ | 3707/4545 [4:00:38<53:51,  3.86s/it] 82%|████████▏ | 3708/4545 [4:00:42<53:12,  3.81s/it] 82%|████████▏ | 3709/4545 [4:00:46<53:42,  3.85s/it] 82%|████████▏ | 3710/4545 [4:00:50<53:32,  3.85s/it]                                                     {'loss': 0.1647, 'grad_norm': 43.38727569580078, 'learning_rate': 1.0345085685207169e-07, 'rewards/chosen': 2.171581983566284, 'rewards/rejected': -4.8828125, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.057812690734863, 'logps/chosen': -239.39999389648438, 'logps/rejected': -210.4499969482422, 'logits/chosen': -7.759375095367432, 'logits/rejected': -7.349999904632568, 'epoch': 2.45}
 82%|████████▏ | 3710/4545 [4:00:50<53:32,  3.85s/it] 82%|████████▏ | 3711/4545 [4:00:54<54:20,  3.91s/it] 82%|████████▏ | 3712/4545 [4:00:58<55:27,  3.99s/it] 82%|████████▏ | 3713/4545 [4:01:02<54:59,  3.97s/it] 82%|████████▏ | 3714/4545 [4:01:05<52:43,  3.81s/it] 82%|████████▏ | 3715/4545 [4:01:09<53:15,  3.85s/it] 82%|████████▏ | 3716/4545 [4:01:13<52:11,  3.78s/it] 82%|████████▏ | 3717/4545 [4:01:17<53:15,  3.86s/it] 82%|████████▏ | 3718/4545 [4:01:21<52:52,  3.84s/it] 82%|████████▏ | 3719/4545 [4:01:25<53:09,  3.86s/it] 82%|████████▏ | 3720/4545 [4:01:28<51:36,  3.75s/it]                                                     {'loss': 0.2221, 'grad_norm': 12.275156021118164, 'learning_rate': 1.020353672477638e-07, 'rewards/chosen': 1.690527319908142, 'rewards/rejected': -5.621874809265137, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 7.307812690734863, 'logps/chosen': -234.35000610351562, 'logps/rejected': -164.39999389648438, 'logits/chosen': -7.599999904632568, 'logits/rejected': -7.34375, 'epoch': 2.46}
 82%|████████▏ | 3720/4545 [4:01:28<51:36,  3.75s/it] 82%|████████▏ | 3721/4545 [4:01:31<48:13,  3.51s/it] 82%|████████▏ | 3722/4545 [4:01:35<49:49,  3.63s/it] 82%|████████▏ | 3723/4545 [4:01:39<51:00,  3.72s/it] 82%|████████▏ | 3724/4545 [4:01:43<52:32,  3.84s/it] 82%|████████▏ | 3725/4545 [4:01:46<48:20,  3.54s/it] 82%|████████▏ | 3726/4545 [4:01:50<50:56,  3.73s/it] 82%|████████▏ | 3727/4545 [4:01:54<51:40,  3.79s/it] 82%|████████▏ | 3728/4545 [4:01:58<53:00,  3.89s/it] 82%|████████▏ | 3729/4545 [4:02:02<54:16,  3.99s/it] 82%|████████▏ | 3730/4545 [4:02:06<51:22,  3.78s/it]                                                     {'loss': 0.1311, 'grad_norm': 17.79890251159668, 'learning_rate': 1.0063255053752273e-07, 'rewards/chosen': 5.036230564117432, 'rewards/rejected': -4.806640625, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.829687118530273, 'logps/chosen': -380.75, 'logps/rejected': -213.39999389648438, 'logits/chosen': -7.690625190734863, 'logits/rejected': -7.224999904632568, 'epoch': 2.46}
 82%|████████▏ | 3730/4545 [4:02:06<51:22,  3.78s/it] 82%|████████▏ | 3731/4545 [4:02:10<52:02,  3.84s/it] 82%|████████▏ | 3732/4545 [4:02:13<50:13,  3.71s/it] 82%|████████▏ | 3733/4545 [4:02:17<51:04,  3.77s/it] 82%|████████▏ | 3734/4545 [4:02:21<52:51,  3.91s/it] 82%|████████▏ | 3735/4545 [4:02:25<50:31,  3.74s/it] 82%|████████▏ | 3736/4545 [4:02:28<51:09,  3.79s/it] 82%|████████▏ | 3737/4545 [4:02:32<49:17,  3.66s/it] 82%|████████▏ | 3738/4545 [4:02:36<50:13,  3.73s/it] 82%|████████▏ | 3739/4545 [4:02:40<50:53,  3.79s/it] 82%|████████▏ | 3740/4545 [4:02:44<51:19,  3.83s/it]                                                     {'loss': 0.1722, 'grad_norm': 24.503076553344727, 'learning_rate': 9.924255742539553e-08, 'rewards/chosen': 2.664355516433716, 'rewards/rejected': -6.057812690734863, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.712499618530273, 'logps/chosen': -255.1999969482422, 'logps/rejected': -190.4499969482422, 'logits/chosen': -7.643750190734863, 'logits/rejected': -7.387499809265137, 'epoch': 2.47}
 82%|████████▏ | 3740/4545 [4:02:44<51:19,  3.83s/it] 82%|████████▏ | 3741/4545 [4:02:48<52:21,  3.91s/it] 82%|████████▏ | 3742/4545 [4:02:52<52:10,  3.90s/it] 82%|████████▏ | 3743/4545 [4:02:55<50:22,  3.77s/it] 82%|████████▏ | 3744/4545 [4:02:59<50:54,  3.81s/it] 82%|████████▏ | 3745/4545 [4:03:03<52:23,  3.93s/it] 82%|████████▏ | 3746/4545 [4:03:07<53:30,  4.02s/it] 82%|████████▏ | 3747/4545 [4:03:11<52:36,  3.96s/it] 82%|████████▏ | 3748/4545 [4:03:15<52:07,  3.92s/it] 82%|████████▏ | 3749/4545 [4:03:19<52:05,  3.93s/it] 83%|████████▎ | 3750/4545 [4:03:23<52:07,  3.93s/it]                                                     {'loss': 0.1238, 'grad_norm': 16.59341812133789, 'learning_rate': 9.786553723779518e-08, 'rewards/chosen': 2.1920745372772217, 'rewards/rejected': -7.463671684265137, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 9.649999618530273, 'logps/chosen': -255.3000030517578, 'logps/rejected': -175.0500030517578, 'logits/chosen': -7.650000095367432, 'logits/rejected': -7.212500095367432, 'epoch': 2.48}
 83%|████████▎ | 3750/4545 [4:03:23<52:07,  3.93s/it] 83%|████████▎ | 3751/4545 [4:03:27<51:18,  3.88s/it] 83%|████████▎ | 3752/4545 [4:03:31<52:01,  3.94s/it] 83%|████████▎ | 3753/4545 [4:03:34<50:10,  3.80s/it] 83%|████████▎ | 3754/4545 [4:03:38<50:21,  3.82s/it] 83%|████████▎ | 3755/4545 [4:03:42<50:38,  3.85s/it] 83%|████████▎ | 3756/4545 [4:03:46<51:23,  3.91s/it] 83%|████████▎ | 3757/4545 [4:03:49<47:43,  3.63s/it] 83%|████████▎ | 3758/4545 [4:03:53<49:20,  3.76s/it] 83%|████████▎ | 3759/4545 [4:03:57<51:07,  3.90s/it] 83%|████████▎ | 3760/4545 [4:04:01<49:42,  3.80s/it]                                                     {'loss': 0.1748, 'grad_norm': 19.434364318847656, 'learning_rate': 9.650163790745847e-08, 'rewards/chosen': 1.226415991783142, 'rewards/rejected': -7.190625190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 8.418749809265137, 'logps/chosen': -180.14999389648438, 'logps/rejected': -163.3000030517578, 'logits/chosen': -7.768750190734863, 'logits/rejected': -7.471875190734863, 'epoch': 2.48}
 83%|████████▎ | 3760/4545 [4:04:01<49:42,  3.80s/it] 83%|████████▎ | 3761/4545 [4:04:05<49:57,  3.82s/it] 83%|████████▎ | 3762/4545 [4:04:06<41:32,  3.18s/it] 83%|████████▎ | 3763/4545 [4:04:10<44:38,  3.43s/it] 83%|████████▎ | 3764/4545 [4:04:14<43:26,  3.34s/it] 83%|████████▎ | 3765/4545 [4:04:16<38:59,  3.00s/it] 83%|████████▎ | 3766/4545 [4:04:20<42:29,  3.27s/it] 83%|████████▎ | 3767/4545 [4:04:24<45:43,  3.53s/it] 83%|████████▎ | 3768/4545 [4:04:28<48:17,  3.73s/it] 83%|████████▎ | 3769/4545 [4:04:32<47:20,  3.66s/it] 83%|████████▎ | 3770/4545 [4:04:36<48:56,  3.79s/it]                                                     {'loss': 0.1713, 'grad_norm': 16.356107711791992, 'learning_rate': 9.515100595755352e-08, 'rewards/chosen': 2.952746629714966, 'rewards/rejected': -5.794531345367432, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.748437881469727, 'logps/chosen': -268.67498779296875, 'logps/rejected': -209.1999969482422, 'logits/chosen': -7.878125190734863, 'logits/rejected': -7.553124904632568, 'epoch': 2.49}
 83%|████████▎ | 3770/4545 [4:04:36<48:56,  3.79s/it] 83%|████████▎ | 3771/4545 [4:04:40<49:22,  3.83s/it] 83%|████████▎ | 3772/4545 [4:04:44<50:47,  3.94s/it] 83%|████████▎ | 3773/4545 [4:04:47<47:56,  3.73s/it] 83%|████████▎ | 3774/4545 [4:04:51<48:35,  3.78s/it] 83%|████████▎ | 3775/4545 [4:04:55<49:47,  3.88s/it] 83%|████████▎ | 3776/4545 [4:04:59<49:50,  3.89s/it] 83%|████████▎ | 3777/4545 [4:05:03<48:47,  3.81s/it] 83%|████████▎ | 3778/4545 [4:05:07<49:49,  3.90s/it] 83%|████████▎ | 3779/4545 [4:05:10<49:40,  3.89s/it] 83%|████████▎ | 3780/4545 [4:05:14<49:33,  3.89s/it]                                                     {'loss': 0.1505, 'grad_norm': 17.11679458618164, 'learning_rate': 9.381378648593922e-08, 'rewards/chosen': 1.81689453125, 'rewards/rejected': -5.939062595367432, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 7.754687309265137, 'logps/chosen': -230.35000610351562, 'logps/rejected': -174.10000610351562, 'logits/chosen': -7.615624904632568, 'logits/rejected': -7.224999904632568, 'epoch': 2.5}
 83%|████████▎ | 3780/4545 [4:05:14<49:33,  3.89s/it] 83%|████████▎ | 3781/4545 [4:05:18<49:29,  3.89s/it] 83%|████████▎ | 3782/4545 [4:05:21<44:23,  3.49s/it] 83%|████████▎ | 3783/4545 [4:05:25<45:55,  3.62s/it] 83%|████████▎ | 3784/4545 [4:05:28<45:30,  3.59s/it] 83%|████████▎ | 3785/4545 [4:05:32<46:39,  3.68s/it] 83%|████████▎ | 3786/4545 [4:05:36<48:24,  3.83s/it] 83%|████████▎ | 3787/4545 [4:05:39<43:59,  3.48s/it] 83%|████████▎ | 3788/4545 [4:05:43<44:36,  3.54s/it] 83%|████████▎ | 3789/4545 [4:05:46<43:54,  3.49s/it] 83%|████████▎ | 3790/4545 [4:05:50<44:27,  3.53s/it]                                                     {'loss': 0.1667, 'grad_norm': 33.780799865722656, 'learning_rate': 9.249012314957708e-08, 'rewards/chosen': 1.7427489757537842, 'rewards/rejected': -7.528124809265137, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.279687881469727, 'logps/chosen': -238.14999389648438, 'logps/rejected': -199.35000610351562, 'logits/chosen': -7.734375, 'logits/rejected': -7.184374809265137, 'epoch': 2.5}
 83%|████████▎ | 3790/4545 [4:05:50<44:27,  3.53s/it] 83%|████████▎ | 3791/4545 [4:05:54<45:42,  3.64s/it] 83%|████████▎ | 3792/4545 [4:05:57<46:04,  3.67s/it] 83%|████████▎ | 3793/4545 [4:06:01<45:22,  3.62s/it] 83%|████████▎ | 3794/4545 [4:06:04<44:52,  3.58s/it] 83%|████████▎ | 3795/4545 [4:06:08<46:06,  3.69s/it] 84%|████████▎ | 3796/4545 [4:06:12<46:05,  3.69s/it] 84%|████████▎ | 3797/4545 [4:06:16<46:43,  3.75s/it] 84%|████████▎ | 3798/4545 [4:06:20<47:58,  3.85s/it] 84%|████████▎ | 3799/4545 [4:06:24<47:27,  3.82s/it] 84%|████████▎ | 3800/4545 [4:06:27<45:12,  3.64s/it]                                                     {'loss': 0.1956, 'grad_norm': 54.92291259765625, 'learning_rate': 9.118015814909829e-08, 'rewards/chosen': 0.897265613079071, 'rewards/rejected': -6.379687309265137, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 7.284375190734863, 'logps/chosen': -130.9499969482422, 'logps/rejected': -129.25, 'logits/chosen': -8.081250190734863, 'logits/rejected': -7.671875, 'epoch': 2.51}
 84%|████████▎ | 3800/4545 [4:06:27<45:12,  3.64s/it] 84%|████████▎ | 3801/4545 [4:06:31<46:40,  3.76s/it] 84%|████████▎ | 3802/4545 [4:06:35<47:11,  3.81s/it] 84%|████████▎ | 3803/4545 [4:06:38<44:53,  3.63s/it] 84%|████████▎ | 3804/4545 [4:06:42<46:49,  3.79s/it] 84%|████████▎ | 3805/4545 [4:06:45<44:37,  3.62s/it] 84%|████████▎ | 3806/4545 [4:06:49<45:21,  3.68s/it] 84%|████████▍ | 3807/4545 [4:06:53<44:45,  3.64s/it] 84%|████████▍ | 3808/4545 [4:06:57<45:58,  3.74s/it] 84%|████████▍ | 3809/4545 [4:07:01<47:15,  3.85s/it] 84%|████████▍ | 3810/4545 [4:07:04<43:49,  3.58s/it]                                                     {'loss': 0.1544, 'grad_norm': 17.672618865966797, 'learning_rate': 8.988403221352727e-08, 'rewards/chosen': 1.067285180091858, 'rewards/rejected': -8.353124618530273, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 9.410937309265137, 'logps/chosen': -192.8000030517578, 'logps/rejected': -150.4499969482422, 'logits/chosen': -7.709374904632568, 'logits/rejected': -7.318749904632568, 'epoch': 2.51}
 84%|████████▍ | 3810/4545 [4:07:04<43:49,  3.58s/it] 84%|████████▍ | 3811/4545 [4:07:08<45:02,  3.68s/it] 84%|████████▍ | 3812/4545 [4:07:12<45:41,  3.74s/it] 84%|████████▍ | 3813/4545 [4:07:14<42:04,  3.45s/it] 84%|████████▍ | 3814/4545 [4:07:18<42:09,  3.46s/it] 84%|████████▍ | 3815/4545 [4:07:22<44:03,  3.62s/it] 84%|████████▍ | 3816/4545 [4:07:26<45:14,  3.72s/it] 84%|████████▍ | 3817/4545 [4:07:30<45:49,  3.78s/it] 84%|████████▍ | 3818/4545 [4:07:33<44:11,  3.65s/it] 84%|████████▍ | 3819/4545 [4:07:37<45:04,  3.73s/it] 84%|████████▍ | 3820/4545 [4:07:41<45:45,  3.79s/it]                                                     {'loss': 0.2075, 'grad_norm': 40.0141716003418, 'learning_rate': 8.860188458516316e-08, 'rewards/chosen': 5.149987697601318, 'rewards/rejected': -4.625, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.771875381469727, 'logps/chosen': -454.6000061035156, 'logps/rejected': -261.20001220703125, 'logits/chosen': -7.387499809265137, 'logits/rejected': -7.28125, 'epoch': 2.52}
 84%|████████▍ | 3820/4545 [4:07:41<45:45,  3.79s/it] 84%|████████▍ | 3821/4545 [4:07:45<46:00,  3.81s/it] 84%|████████▍ | 3822/4545 [4:07:48<44:41,  3.71s/it] 84%|████████▍ | 3823/4545 [4:07:52<46:13,  3.84s/it] 84%|████████▍ | 3824/4545 [4:07:56<46:23,  3.86s/it] 84%|████████▍ | 3825/4545 [4:08:00<47:05,  3.92s/it] 84%|████████▍ | 3826/4545 [4:08:04<44:19,  3.70s/it] 84%|████████▍ | 3827/4545 [4:08:08<45:49,  3.83s/it] 84%|████████▍ | 3828/4545 [4:08:11<42:48,  3.58s/it] 84%|████████▍ | 3829/4545 [4:08:15<44:07,  3.70s/it] 84%|████████▍ | 3830/4545 [4:08:19<44:32,  3.74s/it]                                                     {'loss': 0.0936, 'grad_norm': 12.52431583404541, 'learning_rate': 8.733385300462106e-08, 'rewards/chosen': 1.8365967273712158, 'rewards/rejected': -8.993749618530273, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 10.837499618530273, 'logps/chosen': -237.1999969482422, 'logps/rejected': -191.0, 'logits/chosen': -7.668749809265137, 'logits/rejected': -7.196875095367432, 'epoch': 2.53}
 84%|████████▍ | 3830/4545 [4:08:19<44:32,  3.74s/it] 84%|████████▍ | 3831/4545 [4:08:22<45:06,  3.79s/it] 84%|████████▍ | 3832/4545 [4:08:25<40:47,  3.43s/it] 84%|████████▍ | 3833/4545 [4:08:28<40:52,  3.45s/it] 84%|████████▍ | 3834/4545 [4:08:33<43:16,  3.65s/it] 84%|████████▍ | 3835/4545 [4:08:37<44:08,  3.73s/it] 84%|████████▍ | 3836/4545 [4:08:40<44:35,  3.77s/it] 84%|████████▍ | 3837/4545 [4:08:44<45:00,  3.81s/it] 84%|████████▍ | 3838/4545 [4:08:48<43:47,  3.72s/it] 84%|████████▍ | 3839/4545 [4:08:51<41:35,  3.53s/it] 84%|████████▍ | 3840/4545 [4:08:55<43:24,  3.69s/it]                                                     {'loss': 0.1825, 'grad_norm': 22.44259262084961, 'learning_rate': 8.608007369603458e-08, 'rewards/chosen': 3.2673583030700684, 'rewards/rejected': -5.477343559265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.746874809265137, 'logps/chosen': -287.04998779296875, 'logps/rejected': -225.25, 'logits/chosen': -7.699999809265137, 'logits/rejected': -7.306250095367432, 'epoch': 2.53}
 84%|████████▍ | 3840/4545 [4:08:55<43:24,  3.69s/it] 85%|████████▍ | 3841/4545 [4:08:59<43:57,  3.75s/it] 85%|████████▍ | 3842/4545 [4:09:03<43:40,  3.73s/it] 85%|████████▍ | 3843/4545 [4:09:06<44:11,  3.78s/it] 85%|████████▍ | 3844/4545 [4:09:10<44:37,  3.82s/it] 85%|████████▍ | 3845/4545 [4:09:14<44:05,  3.78s/it] 85%|████████▍ | 3846/4545 [4:09:18<44:29,  3.82s/it] 85%|████████▍ | 3847/4545 [4:09:22<45:55,  3.95s/it] 85%|████████▍ | 3848/4545 [4:09:25<43:18,  3.73s/it] 85%|████████▍ | 3849/4545 [4:09:29<43:27,  3.75s/it] 85%|████████▍ | 3850/4545 [4:09:33<43:49,  3.78s/it]                                                     {'loss': 0.123, 'grad_norm': 41.27058410644531, 'learning_rate': 8.48406813524213e-08, 'rewards/chosen': 2.1297850608825684, 'rewards/rejected': -6.612500190734863, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.746874809265137, 'logps/chosen': -231.85000610351562, 'logps/rejected': -140.5500030517578, 'logits/chosen': -7.743750095367432, 'logits/rejected': -7.293749809265137, 'epoch': 2.54}
 85%|████████▍ | 3850/4545 [4:09:33<43:49,  3.78s/it] 85%|████████▍ | 3851/4545 [4:09:37<44:15,  3.83s/it] 85%|████████▍ | 3852/4545 [4:09:41<45:25,  3.93s/it] 85%|████████▍ | 3853/4545 [4:09:45<43:48,  3.80s/it] 85%|████████▍ | 3854/4545 [4:09:49<43:56,  3.82s/it] 85%|████████▍ | 3855/4545 [4:09:52<43:44,  3.80s/it] 85%|████████▍ | 3856/4545 [4:09:56<41:35,  3.62s/it] 85%|████████▍ | 3857/4545 [4:10:00<42:53,  3.74s/it] 85%|████████▍ | 3858/4545 [4:10:04<43:50,  3.83s/it] 85%|████████▍ | 3859/4545 [4:10:07<42:03,  3.68s/it] 85%|████████▍ | 3860/4545 [4:10:11<42:32,  3.73s/it]                                                     {'loss': 0.2075, 'grad_norm': 35.314231872558594, 'learning_rate': 8.361580912121291e-08, 'rewards/chosen': 2.3365721702575684, 'rewards/rejected': -6.6953125, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 9.03125, 'logps/chosen': -242.0500030517578, 'logps/rejected': -186.89999389648438, 'logits/chosen': -7.609375, 'logits/rejected': -7.028124809265137, 'epoch': 2.55}
 85%|████████▍ | 3860/4545 [4:10:11<42:32,  3.73s/it] 85%|████████▍ | 3861/4545 [4:10:15<44:00,  3.86s/it] 85%|████████▍ | 3862/4545 [4:10:19<44:09,  3.88s/it] 85%|████████▍ | 3863/4545 [4:10:23<44:11,  3.89s/it] 85%|████████▌ | 3864/4545 [4:10:26<40:21,  3.56s/it] 85%|████████▌ | 3865/4545 [4:10:29<40:02,  3.53s/it] 85%|████████▌ | 3866/4545 [4:10:32<37:20,  3.30s/it] 85%|████████▌ | 3867/4545 [4:10:36<39:48,  3.52s/it] 85%|████████▌ | 3868/4545 [4:10:40<41:04,  3.64s/it] 85%|████████▌ | 3869/4545 [4:10:44<41:57,  3.72s/it] 85%|████████▌ | 3870/4545 [4:10:47<40:09,  3.57s/it]                                                     {'loss': 0.1471, 'grad_norm': 17.91250991821289, 'learning_rate': 8.240558858995117e-08, 'rewards/chosen': 2.6473388671875, 'rewards/rejected': -5.782812595367432, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 8.432812690734863, 'logps/chosen': -285.0, 'logps/rejected': -172.60000610351562, 'logits/chosen': -7.721875190734863, 'logits/rejected': -7.434374809265137, 'epoch': 2.55}
 85%|████████▌ | 3870/4545 [4:10:47<40:09,  3.57s/it] 85%|████████▌ | 3871/4545 [4:10:50<38:35,  3.44s/it] 85%|████████▌ | 3872/4545 [4:10:54<39:59,  3.56s/it] 85%|████████▌ | 3873/4545 [4:10:58<41:44,  3.73s/it] 85%|████████▌ | 3874/4545 [4:11:01<38:03,  3.40s/it] 85%|████████▌ | 3875/4545 [4:11:04<39:38,  3.55s/it] 85%|████████▌ | 3876/4545 [4:11:09<41:20,  3.71s/it] 85%|████████▌ | 3877/4545 [4:11:12<41:50,  3.76s/it] 85%|████████▌ | 3878/4545 [4:11:16<42:17,  3.80s/it] 85%|████████▌ | 3879/4545 [4:11:20<42:00,  3.78s/it] 85%|████████▌ | 3880/4545 [4:11:24<42:37,  3.85s/it]                                                     {'loss': 0.1891, 'grad_norm': 40.59341049194336, 'learning_rate': 8.121014977215127e-08, 'rewards/chosen': 3.716796875, 'rewards/rejected': -4.621874809265137, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 8.334375381469727, 'logps/chosen': -344.3999938964844, 'logps/rejected': -193.4499969482422, 'logits/chosen': -7.612500190734863, 'logits/rejected': -7.318749904632568, 'epoch': 2.56}
 85%|████████▌ | 3880/4545 [4:11:24<42:37,  3.85s/it] 85%|████████▌ | 3881/4545 [4:11:26<36:37,  3.31s/it] 85%|████████▌ | 3882/4545 [4:11:29<36:20,  3.29s/it] 85%|████████▌ | 3883/4545 [4:11:33<37:26,  3.39s/it] 85%|████████▌ | 3884/4545 [4:11:37<39:35,  3.59s/it] 85%|████████▌ | 3885/4545 [4:11:40<37:01,  3.37s/it] 86%|████████▌ | 3886/4545 [4:11:44<38:43,  3.53s/it] 86%|████████▌ | 3887/4545 [4:11:48<39:50,  3.63s/it] 86%|████████▌ | 3888/4545 [4:11:52<40:38,  3.71s/it] 86%|████████▌ | 3889/4545 [4:11:55<41:11,  3.77s/it] 86%|████████▌ | 3890/4545 [4:11:58<37:55,  3.47s/it]                                                     {'loss': 0.1843, 'grad_norm': 20.670408248901367, 'learning_rate': 8.002962109333506e-08, 'rewards/chosen': 3.6809449195861816, 'rewards/rejected': -7.601953029632568, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 11.290624618530273, 'logps/chosen': -358.95001220703125, 'logps/rejected': -217.25, 'logits/chosen': -7.534375190734863, 'logits/rejected': -7.246874809265137, 'epoch': 2.57}
 86%|████████▌ | 3890/4545 [4:11:58<37:55,  3.47s/it] 86%|████████▌ | 3891/4545 [4:12:02<37:53,  3.48s/it] 86%|████████▌ | 3892/4545 [4:12:04<32:24,  2.98s/it] 86%|████████▌ | 3893/4545 [4:12:07<35:26,  3.26s/it] 86%|████████▌ | 3894/4545 [4:12:10<33:24,  3.08s/it] 86%|████████▌ | 3895/4545 [4:12:14<36:06,  3.33s/it] 86%|████████▌ | 3896/4545 [4:12:17<35:17,  3.26s/it] 86%|████████▌ | 3897/4545 [4:12:21<37:10,  3.44s/it] 86%|████████▌ | 3898/4545 [4:12:25<38:37,  3.58s/it] 86%|████████▌ | 3899/4545 [4:12:28<38:13,  3.55s/it] 86%|████████▌ | 3900/4545 [4:12:32<39:46,  3.70s/it]                                                     {'loss': 0.1521, 'grad_norm': 27.97553253173828, 'learning_rate': 7.886412937723385e-08, 'rewards/chosen': 1.933984398841858, 'rewards/rejected': -6.745312690734863, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.693750381469727, 'logps/chosen': -206.47500610351562, 'logps/rejected': -164.72500610351562, 'logits/chosen': -7.834374904632568, 'logits/rejected': -7.456250190734863, 'epoch': 2.57}
 86%|████████▌ | 3900/4545 [4:12:32<39:46,  3.70s/it] 86%|████████▌ | 3901/4545 [4:12:36<40:20,  3.76s/it] 86%|████████▌ | 3902/4545 [4:12:39<38:03,  3.55s/it] 86%|████████▌ | 3903/4545 [4:12:43<39:31,  3.69s/it] 86%|████████▌ | 3904/4545 [4:12:47<40:05,  3.75s/it] 86%|████████▌ | 3905/4545 [4:12:52<41:25,  3.88s/it] 86%|████████▌ | 3906/4545 [4:12:55<41:05,  3.86s/it] 86%|████████▌ | 3907/4545 [4:12:59<41:09,  3.87s/it] 86%|████████▌ | 3908/4545 [4:13:03<39:46,  3.75s/it] 86%|████████▌ | 3909/4545 [4:13:06<39:17,  3.71s/it] 86%|████████▌ | 3910/4545 [4:13:10<38:35,  3.65s/it]                                                     {'loss': 0.2418, 'grad_norm': 49.01182556152344, 'learning_rate': 7.771379983216387e-08, 'rewards/chosen': 2.012402296066284, 'rewards/rejected': -7.909375190734863, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 9.903124809265137, 'logps/chosen': -254.39999389648438, 'logps/rejected': -192.8000030517578, 'logits/chosen': -7.846875190734863, 'logits/rejected': -7.349999904632568, 'epoch': 2.58}
 86%|████████▌ | 3910/4545 [4:13:10<38:35,  3.65s/it] 86%|████████▌ | 3911/4545 [4:13:14<39:55,  3.78s/it] 86%|████████▌ | 3912/4545 [4:13:18<39:30,  3.74s/it] 86%|████████▌ | 3913/4545 [4:13:21<39:55,  3.79s/it] 86%|████████▌ | 3914/4545 [4:13:25<40:10,  3.82s/it] 86%|████████▌ | 3915/4545 [4:13:29<38:15,  3.64s/it] 86%|████████▌ | 3916/4545 [4:13:32<38:44,  3.69s/it] 86%|████████▌ | 3917/4545 [4:13:36<38:49,  3.71s/it] 86%|████████▌ | 3918/4545 [4:13:39<37:21,  3.57s/it] 86%|████████▌ | 3919/4545 [4:13:43<37:33,  3.60s/it] 86%|████████▌ | 3920/4545 [4:13:47<38:25,  3.69s/it]                                                     {'loss': 0.1831, 'grad_norm': 26.94091796875, 'learning_rate': 7.657875603757544e-08, 'rewards/chosen': 2.4557862281799316, 'rewards/rejected': -11.151562690734863, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 13.6015625, 'logps/chosen': -294.3500061035156, 'logps/rejected': -215.25, 'logits/chosen': -7.625, 'logits/rejected': -7.318749904632568, 'epoch': 2.59}
 86%|████████▌ | 3920/4545 [4:13:47<38:25,  3.69s/it] 86%|████████▋ | 3921/4545 [4:13:51<39:02,  3.75s/it] 86%|████████▋ | 3922/4545 [4:13:54<37:19,  3.59s/it] 86%|████████▋ | 3923/4545 [4:13:58<38:39,  3.73s/it] 86%|████████▋ | 3924/4545 [4:14:02<38:48,  3.75s/it] 86%|████████▋ | 3925/4545 [4:14:05<37:31,  3.63s/it] 86%|████████▋ | 3926/4545 [4:14:09<38:50,  3.77s/it] 86%|████████▋ | 3927/4545 [4:14:13<39:10,  3.80s/it] 86%|████████▋ | 3928/4545 [4:14:17<39:10,  3.81s/it] 86%|████████▋ | 3929/4545 [4:14:21<39:20,  3.83s/it] 86%|████████▋ | 3930/4545 [4:14:25<39:25,  3.85s/it]                                                     {'loss': 0.19, 'grad_norm': 19.357330322265625, 'learning_rate': 7.545911993077672e-08, 'rewards/chosen': 3.284228563308716, 'rewards/rejected': -7.062890529632568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 10.350000381469727, 'logps/chosen': -316.95001220703125, 'logps/rejected': -229.6999969482422, 'logits/chosen': -7.449999809265137, 'logits/rejected': -7.034375190734863, 'epoch': 2.59}
 86%|████████▋ | 3930/4545 [4:14:25<39:25,  3.85s/it] 86%|████████▋ | 3931/4545 [4:14:28<36:45,  3.59s/it] 87%|████████▋ | 3932/4545 [4:14:32<37:35,  3.68s/it] 87%|████████▋ | 3933/4545 [4:14:35<37:15,  3.65s/it] 87%|████████▋ | 3934/4545 [4:14:39<37:58,  3.73s/it] 87%|████████▋ | 3935/4545 [4:14:43<39:18,  3.87s/it] 87%|████████▋ | 3936/4545 [4:14:47<39:19,  3.87s/it] 87%|████████▋ | 3937/4545 [4:14:51<39:51,  3.93s/it] 87%|████████▋ | 3938/4545 [4:14:55<39:00,  3.86s/it] 87%|████████▋ | 3939/4545 [4:14:59<39:30,  3.91s/it] 87%|████████▋ | 3940/4545 [4:15:02<37:58,  3.77s/it]                                                     {'loss': 0.1683, 'grad_norm': 4.908211708068848, 'learning_rate': 7.43550117938339e-08, 'rewards/chosen': 2.419811964035034, 'rewards/rejected': -6.620312690734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 9.037500381469727, 'logps/chosen': -277.79998779296875, 'logps/rejected': -183.85000610351562, 'logits/chosen': -7.631249904632568, 'logits/rejected': -7.262499809265137, 'epoch': 2.6}
 87%|████████▋ | 3940/4545 [4:15:02<37:58,  3.77s/it] 87%|████████▋ | 3941/4545 [4:15:06<38:13,  3.80s/it] 87%|████████▋ | 3942/4545 [4:15:10<39:01,  3.88s/it] 87%|████████▋ | 3943/4545 [4:15:14<38:17,  3.82s/it] 87%|████████▋ | 3944/4545 [4:15:18<38:28,  3.84s/it] 87%|████████▋ | 3945/4545 [4:15:22<37:36,  3.76s/it] 87%|████████▋ | 3946/4545 [4:15:26<38:12,  3.83s/it] 87%|████████▋ | 3947/4545 [4:15:30<38:41,  3.88s/it] 87%|████████▋ | 3948/4545 [4:15:33<38:25,  3.86s/it] 87%|████████▋ | 3949/4545 [4:15:37<38:26,  3.87s/it] 87%|████████▋ | 3950/4545 [4:15:41<38:28,  3.88s/it]                                                     {'loss': 0.1299, 'grad_norm': 20.625713348388672, 'learning_rate': 7.326655024064958e-08, 'rewards/chosen': 2.965380907058716, 'rewards/rejected': -5.846875190734863, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 8.803125381469727, 'logps/chosen': -297.1499938964844, 'logps/rejected': -230.5, 'logits/chosen': -7.515625, 'logits/rejected': -7.112500190734863, 'epoch': 2.61}
 87%|████████▋ | 3950/4545 [4:15:41<38:28,  3.88s/it] 87%|████████▋ | 3951/4545 [4:15:45<38:10,  3.86s/it] 87%|████████▋ | 3952/4545 [4:15:49<38:12,  3.87s/it] 87%|████████▋ | 3953/4545 [4:15:53<38:31,  3.90s/it] 87%|████████▋ | 3954/4545 [4:15:56<35:21,  3.59s/it] 87%|████████▋ | 3955/4545 [4:16:00<36:11,  3.68s/it] 87%|████████▋ | 3956/4545 [4:16:03<35:56,  3.66s/it] 87%|████████▋ | 3957/4545 [4:16:07<37:18,  3.81s/it] 87%|████████▋ | 3958/4545 [4:16:11<37:30,  3.83s/it] 87%|████████▋ | 3959/4545 [4:16:15<37:36,  3.85s/it] 87%|████████▋ | 3960/4545 [4:16:19<38:02,  3.90s/it]                                                     {'loss': 0.1819, 'grad_norm': 41.21282958984375, 'learning_rate': 7.219385220422005e-08, 'rewards/chosen': 3.411877393722534, 'rewards/rejected': -6.728125095367432, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 10.143750190734863, 'logps/chosen': -299.75, 'logps/rejected': -203.10000610351562, 'logits/chosen': -7.703125, 'logits/rejected': -7.103125095367432, 'epoch': 2.61}
 87%|████████▋ | 3960/4545 [4:16:19<38:02,  3.90s/it] 87%|████████▋ | 3961/4545 [4:16:23<37:59,  3.90s/it] 87%|████████▋ | 3962/4545 [4:16:27<38:18,  3.94s/it] 87%|████████▋ | 3963/4545 [4:16:31<38:09,  3.93s/it] 87%|████████▋ | 3964/4545 [4:16:35<37:07,  3.83s/it] 87%|████████▋ | 3965/4545 [4:16:38<35:51,  3.71s/it] 87%|████████▋ | 3966/4545 [4:16:41<34:27,  3.57s/it] 87%|████████▋ | 3967/4545 [4:16:45<36:00,  3.74s/it] 87%|████████▋ | 3968/4545 [4:16:49<34:41,  3.61s/it] 87%|████████▋ | 3969/4545 [4:16:52<34:09,  3.56s/it] 87%|████████▋ | 3970/4545 [4:16:55<32:10,  3.36s/it]                                                     {'loss': 0.1262, 'grad_norm': 17.28827667236328, 'learning_rate': 7.113703292407312e-08, 'rewards/chosen': 1.4398925304412842, 'rewards/rejected': -9.2421875, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 10.681249618530273, 'logps/chosen': -198.6999969482422, 'logps/rejected': -174.39999389648438, 'logits/chosen': -7.756249904632568, 'logits/rejected': -7.228125095367432, 'epoch': 2.62}
 87%|████████▋ | 3970/4545 [4:16:55<32:10,  3.36s/it] 87%|████████▋ | 3971/4545 [4:16:59<34:05,  3.56s/it] 87%|████████▋ | 3972/4545 [4:17:02<33:03,  3.46s/it] 87%|████████▋ | 3973/4545 [4:17:06<34:14,  3.59s/it] 87%|████████▋ | 3974/4545 [4:17:10<34:20,  3.61s/it] 87%|████████▋ | 3975/4545 [4:17:14<35:50,  3.77s/it] 87%|████████▋ | 3976/4545 [4:17:18<36:02,  3.80s/it] 88%|████████▊ | 3977/4545 [4:17:22<36:08,  3.82s/it] 88%|████████▊ | 3978/4545 [4:17:26<36:11,  3.83s/it] 88%|████████▊ | 3979/4545 [4:17:29<34:04,  3.61s/it] 88%|████████▊ | 3980/4545 [4:17:33<34:52,  3.70s/it]                                                     {'loss': 0.161, 'grad_norm': 24.91534423828125, 'learning_rate': 7.009620593388819e-08, 'rewards/chosen': 3.294726610183716, 'rewards/rejected': -5.978125095367432, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 9.271875381469727, 'logps/chosen': -296.20001220703125, 'logps/rejected': -179.0, 'logits/chosen': -7.625, 'logits/rejected': -7.40625, 'epoch': 2.63}
 88%|████████▊ | 3980/4545 [4:17:33<34:52,  3.70s/it] 88%|████████▊ | 3981/4545 [4:17:37<35:19,  3.76s/it] 88%|████████▊ | 3982/4545 [4:17:41<36:06,  3.85s/it] 88%|████████▊ | 3983/4545 [4:17:44<36:11,  3.86s/it] 88%|████████▊ | 3984/4545 [4:17:48<34:38,  3.70s/it] 88%|████████▊ | 3985/4545 [4:17:52<35:07,  3.76s/it] 88%|████████▊ | 3986/4545 [4:17:56<35:32,  3.82s/it] 88%|████████▊ | 3987/4545 [4:18:00<35:40,  3.84s/it] 88%|████████▊ | 3988/4545 [4:18:04<36:35,  3.94s/it] 88%|████████▊ | 3989/4545 [4:18:08<37:13,  4.02s/it] 88%|████████▊ | 3990/4545 [4:18:11<33:39,  3.64s/it]                                                     {'loss': 0.201, 'grad_norm': 14.87741470336914, 'learning_rate': 6.907148304929904e-08, 'rewards/chosen': 2.8551268577575684, 'rewards/rejected': -7.744140625, 'rewards/accuracies': 0.875, 'rewards/margins': 10.600000381469727, 'logps/chosen': -293.75, 'logps/rejected': -209.4499969482422, 'logits/chosen': -7.740624904632568, 'logits/rejected': -7.337500095367432, 'epoch': 2.63}
 88%|████████▊ | 3990/4545 [4:18:11<33:39,  3.64s/it] 88%|████████▊ | 3991/4545 [4:18:14<33:43,  3.65s/it] 88%|████████▊ | 3992/4545 [4:18:18<34:13,  3.71s/it] 88%|████████▊ | 3993/4545 [4:18:21<31:52,  3.46s/it] 88%|████████▊ | 3994/4545 [4:18:25<33:16,  3.62s/it] 88%|████████▊ | 3995/4545 [4:18:29<33:56,  3.70s/it] 88%|████████▊ | 3996/4545 [4:18:33<34:24,  3.76s/it] 88%|████████▊ | 3997/4545 [4:18:36<33:10,  3.63s/it] 88%|████████▊ | 3998/4545 [4:18:40<33:47,  3.71s/it] 88%|████████▊ | 3999/4545 [4:18:44<34:06,  3.75s/it] 88%|████████▊ | 4000/4545 [4:18:48<35:12,  3.88s/it]                                                     {'loss': 0.1141, 'grad_norm': 18.53362274169922, 'learning_rate': 6.806297435588189e-08, 'rewards/chosen': 2.5147705078125, 'rewards/rejected': -8.2421875, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 10.753125190734863, 'logps/chosen': -273.70001220703125, 'logps/rejected': -185.89999389648438, 'logits/chosen': -7.796875, 'logits/rejected': -7.265625, 'epoch': 2.64}
 88%|████████▊ | 4000/4545 [4:18:48<35:12,  3.88s/it] 88%|████████▊ | 4001/4545 [4:18:51<32:58,  3.64s/it] 88%|████████▊ | 4002/4545 [4:18:55<33:24,  3.69s/it] 88%|████████▊ | 4003/4545 [4:18:59<33:47,  3.74s/it] 88%|████████▊ | 4004/4545 [4:19:02<31:58,  3.55s/it] 88%|████████▊ | 4005/4545 [4:19:06<32:50,  3.65s/it] 88%|████████▊ | 4006/4545 [4:19:10<34:13,  3.81s/it] 88%|████████▊ | 4007/4545 [4:19:13<32:18,  3.60s/it] 88%|████████▊ | 4008/4545 [4:19:17<33:00,  3.69s/it] 88%|████████▊ | 4009/4545 [4:19:21<33:25,  3.74s/it] 88%|████████▊ | 4010/4545 [4:19:25<34:11,  3.84s/it]                                                     {'loss': 0.1648, 'grad_norm': 38.259456634521484, 'learning_rate': 6.707078819732878e-08, 'rewards/chosen': 2.3892579078674316, 'rewards/rejected': -5.954687595367432, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.346875190734863, 'logps/chosen': -243.35000610351562, 'logps/rejected': -122.5999984741211, 'logits/chosen': -7.8125, 'logits/rejected': -7.446875095367432, 'epoch': 2.65}
 88%|████████▊ | 4010/4545 [4:19:25<34:11,  3.84s/it] 88%|████████▊ | 4011/4545 [4:19:29<35:01,  3.94s/it] 88%|████████▊ | 4012/4545 [4:19:33<34:53,  3.93s/it] 88%|████████▊ | 4013/4545 [4:19:36<31:03,  3.50s/it] 88%|████████▊ | 4014/4545 [4:19:39<31:28,  3.56s/it] 88%|████████▊ | 4015/4545 [4:19:43<31:26,  3.56s/it] 88%|████████▊ | 4016/4545 [4:19:47<32:02,  3.63s/it] 88%|████████▊ | 4017/4545 [4:19:50<32:38,  3.71s/it] 88%|████████▊ | 4018/4545 [4:19:54<33:03,  3.76s/it] 88%|████████▊ | 4019/4545 [4:19:58<33:44,  3.85s/it] 88%|████████▊ | 4020/4545 [4:20:01<31:25,  3.59s/it]                                                     {'loss': 0.1343, 'grad_norm': 6.264856815338135, 'learning_rate': 6.609503116380813e-08, 'rewards/chosen': 1.9825439453125, 'rewards/rejected': -8.8828125, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.868749618530273, 'logps/chosen': -242.10000610351562, 'logps/rejected': -206.35000610351562, 'logits/chosen': -7.706250190734863, 'logits/rejected': -7.334374904632568, 'epoch': 2.65}
 88%|████████▊ | 4020/4545 [4:20:01<31:25,  3.59s/it] 88%|████████▊ | 4021/4545 [4:20:05<32:08,  3.68s/it] 88%|████████▊ | 4022/4545 [4:20:09<32:41,  3.75s/it] 89%|████████▊ | 4023/4545 [4:20:13<33:28,  3.85s/it] 89%|████████▊ | 4024/4545 [4:20:16<30:14,  3.48s/it] 89%|████████▊ | 4025/4545 [4:20:20<31:09,  3.60s/it] 89%|████████▊ | 4026/4545 [4:20:22<28:50,  3.33s/it] 89%|████████▊ | 4027/4545 [4:20:26<29:53,  3.46s/it] 89%|████████▊ | 4028/4545 [4:20:29<28:34,  3.32s/it] 89%|████████▊ | 4029/4545 [4:20:33<29:59,  3.49s/it] 89%|████████▊ | 4030/4545 [4:20:37<31:43,  3.70s/it]                                                     {'loss': 0.2156, 'grad_norm': 31.75948715209961, 'learning_rate': 6.513580808051402e-08, 'rewards/chosen': 2.571606397628784, 'rewards/rejected': -6.1982421875, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 8.765625, 'logps/chosen': -279.45001220703125, 'logps/rejected': -175.6999969482422, 'logits/chosen': -7.681250095367432, 'logits/rejected': -7.390625, 'epoch': 2.66}
 89%|████████▊ | 4030/4545 [4:20:37<31:43,  3.70s/it] 89%|████████▊ | 4031/4545 [4:20:41<32:14,  3.76s/it] 89%|████████▊ | 4032/4545 [4:20:44<30:36,  3.58s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.51s/it][A
 13%|█▎        | 8/60 [00:11<01:21,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:19,  1.63s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.61s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.27s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.13s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.29s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.07s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:38<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:41<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.08s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.20s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:16,  1.13s/it][A
 77%|███████▋  | 46/60 [00:58<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:02<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.46s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.38s/it][A
 92%|█████████▏| 55/60 [01:10<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:13<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:16<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A                                                     
                                               [A{'eval_loss': 0.3853021264076233, 'eval_runtime': 80.1955, 'eval_samples_per_second': 11.883, 'eval_steps_per_second': 0.748, 'eval_rewards/chosen': 3.304779052734375, 'eval_rewards/rejected': -5.1390299797058105, 'eval_rewards/accuracies': 0.8311342597007751, 'eval_rewards/margins': 8.445768356323242, 'eval_logps/chosen': -361.20001220703125, 'eval_logps/rejected': -177.58749389648438, 'eval_logits/chosen': -7.387499809265137, 'eval_logits/rejected': -7.679166793823242, 'epoch': 2.66}
 89%|████████▊ | 4032/4545 [4:22:05<30:36,  3.58s/it]
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 89%|████████▊ | 4033/4545 [4:22:19<4:24:10, 30.96s/it] 89%|████████▉ | 4034/4545 [4:22:23<3:14:26, 22.83s/it] 89%|████████▉ | 4035/4545 [4:22:27<2:25:03, 17.07s/it] 89%|████████▉ | 4036/4545 [4:22:30<1:50:09, 12.98s/it] 89%|████████▉ | 4037/4545 [4:22:34<1:26:49, 10.26s/it] 89%|████████▉ | 4038/4545 [4:22:37<1:08:40,  8.13s/it] 89%|████████▉ | 4039/4545 [4:22:41<57:48,  6.86s/it]   89%|████████▉ | 4040/4545 [4:22:45<50:08,  5.96s/it]                                                     {'loss': 0.1958, 'grad_norm': 26.38616943359375, 'learning_rate': 6.419322199640478e-08, 'rewards/chosen': 2.066113233566284, 'rewards/rejected': -6.565625190734863, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.628125190734863, 'logps/chosen': -229.39999389648438, 'logps/rejected': -138.64999389648438, 'logits/chosen': -7.8125, 'logits/rejected': -7.396874904632568, 'epoch': 2.67}
 89%|████████▉ | 4040/4545 [4:22:45<50:08,  5.96s/it] 89%|████████▉ | 4041/4545 [4:22:49<44:55,  5.35s/it] 89%|████████▉ | 4042/4545 [4:22:53<40:35,  4.84s/it] 89%|████████▉ | 4043/4545 [4:22:55<34:29,  4.12s/it] 89%|████████▉ | 4044/4545 [4:22:59<34:03,  4.08s/it] 89%|████████▉ | 4045/4545 [4:23:03<33:33,  4.03s/it] 89%|████████▉ | 4046/4545 [4:23:07<32:58,  3.97s/it] 89%|████████▉ | 4047/4545 [4:23:11<32:42,  3.94s/it] 89%|████████▉ | 4048/4545 [4:23:14<32:17,  3.90s/it] 89%|████████▉ | 4049/4545 [4:23:17<29:25,  3.56s/it] 89%|████████▉ | 4050/4545 [4:23:21<29:36,  3.59s/it]                                                     {'loss': 0.1486, 'grad_norm': 29.77314567565918, 'learning_rate': 6.326737417313241e-08, 'rewards/chosen': 2.4853179454803467, 'rewards/rejected': -6.084374904632568, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.568750381469727, 'logps/chosen': -234.75, 'logps/rejected': -186.5500030517578, 'logits/chosen': -7.831250190734863, 'logits/rejected': -7.334374904632568, 'epoch': 2.67}
 89%|████████▉ | 4050/4545 [4:23:21<29:36,  3.59s/it] 89%|████████▉ | 4051/4545 [4:23:25<30:18,  3.68s/it] 89%|████████▉ | 4052/4545 [4:23:28<29:07,  3.54s/it] 89%|████████▉ | 4053/4545 [4:23:32<30:06,  3.67s/it] 89%|████████▉ | 4054/4545 [4:23:36<31:19,  3.83s/it] 89%|████████▉ | 4055/4545 [4:23:40<31:26,  3.85s/it] 89%|████████▉ | 4056/4545 [4:23:44<31:30,  3.87s/it] 89%|████████▉ | 4057/4545 [4:23:48<31:31,  3.88s/it] 89%|████████▉ | 4058/4545 [4:23:51<29:51,  3.68s/it] 89%|████████▉ | 4059/4545 [4:23:54<29:14,  3.61s/it] 89%|████████▉ | 4060/4545 [4:23:58<29:51,  3.69s/it]                                                     {'loss': 0.1817, 'grad_norm': 45.05237579345703, 'learning_rate': 6.23583640741642e-08, 'rewards/chosen': 3.9849610328674316, 'rewards/rejected': -7.058007717132568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 11.037500381469727, 'logps/chosen': -367.79998779296875, 'logps/rejected': -197.75, 'logits/chosen': -7.659375190734863, 'logits/rejected': -7.321875095367432, 'epoch': 2.68}
 89%|████████▉ | 4060/4545 [4:23:58<29:51,  3.69s/it] 89%|████████▉ | 4061/4545 [4:24:02<30:30,  3.78s/it] 89%|████████▉ | 4062/4545 [4:24:06<30:37,  3.80s/it] 89%|████████▉ | 4063/4545 [4:24:09<27:03,  3.37s/it] 89%|████████▉ | 4064/4545 [4:24:13<28:29,  3.55s/it] 89%|████████▉ | 4065/4545 [4:24:16<29:15,  3.66s/it] 89%|████████▉ | 4066/4545 [4:24:21<30:12,  3.78s/it] 89%|████████▉ | 4067/4545 [4:24:23<28:02,  3.52s/it] 90%|████████▉ | 4068/4545 [4:24:27<28:52,  3.63s/it] 90%|████████▉ | 4069/4545 [4:24:29<24:56,  3.14s/it] 90%|████████▉ | 4070/4545 [4:24:33<26:41,  3.37s/it]                                                     {'loss': 0.1746, 'grad_norm': 25.41128158569336, 'learning_rate': 6.146628935409722e-08, 'rewards/chosen': 2.8533692359924316, 'rewards/rejected': -6.349999904632568, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 9.198437690734863, 'logps/chosen': -259.57501220703125, 'logps/rejected': -164.52499389648438, 'logits/chosen': -7.65625, 'logits/rejected': -7.193749904632568, 'epoch': 2.69}
 90%|████████▉ | 4070/4545 [4:24:33<26:41,  3.37s/it] 90%|████████▉ | 4071/4545 [4:24:37<28:10,  3.57s/it] 90%|████████▉ | 4072/4545 [4:24:41<28:53,  3.66s/it] 90%|████████▉ | 4073/4545 [4:24:44<27:54,  3.55s/it] 90%|████████▉ | 4074/4545 [4:24:48<28:34,  3.64s/it] 90%|████████▉ | 4075/4545 [4:24:52<29:06,  3.72s/it] 90%|████████▉ | 4076/4545 [4:24:56<29:52,  3.82s/it] 90%|████████▉ | 4077/4545 [4:25:00<30:26,  3.90s/it] 90%|████████▉ | 4078/4545 [4:25:03<27:32,  3.54s/it] 90%|████████▉ | 4079/4545 [4:25:07<28:20,  3.65s/it] 90%|████████▉ | 4080/4545 [4:25:11<28:13,  3.64s/it]                                                     {'loss': 0.1671, 'grad_norm': 21.861814498901367, 'learning_rate': 6.05912458481676e-08, 'rewards/chosen': 4.674756050109863, 'rewards/rejected': -5.9453125, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 10.631250381469727, 'logps/chosen': -385.6000061035156, 'logps/rejected': -204.0, 'logits/chosen': -7.403124809265137, 'logits/rejected': -7.056250095367432, 'epoch': 2.69}
 90%|████████▉ | 4080/4545 [4:25:11<28:13,  3.64s/it] 90%|████████▉ | 4081/4545 [4:25:15<29:06,  3.76s/it] 90%|████████▉ | 4082/4545 [4:25:18<29:11,  3.78s/it] 90%|████████▉ | 4083/4545 [4:25:23<29:55,  3.89s/it] 90%|████████▉ | 4084/4545 [4:25:25<27:25,  3.57s/it] 90%|████████▉ | 4085/4545 [4:25:29<28:02,  3.66s/it] 90%|████████▉ | 4086/4545 [4:25:33<28:13,  3.69s/it] 90%|████████▉ | 4087/4545 [4:25:37<28:40,  3.76s/it] 90%|████████▉ | 4088/4545 [4:25:41<28:57,  3.80s/it] 90%|████████▉ | 4089/4545 [4:25:45<29:08,  3.83s/it] 90%|████████▉ | 4090/4545 [4:25:48<28:28,  3.75s/it]                                                     {'loss': 0.2331, 'grad_norm': 24.399635314941406, 'learning_rate': 5.973332756195482e-08, 'rewards/chosen': 3.95263671875, 'rewards/rejected': -6.884521484375, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 10.831250190734863, 'logps/chosen': -352.3500061035156, 'logps/rejected': -215.5500030517578, 'logits/chosen': -7.637499809265137, 'logits/rejected': -7.34375, 'epoch': 2.7}
 90%|████████▉ | 4090/4545 [4:25:48<28:28,  3.75s/it] 90%|█████████ | 4091/4545 [4:25:52<28:25,  3.76s/it] 90%|█████████ | 4092/4545 [4:25:56<28:42,  3.80s/it] 90%|█████████ | 4093/4545 [4:26:00<28:52,  3.83s/it] 90%|█████████ | 4094/4545 [4:26:03<28:02,  3.73s/it] 90%|█████████ | 4095/4545 [4:26:07<28:23,  3.78s/it] 90%|█████████ | 4096/4545 [4:26:10<26:33,  3.55s/it] 90%|█████████ | 4097/4545 [4:26:14<27:15,  3.65s/it] 90%|█████████ | 4098/4545 [4:26:17<26:12,  3.52s/it] 90%|█████████ | 4099/4545 [4:26:21<26:51,  3.61s/it] 90%|█████████ | 4100/4545 [4:26:25<27:49,  3.75s/it]                                                     {'loss': 0.2899, 'grad_norm': 23.413957595825195, 'learning_rate': 5.8892626661282576e-08, 'rewards/chosen': 3.984179735183716, 'rewards/rejected': -6.487500190734863, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 10.463281631469727, 'logps/chosen': -366.8999938964844, 'logps/rejected': -199.10000610351562, 'logits/chosen': -7.537499904632568, 'logits/rejected': -7.278124809265137, 'epoch': 2.71}
 90%|█████████ | 4100/4545 [4:26:25<27:49,  3.75s/it] 90%|█████████ | 4101/4545 [4:26:29<28:06,  3.80s/it] 90%|█████████ | 4102/4545 [4:26:33<28:19,  3.84s/it] 90%|█████████ | 4103/4545 [4:26:37<28:17,  3.84s/it] 90%|█████████ | 4104/4545 [4:26:41<28:26,  3.87s/it] 90%|█████████ | 4105/4545 [4:26:45<28:48,  3.93s/it] 90%|█████████ | 4106/4545 [4:26:49<29:22,  4.01s/it] 90%|█████████ | 4107/4545 [4:26:53<29:03,  3.98s/it] 90%|█████████ | 4108/4545 [4:26:57<29:04,  3.99s/it] 90%|█████████ | 4109/4545 [4:27:01<29:00,  3.99s/it] 90%|█████████ | 4110/4545 [4:27:05<28:44,  3.96s/it]                                                     {'loss': 0.1632, 'grad_norm': 18.064800262451172, 'learning_rate': 5.806923346231777e-08, 'rewards/chosen': 2.92333984375, 'rewards/rejected': -6.954687595367432, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 9.865625381469727, 'logps/chosen': -295.3999938964844, 'logps/rejected': -194.35000610351562, 'logits/chosen': -7.793749809265137, 'logits/rejected': -7.425000190734863, 'epoch': 2.71}
 90%|█████████ | 4110/4545 [4:27:05<28:44,  3.96s/it] 90%|█████████ | 4111/4545 [4:27:09<28:27,  3.93s/it] 90%|█████████ | 4112/4545 [4:27:13<27:59,  3.88s/it] 90%|█████████ | 4113/4545 [4:27:17<28:21,  3.94s/it] 91%|█████████ | 4114/4545 [4:27:20<27:38,  3.85s/it] 91%|█████████ | 4115/4545 [4:27:24<26:25,  3.69s/it] 91%|█████████ | 4116/4545 [4:27:27<25:36,  3.58s/it] 91%|█████████ | 4117/4545 [4:27:31<26:22,  3.70s/it] 91%|█████████ | 4118/4545 [4:27:35<26:42,  3.75s/it] 91%|█████████ | 4119/4545 [4:27:38<26:28,  3.73s/it] 91%|█████████ | 4120/4545 [4:27:42<26:44,  3.77s/it]                                                     {'loss': 0.1293, 'grad_norm': 13.050386428833008, 'learning_rate': 5.726323642186777e-08, 'rewards/chosen': 2.126708984375, 'rewards/rejected': -6.55859375, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 8.671875, 'logps/chosen': -209.64999389648438, 'logps/rejected': -145.1999969482422, 'logits/chosen': -7.862500190734863, 'logits/rejected': -7.271874904632568, 'epoch': 2.72}
 91%|█████████ | 4120/4545 [4:27:42<26:44,  3.77s/it] 91%|█████████ | 4121/4545 [4:27:46<26:58,  3.82s/it] 91%|█████████ | 4122/4545 [4:27:50<27:32,  3.91s/it] 91%|█████████ | 4123/4545 [4:27:54<26:14,  3.73s/it] 91%|█████████ | 4124/4545 [4:27:58<26:34,  3.79s/it] 91%|█████████ | 4125/4545 [4:28:01<26:10,  3.74s/it] 91%|█████████ | 4126/4545 [4:28:05<26:21,  3.77s/it] 91%|█████████ | 4127/4545 [4:28:09<25:59,  3.73s/it] 91%|█████████ | 4128/4545 [4:28:13<26:27,  3.81s/it] 91%|█████████ | 4129/4545 [4:28:17<26:35,  3.83s/it] 91%|█████████ | 4130/4545 [4:28:21<26:44,  3.87s/it]                                                     {'loss': 0.1738, 'grad_norm': 46.56818389892578, 'learning_rate': 5.647472212787733e-08, 'rewards/chosen': 2.1204590797424316, 'rewards/rejected': -10.168749809265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 12.290624618530273, 'logps/chosen': -278.45001220703125, 'logps/rejected': -180.3000030517578, 'logits/chosen': -7.59375, 'logits/rejected': -7.25, 'epoch': 2.73}
 91%|█████████ | 4130/4545 [4:28:21<26:44,  3.87s/it] 91%|█████████ | 4131/4545 [4:28:25<27:18,  3.96s/it] 91%|█████████ | 4132/4545 [4:28:29<27:43,  4.03s/it] 91%|█████████ | 4133/4545 [4:28:33<27:44,  4.04s/it] 91%|█████████ | 4134/4545 [4:28:36<25:28,  3.72s/it] 91%|█████████ | 4135/4545 [4:28:40<25:37,  3.75s/it] 91%|█████████ | 4136/4545 [4:28:44<25:30,  3.74s/it] 91%|█████████ | 4137/4545 [4:28:46<22:24,  3.29s/it] 91%|█████████ | 4138/4545 [4:28:50<24:07,  3.56s/it] 91%|█████████ | 4139/4545 [4:28:54<25:05,  3.71s/it] 91%|█████████ | 4140/4545 [4:28:57<24:07,  3.58s/it]                                                     {'loss': 0.1513, 'grad_norm': 15.115856170654297, 'learning_rate': 5.5703775290126696e-08, 'rewards/chosen': 0.8532959222793579, 'rewards/rejected': -8.768750190734863, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.615625381469727, 'logps/chosen': -139.10000610351562, 'logps/rejected': -128.35000610351562, 'logits/chosen': -7.971875190734863, 'logits/rejected': -7.25, 'epoch': 2.73}
 91%|█████████ | 4140/4545 [4:28:57<24:07,  3.58s/it] 91%|█████████ | 4141/4545 [4:29:00<22:50,  3.39s/it] 91%|█████████ | 4142/4545 [4:29:04<24:03,  3.58s/it] 91%|█████████ | 4143/4545 [4:29:07<22:21,  3.34s/it] 91%|█████████ | 4144/4545 [4:29:11<22:37,  3.39s/it] 91%|█████████ | 4145/4545 [4:29:14<23:20,  3.50s/it] 91%|█████████ | 4146/4545 [4:29:18<24:39,  3.71s/it] 91%|█████████ | 4147/4545 [4:29:22<23:15,  3.51s/it] 91%|█████████▏| 4148/4545 [4:29:26<24:29,  3.70s/it] 91%|█████████▏| 4149/4545 [4:29:28<22:38,  3.43s/it] 91%|█████████▏| 4150/4545 [4:29:33<24:02,  3.65s/it]                                                     {'loss': 0.1748, 'grad_norm': 13.065441131591797, 'learning_rate': 5.495047873113128e-08, 'rewards/chosen': 2.6131348609924316, 'rewards/rejected': -7.881249904632568, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 10.503125190734863, 'logps/chosen': -286.25, 'logps/rejected': -158.3000030517578, 'logits/chosen': -7.574999809265137, 'logits/rejected': -7.143750190734863, 'epoch': 2.74}
 91%|█████████▏| 4150/4545 [4:29:33<24:02,  3.65s/it] 91%|█████████▏| 4151/4545 [4:29:37<24:30,  3.73s/it] 91%|█████████▏| 4152/4545 [4:29:41<25:17,  3.86s/it] 91%|█████████▏| 4153/4545 [4:29:45<25:16,  3.87s/it] 91%|█████████▏| 4154/4545 [4:29:48<24:50,  3.81s/it] 91%|█████████▏| 4155/4545 [4:29:51<21:40,  3.34s/it] 91%|█████████▏| 4156/4545 [4:29:55<22:58,  3.54s/it] 91%|█████████▏| 4157/4545 [4:29:58<23:31,  3.64s/it] 91%|█████████▏| 4158/4545 [4:30:02<23:52,  3.70s/it] 92%|█████████▏| 4159/4545 [4:30:05<22:53,  3.56s/it] 92%|█████████▏| 4160/4545 [4:30:09<23:30,  3.66s/it]                                                     {'loss': 0.1467, 'grad_norm': 6.805185794830322, 'learning_rate': 5.421491337724383e-08, 'rewards/chosen': 3.096874952316284, 'rewards/rejected': -5.520312309265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.615625381469727, 'logps/chosen': -265.5, 'logps/rejected': -216.39999389648438, 'logits/chosen': -7.846875190734863, 'logits/rejected': -7.246874809265137, 'epoch': 2.75}
 92%|█████████▏| 4160/4545 [4:30:09<23:30,  3.66s/it] 92%|█████████▏| 4161/4545 [4:30:13<22:29,  3.51s/it] 92%|█████████▏| 4162/4545 [4:30:15<20:36,  3.23s/it] 92%|█████████▏| 4163/4545 [4:30:19<22:04,  3.47s/it] 92%|█████████▏| 4164/4545 [4:30:23<22:45,  3.58s/it] 92%|█████████▏| 4165/4545 [4:30:27<23:13,  3.67s/it] 92%|█████████▏| 4166/4545 [4:30:31<23:36,  3.74s/it] 92%|█████████▏| 4167/4545 [4:30:34<22:48,  3.62s/it] 92%|█████████▏| 4168/4545 [4:30:38<23:15,  3.70s/it] 92%|█████████▏| 4169/4545 [4:30:42<22:52,  3.65s/it] 92%|█████████▏| 4170/4545 [4:30:45<23:06,  3.70s/it]                                                     {'loss': 0.2064, 'grad_norm': 22.66303062438965, 'learning_rate': 5.349715824996085e-08, 'rewards/chosen': 2.485546827316284, 'rewards/rejected': -6.324999809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.8125, 'logps/chosen': -244.39999389648438, 'logps/rejected': -195.39999389648438, 'logits/chosen': -7.771874904632568, 'logits/rejected': -7.328125, 'epoch': 2.75}
 92%|█████████▏| 4170/4545 [4:30:45<23:06,  3.70s/it] 92%|█████████▏| 4171/4545 [4:30:49<22:57,  3.68s/it] 92%|█████████▏| 4172/4545 [4:30:53<23:20,  3.75s/it] 92%|█████████▏| 4173/4545 [4:30:55<21:02,  3.39s/it] 92%|█████████▏| 4174/4545 [4:30:59<21:54,  3.54s/it] 92%|█████████▏| 4175/4545 [4:31:03<21:11,  3.44s/it] 92%|█████████▏| 4176/4545 [4:31:06<21:53,  3.56s/it] 92%|█████████▏| 4177/4545 [4:31:10<21:01,  3.43s/it] 92%|█████████▏| 4178/4545 [4:31:13<21:32,  3.52s/it] 92%|█████████▏| 4179/4545 [4:31:16<19:37,  3.22s/it] 92%|█████████▏| 4180/4545 [4:31:19<19:33,  3.21s/it]                                                     {'loss': 0.177, 'grad_norm': 21.085893630981445, 'learning_rate': 5.2797290457433174e-08, 'rewards/chosen': 3.0402588844299316, 'rewards/rejected': -7.785937309265137, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 10.828125, 'logps/chosen': -292.29998779296875, 'logps/rejected': -183.35000610351562, 'logits/chosen': -7.684374809265137, 'logits/rejected': -7.356249809265137, 'epoch': 2.76}
 92%|█████████▏| 4180/4545 [4:31:19<19:33,  3.21s/it] 92%|█████████▏| 4181/4545 [4:31:22<19:38,  3.24s/it] 92%|█████████▏| 4182/4545 [4:31:26<20:48,  3.44s/it] 92%|█████████▏| 4183/4545 [4:31:30<21:34,  3.58s/it] 92%|█████████▏| 4184/4545 [4:31:34<22:04,  3.67s/it] 92%|█████████▏| 4185/4545 [4:31:38<22:16,  3.71s/it] 92%|█████████▏| 4186/4545 [4:31:42<22:31,  3.77s/it] 92%|█████████▏| 4187/4545 [4:31:46<23:17,  3.90s/it] 92%|█████████▏| 4188/4545 [4:31:50<23:08,  3.89s/it] 92%|█████████▏| 4189/4545 [4:31:54<23:03,  3.89s/it] 92%|█████████▏| 4190/4545 [4:31:57<22:32,  3.81s/it]                                                     {'loss': 0.1943, 'grad_norm': 56.29338836669922, 'learning_rate': 5.2115385186182256e-08, 'rewards/chosen': 4.325097560882568, 'rewards/rejected': -5.917187690734863, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.240625381469727, 'logps/chosen': -392.29998779296875, 'logps/rejected': -278.75, 'logits/chosen': -7.490624904632568, 'logits/rejected': -7.131249904632568, 'epoch': 2.77}
 92%|█████████▏| 4190/4545 [4:31:57<22:32,  3.81s/it] 92%|█████████▏| 4191/4545 [4:32:01<21:49,  3.70s/it] 92%|█████████▏| 4192/4545 [4:32:03<19:52,  3.38s/it] 92%|█████████▏| 4193/4545 [4:32:07<19:49,  3.38s/it] 92%|█████████▏| 4194/4545 [4:32:10<20:13,  3.46s/it] 92%|█████████▏| 4195/4545 [4:32:14<20:57,  3.59s/it] 92%|█████████▏| 4196/4545 [4:32:18<21:06,  3.63s/it] 92%|█████████▏| 4197/4545 [4:32:22<21:31,  3.71s/it] 92%|█████████▏| 4198/4545 [4:32:25<20:07,  3.48s/it] 92%|█████████▏| 4199/4545 [4:32:29<20:47,  3.61s/it] 92%|█████████▏| 4200/4545 [4:32:33<21:09,  3.68s/it]                                                     {'loss': 0.1545, 'grad_norm': 13.756415367126465, 'learning_rate': 5.1451515693023065e-08, 'rewards/chosen': 1.7089073657989502, 'rewards/rejected': -8.28125, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 9.990625381469727, 'logps/chosen': -236.89999389648438, 'logps/rejected': -149.0500030517578, 'logits/chosen': -7.793749809265137, 'logits/rejected': -7.328125, 'epoch': 2.77}
 92%|█████████▏| 4200/4545 [4:32:33<21:09,  3.68s/it] 92%|█████████▏| 4201/4545 [4:32:36<21:11,  3.70s/it] 92%|█████████▏| 4202/4545 [4:32:40<21:27,  3.75s/it] 92%|█████████▏| 4203/4545 [4:32:44<21:38,  3.80s/it] 92%|█████████▏| 4204/4545 [4:32:48<21:19,  3.75s/it] 93%|█████████▎| 4205/4545 [4:32:52<21:30,  3.79s/it] 93%|█████████▎| 4206/4545 [4:32:56<21:36,  3.82s/it] 93%|█████████▎| 4207/4545 [4:32:59<21:26,  3.81s/it] 93%|█████████▎| 4208/4545 [4:33:03<21:31,  3.83s/it] 93%|█████████▎| 4209/4545 [4:33:07<21:30,  3.84s/it] 93%|█████████▎| 4210/4545 [4:33:11<21:12,  3.80s/it]                                                     {'loss': 0.1947, 'grad_norm': 43.33740997314453, 'learning_rate': 5.080575329719387e-08, 'rewards/chosen': 4.9072265625, 'rewards/rejected': -4.390625, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.290624618530273, 'logps/chosen': -410.45001220703125, 'logps/rejected': -233.3000030517578, 'logits/chosen': -7.462500095367432, 'logits/rejected': -7.353125095367432, 'epoch': 2.78}
 93%|█████████▎| 4210/4545 [4:33:11<21:12,  3.80s/it] 93%|█████████▎| 4211/4545 [4:33:15<21:21,  3.84s/it] 93%|█████████▎| 4212/4545 [4:33:18<20:46,  3.74s/it] 93%|█████████▎| 4213/4545 [4:33:22<20:40,  3.73s/it] 93%|█████████▎| 4214/4545 [4:33:25<19:26,  3.52s/it] 93%|█████████▎| 4215/4545 [4:33:29<19:59,  3.64s/it] 93%|█████████▎| 4216/4545 [4:33:32<19:35,  3.57s/it] 93%|█████████▎| 4217/4545 [4:33:36<19:58,  3.65s/it] 93%|█████████▎| 4218/4545 [4:33:40<19:31,  3.58s/it] 93%|█████████▎| 4219/4545 [4:33:42<18:24,  3.39s/it] 93%|█████████▎| 4220/4545 [4:33:46<19:11,  3.54s/it]                                                     {'loss': 0.1985, 'grad_norm': 41.366004943847656, 'learning_rate': 5.017816737269471e-08, 'rewards/chosen': 1.481054663658142, 'rewards/rejected': -7.115624904632568, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.59375, 'logps/chosen': -179.35000610351562, 'logps/rejected': -140.5, 'logits/chosen': -7.890625, 'logits/rejected': -7.253125190734863, 'epoch': 2.79}
 93%|█████████▎| 4220/4545 [4:33:46<19:11,  3.54s/it] 93%|█████████▎| 4221/4545 [4:33:50<19:47,  3.66s/it] 93%|█████████▎| 4222/4545 [4:33:54<20:25,  3.79s/it] 93%|█████████▎| 4223/4545 [4:33:58<20:35,  3.84s/it] 93%|█████████▎| 4224/4545 [4:34:02<20:36,  3.85s/it] 93%|█████████▎| 4225/4545 [4:34:06<20:36,  3.86s/it] 93%|█████████▎| 4226/4545 [4:34:10<20:37,  3.88s/it] 93%|█████████▎| 4227/4545 [4:34:14<20:12,  3.81s/it] 93%|█████████▎| 4228/4545 [4:34:18<20:17,  3.84s/it] 93%|█████████▎| 4229/4545 [4:34:21<20:15,  3.85s/it] 93%|█████████▎| 4230/4545 [4:34:25<19:26,  3.70s/it]                                                     {'loss': 0.198, 'grad_norm': 75.37062072753906, 'learning_rate': 4.956882534083451e-08, 'rewards/chosen': 1.892608642578125, 'rewards/rejected': -7.534375190734863, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.421875, 'logps/chosen': -230.0, 'logps/rejected': -158.85000610351562, 'logits/chosen': -7.753125190734863, 'logits/rejected': -7.178124904632568, 'epoch': 2.79}
 93%|█████████▎| 4230/4545 [4:34:25<19:26,  3.70s/it] 93%|█████████▎| 4231/4545 [4:34:29<19:40,  3.76s/it] 93%|█████████▎| 4232/4545 [4:34:33<19:59,  3.83s/it] 93%|█████████▎| 4233/4545 [4:34:37<20:02,  3.86s/it] 93%|█████████▎| 4234/4545 [4:34:41<20:24,  3.94s/it] 93%|█████████▎| 4235/4545 [4:34:45<20:16,  3.92s/it] 93%|█████████▎| 4236/4545 [4:34:49<20:10,  3.92s/it] 93%|█████████▎| 4237/4545 [4:34:52<19:22,  3.77s/it] 93%|█████████▎| 4238/4545 [4:34:56<19:37,  3.84s/it] 93%|█████████▎| 4239/4545 [4:34:59<17:56,  3.52s/it] 93%|█████████▎| 4240/4545 [4:35:03<18:54,  3.72s/it]                                                     {'loss': 0.1943, 'grad_norm': 22.165115356445312, 'learning_rate': 4.8977792662987845e-08, 'rewards/chosen': 2.681201219558716, 'rewards/rejected': -7.146874904632568, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 9.828125, 'logps/chosen': -275.70001220703125, 'logps/rejected': -206.6999969482422, 'logits/chosen': -7.678124904632568, 'logits/rejected': -7.246874809265137, 'epoch': 2.8}
 93%|█████████▎| 4240/4545 [4:35:03<18:54,  3.72s/it] 93%|█████████▎| 4241/4545 [4:35:07<18:44,  3.70s/it] 93%|█████████▎| 4242/4545 [4:35:10<18:32,  3.67s/it] 93%|█████████▎| 4243/4545 [4:35:14<18:48,  3.74s/it] 93%|█████████▎| 4244/4545 [4:35:18<19:00,  3.79s/it] 93%|█████████▎| 4245/4545 [4:35:22<19:26,  3.89s/it] 93%|█████████▎| 4246/4545 [4:35:26<19:23,  3.89s/it] 93%|█████████▎| 4247/4545 [4:35:30<19:20,  3.89s/it] 93%|█████████▎| 4248/4545 [4:35:34<18:53,  3.82s/it] 93%|█████████▎| 4249/4545 [4:35:38<19:11,  3.89s/it] 94%|█████████▎| 4250/4545 [4:35:41<19:04,  3.88s/it]                                                     {'loss': 0.1306, 'grad_norm': 8.669132232666016, 'learning_rate': 4.840513283356272e-08, 'rewards/chosen': 5.936425685882568, 'rewards/rejected': -5.6953125, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 11.640625, 'logps/chosen': -477.20001220703125, 'logps/rejected': -250.89999389648438, 'logits/chosen': -7.521874904632568, 'logits/rejected': -7.171875, 'epoch': 2.81}
 94%|█████████▎| 4250/4545 [4:35:41<19:04,  3.88s/it] 94%|█████████▎| 4251/4545 [4:35:46<19:17,  3.94s/it] 94%|█████████▎| 4252/4545 [4:35:49<19:10,  3.93s/it] 94%|█████████▎| 4253/4545 [4:35:53<19:04,  3.92s/it] 94%|█████████▎| 4254/4545 [4:35:57<19:16,  3.97s/it] 94%|█████████▎| 4255/4545 [4:36:01<18:41,  3.87s/it] 94%|█████████▎| 4256/4545 [4:36:05<18:42,  3.88s/it] 94%|█████████▎| 4257/4545 [4:36:08<18:03,  3.76s/it] 94%|█████████▎| 4258/4545 [4:36:12<18:05,  3.78s/it] 94%|█████████▎| 4259/4545 [4:36:16<18:12,  3.82s/it] 94%|█████████▎| 4260/4545 [4:36:18<15:58,  3.36s/it]                                                     {'loss': 0.1945, 'grad_norm': 19.994983673095703, 'learning_rate': 4.785090737317916e-08, 'rewards/chosen': 2.956524610519409, 'rewards/rejected': -6.019140720367432, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.971875190734863, 'logps/chosen': -288.57501220703125, 'logps/rejected': -196.5, 'logits/chosen': -7.715624809265137, 'logits/rejected': -7.296875, 'epoch': 2.81}
 94%|█████████▎| 4260/4545 [4:36:18<15:58,  3.36s/it] 94%|█████████▍| 4261/4545 [4:36:23<16:59,  3.59s/it] 94%|█████████▍| 4262/4545 [4:36:26<17:21,  3.68s/it] 94%|█████████▍| 4263/4545 [4:36:30<16:56,  3.61s/it] 94%|█████████▍| 4264/4545 [4:36:34<17:19,  3.70s/it] 94%|█████████▍| 4265/4545 [4:36:37<16:34,  3.55s/it] 94%|█████████▍| 4266/4545 [4:36:41<17:26,  3.75s/it] 94%|█████████▍| 4267/4545 [4:36:45<17:34,  3.79s/it] 94%|█████████▍| 4268/4545 [4:36:49<17:40,  3.83s/it] 94%|█████████▍| 4269/4545 [4:36:53<17:06,  3.72s/it] 94%|█████████▍| 4270/4545 [4:36:57<17:40,  3.86s/it]                                                     {'loss': 0.1986, 'grad_norm': 22.697052001953125, 'learning_rate': 4.7315175822060295e-08, 'rewards/chosen': 3.5904297828674316, 'rewards/rejected': -4.849999904632568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 8.440625190734863, 'logps/chosen': -320.6499938964844, 'logps/rejected': -223.85000610351562, 'logits/chosen': -7.587500095367432, 'logits/rejected': -7.184374809265137, 'epoch': 2.82}
 94%|█████████▍| 4270/4545 [4:36:57<17:40,  3.86s/it] 94%|█████████▍| 4271/4545 [4:37:01<17:39,  3.87s/it] 94%|█████████▍| 4272/4545 [4:37:03<16:01,  3.52s/it] 94%|█████████▍| 4273/4545 [4:37:07<15:58,  3.52s/it] 94%|█████████▍| 4274/4545 [4:37:10<15:25,  3.42s/it] 94%|█████████▍| 4275/4545 [4:37:14<16:01,  3.56s/it] 94%|█████████▍| 4276/4545 [4:37:18<16:07,  3.60s/it] 94%|█████████▍| 4277/4545 [4:37:19<13:44,  3.07s/it] 94%|█████████▍| 4278/4545 [4:37:23<14:45,  3.32s/it] 94%|█████████▍| 4279/4545 [4:37:27<14:37,  3.30s/it] 94%|█████████▍| 4280/4545 [4:37:30<15:22,  3.48s/it]                                                     {'loss': 0.1255, 'grad_norm': 6.111388206481934, 'learning_rate': 4.679799573363577e-08, 'rewards/chosen': 2.466076612472534, 'rewards/rejected': -6.782812595367432, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 9.245312690734863, 'logps/chosen': -230.02499389648438, 'logps/rejected': -156.64999389648438, 'logits/chosen': -7.771874904632568, 'logits/rejected': -7.309374809265137, 'epoch': 2.83}
 94%|█████████▍| 4280/4545 [4:37:30<15:22,  3.48s/it] 94%|█████████▍| 4281/4545 [4:37:34<15:51,  3.61s/it] 94%|█████████▍| 4282/4545 [4:37:38<16:17,  3.72s/it] 94%|█████████▍| 4283/4545 [4:37:42<16:28,  3.77s/it] 94%|█████████▍| 4284/4545 [4:37:45<15:35,  3.58s/it] 94%|█████████▍| 4285/4545 [4:37:49<15:55,  3.68s/it] 94%|█████████▍| 4286/4545 [4:37:53<15:31,  3.60s/it] 94%|█████████▍| 4287/4545 [4:37:56<14:49,  3.45s/it] 94%|█████████▍| 4288/4545 [4:38:00<15:20,  3.58s/it] 94%|█████████▍| 4289/4545 [4:38:04<15:40,  3.67s/it] 94%|█████████▍| 4290/4545 [4:38:08<16:01,  3.77s/it]                                                     {'loss': 0.1587, 'grad_norm': 48.46257019042969, 'learning_rate': 4.6299422668358976e-08, 'rewards/chosen': 2.351794481277466, 'rewards/rejected': -7.62890625, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.987500190734863, 'logps/chosen': -266.1000061035156, 'logps/rejected': -169.5, 'logits/chosen': -7.762499809265137, 'logits/rejected': -7.393750190734863, 'epoch': 2.83}
 94%|█████████▍| 4290/4545 [4:38:08<16:01,  3.77s/it] 94%|█████████▍| 4291/4545 [4:38:12<16:08,  3.81s/it] 94%|█████████▍| 4292/4545 [4:38:15<15:17,  3.63s/it] 94%|█████████▍| 4293/4545 [4:38:19<15:36,  3.72s/it] 94%|█████████▍| 4294/4545 [4:38:22<15:13,  3.64s/it] 94%|█████████▍| 4295/4545 [4:38:26<15:26,  3.71s/it] 95%|█████████▍| 4296/4545 [4:38:29<13:58,  3.37s/it] 95%|█████████▍| 4297/4545 [4:38:33<14:47,  3.58s/it] 95%|█████████▍| 4298/4545 [4:38:36<15:06,  3.67s/it] 95%|█████████▍| 4299/4545 [4:38:40<15:02,  3.67s/it] 95%|█████████▍| 4300/4545 [4:38:44<15:34,  3.81s/it]                                                     {'loss': 0.149, 'grad_norm': 27.5792179107666, 'learning_rate': 4.581951018773799e-08, 'rewards/chosen': 0.975537121295929, 'rewards/rejected': -7.821875095367432, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 8.806249618530273, 'logps/chosen': -207.89999389648438, 'logps/rejected': -160.64999389648438, 'logits/chosen': -7.696875095367432, 'logits/rejected': -7.349999904632568, 'epoch': 2.84}
 95%|█████████▍| 4300/4545 [4:38:44<15:34,  3.81s/it] 95%|█████████▍| 4301/4545 [4:38:48<15:37,  3.84s/it] 95%|█████████▍| 4302/4545 [4:38:52<15:37,  3.86s/it] 95%|█████████▍| 4303/4545 [4:38:56<15:37,  3.87s/it] 95%|█████████▍| 4304/4545 [4:39:00<15:40,  3.90s/it] 95%|█████████▍| 4305/4545 [4:39:04<15:30,  3.88s/it] 95%|█████████▍| 4306/4545 [4:39:08<15:30,  3.90s/it] 95%|█████████▍| 4307/4545 [4:39:12<15:24,  3.89s/it] 95%|█████████▍| 4308/4545 [4:39:14<13:26,  3.40s/it] 95%|█████████▍| 4309/4545 [4:39:18<13:56,  3.55s/it] 95%|█████████▍| 4310/4545 [4:39:21<13:37,  3.48s/it]                                                     {'loss': 0.1911, 'grad_norm': 27.73917579650879, 'learning_rate': 4.53583098485818e-08, 'rewards/chosen': 4.026757717132568, 'rewards/rejected': -6.607812404632568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 10.631250381469727, 'logps/chosen': -382.75, 'logps/rejected': -212.64999389648438, 'logits/chosen': -7.381249904632568, 'logits/rejected': -7.103125095367432, 'epoch': 2.84}
 95%|█████████▍| 4310/4545 [4:39:21<13:37,  3.48s/it] 95%|█████████▍| 4311/4545 [4:39:25<14:26,  3.70s/it] 95%|█████████▍| 4312/4545 [4:39:28<12:46,  3.29s/it] 95%|█████████▍| 4313/4545 [4:39:32<13:23,  3.46s/it] 95%|█████████▍| 4314/4545 [4:39:36<14:09,  3.68s/it] 95%|█████████▍| 4315/4545 [4:39:40<14:21,  3.74s/it] 95%|█████████▍| 4316/4545 [4:39:43<13:42,  3.59s/it] 95%|█████████▍| 4317/4545 [4:39:47<14:00,  3.69s/it] 95%|█████████▌| 4318/4545 [4:39:50<13:52,  3.67s/it] 95%|█████████▌| 4319/4545 [4:39:54<14:04,  3.74s/it] 95%|█████████▌| 4320/4545 [4:39:57<12:34,  3.35s/it]                                                     {'loss': 0.2325, 'grad_norm': 26.14583396911621, 'learning_rate': 4.49158711974613e-08, 'rewards/chosen': 4.094824314117432, 'rewards/rejected': -3.690234422683716, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 7.790625095367432, 'logps/chosen': -344.3999938964844, 'logps/rejected': -238.60000610351562, 'logits/chosen': -7.637499809265137, 'logits/rejected': -7.365624904632568, 'epoch': 2.85}
 95%|█████████▌| 4320/4545 [4:39:57<12:34,  3.35s/it] 95%|█████████▌| 4321/4545 [4:40:01<13:08,  3.52s/it] 95%|█████████▌| 4322/4545 [4:40:05<13:33,  3.65s/it] 95%|█████████▌| 4323/4545 [4:40:08<13:45,  3.72s/it] 95%|█████████▌| 4324/4545 [4:40:13<14:12,  3.86s/it] 95%|█████████▌| 4325/4545 [4:40:16<13:28,  3.68s/it] 95%|█████████▌| 4326/4545 [4:40:19<13:02,  3.57s/it] 95%|█████████▌| 4327/4545 [4:40:23<13:12,  3.64s/it] 95%|█████████▌| 4328/4545 [4:40:27<13:25,  3.71s/it] 95%|█████████▌| 4329/4545 [4:40:31<13:32,  3.76s/it] 95%|█████████▌| 4330/4545 [4:40:35<13:37,  3.80s/it]                                                     {'loss': 0.2083, 'grad_norm': 19.193050384521484, 'learning_rate': 4.449224176538659e-08, 'rewards/chosen': 2.2067809104919434, 'rewards/rejected': -6.324999809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 8.528124809265137, 'logps/chosen': -229.60000610351562, 'logps/rejected': -185.0, 'logits/chosen': -7.846875190734863, 'logits/rejected': -7.412499904632568, 'epoch': 2.86}
 95%|█████████▌| 4330/4545 [4:40:35<13:37,  3.80s/it] 95%|█████████▌| 4331/4545 [4:40:37<12:04,  3.39s/it] 95%|█████████▌| 4332/4545 [4:40:41<12:46,  3.60s/it] 95%|█████████▌| 4333/4545 [4:40:45<13:02,  3.69s/it] 95%|█████████▌| 4334/4545 [4:40:47<11:36,  3.30s/it] 95%|█████████▌| 4335/4545 [4:40:51<12:01,  3.44s/it] 95%|█████████▌| 4336/4545 [4:40:55<12:36,  3.62s/it] 95%|█████████▌| 4337/4545 [4:40:59<12:49,  3.70s/it] 95%|█████████▌| 4338/4545 [4:41:02<11:59,  3.48s/it] 95%|█████████▌| 4339/4545 [4:41:05<11:25,  3.33s/it] 95%|█████████▌| 4340/4545 [4:41:09<11:57,  3.50s/it]                                                     {'loss': 0.245, 'grad_norm': 30.808223724365234, 'learning_rate': 4.4087467062700876e-08, 'rewards/chosen': 3.1843199729919434, 'rewards/rejected': -6.927734375, 'rewards/accuracies': 0.875, 'rewards/margins': 10.103124618530273, 'logps/chosen': -318.04998779296875, 'logps/rejected': -216.60000610351562, 'logits/chosen': -7.793749809265137, 'logits/rejected': -7.268750190734863, 'epoch': 2.86}
 95%|█████████▌| 4340/4545 [4:41:09<11:57,  3.50s/it] 96%|█████████▌| 4341/4545 [4:41:13<12:13,  3.59s/it] 96%|█████████▌| 4342/4545 [4:41:17<12:29,  3.69s/it] 96%|█████████▌| 4343/4545 [4:41:20<12:02,  3.58s/it] 96%|█████████▌| 4344/4545 [4:41:24<12:18,  3.67s/it] 96%|█████████▌| 4345/4545 [4:41:28<12:33,  3.77s/it] 96%|█████████▌| 4346/4545 [4:41:32<12:38,  3.81s/it] 96%|█████████▌| 4347/4545 [4:41:36<12:43,  3.86s/it] 96%|█████████▌| 4348/4545 [4:41:40<12:42,  3.87s/it] 96%|█████████▌| 4349/4545 [4:41:44<12:38,  3.87s/it] 96%|█████████▌| 4350/4545 [4:41:47<12:35,  3.88s/it]                                                     {'loss': 0.2161, 'grad_norm': 23.85944366455078, 'learning_rate': 4.370159057419114e-08, 'rewards/chosen': 3.4124999046325684, 'rewards/rejected': -7.423437595367432, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 10.846875190734863, 'logps/chosen': -319.20001220703125, 'logps/rejected': -199.0, 'logits/chosen': -7.662499904632568, 'logits/rejected': -7.231249809265137, 'epoch': 2.87}
 96%|█████████▌| 4350/4545 [4:41:47<12:35,  3.88s/it] 96%|█████████▌| 4351/4545 [4:41:51<11:59,  3.71s/it] 96%|█████████▌| 4352/4545 [4:41:54<11:15,  3.50s/it] 96%|█████████▌| 4353/4545 [4:41:58<11:35,  3.62s/it] 96%|█████████▌| 4354/4545 [4:42:02<11:58,  3.76s/it] 96%|█████████▌| 4355/4545 [4:42:04<10:39,  3.36s/it] 96%|█████████▌| 4356/4545 [4:42:07<10:06,  3.21s/it] 96%|█████████▌| 4357/4545 [4:42:11<10:20,  3.30s/it] 96%|█████████▌| 4358/4545 [4:42:14<10:05,  3.24s/it] 96%|█████████▌| 4359/4545 [4:42:17<10:17,  3.32s/it] 96%|█████████▌| 4360/4545 [4:42:21<10:44,  3.48s/it]                                                     {'loss': 0.1465, 'grad_norm': 11.170825958251953, 'learning_rate': 4.333465375441664e-08, 'rewards/chosen': 1.88427734375, 'rewards/rejected': -5.214062690734863, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 7.099999904632568, 'logps/chosen': -207.14999389648438, 'logps/rejected': -186.3000030517578, 'logits/chosen': -7.849999904632568, 'logits/rejected': -7.474999904632568, 'epoch': 2.88}
 96%|█████████▌| 4360/4545 [4:42:21<10:44,  3.48s/it] 96%|█████████▌| 4361/4545 [4:42:25<11:03,  3.61s/it] 96%|█████████▌| 4362/4545 [4:42:29<11:16,  3.70s/it] 96%|█████████▌| 4363/4545 [4:42:31<10:13,  3.37s/it] 96%|█████████▌| 4364/4545 [4:42:35<10:29,  3.48s/it] 96%|█████████▌| 4365/4545 [4:42:39<10:49,  3.61s/it] 96%|█████████▌| 4366/4545 [4:42:43<10:52,  3.65s/it] 96%|█████████▌| 4367/4545 [4:42:47<11:02,  3.72s/it] 96%|█████████▌| 4368/4545 [4:42:51<11:07,  3.77s/it] 96%|█████████▌| 4369/4545 [4:42:54<10:22,  3.53s/it] 96%|█████████▌| 4370/4545 [4:42:57<10:37,  3.64s/it]                                                     {'loss': 0.223, 'grad_norm': 79.16018676757812, 'learning_rate': 4.298669602325555e-08, 'rewards/chosen': 2.777264356613159, 'rewards/rejected': -5.678906440734863, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.46875, 'logps/chosen': -278.5, 'logps/rejected': -170.60000610351562, 'logits/chosen': -7.690625190734863, 'logits/rejected': -7.340624809265137, 'epoch': 2.88}
 96%|█████████▌| 4370/4545 [4:42:57<10:37,  3.64s/it] 96%|█████████▌| 4371/4545 [4:43:01<10:46,  3.72s/it] 96%|█████████▌| 4372/4545 [4:43:05<10:38,  3.69s/it] 96%|█████████▌| 4373/4545 [4:43:09<10:58,  3.83s/it] 96%|█████████▌| 4374/4545 [4:43:13<10:49,  3.80s/it] 96%|█████████▋| 4375/4545 [4:43:17<10:50,  3.82s/it] 96%|█████████▋| 4376/4545 [4:43:20<10:35,  3.76s/it] 96%|█████████▋| 4377/4545 [4:43:24<10:44,  3.83s/it] 96%|█████████▋| 4378/4545 [4:43:28<10:43,  3.85s/it] 96%|█████████▋| 4379/4545 [4:43:32<10:40,  3.86s/it] 96%|█████████▋| 4380/4545 [4:43:35<09:35,  3.49s/it]                                                     {'loss': 0.1882, 'grad_norm': 25.036527633666992, 'learning_rate': 4.2657754761669925e-08, 'rewards/chosen': 3.2081055641174316, 'rewards/rejected': -6.025781154632568, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 9.246874809265137, 'logps/chosen': -308.8500061035156, 'logps/rejected': -213.25, 'logits/chosen': -7.634375095367432, 'logits/rejected': -7.381249904632568, 'epoch': 2.89}
 96%|█████████▋| 4380/4545 [4:43:35<09:35,  3.49s/it] 96%|█████████▋| 4381/4545 [4:43:38<09:38,  3.52s/it] 96%|█████████▋| 4382/4545 [4:43:42<09:52,  3.63s/it] 96%|█████████▋| 4383/4545 [4:43:46<10:02,  3.72s/it] 96%|█████████▋| 4384/4545 [4:43:50<10:24,  3.88s/it] 96%|█████████▋| 4385/4545 [4:43:54<10:21,  3.89s/it] 97%|█████████▋| 4386/4545 [4:43:58<10:19,  3.89s/it] 97%|█████████▋| 4387/4545 [4:44:02<10:16,  3.90s/it] 97%|█████████▋| 4388/4545 [4:44:06<09:59,  3.82s/it] 97%|█████████▋| 4389/4545 [4:44:09<09:35,  3.69s/it] 97%|█████████▋| 4390/4545 [4:44:13<09:40,  3.75s/it]                                                     {'loss': 0.1427, 'grad_norm': 35.08230972290039, 'learning_rate': 4.234786530769007e-08, 'rewards/chosen': 4.869702339172363, 'rewards/rejected': -8.264062881469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 13.120312690734863, 'logps/chosen': -392.1000061035156, 'logps/rejected': -217.5500030517578, 'logits/chosen': -7.609375, 'logits/rejected': -7.150000095367432, 'epoch': 2.9}
 97%|█████████▋| 4390/4545 [4:44:13<09:40,  3.75s/it] 97%|█████████▋| 4391/4545 [4:44:16<09:03,  3.53s/it] 97%|█████████▋| 4392/4545 [4:44:20<09:03,  3.55s/it] 97%|█████████▋| 4393/4545 [4:44:24<09:15,  3.66s/it] 97%|█████████▋| 4394/4545 [4:44:28<09:24,  3.74s/it] 97%|█████████▋| 4395/4545 [4:44:30<08:43,  3.49s/it] 97%|█████████▋| 4396/4545 [4:44:35<09:13,  3.71s/it] 97%|█████████▋| 4397/4545 [4:44:39<09:16,  3.76s/it] 97%|█████████▋| 4398/4545 [4:44:42<08:55,  3.64s/it] 97%|█████████▋| 4399/4545 [4:44:46<09:00,  3.70s/it] 97%|█████████▋| 4400/4545 [4:44:50<09:01,  3.73s/it]                                                     {'loss': 0.1237, 'grad_norm': 42.41494369506836, 'learning_rate': 4.205706095261804e-08, 'rewards/chosen': 1.896484375, 'rewards/rejected': -7.115624904632568, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 9.003125190734863, 'logps/chosen': -232.9499969482422, 'logps/rejected': -160.6999969482422, 'logits/chosen': -7.71875, 'logits/rejected': -7.209374904632568, 'epoch': 2.9}
 97%|█████████▋| 4400/4545 [4:44:50<09:01,  3.73s/it] 97%|█████████▋| 4401/4545 [4:44:53<08:59,  3.75s/it] 97%|█████████▋| 4402/4545 [4:44:57<09:03,  3.80s/it] 97%|█████████▋| 4403/4545 [4:45:01<09:13,  3.90s/it] 97%|█████████▋| 4404/4545 [4:45:04<08:21,  3.55s/it] 97%|█████████▋| 4405/4545 [4:45:08<08:27,  3.63s/it] 97%|█████████▋| 4406/4545 [4:45:12<08:35,  3.71s/it] 97%|█████████▋| 4407/4545 [4:45:16<08:34,  3.73s/it] 97%|█████████▋| 4408/4545 [4:45:19<08:36,  3.77s/it] 97%|█████████▋| 4409/4545 [4:45:23<08:37,  3.80s/it] 97%|█████████▋| 4410/4545 [4:45:28<08:50,  3.93s/it]                                                     {'loss': 0.1481, 'grad_norm': 7.2173752784729, 'learning_rate': 4.17853729374512e-08, 'rewards/chosen': 2.6114258766174316, 'rewards/rejected': -7.321875095367432, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 9.931249618530273, 'logps/chosen': -298.3500061035156, 'logps/rejected': -176.3000030517578, 'logits/chosen': -7.609375, 'logits/rejected': -7.315625190734863, 'epoch': 2.91}
 97%|█████████▋| 4410/4545 [4:45:28<08:50,  3.93s/it] 97%|█████████▋| 4411/4545 [4:45:31<08:28,  3.79s/it] 97%|█████████▋| 4412/4545 [4:45:34<07:43,  3.49s/it] 97%|█████████▋| 4413/4545 [4:45:37<07:19,  3.33s/it] 97%|█████████▋| 4414/4545 [4:45:41<07:38,  3.50s/it] 97%|█████████▋| 4415/4545 [4:45:45<07:51,  3.62s/it] 97%|█████████▋| 4416/4545 [4:45:48<07:28,  3.48s/it] 97%|█████████▋| 4417/4545 [4:45:51<07:30,  3.52s/it] 97%|█████████▋| 4418/4545 [4:45:55<07:40,  3.62s/it] 97%|█████████▋| 4419/4545 [4:45:59<07:48,  3.72s/it] 97%|█████████▋| 4420/4545 [4:46:03<07:51,  3.77s/it]                                                     {'loss': 0.1408, 'grad_norm': 21.091835021972656, 'learning_rate': 4.1532830449526166e-08, 'rewards/chosen': 2.8342528343200684, 'rewards/rejected': -7.879687309265137, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.703125, 'logps/chosen': -276.75, 'logps/rejected': -155.89999389648438, 'logits/chosen': -7.653124809265137, 'logits/rejected': -7.196875095367432, 'epoch': 2.92}
 97%|█████████▋| 4420/4545 [4:46:03<07:51,  3.77s/it] 97%|█████████▋| 4421/4545 [4:46:07<07:59,  3.86s/it] 97%|█████████▋| 4422/4545 [4:46:11<07:55,  3.87s/it] 97%|█████████▋| 4423/4545 [4:46:14<07:05,  3.49s/it] 97%|█████████▋| 4424/4545 [4:46:18<07:16,  3.61s/it] 97%|█████████▋| 4425/4545 [4:46:21<07:26,  3.72s/it] 97%|█████████▋| 4426/4545 [4:46:25<07:29,  3.78s/it] 97%|█████████▋| 4427/4545 [4:46:29<07:29,  3.81s/it] 97%|█████████▋| 4428/4545 [4:46:32<06:49,  3.50s/it] 97%|█████████▋| 4429/4545 [4:46:36<07:13,  3.73s/it] 97%|█████████▋| 4430/4545 [4:46:40<07:09,  3.74s/it]                                                     {'loss': 0.2339, 'grad_norm': 35.79714584350586, 'learning_rate': 4.1299460619382975e-08, 'rewards/chosen': 3.8238282203674316, 'rewards/rejected': -7.164843559265137, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 10.995312690734863, 'logps/chosen': -368.6499938964844, 'logps/rejected': -253.5, 'logits/chosen': -7.568749904632568, 'logits/rejected': -7.421875, 'epoch': 2.92}
 97%|█████████▋| 4430/4545 [4:46:40<07:09,  3.74s/it] 97%|█████████▋| 4431/4545 [4:46:44<07:11,  3.79s/it] 98%|█████████▊| 4432/4545 [4:46:48<07:09,  3.80s/it] 98%|█████████▊| 4433/4545 [4:46:52<07:09,  3.84s/it] 98%|█████████▊| 4434/4545 [4:46:56<07:08,  3.86s/it] 98%|█████████▊| 4435/4545 [4:47:00<07:05,  3.87s/it] 98%|█████████▊| 4436/4545 [4:47:03<07:02,  3.88s/it] 98%|█████████▊| 4437/4545 [4:47:08<07:04,  3.93s/it] 98%|█████████▊| 4438/4545 [4:47:12<07:04,  3.97s/it] 98%|█████████▊| 4439/4545 [4:47:15<06:58,  3.95s/it] 98%|█████████▊| 4440/4545 [4:47:20<07:01,  4.02s/it]                                                     {'loss': 0.1564, 'grad_norm': 25.58350944519043, 'learning_rate': 4.1085288517850625e-08, 'rewards/chosen': 4.863085746765137, 'rewards/rejected': -5.244531154632568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 10.103124618530273, 'logps/chosen': -405.95001220703125, 'logps/rejected': -296.75, 'logits/chosen': -7.440625190734863, 'logits/rejected': -7.228125095367432, 'epoch': 2.93}
 98%|█████████▊| 4440/4545 [4:47:20<07:01,  4.02s/it] 98%|█████████▊| 4441/4545 [4:47:23<06:46,  3.91s/it] 98%|█████████▊| 4442/4545 [4:47:27<06:37,  3.86s/it] 98%|█████████▊| 4443/4545 [4:47:31<06:23,  3.76s/it] 98%|█████████▊| 4444/4545 [4:47:35<06:29,  3.86s/it] 98%|█████████▊| 4445/4545 [4:47:39<06:26,  3.86s/it] 98%|█████████▊| 4446/4545 [4:47:43<06:25,  3.90s/it] 98%|█████████▊| 4447/4545 [4:47:45<05:45,  3.52s/it] 98%|█████████▊| 4448/4545 [4:47:49<05:52,  3.64s/it] 98%|█████████▊| 4449/4545 [4:47:52<05:37,  3.52s/it] 98%|█████████▊| 4450/4545 [4:47:56<05:45,  3.64s/it]                                                     {'loss': 0.2858, 'grad_norm': 42.4151725769043, 'learning_rate': 4.0890337153353696e-08, 'rewards/chosen': 1.882665991783142, 'rewards/rejected': -6.778124809265137, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 8.659375190734863, 'logps/chosen': -228.9499969482422, 'logps/rejected': -155.6999969482422, 'logits/chosen': -7.871874809265137, 'logits/rejected': -7.425000190734863, 'epoch': 2.94}
 98%|█████████▊| 4450/4545 [4:47:56<05:45,  3.64s/it] 98%|█████████▊| 4451/4545 [4:48:00<05:56,  3.79s/it] 98%|█████████▊| 4452/4545 [4:48:03<05:26,  3.51s/it] 98%|█████████▊| 4453/4545 [4:48:07<05:33,  3.63s/it] 98%|█████████▊| 4454/4545 [4:48:11<05:37,  3.70s/it] 98%|█████████▊| 4455/4545 [4:48:15<05:38,  3.76s/it] 98%|█████████▊| 4456/4545 [4:48:19<05:38,  3.80s/it] 98%|█████████▊| 4457/4545 [4:48:22<05:25,  3.69s/it] 98%|█████████▊| 4458/4545 [4:48:26<05:35,  3.85s/it] 98%|█████████▊| 4459/4545 [4:48:30<05:32,  3.87s/it] 98%|█████████▊| 4460/4545 [4:48:34<05:29,  3.87s/it]                                                     {'loss': 0.1887, 'grad_norm': 28.144765853881836, 'learning_rate': 4.071462746944053e-08, 'rewards/chosen': 3.8182005882263184, 'rewards/rejected': -6.432031154632568, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.2421875, 'logps/chosen': -336.0, 'logps/rejected': -239.0, 'logits/chosen': -7.818749904632568, 'logits/rejected': -7.28125, 'epoch': 2.94}
 98%|█████████▊| 4460/4545 [4:48:34<05:29,  3.87s/it] 98%|█████████▊| 4461/4545 [4:48:38<05:26,  3.89s/it] 98%|█████████▊| 4462/4545 [4:48:42<05:23,  3.89s/it] 98%|█████████▊| 4463/4545 [4:48:46<05:26,  3.98s/it] 98%|█████████▊| 4464/4545 [4:48:50<05:05,  3.78s/it] 98%|█████████▊| 4465/4545 [4:48:53<04:54,  3.68s/it] 98%|█████████▊| 4466/4545 [4:48:57<04:51,  3.69s/it] 98%|█████████▊| 4467/4545 [4:49:00<04:44,  3.65s/it] 98%|█████████▊| 4468/4545 [4:49:04<04:50,  3.77s/it] 98%|█████████▊| 4469/4545 [4:49:08<04:49,  3.81s/it] 98%|█████████▊| 4470/4545 [4:49:12<04:47,  3.84s/it]                                                     {'loss': 0.1466, 'grad_norm': 18.931650161743164, 'learning_rate': 4.0558178342533336e-08, 'rewards/chosen': 3.41009521484375, 'rewards/rejected': -8.620312690734863, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 12.006250381469727, 'logps/chosen': -340.75, 'logps/rejected': -205.9499969482422, 'logits/chosen': -7.65625, 'logits/rejected': -7.253125190734863, 'epoch': 2.95}
 98%|█████████▊| 4470/4545 [4:49:12<04:47,  3.84s/it] 98%|█████████▊| 4471/4545 [4:49:16<04:44,  3.85s/it] 98%|█████████▊| 4472/4545 [4:49:20<04:41,  3.85s/it] 98%|█████████▊| 4473/4545 [4:49:23<04:21,  3.64s/it] 98%|█████████▊| 4474/4545 [4:49:27<04:23,  3.71s/it] 98%|█████████▊| 4475/4545 [4:49:31<04:23,  3.77s/it] 98%|█████████▊| 4476/4545 [4:49:34<03:59,  3.46s/it] 99%|█████████▊| 4477/4545 [4:49:36<03:43,  3.29s/it] 99%|█████████▊| 4478/4545 [4:49:40<03:49,  3.42s/it] 99%|█████████▊| 4479/4545 [4:49:44<03:56,  3.59s/it] 99%|█████████▊| 4480/4545 [4:49:47<03:40,  3.40s/it]                                                     {'loss': 0.2646, 'grad_norm': 22.23758316040039, 'learning_rate': 4.0421006579900226e-08, 'rewards/chosen': 2.85888671875, 'rewards/rejected': -6.264062404632568, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 9.118749618530273, 'logps/chosen': -271.3999938964844, 'logps/rejected': -225.14999389648438, 'logits/chosen': -7.553124904632568, 'logits/rejected': -7.106249809265137, 'epoch': 2.96}
 99%|█████████▊| 4480/4545 [4:49:47<03:40,  3.40s/it] 99%|█████████▊| 4481/4545 [4:49:51<03:46,  3.54s/it] 99%|█████████▊| 4482/4545 [4:49:55<03:49,  3.64s/it] 99%|█████████▊| 4483/4545 [4:49:59<03:50,  3.71s/it] 99%|█████████▊| 4484/4545 [4:50:03<03:49,  3.76s/it] 99%|█████████▊| 4485/4545 [4:50:06<03:47,  3.79s/it] 99%|█████████▊| 4486/4545 [4:50:10<03:47,  3.86s/it] 99%|█████████▊| 4487/4545 [4:50:14<03:33,  3.68s/it] 99%|█████████▊| 4488/4545 [4:50:18<03:38,  3.83s/it] 99%|█████████▉| 4489/4545 [4:50:21<03:25,  3.68s/it] 99%|█████████▉| 4490/4545 [4:50:25<03:29,  3.81s/it]                                                     {'loss': 0.1624, 'grad_norm': 9.283645629882812, 'learning_rate': 4.0303126917849654e-08, 'rewards/chosen': 3.020458936691284, 'rewards/rejected': -7.428124904632568, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 10.443750381469727, 'logps/chosen': -320.375, 'logps/rejected': -195.5, 'logits/chosen': -7.625, 'logits/rejected': -7.015625, 'epoch': 2.96}
 99%|█████████▉| 4490/4545 [4:50:25<03:29,  3.81s/it] 99%|█████████▉| 4491/4545 [4:50:29<03:26,  3.82s/it] 99%|█████████▉| 4492/4545 [4:50:32<03:05,  3.51s/it] 99%|█████████▉| 4493/4545 [4:50:36<03:05,  3.57s/it] 99%|█████████▉| 4494/4545 [4:50:38<02:50,  3.34s/it] 99%|█████████▉| 4495/4545 [4:50:42<02:55,  3.50s/it] 99%|█████████▉| 4496/4545 [4:50:46<02:51,  3.50s/it] 99%|█████████▉| 4497/4545 [4:50:50<02:53,  3.62s/it] 99%|█████████▉| 4498/4545 [4:50:54<02:55,  3.73s/it] 99%|█████████▉| 4499/4545 [4:50:58<02:53,  3.78s/it] 99%|█████████▉| 4500/4545 [4:51:01<02:41,  3.60s/it]                                                     {'loss': 0.2018, 'grad_norm': 36.34954071044922, 'learning_rate': 4.020455202014737e-08, 'rewards/chosen': 3.1988861560821533, 'rewards/rejected': -7.667187690734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 10.865625381469727, 'logps/chosen': -341.0, 'logps/rejected': -175.6999969482422, 'logits/chosen': -7.53125, 'logits/rejected': -7.271874904632568, 'epoch': 2.97}
 99%|█████████▉| 4500/4545 [4:51:01<02:41,  3.60s/it] 99%|█████████▉| 4501/4545 [4:51:04<02:31,  3.45s/it] 99%|█████████▉| 4502/4545 [4:51:07<02:21,  3.30s/it] 99%|█████████▉| 4503/4545 [4:51:10<02:15,  3.23s/it] 99%|█████████▉| 4504/4545 [4:51:14<02:17,  3.36s/it] 99%|█████████▉| 4505/4545 [4:51:17<02:20,  3.51s/it] 99%|█████████▉| 4506/4545 [4:51:20<02:08,  3.30s/it] 99%|█████████▉| 4507/4545 [4:51:24<02:11,  3.46s/it] 99%|█████████▉| 4508/4545 [4:51:28<02:12,  3.59s/it] 99%|█████████▉| 4509/4545 [4:51:32<02:13,  3.71s/it] 99%|█████████▉| 4510/4545 [4:51:36<02:12,  3.79s/it]                                                     {'loss': 0.1557, 'grad_norm': 20.55095100402832, 'learning_rate': 4.012529247665578e-08, 'rewards/chosen': 3.1078124046325684, 'rewards/rejected': -6.338281154632568, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.4375, 'logps/chosen': -299.3500061035156, 'logps/rejected': -175.10000610351562, 'logits/chosen': -7.625, 'logits/rejected': -7.321875095367432, 'epoch': 2.98}
 99%|█████████▉| 4510/4545 [4:51:36<02:12,  3.79s/it] 99%|█████████▉| 4511/4545 [4:51:40<02:13,  3.92s/it] 99%|█████████▉| 4512/4545 [4:51:44<02:08,  3.90s/it] 99%|█████████▉| 4513/4545 [4:51:48<02:04,  3.90s/it] 99%|█████████▉| 4514/4545 [4:51:51<01:55,  3.74s/it] 99%|█████████▉| 4515/4545 [4:51:56<01:56,  3.87s/it] 99%|█████████▉| 4516/4545 [4:51:59<01:52,  3.89s/it] 99%|█████████▉| 4517/4545 [4:52:02<01:39,  3.55s/it] 99%|█████████▉| 4518/4545 [4:52:05<01:33,  3.46s/it] 99%|█████████▉| 4519/4545 [4:52:09<01:34,  3.62s/it] 99%|█████████▉| 4520/4545 [4:52:12<01:25,  3.44s/it]                                                     {'loss': 0.209, 'grad_norm': 57.51447296142578, 'learning_rate': 4.006535680219648e-08, 'rewards/chosen': 2.0520997047424316, 'rewards/rejected': -6.0380859375, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 8.090624809265137, 'logps/chosen': -247.35000610351562, 'logps/rejected': -203.8000030517578, 'logits/chosen': -7.803124904632568, 'logits/rejected': -7.384375095367432, 'epoch': 2.98}
 99%|█████████▉| 4520/4545 [4:52:12<01:25,  3.44s/it] 99%|█████████▉| 4521/4545 [4:52:15<01:19,  3.31s/it] 99%|█████████▉| 4522/4545 [4:52:20<01:22,  3.59s/it]100%|█████████▉| 4523/4545 [4:52:23<01:16,  3.48s/it]100%|█████████▉| 4524/4545 [4:52:27<01:17,  3.70s/it]100%|█████████▉| 4525/4545 [4:52:31<01:15,  3.76s/it]100%|█████████▉| 4526/4545 [4:52:35<01:12,  3.80s/it]100%|█████████▉| 4527/4545 [4:52:39<01:08,  3.80s/it]100%|█████████▉| 4528/4545 [4:52:43<01:06,  3.89s/it]100%|█████████▉| 4529/4545 [4:52:47<01:02,  3.89s/it]100%|█████████▉| 4530/4545 [4:52:51<00:58,  3.89s/it]                                                     {'loss': 0.2328, 'grad_norm': 52.41768264770508, 'learning_rate': 4.002475143563535e-08, 'rewards/chosen': 3.322070360183716, 'rewards/rejected': -7.014843940734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 10.321874618530273, 'logps/chosen': -322.0, 'logps/rejected': -189.64999389648438, 'logits/chosen': -7.740624904632568, 'logits/rejected': -7.203125, 'epoch': 2.99}
100%|█████████▉| 4530/4545 [4:52:51<00:58,  3.89s/it]100%|█████████▉| 4531/4545 [4:52:55<00:54,  3.89s/it]100%|█████████▉| 4532/4545 [4:52:59<00:51,  3.92s/it]100%|█████████▉| 4533/4545 [4:53:02<00:46,  3.91s/it]100%|█████████▉| 4534/4545 [4:53:06<00:42,  3.91s/it]100%|█████████▉| 4535/4545 [4:53:10<00:39,  3.91s/it]100%|█████████▉| 4536/4545 [4:53:14<00:35,  3.98s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.51s/it][A
 13%|█▎        | 8/60 [00:11<01:21,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.59s/it][A
 18%|█▊        | 11/60 [00:16<01:19,  1.63s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.61s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.61s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.01it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:43,  1.29s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.07s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.11s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:41<00:38,  1.38s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.36s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.10s/it][A
 68%|██████▊   | 41/60 [00:52<00:23,  1.21s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.32s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.22s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.30s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.15s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.29s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.41s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.23s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.34s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.45s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.48s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.42s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.32s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:06,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A                                                     
                                               [A{'eval_loss': 0.37793681025505066, 'eval_runtime': 80.433, 'eval_samples_per_second': 11.848, 'eval_steps_per_second': 0.746, 'eval_rewards/chosen': 3.2966203689575195, 'eval_rewards/rejected': -5.274251461029053, 'eval_rewards/accuracies': 0.8384259343147278, 'eval_rewards/margins': 8.574902534484863, 'eval_logps/chosen': -361.2583312988281, 'eval_logps/rejected': -178.3333282470703, 'eval_logits/chosen': -7.4083333015441895, 'eval_logits/rejected': -7.695833206176758, 'epoch': 2.99}
100%|█████████▉| 4536/4545 [4:54:35<00:35,  3.98s/it]
100%|██████████| 60/60 [01:18<00:00,  1.49s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 4537/4545 [4:54:49<04:09, 31.15s/it]100%|█████████▉| 4538/4545 [4:54:53<02:41, 23.04s/it]100%|█████████▉| 4539/4545 [4:54:57<01:43, 17.30s/it]100%|█████████▉| 4540/4545 [4:55:01<01:06, 13.36s/it]                                                     {'loss': 0.1585, 'grad_norm': 24.86382293701172, 'learning_rate': 4.0003480739191e-08, 'rewards/chosen': 1.9044921398162842, 'rewards/rejected': -7.239062309265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 9.134374618530273, 'logps/chosen': -226.10000610351562, 'logps/rejected': -182.64999389648438, 'logits/chosen': -7.737500190734863, 'logits/rejected': -7.243750095367432, 'epoch': 3.0}
100%|█████████▉| 4540/4545 [4:55:01<01:06, 13.36s/it]100%|█████████▉| 4541/4545 [4:55:05<00:42, 10.51s/it]100%|█████████▉| 4542/4545 [4:55:09<00:25,  8.62s/it]100%|█████████▉| 4543/4545 [4:55:13<00:14,  7.20s/it]100%|█████████▉| 4544/4545 [4:55:17<00:06,  6.22s/it]100%|██████████| 4545/4545 [4:55:20<00:00,  5.35s/it]                                                     {'train_runtime': 17745.5805, 'train_samples_per_second': 4.096, 'train_steps_per_second': 0.256, 'train_loss': 0.3041541593434131, 'epoch': 3.0}
100%|██████████| 4545/4545 [4:55:38<00:00,  5.35s/it]100%|██████████| 4545/4545 [4:55:38<00:00,  3.90s/it]
Training complete
Saving model
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mDPO_r-64_lr-4e-07_e-3_b-0.2_62717633[0m at: [34mhttps://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/16c6leh6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250607_192807-16c6leh6/logs[0m
[rank0]:[W608 00:23:52.759436054 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 0 ---
