cpu-bind=MASK - gn01, task  0  0 [3249490]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 3
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn01
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 3     --machine_rank 0     --main_process_ip gn01     --main_process_port 29500     --num_processes 12     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_63118420     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train_curriculum.py"     --rank=64 --learning_rate=1e-6 --total_epochs=3 --beta=0.1 --curriculum_stage=2
-------------------------------------------
[2025-06-12 21:20:55,642] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0612 21:20:57.045000 3249538 torch/distributed/run.py:792] 
W0612 21:20:57.045000 3249538 torch/distributed/run.py:792] *****************************************
W0612 21:20:57.045000 3249538 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0612 21:20:57.045000 3249538 torch/distributed/run.py:792] *****************************************
[2025-06-12 21:21:54,486] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 21:21:54,553] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 21:21:54,576] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 21:21:54,584] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[load_data_curriculum.py]: Training data of type 'bad_lang_examples':    3489
[load_data_curriculum.py]: Training data of type 'short_examples':       699
[load_data_curriculum.py]: Training data of type 'choose_examples':      13379
[load_data_curriculum.py]: Training data of type 'bad_format_examples':  3148
[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *
[load_data_curriculum.py]: Evaluation data size: 953
[load_data_curriculum.py]: Curriculum stage 0 training data size: 4890
[load_data_curriculum.py]: Curriculum stage 1 training data size: 6689
[load_data_curriculum.py]: Curriculum stage 2 training data size: 6690
[load_data.py]: Training data of type 'bad_lang_examples':    5343
[load_data.py]: Training data of type 'short_examples':       699
[load_data.py]: Training data of type 'choose_examples':      13379
[load_data.py]: Training data of type 'bad_format_examples':  4806Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1, curriculum_stage=2)
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1, curriculum_stage=2)
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1, curriculum_stage=2)

1e-06
1e-06
1e-06
[2025-06-12 21:21:59,434] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 21:21:59,451] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 21:21:59,500] [INFO] [comm.py:658:init_distributed] cdb=None
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][load_data.py]: Number of training examples: 24227
[load_data.py]: Number of validation examples: 953
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1, curriculum_stage=2)
1e-06
World size: 12
Setting gradient accumulation steps to: 1
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Created datasets
Train dataset size: 6690
Validation dataset size: 953
Steps per epoch: 418
Evaluate each 209 steps
[2025-06-12 21:22:01,103] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 21:22:01,110] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
Loading model from: /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/trained_models/Curriculum_DPO_models/GaMS-9B-DPO-Curriculum-1
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.89s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.93s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.94s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:17,  5.93s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.71s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.72s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.72s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.71s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.56s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.57s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.57s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.31s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.35s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.35s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.02s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.28s/it]
Loaded model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
[rank3]:[W612 21:22:24.337791110 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W612 21:22:25.808688337 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W612 21:22:25.940330486 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   8%|▊         | 540/6690 [00:00<00:01, 5308.04 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1134/6690 [00:00<00:01, 4376.00 examples/s]Extracting prompt in train dataset:  25%|██▍       | 1650/6690 [00:00<00:01, 4667.78 examples/s]Extracting prompt in train dataset:  35%|███▌      | 2367/6690 [00:00<00:00, 4716.86 examples/s]Extracting prompt in train dataset:  43%|████▎     | 2890/6690 [00:00<00:00, 4858.89 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 3520/6690 [00:00<00:00, 4583.94 examples/s]Extracting prompt in train dataset:  61%|██████    | 4061/6690 [00:00<00:00, 4800.14 examples/s]Extracting prompt in train dataset:  69%|██████▊   | 4590/6690 [00:01<00:00, 3757.95 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 5080/6690 [00:01<00:00, 4014.14 examples/s]Extracting prompt in train dataset:  84%|████████▎ | 5591/6690 [00:01<00:00, 4286.85 examples/s]Extracting prompt in train dataset:  91%|█████████ | 6071/6690 [00:01<00:00, 4420.62 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 4526.33 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 4393.83 examples/s]
Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   4%|▍         | 294/6690 [00:00<00:02, 2909.14 examples/s]Applying chat template to train dataset:   9%|▉         | 591/6690 [00:00<00:02, 2938.22 examples/s]Applying chat template to train dataset:  14%|█▍        | 964/6690 [00:00<00:02, 2683.58 examples/s]Applying chat template to train dataset:  19%|█▉        | 1290/6690 [00:00<00:02, 2453.43 examples/s]Applying chat template to train dataset:  24%|██▍       | 1635/6690 [00:00<00:02, 2390.23 examples/s]Applying chat template to train dataset:  29%|██▊       | 1919/6690 [00:00<00:01, 2510.04 examples/s]Applying chat template to train dataset:  33%|███▎      | 2213/6690 [00:00<00:01, 2627.88 examples/s]Applying chat template to train dataset:  39%|███▉      | 2635/6690 [00:01<00:01, 2693.51 examples/s]Applying chat template to train dataset:  44%|████▍     | 2942/6690 [00:01<00:01, 2791.07 examples/s]Applying chat template to train dataset:  49%|████▉     | 3267/6690 [00:01<00:01, 2481.20 examples/s]Applying chat template to train dataset:  53%|█████▎    | 3562/6690 [00:01<00:01, 2595.36 examples/s]Applying chat template to train dataset:  59%|█████▉    | 3964/6690 [00:01<00:01, 2621.89 examples/s]Applying chat template to train dataset:  64%|██████▍   | 4286/6690 [00:01<00:01, 2227.92 examples/s]Applying chat template to train dataset:  69%|██████▉   | 4638/6690 [00:01<00:00, 2261.18 examples/s]Applying chat template to train dataset:  74%|███████▍  | 4963/6690 [00:02<00:00, 2135.40 examples/s]Applying chat template to train dataset:  78%|███████▊  | 5216/6690 [00:02<00:00, 2219.31 examples/s]Applying chat template to train dataset:  82%|████████▏ | 5516/6690 [00:02<00:00, 2400.60 examples/s]Applying chat template to train dataset:  87%|████████▋ | 5820/6690 [00:02<00:00, 2554.46 examples/s]Applying chat template to train dataset:  91%|█████████ | 6092/6690 [00:02<00:00, 2595.72 examples/s]Applying chat template to train dataset:  95%|█████████▌| 6370/6690 [00:02<00:00, 2639.86 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 2589.74 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 2424.94 examples/s]
Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 38/6690 [00:00<00:17, 372.00 examples/s]Tokenizing train dataset:   1%|          | 81/6690 [00:00<00:16, 394.74 examples/s]Tokenizing train dataset:   2%|▏         | 140/6690 [00:00<00:16, 387.38 examples/s]Tokenizing train dataset:   3%|▎         | 192/6690 [00:00<00:17, 367.57 examples/s]Tokenizing train dataset:   4%|▎         | 248/6690 [00:00<00:17, 367.48 examples/s]Tokenizing train dataset:   4%|▍         | 290/6690 [00:00<00:22, 279.55 examples/s]Tokenizing train dataset:   5%|▌         | 337/6690 [00:01<00:22, 282.58 examples/s]Tokenizing train dataset:   6%|▌         | 384/6690 [00:01<00:19, 320.95 examples/s]Tokenizing train dataset:   6%|▋         | 420/6690 [00:01<00:19, 324.02 examples/s]Tokenizing train dataset:   7%|▋         | 457/6690 [00:01<00:18, 331.79 examples/s]Tokenizing train dataset:   7%|▋         | 495/6690 [00:01<00:18, 342.86 examples/s]Tokenizing train dataset:   8%|▊         | 547/6690 [00:01<00:17, 341.63 examples/s]Tokenizing train dataset:   9%|▉         | 591/6690 [00:01<00:16, 365.00 examples/s]Tokenizing train dataset:  10%|▉         | 646/6690 [00:01<00:16, 364.39 examples/s]Tokenizing train dataset:  10%|█         | 694/6690 [00:02<00:18, 320.72 examples/s]Tokenizing train dataset:  11%|█         | 735/6690 [00:02<00:17, 339.78 examples/s]Tokenizing train dataset:  12%|█▏        | 793/6690 [00:02<00:16, 352.05 examples/s]Tokenizing train dataset:  12%|█▏        | 836/6690 [00:02<00:15, 367.88 examples/s]Tokenizing train dataset:  13%|█▎        | 878/6690 [00:02<00:15, 379.69 examples/s]Tokenizing train dataset:  14%|█▍        | 937/6690 [00:02<00:15, 380.24 examples/s]Tokenizing train dataset:  15%|█▍        | 980/6690 [00:02<00:19, 291.22 examples/s]Tokenizing train dataset:  15%|█▌        | 1034/6690 [00:03<00:18, 308.47 examples/s]Tokenizing train dataset:  16%|█▌        | 1077/6690 [00:03<00:16, 330.62 examples/s]Tokenizing train dataset:  17%|█▋        | 1133/6690 [00:03<00:16, 338.72 examples/s]Tokenizing train dataset:  17%|█▋        | 1170/6690 [00:03<00:16, 343.37 examples/s]Tokenizing train dataset:  18%|█▊        | 1208/6690 [00:03<00:15, 352.01 examples/s]Tokenizing train dataset:  19%|█▊        | 1245/6690 [00:03<00:15, 354.49 examples/s]Tokenizing train dataset:  19%|█▉        | 1293/6690 [00:03<00:15, 337.97 examples/s]Tokenizing train dataset:  20%|██        | 1340/6690 [00:03<00:14, 367.00 examples/s]Tokenizing train dataset:  21%|██        | 1387/6690 [00:04<00:16, 313.58 examples/s]Tokenizing train dataset:  22%|██▏       | 1440/6690 [00:04<00:16, 321.45 examples/s]Tokenizing train dataset:  22%|██▏       | 1477/6690 [00:04<00:15, 332.08 examples/s]Tokenizing train dataset:  23%|██▎       | 1519/6690 [00:04<00:14, 351.92 examples/s]Tokenizing train dataset:  24%|██▎       | 1575/6690 [00:04<00:14, 355.37 examples/s]Tokenizing train dataset:  24%|██▍       | 1616/6690 [00:04<00:13, 366.66 examples/s]Tokenizing train dataset:  25%|██▍       | 1669/6690 [00:04<00:14, 357.79 examples/s]Tokenizing train dataset:  26%|██▌       | 1720/6690 [00:05<00:16, 310.19 examples/s]Tokenizing train dataset:  26%|██▋       | 1760/6690 [00:05<00:15, 327.17 examples/s]Tokenizing train dataset:  27%|██▋       | 1807/6690 [00:05<00:15, 311.83 examples/s]Tokenizing train dataset:  28%|██▊       | 1859/6690 [00:05<00:15, 320.01 examples/s]Tokenizing train dataset:  28%|██▊       | 1900/6690 [00:05<00:14, 335.45 examples/s]Tokenizing train dataset:  29%|██▉       | 1948/6690 [00:05<00:15, 312.39 examples/s]Tokenizing train dataset:  30%|██▉       | 1981/6690 [00:05<00:15, 313.10 examples/s]Tokenizing train dataset:  30%|███       | 2037/6690 [00:06<00:14, 331.41 examples/s]Tokenizing train dataset:  31%|███       | 2087/6690 [00:06<00:13, 330.31 examples/s]Tokenizing train dataset:  32%|███▏      | 2131/6690 [00:06<00:12, 353.71 examples/s]Tokenizing train dataset:  32%|███▏      | 2172/6690 [00:06<00:12, 366.13 examples/s]Tokenizing train dataset:  33%|███▎      | 2231/6690 [00:06<00:11, 372.94 examples/s]Tokenizing train dataset:  34%|███▍      | 2279/6690 [00:06<00:12, 349.86 examples/s]Tokenizing train dataset:  35%|███▍      | 2333/6690 [00:06<00:12, 351.89 examples/s]Tokenizing train dataset:  36%|███▌      | 2379/6690 [00:06<00:11, 373.82 examples/s]Tokenizing train dataset:  36%|███▋      | 2440/6690 [00:07<00:11, 378.66 examples/s]Tokenizing train dataset:  37%|███▋      | 2500/6690 [00:07<00:10, 381.67 examples/s]Tokenizing train dataset:  38%|███▊      | 2552/6690 [00:07<00:10, 410.21 examples/s]Tokenizing train dataset:  39%|███▉      | 2613/6690 [00:07<00:10, 406.74 examples/s]Tokenizing train dataset:  40%|███▉      | 2668/6690 [00:07<00:10, 392.03 examples/s]Tokenizing train dataset:  41%|████      | 2713/6690 [00:07<00:11, 351.35 examples/s]Tokenizing train dataset:  41%|████      | 2752/6690 [00:07<00:11, 354.66 examples/s]Tokenizing train dataset:  42%|████▏     | 2789/6690 [00:08<00:10, 356.70 examples/s]Tokenizing train dataset:  42%|████▏     | 2827/6690 [00:08<00:10, 360.31 examples/s]Tokenizing train dataset:  43%|████▎     | 2878/6690 [00:08<00:10, 347.55 examples/s]Tokenizing train dataset:  44%|████▍     | 2929/6690 [00:08<00:11, 336.62 examples/s]Tokenizing train dataset:  44%|████▍     | 2976/6690 [00:08<00:10, 365.54 examples/s]Tokenizing train dataset:  45%|████▌     | 3016/6690 [00:08<00:09, 369.89 examples/s]Tokenizing train dataset:  46%|████▌     | 3079/6690 [00:08<00:09, 384.97 examples/s]Tokenizing train dataset:  47%|████▋     | 3120/6690 [00:08<00:09, 385.07 examples/s]Tokenizing train dataset:  47%|████▋     | 3176/6690 [00:09<00:09, 377.51 examples/s]Tokenizing train dataset:  48%|████▊     | 3228/6690 [00:09<00:09, 362.81 examples/s]Tokenizing train dataset:  49%|████▉     | 3270/6690 [00:09<00:09, 373.60 examples/s]Tokenizing train dataset:  50%|████▉     | 3318/6690 [00:09<00:09, 354.74 examples/s]Tokenizing train dataset:  50%|█████     | 3368/6690 [00:09<00:09, 343.53 examples/s]Tokenizing train dataset:  51%|█████     | 3408/6690 [00:09<00:09, 355.09 examples/s]Tokenizing train dataset:  52%|█████▏    | 3447/6690 [00:09<00:10, 310.07 examples/s]Tokenizing train dataset:  52%|█████▏    | 3490/6690 [00:10<00:09, 333.89 examples/s]Tokenizing train dataset:  53%|█████▎    | 3528/6690 [00:10<00:09, 340.20 examples/s]Tokenizing train dataset:  53%|█████▎    | 3567/6690 [00:10<00:10, 296.21 examples/s]Tokenizing train dataset:  54%|█████▍    | 3611/6690 [00:10<00:10, 290.64 examples/s]Tokenizing train dataset:  55%|█████▍    | 3650/6690 [00:10<00:09, 310.89 examples/s]Tokenizing train dataset:  55%|█████▌    | 3699/6690 [00:10<00:09, 314.20 examples/s]Tokenizing train dataset:  56%|█████▌    | 3749/6690 [00:10<00:09, 319.58 examples/s]Tokenizing train dataset:  57%|█████▋    | 3797/6690 [00:11<00:09, 313.87 examples/s]Tokenizing train dataset:  58%|█████▊    | 3849/6690 [00:11<00:08, 321.80 examples/s]Tokenizing train dataset:  58%|█████▊    | 3899/6690 [00:11<00:09, 304.98 examples/s]Tokenizing train dataset:  59%|█████▉    | 3949/6690 [00:11<00:09, 283.71 examples/s]Tokenizing train dataset:  60%|█████▉    | 3984/6690 [00:11<00:09, 295.18 examples/s]Tokenizing train dataset:  60%|██████    | 4032/6690 [00:12<00:11, 225.80 examples/s]Tokenizing train dataset:  61%|██████    | 4058/6690 [00:12<00:11, 231.22 examples/s]Tokenizing train dataset:  61%|██████▏   | 4105/6690 [00:12<00:10, 252.54 examples/s]Tokenizing train dataset:  62%|██████▏   | 4153/6690 [00:12<00:10, 245.64 examples/s]Tokenizing train dataset:  63%|██████▎   | 4195/6690 [00:12<00:09, 275.34 examples/s]Tokenizing train dataset:  63%|██████▎   | 4245/6690 [00:12<00:08, 290.49 examples/s]Tokenizing train dataset:  64%|██████▍   | 4293/6690 [00:12<00:08, 295.49 examples/s]Tokenizing train dataset:  65%|██████▍   | 4338/6690 [00:13<00:07, 328.59 examples/s]Tokenizing train dataset:  65%|██████▌   | 4381/6690 [00:13<00:07, 311.04 examples/s]Tokenizing train dataset:  66%|██████▌   | 4423/6690 [00:13<00:06, 333.12 examples/s]Tokenizing train dataset:  67%|██████▋   | 4473/6690 [00:13<00:06, 328.33 examples/s]Tokenizing train dataset:  68%|██████▊   | 4520/6690 [00:13<00:06, 315.07 examples/s]Tokenizing train dataset:  68%|██████▊   | 4560/6690 [00:13<00:06, 333.72 examples/s]Tokenizing train dataset:  69%|██████▉   | 4615/6690 [00:13<00:06, 342.33 examples/s]Tokenizing train dataset:  70%|██████▉   | 4660/6690 [00:13<00:05, 364.09 examples/s]Tokenizing train dataset:  71%|███████   | 4718/6690 [00:14<00:05, 365.73 examples/s]Tokenizing train dataset:  71%|███████▏  | 4770/6690 [00:14<00:05, 358.59 examples/s]Tokenizing train dataset:  72%|███████▏  | 4811/6690 [00:14<00:06, 308.09 examples/s]Tokenizing train dataset:  73%|███████▎  | 4862/6690 [00:14<00:05, 316.86 examples/s]Tokenizing train dataset:  73%|███████▎  | 4901/6690 [00:14<00:05, 330.84 examples/s]Tokenizing train dataset:  74%|███████▍  | 4950/6690 [00:14<00:05, 325.93 examples/s]Tokenizing train dataset:  75%|███████▍  | 4992/6690 [00:15<00:05, 307.34 examples/s]Tokenizing train dataset:  75%|███████▌  | 5035/6690 [00:15<00:05, 299.41 examples/s]Tokenizing train dataset:  76%|███████▌  | 5070/6690 [00:15<00:05, 307.12 examples/s]Tokenizing train dataset:  76%|███████▋  | 5110/6690 [00:15<00:04, 326.90 examples/s]Tokenizing train dataset:  77%|███████▋  | 5148/6690 [00:15<00:04, 337.37 examples/s]Tokenizing train dataset:  78%|███████▊  | 5194/6690 [00:15<00:04, 368.67 examples/s]Tokenizing train dataset:  78%|███████▊  | 5240/6690 [00:15<00:04, 342.30 examples/s]Tokenizing train dataset:  79%|███████▉  | 5285/6690 [00:15<00:03, 364.83 examples/s]Tokenizing train dataset:  80%|███████▉  | 5341/6690 [00:15<00:03, 363.76 examples/s]Tokenizing train dataset:  81%|████████  | 5390/6690 [00:16<00:03, 387.75 examples/s]Tokenizing train dataset:  81%|████████▏ | 5440/6690 [00:16<00:03, 364.35 examples/s]Tokenizing train dataset:  82%|████████▏ | 5481/6690 [00:16<00:03, 373.87 examples/s]Tokenizing train dataset:  83%|████████▎ | 5540/6690 [00:16<00:03, 372.40 examples/s]Tokenizing train dataset:  84%|████████▎ | 5587/6690 [00:16<00:03, 346.05 examples/s]Tokenizing train dataset:  84%|████████▍ | 5645/6690 [00:16<00:02, 355.91 examples/s]Tokenizing train dataset:  85%|████████▍ | 5682/6690 [00:16<00:02, 358.23 examples/s]Tokenizing train dataset:  86%|████████▌ | 5743/6690 [00:17<00:02, 369.38 examples/s]Tokenizing train dataset:  87%|████████▋ | 5789/6690 [00:17<00:02, 347.90 examples/s]Tokenizing train dataset:  87%|████████▋ | 5827/6690 [00:17<00:02, 353.34 examples/s]Tokenizing train dataset:  88%|████████▊ | 5884/6690 [00:17<00:02, 361.40 examples/s]Tokenizing train dataset:  89%|████████▊ | 5928/6690 [00:17<00:02, 378.85 examples/s]Tokenizing train dataset:  89%|████████▉ | 5977/6690 [00:17<00:01, 357.10 examples/s]Tokenizing train dataset:  90%|█████████ | 6021/6690 [00:17<00:01, 376.41 examples/s]Tokenizing train dataset:  91%|█████████ | 6073/6690 [00:17<00:01, 363.48 examples/s]Tokenizing train dataset:  91%|█████████▏| 6120/6690 [00:18<00:01, 386.69 examples/s]Tokenizing train dataset:  92%|█████████▏| 6160/6690 [00:18<00:01, 387.90 examples/s]Tokenizing train dataset:  93%|█████████▎| 6216/6690 [00:18<00:01, 379.06 examples/s]Tokenizing train dataset:  94%|█████████▍| 6278/6690 [00:18<00:01, 346.39 examples/s]Tokenizing train dataset:  94%|█████████▍| 6320/6690 [00:18<00:01, 358.76 examples/s]Tokenizing train dataset:  95%|█████████▌| 6376/6690 [00:18<00:00, 359.74 examples/s]Tokenizing train dataset:  96%|█████████▌| 6427/6690 [00:18<00:00, 350.58 examples/s]Tokenizing train dataset:  97%|█████████▋| 6464/6690 [00:19<00:00, 353.82 examples/s]Tokenizing train dataset:  97%|█████████▋| 6508/6690 [00:19<00:00, 304.26 examples/s]Tokenizing train dataset:  98%|█████████▊| 6557/6690 [00:19<00:00, 307.92 examples/s]Tokenizing train dataset:  99%|█████████▊| 6598/6690 [00:19<00:00, 327.00 examples/s]Tokenizing train dataset:  99%|█████████▉| 6633/6690 [00:19<00:00, 330.19 examples/s]Tokenizing train dataset: 100%|█████████▉| 6672/6690 [00:19<00:00, 342.53 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:19<00:00, 337.84 examples/s]
[rank0]:[W612 21:22:51.921665534 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   8%|▊         | 550/6690 [00:00<00:01, 5409.21 examples/s]Extracting prompt in train dataset:   8%|▊         | 552/6690 [00:00<00:01, 5443.08 examples/s]Extracting prompt in train dataset:   7%|▋         | 472/6690 [00:00<00:01, 4679.01 examples/s]Extracting prompt in eval dataset:  49%|████▉     | 470/953 [00:00<00:00, 4620.63 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4592.35 examples/s]Extracting prompt in train dataset:  20%|██        | 1340/6690 [00:00<00:01, 5287.96 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4218.33 examples/s]
Extracting prompt in train dataset:  20%|██        | 1359/6690 [00:00<00:00, 5374.84 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1180/6690 [00:00<00:01, 4677.04 examples/s]Extracting prompt in train dataset:  28%|██▊       | 1890/6690 [00:00<00:00, 5331.50 examples/s]Extracting prompt in train dataset:  30%|███       | 2021/6690 [00:00<00:00, 4900.81 examples/s]Extracting prompt in train dataset:  28%|██▊       | 1846/6690 [00:00<00:01, 4547.54 examples/s]Extracting prompt in train dataset:  40%|████      | 2700/6690 [00:00<00:00, 5343.03 examples/s]Extracting prompt in train dataset:  38%|███▊      | 2540/6690 [00:00<00:00, 4987.57 examples/s]Extracting prompt in train dataset:  35%|███▌      | 2350/6690 [00:00<00:00, 4677.95 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  51%|█████▏    | 3439/6690 [00:00<00:00, 5153.53 examples/s]Extracting prompt in train dataset:  49%|████▉     | 3270/6690 [00:00<00:00, 4924.98 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3020/6690 [00:00<00:00, 4589.82 examples/s]Applying chat template to eval dataset:  33%|███▎      | 315/953 [00:00<00:00, 3114.85 examples/s]Extracting prompt in train dataset:  61%|██████    | 4050/6690 [00:00<00:00, 4752.47 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 3850/6690 [00:00<00:00, 4446.94 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 3600/6690 [00:00<00:00, 4262.90 examples/s]Applying chat template to eval dataset:  79%|███████▉  | 757/953 [00:00<00:00, 2994.54 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 4810/6690 [00:00<00:00, 4834.38 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 4532/6690 [00:00<00:00, 4473.50 examples/s]Extracting prompt in train dataset:  64%|██████▎   | 4261/6690 [00:00<00:00, 4300.65 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2980.09 examples/s]
Extracting prompt in train dataset:  82%|████████▏ | 5500/6690 [00:01<00:00, 4728.83 examples/s]Extracting prompt in train dataset:  79%|███████▊  | 5260/6690 [00:01<00:00, 4585.46 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 4980/6690 [00:01<00:00, 4449.52 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 6140/6690 [00:01<00:00, 4575.14 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 5950/6690 [00:01<00:00, 4570.43 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 5620/6690 [00:01<00:00, 4388.77 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 6680/6690 [00:01<00:00, 4758.50 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  99%|█████████▉| 6620/6690 [00:01<00:00, 4531.15 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 6247/6690 [00:01<00:00, 4322.58 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 4410.23 examples/s]
Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 4393.85 examples/s]
Tokenizing eval dataset:   3%|▎         | 33/953 [00:00<00:02, 318.19 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 3830.32 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 4149.70 examples/s]
Tokenizing eval dataset:   7%|▋         | 67/953 [00:00<00:03, 249.57 examples/s]Tokenizing eval dataset:  10%|▉         | 93/953 [00:00<00:03, 249.25 examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing eval dataset:  14%|█▎        | 130/953 [00:00<00:03, 243.30 examples/s]Applying chat template to train dataset:   4%|▍         | 290/6690 [00:00<00:02, 2872.16 examples/s]Applying chat template to train dataset:   4%|▍         | 294/6690 [00:00<00:02, 2909.92 examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   9%|▉         | 611/6690 [00:00<00:03, 1838.41 examples/s]Tokenizing eval dataset:  17%|█▋        | 158/953 [00:00<00:04, 175.98 examples/s]Applying chat template to train dataset:   9%|▉         | 624/6690 [00:00<00:03, 1788.86 examples/s]Applying chat template to train dataset:   4%|▍         | 294/6690 [00:00<00:02, 2916.25 examples/s]Applying chat template to train dataset:  14%|█▍        | 945/6690 [00:00<00:02, 2002.34 examples/s]Tokenizing eval dataset:  19%|█▉        | 181/953 [00:00<00:04, 161.94 examples/s]Applying chat template to train dataset:  14%|█▍        | 946/6690 [00:00<00:03, 1842.30 examples/s]Applying chat template to train dataset:   9%|▉         | 624/6690 [00:00<00:03, 1850.84 examples/s]Applying chat template to train dataset:  19%|█▊        | 1249/6690 [00:00<00:02, 2298.41 examples/s]Tokenizing eval dataset:  22%|██▏       | 207/953 [00:01<00:04, 181.53 examples/s]Applying chat template to train dataset:  17%|█▋        | 1150/6690 [00:00<00:02, 1894.14 examples/s]Applying chat template to train dataset:  13%|█▎        | 900/6690 [00:00<00:02, 2145.67 examples/s]Applying chat template to train dataset:  23%|██▎       | 1570/6690 [00:00<00:02, 2107.31 examples/s]Applying chat template to train dataset:  22%|██▏       | 1473/6690 [00:00<00:02, 1987.94 examples/s]Tokenizing eval dataset:  27%|██▋       | 257/953 [00:01<00:03, 225.19 examples/s]Applying chat template to train dataset:  18%|█▊        | 1207/6690 [00:00<00:02, 2438.08 examples/s]Applying chat template to train dataset:  27%|██▋       | 1824/6690 [00:00<00:02, 2215.80 examples/s]Applying chat template to train dataset:  26%|██▌       | 1752/6690 [00:00<00:02, 2194.93 examples/s]Tokenizing eval dataset:  33%|███▎      | 312/953 [00:01<00:02, 297.60 examples/s]Applying chat template to train dataset:  22%|██▏       | 1501/6690 [00:00<00:02, 2593.92 examples/s]Applying chat template to train dataset:  32%|███▏      | 2122/6690 [00:00<00:01, 2418.59 examples/s]Applying chat template to train dataset:  31%|███       | 2056/6690 [00:00<00:01, 2421.95 examples/s]Tokenizing eval dataset:  39%|███▊      | 369/953 [00:01<00:01, 360.50 examples/s]Applying chat template to train dataset:  27%|██▋       | 1810/6690 [00:00<00:01, 2741.33 examples/s]Applying chat template to train dataset:  36%|███▌      | 2416/6690 [00:01<00:01, 2559.45 examples/s]Applying chat template to train dataset:  35%|███▌      | 2350/6690 [00:01<00:01, 2562.26 examples/s]Tokenizing eval dataset:  45%|████▌     | 433/953 [00:01<00:01, 431.14 examples/s]Applying chat template to train dataset:  32%|███▏      | 2118/6690 [00:00<00:01, 2842.04 examples/s]Applying chat template to train dataset:  41%|████      | 2710/6690 [00:01<00:01, 2661.91 examples/s]Applying chat template to train dataset:  40%|████      | 2679/6690 [00:01<00:01, 2421.23 examples/s]Tokenizing eval dataset:  53%|█████▎    | 503/953 [00:01<00:01, 442.36 examples/s]Applying chat template to train dataset:  37%|███▋      | 2459/6690 [00:00<00:01, 2614.66 examples/s]Applying chat template to train dataset:  45%|████▌     | 3027/6690 [00:01<00:01, 2386.84 examples/s]Applying chat template to train dataset:  44%|████▍     | 2951/6690 [00:01<00:01, 2497.88 examples/s]Tokenizing eval dataset:  59%|█████▉    | 560/953 [00:01<00:00, 472.55 examples/s]Applying chat template to train dataset:  43%|████▎     | 2864/6690 [00:01<00:01, 2640.64 examples/s]Applying chat template to train dataset:  50%|█████     | 3350/6690 [00:01<00:01, 2059.63 examples/s]Applying chat template to train dataset:  49%|████▉     | 3274/6690 [00:01<00:01, 2098.68 examples/s]Tokenizing eval dataset:  66%|██████▌   | 625/953 [00:01<00:00, 409.07 examples/s]Applying chat template to train dataset:  48%|████▊     | 3191/6690 [00:01<00:01, 2479.49 examples/s]Applying chat template to train dataset:  55%|█████▍    | 3670/6690 [00:01<00:01, 1729.75 examples/s]Applying chat template to train dataset:  54%|█████▎    | 3595/6690 [00:01<00:01, 1628.77 examples/s]Tokenizing eval dataset:  72%|███████▏  | 689/953 [00:02<00:00, 316.04 examples/s]Applying chat template to train dataset:  53%|█████▎    | 3519/6690 [00:01<00:01, 1801.94 examples/s]Applying chat template to train dataset:  59%|█████▉    | 3942/6690 [00:01<00:01, 1921.14 examples/s]Applying chat template to train dataset:  63%|██████▎   | 4206/6690 [00:01<00:01, 2075.87 examples/s]Applying chat template to train dataset:  59%|█████▊    | 3923/6690 [00:01<00:01, 1757.20 examples/s]Applying chat template to train dataset:  58%|█████▊    | 3848/6690 [00:01<00:01, 1901.82 examples/s]Tokenizing eval dataset:  78%|███████▊  | 742/953 [00:02<00:00, 324.98 examples/s]Applying chat template to train dataset:  63%|██████▎   | 4189/6690 [00:02<00:01, 1932.44 examples/s]Applying chat template to train dataset:  67%|██████▋   | 4470/6690 [00:02<00:01, 2205.95 examples/s]Applying chat template to train dataset:  62%|██████▏   | 4142/6690 [00:01<00:01, 2106.78 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:02<00:00, 338.23 examples/s]Applying chat template to train dataset:  67%|██████▋   | 4490/6690 [00:02<00:01, 1816.97 examples/s]Applying chat template to train dataset:  72%|███████▏  | 4792/6690 [00:02<00:00, 1999.28 examples/s]Applying chat template to train dataset:  66%|██████▋   | 4446/6690 [00:02<00:01, 1948.56 examples/s]Tokenizing eval dataset:  87%|████████▋ | 832/953 [00:02<00:00, 303.95 examples/s]Applying chat template to train dataset:  70%|███████   | 4691/6690 [00:02<00:01, 1856.76 examples/s]Applying chat template to train dataset:  77%|███████▋  | 5138/6690 [00:02<00:00, 2090.05 examples/s]Applying chat template to train dataset:  72%|███████▏  | 4791/6690 [00:02<00:00, 2046.98 examples/s]Tokenizing eval dataset:  93%|█████████▎| 882/953 [00:02<00:00, 303.98 examples/s]Applying chat template to train dataset:  74%|███████▍  | 4956/6690 [00:02<00:00, 2037.11 examples/s]Tokenizing eval dataset:  97%|█████████▋| 920/953 [00:02<00:00, 318.77 examples/s]Applying chat template to train dataset:  78%|███████▊  | 5227/6690 [00:02<00:00, 2200.86 examples/s]Applying chat template to train dataset:  82%|████████▏ | 5509/6690 [00:02<00:00, 2204.94 examples/s]Applying chat template to train dataset:  77%|███████▋  | 5140/6690 [00:02<00:00, 2124.34 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 306.04 examples/s]
Applying chat template to train dataset:  83%|████████▎ | 5550/6690 [00:02<00:00, 2000.48 examples/s]Applying chat template to train dataset:  87%|████████▋ | 5834/6690 [00:02<00:00, 1997.44 examples/s]Applying chat template to train dataset:  82%|████████▏ | 5469/6690 [00:02<00:00, 1938.66 examples/s]Applying chat template to train dataset:  88%|████████▊ | 5873/6690 [00:02<00:00, 1869.72 examples/s]Applying chat template to train dataset:  92%|█████████▏| 6160/6690 [00:02<00:00, 1844.84 examples/s]Applying chat template to train dataset:  87%|████████▋ | 5800/6690 [00:02<00:00, 1836.15 examples/s]Applying chat template to train dataset:  92%|█████████▏| 6180/6690 [00:03<00:00, 2122.05 examples/s]Applying chat template to train dataset:  96%|█████████▋| 6452/6690 [00:03<00:00, 2052.94 examples/s]Applying chat template to train dataset:  91%|█████████ | 6091/6690 [00:02<00:00, 2040.90 examples/s]Applying chat template to train dataset:  97%|█████████▋| 6490/6690 [00:03<00:00, 2349.15 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:03<00:00, 2122.72 examples/s]Applying chat template to train dataset:  94%|█████████▍| 6315/6690 [00:02<00:00, 2081.53 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:03<00:00, 2108.84 examples/s]
Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:03<00:00, 2082.36 examples/s]
Applying chat template to train dataset:  99%|█████████▉| 6611/6690 [00:03<00:00, 2284.93 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:03<00:00, 2159.53 examples/s]
Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 43/6690 [00:00<00:15, 419.84 examples/s]Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 43/6690 [00:00<00:15, 417.30 examples/s]Tokenizing train dataset:   2%|▏         | 104/6690 [00:00<00:16, 400.80 examples/s]Tokenizing train dataset:   1%|          | 44/6690 [00:00<00:15, 418.48 examples/s]Tokenizing train dataset:   1%|▏         | 90/6690 [00:00<00:21, 309.94 examples/s]Tokenizing train dataset:   2%|▏         | 159/6690 [00:00<00:17, 379.10 examples/s]Tokenizing train dataset:   1%|▏         | 89/6690 [00:00<00:15, 422.37 examples/s]Tokenizing train dataset:   2%|▏         | 128/6690 [00:00<00:19, 330.35 examples/s]Tokenizing train dataset:   3%|▎         | 218/6690 [00:00<00:17, 378.71 examples/s]Tokenizing train dataset:   2%|▏         | 150/6690 [00:00<00:15, 410.73 examples/s]Tokenizing train dataset:   3%|▎         | 179/6690 [00:00<00:22, 290.62 examples/s]Tokenizing train dataset:   3%|▎         | 202/6690 [00:00<00:14, 438.09 examples/s]Tokenizing train dataset:   4%|▍         | 270/6690 [00:00<00:17, 362.46 examples/s]Tokenizing train dataset:   3%|▎         | 219/6690 [00:00<00:20, 317.23 examples/s]Tokenizing train dataset:   4%|▎         | 249/6690 [00:00<00:14, 442.64 examples/s]Tokenizing train dataset:   5%|▍         | 319/6690 [00:00<00:18, 347.62 examples/s]Tokenizing train dataset:   4%|▍         | 262/6690 [00:00<00:18, 346.39 examples/s]Tokenizing train dataset:   4%|▍         | 294/6690 [00:00<00:16, 378.03 examples/s]Tokenizing train dataset:   5%|▌         | 362/6690 [00:00<00:17, 362.09 examples/s]Tokenizing train dataset:   4%|▍         | 300/6690 [00:00<00:18, 354.12 examples/s]Tokenizing train dataset:   5%|▌         | 337/6690 [00:00<00:17, 355.14 examples/s]Tokenizing train dataset:   5%|▌         | 355/6690 [00:00<00:16, 384.68 examples/s]Tokenizing train dataset:   6%|▋         | 420/6690 [00:01<00:17, 364.08 examples/s]Tokenizing train dataset:   6%|▌         | 393/6690 [00:01<00:21, 297.43 examples/s]Tokenizing train dataset:   6%|▌         | 408/6690 [00:01<00:18, 331.17 examples/s]Tokenizing train dataset:   7%|▋         | 473/6690 [00:01<00:19, 322.04 examples/s]Tokenizing train dataset:   7%|▋         | 443/6690 [00:01<00:21, 297.01 examples/s]Tokenizing train dataset:   7%|▋         | 460/6690 [00:01<00:21, 285.67 examples/s]Tokenizing train dataset:   8%|▊         | 515/6690 [00:01<00:23, 265.93 examples/s]Tokenizing train dataset:   7%|▋         | 494/6690 [00:01<00:20, 302.41 examples/s]Tokenizing train dataset:   8%|▊         | 509/6690 [00:01<00:19, 324.86 examples/s]Tokenizing train dataset:   8%|▊         | 556/6690 [00:01<00:21, 290.29 examples/s]Tokenizing train dataset:   8%|▊         | 540/6690 [00:01<00:18, 332.77 examples/s]Tokenizing train dataset:   8%|▊         | 549/6690 [00:01<00:18, 339.08 examples/s]Tokenizing train dataset:   9%|▉         | 589/6690 [00:01<00:20, 297.24 examples/s]Tokenizing train dataset:   9%|▉         | 587/6690 [00:01<00:16, 364.47 examples/s]Tokenizing train dataset:   9%|▉         | 598/6690 [00:01<00:16, 373.30 examples/s]Tokenizing train dataset:   9%|▉         | 634/6690 [00:01<00:18, 330.76 examples/s]Tokenizing train dataset:  10%|▉         | 637/6690 [00:01<00:15, 395.97 examples/s]Tokenizing train dataset:  10%|▉         | 646/6690 [00:01<00:15, 396.52 examples/s]Tokenizing train dataset:  10%|█         | 694/6690 [00:02<00:17, 347.80 examples/s]Tokenizing train dataset:  10%|█         | 680/6690 [00:01<00:15, 400.24 examples/s]Tokenizing train dataset:  10%|█         | 693/6690 [00:01<00:14, 412.62 examples/s]Tokenizing train dataset:  11%|█         | 742/6690 [00:02<00:15, 377.49 examples/s]Tokenizing train dataset:  11%|█         | 734/6690 [00:02<00:18, 326.68 examples/s]Tokenizing train dataset:  11%|█         | 750/6690 [00:02<00:17, 343.14 examples/s]Tokenizing train dataset:  12%|█▏        | 792/6690 [00:02<00:17, 343.24 examples/s]Tokenizing train dataset:  12%|█▏        | 780/6690 [00:02<00:16, 353.27 examples/s]Tokenizing train dataset:  12%|█▏        | 800/6690 [00:02<00:15, 374.74 examples/s]Tokenizing train dataset:  13%|█▎        | 841/6690 [00:02<00:17, 334.78 examples/s]Tokenizing train dataset:  12%|█▏        | 825/6690 [00:02<00:15, 373.11 examples/s]Tokenizing train dataset:  13%|█▎        | 859/6690 [00:02<00:15, 377.83 examples/s]Tokenizing train dataset:  13%|█▎        | 885/6690 [00:02<00:18, 316.41 examples/s]Tokenizing train dataset:  13%|█▎        | 883/6690 [00:02<00:15, 372.66 examples/s]Tokenizing train dataset:  14%|█▎        | 918/6690 [00:02<00:15, 375.47 examples/s]Tokenizing train dataset:  14%|█▍        | 922/6690 [00:02<00:23, 240.33 examples/s]Tokenizing train dataset:  14%|█▍        | 923/6690 [00:02<00:22, 254.45 examples/s]Tokenizing train dataset:  14%|█▍        | 964/6690 [00:02<00:19, 293.96 examples/s]Tokenizing train dataset:  14%|█▍        | 964/6690 [00:03<00:21, 272.06 examples/s]Tokenizing train dataset:  14%|█▍        | 969/6690 [00:02<00:19, 291.69 examples/s]Tokenizing train dataset:  15%|█▌        | 1009/6690 [00:02<00:17, 322.64 examples/s]Tokenizing train dataset:  15%|█▌        | 1005/6690 [00:03<00:19, 299.01 examples/s]Tokenizing train dataset:  15%|█▌        | 1012/6690 [00:03<00:17, 319.40 examples/s]Tokenizing train dataset:  16%|█▌        | 1053/6690 [00:02<00:16, 344.56 examples/s]Tokenizing train dataset:  16%|█▌        | 1046/6690 [00:03<00:17, 324.17 examples/s]Tokenizing train dataset:  16%|█▌        | 1058/6690 [00:03<00:16, 350.47 examples/s]Tokenizing train dataset:  16%|█▌        | 1086/6690 [00:03<00:16, 338.68 examples/s]Tokenizing train dataset:  17%|█▋        | 1111/6690 [00:03<00:15, 356.63 examples/s]Tokenizing train dataset:  16%|█▋        | 1101/6690 [00:03<00:15, 367.04 examples/s]Tokenizing train dataset:  17%|█▋        | 1130/6690 [00:03<00:17, 318.00 examples/s]Tokenizing train dataset:  17%|█▋        | 1142/6690 [00:03<00:14, 377.09 examples/s]Tokenizing train dataset:  17%|█▋        | 1164/6690 [00:03<00:15, 354.24 examples/s]Tokenizing train dataset:  17%|█▋        | 1168/6690 [00:03<00:16, 331.15 examples/s]Tokenizing train dataset:  18%|█▊        | 1198/6690 [00:03<00:14, 371.93 examples/s]Tokenizing train dataset:  18%|█▊        | 1211/6690 [00:03<00:17, 305.27 examples/s]Tokenizing train dataset:  19%|█▊        | 1241/6690 [00:03<00:16, 333.38 examples/s]Tokenizing train dataset:  18%|█▊        | 1212/6690 [00:03<00:20, 272.88 examples/s]Tokenizing train dataset:  19%|█▊        | 1245/6690 [00:03<00:17, 309.94 examples/s]Tokenizing train dataset:  19%|█▊        | 1245/6690 [00:03<00:19, 283.86 examples/s]Tokenizing train dataset:  19%|█▉        | 1280/6690 [00:03<00:15, 343.23 examples/s]Tokenizing train dataset:  19%|█▉        | 1300/6690 [00:03<00:16, 322.72 examples/s]Tokenizing train dataset:  19%|█▉        | 1277/6690 [00:04<00:18, 290.61 examples/s]Tokenizing train dataset:  20%|█▉        | 1318/6690 [00:03<00:15, 349.87 examples/s]Tokenizing train dataset:  20%|█▉        | 1335/6690 [00:03<00:16, 328.49 examples/s]Tokenizing train dataset:  20%|█▉        | 1324/6690 [00:04<00:16, 334.27 examples/s]Tokenizing train dataset:  20%|██        | 1362/6690 [00:04<00:14, 369.40 examples/s]Tokenizing train dataset:  21%|██        | 1384/6690 [00:03<00:16, 321.14 examples/s]Tokenizing train dataset:  21%|██        | 1376/6690 [00:04<00:15, 336.51 examples/s]Tokenizing train dataset:  21%|██        | 1408/6690 [00:04<00:15, 341.99 examples/s]Tokenizing train dataset:  21%|██▏       | 1438/6690 [00:04<00:15, 331.07 examples/s]Tokenizing train dataset:  21%|██▏       | 1427/6690 [00:04<00:15, 335.53 examples/s]Tokenizing train dataset:  22%|██▏       | 1452/6690 [00:04<00:16, 316.34 examples/s]Tokenizing train dataset:  22%|██▏       | 1487/6690 [00:04<00:15, 326.47 examples/s]Tokenizing train dataset:  22%|██▏       | 1495/6690 [00:04<00:15, 338.84 examples/s]Tokenizing train dataset:  22%|██▏       | 1480/6690 [00:04<00:15, 335.81 examples/s]Tokenizing train dataset:  23%|██▎       | 1540/6690 [00:04<00:14, 367.82 examples/s]Tokenizing train dataset:  23%|██▎       | 1544/6690 [00:04<00:13, 375.99 examples/s]Tokenizing train dataset:  23%|██▎       | 1540/6690 [00:04<00:14, 352.76 examples/s]Tokenizing train dataset:  24%|██▍       | 1599/6690 [00:04<00:13, 371.07 examples/s]Tokenizing train dataset:  24%|██▍       | 1599/6690 [00:04<00:13, 367.20 examples/s]Tokenizing train dataset:  24%|██▎       | 1579/6690 [00:04<00:18, 269.32 examples/s]Tokenizing train dataset:  25%|██▍       | 1645/6690 [00:04<00:15, 318.78 examples/s]Tokenizing train dataset:  25%|██▍       | 1645/6690 [00:04<00:16, 304.26 examples/s]Tokenizing train dataset:  24%|██▍       | 1620/6690 [00:05<00:17, 295.20 examples/s]Tokenizing train dataset:  25%|██▌       | 1688/6690 [00:04<00:14, 340.69 examples/s]Tokenizing train dataset:  25%|██▌       | 1700/6690 [00:05<00:15, 320.65 examples/s]Tokenizing train dataset:  25%|██▍       | 1656/6690 [00:05<00:16, 308.98 examples/s]Tokenizing train dataset:  26%|██▌       | 1739/6690 [00:04<00:14, 335.90 examples/s]Tokenizing train dataset:  26%|██▌       | 1751/6690 [00:05<00:15, 313.48 examples/s]Tokenizing train dataset:  25%|██▌       | 1703/6690 [00:05<00:17, 289.45 examples/s]Tokenizing train dataset:  27%|██▋       | 1789/6690 [00:05<00:14, 329.49 examples/s]Tokenizing train dataset:  27%|██▋       | 1794/6690 [00:05<00:14, 335.84 examples/s]Tokenizing train dataset:  26%|██▌       | 1744/6690 [00:05<00:15, 315.18 examples/s]Tokenizing train dataset:  27%|██▋       | 1833/6690 [00:05<00:13, 353.16 examples/s]Tokenizing train dataset:  27%|██▋       | 1838/6690 [00:05<00:13, 356.38 examples/s]Tokenizing train dataset:  27%|██▋       | 1784/6690 [00:05<00:14, 328.86 examples/s]Tokenizing train dataset:  28%|██▊       | 1880/6690 [00:05<00:14, 326.04 examples/s]Tokenizing train dataset:  28%|██▊       | 1888/6690 [00:05<00:14, 337.76 examples/s]Tokenizing train dataset:  27%|██▋       | 1830/6690 [00:05<00:18, 261.35 examples/s]Tokenizing train dataset:  29%|██▊       | 1922/6690 [00:05<00:15, 310.05 examples/s]Tokenizing train dataset:  29%|██▉       | 1939/6690 [00:05<00:14, 335.60 examples/s]Tokenizing train dataset:  28%|██▊       | 1873/6690 [00:05<00:18, 264.01 examples/s]Tokenizing train dataset:  29%|██▉       | 1971/6690 [00:05<00:15, 310.29 examples/s]Tokenizing train dataset:  30%|██▉       | 1990/6690 [00:05<00:14, 330.89 examples/s]Tokenizing train dataset:  29%|██▊       | 1911/6690 [00:06<00:16, 286.29 examples/s]Tokenizing train dataset:  30%|██▉       | 2004/6690 [00:05<00:14, 314.45 examples/s]Tokenizing train dataset:  31%|███       | 2042/6690 [00:06<00:13, 333.26 examples/s]Tokenizing train dataset:  29%|██▉       | 1953/6690 [00:06<00:15, 314.11 examples/s]Tokenizing train dataset:  31%|███       | 2056/6690 [00:05<00:14, 320.81 examples/s]Tokenizing train dataset:  31%|███▏      | 2094/6690 [00:06<00:13, 335.89 examples/s]Tokenizing train dataset:  30%|██▉       | 2002/6690 [00:06<00:14, 315.35 examples/s]Tokenizing train dataset:  32%|███▏      | 2133/6690 [00:06<00:13, 346.82 examples/s]Tokenizing train dataset:  31%|███▏      | 2105/6690 [00:06<00:15, 302.29 examples/s]Tokenizing train dataset:  31%|███       | 2042/6690 [00:06<00:13, 333.45 examples/s]Tokenizing train dataset:  32%|███▏      | 2169/6690 [00:06<00:12, 349.20 examples/s]Tokenizing train dataset:  32%|███▏      | 2157/6690 [00:06<00:14, 313.84 examples/s]Tokenizing train dataset:  31%|███▏      | 2091/6690 [00:06<00:14, 328.14 examples/s]Tokenizing train dataset:  33%|███▎      | 2217/6690 [00:06<00:11, 379.75 examples/s]Tokenizing train dataset:  33%|███▎      | 2207/6690 [00:06<00:12, 351.92 examples/s]Tokenizing train dataset:  32%|███▏      | 2130/6690 [00:06<00:13, 342.22 examples/s]Tokenizing train dataset:  34%|███▍      | 2259/6690 [00:06<00:11, 389.20 examples/s]Tokenizing train dataset:  34%|███▎      | 2245/6690 [00:06<00:12, 354.49 examples/s]Tokenizing train dataset:  32%|███▏      | 2170/6690 [00:06<00:12, 355.39 examples/s]Tokenizing train dataset:  34%|███▍      | 2300/6690 [00:06<00:11, 387.70 examples/s]Tokenizing train dataset:  34%|███▍      | 2282/6690 [00:06<00:12, 356.12 examples/s]Tokenizing train dataset:  35%|███▌      | 2342/6690 [00:06<00:11, 394.56 examples/s]Tokenizing train dataset:  33%|███▎      | 2222/6690 [00:06<00:12, 350.44 examples/s]Tokenizing train dataset:  35%|███▍      | 2323/6690 [00:06<00:11, 368.24 examples/s]Tokenizing train dataset:  36%|███▌      | 2391/6690 [00:07<00:13, 309.77 examples/s]Tokenizing train dataset:  34%|███▍      | 2267/6690 [00:07<00:15, 291.10 examples/s]Tokenizing train dataset:  35%|███▌      | 2373/6690 [00:06<00:14, 303.37 examples/s]Tokenizing train dataset:  34%|███▍      | 2300/6690 [00:07<00:14, 294.35 examples/s]Tokenizing train dataset:  37%|███▋      | 2449/6690 [00:07<00:12, 331.06 examples/s]Tokenizing train dataset:  36%|███▌      | 2410/6690 [00:07<00:13, 315.02 examples/s]Tokenizing train dataset:  35%|███▌      | 2342/6690 [00:07<00:13, 323.11 examples/s]Tokenizing train dataset:  37%|███▋      | 2499/6690 [00:07<00:14, 292.24 examples/s]Tokenizing train dataset:  37%|███▋      | 2463/6690 [00:07<00:14, 281.86 examples/s]Tokenizing train dataset:  36%|███▌      | 2387/6690 [00:07<00:15, 269.19 examples/s]Tokenizing train dataset:  38%|███▊      | 2550/6690 [00:07<00:12, 331.22 examples/s]Tokenizing train dataset:  37%|███▋      | 2504/6690 [00:07<00:13, 306.11 examples/s]Tokenizing train dataset:  36%|███▋      | 2430/6690 [00:07<00:16, 262.91 examples/s]Tokenizing train dataset:  39%|███▉      | 2601/6690 [00:07<00:13, 311.41 examples/s]Tokenizing train dataset:  38%|███▊      | 2559/6690 [00:07<00:14, 279.36 examples/s]Tokenizing train dataset:  37%|███▋      | 2474/6690 [00:07<00:14, 298.49 examples/s]Tokenizing train dataset:  39%|███▉      | 2641/6690 [00:07<00:12, 328.88 examples/s]Tokenizing train dataset:  39%|███▉      | 2611/6690 [00:07<00:14, 287.77 examples/s]Tokenizing train dataset:  38%|███▊      | 2518/6690 [00:08<00:14, 281.82 examples/s]Tokenizing train dataset:  40%|████      | 2696/6690 [00:07<00:11, 337.15 examples/s]Tokenizing train dataset:  40%|███▉      | 2645/6690 [00:07<00:13, 294.57 examples/s]Tokenizing train dataset:  38%|███▊      | 2552/6690 [00:08<00:14, 291.28 examples/s]Tokenizing train dataset:  41%|████      | 2750/6690 [00:08<00:11, 340.63 examples/s]Tokenizing train dataset:  40%|████      | 2690/6690 [00:08<00:13, 291.36 examples/s]Tokenizing train dataset:  39%|███▉      | 2601/6690 [00:08<00:13, 292.13 examples/s]Tokenizing train dataset:  42%|████▏     | 2787/6690 [00:08<00:11, 343.98 examples/s]Tokenizing train dataset:  41%|████      | 2730/6690 [00:08<00:12, 312.80 examples/s]Tokenizing train dataset:  39%|███▉      | 2636/6690 [00:08<00:13, 302.59 examples/s]Tokenizing train dataset:  42%|████▏     | 2830/6690 [00:08<00:10, 361.32 examples/s]Tokenizing train dataset:  41%|████▏     | 2763/6690 [00:08<00:12, 314.36 examples/s]Tokenizing train dataset:  40%|███▉      | 2671/6690 [00:08<00:12, 310.37 examples/s]Tokenizing train dataset:  43%|████▎     | 2872/6690 [00:08<00:10, 375.24 examples/s]Tokenizing train dataset:  42%|████▏     | 2806/6690 [00:08<00:13, 279.95 examples/s]Tokenizing train dataset:  41%|████      | 2715/6690 [00:08<00:13, 284.53 examples/s]Tokenizing train dataset:  44%|████▎     | 2925/6690 [00:08<00:10, 342.60 examples/s]Tokenizing train dataset:  43%|████▎     | 2856/6690 [00:08<00:13, 293.28 examples/s]Tokenizing train dataset:  41%|████      | 2755/6690 [00:08<00:14, 273.55 examples/s]Tokenizing train dataset:  44%|████▍     | 2977/6690 [00:08<00:11, 325.41 examples/s]Tokenizing train dataset:  43%|████▎     | 2895/6690 [00:08<00:12, 311.90 examples/s]Tokenizing train dataset:  42%|████▏     | 2791/6690 [00:08<00:13, 290.47 examples/s]Tokenizing train dataset:  45%|████▌     | 3024/6690 [00:08<00:10, 356.49 examples/s]Tokenizing train dataset:  44%|████▍     | 2947/6690 [00:08<00:10, 359.96 examples/s]Tokenizing train dataset:  42%|████▏     | 2832/6690 [00:09<00:12, 316.96 examples/s]Tokenizing train dataset:  46%|████▌     | 3075/6690 [00:09<00:09, 391.30 examples/s]Tokenizing train dataset:  45%|████▍     | 2988/6690 [00:08<00:10, 369.44 examples/s]Tokenizing train dataset:  43%|████▎     | 2872/6690 [00:09<00:11, 333.40 examples/s]Tokenizing train dataset:  47%|████▋     | 3119/6690 [00:09<00:08, 400.67 examples/s]Tokenizing train dataset:  45%|████▌     | 3035/6690 [00:09<00:09, 391.76 examples/s]Tokenizing train dataset:  44%|████▎     | 2921/6690 [00:09<00:11, 318.49 examples/s]Tokenizing train dataset:  47%|████▋     | 3164/6690 [00:09<00:09, 363.95 examples/s]Tokenizing train dataset:  46%|████▌     | 3080/6690 [00:09<00:08, 406.97 examples/s]Tokenizing train dataset:  44%|████▍     | 2967/6690 [00:09<00:10, 350.30 examples/s]Tokenizing train dataset:  48%|████▊     | 3220/6690 [00:09<00:09, 364.88 examples/s]Tokenizing train dataset:  47%|████▋     | 3139/6690 [00:09<00:08, 396.25 examples/s]Tokenizing train dataset:  45%|████▍     | 3010/6690 [00:09<00:10, 367.56 examples/s]Tokenizing train dataset:  49%|████▉     | 3269/6690 [00:09<00:10, 334.28 examples/s]Tokenizing train dataset:  48%|████▊     | 3184/6690 [00:09<00:10, 333.50 examples/s]Tokenizing train dataset:  46%|████▌     | 3060/6690 [00:09<00:11, 321.99 examples/s]Tokenizing train dataset:  48%|████▊     | 3229/6690 [00:09<00:09, 358.07 examples/s]Tokenizing train dataset:  50%|████▉     | 3312/6690 [00:09<00:10, 317.11 examples/s]Tokenizing train dataset:  46%|████▋     | 3103/6690 [00:09<00:10, 344.71 examples/s]Tokenizing train dataset:  50%|█████     | 3353/6690 [00:09<00:09, 335.87 examples/s]Tokenizing train dataset:  49%|████▉     | 3290/6690 [00:09<00:09, 368.79 examples/s]Tokenizing train dataset:  47%|████▋     | 3142/6690 [00:10<00:11, 315.33 examples/s]Tokenizing train dataset:  51%|█████     | 3393/6690 [00:10<00:11, 285.81 examples/s]Tokenizing train dataset:  48%|████▊     | 3184/6690 [00:10<00:11, 301.06 examples/s]Tokenizing train dataset:  50%|█████     | 3348/6690 [00:09<00:10, 319.24 examples/s]Tokenizing train dataset:  51%|█████▏    | 3431/6690 [00:10<00:10, 304.97 examples/s]Tokenizing train dataset:  48%|████▊     | 3222/6690 [00:10<00:10, 315.72 examples/s]Tokenizing train dataset:  51%|█████     | 3403/6690 [00:10<00:09, 331.31 examples/s]Tokenizing train dataset:  49%|████▊     | 3255/6690 [00:10<00:10, 315.28 examples/s]Tokenizing train dataset:  52%|█████▏    | 3483/6690 [00:10<00:10, 312.92 examples/s]Tokenizing train dataset:  49%|████▉     | 3295/6690 [00:10<00:10, 335.47 examples/s]Tokenizing train dataset:  52%|█████▏    | 3455/6690 [00:10<00:09, 331.24 examples/s]Tokenizing train dataset:  53%|█████▎    | 3528/6690 [00:10<00:10, 304.67 examples/s]Tokenizing train dataset:  52%|█████▏    | 3500/6690 [00:10<00:09, 353.81 examples/s]Tokenizing train dataset:  50%|█████     | 3347/6690 [00:10<00:09, 335.13 examples/s]Tokenizing train dataset:  53%|█████▎    | 3561/6690 [00:10<00:10, 308.68 examples/s]Tokenizing train dataset:  53%|█████▎    | 3550/6690 [00:10<00:09, 346.45 examples/s]Tokenizing train dataset:  51%|█████     | 3386/6690 [00:10<00:10, 306.63 examples/s]Tokenizing train dataset:  54%|█████▍    | 3600/6690 [00:10<00:11, 279.54 examples/s]Tokenizing train dataset:  54%|█████▍    | 3629/6690 [00:10<00:10, 280.21 examples/s]Tokenizing train dataset:  54%|█████▎    | 3590/6690 [00:10<00:09, 313.55 examples/s]Tokenizing train dataset:  51%|█████     | 3428/6690 [00:10<00:11, 279.35 examples/s]Tokenizing train dataset:  54%|█████▍    | 3630/6690 [00:10<00:09, 330.14 examples/s]Tokenizing train dataset:  55%|█████▍    | 3670/6690 [00:10<00:09, 307.35 examples/s]Tokenizing train dataset:  52%|█████▏    | 3470/6690 [00:11<00:11, 274.67 examples/s]Tokenizing train dataset:  55%|█████▍    | 3665/6690 [00:10<00:09, 332.09 examples/s]Tokenizing train dataset:  52%|█████▏    | 3503/6690 [00:11<00:11, 285.41 examples/s]Tokenizing train dataset:  55%|█████▌    | 3709/6690 [00:11<00:11, 253.44 examples/s]Tokenizing train dataset:  55%|█████▌    | 3700/6690 [00:11<00:09, 324.50 examples/s]Tokenizing train dataset:  53%|█████▎    | 3534/6690 [00:11<00:10, 289.27 examples/s]Tokenizing train dataset:  56%|█████▌    | 3749/6690 [00:11<00:10, 284.89 examples/s]Tokenizing train dataset:  56%|█████▌    | 3735/6690 [00:11<00:08, 328.50 examples/s]Tokenizing train dataset:  53%|█████▎    | 3568/6690 [00:11<00:10, 299.03 examples/s]Tokenizing train dataset:  57%|█████▋    | 3790/6690 [00:11<00:09, 314.41 examples/s]Tokenizing train dataset:  57%|█████▋    | 3782/6690 [00:11<00:09, 306.39 examples/s]Tokenizing train dataset:  57%|█████▋    | 3826/6690 [00:11<00:08, 324.30 examples/s]Tokenizing train dataset:  54%|█████▍    | 3613/6690 [00:11<00:10, 296.07 examples/s]Tokenizing train dataset:  57%|█████▋    | 3821/6690 [00:11<00:08, 324.59 examples/s]Tokenizing train dataset:  58%|█████▊    | 3866/6690 [00:11<00:08, 342.33 examples/s]Tokenizing train dataset:  55%|█████▍    | 3655/6690 [00:11<00:09, 325.29 examples/s]Tokenizing train dataset:  58%|█████▊    | 3858/6690 [00:11<00:08, 331.83 examples/s]Tokenizing train dataset:  59%|█████▊    | 3916/6690 [00:11<00:07, 380.88 examples/s]Tokenizing train dataset:  58%|█████▊    | 3909/6690 [00:11<00:07, 375.25 examples/s]Tokenizing train dataset:  55%|█████▌    | 3700/6690 [00:11<00:09, 304.13 examples/s]Tokenizing train dataset:  59%|█████▉    | 3978/6690 [00:11<00:07, 387.37 examples/s]Tokenizing train dataset:  59%|█████▉    | 3949/6690 [00:11<00:07, 377.92 examples/s]Tokenizing train dataset:  56%|█████▌    | 3739/6690 [00:12<00:10, 285.72 examples/s]Tokenizing train dataset:  60%|██████    | 4029/6690 [00:12<00:07, 342.68 examples/s]Tokenizing train dataset:  60%|█████▉    | 3997/6690 [00:11<00:07, 345.43 examples/s]Tokenizing train dataset:  56%|█████▋    | 3770/6690 [00:12<00:10, 290.07 examples/s]Tokenizing train dataset:  60%|██████    | 4033/6690 [00:11<00:07, 346.34 examples/s]Tokenizing train dataset:  57%|█████▋    | 3801/6690 [00:12<00:09, 293.34 examples/s]Tokenizing train dataset:  61%|██████    | 4084/6690 [00:12<00:07, 347.74 examples/s]Tokenizing train dataset:  61%|██████    | 4075/6690 [00:12<00:09, 273.64 examples/s]Tokenizing train dataset:  57%|█████▋    | 3846/6690 [00:12<00:12, 232.33 examples/s]Tokenizing train dataset:  62%|██████▏   | 4133/6690 [00:12<00:08, 284.84 examples/s]Tokenizing train dataset:  62%|██████▏   | 4119/6690 [00:12<00:08, 309.31 examples/s]Tokenizing train dataset:  58%|█████▊    | 3884/6690 [00:12<00:10, 259.14 examples/s]Tokenizing train dataset:  62%|██████▏   | 4180/6690 [00:12<00:07, 317.92 examples/s]Tokenizing train dataset:  62%|██████▏   | 4162/6690 [00:12<00:07, 334.57 examples/s]Tokenizing train dataset:  59%|█████▉    | 3931/6690 [00:12<00:12, 224.82 examples/s]Tokenizing train dataset:  63%|██████▎   | 4226/6690 [00:12<00:11, 212.23 examples/s]Tokenizing train dataset:  63%|██████▎   | 4213/6690 [00:12<00:13, 187.04 examples/s]Tokenizing train dataset:  59%|█████▉    | 3979/6690 [00:13<00:15, 178.34 examples/s]Tokenizing train dataset:  64%|██████▍   | 4273/6690 [00:13<00:12, 199.90 examples/s]Tokenizing train dataset:  64%|██████▎   | 4257/6690 [00:13<00:11, 207.16 examples/s]Tokenizing train dataset:  60%|██████    | 4018/6690 [00:13<00:12, 208.56 examples/s]Tokenizing train dataset:  65%|██████▍   | 4317/6690 [00:13<00:10, 235.78 examples/s]Tokenizing train dataset:  64%|██████▍   | 4294/6690 [00:13<00:10, 233.49 examples/s]Tokenizing train dataset:  60%|██████    | 4045/6690 [00:13<00:12, 218.04 examples/s]Tokenizing train dataset:  65%|██████▌   | 4357/6690 [00:13<00:08, 263.94 examples/s]Tokenizing train dataset:  65%|██████▍   | 4342/6690 [00:13<00:08, 278.77 examples/s]Tokenizing train dataset:  61%|██████    | 4085/6690 [00:13<00:11, 227.34 examples/s]Tokenizing train dataset:  66%|██████▌   | 4401/6690 [00:13<00:08, 269.29 examples/s]Tokenizing train dataset:  66%|██████▌   | 4394/6690 [00:13<00:07, 296.73 examples/s]Tokenizing train dataset:  62%|██████▏   | 4127/6690 [00:13<00:09, 265.88 examples/s]Tokenizing train dataset:  67%|██████▋   | 4450/6690 [00:13<00:07, 283.22 examples/s]Tokenizing train dataset:  62%|██████▏   | 4170/6690 [00:13<00:08, 300.54 examples/s]Tokenizing train dataset:  67%|██████▋   | 4454/6690 [00:13<00:06, 323.93 examples/s]Tokenizing train dataset:  67%|██████▋   | 4489/6690 [00:13<00:07, 304.87 examples/s]Tokenizing train dataset:  63%|██████▎   | 4211/6690 [00:13<00:07, 325.95 examples/s]Tokenizing train dataset:  67%|██████▋   | 4494/6690 [00:13<00:06, 337.82 examples/s]Tokenizing train dataset:  68%|██████▊   | 4536/6690 [00:13<00:07, 302.62 examples/s]Tokenizing train dataset:  64%|██████▎   | 4258/6690 [00:14<00:07, 318.81 examples/s]Tokenizing train dataset:  68%|██████▊   | 4547/6690 [00:13<00:06, 340.35 examples/s]Tokenizing train dataset:  69%|██████▊   | 4585/6690 [00:14<00:07, 299.39 examples/s]Tokenizing train dataset:  64%|██████▍   | 4305/6690 [00:14<00:07, 311.67 examples/s]Tokenizing train dataset:  69%|██████▊   | 4591/6690 [00:13<00:06, 320.04 examples/s]Tokenizing train dataset:  69%|██████▉   | 4629/6690 [00:14<00:06, 328.58 examples/s]Tokenizing train dataset:  65%|██████▍   | 4340/6690 [00:14<00:07, 318.18 examples/s]Tokenizing train dataset:  69%|██████▉   | 4647/6690 [00:14<00:06, 319.78 examples/s]Tokenizing train dataset:  70%|██████▉   | 4679/6690 [00:14<00:06, 325.73 examples/s]Tokenizing train dataset:  65%|██████▌   | 4377/6690 [00:14<00:07, 293.83 examples/s]Tokenizing train dataset:  70%|███████   | 4694/6690 [00:14<00:06, 285.55 examples/s]Tokenizing train dataset:  71%|███████   | 4728/6690 [00:14<00:06, 322.33 examples/s]Tokenizing train dataset:  66%|██████▌   | 4420/6690 [00:14<00:07, 285.46 examples/s]Tokenizing train dataset:  71%|███████   | 4741/6690 [00:14<00:06, 320.50 examples/s]Tokenizing train dataset:  71%|███████▏  | 4769/6690 [00:14<00:05, 338.75 examples/s]Tokenizing train dataset:  67%|██████▋   | 4459/6690 [00:14<00:07, 307.52 examples/s]Tokenizing train dataset:  67%|██████▋   | 4492/6690 [00:14<00:07, 308.82 examples/s]Tokenizing train dataset:  72%|███████▏  | 4787/6690 [00:14<00:06, 314.92 examples/s]Tokenizing train dataset:  72%|███████▏  | 4823/6690 [00:14<00:05, 341.02 examples/s]Tokenizing train dataset:  72%|███████▏  | 4822/6690 [00:14<00:05, 320.52 examples/s]Tokenizing train dataset:  73%|███████▎  | 4867/6690 [00:14<00:05, 363.01 examples/s]Tokenizing train dataset:  68%|██████▊   | 4537/6690 [00:15<00:07, 304.54 examples/s]Tokenizing train dataset:  73%|███████▎  | 4866/6690 [00:14<00:05, 346.14 examples/s]Tokenizing train dataset:  73%|███████▎  | 4906/6690 [00:15<00:04, 365.68 examples/s]Tokenizing train dataset:  68%|██████▊   | 4580/6690 [00:15<00:06, 332.27 examples/s]Tokenizing train dataset:  73%|███████▎  | 4912/6690 [00:14<00:05, 329.32 examples/s]Tokenizing train dataset:  74%|███████▍  | 4956/6690 [00:15<00:04, 351.41 examples/s]Tokenizing train dataset:  69%|██████▉   | 4634/6690 [00:15<00:06, 335.41 examples/s]Tokenizing train dataset:  74%|███████▍  | 4956/6690 [00:15<00:04, 353.56 examples/s]Tokenizing train dataset:  75%|███████▍  | 5011/6690 [00:15<00:04, 354.59 examples/s]Tokenizing train dataset:  70%|██████▉   | 4680/6690 [00:15<00:07, 258.29 examples/s]Tokenizing train dataset:  75%|███████▍  | 5000/6690 [00:15<00:05, 301.68 examples/s]Tokenizing train dataset:  76%|███████▌  | 5060/6690 [00:15<00:04, 343.26 examples/s]Tokenizing train dataset:  71%|███████   | 4727/6690 [00:15<00:07, 250.23 examples/s]Tokenizing train dataset:  75%|███████▌  | 5045/6690 [00:15<00:06, 262.67 examples/s]Tokenizing train dataset:  76%|███████▋  | 5105/6690 [00:15<00:05, 285.97 examples/s]Tokenizing train dataset:  76%|███████▌  | 5076/6690 [00:15<00:05, 270.68 examples/s]Tokenizing train dataset:  77%|███████▋  | 5136/6690 [00:15<00:05, 290.59 examples/s]Tokenizing train dataset:  71%|███████▏  | 4769/6690 [00:15<00:07, 254.93 examples/s]Tokenizing train dataset:  77%|███████▋  | 5120/6690 [00:15<00:05, 272.71 examples/s]Tokenizing train dataset:  78%|███████▊  | 5185/6690 [00:15<00:05, 298.64 examples/s]Tokenizing train dataset:  72%|███████▏  | 4810/6690 [00:16<00:07, 252.66 examples/s]Tokenizing train dataset:  72%|███████▏  | 4839/6690 [00:16<00:07, 258.73 examples/s]Tokenizing train dataset:  77%|███████▋  | 5169/6690 [00:15<00:05, 277.82 examples/s]Tokenizing train dataset:  78%|███████▊  | 5230/6690 [00:16<00:04, 292.22 examples/s]Tokenizing train dataset:  73%|███████▎  | 4868/6690 [00:16<00:06, 264.76 examples/s]Tokenizing train dataset:  78%|███████▊  | 5210/6690 [00:16<00:04, 301.41 examples/s]Tokenizing train dataset:  73%|███████▎  | 4903/6690 [00:16<00:06, 285.06 examples/s]Tokenizing train dataset:  79%|███████▉  | 5277/6690 [00:16<00:04, 290.36 examples/s]Tokenizing train dataset:  79%|███████▊  | 5264/6690 [00:16<00:04, 317.39 examples/s]Tokenizing train dataset:  74%|███████▍  | 4939/6690 [00:16<00:05, 301.57 examples/s]Tokenizing train dataset:  79%|███████▉  | 5311/6690 [00:16<00:04, 299.96 examples/s]Tokenizing train dataset:  79%|███████▉  | 5308/6690 [00:16<00:05, 263.01 examples/s]Tokenizing train dataset:  74%|███████▍  | 4980/6690 [00:16<00:08, 190.94 examples/s]Tokenizing train dataset:  80%|████████  | 5363/6690 [00:16<00:06, 211.34 examples/s]Tokenizing train dataset:  80%|████████  | 5355/6690 [00:16<00:05, 263.50 examples/s]Tokenizing train dataset:  81%|████████  | 5390/6690 [00:16<00:06, 213.93 examples/s]Tokenizing train dataset:  80%|████████  | 5384/6690 [00:16<00:04, 267.34 examples/s]Tokenizing train dataset:  75%|███████▌  | 5024/6690 [00:17<00:08, 207.31 examples/s]Tokenizing train dataset:  76%|███████▌  | 5057/6690 [00:17<00:07, 229.10 examples/s]Tokenizing train dataset:  81%|████████  | 5434/6690 [00:17<00:05, 231.57 examples/s]Tokenizing train dataset:  81%|████████  | 5427/6690 [00:16<00:04, 265.23 examples/s]Tokenizing train dataset:  76%|███████▌  | 5098/6690 [00:17<00:06, 237.92 examples/s]Tokenizing train dataset:  82%|████████▏ | 5480/6690 [00:17<00:04, 244.89 examples/s]Tokenizing train dataset:  82%|████████▏ | 5471/6690 [00:17<00:04, 261.80 examples/s]Tokenizing train dataset:  77%|███████▋  | 5130/6690 [00:17<00:06, 252.07 examples/s]Tokenizing train dataset:  83%|████████▎ | 5520/6690 [00:17<00:04, 275.02 examples/s]Tokenizing train dataset:  82%|████████▏ | 5498/6690 [00:17<00:05, 217.51 examples/s]Tokenizing train dataset:  77%|███████▋  | 5179/6690 [00:17<00:06, 251.75 examples/s]Tokenizing train dataset:  83%|████████▎ | 5566/6690 [00:17<00:04, 261.44 examples/s]Tokenizing train dataset:  83%|████████▎ | 5532/6690 [00:17<00:04, 239.92 examples/s]Tokenizing train dataset:  83%|████████▎ | 5560/6690 [00:17<00:04, 246.32 examples/s]Tokenizing train dataset:  78%|███████▊  | 5222/6690 [00:17<00:05, 250.88 examples/s]Tokenizing train dataset:  84%|████████▍ | 5609/6690 [00:17<00:04, 262.15 examples/s]Tokenizing train dataset:  84%|████████▎ | 5593/6690 [00:17<00:04, 265.41 examples/s]Tokenizing train dataset:  79%|███████▊  | 5261/6690 [00:17<00:05, 277.74 examples/s]Tokenizing train dataset:  84%|████████▍ | 5650/6690 [00:17<00:03, 290.00 examples/s]Tokenizing train dataset:  84%|████████▍ | 5642/6690 [00:17<00:03, 278.34 examples/s]Tokenizing train dataset:  79%|███████▉  | 5308/6690 [00:18<00:04, 285.87 examples/s]Tokenizing train dataset:  85%|████████▌ | 5702/6690 [00:17<00:03, 305.02 examples/s]Tokenizing train dataset:  85%|████████▌ | 5687/6690 [00:17<00:03, 254.43 examples/s]Tokenizing train dataset:  80%|████████  | 5354/6690 [00:18<00:04, 269.34 examples/s]Tokenizing train dataset:  86%|████████▌ | 5753/6690 [00:18<00:03, 281.04 examples/s]Tokenizing train dataset:  86%|████████▌ | 5733/6690 [00:18<00:03, 296.67 examples/s]Tokenizing train dataset:  81%|████████  | 5393/6690 [00:18<00:04, 293.00 examples/s]Tokenizing train dataset:  87%|████████▋ | 5788/6690 [00:18<00:03, 293.35 examples/s]Tokenizing train dataset:  87%|████████▋ | 5789/6690 [00:18<00:02, 318.77 examples/s]Tokenizing train dataset:  81%|████████▏ | 5438/6690 [00:18<00:04, 290.99 examples/s]Tokenizing train dataset:  87%|████████▋ | 5833/6690 [00:18<00:02, 293.34 examples/s]Tokenizing train dataset:  87%|████████▋ | 5831/6690 [00:18<00:02, 335.94 examples/s]Tokenizing train dataset:  82%|████████▏ | 5476/6690 [00:18<00:03, 309.52 examples/s]Tokenizing train dataset:  88%|████████▊ | 5870/6690 [00:18<00:02, 309.01 examples/s]Tokenizing train dataset:  88%|████████▊ | 5873/6690 [00:18<00:02, 315.58 examples/s]Tokenizing train dataset:  83%|████████▎ | 5521/6690 [00:18<00:03, 302.13 examples/s]Tokenizing train dataset:  89%|████████▊ | 5923/6690 [00:18<00:02, 290.88 examples/s]Tokenizing train dataset:  88%|████████▊ | 5920/6690 [00:18<00:02, 348.98 examples/s]Tokenizing train dataset:  83%|████████▎ | 5556/6690 [00:18<00:03, 312.31 examples/s]Tokenizing train dataset:  89%|████████▉ | 5962/6690 [00:18<00:02, 311.12 examples/s]Tokenizing train dataset:  89%|████████▉ | 5967/6690 [00:18<00:02, 302.97 examples/s]Tokenizing train dataset:  84%|████████▎ | 5593/6690 [00:19<00:04, 258.52 examples/s]Tokenizing train dataset:  90%|████████▉ | 6010/6690 [00:18<00:02, 312.50 examples/s]Tokenizing train dataset:  90%|████████▉ | 6013/6690 [00:18<00:02, 285.95 examples/s]Tokenizing train dataset:  84%|████████▍ | 5640/6690 [00:19<00:04, 262.15 examples/s]Tokenizing train dataset:  91%|█████████ | 6055/6690 [00:19<00:02, 286.49 examples/s]Tokenizing train dataset:  91%|█████████ | 6060/6690 [00:19<00:02, 270.04 examples/s]Tokenizing train dataset:  85%|████████▍ | 5681/6690 [00:19<00:04, 245.98 examples/s]Tokenizing train dataset:  91%|█████████▏| 6110/6690 [00:19<00:01, 295.16 examples/s]Tokenizing train dataset:  91%|█████████ | 6090/6690 [00:19<00:02, 257.05 examples/s]Tokenizing train dataset:  86%|████████▌ | 5723/6690 [00:19<00:04, 237.42 examples/s]Tokenizing train dataset:  92%|█████████▏| 6158/6690 [00:19<00:01, 279.20 examples/s]Tokenizing train dataset:  92%|█████████▏| 6137/6690 [00:19<00:01, 301.38 examples/s]Tokenizing train dataset:  86%|████████▌ | 5749/6690 [00:19<00:04, 225.96 examples/s]Tokenizing train dataset:  93%|█████████▎| 6200/6690 [00:19<00:02, 234.80 examples/s]Tokenizing train dataset:  92%|█████████▏| 6179/6690 [00:19<00:02, 211.66 examples/s]Tokenizing train dataset:  87%|████████▋ | 5791/6690 [00:19<00:04, 197.90 examples/s]Tokenizing train dataset:  93%|█████████▎| 6238/6690 [00:19<00:01, 234.49 examples/s]Tokenizing train dataset:  93%|█████████▎| 6212/6690 [00:19<00:02, 231.31 examples/s]Tokenizing train dataset:  87%|████████▋ | 5825/6690 [00:20<00:03, 222.39 examples/s]Tokenizing train dataset:  94%|█████████▎| 6269/6690 [00:20<00:01, 245.81 examples/s]Tokenizing train dataset:  94%|█████████▍| 6300/6690 [00:20<00:01, 257.91 examples/s]Tokenizing train dataset:  94%|█████████▎| 6258/6690 [00:19<00:01, 249.84 examples/s]Tokenizing train dataset:  88%|████████▊ | 5867/6690 [00:20<00:03, 231.40 examples/s]Tokenizing train dataset:  95%|█████████▍| 6338/6690 [00:20<00:01, 283.38 examples/s]Tokenizing train dataset:  94%|█████████▍| 6303/6690 [00:20<00:01, 289.12 examples/s]Tokenizing train dataset:  88%|████████▊ | 5915/6690 [00:20<00:02, 278.71 examples/s]Tokenizing train dataset:  95%|█████████▌| 6380/6690 [00:20<00:01, 236.43 examples/s]Tokenizing train dataset:  95%|█████████▍| 6344/6690 [00:20<00:01, 188.63 examples/s]Tokenizing train dataset:  89%|████████▉ | 5957/6690 [00:20<00:03, 192.63 examples/s]Tokenizing train dataset:  96%|█████████▌| 6431/6690 [00:20<00:01, 248.46 examples/s]Tokenizing train dataset:  95%|█████████▌| 6379/6690 [00:20<00:01, 213.26 examples/s]Tokenizing train dataset:  90%|████████▉ | 5993/6690 [00:20<00:03, 218.32 examples/s]Tokenizing train dataset:  97%|█████████▋| 6473/6690 [00:20<00:00, 280.40 examples/s]Tokenizing train dataset:  96%|█████████▌| 6431/6690 [00:20<00:01, 212.72 examples/s]Tokenizing train dataset:  90%|█████████ | 6035/6690 [00:21<00:03, 197.39 examples/s]Tokenizing train dataset:  97%|█████████▋| 6518/6690 [00:21<00:00, 235.57 examples/s]Tokenizing train dataset:  97%|█████████▋| 6473/6690 [00:20<00:00, 246.86 examples/s]Tokenizing train dataset:  91%|█████████ | 6071/6690 [00:21<00:02, 223.99 examples/s]Tokenizing train dataset:  98%|█████████▊| 6552/6690 [00:21<00:00, 252.73 examples/s]Tokenizing train dataset:  97%|█████████▋| 6510/6690 [00:21<00:00, 271.04 examples/s]Tokenizing train dataset:  91%|█████████▏| 6121/6690 [00:21<00:02, 277.73 examples/s]Tokenizing train dataset:  99%|█████████▊| 6590/6690 [00:21<00:00, 278.64 examples/s]Tokenizing train dataset:  98%|█████████▊| 6546/6690 [00:21<00:00, 289.38 examples/s]Tokenizing train dataset:  92%|█████████▏| 6161/6690 [00:21<00:01, 302.20 examples/s]Tokenizing train dataset:  99%|█████████▉| 6643/6690 [00:21<00:00, 298.67 examples/s]Tokenizing train dataset:  98%|█████████▊| 6587/6690 [00:21<00:00, 315.12 examples/s]Tokenizing train dataset:  93%|█████████▎| 6211/6690 [00:21<00:01, 310.69 examples/s]Tokenizing train dataset: 100%|█████████▉| 6676/6690 [00:21<00:00, 302.67 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:21<00:00, 310.83 examples/s]
Tokenizing train dataset:  99%|█████████▉| 6628/6690 [00:21<00:00, 297.98 examples/s]Tokenizing train dataset:  94%|█████████▎| 6259/6690 [00:21<00:01, 310.00 examples/s]Tokenizing train dataset: 100%|█████████▉| 6670/6690 [00:21<00:00, 194.76 examples/s]Tokenizing train dataset:  94%|█████████▍| 6306/6690 [00:22<00:01, 228.59 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:21<00:00, 306.19 examples/s]
Tokenizing train dataset:  95%|█████████▍| 6339/6690 [00:22<00:01, 245.23 examples/s]Tokenizing train dataset:  95%|█████████▌| 6385/6690 [00:22<00:01, 260.15 examples/s]Tokenizing train dataset:  96%|█████████▌| 6432/6690 [00:22<00:00, 300.94 examples/s]Tokenizing train dataset:  97%|█████████▋| 6471/6690 [00:22<00:00, 319.03 examples/s]Tokenizing train dataset:  97%|█████████▋| 6512/6690 [00:22<00:00, 252.00 examples/s]Tokenizing train dataset:  98%|█████████▊| 6554/6690 [00:23<00:00, 218.65 examples/s]Tokenizing train dataset:  99%|█████████▊| 6598/6690 [00:23<00:00, 230.67 examples/s]Tokenizing train dataset:  99%|█████████▉| 6630/6690 [00:23<00:00, 244.41 examples/s]Tokenizing train dataset: 100%|█████████▉| 6659/6690 [00:23<00:00, 252.89 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:23<00:00, 258.20 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:23<00:00, 284.21 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5513.17 examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 553/953 [00:00<00:00, 5467.86 examples/s]Extracting prompt in eval dataset:  57%|█████▋    | 540/953 [00:00<00:00, 5316.34 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3271.39 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3128.31 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3013.48 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  33%|███▎      | 310/953 [00:00<00:00, 3066.85 examples/s]Applying chat template to eval dataset:  33%|███▎      | 310/953 [00:00<00:00, 3071.21 examples/s]Applying chat template to eval dataset:  65%|██████▍   | 619/953 [00:00<00:00, 3075.13 examples/s]Applying chat template to eval dataset:  65%|██████▌   | 620/953 [00:00<00:00, 3083.03 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2931.11 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2988.71 examples/s]Applying chat template to eval dataset:  31%|███▏      | 300/953 [00:00<00:00, 2962.02 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2031.70 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2072.87 examples/s]
Applying chat template to eval dataset:  65%|██████▍   | 616/953 [00:00<00:00, 1751.40 examples/s]Applying chat template to eval dataset:  96%|█████████▌| 913/953 [00:00<00:00, 2142.73 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2023.10 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 29/953 [00:00<00:03, 279.40 examples/s]Tokenizing eval dataset:   3%|▎         | 29/953 [00:00<00:03, 280.40 examples/s]Tokenizing eval dataset:   6%|▌         | 59/953 [00:00<00:04, 214.89 examples/s]Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:04, 210.56 examples/s]Tokenizing eval dataset:  10%|▉         | 93/953 [00:00<00:03, 216.88 examples/s]Tokenizing eval dataset:  10%|▉         | 93/953 [00:00<00:03, 215.79 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:  12%|█▏        | 116/953 [00:00<00:03, 215.38 examples/s]Tokenizing eval dataset:  12%|█▏        | 116/953 [00:00<00:03, 215.09 examples/s]Tokenizing eval dataset:   2%|▏         | 23/953 [00:00<00:04, 219.84 examples/s]Tokenizing eval dataset:  15%|█▍        | 139/953 [00:00<00:05, 149.74 examples/s]Tokenizing eval dataset:  15%|█▍        | 139/953 [00:00<00:05, 147.25 examples/s]Tokenizing eval dataset:   5%|▌         | 48/953 [00:00<00:08, 100.86 examples/s]Tokenizing eval dataset:  17%|█▋        | 162/953 [00:00<00:05, 142.60 examples/s]Tokenizing eval dataset:  17%|█▋        | 163/953 [00:00<00:05, 145.83 examples/s]Tokenizing eval dataset:   7%|▋         | 71/953 [00:00<00:07, 116.80 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:01<00:05, 145.78 examples/s]Tokenizing eval dataset:   9%|▉         | 86/953 [00:00<00:07, 123.14 examples/s]Tokenizing eval dataset:  19%|█▉        | 182/953 [00:01<00:06, 122.14 examples/s]Tokenizing eval dataset:  22%|██▏       | 207/953 [00:01<00:04, 153.22 examples/s]Tokenizing eval dataset:  11%|█         | 102/953 [00:00<00:06, 130.19 examples/s]Tokenizing eval dataset:  21%|██        | 198/953 [00:01<00:05, 128.63 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:01<00:03, 186.88 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:01<00:07, 112.42 examples/s]Tokenizing eval dataset:  28%|██▊       | 266/953 [00:01<00:04, 160.46 examples/s]Tokenizing eval dataset:  14%|█▍        | 133/953 [00:01<00:07, 115.54 examples/s]Tokenizing eval dataset:  24%|██▍       | 229/953 [00:01<00:06, 117.28 examples/s]Tokenizing eval dataset:  33%|███▎      | 317/953 [00:01<00:02, 232.84 examples/s]Tokenizing eval dataset:  16%|█▌        | 150/953 [00:01<00:06, 125.97 examples/s]Tokenizing eval dataset:  28%|██▊       | 265/953 [00:01<00:04, 159.13 examples/s]Tokenizing eval dataset:  38%|███▊      | 363/953 [00:01<00:02, 284.35 examples/s]Tokenizing eval dataset:  18%|█▊        | 167/953 [00:01<00:05, 134.88 examples/s]Tokenizing eval dataset:  32%|███▏      | 303/953 [00:01<00:03, 202.57 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:01<00:02, 235.42 examples/s]Tokenizing eval dataset:  44%|████▍     | 419/953 [00:01<00:01, 311.00 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:05, 129.41 examples/s]Tokenizing eval dataset:  40%|████      | 385/953 [00:02<00:01, 284.79 examples/s]Tokenizing eval dataset:  49%|████▉     | 470/953 [00:02<00:01, 356.34 examples/s]Tokenizing eval dataset:  54%|█████▍    | 518/953 [00:02<00:01, 385.78 examples/s]Tokenizing eval dataset:  46%|████▋     | 442/953 [00:02<00:01, 354.53 examples/s]Tokenizing eval dataset:  22%|██▏       | 208/953 [00:01<00:05, 130.08 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:01<00:05, 127.61 examples/s]Tokenizing eval dataset:  61%|██████▏   | 585/953 [00:02<00:00, 397.63 examples/s]Tokenizing eval dataset:  52%|█████▏    | 497/953 [00:02<00:01, 350.62 examples/s]Tokenizing eval dataset:  28%|██▊       | 265/953 [00:01<00:03, 195.14 examples/s]Tokenizing eval dataset:  31%|███       | 292/953 [00:02<00:03, 190.33 examples/s]Tokenizing eval dataset:  58%|█████▊    | 553/953 [00:02<00:01, 286.40 examples/s]Tokenizing eval dataset:  68%|██████▊   | 644/953 [00:02<00:00, 316.45 examples/s]Tokenizing eval dataset:  34%|███▍      | 325/953 [00:02<00:02, 220.45 examples/s]Tokenizing eval dataset:  38%|███▊      | 358/953 [00:02<00:02, 246.86 examples/s]Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:02<00:01, 288.09 examples/s]Tokenizing eval dataset:  73%|███████▎  | 697/953 [00:02<00:00, 300.48 examples/s]Tokenizing eval dataset:  42%|████▏     | 399/953 [00:02<00:01, 290.00 examples/s]Tokenizing eval dataset:  69%|██████▉   | 657/953 [00:02<00:00, 326.52 examples/s]Tokenizing eval dataset:  78%|███████▊  | 744/953 [00:02<00:00, 326.09 examples/s]Tokenizing eval dataset:  48%|████▊     | 456/953 [00:02<00:01, 363.88 examples/s]Tokenizing eval dataset:  74%|███████▎  | 702/953 [00:02<00:00, 349.32 examples/s]Tokenizing eval dataset:  83%|████████▎ | 787/953 [00:02<00:00, 346.70 examples/s]Tokenizing eval dataset:  52%|█████▏    | 496/953 [00:02<00:01, 371.39 examples/s]Tokenizing eval dataset:  78%|███████▊  | 744/953 [00:03<00:00, 361.92 examples/s]Tokenizing eval dataset:  87%|████████▋ | 826/953 [00:03<00:00, 354.40 examples/s]Tokenizing eval dataset:  58%|█████▊    | 556/953 [00:02<00:00, 434.96 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:03<00:00, 371.31 examples/s]Tokenizing eval dataset:  93%|█████████▎| 887/953 [00:03<00:00, 366.91 examples/s]Tokenizing eval dataset:  64%|██████▍   | 612/953 [00:02<00:00, 469.81 examples/s]Tokenizing eval dataset:  87%|████████▋ | 832/953 [00:03<00:00, 392.36 examples/s]Tokenizing eval dataset:  98%|█████████▊| 933/953 [00:03<00:00, 386.23 examples/s]Tokenizing eval dataset:  70%|██████▉   | 665/953 [00:02<00:00, 482.21 examples/s]Tokenizing eval dataset:  92%|█████████▏| 881/953 [00:03<00:00, 413.40 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 281.63 examples/s]
Tokenizing eval dataset:  75%|███████▍  | 714/953 [00:02<00:00, 480.19 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  97%|█████████▋| 928/953 [00:03<00:00, 427.02 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 267.50 examples/s]
Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:03<00:00, 469.93 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  89%|████████▉ | 852/953 [00:03<00:00, 381.12 examples/s]Tokenizing eval dataset:  94%|█████████▍| 894/953 [00:03<00:00, 389.10 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:03<00:00, 357.36 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 260.66 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.7615292072296143 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4722201824188232 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.5004982948303223 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.733765125274658 seconds
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.7
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
  0%|          | 0/1674 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/1674 [00:13<6:07:10, 13.17s/it]  0%|          | 2/1674 [00:16<3:19:55,  7.17s/it]  0%|          | 3/1674 [00:19<2:33:05,  5.50s/it]  0%|          | 4/1674 [00:23<2:12:48,  4.77s/it]  0%|          | 5/1674 [00:26<1:57:35,  4.23s/it]  0%|          | 6/1674 [00:29<1:48:32,  3.90s/it]  0%|          | 7/1674 [00:33<1:49:21,  3.94s/it]  0%|          | 8/1674 [00:36<1:34:46,  3.41s/it]  1%|          | 9/1674 [00:40<1:39:33,  3.59s/it]  1%|          | 10/1674 [00:43<1:41:24,  3.66s/it]                                                   {'loss': 0.689, 'grad_norm': 35.62937545776367, 'learning_rate': 1.076555023923445e-08, 'rewards/chosen': 0.0020385743118822575, 'rewards/rejected': -0.009241485968232155, 'rewards/accuracies': 0.3583333492279053, 'rewards/margins': 0.011279297061264515, 'logps/chosen': -113.9000015258789, 'logps/rejected': -126.3499984741211, 'logits/chosen': -7.815625190734863, 'logits/rejected': -7.800000190734863, 'epoch': 0.02}
  1%|          | 10/1674 [00:44<1:41:24,  3.66s/it]  1%|          | 11/1674 [00:47<1:42:27,  3.70s/it]  1%|          | 12/1674 [00:50<1:34:45,  3.42s/it]  1%|          | 13/1674 [00:54<1:38:47,  3.57s/it]  1%|          | 14/1674 [00:58<1:44:27,  3.78s/it]  1%|          | 15/1674 [01:02<1:45:02,  3.80s/it]  1%|          | 16/1674 [01:05<1:38:41,  3.57s/it]  1%|          | 17/1674 [01:09<1:39:29,  3.60s/it]  1%|          | 18/1674 [01:13<1:42:16,  3.71s/it]  1%|          | 19/1674 [01:15<1:31:46,  3.33s/it]  1%|          | 20/1674 [01:19<1:37:04,  3.52s/it]                                                   {'loss': 0.7112, 'grad_norm': 35.65406799316406, 'learning_rate': 2.2727272727272725e-08, 'rewards/chosen': 0.00915044266730547, 'rewards/rejected': 0.02467041090130806, 'rewards/accuracies': 0.5000000596046448, 'rewards/margins': -0.01541748084127903, 'logps/chosen': -146.5500030517578, 'logps/rejected': -172.0500030517578, 'logits/chosen': -7.853125095367432, 'logits/rejected': -7.6875, 'epoch': 0.04}
  1%|          | 20/1674 [01:19<1:37:04,  3.52s/it]  1%|▏         | 21/1674 [01:23<1:41:26,  3.68s/it]  1%|▏         | 22/1674 [01:26<1:34:06,  3.42s/it]  1%|▏         | 23/1674 [01:29<1:27:25,  3.18s/it]  1%|▏         | 24/1674 [01:33<1:35:52,  3.49s/it]  1%|▏         | 25/1674 [01:37<1:40:46,  3.67s/it]  2%|▏         | 26/1674 [01:39<1:29:04,  3.24s/it]  2%|▏         | 27/1674 [01:42<1:26:54,  3.17s/it]  2%|▏         | 28/1674 [01:46<1:33:15,  3.40s/it]  2%|▏         | 29/1674 [01:48<1:25:04,  3.10s/it]  2%|▏         | 30/1674 [01:52<1:27:18,  3.19s/it]                                                   {'loss': 0.6875, 'grad_norm': 35.26484298706055, 'learning_rate': 3.4688995215311006e-08, 'rewards/chosen': 0.0054534911178052425, 'rewards/rejected': -0.0071624754928052425, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.012638854794204235, 'logps/chosen': -153.3000030517578, 'logps/rejected': -182.4499969482422, 'logits/chosen': -7.690625190734863, 'logits/rejected': -7.709374904632568, 'epoch': 0.05}
  2%|▏         | 30/1674 [01:52<1:27:18,  3.19s/it]  2%|▏         | 31/1674 [01:55<1:24:16,  3.08s/it]  2%|▏         | 32/1674 [01:59<1:32:35,  3.38s/it]  2%|▏         | 33/1674 [02:02<1:32:43,  3.39s/it]  2%|▏         | 34/1674 [02:06<1:35:50,  3.51s/it]  2%|▏         | 35/1674 [02:08<1:27:34,  3.21s/it]  2%|▏         | 36/1674 [02:12<1:34:06,  3.45s/it]  2%|▏         | 37/1674 [02:15<1:27:39,  3.21s/it]  2%|▏         | 38/1674 [02:19<1:34:39,  3.47s/it]  2%|▏         | 39/1674 [02:23<1:33:57,  3.45s/it]  2%|▏         | 40/1674 [02:26<1:31:00,  3.34s/it]                                                   {'loss': 0.7018, 'grad_norm': 34.1948356628418, 'learning_rate': 4.6650717703349284e-08, 'rewards/chosen': -0.0002593994140625, 'rewards/rejected': 0.00914688128978014, 'rewards/accuracies': 0.4333333373069763, 'rewards/margins': -0.00935211218893528, 'logps/chosen': -103.5250015258789, 'logps/rejected': -129.27499389648438, 'logits/chosen': -7.693749904632568, 'logits/rejected': -7.471875190734863, 'epoch': 0.07}
  2%|▏         | 40/1674 [02:26<1:31:00,  3.34s/it]  2%|▏         | 41/1674 [02:29<1:29:30,  3.29s/it]  3%|▎         | 42/1674 [02:33<1:37:06,  3.57s/it]  3%|▎         | 43/1674 [02:36<1:33:32,  3.44s/it]  3%|▎         | 44/1674 [02:40<1:39:03,  3.65s/it]  3%|▎         | 45/1674 [02:43<1:33:02,  3.43s/it]  3%|▎         | 46/1674 [02:46<1:30:44,  3.34s/it]  3%|▎         | 47/1674 [02:49<1:25:07,  3.14s/it]  3%|▎         | 48/1674 [02:52<1:22:12,  3.03s/it]  3%|▎         | 49/1674 [02:55<1:20:29,  2.97s/it]  3%|▎         | 50/1674 [02:57<1:16:47,  2.84s/it]                                                   {'loss': 0.6892, 'grad_norm': 27.68714141845703, 'learning_rate': 5.8612440191387555e-08, 'rewards/chosen': 0.00831527728587389, 'rewards/rejected': -0.0028045654762536287, 'rewards/accuracies': 0.44166669249534607, 'rewards/margins': 0.011126709170639515, 'logps/chosen': -141.35000610351562, 'logps/rejected': -175.5, 'logits/chosen': -7.971875190734863, 'logits/rejected': -7.840624809265137, 'epoch': 0.09}
  3%|▎         | 50/1674 [02:57<1:16:47,  2.84s/it]  3%|▎         | 51/1674 [03:01<1:25:47,  3.17s/it]  3%|▎         | 52/1674 [03:05<1:33:44,  3.47s/it]  3%|▎         | 53/1674 [03:08<1:25:34,  3.17s/it]  3%|▎         | 54/1674 [03:11<1:27:16,  3.23s/it]  3%|▎         | 55/1674 [03:14<1:26:26,  3.20s/it]  3%|▎         | 56/1674 [03:18<1:32:46,  3.44s/it]  3%|▎         | 57/1674 [03:21<1:26:14,  3.20s/it]  3%|▎         | 58/1674 [03:24<1:24:02,  3.12s/it]  4%|▎         | 59/1674 [03:28<1:30:10,  3.35s/it]  4%|▎         | 60/1674 [03:31<1:30:22,  3.36s/it]                                                   {'loss': 0.6855, 'grad_norm': 31.468725204467773, 'learning_rate': 7.057416267942583e-08, 'rewards/chosen': 0.008189392276108265, 'rewards/rejected': -0.007981491275131702, 'rewards/accuracies': 0.46666669845581055, 'rewards/margins': 0.016204070299863815, 'logps/chosen': -101.5, 'logps/rejected': -145.1999969482422, 'logits/chosen': -8.012499809265137, 'logits/rejected': -7.884375095367432, 'epoch': 0.11}
  4%|▎         | 60/1674 [03:31<1:30:22,  3.36s/it]  4%|▎         | 61/1674 [03:35<1:31:58,  3.42s/it]  4%|▎         | 62/1674 [03:39<1:35:13,  3.54s/it]  4%|▍         | 63/1674 [03:41<1:28:23,  3.29s/it]  4%|▍         | 64/1674 [03:44<1:24:50,  3.16s/it]  4%|▍         | 65/1674 [03:47<1:23:02,  3.10s/it]  4%|▍         | 66/1674 [03:51<1:26:47,  3.24s/it]  4%|▍         | 67/1674 [03:55<1:32:16,  3.45s/it]  4%|▍         | 68/1674 [03:58<1:33:11,  3.48s/it]  4%|▍         | 69/1674 [04:01<1:30:46,  3.39s/it]  4%|▍         | 70/1674 [04:05<1:32:36,  3.46s/it]                                                   {'loss': 0.6964, 'grad_norm': 39.72307586669922, 'learning_rate': 8.253588516746412e-08, 'rewards/chosen': -0.003918456844985485, 'rewards/rejected': 0.0034215301275253296, 'rewards/accuracies': 0.38333335518836975, 'rewards/margins': -0.0073699951171875, 'logps/chosen': -109.05000305175781, 'logps/rejected': -129.60000610351562, 'logits/chosen': -7.934374809265137, 'logits/rejected': -7.659375190734863, 'epoch': 0.13}
  4%|▍         | 70/1674 [04:05<1:32:36,  3.46s/it]  4%|▍         | 71/1674 [04:09<1:40:02,  3.74s/it]  4%|▍         | 72/1674 [04:12<1:34:45,  3.55s/it]  4%|▍         | 73/1674 [04:16<1:34:23,  3.54s/it]  4%|▍         | 74/1674 [04:20<1:39:01,  3.71s/it]  4%|▍         | 75/1674 [04:24<1:43:39,  3.89s/it]  5%|▍         | 76/1674 [04:27<1:32:52,  3.49s/it]  5%|▍         | 77/1674 [04:31<1:37:39,  3.67s/it]  5%|▍         | 78/1674 [04:35<1:38:20,  3.70s/it]  5%|▍         | 79/1674 [04:38<1:35:22,  3.59s/it]  5%|▍         | 80/1674 [04:42<1:36:16,  3.62s/it]                                                   {'loss': 0.6943, 'grad_norm': 37.286415100097656, 'learning_rate': 9.449760765550238e-08, 'rewards/chosen': -0.009220886044204235, 'rewards/rejected': -0.009930419735610485, 'rewards/accuracies': 0.4166666567325592, 'rewards/margins': 0.0007230758783407509, 'logps/chosen': -99.2249984741211, 'logps/rejected': -138.1999969482422, 'logits/chosen': -7.837500095367432, 'logits/rejected': -7.59375, 'epoch': 0.14}
  5%|▍         | 80/1674 [04:42<1:36:16,  3.62s/it]  5%|▍         | 81/1674 [04:46<1:39:15,  3.74s/it]  5%|▍         | 82/1674 [04:49<1:34:27,  3.56s/it]  5%|▍         | 83/1674 [04:52<1:33:20,  3.52s/it]  5%|▌         | 84/1674 [04:55<1:26:50,  3.28s/it]  5%|▌         | 85/1674 [04:58<1:25:01,  3.21s/it]  5%|▌         | 86/1674 [05:01<1:25:18,  3.22s/it]  5%|▌         | 87/1674 [05:04<1:23:54,  3.17s/it]  5%|▌         | 88/1674 [05:08<1:23:09,  3.15s/it]  5%|▌         | 89/1674 [05:11<1:26:20,  3.27s/it]  5%|▌         | 90/1674 [05:15<1:31:53,  3.48s/it]                                                   {'loss': 0.6809, 'grad_norm': 35.998748779296875, 'learning_rate': 1.0645933014354067e-07, 'rewards/chosen': 0.02926788292825222, 'rewards/rejected': -0.01371154747903347, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.04293213039636612, 'logps/chosen': -187.85000610351562, 'logps/rejected': -224.3000030517578, 'logits/chosen': -7.753125190734863, 'logits/rejected': -7.559374809265137, 'epoch': 0.16}
  5%|▌         | 90/1674 [05:15<1:31:53,  3.48s/it]  5%|▌         | 91/1674 [05:19<1:34:02,  3.56s/it]  5%|▌         | 92/1674 [05:23<1:37:00,  3.68s/it]  6%|▌         | 93/1674 [05:27<1:40:08,  3.80s/it]  6%|▌         | 94/1674 [05:29<1:27:23,  3.32s/it]  6%|▌         | 95/1674 [05:33<1:33:49,  3.57s/it]  6%|▌         | 96/1674 [05:37<1:36:33,  3.67s/it]  6%|▌         | 97/1674 [05:41<1:35:52,  3.65s/it]  6%|▌         | 98/1674 [05:44<1:35:31,  3.64s/it]  6%|▌         | 99/1674 [05:48<1:37:28,  3.71s/it]  6%|▌         | 100/1674 [05:51<1:29:37,  3.42s/it]                                                    {'loss': 0.6805, 'grad_norm': 28.889057159423828, 'learning_rate': 1.1842105263157894e-07, 'rewards/chosen': 0.006924438290297985, 'rewards/rejected': -0.02480774000287056, 'rewards/accuracies': 0.40833330154418945, 'rewards/margins': 0.03175048902630806, 'logps/chosen': -142.89999389648438, 'logps/rejected': -159.1999969482422, 'logits/chosen': -7.856249809265137, 'logits/rejected': -7.737500190734863, 'epoch': 0.18}
  6%|▌         | 100/1674 [05:51<1:29:37,  3.42s/it]  6%|▌         | 101/1674 [05:55<1:32:17,  3.52s/it]  6%|▌         | 102/1674 [05:58<1:32:50,  3.54s/it]  6%|▌         | 103/1674 [06:02<1:34:33,  3.61s/it]  6%|▌         | 104/1674 [06:05<1:32:30,  3.54s/it]  6%|▋         | 105/1674 [06:09<1:34:46,  3.62s/it]  6%|▋         | 106/1674 [06:12<1:29:35,  3.43s/it]  6%|▋         | 107/1674 [06:16<1:28:23,  3.38s/it]  6%|▋         | 108/1674 [06:18<1:20:39,  3.09s/it]  7%|▋         | 109/1674 [06:21<1:21:48,  3.14s/it]  7%|▋         | 110/1674 [06:25<1:28:11,  3.38s/it]                                                    {'loss': 0.692, 'grad_norm': 34.620052337646484, 'learning_rate': 1.3038277511961721e-07, 'rewards/chosen': -0.001300811767578125, 'rewards/rejected': -0.0074829100631177425, 'rewards/accuracies': 0.4333333373069763, 'rewards/margins': 0.0061706542037427425, 'logps/chosen': -97.5999984741211, 'logps/rejected': -122.25, 'logits/chosen': -7.846875190734863, 'logits/rejected': -7.631249904632568, 'epoch': 0.2}
  7%|▋         | 110/1674 [06:25<1:28:11,  3.38s/it]  7%|▋         | 111/1674 [06:29<1:32:32,  3.55s/it]  7%|▋         | 112/1674 [06:32<1:29:53,  3.45s/it]  7%|▋         | 113/1674 [06:35<1:24:41,  3.26s/it]  7%|▋         | 114/1674 [06:39<1:27:29,  3.37s/it]  7%|▋         | 115/1674 [06:43<1:32:16,  3.55s/it]  7%|▋         | 116/1674 [06:45<1:23:21,  3.21s/it]  7%|▋         | 117/1674 [06:49<1:27:44,  3.38s/it]  7%|▋         | 118/1674 [06:52<1:25:51,  3.31s/it]  7%|▋         | 119/1674 [06:55<1:21:39,  3.15s/it]  7%|▋         | 120/1674 [06:59<1:28:20,  3.41s/it]                                                    {'loss': 0.6983, 'grad_norm': 65.51432800292969, 'learning_rate': 1.4234449760765548e-07, 'rewards/chosen': -0.006771850399672985, 'rewards/rejected': -0.0009582519414834678, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.00579147320240736, 'logps/chosen': -150.1999969482422, 'logps/rejected': -163.89999389648438, 'logits/chosen': -7.846875190734863, 'logits/rejected': -7.643750190734863, 'epoch': 0.22}
  7%|▋         | 120/1674 [06:59<1:28:20,  3.41s/it]  7%|▋         | 121/1674 [07:03<1:35:06,  3.67s/it]  7%|▋         | 122/1674 [07:06<1:27:13,  3.37s/it]  7%|▋         | 123/1674 [07:09<1:24:10,  3.26s/it]  7%|▋         | 124/1674 [07:12<1:25:58,  3.33s/it]  7%|▋         | 125/1674 [07:17<1:34:49,  3.67s/it]  8%|▊         | 126/1674 [07:19<1:27:09,  3.38s/it]  8%|▊         | 127/1674 [07:22<1:21:36,  3.17s/it]  8%|▊         | 128/1674 [07:26<1:27:30,  3.40s/it]  8%|▊         | 129/1674 [07:30<1:29:37,  3.48s/it]  8%|▊         | 130/1674 [07:33<1:31:06,  3.54s/it]                                                    {'loss': 0.6893, 'grad_norm': 24.36069107055664, 'learning_rate': 1.5430622009569377e-07, 'rewards/chosen': 0.00666046142578125, 'rewards/rejected': -0.00582199078053236, 'rewards/accuracies': 0.48333340883255005, 'rewards/margins': 0.012484741397202015, 'logps/chosen': -142.75, 'logps/rejected': -165.64999389648438, 'logits/chosen': -7.662499904632568, 'logits/rejected': -7.368750095367432, 'epoch': 0.23}
  8%|▊         | 130/1674 [07:34<1:31:06,  3.54s/it]  8%|▊         | 131/1674 [07:37<1:33:03,  3.62s/it]  8%|▊         | 132/1674 [07:41<1:35:16,  3.71s/it]  8%|▊         | 133/1674 [07:45<1:33:49,  3.65s/it]  8%|▊         | 134/1674 [07:48<1:30:10,  3.51s/it]  8%|▊         | 135/1674 [07:51<1:29:04,  3.47s/it]  8%|▊         | 136/1674 [07:55<1:34:36,  3.69s/it]  8%|▊         | 137/1674 [07:59<1:37:42,  3.81s/it]  8%|▊         | 138/1674 [08:03<1:35:41,  3.74s/it]  8%|▊         | 139/1674 [08:06<1:29:43,  3.51s/it]  8%|▊         | 140/1674 [08:09<1:25:53,  3.36s/it]                                                    {'loss': 0.7076, 'grad_norm': 35.628719329833984, 'learning_rate': 1.6626794258373206e-07, 'rewards/chosen': 0.00792694091796875, 'rewards/rejected': 0.00972595252096653, 'rewards/accuracies': 0.5083333253860474, 'rewards/margins': -0.0020095824729651213, 'logps/chosen': -150.8000030517578, 'logps/rejected': -184.6999969482422, 'logits/chosen': -7.778124809265137, 'logits/rejected': -7.493750095367432, 'epoch': 0.25}
  8%|▊         | 140/1674 [08:09<1:25:53,  3.36s/it]  8%|▊         | 141/1674 [08:13<1:31:25,  3.58s/it]  8%|▊         | 142/1674 [08:16<1:29:00,  3.49s/it]  9%|▊         | 143/1674 [08:20<1:31:50,  3.60s/it]  9%|▊         | 144/1674 [08:24<1:29:10,  3.50s/it]  9%|▊         | 145/1674 [08:27<1:32:24,  3.63s/it]  9%|▊         | 146/1674 [08:30<1:26:06,  3.38s/it]  9%|▉         | 147/1674 [08:33<1:22:53,  3.26s/it]  9%|▉         | 148/1674 [08:36<1:16:04,  2.99s/it]  9%|▉         | 149/1674 [08:39<1:16:37,  3.01s/it]  9%|▉         | 150/1674 [08:41<1:12:06,  2.84s/it]                                                    {'loss': 0.6837, 'grad_norm': 34.61823272705078, 'learning_rate': 1.7822966507177032e-07, 'rewards/chosen': 0.0022262572310864925, 'rewards/rejected': -0.02242889441549778, 'rewards/accuracies': 0.4833333492279053, 'rewards/margins': 0.02473398670554161, 'logps/chosen': -148.39999389648438, 'logps/rejected': -170.75, 'logits/chosen': -7.737500190734863, 'logits/rejected': -7.609375, 'epoch': 0.27}
  9%|▉         | 150/1674 [08:41<1:12:06,  2.84s/it]  9%|▉         | 151/1674 [08:44<1:15:09,  2.96s/it]  9%|▉         | 152/1674 [08:47<1:14:51,  2.95s/it]  9%|▉         | 153/1674 [08:51<1:19:43,  3.15s/it]  9%|▉         | 154/1674 [08:55<1:25:40,  3.38s/it]  9%|▉         | 155/1674 [08:58<1:26:44,  3.43s/it]  9%|▉         | 156/1674 [09:02<1:29:57,  3.56s/it]  9%|▉         | 157/1674 [09:05<1:26:07,  3.41s/it]  9%|▉         | 158/1674 [09:08<1:21:11,  3.21s/it]  9%|▉         | 159/1674 [09:11<1:22:22,  3.26s/it] 10%|▉         | 160/1674 [09:15<1:28:33,  3.51s/it]                                                    {'loss': 0.6901, 'grad_norm': 65.35233306884766, 'learning_rate': 1.901913875598086e-07, 'rewards/chosen': -0.01610260084271431, 'rewards/rejected': -0.024839401245117188, 'rewards/accuracies': 0.46666669845581055, 'rewards/margins': 0.008708953857421875, 'logps/chosen': -149.6999969482422, 'logps/rejected': -169.47500610351562, 'logits/chosen': -7.753125190734863, 'logits/rejected': -7.609375, 'epoch': 0.29}
 10%|▉         | 160/1674 [09:16<1:28:33,  3.51s/it] 10%|▉         | 161/1674 [09:18<1:22:06,  3.26s/it] 10%|▉         | 162/1674 [09:22<1:27:18,  3.46s/it] 10%|▉         | 163/1674 [09:26<1:27:00,  3.45s/it] 10%|▉         | 164/1674 [09:29<1:26:18,  3.43s/it] 10%|▉         | 165/1674 [09:32<1:22:11,  3.27s/it] 10%|▉         | 166/1674 [09:35<1:21:33,  3.24s/it] 10%|▉         | 167/1674 [09:39<1:26:04,  3.43s/it] 10%|█         | 168/1674 [09:42<1:23:46,  3.34s/it] 10%|█         | 169/1674 [09:45<1:19:33,  3.17s/it] 10%|█         | 170/1674 [09:49<1:28:45,  3.54s/it]                                                    {'loss': 0.6938, 'grad_norm': 36.81425857543945, 'learning_rate': 2.0215311004784688e-07, 'rewards/chosen': -0.02166442945599556, 'rewards/rejected': -0.02121734619140625, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.0004394531133584678, 'logps/chosen': -103.5, 'logps/rejected': -118.25, 'logits/chosen': -7.800000190734863, 'logits/rejected': -7.762499809265137, 'epoch': 0.3}
 10%|█         | 170/1674 [09:49<1:28:45,  3.54s/it] 10%|█         | 171/1674 [09:53<1:33:21,  3.73s/it] 10%|█         | 172/1674 [09:56<1:26:56,  3.47s/it] 10%|█         | 173/1674 [10:00<1:29:44,  3.59s/it] 10%|█         | 174/1674 [10:04<1:33:51,  3.75s/it] 10%|█         | 175/1674 [10:07<1:28:31,  3.54s/it] 11%|█         | 176/1674 [10:11<1:30:29,  3.62s/it] 11%|█         | 177/1674 [10:14<1:22:39,  3.31s/it] 11%|█         | 178/1674 [10:18<1:29:02,  3.57s/it] 11%|█         | 179/1674 [10:21<1:29:18,  3.58s/it] 11%|█         | 180/1674 [10:26<1:34:24,  3.79s/it]                                                    {'loss': 0.6772, 'grad_norm': 35.047027587890625, 'learning_rate': 2.1411483253588517e-07, 'rewards/chosen': -0.0049118041060864925, 'rewards/rejected': -0.0391845703125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.03436279296875, 'logps/chosen': -113.25, 'logps/rejected': -140.60000610351562, 'logits/chosen': -8.078125, 'logits/rejected': -7.875, 'epoch': 0.32}
 11%|█         | 180/1674 [10:26<1:34:24,  3.79s/it] 11%|█         | 181/1674 [10:29<1:30:45,  3.65s/it] 11%|█         | 182/1674 [10:33<1:32:22,  3.72s/it] 11%|█         | 183/1674 [10:36<1:25:39,  3.45s/it] 11%|█         | 184/1674 [10:39<1:24:04,  3.39s/it] 11%|█         | 185/1674 [10:42<1:24:59,  3.42s/it] 11%|█         | 186/1674 [10:46<1:28:37,  3.57s/it] 11%|█         | 187/1674 [10:49<1:24:35,  3.41s/it] 11%|█         | 188/1674 [10:53<1:28:31,  3.57s/it] 11%|█▏        | 189/1674 [10:57<1:26:32,  3.50s/it] 11%|█▏        | 190/1674 [11:00<1:26:30,  3.50s/it]                                                    {'loss': 0.6712, 'grad_norm': 30.38412857055664, 'learning_rate': 2.2607655502392343e-07, 'rewards/chosen': -0.0019668578170239925, 'rewards/rejected': -0.04990234225988388, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.04793090745806694, 'logps/chosen': -109.55000305175781, 'logps/rejected': -157.6999969482422, 'logits/chosen': -7.856249809265137, 'logits/rejected': -7.618750095367432, 'epoch': 0.34}
 11%|█▏        | 190/1674 [11:00<1:26:30,  3.50s/it] 11%|█▏        | 191/1674 [11:04<1:29:16,  3.61s/it] 11%|█▏        | 192/1674 [11:07<1:27:30,  3.54s/it] 12%|█▏        | 193/1674 [11:11<1:28:37,  3.59s/it] 12%|█▏        | 194/1674 [11:15<1:31:00,  3.69s/it] 12%|█▏        | 195/1674 [11:18<1:21:48,  3.32s/it] 12%|█▏        | 196/1674 [11:21<1:25:03,  3.45s/it] 12%|█▏        | 197/1674 [11:25<1:28:29,  3.59s/it] 12%|█▏        | 198/1674 [11:28<1:21:54,  3.33s/it] 12%|█▏        | 199/1674 [11:32<1:26:25,  3.52s/it] 12%|█▏        | 200/1674 [11:36<1:31:44,  3.73s/it]                                                    {'loss': 0.6836, 'grad_norm': 39.93299865722656, 'learning_rate': 2.380382775119617e-07, 'rewards/chosen': -0.01721496507525444, 'rewards/rejected': -0.04958496242761612, 'rewards/accuracies': 0.5916666984558105, 'rewards/margins': 0.03243102878332138, 'logps/chosen': -139.39999389648438, 'logps/rejected': -176.0500030517578, 'logits/chosen': -7.859375, 'logits/rejected': -7.650000095367432, 'epoch': 0.36}
 12%|█▏        | 200/1674 [11:36<1:31:44,  3.73s/it] 12%|█▏        | 201/1674 [11:39<1:25:33,  3.49s/it] 12%|█▏        | 202/1674 [11:43<1:29:05,  3.63s/it] 12%|█▏        | 203/1674 [11:46<1:25:41,  3.49s/it] 12%|█▏        | 204/1674 [11:49<1:23:13,  3.40s/it] 12%|█▏        | 205/1674 [11:53<1:26:05,  3.52s/it] 12%|█▏        | 206/1674 [11:56<1:19:24,  3.25s/it] 12%|█▏        | 207/1674 [12:00<1:24:12,  3.44s/it] 12%|█▏        | 208/1674 [12:03<1:25:04,  3.48s/it] 12%|█▏        | 209/1674 [12:06<1:22:25,  3.38s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<01:00,  1.29it/s][A
  4%|▍         | 3/80 [00:03<01:25,  1.11s/it][A
  5%|▌         | 4/80 [00:04<01:37,  1.28s/it][A
  6%|▋         | 5/80 [00:06<01:45,  1.41s/it][A
  8%|▊         | 6/80 [00:07<01:48,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:50,  1.51s/it][A
 10%|█         | 8/80 [00:11<01:52,  1.57s/it][A
 11%|█▏        | 9/80 [00:12<01:51,  1.58s/it][A
 12%|█▎        | 10/80 [00:14<01:53,  1.62s/it][A
 14%|█▍        | 11/80 [00:16<01:52,  1.63s/it][A
 15%|█▌        | 12/80 [00:17<01:49,  1.61s/it][A
 16%|█▋        | 13/80 [00:19<01:47,  1.60s/it][A
 18%|█▊        | 14/80 [00:21<01:48,  1.64s/it][A
 19%|█▉        | 15/80 [00:22<01:50,  1.70s/it][A
 20%|██        | 16/80 [00:24<01:46,  1.66s/it][A
 21%|██▏       | 17/80 [00:26<01:43,  1.64s/it][A
 22%|██▎       | 18/80 [00:27<01:40,  1.63s/it][A
 24%|██▍       | 19/80 [00:28<01:29,  1.47s/it][A
 25%|██▌       | 20/80 [00:30<01:24,  1.41s/it][A
 26%|██▋       | 21/80 [00:30<01:08,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:05,  1.14s/it][A
 29%|██▉       | 23/80 [00:32<01:05,  1.15s/it][A
 30%|███       | 24/80 [00:33<00:53,  1.05it/s][A
 31%|███▏      | 25/80 [00:34<00:55,  1.02s/it][A
 32%|███▎      | 26/80 [00:35<00:58,  1.09s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.03it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.02it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.10s/it][A
 39%|███▉      | 31/80 [00:41<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.06it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.15s/it][A
 42%|████▎     | 34/80 [00:44<00:56,  1.24s/it][A
 44%|████▍     | 35/80 [00:45<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.07it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.23it/s][A
 49%|████▉     | 39/80 [00:49<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:51,  1.28s/it][A
 51%|█████▏    | 41/80 [00:51<00:41,  1.07s/it][A
 52%|█████▎    | 42/80 [00:52<00:46,  1.22s/it][A
 54%|█████▍    | 43/80 [00:54<00:47,  1.28s/it][A
 55%|█████▌    | 44/80 [00:55<00:45,  1.27s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.13s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.07it/s][A
 59%|█████▉    | 47/80 [00:58<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:38,  1.19s/it][A
 61%|██████▏   | 49/80 [01:00<00:31,  1.01s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.17it/s][A
 64%|██████▍   | 51/80 [01:02<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.09s/it][A
 66%|██████▋   | 53/80 [01:04<00:26,  1.02it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:08<00:28,  1.19s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:10<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.22s/it][A
 75%|███████▌  | 60/80 [01:12<00:20,  1.04s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.18s/it][A
 78%|███████▊  | 62/80 [01:15<00:24,  1.34s/it][A
 79%|███████▉  | 63/80 [01:16<00:21,  1.26s/it][A
 80%|████████  | 64/80 [01:17<00:18,  1.15s/it][A
 81%|████████▏ | 65/80 [01:18<00:19,  1.29s/it][A
 82%|████████▎ | 66/80 [01:20<00:19,  1.37s/it][A
 84%|████████▍ | 67/80 [01:22<00:19,  1.46s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.49s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.39s/it][A
 88%|████████▊ | 70/80 [01:26<00:13,  1.35s/it][A
 89%|████████▉ | 71/80 [01:27<00:12,  1.34s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.41s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.21s/it][A
 92%|█████████▎| 74/80 [01:31<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:32<00:06,  1.29s/it][A
 95%|█████████▌| 76/80 [01:34<00:05,  1.37s/it][A
 96%|█████████▋| 77/80 [01:35<00:04,  1.38s/it][A
 98%|█████████▊| 78/80 [01:36<00:02,  1.14s/it][A
 99%|█████████▉| 79/80 [01:37<00:01,  1.27s/it][A
100%|██████████| 80/80 [01:39<00:00,  1.38s/it][A                                                    
                                               [A{'eval_loss': 0.714022159576416, 'eval_runtime': 101.0325, 'eval_samples_per_second': 9.433, 'eval_steps_per_second': 0.792, 'eval_rewards/chosen': 0.01887340471148491, 'eval_rewards/rejected': 0.017614077776670456, 'eval_rewards/accuracies': 0.39375001192092896, 'eval_rewards/margins': 0.00131397251971066, 'eval_logps/chosen': -377.74688720703125, 'eval_logps/rejected': -153.08203125, 'eval_logits/chosen': -7.257421970367432, 'eval_logits/rejected': -8.023046493530273, 'epoch': 0.37}
 12%|█▏        | 209/1674 [13:48<1:22:25,  3.38s/it]
100%|██████████| 80/80 [01:39<00:00,  1.38s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 13%|█▎        | 210/1674 [14:03<15:08:32, 37.24s/it]                                                     {'loss': 0.6749, 'grad_norm': 30.6053409576416, 'learning_rate': 2.5e-07, 'rewards/chosen': -0.005060958676040173, 'rewards/rejected': -0.04784546047449112, 'rewards/accuracies': 0.5833333730697632, 'rewards/margins': 0.042724609375, 'logps/chosen': -90.5250015258789, 'logps/rejected': -123.9000015258789, 'logits/chosen': -7.875, 'logits/rejected': -7.746874809265137, 'epoch': 0.38}
 13%|█▎        | 210/1674 [14:03<15:08:32, 37.24s/it] 13%|█▎        | 211/1674 [14:06<11:00:30, 27.09s/it] 13%|█▎        | 212/1674 [14:10<8:09:35, 20.09s/it]  13%|█▎        | 213/1674 [14:12<6:01:15, 14.84s/it] 13%|█▎        | 214/1674 [14:15<4:28:42, 11.04s/it] 13%|█▎        | 215/1674 [14:18<3:36:15,  8.89s/it] 13%|█▎        | 216/1674 [14:22<2:57:00,  7.28s/it] 13%|█▎        | 217/1674 [14:26<2:30:01,  6.18s/it] 13%|█▎        | 218/1674 [14:30<2:14:56,  5.56s/it] 13%|█▎        | 219/1674 [14:32<1:54:33,  4.72s/it] 13%|█▎        | 220/1674 [14:34<1:32:23,  3.81s/it]                                                    {'loss': 0.6811, 'grad_norm': 29.33434295654297, 'learning_rate': 2.6196172248803825e-07, 'rewards/chosen': -0.03822631761431694, 'rewards/rejected': -0.07421875, 'rewards/accuracies': 0.5500000715255737, 'rewards/margins': 0.03612060472369194, 'logps/chosen': -102.5999984741211, 'logps/rejected': -135.77499389648438, 'logits/chosen': -8.046875, 'logits/rejected': -7.765625, 'epoch': 0.39}
 13%|█▎        | 220/1674 [14:35<1:32:23,  3.81s/it] 13%|█▎        | 221/1674 [14:37<1:25:04,  3.51s/it] 13%|█▎        | 222/1674 [14:40<1:22:05,  3.39s/it] 13%|█▎        | 223/1674 [14:44<1:22:38,  3.42s/it] 13%|█▎        | 224/1674 [14:47<1:22:51,  3.43s/it] 13%|█▎        | 225/1674 [14:50<1:22:42,  3.42s/it] 14%|█▎        | 226/1674 [14:53<1:15:57,  3.15s/it] 14%|█▎        | 227/1674 [14:56<1:15:41,  3.14s/it] 14%|█▎        | 228/1674 [14:59<1:13:46,  3.06s/it] 14%|█▎        | 229/1674 [15:03<1:24:51,  3.52s/it] 14%|█▎        | 230/1674 [15:08<1:29:44,  3.73s/it]                                                    {'loss': 0.6768, 'grad_norm': 34.84347152709961, 'learning_rate': 2.7392344497607657e-07, 'rewards/chosen': -0.03357429429888725, 'rewards/rejected': -0.07524414360523224, 'rewards/accuracies': 0.5833333730697632, 'rewards/margins': 0.04161987453699112, 'logps/chosen': -117.30000305175781, 'logps/rejected': -123.75, 'logits/chosen': -7.746874809265137, 'logits/rejected': -7.728125095367432, 'epoch': 0.41}
 14%|█▎        | 230/1674 [15:08<1:29:44,  3.73s/it] 14%|█▍        | 231/1674 [15:12<1:30:53,  3.78s/it] 14%|█▍        | 232/1674 [15:16<1:33:56,  3.91s/it] 14%|█▍        | 233/1674 [15:19<1:29:33,  3.73s/it] 14%|█▍        | 234/1674 [15:23<1:31:23,  3.81s/it] 14%|█▍        | 235/1674 [15:25<1:20:01,  3.34s/it] 14%|█▍        | 236/1674 [15:28<1:14:13,  3.10s/it] 14%|█▍        | 237/1674 [15:32<1:20:03,  3.34s/it] 14%|█▍        | 238/1674 [15:36<1:22:48,  3.46s/it] 14%|█▍        | 239/1674 [15:39<1:25:27,  3.57s/it] 14%|█▍        | 240/1674 [15:43<1:26:08,  3.60s/it]                                                    {'loss': 0.6888, 'grad_norm': 26.680644989013672, 'learning_rate': 2.8588516746411483e-07, 'rewards/chosen': -0.02207641676068306, 'rewards/rejected': -0.05372314527630806, 'rewards/accuracies': 0.6583333015441895, 'rewards/margins': 0.03167724609375, 'logps/chosen': -148.52499389648438, 'logps/rejected': -147.85000610351562, 'logits/chosen': -8.009374618530273, 'logits/rejected': -7.943749904632568, 'epoch': 0.43}
 14%|█▍        | 240/1674 [15:43<1:26:08,  3.60s/it] 14%|█▍        | 241/1674 [15:46<1:23:00,  3.48s/it] 14%|█▍        | 242/1674 [15:50<1:25:39,  3.59s/it] 15%|█▍        | 243/1674 [15:54<1:26:58,  3.65s/it] 15%|█▍        | 244/1674 [15:58<1:29:56,  3.77s/it] 15%|█▍        | 245/1674 [16:02<1:31:34,  3.84s/it] 15%|█▍        | 246/1674 [16:06<1:34:10,  3.96s/it] 15%|█▍        | 247/1674 [16:10<1:33:47,  3.94s/it] 15%|█▍        | 248/1674 [16:14<1:32:57,  3.91s/it] 15%|█▍        | 249/1674 [16:18<1:33:24,  3.93s/it] 15%|█▍        | 250/1674 [16:21<1:28:28,  3.73s/it]                                                    {'loss': 0.6611, 'grad_norm': 29.809085845947266, 'learning_rate': 2.978468899521531e-07, 'rewards/chosen': 0.01339569129049778, 'rewards/rejected': -0.06596679985523224, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.07931213080883026, 'logps/chosen': -212.0500030517578, 'logps/rejected': -230.25, 'logits/chosen': -7.765625, 'logits/rejected': -7.615624904632568, 'epoch': 0.45}
 15%|█▍        | 250/1674 [16:21<1:28:28,  3.73s/it] 15%|█▍        | 251/1674 [16:25<1:28:57,  3.75s/it] 15%|█▌        | 252/1674 [16:27<1:20:02,  3.38s/it] 15%|█▌        | 253/1674 [16:31<1:21:00,  3.42s/it] 15%|█▌        | 254/1674 [16:34<1:14:47,  3.16s/it] 15%|█▌        | 255/1674 [16:37<1:16:00,  3.21s/it] 15%|█▌        | 256/1674 [16:40<1:18:18,  3.31s/it] 15%|█▌        | 257/1674 [16:44<1:18:53,  3.34s/it] 15%|█▌        | 258/1674 [16:47<1:19:28,  3.37s/it] 15%|█▌        | 259/1674 [16:51<1:18:40,  3.34s/it] 16%|█▌        | 260/1674 [16:54<1:21:31,  3.46s/it]                                                    {'loss': 0.6573, 'grad_norm': 33.935546875, 'learning_rate': 3.0980861244019136e-07, 'rewards/chosen': -0.01286926306784153, 'rewards/rejected': -0.09885253757238388, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.08601073920726776, 'logps/chosen': -92.80000305175781, 'logps/rejected': -119.6500015258789, 'logits/chosen': -8.159375190734863, 'logits/rejected': -8.012499809265137, 'epoch': 0.47}
 16%|█▌        | 260/1674 [16:55<1:21:31,  3.46s/it] 16%|█▌        | 261/1674 [16:58<1:26:22,  3.67s/it] 16%|█▌        | 262/1674 [17:02<1:25:12,  3.62s/it] 16%|█▌        | 263/1674 [17:06<1:29:44,  3.82s/it] 16%|█▌        | 264/1674 [17:09<1:23:01,  3.53s/it] 16%|█▌        | 265/1674 [17:12<1:20:42,  3.44s/it] 16%|█▌        | 266/1674 [17:15<1:16:30,  3.26s/it] 16%|█▌        | 267/1674 [17:18<1:14:12,  3.16s/it] 16%|█▌        | 268/1674 [17:22<1:19:26,  3.39s/it] 16%|█▌        | 269/1674 [17:26<1:23:02,  3.55s/it] 16%|█▌        | 270/1674 [17:29<1:19:59,  3.42s/it]                                                    {'loss': 0.6748, 'grad_norm': 37.07242202758789, 'learning_rate': 3.2177033492822963e-07, 'rewards/chosen': -0.04188232496380806, 'rewards/rejected': -0.09724120795726776, 'rewards/accuracies': 0.5750000476837158, 'rewards/margins': 0.05538024753332138, 'logps/chosen': -141.25, 'logps/rejected': -159.0, 'logits/chosen': -7.881249904632568, 'logits/rejected': -7.706250190734863, 'epoch': 0.48}
 16%|█▌        | 270/1674 [17:29<1:19:59,  3.42s/it] 16%|█▌        | 271/1674 [17:32<1:20:19,  3.44s/it] 16%|█▌        | 272/1674 [17:36<1:23:59,  3.59s/it] 16%|█▋        | 273/1674 [17:40<1:26:18,  3.70s/it] 16%|█▋        | 274/1674 [17:44<1:27:12,  3.74s/it] 16%|█▋        | 275/1674 [17:47<1:23:54,  3.60s/it] 16%|█▋        | 276/1674 [17:51<1:22:01,  3.52s/it] 17%|█▋        | 277/1674 [17:54<1:20:53,  3.47s/it] 17%|█▋        | 278/1674 [17:57<1:14:13,  3.19s/it] 17%|█▋        | 279/1674 [18:00<1:12:17,  3.11s/it] 17%|█▋        | 280/1674 [18:03<1:15:48,  3.26s/it]                                                    {'loss': 0.6361, 'grad_norm': 28.039169311523438, 'learning_rate': 3.3373205741626794e-07, 'rewards/chosen': 0.04618682712316513, 'rewards/rejected': -0.11479492485523224, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.16093750298023224, 'logps/chosen': -163.375, 'logps/rejected': -211.14999389648438, 'logits/chosen': -8.053125381469727, 'logits/rejected': -7.615624904632568, 'epoch': 0.5}
 17%|█▋        | 280/1674 [18:03<1:15:48,  3.26s/it] 17%|█▋        | 281/1674 [18:07<1:21:53,  3.53s/it] 17%|█▋        | 282/1674 [18:11<1:24:34,  3.65s/it] 17%|█▋        | 283/1674 [18:14<1:17:26,  3.34s/it] 17%|█▋        | 284/1674 [18:17<1:17:56,  3.36s/it] 17%|█▋        | 285/1674 [18:21<1:23:03,  3.59s/it] 17%|█▋        | 286/1674 [18:25<1:21:36,  3.53s/it] 17%|█▋        | 287/1674 [18:29<1:25:14,  3.69s/it] 17%|█▋        | 288/1674 [18:33<1:26:46,  3.76s/it] 17%|█▋        | 289/1674 [18:37<1:29:50,  3.89s/it] 17%|█▋        | 290/1674 [18:41<1:30:18,  3.92s/it]                                                    {'loss': 0.6378, 'grad_norm': 30.776168823242188, 'learning_rate': 3.456937799043062e-07, 'rewards/chosen': 0.03237304836511612, 'rewards/rejected': -0.11147461086511612, 'rewards/accuracies': 0.6833333373069763, 'rewards/margins': 0.1438751220703125, 'logps/chosen': -193.25, 'logps/rejected': -199.39999389648438, 'logits/chosen': -7.837500095367432, 'logits/rejected': -7.853125095367432, 'epoch': 0.52}
 17%|█▋        | 290/1674 [18:41<1:30:18,  3.92s/it] 17%|█▋        | 291/1674 [18:45<1:32:41,  4.02s/it] 17%|█▋        | 292/1674 [18:49<1:32:13,  4.00s/it] 18%|█▊        | 293/1674 [18:52<1:20:08,  3.48s/it] 18%|█▊        | 294/1674 [18:54<1:15:36,  3.29s/it] 18%|█▊        | 295/1674 [18:58<1:20:35,  3.51s/it] 18%|█▊        | 296/1674 [19:02<1:21:44,  3.56s/it] 18%|█▊        | 297/1674 [19:05<1:20:31,  3.51s/it] 18%|█▊        | 298/1674 [19:09<1:20:53,  3.53s/it] 18%|█▊        | 299/1674 [19:13<1:25:47,  3.74s/it] 18%|█▊        | 300/1674 [19:17<1:22:31,  3.60s/it]                                                    {'loss': 0.6522, 'grad_norm': 31.416061401367188, 'learning_rate': 3.5765550239234447e-07, 'rewards/chosen': -0.07483520358800888, 'rewards/rejected': -0.18300780653953552, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.10812988132238388, 'logps/chosen': -109.30000305175781, 'logps/rejected': -139.39999389648438, 'logits/chosen': -8.096875190734863, 'logits/rejected': -7.871874809265137, 'epoch': 0.54}
 18%|█▊        | 300/1674 [19:17<1:22:31,  3.60s/it] 18%|█▊        | 301/1674 [19:21<1:25:39,  3.74s/it] 18%|█▊        | 302/1674 [19:24<1:20:19,  3.51s/it] 18%|█▊        | 303/1674 [19:28<1:23:28,  3.65s/it] 18%|█▊        | 304/1674 [19:31<1:18:41,  3.45s/it] 18%|█▊        | 305/1674 [19:34<1:17:13,  3.38s/it] 18%|█▊        | 306/1674 [19:37<1:14:10,  3.25s/it] 18%|█▊        | 307/1674 [19:40<1:17:24,  3.40s/it] 18%|█▊        | 308/1674 [19:44<1:19:21,  3.49s/it] 18%|█▊        | 309/1674 [19:47<1:17:48,  3.42s/it] 19%|█▊        | 310/1674 [19:51<1:18:44,  3.46s/it]                                                    {'loss': 0.6159, 'grad_norm': 43.083152770996094, 'learning_rate': 3.696172248803828e-07, 'rewards/chosen': -0.07644043117761612, 'rewards/rejected': -0.26875001192092896, 'rewards/accuracies': 0.6833333373069763, 'rewards/margins': 0.192138671875, 'logps/chosen': -96.92500305175781, 'logps/rejected': -157.1999969482422, 'logits/chosen': -8.287500381469727, 'logits/rejected': -7.878125190734863, 'epoch': 0.56}
 19%|█▊        | 310/1674 [19:51<1:18:44,  3.46s/it] 19%|█▊        | 311/1674 [19:54<1:16:38,  3.37s/it] 19%|█▊        | 312/1674 [19:57<1:12:32,  3.20s/it] 19%|█▊        | 313/1674 [20:00<1:13:03,  3.22s/it] 19%|█▉        | 314/1674 [20:04<1:19:41,  3.52s/it] 19%|█▉        | 315/1674 [20:08<1:16:52,  3.39s/it] 19%|█▉        | 316/1674 [20:11<1:14:27,  3.29s/it] 19%|█▉        | 317/1674 [20:14<1:14:19,  3.29s/it] 19%|█▉        | 318/1674 [20:17<1:15:55,  3.36s/it] 19%|█▉        | 319/1674 [20:21<1:15:32,  3.35s/it] 19%|█▉        | 320/1674 [20:24<1:15:15,  3.34s/it]                                                    {'loss': 0.6292, 'grad_norm': 30.80642318725586, 'learning_rate': 3.8157894736842105e-07, 'rewards/chosen': -0.08519287407398224, 'rewards/rejected': -0.24785156548023224, 'rewards/accuracies': 0.7166666388511658, 'rewards/margins': 0.16281738877296448, 'logps/chosen': -101.30000305175781, 'logps/rejected': -131.10000610351562, 'logits/chosen': -8.149999618530273, 'logits/rejected': -7.868750095367432, 'epoch': 0.57}
 19%|█▉        | 320/1674 [20:24<1:15:15,  3.34s/it] 19%|█▉        | 321/1674 [20:28<1:22:25,  3.66s/it] 19%|█▉        | 322/1674 [20:31<1:16:35,  3.40s/it] 19%|█▉        | 323/1674 [20:35<1:19:13,  3.52s/it] 19%|█▉        | 324/1674 [20:39<1:21:12,  3.61s/it] 19%|█▉        | 325/1674 [20:42<1:21:31,  3.63s/it] 19%|█▉        | 326/1674 [20:47<1:24:47,  3.77s/it] 20%|█▉        | 327/1674 [20:49<1:14:08,  3.30s/it] 20%|█▉        | 328/1674 [20:52<1:14:24,  3.32s/it] 20%|█▉        | 329/1674 [20:55<1:12:58,  3.26s/it] 20%|█▉        | 330/1674 [20:59<1:17:30,  3.46s/it]                                                    {'loss': 0.6951, 'grad_norm': 43.43199920654297, 'learning_rate': 3.935406698564593e-07, 'rewards/chosen': -0.18452148139476776, 'rewards/rejected': -0.23037108778953552, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.04596252366900444, 'logps/chosen': -123.8499984741211, 'logps/rejected': -119.0, 'logits/chosen': -8.015625, 'logits/rejected': -8.175000190734863, 'epoch': 0.59}
 20%|█▉        | 330/1674 [20:59<1:17:30,  3.46s/it] 20%|█▉        | 331/1674 [21:03<1:17:38,  3.47s/it] 20%|█▉        | 332/1674 [21:06<1:19:21,  3.55s/it] 20%|█▉        | 333/1674 [21:10<1:21:00,  3.62s/it] 20%|█▉        | 334/1674 [21:13<1:17:30,  3.47s/it] 20%|██        | 335/1674 [21:17<1:18:31,  3.52s/it] 20%|██        | 336/1674 [21:21<1:22:20,  3.69s/it] 20%|██        | 337/1674 [21:25<1:25:53,  3.85s/it] 20%|██        | 338/1674 [21:29<1:22:21,  3.70s/it] 20%|██        | 339/1674 [21:31<1:14:51,  3.36s/it] 20%|██        | 340/1674 [21:35<1:14:58,  3.37s/it]                                                    {'loss': 0.6313, 'grad_norm': 38.94901657104492, 'learning_rate': 4.055023923444976e-07, 'rewards/chosen': -0.13410644233226776, 'rewards/rejected': -0.31132811307907104, 'rewards/accuracies': 0.6416667103767395, 'rewards/margins': 0.17739257216453552, 'logps/chosen': -109.44999694824219, 'logps/rejected': -141.9499969482422, 'logits/chosen': -8.240625381469727, 'logits/rejected': -7.928124904632568, 'epoch': 0.61}
 20%|██        | 340/1674 [21:35<1:14:58,  3.37s/it] 20%|██        | 341/1674 [21:37<1:10:28,  3.17s/it] 20%|██        | 342/1674 [21:41<1:16:04,  3.43s/it] 20%|██        | 343/1674 [21:45<1:14:22,  3.35s/it] 21%|██        | 344/1674 [21:49<1:19:45,  3.60s/it] 21%|██        | 345/1674 [21:52<1:17:57,  3.52s/it] 21%|██        | 346/1674 [21:56<1:21:51,  3.70s/it] 21%|██        | 347/1674 [22:00<1:22:17,  3.72s/it] 21%|██        | 348/1674 [22:04<1:23:01,  3.76s/it] 21%|██        | 349/1674 [22:07<1:19:25,  3.60s/it] 21%|██        | 350/1674 [22:11<1:18:52,  3.57s/it]                                                    {'loss': 0.6103, 'grad_norm': 27.289813995361328, 'learning_rate': 4.1746411483253585e-07, 'rewards/chosen': -0.10729523003101349, 'rewards/rejected': -0.33916014432907104, 'rewards/accuracies': 0.7000000476837158, 'rewards/margins': 0.23173828423023224, 'logps/chosen': -116.5, 'logps/rejected': -136.4499969482422, 'logits/chosen': -8.143750190734863, 'logits/rejected': -8.084375381469727, 'epoch': 0.63}
 21%|██        | 350/1674 [22:11<1:18:52,  3.57s/it] 21%|██        | 351/1674 [22:15<1:23:04,  3.77s/it] 21%|██        | 352/1674 [22:18<1:20:26,  3.65s/it] 21%|██        | 353/1674 [22:21<1:15:56,  3.45s/it] 21%|██        | 354/1674 [22:23<1:08:31,  3.11s/it] 21%|██        | 355/1674 [22:27<1:08:25,  3.11s/it] 21%|██▏       | 356/1674 [22:30<1:09:57,  3.19s/it] 21%|██▏       | 357/1674 [22:32<1:05:58,  3.01s/it] 21%|██▏       | 358/1674 [22:36<1:10:15,  3.20s/it] 21%|██▏       | 359/1674 [22:39<1:10:55,  3.24s/it] 22%|██▏       | 360/1674 [22:43<1:15:50,  3.46s/it]                                                    {'loss': 0.6177, 'grad_norm': 26.70844268798828, 'learning_rate': 4.294258373205741e-07, 'rewards/chosen': -0.13356932997703552, 'rewards/rejected': -0.3472656309604645, 'rewards/accuracies': 0.6750000715255737, 'rewards/margins': 0.21342773735523224, 'logps/chosen': -107.05000305175781, 'logps/rejected': -135.14999389648438, 'logits/chosen': -8.240625381469727, 'logits/rejected': -8.09375, 'epoch': 0.65}
 22%|██▏       | 360/1674 [22:44<1:15:50,  3.46s/it] 22%|██▏       | 361/1674 [22:47<1:15:12,  3.44s/it] 22%|██▏       | 362/1674 [22:50<1:15:24,  3.45s/it] 22%|██▏       | 363/1674 [22:54<1:18:14,  3.58s/it] 22%|██▏       | 364/1674 [22:57<1:13:22,  3.36s/it] 22%|██▏       | 365/1674 [23:01<1:17:04,  3.53s/it] 22%|██▏       | 366/1674 [23:04<1:14:35,  3.42s/it] 22%|██▏       | 367/1674 [23:08<1:17:17,  3.55s/it] 22%|██▏       | 368/1674 [23:12<1:20:59,  3.72s/it] 22%|██▏       | 369/1674 [23:15<1:17:57,  3.58s/it] 22%|██▏       | 370/1674 [23:18<1:14:36,  3.43s/it]                                                    {'loss': 0.6058, 'grad_norm': 30.478191375732422, 'learning_rate': 4.4138755980861243e-07, 'rewards/chosen': -0.07851562649011612, 'rewards/rejected': -0.33964842557907104, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.26103514432907104, 'logps/chosen': -157.1999969482422, 'logps/rejected': -171.8000030517578, 'logits/chosen': -8.356249809265137, 'logits/rejected': -8.175000190734863, 'epoch': 0.66}
 22%|██▏       | 370/1674 [23:19<1:14:36,  3.43s/it] 22%|██▏       | 371/1674 [23:21<1:10:22,  3.24s/it] 22%|██▏       | 372/1674 [23:24<1:05:40,  3.03s/it] 22%|██▏       | 373/1674 [23:28<1:11:22,  3.29s/it] 22%|██▏       | 374/1674 [23:31<1:12:31,  3.35s/it] 22%|██▏       | 375/1674 [23:34<1:06:12,  3.06s/it] 22%|██▏       | 376/1674 [23:37<1:11:09,  3.29s/it] 23%|██▎       | 377/1674 [23:41<1:13:54,  3.42s/it] 23%|██▎       | 378/1674 [23:44<1:11:54,  3.33s/it] 23%|██▎       | 379/1674 [23:47<1:10:50,  3.28s/it] 23%|██▎       | 380/1674 [23:50<1:05:15,  3.03s/it]                                                    {'loss': 0.6275, 'grad_norm': 32.936710357666016, 'learning_rate': 4.533492822966507e-07, 'rewards/chosen': -0.17526397109031677, 'rewards/rejected': -0.36669921875, 'rewards/accuracies': 0.6833332777023315, 'rewards/margins': 0.19172362983226776, 'logps/chosen': -109.1500015258789, 'logps/rejected': -122.6500015258789, 'logits/chosen': -8.037500381469727, 'logits/rejected': -8.059374809265137, 'epoch': 0.68}
 23%|██▎       | 380/1674 [23:50<1:05:15,  3.03s/it] 23%|██▎       | 381/1674 [23:54<1:12:48,  3.38s/it] 23%|██▎       | 382/1674 [23:56<1:06:01,  3.07s/it] 23%|██▎       | 383/1674 [23:59<1:03:24,  2.95s/it] 23%|██▎       | 384/1674 [24:03<1:09:47,  3.25s/it] 23%|██▎       | 385/1674 [24:07<1:15:49,  3.53s/it] 23%|██▎       | 386/1674 [24:10<1:13:05,  3.41s/it] 23%|██▎       | 387/1674 [24:14<1:16:26,  3.56s/it] 23%|██▎       | 388/1674 [24:17<1:14:40,  3.48s/it] 23%|██▎       | 389/1674 [24:21<1:12:10,  3.37s/it] 23%|██▎       | 390/1674 [24:23<1:04:33,  3.02s/it]                                                    {'loss': 0.5827, 'grad_norm': 26.748146057128906, 'learning_rate': 4.65311004784689e-07, 'rewards/chosen': 0.0709228515625, 'rewards/rejected': -0.2515625059604645, 'rewards/accuracies': 0.7166666388511658, 'rewards/margins': 0.32207030057907104, 'logps/chosen': -179.8000030517578, 'logps/rejected': -194.60000610351562, 'logits/chosen': -8.306249618530273, 'logits/rejected': -8.159375190734863, 'epoch': 0.7}
 23%|██▎       | 390/1674 [24:23<1:04:33,  3.02s/it] 23%|██▎       | 391/1674 [24:27<1:12:04,  3.37s/it] 23%|██▎       | 392/1674 [24:31<1:15:03,  3.51s/it] 23%|██▎       | 393/1674 [24:35<1:16:44,  3.59s/it] 24%|██▎       | 394/1674 [24:39<1:18:50,  3.70s/it] 24%|██▎       | 395/1674 [24:42<1:18:44,  3.69s/it] 24%|██▎       | 396/1674 [24:45<1:10:22,  3.30s/it] 24%|██▎       | 397/1674 [24:47<1:07:22,  3.17s/it] 24%|██▍       | 398/1674 [24:51<1:09:32,  3.27s/it] 24%|██▍       | 399/1674 [24:54<1:07:35,  3.18s/it] 24%|██▍       | 400/1674 [24:57<1:08:34,  3.23s/it]                                                    {'loss': 0.6129, 'grad_norm': 29.97928237915039, 'learning_rate': 4.772727272727273e-07, 'rewards/chosen': -0.232421875, 'rewards/rejected': -0.4974609315395355, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.2651611268520355, 'logps/chosen': -125.0999984741211, 'logps/rejected': -117.32499694824219, 'logits/chosen': -8.3125, 'logits/rejected': -8.487500190734863, 'epoch': 0.72}
 24%|██▍       | 400/1674 [24:57<1:08:34,  3.23s/it] 24%|██▍       | 401/1674 [25:01<1:10:20,  3.32s/it] 24%|██▍       | 402/1674 [25:03<1:04:26,  3.04s/it] 24%|██▍       | 403/1674 [25:07<1:08:26,  3.23s/it] 24%|██▍       | 404/1674 [25:11<1:12:44,  3.44s/it] 24%|██▍       | 405/1674 [25:15<1:15:03,  3.55s/it] 24%|██▍       | 406/1674 [25:18<1:13:50,  3.49s/it] 24%|██▍       | 407/1674 [25:22<1:17:50,  3.69s/it] 24%|██▍       | 408/1674 [25:25<1:14:24,  3.53s/it] 24%|██▍       | 409/1674 [25:27<1:04:56,  3.08s/it] 24%|██▍       | 410/1674 [25:30<1:02:52,  2.98s/it]                                                    {'loss': 0.5738, 'grad_norm': 25.676435470581055, 'learning_rate': 4.892344497607655e-07, 'rewards/chosen': -0.18256835639476776, 'rewards/rejected': -0.5244140625, 'rewards/accuracies': 0.7416666746139526, 'rewards/margins': 0.3418945372104645, 'logps/chosen': -102.9000015258789, 'logps/rejected': -140.35000610351562, 'logits/chosen': -8.199999809265137, 'logits/rejected': -7.912499904632568, 'epoch': 0.73}
 24%|██▍       | 410/1674 [25:30<1:02:52,  2.98s/it] 25%|██▍       | 411/1674 [25:34<1:06:33,  3.16s/it] 25%|██▍       | 412/1674 [25:38<1:11:41,  3.41s/it] 25%|██▍       | 413/1674 [25:41<1:10:42,  3.36s/it] 25%|██▍       | 414/1674 [25:45<1:15:49,  3.61s/it] 25%|██▍       | 415/1674 [25:49<1:14:43,  3.56s/it] 25%|██▍       | 416/1674 [25:52<1:11:54,  3.43s/it] 25%|██▍       | 417/1674 [25:55<1:11:19,  3.40s/it] 25%|██▍       | 418/1674 [25:58<1:09:45,  3.33s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:58,  1.34it/s][A
  4%|▍         | 3/80 [00:03<01:24,  1.09s/it][A
  5%|▌         | 4/80 [00:04<01:36,  1.27s/it][A
  6%|▋         | 5/80 [00:06<01:45,  1.40s/it][A
  8%|▊         | 6/80 [00:07<01:48,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:51,  1.53s/it][A
 10%|█         | 8/80 [00:11<01:53,  1.57s/it][A
 11%|█▏        | 9/80 [00:12<01:53,  1.60s/it][A
 12%|█▎        | 10/80 [00:14<01:54,  1.64s/it][A
 14%|█▍        | 11/80 [00:16<01:53,  1.65s/it][A
 15%|█▌        | 12/80 [00:17<01:50,  1.62s/it][A
 16%|█▋        | 13/80 [00:19<01:47,  1.61s/it][A
 18%|█▊        | 14/80 [00:21<01:48,  1.64s/it][A
 19%|█▉        | 15/80 [00:22<01:46,  1.64s/it][A
 20%|██        | 16/80 [00:24<01:43,  1.62s/it][A
 21%|██▏       | 17/80 [00:26<01:41,  1.62s/it][A
 22%|██▎       | 18/80 [00:27<01:44,  1.69s/it][A
 24%|██▍       | 19/80 [00:28<01:32,  1.52s/it][A
 25%|██▌       | 20/80 [00:30<01:26,  1.44s/it][A
 26%|██▋       | 21/80 [00:30<01:09,  1.18s/it][A
 28%|██▊       | 22/80 [00:31<01:06,  1.15s/it][A
 29%|██▉       | 23/80 [00:32<01:04,  1.13s/it][A
 30%|███       | 24/80 [00:33<00:52,  1.07it/s][A
 31%|███▏      | 25/80 [00:34<00:55,  1.00s/it][A
 32%|███▎      | 26/80 [00:35<00:58,  1.08s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.03it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.03it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.10s/it][A
 39%|███▉      | 31/80 [00:41<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.06it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.15s/it][A
 42%|████▎     | 34/80 [00:44<00:56,  1.24s/it][A
 44%|████▍     | 35/80 [00:45<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:46<00:41,  1.06it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.22it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:48,  1.22s/it][A
 51%|█████▏    | 41/80 [00:51<00:40,  1.03s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.19s/it][A
 54%|█████▍    | 43/80 [00:54<00:46,  1.26s/it][A
 55%|█████▌    | 44/80 [00:55<00:45,  1.25s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.07it/s][A
 59%|█████▉    | 47/80 [00:58<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:38,  1.19s/it][A
 61%|██████▏   | 49/80 [01:00<00:31,  1.01s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.19it/s][A
 64%|██████▍   | 51/80 [01:02<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:04<00:26,  1.03it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.18s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:10<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.24s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.03s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.18s/it][A
 78%|███████▊  | 62/80 [01:15<00:24,  1.34s/it][A
 79%|███████▉  | 63/80 [01:16<00:21,  1.27s/it][A
 80%|████████  | 64/80 [01:17<00:18,  1.14s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.25s/it][A
 82%|████████▎ | 66/80 [01:20<00:18,  1.35s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.45s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.48s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.39s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.35s/it][A
 89%|████████▉ | 71/80 [01:27<00:12,  1.34s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.41s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.22s/it][A
 92%|█████████▎| 74/80 [01:31<00:07,  1.32s/it][A
 94%|█████████▍| 75/80 [01:32<00:06,  1.28s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.36s/it][A
 96%|█████████▋| 77/80 [01:35<00:04,  1.36s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.13s/it][A
 99%|█████████▉| 79/80 [01:37<00:01,  1.26s/it][A
100%|██████████| 80/80 [01:39<00:00,  1.37s/it][A                                                    
                                               [A{'eval_loss': 0.6028978228569031, 'eval_runtime': 100.779, 'eval_samples_per_second': 9.456, 'eval_steps_per_second': 0.794, 'eval_rewards/chosen': 0.40310949087142944, 'eval_rewards/rejected': -0.12593193352222443, 'eval_rewards/accuracies': 0.7056249976158142, 'eval_rewards/margins': 0.529079794883728, 'eval_logps/chosen': -373.8999938964844, 'eval_logps/rejected': -154.41250610351562, 'eval_logits/chosen': -7.623827934265137, 'eval_logits/rejected': -8.254687309265137, 'epoch': 0.75}
 25%|██▍       | 418/1674 [27:39<1:09:45,  3.33s/it]
100%|██████████| 80/80 [01:39<00:00,  1.37s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 25%|██▌       | 419/1674 [27:57<13:14:15, 37.97s/it] 25%|██▌       | 420/1674 [27:59<9:31:29, 27.34s/it]                                                     {'loss': 0.5725, 'grad_norm': 24.879518508911133, 'learning_rate': 5.011961722488038e-07, 'rewards/chosen': -0.22763672471046448, 'rewards/rejected': -0.6039062738418579, 'rewards/accuracies': 0.7416666746139526, 'rewards/margins': 0.3760742247104645, 'logps/chosen': -113.1500015258789, 'logps/rejected': -129.75, 'logits/chosen': -8.431249618530273, 'logits/rejected': -8.231249809265137, 'epoch': 0.75}
 25%|██▌       | 420/1674 [28:00<9:31:29, 27.34s/it] 25%|██▌       | 421/1674 [28:03<7:04:47, 20.34s/it] 25%|██▌       | 422/1674 [28:07<5:16:29, 15.17s/it] 25%|██▌       | 423/1674 [28:09<3:57:45, 11.40s/it] 25%|██▌       | 424/1674 [28:13<3:10:47,  9.16s/it] 25%|██▌       | 425/1674 [28:16<2:31:21,  7.27s/it] 25%|██▌       | 426/1674 [28:18<2:00:03,  5.77s/it] 26%|██▌       | 427/1674 [28:22<1:45:07,  5.06s/it] 26%|██▌       | 428/1674 [28:24<1:27:12,  4.20s/it] 26%|██▌       | 429/1674 [28:28<1:24:55,  4.09s/it] 26%|██▌       | 430/1674 [28:30<1:12:28,  3.50s/it]                                                    {'loss': 0.5337, 'grad_norm': 25.567779541015625, 'learning_rate': 5.131578947368422e-07, 'rewards/chosen': -0.18327637016773224, 'rewards/rejected': -0.6558593511581421, 'rewards/accuracies': 0.7750000357627869, 'rewards/margins': 0.47333985567092896, 'logps/chosen': -95.8499984741211, 'logps/rejected': -141.9499969482422, 'logits/chosen': -8.493749618530273, 'logits/rejected': -8.190625190734863, 'epoch': 0.77}
 26%|██▌       | 430/1674 [28:30<1:12:28,  3.50s/it] 26%|██▌       | 431/1674 [28:34<1:15:52,  3.66s/it] 26%|██▌       | 432/1674 [28:37<1:15:00,  3.62s/it] 26%|██▌       | 433/1674 [28:40<1:08:05,  3.29s/it] 26%|██▌       | 434/1674 [28:44<1:11:15,  3.45s/it] 26%|██▌       | 435/1674 [28:46<1:04:48,  3.14s/it] 26%|██▌       | 436/1674 [28:50<1:07:39,  3.28s/it] 26%|██▌       | 437/1674 [28:52<1:02:41,  3.04s/it] 26%|██▌       | 438/1674 [28:56<1:08:07,  3.31s/it] 26%|██▌       | 439/1674 [29:00<1:09:53,  3.40s/it] 26%|██▋       | 440/1674 [29:04<1:13:03,  3.55s/it]                                                    {'loss': 0.5344, 'grad_norm': 60.584285736083984, 'learning_rate': 5.251196172248804e-07, 'rewards/chosen': -0.12882080674171448, 'rewards/rejected': -0.66015625, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.5306640863418579, 'logps/chosen': -155.6999969482422, 'logps/rejected': -189.60000610351562, 'logits/chosen': -8.440625190734863, 'logits/rejected': -8.228124618530273, 'epoch': 0.79}
 26%|██▋       | 440/1674 [29:04<1:13:03,  3.55s/it] 26%|██▋       | 441/1674 [29:07<1:14:36,  3.63s/it] 26%|██▋       | 442/1674 [29:12<1:17:18,  3.77s/it] 26%|██▋       | 443/1674 [29:14<1:12:00,  3.51s/it] 27%|██▋       | 444/1674 [29:19<1:15:45,  3.70s/it] 27%|██▋       | 445/1674 [29:22<1:15:10,  3.67s/it] 27%|██▋       | 446/1674 [29:26<1:14:54,  3.66s/it] 27%|██▋       | 447/1674 [29:28<1:07:47,  3.32s/it] 27%|██▋       | 448/1674 [29:32<1:10:57,  3.47s/it] 27%|██▋       | 449/1674 [29:35<1:09:38,  3.41s/it] 27%|██▋       | 450/1674 [29:39<1:07:54,  3.33s/it]                                                    {'loss': 0.5543, 'grad_norm': 28.061513900756836, 'learning_rate': 5.370813397129187e-07, 'rewards/chosen': -0.34785157442092896, 'rewards/rejected': -0.8042968511581421, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.4559570252895355, 'logps/chosen': -99.3499984741211, 'logps/rejected': -147.6999969482422, 'logits/chosen': -8.584375381469727, 'logits/rejected': -8.243749618530273, 'epoch': 0.81}
 27%|██▋       | 450/1674 [29:39<1:07:54,  3.33s/it] 27%|██▋       | 451/1674 [29:42<1:09:29,  3.41s/it] 27%|██▋       | 452/1674 [29:47<1:14:56,  3.68s/it] 27%|██▋       | 453/1674 [29:50<1:12:12,  3.55s/it] 27%|██▋       | 454/1674 [29:53<1:09:55,  3.44s/it] 27%|██▋       | 455/1674 [29:56<1:09:07,  3.40s/it] 27%|██▋       | 456/1674 [29:59<1:05:13,  3.21s/it] 27%|██▋       | 457/1674 [30:01<58:28,  2.88s/it]   27%|██▋       | 458/1674 [30:04<1:01:06,  3.02s/it] 27%|██▋       | 459/1674 [30:07<58:57,  2.91s/it]   27%|██▋       | 460/1674 [30:11<1:05:06,  3.22s/it]                                                    {'loss': 0.5968, 'grad_norm': 116.63052368164062, 'learning_rate': 5.490430622009569e-07, 'rewards/chosen': -0.23520508408546448, 'rewards/rejected': -0.651562511920929, 'rewards/accuracies': 0.7083333730697632, 'rewards/margins': 0.4157470762729645, 'logps/chosen': -156.25, 'logps/rejected': -164.6999969482422, 'logits/chosen': -8.612500190734863, 'logits/rejected': -8.331250190734863, 'epoch': 0.82}
 27%|██▋       | 460/1674 [30:11<1:05:06,  3.22s/it] 28%|██▊       | 461/1674 [30:15<1:06:55,  3.31s/it] 28%|██▊       | 462/1674 [30:17<1:02:56,  3.12s/it] 28%|██▊       | 463/1674 [30:20<1:01:45,  3.06s/it] 28%|██▊       | 464/1674 [30:24<1:07:19,  3.34s/it] 28%|██▊       | 465/1674 [30:28<1:07:22,  3.34s/it] 28%|██▊       | 466/1674 [30:32<1:12:05,  3.58s/it] 28%|██▊       | 467/1674 [30:35<1:12:23,  3.60s/it] 28%|██▊       | 468/1674 [30:39<1:14:32,  3.71s/it] 28%|██▊       | 469/1674 [30:43<1:14:49,  3.73s/it] 28%|██▊       | 470/1674 [30:46<1:12:04,  3.59s/it]                                                    {'loss': 0.5583, 'grad_norm': 31.626073837280273, 'learning_rate': 5.610047846889951e-07, 'rewards/chosen': -0.4258789122104645, 'rewards/rejected': -0.9609375, 'rewards/accuracies': 0.7166666984558105, 'rewards/margins': 0.5347656011581421, 'logps/chosen': -112.0, 'logps/rejected': -163.5500030517578, 'logits/chosen': -8.75, 'logits/rejected': -8.209375381469727, 'epoch': 0.84}
 28%|██▊       | 470/1674 [30:46<1:12:04,  3.59s/it] 28%|██▊       | 471/1674 [30:49<1:05:28,  3.27s/it] 28%|██▊       | 472/1674 [30:53<1:10:07,  3.50s/it] 28%|██▊       | 473/1674 [30:56<1:08:52,  3.44s/it] 28%|██▊       | 474/1674 [30:58<1:00:51,  3.04s/it] 28%|██▊       | 475/1674 [31:02<1:05:53,  3.30s/it] 28%|██▊       | 476/1674 [31:05<1:03:59,  3.21s/it] 28%|██▊       | 477/1674 [31:09<1:04:45,  3.25s/it] 29%|██▊       | 478/1674 [31:12<1:06:08,  3.32s/it] 29%|██▊       | 479/1674 [31:15<1:05:42,  3.30s/it] 29%|██▊       | 480/1674 [31:19<1:10:33,  3.55s/it]                                                    {'loss': 0.6011, 'grad_norm': 50.765865325927734, 'learning_rate': 5.729665071770334e-07, 'rewards/chosen': -0.565136730670929, 'rewards/rejected': -1.003515601158142, 'rewards/accuracies': 0.6833333969116211, 'rewards/margins': 0.43818360567092896, 'logps/chosen': -133.75, 'logps/rejected': -148.3000030517578, 'logits/chosen': -8.425000190734863, 'logits/rejected': -8.237500190734863, 'epoch': 0.86}
 29%|██▊       | 480/1674 [31:19<1:10:33,  3.55s/it] 29%|██▊       | 481/1674 [31:23<1:12:30,  3.65s/it] 29%|██▉       | 482/1674 [31:26<1:07:56,  3.42s/it] 29%|██▉       | 483/1674 [31:30<1:08:00,  3.43s/it] 29%|██▉       | 484/1674 [31:33<1:09:03,  3.48s/it] 29%|██▉       | 485/1674 [31:35<1:01:28,  3.10s/it] 29%|██▉       | 486/1674 [31:39<1:02:25,  3.15s/it] 29%|██▉       | 487/1674 [31:42<1:03:56,  3.23s/it] 29%|██▉       | 488/1674 [31:46<1:09:33,  3.52s/it] 29%|██▉       | 489/1674 [31:50<1:10:05,  3.55s/it] 29%|██▉       | 490/1674 [31:53<1:09:18,  3.51s/it]                                                    {'loss': 0.6165, 'grad_norm': 45.043582916259766, 'learning_rate': 5.849282296650718e-07, 'rewards/chosen': -0.4164062440395355, 'rewards/rejected': -0.8003906011581421, 'rewards/accuracies': 0.6333333253860474, 'rewards/margins': 0.38374024629592896, 'logps/chosen': -112.75, 'logps/rejected': -138.85000610351562, 'logits/chosen': -8.725000381469727, 'logits/rejected': -8.403124809265137, 'epoch': 0.88}
 29%|██▉       | 490/1674 [31:54<1:09:18,  3.51s/it] 29%|██▉       | 491/1674 [31:56<1:06:50,  3.39s/it] 29%|██▉       | 492/1674 [31:59<1:01:36,  3.13s/it] 29%|██▉       | 493/1674 [32:02<1:02:24,  3.17s/it] 30%|██▉       | 494/1674 [32:06<1:05:20,  3.32s/it] 30%|██▉       | 495/1674 [32:09<1:04:51,  3.30s/it] 30%|██▉       | 496/1674 [32:13<1:10:22,  3.58s/it] 30%|██▉       | 497/1674 [32:17<1:10:03,  3.57s/it] 30%|██▉       | 498/1674 [32:21<1:12:08,  3.68s/it] 30%|██▉       | 499/1674 [32:25<1:14:12,  3.79s/it] 30%|██▉       | 500/1674 [32:29<1:14:16,  3.80s/it]                                                    {'loss': 0.5457, 'grad_norm': 40.525611877441406, 'learning_rate': 5.9688995215311e-07, 'rewards/chosen': -0.30839842557907104, 'rewards/rejected': -0.85546875, 'rewards/accuracies': 0.75, 'rewards/margins': 0.546582043170929, 'logps/chosen': -168.3000030517578, 'logps/rejected': -170.52499389648438, 'logits/chosen': -8.381250381469727, 'logits/rejected': -8.215624809265137, 'epoch': 0.9}
 30%|██▉       | 500/1674 [32:29<1:14:16,  3.80s/it] 30%|██▉       | 501/1674 [32:33<1:14:12,  3.80s/it] 30%|██▉       | 502/1674 [32:36<1:10:53,  3.63s/it] 30%|███       | 503/1674 [32:39<1:09:27,  3.56s/it] 30%|███       | 504/1674 [32:42<1:03:23,  3.25s/it] 30%|███       | 505/1674 [32:45<1:01:29,  3.16s/it] 30%|███       | 506/1674 [32:48<1:04:05,  3.29s/it] 30%|███       | 507/1674 [32:52<1:05:36,  3.37s/it] 30%|███       | 508/1674 [32:56<1:08:43,  3.54s/it] 30%|███       | 509/1674 [32:59<1:10:05,  3.61s/it] 30%|███       | 510/1674 [33:03<1:11:26,  3.68s/it]                                                    {'loss': 0.5567, 'grad_norm': 17.29410743713379, 'learning_rate': 6.088516746411483e-07, 'rewards/chosen': -0.5863281488418579, 'rewards/rejected': -1.162500023841858, 'rewards/accuracies': 0.7166666984558105, 'rewards/margins': 0.5765380859375, 'logps/chosen': -118.7750015258789, 'logps/rejected': -161.35000610351562, 'logits/chosen': -8.462499618530273, 'logits/rejected': -8.050000190734863, 'epoch': 0.91}
 30%|███       | 510/1674 [33:03<1:11:26,  3.68s/it] 31%|███       | 511/1674 [33:06<1:06:05,  3.41s/it] 31%|███       | 512/1674 [33:10<1:08:29,  3.54s/it] 31%|███       | 513/1674 [33:12<1:02:09,  3.21s/it] 31%|███       | 514/1674 [33:16<1:06:45,  3.45s/it] 31%|███       | 515/1674 [33:20<1:07:59,  3.52s/it] 31%|███       | 516/1674 [33:22<1:00:54,  3.16s/it] 31%|███       | 517/1674 [33:24<53:49,  2.79s/it]   31%|███       | 518/1674 [33:28<57:51,  3.00s/it] 31%|███       | 519/1674 [33:32<1:04:33,  3.35s/it] 31%|███       | 520/1674 [33:35<1:04:40,  3.36s/it]                                                    {'loss': 0.5268, 'grad_norm': 25.47852325439453, 'learning_rate': 6.208133971291866e-07, 'rewards/chosen': -0.6144043207168579, 'rewards/rejected': -1.204687476158142, 'rewards/accuracies': 0.7500000596046448, 'rewards/margins': 0.5902343988418579, 'logps/chosen': -113.44999694824219, 'logps/rejected': -150.0500030517578, 'logits/chosen': -8.606249809265137, 'logits/rejected': -8.309374809265137, 'epoch': 0.93}
 31%|███       | 520/1674 [33:36<1:04:40,  3.36s/it] 31%|███       | 521/1674 [33:39<1:07:19,  3.50s/it] 31%|███       | 522/1674 [33:43<1:08:17,  3.56s/it] 31%|███       | 523/1674 [33:47<1:11:29,  3.73s/it] 31%|███▏      | 524/1674 [33:50<1:05:08,  3.40s/it] 31%|███▏      | 525/1674 [33:53<1:03:49,  3.33s/it] 31%|███▏      | 526/1674 [33:57<1:06:48,  3.49s/it] 31%|███▏      | 527/1674 [34:00<1:04:04,  3.35s/it] 32%|███▏      | 528/1674 [34:02<59:33,  3.12s/it]   32%|███▏      | 529/1674 [34:06<1:03:43,  3.34s/it] 32%|███▏      | 530/1674 [34:10<1:05:07,  3.42s/it]                                                    {'loss': 0.5202, 'grad_norm': 31.488704681396484, 'learning_rate': 6.327751196172248e-07, 'rewards/chosen': -0.46806639432907104, 'rewards/rejected': -1.084375023841858, 'rewards/accuracies': 0.7333333492279053, 'rewards/margins': 0.615917980670929, 'logps/chosen': -102.75, 'logps/rejected': -129.3000030517578, 'logits/chosen': -8.449999809265137, 'logits/rejected': -8.271875381469727, 'epoch': 0.95}
 32%|███▏      | 530/1674 [34:10<1:05:07,  3.42s/it] 32%|███▏      | 531/1674 [34:14<1:07:07,  3.52s/it] 32%|███▏      | 532/1674 [34:15<56:38,  2.98s/it]   32%|███▏      | 533/1674 [34:19<1:01:13,  3.22s/it] 32%|███▏      | 534/1674 [34:22<1:02:16,  3.28s/it] 32%|███▏      | 535/1674 [34:26<1:06:11,  3.49s/it] 32%|███▏      | 536/1674 [34:30<1:07:51,  3.58s/it] 32%|███▏      | 537/1674 [34:34<1:10:01,  3.70s/it] 32%|███▏      | 538/1674 [34:37<1:04:24,  3.40s/it] 32%|███▏      | 539/1674 [34:41<1:06:15,  3.50s/it] 32%|███▏      | 540/1674 [34:45<1:09:19,  3.67s/it]                                                    {'loss': 0.4927, 'grad_norm': 26.826854705810547, 'learning_rate': 6.447368421052632e-07, 'rewards/chosen': -0.44707030057907104, 'rewards/rejected': -1.198828101158142, 'rewards/accuracies': 0.7833333611488342, 'rewards/margins': 0.7523437738418579, 'logps/chosen': -137.8000030517578, 'logps/rejected': -189.5, 'logits/chosen': -8.568750381469727, 'logits/rejected': -8.346875190734863, 'epoch': 0.97}
 32%|███▏      | 540/1674 [34:45<1:09:19,  3.67s/it] 32%|███▏      | 541/1674 [34:49<1:11:32,  3.79s/it] 32%|███▏      | 542/1674 [34:52<1:06:43,  3.54s/it] 32%|███▏      | 543/1674 [34:55<1:05:16,  3.46s/it] 32%|███▏      | 544/1674 [34:58<1:03:32,  3.37s/it] 33%|███▎      | 545/1674 [35:02<1:07:50,  3.61s/it] 33%|███▎      | 546/1674 [35:06<1:05:42,  3.49s/it] 33%|███▎      | 547/1674 [35:10<1:09:40,  3.71s/it] 33%|███▎      | 548/1674 [35:13<1:06:59,  3.57s/it] 33%|███▎      | 549/1674 [35:17<1:10:33,  3.76s/it] 33%|███▎      | 550/1674 [35:21<1:12:50,  3.89s/it]                                                    {'loss': 0.5629, 'grad_norm': 34.09469985961914, 'learning_rate': 6.566985645933015e-07, 'rewards/chosen': -0.76171875, 'rewards/rejected': -1.28515625, 'rewards/accuracies': 0.6833333373069763, 'rewards/margins': 0.5237182378768921, 'logps/chosen': -110.6500015258789, 'logps/rejected': -148.0500030517578, 'logits/chosen': -8.762499809265137, 'logits/rejected': -8.487500190734863, 'epoch': 0.99}
 33%|███▎      | 550/1674 [35:22<1:12:50,  3.89s/it] 33%|███▎      | 551/1674 [35:25<1:11:31,  3.82s/it] 33%|███▎      | 552/1674 [35:29<1:11:57,  3.85s/it] 33%|███▎      | 553/1674 [35:33<1:13:09,  3.92s/it] 33%|███▎      | 554/1674 [35:36<1:08:45,  3.68s/it] 33%|███▎      | 555/1674 [35:40<1:11:06,  3.81s/it] 33%|███▎      | 556/1674 [35:44<1:11:14,  3.82s/it] 33%|███▎      | 557/1674 [35:48<1:13:10,  3.93s/it] 33%|███▎      | 558/1674 [35:52<1:09:58,  3.76s/it] 33%|███▎      | 559/1674 [35:55<1:05:26,  3.52s/it] 33%|███▎      | 560/1674 [35:58<1:04:30,  3.47s/it]                                                    {'loss': 0.5428, 'grad_norm': 23.372724533081055, 'learning_rate': 6.686602870813397e-07, 'rewards/chosen': -0.6060546636581421, 'rewards/rejected': -1.228906273841858, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.624218761920929, 'logps/chosen': -157.6999969482422, 'logps/rejected': -178.8000030517578, 'logits/chosen': -8.824999809265137, 'logits/rejected': -8.596875190734863, 'epoch': 1.0}
 33%|███▎      | 560/1674 [35:58<1:04:30,  3.47s/it] 34%|███▎      | 561/1674 [36:01<1:03:19,  3.41s/it] 34%|███▎      | 562/1674 [36:04<58:48,  3.17s/it]   34%|███▎      | 563/1674 [36:07<56:54,  3.07s/it] 34%|███▎      | 564/1674 [36:10<55:58,  3.03s/it] 34%|███▍      | 565/1674 [36:12<53:41,  2.90s/it] 34%|███▍      | 566/1674 [36:16<1:00:53,  3.30s/it] 34%|███▍      | 567/1674 [36:20<1:03:52,  3.46s/it] 34%|███▍      | 568/1674 [36:23<59:17,  3.22s/it]   34%|███▍      | 569/1674 [36:25<54:58,  2.98s/it] 34%|███▍      | 570/1674 [36:29<59:53,  3.25s/it]                                                  {'loss': 0.5398, 'grad_norm': 31.863643646240234, 'learning_rate': 6.80622009569378e-07, 'rewards/chosen': -0.7093750238418579, 'rewards/rejected': -1.317968726158142, 'rewards/accuracies': 0.7333332896232605, 'rewards/margins': 0.607421875, 'logps/chosen': -114.75, 'logps/rejected': -131.85000610351562, 'logits/chosen': -8.756250381469727, 'logits/rejected': -8.46875, 'epoch': 1.02}
 34%|███▍      | 570/1674 [36:29<59:53,  3.25s/it] 34%|███▍      | 571/1674 [36:33<1:01:28,  3.34s/it] 34%|███▍      | 572/1674 [36:36<1:01:52,  3.37s/it] 34%|███▍      | 573/1674 [36:39<1:00:35,  3.30s/it] 34%|███▍      | 574/1674 [36:42<56:09,  3.06s/it]   34%|███▍      | 575/1674 [36:44<52:29,  2.87s/it] 34%|███▍      | 576/1674 [36:48<54:36,  2.98s/it] 34%|███▍      | 577/1674 [36:50<53:23,  2.92s/it] 35%|███▍      | 578/1674 [36:53<52:59,  2.90s/it] 35%|███▍      | 579/1674 [36:57<56:12,  3.08s/it] 35%|███▍      | 580/1674 [37:01<1:01:35,  3.38s/it]                                                    {'loss': 0.5388, 'grad_norm': 34.609798431396484, 'learning_rate': 6.925837320574162e-07, 'rewards/chosen': -0.6224609613418579, 'rewards/rejected': -1.2546875476837158, 'rewards/accuracies': 0.7416666746139526, 'rewards/margins': 0.6314452886581421, 'logps/chosen': -105.6500015258789, 'logps/rejected': -140.8000030517578, 'logits/chosen': -8.875, 'logits/rejected': -8.465624809265137, 'epoch': 1.04}
 35%|███▍      | 580/1674 [37:01<1:01:35,  3.38s/it] 35%|███▍      | 581/1674 [37:03<52:50,  2.90s/it]   35%|███▍      | 582/1674 [37:07<59:34,  3.27s/it] 35%|███▍      | 583/1674 [37:11<1:03:38,  3.50s/it] 35%|███▍      | 584/1674 [37:14<1:03:36,  3.50s/it] 35%|███▍      | 585/1674 [37:18<1:06:04,  3.64s/it] 35%|███▌      | 586/1674 [37:22<1:05:56,  3.64s/it] 35%|███▌      | 587/1674 [37:26<1:09:18,  3.83s/it] 35%|███▌      | 588/1674 [37:29<1:04:05,  3.54s/it] 35%|███▌      | 589/1674 [37:33<1:07:05,  3.71s/it] 35%|███▌      | 590/1674 [37:37<1:07:46,  3.75s/it]                                                    {'loss': 0.5253, 'grad_norm': 78.59780883789062, 'learning_rate': 7.045454545454545e-07, 'rewards/chosen': -0.7744140625, 'rewards/rejected': -1.51953125, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 0.745312511920929, 'logps/chosen': -120.55000305175781, 'logps/rejected': -159.0, 'logits/chosen': -8.806249618530273, 'logits/rejected': -8.53125, 'epoch': 1.06}
 35%|███▌      | 590/1674 [37:37<1:07:46,  3.75s/it] 35%|███▌      | 591/1674 [37:41<1:07:36,  3.75s/it] 35%|███▌      | 592/1674 [37:44<1:03:10,  3.50s/it] 35%|███▌      | 593/1674 [37:46<57:40,  3.20s/it]   35%|███▌      | 594/1674 [37:49<56:28,  3.14s/it] 36%|███▌      | 595/1674 [37:52<56:50,  3.16s/it] 36%|███▌      | 596/1674 [37:56<1:00:19,  3.36s/it] 36%|███▌      | 597/1674 [38:00<1:01:17,  3.42s/it] 36%|███▌      | 598/1674 [38:03<1:01:03,  3.40s/it] 36%|███▌      | 599/1674 [38:06<58:37,  3.27s/it]   36%|███▌      | 600/1674 [38:10<1:01:00,  3.41s/it]                                                    {'loss': 0.5177, 'grad_norm': 29.384233474731445, 'learning_rate': 7.165071770334929e-07, 'rewards/chosen': -0.529492199420929, 'rewards/rejected': -1.274999976158142, 'rewards/accuracies': 0.7916666269302368, 'rewards/margins': 0.7455078363418579, 'logps/chosen': -102.69999694824219, 'logps/rejected': -136.5500030517578, 'logits/chosen': -8.743749618530273, 'logits/rejected': -8.431249618530273, 'epoch': 1.08}
 36%|███▌      | 600/1674 [38:10<1:01:00,  3.41s/it] 36%|███▌      | 601/1674 [38:14<1:04:47,  3.62s/it] 36%|███▌      | 602/1674 [38:18<1:06:05,  3.70s/it] 36%|███▌      | 603/1674 [38:21<1:06:01,  3.70s/it] 36%|███▌      | 604/1674 [38:25<1:05:41,  3.68s/it] 36%|███▌      | 605/1674 [38:28<1:02:29,  3.51s/it] 36%|███▌      | 606/1674 [38:32<1:01:24,  3.45s/it] 36%|███▋      | 607/1674 [38:36<1:04:33,  3.63s/it] 36%|███▋      | 608/1674 [38:40<1:07:33,  3.80s/it] 36%|███▋      | 609/1674 [38:42<1:00:00,  3.38s/it] 36%|███▋      | 610/1674 [38:45<57:59,  3.27s/it]                                                    {'loss': 0.4837, 'grad_norm': 26.682470321655273, 'learning_rate': 7.284688995215311e-07, 'rewards/chosen': -0.7447265386581421, 'rewards/rejected': -1.6140625476837158, 'rewards/accuracies': 0.7916666865348816, 'rewards/margins': 0.868359386920929, 'logps/chosen': -110.19999694824219, 'logps/rejected': -154.39999389648438, 'logits/chosen': -8.768750190734863, 'logits/rejected': -8.246874809265137, 'epoch': 1.09}
 36%|███▋      | 610/1674 [38:45<57:59,  3.27s/it] 36%|███▋      | 611/1674 [38:49<1:01:06,  3.45s/it] 37%|███▋      | 612/1674 [38:53<1:01:40,  3.48s/it] 37%|███▋      | 613/1674 [38:56<1:03:35,  3.60s/it] 37%|███▋      | 614/1674 [39:00<1:03:01,  3.57s/it] 37%|███▋      | 615/1674 [39:04<1:03:20,  3.59s/it] 37%|███▋      | 616/1674 [39:07<1:04:35,  3.66s/it] 37%|███▋      | 617/1674 [39:11<1:04:36,  3.67s/it] 37%|███▋      | 618/1674 [39:15<1:07:25,  3.83s/it] 37%|███▋      | 619/1674 [39:19<1:08:44,  3.91s/it] 37%|███▋      | 620/1674 [39:22<1:00:33,  3.45s/it]                                                    {'loss': 0.5077, 'grad_norm': 16.907634735107422, 'learning_rate': 7.404306220095693e-07, 'rewards/chosen': -0.8873046636581421, 'rewards/rejected': -1.6261718273162842, 'rewards/accuracies': 0.75, 'rewards/margins': 0.740692138671875, 'logps/chosen': -108.44999694824219, 'logps/rejected': -174.0, 'logits/chosen': -8.699999809265137, 'logits/rejected': -8.090624809265137, 'epoch': 1.11}
 37%|███▋      | 620/1674 [39:22<1:00:33,  3.45s/it] 37%|███▋      | 621/1674 [39:25<59:10,  3.37s/it]   37%|███▋      | 622/1674 [39:29<1:00:47,  3.47s/it] 37%|███▋      | 623/1674 [39:32<1:01:53,  3.53s/it] 37%|███▋      | 624/1674 [39:36<1:03:55,  3.65s/it] 37%|███▋      | 625/1674 [39:39<59:24,  3.40s/it]   37%|███▋      | 626/1674 [39:43<1:03:27,  3.63s/it] 37%|███▋      | 627/1674 [39:47<1:02:33,  3.59s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:57,  1.35it/s][A
  4%|▍         | 3/80 [00:03<01:23,  1.09s/it][A
  5%|▌         | 4/80 [00:04<01:35,  1.26s/it][A
  6%|▋         | 5/80 [00:06<01:44,  1.40s/it][A
  8%|▊         | 6/80 [00:07<01:47,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:49,  1.50s/it][A
 10%|█         | 8/80 [00:11<01:51,  1.55s/it][A
 11%|█▏        | 9/80 [00:12<01:51,  1.57s/it][A
 12%|█▎        | 10/80 [00:14<01:52,  1.61s/it][A
 14%|█▍        | 11/80 [00:16<01:52,  1.63s/it][A
 15%|█▌        | 12/80 [00:17<01:49,  1.61s/it][A
 16%|█▋        | 13/80 [00:19<01:46,  1.60s/it][A
 18%|█▊        | 14/80 [00:20<01:48,  1.64s/it][A
 19%|█▉        | 15/80 [00:22<01:46,  1.63s/it][A
 20%|██        | 16/80 [00:24<01:43,  1.61s/it][A
 21%|██▏       | 17/80 [00:25<01:41,  1.61s/it][A
 22%|██▎       | 18/80 [00:27<01:39,  1.60s/it][A
 24%|██▍       | 19/80 [00:28<01:28,  1.46s/it][A
 25%|██▌       | 20/80 [00:29<01:24,  1.40s/it][A
 26%|██▋       | 21/80 [00:30<01:07,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:05,  1.13s/it][A
 29%|██▉       | 23/80 [00:32<01:03,  1.12s/it][A
 30%|███       | 24/80 [00:32<00:51,  1.08it/s][A
 31%|███▏      | 25/80 [00:34<00:54,  1.00it/s][A
 32%|███▎      | 26/80 [00:35<00:58,  1.08s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.04it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.03it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.09s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.06it/s][A
 41%|████▏     | 33/80 [00:42<00:53,  1.15s/it][A
 42%|████▎     | 34/80 [00:44<00:56,  1.23s/it][A
 44%|████▍     | 35/80 [00:44<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.07it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:46<00:34,  1.23it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:48,  1.21s/it][A
 51%|█████▏    | 41/80 [00:50<00:39,  1.02s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.19s/it][A
 54%|█████▍    | 43/80 [00:53<00:46,  1.26s/it][A
 55%|█████▌    | 44/80 [00:54<00:45,  1.25s/it][A
 56%|█████▋    | 45/80 [00:55<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.08it/s][A
 59%|█████▉    | 47/80 [00:57<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:38,  1.19s/it][A
 61%|██████▏   | 49/80 [00:59<00:31,  1.01s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.16it/s][A
 64%|██████▍   | 51/80 [01:01<00:31,  1.07s/it][A
 65%|██████▌   | 52/80 [01:02<00:30,  1.09s/it][A
 66%|██████▋   | 53/80 [01:03<00:26,  1.02it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:05<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.19s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:09<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:10<00:25,  1.21s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.01s/it][A
 76%|███████▋  | 61/80 [01:12<00:22,  1.16s/it][A
 78%|███████▊  | 62/80 [01:14<00:23,  1.32s/it][A
 79%|███████▉  | 63/80 [01:15<00:21,  1.25s/it][A
 80%|████████  | 64/80 [01:16<00:18,  1.13s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.24s/it][A
 82%|████████▎ | 66/80 [01:19<00:18,  1.33s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.44s/it][A
 85%|████████▌ | 68/80 [01:22<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:23<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:26<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:28<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:30<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:31<00:06,  1.29s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.37s/it][A
 96%|█████████▋| 77/80 [01:34<00:04,  1.39s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.15s/it][A
 99%|█████████▉| 79/80 [01:36<00:01,  1.28s/it][A
100%|██████████| 80/80 [01:38<00:00,  1.38s/it][A                                                    
                                               [A{'eval_loss': 0.8005956411361694, 'eval_runtime': 100.1862, 'eval_samples_per_second': 9.512, 'eval_steps_per_second': 0.799, 'eval_rewards/chosen': 0.20816954970359802, 'eval_rewards/rejected': -0.42976075410842896, 'eval_rewards/accuracies': 0.6608333587646484, 'eval_rewards/margins': 0.6378276944160461, 'eval_logps/chosen': -375.9593811035156, 'eval_logps/rejected': -157.5671844482422, 'eval_logits/chosen': -8.117968559265137, 'eval_logits/rejected': -8.641016006469727, 'epoch': 1.12}
 37%|███▋      | 627/1674 [41:27<1:02:33,  3.59s/it]
100%|██████████| 80/80 [01:38<00:00,  1.38s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 38%|███▊      | 628/1674 [41:44<10:54:40, 37.55s/it] 38%|███▊      | 629/1674 [41:48<7:58:24, 27.47s/it]  38%|███▊      | 630/1674 [41:51<5:52:03, 20.23s/it]                                                    {'loss': 0.4403, 'grad_norm': 48.72325897216797, 'learning_rate': 7.523923444976076e-07, 'rewards/chosen': -0.524609386920929, 'rewards/rejected': -1.535546898841858, 'rewards/accuracies': 0.8250001072883606, 'rewards/margins': 1.0109374523162842, 'logps/chosen': -163.75, 'logps/rejected': -198.39999389648438, 'logits/chosen': -8.824999809265137, 'logits/rejected': -8.606249809265137, 'epoch': 1.13}
 38%|███▊      | 630/1674 [41:51<5:52:03, 20.23s/it] 38%|███▊      | 631/1674 [41:54<4:21:30, 15.04s/it] 38%|███▊      | 632/1674 [41:58<3:24:05, 11.75s/it] 38%|███▊      | 633/1674 [42:02<2:43:02,  9.40s/it] 38%|███▊      | 634/1674 [42:05<2:09:55,  7.50s/it] 38%|███▊      | 635/1674 [42:08<1:49:05,  6.30s/it] 38%|███▊      | 636/1674 [42:12<1:35:33,  5.52s/it] 38%|███▊      | 637/1674 [42:15<1:23:07,  4.81s/it] 38%|███▊      | 638/1674 [42:19<1:19:45,  4.62s/it] 38%|███▊      | 639/1674 [42:23<1:16:12,  4.42s/it] 38%|███▊      | 640/1674 [42:27<1:10:47,  4.11s/it]                                                    {'loss': 0.5751, 'grad_norm': 33.14381408691406, 'learning_rate': 7.643540669856458e-07, 'rewards/chosen': -0.7593749761581421, 'rewards/rejected': -1.4734375476837158, 'rewards/accuracies': 0.7166666984558105, 'rewards/margins': 0.7144531011581421, 'logps/chosen': -176.1999969482422, 'logps/rejected': -204.6999969482422, 'logits/chosen': -8.90625, 'logits/rejected': -8.493749618530273, 'epoch': 1.15}
 38%|███▊      | 640/1674 [42:27<1:10:47,  4.11s/it] 38%|███▊      | 641/1674 [42:31<1:10:07,  4.07s/it] 38%|███▊      | 642/1674 [42:34<1:04:26,  3.75s/it] 38%|███▊      | 643/1674 [42:37<1:00:32,  3.52s/it] 38%|███▊      | 644/1674 [42:41<1:03:47,  3.72s/it] 39%|███▊      | 645/1674 [42:45<1:04:24,  3.76s/it] 39%|███▊      | 646/1674 [42:49<1:06:09,  3.86s/it] 39%|███▊      | 647/1674 [42:52<1:00:38,  3.54s/it] 39%|███▊      | 648/1674 [42:56<1:03:49,  3.73s/it] 39%|███▉      | 649/1674 [42:59<1:02:34,  3.66s/it] 39%|███▉      | 650/1674 [43:03<1:02:43,  3.68s/it]                                                    {'loss': 0.4153, 'grad_norm': 24.578201293945312, 'learning_rate': 7.763157894736841e-07, 'rewards/chosen': -0.504101574420929, 'rewards/rejected': -1.5891845226287842, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.0851562023162842, 'logps/chosen': -147.1999969482422, 'logps/rejected': -187.75, 'logits/chosen': -8.681249618530273, 'logits/rejected': -8.524999618530273, 'epoch': 1.16}
 39%|███▉      | 650/1674 [43:03<1:02:43,  3.68s/it] 39%|███▉      | 651/1674 [43:07<1:04:07,  3.76s/it] 39%|███▉      | 652/1674 [43:11<1:04:38,  3.79s/it] 39%|███▉      | 653/1674 [43:15<1:05:15,  3.83s/it] 39%|███▉      | 654/1674 [43:18<1:04:05,  3.77s/it] 39%|███▉      | 655/1674 [43:23<1:06:12,  3.90s/it] 39%|███▉      | 656/1674 [43:26<1:04:18,  3.79s/it] 39%|███▉      | 657/1674 [43:30<1:04:39,  3.81s/it] 39%|███▉      | 658/1674 [43:33<1:00:45,  3.59s/it] 39%|███▉      | 659/1674 [43:37<1:01:53,  3.66s/it] 39%|███▉      | 660/1674 [43:41<1:01:46,  3.65s/it]                                                    {'loss': 0.4785, 'grad_norm': 36.063716888427734, 'learning_rate': 7.882775119617225e-07, 'rewards/chosen': -0.7085937261581421, 'rewards/rejected': -1.803125023841858, 'rewards/accuracies': 0.7916666269302368, 'rewards/margins': 1.093359351158142, 'logps/chosen': -166.6999969482422, 'logps/rejected': -195.0, 'logits/chosen': -8.762499809265137, 'logits/rejected': -8.453125, 'epoch': 1.18}
 39%|███▉      | 660/1674 [43:41<1:01:46,  3.65s/it] 39%|███▉      | 661/1674 [43:45<1:04:46,  3.84s/it] 40%|███▉      | 662/1674 [43:48<1:03:58,  3.79s/it] 40%|███▉      | 663/1674 [43:52<1:03:50,  3.79s/it] 40%|███▉      | 664/1674 [43:55<59:33,  3.54s/it]   40%|███▉      | 665/1674 [43:59<1:01:56,  3.68s/it] 40%|███▉      | 666/1674 [44:03<1:00:29,  3.60s/it] 40%|███▉      | 667/1674 [44:06<1:00:36,  3.61s/it] 40%|███▉      | 668/1674 [44:09<57:34,  3.43s/it]   40%|███▉      | 669/1674 [44:12<56:12,  3.36s/it] 40%|████      | 670/1674 [44:16<59:08,  3.53s/it]                                                  {'loss': 0.4919, 'grad_norm': 41.56572723388672, 'learning_rate': 8.002392344497607e-07, 'rewards/chosen': -0.783203125, 'rewards/rejected': -1.81640625, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.033300757408142, 'logps/chosen': -114.05000305175781, 'logps/rejected': -149.39999389648438, 'logits/chosen': -8.9375, 'logits/rejected': -8.71875, 'epoch': 1.2}
 40%|████      | 670/1674 [44:17<59:08,  3.53s/it] 40%|████      | 671/1674 [44:20<1:01:26,  3.68s/it] 40%|████      | 672/1674 [44:24<1:02:10,  3.72s/it] 40%|████      | 673/1674 [44:28<1:02:05,  3.72s/it] 40%|████      | 674/1674 [44:31<56:45,  3.41s/it]   40%|████      | 675/1674 [44:35<59:20,  3.56s/it] 40%|████      | 676/1674 [44:37<55:55,  3.36s/it] 40%|████      | 677/1674 [44:42<59:27,  3.58s/it] 41%|████      | 678/1674 [44:45<1:00:32,  3.65s/it] 41%|████      | 679/1674 [44:48<57:59,  3.50s/it]   41%|████      | 680/1674 [44:53<1:00:56,  3.68s/it]                                                    {'loss': 0.4622, 'grad_norm': 27.95865821838379, 'learning_rate': 8.12200956937799e-07, 'rewards/chosen': -0.9351562261581421, 'rewards/rejected': -1.9445312023162842, 'rewards/accuracies': 0.7583333253860474, 'rewards/margins': 1.008398413658142, 'logps/chosen': -117.3499984741211, 'logps/rejected': -153.85000610351562, 'logits/chosen': -8.831250190734863, 'logits/rejected': -8.606249809265137, 'epoch': 1.22}
 41%|████      | 680/1674 [44:53<1:00:56,  3.68s/it] 41%|████      | 681/1674 [44:56<58:32,  3.54s/it]   41%|████      | 682/1674 [44:59<57:36,  3.48s/it] 41%|████      | 683/1674 [45:03<59:46,  3.62s/it] 41%|████      | 684/1674 [45:07<59:24,  3.60s/it] 41%|████      | 685/1674 [45:10<1:00:17,  3.66s/it] 41%|████      | 686/1674 [45:13<56:56,  3.46s/it]   41%|████      | 687/1674 [45:17<55:07,  3.35s/it] 41%|████      | 688/1674 [45:20<56:51,  3.46s/it] 41%|████      | 689/1674 [45:24<57:34,  3.51s/it] 41%|████      | 690/1674 [45:28<59:36,  3.63s/it]                                                  {'loss': 0.4197, 'grad_norm': 20.161685943603516, 'learning_rate': 8.241626794258373e-07, 'rewards/chosen': -0.22499999403953552, 'rewards/rejected': -1.373046875, 'rewards/accuracies': 0.8250001072883606, 'rewards/margins': 1.1476562023162842, 'logps/chosen': -195.6999969482422, 'logps/rejected': -218.5500030517578, 'logits/chosen': -8.71875, 'logits/rejected': -8.449999809265137, 'epoch': 1.24}
 41%|████      | 690/1674 [45:28<59:36,  3.63s/it] 41%|████▏     | 691/1674 [45:31<57:09,  3.49s/it] 41%|████▏     | 692/1674 [45:34<53:13,  3.25s/it] 41%|████▏     | 693/1674 [45:38<58:14,  3.56s/it] 41%|████▏     | 694/1674 [45:41<54:49,  3.36s/it] 42%|████▏     | 695/1674 [45:44<55:41,  3.41s/it] 42%|████▏     | 696/1674 [45:47<53:53,  3.31s/it] 42%|████▏     | 697/1674 [45:51<56:31,  3.47s/it] 42%|████▏     | 698/1674 [45:55<59:28,  3.66s/it] 42%|████▏     | 699/1674 [45:59<1:00:26,  3.72s/it] 42%|████▏     | 700/1674 [46:03<1:02:55,  3.88s/it]                                                    {'loss': 0.4329, 'grad_norm': 30.64204978942871, 'learning_rate': 8.361244019138755e-07, 'rewards/chosen': -0.916796863079071, 'rewards/rejected': -2.063281297683716, 'rewards/accuracies': 0.7833333611488342, 'rewards/margins': 1.1476562023162842, 'logps/chosen': -110.5, 'logps/rejected': -162.9499969482422, 'logits/chosen': -8.8125, 'logits/rejected': -8.487500190734863, 'epoch': 1.25}
 42%|████▏     | 700/1674 [46:04<1:02:55,  3.88s/it] 42%|████▏     | 701/1674 [46:08<1:03:45,  3.93s/it] 42%|████▏     | 702/1674 [46:11<1:01:57,  3.82s/it] 42%|████▏     | 703/1674 [46:15<1:03:23,  3.92s/it] 42%|████▏     | 704/1674 [46:19<1:01:55,  3.83s/it] 42%|████▏     | 705/1674 [46:23<1:02:22,  3.86s/it] 42%|████▏     | 706/1674 [46:27<1:02:53,  3.90s/it] 42%|████▏     | 707/1674 [46:30<1:01:49,  3.84s/it] 42%|████▏     | 708/1674 [46:35<1:03:22,  3.94s/it] 42%|████▏     | 709/1674 [46:38<59:59,  3.73s/it]   42%|████▏     | 710/1674 [46:41<56:13,  3.50s/it]                                                  {'loss': 0.4954, 'grad_norm': 40.47248458862305, 'learning_rate': 8.480861244019139e-07, 'rewards/chosen': -0.7734375, 'rewards/rejected': -1.8113281726837158, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0361328125, 'logps/chosen': -160.39999389648438, 'logps/rejected': -218.9499969482422, 'logits/chosen': -9.006250381469727, 'logits/rejected': -8.524999618530273, 'epoch': 1.27}
 42%|████▏     | 710/1674 [46:41<56:13,  3.50s/it] 42%|████▏     | 711/1674 [46:45<57:58,  3.61s/it] 43%|████▎     | 712/1674 [46:49<59:43,  3.73s/it] 43%|████▎     | 713/1674 [46:51<52:33,  3.28s/it] 43%|████▎     | 714/1674 [46:54<53:06,  3.32s/it] 43%|████▎     | 715/1674 [46:57<49:08,  3.07s/it] 43%|████▎     | 716/1674 [47:00<49:13,  3.08s/it] 43%|████▎     | 717/1674 [47:03<49:37,  3.11s/it] 43%|████▎     | 718/1674 [47:07<52:43,  3.31s/it] 43%|████▎     | 719/1674 [47:10<53:46,  3.38s/it] 43%|████▎     | 720/1674 [47:14<56:16,  3.54s/it]                                                  {'loss': 0.4357, 'grad_norm': 35.53851318359375, 'learning_rate': 8.600478468899522e-07, 'rewards/chosen': -0.657031238079071, 'rewards/rejected': -1.907922387123108, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.2507812976837158, 'logps/chosen': -150.4499969482422, 'logps/rejected': -174.9499969482422, 'logits/chosen': -8.846875190734863, 'logits/rejected': -8.540624618530273, 'epoch': 1.29}
 43%|████▎     | 720/1674 [47:14<56:16,  3.54s/it] 43%|████▎     | 721/1674 [47:17<53:47,  3.39s/it] 43%|████▎     | 722/1674 [47:20<50:47,  3.20s/it] 43%|████▎     | 723/1674 [47:24<54:33,  3.44s/it] 43%|████▎     | 724/1674 [47:28<55:40,  3.52s/it] 43%|████▎     | 725/1674 [47:32<57:45,  3.65s/it] 43%|████▎     | 726/1674 [47:35<54:38,  3.46s/it] 43%|████▎     | 727/1674 [47:38<54:30,  3.45s/it] 43%|████▎     | 728/1674 [47:42<54:39,  3.47s/it] 44%|████▎     | 729/1674 [47:44<49:48,  3.16s/it] 44%|████▎     | 730/1674 [47:47<49:47,  3.16s/it]                                                  {'loss': 0.4214, 'grad_norm': 24.606172561645508, 'learning_rate': 8.720095693779904e-07, 'rewards/chosen': -0.3218750059604645, 'rewards/rejected': -1.4988281726837158, 'rewards/accuracies': 0.8166667222976685, 'rewards/margins': 1.177734375, 'logps/chosen': -190.8000030517578, 'logps/rejected': -214.10000610351562, 'logits/chosen': -8.699999809265137, 'logits/rejected': -8.378125190734863, 'epoch': 1.31}
 44%|████▎     | 730/1674 [47:47<49:47,  3.16s/it] 44%|████▎     | 731/1674 [47:50<46:32,  2.96s/it] 44%|████▎     | 732/1674 [47:53<47:18,  3.01s/it] 44%|████▍     | 733/1674 [47:57<52:06,  3.32s/it] 44%|████▍     | 734/1674 [48:01<55:36,  3.55s/it] 44%|████▍     | 735/1674 [48:04<54:11,  3.46s/it] 44%|████▍     | 736/1674 [48:08<56:43,  3.63s/it] 44%|████▍     | 737/1674 [48:11<52:07,  3.34s/it] 44%|████▍     | 738/1674 [48:15<55:47,  3.58s/it] 44%|████▍     | 739/1674 [48:18<53:54,  3.46s/it] 44%|████▍     | 740/1674 [48:21<47:44,  3.07s/it]                                                  {'loss': 0.4525, 'grad_norm': 24.345510482788086, 'learning_rate': 8.839712918660287e-07, 'rewards/chosen': -1.123437523841858, 'rewards/rejected': -2.1390624046325684, 'rewards/accuracies': 0.7916666269302368, 'rewards/margins': 1.016015648841858, 'logps/chosen': -120.4000015258789, 'logps/rejected': -145.10000610351562, 'logits/chosen': -8.899999618530273, 'logits/rejected': -8.793749809265137, 'epoch': 1.33}
 44%|████▍     | 740/1674 [48:21<47:44,  3.07s/it] 44%|████▍     | 741/1674 [48:24<51:09,  3.29s/it] 44%|████▍     | 742/1674 [48:27<46:54,  3.02s/it] 44%|████▍     | 743/1674 [48:30<47:50,  3.08s/it] 44%|████▍     | 744/1674 [48:33<49:06,  3.17s/it] 45%|████▍     | 745/1674 [48:37<53:28,  3.45s/it] 45%|████▍     | 746/1674 [48:41<55:03,  3.56s/it] 45%|████▍     | 747/1674 [48:45<54:41,  3.54s/it] 45%|████▍     | 748/1674 [48:48<51:55,  3.36s/it] 45%|████▍     | 749/1674 [48:50<47:09,  3.06s/it] 45%|████▍     | 750/1674 [48:54<52:29,  3.41s/it]                                                  {'loss': 0.4726, 'grad_norm': 36.10186767578125, 'learning_rate': 8.95933014354067e-07, 'rewards/chosen': -1.064843773841858, 'rewards/rejected': -2.1484375, 'rewards/accuracies': 0.73333340883255, 'rewards/margins': 1.0830078125, 'logps/chosen': -125.25, 'logps/rejected': -143.3000030517578, 'logits/chosen': -8.912500381469727, 'logits/rejected': -8.806249618530273, 'epoch': 1.34}
 45%|████▍     | 750/1674 [48:54<52:29,  3.41s/it] 45%|████▍     | 751/1674 [48:58<55:49,  3.63s/it] 45%|████▍     | 752/1674 [49:01<50:15,  3.27s/it] 45%|████▍     | 753/1674 [49:03<46:17,  3.02s/it] 45%|████▌     | 754/1674 [49:06<47:01,  3.07s/it] 45%|████▌     | 755/1674 [49:10<49:32,  3.23s/it] 45%|████▌     | 756/1674 [49:14<53:39,  3.51s/it] 45%|████▌     | 757/1674 [49:18<56:58,  3.73s/it] 45%|████▌     | 758/1674 [49:21<52:24,  3.43s/it] 45%|████▌     | 759/1674 [49:24<49:54,  3.27s/it] 45%|████▌     | 760/1674 [49:26<44:55,  2.95s/it]                                                  {'loss': 0.4488, 'grad_norm': 22.335844039916992, 'learning_rate': 9.078947368421053e-07, 'rewards/chosen': -1.0251953601837158, 'rewards/rejected': -2.081249952316284, 'rewards/accuracies': 0.7500000596046448, 'rewards/margins': 1.0556640625, 'logps/chosen': -119.05000305175781, 'logps/rejected': -145.52499389648438, 'logits/chosen': -9.012499809265137, 'logits/rejected': -8.637499809265137, 'epoch': 1.36}
 45%|████▌     | 760/1674 [49:27<44:55,  2.95s/it] 45%|████▌     | 761/1674 [49:30<49:32,  3.26s/it] 46%|████▌     | 762/1674 [49:34<50:31,  3.32s/it] 46%|████▌     | 763/1674 [49:37<48:24,  3.19s/it] 46%|████▌     | 764/1674 [49:40<50:19,  3.32s/it] 46%|████▌     | 765/1674 [49:44<51:06,  3.37s/it] 46%|████▌     | 766/1674 [49:47<51:46,  3.42s/it] 46%|████▌     | 767/1674 [49:50<50:05,  3.31s/it] 46%|████▌     | 768/1674 [49:54<52:54,  3.50s/it] 46%|████▌     | 769/1674 [49:58<54:16,  3.60s/it] 46%|████▌     | 770/1674 [50:02<55:53,  3.71s/it]                                                  {'loss': 0.4525, 'grad_norm': 26.012914657592773, 'learning_rate': 9.198564593301436e-07, 'rewards/chosen': -1.0304687023162842, 'rewards/rejected': -2.213671922683716, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.181249976158142, 'logps/chosen': -160.0500030517578, 'logps/rejected': -198.8000030517578, 'logits/chosen': -8.806249618530273, 'logits/rejected': -8.496874809265137, 'epoch': 1.38}
 46%|████▌     | 770/1674 [50:02<55:53,  3.71s/it] 46%|████▌     | 771/1674 [50:06<56:02,  3.72s/it] 46%|████▌     | 772/1674 [50:09<54:01,  3.59s/it] 46%|████▌     | 773/1674 [50:13<56:20,  3.75s/it] 46%|████▌     | 774/1674 [50:17<54:59,  3.67s/it] 46%|████▋     | 775/1674 [50:19<50:04,  3.34s/it] 46%|████▋     | 776/1674 [50:23<50:08,  3.35s/it] 46%|████▋     | 777/1674 [50:26<50:40,  3.39s/it] 46%|████▋     | 778/1674 [50:29<47:28,  3.18s/it] 47%|████▋     | 779/1674 [50:33<51:03,  3.42s/it] 47%|████▋     | 780/1674 [50:37<52:46,  3.54s/it]                                                  {'loss': 0.4805, 'grad_norm': 47.58395004272461, 'learning_rate': 9.318181818181817e-07, 'rewards/chosen': -1.03125, 'rewards/rejected': -2.090625047683716, 'rewards/accuracies': 0.7583333253860474, 'rewards/margins': 1.060546875, 'logps/chosen': -161.3000030517578, 'logps/rejected': -195.0, 'logits/chosen': -8.8125, 'logits/rejected': -8.481249809265137, 'epoch': 1.4}
 47%|████▋     | 780/1674 [50:37<52:46,  3.54s/it] 47%|████▋     | 781/1674 [50:40<53:47,  3.61s/it] 47%|████▋     | 782/1674 [50:44<55:10,  3.71s/it] 47%|████▋     | 783/1674 [50:48<53:25,  3.60s/it] 47%|████▋     | 784/1674 [50:50<47:58,  3.23s/it] 47%|████▋     | 785/1674 [50:54<51:24,  3.47s/it] 47%|████▋     | 786/1674 [50:58<52:45,  3.56s/it] 47%|████▋     | 787/1674 [51:02<54:24,  3.68s/it] 47%|████▋     | 788/1674 [51:05<51:49,  3.51s/it] 47%|████▋     | 789/1674 [51:08<48:58,  3.32s/it] 47%|████▋     | 790/1674 [51:11<46:53,  3.18s/it]                                                  {'loss': 0.4851, 'grad_norm': 39.93313980102539, 'learning_rate': 9.4377990430622e-07, 'rewards/chosen': -0.8203125, 'rewards/rejected': -1.9871094226837158, 'rewards/accuracies': 0.76666659116745, 'rewards/margins': 1.165429711341858, 'logps/chosen': -146.14999389648438, 'logps/rejected': -184.1999969482422, 'logits/chosen': -8.962499618530273, 'logits/rejected': -8.712499618530273, 'epoch': 1.42}
 47%|████▋     | 790/1674 [51:11<46:53,  3.18s/it] 47%|████▋     | 791/1674 [51:14<48:17,  3.28s/it] 47%|████▋     | 792/1674 [51:16<43:15,  2.94s/it] 47%|████▋     | 793/1674 [51:19<41:19,  2.81s/it] 47%|████▋     | 794/1674 [51:22<44:13,  3.02s/it] 47%|████▋     | 795/1674 [51:26<45:17,  3.09s/it] 48%|████▊     | 796/1674 [51:29<46:16,  3.16s/it] 48%|████▊     | 797/1674 [51:33<49:57,  3.42s/it] 48%|████▊     | 798/1674 [51:36<49:01,  3.36s/it] 48%|████▊     | 799/1674 [51:39<46:02,  3.16s/it] 48%|████▊     | 800/1674 [51:43<49:26,  3.39s/it]                                                  {'loss': 0.4194, 'grad_norm': 17.880090713500977, 'learning_rate': 9.557416267942584e-07, 'rewards/chosen': -0.786328136920929, 'rewards/rejected': -2.0601563453674316, 'rewards/accuracies': 0.7916666865348816, 'rewards/margins': 1.275390625, 'logps/chosen': -156.5, 'logps/rejected': -186.4499969482422, 'logits/chosen': -9.087499618530273, 'logits/rejected': -8.831250190734863, 'epoch': 1.43}
 48%|████▊     | 800/1674 [51:43<49:26,  3.39s/it] 48%|████▊     | 801/1674 [51:47<53:07,  3.65s/it] 48%|████▊     | 802/1674 [51:50<51:47,  3.56s/it] 48%|████▊     | 803/1674 [51:55<53:59,  3.72s/it] 48%|████▊     | 804/1674 [51:58<53:35,  3.70s/it] 48%|████▊     | 805/1674 [52:01<50:18,  3.47s/it] 48%|████▊     | 806/1674 [52:05<53:04,  3.67s/it] 48%|████▊     | 807/1674 [52:09<51:08,  3.54s/it] 48%|████▊     | 808/1674 [52:11<48:03,  3.33s/it] 48%|████▊     | 809/1674 [52:15<47:40,  3.31s/it] 48%|████▊     | 810/1674 [52:17<42:55,  2.98s/it]                                                  {'loss': 0.5117, 'grad_norm': 33.617889404296875, 'learning_rate': 9.677033492822966e-07, 'rewards/chosen': -1.110937476158142, 'rewards/rejected': -2.160937547683716, 'rewards/accuracies': 0.783333420753479, 'rewards/margins': 1.0490233898162842, 'logps/chosen': -157.5500030517578, 'logps/rejected': -197.0500030517578, 'logits/chosen': -8.975000381469727, 'logits/rejected': -8.699999809265137, 'epoch': 1.45}
 48%|████▊     | 810/1674 [52:17<42:55,  2.98s/it] 48%|████▊     | 811/1674 [52:19<40:55,  2.85s/it] 49%|████▊     | 812/1674 [52:22<39:45,  2.77s/it] 49%|████▊     | 813/1674 [52:26<43:41,  3.04s/it] 49%|████▊     | 814/1674 [52:29<45:49,  3.20s/it] 49%|████▊     | 815/1674 [52:33<48:28,  3.39s/it] 49%|████▊     | 816/1674 [52:37<52:00,  3.64s/it] 49%|████▉     | 817/1674 [52:41<50:27,  3.53s/it] 49%|████▉     | 818/1674 [52:44<49:09,  3.45s/it] 49%|████▉     | 819/1674 [52:48<50:44,  3.56s/it] 49%|████▉     | 820/1674 [52:51<52:01,  3.65s/it]                                                  {'loss': 0.5271, 'grad_norm': 29.276107788085938, 'learning_rate': 9.79665071770335e-07, 'rewards/chosen': -1.3230469226837158, 'rewards/rejected': -2.325000047683716, 'rewards/accuracies': 0.73333340883255, 'rewards/margins': 1.001953125, 'logps/chosen': -121.19999694824219, 'logps/rejected': -149.8000030517578, 'logits/chosen': -9.212499618530273, 'logits/rejected': -8.818750381469727, 'epoch': 1.47}
 49%|████▉     | 820/1674 [52:52<52:01,  3.65s/it] 49%|████▉     | 821/1674 [52:55<52:42,  3.71s/it] 49%|████▉     | 822/1674 [52:59<52:29,  3.70s/it] 49%|████▉     | 823/1674 [53:02<48:33,  3.42s/it] 49%|████▉     | 824/1674 [53:04<44:40,  3.15s/it] 49%|████▉     | 825/1674 [53:07<43:49,  3.10s/it] 49%|████▉     | 826/1674 [53:11<44:46,  3.17s/it] 49%|████▉     | 827/1674 [53:14<46:41,  3.31s/it] 49%|████▉     | 828/1674 [53:18<47:26,  3.36s/it] 50%|████▉     | 829/1674 [53:21<46:59,  3.34s/it] 50%|████▉     | 830/1674 [53:24<46:54,  3.34s/it]                                                  {'loss': 0.3879, 'grad_norm': 13.606471061706543, 'learning_rate': 9.916267942583732e-07, 'rewards/chosen': -0.9986327886581421, 'rewards/rejected': -2.4515624046325684, 'rewards/accuracies': 0.841666579246521, 'rewards/margins': 1.4541015625, 'logps/chosen': -106.3499984741211, 'logps/rejected': -143.75, 'logits/chosen': -9.037500381469727, 'logits/rejected': -8.712499618530273, 'epoch': 1.49}
 50%|████▉     | 830/1674 [53:24<46:54,  3.34s/it] 50%|████▉     | 831/1674 [53:28<47:23,  3.37s/it] 50%|████▉     | 832/1674 [53:32<49:08,  3.50s/it] 50%|████▉     | 833/1674 [53:35<50:26,  3.60s/it] 50%|████▉     | 834/1674 [53:38<47:08,  3.37s/it] 50%|████▉     | 835/1674 [53:42<47:53,  3.42s/it] 50%|████▉     | 836/1674 [53:46<49:32,  3.55s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:57,  1.35it/s][A
  4%|▍         | 3/80 [00:03<01:23,  1.09s/it][A
  5%|▌         | 4/80 [00:04<01:36,  1.26s/it][A
  6%|▋         | 5/80 [00:06<01:44,  1.40s/it][A
  8%|▊         | 6/80 [00:07<01:47,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:49,  1.50s/it][A
 10%|█         | 8/80 [00:11<01:51,  1.54s/it][A
 11%|█▏        | 9/80 [00:12<01:50,  1.56s/it][A
 12%|█▎        | 10/80 [00:14<01:52,  1.60s/it][A
 14%|█▍        | 11/80 [00:16<01:52,  1.62s/it][A
 15%|█▌        | 12/80 [00:17<01:49,  1.61s/it][A
 16%|█▋        | 13/80 [00:19<01:46,  1.60s/it][A
 18%|█▊        | 14/80 [00:20<01:47,  1.64s/it][A
 19%|█▉        | 15/80 [00:22<01:45,  1.62s/it][A
 20%|██        | 16/80 [00:24<01:42,  1.61s/it][A
 21%|██▏       | 17/80 [00:25<01:41,  1.61s/it][A
 22%|██▎       | 18/80 [00:27<01:41,  1.63s/it][A
 24%|██▍       | 19/80 [00:28<01:30,  1.48s/it][A
 25%|██▌       | 20/80 [00:29<01:24,  1.41s/it][A
 26%|██▋       | 21/80 [00:30<01:08,  1.16s/it][A
 28%|██▊       | 22/80 [00:31<01:06,  1.15s/it][A
 29%|██▉       | 23/80 [00:32<01:05,  1.15s/it][A
 30%|███       | 24/80 [00:33<00:53,  1.06it/s][A
 31%|███▏      | 25/80 [00:34<00:55,  1.01s/it][A
 32%|███▎      | 26/80 [00:35<00:58,  1.09s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.03it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.02it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.10s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.06it/s][A
 41%|████▏     | 33/80 [00:42<00:54,  1.15s/it][A
 42%|████▎     | 34/80 [00:44<00:56,  1.24s/it][A
 44%|████▍     | 35/80 [00:44<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.07it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.23it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:48,  1.21s/it][A
 51%|█████▏    | 41/80 [00:50<00:39,  1.02s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.19s/it][A
 54%|█████▍    | 43/80 [00:53<00:46,  1.26s/it][A
 55%|█████▌    | 44/80 [00:55<00:44,  1.25s/it][A
 56%|█████▋    | 45/80 [00:55<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.08it/s][A
 59%|█████▉    | 47/80 [00:57<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:38,  1.19s/it][A
 61%|██████▏   | 49/80 [00:59<00:31,  1.00s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.19it/s][A
 64%|██████▍   | 51/80 [01:01<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:02<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:03<00:26,  1.03it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:05<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.18s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:09<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:10<00:25,  1.21s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.01s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.16s/it][A
 78%|███████▊  | 62/80 [01:14<00:23,  1.33s/it][A
 79%|███████▉  | 63/80 [01:15<00:21,  1.25s/it][A
 80%|████████  | 64/80 [01:16<00:17,  1.12s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.25s/it][A
 82%|████████▎ | 66/80 [01:19<00:18,  1.34s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.44s/it][A
 85%|████████▌ | 68/80 [01:22<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:26<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:28<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:30<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:31<00:06,  1.28s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.37s/it][A
 96%|█████████▋| 77/80 [01:34<00:04,  1.38s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.14s/it][A
 99%|█████████▉| 79/80 [01:36<00:01,  1.27s/it][A
100%|██████████| 80/80 [01:38<00:00,  1.38s/it][A                                                  
                                               [A{'eval_loss': 0.7044281959533691, 'eval_runtime': 100.2455, 'eval_samples_per_second': 9.507, 'eval_steps_per_second': 0.798, 'eval_rewards/chosen': 0.703381359577179, 'eval_rewards/rejected': -0.8285125494003296, 'eval_rewards/accuracies': 0.7462500333786011, 'eval_rewards/margins': 1.5301421880722046, 'eval_logps/chosen': -370.953125, 'eval_logps/rejected': -161.5031280517578, 'eval_logits/chosen': -8.185937881469727, 'eval_logits/rejected': -8.559765815734863, 'epoch': 1.5}
 50%|████▉     | 836/1674 [55:26<49:32,  3.55s/it]
100%|██████████| 80/80 [01:38<00:00,  1.38s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 50%|█████     | 837/1674 [55:42<8:41:19, 37.37s/it] 50%|█████     | 838/1674 [55:46<6:20:33, 27.31s/it] 50%|█████     | 839/1674 [55:48<4:35:54, 19.83s/it] 50%|█████     | 840/1674 [55:52<3:28:28, 15.00s/it]                                                    {'loss': 0.3965, 'grad_norm': 18.578794479370117, 'learning_rate': 9.999715401794169e-07, 'rewards/chosen': -1.1902344226837158, 'rewards/rejected': -2.475781202316284, 'rewards/accuracies': 0.8333333134651184, 'rewards/margins': 1.28515625, 'logps/chosen': -109.69999694824219, 'logps/rejected': -164.64999389648438, 'logits/chosen': -8.818750381469727, 'logits/rejected': -8.53125, 'epoch': 1.51}
 50%|█████     | 840/1674 [55:52<3:28:28, 15.00s/it] 50%|█████     | 841/1674 [55:56<2:42:07, 11.68s/it] 50%|█████     | 842/1674 [55:59<2:08:07,  9.24s/it] 50%|█████     | 843/1674 [56:03<1:46:10,  7.67s/it] 50%|█████     | 844/1674 [56:08<1:31:57,  6.65s/it] 50%|█████     | 845/1674 [56:12<1:21:14,  5.88s/it] 51%|█████     | 846/1674 [56:16<1:12:43,  5.27s/it] 51%|█████     | 847/1674 [56:20<1:08:08,  4.94s/it] 51%|█████     | 848/1674 [56:24<1:05:11,  4.74s/it] 51%|█████     | 849/1674 [56:27<59:53,  4.36s/it]   51%|█████     | 850/1674 [56:31<58:05,  4.23s/it]                                                  {'loss': 0.4612, 'grad_norm': 47.876808166503906, 'learning_rate': 9.994656879506313e-07, 'rewards/chosen': -1.134374976158142, 'rewards/rejected': -2.453906297683716, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.31884765625, 'logps/chosen': -119.94999694824219, 'logps/rejected': -155.5, 'logits/chosen': -8.96875, 'logits/rejected': -8.5, 'epoch': 1.52}
 51%|█████     | 850/1674 [56:31<58:05,  4.23s/it] 51%|█████     | 851/1674 [56:34<51:52,  3.78s/it] 51%|█████     | 852/1674 [56:37<47:34,  3.47s/it] 51%|█████     | 853/1674 [56:41<49:17,  3.60s/it] 51%|█████     | 854/1674 [56:44<45:53,  3.36s/it] 51%|█████     | 855/1674 [56:47<46:56,  3.44s/it] 51%|█████     | 856/1674 [56:50<46:04,  3.38s/it] 51%|█████     | 857/1674 [56:54<47:25,  3.48s/it] 51%|█████▏    | 858/1674 [56:57<42:58,  3.16s/it] 51%|█████▏    | 859/1674 [57:01<46:32,  3.43s/it] 51%|█████▏    | 860/1674 [57:05<48:51,  3.60s/it]                                                  {'loss': 0.3951, 'grad_norm': 18.90534782409668, 'learning_rate': 9.983282135211588e-07, 'rewards/chosen': -0.8335937261581421, 'rewards/rejected': -2.2085938453674316, 'rewards/accuracies': 0.8166667222976685, 'rewards/margins': 1.3738281726837158, 'logps/chosen': -157.4499969482422, 'logps/rejected': -186.10000610351562, 'logits/chosen': -8.912500381469727, 'logits/rejected': -8.606249809265137, 'epoch': 1.54}
 51%|█████▏    | 860/1674 [57:05<48:51,  3.60s/it] 51%|█████▏    | 861/1674 [57:08<48:03,  3.55s/it] 51%|█████▏    | 862/1674 [57:12<48:52,  3.61s/it] 52%|█████▏    | 863/1674 [57:15<46:27,  3.44s/it] 52%|█████▏    | 864/1674 [57:19<48:11,  3.57s/it] 52%|█████▏    | 865/1674 [57:22<47:52,  3.55s/it] 52%|█████▏    | 866/1674 [57:26<49:02,  3.64s/it] 52%|█████▏    | 867/1674 [57:30<50:55,  3.79s/it] 52%|█████▏    | 868/1674 [57:33<48:54,  3.64s/it] 52%|█████▏    | 869/1674 [57:38<50:56,  3.80s/it] 52%|█████▏    | 870/1674 [57:40<46:36,  3.48s/it]                                                  {'loss': 0.4172, 'grad_norm': 28.08668327331543, 'learning_rate': 9.965607153536225e-07, 'rewards/chosen': -1.3777344226837158, 'rewards/rejected': -2.778125047683716, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.400781273841858, 'logps/chosen': -116.1500015258789, 'logps/rejected': -171.64999389648438, 'logits/chosen': -9.037500381469727, 'logits/rejected': -8.518750190734863, 'epoch': 1.56}
 52%|█████▏    | 870/1674 [57:40<46:36,  3.48s/it] 52%|█████▏    | 871/1674 [57:45<49:34,  3.70s/it] 52%|█████▏    | 872/1674 [57:48<49:22,  3.69s/it] 52%|█████▏    | 873/1674 [57:52<50:29,  3.78s/it] 52%|█████▏    | 874/1674 [57:56<50:24,  3.78s/it] 52%|█████▏    | 875/1674 [57:59<46:59,  3.53s/it] 52%|█████▏    | 876/1674 [58:01<40:41,  3.06s/it] 52%|█████▏    | 877/1674 [58:05<45:07,  3.40s/it] 52%|█████▏    | 878/1674 [58:08<43:09,  3.25s/it] 53%|█████▎    | 879/1674 [58:11<42:09,  3.18s/it] 53%|█████▎    | 880/1674 [58:14<39:13,  2.96s/it]                                                  {'loss': 0.4126, 'grad_norm': 18.793119430541992, 'learning_rate': 9.941656772662803e-07, 'rewards/chosen': -1.234375, 'rewards/rejected': -2.6796875, 'rewards/accuracies': 0.8083332777023315, 'rewards/margins': 1.445703148841858, 'logps/chosen': -115.19999694824219, 'logps/rejected': -147.75, 'logits/chosen': -9.125, 'logits/rejected': -8.925000190734863, 'epoch': 1.58}
 53%|█████▎    | 880/1674 [58:14<39:13,  2.96s/it] 53%|█████▎    | 881/1674 [58:17<39:32,  2.99s/it] 53%|█████▎    | 882/1674 [58:21<43:15,  3.28s/it] 53%|█████▎    | 883/1674 [58:24<45:30,  3.45s/it] 53%|█████▎    | 884/1674 [58:27<41:06,  3.12s/it] 53%|█████▎    | 885/1674 [58:31<43:50,  3.33s/it] 53%|█████▎    | 886/1674 [58:35<47:09,  3.59s/it] 53%|█████▎    | 887/1674 [58:39<49:13,  3.75s/it] 53%|█████▎    | 888/1674 [58:42<46:52,  3.58s/it] 53%|█████▎    | 889/1674 [58:45<43:55,  3.36s/it] 53%|█████▎    | 890/1674 [58:48<44:22,  3.40s/it]                                                  {'loss': 0.5237, 'grad_norm': 46.589874267578125, 'learning_rate': 9.911464649425828e-07, 'rewards/chosen': -1.465234398841858, 'rewards/rejected': -2.5234375, 'rewards/accuracies': 0.7666667103767395, 'rewards/margins': 1.0558350086212158, 'logps/chosen': -120.3499984741211, 'logps/rejected': -144.9499969482422, 'logits/chosen': -9.074999809265137, 'logits/rejected': -8.962499618530273, 'epoch': 1.59}
 53%|█████▎    | 890/1674 [58:48<44:22,  3.40s/it] 53%|█████▎    | 891/1674 [58:51<42:26,  3.25s/it] 53%|█████▎    | 892/1674 [58:55<44:27,  3.41s/it] 53%|█████▎    | 893/1674 [58:58<41:35,  3.20s/it] 53%|█████▎    | 894/1674 [59:01<42:57,  3.31s/it] 53%|█████▎    | 895/1674 [59:05<43:17,  3.33s/it] 54%|█████▎    | 896/1674 [59:08<43:59,  3.39s/it] 54%|█████▎    | 897/1674 [59:12<45:39,  3.53s/it] 54%|█████▎    | 898/1674 [59:14<39:41,  3.07s/it] 54%|█████▎    | 899/1674 [59:17<37:15,  2.88s/it] 54%|█████▍    | 900/1674 [59:20<37:39,  2.92s/it]                                                  {'loss': 0.4768, 'grad_norm': 22.562726974487305, 'learning_rate': 9.875073212014668e-07, 'rewards/chosen': -1.4265625476837158, 'rewards/rejected': -2.7710938453674316, 'rewards/accuracies': 0.7833333611488342, 'rewards/margins': 1.3425781726837158, 'logps/chosen': -116.69999694824219, 'logps/rejected': -154.0500030517578, 'logits/chosen': -8.987500190734863, 'logits/rejected': -8.675000190734863, 'epoch': 1.61}
 54%|█████▍    | 900/1674 [59:20<37:39,  2.92s/it] 54%|█████▍    | 901/1674 [59:24<42:33,  3.30s/it] 54%|█████▍    | 902/1674 [59:28<44:22,  3.45s/it] 54%|█████▍    | 903/1674 [59:30<40:45,  3.17s/it] 54%|█████▍    | 904/1674 [59:34<43:01,  3.35s/it] 54%|█████▍    | 905/1674 [59:38<46:01,  3.59s/it] 54%|█████▍    | 906/1674 [59:40<39:46,  3.11s/it] 54%|█████▍    | 907/1674 [59:42<37:03,  2.90s/it] 54%|█████▍    | 908/1674 [59:46<40:08,  3.14s/it] 54%|█████▍    | 909/1674 [59:50<42:44,  3.35s/it] 54%|█████▍    | 910/1674 [59:53<43:08,  3.39s/it]                                                  {'loss': 0.4506, 'grad_norm': 45.97825622558594, 'learning_rate': 9.832533600350345e-07, 'rewards/chosen': -0.9859374761581421, 'rewards/rejected': -2.5132813453674316, 'rewards/accuracies': 0.7916666269302368, 'rewards/margins': 1.5300781726837158, 'logps/chosen': -157.89999389648438, 'logps/rejected': -170.10000610351562, 'logits/chosen': -8.731249809265137, 'logits/rejected': -8.524999618530273, 'epoch': 1.63}
 54%|█████▍    | 910/1674 [59:53<43:08,  3.39s/it] 54%|█████▍    | 911/1674 [59:55<38:02,  2.99s/it] 54%|█████▍    | 912/1674 [59:59<41:02,  3.23s/it] 55%|█████▍    | 913/1674 [1:00:03<42:46,  3.37s/it] 55%|█████▍    | 914/1674 [1:00:07<45:32,  3.59s/it] 55%|█████▍    | 915/1674 [1:00:10<44:09,  3.49s/it] 55%|█████▍    | 916/1674 [1:00:13<41:46,  3.31s/it] 55%|█████▍    | 917/1674 [1:00:16<41:29,  3.29s/it] 55%|█████▍    | 918/1674 [1:00:20<40:34,  3.22s/it] 55%|█████▍    | 919/1674 [1:00:23<40:25,  3.21s/it] 55%|█████▍    | 920/1674 [1:00:26<39:03,  3.11s/it]                                                    {'loss': 0.4387, 'grad_norm': 9.83222484588623, 'learning_rate': 9.783905594219962e-07, 'rewards/chosen': -1.3562500476837158, 'rewards/rejected': -2.723437547683716, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.368261694908142, 'logps/chosen': -107.8499984741211, 'logps/rejected': -166.0500030517578, 'logits/chosen': -9.112500190734863, 'logits/rejected': -8.768750190734863, 'epoch': 1.65}
 55%|█████▍    | 920/1674 [1:00:26<39:03,  3.11s/it] 55%|█████▌    | 921/1674 [1:00:29<42:02,  3.35s/it] 55%|█████▌    | 922/1674 [1:00:32<40:38,  3.24s/it] 55%|█████▌    | 923/1674 [1:00:36<43:25,  3.47s/it] 55%|█████▌    | 924/1674 [1:00:40<45:01,  3.60s/it] 55%|█████▌    | 925/1674 [1:00:44<43:20,  3.47s/it] 55%|█████▌    | 926/1674 [1:00:46<40:59,  3.29s/it] 55%|█████▌    | 927/1674 [1:00:49<39:53,  3.20s/it] 55%|█████▌    | 928/1674 [1:00:53<42:25,  3.41s/it] 55%|█████▌    | 929/1674 [1:00:56<41:20,  3.33s/it] 56%|█████▌    | 930/1674 [1:01:00<41:11,  3.32s/it]                                                    {'loss': 0.4967, 'grad_norm': 24.54778480529785, 'learning_rate': 9.729257529269751e-07, 'rewards/chosen': -1.1144530773162842, 'rewards/rejected': -2.309375047683716, 'rewards/accuracies': 0.7666666507720947, 'rewards/margins': 1.1964843273162842, 'logps/chosen': -170.5, 'logps/rejected': -211.4499969482422, 'logits/chosen': -9.162500381469727, 'logits/rejected': -8.787500381469727, 'epoch': 1.67}
 56%|█████▌    | 930/1674 [1:01:00<41:11,  3.32s/it] 56%|█████▌    | 931/1674 [1:01:03<40:56,  3.31s/it] 56%|█████▌    | 932/1674 [1:01:05<35:51,  2.90s/it] 56%|█████▌    | 933/1674 [1:01:09<39:29,  3.20s/it] 56%|█████▌    | 934/1674 [1:01:13<42:55,  3.48s/it] 56%|█████▌    | 935/1674 [1:01:17<43:39,  3.54s/it] 56%|█████▌    | 936/1674 [1:01:20<41:28,  3.37s/it] 56%|█████▌    | 937/1674 [1:01:23<39:42,  3.23s/it] 56%|█████▌    | 938/1674 [1:01:27<43:03,  3.51s/it] 56%|█████▌    | 939/1674 [1:01:31<45:17,  3.70s/it] 56%|█████▌    | 940/1674 [1:01:35<45:06,  3.69s/it]                                                    {'loss': 0.4751, 'grad_norm': 67.24052429199219, 'learning_rate': 9.66866620097482e-07, 'rewards/chosen': -1.3816406726837158, 'rewards/rejected': -2.651562452316284, 'rewards/accuracies': 0.7916666865348816, 'rewards/margins': 1.2703125476837158, 'logps/chosen': -126.3499984741211, 'logps/rejected': -144.1999969482422, 'logits/chosen': -9.143750190734863, 'logits/rejected': -9.037500381469727, 'epoch': 1.68}
 56%|█████▌    | 940/1674 [1:01:35<45:06,  3.69s/it] 56%|█████▌    | 941/1674 [1:01:38<45:39,  3.74s/it] 56%|█████▋    | 942/1674 [1:01:41<41:20,  3.39s/it] 56%|█████▋    | 943/1674 [1:01:44<40:56,  3.36s/it] 56%|█████▋    | 944/1674 [1:01:48<42:35,  3.50s/it] 56%|█████▋    | 945/1674 [1:01:52<44:54,  3.70s/it] 57%|█████▋    | 946/1674 [1:01:56<44:51,  3.70s/it] 57%|█████▋    | 947/1674 [1:02:00<45:47,  3.78s/it] 57%|█████▋    | 948/1674 [1:02:04<46:17,  3.83s/it] 57%|█████▋    | 949/1674 [1:02:07<44:41,  3.70s/it] 57%|█████▋    | 950/1674 [1:02:11<43:03,  3.57s/it]                                                    {'loss': 0.4136, 'grad_norm': 26.088043212890625, 'learning_rate': 9.602216756720481e-07, 'rewards/chosen': -1.2277343273162842, 'rewards/rejected': -2.565234422683716, 'rewards/accuracies': 0.7916666865348816, 'rewards/margins': 1.3371093273162842, 'logps/chosen': -150.85000610351562, 'logps/rejected': -193.60000610351562, 'logits/chosen': -8.949999809265137, 'logits/rejected': -8.631250381469727, 'epoch': 1.7}
 57%|█████▋    | 950/1674 [1:02:11<43:03,  3.57s/it] 57%|█████▋    | 951/1674 [1:02:15<45:29,  3.78s/it] 57%|█████▋    | 952/1674 [1:02:18<44:33,  3.70s/it] 57%|█████▋    | 953/1674 [1:02:22<45:10,  3.76s/it] 57%|█████▋    | 954/1674 [1:02:25<43:15,  3.60s/it] 57%|█████▋    | 955/1674 [1:02:29<43:09,  3.60s/it] 57%|█████▋    | 956/1674 [1:02:33<44:22,  3.71s/it] 57%|█████▋    | 957/1674 [1:02:36<42:38,  3.57s/it] 57%|█████▋    | 958/1674 [1:02:40<43:42,  3.66s/it] 57%|█████▋    | 959/1674 [1:02:43<40:09,  3.37s/it] 57%|█████▋    | 960/1674 [1:02:45<37:36,  3.16s/it]                                                    {'loss': 0.4138, 'grad_norm': 27.203739166259766, 'learning_rate': 9.530002576146917e-07, 'rewards/chosen': -1.384374976158142, 'rewards/rejected': -2.735156297683716, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.351171851158142, 'logps/chosen': -115.5, 'logps/rejected': -163.0500030517578, 'logits/chosen': -9.21875, 'logits/rejected': -8.824999809265137, 'epoch': 1.72}
 57%|█████▋    | 960/1674 [1:02:46<37:36,  3.16s/it] 57%|█████▋    | 961/1674 [1:02:48<35:25,  2.98s/it] 57%|█████▋    | 962/1674 [1:02:51<34:55,  2.94s/it] 58%|█████▊    | 963/1674 [1:02:55<39:06,  3.30s/it] 58%|█████▊    | 964/1674 [1:02:59<42:29,  3.59s/it] 58%|█████▊    | 965/1674 [1:03:03<41:34,  3.52s/it] 58%|█████▊    | 966/1674 [1:03:05<36:50,  3.12s/it] 58%|█████▊    | 967/1674 [1:03:09<41:21,  3.51s/it] 58%|█████▊    | 968/1674 [1:03:11<36:16,  3.08s/it] 58%|█████▊    | 969/1674 [1:03:15<36:46,  3.13s/it] 58%|█████▊    | 970/1674 [1:03:19<40:51,  3.48s/it]                                                    {'loss': 0.3998, 'grad_norm': 30.430564880371094, 'learning_rate': 9.452125139925241e-07, 'rewards/chosen': -1.456640601158142, 'rewards/rejected': -2.89453125, 'rewards/accuracies': 0.8166667222976685, 'rewards/margins': 1.437890648841858, 'logps/chosen': -118.55000305175781, 'logps/rejected': -164.1999969482422, 'logits/chosen': -9.09375, 'logits/rejected': -8.850000381469727, 'epoch': 1.74}
 58%|█████▊    | 970/1674 [1:03:19<40:51,  3.48s/it] 58%|█████▊    | 971/1674 [1:03:23<43:13,  3.69s/it] 58%|█████▊    | 972/1674 [1:03:26<40:00,  3.42s/it] 58%|█████▊    | 973/1674 [1:03:29<37:18,  3.19s/it] 58%|█████▊    | 974/1674 [1:03:32<39:49,  3.41s/it] 58%|█████▊    | 975/1674 [1:03:37<42:37,  3.66s/it] 58%|█████▊    | 976/1674 [1:03:41<43:54,  3.77s/it] 58%|█████▊    | 977/1674 [1:03:45<44:21,  3.82s/it] 58%|█████▊    | 978/1674 [1:03:48<41:58,  3.62s/it] 58%|█████▊    | 979/1674 [1:03:50<38:27,  3.32s/it] 59%|█████▊    | 980/1674 [1:03:54<40:26,  3.50s/it]                                                    {'loss': 0.3489, 'grad_norm': 50.39535903930664, 'learning_rate': 9.368693887149401e-07, 'rewards/chosen': -0.88671875, 'rewards/rejected': -2.6500000953674316, 'rewards/accuracies': 0.8333333134651184, 'rewards/margins': 1.7664062976837158, 'logps/chosen': -147.5, 'logps/rejected': -215.8000030517578, 'logits/chosen': -9.318750381469727, 'logits/rejected': -8.868749618530273, 'epoch': 1.76}
 59%|█████▊    | 980/1674 [1:03:54<40:26,  3.50s/it] 59%|█████▊    | 981/1674 [1:03:58<41:12,  3.57s/it] 59%|█████▊    | 982/1674 [1:04:02<43:22,  3.76s/it] 59%|█████▊    | 983/1674 [1:04:05<40:45,  3.54s/it] 59%|█████▉    | 984/1674 [1:04:09<41:33,  3.61s/it] 59%|█████▉    | 985/1674 [1:04:12<38:49,  3.38s/it] 59%|█████▉    | 986/1674 [1:04:16<40:30,  3.53s/it] 59%|█████▉    | 987/1674 [1:04:19<40:09,  3.51s/it] 59%|█████▉    | 988/1674 [1:04:23<40:01,  3.50s/it] 59%|█████▉    | 989/1674 [1:04:26<39:36,  3.47s/it] 59%|█████▉    | 990/1674 [1:04:30<40:47,  3.58s/it]                                                    {'loss': 0.4275, 'grad_norm': 41.203880310058594, 'learning_rate': 9.279826061544326e-07, 'rewards/chosen': -1.4929687976837158, 'rewards/rejected': -2.9625000953674316, 'rewards/accuracies': 0.8333333730697632, 'rewards/margins': 1.466796875, 'logps/chosen': -132.5500030517578, 'logps/rejected': -160.75, 'logits/chosen': -9.287500381469727, 'logits/rejected': -9.006250381469727, 'epoch': 1.77}
 59%|█████▉    | 990/1674 [1:04:30<40:47,  3.58s/it] 59%|█████▉    | 991/1674 [1:04:34<40:34,  3.56s/it] 59%|█████▉    | 992/1674 [1:04:37<40:44,  3.58s/it] 59%|█████▉    | 993/1674 [1:04:41<40:32,  3.57s/it] 59%|█████▉    | 994/1674 [1:04:45<42:03,  3.71s/it] 59%|█████▉    | 995/1674 [1:04:47<38:47,  3.43s/it] 59%|█████▉    | 996/1674 [1:04:50<35:44,  3.16s/it] 60%|█████▉    | 997/1674 [1:04:52<32:35,  2.89s/it] 60%|█████▉    | 998/1674 [1:04:56<35:59,  3.20s/it] 60%|█████▉    | 999/1674 [1:04:59<35:25,  3.15s/it] 60%|█████▉    | 1000/1674 [1:05:03<37:52,  3.37s/it]                                                     {'loss': 0.4655, 'grad_norm': 45.43944549560547, 'learning_rate': 9.18564654670644e-07, 'rewards/chosen': -1.400390625, 'rewards/rejected': -2.58984375, 'rewards/accuracies': 0.7583333253860474, 'rewards/margins': 1.1902344226837158, 'logps/chosen': -124.0999984741211, 'logps/rejected': -137.4499969482422, 'logits/chosen': -9.037500381469727, 'logits/rejected': -9.043749809265137, 'epoch': 1.79}
 60%|█████▉    | 1000/1674 [1:05:03<37:52,  3.37s/it] 60%|█████▉    | 1001/1674 [1:05:06<35:34,  3.17s/it] 60%|█████▉    | 1002/1674 [1:05:09<35:48,  3.20s/it] 60%|█████▉    | 1003/1674 [1:05:12<35:50,  3.20s/it] 60%|█████▉    | 1004/1674 [1:05:15<33:59,  3.04s/it] 60%|██████    | 1005/1674 [1:05:19<35:44,  3.21s/it] 60%|██████    | 1006/1674 [1:05:23<38:32,  3.46s/it] 60%|██████    | 1007/1674 [1:05:27<40:36,  3.65s/it] 60%|██████    | 1008/1674 [1:05:31<41:28,  3.74s/it] 60%|██████    | 1009/1674 [1:05:34<40:23,  3.64s/it] 60%|██████    | 1010/1674 [1:05:38<41:46,  3.77s/it]                                                     {'loss': 0.3432, 'grad_norm': 24.493316650390625, 'learning_rate': 9.086287690608047e-07, 'rewards/chosen': -0.655078113079071, 'rewards/rejected': -2.2445311546325684, 'rewards/accuracies': 0.85833340883255, 'rewards/margins': 1.5906250476837158, 'logps/chosen': -173.4499969482422, 'logps/rejected': -198.60000610351562, 'logits/chosen': -9.024999618530273, 'logits/rejected': -8.931249618530273, 'epoch': 1.81}
 60%|██████    | 1010/1674 [1:05:38<41:46,  3.77s/it] 60%|██████    | 1011/1674 [1:05:41<38:07,  3.45s/it] 60%|██████    | 1012/1674 [1:05:45<39:47,  3.61s/it] 61%|██████    | 1013/1674 [1:05:47<35:48,  3.25s/it] 61%|██████    | 1014/1674 [1:05:51<36:04,  3.28s/it] 61%|██████    | 1015/1674 [1:05:54<38:04,  3.47s/it] 61%|██████    | 1016/1674 [1:05:58<39:30,  3.60s/it] 61%|██████    | 1017/1674 [1:06:02<40:22,  3.69s/it] 61%|██████    | 1018/1674 [1:06:05<38:21,  3.51s/it] 61%|██████    | 1019/1674 [1:06:08<35:38,  3.27s/it] 61%|██████    | 1020/1674 [1:06:12<37:38,  3.45s/it]                                                     {'loss': 0.5967, 'grad_norm': 27.833677291870117, 'learning_rate': 8.981889119612248e-07, 'rewards/chosen': -1.1554687023162842, 'rewards/rejected': -2.401171922683716, 'rewards/accuracies': 0.7333333492279053, 'rewards/margins': 1.248046875, 'logps/chosen': -159.6999969482422, 'logps/rejected': -190.5, 'logits/chosen': -9.100000381469727, 'logits/rejected': -8.949999809265137, 'epoch': 1.83}
 61%|██████    | 1020/1674 [1:06:12<37:38,  3.45s/it] 61%|██████    | 1021/1674 [1:06:15<37:35,  3.45s/it] 61%|██████    | 1022/1674 [1:06:19<37:01,  3.41s/it] 61%|██████    | 1023/1674 [1:06:22<37:04,  3.42s/it] 61%|██████    | 1024/1674 [1:06:25<34:53,  3.22s/it] 61%|██████    | 1025/1674 [1:06:29<36:14,  3.35s/it] 61%|██████▏   | 1026/1674 [1:06:31<34:02,  3.15s/it] 61%|██████▏   | 1027/1674 [1:06:34<34:10,  3.17s/it] 61%|██████▏   | 1028/1674 [1:06:38<36:36,  3.40s/it] 61%|██████▏   | 1029/1674 [1:06:41<35:30,  3.30s/it] 62%|██████▏   | 1030/1674 [1:06:45<35:01,  3.26s/it]                                                     {'loss': 0.3734, 'grad_norm': 32.94118881225586, 'learning_rate': 8.872597542259714e-07, 'rewards/chosen': -1.4716796875, 'rewards/rejected': -3.1484375, 'rewards/accuracies': 0.85833340883255, 'rewards/margins': 1.679296851158142, 'logps/chosen': -130.85000610351562, 'logps/rejected': -161.0500030517578, 'logits/chosen': -9.162500381469727, 'logits/rejected': -8.899999618530273, 'epoch': 1.85}
 62%|██████▏   | 1030/1674 [1:06:45<35:01,  3.26s/it] 62%|██████▏   | 1031/1674 [1:06:48<35:12,  3.28s/it] 62%|██████▏   | 1032/1674 [1:06:51<34:46,  3.25s/it] 62%|██████▏   | 1033/1674 [1:06:54<32:13,  3.02s/it] 62%|██████▏   | 1034/1674 [1:06:57<34:48,  3.26s/it] 62%|██████▏   | 1035/1674 [1:07:02<37:42,  3.54s/it] 62%|██████▏   | 1036/1674 [1:07:05<38:13,  3.60s/it] 62%|██████▏   | 1037/1674 [1:07:08<34:34,  3.26s/it] 62%|██████▏   | 1038/1674 [1:07:11<34:33,  3.26s/it] 62%|██████▏   | 1039/1674 [1:07:15<36:39,  3.46s/it] 62%|██████▏   | 1040/1674 [1:07:18<33:44,  3.19s/it]                                                     {'loss': 0.5033, 'grad_norm': 21.14552879333496, 'learning_rate': 8.75856654310307e-07, 'rewards/chosen': -1.255859375, 'rewards/rejected': -2.6875, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.429296851158142, 'logps/chosen': -157.5500030517578, 'logps/rejected': -180.89999389648438, 'logits/chosen': -8.975000381469727, 'logits/rejected': -8.78125, 'epoch': 1.86}
 62%|██████▏   | 1040/1674 [1:07:18<33:44,  3.19s/it] 62%|██████▏   | 1041/1674 [1:07:22<36:12,  3.43s/it] 62%|██████▏   | 1042/1674 [1:07:24<33:00,  3.13s/it] 62%|██████▏   | 1043/1674 [1:07:27<33:16,  3.16s/it] 62%|██████▏   | 1044/1674 [1:07:31<36:11,  3.45s/it] 62%|██████▏   | 1045/1674 [1:07:35<36:25,  3.48s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:57,  1.35it/s][A
  4%|▍         | 3/80 [00:03<01:23,  1.09s/it][A
  5%|▌         | 4/80 [00:04<01:36,  1.26s/it][A
  6%|▋         | 5/80 [00:06<01:48,  1.44s/it][A
  8%|▊         | 6/80 [00:08<01:49,  1.48s/it][A
  9%|▉         | 7/80 [00:09<01:54,  1.56s/it][A
 10%|█         | 8/80 [00:11<01:54,  1.59s/it][A
 11%|█▏        | 9/80 [00:13<01:54,  1.61s/it][A
 12%|█▎        | 10/80 [00:14<01:54,  1.64s/it][A
 14%|█▍        | 11/80 [00:16<01:54,  1.66s/it][A
 15%|█▌        | 12/80 [00:18<01:50,  1.63s/it][A
 16%|█▋        | 13/80 [00:19<01:47,  1.61s/it][A
 18%|█▊        | 14/80 [00:21<01:48,  1.65s/it][A
 19%|█▉        | 15/80 [00:22<01:46,  1.64s/it][A
 20%|██        | 16/80 [00:24<01:43,  1.62s/it][A
 21%|██▏       | 17/80 [00:26<01:41,  1.62s/it][A
 22%|██▎       | 18/80 [00:27<01:40,  1.63s/it][A
 24%|██▍       | 19/80 [00:28<01:29,  1.47s/it][A
 25%|██▌       | 20/80 [00:30<01:24,  1.41s/it][A
 26%|██▋       | 21/80 [00:30<01:08,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:06,  1.15s/it][A
 29%|██▉       | 23/80 [00:33<01:07,  1.19s/it][A
 30%|███       | 24/80 [00:33<00:54,  1.03it/s][A
 31%|███▏      | 25/80 [00:34<00:56,  1.03s/it][A
 32%|███▎      | 26/80 [00:36<00:59,  1.10s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.02it/s][A
 35%|███▌      | 28/80 [00:37<00:54,  1.05s/it][A
 36%|███▋      | 29/80 [00:39<00:57,  1.12s/it][A
 38%|███▊      | 30/80 [00:40<00:56,  1.13s/it][A
 39%|███▉      | 31/80 [00:41<00:54,  1.12s/it][A
 40%|████      | 32/80 [00:42<00:46,  1.04it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.17s/it][A
 42%|████▎     | 34/80 [00:45<00:57,  1.25s/it][A
 44%|████▍     | 35/80 [00:45<00:45,  1.02s/it][A
 45%|████▌     | 36/80 [00:46<00:41,  1.06it/s][A
 46%|████▋     | 37/80 [00:47<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.22it/s][A
 49%|████▉     | 39/80 [00:49<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:51<00:49,  1.23s/it][A
 51%|█████▏    | 41/80 [00:51<00:40,  1.03s/it][A
 52%|█████▎    | 42/80 [00:53<00:45,  1.19s/it][A
 54%|█████▍    | 43/80 [00:54<00:46,  1.27s/it][A
 55%|█████▌    | 44/80 [00:55<00:45,  1.26s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.13s/it][A
 57%|█████▊    | 46/80 [00:57<00:31,  1.07it/s][A
 59%|█████▉    | 47/80 [00:58<00:35,  1.09s/it][A
 60%|██████    | 48/80 [01:00<00:38,  1.20s/it][A
 61%|██████▏   | 49/80 [01:00<00:31,  1.02s/it][A
 62%|██████▎   | 50/80 [01:01<00:25,  1.16it/s][A
 64%|██████▍   | 51/80 [01:02<00:31,  1.08s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.10s/it][A
 66%|██████▋   | 53/80 [01:04<00:26,  1.01it/s][A
 68%|██████▊   | 54/80 [01:06<00:29,  1.13s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.03s/it][A
 70%|███████   | 56/80 [01:08<00:28,  1.20s/it][A
 71%|███████▏  | 57/80 [01:09<00:23,  1.03s/it][A
 72%|███████▎  | 58/80 [01:10<00:25,  1.17s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.23s/it][A
 75%|███████▌  | 60/80 [01:12<00:20,  1.02s/it][A
 76%|███████▋  | 61/80 [01:14<00:22,  1.18s/it][A
 78%|███████▊  | 62/80 [01:15<00:24,  1.34s/it][A
 79%|███████▉  | 63/80 [01:16<00:21,  1.26s/it][A
 80%|████████  | 64/80 [01:17<00:18,  1.13s/it][A
 81%|████████▏ | 65/80 [01:19<00:18,  1.24s/it][A
 82%|████████▎ | 66/80 [01:20<00:18,  1.34s/it][A
 84%|████████▍ | 67/80 [01:22<00:18,  1.44s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:25<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:26<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:27<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:29<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:31<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:32<00:06,  1.28s/it][A
 95%|█████████▌| 76/80 [01:34<00:05,  1.36s/it][A
 96%|█████████▋| 77/80 [01:35<00:04,  1.39s/it][A
 98%|█████████▊| 78/80 [01:36<00:02,  1.15s/it][A
 99%|█████████▉| 79/80 [01:37<00:01,  1.28s/it][A
100%|██████████| 80/80 [01:39<00:00,  1.38s/it][A                                                     
                                               [A{'eval_loss': 0.6752243041992188, 'eval_runtime': 101.3521, 'eval_samples_per_second': 9.403, 'eval_steps_per_second': 0.789, 'eval_rewards/chosen': 0.6218963861465454, 'eval_rewards/rejected': -1.2351105213165283, 'eval_rewards/accuracies': 0.768541693687439, 'eval_rewards/margins': 1.8576233386993408, 'eval_logps/chosen': -371.6000061035156, 'eval_logps/rejected': -165.6218719482422, 'eval_logits/chosen': -8.395312309265137, 'eval_logits/rejected': -8.691015243530273, 'epoch': 1.87}
 62%|██████▏   | 1045/1674 [1:09:16<36:25,  3.48s/it]
100%|██████████| 80/80 [01:39<00:00,  1.38s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 62%|██████▏   | 1046/1674 [1:09:34<6:38:35, 38.08s/it] 63%|██████▎   | 1047/1674 [1:09:38<4:50:44, 27.82s/it] 63%|██████▎   | 1048/1674 [1:09:40<3:31:59, 20.32s/it] 63%|██████▎   | 1049/1674 [1:09:44<2:40:25, 15.40s/it] 63%|██████▎   | 1050/1674 [1:09:48<2:04:20, 11.96s/it]                                                       {'loss': 0.4498, 'grad_norm': 12.00690746307373, 'learning_rate': 8.639956366878594e-07, 'rewards/chosen': -0.842968761920929, 'rewards/rejected': -2.340625047683716, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.498632788658142, 'logps/chosen': -199.0, 'logps/rejected': -236.89999389648438, 'logits/chosen': -9.006250381469727, 'logits/rejected': -8.668749809265137, 'epoch': 1.88}
 63%|██████▎   | 1050/1674 [1:09:48<2:04:20, 11.96s/it] 63%|██████▎   | 1051/1674 [1:09:52<1:36:51,  9.33s/it] 63%|██████▎   | 1052/1674 [1:09:55<1:18:14,  7.55s/it] 63%|██████▎   | 1053/1674 [1:09:59<1:06:44,  6.45s/it] 63%|██████▎   | 1054/1674 [1:10:01<54:45,  5.30s/it]   63%|██████▎   | 1055/1674 [1:10:05<48:35,  4.71s/it] 63%|██████▎   | 1056/1674 [1:10:07<41:50,  4.06s/it] 63%|██████▎   | 1057/1674 [1:10:11<39:59,  3.89s/it] 63%|██████▎   | 1058/1674 [1:10:14<36:25,  3.55s/it] 63%|██████▎   | 1059/1674 [1:10:18<38:25,  3.75s/it] 63%|██████▎   | 1060/1674 [1:10:22<38:58,  3.81s/it]                                                     {'loss': 0.4709, 'grad_norm': 33.82353591918945, 'learning_rate': 8.516933693318561e-07, 'rewards/chosen': -1.592187523841858, 'rewards/rejected': -2.942187547683716, 'rewards/accuracies': 0.7500000596046448, 'rewards/margins': 1.3507812023162842, 'logps/chosen': -129.35000610351562, 'logps/rejected': -177.6999969482422, 'logits/chosen': -9.100000381469727, 'logits/rejected': -8.743749618530273, 'epoch': 1.9}
 63%|██████▎   | 1060/1674 [1:10:22<38:58,  3.81s/it] 63%|██████▎   | 1061/1674 [1:10:26<38:59,  3.82s/it] 63%|██████▎   | 1062/1674 [1:10:28<35:48,  3.51s/it] 64%|██████▎   | 1063/1674 [1:10:32<36:25,  3.58s/it] 64%|██████▎   | 1064/1674 [1:10:36<36:56,  3.63s/it] 64%|██████▎   | 1065/1674 [1:10:39<34:04,  3.36s/it] 64%|██████▎   | 1066/1674 [1:10:43<36:34,  3.61s/it] 64%|██████▎   | 1067/1674 [1:10:47<38:05,  3.77s/it] 64%|██████▍   | 1068/1674 [1:10:50<36:46,  3.64s/it] 64%|██████▍   | 1069/1674 [1:10:53<35:11,  3.49s/it] 64%|██████▍   | 1070/1674 [1:10:56<33:18,  3.31s/it]                                                     {'loss': 0.3779, 'grad_norm': 24.34519386291504, 'learning_rate': 8.389671402920611e-07, 'rewards/chosen': -1.58984375, 'rewards/rejected': -2.9296875, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 1.33984375, 'logps/chosen': -137.35000610351562, 'logps/rejected': -173.4499969482422, 'logits/chosen': -9.024999618530273, 'logits/rejected': -8.912500381469727, 'epoch': 1.92}
 64%|██████▍   | 1070/1674 [1:10:56<33:18,  3.31s/it] 64%|██████▍   | 1071/1674 [1:10:59<31:01,  3.09s/it] 64%|██████▍   | 1072/1674 [1:11:02<31:15,  3.11s/it] 64%|██████▍   | 1073/1674 [1:11:06<33:58,  3.39s/it] 64%|██████▍   | 1074/1674 [1:11:10<35:30,  3.55s/it] 64%|██████▍   | 1075/1674 [1:11:14<37:12,  3.73s/it] 64%|██████▍   | 1076/1674 [1:11:17<34:45,  3.49s/it] 64%|██████▍   | 1077/1674 [1:11:20<32:29,  3.27s/it] 64%|██████▍   | 1078/1674 [1:11:24<34:58,  3.52s/it] 64%|██████▍   | 1079/1674 [1:11:28<36:52,  3.72s/it] 65%|██████▍   | 1080/1674 [1:11:31<33:53,  3.42s/it]                                                     {'loss': 0.3668, 'grad_norm': 36.710086822509766, 'learning_rate': 8.258348334003402e-07, 'rewards/chosen': -0.977343738079071, 'rewards/rejected': -2.717578172683716, 'rewards/accuracies': 0.841666579246521, 'rewards/margins': 1.741796851158142, 'logps/chosen': -153.0500030517578, 'logps/rejected': -193.39999389648438, 'logits/chosen': -9.168749809265137, 'logits/rejected': -8.918749809265137, 'epoch': 1.94}
 65%|██████▍   | 1080/1674 [1:11:31<33:53,  3.42s/it] 65%|██████▍   | 1081/1674 [1:11:35<35:02,  3.54s/it] 65%|██████▍   | 1082/1674 [1:11:38<33:48,  3.43s/it] 65%|██████▍   | 1083/1674 [1:11:41<33:35,  3.41s/it] 65%|██████▍   | 1084/1674 [1:11:44<32:36,  3.32s/it] 65%|██████▍   | 1085/1674 [1:11:47<31:13,  3.18s/it] 65%|██████▍   | 1086/1674 [1:11:50<31:03,  3.17s/it] 65%|██████▍   | 1087/1674 [1:11:54<31:52,  3.26s/it] 65%|██████▍   | 1088/1674 [1:11:57<32:41,  3.35s/it] 65%|██████▌   | 1089/1674 [1:12:01<33:33,  3.44s/it] 65%|██████▌   | 1090/1674 [1:12:03<30:38,  3.15s/it]                                                     {'loss': 0.407, 'grad_norm': 22.788049697875977, 'learning_rate': 8.12314903138985e-07, 'rewards/chosen': -1.508203148841858, 'rewards/rejected': -3.0250000953674316, 'rewards/accuracies': 0.8333331942558289, 'rewards/margins': 1.5187499523162842, 'logps/chosen': -115.1500015258789, 'logps/rejected': -161.8000030517578, 'logits/chosen': -9.306249618530273, 'logits/rejected': -9.081250190734863, 'epoch': 1.95}
 65%|██████▌   | 1090/1674 [1:12:04<30:38,  3.15s/it] 65%|██████▌   | 1091/1674 [1:12:06<29:32,  3.04s/it] 65%|██████▌   | 1092/1674 [1:12:09<29:41,  3.06s/it] 65%|██████▌   | 1093/1674 [1:12:13<31:58,  3.30s/it] 65%|██████▌   | 1094/1674 [1:12:17<34:02,  3.52s/it] 65%|██████▌   | 1095/1674 [1:12:21<35:00,  3.63s/it] 65%|██████▌   | 1096/1674 [1:12:24<31:41,  3.29s/it] 66%|██████▌   | 1097/1674 [1:12:27<32:18,  3.36s/it] 66%|██████▌   | 1098/1674 [1:12:31<33:51,  3.53s/it] 66%|██████▌   | 1099/1674 [1:12:35<33:54,  3.54s/it] 66%|██████▌   | 1100/1674 [1:12:38<33:38,  3.52s/it]                                                     {'loss': 0.417, 'grad_norm': 19.83460235595703, 'learning_rate': 7.984263487071196e-07, 'rewards/chosen': -0.959765613079071, 'rewards/rejected': -2.6253905296325684, 'rewards/accuracies': 0.8333333730697632, 'rewards/margins': 1.666406273841858, 'logps/chosen': -153.39999389648438, 'logps/rejected': -205.5, 'logits/chosen': -9.318750381469727, 'logits/rejected': -9.012499809265137, 'epoch': 1.97}
 66%|██████▌   | 1100/1674 [1:12:38<33:38,  3.52s/it] 66%|██████▌   | 1101/1674 [1:12:42<34:21,  3.60s/it] 66%|██████▌   | 1102/1674 [1:12:46<35:03,  3.68s/it] 66%|██████▌   | 1103/1674 [1:12:49<35:02,  3.68s/it] 66%|██████▌   | 1104/1674 [1:12:53<34:05,  3.59s/it] 66%|██████▌   | 1105/1674 [1:12:56<34:09,  3.60s/it] 66%|██████▌   | 1106/1674 [1:13:00<34:35,  3.65s/it] 66%|██████▌   | 1107/1674 [1:13:03<32:00,  3.39s/it] 66%|██████▌   | 1108/1674 [1:13:07<33:22,  3.54s/it] 66%|██████▌   | 1109/1674 [1:13:11<33:46,  3.59s/it] 66%|██████▋   | 1110/1674 [1:13:14<34:13,  3.64s/it]                                                     {'loss': 0.4032, 'grad_norm': 32.2618522644043, 'learning_rate': 7.841886873216303e-07, 'rewards/chosen': -1.740625023841858, 'rewards/rejected': -3.3609375953674316, 'rewards/accuracies': 0.85833340883255, 'rewards/margins': 1.6164062023162842, 'logps/chosen': -142.64999389648438, 'logps/rejected': -194.60000610351562, 'logits/chosen': -9.193750381469727, 'logits/rejected': -8.881250381469727, 'epoch': 1.99}
 66%|██████▋   | 1110/1674 [1:13:14<34:13,  3.64s/it] 66%|██████▋   | 1111/1674 [1:13:19<35:49,  3.82s/it] 66%|██████▋   | 1112/1674 [1:13:21<31:47,  3.39s/it] 66%|██████▋   | 1113/1674 [1:13:24<30:47,  3.29s/it] 67%|██████▋   | 1114/1674 [1:13:28<31:42,  3.40s/it] 67%|██████▋   | 1115/1674 [1:13:30<29:09,  3.13s/it] 67%|██████▋   | 1116/1674 [1:13:33<28:35,  3.07s/it] 67%|██████▋   | 1117/1674 [1:13:36<28:45,  3.10s/it] 67%|██████▋   | 1118/1674 [1:13:39<27:28,  2.97s/it] 67%|██████▋   | 1119/1674 [1:13:42<27:31,  2.98s/it] 67%|██████▋   | 1120/1674 [1:13:45<28:02,  3.04s/it]                                                     {'loss': 0.4394, 'grad_norm': 17.297468185424805, 'learning_rate': 7.696219267901382e-07, 'rewards/chosen': -1.599218726158142, 'rewards/rejected': -2.897656202316284, 'rewards/accuracies': 0.7916666865348816, 'rewards/margins': 1.298437476158142, 'logps/chosen': -105.69999694824219, 'logps/rejected': -177.9499969482422, 'logits/chosen': -9.256250381469727, 'logits/rejected': -8.762499809265137, 'epoch': 2.01}
 67%|██████▋   | 1120/1674 [1:13:45<28:02,  3.04s/it] 67%|██████▋   | 1121/1674 [1:13:49<31:28,  3.42s/it] 67%|██████▋   | 1122/1674 [1:13:53<31:48,  3.46s/it] 67%|██████▋   | 1123/1674 [1:13:57<32:54,  3.58s/it] 67%|██████▋   | 1124/1674 [1:14:01<33:49,  3.69s/it] 67%|██████▋   | 1125/1674 [1:14:05<35:05,  3.83s/it] 67%|██████▋   | 1126/1674 [1:14:08<34:07,  3.74s/it] 67%|██████▋   | 1127/1674 [1:14:11<31:12,  3.42s/it] 67%|██████▋   | 1128/1674 [1:14:15<31:25,  3.45s/it] 67%|██████▋   | 1129/1674 [1:14:18<32:10,  3.54s/it] 68%|██████▊   | 1130/1674 [1:14:21<30:10,  3.33s/it]                                                     {'loss': 0.3318, 'grad_norm': 24.985071182250977, 'learning_rate': 7.547465373945592e-07, 'rewards/chosen': -1.322265625, 'rewards/rejected': -3.336718797683716, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0132813453674316, 'logps/chosen': -163.10000610351562, 'logps/rejected': -220.9499969482422, 'logits/chosen': -9.15625, 'logits/rejected': -8.787500381469727, 'epoch': 2.03}
 68%|██████▊   | 1130/1674 [1:14:21<30:10,  3.33s/it] 68%|██████▊   | 1131/1674 [1:14:25<30:27,  3.37s/it] 68%|██████▊   | 1132/1674 [1:14:27<28:58,  3.21s/it] 68%|██████▊   | 1133/1674 [1:14:31<29:36,  3.28s/it] 68%|██████▊   | 1134/1674 [1:14:34<28:35,  3.18s/it] 68%|██████▊   | 1135/1674 [1:14:38<30:59,  3.45s/it] 68%|██████▊   | 1136/1674 [1:14:42<32:48,  3.66s/it] 68%|██████▊   | 1137/1674 [1:14:46<33:57,  3.79s/it] 68%|██████▊   | 1138/1674 [1:14:50<33:49,  3.79s/it] 68%|██████▊   | 1139/1674 [1:14:54<34:12,  3.84s/it] 68%|██████▊   | 1140/1674 [1:14:57<31:48,  3.57s/it]                                                     {'loss': 0.3295, 'grad_norm': 26.00446891784668, 'learning_rate': 7.395834231247594e-07, 'rewards/chosen': -1.493749976158142, 'rewards/rejected': -3.323437452316284, 'rewards/accuracies': 0.85833340883255, 'rewards/margins': 1.825781226158142, 'logps/chosen': -125.0, 'logps/rejected': -191.5500030517578, 'logits/chosen': -9.381250381469727, 'logits/rejected': -9.056249618530273, 'epoch': 2.04}
 68%|██████▊   | 1140/1674 [1:14:57<31:48,  3.57s/it] 68%|██████▊   | 1141/1674 [1:15:00<31:03,  3.50s/it] 68%|██████▊   | 1142/1674 [1:15:03<28:50,  3.25s/it] 68%|██████▊   | 1143/1674 [1:15:07<30:36,  3.46s/it] 68%|██████▊   | 1144/1674 [1:15:11<31:26,  3.56s/it] 68%|██████▊   | 1145/1674 [1:15:14<30:20,  3.44s/it] 68%|██████▊   | 1146/1674 [1:15:18<30:57,  3.52s/it] 69%|██████▊   | 1147/1674 [1:15:21<30:03,  3.42s/it] 69%|██████▊   | 1148/1674 [1:15:23<27:26,  3.13s/it] 69%|██████▊   | 1149/1674 [1:15:27<28:28,  3.25s/it] 69%|██████▊   | 1150/1674 [1:15:31<30:54,  3.54s/it]                                                     {'loss': 0.3092, 'grad_norm': 9.359453201293945, 'learning_rate': 7.241538923027333e-07, 'rewards/chosen': -0.947265625, 'rewards/rejected': -2.6372437477111816, 'rewards/accuracies': 0.8666666150093079, 'rewards/margins': 1.687109351158142, 'logps/chosen': -157.64999389648438, 'logps/rejected': -176.75, 'logits/chosen': -8.9375, 'logits/rejected': -8.84375, 'epoch': 2.06}
 69%|██████▊   | 1150/1674 [1:15:31<30:54,  3.54s/it] 69%|██████▉   | 1151/1674 [1:15:34<30:51,  3.54s/it] 69%|██████▉   | 1152/1674 [1:15:38<30:19,  3.49s/it] 69%|██████▉   | 1153/1674 [1:15:41<29:10,  3.36s/it] 69%|██████▉   | 1154/1674 [1:15:44<28:38,  3.30s/it] 69%|██████▉   | 1155/1674 [1:15:48<29:09,  3.37s/it] 69%|██████▉   | 1156/1674 [1:15:50<27:14,  3.16s/it] 69%|██████▉   | 1157/1674 [1:15:54<28:58,  3.36s/it] 69%|██████▉   | 1158/1674 [1:15:57<27:24,  3.19s/it] 69%|██████▉   | 1159/1674 [1:16:00<26:29,  3.09s/it] 69%|██████▉   | 1160/1674 [1:16:03<28:13,  3.30s/it]                                                     {'loss': 0.2974, 'grad_norm': 16.8319091796875, 'learning_rate': 7.084796276385847e-07, 'rewards/chosen': -1.2527344226837158, 'rewards/rejected': -3.1734375953674316, 'rewards/accuracies': 0.9000000953674316, 'rewards/margins': 1.923437476158142, 'logps/chosen': -112.25, 'logps/rejected': -172.75, 'logits/chosen': -9.056249618530273, 'logits/rejected': -8.818750381469727, 'epoch': 2.08}
 69%|██████▉   | 1160/1674 [1:16:04<28:13,  3.30s/it] 69%|██████▉   | 1161/1674 [1:16:06<25:13,  2.95s/it] 69%|██████▉   | 1162/1674 [1:16:10<27:41,  3.25s/it] 69%|██████▉   | 1163/1674 [1:16:13<28:13,  3.31s/it] 70%|██████▉   | 1164/1674 [1:16:17<28:35,  3.36s/it] 70%|██████▉   | 1165/1674 [1:16:20<29:06,  3.43s/it] 70%|██████▉   | 1166/1674 [1:16:24<29:25,  3.47s/it] 70%|██████▉   | 1167/1674 [1:16:26<26:51,  3.18s/it] 70%|██████▉   | 1168/1674 [1:16:29<26:38,  3.16s/it] 70%|██████▉   | 1169/1674 [1:16:32<26:28,  3.14s/it] 70%|██████▉   | 1170/1674 [1:16:36<28:41,  3.42s/it]                                                     {'loss': 0.326, 'grad_norm': 10.610278129577637, 'learning_rate': 6.925826557603894e-07, 'rewards/chosen': -0.951953113079071, 'rewards/rejected': -2.658203125, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 1.705078125, 'logps/chosen': -154.9499969482422, 'logps/rejected': -192.10000610351562, 'logits/chosen': -9.25, 'logits/rejected': -8.887499809265137, 'epoch': 2.1}
 70%|██████▉   | 1170/1674 [1:16:36<28:41,  3.42s/it] 70%|██████▉   | 1171/1674 [1:16:40<28:09,  3.36s/it] 70%|███████   | 1172/1674 [1:16:43<26:52,  3.21s/it] 70%|███████   | 1173/1674 [1:16:46<27:36,  3.31s/it] 70%|███████   | 1174/1674 [1:16:49<27:05,  3.25s/it] 70%|███████   | 1175/1674 [1:16:53<28:06,  3.38s/it] 70%|███████   | 1176/1674 [1:16:57<29:27,  3.55s/it] 70%|███████   | 1177/1674 [1:17:01<30:25,  3.67s/it] 70%|███████   | 1178/1674 [1:17:04<30:20,  3.67s/it] 70%|███████   | 1179/1674 [1:17:07<27:30,  3.34s/it] 70%|███████   | 1180/1674 [1:17:10<26:49,  3.26s/it]                                                     {'loss': 0.255, 'grad_norm': 8.958756446838379, 'learning_rate': 6.764853162607593e-07, 'rewards/chosen': -1.0750000476837158, 'rewards/rejected': -3.145312547683716, 'rewards/accuracies': 0.9416667222976685, 'rewards/margins': 2.0679688453674316, 'logps/chosen': -104.8499984741211, 'logps/rejected': -152.6999969482422, 'logits/chosen': -9.231249809265137, 'logits/rejected': -8.868749618530273, 'epoch': 2.11}
 70%|███████   | 1180/1674 [1:17:10<26:49,  3.26s/it] 71%|███████   | 1181/1674 [1:17:13<27:09,  3.31s/it] 71%|███████   | 1182/1674 [1:17:17<27:07,  3.31s/it] 71%|███████   | 1183/1674 [1:17:19<25:19,  3.09s/it] 71%|███████   | 1184/1674 [1:17:22<23:26,  2.87s/it] 71%|███████   | 1185/1674 [1:17:25<24:54,  3.06s/it] 71%|███████   | 1186/1674 [1:17:29<26:36,  3.27s/it] 71%|███████   | 1187/1674 [1:17:32<25:27,  3.14s/it] 71%|███████   | 1188/1674 [1:17:36<27:46,  3.43s/it] 71%|███████   | 1189/1674 [1:17:39<27:21,  3.38s/it] 71%|███████   | 1190/1674 [1:17:43<28:54,  3.58s/it]                                                     {'loss': 0.3013, 'grad_norm': 50.893096923828125, 'learning_rate': 6.602102303036068e-07, 'rewards/chosen': -1.435937523841858, 'rewards/rejected': -3.515625, 'rewards/accuracies': 0.8583332896232605, 'rewards/margins': 2.0765624046325684, 'logps/chosen': -133.75, 'logps/rejected': -171.8000030517578, 'logits/chosen': -9.431249618530273, 'logits/rejected': -9.125, 'epoch': 2.13}
 71%|███████   | 1190/1674 [1:17:43<28:54,  3.58s/it] 71%|███████   | 1191/1674 [1:17:47<28:55,  3.59s/it] 71%|███████   | 1192/1674 [1:17:51<30:22,  3.78s/it] 71%|███████▏  | 1193/1674 [1:17:53<26:56,  3.36s/it] 71%|███████▏  | 1194/1674 [1:17:57<27:40,  3.46s/it] 71%|███████▏  | 1195/1674 [1:18:00<26:00,  3.26s/it] 71%|███████▏  | 1196/1674 [1:18:03<24:50,  3.12s/it] 72%|███████▏  | 1197/1674 [1:18:05<23:26,  2.95s/it] 72%|███████▏  | 1198/1674 [1:18:08<23:20,  2.94s/it] 72%|███████▏  | 1199/1674 [1:18:12<25:05,  3.17s/it] 72%|███████▏  | 1200/1674 [1:18:15<26:00,  3.29s/it]                                                     {'loss': 0.2658, 'grad_norm': 13.186958312988281, 'learning_rate': 6.437802688352221e-07, 'rewards/chosen': -1.41015625, 'rewards/rejected': -3.5374999046325684, 'rewards/accuracies': 0.89166659116745, 'rewards/margins': 2.1273436546325684, 'logps/chosen': -116.8499984741211, 'logps/rejected': -174.4499969482422, 'logits/chosen': -9.443750381469727, 'logits/rejected': -9.006250381469727, 'epoch': 2.15}
 72%|███████▏  | 1200/1674 [1:18:16<26:00,  3.29s/it] 72%|███████▏  | 1201/1674 [1:18:20<27:55,  3.54s/it] 72%|███████▏  | 1202/1674 [1:18:23<28:27,  3.62s/it] 72%|███████▏  | 1203/1674 [1:18:26<27:04,  3.45s/it] 72%|███████▏  | 1204/1674 [1:18:31<29:33,  3.77s/it] 72%|███████▏  | 1205/1674 [1:18:35<29:45,  3.81s/it] 72%|███████▏  | 1206/1674 [1:18:39<30:38,  3.93s/it] 72%|███████▏  | 1207/1674 [1:18:42<28:31,  3.67s/it] 72%|███████▏  | 1208/1674 [1:18:46<29:08,  3.75s/it] 72%|███████▏  | 1209/1674 [1:18:50<28:25,  3.67s/it] 72%|███████▏  | 1210/1674 [1:18:54<29:00,  3.75s/it]                                                     {'loss': 0.2955, 'grad_norm': 15.108595848083496, 'learning_rate': 6.272185204443412e-07, 'rewards/chosen': -1.185546875, 'rewards/rejected': -3.018359422683716, 'rewards/accuracies': 0.9416667222976685, 'rewards/margins': 1.830468773841858, 'logps/chosen': -141.9499969482422, 'logps/rejected': -182.3000030517578, 'logits/chosen': -9.193750381469727, 'logits/rejected': -8.850000381469727, 'epoch': 2.17}
 72%|███████▏  | 1210/1674 [1:18:54<29:00,  3.75s/it] 72%|███████▏  | 1211/1674 [1:18:56<25:51,  3.35s/it] 72%|███████▏  | 1212/1674 [1:19:00<27:47,  3.61s/it] 72%|███████▏  | 1213/1674 [1:19:03<26:00,  3.38s/it] 73%|███████▎  | 1214/1674 [1:19:06<24:26,  3.19s/it] 73%|███████▎  | 1215/1674 [1:19:08<23:20,  3.05s/it] 73%|███████▎  | 1216/1674 [1:19:12<23:19,  3.06s/it] 73%|███████▎  | 1217/1674 [1:19:14<22:46,  2.99s/it] 73%|███████▎  | 1218/1674 [1:19:17<21:53,  2.88s/it] 73%|███████▎  | 1219/1674 [1:19:21<23:21,  3.08s/it] 73%|███████▎  | 1220/1674 [1:19:23<22:23,  2.96s/it]                                                     {'loss': 0.2609, 'grad_norm': 23.187875747680664, 'learning_rate': 6.105482589163637e-07, 'rewards/chosen': -1.4832031726837158, 'rewards/rejected': -3.5562500953674316, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.077343702316284, 'logps/chosen': -118.8499984741211, 'logps/rejected': -163.9499969482422, 'logits/chosen': -9.262499809265137, 'logits/rejected': -8.9375, 'epoch': 2.19}
 73%|███████▎  | 1220/1674 [1:19:23<22:23,  2.96s/it] 73%|███████▎  | 1221/1674 [1:19:27<23:32,  3.12s/it] 73%|███████▎  | 1222/1674 [1:19:30<23:58,  3.18s/it] 73%|███████▎  | 1223/1674 [1:19:34<24:42,  3.29s/it] 73%|███████▎  | 1224/1674 [1:19:37<24:13,  3.23s/it] 73%|███████▎  | 1225/1674 [1:19:41<25:36,  3.42s/it] 73%|███████▎  | 1226/1674 [1:19:45<27:21,  3.66s/it] 73%|███████▎  | 1227/1674 [1:19:47<24:24,  3.28s/it] 73%|███████▎  | 1228/1674 [1:19:51<25:06,  3.38s/it] 73%|███████▎  | 1229/1674 [1:19:54<25:27,  3.43s/it] 73%|███████▎  | 1230/1674 [1:19:58<26:30,  3.58s/it]                                                     {'loss': 0.3014, 'grad_norm': 12.396132469177246, 'learning_rate': 5.937929105273203e-07, 'rewards/chosen': -0.857421875, 'rewards/rejected': -2.951367139816284, 'rewards/accuracies': 0.8833333849906921, 'rewards/margins': 2.0960936546325684, 'logps/chosen': -151.14999389648438, 'logps/rejected': -188.3000030517578, 'logits/chosen': -9.268750190734863, 'logits/rejected': -8.981249809265137, 'epoch': 2.2}
 73%|███████▎  | 1230/1674 [1:19:58<26:30,  3.58s/it] 74%|███████▎  | 1231/1674 [1:20:02<26:58,  3.65s/it] 74%|███████▎  | 1232/1674 [1:20:06<27:28,  3.73s/it] 74%|███████▎  | 1233/1674 [1:20:10<27:12,  3.70s/it] 74%|███████▎  | 1234/1674 [1:20:13<27:20,  3.73s/it] 74%|███████▍  | 1235/1674 [1:20:18<28:14,  3.86s/it] 74%|███████▍  | 1236/1674 [1:20:21<26:28,  3.63s/it] 74%|███████▍  | 1237/1674 [1:20:24<26:45,  3.67s/it] 74%|███████▍  | 1238/1674 [1:20:28<26:32,  3.65s/it] 74%|███████▍  | 1239/1674 [1:20:31<24:52,  3.43s/it] 74%|███████▍  | 1240/1674 [1:20:35<25:49,  3.57s/it]                                                     {'loss': 0.2388, 'grad_norm': 15.108538627624512, 'learning_rate': 5.769760211235493e-07, 'rewards/chosen': -1.3679687976837158, 'rewards/rejected': -3.5167479515075684, 'rewards/accuracies': 0.9333333969116211, 'rewards/margins': 2.149218797683716, 'logps/chosen': -158.1999969482422, 'logps/rejected': -217.89999389648438, 'logits/chosen': -9.193750381469727, 'logits/rejected': -9.09375, 'epoch': 2.22}
 74%|███████▍  | 1240/1674 [1:20:35<25:49,  3.57s/it] 74%|███████▍  | 1241/1674 [1:20:37<22:00,  3.05s/it] 74%|███████▍  | 1242/1674 [1:20:41<24:08,  3.35s/it] 74%|███████▍  | 1243/1674 [1:20:44<24:10,  3.36s/it] 74%|███████▍  | 1244/1674 [1:20:48<25:17,  3.53s/it] 74%|███████▍  | 1245/1674 [1:20:50<22:04,  3.09s/it] 74%|███████▍  | 1246/1674 [1:20:54<23:18,  3.27s/it] 74%|███████▍  | 1247/1674 [1:20:58<24:29,  3.44s/it] 75%|███████▍  | 1248/1674 [1:21:01<24:39,  3.47s/it] 75%|███████▍  | 1249/1674 [1:21:04<22:57,  3.24s/it] 75%|███████▍  | 1250/1674 [1:21:07<22:02,  3.12s/it]                                                     {'loss': 0.3785, 'grad_norm': 22.93438148498535, 'learning_rate': 5.601212230333432e-07, 'rewards/chosen': -1.6124999523162842, 'rewards/rejected': -3.160937547683716, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.55078125, 'logps/chosen': -132.1999969482422, 'logps/rejected': -149.5, 'logits/chosen': -9.287500381469727, 'logits/rejected': -9.081250190734863, 'epoch': 2.24}
 75%|███████▍  | 1250/1674 [1:21:07<22:02,  3.12s/it] 75%|███████▍  | 1251/1674 [1:21:10<21:29,  3.05s/it] 75%|███████▍  | 1252/1674 [1:21:14<24:06,  3.43s/it] 75%|███████▍  | 1253/1674 [1:21:17<22:48,  3.25s/it] 75%|███████▍  | 1254/1674 [1:21:21<24:53,  3.56s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:59,  1.30it/s][A
  4%|▍         | 3/80 [00:03<01:24,  1.10s/it][A
  5%|▌         | 4/80 [00:04<01:36,  1.27s/it][A
  6%|▋         | 5/80 [00:06<01:45,  1.41s/it][A
  8%|▊         | 6/80 [00:07<01:48,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:49,  1.51s/it][A
 10%|█         | 8/80 [00:11<01:51,  1.55s/it][A
 11%|█▏        | 9/80 [00:12<01:51,  1.57s/it][A
 12%|█▎        | 10/80 [00:14<01:52,  1.61s/it][A
 14%|█▍        | 11/80 [00:16<01:54,  1.65s/it][A
 15%|█▌        | 12/80 [00:17<01:50,  1.63s/it][A
 16%|█▋        | 13/80 [00:19<01:47,  1.61s/it][A
 18%|█▊        | 14/80 [00:21<01:48,  1.65s/it][A
 19%|█▉        | 15/80 [00:22<01:47,  1.65s/it][A
 20%|██        | 16/80 [00:24<01:44,  1.63s/it][A
 21%|██▏       | 17/80 [00:25<01:42,  1.62s/it][A
 22%|██▎       | 18/80 [00:27<01:41,  1.63s/it][A
 24%|██▍       | 19/80 [00:28<01:30,  1.48s/it][A
 25%|██▌       | 20/80 [00:30<01:24,  1.41s/it][A
 26%|██▋       | 21/80 [00:30<01:08,  1.16s/it][A
 28%|██▊       | 22/80 [00:31<01:05,  1.13s/it][A
 29%|██▉       | 23/80 [00:32<01:03,  1.11s/it][A
 30%|███       | 24/80 [00:33<00:51,  1.08it/s][A
 31%|███▏      | 25/80 [00:34<00:54,  1.00it/s][A
 32%|███▎      | 26/80 [00:35<00:58,  1.08s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.04it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.03it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.09s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.04it/s][A
 41%|████▏     | 33/80 [00:43<00:54,  1.16s/it][A
 42%|████▎     | 34/80 [00:44<00:57,  1.24s/it][A
 44%|████▍     | 35/80 [00:45<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.06it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.22it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:48,  1.22s/it][A
 51%|█████▏    | 41/80 [00:50<00:40,  1.03s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.19s/it][A
 54%|█████▍    | 43/80 [00:53<00:46,  1.26s/it][A
 55%|█████▌    | 44/80 [00:55<00:45,  1.25s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.07it/s][A
 59%|█████▉    | 47/80 [00:57<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:38,  1.19s/it][A
 61%|██████▏   | 49/80 [00:59<00:31,  1.01s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.19it/s][A
 64%|██████▍   | 51/80 [01:01<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:03<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:03<00:26,  1.02it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.19s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:09<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:11<00:25,  1.21s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.01s/it][A
 76%|███████▋  | 61/80 [01:13<00:22,  1.16s/it][A
 78%|███████▊  | 62/80 [01:14<00:23,  1.32s/it][A
 79%|███████▉  | 63/80 [01:15<00:21,  1.25s/it][A
 80%|████████  | 64/80 [01:16<00:17,  1.12s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.24s/it][A
 82%|████████▎ | 66/80 [01:19<00:18,  1.33s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.44s/it][A
 85%|████████▌ | 68/80 [01:23<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:24<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:26<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:29<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:30<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:31<00:06,  1.27s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.36s/it][A
 96%|█████████▋| 77/80 [01:34<00:04,  1.38s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.14s/it][A
 99%|█████████▉| 79/80 [01:36<00:01,  1.27s/it][A
100%|██████████| 80/80 [01:38<00:00,  1.38s/it][A                                                     
                                               [A{'eval_loss': 0.8387051820755005, 'eval_runtime': 100.2954, 'eval_samples_per_second': 9.502, 'eval_steps_per_second': 0.798, 'eval_rewards/chosen': 0.27592772245407104, 'eval_rewards/rejected': -1.5313904285430908, 'eval_rewards/accuracies': 0.736875057220459, 'eval_rewards/margins': 1.8075296878814697, 'eval_logps/chosen': -375.04998779296875, 'eval_logps/rejected': -168.6171875, 'eval_logits/chosen': -8.77734375, 'eval_logits/rejected': -9.058984756469727, 'epoch': 2.25}
 75%|███████▍  | 1254/1674 [1:23:01<24:53,  3.56s/it]
100%|██████████| 80/80 [01:38<00:00,  1.38s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 75%|███████▍  | 1255/1674 [1:23:19<4:23:29, 37.73s/it] 75%|███████▌  | 1256/1674 [1:23:22<3:11:15, 27.45s/it] 75%|███████▌  | 1257/1674 [1:23:24<2:18:32, 19.93s/it] 75%|███████▌  | 1258/1674 [1:23:29<1:45:35, 15.23s/it] 75%|███████▌  | 1259/1674 [1:23:33<1:22:01, 11.86s/it] 75%|███████▌  | 1260/1674 [1:23:37<1:05:22,  9.47s/it]                                                       {'loss': 0.2543, 'grad_norm': 17.08612632751465, 'learning_rate': 5.432522018570655e-07, 'rewards/chosen': -0.754687488079071, 'rewards/rejected': -2.886669874191284, 'rewards/accuracies': 0.908333420753479, 'rewards/margins': 2.1312499046325684, 'logps/chosen': -183.0, 'logps/rejected': -233.39999389648438, 'logits/chosen': -9.53125, 'logits/rejected': -8.981249809265137, 'epoch': 2.26}
 75%|███████▌  | 1260/1674 [1:23:37<1:05:22,  9.47s/it] 75%|███████▌  | 1261/1674 [1:23:39<51:12,  7.44s/it]   75%|███████▌  | 1262/1674 [1:23:43<44:25,  6.47s/it] 75%|███████▌  | 1263/1674 [1:23:46<36:30,  5.33s/it] 76%|███████▌  | 1264/1674 [1:23:49<30:45,  4.50s/it] 76%|███████▌  | 1265/1674 [1:23:52<28:49,  4.23s/it] 76%|███████▌  | 1266/1674 [1:23:55<25:45,  3.79s/it] 76%|███████▌  | 1267/1674 [1:23:58<23:37,  3.48s/it] 76%|███████▌  | 1268/1674 [1:24:02<24:11,  3.57s/it] 76%|███████▌  | 1269/1674 [1:24:05<23:36,  3.50s/it] 76%|███████▌  | 1270/1674 [1:24:09<24:12,  3.60s/it]                                                     {'loss': 0.3043, 'grad_norm': 16.266679763793945, 'learning_rate': 5.26392663182405e-07, 'rewards/chosen': -1.4246094226837158, 'rewards/rejected': -3.5406250953674316, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.1171875, 'logps/chosen': -127.30000305175781, 'logps/rejected': -150.0, 'logits/chosen': -9.543749809265137, 'logits/rejected': -9.318750381469727, 'epoch': 2.28}
 76%|███████▌  | 1270/1674 [1:24:09<24:12,  3.60s/it] 76%|███████▌  | 1271/1674 [1:24:13<24:52,  3.70s/it] 76%|███████▌  | 1272/1674 [1:24:16<23:43,  3.54s/it] 76%|███████▌  | 1273/1674 [1:24:20<24:45,  3.71s/it] 76%|███████▌  | 1274/1674 [1:24:23<23:18,  3.50s/it] 76%|███████▌  | 1275/1674 [1:24:27<24:08,  3.63s/it] 76%|███████▌  | 1276/1674 [1:24:30<23:24,  3.53s/it] 76%|███████▋  | 1277/1674 [1:24:33<21:07,  3.19s/it] 76%|███████▋  | 1278/1674 [1:24:37<22:53,  3.47s/it] 76%|███████▋  | 1279/1674 [1:24:40<22:29,  3.42s/it] 76%|███████▋  | 1280/1674 [1:24:43<20:42,  3.15s/it]                                                     {'loss': 0.2853, 'grad_norm': 30.813486099243164, 'learning_rate': 5.095662992715423e-07, 'rewards/chosen': -0.6097656488418579, 'rewards/rejected': -2.8427734375, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2265625, 'logps/chosen': -193.25, 'logps/rejected': -235.75, 'logits/chosen': -9.212499618530273, 'logits/rejected': -8.949999809265137, 'epoch': 2.29}
 76%|███████▋  | 1280/1674 [1:24:43<20:42,  3.15s/it] 77%|███████▋  | 1281/1674 [1:24:47<23:15,  3.55s/it] 77%|███████▋  | 1282/1674 [1:24:49<20:55,  3.20s/it] 77%|███████▋  | 1283/1674 [1:24:53<21:07,  3.24s/it] 77%|███████▋  | 1284/1674 [1:24:56<21:06,  3.25s/it] 77%|███████▋  | 1285/1674 [1:25:00<22:12,  3.43s/it] 77%|███████▋  | 1286/1674 [1:25:02<20:25,  3.16s/it] 77%|███████▋  | 1287/1674 [1:25:06<21:43,  3.37s/it] 77%|███████▋  | 1288/1674 [1:25:10<22:12,  3.45s/it] 77%|███████▋  | 1289/1674 [1:25:13<21:48,  3.40s/it] 77%|███████▋  | 1290/1674 [1:25:17<22:15,  3.48s/it]                                                     {'loss': 0.2483, 'grad_norm': 27.892845153808594, 'learning_rate': 4.92796755767044e-07, 'rewards/chosen': -1.609765648841858, 'rewards/rejected': -3.8656249046325684, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 2.2578125, 'logps/chosen': -121.9000015258789, 'logps/rejected': -169.35000610351562, 'logits/chosen': -9.568750381469727, 'logits/rejected': -9.15625, 'epoch': 2.31}
 77%|███████▋  | 1290/1674 [1:25:17<22:15,  3.48s/it] 77%|███████▋  | 1291/1674 [1:25:20<22:37,  3.54s/it] 77%|███████▋  | 1292/1674 [1:25:23<20:46,  3.26s/it] 77%|███████▋  | 1293/1674 [1:25:27<22:04,  3.48s/it] 77%|███████▋  | 1294/1674 [1:25:30<21:03,  3.32s/it] 77%|███████▋  | 1295/1674 [1:25:34<22:40,  3.59s/it] 77%|███████▋  | 1296/1674 [1:25:38<23:44,  3.77s/it] 77%|███████▋  | 1297/1674 [1:25:42<23:25,  3.73s/it] 78%|███████▊  | 1298/1674 [1:25:45<22:43,  3.63s/it] 78%|███████▊  | 1299/1674 [1:25:49<23:17,  3.73s/it] 78%|███████▊  | 1300/1674 [1:25:54<23:59,  3.85s/it]                                                     {'loss': 0.2984, 'grad_norm': 23.956077575683594, 'learning_rate': 4.761075984632664e-07, 'rewards/chosen': -1.8359375, 'rewards/rejected': -4.029687404632568, 'rewards/accuracies': 0.8833333253860474, 'rewards/margins': 2.194531202316284, 'logps/chosen': -126.69999694824219, 'logps/rejected': -179.3000030517578, 'logits/chosen': -9.6875, 'logits/rejected': -9.3125, 'epoch': 2.33}
 78%|███████▊  | 1300/1674 [1:25:54<23:59,  3.85s/it] 78%|███████▊  | 1301/1674 [1:25:57<22:13,  3.58s/it] 78%|███████▊  | 1302/1674 [1:26:00<22:40,  3.66s/it] 78%|███████▊  | 1303/1674 [1:26:04<22:38,  3.66s/it] 78%|███████▊  | 1304/1674 [1:26:08<22:42,  3.68s/it] 78%|███████▊  | 1305/1674 [1:26:11<22:07,  3.60s/it] 78%|███████▊  | 1306/1674 [1:26:14<21:03,  3.43s/it] 78%|███████▊  | 1307/1674 [1:26:18<21:29,  3.51s/it] 78%|███████▊  | 1308/1674 [1:26:22<22:37,  3.71s/it] 78%|███████▊  | 1309/1674 [1:26:25<21:51,  3.59s/it] 78%|███████▊  | 1310/1674 [1:26:29<21:06,  3.48s/it]                                                     {'loss': 0.2829, 'grad_norm': 30.840246200561523, 'learning_rate': 4.5952228018997296e-07, 'rewards/chosen': -1.802734375, 'rewards/rejected': -4.212500095367432, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.407031297683716, 'logps/chosen': -118.4000015258789, 'logps/rejected': -198.1999969482422, 'logits/chosen': -9.78125, 'logits/rejected': -9.206250190734863, 'epoch': 2.35}
 78%|███████▊  | 1310/1674 [1:26:29<21:06,  3.48s/it] 78%|███████▊  | 1311/1674 [1:26:32<20:09,  3.33s/it] 78%|███████▊  | 1312/1674 [1:26:35<19:59,  3.31s/it] 78%|███████▊  | 1313/1674 [1:26:38<19:07,  3.18s/it] 78%|███████▊  | 1314/1674 [1:26:41<19:16,  3.21s/it] 79%|███████▊  | 1315/1674 [1:26:44<18:08,  3.03s/it] 79%|███████▊  | 1316/1674 [1:26:47<19:02,  3.19s/it] 79%|███████▊  | 1317/1674 [1:26:51<19:56,  3.35s/it] 79%|███████▊  | 1318/1674 [1:26:54<19:21,  3.26s/it] 79%|███████▉  | 1319/1674 [1:26:58<20:12,  3.42s/it] 79%|███████▉  | 1320/1674 [1:27:02<21:40,  3.67s/it]                                                     {'loss': 0.2524, 'grad_norm': 15.811436653137207, 'learning_rate': 4.430641078546935e-07, 'rewards/chosen': -1.6749999523162842, 'rewards/rejected': -3.910937547683716, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.2367186546325684, 'logps/chosen': -115.1500015258789, 'logps/rejected': -186.10000610351562, 'logits/chosen': -9.831250190734863, 'logits/rejected': -9.337499618530273, 'epoch': 2.37}
 79%|███████▉  | 1320/1674 [1:27:02<21:40,  3.67s/it] 79%|███████▉  | 1321/1674 [1:27:06<22:11,  3.77s/it] 79%|███████▉  | 1322/1674 [1:27:09<20:30,  3.49s/it] 79%|███████▉  | 1323/1674 [1:27:12<20:33,  3.52s/it] 79%|███████▉  | 1324/1674 [1:27:16<20:13,  3.47s/it] 79%|███████▉  | 1325/1674 [1:27:18<18:35,  3.20s/it] 79%|███████▉  | 1326/1674 [1:27:21<18:14,  3.14s/it] 79%|███████▉  | 1327/1674 [1:27:25<18:25,  3.19s/it] 79%|███████▉  | 1328/1674 [1:27:27<16:44,  2.90s/it] 79%|███████▉  | 1329/1674 [1:27:30<16:26,  2.86s/it] 79%|███████▉  | 1330/1674 [1:27:33<17:28,  3.05s/it]                                                     {'loss': 0.2939, 'grad_norm': 25.79955291748047, 'learning_rate': 4.2675620969014604e-07, 'rewards/chosen': -1.615625023841858, 'rewards/rejected': -3.635937452316284, 'rewards/accuracies': 0.875, 'rewards/margins': 2.020312547683716, 'logps/chosen': -173.3000030517578, 'logps/rejected': -207.0, 'logits/chosen': -9.609375, 'logits/rejected': -9.393750190734863, 'epoch': 2.38}
 79%|███████▉  | 1330/1674 [1:27:33<17:28,  3.05s/it] 80%|███████▉  | 1331/1674 [1:27:37<18:12,  3.19s/it] 80%|███████▉  | 1332/1674 [1:27:40<19:13,  3.37s/it] 80%|███████▉  | 1333/1674 [1:27:44<19:52,  3.50s/it] 80%|███████▉  | 1334/1674 [1:27:48<20:18,  3.58s/it] 80%|███████▉  | 1335/1674 [1:27:51<19:08,  3.39s/it] 80%|███████▉  | 1336/1674 [1:27:54<17:45,  3.15s/it] 80%|███████▉  | 1337/1674 [1:27:57<18:53,  3.36s/it] 80%|███████▉  | 1338/1674 [1:28:01<19:55,  3.56s/it] 80%|███████▉  | 1339/1674 [1:28:06<20:50,  3.73s/it] 80%|████████  | 1340/1674 [1:28:09<20:00,  3.60s/it]                                                     {'loss': 0.3172, 'grad_norm': 34.84359359741211, 'learning_rate': 4.106215027527451e-07, 'rewards/chosen': -1.982031226158142, 'rewards/rejected': -4.1171875, 'rewards/accuracies': 0.875, 'rewards/margins': 2.132031202316284, 'logps/chosen': -133.25, 'logps/rejected': -178.89999389648438, 'logits/chosen': -9.649999618530273, 'logits/rejected': -9.306249618530273, 'epoch': 2.4}
 80%|████████  | 1340/1674 [1:28:09<20:00,  3.60s/it] 80%|████████  | 1341/1674 [1:28:12<19:25,  3.50s/it] 80%|████████  | 1342/1674 [1:28:16<20:13,  3.65s/it] 80%|████████  | 1343/1674 [1:28:20<20:55,  3.79s/it] 80%|████████  | 1344/1674 [1:28:23<19:05,  3.47s/it] 80%|████████  | 1345/1674 [1:28:27<19:53,  3.63s/it] 80%|████████  | 1346/1674 [1:28:31<19:58,  3.65s/it] 80%|████████  | 1347/1674 [1:28:34<19:38,  3.60s/it] 81%|████████  | 1348/1674 [1:28:37<18:57,  3.49s/it] 81%|████████  | 1349/1674 [1:28:41<19:22,  3.58s/it] 81%|████████  | 1350/1674 [1:28:45<19:56,  3.69s/it]                                                     {'loss': 0.2385, 'grad_norm': 10.426849365234375, 'learning_rate': 3.946826607178713e-07, 'rewards/chosen': -2.016796827316284, 'rewards/rejected': -4.568749904632568, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.553906202316284, 'logps/chosen': -130.64999389648438, 'logps/rejected': -204.6999969482422, 'logits/chosen': -9.668749809265137, 'logits/rejected': -9.162500381469727, 'epoch': 2.42}
 81%|████████  | 1350/1674 [1:28:45<19:56,  3.69s/it] 81%|████████  | 1351/1674 [1:28:49<20:03,  3.73s/it] 81%|████████  | 1352/1674 [1:28:53<20:30,  3.82s/it] 81%|████████  | 1353/1674 [1:28:55<17:34,  3.29s/it] 81%|████████  | 1354/1674 [1:28:58<17:18,  3.25s/it] 81%|████████  | 1355/1674 [1:29:01<15:49,  2.98s/it] 81%|████████  | 1356/1674 [1:29:05<17:43,  3.34s/it] 81%|████████  | 1357/1674 [1:29:08<17:43,  3.35s/it] 81%|████████  | 1358/1674 [1:29:11<17:31,  3.33s/it] 81%|████████  | 1359/1674 [1:29:15<18:11,  3.46s/it] 81%|████████  | 1360/1674 [1:29:19<18:54,  3.61s/it]                                                     {'loss': 0.3064, 'grad_norm': 12.571174621582031, 'learning_rate': 3.7896208201715653e-07, 'rewards/chosen': -1.825781226158142, 'rewards/rejected': -4.084374904632568, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.2562499046325684, 'logps/chosen': -126.94999694824219, 'logps/rejected': -167.0500030517578, 'logits/chosen': -9.78125, 'logits/rejected': -9.46875, 'epoch': 2.44}
 81%|████████  | 1360/1674 [1:29:19<18:54,  3.61s/it] 81%|████████▏ | 1361/1674 [1:29:23<19:25,  3.72s/it] 81%|████████▏ | 1362/1674 [1:29:26<18:31,  3.56s/it] 81%|████████▏ | 1363/1674 [1:29:29<16:52,  3.26s/it] 81%|████████▏ | 1364/1674 [1:29:33<17:54,  3.47s/it] 82%|████████▏ | 1365/1674 [1:29:37<18:56,  3.68s/it] 82%|████████▏ | 1366/1674 [1:29:40<17:41,  3.44s/it] 82%|████████▏ | 1367/1674 [1:29:44<18:50,  3.68s/it] 82%|████████▏ | 1368/1674 [1:29:48<19:31,  3.83s/it] 82%|████████▏ | 1369/1674 [1:29:52<19:51,  3.91s/it] 82%|████████▏ | 1370/1674 [1:29:56<19:07,  3.78s/it]                                                     {'loss': 0.2623, 'grad_norm': 16.028797149658203, 'learning_rate': 3.6348185836256286e-07, 'rewards/chosen': -1.692968726158142, 'rewards/rejected': -4.036035060882568, 'rewards/accuracies': 0.9333333969116211, 'rewards/margins': 2.346874952316284, 'logps/chosen': -186.85000610351562, 'logps/rejected': -233.64999389648438, 'logits/chosen': -9.4375, 'logits/rejected': -9.112500190734863, 'epoch': 2.46}
 82%|████████▏ | 1370/1674 [1:29:56<19:07,  3.78s/it] 82%|████████▏ | 1371/1674 [1:29:59<17:39,  3.50s/it] 82%|████████▏ | 1372/1674 [1:30:02<17:39,  3.51s/it] 82%|████████▏ | 1373/1674 [1:30:06<18:37,  3.71s/it] 82%|████████▏ | 1374/1674 [1:30:10<18:02,  3.61s/it] 82%|████████▏ | 1375/1674 [1:30:14<18:21,  3.68s/it] 82%|████████▏ | 1376/1674 [1:30:18<18:47,  3.78s/it] 82%|████████▏ | 1377/1674 [1:30:22<19:15,  3.89s/it] 82%|████████▏ | 1378/1674 [1:30:25<18:14,  3.70s/it] 82%|████████▏ | 1379/1674 [1:30:28<16:49,  3.42s/it] 82%|████████▏ | 1380/1674 [1:30:31<16:36,  3.39s/it]                                                     {'loss': 0.321, 'grad_norm': 33.66100311279297, 'learning_rate': 3.4826374370148605e-07, 'rewards/chosen': -1.3484375476837158, 'rewards/rejected': -3.5589842796325684, 'rewards/accuracies': 0.8416666984558105, 'rewards/margins': 2.2085938453674316, 'logps/chosen': -163.39999389648438, 'logps/rejected': -198.1999969482422, 'logits/chosen': -9.487500190734863, 'logits/rejected': -9.112500190734863, 'epoch': 2.47}
 82%|████████▏ | 1380/1674 [1:30:31<16:36,  3.39s/it] 82%|████████▏ | 1381/1674 [1:30:34<16:00,  3.28s/it] 83%|████████▎ | 1382/1674 [1:30:37<15:54,  3.27s/it] 83%|████████▎ | 1383/1674 [1:30:41<16:53,  3.48s/it] 83%|████████▎ | 1384/1674 [1:30:44<15:30,  3.21s/it] 83%|████████▎ | 1385/1674 [1:30:47<14:40,  3.05s/it] 83%|████████▎ | 1386/1674 [1:30:51<15:52,  3.31s/it] 83%|████████▎ | 1387/1674 [1:30:54<15:36,  3.26s/it] 83%|████████▎ | 1388/1674 [1:30:57<15:34,  3.27s/it] 83%|████████▎ | 1389/1674 [1:31:00<15:30,  3.27s/it] 83%|████████▎ | 1390/1674 [1:31:03<14:14,  3.01s/it]                                                     {'loss': 0.2522, 'grad_norm': 13.019304275512695, 'learning_rate': 3.333291236465103e-07, 'rewards/chosen': -0.8628906011581421, 'rewards/rejected': -3.313281297683716, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 2.453125, 'logps/chosen': -178.39999389648438, 'logps/rejected': -206.39999389648438, 'logits/chosen': -9.475000381469727, 'logits/rejected': -9.318750381469727, 'epoch': 2.49}
 83%|████████▎ | 1390/1674 [1:31:03<14:14,  3.01s/it] 83%|████████▎ | 1391/1674 [1:31:07<15:29,  3.29s/it] 83%|████████▎ | 1392/1674 [1:31:10<15:22,  3.27s/it] 83%|████████▎ | 1393/1674 [1:31:13<15:09,  3.24s/it] 83%|████████▎ | 1394/1674 [1:31:17<15:46,  3.38s/it] 83%|████████▎ | 1395/1674 [1:31:21<16:37,  3.58s/it] 83%|████████▎ | 1396/1674 [1:31:24<16:45,  3.62s/it] 83%|████████▎ | 1397/1674 [1:31:28<16:43,  3.62s/it] 84%|████████▎ | 1398/1674 [1:31:31<16:16,  3.54s/it] 84%|████████▎ | 1399/1674 [1:31:35<16:41,  3.64s/it] 84%|████████▎ | 1400/1674 [1:31:38<15:55,  3.49s/it]                                                     {'loss': 0.3756, 'grad_norm': 21.33493995666504, 'learning_rate': 3.186989854227754e-07, 'rewards/chosen': -2.077343702316284, 'rewards/rejected': -4.220312595367432, 'rewards/accuracies': 0.8166667222976685, 'rewards/margins': 2.137500047683716, 'logps/chosen': -143.14999389648438, 'logps/rejected': -188.10000610351562, 'logits/chosen': -9.443750381469727, 'logits/rejected': -9.262499809265137, 'epoch': 2.51}
 84%|████████▎ | 1400/1674 [1:31:38<15:55,  3.49s/it] 84%|████████▎ | 1401/1674 [1:31:42<15:42,  3.45s/it] 84%|████████▍ | 1402/1674 [1:31:44<14:22,  3.17s/it] 84%|████████▍ | 1403/1674 [1:31:48<15:07,  3.35s/it] 84%|████████▍ | 1404/1674 [1:31:51<14:12,  3.16s/it] 84%|████████▍ | 1405/1674 [1:31:54<13:38,  3.04s/it] 84%|████████▍ | 1406/1674 [1:31:58<14:59,  3.36s/it] 84%|████████▍ | 1407/1674 [1:32:01<14:44,  3.31s/it] 84%|████████▍ | 1408/1674 [1:32:04<14:38,  3.30s/it] 84%|████████▍ | 1409/1674 [1:32:08<15:27,  3.50s/it] 84%|████████▍ | 1410/1674 [1:32:11<15:06,  3.43s/it]                                                     {'loss': 0.2836, 'grad_norm': 17.26722526550293, 'learning_rate': 3.0439388837518563e-07, 'rewards/chosen': -1.834375023841858, 'rewards/rejected': -4.020312309265137, 'rewards/accuracies': 0.9333332777023315, 'rewards/margins': 2.1859374046325684, 'logps/chosen': -122.05000305175781, 'logps/rejected': -166.14999389648438, 'logits/chosen': -9.712499618530273, 'logits/rejected': -9.40625, 'epoch': 2.53}
 84%|████████▍ | 1410/1674 [1:32:11<15:06,  3.43s/it] 84%|████████▍ | 1411/1674 [1:32:15<15:04,  3.44s/it] 84%|████████▍ | 1412/1674 [1:32:17<13:26,  3.08s/it] 84%|████████▍ | 1413/1674 [1:32:20<13:35,  3.12s/it] 84%|████████▍ | 1414/1674 [1:32:24<14:08,  3.26s/it] 85%|████████▍ | 1415/1674 [1:32:27<13:53,  3.22s/it] 85%|████████▍ | 1416/1674 [1:32:30<13:26,  3.13s/it] 85%|████████▍ | 1417/1674 [1:32:34<14:39,  3.42s/it] 85%|████████▍ | 1418/1674 [1:32:38<15:28,  3.63s/it] 85%|████████▍ | 1419/1674 [1:32:42<15:36,  3.67s/it] 85%|████████▍ | 1420/1674 [1:32:46<15:42,  3.71s/it]                                                     {'loss': 0.3137, 'grad_norm': 45.93500900268555, 'learning_rate': 2.9043393507690855e-07, 'rewards/chosen': -1.6687500476837158, 'rewards/rejected': -4.037499904632568, 'rewards/accuracies': 0.8666666746139526, 'rewards/margins': 2.3648438453674316, 'logps/chosen': -138.14999389648438, 'logps/rejected': -165.35000610351562, 'logits/chosen': -9.59375, 'logits/rejected': -9.375, 'epoch': 2.54}
 85%|████████▍ | 1420/1674 [1:32:46<15:42,  3.71s/it] 85%|████████▍ | 1421/1674 [1:32:49<15:38,  3.71s/it] 85%|████████▍ | 1422/1674 [1:32:54<16:06,  3.83s/it] 85%|████████▌ | 1423/1674 [1:32:56<14:35,  3.49s/it] 85%|████████▌ | 1424/1674 [1:32:59<13:50,  3.32s/it] 85%|████████▌ | 1425/1674 [1:33:03<14:49,  3.57s/it] 85%|████████▌ | 1426/1674 [1:33:06<13:49,  3.35s/it] 85%|████████▌ | 1427/1674 [1:33:09<13:37,  3.31s/it] 85%|████████▌ | 1428/1674 [1:33:13<14:22,  3.51s/it] 85%|████████▌ | 1429/1674 [1:33:16<13:27,  3.30s/it] 85%|████████▌ | 1430/1674 [1:33:20<13:56,  3.43s/it]                                                     {'loss': 0.2533, 'grad_norm': 23.081518173217773, 'learning_rate': 2.7683874307976173e-07, 'rewards/chosen': -1.7078125476837158, 'rewards/rejected': -3.942187547683716, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 2.237499952316284, 'logps/chosen': -111.5, 'logps/rejected': -167.4499969482422, 'logits/chosen': -9.681249618530273, 'logits/rejected': -9.3125, 'epoch': 2.56}
 85%|████████▌ | 1430/1674 [1:33:20<13:56,  3.43s/it] 85%|████████▌ | 1431/1674 [1:33:24<14:33,  3.60s/it] 86%|████████▌ | 1432/1674 [1:33:26<13:04,  3.24s/it] 86%|████████▌ | 1433/1674 [1:33:30<13:10,  3.28s/it] 86%|████████▌ | 1434/1674 [1:33:33<13:29,  3.37s/it] 86%|████████▌ | 1435/1674 [1:33:37<13:54,  3.49s/it] 86%|████████▌ | 1436/1674 [1:33:41<14:20,  3.62s/it] 86%|████████▌ | 1437/1674 [1:33:45<14:39,  3.71s/it] 86%|████████▌ | 1438/1674 [1:33:48<14:18,  3.64s/it] 86%|████████▌ | 1439/1674 [1:33:51<13:27,  3.44s/it] 86%|████████▌ | 1440/1674 [1:33:54<12:38,  3.24s/it]                                                     {'loss': 0.2836, 'grad_norm': 23.97125244140625, 'learning_rate': 2.636274173461888e-07, 'rewards/chosen': -0.787109375, 'rewards/rejected': -3.0427002906799316, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.253124952316284, 'logps/chosen': -181.25, 'logps/rejected': -211.35000610351562, 'logits/chosen': -9.443750381469727, 'logits/rejected': -9.168749809265137, 'epoch': 2.58}
 86%|████████▌ | 1440/1674 [1:33:54<12:38,  3.24s/it] 86%|████████▌ | 1441/1674 [1:33:57<12:39,  3.26s/it] 86%|████████▌ | 1442/1674 [1:34:01<13:35,  3.52s/it] 86%|████████▌ | 1443/1674 [1:34:05<13:13,  3.44s/it] 86%|████████▋ | 1444/1674 [1:34:09<13:45,  3.59s/it] 86%|████████▋ | 1445/1674 [1:34:12<13:26,  3.52s/it] 86%|████████▋ | 1446/1674 [1:34:15<13:06,  3.45s/it] 86%|████████▋ | 1447/1674 [1:34:19<13:02,  3.45s/it] 86%|████████▋ | 1448/1674 [1:34:23<13:53,  3.69s/it] 87%|████████▋ | 1449/1674 [1:34:26<12:50,  3.43s/it] 87%|████████▋ | 1450/1674 [1:34:30<13:13,  3.54s/it]                                                     {'loss': 0.3578, 'grad_norm': 24.44393539428711, 'learning_rate': 2.508185234015627e-07, 'rewards/chosen': -1.889062523841858, 'rewards/rejected': -3.7796874046325684, 'rewards/accuracies': 0.8583332896232605, 'rewards/margins': 1.885156273841858, 'logps/chosen': -125.80000305175781, 'logps/rejected': -169.0, 'logits/chosen': -9.40625, 'logits/rejected': -9.256250381469727, 'epoch': 2.6}
 87%|████████▋ | 1450/1674 [1:34:30<13:13,  3.54s/it] 87%|████████▋ | 1451/1674 [1:34:33<13:04,  3.52s/it] 87%|████████▋ | 1452/1674 [1:34:36<12:44,  3.44s/it] 87%|████████▋ | 1453/1674 [1:34:40<13:11,  3.58s/it] 87%|████████▋ | 1454/1674 [1:34:43<12:41,  3.46s/it] 87%|████████▋ | 1455/1674 [1:34:45<11:03,  3.03s/it] 87%|████████▋ | 1456/1674 [1:34:48<10:34,  2.91s/it] 87%|████████▋ | 1457/1674 [1:34:51<10:36,  2.93s/it] 87%|████████▋ | 1458/1674 [1:34:54<10:34,  2.94s/it] 87%|████████▋ | 1459/1674 [1:34:56<09:54,  2.76s/it] 87%|████████▋ | 1460/1674 [1:35:00<10:29,  2.94s/it]                                                     {'loss': 0.2362, 'grad_norm': 22.719310760498047, 'learning_rate': 2.3843006124454546e-07, 'rewards/chosen': -1.498046875, 'rewards/rejected': -3.745312452316284, 'rewards/accuracies': 0.9416667222976685, 'rewards/margins': 2.2484374046325684, 'logps/chosen': -116.3499984741211, 'logps/rejected': -155.8000030517578, 'logits/chosen': -9.5, 'logits/rejected': -9.262499809265137, 'epoch': 2.62}
 87%|████████▋ | 1460/1674 [1:35:00<10:29,  2.94s/it] 87%|████████▋ | 1461/1674 [1:35:03<10:36,  2.99s/it] 87%|████████▋ | 1462/1674 [1:35:07<11:25,  3.24s/it] 87%|████████▋ | 1463/1674 [1:35:09<10:52,  3.09s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:58,  1.34it/s][A
  4%|▍         | 3/80 [00:03<01:24,  1.09s/it][A
  5%|▌         | 4/80 [00:04<01:36,  1.27s/it][A
  6%|▋         | 5/80 [00:06<01:45,  1.41s/it][A
  8%|▊         | 6/80 [00:07<01:48,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:50,  1.51s/it][A
 10%|█         | 8/80 [00:11<01:52,  1.56s/it][A
 11%|█▏        | 9/80 [00:12<01:51,  1.57s/it][A
 12%|█▎        | 10/80 [00:14<01:52,  1.61s/it][A
 14%|█▍        | 11/80 [00:16<01:52,  1.63s/it][A
 15%|█▌        | 12/80 [00:17<01:49,  1.61s/it][A
 16%|█▋        | 13/80 [00:19<01:47,  1.60s/it][A
 18%|█▊        | 14/80 [00:21<01:48,  1.64s/it][A
 19%|█▉        | 15/80 [00:22<01:46,  1.63s/it][A
 20%|██        | 16/80 [00:24<01:43,  1.61s/it][A
 21%|██▏       | 17/80 [00:25<01:41,  1.61s/it][A
 22%|██▎       | 18/80 [00:27<01:39,  1.61s/it][A
 24%|██▍       | 19/80 [00:28<01:29,  1.46s/it][A
 25%|██▌       | 20/80 [00:29<01:24,  1.40s/it][A
 26%|██▋       | 21/80 [00:30<01:07,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:05,  1.12s/it][A
 29%|██▉       | 23/80 [00:32<01:03,  1.11s/it][A
 30%|███       | 24/80 [00:32<00:51,  1.09it/s][A
 31%|███▏      | 25/80 [00:34<00:54,  1.00it/s][A
 32%|███▎      | 26/80 [00:35<00:58,  1.08s/it][A
 34%|███▍      | 27/80 [00:36<00:50,  1.04it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.03it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.09s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:45,  1.06it/s][A
 41%|████▏     | 33/80 [00:42<00:54,  1.15s/it][A
 42%|████▎     | 34/80 [00:44<00:56,  1.24s/it][A
 44%|████▍     | 35/80 [00:44<00:45,  1.01s/it][A
 45%|████▌     | 36/80 [00:45<00:41,  1.07it/s][A
 46%|████▋     | 37/80 [00:46<00:40,  1.07it/s][A
 48%|████▊     | 38/80 [00:46<00:34,  1.23it/s][A
 49%|████▉     | 39/80 [00:48<00:41,  1.01s/it][A
 50%|█████     | 40/80 [00:50<00:48,  1.21s/it][A
 51%|█████▏    | 41/80 [00:50<00:39,  1.02s/it][A
 52%|█████▎    | 42/80 [00:52<00:45,  1.18s/it][A
 54%|█████▍    | 43/80 [00:53<00:46,  1.26s/it][A
 55%|█████▌    | 44/80 [00:54<00:44,  1.25s/it][A
 56%|█████▋    | 45/80 [00:55<00:39,  1.12s/it][A
 57%|█████▊    | 46/80 [00:56<00:31,  1.08it/s][A
 59%|█████▉    | 47/80 [00:57<00:35,  1.08s/it][A
 60%|██████    | 48/80 [00:59<00:37,  1.19s/it][A
 61%|██████▏   | 49/80 [00:59<00:31,  1.00s/it][A
 62%|██████▎   | 50/80 [01:00<00:25,  1.19it/s][A
 64%|██████▍   | 51/80 [01:01<00:30,  1.06s/it][A
 65%|██████▌   | 52/80 [01:02<00:30,  1.08s/it][A
 66%|██████▋   | 53/80 [01:03<00:26,  1.02it/s][A
 68%|██████▊   | 54/80 [01:05<00:29,  1.12s/it][A
 69%|██████▉   | 55/80 [01:05<00:25,  1.02s/it][A
 70%|███████   | 56/80 [01:07<00:28,  1.19s/it][A
 71%|███████▏  | 57/80 [01:08<00:23,  1.02s/it][A
 72%|███████▎  | 58/80 [01:09<00:25,  1.15s/it][A
 74%|███████▍  | 59/80 [01:10<00:25,  1.21s/it][A
 75%|███████▌  | 60/80 [01:11<00:20,  1.01s/it][A
 76%|███████▋  | 61/80 [01:12<00:22,  1.17s/it][A
 78%|███████▊  | 62/80 [01:14<00:23,  1.33s/it][A
 79%|███████▉  | 63/80 [01:15<00:21,  1.25s/it][A
 80%|████████  | 64/80 [01:16<00:18,  1.13s/it][A
 81%|████████▏ | 65/80 [01:18<00:18,  1.23s/it][A
 82%|████████▎ | 66/80 [01:19<00:18,  1.33s/it][A
 84%|████████▍ | 67/80 [01:21<00:18,  1.44s/it][A
 85%|████████▌ | 68/80 [01:22<00:17,  1.47s/it][A
 86%|████████▋ | 69/80 [01:23<00:15,  1.38s/it][A
 88%|████████▊ | 70/80 [01:25<00:13,  1.34s/it][A
 89%|████████▉ | 71/80 [01:26<00:11,  1.33s/it][A
 90%|█████████ | 72/80 [01:28<00:11,  1.40s/it][A
 91%|█████████▏| 73/80 [01:28<00:08,  1.20s/it][A
 92%|█████████▎| 74/80 [01:30<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:31<00:06,  1.27s/it][A
 95%|█████████▌| 76/80 [01:33<00:05,  1.36s/it][A
 96%|█████████▋| 77/80 [01:34<00:04,  1.36s/it][A
 98%|█████████▊| 78/80 [01:35<00:02,  1.12s/it][A
 99%|█████████▉| 79/80 [01:36<00:01,  1.26s/it][A
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A                                                     
                                               [A{'eval_loss': 0.842032253742218, 'eval_runtime': 99.9851, 'eval_samples_per_second': 9.531, 'eval_steps_per_second': 0.8, 'eval_rewards/chosen': 0.0023925781715661287, 'eval_rewards/rejected': -1.9488341808319092, 'eval_rewards/accuracies': 0.7420834302902222, 'eval_rewards/margins': 1.9513733386993408, 'eval_logps/chosen': -377.7749938964844, 'eval_logps/rejected': -172.6999969482422, 'eval_logits/chosen': -8.908203125, 'eval_logits/rejected': -9.159375190734863, 'epoch': 2.62}
 87%|████████▋ | 1463/1674 [1:36:49<10:52,  3.09s/it]
100%|██████████| 80/80 [01:38<00:00,  1.37s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 87%|████████▋ | 1464/1674 [1:37:04<2:07:34, 36.45s/it] 88%|████████▊ | 1465/1674 [1:37:07<1:32:21, 26.52s/it] 88%|████████▊ | 1466/1674 [1:37:10<1:07:28, 19.46s/it] 88%|████████▊ | 1467/1674 [1:37:14<51:02, 14.79s/it]   88%|████████▊ | 1468/1674 [1:37:18<39:54, 11.62s/it] 88%|████████▊ | 1469/1674 [1:37:21<31:05,  9.10s/it] 88%|████████▊ | 1470/1674 [1:37:24<24:50,  7.31s/it]                                                     {'loss': 0.296, 'grad_norm': 22.22222900390625, 'learning_rate': 2.2647944005216734e-07, 'rewards/chosen': -1.4734375476837158, 'rewards/rejected': -3.6812500953674316, 'rewards/accuracies': 0.8666666150093079, 'rewards/margins': 2.2046875953674316, 'logps/chosen': -156.35000610351562, 'logps/rejected': -216.5, 'logits/chosen': -9.587499618530273, 'logits/rejected': -9.149999618530273, 'epoch': 2.63}
 88%|████████▊ | 1470/1674 [1:37:25<24:50,  7.31s/it] 88%|████████▊ | 1471/1674 [1:37:28<21:19,  6.30s/it] 88%|████████▊ | 1472/1674 [1:37:32<18:48,  5.59s/it] 88%|████████▊ | 1473/1674 [1:37:36<17:14,  5.15s/it] 88%|████████▊ | 1474/1674 [1:37:39<14:51,  4.46s/it] 88%|████████▊ | 1475/1674 [1:37:43<14:21,  4.33s/it] 88%|████████▊ | 1476/1674 [1:37:47<13:13,  4.01s/it] 88%|████████▊ | 1477/1674 [1:37:51<13:04,  3.98s/it] 88%|████████▊ | 1478/1674 [1:37:54<12:58,  3.97s/it] 88%|████████▊ | 1479/1674 [1:37:58<12:12,  3.76s/it] 88%|████████▊ | 1480/1674 [1:38:01<11:10,  3.46s/it]                                                     {'loss': 0.3063, 'grad_norm': 22.791425704956055, 'learning_rate': 2.1498345371517368e-07, 'rewards/chosen': -0.603515625, 'rewards/rejected': -2.8003907203674316, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.1968750953674316, 'logps/chosen': -187.0500030517578, 'logps/rejected': -228.0, 'logits/chosen': -9.418749809265137, 'logits/rejected': -9.087499618530273, 'epoch': 2.65}
 88%|████████▊ | 1480/1674 [1:38:01<11:10,  3.46s/it] 88%|████████▊ | 1481/1674 [1:38:05<12:01,  3.74s/it] 89%|████████▊ | 1482/1674 [1:38:08<11:31,  3.60s/it] 89%|████████▊ | 1483/1674 [1:38:12<11:47,  3.71s/it] 89%|████████▊ | 1484/1674 [1:38:16<11:50,  3.74s/it] 89%|████████▊ | 1485/1674 [1:38:19<11:33,  3.67s/it] 89%|████████▉ | 1486/1674 [1:38:23<11:20,  3.62s/it] 89%|████████▉ | 1487/1674 [1:38:27<11:20,  3.64s/it] 89%|████████▉ | 1488/1674 [1:38:30<11:19,  3.65s/it] 89%|████████▉ | 1489/1674 [1:38:34<11:30,  3.73s/it] 89%|████████▉ | 1490/1674 [1:38:38<11:29,  3.75s/it]                                                     {'loss': 0.3455, 'grad_norm': 33.644187927246094, 'learning_rate': 2.0395825723801495e-07, 'rewards/chosen': -2.100781202316284, 'rewards/rejected': -4.484375, 'rewards/accuracies': 0.89166659116745, 'rewards/margins': 2.3851561546325684, 'logps/chosen': -145.39999389648438, 'logps/rejected': -182.10000610351562, 'logits/chosen': -9.556249618530273, 'logits/rejected': -9.256250381469727, 'epoch': 2.67}
 89%|████████▉ | 1490/1674 [1:38:38<11:29,  3.75s/it] 89%|████████▉ | 1491/1674 [1:38:41<11:08,  3.65s/it] 89%|████████▉ | 1492/1674 [1:38:46<11:31,  3.80s/it] 89%|████████▉ | 1493/1674 [1:38:50<11:35,  3.84s/it] 89%|████████▉ | 1494/1674 [1:38:54<11:39,  3.89s/it] 89%|████████▉ | 1495/1674 [1:38:57<11:03,  3.71s/it] 89%|████████▉ | 1496/1674 [1:39:01<11:37,  3.92s/it] 89%|████████▉ | 1497/1674 [1:39:05<11:01,  3.74s/it] 89%|████████▉ | 1498/1674 [1:39:08<11:06,  3.79s/it] 90%|████████▉ | 1499/1674 [1:39:12<10:54,  3.74s/it] 90%|████████▉ | 1500/1674 [1:39:15<10:25,  3.60s/it]                                                     {'loss': 0.2862, 'grad_norm': 21.93729591369629, 'learning_rate': 1.9341934403664836e-07, 'rewards/chosen': -1.497656226158142, 'rewards/rejected': -3.5238280296325684, 'rewards/accuracies': 0.908333420753479, 'rewards/margins': 2.0328125953674316, 'logps/chosen': -161.85000610351562, 'logps/rejected': -206.5, 'logits/chosen': -9.412500381469727, 'logits/rejected': -9.118749618530273, 'epoch': 2.69}
 90%|████████▉ | 1500/1674 [1:39:16<10:25,  3.60s/it] 90%|████████▉ | 1501/1674 [1:39:19<10:25,  3.62s/it] 90%|████████▉ | 1502/1674 [1:39:22<10:03,  3.51s/it] 90%|████████▉ | 1503/1674 [1:39:26<10:15,  3.60s/it] 90%|████████▉ | 1504/1674 [1:39:30<10:25,  3.68s/it] 90%|████████▉ | 1505/1674 [1:39:34<10:49,  3.84s/it] 90%|████████▉ | 1506/1674 [1:39:38<10:30,  3.75s/it] 90%|█████████ | 1507/1674 [1:39:41<10:10,  3.66s/it] 90%|█████████ | 1508/1674 [1:39:45<09:55,  3.59s/it] 90%|█████████ | 1509/1674 [1:39:47<09:08,  3.32s/it] 90%|█████████ | 1510/1674 [1:39:49<07:56,  2.91s/it]                                                     {'loss': 0.321, 'grad_norm': 19.165374755859375, 'learning_rate': 1.8338152416605174e-07, 'rewards/chosen': -1.783593773841858, 'rewards/rejected': -3.667187452316284, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.8820312023162842, 'logps/chosen': -113.94999694824219, 'logps/rejected': -158.8000030517578, 'logits/chosen': -9.625, 'logits/rejected': -9.231249809265137, 'epoch': 2.71}
 90%|█████████ | 1510/1674 [1:39:49<07:56,  2.91s/it] 90%|█████████ | 1511/1674 [1:39:53<08:58,  3.31s/it] 90%|█████████ | 1512/1674 [1:39:56<08:40,  3.21s/it] 90%|█████████ | 1513/1674 [1:40:00<09:12,  3.43s/it] 90%|█████████ | 1514/1674 [1:40:03<08:46,  3.29s/it] 91%|█████████ | 1515/1674 [1:40:07<08:40,  3.27s/it] 91%|█████████ | 1516/1674 [1:40:10<08:46,  3.33s/it] 91%|█████████ | 1517/1674 [1:40:13<08:16,  3.16s/it] 91%|█████████ | 1518/1674 [1:40:16<08:35,  3.30s/it] 91%|█████████ | 1519/1674 [1:40:20<08:28,  3.28s/it] 91%|█████████ | 1520/1674 [1:40:22<08:00,  3.12s/it]                                                     {'loss': 0.2603, 'grad_norm': 28.427770614624023, 'learning_rate': 1.7385890350804566e-07, 'rewards/chosen': -2.1070313453674316, 'rewards/rejected': -4.287499904632568, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.184375047683716, 'logps/chosen': -129.1999969482422, 'logps/rejected': -177.39999389648438, 'logits/chosen': -9.568750381469727, 'logits/rejected': -9.1875, 'epoch': 2.72}
 91%|█████████ | 1520/1674 [1:40:22<08:00,  3.12s/it] 91%|█████████ | 1521/1674 [1:40:26<08:38,  3.39s/it] 91%|█████████ | 1522/1674 [1:40:30<08:33,  3.38s/it] 91%|█████████ | 1523/1674 [1:40:32<07:58,  3.17s/it] 91%|█████████ | 1524/1674 [1:40:37<08:39,  3.46s/it] 91%|█████████ | 1525/1674 [1:40:40<08:40,  3.49s/it] 91%|█████████ | 1526/1674 [1:40:44<08:51,  3.59s/it] 91%|█████████ | 1527/1674 [1:40:47<08:42,  3.56s/it] 91%|█████████▏| 1528/1674 [1:40:51<08:25,  3.47s/it] 91%|█████████▏| 1529/1674 [1:40:55<08:40,  3.59s/it] 91%|█████████▏| 1530/1674 [1:40:58<08:17,  3.45s/it]                                                     {'loss': 0.3527, 'grad_norm': 16.795551300048828, 'learning_rate': 1.6486486394867308e-07, 'rewards/chosen': -1.47265625, 'rewards/rejected': -3.592529296875, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.1156249046325684, 'logps/chosen': -161.85000610351562, 'logps/rejected': -218.1999969482422, 'logits/chosen': -9.356249809265137, 'logits/rejected': -9.081250190734863, 'epoch': 2.74}
 91%|█████████▏| 1530/1674 [1:40:58<08:17,  3.45s/it] 91%|█████████▏| 1531/1674 [1:41:01<08:26,  3.54s/it] 92%|█████████▏| 1532/1674 [1:41:04<07:55,  3.35s/it] 92%|█████████▏| 1533/1674 [1:41:07<07:18,  3.11s/it] 92%|█████████▏| 1534/1674 [1:41:09<06:48,  2.91s/it] 92%|█████████▏| 1535/1674 [1:41:13<07:05,  3.06s/it] 92%|█████████▏| 1536/1674 [1:41:16<07:04,  3.08s/it] 92%|█████████▏| 1537/1674 [1:41:20<07:36,  3.33s/it] 92%|█████████▏| 1538/1674 [1:41:22<06:55,  3.06s/it] 92%|█████████▏| 1539/1674 [1:41:25<06:20,  2.82s/it] 92%|█████████▏| 1540/1674 [1:41:28<07:03,  3.16s/it]                                                     {'loss': 0.3277, 'grad_norm': 20.46761703491211, 'learning_rate': 1.564120445729896e-07, 'rewards/chosen': -1.619531273841858, 'rewards/rejected': -3.703125, 'rewards/accuracies': 0.8666666746139526, 'rewards/margins': 2.0835938453674316, 'logps/chosen': -108.55000305175781, 'logps/rejected': -154.25, 'logits/chosen': -9.462499618530273, 'logits/rejected': -9.131250381469727, 'epoch': 2.76}
 92%|█████████▏| 1540/1674 [1:41:29<07:03,  3.16s/it] 92%|█████████▏| 1541/1674 [1:41:32<07:28,  3.37s/it] 92%|█████████▏| 1542/1674 [1:41:36<07:43,  3.51s/it] 92%|█████████▏| 1543/1674 [1:41:39<07:24,  3.39s/it] 92%|█████████▏| 1544/1674 [1:41:43<07:17,  3.36s/it] 92%|█████████▏| 1545/1674 [1:41:46<07:03,  3.28s/it] 92%|█████████▏| 1546/1674 [1:41:48<06:21,  2.98s/it] 92%|█████████▏| 1547/1674 [1:41:51<06:06,  2.89s/it] 92%|█████████▏| 1548/1674 [1:41:53<05:46,  2.75s/it] 93%|█████████▎| 1549/1674 [1:41:56<05:48,  2.79s/it] 93%|█████████▎| 1550/1674 [1:41:59<06:02,  2.93s/it]                                                     {'loss': 0.2823, 'grad_norm': 35.63042449951172, 'learning_rate': 1.4851232390369258e-07, 'rewards/chosen': -1.5871093273162842, 'rewards/rejected': -3.4781250953674316, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 1.889062523841858, 'logps/chosen': -122.9000015258789, 'logps/rejected': -139.8000030517578, 'logits/chosen': -9.481249809265137, 'logits/rejected': -9.393750190734863, 'epoch': 2.78}
 93%|█████████▎| 1550/1674 [1:41:59<06:02,  2.93s/it] 93%|█████████▎| 1551/1674 [1:42:03<06:24,  3.13s/it] 93%|█████████▎| 1552/1674 [1:42:07<06:49,  3.35s/it] 93%|█████████▎| 1553/1674 [1:42:11<07:10,  3.56s/it] 93%|█████████▎| 1554/1674 [1:42:13<06:16,  3.14s/it] 93%|█████████▎| 1555/1674 [1:42:16<06:12,  3.13s/it] 93%|█████████▎| 1556/1674 [1:42:19<06:16,  3.19s/it] 93%|█████████▎| 1557/1674 [1:42:23<06:17,  3.23s/it] 93%|█████████▎| 1558/1674 [1:42:25<05:55,  3.06s/it] 93%|█████████▎| 1559/1674 [1:42:28<05:51,  3.06s/it] 93%|█████████▎| 1560/1674 [1:42:31<05:40,  2.99s/it]                                                     {'loss': 0.2737, 'grad_norm': 12.919116973876953, 'learning_rate': 1.4117680320854893e-07, 'rewards/chosen': -1.8624999523162842, 'rewards/rejected': -3.996875047683716, 'rewards/accuracies': 0.8916667103767395, 'rewards/margins': 2.132031202316284, 'logps/chosen': -125.44999694824219, 'logps/rejected': -177.8000030517578, 'logits/chosen': -9.53125, 'logits/rejected': -9.25, 'epoch': 2.8}
 93%|█████████▎| 1560/1674 [1:42:31<05:40,  2.99s/it] 93%|█████████▎| 1561/1674 [1:42:34<05:46,  3.06s/it] 93%|█████████▎| 1562/1674 [1:42:39<06:23,  3.42s/it] 93%|█████████▎| 1563/1674 [1:42:42<06:28,  3.50s/it] 93%|█████████▎| 1564/1674 [1:42:46<06:38,  3.62s/it] 93%|█████████▎| 1565/1674 [1:42:50<06:50,  3.77s/it] 94%|█████████▎| 1566/1674 [1:42:54<06:48,  3.78s/it] 94%|█████████▎| 1567/1674 [1:42:57<05:59,  3.36s/it] 94%|█████████▎| 1568/1674 [1:43:00<06:01,  3.41s/it] 94%|█████████▎| 1569/1674 [1:43:04<06:22,  3.65s/it] 94%|█████████▍| 1570/1674 [1:43:07<06:03,  3.49s/it]                                                     {'loss': 0.2583, 'grad_norm': 32.21495056152344, 'learning_rate': 1.3441579090007802e-07, 'rewards/chosen': -1.369531273841858, 'rewards/rejected': -3.5746092796325684, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 2.2054686546325684, 'logps/chosen': -158.6999969482422, 'logps/rejected': -213.5, 'logits/chosen': -9.462499618530273, 'logits/rejected': -9.09375, 'epoch': 2.81}
 94%|█████████▍| 1570/1674 [1:43:08<06:03,  3.49s/it] 94%|█████████▍| 1571/1674 [1:43:11<06:14,  3.63s/it] 94%|█████████▍| 1572/1674 [1:43:15<06:21,  3.74s/it] 94%|█████████▍| 1573/1674 [1:43:19<06:21,  3.78s/it] 94%|█████████▍| 1574/1674 [1:43:23<06:07,  3.68s/it] 94%|█████████▍| 1575/1674 [1:43:25<05:18,  3.21s/it] 94%|█████████▍| 1576/1674 [1:43:27<04:46,  2.92s/it] 94%|█████████▍| 1577/1674 [1:43:31<05:10,  3.20s/it] 94%|█████████▍| 1578/1674 [1:43:33<04:46,  2.98s/it] 94%|█████████▍| 1579/1674 [1:43:37<05:10,  3.26s/it] 94%|█████████▍| 1580/1674 [1:43:41<05:23,  3.44s/it]                                                     {'loss': 0.3356, 'grad_norm': 35.48082733154297, 'learning_rate': 1.282387880494129e-07, 'rewards/chosen': -1.9695312976837158, 'rewards/rejected': -4.026562690734863, 'rewards/accuracies': 0.8666666746139526, 'rewards/margins': 2.0562500953674316, 'logps/chosen': -127.44999694824219, 'logps/rejected': -184.4499969482422, 'logits/chosen': -9.493749618530273, 'logits/rejected': -9.175000190734863, 'epoch': 2.83}
 94%|█████████▍| 1580/1674 [1:43:41<05:23,  3.44s/it] 94%|█████████▍| 1581/1674 [1:43:45<05:41,  3.67s/it] 95%|█████████▍| 1582/1674 [1:43:49<05:29,  3.59s/it] 95%|█████████▍| 1583/1674 [1:43:52<05:20,  3.52s/it] 95%|█████████▍| 1584/1674 [1:43:56<05:28,  3.65s/it] 95%|█████████▍| 1585/1674 [1:44:00<05:40,  3.82s/it] 95%|█████████▍| 1586/1674 [1:44:04<05:44,  3.92s/it] 95%|█████████▍| 1587/1674 [1:44:07<05:04,  3.50s/it] 95%|█████████▍| 1588/1674 [1:44:11<05:12,  3.64s/it] 95%|█████████▍| 1589/1674 [1:44:15<05:14,  3.71s/it] 95%|█████████▍| 1590/1674 [1:44:19<05:14,  3.75s/it]                                                     {'loss': 0.3614, 'grad_norm': 50.9622917175293, 'learning_rate': 1.226544750346977e-07, 'rewards/chosen': -1.5632812976837158, 'rewards/rejected': -3.54296875, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.9812500476837158, 'logps/chosen': -179.0500030517578, 'logps/rejected': -209.4499969482422, 'logits/chosen': -9.618749618530273, 'logits/rejected': -9.324999809265137, 'epoch': 2.85}
 95%|█████████▍| 1590/1674 [1:44:19<05:14,  3.75s/it] 95%|█████████▌| 1591/1674 [1:44:23<05:16,  3.81s/it] 95%|█████████▌| 1592/1674 [1:44:26<05:14,  3.84s/it] 95%|█████████▌| 1593/1674 [1:44:29<04:38,  3.44s/it] 95%|█████████▌| 1594/1674 [1:44:33<04:47,  3.59s/it] 95%|█████████▌| 1595/1674 [1:44:37<04:53,  3.72s/it] 95%|█████████▌| 1596/1674 [1:44:41<05:00,  3.85s/it] 95%|█████████▌| 1597/1674 [1:44:44<04:28,  3.48s/it] 95%|█████████▌| 1598/1674 [1:44:47<04:21,  3.43s/it] 96%|█████████▌| 1599/1674 [1:44:51<04:32,  3.64s/it] 96%|█████████▌| 1600/1674 [1:44:53<03:56,  3.19s/it]                                                     {'loss': 0.2311, 'grad_norm': 14.12452507019043, 'learning_rate': 1.1767069934278228e-07, 'rewards/chosen': -1.2742187976837158, 'rewards/rejected': -3.641845703125, 'rewards/accuracies': 0.908333420753479, 'rewards/margins': 2.3671875, 'logps/chosen': -144.85000610351562, 'logps/rejected': -198.0, 'logits/chosen': -9.399999618530273, 'logits/rejected': -8.943750381469727, 'epoch': 2.87}
 96%|█████████▌| 1600/1674 [1:44:53<03:56,  3.19s/it] 96%|█████████▌| 1601/1674 [1:44:57<03:52,  3.19s/it] 96%|█████████▌| 1602/1674 [1:45:00<04:05,  3.41s/it] 96%|█████████▌| 1603/1674 [1:45:03<03:39,  3.09s/it] 96%|█████████▌| 1604/1674 [1:45:07<03:57,  3.39s/it] 96%|█████████▌| 1605/1674 [1:45:10<03:58,  3.45s/it] 96%|█████████▌| 1606/1674 [1:45:14<04:03,  3.59s/it] 96%|█████████▌| 1607/1674 [1:45:18<03:56,  3.53s/it] 96%|█████████▌| 1608/1674 [1:45:22<03:57,  3.60s/it] 96%|█████████▌| 1609/1674 [1:45:25<03:58,  3.67s/it] 96%|█████████▌| 1610/1674 [1:45:29<03:58,  3.73s/it]                                                     {'loss': 0.2278, 'grad_norm': 19.516563415527344, 'learning_rate': 1.132944645413575e-07, 'rewards/chosen': -2.16015625, 'rewards/rejected': -4.410937309265137, 'rewards/accuracies': 0.9333332777023315, 'rewards/margins': 2.24609375, 'logps/chosen': -137.60000610351562, 'logps/rejected': -189.9499969482422, 'logits/chosen': -9.65625, 'logits/rejected': -9.28125, 'epoch': 2.89}
 96%|█████████▌| 1610/1674 [1:45:29<03:58,  3.73s/it] 96%|█████████▌| 1611/1674 [1:45:33<03:59,  3.80s/it] 96%|█████████▋| 1612/1674 [1:45:36<03:42,  3.59s/it] 96%|█████████▋| 1613/1674 [1:45:41<03:50,  3.78s/it] 96%|█████████▋| 1614/1674 [1:45:44<03:45,  3.76s/it] 96%|█████████▋| 1615/1674 [1:45:48<03:43,  3.78s/it] 97%|█████████▋| 1616/1674 [1:45:52<03:37,  3.75s/it] 97%|█████████▋| 1617/1674 [1:45:56<03:36,  3.80s/it] 97%|█████████▋| 1618/1674 [1:45:58<03:12,  3.44s/it] 97%|█████████▋| 1619/1674 [1:46:02<03:11,  3.49s/it] 97%|█████████▋| 1620/1674 [1:46:06<03:11,  3.55s/it]                                                     {'loss': 0.286, 'grad_norm': 21.32523536682129, 'learning_rate': 1.095319204370272e-07, 'rewards/chosen': -1.595312476158142, 'rewards/rejected': -3.750781297683716, 'rewards/accuracies': 0.8583332896232605, 'rewards/margins': 2.15625, 'logps/chosen': -180.39999389648438, 'logps/rejected': -238.89999389648438, 'logits/chosen': -9.393750190734863, 'logits/rejected': -9.050000190734863, 'epoch': 2.9}
 97%|█████████▋| 1620/1674 [1:46:06<03:11,  3.55s/it] 97%|█████████▋| 1621/1674 [1:46:08<02:53,  3.27s/it] 97%|█████████▋| 1622/1674 [1:46:12<03:03,  3.52s/it] 97%|█████████▋| 1623/1674 [1:46:16<02:57,  3.47s/it] 97%|█████████▋| 1624/1674 [1:46:19<02:46,  3.32s/it] 97%|█████████▋| 1625/1674 [1:46:22<02:43,  3.34s/it] 97%|█████████▋| 1626/1674 [1:46:25<02:39,  3.31s/it] 97%|█████████▋| 1627/1674 [1:46:28<02:23,  3.06s/it] 97%|█████████▋| 1628/1674 [1:46:30<02:16,  2.97s/it] 97%|█████████▋| 1629/1674 [1:46:34<02:14,  2.99s/it] 97%|█████████▋| 1630/1674 [1:46:37<02:19,  3.17s/it]                                                     {'loss': 0.2438, 'grad_norm': 24.902015686035156, 'learning_rate': 1.0638835443314856e-07, 'rewards/chosen': -1.708593726158142, 'rewards/rejected': -4.235937595367432, 'rewards/accuracies': 0.9166666865348816, 'rewards/margins': 2.524218797683716, 'logps/chosen': -124.6500015258789, 'logps/rejected': -166.6999969482422, 'logits/chosen': -9.550000190734863, 'logits/rejected': -9.274999618530273, 'epoch': 2.92}
 97%|█████████▋| 1630/1674 [1:46:37<02:19,  3.17s/it] 97%|█████████▋| 1631/1674 [1:46:41<02:29,  3.47s/it] 97%|█████████▋| 1632/1674 [1:46:44<02:16,  3.26s/it] 98%|█████████▊| 1633/1674 [1:46:47<02:12,  3.23s/it] 98%|█████████▊| 1634/1674 [1:46:50<02:07,  3.19s/it] 98%|█████████▊| 1635/1674 [1:46:54<02:11,  3.38s/it] 98%|█████████▊| 1636/1674 [1:46:58<02:11,  3.46s/it] 98%|█████████▊| 1637/1674 [1:47:02<02:11,  3.54s/it] 98%|█████████▊| 1638/1674 [1:47:06<02:12,  3.68s/it] 98%|█████████▊| 1639/1674 [1:47:08<01:54,  3.28s/it] 98%|█████████▊| 1640/1674 [1:47:12<01:59,  3.52s/it]                                                     {'loss': 0.274, 'grad_norm': 18.10657501220703, 'learning_rate': 1.0386818409958415e-07, 'rewards/chosen': -1.3742187023162842, 'rewards/rejected': -3.5916686058044434, 'rewards/accuracies': 0.9000000953674316, 'rewards/margins': 2.217968702316284, 'logps/chosen': -159.0500030517578, 'logps/rejected': -208.5, 'logits/chosen': -9.643750190734863, 'logits/rejected': -9.393750190734863, 'epoch': 2.94}
 98%|█████████▊| 1640/1674 [1:47:12<01:59,  3.52s/it] 98%|█████████▊| 1641/1674 [1:47:14<01:45,  3.20s/it] 98%|█████████▊| 1642/1674 [1:47:17<01:36,  3.02s/it] 98%|█████████▊| 1643/1674 [1:47:20<01:30,  2.92s/it] 98%|█████████▊| 1644/1674 [1:47:23<01:27,  2.92s/it] 98%|█████████▊| 1645/1674 [1:47:26<01:27,  3.01s/it] 98%|█████████▊| 1646/1674 [1:47:28<01:21,  2.90s/it] 98%|█████████▊| 1647/1674 [1:47:32<01:24,  3.12s/it] 98%|█████████▊| 1648/1674 [1:47:36<01:25,  3.30s/it] 99%|█████████▊| 1649/1674 [1:47:40<01:27,  3.50s/it] 99%|█████████▊| 1650/1674 [1:47:44<01:28,  3.68s/it]                                                     {'loss': 0.3158, 'grad_norm': 28.024600982666016, 'learning_rate': 1.0197495096480845e-07, 'rewards/chosen': -1.451171875, 'rewards/rejected': -3.6268553733825684, 'rewards/accuracies': 0.875, 'rewards/margins': 2.172656297683716, 'logps/chosen': -173.1999969482422, 'logps/rejected': -209.14999389648438, 'logits/chosen': -9.725000381469727, 'logits/rejected': -9.475000381469727, 'epoch': 2.96}
 99%|█████████▊| 1650/1674 [1:47:44<01:28,  3.68s/it] 99%|█████████▊| 1651/1674 [1:47:48<01:26,  3.75s/it] 99%|█████████▊| 1652/1674 [1:47:50<01:15,  3.42s/it] 99%|█████████▊| 1653/1674 [1:47:55<01:16,  3.63s/it] 99%|█████████▉| 1654/1674 [1:47:58<01:12,  3.63s/it] 99%|█████████▉| 1655/1674 [1:48:02<01:09,  3.68s/it] 99%|█████████▉| 1656/1674 [1:48:06<01:08,  3.79s/it] 99%|█████████▉| 1657/1674 [1:48:09<00:59,  3.50s/it] 99%|█████████▉| 1658/1674 [1:48:11<00:51,  3.19s/it] 99%|█████████▉| 1659/1674 [1:48:14<00:44,  2.93s/it] 99%|█████████▉| 1660/1674 [1:48:17<00:44,  3.17s/it]                                                     {'loss': 0.2555, 'grad_norm': 17.397972106933594, 'learning_rate': 1.0071131553909197e-07, 'rewards/chosen': -1.8464844226837158, 'rewards/rejected': -3.926562547683716, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.085156202316284, 'logps/chosen': -137.60000610351562, 'logps/rejected': -162.10000610351562, 'logits/chosen': -9.662500381469727, 'logits/rejected': -9.512499809265137, 'epoch': 2.97}
 99%|█████████▉| 1660/1674 [1:48:17<00:44,  3.17s/it] 99%|█████████▉| 1661/1674 [1:48:21<00:42,  3.24s/it] 99%|█████████▉| 1662/1674 [1:48:25<00:42,  3.51s/it] 99%|█████████▉| 1663/1674 [1:48:29<00:39,  3.63s/it] 99%|█████████▉| 1664/1674 [1:48:33<00:36,  3.67s/it] 99%|█████████▉| 1665/1674 [1:48:36<00:31,  3.44s/it]100%|█████████▉| 1666/1674 [1:48:39<00:28,  3.59s/it]100%|█████████▉| 1667/1674 [1:48:42<00:23,  3.36s/it]100%|█████████▉| 1668/1674 [1:48:44<00:18,  3.00s/it]100%|█████████▉| 1669/1674 [1:48:48<00:16,  3.24s/it]100%|█████████▉| 1670/1674 [1:48:52<00:13,  3.29s/it]                                                     {'loss': 0.394, 'grad_norm': 48.544830322265625, 'learning_rate': 1.0007905357575655e-07, 'rewards/chosen': -1.975000023841858, 'rewards/rejected': -3.667187452316284, 'rewards/accuracies': 0.8416666984558105, 'rewards/margins': 1.6925780773162842, 'logps/chosen': -125.0, 'logps/rejected': -166.9499969482422, 'logits/chosen': -9.581250190734863, 'logits/rejected': -9.425000190734863, 'epoch': 2.99}
100%|█████████▉| 1670/1674 [1:48:52<00:13,  3.29s/it]100%|█████████▉| 1671/1674 [1:48:56<00:10,  3.57s/it]100%|█████████▉| 1672/1674 [1:49:00<00:07,  3.62s/it]
  0%|          | 0/80 [00:00<?, ?it/s][A
  2%|▎         | 2/80 [00:01<00:57,  1.37it/s][A
  4%|▍         | 3/80 [00:03<01:23,  1.08s/it][A
  5%|▌         | 4/80 [00:04<01:35,  1.26s/it][A
  6%|▋         | 5/80 [00:06<01:44,  1.40s/it][A
  8%|▊         | 6/80 [00:07<01:47,  1.46s/it][A
  9%|▉         | 7/80 [00:09<01:49,  1.51s/it][A
 10%|█         | 8/80 [00:11<01:51,  1.55s/it][A
 11%|█▏        | 9/80 [00:12<01:51,  1.58s/it][A
 12%|█▎        | 10/80 [00:14<01:53,  1.62s/it][A
 14%|█▍        | 11/80 [00:16<01:53,  1.65s/it][A
 15%|█▌        | 12/80 [00:17<01:50,  1.62s/it][A
 16%|█▋        | 13/80 [00:19<01:47,  1.61s/it][A
 18%|█▊        | 14/80 [00:21<01:48,  1.65s/it][A
 19%|█▉        | 15/80 [00:22<01:47,  1.65s/it][A
 20%|██        | 16/80 [00:24<01:43,  1.62s/it][A
 21%|██▏       | 17/80 [00:25<01:42,  1.62s/it][A
 22%|██▎       | 18/80 [00:27<01:40,  1.62s/it][A
 24%|██▍       | 19/80 [00:28<01:29,  1.47s/it][A
 25%|██▌       | 20/80 [00:29<01:24,  1.41s/it][A
 26%|██▋       | 21/80 [00:30<01:08,  1.15s/it][A
 28%|██▊       | 22/80 [00:31<01:06,  1.14s/it][A
 29%|██▉       | 23/80 [00:32<01:04,  1.14s/it][A
 30%|███       | 24/80 [00:33<00:52,  1.06it/s][A
 31%|███▏      | 25/80 [00:34<00:55,  1.01s/it][A
 32%|███▎      | 26/80 [00:35<00:58,  1.09s/it][A
 34%|███▍      | 27/80 [00:36<00:51,  1.03it/s][A
 35%|███▌      | 28/80 [00:37<00:50,  1.02it/s][A
 36%|███▋      | 29/80 [00:38<00:54,  1.07s/it][A
 38%|███▊      | 30/80 [00:39<00:54,  1.10s/it][A
 39%|███▉      | 31/80 [00:40<00:53,  1.09s/it][A
 40%|████      | 32/80 [00:41<00:52,  1.09s/it][A
 41%|████▏     | 33/80 [00:43<00:58,  1.25s/it][A
 42%|████▎     | 34/80 [00:44<01:00,  1.31s/it][A
 44%|████▍     | 35/80 [00:45<00:47,  1.06s/it][A
 45%|████▌     | 36/80 [00:46<00:42,  1.03it/s][A
 46%|████▋     | 37/80 [00:47<00:41,  1.04it/s][A
 48%|████▊     | 38/80 [00:47<00:34,  1.20it/s][A
 49%|████▉     | 39/80 [00:49<00:41,  1.02s/it][A
 50%|█████     | 40/80 [00:51<00:50,  1.27s/it][A
 51%|█████▏    | 41/80 [00:51<00:41,  1.07s/it][A
 52%|█████▎    | 42/80 [00:53<00:46,  1.22s/it][A
 54%|█████▍    | 43/80 [00:54<00:47,  1.29s/it][A
 55%|█████▌    | 44/80 [00:55<00:45,  1.27s/it][A
 56%|█████▋    | 45/80 [00:56<00:39,  1.14s/it][A
 57%|█████▊    | 46/80 [00:57<00:32,  1.05it/s][A
 59%|█████▉    | 47/80 [00:58<00:36,  1.10s/it][A
 60%|██████    | 48/80 [01:00<00:38,  1.21s/it][A
 61%|██████▏   | 49/80 [01:00<00:31,  1.02s/it][A
 62%|██████▎   | 50/80 [01:01<00:26,  1.15it/s][A
 64%|██████▍   | 51/80 [01:02<00:31,  1.08s/it][A
 65%|██████▌   | 52/80 [01:04<00:30,  1.10s/it][A
 66%|██████▋   | 53/80 [01:04<00:26,  1.01it/s][A
 68%|██████▊   | 54/80 [01:06<00:29,  1.13s/it][A
 69%|██████▉   | 55/80 [01:06<00:25,  1.04s/it][A
 70%|███████   | 56/80 [01:08<00:28,  1.20s/it][A
 71%|███████▏  | 57/80 [01:09<00:23,  1.03s/it][A
 72%|███████▎  | 58/80 [01:10<00:25,  1.17s/it][A
 74%|███████▍  | 59/80 [01:12<00:25,  1.23s/it][A
 75%|███████▌  | 60/80 [01:12<00:20,  1.03s/it][A
 76%|███████▋  | 61/80 [01:14<00:22,  1.18s/it][A
 78%|███████▊  | 62/80 [01:15<00:24,  1.33s/it][A
 79%|███████▉  | 63/80 [01:16<00:21,  1.26s/it][A
 80%|████████  | 64/80 [01:17<00:18,  1.14s/it][A
 81%|████████▏ | 65/80 [01:19<00:19,  1.30s/it][A
 82%|████████▎ | 66/80 [01:21<00:19,  1.37s/it][A
 84%|████████▍ | 67/80 [01:22<00:19,  1.47s/it][A
 85%|████████▌ | 68/80 [01:24<00:17,  1.49s/it][A
 86%|████████▋ | 69/80 [01:25<00:15,  1.39s/it][A
 88%|████████▊ | 70/80 [01:26<00:13,  1.35s/it][A
 89%|████████▉ | 71/80 [01:27<00:12,  1.34s/it][A
 90%|█████████ | 72/80 [01:29<00:11,  1.41s/it][A
 91%|█████████▏| 73/80 [01:30<00:08,  1.21s/it][A
 92%|█████████▎| 74/80 [01:31<00:07,  1.31s/it][A
 94%|█████████▍| 75/80 [01:33<00:06,  1.29s/it][A
 95%|█████████▌| 76/80 [01:34<00:05,  1.37s/it][A
 96%|█████████▋| 77/80 [01:35<00:04,  1.38s/it][A
 98%|█████████▊| 78/80 [01:36<00:02,  1.14s/it][A
 99%|█████████▉| 79/80 [01:38<00:01,  1.27s/it][A
100%|██████████| 80/80 [01:39<00:00,  1.38s/it][A                                                     
                                               [A{'eval_loss': 0.8833925724029541, 'eval_runtime': 101.6224, 'eval_samples_per_second': 9.378, 'eval_steps_per_second': 0.787, 'eval_rewards/chosen': -0.02051086351275444, 'eval_rewards/rejected': -1.8833496570587158, 'eval_rewards/accuracies': 0.7316666841506958, 'eval_rewards/margins': 1.8634231090545654, 'eval_logps/chosen': -378.12188720703125, 'eval_logps/rejected': -172.14999389648438, 'eval_logits/chosen': -8.997265815734863, 'eval_logits/rejected': -9.252734184265137, 'epoch': 3.0}
100%|█████████▉| 1672/1674 [1:50:41<00:07,  3.62s/it]
100%|██████████| 80/80 [01:40<00:00,  1.38s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 1673/1674 [1:50:59<00:38, 38.34s/it]100%|██████████| 1674/1674 [1:51:02<00:00, 27.81s/it]                                                     {'train_runtime': 6682.712, 'train_samples_per_second': 3.003, 'train_steps_per_second': 0.25, 'train_loss': 0.4610461211688772, 'epoch': 3.0}
100%|██████████| 1674/1674 [1:51:21<00:00, 27.81s/it]100%|██████████| 1674/1674 [1:51:21<00:00,  3.99s/it]
Training complete
Saving model
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/offline-run-20250612_212350-5gvm872g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250612_212350-5gvm872g/logs[0m
[rank0]:[W612 23:16:20.842848601 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 0 ---
