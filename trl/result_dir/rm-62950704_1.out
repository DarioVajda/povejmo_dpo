cpu-bind=MASK - gn39, task  1  0 [1242594]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 4
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn33
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 4     --machine_rank 1     --main_process_ip gn33     --main_process_port 29500     --num_processes 16     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62950704     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train_curriculum.py"     --rank=64 --learning_rate=4e-7 --total_epochs=3 --beta=0.2 --curriculum_stage=2
-------------------------------------------
[2025-06-10 23:53:46,347] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0610 23:53:48.173000 1242646 torch/distributed/run.py:792] 
W0610 23:53:48.173000 1242646 torch/distributed/run.py:792] *****************************************
W0610 23:53:48.173000 1242646 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0610 23:53:48.173000 1242646 torch/distributed/run.py:792] *****************************************
[2025-06-10 23:53:57,764] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-10 23:53:57,795] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-10 23:53:57,816] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-10 23:53:57,826] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[load_data_curriculum.py]: Training data of type 'bad_lang_examples':    3489
[load_data_curriculum.py]: Training data of type 'short_examples':       699
[load_data_curriculum.py]: Training data of type 'choose_examples':      13379
[load_data_curriculum.py]: Training data of type 'bad_format_examples':  3148
[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *
[load_data_curriculum.py]: Evaluation data size: 953
[load_data_curriculum.py]: Curriculum stage 0 training data size: 4890
[load_data_curriculum.py]: Curriculum stage 1 training data size: 6689
[load_data_curriculum.py]: Curriculum stage 2 training data size: 6690
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2, curriculum_stage=2)
4e-07
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2, curriculum_stage=2)
4e-07
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2, curriculum_stage=2)
4e-07
[load_data.py]: Number of validation examples: 953
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2, curriculum_stage=2)
4e-07
World size: 16
Setting gradient accumulation steps to: 1
[2025-06-10 23:54:03,612] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-10 23:54:03,622] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-10 23:54:03,631] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Train dataset size: 6690
Validation dataset size: 953
Steps per epoch: 418
Evaluate each 209 steps
[2025-06-10 23:54:03,636] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
Loading model from: /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/trained_models/Curriculum_DPO_models/GaMS-9B-DPO-Curri-1
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:04, 21.48s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:05, 21.86s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:05, 21.86s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:21<01:05, 21.86s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:47<00:47, 23.92s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:47<00:48, 24.08s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:47<00:48, 24.08s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:47<00:48, 24.08s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:12<00:24, 24.40s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:12<00:24, 24.54s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:12<00:24, 24.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:12<00:24, 24.54s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.20s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.13s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.27s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.19s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.19s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.19s/it]
Loaded model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
[rank7]:[W610 23:55:36.347622348 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank6]:[W610 23:55:36.363844709 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s][rank5]:[W610 23:55:36.446596607 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   8%|▊         | 550/6690 [00:00<00:01, 5416.21 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1115/6690 [00:00<00:01, 5519.14 examples/s]Extracting prompt in train dataset:  25%|██▌       | 1680/6690 [00:00<00:00, 5563.08 examples/s]Extracting prompt in train dataset:  34%|███▎      | 2250/6690 [00:00<00:00, 5553.45 examples/s]Extracting prompt in train dataset:  42%|████▏     | 2817/6690 [00:00<00:00, 5594.54 examples/s]Extracting prompt in train dataset:  51%|█████     | 3390/6690 [00:00<00:00, 5609.38 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 3960/6690 [00:00<00:00, 5629.06 examples/s]Extracting prompt in train dataset:  71%|███████▏  | 4780/6690 [00:00<00:00, 5553.47 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 5350/6690 [00:00<00:00, 5586.63 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 5920/6690 [00:01<00:00, 5612.57 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 6498/6690 [00:01<00:00, 5643.62 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5524.81 examples/s]
Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   4%|▍         | 293/6690 [00:00<00:02, 2902.23 examples/s]Applying chat template to train dataset:   9%|▉         | 614/6690 [00:00<00:01, 3075.26 examples/s]Applying chat template to train dataset:  14%|█▍        | 935/6690 [00:00<00:01, 3133.49 examples/s]Applying chat template to train dataset:  19%|█▊        | 1254/6690 [00:00<00:01, 3152.34 examples/s]Applying chat template to train dataset:  24%|██▎       | 1575/6690 [00:00<00:01, 3168.86 examples/s]Applying chat template to train dataset:  28%|██▊       | 1896/6690 [00:00<00:01, 3181.53 examples/s]Applying chat template to train dataset:  33%|███▎      | 2217/6690 [00:00<00:01, 3187.97 examples/s]Applying chat template to train dataset:  40%|████      | 2692/6690 [00:00<00:01, 3176.17 examples/s]Applying chat template to train dataset:  45%|████▌     | 3013/6690 [00:00<00:01, 3183.54 examples/s]Applying chat template to train dataset:  50%|████▉     | 3334/6690 [00:01<00:01, 3189.42 examples/s]Applying chat template to train dataset:  55%|█████▍    | 3654/6690 [00:01<00:00, 3190.11 examples/s]Applying chat template to train dataset:  59%|█████▉    | 3976/6690 [00:01<00:00, 3194.86 examples/s]Applying chat template to train dataset:  64%|██████▍   | 4297/6690 [00:01<00:00, 3198.72 examples/s]Applying chat template to train dataset:  71%|███████   | 4759/6690 [00:01<00:00, 3150.18 examples/s]Applying chat template to train dataset:  76%|███████▌  | 5077/6690 [00:01<00:00, 3156.06 examples/s]Applying chat template to train dataset:  81%|████████  | 5405/6690 [00:01<00:00, 3189.67 examples/s]Applying chat template to train dataset:  86%|████████▌ | 5732/6690 [00:01<00:00, 3206.96 examples/s]Applying chat template to train dataset:  93%|█████████▎| 6214/6690 [00:01<00:00, 3204.53 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3196.32 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3169.56 examples/s]
Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 37/6690 [00:00<00:18, 367.55 examples/s]Tokenizing train dataset:   1%|▏         | 88/6690 [00:00<00:15, 437.52 examples/s]Tokenizing train dataset:   2%|▏         | 155/6690 [00:00<00:15, 433.83 examples/s]Tokenizing train dataset:   3%|▎         | 204/6690 [00:00<00:14, 448.96 examples/s]Tokenizing train dataset:   4%|▍         | 254/6690 [00:00<00:13, 460.39 examples/s]Tokenizing train dataset:   5%|▍         | 319/6690 [00:00<00:14, 444.13 examples/s]Tokenizing train dataset:   6%|▌         | 370/6690 [00:00<00:13, 458.87 examples/s]Tokenizing train dataset:   7%|▋         | 442/6690 [00:00<00:13, 464.42 examples/s]Tokenizing train dataset:   7%|▋         | 491/6690 [00:01<00:13, 469.41 examples/s]Tokenizing train dataset:   8%|▊         | 540/6690 [00:01<00:13, 468.28 examples/s]Tokenizing train dataset:   9%|▉         | 589/6690 [00:01<00:12, 470.22 examples/s]Tokenizing train dataset:  10%|▉         | 640/6690 [00:01<00:12, 479.24 examples/s]Tokenizing train dataset:  10%|█         | 689/6690 [00:01<00:12, 475.65 examples/s]Tokenizing train dataset:  11%|█         | 740/6690 [00:01<00:12, 480.34 examples/s]Tokenizing train dataset:  12%|█▏        | 793/6690 [00:01<00:12, 484.82 examples/s]Tokenizing train dataset:  13%|█▎        | 865/6690 [00:01<00:12, 478.39 examples/s]Tokenizing train dataset:  14%|█▍        | 923/6690 [00:02<00:13, 441.51 examples/s]Tokenizing train dataset:  15%|█▍        | 971/6690 [00:02<00:12, 449.66 examples/s]Tokenizing train dataset:  16%|█▌        | 1039/6690 [00:02<00:12, 446.63 examples/s]Tokenizing train dataset:  16%|█▋        | 1088/6690 [00:02<00:12, 451.58 examples/s]Tokenizing train dataset:  17%|█▋        | 1155/6690 [00:02<00:12, 443.78 examples/s]Tokenizing train dataset:  18%|█▊        | 1203/6690 [00:02<00:12, 445.92 examples/s]Tokenizing train dataset:  19%|█▉        | 1268/6690 [00:02<00:12, 436.81 examples/s]Tokenizing train dataset:  20%|█▉        | 1317/6690 [00:02<00:12, 447.08 examples/s]Tokenizing train dataset:  20%|██        | 1363/6690 [00:02<00:11, 446.27 examples/s]Tokenizing train dataset:  21%|██▏       | 1422/6690 [00:03<00:12, 424.85 examples/s]Tokenizing train dataset:  22%|██▏       | 1485/6690 [00:03<00:12, 421.38 examples/s]Tokenizing train dataset:  23%|██▎       | 1540/6690 [00:03<00:11, 447.21 examples/s]Tokenizing train dataset:  24%|██▍       | 1603/6690 [00:03<00:11, 434.20 examples/s]Tokenizing train dataset:  25%|██▍       | 1668/6690 [00:03<00:11, 431.24 examples/s]Tokenizing train dataset:  26%|██▌       | 1715/6690 [00:03<00:11, 438.97 examples/s]Tokenizing train dataset:  26%|██▋       | 1762/6690 [00:03<00:11, 442.47 examples/s]Tokenizing train dataset:  27%|██▋       | 1807/6690 [00:04<00:11, 438.73 examples/s]Tokenizing train dataset:  28%|██▊       | 1876/6690 [00:04<00:10, 441.89 examples/s]Tokenizing train dataset:  29%|██▉       | 1946/6690 [00:04<00:10, 439.42 examples/s]Tokenizing train dataset:  30%|██▉       | 2003/6690 [00:04<00:11, 417.81 examples/s]Tokenizing train dataset:  31%|███       | 2046/6690 [00:04<00:11, 419.50 examples/s]Tokenizing train dataset:  31%|███       | 2090/6690 [00:04<00:10, 422.23 examples/s]Tokenizing train dataset:  32%|███▏      | 2139/6690 [00:04<00:10, 436.75 examples/s]Tokenizing train dataset:  33%|███▎      | 2188/6690 [00:04<00:10, 450.07 examples/s]Tokenizing train dataset:  33%|███▎      | 2238/6690 [00:04<00:09, 462.10 examples/s]Tokenizing train dataset:  34%|███▍      | 2300/6690 [00:05<00:09, 439.46 examples/s]Tokenizing train dataset:  35%|███▌      | 2347/6690 [00:05<00:09, 443.50 examples/s]Tokenizing train dataset:  36%|███▌      | 2395/6690 [00:05<00:09, 448.18 examples/s]Tokenizing train dataset:  37%|███▋      | 2465/6690 [00:05<00:09, 447.77 examples/s]Tokenizing train dataset:  38%|███▊      | 2535/6690 [00:05<00:09, 450.09 examples/s]Tokenizing train dataset:  39%|███▊      | 2587/6690 [00:05<00:08, 464.84 examples/s]Tokenizing train dataset:  40%|███▉      | 2651/6690 [00:05<00:09, 448.30 examples/s]Tokenizing train dataset:  41%|████      | 2715/6690 [00:06<00:09, 435.37 examples/s]Tokenizing train dataset:  41%|████▏     | 2775/6690 [00:06<00:09, 421.57 examples/s]Tokenizing train dataset:  42%|████▏     | 2838/6690 [00:06<00:09, 418.23 examples/s]Tokenizing train dataset:  43%|████▎     | 2882/6690 [00:06<00:09, 421.94 examples/s]Tokenizing train dataset:  44%|████▍     | 2932/6690 [00:06<00:08, 438.59 examples/s]Tokenizing train dataset:  45%|████▍     | 2986/6690 [00:06<00:08, 454.64 examples/s]Tokenizing train dataset:  45%|████▌     | 3033/6690 [00:06<00:07, 457.98 examples/s]Tokenizing train dataset:  46%|████▌     | 3088/6690 [00:06<00:07, 481.13 examples/s]Tokenizing train dataset:  47%|████▋     | 3151/6690 [00:07<00:07, 452.59 examples/s]Tokenizing train dataset:  48%|████▊     | 3199/6690 [00:07<00:07, 455.97 examples/s]Tokenizing train dataset:  49%|████▊     | 3248/6690 [00:07<00:07, 460.46 examples/s]Tokenizing train dataset:  49%|████▉     | 3306/6690 [00:07<00:07, 431.56 examples/s]Tokenizing train dataset:  50%|█████     | 3368/6690 [00:07<00:07, 422.36 examples/s]Tokenizing train dataset:  51%|█████▏    | 3429/6690 [00:07<00:07, 412.83 examples/s]Tokenizing train dataset:  52%|█████▏    | 3494/6690 [00:07<00:07, 415.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 3553/6690 [00:08<00:07, 402.04 examples/s]Tokenizing train dataset:  54%|█████▍    | 3610/6690 [00:08<00:07, 389.35 examples/s]Tokenizing train dataset:  55%|█████▍    | 3659/6690 [00:08<00:07, 408.64 examples/s]Tokenizing train dataset:  56%|█████▌    | 3718/6690 [00:08<00:07, 393.59 examples/s]Tokenizing train dataset:  56%|█████▌    | 3759/6690 [00:08<00:07, 396.52 examples/s]Tokenizing train dataset:  57%|█████▋    | 3801/6690 [00:08<00:07, 401.83 examples/s]Tokenizing train dataset:  58%|█████▊    | 3848/6690 [00:08<00:06, 415.70 examples/s]Tokenizing train dataset:  58%|█████▊    | 3896/6690 [00:08<00:06, 430.59 examples/s]Tokenizing train dataset:  59%|█████▉    | 3948/6690 [00:08<00:06, 446.85 examples/s]Tokenizing train dataset:  60%|█████▉    | 3994/6690 [00:09<00:06, 444.56 examples/s]Tokenizing train dataset:  60%|██████    | 4040/6690 [00:09<00:06, 436.44 examples/s]Tokenizing train dataset:  61%|██████▏   | 4106/6690 [00:09<00:05, 434.03 examples/s]Tokenizing train dataset:  62%|██████▏   | 4153/6690 [00:09<00:05, 441.22 examples/s]Tokenizing train dataset:  63%|██████▎   | 4201/6690 [00:09<00:05, 449.58 examples/s]Tokenizing train dataset:  64%|██████▍   | 4265/6690 [00:09<00:05, 437.03 examples/s]Tokenizing train dataset:  64%|██████▍   | 4311/6690 [00:09<00:05, 441.60 examples/s]Tokenizing train dataset:  65%|██████▌   | 4371/6690 [00:09<00:05, 422.36 examples/s]Tokenizing train dataset:  66%|██████▌   | 4414/6690 [00:10<00:05, 422.25 examples/s]Tokenizing train dataset:  67%|██████▋   | 4460/6690 [00:10<00:05, 426.64 examples/s]Tokenizing train dataset:  68%|██████▊   | 4527/6690 [00:10<00:05, 427.91 examples/s]Tokenizing train dataset:  68%|██████▊   | 4572/6690 [00:10<00:04, 432.60 examples/s]Tokenizing train dataset:  69%|██████▉   | 4620/6690 [00:10<00:04, 443.88 examples/s]Tokenizing train dataset:  70%|██████▉   | 4669/6690 [00:10<00:04, 452.49 examples/s]Tokenizing train dataset:  71%|███████   | 4739/6690 [00:10<00:04, 454.51 examples/s]Tokenizing train dataset:  72%|███████▏  | 4795/6690 [00:10<00:04, 420.32 examples/s]Tokenizing train dataset:  72%|███████▏  | 4844/6690 [00:11<00:04, 433.34 examples/s]Tokenizing train dataset:  73%|███████▎  | 4906/6690 [00:11<00:04, 423.94 examples/s]Tokenizing train dataset:  74%|███████▍  | 4952/6690 [00:11<00:04, 425.97 examples/s]Tokenizing train dataset:  75%|███████▍  | 4996/6690 [00:11<00:03, 426.10 examples/s]Tokenizing train dataset:  76%|███████▌  | 5060/6690 [00:11<00:03, 416.43 examples/s]Tokenizing train dataset:  76%|███████▋  | 5103/6690 [00:11<00:03, 417.27 examples/s]Tokenizing train dataset:  77%|███████▋  | 5169/6690 [00:11<00:03, 417.87 examples/s]Tokenizing train dataset:  78%|███████▊  | 5217/6690 [00:11<00:03, 428.91 examples/s]Tokenizing train dataset:  79%|███████▉  | 5282/6690 [00:12<00:03, 425.85 examples/s]Tokenizing train dataset:  80%|███████▉  | 5341/6690 [00:12<00:03, 414.08 examples/s]Tokenizing train dataset:  81%|████████  | 5395/6690 [00:12<00:02, 443.71 examples/s]Tokenizing train dataset:  82%|████████▏ | 5460/6690 [00:12<00:02, 433.87 examples/s]Tokenizing train dataset:  83%|████████▎ | 5525/6690 [00:12<00:02, 431.12 examples/s]Tokenizing train dataset:  84%|████████▎ | 5587/6690 [00:12<00:02, 420.41 examples/s]Tokenizing train dataset:  84%|████████▍ | 5630/6690 [00:12<00:02, 420.25 examples/s]Tokenizing train dataset:  85%|████████▍ | 5676/6690 [00:13<00:02, 427.95 examples/s]Tokenizing train dataset:  86%|████████▌ | 5743/6690 [00:13<00:02, 430.43 examples/s]Tokenizing train dataset:  87%|████████▋ | 5788/6690 [00:13<00:02, 429.67 examples/s]Tokenizing train dataset:  87%|████████▋ | 5851/6690 [00:13<00:02, 419.49 examples/s]Tokenizing train dataset:  88%|████████▊ | 5899/6690 [00:13<00:01, 432.03 examples/s]Tokenizing train dataset:  89%|████████▉ | 5943/6690 [00:13<00:01, 429.93 examples/s]Tokenizing train dataset:  90%|████████▉ | 6009/6690 [00:13<00:01, 432.38 examples/s]Tokenizing train dataset:  90%|█████████ | 6053/6690 [00:13<00:01, 430.85 examples/s]Tokenizing train dataset:  91%|█████████ | 6104/6690 [00:13<00:01, 446.80 examples/s]Tokenizing train dataset:  92%|█████████▏| 6153/6690 [00:14<00:01, 452.97 examples/s]Tokenizing train dataset:  93%|█████████▎| 6216/6690 [00:14<00:01, 436.10 examples/s]Tokenizing train dataset:  94%|█████████▍| 6274/6690 [00:14<00:01, 411.20 examples/s]Tokenizing train dataset:  94%|█████████▍| 6320/6690 [00:14<00:00, 416.62 examples/s]Tokenizing train dataset:  95%|█████████▌| 6380/6690 [00:14<00:00, 400.61 examples/s]Tokenizing train dataset:  96%|█████████▌| 6430/6690 [00:14<00:00, 422.16 examples/s]Tokenizing train dataset:  97%|█████████▋| 6494/6690 [00:14<00:00, 423.00 examples/s]Tokenizing train dataset:  98%|█████████▊| 6538/6690 [00:15<00:00, 424.12 examples/s]Tokenizing train dataset:  99%|█████████▊| 6601/6690 [00:15<00:00, 416.14 examples/s]Tokenizing train dataset: 100%|█████████▉| 6660/6690 [00:15<00:00, 401.05 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 434.19 examples/s]
[rank4]:[W610 23:55:56.183060702 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   8%|▊         | 550/6690 [00:00<00:01, 5436.72 examples/s]Extracting prompt in train dataset:   8%|▊         | 543/6690 [00:00<00:01, 5366.95 examples/s]Extracting prompt in train dataset:   8%|▊         | 550/6690 [00:00<00:01, 5424.37 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 563/953 [00:00<00:00, 5546.18 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5516.80 examples/s]
Extracting prompt in train dataset:  17%|█▋        | 1116/6690 [00:00<00:01, 5551.12 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1111/6690 [00:00<00:01, 5508.52 examples/s]Extracting prompt in train dataset:  16%|█▋        | 1100/6690 [00:00<00:01, 5437.58 examples/s]Extracting prompt in train dataset:  25%|██▌       | 1681/6690 [00:00<00:00, 5594.69 examples/s]Extracting prompt in train dataset:  25%|██▌       | 1690/6690 [00:00<00:00, 5612.89 examples/s]Extracting prompt in train dataset:  25%|██▍       | 1670/6690 [00:00<00:00, 5531.78 examples/s]Extracting prompt in train dataset:  34%|███▎      | 2255/6690 [00:00<00:00, 5614.66 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2240/6690 [00:00<00:00, 5593.63 examples/s]Extracting prompt in train dataset:  34%|███▎      | 2250/6690 [00:00<00:00, 5587.76 examples/s]Extracting prompt in train dataset:  42%|████▏     | 2830/6690 [00:00<00:00, 5637.27 examples/s]Extracting prompt in train dataset:  42%|████▏     | 2820/6690 [00:00<00:00, 5613.67 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  46%|████▌     | 3080/6690 [00:00<00:00, 5569.73 examples/s]Extracting prompt in train dataset:  51%|█████     | 3410/6690 [00:00<00:00, 5664.54 examples/s]Extracting prompt in train dataset:  51%|█████     | 3400/6690 [00:00<00:00, 5641.44 examples/s]Applying chat template to eval dataset:  33%|███▎      | 312/953 [00:00<00:00, 3091.95 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 3646/6690 [00:00<00:00, 5596.15 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 3983/6690 [00:00<00:00, 5684.32 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 3970/6690 [00:00<00:00, 5655.36 examples/s]Applying chat template to eval dataset:  67%|██████▋   | 637/953 [00:00<00:00, 3176.42 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 4216/6690 [00:00<00:00, 5611.46 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3195.30 examples/s]
Extracting prompt in train dataset:  72%|███████▏  | 4810/6690 [00:00<00:00, 5596.45 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 4800/6690 [00:00<00:00, 5585.96 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 5030/6690 [00:00<00:00, 5528.69 examples/s]Extracting prompt in train dataset:  81%|████████  | 5390/6690 [00:00<00:00, 5626.88 examples/s]Extracting prompt in train dataset:  80%|████████  | 5379/6690 [00:00<00:00, 5627.92 examples/s]Extracting prompt in train dataset:  84%|████████▎ | 5598/6690 [00:01<00:00, 5567.62 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 5977/6690 [00:01<00:00, 5680.08 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 5950/6690 [00:01<00:00, 5632.93 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 6168/6690 [00:01<00:00, 5590.01 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 6568/6690 [00:01<00:00, 5734.91 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 6530/6690 [00:01<00:00, 5648.48 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5621.13 examples/s]
Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5578.72 examples/s]
Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5529.20 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 318.09 examples/s]Tokenizing eval dataset:   8%|▊         | 78/953 [00:00<00:03, 289.10 examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing eval dataset:  12%|█▏        | 118/953 [00:00<00:03, 272.88 examples/s]Applying chat template to train dataset:   4%|▍         | 289/6690 [00:00<00:02, 2862.41 examples/s]Applying chat template to train dataset:   4%|▍         | 290/6690 [00:00<00:02, 2868.65 examples/s]Applying chat template to train dataset:   4%|▍         | 281/6690 [00:00<00:02, 2782.93 examples/s]Applying chat template to train dataset:   9%|▉         | 604/6690 [00:00<00:02, 3023.00 examples/s]Applying chat template to train dataset:   9%|▉         | 588/6690 [00:00<00:02, 2947.08 examples/s]Applying chat template to train dataset:   9%|▉         | 610/6690 [00:00<00:01, 3046.51 examples/s]Tokenizing eval dataset:  17%|█▋        | 158/953 [00:00<00:03, 264.99 examples/s]Applying chat template to train dataset:  14%|█▍        | 920/6690 [00:00<00:01, 3082.20 examples/s]Applying chat template to train dataset:  13%|█▎        | 894/6690 [00:00<00:01, 2993.36 examples/s]Applying chat template to train dataset:  14%|█▍        | 930/6690 [00:00<00:01, 3105.48 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:00<00:03, 250.94 examples/s]Applying chat template to train dataset:  18%|█▊        | 1236/6690 [00:00<00:01, 3103.63 examples/s]Applying chat template to train dataset:  18%|█▊        | 1200/6690 [00:00<00:01, 3009.34 examples/s]Applying chat template to train dataset:  19%|█▊        | 1248/6690 [00:00<00:01, 3126.85 examples/s]Tokenizing eval dataset:  24%|██▎       | 226/953 [00:00<00:02, 267.17 examples/s]Applying chat template to train dataset:  23%|██▎       | 1551/6690 [00:00<00:01, 3117.99 examples/s]Applying chat template to train dataset:  23%|██▎       | 1507/6690 [00:00<00:01, 3027.54 examples/s]Applying chat template to train dataset:  23%|██▎       | 1565/6690 [00:00<00:01, 3140.55 examples/s]Tokenizing eval dataset:  31%|███       | 292/953 [00:00<00:01, 367.87 examples/s]Applying chat template to train dataset:  28%|██▊       | 1870/6690 [00:00<00:01, 3130.95 examples/s]Applying chat template to train dataset:  27%|██▋       | 1814/6690 [00:00<00:01, 3038.22 examples/s]Applying chat template to train dataset:  28%|██▊       | 1884/6690 [00:00<00:01, 3153.46 examples/s]Tokenizing eval dataset:  37%|███▋      | 355/953 [00:01<00:01, 437.35 examples/s]Applying chat template to train dataset:  33%|███▎      | 2187/6690 [00:00<00:01, 3141.58 examples/s]Applying chat template to train dataset:  32%|███▏      | 2121/6690 [00:00<00:01, 3043.74 examples/s]Applying chat template to train dataset:  33%|███▎      | 2203/6690 [00:00<00:01, 3161.62 examples/s]Tokenizing eval dataset:  44%|████▍     | 418/953 [00:01<00:01, 486.07 examples/s]Applying chat template to train dataset:  40%|███▉      | 2658/6690 [00:00<00:01, 3135.39 examples/s]Applying chat template to train dataset:  40%|████      | 2676/6690 [00:00<00:01, 3155.59 examples/s]Applying chat template to train dataset:  39%|███▊      | 2579/6690 [00:00<00:01, 3043.57 examples/s]Tokenizing eval dataset:  51%|█████     | 484/953 [00:01<00:00, 534.18 examples/s]Applying chat template to train dataset:  44%|████▍     | 2972/6690 [00:00<00:01, 3135.54 examples/s]Applying chat template to train dataset:  45%|████▍     | 2994/6690 [00:00<00:01, 3159.31 examples/s]Applying chat template to train dataset:  43%|████▎     | 2885/6690 [00:00<00:01, 3043.67 examples/s]Tokenizing eval dataset:  58%|█████▊    | 551/953 [00:01<00:00, 569.61 examples/s]Applying chat template to train dataset:  49%|████▉     | 3289/6690 [00:01<00:01, 3143.51 examples/s]Applying chat template to train dataset:  50%|████▉     | 3312/6690 [00:01<00:01, 3162.43 examples/s]Applying chat template to train dataset:  48%|████▊     | 3192/6690 [00:01<00:01, 3047.71 examples/s]Tokenizing eval dataset:  65%|██████▍   | 615/953 [00:01<00:00, 585.01 examples/s]Applying chat template to train dataset:  54%|█████▍    | 3630/6690 [00:01<00:00, 3162.68 examples/s]Applying chat template to train dataset:  52%|█████▏    | 3499/6690 [00:01<00:01, 3051.47 examples/s]Tokenizing eval dataset:  71%|███████   | 676/953 [00:01<00:00, 588.19 examples/s]Applying chat template to train dataset:  56%|█████▌    | 3760/6690 [00:01<00:00, 3138.46 examples/s]Applying chat template to train dataset:  59%|█████▉    | 3950/6690 [00:01<00:00, 3165.96 examples/s]Applying chat template to train dataset:  61%|██████    | 4077/6690 [00:01<00:00, 3144.75 examples/s]Applying chat template to train dataset:  59%|█████▉    | 3959/6690 [00:01<00:00, 3054.79 examples/s]Tokenizing eval dataset:  80%|███████▉  | 759/953 [00:01<00:00, 570.40 examples/s]Applying chat template to train dataset:  64%|██████▍   | 4270/6690 [00:01<00:00, 3167.11 examples/s]Applying chat template to train dataset:  64%|██████▍   | 4265/6690 [00:01<00:00, 3054.30 examples/s]Applying chat template to train dataset:  68%|██████▊   | 4548/6690 [00:01<00:00, 3100.77 examples/s]Tokenizing eval dataset:  87%|████████▋ | 832/953 [00:01<00:00, 536.42 examples/s]Applying chat template to train dataset:  71%|███████   | 4730/6690 [00:01<00:00, 3116.60 examples/s]Applying chat template to train dataset:  70%|███████   | 4708/6690 [00:01<00:00, 3012.34 examples/s]Applying chat template to train dataset:  73%|███████▎  | 4862/6690 [00:01<00:00, 3108.54 examples/s]Applying chat template to train dataset:  75%|███████▌  | 5047/6690 [00:01<00:00, 3127.19 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:02<00:00, 521.45 examples/s]Applying chat template to train dataset:  75%|███████▍  | 5013/6690 [00:01<00:00, 3017.98 examples/s]Applying chat template to train dataset:  77%|███████▋  | 5179/6690 [00:01<00:00, 3118.34 examples/s]Applying chat template to train dataset:  80%|████████  | 5361/6690 [00:01<00:00, 3130.36 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 450.85 examples/s]
Applying chat template to train dataset:  79%|███████▉  | 5318/6690 [00:01<00:00, 3025.22 examples/s]Applying chat template to train dataset:  85%|████████▍ | 5683/6690 [00:01<00:00, 3153.78 examples/s]Applying chat template to train dataset:  84%|████████▍ | 5649/6690 [00:01<00:00, 3117.98 examples/s]Applying chat template to train dataset:  84%|████████▍ | 5624/6690 [00:01<00:00, 3032.38 examples/s]Applying chat template to train dataset:  90%|████████▉ | 6008/6690 [00:01<00:00, 3178.91 examples/s]Applying chat template to train dataset:  89%|████████▉ | 5963/6690 [00:01<00:00, 3120.81 examples/s]Applying chat template to train dataset:  89%|████████▊ | 5930/6690 [00:01<00:00, 3037.42 examples/s]Applying chat template to train dataset:  95%|█████████▍| 6332/6690 [00:02<00:00, 3194.38 examples/s]Applying chat template to train dataset:  94%|█████████▍| 6280/6690 [00:02<00:00, 3127.16 examples/s]Applying chat template to train dataset:  93%|█████████▎| 6238/6690 [00:02<00:00, 3046.52 examples/s]Applying chat template to train dataset:  99%|█████████▉| 6654/6690 [00:02<00:00, 3201.49 examples/s]Applying chat template to train dataset:  99%|█████████▊| 6597/6690 [00:02<00:00, 3134.94 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3146.46 examples/s]
Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3112.91 examples/s]
Applying chat template to train dataset:  98%|█████████▊| 6544/6690 [00:02<00:00, 3046.17 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3025.17 examples/s]
Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 42/6690 [00:00<00:16, 407.79 examples/s]Tokenizing train dataset:   1%|          | 43/6690 [00:00<00:16, 413.97 examples/s]Tokenizing train dataset:   1%|          | 43/6690 [00:00<00:15, 417.56 examples/s]Tokenizing train dataset:   1%|▏         | 90/6690 [00:00<00:15, 438.96 examples/s]Tokenizing train dataset:   1%|▏         | 90/6690 [00:00<00:15, 437.07 examples/s]Tokenizing train dataset:   1%|▏         | 90/6690 [00:00<00:15, 437.91 examples/s]Tokenizing train dataset:   2%|▏         | 135/6690 [00:00<00:14, 440.47 examples/s]Tokenizing train dataset:   2%|▏         | 135/6690 [00:00<00:14, 439.69 examples/s]Tokenizing train dataset:   2%|▏         | 135/6690 [00:00<00:14, 438.81 examples/s]Tokenizing train dataset:   3%|▎         | 189/6690 [00:00<00:13, 472.64 examples/s]Tokenizing train dataset:   3%|▎         | 188/6690 [00:00<00:13, 473.71 examples/s]Tokenizing train dataset:   3%|▎         | 188/6690 [00:00<00:13, 473.64 examples/s]Tokenizing train dataset:   4%|▎         | 237/6690 [00:00<00:13, 472.66 examples/s]Tokenizing train dataset:   4%|▎         | 236/6690 [00:00<00:13, 468.96 examples/s]Tokenizing train dataset:   4%|▎         | 236/6690 [00:00<00:13, 468.67 examples/s]Tokenizing train dataset:   4%|▍         | 285/6690 [00:00<00:13, 470.36 examples/s]Tokenizing train dataset:   4%|▍         | 285/6690 [00:00<00:13, 468.63 examples/s]Tokenizing train dataset:   4%|▍         | 285/6690 [00:00<00:13, 468.31 examples/s]Tokenizing train dataset:   5%|▌         | 355/6690 [00:00<00:13, 460.24 examples/s]Tokenizing train dataset:   5%|▌         | 355/6690 [00:00<00:13, 458.45 examples/s]Tokenizing train dataset:   5%|▌         | 355/6690 [00:00<00:13, 458.45 examples/s]Tokenizing train dataset:   6%|▌         | 408/6690 [00:00<00:13, 473.75 examples/s]Tokenizing train dataset:   6%|▌         | 404/6690 [00:00<00:13, 466.31 examples/s]Tokenizing train dataset:   6%|▌         | 407/6690 [00:00<00:13, 470.69 examples/s]Tokenizing train dataset:   7%|▋         | 459/6690 [00:00<00:12, 481.09 examples/s]Tokenizing train dataset:   7%|▋         | 457/6690 [00:00<00:12, 481.94 examples/s]Tokenizing train dataset:   7%|▋         | 458/6690 [00:00<00:12, 481.02 examples/s]Tokenizing train dataset:   8%|▊         | 510/6690 [00:01<00:12, 481.34 examples/s]Tokenizing train dataset:   8%|▊         | 509/6690 [00:01<00:12, 488.63 examples/s]Tokenizing train dataset:   8%|▊         | 509/6690 [00:01<00:12, 487.94 examples/s]Tokenizing train dataset:   8%|▊         | 560/6690 [00:01<00:12, 482.62 examples/s]Tokenizing train dataset:   8%|▊         | 559/6690 [00:01<00:12, 484.32 examples/s]Tokenizing train dataset:   8%|▊         | 559/6690 [00:01<00:12, 483.97 examples/s]Tokenizing train dataset:   9%|▉         | 610/6690 [00:01<00:12, 483.62 examples/s]Tokenizing train dataset:   9%|▉         | 608/6690 [00:01<00:12, 483.49 examples/s]Tokenizing train dataset:   9%|▉         | 608/6690 [00:01<00:12, 483.15 examples/s]Tokenizing train dataset:  10%|▉         | 660/6690 [00:01<00:12, 484.13 examples/s]Tokenizing train dataset:  10%|▉         | 658/6690 [00:01<00:12, 484.23 examples/s]Tokenizing train dataset:  10%|▉         | 658/6690 [00:01<00:12, 484.16 examples/s]Tokenizing train dataset:  11%|█         | 712/6690 [00:01<00:12, 491.64 examples/s]Tokenizing train dataset:  11%|█         | 708/6690 [00:01<00:12, 486.72 examples/s]Tokenizing train dataset:  11%|█         | 708/6690 [00:01<00:12, 486.97 examples/s]Tokenizing train dataset:  11%|█▏        | 766/6690 [00:01<00:11, 502.98 examples/s]Tokenizing train dataset:  11%|█▏        | 763/6690 [00:01<00:11, 503.26 examples/s]Tokenizing train dataset:  11%|█▏        | 763/6690 [00:01<00:11, 503.66 examples/s]Tokenizing train dataset:  12%|█▏        | 819/6690 [00:01<00:11, 507.43 examples/s]Tokenizing train dataset:  12%|█▏        | 817/6690 [00:01<00:11, 508.15 examples/s]Tokenizing train dataset:  12%|█▏        | 817/6690 [00:01<00:11, 508.57 examples/s]Tokenizing train dataset:  13%|█▎        | 888/6690 [00:01<00:12, 480.97 examples/s]Tokenizing train dataset:  13%|█▎        | 884/6690 [00:01<00:12, 478.37 examples/s]Tokenizing train dataset:  13%|█▎        | 884/6690 [00:01<00:12, 479.00 examples/s]Tokenizing train dataset:  14%|█▍        | 955/6690 [00:02<00:12, 461.62 examples/s]Tokenizing train dataset:  14%|█▍        | 950/6690 [00:02<00:12, 461.40 examples/s]Tokenizing train dataset:  14%|█▍        | 950/6690 [00:02<00:12, 461.75 examples/s]Tokenizing train dataset:  15%|█▍        | 1002/6690 [00:02<00:12, 458.25 examples/s]Tokenizing train dataset:  15%|█▌        | 1021/6690 [00:02<00:12, 457.46 examples/s]Tokenizing train dataset:  16%|█▌        | 1050/6690 [00:02<00:12, 460.86 examples/s]Tokenizing train dataset:  15%|█▌        | 1021/6690 [00:02<00:12, 457.61 examples/s]Tokenizing train dataset:  16%|█▌        | 1073/6690 [00:02<00:12, 468.01 examples/s]Tokenizing train dataset:  16%|█▋        | 1100/6690 [00:02<00:11, 466.69 examples/s]Tokenizing train dataset:  16%|█▌        | 1073/6690 [00:02<00:11, 468.23 examples/s]Tokenizing train dataset:  17%|█▋        | 1142/6690 [00:02<00:12, 458.98 examples/s]Tokenizing train dataset:  17%|█▋        | 1168/6690 [00:02<00:12, 459.00 examples/s]Tokenizing train dataset:  17%|█▋        | 1142/6690 [00:02<00:12, 459.42 examples/s]Tokenizing train dataset:  18%|█▊        | 1190/6690 [00:02<00:11, 460.58 examples/s]Tokenizing train dataset:  18%|█▊        | 1190/6690 [00:02<00:11, 461.35 examples/s]Tokenizing train dataset:  18%|█▊        | 1234/6690 [00:02<00:12, 446.44 examples/s]Tokenizing train dataset:  19%|█▊        | 1254/6690 [00:02<00:12, 441.81 examples/s]Tokenizing train dataset:  19%|█▉        | 1280/6690 [00:02<00:12, 444.43 examples/s]Tokenizing train dataset:  19%|█▊        | 1254/6690 [00:02<00:12, 442.76 examples/s]Tokenizing train dataset:  19%|█▉        | 1300/6690 [00:02<00:12, 441.24 examples/s]Tokenizing train dataset:  20%|█▉        | 1334/6690 [00:02<00:11, 465.30 examples/s]Tokenizing train dataset:  19%|█▉        | 1300/6690 [00:02<00:12, 442.22 examples/s]Tokenizing train dataset:  20%|██        | 1356/6690 [00:02<00:11, 468.47 examples/s]Tokenizing train dataset:  20%|██        | 1356/6690 [00:02<00:11, 469.57 examples/s]Tokenizing train dataset:  21%|██        | 1400/6690 [00:02<00:11, 450.68 examples/s]Tokenizing train dataset:  21%|██        | 1415/6690 [00:03<00:12, 437.84 examples/s]Tokenizing train dataset:  21%|██        | 1416/6690 [00:03<00:11, 439.62 examples/s]Tokenizing train dataset:  22%|██▏       | 1466/6690 [00:03<00:11, 439.06 examples/s]Tokenizing train dataset:  22%|██▏       | 1478/6690 [00:03<00:12, 431.45 examples/s]Tokenizing train dataset:  23%|██▎       | 1516/6690 [00:03<00:11, 451.60 examples/s]Tokenizing train dataset:  22%|██▏       | 1481/6690 [00:03<00:12, 429.64 examples/s]Tokenizing train dataset:  23%|██▎       | 1534/6690 [00:03<00:11, 458.56 examples/s]Tokenizing train dataset:  23%|██▎       | 1563/6690 [00:03<00:11, 451.70 examples/s]Tokenizing train dataset:  23%|██▎       | 1539/6690 [00:03<00:11, 461.43 examples/s]Tokenizing train dataset:  24%|██▍       | 1599/6690 [00:03<00:11, 446.83 examples/s]Tokenizing train dataset:  24%|██▍       | 1630/6690 [00:03<00:11, 445.98 examples/s]Tokenizing train dataset:  24%|██▍       | 1603/6690 [00:03<00:11, 446.15 examples/s]Tokenizing train dataset:  25%|██▍       | 1645/6690 [00:03<00:11, 442.76 examples/s]Tokenizing train dataset:  25%|██▍       | 1649/6690 [00:03<00:11, 444.84 examples/s]Tokenizing train dataset:  25%|██▌       | 1700/6690 [00:03<00:11, 446.72 examples/s]Tokenizing train dataset:  25%|██▌       | 1691/6690 [00:03<00:11, 444.29 examples/s]Tokenizing train dataset:  25%|██▌       | 1695/6690 [00:03<00:11, 446.42 examples/s]Tokenizing train dataset:  26%|██▌       | 1751/6690 [00:03<00:10, 458.88 examples/s]Tokenizing train dataset:  26%|██▌       | 1739/6690 [00:03<00:10, 452.86 examples/s]Tokenizing train dataset:  26%|██▌       | 1744/6690 [00:03<00:10, 453.40 examples/s]Tokenizing train dataset:  27%|██▋       | 1785/6690 [00:03<00:10, 449.56 examples/s]Tokenizing train dataset:  27%|██▋       | 1820/6690 [00:03<00:10, 449.08 examples/s]Tokenizing train dataset:  27%|██▋       | 1790/6690 [00:03<00:10, 451.66 examples/s]Tokenizing train dataset:  27%|██▋       | 1834/6690 [00:03<00:10, 455.59 examples/s]Tokenizing train dataset:  28%|██▊       | 1866/6690 [00:04<00:10, 450.54 examples/s]Tokenizing train dataset:  27%|██▋       | 1838/6690 [00:03<00:10, 455.20 examples/s]Tokenizing train dataset:  28%|██▊       | 1880/6690 [00:04<00:10, 452.69 examples/s]Tokenizing train dataset:  29%|██▊       | 1912/6690 [00:04<00:10, 448.47 examples/s]Tokenizing train dataset:  28%|██▊       | 1886/6690 [00:04<00:10, 457.69 examples/s]Tokenizing train dataset:  29%|██▉       | 1960/6690 [00:04<00:10, 453.29 examples/s]Tokenizing train dataset:  29%|██▉       | 1948/6690 [00:04<00:10, 449.22 examples/s]Tokenizing train dataset:  29%|██▉       | 1953/6690 [00:04<00:10, 446.56 examples/s]Tokenizing train dataset:  30%|██▉       | 2006/6690 [00:04<00:11, 425.41 examples/s]Tokenizing train dataset:  30%|███       | 2023/6690 [00:04<00:10, 430.03 examples/s]Tokenizing train dataset:  30%|███       | 2011/6690 [00:04<00:11, 423.16 examples/s]Tokenizing train dataset:  31%|███       | 2050/6690 [00:04<00:10, 426.15 examples/s]Tokenizing train dataset:  31%|███       | 2090/6690 [00:04<00:10, 430.23 examples/s]Tokenizing train dataset:  31%|███       | 2057/6690 [00:04<00:10, 428.31 examples/s]Tokenizing train dataset:  31%|███▏      | 2096/6690 [00:04<00:10, 433.18 examples/s]Tokenizing train dataset:  32%|███▏      | 2140/6690 [00:04<00:10, 443.36 examples/s]Tokenizing train dataset:  31%|███▏      | 2105/6690 [00:04<00:10, 438.09 examples/s]Tokenizing train dataset:  32%|███▏      | 2144/6690 [00:04<00:10, 444.00 examples/s]Tokenizing train dataset:  33%|███▎      | 2190/6690 [00:04<00:09, 456.37 examples/s]Tokenizing train dataset:  32%|███▏      | 2155/6690 [00:04<00:10, 450.85 examples/s]Tokenizing train dataset:  33%|███▎      | 2195/6690 [00:04<00:09, 460.29 examples/s]Tokenizing train dataset:  34%|███▎      | 2245/6690 [00:04<00:09, 473.63 examples/s]Tokenizing train dataset:  33%|███▎      | 2207/6690 [00:04<00:09, 467.23 examples/s]Tokenizing train dataset:  34%|███▎      | 2247/6690 [00:04<00:09, 469.31 examples/s]Tokenizing train dataset:  35%|███▍      | 2309/6690 [00:05<00:09, 447.94 examples/s]Tokenizing train dataset:  34%|███▍      | 2277/6690 [00:04<00:09, 465.70 examples/s]Tokenizing train dataset:  35%|███▍      | 2312/6690 [00:05<00:09, 445.40 examples/s]Tokenizing train dataset:  35%|███▌      | 2360/6690 [00:05<00:09, 457.75 examples/s]Tokenizing train dataset:  35%|███▌      | 2362/6690 [00:05<00:09, 453.70 examples/s]Tokenizing train dataset:  35%|███▌      | 2344/6690 [00:05<00:09, 454.44 examples/s]Tokenizing train dataset:  36%|███▋      | 2426/6690 [00:05<00:09, 449.80 examples/s]Tokenizing train dataset:  36%|███▌      | 2391/6690 [00:05<00:09, 455.98 examples/s]Tokenizing train dataset:  36%|███▋      | 2432/6690 [00:05<00:09, 452.52 examples/s]Tokenizing train dataset:  37%|███▋      | 2476/6690 [00:05<00:09, 457.44 examples/s]Tokenizing train dataset:  37%|███▋      | 2479/6690 [00:05<00:09, 452.08 examples/s]Tokenizing train dataset:  37%|███▋      | 2463/6690 [00:05<00:09, 456.24 examples/s]Tokenizing train dataset:  38%|███▊      | 2524/6690 [00:05<00:09, 460.91 examples/s]Tokenizing train dataset:  38%|███▊      | 2528/6690 [00:05<00:09, 461.05 examples/s]Tokenizing train dataset:  38%|███▊      | 2509/6690 [00:05<00:09, 452.83 examples/s]Tokenizing train dataset:  39%|███▊      | 2580/6690 [00:05<00:08, 479.07 examples/s]Tokenizing train dataset:  39%|███▊      | 2582/6690 [00:05<00:08, 478.88 examples/s]Tokenizing train dataset:  38%|███▊      | 2561/6690 [00:05<00:08, 467.63 examples/s]Tokenizing train dataset:  40%|███▉      | 2646/6690 [00:05<00:08, 463.46 examples/s]Tokenizing train dataset:  39%|███▉      | 2611/6690 [00:05<00:08, 475.48 examples/s]Tokenizing train dataset:  40%|███▉      | 2648/6690 [00:05<00:08, 462.13 examples/s]Tokenizing train dataset:  41%|████      | 2712/6690 [00:05<00:08, 448.83 examples/s]Tokenizing train dataset:  40%|███▉      | 2675/6690 [00:05<00:08, 449.98 examples/s]Tokenizing train dataset:  41%|████      | 2712/6690 [00:05<00:08, 446.62 examples/s]Tokenizing train dataset:  41%|████▏     | 2774/6690 [00:06<00:09, 428.85 examples/s]Tokenizing train dataset:  41%|████      | 2740/6690 [00:05<00:09, 435.78 examples/s]Tokenizing train dataset:  41%|████▏     | 2774/6690 [00:06<00:09, 427.21 examples/s]Tokenizing train dataset:  42%|████▏     | 2838/6690 [00:06<00:09, 427.57 examples/s]Tokenizing train dataset:  42%|████▏     | 2803/6690 [00:06<00:09, 427.51 examples/s]Tokenizing train dataset:  42%|████▏     | 2838/6690 [00:06<00:09, 426.47 examples/s]Tokenizing train dataset:  43%|████▎     | 2883/6690 [00:06<00:08, 432.08 examples/s]Tokenizing train dataset:  43%|████▎     | 2847/6690 [00:06<00:08, 429.07 examples/s]Tokenizing train dataset:  43%|████▎     | 2883/6690 [00:06<00:08, 431.27 examples/s]Tokenizing train dataset:  44%|████▍     | 2933/6690 [00:06<00:08, 447.37 examples/s]Tokenizing train dataset:  43%|████▎     | 2894/6690 [00:06<00:08, 434.42 examples/s]Tokenizing train dataset:  44%|████▍     | 2933/6690 [00:06<00:08, 446.46 examples/s]Tokenizing train dataset:  45%|████▍     | 2986/6690 [00:06<00:07, 464.56 examples/s]Tokenizing train dataset:  44%|████▍     | 2947/6690 [00:06<00:08, 458.85 examples/s]Tokenizing train dataset:  45%|████▍     | 2986/6690 [00:06<00:07, 463.43 examples/s]Tokenizing train dataset:  45%|████▌     | 3035/6690 [00:06<00:07, 467.96 examples/s]Tokenizing train dataset:  45%|████▍     | 2996/6690 [00:06<00:07, 465.21 examples/s]Tokenizing train dataset:  45%|████▌     | 3035/6690 [00:06<00:07, 467.23 examples/s]Tokenizing train dataset:  46%|████▌     | 3092/6690 [00:06<00:07, 494.08 examples/s]Tokenizing train dataset:  46%|████▌     | 3045/6690 [00:06<00:07, 470.54 examples/s]Tokenizing train dataset:  46%|████▌     | 3092/6690 [00:06<00:07, 493.43 examples/s]Tokenizing train dataset:  46%|████▋     | 3101/6690 [00:06<00:07, 492.40 examples/s]Tokenizing train dataset:  47%|████▋     | 3156/6690 [00:06<00:07, 466.03 examples/s]Tokenizing train dataset:  47%|████▋     | 3156/6690 [00:06<00:07, 465.41 examples/s]Tokenizing train dataset:  47%|████▋     | 3166/6690 [00:06<00:07, 465.29 examples/s]Tokenizing train dataset:  48%|████▊     | 3228/6690 [00:07<00:07, 465.93 examples/s]Tokenizing train dataset:  48%|████▊     | 3228/6690 [00:07<00:07, 465.10 examples/s]Tokenizing train dataset:  49%|████▉     | 3276/6690 [00:07<00:07, 464.96 examples/s]Tokenizing train dataset:  48%|████▊     | 3240/6690 [00:07<00:07, 470.68 examples/s]Tokenizing train dataset:  49%|████▉     | 3276/6690 [00:07<00:07, 463.91 examples/s]Tokenizing train dataset:  50%|████▉     | 3333/6690 [00:07<00:07, 431.44 examples/s]Tokenizing train dataset:  49%|████▉     | 3301/6690 [00:07<00:07, 446.77 examples/s]Tokenizing train dataset:  50%|████▉     | 3333/6690 [00:07<00:07, 430.46 examples/s]Tokenizing train dataset:  50%|█████     | 3378/6690 [00:07<00:07, 433.12 examples/s]Tokenizing train dataset:  50%|█████     | 3378/6690 [00:07<00:07, 432.22 examples/s]Tokenizing train dataset:  50%|█████     | 3365/6690 [00:07<00:07, 435.34 examples/s]Tokenizing train dataset:  51%|█████▏    | 3437/6690 [00:07<00:07, 417.70 examples/s]Tokenizing train dataset:  51%|█████▏    | 3437/6690 [00:07<00:07, 416.76 examples/s]Tokenizing train dataset:  51%|█████     | 3427/6690 [00:07<00:07, 422.48 examples/s]Tokenizing train dataset:  52%|█████▏    | 3483/6690 [00:07<00:07, 424.70 examples/s]Tokenizing train dataset:  52%|█████▏    | 3483/6690 [00:07<00:07, 423.79 examples/s]Tokenizing train dataset:  52%|█████▏    | 3494/6690 [00:07<00:07, 422.96 examples/s]Tokenizing train dataset:  53%|█████▎    | 3543/6690 [00:07<00:07, 410.56 examples/s]Tokenizing train dataset:  53%|█████▎    | 3543/6690 [00:07<00:07, 409.99 examples/s]Tokenizing train dataset:  53%|█████▎    | 3554/6690 [00:07<00:07, 410.77 examples/s]Tokenizing train dataset:  54%|█████▍    | 3600/6690 [00:07<00:07, 397.55 examples/s]Tokenizing train dataset:  54%|█████▍    | 3600/6690 [00:07<00:07, 397.35 examples/s]Tokenizing train dataset:  54%|█████▍    | 3645/6690 [00:08<00:07, 409.18 examples/s]Tokenizing train dataset:  54%|█████▍    | 3612/6690 [00:07<00:07, 399.17 examples/s]Tokenizing train dataset:  54%|█████▍    | 3645/6690 [00:08<00:07, 409.01 examples/s]Tokenizing train dataset:  55%|█████▌    | 3690/6690 [00:08<00:07, 413.16 examples/s]Tokenizing train dataset:  55%|█████▍    | 3663/6690 [00:08<00:07, 416.22 examples/s]Tokenizing train dataset:  55%|█████▌    | 3690/6690 [00:08<00:07, 412.95 examples/s]Tokenizing train dataset:  56%|█████▌    | 3749/6690 [00:08<00:07, 399.66 examples/s]Tokenizing train dataset:  56%|█████▌    | 3719/6690 [00:08<00:07, 399.93 examples/s]Tokenizing train dataset:  56%|█████▌    | 3748/6690 [00:08<00:07, 399.84 examples/s]Tokenizing train dataset:  57%|█████▋    | 3795/6690 [00:08<00:07, 411.13 examples/s]Tokenizing train dataset:  56%|█████▌    | 3763/6690 [00:08<00:07, 404.65 examples/s]Tokenizing train dataset:  57%|█████▋    | 3794/6690 [00:08<00:07, 410.22 examples/s]Tokenizing train dataset:  57%|█████▋    | 3841/6690 [00:08<00:06, 421.99 examples/s]Tokenizing train dataset:  57%|█████▋    | 3808/6690 [00:08<00:06, 414.03 examples/s]Tokenizing train dataset:  57%|█████▋    | 3841/6690 [00:08<00:06, 420.53 examples/s]Tokenizing train dataset:  58%|█████▊    | 3891/6690 [00:08<00:06, 433.61 examples/s]Tokenizing train dataset:  58%|█████▊    | 3852/6690 [00:08<00:06, 418.77 examples/s]Tokenizing train dataset:  58%|█████▊    | 3889/6690 [00:08<00:06, 434.06 examples/s]Tokenizing train dataset:  59%|█████▉    | 3941/6690 [00:08<00:06, 448.07 examples/s]Tokenizing train dataset:  58%|█████▊    | 3903/6690 [00:08<00:06, 440.82 examples/s]Tokenizing train dataset:  59%|█████▉    | 3937/6690 [00:08<00:06, 444.68 examples/s]Tokenizing train dataset:  60%|█████▉    | 3990/6690 [00:08<00:05, 456.08 examples/s]Tokenizing train dataset:  59%|█████▉    | 3951/6690 [00:08<00:06, 449.95 examples/s]Tokenizing train dataset:  60%|█████▉    | 3987/6690 [00:08<00:05, 454.49 examples/s]Tokenizing train dataset:  60%|██████    | 4036/6690 [00:08<00:05, 452.71 examples/s]Tokenizing train dataset:  60%|█████▉    | 4000/6690 [00:08<00:05, 458.76 examples/s]Tokenizing train dataset:  60%|██████    | 4033/6690 [00:08<00:05, 450.26 examples/s]Tokenizing train dataset:  61%|██████▏   | 4103/6690 [00:09<00:05, 445.89 examples/s]Tokenizing train dataset:  61%|██████    | 4067/6690 [00:09<00:05, 448.13 examples/s]Tokenizing train dataset:  61%|██████▏   | 4100/6690 [00:09<00:05, 442.94 examples/s]Tokenizing train dataset:  62%|██████▏   | 4151/6690 [00:09<00:05, 449.38 examples/s]Tokenizing train dataset:  62%|██████▏   | 4148/6690 [00:09<00:05, 447.81 examples/s]Tokenizing train dataset:  62%|██████▏   | 4136/6690 [00:09<00:05, 448.43 examples/s]Tokenizing train dataset:  63%|██████▎   | 4200/6690 [00:09<00:05, 456.99 examples/s]Tokenizing train dataset:  63%|██████▎   | 4199/6690 [00:09<00:05, 460.75 examples/s]Tokenizing train dataset:  63%|██████▎   | 4188/6690 [00:09<00:05, 460.06 examples/s]Tokenizing train dataset:  64%|██████▍   | 4265/6690 [00:09<00:05, 446.18 examples/s]Tokenizing train dataset:  64%|██████▍   | 4265/6690 [00:09<00:05, 443.79 examples/s]Tokenizing train dataset:  64%|██████▎   | 4253/6690 [00:09<00:05, 449.88 examples/s]Tokenizing train dataset:  64%|██████▍   | 4312/6690 [00:09<00:05, 452.07 examples/s]Tokenizing train dataset:  64%|██████▍   | 4310/6690 [00:09<00:05, 442.57 examples/s]Tokenizing train dataset:  65%|██████▍   | 4318/6690 [00:09<00:05, 442.36 examples/s]Tokenizing train dataset:  65%|██████▌   | 4370/6690 [00:09<00:05, 425.76 examples/s]Tokenizing train dataset:  65%|██████▌   | 4370/6690 [00:09<00:05, 423.46 examples/s]Tokenizing train dataset:  65%|██████▌   | 4379/6690 [00:09<00:05, 427.78 examples/s]Tokenizing train dataset:  66%|██████▋   | 4439/6690 [00:09<00:05, 434.02 examples/s]Tokenizing train dataset:  66%|██████▌   | 4413/6690 [00:09<00:05, 421.22 examples/s]Tokenizing train dataset:  66%|██████▌   | 4424/6690 [00:09<00:05, 430.31 examples/s]Tokenizing train dataset:  67%|██████▋   | 4460/6690 [00:09<00:05, 427.86 examples/s]Tokenizing train dataset:  67%|██████▋   | 4500/6690 [00:10<00:05, 420.88 examples/s]Tokenizing train dataset:  67%|██████▋   | 4489/6690 [00:10<00:05, 427.65 examples/s]Tokenizing train dataset:  68%|██████▊   | 4551/6690 [00:10<00:04, 435.74 examples/s]Tokenizing train dataset:  68%|██████▊   | 4528/6690 [00:10<00:05, 430.93 examples/s]Tokenizing train dataset:  68%|██████▊   | 4535/6690 [00:10<00:05, 429.33 examples/s]Tokenizing train dataset:  68%|██████▊   | 4573/6690 [00:10<00:04, 434.56 examples/s]Tokenizing train dataset:  69%|██████▉   | 4623/6690 [00:10<00:04, 445.58 examples/s]Tokenizing train dataset:  69%|██████▊   | 4583/6690 [00:10<00:04, 435.64 examples/s]Tokenizing train dataset:  69%|██████▉   | 4621/6690 [00:10<00:04, 445.75 examples/s]Tokenizing train dataset:  70%|██████▉   | 4670/6690 [00:10<00:04, 448.35 examples/s]Tokenizing train dataset:  69%|██████▉   | 4633/6690 [00:10<00:04, 449.54 examples/s]Tokenizing train dataset:  70%|██████▉   | 4670/6690 [00:10<00:04, 450.25 examples/s]Tokenizing train dataset:  70%|███████   | 4716/6690 [00:10<00:04, 446.52 examples/s]Tokenizing train dataset:  70%|███████   | 4716/6690 [00:10<00:04, 447.85 examples/s]Tokenizing train dataset:  70%|███████   | 4700/6690 [00:10<00:04, 447.24 examples/s]Tokenizing train dataset:  71%|███████▏  | 4778/6690 [00:10<00:04, 430.62 examples/s]Tokenizing train dataset:  71%|███████   | 4748/6690 [00:10<00:04, 452.14 examples/s]Tokenizing train dataset:  71%|███████▏  | 4778/6690 [00:10<00:04, 430.44 examples/s]Tokenizing train dataset:  72%|███████▏  | 4848/6690 [00:10<00:04, 437.00 examples/s]Tokenizing train dataset:  72%|███████▏  | 4808/6690 [00:10<00:04, 428.48 examples/s]Tokenizing train dataset:  72%|███████▏  | 4845/6690 [00:10<00:04, 433.77 examples/s]Tokenizing train dataset:  73%|███████▎  | 4854/6690 [00:10<00:04, 435.10 examples/s]Tokenizing train dataset:  73%|███████▎  | 4889/6690 [00:10<00:04, 432.77 examples/s]Tokenizing train dataset:  73%|███████▎  | 4910/6690 [00:10<00:04, 421.29 examples/s]Tokenizing train dataset:  73%|███████▎  | 4916/6690 [00:10<00:04, 422.49 examples/s]Tokenizing train dataset:  74%|███████▍  | 4956/6690 [00:11<00:04, 426.77 examples/s]Tokenizing train dataset:  74%|███████▍  | 4952/6690 [00:11<00:04, 425.89 examples/s]Tokenizing train dataset:  74%|███████▍  | 4963/6690 [00:11<00:04, 428.57 examples/s]Tokenizing train dataset:  75%|███████▍  | 5000/6690 [00:11<00:03, 424.41 examples/s]Tokenizing train dataset:  75%|███████▍  | 4997/6690 [00:11<00:03, 426.02 examples/s]Tokenizing train dataset:  75%|███████▌  | 5026/6690 [00:11<00:03, 422.24 examples/s]Tokenizing train dataset:  76%|███████▌  | 5064/6690 [00:11<00:03, 420.31 examples/s]Tokenizing train dataset:  76%|███████▌  | 5060/6690 [00:11<00:03, 417.27 examples/s]Tokenizing train dataset:  76%|███████▌  | 5069/6690 [00:11<00:03, 420.86 examples/s]Tokenizing train dataset:  76%|███████▋  | 5103/6690 [00:11<00:03, 418.40 examples/s]Tokenizing train dataset:  77%|███████▋  | 5125/6690 [00:11<00:03, 412.15 examples/s]Tokenizing train dataset:  77%|███████▋  | 5173/6690 [00:11<00:03, 426.96 examples/s]Tokenizing train dataset:  77%|███████▋  | 5130/6690 [00:11<00:03, 411.23 examples/s]Tokenizing train dataset:  77%|███████▋  | 5169/6690 [00:11<00:03, 419.62 examples/s]Tokenizing train dataset:  77%|███████▋  | 5180/6690 [00:11<00:03, 431.15 examples/s]Tokenizing train dataset:  78%|███████▊  | 5219/6690 [00:11<00:03, 430.62 examples/s]Tokenizing train dataset:  78%|███████▊  | 5217/6690 [00:11<00:03, 430.45 examples/s]Tokenizing train dataset:  79%|███████▊  | 5263/6690 [00:11<00:03, 429.65 examples/s]Tokenizing train dataset:  78%|███████▊  | 5245/6690 [00:11<00:03, 427.76 examples/s]Tokenizing train dataset:  79%|███████▉  | 5282/6690 [00:11<00:03, 427.33 examples/s]Tokenizing train dataset:  79%|███████▉  | 5289/6690 [00:11<00:03, 428.42 examples/s]Tokenizing train dataset:  80%|███████▉  | 5326/6690 [00:11<00:03, 418.89 examples/s]Tokenizing train dataset:  80%|███████▉  | 5341/6690 [00:12<00:03, 414.99 examples/s]Tokenizing train dataset:  80%|████████  | 5379/6690 [00:12<00:02, 441.36 examples/s]Tokenizing train dataset:  80%|████████  | 5355/6690 [00:12<00:03, 424.60 examples/s]Tokenizing train dataset:  81%|████████  | 5396/6690 [00:12<00:02, 445.66 examples/s]Tokenizing train dataset:  81%|████████  | 5407/6690 [00:12<00:02, 445.80 examples/s]Tokenizing train dataset:  81%|████████▏ | 5441/6690 [00:12<00:02, 430.76 examples/s]Tokenizing train dataset:  82%|████████▏ | 5461/6690 [00:12<00:02, 435.64 examples/s]Tokenizing train dataset:  82%|████████▏ | 5490/6690 [00:12<00:02, 440.14 examples/s]Tokenizing train dataset:  82%|████████▏ | 5469/6690 [00:12<00:02, 431.53 examples/s]Tokenizing train dataset:  83%|████████▎ | 5526/6690 [00:12<00:02, 432.56 examples/s]Tokenizing train dataset:  82%|████████▏ | 5515/6690 [00:12<00:02, 435.60 examples/s]Tokenizing train dataset:  83%|████████▎ | 5554/6690 [00:12<00:02, 430.76 examples/s]Tokenizing train dataset:  84%|████████▎ | 5590/6690 [00:12<00:02, 424.06 examples/s]Tokenizing train dataset:  83%|████████▎ | 5579/6690 [00:12<00:02, 429.58 examples/s]Tokenizing train dataset:  84%|████████▍ | 5617/6690 [00:12<00:02, 423.12 examples/s]Tokenizing train dataset:  84%|████████▍ | 5639/6690 [00:12<00:02, 434.99 examples/s]Tokenizing train dataset:  85%|████████▍ | 5661/6690 [00:12<00:02, 425.17 examples/s]Tokenizing train dataset:  84%|████████▍ | 5645/6690 [00:12<00:02, 427.20 examples/s]Tokenizing train dataset:  85%|████████▌ | 5707/6690 [00:12<00:02, 431.96 examples/s]Tokenizing train dataset:  85%|████████▌ | 5703/6690 [00:12<00:02, 427.82 examples/s]Tokenizing train dataset:  85%|████████▌ | 5690/6690 [00:12<00:02, 427.37 examples/s]Tokenizing train dataset:  86%|████████▌ | 5757/6690 [00:12<00:02, 446.89 examples/s]Tokenizing train dataset:  86%|████████▌ | 5753/6690 [00:12<00:02, 443.54 examples/s]Tokenizing train dataset:  86%|████████▌ | 5738/6690 [00:12<00:02, 435.26 examples/s]Tokenizing train dataset:  87%|████████▋ | 5821/6690 [00:13<00:01, 436.76 examples/s]Tokenizing train dataset:  86%|████████▋ | 5784/6690 [00:12<00:02, 436.34 examples/s]Tokenizing train dataset:  87%|████████▋ | 5820/6690 [00:13<00:01, 436.11 examples/s]Tokenizing train dataset:  87%|████████▋ | 5828/6690 [00:13<00:01, 431.15 examples/s]Tokenizing train dataset:  88%|████████▊ | 5881/6690 [00:13<00:01, 421.25 examples/s]Tokenizing train dataset:  88%|████████▊ | 5880/6690 [00:13<00:01, 421.04 examples/s]Tokenizing train dataset:  89%|████████▊ | 5935/6690 [00:13<00:01, 444.06 examples/s]Tokenizing train dataset:  88%|████████▊ | 5895/6690 [00:13<00:01, 434.06 examples/s]Tokenizing train dataset:  89%|████████▊ | 5932/6690 [00:13<00:01, 439.16 examples/s]Tokenizing train dataset:  89%|████████▉ | 5943/6690 [00:13<00:01, 439.12 examples/s]Tokenizing train dataset:  90%|████████▉ | 6003/6690 [00:13<00:01, 442.09 examples/s]Tokenizing train dataset:  90%|████████▉ | 6001/6690 [00:13<00:01, 439.45 examples/s]Tokenizing train dataset:  90%|████████▉ | 6010/6690 [00:13<00:01, 439.67 examples/s]Tokenizing train dataset:  91%|█████████ | 6072/6690 [00:13<00:01, 445.25 examples/s]Tokenizing train dataset:  90%|█████████ | 6046/6690 [00:13<00:01, 437.27 examples/s]Tokenizing train dataset:  91%|█████████ | 6055/6690 [00:13<00:01, 440.20 examples/s]Tokenizing train dataset:  92%|█████████▏| 6127/6690 [00:13<00:01, 463.86 examples/s]Tokenizing train dataset:  91%|█████████ | 6100/6690 [00:13<00:01, 459.17 examples/s]Tokenizing train dataset:  91%|█████████▏| 6108/6690 [00:13<00:01, 461.81 examples/s]Tokenizing train dataset:  92%|█████████▏| 6152/6690 [00:13<00:01, 465.30 examples/s]Tokenizing train dataset:  92%|█████████▏| 6155/6690 [00:13<00:01, 460.90 examples/s]Tokenizing train dataset:  93%|█████████▎| 6195/6690 [00:13<00:01, 452.74 examples/s]Tokenizing train dataset:  93%|█████████▎| 6216/6690 [00:13<00:01, 443.89 examples/s]Tokenizing train dataset:  93%|█████████▎| 6219/6690 [00:13<00:01, 446.10 examples/s]Tokenizing train dataset:  93%|█████████▎| 6250/6690 [00:14<00:01, 416.45 examples/s]Tokenizing train dataset:  94%|█████████▍| 6298/6690 [00:14<00:00, 430.56 examples/s]Tokenizing train dataset:  94%|█████████▍| 6276/6690 [00:14<00:00, 421.78 examples/s]Tokenizing train dataset:  94%|█████████▍| 6277/6690 [00:14<00:00, 421.30 examples/s]Tokenizing train dataset:  94%|█████████▍| 6320/6690 [00:14<00:00, 424.36 examples/s]Tokenizing train dataset:  94%|█████████▍| 6321/6690 [00:14<00:00, 421.88 examples/s]Tokenizing train dataset:  95%|█████████▌| 6359/6690 [00:14<00:00, 416.27 examples/s]Tokenizing train dataset:  96%|█████████▌| 6403/6690 [00:14<00:00, 417.00 examples/s]Tokenizing train dataset:  95%|█████████▌| 6380/6690 [00:14<00:00, 407.54 examples/s]Tokenizing train dataset:  95%|█████████▌| 6381/6690 [00:14<00:00, 408.67 examples/s]Tokenizing train dataset:  96%|█████████▋| 6451/6690 [00:14<00:00, 429.93 examples/s]Tokenizing train dataset:  96%|█████████▌| 6431/6690 [00:14<00:00, 429.50 examples/s]Tokenizing train dataset:  96%|█████████▌| 6431/6690 [00:14<00:00, 429.54 examples/s]Tokenizing train dataset:  97%|█████████▋| 6497/6690 [00:14<00:00, 432.81 examples/s]Tokenizing train dataset:  97%|█████████▋| 6496/6690 [00:14<00:00, 429.60 examples/s]Tokenizing train dataset:  97%|█████████▋| 6496/6690 [00:14<00:00, 430.01 examples/s]Tokenizing train dataset:  98%|█████████▊| 6541/6690 [00:14<00:00, 431.00 examples/s]Tokenizing train dataset:  98%|█████████▊| 6540/6690 [00:14<00:00, 427.11 examples/s]Tokenizing train dataset:  98%|█████████▊| 6540/6690 [00:14<00:00, 427.53 examples/s]Tokenizing train dataset:  98%|█████████▊| 6587/6690 [00:14<00:00, 435.42 examples/s]Tokenizing train dataset:  98%|█████████▊| 6584/6690 [00:14<00:00, 429.54 examples/s]Tokenizing train dataset:  98%|█████████▊| 6584/6690 [00:14<00:00, 429.83 examples/s]Tokenizing train dataset:  99%|█████████▉| 6647/6690 [00:14<00:00, 417.48 examples/s]Tokenizing train dataset:  99%|█████████▉| 6644/6690 [00:15<00:00, 415.47 examples/s]Tokenizing train dataset:  99%|█████████▉| 6644/6690 [00:14<00:00, 415.64 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 419.68 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 443.15 examples/s]
Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 419.71 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 442.11 examples/s]
Tokenizing train dataset: 100%|█████████▉| 6689/6690 [00:15<00:00, 420.42 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 442.81 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5415.89 examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5425.97 examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5389.46 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5487.97 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5426.91 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5402.87 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  28%|██▊       | 269/953 [00:00<00:00, 2669.93 examples/s]Applying chat template to eval dataset:  27%|██▋       | 260/953 [00:00<00:00, 2578.97 examples/s]Applying chat template to eval dataset:  28%|██▊       | 269/953 [00:00<00:00, 2660.23 examples/s]Applying chat template to eval dataset:  59%|█████▊    | 558/953 [00:00<00:00, 2792.38 examples/s]Applying chat template to eval dataset:  56%|█████▌    | 533/953 [00:00<00:00, 2660.30 examples/s]Applying chat template to eval dataset:  58%|█████▊    | 548/953 [00:00<00:00, 2732.37 examples/s]Applying chat template to eval dataset:  89%|████████▉ | 850/953 [00:00<00:00, 2845.55 examples/s]Applying chat template to eval dataset:  85%|████████▍ | 809/953 [00:00<00:00, 2698.43 examples/s]Applying chat template to eval dataset:  87%|████████▋ | 831/953 [00:00<00:00, 2770.36 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2808.62 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2744.95 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2673.05 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 265.54 examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 259.62 examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 255.66 examples/s]Tokenizing eval dataset:   7%|▋         | 62/953 [00:00<00:03, 230.27 examples/s]Tokenizing eval dataset:   7%|▋         | 62/953 [00:00<00:03, 230.24 examples/s]Tokenizing eval dataset:   7%|▋         | 62/953 [00:00<00:03, 230.60 examples/s]Tokenizing eval dataset:   9%|▉         | 89/953 [00:00<00:03, 241.90 examples/s]Tokenizing eval dataset:   9%|▉         | 89/953 [00:00<00:03, 243.35 examples/s]Tokenizing eval dataset:   9%|▉         | 89/953 [00:00<00:03, 242.11 examples/s]Tokenizing eval dataset:  13%|█▎        | 123/953 [00:00<00:03, 225.12 examples/s]Tokenizing eval dataset:  13%|█▎        | 123/953 [00:00<00:03, 226.21 examples/s]Tokenizing eval dataset:  13%|█▎        | 121/953 [00:00<00:03, 224.08 examples/s]Tokenizing eval dataset:  15%|█▌        | 147/953 [00:00<00:03, 227.06 examples/s]Tokenizing eval dataset:  15%|█▌        | 144/953 [00:00<00:03, 223.08 examples/s]Tokenizing eval dataset:  16%|█▋        | 157/953 [00:00<00:03, 224.88 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:00<00:03, 217.12 examples/s]Tokenizing eval dataset:  18%|█▊        | 175/953 [00:00<00:03, 211.27 examples/s]Tokenizing eval dataset:  20%|█▉        | 187/953 [00:00<00:03, 213.45 examples/s]Tokenizing eval dataset:  22%|██▏       | 206/953 [00:00<00:03, 225.51 examples/s]Tokenizing eval dataset:  22%|██▏       | 210/953 [00:00<00:03, 215.11 examples/s]Tokenizing eval dataset:  22%|██▏       | 208/953 [00:00<00:03, 212.71 examples/s]Tokenizing eval dataset:  25%|██▌       | 241/953 [00:01<00:02, 257.37 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:01<00:02, 268.79 examples/s]Tokenizing eval dataset:  26%|██▌       | 245/953 [00:01<00:02, 250.23 examples/s]Tokenizing eval dataset:  31%|███▏      | 298/953 [00:01<00:01, 341.23 examples/s]Tokenizing eval dataset:  32%|███▏      | 306/953 [00:01<00:01, 337.47 examples/s]Tokenizing eval dataset:  32%|███▏      | 301/953 [00:01<00:01, 327.64 examples/s]Tokenizing eval dataset:  37%|███▋      | 351/953 [00:01<00:01, 392.21 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:01<00:01, 392.84 examples/s]Tokenizing eval dataset:  37%|███▋      | 355/953 [00:01<00:01, 383.51 examples/s]Tokenizing eval dataset:  42%|████▏     | 403/953 [00:01<00:01, 426.87 examples/s]Tokenizing eval dataset:  44%|████▎     | 416/953 [00:01<00:01, 436.46 examples/s]Tokenizing eval dataset:  43%|████▎     | 408/953 [00:01<00:01, 418.10 examples/s]Tokenizing eval dataset:  49%|████▉     | 467/953 [00:01<00:01, 484.92 examples/s]Tokenizing eval dataset:  50%|████▉     | 474/953 [00:01<00:01, 472.79 examples/s]Tokenizing eval dataset:  49%|████▉     | 470/953 [00:01<00:01, 472.02 examples/s]Tokenizing eval dataset:  54%|█████▍    | 519/953 [00:01<00:00, 492.40 examples/s]Tokenizing eval dataset:  55%|█████▌    | 528/953 [00:01<00:00, 487.66 examples/s]Tokenizing eval dataset:  55%|█████▌    | 525/953 [00:01<00:00, 488.46 examples/s]Tokenizing eval dataset:  60%|██████    | 574/953 [00:01<00:00, 508.28 examples/s]Tokenizing eval dataset:  62%|██████▏   | 588/953 [00:01<00:00, 517.67 examples/s]Tokenizing eval dataset:  61%|██████    | 581/953 [00:01<00:00, 507.21 examples/s]Tokenizing eval dataset:  67%|██████▋   | 635/953 [00:01<00:00, 528.30 examples/s]Tokenizing eval dataset:  68%|██████▊   | 644/953 [00:01<00:00, 522.55 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:01<00:00, 525.10 examples/s]Tokenizing eval dataset:  74%|███████▍  | 709/953 [00:01<00:00, 513.12 examples/s]Tokenizing eval dataset:  73%|███████▎  | 697/953 [00:01<00:00, 514.91 examples/s]Tokenizing eval dataset:  75%|███████▌  | 715/953 [00:01<00:00, 511.64 examples/s]Tokenizing eval dataset:  82%|████████▏ | 780/953 [00:02<00:00, 493.86 examples/s]Tokenizing eval dataset:  81%|████████  | 773/953 [00:02<00:00, 502.04 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:02<00:00, 482.81 examples/s]Tokenizing eval dataset:  88%|████████▊ | 841/953 [00:02<00:00, 462.25 examples/s]Tokenizing eval dataset:  87%|████████▋ | 832/953 [00:02<00:00, 460.31 examples/s]Tokenizing eval dataset:  89%|████████▉ | 849/953 [00:02<00:00, 462.64 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:02<00:00, 446.49 examples/s]Tokenizing eval dataset:  94%|█████████▍| 900/953 [00:02<00:00, 454.06 examples/s]Tokenizing eval dataset:  95%|█████████▌| 910/953 [00:02<00:00, 440.32 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 438.11 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 388.08 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 436.73 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 385.14 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 382.13 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4201388359069824 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3247711658477783 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3387458324432373 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3705146312713623 seconds
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Training complete
Saving model
[rank4]:[W611 01:23:25.684085638 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 1 ---
