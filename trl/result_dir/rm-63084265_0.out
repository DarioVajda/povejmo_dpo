cpu-bind=MASK - gn01, task  0  0 [3209251]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 4
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn01
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 4     --machine_rank 0     --main_process_ip gn01     --main_process_port 29500     --num_processes 16     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_63084265     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=4e-6 --total_epochs=3 --beta=0.1
-------------------------------------------
[2025-06-12 10:22:28,825] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0612 10:22:30.807000 3209303 torch/distributed/run.py:792] 
W0612 10:22:30.807000 3209303 torch/distributed/run.py:792] *****************************************
W0612 10:22:30.807000 3209303 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0612 10:22:30.807000 3209303 torch/distributed/run.py:792] *****************************************
[2025-06-12 10:23:15,009] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 10:23:15,021] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 10:23:15,043] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 10:23:15,051] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[load_data.py]: Training data of type 'bad_lang_examples':    5343
[load_data.py]: Training data of type 'short_examples':       699
[load_data.py]: Training data of type 'choose_examples':      13379
[load_data.py]: Training data of type 'bad_format_examples':  4806
Namespace(rank=64, learning_rate=4e-06, total_epochs=3, beta=0.1)
Namespace(rank=64, learning_rate=4e-06, total_epochs=3, beta=0.1)
Namespace(rank=64, learning_rate=4e-06, total_epochs=3, beta=0.1)
4e-06
4e-06
4e-06
[load_data.py]: Number of training examples: 24227
[load_data.py]: Number of validation examples: 953
Namespace(rank=64, learning_rate=4e-06, total_epochs=3, beta=0.1)
4e-06
World size: 16
[2025-06-12 10:23:20,478] [INFO] [comm.py:658:init_distributed] cdb=None
Setting gradient accumulation steps to: 1
[2025-06-12 10:23:20,631] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 10:23:20,763] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Train dataset size: 24227
Validation dataset size: 953
Steps per epoch: 1514
Evaluate each 504 steps
[2025-06-12 10:23:21,636] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 10:23:21,641] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:07, 22.48s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:08, 22.98s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:08, 22.96s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:09, 23.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:47<00:47, 23.68s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:47<00:47, 23.96s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:47<00:47, 23.92s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:47<00:47, 23.96s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:11<00:24, 24.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:12<00:24, 24.35s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:12<00:24, 24.37s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:12<00:24, 24.34s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 20.93s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.03s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.09s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 21.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.09s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.09s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.12s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loaded model
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
[rank1]:[W612 10:24:55.967640827 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
[rank2]:[W612 10:24:55.047558612 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s][rank3]:[W612 10:24:55.161446153 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   2%|▏         | 506/24227 [00:00<00:04, 5020.87 examples/s]Extracting prompt in train dataset:   5%|▍         | 1140/24227 [00:00<00:05, 4475.26 examples/s]Extracting prompt in train dataset:   7%|▋         | 1666/24227 [00:00<00:06, 3346.73 examples/s]Extracting prompt in train dataset:   9%|▉         | 2130/24227 [00:00<00:05, 3702.82 examples/s]Extracting prompt in train dataset:  11%|█         | 2560/24227 [00:00<00:05, 3865.53 examples/s]Extracting prompt in train dataset:  13%|█▎        | 3151/24227 [00:00<00:05, 3887.54 examples/s]Extracting prompt in train dataset:  15%|█▍        | 3563/24227 [00:00<00:05, 3948.43 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4061/24227 [00:01<00:04, 4231.33 examples/s]Extracting prompt in train dataset:  19%|█▊        | 4520/24227 [00:01<00:04, 4321.78 examples/s]Extracting prompt in train dataset:  21%|██        | 4999/24227 [00:01<00:04, 4454.40 examples/s]Extracting prompt in train dataset:  23%|██▎       | 5471/24227 [00:01<00:04, 4528.56 examples/s]Extracting prompt in train dataset:  25%|██▍       | 5937/24227 [00:01<00:04, 3828.80 examples/s]Extracting prompt in train dataset:  26%|██▌       | 6354/24227 [00:01<00:04, 3906.53 examples/s]Extracting prompt in train dataset:  29%|██▊       | 6909/24227 [00:01<00:05, 3392.05 examples/s]Extracting prompt in train dataset:  31%|███       | 7436/24227 [00:01<00:04, 3816.81 examples/s]Extracting prompt in train dataset:  33%|███▎      | 7991/24227 [00:02<00:04, 3528.09 examples/s]Extracting prompt in train dataset:  35%|███▌      | 8564/24227 [00:02<00:04, 3613.48 examples/s]Extracting prompt in train dataset:  37%|███▋      | 9068/24227 [00:02<00:03, 3934.51 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9541/24227 [00:02<00:03, 4121.56 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10107/24227 [00:02<00:03, 3578.28 examples/s]Extracting prompt in train dataset:  44%|████▍     | 10658/24227 [00:02<00:04, 3330.72 examples/s]Extracting prompt in train dataset:  46%|████▋     | 11208/24227 [00:02<00:03, 3392.53 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11718/24227 [00:03<00:03, 3754.94 examples/s]Extracting prompt in train dataset:  51%|█████     | 12241/24227 [00:03<00:02, 4089.54 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12811/24227 [00:03<00:02, 3979.12 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 13270/24227 [00:03<00:02, 4119.71 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 13935/24227 [00:03<00:02, 4225.13 examples/s]Extracting prompt in train dataset:  60%|██████    | 14541/24227 [00:03<00:02, 4163.22 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 15090/24227 [00:03<00:02, 3513.62 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 15490/24227 [00:04<00:02, 3607.71 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 15956/24227 [00:04<00:02, 3848.61 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 16430/24227 [00:04<00:01, 4059.54 examples/s]Extracting prompt in train dataset:  70%|███████   | 17071/24227 [00:04<00:01, 4124.19 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17590/24227 [00:04<00:01, 4382.10 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 18268/24227 [00:04<00:01, 4428.87 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 18832/24227 [00:04<00:01, 3516.54 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 19281/24227 [00:04<00:01, 3713.29 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19850/24227 [00:05<00:01, 3683.78 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 20450/24227 [00:05<00:01, 3764.42 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 21030/24227 [00:05<00:01, 3141.59 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21610/24227 [00:05<00:00, 3096.01 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 22190/24227 [00:05<00:00, 3269.92 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 22770/24227 [00:06<00:00, 2736.09 examples/s]Extracting prompt in train dataset:  96%|█████████▋| 23350/24227 [00:06<00:00, 2622.56 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 23640/24227 [00:06<00:00, 2640.65 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 24010/24227 [00:06<00:00, 2830.24 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:06<00:00, 3595.79 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 280/24227 [00:00<00:08, 2758.08 examples/s]Applying chat template to train dataset:   3%|▎         | 694/24227 [00:00<00:08, 2753.00 examples/s]Applying chat template to train dataset:   5%|▍         | 1112/24227 [00:00<00:08, 2764.27 examples/s]Applying chat template to train dataset:   6%|▌         | 1510/24227 [00:00<00:08, 2712.55 examples/s]Applying chat template to train dataset:   8%|▊         | 1821/24227 [00:00<00:09, 2259.61 examples/s]Applying chat template to train dataset:   9%|▉         | 2131/24227 [00:00<00:10, 2102.51 examples/s]Applying chat template to train dataset:  10%|▉         | 2361/24227 [00:01<00:10, 2146.80 examples/s]Applying chat template to train dataset:  11%|█         | 2699/24227 [00:01<00:09, 2180.07 examples/s]Applying chat template to train dataset:  12%|█▏        | 2939/24227 [00:01<00:09, 2230.71 examples/s]Applying chat template to train dataset:  14%|█▎        | 3319/24227 [00:01<00:08, 2329.06 examples/s]Applying chat template to train dataset:  15%|█▍        | 3601/24227 [00:01<00:08, 2447.38 examples/s]Applying chat template to train dataset:  16%|█▌        | 3878/24227 [00:01<00:08, 2528.52 examples/s]Applying chat template to train dataset:  18%|█▊        | 4270/24227 [00:01<00:07, 2551.75 examples/s]Applying chat template to train dataset:  19%|█▉        | 4551/24227 [00:01<00:07, 2615.69 examples/s]Applying chat template to train dataset:  20%|██        | 4863/24227 [00:02<00:08, 2220.15 examples/s]Applying chat template to train dataset:  21%|██        | 5138/24227 [00:02<00:08, 2343.42 examples/s]Applying chat template to train dataset:  22%|██▏       | 5430/24227 [00:02<00:07, 2484.99 examples/s]Applying chat template to train dataset:  24%|██▎       | 5752/24227 [00:02<00:07, 2365.32 examples/s]Applying chat template to train dataset:  25%|██▌       | 6136/24227 [00:02<00:07, 2427.08 examples/s]Applying chat template to train dataset:  26%|██▋       | 6386/24227 [00:02<00:07, 2440.32 examples/s]Applying chat template to train dataset:  27%|██▋       | 6650/24227 [00:02<00:07, 2488.12 examples/s]Applying chat template to train dataset:  29%|██▊       | 6962/24227 [00:02<00:07, 2267.27 examples/s]Applying chat template to train dataset:  30%|███       | 7274/24227 [00:03<00:07, 2196.97 examples/s]Applying chat template to train dataset:  31%|███       | 7539/24227 [00:03<00:07, 2302.87 examples/s]Applying chat template to train dataset:  32%|███▏      | 7854/24227 [00:03<00:07, 2094.51 examples/s]Applying chat template to train dataset:  34%|███▎      | 8150/24227 [00:03<00:07, 2290.59 examples/s]Applying chat template to train dataset:  35%|███▌      | 8534/24227 [00:03<00:06, 2377.62 examples/s]Applying chat template to train dataset:  37%|███▋      | 8850/24227 [00:03<00:07, 2092.75 examples/s]Applying chat template to train dataset:  38%|███▊      | 9127/24227 [00:03<00:06, 2239.78 examples/s]Applying chat template to train dataset:  39%|███▉      | 9415/24227 [00:04<00:06, 2390.39 examples/s]Applying chat template to train dataset:  41%|████      | 9813/24227 [00:04<00:05, 2475.15 examples/s]Applying chat template to train dataset:  42%|████▏     | 10208/24227 [00:04<00:05, 2523.54 examples/s]Applying chat template to train dataset:  43%|████▎     | 10518/24227 [00:04<00:06, 2107.95 examples/s]Applying chat template to train dataset:  45%|████▍     | 10800/24227 [00:04<00:05, 2256.83 examples/s]Applying chat template to train dataset:  46%|████▌     | 11112/24227 [00:04<00:07, 1812.03 examples/s]Applying chat template to train dataset:  47%|████▋     | 11423/24227 [00:05<00:07, 1828.54 examples/s]Applying chat template to train dataset:  48%|████▊     | 11687/24227 [00:05<00:06, 1989.34 examples/s]Applying chat template to train dataset:  50%|████▉     | 12030/24227 [00:05<00:05, 2072.80 examples/s]Applying chat template to train dataset:  51%|█████     | 12253/24227 [00:05<00:05, 2106.11 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12574/24227 [00:05<00:05, 2115.20 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12797/24227 [00:05<00:05, 2139.56 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13059/24227 [00:05<00:04, 2257.03 examples/s]Applying chat template to train dataset:  55%|█████▌    | 13440/24227 [00:05<00:04, 2351.82 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13760/24227 [00:06<00:04, 2133.08 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14045/24227 [00:06<00:04, 2295.33 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14363/24227 [00:06<00:04, 2193.86 examples/s]Applying chat template to train dataset:  61%|██████    | 14712/24227 [00:06<00:04, 2233.49 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15026/24227 [00:06<00:05, 1806.59 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15274/24227 [00:06<00:05, 1696.55 examples/s]Applying chat template to train dataset:  64%|██████▍   | 15473/24227 [00:07<00:04, 1753.99 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15729/24227 [00:07<00:04, 1928.86 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15947/24227 [00:07<00:04, 1986.81 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16311/24227 [00:07<00:03, 2132.88 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16558/24227 [00:07<00:03, 2210.97 examples/s]Applying chat template to train dataset:  70%|██████▉   | 16890/24227 [00:07<00:03, 2208.74 examples/s]Applying chat template to train dataset:  71%|███████   | 17238/24227 [00:07<00:03, 2244.53 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17551/24227 [00:07<00:03, 1863.23 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17804/24227 [00:08<00:03, 1998.86 examples/s]Applying chat template to train dataset:  75%|███████▍  | 18087/24227 [00:08<00:02, 2186.64 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18376/24227 [00:08<00:02, 2357.02 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18722/24227 [00:08<00:02, 2336.60 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18996/24227 [00:08<00:02, 2434.31 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19340/24227 [00:08<00:02, 2380.60 examples/s]Applying chat template to train dataset:  81%|████████▏ | 19745/24227 [00:08<00:01, 2483.68 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20039/24227 [00:08<00:01, 2589.98 examples/s]Applying chat template to train dataset:  84%|████████▍ | 20403/24227 [00:09<00:01, 2529.27 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20734/24227 [00:09<00:01, 2422.10 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21019/24227 [00:09<00:01, 2522.57 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21433/24227 [00:09<00:01, 2597.41 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21699/24227 [00:09<00:00, 2610.18 examples/s]Applying chat template to train dataset:  91%|█████████ | 22022/24227 [00:09<00:00, 2307.01 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22320/24227 [00:09<00:00, 2462.18 examples/s]Applying chat template to train dataset:  94%|█████████▎| 22672/24227 [00:10<00:00, 2422.11 examples/s]Applying chat template to train dataset:  95%|█████████▍| 22996/24227 [00:10<00:00, 2226.34 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23297/24227 [00:10<00:00, 2403.56 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23620/24227 [00:10<00:00, 2174.12 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23853/24227 [00:10<00:00, 2207.49 examples/s]Applying chat template to train dataset:  99%|█████████▉| 24095/24227 [00:10<00:00, 2257.51 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:10<00:00, 2252.68 examples/s]
Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/24227 [00:00<01:01, 395.41 examples/s]Tokenizing train dataset:   0%|          | 86/24227 [00:00<01:14, 325.67 examples/s]Tokenizing train dataset:   1%|          | 126/24227 [00:00<01:22, 291.73 examples/s]Tokenizing train dataset:   1%|          | 165/24227 [00:00<01:27, 273.90 examples/s]Tokenizing train dataset:   1%|          | 198/24227 [00:00<01:45, 227.81 examples/s]Tokenizing train dataset:   1%|          | 234/24227 [00:00<01:59, 200.03 examples/s]Tokenizing train dataset:   1%|          | 270/24227 [00:01<01:54, 208.58 examples/s]Tokenizing train dataset:   1%|          | 297/24227 [00:01<01:49, 219.20 examples/s]Tokenizing train dataset:   1%|▏         | 336/24227 [00:01<01:45, 226.27 examples/s]Tokenizing train dataset:   1%|▏         | 360/24227 [00:01<01:44, 227.42 examples/s]Tokenizing train dataset:   2%|▏         | 389/24227 [00:01<01:39, 240.41 examples/s]Tokenizing train dataset:   2%|▏         | 430/24227 [00:01<01:35, 249.47 examples/s]Tokenizing train dataset:   2%|▏         | 459/24227 [00:01<01:46, 223.58 examples/s]Tokenizing train dataset:   2%|▏         | 490/24227 [00:02<01:56, 203.22 examples/s]Tokenizing train dataset:   2%|▏         | 524/24227 [00:02<01:59, 197.94 examples/s]Tokenizing train dataset:   2%|▏         | 549/24227 [00:02<01:54, 206.38 examples/s]Tokenizing train dataset:   2%|▏         | 586/24227 [00:02<01:50, 214.05 examples/s]Tokenizing train dataset:   3%|▎         | 614/24227 [00:02<01:45, 223.28 examples/s]Tokenizing train dataset:   3%|▎         | 644/24227 [00:02<01:38, 238.86 examples/s]Tokenizing train dataset:   3%|▎         | 685/24227 [00:02<01:35, 246.45 examples/s]Tokenizing train dataset:   3%|▎         | 729/24227 [00:03<01:31, 258.07 examples/s]Tokenizing train dataset:   3%|▎         | 768/24227 [00:03<01:31, 255.82 examples/s]Tokenizing train dataset:   3%|▎         | 795/24227 [00:03<01:44, 223.36 examples/s]Tokenizing train dataset:   3%|▎         | 823/24227 [00:03<01:40, 232.77 examples/s]Tokenizing train dataset:   4%|▎         | 854/24227 [00:03<02:02, 190.37 examples/s]Tokenizing train dataset:   4%|▎         | 879/24227 [00:03<01:56, 200.80 examples/s]Tokenizing train dataset:   4%|▍         | 912/24227 [00:03<01:42, 227.60 examples/s]Tokenizing train dataset:   4%|▍         | 951/24227 [00:04<01:38, 235.29 examples/s]Tokenizing train dataset:   4%|▍         | 983/24227 [00:04<01:42, 226.38 examples/s]Tokenizing train dataset:   4%|▍         | 1019/24227 [00:04<01:41, 228.75 examples/s]Tokenizing train dataset:   4%|▍         | 1052/24227 [00:04<01:43, 223.39 examples/s]Tokenizing train dataset:   4%|▍         | 1086/24227 [00:04<01:54, 201.74 examples/s]Tokenizing train dataset:   5%|▍         | 1115/24227 [00:04<01:46, 216.70 examples/s]Tokenizing train dataset:   5%|▍         | 1151/24227 [00:05<01:44, 221.15 examples/s]Tokenizing train dataset:   5%|▍         | 1190/24227 [00:05<01:40, 228.48 examples/s]Tokenizing train dataset:   5%|▌         | 1230/24227 [00:05<01:37, 236.79 examples/s]Tokenizing train dataset:   5%|▌         | 1259/24227 [00:05<01:32, 247.25 examples/s]Tokenizing train dataset:   5%|▌         | 1298/24227 [00:05<01:32, 248.59 examples/s]Tokenizing train dataset:   5%|▌         | 1325/24227 [00:05<01:31, 251.30 examples/s]Tokenizing train dataset:   6%|▌         | 1355/24227 [00:05<01:40, 227.09 examples/s]Tokenizing train dataset:   6%|▌         | 1387/24227 [00:06<01:52, 203.09 examples/s]Tokenizing train dataset:   6%|▌         | 1424/24227 [00:06<01:46, 214.89 examples/s]Tokenizing train dataset:   6%|▌         | 1454/24227 [00:06<01:55, 197.67 examples/s]Tokenizing train dataset:   6%|▌         | 1490/24227 [00:06<01:50, 204.86 examples/s]Tokenizing train dataset:   6%|▋         | 1518/24227 [00:06<01:56, 194.36 examples/s]Tokenizing train dataset:   6%|▋         | 1538/24227 [00:06<02:11, 173.12 examples/s]Tokenizing train dataset:   6%|▋         | 1569/24227 [00:07<02:21, 160.19 examples/s]Tokenizing train dataset:   7%|▋         | 1586/24227 [00:07<02:34, 146.10 examples/s]Tokenizing train dataset:   7%|▋         | 1601/24227 [00:07<02:48, 134.32 examples/s]Tokenizing train dataset:   7%|▋         | 1627/24227 [00:07<02:22, 158.30 examples/s]Tokenizing train dataset:   7%|▋         | 1646/24227 [00:07<02:27, 153.58 examples/s]Tokenizing train dataset:   7%|▋         | 1676/24227 [00:07<02:02, 183.95 examples/s]Tokenizing train dataset:   7%|▋         | 1700/24227 [00:07<02:02, 184.19 examples/s]Tokenizing train dataset:   7%|▋         | 1720/24227 [00:08<01:59, 187.77 examples/s]Tokenizing train dataset:   7%|▋         | 1747/24227 [00:08<01:49, 206.19 examples/s]Tokenizing train dataset:   7%|▋         | 1770/24227 [00:08<01:47, 208.90 examples/s]Tokenizing train dataset:   7%|▋         | 1796/24227 [00:08<01:43, 217.61 examples/s]Tokenizing train dataset:   8%|▊         | 1829/24227 [00:08<01:44, 214.08 examples/s]Tokenizing train dataset:   8%|▊         | 1861/24227 [00:08<02:14, 166.63 examples/s]Tokenizing train dataset:   8%|▊         | 1885/24227 [00:08<02:04, 179.93 examples/s]Tokenizing train dataset:   8%|▊         | 1910/24227 [00:09<02:20, 158.70 examples/s]Tokenizing train dataset:   8%|▊         | 1929/24227 [00:09<02:16, 163.23 examples/s]Tokenizing train dataset:   8%|▊         | 1951/24227 [00:09<02:07, 174.80 examples/s]Tokenizing train dataset:   8%|▊         | 1970/24227 [00:09<02:06, 175.79 examples/s]Tokenizing train dataset:   8%|▊         | 2002/24227 [00:09<02:06, 175.13 examples/s]Tokenizing train dataset:   8%|▊         | 2022/24227 [00:09<02:14, 165.21 examples/s]Tokenizing train dataset:   8%|▊         | 2056/24227 [00:09<02:12, 167.55 examples/s]Tokenizing train dataset:   9%|▊         | 2076/24227 [00:10<02:07, 173.75 examples/s]Tokenizing train dataset:   9%|▊         | 2101/24227 [00:10<01:57, 189.02 examples/s]Tokenizing train dataset:   9%|▉         | 2123/24227 [00:10<01:53, 194.82 examples/s]Tokenizing train dataset:   9%|▉         | 2147/24227 [00:10<01:47, 205.24 examples/s]Tokenizing train dataset:   9%|▉         | 2171/24227 [00:10<01:44, 211.19 examples/s]Tokenizing train dataset:   9%|▉         | 2200/24227 [00:10<02:01, 180.91 examples/s]Tokenizing train dataset:   9%|▉         | 2238/24227 [00:10<01:56, 188.03 examples/s]Tokenizing train dataset:   9%|▉         | 2266/24227 [00:10<01:46, 206.31 examples/s]Tokenizing train dataset:  10%|▉         | 2302/24227 [00:11<01:42, 214.03 examples/s]Tokenizing train dataset:  10%|▉         | 2336/24227 [00:11<01:41, 215.57 examples/s]Tokenizing train dataset:  10%|▉         | 2361/24227 [00:11<01:38, 221.58 examples/s]Tokenizing train dataset:  10%|▉         | 2396/24227 [00:11<01:37, 222.78 examples/s]Tokenizing train dataset:  10%|█         | 2430/24227 [00:11<01:37, 222.51 examples/s]Tokenizing train dataset:  10%|█         | 2458/24227 [00:11<01:45, 205.81 examples/s]Tokenizing train dataset:  10%|█         | 2492/24227 [00:12<02:08, 169.61 examples/s]Tokenizing train dataset:  10%|█         | 2512/24227 [00:12<02:08, 169.15 examples/s]Tokenizing train dataset:  10%|█         | 2540/24227 [00:12<02:22, 152.47 examples/s]Tokenizing train dataset:  11%|█         | 2558/24227 [00:12<02:30, 143.79 examples/s]Tokenizing train dataset:  11%|█         | 2589/24227 [00:12<02:03, 175.82 examples/s]Tokenizing train dataset:  11%|█         | 2617/24227 [00:12<01:49, 197.57 examples/s]Tokenizing train dataset:  11%|█         | 2643/24227 [00:12<01:42, 209.66 examples/s]Tokenizing train dataset:  11%|█         | 2674/24227 [00:13<01:44, 206.15 examples/s]Tokenizing train dataset:  11%|█         | 2706/24227 [00:13<01:33, 230.19 examples/s]Tokenizing train dataset:  11%|█▏        | 2734/24227 [00:13<01:43, 207.82 examples/s]Tokenizing train dataset:  11%|█▏        | 2764/24227 [00:13<01:59, 179.46 examples/s]Tokenizing train dataset:  12%|█▏        | 2798/24227 [00:13<01:55, 185.85 examples/s]Tokenizing train dataset:  12%|█▏        | 2828/24227 [00:13<01:54, 186.61 examples/s]Tokenizing train dataset:  12%|█▏        | 2858/24227 [00:14<02:03, 173.22 examples/s]Tokenizing train dataset:  12%|█▏        | 2880/24227 [00:14<01:58, 180.11 examples/s]Tokenizing train dataset:  12%|█▏        | 2910/24227 [00:14<01:44, 203.89 examples/s]Tokenizing train dataset:  12%|█▏        | 2942/24227 [00:14<02:14, 158.26 examples/s]Tokenizing train dataset:  12%|█▏        | 2962/24227 [00:14<02:09, 164.78 examples/s]Tokenizing train dataset:  12%|█▏        | 2993/24227 [00:14<02:12, 159.83 examples/s]Tokenizing train dataset:  12%|█▏        | 3016/24227 [00:15<02:04, 170.74 examples/s]Tokenizing train dataset:  13%|█▎        | 3044/24227 [00:15<01:50, 192.41 examples/s]Tokenizing train dataset:  13%|█▎        | 3070/24227 [00:15<01:42, 205.99 examples/s]Tokenizing train dataset:  13%|█▎        | 3104/24227 [00:15<01:40, 210.41 examples/s]Tokenizing train dataset:  13%|█▎        | 3135/24227 [00:15<01:44, 201.61 examples/s]Tokenizing train dataset:  13%|█▎        | 3167/24227 [00:15<01:47, 195.90 examples/s]Tokenizing train dataset:  13%|█▎        | 3200/24227 [00:15<01:54, 183.46 examples/s]Tokenizing train dataset:  13%|█▎        | 3230/24227 [00:16<02:02, 171.33 examples/s]Tokenizing train dataset:  13%|█▎        | 3257/24227 [00:16<01:50, 189.10 examples/s]Tokenizing train dataset:  14%|█▎        | 3286/24227 [00:16<01:58, 177.05 examples/s]Tokenizing train dataset:  14%|█▎        | 3308/24227 [00:16<01:53, 184.62 examples/s]Tokenizing train dataset:  14%|█▎        | 3330/24227 [00:16<01:50, 189.76 examples/s]Tokenizing train dataset:  14%|█▍        | 3360/24227 [00:16<01:37, 213.86 examples/s]Tokenizing train dataset:  14%|█▍        | 3396/24227 [00:16<01:36, 216.37 examples/s]Tokenizing train dataset:  14%|█▍        | 3426/24227 [00:17<01:40, 207.79 examples/s]Tokenizing train dataset:  14%|█▍        | 3450/24227 [00:17<01:59, 173.31 examples/s]Tokenizing train dataset:  14%|█▍        | 3474/24227 [00:17<02:22, 145.59 examples/s]Tokenizing train dataset:  14%|█▍        | 3512/24227 [00:17<02:10, 158.49 examples/s]Tokenizing train dataset:  15%|█▍        | 3531/24227 [00:17<02:18, 149.68 examples/s]Tokenizing train dataset:  15%|█▍        | 3567/24227 [00:18<02:07, 161.65 examples/s]Tokenizing train dataset:  15%|█▍        | 3585/24227 [00:18<02:27, 140.40 examples/s]Tokenizing train dataset:  15%|█▍        | 3615/24227 [00:18<02:31, 136.33 examples/s]Tokenizing train dataset:  15%|█▍        | 3634/24227 [00:18<02:21, 145.27 examples/s]Tokenizing train dataset:  15%|█▌        | 3651/24227 [00:18<02:58, 115.49 examples/s]Tokenizing train dataset:  15%|█▌        | 3670/24227 [00:18<02:46, 123.52 examples/s]Tokenizing train dataset:  15%|█▌        | 3684/24227 [00:19<02:42, 126.07 examples/s]Tokenizing train dataset:  15%|█▌        | 3699/24227 [00:19<02:47, 122.43 examples/s]Tokenizing train dataset:  15%|█▌        | 3715/24227 [00:19<02:48, 121.41 examples/s]Tokenizing train dataset:  15%|█▌        | 3734/24227 [00:19<02:31, 135.49 examples/s]Tokenizing train dataset:  15%|█▌        | 3751/24227 [00:19<02:26, 139.39 examples/s]Tokenizing train dataset:  16%|█▌        | 3773/24227 [00:19<02:09, 157.97 examples/s]Tokenizing train dataset:  16%|█▌        | 3807/24227 [00:19<02:04, 164.65 examples/s]Tokenizing train dataset:  16%|█▌        | 3836/24227 [00:19<01:46, 192.32 examples/s]Tokenizing train dataset:  16%|█▌        | 3870/24227 [00:20<01:59, 169.65 examples/s]Tokenizing train dataset:  16%|█▌        | 3893/24227 [00:20<01:51, 181.84 examples/s]Tokenizing train dataset:  16%|█▌        | 3920/24227 [00:20<01:53, 178.17 examples/s]Tokenizing train dataset:  16%|█▋        | 3941/24227 [00:20<01:50, 182.86 examples/s]Tokenizing train dataset:  16%|█▋        | 3973/24227 [00:20<01:34, 214.16 examples/s]Tokenizing train dataset:  17%|█▋        | 4007/24227 [00:20<01:34, 214.31 examples/s]Tokenizing train dataset:  17%|█▋        | 4038/24227 [00:21<01:40, 200.42 examples/s]Tokenizing train dataset:  17%|█▋        | 4066/24227 [00:21<01:47, 187.67 examples/s]Tokenizing train dataset:  17%|█▋        | 4101/24227 [00:21<01:58, 170.38 examples/s]Tokenizing train dataset:  17%|█▋        | 4129/24227 [00:21<01:46, 189.47 examples/s]Tokenizing train dataset:  17%|█▋        | 4165/24227 [00:21<01:39, 202.00 examples/s]Tokenizing train dataset:  17%|█▋        | 4195/24227 [00:21<01:30, 222.27 examples/s]Tokenizing train dataset:  17%|█▋        | 4220/24227 [00:21<01:28, 226.20 examples/s]Tokenizing train dataset:  18%|█▊        | 4250/24227 [00:22<01:33, 213.04 examples/s]Tokenizing train dataset:  18%|█▊        | 4281/24227 [00:22<01:36, 207.63 examples/s]Tokenizing train dataset:  18%|█▊        | 4310/24227 [00:22<01:41, 196.91 examples/s]Tokenizing train dataset:  18%|█▊        | 4348/24227 [00:22<01:34, 210.91 examples/s]Tokenizing train dataset:  18%|█▊        | 4376/24227 [00:22<01:38, 200.76 examples/s]Tokenizing train dataset:  18%|█▊        | 4413/24227 [00:22<01:37, 202.48 examples/s]Tokenizing train dataset:  18%|█▊        | 4440/24227 [00:22<01:32, 213.65 examples/s]Tokenizing train dataset:  18%|█▊        | 4472/24227 [00:23<01:33, 210.94 examples/s]Tokenizing train dataset:  19%|█▊        | 4505/24227 [00:23<01:47, 182.73 examples/s]Tokenizing train dataset:  19%|█▊        | 4530/24227 [00:23<01:41, 194.28 examples/s]Tokenizing train dataset:  19%|█▉        | 4553/24227 [00:23<01:37, 201.18 examples/s]Tokenizing train dataset:  19%|█▉        | 4580/24227 [00:23<01:47, 183.46 examples/s]Tokenizing train dataset:  19%|█▉        | 4601/24227 [00:23<01:54, 171.91 examples/s]Tokenizing train dataset:  19%|█▉        | 4624/24227 [00:23<01:47, 182.71 examples/s]Tokenizing train dataset:  19%|█▉        | 4647/24227 [00:24<01:42, 191.86 examples/s]Tokenizing train dataset:  19%|█▉        | 4672/24227 [00:24<01:37, 201.58 examples/s]Tokenizing train dataset:  19%|█▉        | 4701/24227 [00:24<01:40, 193.67 examples/s]Tokenizing train dataset:  20%|█▉        | 4733/24227 [00:24<01:43, 187.79 examples/s]Tokenizing train dataset:  20%|█▉        | 4766/24227 [00:24<01:44, 186.66 examples/s]Tokenizing train dataset:  20%|█▉        | 4795/24227 [00:24<01:54, 169.85 examples/s]Tokenizing train dataset:  20%|█▉        | 4814/24227 [00:25<01:58, 163.30 examples/s]Tokenizing train dataset:  20%|█▉        | 4837/24227 [00:25<02:17, 141.24 examples/s]Tokenizing train dataset:  20%|██        | 4860/24227 [00:25<02:04, 156.00 examples/s]Tokenizing train dataset:  20%|██        | 4884/24227 [00:25<01:51, 173.49 examples/s]Tokenizing train dataset:  20%|██        | 4909/24227 [00:25<01:41, 189.88 examples/s]Tokenizing train dataset:  20%|██        | 4930/24227 [00:25<01:39, 193.58 examples/s]Tokenizing train dataset:  20%|██        | 4954/24227 [00:25<02:06, 151.94 examples/s]Tokenizing train dataset:  21%|██        | 4990/24227 [00:26<01:58, 162.18 examples/s]Tokenizing train dataset:  21%|██        | 5024/24227 [00:26<01:54, 167.07 examples/s]Tokenizing train dataset:  21%|██        | 5053/24227 [00:26<01:40, 189.96 examples/s]Tokenizing train dataset:  21%|██        | 5082/24227 [00:26<01:49, 174.38 examples/s]Tokenizing train dataset:  21%|██        | 5107/24227 [00:26<01:41, 188.81 examples/s]Tokenizing train dataset:  21%|██        | 5138/24227 [00:26<01:47, 177.83 examples/s]Tokenizing train dataset:  21%|██▏       | 5166/24227 [00:27<01:58, 160.48 examples/s]Tokenizing train dataset:  21%|██▏       | 5190/24227 [00:27<01:48, 175.30 examples/s]Tokenizing train dataset:  22%|██▏       | 5219/24227 [00:27<01:36, 197.84 examples/s]Tokenizing train dataset:  22%|██▏       | 5250/24227 [00:27<01:36, 196.51 examples/s]Tokenizing train dataset:  22%|██▏       | 5283/24227 [00:27<01:35, 198.77 examples/s]Tokenizing train dataset:  22%|██▏       | 5315/24227 [00:27<01:34, 199.80 examples/s]Tokenizing train dataset:  22%|██▏       | 5347/24227 [00:27<01:35, 198.03 examples/s]Tokenizing train dataset:  22%|██▏       | 5370/24227 [00:28<01:36, 195.04 examples/s]Tokenizing train dataset:  22%|██▏       | 5401/24227 [00:28<01:26, 218.04 examples/s]Tokenizing train dataset:  22%|██▏       | 5429/24227 [00:28<01:21, 229.97 examples/s]Tokenizing train dataset:  23%|██▎       | 5460/24227 [00:28<01:28, 212.16 examples/s]Tokenizing train dataset:  23%|██▎       | 5486/24227 [00:28<01:25, 219.95 examples/s]Tokenizing train dataset:  23%|██▎       | 5519/24227 [00:28<01:39, 187.17 examples/s]Tokenizing train dataset:  23%|██▎       | 5545/24227 [00:28<01:33, 198.78 examples/s]Tokenizing train dataset:  23%|██▎       | 5582/24227 [00:29<01:28, 211.04 examples/s]Tokenizing train dataset:  23%|██▎       | 5617/24227 [00:29<01:17, 240.47 examples/s]Tokenizing train dataset:  23%|██▎       | 5644/24227 [00:29<01:15, 245.08 examples/s]Tokenizing train dataset:  23%|██▎       | 5680/24227 [00:29<01:23, 223.09 examples/s]Tokenizing train dataset:  24%|██▎       | 5709/24227 [00:29<01:17, 237.54 examples/s]Tokenizing train dataset:  24%|██▎       | 5749/24227 [00:29<01:16, 242.72 examples/s]Tokenizing train dataset:  24%|██▍       | 5781/24227 [00:29<01:20, 229.41 examples/s]Tokenizing train dataset:  24%|██▍       | 5805/24227 [00:30<01:20, 229.94 examples/s]Tokenizing train dataset:  24%|██▍       | 5832/24227 [00:30<01:17, 238.42 examples/s]Tokenizing train dataset:  24%|██▍       | 5860/24227 [00:30<01:14, 247.19 examples/s]Tokenizing train dataset:  24%|██▍       | 5888/24227 [00:30<01:11, 255.10 examples/s]Tokenizing train dataset:  24%|██▍       | 5921/24227 [00:30<01:16, 238.19 examples/s]Tokenizing train dataset:  25%|██▍       | 5958/24227 [00:30<01:16, 239.81 examples/s]Tokenizing train dataset:  25%|██▍       | 5990/24227 [00:30<01:21, 224.60 examples/s]Tokenizing train dataset:  25%|██▍       | 6017/24227 [00:30<01:18, 231.88 examples/s]Tokenizing train dataset:  25%|██▌       | 6061/24227 [00:31<01:12, 249.43 examples/s]Tokenizing train dataset:  25%|██▌       | 6099/24227 [00:31<01:15, 238.64 examples/s]Tokenizing train dataset:  25%|██▌       | 6132/24227 [00:31<01:09, 258.51 examples/s]Tokenizing train dataset:  25%|██▌       | 6162/24227 [00:31<01:08, 263.69 examples/s]Tokenizing train dataset:  26%|██▌       | 6196/24227 [00:31<01:04, 279.82 examples/s]Tokenizing train dataset:  26%|██▌       | 6237/24227 [00:31<01:05, 274.86 examples/s]Tokenizing train dataset:  26%|██▌       | 6276/24227 [00:31<00:59, 300.52 examples/s]Tokenizing train dataset:  26%|██▌       | 6308/24227 [00:31<00:58, 304.94 examples/s]Tokenizing train dataset:  26%|██▌       | 6357/24227 [00:32<00:57, 309.12 examples/s]Tokenizing train dataset:  26%|██▋       | 6409/24227 [00:32<00:56, 317.65 examples/s]Tokenizing train dataset:  27%|██▋       | 6445/24227 [00:32<00:54, 323.74 examples/s]Tokenizing train dataset:  27%|██▋       | 6482/24227 [00:32<01:00, 292.50 examples/s]Tokenizing train dataset:  27%|██▋       | 6518/24227 [00:32<01:04, 275.16 examples/s]Tokenizing train dataset:  27%|██▋       | 6553/24227 [00:32<01:00, 291.74 examples/s]Tokenizing train dataset:  27%|██▋       | 6584/24227 [00:32<01:00, 293.58 examples/s]Tokenizing train dataset:  27%|██▋       | 6630/24227 [00:32<00:59, 294.26 examples/s]Tokenizing train dataset:  28%|██▊       | 6673/24227 [00:33<01:05, 269.86 examples/s]Tokenizing train dataset:  28%|██▊       | 6712/24227 [00:33<01:06, 263.70 examples/s]Tokenizing train dataset:  28%|██▊       | 6749/24227 [00:33<01:25, 205.41 examples/s]Tokenizing train dataset:  28%|██▊       | 6779/24227 [00:33<01:19, 220.71 examples/s]Tokenizing train dataset:  28%|██▊       | 6813/24227 [00:33<01:11, 243.07 examples/s]Tokenizing train dataset:  28%|██▊       | 6840/24227 [00:33<01:10, 247.12 examples/s]Tokenizing train dataset:  28%|██▊       | 6883/24227 [00:34<01:20, 215.44 examples/s]Tokenizing train dataset:  29%|██▊       | 6920/24227 [00:34<01:10, 245.07 examples/s]Tokenizing train dataset:  29%|██▊       | 6964/24227 [00:34<01:07, 256.74 examples/s]Tokenizing train dataset:  29%|██▉       | 7002/24227 [00:34<01:10, 242.65 examples/s]Tokenizing train dataset:  29%|██▉       | 7039/24227 [00:34<01:14, 230.09 examples/s]Tokenizing train dataset:  29%|██▉       | 7077/24227 [00:35<01:24, 203.12 examples/s]Tokenizing train dataset:  29%|██▉       | 7105/24227 [00:35<01:19, 216.33 examples/s]Tokenizing train dataset:  29%|██▉       | 7146/24227 [00:35<01:14, 228.39 examples/s]Tokenizing train dataset:  30%|██▉       | 7183/24227 [00:35<01:24, 200.86 examples/s]Tokenizing train dataset:  30%|██▉       | 7210/24227 [00:35<01:19, 212.77 examples/s]Tokenizing train dataset:  30%|██▉       | 7243/24227 [00:35<01:11, 235.98 examples/s]Tokenizing train dataset:  30%|███       | 7274/24227 [00:35<01:07, 252.54 examples/s]Tokenizing train dataset:  30%|███       | 7318/24227 [00:35<01:04, 262.47 examples/s]Tokenizing train dataset:  30%|███       | 7362/24227 [00:36<01:02, 268.77 examples/s]Tokenizing train dataset:  31%|███       | 7391/24227 [00:36<01:02, 270.80 examples/s]Tokenizing train dataset:  31%|███       | 7433/24227 [00:36<01:02, 269.09 examples/s]Tokenizing train dataset:  31%|███       | 7475/24227 [00:36<01:05, 254.14 examples/s]Tokenizing train dataset:  31%|███       | 7514/24227 [00:36<01:14, 225.80 examples/s]Tokenizing train dataset:  31%|███       | 7540/24227 [00:36<01:12, 231.39 examples/s]Tokenizing train dataset:  31%|███▏      | 7573/24227 [00:37<01:13, 226.75 examples/s]Tokenizing train dataset:  31%|███▏      | 7607/24227 [00:37<01:20, 207.53 examples/s]Tokenizing train dataset:  32%|███▏      | 7641/24227 [00:37<01:28, 187.15 examples/s]Tokenizing train dataset:  32%|███▏      | 7661/24227 [00:37<01:28, 187.71 examples/s]Tokenizing train dataset:  32%|███▏      | 7702/24227 [00:37<01:10, 234.09 examples/s]Tokenizing train dataset:  32%|███▏      | 7734/24227 [00:37<01:05, 252.96 examples/s]Tokenizing train dataset:  32%|███▏      | 7771/24227 [00:37<01:07, 242.90 examples/s]Tokenizing train dataset:  32%|███▏      | 7829/24227 [00:38<00:51, 320.50 examples/s]Tokenizing train dataset:  32%|███▏      | 7865/24227 [00:38<01:00, 270.99 examples/s]Tokenizing train dataset:  33%|███▎      | 7925/24227 [00:38<00:47, 342.33 examples/s]Tokenizing train dataset:  33%|███▎      | 7996/24227 [00:38<00:37, 431.24 examples/s]Tokenizing train dataset:  33%|███▎      | 8071/24227 [00:38<00:35, 452.38 examples/s]Tokenizing train dataset:  34%|███▎      | 8143/24227 [00:38<00:36, 442.04 examples/s]Tokenizing train dataset:  34%|███▍      | 8197/24227 [00:38<00:34, 461.39 examples/s]Tokenizing train dataset:  34%|███▍      | 8270/24227 [00:38<00:30, 524.67 examples/s]Tokenizing train dataset:  34%|███▍      | 8347/24227 [00:39<00:30, 514.85 examples/s]Tokenizing train dataset:  35%|███▍      | 8402/24227 [00:39<00:30, 519.25 examples/s]Tokenizing train dataset:  35%|███▍      | 8477/24227 [00:39<00:33, 464.65 examples/s]Tokenizing train dataset:  35%|███▌      | 8549/24227 [00:39<00:33, 466.65 examples/s]Tokenizing train dataset:  36%|███▌      | 8637/24227 [00:39<00:32, 476.20 examples/s]Tokenizing train dataset:  36%|███▌      | 8712/24227 [00:39<00:34, 445.29 examples/s]Tokenizing train dataset:  36%|███▌      | 8781/24227 [00:40<00:34, 447.87 examples/s]Tokenizing train dataset:  36%|███▋      | 8830/24227 [00:40<00:34, 452.16 examples/s]Tokenizing train dataset:  37%|███▋      | 8897/24227 [00:40<00:39, 388.01 examples/s]Tokenizing train dataset:  37%|███▋      | 8975/24227 [00:40<00:36, 420.08 examples/s]Tokenizing train dataset:  37%|███▋      | 9035/24227 [00:40<00:33, 454.24 examples/s]Tokenizing train dataset:  38%|███▊      | 9105/24227 [00:40<00:29, 508.39 examples/s]Tokenizing train dataset:  38%|███▊      | 9163/24227 [00:40<00:28, 520.63 examples/s]Tokenizing train dataset:  38%|███▊      | 9229/24227 [00:41<00:27, 553.96 examples/s]Tokenizing train dataset:  38%|███▊      | 9310/24227 [00:41<00:29, 507.80 examples/s]Tokenizing train dataset:  39%|███▉      | 9392/24227 [00:41<00:28, 518.38 examples/s]Tokenizing train dataset:  39%|███▉      | 9450/24227 [00:41<00:27, 531.59 examples/s]Tokenizing train dataset:  39%|███▉      | 9522/24227 [00:41<00:31, 467.14 examples/s]Tokenizing train dataset:  40%|███▉      | 9584/24227 [00:41<00:33, 436.87 examples/s]Tokenizing train dataset:  40%|███▉      | 9652/24227 [00:41<00:33, 431.93 examples/s]Tokenizing train dataset:  40%|████      | 9724/24227 [00:42<00:35, 412.57 examples/s]Tokenizing train dataset:  40%|████      | 9778/24227 [00:42<00:33, 435.87 examples/s]Tokenizing train dataset:  41%|████      | 9851/24227 [00:42<00:31, 450.25 examples/s]Tokenizing train dataset:  41%|████      | 9921/24227 [00:42<00:31, 451.89 examples/s]Tokenizing train dataset:  41%|████      | 9992/24227 [00:42<00:27, 508.88 examples/s]Tokenizing train dataset:  41%|████▏     | 10050/24227 [00:42<00:27, 518.51 examples/s]Tokenizing train dataset:  42%|████▏     | 10130/24227 [00:42<00:27, 518.54 examples/s]Tokenizing train dataset:  42%|████▏     | 10195/24227 [00:43<00:34, 409.46 examples/s]Tokenizing train dataset:  42%|████▏     | 10253/24227 [00:43<00:34, 400.42 examples/s]Tokenizing train dataset:  43%|████▎     | 10307/24227 [00:43<00:42, 331.01 examples/s]Tokenizing train dataset:  43%|████▎     | 10344/24227 [00:43<00:51, 268.97 examples/s]Tokenizing train dataset:  43%|████▎     | 10393/24227 [00:43<00:49, 280.48 examples/s]Tokenizing train dataset:  43%|████▎     | 10430/24227 [00:44<00:46, 294.16 examples/s]Tokenizing train dataset:  43%|████▎     | 10464/24227 [00:44<00:45, 301.95 examples/s]Tokenizing train dataset:  43%|████▎     | 10500/24227 [00:44<00:54, 250.60 examples/s]Tokenizing train dataset:  44%|████▎     | 10542/24227 [00:44<00:53, 255.10 examples/s]Tokenizing train dataset:  44%|████▎     | 10575/24227 [00:44<00:51, 266.96 examples/s]Tokenizing train dataset:  44%|████▍     | 10612/24227 [00:44<00:54, 251.60 examples/s]Tokenizing train dataset:  44%|████▍     | 10651/24227 [00:45<00:58, 232.00 examples/s]Tokenizing train dataset:  44%|████▍     | 10687/24227 [00:45<00:58, 232.71 examples/s]Tokenizing train dataset:  44%|████▍     | 10720/24227 [00:45<00:53, 250.35 examples/s]Tokenizing train dataset:  44%|████▍     | 10757/24227 [00:45<01:00, 222.07 examples/s]Tokenizing train dataset:  45%|████▍     | 10786/24227 [00:45<00:57, 234.70 examples/s]Tokenizing train dataset:  45%|████▍     | 10826/24227 [00:45<00:49, 268.50 examples/s]Tokenizing train dataset:  45%|████▍     | 10858/24227 [00:45<00:48, 276.21 examples/s]Tokenizing train dataset:  45%|████▍     | 10894/24227 [00:46<00:57, 233.38 examples/s]Tokenizing train dataset:  45%|████▌     | 10922/24227 [00:46<00:55, 241.83 examples/s]Tokenizing train dataset:  45%|████▌     | 10960/24227 [00:46<00:55, 238.93 examples/s]Tokenizing train dataset:  45%|████▌     | 10996/24227 [00:46<00:49, 265.15 examples/s]Tokenizing train dataset:  46%|████▌     | 11047/24227 [00:46<00:46, 285.58 examples/s]Tokenizing train dataset:  46%|████▌     | 11085/24227 [00:46<00:56, 233.86 examples/s]Tokenizing train dataset:  46%|████▌     | 11118/24227 [00:46<01:01, 213.99 examples/s]Tokenizing train dataset:  46%|████▌     | 11159/24227 [00:47<01:00, 215.23 examples/s]Tokenizing train dataset:  46%|████▌     | 11193/24227 [00:47<00:54, 237.59 examples/s]Tokenizing train dataset:  46%|████▋     | 11220/24227 [00:47<00:53, 243.68 examples/s]Tokenizing train dataset:  46%|████▋     | 11249/24227 [00:47<00:51, 250.16 examples/s]Tokenizing train dataset:  47%|████▋     | 11281/24227 [00:47<00:48, 264.77 examples/s]Tokenizing train dataset:  47%|████▋     | 11317/24227 [00:47<00:45, 285.77 examples/s]Tokenizing train dataset:  47%|████▋     | 11358/24227 [00:47<00:49, 261.12 examples/s]Tokenizing train dataset:  47%|████▋     | 11393/24227 [00:48<00:51, 247.30 examples/s]Tokenizing train dataset:  47%|████▋     | 11422/24227 [00:48<00:49, 256.20 examples/s]Tokenizing train dataset:  47%|████▋     | 11459/24227 [00:48<00:45, 281.26 examples/s]Tokenizing train dataset:  47%|████▋     | 11496/24227 [00:48<00:42, 299.15 examples/s]Tokenizing train dataset:  48%|████▊     | 11539/24227 [00:48<00:43, 291.04 examples/s]Tokenizing train dataset:  48%|████▊     | 11570/24227 [00:48<00:43, 290.95 examples/s]Tokenizing train dataset:  48%|████▊     | 11608/24227 [00:48<00:49, 254.23 examples/s]Tokenizing train dataset:  48%|████▊     | 11644/24227 [00:48<00:45, 276.62 examples/s]Tokenizing train dataset:  48%|████▊     | 11678/24227 [00:49<00:49, 253.77 examples/s]Tokenizing train dataset:  48%|████▊     | 11721/24227 [00:49<00:47, 262.66 examples/s]Tokenizing train dataset:  49%|████▊     | 11760/24227 [00:49<00:48, 256.96 examples/s]Tokenizing train dataset:  49%|████▊     | 11791/24227 [00:49<00:46, 265.71 examples/s]Tokenizing train dataset:  49%|████▉     | 11831/24227 [00:49<00:55, 223.63 examples/s]Tokenizing train dataset:  49%|████▉     | 11879/24227 [00:49<00:44, 275.87 examples/s]Tokenizing train dataset:  49%|████▉     | 11927/24227 [00:49<00:38, 321.55 examples/s]Tokenizing train dataset:  49%|████▉     | 11981/24227 [00:50<00:32, 372.07 examples/s]Tokenizing train dataset:  50%|████▉     | 12030/24227 [00:50<00:30, 400.46 examples/s]Tokenizing train dataset:  50%|████▉     | 12089/24227 [00:50<00:27, 446.16 examples/s]Tokenizing train dataset:  50%|█████     | 12157/24227 [00:50<00:23, 508.07 examples/s]Tokenizing train dataset:  50%|█████     | 12228/24227 [00:50<00:21, 562.91 examples/s]Tokenizing train dataset:  51%|█████     | 12315/24227 [00:50<00:21, 566.31 examples/s]Tokenizing train dataset:  51%|█████     | 12382/24227 [00:50<00:20, 590.03 examples/s]Tokenizing train dataset:  51%|█████▏    | 12475/24227 [00:50<00:19, 596.65 examples/s]Tokenizing train dataset:  52%|█████▏    | 12564/24227 [00:50<00:19, 588.86 examples/s]Tokenizing train dataset:  52%|█████▏    | 12636/24227 [00:51<00:21, 541.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 12712/24227 [00:51<00:23, 482.99 examples/s]Tokenizing train dataset:  53%|█████▎    | 12785/24227 [00:51<00:24, 472.73 examples/s]Tokenizing train dataset:  53%|█████▎    | 12859/24227 [00:51<00:24, 468.93 examples/s]Tokenizing train dataset:  53%|█████▎    | 12911/24227 [00:51<00:23, 477.11 examples/s]Tokenizing train dataset:  54%|█████▎    | 12979/24227 [00:51<00:24, 467.65 examples/s]Tokenizing train dataset:  54%|█████▍    | 13064/24227 [00:52<00:22, 495.59 examples/s]Tokenizing train dataset:  54%|█████▍    | 13126/24227 [00:52<00:26, 417.70 examples/s]Tokenizing train dataset:  54%|█████▍    | 13178/24227 [00:52<00:25, 437.59 examples/s]Tokenizing train dataset:  55%|█████▍    | 13232/24227 [00:52<00:24, 454.38 examples/s]Tokenizing train dataset:  55%|█████▍    | 13307/24227 [00:52<00:23, 465.60 examples/s]Tokenizing train dataset:  55%|█████▌    | 13380/24227 [00:52<00:23, 468.64 examples/s]Tokenizing train dataset:  56%|█████▌    | 13457/24227 [00:52<00:22, 479.88 examples/s]Tokenizing train dataset:  56%|█████▌    | 13532/24227 [00:53<00:22, 482.83 examples/s]Tokenizing train dataset:  56%|█████▌    | 13608/24227 [00:53<00:27, 390.27 examples/s]Tokenizing train dataset:  56%|█████▋    | 13669/24227 [00:53<00:24, 430.44 examples/s]Tokenizing train dataset:  57%|█████▋    | 13750/24227 [00:53<00:22, 458.45 examples/s]Tokenizing train dataset:  57%|█████▋    | 13820/24227 [00:53<00:20, 506.78 examples/s]Tokenizing train dataset:  57%|█████▋    | 13896/24227 [00:53<00:18, 564.15 examples/s]Tokenizing train dataset:  58%|█████▊    | 13960/24227 [00:54<00:22, 460.87 examples/s]Tokenizing train dataset:  58%|█████▊    | 14026/24227 [00:54<00:22, 453.37 examples/s]Tokenizing train dataset:  58%|█████▊    | 14078/24227 [00:54<00:21, 463.47 examples/s]Tokenizing train dataset:  58%|█████▊    | 14160/24227 [00:54<00:20, 486.35 examples/s]Tokenizing train dataset:  59%|█████▊    | 14220/24227 [00:54<00:19, 509.51 examples/s]Tokenizing train dataset:  59%|█████▉    | 14280/24227 [00:54<00:18, 529.63 examples/s]Tokenizing train dataset:  59%|█████▉    | 14344/24227 [00:54<00:17, 557.55 examples/s]Tokenizing train dataset:  60%|█████▉    | 14420/24227 [00:54<00:18, 536.11 examples/s]Tokenizing train dataset:  60%|█████▉    | 14505/24227 [00:55<00:17, 543.69 examples/s]Tokenizing train dataset:  60%|██████    | 14584/24227 [00:55<00:18, 533.93 examples/s]Tokenizing train dataset:  61%|██████    | 14661/24227 [00:55<00:21, 437.71 examples/s]Tokenizing train dataset:  61%|██████    | 14724/24227 [00:55<00:21, 432.59 examples/s]Tokenizing train dataset:  61%|██████    | 14782/24227 [00:55<00:23, 399.03 examples/s]Tokenizing train dataset:  61%|██████▏   | 14841/24227 [00:56<00:26, 356.78 examples/s]Tokenizing train dataset:  61%|██████▏   | 14897/24227 [00:56<00:26, 358.42 examples/s]Tokenizing train dataset:  62%|██████▏   | 14950/24227 [00:56<00:29, 319.44 examples/s]Tokenizing train dataset:  62%|██████▏   | 14999/24227 [00:56<00:28, 319.51 examples/s]Tokenizing train dataset:  62%|██████▏   | 15039/24227 [00:56<00:27, 333.67 examples/s]Tokenizing train dataset:  62%|██████▏   | 15077/24227 [00:56<00:34, 265.31 examples/s]Tokenizing train dataset:  62%|██████▏   | 15110/24227 [00:56<00:32, 276.75 examples/s]Tokenizing train dataset:  63%|██████▎   | 15150/24227 [00:57<00:41, 220.45 examples/s]Tokenizing train dataset:  63%|██████▎   | 15187/24227 [00:57<00:36, 247.54 examples/s]Tokenizing train dataset:  63%|██████▎   | 15221/24227 [00:57<00:44, 202.20 examples/s]Tokenizing train dataset:  63%|██████▎   | 15250/24227 [00:57<00:41, 216.49 examples/s]Tokenizing train dataset:  63%|██████▎   | 15290/24227 [00:57<00:39, 227.88 examples/s]Tokenizing train dataset:  63%|██████▎   | 15322/24227 [00:57<00:36, 245.66 examples/s]Tokenizing train dataset:  63%|██████▎   | 15354/24227 [00:58<00:34, 260.75 examples/s]Tokenizing train dataset:  64%|██████▎   | 15385/24227 [00:58<00:32, 271.87 examples/s]Tokenizing train dataset:  64%|██████▎   | 15422/24227 [00:58<00:34, 255.71 examples/s]Tokenizing train dataset:  64%|██████▍   | 15455/24227 [00:58<00:32, 272.88 examples/s]Tokenizing train dataset:  64%|██████▍   | 15498/24227 [00:58<00:31, 275.48 examples/s]Tokenizing train dataset:  64%|██████▍   | 15539/24227 [00:58<00:31, 272.22 examples/s]Tokenizing train dataset:  64%|██████▍   | 15572/24227 [00:58<00:30, 285.31 examples/s]Tokenizing train dataset:  64%|██████▍   | 15609/24227 [00:58<00:28, 302.75 examples/s]Tokenizing train dataset:  65%|██████▍   | 15641/24227 [00:59<00:28, 302.53 examples/s]Tokenizing train dataset:  65%|██████▍   | 15679/24227 [00:59<00:31, 274.58 examples/s]Tokenizing train dataset:  65%|██████▍   | 15726/24227 [00:59<00:29, 284.16 examples/s]Tokenizing train dataset:  65%|██████▌   | 15773/24227 [00:59<00:29, 290.15 examples/s]Tokenizing train dataset:  65%|██████▌   | 15811/24227 [00:59<00:32, 255.16 examples/s]Tokenizing train dataset:  65%|██████▌   | 15839/24227 [00:59<00:32, 258.93 examples/s]Tokenizing train dataset:  66%|██████▌   | 15872/24227 [00:59<00:30, 272.43 examples/s]Tokenizing train dataset:  66%|██████▌   | 15912/24227 [01:00<00:36, 229.15 examples/s]Tokenizing train dataset:  66%|██████▌   | 15939/24227 [01:00<00:34, 236.96 examples/s]Tokenizing train dataset:  66%|██████▌   | 15970/24227 [01:00<00:44, 183.75 examples/s]Tokenizing train dataset:  66%|██████▌   | 16002/24227 [01:00<00:39, 209.04 examples/s]Tokenizing train dataset:  66%|██████▌   | 16040/24227 [01:00<00:33, 243.40 examples/s]Tokenizing train dataset:  66%|██████▋   | 16086/24227 [01:00<00:31, 259.68 examples/s]Tokenizing train dataset:  67%|██████▋   | 16128/24227 [01:00<00:27, 291.84 examples/s]Tokenizing train dataset:  67%|██████▋   | 16174/24227 [01:01<00:27, 293.06 examples/s]Tokenizing train dataset:  67%|██████▋   | 16211/24227 [01:01<00:29, 267.25 examples/s]Tokenizing train dataset:  67%|██████▋   | 16240/24227 [01:01<00:29, 270.62 examples/s]Tokenizing train dataset:  67%|██████▋   | 16274/24227 [01:01<00:27, 286.45 examples/s]Tokenizing train dataset:  67%|██████▋   | 16321/24227 [01:01<00:27, 291.51 examples/s]Tokenizing train dataset:  67%|██████▋   | 16352/24227 [01:01<00:26, 292.54 examples/s]Tokenizing train dataset:  68%|██████▊   | 16383/24227 [01:01<00:33, 233.52 examples/s]Tokenizing train dataset:  68%|██████▊   | 16419/24227 [01:02<00:33, 234.34 examples/s]Tokenizing train dataset:  68%|██████▊   | 16451/24227 [01:02<00:30, 250.90 examples/s]Tokenizing train dataset:  68%|██████▊   | 16485/24227 [01:02<00:28, 270.79 examples/s]Tokenizing train dataset:  68%|██████▊   | 16546/24227 [01:02<00:21, 352.74 examples/s]Tokenizing train dataset:  69%|██████▊   | 16608/24227 [01:02<00:18, 421.59 examples/s]Tokenizing train dataset:  69%|██████▉   | 16659/24227 [01:02<00:17, 440.97 examples/s]Tokenizing train dataset:  69%|██████▉   | 16717/24227 [01:02<00:15, 477.64 examples/s]Tokenizing train dataset:  69%|██████▉   | 16768/24227 [01:02<00:15, 485.25 examples/s]Tokenizing train dataset:  69%|██████▉   | 16819/24227 [01:02<00:15, 487.94 examples/s]Tokenizing train dataset:  70%|██████▉   | 16873/24227 [01:03<00:14, 499.02 examples/s]Tokenizing train dataset:  70%|██████▉   | 16949/24227 [01:03<00:14, 497.12 examples/s]Tokenizing train dataset:  70%|███████   | 17034/24227 [01:03<00:13, 514.17 examples/s]Tokenizing train dataset:  71%|███████   | 17123/24227 [01:03<00:13, 536.13 examples/s]Tokenizing train dataset:  71%|███████   | 17210/24227 [01:03<00:12, 541.92 examples/s]Tokenizing train dataset:  71%|███████▏  | 17283/24227 [01:03<00:11, 583.27 examples/s]Tokenizing train dataset:  72%|███████▏  | 17355/24227 [01:04<00:15, 448.56 examples/s]Tokenizing train dataset:  72%|███████▏  | 17429/24227 [01:04<00:14, 459.24 examples/s]Tokenizing train dataset:  72%|███████▏  | 17481/24227 [01:04<00:14, 470.52 examples/s]Tokenizing train dataset:  72%|███████▏  | 17555/24227 [01:04<00:14, 475.12 examples/s]Tokenizing train dataset:  73%|███████▎  | 17630/24227 [01:04<00:13, 476.09 examples/s]Tokenizing train dataset:  73%|███████▎  | 17684/24227 [01:04<00:13, 486.04 examples/s]Tokenizing train dataset:  73%|███████▎  | 17761/24227 [01:04<00:13, 485.92 examples/s]Tokenizing train dataset:  74%|███████▎  | 17840/24227 [01:05<00:12, 493.25 examples/s]Tokenizing train dataset:  74%|███████▍  | 17920/24227 [01:05<00:12, 502.42 examples/s]Tokenizing train dataset:  74%|███████▍  | 17985/24227 [01:05<00:11, 534.80 examples/s]Tokenizing train dataset:  75%|███████▍  | 18060/24227 [01:05<00:12, 481.93 examples/s]Tokenizing train dataset:  75%|███████▍  | 18141/24227 [01:05<00:12, 492.30 examples/s]Tokenizing train dataset:  75%|███████▌  | 18200/24227 [01:05<00:11, 512.79 examples/s]Tokenizing train dataset:  75%|███████▌  | 18253/24227 [01:05<00:11, 512.26 examples/s]Tokenizing train dataset:  76%|███████▌  | 18324/24227 [01:05<00:10, 559.47 examples/s]Tokenizing train dataset:  76%|███████▌  | 18396/24227 [01:06<00:11, 513.55 examples/s]Tokenizing train dataset:  76%|███████▌  | 18457/24227 [01:06<00:10, 536.51 examples/s]Tokenizing train dataset:  76%|███████▋  | 18515/24227 [01:06<00:10, 547.12 examples/s]Tokenizing train dataset:  77%|███████▋  | 18599/24227 [01:06<00:10, 546.65 examples/s]Tokenizing train dataset:  77%|███████▋  | 18680/24227 [01:06<00:11, 502.41 examples/s]Tokenizing train dataset:  77%|███████▋  | 18738/24227 [01:06<00:10, 517.59 examples/s]Tokenizing train dataset:  78%|███████▊  | 18799/24227 [01:06<00:10, 538.69 examples/s]Tokenizing train dataset:  78%|███████▊  | 18881/24227 [01:07<00:10, 523.88 examples/s]Tokenizing train dataset:  78%|███████▊  | 18950/24227 [01:07<00:10, 482.33 examples/s]Tokenizing train dataset:  78%|███████▊  | 19003/24227 [01:07<00:10, 492.02 examples/s]Tokenizing train dataset:  79%|███████▉  | 19087/24227 [01:07<00:10, 509.73 examples/s]Tokenizing train dataset:  79%|███████▉  | 19162/24227 [01:07<00:12, 396.12 examples/s]Tokenizing train dataset:  79%|███████▉  | 19244/24227 [01:07<00:12, 398.47 examples/s]Tokenizing train dataset:  80%|███████▉  | 19309/24227 [01:08<00:12, 386.11 examples/s]Tokenizing train dataset:  80%|███████▉  | 19366/24227 [01:08<00:12, 382.45 examples/s]Tokenizing train dataset:  80%|████████  | 19419/24227 [01:08<00:11, 409.23 examples/s]Tokenizing train dataset:  81%|████████  | 19510/24227 [01:08<00:09, 517.20 examples/s]Tokenizing train dataset:  81%|████████  | 19611/24227 [01:08<00:07, 633.08 examples/s]Tokenizing train dataset:  81%|████████▏ | 19737/24227 [01:08<00:06, 693.15 examples/s]Tokenizing train dataset:  82%|████████▏ | 19840/24227 [01:08<00:05, 769.18 examples/s]Tokenizing train dataset:  82%|████████▏ | 19947/24227 [01:08<00:05, 844.14 examples/s]Tokenizing train dataset:  83%|████████▎ | 20059/24227 [01:09<00:04, 914.63 examples/s]Tokenizing train dataset:  83%|████████▎ | 20185/24227 [01:09<00:05, 769.82 examples/s]Tokenizing train dataset:  84%|████████▎ | 20285/24227 [01:09<00:04, 822.14 examples/s]Tokenizing train dataset:  84%|████████▍ | 20406/24227 [01:09<00:04, 788.51 examples/s]Tokenizing train dataset:  85%|████████▍ | 20495/24227 [01:09<00:04, 810.47 examples/s]Tokenizing train dataset:  85%|████████▌ | 20609/24227 [01:09<00:04, 757.12 examples/s]Tokenizing train dataset:  86%|████████▌ | 20732/24227 [01:09<00:04, 720.75 examples/s]Tokenizing train dataset:  86%|████████▌ | 20839/24227 [01:10<00:04, 795.25 examples/s]Tokenizing train dataset:  87%|████████▋ | 20970/24227 [01:10<00:03, 817.97 examples/s]Tokenizing train dataset:  87%|████████▋ | 21068/24227 [01:10<00:03, 853.93 examples/s]Tokenizing train dataset:  87%|████████▋ | 21187/24227 [01:10<00:03, 827.55 examples/s]Tokenizing train dataset:  88%|████████▊ | 21322/24227 [01:10<00:03, 849.80 examples/s]Tokenizing train dataset:  89%|████████▊ | 21464/24227 [01:10<00:03, 877.95 examples/s]Tokenizing train dataset:  89%|████████▉ | 21584/24227 [01:10<00:03, 798.32 examples/s]Tokenizing train dataset:  90%|████████▉ | 21709/24227 [01:11<00:03, 804.96 examples/s]Tokenizing train dataset:  90%|█████████ | 21810/24227 [01:11<00:02, 846.56 examples/s]Tokenizing train dataset:  90%|█████████ | 21919/24227 [01:11<00:02, 903.36 examples/s]Tokenizing train dataset:  91%|█████████ | 22022/24227 [01:11<00:02, 933.47 examples/s]Tokenizing train dataset:  91%|█████████▏| 22122/24227 [01:11<00:02, 948.96 examples/s]Tokenizing train dataset:  92%|█████████▏| 22223/24227 [01:11<00:02, 964.06 examples/s]Tokenizing train dataset:  92%|█████████▏| 22338/24227 [01:11<00:02, 825.77 examples/s]Tokenizing train dataset:  93%|█████████▎| 22428/24227 [01:11<00:02, 842.98 examples/s]Tokenizing train dataset:  93%|█████████▎| 22530/24227 [01:11<00:01, 887.01 examples/s]Tokenizing train dataset:  93%|█████████▎| 22652/24227 [01:12<00:01, 802.93 examples/s]Tokenizing train dataset:  94%|█████████▍| 22765/24227 [01:12<00:01, 878.37 examples/s]Tokenizing train dataset:  94%|█████████▍| 22863/24227 [01:12<00:01, 900.38 examples/s]Tokenizing train dataset:  95%|█████████▍| 22985/24227 [01:12<00:01, 805.75 examples/s]Tokenizing train dataset:  95%|█████████▌| 23110/24227 [01:12<00:01, 697.17 examples/s]Tokenizing train dataset:  96%|█████████▌| 23230/24227 [01:13<00:01, 581.93 examples/s]Tokenizing train dataset:  96%|█████████▌| 23311/24227 [01:13<00:01, 621.57 examples/s]Tokenizing train dataset:  97%|█████████▋| 23417/24227 [01:13<00:01, 707.97 examples/s]Tokenizing train dataset:  97%|█████████▋| 23507/24227 [01:13<00:00, 749.38 examples/s]Tokenizing train dataset:  98%|█████████▊| 23626/24227 [01:13<00:00, 729.62 examples/s]Tokenizing train dataset:  98%|█████████▊| 23741/24227 [01:13<00:00, 725.33 examples/s]Tokenizing train dataset:  98%|█████████▊| 23863/24227 [01:13<00:00, 745.06 examples/s]Tokenizing train dataset:  99%|█████████▉| 23971/24227 [01:13<00:00, 817.98 examples/s]Tokenizing train dataset:  99%|█████████▉| 24102/24227 [01:14<00:00, 833.97 examples/s]Tokenizing train dataset: 100%|█████████▉| 24226/24227 [01:14<00:00, 806.68 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:14<00:00, 325.85 examples/s]
[rank0]:[W612 10:26:28.051361863 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 520/24227 [00:00<00:04, 5123.02 examples/s]Extracting prompt in train dataset:   2%|▏         | 530/24227 [00:00<00:04, 5208.58 examples/s]Extracting prompt in train dataset:   2%|▏         | 510/24227 [00:00<00:04, 5001.95 examples/s]Extracting prompt in eval dataset:  56%|█████▌    | 530/953 [00:00<00:00, 5219.10 examples/s]Extracting prompt in train dataset:   5%|▍         | 1160/24227 [00:00<00:05, 4495.32 examples/s]Extracting prompt in train dataset:   4%|▍         | 1080/24227 [00:00<00:07, 3261.18 examples/s]Extracting prompt in train dataset:   4%|▍         | 1055/24227 [00:00<00:10, 2214.49 examples/s]Extracting prompt in train dataset:   7%|▋         | 1700/24227 [00:00<00:07, 2908.26 examples/s]Extracting prompt in train dataset:   7%|▋         | 1625/24227 [00:00<00:08, 2823.98 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1564.87 examples/s]
Extracting prompt in train dataset:   7%|▋         | 1590/24227 [00:00<00:10, 2067.75 examples/s]Extracting prompt in train dataset:   9%|▉         | 2260/24227 [00:00<00:08, 2742.69 examples/s]Extracting prompt in train dataset:   9%|▉         | 2191/24227 [00:00<00:07, 2774.82 examples/s]Extracting prompt in train dataset:   8%|▊         | 1890/24227 [00:00<00:09, 2250.67 examples/s]Extracting prompt in train dataset:  12%|█▏        | 2810/24227 [00:00<00:08, 2604.18 examples/s]Extracting prompt in train dataset:  11%|█▏        | 2758/24227 [00:01<00:08, 2546.24 examples/s]Extracting prompt in train dataset:   9%|▉         | 2170/24227 [00:00<00:10, 2134.99 examples/s]Extracting prompt in train dataset:  13%|█▎        | 3206/24227 [00:01<00:07, 2866.05 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  13%|█▎        | 3162/24227 [00:01<00:07, 2824.72 examples/s]Extracting prompt in train dataset:  10%|█         | 2450/24227 [00:01<00:10, 2078.77 examples/s]Extracting prompt in train dataset:  16%|█▌        | 3764/24227 [00:01<00:06, 2956.50 examples/s]Applying chat template to eval dataset:  32%|███▏      | 303/953 [00:00<00:00, 2994.53 examples/s]Extracting prompt in train dataset:  15%|█▌        | 3726/24227 [00:01<00:10, 2046.50 examples/s]Extracting prompt in train dataset:  11%|█▏        | 2730/24227 [00:01<00:17, 1262.75 examples/s]Extracting prompt in train dataset:  18%|█▊        | 4323/24227 [00:01<00:09, 2075.19 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4010/24227 [00:01<00:11, 1799.85 examples/s]Extracting prompt in train dataset:  12%|█▏        | 2980/24227 [00:01<00:16, 1271.89 examples/s]Applying chat template to eval dataset:  65%|██████▌   | 620/953 [00:00<00:00, 1387.91 examples/s]Extracting prompt in train dataset:  19%|█▉        | 4600/24227 [00:01<00:11, 1689.41 examples/s]Extracting prompt in train dataset:  18%|█▊        | 4292/24227 [00:02<00:14, 1338.83 examples/s]Extracting prompt in train dataset:  13%|█▎        | 3260/24227 [00:02<00:24, 861.11 examples/s] Applying chat template to eval dataset:  99%|█████████▊| 939/953 [00:01<00:00, 645.96 examples/s] Extracting prompt in train dataset:  20%|██        | 4879/24227 [00:02<00:18, 1019.07 examples/s]Extracting prompt in train dataset:  19%|█▉        | 4574/24227 [00:02<00:19, 985.57 examples/s] Extracting prompt in train dataset:  15%|█▍        | 3534/24227 [00:02<00:25, 808.60 examples/s]Extracting prompt in train dataset:  21%|██▏       | 5160/24227 [00:02<00:19, 997.80 examples/s] Applying chat template to eval dataset: 100%|██████████| 953/953 [00:01<00:00, 595.32 examples/s]Extracting prompt in train dataset:  20%|██        | 4856/24227 [00:03<00:20, 930.56 examples/s]Extracting prompt in train dataset:  16%|█▌        | 3810/24227 [00:03<00:26, 773.10 examples/s]
Extracting prompt in train dataset:  22%|██▏       | 5440/24227 [00:03<00:17, 1045.75 examples/s]Extracting prompt in train dataset:  21%|██        | 5140/24227 [00:03<00:18, 1050.95 examples/s]Extracting prompt in train dataset:  17%|█▋        | 4180/24227 [00:03<00:18, 1083.66 examples/s]Extracting prompt in train dataset:  23%|██▎       | 5640/24227 [00:03<00:19, 976.03 examples/s] Extracting prompt in train dataset:  22%|██▏       | 5422/24227 [00:03<00:18, 993.02 examples/s] Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  18%|█▊        | 4460/24227 [00:03<00:22, 862.38 examples/s] Extracting prompt in train dataset:  24%|██▍       | 5920/24227 [00:03<00:19, 925.83 examples/s]Extracting prompt in train dataset:  23%|██▎       | 5621/24227 [00:03<00:21, 875.18 examples/s]Extracting prompt in train dataset:  20%|█▉        | 4740/24227 [00:03<00:19, 977.25 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 321.16 examples/s]Extracting prompt in train dataset:  26%|██▌       | 6203/24227 [00:04<00:18, 966.53 examples/s]Extracting prompt in train dataset:  24%|██▍       | 5903/24227 [00:04<00:21, 868.38 examples/s]Extracting prompt in train dataset:  21%|██        | 5020/24227 [00:04<00:20, 953.87 examples/s]Extracting prompt in train dataset:  27%|██▋       | 6485/24227 [00:04<00:17, 1039.85 examples/s]Extracting prompt in train dataset:  26%|██▌       | 6190/24227 [00:04<00:16, 1077.03 examples/s]Extracting prompt in train dataset:  22%|██▏       | 5300/24227 [00:04<00:16, 1157.28 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6770/24227 [00:04<00:13, 1271.26 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:06, 138.68 examples/s]Extracting prompt in train dataset:  27%|██▋       | 6480/24227 [00:04<00:16, 1106.00 examples/s]Extracting prompt in train dataset:  23%|██▎       | 5540/24227 [00:04<00:18, 1033.85 examples/s]Extracting prompt in train dataset:  29%|██▉       | 7051/24227 [00:04<00:15, 1131.87 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:08, 103.67 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6767/24227 [00:04<00:15, 1133.11 examples/s]Extracting prompt in train dataset:  24%|██▍       | 5820/24227 [00:04<00:16, 1097.30 examples/s]Extracting prompt in train dataset:  30%|███       | 7336/24227 [00:04<00:15, 1110.46 examples/s]Tokenizing eval dataset:  14%|█▍        | 137/953 [00:01<00:07, 105.02 examples/s]Extracting prompt in train dataset:  29%|██▉       | 7051/24227 [00:05<00:17, 972.76 examples/s] Extracting prompt in train dataset:  25%|██▌       | 6100/24227 [00:05<00:18, 958.48 examples/s] Extracting prompt in train dataset:  31%|███▏      | 7620/24227 [00:05<00:15, 1055.62 examples/s]Extracting prompt in train dataset:  30%|███       | 7340/24227 [00:05<00:14, 1171.68 examples/s]Tokenizing eval dataset:  16%|█▌        | 150/953 [00:01<00:09, 84.24 examples/s] Extracting prompt in train dataset:  27%|██▋       | 6491/24227 [00:05<00:13, 1339.32 examples/s]Extracting prompt in train dataset:  33%|███▎      | 7990/24227 [00:05<00:11, 1417.23 examples/s]Extracting prompt in train dataset:  31%|███▏      | 7628/24227 [00:05<00:12, 1354.46 examples/s]Tokenizing eval dataset:  17%|█▋        | 165/953 [00:01<00:09, 79.94 examples/s]Extracting prompt in train dataset:  28%|██▊       | 6772/24227 [00:05<00:13, 1333.54 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8282/24227 [00:05<00:12, 1276.74 examples/s]Extracting prompt in train dataset:  33%|███▎      | 7911/24227 [00:05<00:13, 1232.70 examples/s]Tokenizing eval dataset:  19%|█▊        | 177/953 [00:01<00:11, 68.80 examples/s]Extracting prompt in train dataset:  29%|██▉       | 7050/24227 [00:05<00:13, 1244.95 examples/s]Extracting prompt in train dataset:  35%|███▌      | 8573/24227 [00:05<00:11, 1347.26 examples/s]Extracting prompt in train dataset:  34%|███▍      | 8204/24227 [00:05<00:11, 1409.78 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:02<00:10, 74.88 examples/s]Extracting prompt in train dataset:  30%|███       | 7330/24227 [00:05<00:12, 1367.92 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8864/24227 [00:05<00:10, 1424.81 examples/s]Extracting prompt in train dataset:  35%|███▌      | 8499/24227 [00:06<00:10, 1515.77 examples/s]Tokenizing eval dataset:  22%|██▏       | 207/953 [00:02<00:08, 88.61 examples/s]Extracting prompt in train dataset:  32%|███▏      | 7642/24227 [00:06<00:09, 1662.13 examples/s]Extracting prompt in train dataset:  38%|███▊      | 9241/24227 [00:06<00:08, 1823.16 examples/s]Extracting prompt in train dataset:  37%|███▋      | 8914/24227 [00:06<00:07, 1995.34 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:02<00:05, 123.78 examples/s]Extracting prompt in train dataset:  34%|███▎      | 8130/24227 [00:06<00:07, 2279.75 examples/s]Extracting prompt in train dataset:  40%|███▉      | 9602/24227 [00:06<00:06, 2172.33 examples/s]Extracting prompt in train dataset:  38%|███▊      | 9207/24227 [00:06<00:09, 1520.56 examples/s]Tokenizing eval dataset:  28%|██▊       | 266/953 [00:02<00:07, 96.53 examples/s] Extracting prompt in train dataset:  36%|███▌      | 8710/24227 [00:06<00:09, 1594.34 examples/s]Extracting prompt in train dataset:  41%|████      | 9894/24227 [00:06<00:11, 1208.21 examples/s]Extracting prompt in train dataset:  39%|███▉      | 9500/24227 [00:06<00:12, 1208.25 examples/s]Tokenizing eval dataset:  32%|███▏      | 302/953 [00:03<00:05, 108.75 examples/s]Extracting prompt in train dataset:  37%|███▋      | 9005/24227 [00:06<00:10, 1478.95 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10184/24227 [00:07<00:12, 1118.96 examples/s]Extracting prompt in train dataset:  40%|████      | 9790/24227 [00:07<00:12, 1137.79 examples/s]Tokenizing eval dataset:  35%|███▌      | 336/953 [00:03<00:05, 113.45 examples/s]Extracting prompt in train dataset:  38%|███▊      | 9290/24227 [00:07<00:09, 1494.70 examples/s]Extracting prompt in train dataset:  43%|████▎     | 10464/24227 [00:07<00:11, 1233.92 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10080/24227 [00:07<00:11, 1198.38 examples/s]Tokenizing eval dataset:  38%|███▊      | 363/953 [00:03<00:05, 116.51 examples/s]Extracting prompt in train dataset:  40%|███▉      | 9580/24227 [00:07<00:11, 1288.80 examples/s]Extracting prompt in train dataset:  44%|████▍     | 10743/24227 [00:07<00:11, 1153.01 examples/s]Extracting prompt in train dataset:  43%|████▎     | 10370/24227 [00:07<00:11, 1214.02 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:03<00:04, 124.09 examples/s]Extracting prompt in train dataset:  41%|████      | 9870/24227 [00:07<00:09, 1448.61 examples/s]Extracting prompt in train dataset:  46%|████▌     | 11060/24227 [00:07<00:09, 1440.11 examples/s]Extracting prompt in train dataset:  44%|████▍     | 10658/24227 [00:07<00:10, 1268.32 examples/s]Tokenizing eval dataset:  45%|████▌     | 433/953 [00:03<00:04, 129.54 examples/s]Extracting prompt in train dataset:  42%|████▏     | 10160/24227 [00:07<00:10, 1310.11 examples/s]Extracting prompt in train dataset:  47%|████▋     | 11340/24227 [00:07<00:10, 1206.25 examples/s]Extracting prompt in train dataset:  45%|████▌     | 10940/24227 [00:07<00:10, 1286.96 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:04<00:03, 150.24 examples/s]Extracting prompt in train dataset:  43%|████▎     | 10440/24227 [00:07<00:09, 1381.19 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11620/24227 [00:08<00:09, 1312.44 examples/s]Extracting prompt in train dataset:  46%|████▋     | 11229/24227 [00:08<00:09, 1435.45 examples/s]Tokenizing eval dataset:  53%|█████▎    | 503/953 [00:04<00:02, 172.05 examples/s]Extracting prompt in train dataset:  44%|████▍     | 10721/24227 [00:08<00:09, 1486.03 examples/s]Extracting prompt in train dataset:  49%|████▉     | 11907/24227 [00:08<00:08, 1537.46 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11519/24227 [00:08<00:07, 1666.74 examples/s]Tokenizing eval dataset:  56%|█████▌    | 533/953 [00:04<00:02, 186.92 examples/s]Extracting prompt in train dataset:  46%|████▌     | 11139/24227 [00:08<00:06, 1962.82 examples/s]Extracting prompt in train dataset:  51%|█████     | 12383/24227 [00:08<00:05, 2134.72 examples/s]Extracting prompt in train dataset:  50%|████▉     | 12033/24227 [00:08<00:05, 2352.67 examples/s]Tokenizing eval dataset:  60%|█████▉    | 568/953 [00:04<00:01, 209.81 examples/s]Extracting prompt in train dataset:  47%|████▋     | 11420/24227 [00:08<00:06, 1845.97 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 12673/24227 [00:08<00:05, 1954.15 examples/s]Extracting prompt in train dataset:  51%|█████     | 12330/24227 [00:08<00:06, 1889.44 examples/s]Tokenizing eval dataset:  64%|██████▎   | 607/953 [00:04<00:01, 204.16 examples/s]Extracting prompt in train dataset:  48%|████▊     | 11700/24227 [00:08<00:06, 1795.53 examples/s]Extracting prompt in train dataset:  54%|█████▎    | 12966/24227 [00:08<00:05, 1956.06 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 12620/24227 [00:08<00:05, 1994.78 examples/s]Extracting prompt in train dataset:  49%|████▉     | 11987/24227 [00:08<00:07, 1715.14 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 13254/24227 [00:08<00:06, 1825.26 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:04<00:01, 179.89 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12914/24227 [00:08<00:05, 2031.30 examples/s]Extracting prompt in train dataset:  51%|█████     | 12279/24227 [00:08<00:06, 1912.80 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 13550/24227 [00:08<00:05, 1912.09 examples/s]Tokenizing eval dataset:  70%|███████   | 669/953 [00:05<00:01, 184.25 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 13206/24227 [00:08<00:05, 2041.18 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 12660/24227 [00:08<00:04, 2320.19 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13930/24227 [00:09<00:04, 2307.50 examples/s]Tokenizing eval dataset:  73%|███████▎  | 700/953 [00:05<00:01, 175.95 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 13499/24227 [00:09<00:05, 1831.50 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 12951/24227 [00:09<00:05, 2034.76 examples/s]Extracting prompt in train dataset:  59%|█████▊    | 14229/24227 [00:09<00:04, 2008.68 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:05<00:01, 194.72 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 13800/24227 [00:09<00:05, 1897.42 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 13240/24227 [00:09<00:05, 2083.51 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 14520/24227 [00:09<00:04, 2177.30 examples/s]Tokenizing eval dataset:  79%|███████▉  | 756/953 [00:05<00:01, 195.04 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 14140/24227 [00:09<00:04, 2208.39 examples/s]Extracting prompt in train dataset:  56%|█████▋    | 13660/24227 [00:09<00:04, 2552.78 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 14970/24227 [00:09<00:03, 2703.10 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:05<00:00, 216.04 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 14434/24227 [00:09<00:04, 2358.39 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 14041/24227 [00:09<00:03, 2857.96 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 15450/24227 [00:09<00:03, 2857.42 examples/s]Tokenizing eval dataset:  87%|████████▋ | 829/953 [00:05<00:00, 264.09 examples/s]Extracting prompt in train dataset:  61%|██████▏   | 14890/24227 [00:09<00:03, 2900.59 examples/s]Extracting prompt in train dataset:  60%|██████    | 14560/24227 [00:09<00:02, 3445.26 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 16026/24227 [00:09<00:02, 3084.55 examples/s]Tokenizing eval dataset:  92%|█████████▏| 880/953 [00:06<00:00, 213.10 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 15378/24227 [00:10<00:04, 1785.35 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:06<00:00, 193.72 examples/s]Extracting prompt in train dataset:  69%|██████▊   | 16600/24227 [00:10<00:03, 2320.11 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 15090/24227 [00:10<00:04, 1903.75 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 15664/24227 [00:10<00:04, 1724.11 examples/s]Tokenizing eval dataset:  98%|█████████▊| 936/953 [00:06<00:00, 150.79 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 16890/24227 [00:10<00:04, 1744.45 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 15950/24227 [00:10<00:05, 1515.45 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:06<00:00, 142.53 examples/s]
Extracting prompt in train dataset:  65%|██████▍   | 15652/24227 [00:10<00:05, 1694.98 examples/s]Extracting prompt in train dataset:  71%|███████▏  | 17280/24227 [00:10<00:03, 2064.06 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 16437/24227 [00:10<00:03, 2052.68 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 16003/24227 [00:10<00:04, 1932.56 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17575/24227 [00:10<00:03, 2208.68 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 16933/24227 [00:10<00:02, 2592.89 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 16350/24227 [00:10<00:03, 2174.38 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 17912/24227 [00:10<00:02, 2440.20 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 17526/24227 [00:10<00:02, 2748.76 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 18209/24227 [00:11<00:03, 1888.03 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 16920/24227 [00:10<00:03, 2098.98 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 18115/24227 [00:11<00:02, 2955.55 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 18502/24227 [00:11<00:02, 2057.64 examples/s]Extracting prompt in train dataset:  71%|███████   | 17210/24227 [00:11<00:03, 2164.80 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 18953/24227 [00:11<00:02, 2573.80 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18724/24227 [00:11<00:01, 3248.47 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 17660/24227 [00:11<00:02, 2595.36 examples/s]Extracting prompt in train dataset:  81%|████████  | 19543/24227 [00:11<00:01, 2768.70 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 19310/24227 [00:11<00:01, 3051.54 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 18240/24227 [00:11<00:02, 2582.81 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 20040/24227 [00:11<00:01, 3228.95 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19860/24227 [00:11<00:01, 3513.05 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 18771/24227 [00:11<00:01, 3103.22 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 20640/24227 [00:11<00:01, 3407.76 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 20460/24227 [00:11<00:01, 3636.96 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 19350/24227 [00:11<00:01, 3158.71 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 21280/24227 [00:11<00:00, 3656.47 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 21060/24227 [00:11<00:00, 3347.61 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 19940/24227 [00:11<00:01, 2852.69 examples/s]Extracting prompt in train dataset:  89%|████████▊ | 21486/24227 [00:11<00:00, 3528.76 examples/s]Extracting prompt in train dataset:  90%|█████████ | 21880/24227 [00:12<00:00, 3515.73 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 20529/24227 [00:12<00:01, 2966.23 examples/s]Extracting prompt in train dataset:  91%|█████████ | 22080/24227 [00:12<00:00, 3420.40 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 20854/24227 [00:12<00:01, 3018.94 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 22480/24227 [00:12<00:00, 3533.99 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 22480/24227 [00:12<00:00, 2838.22 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 21295/24227 [00:12<00:00, 3310.65 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 22950/24227 [00:12<00:00, 3791.32 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 23000/24227 [00:12<00:00, 3251.98 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 21673/24227 [00:12<00:00, 3417.85 examples/s]Extracting prompt in train dataset:  96%|█████████▋| 23350/24227 [00:12<00:00, 3833.64 examples/s]Extracting prompt in train dataset:  91%|█████████▏| 22140/24227 [00:12<00:00, 3720.56 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 23600/24227 [00:12<00:00, 3333.40 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 23800/24227 [00:12<00:00, 4000.60 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 22734/24227 [00:12<00:00, 3557.10 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:12<00:00, 3461.09 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 24200/24227 [00:12<00:00, 3284.07 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:12<00:00, 1891.82 examples/s]
Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:12<00:00, 1885.10 examples/s]
Extracting prompt in train dataset:  96%|█████████▌| 23260/24227 [00:12<00:00, 3951.65 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 23860/24227 [00:12<00:00, 3919.36 examples/s]Extracting prompt in train dataset: 100%|██████████| 24227/24227 [00:13<00:00, 1850.91 examples/s]
Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 291/24227 [00:00<00:08, 2878.67 examples/s]Applying chat template to train dataset:   1%|          | 287/24227 [00:00<00:08, 2844.04 examples/s]Applying chat template to train dataset:   3%|▎         | 713/24227 [00:00<00:08, 2827.57 examples/s]Applying chat template to train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 669/24227 [00:00<00:08, 2634.27 examples/s]Applying chat template to train dataset:   5%|▍         | 1096/24227 [00:00<00:08, 2689.36 examples/s]Applying chat template to train dataset:   1%|          | 286/24227 [00:00<00:08, 2834.32 examples/s]Applying chat template to train dataset:   4%|▍         | 981/24227 [00:00<00:12, 1841.09 examples/s]Applying chat template to train dataset:   6%|▌         | 1417/24227 [00:00<00:09, 2347.97 examples/s]Applying chat template to train dataset:   5%|▌         | 1244/24227 [00:00<00:11, 2051.06 examples/s]Applying chat template to train dataset:   2%|▏         | 598/24227 [00:00<00:10, 2190.47 examples/s]Applying chat template to train dataset:   7%|▋         | 1703/24227 [00:00<00:09, 2486.58 examples/s]Applying chat template to train dataset:   6%|▋         | 1556/24227 [00:00<00:11, 1974.82 examples/s]Applying chat template to train dataset:   4%|▍         | 910/24227 [00:00<00:11, 2003.65 examples/s]Applying chat template to train dataset:   7%|▋         | 1788/24227 [00:00<00:10, 2059.15 examples/s]Applying chat template to train dataset:   8%|▊         | 2024/24227 [00:00<00:11, 1972.02 examples/s]Applying chat template to train dataset:   5%|▌         | 1258/24227 [00:00<00:10, 2121.56 examples/s]Applying chat template to train dataset:   9%|▉         | 2155/24227 [00:01<00:10, 2192.03 examples/s]Applying chat template to train dataset:  10%|▉         | 2384/24227 [00:01<00:10, 2100.78 examples/s]Applying chat template to train dataset:   6%|▋         | 1546/24227 [00:00<00:09, 2325.46 examples/s]Applying chat template to train dataset:  10%|█         | 2471/24227 [00:01<00:11, 1917.43 examples/s]Applying chat template to train dataset:  11%|█         | 2706/24227 [00:01<00:13, 1565.30 examples/s]Applying chat template to train dataset:   8%|▊         | 1862/24227 [00:01<00:15, 1484.40 examples/s]Applying chat template to train dataset:  12%|█▏        | 2789/24227 [00:01<00:12, 1718.32 examples/s]Applying chat template to train dataset:   9%|▊         | 2118/24227 [00:01<00:13, 1684.93 examples/s]Applying chat template to train dataset:  12%|█▏        | 3007/24227 [00:01<00:12, 1671.57 examples/s]Applying chat template to train dataset:  10%|▉         | 2340/24227 [00:01<00:12, 1797.17 examples/s]Applying chat template to train dataset:  13%|█▎        | 3257/24227 [00:01<00:11, 1826.70 examples/s]Applying chat template to train dataset:  13%|█▎        | 3129/24227 [00:01<00:11, 1862.44 examples/s]Applying chat template to train dataset:  11%|█         | 2655/24227 [00:01<00:12, 1763.36 examples/s]Applying chat template to train dataset:  15%|█▍        | 3584/24227 [00:01<00:11, 1763.43 examples/s]Applying chat template to train dataset:  14%|█▍        | 3447/24227 [00:01<00:12, 1697.46 examples/s]Applying chat template to train dataset:  12%|█▏        | 2894/24227 [00:01<00:11, 1898.40 examples/s]Applying chat template to train dataset:  16%|█▌        | 3801/24227 [00:01<00:11, 1844.58 examples/s]Applying chat template to train dataset:  15%|█▌        | 3712/24227 [00:01<00:10, 1874.22 examples/s]Applying chat template to train dataset:  13%|█▎        | 3158/24227 [00:01<00:10, 2071.96 examples/s]Applying chat template to train dataset:  17%|█▋        | 4107/24227 [00:02<00:09, 2114.14 examples/s]Applying chat template to train dataset:  14%|█▍        | 3421/24227 [00:01<00:09, 2211.20 examples/s]Applying chat template to train dataset:  17%|█▋        | 4032/24227 [00:02<00:10, 1947.13 examples/s]Applying chat template to train dataset:  18%|█▊        | 4361/24227 [00:02<00:08, 2214.69 examples/s]Applying chat template to train dataset:  15%|█▌        | 3718/24227 [00:01<00:08, 2409.99 examples/s]Applying chat template to train dataset:  18%|█▊        | 4254/24227 [00:02<00:09, 2004.82 examples/s]Applying chat template to train dataset:  19%|█▉        | 4640/24227 [00:02<00:08, 2358.36 examples/s]Applying chat template to train dataset:  16%|█▋        | 3990/24227 [00:01<00:08, 2490.12 examples/s]Applying chat template to train dataset:  19%|█▊        | 4502/24227 [00:02<00:09, 2114.78 examples/s]Applying chat template to train dataset:  20%|██        | 4938/24227 [00:02<00:07, 2521.70 examples/s]Applying chat template to train dataset:  18%|█▊        | 4268/24227 [00:02<00:07, 2566.00 examples/s]Applying chat template to train dataset:  20%|██        | 4874/24227 [00:02<00:08, 2235.27 examples/s]Applying chat template to train dataset:  22%|██▏       | 5270/24227 [00:02<00:07, 2403.84 examples/s]Applying chat template to train dataset:  19%|█▉        | 4683/24227 [00:02<00:07, 2639.69 examples/s]Applying chat template to train dataset:  21%|██▏       | 5197/24227 [00:02<00:08, 2192.70 examples/s]Applying chat template to train dataset:  23%|██▎       | 5551/24227 [00:02<00:08, 2214.51 examples/s]Applying chat template to train dataset:  21%|██        | 4997/24227 [00:02<00:08, 2139.14 examples/s]Applying chat template to train dataset:  23%|██▎       | 5519/24227 [00:02<00:11, 1628.22 examples/s]Applying chat template to train dataset:  24%|██▍       | 5873/24227 [00:02<00:11, 1598.28 examples/s]Applying chat template to train dataset:  22%|██▏       | 5309/24227 [00:02<00:09, 1965.87 examples/s]Applying chat template to train dataset:  24%|██▎       | 5733/24227 [00:02<00:10, 1720.79 examples/s]Applying chat template to train dataset:  26%|██▌       | 6219/24227 [00:03<00:10, 1777.48 examples/s]Applying chat template to train dataset:  23%|██▎       | 5579/24227 [00:02<00:09, 1883.97 examples/s]Applying chat template to train dataset:  25%|██▍       | 6055/24227 [00:03<00:11, 1563.25 examples/s]Applying chat template to train dataset:  27%|██▋       | 6550/24227 [00:03<00:11, 1515.25 examples/s]Applying chat template to train dataset:  24%|██▍       | 5896/24227 [00:03<00:13, 1362.07 examples/s]Applying chat template to train dataset:  26%|██▋       | 6384/24227 [00:03<00:12, 1423.99 examples/s]Applying chat template to train dataset:  25%|██▌       | 6085/24227 [00:03<00:12, 1445.89 examples/s]Applying chat template to train dataset:  28%|██▊       | 6880/24227 [00:03<00:11, 1548.46 examples/s]Applying chat template to train dataset:  27%|██▋       | 6544/24227 [00:03<00:12, 1414.18 examples/s]Applying chat template to train dataset:  26%|██▋       | 6401/24227 [00:03<00:11, 1510.49 examples/s]Applying chat template to train dataset:  28%|██▊       | 6706/24227 [00:03<00:12, 1391.82 examples/s]Applying chat template to train dataset:  30%|██▉       | 7203/24227 [00:03<00:11, 1545.85 examples/s]Applying chat template to train dataset:  27%|██▋       | 6660/24227 [00:03<00:10, 1709.99 examples/s]Applying chat template to train dataset:  28%|██▊       | 6870/24227 [00:03<00:12, 1440.29 examples/s]Applying chat template to train dataset:  31%|███       | 7530/24227 [00:03<00:10, 1641.68 examples/s]Applying chat template to train dataset:  29%|██▊       | 6946/24227 [00:03<00:08, 1949.17 examples/s]Applying chat template to train dataset:  29%|██▉       | 7044/24227 [00:03<00:11, 1507.87 examples/s]Applying chat template to train dataset:  32%|███▏      | 7819/24227 [00:04<00:08, 1863.27 examples/s]Applying chat template to train dataset:  30%|██▉       | 7230/24227 [00:03<00:07, 2152.50 examples/s]Applying chat template to train dataset:  30%|███       | 7328/24227 [00:04<00:09, 1831.64 examples/s]Applying chat template to train dataset:  33%|███▎      | 8114/24227 [00:04<00:07, 2083.08 examples/s]Applying chat template to train dataset:  31%|███       | 7516/24227 [00:03<00:07, 2325.24 examples/s]Applying chat template to train dataset:  31%|███       | 7558/24227 [00:04<00:08, 1951.41 examples/s]Applying chat template to train dataset:  35%|███▍      | 8412/24227 [00:04<00:06, 2283.90 examples/s]Applying chat template to train dataset:  32%|███▏      | 7782/24227 [00:03<00:06, 2410.72 examples/s]Applying chat template to train dataset:  33%|███▎      | 7919/24227 [00:04<00:07, 2112.37 examples/s]Applying chat template to train dataset:  36%|███▌      | 8733/24227 [00:04<00:06, 2508.06 examples/s]Applying chat template to train dataset:  34%|███▍      | 8197/24227 [00:04<00:06, 2535.71 examples/s]Applying chat template to train dataset:  34%|███▍      | 8191/24227 [00:04<00:07, 2264.98 examples/s]Applying chat template to train dataset:  38%|███▊      | 9092/24227 [00:04<00:06, 2466.57 examples/s]Applying chat template to train dataset:  35%|███▌      | 8491/24227 [00:04<00:05, 2638.13 examples/s]Applying chat template to train dataset:  35%|███▍      | 8444/24227 [00:04<00:06, 2333.45 examples/s]Applying chat template to train dataset:  39%|███▊      | 9380/24227 [00:04<00:05, 2564.67 examples/s]Applying chat template to train dataset:  37%|███▋      | 8891/24227 [00:04<00:05, 2646.14 examples/s]Applying chat template to train dataset:  36%|███▋      | 8835/24227 [00:04<00:06, 2427.38 examples/s]Applying chat template to train dataset:  40%|████      | 9692/24227 [00:04<00:05, 2705.68 examples/s]Applying chat template to train dataset:  38%|███▊      | 9182/24227 [00:04<00:05, 2706.55 examples/s]Applying chat template to train dataset:  38%|███▊      | 9105/24227 [00:04<00:06, 2496.22 examples/s]Applying chat template to train dataset:  42%|████▏     | 10116/24227 [00:04<00:05, 2746.14 examples/s]Applying chat template to train dataset:  39%|███▉      | 9402/24227 [00:04<00:05, 2622.24 examples/s]Applying chat template to train dataset:  39%|███▉      | 9491/24227 [00:04<00:05, 2802.70 examples/s]Applying chat template to train dataset:  40%|███▉      | 9679/24227 [00:04<00:05, 2660.20 examples/s]Applying chat template to train dataset:  44%|████▎     | 10541/24227 [00:05<00:04, 2771.34 examples/s]Applying chat template to train dataset:  41%|████      | 9868/24227 [00:04<00:05, 2696.47 examples/s]Applying chat template to train dataset:  41%|████▏     | 10049/24227 [00:05<00:05, 2584.85 examples/s]Applying chat template to train dataset:  45%|████▌     | 10903/24227 [00:05<00:05, 2652.81 examples/s]Applying chat template to train dataset:  42%|████▏     | 10193/24227 [00:04<00:05, 2513.14 examples/s]Applying chat template to train dataset:  43%|████▎     | 10330/24227 [00:05<00:05, 2640.69 examples/s]Applying chat template to train dataset:  46%|████▋     | 11228/24227 [00:05<00:06, 2089.94 examples/s]Applying chat template to train dataset:  43%|████▎     | 10506/24227 [00:05<00:07, 1819.69 examples/s]Applying chat template to train dataset:  44%|████▍     | 10650/24227 [00:05<00:07, 1822.10 examples/s]Applying chat template to train dataset:  48%|████▊     | 11592/24227 [00:05<00:05, 2181.10 examples/s]Applying chat template to train dataset:  45%|████▍     | 10785/24227 [00:05<00:06, 2005.10 examples/s]Applying chat template to train dataset:  49%|████▉     | 11900/24227 [00:05<00:05, 2364.08 examples/s]Applying chat template to train dataset:  45%|████▌     | 11010/24227 [00:05<00:06, 1978.65 examples/s]Applying chat template to train dataset:  46%|████▌     | 11110/24227 [00:05<00:06, 2049.96 examples/s]Applying chat template to train dataset:  50%|█████     | 12232/24227 [00:05<00:05, 2029.74 examples/s]Applying chat template to train dataset:  47%|████▋     | 11330/24227 [00:05<00:07, 1728.81 examples/s]Applying chat template to train dataset:  47%|████▋     | 11428/24227 [00:05<00:07, 1742.77 examples/s]Applying chat template to train dataset:  48%|████▊     | 11575/24227 [00:05<00:06, 1862.51 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12602/24227 [00:06<00:05, 2149.15 examples/s]Applying chat template to train dataset:  48%|████▊     | 11670/24227 [00:05<00:06, 1870.05 examples/s]Applying chat template to train dataset:  49%|████▉     | 11893/24227 [00:05<00:06, 1946.64 examples/s]Applying chat template to train dataset:  49%|████▉     | 11901/24227 [00:06<00:06, 1946.20 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12943/24227 [00:06<00:05, 2175.12 examples/s]Applying chat template to train dataset:  50%|████▉     | 12110/24227 [00:05<00:06, 1997.72 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13172/24227 [00:06<00:05, 2197.97 examples/s]Applying chat template to train dataset:  51%|█████     | 12268/24227 [00:06<00:05, 2089.68 examples/s]Applying chat template to train dataset:  52%|█████▏    | 12521/24227 [00:06<00:05, 2183.63 examples/s]Applying chat template to train dataset:  51%|█████▏    | 12443/24227 [00:06<00:05, 2058.26 examples/s]Applying chat template to train dataset:  56%|█████▌    | 13515/24227 [00:06<00:04, 2224.52 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12839/24227 [00:06<00:04, 2417.20 examples/s]Applying chat template to train dataset:  53%|█████▎    | 12742/24227 [00:06<00:05, 2280.75 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13854/24227 [00:06<00:04, 2148.47 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13126/24227 [00:06<00:04, 2528.45 examples/s]Applying chat template to train dataset:  54%|█████▍    | 13074/24227 [00:06<00:04, 2242.70 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14146/24227 [00:06<00:04, 2316.69 examples/s]Applying chat template to train dataset:  55%|█████▌    | 13415/24227 [00:06<00:04, 2622.51 examples/s]Applying chat template to train dataset:  55%|█████▌    | 13372/24227 [00:06<00:04, 2421.79 examples/s]Applying chat template to train dataset:  60%|█████▉    | 14485/24227 [00:06<00:04, 2266.83 examples/s]Applying chat template to train dataset:  57%|█████▋    | 13755/24227 [00:06<00:04, 2492.50 examples/s]Applying chat template to train dataset:  56%|█████▋    | 13670/24227 [00:06<00:04, 2562.43 examples/s]Applying chat template to train dataset:  61%|██████    | 14838/24227 [00:07<00:04, 2291.72 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14091/24227 [00:06<00:04, 2405.06 examples/s]Applying chat template to train dataset:  58%|█████▊    | 14001/24227 [00:06<00:04, 2418.47 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14357/24227 [00:07<00:04, 2465.33 examples/s]Applying chat template to train dataset:  59%|█████▉    | 14266/24227 [00:06<00:04, 2474.24 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15120/24227 [00:07<00:03, 2306.32 examples/s]Applying chat template to train dataset:  60%|██████    | 14643/24227 [00:07<00:03, 2563.95 examples/s]Applying chat template to train dataset:  60%|█████▉    | 14531/24227 [00:06<00:03, 2518.65 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15356/24227 [00:07<00:03, 2317.72 examples/s]Applying chat template to train dataset:  62%|██████▏   | 14925/24227 [00:07<00:03, 2631.96 examples/s]Applying chat template to train dataset:  61%|██████▏   | 14882/24227 [00:07<00:03, 2451.80 examples/s]Applying chat template to train dataset:  65%|██████▍   | 15687/24227 [00:07<00:04, 1891.11 examples/s]Applying chat template to train dataset:  62%|██████▏   | 15136/24227 [00:07<00:04, 2189.45 examples/s]Applying chat template to train dataset:  63%|██████▎   | 15324/24227 [00:07<00:03, 2241.73 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15943/24227 [00:07<00:04, 2030.78 examples/s]Applying chat template to train dataset:  64%|██████▎   | 15432/24227 [00:07<00:03, 2375.97 examples/s]Applying chat template to train dataset:  64%|██████▍   | 15625/24227 [00:07<00:03, 2414.48 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16165/24227 [00:07<00:03, 2072.59 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16406/24227 [00:07<00:03, 2155.17 examples/s]Applying chat template to train dataset:  65%|██████▌   | 15756/24227 [00:07<00:03, 2238.87 examples/s]Applying chat template to train dataset:  66%|██████▌   | 15945/24227 [00:07<00:03, 2318.45 examples/s]Applying chat template to train dataset:  69%|██████▊   | 16640/24227 [00:07<00:03, 2203.22 examples/s]Applying chat template to train dataset:  66%|██████▌   | 16013/24227 [00:07<00:03, 2317.71 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16198/24227 [00:07<00:03, 2368.48 examples/s]Applying chat template to train dataset:  70%|██████▉   | 16880/24227 [00:07<00:03, 2255.54 examples/s]Applying chat template to train dataset:  67%|██████▋   | 16262/24227 [00:07<00:03, 2359.69 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16544/24227 [00:08<00:03, 2345.84 examples/s]Applying chat template to train dataset:  71%|███████   | 17214/24227 [00:08<00:04, 1520.92 examples/s]Applying chat template to train dataset:  68%|██████▊   | 16581/24227 [00:07<00:04, 1567.75 examples/s]Applying chat template to train dataset:  70%|██████▉   | 16870/24227 [00:08<00:04, 1735.16 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17507/24227 [00:08<00:03, 1790.24 examples/s]Applying chat template to train dataset:  69%|██████▉   | 16794/24227 [00:08<00:04, 1672.78 examples/s]Applying chat template to train dataset:  71%|███████   | 17088/24227 [00:08<00:03, 1818.99 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17738/24227 [00:08<00:03, 1900.57 examples/s]Applying chat template to train dataset:  71%|███████   | 17150/24227 [00:08<00:03, 1871.32 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17418/24227 [00:08<00:03, 1925.31 examples/s]Applying chat template to train dataset:  75%|███████▍  | 18126/24227 [00:08<00:02, 2114.87 examples/s]Applying chat template to train dataset:  72%|███████▏  | 17475/24227 [00:08<00:03, 1771.56 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17743/24227 [00:08<00:04, 1533.86 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18462/24227 [00:08<00:03, 1797.97 examples/s]Applying chat template to train dataset:  73%|███████▎  | 17802/24227 [00:08<00:03, 1854.93 examples/s]Applying chat template to train dataset:  74%|███████▍  | 18002/24227 [00:08<00:03, 1718.87 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18820/24227 [00:09<00:02, 1954.13 examples/s]Applying chat template to train dataset:  75%|███████▍  | 18131/24227 [00:08<00:03, 1921.95 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18361/24227 [00:09<00:03, 1902.22 examples/s]Applying chat template to train dataset:  79%|███████▉  | 19090/24227 [00:09<00:02, 2104.70 examples/s]Applying chat template to train dataset:  76%|███████▌  | 18409/24227 [00:08<00:02, 2099.05 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18634/24227 [00:09<00:02, 2072.91 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19321/24227 [00:09<00:02, 2149.63 examples/s]Applying chat template to train dataset:  77%|███████▋  | 18703/24227 [00:08<00:02, 2288.90 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18940/24227 [00:09<00:02, 2295.50 examples/s]Applying chat template to train dataset:  81%|████████  | 19610/24227 [00:09<00:01, 2325.94 examples/s]Applying chat template to train dataset:  78%|███████▊  | 18982/24227 [00:09<00:02, 2410.65 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19268/24227 [00:09<00:02, 2225.92 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19947/24227 [00:09<00:02, 2034.23 examples/s]Applying chat template to train dataset:  80%|███████▉  | 19306/24227 [00:09<00:02, 2194.63 examples/s]Applying chat template to train dataset:  84%|████████▎ | 20250/24227 [00:09<00:01, 2254.91 examples/s]Applying chat template to train dataset:  81%|████████  | 19590/24227 [00:09<00:01, 2344.39 examples/s]Applying chat template to train dataset:  81%|████████  | 19597/24227 [00:09<00:02, 2108.41 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20523/24227 [00:09<00:01, 2368.21 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19979/24227 [00:09<00:01, 2423.65 examples/s]Applying chat template to train dataset:  82%|████████▏ | 19945/24227 [00:09<00:01, 2170.37 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20833/24227 [00:09<00:01, 2553.82 examples/s]Applying chat template to train dataset:  83%|████████▎ | 20174/24227 [00:09<00:01, 2196.58 examples/s]Applying chat template to train dataset:  84%|████████▍ | 20387/24227 [00:09<00:01, 2516.71 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21266/24227 [00:10<00:01, 2670.55 examples/s]Applying chat template to train dataset:  85%|████████▍ | 20472/24227 [00:10<00:01, 2384.32 examples/s]Applying chat template to train dataset:  85%|████████▌ | 20679/24227 [00:09<00:01, 2610.81 examples/s]Applying chat template to train dataset:  89%|████████▉ | 21610/24227 [00:10<00:01, 2117.75 examples/s]Applying chat template to train dataset:  86%|████████▌ | 20802/24227 [00:10<00:01, 1780.14 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21016/24227 [00:09<00:01, 2035.26 examples/s]Applying chat template to train dataset:  91%|█████████ | 21929/24227 [00:10<00:00, 2340.81 examples/s]Applying chat template to train dataset:  87%|████████▋ | 21134/24227 [00:10<00:01, 1645.54 examples/s]Applying chat template to train dataset:  88%|████████▊ | 21350/24227 [00:10<00:02, 1316.39 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22274/24227 [00:10<00:01, 1439.33 examples/s]Applying chat template to train dataset:  89%|████████▊ | 21470/24227 [00:10<00:01, 1463.36 examples/s]Applying chat template to train dataset:  89%|████████▉ | 21653/24227 [00:10<00:01, 1522.23 examples/s]Applying chat template to train dataset:  90%|████████▉ | 21689/24227 [00:10<00:01, 1472.10 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22610/24227 [00:10<00:01, 1595.18 examples/s]Applying chat template to train dataset:  91%|█████████ | 21986/24227 [00:11<00:01, 1575.01 examples/s]Applying chat template to train dataset:  91%|█████████ | 22027/24227 [00:10<00:01, 1524.18 examples/s]Applying chat template to train dataset:  95%|█████████▍| 22953/24227 [00:11<00:00, 1612.00 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22236/24227 [00:11<00:01, 1745.98 examples/s]Applying chat template to train dataset:  92%|█████████▏| 22246/24227 [00:10<00:01, 1631.74 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23162/24227 [00:11<00:00, 1691.09 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22551/24227 [00:11<00:00, 2038.41 examples/s]Applying chat template to train dataset:  93%|█████████▎| 22584/24227 [00:11<00:00, 1774.13 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23507/24227 [00:11<00:00, 1716.81 examples/s]Applying chat template to train dataset:  94%|█████████▍| 22887/24227 [00:11<00:00, 2079.52 examples/s]Applying chat template to train dataset:  95%|█████████▍| 22900/24227 [00:11<00:00, 2041.78 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23832/24227 [00:11<00:00, 2006.42 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23175/24227 [00:11<00:00, 2195.37 examples/s]Applying chat template to train dataset:  96%|█████████▌| 23278/24227 [00:11<00:00, 2238.37 examples/s]Applying chat template to train dataset: 100%|█████████▉| 24124/24227 [00:11<00:00, 2200.96 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23444/24227 [00:11<00:00, 2311.19 examples/s]Applying chat template to train dataset:  97%|█████████▋| 23550/24227 [00:11<00:00, 2344.84 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:11<00:00, 2061.92 examples/s]
Applying chat template to train dataset:  98%|█████████▊| 23713/24227 [00:11<00:00, 2406.63 examples/s]Applying chat template to train dataset:  98%|█████████▊| 23832/24227 [00:11<00:00, 2459.12 examples/s]Applying chat template to train dataset:  99%|█████████▉| 24026/24227 [00:11<00:00, 2596.76 examples/s]Applying chat template to train dataset: 100%|█████████▉| 24150/24227 [00:11<00:00, 2642.67 examples/s]Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:11<00:00, 2025.57 examples/s]
Applying chat template to train dataset: 100%|██████████| 24227/24227 [00:11<00:00, 2078.64 examples/s]
Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 408.57 examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/24227 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 87/24227 [00:00<01:14, 325.18 examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 409.21 examples/s]Tokenizing train dataset:   0%|          | 42/24227 [00:00<00:59, 408.25 examples/s]Tokenizing train dataset:   1%|          | 128/24227 [00:00<01:38, 244.26 examples/s]Tokenizing train dataset:   0%|          | 92/24227 [00:00<01:42, 234.46 examples/s]Tokenizing train dataset:   1%|          | 160/24227 [00:00<02:31, 159.14 examples/s]Tokenizing train dataset:   1%|          | 122/24227 [00:00<02:00, 199.50 examples/s]Tokenizing train dataset:   0%|          | 92/24227 [00:00<02:41, 149.66 examples/s]Tokenizing train dataset:   1%|          | 182/24227 [00:00<02:22, 168.70 examples/s]Tokenizing train dataset:   1%|          | 149/24227 [00:00<01:52, 214.58 examples/s]Tokenizing train dataset:   0%|          | 120/24227 [00:00<02:17, 175.75 examples/s]Tokenizing train dataset:   1%|          | 213/24227 [00:01<02:02, 196.60 examples/s]Tokenizing train dataset:   1%|          | 154/24227 [00:00<01:54, 210.81 examples/s]Tokenizing train dataset:   1%|          | 187/24227 [00:00<01:48, 222.56 examples/s]Tokenizing train dataset:   1%|          | 246/24227 [00:01<02:07, 187.42 examples/s]Tokenizing train dataset:   1%|          | 183/24227 [00:00<02:02, 196.64 examples/s]Tokenizing train dataset:   1%|          | 223/24227 [00:00<01:47, 223.97 examples/s]Tokenizing train dataset:   1%|          | 280/24227 [00:01<02:03, 193.77 examples/s]Tokenizing train dataset:   1%|          | 220/24227 [00:01<01:54, 209.12 examples/s]Tokenizing train dataset:   1%|          | 260/24227 [00:01<01:46, 225.54 examples/s]Tokenizing train dataset:   1%|▏         | 308/24227 [00:01<01:54, 209.34 examples/s]Tokenizing train dataset:   1%|          | 245/24227 [00:01<01:50, 216.92 examples/s]Tokenizing train dataset:   1%|          | 292/24227 [00:01<01:37, 246.12 examples/s]Tokenizing train dataset:   1%|          | 272/24227 [00:01<01:44, 229.22 examples/s]Tokenizing train dataset:   1%|▏         | 320/24227 [00:01<01:35, 249.52 examples/s]Tokenizing train dataset:   1%|▏         | 344/24227 [00:01<01:51, 214.25 examples/s]Tokenizing train dataset:   1%|          | 300/24227 [00:01<01:40, 238.90 examples/s]Tokenizing train dataset:   1%|▏         | 346/24227 [00:01<01:35, 249.79 examples/s]Tokenizing train dataset:   2%|▏         | 372/24227 [00:01<01:45, 226.63 examples/s]Tokenizing train dataset:   1%|▏         | 332/24227 [00:01<01:33, 256.18 examples/s]Tokenizing train dataset:   2%|▏         | 372/24227 [00:01<01:35, 249.48 examples/s]Tokenizing train dataset:   2%|▏         | 400/24227 [00:01<01:39, 238.40 examples/s]Tokenizing train dataset:   1%|▏         | 361/24227 [00:01<01:30, 263.39 examples/s]Tokenizing train dataset:   2%|▏         | 401/24227 [00:01<01:32, 256.81 examples/s]Tokenizing train dataset:   2%|▏         | 430/24227 [00:01<01:34, 251.79 examples/s]Tokenizing train dataset:   2%|▏         | 390/24227 [00:01<01:29, 266.25 examples/s]Tokenizing train dataset:   2%|▏         | 440/24227 [00:01<01:34, 251.37 examples/s]Tokenizing train dataset:   2%|▏         | 457/24227 [00:02<02:13, 178.19 examples/s]Tokenizing train dataset:   2%|▏         | 424/24227 [00:01<01:51, 213.44 examples/s]Tokenizing train dataset:   2%|▏         | 475/24227 [00:01<01:38, 241.75 examples/s]Tokenizing train dataset:   2%|▏         | 480/24227 [00:02<02:06, 187.97 examples/s]Tokenizing train dataset:   2%|▏         | 503/24227 [00:02<01:36, 245.49 examples/s]Tokenizing train dataset:   2%|▏         | 463/24227 [00:02<01:44, 226.57 examples/s]Tokenizing train dataset:   2%|▏         | 510/24227 [00:02<02:08, 184.63 examples/s]Tokenizing train dataset:   2%|▏         | 543/24227 [00:02<01:35, 247.83 examples/s]Tokenizing train dataset:   2%|▏         | 503/24227 [00:02<01:41, 234.16 examples/s]Tokenizing train dataset:   2%|▏         | 539/24227 [00:02<01:54, 206.25 examples/s]Tokenizing train dataset:   2%|▏         | 571/24227 [00:02<01:33, 252.81 examples/s]Tokenizing train dataset:   2%|▏         | 597/24227 [00:02<01:33, 252.94 examples/s]Tokenizing train dataset:   2%|▏         | 540/24227 [00:02<01:44, 225.90 examples/s]Tokenizing train dataset:   2%|▏         | 573/24227 [00:02<01:51, 212.38 examples/s]Tokenizing train dataset:   3%|▎         | 636/24227 [00:02<01:35, 246.53 examples/s]Tokenizing train dataset:   2%|▏         | 573/24227 [00:02<01:50, 214.46 examples/s]Tokenizing train dataset:   2%|▏         | 602/24227 [00:02<01:56, 203.30 examples/s]Tokenizing train dataset:   3%|▎         | 667/24227 [00:02<01:47, 218.24 examples/s]Tokenizing train dataset:   2%|▏         | 601/24227 [00:02<02:24, 163.97 examples/s]Tokenizing train dataset:   3%|▎         | 638/24227 [00:03<02:32, 154.39 examples/s]Tokenizing train dataset:   3%|▎         | 697/24227 [00:03<02:17, 171.06 examples/s]Tokenizing train dataset:   3%|▎         | 640/24227 [00:03<02:08, 183.63 examples/s]Tokenizing train dataset:   3%|▎         | 664/24227 [00:03<02:17, 171.67 examples/s]Tokenizing train dataset:   3%|▎         | 732/24227 [00:03<01:55, 202.90 examples/s]Tokenizing train dataset:   3%|▎         | 671/24227 [00:03<02:08, 183.37 examples/s]Tokenizing train dataset:   3%|▎         | 692/24227 [00:03<02:19, 169.16 examples/s]Tokenizing train dataset:   3%|▎         | 760/24227 [00:03<01:47, 217.60 examples/s]Tokenizing train dataset:   3%|▎         | 698/24227 [00:03<01:58, 198.29 examples/s]Tokenizing train dataset:   3%|▎         | 717/24227 [00:03<02:09, 182.03 examples/s]Tokenizing train dataset:   3%|▎         | 798/24227 [00:03<01:43, 225.49 examples/s]Tokenizing train dataset:   3%|▎         | 732/24227 [00:03<01:43, 226.37 examples/s]Tokenizing train dataset:   3%|▎         | 750/24227 [00:03<01:50, 211.81 examples/s]Tokenizing train dataset:   3%|▎         | 759/24227 [00:03<01:39, 235.35 examples/s]Tokenizing train dataset:   3%|▎         | 833/24227 [00:03<01:44, 223.29 examples/s]Tokenizing train dataset:   3%|▎         | 778/24227 [00:03<01:56, 202.07 examples/s]Tokenizing train dataset:   4%|▎         | 860/24227 [00:03<01:40, 232.64 examples/s]Tokenizing train dataset:   3%|▎         | 791/24227 [00:03<01:43, 226.95 examples/s]Tokenizing train dataset:   3%|▎         | 801/24227 [00:04<01:54, 205.36 examples/s]Tokenizing train dataset:   4%|▎         | 890/24227 [00:03<01:35, 244.19 examples/s]Tokenizing train dataset:   3%|▎         | 819/24227 [00:03<01:39, 236.30 examples/s]Tokenizing train dataset:   3%|▎         | 830/24227 [00:04<01:56, 200.75 examples/s]Tokenizing train dataset:   4%|▍         | 917/24227 [00:03<01:33, 249.64 examples/s]Tokenizing train dataset:   4%|▎         | 860/24227 [00:03<01:35, 244.99 examples/s]Tokenizing train dataset:   4%|▎         | 854/24227 [00:04<01:52, 208.05 examples/s]Tokenizing train dataset:   4%|▍         | 957/24227 [00:04<01:32, 251.92 examples/s]Tokenizing train dataset:   4%|▎         | 890/24227 [00:04<01:32, 253.66 examples/s]Tokenizing train dataset:   4%|▎         | 892/24227 [00:04<01:46, 218.57 examples/s]Tokenizing train dataset:   4%|▍         | 917/24227 [00:04<01:32, 252.91 examples/s]Tokenizing train dataset:   4%|▍         | 991/24227 [00:04<01:37, 238.69 examples/s]Tokenizing train dataset:   4%|▍         | 921/24227 [00:04<01:53, 205.07 examples/s]Tokenizing train dataset:   4%|▍         | 957/24227 [00:04<01:32, 252.93 examples/s]Tokenizing train dataset:   4%|▍         | 1028/24227 [00:04<01:37, 238.04 examples/s]Tokenizing train dataset:   4%|▍         | 952/24227 [00:04<01:56, 199.99 examples/s]Tokenizing train dataset:   4%|▍         | 985/24227 [00:04<01:52, 206.98 examples/s]Tokenizing train dataset:   4%|▍         | 1061/24227 [00:04<01:47, 214.67 examples/s]Tokenizing train dataset:   4%|▍         | 979/24227 [00:04<01:49, 212.82 examples/s]Tokenizing train dataset:   4%|▍         | 1008/24227 [00:04<01:49, 211.43 examples/s]Tokenizing train dataset:   5%|▍         | 1098/24227 [00:04<01:45, 220.02 examples/s]Tokenizing train dataset:   4%|▍         | 1007/24227 [00:05<02:06, 183.20 examples/s]Tokenizing train dataset:   5%|▍         | 1121/24227 [00:04<01:44, 220.07 examples/s]Tokenizing train dataset:   4%|▍         | 1037/24227 [00:04<02:04, 186.17 examples/s]Tokenizing train dataset:   5%|▍         | 1147/24227 [00:04<01:41, 226.94 examples/s]Tokenizing train dataset:   4%|▍         | 1032/24227 [00:05<02:12, 174.60 examples/s]Tokenizing train dataset:   4%|▍         | 1063/24227 [00:04<01:55, 200.41 examples/s]Tokenizing train dataset:   5%|▍         | 1178/24227 [00:05<01:57, 195.53 examples/s]Tokenizing train dataset:   4%|▍         | 1062/24227 [00:05<02:26, 157.69 examples/s]Tokenizing train dataset:   5%|▍         | 1099/24227 [00:05<02:11, 175.71 examples/s]Tokenizing train dataset:   5%|▍         | 1199/24227 [00:05<01:57, 196.48 examples/s]Tokenizing train dataset:   4%|▍         | 1084/24227 [00:05<02:17, 168.22 examples/s]Tokenizing train dataset:   5%|▍         | 1120/24227 [00:05<02:08, 179.73 examples/s]Tokenizing train dataset:   5%|▌         | 1227/24227 [00:05<01:46, 215.44 examples/s]Tokenizing train dataset:   5%|▍         | 1103/24227 [00:05<02:13, 172.76 examples/s]Tokenizing train dataset:   5%|▍         | 1140/24227 [00:05<02:07, 181.59 examples/s]Tokenizing train dataset:   5%|▌         | 1263/24227 [00:05<01:47, 213.17 examples/s]Tokenizing train dataset:   5%|▍         | 1164/24227 [00:05<02:00, 191.57 examples/s]Tokenizing train dataset:   5%|▍         | 1131/24227 [00:05<02:15, 170.67 examples/s]Tokenizing train dataset:   5%|▌         | 1289/24227 [00:05<01:42, 223.15 examples/s]Tokenizing train dataset:   5%|▍         | 1199/24227 [00:05<01:40, 228.29 examples/s]Tokenizing train dataset:   5%|▍         | 1154/24227 [00:05<02:07, 181.47 examples/s]Tokenizing train dataset:   5%|▌         | 1314/24227 [00:05<01:39, 229.32 examples/s]Tokenizing train dataset:   5%|▍         | 1176/24227 [00:06<02:02, 188.58 examples/s]Tokenizing train dataset:   5%|▌         | 1240/24227 [00:05<01:36, 239.40 examples/s]Tokenizing train dataset:   6%|▌         | 1348/24227 [00:05<01:43, 221.80 examples/s]Tokenizing train dataset:   5%|▍         | 1209/24227 [00:06<02:04, 184.85 examples/s]Tokenizing train dataset:   5%|▌         | 1273/24227 [00:05<01:39, 230.72 examples/s]Tokenizing train dataset:   5%|▌         | 1239/24227 [00:06<01:49, 209.20 examples/s]Tokenizing train dataset:   6%|▌         | 1382/24227 [00:06<01:42, 221.99 examples/s]Tokenizing train dataset:   5%|▌         | 1304/24227 [00:06<01:33, 246.44 examples/s]Tokenizing train dataset:   6%|▌         | 1407/24227 [00:06<01:41, 224.38 examples/s]Tokenizing train dataset:   5%|▌         | 1270/24227 [00:06<01:41, 226.42 examples/s]Tokenizing train dataset:   5%|▌         | 1330/24227 [00:06<01:32, 246.91 examples/s]Tokenizing train dataset:   6%|▌         | 1432/24227 [00:06<01:39, 227.97 examples/s]Tokenizing train dataset:   5%|▌         | 1310/24227 [00:06<01:36, 238.01 examples/s]Tokenizing train dataset:   6%|▌         | 1367/24227 [00:06<01:33, 243.96 examples/s]Tokenizing train dataset:   6%|▌         | 1458/24227 [00:06<01:37, 233.95 examples/s]Tokenizing train dataset:   6%|▌         | 1482/24227 [00:06<01:37, 232.28 examples/s]Tokenizing train dataset:   6%|▌         | 1348/24227 [00:06<01:35, 239.10 examples/s]Tokenizing train dataset:   6%|▌         | 1402/24227 [00:06<01:36, 236.80 examples/s]Tokenizing train dataset:   6%|▌         | 1508/24227 [00:06<01:35, 237.10 examples/s]Tokenizing train dataset:   6%|▌         | 1429/24227 [00:06<01:34, 242.23 examples/s]Tokenizing train dataset:   6%|▌         | 1386/24227 [00:06<01:36, 237.75 examples/s]Tokenizing train dataset:   6%|▋         | 1537/24227 [00:06<01:31, 248.92 examples/s]Tokenizing train dataset:   6%|▌         | 1454/24227 [00:06<01:35, 239.44 examples/s]Tokenizing train dataset:   6%|▌         | 1412/24227 [00:07<01:34, 242.25 examples/s]Tokenizing train dataset:   6%|▋         | 1565/24227 [00:06<01:28, 255.11 examples/s]Tokenizing train dataset:   6%|▌         | 1481/24227 [00:06<01:32, 245.33 examples/s]Tokenizing train dataset:   6%|▌         | 1438/24227 [00:07<01:33, 243.91 examples/s]Tokenizing train dataset:   7%|▋         | 1608/24227 [00:06<01:26, 261.96 examples/s]Tokenizing train dataset:   6%|▌         | 1514/24227 [00:06<01:36, 234.61 examples/s]Tokenizing train dataset:   6%|▌         | 1471/24227 [00:07<01:38, 230.20 examples/s]Tokenizing train dataset:   7%|▋         | 1643/24227 [00:07<01:53, 199.70 examples/s]Tokenizing train dataset:   6%|▋         | 1550/24227 [00:07<02:01, 185.95 examples/s]Tokenizing train dataset:   6%|▌         | 1499/24227 [00:07<02:04, 181.93 examples/s]Tokenizing train dataset:   7%|▋         | 1674/24227 [00:07<01:42, 220.19 examples/s]Tokenizing train dataset:   7%|▋         | 1580/24227 [00:07<01:50, 205.62 examples/s]Tokenizing train dataset:   6%|▋         | 1526/24227 [00:07<01:54, 198.25 examples/s]Tokenizing train dataset:   7%|▋         | 1710/24227 [00:07<01:30, 248.06 examples/s]Tokenizing train dataset:   7%|▋         | 1614/24227 [00:07<01:48, 209.07 examples/s]Tokenizing train dataset:   6%|▋         | 1556/24227 [00:07<01:54, 197.98 examples/s]Tokenizing train dataset:   7%|▋         | 1738/24227 [00:07<01:28, 254.14 examples/s]Tokenizing train dataset:   7%|▋         | 1650/24227 [00:07<01:35, 237.15 examples/s]Tokenizing train dataset:   7%|▋         | 1583/24227 [00:07<01:47, 211.05 examples/s]Tokenizing train dataset:   7%|▋         | 1767/24227 [00:07<01:26, 260.99 examples/s]Tokenizing train dataset:   7%|▋         | 1684/24227 [00:07<01:28, 255.99 examples/s]Tokenizing train dataset:   7%|▋         | 1608/24227 [00:07<01:43, 218.77 examples/s]Tokenizing train dataset:   7%|▋         | 1801/24227 [00:07<01:34, 236.80 examples/s]Tokenizing train dataset:   7%|▋         | 1723/24227 [00:07<01:28, 253.78 examples/s]Tokenizing train dataset:   7%|▋         | 1643/24227 [00:08<01:43, 218.09 examples/s]Tokenizing train dataset:   8%|▊         | 1835/24227 [00:07<01:36, 231.03 examples/s]Tokenizing train dataset:   7%|▋         | 1761/24227 [00:07<01:29, 250.02 examples/s]Tokenizing train dataset:   7%|▋         | 1674/24227 [00:08<01:47, 210.09 examples/s]Tokenizing train dataset:   8%|▊         | 1872/24227 [00:08<01:36, 230.99 examples/s]Tokenizing train dataset:   7%|▋         | 1796/24227 [00:08<01:23, 268.51 examples/s]Tokenizing train dataset:   7%|▋         | 1709/24227 [00:08<01:33, 241.19 examples/s]Tokenizing train dataset:   8%|▊         | 1900/24227 [00:08<01:42, 216.81 examples/s]Tokenizing train dataset:   8%|▊         | 1826/24227 [00:08<01:33, 240.43 examples/s]Tokenizing train dataset:   7%|▋         | 1743/24227 [00:08<01:50, 203.92 examples/s]Tokenizing train dataset:   8%|▊         | 1855/24227 [00:08<01:30, 248.29 examples/s]Tokenizing train dataset:   8%|▊         | 1933/24227 [00:08<01:43, 215.22 examples/s]Tokenizing train dataset:   7%|▋         | 1778/24227 [00:08<02:00, 185.66 examples/s]Tokenizing train dataset:   8%|▊         | 1884/24227 [00:08<01:49, 203.13 examples/s]Tokenizing train dataset:   8%|▊         | 1964/24227 [00:08<01:51, 199.65 examples/s]Tokenizing train dataset:   7%|▋         | 1803/24227 [00:08<01:54, 196.16 examples/s]Tokenizing train dataset:   8%|▊         | 1910/24227 [00:08<02:13, 167.50 examples/s]Tokenizing train dataset:   8%|▊         | 1997/24227 [00:08<02:15, 164.37 examples/s]Tokenizing train dataset:   8%|▊         | 1830/24227 [00:09<02:11, 169.88 examples/s]Tokenizing train dataset:   8%|▊         | 1937/24227 [00:09<02:25, 153.34 examples/s]Tokenizing train dataset:   8%|▊         | 2031/24227 [00:09<02:16, 162.78 examples/s]Tokenizing train dataset:   8%|▊         | 1861/24227 [00:09<02:23, 155.40 examples/s]Tokenizing train dataset:   8%|▊         | 1964/24227 [00:09<02:09, 171.78 examples/s]Tokenizing train dataset:   9%|▊         | 2061/24227 [00:09<01:59, 185.72 examples/s]Tokenizing train dataset:   8%|▊         | 1885/24227 [00:09<02:12, 168.68 examples/s]Tokenizing train dataset:   8%|▊         | 1993/24227 [00:09<01:54, 194.48 examples/s]Tokenizing train dataset:   9%|▊         | 2091/24227 [00:09<01:46, 207.26 examples/s]Tokenizing train dataset:   8%|▊         | 1911/24227 [00:09<02:13, 167.15 examples/s]Tokenizing train dataset:   9%|▊         | 2116/24227 [00:09<01:42, 214.87 examples/s]Tokenizing train dataset:   8%|▊         | 2030/24227 [00:09<01:48, 204.57 examples/s]Tokenizing train dataset:   8%|▊         | 1933/24227 [00:09<02:05, 177.80 examples/s]Tokenizing train dataset:   9%|▉         | 2144/24227 [00:09<01:36, 228.74 examples/s]Tokenizing train dataset:   9%|▊         | 2070/24227 [00:09<01:45, 209.62 examples/s]Tokenizing train dataset:   8%|▊         | 1954/24227 [00:09<02:01, 182.70 examples/s]Tokenizing train dataset:   9%|▉         | 2179/24227 [00:09<01:37, 226.48 examples/s]Tokenizing train dataset:   9%|▊         | 2100/24227 [00:09<01:38, 225.19 examples/s]Tokenizing train dataset:   8%|▊         | 1981/24227 [00:10<02:06, 176.38 examples/s]Tokenizing train dataset:   9%|▉         | 2130/24227 [00:09<01:32, 238.10 examples/s]Tokenizing train dataset:   9%|▉         | 2220/24227 [00:09<01:33, 236.59 examples/s]Tokenizing train dataset:   8%|▊         | 2010/24227 [00:10<01:50, 201.76 examples/s]Tokenizing train dataset:   8%|▊         | 2034/24227 [00:10<01:45, 209.48 examples/s]Tokenizing train dataset:   9%|▉         | 2163/24227 [00:09<01:36, 228.88 examples/s]Tokenizing train dataset:   9%|▉         | 2257/24227 [00:09<01:34, 233.47 examples/s]Tokenizing train dataset:   9%|▊         | 2060/24227 [00:10<01:41, 218.33 examples/s]Tokenizing train dataset:   9%|▉         | 2197/24227 [00:10<01:37, 225.38 examples/s]Tokenizing train dataset:   9%|▉         | 2293/24227 [00:10<01:33, 233.85 examples/s]Tokenizing train dataset:   9%|▉         | 2222/24227 [00:10<01:36, 228.75 examples/s]Tokenizing train dataset:   9%|▊         | 2091/24227 [00:10<01:45, 208.93 examples/s]Tokenizing train dataset:  10%|▉         | 2320/24227 [00:10<01:31, 239.30 examples/s]Tokenizing train dataset:   9%|▉         | 2257/24227 [00:10<01:25, 255.85 examples/s]Tokenizing train dataset:   9%|▉         | 2123/24227 [00:10<01:35, 231.60 examples/s]Tokenizing train dataset:  10%|▉         | 2352/24227 [00:10<01:34, 230.39 examples/s]Tokenizing train dataset:   9%|▉         | 2295/24227 [00:10<01:26, 253.45 examples/s]Tokenizing train dataset:  10%|▉         | 2380/24227 [00:10<01:31, 238.58 examples/s]Tokenizing train dataset:   9%|▉         | 2157/24227 [00:10<01:37, 227.11 examples/s]Tokenizing train dataset:  10%|▉         | 2330/24227 [00:10<01:30, 242.43 examples/s]Tokenizing train dataset:  10%|▉         | 2417/24227 [00:10<01:31, 238.18 examples/s]Tokenizing train dataset:   9%|▉         | 2190/24227 [00:10<01:39, 222.35 examples/s]Tokenizing train dataset:  10%|▉         | 2365/24227 [00:10<01:32, 236.87 examples/s]Tokenizing train dataset:  10%|█         | 2447/24227 [00:10<01:41, 215.59 examples/s]Tokenizing train dataset:   9%|▉         | 2219/24227 [00:11<01:51, 196.81 examples/s]Tokenizing train dataset:   9%|▉         | 2248/24227 [00:11<01:42, 214.89 examples/s]Tokenizing train dataset:  10%|▉         | 2396/24227 [00:10<01:37, 223.96 examples/s]Tokenizing train dataset:  10%|█         | 2487/24227 [00:10<01:35, 228.41 examples/s]Tokenizing train dataset:   9%|▉         | 2276/24227 [00:11<01:36, 226.37 examples/s]Tokenizing train dataset:  10%|█         | 2423/24227 [00:11<01:33, 233.49 examples/s]Tokenizing train dataset:  10%|█         | 2512/24227 [00:11<01:44, 207.09 examples/s]Tokenizing train dataset:  10%|▉         | 2305/24227 [00:11<01:44, 210.76 examples/s]Tokenizing train dataset:  10%|█         | 2452/24227 [00:11<01:57, 185.78 examples/s]Tokenizing train dataset:  10%|█         | 2540/24227 [00:11<02:02, 176.55 examples/s]Tokenizing train dataset:  10%|▉         | 2334/24227 [00:11<01:56, 188.18 examples/s]Tokenizing train dataset:  10%|█         | 2487/24227 [00:11<02:21, 153.94 examples/s]Tokenizing train dataset:  11%|█         | 2574/24227 [00:11<02:25, 149.05 examples/s]Tokenizing train dataset:  10%|▉         | 2363/24227 [00:12<02:36, 139.26 examples/s]Tokenizing train dataset:  11%|█         | 2600/24227 [00:11<02:09, 167.11 examples/s]Tokenizing train dataset:  10%|█         | 2512/24227 [00:11<02:28, 146.52 examples/s]Tokenizing train dataset:  10%|▉         | 2380/24227 [00:12<02:31, 143.92 examples/s]Tokenizing train dataset:  11%|█         | 2620/24227 [00:11<02:05, 171.91 examples/s]Tokenizing train dataset:  10%|█         | 2540/24227 [00:12<03:14, 111.43 examples/s]Tokenizing train dataset:  10%|▉         | 2409/24227 [00:12<03:13, 112.90 examples/s]Tokenizing train dataset:  11%|█         | 2653/24227 [00:12<02:43, 132.33 examples/s]Tokenizing train dataset:  11%|█         | 2570/24227 [00:12<02:38, 136.41 examples/s]Tokenizing train dataset:  10%|█         | 2431/24227 [00:12<02:48, 129.19 examples/s]Tokenizing train dataset:  11%|█         | 2670/24227 [00:12<02:36, 137.82 examples/s]Tokenizing train dataset:  11%|█         | 2602/24227 [00:12<02:10, 166.28 examples/s]Tokenizing train dataset:  10%|█         | 2455/24227 [00:12<02:27, 148.08 examples/s]Tokenizing train dataset:  11%|█         | 2702/24227 [00:12<02:05, 171.61 examples/s]Tokenizing train dataset:  11%|█         | 2637/24227 [00:12<02:05, 172.29 examples/s]Tokenizing train dataset:  10%|█         | 2490/24227 [00:12<02:12, 163.46 examples/s]Tokenizing train dataset:  11%|█▏        | 2732/24227 [00:12<02:08, 167.29 examples/s]Tokenizing train dataset:  11%|█         | 2662/24227 [00:12<01:56, 185.89 examples/s]Tokenizing train dataset:  10%|█         | 2511/24227 [00:13<02:18, 156.87 examples/s]Tokenizing train dataset:  11%|█▏        | 2760/24227 [00:12<02:09, 166.35 examples/s]Tokenizing train dataset:  11%|█         | 2700/24227 [00:12<01:45, 203.95 examples/s]Tokenizing train dataset:  12%|█▏        | 2788/24227 [00:12<01:54, 187.40 examples/s]Tokenizing train dataset:  10%|█         | 2543/24227 [00:13<02:06, 171.67 examples/s]Tokenizing train dataset:  11%|█▏        | 2728/24227 [00:12<01:38, 217.50 examples/s]Tokenizing train dataset:  12%|█▏        | 2811/24227 [00:13<01:49, 196.00 examples/s]Tokenizing train dataset:  11%|█         | 2570/24227 [00:13<01:53, 190.76 examples/s]Tokenizing train dataset:  11%|█▏        | 2752/24227 [00:13<01:37, 219.93 examples/s]Tokenizing train dataset:  12%|█▏        | 2838/24227 [00:13<01:40, 211.93 examples/s]Tokenizing train dataset:  11%|█         | 2599/24227 [00:13<01:41, 212.70 examples/s]Tokenizing train dataset:  12%|█▏        | 2861/24227 [00:13<01:40, 213.41 examples/s]Tokenizing train dataset:  12%|█▏        | 2791/24227 [00:13<01:33, 230.26 examples/s]Tokenizing train dataset:  11%|█         | 2637/24227 [00:13<01:36, 224.31 examples/s]Tokenizing train dataset:  12%|█▏        | 2884/24227 [00:13<01:39, 213.49 examples/s]Tokenizing train dataset:  12%|█▏        | 2815/24227 [00:13<01:32, 230.61 examples/s]Tokenizing train dataset:  11%|█         | 2663/24227 [00:13<01:33, 229.50 examples/s]Tokenizing train dataset:  12%|█▏        | 2917/24227 [00:13<01:41, 210.73 examples/s]Tokenizing train dataset:  12%|█▏        | 2845/24227 [00:13<01:47, 198.82 examples/s]Tokenizing train dataset:  11%|█         | 2697/24227 [00:13<01:36, 222.87 examples/s]Tokenizing train dataset:  12%|█▏        | 2942/24227 [00:13<01:37, 218.04 examples/s]Tokenizing train dataset:  12%|█▏        | 2876/24227 [00:13<01:47, 198.65 examples/s]Tokenizing train dataset:  12%|█▏        | 2968/24227 [00:13<01:33, 228.38 examples/s]Tokenizing train dataset:  11%|█▏        | 2727/24227 [00:13<01:42, 210.31 examples/s]Tokenizing train dataset:  12%|█▏        | 2905/24227 [00:13<01:37, 217.75 examples/s]Tokenizing train dataset:  12%|█▏        | 2996/24227 [00:13<01:28, 239.79 examples/s]Tokenizing train dataset:  11%|█▏        | 2752/24227 [00:14<01:39, 216.90 examples/s]Tokenizing train dataset:  12%|█▏        | 2930/24227 [00:13<01:36, 221.10 examples/s]Tokenizing train dataset:  12%|█▏        | 3025/24227 [00:13<01:25, 249.02 examples/s]Tokenizing train dataset:  11%|█▏        | 2778/24227 [00:14<01:34, 226.11 examples/s]Tokenizing train dataset:  12%|█▏        | 2957/24227 [00:13<01:32, 230.29 examples/s]Tokenizing train dataset:  12%|█▏        | 2814/24227 [00:14<01:33, 228.96 examples/s]Tokenizing train dataset:  13%|█▎        | 3060/24227 [00:14<01:30, 233.29 examples/s]Tokenizing train dataset:  12%|█▏        | 2986/24227 [00:14<01:26, 245.12 examples/s]Tokenizing train dataset:  13%|█▎        | 3086/24227 [00:14<01:29, 235.91 examples/s]Tokenizing train dataset:  12%|█▏        | 3012/24227 [00:14<01:25, 248.44 examples/s]Tokenizing train dataset:  12%|█▏        | 2848/24227 [00:14<01:34, 226.79 examples/s]Tokenizing train dataset:  13%|█▎        | 3116/24227 [00:14<01:23, 251.42 examples/s]Tokenizing train dataset:  13%|█▎        | 3048/24227 [00:14<01:29, 237.34 examples/s]Tokenizing train dataset:  12%|█▏        | 2883/24227 [00:14<01:35, 222.74 examples/s]Tokenizing train dataset:  13%|█▎        | 3151/24227 [00:14<01:26, 243.56 examples/s]Tokenizing train dataset:  13%|█▎        | 3085/24227 [00:14<01:30, 234.50 examples/s]Tokenizing train dataset:  12%|█▏        | 2915/24227 [00:14<01:41, 210.19 examples/s]Tokenizing train dataset:  13%|█▎        | 3189/24227 [00:14<01:30, 233.33 examples/s]Tokenizing train dataset:  13%|█▎        | 3119/24227 [00:14<01:33, 226.09 examples/s]Tokenizing train dataset:  13%|█▎        | 3215/24227 [00:14<01:27, 238.93 examples/s]Tokenizing train dataset:  12%|█▏        | 2950/24227 [00:14<01:39, 213.79 examples/s]Tokenizing train dataset:  13%|█▎        | 3148/24227 [00:14<01:38, 214.00 examples/s]Tokenizing train dataset:  13%|█▎        | 3250/24227 [00:14<01:36, 217.16 examples/s]Tokenizing train dataset:  12%|█▏        | 2980/24227 [00:15<01:52, 188.83 examples/s]Tokenizing train dataset:  13%|█▎        | 3176/24227 [00:14<01:32, 227.41 examples/s]Tokenizing train dataset:  13%|█▎        | 3202/24227 [00:15<01:30, 232.35 examples/s]Tokenizing train dataset:  14%|█▎        | 3290/24227 [00:15<01:32, 226.80 examples/s]Tokenizing train dataset:  12%|█▏        | 3013/24227 [00:15<01:48, 196.09 examples/s]Tokenizing train dataset:  13%|█▎        | 3227/24227 [00:15<01:29, 235.30 examples/s]Tokenizing train dataset:  13%|█▎        | 3035/24227 [00:15<01:46, 199.53 examples/s]Tokenizing train dataset:  14%|█▎        | 3327/24227 [00:15<01:29, 232.40 examples/s]Tokenizing train dataset:  13%|█▎        | 3258/24227 [00:15<01:22, 253.24 examples/s]Tokenizing train dataset:  13%|█▎        | 3060/24227 [00:15<01:41, 208.08 examples/s]Tokenizing train dataset:  14%|█▍        | 3355/24227 [00:15<01:26, 240.68 examples/s]Tokenizing train dataset:  13%|█▎        | 3089/24227 [00:15<01:33, 225.18 examples/s]Tokenizing train dataset:  14%|█▎        | 3300/24227 [00:15<01:21, 256.96 examples/s]Tokenizing train dataset:  14%|█▍        | 3390/24227 [00:15<01:29, 233.18 examples/s]Tokenizing train dataset:  13%|█▎        | 3118/24227 [00:15<01:27, 240.26 examples/s]Tokenizing train dataset:  14%|█▎        | 3329/24227 [00:15<01:20, 260.72 examples/s]Tokenizing train dataset:  14%|█▍        | 3417/24227 [00:15<01:26, 239.30 examples/s]Tokenizing train dataset:  13%|█▎        | 3155/24227 [00:15<01:29, 234.19 examples/s]Tokenizing train dataset:  14%|█▍        | 3366/24227 [00:15<01:22, 251.72 examples/s]Tokenizing train dataset:  14%|█▍        | 3452/24227 [00:15<01:29, 232.50 examples/s]Tokenizing train dataset:  13%|█▎        | 3186/24227 [00:16<01:23, 251.35 examples/s]Tokenizing train dataset:  14%|█▍        | 3403/24227 [00:15<01:23, 248.58 examples/s]Tokenizing train dataset:  14%|█▍        | 3485/24227 [00:15<01:32, 224.19 examples/s]Tokenizing train dataset:  13%|█▎        | 3220/24227 [00:16<01:27, 239.41 examples/s]Tokenizing train dataset:  14%|█▍        | 3438/24227 [00:15<01:26, 240.60 examples/s]Tokenizing train dataset:  15%|█▍        | 3517/24227 [00:15<01:24, 245.38 examples/s]Tokenizing train dataset:  13%|█▎        | 3262/24227 [00:16<01:24, 248.24 examples/s]Tokenizing train dataset:  15%|█▍        | 3543/24227 [00:16<01:24, 244.59 examples/s]Tokenizing train dataset:  14%|█▍        | 3470/24227 [00:16<01:30, 229.36 examples/s]Tokenizing train dataset:  15%|█▍        | 3580/24227 [00:16<01:15, 272.98 examples/s]Tokenizing train dataset:  14%|█▎        | 3302/24227 [00:16<01:23, 250.95 examples/s]Tokenizing train dataset:  14%|█▍        | 3510/24227 [00:16<01:27, 236.07 examples/s]Tokenizing train dataset:  15%|█▍        | 3612/24227 [00:16<01:51, 184.82 examples/s]Tokenizing train dataset:  14%|█▎        | 3330/24227 [00:16<02:02, 170.99 examples/s]Tokenizing train dataset:  15%|█▍        | 3545/24227 [00:16<01:46, 193.65 examples/s]Tokenizing train dataset:  15%|█▌        | 3646/24227 [00:16<01:36, 214.13 examples/s]Tokenizing train dataset:  14%|█▍        | 3356/24227 [00:16<01:53, 184.55 examples/s]Tokenizing train dataset:  15%|█▍        | 3580/24227 [00:16<01:32, 222.39 examples/s]Tokenizing train dataset:  15%|█▌        | 3673/24227 [00:16<01:32, 223.11 examples/s]Tokenizing train dataset:  14%|█▍        | 3388/24227 [00:17<01:48, 191.60 examples/s]Tokenizing train dataset:  15%|█▍        | 3620/24227 [00:16<01:28, 232.15 examples/s]Tokenizing train dataset:  15%|█▌        | 3701/24227 [00:16<01:28, 232.84 examples/s]Tokenizing train dataset:  14%|█▍        | 3410/24227 [00:17<01:45, 196.85 examples/s]Tokenizing train dataset:  15%|█▌        | 3652/24227 [00:16<01:22, 248.72 examples/s]Tokenizing train dataset:  15%|█▌        | 3727/24227 [00:16<01:26, 238.28 examples/s]Tokenizing train dataset:  14%|█▍        | 3433/24227 [00:17<01:43, 200.61 examples/s]Tokenizing train dataset:  15%|█▌        | 3681/24227 [00:17<01:19, 257.30 examples/s]Tokenizing train dataset:  16%|█▌        | 3756/24227 [00:17<01:21, 250.54 examples/s]Tokenizing train dataset:  14%|█▍        | 3455/24227 [00:17<01:41, 203.79 examples/s]Tokenizing train dataset:  16%|█▌        | 3786/24227 [00:17<01:18, 260.91 examples/s]Tokenizing train dataset:  15%|█▌        | 3722/24227 [00:17<01:19, 256.81 examples/s]Tokenizing train dataset:  14%|█▍        | 3485/24227 [00:17<01:43, 200.05 examples/s]Tokenizing train dataset:  16%|█▌        | 3832/24227 [00:17<01:14, 273.51 examples/s]Tokenizing train dataset:  16%|█▌        | 3770/24227 [00:17<01:15, 272.54 examples/s]Tokenizing train dataset:  15%|█▍        | 3526/24227 [00:17<01:23, 248.51 examples/s]Tokenizing train dataset:  16%|█▌        | 3861/24227 [00:17<01:14, 275.04 examples/s]Tokenizing train dataset:  16%|█▌        | 3800/24227 [00:17<01:14, 273.37 examples/s]Tokenizing train dataset:  15%|█▍        | 3571/24227 [00:17<01:18, 261.88 examples/s]Tokenizing train dataset:  16%|█▌        | 3904/24227 [00:17<01:13, 277.88 examples/s]Tokenizing train dataset:  16%|█▌        | 3832/24227 [00:17<01:12, 280.83 examples/s]Tokenizing train dataset:  15%|█▍        | 3601/24227 [00:17<01:33, 221.31 examples/s]Tokenizing train dataset:  16%|█▌        | 3866/24227 [00:17<01:21, 248.55 examples/s]Tokenizing train dataset:  16%|█▋        | 3943/24227 [00:17<01:27, 230.56 examples/s]Tokenizing train dataset:  15%|█▍        | 3630/24227 [00:18<01:28, 232.77 examples/s]Tokenizing train dataset:  16%|█▌        | 3904/24227 [00:17<01:21, 248.05 examples/s]Tokenizing train dataset:  16%|█▋        | 3975/24227 [00:17<01:22, 244.75 examples/s]Tokenizing train dataset:  15%|█▌        | 3671/24227 [00:18<01:25, 241.01 examples/s]Tokenizing train dataset:  16%|█▋        | 3937/24227 [00:18<01:25, 237.15 examples/s]Tokenizing train dataset:  17%|█▋        | 4011/24227 [00:18<01:24, 240.42 examples/s]Tokenizing train dataset:  16%|█▋        | 3970/24227 [00:18<01:18, 256.82 examples/s]Tokenizing train dataset:  15%|█▌        | 3700/24227 [00:18<01:32, 222.50 examples/s]Tokenizing train dataset:  17%|█▋        | 4048/24227 [00:18<01:23, 240.40 examples/s]Tokenizing train dataset:  17%|█▋        | 4004/24227 [00:18<01:22, 245.24 examples/s]Tokenizing train dataset:  15%|█▌        | 3727/24227 [00:18<01:42, 200.09 examples/s]Tokenizing train dataset:  17%|█▋        | 4083/24227 [00:18<01:25, 234.38 examples/s]Tokenizing train dataset:  15%|█▌        | 3751/24227 [00:18<01:38, 207.25 examples/s]Tokenizing train dataset:  17%|█▋        | 4043/24227 [00:18<01:22, 245.33 examples/s]Tokenizing train dataset:  17%|█▋        | 4115/24227 [00:18<01:20, 249.86 examples/s]Tokenizing train dataset:  16%|█▌        | 3786/24227 [00:18<01:39, 204.90 examples/s]Tokenizing train dataset:  17%|█▋        | 4074/24227 [00:18<01:30, 222.50 examples/s]Tokenizing train dataset:  17%|█▋        | 4148/24227 [00:18<01:28, 226.15 examples/s]Tokenizing train dataset:  17%|█▋        | 4098/24227 [00:18<01:30, 223.34 examples/s]Tokenizing train dataset:  16%|█▌        | 3821/24227 [00:19<01:36, 211.70 examples/s]Tokenizing train dataset:  17%|█▋        | 4189/24227 [00:18<01:24, 237.72 examples/s]Tokenizing train dataset:  17%|█▋        | 4130/24227 [00:18<01:34, 211.57 examples/s]Tokenizing train dataset:  16%|█▌        | 3851/24227 [00:19<01:40, 202.16 examples/s]Tokenizing train dataset:  17%|█▋        | 4222/24227 [00:18<01:27, 227.88 examples/s]Tokenizing train dataset:  18%|█▊        | 4250/24227 [00:19<01:25, 234.96 examples/s]Tokenizing train dataset:  17%|█▋        | 4166/24227 [00:19<01:33, 215.22 examples/s]Tokenizing train dataset:  16%|█▌        | 3881/24227 [00:19<01:41, 199.48 examples/s]Tokenizing train dataset:  18%|█▊        | 4277/24227 [00:19<01:22, 241.62 examples/s]Tokenizing train dataset:  17%|█▋        | 4195/24227 [00:19<01:27, 229.16 examples/s]Tokenizing train dataset:  16%|█▌        | 3912/24227 [00:19<01:43, 196.75 examples/s]Tokenizing train dataset:  17%|█▋        | 4220/24227 [00:19<01:26, 232.29 examples/s]Tokenizing train dataset:  18%|█▊        | 4303/24227 [00:19<01:22, 241.33 examples/s]Tokenizing train dataset:  16%|█▌        | 3933/24227 [00:19<01:42, 197.27 examples/s]Tokenizing train dataset:  18%|█▊        | 4248/24227 [00:19<01:22, 241.96 examples/s]Tokenizing train dataset:  18%|█▊        | 4344/24227 [00:19<01:20, 248.53 examples/s]Tokenizing train dataset:  16%|█▋        | 3966/24227 [00:19<01:40, 202.35 examples/s]Tokenizing train dataset:  18%|█▊        | 4287/24227 [00:19<01:20, 247.38 examples/s]Tokenizing train dataset:  18%|█▊        | 4381/24227 [00:19<01:20, 247.14 examples/s]Tokenizing train dataset:  17%|█▋        | 4000/24227 [00:19<01:38, 206.04 examples/s]Tokenizing train dataset:  18%|█▊        | 4314/24227 [00:19<01:37, 203.58 examples/s]Tokenizing train dataset:  18%|█▊        | 4418/24227 [00:19<01:22, 239.17 examples/s]Tokenizing train dataset:  17%|█▋        | 4027/24227 [00:20<01:32, 217.38 examples/s]Tokenizing train dataset:  18%|█▊        | 4343/24227 [00:19<01:30, 220.25 examples/s]Tokenizing train dataset:  18%|█▊        | 4448/24227 [00:19<01:19, 249.27 examples/s]Tokenizing train dataset:  17%|█▋        | 4057/24227 [00:20<01:36, 209.24 examples/s]Tokenizing train dataset:  18%|█▊        | 4371/24227 [00:19<01:38, 202.42 examples/s]Tokenizing train dataset:  18%|█▊        | 4477/24227 [00:20<02:06, 156.51 examples/s]Tokenizing train dataset:  17%|█▋        | 4090/24227 [00:20<02:30, 133.76 examples/s]Tokenizing train dataset:  18%|█▊        | 4411/24227 [00:20<02:09, 153.07 examples/s]Tokenizing train dataset:  19%|█▊        | 4508/24227 [00:20<02:09, 152.06 examples/s]Tokenizing train dataset:  17%|█▋        | 4116/24227 [00:20<02:12, 152.31 examples/s]Tokenizing train dataset:  18%|█▊        | 4439/24227 [00:20<01:55, 171.60 examples/s]Tokenizing train dataset:  19%|█▊        | 4533/24227 [00:20<01:57, 167.31 examples/s]Tokenizing train dataset:  17%|█▋        | 4136/24227 [00:20<02:05, 160.51 examples/s]Tokenizing train dataset:  18%|█▊        | 4463/24227 [00:20<01:47, 184.07 examples/s]Tokenizing train dataset:  19%|█▉        | 4558/24227 [00:20<01:48, 181.35 examples/s]Tokenizing train dataset:  17%|█▋        | 4160/24227 [00:20<01:54, 175.97 examples/s]Tokenizing train dataset:  19%|█▊        | 4490/24227 [00:20<01:38, 200.16 examples/s]Tokenizing train dataset:  19%|█▉        | 4585/24227 [00:20<01:38, 199.72 examples/s]Tokenizing train dataset:  17%|█▋        | 4191/24227 [00:21<01:38, 203.29 examples/s]Tokenizing train dataset:  19%|█▊        | 4515/24227 [00:20<01:34, 208.86 examples/s]Tokenizing train dataset:  19%|█▉        | 4619/24227 [00:20<01:42, 190.45 examples/s]Tokenizing train dataset:  17%|█▋        | 4221/24227 [00:21<02:09, 154.77 examples/s]Tokenizing train dataset:  19%|█▊        | 4542/24227 [00:21<02:29, 131.30 examples/s]Tokenizing train dataset:  19%|█▉        | 4649/24227 [00:21<02:11, 148.97 examples/s]Tokenizing train dataset:  18%|█▊        | 4250/24227 [00:21<02:30, 132.76 examples/s]Tokenizing train dataset:  19%|█▉        | 4561/24227 [00:21<02:44, 119.57 examples/s]Tokenizing train dataset:  18%|█▊        | 4273/24227 [00:21<02:14, 148.32 examples/s]Tokenizing train dataset:  19%|█▉        | 4680/24227 [00:21<02:09, 151.00 examples/s]Tokenizing train dataset:  19%|█▉        | 4591/24227 [00:21<02:36, 125.12 examples/s]Tokenizing train dataset:  18%|█▊        | 4302/24227 [00:21<02:09, 153.50 examples/s]Tokenizing train dataset:  19%|█▉        | 4710/24227 [00:21<02:11, 148.59 examples/s]Tokenizing train dataset:  19%|█▉        | 4610/24227 [00:21<02:25, 135.16 examples/s]Tokenizing train dataset:  18%|█▊        | 4331/24227 [00:22<02:11, 151.10 examples/s]Tokenizing train dataset:  20%|█▉        | 4744/24227 [00:21<02:17, 141.83 examples/s]Tokenizing train dataset:  19%|█▉        | 4627/24227 [00:21<02:52, 113.77 examples/s]Tokenizing train dataset:  18%|█▊        | 4349/24227 [00:22<02:14, 148.18 examples/s]Tokenizing train dataset:  20%|█▉        | 4760/24227 [00:22<02:19, 139.94 examples/s]Tokenizing train dataset:  19%|█▉        | 4643/24227 [00:22<02:43, 119.62 examples/s]Tokenizing train dataset:  18%|█▊        | 4377/24227 [00:22<02:16, 145.41 examples/s]Tokenizing train dataset:  20%|█▉        | 4777/24227 [00:22<02:26, 132.60 examples/s]Tokenizing train dataset:  19%|█▉        | 4660/24227 [00:22<02:50, 114.76 examples/s]Tokenizing train dataset:  18%|█▊        | 4410/24227 [00:22<01:50, 179.33 examples/s]Tokenizing train dataset:  20%|█▉        | 4798/24227 [00:22<02:12, 146.69 examples/s]Tokenizing train dataset:  19%|█▉        | 4680/24227 [00:22<02:30, 130.24 examples/s]Tokenizing train dataset:  20%|█▉        | 4817/24227 [00:22<02:05, 155.15 examples/s]Tokenizing train dataset:  18%|█▊        | 4444/24227 [00:22<01:48, 182.37 examples/s]Tokenizing train dataset:  19%|█▉        | 4697/24227 [00:22<02:29, 130.89 examples/s]Tokenizing train dataset:  20%|█▉        | 4838/24227 [00:22<01:57, 164.88 examples/s]Tokenizing train dataset:  18%|█▊        | 4467/24227 [00:22<01:44, 188.97 examples/s]Tokenizing train dataset:  20%|█▉        | 4726/24227 [00:22<02:16, 142.39 examples/s]Tokenizing train dataset:  20%|██        | 4869/24227 [00:22<02:28, 130.46 examples/s]Tokenizing train dataset:  19%|█▊        | 4496/24227 [00:23<02:15, 145.87 examples/s]Tokenizing train dataset:  20%|█▉        | 4745/24227 [00:22<02:49, 114.92 examples/s]Tokenizing train dataset:  20%|██        | 4887/24227 [00:23<02:36, 123.68 examples/s]Tokenizing train dataset:  20%|█▉        | 4760/24227 [00:23<03:22, 96.11 examples/s] Tokenizing train dataset:  19%|█▊        | 4524/24227 [00:23<02:35, 126.43 examples/s]Tokenizing train dataset:  20%|██        | 4904/24227 [00:23<02:41, 119.36 examples/s]Tokenizing train dataset:  20%|█▉        | 4785/24227 [00:23<02:40, 121.43 examples/s]Tokenizing train dataset:  19%|█▉        | 4547/24227 [00:23<02:17, 142.95 examples/s]Tokenizing train dataset:  20%|██        | 4917/24227 [00:23<02:41, 119.23 examples/s]Tokenizing train dataset:  20%|█▉        | 4817/24227 [00:23<02:17, 141.57 examples/s]Tokenizing train dataset:  20%|██        | 4936/24227 [00:23<02:33, 125.65 examples/s]Tokenizing train dataset:  19%|█▉        | 4575/24227 [00:23<02:13, 147.03 examples/s]Tokenizing train dataset:  20%|█▉        | 4843/24227 [00:23<02:17, 141.14 examples/s]Tokenizing train dataset:  20%|██        | 4950/24227 [00:23<03:01, 106.27 examples/s]Tokenizing train dataset:  19%|█▉        | 4596/24227 [00:23<02:24, 135.46 examples/s]Tokenizing train dataset:  20%|██        | 4868/24227 [00:23<02:00, 160.47 examples/s]Tokenizing train dataset:  21%|██        | 4976/24227 [00:23<02:19, 137.91 examples/s]Tokenizing train dataset:  19%|█▉        | 4615/24227 [00:23<02:16, 143.57 examples/s]Tokenizing train dataset:  20%|██        | 4887/24227 [00:23<01:57, 165.19 examples/s]Tokenizing train dataset:  21%|██        | 4996/24227 [00:23<02:07, 151.20 examples/s]Tokenizing train dataset:  19%|█▉        | 4643/24227 [00:24<02:24, 135.60 examples/s]Tokenizing train dataset:  20%|██        | 4916/24227 [00:23<02:04, 155.37 examples/s]Tokenizing train dataset:  19%|█▉        | 4665/24227 [00:24<02:09, 151.08 examples/s]Tokenizing train dataset:  21%|██        | 5031/24227 [00:24<02:11, 146.47 examples/s]Tokenizing train dataset:  20%|██        | 4944/24227 [00:24<01:46, 181.28 examples/s]Tokenizing train dataset:  19%|█▉        | 4687/24227 [00:24<01:58, 164.96 examples/s]Tokenizing train dataset:  21%|██        | 5049/24227 [00:24<02:13, 143.47 examples/s]Tokenizing train dataset:  21%|██        | 4967/24227 [00:24<01:54, 168.37 examples/s]Tokenizing train dataset:  19%|█▉        | 4709/24227 [00:24<01:52, 173.84 examples/s]Tokenizing train dataset:  21%|██        | 5076/24227 [00:24<01:53, 168.63 examples/s]Tokenizing train dataset:  21%|██        | 4990/24227 [00:24<01:47, 179.45 examples/s]Tokenizing train dataset:  20%|█▉        | 4743/24227 [00:24<01:47, 181.79 examples/s]Tokenizing train dataset:  21%|██        | 5108/24227 [00:24<01:45, 181.92 examples/s]Tokenizing train dataset:  21%|██        | 5022/24227 [00:24<01:31, 209.75 examples/s]Tokenizing train dataset:  20%|█▉        | 4773/24227 [00:24<01:45, 183.73 examples/s]Tokenizing train dataset:  21%|██        | 5139/24227 [00:24<01:46, 178.80 examples/s]Tokenizing train dataset:  21%|██        | 5057/24227 [00:24<01:30, 211.80 examples/s]Tokenizing train dataset:  21%|██▏       | 5160/24227 [00:24<01:43, 184.12 examples/s]Tokenizing train dataset:  20%|█▉        | 4804/24227 [00:25<01:43, 187.00 examples/s]Tokenizing train dataset:  21%|██        | 5086/24227 [00:24<01:37, 195.94 examples/s]Tokenizing train dataset:  21%|██▏       | 5182/24227 [00:24<01:39, 191.89 examples/s]Tokenizing train dataset:  20%|█▉        | 4828/24227 [00:25<01:38, 197.02 examples/s]Tokenizing train dataset:  21%|██        | 5112/24227 [00:24<01:31, 209.34 examples/s]Tokenizing train dataset:  22%|██▏       | 5214/24227 [00:25<02:06, 150.87 examples/s]Tokenizing train dataset:  20%|██        | 4856/24227 [00:25<02:08, 150.34 examples/s]Tokenizing train dataset:  21%|██        | 5140/24227 [00:25<01:55, 164.89 examples/s]Tokenizing train dataset:  22%|██▏       | 5232/24227 [00:25<02:02, 155.32 examples/s]Tokenizing train dataset:  20%|██        | 4876/24227 [00:25<02:02, 157.93 examples/s]Tokenizing train dataset:  21%|██▏       | 5170/24227 [00:25<02:04, 152.62 examples/s]Tokenizing train dataset:  22%|██▏       | 5261/24227 [00:25<02:12, 142.72 examples/s]Tokenizing train dataset:  20%|██        | 4908/24227 [00:25<02:12, 146.34 examples/s]Tokenizing train dataset:  21%|██▏       | 5192/24227 [00:25<01:56, 163.95 examples/s]Tokenizing train dataset:  20%|██        | 4930/24227 [00:25<02:01, 158.73 examples/s]Tokenizing train dataset:  22%|██▏       | 5288/24227 [00:25<02:05, 151.22 examples/s]Tokenizing train dataset:  22%|██▏       | 5222/24227 [00:25<01:51, 169.83 examples/s]Tokenizing train dataset:  22%|██▏       | 5241/24227 [00:25<01:53, 167.87 examples/s]Tokenizing train dataset:  20%|██        | 4953/24227 [00:26<02:10, 147.85 examples/s]Tokenizing train dataset:  22%|██▏       | 5312/24227 [00:25<02:13, 141.90 examples/s]Tokenizing train dataset:  22%|██▏       | 5263/24227 [00:25<01:46, 177.50 examples/s]Tokenizing train dataset:  21%|██        | 4971/24227 [00:26<02:06, 152.04 examples/s]Tokenizing train dataset:  22%|██▏       | 5340/24227 [00:25<02:04, 151.25 examples/s]Tokenizing train dataset:  21%|██        | 4990/24227 [00:26<02:06, 152.31 examples/s]Tokenizing train dataset:  22%|██▏       | 5291/24227 [00:26<01:50, 171.81 examples/s]Tokenizing train dataset:  22%|██▏       | 5379/24227 [00:26<01:35, 197.32 examples/s]Tokenizing train dataset:  21%|██        | 5016/24227 [00:26<01:48, 176.34 examples/s]Tokenizing train dataset:  22%|██▏       | 5312/24227 [00:26<01:45, 179.21 examples/s]Tokenizing train dataset:  22%|██▏       | 5405/24227 [00:26<01:29, 210.46 examples/s]Tokenizing train dataset:  21%|██        | 5035/24227 [00:26<01:51, 171.61 examples/s]Tokenizing train dataset:  22%|██▏       | 5340/24227 [00:26<01:46, 176.80 examples/s]Tokenizing train dataset:  22%|██▏       | 5441/24227 [00:26<01:30, 207.41 examples/s]Tokenizing train dataset:  21%|██        | 5064/24227 [00:26<01:48, 176.00 examples/s]Tokenizing train dataset:  22%|██▏       | 5384/24227 [00:26<01:20, 232.96 examples/s]Tokenizing train dataset:  23%|██▎       | 5477/24227 [00:26<01:27, 215.30 examples/s]Tokenizing train dataset:  21%|██        | 5094/24227 [00:26<01:45, 181.49 examples/s]Tokenizing train dataset:  22%|██▏       | 5425/24227 [00:26<01:17, 243.57 examples/s]Tokenizing train dataset:  23%|██▎       | 5508/24227 [00:26<01:19, 234.07 examples/s]Tokenizing train dataset:  21%|██        | 5119/24227 [00:26<01:37, 195.57 examples/s]Tokenizing train dataset:  23%|██▎       | 5465/24227 [00:26<01:15, 247.74 examples/s]Tokenizing train dataset:  23%|██▎       | 5545/24227 [00:26<01:19, 235.15 examples/s]Tokenizing train dataset:  21%|██▏       | 5151/24227 [00:27<01:35, 200.51 examples/s]Tokenizing train dataset:  23%|██▎       | 5501/24227 [00:26<01:17, 240.97 examples/s]Tokenizing train dataset:  21%|██▏       | 5174/24227 [00:27<01:32, 206.47 examples/s]Tokenizing train dataset:  23%|██▎       | 5592/24227 [00:26<01:12, 258.22 examples/s]Tokenizing train dataset:  23%|██▎       | 5533/24227 [00:27<01:21, 230.00 examples/s]Tokenizing train dataset:  21%|██▏       | 5204/24227 [00:27<01:35, 199.37 examples/s]Tokenizing train dataset:  23%|██▎       | 5630/24227 [00:27<01:15, 246.00 examples/s]Tokenizing train dataset:  23%|██▎       | 5569/24227 [00:27<01:20, 230.83 examples/s]Tokenizing train dataset:  22%|██▏       | 5235/24227 [00:27<01:54, 165.23 examples/s]Tokenizing train dataset:  23%|██▎       | 5596/24227 [00:27<01:19, 232.93 examples/s]Tokenizing train dataset:  23%|██▎       | 5668/24227 [00:27<01:33, 198.00 examples/s]Tokenizing train dataset:  22%|██▏       | 5263/24227 [00:27<02:28, 128.09 examples/s]Tokenizing train dataset:  23%|██▎       | 5631/24227 [00:27<01:54, 162.66 examples/s]Tokenizing train dataset:  24%|██▎       | 5702/24227 [00:27<02:06, 146.21 examples/s]Tokenizing train dataset:  22%|██▏       | 5284/24227 [00:28<02:14, 140.77 examples/s]Tokenizing train dataset:  23%|██▎       | 5659/24227 [00:27<01:42, 181.99 examples/s]Tokenizing train dataset:  22%|██▏       | 5301/24227 [00:28<02:09, 145.94 examples/s]Tokenizing train dataset:  24%|██▎       | 5728/24227 [00:27<01:54, 161.23 examples/s]Tokenizing train dataset:  23%|██▎       | 5690/24227 [00:27<01:29, 206.05 examples/s]Tokenizing train dataset:  22%|██▏       | 5328/24227 [00:28<02:02, 153.76 examples/s]Tokenizing train dataset:  24%|██▍       | 5757/24227 [00:28<01:51, 166.09 examples/s]Tokenizing train dataset:  24%|██▎       | 5722/24227 [00:28<01:41, 181.51 examples/s]Tokenizing train dataset:  22%|██▏       | 5345/24227 [00:28<02:11, 143.61 examples/s]Tokenizing train dataset:  24%|██▍       | 5788/24227 [00:28<02:06, 145.98 examples/s]Tokenizing train dataset:  22%|██▏       | 5365/24227 [00:28<02:38, 119.08 examples/s]Tokenizing train dataset:  24%|██▎       | 5752/24227 [00:28<02:07, 144.97 examples/s]Tokenizing train dataset:  22%|██▏       | 5395/24227 [00:28<02:04, 151.84 examples/s]Tokenizing train dataset:  24%|██▍       | 5823/24227 [00:28<02:02, 150.36 examples/s]Tokenizing train dataset:  24%|██▍       | 5775/24227 [00:28<01:57, 157.01 examples/s]Tokenizing train dataset:  24%|██▍       | 5840/24227 [00:28<02:13, 137.47 examples/s]Tokenizing train dataset:  22%|██▏       | 5427/24227 [00:29<02:05, 149.39 examples/s]Tokenizing train dataset:  24%|██▍       | 5805/24227 [00:28<02:11, 140.11 examples/s]Tokenizing train dataset:  24%|██▍       | 5863/24227 [00:28<02:08, 143.30 examples/s]Tokenizing train dataset:  22%|██▏       | 5444/24227 [00:29<02:05, 149.50 examples/s]Tokenizing train dataset:  24%|██▍       | 5842/24227 [00:28<01:42, 178.57 examples/s]Tokenizing train dataset:  24%|██▍       | 5883/24227 [00:28<02:07, 144.42 examples/s]Tokenizing train dataset:  23%|██▎       | 5473/24227 [00:29<02:08, 145.99 examples/s]Tokenizing train dataset:  24%|██▍       | 5883/24227 [00:29<01:36, 190.84 examples/s]Tokenizing train dataset:  24%|██▍       | 5909/24227 [00:29<02:07, 144.11 examples/s]Tokenizing train dataset:  23%|██▎       | 5500/24227 [00:29<01:50, 170.06 examples/s]Tokenizing train dataset:  24%|██▍       | 5906/24227 [00:29<01:32, 197.72 examples/s]Tokenizing train dataset:  24%|██▍       | 5933/24227 [00:29<01:52, 162.58 examples/s]Tokenizing train dataset:  23%|██▎       | 5522/24227 [00:29<01:43, 180.11 examples/s]Tokenizing train dataset:  24%|██▍       | 5934/24227 [00:29<01:25, 213.59 examples/s]Tokenizing train dataset:  25%|██▍       | 5959/24227 [00:29<01:39, 183.04 examples/s]Tokenizing train dataset:  23%|██▎       | 5544/24227 [00:29<01:39, 188.40 examples/s]Tokenizing train dataset:  25%|██▍       | 5960/24227 [00:29<01:22, 220.72 examples/s]Tokenizing train dataset:  25%|██▍       | 5990/24227 [00:29<02:07, 143.13 examples/s]Tokenizing train dataset:  23%|██▎       | 5577/24227 [00:29<02:18, 135.12 examples/s]Tokenizing train dataset:  25%|██▍       | 5990/24227 [00:29<01:58, 153.33 examples/s]Tokenizing train dataset:  25%|██▍       | 6011/24227 [00:29<01:58, 153.95 examples/s]Tokenizing train dataset:  23%|██▎       | 5604/24227 [00:30<01:57, 158.53 examples/s]Tokenizing train dataset:  25%|██▍       | 6020/24227 [00:29<02:07, 142.61 examples/s]Tokenizing train dataset:  25%|██▍       | 6042/24227 [00:30<02:05, 145.19 examples/s]Tokenizing train dataset:  23%|██▎       | 5635/24227 [00:30<01:55, 161.30 examples/s]Tokenizing train dataset:  25%|██▍       | 6040/24227 [00:30<02:00, 151.06 examples/s]Tokenizing train dataset:  25%|██▌       | 6065/24227 [00:30<02:13, 136.31 examples/s]Tokenizing train dataset:  23%|██▎       | 5670/24227 [00:30<02:02, 152.00 examples/s]Tokenizing train dataset:  25%|██▌       | 6062/24227 [00:30<03:07, 97.10 examples/s] Tokenizing train dataset:  25%|██▌       | 6083/24227 [00:30<03:30, 86.16 examples/s] Tokenizing train dataset:  23%|██▎       | 5688/24227 [00:31<03:15, 94.64 examples/s] Tokenizing train dataset:  25%|██▌       | 6082/24227 [00:30<03:12, 94.46 examples/s]Tokenizing train dataset:  25%|██▌       | 6102/24227 [00:30<03:04, 98.40 examples/s]Tokenizing train dataset:  24%|██▎       | 5704/24227 [00:31<03:03, 101.04 examples/s]Tokenizing train dataset:  25%|██▌       | 6101/24227 [00:30<02:52, 105.14 examples/s]Tokenizing train dataset:  25%|██▌       | 6122/24227 [00:31<03:33, 84.80 examples/s]Tokenizing train dataset:  24%|██▎       | 5720/24227 [00:31<03:31, 87.32 examples/s] Tokenizing train dataset:  25%|██▌       | 6121/24227 [00:31<03:12, 94.28 examples/s] Tokenizing train dataset:  25%|██▌       | 6151/24227 [00:31<02:38, 114.07 examples/s]Tokenizing train dataset:  24%|██▎       | 5746/24227 [00:31<02:43, 112.78 examples/s]Tokenizing train dataset:  25%|██▌       | 6144/24227 [00:31<02:36, 115.27 examples/s]Tokenizing train dataset:  26%|██▌       | 6183/24227 [00:31<02:01, 148.52 examples/s]Tokenizing train dataset:  24%|██▍       | 5767/24227 [00:31<02:23, 128.89 examples/s]Tokenizing train dataset:  25%|██▌       | 6162/24227 [00:31<02:30, 119.84 examples/s]Tokenizing train dataset:  26%|██▌       | 6220/24227 [00:31<01:52, 160.31 examples/s]Tokenizing train dataset:  24%|██▍       | 5795/24227 [00:31<02:34, 119.64 examples/s]Tokenizing train dataset:  26%|██▌       | 6181/24227 [00:31<02:56, 102.39 examples/s]Tokenizing train dataset:  24%|██▍       | 5811/24227 [00:31<02:25, 126.47 examples/s]Tokenizing train dataset:  26%|██▌       | 6261/24227 [00:31<01:47, 167.14 examples/s]Tokenizing train dataset:  26%|██▌       | 6198/24227 [00:31<03:12, 93.42 examples/s] Tokenizing train dataset:  24%|██▍       | 5831/24227 [00:32<02:40, 114.35 examples/s]Tokenizing train dataset:  26%|██▌       | 6283/24227 [00:31<02:00, 149.23 examples/s]Tokenizing train dataset:  26%|██▌       | 6224/24227 [00:31<02:28, 121.44 examples/s]Tokenizing train dataset:  24%|██▍       | 5861/24227 [00:32<02:05, 146.77 examples/s]Tokenizing train dataset:  26%|██▌       | 6306/24227 [00:32<01:49, 163.19 examples/s]Tokenizing train dataset:  26%|██▌       | 6243/24227 [00:32<02:22, 126.25 examples/s]Tokenizing train dataset:  24%|██▍       | 5880/24227 [00:32<02:11, 139.70 examples/s]Tokenizing train dataset:  26%|██▌       | 6328/24227 [00:32<01:53, 157.82 examples/s]Tokenizing train dataset:  26%|██▌       | 6272/24227 [00:32<01:53, 158.86 examples/s]Tokenizing train dataset:  24%|██▍       | 5904/24227 [00:32<01:54, 159.34 examples/s]Tokenizing train dataset:  26%|██▌       | 6350/24227 [00:32<01:46, 167.80 examples/s]Tokenizing train dataset:  26%|██▌       | 6299/24227 [00:32<01:38, 182.64 examples/s]Tokenizing train dataset:  24%|██▍       | 5929/24227 [00:32<01:42, 178.08 examples/s]Tokenizing train dataset:  26%|██▋       | 6375/24227 [00:32<01:36, 184.60 examples/s]Tokenizing train dataset:  26%|██▌       | 6339/24227 [00:32<01:43, 172.31 examples/s]Tokenizing train dataset:  25%|██▍       | 5960/24227 [00:32<02:03, 148.27 examples/s]Tokenizing train dataset:  26%|██▋       | 6360/24227 [00:32<02:02, 145.63 examples/s]Tokenizing train dataset:  26%|██▋       | 6412/24227 [00:32<02:19, 127.91 examples/s]Tokenizing train dataset:  25%|██▍       | 5987/24227 [00:33<02:08, 141.90 examples/s]Tokenizing train dataset:  26%|██▋       | 6392/24227 [00:32<01:40, 177.46 examples/s]Tokenizing train dataset:  27%|██▋       | 6434/24227 [00:32<02:05, 141.65 examples/s]Tokenizing train dataset:  26%|██▋       | 6420/24227 [00:32<01:30, 196.55 examples/s]Tokenizing train dataset:  25%|██▍       | 6016/24227 [00:33<02:00, 151.48 examples/s]Tokenizing train dataset:  27%|██▋       | 6463/24227 [00:33<01:45, 168.39 examples/s]Tokenizing train dataset:  27%|██▋       | 6461/24227 [00:33<01:32, 193.02 examples/s]Tokenizing train dataset:  25%|██▍       | 6044/24227 [00:33<02:08, 141.42 examples/s]Tokenizing train dataset:  27%|██▋       | 6491/24227 [00:33<01:23, 213.15 examples/s]Tokenizing train dataset:  27%|██▋       | 6502/24227 [00:33<01:54, 154.38 examples/s]Tokenizing train dataset:  25%|██▌       | 6067/24227 [00:33<02:13, 136.03 examples/s]Tokenizing train dataset:  27%|██▋       | 6529/24227 [00:33<01:25, 206.18 examples/s]Tokenizing train dataset:  27%|██▋       | 6537/24227 [00:33<01:54, 154.51 examples/s]Tokenizing train dataset:  25%|██▌       | 6084/24227 [00:33<02:20, 128.82 examples/s]Tokenizing train dataset:  27%|██▋       | 6560/24227 [00:33<01:46, 165.85 examples/s]Tokenizing train dataset:  27%|██▋       | 6569/24227 [00:33<01:22, 213.09 examples/s]Tokenizing train dataset:  25%|██▌       | 6102/24227 [00:33<02:15, 133.57 examples/s]Tokenizing train dataset:  27%|██▋       | 6585/24227 [00:33<01:37, 181.05 examples/s]Tokenizing train dataset:  27%|██▋       | 6602/24227 [00:33<01:15, 233.94 examples/s]Tokenizing train dataset:  25%|██▌       | 6133/24227 [00:34<01:46, 169.48 examples/s]Tokenizing train dataset:  27%|██▋       | 6612/24227 [00:33<01:28, 198.05 examples/s]Tokenizing train dataset:  27%|██▋       | 6628/24227 [00:33<01:14, 237.62 examples/s]Tokenizing train dataset:  25%|██▌       | 6162/24227 [00:34<01:32, 195.53 examples/s]Tokenizing train dataset:  27%|██▋       | 6653/24227 [00:34<01:22, 213.12 examples/s]Tokenizing train dataset:  28%|██▊       | 6670/24227 [00:34<01:10, 248.79 examples/s]Tokenizing train dataset:  26%|██▌       | 6199/24227 [00:34<01:25, 210.48 examples/s]Tokenizing train dataset:  28%|██▊       | 6683/24227 [00:34<01:16, 230.25 examples/s]Tokenizing train dataset:  26%|██▌       | 6222/24227 [00:34<01:24, 214.16 examples/s]Tokenizing train dataset:  28%|██▊       | 6712/24227 [00:34<01:08, 256.34 examples/s]Tokenizing train dataset:  28%|██▊       | 6723/24227 [00:34<01:12, 241.18 examples/s]Tokenizing train dataset:  26%|██▌       | 6257/24227 [00:34<01:13, 245.46 examples/s]Tokenizing train dataset:  28%|██▊       | 6740/24227 [00:34<01:07, 260.07 examples/s]Tokenizing train dataset:  28%|██▊       | 6752/24227 [00:34<01:09, 252.21 examples/s]Tokenizing train dataset:  26%|██▌       | 6284/24227 [00:34<01:12, 247.21 examples/s]Tokenizing train dataset:  28%|██▊       | 6767/24227 [00:34<01:06, 261.44 examples/s]Tokenizing train dataset:  28%|██▊       | 6789/24227 [00:34<01:10, 247.56 examples/s]Tokenizing train dataset:  26%|██▌       | 6320/24227 [00:34<01:15, 237.56 examples/s]Tokenizing train dataset:  28%|██▊       | 6807/24227 [00:34<01:06, 261.63 examples/s]Tokenizing train dataset:  28%|██▊       | 6826/24227 [00:34<01:03, 273.91 examples/s]Tokenizing train dataset:  26%|██▋       | 6360/24227 [00:34<01:13, 243.07 examples/s]Tokenizing train dataset:  28%|██▊       | 6841/24227 [00:34<01:10, 245.73 examples/s]Tokenizing train dataset:  28%|██▊       | 6869/24227 [00:34<01:02, 276.67 examples/s]Tokenizing train dataset:  26%|██▋       | 6390/24227 [00:35<01:10, 254.01 examples/s]Tokenizing train dataset:  28%|██▊       | 6885/24227 [00:34<01:07, 256.88 examples/s]Tokenizing train dataset:  26%|██▋       | 6418/24227 [00:35<01:08, 258.85 examples/s]Tokenizing train dataset:  29%|██▊       | 6916/24227 [00:34<01:00, 286.61 examples/s]Tokenizing train dataset:  29%|██▊       | 6917/24227 [00:34<01:04, 269.78 examples/s]Tokenizing train dataset:  27%|██▋       | 6451/24227 [00:35<01:04, 275.70 examples/s]Tokenizing train dataset:  29%|██▊       | 6955/24227 [00:35<00:56, 308.00 examples/s]Tokenizing train dataset:  29%|██▊       | 6945/24227 [00:35<01:04, 269.16 examples/s]Tokenizing train dataset:  29%|██▉       | 6987/24227 [00:35<00:56, 306.79 examples/s]Tokenizing train dataset:  27%|██▋       | 6496/24227 [00:35<01:03, 280.93 examples/s]Tokenizing train dataset:  29%|██▉       | 6983/24227 [00:35<01:09, 247.18 examples/s]Tokenizing train dataset:  29%|██▉       | 7026/24227 [00:35<01:02, 276.67 examples/s]Tokenizing train dataset:  27%|██▋       | 6530/24227 [00:35<01:35, 184.78 examples/s]Tokenizing train dataset:  29%|██▉       | 7023/24227 [00:35<01:32, 186.44 examples/s]Tokenizing train dataset:  29%|██▉       | 7061/24227 [00:35<01:27, 195.84 examples/s]Tokenizing train dataset:  27%|██▋       | 6553/24227 [00:35<01:45, 167.99 examples/s]Tokenizing train dataset:  29%|██▉       | 7059/24227 [00:35<01:43, 165.90 examples/s]Tokenizing train dataset:  29%|██▉       | 7102/24227 [00:35<01:37, 175.29 examples/s]Tokenizing train dataset:  29%|██▉       | 7081/24227 [00:35<01:42, 167.89 examples/s]Tokenizing train dataset:  27%|██▋       | 6586/24227 [00:36<02:04, 141.19 examples/s]Tokenizing train dataset:  29%|██▉       | 7125/24227 [00:36<01:33, 183.62 examples/s]Tokenizing train dataset:  29%|██▉       | 7102/24227 [00:36<02:16, 125.51 examples/s]Tokenizing train dataset:  27%|██▋       | 6606/24227 [00:36<02:40, 109.59 examples/s]Tokenizing train dataset:  30%|██▉       | 7162/24227 [00:36<01:58, 143.97 examples/s]Tokenizing train dataset:  29%|██▉       | 7132/24227 [00:36<01:52, 152.06 examples/s]Tokenizing train dataset:  27%|██▋       | 6626/24227 [00:36<02:33, 114.65 examples/s]Tokenizing train dataset:  30%|██▉       | 7181/24227 [00:36<01:57, 145.66 examples/s]Tokenizing train dataset:  30%|██▉       | 7170/24227 [00:36<01:46, 160.01 examples/s]Tokenizing train dataset:  27%|██▋       | 6648/24227 [00:36<02:27, 119.53 examples/s]Tokenizing train dataset:  30%|██▉       | 7200/24227 [00:36<02:02, 138.74 examples/s]Tokenizing train dataset:  28%|██▊       | 6669/24227 [00:37<02:24, 121.27 examples/s]Tokenizing train dataset:  30%|██▉       | 7221/24227 [00:36<02:03, 138.03 examples/s]Tokenizing train dataset:  30%|██▉       | 7207/24227 [00:36<01:46, 159.22 examples/s]Tokenizing train dataset:  28%|██▊       | 6697/24227 [00:37<01:57, 149.16 examples/s]Tokenizing train dataset:  30%|██▉       | 7256/24227 [00:36<01:36, 176.33 examples/s]Tokenizing train dataset:  30%|██▉       | 7235/24227 [00:36<01:34, 179.57 examples/s]Tokenizing train dataset:  28%|██▊       | 6730/24227 [00:37<01:35, 183.44 examples/s]Tokenizing train dataset:  30%|██▉       | 7257/24227 [00:37<01:33, 181.17 examples/s]Tokenizing train dataset:  30%|███       | 7291/24227 [00:37<01:28, 191.65 examples/s]Tokenizing train dataset:  28%|██▊       | 6761/24227 [00:37<01:23, 209.98 examples/s]Tokenizing train dataset:  30%|███       | 7285/24227 [00:37<01:24, 201.21 examples/s]Tokenizing train dataset:  30%|███       | 7328/24227 [00:37<01:23, 203.42 examples/s]Tokenizing train dataset:  28%|██▊       | 6796/24227 [00:37<01:27, 200.05 examples/s]Tokenizing train dataset:  30%|███       | 7322/24227 [00:37<01:21, 207.84 examples/s]Tokenizing train dataset:  30%|███       | 7360/24227 [00:37<01:14, 226.72 examples/s]Tokenizing train dataset:  28%|██▊       | 6832/24227 [00:37<01:26, 201.71 examples/s]Tokenizing train dataset:  30%|███       | 7362/24227 [00:37<01:21, 205.75 examples/s]Tokenizing train dataset:  31%|███       | 7400/24227 [00:37<01:14, 224.51 examples/s]Tokenizing train dataset:  28%|██▊       | 6867/24227 [00:37<01:27, 198.97 examples/s]Tokenizing train dataset:  31%|███       | 7402/24227 [00:37<01:16, 220.00 examples/s]Tokenizing train dataset:  31%|███       | 7434/24227 [00:37<01:15, 221.24 examples/s]Tokenizing train dataset:  28%|██▊       | 6896/24227 [00:38<01:20, 216.52 examples/s]Tokenizing train dataset:  31%|███       | 7436/24227 [00:37<01:17, 217.88 examples/s]Tokenizing train dataset:  29%|██▊       | 6920/24227 [00:38<01:18, 220.41 examples/s]Tokenizing train dataset:  31%|███       | 7476/24227 [00:37<01:16, 218.51 examples/s]Tokenizing train dataset:  31%|███       | 7471/24227 [00:37<01:09, 242.35 examples/s]Tokenizing train dataset:  29%|██▊       | 6954/24227 [00:38<01:10, 246.23 examples/s]Tokenizing train dataset:  31%|███       | 7515/24227 [00:38<01:13, 227.86 examples/s]Tokenizing train dataset:  31%|███       | 7502/24227 [00:38<01:05, 256.06 examples/s]Tokenizing train dataset:  29%|██▉       | 6989/24227 [00:38<01:12, 237.40 examples/s]Tokenizing train dataset:  31%|███       | 7553/24227 [00:38<01:14, 224.11 examples/s]Tokenizing train dataset:  31%|███       | 7542/24227 [00:38<01:24, 198.28 examples/s]Tokenizing train dataset:  31%|███▏      | 7587/24227 [00:38<01:17, 215.40 examples/s]Tokenizing train dataset:  29%|██▉       | 7027/24227 [00:38<01:26, 198.08 examples/s]Tokenizing train dataset:  31%|███       | 7566/24227 [00:38<01:20, 205.78 examples/s]Tokenizing train dataset:  31%|███▏      | 7625/24227 [00:38<01:13, 225.58 examples/s]Tokenizing train dataset:  29%|██▉       | 7060/24227 [00:38<01:34, 181.90 examples/s]Tokenizing train dataset:  31%|███▏      | 7600/24227 [00:38<01:26, 192.71 examples/s]Tokenizing train dataset:  29%|██▉       | 7080/24227 [00:39<01:38, 173.64 examples/s]Tokenizing train dataset:  32%|███▏      | 7658/24227 [00:38<01:24, 195.05 examples/s]Tokenizing train dataset:  32%|███▏      | 7636/24227 [00:38<01:26, 191.30 examples/s]Tokenizing train dataset:  29%|██▉       | 7112/24227 [00:39<01:24, 201.88 examples/s]Tokenizing train dataset:  32%|███▏      | 7684/24227 [00:38<01:23, 198.26 examples/s]Tokenizing train dataset:  32%|███▏      | 7680/24227 [00:38<01:16, 216.43 examples/s]Tokenizing train dataset:  32%|███▏      | 7737/24227 [00:39<01:02, 264.81 examples/s]Tokenizing train dataset:  30%|██▉       | 7148/24227 [00:39<01:20, 212.00 examples/s]Tokenizing train dataset:  32%|███▏      | 7735/24227 [00:39<00:58, 280.27 examples/s]Tokenizing train dataset:  32%|███▏      | 7775/24227 [00:39<00:58, 280.18 examples/s]Tokenizing train dataset:  30%|██▉       | 7183/24227 [00:39<01:23, 203.43 examples/s]Tokenizing train dataset:  32%|███▏      | 7790/24227 [00:39<00:48, 337.70 examples/s]Tokenizing train dataset:  32%|███▏      | 7824/24227 [00:39<00:49, 329.68 examples/s]Tokenizing train dataset:  30%|██▉       | 7213/24227 [00:39<01:16, 222.24 examples/s]Tokenizing train dataset:  32%|███▏      | 7850/24227 [00:39<00:41, 399.29 examples/s]Tokenizing train dataset:  33%|███▎      | 7887/24227 [00:39<00:40, 403.54 examples/s]Tokenizing train dataset:  30%|██▉       | 7244/24227 [00:39<01:10, 240.13 examples/s]Tokenizing train dataset:  33%|███▎      | 7932/24227 [00:39<00:36, 443.46 examples/s]Tokenizing train dataset:  30%|███       | 7273/24227 [00:39<01:07, 250.45 examples/s]Tokenizing train dataset:  33%|███▎      | 7964/24227 [00:39<00:40, 403.60 examples/s]Tokenizing train dataset:  33%|███▎      | 8010/24227 [00:39<00:34, 465.26 examples/s]Tokenizing train dataset:  30%|███       | 7312/24227 [00:39<01:07, 249.67 examples/s]Tokenizing train dataset:  33%|███▎      | 8037/24227 [00:39<00:38, 416.30 examples/s]Tokenizing train dataset:  33%|███▎      | 8062/24227 [00:39<00:33, 475.79 examples/s]Tokenizing train dataset:  30%|███       | 7346/24227 [00:40<01:02, 270.33 examples/s]Tokenizing train dataset:  33%|███▎      | 8083/24227 [00:39<00:37, 424.95 examples/s]Tokenizing train dataset:  34%|███▎      | 8134/24227 [00:39<00:35, 456.40 examples/s]Tokenizing train dataset:  30%|███       | 7383/24227 [00:40<01:07, 251.38 examples/s]Tokenizing train dataset:  34%|███▎      | 8154/24227 [00:39<00:36, 436.75 examples/s]Tokenizing train dataset:  34%|███▍      | 8200/24227 [00:40<00:35, 449.70 examples/s]Tokenizing train dataset:  34%|███▍      | 8236/24227 [00:40<00:34, 467.83 examples/s]Tokenizing train dataset:  31%|███       | 7422/24227 [00:40<01:07, 248.57 examples/s]Tokenizing train dataset:  34%|███▍      | 8296/24227 [00:40<00:32, 497.54 examples/s]Tokenizing train dataset:  34%|███▍      | 8283/24227 [00:40<00:33, 477.13 examples/s]Tokenizing train dataset:  31%|███       | 7452/24227 [00:40<01:05, 257.54 examples/s]Tokenizing train dataset:  34%|███▍      | 8348/24227 [00:40<00:31, 501.08 examples/s]Tokenizing train dataset:  35%|███▍      | 8361/24227 [00:40<00:32, 488.85 examples/s]Tokenizing train dataset:  31%|███       | 7492/24227 [00:40<01:05, 256.90 examples/s]Tokenizing train dataset:  35%|███▍      | 8418/24227 [00:40<00:32, 485.00 examples/s]Tokenizing train dataset:  35%|███▍      | 8411/24227 [00:40<00:32, 489.22 examples/s]Tokenizing train dataset:  31%|███       | 7538/24227 [00:40<01:01, 269.53 examples/s]Tokenizing train dataset:  35%|███▍      | 8474/24227 [00:40<00:31, 503.10 examples/s]Tokenizing train dataset:  35%|███▌      | 8488/24227 [00:40<00:35, 438.19 examples/s]Tokenizing train dataset:  31%|███       | 7570/24227 [00:41<01:13, 226.91 examples/s]Tokenizing train dataset:  35%|███▌      | 8543/24227 [00:40<00:36, 435.11 examples/s]Tokenizing train dataset:  35%|███▌      | 8557/24227 [00:40<00:38, 411.44 examples/s]Tokenizing train dataset:  35%|███▌      | 8590/24227 [00:40<00:38, 403.54 examples/s]Tokenizing train dataset:  31%|███▏      | 7601/24227 [00:41<01:19, 208.79 examples/s]Tokenizing train dataset:  36%|███▌      | 8636/24227 [00:40<00:31, 487.43 examples/s]Tokenizing train dataset:  36%|███▌      | 8650/24227 [00:41<00:35, 443.16 examples/s]Tokenizing train dataset:  32%|███▏      | 7637/24227 [00:41<01:16, 216.62 examples/s]Tokenizing train dataset:  36%|███▌      | 8712/24227 [00:41<00:33, 470.09 examples/s]Tokenizing train dataset:  36%|███▌      | 8730/24227 [00:41<00:39, 393.80 examples/s]Tokenizing train dataset:  32%|███▏      | 7670/24227 [00:41<01:35, 172.82 examples/s]Tokenizing train dataset:  36%|███▌      | 8779/24227 [00:41<00:37, 411.97 examples/s]Tokenizing train dataset:  36%|███▌      | 8780/24227 [00:41<00:37, 412.94 examples/s]Tokenizing train dataset:  32%|███▏      | 7723/24227 [00:41<01:10, 235.05 examples/s]Tokenizing train dataset:  36%|███▋      | 8830/24227 [00:41<00:35, 430.40 examples/s]Tokenizing train dataset:  36%|███▋      | 8830/24227 [00:41<00:35, 430.81 examples/s]Tokenizing train dataset:  32%|███▏      | 7788/24227 [00:41<00:52, 314.47 examples/s]Tokenizing train dataset:  37%|███▋      | 8890/24227 [00:41<00:32, 465.10 examples/s]Tokenizing train dataset:  37%|███▋      | 8886/24227 [00:41<00:33, 460.29 examples/s]Tokenizing train dataset:  32%|███▏      | 7850/24227 [00:41<00:43, 378.99 examples/s]Tokenizing train dataset:  37%|███▋      | 8954/24227 [00:41<00:30, 503.26 examples/s]Tokenizing train dataset:  37%|███▋      | 8944/24227 [00:41<00:31, 486.90 examples/s]Tokenizing train dataset:  33%|███▎      | 7897/24227 [00:42<00:40, 399.70 examples/s]Tokenizing train dataset:  37%|███▋      | 9040/24227 [00:41<00:29, 522.56 examples/s]Tokenizing train dataset:  37%|███▋      | 9030/24227 [00:41<00:29, 511.57 examples/s]Tokenizing train dataset:  33%|███▎      | 7973/24227 [00:42<00:37, 432.31 examples/s]Tokenizing train dataset:  38%|███▊      | 9101/24227 [00:41<00:27, 541.81 examples/s]Tokenizing train dataset:  38%|███▊      | 9089/24227 [00:41<00:28, 527.86 examples/s]Tokenizing train dataset:  33%|███▎      | 8035/24227 [00:42<00:34, 475.78 examples/s]Tokenizing train dataset:  38%|███▊      | 9158/24227 [00:41<00:27, 546.38 examples/s]Tokenizing train dataset:  38%|███▊      | 9172/24227 [00:42<00:28, 534.53 examples/s]Tokenizing train dataset:  33%|███▎      | 8089/24227 [00:42<00:32, 490.43 examples/s]Tokenizing train dataset:  38%|███▊      | 9253/24227 [00:42<00:26, 574.15 examples/s]Tokenizing train dataset:  38%|███▊      | 9246/24227 [00:42<00:29, 511.62 examples/s]Tokenizing train dataset:  34%|███▎      | 8164/24227 [00:42<00:32, 490.73 examples/s]Tokenizing train dataset:  39%|███▊      | 9336/24227 [00:42<00:26, 563.26 examples/s]Tokenizing train dataset:  38%|███▊      | 9300/24227 [00:42<00:28, 515.63 examples/s]Tokenizing train dataset:  34%|███▍      | 8229/24227 [00:42<00:30, 526.69 examples/s]Tokenizing train dataset:  39%|███▉      | 9413/24227 [00:42<00:27, 539.61 examples/s]Tokenizing train dataset:  39%|███▊      | 9377/24227 [00:42<00:29, 506.65 examples/s]Tokenizing train dataset:  34%|███▍      | 8307/24227 [00:42<00:30, 522.42 examples/s]Tokenizing train dataset:  39%|███▉      | 9469/24227 [00:42<00:27, 543.62 examples/s]Tokenizing train dataset:  39%|███▉      | 9452/24227 [00:42<00:29, 496.77 examples/s]Tokenizing train dataset:  35%|███▍      | 8378/24227 [00:43<00:44, 360.02 examples/s]Tokenizing train dataset:  39%|███▉      | 9541/24227 [00:42<00:38, 385.70 examples/s]Tokenizing train dataset:  39%|███▉      | 9529/24227 [00:42<00:37, 390.28 examples/s]Tokenizing train dataset:  35%|███▍      | 8430/24227 [00:43<00:40, 387.06 examples/s]Tokenizing train dataset:  35%|███▌      | 8480/24227 [00:43<00:38, 409.61 examples/s]Tokenizing train dataset:  40%|███▉      | 9600/24227 [00:43<00:39, 368.71 examples/s]Tokenizing train dataset:  40%|███▉      | 9591/24227 [00:43<00:37, 388.71 examples/s]Tokenizing train dataset:  35%|███▌      | 8528/24227 [00:43<00:37, 424.10 examples/s]Tokenizing train dataset:  40%|███▉      | 9675/24227 [00:43<00:36, 395.64 examples/s]Tokenizing train dataset:  35%|███▌      | 8599/24227 [00:43<00:31, 493.44 examples/s]Tokenizing train dataset:  40%|███▉      | 9664/24227 [00:43<00:36, 399.82 examples/s]Tokenizing train dataset:  40%|████      | 9740/24227 [00:43<00:32, 444.71 examples/s]Tokenizing train dataset:  36%|███▌      | 8663/24227 [00:43<00:29, 530.80 examples/s]Tokenizing train dataset:  40%|████      | 9720/24227 [00:43<00:33, 429.13 examples/s]Tokenizing train dataset:  40%|████      | 9799/24227 [00:43<00:30, 474.05 examples/s]Tokenizing train dataset:  36%|███▌      | 8740/24227 [00:43<00:29, 522.36 examples/s]Tokenizing train dataset:  40%|████      | 9794/24227 [00:43<00:33, 435.95 examples/s]Tokenizing train dataset:  41%|████      | 9851/24227 [00:43<00:29, 482.82 examples/s]Tokenizing train dataset:  36%|███▋      | 8811/24227 [00:43<00:30, 503.78 examples/s]Tokenizing train dataset:  41%|████      | 9860/24227 [00:43<00:33, 431.83 examples/s]Tokenizing train dataset:  41%|████      | 9921/24227 [00:43<00:32, 446.63 examples/s]Tokenizing train dataset:  41%|████      | 9910/24227 [00:43<00:32, 443.76 examples/s]Tokenizing train dataset:  41%|████      | 9974/24227 [00:43<00:30, 465.67 examples/s]Tokenizing train dataset:  37%|███▋      | 8898/24227 [00:44<00:29, 525.17 examples/s]Tokenizing train dataset:  41%|████▏     | 9995/24227 [00:43<00:31, 453.84 examples/s]Tokenizing train dataset:  41%|████▏     | 10043/24227 [00:43<00:31, 449.12 examples/s]Tokenizing train dataset:  37%|███▋      | 8975/24227 [00:44<00:30, 498.28 examples/s]Tokenizing train dataset:  41%|████▏     | 10049/24227 [00:44<00:30, 471.25 examples/s]Tokenizing train dataset:  42%|████▏     | 10102/24227 [00:44<00:29, 479.34 examples/s]Tokenizing train dataset:  37%|███▋      | 9036/24227 [00:44<00:29, 521.79 examples/s]Tokenizing train dataset:  42%|████▏     | 10133/24227 [00:44<00:28, 497.86 examples/s]Tokenizing train dataset:  42%|████▏     | 10166/24227 [00:44<00:30, 458.61 examples/s]Tokenizing train dataset:  38%|███▊      | 9109/24227 [00:44<00:32, 460.26 examples/s]Tokenizing train dataset:  42%|████▏     | 10197/24227 [00:44<00:35, 391.54 examples/s]Tokenizing train dataset:  38%|███▊      | 9170/24227 [00:44<00:46, 322.20 examples/s]Tokenizing train dataset:  42%|████▏     | 10225/24227 [00:44<00:49, 282.59 examples/s]Tokenizing train dataset:  42%|████▏     | 10242/24227 [00:44<00:46, 300.65 examples/s]Tokenizing train dataset:  38%|███▊      | 9240/24227 [00:45<00:47, 318.86 examples/s]Tokenizing train dataset:  42%|████▏     | 10265/24227 [00:44<01:04, 215.61 examples/s]Tokenizing train dataset:  38%|███▊      | 9281/24227 [00:45<00:49, 300.36 examples/s]Tokenizing train dataset:  42%|████▏     | 10279/24227 [00:45<01:01, 226.59 examples/s]Tokenizing train dataset:  39%|███▊      | 9335/24227 [00:45<00:43, 341.73 examples/s]Tokenizing train dataset:  43%|████▎     | 10300/24227 [00:45<01:03, 217.71 examples/s]Tokenizing train dataset:  43%|████▎     | 10315/24227 [00:45<01:01, 225.19 examples/s]Tokenizing train dataset:  39%|███▉      | 9398/24227 [00:45<00:43, 342.20 examples/s]Tokenizing train dataset:  39%|███▉      | 9440/24227 [00:45<00:47, 308.35 examples/s]Tokenizing train dataset:  43%|████▎     | 10339/24227 [00:45<01:20, 172.88 examples/s]Tokenizing train dataset:  43%|████▎     | 10358/24227 [00:45<01:11, 194.14 examples/s]Tokenizing train dataset:  39%|███▉      | 9498/24227 [00:45<00:40, 361.30 examples/s]Tokenizing train dataset:  43%|████▎     | 10362/24227 [00:45<01:18, 175.55 examples/s]Tokenizing train dataset:  43%|████▎     | 10395/24227 [00:45<01:19, 173.40 examples/s]Tokenizing train dataset:  39%|███▉      | 9562/24227 [00:46<00:47, 311.36 examples/s]Tokenizing train dataset:  43%|████▎     | 10402/24227 [00:45<01:21, 170.57 examples/s]Tokenizing train dataset:  43%|████▎     | 10415/24227 [00:45<01:21, 168.71 examples/s]Tokenizing train dataset:  43%|████▎     | 10423/24227 [00:45<01:22, 166.37 examples/s]Tokenizing train dataset:  40%|███▉      | 9625/24227 [00:46<00:45, 321.91 examples/s]Tokenizing train dataset:  43%|████▎     | 10438/24227 [00:46<01:19, 174.27 examples/s]Tokenizing train dataset:  43%|████▎     | 10444/24227 [00:46<01:20, 170.23 examples/s]Tokenizing train dataset:  40%|███▉      | 9662/24227 [00:46<00:47, 304.74 examples/s]Tokenizing train dataset:  43%|████▎     | 10459/24227 [00:46<01:22, 167.30 examples/s]Tokenizing train dataset:  43%|████▎     | 10466/24227 [00:46<01:26, 158.75 examples/s]Tokenizing train dataset:  40%|████      | 9696/24227 [00:46<00:48, 298.22 examples/s]Tokenizing train dataset:  43%|████▎     | 10480/24227 [00:46<01:22, 166.30 examples/s]Tokenizing train dataset:  43%|████▎     | 10499/24227 [00:46<01:12, 190.50 examples/s]Tokenizing train dataset:  40%|████      | 9755/24227 [00:46<00:40, 358.38 examples/s]Tokenizing train dataset:  43%|████▎     | 10509/24227 [00:46<01:11, 191.94 examples/s]Tokenizing train dataset:  43%|████▎     | 10532/24227 [00:46<01:02, 219.08 examples/s]Tokenizing train dataset:  41%|████      | 9812/24227 [00:46<00:35, 406.44 examples/s]Tokenizing train dataset:  44%|████▎     | 10544/24227 [00:46<01:00, 227.54 examples/s]Tokenizing train dataset:  44%|████▎     | 10567/24227 [00:46<00:55, 247.84 examples/s]Tokenizing train dataset:  41%|████      | 9861/24227 [00:46<00:33, 425.20 examples/s]Tokenizing train dataset:  44%|████▎     | 10580/24227 [00:46<01:09, 195.58 examples/s]Tokenizing train dataset:  44%|████▍     | 10604/24227 [00:46<01:08, 197.95 examples/s]Tokenizing train dataset:  41%|████      | 9928/24227 [00:47<00:45, 315.66 examples/s]Tokenizing train dataset:  44%|████▍     | 10619/24227 [00:46<01:06, 205.20 examples/s]Tokenizing train dataset:  41%|████      | 9974/24227 [00:47<00:47, 303.11 examples/s]Tokenizing train dataset:  44%|████▍     | 10644/24227 [00:47<01:12, 186.49 examples/s]Tokenizing train dataset:  44%|████▍     | 10657/24227 [00:47<01:09, 196.29 examples/s]Tokenizing train dataset:  41%|████▏     | 10012/24227 [00:47<00:46, 302.53 examples/s]Tokenizing train dataset:  44%|████▍     | 10679/24227 [00:47<01:13, 183.79 examples/s]Tokenizing train dataset:  44%|████▍     | 10691/24227 [00:47<01:11, 188.57 examples/s]Tokenizing train dataset:  42%|████▏     | 10080/24227 [00:47<00:43, 326.96 examples/s]Tokenizing train dataset:  44%|████▍     | 10704/24227 [00:47<01:09, 195.61 examples/s]Tokenizing train dataset:  44%|████▍     | 10730/24227 [00:47<00:59, 224.95 examples/s]Tokenizing train dataset:  42%|████▏     | 10138/24227 [00:47<00:37, 376.88 examples/s]Tokenizing train dataset:  44%|████▍     | 10728/24227 [00:47<01:18, 171.30 examples/s]Tokenizing train dataset:  44%|████▍     | 10766/24227 [00:47<01:04, 207.31 examples/s]Tokenizing train dataset:  42%|████▏     | 10180/24227 [00:47<00:43, 326.06 examples/s]Tokenizing train dataset:  44%|████▍     | 10748/24227 [00:47<01:19, 169.06 examples/s]Tokenizing train dataset:  45%|████▍     | 10796/24227 [00:47<00:59, 223.92 examples/s]Tokenizing train dataset:  44%|████▍     | 10770/24227 [00:47<01:15, 177.69 examples/s]Tokenizing train dataset:  42%|████▏     | 10230/24227 [00:48<00:42, 326.11 examples/s]Tokenizing train dataset:  45%|████▍     | 10830/24227 [00:47<00:54, 247.94 examples/s]Tokenizing train dataset:  45%|████▍     | 10796/24227 [00:47<01:09, 194.53 examples/s]Tokenizing train dataset:  45%|████▍     | 10819/24227 [00:48<01:07, 198.82 examples/s]Tokenizing train dataset:  42%|████▏     | 10270/24227 [00:48<00:52, 266.07 examples/s]Tokenizing train dataset:  45%|████▍     | 10866/24227 [00:48<01:01, 216.25 examples/s]Tokenizing train dataset:  45%|████▍     | 10854/24227 [00:48<01:12, 183.59 examples/s]Tokenizing train dataset:  43%|████▎     | 10302/24227 [00:48<01:00, 230.93 examples/s]Tokenizing train dataset:  45%|████▌     | 10903/24227 [00:48<01:04, 207.51 examples/s]Tokenizing train dataset:  45%|████▍     | 10891/24227 [00:48<01:00, 221.30 examples/s]Tokenizing train dataset:  43%|████▎     | 10334/24227 [00:48<00:57, 243.46 examples/s]Tokenizing train dataset:  45%|████▌     | 10920/24227 [00:48<00:56, 234.28 examples/s]Tokenizing train dataset:  45%|████▌     | 10940/24227 [00:48<01:05, 202.38 examples/s]Tokenizing train dataset:  43%|████▎     | 10373/24227 [00:48<00:57, 240.13 examples/s]Tokenizing train dataset:  45%|████▌     | 10950/24227 [00:48<00:53, 247.95 examples/s]Tokenizing train dataset:  45%|████▌     | 10982/24227 [00:48<01:05, 203.14 examples/s]Tokenizing train dataset:  45%|████▌     | 10987/24227 [00:48<00:47, 278.57 examples/s]Tokenizing train dataset:  43%|████▎     | 10416/24227 [00:48<00:55, 250.39 examples/s]Tokenizing train dataset:  45%|████▌     | 11013/24227 [00:48<00:59, 221.86 examples/s]Tokenizing train dataset:  45%|████▌     | 11023/24227 [00:48<00:57, 229.68 examples/s]Tokenizing train dataset:  43%|████▎     | 10455/24227 [00:49<01:08, 200.65 examples/s]Tokenizing train dataset:  46%|████▌     | 11038/24227 [00:49<01:19, 165.11 examples/s]Tokenizing train dataset:  46%|████▌     | 11050/24227 [00:49<01:04, 203.42 examples/s]Tokenizing train dataset:  43%|████▎     | 10479/24227 [00:49<01:06, 207.20 examples/s]Tokenizing train dataset:  46%|████▌     | 11078/24227 [00:49<01:11, 184.09 examples/s]Tokenizing train dataset:  46%|████▌     | 11089/24227 [00:49<01:01, 212.04 examples/s]Tokenizing train dataset:  43%|████▎     | 10513/24227 [00:49<01:05, 210.45 examples/s]Tokenizing train dataset:  46%|████▌     | 11111/24227 [00:49<01:08, 190.98 examples/s]Tokenizing train dataset:  46%|████▌     | 11124/24227 [00:49<01:02, 208.31 examples/s]Tokenizing train dataset:  44%|████▎     | 10550/24227 [00:49<01:07, 202.67 examples/s]Tokenizing train dataset:  46%|████▌     | 11146/24227 [00:49<00:59, 220.51 examples/s]Tokenizing train dataset:  46%|████▌     | 11148/24227 [00:49<01:02, 210.73 examples/s]Tokenizing train dataset:  46%|████▌     | 11179/24227 [00:49<00:53, 243.00 examples/s]Tokenizing train dataset:  44%|████▎     | 10590/24227 [00:49<01:02, 217.13 examples/s]Tokenizing train dataset:  46%|████▌     | 11177/24227 [00:49<00:57, 225.70 examples/s]Tokenizing train dataset:  46%|████▋     | 11220/24227 [00:49<00:53, 243.63 examples/s]Tokenizing train dataset:  44%|████▍     | 10626/24227 [00:50<01:03, 214.89 examples/s]Tokenizing train dataset:  46%|████▋     | 11216/24227 [00:49<00:58, 221.72 examples/s]Tokenizing train dataset:  44%|████▍     | 10653/24227 [00:50<01:00, 224.88 examples/s]Tokenizing train dataset:  46%|████▋     | 11245/24227 [00:49<00:55, 234.84 examples/s]Tokenizing train dataset:  46%|████▋     | 11261/24227 [00:49<00:51, 250.06 examples/s]Tokenizing train dataset:  44%|████▍     | 10681/24227 [00:50<00:57, 234.57 examples/s]Tokenizing train dataset:  47%|████▋     | 11281/24227 [00:50<01:04, 201.66 examples/s]Tokenizing train dataset:  47%|████▋     | 11299/24227 [00:50<01:09, 186.82 examples/s]Tokenizing train dataset:  47%|████▋     | 11315/24227 [00:50<00:56, 227.92 examples/s]Tokenizing train dataset:  44%|████▍     | 10721/24227 [00:50<01:09, 195.42 examples/s]Tokenizing train dataset:  47%|████▋     | 11330/24227 [00:50<01:02, 207.34 examples/s]Tokenizing train dataset:  47%|████▋     | 11348/24227 [00:50<00:51, 249.70 examples/s]Tokenizing train dataset:  44%|████▍     | 10757/24227 [00:50<01:10, 190.45 examples/s]Tokenizing train dataset:  47%|████▋     | 11368/24227 [00:50<00:59, 217.50 examples/s]Tokenizing train dataset:  47%|████▋     | 11382/24227 [00:50<00:58, 218.62 examples/s]Tokenizing train dataset:  45%|████▍     | 10791/24227 [00:50<01:09, 193.20 examples/s]Tokenizing train dataset:  45%|████▍     | 10820/24227 [00:51<01:03, 210.57 examples/s]Tokenizing train dataset:  47%|████▋     | 11400/24227 [00:50<01:08, 185.95 examples/s]Tokenizing train dataset:  47%|████▋     | 11413/24227 [00:50<01:04, 198.96 examples/s]Tokenizing train dataset:  45%|████▍     | 10854/24227 [00:51<01:04, 206.98 examples/s]Tokenizing train dataset:  47%|████▋     | 11438/24227 [00:50<01:09, 185.32 examples/s]Tokenizing train dataset:  47%|████▋     | 11436/24227 [00:50<01:19, 160.92 examples/s]Tokenizing train dataset:  47%|████▋     | 11472/24227 [00:51<01:00, 210.95 examples/s]Tokenizing train dataset:  45%|████▍     | 10895/24227 [00:51<01:00, 221.59 examples/s]Tokenizing train dataset:  47%|████▋     | 11460/24227 [00:51<01:12, 175.25 examples/s]Tokenizing train dataset:  47%|████▋     | 11497/24227 [00:51<00:58, 218.23 examples/s]Tokenizing train dataset:  47%|████▋     | 11481/24227 [00:51<01:18, 162.94 examples/s]Tokenizing train dataset:  45%|████▌     | 10927/24227 [00:51<01:07, 197.59 examples/s]Tokenizing train dataset:  48%|████▊     | 11535/24227 [00:51<00:58, 218.71 examples/s]Tokenizing train dataset:  47%|████▋     | 11503/24227 [00:51<01:14, 170.71 examples/s]Tokenizing train dataset:  45%|████▌     | 10952/24227 [00:51<01:04, 206.65 examples/s]Tokenizing train dataset:  48%|████▊     | 11572/24227 [00:51<00:59, 212.61 examples/s]Tokenizing train dataset:  48%|████▊     | 11539/24227 [00:51<01:09, 182.90 examples/s]Tokenizing train dataset:  45%|████▌     | 10993/24227 [00:51<01:00, 219.28 examples/s]Tokenizing train dataset:  48%|████▊     | 11609/24227 [00:51<01:01, 205.69 examples/s]Tokenizing train dataset:  48%|████▊     | 11579/24227 [00:51<01:07, 188.71 examples/s]Tokenizing train dataset:  46%|████▌     | 11032/24227 [00:52<01:01, 213.13 examples/s]Tokenizing train dataset:  48%|████▊     | 11645/24227 [00:51<00:53, 235.76 examples/s]Tokenizing train dataset:  48%|████▊     | 11618/24227 [00:51<01:04, 195.46 examples/s]Tokenizing train dataset:  46%|████▌     | 11071/24227 [00:52<01:05, 200.34 examples/s]Tokenizing train dataset:  48%|████▊     | 11680/24227 [00:51<00:57, 220.01 examples/s]Tokenizing train dataset:  48%|████▊     | 11650/24227 [00:51<00:57, 219.00 examples/s]Tokenizing train dataset:  46%|████▌     | 11100/24227 [00:52<01:00, 216.31 examples/s]Tokenizing train dataset:  48%|████▊     | 11719/24227 [00:52<00:56, 222.48 examples/s]Tokenizing train dataset:  48%|████▊     | 11688/24227 [00:52<00:57, 217.49 examples/s]Tokenizing train dataset:  46%|████▌     | 11136/24227 [00:52<00:59, 220.37 examples/s]Tokenizing train dataset:  49%|████▊     | 11759/24227 [00:52<01:02, 200.41 examples/s]Tokenizing train dataset:  48%|████▊     | 11726/24227 [00:52<01:14, 166.72 examples/s]Tokenizing train dataset:  46%|████▌     | 11171/24227 [00:52<01:31, 142.95 examples/s]Tokenizing train dataset:  49%|████▊     | 11794/24227 [00:52<01:20, 155.00 examples/s]Tokenizing train dataset:  46%|████▌     | 11200/24227 [00:53<01:19, 163.26 examples/s]Tokenizing train dataset:  49%|████▊     | 11761/24227 [00:52<01:18, 159.70 examples/s]Tokenizing train dataset:  46%|████▋     | 11232/24227 [00:53<01:08, 189.38 examples/s]Tokenizing train dataset:  49%|████▊     | 11792/24227 [00:52<01:07, 183.41 examples/s]Tokenizing train dataset:  49%|████▉     | 11817/24227 [00:52<01:17, 161.14 examples/s]Tokenizing train dataset:  46%|████▋     | 11260/24227 [00:53<01:03, 205.31 examples/s]Tokenizing train dataset:  49%|████▉     | 11844/24227 [00:52<01:09, 179.38 examples/s]Tokenizing train dataset:  49%|████▉     | 11817/24227 [00:52<01:08, 182.21 examples/s]Tokenizing train dataset:  47%|████▋     | 11286/24227 [00:53<01:00, 214.63 examples/s]Tokenizing train dataset:  49%|████▉     | 11898/24227 [00:53<00:49, 249.96 examples/s]Tokenizing train dataset:  49%|████▉     | 11866/24227 [00:53<00:59, 206.65 examples/s]Tokenizing train dataset:  47%|████▋     | 11323/24227 [00:53<00:58, 219.36 examples/s]Tokenizing train dataset:  49%|████▉     | 11937/24227 [00:53<00:51, 240.63 examples/s]Tokenizing train dataset:  49%|████▉     | 11900/24227 [00:53<00:57, 214.90 examples/s]Tokenizing train dataset:  49%|████▉     | 11973/24227 [00:53<00:46, 264.61 examples/s]Tokenizing train dataset:  47%|████▋     | 11363/24227 [00:53<00:57, 224.91 examples/s]Tokenizing train dataset:  49%|████▉     | 11971/24227 [00:53<00:38, 315.33 examples/s]Tokenizing train dataset:  50%|████▉     | 12040/24227 [00:53<00:34, 358.13 examples/s]Tokenizing train dataset:  50%|████▉     | 12022/24227 [00:53<00:33, 359.12 examples/s]Tokenizing train dataset:  47%|████▋     | 11392/24227 [00:53<01:01, 207.41 examples/s]Tokenizing train dataset:  50%|████▉     | 12110/24227 [00:53<00:32, 370.89 examples/s]Tokenizing train dataset:  50%|████▉     | 12079/24227 [00:53<00:29, 407.91 examples/s]Tokenizing train dataset:  50%|█████     | 12160/24227 [00:53<00:30, 398.21 examples/s]Tokenizing train dataset:  47%|████▋     | 11425/24227 [00:54<01:03, 201.92 examples/s]Tokenizing train dataset:  50%|█████     | 12132/24227 [00:53<00:27, 437.81 examples/s]Tokenizing train dataset:  50%|█████     | 12232/24227 [00:53<00:25, 473.77 examples/s]Tokenizing train dataset:  47%|████▋     | 11454/24227 [00:54<00:58, 217.91 examples/s]Tokenizing train dataset:  50%|█████     | 12211/24227 [00:53<00:27, 441.09 examples/s]Tokenizing train dataset:  51%|█████     | 12292/24227 [00:53<00:23, 504.11 examples/s]Tokenizing train dataset:  47%|████▋     | 11486/24227 [00:54<00:53, 240.00 examples/s]Tokenizing train dataset:  51%|█████     | 12285/24227 [00:54<00:28, 423.39 examples/s]Tokenizing train dataset:  51%|█████     | 12366/24227 [00:54<00:26, 454.88 examples/s]Tokenizing train dataset:  48%|████▊     | 11521/24227 [00:54<00:59, 214.10 examples/s]Tokenizing train dataset:  51%|█████     | 12351/24227 [00:54<00:25, 473.85 examples/s]Tokenizing train dataset:  51%|█████▏    | 12422/24227 [00:54<00:24, 475.42 examples/s]Tokenizing train dataset:  48%|████▊     | 11548/24227 [00:54<00:56, 226.23 examples/s]Tokenizing train dataset:  51%|█████▏    | 12433/24227 [00:54<00:23, 494.92 examples/s]Tokenizing train dataset:  52%|█████▏    | 12494/24227 [00:54<00:27, 426.29 examples/s]Tokenizing train dataset:  48%|████▊     | 11586/24227 [00:54<01:02, 203.30 examples/s]Tokenizing train dataset:  52%|█████▏    | 12502/24227 [00:54<00:25, 454.38 examples/s]Tokenizing train dataset:  52%|█████▏    | 12564/24227 [00:54<00:28, 406.17 examples/s]Tokenizing train dataset:  48%|████▊     | 11620/24227 [00:54<01:06, 189.31 examples/s]Tokenizing train dataset:  52%|█████▏    | 12569/24227 [00:54<00:26, 432.62 examples/s]Tokenizing train dataset:  52%|█████▏    | 12637/24227 [00:54<00:31, 368.28 examples/s]Tokenizing train dataset:  48%|████▊     | 11657/24227 [00:55<01:07, 185.68 examples/s]Tokenizing train dataset:  52%|█████▏    | 12647/24227 [00:54<00:29, 396.82 examples/s]Tokenizing train dataset:  52%|█████▏    | 12685/24227 [00:54<00:29, 388.05 examples/s]Tokenizing train dataset:  52%|█████▏    | 12693/24227 [00:55<00:28, 405.88 examples/s]Tokenizing train dataset:  48%|████▊     | 11692/24227 [00:55<01:08, 181.94 examples/s]Tokenizing train dataset:  53%|█████▎    | 12760/24227 [00:55<00:27, 418.78 examples/s]Tokenizing train dataset:  53%|█████▎    | 12767/24227 [00:55<00:26, 427.03 examples/s]Tokenizing train dataset:  48%|████▊     | 11712/24227 [00:55<01:13, 169.38 examples/s]Tokenizing train dataset:  53%|█████▎    | 12843/24227 [00:55<00:27, 411.05 examples/s]Tokenizing train dataset:  53%|█████▎    | 12848/24227 [00:55<00:27, 415.62 examples/s]Tokenizing train dataset:  48%|████▊     | 11730/24227 [00:55<01:26, 143.72 examples/s]Tokenizing train dataset:  53%|█████▎    | 12910/24227 [00:55<00:28, 396.26 examples/s]Tokenizing train dataset:  53%|█████▎    | 12909/24227 [00:55<00:24, 452.74 examples/s]Tokenizing train dataset:  48%|████▊     | 11749/24227 [00:55<01:35, 130.98 examples/s]Tokenizing train dataset:  54%|█████▎    | 12979/24227 [00:55<00:28, 392.61 examples/s]Tokenizing train dataset:  54%|█████▎    | 12979/24227 [00:55<00:27, 409.88 examples/s]Tokenizing train dataset:  49%|████▊     | 11767/24227 [00:56<01:29, 139.38 examples/s]Tokenizing train dataset:  54%|█████▍    | 13043/24227 [00:55<00:25, 439.05 examples/s]Tokenizing train dataset:  54%|█████▍    | 13039/24227 [00:55<00:24, 447.91 examples/s]Tokenizing train dataset:  49%|████▊     | 11784/24227 [00:56<01:40, 123.32 examples/s]Tokenizing train dataset:  54%|█████▍    | 13115/24227 [00:56<00:27, 403.10 examples/s]Tokenizing train dataset:  54%|█████▍    | 13109/24227 [00:56<00:30, 359.58 examples/s]Tokenizing train dataset:  49%|████▊     | 11800/24227 [00:56<02:12, 94.12 examples/s] Tokenizing train dataset:  54%|█████▍    | 13183/24227 [00:56<00:30, 360.20 examples/s]Tokenizing train dataset:  54%|█████▍    | 13177/24227 [00:56<00:29, 380.84 examples/s]Tokenizing train dataset:  49%|████▉     | 11828/24227 [00:56<01:38, 125.61 examples/s]Tokenizing train dataset:  55%|█████▍    | 13232/24227 [00:56<00:28, 382.29 examples/s]Tokenizing train dataset:  55%|█████▍    | 13233/24227 [00:56<00:26, 413.68 examples/s]Tokenizing train dataset:  49%|████▉     | 11863/24227 [00:56<01:13, 167.81 examples/s]Tokenizing train dataset:  55%|█████▍    | 13282/24227 [00:56<00:27, 403.90 examples/s]Tokenizing train dataset:  55%|█████▍    | 13301/24227 [00:56<00:25, 421.82 examples/s]Tokenizing train dataset:  49%|████▉     | 11902/24227 [00:56<00:57, 215.38 examples/s]Tokenizing train dataset:  55%|█████▌    | 13349/24227 [00:56<00:27, 398.27 examples/s]Tokenizing train dataset:  49%|████▉     | 11943/24227 [00:57<01:07, 181.26 examples/s]Tokenizing train dataset:  55%|█████▌    | 13365/24227 [00:56<00:34, 315.96 examples/s]Tokenizing train dataset:  55%|█████▌    | 13407/24227 [00:56<00:34, 312.52 examples/s]Tokenizing train dataset:  49%|████▉     | 11992/24227 [00:57<00:51, 239.01 examples/s]Tokenizing train dataset:  55%|█████▌    | 13436/24227 [00:57<00:35, 307.05 examples/s]Tokenizing train dataset:  56%|█████▌    | 13450/24227 [00:57<00:39, 275.96 examples/s]Tokenizing train dataset:  50%|████▉     | 12036/24227 [00:57<00:59, 205.15 examples/s]Tokenizing train dataset:  56%|█████▌    | 13509/24227 [00:57<00:34, 310.70 examples/s]Tokenizing train dataset:  56%|█████▌    | 13492/24227 [00:57<00:46, 232.30 examples/s]Tokenizing train dataset:  50%|████▉     | 12066/24227 [00:57<01:05, 185.05 examples/s]Tokenizing train dataset:  56%|█████▌    | 13545/24227 [00:57<00:33, 316.45 examples/s]Tokenizing train dataset:  56%|█████▌    | 13528/24227 [00:57<00:43, 245.59 examples/s]Tokenizing train dataset:  50%|████▉     | 12101/24227 [00:57<01:03, 189.76 examples/s]Tokenizing train dataset:  56%|█████▌    | 13590/24227 [00:57<00:36, 291.40 examples/s]Tokenizing train dataset:  56%|█████▌    | 13563/24227 [00:57<00:45, 236.36 examples/s]Tokenizing train dataset:  50%|█████     | 12137/24227 [00:57<00:57, 208.56 examples/s]Tokenizing train dataset:  56%|█████▋    | 13629/24227 [00:57<00:35, 301.40 examples/s]Tokenizing train dataset:  56%|█████▌    | 13627/24227 [00:57<00:34, 310.76 examples/s]Tokenizing train dataset:  50%|█████     | 12200/24227 [00:58<00:41, 290.74 examples/s]Tokenizing train dataset:  57%|█████▋    | 13695/24227 [00:57<00:28, 374.26 examples/s]Tokenizing train dataset:  56%|█████▋    | 13666/24227 [00:57<00:33, 314.79 examples/s]Tokenizing train dataset:  51%|█████     | 12238/24227 [00:58<00:38, 309.78 examples/s]Tokenizing train dataset:  57%|█████▋    | 13743/24227 [00:57<00:26, 395.29 examples/s]Tokenizing train dataset:  57%|█████▋    | 13724/24227 [00:58<00:28, 372.79 examples/s]Tokenizing train dataset:  51%|█████     | 12280/24227 [00:58<00:35, 332.49 examples/s]Tokenizing train dataset:  57%|█████▋    | 13806/24227 [00:58<00:23, 448.42 examples/s]Tokenizing train dataset:  51%|█████     | 12319/24227 [00:58<00:35, 333.87 examples/s]Tokenizing train dataset:  57%|█████▋    | 13800/24227 [00:58<00:26, 396.74 examples/s]Tokenizing train dataset:  57%|█████▋    | 13884/24227 [00:58<00:23, 437.26 examples/s]Tokenizing train dataset:  51%|█████     | 12386/24227 [00:58<00:28, 417.05 examples/s]Tokenizing train dataset:  57%|█████▋    | 13865/24227 [00:58<00:22, 453.50 examples/s]Tokenizing train dataset:  58%|█████▊    | 13944/24227 [00:58<00:21, 471.17 examples/s]Tokenizing train dataset:  51%|█████▏    | 12442/24227 [00:58<00:26, 451.40 examples/s]Tokenizing train dataset:  58%|█████▊    | 13937/24227 [00:58<00:19, 517.61 examples/s]Tokenizing train dataset:  58%|█████▊    | 13999/24227 [00:58<00:20, 488.03 examples/s]Tokenizing train dataset:  52%|█████▏    | 12498/24227 [00:58<00:24, 473.78 examples/s]Tokenizing train dataset:  58%|█████▊    | 13998/24227 [00:58<00:22, 462.86 examples/s]Tokenizing train dataset:  58%|█████▊    | 14075/24227 [00:58<00:20, 493.84 examples/s]Tokenizing train dataset:  52%|█████▏    | 12570/24227 [00:58<00:24, 471.74 examples/s]Tokenizing train dataset:  58%|█████▊    | 14056/24227 [00:58<00:20, 486.40 examples/s]Tokenizing train dataset:  58%|█████▊    | 14156/24227 [00:58<00:21, 470.52 examples/s]Tokenizing train dataset:  52%|█████▏    | 12644/24227 [00:59<00:26, 445.42 examples/s]Tokenizing train dataset:  58%|█████▊    | 14132/24227 [00:58<00:22, 441.44 examples/s]Tokenizing train dataset:  59%|█████▊    | 14220/24227 [00:58<00:19, 504.75 examples/s]Tokenizing train dataset:  52%|█████▏    | 12708/24227 [00:59<00:23, 488.13 examples/s]Tokenizing train dataset:  59%|█████▊    | 14208/24227 [00:59<00:23, 434.88 examples/s]Tokenizing train dataset:  59%|█████▉    | 14292/24227 [00:59<00:20, 479.52 examples/s]Tokenizing train dataset:  53%|█████▎    | 12777/24227 [00:59<00:24, 466.20 examples/s]Tokenizing train dataset:  59%|█████▉    | 14267/24227 [00:59<00:21, 466.43 examples/s]Tokenizing train dataset:  59%|█████▉    | 14368/24227 [00:59<00:20, 485.25 examples/s]Tokenizing train dataset:  53%|█████▎    | 12850/24227 [00:59<00:24, 462.13 examples/s]Tokenizing train dataset:  59%|█████▉    | 14331/24227 [00:59<00:19, 503.86 examples/s]Tokenizing train dataset:  60%|█████▉    | 14434/24227 [00:59<00:21, 459.74 examples/s]Tokenizing train dataset:  53%|█████▎    | 12919/24227 [00:59<00:25, 451.22 examples/s]Tokenizing train dataset:  59%|█████▉    | 14410/24227 [00:59<00:19, 504.00 examples/s]Tokenizing train dataset:  60%|█████▉    | 14494/24227 [00:59<00:19, 490.06 examples/s]Tokenizing train dataset:  54%|█████▎    | 12972/24227 [00:59<00:24, 468.28 examples/s]Tokenizing train dataset:  60%|█████▉    | 14477/24227 [00:59<00:17, 542.87 examples/s]Tokenizing train dataset:  60%|██████    | 14556/24227 [00:59<00:18, 520.79 examples/s]Tokenizing train dataset:  54%|█████▍    | 13032/24227 [00:59<00:22, 497.26 examples/s]Tokenizing train dataset:  60%|█████▉    | 14535/24227 [00:59<00:17, 551.16 examples/s]Tokenizing train dataset:  60%|██████    | 14627/24227 [00:59<00:20, 472.52 examples/s]Tokenizing train dataset:  54%|█████▍    | 13100/24227 [01:00<00:25, 444.04 examples/s]Tokenizing train dataset:  60%|██████    | 14607/24227 [00:59<00:20, 468.65 examples/s]Tokenizing train dataset:  61%|██████    | 14678/24227 [00:59<00:19, 480.35 examples/s]Tokenizing train dataset:  54%|█████▍    | 13156/24227 [01:00<00:23, 465.72 examples/s]Tokenizing train dataset:  61%|██████    | 14662/24227 [00:59<00:19, 486.52 examples/s]Tokenizing train dataset:  61%|██████    | 14728/24227 [00:59<00:19, 481.76 examples/s]Tokenizing train dataset:  55%|█████▍    | 13211/24227 [01:00<00:22, 485.71 examples/s]Tokenizing train dataset:  61%|██████    | 14782/24227 [01:00<00:19, 495.97 examples/s]Tokenizing train dataset:  61%|██████    | 14731/24227 [01:00<00:20, 472.20 examples/s]Tokenizing train dataset:  55%|█████▍    | 13275/24227 [01:00<00:23, 463.74 examples/s]Tokenizing train dataset:  61%|██████    | 14839/24227 [01:00<00:20, 448.77 examples/s]Tokenizing train dataset:  61%|██████    | 14797/24227 [01:00<00:20, 457.03 examples/s]Tokenizing train dataset:  55%|█████▌    | 13339/24227 [01:00<00:25, 422.80 examples/s]Tokenizing train dataset:  61%|██████▏   | 14891/24227 [01:00<00:22, 412.60 examples/s]Tokenizing train dataset:  55%|█████▌    | 13386/24227 [01:00<00:25, 428.48 examples/s]Tokenizing train dataset:  61%|██████▏   | 14856/24227 [01:00<00:25, 366.07 examples/s]Tokenizing train dataset:  62%|██████▏   | 14939/24227 [01:00<00:24, 376.61 examples/s]Tokenizing train dataset:  55%|█████▌    | 13444/24227 [01:00<00:23, 460.13 examples/s]Tokenizing train dataset:  62%|██████▏   | 14912/24227 [01:00<00:25, 365.94 examples/s]Tokenizing train dataset:  56%|█████▌    | 13502/24227 [01:00<00:22, 486.04 examples/s]Tokenizing train dataset:  62%|██████▏   | 14986/24227 [01:00<00:26, 354.97 examples/s]Tokenizing train dataset:  56%|█████▌    | 13563/24227 [01:00<00:20, 516.73 examples/s]Tokenizing train dataset:  62%|██████▏   | 14960/24227 [01:00<00:26, 348.07 examples/s]Tokenizing train dataset:  62%|██████▏   | 15037/24227 [01:00<00:26, 346.10 examples/s]Tokenizing train dataset:  56%|█████▋    | 13649/24227 [01:01<00:19, 533.86 examples/s]Tokenizing train dataset:  62%|██████▏   | 15013/24227 [01:00<00:26, 346.53 examples/s]Tokenizing train dataset:  62%|██████▏   | 15083/24227 [01:00<00:27, 330.39 examples/s]Tokenizing train dataset:  57%|█████▋    | 13733/24227 [01:01<00:19, 541.74 examples/s]Tokenizing train dataset:  62%|██████▏   | 15052/24227 [01:01<00:26, 350.76 examples/s]Tokenizing train dataset:  57%|█████▋    | 13799/24227 [01:01<00:18, 569.57 examples/s]Tokenizing train dataset:  62%|██████▏   | 15131/24227 [01:01<00:28, 324.50 examples/s]Tokenizing train dataset:  62%|██████▏   | 15104/24227 [01:01<00:26, 346.16 examples/s]Tokenizing train dataset:  57%|█████▋    | 13879/24227 [01:01<00:21, 488.50 examples/s]Tokenizing train dataset:  63%|██████▎   | 15174/24227 [01:01<00:36, 250.06 examples/s]Tokenizing train dataset:  63%|██████▎   | 15143/24227 [01:01<00:35, 257.96 examples/s]Tokenizing train dataset:  58%|█████▊    | 13958/24227 [01:01<00:20, 496.52 examples/s]Tokenizing train dataset:  63%|██████▎   | 15204/24227 [01:01<00:34, 258.44 examples/s]Tokenizing train dataset:  63%|██████▎   | 15179/24227 [01:01<00:32, 276.10 examples/s]Tokenizing train dataset:  58%|█████▊    | 14016/24227 [01:01<00:22, 462.82 examples/s]Tokenizing train dataset:  63%|██████▎   | 15213/24227 [01:01<00:31, 288.24 examples/s]Tokenizing train dataset:  63%|██████▎   | 15244/24227 [01:01<00:34, 258.24 examples/s]Tokenizing train dataset:  58%|█████▊    | 14086/24227 [01:02<00:21, 461.22 examples/s]Tokenizing train dataset:  63%|██████▎   | 15259/24227 [01:01<00:30, 290.62 examples/s]Tokenizing train dataset:  63%|██████▎   | 15288/24227 [01:01<00:33, 265.45 examples/s]Tokenizing train dataset:  58%|█████▊    | 14140/24227 [01:02<00:21, 477.63 examples/s]Tokenizing train dataset:  63%|██████▎   | 15309/24227 [01:01<00:29, 301.13 examples/s]Tokenizing train dataset:  63%|██████▎   | 15336/24227 [01:01<00:31, 280.00 examples/s]Tokenizing train dataset:  59%|█████▊    | 14218/24227 [01:02<00:20, 486.76 examples/s]Tokenizing train dataset:  63%|██████▎   | 15347/24227 [01:02<00:37, 237.86 examples/s]Tokenizing train dataset:  63%|██████▎   | 15373/24227 [01:02<00:40, 217.40 examples/s]Tokenizing train dataset:  59%|█████▉    | 14284/24227 [01:02<00:23, 428.69 examples/s]Tokenizing train dataset:  63%|██████▎   | 15384/24227 [01:02<00:38, 228.80 examples/s]Tokenizing train dataset:  59%|█████▉    | 14354/24227 [01:02<00:22, 432.65 examples/s]Tokenizing train dataset:  64%|██████▎   | 15413/24227 [01:02<00:39, 225.90 examples/s]Tokenizing train dataset:  64%|██████▎   | 15420/24227 [01:02<00:34, 253.62 examples/s]Tokenizing train dataset:  59%|█████▉    | 14411/24227 [01:02<00:21, 458.53 examples/s]Tokenizing train dataset:  64%|██████▍   | 15446/24227 [01:02<00:36, 243.84 examples/s]Tokenizing train dataset:  64%|██████▍   | 15450/24227 [01:02<00:33, 261.94 examples/s]Tokenizing train dataset:  60%|█████▉    | 14480/24227 [01:03<00:26, 373.70 examples/s]Tokenizing train dataset:  64%|██████▍   | 15483/24227 [01:02<00:44, 196.74 examples/s]Tokenizing train dataset:  64%|██████▍   | 15489/24227 [01:02<00:36, 237.28 examples/s]Tokenizing train dataset:  60%|██████    | 14547/24227 [01:03<00:26, 359.66 examples/s]Tokenizing train dataset:  64%|██████▍   | 15522/24227 [01:02<00:43, 199.54 examples/s]Tokenizing train dataset:  64%|██████▍   | 15526/24227 [01:03<00:40, 215.51 examples/s]Tokenizing train dataset:  64%|██████▍   | 15552/24227 [01:03<00:38, 223.52 examples/s]Tokenizing train dataset:  60%|██████    | 14615/24227 [01:03<00:25, 377.94 examples/s]Tokenizing train dataset:  64%|██████▍   | 15559/24227 [01:03<00:42, 205.71 examples/s]Tokenizing train dataset:  64%|██████▍   | 15583/24227 [01:03<00:35, 240.83 examples/s]Tokenizing train dataset:  61%|██████    | 14671/24227 [01:03<00:23, 411.40 examples/s]Tokenizing train dataset:  64%|██████▍   | 15597/24227 [01:03<00:36, 236.30 examples/s]Tokenizing train dataset:  64%|██████▍   | 15619/24227 [01:03<00:37, 230.17 examples/s]Tokenizing train dataset:  61%|██████    | 14726/24227 [01:03<00:24, 385.51 examples/s]Tokenizing train dataset:  65%|██████▍   | 15632/24227 [01:03<00:37, 231.35 examples/s]Tokenizing train dataset:  65%|██████▍   | 15660/24227 [01:03<00:36, 231.65 examples/s]Tokenizing train dataset:  61%|██████    | 14782/24227 [01:03<00:28, 333.94 examples/s]Tokenizing train dataset:  65%|██████▍   | 15694/24227 [01:03<00:33, 252.02 examples/s]Tokenizing train dataset:  65%|██████▍   | 15675/24227 [01:03<00:42, 199.11 examples/s]Tokenizing train dataset:  65%|██████▍   | 15733/24227 [01:03<00:30, 282.22 examples/s]Tokenizing train dataset:  61%|██████    | 14822/24227 [01:04<00:30, 312.49 examples/s]Tokenizing train dataset:  65%|██████▍   | 15710/24227 [01:03<00:38, 224.07 examples/s]Tokenizing train dataset:  65%|██████▌   | 15771/24227 [01:03<00:36, 233.15 examples/s]Tokenizing train dataset:  61%|██████▏   | 14860/24227 [01:04<00:41, 225.06 examples/s]Tokenizing train dataset:  65%|██████▌   | 15750/24227 [01:04<00:49, 172.84 examples/s]Tokenizing train dataset:  61%|██████▏   | 14896/24227 [01:04<00:37, 245.93 examples/s]Tokenizing train dataset:  65%|██████▌   | 15811/24227 [01:04<00:38, 217.50 examples/s]Tokenizing train dataset:  65%|██████▌   | 15786/24227 [01:04<00:41, 201.20 examples/s]Tokenizing train dataset:  65%|██████▌   | 15816/24227 [01:04<00:38, 219.21 examples/s]Tokenizing train dataset:  62%|██████▏   | 14932/24227 [01:04<00:38, 241.47 examples/s]Tokenizing train dataset:  65%|██████▌   | 15846/24227 [01:04<00:38, 216.47 examples/s]Tokenizing train dataset:  65%|██████▌   | 15846/24227 [01:04<00:35, 234.40 examples/s]Tokenizing train dataset:  62%|██████▏   | 14966/24227 [01:04<00:39, 232.72 examples/s]Tokenizing train dataset:  66%|██████▌   | 15887/24227 [01:04<00:36, 227.06 examples/s]Tokenizing train dataset:  66%|██████▌   | 15890/24227 [01:04<00:33, 248.46 examples/s]Tokenizing train dataset:  62%|██████▏   | 14998/24227 [01:04<00:37, 248.53 examples/s]Tokenizing train dataset:  66%|██████▌   | 15924/24227 [01:04<00:32, 255.49 examples/s]Tokenizing train dataset:  66%|██████▌   | 15929/24227 [01:04<00:29, 278.71 examples/s]Tokenizing train dataset:  62%|██████▏   | 15040/24227 [01:05<00:36, 253.86 examples/s]Tokenizing train dataset:  66%|██████▌   | 15960/24227 [01:04<00:33, 246.20 examples/s]Tokenizing train dataset:  66%|██████▌   | 15960/24227 [01:04<00:29, 284.47 examples/s]Tokenizing train dataset:  62%|██████▏   | 15075/24227 [01:05<00:33, 273.27 examples/s]Tokenizing train dataset:  66%|██████▌   | 16007/24227 [01:04<00:31, 262.52 examples/s]Tokenizing train dataset:  66%|██████▌   | 16007/24227 [01:04<00:28, 290.41 examples/s]Tokenizing train dataset:  62%|██████▏   | 15105/24227 [01:05<00:32, 279.18 examples/s]Tokenizing train dataset:  66%|██████▌   | 16048/24227 [01:05<00:38, 211.45 examples/s]Tokenizing train dataset:  66%|██████▌   | 16048/24227 [01:05<00:39, 205.53 examples/s]Tokenizing train dataset:  63%|██████▎   | 15142/24227 [01:05<00:45, 198.24 examples/s]Tokenizing train dataset:  66%|██████▋   | 16080/24227 [01:05<00:35, 227.77 examples/s]Tokenizing train dataset:  66%|██████▋   | 16084/24227 [01:05<00:40, 202.82 examples/s]Tokenizing train dataset:  63%|██████▎   | 15184/24227 [01:05<00:43, 207.15 examples/s]Tokenizing train dataset:  67%|██████▋   | 16127/24227 [01:05<00:32, 247.15 examples/s]Tokenizing train dataset:  67%|██████▋   | 16122/24227 [01:05<00:34, 233.34 examples/s]Tokenizing train dataset:  63%|██████▎   | 15218/24227 [01:05<00:43, 207.50 examples/s]Tokenizing train dataset:  67%|██████▋   | 16168/24227 [01:05<00:32, 248.27 examples/s]Tokenizing train dataset:  67%|██████▋   | 16161/24227 [01:05<00:30, 263.86 examples/s]Tokenizing train dataset:  63%|██████▎   | 15255/24227 [01:06<00:44, 202.14 examples/s]Tokenizing train dataset:  67%|██████▋   | 16207/24227 [01:05<00:33, 236.54 examples/s]Tokenizing train dataset:  67%|██████▋   | 16200/24227 [01:05<00:32, 249.26 examples/s]Tokenizing train dataset:  63%|██████▎   | 15290/24227 [01:06<00:47, 188.39 examples/s]Tokenizing train dataset:  67%|██████▋   | 16241/24227 [01:06<00:38, 206.06 examples/s]Tokenizing train dataset:  67%|██████▋   | 16239/24227 [01:06<00:38, 206.18 examples/s]Tokenizing train dataset:  63%|██████▎   | 15327/24227 [01:06<00:44, 198.48 examples/s]Tokenizing train dataset:  67%|██████▋   | 16280/24227 [01:06<00:38, 207.37 examples/s]Tokenizing train dataset:  67%|██████▋   | 16279/24227 [01:06<00:37, 211.69 examples/s]Tokenizing train dataset:  63%|██████▎   | 15354/24227 [01:06<00:42, 209.49 examples/s]Tokenizing train dataset:  67%|██████▋   | 16315/24227 [01:06<00:39, 199.25 examples/s]Tokenizing train dataset:  67%|██████▋   | 16315/24227 [01:06<00:37, 210.61 examples/s]Tokenizing train dataset:  64%|██████▎   | 15388/24227 [01:06<00:41, 212.24 examples/s]Tokenizing train dataset:  67%|██████▋   | 16351/24227 [01:06<00:34, 228.58 examples/s]Tokenizing train dataset:  67%|██████▋   | 16348/24227 [01:06<00:33, 232.73 examples/s]Tokenizing train dataset:  64%|██████▎   | 15415/24227 [01:06<00:39, 222.48 examples/s]Tokenizing train dataset:  68%|██████▊   | 16378/24227 [01:06<00:33, 235.23 examples/s]Tokenizing train dataset:  68%|██████▊   | 16380/24227 [01:06<00:35, 219.61 examples/s]Tokenizing train dataset:  68%|██████▊   | 16406/24227 [01:06<00:32, 243.85 examples/s]Tokenizing train dataset:  64%|██████▍   | 15450/24227 [01:07<00:41, 213.26 examples/s]Tokenizing train dataset:  68%|██████▊   | 16416/24227 [01:06<00:34, 224.46 examples/s]Tokenizing train dataset:  68%|██████▊   | 16441/24227 [01:06<00:34, 228.54 examples/s]Tokenizing train dataset:  64%|██████▍   | 15486/24227 [01:07<00:43, 202.58 examples/s]Tokenizing train dataset:  68%|██████▊   | 16452/24227 [01:07<00:39, 197.17 examples/s]Tokenizing train dataset:  68%|██████▊   | 16478/24227 [01:07<00:36, 210.35 examples/s]Tokenizing train dataset:  64%|██████▍   | 15521/24227 [01:07<00:43, 200.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 16478/24227 [01:07<00:37, 208.43 examples/s]Tokenizing train dataset:  68%|██████▊   | 16525/24227 [01:07<00:29, 262.92 examples/s]Tokenizing train dataset:  64%|██████▍   | 15542/24227 [01:07<00:43, 201.07 examples/s]Tokenizing train dataset:  68%|██████▊   | 16511/24227 [01:07<00:33, 231.81 examples/s]Tokenizing train dataset:  68%|██████▊   | 16570/24227 [01:07<00:25, 298.66 examples/s]Tokenizing train dataset:  64%|██████▍   | 15582/24227 [01:07<00:40, 214.24 examples/s]Tokenizing train dataset:  68%|██████▊   | 16561/24227 [01:07<00:26, 293.44 examples/s]Tokenizing train dataset:  69%|██████▊   | 16604/24227 [01:07<00:26, 284.19 examples/s]Tokenizing train dataset:  64%|██████▍   | 15610/24227 [01:07<00:38, 224.32 examples/s]Tokenizing train dataset:  69%|██████▊   | 16630/24227 [01:07<00:19, 386.66 examples/s]Tokenizing train dataset:  69%|██████▊   | 16643/24227 [01:07<00:24, 308.80 examples/s]Tokenizing train dataset:  65%|██████▍   | 15635/24227 [01:07<00:37, 227.64 examples/s]Tokenizing train dataset:  69%|██████▉   | 16684/24227 [01:07<00:17, 422.11 examples/s]Tokenizing train dataset:  69%|██████▉   | 16700/24227 [01:07<00:20, 374.74 examples/s]Tokenizing train dataset:  65%|██████▍   | 15672/24227 [01:07<00:33, 258.93 examples/s]Tokenizing train dataset:  69%|██████▉   | 16757/24227 [01:07<00:20, 365.71 examples/s]Tokenizing train dataset:  69%|██████▉   | 16770/24227 [01:07<00:21, 344.98 examples/s]Tokenizing train dataset:  65%|██████▍   | 15712/24227 [01:08<00:38, 222.58 examples/s]Tokenizing train dataset:  69%|██████▉   | 16800/24227 [01:07<00:19, 377.92 examples/s]Tokenizing train dataset:  69%|██████▉   | 16819/24227 [01:08<00:19, 375.13 examples/s]Tokenizing train dataset:  65%|██████▌   | 15749/24227 [01:08<00:33, 252.27 examples/s]Tokenizing train dataset:  70%|██████▉   | 16860/24227 [01:08<00:17, 428.31 examples/s]Tokenizing train dataset:  70%|██████▉   | 16885/24227 [01:08<00:16, 440.28 examples/s]Tokenizing train dataset:  65%|██████▌   | 15786/24227 [01:08<00:36, 232.51 examples/s]Tokenizing train dataset:  70%|██████▉   | 16934/24227 [01:08<00:16, 448.03 examples/s]Tokenizing train dataset:  70%|██████▉   | 16952/24227 [01:08<00:16, 438.04 examples/s]Tokenizing train dataset:  65%|██████▌   | 15812/24227 [01:08<00:35, 236.83 examples/s]Tokenizing train dataset:  70%|███████   | 17006/24227 [01:08<00:15, 458.05 examples/s]Tokenizing train dataset:  70%|███████   | 17020/24227 [01:08<00:15, 480.08 examples/s]Tokenizing train dataset:  65%|██████▌   | 15846/24227 [01:08<00:40, 208.64 examples/s]Tokenizing train dataset:  70%|███████   | 17078/24227 [01:08<00:16, 427.47 examples/s]Tokenizing train dataset:  71%|███████   | 17094/24227 [01:08<00:15, 470.03 examples/s]Tokenizing train dataset:  66%|██████▌   | 15882/24227 [01:08<00:38, 216.57 examples/s]Tokenizing train dataset:  71%|███████   | 17157/24227 [01:08<00:15, 450.82 examples/s]Tokenizing train dataset:  71%|███████   | 17170/24227 [01:08<00:15, 469.42 examples/s]Tokenizing train dataset:  66%|██████▌   | 15906/24227 [01:09<00:37, 220.19 examples/s]Tokenizing train dataset:  71%|███████   | 17209/24227 [01:08<00:15, 458.81 examples/s]Tokenizing train dataset:  71%|███████   | 17251/24227 [01:08<00:14, 487.57 examples/s]Tokenizing train dataset:  71%|███████   | 17261/24227 [01:08<00:14, 472.94 examples/s]Tokenizing train dataset:  66%|██████▌   | 15944/24227 [01:09<00:36, 227.56 examples/s]Tokenizing train dataset:  71%|███████▏  | 17305/24227 [01:08<00:13, 496.84 examples/s]Tokenizing train dataset:  72%|███████▏  | 17329/24227 [01:09<00:13, 523.79 examples/s]Tokenizing train dataset:  66%|██████▌   | 15975/24227 [01:09<00:39, 210.62 examples/s]Tokenizing train dataset:  72%|███████▏  | 17381/24227 [01:09<00:13, 495.05 examples/s]Tokenizing train dataset:  72%|███████▏  | 17410/24227 [01:09<00:12, 527.15 examples/s]Tokenizing train dataset:  66%|██████▌   | 16015/24227 [01:09<00:36, 225.21 examples/s]Tokenizing train dataset:  72%|███████▏  | 17456/24227 [01:09<00:13, 490.41 examples/s]Tokenizing train dataset:  72%|███████▏  | 17492/24227 [01:09<00:12, 527.94 examples/s]Tokenizing train dataset:  66%|██████▋   | 16055/24227 [01:09<00:36, 225.49 examples/s]Tokenizing train dataset:  72%|███████▏  | 17519/24227 [01:09<00:15, 434.72 examples/s]Tokenizing train dataset:  72%|███████▏  | 17555/24227 [01:09<00:13, 483.75 examples/s]Tokenizing train dataset:  66%|██████▋   | 16090/24227 [01:09<00:40, 202.12 examples/s]Tokenizing train dataset:  73%|███████▎  | 17580/24227 [01:09<00:20, 317.28 examples/s]Tokenizing train dataset:  67%|██████▋   | 16112/24227 [01:10<00:43, 187.86 examples/s]Tokenizing train dataset:  73%|███████▎  | 17612/24227 [01:09<00:21, 306.02 examples/s]Tokenizing train dataset:  73%|███████▎  | 17636/24227 [01:09<00:18, 355.70 examples/s]Tokenizing train dataset:  67%|██████▋   | 16147/24227 [01:10<00:36, 218.70 examples/s]Tokenizing train dataset:  73%|███████▎  | 17676/24227 [01:09<00:18, 361.18 examples/s]Tokenizing train dataset:  73%|███████▎  | 17712/24227 [01:10<00:19, 342.83 examples/s]Tokenizing train dataset:  67%|██████▋   | 16185/24227 [01:10<00:40, 198.59 examples/s]Tokenizing train dataset:  73%|███████▎  | 17750/24227 [01:10<00:17, 370.48 examples/s]Tokenizing train dataset:  73%|███████▎  | 17787/24227 [01:10<00:17, 366.82 examples/s]Tokenizing train dataset:  67%|██████▋   | 16220/24227 [01:10<00:40, 198.08 examples/s]Tokenizing train dataset:  74%|███████▎  | 17820/24227 [01:10<00:17, 376.34 examples/s]Tokenizing train dataset:  74%|███████▎  | 17829/24227 [01:10<00:17, 375.86 examples/s]Tokenizing train dataset:  67%|██████▋   | 16246/24227 [01:10<00:38, 208.46 examples/s]Tokenizing train dataset:  74%|███████▎  | 17866/24227 [01:10<00:16, 390.18 examples/s]Tokenizing train dataset:  74%|███████▍  | 17891/24227 [01:10<00:20, 313.44 examples/s]Tokenizing train dataset:  67%|██████▋   | 16282/24227 [01:10<00:44, 177.94 examples/s]Tokenizing train dataset:  74%|███████▍  | 17925/24227 [01:10<00:19, 319.46 examples/s]Tokenizing train dataset:  74%|███████▍  | 17962/24227 [01:10<00:20, 304.09 examples/s]Tokenizing train dataset:  74%|███████▍  | 17962/24227 [01:10<00:18, 330.90 examples/s]Tokenizing train dataset:  67%|██████▋   | 16314/24227 [01:11<00:45, 174.79 examples/s]Tokenizing train dataset:  74%|███████▍  | 18031/24227 [01:10<00:16, 377.69 examples/s]Tokenizing train dataset:  74%|███████▍  | 17999/24227 [01:10<00:18, 336.64 examples/s]Tokenizing train dataset:  67%|██████▋   | 16335/24227 [01:11<00:44, 175.74 examples/s]Tokenizing train dataset:  75%|███████▍  | 18107/24227 [01:11<00:13, 458.69 examples/s]Tokenizing train dataset:  75%|███████▍  | 18070/24227 [01:11<00:14, 411.90 examples/s]Tokenizing train dataset:  68%|██████▊   | 16366/24227 [01:11<00:44, 176.95 examples/s]Tokenizing train dataset:  75%|███████▌  | 18186/24227 [01:11<00:12, 472.72 examples/s]Tokenizing train dataset:  75%|███████▍  | 18147/24227 [01:11<00:13, 438.91 examples/s]Tokenizing train dataset:  68%|██████▊   | 16399/24227 [01:11<00:49, 158.95 examples/s]Tokenizing train dataset:  75%|███████▌  | 18267/24227 [01:11<00:15, 388.55 examples/s]Tokenizing train dataset:  75%|███████▌  | 18233/24227 [01:11<00:15, 389.50 examples/s]Tokenizing train dataset:  68%|██████▊   | 16416/24227 [01:11<00:49, 157.00 examples/s]Tokenizing train dataset:  76%|███████▌  | 18330/24227 [01:11<00:13, 432.45 examples/s]Tokenizing train dataset:  68%|██████▊   | 16434/24227 [01:11<00:48, 160.62 examples/s]Tokenizing train dataset:  76%|███████▌  | 18305/24227 [01:11<00:14, 404.79 examples/s]Tokenizing train dataset:  76%|███████▌  | 18390/24227 [01:11<00:12, 466.70 examples/s]Tokenizing train dataset:  68%|██████▊   | 16451/24227 [01:12<00:57, 135.65 examples/s]Tokenizing train dataset:  76%|███████▌  | 18382/24227 [01:11<00:16, 361.05 examples/s]Tokenizing train dataset:  76%|███████▌  | 18466/24227 [01:11<00:14, 399.68 examples/s]Tokenizing train dataset:  68%|██████▊   | 16480/24227 [01:12<00:46, 167.21 examples/s]Tokenizing train dataset:  68%|██████▊   | 16515/24227 [01:12<00:40, 188.87 examples/s]Tokenizing train dataset:  76%|███████▌  | 18454/24227 [01:12<00:16, 360.70 examples/s]Tokenizing train dataset:  76%|███████▋  | 18528/24227 [01:12<00:15, 370.79 examples/s]Tokenizing train dataset:  68%|██████▊   | 16563/24227 [01:12<00:30, 255.01 examples/s]Tokenizing train dataset:  76%|███████▋  | 18514/24227 [01:12<00:14, 401.53 examples/s]Tokenizing train dataset:  77%|███████▋  | 18584/24227 [01:12<00:13, 406.53 examples/s]Tokenizing train dataset:  69%|██████▊   | 16624/24227 [01:12<00:22, 341.36 examples/s]Tokenizing train dataset:  77%|███████▋  | 18568/24227 [01:12<00:13, 428.22 examples/s]Tokenizing train dataset:  77%|███████▋  | 18648/24227 [01:12<00:12, 455.64 examples/s]Tokenizing train dataset:  69%|██████▉   | 16670/24227 [01:12<00:20, 370.38 examples/s]Tokenizing train dataset:  77%|███████▋  | 18633/24227 [01:12<00:11, 474.57 examples/s]Tokenizing train dataset:  69%|██████▉   | 16725/24227 [01:12<00:18, 414.58 examples/s]Tokenizing train dataset:  77%|███████▋  | 18727/24227 [01:12<00:11, 462.68 examples/s]Tokenizing train dataset:  77%|███████▋  | 18707/24227 [01:12<00:10, 532.13 examples/s]Tokenizing train dataset:  69%|██████▉   | 16783/24227 [01:12<00:16, 458.83 examples/s]Tokenizing train dataset:  78%|███████▊  | 18796/24227 [01:12<00:10, 512.04 examples/s]Tokenizing train dataset:  77%|███████▋  | 18770/24227 [01:12<00:09, 553.20 examples/s]Tokenizing train dataset:  70%|██████▉   | 16850/24227 [01:13<00:17, 415.20 examples/s]Tokenizing train dataset:  78%|███████▊  | 18872/24227 [01:12<00:11, 458.62 examples/s]Tokenizing train dataset:  78%|███████▊  | 18849/24227 [01:12<00:11, 450.74 examples/s]Tokenizing train dataset:  70%|██████▉   | 16914/24227 [01:13<00:15, 469.11 examples/s]Tokenizing train dataset:  78%|███████▊  | 18926/24227 [01:12<00:11, 475.05 examples/s]Tokenizing train dataset:  78%|███████▊  | 18927/24227 [01:13<00:11, 453.31 examples/s]Tokenizing train dataset:  70%|███████   | 16980/24227 [01:13<00:19, 378.40 examples/s]Tokenizing train dataset:  78%|███████▊  | 18992/24227 [01:13<00:12, 402.83 examples/s]Tokenizing train dataset:  78%|███████▊  | 18990/24227 [01:13<00:10, 489.59 examples/s]Tokenizing train dataset:  70%|███████   | 17028/24227 [01:13<00:18, 399.49 examples/s]Tokenizing train dataset:  79%|███████▊  | 19063/24227 [01:13<00:12, 419.11 examples/s]Tokenizing train dataset:  79%|███████▊  | 19050/24227 [01:13<00:13, 379.41 examples/s]Tokenizing train dataset:  71%|███████   | 17100/24227 [01:13<00:18, 378.34 examples/s]Tokenizing train dataset:  79%|███████▉  | 19142/24227 [01:13<00:12, 421.73 examples/s]Tokenizing train dataset:  79%|███████▉  | 19101/24227 [01:13<00:12, 404.10 examples/s]Tokenizing train dataset:  71%|███████   | 17169/24227 [01:13<00:15, 442.72 examples/s]Tokenizing train dataset:  79%|███████▉  | 19219/24227 [01:13<00:11, 430.23 examples/s]Tokenizing train dataset:  79%|███████▉  | 19179/24227 [01:13<00:12, 415.27 examples/s]Tokenizing train dataset:  71%|███████   | 17249/24227 [01:13<00:15, 449.30 examples/s]Tokenizing train dataset:  80%|███████▉  | 19278/24227 [01:13<00:10, 461.72 examples/s]Tokenizing train dataset:  79%|███████▉  | 19251/24227 [01:13<00:10, 477.66 examples/s]Tokenizing train dataset:  71%|███████▏  | 17300/24227 [01:14<00:15, 461.71 examples/s]Tokenizing train dataset:  80%|███████▉  | 19333/24227 [01:13<00:10, 476.49 examples/s]Tokenizing train dataset:  80%|███████▉  | 19318/24227 [01:13<00:11, 442.48 examples/s]Tokenizing train dataset:  72%|███████▏  | 17372/24227 [01:14<00:18, 365.86 examples/s]Tokenizing train dataset:  80%|████████  | 19393/24227 [01:14<00:17, 283.41 examples/s]Tokenizing train dataset:  80%|███████▉  | 19371/24227 [01:14<00:15, 314.91 examples/s]Tokenizing train dataset:  72%|███████▏  | 17439/24227 [01:14<00:21, 317.05 examples/s]Tokenizing train dataset:  80%|████████  | 19441/24227 [01:14<00:15, 314.03 examples/s]Tokenizing train dataset:  80%|████████  | 19439/24227 [01:14<00:14, 339.51 examples/s]Tokenizing train dataset:  81%|████████  | 19518/24227 [01:14<00:11, 398.44 examples/s]Tokenizing train dataset:  72%|███████▏  | 17502/24227 [01:14<00:19, 339.30 examples/s]Tokenizing train dataset:  81%|████████  | 19532/24227 [01:14<00:10, 447.33 examples/s]Tokenizing train dataset:  81%|████████  | 19638/24227 [01:14<00:08, 566.29 examples/s]Tokenizing train dataset:  81%|████████  | 19598/24227 [01:14<00:09, 469.43 examples/s]Tokenizing train dataset:  72%|███████▏  | 17560/24227 [01:14<00:19, 334.04 examples/s]Tokenizing train dataset:  82%|████████▏ | 19762/24227 [01:14<00:06, 641.78 examples/s]Tokenizing train dataset:  81%|████████▏ | 19711/24227 [01:14<00:07, 613.52 examples/s]Tokenizing train dataset:  82%|████████▏ | 19863/24227 [01:14<00:06, 724.02 examples/s]Tokenizing train dataset:  73%|███████▎  | 17623/24227 [01:15<00:18, 352.84 examples/s]Tokenizing train dataset:  82%|████████▏ | 19823/24227 [01:14<00:06, 732.75 examples/s]Tokenizing train dataset:  82%|████████▏ | 19959/24227 [01:14<00:05, 781.41 examples/s]Tokenizing train dataset:  73%|███████▎  | 17695/24227 [01:15<00:18, 356.06 examples/s]Tokenizing train dataset:  82%|████████▏ | 19946/24227 [01:15<00:06, 697.47 examples/s]Tokenizing train dataset:  83%|████████▎ | 20089/24227 [01:15<00:05, 691.20 examples/s]Tokenizing train dataset:  73%|███████▎  | 17767/24227 [01:15<00:15, 422.54 examples/s]Tokenizing train dataset:  83%|████████▎ | 20068/24227 [01:15<00:05, 815.08 examples/s]Tokenizing train dataset:  83%|████████▎ | 20208/24227 [01:15<00:05, 798.19 examples/s]Tokenizing train dataset:  74%|███████▎  | 17828/24227 [01:15<00:16, 390.83 examples/s]Tokenizing train dataset:  84%|████████▍ | 20316/24227 [01:15<00:04, 863.17 examples/s]Tokenizing train dataset:  83%|████████▎ | 20196/24227 [01:15<00:05, 748.40 examples/s]Tokenizing train dataset:  74%|███████▍  | 17885/24227 [01:15<00:14, 426.06 examples/s]Tokenizing train dataset:  84%|████████▍ | 20450/24227 [01:15<00:04, 866.29 examples/s]Tokenizing train dataset:  84%|████████▍ | 20320/24227 [01:15<00:05, 766.29 examples/s]Tokenizing train dataset:  74%|███████▍  | 17956/24227 [01:15<00:15, 405.71 examples/s]Tokenizing train dataset:  85%|████████▍ | 20570/24227 [01:15<00:05, 720.22 examples/s]Tokenizing train dataset:  84%|████████▍ | 20443/24227 [01:15<00:05, 654.74 examples/s]Tokenizing train dataset:  74%|███████▍  | 18029/24227 [01:16<00:14, 425.57 examples/s]Tokenizing train dataset:  85%|████████▌ | 20665/24227 [01:15<00:04, 766.51 examples/s]Tokenizing train dataset:  85%|████████▍ | 20550/24227 [01:15<00:05, 731.28 examples/s]Tokenizing train dataset:  86%|████████▌ | 20763/24227 [01:15<00:04, 814.69 examples/s]Tokenizing train dataset:  75%|███████▍  | 18108/24227 [01:16<00:13, 450.08 examples/s]Tokenizing train dataset:  85%|████████▌ | 20662/24227 [01:15<00:04, 812.53 examples/s]Tokenizing train dataset:  86%|████████▋ | 20910/24227 [01:16<00:03, 862.29 examples/s]Tokenizing train dataset:  75%|███████▌  | 18178/24227 [01:16<00:14, 428.49 examples/s]Tokenizing train dataset:  86%|████████▌ | 20787/24227 [01:16<00:04, 740.13 examples/s]Tokenizing train dataset:  87%|████████▋ | 21033/24227 [01:16<00:04, 758.82 examples/s]Tokenizing train dataset:  75%|███████▌  | 18256/24227 [01:16<00:14, 423.54 examples/s]Tokenizing train dataset:  86%|████████▋ | 20910/24227 [01:16<00:04, 740.36 examples/s]Tokenizing train dataset:  87%|████████▋ | 21130/24227 [01:16<00:03, 802.69 examples/s]Tokenizing train dataset:  76%|███████▌  | 18326/24227 [01:16<00:12, 476.57 examples/s]Tokenizing train dataset:  87%|████████▋ | 21034/24227 [01:16<00:05, 618.01 examples/s]Tokenizing train dataset:  88%|████████▊ | 21259/24227 [01:16<00:04, 709.66 examples/s]Tokenizing train dataset:  76%|███████▌  | 18396/24227 [01:16<00:14, 410.64 examples/s]Tokenizing train dataset:  87%|████████▋ | 21107/24227 [01:16<00:04, 637.76 examples/s]Tokenizing train dataset:  88%|████████▊ | 21337/24227 [01:16<00:03, 722.95 examples/s]Tokenizing train dataset:  76%|███████▌  | 18446/24227 [01:17<00:13, 427.51 examples/s]Tokenizing train dataset:  87%|████████▋ | 21181/24227 [01:16<00:04, 657.25 examples/s]Tokenizing train dataset:  89%|████████▊ | 21467/24227 [01:16<00:03, 765.84 examples/s]Tokenizing train dataset:  88%|████████▊ | 21261/24227 [01:16<00:04, 688.50 examples/s]Tokenizing train dataset:  76%|███████▋  | 18514/24227 [01:17<00:14, 399.03 examples/s]Tokenizing train dataset:  77%|███████▋  | 18564/24227 [01:17<00:13, 415.96 examples/s]Tokenizing train dataset:  89%|████████▉ | 21590/24227 [01:17<00:03, 747.56 examples/s]Tokenizing train dataset:  88%|████████▊ | 21388/24227 [01:17<00:03, 738.90 examples/s]Tokenizing train dataset:  77%|███████▋  | 18625/24227 [01:17<00:12, 458.22 examples/s]Tokenizing train dataset:  90%|████████▉ | 21691/24227 [01:17<00:03, 803.91 examples/s]Tokenizing train dataset:  89%|████████▊ | 21499/24227 [01:17<00:03, 825.92 examples/s]Tokenizing train dataset:  77%|███████▋  | 18698/24227 [01:17<00:10, 521.07 examples/s]Tokenizing train dataset:  90%|████████▉ | 21792/24227 [01:17<00:02, 849.59 examples/s]Tokenizing train dataset:  89%|████████▉ | 21597/24227 [01:17<00:03, 862.47 examples/s]Tokenizing train dataset:  77%|███████▋  | 18755/24227 [01:17<00:10, 530.61 examples/s]Tokenizing train dataset:  90%|█████████ | 21884/24227 [01:17<00:02, 866.44 examples/s]Tokenizing train dataset:  90%|████████▉ | 21744/24227 [01:17<00:02, 901.51 examples/s]Tokenizing train dataset:  78%|███████▊  | 18834/24227 [01:17<00:11, 487.97 examples/s]Tokenizing train dataset:  91%|█████████ | 22005/24227 [01:17<00:02, 759.70 examples/s]Tokenizing train dataset:  90%|█████████ | 21871/24227 [01:17<00:03, 627.54 examples/s]Tokenizing train dataset:  78%|███████▊  | 18910/24227 [01:18<00:12, 416.26 examples/s]Tokenizing train dataset:  91%|█████████▏| 22127/24227 [01:17<00:03, 668.20 examples/s]Tokenizing train dataset:  91%|█████████ | 21991/24227 [01:17<00:03, 651.07 examples/s]Tokenizing train dataset:  78%|███████▊  | 18980/24227 [01:18<00:12, 427.21 examples/s]Tokenizing train dataset:  92%|█████████▏| 22253/24227 [01:17<00:02, 713.77 examples/s]Tokenizing train dataset:  91%|█████████▏| 22117/24227 [01:18<00:03, 694.20 examples/s]Tokenizing train dataset:  79%|███████▊  | 19040/24227 [01:18<00:12, 414.77 examples/s]Tokenizing train dataset:  92%|█████████▏| 22373/24227 [01:18<00:02, 708.88 examples/s]Tokenizing train dataset:  92%|█████████▏| 22224/24227 [01:18<00:02, 767.36 examples/s]Tokenizing train dataset:  79%|███████▉  | 19102/24227 [01:18<00:11, 454.15 examples/s]Tokenizing train dataset:  93%|█████████▎| 22499/24227 [01:18<00:02, 729.29 examples/s]Tokenizing train dataset:  92%|█████████▏| 22323/24227 [01:18<00:02, 815.36 examples/s]Tokenizing train dataset:  79%|███████▉  | 19167/24227 [01:18<00:10, 498.39 examples/s]Tokenizing train dataset:  93%|█████████▎| 22602/24227 [01:18<00:02, 787.73 examples/s]Tokenizing train dataset:  93%|█████████▎| 22425/24227 [01:18<00:02, 861.42 examples/s]Tokenizing train dataset:  79%|███████▉  | 19234/24227 [01:18<00:09, 538.63 examples/s]Tokenizing train dataset:  94%|█████████▍| 22716/24227 [01:18<00:01, 865.48 examples/s]Tokenizing train dataset:  93%|█████████▎| 22532/24227 [01:18<00:01, 913.91 examples/s]Tokenizing train dataset:  80%|███████▉  | 19293/24227 [01:18<00:08, 548.87 examples/s]Tokenizing train dataset:  94%|█████████▍| 22844/24227 [01:18<00:01, 800.36 examples/s]Tokenizing train dataset:  94%|█████████▎| 22656/24227 [01:18<00:01, 808.19 examples/s]Tokenizing train dataset:  80%|███████▉  | 19374/24227 [01:19<00:10, 457.67 examples/s]Tokenizing train dataset:  95%|█████████▍| 22959/24227 [01:18<00:01, 877.35 examples/s]Tokenizing train dataset:  94%|█████████▍| 22774/24227 [01:18<00:01, 891.77 examples/s]Tokenizing train dataset:  95%|█████████▌| 23061/24227 [01:18<00:01, 910.78 examples/s]Tokenizing train dataset:  80%|████████  | 19472/24227 [01:19<00:09, 512.85 examples/s]Tokenizing train dataset:  95%|█████████▍| 22933/24227 [01:18<00:01, 944.47 examples/s]Tokenizing train dataset:  96%|█████████▌| 23170/24227 [01:18<00:01, 954.96 examples/s]Tokenizing train dataset:  81%|████████  | 19572/24227 [01:19<00:07, 619.53 examples/s]Tokenizing train dataset:  95%|█████████▌| 23040/24227 [01:18<00:01, 972.69 examples/s]Tokenizing train dataset:  81%|████████  | 19673/24227 [01:19<00:06, 711.31 examples/s]Tokenizing train dataset:  96%|█████████▌| 23317/24227 [01:19<00:00, 960.56 examples/s]Tokenizing train dataset:  96%|█████████▌| 23160/24227 [01:19<00:01, 1027.65 examples/s]Tokenizing train dataset:  82%|████████▏ | 19800/24227 [01:19<00:06, 712.80 examples/s]Tokenizing train dataset:  97%|█████████▋| 23442/24227 [01:19<00:00, 907.90 examples/s]Tokenizing train dataset:  96%|█████████▌| 23287/24227 [01:19<00:01, 937.36 examples/s] Tokenizing train dataset:  82%|████████▏ | 19910/24227 [01:19<00:05, 799.37 examples/s]Tokenizing train dataset:  97%|█████████▋| 23543/24227 [01:19<00:00, 930.16 examples/s]Tokenizing train dataset:  97%|█████████▋| 23392/24227 [01:19<00:00, 963.01 examples/s]Tokenizing train dataset:  83%|████████▎ | 20041/24227 [01:19<00:05, 823.20 examples/s]Tokenizing train dataset:  98%|█████████▊| 23666/24227 [01:19<00:00, 890.81 examples/s]Tokenizing train dataset:  97%|█████████▋| 23521/24227 [01:19<00:00, 923.62 examples/s]Tokenizing train dataset:  83%|████████▎ | 20182/24227 [01:19<00:04, 858.98 examples/s]Tokenizing train dataset:  98%|█████████▊| 23805/24227 [01:19<00:00, 898.82 examples/s]Tokenizing train dataset:  98%|█████████▊| 23646/24227 [01:19<00:00, 883.78 examples/s]Tokenizing train dataset:  84%|████████▎ | 20272/24227 [01:20<00:04, 867.92 examples/s]Tokenizing train dataset:  99%|█████████▉| 23939/24227 [01:19<00:00, 891.96 examples/s]Tokenizing train dataset:  98%|█████████▊| 23769/24227 [01:19<00:00, 863.09 examples/s]Tokenizing train dataset:  84%|████████▍ | 20384/24227 [01:20<00:04, 929.88 examples/s]Tokenizing train dataset:  99%|█████████▉| 24054/24227 [01:19<00:00, 950.28 examples/s]Tokenizing train dataset:  99%|█████████▊| 23884/24227 [01:19<00:00, 925.89 examples/s]Tokenizing train dataset:  85%|████████▍ | 20510/24227 [01:20<00:04, 895.03 examples/s]Tokenizing train dataset: 100%|█████████▉| 24174/24227 [01:20<00:00, 1008.80 examples/s]Tokenizing train dataset:  99%|█████████▉| 23997/24227 [01:20<00:00, 973.83 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:20<00:00, 302.37 examples/s] 
Tokenizing train dataset:  85%|████████▌ | 20614/24227 [01:20<00:03, 928.13 examples/s]Tokenizing train dataset: 100%|█████████▉| 24159/24227 [01:20<00:00, 1008.84 examples/s]Tokenizing train dataset:  86%|████████▌ | 20748/24227 [01:20<00:03, 914.56 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:20<00:00, 301.63 examples/s] 
Tokenizing train dataset:  86%|████████▌ | 20866/24227 [01:20<00:04, 838.10 examples/s]Tokenizing train dataset:  87%|████████▋ | 20983/24227 [01:20<00:03, 816.75 examples/s]Tokenizing train dataset:  87%|████████▋ | 21090/24227 [01:20<00:03, 871.73 examples/s]Tokenizing train dataset:  88%|████████▊ | 21212/24227 [01:21<00:03, 818.41 examples/s]Tokenizing train dataset:  88%|████████▊ | 21310/24227 [01:21<00:03, 853.37 examples/s]Tokenizing train dataset:  88%|████████▊ | 21427/24227 [01:21<00:03, 931.30 examples/s]Tokenizing train dataset:  89%|████████▉ | 21548/24227 [01:21<00:03, 814.95 examples/s]Tokenizing train dataset:  89%|████████▉ | 21654/24227 [01:21<00:02, 868.55 examples/s]Tokenizing train dataset:  90%|████████▉ | 21770/24227 [01:21<00:02, 938.29 examples/s]Tokenizing train dataset:  90%|█████████ | 21873/24227 [01:21<00:02, 960.64 examples/s]Tokenizing train dataset:  91%|█████████ | 21990/24227 [01:22<00:03, 646.05 examples/s]Tokenizing train dataset:  91%|█████████ | 22093/24227 [01:22<00:02, 719.85 examples/s]Tokenizing train dataset:  92%|█████████▏| 22213/24227 [01:22<00:02, 688.23 examples/s]Tokenizing train dataset:  92%|█████████▏| 22351/24227 [01:22<00:02, 751.60 examples/s]Tokenizing train dataset:  93%|█████████▎| 22476/24227 [01:22<00:02, 733.00 examples/s]Tokenizing train dataset:  93%|█████████▎| 22591/24227 [01:22<00:02, 670.49 examples/s]Tokenizing train dataset:  94%|█████████▍| 22714/24227 [01:23<00:02, 703.07 examples/s]Tokenizing train dataset:  94%|█████████▍| 22820/24227 [01:23<00:01, 773.70 examples/s]Tokenizing train dataset:  95%|█████████▍| 22932/24227 [01:23<00:01, 849.53 examples/s]Tokenizing train dataset:  95%|█████████▌| 23042/24227 [01:23<00:01, 908.70 examples/s]Tokenizing train dataset:  96%|█████████▌| 23141/24227 [01:23<00:01, 926.75 examples/s]Tokenizing train dataset:  96%|█████████▌| 23246/24227 [01:23<00:01, 959.25 examples/s]Tokenizing train dataset:  96%|█████████▋| 23361/24227 [01:23<00:00, 1010.18 examples/s]Tokenizing train dataset:  97%|█████████▋| 23483/24227 [01:23<00:00, 885.40 examples/s] Tokenizing train dataset:  97%|█████████▋| 23595/24227 [01:24<00:00, 943.54 examples/s]Tokenizing train dataset:  98%|█████████▊| 23751/24227 [01:24<00:00, 974.80 examples/s]Tokenizing train dataset:  99%|█████████▊| 23876/24227 [01:24<00:00, 873.16 examples/s]Tokenizing train dataset:  99%|█████████▉| 23992/24227 [01:24<00:00, 814.90 examples/s]Tokenizing train dataset: 100%|█████████▉| 24123/24227 [01:24<00:00, 830.21 examples/s]Tokenizing train dataset: 100%|██████████| 24227/24227 [01:24<00:00, 285.77 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  57%|█████▋    | 545/953 [00:00<00:00, 5368.76 examples/s]Extracting prompt in eval dataset:  57%|█████▋    | 540/953 [00:00<00:00, 5320.22 examples/s]Extracting prompt in eval dataset:  57%|█████▋    | 542/953 [00:00<00:00, 5379.02 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2978.21 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2880.21 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2002.70 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  28%|██▊       | 267/953 [00:00<00:00, 2623.76 examples/s]Applying chat template to eval dataset:  28%|██▊       | 267/953 [00:00<00:00, 2635.00 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  69%|██████▉   | 656/953 [00:00<00:00, 2599.09 examples/s]Applying chat template to eval dataset:  66%|██████▋   | 632/953 [00:00<00:00, 2489.56 examples/s]Applying chat template to eval dataset:  24%|██▍       | 231/953 [00:00<00:00, 2274.49 examples/s]Applying chat template to eval dataset:  97%|█████████▋| 920/953 [00:00<00:00, 1729.65 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1734.89 examples/s]
Applying chat template to eval dataset:  95%|█████████▌| 907/953 [00:00<00:00, 1441.38 examples/s]Applying chat template to eval dataset:  53%|█████▎    | 504/953 [00:00<00:00, 1778.69 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1606.85 examples/s]
Applying chat template to eval dataset:  84%|████████▍ | 802/953 [00:00<00:00, 1867.11 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1579.88 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 257.87 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   6%|▌         | 53/953 [00:00<00:06, 129.63 examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 256.95 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:06, 138.50 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:  10%|█         | 99/953 [00:00<00:05, 152.47 examples/s]Tokenizing eval dataset:   6%|▋         | 60/953 [00:00<00:04, 221.44 examples/s]Tokenizing eval dataset:   2%|▏         | 23/953 [00:00<00:04, 207.42 examples/s]Tokenizing eval dataset:  12%|█▏        | 118/953 [00:00<00:05, 160.51 examples/s]Tokenizing eval dataset:   9%|▉         | 85/953 [00:00<00:03, 225.14 examples/s]Tokenizing eval dataset:   6%|▌         | 53/953 [00:00<00:04, 199.53 examples/s]Tokenizing eval dataset:  15%|█▌        | 143/953 [00:00<00:05, 148.75 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:05, 162.23 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:05, 161.55 examples/s]Tokenizing eval dataset:  18%|█▊        | 167/953 [00:01<00:05, 143.87 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:00<00:04, 171.59 examples/s]Tokenizing eval dataset:  19%|█▉        | 185/953 [00:01<00:05, 150.45 examples/s]Tokenizing eval dataset:  11%|█         | 103/953 [00:00<00:05, 163.76 examples/s]Tokenizing eval dataset:  22%|██▏       | 205/953 [00:01<00:04, 159.99 examples/s]Tokenizing eval dataset:  13%|█▎        | 121/953 [00:00<00:05, 164.35 examples/s]Tokenizing eval dataset:  17%|█▋        | 163/953 [00:00<00:04, 162.47 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:01<00:03, 193.82 examples/s]Tokenizing eval dataset:  15%|█▍        | 141/953 [00:00<00:04, 173.59 examples/s]Tokenizing eval dataset:  20%|█▉        | 188/953 [00:01<00:04, 161.56 examples/s]Tokenizing eval dataset:  28%|██▊       | 263/953 [00:01<00:03, 210.37 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:05, 151.72 examples/s]Tokenizing eval dataset:  22%|██▏       | 210/953 [00:01<00:04, 173.16 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:01<00:02, 262.82 examples/s]Tokenizing eval dataset:  24%|██▍       | 231/953 [00:01<00:04, 175.03 examples/s]Tokenizing eval dataset:  35%|███▌      | 336/953 [00:01<00:02, 277.77 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:01<00:05, 138.58 examples/s]Tokenizing eval dataset:  27%|██▋       | 259/953 [00:01<00:03, 197.42 examples/s]Tokenizing eval dataset:  38%|███▊      | 366/953 [00:01<00:02, 281.68 examples/s]Tokenizing eval dataset:  21%|██        | 200/953 [00:01<00:05, 149.75 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:01<00:02, 259.57 examples/s]Tokenizing eval dataset:  44%|████▍     | 418/953 [00:01<00:01, 346.26 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:01<00:02, 228.98 examples/s]Tokenizing eval dataset:  25%|██▌       | 240/953 [00:01<00:04, 153.24 examples/s]Tokenizing eval dataset:  48%|████▊     | 461/953 [00:02<00:01, 259.02 examples/s]Tokenizing eval dataset:  39%|███▊      | 368/953 [00:01<00:02, 242.77 examples/s]Tokenizing eval dataset:  29%|██▉       | 278/953 [00:01<00:03, 199.23 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:02<00:01, 294.00 examples/s]Tokenizing eval dataset:  45%|████▌     | 432/953 [00:01<00:01, 338.88 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:01<00:02, 290.93 examples/s]Tokenizing eval dataset:  59%|█████▉    | 562/953 [00:02<00:01, 359.39 examples/s]Tokenizing eval dataset:  52%|█████▏    | 495/953 [00:02<00:01, 410.48 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:01<00:01, 353.67 examples/s]Tokenizing eval dataset:  65%|██████▌   | 620/953 [00:02<00:00, 413.87 examples/s]Tokenizing eval dataset:  70%|██████▉   | 667/953 [00:02<00:00, 427.72 examples/s]Tokenizing eval dataset:  59%|█████▉    | 562/953 [00:02<00:00, 396.54 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:02<00:01, 371.50 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:02<00:00, 460.66 examples/s]Tokenizing eval dataset:  65%|██████▍   | 616/953 [00:02<00:00, 428.57 examples/s]Tokenizing eval dataset:  56%|█████▌    | 529/953 [00:02<00:01, 240.40 examples/s]Tokenizing eval dataset:  82%|████████▏ | 780/953 [00:03<00:00, 282.28 examples/s]Tokenizing eval dataset:  71%|███████▏  | 681/953 [00:02<00:00, 281.17 examples/s]Tokenizing eval dataset:  59%|█████▉    | 564/953 [00:02<00:01, 256.63 examples/s]Tokenizing eval dataset:  87%|████████▋ | 829/953 [00:03<00:00, 290.87 examples/s]Tokenizing eval dataset:  77%|███████▋  | 737/953 [00:02<00:00, 301.72 examples/s]Tokenizing eval dataset:  65%|██████▌   | 624/953 [00:02<00:01, 319.43 examples/s]Tokenizing eval dataset:  92%|█████████▏| 877/953 [00:03<00:00, 326.14 examples/s]Tokenizing eval dataset:  82%|████████▏ | 781/953 [00:02<00:00, 326.37 examples/s]Tokenizing eval dataset:  71%|███████   | 674/953 [00:02<00:00, 352.97 examples/s]Tokenizing eval dataset:  97%|█████████▋| 920/953 [00:03<00:00, 345.47 examples/s]Tokenizing eval dataset:  76%|███████▌  | 720/953 [00:02<00:00, 374.85 examples/s]Tokenizing eval dataset:  88%|████████▊ | 840/953 [00:03<00:00, 343.02 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 269.25 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  81%|████████  | 769/953 [00:02<00:00, 401.92 examples/s]Tokenizing eval dataset:  93%|█████████▎| 882/953 [00:03<00:00, 355.16 examples/s]Tokenizing eval dataset:  97%|█████████▋| 924/953 [00:03<00:00, 366.68 examples/s]Tokenizing eval dataset:  87%|████████▋ | 827/953 [00:03<00:00, 393.83 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 276.50 examples/s]
Tokenizing eval dataset:  92%|█████████▏| 877/953 [00:03<00:00, 329.73 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  98%|█████████▊| 936/953 [00:03<00:00, 347.02 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 267.74 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.1192173957824707 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Building extension module cpu_adam...
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.6500799655914307 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.6941676139831543 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.686480760574341 seconds
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250612_102854-pprizq84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-4e-06_e-3_b-0.1_63084265
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/pprizq84
  0%|          | 0/4545 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/4545 [00:11<14:51:35, 11.77s/it]  0%|          | 2/4545 [00:15<9:00:26,  7.14s/it]   0%|          | 3/4545 [00:19<7:08:31,  5.66s/it]  0%|          | 4/4545 [00:23<6:07:11,  4.85s/it]  0%|          | 5/4545 [00:27<5:41:56,  4.52s/it]  0%|          | 6/4545 [00:31<5:34:45,  4.43s/it]  0%|          | 7/4545 [00:35<5:27:00,  4.32s/it]  0%|          | 8/4545 [00:39<5:16:59,  4.19s/it]  0%|          | 9/4545 [00:43<5:16:46,  4.19s/it]  0%|          | 10/4545 [00:47<5:06:54,  4.06s/it]                                                   {'loss': 0.7234, 'grad_norm': 32.1220588684082, 'learning_rate': 2.3778071334214e-08, 'rewards/chosen': -0.031621553003787994, 'rewards/rejected': 0.01080932654440403, 'rewards/accuracies': 0.2562499940395355, 'rewards/margins': -0.04250030592083931, 'logps/chosen': -447.79998779296875, 'logps/rejected': -256.3500061035156, 'logits/chosen': -6.065625190734863, 'logits/rejected': -6.171875, 'epoch': 0.01}
  0%|          | 10/4545 [00:47<5:06:54,  4.06s/it]  0%|          | 11/4545 [00:51<5:10:47,  4.11s/it]  0%|          | 12/4545 [00:55<5:06:16,  4.05s/it]  0%|          | 13/4545 [00:57<4:25:08,  3.51s/it]  0%|          | 14/4545 [01:01<4:21:19,  3.46s/it]  0%|          | 15/4545 [01:05<4:31:44,  3.60s/it]  0%|          | 16/4545 [01:08<4:26:14,  3.53s/it]  0%|          | 17/4545 [01:12<4:34:58,  3.64s/it]  0%|          | 18/4545 [01:16<4:47:31,  3.81s/it]  0%|          | 19/4545 [01:19<4:28:36,  3.56s/it]  0%|          | 20/4545 [01:23<4:36:45,  3.67s/it]                                                   {'loss': 0.6904, 'grad_norm': 28.953105926513672, 'learning_rate': 5.0198150594451784e-08, 'rewards/chosen': 0.02576599083840847, 'rewards/rejected': 0.00763015728443861, 'rewards/accuracies': 0.38749998807907104, 'rewards/margins': 0.01819152757525444, 'logps/chosen': -254.64999389648438, 'logps/rejected': -121.0250015258789, 'logits/chosen': -6.278124809265137, 'logits/rejected': -6.668749809265137, 'epoch': 0.01}
  0%|          | 20/4545 [01:23<4:36:45,  3.67s/it]  0%|          | 21/4545 [01:26<4:28:48,  3.57s/it]  0%|          | 22/4545 [01:30<4:37:35,  3.68s/it]  1%|          | 23/4545 [01:34<4:42:51,  3.75s/it]  1%|          | 24/4545 [01:37<4:29:38,  3.58s/it]  1%|          | 25/4545 [01:41<4:37:25,  3.68s/it]  1%|          | 26/4545 [01:45<4:31:06,  3.60s/it]  1%|          | 27/4545 [01:49<4:39:01,  3.71s/it]  1%|          | 28/4545 [01:52<4:42:41,  3.76s/it]  1%|          | 29/4545 [01:56<4:46:05,  3.80s/it]  1%|          | 30/4545 [02:01<4:55:47,  3.93s/it]                                                   {'loss': 0.6922, 'grad_norm': 25.045791625976562, 'learning_rate': 7.661822985468956e-08, 'rewards/chosen': 0.0034439086448401213, 'rewards/rejected': 0.0024536133278161287, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.0009918212890625, 'logps/chosen': -283.1000061035156, 'logps/rejected': -142.3000030517578, 'logits/chosen': -6.196875095367432, 'logits/rejected': -6.546875, 'epoch': 0.02}
  1%|          | 30/4545 [02:01<4:55:47,  3.93s/it]  1%|          | 31/4545 [02:05<4:58:52,  3.97s/it]  1%|          | 32/4545 [02:09<4:59:37,  3.98s/it]  1%|          | 33/4545 [02:13<4:58:29,  3.97s/it]  1%|          | 34/4545 [02:17<5:03:47,  4.04s/it]  1%|          | 35/4545 [02:21<5:01:06,  4.01s/it]  1%|          | 36/4545 [02:24<4:53:30,  3.91s/it]  1%|          | 37/4545 [02:28<4:46:51,  3.82s/it]  1%|          | 38/4545 [02:32<4:46:50,  3.82s/it]  1%|          | 39/4545 [02:36<4:49:04,  3.85s/it]  1%|          | 40/4545 [02:40<4:50:45,  3.87s/it]                                                   {'loss': 0.6906, 'grad_norm': 164.3693389892578, 'learning_rate': 1.0303830911492733e-07, 'rewards/chosen': 0.01841278001666069, 'rewards/rejected': 0.005076599307358265, 'rewards/accuracies': 0.4437499940395355, 'rewards/margins': 0.01328430138528347, 'logps/chosen': -416.25, 'logps/rejected': -175.35000610351562, 'logits/chosen': -6.265625, 'logits/rejected': -6.5625, 'epoch': 0.03}
  1%|          | 40/4545 [02:40<4:50:45,  3.87s/it]  1%|          | 41/4545 [02:43<4:44:40,  3.79s/it]  1%|          | 42/4545 [02:47<4:47:46,  3.83s/it]  1%|          | 43/4545 [02:51<4:51:31,  3.89s/it]  1%|          | 44/4545 [02:55<4:56:00,  3.95s/it]  1%|          | 45/4545 [02:59<4:59:40,  4.00s/it]  1%|          | 46/4545 [03:03<4:59:05,  3.99s/it]  1%|          | 47/4545 [03:07<4:50:12,  3.87s/it]  1%|          | 48/4545 [03:11<4:51:31,  3.89s/it]  1%|          | 49/4545 [03:15<4:51:54,  3.90s/it]  1%|          | 50/4545 [03:19<4:52:27,  3.90s/it]                                                   {'loss': 0.7025, 'grad_norm': 194.30960083007812, 'learning_rate': 1.2945838837516513e-07, 'rewards/chosen': 0.02373046800494194, 'rewards/rejected': 0.016031360253691673, 'rewards/accuracies': 0.4312500059604645, 'rewards/margins': 0.007656860165297985, 'logps/chosen': -366.25, 'logps/rejected': -200.8000030517578, 'logits/chosen': -6.290625095367432, 'logits/rejected': -6.474999904632568, 'epoch': 0.03}
  1%|          | 50/4545 [03:19<4:52:27,  3.90s/it]  1%|          | 51/4545 [03:22<4:49:16,  3.86s/it]  1%|          | 52/4545 [03:26<4:47:41,  3.84s/it]  1%|          | 53/4545 [03:30<4:43:10,  3.78s/it]  1%|          | 54/4545 [03:34<4:51:05,  3.89s/it]  1%|          | 55/4545 [03:38<4:52:00,  3.90s/it]  1%|          | 56/4545 [03:42<4:48:52,  3.86s/it]  1%|▏         | 57/4545 [03:46<4:50:07,  3.88s/it]  1%|▏         | 58/4545 [03:49<4:46:23,  3.83s/it]  1%|▏         | 59/4545 [03:53<4:30:57,  3.62s/it]  1%|▏         | 60/4545 [03:56<4:38:10,  3.72s/it]                                                   {'loss': 0.6896, 'grad_norm': 29.611248016357422, 'learning_rate': 1.5587846763540292e-07, 'rewards/chosen': 0.010775089263916016, 'rewards/rejected': 0.0006591796991415322, 'rewards/accuracies': 0.48124998807907104, 'rewards/margins': 0.01010742224752903, 'logps/chosen': -227.1999969482422, 'logps/rejected': -122.625, 'logits/chosen': -6.384375095367432, 'logits/rejected': -6.584374904632568, 'epoch': 0.04}
  1%|▏         | 60/4545 [03:57<4:38:10,  3.72s/it]  1%|▏         | 61/4545 [04:00<4:30:01,  3.61s/it]  1%|▏         | 62/4545 [04:04<4:31:53,  3.64s/it]  1%|▏         | 63/4545 [04:08<4:39:31,  3.74s/it]  1%|▏         | 64/4545 [04:12<4:46:07,  3.83s/it]  1%|▏         | 65/4545 [04:14<4:23:24,  3.53s/it]  1%|▏         | 66/4545 [04:18<4:25:23,  3.56s/it]  1%|▏         | 67/4545 [04:22<4:34:19,  3.68s/it]  1%|▏         | 68/4545 [04:26<4:34:52,  3.68s/it]  2%|▏         | 69/4545 [04:30<4:40:27,  3.76s/it]  2%|▏         | 70/4545 [04:33<4:38:34,  3.73s/it]                                                   {'loss': 0.6602, 'grad_norm': 32.006290435791016, 'learning_rate': 1.8229854689564068e-07, 'rewards/chosen': 0.13818970322608948, 'rewards/rejected': -0.0013641357654705644, 'rewards/accuracies': 0.5375000238418579, 'rewards/margins': 0.13935089111328125, 'logps/chosen': -315.25, 'logps/rejected': -154.9250030517578, 'logits/chosen': -6.15625, 'logits/rejected': -6.550000190734863, 'epoch': 0.05}
  2%|▏         | 70/4545 [04:33<4:38:34,  3.73s/it]  2%|▏         | 71/4545 [04:37<4:48:44,  3.87s/it]  2%|▏         | 72/4545 [04:41<4:31:42,  3.64s/it]  2%|▏         | 73/4545 [04:45<4:43:31,  3.80s/it]  2%|▏         | 74/4545 [04:49<4:49:55,  3.89s/it]  2%|▏         | 75/4545 [04:53<4:50:54,  3.90s/it]  2%|▏         | 76/4545 [04:56<4:45:30,  3.83s/it]  2%|▏         | 77/4545 [05:01<4:50:16,  3.90s/it]  2%|▏         | 78/4545 [05:04<4:51:50,  3.92s/it]  2%|▏         | 79/4545 [05:08<4:52:02,  3.92s/it]  2%|▏         | 80/4545 [05:12<4:52:56,  3.94s/it]                                                   {'loss': 0.6802, 'grad_norm': 46.06798553466797, 'learning_rate': 2.0871862615587847e-07, 'rewards/chosen': 0.19510650634765625, 'rewards/rejected': 0.09712371975183487, 'rewards/accuracies': 0.48750001192092896, 'rewards/margins': 0.09775390475988388, 'logps/chosen': -350.8999938964844, 'logps/rejected': -215.9499969482422, 'logits/chosen': -6.224999904632568, 'logits/rejected': -6.403124809265137, 'epoch': 0.05}
  2%|▏         | 80/4545 [05:13<4:52:56,  3.94s/it]  2%|▏         | 81/4545 [05:16<4:53:41,  3.95s/it]  2%|▏         | 82/4545 [05:20<4:48:30,  3.88s/it]  2%|▏         | 83/4545 [05:24<4:49:01,  3.89s/it]  2%|▏         | 84/4545 [05:27<4:27:08,  3.59s/it]  2%|▏         | 85/4545 [05:31<4:42:05,  3.79s/it]  2%|▏         | 86/4545 [05:35<4:47:47,  3.87s/it]  2%|▏         | 87/4545 [05:39<4:49:15,  3.89s/it]  2%|▏         | 88/4545 [05:43<4:50:01,  3.90s/it]  2%|▏         | 89/4545 [05:46<4:33:03,  3.68s/it]  2%|▏         | 90/4545 [05:50<4:25:58,  3.58s/it]                                                   {'loss': 0.6616, 'grad_norm': 29.544347763061523, 'learning_rate': 2.3513870541611625e-07, 'rewards/chosen': 0.2608085572719574, 'rewards/rejected': 0.0014770508278161287, 'rewards/accuracies': 0.518750011920929, 'rewards/margins': 0.25877684354782104, 'logps/chosen': -319.54998779296875, 'logps/rejected': -167.4499969482422, 'logits/chosen': -6.353125095367432, 'logits/rejected': -6.634375095367432, 'epoch': 0.06}
  2%|▏         | 90/4545 [05:50<4:25:58,  3.58s/it]  2%|▏         | 91/4545 [05:54<4:36:27,  3.72s/it]  2%|▏         | 92/4545 [05:58<4:41:14,  3.79s/it]  2%|▏         | 93/4545 [06:02<4:44:37,  3.84s/it]  2%|▏         | 94/4545 [06:06<4:48:25,  3.89s/it]  2%|▏         | 95/4545 [06:09<4:49:13,  3.90s/it]  2%|▏         | 96/4545 [06:13<4:49:20,  3.90s/it]  2%|▏         | 97/4545 [06:17<4:50:06,  3.91s/it]  2%|▏         | 98/4545 [06:21<4:37:04,  3.74s/it]  2%|▏         | 99/4545 [06:24<4:22:30,  3.54s/it]  2%|▏         | 100/4545 [06:27<4:21:40,  3.53s/it]                                                    {'loss': 0.6497, 'grad_norm': 21.276451110839844, 'learning_rate': 2.61558784676354e-07, 'rewards/chosen': 0.3065429627895355, 'rewards/rejected': 0.0022033690474927425, 'rewards/accuracies': 0.643750011920929, 'rewards/margins': 0.30438232421875, 'logps/chosen': -327.29998779296875, 'logps/rejected': -159.78750610351562, 'logits/chosen': -6.284375190734863, 'logits/rejected': -6.643750190734863, 'epoch': 0.07}
  2%|▏         | 100/4545 [06:27<4:21:40,  3.53s/it]  2%|▏         | 101/4545 [06:31<4:31:08,  3.66s/it]  2%|▏         | 102/4545 [06:35<4:36:28,  3.73s/it]  2%|▏         | 103/4545 [06:38<4:12:21,  3.41s/it]  2%|▏         | 104/4545 [06:41<4:17:16,  3.48s/it]  2%|▏         | 105/4545 [06:45<4:15:40,  3.46s/it]  2%|▏         | 106/4545 [06:49<4:22:40,  3.55s/it]  2%|▏         | 107/4545 [06:53<4:31:32,  3.67s/it]  2%|▏         | 108/4545 [06:56<4:32:48,  3.69s/it]  2%|▏         | 109/4545 [07:00<4:38:01,  3.76s/it]  2%|▏         | 110/4545 [07:05<4:54:41,  3.99s/it]                                                    {'loss': 0.6582, 'grad_norm': 30.444828033447266, 'learning_rate': 2.879788639365918e-07, 'rewards/chosen': 0.22983399033546448, 'rewards/rejected': 0.03105011023581028, 'rewards/accuracies': 0.606249988079071, 'rewards/margins': 0.19904175400733948, 'logps/chosen': -218.9499969482422, 'logps/rejected': -128.0, 'logits/chosen': -6.287499904632568, 'logits/rejected': -6.596875190734863, 'epoch': 0.07}
  2%|▏         | 110/4545 [07:05<4:54:41,  3.99s/it]  2%|▏         | 111/4545 [07:09<5:00:04,  4.06s/it]  2%|▏         | 112/4545 [07:13<4:57:06,  4.02s/it]  2%|▏         | 113/4545 [07:17<4:55:13,  4.00s/it]  3%|▎         | 114/4545 [07:21<4:53:36,  3.98s/it]  3%|▎         | 115/4545 [07:25<4:54:13,  3.99s/it]  3%|▎         | 116/4545 [07:29<4:52:55,  3.97s/it]  3%|▎         | 117/4545 [07:33<4:58:22,  4.04s/it]  3%|▎         | 118/4545 [07:37<5:02:53,  4.11s/it]  3%|▎         | 119/4545 [07:41<4:57:48,  4.04s/it]  3%|▎         | 120/4545 [07:45<4:49:33,  3.93s/it]                                                    {'loss': 0.6172, 'grad_norm': 22.82577133178711, 'learning_rate': 3.143989431968296e-07, 'rewards/chosen': 0.578173816204071, 'rewards/rejected': 0.10340575873851776, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 0.4749755859375, 'logps/chosen': -424.70001220703125, 'logps/rejected': -148.5500030517578, 'logits/chosen': -6.074999809265137, 'logits/rejected': -6.59375, 'epoch': 0.08}
  3%|▎         | 120/4545 [07:45<4:49:33,  3.93s/it]  3%|▎         | 121/4545 [07:49<4:51:17,  3.95s/it]  3%|▎         | 122/4545 [07:53<4:51:01,  3.95s/it]  3%|▎         | 123/4545 [07:57<4:50:50,  3.95s/it]  3%|▎         | 124/4545 [08:00<4:44:55,  3.87s/it]  3%|▎         | 125/4545 [08:04<4:51:00,  3.95s/it]  3%|▎         | 126/4545 [08:09<5:09:09,  4.20s/it]  3%|▎         | 127/4545 [08:13<4:56:43,  4.03s/it]  3%|▎         | 128/4545 [08:17<4:54:35,  4.00s/it]  3%|▎         | 129/4545 [08:21<4:53:06,  3.98s/it]  3%|▎         | 130/4545 [08:25<4:52:40,  3.98s/it]                                                    {'loss': 0.6256, 'grad_norm': 20.05858612060547, 'learning_rate': 3.4081902245706735e-07, 'rewards/chosen': 0.7218261957168579, 'rewards/rejected': 0.07032966613769531, 'rewards/accuracies': 0.625, 'rewards/margins': 0.65155029296875, 'logps/chosen': -391.79998779296875, 'logps/rejected': -263.1000061035156, 'logits/chosen': -6.099999904632568, 'logits/rejected': -6.300000190734863, 'epoch': 0.09}
  3%|▎         | 130/4545 [08:25<4:52:40,  3.98s/it]  3%|▎         | 131/4545 [08:29<4:52:24,  3.97s/it]  3%|▎         | 132/4545 [08:32<4:42:36,  3.84s/it]  3%|▎         | 133/4545 [08:35<4:25:28,  3.61s/it]  3%|▎         | 134/4545 [08:39<4:23:04,  3.58s/it]  3%|▎         | 135/4545 [08:41<3:58:08,  3.24s/it]  3%|▎         | 136/4545 [08:44<3:55:24,  3.20s/it]  3%|▎         | 137/4545 [08:48<4:17:18,  3.50s/it]  3%|▎         | 138/4545 [08:52<4:27:07,  3.64s/it]  3%|▎         | 139/4545 [08:56<4:30:26,  3.68s/it]  3%|▎         | 140/4545 [09:00<4:35:42,  3.76s/it]                                                    {'loss': 0.6118, 'grad_norm': 21.227020263671875, 'learning_rate': 3.6723910171730516e-07, 'rewards/chosen': 0.6357421875, 'rewards/rejected': 0.13545532524585724, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.4999023377895355, 'logps/chosen': -319.45001220703125, 'logps/rejected': -179.5749969482422, 'logits/chosen': -6.359375, 'logits/rejected': -6.681250095367432, 'epoch': 0.09}
  3%|▎         | 140/4545 [09:00<4:35:42,  3.76s/it]  3%|▎         | 141/4545 [09:04<4:39:57,  3.81s/it]  3%|▎         | 142/4545 [09:08<4:45:44,  3.89s/it]  3%|▎         | 143/4545 [09:12<4:47:30,  3.92s/it]  3%|▎         | 144/4545 [09:16<4:47:35,  3.92s/it]  3%|▎         | 145/4545 [09:20<4:47:19,  3.92s/it]  3%|▎         | 146/4545 [09:23<4:37:28,  3.78s/it]  3%|▎         | 147/4545 [09:27<4:34:19,  3.74s/it]  3%|▎         | 148/4545 [09:31<4:38:30,  3.80s/it]  3%|▎         | 149/4545 [09:35<4:41:13,  3.84s/it]  3%|▎         | 150/4545 [09:38<4:24:16,  3.61s/it]                                                    {'loss': 0.6098, 'grad_norm': 16.461153030395508, 'learning_rate': 3.936591809775429e-07, 'rewards/chosen': 0.5667968988418579, 'rewards/rejected': 0.05542602390050888, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.5113281011581421, 'logps/chosen': -277.54998779296875, 'logps/rejected': -116.4000015258789, 'logits/chosen': -6.271874904632568, 'logits/rejected': -6.574999809265137, 'epoch': 0.1}
  3%|▎         | 150/4545 [09:38<4:24:16,  3.61s/it]  3%|▎         | 151/4545 [09:41<4:14:29,  3.47s/it]  3%|▎         | 152/4545 [09:45<4:21:02,  3.57s/it]  3%|▎         | 153/4545 [09:49<4:29:13,  3.68s/it]  3%|▎         | 154/4545 [09:53<4:29:25,  3.68s/it]  3%|▎         | 155/4545 [09:57<4:35:31,  3.77s/it]  3%|▎         | 156/4545 [10:00<4:36:12,  3.78s/it]  3%|▎         | 157/4545 [10:04<4:36:18,  3.78s/it]  3%|▎         | 158/4545 [10:08<4:35:23,  3.77s/it]  3%|▎         | 159/4545 [10:12<4:45:50,  3.91s/it]  4%|▎         | 160/4545 [10:16<4:46:24,  3.92s/it]                                                    {'loss': 0.6019, 'grad_norm': 41.34400939941406, 'learning_rate': 4.200792602377807e-07, 'rewards/chosen': 0.663769543170929, 'rewards/rejected': 0.13193969428539276, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.53173828125, 'logps/chosen': -288.54998779296875, 'logps/rejected': -158.39999389648438, 'logits/chosen': -6.140625, 'logits/rejected': -6.506249904632568, 'epoch': 0.11}
  4%|▎         | 160/4545 [10:16<4:46:24,  3.92s/it]  4%|▎         | 161/4545 [10:20<4:52:15,  4.00s/it]  4%|▎         | 162/4545 [10:24<4:50:46,  3.98s/it]  4%|▎         | 163/4545 [10:28<4:54:39,  4.03s/it]  4%|▎         | 164/4545 [10:32<4:52:26,  4.01s/it]  4%|▎         | 165/4545 [10:36<4:40:29,  3.84s/it]  4%|▎         | 166/4545 [10:40<4:42:32,  3.87s/it]  4%|▎         | 167/4545 [10:44<4:43:56,  3.89s/it]  4%|▎         | 168/4545 [10:48<4:45:13,  3.91s/it]  4%|▎         | 169/4545 [10:52<4:45:22,  3.91s/it]  4%|▎         | 170/4545 [10:55<4:45:50,  3.92s/it]                                                    {'loss': 0.5422, 'grad_norm': 35.871070861816406, 'learning_rate': 4.464993394980185e-07, 'rewards/chosen': 1.1708984375, 'rewards/rejected': 0.13142089545726776, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.041015625, 'logps/chosen': -452.95001220703125, 'logps/rejected': -204.97500610351562, 'logits/chosen': -5.981249809265137, 'logits/rejected': -6.534375190734863, 'epoch': 0.11}
  4%|▎         | 170/4545 [10:56<4:45:50,  3.92s/it]  4%|▍         | 171/4545 [10:58<4:24:43,  3.63s/it]  4%|▍         | 172/4545 [11:03<4:35:45,  3.78s/it]  4%|▍         | 173/4545 [11:06<4:38:53,  3.83s/it]  4%|▍         | 174/4545 [11:11<4:44:15,  3.90s/it]  4%|▍         | 175/4545 [11:14<4:31:07,  3.72s/it]  4%|▍         | 176/4545 [11:18<4:35:56,  3.79s/it]  4%|▍         | 177/4545 [11:21<4:15:58,  3.52s/it]  4%|▍         | 178/4545 [11:25<4:25:56,  3.65s/it]  4%|▍         | 179/4545 [11:28<4:17:29,  3.54s/it]  4%|▍         | 180/4545 [11:32<4:26:08,  3.66s/it]                                                    {'loss': 0.5878, 'grad_norm': 16.84534454345703, 'learning_rate': 4.7291941875825625e-07, 'rewards/chosen': 0.782421886920929, 'rewards/rejected': 0.05985107272863388, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.7232421636581421, 'logps/chosen': -276.95001220703125, 'logps/rejected': -181.1750030517578, 'logits/chosen': -6.259375095367432, 'logits/rejected': -6.428124904632568, 'epoch': 0.12}
  4%|▍         | 180/4545 [11:32<4:26:08,  3.66s/it]  4%|▍         | 181/4545 [11:36<4:33:04,  3.75s/it]  4%|▍         | 182/4545 [11:39<4:22:33,  3.61s/it]  4%|▍         | 183/4545 [11:43<4:29:08,  3.70s/it]  4%|▍         | 184/4545 [11:47<4:34:03,  3.77s/it]  4%|▍         | 185/4545 [11:51<4:37:33,  3.82s/it]  4%|▍         | 186/4545 [11:55<4:32:50,  3.76s/it]  4%|▍         | 187/4545 [11:58<4:36:20,  3.80s/it]  4%|▍         | 188/4545 [12:02<4:21:10,  3.60s/it]  4%|▍         | 189/4545 [12:05<4:13:31,  3.49s/it]  4%|▍         | 190/4545 [12:08<4:05:12,  3.38s/it]                                                    {'loss': 0.5716, 'grad_norm': 19.903329849243164, 'learning_rate': 4.99339498018494e-07, 'rewards/chosen': 0.8656250238418579, 'rewards/rejected': 0.15903320908546448, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.706835925579071, 'logps/chosen': -293.5, 'logps/rejected': -154.27499389648438, 'logits/chosen': -6.275000095367432, 'logits/rejected': -6.584374904632568, 'epoch': 0.13}
  4%|▍         | 190/4545 [12:08<4:05:12,  3.38s/it]  4%|▍         | 191/4545 [12:12<4:17:07,  3.54s/it]  4%|▍         | 192/4545 [12:16<4:19:56,  3.58s/it]  4%|▍         | 193/4545 [12:18<4:05:22,  3.38s/it]  4%|▍         | 194/4545 [12:21<3:53:06,  3.21s/it]  4%|▍         | 195/4545 [12:25<4:08:50,  3.43s/it]  4%|▍         | 196/4545 [12:29<4:20:51,  3.60s/it]  4%|▍         | 197/4545 [12:34<4:39:05,  3.85s/it]  4%|▍         | 198/4545 [12:38<4:41:36,  3.89s/it]  4%|▍         | 199/4545 [12:42<4:42:38,  3.90s/it]  4%|▍         | 200/4545 [12:45<4:44:05,  3.92s/it]                                                    {'loss': 0.6008, 'grad_norm': 130.2917022705078, 'learning_rate': 5.257595772787318e-07, 'rewards/chosen': 1.0265624523162842, 'rewards/rejected': 0.21047362685203552, 'rewards/accuracies': 0.699999988079071, 'rewards/margins': 0.814990222454071, 'logps/chosen': -346.25, 'logps/rejected': -239.52499389648438, 'logits/chosen': -6.178124904632568, 'logits/rejected': -6.478125095367432, 'epoch': 0.13}
  4%|▍         | 200/4545 [12:46<4:44:05,  3.92s/it]  4%|▍         | 201/4545 [12:50<4:46:47,  3.96s/it]  4%|▍         | 202/4545 [12:53<4:43:56,  3.92s/it]  4%|▍         | 203/4545 [12:57<4:40:30,  3.88s/it]  4%|▍         | 204/4545 [13:01<4:47:56,  3.98s/it]  5%|▍         | 205/4545 [13:05<4:45:22,  3.95s/it]  5%|▍         | 206/4545 [13:09<4:45:10,  3.94s/it]  5%|▍         | 207/4545 [13:13<4:45:14,  3.95s/it]  5%|▍         | 208/4545 [13:17<4:35:33,  3.81s/it]  5%|▍         | 209/4545 [13:21<4:42:23,  3.91s/it]  5%|▍         | 210/4545 [13:25<4:49:27,  4.01s/it]                                                    {'loss': 0.54, 'grad_norm': 33.70793151855469, 'learning_rate': 5.521796565389696e-07, 'rewards/chosen': 0.870898425579071, 'rewards/rejected': -0.00979003868997097, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 0.8804687261581421, 'logps/chosen': -287.45001220703125, 'logps/rejected': -195.14999389648438, 'logits/chosen': -6.324999809265137, 'logits/rejected': -6.481249809265137, 'epoch': 0.14}
  5%|▍         | 210/4545 [13:25<4:49:27,  4.01s/it]  5%|▍         | 211/4545 [13:29<4:50:54,  4.03s/it]  5%|▍         | 212/4545 [13:33<4:51:23,  4.04s/it]  5%|▍         | 213/4545 [13:37<4:48:47,  4.00s/it]  5%|▍         | 214/4545 [13:41<4:46:31,  3.97s/it]  5%|▍         | 215/4545 [13:45<4:44:14,  3.94s/it]  5%|▍         | 216/4545 [13:49<4:44:24,  3.94s/it]  5%|▍         | 217/4545 [13:53<4:44:09,  3.94s/it]  5%|▍         | 218/4545 [13:57<4:44:04,  3.94s/it]  5%|▍         | 219/4545 [14:00<4:30:14,  3.75s/it]  5%|▍         | 220/4545 [14:04<4:38:05,  3.86s/it]                                                    {'loss': 0.5516, 'grad_norm': 21.58647346496582, 'learning_rate': 5.785997357992074e-07, 'rewards/chosen': 1.015039086341858, 'rewards/rejected': 0.0814208984375, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.935351550579071, 'logps/chosen': -316.25, 'logps/rejected': -181.60000610351562, 'logits/chosen': -6.368750095367432, 'logits/rejected': -6.565625190734863, 'epoch': 0.15}
  5%|▍         | 220/4545 [14:04<4:38:05,  3.86s/it]  5%|▍         | 221/4545 [14:08<4:33:41,  3.80s/it]  5%|▍         | 222/4545 [14:12<4:43:13,  3.93s/it]  5%|▍         | 223/4545 [14:16<4:43:27,  3.94s/it]  5%|▍         | 224/4545 [14:20<4:43:34,  3.94s/it]  5%|▍         | 225/4545 [14:24<4:49:40,  4.02s/it]  5%|▍         | 226/4545 [14:27<4:19:19,  3.60s/it]  5%|▍         | 227/4545 [14:31<4:26:40,  3.71s/it]  5%|▌         | 228/4545 [14:34<4:26:18,  3.70s/it]  5%|▌         | 229/4545 [14:38<4:19:59,  3.61s/it]  5%|▌         | 230/4545 [14:42<4:27:01,  3.71s/it]                                                    {'loss': 0.5192, 'grad_norm': 13.89991283416748, 'learning_rate': 6.050198150594451e-07, 'rewards/chosen': 1.474707007408142, 'rewards/rejected': 0.043450165539979935, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 1.4318358898162842, 'logps/chosen': -473.75, 'logps/rejected': -243.52499389648438, 'logits/chosen': -6.193749904632568, 'logits/rejected': -6.337500095367432, 'epoch': 0.15}
  5%|▌         | 230/4545 [14:42<4:27:01,  3.71s/it]  5%|▌         | 231/4545 [14:46<4:39:29,  3.89s/it]  5%|▌         | 232/4545 [14:50<4:44:52,  3.96s/it]  5%|▌         | 233/4545 [14:54<4:37:53,  3.87s/it]  5%|▌         | 234/4545 [14:58<4:40:58,  3.91s/it]  5%|▌         | 235/4545 [15:02<4:45:25,  3.97s/it]  5%|▌         | 236/4545 [15:05<4:33:08,  3.80s/it]  5%|▌         | 237/4545 [15:09<4:38:05,  3.87s/it]  5%|▌         | 238/4545 [15:12<4:05:31,  3.42s/it]  5%|▌         | 239/4545 [15:16<4:16:42,  3.58s/it]  5%|▌         | 240/4545 [15:20<4:24:47,  3.69s/it]                                                    {'loss': 0.4991, 'grad_norm': 17.100282669067383, 'learning_rate': 6.314398943196829e-07, 'rewards/chosen': 1.005273461341858, 'rewards/rejected': -0.11713866889476776, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.1238281726837158, 'logps/chosen': -288.6499938964844, 'logps/rejected': -138.4250030517578, 'logits/chosen': -6.449999809265137, 'logits/rejected': -6.590624809265137, 'epoch': 0.16}
  5%|▌         | 240/4545 [15:20<4:24:47,  3.69s/it]  5%|▌         | 241/4545 [15:23<4:16:05,  3.57s/it]  5%|▌         | 242/4545 [15:27<4:29:21,  3.76s/it]  5%|▌         | 243/4545 [15:30<4:17:00,  3.58s/it]  5%|▌         | 244/4545 [15:34<4:24:33,  3.69s/it]  5%|▌         | 245/4545 [15:38<4:29:50,  3.77s/it]  5%|▌         | 246/4545 [15:42<4:32:49,  3.81s/it]  5%|▌         | 247/4545 [15:46<4:38:12,  3.88s/it]  5%|▌         | 248/4545 [15:50<4:39:27,  3.90s/it]  5%|▌         | 249/4545 [15:54<4:40:12,  3.91s/it]  6%|▌         | 250/4545 [15:58<4:47:08,  4.01s/it]                                                    {'loss': 0.5197, 'grad_norm': 13.807673454284668, 'learning_rate': 6.578599735799207e-07, 'rewards/chosen': 1.4879882335662842, 'rewards/rejected': 0.05148277431726456, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.4368164539337158, 'logps/chosen': -381.75, 'logps/rejected': -172.0500030517578, 'logits/chosen': -6.324999809265137, 'logits/rejected': -6.365624904632568, 'epoch': 0.17}
  6%|▌         | 250/4545 [15:58<4:47:08,  4.01s/it]  6%|▌         | 251/4545 [16:02<4:45:24,  3.99s/it]  6%|▌         | 252/4545 [16:06<4:44:31,  3.98s/it]  6%|▌         | 253/4545 [16:09<4:29:13,  3.76s/it]  6%|▌         | 254/4545 [16:39<13:38:14, 11.44s/it]  6%|▌         | 255/4545 [16:43<10:55:01,  9.16s/it]  6%|▌         | 256/4545 [16:47<9:08:34,  7.67s/it]   6%|▌         | 257/4545 [16:51<7:51:52,  6.60s/it]  6%|▌         | 258/4545 [16:54<6:46:00,  5.68s/it]  6%|▌         | 259/4545 [16:56<5:27:10,  4.58s/it]  6%|▌         | 260/4545 [17:01<5:18:19,  4.46s/it]                                                    {'loss': 0.4904, 'grad_norm': 20.353004455566406, 'learning_rate': 6.842800528401584e-07, 'rewards/chosen': 0.868457019329071, 'rewards/rejected': -0.19980469346046448, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.066796898841858, 'logps/chosen': -203.5500030517578, 'logps/rejected': -107.07499694824219, 'logits/chosen': -6.715624809265137, 'logits/rejected': -6.768750190734863, 'epoch': 0.17}
  6%|▌         | 260/4545 [17:01<5:18:19,  4.46s/it]  6%|▌         | 261/4545 [17:04<5:05:18,  4.28s/it]  6%|▌         | 262/4545 [17:08<4:57:46,  4.17s/it]  6%|▌         | 263/4545 [17:12<4:56:16,  4.15s/it]  6%|▌         | 264/4545 [17:16<4:37:29,  3.89s/it]  6%|▌         | 265/4545 [17:20<4:38:41,  3.91s/it]  6%|▌         | 266/4545 [17:24<4:39:25,  3.92s/it]  6%|▌         | 267/4545 [17:28<4:39:58,  3.93s/it]  6%|▌         | 268/4545 [17:31<4:26:37,  3.74s/it]  6%|▌         | 269/4545 [17:35<4:30:38,  3.80s/it]  6%|▌         | 270/4545 [17:39<4:33:17,  3.84s/it]                                                    {'loss': 0.4466, 'grad_norm': 22.621442794799805, 'learning_rate': 7.107001321003963e-07, 'rewards/chosen': 1.9208984375, 'rewards/rejected': 0.21555176377296448, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.7048828601837158, 'logps/chosen': -445.04998779296875, 'logps/rejected': -257.79998779296875, 'logits/chosen': -6.493750095367432, 'logits/rejected': -6.440625190734863, 'epoch': 0.18}
  6%|▌         | 270/4545 [17:39<4:33:17,  3.84s/it]  6%|▌         | 271/4545 [17:43<4:36:46,  3.89s/it]  6%|▌         | 272/4545 [17:46<4:33:14,  3.84s/it]  6%|▌         | 273/4545 [17:50<4:35:00,  3.86s/it]  6%|▌         | 274/4545 [17:54<4:39:03,  3.92s/it]  6%|▌         | 275/4545 [17:57<4:20:17,  3.66s/it]  6%|▌         | 276/4545 [18:02<4:35:03,  3.87s/it]  6%|▌         | 277/4545 [18:06<4:38:02,  3.91s/it]  6%|▌         | 278/4545 [18:10<4:39:05,  3.92s/it]  6%|▌         | 279/4545 [18:13<4:29:29,  3.79s/it]  6%|▌         | 280/4545 [18:17<4:33:14,  3.84s/it]                                                    {'loss': 0.4388, 'grad_norm': 20.773683547973633, 'learning_rate': 7.371202113606341e-07, 'rewards/chosen': 1.915624976158142, 'rewards/rejected': -0.08256836235523224, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.9998047351837158, 'logps/chosen': -373.70001220703125, 'logps/rejected': -172.3249969482422, 'logits/chosen': -6.690625190734863, 'logits/rejected': -6.743750095367432, 'epoch': 0.18}
  6%|▌         | 280/4545 [18:17<4:33:14,  3.84s/it]  6%|▌         | 281/4545 [18:21<4:41:25,  3.96s/it]  6%|▌         | 282/4545 [18:54<14:46:26, 12.48s/it]  6%|▌         | 283/4545 [19:01<12:45:08, 10.77s/it]  6%|▌         | 284/4545 [19:08<11:35:36,  9.79s/it]  6%|▋         | 285/4545 [19:16<10:52:58,  9.20s/it]  6%|▋         | 286/4545 [19:23<10:01:00,  8.47s/it]  6%|▋         | 287/4545 [19:29<9:19:06,  7.88s/it]   6%|▋         | 288/4545 [19:37<9:15:48,  7.83s/it]  6%|▋         | 289/4545 [19:44<9:09:51,  7.75s/it]  6%|▋         | 290/4545 [19:52<9:05:10,  7.69s/it]                                                    {'loss': 0.4037, 'grad_norm': 9.697966575622559, 'learning_rate': 7.635402906208718e-07, 'rewards/chosen': 1.8654296398162842, 'rewards/rejected': 0.054773710668087006, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.812109351158142, 'logps/chosen': -360.95001220703125, 'logps/rejected': -227.14999389648438, 'logits/chosen': -6.553124904632568, 'logits/rejected': -6.650000095367432, 'epoch': 0.19}
  6%|▋         | 290/4545 [19:52<9:05:10,  7.69s/it]  6%|▋         | 291/4545 [19:59<8:51:14,  7.49s/it]  6%|▋         | 292/4545 [20:07<8:53:32,  7.53s/it]  6%|▋         | 293/4545 [20:14<8:57:28,  7.58s/it]  6%|▋         | 294/4545 [20:22<8:54:14,  7.54s/it]  6%|▋         | 295/4545 [20:29<8:45:09,  7.41s/it]  7%|▋         | 296/4545 [20:37<8:48:01,  7.46s/it]  7%|▋         | 297/4545 [20:44<8:51:13,  7.50s/it]  7%|▋         | 298/4545 [20:50<8:26:22,  7.15s/it]  7%|▋         | 299/4545 [20:58<8:41:06,  7.36s/it]  7%|▋         | 300/4545 [21:05<8:29:23,  7.20s/it]                                                    {'loss': 0.448, 'grad_norm': 24.611696243286133, 'learning_rate': 7.899603698811096e-07, 'rewards/chosen': 1.271582007408142, 'rewards/rejected': -0.250244140625, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.51953125, 'logps/chosen': -271.95001220703125, 'logps/rejected': -152.10000610351562, 'logits/chosen': -6.809374809265137, 'logits/rejected': -6.762499809265137, 'epoch': 0.2}
  7%|▋         | 300/4545 [21:05<8:29:23,  7.20s/it]  7%|▋         | 301/4545 [21:12<8:24:19,  7.13s/it]  7%|▋         | 302/4545 [21:20<8:39:28,  7.35s/it]  7%|▋         | 303/4545 [21:26<8:17:57,  7.04s/it]  7%|▋         | 304/4545 [21:34<8:23:29,  7.12s/it]  7%|▋         | 305/4545 [21:41<8:36:11,  7.30s/it]  7%|▋         | 306/4545 [21:49<8:41:02,  7.37s/it]  7%|▋         | 307/4545 [21:57<8:51:15,  7.52s/it]  7%|▋         | 308/4545 [22:04<8:52:09,  7.54s/it]  7%|▋         | 309/4545 [22:12<8:52:38,  7.54s/it]  7%|▋         | 310/4545 [22:20<8:56:50,  7.61s/it]                                                    {'loss': 0.3909, 'grad_norm': 23.13298797607422, 'learning_rate': 8.163804491413474e-07, 'rewards/chosen': 2.5916991233825684, 'rewards/rejected': 0.02290039137005806, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.568359375, 'logps/chosen': -458.04998779296875, 'logps/rejected': -263.375, 'logits/chosen': -6.728125095367432, 'logits/rejected': -6.512499809265137, 'epoch': 0.2}
  7%|▋         | 310/4545 [22:20<8:56:50,  7.61s/it]  7%|▋         | 311/4545 [22:27<8:59:27,  7.64s/it]  7%|▋         | 312/4545 [22:34<8:41:21,  7.39s/it]  7%|▋         | 313/4545 [22:42<8:51:12,  7.53s/it]  7%|▋         | 314/4545 [22:50<8:53:27,  7.57s/it]  7%|▋         | 315/4545 [22:57<8:52:50,  7.56s/it]  7%|▋         | 316/4545 [23:05<8:48:39,  7.50s/it]  7%|▋         | 317/4545 [23:11<8:16:59,  7.05s/it]  7%|▋         | 318/4545 [23:18<8:32:47,  7.28s/it]  7%|▋         | 319/4545 [23:26<8:38:30,  7.36s/it]  7%|▋         | 320/4545 [23:34<8:43:07,  7.43s/it]                                                    {'loss': 0.3853, 'grad_norm': 25.39702606201172, 'learning_rate': 8.428005284015852e-07, 'rewards/chosen': 1.274572730064392, 'rewards/rejected': -0.6634765863418579, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 1.9406249523162842, 'logps/chosen': -278.20001220703125, 'logps/rejected': -175.64999389648438, 'logits/chosen': -7.143750190734863, 'logits/rejected': -7.109375, 'epoch': 0.21}
  7%|▋         | 320/4545 [23:34<8:43:07,  7.43s/it]  7%|▋         | 321/4545 [23:40<8:31:53,  7.27s/it]  7%|▋         | 322/4545 [23:48<8:41:02,  7.40s/it]  7%|▋         | 323/4545 [23:56<8:50:00,  7.53s/it]  7%|▋         | 324/4545 [24:39<21:25:01, 18.27s/it]  7%|▋         | 325/4545 [24:56<20:51:10, 17.79s/it]  7%|▋         | 326/4545 [25:13<20:39:46, 17.63s/it]  7%|▋         | 327/4545 [25:30<20:30:14, 17.50s/it]  7%|▋         | 328/4545 [25:48<20:32:58, 17.54s/it]  7%|▋         | 329/4545 [26:05<20:20:31, 17.37s/it]  7%|▋         | 330/4545 [26:22<20:18:33, 17.35s/it]                                                     {'loss': 0.4091, 'grad_norm': 17.127994537353516, 'learning_rate': 8.692206076618229e-07, 'rewards/chosen': 0.917095959186554, 'rewards/rejected': -0.763867199420929, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.6798827648162842, 'logps/chosen': -218.10000610351562, 'logps/rejected': -155.0500030517578, 'logits/chosen': -7.221875190734863, 'logits/rejected': -6.931250095367432, 'epoch': 0.22}
  7%|▋         | 330/4545 [26:22<20:18:33, 17.35s/it]  7%|▋         | 331/4545 [26:39<20:02:08, 17.12s/it]  7%|▋         | 332/4545 [26:57<20:14:00, 17.29s/it]  7%|▋         | 333/4545 [27:13<20:02:44, 17.13s/it]  7%|▋         | 334/4545 [27:31<20:12:02, 17.27s/it]  7%|▋         | 335/4545 [27:48<20:04:24, 17.16s/it]  7%|▋         | 336/4545 [28:04<19:53:12, 17.01s/it]  7%|▋         | 337/4545 [28:22<20:03:37, 17.16s/it]  7%|▋         | 338/4545 [28:28<16:07:09, 13.79s/it]  7%|▋         | 339/4545 [28:32<12:39:44, 10.84s/it]  7%|▋         | 340/4545 [28:36<10:14:53,  8.77s/it]                                                     {'loss': 0.3486, 'grad_norm': 21.386062622070312, 'learning_rate': 8.956406869220607e-07, 'rewards/chosen': 0.727063000202179, 'rewards/rejected': -1.201171875, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.9296875, 'logps/chosen': -171.5, 'logps/rejected': -126.67500305175781, 'logits/chosen': -7.409375190734863, 'logits/rejected': -7.175000190734863, 'epoch': 0.22}
  7%|▋         | 340/4545 [28:36<10:14:53,  8.77s/it]  8%|▊         | 341/4545 [28:40<8:35:42,  7.36s/it]   8%|▊         | 342/4545 [28:44<7:23:52,  6.34s/it]  8%|▊         | 343/4545 [28:48<6:35:23,  5.65s/it]  8%|▊         | 344/4545 [28:52<5:52:51,  5.04s/it]  8%|▊         | 345/4545 [28:54<5:08:13,  4.40s/it]  8%|▊         | 346/4545 [28:58<4:59:05,  4.27s/it]  8%|▊         | 347/4545 [29:03<4:57:31,  4.25s/it]  8%|▊         | 348/4545 [29:07<4:54:42,  4.21s/it]  8%|▊         | 349/4545 [29:11<4:49:12,  4.14s/it]  8%|▊         | 350/4545 [29:15<4:44:53,  4.07s/it]                                                    {'loss': 0.337, 'grad_norm': 17.569923400878906, 'learning_rate': 9.220607661822985e-07, 'rewards/chosen': 2.096057176589966, 'rewards/rejected': -0.94287109375, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.038281202316284, 'logps/chosen': -379.5, 'logps/rejected': -204.0, 'logits/chosen': -7.162499904632568, 'logits/rejected': -6.84375, 'epoch': 0.23}
  8%|▊         | 350/4545 [29:15<4:44:53,  4.07s/it]  8%|▊         | 351/4545 [29:19<4:45:44,  4.09s/it]  8%|▊         | 352/4545 [29:21<4:14:50,  3.65s/it]  8%|▊         | 353/4545 [29:25<4:20:59,  3.74s/it]  8%|▊         | 354/4545 [29:29<4:27:19,  3.83s/it]  8%|▊         | 355/4545 [29:33<4:30:02,  3.87s/it]  8%|▊         | 356/4545 [29:37<4:34:46,  3.94s/it]  8%|▊         | 357/4545 [29:41<4:23:06,  3.77s/it]  8%|▊         | 358/4545 [29:43<3:53:30,  3.35s/it]  8%|▊         | 359/4545 [29:47<4:10:08,  3.59s/it]  8%|▊         | 360/4545 [29:51<4:17:36,  3.69s/it]                                                    {'loss': 0.3294, 'grad_norm': 28.4904842376709, 'learning_rate': 9.484808454425363e-07, 'rewards/chosen': 1.7938964366912842, 'rewards/rejected': -1.229394555091858, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.0234375, 'logps/chosen': -313.45001220703125, 'logps/rejected': -184.64999389648438, 'logits/chosen': -7.290625095367432, 'logits/rejected': -6.996874809265137, 'epoch': 0.24}
  8%|▊         | 360/4545 [29:51<4:17:36,  3.69s/it]  8%|▊         | 361/4545 [29:55<4:09:46,  3.58s/it]  8%|▊         | 362/4545 [29:59<4:18:12,  3.70s/it]  8%|▊         | 363/4545 [30:02<4:22:58,  3.77s/it]  8%|▊         | 364/4545 [30:06<4:10:34,  3.60s/it]  8%|▊         | 365/4545 [30:10<4:22:27,  3.77s/it]  8%|▊         | 366/4545 [30:14<4:26:11,  3.82s/it]  8%|▊         | 367/4545 [30:18<4:32:49,  3.92s/it]  8%|▊         | 368/4545 [30:22<4:33:31,  3.93s/it]  8%|▊         | 369/4545 [30:26<4:34:02,  3.94s/it]  8%|▊         | 370/4545 [30:30<4:34:47,  3.95s/it]                                                    {'loss': 0.3359, 'grad_norm': 21.32956314086914, 'learning_rate': 9.74900924702774e-07, 'rewards/chosen': 2.9296875, 'rewards/rejected': -1.199804663658142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.131249904632568, 'logps/chosen': -464.8500061035156, 'logps/rejected': -256.3999938964844, 'logits/chosen': -7.243750095367432, 'logits/rejected': -7.0, 'epoch': 0.24}
  8%|▊         | 370/4545 [30:30<4:34:47,  3.95s/it]  8%|▊         | 371/4545 [30:33<4:22:08,  3.77s/it]  8%|▊         | 372/4545 [30:37<4:32:42,  3.92s/it]  8%|▊         | 373/4545 [30:41<4:33:36,  3.93s/it]  8%|▊         | 374/4545 [30:45<4:28:38,  3.86s/it]  8%|▊         | 375/4545 [30:48<4:06:07,  3.54s/it]  8%|▊         | 376/4545 [30:52<4:14:49,  3.67s/it]  8%|▊         | 377/4545 [30:56<4:20:21,  3.75s/it]  8%|▊         | 378/4545 [31:00<4:22:36,  3.78s/it]  8%|▊         | 379/4545 [31:01<3:34:10,  3.08s/it]  8%|▊         | 380/4545 [31:05<3:46:47,  3.27s/it]                                                    {'loss': 0.3187, 'grad_norm': 10.849260330200195, 'learning_rate': 1.0013210039630118e-06, 'rewards/chosen': 0.9964355230331421, 'rewards/rejected': -1.5421874523162842, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.5406250953674316, 'logps/chosen': -200.14999389648438, 'logps/rejected': -152.125, 'logits/chosen': -7.506249904632568, 'logits/rejected': -7.146874904632568, 'epoch': 0.25}
  8%|▊         | 380/4545 [31:05<3:46:47,  3.27s/it]  8%|▊         | 381/4545 [31:08<3:43:26,  3.22s/it]  8%|▊         | 382/4545 [31:12<3:57:28,  3.42s/it]  8%|▊         | 383/4545 [31:16<4:08:32,  3.58s/it]  8%|▊         | 384/4545 [31:20<4:16:02,  3.69s/it]  8%|▊         | 385/4545 [31:24<4:19:11,  3.74s/it]  8%|▊         | 386/4545 [31:27<4:23:28,  3.80s/it]  9%|▊         | 387/4545 [31:32<4:31:08,  3.91s/it]  9%|▊         | 388/4545 [31:36<4:31:51,  3.92s/it]  9%|▊         | 389/4545 [31:40<4:32:31,  3.93s/it]  9%|▊         | 390/4545 [31:43<4:32:08,  3.93s/it]                                                    {'loss': 0.3403, 'grad_norm': 14.809441566467285, 'learning_rate': 1.0277410832232497e-06, 'rewards/chosen': 2.298287868499756, 'rewards/rejected': -1.727636694908142, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.024609565734863, 'logps/chosen': -355.3500061035156, 'logps/rejected': -208.89999389648438, 'logits/chosen': -7.484375, 'logits/rejected': -7.143750190734863, 'epoch': 0.26}
  9%|▊         | 390/4545 [31:44<4:32:08,  3.93s/it]  9%|▊         | 391/4545 [31:48<4:36:10,  3.99s/it]  9%|▊         | 392/4545 [31:52<4:40:45,  4.06s/it]  9%|▊         | 393/4545 [31:56<4:38:41,  4.03s/it]  9%|▊         | 394/4545 [32:00<4:32:15,  3.94s/it]  9%|▊         | 395/4545 [32:03<4:23:19,  3.81s/it]  9%|▊         | 396/4545 [32:07<4:27:20,  3.87s/it]  9%|▊         | 397/4545 [32:11<4:30:47,  3.92s/it]  9%|▉         | 398/4545 [32:15<4:30:38,  3.92s/it]  9%|▉         | 399/4545 [32:19<4:30:59,  3.92s/it]  9%|▉         | 400/4545 [32:23<4:32:06,  3.94s/it]                                                    {'loss': 0.2732, 'grad_norm': 10.548149108886719, 'learning_rate': 1.0541611624834874e-06, 'rewards/chosen': 1.52880859375, 'rewards/rejected': -2.4847655296325684, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.01171875, 'logps/chosen': -288.54998779296875, 'logps/rejected': -191.5, 'logits/chosen': -7.653124809265137, 'logits/rejected': -7.349999904632568, 'epoch': 0.26}
  9%|▉         | 400/4545 [32:23<4:32:06,  3.94s/it]  9%|▉         | 401/4545 [32:26<4:17:26,  3.73s/it]  9%|▉         | 402/4545 [32:30<4:28:10,  3.88s/it]  9%|▉         | 403/4545 [32:34<4:29:00,  3.90s/it]  9%|▉         | 404/4545 [32:38<4:29:50,  3.91s/it]  9%|▉         | 405/4545 [32:41<4:00:17,  3.48s/it]  9%|▉         | 406/4545 [32:44<3:48:52,  3.32s/it]  9%|▉         | 407/4545 [32:46<3:37:50,  3.16s/it]  9%|▉         | 408/4545 [32:51<4:01:49,  3.51s/it]  9%|▉         | 409/4545 [32:54<4:01:35,  3.50s/it]  9%|▉         | 410/4545 [32:58<4:04:07,  3.54s/it]                                                    {'loss': 0.2981, 'grad_norm': 14.74892520904541, 'learning_rate': 1.0805812417437253e-06, 'rewards/chosen': 0.7607177495956421, 'rewards/rejected': -2.639843702316284, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.4000000953674316, 'logps/chosen': -192.6999969482422, 'logps/rejected': -154.9499969482422, 'logits/chosen': -7.793749809265137, 'logits/rejected': -7.434374809265137, 'epoch': 0.27}
  9%|▉         | 410/4545 [32:58<4:04:07,  3.54s/it]  9%|▉         | 411/4545 [33:02<4:13:26,  3.68s/it]  9%|▉         | 412/4545 [33:06<4:18:03,  3.75s/it]  9%|▉         | 413/4545 [33:09<4:10:22,  3.64s/it]  9%|▉         | 414/4545 [33:13<4:20:23,  3.78s/it]  9%|▉         | 415/4545 [33:16<3:57:12,  3.45s/it]  9%|▉         | 416/4545 [33:19<3:45:48,  3.28s/it]  9%|▉         | 417/4545 [33:23<4:02:17,  3.52s/it]  9%|▉         | 418/4545 [33:26<3:54:04,  3.40s/it]  9%|▉         | 419/4545 [33:30<4:05:08,  3.56s/it]  9%|▉         | 420/4545 [33:33<3:57:37,  3.46s/it]                                                    {'loss': 0.3176, 'grad_norm': 18.809911727905273, 'learning_rate': 1.107001321003963e-06, 'rewards/chosen': 1.3354003429412842, 'rewards/rejected': -2.765625, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.099218845367432, 'logps/chosen': -257.25, 'logps/rejected': -172.1999969482422, 'logits/chosen': -7.734375, 'logits/rejected': -7.375, 'epoch': 0.28}
  9%|▉         | 420/4545 [33:33<3:57:37,  3.46s/it]  9%|▉         | 421/4545 [33:37<4:08:09,  3.61s/it]  9%|▉         | 422/4545 [33:41<4:16:08,  3.73s/it]  9%|▉         | 423/4545 [33:44<4:06:31,  3.59s/it]  9%|▉         | 424/4545 [33:48<4:06:53,  3.59s/it]  9%|▉         | 425/4545 [33:52<4:08:51,  3.62s/it]  9%|▉         | 426/4545 [33:56<4:14:52,  3.71s/it]  9%|▉         | 427/4545 [34:00<4:21:16,  3.81s/it]  9%|▉         | 428/4545 [34:02<3:45:13,  3.28s/it]  9%|▉         | 429/4545 [34:05<3:47:32,  3.32s/it]  9%|▉         | 430/4545 [34:09<4:02:58,  3.54s/it]                                                    {'loss': 0.3794, 'grad_norm': 33.644508361816406, 'learning_rate': 1.1334214002642007e-06, 'rewards/chosen': 1.141357421875, 'rewards/rejected': -2.44921875, 'rewards/accuracies': 0.8125, 'rewards/margins': 3.5914063453674316, 'logps/chosen': -272.95001220703125, 'logps/rejected': -145.14999389648438, 'logits/chosen': -7.78125, 'logits/rejected': -7.559374809265137, 'epoch': 0.28}
  9%|▉         | 430/4545 [34:09<4:02:58,  3.54s/it]  9%|▉         | 431/4545 [34:14<4:19:00,  3.78s/it] 10%|▉         | 432/4545 [34:17<4:22:28,  3.83s/it] 10%|▉         | 433/4545 [34:22<4:27:36,  3.90s/it] 10%|▉         | 434/4545 [34:26<4:33:35,  3.99s/it] 10%|▉         | 435/4545 [34:29<4:11:50,  3.68s/it] 10%|▉         | 436/4545 [34:33<4:18:28,  3.77s/it] 10%|▉         | 437/4545 [34:37<4:27:05,  3.90s/it] 10%|▉         | 438/4545 [34:40<4:11:59,  3.68s/it] 10%|▉         | 439/4545 [34:43<3:57:31,  3.47s/it] 10%|▉         | 440/4545 [34:47<4:07:03,  3.61s/it]                                                    {'loss': 0.3215, 'grad_norm': 22.97377586364746, 'learning_rate': 1.1598414795244384e-06, 'rewards/chosen': 0.8493286371231079, 'rewards/rejected': -2.658984422683716, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 3.5093750953674316, 'logps/chosen': -206.75, 'logps/rejected': -190.9499969482422, 'logits/chosen': -8.0, 'logits/rejected': -7.596875190734863, 'epoch': 0.29}
 10%|▉         | 440/4545 [34:47<4:07:03,  3.61s/it] 10%|▉         | 441/4545 [34:51<4:17:39,  3.77s/it] 10%|▉         | 442/4545 [34:54<4:09:25,  3.65s/it] 10%|▉         | 443/4545 [34:59<4:17:43,  3.77s/it] 10%|▉         | 444/4545 [35:02<4:21:12,  3.82s/it] 10%|▉         | 445/4545 [35:05<4:00:09,  3.51s/it] 10%|▉         | 446/4545 [35:09<4:14:10,  3.72s/it] 10%|▉         | 447/4545 [35:12<3:53:00,  3.41s/it] 10%|▉         | 448/4545 [35:16<4:03:33,  3.57s/it] 10%|▉         | 449/4545 [35:20<4:11:09,  3.68s/it] 10%|▉         | 450/4545 [35:24<4:17:47,  3.78s/it]                                                    {'loss': 0.226, 'grad_norm': 8.776082038879395, 'learning_rate': 1.1862615587846764e-06, 'rewards/chosen': 2.040820360183716, 'rewards/rejected': -2.9281249046325684, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.965624809265137, 'logps/chosen': -343.5249938964844, 'logps/rejected': -210.35000610351562, 'logits/chosen': -7.821875095367432, 'logits/rejected': -7.412499904632568, 'epoch': 0.3}
 10%|▉         | 450/4545 [35:24<4:17:47,  3.78s/it] 10%|▉         | 451/4545 [35:28<4:23:03,  3.86s/it] 10%|▉         | 452/4545 [35:32<4:24:27,  3.88s/it] 10%|▉         | 453/4545 [35:36<4:28:01,  3.93s/it] 10%|▉         | 454/4545 [35:40<4:28:25,  3.94s/it] 10%|█         | 455/4545 [35:44<4:28:28,  3.94s/it] 10%|█         | 456/4545 [35:48<4:24:21,  3.88s/it] 10%|█         | 457/4545 [35:52<4:25:40,  3.90s/it] 10%|█         | 458/4545 [35:56<4:26:31,  3.91s/it] 10%|█         | 459/4545 [36:00<4:28:40,  3.95s/it] 10%|█         | 460/4545 [36:03<4:22:39,  3.86s/it]                                                    {'loss': 0.2869, 'grad_norm': 35.691165924072266, 'learning_rate': 1.212681638044914e-06, 'rewards/chosen': 3.3511719703674316, 'rewards/rejected': -2.5611329078674316, 'rewards/accuracies': 0.875, 'rewards/margins': 5.912499904632568, 'logps/chosen': -508.20001220703125, 'logps/rejected': -306.0, 'logits/chosen': -7.556250095367432, 'logits/rejected': -7.243750095367432, 'epoch': 0.3}
 10%|█         | 460/4545 [36:03<4:22:39,  3.86s/it] 10%|█         | 461/4545 [36:07<4:24:07,  3.88s/it] 10%|█         | 462/4545 [36:11<4:28:42,  3.95s/it] 10%|█         | 463/4545 [36:15<4:29:13,  3.96s/it] 10%|█         | 464/4545 [36:19<4:14:46,  3.75s/it] 10%|█         | 465/4545 [36:47<12:47:35, 11.29s/it] 10%|█         | 466/4545 [36:50<9:55:54,  8.77s/it]  10%|█         | 467/4545 [36:54<8:17:30,  7.32s/it] 10%|█         | 468/4545 [36:58<7:09:19,  6.32s/it] 10%|█         | 469/4545 [37:02<6:20:54,  5.61s/it] 10%|█         | 470/4545 [37:05<5:17:08,  4.67s/it]                                                    {'loss': 0.2836, 'grad_norm': 13.70383071899414, 'learning_rate': 1.239101717305152e-06, 'rewards/chosen': 0.650390625, 'rewards/rejected': -4.295312404632568, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.942968845367432, 'logps/chosen': -202.5, 'logps/rejected': -142.9499969482422, 'logits/chosen': -7.946875095367432, 'logits/rejected': -7.321875095367432, 'epoch': 0.31}
 10%|█         | 470/4545 [37:05<5:17:08,  4.67s/it] 10%|█         | 471/4545 [37:09<5:07:04,  4.52s/it] 10%|█         | 472/4545 [37:13<5:00:23,  4.43s/it] 10%|█         | 473/4545 [37:17<4:52:54,  4.32s/it] 10%|█         | 474/4545 [37:21<4:43:31,  4.18s/it] 10%|█         | 475/4545 [37:25<4:38:34,  4.11s/it] 10%|█         | 476/4545 [37:29<4:38:16,  4.10s/it] 10%|█         | 477/4545 [37:58<13:05:46, 11.59s/it] 11%|█         | 478/4545 [38:02<10:24:30,  9.21s/it] 11%|█         | 479/4545 [38:05<8:26:41,  7.48s/it]  11%|█         | 480/4545 [38:09<7:15:27,  6.43s/it]                                                    {'loss': 0.2414, 'grad_norm': 12.398701667785645, 'learning_rate': 1.2655217965653897e-06, 'rewards/chosen': 0.8764892816543579, 'rewards/rejected': -4.7265625, 'rewards/accuracies': 0.875, 'rewards/margins': 5.606249809265137, 'logps/chosen': -266.3500061035156, 'logps/rejected': -209.10000610351562, 'logits/chosen': -8.009374618530273, 'logits/rejected': -7.59375, 'epoch': 0.32}
 11%|█         | 480/4545 [38:09<7:15:27,  6.43s/it] 11%|█         | 481/4545 [38:13<6:26:00,  5.70s/it] 11%|█         | 482/4545 [38:17<5:52:42,  5.21s/it] 11%|█         | 483/4545 [38:21<5:24:21,  4.79s/it] 11%|█         | 484/4545 [38:25<5:09:28,  4.57s/it] 11%|█         | 485/4545 [38:29<5:00:24,  4.44s/it] 11%|█         | 486/4545 [38:33<4:44:36,  4.21s/it] 11%|█         | 487/4545 [38:35<4:09:59,  3.70s/it] 11%|█         | 488/4545 [38:39<4:15:32,  3.78s/it] 11%|█         | 489/4545 [38:43<4:20:40,  3.86s/it] 11%|█         | 490/4545 [38:47<4:24:00,  3.91s/it]                                                    {'loss': 0.3013, 'grad_norm': 26.765880584716797, 'learning_rate': 1.2919418758256276e-06, 'rewards/chosen': 0.9100921750068665, 'rewards/rejected': -4.829687595367432, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 5.740624904632568, 'logps/chosen': -253.10000610351562, 'logps/rejected': -161.0500030517578, 'logits/chosen': -8.309374809265137, 'logits/rejected': -7.675000190734863, 'epoch': 0.32}
 11%|█         | 490/4545 [38:48<4:24:00,  3.91s/it] 11%|█         | 491/4545 [38:50<3:59:07,  3.54s/it] 11%|█         | 492/4545 [38:54<4:09:54,  3.70s/it] 11%|█         | 493/4545 [38:58<4:19:13,  3.84s/it] 11%|█         | 494/4545 [39:02<4:25:07,  3.93s/it] 11%|█         | 495/4545 [39:06<4:21:36,  3.88s/it] 11%|█         | 496/4545 [39:10<4:14:19,  3.77s/it] 11%|█         | 497/4545 [39:14<4:15:32,  3.79s/it] 11%|█         | 498/4545 [39:18<4:19:13,  3.84s/it] 11%|█         | 499/4545 [39:21<4:19:24,  3.85s/it] 11%|█         | 500/4545 [39:25<4:22:51,  3.90s/it]                                                    {'loss': 0.2411, 'grad_norm': 34.7933349609375, 'learning_rate': 1.3183619550858651e-06, 'rewards/chosen': 0.634082019329071, 'rewards/rejected': -6.193749904632568, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 6.831250190734863, 'logps/chosen': -226.25, 'logps/rejected': -166.35000610351562, 'logits/chosen': -8.393750190734863, 'logits/rejected': -7.840624809265137, 'epoch': 0.33}
 11%|█         | 500/4545 [39:26<4:22:51,  3.90s/it] 11%|█         | 501/4545 [39:29<4:17:53,  3.83s/it] 11%|█         | 502/4545 [39:33<4:19:59,  3.86s/it] 11%|█         | 503/4545 [39:36<4:12:10,  3.74s/it] 11%|█         | 504/4545 [39:40<4:16:06,  3.80s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:40,  1.44it/s][A
  5%|▌         | 3/60 [00:03<01:00,  1.06s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.29s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.39s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:22,  1.55s/it][A
 13%|█▎        | 8/60 [00:11<01:23,  1.60s/it][A
 15%|█▌        | 9/60 [00:12<01:22,  1.62s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.61s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.63s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.52s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:40,  1.13s/it][A
 42%|████▏     | 25/60 [00:33<00:44,  1.28s/it][A
 43%|████▎     | 26/60 [00:34<00:45,  1.33s/it][A
 45%|████▌     | 27/60 [00:35<00:38,  1.16s/it][A
 47%|████▋     | 28/60 [00:36<00:35,  1.09s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.13s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.29s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:46<00:31,  1.28s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.33s/it][A
 62%|██████▏   | 37/60 [00:48<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [01:14<03:13,  8.82s/it][A
 65%|██████▌   | 39/60 [01:15<02:16,  6.52s/it][A
 67%|██████▋   | 40/60 [01:16<01:36,  4.81s/it][A
 68%|██████▊   | 41/60 [01:18<01:12,  3.81s/it][A
 70%|███████   | 42/60 [01:19<00:56,  3.14s/it][A
 72%|███████▏  | 43/60 [01:20<00:42,  2.49s/it][A
 73%|███████▎  | 44/60 [01:22<00:35,  2.19s/it][A
 75%|███████▌  | 45/60 [01:23<00:26,  1.77s/it][A
 77%|███████▋  | 46/60 [01:24<00:24,  1.72s/it][A
 78%|███████▊  | 47/60 [01:26<00:22,  1.72s/it][A
 80%|████████  | 48/60 [01:27<00:17,  1.45s/it][A
 82%|████████▏ | 49/60 [01:28<00:16,  1.49s/it][A
 83%|████████▎ | 50/60 [01:30<00:15,  1.55s/it][A
 85%|████████▌ | 51/60 [01:32<00:13,  1.55s/it][A
 87%|████████▋ | 52/60 [01:33<00:11,  1.46s/it][A
 88%|████████▊ | 53/60 [01:34<00:09,  1.35s/it][A
 90%|█████████ | 54/60 [01:35<00:08,  1.42s/it][A
 92%|█████████▏| 55/60 [01:36<00:06,  1.22s/it][A
 93%|█████████▎| 56/60 [01:38<00:05,  1.33s/it][A
 95%|█████████▌| 57/60 [01:39<00:04,  1.40s/it][A
 97%|█████████▋| 58/60 [01:41<00:02,  1.40s/it][A
 98%|█████████▊| 59/60 [01:42<00:01,  1.46s/it][A
100%|██████████| 60/60 [01:44<00:00,  1.51s/it][A                                                    
                                               [A{'eval_loss': 0.43948182463645935, 'eval_runtime': 106.3474, 'eval_samples_per_second': 8.961, 'eval_steps_per_second': 0.564, 'eval_rewards/chosen': 1.2937769889831543, 'eval_rewards/rejected': -4.818652153015137, 'eval_rewards/accuracies': 0.7993055582046509, 'eval_rewards/margins': 6.1100993156433105, 'eval_logps/chosen': -364.6000061035156, 'eval_logps/rejected': -200.2291717529297, 'eval_logits/chosen': -8.171875, 'eval_logits/rejected': -8.322396278381348, 'epoch': 0.33}
 11%|█         | 504/4545 [41:27<4:16:06,  3.80s/it]
100%|██████████| 60/60 [01:44<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 11%|█         | 505/4545 [41:43<44:23:37, 39.56s/it] 11%|█         | 506/4545 [41:46<32:06:06, 28.61s/it] 11%|█         | 507/4545 [41:50<23:47:26, 21.21s/it] 11%|█         | 508/4545 [41:54<17:59:11, 16.04s/it] 11%|█         | 509/4545 [41:58<13:40:39, 12.20s/it] 11%|█         | 510/4545 [42:02<10:53:23,  9.72s/it]                                                     {'loss': 0.2822, 'grad_norm': 15.112360000610352, 'learning_rate': 1.344782034346103e-06, 'rewards/chosen': 1.7345702648162842, 'rewards/rejected': -7.3671875, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 9.109375, 'logps/chosen': -373.3500061035156, 'logps/rejected': -293.95001220703125, 'logits/chosen': -8.240625381469727, 'logits/rejected': -7.740624904632568, 'epoch': 0.34}
 11%|█         | 510/4545 [42:02<10:53:23,  9.72s/it] 11%|█         | 511/4545 [42:06<9:03:37,  8.09s/it]  11%|█▏        | 512/4545 [42:10<7:34:59,  6.77s/it] 11%|█▏        | 513/4545 [42:13<6:38:08,  5.92s/it] 11%|█▏        | 514/4545 [42:17<5:57:48,  5.33s/it] 11%|█▏        | 515/4545 [42:21<5:13:43,  4.67s/it] 11%|█▏        | 516/4545 [42:24<4:56:47,  4.42s/it] 11%|█▏        | 517/4545 [42:27<4:29:03,  4.01s/it] 11%|█▏        | 518/4545 [42:31<4:19:05,  3.86s/it] 11%|█▏        | 519/4545 [42:35<4:21:31,  3.90s/it] 11%|█▏        | 520/4545 [42:39<4:23:12,  3.92s/it]                                                    {'loss': 0.3026, 'grad_norm': 27.21781349182129, 'learning_rate': 1.3712021136063407e-06, 'rewards/chosen': 0.9390624761581421, 'rewards/rejected': -8.23046875, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 9.175000190734863, 'logps/chosen': -289.70001220703125, 'logps/rejected': -217.6999969482422, 'logits/chosen': -8.321874618530273, 'logits/rejected': -7.6875, 'epoch': 0.34}
 11%|█▏        | 520/4545 [42:39<4:23:12,  3.92s/it] 11%|█▏        | 521/4545 [42:43<4:25:04,  3.95s/it] 11%|█▏        | 522/4545 [42:47<4:31:50,  4.05s/it] 12%|█▏        | 523/4545 [42:51<4:29:41,  4.02s/it] 12%|█▏        | 524/4545 [42:55<4:27:39,  3.99s/it] 12%|█▏        | 525/4545 [42:59<4:21:56,  3.91s/it] 12%|█▏        | 526/4545 [43:03<4:26:31,  3.98s/it] 12%|█▏        | 527/4545 [43:07<4:28:12,  4.01s/it] 12%|█▏        | 528/4545 [43:11<4:32:23,  4.07s/it] 12%|█▏        | 529/4545 [43:15<4:21:28,  3.91s/it] 12%|█▏        | 530/4545 [43:19<4:26:30,  3.98s/it]                                                    {'loss': 0.263, 'grad_norm': 28.048479080200195, 'learning_rate': 1.3976221928665787e-06, 'rewards/chosen': 0.5717407464981079, 'rewards/rejected': -7.231249809265137, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 7.806250095367432, 'logps/chosen': -259.25, 'logps/rejected': -200.89999389648438, 'logits/chosen': -8.125, 'logits/rejected': -7.540625095367432, 'epoch': 0.35}
 12%|█▏        | 530/4545 [43:19<4:26:30,  3.98s/it] 12%|█▏        | 531/4545 [43:23<4:33:27,  4.09s/it] 12%|█▏        | 532/4545 [43:27<4:30:22,  4.04s/it] 12%|█▏        | 533/4545 [43:30<4:12:08,  3.77s/it] 12%|█▏        | 534/4545 [43:35<4:20:40,  3.90s/it] 12%|█▏        | 535/4545 [43:38<4:21:00,  3.91s/it] 12%|█▏        | 536/4545 [43:42<4:21:43,  3.92s/it] 12%|█▏        | 537/4545 [43:45<4:01:17,  3.61s/it] 12%|█▏        | 538/4545 [43:49<4:04:05,  3.66s/it] 12%|█▏        | 539/4545 [43:53<4:09:47,  3.74s/it] 12%|█▏        | 540/4545 [43:57<4:14:21,  3.81s/it]                                                    {'loss': 0.2907, 'grad_norm': 8.563004493713379, 'learning_rate': 1.4240422721268164e-06, 'rewards/chosen': 0.7920898199081421, 'rewards/rejected': -4.653124809265137, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 5.443749904632568, 'logps/chosen': -216.9499969482422, 'logps/rejected': -188.6999969482422, 'logits/chosen': -8.131250381469727, 'logits/rejected': -7.559374809265137, 'epoch': 0.36}
 12%|█▏        | 540/4545 [43:57<4:14:21,  3.81s/it] 12%|█▏        | 541/4545 [44:01<4:17:48,  3.86s/it] 12%|█▏        | 542/4545 [44:05<4:18:34,  3.88s/it] 12%|█▏        | 543/4545 [44:09<4:15:33,  3.83s/it] 12%|█▏        | 544/4545 [44:13<4:17:41,  3.86s/it] 12%|█▏        | 545/4545 [44:17<4:25:38,  3.98s/it] 12%|█▏        | 546/4545 [44:21<4:24:10,  3.96s/it] 12%|█▏        | 547/4545 [44:25<4:23:12,  3.95s/it] 12%|█▏        | 548/4545 [44:28<4:14:31,  3.82s/it] 12%|█▏        | 549/4545 [44:32<4:09:06,  3.74s/it] 12%|█▏        | 550/4545 [44:36<4:13:16,  3.80s/it]                                                    {'loss': 0.3334, 'grad_norm': 31.43065643310547, 'learning_rate': 1.4504623513870543e-06, 'rewards/chosen': 1.132421851158142, 'rewards/rejected': -6.131249904632568, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 7.265625, 'logps/chosen': -325.45001220703125, 'logps/rejected': -246.0500030517578, 'logits/chosen': -7.878125190734863, 'logits/rejected': -7.365624904632568, 'epoch': 0.36}
 12%|█▏        | 550/4545 [44:36<4:13:16,  3.80s/it] 12%|█▏        | 551/4545 [44:40<4:17:26,  3.87s/it] 12%|█▏        | 552/4545 [44:44<4:18:49,  3.89s/it] 12%|█▏        | 553/4545 [44:48<4:19:51,  3.91s/it] 12%|█▏        | 554/4545 [44:51<4:09:24,  3.75s/it] 12%|█▏        | 555/4545 [44:55<4:13:21,  3.81s/it] 12%|█▏        | 556/4545 [44:59<4:17:09,  3.87s/it] 12%|█▏        | 557/4545 [45:01<3:50:43,  3.47s/it] 12%|█▏        | 558/4545 [45:05<4:00:51,  3.62s/it] 12%|█▏        | 559/4545 [45:08<3:49:24,  3.45s/it] 12%|█▏        | 560/4545 [45:12<3:58:04,  3.58s/it]                                                    {'loss': 0.2816, 'grad_norm': 15.26225757598877, 'learning_rate': 1.4768824306472918e-06, 'rewards/chosen': 1.388372778892517, 'rewards/rejected': -6.453125, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 7.840624809265137, 'logps/chosen': -323.79998779296875, 'logps/rejected': -269.8999938964844, 'logits/chosen': -8.090624809265137, 'logits/rejected': -7.449999809265137, 'epoch': 0.37}
 12%|█▏        | 560/4545 [45:12<3:58:04,  3.58s/it] 12%|█▏        | 561/4545 [45:16<4:04:48,  3.69s/it] 12%|█▏        | 562/4545 [45:20<4:09:38,  3.76s/it] 12%|█▏        | 563/4545 [45:23<3:56:02,  3.56s/it] 12%|█▏        | 564/4545 [45:27<3:52:29,  3.50s/it] 12%|█▏        | 565/4545 [45:31<4:02:49,  3.66s/it] 12%|█▏        | 566/4545 [45:35<4:08:50,  3.75s/it] 12%|█▏        | 567/4545 [45:38<4:09:39,  3.77s/it] 12%|█▏        | 568/4545 [45:42<4:12:49,  3.81s/it] 13%|█▎        | 569/4545 [45:46<4:11:59,  3.80s/it] 13%|█▎        | 570/4545 [45:50<4:18:16,  3.90s/it]                                                    {'loss': 0.2331, 'grad_norm': 10.86473560333252, 'learning_rate': 1.5033025099075297e-06, 'rewards/chosen': 1.125390648841858, 'rewards/rejected': -5.734375, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 6.854687690734863, 'logps/chosen': -256.8500061035156, 'logps/rejected': -234.60000610351562, 'logits/chosen': -8.528124809265137, 'logits/rejected': -8.03125, 'epoch': 0.38}
 13%|█▎        | 570/4545 [45:50<4:18:16,  3.90s/it] 13%|█▎        | 571/4545 [45:54<4:19:22,  3.92s/it] 13%|█▎        | 572/4545 [45:58<4:19:35,  3.92s/it] 13%|█▎        | 573/4545 [46:02<4:25:53,  4.02s/it] 13%|█▎        | 574/4545 [46:07<4:27:51,  4.05s/it] 13%|█▎        | 575/4545 [46:10<4:25:31,  4.01s/it] 13%|█▎        | 576/4545 [46:14<4:23:02,  3.98s/it] 13%|█▎        | 577/4545 [46:18<4:21:46,  3.96s/it] 13%|█▎        | 578/4545 [46:22<4:11:21,  3.80s/it] 13%|█▎        | 579/4545 [46:25<3:54:06,  3.54s/it] 13%|█▎        | 580/4545 [46:29<4:05:54,  3.72s/it]                                                    {'loss': 0.237, 'grad_norm': 18.626585006713867, 'learning_rate': 1.5297225891677674e-06, 'rewards/chosen': 1.1619141101837158, 'rewards/rejected': -5.998437404632568, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 7.15625, 'logps/chosen': -301.3500061035156, 'logps/rejected': -242.10000610351562, 'logits/chosen': -8.553125381469727, 'logits/rejected': -7.96875, 'epoch': 0.38}
 13%|█▎        | 580/4545 [46:29<4:05:54,  3.72s/it] 13%|█▎        | 581/4545 [46:32<3:57:53,  3.60s/it] 13%|█▎        | 582/4545 [46:36<4:04:41,  3.70s/it] 13%|█▎        | 583/4545 [46:39<3:47:00,  3.44s/it] 13%|█▎        | 584/4545 [46:43<3:57:23,  3.60s/it] 13%|█▎        | 585/4545 [46:46<3:51:08,  3.50s/it] 13%|█▎        | 586/4545 [46:50<3:59:29,  3.63s/it] 13%|█▎        | 587/4545 [46:54<4:10:58,  3.80s/it] 13%|█▎        | 588/4545 [46:58<4:13:52,  3.85s/it] 13%|█▎        | 589/4545 [47:01<3:53:16,  3.54s/it] 13%|█▎        | 590/4545 [47:05<3:53:02,  3.54s/it]                                                    {'loss': 0.2448, 'grad_norm': 14.224255561828613, 'learning_rate': 1.5561426684280053e-06, 'rewards/chosen': 1.159814476966858, 'rewards/rejected': -7.6796875, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 8.826562881469727, 'logps/chosen': -313.0, 'logps/rejected': -276.6000061035156, 'logits/chosen': -8.587499618530273, 'logits/rejected': -8.137499809265137, 'epoch': 0.39}
 13%|█▎        | 590/4545 [47:05<3:53:02,  3.54s/it] 13%|█▎        | 591/4545 [47:09<4:03:13,  3.69s/it] 13%|█▎        | 592/4545 [47:12<3:56:56,  3.60s/it] 13%|█▎        | 593/4545 [47:15<3:54:26,  3.56s/it] 13%|█▎        | 594/4545 [47:19<4:01:54,  3.67s/it] 13%|█▎        | 595/4545 [47:23<4:04:25,  3.71s/it] 13%|█▎        | 596/4545 [47:27<4:08:26,  3.77s/it] 13%|█▎        | 597/4545 [47:31<4:17:46,  3.92s/it] 13%|█▎        | 598/4545 [47:34<4:01:44,  3.67s/it] 13%|█▎        | 599/4545 [47:39<4:12:47,  3.84s/it] 13%|█▎        | 600/4545 [47:42<3:58:51,  3.63s/it]                                                    {'loss': 0.3173, 'grad_norm': 13.118025779724121, 'learning_rate': 1.582562747688243e-06, 'rewards/chosen': 1.073632836341858, 'rewards/rejected': -6.792187690734863, 'rewards/accuracies': 0.875, 'rewards/margins': 7.859375, 'logps/chosen': -295.8999938964844, 'logps/rejected': -257.5, 'logits/chosen': -8.675000190734863, 'logits/rejected': -7.987500190734863, 'epoch': 0.4}
 13%|█▎        | 600/4545 [47:42<3:58:51,  3.63s/it] 13%|█▎        | 601/4545 [47:45<3:57:57,  3.62s/it] 13%|█▎        | 602/4545 [47:49<3:51:44,  3.53s/it] 13%|█▎        | 603/4545 [47:53<4:00:06,  3.65s/it] 13%|█▎        | 604/4545 [47:56<3:54:41,  3.57s/it] 13%|█▎        | 605/4545 [48:00<4:07:49,  3.77s/it] 13%|█▎        | 606/4545 [48:04<3:59:12,  3.64s/it] 13%|█▎        | 607/4545 [48:08<4:08:48,  3.79s/it] 13%|█▎        | 608/4545 [48:12<4:12:04,  3.84s/it] 13%|█▎        | 609/4545 [48:16<4:13:27,  3.86s/it] 13%|█▎        | 610/4545 [48:20<4:16:18,  3.91s/it]                                                    {'loss': 0.2406, 'grad_norm': 11.136154174804688, 'learning_rate': 1.608982826948481e-06, 'rewards/chosen': 2.025195360183716, 'rewards/rejected': -8.081250190734863, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 10.09375, 'logps/chosen': -363.6000061035156, 'logps/rejected': -267.6499938964844, 'logits/chosen': -8.296875, 'logits/rejected': -7.759375095367432, 'epoch': 0.4}
 13%|█▎        | 610/4545 [48:20<4:16:18,  3.91s/it] 13%|█▎        | 611/4545 [48:24<4:23:26,  4.02s/it] 13%|█▎        | 612/4545 [48:27<4:02:00,  3.69s/it] 13%|█▎        | 613/4545 [48:31<4:06:36,  3.76s/it] 14%|█▎        | 614/4545 [48:35<4:09:34,  3.81s/it] 14%|█▎        | 615/4545 [48:38<3:51:17,  3.53s/it] 14%|█▎        | 616/4545 [48:41<3:51:22,  3.53s/it] 14%|█▎        | 617/4545 [48:45<3:59:20,  3.66s/it] 14%|█▎        | 618/4545 [48:48<3:46:36,  3.46s/it] 14%|█▎        | 619/4545 [48:52<3:55:56,  3.61s/it] 14%|█▎        | 620/4545 [48:55<3:41:10,  3.38s/it]                                                    {'loss': 0.2106, 'grad_norm': 16.112821578979492, 'learning_rate': 1.6354029062087184e-06, 'rewards/chosen': 0.7115753293037415, 'rewards/rejected': -8.732812881469727, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 9.4375, 'logps/chosen': -219.4499969482422, 'logps/rejected': -202.10000610351562, 'logits/chosen': -8.637499809265137, 'logits/rejected': -7.900000095367432, 'epoch': 0.41}
 14%|█▎        | 620/4545 [48:55<3:41:10,  3.38s/it] 14%|█▎        | 621/4545 [48:59<3:55:00,  3.59s/it] 14%|█▎        | 622/4545 [49:03<4:01:41,  3.70s/it] 14%|█▎        | 623/4545 [49:07<4:01:20,  3.69s/it] 14%|█▎        | 624/4545 [49:11<4:04:41,  3.74s/it] 14%|█▍        | 625/4545 [49:14<4:09:13,  3.81s/it] 14%|█▍        | 626/4545 [49:18<4:12:33,  3.87s/it] 14%|█▍        | 627/4545 [49:22<4:05:53,  3.77s/it] 14%|█▍        | 628/4545 [49:26<4:07:16,  3.79s/it] 14%|█▍        | 629/4545 [49:30<4:10:15,  3.83s/it] 14%|█▍        | 630/4545 [49:34<4:11:50,  3.86s/it]                                                    {'loss': 0.1432, 'grad_norm': 7.610009670257568, 'learning_rate': 1.6618229854689564e-06, 'rewards/chosen': 1.084570288658142, 'rewards/rejected': -9.948437690734863, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 11.032812118530273, 'logps/chosen': -273.29998779296875, 'logps/rejected': -251.6999969482422, 'logits/chosen': -8.5625, 'logits/rejected': -7.909375190734863, 'epoch': 0.42}
 14%|█▍        | 630/4545 [49:34<4:11:50,  3.86s/it] 14%|█▍        | 631/4545 [49:38<4:26:48,  4.09s/it] 14%|█▍        | 632/4545 [49:42<4:23:43,  4.04s/it] 14%|█▍        | 633/4545 [49:46<4:16:25,  3.93s/it] 14%|█▍        | 634/4545 [49:50<4:21:59,  4.02s/it] 14%|█▍        | 635/4545 [49:54<4:24:16,  4.06s/it] 14%|█▍        | 636/4545 [49:58<4:25:04,  4.07s/it] 14%|█▍        | 637/4545 [50:03<4:25:47,  4.08s/it] 14%|█▍        | 638/4545 [50:06<4:22:59,  4.04s/it] 14%|█▍        | 639/4545 [50:10<4:16:06,  3.93s/it] 14%|█▍        | 640/4545 [50:14<4:11:25,  3.86s/it]                                                    {'loss': 0.2303, 'grad_norm': 10.39172649383545, 'learning_rate': 1.688243064729194e-06, 'rewards/chosen': 0.11562500149011612, 'rewards/rejected': -13.96875, 'rewards/accuracies': 0.90625, 'rewards/margins': 14.09375, 'logps/chosen': -200.0, 'logps/rejected': -274.3999938964844, 'logits/chosen': -8.84375, 'logits/rejected': -8.053125381469727, 'epoch': 0.42}
 14%|█▍        | 640/4545 [50:14<4:11:25,  3.86s/it] 14%|█▍        | 641/4545 [50:18<4:18:03,  3.97s/it] 14%|█▍        | 642/4545 [50:22<4:17:50,  3.96s/it] 14%|█▍        | 643/4545 [50:26<4:17:02,  3.95s/it] 14%|█▍        | 644/4545 [50:30<4:16:11,  3.94s/it] 14%|█▍        | 645/4545 [50:34<4:16:19,  3.94s/it] 14%|█▍        | 646/4545 [50:38<4:16:17,  3.94s/it] 14%|█▍        | 647/4545 [50:41<4:00:17,  3.70s/it] 14%|█▍        | 648/4545 [50:45<4:04:39,  3.77s/it] 14%|█▍        | 649/4545 [50:49<4:09:30,  3.84s/it] 14%|█▍        | 650/4545 [50:53<4:11:22,  3.87s/it]                                                    {'loss': 0.3043, 'grad_norm': 14.186244010925293, 'learning_rate': 1.714663143989432e-06, 'rewards/chosen': 1.785546898841858, 'rewards/rejected': -10.022656440734863, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 11.818750381469727, 'logps/chosen': -424.6000061035156, 'logps/rejected': -330.79998779296875, 'logits/chosen': -8.587499618530273, 'logits/rejected': -8.118749618530273, 'epoch': 0.43}
 14%|█▍        | 650/4545 [50:53<4:11:22,  3.87s/it] 14%|█▍        | 651/4545 [50:57<4:13:28,  3.91s/it] 14%|█▍        | 652/4545 [51:00<4:08:59,  3.84s/it] 14%|█▍        | 653/4545 [51:04<4:12:10,  3.89s/it] 14%|█▍        | 654/4545 [51:08<4:12:50,  3.90s/it] 14%|█▍        | 655/4545 [51:12<4:03:44,  3.76s/it] 14%|█▍        | 656/4545 [51:15<4:02:14,  3.74s/it] 14%|█▍        | 657/4545 [51:20<4:13:00,  3.90s/it] 14%|█▍        | 658/4545 [51:22<3:47:30,  3.51s/it] 14%|█▍        | 659/4545 [51:26<3:55:49,  3.64s/it] 15%|█▍        | 660/4545 [51:30<4:01:30,  3.73s/it]                                                    {'loss': 0.2314, 'grad_norm': 9.619524955749512, 'learning_rate': 1.7410832232496697e-06, 'rewards/chosen': 0.805859386920929, 'rewards/rejected': -12.403124809265137, 'rewards/accuracies': 0.90625, 'rewards/margins': 13.1875, 'logps/chosen': -308.3999938964844, 'logps/rejected': -267.8999938964844, 'logits/chosen': -8.903124809265137, 'logits/rejected': -8.175000190734863, 'epoch': 0.44}
 15%|█▍        | 660/4545 [51:30<4:01:30,  3.73s/it] 15%|█▍        | 661/4545 [51:34<4:09:38,  3.86s/it] 15%|█▍        | 662/4545 [51:39<4:16:14,  3.96s/it] 15%|█▍        | 663/4545 [51:42<4:10:17,  3.87s/it] 15%|█▍        | 664/4545 [51:46<4:03:48,  3.77s/it] 15%|█▍        | 665/4545 [51:49<3:58:25,  3.69s/it] 15%|█▍        | 666/4545 [51:53<4:02:13,  3.75s/it] 15%|█▍        | 667/4545 [51:57<4:05:55,  3.80s/it] 15%|█▍        | 668/4545 [52:01<4:00:08,  3.72s/it] 15%|█▍        | 669/4545 [52:05<4:04:02,  3.78s/it] 15%|█▍        | 670/4545 [52:09<4:08:19,  3.84s/it]                                                    {'loss': 0.3143, 'grad_norm': 29.18608283996582, 'learning_rate': 1.7675033025099076e-06, 'rewards/chosen': -0.927734375, 'rewards/rejected': -12.546875, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 11.606249809265137, 'logps/chosen': -160.75, 'logps/rejected': -220.1999969482422, 'logits/chosen': -9.056249618530273, 'logits/rejected': -8.315625190734863, 'epoch': 0.44}
 15%|█▍        | 670/4545 [52:09<4:08:19,  3.84s/it] 15%|█▍        | 671/4545 [52:13<4:12:55,  3.92s/it] 15%|█▍        | 672/4545 [52:17<4:17:16,  3.99s/it] 15%|█▍        | 673/4545 [52:20<4:05:22,  3.80s/it] 15%|█▍        | 674/4545 [52:24<4:07:30,  3.84s/it] 15%|█▍        | 675/4545 [52:53<12:16:39, 11.42s/it] 15%|█▍        | 676/4545 [52:57<9:50:49,  9.16s/it]  15%|█▍        | 677/4545 [53:00<7:42:10,  7.17s/it] 15%|█▍        | 678/4545 [53:04<6:40:21,  6.21s/it] 15%|█▍        | 679/4545 [53:08<6:00:06,  5.59s/it] 15%|█▍        | 680/4545 [53:12<5:27:41,  5.09s/it]                                                    {'loss': 0.178, 'grad_norm': 12.015869140625, 'learning_rate': 1.7939233817701451e-06, 'rewards/chosen': 1.502343773841858, 'rewards/rejected': -12.513280868530273, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 14.018750190734863, 'logps/chosen': -358.45001220703125, 'logps/rejected': -289.0, 'logits/chosen': -8.606249809265137, 'logits/rejected': -7.921875, 'epoch': 0.45}
 15%|█▍        | 680/4545 [53:12<5:27:41,  5.09s/it] 15%|█▍        | 681/4545 [53:16<5:12:06,  4.85s/it] 15%|█▌        | 682/4545 [53:20<4:52:18,  4.54s/it] 15%|█▌        | 683/4545 [53:24<4:42:07,  4.38s/it] 15%|█▌        | 684/4545 [53:28<4:38:33,  4.33s/it] 15%|█▌        | 685/4545 [53:32<4:31:07,  4.21s/it] 15%|█▌        | 686/4545 [53:36<4:25:27,  4.13s/it] 15%|█▌        | 687/4545 [53:40<4:17:38,  4.01s/it] 15%|█▌        | 688/4545 [53:43<4:16:29,  3.99s/it] 15%|█▌        | 689/4545 [53:47<4:08:25,  3.87s/it] 15%|█▌        | 690/4545 [53:51<4:09:46,  3.89s/it]                                                    {'loss': 0.3069, 'grad_norm': 19.008798599243164, 'learning_rate': 1.820343461030383e-06, 'rewards/chosen': 1.0802733898162842, 'rewards/rejected': -11.595312118530273, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 12.671875, 'logps/chosen': -327.8500061035156, 'logps/rejected': -265.8500061035156, 'logits/chosen': -8.693750381469727, 'logits/rejected': -8.162500381469727, 'epoch': 0.46}
 15%|█▌        | 690/4545 [53:51<4:09:46,  3.89s/it] 15%|█▌        | 691/4545 [53:55<4:15:40,  3.98s/it] 15%|█▌        | 692/4545 [53:58<3:47:19,  3.54s/it] 15%|█▌        | 693/4545 [54:02<3:57:28,  3.70s/it] 15%|█▌        | 694/4545 [54:05<3:51:47,  3.61s/it] 15%|█▌        | 695/4545 [54:09<4:03:31,  3.80s/it] 15%|█▌        | 696/4545 [54:13<4:06:14,  3.84s/it] 15%|█▌        | 697/4545 [54:17<4:02:32,  3.78s/it] 15%|█▌        | 698/4545 [54:21<4:05:46,  3.83s/it] 15%|█▌        | 699/4545 [54:25<4:07:35,  3.86s/it] 15%|█▌        | 700/4545 [54:29<4:06:43,  3.85s/it]                                                    {'loss': 0.2531, 'grad_norm': 7.636590957641602, 'learning_rate': 1.8467635402906207e-06, 'rewards/chosen': 0.7409912347793579, 'rewards/rejected': -12.374218940734863, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 13.100000381469727, 'logps/chosen': -264.45001220703125, 'logps/rejected': -280.25, 'logits/chosen': -8.556249618530273, 'logits/rejected': -7.896874904632568, 'epoch': 0.46}
 15%|█▌        | 700/4545 [54:29<4:06:43,  3.85s/it] 15%|█▌        | 701/4545 [54:33<4:09:39,  3.90s/it] 15%|█▌        | 702/4545 [54:37<4:10:17,  3.91s/it] 15%|█▌        | 703/4545 [54:41<4:15:47,  3.99s/it] 15%|█▌        | 704/4545 [54:44<3:56:41,  3.70s/it] 16%|█▌        | 705/4545 [54:48<3:58:19,  3.72s/it] 16%|█▌        | 706/4545 [54:52<4:03:35,  3.81s/it] 16%|█▌        | 707/4545 [54:56<4:05:56,  3.84s/it] 16%|█▌        | 708/4545 [54:59<4:07:27,  3.87s/it] 16%|█▌        | 709/4545 [55:03<3:54:55,  3.67s/it] 16%|█▌        | 710/4545 [55:07<3:59:41,  3.75s/it]                                                    {'loss': 0.228, 'grad_norm': 13.458303451538086, 'learning_rate': 1.8731836195508587e-06, 'rewards/chosen': 0.07851562649011612, 'rewards/rejected': -18.5, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 18.59375, 'logps/chosen': -236.64999389648438, 'logps/rejected': -284.8999938964844, 'logits/chosen': -8.543749809265137, 'logits/rejected': -7.934374809265137, 'epoch': 0.47}
 16%|█▌        | 710/4545 [55:07<3:59:41,  3.75s/it] 16%|█▌        | 711/4545 [55:10<3:42:56,  3.49s/it] 16%|█▌        | 712/4545 [55:13<3:51:34,  3.62s/it] 16%|█▌        | 713/4545 [55:17<3:54:34,  3.67s/it] 16%|█▌        | 714/4545 [55:21<3:59:59,  3.76s/it] 16%|█▌        | 715/4545 [55:25<4:01:21,  3.78s/it] 16%|█▌        | 716/4545 [55:28<3:53:45,  3.66s/it] 16%|█▌        | 717/4545 [55:32<3:58:59,  3.75s/it] 16%|█▌        | 718/4545 [55:37<4:07:35,  3.88s/it] 16%|█▌        | 719/4545 [55:39<3:48:56,  3.59s/it] 16%|█▌        | 720/4545 [55:44<4:01:04,  3.78s/it]                                                    {'loss': 0.2556, 'grad_norm': 9.171443939208984, 'learning_rate': 1.8996036988110964e-06, 'rewards/chosen': 0.8199218511581421, 'rewards/rejected': -15.399999618530273, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 16.207813262939453, 'logps/chosen': -285.8500061035156, 'logps/rejected': -363.75, 'logits/chosen': -8.509374618530273, 'logits/rejected': -8.053125381469727, 'epoch': 0.48}
 16%|█▌        | 720/4545 [55:44<4:01:04,  3.78s/it] 16%|█▌        | 721/4545 [55:48<4:05:04,  3.85s/it] 16%|█▌        | 722/4545 [55:51<3:58:56,  3.75s/it] 16%|█▌        | 723/4545 [55:55<4:03:00,  3.81s/it] 16%|█▌        | 724/4545 [55:59<4:05:08,  3.85s/it] 16%|█▌        | 725/4545 [56:03<4:06:41,  3.87s/it] 16%|█▌        | 726/4545 [56:07<4:08:02,  3.90s/it] 16%|█▌        | 727/4545 [56:09<3:40:02,  3.46s/it] 16%|█▌        | 728/4545 [56:11<3:10:41,  3.00s/it] 16%|█▌        | 729/4545 [56:14<3:07:03,  2.94s/it] 16%|█▌        | 730/4545 [56:18<3:26:23,  3.25s/it]                                                    {'loss': 0.2851, 'grad_norm': 135.83883666992188, 'learning_rate': 1.926023778071334e-06, 'rewards/chosen': 0.9173828363418579, 'rewards/rejected': -11.324999809265137, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 12.225000381469727, 'logps/chosen': -296.75, 'logps/rejected': -261.0, 'logits/chosen': -8.706250190734863, 'logits/rejected': -8.100000381469727, 'epoch': 0.48}
 16%|█▌        | 730/4545 [56:18<3:26:23,  3.25s/it] 16%|█▌        | 731/4545 [56:21<3:14:37,  3.06s/it] 16%|█▌        | 732/4545 [56:25<3:31:13,  3.32s/it] 16%|█▌        | 733/4545 [56:29<3:42:58,  3.51s/it] 16%|█▌        | 734/4545 [56:33<3:51:19,  3.64s/it] 16%|█▌        | 735/4545 [56:37<4:02:47,  3.82s/it] 16%|█▌        | 736/4545 [56:41<4:06:05,  3.88s/it] 16%|█▌        | 737/4545 [56:45<4:07:07,  3.89s/it] 16%|█▌        | 738/4545 [56:49<4:11:29,  3.96s/it] 16%|█▋        | 739/4545 [56:52<3:59:19,  3.77s/it] 16%|█▋        | 740/4545 [56:56<4:08:24,  3.92s/it]                                                    {'loss': 0.2585, 'grad_norm': 7.773384094238281, 'learning_rate': 1.9524438573315718e-06, 'rewards/chosen': 0.893359363079071, 'rewards/rejected': -16.249217987060547, 'rewards/accuracies': 0.875, 'rewards/margins': 17.128124237060547, 'logps/chosen': -326.8500061035156, 'logps/rejected': -360.29998779296875, 'logits/chosen': -8.584375381469727, 'logits/rejected': -7.900000095367432, 'epoch': 0.49}
 16%|█▋        | 740/4545 [56:57<4:08:24,  3.92s/it] 16%|█▋        | 741/4545 [57:00<4:10:09,  3.95s/it] 16%|█▋        | 742/4545 [57:04<4:00:04,  3.79s/it] 16%|█▋        | 743/4545 [57:07<3:55:24,  3.72s/it] 16%|█▋        | 744/4545 [57:11<3:59:32,  3.78s/it] 16%|█▋        | 745/4545 [57:15<3:54:02,  3.70s/it] 16%|█▋        | 746/4545 [57:19<4:05:04,  3.87s/it] 16%|█▋        | 747/4545 [57:23<4:06:06,  3.89s/it] 16%|█▋        | 748/4545 [57:26<3:52:41,  3.68s/it] 16%|█▋        | 749/4545 [57:30<3:57:53,  3.76s/it] 17%|█▋        | 750/4545 [57:34<4:01:16,  3.81s/it]                                                    {'loss': 0.2387, 'grad_norm': 7.266371250152588, 'learning_rate': 1.9788639365918095e-06, 'rewards/chosen': -0.125, 'rewards/rejected': -13.965624809265137, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 13.837499618530273, 'logps/chosen': -217.89999389648438, 'logps/rejected': -249.0, 'logits/chosen': -8.899999618530273, 'logits/rejected': -8.284375190734863, 'epoch': 0.5}
 17%|█▋        | 750/4545 [57:34<4:01:16,  3.81s/it] 17%|█▋        | 751/4545 [57:38<4:04:47,  3.87s/it] 17%|█▋        | 752/4545 [57:42<4:04:28,  3.87s/it] 17%|█▋        | 753/4545 [57:46<4:11:25,  3.98s/it] 17%|█▋        | 754/4545 [57:50<4:00:40,  3.81s/it] 17%|█▋        | 755/4545 [57:54<4:03:08,  3.85s/it] 17%|█▋        | 756/4545 [57:58<4:11:50,  3.99s/it] 17%|█▋        | 757/4545 [58:02<4:10:54,  3.97s/it] 17%|█▋        | 758/4545 [58:06<4:11:40,  3.99s/it] 17%|█▋        | 759/4545 [58:10<4:07:41,  3.93s/it] 17%|█▋        | 760/4545 [58:13<4:02:31,  3.84s/it]                                                    {'loss': 0.2251, 'grad_norm': 22.35420799255371, 'learning_rate': 2.0052840158520476e-06, 'rewards/chosen': 1.5812499523162842, 'rewards/rejected': -16.334375381469727, 'rewards/accuracies': 0.90625, 'rewards/margins': 17.921875, 'logps/chosen': -422.1000061035156, 'logps/rejected': -388.29998779296875, 'logits/chosen': -8.740625381469727, 'logits/rejected': -8.068750381469727, 'epoch': 0.5}
 17%|█▋        | 760/4545 [58:14<4:02:31,  3.84s/it] 17%|█▋        | 761/4545 [58:17<4:07:20,  3.92s/it] 17%|█▋        | 762/4545 [58:21<4:07:33,  3.93s/it] 17%|█▋        | 763/4545 [58:25<3:56:56,  3.76s/it] 17%|█▋        | 764/4545 [58:29<3:58:17,  3.78s/it] 17%|█▋        | 765/4545 [58:31<3:39:52,  3.49s/it] 17%|█▋        | 766/4545 [58:35<3:50:10,  3.65s/it] 17%|█▋        | 767/4545 [58:39<3:55:29,  3.74s/it] 17%|█▋        | 768/4545 [58:44<4:03:08,  3.86s/it] 17%|█▋        | 769/4545 [58:47<3:49:07,  3.64s/it] 17%|█▋        | 770/4545 [58:50<3:38:54,  3.48s/it]                                                    {'loss': 0.196, 'grad_norm': 2.041689872741699, 'learning_rate': 2.0317040951122853e-06, 'rewards/chosen': 0.0458984375, 'rewards/rejected': -14.909375190734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 14.934374809265137, 'logps/chosen': -250.9499969482422, 'logps/rejected': -301.20001220703125, 'logits/chosen': -9.100000381469727, 'logits/rejected': -8.418749809265137, 'epoch': 0.51}
 17%|█▋        | 770/4545 [58:50<3:38:54,  3.48s/it] 17%|█▋        | 771/4545 [58:52<3:20:21,  3.19s/it] 17%|█▋        | 772/4545 [58:56<3:39:52,  3.50s/it] 17%|█▋        | 773/4545 [58:59<3:19:43,  3.18s/it] 17%|█▋        | 774/4545 [59:03<3:28:17,  3.31s/it] 17%|█▋        | 775/4545 [59:07<3:45:24,  3.59s/it] 17%|█▋        | 776/4545 [59:11<3:51:33,  3.69s/it] 17%|█▋        | 777/4545 [59:14<3:44:03,  3.57s/it] 17%|█▋        | 778/4545 [59:18<3:44:19,  3.57s/it] 17%|█▋        | 779/4545 [59:22<3:56:56,  3.77s/it] 17%|█▋        | 780/4545 [59:26<4:00:22,  3.83s/it]                                                    {'loss': 0.3097, 'grad_norm': 29.502470016479492, 'learning_rate': 2.058124174372523e-06, 'rewards/chosen': 0.3193359375, 'rewards/rejected': -12.737500190734863, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 13.0625, 'logps/chosen': -264.3500061035156, 'logps/rejected': -279.5, 'logits/chosen': -9.225000381469727, 'logits/rejected': -8.571874618530273, 'epoch': 0.51}
 17%|█▋        | 780/4545 [59:26<4:00:22,  3.83s/it] 17%|█▋        | 781/4545 [59:29<3:43:12,  3.56s/it] 17%|█▋        | 782/4545 [59:33<3:52:43,  3.71s/it] 17%|█▋        | 783/4545 [59:37<4:02:47,  3.87s/it] 17%|█▋        | 784/4545 [59:41<3:55:52,  3.76s/it] 17%|█▋        | 785/4545 [59:44<3:59:24,  3.82s/it] 17%|█▋        | 786/4545 [59:48<4:00:47,  3.84s/it] 17%|█▋        | 787/4545 [59:52<4:02:29,  3.87s/it] 17%|█▋        | 788/4545 [59:56<4:04:10,  3.90s/it] 17%|█▋        | 789/4545 [59:59<3:51:48,  3.70s/it] 17%|█▋        | 790/4545 [1:00:02<3:29:08,  3.34s/it]                                                      {'loss': 0.31, 'grad_norm': 8.600221633911133, 'learning_rate': 2.0845442536327607e-06, 'rewards/chosen': -0.11118163913488388, 'rewards/rejected': -15.103124618530273, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 14.996874809265137, 'logps/chosen': -245.0, 'logps/rejected': -254.3000030517578, 'logits/chosen': -9.231249809265137, 'logits/rejected': -8.712499618530273, 'epoch': 0.52}
 17%|█▋        | 790/4545 [1:00:02<3:29:08,  3.34s/it] 17%|█▋        | 791/4545 [1:00:05<3:26:58,  3.31s/it] 17%|█▋        | 792/4545 [1:00:09<3:42:11,  3.55s/it] 17%|█▋        | 793/4545 [1:00:14<3:54:08,  3.74s/it] 17%|█▋        | 794/4545 [1:00:18<4:03:45,  3.90s/it] 17%|█▋        | 795/4545 [1:00:22<4:08:54,  3.98s/it] 18%|█▊        | 796/4545 [1:00:26<4:06:40,  3.95s/it] 18%|█▊        | 797/4545 [1:00:30<4:06:34,  3.95s/it] 18%|█▊        | 798/4545 [1:00:34<4:06:08,  3.94s/it] 18%|█▊        | 799/4545 [1:00:38<4:04:53,  3.92s/it] 18%|█▊        | 800/4545 [1:00:42<4:05:02,  3.93s/it]                                                      {'loss': 0.2276, 'grad_norm': 5.570343017578125, 'learning_rate': 2.1109643328929984e-06, 'rewards/chosen': 0.7646484375, 'rewards/rejected': -12.879687309265137, 'rewards/accuracies': 0.90625, 'rewards/margins': 13.626562118530273, 'logps/chosen': -315.25, 'logps/rejected': -277.75, 'logits/chosen': -8.949999809265137, 'logits/rejected': -8.271875381469727, 'epoch': 0.53}
 18%|█▊        | 800/4545 [1:00:42<4:05:02,  3.93s/it] 18%|█▊        | 801/4545 [1:00:45<4:05:14,  3.93s/it] 18%|█▊        | 802/4545 [1:00:49<3:59:56,  3.85s/it] 18%|█▊        | 803/4545 [1:00:53<3:55:15,  3.77s/it] 18%|█▊        | 804/4545 [1:00:57<4:03:27,  3.90s/it] 18%|█▊        | 805/4545 [1:01:01<4:03:47,  3.91s/it] 18%|█▊        | 806/4545 [1:01:04<3:55:05,  3.77s/it] 18%|█▊        | 807/4545 [1:01:08<3:57:45,  3.82s/it] 18%|█▊        | 808/4545 [1:01:12<3:59:36,  3.85s/it] 18%|█▊        | 809/4545 [1:01:16<3:51:14,  3.71s/it] 18%|█▊        | 810/4545 [1:01:19<3:55:11,  3.78s/it]                                                      {'loss': 0.2233, 'grad_norm': 9.884490966796875, 'learning_rate': 2.137384412153236e-06, 'rewards/chosen': 0.28398436307907104, 'rewards/rejected': -13.381250381469727, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 13.671875, 'logps/chosen': -225.14999389648438, 'logps/rejected': -286.79998779296875, 'logits/chosen': -8.774999618530273, 'logits/rejected': -8.106249809265137, 'epoch': 0.53}
 18%|█▊        | 810/4545 [1:01:20<3:55:11,  3.78s/it] 18%|█▊        | 811/4545 [1:01:23<3:59:01,  3.84s/it] 18%|█▊        | 812/4545 [1:01:27<4:00:29,  3.87s/it] 18%|█▊        | 813/4545 [1:01:31<4:01:40,  3.89s/it] 18%|█▊        | 814/4545 [1:01:35<3:52:08,  3.73s/it] 18%|█▊        | 815/4545 [1:01:39<3:56:20,  3.80s/it] 18%|█▊        | 816/4545 [1:01:43<3:58:50,  3.84s/it] 18%|█▊        | 817/4545 [1:01:45<3:32:37,  3.42s/it] 18%|█▊        | 818/4545 [1:01:49<3:42:07,  3.58s/it] 18%|█▊        | 819/4545 [1:01:53<3:52:46,  3.75s/it] 18%|█▊        | 820/4545 [1:01:57<3:57:34,  3.83s/it]                                                      {'loss': 0.2458, 'grad_norm': 22.171268463134766, 'learning_rate': 2.1638044914134743e-06, 'rewards/chosen': 1.4923827648162842, 'rewards/rejected': -16.890625, 'rewards/accuracies': 0.90625, 'rewards/margins': 18.375, 'logps/chosen': -409.54998779296875, 'logps/rejected': -366.70001220703125, 'logits/chosen': -8.446874618530273, 'logits/rejected': -7.837500095367432, 'epoch': 0.54}
 18%|█▊        | 820/4545 [1:01:57<3:57:34,  3.83s/it] 18%|█▊        | 821/4545 [1:02:01<4:07:25,  3.99s/it] 18%|█▊        | 822/4545 [1:02:06<4:10:29,  4.04s/it] 18%|█▊        | 823/4545 [1:02:10<4:11:02,  4.05s/it] 18%|█▊        | 824/4545 [1:02:13<3:54:02,  3.77s/it] 18%|█▊        | 825/4545 [1:02:17<3:57:35,  3.83s/it] 18%|█▊        | 826/4545 [1:02:20<3:44:10,  3.62s/it] 18%|█▊        | 827/4545 [1:02:24<3:53:00,  3.76s/it] 18%|█▊        | 828/4545 [1:02:28<3:56:22,  3.82s/it] 18%|█▊        | 829/4545 [1:02:32<4:04:35,  3.95s/it] 18%|█▊        | 830/4545 [1:02:36<3:55:22,  3.80s/it]                                                      {'loss': 0.215, 'grad_norm': 8.52798080444336, 'learning_rate': 2.190224570673712e-06, 'rewards/chosen': 0.10175780951976776, 'rewards/rejected': -20.128124237060547, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 20.225000381469727, 'logps/chosen': -307.0, 'logps/rejected': -361.04998779296875, 'logits/chosen': -8.756250381469727, 'logits/rejected': -8.143750190734863, 'epoch': 0.55}
 18%|█▊        | 830/4545 [1:02:36<3:55:22,  3.80s/it] 18%|█▊        | 831/4545 [1:02:40<4:04:26,  3.95s/it] 18%|█▊        | 832/4545 [1:02:43<3:55:56,  3.81s/it] 18%|█▊        | 833/4545 [1:02:47<3:57:59,  3.85s/it] 18%|█▊        | 834/4545 [1:02:52<4:04:45,  3.96s/it] 18%|█▊        | 835/4545 [1:02:55<4:00:06,  3.88s/it] 18%|█▊        | 836/4545 [1:02:58<3:33:30,  3.45s/it] 18%|█▊        | 837/4545 [1:03:01<3:28:09,  3.37s/it] 18%|█▊        | 838/4545 [1:03:05<3:38:45,  3.54s/it] 18%|█▊        | 839/4545 [1:03:08<3:32:43,  3.44s/it] 18%|█▊        | 840/4545 [1:03:12<3:35:09,  3.48s/it]                                                      {'loss': 0.2439, 'grad_norm': 15.089498519897461, 'learning_rate': 2.2166446499339497e-06, 'rewards/chosen': -0.3960937559604645, 'rewards/rejected': -18.165624618530273, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 17.774999618530273, 'logps/chosen': -263.8999938964844, 'logps/rejected': -318.1000061035156, 'logits/chosen': -9.337499618530273, 'logits/rejected': -8.740625381469727, 'epoch': 0.55}
 18%|█▊        | 840/4545 [1:03:12<3:35:09,  3.48s/it] 19%|█▊        | 841/4545 [1:03:16<3:44:41,  3.64s/it] 19%|█▊        | 842/4545 [1:03:18<3:16:51,  3.19s/it] 19%|█▊        | 843/4545 [1:03:22<3:33:13,  3.46s/it] 19%|█▊        | 844/4545 [1:03:26<3:36:11,  3.50s/it] 19%|█▊        | 845/4545 [1:03:29<3:43:54,  3.63s/it] 19%|█▊        | 846/4545 [1:03:34<3:52:08,  3.77s/it] 19%|█▊        | 847/4545 [1:03:37<3:43:12,  3.62s/it] 19%|█▊        | 848/4545 [1:03:41<3:53:03,  3.78s/it] 19%|█▊        | 849/4545 [1:03:45<3:58:31,  3.87s/it] 19%|█▊        | 850/4545 [1:03:49<3:52:35,  3.78s/it]                                                      {'loss': 0.397, 'grad_norm': 26.249685287475586, 'learning_rate': 2.2430647291941874e-06, 'rewards/chosen': -0.840136706829071, 'rewards/rejected': -18.049999237060547, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 17.206249237060547, 'logps/chosen': -266.8500061035156, 'logps/rejected': -315.6000061035156, 'logits/chosen': -9.149999618530273, 'logits/rejected': -8.471875190734863, 'epoch': 0.56}
 19%|█▊        | 850/4545 [1:03:49<3:52:35,  3.78s/it] 19%|█▊        | 851/4545 [1:03:52<3:45:59,  3.67s/it] 19%|█▊        | 852/4545 [1:03:56<3:50:41,  3.75s/it] 19%|█▉        | 853/4545 [1:04:00<3:48:03,  3.71s/it] 19%|█▉        | 854/4545 [1:04:03<3:38:05,  3.55s/it] 19%|█▉        | 855/4545 [1:04:33<11:53:27, 11.60s/it] 19%|█▉        | 856/4545 [1:04:36<9:20:50,  9.12s/it]  19%|█▉        | 857/4545 [1:04:40<7:45:46,  7.58s/it] 19%|█▉        | 858/4545 [1:04:44<6:39:57,  6.51s/it] 19%|█▉        | 859/4545 [1:04:48<5:41:27,  5.56s/it] 19%|█▉        | 860/4545 [1:04:51<5:04:36,  4.96s/it]                                                      {'loss': 0.301, 'grad_norm': 23.473825454711914, 'learning_rate': 2.2694848084544255e-06, 'rewards/chosen': -0.03203124925494194, 'rewards/rejected': -11.451562881469727, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 11.418749809265137, 'logps/chosen': -237.0, 'logps/rejected': -224.0500030517578, 'logits/chosen': -9.149999618530273, 'logits/rejected': -8.559374809265137, 'epoch': 0.57}
 19%|█▉        | 860/4545 [1:04:52<5:04:36,  4.96s/it] 19%|█▉        | 861/4545 [1:04:55<4:47:36,  4.68s/it] 19%|█▉        | 862/4545 [1:04:59<4:31:46,  4.43s/it] 19%|█▉        | 863/4545 [1:05:03<4:26:57,  4.35s/it] 19%|█▉        | 864/4545 [1:05:07<4:19:09,  4.22s/it] 19%|█▉        | 865/4545 [1:05:11<4:03:43,  3.97s/it] 19%|█▉        | 866/4545 [1:05:15<4:00:36,  3.92s/it] 19%|█▉        | 867/4545 [1:05:18<3:59:43,  3.91s/it] 19%|█▉        | 868/4545 [1:05:22<4:01:07,  3.93s/it] 19%|█▉        | 869/4545 [1:05:26<3:47:06,  3.71s/it] 19%|█▉        | 870/4545 [1:05:30<3:51:09,  3.77s/it]                                                      {'loss': 0.2213, 'grad_norm': 14.503050804138184, 'learning_rate': 2.2959048877146632e-06, 'rewards/chosen': 0.14492186903953552, 'rewards/rejected': -14.290624618530273, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 14.440625190734863, 'logps/chosen': -253.85000610351562, 'logps/rejected': -260.29998779296875, 'logits/chosen': -9.137499809265137, 'logits/rejected': -8.612500190734863, 'epoch': 0.57}
 19%|█▉        | 870/4545 [1:05:30<3:51:09,  3.77s/it] 19%|█▉        | 871/4545 [1:05:33<3:47:26,  3.71s/it] 19%|█▉        | 872/4545 [1:05:36<3:38:27,  3.57s/it] 19%|█▉        | 873/4545 [1:05:40<3:33:52,  3.49s/it] 19%|█▉        | 874/4545 [1:05:44<3:43:55,  3.66s/it] 19%|█▉        | 875/4545 [1:05:46<3:25:44,  3.36s/it] 19%|█▉        | 876/4545 [1:05:50<3:36:15,  3.54s/it] 19%|█▉        | 877/4545 [1:05:54<3:47:02,  3.71s/it] 19%|█▉        | 878/4545 [1:05:58<3:46:03,  3.70s/it] 19%|█▉        | 879/4545 [1:06:02<3:50:31,  3.77s/it] 19%|█▉        | 880/4545 [1:06:06<3:49:52,  3.76s/it]                                                      {'loss': 0.2797, 'grad_norm': 21.746889114379883, 'learning_rate': 2.322324966974901e-06, 'rewards/chosen': 0.4579101502895355, 'rewards/rejected': -18.090625762939453, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 18.549999237060547, 'logps/chosen': -301.8500061035156, 'logps/rejected': -329.0, 'logits/chosen': -8.934374809265137, 'logits/rejected': -8.315625190734863, 'epoch': 0.58}
 19%|█▉        | 880/4545 [1:06:06<3:49:52,  3.76s/it] 19%|█▉        | 881/4545 [1:06:10<4:00:22,  3.94s/it] 19%|█▉        | 882/4545 [1:06:14<4:00:28,  3.94s/it] 19%|█▉        | 883/4545 [1:06:18<3:59:14,  3.92s/it] 19%|█▉        | 884/4545 [1:06:21<3:51:22,  3.79s/it] 19%|█▉        | 885/4545 [1:06:25<3:39:35,  3.60s/it] 19%|█▉        | 886/4545 [1:06:28<3:44:12,  3.68s/it] 20%|█▉        | 887/4545 [1:06:32<3:45:42,  3.70s/it] 20%|█▉        | 888/4545 [1:06:35<3:33:12,  3.50s/it] 20%|█▉        | 889/4545 [1:06:39<3:41:45,  3.64s/it] 20%|█▉        | 890/4545 [1:06:43<3:52:54,  3.82s/it]                                                      {'loss': 0.2034, 'grad_norm': 25.824474334716797, 'learning_rate': 2.3487450462351387e-06, 'rewards/chosen': 0.03203124925494194, 'rewards/rejected': -15.449999809265137, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 15.46875, 'logps/chosen': -249.97500610351562, 'logps/rejected': -273.20001220703125, 'logits/chosen': -9.168749809265137, 'logits/rejected': -8.434374809265137, 'epoch': 0.59}
 20%|█▉        | 890/4545 [1:06:44<3:52:54,  3.82s/it] 20%|█▉        | 891/4545 [1:06:47<3:56:28,  3.88s/it] 20%|█▉        | 892/4545 [1:06:51<3:57:44,  3.90s/it] 20%|█▉        | 893/4545 [1:06:55<3:51:17,  3.80s/it] 20%|█▉        | 894/4545 [1:06:58<3:44:31,  3.69s/it] 20%|█▉        | 895/4545 [1:07:02<3:49:15,  3.77s/it] 20%|█▉        | 896/4545 [1:07:06<3:52:39,  3.83s/it] 20%|█▉        | 897/4545 [1:07:10<3:54:43,  3.86s/it] 20%|█▉        | 898/4545 [1:07:14<3:59:10,  3.93s/it] 20%|█▉        | 899/4545 [1:07:18<3:58:06,  3.92s/it] 20%|█▉        | 900/4545 [1:07:22<3:58:30,  3.93s/it]                                                      {'loss': 0.2333, 'grad_norm': 24.3477725982666, 'learning_rate': 2.3751651254953764e-06, 'rewards/chosen': 1.0177733898162842, 'rewards/rejected': -19.245311737060547, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 20.268749237060547, 'logps/chosen': -468.6000061035156, 'logps/rejected': -443.79998779296875, 'logits/chosen': -8.643750190734863, 'logits/rejected': -8.090624809265137, 'epoch': 0.59}
 20%|█▉        | 900/4545 [1:07:22<3:58:30,  3.93s/it] 20%|█▉        | 901/4545 [1:07:26<3:49:55,  3.79s/it] 20%|█▉        | 902/4545 [1:07:30<3:52:34,  3.83s/it] 20%|█▉        | 903/4545 [1:07:33<3:52:02,  3.82s/it] 20%|█▉        | 904/4545 [1:07:37<3:40:21,  3.63s/it] 20%|█▉        | 905/4545 [1:07:41<3:45:40,  3.72s/it] 20%|█▉        | 906/4545 [1:07:44<3:49:12,  3.78s/it] 20%|█▉        | 907/4545 [1:07:49<3:57:23,  3.92s/it] 20%|█▉        | 908/4545 [1:07:53<3:57:35,  3.92s/it] 20%|██        | 909/4545 [1:07:57<3:58:11,  3.93s/it] 20%|██        | 910/4545 [1:08:00<3:48:29,  3.77s/it]                                                      {'loss': 0.3526, 'grad_norm': 21.731351852416992, 'learning_rate': 2.401585204755614e-06, 'rewards/chosen': -0.01914062537252903, 'rewards/rejected': -10.029687881469727, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 10.017187118530273, 'logps/chosen': -253.10000610351562, 'logps/rejected': -257.1000061035156, 'logits/chosen': -8.665624618530273, 'logits/rejected': -8.387499809265137, 'epoch': 0.6}
 20%|██        | 910/4545 [1:08:00<3:48:29,  3.77s/it] 20%|██        | 911/4545 [1:08:04<3:54:57,  3.88s/it] 20%|██        | 912/4545 [1:08:08<3:57:59,  3.93s/it] 20%|██        | 913/4545 [1:08:12<3:59:00,  3.95s/it] 20%|██        | 914/4545 [1:08:16<3:58:56,  3.95s/it] 20%|██        | 915/4545 [1:08:20<3:49:53,  3.80s/it] 20%|██        | 916/4545 [1:08:23<3:51:53,  3.83s/it] 20%|██        | 917/4545 [1:08:27<3:53:32,  3.86s/it] 20%|██        | 918/4545 [1:08:30<3:23:13,  3.36s/it] 20%|██        | 919/4545 [1:08:33<3:28:17,  3.45s/it] 20%|██        | 920/4545 [1:08:37<3:37:15,  3.60s/it]                                                      {'loss': 0.2939, 'grad_norm': 26.367835998535156, 'learning_rate': 2.4280052840158518e-06, 'rewards/chosen': 1.805932641029358, 'rewards/rejected': -12.551562309265137, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 14.350000381469727, 'logps/chosen': -400.3999938964844, 'logps/rejected': -310.5, 'logits/chosen': -8.590624809265137, 'logits/rejected': -8.081250190734863, 'epoch': 0.61}
 20%|██        | 920/4545 [1:08:37<3:37:15,  3.60s/it] 20%|██        | 921/4545 [1:08:40<3:32:22,  3.52s/it] 20%|██        | 922/4545 [1:08:43<3:21:15,  3.33s/it] 20%|██        | 923/4545 [1:08:47<3:32:07,  3.51s/it] 20%|██        | 924/4545 [1:08:51<3:41:17,  3.67s/it] 20%|██        | 925/4545 [1:08:55<3:50:03,  3.81s/it] 20%|██        | 926/4545 [1:09:00<3:57:58,  3.95s/it] 20%|██        | 927/4545 [1:09:03<3:44:25,  3.72s/it] 20%|██        | 928/4545 [1:09:07<3:48:06,  3.78s/it] 20%|██        | 929/4545 [1:09:11<3:45:21,  3.74s/it] 20%|██        | 930/4545 [1:09:15<3:51:46,  3.85s/it]                                                      {'loss': 0.2694, 'grad_norm': 47.53031539916992, 'learning_rate': 2.4544253632760895e-06, 'rewards/chosen': 0.37568360567092896, 'rewards/rejected': -12.71875, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 13.09375, 'logps/chosen': -259.17498779296875, 'logps/rejected': -260.29998779296875, 'logits/chosen': -8.868749618530273, 'logits/rejected': -8.337499618530273, 'epoch': 0.61}
 20%|██        | 930/4545 [1:09:15<3:51:46,  3.85s/it] 20%|██        | 931/4545 [1:09:19<3:59:20,  3.97s/it] 21%|██        | 932/4545 [1:09:22<3:50:22,  3.83s/it] 21%|██        | 933/4545 [1:09:26<3:38:08,  3.62s/it] 21%|██        | 934/4545 [1:09:29<3:34:12,  3.56s/it] 21%|██        | 935/4545 [1:09:33<3:44:53,  3.74s/it] 21%|██        | 936/4545 [1:09:35<3:20:55,  3.34s/it] 21%|██        | 937/4545 [1:09:39<3:31:43,  3.52s/it] 21%|██        | 938/4545 [1:10:09<11:29:57, 11.48s/it] 21%|██        | 939/4545 [1:10:13<9:12:11,  9.19s/it]  21%|██        | 940/4545 [1:10:18<7:42:27,  7.70s/it]                                                      {'loss': 0.2628, 'grad_norm': 19.24738311767578, 'learning_rate': 2.4808454425363276e-06, 'rewards/chosen': 0.41572266817092896, 'rewards/rejected': -10.856249809265137, 'rewards/accuracies': 0.875, 'rewards/margins': 11.256250381469727, 'logps/chosen': -203.6999969482422, 'logps/rejected': -220.5500030517578, 'logits/chosen': -8.96875, 'logits/rejected': -8.365625381469727, 'epoch': 0.62}
 21%|██        | 940/4545 [1:10:18<7:42:27,  7.70s/it] 21%|██        | 941/4545 [1:10:22<6:41:40,  6.69s/it] 21%|██        | 942/4545 [1:10:26<5:51:42,  5.86s/it] 21%|██        | 943/4545 [1:10:30<5:13:34,  5.22s/it] 21%|██        | 944/4545 [1:10:32<4:25:08,  4.42s/it] 21%|██        | 945/4545 [1:10:36<4:08:24,  4.14s/it] 21%|██        | 946/4545 [1:10:39<3:59:50,  4.00s/it] 21%|██        | 947/4545 [1:10:43<3:58:54,  3.98s/it] 21%|██        | 948/4545 [1:10:47<3:47:28,  3.79s/it] 21%|██        | 949/4545 [1:10:50<3:50:09,  3.84s/it] 21%|██        | 950/4545 [1:10:54<3:51:48,  3.87s/it]                                                      {'loss': 0.2384, 'grad_norm': 14.368269920349121, 'learning_rate': 2.5072655217965653e-06, 'rewards/chosen': 0.205963134765625, 'rewards/rejected': -16.035938262939453, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 16.254688262939453, 'logps/chosen': -220.9499969482422, 'logps/rejected': -290.8500061035156, 'logits/chosen': -8.931249618530273, 'logits/rejected': -8.21875, 'epoch': 0.63}
 21%|██        | 950/4545 [1:10:55<3:51:48,  3.87s/it] 21%|██        | 951/4545 [1:10:57<3:28:02,  3.47s/it] 21%|██        | 952/4545 [1:11:00<3:24:31,  3.42s/it] 21%|██        | 953/4545 [1:11:04<3:33:21,  3.56s/it] 21%|██        | 954/4545 [1:11:08<3:42:12,  3.71s/it] 21%|██        | 955/4545 [1:11:12<3:46:33,  3.79s/it] 21%|██        | 956/4545 [1:11:16<3:49:16,  3.83s/it] 21%|██        | 957/4545 [1:11:20<3:51:03,  3.86s/it] 21%|██        | 958/4545 [1:11:24<3:52:27,  3.89s/it] 21%|██        | 959/4545 [1:11:28<3:53:00,  3.90s/it] 21%|██        | 960/4545 [1:11:32<3:48:59,  3.83s/it]                                                      {'loss': 0.1221, 'grad_norm': 13.355851173400879, 'learning_rate': 2.533685601056803e-06, 'rewards/chosen': 2.09765625, 'rewards/rejected': -9.8515625, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 11.940625190734863, 'logps/chosen': -441.375, 'logps/rejected': -315.6000061035156, 'logits/chosen': -8.821874618530273, 'logits/rejected': -8.390625, 'epoch': 0.63}
 21%|██        | 960/4545 [1:11:32<3:48:59,  3.83s/it] 21%|██        | 961/4545 [1:11:35<3:49:18,  3.84s/it] 21%|██        | 962/4545 [1:11:40<3:56:27,  3.96s/it] 21%|██        | 963/4545 [1:11:43<3:50:40,  3.86s/it] 21%|██        | 964/4545 [1:11:47<3:51:51,  3.88s/it] 21%|██        | 965/4545 [1:11:51<3:53:15,  3.91s/it] 21%|██▏       | 966/4545 [1:11:55<3:53:01,  3.91s/it] 21%|██▏       | 967/4545 [1:11:59<3:53:20,  3.91s/it] 21%|██▏       | 968/4545 [1:12:03<3:53:54,  3.92s/it] 21%|██▏       | 969/4545 [1:12:07<3:53:45,  3.92s/it] 21%|██▏       | 970/4545 [1:12:10<3:46:48,  3.81s/it]                                                      {'loss': 0.2489, 'grad_norm': 29.577348709106445, 'learning_rate': 2.5601056803170407e-06, 'rewards/chosen': 0.940625011920929, 'rewards/rejected': -15.412500381469727, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 16.356250762939453, 'logps/chosen': -372.79998779296875, 'logps/rejected': -322.5, 'logits/chosen': -9.100000381469727, 'logits/rejected': -8.612500190734863, 'epoch': 0.64}
 21%|██▏       | 970/4545 [1:12:11<3:46:48,  3.81s/it] 21%|██▏       | 971/4545 [1:12:14<3:33:18,  3.58s/it] 21%|██▏       | 972/4545 [1:12:18<3:44:14,  3.77s/it] 21%|██▏       | 973/4545 [1:12:22<3:48:44,  3.84s/it] 21%|██▏       | 974/4545 [1:12:26<3:50:21,  3.87s/it] 21%|██▏       | 975/4545 [1:12:30<3:51:31,  3.89s/it] 21%|██▏       | 976/4545 [1:12:34<4:00:53,  4.05s/it] 21%|██▏       | 977/4545 [1:12:38<3:57:08,  3.99s/it] 22%|██▏       | 978/4545 [1:12:41<3:33:11,  3.59s/it] 22%|██▏       | 979/4545 [1:12:45<3:40:30,  3.71s/it] 22%|██▏       | 980/4545 [1:12:49<3:50:02,  3.87s/it]                                                      {'loss': 0.1811, 'grad_norm': 8.090056419372559, 'learning_rate': 2.586525759577279e-06, 'rewards/chosen': 1.424072265625, 'rewards/rejected': -14.659375190734863, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 16.09375, 'logps/chosen': -367.6000061035156, 'logps/rejected': -342.8999938964844, 'logits/chosen': -9.356249809265137, 'logits/rejected': -8.706250190734863, 'epoch': 0.65}
 22%|██▏       | 980/4545 [1:12:49<3:50:02,  3.87s/it] 22%|██▏       | 981/4545 [1:12:53<3:51:15,  3.89s/it] 22%|██▏       | 982/4545 [1:12:57<3:57:07,  3.99s/it] 22%|██▏       | 983/4545 [1:12:59<3:25:52,  3.47s/it] 22%|██▏       | 984/4545 [1:13:03<3:33:47,  3.60s/it] 22%|██▏       | 985/4545 [1:13:06<3:22:33,  3.41s/it] 22%|██▏       | 986/4545 [1:13:09<3:11:02,  3.22s/it] 22%|██▏       | 987/4545 [1:13:12<3:14:19,  3.28s/it] 22%|██▏       | 988/4545 [1:13:16<3:25:55,  3.47s/it] 22%|██▏       | 989/4545 [1:13:19<3:15:53,  3.31s/it] 22%|██▏       | 990/4545 [1:13:23<3:27:39,  3.50s/it]                                                      {'loss': 0.2367, 'grad_norm': 24.795440673828125, 'learning_rate': 2.6129458388375166e-06, 'rewards/chosen': -0.5289062261581421, 'rewards/rejected': -13.053125381469727, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 12.512499809265137, 'logps/chosen': -151.47500610351562, 'logps/rejected': -210.89999389648438, 'logits/chosen': -9.46875, 'logits/rejected': -8.806249618530273, 'epoch': 0.65}
 22%|██▏       | 990/4545 [1:13:23<3:27:39,  3.50s/it] 22%|██▏       | 991/4545 [1:13:28<3:46:42,  3.83s/it] 22%|██▏       | 992/4545 [1:13:30<3:28:34,  3.52s/it] 22%|██▏       | 993/4545 [1:13:34<3:31:22,  3.57s/it] 22%|██▏       | 994/4545 [1:13:38<3:37:43,  3.68s/it] 22%|██▏       | 995/4545 [1:13:41<3:30:58,  3.57s/it] 22%|██▏       | 996/4545 [1:13:44<3:07:32,  3.17s/it] 22%|██▏       | 997/4545 [1:13:48<3:25:45,  3.48s/it] 22%|██▏       | 998/4545 [1:13:52<3:36:41,  3.67s/it] 22%|██▏       | 999/4545 [1:13:56<3:44:38,  3.80s/it] 22%|██▏       | 1000/4545 [1:14:00<3:43:26,  3.78s/it]                                                       {'loss': 0.2476, 'grad_norm': 41.99972915649414, 'learning_rate': 2.6393659180977543e-06, 'rewards/chosen': -0.6875, 'rewards/rejected': -15.6015625, 'rewards/accuracies': 0.90625, 'rewards/margins': 14.926562309265137, 'logps/chosen': -167.5500030517578, 'logps/rejected': -246.5500030517578, 'logits/chosen': -9.34375, 'logits/rejected': -8.725000381469727, 'epoch': 0.66}
 22%|██▏       | 1000/4545 [1:14:00<3:43:26,  3.78s/it] 22%|██▏       | 1001/4545 [1:14:04<3:45:02,  3.81s/it] 22%|██▏       | 1002/4545 [1:14:08<3:50:29,  3.90s/it] 22%|██▏       | 1003/4545 [1:14:12<3:50:15,  3.90s/it] 22%|██▏       | 1004/4545 [1:14:15<3:45:31,  3.82s/it] 22%|██▏       | 1005/4545 [1:14:18<3:27:08,  3.51s/it] 22%|██▏       | 1006/4545 [1:14:22<3:41:23,  3.75s/it] 22%|██▏       | 1007/4545 [1:14:26<3:35:26,  3.65s/it] 22%|██▏       | 1008/4545 [1:14:30<3:38:03,  3.70s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:41,  1.38it/s][A
  5%|▌         | 3/60 [00:03<01:01,  1.08s/it][A
  7%|▋         | 4/60 [00:04<01:12,  1.30s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.40s/it][A
 10%|█         | 6/60 [00:07<01:20,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:22,  1.57s/it][A
 13%|█▎        | 8/60 [00:11<01:23,  1.61s/it][A
 15%|█▌        | 9/60 [00:13<01:22,  1.62s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.61s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.65s/it][A
 20%|██        | 12/60 [00:18<01:20,  1.67s/it][A
 22%|██▏       | 13/60 [00:19<01:17,  1.65s/it][A
 23%|██▎       | 14/60 [00:21<01:18,  1.71s/it][A
 25%|██▌       | 15/60 [00:22<01:10,  1.58s/it][A
 27%|██▋       | 16/60 [00:23<01:02,  1.42s/it][A
 28%|██▊       | 17/60 [00:24<00:56,  1.31s/it][A
 30%|███       | 18/60 [00:25<00:46,  1.11s/it][A
 32%|███▏      | 19/60 [00:26<00:47,  1.15s/it][A
 33%|███▎      | 20/60 [00:27<00:40,  1.01s/it][A
 35%|███▌      | 21/60 [00:28<00:39,  1.01s/it][A
 37%|███▋      | 22/60 [00:29<00:41,  1.10s/it][A
 38%|███▊      | 23/60 [00:31<00:41,  1.11s/it][A
 40%|████      | 24/60 [00:32<00:40,  1.13s/it][A
 42%|████▏     | 25/60 [00:33<00:45,  1.29s/it][A
 43%|████▎     | 26/60 [00:35<00:45,  1.33s/it][A
 45%|████▌     | 27/60 [00:36<00:38,  1.17s/it][A
 47%|████▋     | 28/60 [01:02<04:43,  8.87s/it][A
 48%|████▊     | 29/60 [01:04<03:23,  6.57s/it][A
 50%|█████     | 30/60 [01:05<02:32,  5.09s/it][A
 52%|█████▏    | 31/60 [01:07<01:57,  4.04s/it][A
 53%|█████▎    | 32/60 [01:08<01:31,  3.26s/it][A
 55%|█████▌    | 33/60 [01:10<01:12,  2.68s/it][A
 57%|█████▋    | 34/60 [01:10<00:55,  2.12s/it][A
 58%|█████▊    | 35/60 [01:12<00:47,  1.92s/it][A
 60%|██████    | 36/60 [01:13<00:42,  1.77s/it][A
 62%|██████▏   | 37/60 [01:14<00:33,  1.44s/it][A
 63%|██████▎   | 38/60 [01:16<00:32,  1.48s/it][A
 65%|██████▌   | 39/60 [01:17<00:28,  1.38s/it][A
 67%|██████▋   | 40/60 [01:18<00:24,  1.20s/it][A
 68%|██████▊   | 41/60 [01:19<00:24,  1.28s/it][A
 70%|███████   | 42/60 [01:21<00:24,  1.37s/it][A
 72%|███████▏  | 43/60 [01:21<00:21,  1.25s/it][A
 73%|███████▎  | 44/60 [01:23<00:21,  1.31s/it][A
 75%|███████▌  | 45/60 [01:24<00:17,  1.15s/it][A
 77%|███████▋  | 46/60 [01:25<00:17,  1.28s/it][A
 78%|███████▊  | 47/60 [01:27<00:18,  1.41s/it][A
 80%|████████  | 48/60 [01:28<00:14,  1.23s/it][A
 82%|████████▏ | 49/60 [01:30<00:15,  1.40s/it][A
 83%|████████▎ | 50/60 [01:31<00:14,  1.49s/it][A
 85%|████████▌ | 51/60 [01:33<00:13,  1.51s/it][A
 87%|████████▋ | 52/60 [01:34<00:11,  1.43s/it][A
 88%|████████▊ | 53/60 [01:35<00:09,  1.33s/it][A
 90%|█████████ | 54/60 [01:37<00:08,  1.40s/it][A
 92%|█████████▏| 55/60 [01:38<00:06,  1.21s/it][A
 93%|█████████▎| 56/60 [01:39<00:05,  1.41s/it][A
 95%|█████████▌| 57/60 [01:41<00:04,  1.45s/it][A
 97%|█████████▋| 58/60 [01:43<00:03,  1.51s/it][A
 98%|█████████▊| 59/60 [01:44<00:01,  1.53s/it][A
100%|██████████| 60/60 [01:46<00:00,  1.56s/it][A                                                       
                                               [A{'eval_loss': 0.3245103359222412, 'eval_runtime': 108.2478, 'eval_samples_per_second': 8.804, 'eval_steps_per_second': 0.554, 'eval_rewards/chosen': 0.7254964113235474, 'eval_rewards/rejected': -12.644274711608887, 'eval_rewards/accuracies': 0.8550926446914673, 'eval_rewards/margins': 13.358919143676758, 'eval_logps/chosen': -370.57501220703125, 'eval_logps/rejected': -278.3166809082031, 'eval_logits/chosen': -8.756771087646484, 'eval_logits/rejected': -8.712499618530273, 'epoch': 0.67}
 22%|██▏       | 1008/4545 [1:16:18<3:38:03,  3.70s/it]
100%|██████████| 60/60 [01:46<00:00,  1.56s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 22%|██▏       | 1009/4545 [1:16:35<39:31:04, 40.23s/it] 22%|██▏       | 1010/4545 [1:16:39<28:49:04, 29.35s/it]                                                        {'loss': 0.2367, 'grad_norm': 19.24403953552246, 'learning_rate': 2.665785997357992e-06, 'rewards/chosen': -0.71484375, 'rewards/rejected': -15.618749618530273, 'rewards/accuracies': 0.90625, 'rewards/margins': 14.890625, 'logps/chosen': -194.60000610351562, 'logps/rejected': -259.95001220703125, 'logits/chosen': -9.100000381469727, 'logits/rejected': -8.618749618530273, 'epoch': 0.67}
 22%|██▏       | 1010/4545 [1:16:40<28:49:04, 29.35s/it] 22%|██▏       | 1011/4545 [1:16:43<21:22:41, 21.78s/it] 22%|██▏       | 1012/4545 [1:16:47<16:07:20, 16.43s/it] 22%|██▏       | 1013/4545 [1:16:51<12:26:30, 12.68s/it] 22%|██▏       | 1014/4545 [1:16:55<9:52:11, 10.06s/it]  22%|██▏       | 1015/4545 [1:16:59<8:03:50,  8.22s/it] 22%|██▏       | 1016/4545 [1:17:03<6:48:25,  6.94s/it] 22%|██▏       | 1017/4545 [1:17:07<5:54:02,  6.02s/it] 22%|██▏       | 1018/4545 [1:17:09<4:49:57,  4.93s/it] 22%|██▏       | 1019/4545 [1:17:13<4:35:09,  4.68s/it] 22%|██▏       | 1020/4545 [1:17:16<4:08:11,  4.22s/it]                                                       {'loss': 0.2745, 'grad_norm': 25.709047317504883, 'learning_rate': 2.6922060766182297e-06, 'rewards/chosen': 0.805468738079071, 'rewards/rejected': -10.725000381469727, 'rewards/accuracies': 0.875, 'rewards/margins': 11.53125, 'logps/chosen': -307.54998779296875, 'logps/rejected': -289.1000061035156, 'logits/chosen': -9.287500381469727, 'logits/rejected': -8.831250190734863, 'epoch': 0.67}
 22%|██▏       | 1020/4545 [1:17:17<4:08:11,  4.22s/it] 22%|██▏       | 1021/4545 [1:17:19<3:30:49,  3.59s/it] 22%|██▏       | 1022/4545 [1:17:21<3:18:30,  3.38s/it] 23%|██▎       | 1023/4545 [1:17:25<3:21:30,  3.43s/it] 23%|██▎       | 1024/4545 [1:17:29<3:33:25,  3.64s/it] 23%|██▎       | 1025/4545 [1:17:33<3:39:21,  3.74s/it] 23%|██▎       | 1026/4545 [1:17:37<3:42:41,  3.80s/it] 23%|██▎       | 1027/4545 [1:17:41<3:38:32,  3.73s/it] 23%|██▎       | 1028/4545 [1:17:44<3:38:09,  3.72s/it] 23%|██▎       | 1029/4545 [1:17:48<3:45:16,  3.84s/it] 23%|██▎       | 1030/4545 [1:17:52<3:47:02,  3.88s/it]                                                       {'loss': 0.2715, 'grad_norm': 34.20819091796875, 'learning_rate': 2.7186261558784674e-06, 'rewards/chosen': -0.618945300579071, 'rewards/rejected': -12.259374618530273, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 11.65625, 'logps/chosen': -212.89999389648438, 'logps/rejected': -247.75, 'logits/chosen': -9.912500381469727, 'logits/rejected': -9.46875, 'epoch': 0.68}
 23%|██▎       | 1030/4545 [1:17:53<3:47:02,  3.88s/it] 23%|██▎       | 1031/4545 [1:17:56<3:38:27,  3.73s/it] 23%|██▎       | 1032/4545 [1:17:59<3:37:33,  3.72s/it] 23%|██▎       | 1033/4545 [1:18:03<3:41:52,  3.79s/it] 23%|██▎       | 1034/4545 [1:18:06<3:27:36,  3.55s/it] 23%|██▎       | 1035/4545 [1:18:10<3:37:17,  3.71s/it] 23%|██▎       | 1036/4545 [1:18:14<3:30:00,  3.59s/it] 23%|██▎       | 1037/4545 [1:18:17<3:26:36,  3.53s/it] 23%|██▎       | 1038/4545 [1:18:20<3:13:27,  3.31s/it] 23%|██▎       | 1039/4545 [1:18:24<3:25:50,  3.52s/it] 23%|██▎       | 1040/4545 [1:18:27<3:22:20,  3.46s/it]                                                       {'loss': 0.2286, 'grad_norm': 36.46025085449219, 'learning_rate': 2.745046235138705e-06, 'rewards/chosen': 0.012500000186264515, 'rewards/rejected': -12.139062881469727, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 12.15625, 'logps/chosen': -187.4499969482422, 'logps/rejected': -230.60000610351562, 'logits/chosen': -10.206250190734863, 'logits/rejected': -9.59375, 'epoch': 0.69}
 23%|██▎       | 1040/4545 [1:18:27<3:22:20,  3.46s/it] 23%|██▎       | 1041/4545 [1:18:56<10:50:14, 11.13s/it] 23%|██▎       | 1042/4545 [1:19:00<8:38:45,  8.89s/it]  23%|██▎       | 1043/4545 [1:19:03<7:01:20,  7.22s/it] 23%|██▎       | 1044/4545 [1:19:07<6:02:18,  6.21s/it] 23%|██▎       | 1045/4545 [1:19:11<5:22:53,  5.54s/it] 23%|██▎       | 1046/4545 [1:19:15<4:54:52,  5.06s/it] 23%|██▎       | 1047/4545 [1:19:19<4:35:21,  4.72s/it] 23%|██▎       | 1048/4545 [1:19:23<4:21:57,  4.49s/it] 23%|██▎       | 1049/4545 [1:19:26<4:02:43,  4.17s/it] 23%|██▎       | 1050/4545 [1:19:30<3:58:46,  4.10s/it]                                                       {'loss': 0.1769, 'grad_norm': 8.021631240844727, 'learning_rate': 2.771466314398943e-06, 'rewards/chosen': 1.551171898841858, 'rewards/rejected': -14.160937309265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 15.699999809265137, 'logps/chosen': -340.04998779296875, 'logps/rejected': -308.5, 'logits/chosen': -9.84375, 'logits/rejected': -9.293749809265137, 'epoch': 0.69}
 23%|██▎       | 1050/4545 [1:19:31<3:58:46,  4.10s/it] 23%|██▎       | 1051/4545 [1:19:35<4:01:45,  4.15s/it] 23%|██▎       | 1052/4545 [1:19:38<3:57:24,  4.08s/it] 23%|██▎       | 1053/4545 [1:19:42<3:49:09,  3.94s/it] 23%|██▎       | 1054/4545 [1:19:46<3:40:08,  3.78s/it] 23%|██▎       | 1055/4545 [1:19:49<3:38:53,  3.76s/it] 23%|██▎       | 1056/4545 [1:19:53<3:39:55,  3.78s/it] 23%|██▎       | 1057/4545 [1:19:57<3:42:29,  3.83s/it] 23%|██▎       | 1058/4545 [1:20:00<3:28:21,  3.59s/it] 23%|██▎       | 1059/4545 [1:20:04<3:34:44,  3.70s/it] 23%|██▎       | 1060/4545 [1:20:08<3:40:46,  3.80s/it]                                                       {'loss': 0.2835, 'grad_norm': 24.561450958251953, 'learning_rate': 2.797886393659181e-06, 'rewards/chosen': 0.789257824420929, 'rewards/rejected': -14.259374618530273, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 15.065625190734863, 'logps/chosen': -286.8500061035156, 'logps/rejected': -307.5, 'logits/chosen': -9.9375, 'logits/rejected': -9.268750190734863, 'epoch': 0.7}
 23%|██▎       | 1060/4545 [1:20:08<3:40:46,  3.80s/it] 23%|██▎       | 1061/4545 [1:20:12<3:42:57,  3.84s/it] 23%|██▎       | 1062/4545 [1:20:16<3:49:59,  3.96s/it] 23%|██▎       | 1063/4545 [1:20:20<3:42:12,  3.83s/it] 23%|██▎       | 1064/4545 [1:20:24<3:44:18,  3.87s/it] 23%|██▎       | 1065/4545 [1:20:28<3:48:44,  3.94s/it] 23%|██▎       | 1066/4545 [1:20:32<3:53:30,  4.03s/it] 23%|██▎       | 1067/4545 [1:20:35<3:39:01,  3.78s/it] 23%|██▎       | 1068/4545 [1:20:39<3:37:51,  3.76s/it] 24%|██▎       | 1069/4545 [1:20:43<3:34:47,  3.71s/it] 24%|██▎       | 1070/4545 [1:20:46<3:29:33,  3.62s/it]                                                       {'loss': 0.2393, 'grad_norm': 25.702754974365234, 'learning_rate': 2.8243064729194187e-06, 'rewards/chosen': -0.5146484375, 'rewards/rejected': -19.450000762939453, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 18.920312881469727, 'logps/chosen': -200.35000610351562, 'logps/rejected': -292.5, 'logits/chosen': -9.862500190734863, 'logits/rejected': -9.381250381469727, 'epoch': 0.71}
 24%|██▎       | 1070/4545 [1:20:46<3:29:33,  3.62s/it] 24%|██▎       | 1071/4545 [1:20:50<3:35:58,  3.73s/it] 24%|██▎       | 1072/4545 [1:20:54<3:40:25,  3.81s/it] 24%|██▎       | 1073/4545 [1:20:58<3:42:53,  3.85s/it] 24%|██▎       | 1074/4545 [1:21:02<3:44:00,  3.87s/it] 24%|██▎       | 1075/4545 [1:21:06<3:47:35,  3.94s/it] 24%|██▎       | 1076/4545 [1:21:09<3:31:13,  3.65s/it] 24%|██▎       | 1077/4545 [1:21:13<3:36:21,  3.74s/it] 24%|██▎       | 1078/4545 [1:21:17<3:40:09,  3.81s/it] 24%|██▎       | 1079/4545 [1:21:21<3:42:31,  3.85s/it] 24%|██▍       | 1080/4545 [1:21:25<3:44:12,  3.88s/it]                                                       {'loss': 0.2831, 'grad_norm': 11.106023788452148, 'learning_rate': 2.8507265521796564e-06, 'rewards/chosen': 2.0863280296325684, 'rewards/rejected': -11.276562690734863, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 13.350000381469727, 'logps/chosen': -445.95001220703125, 'logps/rejected': -332.29998779296875, 'logits/chosen': -9.006250381469727, 'logits/rejected': -8.690625190734863, 'epoch': 0.71}
 24%|██▍       | 1080/4545 [1:21:25<3:44:12,  3.88s/it] 24%|██▍       | 1081/4545 [1:21:29<3:45:59,  3.91s/it] 24%|██▍       | 1082/4545 [1:21:33<3:48:51,  3.97s/it] 24%|██▍       | 1083/4545 [1:21:36<3:34:29,  3.72s/it] 24%|██▍       | 1084/4545 [1:21:40<3:41:11,  3.83s/it] 24%|██▍       | 1085/4545 [1:21:44<3:36:53,  3.76s/it] 24%|██▍       | 1086/4545 [1:21:46<3:19:05,  3.45s/it] 24%|██▍       | 1087/4545 [1:21:49<3:10:33,  3.31s/it] 24%|██▍       | 1088/4545 [1:21:53<3:21:42,  3.50s/it] 24%|██▍       | 1089/4545 [1:21:57<3:29:44,  3.64s/it] 24%|██▍       | 1090/4545 [1:22:01<3:38:51,  3.80s/it]                                                       {'loss': 0.1567, 'grad_norm': 37.10694885253906, 'learning_rate': 2.877146631439894e-06, 'rewards/chosen': 0.16416016221046448, 'rewards/rejected': -16.728124618530273, 'rewards/accuracies': 0.9375, 'rewards/margins': 16.881250381469727, 'logps/chosen': -249.5749969482422, 'logps/rejected': -280.3500061035156, 'logits/chosen': -9.6875, 'logits/rejected': -9.199999809265137, 'epoch': 0.72}
 24%|██▍       | 1090/4545 [1:22:02<3:38:51,  3.80s/it] 24%|██▍       | 1091/4545 [1:22:05<3:35:32,  3.74s/it] 24%|██▍       | 1092/4545 [1:22:07<3:09:18,  3.29s/it] 24%|██▍       | 1093/4545 [1:22:11<3:23:03,  3.53s/it] 24%|██▍       | 1094/4545 [1:22:15<3:22:13,  3.52s/it] 24%|██▍       | 1095/4545 [1:22:19<3:29:26,  3.64s/it] 24%|██▍       | 1096/4545 [1:22:22<3:18:06,  3.45s/it] 24%|██▍       | 1097/4545 [1:22:26<3:30:42,  3.67s/it] 24%|██▍       | 1098/4545 [1:22:30<3:38:09,  3.80s/it] 24%|██▍       | 1099/4545 [1:22:34<3:40:43,  3.84s/it] 24%|██▍       | 1100/4545 [1:22:38<3:45:44,  3.93s/it]                                                       {'loss': 0.2413, 'grad_norm': 15.26858139038086, 'learning_rate': 2.903566710700132e-06, 'rewards/chosen': -0.5299072265625, 'rewards/rejected': -18.959375381469727, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 18.412500381469727, 'logps/chosen': -266.29998779296875, 'logps/rejected': -317.20001220703125, 'logits/chosen': -9.931249618530273, 'logits/rejected': -9.493749618530273, 'epoch': 0.73}
 24%|██▍       | 1100/4545 [1:22:38<3:45:44,  3.93s/it] 24%|██▍       | 1101/4545 [1:22:42<3:48:17,  3.98s/it] 24%|██▍       | 1102/4545 [1:22:46<3:47:48,  3.97s/it] 24%|██▍       | 1103/4545 [1:22:50<3:37:43,  3.80s/it] 24%|██▍       | 1104/4545 [1:22:53<3:40:13,  3.84s/it] 24%|██▍       | 1105/4545 [1:22:58<3:45:38,  3.94s/it] 24%|██▍       | 1106/4545 [1:23:02<3:45:47,  3.94s/it] 24%|██▍       | 1107/4545 [1:23:06<3:51:14,  4.04s/it] 24%|██▍       | 1108/4545 [1:23:08<3:25:46,  3.59s/it] 24%|██▍       | 1109/4545 [1:23:12<3:32:03,  3.70s/it] 24%|██▍       | 1110/4545 [1:23:16<3:24:40,  3.58s/it]                                                       {'loss': 0.2732, 'grad_norm': 21.502790451049805, 'learning_rate': 2.92998678996037e-06, 'rewards/chosen': 0.10039062798023224, 'rewards/rejected': -16.875, 'rewards/accuracies': 0.90625, 'rewards/margins': 16.959375381469727, 'logps/chosen': -311.3999938964844, 'logps/rejected': -334.70001220703125, 'logits/chosen': -9.53125, 'logits/rejected': -9.081250190734863, 'epoch': 0.73}
 24%|██▍       | 1110/4545 [1:23:16<3:24:40,  3.58s/it] 24%|██▍       | 1111/4545 [1:23:18<3:10:03,  3.32s/it] 24%|██▍       | 1112/4545 [1:23:22<3:22:31,  3.54s/it] 24%|██▍       | 1113/4545 [1:23:51<10:33:18, 11.07s/it] 25%|██▍       | 1114/4545 [1:23:55<8:30:54,  8.93s/it]  25%|██▍       | 1115/4545 [1:23:59<7:10:12,  7.53s/it] 25%|██▍       | 1116/4545 [1:24:03<5:57:38,  6.26s/it] 25%|██▍       | 1117/4545 [1:24:05<4:48:48,  5.06s/it] 25%|██▍       | 1118/4545 [1:24:09<4:37:12,  4.85s/it] 25%|██▍       | 1119/4545 [1:24:13<4:20:21,  4.56s/it] 25%|██▍       | 1120/4545 [1:24:17<4:06:55,  4.33s/it]                                                       {'loss': 0.1869, 'grad_norm': 30.089685440063477, 'learning_rate': 2.9564068692206076e-06, 'rewards/chosen': 0.43470460176467896, 'rewards/rejected': -16.206249237060547, 'rewards/accuracies': 0.90625, 'rewards/margins': 16.659374237060547, 'logps/chosen': -264.70001220703125, 'logps/rejected': -296.45001220703125, 'logits/chosen': -9.662500381469727, 'logits/rejected': -9.106249809265137, 'epoch': 0.74}
 25%|██▍       | 1120/4545 [1:24:17<4:06:55,  4.33s/it] 25%|██▍       | 1121/4545 [1:24:21<4:05:34,  4.30s/it] 25%|██▍       | 1122/4545 [1:24:25<4:01:22,  4.23s/it] 25%|██▍       | 1123/4545 [1:24:29<3:55:02,  4.12s/it] 25%|██▍       | 1124/4545 [1:24:33<3:52:17,  4.07s/it] 25%|██▍       | 1125/4545 [1:24:36<3:39:48,  3.86s/it] 25%|██▍       | 1126/4545 [1:24:40<3:40:59,  3.88s/it] 25%|██▍       | 1127/4545 [1:24:44<3:34:54,  3.77s/it] 25%|██▍       | 1128/4545 [1:24:47<3:24:13,  3.59s/it] 25%|██▍       | 1129/4545 [1:24:51<3:33:07,  3.74s/it] 25%|██▍       | 1130/4545 [1:24:53<3:02:32,  3.21s/it]                                                       {'loss': 0.1895, 'grad_norm': 10.185420989990234, 'learning_rate': 2.9828269484808453e-06, 'rewards/chosen': -0.11445312201976776, 'rewards/rejected': -14.065625190734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 13.943750381469727, 'logps/chosen': -219.4499969482422, 'logps/rejected': -247.0500030517578, 'logits/chosen': -9.887499809265137, 'logits/rejected': -9.34375, 'epoch': 0.75}
 25%|██▍       | 1130/4545 [1:24:53<3:02:32,  3.21s/it] 25%|██▍       | 1131/4545 [1:24:57<3:12:19,  3.38s/it] 25%|██▍       | 1132/4545 [1:25:00<3:04:46,  3.25s/it] 25%|██▍       | 1133/4545 [1:25:04<3:14:46,  3.43s/it] 25%|██▍       | 1134/4545 [1:25:07<3:11:48,  3.37s/it] 25%|██▍       | 1135/4545 [1:25:11<3:21:14,  3.54s/it] 25%|██▍       | 1136/4545 [1:25:14<3:17:00,  3.47s/it] 25%|██▌       | 1137/4545 [1:25:17<3:13:55,  3.41s/it] 25%|██▌       | 1138/4545 [1:25:21<3:22:48,  3.57s/it] 25%|██▌       | 1139/4545 [1:25:25<3:17:03,  3.47s/it] 25%|██▌       | 1140/4545 [1:25:28<3:17:51,  3.49s/it]                                                       {'loss': 0.2023, 'grad_norm': 16.50124740600586, 'learning_rate': 3.0092470277410835e-06, 'rewards/chosen': -0.610156238079071, 'rewards/rejected': -13.481249809265137, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 12.890625, 'logps/chosen': -171.3000030517578, 'logps/rejected': -248.5, 'logits/chosen': -9.931249618530273, 'logits/rejected': -9.399999618530273, 'epoch': 0.75}
 25%|██▌       | 1140/4545 [1:25:28<3:17:51,  3.49s/it] 25%|██▌       | 1141/4545 [1:25:32<3:26:29,  3.64s/it] 25%|██▌       | 1142/4545 [1:25:35<3:18:08,  3.49s/it] 25%|██▌       | 1143/4545 [1:25:39<3:16:18,  3.46s/it] 25%|██▌       | 1144/4545 [1:25:43<3:25:04,  3.62s/it] 25%|██▌       | 1145/4545 [1:25:46<3:30:41,  3.72s/it] 25%|██▌       | 1146/4545 [1:25:50<3:34:39,  3.79s/it] 25%|██▌       | 1147/4545 [1:25:54<3:23:47,  3.60s/it] 25%|██▌       | 1148/4545 [1:25:57<3:12:02,  3.39s/it] 25%|██▌       | 1149/4545 [1:26:00<3:16:27,  3.47s/it] 25%|██▌       | 1150/4545 [1:26:04<3:21:25,  3.56s/it]                                                       {'loss': 0.1889, 'grad_norm': 21.051559448242188, 'learning_rate': 3.0356671070013207e-06, 'rewards/chosen': 0.845703125, 'rewards/rejected': -14.793749809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 15.640625, 'logps/chosen': -300.1000061035156, 'logps/rejected': -319.20001220703125, 'logits/chosen': -9.831250190734863, 'logits/rejected': -9.368749618530273, 'epoch': 0.76}
 25%|██▌       | 1150/4545 [1:26:04<3:21:25,  3.56s/it] 25%|██▌       | 1151/4545 [1:26:08<3:30:11,  3.72s/it] 25%|██▌       | 1152/4545 [1:26:12<3:34:12,  3.79s/it] 25%|██▌       | 1153/4545 [1:26:16<3:36:56,  3.84s/it] 25%|██▌       | 1154/4545 [1:26:18<2:59:00,  3.17s/it] 25%|██▌       | 1155/4545 [1:26:21<3:10:54,  3.38s/it] 25%|██▌       | 1156/4545 [1:26:25<3:18:53,  3.52s/it] 25%|██▌       | 1157/4545 [1:26:29<3:27:19,  3.67s/it] 25%|██▌       | 1158/4545 [1:26:33<3:32:32,  3.77s/it] 26%|██▌       | 1159/4545 [1:26:37<3:35:42,  3.82s/it] 26%|██▌       | 1160/4545 [1:26:40<3:22:58,  3.60s/it]                                                       {'loss': 0.2779, 'grad_norm': 1.7731112241744995, 'learning_rate': 3.0620871862615585e-06, 'rewards/chosen': 0.08730468899011612, 'rewards/rejected': -18.606250762939453, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 18.681249618530273, 'logps/chosen': -288.75, 'logps/rejected': -319.6000061035156, 'logits/chosen': -9.868749618530273, 'logits/rejected': -9.462499618530273, 'epoch': 0.77}
 26%|██▌       | 1160/4545 [1:26:40<3:22:58,  3.60s/it] 26%|██▌       | 1161/4545 [1:26:44<3:29:24,  3.71s/it] 26%|██▌       | 1162/4545 [1:26:48<3:33:52,  3.79s/it] 26%|██▌       | 1163/4545 [1:26:52<3:36:41,  3.84s/it] 26%|██▌       | 1164/4545 [1:26:56<3:40:36,  3.92s/it] 26%|██▌       | 1165/4545 [1:27:00<3:41:19,  3.93s/it] 26%|██▌       | 1166/4545 [1:27:03<3:14:16,  3.45s/it] 26%|██▌       | 1167/4545 [1:27:07<3:28:14,  3.70s/it] 26%|██▌       | 1168/4545 [1:27:11<3:34:41,  3.81s/it] 26%|██▌       | 1169/4545 [1:27:15<3:30:31,  3.74s/it] 26%|██▌       | 1170/4545 [1:27:19<3:38:57,  3.89s/it]                                                       {'loss': 0.3314, 'grad_norm': 40.48253631591797, 'learning_rate': 3.088507265521796e-06, 'rewards/chosen': -0.33759766817092896, 'rewards/rejected': -21.018749237060547, 'rewards/accuracies': 0.90625, 'rewards/margins': 20.6875, 'logps/chosen': -346.5, 'logps/rejected': -346.3999938964844, 'logits/chosen': -9.78125, 'logits/rejected': -9.431249618530273, 'epoch': 0.77}
 26%|██▌       | 1170/4545 [1:27:19<3:38:57,  3.89s/it] 26%|██▌       | 1171/4545 [1:27:48<10:51:11, 11.58s/it] 26%|██▌       | 1172/4545 [1:27:52<8:42:17,  9.29s/it]  26%|██▌       | 1173/4545 [1:27:56<7:00:50,  7.49s/it] 26%|██▌       | 1174/4545 [1:28:00<6:02:24,  6.45s/it] 26%|██▌       | 1175/4545 [1:28:03<5:19:19,  5.69s/it] 26%|██▌       | 1176/4545 [1:28:07<4:50:05,  5.17s/it] 26%|██▌       | 1177/4545 [1:28:11<4:23:09,  4.69s/it] 26%|██▌       | 1178/4545 [1:28:15<4:11:16,  4.48s/it] 26%|██▌       | 1179/4545 [1:28:19<4:06:47,  4.40s/it] 26%|██▌       | 1180/4545 [1:28:23<4:03:48,  4.35s/it]                                                       {'loss': 0.1771, 'grad_norm': 12.052674293518066, 'learning_rate': 3.1149273447820343e-06, 'rewards/chosen': 0.47968751192092896, 'rewards/rejected': -16.524999618530273, 'rewards/accuracies': 0.90625, 'rewards/margins': 17.012500762939453, 'logps/chosen': -316.0, 'logps/rejected': -349.3999938964844, 'logits/chosen': -9.818750381469727, 'logits/rejected': -9.331250190734863, 'epoch': 0.78}
 26%|██▌       | 1180/4545 [1:28:24<4:03:48,  4.35s/it] 26%|██▌       | 1181/4545 [1:28:28<4:00:32,  4.29s/it] 26%|██▌       | 1182/4545 [1:28:32<3:54:31,  4.18s/it] 26%|██▌       | 1183/4545 [1:28:36<3:55:42,  4.21s/it] 26%|██▌       | 1184/4545 [1:28:40<3:51:19,  4.13s/it] 26%|██▌       | 1185/4545 [1:28:42<3:28:31,  3.72s/it] 26%|██▌       | 1186/4545 [1:28:46<3:32:44,  3.80s/it] 26%|██▌       | 1187/4545 [1:28:50<3:35:03,  3.84s/it] 26%|██▌       | 1188/4545 [1:28:54<3:37:08,  3.88s/it] 26%|██▌       | 1189/4545 [1:28:58<3:28:51,  3.73s/it] 26%|██▌       | 1190/4545 [1:29:02<3:32:23,  3.80s/it]                                                       {'loss': 0.1706, 'grad_norm': 9.64236068725586, 'learning_rate': 3.141347424042272e-06, 'rewards/chosen': 1.0558593273162842, 'rewards/rejected': -16.106250762939453, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 17.165624618530273, 'logps/chosen': -292.79998779296875, 'logps/rejected': -358.8999938964844, 'logits/chosen': -9.537500381469727, 'logits/rejected': -9.128125190734863, 'epoch': 0.79}
 26%|██▌       | 1190/4545 [1:29:02<3:32:23,  3.80s/it] 26%|██▌       | 1191/4545 [1:29:05<3:24:19,  3.66s/it] 26%|██▌       | 1192/4545 [1:29:09<3:33:11,  3.81s/it] 26%|██▌       | 1193/4545 [1:29:13<3:30:57,  3.78s/it] 26%|██▋       | 1194/4545 [1:29:17<3:32:55,  3.81s/it] 26%|██▋       | 1195/4545 [1:29:21<3:34:50,  3.85s/it] 26%|██▋       | 1196/4545 [1:29:25<3:36:35,  3.88s/it] 26%|██▋       | 1197/4545 [1:29:29<3:37:29,  3.90s/it] 26%|██▋       | 1198/4545 [1:29:32<3:22:04,  3.62s/it] 26%|██▋       | 1199/4545 [1:29:35<3:13:20,  3.47s/it] 26%|██▋       | 1200/4545 [1:29:39<3:27:15,  3.72s/it]                                                       {'loss': 0.183, 'grad_norm': 23.336259841918945, 'learning_rate': 3.1677675033025097e-06, 'rewards/chosen': 0.3013671934604645, 'rewards/rejected': -17.012500762939453, 'rewards/accuracies': 0.90625, 'rewards/margins': 17.346874237060547, 'logps/chosen': -263.95001220703125, 'logps/rejected': -318.70001220703125, 'logits/chosen': -9.875, 'logits/rejected': -9.21875, 'epoch': 0.79}
 26%|██▋       | 1200/4545 [1:29:39<3:27:15,  3.72s/it] 26%|██▋       | 1201/4545 [1:29:42<3:14:14,  3.49s/it] 26%|██▋       | 1202/4545 [1:29:46<3:19:58,  3.59s/it] 26%|██▋       | 1203/4545 [1:29:50<3:30:01,  3.77s/it] 26%|██▋       | 1204/4545 [1:29:54<3:29:04,  3.75s/it] 27%|██▋       | 1205/4545 [1:29:58<3:31:09,  3.79s/it] 27%|██▋       | 1206/4545 [1:30:01<3:22:33,  3.64s/it] 27%|██▋       | 1207/4545 [1:30:05<3:26:18,  3.71s/it] 27%|██▋       | 1208/4545 [1:30:09<3:30:06,  3.78s/it] 27%|██▋       | 1209/4545 [1:30:13<3:36:00,  3.89s/it] 27%|██▋       | 1210/4545 [1:30:17<3:37:09,  3.91s/it]                                                       {'loss': 0.2185, 'grad_norm': 17.81892967224121, 'learning_rate': 3.1941875825627474e-06, 'rewards/chosen': -1.3310546875, 'rewards/rejected': -27.012500762939453, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 25.668750762939453, 'logps/chosen': -244.4499969482422, 'logps/rejected': -399.29998779296875, 'logits/chosen': -10.206250190734863, 'logits/rejected': -9.675000190734863, 'epoch': 0.8}
 27%|██▋       | 1210/4545 [1:30:17<3:37:09,  3.91s/it] 27%|██▋       | 1211/4545 [1:30:21<3:38:16,  3.93s/it] 27%|██▋       | 1212/4545 [1:30:25<3:38:35,  3.93s/it] 27%|██▋       | 1213/4545 [1:30:29<3:38:58,  3.94s/it] 27%|██▋       | 1214/4545 [1:30:33<3:43:28,  4.03s/it] 27%|██▋       | 1215/4545 [1:30:36<3:31:21,  3.81s/it] 27%|██▋       | 1216/4545 [1:30:40<3:29:36,  3.78s/it] 27%|██▋       | 1217/4545 [1:30:44<3:33:45,  3.85s/it] 27%|██▋       | 1218/4545 [1:30:48<3:40:09,  3.97s/it] 27%|██▋       | 1219/4545 [1:30:52<3:39:48,  3.97s/it] 27%|██▋       | 1220/4545 [1:30:56<3:39:31,  3.96s/it]                                                       {'loss': 0.1459, 'grad_norm': 6.986197471618652, 'learning_rate': 3.2206076618229855e-06, 'rewards/chosen': 0.5531250238418579, 'rewards/rejected': -15.024999618530273, 'rewards/accuracies': 0.9375, 'rewards/margins': 15.587499618530273, 'logps/chosen': -334.1000061035156, 'logps/rejected': -335.0, 'logits/chosen': -10.149999618530273, 'logits/rejected': -9.681249618530273, 'epoch': 0.81}
 27%|██▋       | 1220/4545 [1:30:56<3:39:31,  3.96s/it] 27%|██▋       | 1221/4545 [1:31:00<3:34:06,  3.86s/it] 27%|██▋       | 1222/4545 [1:31:03<3:29:18,  3.78s/it] 27%|██▋       | 1223/4545 [1:31:07<3:31:10,  3.81s/it] 27%|██▋       | 1224/4545 [1:31:11<3:33:10,  3.85s/it] 27%|██▋       | 1225/4545 [1:31:14<3:25:08,  3.71s/it] 27%|██▋       | 1226/4545 [1:31:18<3:29:45,  3.79s/it] 27%|██▋       | 1227/4545 [1:31:22<3:32:10,  3.84s/it] 27%|██▋       | 1228/4545 [1:31:27<3:37:03,  3.93s/it] 27%|██▋       | 1229/4545 [1:31:30<3:36:22,  3.92s/it] 27%|██▋       | 1230/4545 [1:31:34<3:31:12,  3.82s/it]                                                       {'loss': 0.1798, 'grad_norm': 6.175473213195801, 'learning_rate': 3.2470277410832233e-06, 'rewards/chosen': 0.591796875, 'rewards/rejected': -16.471874237060547, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 17.056249618530273, 'logps/chosen': -348.20001220703125, 'logps/rejected': -415.8999938964844, 'logits/chosen': -10.125, 'logits/rejected': -9.53125, 'epoch': 0.81}
 27%|██▋       | 1230/4545 [1:31:35<3:31:12,  3.82s/it] 27%|██▋       | 1231/4545 [1:31:38<3:34:15,  3.88s/it] 27%|██▋       | 1232/4545 [1:31:42<3:35:21,  3.90s/it] 27%|██▋       | 1233/4545 [1:31:46<3:33:53,  3.87s/it] 27%|██▋       | 1234/4545 [1:31:50<3:39:11,  3.97s/it] 27%|██▋       | 1235/4545 [1:31:53<3:22:42,  3.67s/it] 27%|██▋       | 1236/4545 [1:31:57<3:26:54,  3.75s/it] 27%|██▋       | 1237/4545 [1:32:01<3:29:55,  3.81s/it] 27%|██▋       | 1238/4545 [1:32:05<3:32:19,  3.85s/it] 27%|██▋       | 1239/4545 [1:32:09<3:34:00,  3.88s/it] 27%|██▋       | 1240/4545 [1:32:13<3:34:46,  3.90s/it]                                                       {'loss': 0.2786, 'grad_norm': 30.038816452026367, 'learning_rate': 3.273447820343461e-06, 'rewards/chosen': 0.46875, 'rewards/rejected': -17.006250381469727, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 17.462499618530273, 'logps/chosen': -435.29998779296875, 'logps/rejected': -390.3999938964844, 'logits/chosen': -10.118749618530273, 'logits/rejected': -9.475000381469727, 'epoch': 0.82}
 27%|██▋       | 1240/4545 [1:32:13<3:34:46,  3.90s/it] 27%|██▋       | 1241/4545 [1:32:17<3:35:48,  3.92s/it] 27%|██▋       | 1242/4545 [1:32:21<3:37:01,  3.94s/it] 27%|██▋       | 1243/4545 [1:32:25<3:36:49,  3.94s/it] 27%|██▋       | 1244/4545 [1:32:29<3:42:05,  4.04s/it] 27%|██▋       | 1245/4545 [1:32:33<3:40:25,  4.01s/it] 27%|██▋       | 1246/4545 [1:32:37<3:40:07,  4.00s/it] 27%|██▋       | 1247/4545 [1:32:40<3:33:35,  3.89s/it] 27%|██▋       | 1248/4545 [1:32:44<3:34:20,  3.90s/it] 27%|██▋       | 1249/4545 [1:32:49<3:38:25,  3.98s/it] 28%|██▊       | 1250/4545 [1:32:52<3:38:12,  3.97s/it]                                                       {'loss': 0.1841, 'grad_norm': 26.169248580932617, 'learning_rate': 3.2998678996036987e-06, 'rewards/chosen': -0.5638672113418579, 'rewards/rejected': -12.806249618530273, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 12.243749618530273, 'logps/chosen': -238.5, 'logps/rejected': -275.70001220703125, 'logits/chosen': -10.743749618530273, 'logits/rejected': -10.243749618530273, 'epoch': 0.83}
 28%|██▊       | 1250/4545 [1:32:53<3:38:12,  3.97s/it] 28%|██▊       | 1251/4545 [1:32:56<3:32:18,  3.87s/it] 28%|██▊       | 1252/4545 [1:33:00<3:27:06,  3.77s/it] 28%|██▊       | 1253/4545 [1:33:04<3:29:45,  3.82s/it] 28%|██▊       | 1254/4545 [1:33:08<3:31:01,  3.85s/it] 28%|██▊       | 1255/4545 [1:33:11<3:31:42,  3.86s/it] 28%|██▊       | 1256/4545 [1:33:15<3:33:02,  3.89s/it] 28%|██▊       | 1257/4545 [1:33:20<3:39:01,  4.00s/it] 28%|██▊       | 1258/4545 [1:33:24<3:43:32,  4.08s/it] 28%|██▊       | 1259/4545 [1:33:28<3:42:50,  4.07s/it] 28%|██▊       | 1260/4545 [1:33:30<3:16:09,  3.58s/it]                                                       {'loss': 0.3101, 'grad_norm': 24.318395614624023, 'learning_rate': 3.326287978863937e-06, 'rewards/chosen': -1.619531273841858, 'rewards/rejected': -14.037500381469727, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 12.431249618530273, 'logps/chosen': -218.5500030517578, 'logps/rejected': -273.6000061035156, 'logits/chosen': -10.362500190734863, 'logits/rejected': -9.90625, 'epoch': 0.83}
 28%|██▊       | 1260/4545 [1:33:30<3:16:09,  3.58s/it] 28%|██▊       | 1261/4545 [1:33:34<3:22:49,  3.71s/it] 28%|██▊       | 1262/4545 [1:33:38<3:26:31,  3.77s/it] 28%|██▊       | 1263/4545 [1:34:07<10:22:44, 11.38s/it] 28%|██▊       | 1264/4545 [1:34:11<8:20:24,  9.15s/it]  28%|██▊       | 1265/4545 [1:34:15<6:54:01,  7.57s/it] 28%|██▊       | 1266/4545 [1:34:19<5:52:21,  6.45s/it] 28%|██▊       | 1267/4545 [1:34:22<4:54:49,  5.40s/it] 28%|██▊       | 1268/4545 [1:34:26<4:30:55,  4.96s/it] 28%|██▊       | 1269/4545 [1:34:30<4:07:53,  4.54s/it] 28%|██▊       | 1270/4545 [1:34:34<4:00:00,  4.40s/it]                                                       {'loss': 0.2461, 'grad_norm': 15.10695743560791, 'learning_rate': 3.352708058124174e-06, 'rewards/chosen': -0.48681640625, 'rewards/rejected': -12.431249618530273, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 11.940625190734863, 'logps/chosen': -311.25, 'logps/rejected': -257.20001220703125, 'logits/chosen': -9.987500190734863, 'logits/rejected': -9.574999809265137, 'epoch': 0.84}
 28%|██▊       | 1270/4545 [1:34:34<4:00:00,  4.40s/it] 28%|██▊       | 1271/4545 [1:34:38<3:58:15,  4.37s/it] 28%|██▊       | 1272/4545 [1:34:41<3:35:30,  3.95s/it] 28%|██▊       | 1273/4545 [1:34:45<3:35:33,  3.95s/it] 28%|██▊       | 1274/4545 [1:34:49<3:35:30,  3.95s/it] 28%|██▊       | 1275/4545 [1:35:21<11:14:22, 12.37s/it] 28%|██▊       | 1276/4545 [1:35:27<9:38:51, 10.62s/it]  28%|██▊       | 1277/4545 [1:35:35<8:47:56,  9.69s/it] 28%|██▊       | 1278/4545 [1:35:43<8:15:10,  9.09s/it] 28%|██▊       | 1279/4545 [1:35:49<7:37:02,  8.40s/it] 28%|██▊       | 1280/4545 [1:35:57<7:23:59,  8.16s/it]                                                       {'loss': 0.2109, 'grad_norm': 14.750481605529785, 'learning_rate': 3.379128137384412e-06, 'rewards/chosen': 0.774609386920929, 'rewards/rejected': -13.665624618530273, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 14.449999809265137, 'logps/chosen': -351.3500061035156, 'logps/rejected': -316.79998779296875, 'logits/chosen': -9.706250190734863, 'logits/rejected': -9.300000190734863, 'epoch': 0.84}
 28%|██▊       | 1280/4545 [1:35:57<7:23:59,  8.16s/it] 28%|██▊       | 1281/4545 [1:36:05<7:15:53,  8.01s/it] 28%|██▊       | 1282/4545 [1:36:12<7:07:28,  7.86s/it] 28%|██▊       | 1283/4545 [1:36:19<6:47:17,  7.49s/it] 28%|██▊       | 1284/4545 [1:36:26<6:42:04,  7.40s/it] 28%|██▊       | 1285/4545 [1:36:33<6:43:11,  7.42s/it] 28%|██▊       | 1286/4545 [1:36:41<6:47:05,  7.49s/it] 28%|██▊       | 1287/4545 [1:36:49<6:48:48,  7.53s/it] 28%|██▊       | 1288/4545 [1:36:56<6:50:36,  7.56s/it] 28%|██▊       | 1289/4545 [1:37:04<6:48:47,  7.53s/it] 28%|██▊       | 1290/4545 [1:37:12<6:54:08,  7.63s/it]                                                       {'loss': 0.2083, 'grad_norm': 30.344242095947266, 'learning_rate': 3.4055482166446495e-06, 'rewards/chosen': 0.4716796875, 'rewards/rejected': -16.674999237060547, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 17.118749618530273, 'logps/chosen': -343.6499938964844, 'logps/rejected': -339.3999938964844, 'logits/chosen': -9.625, 'logits/rejected': -9.212499618530273, 'epoch': 0.85}
 28%|██▊       | 1290/4545 [1:37:12<6:54:08,  7.63s/it] 28%|██▊       | 1291/4545 [1:37:20<7:00:41,  7.76s/it] 28%|██▊       | 1292/4545 [1:37:27<6:52:45,  7.61s/it] 28%|██▊       | 1293/4545 [1:37:35<6:51:50,  7.60s/it] 28%|██▊       | 1294/4545 [1:37:42<6:52:48,  7.62s/it] 28%|██▊       | 1295/4545 [1:37:50<6:50:23,  7.58s/it] 29%|██▊       | 1296/4545 [1:37:57<6:40:58,  7.41s/it] 29%|██▊       | 1297/4545 [1:38:04<6:31:31,  7.23s/it] 29%|██▊       | 1298/4545 [1:38:11<6:35:03,  7.30s/it] 29%|██▊       | 1299/4545 [1:38:17<6:16:05,  6.95s/it] 29%|██▊       | 1300/4545 [1:38:25<6:30:00,  7.21s/it]                                                       {'loss': 0.259, 'grad_norm': 14.84942626953125, 'learning_rate': 3.4319682959048876e-06, 'rewards/chosen': -0.6070312261581421, 'rewards/rejected': -17.15625, 'rewards/accuracies': 0.90625, 'rewards/margins': 16.546875, 'logps/chosen': -240.89999389648438, 'logps/rejected': -260.0, 'logits/chosen': -9.993749618530273, 'logits/rejected': -9.568750381469727, 'epoch': 0.86}
 29%|██▊       | 1300/4545 [1:38:25<6:30:00,  7.21s/it] 29%|██▊       | 1301/4545 [1:38:33<6:46:15,  7.51s/it] 29%|██▊       | 1302/4545 [1:38:41<6:46:14,  7.52s/it] 29%|██▊       | 1303/4545 [1:38:48<6:37:03,  7.35s/it] 29%|██▊       | 1304/4545 [1:38:55<6:30:34,  7.23s/it] 29%|██▊       | 1305/4545 [1:38:59<5:37:03,  6.24s/it] 29%|██▊       | 1306/4545 [1:39:02<4:57:11,  5.51s/it] 29%|██▉       | 1307/4545 [1:39:06<4:34:53,  5.09s/it] 29%|██▉       | 1308/4545 [1:39:09<3:55:01,  4.36s/it] 29%|██▉       | 1309/4545 [1:39:12<3:37:21,  4.03s/it] 29%|██▉       | 1310/4545 [1:39:15<3:19:21,  3.70s/it]                                                       {'loss': 0.1971, 'grad_norm': 10.111627578735352, 'learning_rate': 3.4583883751651253e-06, 'rewards/chosen': 0.25800782442092896, 'rewards/rejected': -13.71875, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 13.965624809265137, 'logps/chosen': -227.5500030517578, 'logps/rejected': -265.75, 'logits/chosen': -9.899999618530273, 'logits/rejected': -9.387499809265137, 'epoch': 0.86}
 29%|██▉       | 1310/4545 [1:39:15<3:19:21,  3.70s/it] 29%|██▉       | 1311/4545 [1:39:19<3:24:28,  3.79s/it] 29%|██▉       | 1312/4545 [1:39:23<3:24:11,  3.79s/it] 29%|██▉       | 1313/4545 [1:39:26<3:07:22,  3.48s/it] 29%|██▉       | 1314/4545 [1:39:30<3:17:08,  3.66s/it] 29%|██▉       | 1315/4545 [1:39:33<3:15:50,  3.64s/it] 29%|██▉       | 1316/4545 [1:39:37<3:15:56,  3.64s/it] 29%|██▉       | 1317/4545 [1:39:41<3:23:39,  3.79s/it] 29%|██▉       | 1318/4545 [1:39:45<3:28:40,  3.88s/it] 29%|██▉       | 1319/4545 [1:39:49<3:28:30,  3.88s/it] 29%|██▉       | 1320/4545 [1:39:53<3:22:34,  3.77s/it]                                                       {'loss': 0.3406, 'grad_norm': 15.121504783630371, 'learning_rate': 3.484808454425363e-06, 'rewards/chosen': 0.02500000037252903, 'rewards/rejected': -14.353124618530273, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 14.418749809265137, 'logps/chosen': -245.64999389648438, 'logps/rejected': -288.1000061035156, 'logits/chosen': -9.518750190734863, 'logits/rejected': -9.081250190734863, 'epoch': 0.87}
 29%|██▉       | 1320/4545 [1:39:53<3:22:34,  3.77s/it] 29%|██▉       | 1321/4545 [1:39:57<3:26:17,  3.84s/it] 29%|██▉       | 1322/4545 [1:40:01<3:31:11,  3.93s/it] 29%|██▉       | 1323/4545 [1:40:04<3:21:56,  3.76s/it] 29%|██▉       | 1324/4545 [1:40:08<3:18:39,  3.70s/it] 29%|██▉       | 1325/4545 [1:40:11<3:17:19,  3.68s/it] 29%|██▉       | 1326/4545 [1:40:15<3:21:21,  3.75s/it] 29%|██▉       | 1327/4545 [1:40:19<3:14:33,  3.63s/it] 29%|██▉       | 1328/4545 [1:40:23<3:20:55,  3.75s/it] 29%|██▉       | 1329/4545 [1:40:27<3:24:47,  3.82s/it] 29%|██▉       | 1330/4545 [1:40:29<2:58:37,  3.33s/it]                                                       {'loss': 0.238, 'grad_norm': 10.291348457336426, 'learning_rate': 3.5112285336856008e-06, 'rewards/chosen': -0.57421875, 'rewards/rejected': -11.106249809265137, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 10.534375190734863, 'logps/chosen': -192.3000030517578, 'logps/rejected': -240.60000610351562, 'logits/chosen': -9.681249618530273, 'logits/rejected': -9.331250190734863, 'epoch': 0.88}
 29%|██▉       | 1330/4545 [1:40:29<2:58:37,  3.33s/it] 29%|██▉       | 1331/4545 [1:40:33<3:12:11,  3.59s/it] 29%|██▉       | 1332/4545 [1:40:37<3:15:23,  3.65s/it] 29%|██▉       | 1333/4545 [1:40:41<3:20:38,  3.75s/it] 29%|██▉       | 1334/4545 [1:40:45<3:23:42,  3.81s/it] 29%|██▉       | 1335/4545 [1:40:49<3:25:37,  3.84s/it] 29%|██▉       | 1336/4545 [1:40:53<3:28:15,  3.89s/it] 29%|██▉       | 1337/4545 [1:40:57<3:32:22,  3.97s/it] 29%|██▉       | 1338/4545 [1:41:01<3:26:20,  3.86s/it] 29%|██▉       | 1339/4545 [1:41:04<3:27:47,  3.89s/it] 29%|██▉       | 1340/4545 [1:41:08<3:28:46,  3.91s/it]                                                       {'loss': 0.1823, 'grad_norm': 26.47826385498047, 'learning_rate': 3.537648612945839e-06, 'rewards/chosen': 0.772167980670929, 'rewards/rejected': -24.053125381469727, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 24.8125, 'logps/chosen': -406.3999938964844, 'logps/rejected': -437.20001220703125, 'logits/chosen': -9.15625, 'logits/rejected': -8.931249618530273, 'epoch': 0.88}
 29%|██▉       | 1340/4545 [1:41:09<3:28:46,  3.91s/it] 30%|██▉       | 1341/4545 [1:41:12<3:18:38,  3.72s/it] 30%|██▉       | 1342/4545 [1:41:15<3:10:43,  3.57s/it] 30%|██▉       | 1343/4545 [1:41:19<3:10:59,  3.58s/it] 30%|██▉       | 1344/4545 [1:41:23<3:21:58,  3.79s/it] 30%|██▉       | 1345/4545 [1:41:27<3:23:14,  3.81s/it] 30%|██▉       | 1346/4545 [1:41:31<3:28:08,  3.90s/it] 30%|██▉       | 1347/4545 [1:41:35<3:28:52,  3.92s/it] 30%|██▉       | 1348/4545 [1:41:39<3:29:10,  3.93s/it] 30%|██▉       | 1349/4545 [1:41:43<3:29:44,  3.94s/it] 30%|██▉       | 1350/4545 [1:41:47<3:29:38,  3.94s/it]                                                       {'loss': 0.2401, 'grad_norm': 6.830395221710205, 'learning_rate': 3.5640686922060766e-06, 'rewards/chosen': 0.970898449420929, 'rewards/rejected': -15.168749809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 16.131250381469727, 'logps/chosen': -382.25, 'logps/rejected': -360.1000061035156, 'logits/chosen': -9.612500190734863, 'logits/rejected': -9.331250190734863, 'epoch': 0.89}
 30%|██▉       | 1350/4545 [1:41:47<3:29:38,  3.94s/it] 30%|██▉       | 1351/4545 [1:41:51<3:35:39,  4.05s/it] 30%|██▉       | 1352/4545 [1:41:53<3:11:15,  3.59s/it] 30%|██▉       | 1353/4545 [1:41:57<3:06:15,  3.50s/it] 30%|██▉       | 1354/4545 [1:42:01<3:17:16,  3.71s/it] 30%|██▉       | 1355/4545 [1:42:05<3:21:23,  3.79s/it] 30%|██▉       | 1356/4545 [1:42:09<3:20:07,  3.77s/it] 30%|██▉       | 1357/4545 [1:42:13<3:27:00,  3.90s/it] 30%|██▉       | 1358/4545 [1:42:16<3:19:43,  3.76s/it] 30%|██▉       | 1359/4545 [1:42:20<3:22:41,  3.82s/it] 30%|██▉       | 1360/4545 [1:42:24<3:27:01,  3.90s/it]                                                       {'loss': 0.1903, 'grad_norm': 7.503037452697754, 'learning_rate': 3.5904887714663143e-06, 'rewards/chosen': 1.092187523841858, 'rewards/rejected': -14.743749618530273, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 15.839062690734863, 'logps/chosen': -358.1000061035156, 'logps/rejected': -341.5, 'logits/chosen': -9.543749809265137, 'logits/rejected': -9.175000190734863, 'epoch': 0.9}
 30%|██▉       | 1360/4545 [1:42:24<3:27:01,  3.90s/it] 30%|██▉       | 1361/4545 [1:42:28<3:28:56,  3.94s/it] 30%|██▉       | 1362/4545 [1:42:31<3:06:34,  3.52s/it] 30%|██▉       | 1363/4545 [1:42:35<3:13:26,  3.65s/it] 30%|███       | 1364/4545 [1:42:39<3:21:12,  3.80s/it] 30%|███       | 1365/4545 [1:42:43<3:23:20,  3.84s/it] 30%|███       | 1366/4545 [1:42:47<3:26:29,  3.90s/it] 30%|███       | 1367/4545 [1:42:50<3:13:23,  3.65s/it] 30%|███       | 1368/4545 [1:42:54<3:14:32,  3.67s/it] 30%|███       | 1369/4545 [1:42:58<3:17:51,  3.74s/it] 30%|███       | 1370/4545 [1:43:02<3:20:40,  3.79s/it]                                                       {'loss': 0.2294, 'grad_norm': 23.432048797607422, 'learning_rate': 3.616908850726552e-06, 'rewards/chosen': 0.4032226502895355, 'rewards/rejected': -11.037500381469727, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 11.449999809265137, 'logps/chosen': -227.89999389648438, 'logps/rejected': -231.3000030517578, 'logits/chosen': -9.912500381469727, 'logits/rejected': -9.512499809265137, 'epoch': 0.9}
 30%|███       | 1370/4545 [1:43:02<3:20:40,  3.79s/it] 30%|███       | 1371/4545 [1:43:06<3:24:20,  3.86s/it] 30%|███       | 1372/4545 [1:43:09<3:17:34,  3.74s/it] 30%|███       | 1373/4545 [1:43:13<3:25:14,  3.88s/it] 30%|███       | 1374/4545 [1:43:16<3:02:55,  3.46s/it] 30%|███       | 1375/4545 [1:43:20<3:10:28,  3.61s/it] 30%|███       | 1376/4545 [1:43:23<3:00:45,  3.42s/it] 30%|███       | 1377/4545 [1:43:26<2:59:28,  3.40s/it] 30%|███       | 1378/4545 [1:43:30<3:02:30,  3.46s/it] 30%|███       | 1379/4545 [1:43:33<3:10:07,  3.60s/it] 30%|███       | 1380/4545 [1:43:37<3:15:06,  3.70s/it]                                                       {'loss': 0.1637, 'grad_norm': 3.4906911849975586, 'learning_rate': 3.64332892998679e-06, 'rewards/chosen': 0.8900390863418579, 'rewards/rejected': -15.5, 'rewards/accuracies': 0.9375, 'rewards/margins': 16.381250381469727, 'logps/chosen': -279.6499938964844, 'logps/rejected': -265.45001220703125, 'logits/chosen': -9.993749618530273, 'logits/rejected': -9.5, 'epoch': 0.91}
 30%|███       | 1380/4545 [1:43:38<3:15:06,  3.70s/it] 30%|███       | 1381/4545 [1:43:41<3:20:16,  3.80s/it] 30%|███       | 1382/4545 [1:43:45<3:17:34,  3.75s/it] 30%|███       | 1383/4545 [1:43:49<3:20:40,  3.81s/it] 30%|███       | 1384/4545 [1:43:53<3:23:34,  3.86s/it] 30%|███       | 1385/4545 [1:43:57<3:24:38,  3.89s/it] 30%|███       | 1386/4545 [1:44:01<3:28:49,  3.97s/it] 31%|███       | 1387/4545 [1:44:05<3:28:28,  3.96s/it] 31%|███       | 1388/4545 [1:44:09<3:27:17,  3.94s/it] 31%|███       | 1389/4545 [1:44:13<3:28:00,  3.95s/it] 31%|███       | 1390/4545 [1:44:17<3:27:49,  3.95s/it]                                                       {'loss': 0.2102, 'grad_norm': 20.152727127075195, 'learning_rate': 3.669749009247028e-06, 'rewards/chosen': 1.737890601158142, 'rewards/rejected': -13.25, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 14.981249809265137, 'logps/chosen': -453.70001220703125, 'logps/rejected': -378.0, 'logits/chosen': -9.850000381469727, 'logits/rejected': -9.537500381469727, 'epoch': 0.92}
 31%|███       | 1390/4545 [1:44:17<3:27:49,  3.95s/it] 31%|███       | 1391/4545 [1:44:21<3:28:52,  3.97s/it] 31%|███       | 1392/4545 [1:44:25<3:27:03,  3.94s/it] 31%|███       | 1393/4545 [1:44:29<3:26:40,  3.93s/it] 31%|███       | 1394/4545 [1:44:33<3:24:47,  3.90s/it] 31%|███       | 1395/4545 [1:44:36<3:23:30,  3.88s/it] 31%|███       | 1396/4545 [1:44:40<3:24:30,  3.90s/it] 31%|███       | 1397/4545 [1:44:44<3:28:19,  3.97s/it] 31%|███       | 1398/4545 [1:44:49<3:30:00,  4.00s/it] 31%|███       | 1399/4545 [1:44:52<3:25:58,  3.93s/it] 31%|███       | 1400/4545 [1:44:56<3:29:53,  4.00s/it]                                                       {'loss': 0.2467, 'grad_norm': 20.097524642944336, 'learning_rate': 3.696169088507265e-06, 'rewards/chosen': -0.8031250238418579, 'rewards/rejected': -18.212499618530273, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 17.421875, 'logps/chosen': -249.25, 'logps/rejected': -292.8999938964844, 'logits/chosen': -10.199999809265137, 'logits/rejected': -9.706250190734863, 'epoch': 0.92}
 31%|███       | 1400/4545 [1:44:57<3:29:53,  4.00s/it] 31%|███       | 1401/4545 [1:45:00<3:24:52,  3.91s/it] 31%|███       | 1402/4545 [1:45:04<3:25:03,  3.91s/it] 31%|███       | 1403/4545 [1:45:08<3:18:43,  3.79s/it] 31%|███       | 1404/4545 [1:45:11<3:20:29,  3.83s/it] 31%|███       | 1405/4545 [1:45:15<3:21:54,  3.86s/it] 31%|███       | 1406/4545 [1:45:20<3:27:51,  3.97s/it] 31%|███       | 1407/4545 [1:45:23<3:23:24,  3.89s/it] 31%|███       | 1408/4545 [1:45:27<3:23:43,  3.90s/it] 31%|███       | 1409/4545 [1:45:31<3:17:44,  3.78s/it] 31%|███       | 1410/4545 [1:45:34<3:10:07,  3.64s/it]                                                       {'loss': 0.1072, 'grad_norm': 7.412668228149414, 'learning_rate': 3.722589167767503e-06, 'rewards/chosen': -1.4484374523162842, 'rewards/rejected': -23.106250762939453, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 21.65625, 'logps/chosen': -198.14999389648438, 'logps/rejected': -319.6000061035156, 'logits/chosen': -9.975000381469727, 'logits/rejected': -9.431249618530273, 'epoch': 0.93}
 31%|███       | 1410/4545 [1:45:34<3:10:07,  3.64s/it] 31%|███       | 1411/4545 [1:45:38<3:07:48,  3.60s/it] 31%|███       | 1412/4545 [1:45:42<3:13:44,  3.71s/it] 31%|███       | 1413/4545 [1:45:45<3:09:47,  3.64s/it] 31%|███       | 1414/4545 [1:45:48<3:04:48,  3.54s/it] 31%|███       | 1415/4545 [1:45:52<3:10:38,  3.65s/it] 31%|███       | 1416/4545 [1:45:56<3:16:52,  3.78s/it] 31%|███       | 1417/4545 [1:46:00<3:10:18,  3.65s/it] 31%|███       | 1418/4545 [1:46:03<3:01:59,  3.49s/it] 31%|███       | 1419/4545 [1:46:07<3:08:53,  3.63s/it] 31%|███       | 1420/4545 [1:46:09<2:52:13,  3.31s/it]                                                       {'loss': 0.2494, 'grad_norm': 26.412649154663086, 'learning_rate': 3.749009247027741e-06, 'rewards/chosen': -0.20390625298023224, 'rewards/rejected': -15.162500381469727, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 14.962499618530273, 'logps/chosen': -240.5, 'logps/rejected': -293.20001220703125, 'logits/chosen': -10.137499809265137, 'logits/rejected': -9.59375, 'epoch': 0.94}
 31%|███       | 1420/4545 [1:46:09<2:52:13,  3.31s/it] 31%|███▏      | 1421/4545 [1:46:13<3:02:54,  3.51s/it] 31%|███▏      | 1422/4545 [1:46:17<3:08:06,  3.61s/it] 31%|███▏      | 1423/4545 [1:46:21<3:09:45,  3.65s/it] 31%|███▏      | 1424/4545 [1:46:25<3:15:09,  3.75s/it] 31%|███▏      | 1425/4545 [1:46:28<3:05:59,  3.58s/it] 31%|███▏      | 1426/4545 [1:46:32<3:11:37,  3.69s/it] 31%|███▏      | 1427/4545 [1:46:36<3:14:28,  3.74s/it] 31%|███▏      | 1428/4545 [1:46:40<3:17:52,  3.81s/it] 31%|███▏      | 1429/4545 [1:46:43<3:03:15,  3.53s/it] 31%|███▏      | 1430/4545 [1:46:45<2:51:31,  3.30s/it]                                                       {'loss': 0.1961, 'grad_norm': 13.753715515136719, 'learning_rate': 3.7754293262879787e-06, 'rewards/chosen': 0.014843749813735485, 'rewards/rejected': -10.668749809265137, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 10.6875, 'logps/chosen': -211.4499969482422, 'logps/rejected': -263.8999938964844, 'logits/chosen': -10.199999809265137, 'logits/rejected': -9.668749809265137, 'epoch': 0.94}
 31%|███▏      | 1430/4545 [1:46:46<2:51:31,  3.30s/it] 31%|███▏      | 1431/4545 [1:46:50<3:03:14,  3.53s/it] 32%|███▏      | 1432/4545 [1:46:53<3:09:37,  3.65s/it] 32%|███▏      | 1433/4545 [1:46:57<3:14:10,  3.74s/it] 32%|███▏      | 1434/4545 [1:47:01<3:16:58,  3.80s/it] 32%|███▏      | 1435/4545 [1:47:06<3:23:52,  3.93s/it] 32%|███▏      | 1436/4545 [1:47:10<3:23:36,  3.93s/it] 32%|███▏      | 1437/4545 [1:47:13<3:24:30,  3.95s/it] 32%|███▏      | 1438/4545 [1:47:17<3:23:09,  3.92s/it] 32%|███▏      | 1439/4545 [1:47:22<3:26:46,  3.99s/it] 32%|███▏      | 1440/4545 [1:47:24<3:08:02,  3.63s/it]                                                       {'loss': 0.2252, 'grad_norm': 22.17677879333496, 'learning_rate': 3.8018494055482164e-06, 'rewards/chosen': 1.197265625, 'rewards/rejected': -9.731249809265137, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.9375, 'logps/chosen': -284.5, 'logps/rejected': -246.64999389648438, 'logits/chosen': -10.618749618530273, 'logits/rejected': -10.243749618530273, 'epoch': 0.95}
 32%|███▏      | 1440/4545 [1:47:25<3:08:02,  3.63s/it] 32%|███▏      | 1441/4545 [1:47:28<3:07:38,  3.63s/it] 32%|███▏      | 1442/4545 [1:47:32<3:13:21,  3.74s/it] 32%|███▏      | 1443/4545 [1:47:36<3:17:27,  3.82s/it] 32%|███▏      | 1444/4545 [1:47:40<3:20:39,  3.88s/it] 32%|███▏      | 1445/4545 [1:47:44<3:15:22,  3.78s/it] 32%|███▏      | 1446/4545 [1:47:47<3:08:56,  3.66s/it] 32%|███▏      | 1447/4545 [1:47:49<2:44:40,  3.19s/it] 32%|███▏      | 1448/4545 [1:47:53<2:56:19,  3.42s/it] 32%|███▏      | 1449/4545 [1:47:56<2:52:11,  3.34s/it] 32%|███▏      | 1450/4545 [1:48:00<3:02:29,  3.54s/it]                                                       {'loss': 0.2525, 'grad_norm': 5.146316051483154, 'learning_rate': 3.828269484808454e-06, 'rewards/chosen': 1.825781226158142, 'rewards/rejected': -13.657031059265137, 'rewards/accuracies': 0.875, 'rewards/margins': 15.471875190734863, 'logps/chosen': -297.3999938964844, 'logps/rejected': -318.29998779296875, 'logits/chosen': -10.381250381469727, 'logits/rejected': -9.875, 'epoch': 0.96}
 32%|███▏      | 1450/4545 [1:48:00<3:02:29,  3.54s/it] 32%|███▏      | 1451/4545 [1:48:03<2:45:32,  3.21s/it] 32%|███▏      | 1452/4545 [1:48:05<2:32:52,  2.97s/it] 32%|███▏      | 1453/4545 [1:48:08<2:36:23,  3.03s/it] 32%|███▏      | 1454/4545 [1:48:12<2:46:58,  3.24s/it] 32%|███▏      | 1455/4545 [1:48:16<2:58:57,  3.47s/it] 32%|███▏      | 1456/4545 [1:48:19<2:57:06,  3.44s/it] 32%|███▏      | 1457/4545 [1:48:23<3:04:36,  3.59s/it] 32%|███▏      | 1458/4545 [1:48:26<2:58:13,  3.46s/it] 32%|███▏      | 1459/4545 [1:48:30<3:05:26,  3.61s/it] 32%|███▏      | 1460/4545 [1:48:34<3:10:28,  3.70s/it]                                                       {'loss': 0.2889, 'grad_norm': 17.98870849609375, 'learning_rate': 3.854689564068692e-06, 'rewards/chosen': 0.82421875, 'rewards/rejected': -14.787500381469727, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 15.618749618530273, 'logps/chosen': -242.85000610351562, 'logps/rejected': -298.8999938964844, 'logits/chosen': -10.21875, 'logits/rejected': -9.793749809265137, 'epoch': 0.96}
 32%|███▏      | 1460/4545 [1:48:34<3:10:28,  3.70s/it] 32%|███▏      | 1461/4545 [1:48:38<3:15:33,  3.80s/it] 32%|███▏      | 1462/4545 [1:48:42<3:14:00,  3.78s/it] 32%|███▏      | 1463/4545 [1:48:46<3:14:21,  3.78s/it] 32%|███▏      | 1464/4545 [1:48:50<3:16:55,  3.83s/it] 32%|███▏      | 1465/4545 [1:48:53<3:14:42,  3.79s/it] 32%|███▏      | 1466/4545 [1:48:57<3:14:05,  3.78s/it] 32%|███▏      | 1467/4545 [1:49:01<3:16:28,  3.83s/it] 32%|███▏      | 1468/4545 [1:49:05<3:22:45,  3.95s/it] 32%|███▏      | 1469/4545 [1:49:09<3:19:45,  3.90s/it] 32%|███▏      | 1470/4545 [1:49:13<3:19:54,  3.90s/it]                                                       {'loss': 0.2556, 'grad_norm': 18.456789016723633, 'learning_rate': 3.8811096433289295e-06, 'rewards/chosen': 0.181640625, 'rewards/rejected': -13.309374809265137, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 13.490625381469727, 'logps/chosen': -208.60000610351562, 'logps/rejected': -266.29998779296875, 'logits/chosen': -10.100000381469727, 'logits/rejected': -9.693750381469727, 'epoch': 0.97}
 32%|███▏      | 1470/4545 [1:49:13<3:19:54,  3.90s/it] 32%|███▏      | 1471/4545 [1:49:17<3:23:53,  3.98s/it] 32%|███▏      | 1472/4545 [1:49:21<3:28:30,  4.07s/it] 32%|███▏      | 1473/4545 [1:49:25<3:18:48,  3.88s/it] 32%|███▏      | 1474/4545 [1:49:28<3:09:13,  3.70s/it] 32%|███▏      | 1475/4545 [1:49:32<3:07:48,  3.67s/it] 32%|███▏      | 1476/4545 [1:49:36<3:13:59,  3.79s/it] 32%|███▏      | 1477/4545 [1:49:40<3:17:19,  3.86s/it] 33%|███▎      | 1478/4545 [1:49:43<3:06:26,  3.65s/it] 33%|███▎      | 1479/4545 [1:49:47<3:10:47,  3.73s/it] 33%|███▎      | 1480/4545 [1:49:51<3:16:51,  3.85s/it]                                                       {'loss': 0.2505, 'grad_norm': 15.736326217651367, 'learning_rate': 3.907529722589168e-06, 'rewards/chosen': 2.34765625, 'rewards/rejected': -14.175000190734863, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 16.493749618530273, 'logps/chosen': -371.6000061035156, 'logps/rejected': -325.1000061035156, 'logits/chosen': -9.600000381469727, 'logits/rejected': -9.293749809265137, 'epoch': 0.98}
 33%|███▎      | 1480/4545 [1:49:51<3:16:51,  3.85s/it] 33%|███▎      | 1481/4545 [1:49:55<3:19:30,  3.91s/it] 33%|███▎      | 1482/4545 [1:49:57<2:56:09,  3.45s/it] 33%|███▎      | 1483/4545 [1:50:01<3:03:55,  3.60s/it] 33%|███▎      | 1484/4545 [1:50:06<3:13:38,  3.80s/it] 33%|███▎      | 1485/4545 [1:50:10<3:15:38,  3.84s/it] 33%|███▎      | 1486/4545 [1:50:14<3:16:57,  3.86s/it] 33%|███▎      | 1487/4545 [1:50:17<3:15:08,  3.83s/it] 33%|███▎      | 1488/4545 [1:50:21<3:09:08,  3.71s/it] 33%|███▎      | 1489/4545 [1:50:25<3:14:36,  3.82s/it] 33%|███▎      | 1490/4545 [1:50:29<3:19:38,  3.92s/it]                                                       {'loss': 0.2608, 'grad_norm': 38.063140869140625, 'learning_rate': 3.933949801849406e-06, 'rewards/chosen': 1.8933594226837158, 'rewards/rejected': -11.662500381469727, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 13.537500381469727, 'logps/chosen': -281.1000061035156, 'logps/rejected': -254.39999389648438, 'logits/chosen': -9.268750190734863, 'logits/rejected': -8.981249809265137, 'epoch': 0.98}
 33%|███▎      | 1490/4545 [1:50:29<3:19:38,  3.92s/it] 33%|███▎      | 1491/4545 [1:50:33<3:20:56,  3.95s/it] 33%|███▎      | 1492/4545 [1:50:37<3:25:15,  4.03s/it] 33%|███▎      | 1493/4545 [1:50:40<3:04:00,  3.62s/it] 33%|███▎      | 1494/4545 [1:50:43<3:00:10,  3.54s/it] 33%|███▎      | 1495/4545 [1:50:47<3:04:50,  3.64s/it] 33%|███▎      | 1496/4545 [1:50:50<3:00:48,  3.56s/it] 33%|███▎      | 1497/4545 [1:50:54<3:06:19,  3.67s/it] 33%|███▎      | 1498/4545 [1:50:57<2:56:45,  3.48s/it] 33%|███▎      | 1499/4545 [1:51:02<3:08:44,  3.72s/it] 33%|███▎      | 1500/4545 [1:51:06<3:16:39,  3.88s/it]                                                       {'loss': 0.2376, 'grad_norm': 7.910409450531006, 'learning_rate': 3.960369881109643e-06, 'rewards/chosen': 0.45039063692092896, 'rewards/rejected': -14.806249618530273, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 15.256250381469727, 'logps/chosen': -229.0, 'logps/rejected': -249.0, 'logits/chosen': -9.421875, 'logits/rejected': -8.959375381469727, 'epoch': 0.99}
 33%|███▎      | 1500/4545 [1:51:06<3:16:39,  3.88s/it] 33%|███▎      | 1501/4545 [1:51:10<3:20:21,  3.95s/it] 33%|███▎      | 1502/4545 [1:51:14<3:20:04,  3.95s/it] 33%|███▎      | 1503/4545 [1:51:18<3:14:39,  3.84s/it] 33%|███▎      | 1504/4545 [1:51:22<3:16:23,  3.87s/it] 33%|███▎      | 1505/4545 [1:51:26<3:17:51,  3.91s/it] 33%|███▎      | 1506/4545 [1:51:29<3:16:20,  3.88s/it] 33%|███▎      | 1507/4545 [1:51:33<3:09:20,  3.74s/it] 33%|███▎      | 1508/4545 [1:51:36<2:57:35,  3.51s/it] 33%|███▎      | 1509/4545 [1:51:40<3:04:19,  3.64s/it] 33%|███▎      | 1510/4545 [1:51:44<3:12:25,  3.80s/it]                                                       {'loss': 0.2075, 'grad_norm': 19.763031005859375, 'learning_rate': 3.986789960369881e-06, 'rewards/chosen': 3.539257764816284, 'rewards/rejected': -8.407812118530273, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 11.962499618530273, 'logps/chosen': -378.95001220703125, 'logps/rejected': -273.6000061035156, 'logits/chosen': -9.362500190734863, 'logits/rejected': -9.175000190734863, 'epoch': 1.0}
 33%|███▎      | 1510/4545 [1:51:44<3:12:25,  3.80s/it] 33%|███▎      | 1511/4545 [1:51:48<3:14:46,  3.85s/it] 33%|███▎      | 1512/4545 [1:51:52<3:15:49,  3.87s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:44,  1.31it/s][A
  5%|▌         | 3/60 [00:03<01:02,  1.10s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:16,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.53s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:18,  1.64s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:14,  1.63s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.52s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.38s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.29s/it][A
 30%|███       | 18/60 [00:51<06:12,  8.86s/it][A
 32%|███▏      | 19/60 [00:52<04:29,  6.58s/it][A
 33%|███▎      | 20/60 [00:53<03:12,  4.80s/it][A
 35%|███▌      | 21/60 [00:54<02:22,  3.66s/it][A
 37%|███▋      | 22/60 [00:55<01:52,  2.95s/it][A
 38%|███▊      | 23/60 [00:56<01:29,  2.41s/it][A
 40%|████      | 24/60 [00:57<01:12,  2.03s/it][A
 42%|████▏     | 25/60 [00:59<01:06,  1.91s/it][A
 43%|████▎     | 26/60 [01:00<01:00,  1.77s/it][A
 45%|████▌     | 27/60 [01:01<00:48,  1.47s/it][A
 47%|████▋     | 28/60 [01:02<00:41,  1.31s/it][A
 48%|████▊     | 29/60 [01:03<00:39,  1.28s/it][A
 50%|█████     | 30/60 [01:05<00:41,  1.39s/it][A
 52%|█████▏    | 31/60 [01:06<00:41,  1.44s/it][A
 53%|█████▎    | 32/60 [01:08<00:40,  1.44s/it][A
 55%|█████▌    | 33/60 [01:35<04:05,  9.08s/it][A
 57%|█████▋    | 34/60 [01:36<02:51,  6.60s/it][A
 58%|█████▊    | 35/60 [01:37<02:06,  5.06s/it][A
 60%|██████    | 36/60 [01:38<01:35,  3.97s/it][A
 62%|██████▏   | 37/60 [01:39<01:08,  2.97s/it][A
 63%|██████▎   | 38/60 [02:06<03:43, 10.14s/it][A
 65%|██████▌   | 39/60 [02:07<02:36,  7.44s/it][A
 67%|██████▋   | 40/60 [02:08<01:48,  5.45s/it][A
 68%|██████▊   | 41/60 [02:09<01:20,  4.25s/it][A
 70%|███████   | 42/60 [02:11<01:02,  3.44s/it][A
 72%|███████▏  | 43/60 [02:12<00:45,  2.70s/it][A
 73%|███████▎  | 44/60 [02:13<00:37,  2.33s/it][A
 75%|███████▌  | 45/60 [02:14<00:28,  1.87s/it][A
 77%|███████▋  | 46/60 [02:16<00:24,  1.78s/it][A
 78%|███████▊  | 47/60 [02:17<00:22,  1.76s/it][A
 80%|████████  | 48/60 [02:18<00:17,  1.47s/it][A
 82%|████████▏ | 49/60 [02:20<00:16,  1.50s/it][A
 83%|████████▎ | 50/60 [02:22<00:15,  1.56s/it][A
 85%|████████▌ | 51/60 [02:23<00:14,  1.56s/it][A
 87%|████████▋ | 52/60 [02:24<00:11,  1.47s/it][A
 88%|████████▊ | 53/60 [02:25<00:09,  1.36s/it][A
 90%|█████████ | 54/60 [02:27<00:08,  1.42s/it][A
 92%|█████████▏| 55/60 [02:28<00:06,  1.22s/it][A
 93%|█████████▎| 56/60 [02:29<00:05,  1.37s/it][A
 95%|█████████▌| 57/60 [02:31<00:04,  1.43s/it][A
 97%|█████████▋| 58/60 [02:32<00:02,  1.43s/it][A
 98%|█████████▊| 59/60 [02:34<00:01,  1.48s/it][A
100%|██████████| 60/60 [02:36<00:00,  1.53s/it][A                                                       
                                               [A{'eval_loss': 0.28410810232162476, 'eval_runtime': 157.8317, 'eval_samples_per_second': 6.038, 'eval_steps_per_second': 0.38, 'eval_rewards/chosen': 2.200284719467163, 'eval_rewards/rejected': -12.809306144714355, 'eval_rewards/accuracies': 0.8777778148651123, 'eval_rewards/margins': 15.027083396911621, 'eval_logps/chosen': -355.9083251953125, 'eval_logps/rejected': -280.2250061035156, 'eval_logits/chosen': -9.34375, 'eval_logits/rejected': -9.340104103088379, 'epoch': 1.0}
 33%|███▎      | 1512/4545 [1:54:30<3:15:49,  3.87s/it]
100%|██████████| 60/60 [02:37<00:00,  1.53s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 33%|███▎      | 1513/4545 [1:54:47<46:38:07, 55.37s/it] 33%|███▎      | 1514/4545 [1:54:52<33:43:31, 40.06s/it] 33%|███▎      | 1515/4545 [1:54:56<24:35:35, 29.22s/it] 33%|███▎      | 1516/4545 [1:54:59<18:12:19, 21.64s/it] 33%|███▎      | 1517/4545 [1:55:02<13:29:39, 16.04s/it] 33%|███▎      | 1518/4545 [1:55:06<10:21:14, 12.31s/it] 33%|███▎      | 1519/4545 [1:55:10<8:14:17,  9.80s/it]  33%|███▎      | 1520/4545 [1:55:14<6:48:13,  8.10s/it]                                                       {'loss': 0.1872, 'grad_norm': 6.7260332107543945, 'learning_rate': 3.999975828176259e-06, 'rewards/chosen': 6.466796875, 'rewards/rejected': -13.645312309265137, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 20.121875762939453, 'logps/chosen': -537.7999877929688, 'logps/rejected': -332.29998779296875, 'logits/chosen': -9.109375, 'logits/rejected': -8.943750381469727, 'epoch': 1.0}
 33%|███▎      | 1520/4545 [1:55:14<6:48:13,  8.10s/it] 33%|███▎      | 1521/4545 [1:55:18<5:48:36,  6.92s/it] 33%|███▎      | 1522/4545 [1:55:22<5:03:34,  6.03s/it] 34%|███▎      | 1523/4545 [1:55:26<4:32:44,  5.42s/it] 34%|███▎      | 1524/4545 [1:55:30<4:10:07,  4.97s/it] 34%|███▎      | 1525/4545 [1:55:34<3:54:20,  4.66s/it] 34%|███▎      | 1526/4545 [1:55:38<3:43:14,  4.44s/it] 34%|███▎      | 1527/4545 [1:55:41<3:25:40,  4.09s/it] 34%|███▎      | 1528/4545 [1:55:45<3:23:14,  4.04s/it] 34%|███▎      | 1529/4545 [1:55:49<3:13:17,  3.85s/it] 34%|███▎      | 1530/4545 [1:55:51<2:58:29,  3.55s/it]                                                       {'loss': 0.1695, 'grad_norm': 15.941038131713867, 'learning_rate': 3.99978245748149e-06, 'rewards/chosen': 4.395312309265137, 'rewards/rejected': -20.662500381469727, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 25.037500381469727, 'logps/chosen': -429.70001220703125, 'logps/rejected': -402.5, 'logits/chosen': -9.481249809265137, 'logits/rejected': -9.0625, 'epoch': 1.01}
 34%|███▎      | 1530/4545 [1:55:52<2:58:29,  3.55s/it] 34%|███▎      | 1531/4545 [1:55:56<3:05:18,  3.69s/it] 34%|███▎      | 1532/4545 [1:55:59<2:59:22,  3.57s/it] 34%|███▎      | 1533/4545 [1:56:03<3:09:33,  3.78s/it] 34%|███▍      | 1534/4545 [1:56:07<3:11:53,  3.82s/it] 34%|███▍      | 1535/4545 [1:56:10<2:58:08,  3.55s/it] 34%|███▍      | 1536/4545 [1:56:12<2:37:52,  3.15s/it] 34%|███▍      | 1537/4545 [1:56:16<2:51:35,  3.42s/it] 34%|███▍      | 1538/4545 [1:56:19<2:48:12,  3.36s/it] 34%|███▍      | 1539/4545 [1:56:23<2:51:47,  3.43s/it] 34%|███▍      | 1540/4545 [1:56:27<2:59:14,  3.58s/it]                                                       {'loss': 0.0901, 'grad_norm': 13.244928359985352, 'learning_rate': 3.999395736865692e-06, 'rewards/chosen': 0.693359375, 'rewards/rejected': -24.959375381469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 25.625, 'logps/chosen': -259.3999938964844, 'logps/rejected': -400.5, 'logits/chosen': -10.237500190734863, 'logits/rejected': -9.881250381469727, 'epoch': 1.02}
 34%|███▍      | 1540/4545 [1:56:27<2:59:14,  3.58s/it] 34%|███▍      | 1541/4545 [1:56:31<3:05:13,  3.70s/it] 34%|███▍      | 1542/4545 [1:56:35<3:08:37,  3.77s/it] 34%|███▍      | 1543/4545 [1:56:38<3:03:32,  3.67s/it] 34%|███▍      | 1544/4545 [1:56:42<3:06:10,  3.72s/it] 34%|███▍      | 1545/4545 [1:56:46<3:09:35,  3.79s/it] 34%|███▍      | 1546/4545 [1:56:50<3:11:38,  3.83s/it] 34%|███▍      | 1547/4545 [1:56:54<3:13:12,  3.87s/it] 34%|███▍      | 1548/4545 [1:56:58<3:18:19,  3.97s/it] 34%|███▍      | 1549/4545 [1:57:02<3:15:49,  3.92s/it] 34%|███▍      | 1550/4545 [1:57:06<3:19:00,  3.99s/it]                                                       {'loss': 0.0736, 'grad_norm': 11.90914249420166, 'learning_rate': 3.998815707874108e-06, 'rewards/chosen': 1.928613305091858, 'rewards/rejected': -24.881250381469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 26.825000762939453, 'logps/chosen': -305.0, 'logps/rejected': -418.0, 'logits/chosen': -10.362500190734863, 'logits/rejected': -9.875, 'epoch': 1.02}
 34%|███▍      | 1550/4545 [1:57:06<3:19:00,  3.99s/it] 34%|███▍      | 1551/4545 [1:57:10<3:23:34,  4.08s/it] 34%|███▍      | 1552/4545 [1:57:14<3:14:40,  3.90s/it] 34%|███▍      | 1553/4545 [1:57:17<3:01:24,  3.64s/it] 34%|███▍      | 1554/4545 [1:57:21<3:05:59,  3.73s/it] 34%|███▍      | 1555/4545 [1:57:25<3:10:15,  3.82s/it] 34%|███▍      | 1556/4545 [1:57:29<3:11:49,  3.85s/it] 34%|███▍      | 1557/4545 [1:57:33<3:18:06,  3.98s/it] 34%|███▍      | 1558/4545 [1:57:35<2:48:54,  3.39s/it] 34%|███▍      | 1559/4545 [1:57:39<2:50:12,  3.42s/it] 34%|███▍      | 1560/4545 [1:57:42<2:54:51,  3.51s/it]                                                       {'loss': 0.0985, 'grad_norm': 1.6188616752624512, 'learning_rate': 3.998042432819023e-06, 'rewards/chosen': 2.3570313453674316, 'rewards/rejected': -27.790624618530273, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 30.112499237060547, 'logps/chosen': -346.04998779296875, 'logps/rejected': -472.5, 'logits/chosen': -10.262499809265137, 'logits/rejected': -9.90625, 'epoch': 1.03}
 34%|███▍      | 1560/4545 [1:57:42<2:54:51,  3.51s/it] 34%|███▍      | 1561/4545 [1:57:45<2:49:07,  3.40s/it] 34%|███▍      | 1562/4545 [1:57:50<3:01:19,  3.65s/it] 34%|███▍      | 1563/4545 [1:57:54<3:07:41,  3.78s/it] 34%|███▍      | 1564/4545 [1:57:56<2:50:28,  3.43s/it] 34%|███▍      | 1565/4545 [1:58:00<2:58:04,  3.59s/it] 34%|███▍      | 1566/4545 [1:58:04<3:03:55,  3.70s/it] 34%|███▍      | 1567/4545 [1:58:08<3:08:33,  3.80s/it] 34%|███▍      | 1568/4545 [1:58:12<3:11:10,  3.85s/it] 35%|███▍      | 1569/4545 [1:58:16<3:06:49,  3.77s/it] 35%|███▍      | 1570/4545 [1:58:19<2:54:00,  3.51s/it]                                                       {'loss': 0.1671, 'grad_norm': 24.52056121826172, 'learning_rate': 3.997075994773073e-06, 'rewards/chosen': 0.2914062440395355, 'rewards/rejected': -25.581249237060547, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 25.862499237060547, 'logps/chosen': -300.1000061035156, 'logps/rejected': -414.1000061035156, 'logits/chosen': -10.65625, 'logits/rejected': -10.199999809265137, 'epoch': 1.04}
 35%|███▍      | 1570/4545 [1:58:19<2:54:00,  3.51s/it] 35%|███▍      | 1571/4545 [1:58:23<2:58:13,  3.60s/it] 35%|███▍      | 1572/4545 [1:58:27<3:04:28,  3.72s/it] 35%|███▍      | 1573/4545 [1:58:31<3:09:43,  3.83s/it] 35%|███▍      | 1574/4545 [1:58:34<2:59:27,  3.62s/it] 35%|███▍      | 1575/4545 [1:58:37<2:50:58,  3.45s/it] 35%|███▍      | 1576/4545 [1:58:40<2:49:06,  3.42s/it] 35%|███▍      | 1577/4545 [1:58:43<2:47:05,  3.38s/it] 35%|███▍      | 1578/4545 [1:58:47<2:55:37,  3.55s/it] 35%|███▍      | 1579/4545 [1:58:51<2:51:20,  3.47s/it] 35%|███▍      | 1580/4545 [1:58:55<3:00:19,  3.65s/it]                                                       {'loss': 0.0736, 'grad_norm': 3.2935140132904053, 'learning_rate': 3.995916497560316e-06, 'rewards/chosen': -1.814062476158142, 'rewards/rejected': -31.8125, 'rewards/accuracies': 0.96875, 'rewards/margins': 29.975000381469727, 'logps/chosen': -210.5, 'logps/rejected': -411.3999938964844, 'logits/chosen': -11.324999809265137, 'logits/rejected': -10.806249618530273, 'epoch': 1.04}
 35%|███▍      | 1580/4545 [1:58:55<3:00:19,  3.65s/it] 35%|███▍      | 1581/4545 [1:58:58<2:49:33,  3.43s/it] 35%|███▍      | 1582/4545 [1:59:01<2:52:53,  3.50s/it] 35%|███▍      | 1583/4545 [1:59:05<3:00:15,  3.65s/it] 35%|███▍      | 1584/4545 [1:59:10<3:08:48,  3.83s/it] 35%|███▍      | 1585/4545 [1:59:14<3:09:58,  3.85s/it] 35%|███▍      | 1586/4545 [1:59:16<2:45:16,  3.35s/it] 35%|███▍      | 1587/4545 [1:59:20<2:56:36,  3.58s/it] 35%|███▍      | 1588/4545 [1:59:24<3:03:24,  3.72s/it] 35%|███▍      | 1589/4545 [1:59:28<3:09:46,  3.85s/it] 35%|███▍      | 1590/4545 [1:59:32<3:04:41,  3.75s/it]                                                       {'loss': 0.0532, 'grad_norm': 2.5565788745880127, 'learning_rate': 3.994564065745081e-06, 'rewards/chosen': -2.23193359375, 'rewards/rejected': -38.787498474121094, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 36.57500076293945, 'logps/chosen': -199.39999389648438, 'logps/rejected': -475.3999938964844, 'logits/chosen': -11.15625, 'logits/rejected': -10.618749618530273, 'epoch': 1.05}
 35%|███▍      | 1590/4545 [1:59:32<3:04:41,  3.75s/it] 35%|███▌      | 1591/4545 [1:59:36<3:07:59,  3.82s/it] 35%|███▌      | 1592/4545 [1:59:39<2:59:40,  3.65s/it] 35%|███▌      | 1593/4545 [1:59:43<3:03:50,  3.74s/it] 35%|███▌      | 1594/4545 [1:59:46<2:52:48,  3.51s/it] 35%|███▌      | 1595/4545 [1:59:49<2:45:07,  3.36s/it] 35%|███▌      | 1596/4545 [1:59:53<2:57:11,  3.61s/it] 35%|███▌      | 1597/4545 [1:59:56<2:57:03,  3.60s/it] 35%|███▌      | 1598/4545 [2:00:00<3:01:51,  3.70s/it] 35%|███▌      | 1599/4545 [2:00:05<3:08:27,  3.84s/it] 35%|███▌      | 1600/4545 [2:00:09<3:14:26,  3.96s/it]                                                       {'loss': 0.1093, 'grad_norm': 2.27646803855896, 'learning_rate': 3.993018844618586e-06, 'rewards/chosen': -0.699999988079071, 'rewards/rejected': -30.024999618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 29.337499618530273, 'logps/chosen': -248.35000610351562, 'logps/rejected': -443.0, 'logits/chosen': -11.418749809265137, 'logits/rejected': -10.693750381469727, 'epoch': 1.06}
 35%|███▌      | 1600/4545 [2:00:09<3:14:26,  3.96s/it] 35%|███▌      | 1601/4545 [2:00:13<3:11:56,  3.91s/it] 35%|███▌      | 1602/4545 [2:00:17<3:12:14,  3.92s/it] 35%|███▌      | 1603/4545 [2:00:21<3:15:19,  3.98s/it] 35%|███▌      | 1604/4545 [2:00:25<3:18:49,  4.06s/it] 35%|███▌      | 1605/4545 [2:00:28<3:08:08,  3.84s/it] 35%|███▌      | 1606/4545 [2:00:32<3:09:48,  3.87s/it] 35%|███▌      | 1607/4545 [2:01:02<9:28:14, 11.60s/it] 35%|███▌      | 1608/4545 [2:01:08<8:14:41, 10.11s/it] 35%|███▌      | 1609/4545 [2:01:11<6:27:05,  7.91s/it] 35%|███▌      | 1610/4545 [2:01:15<5:19:59,  6.54s/it]                                                       {'loss': 0.1383, 'grad_norm': 35.630435943603516, 'learning_rate': 3.99128100018333e-06, 'rewards/chosen': 0.860156238079071, 'rewards/rejected': -24.424999237060547, 'rewards/accuracies': 0.9375, 'rewards/margins': 25.3125, 'logps/chosen': -371.1000061035156, 'logps/rejected': -408.6000061035156, 'logits/chosen': -11.475000381469727, 'logits/rejected': -11.181249618530273, 'epoch': 1.06}
 35%|███▌      | 1610/4545 [2:01:15<5:19:59,  6.54s/it] 35%|███▌      | 1611/4545 [2:01:19<4:42:41,  5.78s/it] 35%|███▌      | 1612/4545 [2:01:23<4:18:11,  5.28s/it] 35%|███▌      | 1613/4545 [2:01:26<3:52:49,  4.76s/it] 36%|███▌      | 1614/4545 [2:01:30<3:41:43,  4.54s/it] 36%|███▌      | 1615/4545 [2:01:34<3:32:39,  4.35s/it] 36%|███▌      | 1616/4545 [2:01:37<3:06:49,  3.83s/it] 36%|███▌      | 1617/4545 [2:01:41<3:09:09,  3.88s/it] 36%|███▌      | 1618/4545 [2:01:45<3:12:43,  3.95s/it] 36%|███▌      | 1619/4545 [2:01:49<3:09:02,  3.88s/it] 36%|███▌      | 1620/4545 [2:01:52<3:04:12,  3.78s/it]                                                       {'loss': 0.1025, 'grad_norm': 30.430871963500977, 'learning_rate': 3.989350719135254e-06, 'rewards/chosen': 0.662402331829071, 'rewards/rejected': -28.209375381469727, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 28.837499618530273, 'logps/chosen': -395.6499938964844, 'logps/rejected': -507.3999938964844, 'logits/chosen': -11.081250190734863, 'logits/rejected': -10.699999809265137, 'epoch': 1.07}
 36%|███▌      | 1620/4545 [2:01:52<3:04:12,  3.78s/it] 36%|███▌      | 1621/4545 [2:01:56<3:11:12,  3.92s/it] 36%|███▌      | 1622/4545 [2:02:00<3:11:13,  3.93s/it] 36%|███▌      | 1623/4545 [2:02:04<3:06:44,  3.83s/it] 36%|███▌      | 1624/4545 [2:02:08<3:12:18,  3.95s/it] 36%|███▌      | 1625/4545 [2:02:12<3:12:56,  3.96s/it] 36%|███▌      | 1626/4545 [2:02:16<3:12:31,  3.96s/it] 36%|███▌      | 1627/4545 [2:02:20<3:07:05,  3.85s/it] 36%|███▌      | 1628/4545 [2:02:22<2:45:30,  3.40s/it] 36%|███▌      | 1629/4545 [2:02:26<2:50:44,  3.51s/it] 36%|███▌      | 1630/4545 [2:02:30<2:54:02,  3.58s/it]                                                       {'loss': 0.2121, 'grad_norm': 4.576199531555176, 'learning_rate': 3.9872282088436935e-06, 'rewards/chosen': -0.75, 'rewards/rejected': -22.443750381469727, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 21.668750762939453, 'logps/chosen': -252.35000610351562, 'logps/rejected': -324.70001220703125, 'logits/chosen': -11.231249809265137, 'logits/rejected': -10.856249809265137, 'epoch': 1.08}
 36%|███▌      | 1630/4545 [2:02:30<2:54:02,  3.58s/it] 36%|███▌      | 1631/4545 [2:02:33<2:49:14,  3.48s/it] 36%|███▌      | 1632/4545 [2:02:36<2:50:50,  3.52s/it] 36%|███▌      | 1633/4545 [2:02:40<2:54:27,  3.59s/it] 36%|███▌      | 1634/4545 [2:02:44<2:59:34,  3.70s/it] 36%|███▌      | 1635/4545 [2:02:48<3:03:04,  3.77s/it] 36%|███▌      | 1636/4545 [2:02:52<3:05:05,  3.82s/it] 36%|███▌      | 1637/4545 [2:02:56<3:10:14,  3.93s/it] 36%|███▌      | 1638/4545 [2:03:00<3:10:40,  3.94s/it] 36%|███▌      | 1639/4545 [2:03:04<3:06:21,  3.85s/it] 36%|███▌      | 1640/4545 [2:03:07<2:52:59,  3.57s/it]                                                       {'loss': 0.1437, 'grad_norm': 9.138720512390137, 'learning_rate': 3.9849136973290916e-06, 'rewards/chosen': -0.727343738079071, 'rewards/rejected': -20.34375, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 19.621875762939453, 'logps/chosen': -260.29998779296875, 'logps/rejected': -345.6000061035156, 'logits/chosen': -10.675000190734863, 'logits/rejected': -10.168749809265137, 'epoch': 1.08}
 36%|███▌      | 1640/4545 [2:03:07<2:52:59,  3.57s/it] 36%|███▌      | 1641/4545 [2:03:10<2:45:39,  3.42s/it] 36%|███▌      | 1642/4545 [2:03:14<2:53:47,  3.59s/it] 36%|███▌      | 1643/4545 [2:03:17<2:46:02,  3.43s/it] 36%|███▌      | 1644/4545 [2:03:21<2:52:22,  3.57s/it] 36%|███▌      | 1645/4545 [2:03:24<2:54:34,  3.61s/it] 36%|███▌      | 1646/4545 [2:03:29<3:03:04,  3.79s/it] 36%|███▌      | 1647/4545 [2:03:33<3:03:36,  3.80s/it] 36%|███▋      | 1648/4545 [2:03:35<2:47:23,  3.47s/it] 36%|███▋      | 1649/4545 [2:03:39<2:50:34,  3.53s/it] 36%|███▋      | 1650/4545 [2:03:41<2:29:53,  3.11s/it]                                                       {'loss': 0.0944, 'grad_norm': 14.788121223449707, 'learning_rate': 3.982407433238511e-06, 'rewards/chosen': -1.2859375476837158, 'rewards/rejected': -18.306249618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 17.028125762939453, 'logps/chosen': -189.10000610351562, 'logps/rejected': -286.3500061035156, 'logits/chosen': -10.762499809265137, 'logits/rejected': -10.137499809265137, 'epoch': 1.09}
 36%|███▋      | 1650/4545 [2:03:41<2:29:53,  3.11s/it] 36%|███▋      | 1651/4545 [2:03:45<2:43:17,  3.39s/it] 36%|███▋      | 1652/4545 [2:03:49<2:51:11,  3.55s/it] 36%|███▋      | 1653/4545 [2:03:53<2:56:58,  3.67s/it] 36%|███▋      | 1654/4545 [2:03:56<2:54:46,  3.63s/it] 36%|███▋      | 1655/4545 [2:04:00<2:59:16,  3.72s/it] 36%|███▋      | 1656/4545 [2:04:04<2:56:41,  3.67s/it] 36%|███▋      | 1657/4545 [2:04:08<3:01:14,  3.77s/it] 36%|███▋      | 1658/4545 [2:04:12<3:03:30,  3.81s/it] 37%|███▋      | 1659/4545 [2:04:15<2:52:01,  3.58s/it] 37%|███▋      | 1660/4545 [2:04:19<2:59:05,  3.72s/it]                                                       {'loss': 0.1936, 'grad_norm': 17.782718658447266, 'learning_rate': 3.979709685818917e-06, 'rewards/chosen': 1.1101562976837158, 'rewards/rejected': -24.987499237060547, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 26.068750381469727, 'logps/chosen': -326.20001220703125, 'logps/rejected': -399.1000061035156, 'logits/chosen': -10.84375, 'logits/rejected': -10.40625, 'epoch': 1.1}
 37%|███▋      | 1660/4545 [2:04:19<2:59:05,  3.72s/it] 37%|███▋      | 1661/4545 [2:04:49<9:16:12, 11.57s/it] 37%|███▋      | 1662/4545 [2:04:53<7:25:59,  9.28s/it] 37%|███▋      | 1663/4545 [2:04:56<6:01:04,  7.52s/it] 37%|███▋      | 1664/4545 [2:05:00<5:10:50,  6.47s/it] 37%|███▋      | 1665/4545 [2:05:03<4:21:55,  5.46s/it] 37%|███▋      | 1666/4545 [2:05:07<4:00:04,  5.00s/it] 37%|███▋      | 1667/4545 [2:05:11<3:40:50,  4.60s/it] 37%|███▋      | 1668/4545 [2:05:14<3:25:15,  4.28s/it] 37%|███▋      | 1669/4545 [2:05:19<3:23:46,  4.25s/it] 37%|███▋      | 1670/4545 [2:05:23<3:18:59,  4.15s/it]                                                       {'loss': 0.1551, 'grad_norm': 7.753782749176025, 'learning_rate': 3.976820744888251e-06, 'rewards/chosen': 0.21757812798023224, 'rewards/rejected': -24.34375, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 24.600000381469727, 'logps/chosen': -268.20001220703125, 'logps/rejected': -385.5, 'logits/chosen': -10.887499809265137, 'logits/rejected': -10.40625, 'epoch': 1.1}
 37%|███▋      | 1670/4545 [2:05:23<3:18:59,  4.15s/it] 37%|███▋      | 1671/4545 [2:05:27<3:17:29,  4.12s/it] 37%|███▋      | 1672/4545 [2:05:31<3:14:38,  4.06s/it] 37%|███▋      | 1673/4545 [2:05:35<3:16:27,  4.10s/it] 37%|███▋      | 1674/4545 [2:05:38<3:05:57,  3.89s/it] 37%|███▋      | 1675/4545 [2:05:42<3:06:42,  3.90s/it] 37%|███▋      | 1676/4545 [2:05:45<2:55:04,  3.66s/it] 37%|███▋      | 1677/4545 [2:05:49<2:56:20,  3.69s/it] 37%|███▋      | 1678/4545 [2:05:53<2:59:57,  3.77s/it] 37%|███▋      | 1679/4545 [2:05:57<3:02:23,  3.82s/it] 37%|███▋      | 1680/4545 [2:06:00<2:58:12,  3.73s/it]                                                       {'loss': 0.1603, 'grad_norm': 17.905513763427734, 'learning_rate': 3.973740920804301e-06, 'rewards/chosen': 0.50390625, 'rewards/rejected': -31.512500762939453, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 31.987499237060547, 'logps/chosen': -322.1000061035156, 'logps/rejected': -434.6000061035156, 'logits/chosen': -10.449999809265137, 'logits/rejected': -10.074999809265137, 'epoch': 1.11}
 37%|███▋      | 1680/4545 [2:06:01<2:58:12,  3.73s/it] 37%|███▋      | 1681/4545 [2:06:04<2:57:53,  3.73s/it] 37%|███▋      | 1682/4545 [2:06:07<2:43:06,  3.42s/it] 37%|███▋      | 1683/4545 [2:06:10<2:39:33,  3.35s/it] 37%|███▋      | 1684/4545 [2:06:13<2:37:14,  3.30s/it] 37%|███▋      | 1685/4545 [2:06:17<2:46:45,  3.50s/it] 37%|███▋      | 1686/4545 [2:06:21<2:52:49,  3.63s/it] 37%|███▋      | 1687/4545 [2:06:25<2:57:29,  3.73s/it] 37%|███▋      | 1688/4545 [2:06:29<3:01:22,  3.81s/it] 37%|███▋      | 1689/4545 [2:06:33<3:03:15,  3.85s/it] 37%|███▋      | 1690/4545 [2:06:37<3:04:35,  3.88s/it]                                                       {'loss': 0.1202, 'grad_norm': 27.6434326171875, 'learning_rate': 3.970470544431358e-06, 'rewards/chosen': 0.9984375238418579, 'rewards/rejected': -23.4375, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 24.475000381469727, 'logps/chosen': -279.75, 'logps/rejected': -386.8999938964844, 'logits/chosen': -10.512499809265137, 'logits/rejected': -10.193750381469727, 'epoch': 1.12}
 37%|███▋      | 1690/4545 [2:06:37<3:04:35,  3.88s/it] 37%|███▋      | 1691/4545 [2:06:41<3:06:12,  3.91s/it] 37%|███▋      | 1692/4545 [2:06:45<3:06:38,  3.93s/it] 37%|███▋      | 1693/4545 [2:06:49<3:06:32,  3.92s/it] 37%|███▋      | 1694/4545 [2:06:52<2:58:04,  3.75s/it] 37%|███▋      | 1695/4545 [2:06:55<2:52:06,  3.62s/it] 37%|███▋      | 1696/4545 [2:06:59<2:56:27,  3.72s/it] 37%|███▋      | 1697/4545 [2:07:03<2:59:32,  3.78s/it] 37%|███▋      | 1698/4545 [2:07:07<3:01:26,  3.82s/it] 37%|███▋      | 1699/4545 [2:07:11<2:58:28,  3.76s/it] 37%|███▋      | 1700/4545 [2:07:15<3:04:57,  3.90s/it]                                                       {'loss': 0.1797, 'grad_norm': 18.20817756652832, 'learning_rate': 3.967009967104665e-06, 'rewards/chosen': 1.9929687976837158, 'rewards/rejected': -20.353124618530273, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 22.375, 'logps/chosen': -345.1499938964844, 'logps/rejected': -382.6000061035156, 'logits/chosen': -10.537500381469727, 'logits/rejected': -10.262499809265137, 'epoch': 1.12}
 37%|███▋      | 1700/4545 [2:07:15<3:04:57,  3.90s/it] 37%|███▋      | 1701/4545 [2:07:19<3:04:10,  3.89s/it] 37%|███▋      | 1702/4545 [2:07:22<2:50:06,  3.59s/it] 37%|███▋      | 1703/4545 [2:07:26<2:54:49,  3.69s/it] 37%|███▋      | 1704/4545 [2:07:30<2:58:22,  3.77s/it] 38%|███▊      | 1705/4545 [2:07:59<8:59:14, 11.39s/it] 38%|███▊      | 1706/4545 [2:08:03<7:13:08,  9.15s/it] 38%|███▊      | 1707/4545 [2:08:07<5:58:58,  7.59s/it] 38%|███▊      | 1708/4545 [2:08:11<5:09:17,  6.54s/it] 38%|███▊      | 1709/4545 [2:08:15<4:29:18,  5.70s/it] 38%|███▊      | 1710/4545 [2:08:19<4:07:25,  5.24s/it]                                                       {'loss': 0.0518, 'grad_norm': 3.341520071029663, 'learning_rate': 3.963359560592685e-06, 'rewards/chosen': 1.941796898841858, 'rewards/rejected': -22.456249237060547, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 24.415624618530273, 'logps/chosen': -370.25, 'logps/rejected': -447.29998779296875, 'logits/chosen': -10.53125, 'logits/rejected': -10.162500381469727, 'epoch': 1.13}
 38%|███▊      | 1710/4545 [2:08:19<4:07:25,  5.24s/it] 38%|███▊      | 1711/4545 [2:08:21<3:31:44,  4.48s/it] 38%|███▊      | 1712/4545 [2:08:25<3:20:36,  4.25s/it] 38%|███▊      | 1713/4545 [2:08:29<3:19:48,  4.23s/it] 38%|███▊      | 1714/4545 [2:08:33<3:15:40,  4.15s/it] 38%|███▊      | 1715/4545 [2:08:37<3:16:51,  4.17s/it] 38%|███▊      | 1716/4545 [2:08:41<3:13:24,  4.10s/it] 38%|███▊      | 1717/4545 [2:08:45<3:04:48,  3.92s/it] 38%|███▊      | 1718/4545 [2:08:48<2:58:33,  3.79s/it] 38%|███▊      | 1719/4545 [2:08:52<2:49:30,  3.60s/it] 38%|███▊      | 1720/4545 [2:08:55<2:53:58,  3.70s/it]                                                       {'loss': 0.0738, 'grad_norm': 4.909262180328369, 'learning_rate': 3.959519717057151e-06, 'rewards/chosen': -0.650195300579071, 'rewards/rejected': -22.640625, 'rewards/accuracies': 0.96875, 'rewards/margins': 21.956249237060547, 'logps/chosen': -222.0500030517578, 'logps/rejected': -344.70001220703125, 'logits/chosen': -10.96875, 'logits/rejected': -10.356249809265137, 'epoch': 1.14}
 38%|███▊      | 1720/4545 [2:08:56<2:53:58,  3.70s/it] 38%|███▊      | 1721/4545 [2:09:00<3:02:37,  3.88s/it] 38%|███▊      | 1722/4545 [2:09:04<3:03:19,  3.90s/it] 38%|███▊      | 1723/4545 [2:09:08<3:03:47,  3.91s/it] 38%|███▊      | 1724/4545 [2:09:11<2:50:37,  3.63s/it] 38%|███▊      | 1725/4545 [2:09:15<2:54:35,  3.71s/it] 38%|███▊      | 1726/4545 [2:09:18<2:55:31,  3.74s/it] 38%|███▊      | 1727/4545 [2:09:22<2:48:37,  3.59s/it] 38%|███▊      | 1728/4545 [2:09:50<8:43:58, 11.16s/it] 38%|███▊      | 1729/4545 [2:09:54<7:01:59,  8.99s/it] 38%|███▊      | 1730/4545 [2:09:58<5:50:44,  7.48s/it]                                                       {'loss': 0.1529, 'grad_norm': 44.86920166015625, 'learning_rate': 3.955490849010944e-06, 'rewards/chosen': 2.5875000953674316, 'rewards/rejected': -21.850000381469727, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 24.450000762939453, 'logps/chosen': -382.1499938964844, 'logps/rejected': -413.29998779296875, 'logits/chosen': -11.068750381469727, 'logits/rejected': -10.587499618530273, 'epoch': 1.14}
 38%|███▊      | 1730/4545 [2:09:59<5:50:44,  7.48s/it] 38%|███▊      | 1731/4545 [2:10:02<4:57:31,  6.34s/it] 38%|███▊      | 1732/4545 [2:10:06<4:22:28,  5.60s/it] 38%|███▊      | 1733/4545 [2:10:10<3:59:06,  5.10s/it] 38%|███▊      | 1734/4545 [2:10:14<3:42:34,  4.75s/it] 38%|███▊      | 1735/4545 [2:10:18<3:31:18,  4.51s/it] 38%|███▊      | 1736/4545 [2:10:22<3:26:41,  4.42s/it] 38%|███▊      | 1737/4545 [2:10:26<3:19:44,  4.27s/it] 38%|███▊      | 1738/4545 [2:10:29<3:09:45,  4.06s/it] 38%|███▊      | 1739/4545 [2:10:32<2:54:16,  3.73s/it] 38%|███▊      | 1740/4545 [2:10:36<2:55:39,  3.76s/it]                                                       {'loss': 0.1652, 'grad_norm': 12.808100700378418, 'learning_rate': 3.9512733892737734e-06, 'rewards/chosen': -0.5819336175918579, 'rewards/rejected': -21.412500381469727, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 20.840625762939453, 'logps/chosen': -302.0, 'logps/rejected': -396.3999938964844, 'logits/chosen': -11.5, 'logits/rejected': -11.0, 'epoch': 1.15}
 38%|███▊      | 1740/4545 [2:10:36<2:55:39,  3.76s/it] 38%|███▊      | 1741/4545 [2:10:40<3:03:56,  3.94s/it] 38%|███▊      | 1742/4545 [2:10:43<2:44:16,  3.52s/it] 38%|███▊      | 1743/4545 [2:10:46<2:41:20,  3.46s/it] 38%|███▊      | 1744/4545 [2:10:49<2:29:17,  3.20s/it] 38%|███▊      | 1745/4545 [2:10:53<2:39:29,  3.42s/it] 38%|███▊      | 1746/4545 [2:10:57<2:44:03,  3.52s/it] 38%|███▊      | 1747/4545 [2:11:01<2:49:51,  3.64s/it] 38%|███▊      | 1748/4545 [2:11:05<2:54:21,  3.74s/it] 38%|███▊      | 1749/4545 [2:11:08<2:49:04,  3.63s/it] 39%|███▊      | 1750/4545 [2:11:11<2:42:53,  3.50s/it]                                                       {'loss': 0.0715, 'grad_norm': 4.4223127365112305, 'learning_rate': 3.946867790925676e-06, 'rewards/chosen': -2.42578125, 'rewards/rejected': -26.868749618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 24.475000381469727, 'logps/chosen': -244.10000610351562, 'logps/rejected': -423.70001220703125, 'logits/chosen': -11.725000381469727, 'logits/rejected': -11.112500190734863, 'epoch': 1.16}
 39%|███▊      | 1750/4545 [2:11:11<2:42:53,  3.50s/it] 39%|███▊      | 1751/4545 [2:11:14<2:36:56,  3.37s/it] 39%|███▊      | 1752/4545 [2:11:18<2:44:21,  3.53s/it] 39%|███▊      | 1753/4545 [2:11:22<2:50:01,  3.65s/it] 39%|███▊      | 1754/4545 [2:11:26<2:52:46,  3.71s/it] 39%|███▊      | 1755/4545 [2:11:30<2:59:16,  3.86s/it] 39%|███▊      | 1756/4545 [2:11:34<3:00:49,  3.89s/it] 39%|███▊      | 1757/4545 [2:11:38<2:55:46,  3.78s/it] 39%|███▊      | 1758/4545 [2:11:40<2:41:25,  3.48s/it] 39%|███▊      | 1759/4545 [2:11:44<2:41:43,  3.48s/it] 39%|███▊      | 1760/4545 [2:11:47<2:37:45,  3.40s/it]                                                       {'loss': 0.1563, 'grad_norm': 6.524687767028809, 'learning_rate': 3.94227452725835e-06, 'rewards/chosen': -3.360156297683716, 'rewards/rejected': -25.024999618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 21.6875, 'logps/chosen': -228.89999389648438, 'logps/rejected': -342.8999938964844, 'logits/chosen': -11.84375, 'logits/rejected': -11.356249809265137, 'epoch': 1.16}
 39%|███▊      | 1760/4545 [2:11:47<2:37:45,  3.40s/it] 39%|███▊      | 1761/4545 [2:11:51<2:44:23,  3.54s/it] 39%|███▉      | 1762/4545 [2:11:55<2:53:57,  3.75s/it] 39%|███▉      | 1763/4545 [2:11:59<2:58:36,  3.85s/it] 39%|███▉      | 1764/4545 [2:12:03<2:59:38,  3.88s/it] 39%|███▉      | 1765/4545 [2:12:06<2:51:28,  3.70s/it] 39%|███▉      | 1766/4545 [2:12:10<2:54:40,  3.77s/it] 39%|███▉      | 1767/4545 [2:12:14<2:49:42,  3.67s/it] 39%|███▉      | 1768/4545 [2:12:44<8:57:25, 11.61s/it] 39%|███▉      | 1769/4545 [2:12:48<7:10:58,  9.32s/it] 39%|███▉      | 1770/4545 [2:12:51<5:46:59,  7.50s/it]                                                       {'loss': 0.083, 'grad_norm': 5.183752536773682, 'learning_rate': 3.937494091724304e-06, 'rewards/chosen': -0.717968761920929, 'rewards/rejected': -22.481250762939453, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 21.771875381469727, 'logps/chosen': -297.79998779296875, 'logps/rejected': -383.5, 'logits/chosen': -11.087499618530273, 'logits/rejected': -10.71875, 'epoch': 1.17}
 39%|███▉      | 1770/4545 [2:12:51<5:46:59,  7.50s/it] 39%|███▉      | 1771/4545 [2:12:55<4:57:56,  6.44s/it] 39%|███▉      | 1772/4545 [2:12:59<4:18:37,  5.60s/it] 39%|███▉      | 1773/4545 [2:13:03<3:58:12,  5.16s/it] 39%|███▉      | 1774/4545 [2:13:07<3:41:49,  4.80s/it] 39%|███▉      | 1775/4545 [2:13:11<3:34:01,  4.64s/it] 39%|███▉      | 1776/4545 [2:13:15<3:24:10,  4.42s/it] 39%|███▉      | 1777/4545 [2:13:18<3:07:39,  4.07s/it] 39%|███▉      | 1778/4545 [2:13:23<3:10:04,  4.12s/it] 39%|███▉      | 1779/4545 [2:13:26<2:54:31,  3.79s/it] 39%|███▉      | 1780/4545 [2:13:29<2:57:03,  3.84s/it]                                                       {'loss': 0.1379, 'grad_norm': 23.477462768554688, 'learning_rate': 3.932526997883844e-06, 'rewards/chosen': -1.1008789539337158, 'rewards/rejected': -29.0625, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.981250762939453, 'logps/chosen': -264.04998779296875, 'logps/rejected': -427.79998779296875, 'logits/chosen': -10.931249618530273, 'logits/rejected': -10.493749618530273, 'epoch': 1.17}
 39%|███▉      | 1780/4545 [2:13:30<2:57:03,  3.84s/it] 39%|███▉      | 1781/4545 [2:13:33<2:58:47,  3.88s/it] 39%|███▉      | 1782/4545 [2:13:37<2:59:13,  3.89s/it] 39%|███▉      | 1783/4545 [2:14:07<8:53:50, 11.60s/it] 39%|███▉      | 1784/4545 [2:14:11<7:07:52,  9.30s/it] 39%|███▉      | 1785/4545 [2:14:15<5:55:50,  7.74s/it] 39%|███▉      | 1786/4545 [2:14:45<11:08:16, 14.53s/it] 39%|███▉      | 1787/4545 [2:14:48<8:30:24, 11.10s/it]  39%|███▉      | 1788/4545 [2:14:53<6:55:56,  9.05s/it] 39%|███▉      | 1789/4545 [2:14:57<5:45:43,  7.53s/it] 39%|███▉      | 1790/4545 [2:15:01<4:59:35,  6.52s/it]                                                       {'loss': 0.2101, 'grad_norm': 2.815300226211548, 'learning_rate': 3.927373779349908e-06, 'rewards/chosen': 1.8664062023162842, 'rewards/rejected': -20.674999237060547, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 22.5625, 'logps/chosen': -361.75, 'logps/rejected': -389.20001220703125, 'logits/chosen': -10.600000381469727, 'logits/rejected': -10.362500190734863, 'epoch': 1.18}
 39%|███▉      | 1790/4545 [2:15:01<4:59:35,  6.52s/it] 39%|███▉      | 1791/4545 [2:15:05<4:26:40,  5.81s/it] 39%|███▉      | 1792/4545 [2:15:09<4:00:51,  5.25s/it] 39%|███▉      | 1793/4545 [2:15:13<3:46:22,  4.94s/it] 39%|███▉      | 1794/4545 [2:15:17<3:32:27,  4.63s/it] 39%|███▉      | 1795/4545 [2:15:21<3:21:52,  4.40s/it] 40%|███▉      | 1796/4545 [2:15:25<3:18:48,  4.34s/it] 40%|███▉      | 1797/4545 [2:15:29<3:13:09,  4.22s/it] 40%|███▉      | 1798/4545 [2:15:33<3:09:06,  4.13s/it] 40%|███▉      | 1799/4545 [2:15:37<3:06:31,  4.08s/it] 40%|███▉      | 1800/4545 [2:15:41<3:00:09,  3.94s/it]                                                       {'loss': 0.0769, 'grad_norm': 18.487253189086914, 'learning_rate': 3.922034989730734e-06, 'rewards/chosen': -0.5582031011581421, 'rewards/rejected': -28.356250762939453, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 27.768749237060547, 'logps/chosen': -310.79998779296875, 'logps/rejected': -439.3999938964844, 'logits/chosen': -10.743749618530273, 'logits/rejected': -10.175000190734863, 'epoch': 1.19}
 40%|███▉      | 1800/4545 [2:15:41<3:00:09,  3.94s/it] 40%|███▉      | 1801/4545 [2:15:45<3:00:15,  3.94s/it] 40%|███▉      | 1802/4545 [2:15:48<3:00:11,  3.94s/it] 40%|███▉      | 1803/4545 [2:15:53<3:02:25,  3.99s/it] 40%|███▉      | 1804/4545 [2:15:56<2:57:45,  3.89s/it] 40%|███▉      | 1805/4545 [2:16:00<3:00:16,  3.95s/it] 40%|███▉      | 1806/4545 [2:16:04<2:57:25,  3.89s/it] 40%|███▉      | 1807/4545 [2:16:07<2:49:08,  3.71s/it] 40%|███▉      | 1808/4545 [2:16:10<2:39:12,  3.49s/it] 40%|███▉      | 1809/4545 [2:16:14<2:47:56,  3.68s/it] 40%|███▉      | 1810/4545 [2:16:18<2:43:14,  3.58s/it]                                                       {'loss': 0.1049, 'grad_norm': 8.065924644470215, 'learning_rate': 3.91651120257039e-06, 'rewards/chosen': -1.0906250476837158, 'rewards/rejected': -28.0625, 'rewards/accuracies': 0.96875, 'rewards/margins': 26.946874618530273, 'logps/chosen': -233.39999389648438, 'logps/rejected': -394.79998779296875, 'logits/chosen': -11.418749809265137, 'logits/rejected': -11.056249618530273, 'epoch': 1.19}
 40%|███▉      | 1810/4545 [2:16:18<2:43:14,  3.58s/it] 40%|███▉      | 1811/4545 [2:16:22<2:48:21,  3.69s/it] 40%|███▉      | 1812/4545 [2:16:26<2:51:37,  3.77s/it] 40%|███▉      | 1813/4545 [2:16:30<2:53:54,  3.82s/it] 40%|███▉      | 1814/4545 [2:16:34<2:55:58,  3.87s/it] 40%|███▉      | 1815/4545 [2:16:38<2:57:27,  3.90s/it] 40%|███▉      | 1816/4545 [2:16:42<2:57:35,  3.90s/it] 40%|███▉      | 1817/4545 [2:16:46<3:00:50,  3.98s/it] 40%|████      | 1818/4545 [2:16:49<2:57:15,  3.90s/it] 40%|████      | 1819/4545 [2:16:54<3:01:53,  4.00s/it] 40%|████      | 1820/4545 [2:16:58<3:00:52,  3.98s/it]                                                       {'loss': 0.0721, 'grad_norm': 12.7111177444458, 'learning_rate': 3.910803011287155e-06, 'rewards/chosen': 3.2060546875, 'rewards/rejected': -36.32500076293945, 'rewards/accuracies': 0.96875, 'rewards/margins': 39.537498474121094, 'logps/chosen': -434.20001220703125, 'logps/rejected': -594.5999755859375, 'logits/chosen': -10.824999809265137, 'logits/rejected': -10.456250190734863, 'epoch': 1.2}
 40%|████      | 1820/4545 [2:16:58<3:00:52,  3.98s/it] 40%|████      | 1821/4545 [2:17:02<3:00:47,  3.98s/it] 40%|████      | 1822/4545 [2:17:06<3:00:57,  3.99s/it] 40%|████      | 1823/4545 [2:17:09<3:00:03,  3.97s/it] 40%|████      | 1824/4545 [2:17:13<2:48:56,  3.73s/it] 40%|████      | 1825/4545 [2:17:17<2:51:55,  3.79s/it] 40%|████      | 1826/4545 [2:17:19<2:38:37,  3.50s/it] 40%|████      | 1827/4545 [2:17:50<8:44:39, 11.58s/it] 40%|████      | 1828/4545 [2:17:54<7:04:39,  9.38s/it] 40%|████      | 1829/4545 [2:17:57<5:42:57,  7.58s/it] 40%|████      | 1830/4545 [2:18:00<4:34:35,  6.07s/it]                                                       {'loss': 0.1082, 'grad_norm': 7.557916164398193, 'learning_rate': 3.9049110291097735e-06, 'rewards/chosen': -0.4742187559604645, 'rewards/rejected': -24.918750762939453, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 24.412500381469727, 'logps/chosen': -286.6499938964844, 'logps/rejected': -417.1000061035156, 'logits/chosen': -11.168749809265137, 'logits/rejected': -10.868749618530273, 'epoch': 1.21}
 40%|████      | 1830/4545 [2:18:00<4:34:35,  6.07s/it] 40%|████      | 1831/4545 [2:18:04<4:06:03,  5.44s/it] 40%|████      | 1832/4545 [2:18:08<3:50:00,  5.09s/it] 40%|████      | 1833/4545 [2:18:12<3:32:41,  4.71s/it] 40%|████      | 1834/4545 [2:18:16<3:20:23,  4.43s/it] 40%|████      | 1835/4545 [2:18:19<3:02:37,  4.04s/it] 40%|████      | 1836/4545 [2:18:23<3:00:51,  4.01s/it] 40%|████      | 1837/4545 [2:18:27<3:02:43,  4.05s/it] 40%|████      | 1838/4545 [2:18:31<2:55:13,  3.88s/it] 40%|████      | 1839/4545 [2:18:33<2:35:44,  3.45s/it] 40%|████      | 1840/4545 [2:18:37<2:45:41,  3.68s/it]                                                       {'loss': 0.1228, 'grad_norm': 4.373284816741943, 'learning_rate': 3.898835889011572e-06, 'rewards/chosen': -2.5550780296325684, 'rewards/rejected': -36.849998474121094, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 34.26250076293945, 'logps/chosen': -251.89999389648438, 'logps/rejected': -493.3999938964844, 'logits/chosen': -11.193750381469727, 'logits/rejected': -10.612500190734863, 'epoch': 1.21}
 40%|████      | 1840/4545 [2:18:37<2:45:41,  3.68s/it] 41%|████      | 1841/4545 [2:18:41<2:51:08,  3.80s/it] 41%|████      | 1842/4545 [2:18:45<2:52:43,  3.83s/it] 41%|████      | 1843/4545 [2:18:49<2:53:57,  3.86s/it] 41%|████      | 1844/4545 [2:18:52<2:40:45,  3.57s/it] 41%|████      | 1845/4545 [2:18:56<2:42:45,  3.62s/it] 41%|████      | 1846/4545 [2:18:58<2:29:28,  3.32s/it] 41%|████      | 1847/4545 [2:19:02<2:37:32,  3.50s/it] 41%|████      | 1848/4545 [2:19:06<2:44:43,  3.66s/it] 41%|████      | 1849/4545 [2:19:10<2:48:07,  3.74s/it] 41%|████      | 1850/4545 [2:19:14<2:50:16,  3.79s/it]                                                       {'loss': 0.071, 'grad_norm': 25.02631378173828, 'learning_rate': 3.892578243642459e-06, 'rewards/chosen': -0.28276365995407104, 'rewards/rejected': -32.912498474121094, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 32.650001525878906, 'logps/chosen': -336.3999938964844, 'logps/rejected': -505.1000061035156, 'logits/chosen': -11.331250190734863, 'logits/rejected': -10.881250381469727, 'epoch': 1.22}
 41%|████      | 1850/4545 [2:19:14<2:50:16,  3.79s/it] 41%|████      | 1851/4545 [2:19:18<2:52:36,  3.84s/it] 41%|████      | 1852/4545 [2:19:22<2:50:05,  3.79s/it] 41%|████      | 1853/4545 [2:19:26<2:52:07,  3.84s/it] 41%|████      | 1854/4545 [2:19:30<2:54:10,  3.88s/it] 41%|████      | 1855/4545 [2:19:34<2:54:40,  3.90s/it] 41%|████      | 1856/4545 [2:19:38<2:55:00,  3.91s/it] 41%|████      | 1857/4545 [2:19:42<2:55:25,  3.92s/it] 41%|████      | 1858/4545 [2:19:46<2:56:54,  3.95s/it] 41%|████      | 1859/4545 [2:19:48<2:42:59,  3.64s/it] 41%|████      | 1860/4545 [2:19:52<2:46:49,  3.73s/it]                                                       {'loss': 0.0833, 'grad_norm': 7.292300224304199, 'learning_rate': 3.886138765258814e-06, 'rewards/chosen': 1.1277344226837158, 'rewards/rejected': -36.98125076293945, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 38.118751525878906, 'logps/chosen': -406.5, 'logps/rejected': -601.4000244140625, 'logits/chosen': -10.949999809265137, 'logits/rejected': -10.756250381469727, 'epoch': 1.23}
 41%|████      | 1860/4545 [2:19:52<2:46:49,  3.73s/it] 41%|████      | 1861/4545 [2:19:56<2:49:44,  3.79s/it] 41%|████      | 1862/4545 [2:20:00<2:51:35,  3.84s/it] 41%|████      | 1863/4545 [2:20:04<2:48:38,  3.77s/it] 41%|████      | 1864/4545 [2:20:08<2:50:44,  3.82s/it] 41%|████      | 1865/4545 [2:20:12<2:57:02,  3.96s/it] 41%|████      | 1866/4545 [2:20:16<2:56:37,  3.96s/it] 41%|████      | 1867/4545 [2:20:19<2:46:59,  3.74s/it] 41%|████      | 1868/4545 [2:20:23<2:49:32,  3.80s/it] 41%|████      | 1869/4545 [2:20:27<2:51:17,  3.84s/it] 41%|████      | 1870/4545 [2:20:31<2:52:31,  3.87s/it]                                                       {'loss': 0.1083, 'grad_norm': 4.79496431350708, 'learning_rate': 3.879518145651265e-06, 'rewards/chosen': 1.898828148841858, 'rewards/rejected': -31.143749237060547, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 33.01874923706055, 'logps/chosen': -383.3500061035156, 'logps/rejected': -517.9000244140625, 'logits/chosen': -11.274999618530273, 'logits/rejected': -10.943750381469727, 'epoch': 1.23}
 41%|████      | 1870/4545 [2:20:31<2:52:31,  3.87s/it] 41%|████      | 1871/4545 [2:20:35<2:53:23,  3.89s/it] 41%|████      | 1872/4545 [2:20:39<2:50:05,  3.82s/it] 41%|████      | 1873/4545 [2:20:41<2:31:06,  3.39s/it] 41%|████      | 1874/4545 [2:20:45<2:39:20,  3.58s/it] 41%|████▏     | 1875/4545 [2:20:49<2:41:54,  3.64s/it] 41%|████▏     | 1876/4545 [2:20:52<2:29:45,  3.37s/it] 41%|████▏     | 1877/4545 [2:20:56<2:37:18,  3.54s/it] 41%|████▏     | 1878/4545 [2:21:00<2:42:19,  3.65s/it] 41%|████▏     | 1879/4545 [2:21:03<2:42:26,  3.66s/it] 41%|████▏     | 1880/4545 [2:21:07<2:46:11,  3.74s/it]                                                       {'loss': 0.2025, 'grad_norm': 3.9215588569641113, 'learning_rate': 3.872717096070371e-06, 'rewards/chosen': -0.776562511920929, 'rewards/rejected': -37.76250076293945, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 36.9375, 'logps/chosen': -234.35000610351562, 'logps/rejected': -455.6000061035156, 'logits/chosen': -11.731249809265137, 'logits/rejected': -11.149999618530273, 'epoch': 1.24}
 41%|████▏     | 1880/4545 [2:21:07<2:46:11,  3.74s/it] 41%|████▏     | 1881/4545 [2:21:10<2:38:10,  3.56s/it] 41%|████▏     | 1882/4545 [2:21:14<2:45:00,  3.72s/it] 41%|████▏     | 1883/4545 [2:21:18<2:40:30,  3.62s/it] 41%|████▏     | 1884/4545 [2:21:22<2:44:26,  3.71s/it] 41%|████▏     | 1885/4545 [2:21:26<2:50:12,  3.84s/it] 41%|████▏     | 1886/4545 [2:21:30<2:51:34,  3.87s/it] 42%|████▏     | 1887/4545 [2:21:34<2:52:19,  3.89s/it] 42%|████▏     | 1888/4545 [2:21:37<2:47:32,  3.78s/it] 42%|████▏     | 1889/4545 [2:21:41<2:46:50,  3.77s/it] 42%|████▏     | 1890/4545 [2:21:44<2:35:07,  3.51s/it]                                                       {'loss': 0.2033, 'grad_norm': 19.864789962768555, 'learning_rate': 3.865736347150212e-06, 'rewards/chosen': 0.15156249701976776, 'rewards/rejected': -29.581249237060547, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 29.725000381469727, 'logps/chosen': -240.9499969482422, 'logps/rejected': -470.6000061035156, 'logits/chosen': -11.712499618530273, 'logits/rejected': -11.287500381469727, 'epoch': 1.25}
 42%|████▏     | 1890/4545 [2:21:44<2:35:07,  3.51s/it] 42%|████▏     | 1891/4545 [2:21:48<2:43:31,  3.70s/it] 42%|████▏     | 1892/4545 [2:21:52<2:46:47,  3.77s/it] 42%|████▏     | 1893/4545 [2:21:56<2:48:57,  3.82s/it] 42%|████▏     | 1894/4545 [2:21:59<2:44:35,  3.73s/it] 42%|████▏     | 1895/4545 [2:22:03<2:39:55,  3.62s/it] 42%|████▏     | 1896/4545 [2:22:07<2:46:18,  3.77s/it] 42%|████▏     | 1897/4545 [2:22:09<2:31:08,  3.42s/it] 42%|████▏     | 1898/4545 [2:22:13<2:37:39,  3.57s/it] 42%|████▏     | 1899/4545 [2:22:17<2:42:30,  3.68s/it] 42%|████▏     | 1900/4545 [2:22:21<2:46:04,  3.77s/it]                                                       {'loss': 0.1243, 'grad_norm': 20.3876895904541, 'learning_rate': 3.858576648829896e-06, 'rewards/chosen': 3.239062547683716, 'rewards/rejected': -29.549999237060547, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 32.775001525878906, 'logps/chosen': -386.1499938964844, 'logps/rejected': -532.7999877929688, 'logits/chosen': -11.087499618530273, 'logits/rejected': -10.800000190734863, 'epoch': 1.25}
 42%|████▏     | 1900/4545 [2:22:21<2:46:04,  3.77s/it] 42%|████▏     | 1901/4545 [2:22:25<2:51:08,  3.88s/it] 42%|████▏     | 1902/4545 [2:22:30<2:55:15,  3.98s/it] 42%|████▏     | 1903/4545 [2:22:34<2:57:19,  4.03s/it] 42%|████▏     | 1904/4545 [2:22:37<2:52:44,  3.92s/it] 42%|████▏     | 1905/4545 [2:22:42<2:54:41,  3.97s/it] 42%|████▏     | 1906/4545 [2:22:45<2:54:14,  3.96s/it] 42%|████▏     | 1907/4545 [2:22:49<2:48:20,  3.83s/it] 42%|████▏     | 1908/4545 [2:22:53<2:53:49,  3.96s/it] 42%|████▏     | 1909/4545 [2:22:57<2:53:40,  3.95s/it] 42%|████▏     | 1910/4545 [2:23:01<2:53:23,  3.95s/it]                                                       {'loss': 0.0793, 'grad_norm': 7.870271682739258, 'learning_rate': 3.8512387702729965e-06, 'rewards/chosen': 1.353906273841858, 'rewards/rejected': -36.587501525878906, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 38.0, 'logps/chosen': -325.1499938964844, 'logps/rejected': -526.0, 'logits/chosen': -11.100000381469727, 'logits/rejected': -10.550000190734863, 'epoch': 1.26}
 42%|████▏     | 1910/4545 [2:23:01<2:53:23,  3.95s/it] 42%|████▏     | 1911/4545 [2:23:05<2:54:01,  3.96s/it] 42%|████▏     | 1912/4545 [2:23:09<2:46:31,  3.79s/it] 42%|████▏     | 1913/4545 [2:23:12<2:48:27,  3.84s/it] 42%|████▏     | 1914/4545 [2:23:16<2:49:38,  3.87s/it] 42%|████▏     | 1915/4545 [2:23:20<2:50:29,  3.89s/it] 42%|████▏     | 1916/4545 [2:23:24<2:48:54,  3.86s/it] 42%|████▏     | 1917/4545 [2:23:28<2:49:57,  3.88s/it] 42%|████▏     | 1918/4545 [2:23:58<8:33:49, 11.74s/it] 42%|████▏     | 1919/4545 [2:24:01<6:41:23,  9.17s/it] 42%|████▏     | 1920/4545 [2:24:05<5:32:33,  7.60s/it]                                                       {'loss': 0.1087, 'grad_norm': 20.997041702270508, 'learning_rate': 3.8437234997849174e-06, 'rewards/chosen': 1.546875, 'rewards/rejected': -26.784374237060547, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 28.34375, 'logps/chosen': -310.5, 'logps/rejected': -449.20001220703125, 'logits/chosen': -11.012499809265137, 'logits/rejected': -10.631250381469727, 'epoch': 1.27}
 42%|████▏     | 1920/4545 [2:24:05<5:32:33,  7.60s/it] 42%|████▏     | 1921/4545 [2:24:10<4:50:32,  6.64s/it] 42%|████▏     | 1922/4545 [2:24:13<4:13:05,  5.79s/it] 42%|████▏     | 1923/4545 [2:24:17<3:47:06,  5.20s/it] 42%|████▏     | 1924/4545 [2:24:21<3:34:03,  4.90s/it] 42%|████▏     | 1925/4545 [2:24:25<3:21:10,  4.61s/it] 42%|████▏     | 1926/4545 [2:24:29<3:09:56,  4.35s/it] 42%|████▏     | 1927/4545 [2:24:33<2:59:15,  4.11s/it] 42%|████▏     | 1928/4545 [2:24:36<2:49:14,  3.88s/it] 42%|████▏     | 1929/4545 [2:24:40<2:49:41,  3.89s/it] 42%|████▏     | 1930/4545 [2:24:43<2:40:44,  3.69s/it]                                                       {'loss': 0.1789, 'grad_norm': 17.564037322998047, 'learning_rate': 3.8360316447282105e-06, 'rewards/chosen': -1.580468773841858, 'rewards/rejected': -27.631250381469727, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 26.03125, 'logps/chosen': -207.39999389648438, 'logps/rejected': -385.1000061035156, 'logits/chosen': -11.237500190734863, 'logits/rejected': -10.737500190734863, 'epoch': 1.27}
 42%|████▏     | 1930/4545 [2:24:43<2:40:44,  3.69s/it] 42%|████▏     | 1931/4545 [2:24:47<2:39:27,  3.66s/it] 43%|████▎     | 1932/4545 [2:24:51<2:42:50,  3.74s/it] 43%|████▎     | 1933/4545 [2:24:53<2:30:22,  3.45s/it] 43%|████▎     | 1934/4545 [2:24:58<2:38:55,  3.65s/it] 43%|████▎     | 1935/4545 [2:25:02<2:42:39,  3.74s/it] 43%|████▎     | 1936/4545 [2:25:05<2:44:07,  3.77s/it] 43%|████▎     | 1937/4545 [2:25:09<2:44:56,  3.79s/it] 43%|████▎     | 1938/4545 [2:25:13<2:46:52,  3.84s/it] 43%|████▎     | 1939/4545 [2:25:17<2:50:24,  3.92s/it] 43%|████▎     | 1940/4545 [2:25:21<2:50:18,  3.92s/it]                                                       {'loss': 0.0982, 'grad_norm': 6.142003059387207, 'learning_rate': 3.828164031435837e-06, 'rewards/chosen': 1.009765625, 'rewards/rejected': -33.41875076293945, 'rewards/accuracies': 0.96875, 'rewards/margins': 34.45000076293945, 'logps/chosen': -293.54998779296875, 'logps/rejected': -511.6000061035156, 'logits/chosen': -11.1875, 'logits/rejected': -10.787500381469727, 'epoch': 1.28}
 43%|████▎     | 1940/4545 [2:25:21<2:50:18,  3.92s/it] 43%|████▎     | 1941/4545 [2:25:26<2:55:06,  4.03s/it] 43%|████▎     | 1942/4545 [2:25:29<2:53:36,  4.00s/it] 43%|████▎     | 1943/4545 [2:25:33<2:52:52,  3.99s/it] 43%|████▎     | 1944/4545 [2:25:37<2:52:13,  3.97s/it] 43%|████▎     | 1945/4545 [2:25:41<2:41:33,  3.73s/it] 43%|████▎     | 1946/4545 [2:25:44<2:44:08,  3.79s/it] 43%|████▎     | 1947/4545 [2:25:47<2:33:15,  3.54s/it] 43%|████▎     | 1948/4545 [2:26:16<7:57:30, 11.03s/it] 43%|████▎     | 1949/4545 [2:26:20<6:25:20,  8.91s/it] 43%|████▎     | 1950/4545 [2:26:24<5:23:20,  7.48s/it]                                                       {'loss': 0.1333, 'grad_norm': 116.77145385742188, 'learning_rate': 3.820121505122396e-06, 'rewards/chosen': -1.221093773841858, 'rewards/rejected': -25.799999237060547, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 24.549999237060547, 'logps/chosen': -218.14999389648438, 'logps/rejected': -399.6000061035156, 'logits/chosen': -11.318750381469727, 'logits/rejected': -10.837499618530273, 'epoch': 1.29}
 43%|████▎     | 1950/4545 [2:26:24<5:23:20,  7.48s/it] 43%|████▎     | 1951/4545 [2:26:28<4:38:06,  6.43s/it] 43%|████▎     | 1952/4545 [2:26:32<4:05:24,  5.68s/it] 43%|████▎     | 1953/4545 [2:26:36<3:39:40,  5.09s/it] 43%|████▎     | 1954/4545 [2:26:40<3:24:46,  4.74s/it] 43%|████▎     | 1955/4545 [2:26:44<3:18:05,  4.59s/it] 43%|████▎     | 1956/4545 [2:26:48<3:09:25,  4.39s/it] 43%|████▎     | 1957/4545 [2:26:52<3:03:26,  4.25s/it] 43%|████▎     | 1958/4545 [2:26:54<2:38:21,  3.67s/it] 43%|████▎     | 1959/4545 [2:26:56<2:21:00,  3.27s/it] 43%|████▎     | 1960/4545 [2:27:00<2:23:52,  3.34s/it]                                                       {'loss': 0.1109, 'grad_norm': 52.47715759277344, 'learning_rate': 3.811904929793324e-06, 'rewards/chosen': 0.7222656011581421, 'rewards/rejected': -29.818750381469727, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 30.512500762939453, 'logps/chosen': -307.20001220703125, 'logps/rejected': -439.20001220703125, 'logits/chosen': -11.506250381469727, 'logits/rejected': -11.09375, 'epoch': 1.29}
 43%|████▎     | 1960/4545 [2:27:00<2:23:52,  3.34s/it] 43%|████▎     | 1961/4545 [2:27:04<2:37:28,  3.66s/it] 43%|████▎     | 1962/4545 [2:27:07<2:24:50,  3.36s/it] 43%|████▎     | 1963/4545 [2:27:11<2:30:41,  3.50s/it] 43%|████▎     | 1964/4545 [2:27:15<2:36:17,  3.63s/it] 43%|████▎     | 1965/4545 [2:27:18<2:34:20,  3.59s/it] 43%|████▎     | 1966/4545 [2:27:22<2:35:10,  3.61s/it] 43%|████▎     | 1967/4545 [2:27:26<2:39:18,  3.71s/it] 43%|████▎     | 1968/4545 [2:27:30<2:41:56,  3.77s/it] 43%|████▎     | 1969/4545 [2:27:34<2:46:33,  3.88s/it] 43%|████▎     | 1970/4545 [2:27:37<2:44:22,  3.83s/it]                                                       {'loss': 0.0874, 'grad_norm': 4.512709140777588, 'learning_rate': 3.8035151881520747e-06, 'rewards/chosen': -0.960156261920929, 'rewards/rejected': -31.4375, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 30.456249237060547, 'logps/chosen': -245.60000610351562, 'logps/rejected': -409.5, 'logits/chosen': -11.625, 'logits/rejected': -11.175000190734863, 'epoch': 1.3}
 43%|████▎     | 1970/4545 [2:27:38<2:44:22,  3.83s/it] 43%|████▎     | 1971/4545 [2:27:41<2:42:30,  3.79s/it] 43%|████▎     | 1972/4545 [2:27:44<2:34:04,  3.59s/it] 43%|████▎     | 1973/4545 [2:27:48<2:38:12,  3.69s/it] 43%|████▎     | 1974/4545 [2:27:52<2:41:31,  3.77s/it] 43%|████▎     | 1975/4545 [2:27:56<2:40:55,  3.76s/it] 43%|████▎     | 1976/4545 [2:28:00<2:46:37,  3.89s/it] 43%|████▎     | 1977/4545 [2:28:04<2:45:34,  3.87s/it] 44%|████▎     | 1978/4545 [2:28:08<2:46:11,  3.88s/it] 44%|████▎     | 1979/4545 [2:28:12<2:48:41,  3.94s/it] 44%|████▎     | 1980/4545 [2:28:16<2:49:44,  3.97s/it]                                                       {'loss': 0.0723, 'grad_norm': 0.8314028382301331, 'learning_rate': 3.79495318150529e-06, 'rewards/chosen': -1.3488280773162842, 'rewards/rejected': -34.51250076293945, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 33.150001525878906, 'logps/chosen': -263.3999938964844, 'logps/rejected': -485.6000061035156, 'logits/chosen': -11.737500190734863, 'logits/rejected': -11.306249618530273, 'epoch': 1.31}
 44%|████▎     | 1980/4545 [2:28:16<2:49:44,  3.97s/it] 44%|████▎     | 1981/4545 [2:28:19<2:41:31,  3.78s/it] 44%|████▎     | 1982/4545 [2:28:23<2:44:55,  3.86s/it] 44%|████▎     | 1983/4545 [2:28:27<2:44:58,  3.86s/it] 44%|████▎     | 1984/4545 [2:28:31<2:40:35,  3.76s/it] 44%|████▎     | 1985/4545 [2:28:35<2:42:49,  3.82s/it] 44%|████▎     | 1986/4545 [2:28:39<2:44:13,  3.85s/it] 44%|████▎     | 1987/4545 [2:28:43<2:49:05,  3.97s/it] 44%|████▎     | 1988/4545 [2:28:47<2:49:26,  3.98s/it] 44%|████▍     | 1989/4545 [2:28:51<2:45:06,  3.88s/it] 44%|████▍     | 1990/4545 [2:28:54<2:46:25,  3.91s/it]                                                       {'loss': 0.198, 'grad_norm': 18.79275894165039, 'learning_rate': 3.7862198296659742e-06, 'rewards/chosen': -1.506445288658142, 'rewards/rejected': -26.28125, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 24.765625, 'logps/chosen': -267.25, 'logps/rejected': -398.79998779296875, 'logits/chosen': -11.818750381469727, 'logits/rejected': -11.4375, 'epoch': 1.31}
 44%|████▍     | 1990/4545 [2:28:55<2:46:25,  3.91s/it] 44%|████▍     | 1991/4545 [2:28:59<2:48:08,  3.95s/it] 44%|████▍     | 1992/4545 [2:29:02<2:48:01,  3.95s/it] 44%|████▍     | 1993/4545 [2:29:06<2:47:59,  3.95s/it] 44%|████▍     | 1994/4545 [2:29:10<2:47:31,  3.94s/it] 44%|████▍     | 1995/4545 [2:29:14<2:49:31,  3.99s/it] 44%|████▍     | 1996/4545 [2:29:18<2:45:12,  3.89s/it] 44%|████▍     | 1997/4545 [2:29:22<2:42:57,  3.84s/it] 44%|████▍     | 1998/4545 [2:29:26<2:44:13,  3.87s/it] 44%|████▍     | 1999/4545 [2:29:29<2:38:21,  3.73s/it] 44%|████▍     | 2000/4545 [2:29:33<2:37:13,  3.71s/it]                                                       {'loss': 0.1118, 'grad_norm': 2.860816478729248, 'learning_rate': 3.777316070854679e-06, 'rewards/chosen': 0.45585936307907104, 'rewards/rejected': -27.081249237060547, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 27.543750762939453, 'logps/chosen': -348.1000061035156, 'logps/rejected': -513.7999877929688, 'logits/chosen': -11.356249809265137, 'logits/rejected': -10.931249618530273, 'epoch': 1.32}
 44%|████▍     | 2000/4545 [2:29:33<2:37:13,  3.71s/it] 44%|████▍     | 2001/4545 [2:29:36<2:30:22,  3.55s/it] 44%|████▍     | 2002/4545 [2:29:40<2:36:54,  3.70s/it] 44%|████▍     | 2003/4545 [2:29:44<2:39:09,  3.76s/it] 44%|████▍     | 2004/4545 [2:29:48<2:38:20,  3.74s/it] 44%|████▍     | 2005/4545 [2:29:51<2:39:26,  3.77s/it] 44%|████▍     | 2006/4545 [2:29:55<2:41:37,  3.82s/it] 44%|████▍     | 2007/4545 [2:29:59<2:42:55,  3.85s/it] 44%|████▍     | 2008/4545 [2:30:03<2:43:24,  3.86s/it] 44%|████▍     | 2009/4545 [2:30:07<2:44:02,  3.88s/it] 44%|████▍     | 2010/4545 [2:30:11<2:44:59,  3.90s/it]                                                       {'loss': 0.1858, 'grad_norm': 7.134303092956543, 'learning_rate': 3.768242861598708e-06, 'rewards/chosen': 0.31523436307907104, 'rewards/rejected': -28.262500762939453, 'rewards/accuracies': 0.9375, 'rewards/margins': 28.5625, 'logps/chosen': -352.3500061035156, 'logps/rejected': -474.70001220703125, 'logits/chosen': -11.71875, 'logits/rejected': -11.21875, 'epoch': 1.33}
 44%|████▍     | 2010/4545 [2:30:11<2:44:59,  3.90s/it] 44%|████▍     | 2011/4545 [2:30:15<2:45:52,  3.93s/it] 44%|████▍     | 2012/4545 [2:30:19<2:40:37,  3.80s/it] 44%|████▍     | 2013/4545 [2:30:22<2:28:53,  3.53s/it] 44%|████▍     | 2014/4545 [2:30:25<2:33:41,  3.64s/it] 44%|████▍     | 2015/4545 [2:30:29<2:37:19,  3.73s/it] 44%|████▍     | 2016/4545 [2:30:33<2:39:36,  3.79s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:44,  1.29it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.11s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.31s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.40s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.48s/it][A
 12%|█▏        | 7/60 [00:09<01:21,  1.54s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.59s/it][A
 15%|█▌        | 9/60 [00:13<01:22,  1.61s/it][A
 17%|█▋        | 10/60 [00:14<01:20,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:18<01:18,  1.65s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:22<01:16,  1.67s/it][A
 25%|██▌       | 15/60 [00:23<01:21,  1.80s/it][A
 27%|██▋       | 16/60 [00:24<01:09,  1.58s/it][A
 28%|██▊       | 17/60 [00:25<01:01,  1.42s/it][A
 30%|███       | 18/60 [00:26<00:49,  1.19s/it][A
 32%|███▏      | 19/60 [00:27<00:49,  1.21s/it][A
 33%|███▎      | 20/60 [00:28<00:41,  1.05s/it][A
 35%|███▌      | 21/60 [00:29<00:40,  1.03s/it][A
 37%|███▋      | 22/60 [00:30<00:42,  1.11s/it][A
 38%|███▊      | 23/60 [00:31<00:41,  1.12s/it][A
 40%|████      | 24/60 [00:32<00:39,  1.10s/it][A
 42%|████▏     | 25/60 [00:34<00:44,  1.26s/it][A
 43%|████▎     | 26/60 [00:35<00:44,  1.32s/it][A
 45%|████▌     | 27/60 [00:36<00:38,  1.15s/it][A
 47%|████▋     | 28/60 [00:37<00:34,  1.09s/it][A
 48%|████▊     | 29/60 [00:38<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:40<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:42<00:39,  1.37s/it][A
 53%|█████▎    | 32/60 [00:43<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:44<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:45<00:31,  1.21s/it][A
 58%|█████▊    | 35/60 [00:46<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:48<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:48<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:50<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:51<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:52<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:53<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:55<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:56<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:57<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:58<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [01:00<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:02<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:02<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:04<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:06<00:14,  1.44s/it][A
 85%|████████▌ | 51/60 [01:07<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:08<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:09<00:09,  1.32s/it][A
 90%|█████████ | 54/60 [01:11<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:12<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:13<00:05,  1.32s/it][A
 95%|█████████▌| 57/60 [01:15<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [01:16<00:02,  1.40s/it][A
 98%|█████████▊| 59/60 [01:18<00:01,  1.46s/it][A
100%|██████████| 60/60 [01:20<00:00,  1.51s/it][A                                                       
                                               [A{'eval_loss': 0.45017009973526, 'eval_runtime': 81.7588, 'eval_samples_per_second': 11.656, 'eval_steps_per_second': 0.734, 'eval_rewards/chosen': -0.20537109673023224, 'eval_rewards/rejected': -25.75618553161621, 'eval_rewards/accuracies': 0.835069477558136, 'eval_rewards/margins': 25.57421875, 'eval_logps/chosen': -379.70001220703125, 'eval_logps/rejected': -409.5916748046875, 'eval_logits/chosen': -11.387499809265137, 'eval_logits/rejected': -11.276562690734863, 'epoch': 1.33}
 44%|████▍     | 2016/4545 [2:31:55<2:39:36,  3.79s/it]
100%|██████████| 60/60 [01:20<00:00,  1.51s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 44%|████▍     | 2017/4545 [2:32:11<22:21:51, 31.85s/it] 44%|████▍     | 2018/4545 [2:32:14<16:24:55, 23.39s/it] 44%|████▍     | 2019/4545 [2:32:18<12:21:30, 17.61s/it] 44%|████▍     | 2020/4545 [2:32:22<9:30:21, 13.55s/it]                                                        {'loss': 0.0718, 'grad_norm': 12.331316947937012, 'learning_rate': 3.7590011766293607e-06, 'rewards/chosen': 0.32246094942092896, 'rewards/rejected': -31.6875, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 31.975000381469727, 'logps/chosen': -317.75, 'logps/rejected': -470.20001220703125, 'logits/chosen': -11.768750190734863, 'logits/rejected': -11.487500190734863, 'epoch': 1.33}
 44%|████▍     | 2020/4545 [2:32:23<9:30:21, 13.55s/it] 44%|████▍     | 2021/4545 [2:32:26<7:29:07, 10.68s/it] 44%|████▍     | 2022/4545 [2:32:30<6:02:42,  8.63s/it] 45%|████▍     | 2023/4545 [2:32:34<4:57:57,  7.09s/it] 45%|████▍     | 2024/4545 [2:32:38<4:21:13,  6.22s/it] 45%|████▍     | 2025/4545 [2:32:42<3:53:46,  5.57s/it] 45%|████▍     | 2026/4545 [2:32:45<3:27:34,  4.94s/it] 45%|████▍     | 2027/4545 [2:32:50<3:17:18,  4.70s/it] 45%|████▍     | 2028/4545 [2:32:52<2:51:28,  4.09s/it] 45%|████▍     | 2029/4545 [2:32:56<2:52:38,  4.12s/it] 45%|████▍     | 2030/4545 [2:33:00<2:46:50,  3.98s/it]                                                       {'loss': 0.0943, 'grad_norm': 25.00748062133789, 'learning_rate': 3.7495920087772166e-06, 'rewards/chosen': 0.06328125298023224, 'rewards/rejected': -35.712501525878906, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 35.775001525878906, 'logps/chosen': -335.3500061035156, 'logps/rejected': -555.4000244140625, 'logits/chosen': -12.087499618530273, 'logits/rejected': -11.662500381469727, 'epoch': 1.34}
 45%|████▍     | 2030/4545 [2:33:00<2:46:50,  3.98s/it] 45%|████▍     | 2031/4545 [2:33:04<2:48:49,  4.03s/it] 45%|████▍     | 2032/4545 [2:33:33<8:00:07, 11.46s/it] 45%|████▍     | 2033/4545 [2:33:37<6:26:04,  9.22s/it] 45%|████▍     | 2034/4545 [2:33:41<5:19:13,  7.63s/it] 45%|████▍     | 2035/4545 [2:33:45<4:32:23,  6.51s/it] 45%|████▍     | 2036/4545 [2:33:49<4:00:13,  5.74s/it] 45%|████▍     | 2037/4545 [2:33:53<3:37:04,  5.19s/it] 45%|████▍     | 2038/4545 [2:33:56<3:15:34,  4.68s/it] 45%|████▍     | 2039/4545 [2:34:00<3:06:09,  4.46s/it] 45%|████▍     | 2040/4545 [2:34:04<3:02:30,  4.37s/it]                                                       {'loss': 0.1928, 'grad_norm': 11.279496192932129, 'learning_rate': 3.7400163688654727e-06, 'rewards/chosen': 0.852343738079071, 'rewards/rejected': -26.481250762939453, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 27.362499237060547, 'logps/chosen': -353.8500061035156, 'logps/rejected': -451.5, 'logits/chosen': -12.206250190734863, 'logits/rejected': -11.943750381469727, 'epoch': 1.35}
 45%|████▍     | 2040/4545 [2:34:04<3:02:30,  4.37s/it] 45%|████▍     | 2041/4545 [2:34:08<2:54:30,  4.18s/it] 45%|████▍     | 2042/4545 [2:34:37<8:05:33, 11.64s/it] 45%|████▍     | 2043/4545 [2:34:41<6:28:43,  9.32s/it] 45%|████▍     | 2044/4545 [2:34:45<5:21:02,  7.70s/it] 45%|████▍     | 2045/4545 [2:34:49<4:33:07,  6.55s/it] 45%|████▌     | 2046/4545 [2:34:52<3:53:14,  5.60s/it] 45%|████▌     | 2047/4545 [2:34:56<3:32:56,  5.11s/it] 45%|████▌     | 2048/4545 [2:35:00<3:18:56,  4.78s/it] 45%|████▌     | 2049/4545 [2:35:03<2:54:20,  4.19s/it] 45%|████▌     | 2050/4545 [2:35:07<2:45:54,  3.99s/it]                                                       {'loss': 0.1171, 'grad_norm': 20.586843490600586, 'learning_rate': 3.7302752856013584e-06, 'rewards/chosen': -0.934374988079071, 'rewards/rejected': -35.962501525878906, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 35.03125, 'logps/chosen': -260.3999938964844, 'logps/rejected': -510.6000061035156, 'logits/chosen': -12.399999618530273, 'logits/rejected': -11.856249809265137, 'epoch': 1.35}
 45%|████▌     | 2050/4545 [2:35:07<2:45:54,  3.99s/it] 45%|████▌     | 2051/4545 [2:35:10<2:42:14,  3.90s/it] 45%|████▌     | 2052/4545 [2:35:14<2:40:25,  3.86s/it] 45%|████▌     | 2053/4545 [2:35:18<2:41:03,  3.88s/it] 45%|████▌     | 2054/4545 [2:35:22<2:41:31,  3.89s/it] 45%|████▌     | 2055/4545 [2:35:26<2:41:47,  3.90s/it] 45%|████▌     | 2056/4545 [2:35:29<2:28:45,  3.59s/it] 45%|████▌     | 2057/4545 [2:35:33<2:32:39,  3.68s/it] 45%|████▌     | 2058/4545 [2:35:36<2:35:24,  3.75s/it] 45%|████▌     | 2059/4545 [2:35:40<2:37:17,  3.80s/it] 45%|████▌     | 2060/4545 [2:35:43<2:22:31,  3.44s/it]                                                       {'loss': 0.0963, 'grad_norm': 27.51783561706543, 'learning_rate': 3.7203698054656128e-06, 'rewards/chosen': 1.8359375, 'rewards/rejected': -31.056249618530273, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 32.90625, 'logps/chosen': -396.8999938964844, 'logps/rejected': -467.79998779296875, 'logits/chosen': -11.956250190734863, 'logits/rejected': -11.524999618530273, 'epoch': 1.36}
 45%|████▌     | 2060/4545 [2:35:43<2:22:31,  3.44s/it] 45%|████▌     | 2061/4545 [2:35:47<2:31:16,  3.65s/it] 45%|████▌     | 2062/4545 [2:35:51<2:34:23,  3.73s/it] 45%|████▌     | 2063/4545 [2:35:55<2:36:41,  3.79s/it] 45%|████▌     | 2064/4545 [2:35:59<2:38:56,  3.84s/it] 45%|████▌     | 2065/4545 [2:36:02<2:32:57,  3.70s/it] 45%|████▌     | 2066/4545 [2:36:06<2:27:58,  3.58s/it] 45%|████▌     | 2067/4545 [2:36:10<2:35:52,  3.77s/it] 46%|████▌     | 2068/4545 [2:36:14<2:37:23,  3.81s/it] 46%|████▌     | 2069/4545 [2:36:18<2:40:40,  3.89s/it] 46%|████▌     | 2070/4545 [2:36:22<2:40:43,  3.90s/it]                                                       {'loss': 0.1057, 'grad_norm': 33.110443115234375, 'learning_rate': 3.7103009926000696e-06, 'rewards/chosen': -2.3929686546325684, 'rewards/rejected': -34.8125, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 32.415626525878906, 'logps/chosen': -236.60000610351562, 'logps/rejected': -508.0, 'logits/chosen': -12.53125, 'logits/rejected': -12.0625, 'epoch': 1.37}
 46%|████▌     | 2070/4545 [2:36:22<2:40:43,  3.90s/it] 46%|████▌     | 2071/4545 [2:36:26<2:42:06,  3.93s/it] 46%|████▌     | 2072/4545 [2:36:29<2:36:14,  3.79s/it] 46%|████▌     | 2073/4545 [2:36:33<2:37:45,  3.83s/it] 46%|████▌     | 2074/4545 [2:36:36<2:29:33,  3.63s/it] 46%|████▌     | 2075/4545 [2:36:40<2:31:40,  3.68s/it] 46%|████▌     | 2076/4545 [2:36:43<2:28:13,  3.60s/it] 46%|████▌     | 2077/4545 [2:36:47<2:30:58,  3.67s/it] 46%|████▌     | 2078/4545 [2:36:51<2:34:01,  3.75s/it] 46%|████▌     | 2079/4545 [2:36:55<2:32:28,  3.71s/it] 46%|████▌     | 2080/4545 [2:36:58<2:22:42,  3.47s/it]                                                       {'loss': 0.1765, 'grad_norm': 21.689590454101562, 'learning_rate': 3.700069928693331e-06, 'rewards/chosen': -2.5458984375, 'rewards/rejected': -33.806251525878906, 'rewards/accuracies': 0.9375, 'rewards/margins': 31.287500381469727, 'logps/chosen': -184.1999969482422, 'logps/rejected': -441.1000061035156, 'logits/chosen': -12.274999618530273, 'logits/rejected': -11.793749809265137, 'epoch': 1.37}
 46%|████▌     | 2080/4545 [2:36:58<2:22:42,  3.47s/it] 46%|████▌     | 2081/4545 [2:37:00<2:10:23,  3.17s/it] 46%|████▌     | 2082/4545 [2:37:04<2:12:50,  3.24s/it] 46%|████▌     | 2083/4545 [2:37:08<2:21:34,  3.45s/it] 46%|████▌     | 2084/4545 [2:37:11<2:27:08,  3.59s/it] 46%|████▌     | 2085/4545 [2:37:16<2:34:46,  3.77s/it] 46%|████▌     | 2086/4545 [2:37:20<2:36:17,  3.81s/it] 46%|████▌     | 2087/4545 [2:37:24<2:37:38,  3.85s/it] 46%|████▌     | 2088/4545 [2:37:27<2:38:22,  3.87s/it] 46%|████▌     | 2089/4545 [2:37:31<2:37:32,  3.85s/it] 46%|████▌     | 2090/4545 [2:37:35<2:34:54,  3.79s/it]                                                       {'loss': 0.1377, 'grad_norm': 35.072654724121094, 'learning_rate': 3.689677712864566e-06, 'rewards/chosen': 0.965624988079071, 'rewards/rejected': -23.493749618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 24.46875, 'logps/chosen': -332.04998779296875, 'logps/rejected': -460.70001220703125, 'logits/chosen': -11.550000190734863, 'logits/rejected': -11.1875, 'epoch': 1.38}
 46%|████▌     | 2090/4545 [2:37:35<2:34:54,  3.79s/it] 46%|████▌     | 2091/4545 [2:37:39<2:33:41,  3.76s/it] 46%|████▌     | 2092/4545 [2:37:42<2:29:33,  3.66s/it] 46%|████▌     | 2093/4545 [2:37:46<2:32:56,  3.74s/it] 46%|████▌     | 2094/4545 [2:37:50<2:38:41,  3.88s/it] 46%|████▌     | 2095/4545 [2:37:54<2:35:12,  3.80s/it] 46%|████▌     | 2096/4545 [2:37:58<2:36:33,  3.84s/it] 46%|████▌     | 2097/4545 [2:38:02<2:37:23,  3.86s/it] 46%|████▌     | 2098/4545 [2:38:05<2:38:03,  3.88s/it] 46%|████▌     | 2099/4545 [2:38:09<2:38:59,  3.90s/it] 46%|████▌     | 2100/4545 [2:38:13<2:38:52,  3.90s/it]                                                       {'loss': 0.1826, 'grad_norm': 1.3794611692428589, 'learning_rate': 3.679125461545431e-06, 'rewards/chosen': 2.3921875953674316, 'rewards/rejected': -21.553125381469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 23.962499618530273, 'logps/chosen': -392.3999938964844, 'logps/rejected': -420.79998779296875, 'logits/chosen': -11.324999809265137, 'logits/rejected': -11.131250381469727, 'epoch': 1.39}
 46%|████▌     | 2100/4545 [2:38:13<2:38:52,  3.90s/it] 46%|████▌     | 2101/4545 [2:38:17<2:41:38,  3.97s/it] 46%|████▌     | 2102/4545 [2:38:21<2:40:56,  3.95s/it] 46%|████▋     | 2103/4545 [2:38:25<2:40:08,  3.93s/it] 46%|████▋     | 2104/4545 [2:38:29<2:39:51,  3.93s/it] 46%|████▋     | 2105/4545 [2:38:33<2:40:04,  3.94s/it] 46%|████▋     | 2106/4545 [2:38:37<2:39:56,  3.93s/it] 46%|████▋     | 2107/4545 [2:38:41<2:41:55,  3.99s/it] 46%|████▋     | 2108/4545 [2:38:45<2:41:19,  3.97s/it] 46%|████▋     | 2109/4545 [2:38:49<2:40:42,  3.96s/it] 46%|████▋     | 2110/4545 [2:38:53<2:40:10,  3.95s/it]                                                       {'loss': 0.0952, 'grad_norm': 14.765138626098633, 'learning_rate': 3.6684143083601314e-06, 'rewards/chosen': 3.884960889816284, 'rewards/rejected': -25.993749618530273, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 29.850000381469727, 'logps/chosen': -487.20001220703125, 'logps/rejected': -525.2000122070312, 'logits/chosen': -11.231249809265137, 'logits/rejected': -11.03125, 'epoch': 1.39}
 46%|████▋     | 2110/4545 [2:38:53<2:40:10,  3.95s/it] 46%|████▋     | 2111/4545 [2:38:57<2:43:21,  4.03s/it] 46%|████▋     | 2112/4545 [2:39:00<2:34:05,  3.80s/it] 46%|████▋     | 2113/4545 [2:39:04<2:35:15,  3.83s/it] 47%|████▋     | 2114/4545 [2:39:08<2:36:45,  3.87s/it] 47%|████▋     | 2115/4545 [2:39:12<2:37:17,  3.88s/it] 47%|████▋     | 2116/4545 [2:39:16<2:37:32,  3.89s/it] 47%|████▋     | 2117/4545 [2:39:19<2:30:55,  3.73s/it] 47%|████▋     | 2118/4545 [2:39:23<2:34:09,  3.81s/it] 47%|████▋     | 2119/4545 [2:39:28<2:38:37,  3.92s/it] 47%|████▋     | 2120/4545 [2:39:31<2:33:40,  3.80s/it]                                                       {'loss': 0.1484, 'grad_norm': 19.92344093322754, 'learning_rate': 3.6575454040036385e-06, 'rewards/chosen': 1.7234375476837158, 'rewards/rejected': -28.712499618530273, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 30.418750762939453, 'logps/chosen': -396.79998779296875, 'logps/rejected': -496.6000061035156, 'logits/chosen': -11.918749809265137, 'logits/rejected': -11.556249618530273, 'epoch': 1.4}
 47%|████▋     | 2120/4545 [2:39:31<2:33:40,  3.80s/it] 47%|████▋     | 2121/4545 [2:39:35<2:35:08,  3.84s/it] 47%|████▋     | 2122/4545 [2:39:39<2:36:08,  3.87s/it] 47%|████▋     | 2123/4545 [2:39:42<2:30:32,  3.73s/it] 47%|████▋     | 2124/4545 [2:39:47<2:35:04,  3.84s/it] 47%|████▋     | 2125/4545 [2:39:51<2:37:21,  3.90s/it] 47%|████▋     | 2126/4545 [2:39:54<2:27:30,  3.66s/it] 47%|████▋     | 2127/4545 [2:39:58<2:30:25,  3.73s/it] 47%|████▋     | 2128/4545 [2:40:02<2:32:19,  3.78s/it] 47%|████▋     | 2129/4545 [2:40:05<2:33:45,  3.82s/it] 47%|████▋     | 2130/4545 [2:40:09<2:34:57,  3.85s/it]                                                       {'loss': 0.1789, 'grad_norm': 1.203028678894043, 'learning_rate': 3.6465199161180696e-06, 'rewards/chosen': 0.41093748807907104, 'rewards/rejected': -32.681251525878906, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 33.09375, 'logps/chosen': -352.54998779296875, 'logps/rejected': -464.5, 'logits/chosen': -11.831250190734863, 'logits/rejected': -11.425000190734863, 'epoch': 1.41}
 47%|████▋     | 2130/4545 [2:40:09<2:34:57,  3.85s/it] 47%|████▋     | 2131/4545 [2:40:13<2:35:48,  3.87s/it] 47%|████▋     | 2132/4545 [2:40:17<2:32:41,  3.80s/it] 47%|████▋     | 2133/4545 [2:40:21<2:34:15,  3.84s/it] 47%|████▋     | 2134/4545 [2:40:25<2:35:02,  3.86s/it] 47%|████▋     | 2135/4545 [2:40:29<2:35:43,  3.88s/it] 47%|████▋     | 2136/4545 [2:40:33<2:36:21,  3.89s/it] 47%|████▋     | 2137/4545 [2:40:36<2:35:27,  3.87s/it] 47%|████▋     | 2138/4545 [2:40:40<2:36:01,  3.89s/it] 47%|████▋     | 2139/4545 [2:40:43<2:26:46,  3.66s/it] 47%|████▋     | 2140/4545 [2:40:47<2:29:52,  3.74s/it]                                                       {'loss': 0.1385, 'grad_norm': 16.844995498657227, 'learning_rate': 3.6353390291672485e-06, 'rewards/chosen': 3.311328172683716, 'rewards/rejected': -29.962499618530273, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 33.25, 'logps/chosen': -482.0, 'logps/rejected': -540.4000244140625, 'logits/chosen': -11.212499618530273, 'logits/rejected': -10.993749618530273, 'epoch': 1.41}
 47%|████▋     | 2140/4545 [2:40:47<2:29:52,  3.74s/it] 47%|████▋     | 2141/4545 [2:40:51<2:31:56,  3.79s/it] 47%|████▋     | 2142/4545 [2:40:55<2:33:25,  3.83s/it] 47%|████▋     | 2143/4545 [2:40:58<2:21:56,  3.55s/it] 47%|████▋     | 2144/4545 [2:41:01<2:12:03,  3.30s/it] 47%|████▋     | 2145/4545 [2:41:05<2:19:05,  3.48s/it] 47%|████▋     | 2146/4545 [2:41:09<2:24:19,  3.61s/it] 47%|████▋     | 2147/4545 [2:41:12<2:26:59,  3.68s/it] 47%|████▋     | 2148/4545 [2:41:16<2:29:49,  3.75s/it] 47%|████▋     | 2149/4545 [2:41:20<2:24:45,  3.63s/it] 47%|████▋     | 2150/4545 [2:41:24<2:28:10,  3.71s/it]                                                       {'loss': 0.0475, 'grad_norm': 10.464784622192383, 'learning_rate': 3.6240039443094595e-06, 'rewards/chosen': -0.8851562738418579, 'rewards/rejected': -32.92499923706055, 'rewards/accuracies': 0.96875, 'rewards/margins': 32.037498474121094, 'logps/chosen': -236.89999389648438, 'logps/rejected': -432.1000061035156, 'logits/chosen': -11.712499618530273, 'logits/rejected': -11.0625, 'epoch': 1.42}
 47%|████▋     | 2150/4545 [2:41:24<2:28:10,  3.71s/it] 47%|████▋     | 2151/4545 [2:41:28<2:33:46,  3.85s/it] 47%|████▋     | 2152/4545 [2:41:32<2:34:32,  3.87s/it] 47%|████▋     | 2153/4545 [2:41:36<2:34:39,  3.88s/it] 47%|████▋     | 2154/4545 [2:41:39<2:25:43,  3.66s/it] 47%|████▋     | 2155/4545 [2:41:43<2:28:53,  3.74s/it] 47%|████▋     | 2156/4545 [2:41:45<2:11:41,  3.31s/it] 47%|████▋     | 2157/4545 [2:41:49<2:21:01,  3.54s/it] 47%|████▋     | 2158/4545 [2:41:53<2:27:04,  3.70s/it] 48%|████▊     | 2159/4545 [2:41:56<2:17:18,  3.45s/it] 48%|████▊     | 2160/4545 [2:42:00<2:23:32,  3.61s/it]                                                       {'loss': 0.1187, 'grad_norm': 21.777036666870117, 'learning_rate': 3.6125158792684068e-06, 'rewards/chosen': 1.1593749523162842, 'rewards/rejected': -25.806249618530273, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 26.975000381469727, 'logps/chosen': -354.5, 'logps/rejected': -405.8999938964844, 'logits/chosen': -11.225000381469727, 'logits/rejected': -10.918749809265137, 'epoch': 1.43}
 48%|████▊     | 2160/4545 [2:42:00<2:23:32,  3.61s/it] 48%|████▊     | 2161/4545 [2:42:04<2:23:55,  3.62s/it] 48%|████▊     | 2162/4545 [2:42:08<2:27:23,  3.71s/it] 48%|████▊     | 2163/4545 [2:42:12<2:32:04,  3.83s/it] 48%|████▊     | 2164/4545 [2:42:16<2:33:13,  3.86s/it] 48%|████▊     | 2165/4545 [2:42:20<2:36:51,  3.95s/it] 48%|████▊     | 2166/4545 [2:42:24<2:35:58,  3.93s/it] 48%|████▊     | 2167/4545 [2:42:27<2:22:47,  3.60s/it] 48%|████▊     | 2168/4545 [2:42:30<2:26:30,  3.70s/it] 48%|████▊     | 2169/4545 [2:42:59<7:26:10, 11.27s/it] 48%|████▊     | 2170/4545 [2:43:03<5:54:16,  8.95s/it]                                                       {'loss': 0.1185, 'grad_norm': 22.505380630493164, 'learning_rate': 3.600876068202398e-06, 'rewards/chosen': -0.18007811903953552, 'rewards/rejected': -32.54999923706055, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 32.337501525878906, 'logps/chosen': -285.1000061035156, 'logps/rejected': -443.79998779296875, 'logits/chosen': -11.756250381469727, 'logits/rejected': -11.318750381469727, 'epoch': 1.43}
 48%|████▊     | 2170/4545 [2:43:03<5:54:16,  8.95s/it] 48%|████▊     | 2171/4545 [2:43:07<4:55:07,  7.46s/it] 48%|████▊     | 2172/4545 [2:43:11<4:16:35,  6.49s/it] 48%|████▊     | 2173/4545 [2:43:15<3:41:28,  5.60s/it] 48%|████▊     | 2174/4545 [2:43:19<3:21:20,  5.09s/it] 48%|████▊     | 2175/4545 [2:43:22<2:59:15,  4.54s/it] 48%|████▊     | 2176/4545 [2:43:26<2:53:45,  4.40s/it] 48%|████▊     | 2177/4545 [2:43:30<2:48:00,  4.26s/it] 48%|████▊     | 2178/4545 [2:43:34<2:43:54,  4.15s/it] 48%|████▊     | 2179/4545 [2:43:37<2:29:31,  3.79s/it] 48%|████▊     | 2180/4545 [2:43:41<2:31:01,  3.83s/it]                                                       {'loss': 0.0771, 'grad_norm': 6.725559234619141, 'learning_rate': 3.589085761571753e-06, 'rewards/chosen': 0.3843750059604645, 'rewards/rejected': -30.899999618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 31.299999237060547, 'logps/chosen': -340.6499938964844, 'logps/rejected': -442.79998779296875, 'logits/chosen': -11.649999618530273, 'logits/rejected': -11.193750381469727, 'epoch': 1.44}
 48%|████▊     | 2180/4545 [2:43:41<2:31:01,  3.83s/it] 48%|████▊     | 2181/4545 [2:43:44<2:31:50,  3.85s/it] 48%|████▊     | 2182/4545 [2:43:48<2:29:02,  3.78s/it] 48%|████▊     | 2183/4545 [2:43:52<2:32:29,  3.87s/it] 48%|████▊     | 2184/4545 [2:43:56<2:33:04,  3.89s/it] 48%|████▊     | 2185/4545 [2:44:00<2:37:08,  4.00s/it] 48%|████▊     | 2186/4545 [2:44:04<2:36:55,  3.99s/it] 48%|████▊     | 2187/4545 [2:44:08<2:36:02,  3.97s/it] 48%|████▊     | 2188/4545 [2:44:12<2:29:03,  3.79s/it] 48%|████▊     | 2189/4545 [2:44:15<2:27:10,  3.75s/it] 48%|████▊     | 2190/4545 [2:44:19<2:22:35,  3.63s/it]                                                       {'loss': 0.0905, 'grad_norm': 4.2865986824035645, 'learning_rate': 3.577146226004473e-06, 'rewards/chosen': -1.178125023841858, 'rewards/rejected': -30.818750381469727, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 29.643749237060547, 'logps/chosen': -264.29998779296875, 'logps/rejected': -470.0, 'logits/chosen': -11.637499809265137, 'logits/rejected': -11.175000190734863, 'epoch': 1.45}
 48%|████▊     | 2190/4545 [2:44:19<2:22:35,  3.63s/it] 48%|████▊     | 2191/4545 [2:44:23<2:26:23,  3.73s/it] 48%|████▊     | 2192/4545 [2:44:27<2:28:16,  3.78s/it] 48%|████▊     | 2193/4545 [2:44:30<2:29:27,  3.81s/it] 48%|████▊     | 2194/4545 [2:44:35<2:32:55,  3.90s/it] 48%|████▊     | 2195/4545 [2:44:38<2:33:02,  3.91s/it] 48%|████▊     | 2196/4545 [2:44:42<2:33:15,  3.91s/it] 48%|████▊     | 2197/4545 [2:44:46<2:33:27,  3.92s/it] 48%|████▊     | 2198/4545 [2:44:50<2:33:24,  3.92s/it] 48%|████▊     | 2199/4545 [2:44:54<2:30:44,  3.86s/it] 48%|████▊     | 2200/4545 [2:44:58<2:31:53,  3.89s/it]                                                       {'loss': 0.2046, 'grad_norm': 5.8364787101745605, 'learning_rate': 3.5650587441601657e-06, 'rewards/chosen': -0.2520507872104645, 'rewards/rejected': -39.162498474121094, 'rewards/accuracies': 0.9375, 'rewards/margins': 38.9375, 'logps/chosen': -452.54998779296875, 'logps/rejected': -623.2000122070312, 'logits/chosen': -11.237500190734863, 'logits/rejected': -10.881250381469727, 'epoch': 1.45}
 48%|████▊     | 2200/4545 [2:44:58<2:31:53,  3.89s/it] 48%|████▊     | 2201/4545 [2:45:01<2:24:20,  3.69s/it] 48%|████▊     | 2202/4545 [2:45:04<2:20:11,  3.59s/it] 48%|████▊     | 2203/4545 [2:45:07<2:13:35,  3.42s/it] 48%|████▊     | 2204/4545 [2:45:11<2:16:46,  3.51s/it] 49%|████▊     | 2205/4545 [2:45:15<2:24:48,  3.71s/it] 49%|████▊     | 2206/4545 [2:45:19<2:23:40,  3.69s/it] 49%|████▊     | 2207/4545 [2:45:23<2:26:10,  3.75s/it] 49%|████▊     | 2208/4545 [2:45:27<2:31:18,  3.88s/it] 49%|████▊     | 2209/4545 [2:45:31<2:31:40,  3.90s/it] 49%|████▊     | 2210/4545 [2:45:35<2:31:44,  3.90s/it]                                                       {'loss': 0.1254, 'grad_norm': 33.18953323364258, 'learning_rate': 3.5528246145922465e-06, 'rewards/chosen': -2.1695313453674316, 'rewards/rejected': -35.162498474121094, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 32.974998474121094, 'logps/chosen': -259.75, 'logps/rejected': -475.0, 'logits/chosen': -11.65625, 'logits/rejected': -11.043749809265137, 'epoch': 1.46}
 49%|████▊     | 2210/4545 [2:45:35<2:31:44,  3.90s/it] 49%|████▊     | 2211/4545 [2:45:39<2:32:03,  3.91s/it] 49%|████▊     | 2212/4545 [2:45:43<2:32:16,  3.92s/it] 49%|████▊     | 2213/4545 [2:45:47<2:33:05,  3.94s/it] 49%|████▊     | 2214/4545 [2:45:51<2:31:24,  3.90s/it] 49%|████▊     | 2215/4545 [2:45:54<2:26:20,  3.77s/it] 49%|████▉     | 2216/4545 [2:45:58<2:28:04,  3.81s/it] 49%|████▉     | 2217/4545 [2:46:02<2:31:20,  3.90s/it] 49%|████▉     | 2218/4545 [2:46:06<2:31:23,  3.90s/it] 49%|████▉     | 2219/4545 [2:46:10<2:31:26,  3.91s/it] 49%|████▉     | 2220/4545 [2:46:14<2:31:25,  3.91s/it]                                                       {'loss': 0.0837, 'grad_norm': 15.87479305267334, 'learning_rate': 3.5404451516084407e-06, 'rewards/chosen': -0.12226562201976776, 'rewards/rejected': -25.40625, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 25.287500381469727, 'logps/chosen': -335.0, 'logps/rejected': -418.8999938964844, 'logits/chosen': -11.199999809265137, 'logits/rejected': -10.899999618530273, 'epoch': 1.47}
 49%|████▉     | 2220/4545 [2:46:14<2:31:25,  3.91s/it] 49%|████▉     | 2221/4545 [2:46:17<2:28:37,  3.84s/it] 49%|████▉     | 2222/4545 [2:46:21<2:25:48,  3.77s/it] 49%|████▉     | 2223/4545 [2:46:25<2:27:33,  3.81s/it] 49%|████▉     | 2224/4545 [2:46:29<2:28:49,  3.85s/it] 49%|████▉     | 2225/4545 [2:46:33<2:29:23,  3.86s/it] 49%|████▉     | 2226/4545 [2:46:37<2:29:54,  3.88s/it] 49%|████▉     | 2227/4545 [2:46:40<2:27:19,  3.81s/it] 49%|████▉     | 2228/4545 [2:46:44<2:28:19,  3.84s/it] 49%|████▉     | 2229/4545 [2:46:47<2:16:01,  3.52s/it] 49%|████▉     | 2230/4545 [2:46:51<2:20:36,  3.64s/it]                                                       {'loss': 0.0875, 'grad_norm': 4.37287712097168, 'learning_rate': 3.5279216851295837e-06, 'rewards/chosen': 0.0003906250058207661, 'rewards/rejected': -33.23749923706055, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 33.256248474121094, 'logps/chosen': -398.6000061035156, 'logps/rejected': -536.7999877929688, 'logits/chosen': -10.84375, 'logits/rejected': -10.381250381469727, 'epoch': 1.47}
 49%|████▉     | 2230/4545 [2:46:51<2:20:36,  3.64s/it] 49%|████▉     | 2231/4545 [2:46:55<2:23:48,  3.73s/it] 49%|████▉     | 2232/4545 [2:46:59<2:23:49,  3.73s/it] 49%|████▉     | 2233/4545 [2:47:03<2:26:42,  3.81s/it] 49%|████▉     | 2234/4545 [2:47:07<2:28:00,  3.84s/it] 49%|████▉     | 2235/4545 [2:47:10<2:19:33,  3.63s/it] 49%|████▉     | 2236/4545 [2:47:14<2:26:33,  3.81s/it] 49%|████▉     | 2237/4545 [2:47:18<2:27:51,  3.84s/it] 49%|████▉     | 2238/4545 [2:47:22<2:28:39,  3.87s/it] 49%|████▉     | 2239/4545 [2:47:26<2:29:22,  3.89s/it] 49%|████▉     | 2240/4545 [2:47:28<2:15:07,  3.52s/it]                                                       {'loss': 0.0521, 'grad_norm': 3.2124860286712646, 'learning_rate': 3.5152555605467506e-06, 'rewards/chosen': -0.4771484434604645, 'rewards/rejected': -26.681249618530273, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 26.168750762939453, 'logps/chosen': -339.1499938964844, 'logps/rejected': -421.5, 'logits/chosen': -11.412500381469727, 'logits/rejected': -11.056249618530273, 'epoch': 1.48}
 49%|████▉     | 2240/4545 [2:47:28<2:15:07,  3.52s/it] 49%|████▉     | 2241/4545 [2:47:32<2:20:23,  3.66s/it] 49%|████▉     | 2242/4545 [2:47:36<2:14:42,  3.51s/it] 49%|████▉     | 2243/4545 [2:47:39<2:16:34,  3.56s/it] 49%|████▉     | 2244/4545 [2:47:42<2:04:18,  3.24s/it] 49%|████▉     | 2245/4545 [2:47:46<2:12:19,  3.45s/it] 49%|████▉     | 2246/4545 [2:47:50<2:18:52,  3.62s/it] 49%|████▉     | 2247/4545 [2:47:54<2:22:13,  3.71s/it] 49%|████▉     | 2248/4545 [2:47:58<2:24:36,  3.78s/it] 49%|████▉     | 2249/4545 [2:48:02<2:27:39,  3.86s/it] 50%|████▉     | 2250/4545 [2:48:06<2:31:46,  3.97s/it]                                                       {'loss': 0.1586, 'grad_norm': 4.789372444152832, 'learning_rate': 3.50244813857672e-06, 'rewards/chosen': -1.907476782798767, 'rewards/rejected': -36.275001525878906, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 34.375, 'logps/chosen': -323.1000061035156, 'logps/rejected': -527.7999877929688, 'logits/chosen': -11.268750190734863, 'logits/rejected': -10.824999809265137, 'epoch': 1.49}
 50%|████▉     | 2250/4545 [2:48:06<2:31:46,  3.97s/it] 50%|████▉     | 2251/4545 [2:48:10<2:33:17,  4.01s/it] 50%|████▉     | 2252/4545 [2:48:14<2:32:20,  3.99s/it] 50%|████▉     | 2253/4545 [2:48:17<2:25:26,  3.81s/it] 50%|████▉     | 2254/4545 [2:48:21<2:26:45,  3.84s/it] 50%|████▉     | 2255/4545 [2:48:24<2:18:37,  3.63s/it] 50%|████▉     | 2256/4545 [2:48:28<2:22:16,  3.73s/it] 50%|████▉     | 2257/4545 [2:48:32<2:25:58,  3.83s/it] 50%|████▉     | 2258/4545 [2:48:36<2:25:52,  3.83s/it] 50%|████▉     | 2259/4545 [2:48:40<2:26:41,  3.85s/it] 50%|████▉     | 2260/4545 [2:48:44<2:27:17,  3.87s/it]                                                       {'loss': 0.0913, 'grad_norm': 16.8850154876709, 'learning_rate': 3.489500795115793e-06, 'rewards/chosen': -0.9515625238418579, 'rewards/rejected': -23.975000381469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 23.024999618530273, 'logps/chosen': -321.8500061035156, 'logps/rejected': -413.20001220703125, 'logits/chosen': -11.293749809265137, 'logits/rejected': -10.981249809265137, 'epoch': 1.49}
 50%|████▉     | 2260/4545 [2:48:44<2:27:17,  3.87s/it] 50%|████▉     | 2261/4545 [2:48:47<2:17:23,  3.61s/it] 50%|████▉     | 2262/4545 [2:48:51<2:20:26,  3.69s/it] 50%|████▉     | 2263/4545 [2:48:55<2:27:03,  3.87s/it] 50%|████▉     | 2264/4545 [2:48:59<2:29:07,  3.92s/it] 50%|████▉     | 2265/4545 [2:49:03<2:25:56,  3.84s/it] 50%|████▉     | 2266/4545 [2:49:07<2:25:34,  3.83s/it] 50%|████▉     | 2267/4545 [2:49:11<2:26:49,  3.87s/it] 50%|████▉     | 2268/4545 [2:49:13<2:14:30,  3.54s/it] 50%|████▉     | 2269/4545 [2:49:18<2:22:05,  3.75s/it] 50%|████▉     | 2270/4545 [2:49:21<2:20:43,  3.71s/it]                                                       {'loss': 0.0923, 'grad_norm': 17.239648818969727, 'learning_rate': 3.476414921091983e-06, 'rewards/chosen': -2.7109375, 'rewards/rejected': -29.024999618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 26.315624237060547, 'logps/chosen': -204.6999969482422, 'logps/rejected': -392.3999938964844, 'logits/chosen': -11.212499618530273, 'logits/rejected': -10.881250381469727, 'epoch': 1.5}
 50%|████▉     | 2270/4545 [2:49:21<2:20:43,  3.71s/it] 50%|████▉     | 2271/4545 [2:49:25<2:25:12,  3.83s/it] 50%|████▉     | 2272/4545 [2:49:28<2:12:20,  3.49s/it] 50%|█████     | 2273/4545 [2:49:32<2:15:08,  3.57s/it] 50%|█████     | 2274/4545 [2:49:35<2:10:07,  3.44s/it] 50%|█████     | 2275/4545 [2:49:39<2:17:26,  3.63s/it] 50%|█████     | 2276/4545 [2:49:42<2:14:26,  3.56s/it] 50%|█████     | 2277/4545 [2:49:46<2:18:23,  3.66s/it] 50%|█████     | 2278/4545 [2:49:50<2:18:34,  3.67s/it] 50%|█████     | 2279/4545 [2:49:54<2:22:15,  3.77s/it] 50%|█████     | 2280/4545 [2:49:58<2:23:51,  3.81s/it]                                                       {'loss': 0.1161, 'grad_norm': 24.809261322021484, 'learning_rate': 3.463191922315583e-06, 'rewards/chosen': -2.1187500953674316, 'rewards/rejected': -24.100000381469727, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 22.006250381469727, 'logps/chosen': -236.85000610351562, 'logps/rejected': -333.20001220703125, 'logits/chosen': -10.887499809265137, 'logits/rejected': -10.574999809265137, 'epoch': 1.5}
 50%|█████     | 2280/4545 [2:49:58<2:23:51,  3.81s/it] 50%|█████     | 2281/4545 [2:50:02<2:25:11,  3.85s/it] 50%|█████     | 2282/4545 [2:50:05<2:18:25,  3.67s/it] 50%|█████     | 2283/4545 [2:50:09<2:21:20,  3.75s/it] 50%|█████     | 2284/4545 [2:50:13<2:23:16,  3.80s/it] 50%|█████     | 2285/4545 [2:50:16<2:18:35,  3.68s/it] 50%|█████     | 2286/4545 [2:50:20<2:21:07,  3.75s/it] 50%|█████     | 2287/4545 [2:50:24<2:23:28,  3.81s/it] 50%|█████     | 2288/4545 [2:50:28<2:24:42,  3.85s/it] 50%|█████     | 2289/4545 [2:50:32<2:25:28,  3.87s/it] 50%|█████     | 2290/4545 [2:50:36<2:26:11,  3.89s/it]                                                       {'loss': 0.0883, 'grad_norm': 4.013035297393799, 'learning_rate': 3.4498332193281494e-06, 'rewards/chosen': 1.7361328601837158, 'rewards/rejected': -28.662500381469727, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 30.375, 'logps/chosen': -437.25, 'logps/rejected': -513.7999877929688, 'logits/chosen': -10.612500190734863, 'logits/rejected': -10.324999809265137, 'epoch': 1.51}
 50%|█████     | 2290/4545 [2:50:36<2:26:11,  3.89s/it] 50%|█████     | 2291/4545 [2:50:39<2:21:31,  3.77s/it] 50%|█████     | 2292/4545 [2:50:43<2:17:57,  3.67s/it] 50%|█████     | 2293/4545 [2:50:47<2:23:24,  3.82s/it] 50%|█████     | 2294/4545 [2:50:51<2:24:59,  3.86s/it] 50%|█████     | 2295/4545 [2:50:55<2:25:42,  3.89s/it] 51%|█████     | 2296/4545 [2:50:59<2:25:57,  3.89s/it] 51%|█████     | 2297/4545 [2:51:03<2:23:16,  3.82s/it] 51%|█████     | 2298/4545 [2:51:07<2:26:43,  3.92s/it] 51%|█████     | 2299/4545 [2:51:11<2:26:36,  3.92s/it] 51%|█████     | 2300/4545 [2:51:15<2:28:47,  3.98s/it]                                                       {'loss': 0.06, 'grad_norm': 1.380729079246521, 'learning_rate': 3.4363402472498858e-06, 'rewards/chosen': 0.502001941204071, 'rewards/rejected': -31.71875, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 32.224998474121094, 'logps/chosen': -413.29998779296875, 'logps/rejected': -508.6000061035156, 'logits/chosen': -10.725000381469727, 'logits/rejected': -10.274999618530273, 'epoch': 1.52}
 51%|█████     | 2300/4545 [2:51:15<2:28:47,  3.98s/it] 51%|█████     | 2301/4545 [2:51:19<2:30:10,  4.02s/it] 51%|█████     | 2302/4545 [2:51:23<2:29:12,  3.99s/it] 51%|█████     | 2303/4545 [2:51:27<2:27:37,  3.95s/it] 51%|█████     | 2304/4545 [2:51:30<2:19:12,  3.73s/it] 51%|█████     | 2305/4545 [2:51:33<2:18:06,  3.70s/it] 51%|█████     | 2306/4545 [2:51:37<2:14:37,  3.61s/it] 51%|█████     | 2307/4545 [2:51:41<2:18:03,  3.70s/it] 51%|█████     | 2308/4545 [2:51:45<2:20:20,  3.76s/it] 51%|█████     | 2309/4545 [2:51:48<2:20:01,  3.76s/it] 51%|█████     | 2310/4545 [2:51:52<2:15:12,  3.63s/it]                                                       {'loss': 0.1891, 'grad_norm': 8.864151954650879, 'learning_rate': 3.4227144556254715e-06, 'rewards/chosen': -0.7890625, 'rewards/rejected': -23.549999237060547, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 22.78125, 'logps/chosen': -314.8999938964844, 'logps/rejected': -414.1000061035156, 'logits/chosen': -11.693750381469727, 'logits/rejected': -11.212499618530273, 'epoch': 1.52}
 51%|█████     | 2310/4545 [2:51:52<2:15:12,  3.63s/it] 51%|█████     | 2311/4545 [2:51:56<2:18:27,  3.72s/it] 51%|█████     | 2312/4545 [2:52:00<2:20:40,  3.78s/it] 51%|█████     | 2313/4545 [2:52:04<2:22:07,  3.82s/it] 51%|█████     | 2314/4545 [2:52:07<2:19:05,  3.74s/it] 51%|█████     | 2315/4545 [2:52:11<2:24:08,  3.88s/it] 51%|█████     | 2316/4545 [2:52:15<2:24:20,  3.89s/it] 51%|█████     | 2317/4545 [2:52:19<2:19:58,  3.77s/it] 51%|█████     | 2318/4545 [2:52:23<2:21:45,  3.82s/it] 51%|█████     | 2319/4545 [2:52:27<2:25:56,  3.93s/it] 51%|█████     | 2320/4545 [2:52:31<2:27:00,  3.96s/it]                                                       {'loss': 0.0989, 'grad_norm': 13.544112205505371, 'learning_rate': 3.4089573082683384e-06, 'rewards/chosen': 1.3346436023712158, 'rewards/rejected': -26.618749618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 27.924999237060547, 'logps/chosen': -431.8999938964844, 'logps/rejected': -512.4000244140625, 'logits/chosen': -11.725000381469727, 'logits/rejected': -11.318750381469727, 'epoch': 1.53}
 51%|█████     | 2320/4545 [2:52:31<2:27:00,  3.96s/it] 51%|█████     | 2321/4545 [2:52:35<2:24:34,  3.90s/it] 51%|█████     | 2322/4545 [2:52:39<2:24:48,  3.91s/it] 51%|█████     | 2323/4545 [2:52:42<2:25:01,  3.92s/it] 51%|█████     | 2324/4545 [2:52:46<2:24:53,  3.91s/it] 51%|█████     | 2325/4545 [2:52:50<2:25:06,  3.92s/it] 51%|█████     | 2326/4545 [2:52:55<2:28:27,  4.01s/it] 51%|█████     | 2327/4545 [2:52:58<2:27:22,  3.99s/it] 51%|█████     | 2328/4545 [2:53:02<2:26:43,  3.97s/it] 51%|█████     | 2329/4545 [2:53:07<2:28:22,  4.02s/it] 51%|█████▏    | 2330/4545 [2:53:10<2:27:20,  3.99s/it]                                                       {'loss': 0.0746, 'grad_norm': 4.366530418395996, 'learning_rate': 3.3950702831034115e-06, 'rewards/chosen': 1.605859398841858, 'rewards/rejected': -30.506250381469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 32.150001525878906, 'logps/chosen': -491.0, 'logps/rejected': -549.7999877929688, 'logits/chosen': -11.6875, 'logits/rejected': -11.431249618530273, 'epoch': 1.54}
 51%|█████▏    | 2330/4545 [2:53:10<2:27:20,  3.99s/it] 51%|█████▏    | 2331/4545 [2:53:14<2:26:43,  3.98s/it] 51%|█████▏    | 2332/4545 [2:53:18<2:25:53,  3.96s/it] 51%|█████▏    | 2333/4545 [2:53:22<2:27:41,  4.01s/it] 51%|█████▏    | 2334/4545 [2:53:26<2:17:38,  3.74s/it] 51%|█████▏    | 2335/4545 [2:53:29<2:19:41,  3.79s/it] 51%|█████▏    | 2336/4545 [2:53:33<2:13:45,  3.63s/it] 51%|█████▏    | 2337/4545 [2:53:35<1:58:48,  3.23s/it] 51%|█████▏    | 2338/4545 [2:53:39<2:08:42,  3.50s/it] 51%|█████▏    | 2339/4545 [2:53:43<2:13:54,  3.64s/it] 51%|█████▏    | 2340/4545 [2:53:47<2:17:02,  3.73s/it]                                                       {'loss': 0.0988, 'grad_norm': 0.7245957851409912, 'learning_rate': 3.3810548720083394e-06, 'rewards/chosen': -1.06640625, 'rewards/rejected': -26.681249618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 25.575000762939453, 'logps/chosen': -304.70001220703125, 'logps/rejected': -433.8999938964844, 'logits/chosen': -12.84375, 'logits/rejected': -12.28125, 'epoch': 1.54}
 51%|█████▏    | 2340/4545 [2:53:47<2:17:02,  3.73s/it] 52%|█████▏    | 2341/4545 [2:53:51<2:19:04,  3.79s/it] 52%|█████▏    | 2342/4545 [2:53:55<2:22:11,  3.87s/it] 52%|█████▏    | 2343/4545 [2:53:59<2:24:24,  3.93s/it] 52%|█████▏    | 2344/4545 [2:54:03<2:24:20,  3.93s/it] 52%|█████▏    | 2345/4545 [2:54:07<2:24:10,  3.93s/it] 52%|█████▏    | 2346/4545 [2:54:11<2:23:50,  3.92s/it] 52%|█████▏    | 2347/4545 [2:54:15<2:25:52,  3.98s/it] 52%|█████▏    | 2348/4545 [2:54:19<2:25:33,  3.98s/it] 52%|█████▏    | 2349/4545 [2:54:23<2:25:06,  3.96s/it] 52%|█████▏    | 2350/4545 [2:54:52<7:02:18, 11.54s/it]                                                       {'loss': 0.0923, 'grad_norm': 15.651391983032227, 'learning_rate': 3.3669125806532193e-06, 'rewards/chosen': 0.345703125, 'rewards/rejected': -27.118749618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 27.456249237060547, 'logps/chosen': -368.20001220703125, 'logps/rejected': -480.79998779296875, 'logits/chosen': -12.112500190734863, 'logits/rejected': -11.675000190734863, 'epoch': 1.55}
 52%|█████▏    | 2350/4545 [2:54:52<7:02:18, 11.54s/it] 52%|█████▏    | 2351/4545 [2:54:56<5:38:34,  9.26s/it] 52%|█████▏    | 2352/4545 [2:55:00<4:37:35,  7.59s/it] 52%|█████▏    | 2353/4545 [2:55:03<3:45:28,  6.17s/it] 52%|█████▏    | 2354/4545 [2:55:07<3:23:47,  5.58s/it] 52%|█████▏    | 2355/4545 [2:55:11<3:04:44,  5.06s/it] 52%|█████▏    | 2356/4545 [2:55:15<2:55:22,  4.81s/it] 52%|█████▏    | 2357/4545 [2:55:18<2:32:52,  4.19s/it] 52%|█████▏    | 2358/4545 [2:55:21<2:25:43,  4.00s/it] 52%|█████▏    | 2359/4545 [2:55:25<2:26:26,  4.02s/it] 52%|█████▏    | 2360/4545 [2:55:28<2:12:59,  3.65s/it]                                                       {'loss': 0.0903, 'grad_norm': 5.265460968017578, 'learning_rate': 3.352644928338845e-06, 'rewards/chosen': -3.3511719703674316, 'rewards/rejected': -24.9375, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 21.587499618530273, 'logps/chosen': -196.0, 'logps/rejected': -351.8999938964844, 'logits/chosen': -12.425000190734863, 'logits/rejected': -11.943750381469727, 'epoch': 1.56}
 52%|█████▏    | 2360/4545 [2:55:28<2:12:59,  3.65s/it] 52%|█████▏    | 2361/4545 [2:55:32<2:16:32,  3.75s/it] 52%|█████▏    | 2362/4545 [2:55:36<2:18:42,  3.81s/it] 52%|█████▏    | 2363/4545 [2:55:39<2:11:15,  3.61s/it] 52%|█████▏    | 2364/4545 [2:55:43<2:14:53,  3.71s/it] 52%|█████▏    | 2365/4545 [2:55:46<2:07:50,  3.52s/it] 52%|█████▏    | 2366/4545 [2:55:50<2:15:42,  3.74s/it] 52%|█████▏    | 2367/4545 [2:55:53<2:01:29,  3.35s/it] 52%|█████▏    | 2368/4545 [2:55:57<2:07:43,  3.52s/it] 52%|█████▏    | 2369/4545 [2:56:01<2:12:11,  3.64s/it] 52%|█████▏    | 2370/4545 [2:56:03<1:59:02,  3.28s/it]                                                       {'loss': 0.1334, 'grad_norm': 21.652799606323242, 'learning_rate': 3.3382534478334894e-06, 'rewards/chosen': -1.4140625, 'rewards/rejected': -23.34375, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 21.931249618530273, 'logps/chosen': -262.6499938964844, 'logps/rejected': -396.0, 'logits/chosen': -12.0, 'logits/rejected': -11.574999809265137, 'epoch': 1.56}
 52%|█████▏    | 2370/4545 [2:56:03<1:59:02,  3.28s/it] 52%|█████▏    | 2371/4545 [2:56:07<2:06:30,  3.49s/it] 52%|█████▏    | 2372/4545 [2:56:11<2:13:06,  3.68s/it] 52%|█████▏    | 2373/4545 [2:56:15<2:14:32,  3.72s/it] 52%|█████▏    | 2374/4545 [2:56:18<2:05:14,  3.46s/it] 52%|█████▏    | 2375/4545 [2:56:21<2:02:49,  3.40s/it] 52%|█████▏    | 2376/4545 [2:56:25<2:08:30,  3.55s/it] 52%|█████▏    | 2377/4545 [2:56:29<2:13:52,  3.71s/it] 52%|█████▏    | 2378/4545 [2:56:33<2:18:22,  3.83s/it] 52%|█████▏    | 2379/4545 [2:56:37<2:17:43,  3.81s/it] 52%|█████▏    | 2380/4545 [2:56:41<2:18:41,  3.84s/it]                                                       {'loss': 0.1218, 'grad_norm': 5.491799354553223, 'learning_rate': 3.3237396852082387e-06, 'rewards/chosen': -2.5296874046325684, 'rewards/rejected': -37.13750076293945, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 34.64374923706055, 'logps/chosen': -264.0, 'logps/rejected': -500.79998779296875, 'logits/chosen': -11.46875, 'logits/rejected': -10.931249618530273, 'epoch': 1.57}
 52%|█████▏    | 2380/4545 [2:56:41<2:18:41,  3.84s/it] 52%|█████▏    | 2381/4545 [2:56:44<2:09:01,  3.58s/it] 52%|█████▏    | 2382/4545 [2:56:48<2:12:54,  3.69s/it] 52%|█████▏    | 2383/4545 [2:56:52<2:17:20,  3.81s/it] 52%|█████▏    | 2384/4545 [2:56:56<2:20:59,  3.91s/it] 52%|█████▏    | 2385/4545 [2:56:59<2:13:14,  3.70s/it] 52%|█████▏    | 2386/4545 [2:57:03<2:09:25,  3.60s/it] 53%|█████▎    | 2387/4545 [2:57:07<2:13:49,  3.72s/it] 53%|█████▎    | 2388/4545 [2:57:11<2:16:05,  3.79s/it] 53%|█████▎    | 2389/4545 [2:57:15<2:17:34,  3.83s/it] 53%|█████▎    | 2390/4545 [2:57:18<2:16:09,  3.79s/it]                                                       {'loss': 0.084, 'grad_norm': 20.936473846435547, 'learning_rate': 3.309105199670899e-06, 'rewards/chosen': -0.20156249403953552, 'rewards/rejected': -24.806249618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 24.637500762939453, 'logps/chosen': -316.45001220703125, 'logps/rejected': -459.20001220703125, 'logits/chosen': -11.387499809265137, 'logits/rejected': -11.074999809265137, 'epoch': 1.58}
 53%|█████▎    | 2390/4545 [2:57:18<2:16:09,  3.79s/it] 53%|█████▎    | 2391/4545 [2:57:22<2:14:20,  3.74s/it] 53%|█████▎    | 2392/4545 [2:57:25<2:12:04,  3.68s/it] 53%|█████▎    | 2393/4545 [2:57:29<2:10:43,  3.64s/it] 53%|█████▎    | 2394/4545 [2:57:33<2:15:29,  3.78s/it] 53%|█████▎    | 2395/4545 [2:57:37<2:17:03,  3.82s/it] 53%|█████▎    | 2396/4545 [2:57:40<2:10:35,  3.65s/it] 53%|█████▎    | 2397/4545 [2:57:44<2:08:46,  3.60s/it] 53%|█████▎    | 2398/4545 [2:57:47<2:02:34,  3.43s/it] 53%|█████▎    | 2399/4545 [2:57:51<2:08:30,  3.59s/it] 53%|█████▎    | 2400/4545 [2:57:55<2:15:36,  3.79s/it]                                                       {'loss': 0.0717, 'grad_norm': 2.0374395847320557, 'learning_rate': 3.294351563398492e-06, 'rewards/chosen': -0.815625011920929, 'rewards/rejected': -22.381250381469727, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 21.556249618530273, 'logps/chosen': -259.8999938964844, 'logps/rejected': -361.79998779296875, 'logits/chosen': -11.681249618530273, 'logits/rejected': -11.318750381469727, 'epoch': 1.58}
 53%|█████▎    | 2400/4545 [2:57:55<2:15:36,  3.79s/it] 53%|█████▎    | 2401/4545 [2:57:59<2:17:25,  3.85s/it] 53%|█████▎    | 2402/4545 [2:58:03<2:18:01,  3.86s/it] 53%|█████▎    | 2403/4545 [2:58:07<2:18:29,  3.88s/it] 53%|█████▎    | 2404/4545 [2:58:11<2:19:01,  3.90s/it] 53%|█████▎    | 2405/4545 [2:58:15<2:19:21,  3.91s/it] 53%|█████▎    | 2406/4545 [2:58:18<2:18:52,  3.90s/it] 53%|█████▎    | 2407/4545 [2:58:22<2:09:37,  3.64s/it] 53%|█████▎    | 2408/4545 [2:58:25<2:11:30,  3.69s/it] 53%|█████▎    | 2409/4545 [2:58:30<2:17:04,  3.85s/it] 53%|█████▎    | 2410/4545 [2:58:33<2:17:49,  3.87s/it]                                                       {'loss': 0.1091, 'grad_norm': 1.3428022861480713, 'learning_rate': 3.279480361368355e-06, 'rewards/chosen': 0.30058592557907104, 'rewards/rejected': -28.256250381469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 28.524999618530273, 'logps/chosen': -363.25, 'logps/rejected': -471.0, 'logits/chosen': -11.706250190734863, 'logits/rejected': -11.168749809265137, 'epoch': 1.59}
 53%|█████▎    | 2410/4545 [2:58:33<2:17:49,  3.87s/it] 53%|█████▎    | 2411/4545 [2:58:37<2:17:45,  3.87s/it] 53%|█████▎    | 2412/4545 [2:58:41<2:17:59,  3.88s/it] 53%|█████▎    | 2413/4545 [2:58:45<2:18:14,  3.89s/it] 53%|█████▎    | 2414/4545 [2:58:49<2:21:49,  3.99s/it] 53%|█████▎    | 2415/4545 [2:58:53<2:19:53,  3.94s/it] 53%|█████▎    | 2416/4545 [2:58:57<2:16:45,  3.85s/it] 53%|█████▎    | 2417/4545 [2:59:01<2:19:14,  3.93s/it] 53%|█████▎    | 2418/4545 [2:59:05<2:19:09,  3.93s/it] 53%|█████▎    | 2419/4545 [2:59:08<2:11:41,  3.72s/it] 53%|█████▎    | 2420/4545 [2:59:11<2:05:44,  3.55s/it]                                                       {'loss': 0.2184, 'grad_norm': 22.760543823242188, 'learning_rate': 3.2644931911878696e-06, 'rewards/chosen': -2.2398438453674316, 'rewards/rejected': -20.3125, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 18.068750381469727, 'logps/chosen': -239.8000030517578, 'logps/rejected': -334.3999938964844, 'logits/chosen': -11.837499618530273, 'logits/rejected': -11.381250381469727, 'epoch': 1.6}
 53%|█████▎    | 2420/4545 [2:59:11<2:05:44,  3.55s/it] 53%|█████▎    | 2421/4545 [2:59:15<2:07:11,  3.59s/it] 53%|█████▎    | 2422/4545 [2:59:19<2:10:59,  3.70s/it] 53%|█████▎    | 2423/4545 [2:59:23<2:13:33,  3.78s/it] 53%|█████▎    | 2424/4545 [2:59:27<2:15:06,  3.82s/it] 53%|█████▎    | 2425/4545 [2:59:30<2:05:17,  3.55s/it] 53%|█████▎    | 2426/4545 [2:59:34<2:10:31,  3.70s/it] 53%|█████▎    | 2427/4545 [2:59:38<2:12:55,  3.77s/it] 53%|█████▎    | 2428/4545 [2:59:40<2:00:27,  3.41s/it] 53%|█████▎    | 2429/4545 [2:59:44<2:05:37,  3.56s/it] 53%|█████▎    | 2430/4545 [2:59:48<2:07:17,  3.61s/it]                                                       {'loss': 0.1043, 'grad_norm': 1.1519265174865723, 'learning_rate': 3.249391662922829e-06, 'rewards/chosen': 0.16914062201976776, 'rewards/rejected': -18.09375, 'rewards/accuracies': 0.96875, 'rewards/margins': 18.262500762939453, 'logps/chosen': -286.8500061035156, 'logps/rejected': -332.6000061035156, 'logits/chosen': -11.606249809265137, 'logits/rejected': -11.21875, 'epoch': 1.6}
 53%|█████▎    | 2430/4545 [2:59:48<2:07:17,  3.61s/it] 53%|█████▎    | 2431/4545 [2:59:52<2:10:41,  3.71s/it] 54%|█████▎    | 2432/4545 [2:59:56<2:12:46,  3.77s/it] 54%|█████▎    | 2433/4545 [2:59:59<2:11:08,  3.73s/it] 54%|█████▎    | 2434/4545 [3:00:03<2:14:31,  3.82s/it] 54%|█████▎    | 2435/4545 [3:00:06<2:06:05,  3.59s/it] 54%|█████▎    | 2436/4545 [3:00:09<1:57:35,  3.35s/it] 54%|█████▎    | 2437/4545 [3:00:13<2:03:41,  3.52s/it] 54%|█████▎    | 2438/4545 [3:00:17<2:06:48,  3.61s/it] 54%|█████▎    | 2439/4545 [3:00:21<2:07:31,  3.63s/it] 54%|█████▎    | 2440/4545 [3:00:25<2:09:52,  3.70s/it]                                                       {'loss': 0.3146, 'grad_norm': 5.871593475341797, 'learning_rate': 3.234177398924471e-06, 'rewards/chosen': -1.388281226158142, 'rewards/rejected': -17.162500381469727, 'rewards/accuracies': 0.9375, 'rewards/margins': 15.787500381469727, 'logps/chosen': -210.85000610351562, 'logps/rejected': -309.70001220703125, 'logits/chosen': -11.65625, 'logits/rejected': -11.256250381469727, 'epoch': 1.61}
 54%|█████▎    | 2440/4545 [3:00:25<2:09:52,  3.70s/it] 54%|█████▎    | 2441/4545 [3:00:29<2:12:42,  3.78s/it] 54%|█████▎    | 2442/4545 [3:00:32<2:11:33,  3.75s/it] 54%|█████▍    | 2443/4545 [3:00:36<2:13:11,  3.80s/it] 54%|█████▍    | 2444/4545 [3:00:40<2:11:12,  3.75s/it] 54%|█████▍    | 2445/4545 [3:00:44<2:12:48,  3.79s/it] 54%|█████▍    | 2446/4545 [3:00:47<2:13:03,  3.80s/it] 54%|█████▍    | 2447/4545 [3:00:51<2:14:41,  3.85s/it] 54%|█████▍    | 2448/4545 [3:00:56<2:16:58,  3.92s/it] 54%|█████▍    | 2449/4545 [3:00:59<2:16:46,  3.92s/it] 54%|█████▍    | 2450/4545 [3:01:03<2:16:52,  3.92s/it]                                                       {'loss': 0.1062, 'grad_norm': 4.794485569000244, 'learning_rate': 3.218852033655189e-06, 'rewards/chosen': 0.44414061307907104, 'rewards/rejected': -18.756250381469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 19.193750381469727, 'logps/chosen': -343.1000061035156, 'logps/rejected': -396.0, 'logits/chosen': -11.181249618530273, 'logits/rejected': -10.787500381469727, 'epoch': 1.62}
 54%|█████▍    | 2450/4545 [3:01:03<2:16:52,  3.92s/it] 54%|█████▍    | 2451/4545 [3:01:07<2:10:52,  3.75s/it] 54%|█████▍    | 2452/4545 [3:01:10<2:07:12,  3.65s/it] 54%|█████▍    | 2453/4545 [3:01:14<2:12:15,  3.79s/it] 54%|█████▍    | 2454/4545 [3:01:18<2:13:24,  3.83s/it] 54%|█████▍    | 2455/4545 [3:01:22<2:14:22,  3.86s/it] 54%|█████▍    | 2456/4545 [3:01:26<2:14:56,  3.88s/it] 54%|█████▍    | 2457/4545 [3:01:30<2:14:58,  3.88s/it] 54%|█████▍    | 2458/4545 [3:01:34<2:15:16,  3.89s/it] 54%|█████▍    | 2459/4545 [3:01:38<2:16:11,  3.92s/it] 54%|█████▍    | 2460/4545 [3:01:42<2:17:43,  3.96s/it]                                                       {'loss': 0.2068, 'grad_norm': 39.52830505371094, 'learning_rate': 3.2034172135129417e-06, 'rewards/chosen': 1.2265625, 'rewards/rejected': -19.53125, 'rewards/accuracies': 0.9375, 'rewards/margins': 20.743749618530273, 'logps/chosen': -389.20001220703125, 'logps/rejected': -408.79998779296875, 'logits/chosen': -11.28125, 'logits/rejected': -10.962499618530273, 'epoch': 1.62}
 54%|█████▍    | 2460/4545 [3:01:42<2:17:43,  3.96s/it] 54%|█████▍    | 2461/4545 [3:01:46<2:14:50,  3.88s/it] 54%|█████▍    | 2462/4545 [3:01:48<1:59:26,  3.44s/it] 54%|█████▍    | 2463/4545 [3:01:52<2:04:30,  3.59s/it] 54%|█████▍    | 2464/4545 [3:01:56<2:07:48,  3.69s/it] 54%|█████▍    | 2465/4545 [3:01:59<2:04:03,  3.58s/it] 54%|█████▍    | 2466/4545 [3:02:03<2:05:02,  3.61s/it] 54%|█████▍    | 2467/4545 [3:02:07<2:11:32,  3.80s/it] 54%|█████▍    | 2468/4545 [3:02:11<2:14:22,  3.88s/it] 54%|█████▍    | 2469/4545 [3:02:15<2:14:46,  3.90s/it] 54%|█████▍    | 2470/4545 [3:02:19<2:12:14,  3.82s/it]                                                       {'loss': 0.1547, 'grad_norm': 14.305956840515137, 'learning_rate': 3.1878745966543827e-06, 'rewards/chosen': -2.1528563499450684, 'rewards/rejected': -21.53125, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 19.375, 'logps/chosen': -235.6999969482422, 'logps/rejected': -357.0, 'logits/chosen': -11.649999618530273, 'logits/rejected': -11.3125, 'epoch': 1.63}
 54%|█████▍    | 2470/4545 [3:02:19<2:12:14,  3.82s/it] 54%|█████▍    | 2471/4545 [3:02:23<2:13:16,  3.86s/it] 54%|█████▍    | 2472/4545 [3:02:27<2:14:26,  3.89s/it] 54%|█████▍    | 2473/4545 [3:02:30<2:13:52,  3.88s/it] 54%|█████▍    | 2474/4545 [3:02:34<2:13:03,  3.85s/it] 54%|█████▍    | 2475/4545 [3:02:38<2:14:04,  3.89s/it] 54%|█████▍    | 2476/4545 [3:02:42<2:08:30,  3.73s/it] 54%|█████▍    | 2477/4545 [3:02:45<2:06:05,  3.66s/it] 55%|█████▍    | 2478/4545 [3:02:49<2:05:41,  3.65s/it] 55%|█████▍    | 2479/4545 [3:02:52<2:03:52,  3.60s/it] 55%|█████▍    | 2480/4545 [3:02:56<2:09:59,  3.78s/it]                                                       {'loss': 0.1067, 'grad_norm': 17.026447296142578, 'learning_rate': 3.172225852816722e-06, 'rewards/chosen': -2.095703125, 'rewards/rejected': -16.8125, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 14.703125, 'logps/chosen': -177.0500030517578, 'logps/rejected': -266.29998779296875, 'logits/chosen': -11.8125, 'logits/rejected': -11.418749809265137, 'epoch': 1.64}
 55%|█████▍    | 2480/4545 [3:02:56<2:09:59,  3.78s/it] 55%|█████▍    | 2481/4545 [3:03:01<2:13:58,  3.89s/it] 55%|█████▍    | 2482/4545 [3:03:04<2:12:19,  3.85s/it] 55%|█████▍    | 2483/4545 [3:03:08<2:12:55,  3.87s/it] 55%|█████▍    | 2484/4545 [3:03:12<2:13:33,  3.89s/it] 55%|█████▍    | 2485/4545 [3:03:16<2:13:37,  3.89s/it] 55%|█████▍    | 2486/4545 [3:03:19<1:59:04,  3.47s/it] 55%|█████▍    | 2487/4545 [3:03:22<1:58:23,  3.45s/it] 55%|█████▍    | 2488/4545 [3:03:25<1:54:23,  3.34s/it] 55%|█████▍    | 2489/4545 [3:03:29<1:56:42,  3.41s/it] 55%|█████▍    | 2490/4545 [3:03:32<1:53:51,  3.32s/it]                                                       {'loss': 0.1583, 'grad_norm': 3.8391835689544678, 'learning_rate': 3.156472663138353e-06, 'rewards/chosen': -1.6687500476837158, 'rewards/rejected': -21.549999237060547, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 19.862499237060547, 'logps/chosen': -250.0, 'logps/rejected': -343.5, 'logits/chosen': -11.387499809265137, 'logits/rejected': -11.09375, 'epoch': 1.64}
 55%|█████▍    | 2490/4545 [3:03:32<1:53:51,  3.32s/it] 55%|█████▍    | 2491/4545 [3:03:36<2:00:35,  3.52s/it] 55%|█████▍    | 2492/4545 [3:03:39<2:01:42,  3.56s/it] 55%|█████▍    | 2493/4545 [3:03:43<2:05:07,  3.66s/it] 55%|█████▍    | 2494/4545 [3:03:47<2:05:22,  3.67s/it] 55%|█████▍    | 2495/4545 [3:03:51<2:07:51,  3.74s/it] 55%|█████▍    | 2496/4545 [3:03:55<2:09:55,  3.80s/it] 55%|█████▍    | 2497/4545 [3:03:59<2:14:13,  3.93s/it] 55%|█████▍    | 2498/4545 [3:04:02<2:08:06,  3.76s/it] 55%|█████▍    | 2499/4545 [3:04:06<2:09:47,  3.81s/it] 55%|█████▌    | 2500/4545 [3:04:10<2:10:00,  3.81s/it]                                                       {'loss': 0.2463, 'grad_norm': 27.69416046142578, 'learning_rate': 3.140616719978241e-06, 'rewards/chosen': -1.5031249523162842, 'rewards/rejected': -17.443750381469727, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 15.940625190734863, 'logps/chosen': -225.39999389648438, 'logps/rejected': -326.79998779296875, 'logits/chosen': -10.981249809265137, 'logits/rejected': -10.481249809265137, 'epoch': 1.65}
 55%|█████▌    | 2500/4545 [3:04:10<2:10:00,  3.81s/it] 55%|█████▌    | 2501/4545 [3:04:14<2:07:06,  3.73s/it] 55%|█████▌    | 2502/4545 [3:04:18<2:09:08,  3.79s/it] 55%|█████▌    | 2503/4545 [3:04:20<1:58:43,  3.49s/it] 55%|█████▌    | 2504/4545 [3:04:25<2:05:55,  3.70s/it] 55%|█████▌    | 2505/4545 [3:04:28<2:08:04,  3.77s/it] 55%|█████▌    | 2506/4545 [3:04:32<2:09:36,  3.81s/it] 55%|█████▌    | 2507/4545 [3:04:36<2:10:37,  3.85s/it] 55%|█████▌    | 2508/4545 [3:04:40<2:11:10,  3.86s/it] 55%|█████▌    | 2509/4545 [3:04:43<2:03:57,  3.65s/it] 55%|█████▌    | 2510/4545 [3:04:45<1:48:19,  3.19s/it]                                                       {'loss': 0.0699, 'grad_norm': 11.59481430053711, 'learning_rate': 3.124659726734119e-06, 'rewards/chosen': 2.05859375, 'rewards/rejected': -21.53125, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 23.606250762939453, 'logps/chosen': -368.75, 'logps/rejected': -365.79998779296875, 'logits/chosen': -11.024999618530273, 'logits/rejected': -10.787500381469727, 'epoch': 1.66}
 55%|█████▌    | 2510/4545 [3:04:45<1:48:19,  3.19s/it] 55%|█████▌    | 2511/4545 [3:04:49<1:47:51,  3.18s/it] 55%|█████▌    | 2512/4545 [3:04:53<1:57:42,  3.47s/it] 55%|█████▌    | 2513/4545 [3:04:57<2:02:02,  3.60s/it] 55%|█████▌    | 2514/4545 [3:05:01<2:07:40,  3.77s/it] 55%|█████▌    | 2515/4545 [3:05:05<2:10:01,  3.84s/it] 55%|█████▌    | 2516/4545 [3:05:09<2:10:43,  3.87s/it] 55%|█████▌    | 2517/4545 [3:05:38<6:31:16, 11.58s/it] 55%|█████▌    | 2518/4545 [3:05:42<5:13:38,  9.28s/it] 55%|█████▌    | 2519/4545 [3:05:46<4:19:15,  7.68s/it] 55%|█████▌    | 2520/4545 [3:05:50<3:36:27,  6.41s/it]                                                       {'loss': 0.0649, 'grad_norm': 27.662548065185547, 'learning_rate': 3.108603397659491e-06, 'rewards/chosen': 1.607812523841858, 'rewards/rejected': -22.887500762939453, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 24.5, 'logps/chosen': -391.1499938964844, 'logps/rejected': -403.8999938964844, 'logits/chosen': -11.081250190734863, 'logits/rejected': -10.774999618530273, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [3:05:50<3:36:27,  6.41s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:21,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:51<06:15,  8.94s/it][A
 32%|███▏      | 19/60 [00:52<04:32,  6.64s/it][A
 33%|███▎      | 20/60 [00:53<03:13,  4.84s/it][A
 35%|███▌      | 21/60 [00:54<02:23,  3.69s/it][A
 37%|███▋      | 22/60 [00:55<01:52,  2.97s/it][A
 38%|███▊      | 23/60 [00:56<01:29,  2.42s/it][A
 40%|████      | 24/60 [00:57<01:11,  1.99s/it][A
 42%|████▏     | 25/60 [00:59<01:06,  1.89s/it][A
 43%|████▎     | 26/60 [01:00<00:59,  1.75s/it][A
 45%|████▌     | 27/60 [01:01<00:48,  1.46s/it][A
 47%|████▋     | 28/60 [01:02<00:41,  1.30s/it][A
 48%|████▊     | 29/60 [01:03<00:39,  1.27s/it][A
 50%|█████     | 30/60 [01:05<00:41,  1.39s/it][A
 52%|█████▏    | 31/60 [01:06<00:41,  1.44s/it][A
 53%|█████▎    | 32/60 [01:08<00:40,  1.44s/it][A
 55%|█████▌    | 33/60 [01:09<00:37,  1.41s/it][A
 57%|█████▋    | 34/60 [01:10<00:31,  1.23s/it][A
 58%|█████▊    | 35/60 [01:11<00:32,  1.29s/it][A
 60%|██████    | 36/60 [01:13<00:32,  1.33s/it][A
 62%|██████▏   | 37/60 [01:13<00:25,  1.11s/it][A
 63%|██████▎   | 38/60 [01:15<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [01:16<00:25,  1.22s/it][A
 67%|██████▋   | 40/60 [01:17<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [01:18<00:22,  1.20s/it][A
 70%|███████   | 42/60 [01:20<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [01:21<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [01:22<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [01:23<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [01:25<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:26<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:27<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:29<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:30<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:32<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:33<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [01:34<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:36<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:37<00:05,  1.19s/it][A
 93%|█████████▎| 56/60 [01:38<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:40<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:41<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:43<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:44<00:00,  1.49s/it][A                                                       
                                               [A{'eval_loss': 0.37871211767196655, 'eval_runtime': 106.4561, 'eval_samples_per_second': 8.952, 'eval_steps_per_second': 0.564, 'eval_rewards/chosen': -0.22858072817325592, 'eval_rewards/rejected': -17.548046112060547, 'eval_rewards/accuracies': 0.8613426089286804, 'eval_rewards/margins': 17.32105255126953, 'eval_logps/chosen': -379.9750061035156, 'eval_logps/rejected': -327.48333740234375, 'eval_logits/chosen': -11.058333396911621, 'eval_logits/rejected': -10.970312118530273, 'epoch': 1.66}
 55%|█████▌    | 2520/4545 [3:07:36<3:36:27,  6.41s/it]
100%|██████████| 60/60 [01:44<00:00,  1.49s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 55%|█████▌    | 2521/4545 [3:07:51<23:03:35, 41.02s/it] 55%|█████▌    | 2522/4545 [3:07:55<16:47:43, 29.89s/it] 56%|█████▌    | 2523/4545 [3:07:59<12:24:38, 22.10s/it] 56%|█████▌    | 2524/4545 [3:08:03<9:18:10, 16.57s/it]  56%|█████▌    | 2525/4545 [3:08:06<6:58:46, 12.44s/it] 56%|█████▌    | 2526/4545 [3:08:10<5:35:39,  9.97s/it] 56%|█████▌    | 2527/4545 [3:08:13<4:27:52,  7.96s/it] 56%|█████▌    | 2528/4545 [3:08:17<3:41:48,  6.60s/it] 56%|█████▌    | 2529/4545 [3:08:21<3:16:14,  5.84s/it] 56%|█████▌    | 2530/4545 [3:08:25<2:56:39,  5.26s/it]                                                       {'loss': 0.1388, 'grad_norm': 37.85334014892578, 'learning_rate': 3.0924494576794707e-06, 'rewards/chosen': -0.24238280951976776, 'rewards/rejected': -23.646875381469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 23.424999237060547, 'logps/chosen': -304.95001220703125, 'logps/rejected': -426.1000061035156, 'logits/chosen': -11.237500190734863, 'logits/rejected': -10.912500381469727, 'epoch': 1.67}
 56%|█████▌    | 2530/4545 [3:08:25<2:56:39,  5.26s/it] 56%|█████▌    | 2531/4545 [3:08:29<2:43:15,  4.86s/it] 56%|█████▌    | 2532/4545 [3:08:33<2:33:39,  4.58s/it] 56%|█████▌    | 2533/4545 [3:08:36<2:25:00,  4.32s/it] 56%|█████▌    | 2534/4545 [3:08:40<2:22:44,  4.26s/it] 56%|█████▌    | 2535/4545 [3:09:09<6:23:17, 11.44s/it] 56%|█████▌    | 2536/4545 [3:09:12<5:07:28,  9.18s/it] 56%|█████▌    | 2537/4545 [3:09:16<4:14:33,  7.61s/it] 56%|█████▌    | 2538/4545 [3:09:19<3:24:12,  6.10s/it] 56%|█████▌    | 2539/4545 [3:09:23<3:02:43,  5.47s/it] 56%|█████▌    | 2540/4545 [3:09:26<2:33:59,  4.61s/it]                                                       {'loss': 0.1964, 'grad_norm': 31.744144439697266, 'learning_rate': 3.076199642205471e-06, 'rewards/chosen': 1.5203125476837158, 'rewards/rejected': -16.534374237060547, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 18.053125381469727, 'logps/chosen': -348.8999938964844, 'logps/rejected': -330.3999938964844, 'logits/chosen': -11.387499809265137, 'logits/rejected': -11.175000190734863, 'epoch': 1.68}
 56%|█████▌    | 2540/4545 [3:09:26<2:33:59,  4.61s/it] 56%|█████▌    | 2541/4545 [3:09:30<2:27:50,  4.43s/it] 56%|█████▌    | 2542/4545 [3:09:32<2:08:12,  3.84s/it] 56%|█████▌    | 2543/4545 [3:09:36<2:10:33,  3.91s/it] 56%|█████▌    | 2544/4545 [3:09:40<2:12:18,  3.97s/it] 56%|█████▌    | 2545/4545 [3:09:44<2:11:34,  3.95s/it] 56%|█████▌    | 2546/4545 [3:09:47<1:57:21,  3.52s/it] 56%|█████▌    | 2547/4545 [3:09:51<2:03:29,  3.71s/it] 56%|█████▌    | 2548/4545 [3:09:55<2:05:55,  3.78s/it] 56%|█████▌    | 2549/4545 [3:09:59<2:07:02,  3.82s/it] 56%|█████▌    | 2550/4545 [3:10:03<2:07:26,  3.83s/it]                                                       {'loss': 0.1, 'grad_norm': 18.322994232177734, 'learning_rate': 3.0598556969487734e-06, 'rewards/chosen': -0.96875, 'rewards/rejected': -20.193750381469727, 'rewards/accuracies': 0.96875, 'rewards/margins': 19.212499618530273, 'logps/chosen': -242.89999389648438, 'logps/rejected': -332.29998779296875, 'logits/chosen': -11.350000381469727, 'logits/rejected': -10.956250190734863, 'epoch': 1.68}
 56%|█████▌    | 2550/4545 [3:10:03<2:07:26,  3.83s/it] 56%|█████▌    | 2551/4545 [3:10:06<2:08:16,  3.86s/it] 56%|█████▌    | 2552/4545 [3:10:11<2:11:25,  3.96s/it] 56%|█████▌    | 2553/4545 [3:10:15<2:13:08,  4.01s/it] 56%|█████▌    | 2554/4545 [3:10:19<2:12:01,  3.98s/it] 56%|█████▌    | 2555/4545 [3:10:23<2:11:22,  3.96s/it] 56%|█████▌    | 2556/4545 [3:10:26<2:10:08,  3.93s/it] 56%|█████▋    | 2557/4545 [3:10:30<2:09:54,  3.92s/it] 56%|█████▋    | 2558/4545 [3:10:34<2:10:23,  3.94s/it] 56%|█████▋    | 2559/4545 [3:10:38<2:03:59,  3.75s/it] 56%|█████▋    | 2560/4545 [3:10:41<2:03:07,  3.72s/it]                                                       {'loss': 0.2245, 'grad_norm': 27.385536193847656, 'learning_rate': 3.0434193777329836e-06, 'rewards/chosen': 0.21054688096046448, 'rewards/rejected': -18.193750381469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 18.418750762939453, 'logps/chosen': -364.6000061035156, 'logps/rejected': -379.29998779296875, 'logits/chosen': -10.806249618530273, 'logits/rejected': -10.512499809265137, 'epoch': 1.69}
 56%|█████▋    | 2560/4545 [3:10:41<2:03:07,  3.72s/it] 56%|█████▋    | 2561/4545 [3:10:44<1:51:17,  3.37s/it] 56%|█████▋    | 2562/4545 [3:10:48<1:56:59,  3.54s/it] 56%|█████▋    | 2563/4545 [3:10:50<1:41:13,  3.06s/it] 56%|█████▋    | 2564/4545 [3:10:54<1:50:46,  3.36s/it] 56%|█████▋    | 2565/4545 [3:10:58<1:57:41,  3.57s/it] 56%|█████▋    | 2566/4545 [3:11:01<1:56:30,  3.53s/it] 56%|█████▋    | 2567/4545 [3:11:05<1:58:14,  3.59s/it] 57%|█████▋    | 2568/4545 [3:11:09<1:58:49,  3.61s/it] 57%|█████▋    | 2569/4545 [3:11:12<2:00:14,  3.65s/it] 57%|█████▋    | 2570/4545 [3:11:15<1:52:22,  3.41s/it]                                                       {'loss': 0.1058, 'grad_norm': 14.327493667602539, 'learning_rate': 3.026892450305405e-06, 'rewards/chosen': -2.3265624046325684, 'rewards/rejected': -20.256250381469727, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 17.893749237060547, 'logps/chosen': -191.3000030517578, 'logps/rejected': -316.0, 'logits/chosen': -11.574999809265137, 'logits/rejected': -11.081250190734863, 'epoch': 1.7}
 57%|█████▋    | 2570/4545 [3:11:15<1:52:22,  3.41s/it] 57%|█████▋    | 2571/4545 [3:11:19<1:54:19,  3.47s/it] 57%|█████▋    | 2572/4545 [3:11:22<1:55:31,  3.51s/it] 57%|█████▋    | 2573/4545 [3:11:26<1:53:39,  3.46s/it] 57%|█████▋    | 2574/4545 [3:11:30<1:59:58,  3.65s/it] 57%|█████▋    | 2575/4545 [3:11:34<2:02:24,  3.73s/it] 57%|█████▋    | 2576/4545 [3:11:38<2:02:46,  3.74s/it] 57%|█████▋    | 2577/4545 [3:11:41<2:04:27,  3.79s/it] 57%|█████▋    | 2578/4545 [3:11:45<2:05:08,  3.82s/it] 57%|█████▋    | 2579/4545 [3:11:49<2:04:32,  3.80s/it] 57%|█████▋    | 2580/4545 [3:11:53<2:05:43,  3.84s/it]                                                       {'loss': 0.0663, 'grad_norm': 19.127120971679688, 'learning_rate': 3.010276690147348e-06, 'rewards/chosen': -1.482812523841858, 'rewards/rejected': -32.51874923706055, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 31.018749237060547, 'logps/chosen': -284.0, 'logps/rejected': -450.6000061035156, 'logits/chosen': -11.587499618530273, 'logits/rejected': -11.175000190734863, 'epoch': 1.7}
 57%|█████▋    | 2580/4545 [3:11:53<2:05:43,  3.84s/it] 57%|█████▋    | 2581/4545 [3:11:57<2:09:22,  3.95s/it] 57%|█████▋    | 2582/4545 [3:12:01<2:08:44,  3.94s/it] 57%|█████▋    | 2583/4545 [3:12:05<2:08:26,  3.93s/it] 57%|█████▋    | 2584/4545 [3:12:09<2:04:43,  3.82s/it] 57%|█████▋    | 2585/4545 [3:12:12<2:03:36,  3.78s/it] 57%|█████▋    | 2586/4545 [3:12:16<2:04:55,  3.83s/it] 57%|█████▋    | 2587/4545 [3:12:19<1:57:23,  3.60s/it] 57%|█████▋    | 2588/4545 [3:12:23<2:00:41,  3.70s/it] 57%|█████▋    | 2589/4545 [3:12:27<2:04:35,  3.82s/it] 57%|█████▋    | 2590/4545 [3:12:31<2:05:19,  3.85s/it]                                                       {'loss': 0.2506, 'grad_norm': 19.399826049804688, 'learning_rate': 2.993573882283384e-06, 'rewards/chosen': -1.4638671875, 'rewards/rejected': -28.737499237060547, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 27.262500762939453, 'logps/chosen': -306.6000061035156, 'logps/rejected': -413.20001220703125, 'logits/chosen': -11.387499809265137, 'logits/rejected': -10.925000190734863, 'epoch': 1.71}
 57%|█████▋    | 2590/4545 [3:12:31<2:05:19,  3.85s/it] 57%|█████▋    | 2591/4545 [3:12:35<2:03:32,  3.79s/it] 57%|█████▋    | 2592/4545 [3:12:39<2:04:56,  3.84s/it] 57%|█████▋    | 2593/4545 [3:13:08<6:09:39, 11.36s/it] 57%|█████▋    | 2594/4545 [3:13:12<4:56:48,  9.13s/it] 57%|█████▋    | 2595/4545 [3:13:16<4:07:32,  7.62s/it] 57%|█████▋    | 2596/4545 [3:13:20<3:31:26,  6.51s/it] 57%|█████▋    | 2597/4545 [3:13:23<3:02:10,  5.61s/it] 57%|█████▋    | 2598/4545 [3:13:27<2:45:38,  5.10s/it] 57%|█████▋    | 2599/4545 [3:13:31<2:35:23,  4.79s/it] 57%|█████▋    | 2600/4545 [3:13:35<2:26:59,  4.53s/it]                                                       {'loss': 0.0709, 'grad_norm': 30.972618103027344, 'learning_rate': 2.976785821089591e-06, 'rewards/chosen': 1.754296898841858, 'rewards/rejected': -31.006250381469727, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 32.743751525878906, 'logps/chosen': -450.0, 'logps/rejected': -546.0, 'logits/chosen': -10.84375, 'logits/rejected': -10.412500381469727, 'epoch': 1.72}
 57%|█████▋    | 2600/4545 [3:13:35<2:26:59,  4.53s/it] 57%|█████▋    | 2601/4545 [3:13:39<2:23:08,  4.42s/it] 57%|█████▋    | 2602/4545 [3:13:43<2:15:33,  4.19s/it] 57%|█████▋    | 2603/4545 [3:14:12<6:14:10, 11.56s/it] 57%|█████▋    | 2604/4545 [3:14:16<4:59:45,  9.27s/it] 57%|█████▋    | 2605/4545 [3:14:20<4:08:37,  7.69s/it] 57%|█████▋    | 2606/4545 [3:14:24<3:32:14,  6.57s/it] 57%|█████▋    | 2607/4545 [3:14:28<3:06:32,  5.78s/it] 57%|█████▋    | 2608/4545 [3:14:30<2:34:31,  4.79s/it] 57%|█████▋    | 2609/4545 [3:14:34<2:23:56,  4.46s/it] 57%|█████▋    | 2610/4545 [3:14:38<2:19:19,  4.32s/it]                                                       {'loss': 0.0708, 'grad_norm': 13.94442367553711, 'learning_rate': 2.959914310100773e-06, 'rewards/chosen': -3.475781202316284, 'rewards/rejected': -24.03125, 'rewards/accuracies': 0.96875, 'rewards/margins': 20.581249237060547, 'logps/chosen': -209.89999389648438, 'logps/rejected': -386.5, 'logits/chosen': -11.550000190734863, 'logits/rejected': -11.137499809265137, 'epoch': 1.72}
 57%|█████▋    | 2610/4545 [3:14:38<2:19:19,  4.32s/it] 57%|█████▋    | 2611/4545 [3:14:42<2:15:15,  4.20s/it] 57%|█████▋    | 2612/4545 [3:14:46<2:12:35,  4.12s/it] 57%|█████▋    | 2613/4545 [3:14:50<2:13:37,  4.15s/it] 58%|█████▊    | 2614/4545 [3:14:54<2:13:23,  4.14s/it] 58%|█████▊    | 2615/4545 [3:14:58<2:11:00,  4.07s/it] 58%|█████▊    | 2616/4545 [3:15:02<2:09:27,  4.03s/it] 58%|█████▊    | 2617/4545 [3:15:05<2:01:32,  3.78s/it] 58%|█████▊    | 2618/4545 [3:15:09<2:03:03,  3.83s/it] 58%|█████▊    | 2619/4545 [3:15:12<2:00:53,  3.77s/it] 58%|█████▊    | 2620/4545 [3:15:15<1:51:43,  3.48s/it]                                                       {'loss': 0.1268, 'grad_norm': 16.532869338989258, 'learning_rate': 2.9429611618167156e-06, 'rewards/chosen': 0.766406238079071, 'rewards/rejected': -19.25, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 20.012500762939453, 'logps/chosen': -358.70001220703125, 'logps/rejected': -393.70001220703125, 'logits/chosen': -11.668749809265137, 'logits/rejected': -11.318750381469727, 'epoch': 1.73}
 58%|█████▊    | 2620/4545 [3:15:15<1:51:43,  3.48s/it] 58%|█████▊    | 2621/4545 [3:15:19<1:49:09,  3.40s/it] 58%|█████▊    | 2622/4545 [3:15:22<1:54:02,  3.56s/it] 58%|█████▊    | 2623/4545 [3:15:26<1:51:47,  3.49s/it] 58%|█████▊    | 2624/4545 [3:15:30<1:57:55,  3.68s/it] 58%|█████▊    | 2625/4545 [3:15:34<2:00:07,  3.75s/it] 58%|█████▊    | 2626/4545 [3:15:38<2:01:38,  3.80s/it] 58%|█████▊    | 2627/4545 [3:15:42<2:04:40,  3.90s/it] 58%|█████▊    | 2628/4545 [3:15:44<1:51:27,  3.49s/it] 58%|█████▊    | 2629/4545 [3:15:48<1:50:12,  3.45s/it] 58%|█████▊    | 2630/4545 [3:15:51<1:50:49,  3.47s/it]                                                       {'loss': 0.1383, 'grad_norm': 13.446772575378418, 'learning_rate': 2.9259281975074667e-06, 'rewards/chosen': -0.6812499761581421, 'rewards/rejected': -27.818750381469727, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.112499237060547, 'logps/chosen': -332.29998779296875, 'logps/rejected': -431.1000061035156, 'logits/chosen': -11.15625, 'logits/rejected': -10.706250190734863, 'epoch': 1.74}
 58%|█████▊    | 2630/4545 [3:15:51<1:50:49,  3.47s/it] 58%|█████▊    | 2631/4545 [3:15:55<1:55:21,  3.62s/it] 58%|█████▊    | 2632/4545 [3:15:59<2:01:06,  3.80s/it] 58%|█████▊    | 2633/4545 [3:16:03<2:01:47,  3.82s/it] 58%|█████▊    | 2634/4545 [3:16:07<2:03:01,  3.86s/it] 58%|█████▊    | 2635/4545 [3:16:12<2:06:25,  3.97s/it] 58%|█████▊    | 2636/4545 [3:16:15<2:01:33,  3.82s/it] 58%|█████▊    | 2637/4545 [3:16:19<2:05:41,  3.95s/it] 58%|█████▊    | 2638/4545 [3:16:23<2:05:14,  3.94s/it] 58%|█████▊    | 2639/4545 [3:16:27<2:05:00,  3.93s/it] 58%|█████▊    | 2640/4545 [3:16:31<2:04:53,  3.93s/it]                                                       {'loss': 0.1055, 'grad_norm': 1.2081738710403442, 'learning_rate': 2.908817247017678e-06, 'rewards/chosen': 0.39921873807907104, 'rewards/rejected': -23.125, 'rewards/accuracies': 0.96875, 'rewards/margins': 23.475000381469727, 'logps/chosen': -317.29998779296875, 'logps/rejected': -372.29998779296875, 'logits/chosen': -11.03125, 'logits/rejected': -10.587499618530273, 'epoch': 1.74}
 58%|█████▊    | 2640/4545 [3:16:31<2:04:53,  3.93s/it] 58%|█████▊    | 2641/4545 [3:16:35<2:04:45,  3.93s/it] 58%|█████▊    | 2642/4545 [3:16:39<2:04:34,  3.93s/it] 58%|█████▊    | 2643/4545 [3:16:43<2:02:01,  3.85s/it] 58%|█████▊    | 2644/4545 [3:16:46<1:56:49,  3.69s/it] 58%|█████▊    | 2645/4545 [3:16:50<1:58:57,  3.76s/it] 58%|█████▊    | 2646/4545 [3:16:54<2:00:31,  3.81s/it] 58%|█████▊    | 2647/4545 [3:16:58<2:01:35,  3.84s/it] 58%|█████▊    | 2648/4545 [3:17:26<5:58:44, 11.35s/it] 58%|█████▊    | 2649/4545 [3:17:30<4:48:00,  9.11s/it] 58%|█████▊    | 2650/4545 [3:17:34<3:58:30,  7.55s/it]                                                       {'loss': 0.0822, 'grad_norm': 24.20279312133789, 'learning_rate': 2.8916301485700266e-06, 'rewards/chosen': 2.592968702316284, 'rewards/rejected': -23.96875, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 26.537500381469727, 'logps/chosen': -377.20001220703125, 'logps/rejected': -426.6000061035156, 'logits/chosen': -10.9375, 'logits/rejected': -10.712499618530273, 'epoch': 1.75}
 58%|█████▊    | 2650/4545 [3:17:34<3:58:30,  7.55s/it] 58%|█████▊    | 2651/4545 [3:17:38<3:22:55,  6.43s/it] 58%|█████▊    | 2652/4545 [3:17:42<2:59:17,  5.68s/it] 58%|█████▊    | 2653/4545 [3:17:46<2:44:42,  5.22s/it] 58%|█████▊    | 2654/4545 [3:17:50<2:32:10,  4.83s/it] 58%|█████▊    | 2655/4545 [3:17:54<2:21:52,  4.50s/it] 58%|█████▊    | 2656/4545 [3:17:58<2:18:29,  4.40s/it] 58%|█████▊    | 2657/4545 [3:18:02<2:10:55,  4.16s/it] 58%|█████▊    | 2658/4545 [3:18:06<2:08:23,  4.08s/it] 59%|█████▊    | 2659/4545 [3:18:09<2:05:18,  3.99s/it] 59%|█████▊    | 2660/4545 [3:18:13<2:04:27,  3.96s/it]                                                       {'loss': 0.1249, 'grad_norm': 10.712636947631836, 'learning_rate': 2.8743687485677315e-06, 'rewards/chosen': 0.03437500074505806, 'rewards/rejected': -28.412500381469727, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 28.471874237060547, 'logps/chosen': -362.1000061035156, 'logps/rejected': -463.29998779296875, 'logits/chosen': -10.90625, 'logits/rejected': -10.587499618530273, 'epoch': 1.76}
 59%|█████▊    | 2660/4545 [3:18:13<2:04:27,  3.96s/it] 59%|█████▊    | 2661/4545 [3:18:17<1:58:57,  3.79s/it] 59%|█████▊    | 2662/4545 [3:18:20<1:59:30,  3.81s/it] 59%|█████▊    | 2663/4545 [3:18:24<1:58:29,  3.78s/it] 59%|█████▊    | 2664/4545 [3:18:28<1:59:38,  3.82s/it] 59%|█████▊    | 2665/4545 [3:18:32<1:57:49,  3.76s/it] 59%|█████▊    | 2666/4545 [3:18:36<2:01:06,  3.87s/it] 59%|█████▊    | 2667/4545 [3:18:40<2:03:19,  3.94s/it] 59%|█████▊    | 2668/4545 [3:18:44<2:04:59,  4.00s/it] 59%|█████▊    | 2669/4545 [3:18:48<2:05:04,  4.00s/it] 59%|█████▊    | 2670/4545 [3:18:50<1:49:00,  3.49s/it]                                                       {'loss': 0.1641, 'grad_norm': 24.419628143310547, 'learning_rate': 2.8570349013962045e-06, 'rewards/chosen': -0.903613269329071, 'rewards/rejected': -25.681249618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 24.787500381469727, 'logps/chosen': -327.20001220703125, 'logps/rejected': -426.70001220703125, 'logits/chosen': -11.1875, 'logits/rejected': -10.831250190734863, 'epoch': 1.76}
 59%|█████▊    | 2670/4545 [3:18:50<1:49:00,  3.49s/it] 59%|█████▉    | 2671/4545 [3:18:53<1:42:33,  3.28s/it] 59%|█████▉    | 2672/4545 [3:18:57<1:48:17,  3.47s/it] 59%|█████▉    | 2673/4545 [3:19:01<1:50:46,  3.55s/it] 59%|█████▉    | 2674/4545 [3:19:05<1:54:01,  3.66s/it] 59%|█████▉    | 2675/4545 [3:19:09<1:56:18,  3.73s/it] 59%|█████▉    | 2676/4545 [3:19:12<1:58:07,  3.79s/it] 59%|█████▉    | 2677/4545 [3:19:16<1:57:19,  3.77s/it] 59%|█████▉    | 2678/4545 [3:19:20<1:58:34,  3.81s/it] 59%|█████▉    | 2679/4545 [3:19:24<1:57:14,  3.77s/it] 59%|█████▉    | 2680/4545 [3:19:28<1:58:45,  3.82s/it]                                                       {'loss': 0.0531, 'grad_norm': 10.483879089355469, 'learning_rate': 2.8396304692238227e-06, 'rewards/chosen': 0.6421874761581421, 'rewards/rejected': -26.506250381469727, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 27.174999237060547, 'logps/chosen': -327.1499938964844, 'logps/rejected': -450.0, 'logits/chosen': -11.15625, 'logits/rejected': -10.768750190734863, 'epoch': 1.77}
 59%|█████▉    | 2680/4545 [3:19:28<1:58:45,  3.82s/it] 59%|█████▉    | 2681/4545 [3:19:32<1:59:38,  3.85s/it] 59%|█████▉    | 2682/4545 [3:19:36<2:01:24,  3.91s/it] 59%|█████▉    | 2683/4545 [3:19:40<2:02:44,  3.96s/it] 59%|█████▉    | 2684/4545 [3:19:44<2:03:01,  3.97s/it] 59%|█████▉    | 2685/4545 [3:19:48<2:03:50,  4.00s/it] 59%|█████▉    | 2686/4545 [3:19:52<2:06:03,  4.07s/it] 59%|█████▉    | 2687/4545 [3:19:56<2:07:24,  4.11s/it] 59%|█████▉    | 2688/4545 [3:20:00<2:05:20,  4.05s/it] 59%|█████▉    | 2689/4545 [3:20:03<1:51:23,  3.60s/it] 59%|█████▉    | 2690/4545 [3:20:32<5:47:39, 11.25s/it]                                                       {'loss': 0.1154, 'grad_norm': 12.486175537109375, 'learning_rate': 2.8221573218018843e-06, 'rewards/chosen': 0.32343751192092896, 'rewards/rejected': -23.112499237060547, 'rewards/accuracies': 0.9375, 'rewards/margins': 23.4375, 'logps/chosen': -343.8500061035156, 'logps/rejected': -431.6000061035156, 'logits/chosen': -11.324999809265137, 'logits/rejected': -11.018750190734863, 'epoch': 1.78}
 59%|█████▉    | 2690/4545 [3:20:32<5:47:39, 11.25s/it] 59%|█████▉    | 2691/4545 [3:20:36<4:39:42,  9.05s/it] 59%|█████▉    | 2692/4545 [3:20:40<3:51:57,  7.51s/it] 59%|█████▉    | 2693/4545 [3:20:44<3:18:34,  6.43s/it] 59%|█████▉    | 2694/4545 [3:20:47<2:53:55,  5.64s/it] 59%|█████▉    | 2695/4545 [3:20:51<2:35:15,  5.04s/it] 59%|█████▉    | 2696/4545 [3:20:54<2:12:26,  4.30s/it] 59%|█████▉    | 2697/4545 [3:20:57<2:08:56,  4.19s/it] 59%|█████▉    | 2698/4545 [3:21:01<2:06:45,  4.12s/it] 59%|█████▉    | 2699/4545 [3:21:04<1:54:32,  3.72s/it] 59%|█████▉    | 2700/4545 [3:21:08<1:57:44,  3.83s/it]                                                       {'loss': 0.1709, 'grad_norm': 14.171385765075684, 'learning_rate': 2.8046173362637406e-06, 'rewards/chosen': -0.9297851324081421, 'rewards/rejected': -23.162500381469727, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 22.231250762939453, 'logps/chosen': -291.29998779296875, 'logps/rejected': -368.6000061035156, 'logits/chosen': -11.699999809265137, 'logits/rejected': -11.4375, 'epoch': 1.78}
 59%|█████▉    | 2700/4545 [3:21:08<1:57:44,  3.83s/it] 59%|█████▉    | 2701/4545 [3:21:12<1:53:02,  3.68s/it] 59%|█████▉    | 2702/4545 [3:21:15<1:46:50,  3.48s/it] 59%|█████▉    | 2703/4545 [3:21:19<1:53:48,  3.71s/it] 59%|█████▉    | 2704/4545 [3:21:23<1:55:47,  3.77s/it] 60%|█████▉    | 2705/4545 [3:21:27<1:57:02,  3.82s/it] 60%|█████▉    | 2706/4545 [3:21:31<1:56:45,  3.81s/it] 60%|█████▉    | 2707/4545 [3:21:35<1:58:06,  3.86s/it] 60%|█████▉    | 2708/4545 [3:21:39<1:59:53,  3.92s/it] 60%|█████▉    | 2709/4545 [3:21:42<1:57:25,  3.84s/it] 60%|█████▉    | 2710/4545 [3:21:46<1:54:47,  3.75s/it]                                                       {'loss': 0.0896, 'grad_norm': 20.54749298095703, 'learning_rate': 2.7870123969231327e-06, 'rewards/chosen': -2.5960936546325684, 'rewards/rejected': -24.243749618530273, 'rewards/accuracies': 0.96875, 'rewards/margins': 21.662500381469727, 'logps/chosen': -256.3999938964844, 'logps/rejected': -373.70001220703125, 'logits/chosen': -11.568750381469727, 'logits/rejected': -11.262499809265137, 'epoch': 1.79}
 60%|█████▉    | 2710/4545 [3:21:46<1:54:47,  3.75s/it] 60%|█████▉    | 2711/4545 [3:21:50<1:56:20,  3.81s/it] 60%|█████▉    | 2712/4545 [3:21:53<1:53:09,  3.70s/it] 60%|█████▉    | 2713/4545 [3:21:57<1:55:22,  3.78s/it] 60%|█████▉    | 2714/4545 [3:22:01<1:56:43,  3.82s/it] 60%|█████▉    | 2715/4545 [3:22:05<1:56:26,  3.82s/it] 60%|█████▉    | 2716/4545 [3:22:08<1:48:44,  3.57s/it] 60%|█████▉    | 2717/4545 [3:22:12<1:51:57,  3.67s/it] 60%|█████▉    | 2718/4545 [3:22:16<1:54:17,  3.75s/it] 60%|█████▉    | 2719/4545 [3:22:20<1:55:04,  3.78s/it] 60%|█████▉    | 2720/4545 [3:22:23<1:56:28,  3.83s/it]                                                       {'loss': 0.1875, 'grad_norm': 22.23797035217285, 'learning_rate': 2.7693443950717667e-06, 'rewards/chosen': -2.0843749046325684, 'rewards/rejected': -22.462499618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 20.40625, 'logps/chosen': -260.3500061035156, 'logps/rejected': -347.79998779296875, 'logits/chosen': -11.206250190734863, 'logits/rejected': -10.931249618530273, 'epoch': 1.8}
 60%|█████▉    | 2720/4545 [3:22:23<1:56:28,  3.83s/it] 60%|█████▉    | 2721/4545 [3:22:25<1:37:23,  3.20s/it] 60%|█████▉    | 2722/4545 [3:22:29<1:44:07,  3.43s/it] 60%|█████▉    | 2723/4545 [3:22:33<1:48:32,  3.57s/it] 60%|█████▉    | 2724/4545 [3:22:37<1:47:53,  3.56s/it] 60%|█████▉    | 2725/4545 [3:22:40<1:49:04,  3.60s/it] 60%|█████▉    | 2726/4545 [3:22:44<1:54:25,  3.77s/it] 60%|██████    | 2727/4545 [3:22:48<1:55:45,  3.82s/it] 60%|██████    | 2728/4545 [3:22:52<1:54:10,  3.77s/it] 60%|██████    | 2729/4545 [3:22:56<1:51:15,  3.68s/it] 60%|██████    | 2730/4545 [3:22:59<1:53:22,  3.75s/it]                                                       {'loss': 0.1598, 'grad_norm': 4.141008377075195, 'learning_rate': 2.7516152287761255e-06, 'rewards/chosen': -1.7578125, 'rewards/rejected': -25.337499618530273, 'rewards/accuracies': 0.9437500238418579, 'rewards/margins': 23.556249618530273, 'logps/chosen': -251.5500030517578, 'logps/rejected': -382.20001220703125, 'logits/chosen': -11.21875, 'logits/rejected': -10.887499809265137, 'epoch': 1.8}
 60%|██████    | 2730/4545 [3:22:59<1:53:22,  3.75s/it] 60%|██████    | 2731/4545 [3:23:03<1:55:03,  3.81s/it] 60%|██████    | 2732/4545 [3:23:07<1:56:01,  3.84s/it] 60%|██████    | 2733/4545 [3:23:11<1:55:21,  3.82s/it] 60%|██████    | 2734/4545 [3:23:15<1:52:55,  3.74s/it] 60%|██████    | 2735/4545 [3:23:19<1:55:51,  3.84s/it] 60%|██████    | 2736/4545 [3:23:23<1:56:49,  3.87s/it] 60%|██████    | 2737/4545 [3:23:26<1:50:49,  3.68s/it] 60%|██████    | 2738/4545 [3:23:30<1:54:16,  3.79s/it] 60%|██████    | 2739/4545 [3:23:34<1:55:22,  3.83s/it] 60%|██████    | 2740/4545 [3:23:38<1:56:09,  3.86s/it]                                                       {'loss': 0.1704, 'grad_norm': 4.75032377243042, 'learning_rate': 2.7338268026735687e-06, 'rewards/chosen': 0.44609373807907104, 'rewards/rejected': -20.706249237060547, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 21.15625, 'logps/chosen': -323.95001220703125, 'logps/rejected': -355.6000061035156, 'logits/chosen': -10.800000190734863, 'logits/rejected': -10.693750381469727, 'epoch': 1.81}
 60%|██████    | 2740/4545 [3:23:38<1:56:09,  3.86s/it] 60%|██████    | 2741/4545 [3:23:41<1:53:21,  3.77s/it] 60%|██████    | 2742/4545 [3:23:45<1:55:07,  3.83s/it] 60%|██████    | 2743/4545 [3:23:49<1:56:01,  3.86s/it] 60%|██████    | 2744/4545 [3:23:52<1:48:23,  3.61s/it] 60%|██████    | 2745/4545 [3:23:56<1:48:02,  3.60s/it] 60%|██████    | 2746/4545 [3:24:00<1:52:16,  3.74s/it] 60%|██████    | 2747/4545 [3:24:04<1:51:38,  3.73s/it] 60%|██████    | 2748/4545 [3:24:07<1:49:35,  3.66s/it] 60%|██████    | 2749/4545 [3:24:10<1:46:14,  3.55s/it] 61%|██████    | 2750/4545 [3:24:14<1:49:37,  3.66s/it]                                                       {'loss': 0.1563, 'grad_norm': 3.9096920490264893, 'learning_rate': 2.7159810277677085e-06, 'rewards/chosen': -2.585009813308716, 'rewards/rejected': -24.837499618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 22.231250762939453, 'logps/chosen': -196.3000030517578, 'logps/rejected': -366.0, 'logits/chosen': -10.84375, 'logits/rejected': -10.481249809265137, 'epoch': 1.82}
 61%|██████    | 2750/4545 [3:24:14<1:49:37,  3.66s/it] 61%|██████    | 2751/4545 [3:24:19<1:54:37,  3.83s/it] 61%|██████    | 2752/4545 [3:24:22<1:51:11,  3.72s/it] 61%|██████    | 2753/4545 [3:24:25<1:45:46,  3.54s/it] 61%|██████    | 2754/4545 [3:24:29<1:49:28,  3.67s/it] 61%|██████    | 2755/4545 [3:24:32<1:43:03,  3.45s/it] 61%|██████    | 2756/4545 [3:24:36<1:43:21,  3.47s/it] 61%|██████    | 2757/4545 [3:24:40<1:48:39,  3.65s/it] 61%|██████    | 2758/4545 [3:24:44<1:50:48,  3.72s/it] 61%|██████    | 2759/4545 [3:24:48<1:54:20,  3.84s/it] 61%|██████    | 2760/4545 [3:24:52<1:56:46,  3.93s/it]                                                       {'loss': 0.2764, 'grad_norm': 23.421194076538086, 'learning_rate': 2.6980798212231208e-06, 'rewards/chosen': -1.705468773841858, 'rewards/rejected': -23.75, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 22.021875381469727, 'logps/chosen': -237.89999389648438, 'logps/rejected': -372.8999938964844, 'logits/chosen': -10.675000190734863, 'logits/rejected': -10.324999809265137, 'epoch': 1.82}
 61%|██████    | 2760/4545 [3:24:52<1:56:46,  3.93s/it] 61%|██████    | 2761/4545 [3:24:56<1:56:50,  3.93s/it] 61%|██████    | 2762/4545 [3:25:00<1:56:35,  3.92s/it] 61%|██████    | 2763/4545 [3:25:03<1:50:23,  3.72s/it] 61%|██████    | 2764/4545 [3:25:07<1:52:08,  3.78s/it] 61%|██████    | 2765/4545 [3:25:10<1:50:09,  3.71s/it] 61%|██████    | 2766/4545 [3:25:14<1:48:21,  3.65s/it] 61%|██████    | 2767/4545 [3:25:18<1:53:29,  3.83s/it] 61%|██████    | 2768/4545 [3:25:22<1:54:18,  3.86s/it] 61%|██████    | 2769/4545 [3:25:26<1:56:05,  3.92s/it] 61%|██████    | 2770/4545 [3:25:30<1:55:59,  3.92s/it]                                                       {'loss': 0.1291, 'grad_norm': 10.285727500915527, 'learning_rate': 2.680125106159379e-06, 'rewards/chosen': 1.166406273841858, 'rewards/rejected': -20.806249618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 21.975000381469727, 'logps/chosen': -342.70001220703125, 'logps/rejected': -423.0, 'logits/chosen': -10.693750381469727, 'logits/rejected': -10.487500190734863, 'epoch': 1.83}
 61%|██████    | 2770/4545 [3:25:30<1:55:59,  3.92s/it] 61%|██████    | 2771/4545 [3:25:34<1:56:04,  3.93s/it] 61%|██████    | 2772/4545 [3:25:38<1:56:03,  3.93s/it] 61%|██████    | 2773/4545 [3:25:41<1:49:49,  3.72s/it] 61%|██████    | 2774/4545 [3:25:45<1:51:39,  3.78s/it] 61%|██████    | 2775/4545 [3:25:49<1:52:43,  3.82s/it] 61%|██████    | 2776/4545 [3:25:53<1:51:29,  3.78s/it] 61%|██████    | 2777/4545 [3:25:56<1:48:00,  3.67s/it] 61%|██████    | 2778/4545 [3:26:00<1:50:15,  3.74s/it] 61%|██████    | 2779/4545 [3:26:04<1:49:23,  3.72s/it] 61%|██████    | 2780/4545 [3:26:07<1:49:55,  3.74s/it]                                                       {'loss': 0.0946, 'grad_norm': 14.84940242767334, 'learning_rate': 2.6621188114444548e-06, 'rewards/chosen': -1.717382788658142, 'rewards/rejected': -22.524999618530273, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 20.8125, 'logps/chosen': -291.20001220703125, 'logps/rejected': -387.5, 'logits/chosen': -10.90625, 'logits/rejected': -10.550000190734863, 'epoch': 1.83}
 61%|██████    | 2780/4545 [3:26:07<1:49:55,  3.74s/it] 61%|██████    | 2781/4545 [3:26:11<1:52:40,  3.83s/it] 61%|██████    | 2782/4545 [3:26:40<5:34:10, 11.37s/it] 61%|██████    | 2783/4545 [3:26:44<4:24:51,  9.02s/it] 61%|██████▏   | 2784/4545 [3:27:17<7:53:51, 16.14s/it] 61%|██████▏   | 2785/4545 [3:27:24<6:38:25, 13.58s/it] 61%|██████▏   | 2786/4545 [3:27:32<5:46:55, 11.83s/it] 61%|██████▏   | 2787/4545 [3:27:40<5:09:50, 10.57s/it] 61%|██████▏   | 2788/4545 [3:27:46<4:35:40,  9.41s/it] 61%|██████▏   | 2789/4545 [3:27:54<4:21:10,  8.92s/it] 61%|██████▏   | 2790/4545 [3:28:02<4:09:40,  8.54s/it]                                                       {'loss': 0.1115, 'grad_norm': 26.903663635253906, 'learning_rate': 2.6440628714875025e-06, 'rewards/chosen': -0.635937511920929, 'rewards/rejected': -22.325000762939453, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 21.715625762939453, 'logps/chosen': -266.20001220703125, 'logps/rejected': -382.5, 'logits/chosen': -10.856249809265137, 'logits/rejected': -10.481249809265137, 'epoch': 1.84}
 61%|██████▏   | 2790/4545 [3:28:02<4:09:40,  8.54s/it] 61%|██████▏   | 2791/4545 [3:28:10<4:01:55,  8.28s/it] 61%|██████▏   | 2792/4545 [3:28:18<3:59:24,  8.19s/it] 61%|██████▏   | 2793/4545 [3:28:25<3:53:07,  7.98s/it] 61%|██████▏   | 2794/4545 [3:28:33<3:49:48,  7.87s/it] 61%|██████▏   | 2795/4545 [3:28:40<3:43:46,  7.67s/it] 62%|██████▏   | 2796/4545 [3:28:47<3:43:21,  7.66s/it] 62%|██████▏   | 2797/4545 [3:28:55<3:38:17,  7.49s/it] 62%|██████▏   | 2798/4545 [3:29:02<3:40:26,  7.57s/it] 62%|██████▏   | 2799/4545 [3:29:08<3:27:54,  7.14s/it] 62%|██████▏   | 2800/4545 [3:29:11<2:46:47,  5.73s/it]                                                       {'loss': 0.1103, 'grad_norm': 10.544239044189453, 'learning_rate': 2.6259592260310446e-06, 'rewards/chosen': -1.014062523841858, 'rewards/rejected': -21.346874237060547, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 20.306249618530273, 'logps/chosen': -270.95001220703125, 'logps/rejected': -367.79998779296875, 'logits/chosen': -10.725000381469727, 'logits/rejected': -10.324999809265137, 'epoch': 1.85}
 62%|██████▏   | 2800/4545 [3:29:11<2:46:47,  5.73s/it] 62%|██████▏   | 2801/4545 [3:29:15<2:29:08,  5.13s/it] 62%|██████▏   | 2802/4545 [3:29:17<2:08:31,  4.42s/it] 62%|██████▏   | 2803/4545 [3:29:20<1:56:19,  4.01s/it] 62%|██████▏   | 2804/4545 [3:29:24<1:48:51,  3.75s/it] 62%|██████▏   | 2805/4545 [3:29:27<1:45:10,  3.63s/it] 62%|██████▏   | 2806/4545 [3:29:31<1:48:28,  3.74s/it] 62%|██████▏   | 2807/4545 [3:29:34<1:42:21,  3.53s/it] 62%|██████▏   | 2808/4545 [3:29:38<1:47:07,  3.70s/it] 62%|██████▏   | 2809/4545 [3:29:42<1:48:58,  3.77s/it] 62%|██████▏   | 2810/4545 [3:29:45<1:38:54,  3.42s/it]                                                       {'loss': 0.0716, 'grad_norm': 1.7621214389801025, 'learning_rate': 2.607809819942589e-06, 'rewards/chosen': -2.385937452316284, 'rewards/rejected': -20.293750762939453, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 17.912500381469727, 'logps/chosen': -163.64999389648438, 'logps/rejected': -283.1000061035156, 'logits/chosen': -10.993749618530273, 'logits/rejected': -10.699999809265137, 'epoch': 1.85}
 62%|██████▏   | 2810/4545 [3:29:45<1:38:54,  3.42s/it] 62%|██████▏   | 2811/4545 [3:29:48<1:39:49,  3.45s/it] 62%|██████▏   | 2812/4545 [3:29:52<1:44:24,  3.61s/it] 62%|██████▏   | 2813/4545 [3:29:56<1:45:50,  3.67s/it] 62%|██████▏   | 2814/4545 [3:30:00<1:50:08,  3.82s/it] 62%|██████▏   | 2815/4545 [3:30:04<1:50:45,  3.84s/it] 62%|██████▏   | 2816/4545 [3:30:08<1:51:29,  3.87s/it] 62%|██████▏   | 2817/4545 [3:30:12<1:52:20,  3.90s/it] 62%|██████▏   | 2818/4545 [3:30:16<1:53:27,  3.94s/it] 62%|██████▏   | 2819/4545 [3:30:20<1:54:47,  3.99s/it] 62%|██████▏   | 2820/4545 [3:30:23<1:49:15,  3.80s/it]                                                       {'loss': 0.2348, 'grad_norm': 2.568591356277466, 'learning_rate': 2.589616603005686e-06, 'rewards/chosen': -0.6625000238418579, 'rewards/rejected': -22.681249618530273, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 22.006250381469727, 'logps/chosen': -293.6499938964844, 'logps/rejected': -381.6000061035156, 'logits/chosen': -10.268750190734863, 'logits/rejected': -9.881250381469727, 'epoch': 1.86}
 62%|██████▏   | 2820/4545 [3:30:23<1:49:15,  3.80s/it] 62%|██████▏   | 2821/4545 [3:30:27<1:51:33,  3.88s/it] 62%|██████▏   | 2822/4545 [3:30:30<1:43:08,  3.59s/it] 62%|██████▏   | 2823/4545 [3:30:32<1:29:43,  3.13s/it] 62%|██████▏   | 2824/4545 [3:30:36<1:29:58,  3.14s/it] 62%|██████▏   | 2825/4545 [3:30:40<1:38:45,  3.44s/it] 62%|██████▏   | 2826/4545 [3:30:44<1:43:39,  3.62s/it] 62%|██████▏   | 2827/4545 [3:30:47<1:38:11,  3.43s/it] 62%|██████▏   | 2828/4545 [3:30:51<1:42:13,  3.57s/it] 62%|██████▏   | 2829/4545 [3:30:55<1:44:22,  3.65s/it] 62%|██████▏   | 2830/4545 [3:30:58<1:46:29,  3.73s/it]                                                       {'loss': 0.1339, 'grad_norm': 12.797553062438965, 'learning_rate': 2.571381529710472e-06, 'rewards/chosen': -0.08203125, 'rewards/rejected': -23.037500381469727, 'rewards/accuracies': 0.9375, 'rewards/margins': 22.953125, 'logps/chosen': -319.3500061035156, 'logps/rejected': -366.3999938964844, 'logits/chosen': -10.556249618530273, 'logits/rejected': -10.237500190734863, 'epoch': 1.87}
 62%|██████▏   | 2830/4545 [3:30:58<1:46:29,  3.73s/it] 62%|██████▏   | 2831/4545 [3:31:02<1:48:12,  3.79s/it] 62%|██████▏   | 2832/4545 [3:31:06<1:42:49,  3.60s/it] 62%|██████▏   | 2833/4545 [3:31:09<1:45:32,  3.70s/it] 62%|██████▏   | 2834/4545 [3:31:12<1:39:00,  3.47s/it] 62%|██████▏   | 2835/4545 [3:31:16<1:36:40,  3.39s/it] 62%|██████▏   | 2836/4545 [3:31:19<1:33:20,  3.28s/it] 62%|██████▏   | 2837/4545 [3:31:21<1:25:23,  3.00s/it] 62%|██████▏   | 2838/4545 [3:31:25<1:33:28,  3.29s/it] 62%|██████▏   | 2839/4545 [3:31:29<1:37:31,  3.43s/it] 62%|██████▏   | 2840/4545 [3:31:33<1:41:35,  3.57s/it]                                                       {'loss': 0.0846, 'grad_norm': 44.82539749145508, 'learning_rate': 2.5531065590436933e-06, 'rewards/chosen': -2.684765577316284, 'rewards/rejected': -20.78125, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 18.125, 'logps/chosen': -206.35000610351562, 'logps/rejected': -332.70001220703125, 'logits/chosen': -11.018750190734863, 'logits/rejected': -10.637499809265137, 'epoch': 1.87}
 62%|██████▏   | 2840/4545 [3:31:33<1:41:35,  3.57s/it] 63%|██████▎   | 2841/4545 [3:31:37<1:44:44,  3.69s/it] 63%|██████▎   | 2842/4545 [3:31:40<1:43:10,  3.64s/it] 63%|██████▎   | 2843/4545 [3:31:44<1:44:36,  3.69s/it] 63%|██████▎   | 2844/4545 [3:31:48<1:46:37,  3.76s/it] 63%|██████▎   | 2845/4545 [3:31:51<1:45:16,  3.72s/it] 63%|██████▎   | 2846/4545 [3:31:55<1:46:57,  3.78s/it] 63%|██████▎   | 2847/4545 [3:32:00<1:50:25,  3.90s/it] 63%|██████▎   | 2848/4545 [3:32:30<5:31:48, 11.73s/it] 63%|██████▎   | 2849/4545 [3:32:33<4:25:18,  9.39s/it] 63%|██████▎   | 2850/4545 [3:32:37<3:38:39,  7.74s/it]                                                       {'loss': 0.1121, 'grad_norm': 26.523162841796875, 'learning_rate': 2.534793654278255e-06, 'rewards/chosen': -0.77783203125, 'rewards/rejected': -31.125, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 30.356250762939453, 'logps/chosen': -301.70001220703125, 'logps/rejected': -479.6000061035156, 'logits/chosen': -11.131250381469727, 'logits/rejected': -10.643750190734863, 'epoch': 1.88}
 63%|██████▎   | 2850/4545 [3:32:37<3:38:39,  7.74s/it] 63%|██████▎   | 2851/4545 [3:32:41<3:06:13,  6.60s/it] 63%|██████▎   | 2852/4545 [3:32:45<2:43:24,  5.79s/it] 63%|██████▎   | 2853/4545 [3:32:49<2:27:34,  5.23s/it] 63%|██████▎   | 2854/4545 [3:32:53<2:16:22,  4.84s/it] 63%|██████▎   | 2855/4545 [3:32:56<2:01:16,  4.31s/it] 63%|██████▎   | 2856/4545 [3:32:59<1:48:32,  3.86s/it] 63%|██████▎   | 2857/4545 [3:33:03<1:48:51,  3.87s/it] 63%|██████▎   | 2858/4545 [3:33:07<1:49:10,  3.88s/it] 63%|██████▎   | 2859/4545 [3:33:11<1:51:41,  3.97s/it] 63%|██████▎   | 2860/4545 [3:33:14<1:47:19,  3.82s/it]                                                       {'loss': 0.1235, 'grad_norm': 2.412540912628174, 'learning_rate': 2.5164447827623104e-06, 'rewards/chosen': -0.20703125, 'rewards/rejected': -25.318750381469727, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 25.059375762939453, 'logps/chosen': -345.8999938964844, 'logps/rejected': -416.29998779296875, 'logits/chosen': -11.399999618530273, 'logits/rejected': -11.125, 'epoch': 1.89}
 63%|██████▎   | 2860/4545 [3:33:14<1:47:19,  3.82s/it] 63%|██████▎   | 2861/4545 [3:33:18<1:48:21,  3.86s/it] 63%|██████▎   | 2862/4545 [3:33:22<1:42:53,  3.67s/it] 63%|██████▎   | 2863/4545 [3:33:26<1:46:10,  3.79s/it] 63%|██████▎   | 2864/4545 [3:33:30<1:47:20,  3.83s/it] 63%|██████▎   | 2865/4545 [3:33:33<1:46:58,  3.82s/it] 63%|██████▎   | 2866/4545 [3:33:36<1:41:08,  3.61s/it] 63%|██████▎   | 2867/4545 [3:33:40<1:40:12,  3.58s/it] 63%|██████▎   | 2868/4545 [3:33:44<1:40:24,  3.59s/it] 63%|██████▎   | 2869/4545 [3:33:47<1:39:45,  3.57s/it] 63%|██████▎   | 2870/4545 [3:33:51<1:42:36,  3.68s/it]                                                       {'loss': 0.1025, 'grad_norm': 3.749598503112793, 'learning_rate': 2.4980619157079026e-06, 'rewards/chosen': -0.670703113079071, 'rewards/rejected': -33.462501525878906, 'rewards/accuracies': 0.96875, 'rewards/margins': 32.75, 'logps/chosen': -400.25, 'logps/rejected': -532.4000244140625, 'logits/chosen': -10.899999618530273, 'logits/rejected': -10.612500190734863, 'epoch': 1.89}
 63%|██████▎   | 2870/4545 [3:33:51<1:42:36,  3.68s/it] 63%|██████▎   | 2871/4545 [3:33:55<1:46:37,  3.82s/it] 63%|██████▎   | 2872/4545 [3:33:59<1:45:33,  3.79s/it] 63%|██████▎   | 2873/4545 [3:34:03<1:47:50,  3.87s/it] 63%|██████▎   | 2874/4545 [3:34:07<1:49:07,  3.92s/it] 63%|██████▎   | 2875/4545 [3:34:11<1:47:59,  3.88s/it] 63%|██████▎   | 2876/4545 [3:34:14<1:40:08,  3.60s/it] 63%|██████▎   | 2877/4545 [3:34:17<1:39:16,  3.57s/it] 63%|██████▎   | 2878/4545 [3:34:21<1:44:44,  3.77s/it] 63%|██████▎   | 2879/4545 [3:34:26<1:47:33,  3.87s/it] 63%|██████▎   | 2880/4545 [3:34:30<1:48:32,  3.91s/it]                                                       {'loss': 0.1656, 'grad_norm': 36.06305694580078, 'learning_rate': 2.4796470279792044e-06, 'rewards/chosen': -3.6890625953674316, 'rewards/rejected': -30.081249237060547, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 26.399999618530273, 'logps/chosen': -253.5500030517578, 'logps/rejected': -403.20001220703125, 'logits/chosen': -11.449999809265137, 'logits/rejected': -11.03125, 'epoch': 1.9}
 63%|██████▎   | 2880/4545 [3:34:30<1:48:32,  3.91s/it] 63%|██████▎   | 2881/4545 [3:34:33<1:46:33,  3.84s/it] 63%|██████▎   | 2882/4545 [3:34:37<1:44:30,  3.77s/it] 63%|██████▎   | 2883/4545 [3:34:40<1:40:48,  3.64s/it] 63%|██████▎   | 2884/4545 [3:34:44<1:43:05,  3.72s/it] 63%|██████▎   | 2885/4545 [3:34:48<1:47:13,  3.88s/it] 63%|██████▎   | 2886/4545 [3:34:53<1:49:53,  3.97s/it] 64%|██████▎   | 2887/4545 [3:34:56<1:49:32,  3.96s/it] 64%|██████▎   | 2888/4545 [3:35:00<1:42:32,  3.71s/it] 64%|██████▎   | 2889/4545 [3:35:04<1:44:15,  3.78s/it] 64%|██████▎   | 2890/4545 [3:35:07<1:44:54,  3.80s/it]                                                       {'loss': 0.1586, 'grad_norm': 10.39697551727295, 'learning_rate': 2.4612020978803575e-06, 'rewards/chosen': -2.604296922683716, 'rewards/rejected': -31.100000381469727, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 28.456249237060547, 'logps/chosen': -287.75, 'logps/rejected': -473.20001220703125, 'logits/chosen': -11.125, 'logits/rejected': -10.637499809265137, 'epoch': 1.91}
 64%|██████▎   | 2890/4545 [3:35:07<1:44:54,  3.80s/it] 64%|██████▎   | 2891/4545 [3:35:11<1:43:38,  3.76s/it] 64%|██████▎   | 2892/4545 [3:35:14<1:36:31,  3.50s/it] 64%|██████▎   | 2893/4545 [3:35:18<1:40:06,  3.64s/it] 64%|██████▎   | 2894/4545 [3:35:22<1:41:39,  3.69s/it] 64%|██████▎   | 2895/4545 [3:35:26<1:43:17,  3.76s/it] 64%|██████▎   | 2896/4545 [3:35:30<1:44:29,  3.80s/it] 64%|██████▎   | 2897/4545 [3:35:33<1:45:25,  3.84s/it] 64%|██████▍   | 2898/4545 [3:35:37<1:46:05,  3.86s/it] 64%|██████▍   | 2899/4545 [3:35:41<1:46:33,  3.88s/it] 64%|██████▍   | 2900/4545 [3:35:45<1:46:50,  3.90s/it]                                                       {'loss': 0.1563, 'grad_norm': 6.061556816101074, 'learning_rate': 2.442729106942942e-06, 'rewards/chosen': 0.521289050579071, 'rewards/rejected': -33.875, 'rewards/accuracies': 0.9375, 'rewards/margins': 34.462501525878906, 'logps/chosen': -414.70001220703125, 'logps/rejected': -516.5999755859375, 'logits/chosen': -10.675000190734863, 'logits/rejected': -10.337499618530273, 'epoch': 1.91}
 64%|██████▍   | 2900/4545 [3:35:45<1:46:50,  3.90s/it] 64%|██████▍   | 2901/4545 [3:35:49<1:43:58,  3.79s/it] 64%|██████▍   | 2902/4545 [3:35:52<1:41:44,  3.72s/it] 64%|██████▍   | 2903/4545 [3:35:56<1:42:46,  3.76s/it] 64%|██████▍   | 2904/4545 [3:36:00<1:43:02,  3.77s/it] 64%|██████▍   | 2905/4545 [3:36:04<1:40:57,  3.69s/it] 64%|██████▍   | 2906/4545 [3:36:07<1:42:41,  3.76s/it] 64%|██████▍   | 2907/4545 [3:36:11<1:43:57,  3.81s/it] 64%|██████▍   | 2908/4545 [3:36:15<1:44:30,  3.83s/it] 64%|██████▍   | 2909/4545 [3:36:19<1:40:22,  3.68s/it] 64%|██████▍   | 2910/4545 [3:36:22<1:39:23,  3.65s/it]                                                       {'loss': 0.0947, 'grad_norm': 12.666664123535156, 'learning_rate': 2.4242300397131025e-06, 'rewards/chosen': -3.3031249046325684, 'rewards/rejected': -25.618749618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 22.3125, 'logps/chosen': -252.5, 'logps/rejected': -394.3999938964844, 'logits/chosen': -11.168749809265137, 'logits/rejected': -10.756250381469727, 'epoch': 1.92}
 64%|██████▍   | 2910/4545 [3:36:22<1:39:23,  3.65s/it] 64%|██████▍   | 2911/4545 [3:36:26<1:44:16,  3.83s/it] 64%|██████▍   | 2912/4545 [3:36:30<1:45:59,  3.89s/it] 64%|██████▍   | 2913/4545 [3:36:34<1:46:13,  3.91s/it] 64%|██████▍   | 2914/4545 [3:36:39<1:48:47,  4.00s/it] 64%|██████▍   | 2915/4545 [3:36:42<1:47:23,  3.95s/it] 64%|██████▍   | 2916/4545 [3:36:46<1:45:53,  3.90s/it] 64%|██████▍   | 2917/4545 [3:36:50<1:46:09,  3.91s/it] 64%|██████▍   | 2918/4545 [3:36:54<1:47:53,  3.98s/it] 64%|██████▍   | 2919/4545 [3:36:58<1:46:33,  3.93s/it] 64%|██████▍   | 2920/4545 [3:37:02<1:46:25,  3.93s/it]                                                       {'loss': 0.055, 'grad_norm': 2.4142138957977295, 'learning_rate': 2.405706883538352e-06, 'rewards/chosen': 0.20976562798023224, 'rewards/rejected': -26.196874618530273, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 26.387500762939453, 'logps/chosen': -338.20001220703125, 'logps/rejected': -450.3999938964844, 'logits/chosen': -11.118749618530273, 'logits/rejected': -10.756250381469727, 'epoch': 1.93}
 64%|██████▍   | 2920/4545 [3:37:02<1:46:25,  3.93s/it] 64%|██████▍   | 2921/4545 [3:37:06<1:45:09,  3.88s/it] 64%|██████▍   | 2922/4545 [3:37:08<1:33:28,  3.46s/it] 64%|██████▍   | 2923/4545 [3:37:10<1:22:51,  3.06s/it] 64%|██████▍   | 2924/4545 [3:37:14<1:29:52,  3.33s/it] 64%|██████▍   | 2925/4545 [3:37:19<1:37:14,  3.60s/it] 64%|██████▍   | 2926/4545 [3:37:22<1:37:33,  3.62s/it] 64%|██████▍   | 2927/4545 [3:37:26<1:40:04,  3.71s/it] 64%|██████▍   | 2928/4545 [3:37:30<1:43:40,  3.85s/it] 64%|██████▍   | 2929/4545 [3:37:34<1:44:13,  3.87s/it] 64%|██████▍   | 2930/4545 [3:37:38<1:40:57,  3.75s/it]                                                       {'loss': 0.136, 'grad_norm': 0.4482736885547638, 'learning_rate': 2.3871616283540673e-06, 'rewards/chosen': -1.8542969226837158, 'rewards/rejected': -28.268749237060547, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 26.424999237060547, 'logps/chosen': -270.79998779296875, 'logps/rejected': -435.6000061035156, 'logits/chosen': -11.675000190734863, 'logits/rejected': -11.1875, 'epoch': 1.93}
 64%|██████▍   | 2930/4545 [3:37:38<1:40:57,  3.75s/it] 64%|██████▍   | 2931/4545 [3:37:40<1:32:50,  3.45s/it] 65%|██████▍   | 2932/4545 [3:37:45<1:37:41,  3.63s/it] 65%|██████▍   | 2933/4545 [3:37:48<1:37:56,  3.65s/it] 65%|██████▍   | 2934/4545 [3:37:52<1:38:38,  3.67s/it] 65%|██████▍   | 2935/4545 [3:37:56<1:40:44,  3.75s/it] 65%|██████▍   | 2936/4545 [3:38:00<1:39:47,  3.72s/it] 65%|██████▍   | 2937/4545 [3:38:03<1:39:06,  3.70s/it] 65%|██████▍   | 2938/4545 [3:38:07<1:38:32,  3.68s/it] 65%|██████▍   | 2939/4545 [3:38:11<1:41:56,  3.81s/it] 65%|██████▍   | 2940/4545 [3:38:15<1:44:20,  3.90s/it]                                                       {'loss': 0.1015, 'grad_norm': 0.6609407663345337, 'learning_rate': 2.3685962664697135e-06, 'rewards/chosen': -4.114453315734863, 'rewards/rejected': -33.88750076293945, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 29.762500762939453, 'logps/chosen': -216.5, 'logps/rejected': -457.3999938964844, 'logits/chosen': -11.918749809265137, 'logits/rejected': -11.362500190734863, 'epoch': 1.94}
 65%|██████▍   | 2940/4545 [3:38:15<1:44:20,  3.90s/it] 65%|██████▍   | 2941/4545 [3:38:19<1:42:29,  3.83s/it] 65%|██████▍   | 2942/4545 [3:38:22<1:38:33,  3.69s/it] 65%|██████▍   | 2943/4545 [3:38:26<1:42:32,  3.84s/it] 65%|██████▍   | 2944/4545 [3:38:29<1:33:20,  3.50s/it] 65%|██████▍   | 2945/4545 [3:38:33<1:38:38,  3.70s/it] 65%|██████▍   | 2946/4545 [3:38:37<1:42:00,  3.83s/it] 65%|██████▍   | 2947/4545 [3:38:41<1:42:40,  3.86s/it] 65%|██████▍   | 2948/4545 [3:38:45<1:44:32,  3.93s/it] 65%|██████▍   | 2949/4545 [3:38:48<1:34:29,  3.55s/it] 65%|██████▍   | 2950/4545 [3:38:51<1:29:34,  3.37s/it]                                                       {'loss': 0.0589, 'grad_norm': 0.29391565918922424, 'learning_rate': 2.3500127923548104e-06, 'rewards/chosen': -2.332812547683716, 'rewards/rejected': -37.162498474121094, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 34.78437423706055, 'logps/chosen': -236.64999389648438, 'logps/rejected': -477.70001220703125, 'logits/chosen': -12.037500381469727, 'logits/rejected': -11.600000381469727, 'epoch': 1.95}
 65%|██████▍   | 2950/4545 [3:38:51<1:29:34,  3.37s/it] 65%|██████▍   | 2951/4545 [3:38:55<1:35:55,  3.61s/it] 65%|██████▍   | 2952/4545 [3:38:57<1:26:02,  3.24s/it] 65%|██████▍   | 2953/4545 [3:39:02<1:33:27,  3.52s/it] 65%|██████▍   | 2954/4545 [3:39:06<1:36:34,  3.64s/it] 65%|██████▌   | 2955/4545 [3:39:09<1:38:38,  3.72s/it] 65%|██████▌   | 2956/4545 [3:39:12<1:31:21,  3.45s/it] 65%|██████▌   | 2957/4545 [3:39:16<1:34:59,  3.59s/it] 65%|██████▌   | 2958/4545 [3:39:20<1:39:44,  3.77s/it] 65%|██████▌   | 2959/4545 [3:39:24<1:41:46,  3.85s/it] 65%|██████▌   | 2960/4545 [3:39:53<4:56:36, 11.23s/it]                                                       {'loss': 0.0849, 'grad_norm': 2.9338417053222656, 'learning_rate': 2.331413202424668e-06, 'rewards/chosen': -1.3507201671600342, 'rewards/rejected': -25.03125, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 23.71875, 'logps/chosen': -330.3999938964844, 'logps/rejected': -437.1000061035156, 'logits/chosen': -11.675000190734863, 'logits/rejected': -11.206250190734863, 'epoch': 1.95}
 65%|██████▌   | 2960/4545 [3:39:53<4:56:36, 11.23s/it] 65%|██████▌   | 2961/4545 [3:39:57<3:58:31,  9.03s/it] 65%|██████▌   | 2962/4545 [3:40:01<3:17:49,  7.50s/it] 65%|██████▌   | 2963/4545 [3:40:05<2:50:54,  6.48s/it] 65%|██████▌   | 2964/4545 [3:40:08<2:27:03,  5.58s/it] 65%|██████▌   | 2965/4545 [3:40:12<2:13:56,  5.09s/it] 65%|██████▌   | 2966/4545 [3:40:16<2:04:25,  4.73s/it] 65%|██████▌   | 2967/4545 [3:40:19<1:53:34,  4.32s/it] 65%|██████▌   | 2968/4545 [3:40:23<1:50:19,  4.20s/it] 65%|██████▌   | 2969/4545 [3:40:27<1:49:21,  4.16s/it] 65%|██████▌   | 2970/4545 [3:40:31<1:47:31,  4.10s/it]                                                       {'loss': 0.0883, 'grad_norm': 0.8595091104507446, 'learning_rate': 2.3127994948259132e-06, 'rewards/chosen': -1.2839844226837158, 'rewards/rejected': -33.287498474121094, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 31.975000381469727, 'logps/chosen': -367.1000061035156, 'logps/rejected': -488.6000061035156, 'logits/chosen': -11.962499618530273, 'logits/rejected': -11.46875, 'epoch': 1.96}
 65%|██████▌   | 2970/4545 [3:40:31<1:47:31,  4.10s/it] 65%|██████▌   | 2971/4545 [3:40:35<1:45:58,  4.04s/it] 65%|██████▌   | 2972/4545 [3:40:39<1:42:41,  3.92s/it] 65%|██████▌   | 2973/4545 [3:40:43<1:45:16,  4.02s/it] 65%|██████▌   | 2974/4545 [3:40:47<1:44:01,  3.97s/it] 65%|██████▌   | 2975/4545 [3:40:51<1:44:07,  3.98s/it] 65%|██████▌   | 2976/4545 [3:40:55<1:43:37,  3.96s/it] 66%|██████▌   | 2977/4545 [3:40:59<1:43:30,  3.96s/it] 66%|██████▌   | 2978/4545 [3:41:03<1:44:42,  4.01s/it] 66%|██████▌   | 2979/4545 [3:41:07<1:45:24,  4.04s/it] 66%|██████▌   | 2980/4545 [3:41:11<1:44:27,  4.01s/it]                                                       {'loss': 0.1654, 'grad_norm': 2.188615560531616, 'learning_rate': 2.294173669221825e-06, 'rewards/chosen': -0.8218749761581421, 'rewards/rejected': -27.712499618530273, 'rewards/accuracies': 0.956250011920929, 'rewards/margins': 26.918750762939453, 'logps/chosen': -423.29998779296875, 'logps/rejected': -488.6000061035156, 'logits/chosen': -12.081250190734863, 'logits/rejected': -11.65625, 'epoch': 1.97}
 66%|██████▌   | 2980/4545 [3:41:11<1:44:27,  4.01s/it] 66%|██████▌   | 2981/4545 [3:41:14<1:38:36,  3.78s/it] 66%|██████▌   | 2982/4545 [3:41:18<1:40:04,  3.84s/it] 66%|██████▌   | 2983/4545 [3:41:22<1:37:38,  3.75s/it] 66%|██████▌   | 2984/4545 [3:41:26<1:38:29,  3.79s/it] 66%|██████▌   | 2985/4545 [3:41:29<1:35:27,  3.67s/it] 66%|██████▌   | 2986/4545 [3:41:33<1:37:12,  3.74s/it] 66%|██████▌   | 2987/4545 [3:41:37<1:38:57,  3.81s/it] 66%|██████▌   | 2988/4545 [3:41:41<1:36:38,  3.72s/it] 66%|██████▌   | 2989/4545 [3:41:45<1:39:48,  3.85s/it] 66%|██████▌   | 2990/4545 [3:41:49<1:40:38,  3.88s/it]                                                       {'loss': 0.075, 'grad_norm': 7.920345783233643, 'learning_rate': 2.275537726577519e-06, 'rewards/chosen': -2.909374952316284, 'rewards/rejected': -35.48749923706055, 'rewards/accuracies': 0.96875, 'rewards/margins': 32.54999923706055, 'logps/chosen': -320.1000061035156, 'logps/rejected': -482.79998779296875, 'logits/chosen': -12.043749809265137, 'logits/rejected': -11.537500381469727, 'epoch': 1.97}
 66%|██████▌   | 2990/4545 [3:41:49<1:40:38,  3.88s/it] 66%|██████▌   | 2991/4545 [3:41:53<1:40:50,  3.89s/it] 66%|██████▌   | 2992/4545 [3:41:57<1:43:11,  3.99s/it] 66%|██████▌   | 2993/4545 [3:42:01<1:45:06,  4.06s/it] 66%|██████▌   | 2994/4545 [3:42:05<1:43:51,  4.02s/it] 66%|██████▌   | 2995/4545 [3:42:09<1:43:00,  3.99s/it] 66%|██████▌   | 2996/4545 [3:42:12<1:34:12,  3.65s/it] 66%|██████▌   | 2997/4545 [3:42:16<1:36:12,  3.73s/it] 66%|██████▌   | 2998/4545 [3:42:19<1:35:26,  3.70s/it] 66%|██████▌   | 2999/4545 [3:42:23<1:36:58,  3.76s/it] 66%|██████▌   | 3000/4545 [3:42:27<1:35:34,  3.71s/it]                                                       {'loss': 0.0919, 'grad_norm': 9.559877395629883, 'learning_rate': 2.256893668944977e-06, 'rewards/chosen': -1.813867211341858, 'rewards/rejected': -33.631248474121094, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 31.787500381469727, 'logps/chosen': -389.75, 'logps/rejected': -521.4000244140625, 'logits/chosen': -12.012499809265137, 'logits/rejected': -11.518750190734863, 'epoch': 1.98}
 66%|██████▌   | 3000/4545 [3:42:27<1:35:34,  3.71s/it] 66%|██████▌   | 3001/4545 [3:42:31<1:37:15,  3.78s/it] 66%|██████▌   | 3002/4545 [3:42:34<1:35:59,  3.73s/it] 66%|██████▌   | 3003/4545 [3:42:38<1:37:25,  3.79s/it] 66%|██████▌   | 3004/4545 [3:42:42<1:38:22,  3.83s/it] 66%|██████▌   | 3005/4545 [3:42:46<1:41:22,  3.95s/it] 66%|██████▌   | 3006/4545 [3:42:50<1:37:56,  3.82s/it] 66%|██████▌   | 3007/4545 [3:42:54<1:37:24,  3.80s/it] 66%|██████▌   | 3008/4545 [3:42:58<1:38:21,  3.84s/it] 66%|██████▌   | 3009/4545 [3:43:01<1:32:46,  3.62s/it] 66%|██████▌   | 3010/4545 [3:43:04<1:31:50,  3.59s/it]                                                       {'loss': 0.1028, 'grad_norm': 1.8885225057601929, 'learning_rate': 2.2382434992479735e-06, 'rewards/chosen': -1.4865233898162842, 'rewards/rejected': -28.5, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 26.981250762939453, 'logps/chosen': -361.0, 'logps/rejected': -436.29998779296875, 'logits/chosen': -11.612500190734863, 'logits/rejected': -11.181249618530273, 'epoch': 1.99}
 66%|██████▌   | 3010/4545 [3:43:04<1:31:50,  3.59s/it] 66%|██████▌   | 3011/4545 [3:43:08<1:32:29,  3.62s/it] 66%|██████▋   | 3012/4545 [3:43:12<1:34:47,  3.71s/it] 66%|██████▋   | 3013/4545 [3:43:16<1:35:27,  3.74s/it] 66%|██████▋   | 3014/4545 [3:43:20<1:36:52,  3.80s/it] 66%|██████▋   | 3015/4545 [3:43:24<1:37:50,  3.84s/it] 66%|██████▋   | 3016/4545 [3:43:28<1:39:52,  3.92s/it] 66%|██████▋   | 3017/4545 [3:43:30<1:27:53,  3.45s/it] 66%|██████▋   | 3018/4545 [3:43:34<1:31:22,  3.59s/it] 66%|██████▋   | 3019/4545 [3:43:38<1:34:01,  3.70s/it] 66%|██████▋   | 3020/4545 [3:43:41<1:29:38,  3.53s/it]                                                       {'loss': 0.1189, 'grad_norm': 3.5773696899414062, 'learning_rate': 2.2195892210668975e-06, 'rewards/chosen': -2.969921827316284, 'rewards/rejected': -24.774999618530273, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 21.78125, 'logps/chosen': -278.79998779296875, 'logps/rejected': -353.0, 'logits/chosen': -11.675000190734863, 'logits/rejected': -11.225000381469727, 'epoch': 1.99}
 66%|██████▋   | 3020/4545 [3:43:41<1:29:38,  3.53s/it] 66%|██████▋   | 3021/4545 [3:43:45<1:31:31,  3.60s/it] 66%|██████▋   | 3022/4545 [3:43:48<1:29:34,  3.53s/it] 67%|██████▋   | 3023/4545 [3:43:52<1:32:23,  3.64s/it] 67%|██████▋   | 3024/4545 [3:43:56<1:35:52,  3.78s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:21,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.50s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:54,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:26<00:39,  1.01it/s][A
 35%|███▌      | 21/60 [00:27<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.10s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [01:02<04:43,  8.86s/it][A
 48%|████▊     | 29/60 [01:03<03:23,  6.56s/it][A
 50%|█████     | 30/60 [01:05<02:32,  5.09s/it][A
 52%|█████▏    | 31/60 [01:06<01:56,  4.03s/it][A
 53%|█████▎    | 32/60 [01:08<01:31,  3.26s/it][A
 55%|█████▌    | 33/60 [01:09<01:12,  2.68s/it][A
 57%|█████▋    | 34/60 [01:10<00:55,  2.12s/it][A
 58%|█████▊    | 35/60 [01:11<00:47,  1.91s/it][A
 60%|██████    | 36/60 [01:13<00:42,  1.77s/it][A
 62%|██████▏   | 37/60 [01:13<00:32,  1.41s/it][A
 63%|██████▎   | 38/60 [01:15<00:32,  1.46s/it][A
 65%|██████▌   | 39/60 [01:16<00:28,  1.37s/it][A
 67%|██████▋   | 40/60 [01:17<00:23,  1.19s/it][A
 68%|██████▊   | 41/60 [01:18<00:24,  1.28s/it][A
 70%|███████   | 42/60 [01:20<00:24,  1.36s/it][A
 72%|███████▏  | 43/60 [01:21<00:21,  1.25s/it][A
 73%|███████▎  | 44/60 [01:22<00:20,  1.31s/it][A
 75%|███████▌  | 45/60 [01:23<00:17,  1.15s/it][A
 77%|███████▋  | 46/60 [01:24<00:17,  1.28s/it][A
 78%|███████▊  | 47/60 [01:52<02:00,  9.26s/it][A
 80%|████████  | 48/60 [01:53<01:20,  6.72s/it][A
 82%|████████▏ | 49/60 [01:55<00:56,  5.18s/it][A
 83%|████████▎ | 50/60 [01:56<00:41,  4.13s/it][A
 85%|████████▌ | 51/60 [01:58<00:30,  3.36s/it][A
 87%|████████▋ | 52/60 [01:59<00:21,  2.73s/it][A
 88%|████████▊ | 53/60 [02:00<00:15,  2.24s/it][A
 90%|█████████ | 54/60 [02:02<00:12,  2.03s/it][A
 92%|█████████▏| 55/60 [02:03<00:08,  1.65s/it][A
 93%|█████████▎| 56/60 [02:04<00:06,  1.63s/it][A
 95%|█████████▌| 57/60 [02:06<00:04,  1.61s/it][A
 97%|█████████▋| 58/60 [02:07<00:03,  1.52s/it][A
 98%|█████████▊| 59/60 [02:09<00:01,  1.54s/it][A
100%|██████████| 60/60 [02:10<00:00,  1.57s/it][A                                                       
                                               [A{'eval_loss': 0.35144418478012085, 'eval_runtime': 132.4483, 'eval_samples_per_second': 7.195, 'eval_steps_per_second': 0.453, 'eval_rewards/chosen': -2.2305338382720947, 'eval_rewards/rejected': -24.615625381469727, 'eval_rewards/accuracies': 0.8800926208496094, 'eval_rewards/margins': 22.392578125, 'eval_logps/chosen': -400.125, 'eval_logps/rejected': -398.29998779296875, 'eval_logits/chosen': -11.252604484558105, 'eval_logits/rejected': -11.060937881469727, 'epoch': 2.0}
 67%|██████▋   | 3024/4545 [3:46:09<1:35:52,  3.78s/it]
100%|██████████| 60/60 [02:10<00:00,  1.57s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 67%|██████▋   | 3025/4545 [3:46:23<19:40:57, 46.62s/it] 67%|██████▋   | 3026/4545 [3:46:27<14:15:22, 33.79s/it] 67%|██████▋   | 3027/4545 [3:46:30<10:27:53, 24.82s/it] 67%|██████▋   | 3028/4545 [3:46:34<7:48:11, 18.52s/it]  67%|██████▋   | 3029/4545 [3:46:38<5:57:22, 14.14s/it] 67%|██████▋   | 3030/4545 [3:46:42<4:39:42, 11.08s/it]                                                       {'loss': 0.1415, 'grad_norm': 0.21071873605251312, 'learning_rate': 2.200932838423513e-06, 'rewards/chosen': 2.2554688453674316, 'rewards/rejected': -28.743749618530273, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 30.993749618530273, 'logps/chosen': -571.7000122070312, 'logps/rejected': -594.7999877929688, 'logits/chosen': -10.721875190734863, 'logits/rejected': -10.524999618530273, 'epoch': 2.0}
 67%|██████▋   | 3030/4545 [3:46:42<4:39:42, 11.08s/it] 67%|██████▋   | 3031/4545 [3:46:45<3:41:04,  8.76s/it] 67%|██████▋   | 3032/4545 [3:46:49<3:04:20,  7.31s/it] 67%|██████▋   | 3033/4545 [3:46:53<2:36:49,  6.22s/it] 67%|██████▋   | 3034/4545 [3:46:56<2:14:22,  5.34s/it] 67%|██████▋   | 3035/4545 [3:47:00<2:00:42,  4.80s/it] 67%|██████▋   | 3036/4545 [3:47:04<1:54:03,  4.54s/it] 67%|██████▋   | 3037/4545 [3:47:08<1:49:19,  4.35s/it] 67%|██████▋   | 3038/4545 [3:47:12<1:45:54,  4.22s/it] 67%|██████▋   | 3039/4545 [3:47:15<1:42:43,  4.09s/it] 67%|██████▋   | 3040/4545 [3:47:19<1:38:02,  3.91s/it]                                                       {'loss': 0.0062, 'grad_norm': 0.4622560739517212, 'learning_rate': 2.182276355565664e-06, 'rewards/chosen': -2.362109422683716, 'rewards/rejected': -32.431251525878906, 'rewards/accuracies': 1.0, 'rewards/margins': 30.056249618530273, 'logps/chosen': -287.6000061035156, 'logps/rejected': -465.70001220703125, 'logits/chosen': -11.637499809265137, 'logits/rejected': -11.262499809265137, 'epoch': 2.01}
 67%|██████▋   | 3040/4545 [3:47:19<1:38:02,  3.91s/it] 67%|██████▋   | 3041/4545 [3:47:22<1:35:06,  3.79s/it] 67%|██████▋   | 3042/4545 [3:47:27<1:37:31,  3.89s/it] 67%|██████▋   | 3043/4545 [3:47:31<1:39:02,  3.96s/it] 67%|██████▋   | 3044/4545 [3:47:59<4:42:34, 11.30s/it] 67%|██████▋   | 3045/4545 [3:48:03<3:46:59,  9.08s/it] 67%|██████▋   | 3046/4545 [3:48:06<2:59:47,  7.20s/it] 67%|██████▋   | 3047/4545 [3:48:10<2:34:59,  6.21s/it] 67%|██████▋   | 3048/4545 [3:48:13<2:16:33,  5.47s/it] 67%|██████▋   | 3049/4545 [3:48:17<2:04:44,  5.00s/it] 67%|██████▋   | 3050/4545 [3:48:20<1:49:15,  4.38s/it]                                                       {'loss': 0.0083, 'grad_norm': 0.6480205059051514, 'learning_rate': 2.16362177675196e-06, 'rewards/chosen': -1.282812476158142, 'rewards/rejected': -30.293750762939453, 'rewards/accuracies': 1.0, 'rewards/margins': 29.006250381469727, 'logps/chosen': -371.79998779296875, 'logps/rejected': -438.3999938964844, 'logits/chosen': -11.743749618530273, 'logits/rejected': -11.175000190734863, 'epoch': 2.01}
 67%|██████▋   | 3050/4545 [3:48:20<1:49:15,  4.38s/it] 67%|██████▋   | 3051/4545 [3:48:24<1:45:32,  4.24s/it] 67%|██████▋   | 3052/4545 [3:48:28<1:42:57,  4.14s/it] 67%|██████▋   | 3053/4545 [3:48:32<1:42:24,  4.12s/it] 67%|██████▋   | 3054/4545 [3:48:36<1:40:50,  4.06s/it] 67%|██████▋   | 3055/4545 [3:48:40<1:39:41,  4.01s/it] 67%|██████▋   | 3056/4545 [3:48:44<1:40:47,  4.06s/it] 67%|██████▋   | 3057/4545 [3:48:48<1:39:24,  4.01s/it] 67%|██████▋   | 3058/4545 [3:48:52<1:38:44,  3.98s/it] 67%|██████▋   | 3059/4545 [3:48:56<1:38:06,  3.96s/it] 67%|██████▋   | 3060/4545 [3:48:59<1:33:55,  3.80s/it]                                                       {'loss': 0.0208, 'grad_norm': 11.633434295654297, 'learning_rate': 2.1449711060364608e-06, 'rewards/chosen': -2.0521483421325684, 'rewards/rejected': -26.337499618530273, 'rewards/accuracies': 1.0, 'rewards/margins': 24.3125, 'logps/chosen': -330.29998779296875, 'logps/rejected': -432.20001220703125, 'logits/chosen': -11.475000381469727, 'logits/rejected': -11.037500381469727, 'epoch': 2.02}
 67%|██████▋   | 3060/4545 [3:48:59<1:33:55,  3.80s/it] 67%|██████▋   | 3061/4545 [3:49:03<1:34:48,  3.83s/it] 67%|██████▋   | 3062/4545 [3:49:07<1:35:13,  3.85s/it] 67%|██████▋   | 3063/4545 [3:49:11<1:35:31,  3.87s/it] 67%|██████▋   | 3064/4545 [3:49:15<1:34:07,  3.81s/it] 67%|██████▋   | 3065/4545 [3:49:19<1:36:36,  3.92s/it] 67%|██████▋   | 3066/4545 [3:49:22<1:32:35,  3.76s/it] 67%|██████▋   | 3067/4545 [3:49:26<1:33:11,  3.78s/it] 68%|██████▊   | 3068/4545 [3:49:30<1:35:06,  3.86s/it] 68%|██████▊   | 3069/4545 [3:49:34<1:32:16,  3.75s/it] 68%|██████▊   | 3070/4545 [3:49:36<1:25:29,  3.48s/it]                                                       {'loss': 0.0327, 'grad_norm': 7.957546710968018, 'learning_rate': 2.1263263470533824e-06, 'rewards/chosen': -5.01171875, 'rewards/rejected': -34.962501525878906, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 29.950000762939453, 'logps/chosen': -228.75, 'logps/rejected': -440.20001220703125, 'logits/chosen': -12.143750190734863, 'logits/rejected': -11.612500190734863, 'epoch': 2.03}
 68%|██████▊   | 3070/4545 [3:49:36<1:25:29,  3.48s/it] 68%|██████▊   | 3071/4545 [3:49:41<1:30:45,  3.69s/it] 68%|██████▊   | 3072/4545 [3:49:45<1:32:14,  3.76s/it] 68%|██████▊   | 3073/4545 [3:49:49<1:34:36,  3.86s/it] 68%|██████▊   | 3074/4545 [3:49:52<1:30:52,  3.71s/it] 68%|██████▊   | 3075/4545 [3:49:56<1:32:12,  3.76s/it] 68%|██████▊   | 3076/4545 [3:50:00<1:33:12,  3.81s/it] 68%|██████▊   | 3077/4545 [3:50:04<1:33:42,  3.83s/it] 68%|██████▊   | 3078/4545 [3:50:07<1:32:37,  3.79s/it] 68%|██████▊   | 3079/4545 [3:50:11<1:33:22,  3.82s/it] 68%|██████▊   | 3080/4545 [3:50:14<1:24:45,  3.47s/it]                                                       {'loss': 0.0557, 'grad_norm': 6.337785720825195, 'learning_rate': 2.107689502801843e-06, 'rewards/chosen': -4.528906345367432, 'rewards/rejected': -38.912498474121094, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 34.349998474121094, 'logps/chosen': -337.6000061035156, 'logps/rejected': -564.5999755859375, 'logits/chosen': -12.024999618530273, 'logits/rejected': -11.524999618530273, 'epoch': 2.03}
 68%|██████▊   | 3080/4545 [3:50:14<1:24:45,  3.47s/it] 68%|██████▊   | 3081/4545 [3:50:18<1:28:42,  3.64s/it] 68%|██████▊   | 3082/4545 [3:50:22<1:29:56,  3.69s/it] 68%|██████▊   | 3083/4545 [3:50:26<1:32:53,  3.81s/it] 68%|██████▊   | 3084/4545 [3:50:30<1:33:27,  3.84s/it] 68%|██████▊   | 3085/4545 [3:50:34<1:33:37,  3.85s/it] 68%|██████▊   | 3086/4545 [3:50:36<1:22:45,  3.40s/it] 68%|██████▊   | 3087/4545 [3:50:40<1:26:21,  3.55s/it] 68%|██████▊   | 3088/4545 [3:50:44<1:28:45,  3.66s/it] 68%|██████▊   | 3089/4545 [3:50:48<1:30:29,  3.73s/it] 68%|██████▊   | 3090/4545 [3:50:52<1:31:57,  3.79s/it]                                                       {'loss': 0.043, 'grad_norm': 10.361865043640137, 'learning_rate': 2.0890625754306844e-06, 'rewards/chosen': -3.5531249046325684, 'rewards/rejected': -29.862499237060547, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 26.287500381469727, 'logps/chosen': -357.70001220703125, 'logps/rejected': -448.8999938964844, 'logits/chosen': -12.362500190734863, 'logits/rejected': -11.943750381469727, 'epoch': 2.04}
 68%|██████▊   | 3090/4545 [3:50:52<1:31:57,  3.79s/it] 68%|██████▊   | 3091/4545 [3:50:55<1:28:39,  3.66s/it] 68%|██████▊   | 3092/4545 [3:50:59<1:28:01,  3.64s/it] 68%|██████▊   | 3093/4545 [3:51:03<1:30:52,  3.76s/it] 68%|██████▊   | 3094/4545 [3:51:31<4:32:07, 11.25s/it] 68%|██████▊   | 3095/4545 [3:51:34<3:28:02,  8.61s/it] 68%|██████▊   | 3096/4545 [3:51:38<2:53:41,  7.19s/it] 68%|██████▊   | 3097/4545 [3:51:42<2:31:01,  6.26s/it] 68%|██████▊   | 3098/4545 [3:51:46<2:13:52,  5.55s/it] 68%|██████▊   | 3099/4545 [3:51:50<2:02:02,  5.06s/it] 68%|██████▊   | 3100/4545 [3:52:22<5:18:44, 13.24s/it]                                                       {'loss': 0.0403, 'grad_norm': 33.7939338684082, 'learning_rate': 2.0704475660233837e-06, 'rewards/chosen': -1.965429663658142, 'rewards/rejected': -31.350000381469727, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 29.387500762939453, 'logps/chosen': -379.29998779296875, 'logps/rejected': -520.2000122070312, 'logits/chosen': -12.462499618530273, 'logits/rejected': -11.931249618530273, 'epoch': 2.05}
 68%|██████▊   | 3100/4545 [3:52:22<5:18:44, 13.24s/it] 68%|██████▊   | 3101/4545 [3:52:29<4:33:40, 11.37s/it] 68%|██████▊   | 3102/4545 [3:52:37<4:06:29, 10.25s/it] 68%|██████▊   | 3103/4545 [3:52:44<3:46:36,  9.43s/it] 68%|██████▊   | 3104/4545 [3:52:52<3:34:15,  8.92s/it] 68%|██████▊   | 3105/4545 [3:52:58<3:12:27,  8.02s/it] 68%|██████▊   | 3106/4545 [3:53:05<3:09:20,  7.90s/it] 68%|██████▊   | 3107/4545 [3:53:12<3:00:06,  7.52s/it] 68%|██████▊   | 3108/4545 [3:53:19<2:59:35,  7.50s/it] 68%|██████▊   | 3109/4545 [3:53:27<3:00:14,  7.53s/it] 68%|██████▊   | 3110/4545 [3:53:35<2:59:49,  7.52s/it]                                                       {'loss': 0.0387, 'grad_norm': 0.2734803557395935, 'learning_rate': 2.0518464743830747e-06, 'rewards/chosen': -2.5318360328674316, 'rewards/rejected': -29.274999618530273, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 26.75, 'logps/chosen': -320.5, 'logps/rejected': -427.20001220703125, 'logits/chosen': -12.837499618530273, 'logits/rejected': -12.256250381469727, 'epoch': 2.05}
 68%|██████▊   | 3110/4545 [3:53:35<2:59:49,  7.52s/it] 68%|██████▊   | 3111/4545 [3:53:42<3:00:05,  7.54s/it] 68%|██████▊   | 3112/4545 [3:53:50<3:01:56,  7.62s/it] 68%|██████▊   | 3113/4545 [3:53:57<2:56:20,  7.39s/it] 69%|██████▊   | 3114/4545 [3:54:04<2:58:15,  7.47s/it] 69%|██████▊   | 3115/4545 [3:54:12<2:58:28,  7.49s/it] 69%|██████▊   | 3116/4545 [3:54:19<2:58:31,  7.50s/it] 69%|██████▊   | 3117/4545 [3:54:27<3:00:08,  7.57s/it] 69%|██████▊   | 3118/4545 [3:54:35<3:00:05,  7.57s/it] 69%|██████▊   | 3119/4545 [3:54:42<2:59:53,  7.57s/it] 69%|██████▊   | 3120/4545 [3:54:50<2:57:00,  7.45s/it]                                                       {'loss': 0.0145, 'grad_norm': 3.3356287479400635, 'learning_rate': 2.033261298817711e-06, 'rewards/chosen': -0.15156249701976776, 'rewards/rejected': -34.75, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 34.587501525878906, 'logps/chosen': -505.8999938964844, 'logps/rejected': -594.5999755859375, 'logits/chosen': -12.118749618530273, 'logits/rejected': -11.818750381469727, 'epoch': 2.06}
 69%|██████▊   | 3120/4545 [3:54:50<2:57:00,  7.45s/it] 69%|██████▊   | 3121/4545 [3:54:57<2:57:38,  7.49s/it] 69%|██████▊   | 3122/4545 [3:55:05<2:59:54,  7.59s/it] 69%|██████▊   | 3123/4545 [3:55:12<2:59:28,  7.57s/it] 69%|██████▊   | 3124/4545 [3:55:19<2:50:20,  7.19s/it] 69%|██████▉   | 3125/4545 [3:55:26<2:52:23,  7.28s/it] 69%|██████▉   | 3126/4545 [3:55:33<2:46:24,  7.04s/it] 69%|██████▉   | 3127/4545 [3:55:40<2:50:13,  7.20s/it] 69%|██████▉   | 3128/4545 [3:55:48<2:52:41,  7.31s/it] 69%|██████▉   | 3129/4545 [3:55:54<2:43:28,  6.93s/it] 69%|██████▉   | 3130/4545 [3:56:01<2:45:08,  7.00s/it]                                                       {'loss': 0.0571, 'grad_norm': 4.718708038330078, 'learning_rate': 2.0146940359253873e-06, 'rewards/chosen': -2.4837889671325684, 'rewards/rejected': -22.862499237060547, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 20.378124237060547, 'logps/chosen': -313.54998779296875, 'logps/rejected': -425.8999938964844, 'logits/chosen': -12.793749809265137, 'logits/rejected': -12.462499618530273, 'epoch': 2.07}
 69%|██████▉   | 3130/4545 [3:56:01<2:45:08,  7.00s/it] 69%|██████▉   | 3131/4545 [3:56:08<2:43:32,  6.94s/it] 69%|██████▉   | 3132/4545 [3:56:16<2:49:28,  7.20s/it] 69%|██████▉   | 3133/4545 [3:56:22<2:43:13,  6.94s/it] 69%|██████▉   | 3134/4545 [3:56:30<2:47:12,  7.11s/it] 69%|██████▉   | 3135/4545 [3:56:37<2:49:27,  7.21s/it] 69%|██████▉   | 3136/4545 [3:56:45<2:51:48,  7.32s/it] 69%|██████▉   | 3137/4545 [3:56:52<2:54:47,  7.45s/it] 69%|██████▉   | 3138/4545 [3:56:59<2:47:52,  7.16s/it] 69%|██████▉   | 3139/4545 [3:57:06<2:48:12,  7.18s/it] 69%|██████▉   | 3140/4545 [3:57:13<2:49:54,  7.26s/it]                                                       {'loss': 0.0327, 'grad_norm': 0.707243800163269, 'learning_rate': 1.9961466803798504e-06, 'rewards/chosen': -3.2503905296325684, 'rewards/rejected': -34.20624923706055, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 30.975000381469727, 'logps/chosen': -296.1499938964844, 'logps/rejected': -513.5999755859375, 'logits/chosen': -12.71875, 'logits/rejected': -12.112500190734863, 'epoch': 2.07}
 69%|██████▉   | 3140/4545 [3:57:13<2:49:54,  7.26s/it] 69%|██████▉   | 3141/4545 [3:57:21<2:50:52,  7.30s/it] 69%|██████▉   | 3142/4545 [3:57:28<2:51:47,  7.35s/it] 69%|██████▉   | 3143/4545 [3:57:34<2:42:57,  6.97s/it] 69%|██████▉   | 3144/4545 [3:58:42<9:48:21, 25.20s/it] 69%|██████▉   | 3145/4545 [3:58:59<8:48:40, 22.66s/it] 69%|██████▉   | 3146/4545 [3:59:09<7:23:24, 19.02s/it] 69%|██████▉   | 3147/4545 [3:59:13<5:37:43, 14.49s/it] 69%|██████▉   | 3148/4545 [3:59:17<4:23:29, 11.32s/it] 69%|██████▉   | 3149/4545 [3:59:20<3:22:13,  8.69s/it] 69%|██████▉   | 3150/4545 [3:59:24<2:49:06,  7.27s/it]                                                       {'loss': 0.066, 'grad_norm': 0.1048276275396347, 'learning_rate': 1.977621224716206e-06, 'rewards/chosen': -2.171875, 'rewards/rejected': -25.5, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 23.331249237060547, 'logps/chosen': -373.70001220703125, 'logps/rejected': -418.3999938964844, 'logits/chosen': -12.568750381469727, 'logits/rejected': -12.162500381469727, 'epoch': 2.08}
 69%|██████▉   | 3150/4545 [3:59:24<2:49:06,  7.27s/it] 69%|██████▉   | 3151/4545 [3:59:28<2:26:25,  6.30s/it] 69%|██████▉   | 3152/4545 [3:59:32<2:09:36,  5.58s/it] 69%|██████▉   | 3153/4545 [3:59:36<1:59:16,  5.14s/it] 69%|██████▉   | 3154/4545 [3:59:40<1:50:25,  4.76s/it] 69%|██████▉   | 3155/4545 [3:59:43<1:43:48,  4.48s/it] 69%|██████▉   | 3156/4545 [3:59:46<1:29:45,  3.88s/it] 69%|██████▉   | 3157/4545 [3:59:49<1:26:46,  3.75s/it] 69%|██████▉   | 3158/4545 [3:59:53<1:29:00,  3.85s/it] 70%|██████▉   | 3159/4545 [3:59:57<1:25:37,  3.71s/it] 70%|██████▉   | 3160/4545 [4:00:01<1:27:00,  3.77s/it]                                                       {'loss': 0.0335, 'grad_norm': 3.280651330947876, 'learning_rate': 1.959119659116864e-06, 'rewards/chosen': -3.6234374046325684, 'rewards/rejected': -31.662500381469727, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 28.0, 'logps/chosen': -338.20001220703125, 'logps/rejected': -534.0, 'logits/chosen': -12.837499618530273, 'logits/rejected': -12.462499618530273, 'epoch': 2.09}
 70%|██████▉   | 3160/4545 [4:00:01<1:27:00,  3.77s/it] 70%|██████▉   | 3161/4545 [4:00:04<1:25:35,  3.71s/it] 70%|██████▉   | 3162/4545 [4:00:08<1:26:48,  3.77s/it] 70%|██████▉   | 3163/4545 [4:00:12<1:27:00,  3.78s/it] 70%|██████▉   | 3164/4545 [4:00:16<1:24:46,  3.68s/it] 70%|██████▉   | 3165/4545 [4:00:19<1:22:45,  3.60s/it] 70%|██████▉   | 3166/4545 [4:00:23<1:24:43,  3.69s/it] 70%|██████▉   | 3167/4545 [4:00:27<1:26:07,  3.75s/it] 70%|██████▉   | 3168/4545 [4:00:31<1:26:40,  3.78s/it] 70%|██████▉   | 3169/4545 [4:00:34<1:27:05,  3.80s/it] 70%|██████▉   | 3170/4545 [4:00:38<1:27:46,  3.83s/it]                                                       {'loss': 0.0109, 'grad_norm': 6.924345016479492, 'learning_rate': 1.940643971197735e-06, 'rewards/chosen': -4.823046684265137, 'rewards/rejected': -39.8125, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 34.98749923706055, 'logps/chosen': -322.5, 'logps/rejected': -547.7999877929688, 'logits/chosen': -12.84375, 'logits/rejected': -12.337499618530273, 'epoch': 2.09}
 70%|██████▉   | 3170/4545 [4:00:38<1:27:46,  3.83s/it] 70%|██████▉   | 3171/4545 [4:00:42<1:24:12,  3.68s/it] 70%|██████▉   | 3172/4545 [4:00:46<1:26:02,  3.76s/it] 70%|██████▉   | 3173/4545 [4:00:50<1:28:32,  3.87s/it] 70%|██████▉   | 3174/4545 [4:00:54<1:28:40,  3.88s/it] 70%|██████▉   | 3175/4545 [4:00:57<1:25:55,  3.76s/it] 70%|██████▉   | 3176/4545 [4:01:26<4:20:13, 11.41s/it] 70%|██████▉   | 3177/4545 [4:01:30<3:28:39,  9.15s/it] 70%|██████▉   | 3178/4545 [4:01:34<2:52:38,  7.58s/it] 70%|██████▉   | 3179/4545 [4:01:38<2:27:30,  6.48s/it] 70%|██████▉   | 3180/4545 [4:01:42<2:10:13,  5.72s/it]                                                       {'loss': 0.0204, 'grad_norm': 2.084728240966797, 'learning_rate': 1.9221961457946997e-06, 'rewards/chosen': -1.403906226158142, 'rewards/rejected': -28.162500381469727, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 26.774999618530273, 'logps/chosen': -482.8999938964844, 'logps/rejected': -483.0, 'logits/chosen': -12.543749809265137, 'logits/rejected': -12.431249618530273, 'epoch': 2.1}
 70%|██████▉   | 3180/4545 [4:01:42<2:10:13,  5.72s/it] 70%|██████▉   | 3181/4545 [4:01:46<1:58:49,  5.23s/it] 70%|███████   | 3182/4545 [4:01:50<1:49:43,  4.83s/it] 70%|███████   | 3183/4545 [4:01:54<1:43:13,  4.55s/it] 70%|███████   | 3184/4545 [4:01:58<1:38:42,  4.35s/it] 70%|███████   | 3185/4545 [4:02:02<1:35:39,  4.22s/it] 70%|███████   | 3186/4545 [4:02:05<1:30:43,  4.01s/it] 70%|███████   | 3187/4545 [4:02:08<1:25:41,  3.79s/it] 70%|███████   | 3188/4545 [4:02:12<1:27:19,  3.86s/it] 70%|███████   | 3189/4545 [4:02:17<1:28:42,  3.93s/it] 70%|███████   | 3190/4545 [4:02:21<1:28:49,  3.93s/it]                                                       {'loss': 0.0913, 'grad_norm': 0.13315269351005554, 'learning_rate': 1.9037781647503809e-06, 'rewards/chosen': -4.414843559265137, 'rewards/rejected': -35.462501525878906, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 31.049999237060547, 'logps/chosen': -338.29998779296875, 'logps/rejected': -500.3999938964844, 'logits/chosen': -13.40625, 'logits/rejected': -13.087499618530273, 'epoch': 2.11}
 70%|███████   | 3190/4545 [4:02:21<1:28:49,  3.93s/it] 70%|███████   | 3191/4545 [4:02:25<1:31:42,  4.06s/it] 70%|███████   | 3192/4545 [4:02:29<1:31:48,  4.07s/it] 70%|███████   | 3193/4545 [4:02:32<1:24:34,  3.75s/it] 70%|███████   | 3194/4545 [4:02:36<1:27:03,  3.87s/it] 70%|███████   | 3195/4545 [4:02:40<1:27:47,  3.90s/it] 70%|███████   | 3196/4545 [4:02:44<1:28:03,  3.92s/it] 70%|███████   | 3197/4545 [4:02:48<1:27:57,  3.92s/it] 70%|███████   | 3198/4545 [4:02:52<1:25:57,  3.83s/it] 70%|███████   | 3199/4545 [4:02:55<1:26:25,  3.85s/it] 70%|███████   | 3200/4545 [4:03:00<1:27:59,  3.93s/it]                                                       {'loss': 0.027, 'grad_norm': 0.35846760869026184, 'learning_rate': 1.8853920067012332e-06, 'rewards/chosen': -2.033642530441284, 'rewards/rejected': -29.112499237060547, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 27.081249237060547, 'logps/chosen': -451.70001220703125, 'logps/rejected': -521.0, 'logits/chosen': -12.643750190734863, 'logits/rejected': -12.4375, 'epoch': 2.11}
 70%|███████   | 3200/4545 [4:03:00<1:27:59,  3.93s/it] 70%|███████   | 3201/4545 [4:03:03<1:27:45,  3.92s/it] 70%|███████   | 3202/4545 [4:03:07<1:24:42,  3.78s/it] 70%|███████   | 3203/4545 [4:03:11<1:25:49,  3.84s/it] 70%|███████   | 3204/4545 [4:03:14<1:19:59,  3.58s/it] 71%|███████   | 3205/4545 [4:03:16<1:10:41,  3.17s/it] 71%|███████   | 3206/4545 [4:03:20<1:17:44,  3.48s/it] 71%|███████   | 3207/4545 [4:03:24<1:17:19,  3.47s/it] 71%|███████   | 3208/4545 [4:03:27<1:13:07,  3.28s/it] 71%|███████   | 3209/4545 [4:03:30<1:11:59,  3.23s/it] 71%|███████   | 3210/4545 [4:03:33<1:15:05,  3.38s/it]                                                       {'loss': 0.0342, 'grad_norm': 1.1505659818649292, 'learning_rate': 1.867039646864978e-06, 'rewards/chosen': -5.211718559265137, 'rewards/rejected': -41.537498474121094, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 36.337501525878906, 'logps/chosen': -270.6000061035156, 'logps/rejected': -517.0, 'logits/chosen': -13.100000381469727, 'logits/rejected': -12.53125, 'epoch': 2.12}
 71%|███████   | 3210/4545 [4:03:33<1:15:05,  3.38s/it] 71%|███████   | 3211/4545 [4:03:37<1:19:37,  3.58s/it] 71%|███████   | 3212/4545 [4:04:10<4:32:07, 12.25s/it] 71%|███████   | 3213/4545 [4:04:18<4:00:33, 10.84s/it] 71%|███████   | 3214/4545 [4:04:25<3:38:48,  9.86s/it] 71%|███████   | 3215/4545 [4:04:33<3:23:57,  9.20s/it] 71%|███████   | 3216/4545 [4:04:40<3:07:27,  8.46s/it] 71%|███████   | 3217/4545 [4:04:47<3:01:00,  8.18s/it] 71%|███████   | 3218/4545 [4:04:55<2:56:27,  7.98s/it] 71%|███████   | 3219/4545 [4:05:02<2:53:00,  7.83s/it] 71%|███████   | 3220/4545 [4:05:09<2:49:54,  7.69s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.43066930770874023, 'learning_rate': 1.848723056828411e-06, 'rewards/chosen': -1.753515601158142, 'rewards/rejected': -40.95624923706055, 'rewards/accuracies': 1.0, 'rewards/margins': 39.243751525878906, 'logps/chosen': -438.20001220703125, 'logps/rejected': -608.9000244140625, 'logits/chosen': -12.118749618530273, 'logits/rejected': -11.756250381469727, 'epoch': 2.13}
 71%|███████   | 3220/4545 [4:05:09<2:49:54,  7.69s/it] 71%|███████   | 3221/4545 [4:05:17<2:48:17,  7.63s/it] 71%|███████   | 3222/4545 [4:05:23<2:38:32,  7.19s/it] 71%|███████   | 3223/4545 [4:05:30<2:39:41,  7.25s/it] 71%|███████   | 3224/4545 [4:05:38<2:42:22,  7.37s/it] 71%|███████   | 3225/4545 [4:05:45<2:36:41,  7.12s/it] 71%|███████   | 3226/4545 [4:05:51<2:32:44,  6.95s/it] 71%|███████   | 3227/4545 [4:05:59<2:35:51,  7.10s/it] 71%|███████   | 3228/4545 [4:06:06<2:39:52,  7.28s/it] 71%|███████   | 3229/4545 [4:06:13<2:38:21,  7.22s/it] 71%|███████   | 3230/4545 [4:06:21<2:40:34,  7.33s/it]                                                       {'loss': 0.0321, 'grad_norm': 2.9848170280456543, 'learning_rate': 1.8304442043355893e-06, 'rewards/chosen': -3.762500047683716, 'rewards/rejected': -40.443748474121094, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 36.693748474121094, 'logps/chosen': -298.3500061035156, 'logps/rejected': -545.7000122070312, 'logits/chosen': -12.28125, 'logits/rejected': -11.75, 'epoch': 2.13}
 71%|███████   | 3230/4545 [4:06:21<2:40:34,  7.33s/it] 71%|███████   | 3231/4545 [4:06:28<2:40:01,  7.31s/it] 71%|███████   | 3232/4545 [4:06:36<2:39:50,  7.30s/it] 71%|███████   | 3233/4545 [4:06:43<2:40:40,  7.35s/it] 71%|███████   | 3234/4545 [4:06:51<2:42:07,  7.42s/it] 71%|███████   | 3235/4545 [4:06:58<2:44:34,  7.54s/it] 71%|███████   | 3236/4545 [4:07:06<2:44:06,  7.52s/it] 71%|███████   | 3237/4545 [4:07:13<2:43:57,  7.52s/it] 71%|███████   | 3238/4545 [4:07:21<2:43:49,  7.52s/it] 71%|███████▏  | 3239/4545 [4:07:28<2:42:56,  7.49s/it] 71%|███████▏  | 3240/4545 [4:07:35<2:37:01,  7.22s/it]                                                       {'loss': 0.0513, 'grad_norm': 31.591337203979492, 'learning_rate': 1.8122050530764424e-06, 'rewards/chosen': -2.865039110183716, 'rewards/rejected': -38.9375, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 36.099998474121094, 'logps/chosen': -300.29998779296875, 'logps/rejected': -503.3999938964844, 'logits/chosen': -12.262499809265137, 'logits/rejected': -11.662500381469727, 'epoch': 2.14}
 71%|███████▏  | 3240/4545 [4:07:35<2:37:01,  7.22s/it] 71%|███████▏  | 3241/4545 [4:07:43<2:41:21,  7.42s/it] 71%|███████▏  | 3242/4545 [4:07:50<2:41:17,  7.43s/it] 71%|███████▏  | 3243/4545 [4:07:57<2:39:35,  7.35s/it] 71%|███████▏  | 3244/4545 [4:08:05<2:40:12,  7.39s/it] 71%|███████▏  | 3245/4545 [4:08:12<2:41:14,  7.44s/it] 71%|███████▏  | 3246/4545 [4:08:19<2:36:55,  7.25s/it] 71%|███████▏  | 3247/4545 [4:08:26<2:33:40,  7.10s/it] 71%|███████▏  | 3248/4545 [4:08:33<2:35:36,  7.20s/it] 71%|███████▏  | 3249/4545 [4:08:41<2:37:25,  7.29s/it] 72%|███████▏  | 3250/4545 [4:08:48<2:35:54,  7.22s/it]                                                       {'loss': 0.0737, 'grad_norm': 0.9723972082138062, 'learning_rate': 1.7940075624758112e-06, 'rewards/chosen': -2.19921875, 'rewards/rejected': -35.95000076293945, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 33.806251525878906, 'logps/chosen': -356.79998779296875, 'logps/rejected': -530.0, 'logits/chosen': -12.493749618530273, 'logits/rejected': -12.131250381469727, 'epoch': 2.15}
 72%|███████▏  | 3250/4545 [4:08:48<2:35:54,  7.22s/it] 72%|███████▏  | 3251/4545 [4:08:56<2:39:00,  7.37s/it] 72%|███████▏  | 3252/4545 [4:09:03<2:41:11,  7.48s/it] 72%|███████▏  | 3253/4545 [4:09:09<2:30:34,  6.99s/it] 72%|███████▏  | 3254/4545 [4:09:13<2:11:25,  6.11s/it] 72%|███████▏  | 3255/4545 [4:09:18<1:58:43,  5.52s/it] 72%|███████▏  | 3256/4545 [4:09:21<1:42:56,  4.79s/it] 72%|███████▏  | 3257/4545 [4:09:24<1:36:36,  4.50s/it] 72%|███████▏  | 3258/4545 [4:09:28<1:32:57,  4.33s/it] 72%|███████▏  | 3259/4545 [4:09:32<1:30:08,  4.21s/it] 72%|███████▏  | 3260/4545 [4:09:36<1:28:03,  4.11s/it]                                                       {'loss': 0.0263, 'grad_norm': 23.214393615722656, 'learning_rate': 1.7758536874829484e-06, 'rewards/chosen': -4.266015529632568, 'rewards/rejected': -36.287498474121094, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 32.025001525878906, 'logps/chosen': -300.20001220703125, 'logps/rejected': -520.5999755859375, 'logits/chosen': -12.625, 'logits/rejected': -12.3125, 'epoch': 2.15}
 72%|███████▏  | 3260/4545 [4:09:36<1:28:03,  4.11s/it] 72%|███████▏  | 3261/4545 [4:09:40<1:26:39,  4.05s/it] 72%|███████▏  | 3262/4545 [4:09:44<1:25:37,  4.00s/it] 72%|███████▏  | 3263/4545 [4:09:48<1:23:33,  3.91s/it] 72%|███████▏  | 3264/4545 [4:09:51<1:19:36,  3.73s/it] 72%|███████▏  | 3265/4545 [4:09:55<1:21:04,  3.80s/it] 72%|███████▏  | 3266/4545 [4:09:59<1:22:22,  3.86s/it] 72%|███████▏  | 3267/4545 [4:10:03<1:22:29,  3.87s/it] 72%|███████▏  | 3268/4545 [4:10:06<1:15:15,  3.54s/it] 72%|███████▏  | 3269/4545 [4:10:10<1:17:58,  3.67s/it] 72%|███████▏  | 3270/4545 [4:10:14<1:21:25,  3.83s/it]                                                       {'loss': 0.0147, 'grad_norm': 0.9029985666275024, 'learning_rate': 1.7577453783614997e-06, 'rewards/chosen': -2.1202149391174316, 'rewards/rejected': -28.262500762939453, 'rewards/accuracies': 1.0, 'rewards/margins': 26.149999618530273, 'logps/chosen': -365.70001220703125, 'logps/rejected': -530.2000122070312, 'logits/chosen': -13.037500381469727, 'logits/rejected': -12.649999618530273, 'epoch': 2.16}
 72%|███████▏  | 3270/4545 [4:10:14<1:21:25,  3.83s/it] 72%|███████▏  | 3271/4545 [4:10:18<1:21:50,  3.85s/it] 72%|███████▏  | 3272/4545 [4:10:21<1:17:59,  3.68s/it] 72%|███████▏  | 3273/4545 [4:10:25<1:19:15,  3.74s/it] 72%|███████▏  | 3274/4545 [4:10:27<1:12:10,  3.41s/it] 72%|███████▏  | 3275/4545 [4:10:31<1:11:18,  3.37s/it] 72%|███████▏  | 3276/4545 [4:10:35<1:15:45,  3.58s/it] 72%|███████▏  | 3277/4545 [4:10:38<1:15:28,  3.57s/it] 72%|███████▏  | 3278/4545 [4:10:42<1:17:29,  3.67s/it] 72%|███████▏  | 3279/4545 [4:10:46<1:18:49,  3.74s/it] 72%|███████▏  | 3280/4545 [4:10:49<1:12:44,  3.45s/it]                                                       {'loss': 0.0724, 'grad_norm': 1.6690785884857178, 'learning_rate': 1.7396845804799858e-06, 'rewards/chosen': -3.383593797683716, 'rewards/rejected': -27.262500762939453, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 23.90625, 'logps/chosen': -279.75, 'logps/rejected': -384.0, 'logits/chosen': -13.28125, 'logits/rejected': -12.800000190734863, 'epoch': 2.17}
 72%|███████▏  | 3280/4545 [4:10:49<1:12:44,  3.45s/it] 72%|███████▏  | 3281/4545 [4:10:53<1:14:18,  3.53s/it] 72%|███████▏  | 3282/4545 [4:10:55<1:07:33,  3.21s/it] 72%|███████▏  | 3283/4545 [4:10:59<1:11:37,  3.40s/it] 72%|███████▏  | 3284/4545 [4:11:03<1:15:01,  3.57s/it] 72%|███████▏  | 3285/4545 [4:11:06<1:12:35,  3.46s/it] 72%|███████▏  | 3286/4545 [4:11:10<1:16:15,  3.63s/it] 72%|███████▏  | 3287/4545 [4:11:13<1:09:54,  3.33s/it] 72%|███████▏  | 3288/4545 [4:11:17<1:13:26,  3.51s/it] 72%|███████▏  | 3289/4545 [4:11:20<1:09:06,  3.30s/it] 72%|███████▏  | 3290/4545 [4:11:24<1:13:32,  3.52s/it]                                                       {'loss': 0.0285, 'grad_norm': 0.23815302550792694, 'learning_rate': 1.7216732341028153e-06, 'rewards/chosen': -3.6402344703674316, 'rewards/rejected': -33.29999923706055, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 29.671875, 'logps/chosen': -242.5500030517578, 'logps/rejected': -447.29998779296875, 'logits/chosen': -12.90625, 'logits/rejected': -12.543749809265137, 'epoch': 2.17}
 72%|███████▏  | 3290/4545 [4:11:24<1:13:32,  3.52s/it] 72%|███████▏  | 3291/4545 [4:11:27<1:14:07,  3.55s/it] 72%|███████▏  | 3292/4545 [4:11:31<1:15:31,  3.62s/it] 72%|███████▏  | 3293/4545 [4:11:34<1:14:46,  3.58s/it] 72%|███████▏  | 3294/4545 [4:11:38<1:17:04,  3.70s/it] 72%|███████▏  | 3295/4545 [4:11:42<1:18:17,  3.76s/it] 73%|███████▎  | 3296/4545 [4:11:46<1:19:08,  3.80s/it] 73%|███████▎  | 3297/4545 [4:11:50<1:20:13,  3.86s/it] 73%|███████▎  | 3298/4545 [4:11:54<1:20:27,  3.87s/it] 73%|███████▎  | 3299/4545 [4:11:57<1:13:49,  3.56s/it] 73%|███████▎  | 3300/4545 [4:12:01<1:16:03,  3.67s/it]                                                       {'loss': 0.0074, 'grad_norm': 0.10779233276844025, 'learning_rate': 1.7037132741818408e-06, 'rewards/chosen': -3.2085938453674316, 'rewards/rejected': -31.293750762939453, 'rewards/accuracies': 1.0, 'rewards/margins': 28.049999237060547, 'logps/chosen': -285.70001220703125, 'logps/rejected': -407.6000061035156, 'logits/chosen': -13.118749618530273, 'logits/rejected': -12.78125, 'epoch': 2.18}
 73%|███████▎  | 3300/4545 [4:12:01<1:16:03,  3.67s/it] 73%|███████▎  | 3301/4545 [4:12:04<1:15:31,  3.64s/it] 73%|███████▎  | 3302/4545 [4:12:08<1:13:17,  3.54s/it] 73%|███████▎  | 3303/4545 [4:12:12<1:16:47,  3.71s/it] 73%|███████▎  | 3304/4545 [4:12:15<1:14:18,  3.59s/it] 73%|███████▎  | 3305/4545 [4:12:19<1:15:52,  3.67s/it] 73%|███████▎  | 3306/4545 [4:12:48<3:51:12, 11.20s/it] 73%|███████▎  | 3307/4545 [4:12:52<3:05:53,  9.01s/it] 73%|███████▎  | 3308/4545 [4:12:56<2:34:19,  7.49s/it] 73%|███████▎  | 3309/4545 [4:13:00<2:13:47,  6.50s/it] 73%|███████▎  | 3310/4545 [4:13:03<1:56:20,  5.65s/it]                                                       {'loss': 0.0132, 'grad_norm': 5.012979984283447, 'learning_rate': 1.685806630148487e-06, 'rewards/chosen': -2.7994627952575684, 'rewards/rejected': -33.712501525878906, 'rewards/accuracies': 1.0, 'rewards/margins': 30.862499237060547, 'logps/chosen': -323.20001220703125, 'logps/rejected': -477.3999938964844, 'logits/chosen': -12.949999809265137, 'logits/rejected': -12.5, 'epoch': 2.18}
 73%|███████▎  | 3310/4545 [4:13:03<1:56:20,  5.65s/it] 73%|███████▎  | 3311/4545 [4:13:07<1:45:27,  5.13s/it] 73%|███████▎  | 3312/4545 [4:13:11<1:37:43,  4.76s/it] 73%|███████▎  | 3313/4545 [4:13:16<1:34:28,  4.60s/it] 73%|███████▎  | 3314/4545 [4:13:19<1:29:01,  4.34s/it] 73%|███████▎  | 3315/4545 [4:13:23<1:26:22,  4.21s/it] 73%|███████▎  | 3316/4545 [4:13:27<1:25:31,  4.18s/it] 73%|███████▎  | 3317/4545 [4:13:30<1:15:51,  3.71s/it] 73%|███████▎  | 3318/4545 [4:13:34<1:16:13,  3.73s/it] 73%|███████▎  | 3319/4545 [4:13:37<1:15:19,  3.69s/it] 73%|███████▎  | 3320/4545 [4:13:41<1:17:33,  3.80s/it]                                                       {'loss': 0.093, 'grad_norm': 1.6661254167556763, 'learning_rate': 1.6679552257064753e-06, 'rewards/chosen': -1.992285132408142, 'rewards/rejected': -36.974998474121094, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 34.993751525878906, 'logps/chosen': -384.79998779296875, 'logps/rejected': -548.4000244140625, 'logits/chosen': -12.737500190734863, 'logits/rejected': -12.368749618530273, 'epoch': 2.19}
 73%|███████▎  | 3320/4545 [4:13:41<1:17:33,  3.80s/it] 73%|███████▎  | 3321/4545 [4:13:45<1:15:39,  3.71s/it] 73%|███████▎  | 3322/4545 [4:13:48<1:12:50,  3.57s/it] 73%|███████▎  | 3323/4545 [4:13:52<1:14:45,  3.67s/it] 73%|███████▎  | 3324/4545 [4:13:56<1:16:31,  3.76s/it] 73%|███████▎  | 3325/4545 [4:13:59<1:09:43,  3.43s/it] 73%|███████▎  | 3326/4545 [4:14:02<1:12:37,  3.58s/it] 73%|███████▎  | 3327/4545 [4:14:06<1:14:21,  3.66s/it] 73%|███████▎  | 3328/4545 [4:14:10<1:14:23,  3.67s/it] 73%|███████▎  | 3329/4545 [4:14:14<1:15:57,  3.75s/it] 73%|███████▎  | 3330/4545 [4:14:18<1:16:34,  3.78s/it]                                                       {'loss': 0.0274, 'grad_norm': 0.12769293785095215, 'learning_rate': 1.6501609786251573e-06, 'rewards/chosen': -4.510546684265137, 'rewards/rejected': -29.737499237060547, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 25.200000762939453, 'logps/chosen': -261.29998779296875, 'logps/rejected': -426.6000061035156, 'logits/chosen': -13.418749809265137, 'logits/rejected': -13.012499809265137, 'epoch': 2.2}
 73%|███████▎  | 3330/4545 [4:14:18<1:16:34,  3.78s/it] 73%|███████▎  | 3331/4545 [4:14:22<1:17:18,  3.82s/it] 73%|███████▎  | 3332/4545 [4:14:26<1:17:59,  3.86s/it] 73%|███████▎  | 3333/4545 [4:14:29<1:16:22,  3.78s/it] 73%|███████▎  | 3334/4545 [4:14:32<1:10:56,  3.51s/it] 73%|███████▎  | 3335/4545 [4:14:35<1:06:52,  3.32s/it] 73%|███████▎  | 3336/4545 [4:14:38<1:02:22,  3.10s/it] 73%|███████▎  | 3337/4545 [4:14:40<1:00:56,  3.03s/it] 73%|███████▎  | 3338/4545 [4:14:44<1:06:26,  3.30s/it] 73%|███████▎  | 3339/4545 [4:14:48<1:06:16,  3.30s/it] 73%|███████▎  | 3340/4545 [4:14:50<59:51,  2.98s/it]                                                       {'loss': 0.1102, 'grad_norm': 1.4082870483398438, 'learning_rate': 1.632425800533495e-06, 'rewards/chosen': -5.452343940734863, 'rewards/rejected': -34.53125, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 29.075000762939453, 'logps/chosen': -214.89999389648438, 'logps/rejected': -435.1000061035156, 'logits/chosen': -13.449999809265137, 'logits/rejected': -12.918749809265137, 'epoch': 2.2}
 73%|███████▎  | 3340/4545 [4:14:50<59:51,  2.98s/it] 74%|███████▎  | 3341/4545 [4:14:54<1:05:30,  3.26s/it] 74%|███████▎  | 3342/4545 [4:14:58<1:11:01,  3.54s/it] 74%|███████▎  | 3343/4545 [4:15:02<1:13:54,  3.69s/it] 74%|███████▎  | 3344/4545 [4:15:06<1:15:13,  3.76s/it] 74%|███████▎  | 3345/4545 [4:15:09<1:12:16,  3.61s/it] 74%|███████▎  | 3346/4545 [4:15:13<1:14:30,  3.73s/it] 74%|███████▎  | 3347/4545 [4:15:17<1:14:44,  3.74s/it] 74%|███████▎  | 3348/4545 [4:15:21<1:16:23,  3.83s/it] 74%|███████▎  | 3349/4545 [4:15:25<1:14:52,  3.76s/it] 74%|███████▎  | 3350/4545 [4:15:28<1:13:44,  3.70s/it]                                                       {'loss': 0.0123, 'grad_norm': 0.07209581881761551, 'learning_rate': 1.6147515967146897e-06, 'rewards/chosen': -4.275000095367432, 'rewards/rejected': -32.6875, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 28.462499618530273, 'logps/chosen': -273.1000061035156, 'logps/rejected': -470.79998779296875, 'logits/chosen': -13.087499618530273, 'logits/rejected': -12.693750381469727, 'epoch': 2.21}
 74%|███████▎  | 3350/4545 [4:15:28<1:13:44,  3.70s/it] 74%|███████▎  | 3351/4545 [4:15:32<1:11:55,  3.61s/it] 74%|███████▍  | 3352/4545 [4:15:35<1:11:43,  3.61s/it] 74%|███████▍  | 3353/4545 [4:15:39<1:11:53,  3.62s/it] 74%|███████▍  | 3354/4545 [4:15:43<1:13:38,  3.71s/it] 74%|███████▍  | 3355/4545 [4:15:46<1:12:58,  3.68s/it] 74%|███████▍  | 3356/4545 [4:15:50<1:14:26,  3.76s/it] 74%|███████▍  | 3357/4545 [4:15:54<1:15:24,  3.81s/it] 74%|███████▍  | 3358/4545 [4:15:58<1:15:50,  3.83s/it] 74%|███████▍  | 3359/4545 [4:16:02<1:16:10,  3.85s/it] 74%|███████▍  | 3360/4545 [4:16:06<1:16:25,  3.87s/it]                                                       {'loss': 0.1297, 'grad_norm': 0.16745641827583313, 'learning_rate': 1.5971402659015003e-06, 'rewards/chosen': -1.843164086341858, 'rewards/rejected': -35.631248474121094, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 33.82500076293945, 'logps/chosen': -404.6000061035156, 'logps/rejected': -556.7999877929688, 'logits/chosen': -12.637499809265137, 'logits/rejected': -12.256250381469727, 'epoch': 2.22}
 74%|███████▍  | 3360/4545 [4:16:06<1:16:25,  3.87s/it] 74%|███████▍  | 3361/4545 [4:16:10<1:16:39,  3.88s/it] 74%|███████▍  | 3362/4545 [4:16:13<1:14:00,  3.75s/it] 74%|███████▍  | 3363/4545 [4:16:17<1:14:16,  3.77s/it] 74%|███████▍  | 3364/4545 [4:16:21<1:14:59,  3.81s/it] 74%|███████▍  | 3365/4545 [4:16:25<1:14:54,  3.81s/it] 74%|███████▍  | 3366/4545 [4:16:29<1:14:42,  3.80s/it] 74%|███████▍  | 3367/4545 [4:16:33<1:16:30,  3.90s/it] 74%|███████▍  | 3368/4545 [4:16:35<1:08:49,  3.51s/it] 74%|███████▍  | 3369/4545 [4:16:39<1:11:00,  3.62s/it] 74%|███████▍  | 3370/4545 [4:16:43<1:12:37,  3.71s/it]                                                       {'loss': 0.0205, 'grad_norm': 23.66604232788086, 'learning_rate': 1.579593700072266e-06, 'rewards/chosen': -3.128124952316284, 'rewards/rejected': -36.42499923706055, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 33.287498474121094, 'logps/chosen': -319.0, 'logps/rejected': -511.20001220703125, 'logits/chosen': -12.918749809265137, 'logits/rejected': -12.449999809265137, 'epoch': 2.22}
 74%|███████▍  | 3370/4545 [4:16:43<1:12:37,  3.71s/it] 74%|███████▍  | 3371/4545 [4:16:47<1:10:31,  3.60s/it] 74%|███████▍  | 3372/4545 [4:16:50<1:12:16,  3.70s/it] 74%|███████▍  | 3373/4545 [4:16:54<1:10:59,  3.63s/it] 74%|███████▍  | 3374/4545 [4:16:58<1:13:45,  3.78s/it] 74%|███████▍  | 3375/4545 [4:17:02<1:14:26,  3.82s/it] 74%|███████▍  | 3376/4545 [4:17:05<1:09:18,  3.56s/it] 74%|███████▍  | 3377/4545 [4:17:09<1:10:26,  3.62s/it] 74%|███████▍  | 3378/4545 [4:17:12<1:08:12,  3.51s/it] 74%|███████▍  | 3379/4545 [4:17:16<1:12:09,  3.71s/it] 74%|███████▍  | 3380/4545 [4:17:20<1:10:38,  3.64s/it]                                                       {'loss': 0.0081, 'grad_norm': 3.528489351272583, 'learning_rate': 1.5621137842476469e-06, 'rewards/chosen': -3.342236280441284, 'rewards/rejected': -34.662498474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 31.299999237060547, 'logps/chosen': -312.6000061035156, 'logps/rejected': -536.0, 'logits/chosen': -12.9375, 'logits/rejected': -12.381250381469727, 'epoch': 2.23}
 74%|███████▍  | 3380/4545 [4:17:20<1:10:38,  3.64s/it] 74%|███████▍  | 3381/4545 [4:17:23<1:10:34,  3.64s/it] 74%|███████▍  | 3382/4545 [4:17:27<1:12:01,  3.72s/it] 74%|███████▍  | 3383/4545 [4:17:31<1:10:51,  3.66s/it] 74%|███████▍  | 3384/4545 [4:17:35<1:13:46,  3.81s/it] 74%|███████▍  | 3385/4545 [4:17:39<1:15:15,  3.89s/it] 74%|███████▍  | 3386/4545 [4:17:43<1:16:47,  3.98s/it] 75%|███████▍  | 3387/4545 [4:17:47<1:16:19,  3.95s/it] 75%|███████▍  | 3388/4545 [4:17:51<1:17:42,  4.03s/it] 75%|███████▍  | 3389/4545 [4:17:55<1:18:45,  4.09s/it] 75%|███████▍  | 3390/4545 [4:17:59<1:17:43,  4.04s/it]                                                       {'loss': 0.032, 'grad_norm': 16.803539276123047, 'learning_rate': 1.5447023962881204e-06, 'rewards/chosen': -4.241406440734863, 'rewards/rejected': -40.625, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 36.381248474121094, 'logps/chosen': -360.70001220703125, 'logps/rejected': -599.7999877929688, 'logits/chosen': -12.71875, 'logits/rejected': -12.300000190734863, 'epoch': 2.24}
 75%|███████▍  | 3390/4545 [4:17:59<1:17:43,  4.04s/it] 75%|███████▍  | 3391/4545 [4:18:03<1:17:06,  4.01s/it] 75%|███████▍  | 3392/4545 [4:18:08<1:18:32,  4.09s/it] 75%|███████▍  | 3393/4545 [4:18:11<1:15:11,  3.92s/it] 75%|███████▍  | 3394/4545 [4:18:15<1:14:59,  3.91s/it] 75%|███████▍  | 3395/4545 [4:18:19<1:14:40,  3.90s/it] 75%|███████▍  | 3396/4545 [4:18:22<1:10:57,  3.71s/it] 75%|███████▍  | 3397/4545 [4:18:26<1:12:12,  3.77s/it] 75%|███████▍  | 3398/4545 [4:18:29<1:06:24,  3.47s/it] 75%|███████▍  | 3399/4545 [4:18:32<1:05:16,  3.42s/it] 75%|███████▍  | 3400/4545 [4:18:35<1:04:44,  3.39s/it]                                                       {'loss': 0.0241, 'grad_norm': 0.8694776296615601, 'learning_rate': 1.5273614066922417e-06, 'rewards/chosen': -3.9781250953674316, 'rewards/rejected': -36.25, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 32.29999923706055, 'logps/chosen': -317.3999938964844, 'logps/rejected': -539.2000122070312, 'logits/chosen': -13.100000381469727, 'logits/rejected': -12.600000381469727, 'epoch': 2.24}
 75%|███████▍  | 3400/4545 [4:18:35<1:04:44,  3.39s/it] 75%|███████▍  | 3401/4545 [4:18:40<1:09:05,  3.62s/it] 75%|███████▍  | 3402/4545 [4:18:43<1:10:45,  3.71s/it] 75%|███████▍  | 3403/4545 [4:18:48<1:12:53,  3.83s/it] 75%|███████▍  | 3404/4545 [4:18:52<1:15:03,  3.95s/it] 75%|███████▍  | 3405/4545 [4:18:55<1:12:35,  3.82s/it] 75%|███████▍  | 3406/4545 [4:18:58<1:04:05,  3.38s/it] 75%|███████▍  | 3407/4545 [4:19:01<1:02:03,  3.27s/it] 75%|███████▍  | 3408/4545 [4:19:05<1:05:48,  3.47s/it] 75%|███████▌  | 3409/4545 [4:19:08<1:07:32,  3.57s/it] 75%|███████▌  | 3410/4545 [4:19:12<1:08:30,  3.62s/it]                                                       {'loss': 0.0294, 'grad_norm': 0.40775153040885925, 'learning_rate': 1.5100926783956974e-06, 'rewards/chosen': -5.684374809265137, 'rewards/rejected': -39.98749923706055, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 34.25, 'logps/chosen': -282.8500061035156, 'logps/rejected': -497.6000061035156, 'logits/chosen': -13.356249809265137, 'logits/rejected': -13.018750190734863, 'epoch': 2.25}
 75%|███████▌  | 3410/4545 [4:19:12<1:08:30,  3.62s/it] 75%|███████▌  | 3411/4545 [4:19:16<1:09:52,  3.70s/it] 75%|███████▌  | 3412/4545 [4:19:20<1:10:08,  3.71s/it] 75%|███████▌  | 3413/4545 [4:19:24<1:11:10,  3.77s/it] 75%|███████▌  | 3414/4545 [4:19:27<1:06:52,  3.55s/it] 75%|███████▌  | 3415/4545 [4:19:30<1:07:39,  3.59s/it] 75%|███████▌  | 3416/4545 [4:19:34<1:09:39,  3.70s/it] 75%|███████▌  | 3417/4545 [4:19:38<1:10:43,  3.76s/it] 75%|███████▌  | 3418/4545 [4:19:42<1:11:00,  3.78s/it] 75%|███████▌  | 3419/4545 [4:19:46<1:11:13,  3.80s/it] 75%|███████▌  | 3420/4545 [4:19:49<1:09:34,  3.71s/it]                                                       {'loss': 0.0092, 'grad_norm': 1.8961806297302246, 'learning_rate': 1.4928980665711733e-06, 'rewards/chosen': -4.46875, 'rewards/rejected': -38.162498474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 33.662498474121094, 'logps/chosen': -295.8999938964844, 'logps/rejected': -528.0, 'logits/chosen': -13.112500190734863, 'logits/rejected': -12.725000381469727, 'epoch': 2.26}
 75%|███████▌  | 3420/4545 [4:19:49<1:09:34,  3.71s/it] 75%|███████▌  | 3421/4545 [4:19:54<1:11:36,  3.82s/it] 75%|███████▌  | 3422/4545 [4:19:58<1:13:47,  3.94s/it] 75%|███████▌  | 3423/4545 [4:20:01<1:07:36,  3.61s/it] 75%|███████▌  | 3424/4545 [4:20:05<1:10:52,  3.79s/it] 75%|███████▌  | 3425/4545 [4:20:09<1:11:43,  3.84s/it] 75%|███████▌  | 3426/4545 [4:20:13<1:11:14,  3.82s/it] 75%|███████▌  | 3427/4545 [4:20:16<1:11:00,  3.81s/it] 75%|███████▌  | 3428/4545 [4:20:20<1:11:24,  3.84s/it] 75%|███████▌  | 3429/4545 [4:20:24<1:12:00,  3.87s/it] 75%|███████▌  | 3430/4545 [4:20:28<1:12:13,  3.89s/it]                                                       {'loss': 0.0763, 'grad_norm': 0.3658435642719269, 'learning_rate': 1.4757794184290476e-06, 'rewards/chosen': -4.3515625, 'rewards/rejected': -36.57500076293945, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 32.23749923706055, 'logps/chosen': -340.6000061035156, 'logps/rejected': -525.4000244140625, 'logits/chosen': -12.881250381469727, 'logits/rejected': -12.493749618530273, 'epoch': 2.26}
 75%|███████▌  | 3430/4545 [4:20:28<1:12:13,  3.89s/it] 75%|███████▌  | 3431/4545 [4:20:31<1:03:47,  3.44s/it] 76%|███████▌  | 3432/4545 [4:20:33<57:57,  3.12s/it]   76%|███████▌  | 3433/4545 [4:20:37<1:02:04,  3.35s/it] 76%|███████▌  | 3434/4545 [4:20:41<1:05:08,  3.52s/it] 76%|███████▌  | 3435/4545 [4:20:44<1:05:17,  3.53s/it] 76%|███████▌  | 3436/4545 [4:20:48<1:07:21,  3.64s/it] 76%|███████▌  | 3437/4545 [4:20:52<1:08:54,  3.73s/it] 76%|███████▌  | 3438/4545 [4:20:56<1:09:51,  3.79s/it] 76%|███████▌  | 3439/4545 [4:21:25<3:31:09, 11.46s/it] 76%|███████▌  | 3440/4545 [4:21:29<2:47:01,  9.07s/it]                                                       {'loss': 0.0046, 'grad_norm': 3.283546209335327, 'learning_rate': 1.4587385730189549e-06, 'rewards/chosen': -4.289843559265137, 'rewards/rejected': -33.0625, 'rewards/accuracies': 1.0, 'rewards/margins': 28.762500762939453, 'logps/chosen': -274.6000061035156, 'logps/rejected': -422.6000061035156, 'logits/chosen': -13.243749618530273, 'logits/rejected': -12.806249618530273, 'epoch': 2.27}
 76%|███████▌  | 3440/4545 [4:21:29<2:47:01,  9.07s/it] 76%|███████▌  | 3441/4545 [4:21:33<2:18:18,  7.52s/it] 76%|███████▌  | 3442/4545 [4:21:37<1:58:07,  6.43s/it] 76%|███████▌  | 3443/4545 [4:21:41<1:44:09,  5.67s/it] 76%|███████▌  | 3444/4545 [4:21:44<1:34:25,  5.15s/it] 76%|███████▌  | 3445/4545 [4:21:49<1:28:36,  4.83s/it] 76%|███████▌  | 3446/4545 [4:21:52<1:23:27,  4.56s/it] 76%|███████▌  | 3447/4545 [4:21:56<1:18:27,  4.29s/it] 76%|███████▌  | 3448/4545 [4:22:00<1:17:14,  4.22s/it] 76%|███████▌  | 3449/4545 [4:22:04<1:15:29,  4.13s/it] 76%|███████▌  | 3450/4545 [4:22:08<1:14:09,  4.06s/it]                                                       {'loss': 0.0113, 'grad_norm': 0.17319752275943756, 'learning_rate': 1.4417773610322091e-06, 'rewards/chosen': -3.2181639671325684, 'rewards/rejected': -37.037498474121094, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 33.88750076293945, 'logps/chosen': -347.29998779296875, 'logps/rejected': -516.0, 'logits/chosen': -12.75, 'logits/rejected': -12.350000381469727, 'epoch': 2.28}
 76%|███████▌  | 3450/4545 [4:22:08<1:14:09,  4.06s/it] 76%|███████▌  | 3451/4545 [4:22:12<1:13:12,  4.02s/it] 76%|███████▌  | 3452/4545 [4:22:15<1:05:59,  3.62s/it] 76%|███████▌  | 3453/4545 [4:22:18<1:03:19,  3.48s/it] 76%|███████▌  | 3454/4545 [4:22:22<1:07:09,  3.69s/it] 76%|███████▌  | 3455/4545 [4:22:26<1:07:58,  3.74s/it] 76%|███████▌  | 3456/4545 [4:22:30<1:08:51,  3.79s/it] 76%|███████▌  | 3457/4545 [4:22:34<1:10:54,  3.91s/it] 76%|███████▌  | 3458/4545 [4:22:38<1:10:46,  3.91s/it] 76%|███████▌  | 3459/4545 [4:22:42<1:12:09,  3.99s/it] 76%|███████▌  | 3460/4545 [4:22:45<1:08:01,  3.76s/it]                                                       {'loss': 0.0069, 'grad_norm': 0.5667995810508728, 'learning_rate': 1.424897604605138e-06, 'rewards/chosen': -3.2476563453674316, 'rewards/rejected': -34.38750076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 31.149999618530273, 'logps/chosen': -371.0, 'logps/rejected': -499.79998779296875, 'logits/chosen': -12.556249618530273, 'logits/rejected': -12.262499809265137, 'epoch': 2.28}
 76%|███████▌  | 3460/4545 [4:22:45<1:08:01,  3.76s/it] 76%|███████▌  | 3461/4545 [4:22:49<1:08:47,  3.81s/it] 76%|███████▌  | 3462/4545 [4:22:53<1:06:20,  3.68s/it] 76%|███████▌  | 3463/4545 [4:22:57<1:08:36,  3.80s/it] 76%|███████▌  | 3464/4545 [4:23:01<1:09:00,  3.83s/it] 76%|███████▌  | 3465/4545 [4:23:05<1:10:38,  3.92s/it] 76%|███████▋  | 3466/4545 [4:23:08<1:06:47,  3.71s/it] 76%|███████▋  | 3467/4545 [4:23:12<1:07:51,  3.78s/it] 76%|███████▋  | 3468/4545 [4:23:15<1:05:51,  3.67s/it] 76%|███████▋  | 3469/4545 [4:23:19<1:07:47,  3.78s/it] 76%|███████▋  | 3470/4545 [4:23:23<1:08:22,  3.82s/it]                                                       {'loss': 0.0148, 'grad_norm': 0.04640670493245125, 'learning_rate': 1.4081011171233312e-06, 'rewards/chosen': -4.0712890625, 'rewards/rejected': -38.76250076293945, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 34.73125076293945, 'logps/chosen': -294.8999938964844, 'logps/rejected': -539.2000122070312, 'logits/chosen': -13.081250190734863, 'logits/rejected': -12.643750190734863, 'epoch': 2.29}
 76%|███████▋  | 3470/4545 [4:23:23<1:08:22,  3.82s/it] 76%|███████▋  | 3471/4545 [4:23:27<1:10:17,  3.93s/it] 76%|███████▋  | 3472/4545 [4:23:31<1:10:07,  3.92s/it] 76%|███████▋  | 3473/4545 [4:23:35<1:06:28,  3.72s/it] 76%|███████▋  | 3474/4545 [4:23:38<1:07:24,  3.78s/it] 76%|███████▋  | 3475/4545 [4:23:42<1:04:54,  3.64s/it] 76%|███████▋  | 3476/4545 [4:23:46<1:06:23,  3.73s/it] 77%|███████▋  | 3477/4545 [4:23:50<1:07:19,  3.78s/it] 77%|███████▋  | 3478/4545 [4:23:53<1:07:55,  3.82s/it] 77%|███████▋  | 3479/4545 [4:23:57<1:08:22,  3.85s/it] 77%|███████▋  | 3480/4545 [4:24:01<1:08:31,  3.86s/it]                                                       {'loss': 0.0301, 'grad_norm': 3.0290167331695557, 'learning_rate': 1.3913897030268293e-06, 'rewards/chosen': -1.142578125, 'rewards/rejected': -38.70624923706055, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 37.537498474121094, 'logps/chosen': -502.6000061035156, 'logps/rejected': -562.4000244140625, 'logits/chosen': -12.824999809265137, 'logits/rejected': -12.462499618530273, 'epoch': 2.3}
 77%|███████▋  | 3480/4545 [4:24:01<1:08:31,  3.86s/it] 77%|███████▋  | 3481/4545 [4:24:05<1:08:57,  3.89s/it] 77%|███████▋  | 3482/4545 [4:24:09<1:08:59,  3.89s/it] 77%|███████▋  | 3483/4545 [4:24:13<1:09:04,  3.90s/it] 77%|███████▋  | 3484/4545 [4:24:17<1:07:54,  3.84s/it] 77%|███████▋  | 3485/4545 [4:24:21<1:08:31,  3.88s/it] 77%|███████▋  | 3486/4545 [4:24:24<1:06:09,  3.75s/it] 77%|███████▋  | 3487/4545 [4:24:28<1:04:00,  3.63s/it] 77%|███████▋  | 3488/4545 [4:24:31<1:04:12,  3.64s/it] 77%|███████▋  | 3489/4545 [4:24:35<1:05:34,  3.73s/it] 77%|███████▋  | 3490/4545 [4:24:39<1:08:03,  3.87s/it]                                                       {'loss': 0.0078, 'grad_norm': 1.700605034828186, 'learning_rate': 1.3747651576162689e-06, 'rewards/chosen': -2.9664063453674316, 'rewards/rejected': -40.23749923706055, 'rewards/accuracies': 1.0, 'rewards/margins': 37.25, 'logps/chosen': -403.5, 'logps/rejected': -577.2000122070312, 'logits/chosen': -12.675000190734863, 'logits/rejected': -12.324999809265137, 'epoch': 2.3}
 77%|███████▋  | 3490/4545 [4:24:39<1:08:03,  3.87s/it] 77%|███████▋  | 3491/4545 [4:24:43<1:08:10,  3.88s/it] 77%|███████▋  | 3492/4545 [4:24:46<1:04:32,  3.68s/it] 77%|███████▋  | 3493/4545 [4:24:51<1:06:47,  3.81s/it] 77%|███████▋  | 3494/4545 [4:24:53<59:03,  3.37s/it]   77%|███████▋  | 3495/4545 [4:24:56<59:37,  3.41s/it] 77%|███████▋  | 3496/4545 [4:25:00<1:02:02,  3.55s/it] 77%|███████▋  | 3497/4545 [4:25:04<1:04:56,  3.72s/it] 77%|███████▋  | 3498/4545 [4:25:08<1:05:53,  3.78s/it] 77%|███████▋  | 3499/4545 [4:25:12<1:06:20,  3.81s/it] 77%|███████▋  | 3500/4545 [4:25:16<1:05:20,  3.75s/it]                                                       {'loss': 0.0115, 'grad_norm': 6.496708393096924, 'learning_rate': 1.3582292668600216e-06, 'rewards/chosen': -3.710156202316284, 'rewards/rejected': -33.36249923706055, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 29.600000381469727, 'logps/chosen': -315.3500061035156, 'logps/rejected': -474.1000061035156, 'logits/chosen': -13.206250190734863, 'logits/rejected': -12.831250190734863, 'epoch': 2.31}
 77%|███████▋  | 3500/4545 [4:25:16<1:05:20,  3.75s/it] 77%|███████▋  | 3501/4545 [4:25:20<1:06:37,  3.83s/it] 77%|███████▋  | 3502/4545 [4:25:24<1:07:56,  3.91s/it] 77%|███████▋  | 3503/4545 [4:25:28<1:07:56,  3.91s/it] 77%|███████▋  | 3504/4545 [4:25:31<1:01:27,  3.54s/it] 77%|███████▋  | 3505/4545 [4:25:34<1:02:06,  3.58s/it] 77%|███████▋  | 3506/4545 [4:25:37<56:53,  3.29s/it]   77%|███████▋  | 3507/4545 [4:25:41<1:00:59,  3.53s/it] 77%|███████▋  | 3508/4545 [4:25:45<1:02:47,  3.63s/it] 77%|███████▋  | 3509/4545 [4:25:49<1:04:06,  3.71s/it] 77%|███████▋  | 3510/4545 [4:25:52<1:03:01,  3.65s/it]                                                       {'loss': 0.0371, 'grad_norm': 0.12007690966129303, 'learning_rate': 1.3417838072023227e-06, 'rewards/chosen': -3.0093750953674316, 'rewards/rejected': -39.01250076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 35.98749923706055, 'logps/chosen': -397.70001220703125, 'logps/rejected': -599.7999877929688, 'logits/chosen': -12.912500381469727, 'logits/rejected': -12.512499809265137, 'epoch': 2.32}
 77%|███████▋  | 3510/4545 [4:25:52<1:03:01,  3.65s/it] 77%|███████▋  | 3511/4545 [4:25:56<1:05:43,  3.81s/it] 77%|███████▋  | 3512/4545 [4:26:00<1:06:20,  3.85s/it] 77%|███████▋  | 3513/4545 [4:26:04<1:06:31,  3.87s/it] 77%|███████▋  | 3514/4545 [4:26:08<1:06:39,  3.88s/it] 77%|███████▋  | 3515/4545 [4:26:12<1:04:46,  3.77s/it] 77%|███████▋  | 3516/4545 [4:26:16<1:05:21,  3.81s/it] 77%|███████▋  | 3517/4545 [4:26:19<1:05:45,  3.84s/it] 77%|███████▋  | 3518/4545 [4:26:23<1:04:58,  3.80s/it] 77%|███████▋  | 3519/4545 [4:26:26<1:00:09,  3.52s/it] 77%|███████▋  | 3520/4545 [4:26:30<1:02:05,  3.63s/it]                                                       {'loss': 0.0273, 'grad_norm': 5.520552635192871, 'learning_rate': 1.3254305453724302e-06, 'rewards/chosen': 0.10507812350988388, 'rewards/rejected': -29.65625, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 29.806249618530273, 'logps/chosen': -475.0, 'logps/rejected': -552.0, 'logits/chosen': -12.931249618530273, 'logits/rejected': -12.587499618530273, 'epoch': 2.32}
 77%|███████▋  | 3520/4545 [4:26:30<1:02:05,  3.63s/it] 77%|███████▋  | 3521/4545 [4:26:34<1:03:15,  3.71s/it] 77%|███████▋  | 3522/4545 [4:26:38<1:04:13,  3.77s/it] 78%|███████▊  | 3523/4545 [4:26:41<1:03:53,  3.75s/it] 78%|███████▊  | 3524/4545 [4:26:45<1:04:36,  3.80s/it] 78%|███████▊  | 3525/4545 [4:26:49<1:03:41,  3.75s/it] 78%|███████▊  | 3526/4545 [4:26:52<1:01:42,  3.63s/it] 78%|███████▊  | 3527/4545 [4:26:55<56:40,  3.34s/it]   78%|███████▊  | 3528/4545 [4:26:59<59:36,  3.52s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.09s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:39,  1.00s/it][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.11s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:37,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.08s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.28s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.13s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.43s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.47452107071876526, 'eval_runtime': 80.4043, 'eval_samples_per_second': 11.853, 'eval_steps_per_second': 0.746, 'eval_rewards/chosen': -4.787109375, 'eval_rewards/rejected': -34.83541488647461, 'eval_rewards/accuracies': 0.8590278029441833, 'eval_rewards/margins': 30.037109375, 'eval_logps/chosen': -425.48333740234375, 'eval_logps/rejected': -500.45001220703125, 'eval_logits/chosen': -12.692187309265137, 'eval_logits/rejected': -12.542187690734863, 'epoch': 2.33}
 78%|███████▊  | 3528/4545 [4:28:19<59:36,  3.52s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 78%|███████▊  | 3529/4545 [4:28:35<8:50:17, 31.32s/it] 78%|███████▊  | 3530/4545 [4:28:39<6:31:44, 23.16s/it]                                                       {'loss': 0.009, 'grad_norm': 0.688813328742981, 'learning_rate': 1.3091712381948262e-06, 'rewards/chosen': -5.047656059265137, 'rewards/rejected': -33.63750076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 28.556249618530273, 'logps/chosen': -293.20001220703125, 'logps/rejected': -456.79998779296875, 'logits/chosen': -13.137499809265137, 'logits/rejected': -12.8125, 'epoch': 2.33}
 78%|███████▊  | 3530/4545 [4:28:39<6:31:44, 23.16s/it] 78%|███████▊  | 3531/4545 [4:28:43<4:52:24, 17.30s/it] 78%|███████▊  | 3532/4545 [4:28:47<3:45:19, 13.35s/it] 78%|███████▊  | 3533/4545 [4:28:51<2:55:48, 10.42s/it] 78%|███████▊  | 3534/4545 [4:28:54<2:22:09,  8.44s/it] 78%|███████▊  | 3535/4545 [4:28:58<1:59:15,  7.09s/it] 78%|███████▊  | 3536/4545 [4:29:02<1:41:02,  6.01s/it] 78%|███████▊  | 3537/4545 [4:29:05<1:29:03,  5.30s/it] 78%|███████▊  | 3538/4545 [4:29:08<1:15:43,  4.51s/it] 78%|███████▊  | 3539/4545 [4:29:12<1:11:26,  4.26s/it] 78%|███████▊  | 3540/4545 [4:29:15<1:08:38,  4.10s/it]                                                       {'loss': 0.0296, 'grad_norm': 0.2723624110221863, 'learning_rate': 1.293007632400482e-06, 'rewards/chosen': -6.324999809265137, 'rewards/rejected': -40.625, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 34.29375076293945, 'logps/chosen': -207.10000610351562, 'logps/rejected': -499.70001220703125, 'logits/chosen': -13.225000381469727, 'logits/rejected': -12.84375, 'epoch': 2.34}
 78%|███████▊  | 3540/4545 [4:29:16<1:08:38,  4.10s/it] 78%|███████▊  | 3541/4545 [4:29:20<1:09:04,  4.13s/it] 78%|███████▊  | 3542/4545 [4:29:24<1:09:12,  4.14s/it] 78%|███████▊  | 3543/4545 [4:29:28<1:07:57,  4.07s/it] 78%|███████▊  | 3544/4545 [4:29:31<1:06:02,  3.96s/it] 78%|███████▊  | 3545/4545 [4:29:35<1:05:43,  3.94s/it] 78%|███████▊  | 3546/4545 [4:29:39<1:05:31,  3.94s/it] 78%|███████▊  | 3547/4545 [4:29:43<1:05:15,  3.92s/it] 78%|███████▊  | 3548/4545 [4:29:46<1:00:30,  3.64s/it] 78%|███████▊  | 3549/4545 [4:29:50<1:01:21,  3.70s/it] 78%|███████▊  | 3550/4545 [4:29:54<1:02:18,  3.76s/it]                                                       {'loss': 0.0686, 'grad_norm': 0.8571342825889587, 'learning_rate': 1.2769414644392049e-06, 'rewards/chosen': -4.119140625, 'rewards/rejected': -38.6875, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 34.54999923706055, 'logps/chosen': -325.70001220703125, 'logps/rejected': -543.9000244140625, 'logits/chosen': -13.131250381469727, 'logits/rejected': -12.731249809265137, 'epoch': 2.34}
 78%|███████▊  | 3550/4545 [4:29:54<1:02:18,  3.76s/it] 78%|███████▊  | 3551/4545 [4:29:58<1:02:59,  3.80s/it] 78%|███████▊  | 3552/4545 [4:30:02<1:03:28,  3.84s/it] 78%|███████▊  | 3553/4545 [4:30:06<1:03:50,  3.86s/it] 78%|███████▊  | 3554/4545 [4:30:09<1:03:18,  3.83s/it] 78%|███████▊  | 3555/4545 [4:30:13<1:03:41,  3.86s/it] 78%|███████▊  | 3556/4545 [4:30:17<1:04:03,  3.89s/it] 78%|███████▊  | 3557/4545 [4:30:21<1:02:46,  3.81s/it] 78%|███████▊  | 3558/4545 [4:30:25<1:03:24,  3.85s/it] 78%|███████▊  | 3559/4545 [4:30:54<3:09:01, 11.50s/it] 78%|███████▊  | 3560/4545 [4:30:58<2:30:47,  9.19s/it]                                                       {'loss': 0.1666, 'grad_norm': 0.8708204627037048, 'learning_rate': 1.260974460293096e-06, 'rewards/chosen': -3.6092772483825684, 'rewards/rejected': -42.650001525878906, 'rewards/accuracies': 0.96875, 'rewards/margins': 39.0, 'logps/chosen': -401.79998779296875, 'logps/rejected': -607.5999755859375, 'logits/chosen': -12.931249618530273, 'logits/rejected': -12.612500190734863, 'epoch': 2.35}
 78%|███████▊  | 3560/4545 [4:30:58<2:30:47,  9.19s/it] 78%|███████▊  | 3561/4545 [4:31:02<2:02:47,  7.49s/it] 78%|███████▊  | 3562/4545 [4:31:05<1:44:26,  6.37s/it] 78%|███████▊  | 3563/4545 [4:31:09<1:30:10,  5.51s/it] 78%|███████▊  | 3564/4545 [4:31:13<1:22:26,  5.04s/it] 78%|███████▊  | 3565/4545 [4:31:17<1:16:47,  4.70s/it] 78%|███████▊  | 3566/4545 [4:31:20<1:12:32,  4.45s/it] 78%|███████▊  | 3567/4545 [4:31:24<1:09:26,  4.26s/it] 79%|███████▊  | 3568/4545 [4:31:28<1:08:52,  4.23s/it] 79%|███████▊  | 3569/4545 [4:31:32<1:07:13,  4.13s/it] 79%|███████▊  | 3570/4545 [4:31:36<1:06:11,  4.07s/it]                                                       {'loss': 0.0437, 'grad_norm': 0.20900879800319672, 'learning_rate': 1.2451083352911273e-06, 'rewards/chosen': -4.358593940734863, 'rewards/rejected': -35.025001525878906, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 30.65625, 'logps/chosen': -303.3500061035156, 'logps/rejected': -478.20001220703125, 'logits/chosen': -13.09375, 'logits/rejected': -12.71875, 'epoch': 2.36}
 79%|███████▊  | 3570/4545 [4:31:36<1:06:11,  4.07s/it] 79%|███████▊  | 3571/4545 [4:31:40<1:05:19,  4.02s/it] 79%|███████▊  | 3572/4545 [4:31:44<1:04:44,  3.99s/it] 79%|███████▊  | 3573/4545 [4:31:48<1:04:18,  3.97s/it] 79%|███████▊  | 3574/4545 [4:31:52<1:04:00,  3.96s/it] 79%|███████▊  | 3575/4545 [4:31:56<1:02:34,  3.87s/it] 79%|███████▊  | 3576/4545 [4:31:59<59:57,  3.71s/it]   79%|███████▊  | 3577/4545 [4:32:02<54:30,  3.38s/it] 79%|███████▊  | 3578/4545 [4:32:06<57:34,  3.57s/it] 79%|███████▊  | 3579/4545 [4:32:10<59:07,  3.67s/it] 79%|███████▉  | 3580/4545 [4:32:13<1:00:09,  3.74s/it]                                                       {'loss': 0.0374, 'grad_norm': 0.925679624080658, 'learning_rate': 1.2293447939248607e-06, 'rewards/chosen': -3.5757813453674316, 'rewards/rejected': -39.412498474121094, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 35.82500076293945, 'logps/chosen': -405.8999938964844, 'logps/rejected': -593.5999755859375, 'logits/chosen': -13.118749618530273, 'logits/rejected': -12.756250381469727, 'epoch': 2.36}
 79%|███████▉  | 3580/4545 [4:32:13<1:00:09,  3.74s/it] 79%|███████▉  | 3581/4545 [4:32:17<1:00:51,  3.79s/it] 79%|███████▉  | 3582/4545 [4:32:21<1:01:22,  3.82s/it] 79%|███████▉  | 3583/4545 [4:32:25<1:01:13,  3.82s/it] 79%|███████▉  | 3584/4545 [4:32:29<1:00:32,  3.78s/it] 79%|███████▉  | 3585/4545 [4:32:33<1:01:04,  3.82s/it] 79%|███████▉  | 3586/4545 [4:32:36<1:00:09,  3.76s/it] 79%|███████▉  | 3587/4545 [4:32:40<1:00:42,  3.80s/it] 79%|███████▉  | 3588/4545 [4:32:43<58:11,  3.65s/it]   79%|███████▉  | 3589/4545 [4:32:47<59:13,  3.72s/it] 79%|███████▉  | 3590/4545 [4:32:51<1:00:55,  3.83s/it]                                                       {'loss': 0.0765, 'grad_norm': 0.014106153510510921, 'learning_rate': 1.2136855296653434e-06, 'rewards/chosen': -4.701562404632568, 'rewards/rejected': -48.01250076293945, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 43.3125, 'logps/chosen': -375.0, 'logps/rejected': -652.4000244140625, 'logits/chosen': -13.131250381469727, 'logits/rejected': -12.71875, 'epoch': 2.37}
 79%|███████▉  | 3590/4545 [4:32:51<1:00:55,  3.83s/it] 79%|███████▉  | 3591/4545 [4:32:55<1:01:12,  3.85s/it] 79%|███████▉  | 3592/4545 [4:32:59<1:01:28,  3.87s/it] 79%|███████▉  | 3593/4545 [4:33:03<1:01:55,  3.90s/it] 79%|███████▉  | 3594/4545 [4:33:07<1:03:29,  4.01s/it] 79%|███████▉  | 3595/4545 [4:33:11<1:02:45,  3.96s/it] 79%|███████▉  | 3596/4545 [4:33:15<1:02:37,  3.96s/it] 79%|███████▉  | 3597/4545 [4:33:19<1:01:51,  3.91s/it] 79%|███████▉  | 3598/4545 [4:33:23<1:01:40,  3.91s/it] 79%|███████▉  | 3599/4545 [4:33:27<1:02:32,  3.97s/it] 79%|███████▉  | 3600/4545 [4:33:31<1:03:20,  4.02s/it]                                                       {'loss': 0.0171, 'grad_norm': 12.672456741333008, 'learning_rate': 1.1981322247811696e-06, 'rewards/chosen': -5.961718559265137, 'rewards/rejected': -50.63750076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 44.724998474121094, 'logps/chosen': -383.79998779296875, 'logps/rejected': -676.0, 'logits/chosen': -13.125, 'logits/rejected': -12.818750381469727, 'epoch': 2.38}
 79%|███████▉  | 3600/4545 [4:33:31<1:03:20,  4.02s/it] 79%|███████▉  | 3601/4545 [4:33:35<1:03:36,  4.04s/it] 79%|███████▉  | 3602/4545 [4:33:39<1:00:45,  3.87s/it] 79%|███████▉  | 3603/4545 [4:33:43<1:00:39,  3.86s/it] 79%|███████▉  | 3604/4545 [4:33:47<1:00:57,  3.89s/it] 79%|███████▉  | 3605/4545 [4:33:50<1:00:57,  3.89s/it] 79%|███████▉  | 3606/4545 [4:33:54<1:00:58,  3.90s/it] 79%|███████▉  | 3607/4545 [4:33:58<1:01:44,  3.95s/it] 79%|███████▉  | 3608/4545 [4:34:02<1:01:28,  3.94s/it] 79%|███████▉  | 3609/4545 [4:34:06<1:02:09,  3.98s/it] 79%|███████▉  | 3610/4545 [4:34:10<1:01:37,  3.95s/it]                                                       {'loss': 0.0189, 'grad_norm': 0.3583248555660248, 'learning_rate': 1.1826865501577623e-06, 'rewards/chosen': -4.949609279632568, 'rewards/rejected': -45.5, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 40.525001525878906, 'logps/chosen': -341.70001220703125, 'logps/rejected': -577.7999877929688, 'logits/chosen': -13.59375, 'logits/rejected': -13.106249809265137, 'epoch': 2.38}
 79%|███████▉  | 3610/4545 [4:34:10<1:01:37,  3.95s/it] 79%|███████▉  | 3611/4545 [4:34:14<1:00:17,  3.87s/it] 79%|███████▉  | 3612/4545 [4:34:18<1:00:11,  3.87s/it] 79%|███████▉  | 3613/4545 [4:34:22<59:00,  3.80s/it]   80%|███████▉  | 3614/4545 [4:34:25<59:29,  3.83s/it] 80%|███████▉  | 3615/4545 [4:34:29<59:45,  3.85s/it] 80%|███████▉  | 3616/4545 [4:34:33<57:16,  3.70s/it] 80%|███████▉  | 3617/4545 [4:34:37<58:16,  3.77s/it] 80%|███████▉  | 3618/4545 [4:34:41<58:52,  3.81s/it] 80%|███████▉  | 3619/4545 [4:34:44<59:17,  3.84s/it] 80%|███████▉  | 3620/4545 [4:34:48<57:24,  3.72s/it]                                                     {'loss': 0.02, 'grad_norm': 0.8395030498504639, 'learning_rate': 1.1673501651178672e-06, 'rewards/chosen': -4.074999809265137, 'rewards/rejected': -44.962501525878906, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 40.849998474121094, 'logps/chosen': -332.3999938964844, 'logps/rejected': -604.2000122070312, 'logits/chosen': -13.46875, 'logits/rejected': -13.024999618530273, 'epoch': 2.39}
 80%|███████▉  | 3620/4545 [4:34:48<57:24,  3.72s/it] 80%|███████▉  | 3621/4545 [4:34:52<58:49,  3.82s/it] 80%|███████▉  | 3622/4545 [4:34:56<1:00:25,  3.93s/it] 80%|███████▉  | 3623/4545 [4:34:59<54:32,  3.55s/it]   80%|███████▉  | 3624/4545 [4:35:03<56:12,  3.66s/it] 80%|███████▉  | 3625/4545 [4:35:07<56:56,  3.71s/it] 80%|███████▉  | 3626/4545 [4:35:10<57:46,  3.77s/it] 80%|███████▉  | 3627/4545 [4:35:14<57:54,  3.78s/it] 80%|███████▉  | 3628/4545 [4:35:18<59:05,  3.87s/it] 80%|███████▉  | 3629/4545 [4:35:46<2:50:15, 11.15s/it] 80%|███████▉  | 3630/4545 [4:35:50<2:16:54,  8.98s/it]                                                       {'loss': 0.079, 'grad_norm': 0.32679712772369385, 'learning_rate': 1.152124717243292e-06, 'rewards/chosen': -2.047656297683716, 'rewards/rejected': -38.462501525878906, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 36.443748474121094, 'logps/chosen': -452.8999938964844, 'logps/rejected': -594.0, 'logits/chosen': -12.949999809265137, 'logits/rejected': -12.824999809265137, 'epoch': 2.4}
 80%|███████▉  | 3630/4545 [4:35:50<2:16:54,  8.98s/it] 80%|███████▉  | 3631/4545 [4:35:54<1:53:04,  7.42s/it] 80%|███████▉  | 3632/4545 [4:35:58<1:37:44,  6.42s/it] 80%|███████▉  | 3633/4545 [4:36:02<1:24:45,  5.58s/it] 80%|███████▉  | 3634/4545 [4:36:06<1:17:06,  5.08s/it] 80%|███████▉  | 3635/4545 [4:36:10<1:11:46,  4.73s/it] 80%|████████  | 3636/4545 [4:36:14<1:07:58,  4.49s/it] 80%|████████  | 3637/4545 [4:36:17<1:03:35,  4.20s/it] 80%|████████  | 3638/4545 [4:36:21<1:02:10,  4.11s/it] 80%|████████  | 3639/4545 [4:36:25<1:00:39,  4.02s/it] 80%|████████  | 3640/4545 [4:36:29<1:00:05,  3.98s/it]                                                       {'loss': 0.0262, 'grad_norm': 1.4264625310897827, 'learning_rate': 1.1370118421979093e-06, 'rewards/chosen': -1.5285155773162842, 'rewards/rejected': -32.375, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 30.825000762939453, 'logps/chosen': -458.5, 'logps/rejected': -491.0, 'logits/chosen': -13.293749809265137, 'logits/rejected': -13.006250381469727, 'epoch': 2.4}
 80%|████████  | 3640/4545 [4:36:29<1:00:05,  3.98s/it] 80%|████████  | 3641/4545 [4:36:33<1:00:47,  4.03s/it] 80%|████████  | 3642/4545 [4:36:36<56:12,  3.73s/it]   80%|████████  | 3643/4545 [4:36:40<56:56,  3.79s/it] 80%|████████  | 3644/4545 [4:36:44<57:24,  3.82s/it] 80%|████████  | 3645/4545 [4:36:47<53:18,  3.55s/it] 80%|████████  | 3646/4545 [4:36:50<53:43,  3.59s/it] 80%|████████  | 3647/4545 [4:36:54<53:53,  3.60s/it] 80%|████████  | 3648/4545 [4:36:57<50:46,  3.40s/it] 80%|████████  | 3649/4545 [4:37:01<53:00,  3.55s/it] 80%|████████  | 3650/4545 [4:37:05<54:32,  3.66s/it]                                                     {'loss': 0.0246, 'grad_norm': 0.8158296942710876, 'learning_rate': 1.1220131635519381e-06, 'rewards/chosen': -4.706250190734863, 'rewards/rejected': -37.01250076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 32.306251525878906, 'logps/chosen': -276.0, 'logps/rejected': -482.3999938964844, 'logits/chosen': -13.5625, 'logits/rejected': -13.125, 'epoch': 2.41}
 80%|████████  | 3650/4545 [4:37:05<54:32,  3.66s/it] 80%|████████  | 3651/4545 [4:37:08<52:03,  3.49s/it] 80%|████████  | 3652/4545 [4:37:12<53:47,  3.61s/it] 80%|████████  | 3653/4545 [4:37:16<55:20,  3.72s/it] 80%|████████  | 3654/4545 [4:37:20<56:19,  3.79s/it] 80%|████████  | 3655/4545 [4:37:24<56:44,  3.83s/it] 80%|████████  | 3656/4545 [4:37:27<57:06,  3.85s/it] 80%|████████  | 3657/4545 [4:37:32<58:30,  3.95s/it] 80%|████████  | 3658/4545 [4:38:06<3:14:57, 13.19s/it] 81%|████████  | 3659/4545 [4:38:15<2:53:31, 11.75s/it] 81%|████████  | 3660/4545 [4:38:23<2:38:43, 10.76s/it]                                                       {'loss': 0.0109, 'grad_norm': 10.975049018859863, 'learning_rate': 1.1071302926075201e-06, 'rewards/chosen': -2.0601563453674316, 'rewards/rejected': -38.662498474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 36.61249923706055, 'logps/chosen': -409.70001220703125, 'logps/rejected': -590.4000244140625, 'logits/chosen': -13.03125, 'logits/rejected': -12.756250381469727, 'epoch': 2.42}
 81%|████████  | 3660/4545 [4:38:23<2:38:43, 10.76s/it] 81%|████████  | 3661/4545 [4:38:32<2:29:52, 10.17s/it] 81%|████████  | 3662/4545 [4:38:41<2:22:11,  9.66s/it] 81%|████████  | 3663/4545 [4:38:49<2:16:23,  9.28s/it] 81%|████████  | 3664/4545 [4:38:58<2:13:31,  9.09s/it] 81%|████████  | 3665/4545 [4:39:05<2:06:31,  8.63s/it] 81%|████████  | 3666/4545 [4:39:12<1:57:05,  7.99s/it] 81%|████████  | 3667/4545 [4:39:15<1:37:38,  6.67s/it] 81%|████████  | 3668/4545 [4:39:19<1:25:28,  5.85s/it] 81%|████████  | 3669/4545 [4:39:23<1:16:52,  5.27s/it] 81%|████████  | 3670/4545 [4:39:27<1:10:51,  4.86s/it]                                                       {'loss': 0.0477, 'grad_norm': 7.940504550933838, 'learning_rate': 1.0923648282256257e-06, 'rewards/chosen': -1.948828101158142, 'rewards/rejected': -38.006248474121094, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 36.07500076293945, 'logps/chosen': -412.6000061035156, 'logps/rejected': -576.4000244140625, 'logits/chosen': -13.425000190734863, 'logits/rejected': -12.962499618530273, 'epoch': 2.42}
 81%|████████  | 3670/4545 [4:39:27<1:10:51,  4.86s/it] 81%|████████  | 3671/4545 [4:39:31<1:06:36,  4.57s/it] 81%|████████  | 3672/4545 [4:39:34<1:01:17,  4.21s/it] 81%|████████  | 3673/4545 [4:39:38<58:06,  4.00s/it]   81%|████████  | 3674/4545 [4:39:42<57:52,  3.99s/it] 81%|████████  | 3675/4545 [4:39:46<57:25,  3.96s/it] 81%|████████  | 3676/4545 [4:39:49<57:07,  3.94s/it] 81%|████████  | 3677/4545 [4:39:53<56:53,  3.93s/it] 81%|████████  | 3678/4545 [4:39:57<57:09,  3.96s/it] 81%|████████  | 3679/4545 [4:40:01<56:46,  3.93s/it] 81%|████████  | 3680/4545 [4:40:05<55:39,  3.86s/it]                                                     {'loss': 0.0071, 'grad_norm': 1.2595597505569458, 'learning_rate': 1.0777183566542798e-06, 'rewards/chosen': -2.254687547683716, 'rewards/rejected': -30.0, 'rewards/accuracies': 1.0, 'rewards/margins': 27.774999618530273, 'logps/chosen': -358.25, 'logps/rejected': -541.0999755859375, 'logits/chosen': -13.206250190734863, 'logits/rejected': -12.824999809265137, 'epoch': 2.43}
 81%|████████  | 3680/4545 [4:40:05<55:39,  3.86s/it] 81%|████████  | 3681/4545 [4:40:08<50:54,  3.54s/it] 81%|████████  | 3682/4545 [4:40:12<53:03,  3.69s/it] 81%|████████  | 3683/4545 [4:40:16<54:10,  3.77s/it] 81%|████████  | 3684/4545 [4:40:20<54:38,  3.81s/it] 81%|████████  | 3685/4545 [4:40:22<49:26,  3.45s/it] 81%|████████  | 3686/4545 [4:40:26<52:40,  3.68s/it] 81%|████████  | 3687/4545 [4:40:30<53:34,  3.75s/it] 81%|████████  | 3688/4545 [4:40:34<54:23,  3.81s/it] 81%|████████  | 3689/4545 [4:40:38<54:41,  3.83s/it] 81%|████████  | 3690/4545 [4:40:42<54:55,  3.85s/it]                                                     {'loss': 0.0186, 'grad_norm': 1.8239078521728516, 'learning_rate': 1.063192451358159e-06, 'rewards/chosen': -0.526171863079071, 'rewards/rejected': -34.29999923706055, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 33.775001525878906, 'logps/chosen': -481.3999938964844, 'logps/rejected': -575.0, 'logits/chosen': -13.34375, 'logits/rejected': -13.0, 'epoch': 2.44}
 81%|████████  | 3690/4545 [4:40:42<54:55,  3.85s/it] 81%|████████  | 3691/4545 [4:40:46<53:59,  3.79s/it] 81%|████████  | 3692/4545 [4:40:50<54:41,  3.85s/it] 81%|████████▏ | 3693/4545 [4:40:54<54:58,  3.87s/it] 81%|████████▏ | 3694/4545 [4:40:57<52:35,  3.71s/it] 81%|████████▏ | 3695/4545 [4:41:01<53:31,  3.78s/it] 81%|████████▏ | 3696/4545 [4:41:05<54:02,  3.82s/it] 81%|████████▏ | 3697/4545 [4:41:08<48:59,  3.47s/it] 81%|████████▏ | 3698/4545 [4:41:12<52:07,  3.69s/it] 81%|████████▏ | 3699/4545 [4:41:15<49:48,  3.53s/it] 81%|████████▏ | 3700/4545 [4:41:19<51:21,  3.65s/it]                                                     {'loss': 0.0186, 'grad_norm': 2.4153032302856445, 'learning_rate': 1.048788672849553e-06, 'rewards/chosen': -3.2310547828674316, 'rewards/rejected': -29.600000381469727, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 26.362499237060547, 'logps/chosen': -301.6000061035156, 'logps/rejected': -475.6000061035156, 'logits/chosen': -13.46875, 'logits/rejected': -13.131250381469727, 'epoch': 2.44}
 81%|████████▏ | 3700/4545 [4:41:19<51:21,  3.65s/it] 81%|████████▏ | 3701/4545 [4:41:23<51:56,  3.69s/it] 81%|████████▏ | 3702/4545 [4:41:27<52:48,  3.76s/it] 81%|████████▏ | 3703/4545 [4:41:30<53:27,  3.81s/it] 81%|████████▏ | 3704/4545 [4:41:34<53:54,  3.85s/it] 82%|████████▏ | 3705/4545 [4:41:38<54:48,  3.92s/it] 82%|████████▏ | 3706/4545 [4:41:42<54:47,  3.92s/it] 82%|████████▏ | 3707/4545 [4:41:46<53:59,  3.87s/it] 82%|████████▏ | 3708/4545 [4:41:50<53:24,  3.83s/it] 82%|████████▏ | 3709/4545 [4:41:54<53:46,  3.86s/it] 82%|████████▏ | 3710/4545 [4:41:58<53:36,  3.85s/it]                                                     {'loss': 0.0066, 'grad_norm': 1.0417606830596924, 'learning_rate': 1.0345085685207168e-06, 'rewards/chosen': -4.508593559265137, 'rewards/rejected': -34.53125, 'rewards/accuracies': 1.0, 'rewards/margins': 29.962499618530273, 'logps/chosen': -295.70001220703125, 'logps/rejected': -531.0999755859375, 'logits/chosen': -13.637499809265137, 'logits/rejected': -13.1875, 'epoch': 2.45}
 82%|████████▏ | 3710/4545 [4:41:58<53:36,  3.85s/it] 82%|████████▏ | 3711/4545 [4:42:02<54:23,  3.91s/it] 82%|████████▏ | 3712/4545 [4:42:06<55:38,  4.01s/it] 82%|████████▏ | 3713/4545 [4:42:10<55:09,  3.98s/it] 82%|████████▏ | 3714/4545 [4:42:13<52:53,  3.82s/it] 82%|████████▏ | 3715/4545 [4:42:17<53:24,  3.86s/it] 82%|████████▏ | 3716/4545 [4:42:21<52:20,  3.79s/it] 82%|████████▏ | 3717/4545 [4:42:25<53:24,  3.87s/it] 82%|████████▏ | 3718/4545 [4:42:29<52:59,  3.84s/it] 82%|████████▏ | 3719/4545 [4:42:33<53:09,  3.86s/it] 82%|████████▏ | 3720/4545 [4:42:36<51:33,  3.75s/it]                                                     {'loss': 0.0089, 'grad_norm': 0.016736485064029694, 'learning_rate': 1.020353672477638e-06, 'rewards/chosen': -5.349999904632568, 'rewards/rejected': -34.75, 'rewards/accuracies': 1.0, 'rewards/margins': 29.412500381469727, 'logps/chosen': -296.1000061035156, 'logps/rejected': -484.0, 'logits/chosen': -13.5625, 'logits/rejected': -13.287500381469727, 'epoch': 2.46}
 82%|████████▏ | 3720/4545 [4:42:36<51:33,  3.75s/it] 82%|████████▏ | 3721/4545 [4:42:39<48:18,  3.52s/it] 82%|████████▏ | 3722/4545 [4:42:43<49:55,  3.64s/it] 82%|████████▏ | 3723/4545 [4:42:47<50:58,  3.72s/it] 82%|████████▏ | 3724/4545 [4:42:51<52:30,  3.84s/it] 82%|████████▏ | 3725/4545 [4:42:54<48:18,  3.54s/it] 82%|████████▏ | 3726/4545 [4:42:58<51:03,  3.74s/it] 82%|████████▏ | 3727/4545 [4:43:02<51:43,  3.79s/it] 82%|████████▏ | 3728/4545 [4:43:06<53:15,  3.91s/it] 82%|████████▏ | 3729/4545 [4:43:10<54:23,  4.00s/it] 82%|████████▏ | 3730/4545 [4:43:14<51:35,  3.80s/it]                                                     {'loss': 0.0056, 'grad_norm': 0.018767407163977623, 'learning_rate': 1.0063255053752272e-06, 'rewards/chosen': -0.46171873807907104, 'rewards/rejected': -29.037500381469727, 'rewards/accuracies': 1.0, 'rewards/margins': 28.556249618530273, 'logps/chosen': -410.1000061035156, 'logps/rejected': -479.20001220703125, 'logits/chosen': -13.524999618530273, 'logits/rejected': -13.074999809265137, 'epoch': 2.46}
 82%|████████▏ | 3730/4545 [4:43:14<51:35,  3.80s/it] 82%|████████▏ | 3731/4545 [4:43:18<52:12,  3.85s/it] 82%|████████▏ | 3732/4545 [4:43:21<50:17,  3.71s/it] 82%|████████▏ | 3733/4545 [4:43:25<51:04,  3.77s/it] 82%|████████▏ | 3734/4545 [4:43:29<52:44,  3.90s/it] 82%|████████▏ | 3735/4545 [4:43:33<50:24,  3.73s/it] 82%|████████▏ | 3736/4545 [4:43:36<51:05,  3.79s/it] 82%|████████▏ | 3737/4545 [4:43:40<49:14,  3.66s/it] 82%|████████▏ | 3738/4545 [4:43:44<50:13,  3.73s/it] 82%|████████▏ | 3739/4545 [4:43:48<50:51,  3.79s/it] 82%|████████▏ | 3740/4545 [4:43:52<51:26,  3.83s/it]                                                     {'loss': 0.0549, 'grad_norm': 1.441983938217163, 'learning_rate': 9.924255742539553e-07, 'rewards/chosen': -4.012499809265137, 'rewards/rejected': -32.70000076293945, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 28.706249237060547, 'logps/chosen': -309.1000061035156, 'logps/rejected': -487.0, 'logits/chosen': -13.731249809265137, 'logits/rejected': -13.399999618530273, 'epoch': 2.47}
 82%|████████▏ | 3740/4545 [4:43:52<51:26,  3.83s/it] 82%|████████▏ | 3741/4545 [4:43:56<52:30,  3.92s/it] 82%|████████▏ | 3742/4545 [4:44:00<52:27,  3.92s/it] 82%|████████▏ | 3743/4545 [4:44:03<50:45,  3.80s/it] 82%|████████▏ | 3744/4545 [4:44:07<51:08,  3.83s/it] 82%|████████▏ | 3745/4545 [4:44:11<52:35,  3.94s/it] 82%|████████▏ | 3746/4545 [4:44:15<53:41,  4.03s/it] 82%|████████▏ | 3747/4545 [4:44:19<52:37,  3.96s/it] 82%|████████▏ | 3748/4545 [4:44:23<52:09,  3.93s/it] 82%|████████▏ | 3749/4545 [4:44:27<52:06,  3.93s/it] 83%|████████▎ | 3750/4545 [4:44:31<52:17,  3.95s/it]                                                     {'loss': 0.0021, 'grad_norm': 0.0013734523672610521, 'learning_rate': 9.786553723779518e-07, 'rewards/chosen': -4.739062309265137, 'rewards/rejected': -39.20000076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 34.48749923706055, 'logps/chosen': -313.5, 'logps/rejected': -529.7999877929688, 'logits/chosen': -13.65625, 'logits/rejected': -13.274999618530273, 'epoch': 2.48}
 83%|████████▎ | 3750/4545 [4:44:31<52:17,  3.95s/it] 83%|████████▎ | 3751/4545 [4:44:35<51:24,  3.89s/it] 83%|████████▎ | 3752/4545 [4:44:39<52:00,  3.94s/it] 83%|████████▎ | 3753/4545 [4:44:42<50:23,  3.82s/it] 83%|████████▎ | 3754/4545 [4:44:46<50:41,  3.85s/it] 83%|████████▎ | 3755/4545 [4:44:50<50:59,  3.87s/it] 83%|████████▎ | 3756/4545 [4:44:54<51:51,  3.94s/it] 83%|████████▎ | 3757/4545 [4:44:57<48:01,  3.66s/it] 83%|████████▎ | 3758/4545 [4:45:01<49:45,  3.79s/it] 83%|████████▎ | 3759/4545 [4:45:06<51:27,  3.93s/it] 83%|████████▎ | 3760/4545 [4:45:09<50:04,  3.83s/it]                                                     {'loss': 0.0332, 'grad_norm': 7.430426120758057, 'learning_rate': 9.650163790745847e-07, 'rewards/chosen': -6.138671875, 'rewards/rejected': -39.32500076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 33.16875076293945, 'logps/chosen': -247.8000030517578, 'logps/rejected': -520.2000122070312, 'logits/chosen': -13.768750190734863, 'logits/rejected': -13.34375, 'epoch': 2.48}
 83%|████████▎ | 3760/4545 [4:45:09<50:04,  3.83s/it] 83%|████████▎ | 3761/4545 [4:45:13<50:26,  3.86s/it] 83%|████████▎ | 3762/4545 [4:45:15<41:57,  3.22s/it] 83%|████████▎ | 3763/4545 [4:45:19<45:10,  3.47s/it] 83%|████████▎ | 3764/4545 [4:45:22<43:51,  3.37s/it] 83%|████████▎ | 3765/4545 [4:45:24<39:17,  3.02s/it] 83%|████████▎ | 3766/4545 [4:45:28<42:42,  3.29s/it] 83%|████████▎ | 3767/4545 [4:45:32<45:54,  3.54s/it] 83%|████████▎ | 3768/4545 [4:45:37<48:17,  3.73s/it] 83%|████████▎ | 3769/4545 [4:45:40<47:21,  3.66s/it] 83%|████████▎ | 3770/4545 [4:45:44<48:55,  3.79s/it]                                                     {'loss': 0.0284, 'grad_norm': 0.8350361585617065, 'learning_rate': 9.515100595755353e-07, 'rewards/chosen': -4.05078125, 'rewards/rejected': -35.04999923706055, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 31.018749237060547, 'logps/chosen': -323.8500061035156, 'logps/rejected': -530.7999877929688, 'logits/chosen': -14.012499809265137, 'logits/rejected': -13.568750381469727, 'epoch': 2.49}
 83%|████████▎ | 3770/4545 [4:45:44<48:55,  3.79s/it] 83%|████████▎ | 3771/4545 [4:45:48<49:23,  3.83s/it] 83%|████████▎ | 3772/4545 [4:45:52<50:49,  3.94s/it] 83%|████████▎ | 3773/4545 [4:45:56<48:14,  3.75s/it] 83%|████████▎ | 3774/4545 [4:45:59<48:49,  3.80s/it] 83%|████████▎ | 3775/4545 [4:46:04<49:55,  3.89s/it] 83%|████████▎ | 3776/4545 [4:46:07<49:55,  3.89s/it] 83%|████████▎ | 3777/4545 [4:46:11<48:52,  3.82s/it] 83%|████████▎ | 3778/4545 [4:46:15<49:57,  3.91s/it] 83%|████████▎ | 3779/4545 [4:46:19<49:57,  3.91s/it] 83%|████████▎ | 3780/4545 [4:46:23<49:45,  3.90s/it]                                                     {'loss': 0.0208, 'grad_norm': 0.6777032017707825, 'learning_rate': 9.381378648593922e-07, 'rewards/chosen': -5.564062595367432, 'rewards/rejected': -35.98749923706055, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 30.40625, 'logps/chosen': -294.79998779296875, 'logps/rejected': -504.20001220703125, 'logits/chosen': -13.618749618530273, 'logits/rejected': -13.262499809265137, 'epoch': 2.5}
 83%|████████▎ | 3780/4545 [4:46:23<49:45,  3.90s/it] 83%|████████▎ | 3781/4545 [4:46:27<49:48,  3.91s/it] 83%|████████▎ | 3782/4545 [4:46:30<44:38,  3.51s/it] 83%|████████▎ | 3783/4545 [4:46:33<46:08,  3.63s/it] 83%|████████▎ | 3784/4545 [4:46:37<45:59,  3.63s/it] 83%|████████▎ | 3785/4545 [4:46:41<47:01,  3.71s/it] 83%|████████▎ | 3786/4545 [4:46:45<48:32,  3.84s/it] 83%|████████▎ | 3787/4545 [4:46:48<44:08,  3.49s/it] 83%|████████▎ | 3788/4545 [4:46:51<44:45,  3.55s/it] 83%|████████▎ | 3789/4545 [4:46:55<43:36,  3.46s/it] 83%|████████▎ | 3790/4545 [4:46:58<44:13,  3.51s/it]                                                     {'loss': 0.0454, 'grad_norm': 28.920995712280273, 'learning_rate': 9.249012314957709e-07, 'rewards/chosen': -5.396874904632568, 'rewards/rejected': -40.3125, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 34.91875076293945, 'logps/chosen': -300.79998779296875, 'logps/rejected': -564.5999755859375, 'logits/chosen': -13.65625, 'logits/rejected': -13.162500381469727, 'epoch': 2.5}
 83%|████████▎ | 3790/4545 [4:46:58<44:13,  3.51s/it] 83%|████████▎ | 3791/4545 [4:47:02<45:45,  3.64s/it] 83%|████████▎ | 3792/4545 [4:47:06<46:08,  3.68s/it] 83%|████████▎ | 3793/4545 [4:47:10<45:26,  3.63s/it] 83%|████████▎ | 3794/4545 [4:47:13<44:51,  3.58s/it] 83%|████████▎ | 3795/4545 [4:47:17<46:11,  3.70s/it] 84%|████████▎ | 3796/4545 [4:47:21<46:08,  3.70s/it] 84%|████████▎ | 3797/4545 [4:47:50<2:20:06, 11.24s/it] 84%|████████▎ | 3798/4545 [4:47:54<1:53:14,  9.10s/it] 84%|████████▎ | 3799/4545 [4:47:57<1:33:14,  7.50s/it] 84%|████████▎ | 3800/4545 [4:48:01<1:17:16,  6.22s/it]                                                       {'loss': 0.0298, 'grad_norm': 29.167354583740234, 'learning_rate': 9.11801581490983e-07, 'rewards/chosen': -5.9375, 'rewards/rejected': -36.20000076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 30.262500762939453, 'logps/chosen': -194.8000030517578, 'logps/rejected': -459.20001220703125, 'logits/chosen': -14.324999809265137, 'logits/rejected': -13.84375, 'epoch': 2.51}
 84%|████████▎ | 3800/4545 [4:48:01<1:17:16,  6.22s/it] 84%|████████▎ | 3801/4545 [4:48:05<1:09:05,  5.57s/it] 84%|████████▎ | 3802/4545 [4:48:09<1:02:57,  5.08s/it] 84%|████████▎ | 3803/4545 [4:48:12<55:56,  4.52s/it]   84%|████████▎ | 3804/4545 [4:48:16<54:41,  4.43s/it] 84%|████████▎ | 3805/4545 [4:48:19<50:02,  4.06s/it] 84%|████████▎ | 3806/4545 [4:48:23<49:03,  3.98s/it] 84%|████████▍ | 3807/4545 [4:48:27<47:19,  3.85s/it] 84%|████████▍ | 3808/4545 [4:48:31<47:51,  3.90s/it] 84%|████████▍ | 3809/4545 [4:48:35<48:44,  3.97s/it] 84%|████████▍ | 3810/4545 [4:48:38<44:56,  3.67s/it]                                                     {'loss': 0.0061, 'grad_norm': 0.11682126671075821, 'learning_rate': 8.988403221352728e-07, 'rewards/chosen': -6.462500095367432, 'rewards/rejected': -43.587501525878906, 'rewards/accuracies': 1.0, 'rewards/margins': 37.099998474121094, 'logps/chosen': -262.5, 'logps/rejected': -544.4000244140625, 'logits/chosen': -13.737500190734863, 'logits/rejected': -13.287500381469727, 'epoch': 2.51}
 84%|████████▍ | 3810/4545 [4:48:38<44:56,  3.67s/it] 84%|████████▍ | 3811/4545 [4:48:42<46:05,  3.77s/it] 84%|████████▍ | 3812/4545 [4:48:46<46:34,  3.81s/it] 84%|████████▍ | 3813/4545 [4:48:48<42:40,  3.50s/it] 84%|████████▍ | 3814/4545 [4:48:52<42:36,  3.50s/it] 84%|████████▍ | 3815/4545 [4:48:56<44:05,  3.62s/it] 84%|████████▍ | 3816/4545 [4:49:00<45:14,  3.72s/it] 84%|████████▍ | 3817/4545 [4:49:04<45:52,  3.78s/it] 84%|████████▍ | 3818/4545 [4:49:07<44:15,  3.65s/it] 84%|████████▍ | 3819/4545 [4:49:11<45:09,  3.73s/it] 84%|████████▍ | 3820/4545 [4:49:15<45:52,  3.80s/it]                                                     {'loss': 0.0258, 'grad_norm': 14.322871208190918, 'learning_rate': 8.860188458516316e-07, 'rewards/chosen': -1.587792992591858, 'rewards/rejected': -32.0625, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 30.481250762939453, 'logps/chosen': -496.5, 'logps/rejected': -558.4000244140625, 'logits/chosen': -13.0625, 'logits/rejected': -12.912500381469727, 'epoch': 2.52}
 84%|████████▍ | 3820/4545 [4:49:15<45:52,  3.80s/it] 84%|████████▍ | 3821/4545 [4:49:19<46:18,  3.84s/it] 84%|████████▍ | 3822/4545 [4:49:22<44:51,  3.72s/it] 84%|████████▍ | 3823/4545 [4:49:26<46:24,  3.86s/it] 84%|████████▍ | 3824/4545 [4:49:30<46:31,  3.87s/it] 84%|████████▍ | 3825/4545 [4:49:34<47:18,  3.94s/it] 84%|████████▍ | 3826/4545 [4:49:38<44:22,  3.70s/it] 84%|████████▍ | 3827/4545 [4:49:42<45:56,  3.84s/it] 84%|████████▍ | 3828/4545 [4:49:45<42:55,  3.59s/it] 84%|████████▍ | 3829/4545 [4:49:49<44:23,  3.72s/it] 84%|████████▍ | 3830/4545 [4:49:53<44:54,  3.77s/it]                                                     {'loss': 0.0067, 'grad_norm': 0.4437345266342163, 'learning_rate': 8.733385300462106e-07, 'rewards/chosen': -5.646874904632568, 'rewards/rejected': -47.974998474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 42.3125, 'logps/chosen': -302.6000061035156, 'logps/rejected': -625.2000122070312, 'logits/chosen': -13.368749618530273, 'logits/rejected': -12.956250190734863, 'epoch': 2.53}
 84%|████████▍ | 3830/4545 [4:49:53<44:54,  3.77s/it] 84%|████████▍ | 3831/4545 [4:49:57<45:23,  3.81s/it] 84%|████████▍ | 3832/4545 [4:49:59<41:08,  3.46s/it] 84%|████████▍ | 3833/4545 [4:50:03<41:31,  3.50s/it] 84%|████████▍ | 3834/4545 [4:50:07<43:25,  3.66s/it] 84%|████████▍ | 3835/4545 [4:50:11<44:16,  3.74s/it] 84%|████████▍ | 3836/4545 [4:50:15<44:48,  3.79s/it] 84%|████████▍ | 3837/4545 [4:50:19<45:06,  3.82s/it] 84%|████████▍ | 3838/4545 [4:50:22<43:49,  3.72s/it] 84%|████████▍ | 3839/4545 [4:50:25<41:40,  3.54s/it] 84%|████████▍ | 3840/4545 [4:50:29<43:26,  3.70s/it]                                                     {'loss': 0.0061, 'grad_norm': 0.8105839490890503, 'learning_rate': 8.608007369603458e-07, 'rewards/chosen': -4.510937690734863, 'rewards/rejected': -36.48749923706055, 'rewards/accuracies': 1.0, 'rewards/margins': 31.975000381469727, 'logps/chosen': -348.25, 'logps/rejected': -561.7999877929688, 'logits/chosen': -13.762499809265137, 'logits/rejected': -13.206250190734863, 'epoch': 2.53}
 84%|████████▍ | 3840/4545 [4:50:29<43:26,  3.70s/it] 85%|████████▍ | 3841/4545 [4:50:33<44:08,  3.76s/it] 85%|████████▍ | 3842/4545 [4:50:37<43:49,  3.74s/it] 85%|████████▍ | 3843/4545 [4:50:41<44:18,  3.79s/it] 85%|████████▍ | 3844/4545 [4:50:45<44:42,  3.83s/it] 85%|████████▍ | 3845/4545 [4:50:48<44:08,  3.78s/it] 85%|████████▍ | 3846/4545 [4:51:18<2:15:25, 11.62s/it] 85%|████████▍ | 3847/4545 [4:51:23<1:49:27,  9.41s/it] 85%|████████▍ | 3848/4545 [4:51:26<1:27:51,  7.56s/it] 85%|████████▍ | 3849/4545 [4:51:30<1:14:36,  6.43s/it] 85%|████████▍ | 3850/4545 [4:51:33<1:05:34,  5.66s/it]                                                       {'loss': 0.0012, 'grad_norm': 0.3911669850349426, 'learning_rate': 8.48406813524213e-07, 'rewards/chosen': -5.48828125, 'rewards/rejected': -35.875, 'rewards/accuracies': 1.0, 'rewards/margins': 30.362499237060547, 'logps/chosen': -297.5, 'logps/rejected': -466.3999938964844, 'logits/chosen': -13.850000381469727, 'logits/rejected': -13.512499809265137, 'epoch': 2.54}
 85%|████████▍ | 3850/4545 [4:51:33<1:05:34,  5.66s/it] 85%|████████▍ | 3851/4545 [4:51:37<59:20,  5.13s/it]   85%|████████▍ | 3852/4545 [4:51:42<55:56,  4.84s/it] 85%|████████▍ | 3853/4545 [4:51:45<51:07,  4.43s/it] 85%|████████▍ | 3854/4545 [4:51:49<49:08,  4.27s/it] 85%|████████▍ | 3855/4545 [4:51:53<47:18,  4.11s/it] 85%|████████▍ | 3856/4545 [4:51:56<44:05,  3.84s/it] 85%|████████▍ | 3857/4545 [4:52:00<44:41,  3.90s/it] 85%|████████▍ | 3858/4545 [4:52:04<45:00,  3.93s/it] 85%|████████▍ | 3859/4545 [4:52:07<43:00,  3.76s/it] 85%|████████▍ | 3860/4545 [4:52:11<43:17,  3.79s/it]                                                     {'loss': 0.0228, 'grad_norm': 0.7829821109771729, 'learning_rate': 8.361580912121291e-07, 'rewards/chosen': -5.753125190734863, 'rewards/rejected': -42.17499923706055, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 36.349998474121094, 'logps/chosen': -310.70001220703125, 'logps/rejected': -574.5999755859375, 'logits/chosen': -13.793749809265137, 'logits/rejected': -13.318750381469727, 'epoch': 2.55}
 85%|████████▍ | 3860/4545 [4:52:11<43:17,  3.79s/it] 85%|████████▍ | 3861/4545 [4:52:15<44:30,  3.90s/it] 85%|████████▍ | 3862/4545 [4:52:44<2:10:30, 11.46s/it] 85%|████████▍ | 3863/4545 [4:53:15<3:14:29, 17.11s/it] 85%|████████▌ | 3864/4545 [4:53:17<2:25:25, 12.81s/it] 85%|████████▌ | 3865/4545 [4:53:21<1:53:09,  9.98s/it] 85%|████████▌ | 3866/4545 [4:53:24<1:28:31,  7.82s/it] 85%|████████▌ | 3867/4545 [4:53:28<1:15:08,  6.65s/it] 85%|████████▌ | 3868/4545 [4:53:31<1:05:42,  5.82s/it] 85%|████████▌ | 3869/4545 [4:53:35<59:07,  5.25s/it]   85%|████████▌ | 3870/4545 [4:53:39<52:06,  4.63s/it]                                                     {'loss': 0.0415, 'grad_norm': 0.08131761103868484, 'learning_rate': 8.240558858995117e-07, 'rewards/chosen': -5.116406440734863, 'rewards/rejected': -32.79999923706055, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 27.681249618530273, 'logps/chosen': -349.20001220703125, 'logps/rejected': -471.6000061035156, 'logits/chosen': -13.8125, 'logits/rejected': -13.512499809265137, 'epoch': 2.55}
 85%|████████▌ | 3870/4545 [4:53:39<52:06,  4.63s/it] 85%|████████▌ | 3871/4545 [4:53:42<47:10,  4.20s/it] 85%|████████▌ | 3872/4545 [4:53:46<46:08,  4.11s/it] 85%|████████▌ | 3873/4545 [4:53:50<46:13,  4.13s/it] 85%|████████▌ | 3874/4545 [4:53:52<41:08,  3.68s/it] 85%|████████▌ | 3875/4545 [4:53:56<41:47,  3.74s/it] 85%|████████▌ | 3876/4545 [4:54:00<42:55,  3.85s/it] 85%|████████▌ | 3877/4545 [4:54:04<43:04,  3.87s/it] 85%|████████▌ | 3878/4545 [4:54:08<43:11,  3.89s/it] 85%|████████▌ | 3879/4545 [4:54:12<42:42,  3.85s/it] 85%|████████▌ | 3880/4545 [4:54:16<43:07,  3.89s/it]                                                     {'loss': 0.032, 'grad_norm': 3.303851366043091, 'learning_rate': 8.121014977215127e-07, 'rewards/chosen': -3.7750000953674316, 'rewards/rejected': -32.98749923706055, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 29.225000381469727, 'logps/chosen': -400.20001220703125, 'logps/rejected': -500.0, 'logits/chosen': -13.675000190734863, 'logits/rejected': -13.3125, 'epoch': 2.56}
 85%|████████▌ | 3880/4545 [4:54:16<43:07,  3.89s/it] 85%|████████▌ | 3881/4545 [4:54:18<36:41,  3.32s/it] 85%|████████▌ | 3882/4545 [4:54:21<36:25,  3.30s/it] 85%|████████▌ | 3883/4545 [4:54:25<37:26,  3.39s/it] 85%|████████▌ | 3884/4545 [4:54:29<39:47,  3.61s/it] 85%|████████▌ | 3885/4545 [4:54:32<37:10,  3.38s/it] 86%|████████▌ | 3886/4545 [4:54:36<38:49,  3.54s/it] 86%|████████▌ | 3887/4545 [4:54:40<39:59,  3.65s/it] 86%|████████▌ | 3888/4545 [4:54:44<40:48,  3.73s/it] 86%|████████▌ | 3889/4545 [4:54:47<41:20,  3.78s/it] 86%|████████▌ | 3890/4545 [4:54:50<38:16,  3.51s/it]                                                     {'loss': 0.0043, 'grad_norm': 0.08120427280664444, 'learning_rate': 8.002962109333507e-07, 'rewards/chosen': -3.4156250953674316, 'rewards/rejected': -40.07500076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 36.712501525878906, 'logps/chosen': -411.45001220703125, 'logps/rejected': -580.0, 'logits/chosen': -13.337499618530273, 'logits/rejected': -13.068750381469727, 'epoch': 2.57}
 86%|████████▌ | 3890/4545 [4:54:50<38:16,  3.51s/it] 86%|████████▌ | 3891/4545 [4:54:54<38:09,  3.50s/it] 86%|████████▌ | 3892/4545 [4:54:56<32:42,  3.01s/it] 86%|████████▌ | 3893/4545 [4:55:00<35:37,  3.28s/it] 86%|████████▌ | 3894/4545 [4:55:02<33:33,  3.09s/it] 86%|████████▌ | 3895/4545 [4:55:06<36:17,  3.35s/it] 86%|████████▌ | 3896/4545 [4:55:09<35:25,  3.28s/it] 86%|████████▌ | 3897/4545 [4:55:13<37:14,  3.45s/it] 86%|████████▌ | 3898/4545 [4:55:17<38:43,  3.59s/it] 86%|████████▌ | 3899/4545 [4:55:21<38:26,  3.57s/it] 86%|████████▌ | 3900/4545 [4:55:25<40:06,  3.73s/it]                                                     {'loss': 0.0133, 'grad_norm': 4.1133198738098145, 'learning_rate': 7.886412937723385e-07, 'rewards/chosen': -4.655077934265137, 'rewards/rejected': -36.88750076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 32.23749923706055, 'logps/chosen': -262.45001220703125, 'logps/rejected': -499.5, 'logits/chosen': -13.90625, 'logits/rejected': -13.443750381469727, 'epoch': 2.57}
 86%|████████▌ | 3900/4545 [4:55:25<40:06,  3.73s/it] 86%|████████▌ | 3901/4545 [4:55:29<40:35,  3.78s/it] 86%|████████▌ | 3902/4545 [4:55:32<38:18,  3.57s/it] 86%|████████▌ | 3903/4545 [4:55:36<39:50,  3.72s/it] 86%|████████▌ | 3904/4545 [4:55:40<40:23,  3.78s/it] 86%|████████▌ | 3905/4545 [4:55:44<41:39,  3.91s/it] 86%|████████▌ | 3906/4545 [4:55:48<41:21,  3.88s/it] 86%|████████▌ | 3907/4545 [4:55:52<41:21,  3.89s/it] 86%|████████▌ | 3908/4545 [4:55:55<40:04,  3.78s/it] 86%|████████▌ | 3909/4545 [4:55:59<39:38,  3.74s/it] 86%|████████▌ | 3910/4545 [4:56:02<38:55,  3.68s/it]                                                     {'loss': 0.0623, 'grad_norm': 7.075848579406738, 'learning_rate': 7.771379983216387e-07, 'rewards/chosen': -4.869140625, 'rewards/rejected': -42.63750076293945, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 37.82500076293945, 'logps/chosen': -312.8999938964844, 'logps/rejected': -579.5999755859375, 'logits/chosen': -13.393750190734863, 'logits/rejected': -13.018750190734863, 'epoch': 2.58}
 86%|████████▌ | 3910/4545 [4:56:02<38:55,  3.68s/it] 86%|████████▌ | 3911/4545 [4:56:06<40:15,  3.81s/it] 86%|████████▌ | 3912/4545 [4:56:10<39:46,  3.77s/it] 86%|████████▌ | 3913/4545 [4:56:14<40:09,  3.81s/it] 86%|████████▌ | 3914/4545 [4:56:18<40:26,  3.85s/it] 86%|████████▌ | 3915/4545 [4:56:21<38:28,  3.66s/it] 86%|████████▌ | 3916/4545 [4:56:25<39:01,  3.72s/it] 86%|████████▌ | 3917/4545 [4:56:29<38:58,  3.72s/it] 86%|████████▌ | 3918/4545 [4:56:32<37:29,  3.59s/it] 86%|████████▌ | 3919/4545 [4:56:36<37:43,  3.62s/it] 86%|████████▌ | 3920/4545 [4:56:40<38:37,  3.71s/it]                                                     {'loss': 0.0234, 'grad_norm': 7.165960311889648, 'learning_rate': 7.657875603757544e-07, 'rewards/chosen': -4.087500095367432, 'rewards/rejected': -39.01250076293945, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 34.875, 'logps/chosen': -347.5, 'logps/rejected': -549.0, 'logits/chosen': -13.118749618530273, 'logits/rejected': -12.824999809265137, 'epoch': 2.59}
 86%|████████▌ | 3920/4545 [4:56:40<38:37,  3.71s/it] 86%|████████▋ | 3921/4545 [4:56:44<39:21,  3.78s/it] 86%|████████▋ | 3922/4545 [4:56:47<37:36,  3.62s/it] 86%|████████▋ | 3923/4545 [4:56:51<38:56,  3.76s/it] 86%|████████▋ | 3924/4545 [4:56:55<39:06,  3.78s/it] 86%|████████▋ | 3925/4545 [4:56:58<37:43,  3.65s/it] 86%|████████▋ | 3926/4545 [4:57:02<39:04,  3.79s/it] 86%|████████▋ | 3927/4545 [4:57:06<39:22,  3.82s/it] 86%|████████▋ | 3928/4545 [4:57:10<39:19,  3.82s/it] 86%|████████▋ | 3929/4545 [4:57:14<39:40,  3.86s/it] 86%|████████▋ | 3930/4545 [4:57:18<39:42,  3.87s/it]                                                     {'loss': 0.0456, 'grad_norm': 0.19934794306755066, 'learning_rate': 7.545911993077672e-07, 'rewards/chosen': -3.7601561546325684, 'rewards/rejected': -40.82500076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 37.09375, 'logps/chosen': -371.1000061035156, 'logps/rejected': -603.0, 'logits/chosen': -12.806249618530273, 'logits/rejected': -12.412500381469727, 'epoch': 2.59}
 86%|████████▋ | 3930/4545 [4:57:18<39:42,  3.87s/it] 86%|████████▋ | 3931/4545 [4:57:21<36:56,  3.61s/it] 87%|████████▋ | 3932/4545 [4:57:25<37:56,  3.71s/it] 87%|████████▋ | 3933/4545 [4:57:28<37:33,  3.68s/it] 87%|████████▋ | 3934/4545 [4:57:32<38:12,  3.75s/it] 87%|████████▋ | 3935/4545 [4:57:36<39:29,  3.88s/it] 87%|████████▋ | 3936/4545 [4:57:40<39:27,  3.89s/it] 87%|████████▋ | 3937/4545 [4:57:44<40:05,  3.96s/it] 87%|████████▋ | 3938/4545 [4:57:48<39:14,  3.88s/it] 87%|████████▋ | 3939/4545 [4:57:52<39:43,  3.93s/it] 87%|████████▋ | 3940/4545 [4:57:56<38:11,  3.79s/it]                                                     {'loss': 0.0099, 'grad_norm': 2.6901755332946777, 'learning_rate': 7.43550117938339e-07, 'rewards/chosen': -4.3193359375, 'rewards/rejected': -35.337501525878906, 'rewards/accuracies': 1.0, 'rewards/margins': 31.012500762939453, 'logps/chosen': -333.0, 'logps/rejected': -504.0, 'logits/chosen': -13.3125, 'logits/rejected': -13.0625, 'epoch': 2.6}
 87%|████████▋ | 3940/4545 [4:57:56<38:11,  3.79s/it] 87%|████████▋ | 3941/4545 [4:58:00<38:31,  3.83s/it] 87%|████████▋ | 3942/4545 [4:58:04<39:18,  3.91s/it] 87%|████████▋ | 3943/4545 [4:58:07<38:29,  3.84s/it] 87%|████████▋ | 3944/4545 [4:58:11<38:41,  3.86s/it] 87%|████████▋ | 3945/4545 [4:58:15<37:55,  3.79s/it] 87%|████████▋ | 3946/4545 [4:58:19<38:29,  3.85s/it] 87%|████████▋ | 3947/4545 [4:58:23<38:57,  3.91s/it] 87%|████████▋ | 3948/4545 [4:58:27<38:39,  3.88s/it] 87%|████████▋ | 3949/4545 [4:58:31<38:41,  3.89s/it] 87%|████████▋ | 3950/4545 [4:58:35<38:44,  3.91s/it]                                                     {'loss': 0.0024, 'grad_norm': 0.14954550564289093, 'learning_rate': 7.326655024064958e-07, 'rewards/chosen': -3.8902344703674316, 'rewards/rejected': -37.375, 'rewards/accuracies': 1.0, 'rewards/margins': 33.462501525878906, 'logps/chosen': -351.20001220703125, 'logps/rejected': -575.2000122070312, 'logits/chosen': -12.975000381469727, 'logits/rejected': -12.662500381469727, 'epoch': 2.61}
 87%|████████▋ | 3950/4545 [4:58:35<38:44,  3.91s/it] 87%|████████▋ | 3951/4545 [4:58:38<38:25,  3.88s/it] 87%|████████▋ | 3952/4545 [4:58:42<38:26,  3.89s/it] 87%|████████▋ | 3953/4545 [4:58:46<38:42,  3.92s/it] 87%|████████▋ | 3954/4545 [4:58:49<35:37,  3.62s/it] 87%|████████▋ | 3955/4545 [4:58:53<36:29,  3.71s/it] 87%|████████▋ | 3956/4545 [4:58:57<35:58,  3.67s/it] 87%|████████▋ | 3957/4545 [4:59:01<37:37,  3.84s/it] 87%|████████▋ | 3958/4545 [4:59:05<37:50,  3.87s/it] 87%|████████▋ | 3959/4545 [4:59:09<38:03,  3.90s/it] 87%|████████▋ | 3960/4545 [4:59:13<38:32,  3.95s/it]                                                     {'loss': 0.0556, 'grad_norm': 0.2621326446533203, 'learning_rate': 7.219385220422006e-07, 'rewards/chosen': -3.545117139816284, 'rewards/rejected': -36.38750076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 32.82500076293945, 'logps/chosen': -352.70001220703125, 'logps/rejected': -533.0, 'logits/chosen': -13.193750381469727, 'logits/rejected': -12.831250190734863, 'epoch': 2.61}
 87%|████████▋ | 3960/4545 [4:59:13<38:32,  3.95s/it] 87%|████████▋ | 3961/4545 [4:59:17<38:24,  3.95s/it] 87%|████████▋ | 3962/4545 [4:59:21<38:37,  3.97s/it] 87%|████████▋ | 3963/4545 [4:59:25<38:32,  3.97s/it] 87%|████████▋ | 3964/4545 [4:59:29<37:32,  3.88s/it] 87%|████████▋ | 3965/4545 [4:59:32<36:11,  3.74s/it] 87%|████████▋ | 3966/4545 [4:59:35<34:43,  3.60s/it] 87%|████████▋ | 3967/4545 [4:59:39<36:19,  3.77s/it] 87%|████████▋ | 3968/4545 [4:59:43<34:58,  3.64s/it] 87%|████████▋ | 3969/4545 [4:59:46<34:28,  3.59s/it] 87%|████████▋ | 3970/4545 [4:59:49<32:55,  3.44s/it]                                                     {'loss': 0.005, 'grad_norm': 0.18563717603683472, 'learning_rate': 7.113703292407311e-07, 'rewards/chosen': -5.60546875, 'rewards/rejected': -44.3125, 'rewards/accuracies': 1.0, 'rewards/margins': 38.70000076293945, 'logps/chosen': -262.20001220703125, 'logps/rejected': -570.5999755859375, 'logits/chosen': -13.3125, 'logits/rejected': -12.800000190734863, 'epoch': 2.62}
 87%|████████▋ | 3970/4545 [4:59:49<32:55,  3.44s/it] 87%|████████▋ | 3971/4545 [4:59:53<34:42,  3.63s/it] 87%|████████▋ | 3972/4545 [4:59:57<33:35,  3.52s/it] 87%|████████▋ | 3973/4545 [5:00:01<34:41,  3.64s/it] 87%|████████▋ | 3974/4545 [5:00:04<34:39,  3.64s/it] 87%|████████▋ | 3975/4545 [5:00:08<36:07,  3.80s/it] 87%|████████▋ | 3976/4545 [5:00:12<36:19,  3.83s/it] 88%|████████▊ | 3977/4545 [5:00:16<36:31,  3.86s/it] 88%|████████▊ | 3978/4545 [5:00:20<36:36,  3.87s/it] 88%|████████▊ | 3979/4545 [5:00:23<34:26,  3.65s/it] 88%|████████▊ | 3980/4545 [5:00:27<35:05,  3.73s/it]                                                     {'loss': 0.033, 'grad_norm': 19.806201934814453, 'learning_rate': 7.009620593388818e-07, 'rewards/chosen': -3.706249952316284, 'rewards/rejected': -32.28125, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 28.606250762939453, 'logps/chosen': -349.20001220703125, 'logps/rejected': -472.0, 'logits/chosen': -13.34375, 'logits/rejected': -13.181249618530273, 'epoch': 2.63}
 88%|████████▊ | 3980/4545 [5:00:27<35:05,  3.73s/it] 88%|████████▊ | 3981/4545 [5:00:31<35:32,  3.78s/it] 88%|████████▊ | 3982/4545 [5:00:35<36:17,  3.87s/it] 88%|████████▊ | 3983/4545 [5:00:39<36:22,  3.88s/it] 88%|████████▊ | 3984/4545 [5:00:42<34:50,  3.73s/it] 88%|████████▊ | 3985/4545 [5:00:46<35:14,  3.78s/it] 88%|████████▊ | 3986/4545 [5:00:50<35:40,  3.83s/it] 88%|████████▊ | 3987/4545 [5:00:54<35:48,  3.85s/it] 88%|████████▊ | 3988/4545 [5:00:58<36:44,  3.96s/it] 88%|████████▊ | 3989/4545 [5:01:03<37:23,  4.03s/it] 88%|████████▊ | 3990/4545 [5:01:05<33:44,  3.65s/it]                                                     {'loss': 0.0272, 'grad_norm': 2.0131499767303467, 'learning_rate': 6.907148304929903e-07, 'rewards/chosen': -4.103125095367432, 'rewards/rejected': -35.13750076293945, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 31.037500381469727, 'logps/chosen': -349.1000061035156, 'logps/rejected': -522.2000122070312, 'logits/chosen': -13.34375, 'logits/rejected': -12.90625, 'epoch': 2.63}
 88%|████████▊ | 3990/4545 [5:01:05<33:44,  3.65s/it] 88%|████████▊ | 3991/4545 [5:01:09<33:50,  3.67s/it] 88%|████████▊ | 3992/4545 [5:01:13<34:32,  3.75s/it] 88%|████████▊ | 3993/4545 [5:01:16<32:05,  3.49s/it] 88%|████████▊ | 3994/4545 [5:01:20<33:29,  3.65s/it] 88%|████████▊ | 3995/4545 [5:01:24<34:10,  3.73s/it] 88%|████████▊ | 3996/4545 [5:01:28<34:35,  3.78s/it] 88%|████████▊ | 3997/4545 [5:01:31<33:25,  3.66s/it] 88%|████████▊ | 3998/4545 [5:01:35<34:10,  3.75s/it] 88%|████████▊ | 3999/4545 [5:01:39<34:27,  3.79s/it] 88%|████████▊ | 4000/4545 [5:01:43<35:30,  3.91s/it]                                                     {'loss': 0.0068, 'grad_norm': 0.08051992207765579, 'learning_rate': 6.806297435588189e-07, 'rewards/chosen': -4.932812690734863, 'rewards/rejected': -41.162498474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 36.275001525878906, 'logps/chosen': -335.6000061035156, 'logps/rejected': -556.5999755859375, 'logits/chosen': -13.524999618530273, 'logits/rejected': -13.018750190734863, 'epoch': 2.64}
 88%|████████▊ | 4000/4545 [5:01:43<35:30,  3.91s/it] 88%|████████▊ | 4001/4545 [5:01:46<33:19,  3.68s/it] 88%|████████▊ | 4002/4545 [5:01:50<33:41,  3.72s/it] 88%|████████▊ | 4003/4545 [5:01:54<34:09,  3.78s/it] 88%|████████▊ | 4004/4545 [5:01:57<32:18,  3.58s/it] 88%|████████▊ | 4005/4545 [5:02:01<33:08,  3.68s/it] 88%|████████▊ | 4006/4545 [5:02:05<34:27,  3.84s/it] 88%|████████▊ | 4007/4545 [5:02:08<32:31,  3.63s/it] 88%|████████▊ | 4008/4545 [5:02:12<33:10,  3.71s/it] 88%|████████▊ | 4009/4545 [5:02:16<33:38,  3.77s/it] 88%|████████▊ | 4010/4545 [5:02:20<34:20,  3.85s/it]                                                     {'loss': 0.0045, 'grad_norm': 8.681901931762695, 'learning_rate': 6.707078819732879e-07, 'rewards/chosen': -3.802734375, 'rewards/rejected': -31.0, 'rewards/accuracies': 1.0, 'rewards/margins': 27.206249237060547, 'logps/chosen': -293.29998779296875, 'logps/rejected': -402.8999938964844, 'logits/chosen': -13.831250190734863, 'logits/rejected': -13.481249809265137, 'epoch': 2.65}
 88%|████████▊ | 4010/4545 [5:02:20<34:20,  3.85s/it] 88%|████████▊ | 4011/4545 [5:02:24<35:10,  3.95s/it] 88%|████████▊ | 4012/4545 [5:02:28<35:02,  3.94s/it] 88%|████████▊ | 4013/4545 [5:02:31<31:10,  3.52s/it] 88%|████████▊ | 4014/4545 [5:02:35<31:43,  3.58s/it] 88%|████████▊ | 4015/4545 [5:02:38<31:21,  3.55s/it] 88%|████████▊ | 4016/4545 [5:02:42<32:00,  3.63s/it] 88%|████████▊ | 4017/4545 [5:02:46<32:54,  3.74s/it] 88%|████████▊ | 4018/4545 [5:02:50<33:14,  3.79s/it] 88%|████████▊ | 4019/4545 [5:02:54<33:57,  3.87s/it] 88%|████████▊ | 4020/4545 [5:02:57<31:37,  3.61s/it]                                                     {'loss': 0.0048, 'grad_norm': 0.2551170289516449, 'learning_rate': 6.609503116380812e-07, 'rewards/chosen': -5.735547065734863, 'rewards/rejected': -45.76250076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 39.95000076293945, 'logps/chosen': -309.29998779296875, 'logps/rejected': -619.7999877929688, 'logits/chosen': -13.118749618530273, 'logits/rejected': -12.65625, 'epoch': 2.65}
 88%|████████▊ | 4020/4545 [5:02:57<31:37,  3.61s/it] 88%|████████▊ | 4021/4545 [5:03:01<32:20,  3.70s/it] 88%|████████▊ | 4022/4545 [5:03:05<32:47,  3.76s/it] 89%|████████▊ | 4023/4545 [5:03:09<33:41,  3.87s/it] 89%|████████▊ | 4024/4545 [5:03:11<30:26,  3.51s/it] 89%|████████▊ | 4025/4545 [5:03:15<31:31,  3.64s/it] 89%|████████▊ | 4026/4545 [5:03:18<29:06,  3.37s/it] 89%|████████▊ | 4027/4545 [5:03:22<29:47,  3.45s/it] 89%|████████▊ | 4028/4545 [5:03:25<28:32,  3.31s/it] 89%|████████▊ | 4029/4545 [5:03:29<30:07,  3.50s/it] 89%|████████▊ | 4030/4545 [5:03:33<31:56,  3.72s/it]                                                     {'loss': 0.0109, 'grad_norm': 0.20723852515220642, 'learning_rate': 6.513580808051402e-07, 'rewards/chosen': -4.707812309265137, 'rewards/rejected': -35.837501525878906, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 31.112499237060547, 'logps/chosen': -339.5, 'logps/rejected': -502.6000061035156, 'logits/chosen': -13.46875, 'logits/rejected': -13.15625, 'epoch': 2.66}
 89%|████████▊ | 4030/4545 [5:03:33<31:56,  3.72s/it] 89%|████████▊ | 4031/4545 [5:03:37<32:25,  3.78s/it] 89%|████████▊ | 4032/4545 [5:03:40<30:46,  3.60s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:45,  1.27it/s][A
  5%|▌         | 3/60 [00:03<01:03,  1.12s/it][A
  7%|▋         | 4/60 [00:04<01:13,  1.32s/it][A
  8%|▊         | 5/60 [00:06<01:17,  1.41s/it][A
 10%|█         | 6/60 [00:08<01:20,  1.49s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.52s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:17,  1.62s/it][A
 22%|██▏       | 13/60 [00:19<01:15,  1.62s/it][A
 23%|██▎       | 14/60 [00:21<01:13,  1.60s/it][A
 25%|██▌       | 15/60 [00:22<01:07,  1.51s/it][A
 27%|██▋       | 16/60 [00:23<01:00,  1.37s/it][A
 28%|██▊       | 17/60 [00:24<00:55,  1.28s/it][A
 30%|███       | 18/60 [00:25<00:45,  1.08s/it][A
 32%|███▏      | 19/60 [00:26<00:46,  1.14s/it][A
 33%|███▎      | 20/60 [00:27<00:39,  1.00it/s][A
 35%|███▌      | 21/60 [00:28<00:38,  1.00it/s][A
 37%|███▋      | 22/60 [00:29<00:41,  1.09s/it][A
 38%|███▊      | 23/60 [00:30<00:40,  1.10s/it][A
 40%|████      | 24/60 [00:31<00:38,  1.07s/it][A
 42%|████▏     | 25/60 [00:33<00:43,  1.24s/it][A
 43%|████▎     | 26/60 [00:34<00:44,  1.30s/it][A
 45%|████▌     | 27/60 [00:35<00:37,  1.14s/it][A
 47%|████▋     | 28/60 [00:36<00:34,  1.08s/it][A
 48%|████▊     | 29/60 [00:37<00:34,  1.12s/it][A
 50%|█████     | 30/60 [00:39<00:38,  1.28s/it][A
 52%|█████▏    | 31/60 [00:40<00:39,  1.36s/it][A
 53%|█████▎    | 32/60 [00:42<00:38,  1.39s/it][A
 55%|█████▌    | 33/60 [00:43<00:36,  1.37s/it][A
 57%|█████▋    | 34/60 [00:44<00:31,  1.20s/it][A
 58%|█████▊    | 35/60 [00:45<00:31,  1.27s/it][A
 60%|██████    | 36/60 [00:47<00:31,  1.32s/it][A
 62%|██████▏   | 37/60 [00:47<00:25,  1.10s/it][A
 63%|██████▎   | 38/60 [00:49<00:27,  1.24s/it][A
 65%|██████▌   | 39/60 [00:50<00:25,  1.21s/it][A
 67%|██████▋   | 40/60 [00:51<00:21,  1.09s/it][A
 68%|██████▊   | 41/60 [00:52<00:22,  1.20s/it][A
 70%|███████   | 42/60 [00:54<00:23,  1.31s/it][A
 72%|███████▏  | 43/60 [00:55<00:20,  1.21s/it][A
 73%|███████▎  | 44/60 [00:56<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [00:57<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [00:59<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:00<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:01<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:03<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:04<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:06<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:07<00:11,  1.41s/it][A
 88%|████████▊ | 53/60 [01:08<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [01:10<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [01:11<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [01:12<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [01:14<00:04,  1.38s/it][A
 97%|█████████▋| 58/60 [01:15<00:02,  1.37s/it][A
 98%|█████████▊| 59/60 [01:17<00:01,  1.44s/it][A
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.5168884992599487, 'eval_runtime': 80.3629, 'eval_samples_per_second': 11.859, 'eval_steps_per_second': 0.747, 'eval_rewards/chosen': -5.278873920440674, 'eval_rewards/rejected': -35.63020706176758, 'eval_rewards/accuracies': 0.8582175970077515, 'eval_rewards/margins': 30.31848907470703, 'eval_logps/chosen': -430.54998779296875, 'eval_logps/rejected': -507.7166748046875, 'eval_logits/chosen': -13.053125381469727, 'eval_logits/rejected': -12.942708015441895, 'epoch': 2.66}
 89%|████████▊ | 4032/4545 [5:05:00<30:46,  3.60s/it]
100%|██████████| 60/60 [01:18<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 89%|████████▊ | 4033/4545 [5:05:16<4:27:27, 31.34s/it] 89%|████████▉ | 4034/4545 [5:05:20<3:16:54, 23.12s/it] 89%|████████▉ | 4035/4545 [5:05:24<2:26:48, 17.27s/it] 89%|████████▉ | 4036/4545 [5:05:27<1:51:28, 13.14s/it] 89%|████████▉ | 4037/4545 [5:05:31<1:27:46, 10.37s/it] 89%|████████▉ | 4038/4545 [5:05:34<1:09:22,  8.21s/it] 89%|████████▉ | 4039/4545 [5:05:38<58:19,  6.92s/it]   89%|████████▉ | 4040/4545 [5:05:42<50:35,  6.01s/it]                                                     {'loss': 0.0413, 'grad_norm': 0.18099108338356018, 'learning_rate': 6.419322199640478e-07, 'rewards/chosen': -4.734570503234863, 'rewards/rejected': -36.42499923706055, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 31.725000381469727, 'logps/chosen': -286.70001220703125, 'logps/rejected': -470.0, 'logits/chosen': -13.737500190734863, 'logits/rejected': -13.306249618530273, 'epoch': 2.67}
 89%|████████▉ | 4040/4545 [5:05:42<50:35,  6.01s/it] 89%|████████▉ | 4041/4545 [5:05:46<45:13,  5.38s/it] 89%|████████▉ | 4042/4545 [5:05:50<40:47,  4.87s/it] 89%|████████▉ | 4043/4545 [5:05:52<34:25,  4.11s/it] 89%|████████▉ | 4044/4545 [5:05:56<34:19,  4.11s/it] 89%|████████▉ | 4045/4545 [5:06:00<33:45,  4.05s/it] 89%|████████▉ | 4046/4545 [5:06:04<33:08,  3.98s/it] 89%|████████▉ | 4047/4545 [5:06:08<32:50,  3.96s/it] 89%|████████▉ | 4048/4545 [5:06:11<32:23,  3.91s/it] 89%|████████▉ | 4049/4545 [5:06:14<29:33,  3.57s/it] 89%|████████▉ | 4050/4545 [5:06:18<30:01,  3.64s/it]                                                     {'loss': 0.0114, 'grad_norm': 9.855957984924316, 'learning_rate': 6.32673741731324e-07, 'rewards/chosen': -4.714941501617432, 'rewards/rejected': -31.8125, 'rewards/accuracies': 1.0, 'rewards/margins': 27.087499618530273, 'logps/chosen': -294.6000061035156, 'logps/rejected': -474.0, 'logits/chosen': -13.737500190734863, 'logits/rejected': -13.381250381469727, 'epoch': 2.67}
 89%|████████▉ | 4050/4545 [5:06:18<30:01,  3.64s/it] 89%|████████▉ | 4051/4545 [5:06:22<30:40,  3.72s/it] 89%|████████▉ | 4052/4545 [5:06:25<29:24,  3.58s/it] 89%|████████▉ | 4053/4545 [5:06:29<30:32,  3.72s/it] 89%|████████▉ | 4054/4545 [5:06:34<31:41,  3.87s/it] 89%|████████▉ | 4055/4545 [5:06:37<31:43,  3.89s/it] 89%|████████▉ | 4056/4545 [5:06:41<31:44,  3.89s/it] 89%|████████▉ | 4057/4545 [5:06:45<31:42,  3.90s/it] 89%|████████▉ | 4058/4545 [5:06:48<30:02,  3.70s/it] 89%|████████▉ | 4059/4545 [5:06:52<29:22,  3.63s/it] 89%|████████▉ | 4060/4545 [5:06:56<29:58,  3.71s/it]                                                     {'loss': 0.0126, 'grad_norm': 9.46056842803955, 'learning_rate': 6.23583640741642e-07, 'rewards/chosen': -3.073437452316284, 'rewards/rejected': -39.38750076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 36.275001525878906, 'logps/chosen': -418.5, 'logps/rejected': -555.5999755859375, 'logits/chosen': -13.443750381469727, 'logits/rejected': -13.112500190734863, 'epoch': 2.68}
 89%|████████▉ | 4060/4545 [5:06:56<29:58,  3.71s/it] 89%|████████▉ | 4061/4545 [5:07:00<30:38,  3.80s/it] 89%|████████▉ | 4062/4545 [5:07:04<30:50,  3.83s/it] 89%|████████▉ | 4063/4545 [5:07:06<27:18,  3.40s/it] 89%|████████▉ | 4064/4545 [5:07:10<28:46,  3.59s/it] 89%|████████▉ | 4065/4545 [5:07:14<29:29,  3.69s/it] 89%|████████▉ | 4066/4545 [5:07:18<30:25,  3.81s/it] 89%|████████▉ | 4067/4545 [5:07:21<28:10,  3.54s/it] 90%|████████▉ | 4068/4545 [5:07:25<28:59,  3.65s/it] 90%|████████▉ | 4069/4545 [5:07:27<25:06,  3.16s/it] 90%|████████▉ | 4070/4545 [5:07:31<26:48,  3.39s/it]                                                     {'loss': 0.0055, 'grad_norm': 8.739282608032227, 'learning_rate': 6.146628935409722e-07, 'rewards/chosen': -4.300000190734863, 'rewards/rejected': -34.099998474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 29.806249618530273, 'logps/chosen': -317.0, 'logps/rejected': -473.8999938964844, 'logits/chosen': -13.818750381469727, 'logits/rejected': -13.418749809265137, 'epoch': 2.69}
 90%|████████▉ | 4070/4545 [5:07:31<26:48,  3.39s/it] 90%|████████▉ | 4071/4545 [5:07:35<27:59,  3.54s/it] 90%|████████▉ | 4072/4545 [5:07:39<28:53,  3.66s/it] 90%|████████▉ | 4073/4545 [5:07:42<27:52,  3.54s/it] 90%|████████▉ | 4074/4545 [5:07:46<28:42,  3.66s/it] 90%|████████▉ | 4075/4545 [5:07:50<29:15,  3.73s/it] 90%|████████▉ | 4076/4545 [5:07:54<30:03,  3.85s/it] 90%|████████▉ | 4077/4545 [5:07:58<30:35,  3.92s/it] 90%|████████▉ | 4078/4545 [5:08:01<27:39,  3.55s/it] 90%|████████▉ | 4079/4545 [5:08:05<28:26,  3.66s/it] 90%|████████▉ | 4080/4545 [5:08:08<28:18,  3.65s/it]                                                     {'loss': 0.0135, 'grad_norm': 4.130095958709717, 'learning_rate': 6.059124584816761e-07, 'rewards/chosen': -2.5296874046325684, 'rewards/rejected': -34.618751525878906, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 32.03125, 'logps/chosen': -433.70001220703125, 'logps/rejected': -520.4000244140625, 'logits/chosen': -13.21875, 'logits/rejected': -12.800000190734863, 'epoch': 2.69}
 90%|████████▉ | 4080/4545 [5:08:08<28:18,  3.65s/it] 90%|████████▉ | 4081/4545 [5:08:12<29:17,  3.79s/it] 90%|████████▉ | 4082/4545 [5:08:16<29:20,  3.80s/it] 90%|████████▉ | 4083/4545 [5:08:46<1:28:15, 11.46s/it] 90%|████████▉ | 4084/4545 [5:08:48<1:08:12,  8.88s/it] 90%|████████▉ | 4085/4545 [5:08:52<56:38,  7.39s/it]   90%|████████▉ | 4086/4545 [5:08:56<47:59,  6.27s/it] 90%|████████▉ | 4087/4545 [5:09:00<42:29,  5.57s/it] 90%|████████▉ | 4088/4545 [5:09:04<38:35,  5.07s/it] 90%|████████▉ | 4089/4545 [5:09:08<35:53,  4.72s/it] 90%|████████▉ | 4090/4545 [5:09:11<33:16,  4.39s/it]                                                     {'loss': 0.0085, 'grad_norm': 0.33045968413352966, 'learning_rate': 5.973332756195482e-07, 'rewards/chosen': -2.853710889816284, 'rewards/rejected': -41.26874923706055, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 38.36249923706055, 'logps/chosen': -400.1000061035156, 'logps/rejected': -594.0, 'logits/chosen': -13.4375, 'logits/rejected': -13.137499809265137, 'epoch': 2.7}
 90%|████████▉ | 4090/4545 [5:09:11<33:16,  4.39s/it] 90%|█████████ | 4091/4545 [5:09:15<31:48,  4.20s/it] 90%|█████████ | 4092/4545 [5:09:19<31:05,  4.12s/it] 90%|█████████ | 4093/4545 [5:09:23<30:37,  4.06s/it] 90%|█████████ | 4094/4545 [5:09:27<29:19,  3.90s/it] 90%|█████████ | 4095/4545 [5:09:30<29:18,  3.91s/it] 90%|█████████ | 4096/4545 [5:09:33<27:15,  3.64s/it] 90%|█████████ | 4097/4545 [5:09:37<27:48,  3.73s/it] 90%|█████████ | 4098/4545 [5:09:41<26:24,  3.55s/it] 90%|█████████ | 4099/4545 [5:09:44<27:07,  3.65s/it] 90%|█████████ | 4100/4545 [5:09:49<28:02,  3.78s/it]                                                     {'loss': 0.1412, 'grad_norm': 6.063177585601807, 'learning_rate': 5.889262666128258e-07, 'rewards/chosen': -3.3578124046325684, 'rewards/rejected': -35.26250076293945, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 31.9375, 'logps/chosen': -420.20001220703125, 'logps/rejected': -519.7999877929688, 'logits/chosen': -13.412500381469727, 'logits/rejected': -13.237500190734863, 'epoch': 2.71}
 90%|█████████ | 4100/4545 [5:09:49<28:02,  3.78s/it] 90%|█████████ | 4101/4545 [5:09:52<28:18,  3.83s/it] 90%|█████████ | 4102/4545 [5:09:56<28:29,  3.86s/it] 90%|█████████ | 4103/4545 [5:10:00<28:26,  3.86s/it] 90%|█████████ | 4104/4545 [5:10:04<28:31,  3.88s/it] 90%|█████████ | 4105/4545 [5:10:08<28:54,  3.94s/it] 90%|█████████ | 4106/4545 [5:10:12<29:29,  4.03s/it] 90%|█████████ | 4107/4545 [5:10:16<29:09,  3.99s/it] 90%|█████████ | 4108/4545 [5:10:20<29:15,  4.02s/it] 90%|█████████ | 4109/4545 [5:10:25<29:14,  4.02s/it] 90%|█████████ | 4110/4545 [5:10:28<28:57,  3.99s/it]                                                     {'loss': 0.0321, 'grad_norm': 37.37809753417969, 'learning_rate': 5.806923346231776e-07, 'rewards/chosen': -4.473437309265137, 'rewards/rejected': -42.150001525878906, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 37.70000076293945, 'logps/chosen': -354.79998779296875, 'logps/rejected': -581.4000244140625, 'logits/chosen': -13.493749618530273, 'logits/rejected': -13.100000381469727, 'epoch': 2.71}
 90%|█████████ | 4110/4545 [5:10:28<28:57,  3.99s/it] 90%|█████████ | 4111/4545 [5:10:32<28:43,  3.97s/it] 90%|█████████ | 4112/4545 [5:10:36<28:18,  3.92s/it] 90%|█████████ | 4113/4545 [5:10:40<28:35,  3.97s/it] 91%|█████████ | 4114/4545 [5:10:44<27:50,  3.88s/it] 91%|█████████ | 4115/4545 [5:10:47<26:38,  3.72s/it] 91%|█████████ | 4116/4545 [5:10:50<25:34,  3.58s/it] 91%|█████████ | 4117/4545 [5:10:54<26:13,  3.68s/it] 91%|█████████ | 4118/4545 [5:10:58<26:37,  3.74s/it] 91%|█████████ | 4119/4545 [5:11:02<26:24,  3.72s/it] 91%|█████████ | 4120/4545 [5:11:06<26:43,  3.77s/it]                                                     {'loss': 0.0109, 'grad_norm': 22.673044204711914, 'learning_rate': 5.726323642186777e-07, 'rewards/chosen': -4.471093654632568, 'rewards/rejected': -35.368751525878906, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 30.84375, 'logps/chosen': -265.1000061035156, 'logps/rejected': -465.6000061035156, 'logits/chosen': -13.725000381469727, 'logits/rejected': -13.287500381469727, 'epoch': 2.72}
 91%|█████████ | 4120/4545 [5:11:06<26:43,  3.77s/it] 91%|█████████ | 4121/4545 [5:11:10<26:57,  3.81s/it] 91%|█████████ | 4122/4545 [5:11:14<27:37,  3.92s/it] 91%|█████████ | 4123/4545 [5:11:17<26:28,  3.76s/it] 91%|█████████ | 4124/4545 [5:11:21<26:47,  3.82s/it] 91%|█████████ | 4125/4545 [5:11:25<26:20,  3.76s/it] 91%|█████████ | 4126/4545 [5:11:29<26:35,  3.81s/it] 91%|█████████ | 4127/4545 [5:11:32<26:10,  3.76s/it] 91%|█████████ | 4128/4545 [5:11:36<26:32,  3.82s/it] 91%|█████████ | 4129/4545 [5:11:40<26:40,  3.85s/it] 91%|█████████ | 4130/4545 [5:11:44<26:50,  3.88s/it]                                                     {'loss': 0.0046, 'grad_norm': 0.6754171252250671, 'learning_rate': 5.647472212787733e-07, 'rewards/chosen': -4.967187404632568, 'rewards/rejected': -51.474998474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 46.5625, 'logps/chosen': -338.79998779296875, 'logps/rejected': -644.7999877929688, 'logits/chosen': -13.231249809265137, 'logits/rejected': -12.806249618530273, 'epoch': 2.73}
 91%|█████████ | 4130/4545 [5:11:44<26:50,  3.88s/it] 91%|█████████ | 4131/4545 [5:11:48<27:24,  3.97s/it] 91%|█████████ | 4132/4545 [5:11:53<27:45,  4.03s/it] 91%|█████████ | 4133/4545 [5:11:57<27:52,  4.06s/it] 91%|█████████ | 4134/4545 [5:12:00<25:38,  3.74s/it] 91%|█████████ | 4135/4545 [5:12:04<25:40,  3.76s/it] 91%|█████████ | 4136/4545 [5:12:07<25:38,  3.76s/it] 91%|█████████ | 4137/4545 [5:12:10<22:33,  3.32s/it] 91%|█████████ | 4138/4545 [5:12:14<24:17,  3.58s/it] 91%|█████████ | 4139/4545 [5:12:18<24:58,  3.69s/it] 91%|█████████ | 4140/4545 [5:12:21<24:04,  3.57s/it]                                                     {'loss': 0.0107, 'grad_norm': 1.165702223777771, 'learning_rate': 5.570377529012669e-07, 'rewards/chosen': -5.774218559265137, 'rewards/rejected': -44.875, 'rewards/accuracies': 1.0, 'rewards/margins': 39.099998474121094, 'logps/chosen': -201.10000610351562, 'logps/rejected': -533.5999755859375, 'logits/chosen': -13.899999618530273, 'logits/rejected': -13.362500190734863, 'epoch': 2.73}
 91%|█████████ | 4140/4545 [5:12:21<24:04,  3.57s/it] 91%|█████████ | 4141/4545 [5:12:24<22:49,  3.39s/it] 91%|█████████ | 4142/4545 [5:12:28<23:48,  3.54s/it] 91%|█████████ | 4143/4545 [5:12:31<22:21,  3.34s/it] 91%|█████████ | 4144/4545 [5:12:34<22:53,  3.43s/it] 91%|█████████ | 4145/4545 [5:12:38<23:45,  3.56s/it] 91%|█████████ | 4146/4545 [5:12:43<25:00,  3.76s/it] 91%|█████████ | 4147/4545 [5:12:46<23:33,  3.55s/it] 91%|█████████▏| 4148/4545 [5:12:50<24:44,  3.74s/it] 91%|█████████▏| 4149/4545 [5:12:53<22:56,  3.48s/it] 91%|█████████▏| 4150/4545 [5:12:57<24:16,  3.69s/it]                                                     {'loss': 0.0099, 'grad_norm': 0.06233019754290581, 'learning_rate': 5.495047873113128e-07, 'rewards/chosen': -4.551171779632568, 'rewards/rejected': -43.837501525878906, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 39.275001525878906, 'logps/chosen': -344.8999938964844, 'logps/rejected': -557.2000122070312, 'logits/chosen': -13.175000190734863, 'logits/rejected': -12.693750381469727, 'epoch': 2.74}
 91%|█████████▏| 4150/4545 [5:12:57<24:16,  3.69s/it] 91%|█████████▏| 4151/4545 [5:13:01<24:38,  3.75s/it] 91%|█████████▏| 4152/4545 [5:13:05<25:25,  3.88s/it] 91%|█████████▏| 4153/4545 [5:13:09<25:24,  3.89s/it] 91%|█████████▏| 4154/4545 [5:13:12<24:54,  3.82s/it] 91%|█████████▏| 4155/4545 [5:13:15<21:56,  3.37s/it] 91%|█████████▏| 4156/4545 [5:13:19<23:25,  3.61s/it] 91%|█████████▏| 4157/4545 [5:13:23<23:57,  3.70s/it] 91%|█████████▏| 4158/4545 [5:13:27<24:18,  3.77s/it] 92%|█████████▏| 4159/4545 [5:13:30<23:12,  3.61s/it] 92%|█████████▏| 4160/4545 [5:13:34<23:44,  3.70s/it]                                                     {'loss': 0.0018, 'grad_norm': 0.17443080246448517, 'learning_rate': 5.421491337724384e-07, 'rewards/chosen': -3.373828172683716, 'rewards/rejected': -35.625, 'rewards/accuracies': 1.0, 'rewards/margins': 32.256248474121094, 'logps/chosen': -314.75, 'logps/rejected': -545.0, 'logits/chosen': -13.706250190734863, 'logits/rejected': -13.287500381469727, 'epoch': 2.75}
 92%|█████████▏| 4160/4545 [5:13:34<23:44,  3.70s/it] 92%|█████████▏| 4161/4545 [5:13:37<22:42,  3.55s/it] 92%|█████████▏| 4162/4545 [5:13:40<20:47,  3.26s/it] 92%|█████████▏| 4163/4545 [5:13:44<22:04,  3.47s/it] 92%|█████████▏| 4164/4545 [5:13:48<23:00,  3.62s/it] 92%|█████████▏| 4165/4545 [5:13:52<23:30,  3.71s/it] 92%|█████████▏| 4166/4545 [5:13:56<23:49,  3.77s/it] 92%|█████████▏| 4167/4545 [5:13:59<23:03,  3.66s/it] 92%|█████████▏| 4168/4545 [5:14:03<23:28,  3.74s/it] 92%|█████████▏| 4169/4545 [5:14:06<23:02,  3.68s/it] 92%|█████████▏| 4170/4545 [5:14:10<23:20,  3.73s/it]                                                     {'loss': 0.0116, 'grad_norm': 6.797069072723389, 'learning_rate': 5.349715824996085e-07, 'rewards/chosen': -4.909375190734863, 'rewards/rejected': -34.82500076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 29.912500381469727, 'logps/chosen': -305.6000061035156, 'logps/rejected': -511.3999938964844, 'logits/chosen': -13.518750190734863, 'logits/rejected': -13.143750190734863, 'epoch': 2.75}
 92%|█████████▏| 4170/4545 [5:14:10<23:20,  3.73s/it] 92%|█████████▏| 4171/4545 [5:14:14<23:07,  3.71s/it] 92%|█████████▏| 4172/4545 [5:14:18<23:30,  3.78s/it] 92%|█████████▏| 4173/4545 [5:14:21<21:23,  3.45s/it] 92%|█████████▏| 4174/4545 [5:14:24<22:10,  3.59s/it] 92%|█████████▏| 4175/4545 [5:14:28<21:33,  3.50s/it] 92%|█████████▏| 4176/4545 [5:14:32<22:21,  3.63s/it] 92%|█████████▏| 4177/4545 [5:14:35<21:30,  3.51s/it] 92%|█████████▏| 4178/4545 [5:14:39<21:54,  3.58s/it] 92%|█████████▏| 4179/4545 [5:14:41<20:06,  3.30s/it] 92%|█████████▏| 4180/4545 [5:14:44<19:53,  3.27s/it]                                                     {'loss': 0.0186, 'grad_norm': 16.92045021057129, 'learning_rate': 5.279729045743318e-07, 'rewards/chosen': -3.8857421875, 'rewards/rejected': -40.650001525878906, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 36.73749923706055, 'logps/chosen': -346.6000061035156, 'logps/rejected': -550.7999877929688, 'logits/chosen': -13.600000381469727, 'logits/rejected': -13.350000381469727, 'epoch': 2.76}
 92%|█████████▏| 4180/4545 [5:14:44<19:53,  3.27s/it] 92%|█████████▏| 4181/4545 [5:14:48<19:53,  3.28s/it] 92%|█████████▏| 4182/4545 [5:14:52<21:03,  3.48s/it] 92%|█████████▏| 4183/4545 [5:14:56<21:46,  3.61s/it] 92%|█████████▏| 4184/4545 [5:15:00<22:13,  3.70s/it] 92%|█████████▏| 4185/4545 [5:15:03<22:29,  3.75s/it] 92%|█████████▏| 4186/4545 [5:15:07<22:42,  3.80s/it] 92%|█████████▏| 4187/4545 [5:15:12<23:24,  3.92s/it] 92%|█████████▏| 4188/4545 [5:15:15<23:20,  3.92s/it] 92%|█████████▏| 4189/4545 [5:15:19<23:13,  3.92s/it] 92%|█████████▏| 4190/4545 [5:15:23<22:41,  3.84s/it]                                                     {'loss': 0.0066, 'grad_norm': 2.054652214050293, 'learning_rate': 5.211538518618226e-07, 'rewards/chosen': -2.8265624046325684, 'rewards/rejected': -36.3125, 'rewards/accuracies': 1.0, 'rewards/margins': 33.48125076293945, 'logps/chosen': -442.0, 'logps/rejected': -612.4000244140625, 'logits/chosen': -13.149999618530273, 'logits/rejected': -12.831250190734863, 'epoch': 2.77}
 92%|█████████▏| 4190/4545 [5:15:23<22:41,  3.84s/it] 92%|█████████▏| 4191/4545 [5:15:26<22:02,  3.74s/it] 92%|█████████▏| 4192/4545 [5:15:29<20:22,  3.46s/it] 92%|█████████▏| 4193/4545 [5:15:33<20:18,  3.46s/it] 92%|█████████▏| 4194/4545 [5:15:36<20:34,  3.52s/it] 92%|█████████▏| 4195/4545 [5:15:40<21:12,  3.64s/it] 92%|█████████▏| 4196/4545 [5:15:44<21:13,  3.65s/it] 92%|█████████▏| 4197/4545 [5:15:48<21:37,  3.73s/it] 92%|█████████▏| 4198/4545 [5:15:51<20:13,  3.50s/it] 92%|█████████▏| 4199/4545 [5:15:55<20:53,  3.62s/it] 92%|█████████▏| 4200/4545 [5:15:59<21:14,  3.69s/it]                                                     {'loss': 0.0057, 'grad_norm': 0.1766340136528015, 'learning_rate': 5.145151569302306e-07, 'rewards/chosen': -5.353906154632568, 'rewards/rejected': -43.32500076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 37.95000076293945, 'logps/chosen': -299.1000061035156, 'logps/rejected': -540.5999755859375, 'logits/chosen': -13.537500381469727, 'logits/rejected': -13.100000381469727, 'epoch': 2.77}
 92%|█████████▏| 4200/4545 [5:15:59<21:14,  3.69s/it] 92%|█████████▏| 4201/4545 [5:16:02<21:20,  3.72s/it] 92%|█████████▏| 4202/4545 [5:16:06<21:41,  3.80s/it] 92%|█████████▏| 4203/4545 [5:16:10<21:51,  3.83s/it] 92%|█████████▏| 4204/4545 [5:16:14<21:31,  3.79s/it] 93%|█████████▎| 4205/4545 [5:16:18<21:40,  3.82s/it] 93%|█████████▎| 4206/4545 [5:16:22<21:45,  3.85s/it] 93%|█████████▎| 4207/4545 [5:16:26<21:36,  3.84s/it] 93%|█████████▎| 4208/4545 [5:16:30<21:46,  3.88s/it] 93%|█████████▎| 4209/4545 [5:16:34<21:45,  3.89s/it] 93%|█████████▎| 4210/4545 [5:16:37<21:24,  3.83s/it]                                                     {'loss': 0.0114, 'grad_norm': 8.929421424865723, 'learning_rate': 5.080575329719386e-07, 'rewards/chosen': -2.375781297683716, 'rewards/rejected': -29.024999618530273, 'rewards/accuracies': 1.0, 'rewards/margins': 26.637500762939453, 'logps/chosen': -458.70001220703125, 'logps/rejected': -501.79998779296875, 'logits/chosen': -13.081250190734863, 'logits/rejected': -12.981249809265137, 'epoch': 2.78}
 93%|█████████▎| 4210/4545 [5:16:37<21:24,  3.83s/it] 93%|█████████▎| 4211/4545 [5:16:41<21:36,  3.88s/it] 93%|█████████▎| 4212/4545 [5:16:45<20:57,  3.78s/it] 93%|█████████▎| 4213/4545 [5:16:48<20:49,  3.76s/it] 93%|█████████▎| 4214/4545 [5:16:52<19:34,  3.55s/it] 93%|█████████▎| 4215/4545 [5:16:55<20:10,  3.67s/it] 93%|█████████▎| 4216/4545 [5:16:59<19:47,  3.61s/it] 93%|█████████▎| 4217/4545 [5:17:03<20:08,  3.68s/it] 93%|█████████▎| 4218/4545 [5:17:06<19:43,  3.62s/it] 93%|█████████▎| 4219/4545 [5:17:09<18:26,  3.40s/it] 93%|█████████▎| 4220/4545 [5:17:13<19:14,  3.55s/it]                                                     {'loss': 0.0045, 'grad_norm': 0.9024231433868408, 'learning_rate': 5.017816737269471e-07, 'rewards/chosen': -6.053857326507568, 'rewards/rejected': -39.724998474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 33.712501525878906, 'logps/chosen': -247.3000030517578, 'logps/rejected': -502.20001220703125, 'logits/chosen': -13.831250190734863, 'logits/rejected': -13.362500190734863, 'epoch': 2.79}
 93%|█████████▎| 4220/4545 [5:17:13<19:14,  3.55s/it] 93%|█████████▎| 4221/4545 [5:17:17<19:48,  3.67s/it] 93%|█████████▎| 4222/4545 [5:17:21<20:28,  3.80s/it] 93%|█████████▎| 4223/4545 [5:17:25<20:38,  3.85s/it] 93%|█████████▎| 4224/4545 [5:17:29<20:38,  3.86s/it] 93%|█████████▎| 4225/4545 [5:17:33<20:39,  3.87s/it] 93%|█████████▎| 4226/4545 [5:17:37<20:39,  3.89s/it] 93%|█████████▎| 4227/4545 [5:17:40<20:15,  3.82s/it] 93%|█████████▎| 4228/4545 [5:17:44<20:22,  3.85s/it] 93%|█████████▎| 4229/4545 [5:17:48<20:23,  3.87s/it] 93%|█████████▎| 4230/4545 [5:17:52<19:32,  3.72s/it]                                                     {'loss': 0.0498, 'grad_norm': 40.67195510864258, 'learning_rate': 4.956882534083451e-07, 'rewards/chosen': -5.239843845367432, 'rewards/rejected': -39.13750076293945, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 33.912498474121094, 'logps/chosen': -291.8999938964844, 'logps/rejected': -512.2000122070312, 'logits/chosen': -13.899999618530273, 'logits/rejected': -13.625, 'epoch': 2.79}
 93%|█████████▎| 4230/4545 [5:17:52<19:32,  3.72s/it] 93%|█████████▎| 4231/4545 [5:17:56<19:48,  3.79s/it] 93%|█████████▎| 4232/4545 [5:18:00<20:09,  3.86s/it] 93%|█████████▎| 4233/4545 [5:18:04<20:08,  3.87s/it] 93%|█████████▎| 4234/4545 [5:18:08<20:33,  3.97s/it] 93%|█████████▎| 4235/4545 [5:18:12<20:28,  3.96s/it] 93%|█████████▎| 4236/4545 [5:18:16<20:20,  3.95s/it] 93%|█████████▎| 4237/4545 [5:18:19<19:30,  3.80s/it] 93%|█████████▎| 4238/4545 [5:18:23<19:45,  3.86s/it] 93%|█████████▎| 4239/4545 [5:18:26<17:56,  3.52s/it] 93%|█████████▎| 4240/4545 [5:18:30<18:54,  3.72s/it]                                                     {'loss': 0.0127, 'grad_norm': 0.08194762468338013, 'learning_rate': 4.897779266298784e-07, 'rewards/chosen': -4.641015529632568, 'rewards/rejected': -37.36249923706055, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 32.73749923706055, 'logps/chosen': -335.70001220703125, 'logps/rejected': -544.7999877929688, 'logits/chosen': -13.587499618530273, 'logits/rejected': -13.243749618530273, 'epoch': 2.8}
 93%|█████████▎| 4240/4545 [5:18:30<18:54,  3.72s/it] 93%|█████████▎| 4241/4545 [5:18:34<18:46,  3.70s/it] 93%|█████████▎| 4242/4545 [5:18:37<18:33,  3.67s/it] 93%|█████████▎| 4243/4545 [5:19:07<57:12, 11.37s/it] 93%|█████████▎| 4244/4545 [5:19:10<45:48,  9.13s/it] 93%|█████████▎| 4245/4545 [5:19:15<38:09,  7.63s/it] 93%|█████████▎| 4246/4545 [5:19:19<32:27,  6.51s/it] 93%|█████████▎| 4247/4545 [5:19:22<28:29,  5.74s/it] 93%|█████████▎| 4248/4545 [5:19:26<25:16,  5.11s/it] 93%|█████████▎| 4249/4545 [5:19:30<23:43,  4.81s/it] 94%|█████████▎| 4250/4545 [5:19:34<22:20,  4.54s/it]                                                     {'loss': 0.0011, 'grad_norm': 0.7591127753257751, 'learning_rate': 4.840513283356272e-07, 'rewards/chosen': -1.64453125, 'rewards/rejected': -38.20000076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 36.525001525878906, 'logps/chosen': -522.5, 'logps/rejected': -604.2000122070312, 'logits/chosen': -13.225000381469727, 'logits/rejected': -12.975000381469727, 'epoch': 2.81}
 94%|█████████▎| 4250/4545 [5:19:34<22:20,  4.54s/it] 94%|█████████▎| 4251/4545 [5:19:38<21:39,  4.42s/it] 94%|█████████▎| 4252/4545 [5:19:42<20:50,  4.27s/it] 94%|█████████▎| 4253/4545 [5:19:46<20:15,  4.16s/it] 94%|█████████▎| 4254/4545 [5:19:50<20:09,  4.16s/it] 94%|█████████▎| 4255/4545 [5:19:54<19:21,  4.01s/it] 94%|█████████▎| 4256/4545 [5:19:58<19:10,  3.98s/it] 94%|█████████▎| 4257/4545 [5:20:01<18:28,  3.85s/it] 94%|█████████▎| 4258/4545 [5:20:05<18:24,  3.85s/it] 94%|█████████▎| 4259/4545 [5:20:09<18:25,  3.87s/it] 94%|█████████▎| 4260/4545 [5:20:12<16:27,  3.47s/it]                                                     {'loss': 0.0262, 'grad_norm': 9.56350040435791, 'learning_rate': 4.785090737317916e-07, 'rewards/chosen': -4.683642387390137, 'rewards/rejected': -34.224998474121094, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 29.524999618530273, 'logps/chosen': -349.6499938964844, 'logps/rejected': -508.3999938964844, 'logits/chosen': -13.818750381469727, 'logits/rejected': -13.487500190734863, 'epoch': 2.81}
 94%|█████████▎| 4260/4545 [5:20:12<16:27,  3.47s/it] 94%|█████████▍| 4261/4545 [5:20:16<17:46,  3.75s/it] 94%|█████████▍| 4262/4545 [5:20:20<17:55,  3.80s/it] 94%|█████████▍| 4263/4545 [5:20:23<17:22,  3.70s/it] 94%|█████████▍| 4264/4545 [5:20:27<17:38,  3.77s/it] 94%|█████████▍| 4265/4545 [5:20:31<16:52,  3.62s/it] 94%|█████████▍| 4266/4545 [5:20:35<17:41,  3.80s/it] 94%|█████████▍| 4267/4545 [5:20:39<17:48,  3.84s/it] 94%|█████████▍| 4268/4545 [5:20:43<17:51,  3.87s/it] 94%|█████████▍| 4269/4545 [5:20:46<17:18,  3.76s/it] 94%|█████████▍| 4270/4545 [5:20:50<17:54,  3.91s/it]                                                     {'loss': 0.0178, 'grad_norm': 0.4223365783691406, 'learning_rate': 4.7315175822060295e-07, 'rewards/chosen': -3.8187499046325684, 'rewards/rejected': -31.950000762939453, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 28.1875, 'logps/chosen': -376.20001220703125, 'logps/rejected': -519.5999755859375, 'logits/chosen': -13.53125, 'logits/rejected': -13.106249809265137, 'epoch': 2.82}
 94%|█████████▍| 4270/4545 [5:20:51<17:54,  3.91s/it] 94%|█████████▍| 4271/4545 [5:20:54<17:53,  3.92s/it] 94%|█████████▍| 4272/4545 [5:20:57<16:13,  3.57s/it] 94%|█████████▍| 4273/4545 [5:21:01<15:53,  3.51s/it] 94%|█████████▍| 4274/4545 [5:21:04<15:24,  3.41s/it] 94%|█████████▍| 4275/4545 [5:21:08<16:02,  3.57s/it] 94%|█████████▍| 4276/4545 [5:21:11<16:07,  3.60s/it] 94%|█████████▍| 4277/4545 [5:21:13<13:46,  3.08s/it] 94%|█████████▍| 4278/4545 [5:21:17<14:50,  3.33s/it] 94%|█████████▍| 4279/4545 [5:21:20<14:41,  3.32s/it] 94%|█████████▍| 4280/4545 [5:21:24<15:30,  3.51s/it]                                                     {'loss': 0.0384, 'grad_norm': 0.023201242089271545, 'learning_rate': 4.679799573363577e-07, 'rewards/chosen': -4.846875190734863, 'rewards/rejected': -36.337501525878906, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 31.5, 'logps/chosen': -290.79998779296875, 'logps/rejected': -486.6000061035156, 'logits/chosen': -14.131250381469727, 'logits/rejected': -13.756250381469727, 'epoch': 2.83}
 94%|█████████▍| 4280/4545 [5:21:24<15:30,  3.51s/it] 94%|█████████▍| 4281/4545 [5:21:28<16:12,  3.68s/it] 94%|█████████▍| 4282/4545 [5:21:32<16:32,  3.77s/it] 94%|█████████▍| 4283/4545 [5:21:36<16:40,  3.82s/it] 94%|█████████▍| 4284/4545 [5:21:40<15:49,  3.64s/it] 94%|█████████▍| 4285/4545 [5:21:43<16:08,  3.72s/it] 94%|█████████▍| 4286/4545 [5:21:47<15:34,  3.61s/it] 94%|█████████▍| 4287/4545 [5:21:50<14:56,  3.47s/it] 94%|█████████▍| 4288/4545 [5:21:54<15:27,  3.61s/it] 94%|█████████▍| 4289/4545 [5:21:58<15:53,  3.72s/it] 94%|█████████▍| 4290/4545 [5:22:02<16:16,  3.83s/it]                                                     {'loss': 0.0072, 'grad_norm': 2.271813154220581, 'learning_rate': 4.629942266835897e-07, 'rewards/chosen': -5.446093559265137, 'rewards/rejected': -44.01250076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 38.525001525878906, 'logps/chosen': -332.3999938964844, 'logps/rejected': -571.2000122070312, 'logits/chosen': -13.75, 'logits/rejected': -13.318750381469727, 'epoch': 2.83}
 94%|█████████▍| 4290/4545 [5:22:02<16:16,  3.83s/it] 94%|█████████▍| 4291/4545 [5:22:06<16:23,  3.87s/it] 94%|█████████▍| 4292/4545 [5:22:09<15:32,  3.69s/it] 94%|█████████▍| 4293/4545 [5:22:13<15:50,  3.77s/it] 94%|█████████▍| 4294/4545 [5:22:17<15:25,  3.69s/it] 94%|█████████▍| 4295/4545 [5:22:21<15:41,  3.77s/it] 95%|█████████▍| 4296/4545 [5:22:23<14:13,  3.43s/it] 95%|█████████▍| 4297/4545 [5:22:27<14:58,  3.62s/it] 95%|█████████▍| 4298/4545 [5:22:31<15:16,  3.71s/it] 95%|█████████▍| 4299/4545 [5:22:35<15:13,  3.71s/it] 95%|█████████▍| 4300/4545 [5:22:39<15:43,  3.85s/it]                                                     {'loss': 0.0106, 'grad_norm': 18.808977127075195, 'learning_rate': 4.5819510187737984e-07, 'rewards/chosen': -6.8359375, 'rewards/rejected': -39.724998474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 32.912498474121094, 'logps/chosen': -281.29998779296875, 'logps/rejected': -518.7999877929688, 'logits/chosen': -13.512499809265137, 'logits/rejected': -13.331250190734863, 'epoch': 2.84}
 95%|█████████▍| 4300/4545 [5:22:39<15:43,  3.85s/it] 95%|█████████▍| 4301/4545 [5:22:43<15:50,  3.90s/it] 95%|█████████▍| 4302/4545 [5:22:47<15:48,  3.90s/it] 95%|█████████▍| 4303/4545 [5:22:51<15:45,  3.91s/it] 95%|█████████▍| 4304/4545 [5:22:55<15:49,  3.94s/it] 95%|█████████▍| 4305/4545 [5:22:59<15:40,  3.92s/it] 95%|█████████▍| 4306/4545 [5:23:03<15:38,  3.93s/it] 95%|█████████▍| 4307/4545 [5:23:07<15:33,  3.92s/it] 95%|█████████▍| 4308/4545 [5:23:09<13:41,  3.46s/it] 95%|█████████▍| 4309/4545 [5:23:13<14:21,  3.65s/it] 95%|█████████▍| 4310/4545 [5:23:17<13:56,  3.56s/it]                                                     {'loss': 0.0172, 'grad_norm': 0.08355634659528732, 'learning_rate': 4.53583098485818e-07, 'rewards/chosen': -3.348828077316284, 'rewards/rejected': -35.29375076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 31.9375, 'logps/chosen': -436.29998779296875, 'logps/rejected': -532.4000244140625, 'logits/chosen': -13.131250381469727, 'logits/rejected': -12.787500381469727, 'epoch': 2.84}
 95%|█████████▍| 4310/4545 [5:23:17<13:56,  3.56s/it] 95%|█████████▍| 4311/4545 [5:23:21<14:42,  3.77s/it] 95%|█████████▍| 4312/4545 [5:23:23<12:58,  3.34s/it] 95%|█████████▍| 4313/4545 [5:23:27<13:35,  3.52s/it] 95%|█████████▍| 4314/4545 [5:23:31<14:17,  3.71s/it] 95%|█████████▍| 4315/4545 [5:23:35<14:33,  3.80s/it] 95%|█████████▍| 4316/4545 [5:23:39<13:54,  3.64s/it] 95%|█████████▍| 4317/4545 [5:23:42<14:10,  3.73s/it] 95%|█████████▌| 4318/4545 [5:23:46<14:01,  3.71s/it] 95%|█████████▌| 4319/4545 [5:23:50<14:11,  3.77s/it] 95%|█████████▌| 4320/4545 [5:23:52<12:36,  3.36s/it]                                                     {'loss': 0.0274, 'grad_norm': 8.789987564086914, 'learning_rate': 4.4915871197461296e-07, 'rewards/chosen': -2.4710936546325684, 'rewards/rejected': -28.15625, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 25.693750381469727, 'logps/chosen': -389.5, 'logps/rejected': -501.29998779296875, 'logits/chosen': -13.625, 'logits/rejected': -13.262499809265137, 'epoch': 2.85}
 95%|█████████▌| 4320/4545 [5:23:53<12:36,  3.36s/it] 95%|█████████▌| 4321/4545 [5:23:56<13:20,  3.57s/it] 95%|█████████▌| 4322/4545 [5:24:00<13:45,  3.70s/it] 95%|█████████▌| 4323/4545 [5:24:04<13:55,  3.76s/it] 95%|█████████▌| 4324/4545 [5:24:09<14:21,  3.90s/it] 95%|█████████▌| 4325/4545 [5:24:12<13:36,  3.71s/it] 95%|█████████▌| 4326/4545 [5:24:15<13:09,  3.60s/it] 95%|█████████▌| 4327/4545 [5:24:19<13:16,  3.65s/it] 95%|█████████▌| 4328/4545 [5:24:23<13:33,  3.75s/it] 95%|█████████▌| 4329/4545 [5:24:27<13:39,  3.79s/it] 95%|█████████▌| 4330/4545 [5:24:31<13:42,  3.83s/it]                                                     {'loss': 0.0381, 'grad_norm': 0.6476737856864929, 'learning_rate': 4.4492241765386584e-07, 'rewards/chosen': -4.85107421875, 'rewards/rejected': -37.92499923706055, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 33.07500076293945, 'logps/chosen': -289.3999938964844, 'logps/rejected': -532.4000244140625, 'logits/chosen': -13.737500190734863, 'logits/rejected': -13.243749618530273, 'epoch': 2.86}
 95%|█████████▌| 4330/4545 [5:24:31<13:42,  3.83s/it] 95%|█████████▌| 4331/4545 [5:24:33<12:17,  3.45s/it] 95%|█████████▌| 4332/4545 [5:24:37<12:57,  3.65s/it] 95%|█████████▌| 4333/4545 [5:24:41<13:11,  3.73s/it] 95%|█████████▌| 4334/4545 [5:24:44<11:44,  3.34s/it] 95%|█████████▌| 4335/4545 [5:24:48<12:06,  3.46s/it] 95%|█████████▌| 4336/4545 [5:24:52<12:39,  3.63s/it] 95%|█████████▌| 4337/4545 [5:24:56<12:55,  3.73s/it] 95%|█████████▌| 4338/4545 [5:24:59<12:05,  3.50s/it] 95%|█████████▌| 4339/4545 [5:25:02<11:33,  3.37s/it] 95%|█████████▌| 4340/4545 [5:25:05<12:05,  3.54s/it]                                                     {'loss': 0.0235, 'grad_norm': 6.069897651672363, 'learning_rate': 4.4087467062700873e-07, 'rewards/chosen': -4.053906440734863, 'rewards/rejected': -34.75, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 30.662500381469727, 'logps/chosen': -374.29998779296875, 'logps/rejected': -529.0, 'logits/chosen': -13.681249618530273, 'logits/rejected': -13.199999809265137, 'epoch': 2.86}
 95%|█████████▌| 4340/4545 [5:25:06<12:05,  3.54s/it] 96%|█████████▌| 4341/4545 [5:25:09<12:21,  3.64s/it] 96%|█████████▌| 4342/4545 [5:25:13<12:39,  3.74s/it] 96%|█████████▌| 4343/4545 [5:25:17<12:13,  3.63s/it] 96%|█████████▌| 4344/4545 [5:25:21<12:28,  3.72s/it] 96%|█████████▌| 4345/4545 [5:25:24<12:25,  3.73s/it] 96%|█████████▌| 4346/4545 [5:25:28<12:33,  3.78s/it] 96%|█████████▌| 4347/4545 [5:25:32<12:44,  3.86s/it] 96%|█████████▌| 4348/4545 [5:25:36<12:45,  3.89s/it] 96%|█████████▌| 4349/4545 [5:25:40<12:43,  3.90s/it] 96%|█████████▌| 4350/4545 [5:25:44<12:42,  3.91s/it]                                                     {'loss': 0.0098, 'grad_norm': 1.4957290887832642, 'learning_rate': 4.370159057419114e-07, 'rewards/chosen': -3.219921827316284, 'rewards/rejected': -45.76250076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 42.5, 'logps/chosen': -368.20001220703125, 'logps/rejected': -618.5999755859375, 'logits/chosen': -13.693750381469727, 'logits/rejected': -13.243749618530273, 'epoch': 2.87}
 96%|█████████▌| 4350/4545 [5:25:44<12:42,  3.91s/it] 96%|█████████▌| 4351/4545 [5:26:14<37:40, 11.65s/it] 96%|█████████▌| 4352/4545 [5:26:17<29:08,  9.06s/it] 96%|█████████▌| 4353/4545 [5:26:21<24:03,  7.52s/it] 96%|█████████▌| 4354/4545 [5:26:25<20:40,  6.50s/it] 96%|█████████▌| 4355/4545 [5:26:27<16:45,  5.29s/it] 96%|█████████▌| 4356/4545 [5:26:30<14:25,  4.58s/it] 96%|█████████▌| 4357/4545 [5:26:34<13:20,  4.26s/it] 96%|█████████▌| 4358/4545 [5:26:37<12:27,  4.00s/it] 96%|█████████▌| 4359/4545 [5:26:41<12:00,  3.87s/it] 96%|█████████▌| 4360/4545 [5:26:45<11:59,  3.89s/it]                                                     {'loss': 0.028, 'grad_norm': 0.3536299765110016, 'learning_rate': 4.333465375441664e-07, 'rewards/chosen': -4.974218845367432, 'rewards/rejected': -31.787500381469727, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 26.850000381469727, 'logps/chosen': -266.25, 'logps/rejected': -478.1000061035156, 'logits/chosen': -14.0, 'logits/rejected': -13.600000381469727, 'epoch': 2.88}
 96%|█████████▌| 4360/4545 [5:26:45<11:59,  3.89s/it] 96%|█████████▌| 4361/4545 [5:26:49<11:59,  3.91s/it] 96%|█████████▌| 4362/4545 [5:26:53<11:55,  3.91s/it] 96%|█████████▌| 4363/4545 [5:26:55<10:41,  3.52s/it] 96%|█████████▌| 4364/4545 [5:26:59<10:51,  3.60s/it] 96%|█████████▌| 4365/4545 [5:27:03<11:08,  3.71s/it] 96%|█████████▌| 4366/4545 [5:27:07<11:06,  3.72s/it] 96%|█████████▌| 4367/4545 [5:27:11<11:14,  3.79s/it] 96%|█████████▌| 4368/4545 [5:27:15<11:18,  3.83s/it] 96%|█████████▌| 4369/4545 [5:27:18<10:31,  3.59s/it] 96%|█████████▌| 4370/4545 [5:27:22<10:44,  3.69s/it]                                                     {'loss': 0.0685, 'grad_norm': 0.05852237343788147, 'learning_rate': 4.298669602325555e-07, 'rewards/chosen': -3.9476561546325684, 'rewards/rejected': -30.512500762939453, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 26.587499618530273, 'logps/chosen': -331.79998779296875, 'logps/rejected': -447.20001220703125, 'logits/chosen': -13.612500190734863, 'logits/rejected': -13.40625, 'epoch': 2.88}
 96%|█████████▌| 4370/4545 [5:27:22<10:44,  3.69s/it] 96%|█████████▌| 4371/4545 [5:27:26<10:56,  3.77s/it] 96%|█████████▌| 4372/4545 [5:27:29<10:48,  3.75s/it] 96%|█████████▌| 4373/4545 [5:27:33<11:07,  3.88s/it] 96%|█████████▌| 4374/4545 [5:27:37<10:58,  3.85s/it] 96%|█████████▋| 4375/4545 [5:27:41<10:56,  3.86s/it] 96%|█████████▋| 4376/4545 [5:27:45<10:40,  3.79s/it] 96%|█████████▋| 4377/4545 [5:27:49<10:51,  3.88s/it] 96%|█████████▋| 4378/4545 [5:27:53<10:50,  3.90s/it] 96%|█████████▋| 4379/4545 [5:27:57<10:47,  3.90s/it] 96%|█████████▋| 4380/4545 [5:27:59<09:40,  3.52s/it]                                                     {'loss': 0.0026, 'grad_norm': 0.6652799844741821, 'learning_rate': 4.265775476166992e-07, 'rewards/chosen': -3.8218750953674316, 'rewards/rejected': -35.86249923706055, 'rewards/accuracies': 1.0, 'rewards/margins': 32.01250076293945, 'logps/chosen': -363.29998779296875, 'logps/rejected': -541.5999755859375, 'logits/chosen': -13.462499618530273, 'logits/rejected': -13.118749618530273, 'epoch': 2.89}
 96%|█████████▋| 4380/4545 [5:27:59<09:40,  3.52s/it] 96%|█████████▋| 4381/4545 [5:28:03<09:44,  3.56s/it] 96%|█████████▋| 4382/4545 [5:28:07<09:58,  3.67s/it] 96%|█████████▋| 4383/4545 [5:28:11<10:07,  3.75s/it] 96%|█████████▋| 4384/4545 [5:28:15<10:27,  3.90s/it] 96%|█████████▋| 4385/4545 [5:28:48<33:23, 12.52s/it] 97%|█████████▋| 4386/4545 [5:28:55<29:22, 11.09s/it] 97%|█████████▋| 4387/4545 [5:29:03<26:26, 10.04s/it] 97%|█████████▋| 4388/4545 [5:29:10<24:13,  9.26s/it] 97%|█████████▋| 4389/4545 [5:29:15<20:05,  7.73s/it] 97%|█████████▋| 4390/4545 [5:29:19<17:01,  6.59s/it]                                                     {'loss': 0.0034, 'grad_norm': 0.2705550491809845, 'learning_rate': 4.2347865307690065e-07, 'rewards/chosen': -1.0070312023162842, 'rewards/rejected': -31.049999237060547, 'rewards/accuracies': 1.0, 'rewards/margins': 30.024999618530273, 'logps/chosen': -426.1000061035156, 'logps/rejected': -486.6000061035156, 'logits/chosen': -13.743749618530273, 'logits/rejected': -13.456250190734863, 'epoch': 2.9}
 97%|█████████▋| 4390/4545 [5:29:19<17:01,  6.59s/it] 97%|█████████▋| 4391/4545 [5:29:21<14:07,  5.50s/it] 97%|█████████▋| 4392/4545 [5:29:25<12:37,  4.95s/it] 97%|█████████▋| 4393/4545 [5:29:29<11:49,  4.67s/it] 97%|█████████▋| 4394/4545 [5:29:33<11:13,  4.46s/it] 97%|█████████▋| 4395/4545 [5:29:36<10:02,  4.02s/it] 97%|█████████▋| 4396/4545 [5:29:40<10:08,  4.09s/it] 97%|█████████▋| 4397/4545 [5:29:44<09:57,  4.03s/it] 97%|█████████▋| 4398/4545 [5:29:48<09:25,  3.84s/it] 97%|█████████▋| 4399/4545 [5:29:52<09:22,  3.85s/it] 97%|█████████▋| 4400/4545 [5:29:55<09:17,  3.84s/it]                                                     {'loss': 0.0069, 'grad_norm': 3.4216368198394775, 'learning_rate': 4.205706095261804e-07, 'rewards/chosen': -4.8515625, 'rewards/rejected': -36.32500076293945, 'rewards/accuracies': 1.0, 'rewards/margins': 31.475000381469727, 'logps/chosen': -290.95001220703125, 'logps/rejected': -488.3999938964844, 'logits/chosen': -13.774999618530273, 'logits/rejected': -13.443750381469727, 'epoch': 2.9}
 97%|█████████▋| 4400/4545 [5:29:55<09:17,  3.84s/it] 97%|█████████▋| 4401/4545 [5:29:59<09:13,  3.85s/it] 97%|█████████▋| 4402/4545 [5:30:03<09:17,  3.90s/it] 97%|█████████▋| 4403/4545 [5:30:07<09:24,  3.97s/it] 97%|█████████▋| 4404/4545 [5:30:10<08:28,  3.61s/it] 97%|█████████▋| 4405/4545 [5:30:14<08:35,  3.68s/it] 97%|█████████▋| 4406/4545 [5:30:18<08:41,  3.75s/it] 97%|█████████▋| 4407/4545 [5:30:22<08:40,  3.77s/it] 97%|█████████▋| 4408/4545 [5:30:26<08:42,  3.82s/it] 97%|█████████▋| 4409/4545 [5:30:30<08:43,  3.85s/it] 97%|█████████▋| 4410/4545 [5:30:34<08:55,  3.96s/it]                                                     {'loss': 0.011, 'grad_norm': 0.17923994362354279, 'learning_rate': 4.1785372937451204e-07, 'rewards/chosen': -4.417382717132568, 'rewards/rejected': -38.01250076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 33.587501525878906, 'logps/chosen': -355.79998779296875, 'logps/rejected': -519.4000244140625, 'logits/chosen': -13.556249618530273, 'logits/rejected': -13.3125, 'epoch': 2.91}
 97%|█████████▋| 4410/4545 [5:30:34<08:55,  3.96s/it] 97%|█████████▋| 4411/4545 [5:30:37<08:34,  3.84s/it] 97%|█████████▋| 4412/4545 [5:30:40<07:48,  3.52s/it] 97%|█████████▋| 4413/4545 [5:30:43<07:24,  3.37s/it] 97%|█████████▋| 4414/4545 [5:30:47<07:44,  3.55s/it] 97%|█████████▋| 4415/4545 [5:30:51<07:57,  3.67s/it] 97%|█████████▋| 4416/4545 [5:30:54<07:33,  3.52s/it] 97%|█████████▋| 4417/4545 [5:30:58<07:36,  3.56s/it] 97%|█████████▋| 4418/4545 [5:31:02<07:46,  3.67s/it] 97%|█████████▋| 4419/4545 [5:31:06<07:54,  3.76s/it] 97%|█████████▋| 4420/4545 [5:31:10<07:57,  3.82s/it]                                                     {'loss': 0.0054, 'grad_norm': 0.11593713611364365, 'learning_rate': 4.153283044952617e-07, 'rewards/chosen': -3.902783155441284, 'rewards/rejected': -39.787498474121094, 'rewards/accuracies': 1.0, 'rewards/margins': 35.875, 'logps/chosen': -329.5, 'logps/rejected': -514.2000122070312, 'logits/chosen': -13.662500381469727, 'logits/rejected': -13.318750381469727, 'epoch': 2.92}
 97%|█████████▋| 4420/4545 [5:31:10<07:57,  3.82s/it] 97%|█████████▋| 4421/4545 [5:31:14<08:09,  3.95s/it] 97%|█████████▋| 4422/4545 [5:31:18<08:04,  3.94s/it] 97%|█████████▋| 4423/4545 [5:31:21<07:13,  3.55s/it] 97%|█████████▋| 4424/4545 [5:31:24<07:23,  3.67s/it] 97%|█████████▋| 4425/4545 [5:31:28<07:30,  3.75s/it] 97%|█████████▋| 4426/4545 [5:31:32<07:32,  3.80s/it] 97%|█████████▋| 4427/4545 [5:31:36<07:32,  3.83s/it] 97%|█████████▋| 4428/4545 [5:31:39<06:54,  3.54s/it] 97%|█████████▋| 4429/4545 [5:31:43<07:14,  3.75s/it] 97%|█████████▋| 4430/4545 [5:31:47<07:12,  3.76s/it]                                                     {'loss': 0.0715, 'grad_norm': 66.6124267578125, 'learning_rate': 4.1299460619382975e-07, 'rewards/chosen': -3.666796922683716, 'rewards/rejected': -40.83124923706055, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 37.212501525878906, 'logps/chosen': -424.6000061035156, 'logps/rejected': -626.2000122070312, 'logits/chosen': -13.018750190734863, 'logits/rejected': -12.787500381469727, 'epoch': 2.92}
 97%|█████████▋| 4430/4545 [5:31:47<07:12,  3.76s/it] 97%|█████████▋| 4431/4545 [5:31:51<07:15,  3.82s/it] 98%|█████████▊| 4432/4545 [5:31:55<07:13,  3.84s/it] 98%|█████████▊| 4433/4545 [5:31:59<07:14,  3.88s/it] 98%|█████████▊| 4434/4545 [5:32:03<07:12,  3.90s/it] 98%|█████████▊| 4435/4545 [5:32:07<07:10,  3.91s/it] 98%|█████████▊| 4436/4545 [5:32:11<07:07,  3.92s/it] 98%|█████████▊| 4437/4545 [5:32:15<07:08,  3.96s/it] 98%|█████████▊| 4438/4545 [5:32:19<07:09,  4.01s/it] 98%|█████████▊| 4439/4545 [5:32:23<07:03,  3.99s/it] 98%|█████████▊| 4440/4545 [5:32:27<07:06,  4.06s/it]                                                     {'loss': 0.0512, 'grad_norm': 17.888813018798828, 'learning_rate': 4.1085288517850625e-07, 'rewards/chosen': -2.1724610328674316, 'rewards/rejected': -35.025001525878906, 'rewards/accuracies': 0.981249988079071, 'rewards/margins': 32.849998474121094, 'logps/chosen': -451.8999938964844, 'logps/rejected': -620.4000244140625, 'logits/chosen': -13.287500381469727, 'logits/rejected': -13.024999618530273, 'epoch': 2.93}
 98%|█████████▊| 4440/4545 [5:32:27<07:06,  4.06s/it] 98%|█████████▊| 4441/4545 [5:32:31<06:52,  3.97s/it] 98%|█████████▊| 4442/4545 [5:32:35<06:43,  3.92s/it] 98%|█████████▊| 4443/4545 [5:32:38<06:28,  3.81s/it] 98%|█████████▊| 4444/4545 [5:32:42<06:35,  3.92s/it] 98%|█████████▊| 4445/4545 [5:32:46<06:31,  3.91s/it] 98%|█████████▊| 4446/4545 [5:32:50<06:30,  3.94s/it] 98%|█████████▊| 4447/4545 [5:32:53<05:48,  3.56s/it] 98%|█████████▊| 4448/4545 [5:32:57<05:56,  3.67s/it] 98%|█████████▊| 4449/4545 [5:33:00<05:42,  3.57s/it] 98%|█████████▊| 4450/4545 [5:33:04<05:49,  3.68s/it]                                                     {'loss': 0.0117, 'grad_norm': 1.1238504648208618, 'learning_rate': 4.089033715335369e-07, 'rewards/chosen': -5.46875, 'rewards/rejected': -39.212501525878906, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 33.70000076293945, 'logps/chosen': -292.8999938964844, 'logps/rejected': -513.4000244140625, 'logits/chosen': -13.931249618530273, 'logits/rejected': -13.574999809265137, 'epoch': 2.94}
 98%|█████████▊| 4450/4545 [5:33:04<05:49,  3.68s/it] 98%|█████████▊| 4451/4545 [5:33:08<06:01,  3.85s/it] 98%|█████████▊| 4452/4545 [5:33:11<05:31,  3.57s/it] 98%|█████████▊| 4453/4545 [5:33:15<05:37,  3.67s/it] 98%|█████████▊| 4454/4545 [5:33:19<05:41,  3.75s/it] 98%|█████████▊| 4455/4545 [5:33:23<05:41,  3.80s/it] 98%|█████████▊| 4456/4545 [5:33:27<05:41,  3.84s/it] 98%|█████████▊| 4457/4545 [5:33:30<05:27,  3.72s/it] 98%|█████████▊| 4458/4545 [5:33:35<05:37,  3.88s/it] 98%|█████████▊| 4459/4545 [5:33:39<05:34,  3.89s/it] 98%|█████████▊| 4460/4545 [5:33:43<05:31,  3.90s/it]                                                     {'loss': 0.0677, 'grad_norm': 24.958728790283203, 'learning_rate': 4.0714627469440526e-07, 'rewards/chosen': -2.500903367996216, 'rewards/rejected': -29.75, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 27.225000381469727, 'logps/chosen': -380.1000061035156, 'logps/rejected': -504.5, 'logits/chosen': -13.662500381469727, 'logits/rejected': -13.34375, 'epoch': 2.94}
 98%|█████████▊| 4460/4545 [5:33:43<05:31,  3.90s/it] 98%|█████████▊| 4461/4545 [5:33:47<05:28,  3.92s/it] 98%|█████████▊| 4462/4545 [5:33:50<05:25,  3.92s/it] 98%|█████████▊| 4463/4545 [5:33:55<05:28,  4.01s/it] 98%|█████████▊| 4464/4545 [5:33:58<05:08,  3.81s/it] 98%|█████████▊| 4465/4545 [5:34:02<04:57,  3.72s/it] 98%|█████████▊| 4466/4545 [5:34:05<04:55,  3.74s/it] 98%|█████████▊| 4467/4545 [5:34:09<04:48,  3.70s/it] 98%|█████████▊| 4468/4545 [5:34:13<04:53,  3.81s/it] 98%|█████████▊| 4469/4545 [5:34:17<04:52,  3.84s/it] 98%|█████████▊| 4470/4545 [5:34:21<04:50,  3.87s/it]                                                     {'loss': 0.0025, 'grad_norm': 4.136773586273193, 'learning_rate': 4.055817834253334e-07, 'rewards/chosen': -4.293749809265137, 'rewards/rejected': -47.04999923706055, 'rewards/accuracies': 1.0, 'rewards/margins': 42.78125, 'logps/chosen': -400.79998779296875, 'logps/rejected': -633.5999755859375, 'logits/chosen': -13.506250381469727, 'logits/rejected': -13.21875, 'epoch': 2.95}
 98%|█████████▊| 4470/4545 [5:34:21<04:50,  3.87s/it] 98%|█████████▊| 4471/4545 [5:34:25<04:48,  3.90s/it] 98%|█████████▊| 4472/4545 [5:34:29<04:45,  3.91s/it] 98%|█████████▊| 4473/4545 [5:34:32<04:25,  3.69s/it] 98%|█████████▊| 4474/4545 [5:34:36<04:26,  3.76s/it] 98%|█████████▊| 4475/4545 [5:34:40<04:26,  3.81s/it] 98%|█████████▊| 4476/4545 [5:34:43<04:02,  3.51s/it] 99%|█████████▊| 4477/4545 [5:34:45<03:46,  3.33s/it] 99%|█████████▊| 4478/4545 [5:34:49<03:52,  3.47s/it] 99%|█████████▊| 4479/4545 [5:34:53<03:59,  3.64s/it] 99%|█████████▊| 4480/4545 [5:34:56<03:43,  3.43s/it]                                                     {'loss': 0.0732, 'grad_norm': 19.751428604125977, 'learning_rate': 4.042100657990022e-07, 'rewards/chosen': -4.654687404632568, 'rewards/rejected': -33.900001525878906, 'rewards/accuracies': 0.9750000238418579, 'rewards/margins': 29.243749618530273, 'logps/chosen': -332.20001220703125, 'logps/rejected': -532.5, 'logits/chosen': -13.512499809265137, 'logits/rejected': -13.125, 'epoch': 2.96}
 99%|█████████▊| 4480/4545 [5:34:56<03:43,  3.43s/it] 99%|█████████▊| 4481/4545 [5:35:00<03:50,  3.60s/it] 99%|█████████▊| 4482/4545 [5:35:04<03:53,  3.70s/it] 99%|█████████▊| 4483/4545 [5:35:08<03:54,  3.78s/it] 99%|█████████▊| 4484/4545 [5:35:12<03:53,  3.82s/it] 99%|█████████▊| 4485/4545 [5:35:16<03:51,  3.86s/it] 99%|█████████▊| 4486/4545 [5:35:20<03:51,  3.92s/it] 99%|█████████▊| 4487/4545 [5:35:23<03:36,  3.74s/it] 99%|█████████▊| 4488/4545 [5:35:28<03:41,  3.88s/it] 99%|█████████▉| 4489/4545 [5:35:31<03:28,  3.72s/it] 99%|█████████▉| 4490/4545 [5:35:35<03:31,  3.84s/it]                                                     {'loss': 0.0209, 'grad_norm': 0.6231156587600708, 'learning_rate': 4.0303126917849655e-07, 'rewards/chosen': -4.330078125, 'rewards/rejected': -39.26250076293945, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 34.912498474121094, 'logps/chosen': -378.70001220703125, 'logps/rejected': -551.0, 'logits/chosen': -13.462499618530273, 'logits/rejected': -12.949999809265137, 'epoch': 2.96}
 99%|█████████▉| 4490/4545 [5:35:35<03:31,  3.84s/it] 99%|█████████▉| 4491/4545 [5:35:39<03:28,  3.86s/it] 99%|█████████▉| 4492/4545 [5:35:42<03:07,  3.54s/it] 99%|█████████▉| 4493/4545 [5:35:45<03:06,  3.59s/it] 99%|█████████▉| 4494/4545 [5:35:48<02:51,  3.37s/it] 99%|█████████▉| 4495/4545 [5:35:52<02:57,  3.55s/it] 99%|█████████▉| 4496/4545 [5:35:56<02:54,  3.56s/it] 99%|█████████▉| 4497/4545 [5:36:00<02:56,  3.67s/it] 99%|█████████▉| 4498/4545 [5:36:04<02:57,  3.77s/it] 99%|█████████▉| 4499/4545 [5:36:08<02:55,  3.82s/it] 99%|█████████▉| 4500/4545 [5:36:11<02:43,  3.64s/it]                                                     {'loss': 0.0375, 'grad_norm': 0.2905261516571045, 'learning_rate': 4.020455202014737e-07, 'rewards/chosen': -4.301562309265137, 'rewards/rejected': -42.32500076293945, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 38.07500076293945, 'logps/chosen': -400.5, 'logps/rejected': -560.4000244140625, 'logits/chosen': -13.5, 'logits/rejected': -13.206250190734863, 'epoch': 2.97}
 99%|█████████▉| 4500/4545 [5:36:11<02:43,  3.64s/it] 99%|█████████▉| 4501/4545 [5:36:14<02:33,  3.50s/it] 99%|█████████▉| 4502/4545 [5:36:17<02:24,  3.35s/it] 99%|█████████▉| 4503/4545 [5:36:20<02:17,  3.27s/it] 99%|█████████▉| 4504/4545 [5:36:24<02:19,  3.39s/it] 99%|█████████▉| 4505/4545 [5:36:28<02:22,  3.56s/it] 99%|█████████▉| 4506/4545 [5:36:31<02:10,  3.35s/it] 99%|█████████▉| 4507/4545 [5:36:35<02:12,  3.50s/it] 99%|█████████▉| 4508/4545 [5:36:38<02:14,  3.63s/it] 99%|█████████▉| 4509/4545 [5:36:43<02:15,  3.75s/it] 99%|█████████▉| 4510/4545 [5:36:47<02:14,  3.84s/it]                                                     {'loss': 0.0169, 'grad_norm': 0.9887063503265381, 'learning_rate': 4.0125292476655777e-07, 'rewards/chosen': -4.431250095367432, 'rewards/rejected': -35.65625, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 31.212499618530273, 'logps/chosen': -359.25, 'logps/rejected': -499.79998779296875, 'logits/chosen': -13.75, 'logits/rejected': -13.456250190734863, 'epoch': 2.98}
 99%|█████████▉| 4510/4545 [5:36:47<02:14,  3.84s/it] 99%|█████████▉| 4511/4545 [5:36:51<02:15,  3.98s/it] 99%|█████████▉| 4512/4545 [5:36:55<02:10,  3.96s/it] 99%|█████████▉| 4513/4545 [5:36:59<02:06,  3.96s/it] 99%|█████████▉| 4514/4545 [5:37:02<01:57,  3.79s/it] 99%|█████████▉| 4515/4545 [5:37:06<01:57,  3.91s/it] 99%|█████████▉| 4516/4545 [5:37:10<01:54,  3.94s/it] 99%|█████████▉| 4517/4545 [5:37:13<01:40,  3.59s/it] 99%|█████████▉| 4518/4545 [5:37:16<01:34,  3.51s/it] 99%|█████████▉| 4519/4545 [5:37:20<01:35,  3.67s/it] 99%|█████████▉| 4520/4545 [5:37:23<01:27,  3.48s/it]                                                     {'loss': 0.0271, 'grad_norm': 1.1563804149627686, 'learning_rate': 4.006535680219648e-07, 'rewards/chosen': -5.6640625, 'rewards/rejected': -32.837501525878906, 'rewards/accuracies': 0.987500011920929, 'rewards/margins': 27.174999237060547, 'logps/chosen': -314.20001220703125, 'logps/rejected': -501.79998779296875, 'logits/chosen': -14.125, 'logits/rejected': -13.800000190734863, 'epoch': 2.98}
 99%|█████████▉| 4520/4545 [5:37:24<01:27,  3.48s/it] 99%|█████████▉| 4521/4545 [5:37:27<01:21,  3.38s/it] 99%|█████████▉| 4522/4545 [5:37:31<01:22,  3.59s/it]100%|█████████▉| 4523/4545 [5:37:34<01:16,  3.49s/it]100%|█████████▉| 4524/4545 [5:37:38<01:18,  3.72s/it]100%|█████████▉| 4525/4545 [5:37:42<01:15,  3.78s/it]100%|█████████▉| 4526/4545 [5:37:46<01:12,  3.82s/it]100%|█████████▉| 4527/4545 [5:37:50<01:08,  3.83s/it]100%|█████████▉| 4528/4545 [5:37:54<01:06,  3.93s/it]100%|█████████▉| 4529/4545 [5:37:58<01:02,  3.92s/it]100%|█████████▉| 4530/4545 [5:38:02<00:58,  3.92s/it]                                                     {'loss': 0.0336, 'grad_norm': 54.142333984375, 'learning_rate': 4.002475143563535e-07, 'rewards/chosen': -4.56640625, 'rewards/rejected': -41.349998474121094, 'rewards/accuracies': 0.9937499761581421, 'rewards/margins': 36.775001525878906, 'logps/chosen': -384.3999938964844, 'logps/rejected': -567.7999877929688, 'logits/chosen': -13.762499809265137, 'logits/rejected': -13.306249618530273, 'epoch': 2.99}
100%|█████████▉| 4530/4545 [5:38:02<00:58,  3.92s/it]100%|█████████▉| 4531/4545 [5:38:06<00:55,  3.94s/it]100%|█████████▉| 4532/4545 [5:38:10<00:51,  3.97s/it]100%|█████████▉| 4533/4545 [5:38:14<00:47,  3.96s/it]100%|█████████▉| 4534/4545 [5:38:18<00:43,  3.96s/it]100%|█████████▉| 4535/4545 [5:38:22<00:39,  3.95s/it]100%|█████████▉| 4536/4545 [5:38:26<00:36,  4.02s/it]
  0%|          | 0/60 [00:00<?, ?it/s][A
  3%|▎         | 2/60 [00:01<00:38,  1.50it/s][A
  5%|▌         | 3/60 [00:02<00:59,  1.05s/it][A
  7%|▋         | 4/60 [00:04<01:11,  1.28s/it][A
  8%|▊         | 5/60 [00:06<01:15,  1.38s/it][A
 10%|█         | 6/60 [00:07<01:19,  1.47s/it][A
 12%|█▏        | 7/60 [00:09<01:20,  1.53s/it][A
 13%|█▎        | 8/60 [00:11<01:22,  1.58s/it][A
 15%|█▌        | 9/60 [00:12<01:21,  1.60s/it][A
 17%|█▋        | 10/60 [00:14<01:19,  1.60s/it][A
 18%|█▊        | 11/60 [00:16<01:20,  1.64s/it][A
 20%|██        | 12/60 [00:17<01:19,  1.65s/it][A
 22%|██▏       | 13/60 [00:19<01:16,  1.63s/it][A
 23%|██▎       | 14/60 [00:21<01:15,  1.64s/it][A
 25%|██▌       | 15/60 [00:22<01:08,  1.53s/it][A
 27%|██▋       | 16/60 [00:49<06:43,  9.18s/it][A
 28%|██▊       | 17/60 [00:50<04:49,  6.74s/it][A
 30%|███       | 18/60 [01:16<08:53, 12.70s/it][A
 32%|███▏      | 19/60 [01:18<06:19,  9.27s/it][A
 33%|███▎      | 20/60 [01:18<04:27,  6.68s/it][A
 35%|███▌      | 21/60 [01:19<03:14,  4.98s/it][A
 37%|███▋      | 22/60 [01:21<02:27,  3.88s/it][A
 38%|███▊      | 23/60 [01:22<01:53,  3.05s/it][A
 40%|████      | 24/60 [01:23<01:28,  2.44s/it][A
 42%|████▏     | 25/60 [01:25<01:17,  2.21s/it][A
 43%|████▎     | 26/60 [01:26<01:07,  1.98s/it][A
 45%|████▌     | 27/60 [01:27<00:53,  1.62s/it][A
 47%|████▋     | 28/60 [01:28<00:45,  1.42s/it][A
 48%|████▊     | 29/60 [01:29<00:42,  1.36s/it][A
 50%|█████     | 30/60 [01:31<00:43,  1.45s/it][A
 52%|█████▏    | 31/60 [01:32<00:43,  1.49s/it][A
 53%|█████▎    | 32/60 [01:34<00:41,  1.48s/it][A
 55%|█████▌    | 33/60 [01:35<00:38,  1.44s/it][A
 57%|█████▋    | 34/60 [01:36<00:32,  1.26s/it][A
 58%|█████▊    | 35/60 [01:37<00:32,  1.32s/it][A
 60%|██████    | 36/60 [01:39<00:32,  1.36s/it][A
 62%|██████▏   | 37/60 [01:39<00:26,  1.14s/it][A
 63%|██████▎   | 38/60 [01:41<00:28,  1.28s/it][A
 65%|██████▌   | 39/60 [01:42<00:26,  1.24s/it][A
 67%|██████▋   | 40/60 [01:43<00:22,  1.11s/it][A
 68%|██████▊   | 41/60 [01:44<00:23,  1.22s/it][A
 70%|███████   | 42/60 [01:46<00:23,  1.32s/it][A
 72%|███████▏  | 43/60 [01:47<00:20,  1.22s/it][A
 73%|███████▎  | 44/60 [01:48<00:20,  1.29s/it][A
 75%|███████▌  | 45/60 [01:49<00:17,  1.14s/it][A
 77%|███████▋  | 46/60 [01:51<00:17,  1.27s/it][A
 78%|███████▊  | 47/60 [01:52<00:18,  1.40s/it][A
 80%|████████  | 48/60 [01:53<00:14,  1.22s/it][A
 82%|████████▏ | 49/60 [01:55<00:14,  1.32s/it][A
 83%|████████▎ | 50/60 [01:56<00:14,  1.43s/it][A
 85%|████████▌ | 51/60 [01:58<00:13,  1.47s/it][A
 87%|████████▋ | 52/60 [01:59<00:11,  1.40s/it][A
 88%|████████▊ | 53/60 [02:00<00:09,  1.31s/it][A
 90%|█████████ | 54/60 [02:02<00:08,  1.39s/it][A
 92%|█████████▏| 55/60 [02:03<00:05,  1.20s/it][A
 93%|█████████▎| 56/60 [02:04<00:05,  1.31s/it][A
 95%|█████████▌| 57/60 [02:06<00:04,  1.39s/it][A
 97%|█████████▋| 58/60 [02:07<00:02,  1.38s/it][A
 98%|█████████▊| 59/60 [02:09<00:01,  1.44s/it][A
100%|██████████| 60/60 [02:10<00:00,  1.50s/it][A                                                     
                                               [A{'eval_loss': 0.5007104873657227, 'eval_runtime': 132.8877, 'eval_samples_per_second': 7.171, 'eval_steps_per_second': 0.452, 'eval_rewards/chosen': -5.688020706176758, 'eval_rewards/rejected': -34.204166412353516, 'eval_rewards/accuracies': 0.8665509819984436, 'eval_rewards/margins': 28.522655487060547, 'eval_logps/chosen': -434.5833435058594, 'eval_logps/rejected': -494.0833435058594, 'eval_logits/chosen': -13.430208206176758, 'eval_logits/rejected': -13.348958015441895, 'epoch': 2.99}
100%|█████████▉| 4536/4545 [5:40:39<00:36,  4.02s/it]
100%|██████████| 60/60 [02:11<00:00,  1.50s/it][A
                                               [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 4537/4545 [5:40:55<06:20, 47.56s/it]100%|█████████▉| 4538/4545 [5:40:59<04:01, 34.54s/it]100%|█████████▉| 4539/4545 [5:41:03<02:32, 25.35s/it]100%|█████████▉| 4540/4545 [5:41:07<01:35, 19.01s/it]                                                     {'loss': 0.0017, 'grad_norm': 0.3203466236591339, 'learning_rate': 4.0003480739191e-07, 'rewards/chosen': -5.987500190734863, 'rewards/rejected': -44.150001525878906, 'rewards/accuracies': 1.0, 'rewards/margins': 38.162498474121094, 'logps/chosen': -295.3999938964844, 'logps/rejected': -587.5999755859375, 'logits/chosen': -13.943750381469727, 'logits/rejected': -13.462499618530273, 'epoch': 3.0}
100%|█████████▉| 4540/4545 [5:41:07<01:35, 19.01s/it]100%|█████████▉| 4541/4545 [5:41:11<00:57, 14.48s/it]100%|█████████▉| 4542/4545 [5:41:16<00:34, 11.41s/it]100%|█████████▉| 4543/4545 [5:41:19<00:18,  9.17s/it]100%|█████████▉| 4544/4545 [5:41:23<00:07,  7.60s/it]100%|██████████| 4545/4545 [5:41:27<00:00,  6.32s/it]                                                     {'train_runtime': 20512.5991, 'train_samples_per_second': 3.543, 'train_steps_per_second': 0.222, 'train_loss': 0.15770478940992005, 'epoch': 3.0}
100%|██████████| 4545/4545 [5:41:45<00:00,  6.32s/it]100%|██████████| 4545/4545 [5:41:45<00:00,  4.51s/it]
Training complete
Saving model
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mDPO_r-64_lr-4e-06_e-3_b-0.1_63084265[0m at: [34mhttps://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/pprizq84[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250612_102854-pprizq84/logs[0m
[rank0]:[W612 16:11:50.803121190 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 0 ---
