cpu-bind=MASK - gn04, task  2  0 [2121880]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 2 ---
Total Nodes: 3
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn01
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 3     --machine_rank 2     --main_process_ip gn01     --main_process_port 29500     --num_processes 12     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_63118420     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train_curriculum.py"     --rank=64 --learning_rate=1e-6 --total_epochs=3 --beta=0.1 --curriculum_stage=2
-------------------------------------------
[2025-06-12 21:21:48,395] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0612 21:21:49.763000 2121931 torch/distributed/run.py:792] 
W0612 21:21:49.763000 2121931 torch/distributed/run.py:792] *****************************************
W0612 21:21:49.763000 2121931 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0612 21:21:49.763000 2121931 torch/distributed/run.py:792] *****************************************
[2025-06-12 21:21:54,574] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 21:21:54,624] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 21:21:54,630] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-12 21:21:54,639] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[load_data_curriculum.py]: Training data of type 'bad_lang_examples':    3489
[load_data_curriculum.py]: Training data of type 'short_examples':       699
[load_data_curriculum.py]: Training data of type 'choose_examples':      13379
[load_data_curriculum.py]: Training data of type 'bad_format_examples':  3148
[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *[load_data_curriculum.py]: *
[load_data_curriculum.py]: Evaluation data size: 953
[load_data_curriculum.py]: Curriculum stage 0 training data size: 4890
[load_data_curriculum.py]: Curriculum stage 1 training data size: 6689
[load_data_curriculum.py]: Curriculum stage 2 training data size: 6690
[load_data.py]: Training data of type 'bad_lang_examples':    5343
[load_data.py]: Training data of type 'short_examples':       699
[load_data.py]: Training data of type 'choose_examples':      13379
[load_data.py]: Training data of type 'bad_format_examples':  4806
[load_data.py]: Number of training examples: 24227
[load_data.py]: Number of validation examples: 953
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1, curriculum_stage=2)
1e-06
World size: 12
Setting gradient accumulation steps to: 1
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1, curriculum_stage=2)
1e-06
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1, curriculum_stage=2)
1e-06
Namespace(rank=64, learning_rate=1e-06, total_epochs=3, beta=0.1, curriculum_stage=2)
1e-06
Created datasets
Train dataset size: 6690
Validation dataset size: 953
Steps per epoch: 418
Evaluate each 209 steps
[2025-06-12 21:21:59,180] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 21:21:59,200] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 21:21:59,207] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-12 21:21:59,214] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
Loading model from: /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/trained_models/Curriculum_DPO_models/GaMS-9B-DPO-Curriculum-1
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.31s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.36s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.37s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:16,  5.40s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.57s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.61s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.61s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:11<00:11,  5.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.67s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.67s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:16<00:05,  5.68s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.23s/it]
Loaded model
Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.09s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.27s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.28s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.28s/it]
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   8%|▊         | 540/6690 [00:00<00:01, 5290.52 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1104/6690 [00:00<00:01, 5469.15 examples/s]Extracting prompt in train dataset:  25%|██▍       | 1660/6690 [00:00<00:00, 5503.13 examples/s][rank9]:[W612 21:22:24.862689589 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 9]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:  37%|███▋      | 2470/6690 [00:00<00:00, 5420.81 examples/s][rank11]:[W612 21:22:24.913620432 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 11]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank10]:[W612 21:22:24.946754791 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 10]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:  49%|████▊     | 3259/6690 [00:00<00:00, 5353.27 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 3820/6690 [00:00<00:00, 5412.40 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 4380/6690 [00:00<00:00, 5367.13 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 4945/6690 [00:00<00:00, 5447.55 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 5510/6690 [00:01<00:00, 5495.00 examples/s]Extracting prompt in train dataset:  91%|█████████ | 6073/6690 [00:01<00:00, 5533.35 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 6636/6690 [00:01<00:00, 5561.07 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5404.36 examples/s]
Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   4%|▍         | 288/6690 [00:00<00:02, 2851.46 examples/s]Applying chat template to train dataset:   9%|▉         | 599/6690 [00:00<00:02, 2998.93 examples/s]Applying chat template to train dataset:  14%|█▎        | 911/6690 [00:00<00:01, 3049.56 examples/s]Applying chat template to train dataset:  18%|█▊        | 1222/6690 [00:00<00:01, 3069.92 examples/s]Applying chat template to train dataset:  23%|██▎       | 1535/6690 [00:00<00:01, 3087.32 examples/s]Applying chat template to train dataset:  28%|██▊       | 1849/6690 [00:00<00:01, 3099.59 examples/s]Applying chat template to train dataset:  32%|███▏      | 2161/6690 [00:00<00:01, 3103.39 examples/s]Applying chat template to train dataset:  39%|███▉      | 2624/6690 [00:00<00:01, 3093.35 examples/s]Applying chat template to train dataset:  44%|████▍     | 2938/6690 [00:00<00:01, 3100.24 examples/s]Applying chat template to train dataset:  49%|████▊     | 3250/6690 [00:01<00:01, 3104.52 examples/s]Applying chat template to train dataset:  53%|█████▎    | 3561/6690 [00:01<00:01, 3104.24 examples/s]Applying chat template to train dataset:  58%|█████▊    | 3873/6690 [00:01<00:00, 3107.06 examples/s]Applying chat template to train dataset:  63%|██████▎   | 4188/6690 [00:01<00:00, 3115.10 examples/s]Applying chat template to train dataset:  69%|██████▉   | 4627/6690 [00:01<00:00, 3038.83 examples/s]Applying chat template to train dataset:  74%|███████▍  | 4938/6690 [00:01<00:00, 3055.88 examples/s]Applying chat template to train dataset:  78%|███████▊  | 5249/6690 [00:01<00:00, 3069.18 examples/s]Applying chat template to train dataset:  83%|████████▎ | 5560/6690 [00:01<00:00, 3075.91 examples/s]Applying chat template to train dataset:  88%|████████▊ | 5871/6690 [00:01<00:00, 3084.40 examples/s]Applying chat template to train dataset:  92%|█████████▏| 6184/6690 [00:02<00:00, 3094.22 examples/s]Applying chat template to train dataset:  97%|█████████▋| 6497/6690 [00:02<00:00, 3096.43 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3075.47 examples/s]
Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 40/6690 [00:00<00:17, 383.07 examples/s]Tokenizing train dataset:   1%|▏         | 89/6690 [00:00<00:15, 438.32 examples/s]Tokenizing train dataset:   2%|▏         | 157/6690 [00:00<00:14, 441.47 examples/s]Tokenizing train dataset:   3%|▎         | 204/6690 [00:00<00:14, 449.30 examples/s]Tokenizing train dataset:   4%|▍         | 254/6690 [00:00<00:13, 460.48 examples/s]Tokenizing train dataset:   5%|▍         | 319/6690 [00:00<00:14, 444.11 examples/s]Tokenizing train dataset:   6%|▌         | 370/6690 [00:00<00:13, 459.23 examples/s]Tokenizing train dataset:   7%|▋         | 442/6690 [00:00<00:13, 465.52 examples/s]Tokenizing train dataset:   7%|▋         | 491/6690 [00:01<00:13, 470.43 examples/s]Tokenizing train dataset:   8%|▊         | 540/6690 [00:01<00:13, 469.62 examples/s]Tokenizing train dataset:   9%|▉         | 589/6690 [00:01<00:12, 471.45 examples/s]Tokenizing train dataset:  10%|▉         | 641/6690 [00:01<00:12, 478.10 examples/s]Tokenizing train dataset:  10%|█         | 690/6690 [00:01<00:12, 475.60 examples/s]Tokenizing train dataset:  11%|█         | 742/6690 [00:01<00:12, 485.81 examples/s]Tokenizing train dataset:  12%|█▏        | 793/6690 [00:01<00:12, 486.43 examples/s]Tokenizing train dataset:  13%|█▎        | 865/6690 [00:01<00:12, 480.30 examples/s]Tokenizing train dataset:  14%|█▍        | 923/6690 [00:02<00:13, 443.11 examples/s]Tokenizing train dataset:  15%|█▍        | 972/6690 [00:02<00:12, 452.76 examples/s]Tokenizing train dataset:  16%|█▌        | 1039/6690 [00:02<00:12, 448.01 examples/s]Tokenizing train dataset:  16%|█▋        | 1088/6690 [00:02<00:12, 453.33 examples/s]Tokenizing train dataset:  17%|█▋        | 1155/6690 [00:02<00:12, 445.63 examples/s]Tokenizing train dataset:  18%|█▊        | 1203/6690 [00:02<00:12, 447.74 examples/s]Tokenizing train dataset:  19%|█▉        | 1268/6690 [00:02<00:12, 438.88 examples/s]Tokenizing train dataset:  20%|█▉        | 1317/6690 [00:02<00:11, 449.17 examples/s]Tokenizing train dataset:  20%|██        | 1363/6690 [00:02<00:11, 447.98 examples/s]Tokenizing train dataset:  21%|██▏       | 1422/6690 [00:03<00:12, 426.65 examples/s]Tokenizing train dataset:  22%|██▏       | 1485/6690 [00:03<00:12, 422.73 examples/s]Tokenizing train dataset:  23%|██▎       | 1540/6690 [00:03<00:11, 448.70 examples/s]Tokenizing train dataset:  24%|██▍       | 1603/6690 [00:03<00:11, 435.52 examples/s]Tokenizing train dataset:  25%|██▍       | 1668/6690 [00:03<00:11, 432.52 examples/s]Tokenizing train dataset:  26%|██▌       | 1715/6690 [00:03<00:11, 440.14 examples/s]Tokenizing train dataset:  26%|██▋       | 1762/6690 [00:03<00:11, 443.84 examples/s]Tokenizing train dataset:  27%|██▋       | 1807/6690 [00:04<00:11, 439.89 examples/s]Tokenizing train dataset:  28%|██▊       | 1876/6690 [00:04<00:10, 443.13 examples/s]Tokenizing train dataset:  29%|██▉       | 1946/6690 [00:04<00:10, 440.07 examples/s]Tokenizing train dataset:  30%|██▉       | 2003/6690 [00:04<00:11, 418.93 examples/s]Tokenizing train dataset:  31%|███       | 2046/6690 [00:04<00:11, 420.60 examples/s]Tokenizing train dataset:  31%|███       | 2090/6690 [00:04<00:10, 423.25 examples/s]Tokenizing train dataset:  32%|███▏      | 2139/6690 [00:04<00:10, 438.12 examples/s]Tokenizing train dataset:  33%|███▎      | 2190/6690 [00:04<00:10, 449.40 examples/s]Tokenizing train dataset:  33%|███▎      | 2241/6690 [00:04<00:09, 463.20 examples/s]Tokenizing train dataset:  34%|███▍      | 2304/6690 [00:05<00:09, 441.27 examples/s]Tokenizing train dataset:  35%|███▌      | 2350/6690 [00:05<00:09, 443.35 examples/s]Tokenizing train dataset:  36%|███▌      | 2397/6690 [00:05<00:09, 446.98 examples/s]Tokenizing train dataset:  37%|███▋      | 2461/6690 [00:05<00:09, 437.56 examples/s]Tokenizing train dataset:  38%|███▊      | 2530/6690 [00:05<00:09, 438.82 examples/s]Tokenizing train dataset:  39%|███▊      | 2584/6690 [00:05<00:08, 459.38 examples/s]Tokenizing train dataset:  40%|███▉      | 2649/6690 [00:05<00:09, 448.70 examples/s]Tokenizing train dataset:  41%|████      | 2713/6690 [00:06<00:09, 435.68 examples/s]Tokenizing train dataset:  41%|████▏     | 2774/6690 [00:06<00:09, 419.49 examples/s]Tokenizing train dataset:  42%|████▏     | 2838/6690 [00:06<00:09, 418.79 examples/s]Tokenizing train dataset:  43%|████▎     | 2882/6690 [00:06<00:09, 422.68 examples/s]Tokenizing train dataset:  44%|████▍     | 2933/6690 [00:06<00:08, 439.36 examples/s]Tokenizing train dataset:  45%|████▍     | 2986/6690 [00:06<00:08, 456.06 examples/s]Tokenizing train dataset:  45%|████▌     | 3035/6690 [00:06<00:07, 459.71 examples/s]Tokenizing train dataset:  46%|████▌     | 3090/6690 [00:06<00:07, 482.00 examples/s]Tokenizing train dataset:  47%|████▋     | 3153/6690 [00:07<00:07, 455.56 examples/s]Tokenizing train dataset:  48%|████▊     | 3200/6690 [00:07<00:07, 455.20 examples/s]Tokenizing train dataset:  49%|████▊     | 3249/6690 [00:07<00:07, 460.96 examples/s]Tokenizing train dataset:  49%|████▉     | 3309/6690 [00:07<00:07, 434.95 examples/s]Tokenizing train dataset:  50%|█████     | 3370/6690 [00:07<00:07, 423.00 examples/s]Tokenizing train dataset:  51%|█████▏    | 3431/6690 [00:07<00:07, 412.77 examples/s]Tokenizing train dataset:  52%|█████▏    | 3496/6690 [00:07<00:07, 416.71 examples/s]Tokenizing train dataset:  53%|█████▎    | 3556/6690 [00:08<00:07, 405.42 examples/s]Tokenizing train dataset:  54%|█████▍    | 3611/6690 [00:08<00:07, 390.21 examples/s]Tokenizing train dataset:  55%|█████▍    | 3656/6690 [00:08<00:07, 401.69 examples/s]Tokenizing train dataset:  55%|█████▌    | 3699/6690 [00:08<00:07, 407.27 examples/s]Tokenizing train dataset:  56%|█████▌    | 3754/6690 [00:08<00:07, 386.03 examples/s]Tokenizing train dataset:  57%|█████▋    | 3799/6690 [00:08<00:07, 398.09 examples/s]Tokenizing train dataset:  57%|█████▋    | 3845/6690 [00:08<00:06, 410.58 examples/s]Tokenizing train dataset:  58%|█████▊    | 3893/6690 [00:08<00:06, 425.49 examples/s]Tokenizing train dataset:  59%|█████▉    | 3942/6690 [00:08<00:06, 437.95 examples/s]Tokenizing train dataset:  60%|█████▉    | 3991/6690 [00:09<00:06, 447.04 examples/s]Tokenizing train dataset:  61%|██████    | 4058/6690 [00:09<00:05, 442.94 examples/s]Tokenizing train dataset:  61%|██████▏   | 4103/6690 [00:09<00:05, 438.16 examples/s]Tokenizing train dataset:  62%|██████▏   | 4148/6690 [00:09<00:05, 440.69 examples/s]Tokenizing train dataset:  63%|██████▎   | 4197/6690 [00:09<00:05, 450.93 examples/s]Tokenizing train dataset:  64%|██████▎   | 4261/6690 [00:09<00:05, 437.53 examples/s]Tokenizing train dataset:  64%|██████▍   | 4308/6690 [00:09<00:05, 441.22 examples/s]Tokenizing train dataset:  65%|██████▌   | 4369/6690 [00:09<00:05, 426.29 examples/s]Tokenizing train dataset:  66%|██████▋   | 4436/6690 [00:10<00:05, 430.51 examples/s]Tokenizing train dataset:  67%|██████▋   | 4498/6690 [00:10<00:05, 422.09 examples/s]Tokenizing train dataset:  68%|██████▊   | 4546/6690 [00:10<00:04, 434.30 examples/s]Tokenizing train dataset:  69%|██████▉   | 4615/6690 [00:10<00:04, 442.14 examples/s]Tokenizing train dataset:  70%|██████▉   | 4666/6690 [00:10<00:04, 450.15 examples/s]Tokenizing train dataset:  71%|███████   | 4736/6690 [00:10<00:04, 451.71 examples/s]Tokenizing train dataset:  72%|███████▏  | 4795/6690 [00:10<00:04, 423.56 examples/s]Tokenizing train dataset:  72%|███████▏  | 4844/6690 [00:11<00:04, 435.81 examples/s]Tokenizing train dataset:  73%|███████▎  | 4907/6690 [00:11<00:04, 425.64 examples/s]Tokenizing train dataset:  74%|███████▍  | 4952/6690 [00:11<00:04, 428.27 examples/s]Tokenizing train dataset:  75%|███████▍  | 4996/6690 [00:11<00:03, 428.26 examples/s]Tokenizing train dataset:  76%|███████▌  | 5060/6690 [00:11<00:03, 418.63 examples/s]Tokenizing train dataset:  76%|███████▋  | 5103/6690 [00:11<00:03, 419.32 examples/s]Tokenizing train dataset:  77%|███████▋  | 5169/6690 [00:11<00:03, 419.78 examples/s]Tokenizing train dataset:  78%|███████▊  | 5217/6690 [00:11<00:03, 430.63 examples/s]Tokenizing train dataset:  79%|███████▉  | 5282/6690 [00:12<00:03, 427.63 examples/s]Tokenizing train dataset:  80%|███████▉  | 5341/6690 [00:12<00:03, 415.40 examples/s]Tokenizing train dataset:  81%|████████  | 5396/6690 [00:12<00:02, 445.42 examples/s]Tokenizing train dataset:  82%|████████▏ | 5461/6690 [00:12<00:02, 435.51 examples/s]Tokenizing train dataset:  83%|████████▎ | 5526/6690 [00:12<00:02, 432.01 examples/s]Tokenizing train dataset:  84%|████████▎ | 5587/6690 [00:12<00:02, 421.93 examples/s]Tokenizing train dataset:  84%|████████▍ | 5630/6690 [00:12<00:02, 421.81 examples/s]Tokenizing train dataset:  85%|████████▍ | 5676/6690 [00:12<00:02, 429.52 examples/s]Tokenizing train dataset:  86%|████████▌ | 5743/6690 [00:13<00:02, 431.84 examples/s]Tokenizing train dataset:  87%|████████▋ | 5788/6690 [00:13<00:02, 431.16 examples/s]Tokenizing train dataset:  87%|████████▋ | 5851/6690 [00:13<00:01, 420.78 examples/s]Tokenizing train dataset:  88%|████████▊ | 5900/6690 [00:13<00:01, 433.51 examples/s]Tokenizing train dataset:  89%|████████▉ | 5944/6690 [00:13<00:01, 432.05 examples/s]Tokenizing train dataset:  90%|████████▉ | 6010/6690 [00:13<00:01, 431.61 examples/s]Tokenizing train dataset:  91%|█████████ | 6055/6690 [00:13<00:01, 432.39 examples/s]Tokenizing train dataset:  91%|█████████▏| 6107/6690 [00:13<00:01, 451.51 examples/s]Tokenizing train dataset:  92%|█████████▏| 6154/6690 [00:14<00:01, 453.69 examples/s]Tokenizing train dataset:  93%|█████████▎| 6218/6690 [00:14<00:01, 437.36 examples/s]Tokenizing train dataset:  94%|█████████▍| 6275/6690 [00:14<00:01, 413.55 examples/s]Tokenizing train dataset:  94%|█████████▍| 6320/6690 [00:14<00:00, 417.38 examples/s]Tokenizing train dataset:  95%|█████████▌| 6380/6690 [00:14<00:00, 401.38 examples/s]Tokenizing train dataset:  96%|█████████▌| 6430/6690 [00:14<00:00, 423.53 examples/s]Tokenizing train dataset:  97%|█████████▋| 6474/6690 [00:14<00:00, 422.21 examples/s]Tokenizing train dataset:  97%|█████████▋| 6518/6690 [00:14<00:00, 424.19 examples/s]Tokenizing train dataset:  98%|█████████▊| 6581/6690 [00:15<00:00, 418.62 examples/s]Tokenizing train dataset:  99%|█████████▉| 6642/6690 [00:15<00:00, 410.16 examples/s]Tokenizing train dataset: 100%|█████████▉| 6684/6690 [00:15<00:00, 409.87 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 435.13 examples/s]
[rank8]:[W612 21:22:43.266035844 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 8]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  60%|█████▉    | 570/953 [00:00<00:00, 5643.55 examples/s]Extracting prompt in train dataset:   9%|▊         | 569/6690 [00:00<00:01, 5620.83 examples/s]Extracting prompt in train dataset:   9%|▊         | 570/6690 [00:00<00:01, 5622.40 examples/s]Extracting prompt in train dataset:   9%|▊         | 570/6690 [00:00<00:01, 5578.78 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5632.32 examples/s]
Extracting prompt in train dataset:  17%|█▋        | 1140/6690 [00:00<00:00, 5654.67 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1158/6690 [00:00<00:00, 5752.50 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1150/6690 [00:00<00:00, 5678.09 examples/s]Extracting prompt in train dataset:  26%|██▌       | 1726/6690 [00:00<00:00, 5735.50 examples/s]Extracting prompt in train dataset:  26%|██▌       | 1738/6690 [00:00<00:00, 5762.78 examples/s]Extracting prompt in train dataset:  26%|██▌       | 1750/6690 [00:00<00:00, 5790.19 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2300/6690 [00:00<00:00, 5694.44 examples/s]Extracting prompt in train dataset:  35%|███▍      | 2330/6690 [00:00<00:00, 5773.54 examples/s]Extracting prompt in train dataset:  39%|███▉      | 2607/6690 [00:00<00:00, 5751.96 examples/s]Extracting prompt in train dataset:  43%|████▎     | 2881/6690 [00:00<00:00, 5735.26 examples/s]Extracting prompt in train dataset:  44%|████▍     | 2929/6690 [00:00<00:00, 5831.94 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  48%|████▊     | 3190/6690 [00:00<00:00, 5757.43 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 3461/6690 [00:00<00:00, 5755.96 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 3519/6690 [00:00<00:00, 5846.87 examples/s]Applying chat template to eval dataset:  32%|███▏      | 307/953 [00:00<00:00, 3037.37 examples/s]Extracting prompt in train dataset:  56%|█████▋    | 3772/6690 [00:00<00:00, 5775.58 examples/s]Extracting prompt in train dataset:  60%|██████    | 4042/6690 [00:00<00:00, 5771.97 examples/s]Extracting prompt in train dataset:  61%|██████▏   | 4110/6690 [00:00<00:00, 5840.66 examples/s]Applying chat template to eval dataset:  65%|██████▌   | 623/953 [00:00<00:00, 3105.21 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 4360/6690 [00:00<00:00, 5790.27 examples/s]Applying chat template to eval dataset:  99%|█████████▊| 940/953 [00:00<00:00, 3128.81 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3099.17 examples/s]
Extracting prompt in train dataset:  73%|███████▎  | 4880/6690 [00:00<00:00, 5679.39 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 4970/6690 [00:00<00:00, 5761.92 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 5204/6690 [00:00<00:00, 5711.32 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 5462/6690 [00:00<00:00, 5714.72 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 5560/6690 [00:00<00:00, 5793.24 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 5789/6690 [00:01<00:00, 5748.27 examples/s]Extracting prompt in train dataset:  90%|█████████ | 6043/6690 [00:01<00:00, 5740.09 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 6150/6690 [00:01<00:00, 5817.94 examples/s]Extracting prompt in train dataset:  95%|█████████▌| 6373/6690 [00:01<00:00, 5759.76 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 6622/6690 [00:01<00:00, 5753.85 examples/s]Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5768.03 examples/s]
Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5711.54 examples/s]
Extracting prompt in train dataset: 100%|██████████| 6690/6690 [00:01<00:00, 5689.66 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 319.32 examples/s]Tokenizing eval dataset:   8%|▊         | 76/953 [00:00<00:03, 286.73 examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:00<00:03, 276.07 examples/s]Applying chat template to train dataset:   4%|▍         | 288/6690 [00:00<00:02, 2852.68 examples/s]Applying chat template to train dataset:   4%|▍         | 295/6690 [00:00<00:02, 2923.88 examples/s]Applying chat template to train dataset:   4%|▍         | 298/6690 [00:00<00:02, 2956.15 examples/s]Applying chat template to train dataset:   9%|▉         | 601/6690 [00:00<00:02, 3010.56 examples/s]Applying chat template to train dataset:   9%|▉         | 619/6690 [00:00<00:01, 3103.53 examples/s]Applying chat template to train dataset:   9%|▉         | 623/6690 [00:00<00:01, 3123.75 examples/s]Tokenizing eval dataset:  16%|█▋        | 157/953 [00:00<00:03, 264.97 examples/s]Applying chat template to train dataset:  14%|█▎        | 918/6690 [00:00<00:01, 3075.01 examples/s]Applying chat template to train dataset:  14%|█▍        | 943/6690 [00:00<00:01, 3161.77 examples/s]Applying chat template to train dataset:  14%|█▍        | 950/6690 [00:00<00:01, 3179.82 examples/s]Applying chat template to train dataset:  18%|█▊        | 1230/6690 [00:00<00:01, 3089.89 examples/s]Applying chat template to train dataset:  19%|█▉        | 1267/6690 [00:00<00:01, 3186.94 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:00<00:03, 251.53 examples/s]Applying chat template to train dataset:  19%|█▉        | 1274/6690 [00:00<00:01, 3200.57 examples/s]Applying chat template to train dataset:  23%|██▎       | 1545/6690 [00:00<00:01, 3107.92 examples/s]Applying chat template to train dataset:  24%|██▍       | 1590/6690 [00:00<00:01, 3199.29 examples/s]Applying chat template to train dataset:  24%|██▍       | 1600/6690 [00:00<00:01, 3213.95 examples/s]Tokenizing eval dataset:  24%|██▍       | 230/953 [00:00<00:02, 274.10 examples/s]Applying chat template to train dataset:  28%|██▊       | 1859/6690 [00:00<00:01, 3117.28 examples/s]Applying chat template to train dataset:  29%|██▊       | 1916/6690 [00:00<00:01, 3214.53 examples/s]Applying chat template to train dataset:  29%|██▉       | 1927/6690 [00:00<00:01, 3229.54 examples/s]Tokenizing eval dataset:  31%|███       | 295/953 [00:00<00:01, 368.88 examples/s]Applying chat template to train dataset:  32%|███▏      | 2172/6690 [00:00<00:01, 3120.60 examples/s]Applying chat template to train dataset:  33%|███▎      | 2240/6690 [00:00<00:01, 3218.57 examples/s]Applying chat template to train dataset:  34%|███▎      | 2250/6690 [00:00<00:01, 3219.67 examples/s]Tokenizing eval dataset:  38%|███▊      | 359/953 [00:01<00:01, 439.80 examples/s]Applying chat template to train dataset:  38%|███▊      | 2575/6690 [00:00<00:01, 3225.99 examples/s]Tokenizing eval dataset:  44%|████▍     | 420/953 [00:01<00:01, 484.19 examples/s]Applying chat template to train dataset:  39%|███▉      | 2640/6690 [00:00<00:01, 3113.58 examples/s]Applying chat template to train dataset:  41%|████      | 2722/6690 [00:00<00:01, 3210.76 examples/s]Applying chat template to train dataset:  43%|████▎     | 2900/6690 [00:00<00:01, 3228.80 examples/s]Tokenizing eval dataset:  51%|█████     | 488/953 [00:01<00:00, 537.02 examples/s]Applying chat template to train dataset:  44%|████▍     | 2954/6690 [00:00<00:01, 3118.99 examples/s]Applying chat template to train dataset:  46%|████▌     | 3047/6690 [00:00<00:01, 3218.63 examples/s]Applying chat template to train dataset:  48%|████▊     | 3228/6690 [00:01<00:01, 3240.33 examples/s]Tokenizing eval dataset:  58%|█████▊    | 553/953 [00:01<00:00, 568.23 examples/s]Applying chat template to train dataset:  49%|████▉     | 3269/6690 [00:01<00:01, 3126.07 examples/s]Applying chat template to train dataset:  50%|█████     | 3370/6690 [00:01<00:01, 3219.24 examples/s]Tokenizing eval dataset:  65%|██████▍   | 616/953 [00:01<00:00, 580.93 examples/s]Applying chat template to train dataset:  56%|█████▌    | 3714/6690 [00:01<00:00, 3232.81 examples/s]Applying chat template to train dataset:  56%|█████▌    | 3730/6690 [00:01<00:00, 3103.38 examples/s]Applying chat template to train dataset:  58%|█████▊    | 3850/6690 [00:01<00:00, 3205.96 examples/s]Tokenizing eval dataset:  71%|███████   | 678/953 [00:01<00:00, 590.29 examples/s]Applying chat template to train dataset:  60%|██████    | 4040/6690 [00:01<00:00, 3235.41 examples/s]Applying chat template to train dataset:  60%|██████    | 4045/6690 [00:01<00:00, 3113.54 examples/s]Applying chat template to train dataset:  62%|██████▏   | 4174/6690 [00:01<00:00, 3213.86 examples/s]Applying chat template to train dataset:  65%|██████▌   | 4366/6690 [00:01<00:00, 3240.85 examples/s]Tokenizing eval dataset:  80%|███████▉  | 762/953 [00:01<00:00, 571.17 examples/s]Applying chat template to train dataset:  65%|██████▌   | 4359/6690 [00:01<00:00, 3118.99 examples/s]Applying chat template to train dataset:  69%|██████▉   | 4640/6690 [00:01<00:00, 3169.42 examples/s]Applying chat template to train dataset:  72%|███████▏  | 4833/6690 [00:01<00:00, 3190.72 examples/s]Tokenizing eval dataset:  88%|████████▊ | 839/953 [00:01<00:00, 539.44 examples/s]Applying chat template to train dataset:  72%|███████▏  | 4810/6690 [00:01<00:00, 3072.17 examples/s]Applying chat template to train dataset:  74%|███████▍  | 4963/6690 [00:01<00:00, 3181.93 examples/s]Applying chat template to train dataset:  77%|███████▋  | 5157/6690 [00:01<00:00, 3201.63 examples/s]Applying chat template to train dataset:  77%|███████▋  | 5122/6690 [00:01<00:00, 3082.48 examples/s]Applying chat template to train dataset:  79%|███████▉  | 5286/6690 [00:01<00:00, 3191.69 examples/s]Tokenizing eval dataset:  95%|█████████▌| 910/953 [00:02<00:00, 514.57 examples/s]Applying chat template to train dataset:  82%|████████▏ | 5481/6690 [00:01<00:00, 3209.22 examples/s]Applying chat template to train dataset:  81%|████████▏ | 5438/6690 [00:01<00:00, 3096.87 examples/s]Applying chat template to train dataset:  84%|████████▍ | 5609/6690 [00:01<00:00, 3200.13 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 450.99 examples/s]
Applying chat template to train dataset:  87%|████████▋ | 5806/6690 [00:01<00:00, 3218.15 examples/s]Applying chat template to train dataset:  86%|████████▌ | 5750/6690 [00:01<00:00, 3100.66 examples/s]Applying chat template to train dataset:  89%|████████▊ | 5932/6690 [00:01<00:00, 3202.41 examples/s]Applying chat template to train dataset:  92%|█████████▏| 6130/6690 [00:01<00:00, 3224.18 examples/s]Applying chat template to train dataset:  91%|█████████ | 6064/6690 [00:01<00:00, 3108.93 examples/s]Applying chat template to train dataset:  93%|█████████▎| 6254/6690 [00:01<00:00, 3206.85 examples/s]Applying chat template to train dataset:  96%|█████████▋| 6455/6690 [00:02<00:00, 3228.47 examples/s]Applying chat template to train dataset:  95%|█████████▌| 6378/6690 [00:02<00:00, 3114.78 examples/s]Applying chat template to train dataset:  98%|█████████▊| 6576/6690 [00:02<00:00, 3209.36 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3207.86 examples/s]
Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3188.59 examples/s]
Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3110.50 examples/s]Applying chat template to train dataset: 100%|██████████| 6690/6690 [00:02<00:00, 3093.61 examples/s]
Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/6690 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 43/6690 [00:00<00:15, 419.08 examples/s]Tokenizing train dataset:   1%|          | 43/6690 [00:00<00:15, 421.68 examples/s]Tokenizing train dataset:   1%|          | 43/6690 [00:00<00:15, 422.14 examples/s]Tokenizing train dataset:   1%|▏         | 90/6690 [00:00<00:15, 439.68 examples/s]Tokenizing train dataset:   1%|▏         | 90/6690 [00:00<00:15, 438.73 examples/s]Tokenizing train dataset:   1%|▏         | 90/6690 [00:00<00:14, 440.51 examples/s]Tokenizing train dataset:   2%|▏         | 135/6690 [00:00<00:14, 440.65 examples/s]Tokenizing train dataset:   2%|▏         | 135/6690 [00:00<00:14, 438.22 examples/s]Tokenizing train dataset:   2%|▏         | 135/6690 [00:00<00:14, 440.84 examples/s]Tokenizing train dataset:   3%|▎         | 189/6690 [00:00<00:13, 473.37 examples/s]Tokenizing train dataset:   3%|▎         | 188/6690 [00:00<00:13, 472.19 examples/s]Tokenizing train dataset:   3%|▎         | 189/6690 [00:00<00:13, 473.11 examples/s]Tokenizing train dataset:   4%|▎         | 237/6690 [00:00<00:13, 473.19 examples/s]Tokenizing train dataset:   4%|▎         | 236/6690 [00:00<00:13, 467.09 examples/s]Tokenizing train dataset:   4%|▎         | 237/6690 [00:00<00:13, 472.38 examples/s]Tokenizing train dataset:   4%|▍         | 285/6690 [00:00<00:13, 470.64 examples/s]Tokenizing train dataset:   4%|▍         | 285/6690 [00:00<00:13, 466.43 examples/s]Tokenizing train dataset:   4%|▍         | 285/6690 [00:00<00:13, 470.16 examples/s]Tokenizing train dataset:   5%|▌         | 355/6690 [00:00<00:13, 460.65 examples/s]Tokenizing train dataset:   5%|▌         | 353/6690 [00:00<00:13, 458.30 examples/s]Tokenizing train dataset:   5%|▌         | 353/6690 [00:00<00:13, 461.91 examples/s]Tokenizing train dataset:   6%|▌         | 408/6690 [00:00<00:13, 474.68 examples/s]Tokenizing train dataset:   6%|▌         | 403/6690 [00:00<00:13, 468.00 examples/s]Tokenizing train dataset:   6%|▌         | 404/6690 [00:00<00:13, 467.30 examples/s]Tokenizing train dataset:   7%|▋         | 459/6690 [00:00<00:12, 482.58 examples/s]Tokenizing train dataset:   7%|▋         | 456/6690 [00:00<00:12, 480.02 examples/s]Tokenizing train dataset:   7%|▋         | 458/6690 [00:00<00:12, 483.68 examples/s]Tokenizing train dataset:   8%|▊         | 510/6690 [00:01<00:12, 484.93 examples/s]Tokenizing train dataset:   8%|▊         | 507/6690 [00:01<00:12, 486.93 examples/s]Tokenizing train dataset:   8%|▊         | 509/6690 [00:01<00:12, 490.08 examples/s]Tokenizing train dataset:   8%|▊         | 560/6690 [00:01<00:12, 485.04 examples/s]Tokenizing train dataset:   8%|▊         | 556/6690 [00:01<00:12, 480.80 examples/s]Tokenizing train dataset:   8%|▊         | 559/6690 [00:01<00:12, 486.08 examples/s]Tokenizing train dataset:   9%|▉         | 610/6690 [00:01<00:12, 485.38 examples/s]Tokenizing train dataset:   9%|▉         | 620/6690 [00:01<00:13, 456.29 examples/s]Tokenizing train dataset:   9%|▉         | 610/6690 [00:01<00:12, 483.39 examples/s]Tokenizing train dataset:  10%|▉         | 660/6690 [00:01<00:12, 485.68 examples/s]Tokenizing train dataset:  10%|█         | 669/6690 [00:01<00:13, 461.41 examples/s]Tokenizing train dataset:  10%|▉         | 660/6690 [00:01<00:12, 484.58 examples/s]Tokenizing train dataset:  11%|█         | 712/6690 [00:01<00:12, 492.85 examples/s]Tokenizing train dataset:  11%|█         | 723/6690 [00:01<00:12, 480.98 examples/s]Tokenizing train dataset:  11%|█         | 712/6690 [00:01<00:12, 492.30 examples/s]Tokenizing train dataset:  11%|█▏        | 766/6690 [00:01<00:11, 504.07 examples/s]Tokenizing train dataset:  12%|█▏        | 776/6690 [00:01<00:12, 490.48 examples/s]Tokenizing train dataset:  11%|█▏        | 766/6690 [00:01<00:11, 503.74 examples/s]Tokenizing train dataset:  12%|█▏        | 819/6690 [00:01<00:11, 508.69 examples/s]Tokenizing train dataset:  12%|█▏        | 819/6690 [00:01<00:11, 508.74 examples/s]Tokenizing train dataset:  13%|█▎        | 849/6690 [00:01<00:12, 484.47 examples/s]Tokenizing train dataset:  13%|█▎        | 888/6690 [00:01<00:12, 481.53 examples/s]Tokenizing train dataset:  13%|█▎        | 888/6690 [00:01<00:12, 481.66 examples/s]Tokenizing train dataset:  14%|█▎        | 912/6690 [00:01<00:12, 458.78 examples/s]Tokenizing train dataset:  14%|█▍        | 955/6690 [00:02<00:12, 462.37 examples/s]Tokenizing train dataset:  14%|█▍        | 959/6690 [00:02<00:12, 458.38 examples/s]Tokenizing train dataset:  14%|█▍        | 955/6690 [00:02<00:12, 462.77 examples/s]Tokenizing train dataset:  15%|█▌        | 1025/6690 [00:02<00:12, 458.96 examples/s]Tokenizing train dataset:  15%|█▌        | 1028/6690 [00:02<00:12, 456.93 examples/s]Tokenizing train dataset:  15%|█▌        | 1025/6690 [00:02<00:12, 459.80 examples/s]Tokenizing train dataset:  16%|█▌        | 1077/6690 [00:02<00:11, 468.79 examples/s]Tokenizing train dataset:  16%|█▌        | 1078/6690 [00:02<00:12, 465.27 examples/s]Tokenizing train dataset:  16%|█▌        | 1077/6690 [00:02<00:11, 469.40 examples/s]Tokenizing train dataset:  17%|█▋        | 1146/6690 [00:02<00:12, 460.22 examples/s]Tokenizing train dataset:  17%|█▋        | 1146/6690 [00:02<00:12, 456.56 examples/s]Tokenizing train dataset:  17%|█▋        | 1146/6690 [00:02<00:12, 460.51 examples/s]Tokenizing train dataset:  18%|█▊        | 1193/6690 [00:02<00:11, 459.70 examples/s]Tokenizing train dataset:  18%|█▊        | 1193/6690 [00:02<00:12, 455.91 examples/s]Tokenizing train dataset:  18%|█▊        | 1193/6690 [00:02<00:11, 459.70 examples/s]Tokenizing train dataset:  19%|█▉        | 1262/6690 [00:02<00:12, 452.30 examples/s]Tokenizing train dataset:  19%|█▉        | 1260/6690 [00:02<00:12, 448.18 examples/s]Tokenizing train dataset:  19%|█▉        | 1262/6690 [00:02<00:12, 452.17 examples/s]Tokenizing train dataset:  20%|█▉        | 1308/6690 [00:02<00:11, 452.60 examples/s]Tokenizing train dataset:  20%|█▉        | 1306/6690 [00:02<00:12, 447.34 examples/s]Tokenizing train dataset:  20%|█▉        | 1308/6690 [00:02<00:11, 452.21 examples/s]Tokenizing train dataset:  20%|██        | 1361/6690 [00:02<00:11, 466.69 examples/s]Tokenizing train dataset:  20%|██        | 1360/6690 [00:02<00:11, 466.44 examples/s]Tokenizing train dataset:  20%|██        | 1360/6690 [00:02<00:11, 468.52 examples/s]Tokenizing train dataset:  21%|██        | 1420/6690 [00:03<00:12, 436.61 examples/s]Tokenizing train dataset:  21%|██        | 1420/6690 [00:03<00:12, 433.49 examples/s]Tokenizing train dataset:  21%|██        | 1420/6690 [00:03<00:12, 435.64 examples/s]Tokenizing train dataset:  22%|██▏       | 1466/6690 [00:03<00:11, 437.69 examples/s]Tokenizing train dataset:  22%|██▏       | 1465/6690 [00:03<00:11, 435.54 examples/s]Tokenizing train dataset:  22%|██▏       | 1466/6690 [00:03<00:11, 436.79 examples/s]Tokenizing train dataset:  23%|██▎       | 1516/6690 [00:03<00:11, 452.23 examples/s]Tokenizing train dataset:  23%|██▎       | 1511/6690 [00:03<00:11, 441.42 examples/s]Tokenizing train dataset:  23%|██▎       | 1516/6690 [00:03<00:11, 451.51 examples/s]Tokenizing train dataset:  23%|██▎       | 1563/6690 [00:03<00:11, 452.45 examples/s]Tokenizing train dataset:  23%|██▎       | 1560/6690 [00:03<00:11, 449.90 examples/s]Tokenizing train dataset:  23%|██▎       | 1563/6690 [00:03<00:11, 452.03 examples/s]Tokenizing train dataset:  24%|██▍       | 1630/6690 [00:03<00:11, 446.50 examples/s]Tokenizing train dataset:  24%|██▍       | 1628/6690 [00:03<00:11, 445.21 examples/s]Tokenizing train dataset:  24%|██▍       | 1630/6690 [00:03<00:11, 446.35 examples/s]Tokenizing train dataset:  25%|██▌       | 1700/6690 [00:03<00:11, 447.12 examples/s]Tokenizing train dataset:  25%|██▌       | 1698/6690 [00:03<00:11, 447.11 examples/s]Tokenizing train dataset:  25%|██▌       | 1700/6690 [00:03<00:11, 447.09 examples/s]Tokenizing train dataset:  26%|██▌       | 1751/6690 [00:03<00:10, 459.57 examples/s]Tokenizing train dataset:  26%|██▌       | 1746/6690 [00:03<00:10, 453.63 examples/s]Tokenizing train dataset:  26%|██▌       | 1751/6690 [00:03<00:10, 459.80 examples/s]Tokenizing train dataset:  27%|██▋       | 1820/6690 [00:03<00:10, 449.51 examples/s]Tokenizing train dataset:  27%|██▋       | 1812/6690 [00:03<00:10, 446.09 examples/s]Tokenizing train dataset:  27%|██▋       | 1820/6690 [00:03<00:10, 449.38 examples/s]Tokenizing train dataset:  28%|██▊       | 1866/6690 [00:04<00:10, 450.62 examples/s]Tokenizing train dataset:  28%|██▊       | 1858/6690 [00:04<00:10, 448.65 examples/s]Tokenizing train dataset:  28%|██▊       | 1866/6690 [00:04<00:10, 450.50 examples/s]Tokenizing train dataset:  28%|██▊       | 1904/6690 [00:04<00:10, 446.99 examples/s]Tokenizing train dataset:  29%|██▉       | 1933/6690 [00:04<00:10, 447.03 examples/s]Tokenizing train dataset:  29%|██▊       | 1912/6690 [00:04<00:10, 448.33 examples/s]Tokenizing train dataset:  29%|██▉       | 1952/6690 [00:04<00:10, 450.32 examples/s]Tokenizing train dataset:  30%|██▉       | 1978/6690 [00:04<00:10, 446.22 examples/s]Tokenizing train dataset:  29%|██▉       | 1960/6690 [00:04<00:10, 453.29 examples/s]Tokenizing train dataset:  31%|███       | 2041/6690 [00:04<00:10, 432.95 examples/s]Tokenizing train dataset:  30%|███       | 2011/6690 [00:04<00:11, 421.93 examples/s]Tokenizing train dataset:  30%|███       | 2023/6690 [00:04<00:10, 430.04 examples/s]Tokenizing train dataset:  31%|███       | 2085/6690 [00:04<00:10, 434.24 examples/s]Tokenizing train dataset:  31%|███       | 2057/6690 [00:04<00:10, 427.05 examples/s]Tokenizing train dataset:  31%|███       | 2090/6690 [00:04<00:10, 430.70 examples/s]Tokenizing train dataset:  32%|███▏      | 2134/6690 [00:04<00:10, 446.78 examples/s]Tokenizing train dataset:  31%|███▏      | 2105/6690 [00:04<00:10, 437.02 examples/s]Tokenizing train dataset:  32%|███▏      | 2140/6690 [00:04<00:10, 444.17 examples/s]Tokenizing train dataset:  33%|███▎      | 2184/6690 [00:04<00:09, 457.87 examples/s]Tokenizing train dataset:  32%|███▏      | 2155/6690 [00:04<00:10, 449.72 examples/s]Tokenizing train dataset:  33%|███▎      | 2190/6690 [00:04<00:09, 457.20 examples/s]Tokenizing train dataset:  33%|███▎      | 2236/6690 [00:04<00:09, 468.81 examples/s]Tokenizing train dataset:  33%|███▎      | 2207/6690 [00:04<00:09, 466.24 examples/s]Tokenizing train dataset:  34%|███▎      | 2245/6690 [00:04<00:09, 474.45 examples/s]Tokenizing train dataset:  34%|███▍      | 2300/6690 [00:04<00:09, 450.31 examples/s]Tokenizing train dataset:  34%|███▍      | 2277/6690 [00:04<00:09, 464.29 examples/s]Tokenizing train dataset:  35%|███▍      | 2309/6690 [00:05<00:09, 448.58 examples/s]Tokenizing train dataset:  35%|███▌      | 2347/6690 [00:05<00:09, 454.27 examples/s]Tokenizing train dataset:  35%|███▌      | 2343/6690 [00:05<00:09, 451.11 examples/s]Tokenizing train dataset:  35%|███▌      | 2360/6690 [00:05<00:09, 458.13 examples/s]Tokenizing train dataset:  36%|███▌      | 2395/6690 [00:05<00:09, 459.05 examples/s]Tokenizing train dataset:  36%|███▌      | 2391/6690 [00:05<00:09, 454.60 examples/s]Tokenizing train dataset:  36%|███▋      | 2426/6690 [00:05<00:09, 450.33 examples/s]Tokenizing train dataset:  37%|███▋      | 2469/6690 [00:05<00:09, 457.74 examples/s]Tokenizing train dataset:  37%|███▋      | 2462/6690 [00:05<00:09, 456.92 examples/s]Tokenizing train dataset:  37%|███▋      | 2476/6690 [00:05<00:09, 458.31 examples/s]Tokenizing train dataset:  38%|███▊      | 2543/6690 [00:05<00:08, 467.44 examples/s]Tokenizing train dataset:  37%|███▋      | 2508/6690 [00:05<00:09, 453.31 examples/s]Tokenizing train dataset:  38%|███▊      | 2524/6690 [00:05<00:09, 461.74 examples/s]Tokenizing train dataset:  39%|███▉      | 2595/6690 [00:05<00:08, 476.39 examples/s]Tokenizing train dataset:  38%|███▊      | 2560/6690 [00:05<00:08, 463.69 examples/s]Tokenizing train dataset:  39%|███▊      | 2580/6690 [00:05<00:08, 480.18 examples/s]Tokenizing train dataset:  39%|███▉      | 2611/6690 [00:05<00:08, 472.94 examples/s]Tokenizing train dataset:  39%|███▉      | 2629/6690 [00:05<00:08, 477.32 examples/s]Tokenizing train dataset:  40%|███▉      | 2658/6690 [00:05<00:08, 454.89 examples/s]Tokenizing train dataset:  40%|███▉      | 2675/6690 [00:05<00:08, 448.30 examples/s]Tokenizing train dataset:  40%|████      | 2694/6690 [00:05<00:08, 454.04 examples/s]Tokenizing train dataset:  41%|████      | 2724/6690 [00:05<00:08, 444.64 examples/s]Tokenizing train dataset:  41%|████      | 2740/6690 [00:06<00:09, 434.03 examples/s]Tokenizing train dataset:  41%|████      | 2756/6690 [00:06<00:09, 435.50 examples/s]Tokenizing train dataset:  42%|████▏     | 2787/6690 [00:06<00:09, 427.88 examples/s]Tokenizing train dataset:  42%|████▏     | 2833/6690 [00:06<00:08, 430.59 examples/s]Tokenizing train dataset:  42%|████▏     | 2803/6690 [00:06<00:09, 426.34 examples/s]Tokenizing train dataset:  42%|████▏     | 2816/6690 [00:06<00:09, 420.64 examples/s]Tokenizing train dataset:  43%|████▎     | 2878/6690 [00:06<00:08, 433.99 examples/s]Tokenizing train dataset:  43%|████▎     | 2847/6690 [00:06<00:08, 428.82 examples/s]Tokenizing train dataset:  43%|████▎     | 2867/6690 [00:06<00:08, 437.39 examples/s]Tokenizing train dataset:  44%|████▍     | 2930/6690 [00:06<00:08, 448.51 examples/s]Tokenizing train dataset:  43%|████▎     | 2894/6690 [00:06<00:08, 433.68 examples/s]Tokenizing train dataset:  44%|████▍     | 2930/6690 [00:06<00:08, 426.72 examples/s]Tokenizing train dataset:  45%|████▍     | 2981/6690 [00:06<00:08, 461.01 examples/s]Tokenizing train dataset:  44%|████▍     | 2947/6690 [00:06<00:08, 458.11 examples/s]Tokenizing train dataset:  45%|████▍     | 2981/6690 [00:06<00:08, 443.31 examples/s]Tokenizing train dataset:  45%|████▍     | 2996/6690 [00:06<00:07, 464.65 examples/s]Tokenizing train dataset:  45%|████▌     | 3033/6690 [00:06<00:07, 469.57 examples/s]Tokenizing train dataset:  45%|████▌     | 3033/6690 [00:06<00:08, 456.35 examples/s]Tokenizing train dataset:  46%|████▌     | 3045/6690 [00:06<00:07, 469.35 examples/s]Tokenizing train dataset:  46%|████▌     | 3090/6690 [00:06<00:07, 492.69 examples/s]Tokenizing train dataset:  46%|████▌     | 3090/6690 [00:06<00:07, 482.21 examples/s]Tokenizing train dataset:  46%|████▋     | 3100/6690 [00:06<00:07, 490.03 examples/s]Tokenizing train dataset:  47%|████▋     | 3156/6690 [00:06<00:07, 468.77 examples/s]Tokenizing train dataset:  47%|████▋     | 3154/6690 [00:06<00:07, 461.27 examples/s]Tokenizing train dataset:  47%|████▋     | 3165/6690 [00:06<00:07, 463.50 examples/s]Tokenizing train dataset:  48%|████▊     | 3228/6690 [00:07<00:07, 467.57 examples/s]Tokenizing train dataset:  48%|████▊     | 3224/6690 [00:07<00:07, 461.30 examples/s]Tokenizing train dataset:  48%|████▊     | 3240/6690 [00:07<00:07, 468.28 examples/s]Tokenizing train dataset:  49%|████▉     | 3276/6690 [00:07<00:07, 465.82 examples/s]Tokenizing train dataset:  49%|████▉     | 3273/6690 [00:07<00:07, 465.16 examples/s]Tokenizing train dataset:  49%|████▉     | 3301/6690 [00:07<00:07, 444.50 examples/s]Tokenizing train dataset:  50%|████▉     | 3333/6690 [00:07<00:07, 432.15 examples/s]Tokenizing train dataset:  50%|████▉     | 3331/6690 [00:07<00:07, 434.41 examples/s]Tokenizing train dataset:  50%|█████     | 3378/6690 [00:07<00:07, 433.83 examples/s]Tokenizing train dataset:  50%|█████     | 3363/6690 [00:07<00:07, 430.54 examples/s]Tokenizing train dataset:  50%|█████     | 3376/6690 [00:07<00:07, 434.67 examples/s]Tokenizing train dataset:  51%|█████▏    | 3437/6690 [00:07<00:07, 418.00 examples/s]Tokenizing train dataset:  51%|█████     | 3422/6690 [00:07<00:07, 416.89 examples/s]Tokenizing train dataset:  51%|█████▏    | 3437/6690 [00:07<00:07, 417.89 examples/s]Tokenizing train dataset:  52%|█████▏    | 3483/6690 [00:07<00:07, 425.09 examples/s]Tokenizing train dataset:  52%|█████▏    | 3483/6690 [00:07<00:07, 424.82 examples/s]Tokenizing train dataset:  52%|█████▏    | 3490/6690 [00:07<00:07, 422.60 examples/s]Tokenizing train dataset:  53%|█████▎    | 3543/6690 [00:07<00:07, 411.19 examples/s]Tokenizing train dataset:  53%|█████▎    | 3543/6690 [00:07<00:07, 410.86 examples/s]Tokenizing train dataset:  53%|█████▎    | 3549/6690 [00:07<00:07, 409.35 examples/s]Tokenizing train dataset:  54%|█████▍    | 3600/6690 [00:07<00:07, 398.16 examples/s]Tokenizing train dataset:  54%|█████▍    | 3600/6690 [00:07<00:07, 398.12 examples/s]Tokenizing train dataset:  54%|█████▍    | 3645/6690 [00:08<00:07, 409.58 examples/s]Tokenizing train dataset:  54%|█████▍    | 3608/6690 [00:08<00:07, 400.05 examples/s]Tokenizing train dataset:  54%|█████▍    | 3646/6690 [00:08<00:07, 411.24 examples/s]Tokenizing train dataset:  55%|█████▍    | 3653/6690 [00:08<00:07, 408.61 examples/s]Tokenizing train dataset:  55%|█████▌    | 3690/6690 [00:08<00:07, 413.35 examples/s]Tokenizing train dataset:  55%|█████▌    | 3690/6690 [00:08<00:07, 413.12 examples/s]Tokenizing train dataset:  55%|█████▌    | 3699/6690 [00:08<00:07, 417.11 examples/s]Tokenizing train dataset:  56%|█████▌    | 3749/6690 [00:08<00:07, 399.51 examples/s]Tokenizing train dataset:  56%|█████▌    | 3749/6690 [00:08<00:07, 398.59 examples/s]Tokenizing train dataset:  56%|█████▌    | 3754/6690 [00:08<00:07, 393.20 examples/s]Tokenizing train dataset:  57%|█████▋    | 3795/6690 [00:08<00:07, 411.20 examples/s]Tokenizing train dataset:  57%|█████▋    | 3795/6690 [00:08<00:07, 410.58 examples/s]Tokenizing train dataset:  57%|█████▋    | 3841/6690 [00:08<00:06, 422.26 examples/s]Tokenizing train dataset:  57%|█████▋    | 3799/6690 [00:08<00:07, 404.78 examples/s]Tokenizing train dataset:  57%|█████▋    | 3841/6690 [00:08<00:06, 422.01 examples/s]Tokenizing train dataset:  57%|█████▋    | 3845/6690 [00:08<00:06, 416.63 examples/s]Tokenizing train dataset:  58%|█████▊    | 3891/6690 [00:08<00:06, 433.88 examples/s]Tokenizing train dataset:  58%|█████▊    | 3891/6690 [00:08<00:06, 433.86 examples/s]Tokenizing train dataset:  58%|█████▊    | 3893/6690 [00:08<00:06, 431.12 examples/s]Tokenizing train dataset:  59%|█████▉    | 3941/6690 [00:08<00:06, 448.02 examples/s]Tokenizing train dataset:  59%|█████▉    | 3941/6690 [00:08<00:06, 447.89 examples/s]Tokenizing train dataset:  59%|█████▉    | 3943/6690 [00:08<00:06, 445.61 examples/s]Tokenizing train dataset:  60%|█████▉    | 3990/6690 [00:08<00:05, 456.20 examples/s]Tokenizing train dataset:  60%|█████▉    | 3990/6690 [00:08<00:05, 455.92 examples/s]Tokenizing train dataset:  60%|█████▉    | 3992/6690 [00:08<00:05, 455.03 examples/s]Tokenizing train dataset:  60%|██████    | 4036/6690 [00:08<00:05, 452.90 examples/s]Tokenizing train dataset:  60%|██████    | 4036/6690 [00:08<00:05, 452.49 examples/s]Tokenizing train dataset:  61%|██████    | 4060/6690 [00:09<00:05, 446.71 examples/s]Tokenizing train dataset:  61%|██████▏   | 4103/6690 [00:09<00:05, 446.06 examples/s]Tokenizing train dataset:  61%|██████▏   | 4103/6690 [00:09<00:05, 445.47 examples/s]Tokenizing train dataset:  62%|██████▏   | 4151/6690 [00:09<00:05, 449.36 examples/s]Tokenizing train dataset:  62%|██████▏   | 4127/6690 [00:09<00:05, 442.41 examples/s]Tokenizing train dataset:  62%|██████▏   | 4151/6690 [00:09<00:05, 449.08 examples/s]Tokenizing train dataset:  63%|██████▎   | 4200/6690 [00:09<00:05, 457.28 examples/s]Tokenizing train dataset:  62%|██████▏   | 4178/6690 [00:09<00:05, 454.86 examples/s]Tokenizing train dataset:  63%|██████▎   | 4200/6690 [00:09<00:05, 456.99 examples/s]Tokenizing train dataset:  64%|██████▍   | 4265/6690 [00:09<00:05, 446.41 examples/s]Tokenizing train dataset:  63%|██████▎   | 4246/6690 [00:09<00:05, 452.46 examples/s]Tokenizing train dataset:  64%|██████▍   | 4265/6690 [00:09<00:05, 446.37 examples/s]Tokenizing train dataset:  64%|██████▍   | 4313/6690 [00:09<00:05, 451.61 examples/s]Tokenizing train dataset:  64%|██████▍   | 4313/6690 [00:09<00:05, 451.53 examples/s]Tokenizing train dataset:  64%|██████▍   | 4314/6690 [00:09<00:05, 447.59 examples/s]Tokenizing train dataset:  65%|██████▌   | 4376/6690 [00:09<00:05, 432.16 examples/s]Tokenizing train dataset:  65%|██████▌   | 4376/6690 [00:09<00:05, 431.89 examples/s]Tokenizing train dataset:  65%|██████▌   | 4376/6690 [00:09<00:05, 430.24 examples/s]Tokenizing train dataset:  66%|██████▌   | 4423/6690 [00:09<00:05, 436.65 examples/s]Tokenizing train dataset:  66%|██████▌   | 4423/6690 [00:09<00:05, 436.32 examples/s]Tokenizing train dataset:  66%|██████▌   | 4423/6690 [00:09<00:05, 434.18 examples/s]Tokenizing train dataset:  67%|██████▋   | 4489/6690 [00:09<00:05, 435.56 examples/s]Tokenizing train dataset:  67%|██████▋   | 4489/6690 [00:09<00:05, 435.29 examples/s]Tokenizing train dataset:  67%|██████▋   | 4489/6690 [00:10<00:05, 432.89 examples/s]Tokenizing train dataset:  68%|██████▊   | 4535/6690 [00:10<00:04, 437.52 examples/s]Tokenizing train dataset:  68%|██████▊   | 4535/6690 [00:10<00:04, 437.42 examples/s]Tokenizing train dataset:  68%|██████▊   | 4535/6690 [00:10<00:04, 434.61 examples/s]Tokenizing train dataset:  69%|██████▊   | 4584/6690 [00:10<00:04, 445.35 examples/s]Tokenizing train dataset:  69%|██████▊   | 4584/6690 [00:10<00:04, 445.55 examples/s]Tokenizing train dataset:  69%|██████▊   | 4584/6690 [00:10<00:04, 442.40 examples/s]Tokenizing train dataset:  69%|██████▉   | 4635/6690 [00:10<00:04, 453.90 examples/s]Tokenizing train dataset:  69%|██████▉   | 4635/6690 [00:10<00:04, 454.23 examples/s]Tokenizing train dataset:  70%|██████▉   | 4682/6690 [00:10<00:04, 457.38 examples/s]Tokenizing train dataset:  69%|██████▉   | 4635/6690 [00:10<00:04, 451.02 examples/s]Tokenizing train dataset:  70%|██████▉   | 4682/6690 [00:10<00:04, 457.65 examples/s]Tokenizing train dataset:  71%|███████   | 4730/6690 [00:10<00:04, 462.58 examples/s]Tokenizing train dataset:  70%|██████▉   | 4681/6690 [00:10<00:04, 452.50 examples/s]Tokenizing train dataset:  71%|███████   | 4731/6690 [00:10<00:04, 460.70 examples/s]Tokenizing train dataset:  71%|███████   | 4730/6690 [00:10<00:04, 459.94 examples/s]Tokenizing train dataset:  72%|███████▏  | 4790/6690 [00:10<00:04, 432.07 examples/s]Tokenizing train dataset:  72%|███████▏  | 4791/6690 [00:10<00:04, 432.62 examples/s]Tokenizing train dataset:  72%|███████▏  | 4788/6690 [00:10<00:04, 431.10 examples/s]Tokenizing train dataset:  72%|███████▏  | 4840/6690 [00:10<00:04, 446.22 examples/s]Tokenizing train dataset:  72%|███████▏  | 4842/6690 [00:10<00:04, 447.68 examples/s]Tokenizing train dataset:  72%|███████▏  | 4838/6690 [00:10<00:04, 444.45 examples/s]Tokenizing train dataset:  73%|███████▎  | 4905/6690 [00:10<00:04, 437.04 examples/s]Tokenizing train dataset:  73%|███████▎  | 4906/6690 [00:10<00:04, 435.40 examples/s]Tokenizing train dataset:  73%|███████▎  | 4902/6690 [00:10<00:04, 435.42 examples/s]Tokenizing train dataset:  74%|███████▍  | 4951/6690 [00:10<00:03, 440.58 examples/s]Tokenizing train dataset:  74%|███████▍  | 4952/6690 [00:11<00:03, 437.15 examples/s]Tokenizing train dataset:  74%|███████▍  | 4947/6690 [00:11<00:04, 435.25 examples/s]Tokenizing train dataset:  75%|███████▍  | 5017/6690 [00:11<00:03, 431.69 examples/s]Tokenizing train dataset:  75%|███████▍  | 4997/6690 [00:11<00:03, 436.30 examples/s]Tokenizing train dataset:  75%|███████▍  | 5011/6690 [00:11<00:03, 427.69 examples/s]Tokenizing train dataset:  76%|███████▌  | 5082/6690 [00:11<00:03, 423.86 examples/s]Tokenizing train dataset:  76%|███████▌  | 5060/6690 [00:11<00:03, 426.13 examples/s]Tokenizing train dataset:  76%|███████▌  | 5075/6690 [00:11<00:03, 425.65 examples/s]Tokenizing train dataset:  76%|███████▋  | 5104/6690 [00:11<00:03, 427.98 examples/s]Tokenizing train dataset:  77%|███████▋  | 5147/6690 [00:11<00:03, 423.43 examples/s]Tokenizing train dataset:  77%|███████▋  | 5139/6690 [00:11<00:03, 420.17 examples/s]Tokenizing train dataset:  78%|███████▊  | 5210/6690 [00:11<00:03, 414.86 examples/s]Tokenizing train dataset:  77%|███████▋  | 5172/6690 [00:11<00:03, 384.42 examples/s]Tokenizing train dataset:  78%|███████▊  | 5186/6690 [00:11<00:03, 431.22 examples/s]Tokenizing train dataset:  79%|███████▊  | 5255/6690 [00:11<00:03, 420.99 examples/s]Tokenizing train dataset:  78%|███████▊  | 5219/6690 [00:11<00:03, 400.80 examples/s]Tokenizing train dataset:  78%|███████▊  | 5230/6690 [00:11<00:03, 426.81 examples/s]Tokenizing train dataset:  79%|███████▊  | 5264/6690 [00:11<00:03, 409.19 examples/s]Tokenizing train dataset:  79%|███████▉  | 5276/6690 [00:11<00:03, 433.80 examples/s]Tokenizing train dataset:  79%|███████▉  | 5316/6690 [00:11<00:03, 415.02 examples/s]Tokenizing train dataset:  79%|███████▉  | 5307/6690 [00:11<00:03, 410.41 examples/s]Tokenizing train dataset:  80%|████████  | 5367/6690 [00:11<00:03, 435.04 examples/s]Tokenizing train dataset:  80%|███████▉  | 5338/6690 [00:12<00:03, 422.56 examples/s]Tokenizing train dataset:  80%|███████▉  | 5350/6690 [00:11<00:03, 413.16 examples/s]Tokenizing train dataset:  81%|████████  | 5415/6690 [00:12<00:02, 442.87 examples/s]Tokenizing train dataset:  81%|████████  | 5392/6690 [00:12<00:02, 450.44 examples/s]Tokenizing train dataset:  81%|████████  | 5404/6690 [00:12<00:02, 444.71 examples/s]Tokenizing train dataset:  82%|████████▏ | 5460/6690 [00:12<00:02, 439.63 examples/s]Tokenizing train dataset:  82%|████████▏ | 5460/6690 [00:12<00:02, 442.39 examples/s]Tokenizing train dataset:  82%|████████▏ | 5469/6690 [00:12<00:02, 435.66 examples/s]Tokenizing train dataset:  83%|████████▎ | 5526/6690 [00:12<00:02, 437.12 examples/s]Tokenizing train dataset:  82%|████████▏ | 5515/6690 [00:12<00:02, 440.47 examples/s]Tokenizing train dataset:  83%|████████▎ | 5526/6690 [00:12<00:02, 438.42 examples/s]Tokenizing train dataset:  84%|████████▎ | 5590/6690 [00:12<00:02, 426.61 examples/s]Tokenizing train dataset:  83%|████████▎ | 5579/6690 [00:12<00:02, 433.24 examples/s]Tokenizing train dataset:  84%|████████▎ | 5590/6690 [00:12<00:02, 426.99 examples/s]Tokenizing train dataset:  84%|████████▍ | 5639/6690 [00:12<00:02, 437.43 examples/s]Tokenizing train dataset:  84%|████████▍ | 5639/6690 [00:12<00:02, 436.77 examples/s]Tokenizing train dataset:  84%|████████▍ | 5645/6690 [00:12<00:02, 429.98 examples/s]Tokenizing train dataset:  85%|████████▌ | 5703/6690 [00:12<00:02, 429.29 examples/s]Tokenizing train dataset:  85%|████████▌ | 5690/6690 [00:12<00:02, 429.77 examples/s]Tokenizing train dataset:  85%|████████▌ | 5702/6690 [00:12<00:02, 428.96 examples/s]Tokenizing train dataset:  86%|████████▌ | 5753/6690 [00:12<00:02, 445.41 examples/s]Tokenizing train dataset:  86%|████████▌ | 5738/6690 [00:12<00:02, 437.51 examples/s]Tokenizing train dataset:  86%|████████▌ | 5751/6690 [00:12<00:02, 441.21 examples/s]Tokenizing train dataset:  87%|████████▋ | 5820/6690 [00:13<00:01, 437.27 examples/s]Tokenizing train dataset:  86%|████████▋ | 5784/6690 [00:12<00:02, 438.34 examples/s]Tokenizing train dataset:  87%|████████▋ | 5817/6690 [00:13<00:01, 438.72 examples/s]Tokenizing train dataset:  88%|████████▊ | 5880/6690 [00:13<00:01, 421.70 examples/s]Tokenizing train dataset:  87%|████████▋ | 5848/6690 [00:13<00:01, 428.03 examples/s]Tokenizing train dataset:  88%|████████▊ | 5875/6690 [00:13<00:01, 419.06 examples/s]Tokenizing train dataset:  89%|████████▊ | 5932/6690 [00:13<00:01, 440.29 examples/s]Tokenizing train dataset:  88%|████████▊ | 5895/6690 [00:13<00:01, 436.32 examples/s]Tokenizing train dataset:  89%|████████▊ | 5926/6690 [00:13<00:01, 436.97 examples/s]Tokenizing train dataset:  89%|████████▉ | 5943/6690 [00:13<00:01, 441.58 examples/s]Tokenizing train dataset:  90%|████████▉ | 6001/6690 [00:13<00:01, 440.91 examples/s]Tokenizing train dataset:  89%|████████▉ | 5973/6690 [00:13<00:01, 439.21 examples/s]Tokenizing train dataset:  90%|█████████ | 6046/6690 [00:13<00:01, 438.69 examples/s]Tokenizing train dataset:  90%|████████▉ | 6010/6690 [00:13<00:01, 441.73 examples/s]Tokenizing train dataset:  90%|████████▉ | 6018/6690 [00:13<00:01, 441.10 examples/s]Tokenizing train dataset:  91%|█████████ | 6100/6690 [00:13<00:01, 461.10 examples/s]Tokenizing train dataset:  91%|█████████ | 6055/6690 [00:13<00:01, 441.72 examples/s]Tokenizing train dataset:  91%|█████████ | 6090/6690 [00:13<00:01, 448.61 examples/s]Tokenizing train dataset:  92%|█████████▏| 6152/6690 [00:13<00:01, 467.20 examples/s]Tokenizing train dataset:  91%|█████████▏| 6108/6690 [00:13<00:01, 463.57 examples/s]Tokenizing train dataset:  92%|█████████▏| 6142/6690 [00:13<00:01, 464.34 examples/s]Tokenizing train dataset:  92%|█████████▏| 6155/6690 [00:13<00:01, 462.38 examples/s]Tokenizing train dataset:  93%|█████████▎| 6216/6690 [00:13<00:01, 445.51 examples/s]Tokenizing train dataset:  93%|█████████▎| 6206/6690 [00:13<00:01, 448.44 examples/s]Tokenizing train dataset:  93%|█████████▎| 6219/6690 [00:13<00:01, 446.96 examples/s]Tokenizing train dataset:  94%|█████████▍| 6276/6690 [00:14<00:00, 422.98 examples/s]Tokenizing train dataset:  94%|█████████▎| 6260/6690 [00:14<00:01, 410.32 examples/s]Tokenizing train dataset:  94%|█████████▍| 6320/6690 [00:14<00:00, 425.39 examples/s]Tokenizing train dataset:  94%|█████████▍| 6277/6690 [00:14<00:00, 421.96 examples/s]Tokenizing train dataset:  94%|█████████▍| 6309/6690 [00:14<00:00, 428.01 examples/s]Tokenizing train dataset:  94%|█████████▍| 6321/6690 [00:14<00:00, 422.60 examples/s]Tokenizing train dataset:  95%|█████████▌| 6380/6690 [00:14<00:00, 408.78 examples/s]Tokenizing train dataset:  95%|█████████▌| 6369/6690 [00:14<00:00, 412.59 examples/s]Tokenizing train dataset:  96%|█████████▌| 6431/6690 [00:14<00:00, 430.89 examples/s]Tokenizing train dataset:  95%|█████████▌| 6381/6690 [00:14<00:00, 409.07 examples/s]Tokenizing train dataset:  96%|█████████▌| 6414/6690 [00:14<00:00, 420.15 examples/s]Tokenizing train dataset:  96%|█████████▌| 6431/6690 [00:14<00:00, 430.13 examples/s]Tokenizing train dataset:  97%|█████████▋| 6496/6690 [00:14<00:00, 431.28 examples/s]Tokenizing train dataset:  97%|█████████▋| 6459/6690 [00:14<00:00, 424.55 examples/s]Tokenizing train dataset:  98%|█████████▊| 6540/6690 [00:14<00:00, 428.76 examples/s]Tokenizing train dataset:  97%|█████████▋| 6497/6690 [00:14<00:00, 429.19 examples/s]Tokenizing train dataset:  97%|█████████▋| 6503/6690 [00:14<00:00, 427.72 examples/s]Tokenizing train dataset:  98%|█████████▊| 6584/6690 [00:14<00:00, 430.97 examples/s]Tokenizing train dataset:  98%|█████████▊| 6541/6690 [00:14<00:00, 428.79 examples/s]Tokenizing train dataset:  98%|█████████▊| 6548/6690 [00:14<00:00, 430.01 examples/s]Tokenizing train dataset:  98%|█████████▊| 6587/6690 [00:14<00:00, 433.34 examples/s]Tokenizing train dataset:  99%|█████████▉| 6644/6690 [00:14<00:00, 416.43 examples/s]Tokenizing train dataset:  99%|█████████▉| 6609/6690 [00:14<00:00, 418.18 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 420.68 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 444.67 examples/s]
Tokenizing train dataset:  99%|█████████▉| 6648/6690 [00:14<00:00, 416.74 examples/s]Tokenizing train dataset: 100%|█████████▉| 6670/6690 [00:15<00:00, 409.21 examples/s]Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 443.39 examples/s]
Tokenizing train dataset: 100%|██████████| 6690/6690 [00:15<00:00, 441.72 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5561.00 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5544.03 examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5535.72 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5554.31 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5544.86 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5534.37 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  31%|███▏      | 298/953 [00:00<00:00, 2954.83 examples/s]Applying chat template to eval dataset:  32%|███▏      | 301/953 [00:00<00:00, 2982.98 examples/s]Applying chat template to eval dataset:  32%|███▏      | 302/953 [00:00<00:00, 2988.06 examples/s]Applying chat template to eval dataset:  75%|███████▍  | 710/953 [00:00<00:00, 2800.09 examples/s]Applying chat template to eval dataset:  76%|███████▌  | 724/953 [00:00<00:00, 2865.97 examples/s]Applying chat template to eval dataset:  76%|███████▌  | 726/953 [00:00<00:00, 2873.55 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2838.14 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2764.56 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2843.21 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 263.87 examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 264.94 examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 263.20 examples/s]Tokenizing eval dataset:   7%|▋         | 63/953 [00:00<00:03, 238.11 examples/s]Tokenizing eval dataset:   7%|▋         | 63/953 [00:00<00:03, 238.69 examples/s]Tokenizing eval dataset:   7%|▋         | 63/953 [00:00<00:03, 238.70 examples/s]Tokenizing eval dataset:   9%|▉         | 90/953 [00:00<00:03, 246.89 examples/s]Tokenizing eval dataset:   9%|▉         | 90/953 [00:00<00:03, 247.82 examples/s]Tokenizing eval dataset:   9%|▉         | 90/953 [00:00<00:03, 247.20 examples/s]Tokenizing eval dataset:  13%|█▎        | 123/953 [00:00<00:03, 230.67 examples/s]Tokenizing eval dataset:  13%|█▎        | 124/953 [00:00<00:03, 231.53 examples/s]Tokenizing eval dataset:  13%|█▎        | 123/953 [00:00<00:03, 231.21 examples/s]Tokenizing eval dataset:  16%|█▌        | 148/953 [00:00<00:03, 229.49 examples/s]Tokenizing eval dataset:  16%|█▋        | 157/953 [00:00<00:03, 225.84 examples/s]Tokenizing eval dataset:  16%|█▋        | 157/953 [00:00<00:03, 225.58 examples/s]Tokenizing eval dataset:  19%|█▉        | 179/953 [00:00<00:03, 217.03 examples/s]Tokenizing eval dataset:  20%|█▉        | 187/953 [00:00<00:03, 213.03 examples/s]Tokenizing eval dataset:  20%|█▉        | 187/953 [00:00<00:03, 212.79 examples/s]Tokenizing eval dataset:  22%|██▏       | 210/953 [00:00<00:03, 215.11 examples/s]Tokenizing eval dataset:  22%|██▏       | 212/953 [00:00<00:03, 216.74 examples/s]Tokenizing eval dataset:  22%|██▏       | 210/953 [00:00<00:03, 214.65 examples/s]Tokenizing eval dataset:  27%|██▋       | 255/953 [00:01<00:02, 275.06 examples/s]Tokenizing eval dataset:  27%|██▋       | 259/953 [00:01<00:02, 278.77 examples/s]Tokenizing eval dataset:  27%|██▋       | 256/953 [00:01<00:02, 276.50 examples/s]Tokenizing eval dataset:  33%|███▎      | 310/953 [00:01<00:01, 348.59 examples/s]Tokenizing eval dataset:  33%|███▎      | 317/953 [00:01<00:01, 354.99 examples/s]Tokenizing eval dataset:  33%|███▎      | 311/953 [00:01<00:01, 348.04 examples/s]Tokenizing eval dataset:  38%|███▊      | 363/953 [00:01<00:01, 393.94 examples/s]Tokenizing eval dataset:  38%|███▊      | 366/953 [00:01<00:01, 390.10 examples/s]Tokenizing eval dataset:  38%|███▊      | 364/953 [00:01<00:01, 395.29 examples/s]Tokenizing eval dataset:  44%|████▍     | 419/953 [00:01<00:01, 437.45 examples/s]Tokenizing eval dataset:  44%|████▍     | 422/953 [00:01<00:01, 434.85 examples/s]Tokenizing eval dataset:  44%|████▍     | 419/953 [00:01<00:01, 436.79 examples/s]Tokenizing eval dataset:  50%|█████     | 477/953 [00:01<00:01, 475.24 examples/s]Tokenizing eval dataset:  50%|█████     | 479/953 [00:01<00:01, 471.08 examples/s]Tokenizing eval dataset:  50%|█████     | 477/953 [00:01<00:01, 474.84 examples/s]Tokenizing eval dataset:  56%|█████▌    | 530/953 [00:01<00:00, 487.31 examples/s]Tokenizing eval dataset:  56%|█████▌    | 534/953 [00:01<00:00, 489.78 examples/s]Tokenizing eval dataset:  56%|█████▌    | 530/953 [00:01<00:00, 485.98 examples/s]Tokenizing eval dataset:  62%|██████▏   | 593/953 [00:01<00:00, 516.77 examples/s]Tokenizing eval dataset:  62%|██████▏   | 590/953 [00:01<00:00, 513.05 examples/s]Tokenizing eval dataset:  62%|██████▏   | 590/953 [00:01<00:00, 511.96 examples/s]Tokenizing eval dataset:  68%|██████▊   | 644/953 [00:01<00:00, 519.00 examples/s]Tokenizing eval dataset:  68%|██████▊   | 647/953 [00:01<00:00, 519.21 examples/s]Tokenizing eval dataset:  68%|██████▊   | 644/953 [00:01<00:00, 517.32 examples/s]Tokenizing eval dataset:  73%|███████▎  | 697/953 [00:01<00:00, 511.33 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:01<00:00, 514.20 examples/s]Tokenizing eval dataset:  76%|███████▌  | 723/953 [00:01<00:00, 515.89 examples/s]Tokenizing eval dataset:  81%|████████  | 769/953 [00:02<00:00, 495.69 examples/s]Tokenizing eval dataset:  83%|████████▎ | 787/953 [00:02<00:00, 477.78 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:02<00:00, 475.37 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:02<00:00, 460.97 examples/s]Tokenizing eval dataset:  89%|████████▉ | 851/953 [00:02<00:00, 455.96 examples/s]Tokenizing eval dataset:  89%|████████▉ | 850/953 [00:02<00:00, 455.32 examples/s]Tokenizing eval dataset:  94%|█████████▍| 894/953 [00:02<00:00, 444.04 examples/s]Tokenizing eval dataset:  96%|█████████▌| 913/953 [00:02<00:00, 440.18 examples/s]Tokenizing eval dataset:  96%|█████████▌| 913/953 [00:02<00:00, 437.82 examples/s]Tokenizing eval dataset:  99%|█████████▊| 941/953 [00:02<00:00, 448.63 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 389.76 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 387.98 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 387.47 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.463407278060913 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3566489219665527 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3373146057128906 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.344438314437866 seconds
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Training complete
Saving model
[rank8]:[W612 23:15:49.361099546 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 2 ---
