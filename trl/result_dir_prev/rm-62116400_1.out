cpu-bind=MASK - gn60, task  1  0 [974225]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn56
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 1     --main_process_ip gn56     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62116400     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-31 12:04:37,853] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0531 12:04:39.678000 974278 torch/distributed/run.py:792] 
W0531 12:04:39.678000 974278 torch/distributed/run.py:792] *****************************************
W0531 12:04:39.678000 974278 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0531 12:04:39.678000 974278 torch/distributed/run.py:792] *****************************************
[2025-05-31 12:04:44,701] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 12:04:44,715] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 12:04:44,760] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 12:04:44,770] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 2
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
[2025-05-31 12:04:47,997] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 4282
Eval steps: 2141
[2025-05-31 12:04:48,049] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 12:04:48,054] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 12:04:48,056] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:06, 22.01s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:07, 22.42s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:07, 22.42s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:22<01:07, 22.42s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:43<00:43, 21.84s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:44<00:44, 22.01s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:44<00:43, 21.95s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:44<00:43, 21.94s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:05<00:21, 21.83s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:05<00:21, 21.96s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:05<00:21, 21.92s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:05<00:21, 21.92s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:21<00:00, 19.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:21<00:00, 20.47s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 4/4 [01:22<00:00, 19.68s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:22<00:00, 19.70s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:22<00:00, 19.72s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:22<00:00, 20.54s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:22<00:00, 20.54s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:22<00:00, 20.54s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
[rank5]:[W531 12:06:17.381726187 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
[rank6]:[W531 12:06:17.424752599 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   7%|▋         | 570/8564 [00:00<00:01, 5588.47 examples/s][rank7]:[W531 12:06:17.620601972 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:  13%|█▎        | 1150/8564 [00:00<00:01, 5674.08 examples/s]Extracting prompt in train dataset:  20%|██        | 1723/8564 [00:00<00:01, 5698.90 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2308/8564 [00:00<00:01, 5756.90 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2892/8564 [00:00<00:00, 5767.16 examples/s]Extracting prompt in train dataset:  44%|████▎     | 3740/8564 [00:00<00:00, 5695.63 examples/s]Extracting prompt in train dataset:  51%|█████     | 4327/8564 [00:00<00:00, 5745.15 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4910/8564 [00:00<00:00, 5762.53 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5510/8564 [00:00<00:00, 5823.67 examples/s]Extracting prompt in train dataset:  71%|███████▏  | 6110/8564 [00:01<00:00, 5867.01 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6710/8564 [00:01<00:00, 5895.83 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7310/8564 [00:01<00:00, 5912.99 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8130/8564 [00:01<00:00, 5719.32 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5719.37 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 289/8564 [00:00<00:02, 2862.58 examples/s]Applying chat template to train dataset:   7%|▋         | 602/8564 [00:00<00:02, 3012.57 examples/s]Applying chat template to train dataset:  11%|█         | 916/8564 [00:00<00:02, 3067.60 examples/s]Applying chat template to train dataset:  14%|█▍        | 1230/8564 [00:00<00:02, 3092.23 examples/s]Applying chat template to train dataset:  18%|█▊        | 1540/8564 [00:00<00:02, 3091.59 examples/s]Applying chat template to train dataset:  22%|██▏       | 1855/8564 [00:00<00:02, 3110.50 examples/s]Applying chat template to train dataset:  25%|██▌       | 2172/8564 [00:00<00:02, 3126.98 examples/s]Applying chat template to train dataset:  29%|██▉       | 2490/8564 [00:00<00:01, 3140.00 examples/s]Applying chat template to train dataset:  33%|███▎      | 2810/8564 [00:00<00:01, 3148.03 examples/s]Applying chat template to train dataset:  38%|███▊      | 3270/8564 [00:01<00:01, 3104.12 examples/s]Applying chat template to train dataset:  42%|████▏     | 3587/8564 [00:01<00:01, 3118.98 examples/s]Applying chat template to train dataset:  46%|████▌     | 3903/8564 [00:01<00:01, 3127.31 examples/s]Applying chat template to train dataset:  49%|████▉     | 4220/8564 [00:01<00:01, 3134.33 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4537/8564 [00:01<00:01, 3140.94 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4853/8564 [00:01<00:01, 3142.00 examples/s]Applying chat template to train dataset:  60%|██████    | 5176/8564 [00:01<00:01, 3167.59 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5500/8564 [00:01<00:00, 3182.59 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5825/8564 [00:01<00:00, 3198.43 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6147/8564 [00:01<00:00, 3203.36 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6470/8564 [00:02<00:00, 3207.63 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6793/8564 [00:02<00:00, 3211.36 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7117/8564 [00:02<00:00, 3216.28 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7440/8564 [00:02<00:00, 3218.03 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7910/8564 [00:02<00:00, 3125.57 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8233/8564 [00:02<00:00, 3150.25 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8557/8564 [00:02<00:00, 3172.77 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3141.41 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:20, 408.05 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:24, 340.95 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:26, 322.53 examples/s]Tokenizing train dataset:   2%|▏         | 184/8564 [00:00<00:27, 309.98 examples/s]Tokenizing train dataset:   3%|▎         | 220/8564 [00:00<00:29, 281.63 examples/s]Tokenizing train dataset:   3%|▎         | 254/8564 [00:00<00:28, 294.81 examples/s]Tokenizing train dataset:   3%|▎         | 291/8564 [00:00<00:26, 313.21 examples/s]Tokenizing train dataset:   4%|▍         | 325/8564 [00:01<00:26, 316.25 examples/s]Tokenizing train dataset:   4%|▍         | 372/8564 [00:01<00:26, 311.18 examples/s]Tokenizing train dataset:   5%|▍         | 404/8564 [00:01<00:26, 309.70 examples/s]Tokenizing train dataset:   5%|▌         | 437/8564 [00:01<00:26, 312.26 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:25, 312.38 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:01<00:26, 301.40 examples/s]Tokenizing train dataset:   6%|▋         | 549/8564 [00:01<00:25, 317.04 examples/s]Tokenizing train dataset:   7%|▋         | 596/8564 [00:01<00:25, 307.82 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:02<00:24, 323.32 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:02<00:25, 314.28 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:02<00:25, 312.47 examples/s]Tokenizing train dataset:   9%|▉         | 762/8564 [00:02<00:24, 314.31 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:02<00:25, 300.39 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:02<00:26, 294.88 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:02<00:25, 302.98 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:02<00:24, 308.30 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:03<00:24, 306.42 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:03<00:25, 302.02 examples/s]Tokenizing train dataset:  12%|█▏        | 1027/8564 [00:03<00:25, 292.34 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:03<00:25, 294.00 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:03<00:24, 307.51 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:03<00:25, 295.04 examples/s]Tokenizing train dataset:  14%|█▍        | 1183/8564 [00:03<00:24, 295.49 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:03<00:24, 303.97 examples/s]Tokenizing train dataset:  15%|█▍        | 1252/8564 [00:04<00:23, 312.22 examples/s]Tokenizing train dataset:  15%|█▌        | 1286/8564 [00:04<00:23, 309.90 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:04<00:22, 316.92 examples/s]Tokenizing train dataset:  16%|█▌        | 1353/8564 [00:04<00:23, 313.48 examples/s]Tokenizing train dataset:  16%|█▋        | 1397/8564 [00:04<00:23, 303.49 examples/s]Tokenizing train dataset:  17%|█▋        | 1428/8564 [00:04<00:23, 303.11 examples/s]Tokenizing train dataset:  17%|█▋        | 1473/8564 [00:04<00:23, 298.52 examples/s]Tokenizing train dataset:  18%|█▊        | 1515/8564 [00:04<00:24, 289.91 examples/s]Tokenizing train dataset:  18%|█▊        | 1550/8564 [00:05<00:23, 298.52 examples/s]Tokenizing train dataset:  18%|█▊        | 1581/8564 [00:05<00:23, 297.56 examples/s]Tokenizing train dataset:  19%|█▉        | 1614/8564 [00:05<00:22, 303.20 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:05<00:21, 315.97 examples/s]Tokenizing train dataset:  20%|█▉        | 1686/8564 [00:05<00:21, 321.65 examples/s]Tokenizing train dataset:  20%|██        | 1725/8564 [00:05<00:20, 333.58 examples/s]Tokenizing train dataset:  21%|██        | 1760/8564 [00:05<00:20, 337.16 examples/s]Tokenizing train dataset:  21%|██        | 1808/8564 [00:05<00:20, 323.24 examples/s]Tokenizing train dataset:  22%|██▏       | 1842/8564 [00:05<00:20, 324.35 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:06<00:21, 310.62 examples/s]Tokenizing train dataset:  23%|██▎       | 1931/8564 [00:06<00:19, 339.90 examples/s]Tokenizing train dataset:  23%|██▎       | 1967/8564 [00:06<00:19, 342.96 examples/s]Tokenizing train dataset:  23%|██▎       | 2003/8564 [00:06<00:18, 346.44 examples/s]Tokenizing train dataset:  24%|██▍       | 2043/8564 [00:06<00:18, 358.80 examples/s]Tokenizing train dataset:  24%|██▍       | 2080/8564 [00:06<00:18, 359.98 examples/s]Tokenizing train dataset:  25%|██▍       | 2120/8564 [00:06<00:17, 364.46 examples/s]Tokenizing train dataset:  25%|██▌       | 2157/8564 [00:06<00:17, 365.02 examples/s]Tokenizing train dataset:  26%|██▌       | 2194/8564 [00:06<00:17, 364.42 examples/s]Tokenizing train dataset:  26%|██▌       | 2232/8564 [00:07<00:17, 365.86 examples/s]Tokenizing train dataset:  27%|██▋       | 2272/8564 [00:07<00:16, 373.20 examples/s]Tokenizing train dataset:  27%|██▋       | 2328/8564 [00:07<00:16, 369.66 examples/s]Tokenizing train dataset:  28%|██▊       | 2380/8564 [00:07<00:17, 358.09 examples/s]Tokenizing train dataset:  28%|██▊       | 2421/8564 [00:07<00:16, 369.33 examples/s]Tokenizing train dataset:  29%|██▊       | 2461/8564 [00:07<00:16, 377.14 examples/s]Tokenizing train dataset:  29%|██▉       | 2511/8564 [00:07<00:16, 357.34 examples/s]Tokenizing train dataset:  30%|██▉       | 2555/8564 [00:07<00:16, 374.07 examples/s]Tokenizing train dataset:  30%|███       | 2594/8564 [00:08<00:15, 374.83 examples/s]Tokenizing train dataset:  31%|███       | 2642/8564 [00:08<00:16, 351.53 examples/s]Tokenizing train dataset:  31%|███▏      | 2693/8564 [00:08<00:17, 341.38 examples/s]Tokenizing train dataset:  32%|███▏      | 2731/8564 [00:08<00:16, 348.87 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:08<00:16, 348.32 examples/s]Tokenizing train dataset:  33%|███▎      | 2825/8564 [00:08<00:15, 360.00 examples/s]Tokenizing train dataset:  34%|███▎      | 2874/8564 [00:08<00:16, 345.73 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:08<00:15, 369.40 examples/s]Tokenizing train dataset:  35%|███▍      | 2961/8564 [00:09<00:14, 376.05 examples/s]Tokenizing train dataset:  35%|███▌      | 3005/8564 [00:09<00:14, 391.96 examples/s]Tokenizing train dataset:  36%|███▌      | 3057/8564 [00:09<00:14, 369.84 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:09<00:14, 374.15 examples/s]Tokenizing train dataset:  37%|███▋      | 3151/8564 [00:09<00:14, 366.29 examples/s]Tokenizing train dataset:  37%|███▋      | 3189/8564 [00:09<00:14, 363.05 examples/s]Tokenizing train dataset:  38%|███▊      | 3227/8564 [00:09<00:14, 367.09 examples/s]Tokenizing train dataset:  38%|███▊      | 3269/8564 [00:09<00:14, 374.80 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:10<00:14, 358.58 examples/s]Tokenizing train dataset:  39%|███▉      | 3357/8564 [00:10<00:14, 359.20 examples/s]Tokenizing train dataset:  40%|███▉      | 3397/8564 [00:10<00:14, 368.51 examples/s]Tokenizing train dataset:  40%|████      | 3437/8564 [00:10<00:13, 375.37 examples/s]Tokenizing train dataset:  41%|████      | 3491/8564 [00:10<00:13, 365.91 examples/s]Tokenizing train dataset:  41%|████▏     | 3533/8564 [00:10<00:13, 377.73 examples/s]Tokenizing train dataset:  42%|████▏     | 3583/8564 [00:10<00:21, 233.38 examples/s]Tokenizing train dataset:  42%|████▏     | 3623/8564 [00:11<00:18, 260.73 examples/s]Tokenizing train dataset:  43%|████▎     | 3659/8564 [00:11<00:17, 278.72 examples/s]Tokenizing train dataset:  43%|████▎     | 3693/8564 [00:11<00:16, 290.27 examples/s]Tokenizing train dataset:  44%|████▎     | 3732/8564 [00:11<00:15, 312.59 examples/s]Tokenizing train dataset:  44%|████▍     | 3771/8564 [00:11<00:14, 330.78 examples/s]Tokenizing train dataset:  44%|████▍     | 3808/8564 [00:11<00:13, 340.71 examples/s]Tokenizing train dataset:  45%|████▌     | 3861/8564 [00:11<00:13, 342.48 examples/s]Tokenizing train dataset:  46%|████▌     | 3897/8564 [00:11<00:13, 344.85 examples/s]Tokenizing train dataset:  46%|████▌     | 3950/8564 [00:12<00:13, 341.88 examples/s]Tokenizing train dataset:  47%|████▋     | 3987/8564 [00:12<00:13, 346.11 examples/s]Tokenizing train dataset:  47%|████▋     | 4028/8564 [00:12<00:12, 360.99 examples/s]Tokenizing train dataset:  47%|████▋     | 4065/8564 [00:12<00:12, 361.68 examples/s]Tokenizing train dataset:  48%|████▊     | 4120/8564 [00:12<00:12, 356.25 examples/s]Tokenizing train dataset:  49%|████▊     | 4172/8564 [00:12<00:12, 349.78 examples/s]Tokenizing train dataset:  49%|████▉     | 4212/8564 [00:12<00:12, 358.37 examples/s]Tokenizing train dataset:  50%|████▉     | 4266/8564 [00:12<00:12, 356.96 examples/s]Tokenizing train dataset:  50%|█████     | 4304/8564 [00:12<00:11, 359.52 examples/s]Tokenizing train dataset:  51%|█████     | 4359/8564 [00:13<00:11, 357.05 examples/s]Tokenizing train dataset:  51%|█████▏    | 4398/8564 [00:13<00:11, 362.82 examples/s]Tokenizing train dataset:  52%|█████▏    | 4435/8564 [00:13<00:11, 362.66 examples/s]Tokenizing train dataset:  52%|█████▏    | 4490/8564 [00:13<00:11, 362.19 examples/s]Tokenizing train dataset:  53%|█████▎    | 4544/8564 [00:13<00:11, 357.59 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:13<00:11, 350.26 examples/s]Tokenizing train dataset:  54%|█████▍    | 4620/8564 [00:13<00:11, 357.04 examples/s]Tokenizing train dataset:  55%|█████▍    | 4670/8564 [00:14<00:11, 341.35 examples/s]Tokenizing train dataset:  55%|█████▌    | 4718/8564 [00:14<00:11, 329.92 examples/s]Tokenizing train dataset:  56%|█████▌    | 4767/8564 [00:14<00:11, 324.93 examples/s]Tokenizing train dataset:  56%|█████▌    | 4804/8564 [00:14<00:11, 332.37 examples/s]Tokenizing train dataset:  57%|█████▋    | 4867/8564 [00:14<00:09, 404.74 examples/s]Tokenizing train dataset:  58%|█████▊    | 4932/8564 [00:14<00:07, 460.23 examples/s]Tokenizing train dataset:  58%|█████▊    | 4991/8564 [00:14<00:07, 493.36 examples/s]Tokenizing train dataset:  59%|█████▉    | 5055/8564 [00:14<00:06, 529.56 examples/s]Tokenizing train dataset:  60%|█████▉    | 5123/8564 [00:14<00:06, 568.05 examples/s]Tokenizing train dataset:  61%|██████    | 5195/8564 [00:15<00:05, 610.17 examples/s]Tokenizing train dataset:  62%|██████▏   | 5273/8564 [00:15<00:05, 649.19 examples/s]Tokenizing train dataset:  63%|██████▎   | 5365/8564 [00:15<00:05, 632.35 examples/s]Tokenizing train dataset:  64%|██████▎   | 5459/8564 [00:15<00:04, 627.05 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:15<00:04, 609.84 examples/s]Tokenizing train dataset:  66%|██████▌   | 5614/8564 [00:15<00:04, 622.21 examples/s]Tokenizing train dataset:  66%|██████▋   | 5677/8564 [00:15<00:04, 623.93 examples/s]Tokenizing train dataset:  67%|██████▋   | 5743/8564 [00:15<00:04, 628.36 examples/s]Tokenizing train dataset:  68%|██████▊   | 5822/8564 [00:16<00:04, 671.98 examples/s]Tokenizing train dataset:  69%|██████▉   | 5906/8564 [00:16<00:04, 622.09 examples/s]Tokenizing train dataset:  70%|██████▉   | 5975/8564 [00:16<00:04, 637.94 examples/s]Tokenizing train dataset:  71%|███████   | 6058/8564 [00:16<00:04, 598.06 examples/s]Tokenizing train dataset:  72%|███████▏  | 6155/8564 [00:16<00:03, 604.51 examples/s]Tokenizing train dataset:  73%|███████▎  | 6228/8564 [00:16<00:03, 632.01 examples/s]Tokenizing train dataset:  74%|███████▍  | 6325/8564 [00:16<00:03, 634.58 examples/s]Tokenizing train dataset:  75%|███████▍  | 6397/8564 [00:16<00:03, 649.63 examples/s]Tokenizing train dataset:  76%|███████▌  | 6489/8564 [00:17<00:03, 633.28 examples/s]Tokenizing train dataset:  77%|███████▋  | 6579/8564 [00:17<00:03, 612.70 examples/s]Tokenizing train dataset:  78%|███████▊  | 6663/8564 [00:17<00:03, 589.23 examples/s]Tokenizing train dataset:  79%|███████▊  | 6733/8564 [00:17<00:03, 609.16 examples/s]Tokenizing train dataset:  79%|███████▉  | 6801/8564 [00:17<00:02, 621.33 examples/s]Tokenizing train dataset:  80%|████████  | 6890/8564 [00:17<00:02, 609.03 examples/s]Tokenizing train dataset:  81%|████████  | 6957/8564 [00:17<00:02, 622.42 examples/s]Tokenizing train dataset:  82%|████████▏ | 7043/8564 [00:18<00:02, 597.17 examples/s]Tokenizing train dataset:  83%|████████▎ | 7111/8564 [00:18<00:02, 615.00 examples/s]Tokenizing train dataset:  84%|████████▍ | 7180/8564 [00:18<00:02, 629.42 examples/s]Tokenizing train dataset:  85%|████████▍ | 7271/8564 [00:18<00:02, 617.42 examples/s]Tokenizing train dataset:  86%|████████▌ | 7367/8564 [00:18<00:01, 621.29 examples/s]Tokenizing train dataset:  87%|████████▋ | 7430/8564 [00:18<00:01, 622.09 examples/s]Tokenizing train dataset:  88%|████████▊ | 7497/8564 [00:18<00:01, 631.59 examples/s]Tokenizing train dataset:  88%|████████▊ | 7566/8564 [00:18<00:01, 641.80 examples/s]Tokenizing train dataset:  89%|████████▉ | 7634/8564 [00:18<00:01, 646.69 examples/s]Tokenizing train dataset:  90%|█████████ | 7721/8564 [00:19<00:01, 617.92 examples/s]Tokenizing train dataset:  91%|█████████ | 7803/8564 [00:19<00:01, 587.32 examples/s]Tokenizing train dataset:  92%|█████████▏| 7865/8564 [00:19<00:01, 593.88 examples/s]Tokenizing train dataset:  93%|█████████▎| 7930/8564 [00:19<00:01, 602.14 examples/s]Tokenizing train dataset:  93%|█████████▎| 7996/8564 [00:19<00:00, 613.27 examples/s]Tokenizing train dataset:  94%|█████████▍| 8062/8564 [00:19<00:00, 618.38 examples/s]Tokenizing train dataset:  95%|█████████▌| 8144/8564 [00:19<00:00, 587.25 examples/s]Tokenizing train dataset:  96%|█████████▌| 8209/8564 [00:19<00:00, 595.74 examples/s]Tokenizing train dataset:  97%|█████████▋| 8286/8564 [00:20<00:00, 640.79 examples/s]Tokenizing train dataset:  98%|█████████▊| 8373/8564 [00:20<00:00, 614.96 examples/s]Tokenizing train dataset:  99%|█████████▉| 8464/8564 [00:20<00:00, 609.50 examples/s]Tokenizing train dataset: 100%|█████████▉| 8530/8564 [00:20<00:00, 617.43 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 417.81 examples/s]
[rank4]:[W531 12:06:43.089258632 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11511.13 examples/s]
Extracting prompt in train dataset:   7%|▋         | 573/8564 [00:00<00:01, 5691.66 examples/s]Extracting prompt in train dataset:   7%|▋         | 560/8564 [00:00<00:01, 5512.09 examples/s]Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:00<00:01, 5415.08 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1152/8564 [00:00<00:01, 5735.24 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1128/8564 [00:00<00:01, 5604.14 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1116/8564 [00:00<00:01, 5542.08 examples/s]Extracting prompt in train dataset:  20%|██        | 1732/8564 [00:00<00:01, 5736.45 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1690/8564 [00:00<00:01, 5586.61 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1680/8564 [00:00<00:01, 5541.21 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2320/8564 [00:00<00:01, 5780.42 examples/s]Extracting prompt in train dataset:  26%|██▋       | 2263/8564 [00:00<00:01, 5641.23 examples/s]Extracting prompt in train dataset:  26%|██▋       | 2250/8564 [00:00<00:01, 5593.88 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 14010.17 examples/s]
Extracting prompt in train dataset:  34%|███▍      | 2910/8564 [00:00<00:00, 5814.85 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2840/8564 [00:00<00:01, 5662.81 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2820/8564 [00:00<00:01, 5626.04 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3768/8564 [00:00<00:00, 5754.40 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3670/8564 [00:00<00:00, 5587.26 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3650/8564 [00:00<00:00, 5546.60 examples/s]Extracting prompt in train dataset:  51%|█████     | 4359/8564 [00:00<00:00, 5788.55 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4250/8564 [00:00<00:00, 5627.57 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4220/8564 [00:00<00:00, 5583.76 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4950/8564 [00:00<00:00, 5804.26 examples/s]Extracting prompt in train dataset:  56%|█████▋    | 4830/8564 [00:00<00:00, 5649.83 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4790/8564 [00:00<00:00, 5605.61 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 327.70 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5553/8564 [00:00<00:00, 5869.18 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5373/8564 [00:00<00:00, 5669.98 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5420/8564 [00:00<00:00, 5707.37 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6157/8564 [00:01<00:00, 5918.85 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5955/8564 [00:01<00:00, 5712.99 examples/s]Extracting prompt in train dataset:  70%|███████   | 6010/8564 [00:01<00:00, 5749.14 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 296.95 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6757/8564 [00:01<00:00, 5941.53 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 6536/8564 [00:01<00:00, 5740.06 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6600/8564 [00:01<00:00, 5776.17 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7358/8564 [00:01<00:00, 5960.57 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7116/8564 [00:01<00:00, 5755.76 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7190/8564 [00:01<00:00, 5796.22 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:02, 278.24 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 7695/8564 [00:01<00:00, 5764.92 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 8180/8564 [00:01<00:00, 5758.37 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 8022/8564 [00:01<00:00, 5586.14 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 268.74 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5784.85 examples/s]
Extracting prompt in train dataset:  99%|█████████▉| 8470/8564 [00:01<00:00, 5517.93 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5627.96 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5576.45 examples/s]
Tokenizing eval dataset:  21%|██        | 198/953 [00:00<00:02, 259.64 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:00<00:02, 291.45 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:00<00:01, 385.84 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  39%|███▊      | 367/953 [00:01<00:01, 449.73 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 298/8564 [00:00<00:02, 2956.17 examples/s]Applying chat template to train dataset:   3%|▎         | 291/8564 [00:00<00:02, 2882.27 examples/s]Tokenizing eval dataset:  46%|████▌     | 435/953 [00:01<00:01, 513.58 examples/s]Applying chat template to train dataset:   3%|▎         | 282/8564 [00:00<00:02, 2782.21 examples/s]Applying chat template to train dataset:   7%|▋         | 624/8564 [00:00<00:02, 3120.90 examples/s]Applying chat template to train dataset:   7%|▋         | 607/8564 [00:00<00:02, 3039.53 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:01<00:00, 557.02 examples/s]Applying chat template to train dataset:   7%|▋         | 590/8564 [00:00<00:02, 2941.64 examples/s]Applying chat template to train dataset:  11%|█         | 948/8564 [00:00<00:02, 3170.57 examples/s]Applying chat template to train dataset:  11%|█         | 921/8564 [00:00<00:02, 3079.78 examples/s]Tokenizing eval dataset:  60%|█████▉    | 569/953 [00:01<00:00, 580.07 examples/s]Applying chat template to train dataset:  10%|█         | 896/8564 [00:00<00:02, 2990.41 examples/s]Applying chat template to train dataset:  15%|█▍        | 1274/8564 [00:00<00:02, 3199.02 examples/s]Applying chat template to train dataset:  14%|█▍        | 1240/8564 [00:00<00:02, 3109.84 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:01<00:00, 605.08 examples/s]Applying chat template to train dataset:  14%|█▍        | 1202/8564 [00:00<00:02, 3013.33 examples/s]Applying chat template to train dataset:  19%|█▊        | 1595/8564 [00:00<00:02, 3197.46 examples/s]Applying chat template to train dataset:  18%|█▊        | 1552/8564 [00:00<00:02, 3110.51 examples/s]Applying chat template to train dataset:  18%|█▊        | 1504/8564 [00:00<00:02, 3013.45 examples/s]Applying chat template to train dataset:  22%|██▏       | 1921/8564 [00:00<00:02, 3215.41 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 595.12 examples/s]Applying chat template to train dataset:  22%|██▏       | 1870/8564 [00:00<00:02, 3131.33 examples/s]Applying chat template to train dataset:  21%|██        | 1811/8564 [00:00<00:02, 3028.78 examples/s]Applying chat template to train dataset:  26%|██▋       | 2250/8564 [00:00<00:01, 3232.59 examples/s]Applying chat template to train dataset:  26%|██▌       | 2190/8564 [00:00<00:02, 3149.09 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:01<00:00, 559.09 examples/s]Applying chat template to train dataset:  25%|██▍       | 2120/8564 [00:00<00:02, 3043.85 examples/s]Applying chat template to train dataset:  30%|███       | 2578/8564 [00:00<00:01, 3246.18 examples/s]Applying chat template to train dataset:  29%|██▉       | 2510/8564 [00:00<00:01, 3160.71 examples/s]Applying chat template to train dataset:  28%|██▊       | 2430/8564 [00:00<00:02, 3055.35 examples/s]Applying chat template to train dataset:  34%|███▍      | 2905/8564 [00:00<00:01, 3250.95 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:01<00:00, 539.63 examples/s]Applying chat template to train dataset:  33%|███▎      | 2830/8564 [00:00<00:01, 3166.61 examples/s]Applying chat template to train dataset:  32%|███▏      | 2740/8564 [00:00<00:01, 3061.55 examples/s]Applying chat template to train dataset:  39%|███▉      | 3377/8564 [00:01<00:01, 3206.03 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 528.69 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 462.46 examples/s]
Applying chat template to train dataset:  36%|███▌      | 3050/8564 [00:01<00:01, 3014.81 examples/s]Applying chat template to train dataset:  38%|███▊      | 3290/8564 [00:01<00:01, 3122.19 examples/s]Applying chat template to train dataset:  43%|████▎     | 3710/8564 [00:01<00:01, 3236.19 examples/s]Applying chat template to train dataset:  39%|███▉      | 3358/8564 [00:01<00:01, 3030.94 examples/s]Applying chat template to train dataset:  42%|████▏     | 3608/8564 [00:01<00:01, 3136.39 examples/s]Applying chat template to train dataset:  47%|████▋     | 4037/8564 [00:01<00:01, 3241.69 examples/s]Applying chat template to train dataset:  43%|████▎     | 3665/8564 [00:01<00:01, 3041.76 examples/s]Applying chat template to train dataset:  46%|████▌     | 3925/8564 [00:01<00:01, 3143.13 examples/s]Applying chat template to train dataset:  51%|█████     | 4363/8564 [00:01<00:01, 3243.21 examples/s]Applying chat template to train dataset:  46%|████▋     | 3978/8564 [00:01<00:01, 3061.22 examples/s]Applying chat template to train dataset:  50%|████▉     | 4241/8564 [00:01<00:01, 3146.41 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4690/8564 [00:01<00:01, 3244.57 examples/s]Applying chat template to train dataset:  50%|█████     | 4291/8564 [00:01<00:01, 3077.17 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4560/8564 [00:01<00:01, 3152.67 examples/s]Applying chat template to train dataset:  59%|█████▊    | 5021/8564 [00:01<00:01, 3261.48 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4605/8564 [00:01<00:01, 3092.60 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4879/8564 [00:01<00:01, 3160.43 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5362/8564 [00:01<00:00, 3299.77 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4920/8564 [00:01<00:01, 3105.04 examples/s]Applying chat template to train dataset:  61%|██████    | 5203/8564 [00:01<00:01, 3179.84 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5706/8564 [00:01<00:00, 3337.20 examples/s]Applying chat template to train dataset:  61%|██████    | 5241/8564 [00:01<00:01, 3133.13 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5528/8564 [00:01<00:00, 3198.35 examples/s]Applying chat template to train dataset:  71%|███████   | 6045/8564 [00:01<00:00, 3350.19 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5561/8564 [00:01<00:00, 3151.22 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5853/8564 [00:01<00:00, 3209.75 examples/s]Applying chat template to train dataset:  69%|██████▊   | 5883/8564 [00:01<00:00, 3166.94 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6178/8564 [00:01<00:00, 3219.80 examples/s]Applying chat template to train dataset:  76%|███████▋  | 6548/8564 [00:02<00:00, 3347.33 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6204/8564 [00:02<00:00, 3178.05 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6502/8564 [00:02<00:00, 3222.59 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7049/8564 [00:02<00:00, 3340.07 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6524/8564 [00:02<00:00, 3183.56 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6826/8564 [00:02<00:00, 3225.34 examples/s]Applying chat template to train dataset:  86%|████████▋ | 7391/8564 [00:02<00:00, 3357.91 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7150/8564 [00:02<00:00, 3226.37 examples/s]Applying chat template to train dataset:  82%|████████▏ | 6996/8564 [00:02<00:00, 3165.60 examples/s]Applying chat template to train dataset:  90%|█████████ | 7735/8564 [00:02<00:00, 3377.06 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7475/8564 [00:02<00:00, 3231.97 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7468/8564 [00:02<00:00, 3154.13 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8191/8564 [00:02<00:00, 3252.99 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7916/8564 [00:02<00:00, 3113.48 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8526/8564 [00:02<00:00, 3275.37 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3259.44 examples/s]
Applying chat template to train dataset:  96%|█████████▌| 8240/8564 [00:02<00:00, 3145.99 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7906/8564 [00:02<00:00, 3036.33 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3170.87 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8220/8564 [00:02<00:00, 3058.00 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3153.44 examples/s]
Applying chat template to train dataset: 100%|█████████▉| 8535/8564 [00:02<00:00, 3080.55 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3071.41 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:20, 409.78 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:20, 406.63 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:24, 341.21 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:20, 407.59 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:24, 339.60 examples/s]Tokenizing train dataset:   2%|▏         | 133/8564 [00:00<00:27, 308.46 examples/s]Tokenizing train dataset:   2%|▏         | 165/8564 [00:00<00:27, 308.99 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:24, 340.70 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:26, 321.76 examples/s]Tokenizing train dataset:   2%|▏         | 213/8564 [00:00<00:26, 309.78 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:26, 322.00 examples/s]Tokenizing train dataset:   2%|▏         | 184/8564 [00:00<00:27, 309.42 examples/s]Tokenizing train dataset:   3%|▎         | 249/8564 [00:00<00:25, 319.82 examples/s]Tokenizing train dataset:   3%|▎         | 218/8564 [00:00<00:26, 315.22 examples/s]Tokenizing train dataset:   2%|▏         | 184/8564 [00:00<00:27, 309.56 examples/s]Tokenizing train dataset:   3%|▎         | 285/8564 [00:00<00:25, 330.42 examples/s]Tokenizing train dataset:   3%|▎         | 252/8564 [00:00<00:25, 320.01 examples/s]Tokenizing train dataset:   3%|▎         | 218/8564 [00:00<00:26, 315.18 examples/s]Tokenizing train dataset:   4%|▎         | 319/8564 [00:00<00:24, 329.92 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:00<00:24, 333.33 examples/s]Tokenizing train dataset:   3%|▎         | 252/8564 [00:00<00:25, 319.97 examples/s]Tokenizing train dataset:   4%|▍         | 324/8564 [00:00<00:24, 332.23 examples/s]Tokenizing train dataset:   4%|▍         | 366/8564 [00:01<00:25, 320.74 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:00<00:24, 333.15 examples/s]Tokenizing train dataset:   5%|▍         | 399/8564 [00:01<00:25, 321.15 examples/s]Tokenizing train dataset:   4%|▍         | 324/8564 [00:00<00:24, 332.17 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:01<00:25, 318.70 examples/s]Tokenizing train dataset:   5%|▌         | 432/8564 [00:01<00:25, 319.09 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:01<00:25, 318.62 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:01<00:25, 317.34 examples/s]Tokenizing train dataset:   6%|▌         | 478/8564 [00:01<00:26, 310.90 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:01<00:25, 316.94 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:25, 315.34 examples/s]Tokenizing train dataset:   6%|▌         | 525/8564 [00:01<00:26, 307.94 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:25, 314.73 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:01<00:26, 304.78 examples/s]Tokenizing train dataset:   7%|▋         | 559/8564 [00:01<00:25, 313.12 examples/s]Tokenizing train dataset:   6%|▋         | 549/8564 [00:01<00:25, 317.84 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:01<00:26, 304.34 examples/s]Tokenizing train dataset:   7%|▋         | 604/8564 [00:01<00:26, 304.14 examples/s]Tokenizing train dataset:   6%|▋         | 549/8564 [00:01<00:25, 317.50 examples/s]Tokenizing train dataset:   7%|▋         | 596/8564 [00:01<00:25, 308.85 examples/s]Tokenizing train dataset:   8%|▊         | 643/8564 [00:02<00:24, 321.47 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:01<00:24, 323.16 examples/s]Tokenizing train dataset:   7%|▋         | 596/8564 [00:01<00:25, 308.72 examples/s]Tokenizing train dataset:   8%|▊         | 689/8564 [00:02<00:25, 312.51 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:01<00:24, 323.13 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:02<00:25, 313.59 examples/s]Tokenizing train dataset:   9%|▊         | 740/8564 [00:02<00:24, 319.26 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:02<00:25, 314.43 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:02<00:25, 311.84 examples/s]Tokenizing train dataset:   9%|▉         | 785/8564 [00:02<00:25, 309.83 examples/s]Tokenizing train dataset:   9%|▉         | 763/8564 [00:02<00:24, 313.39 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:02<00:25, 312.49 examples/s]Tokenizing train dataset:  10%|▉         | 827/8564 [00:02<00:26, 296.42 examples/s]Tokenizing train dataset:   9%|▉         | 763/8564 [00:02<00:24, 313.78 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:02<00:25, 300.26 examples/s]Tokenizing train dataset:  10%|█         | 860/8564 [00:02<00:25, 301.77 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:02<00:25, 300.70 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:02<00:26, 294.59 examples/s]Tokenizing train dataset:  10%|█         | 897/8564 [00:02<00:24, 317.59 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:02<00:25, 302.69 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:02<00:26, 294.70 examples/s]Tokenizing train dataset:  11%|█         | 942/8564 [00:02<00:24, 307.06 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:02<00:24, 308.13 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:02<00:25, 302.63 examples/s]Tokenizing train dataset:  12%|█▏        | 986/8564 [00:03<00:25, 299.03 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:03<00:24, 306.29 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:02<00:24, 307.86 examples/s]Tokenizing train dataset:  12%|█▏        | 1017/8564 [00:03<00:25, 297.16 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:03<00:25, 301.69 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:03<00:24, 306.20 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:03<00:25, 301.77 examples/s]Tokenizing train dataset:  12%|█▏        | 1062/8564 [00:03<00:25, 293.01 examples/s]Tokenizing train dataset:  12%|█▏        | 1027/8564 [00:03<00:25, 292.22 examples/s]Tokenizing train dataset:  13%|█▎        | 1098/8564 [00:03<00:24, 307.05 examples/s]Tokenizing train dataset:  12%|█▏        | 1027/8564 [00:03<00:25, 292.33 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:03<00:25, 293.99 examples/s]Tokenizing train dataset:  13%|█▎        | 1141/8564 [00:03<00:24, 297.45 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:03<00:24, 307.39 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:03<00:25, 293.94 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:03<00:24, 307.19 examples/s]Tokenizing train dataset:  14%|█▍        | 1190/8564 [00:03<00:24, 299.71 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:03<00:25, 294.85 examples/s]Tokenizing train dataset:  14%|█▍        | 1181/8564 [00:03<00:24, 295.75 examples/s]Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:03<00:24, 301.45 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:03<00:25, 294.73 examples/s]Tokenizing train dataset:  14%|█▍        | 1214/8564 [00:03<00:24, 299.87 examples/s]Tokenizing train dataset:  15%|█▍        | 1260/8564 [00:04<00:23, 315.46 examples/s]Tokenizing train dataset:  14%|█▍        | 1181/8564 [00:03<00:24, 295.63 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:04<00:23, 314.23 examples/s]Tokenizing train dataset:  14%|█▍        | 1214/8564 [00:03<00:24, 299.71 examples/s]Tokenizing train dataset:  15%|█▌        | 1310/8564 [00:04<00:22, 318.56 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:04<00:23, 314.21 examples/s]Tokenizing train dataset:  15%|█▌        | 1299/8564 [00:04<00:23, 314.71 examples/s]Tokenizing train dataset:  16%|█▌        | 1344/8564 [00:04<00:22, 318.90 examples/s]Tokenizing train dataset:  16%|█▌        | 1331/8564 [00:04<00:23, 313.48 examples/s]Tokenizing train dataset:  15%|█▌        | 1299/8564 [00:04<00:23, 315.41 examples/s]Tokenizing train dataset:  16%|█▌        | 1387/8564 [00:04<00:23, 302.28 examples/s]Tokenizing train dataset:  16%|█▌        | 1331/8564 [00:04<00:23, 314.08 examples/s]Tokenizing train dataset:  16%|█▌        | 1373/8564 [00:04<00:24, 297.88 examples/s]Tokenizing train dataset:  17%|█▋        | 1418/8564 [00:04<00:23, 303.50 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:04<00:23, 304.14 examples/s]Tokenizing train dataset:  17%|█▋        | 1449/8564 [00:04<00:23, 300.24 examples/s]Tokenizing train dataset:  16%|█▌        | 1373/8564 [00:04<00:24, 298.07 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:04<00:23, 297.89 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:04<00:23, 304.34 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:04<00:23, 300.02 examples/s]Tokenizing train dataset:  18%|█▊        | 1527/8564 [00:04<00:23, 296.45 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:04<00:23, 300.34 examples/s]Tokenizing train dataset:  17%|█▋        | 1496/8564 [00:04<00:24, 293.58 examples/s]Tokenizing train dataset:  18%|█▊        | 1559/8564 [00:05<00:23, 300.33 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:04<00:23, 297.12 examples/s]Tokenizing train dataset:  18%|█▊        | 1499/8564 [00:04<00:23, 298.01 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:05<00:23, 297.80 examples/s]Tokenizing train dataset:  19%|█▊        | 1605/8564 [00:05<00:23, 299.56 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:04<00:23, 297.77 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:05<00:23, 293.68 examples/s]Tokenizing train dataset:  19%|█▉        | 1641/8564 [00:05<00:22, 310.07 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:05<00:23, 298.45 examples/s]Tokenizing train dataset:  19%|█▉        | 1627/8564 [00:05<00:22, 304.56 examples/s]Tokenizing train dataset:  20%|█▉        | 1676/8564 [00:05<00:21, 316.80 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:05<00:23, 294.44 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:05<00:22, 312.77 examples/s]Tokenizing train dataset:  20%|██        | 1718/8564 [00:05<00:20, 339.02 examples/s]Tokenizing train dataset:  19%|█▉        | 1627/8564 [00:05<00:22, 304.98 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:05<00:20, 340.38 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:05<00:22, 312.83 examples/s]Tokenizing train dataset:  21%|██        | 1769/8564 [00:05<00:20, 333.74 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:05<00:20, 340.14 examples/s]Tokenizing train dataset:  20%|██        | 1754/8564 [00:05<00:20, 331.49 examples/s]Tokenizing train dataset:  21%|██        | 1815/8564 [00:05<00:20, 322.96 examples/s]Tokenizing train dataset:  20%|██        | 1753/8564 [00:05<00:20, 329.54 examples/s]Tokenizing train dataset:  21%|██        | 1802/8564 [00:05<00:20, 324.19 examples/s]Tokenizing train dataset:  22%|██▏       | 1848/8564 [00:05<00:20, 321.64 examples/s]Tokenizing train dataset:  21%|██▏       | 1836/8564 [00:05<00:20, 327.44 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:05<00:20, 322.89 examples/s]Tokenizing train dataset:  22%|██▏       | 1893/8564 [00:06<00:21, 309.85 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:05<00:20, 325.00 examples/s]Tokenizing train dataset:  23%|██▎       | 1938/8564 [00:06<00:19, 342.55 examples/s]Tokenizing train dataset:  22%|██▏       | 1880/8564 [00:06<00:21, 309.37 examples/s]Tokenizing train dataset:  22%|██▏       | 1920/8564 [00:06<00:20, 330.69 examples/s]Tokenizing train dataset:  23%|██▎       | 1975/8564 [00:06<00:19, 346.23 examples/s]Tokenizing train dataset:  22%|██▏       | 1880/8564 [00:06<00:21, 311.05 examples/s]Tokenizing train dataset:  23%|██▎       | 1958/8564 [00:06<00:19, 341.36 examples/s]Tokenizing train dataset:  23%|██▎       | 2012/8564 [00:06<00:18, 351.61 examples/s]Tokenizing train dataset:  22%|██▏       | 1920/8564 [00:06<00:20, 331.98 examples/s]Tokenizing train dataset:  23%|██▎       | 1994/8564 [00:06<00:19, 345.03 examples/s]Tokenizing train dataset:  24%|██▍       | 2051/8564 [00:06<00:18, 358.80 examples/s]Tokenizing train dataset:  23%|██▎       | 1958/8564 [00:06<00:19, 342.11 examples/s]Tokenizing train dataset:  24%|██▍       | 2035/8564 [00:06<00:18, 357.56 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:06<00:17, 360.41 examples/s]Tokenizing train dataset:  23%|██▎       | 1994/8564 [00:06<00:19, 345.45 examples/s]Tokenizing train dataset:  24%|██▍       | 2072/8564 [00:06<00:18, 357.75 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:06<00:17, 367.79 examples/s]Tokenizing train dataset:  24%|██▍       | 2035/8564 [00:06<00:18, 357.98 examples/s]Tokenizing train dataset:  25%|██▍       | 2112/8564 [00:06<00:17, 365.71 examples/s]Tokenizing train dataset:  24%|██▍       | 2073/8564 [00:06<00:18, 357.26 examples/s]Tokenizing train dataset:  26%|██▌       | 2187/8564 [00:06<00:17, 366.25 examples/s]Tokenizing train dataset:  25%|██▌       | 2150/8564 [00:06<00:17, 365.06 examples/s]Tokenizing train dataset:  25%|██▍       | 2114/8564 [00:06<00:17, 367.82 examples/s]Tokenizing train dataset:  26%|██▌       | 2225/8564 [00:06<00:17, 365.44 examples/s]Tokenizing train dataset:  26%|██▌       | 2187/8564 [00:06<00:17, 365.98 examples/s]Tokenizing train dataset:  26%|██▋       | 2263/8564 [00:07<00:17, 365.98 examples/s]Tokenizing train dataset:  25%|██▌       | 2170/8564 [00:06<00:17, 364.46 examples/s]Tokenizing train dataset:  26%|██▌       | 2225/8564 [00:06<00:17, 364.84 examples/s]Tokenizing train dataset:  27%|██▋       | 2306/8564 [00:07<00:16, 378.90 examples/s]Tokenizing train dataset:  26%|██▌       | 2207/8564 [00:06<00:17, 361.37 examples/s]Tokenizing train dataset:  26%|██▋       | 2263/8564 [00:07<00:17, 365.16 examples/s]Tokenizing train dataset:  26%|██▋       | 2249/8564 [00:07<00:16, 373.02 examples/s]Tokenizing train dataset:  27%|██▋       | 2306/8564 [00:07<00:16, 379.00 examples/s]Tokenizing train dataset:  28%|██▊       | 2356/8564 [00:07<00:17, 357.01 examples/s]Tokenizing train dataset:  27%|██▋       | 2290/8564 [00:07<00:16, 379.40 examples/s]Tokenizing train dataset:  28%|██▊       | 2396/8564 [00:07<00:16, 367.70 examples/s]Tokenizing train dataset:  28%|██▊       | 2356/8564 [00:07<00:17, 355.78 examples/s]Tokenizing train dataset:  28%|██▊       | 2435/8564 [00:07<00:16, 372.10 examples/s]Tokenizing train dataset:  27%|██▋       | 2342/8564 [00:07<00:17, 361.87 examples/s]Tokenizing train dataset:  28%|██▊       | 2396/8564 [00:07<00:16, 366.75 examples/s]Tokenizing train dataset:  29%|██▉       | 2474/8564 [00:07<00:16, 376.66 examples/s]Tokenizing train dataset:  28%|██▊       | 2435/8564 [00:07<00:16, 371.28 examples/s]Tokenizing train dataset:  28%|██▊       | 2401/8564 [00:07<00:16, 370.27 examples/s]Tokenizing train dataset:  29%|██▉       | 2474/8564 [00:07<00:16, 375.93 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:07<00:16, 367.97 examples/s]Tokenizing train dataset:  28%|██▊       | 2440/8564 [00:07<00:16, 368.87 examples/s]Tokenizing train dataset:  30%|███       | 2572/8564 [00:07<00:15, 379.45 examples/s]Tokenizing train dataset:  29%|██▉       | 2478/8564 [00:07<00:16, 370.90 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:07<00:16, 367.23 examples/s]Tokenizing train dataset:  30%|███       | 2572/8564 [00:07<00:15, 378.70 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:08<00:16, 355.46 examples/s]Tokenizing train dataset:  30%|██▉       | 2534/8564 [00:07<00:16, 366.66 examples/s]Tokenizing train dataset:  30%|███       | 2577/8564 [00:07<00:15, 376.73 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:08<00:16, 353.50 examples/s]Tokenizing train dataset:  31%|███       | 2671/8564 [00:08<00:17, 345.63 examples/s]Tokenizing train dataset:  32%|███▏      | 2708/8564 [00:08<00:16, 350.34 examples/s]Tokenizing train dataset:  31%|███       | 2670/8564 [00:08<00:17, 342.68 examples/s]Tokenizing train dataset:  31%|███       | 2624/8564 [00:08<00:16, 349.70 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:08<00:17, 343.43 examples/s]Tokenizing train dataset:  32%|███▏      | 2759/8564 [00:08<00:16, 345.02 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:08<00:16, 347.92 examples/s]Tokenizing train dataset:  32%|███▏      | 2740/8564 [00:08<00:17, 341.16 examples/s]Tokenizing train dataset:  33%|███▎      | 2798/8564 [00:08<00:16, 352.85 examples/s]Tokenizing train dataset:  32%|███▏      | 2715/8564 [00:08<00:16, 350.20 examples/s]Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:08<00:16, 342.15 examples/s]Tokenizing train dataset:  33%|███▎      | 2837/8564 [00:08<00:15, 358.85 examples/s]Tokenizing train dataset:  32%|███▏      | 2763/8564 [00:08<00:17, 337.99 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:08<00:15, 363.86 examples/s]Tokenizing train dataset:  34%|███▍      | 2893/8564 [00:08<00:15, 357.94 examples/s]Tokenizing train dataset:  33%|███▎      | 2807/8564 [00:08<00:16, 357.50 examples/s]Tokenizing train dataset:  34%|███▍      | 2934/8564 [00:08<00:15, 370.42 examples/s]Tokenizing train dataset:  34%|███▎      | 2870/8564 [00:08<00:16, 344.53 examples/s]Tokenizing train dataset:  33%|███▎      | 2859/8564 [00:08<00:16, 352.29 examples/s]Tokenizing train dataset:  35%|███▍      | 2980/8564 [00:09<00:14, 390.78 examples/s]Tokenizing train dataset:  34%|███▍      | 2914/8564 [00:08<00:15, 367.82 examples/s]Tokenizing train dataset:  34%|███▍      | 2898/8564 [00:08<00:15, 358.41 examples/s]Tokenizing train dataset:  35%|███▍      | 2957/8564 [00:09<00:14, 380.97 examples/s]Tokenizing train dataset:  35%|███▌      | 3036/8564 [00:09<00:14, 377.88 examples/s]Tokenizing train dataset:  34%|███▍      | 2942/8564 [00:08<00:15, 373.83 examples/s]Tokenizing train dataset:  35%|███▌      | 3000/8564 [00:09<00:14, 390.56 examples/s]Tokenizing train dataset:  35%|███▍      | 2987/8564 [00:09<00:14, 392.99 examples/s]Tokenizing train dataset:  36%|███▌      | 3092/8564 [00:09<00:14, 373.85 examples/s]Tokenizing train dataset:  36%|███▌      | 3054/8564 [00:09<00:14, 373.26 examples/s]Tokenizing train dataset:  37%|███▋      | 3148/8564 [00:09<00:14, 370.50 examples/s]Tokenizing train dataset:  35%|███▌      | 3040/8564 [00:09<00:14, 373.69 examples/s]Tokenizing train dataset:  36%|███▋      | 3111/8564 [00:09<00:14, 373.31 examples/s]Tokenizing train dataset:  37%|███▋      | 3204/8564 [00:09<00:14, 367.96 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:09<00:14, 371.24 examples/s]Tokenizing train dataset:  37%|███▋      | 3166/8564 [00:09<00:14, 366.44 examples/s]Tokenizing train dataset:  38%|███▊      | 3245/8564 [00:09<00:14, 374.78 examples/s]Tokenizing train dataset:  37%|███▋      | 3151/8564 [00:09<00:14, 364.94 examples/s]Tokenizing train dataset:  38%|███▊      | 3222/8564 [00:09<00:14, 365.58 examples/s]Tokenizing train dataset:  39%|███▊      | 3299/8564 [00:09<00:14, 365.69 examples/s]Tokenizing train dataset:  37%|███▋      | 3189/8564 [00:09<00:14, 362.24 examples/s]Tokenizing train dataset:  38%|███▊      | 3264/8564 [00:09<00:14, 373.84 examples/s]Tokenizing train dataset:  38%|███▊      | 3228/8564 [00:09<00:14, 367.82 examples/s]Tokenizing train dataset:  39%|███▉      | 3352/8564 [00:10<00:14, 359.46 examples/s]Tokenizing train dataset:  38%|███▊      | 3269/8564 [00:09<00:14, 373.99 examples/s]Tokenizing train dataset:  39%|███▊      | 3316/8564 [00:09<00:14, 362.08 examples/s]Tokenizing train dataset:  40%|███▉      | 3394/8564 [00:10<00:13, 370.50 examples/s]Tokenizing train dataset:  40%|████      | 3435/8564 [00:10<00:13, 378.03 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:09<00:14, 358.80 examples/s]Tokenizing train dataset:  39%|███▉      | 3370/8564 [00:10<00:14, 356.96 examples/s]Tokenizing train dataset:  39%|███▉      | 3357/8564 [00:10<00:14, 359.72 examples/s]Tokenizing train dataset:  40%|███▉      | 3414/8564 [00:10<00:13, 372.19 examples/s]Tokenizing train dataset:  41%|████      | 3489/8564 [00:10<00:13, 368.26 examples/s]Tokenizing train dataset:  40%|███▉      | 3397/8564 [00:10<00:14, 368.88 examples/s]Tokenizing train dataset:  40%|████      | 3452/8564 [00:10<00:13, 370.98 examples/s]Tokenizing train dataset:  41%|████      | 3531/8564 [00:10<00:13, 377.56 examples/s]Tokenizing train dataset:  40%|████      | 3437/8564 [00:10<00:13, 376.89 examples/s]Tokenizing train dataset:  41%|████      | 3506/8564 [00:10<00:13, 362.61 examples/s]Tokenizing train dataset:  42%|████▏     | 3589/8564 [00:10<00:13, 375.80 examples/s]Tokenizing train dataset:  41%|████      | 3491/8564 [00:10<00:13, 366.51 examples/s]Tokenizing train dataset:  41%|████▏     | 3545/8564 [00:10<00:13, 366.36 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:10<00:13, 376.61 examples/s]Tokenizing train dataset:  41%|████▏     | 3533/8564 [00:10<00:13, 378.20 examples/s]Tokenizing train dataset:  42%|████▏     | 3602/8564 [00:10<00:13, 369.45 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:10<00:13, 354.12 examples/s]Tokenizing train dataset:  42%|████▏     | 3592/8564 [00:10<00:13, 374.40 examples/s]Tokenizing train dataset:  43%|████▎     | 3640/8564 [00:10<00:13, 365.58 examples/s]Tokenizing train dataset:  43%|████▎     | 3724/8564 [00:11<00:12, 372.36 examples/s]Tokenizing train dataset:  42%|████▏     | 3631/8564 [00:10<00:13, 375.58 examples/s]Tokenizing train dataset:  43%|████▎     | 3691/8564 [00:11<00:13, 354.93 examples/s]Tokenizing train dataset:  44%|████▍     | 3781/8564 [00:11<00:12, 372.61 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:10<00:13, 353.74 examples/s]Tokenizing train dataset:  44%|████▎     | 3730/8564 [00:11<00:13, 362.43 examples/s]Tokenizing train dataset:  43%|████▎     | 3724/8564 [00:11<00:13, 372.02 examples/s]Tokenizing train dataset:  44%|████▍     | 3769/8564 [00:11<00:13, 368.07 examples/s]Tokenizing train dataset:  45%|████▍     | 3835/8564 [00:11<00:12, 365.84 examples/s]Tokenizing train dataset:  44%|████▍     | 3807/8564 [00:11<00:12, 368.09 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:11<00:12, 370.47 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:11<00:12, 363.98 examples/s]Tokenizing train dataset:  45%|████▌     | 3861/8564 [00:11<00:13, 359.78 examples/s]Tokenizing train dataset:  45%|████▍     | 3834/8564 [00:11<00:12, 364.59 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:11<00:13, 354.00 examples/s]Tokenizing train dataset:  46%|████▌     | 3898/8564 [00:11<00:12, 358.96 examples/s]Tokenizing train dataset:  46%|████▋     | 3978/8564 [00:11<00:12, 355.61 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:11<00:12, 362.68 examples/s]Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:11<00:12, 357.94 examples/s]Tokenizing train dataset:  46%|████▌     | 3951/8564 [00:11<00:13, 351.99 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:11<00:13, 352.74 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:11<00:12, 366.47 examples/s]Tokenizing train dataset:  47%|████▋     | 3987/8564 [00:11<00:12, 353.50 examples/s]Tokenizing train dataset:  46%|████▋     | 3978/8564 [00:11<00:12, 354.43 examples/s]Tokenizing train dataset:  47%|████▋     | 4028/8564 [00:11<00:12, 366.76 examples/s]Tokenizing train dataset:  48%|████▊     | 4112/8564 [00:12<00:12, 363.72 examples/s]Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:11<00:12, 356.79 examples/s]Tokenizing train dataset:  48%|████▊     | 4083/8564 [00:12<00:12, 361.23 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:11<00:12, 365.29 examples/s]Tokenizing train dataset:  49%|████▊     | 4164/8564 [00:12<00:12, 353.41 examples/s]Tokenizing train dataset:  48%|████▊     | 4120/8564 [00:12<00:12, 360.19 examples/s]Tokenizing train dataset:  49%|████▉     | 4205/8564 [00:12<00:11, 366.01 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:12<00:12, 359.97 examples/s]Tokenizing train dataset:  49%|████▊     | 4172/8564 [00:12<00:12, 352.82 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:12<00:12, 356.12 examples/s]Tokenizing train dataset:  49%|████▊     | 4162/8564 [00:12<00:12, 352.91 examples/s]Tokenizing train dataset:  49%|████▉     | 4212/8564 [00:12<00:12, 361.01 examples/s]Tokenizing train dataset:  50%|█████     | 4299/8564 [00:12<00:11, 361.31 examples/s]Tokenizing train dataset:  49%|████▉     | 4203/8564 [00:12<00:12, 363.01 examples/s]Tokenizing train dataset:  50%|████▉     | 4266/8564 [00:12<00:11, 358.88 examples/s]Tokenizing train dataset:  51%|█████     | 4353/8564 [00:12<00:11, 354.61 examples/s]Tokenizing train dataset:  50%|████▉     | 4257/8564 [00:12<00:12, 357.74 examples/s]Tokenizing train dataset:  50%|█████     | 4304/8564 [00:12<00:11, 361.40 examples/s]Tokenizing train dataset:  51%|█████▏    | 4393/8564 [00:12<00:11, 361.90 examples/s]Tokenizing train dataset:  50%|█████     | 4313/8564 [00:12<00:11, 359.63 examples/s]Tokenizing train dataset:  51%|█████     | 4359/8564 [00:12<00:11, 358.02 examples/s]Tokenizing train dataset:  52%|█████▏    | 4430/8564 [00:13<00:11, 361.00 examples/s]Tokenizing train dataset:  51%|█████▏    | 4398/8564 [00:12<00:11, 363.91 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:13<00:11, 365.09 examples/s]Tokenizing train dataset:  51%|█████     | 4365/8564 [00:12<00:11, 353.32 examples/s]Tokenizing train dataset:  52%|█████▏    | 4435/8564 [00:13<00:11, 363.83 examples/s]Tokenizing train dataset:  53%|█████▎    | 4507/8564 [00:13<00:11, 359.25 examples/s]Tokenizing train dataset:  51%|█████▏    | 4405/8564 [00:12<00:11, 360.29 examples/s]Tokenizing train dataset:  52%|█████▏    | 4472/8564 [00:13<00:11, 362.73 examples/s]Tokenizing train dataset:  53%|█████▎    | 4545/8564 [00:13<00:11, 359.26 examples/s]Tokenizing train dataset:  52%|█████▏    | 4444/8564 [00:13<00:11, 363.65 examples/s]Tokenizing train dataset:  53%|█████▎    | 4525/8564 [00:13<00:11, 354.52 examples/s]Tokenizing train dataset:  52%|█████▏    | 4482/8564 [00:13<00:11, 362.76 examples/s]Tokenizing train dataset:  54%|█████▎    | 4600/8564 [00:13<00:11, 356.22 examples/s]Tokenizing train dataset:  53%|█████▎    | 4566/8564 [00:13<00:10, 366.83 examples/s]Tokenizing train dataset:  54%|█████▍    | 4636/8564 [00:13<00:11, 349.62 examples/s]Tokenizing train dataset:  53%|█████▎    | 4536/8564 [00:13<00:11, 356.91 examples/s]Tokenizing train dataset:  53%|█████▎    | 4572/8564 [00:13<00:11, 354.57 examples/s]Tokenizing train dataset:  54%|█████▍    | 4620/8564 [00:13<00:11, 355.48 examples/s]Tokenizing train dataset:  55%|█████▍    | 4686/8564 [00:13<00:11, 338.13 examples/s]Tokenizing train dataset:  54%|█████▍    | 4609/8564 [00:13<00:11, 354.72 examples/s]Tokenizing train dataset:  55%|█████▍    | 4670/8564 [00:13<00:11, 340.94 examples/s]Tokenizing train dataset:  55%|█████▌    | 4737/8564 [00:13<00:11, 334.81 examples/s]Tokenizing train dataset:  54%|█████▍    | 4660/8564 [00:13<00:11, 342.13 examples/s]Tokenizing train dataset:  55%|█████▌    | 4718/8564 [00:13<00:11, 329.75 examples/s]Tokenizing train dataset:  56%|█████▌    | 4782/8564 [00:14<00:11, 320.92 examples/s]Tokenizing train dataset:  55%|█████▍    | 4708/8564 [00:13<00:11, 329.72 examples/s]Tokenizing train dataset:  57%|█████▋    | 4839/8564 [00:14<00:09, 376.61 examples/s]Tokenizing train dataset:  56%|█████▌    | 4767/8564 [00:14<00:11, 325.25 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:13<00:11, 329.34 examples/s]Tokenizing train dataset:  57%|█████▋    | 4896/8564 [00:14<00:08, 420.52 examples/s]Tokenizing train dataset:  56%|█████▌    | 4804/8564 [00:14<00:11, 332.54 examples/s]Tokenizing train dataset:  58%|█████▊    | 4960/8564 [00:14<00:07, 476.05 examples/s]Tokenizing train dataset:  57%|█████▋    | 4868/8564 [00:14<00:09, 406.52 examples/s]Tokenizing train dataset:  56%|█████▌    | 4792/8564 [00:14<00:11, 323.86 examples/s]Tokenizing train dataset:  59%|█████▊    | 5022/8564 [00:14<00:06, 512.44 examples/s]Tokenizing train dataset:  58%|█████▊    | 4932/8564 [00:14<00:07, 459.49 examples/s]Tokenizing train dataset:  57%|█████▋    | 4853/8564 [00:14<00:09, 389.67 examples/s]Tokenizing train dataset:  59%|█████▉    | 5088/8564 [00:14<00:06, 550.93 examples/s]Tokenizing train dataset:  58%|█████▊    | 4993/8564 [00:14<00:07, 493.16 examples/s]Tokenizing train dataset:  57%|█████▋    | 4912/8564 [00:14<00:08, 433.35 examples/s]Tokenizing train dataset:  60%|██████    | 5156/8564 [00:14<00:05, 584.27 examples/s]Tokenizing train dataset:  58%|█████▊    | 4974/8564 [00:14<00:07, 480.76 examples/s]Tokenizing train dataset:  59%|█████▉    | 5060/8564 [00:14<00:06, 535.28 examples/s]Tokenizing train dataset:  61%|██████    | 5228/8564 [00:14<00:05, 620.21 examples/s]Tokenizing train dataset:  60%|█████▉    | 5127/8564 [00:14<00:06, 571.97 examples/s]Tokenizing train dataset:  59%|█████▉    | 5033/8564 [00:14<00:06, 506.23 examples/s]Tokenizing train dataset:  62%|██████▏   | 5304/8564 [00:14<00:04, 657.37 examples/s]Tokenizing train dataset:  61%|██████    | 5200/8564 [00:14<00:05, 607.66 examples/s]Tokenizing train dataset:  60%|█████▉    | 5106/8564 [00:14<00:06, 561.98 examples/s]Tokenizing train dataset:  62%|██████▏   | 5279/8564 [00:14<00:05, 655.56 examples/s]Tokenizing train dataset:  60%|██████    | 5177/8564 [00:14<00:05, 598.32 examples/s]Tokenizing train dataset:  63%|██████▎   | 5390/8564 [00:15<00:05, 618.10 examples/s]Tokenizing train dataset:  61%|██████▏   | 5247/8564 [00:14<00:05, 626.68 examples/s]Tokenizing train dataset:  64%|██████▎   | 5454/8564 [00:15<00:04, 623.05 examples/s]Tokenizing train dataset:  63%|██████▎   | 5371/8564 [00:15<00:05, 633.05 examples/s]Tokenizing train dataset:  62%|██████▏   | 5319/8564 [00:14<00:04, 650.59 examples/s]Tokenizing train dataset:  63%|██████▎   | 5436/8564 [00:15<00:04, 633.60 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:15<00:04, 611.54 examples/s]Tokenizing train dataset:  63%|██████▎   | 5402/8564 [00:15<00:05, 604.64 examples/s]Tokenizing train dataset:  66%|██████▌   | 5614/8564 [00:15<00:04, 624.28 examples/s]Tokenizing train dataset:  65%|██████▍   | 5526/8564 [00:15<00:04, 612.36 examples/s]Tokenizing train dataset:  64%|██████▍   | 5470/8564 [00:15<00:05, 618.42 examples/s]Tokenizing train dataset:  67%|██████▋   | 5712/8564 [00:15<00:04, 632.34 examples/s]Tokenizing train dataset:  66%|██████▌   | 5621/8564 [00:15<00:04, 617.24 examples/s]Tokenizing train dataset:  65%|██████▍   | 5560/8564 [00:15<00:04, 601.48 examples/s]Tokenizing train dataset:  68%|██████▊   | 5783/8564 [00:15<00:04, 647.64 examples/s]Tokenizing train dataset:  66%|██████▋   | 5689/8564 [00:15<00:04, 629.83 examples/s]Tokenizing train dataset:  66%|██████▌   | 5631/8564 [00:15<00:04, 624.25 examples/s]Tokenizing train dataset:  68%|██████▊   | 5850/8564 [00:15<00:04, 647.99 examples/s]Tokenizing train dataset:  67%|██████▋   | 5757/8564 [00:15<00:04, 638.69 examples/s]Tokenizing train dataset:  67%|██████▋   | 5698/8564 [00:15<00:04, 633.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 5832/8564 [00:15<00:04, 664.48 examples/s]Tokenizing train dataset:  69%|██████▉   | 5941/8564 [00:15<00:04, 629.55 examples/s]Tokenizing train dataset:  67%|██████▋   | 5771/8564 [00:15<00:04, 652.31 examples/s]Tokenizing train dataset:  69%|██████▉   | 5918/8564 [00:15<00:04, 628.10 examples/s]Tokenizing train dataset:  70%|███████   | 6023/8564 [00:16<00:04, 592.96 examples/s]Tokenizing train dataset:  68%|██████▊   | 5842/8564 [00:15<00:04, 658.47 examples/s]Tokenizing train dataset:  71%|███████   | 6085/8564 [00:16<00:04, 594.57 examples/s]Tokenizing train dataset:  69%|██████▉   | 5930/8564 [00:15<00:04, 625.89 examples/s]Tokenizing train dataset:  70%|███████   | 6014/8564 [00:16<00:04, 605.07 examples/s]Tokenizing train dataset:  72%|███████▏  | 6156/8564 [00:16<00:03, 619.67 examples/s]Tokenizing train dataset:  73%|███████▎  | 6230/8564 [00:16<00:03, 649.52 examples/s]Tokenizing train dataset:  70%|███████   | 6015/8564 [00:16<00:04, 601.73 examples/s]Tokenizing train dataset:  71%|███████   | 6100/8564 [00:16<00:04, 590.82 examples/s]Tokenizing train dataset:  72%|███████▏  | 6176/8564 [00:16<00:03, 628.30 examples/s]Tokenizing train dataset:  71%|███████   | 6099/8564 [00:16<00:04, 587.28 examples/s]Tokenizing train dataset:  74%|███████▍  | 6329/8564 [00:16<00:03, 644.56 examples/s]Tokenizing train dataset:  73%|███████▎  | 6245/8564 [00:16<00:03, 642.54 examples/s]Tokenizing train dataset:  72%|███████▏  | 6175/8564 [00:16<00:03, 622.85 examples/s]Tokenizing train dataset:  75%|███████▍  | 6400/8564 [00:16<00:03, 654.07 examples/s]Tokenizing train dataset:  74%|███████▎  | 6311/8564 [00:16<00:03, 643.32 examples/s]Tokenizing train dataset:  73%|███████▎  | 6244/8564 [00:16<00:03, 637.00 examples/s]Tokenizing train dataset:  75%|███████▍  | 6385/8564 [00:16<00:03, 666.64 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [00:16<00:03, 630.07 examples/s]Tokenizing train dataset:  74%|███████▎  | 6311/8564 [00:16<00:03, 639.18 examples/s]Tokenizing train dataset:  75%|███████▍  | 6384/8564 [00:16<00:03, 660.34 examples/s]Tokenizing train dataset:  76%|███████▌  | 6477/8564 [00:16<00:03, 639.65 examples/s]Tokenizing train dataset:  77%|███████▋  | 6582/8564 [00:16<00:03, 614.94 examples/s]Tokenizing train dataset:  76%|███████▌  | 6477/8564 [00:16<00:03, 635.98 examples/s]Tokenizing train dataset:  77%|███████▋  | 6568/8564 [00:16<00:03, 623.35 examples/s]Tokenizing train dataset:  78%|███████▊  | 6665/8564 [00:17<00:03, 593.26 examples/s]Tokenizing train dataset:  79%|███████▊  | 6733/8564 [00:17<00:02, 611.68 examples/s]Tokenizing train dataset:  77%|███████▋  | 6567/8564 [00:16<00:03, 621.40 examples/s]Tokenizing train dataset:  78%|███████▊  | 6647/8564 [00:17<00:03, 588.21 examples/s]Tokenizing train dataset:  79%|███████▉  | 6801/8564 [00:17<00:02, 623.65 examples/s]Tokenizing train dataset:  78%|███████▊  | 6718/8564 [00:17<00:02, 616.08 examples/s]Tokenizing train dataset:  78%|███████▊  | 6646/8564 [00:17<00:03, 584.11 examples/s]Tokenizing train dataset:  79%|███████▉  | 6785/8564 [00:17<00:02, 627.99 examples/s]Tokenizing train dataset:  80%|████████  | 6891/8564 [00:17<00:02, 612.22 examples/s]Tokenizing train dataset:  78%|███████▊  | 6718/8564 [00:17<00:03, 613.16 examples/s]Tokenizing train dataset:  81%|████████  | 6958/8564 [00:17<00:02, 623.11 examples/s]Tokenizing train dataset:  79%|███████▉  | 6783/8564 [00:17<00:02, 621.68 examples/s]Tokenizing train dataset:  80%|████████  | 6874/8564 [00:17<00:02, 609.40 examples/s]Tokenizing train dataset:  81%|████████  | 6945/8564 [00:17<00:02, 631.53 examples/s]Tokenizing train dataset:  82%|████████▏ | 7043/8564 [00:17<00:02, 597.51 examples/s]Tokenizing train dataset:  80%|████████  | 6872/8564 [00:17<00:02, 604.65 examples/s]Tokenizing train dataset:  83%|████████▎ | 7111/8564 [00:17<00:02, 615.66 examples/s]Tokenizing train dataset:  82%|████████▏ | 7025/8564 [00:17<00:02, 589.60 examples/s]Tokenizing train dataset:  81%|████████  | 6944/8564 [00:17<00:02, 628.96 examples/s]Tokenizing train dataset:  84%|████████▍ | 7180/8564 [00:17<00:02, 629.95 examples/s]Tokenizing train dataset:  83%|████████▎ | 7097/8564 [00:17<00:02, 618.02 examples/s]Tokenizing train dataset:  82%|████████▏ | 7020/8564 [00:17<00:02, 584.65 examples/s]Tokenizing train dataset:  85%|████████▍ | 7271/8564 [00:18<00:02, 617.89 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [00:17<00:02, 613.75 examples/s]Tokenizing train dataset:  84%|████████▍ | 7202/8564 [00:17<00:02, 642.26 examples/s]Tokenizing train dataset:  84%|████████▎ | 7154/8564 [00:17<00:02, 615.27 examples/s]Tokenizing train dataset:  86%|████████▌ | 7367/8564 [00:18<00:01, 622.43 examples/s]Tokenizing train dataset:  85%|████████▌ | 7290/8564 [00:18<00:02, 619.10 examples/s]Tokenizing train dataset:  84%|████████▍ | 7221/8564 [00:18<00:02, 629.24 examples/s]Tokenizing train dataset:  87%|████████▋ | 7430/8564 [00:18<00:01, 622.78 examples/s]Tokenizing train dataset:  86%|████████▌ | 7356/8564 [00:18<00:01, 624.88 examples/s]Tokenizing train dataset:  88%|████████▊ | 7497/8564 [00:18<00:01, 631.91 examples/s]Tokenizing train dataset:  85%|████████▌ | 7313/8564 [00:18<00:02, 616.77 examples/s]Tokenizing train dataset:  87%|████████▋ | 7421/8564 [00:18<00:01, 621.71 examples/s]Tokenizing train dataset:  88%|████████▊ | 7566/8564 [00:18<00:01, 642.62 examples/s]Tokenizing train dataset:  86%|████████▌ | 7379/8564 [00:18<00:01, 627.15 examples/s]Tokenizing train dataset:  87%|████████▋ | 7487/8564 [00:18<00:01, 630.61 examples/s]Tokenizing train dataset:  89%|████████▉ | 7634/8564 [00:18<00:01, 647.41 examples/s]Tokenizing train dataset:  87%|████████▋ | 7443/8564 [00:18<00:01, 628.55 examples/s]Tokenizing train dataset:  88%|████████▊ | 7556/8564 [00:18<00:01, 643.55 examples/s]Tokenizing train dataset:  90%|█████████ | 7721/8564 [00:18<00:01, 619.00 examples/s]Tokenizing train dataset:  89%|████████▉ | 7629/8564 [00:18<00:01, 657.67 examples/s]Tokenizing train dataset:  88%|████████▊ | 7543/8564 [00:18<00:01, 637.62 examples/s]Tokenizing train dataset:  89%|████████▉ | 7612/8564 [00:18<00:01, 646.99 examples/s]Tokenizing train dataset:  91%|█████████ | 7803/8564 [00:18<00:01, 588.98 examples/s]Tokenizing train dataset:  90%|█████████ | 7715/8564 [00:18<00:01, 621.68 examples/s]Tokenizing train dataset:  92%|█████████▏| 7865/8564 [00:19<00:01, 595.13 examples/s]Tokenizing train dataset:  90%|████████▉ | 7698/8564 [00:18<00:01, 619.43 examples/s]Tokenizing train dataset:  91%|█████████ | 7799/8564 [00:18<00:01, 593.97 examples/s]Tokenizing train dataset:  93%|█████████▎| 7930/8564 [00:19<00:01, 603.71 examples/s]Tokenizing train dataset:  92%|█████████▏| 7861/8564 [00:19<00:01, 596.87 examples/s]Tokenizing train dataset:  91%|█████████ | 7784/8564 [00:18<00:01, 598.26 examples/s]Tokenizing train dataset:  93%|█████████▎| 7995/8564 [00:19<00:00, 614.72 examples/s]Tokenizing train dataset:  93%|█████████▎| 7926/8564 [00:19<00:01, 605.99 examples/s]Tokenizing train dataset:  92%|█████████▏| 7847/8564 [00:19<00:01, 602.40 examples/s]Tokenizing train dataset:  94%|█████████▍| 8062/8564 [00:19<00:00, 619.09 examples/s]Tokenizing train dataset:  93%|█████████▎| 7991/8564 [00:19<00:00, 614.37 examples/s]Tokenizing train dataset:  92%|█████████▏| 7908/8564 [00:19<00:01, 602.46 examples/s]Tokenizing train dataset:  95%|█████████▌| 8144/8564 [00:19<00:00, 588.97 examples/s]Tokenizing train dataset:  94%|█████████▍| 8055/8564 [00:19<00:00, 616.90 examples/s]Tokenizing train dataset:  93%|█████████▎| 7969/8564 [00:19<00:00, 603.29 examples/s]Tokenizing train dataset:  96%|█████████▌| 8209/8564 [00:19<00:00, 597.81 examples/s]Tokenizing train dataset:  94%|█████████▍| 8032/8564 [00:19<00:00, 608.02 examples/s]Tokenizing train dataset:  95%|█████████▌| 8141/8564 [00:19<00:00, 596.89 examples/s]Tokenizing train dataset:  97%|█████████▋| 8287/8564 [00:19<00:00, 643.46 examples/s]Tokenizing train dataset:  96%|█████████▌| 8205/8564 [00:19<00:00, 602.88 examples/s]Tokenizing train dataset:  95%|█████████▍| 8120/8564 [00:19<00:00, 592.23 examples/s]Tokenizing train dataset:  98%|█████████▊| 8373/8564 [00:19<00:00, 615.25 examples/s]Tokenizing train dataset:  97%|█████████▋| 8280/8564 [00:19<00:00, 638.40 examples/s]Tokenizing train dataset:  96%|█████████▌| 8184/8564 [00:19<00:00, 600.69 examples/s]Tokenizing train dataset:  97%|█████████▋| 8345/8564 [00:19<00:00, 631.00 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [00:19<00:00, 610.52 examples/s]Tokenizing train dataset:  99%|█████████▉| 8465/8564 [00:19<00:00, 610.26 examples/s]Tokenizing train dataset:  97%|█████████▋| 8328/8564 [00:19<00:00, 649.04 examples/s]Tokenizing train dataset: 100%|█████████▉| 8532/8564 [00:20<00:00, 619.35 examples/s]Tokenizing train dataset:  98%|█████████▊| 8434/8564 [00:19<00:00, 611.75 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 424.86 examples/s]
Tokenizing train dataset:  99%|█████████▉| 8499/8564 [00:20<00:00, 617.14 examples/s]Tokenizing train dataset:  98%|█████████▊| 8410/8564 [00:19<00:00, 609.09 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 620.92 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 424.04 examples/s]
Tokenizing train dataset:  99%|█████████▉| 8474/8564 [00:20<00:00, 615.94 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 611.64 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 423.38 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11513.79 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11385.33 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 10962.69 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13504.55 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11480.98 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11905.24 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 320.13 examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:03, 265.69 examples/s]Tokenizing eval dataset:   3%|▎         | 30/953 [00:00<00:03, 283.20 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:03, 289.78 examples/s]Tokenizing eval dataset:   7%|▋         | 63/953 [00:00<00:03, 238.61 examples/s]Tokenizing eval dataset:   7%|▋         | 67/953 [00:00<00:03, 250.17 examples/s]Tokenizing eval dataset:  12%|█▏        | 118/953 [00:00<00:03, 277.98 examples/s]Tokenizing eval dataset:   9%|▉         | 90/953 [00:00<00:03, 245.09 examples/s]Tokenizing eval dataset:  10%|▉         | 94/953 [00:00<00:03, 252.57 examples/s]Tokenizing eval dataset:  17%|█▋        | 158/953 [00:00<00:02, 268.69 examples/s]Tokenizing eval dataset:  13%|█▎        | 123/953 [00:00<00:03, 227.38 examples/s]Tokenizing eval dataset:  14%|█▎        | 130/953 [00:00<00:03, 239.01 examples/s]Tokenizing eval dataset:  16%|█▋        | 157/953 [00:00<00:03, 222.84 examples/s]Tokenizing eval dataset:  20%|██        | 195/953 [00:00<00:02, 253.80 examples/s]Tokenizing eval dataset:  17%|█▋        | 164/953 [00:00<00:03, 230.90 examples/s]Tokenizing eval dataset:  24%|██▍       | 231/953 [00:00<00:02, 278.78 examples/s]Tokenizing eval dataset:  20%|█▉        | 187/953 [00:00<00:03, 209.18 examples/s]Tokenizing eval dataset:  20%|██        | 195/953 [00:00<00:03, 217.90 examples/s]Tokenizing eval dataset:  31%|███       | 297/953 [00:00<00:01, 377.91 examples/s]Tokenizing eval dataset:  22%|██▏       | 210/953 [00:00<00:03, 210.42 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:00<00:03, 230.14 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:01<00:01, 441.94 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:01<00:02, 266.05 examples/s]Tokenizing eval dataset:  29%|██▉       | 280/953 [00:01<00:02, 315.16 examples/s]Tokenizing eval dataset:  45%|████▍     | 426/953 [00:01<00:01, 500.93 examples/s]Tokenizing eval dataset:  32%|███▏      | 307/953 [00:01<00:01, 338.03 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:01<00:01, 382.50 examples/s]Tokenizing eval dataset:  52%|█████▏    | 494/953 [00:01<00:00, 543.65 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:01<00:01, 384.70 examples/s]Tokenizing eval dataset:  41%|████      | 391/953 [00:01<00:01, 417.37 examples/s]Tokenizing eval dataset:  59%|█████▉    | 562/953 [00:01<00:00, 576.61 examples/s]Tokenizing eval dataset:  43%|████▎     | 410/953 [00:01<00:01, 414.98 examples/s]Tokenizing eval dataset:  48%|████▊     | 456/953 [00:01<00:01, 479.80 examples/s]Tokenizing eval dataset:  66%|██████▌   | 628/953 [00:01<00:00, 598.51 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:01<00:01, 461.49 examples/s]Tokenizing eval dataset:  53%|█████▎    | 506/953 [00:01<00:00, 482.44 examples/s]Tokenizing eval dataset:  73%|███████▎  | 691/953 [00:01<00:00, 602.46 examples/s]Tokenizing eval dataset:  55%|█████▍    | 520/953 [00:01<00:00, 469.90 examples/s]Tokenizing eval dataset:  59%|█████▉    | 562/953 [00:01<00:00, 499.12 examples/s]Tokenizing eval dataset:  82%|████████▏ | 777/953 [00:01<00:00, 577.41 examples/s]Tokenizing eval dataset:  60%|██████    | 572/953 [00:01<00:00, 481.88 examples/s]Tokenizing eval dataset:  65%|██████▍   | 618/953 [00:01<00:00, 514.42 examples/s]Tokenizing eval dataset:  66%|██████▌   | 627/953 [00:01<00:00, 498.58 examples/s]Tokenizing eval dataset:  89%|████████▉ | 852/953 [00:01<00:00, 540.67 examples/s]Tokenizing eval dataset:  73%|███████▎  | 696/953 [00:01<00:00, 512.36 examples/s]Tokenizing eval dataset:  73%|███████▎  | 700/953 [00:01<00:00, 485.53 examples/s]Tokenizing eval dataset:  97%|█████████▋| 929/953 [00:02<00:00, 525.55 examples/s]Tokenizing eval dataset:  80%|████████  | 765/953 [00:01<00:00, 490.74 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 458.08 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  81%|████████  | 770/953 [00:02<00:00, 465.42 examples/s]Tokenizing eval dataset:  87%|████████▋ | 828/953 [00:02<00:00, 463.56 examples/s]Tokenizing eval dataset:  88%|████████▊ | 840/953 [00:02<00:00, 461.64 examples/s]Tokenizing eval dataset:  92%|█████████▏| 880/953 [00:02<00:00, 474.92 examples/s]Tokenizing eval dataset:  93%|█████████▎| 890/953 [00:02<00:00, 467.08 examples/s]Tokenizing eval dataset:  98%|█████████▊| 930/953 [00:02<00:00, 479.57 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 399.87 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:02<00:00, 472.59 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 384.86 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.505331516265869 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.5220437049865723 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3855197429656982 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.457289218902588 seconds
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Training complete
Saving model
[rank4]:[W531 15:08:49.737089301 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 1 ---
