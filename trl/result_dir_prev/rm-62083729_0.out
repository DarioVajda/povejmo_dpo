cpu-bind=MASK - gn21, task  0  0 [622601]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn21
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 0     --main_process_ip gn21     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62083729     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-31 01:43:04,642] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0531 01:43:06.464000 622654 torch/distributed/run.py:792] 
W0531 01:43:06.464000 622654 torch/distributed/run.py:792] *****************************************
W0531 01:43:06.464000 622654 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0531 01:43:06.464000 622654 torch/distributed/run.py:792] *****************************************
[2025-05-31 01:43:17,098] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 01:43:17,140] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 01:43:17,151] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 01:43:17,155] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Created datasets
Created datasets
Created datasets
Number of training examples: Number of training examples: Number of training examples: Number of training examples: 8564
8564
8564
8564
Number of validation examples: Number of validation examples: Number of validation examples: Number of validation examples: 953
953
953
953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
3e-07
3e-07
3e-07
World size: 8
Setting gradient accumulation steps to: 2
[2025-05-31 01:43:21,358] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 01:43:21,375] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 01:43:21,387] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 4282
Eval steps: 2141
[2025-05-31 01:43:21,551] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 01:43:21,564] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
[2025-05-31 01:43:23,129] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-31 01:43:23,129] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-31 01:43:23,129] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-31 01:43:23,129] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
hpZeRO group size: 4
[2025-05-31 01:43:38,949] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 465, num_elems = 10.16B
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.28s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.29s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.30s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:16<00:48, 16.09s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:19<00:21, 10.64s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:19<00:21, 10.64s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:19<00:21, 10.65s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:27<00:27, 13.51s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:30<00:11, 11.03s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:30<00:11, 11.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:30<00:11, 11.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:39<00:12, 12.85s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.45s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.46s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.46s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.04s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.04s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.04s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00, 11.30s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00, 12.21s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
Using LoRA and set up the model
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:00<00:01, 5418.95 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1375/8564 [00:00<00:01, 5441.70 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2060/8564 [00:00<00:01, 4994.57 examples/s]Extracting prompt in train dataset:  31%|███       | 2648/8564 [00:00<00:01, 4488.59 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3370/8564 [00:00<00:01, 4603.01 examples/s]Extracting prompt in train dataset:  46%|████▌     | 3960/8564 [00:00<00:01, 4085.75 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4490/8564 [00:00<00:00, 4362.00 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4990/8564 [00:01<00:00, 4505.16 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5470/8564 [00:01<00:00, 4579.74 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5994/8564 [00:01<00:00, 4759.10 examples/s]Extracting prompt in train dataset:  79%|███████▊  | 6740/8564 [00:01<00:00, 4828.74 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7450/8564 [00:01<00:00, 4787.27 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 8020/8564 [00:01<00:00, 3779.88 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 8532/8564 [00:01<00:00, 4061.09 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 4152.39 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 288/8564 [00:00<00:02, 2850.53 examples/s]Applying chat template to train dataset:   7%|▋         | 586/8564 [00:00<00:02, 2924.43 examples/s]Applying chat template to train dataset:  10%|█         | 880/8564 [00:00<00:02, 2924.19 examples/s]Applying chat template to train dataset:  15%|█▌        | 1291/8564 [00:00<00:02, 2829.66 examples/s]Applying chat template to train dataset:  18%|█▊        | 1584/8564 [00:00<00:02, 2858.32 examples/s]Applying chat template to train dataset:  23%|██▎       | 1938/8564 [00:00<00:02, 2648.01 examples/s]Applying chat template to train dataset:  27%|██▋       | 2342/8564 [00:00<00:02, 2661.44 examples/s]Applying chat template to train dataset:  31%|███       | 2638/8564 [00:00<00:02, 2736.46 examples/s]Applying chat template to train dataset:  34%|███▍      | 2927/8564 [00:01<00:02, 2776.41 examples/s]Applying chat template to train dataset:  39%|███▉      | 3347/8564 [00:01<00:01, 2783.71 examples/s]Applying chat template to train dataset:  44%|████▍     | 3761/8564 [00:01<00:01, 2773.84 examples/s]Applying chat template to train dataset:  47%|████▋     | 4050/8564 [00:01<00:01, 2798.70 examples/s]Applying chat template to train dataset:  51%|█████     | 4362/8564 [00:01<00:01, 2881.97 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4816/8564 [00:01<00:01, 2929.09 examples/s]Applying chat template to train dataset:  61%|██████    | 5200/8564 [00:01<00:01, 2802.11 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5644/8564 [00:02<00:01, 2850.10 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5963/8564 [00:02<00:00, 2927.74 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6263/8564 [00:02<00:00, 2943.38 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6570/8564 [00:02<00:00, 2975.93 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7030/8564 [00:02<00:00, 3006.42 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7368/8564 [00:02<00:00, 2722.02 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7670/8564 [00:02<00:00, 2792.58 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8074/8564 [00:02<00:00, 2710.86 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8470/8564 [00:03<00:00, 2684.56 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2765.45 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/8564 [00:00<00:21, 401.06 examples/s]Tokenizing train dataset:   1%|          | 88/8564 [00:00<00:25, 331.44 examples/s]Tokenizing train dataset:   2%|▏         | 129/8564 [00:00<00:27, 301.44 examples/s]Tokenizing train dataset:   2%|▏         | 171/8564 [00:00<00:29, 289.18 examples/s]Tokenizing train dataset:   2%|▏         | 214/8564 [00:00<00:29, 284.27 examples/s]Tokenizing train dataset:   3%|▎         | 247/8564 [00:00<00:28, 294.86 examples/s]Tokenizing train dataset:   3%|▎         | 280/8564 [00:00<00:27, 301.47 examples/s]Tokenizing train dataset:   4%|▎         | 315/8564 [00:01<00:30, 266.44 examples/s]Tokenizing train dataset:   4%|▍         | 347/8564 [00:01<00:33, 246.04 examples/s]Tokenizing train dataset:   4%|▍         | 384/8564 [00:01<00:35, 233.33 examples/s]Tokenizing train dataset:   5%|▍         | 413/8564 [00:01<00:33, 245.22 examples/s]Tokenizing train dataset:   5%|▌         | 440/8564 [00:01<00:32, 249.68 examples/s]Tokenizing train dataset:   6%|▌         | 472/8564 [00:01<00:30, 264.55 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:01<00:30, 261.59 examples/s]Tokenizing train dataset:   6%|▋         | 543/8564 [00:01<00:29, 271.61 examples/s]Tokenizing train dataset:   7%|▋         | 571/8564 [00:02<00:29, 271.38 examples/s]Tokenizing train dataset:   7%|▋         | 614/8564 [00:02<00:29, 271.65 examples/s]Tokenizing train dataset:   8%|▊         | 644/8564 [00:02<00:28, 277.88 examples/s]Tokenizing train dataset:   8%|▊         | 673/8564 [00:02<00:28, 276.73 examples/s]Tokenizing train dataset:   8%|▊         | 713/8564 [00:02<00:29, 267.33 examples/s]Tokenizing train dataset:   9%|▉         | 753/8564 [00:02<00:30, 252.86 examples/s]Tokenizing train dataset:   9%|▉         | 787/8564 [00:02<00:32, 242.61 examples/s]Tokenizing train dataset:  10%|▉         | 825/8564 [00:03<00:32, 241.52 examples/s]Tokenizing train dataset:  10%|▉         | 851/8564 [00:03<00:31, 243.77 examples/s]Tokenizing train dataset:  10%|█         | 882/8564 [00:03<00:29, 258.05 examples/s]Tokenizing train dataset:  11%|█         | 915/8564 [00:03<00:27, 274.72 examples/s]Tokenizing train dataset:  11%|█         | 957/8564 [00:03<00:27, 273.03 examples/s]Tokenizing train dataset:  12%|█▏        | 988/8564 [00:03<00:30, 246.42 examples/s]Tokenizing train dataset:  12%|█▏        | 1017/8564 [00:03<00:29, 253.29 examples/s]Tokenizing train dataset:  12%|█▏        | 1054/8564 [00:03<00:30, 247.68 examples/s]Tokenizing train dataset:  13%|█▎        | 1096/8564 [00:04<00:29, 254.52 examples/s]Tokenizing train dataset:  13%|█▎        | 1125/8564 [00:04<00:32, 229.85 examples/s]Tokenizing train dataset:  14%|█▎        | 1159/8564 [00:04<00:32, 226.54 examples/s]Tokenizing train dataset:  14%|█▍        | 1188/8564 [00:04<00:30, 238.95 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:04<00:29, 248.52 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:04<00:28, 260.56 examples/s]Tokenizing train dataset:  15%|█▍        | 1278/8564 [00:04<00:27, 262.86 examples/s]Tokenizing train dataset:  15%|█▌        | 1308/8564 [00:04<00:26, 269.55 examples/s]Tokenizing train dataset:  16%|█▌        | 1338/8564 [00:05<00:26, 275.68 examples/s]Tokenizing train dataset:  16%|█▌        | 1372/8564 [00:05<00:28, 253.08 examples/s]Tokenizing train dataset:  16%|█▋        | 1402/8564 [00:05<00:27, 263.01 examples/s]Tokenizing train dataset:  17%|█▋        | 1429/8564 [00:05<00:27, 262.12 examples/s]Tokenizing train dataset:  17%|█▋        | 1456/8564 [00:05<00:26, 263.81 examples/s]Tokenizing train dataset:  17%|█▋        | 1492/8564 [00:05<00:28, 250.48 examples/s]Tokenizing train dataset:  18%|█▊        | 1531/8564 [00:05<00:28, 249.61 examples/s]Tokenizing train dataset:  18%|█▊        | 1560/8564 [00:05<00:27, 257.54 examples/s]Tokenizing train dataset:  19%|█▊        | 1601/8564 [00:06<00:26, 258.01 examples/s]Tokenizing train dataset:  19%|█▉        | 1640/8564 [00:06<00:27, 255.23 examples/s]Tokenizing train dataset:  19%|█▉        | 1667/8564 [00:06<00:26, 255.63 examples/s]Tokenizing train dataset:  20%|█▉        | 1702/8564 [00:06<00:24, 278.55 examples/s]Tokenizing train dataset:  20%|██        | 1736/8564 [00:06<00:26, 257.28 examples/s]Tokenizing train dataset:  21%|██        | 1774/8564 [00:06<00:26, 251.73 examples/s]Tokenizing train dataset:  21%|██        | 1802/8564 [00:06<00:26, 257.55 examples/s]Tokenizing train dataset:  21%|██▏       | 1833/8564 [00:07<00:25, 267.20 examples/s]Tokenizing train dataset:  22%|██▏       | 1863/8564 [00:07<00:28, 232.99 examples/s]Tokenizing train dataset:  22%|██▏       | 1890/8564 [00:07<00:28, 237.14 examples/s]Tokenizing train dataset:  22%|██▏       | 1920/8564 [00:07<00:26, 251.20 examples/s]Tokenizing train dataset:  23%|██▎       | 1952/8564 [00:07<00:24, 268.72 examples/s]Tokenizing train dataset:  23%|██▎       | 1981/8564 [00:07<00:24, 272.61 examples/s]Tokenizing train dataset:  23%|██▎       | 2009/8564 [00:07<00:23, 274.18 examples/s]Tokenizing train dataset:  24%|██▍       | 2050/8564 [00:07<00:27, 234.33 examples/s]Tokenizing train dataset:  24%|██▍       | 2088/8564 [00:08<00:27, 231.63 examples/s]Tokenizing train dataset:  25%|██▍       | 2128/8564 [00:08<00:28, 228.25 examples/s]Tokenizing train dataset:  25%|██▌       | 2160/8564 [00:08<00:26, 244.01 examples/s]Tokenizing train dataset:  26%|██▌       | 2192/8564 [00:08<00:24, 257.89 examples/s]Tokenizing train dataset:  26%|██▌       | 2235/8564 [00:08<00:23, 264.44 examples/s]Tokenizing train dataset:  27%|██▋       | 2270/8564 [00:08<00:22, 283.17 examples/s]Tokenizing train dataset:  27%|██▋       | 2305/8564 [00:08<00:20, 298.17 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:08<00:21, 294.28 examples/s]Tokenizing train dataset:  28%|██▊       | 2384/8564 [00:09<00:20, 305.19 examples/s]Tokenizing train dataset:  28%|██▊       | 2417/8564 [00:09<00:19, 310.07 examples/s]Tokenizing train dataset:  29%|██▊       | 2449/8564 [00:09<00:19, 306.99 examples/s]Tokenizing train dataset:  29%|██▉       | 2494/8564 [00:09<00:20, 300.54 examples/s]Tokenizing train dataset:  30%|██▉       | 2534/8564 [00:09<00:21, 286.97 examples/s]Tokenizing train dataset:  30%|███       | 2571/8564 [00:09<00:19, 304.70 examples/s]Tokenizing train dataset:  30%|███       | 2606/8564 [00:09<00:18, 314.97 examples/s]Tokenizing train dataset:  31%|███       | 2652/8564 [00:09<00:19, 297.70 examples/s]Tokenizing train dataset:  31%|███▏      | 2696/8564 [00:10<00:20, 293.39 examples/s]Tokenizing train dataset:  32%|███▏      | 2730/8564 [00:10<00:19, 301.66 examples/s]Tokenizing train dataset:  32%|███▏      | 2776/8564 [00:10<00:19, 301.35 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:10<00:19, 292.24 examples/s]Tokenizing train dataset:  33%|███▎      | 2857/8564 [00:10<00:20, 276.12 examples/s]Tokenizing train dataset:  34%|███▎      | 2890/8564 [00:10<00:19, 284.26 examples/s]Tokenizing train dataset:  34%|███▍      | 2924/8564 [00:10<00:19, 295.86 examples/s]Tokenizing train dataset:  35%|███▍      | 2960/8564 [00:11<00:18, 310.03 examples/s]Tokenizing train dataset:  35%|███▌      | 2998/8564 [00:11<00:17, 325.20 examples/s]Tokenizing train dataset:  35%|███▌      | 3040/8564 [00:11<00:18, 304.64 examples/s]Tokenizing train dataset:  36%|███▌      | 3090/8564 [00:11<00:17, 310.83 examples/s]Tokenizing train dataset:  37%|███▋      | 3137/8564 [00:11<00:17, 308.67 examples/s]Tokenizing train dataset:  37%|███▋      | 3170/8564 [00:11<00:17, 308.28 examples/s]Tokenizing train dataset:  37%|███▋      | 3205/8564 [00:11<00:16, 316.39 examples/s]Tokenizing train dataset:  38%|███▊      | 3256/8564 [00:11<00:16, 322.28 examples/s]Tokenizing train dataset:  38%|███▊      | 3289/8564 [00:12<00:16, 320.61 examples/s]Tokenizing train dataset:  39%|███▉      | 3335/8564 [00:12<00:16, 311.96 examples/s]Tokenizing train dataset:  39%|███▉      | 3382/8564 [00:12<00:16, 311.24 examples/s]Tokenizing train dataset:  40%|███▉      | 3423/8564 [00:12<00:15, 329.48 examples/s]Tokenizing train dataset:  40%|████      | 3457/8564 [00:12<00:15, 330.70 examples/s]Tokenizing train dataset:  41%|████      | 3494/8564 [00:12<00:16, 300.80 examples/s]Tokenizing train dataset:  41%|████      | 3532/8564 [00:12<00:15, 318.65 examples/s]Tokenizing train dataset:  42%|████▏     | 3586/8564 [00:12<00:15, 329.75 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:13<00:16, 295.81 examples/s]Tokenizing train dataset:  43%|████▎     | 3664/8564 [00:13<00:17, 276.76 examples/s]Tokenizing train dataset:  43%|████▎     | 3696/8564 [00:13<00:17, 284.89 examples/s]Tokenizing train dataset:  44%|████▎     | 3729/8564 [00:13<00:16, 293.29 examples/s]Tokenizing train dataset:  44%|████▍     | 3779/8564 [00:13<00:15, 304.36 examples/s]Tokenizing train dataset:  45%|████▍     | 3811/8564 [00:13<00:15, 305.25 examples/s]Tokenizing train dataset:  45%|████▍     | 3850/8564 [00:13<00:16, 287.47 examples/s]Tokenizing train dataset:  45%|████▌     | 3894/8564 [00:14<00:16, 284.87 examples/s]Tokenizing train dataset:  46%|████▌     | 3933/8564 [00:14<00:16, 273.59 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:14<00:16, 277.10 examples/s]Tokenizing train dataset:  47%|████▋     | 3997/8564 [00:14<00:15, 289.57 examples/s]Tokenizing train dataset:  47%|████▋     | 4029/8564 [00:14<00:15, 296.63 examples/s]Tokenizing train dataset:  47%|████▋     | 4060/8564 [00:14<00:15, 296.62 examples/s]Tokenizing train dataset:  48%|████▊     | 4103/8564 [00:14<00:15, 290.84 examples/s]Tokenizing train dataset:  48%|████▊     | 4145/8564 [00:14<00:15, 282.94 examples/s]Tokenizing train dataset:  49%|████▉     | 4189/8564 [00:15<00:15, 282.21 examples/s]Tokenizing train dataset:  49%|████▉     | 4226/8564 [00:15<00:14, 300.40 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:15<00:14, 303.92 examples/s]Tokenizing train dataset:  50%|█████     | 4295/8564 [00:15<00:13, 312.38 examples/s]Tokenizing train dataset:  51%|█████     | 4341/8564 [00:15<00:13, 304.04 examples/s]Tokenizing train dataset:  51%|█████     | 4379/8564 [00:15<00:13, 319.57 examples/s]Tokenizing train dataset:  52%|█████▏    | 4415/8564 [00:15<00:12, 327.42 examples/s]Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:15<00:12, 328.50 examples/s]Tokenizing train dataset:  53%|█████▎    | 4498/8564 [00:16<00:12, 323.62 examples/s]Tokenizing train dataset:  53%|█████▎    | 4546/8564 [00:16<00:12, 317.88 examples/s]Tokenizing train dataset:  54%|█████▎    | 4593/8564 [00:16<00:12, 314.17 examples/s]Tokenizing train dataset:  54%|█████▍    | 4628/8564 [00:16<00:12, 317.85 examples/s]Tokenizing train dataset:  55%|█████▍    | 4671/8564 [00:16<00:12, 303.04 examples/s]Tokenizing train dataset:  55%|█████▌    | 4716/8564 [00:16<00:12, 299.30 examples/s]Tokenizing train dataset:  56%|█████▌    | 4759/8564 [00:16<00:13, 291.92 examples/s]Tokenizing train dataset:  56%|█████▌    | 4790/8564 [00:17<00:12, 292.68 examples/s]Tokenizing train dataset:  57%|█████▋    | 4848/8564 [00:17<00:10, 360.90 examples/s]Tokenizing train dataset:  57%|█████▋    | 4893/8564 [00:17<00:09, 379.69 examples/s]Tokenizing train dataset:  58%|█████▊    | 4946/8564 [00:17<00:08, 413.87 examples/s]Tokenizing train dataset:  58%|█████▊    | 4995/8564 [00:17<00:08, 433.52 examples/s]Tokenizing train dataset:  59%|█████▉    | 5045/8564 [00:17<00:07, 450.67 examples/s]Tokenizing train dataset:  60%|█████▉    | 5106/8564 [00:17<00:07, 491.68 examples/s]Tokenizing train dataset:  60%|██████    | 5164/8564 [00:17<00:06, 515.13 examples/s]Tokenizing train dataset:  61%|██████    | 5229/8564 [00:17<00:06, 553.37 examples/s]Tokenizing train dataset:  62%|██████▏   | 5291/8564 [00:17<00:05, 569.93 examples/s]Tokenizing train dataset:  63%|██████▎   | 5368/8564 [00:18<00:05, 544.66 examples/s]Tokenizing train dataset:  64%|██████▎   | 5453/8564 [00:18<00:05, 551.14 examples/s]Tokenizing train dataset:  65%|██████▍   | 5534/8564 [00:18<00:05, 539.54 examples/s]Tokenizing train dataset:  65%|██████▌   | 5593/8564 [00:18<00:05, 547.03 examples/s]Tokenizing train dataset:  66%|██████▌   | 5663/8564 [00:18<00:05, 495.70 examples/s]Tokenizing train dataset:  67%|██████▋   | 5722/8564 [00:18<00:05, 515.81 examples/s]Tokenizing train dataset:  68%|██████▊   | 5789/8564 [00:18<00:05, 552.38 examples/s]Tokenizing train dataset:  68%|██████▊   | 5866/8564 [00:19<00:05, 532.63 examples/s]Tokenizing train dataset:  69%|██████▉   | 5943/8564 [00:19<00:05, 520.90 examples/s]Tokenizing train dataset:  70%|███████   | 6020/8564 [00:19<00:04, 515.51 examples/s]Tokenizing train dataset:  71%|███████   | 6092/8564 [00:19<00:04, 503.35 examples/s]Tokenizing train dataset:  72%|███████▏  | 6168/8564 [00:19<00:04, 502.86 examples/s]Tokenizing train dataset:  73%|███████▎  | 6224/8564 [00:19<00:04, 513.75 examples/s]Tokenizing train dataset:  73%|███████▎  | 6286/8564 [00:19<00:04, 539.09 examples/s]Tokenizing train dataset:  74%|███████▍  | 6347/8564 [00:19<00:04, 553.21 examples/s]Tokenizing train dataset:  75%|███████▍  | 6410/8564 [00:20<00:03, 568.47 examples/s]Tokenizing train dataset:  76%|███████▌  | 6469/8564 [00:20<00:03, 572.00 examples/s]Tokenizing train dataset:  76%|███████▋  | 6543/8564 [00:20<00:03, 539.86 examples/s]Tokenizing train dataset:  77%|███████▋  | 6602/8564 [00:20<00:04, 486.94 examples/s]Tokenizing train dataset:  78%|███████▊  | 6656/8564 [00:20<00:03, 498.56 examples/s]Tokenizing train dataset:  78%|███████▊  | 6722/8564 [00:20<00:03, 538.81 examples/s]Tokenizing train dataset:  79%|███████▉  | 6782/8564 [00:20<00:03, 550.36 examples/s]Tokenizing train dataset:  80%|████████  | 6864/8564 [00:20<00:03, 541.54 examples/s]Tokenizing train dataset:  81%|████████  | 6920/8564 [00:21<00:03, 544.13 examples/s]Tokenizing train dataset:  82%|████████▏ | 6980/8564 [00:21<00:02, 549.24 examples/s]Tokenizing train dataset:  82%|████████▏ | 7057/8564 [00:21<00:02, 531.07 examples/s]Tokenizing train dataset:  83%|████████▎ | 7135/8564 [00:21<00:02, 523.65 examples/s]Tokenizing train dataset:  84%|████████▍ | 7212/8564 [00:21<00:02, 516.71 examples/s]Tokenizing train dataset:  85%|████████▌ | 7293/8564 [00:21<00:02, 520.57 examples/s]Tokenizing train dataset:  86%|████████▌ | 7355/8564 [00:21<00:02, 537.44 examples/s]Tokenizing train dataset:  87%|████████▋ | 7413/8564 [00:21<00:02, 542.03 examples/s]Tokenizing train dataset:  87%|████████▋ | 7472/8564 [00:22<00:01, 551.68 examples/s]Tokenizing train dataset:  88%|████████▊ | 7555/8564 [00:22<00:01, 549.82 examples/s]Tokenizing train dataset:  89%|████████▉ | 7623/8564 [00:22<00:01, 580.89 examples/s]Tokenizing train dataset:  90%|████████▉ | 7691/8564 [00:22<00:01, 528.78 examples/s]Tokenizing train dataset:  91%|█████████ | 7770/8564 [00:22<00:01, 521.65 examples/s]Tokenizing train dataset:  92%|█████████▏| 7859/8564 [00:22<00:01, 534.54 examples/s]Tokenizing train dataset:  92%|█████████▏| 7915/8564 [00:22<00:01, 535.41 examples/s]Tokenizing train dataset:  93%|█████████▎| 7996/8564 [00:23<00:01, 533.82 examples/s]Tokenizing train dataset:  94%|█████████▍| 8063/8564 [00:23<00:00, 502.94 examples/s]Tokenizing train dataset:  95%|█████████▍| 8134/8564 [00:23<00:00, 492.22 examples/s]Tokenizing train dataset:  96%|█████████▌| 8187/8564 [00:23<00:00, 500.04 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [00:23<00:00, 467.85 examples/s]Tokenizing train dataset:  97%|█████████▋| 8311/8564 [00:23<00:00, 496.22 examples/s]Tokenizing train dataset:  98%|█████████▊| 8390/8564 [00:23<00:00, 504.21 examples/s]Tokenizing train dataset:  99%|█████████▊| 8443/8564 [00:23<00:00, 509.38 examples/s]Tokenizing train dataset: 100%|█████████▉| 8522/8564 [00:24<00:00, 513.13 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:24<00:00, 353.49 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 10682.03 examples/s]
Extracting prompt in train dataset:   7%|▋         | 560/8564 [00:00<00:01, 5516.53 examples/s]Extracting prompt in train dataset:   7%|▋         | 569/8564 [00:00<00:01, 5587.29 examples/s]Extracting prompt in train dataset:   6%|▋         | 553/8564 [00:00<00:01, 5480.50 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1380/8564 [00:00<00:01, 5447.84 examples/s]Extracting prompt in train dataset:  15%|█▍        | 1242/8564 [00:00<00:01, 4802.17 examples/s]Extracting prompt in train dataset:  15%|█▍        | 1274/8564 [00:00<00:01, 5019.77 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2110/8564 [00:00<00:01, 5139.72 examples/s]Extracting prompt in train dataset:  21%|██        | 1764/8564 [00:00<00:01, 4961.38 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1968/8564 [00:00<00:01, 4810.98 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  34%|███▎      | 2880/8564 [00:00<00:01, 5103.32 examples/s]Extracting prompt in train dataset:  30%|██▉       | 2558/8564 [00:00<00:01, 5100.53 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13090.59 examples/s]
Extracting prompt in train dataset:  31%|███▏      | 2686/8564 [00:00<00:01, 4786.91 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3630/8564 [00:00<00:00, 4983.61 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3280/8564 [00:00<00:01, 4962.35 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3226/8564 [00:00<00:01, 4323.71 examples/s]Extracting prompt in train dataset:  51%|█████     | 4370/8564 [00:00<00:00, 4944.11 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3716/8564 [00:00<00:01, 4464.96 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3862/8564 [00:00<00:01, 4310.07 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4880/8564 [00:00<00:00, 4970.22 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4255/8564 [00:00<00:00, 4708.47 examples/s]Extracting prompt in train dataset:  51%|█████     | 4370/8564 [00:00<00:00, 4495.60 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  64%|██████▎   | 5450/8564 [00:01<00:00, 5154.27 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4750/8564 [00:01<00:00, 4763.92 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 322.63 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 5090/8564 [00:01<00:00, 4584.66 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6130/8564 [00:01<00:00, 4922.66 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5462/8564 [00:01<00:00, 4746.68 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 5640/8564 [00:01<00:00, 4803.41 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:03, 284.66 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6680/8564 [00:01<00:00, 5058.29 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6143/8564 [00:01<00:00, 4672.44 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6290/8564 [00:01<00:00, 4636.75 examples/s]Tokenizing eval dataset:  12%|█▏        | 112/953 [00:00<00:03, 254.25 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 7270/8564 [00:01<00:00, 4540.38 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6773/8564 [00:01<00:00, 4507.68 examples/s]Extracting prompt in train dataset:  81%|████████  | 6930/8564 [00:01<00:00, 4506.89 examples/s]Tokenizing eval dataset:  16%|█▌        | 148/953 [00:00<00:03, 244.32 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7870/8564 [00:01<00:00, 4358.25 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7481/8564 [00:01<00:00, 4574.53 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7657/8564 [00:01<00:00, 4605.05 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8380/8564 [00:01<00:00, 4530.11 examples/s]Tokenizing eval dataset:  19%|█▉        | 179/953 [00:00<00:03, 225.68 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 4717.89 examples/s]
Extracting prompt in train dataset:  96%|█████████▌| 8180/8564 [00:01<00:00, 4587.63 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8360/8564 [00:01<00:00, 4613.55 examples/s]Tokenizing eval dataset:  23%|██▎       | 215/953 [00:00<00:03, 228.87 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 4508.06 examples/s]Tokenizing eval dataset:  29%|██▉       | 275/953 [00:00<00:02, 312.99 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 4384.33 examples/s]
Tokenizing eval dataset:  33%|███▎      | 316/953 [00:01<00:01, 336.77 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  40%|███▉      | 378/953 [00:01<00:01, 302.26 examples/s]Applying chat template to train dataset:   3%|▎         | 290/8564 [00:00<00:02, 2865.20 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  45%|████▍     | 426/953 [00:01<00:01, 339.37 examples/s]Applying chat template to train dataset:   8%|▊         | 698/8564 [00:00<00:02, 2762.19 examples/s]Tokenizing eval dataset:  49%|████▉     | 467/953 [00:01<00:01, 342.01 examples/s]Applying chat template to train dataset:   3%|▎         | 287/8564 [00:00<00:02, 2835.16 examples/s]Applying chat template to train dataset:   3%|▎         | 290/8564 [00:00<00:02, 2862.51 examples/s]Applying chat template to train dataset:  12%|█▏        | 1017/8564 [00:00<00:03, 2239.41 examples/s]Tokenizing eval dataset:  55%|█████▌    | 528/953 [00:01<00:01, 359.64 examples/s]Applying chat template to train dataset:   7%|▋         | 610/8564 [00:00<00:03, 2370.56 examples/s]Applying chat template to train dataset:   8%|▊         | 672/8564 [00:00<00:02, 2642.09 examples/s]Applying chat template to train dataset:  15%|█▌        | 1296/8564 [00:00<00:03, 2403.40 examples/s]Tokenizing eval dataset:  62%|██████▏   | 593/953 [00:01<00:00, 426.64 examples/s]Applying chat template to train dataset:  11%|█▏        | 975/8564 [00:00<00:03, 2395.55 examples/s]Applying chat template to train dataset:  12%|█▏        | 991/8564 [00:00<00:03, 2020.21 examples/s]Applying chat template to train dataset:  19%|█▉        | 1615/8564 [00:00<00:03, 2260.86 examples/s]Tokenizing eval dataset:  69%|██████▉   | 660/953 [00:01<00:00, 401.70 examples/s]Applying chat template to train dataset:  16%|█▌        | 1336/8564 [00:00<00:03, 2398.32 examples/s]Applying chat template to train dataset:  15%|█▌        | 1320/8564 [00:00<00:03, 2080.15 examples/s]Applying chat template to train dataset:  23%|██▎       | 1938/8564 [00:00<00:03, 2206.78 examples/s]Applying chat template to train dataset:  19%|█▊        | 1600/8564 [00:00<00:02, 2463.89 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:02<00:00, 419.20 examples/s]Applying chat template to train dataset:  19%|█▉        | 1661/8564 [00:00<00:03, 2142.20 examples/s]Applying chat template to train dataset:  26%|██▋       | 2262/8564 [00:00<00:02, 2175.10 examples/s]Applying chat template to train dataset:  23%|██▎       | 1945/8564 [00:00<00:02, 2398.79 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:02<00:00, 380.60 examples/s]Applying chat template to train dataset:  24%|██▎       | 2020/8564 [00:00<00:02, 2218.93 examples/s]Applying chat template to train dataset:  30%|███       | 2602/8564 [00:01<00:02, 2200.65 examples/s]Applying chat template to train dataset:  27%|██▋       | 2270/8564 [00:00<00:02, 2138.26 examples/s]Tokenizing eval dataset:  87%|████████▋ | 833/953 [00:02<00:00, 363.38 examples/s]Applying chat template to train dataset:  27%|██▋       | 2343/8564 [00:01<00:03, 1883.13 examples/s]Applying chat template to train dataset:  34%|███▍      | 2928/8564 [00:01<00:03, 1830.98 examples/s]Applying chat template to train dataset:  30%|███       | 2590/8564 [00:01<00:03, 1674.21 examples/s]Tokenizing eval dataset:  93%|█████████▎| 887/953 [00:02<00:00, 253.74 examples/s]Applying chat template to train dataset:  31%|███       | 2664/8564 [00:01<00:03, 1557.25 examples/s]Applying chat template to train dataset:  38%|███▊      | 3235/8564 [00:01<00:03, 1511.82 examples/s]Applying chat template to train dataset:  34%|███▍      | 2910/8564 [00:01<00:03, 1633.97 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:02<00:00, 279.03 examples/s]Applying chat template to train dataset:  34%|███▍      | 2946/8564 [00:01<00:03, 1778.63 examples/s]Applying chat template to train dataset:  41%|████      | 3497/8564 [00:01<00:02, 1702.49 examples/s]Applying chat template to train dataset:  37%|███▋      | 3132/8564 [00:01<00:03, 1741.13 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 312.18 examples/s]
Applying chat template to train dataset:  44%|████▍     | 3766/8564 [00:01<00:02, 1895.97 examples/s]Applying chat template to train dataset:  39%|███▉      | 3380/8564 [00:01<00:02, 1893.57 examples/s]Applying chat template to train dataset:  39%|███▊      | 3300/8564 [00:01<00:02, 1935.09 examples/s]Applying chat template to train dataset:  47%|████▋     | 4039/8564 [00:01<00:02, 2077.43 examples/s]Applying chat template to train dataset:  41%|████      | 3516/8564 [00:01<00:02, 1980.41 examples/s]Applying chat template to train dataset:  43%|████▎     | 3707/8564 [00:01<00:02, 1980.40 examples/s]Applying chat template to train dataset:  50%|█████     | 4291/8564 [00:02<00:01, 2179.72 examples/s]Applying chat template to train dataset:  44%|████▍     | 3797/8564 [00:01<00:02, 2167.67 examples/s]Applying chat template to train dataset:  47%|████▋     | 4026/8564 [00:01<00:02, 1964.72 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4670/8564 [00:02<00:01, 2294.85 examples/s]Applying chat template to train dataset:  49%|████▉     | 4175/8564 [00:02<00:01, 2280.75 examples/s]Applying chat template to train dataset:  50%|█████     | 4318/8564 [00:02<00:01, 2173.50 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4979/8564 [00:02<00:01, 2485.69 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4450/8564 [00:02<00:01, 2388.34 examples/s]Applying chat template to train dataset:  54%|█████▎    | 4600/8564 [00:02<00:01, 2323.25 examples/s]Applying chat template to train dataset:  61%|██████▏   | 5258/8564 [00:02<00:01, 2561.56 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4740/8564 [00:02<00:01, 2516.77 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4874/8564 [00:02<00:01, 2427.65 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5585/8564 [00:02<00:01, 2227.97 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5066/8564 [00:02<00:01, 2225.83 examples/s]Applying chat template to train dataset:  61%|██████    | 5226/8564 [00:02<00:01, 2396.80 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5980/8564 [00:02<00:01, 2351.41 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5432/8564 [00:02<00:01, 2291.94 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5544/8564 [00:02<00:01, 2272.57 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6252/8564 [00:02<00:00, 2434.99 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5719/8564 [00:02<00:01, 2423.89 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5835/8564 [00:02<00:01, 2424.11 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6528/8564 [00:02<00:00, 2513.39 examples/s]Applying chat template to train dataset:  71%|███████   | 6048/8564 [00:02<00:01, 2304.32 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6171/8564 [00:02<00:01, 2358.55 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6796/8564 [00:03<00:00, 2556.00 examples/s]Applying chat template to train dataset:  74%|███████▎  | 6315/8564 [00:02<00:00, 2390.61 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6449/8564 [00:02<00:00, 2459.93 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7134/8564 [00:03<00:00, 2442.95 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6642/8564 [00:03<00:01, 1691.61 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6772/8564 [00:03<00:01, 1703.18 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7465/8564 [00:03<00:00, 1892.98 examples/s]Applying chat template to train dataset:  81%|████████  | 6950/8564 [00:03<00:00, 1953.57 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7060/8564 [00:03<00:00, 1925.84 examples/s]Applying chat template to train dataset:  90%|█████████ | 7725/8564 [00:03<00:00, 2036.87 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7293/8564 [00:03<00:00, 2011.73 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7346/8564 [00:03<00:00, 2149.52 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8086/8564 [00:03<00:00, 2148.44 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7563/8564 [00:03<00:00, 2170.59 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7640/8564 [00:03<00:00, 2316.47 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8402/8564 [00:03<00:00, 2374.19 examples/s]Applying chat template to train dataset:  91%|█████████ | 7810/8564 [00:03<00:00, 2242.88 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2198.55 examples/s]
Applying chat template to train dataset:  92%|█████████▏| 7914/8564 [00:03<00:00, 2382.83 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8100/8564 [00:03<00:00, 2415.04 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8229/8564 [00:03<00:00, 2571.45 examples/s]Applying chat template to train dataset:  99%|█████████▊| 8440/8564 [00:03<00:00, 2357.73 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2535.03 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2141.77 examples/s]
Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:04<00:00, 2113.91 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 43/8564 [00:00<00:21, 399.65 examples/s]Tokenizing train dataset:   1%|          | 88/8564 [00:00<00:26, 324.24 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|▏         | 128/8564 [00:00<00:29, 287.27 examples/s]Tokenizing train dataset:   0%|          | 41/8564 [00:00<00:20, 406.17 examples/s]Tokenizing train dataset:   1%|          | 43/8564 [00:00<00:21, 400.35 examples/s]Tokenizing train dataset:   2%|▏         | 162/8564 [00:00<00:33, 253.81 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:30, 281.08 examples/s]Tokenizing train dataset:   1%|          | 92/8564 [00:00<00:30, 277.13 examples/s]Tokenizing train dataset:   2%|▏         | 204/8564 [00:00<00:32, 257.33 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:48, 172.44 examples/s]Tokenizing train dataset:   3%|▎         | 240/8564 [00:01<00:46, 178.03 examples/s]Tokenizing train dataset:   2%|▏         | 140/8564 [00:00<00:52, 160.79 examples/s]Tokenizing train dataset:   2%|▏         | 164/8564 [00:00<00:45, 184.85 examples/s]Tokenizing train dataset:   3%|▎         | 274/8564 [00:01<00:40, 206.03 examples/s]Tokenizing train dataset:   2%|▏         | 167/8564 [00:00<00:46, 179.19 examples/s]Tokenizing train dataset:   2%|▏         | 192/8564 [00:00<00:40, 204.45 examples/s]Tokenizing train dataset:   4%|▎         | 305/8564 [00:01<00:36, 226.42 examples/s]Tokenizing train dataset:   2%|▏         | 194/8564 [00:00<00:42, 196.47 examples/s]Tokenizing train dataset:   3%|▎         | 226/8564 [00:01<00:35, 233.53 examples/s]Tokenizing train dataset:   4%|▍         | 333/8564 [00:01<00:34, 236.78 examples/s]Tokenizing train dataset:   3%|▎         | 254/8564 [00:01<00:34, 243.81 examples/s]Tokenizing train dataset:   3%|▎         | 233/8564 [00:01<00:38, 214.25 examples/s]Tokenizing train dataset:   4%|▍         | 373/8564 [00:01<00:33, 243.11 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:01<00:30, 271.08 examples/s]Tokenizing train dataset:   3%|▎         | 263/8564 [00:01<00:36, 230.56 examples/s]Tokenizing train dataset:   5%|▍         | 401/8564 [00:01<00:32, 248.08 examples/s]Tokenizing train dataset:   4%|▍         | 332/8564 [00:01<00:30, 269.95 examples/s]Tokenizing train dataset:   4%|▎         | 300/8564 [00:01<00:37, 219.48 examples/s]Tokenizing train dataset:   5%|▌         | 439/8564 [00:01<00:33, 245.57 examples/s]Tokenizing train dataset:   4%|▍         | 331/8564 [00:01<00:34, 235.58 examples/s]Tokenizing train dataset:   4%|▍         | 375/8564 [00:01<00:30, 271.09 examples/s]Tokenizing train dataset:   6%|▌         | 478/8564 [00:01<00:32, 247.86 examples/s]Tokenizing train dataset:   4%|▍         | 372/8564 [00:01<00:33, 242.94 examples/s]Tokenizing train dataset:   5%|▍         | 418/8564 [00:01<00:30, 270.64 examples/s]Tokenizing train dataset:   6%|▌         | 506/8564 [00:02<00:31, 251.88 examples/s]Tokenizing train dataset:   5%|▍         | 401/8564 [00:01<00:32, 250.48 examples/s]Tokenizing train dataset:   5%|▌         | 460/8564 [00:01<00:30, 270.12 examples/s]Tokenizing train dataset:   6%|▋         | 545/8564 [00:02<00:31, 250.72 examples/s]Tokenizing train dataset:   5%|▌         | 433/8564 [00:01<00:30, 263.87 examples/s]Tokenizing train dataset:   6%|▌         | 501/8564 [00:02<00:29, 268.80 examples/s]Tokenizing train dataset:   7%|▋         | 578/8564 [00:02<00:33, 239.62 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:02<00:32, 252.90 examples/s]Tokenizing train dataset:   6%|▌         | 532/8564 [00:02<00:28, 277.34 examples/s]Tokenizing train dataset:   7%|▋         | 604/8564 [00:02<00:32, 242.73 examples/s]Tokenizing train dataset:   6%|▌         | 497/8564 [00:02<00:31, 257.10 examples/s]Tokenizing train dataset:   7%|▋         | 561/8564 [00:02<00:28, 276.32 examples/s]Tokenizing train dataset:   7%|▋         | 640/8564 [00:02<00:29, 268.78 examples/s]Tokenizing train dataset:   6%|▌         | 527/8564 [00:02<00:30, 266.78 examples/s]Tokenizing train dataset:   8%|▊         | 669/8564 [00:02<00:29, 268.24 examples/s]Tokenizing train dataset:   7%|▋         | 600/8564 [00:02<00:29, 266.56 examples/s]Tokenizing train dataset:   7%|▋         | 568/8564 [00:02<00:30, 264.51 examples/s]Tokenizing train dataset:   7%|▋         | 630/8564 [00:02<00:29, 272.02 examples/s]Tokenizing train dataset:   8%|▊         | 698/8564 [00:02<00:32, 240.65 examples/s]Tokenizing train dataset:   7%|▋         | 605/8564 [00:02<00:31, 253.72 examples/s]Tokenizing train dataset:   8%|▊         | 725/8564 [00:02<00:31, 246.21 examples/s]Tokenizing train dataset:   8%|▊         | 671/8564 [00:02<00:29, 268.97 examples/s]Tokenizing train dataset:   7%|▋         | 641/8564 [00:02<00:28, 274.92 examples/s]Tokenizing train dataset:   9%|▉         | 756/8564 [00:03<00:30, 258.94 examples/s]Tokenizing train dataset:   8%|▊         | 699/8564 [00:02<00:33, 232.26 examples/s]Tokenizing train dataset:   8%|▊         | 674/8564 [00:02<00:30, 255.12 examples/s]Tokenizing train dataset:   9%|▉         | 792/8564 [00:03<00:31, 246.87 examples/s]Tokenizing train dataset:   9%|▊         | 735/8564 [00:02<00:30, 258.84 examples/s]Tokenizing train dataset:   8%|▊         | 716/8564 [00:02<00:30, 258.45 examples/s]Tokenizing train dataset:  10%|▉         | 823/8564 [00:03<00:33, 230.77 examples/s]Tokenizing train dataset:   9%|▉         | 774/8564 [00:03<00:30, 256.61 examples/s]Tokenizing train dataset:   9%|▉         | 754/8564 [00:03<00:27, 282.96 examples/s]Tokenizing train dataset:  10%|▉         | 847/8564 [00:03<00:33, 230.30 examples/s]Tokenizing train dataset:  10%|▉         | 815/8564 [00:03<00:30, 256.93 examples/s]Tokenizing train dataset:  10%|█         | 872/8564 [00:03<00:33, 232.66 examples/s]Tokenizing train dataset:   9%|▉         | 790/8564 [00:03<00:29, 261.78 examples/s]Tokenizing train dataset:  10%|▉         | 853/8564 [00:03<00:30, 251.58 examples/s]Tokenizing train dataset:  11%|█         | 911/8564 [00:03<00:41, 185.58 examples/s]Tokenizing train dataset:  10%|▉         | 821/8564 [00:03<00:40, 189.18 examples/s]Tokenizing train dataset:  10%|█         | 890/8564 [00:03<00:35, 216.96 examples/s]Tokenizing train dataset:  11%|█         | 937/8564 [00:03<00:38, 200.00 examples/s]Tokenizing train dataset:  10%|▉         | 849/8564 [00:03<00:37, 205.34 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:03<00:33, 229.99 examples/s]Tokenizing train dataset:  11%|█▏        | 968/8564 [00:04<00:34, 221.18 examples/s]Tokenizing train dataset:  10%|█         | 876/8564 [00:03<00:35, 217.41 examples/s]Tokenizing train dataset:  11%|█         | 950/8564 [00:03<00:31, 241.55 examples/s]Tokenizing train dataset:  11%|█         | 907/8564 [00:03<00:32, 237.91 examples/s]Tokenizing train dataset:  12%|█▏        | 1007/8564 [00:04<00:32, 229.65 examples/s]Tokenizing train dataset:  11%|█▏        | 980/8564 [00:03<00:33, 224.20 examples/s]Tokenizing train dataset:  11%|█         | 940/8564 [00:04<00:33, 227.78 examples/s]Tokenizing train dataset:  12%|█▏        | 1042/8564 [00:04<00:32, 227.98 examples/s]Tokenizing train dataset:  12%|█▏        | 1008/8564 [00:04<00:32, 235.50 examples/s]Tokenizing train dataset:  11%|█▏        | 968/8564 [00:04<00:31, 237.80 examples/s]Tokenizing train dataset:  12%|█▏        | 1068/8564 [00:04<00:31, 234.90 examples/s]Tokenizing train dataset:  12%|█▏        | 1034/8564 [00:04<00:31, 236.45 examples/s]Tokenizing train dataset:  13%|█▎        | 1101/8564 [00:04<00:29, 255.07 examples/s]Tokenizing train dataset:  12%|█▏        | 1008/8564 [00:04<00:30, 243.99 examples/s]Tokenizing train dataset:  12%|█▏        | 1064/8564 [00:04<00:30, 248.32 examples/s]Tokenizing train dataset:  12%|█▏        | 1034/8564 [00:04<00:31, 242.82 examples/s]Tokenizing train dataset:  13%|█▎        | 1142/8564 [00:04<00:28, 259.07 examples/s]Tokenizing train dataset:  13%|█▎        | 1100/8564 [00:04<00:31, 239.01 examples/s]Tokenizing train dataset:  12%|█▏        | 1064/8564 [00:04<00:29, 252.95 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:04<00:28, 257.48 examples/s]Tokenizing train dataset:  13%|█▎        | 1137/8564 [00:04<00:31, 236.93 examples/s]Tokenizing train dataset:  13%|█▎        | 1104/8564 [00:04<00:29, 254.56 examples/s]Tokenizing train dataset:  14%|█▍        | 1209/8564 [00:05<00:28, 254.02 examples/s]Tokenizing train dataset:  14%|█▎        | 1164/8564 [00:04<00:30, 241.34 examples/s]Tokenizing train dataset:  13%|█▎        | 1141/8564 [00:04<00:29, 249.52 examples/s]Tokenizing train dataset:  15%|█▍        | 1251/8564 [00:05<00:28, 258.88 examples/s]Tokenizing train dataset:  14%|█▍        | 1199/8564 [00:04<00:27, 265.58 examples/s]Tokenizing train dataset:  14%|█▍        | 1180/8564 [00:04<00:29, 247.67 examples/s]Tokenizing train dataset:  15%|█▌        | 1289/8564 [00:05<00:28, 255.52 examples/s]Tokenizing train dataset:  15%|█▍        | 1245/8564 [00:04<00:26, 276.82 examples/s]Tokenizing train dataset:  14%|█▍        | 1211/8564 [00:05<00:28, 259.20 examples/s]Tokenizing train dataset:  15%|█▌        | 1318/8564 [00:05<00:27, 262.39 examples/s]Tokenizing train dataset:  15%|█▌        | 1285/8564 [00:05<00:27, 266.55 examples/s]Tokenizing train dataset:  15%|█▍        | 1247/8564 [00:05<00:26, 280.55 examples/s]Tokenizing train dataset:  16%|█▌        | 1348/8564 [00:05<00:27, 265.69 examples/s]Tokenizing train dataset:  16%|█▌        | 1328/8564 [00:05<00:26, 270.23 examples/s]Tokenizing train dataset:  15%|█▌        | 1286/8564 [00:05<00:26, 271.14 examples/s]Tokenizing train dataset:  16%|█▌        | 1387/8564 [00:05<00:27, 258.42 examples/s]Tokenizing train dataset:  15%|█▌        | 1318/8564 [00:05<00:25, 281.19 examples/s]Tokenizing train dataset:  16%|█▌        | 1365/8564 [00:05<00:27, 261.47 examples/s]Tokenizing train dataset:  17%|█▋        | 1428/8564 [00:05<00:27, 261.07 examples/s]Tokenizing train dataset:  16%|█▌        | 1348/8564 [00:05<00:25, 282.58 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:05<00:27, 263.02 examples/s]Tokenizing train dataset:  17%|█▋        | 1470/8564 [00:06<00:26, 263.33 examples/s]Tokenizing train dataset:  16%|█▌        | 1383/8564 [00:05<00:27, 262.98 examples/s]Tokenizing train dataset:  17%|█▋        | 1448/8564 [00:05<00:27, 263.17 examples/s]Tokenizing train dataset:  16%|█▋        | 1410/8564 [00:05<00:27, 262.71 examples/s]Tokenizing train dataset:  18%|█▊        | 1505/8564 [00:06<00:28, 250.74 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:05<00:29, 237.96 examples/s]Tokenizing train dataset:  17%|█▋        | 1441/8564 [00:05<00:29, 238.82 examples/s]Tokenizing train dataset:  18%|█▊        | 1540/8564 [00:06<00:28, 242.87 examples/s]Tokenizing train dataset:  18%|█▊        | 1506/8564 [00:06<00:29, 241.02 examples/s]Tokenizing train dataset:  17%|█▋        | 1470/8564 [00:06<00:28, 249.02 examples/s]Tokenizing train dataset:  18%|█▊        | 1568/8564 [00:06<00:28, 249.81 examples/s]Tokenizing train dataset:  18%|█▊        | 1533/8564 [00:06<00:28, 247.28 examples/s]Tokenizing train dataset:  18%|█▊        | 1509/8564 [00:06<00:28, 244.59 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:06<00:27, 253.09 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:06<00:27, 253.01 examples/s]Tokenizing train dataset:  18%|█▊        | 1538/8564 [00:06<00:27, 253.05 examples/s]Tokenizing train dataset:  19%|█▉        | 1641/8564 [00:06<00:26, 263.84 examples/s]Tokenizing train dataset:  19%|█▊        | 1601/8564 [00:06<00:27, 253.29 examples/s]Tokenizing train dataset:  18%|█▊        | 1565/8564 [00:06<00:27, 254.68 examples/s]Tokenizing train dataset:  20%|█▉        | 1672/8564 [00:06<00:25, 272.62 examples/s]Tokenizing train dataset:  20%|█▉        | 1708/8564 [00:06<00:23, 294.14 examples/s]Tokenizing train dataset:  19%|█▉        | 1641/8564 [00:06<00:26, 256.75 examples/s]Tokenizing train dataset:  19%|█▊        | 1602/8564 [00:06<00:27, 250.15 examples/s]Tokenizing train dataset:  20%|█▉        | 1670/8564 [00:06<00:26, 263.16 examples/s]Tokenizing train dataset:  19%|█▉        | 1631/8564 [00:06<00:26, 257.51 examples/s]Tokenizing train dataset:  20%|██        | 1750/8564 [00:07<00:23, 284.19 examples/s]Tokenizing train dataset:  20%|█▉        | 1705/8564 [00:06<00:24, 281.87 examples/s]Tokenizing train dataset:  19%|█▉        | 1663/8564 [00:06<00:25, 272.86 examples/s]Tokenizing train dataset:  21%|██        | 1782/8564 [00:07<00:23, 290.22 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:06<00:22, 305.02 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:07<00:23, 292.89 examples/s]Tokenizing train dataset:  20%|██        | 1750/8564 [00:06<00:24, 281.41 examples/s]Tokenizing train dataset:  22%|██▏       | 1844/8564 [00:07<00:22, 293.10 examples/s]Tokenizing train dataset:  20%|██        | 1745/8564 [00:07<00:23, 292.07 examples/s]Tokenizing train dataset:  21%|██        | 1790/8564 [00:07<00:24, 271.55 examples/s]Tokenizing train dataset:  21%|██        | 1778/8564 [00:07<00:22, 299.25 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:07<00:23, 286.67 examples/s]Tokenizing train dataset:  21%|██▏       | 1821/8564 [00:07<00:24, 277.59 examples/s]Tokenizing train dataset:  22%|██▏       | 1926/8564 [00:07<00:21, 310.48 examples/s]Tokenizing train dataset:  22%|██▏       | 1852/8564 [00:07<00:23, 282.59 examples/s]Tokenizing train dataset:  21%|██▏       | 1822/8564 [00:07<00:23, 291.55 examples/s]Tokenizing train dataset:  23%|██▎       | 1972/8564 [00:07<00:21, 306.92 examples/s]Tokenizing train dataset:  22%|██▏       | 1882/8564 [00:07<00:26, 250.30 examples/s]Tokenizing train dataset:  22%|██▏       | 1856/8564 [00:07<00:25, 262.47 examples/s]Tokenizing train dataset:  23%|██▎       | 2007/8564 [00:07<00:20, 316.36 examples/s]Tokenizing train dataset:  22%|██▏       | 1912/8564 [00:07<00:25, 261.24 examples/s]Tokenizing train dataset:  22%|██▏       | 1895/8564 [00:07<00:25, 259.43 examples/s]Tokenizing train dataset:  24%|██▍       | 2048/8564 [00:08<00:23, 280.32 examples/s]Tokenizing train dataset:  23%|██▎       | 1952/8564 [00:07<00:25, 260.48 examples/s]Tokenizing train dataset:  23%|██▎       | 1934/8564 [00:07<00:23, 287.62 examples/s]Tokenizing train dataset:  24%|██▍       | 2094/8564 [00:08<00:22, 286.15 examples/s]Tokenizing train dataset:  23%|██▎       | 1994/8564 [00:07<00:25, 262.07 examples/s]Tokenizing train dataset:  23%|██▎       | 1970/8564 [00:07<00:24, 265.39 examples/s]Tokenizing train dataset:  25%|██▍       | 2129/8564 [00:08<00:21, 298.48 examples/s]Tokenizing train dataset:  24%|██▎       | 2025/8564 [00:07<00:24, 270.80 examples/s]Tokenizing train dataset:  23%|██▎       | 2001/8564 [00:07<00:23, 273.78 examples/s]Tokenizing train dataset:  25%|██▌       | 2165/8564 [00:08<00:20, 309.45 examples/s]Tokenizing train dataset:  24%|██▍       | 2062/8564 [00:08<00:22, 294.36 examples/s]Tokenizing train dataset:  24%|██▍       | 2041/8564 [00:08<00:25, 256.77 examples/s]Tokenizing train dataset:  26%|██▌       | 2214/8564 [00:08<00:20, 311.74 examples/s]Tokenizing train dataset:  25%|██▍       | 2110/8564 [00:08<00:21, 301.06 examples/s]Tokenizing train dataset:  24%|██▍       | 2076/8564 [00:08<00:23, 277.72 examples/s]Tokenizing train dataset:  26%|██▋       | 2250/8564 [00:08<00:19, 322.39 examples/s]Tokenizing train dataset:  25%|██▌       | 2150/8564 [00:08<00:22, 281.99 examples/s]Tokenizing train dataset:  25%|██▍       | 2118/8564 [00:08<00:23, 276.03 examples/s]Tokenizing train dataset:  27%|██▋       | 2288/8564 [00:08<00:18, 334.42 examples/s]Tokenizing train dataset:  26%|██▌       | 2184/8564 [00:08<00:21, 292.34 examples/s]Tokenizing train dataset:  25%|██▌       | 2153/8564 [00:08<00:22, 290.60 examples/s]Tokenizing train dataset:  27%|██▋       | 2339/8564 [00:08<00:18, 329.07 examples/s]Tokenizing train dataset:  26%|██▌       | 2214/8564 [00:08<00:21, 292.01 examples/s]Tokenizing train dataset:  26%|██▌       | 2194/8564 [00:08<00:22, 282.98 examples/s]Tokenizing train dataset:  28%|██▊       | 2386/8564 [00:09<00:19, 321.19 examples/s]Tokenizing train dataset:  26%|██▋       | 2260/8564 [00:08<00:21, 294.08 examples/s]Tokenizing train dataset:  26%|██▌       | 2228/8564 [00:08<00:21, 292.39 examples/s]Tokenizing train dataset:  28%|██▊       | 2423/8564 [00:09<00:18, 330.42 examples/s]Tokenizing train dataset:  26%|██▋       | 2260/8564 [00:08<00:21, 298.67 examples/s]Tokenizing train dataset:  27%|██▋       | 2306/8564 [00:08<00:21, 296.03 examples/s]Tokenizing train dataset:  29%|██▊       | 2459/8564 [00:09<00:18, 336.68 examples/s]Tokenizing train dataset:  27%|██▋       | 2292/8564 [00:08<00:20, 302.76 examples/s]Tokenizing train dataset:  27%|██▋       | 2347/8564 [00:09<00:21, 286.15 examples/s]Tokenizing train dataset:  29%|██▉       | 2508/8564 [00:09<00:18, 329.50 examples/s]Tokenizing train dataset:  27%|██▋       | 2330/8564 [00:09<00:22, 277.15 examples/s]Tokenizing train dataset:  30%|██▉       | 2542/8564 [00:09<00:18, 327.79 examples/s]Tokenizing train dataset:  28%|██▊       | 2387/8564 [00:09<00:22, 278.38 examples/s]Tokenizing train dataset:  28%|██▊       | 2374/8564 [00:09<00:22, 277.20 examples/s]Tokenizing train dataset:  30%|███       | 2591/8564 [00:09<00:18, 326.13 examples/s]Tokenizing train dataset:  28%|██▊       | 2430/8564 [00:09<00:22, 276.71 examples/s]Tokenizing train dataset:  28%|██▊       | 2405/8564 [00:09<00:21, 283.08 examples/s]Tokenizing train dataset:  29%|██▊       | 2462/8564 [00:09<00:21, 285.46 examples/s]Tokenizing train dataset:  29%|██▊       | 2441/8564 [00:09<00:20, 299.95 examples/s]Tokenizing train dataset:  31%|███       | 2638/8564 [00:09<00:19, 307.45 examples/s]Tokenizing train dataset:  29%|██▉       | 2476/8564 [00:09<00:19, 309.96 examples/s]Tokenizing train dataset:  29%|██▉       | 2503/8564 [00:09<00:21, 276.72 examples/s]Tokenizing train dataset:  31%|███       | 2670/8564 [00:09<00:19, 307.03 examples/s]Tokenizing train dataset:  30%|██▉       | 2542/8564 [00:09<00:20, 300.12 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:09<00:18, 320.72 examples/s]Tokenizing train dataset:  32%|███▏      | 2720/8564 [00:10<00:18, 309.71 examples/s]Tokenizing train dataset:  30%|███       | 2581/8564 [00:09<00:18, 318.45 examples/s]Tokenizing train dataset:  30%|██▉       | 2563/8564 [00:09<00:18, 316.90 examples/s]Tokenizing train dataset:  31%|███       | 2615/8564 [00:09<00:18, 319.58 examples/s]Tokenizing train dataset:  32%|███▏      | 2761/8564 [00:10<00:19, 294.33 examples/s]Tokenizing train dataset:  30%|███       | 2597/8564 [00:09<00:18, 319.31 examples/s]Tokenizing train dataset:  31%|███       | 2652/8564 [00:10<00:20, 287.32 examples/s]Tokenizing train dataset:  33%|███▎      | 2809/8564 [00:10<00:19, 298.81 examples/s]Tokenizing train dataset:  31%|███       | 2638/8564 [00:10<00:20, 292.61 examples/s]Tokenizing train dataset:  31%|███▏      | 2683/8564 [00:10<00:20, 288.76 examples/s]Tokenizing train dataset:  31%|███       | 2669/8564 [00:10<00:20, 293.96 examples/s]Tokenizing train dataset:  33%|███▎      | 2855/8564 [00:10<00:19, 296.51 examples/s]Tokenizing train dataset:  32%|███▏      | 2722/8564 [00:10<00:21, 267.64 examples/s]Tokenizing train dataset:  32%|███▏      | 2710/8564 [00:10<00:20, 283.12 examples/s]Tokenizing train dataset:  34%|███▍      | 2893/8564 [00:10<00:20, 280.18 examples/s]Tokenizing train dataset:  34%|███▍      | 2922/8564 [00:10<00:20, 279.35 examples/s]Tokenizing train dataset:  32%|███▏      | 2762/8564 [00:10<00:21, 264.81 examples/s]Tokenizing train dataset:  32%|███▏      | 2753/8564 [00:10<00:20, 279.35 examples/s]Tokenizing train dataset:  34%|███▍      | 2953/8564 [00:10<00:19, 284.32 examples/s]Tokenizing train dataset:  33%|███▎      | 2792/8564 [00:10<00:21, 270.13 examples/s]Tokenizing train dataset:  33%|███▎      | 2786/8564 [00:10<00:19, 290.21 examples/s]Tokenizing train dataset:  35%|███▍      | 2994/8564 [00:11<00:17, 313.68 examples/s]Tokenizing train dataset:  33%|███▎      | 2828/8564 [00:10<00:19, 290.55 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:10<00:19, 299.60 examples/s]Tokenizing train dataset:  35%|███▌      | 3029/8564 [00:11<00:17, 319.38 examples/s]Tokenizing train dataset:  33%|███▎      | 2852/8564 [00:10<00:18, 302.26 examples/s]Tokenizing train dataset:  34%|███▎      | 2869/8564 [00:10<00:20, 281.26 examples/s]Tokenizing train dataset:  36%|███▌      | 3077/8564 [00:11<00:17, 316.99 examples/s]Tokenizing train dataset:  34%|███▍      | 2910/8564 [00:10<00:18, 311.78 examples/s]Tokenizing train dataset:  34%|███▍      | 2901/8564 [00:11<00:18, 308.66 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:11<00:17, 316.43 examples/s]Tokenizing train dataset:  34%|███▍      | 2944/8564 [00:11<00:17, 317.61 examples/s]Tokenizing train dataset:  34%|███▍      | 2936/8564 [00:11<00:17, 317.24 examples/s]Tokenizing train dataset:  37%|███▋      | 3148/8564 [00:11<00:19, 274.54 examples/s]Tokenizing train dataset:  35%|███▍      | 2990/8564 [00:11<00:20, 275.49 examples/s]Tokenizing train dataset:  35%|███▍      | 2981/8564 [00:11<00:21, 259.97 examples/s]Tokenizing train dataset:  37%|███▋      | 3181/8564 [00:11<00:18, 284.67 examples/s]Tokenizing train dataset:  35%|███▌      | 3025/8564 [00:11<00:19, 291.40 examples/s]Tokenizing train dataset:  35%|███▌      | 3013/8564 [00:11<00:20, 271.81 examples/s]Tokenizing train dataset:  38%|███▊      | 3212/8564 [00:11<00:18, 289.31 examples/s]Tokenizing train dataset:  36%|███▌      | 3073/8564 [00:11<00:18, 299.30 examples/s]Tokenizing train dataset:  36%|███▌      | 3046/8564 [00:11<00:19, 281.16 examples/s]Tokenizing train dataset:  38%|███▊      | 3247/8564 [00:11<00:17, 303.89 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:11<00:17, 312.95 examples/s]Tokenizing train dataset:  36%|███▌      | 3081/8564 [00:11<00:18, 297.34 examples/s]Tokenizing train dataset:  38%|███▊      | 3280/8564 [00:12<00:17, 305.84 examples/s]Tokenizing train dataset:  36%|███▋      | 3114/8564 [00:11<00:17, 303.63 examples/s]Tokenizing train dataset:  39%|███▊      | 3314/8564 [00:12<00:16, 310.99 examples/s]Tokenizing train dataset:  37%|███▋      | 3162/8564 [00:11<00:16, 321.93 examples/s]Tokenizing train dataset:  37%|███▋      | 3147/8564 [00:11<00:17, 310.35 examples/s]Tokenizing train dataset:  39%|███▉      | 3346/8564 [00:12<00:16, 312.31 examples/s]Tokenizing train dataset:  38%|███▊      | 3213/8564 [00:11<00:16, 325.96 examples/s]Tokenizing train dataset:  37%|███▋      | 3180/8564 [00:11<00:17, 310.93 examples/s]Tokenizing train dataset:  39%|███▉      | 3379/8564 [00:12<00:16, 315.55 examples/s]Tokenizing train dataset:  38%|███▊      | 3251/8564 [00:12<00:15, 335.90 examples/s]Tokenizing train dataset:  38%|███▊      | 3213/8564 [00:12<00:16, 315.36 examples/s]Tokenizing train dataset:  40%|███▉      | 3425/8564 [00:12<00:16, 307.83 examples/s]Tokenizing train dataset:  38%|███▊      | 3247/8564 [00:12<00:16, 320.47 examples/s]Tokenizing train dataset:  39%|███▊      | 3301/8564 [00:12<00:15, 331.30 examples/s]Tokenizing train dataset:  41%|████      | 3474/8564 [00:12<00:16, 309.42 examples/s]Tokenizing train dataset:  38%|███▊      | 3295/8564 [00:12<00:16, 315.65 examples/s]Tokenizing train dataset:  39%|███▉      | 3350/8564 [00:12<00:15, 326.62 examples/s]Tokenizing train dataset:  41%|████      | 3512/8564 [00:12<00:15, 322.82 examples/s]Tokenizing train dataset:  40%|███▉      | 3388/8564 [00:12<00:15, 337.33 examples/s]Tokenizing train dataset:  39%|███▉      | 3340/8564 [00:12<00:17, 305.76 examples/s]Tokenizing train dataset:  41%|████▏     | 3548/8564 [00:12<00:15, 326.68 examples/s]Tokenizing train dataset:  40%|███▉      | 3423/8564 [00:12<00:15, 339.75 examples/s]Tokenizing train dataset:  39%|███▉      | 3372/8564 [00:12<00:16, 308.44 examples/s]Tokenizing train dataset:  42%|████▏     | 3592/8564 [00:13<00:16, 310.60 examples/s]Tokenizing train dataset:  40%|████      | 3464/8564 [00:12<00:16, 300.75 examples/s]Tokenizing train dataset:  40%|███▉      | 3415/8564 [00:12<00:17, 294.23 examples/s]Tokenizing train dataset:  43%|████▎     | 3641/8564 [00:13<00:15, 312.33 examples/s]Tokenizing train dataset:  41%|████      | 3514/8564 [00:12<00:16, 307.19 examples/s]Tokenizing train dataset:  40%|████      | 3461/8564 [00:12<00:17, 294.97 examples/s]Tokenizing train dataset:  43%|████▎     | 3688/8564 [00:13<00:15, 307.38 examples/s]Tokenizing train dataset:  42%|████▏     | 3558/8564 [00:13<00:16, 301.30 examples/s]Tokenizing train dataset:  41%|████      | 3512/8564 [00:13<00:16, 305.60 examples/s]Tokenizing train dataset:  44%|████▎     | 3730/8564 [00:13<00:16, 297.90 examples/s]Tokenizing train dataset:  42%|████▏     | 3593/8564 [00:13<00:15, 311.59 examples/s]Tokenizing train dataset:  42%|████▏     | 3558/8564 [00:13<00:16, 304.41 examples/s]Tokenizing train dataset:  44%|████▍     | 3770/8564 [00:13<00:17, 276.57 examples/s]Tokenizing train dataset:  42%|████▏     | 3633/8564 [00:13<00:16, 290.54 examples/s]Tokenizing train dataset:  42%|████▏     | 3596/8564 [00:13<00:15, 319.34 examples/s]Tokenizing train dataset:  44%|████▍     | 3803/8564 [00:13<00:16, 285.25 examples/s]Tokenizing train dataset:  43%|████▎     | 3663/8564 [00:13<00:16, 289.33 examples/s]Tokenizing train dataset:  42%|████▏     | 3631/8564 [00:13<00:15, 321.55 examples/s]Tokenizing train dataset:  45%|████▍     | 3836/8564 [00:13<00:16, 292.47 examples/s]Tokenizing train dataset:  43%|████▎     | 3704/8564 [00:13<00:17, 281.42 examples/s]Tokenizing train dataset:  43%|████▎     | 3665/8564 [00:13<00:17, 285.99 examples/s]Tokenizing train dataset:  45%|████▌     | 3870/8564 [00:13<00:15, 302.11 examples/s]Tokenizing train dataset:  44%|████▎     | 3740/8564 [00:13<00:16, 297.79 examples/s]Tokenizing train dataset:  43%|████▎     | 3695/8564 [00:13<00:16, 286.82 examples/s]Tokenizing train dataset:  46%|████▌     | 3915/8564 [00:14<00:15, 298.12 examples/s]Tokenizing train dataset:  44%|████▍     | 3775/8564 [00:13<00:15, 306.89 examples/s]Tokenizing train dataset:  44%|████▎     | 3729/8564 [00:13<00:16, 298.08 examples/s]Tokenizing train dataset:  44%|████▍     | 3809/8564 [00:13<00:15, 313.19 examples/s]Tokenizing train dataset:  44%|████▍     | 3764/8564 [00:13<00:15, 309.69 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:14<00:15, 303.11 examples/s]Tokenizing train dataset:  45%|████▍     | 3846/8564 [00:14<00:19, 246.91 examples/s]Tokenizing train dataset:  44%|████▍     | 3803/8564 [00:14<00:19, 239.49 examples/s]Tokenizing train dataset:  47%|████▋     | 4002/8564 [00:14<00:19, 239.79 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:14<00:18, 258.78 examples/s]Tokenizing train dataset:  47%|████▋     | 4036/8564 [00:14<00:17, 257.93 examples/s]Tokenizing train dataset:  45%|████▍     | 3846/8564 [00:14<00:18, 250.44 examples/s]Tokenizing train dataset:  46%|████▌     | 3919/8564 [00:14<00:17, 263.80 examples/s]Tokenizing train dataset:  48%|████▊     | 4072/8564 [00:14<00:16, 278.48 examples/s]Tokenizing train dataset:  45%|████▌     | 3875/8564 [00:14<00:18, 258.07 examples/s]Tokenizing train dataset:  46%|████▌     | 3951/8564 [00:14<00:16, 275.71 examples/s]Tokenizing train dataset:  48%|████▊     | 4116/8564 [00:14<00:16, 277.89 examples/s]Tokenizing train dataset:  46%|████▌     | 3910/8564 [00:14<00:18, 246.62 examples/s]Tokenizing train dataset:  47%|████▋     | 3987/8564 [00:14<00:15, 293.24 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:14<00:17, 259.60 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:14<00:15, 302.24 examples/s]Tokenizing train dataset:  49%|████▊     | 4160/8564 [00:15<00:15, 279.12 examples/s]Tokenizing train dataset:  46%|████▋     | 3975/8564 [00:14<00:16, 277.79 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:14<00:14, 313.48 examples/s]Tokenizing train dataset:  49%|████▉     | 4197/8564 [00:15<00:14, 295.56 examples/s]Tokenizing train dataset:  47%|████▋     | 4006/8564 [00:14<00:16, 284.08 examples/s]Tokenizing train dataset:  49%|████▉     | 4230/8564 [00:15<00:14, 299.89 examples/s]Tokenizing train dataset:  48%|████▊     | 4105/8564 [00:14<00:14, 314.48 examples/s]Tokenizing train dataset:  47%|████▋     | 4044/8564 [00:14<00:14, 308.36 examples/s]Tokenizing train dataset:  50%|████▉     | 4262/8564 [00:15<00:14, 303.67 examples/s]Tokenizing train dataset:  48%|████▊     | 4137/8564 [00:15<00:14, 313.21 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:15<00:14, 316.23 examples/s]Tokenizing train dataset:  50%|█████     | 4294/8564 [00:15<00:14, 304.68 examples/s]Tokenizing train dataset:  49%|████▊     | 4169/8564 [00:15<00:14, 312.73 examples/s]Tokenizing train dataset:  48%|████▊     | 4115/8564 [00:15<00:13, 322.69 examples/s]Tokenizing train dataset:  51%|█████     | 4329/8564 [00:15<00:13, 315.90 examples/s]Tokenizing train dataset:  49%|████▉     | 4207/8564 [00:15<00:13, 329.00 examples/s]Tokenizing train dataset:  48%|████▊     | 4149/8564 [00:15<00:13, 318.55 examples/s]Tokenizing train dataset:  51%|█████     | 4370/8564 [00:15<00:14, 296.24 examples/s]Tokenizing train dataset:  50%|████▉     | 4250/8564 [00:15<00:13, 310.84 examples/s]Tokenizing train dataset:  49%|████▉     | 4202/8564 [00:15<00:13, 327.41 examples/s]Tokenizing train dataset:  51%|█████▏    | 4405/8564 [00:15<00:13, 306.97 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:15<00:13, 312.82 examples/s]Tokenizing train dataset:  52%|█████▏    | 4442/8564 [00:15<00:12, 321.45 examples/s]Tokenizing train dataset:  50%|████▉     | 4250/8564 [00:15<00:13, 321.87 examples/s]Tokenizing train dataset:  51%|█████     | 4332/8564 [00:15<00:13, 311.24 examples/s]Tokenizing train dataset:  50%|█████     | 4283/8564 [00:15<00:13, 321.63 examples/s]Tokenizing train dataset:  52%|█████▏    | 4490/8564 [00:16<00:12, 316.88 examples/s]Tokenizing train dataset:  50%|█████     | 4316/8564 [00:15<00:13, 320.92 examples/s]Tokenizing train dataset:  51%|█████     | 4380/8564 [00:15<00:13, 307.36 examples/s]Tokenizing train dataset:  53%|█████▎    | 4536/8564 [00:16<00:13, 307.59 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:15<00:13, 306.51 examples/s]Tokenizing train dataset:  52%|█████▏    | 4426/8564 [00:15<00:13, 304.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 4570/8564 [00:16<00:12, 314.43 examples/s]Tokenizing train dataset:  51%|█████▏    | 4400/8564 [00:16<00:12, 322.95 examples/s]Tokenizing train dataset:  52%|█████▏    | 4460/8564 [00:16<00:13, 308.21 examples/s]Tokenizing train dataset:  54%|█████▍    | 4617/8564 [00:16<00:12, 309.79 examples/s]Tokenizing train dataset:  52%|█████▏    | 4437/8564 [00:16<00:12, 330.96 examples/s]Tokenizing train dataset:  53%|█████▎    | 4508/8564 [00:16<00:13, 307.35 examples/s]Tokenizing train dataset:  54%|█████▍    | 4663/8564 [00:16<00:12, 304.93 examples/s]Tokenizing train dataset:  52%|█████▏    | 4486/8564 [00:16<00:12, 327.02 examples/s]Tokenizing train dataset:  53%|█████▎    | 4540/8564 [00:16<00:13, 307.28 examples/s]Tokenizing train dataset:  55%|█████▍    | 4695/8564 [00:16<00:12, 305.84 examples/s]Tokenizing train dataset:  53%|█████▎    | 4573/8564 [00:16<00:12, 311.00 examples/s]Tokenizing train dataset:  53%|█████▎    | 4529/8564 [00:16<00:12, 312.96 examples/s]Tokenizing train dataset:  55%|█████▌    | 4740/8564 [00:16<00:12, 300.87 examples/s]Tokenizing train dataset:  53%|█████▎    | 4564/8564 [00:16<00:12, 318.79 examples/s]Tokenizing train dataset:  54%|█████▍    | 4624/8564 [00:16<00:12, 317.62 examples/s]Tokenizing train dataset:  56%|█████▌    | 4785/8564 [00:17<00:12, 299.13 examples/s]Tokenizing train dataset:  54%|█████▍    | 4615/8564 [00:16<00:12, 322.06 examples/s]Tokenizing train dataset:  54%|█████▍    | 4664/8564 [00:16<00:13, 296.88 examples/s]Tokenizing train dataset:  56%|█████▌    | 4816/8564 [00:17<00:12, 298.51 examples/s]Tokenizing train dataset:  54%|█████▍    | 4651/8564 [00:16<00:13, 292.01 examples/s]Tokenizing train dataset:  57%|█████▋    | 4872/8564 [00:17<00:10, 362.69 examples/s]Tokenizing train dataset:  55%|█████▍    | 4698/8564 [00:16<00:14, 262.24 examples/s]Tokenizing train dataset:  55%|█████▍    | 4681/8564 [00:16<00:13, 293.14 examples/s]Tokenizing train dataset:  57%|█████▋    | 4917/8564 [00:17<00:09, 381.43 examples/s]Tokenizing train dataset:  55%|█████▌    | 4731/8564 [00:17<00:15, 245.86 examples/s]Tokenizing train dataset:  58%|█████▊    | 4972/8564 [00:17<00:08, 426.63 examples/s]Tokenizing train dataset:  55%|█████▌    | 4724/8564 [00:17<00:13, 288.58 examples/s]Tokenizing train dataset:  56%|█████▌    | 4760/8564 [00:17<00:14, 253.89 examples/s]Tokenizing train dataset:  59%|█████▊    | 5025/8564 [00:17<00:07, 453.81 examples/s]Tokenizing train dataset:  56%|█████▌    | 4754/8564 [00:17<00:13, 288.07 examples/s]Tokenizing train dataset:  56%|█████▌    | 4790/8564 [00:17<00:14, 261.24 examples/s]Tokenizing train dataset:  59%|█████▉    | 5076/8564 [00:17<00:07, 469.18 examples/s]Tokenizing train dataset:  57%|█████▋    | 4841/8564 [00:17<00:11, 322.67 examples/s]Tokenizing train dataset:  56%|█████▌    | 4795/8564 [00:17<00:13, 280.89 examples/s]Tokenizing train dataset:  60%|█████▉    | 5138/8564 [00:17<00:06, 509.49 examples/s]Tokenizing train dataset:  57%|█████▋    | 4849/8564 [00:17<00:10, 341.84 examples/s]Tokenizing train dataset:  57%|█████▋    | 4894/8564 [00:17<00:09, 372.46 examples/s]Tokenizing train dataset:  61%|██████    | 5200/8564 [00:17<00:06, 533.31 examples/s]Tokenizing train dataset:  57%|█████▋    | 4894/8564 [00:17<00:10, 366.89 examples/s]Tokenizing train dataset:  58%|█████▊    | 4947/8564 [00:17<00:08, 413.06 examples/s]Tokenizing train dataset:  62%|██████▏   | 5270/8564 [00:17<00:05, 576.94 examples/s]Tokenizing train dataset:  58%|█████▊    | 4946/8564 [00:17<00:08, 405.62 examples/s]Tokenizing train dataset:  59%|█████▊    | 5015/8564 [00:17<00:08, 424.38 examples/s]Tokenizing train dataset:  63%|██████▎   | 5354/8564 [00:18<00:05, 564.51 examples/s]Tokenizing train dataset:  58%|█████▊    | 5000/8564 [00:17<00:08, 440.56 examples/s]Tokenizing train dataset:  59%|█████▉    | 5077/8564 [00:17<00:07, 474.19 examples/s]Tokenizing train dataset:  59%|█████▉    | 5055/8564 [00:17<00:07, 467.06 examples/s]Tokenizing train dataset:  63%|██████▎   | 5431/8564 [00:18<00:05, 543.21 examples/s]Tokenizing train dataset:  60%|█████▉    | 5135/8564 [00:17<00:06, 500.41 examples/s]Tokenizing train dataset:  60%|█████▉    | 5113/8564 [00:18<00:06, 497.44 examples/s]Tokenizing train dataset:  64%|██████▍   | 5506/8564 [00:18<00:05, 526.67 examples/s]Tokenizing train dataset:  61%|██████    | 5214/8564 [00:18<00:06, 508.33 examples/s]Tokenizing train dataset:  60%|██████    | 5175/8564 [00:18<00:06, 531.62 examples/s]Tokenizing train dataset:  62%|██████▏   | 5279/8564 [00:18<00:06, 543.68 examples/s]Tokenizing train dataset:  65%|██████▌   | 5589/8564 [00:18<00:05, 533.52 examples/s]Tokenizing train dataset:  61%|██████▏   | 5258/8564 [00:18<00:06, 537.00 examples/s]Tokenizing train dataset:  66%|██████▌   | 5651/8564 [00:18<00:05, 553.22 examples/s]Tokenizing train dataset:  62%|██████▏   | 5320/8564 [00:18<00:05, 557.34 examples/s]Tokenizing train dataset:  63%|██████▎   | 5364/8564 [00:18<00:05, 545.07 examples/s]Tokenizing train dataset:  67%|██████▋   | 5730/8564 [00:18<00:05, 541.49 examples/s]Tokenizing train dataset:  63%|██████▎   | 5387/8564 [00:18<00:06, 514.46 examples/s]Tokenizing train dataset:  63%|██████▎   | 5426/8564 [00:18<00:06, 490.16 examples/s]Tokenizing train dataset:  68%|██████▊   | 5788/8564 [00:18<00:05, 549.14 examples/s]Tokenizing train dataset:  64%|██████▍   | 5465/8564 [00:18<00:06, 514.24 examples/s]Tokenizing train dataset:  64%|██████▍   | 5500/8564 [00:18<00:06, 486.59 examples/s]Tokenizing train dataset:  68%|██████▊   | 5866/8564 [00:19<00:05, 537.20 examples/s]Tokenizing train dataset:  65%|██████▍   | 5537/8564 [00:18<00:06, 495.55 examples/s]Tokenizing train dataset:  65%|██████▌   | 5570/8564 [00:18<00:06, 476.37 examples/s]Tokenizing train dataset:  69%|██████▉   | 5949/8564 [00:19<00:04, 538.66 examples/s]Tokenizing train dataset:  65%|██████▌   | 5596/8564 [00:18<00:05, 514.04 examples/s]Tokenizing train dataset:  66%|██████▌   | 5632/8564 [00:18<00:05, 506.46 examples/s]Tokenizing train dataset:  66%|██████▌   | 5654/8564 [00:19<00:05, 530.18 examples/s]Tokenizing train dataset:  66%|██████▋   | 5691/8564 [00:19<00:05, 522.80 examples/s]Tokenizing train dataset:  70%|███████   | 6020/8564 [00:19<00:04, 516.76 examples/s]Tokenizing train dataset:  67%|██████▋   | 5739/8564 [00:19<00:05, 540.03 examples/s]Tokenizing train dataset:  68%|██████▊   | 5783/8564 [00:19<00:05, 551.54 examples/s]Tokenizing train dataset:  71%|███████   | 6091/8564 [00:19<00:04, 500.68 examples/s]Tokenizing train dataset:  68%|██████▊   | 5802/8564 [00:19<00:04, 561.70 examples/s]Tokenizing train dataset:  68%|██████▊   | 5849/8564 [00:19<00:05, 485.98 examples/s]Tokenizing train dataset:  72%|███████▏  | 6161/8564 [00:19<00:05, 460.52 examples/s]Tokenizing train dataset:  69%|██████▊   | 5880/8564 [00:19<00:04, 539.29 examples/s]Tokenizing train dataset:  69%|██████▉   | 5907/8564 [00:19<00:05, 450.30 examples/s]Tokenizing train dataset:  69%|██████▉   | 5937/8564 [00:19<00:04, 544.80 examples/s]Tokenizing train dataset:  73%|███████▎  | 6240/8564 [00:19<00:04, 474.25 examples/s]Tokenizing train dataset:  70%|██████▉   | 5965/8564 [00:19<00:05, 475.83 examples/s]Tokenizing train dataset:  74%|███████▎  | 6307/8564 [00:20<00:04, 457.05 examples/s]Tokenizing train dataset:  70%|███████   | 6015/8564 [00:19<00:05, 507.15 examples/s]Tokenizing train dataset:  70%|███████   | 6015/8564 [00:19<00:05, 429.20 examples/s]Tokenizing train dataset:  74%|███████▍  | 6371/8564 [00:20<00:04, 493.55 examples/s]Tokenizing train dataset:  71%|███████   | 6071/8564 [00:19<00:04, 518.75 examples/s]Tokenizing train dataset:  71%|███████   | 6062/8564 [00:19<00:05, 436.60 examples/s]Tokenizing train dataset:  75%|███████▌  | 6427/8564 [00:20<00:04, 504.75 examples/s]Tokenizing train dataset:  72%|███████▏  | 6156/8564 [00:19<00:04, 532.05 examples/s]Tokenizing train dataset:  71%|███████▏  | 6111/8564 [00:19<00:05, 446.33 examples/s]Tokenizing train dataset:  76%|███████▌  | 6485/8564 [00:20<00:04, 519.39 examples/s]Tokenizing train dataset:  73%|███████▎  | 6210/8564 [00:20<00:04, 530.36 examples/s]Tokenizing train dataset:  72%|███████▏  | 6172/8564 [00:20<00:04, 487.07 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [00:20<00:03, 519.35 examples/s]Tokenizing train dataset:  73%|███████▎  | 6268/8564 [00:20<00:04, 538.24 examples/s]Tokenizing train dataset:  73%|███████▎  | 6253/8564 [00:20<00:04, 499.54 examples/s]Tokenizing train dataset:  77%|███████▋  | 6636/8564 [00:20<00:03, 502.30 examples/s]Tokenizing train dataset:  74%|███████▍  | 6341/8564 [00:20<00:04, 518.24 examples/s]Tokenizing train dataset:  74%|███████▍  | 6330/8564 [00:20<00:04, 499.61 examples/s]Tokenizing train dataset:  78%|███████▊  | 6722/8564 [00:20<00:03, 521.22 examples/s]Tokenizing train dataset:  75%|███████▍  | 6414/8564 [00:20<00:04, 500.60 examples/s]Tokenizing train dataset:  75%|███████▍  | 6397/8564 [00:20<00:04, 534.93 examples/s]Tokenizing train dataset:  79%|███████▉  | 6804/8564 [00:20<00:03, 526.25 examples/s]Tokenizing train dataset:  76%|███████▌  | 6477/8564 [00:20<00:04, 462.09 examples/s]Tokenizing train dataset:  75%|███████▌  | 6462/8564 [00:20<00:04, 491.28 examples/s]Tokenizing train dataset:  76%|███████▋  | 6535/8564 [00:20<00:04, 485.14 examples/s]Tokenizing train dataset:  76%|███████▌  | 6519/8564 [00:20<00:04, 508.50 examples/s]Tokenizing train dataset:  80%|████████  | 6885/8564 [00:21<00:03, 524.88 examples/s]Tokenizing train dataset:  77%|███████▋  | 6587/8564 [00:20<00:04, 490.16 examples/s]Tokenizing train dataset:  81%|████████  | 6944/8564 [00:21<00:03, 534.92 examples/s]Tokenizing train dataset:  77%|███████▋  | 6595/8564 [00:20<00:03, 504.34 examples/s]Tokenizing train dataset:  78%|███████▊  | 6664/8564 [00:20<00:03, 495.50 examples/s]Tokenizing train dataset:  82%|████████▏ | 7016/8564 [00:21<00:03, 512.74 examples/s]Tokenizing train dataset:  78%|███████▊  | 6678/8564 [00:21<00:03, 514.85 examples/s]Tokenizing train dataset:  78%|███████▊  | 6718/8564 [00:21<00:03, 501.12 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [00:21<00:02, 504.01 examples/s]Tokenizing train dataset:  79%|███████▉  | 6770/8564 [00:21<00:03, 501.73 examples/s]Tokenizing train dataset:  79%|███████▉  | 6749/8564 [00:21<00:03, 496.25 examples/s]Tokenizing train dataset:  83%|████████▎ | 7150/8564 [00:21<00:02, 519.02 examples/s]Tokenizing train dataset:  79%|███████▉  | 6800/8564 [00:21<00:03, 497.71 examples/s]Tokenizing train dataset:  80%|███████▉  | 6837/8564 [00:21<00:03, 480.31 examples/s]Tokenizing train dataset:  84%|████████▍ | 7216/8564 [00:21<00:02, 547.60 examples/s]Tokenizing train dataset:  81%|████████  | 6899/8564 [00:21<00:03, 507.38 examples/s]Tokenizing train dataset:  80%|████████  | 6875/8564 [00:21<00:03, 496.77 examples/s]Tokenizing train dataset:  85%|████████▌ | 7293/8564 [00:21<00:02, 532.20 examples/s]Tokenizing train dataset:  81%|████████▏ | 6959/8564 [00:21<00:03, 530.51 examples/s]Tokenizing train dataset:  81%|████████  | 6931/8564 [00:21<00:03, 510.52 examples/s]Tokenizing train dataset:  86%|████████▌ | 7351/8564 [00:22<00:02, 542.58 examples/s]Tokenizing train dataset:  82%|████████▏ | 7020/8564 [00:21<00:03, 478.81 examples/s]Tokenizing train dataset:  82%|████████▏ | 6997/8564 [00:21<00:03, 481.19 examples/s]Tokenizing train dataset:  87%|████████▋ | 7438/8564 [00:22<00:02, 546.86 examples/s]Tokenizing train dataset:  83%|████████▎ | 7071/8564 [00:21<00:03, 485.34 examples/s]Tokenizing train dataset:  82%|████████▏ | 7063/8564 [00:21<00:03, 465.17 examples/s]Tokenizing train dataset:  83%|████████▎ | 7135/8564 [00:21<00:02, 520.12 examples/s]Tokenizing train dataset:  88%|████████▊ | 7524/8564 [00:22<00:01, 552.67 examples/s]Tokenizing train dataset:  83%|████████▎ | 7127/8564 [00:21<00:02, 503.45 examples/s]Tokenizing train dataset:  84%|████████▍ | 7203/8564 [00:22<00:02, 556.91 examples/s]Tokenizing train dataset:  89%|████████▊ | 7598/8564 [00:22<00:01, 530.81 examples/s]Tokenizing train dataset:  84%|████████▍ | 7208/8564 [00:22<00:02, 512.30 examples/s]Tokenizing train dataset:  85%|████████▌ | 7282/8564 [00:22<00:02, 544.28 examples/s]Tokenizing train dataset:  89%|████████▉ | 7662/8564 [00:22<00:01, 494.99 examples/s]Tokenizing train dataset:  85%|████████▍ | 7261/8564 [00:22<00:03, 430.19 examples/s]Tokenizing train dataset:  86%|████████▌ | 7355/8564 [00:22<00:02, 518.36 examples/s]Tokenizing train dataset:  90%|█████████ | 7713/8564 [00:22<00:01, 495.88 examples/s]Tokenizing train dataset:  85%|████████▌ | 7314/8564 [00:22<00:02, 448.76 examples/s]Tokenizing train dataset:  91%|█████████ | 7763/8564 [00:22<00:01, 494.58 examples/s]Tokenizing train dataset:  87%|████████▋ | 7440/8564 [00:22<00:02, 528.78 examples/s]Tokenizing train dataset:  86%|████████▌ | 7376/8564 [00:22<00:02, 483.47 examples/s]Tokenizing train dataset:  88%|████████▊ | 7501/8564 [00:22<00:01, 543.07 examples/s]Tokenizing train dataset:  92%|█████████▏| 7850/8564 [00:22<00:01, 517.56 examples/s]Tokenizing train dataset:  87%|████████▋ | 7438/8564 [00:22<00:02, 514.91 examples/s]Tokenizing train dataset:  88%|████████▊ | 7561/8564 [00:22<00:01, 557.05 examples/s]Tokenizing train dataset:  92%|█████████▏| 7902/8564 [00:23<00:01, 517.36 examples/s]Tokenizing train dataset:  88%|████████▊ | 7519/8564 [00:22<00:02, 520.77 examples/s]Tokenizing train dataset:  89%|████████▉ | 7626/8564 [00:22<00:01, 576.61 examples/s]Tokenizing train dataset:  93%|█████████▎| 7955/8564 [00:23<00:01, 514.70 examples/s]Tokenizing train dataset:  89%|████████▊ | 7581/8564 [00:22<00:01, 544.76 examples/s]Tokenizing train dataset:  93%|█████████▎| 8007/8564 [00:23<00:01, 511.60 examples/s]Tokenizing train dataset:  90%|█████████ | 7710/8564 [00:23<00:01, 507.02 examples/s]Tokenizing train dataset:  89%|████████▉ | 7645/8564 [00:23<00:01, 502.05 examples/s]Tokenizing train dataset:  94%|█████████▍| 8083/8564 [00:23<00:00, 503.62 examples/s]Tokenizing train dataset:  91%|█████████ | 7786/8564 [00:23<00:01, 500.98 examples/s]Tokenizing train dataset:  90%|█████████ | 7726/8564 [00:23<00:01, 509.18 examples/s]Tokenizing train dataset:  95%|█████████▌| 8155/8564 [00:23<00:00, 490.15 examples/s]Tokenizing train dataset:  92%|█████████▏| 7863/8564 [00:23<00:01, 501.71 examples/s]Tokenizing train dataset:  91%|█████████ | 7791/8564 [00:23<00:01, 482.87 examples/s]Tokenizing train dataset:  96%|█████████▌| 8226/8564 [00:23<00:00, 479.53 examples/s]Tokenizing train dataset:  93%|█████████▎| 7933/8564 [00:23<00:01, 485.34 examples/s]Tokenizing train dataset:  92%|█████████▏| 7860/8564 [00:23<00:01, 472.49 examples/s]Tokenizing train dataset:  97%|█████████▋| 8300/8564 [00:23<00:00, 536.20 examples/s]Tokenizing train dataset:  93%|█████████▎| 7992/8564 [00:23<00:01, 508.28 examples/s]Tokenizing train dataset:  92%|█████████▏| 7916/8564 [00:23<00:01, 488.78 examples/s]Tokenizing train dataset:  98%|█████████▊| 8382/8564 [00:24<00:00, 533.27 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [00:23<00:01, 514.45 examples/s]Tokenizing train dataset:  93%|█████████▎| 7976/8564 [00:23<00:01, 510.59 examples/s]Tokenizing train dataset:  94%|█████████▍| 8032/8564 [00:23<00:01, 517.90 examples/s]Tokenizing train dataset:  99%|█████████▉| 8460/8564 [00:24<00:00, 524.48 examples/s]Tokenizing train dataset:  95%|█████████▍| 8123/8564 [00:23<00:00, 509.45 examples/s]Tokenizing train dataset:  94%|█████████▍| 8086/8564 [00:23<00:00, 520.63 examples/s]Tokenizing train dataset: 100%|█████████▉| 8530/8564 [00:24<00:00, 472.02 examples/s]Tokenizing train dataset:  96%|█████████▌| 8192/8564 [00:24<00:00, 459.65 examples/s]Tokenizing train dataset:  95%|█████████▌| 8151/8564 [00:24<00:00, 485.28 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:24<00:00, 350.47 examples/s]
Tokenizing train dataset:  96%|█████████▋| 8244/8564 [00:24<00:00, 469.60 examples/s]Tokenizing train dataset:  96%|█████████▌| 8211/8564 [00:24<00:00, 510.74 examples/s]Tokenizing train dataset:  97%|█████████▋| 8310/8564 [00:24<00:00, 514.70 examples/s]Tokenizing train dataset:  97%|█████████▋| 8299/8564 [00:24<00:00, 535.12 examples/s]Tokenizing train dataset:  98%|█████████▊| 8384/8564 [00:24<00:00, 505.71 examples/s]Tokenizing train dataset:  98%|█████████▊| 8382/8564 [00:24<00:00, 539.04 examples/s]Tokenizing train dataset:  99%|█████████▉| 8464/8564 [00:24<00:00, 509.15 examples/s]Tokenizing train dataset: 100%|█████████▉| 8526/8564 [00:24<00:00, 532.03 examples/s]Tokenizing train dataset:  99%|█████████▉| 8466/8564 [00:24<00:00, 544.31 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:24<00:00, 346.77 examples/s]
Tokenizing train dataset: 100%|█████████▉| 8546/8564 [00:24<00:00, 534.95 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:24<00:00, 344.73 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11276.63 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11236.63 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer

Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 9273.53 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11672.24 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13591.85 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13180.46 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 323.28 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 325.15 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 323.17 examples/s]Tokenizing eval dataset:   7%|▋         | 69/953 [00:00<00:03, 253.07 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:03, 285.42 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:03, 283.93 examples/s]Tokenizing eval dataset:  10%|█         | 96/953 [00:00<00:03, 254.04 examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:00<00:03, 274.32 examples/s]Tokenizing eval dataset:  12%|█▏        | 112/953 [00:00<00:03, 254.44 examples/s]Tokenizing eval dataset:  14%|█▎        | 131/953 [00:00<00:03, 241.17 examples/s]Tokenizing eval dataset:  15%|█▌        | 145/953 [00:00<00:03, 230.59 examples/s]Tokenizing eval dataset:  15%|█▌        | 143/953 [00:00<00:03, 232.13 examples/s]Tokenizing eval dataset:  17%|█▋        | 162/953 [00:00<00:03, 224.18 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:00<00:03, 223.97 examples/s]Tokenizing eval dataset:  18%|█▊        | 175/953 [00:00<00:03, 223.01 examples/s]Tokenizing eval dataset:  20%|█▉        | 187/953 [00:00<00:03, 197.88 examples/s]Tokenizing eval dataset:  23%|██▎       | 215/953 [00:00<00:03, 225.43 examples/s]Tokenizing eval dataset:  21%|██        | 202/953 [00:00<00:03, 195.68 examples/s]Tokenizing eval dataset:  23%|██▎       | 217/953 [00:01<00:03, 186.61 examples/s]Tokenizing eval dataset:  26%|██▌       | 244/953 [00:01<00:03, 227.00 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:01<00:03, 196.75 examples/s]Tokenizing eval dataset:  28%|██▊       | 263/953 [00:01<00:02, 248.02 examples/s]Tokenizing eval dataset:  31%|███       | 295/953 [00:01<00:02, 295.42 examples/s]Tokenizing eval dataset:  29%|██▉       | 276/953 [00:01<00:02, 278.79 examples/s]Tokenizing eval dataset:  34%|███▍      | 328/953 [00:01<00:01, 343.10 examples/s]Tokenizing eval dataset:  35%|███▌      | 338/953 [00:01<00:01, 328.54 examples/s]Tokenizing eval dataset:  34%|███▍      | 326/953 [00:01<00:01, 334.53 examples/s]Tokenizing eval dataset:  41%|████      | 387/953 [00:01<00:01, 404.11 examples/s]Tokenizing eval dataset:  41%|████      | 392/953 [00:01<00:01, 380.07 examples/s]Tokenizing eval dataset:  39%|███▉      | 374/953 [00:01<00:01, 372.67 examples/s]Tokenizing eval dataset:  48%|████▊     | 459/953 [00:01<00:01, 486.45 examples/s]Tokenizing eval dataset:  46%|████▌     | 439/953 [00:01<00:01, 400.06 examples/s]Tokenizing eval dataset:  44%|████▍     | 419/953 [00:01<00:01, 391.93 examples/s]Tokenizing eval dataset:  57%|█████▋    | 540/953 [00:01<00:00, 500.47 examples/s]Tokenizing eval dataset:  52%|█████▏    | 497/953 [00:01<00:01, 447.65 examples/s]Tokenizing eval dataset:  50%|█████     | 479/953 [00:01<00:01, 446.97 examples/s]Tokenizing eval dataset:  64%|██████▍   | 610/953 [00:01<00:00, 430.43 examples/s]Tokenizing eval dataset:  59%|█████▉    | 564/953 [00:01<00:01, 308.81 examples/s]Tokenizing eval dataset:  58%|█████▊    | 550/953 [00:01<00:01, 312.83 examples/s]Tokenizing eval dataset:  71%|███████   | 674/953 [00:01<00:00, 395.75 examples/s]Tokenizing eval dataset:  66%|██████▌   | 628/953 [00:01<00:00, 371.93 examples/s]Tokenizing eval dataset:  64%|██████▍   | 611/953 [00:01<00:00, 369.75 examples/s]Tokenizing eval dataset:  77%|███████▋  | 733/953 [00:02<00:00, 383.82 examples/s]Tokenizing eval dataset:  73%|███████▎  | 692/953 [00:02<00:00, 353.13 examples/s]Tokenizing eval dataset:  71%|███████   | 674/953 [00:02<00:00, 321.66 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:02<00:00, 348.03 examples/s]Tokenizing eval dataset:  78%|███████▊  | 747/953 [00:02<00:00, 350.42 examples/s]Tokenizing eval dataset:  76%|███████▌  | 725/953 [00:02<00:00, 353.62 examples/s]Tokenizing eval dataset:  88%|████████▊ | 840/953 [00:02<00:00, 340.41 examples/s]Tokenizing eval dataset:  85%|████████▍ | 807/953 [00:02<00:00, 360.42 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:02<00:00, 363.31 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:02<00:00, 358.26 examples/s]Tokenizing eval dataset:  89%|████████▉ | 852/953 [00:02<00:00, 377.54 examples/s]Tokenizing eval dataset:  89%|████████▉ | 850/953 [00:02<00:00, 378.89 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:02<00:00, 363.34 examples/s]Tokenizing eval dataset:  95%|█████████▌| 908/953 [00:02<00:00, 370.22 examples/s]Tokenizing eval dataset:  95%|█████████▍| 901/953 [00:02<00:00, 403.64 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 328.34 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 343.29 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 325.15 examples/s]Tokenizing eval dataset: 100%|█████████▉| 951/953 [00:02<00:00, 362.96 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 315.49 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.

No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Parameter Offload: Total persistent parameters: 605696 in 169 params
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250531_014547-uecrviy0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-3e-07_e-3_b-0.2
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/uecrviy0
  0%|          | 0/1605 [00:00<?, ?it/s][rank3]: Traceback (most recent call last):
[rank3]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 208, in <module>
[rank3]:     main(train_data, val_data, args.rank, args.learning_rate, args.total_epochs, args.beta)
[rank3]:   File "/ceph/hpc/data/s24o01-42-users/translation_optimization/trl/train.py", line 187, in main
[rank3]:     dpo_trainer.train()
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2245, in train
[rank3]:     return inner_training_loop(
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2560, in _inner_training_loop
[rank3]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/trainer.py", line 3736, in training_step
[rank3]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py", line 1356, in compute_loss
[rank3]:     loss, metrics = self.get_batch_loss_metrics(model, inputs, train_eval="train")
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py", line 1291, in get_batch_loss_metrics
[rank3]:     model_output = self.concatenated_forward(model, batch)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/trl/trainer/dpo_trainer.py", line 1193, in concatenated_forward
[rank3]:     outputs = model(input_ids, **model_kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1750, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/utils/nvtx.py", line 18, in wrapped_fn
[rank3]:     ret_val = func(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/deepspeed/runtime/engine.py", line 1987, in forward
[rank3]:     loss = self.module(*inputs, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank3]:     return inner()
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1793, in inner
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 1719, in forward
[rank3]:     return self.base_model(
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank3]:     return inner()
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1793, in inner
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py", line 197, in forward
[rank3]:     return self.model.forward(*args, **kwargs)
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank3]:     output = func(self, *args, **kwargs)
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
[rank3]:     return func(*args, **kwargs)
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/models/gemma2/modeling_gemma2.py", line 851, in forward
[rank3]:     outputs: BaseModelOutputWithPast = self.model(
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank3]:     return inner()
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1793, in inner
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/utils/generic.py", line 965, in wrapper
[rank3]:     output = func(self, *args, **kwargs)
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/models/gemma2/modeling_gemma2.py", line 634, in forward
[rank3]:     layer_outputs = decoder_layer(
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank3]:     return inner()
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1793, in inner
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/models/gemma2/modeling_gemma2.py", line 319, in forward
[rank3]:     hidden_states = self.input_layernorm(hidden_states)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1845, in _call_impl
[rank3]:     return inner()
[rank3]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1793, in inner
[rank3]:     result = forward_call(*args, **kwargs)
[rank3]:   File "/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/models/gemma2/modeling_gemma2.py", line 73, in forward
[rank3]:     output = output * (1.0 + self.weight.float())
[rank3]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 52.00 MiB. GPU 3 has a total capacity of 39.50 GiB of which 10.12 MiB is free. Including non-PyTorch memory, this process has 39.48 GiB memory in use. Of the allocated memory 36.81 GiB is allocated by PyTorch, and 1008.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0531 01:45:59.029000 622654 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 622966 closing signal SIGTERM
W0531 01:45:59.037000 622654 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 622967 closing signal SIGTERM
W0531 01:45:59.046000 622654 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 622968 closing signal SIGTERM
E0531 01:45:59.643000 622654 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 3 (pid: 622969) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1182, in launch_command
    deepspeed_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 861, in deepspeed_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-31_01:45:59
  host      : pm5-nod60.vega.pri
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 622969)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
