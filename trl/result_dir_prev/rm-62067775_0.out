cpu-bind=MASK - gn23, task  0  0 [3023992]: mask 0x1000000000000000000000000000000010000000000000000000000000000 set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn23
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 0     --main_process_ip gn23     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62067775     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-30 22:07:38,483] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0530 22:07:41.179000 3024035 torch/distributed/run.py:792] 
W0530 22:07:41.179000 3024035 torch/distributed/run.py:792] *****************************************
W0530 22:07:41.179000 3024035 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0530 22:07:41.179000 3024035 torch/distributed/run.py:792] *****************************************
[2025-05-30 22:08:10,821] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 22:08:10,864] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 22:08:10,883] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 22:08:10,910] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 2
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Steps per epoch: 4282
Eval steps: 2141
[2025-05-30 22:08:21,264] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 22:08:21,264] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-05-30 22:08:21,266] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 22:08:21,273] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 22:08:21,284] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
[2025-05-30 22:08:25,161] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 22:08:25,161] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
hpZeRO group size: 4
[2025-05-30 22:08:25,172] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 22:08:25,183] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 22:09:56,982] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 465, num_elems = 10.16B
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:53<02:41, 53.94s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:53<02:41, 53.86s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:53<02:41, 53.85s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:53<02:41, 53.90s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:53<01:55, 57.52s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:53<01:54, 57.45s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:53<01:54, 57.46s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:53<01:54, 57.48s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:53<00:58, 58.25s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:53<00:58, 58.24s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:52<00:58, 58.23s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:53<00:58, 58.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:36<00:00, 52.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:36<00:00, 52.45s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:36<00:00, 54.20s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [03:36<00:00, 54.16s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [03:36<00:00, 52.45s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:36<00:00, 54.17s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [03:36<00:00, 52.46s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:36<00:00, 54.17s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
Total Parameters: 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 100.0000%
Total Parameters: 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 100.0000%
Total Parameters: 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 100.0000%
Total Parameters: 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 100.0000%
Using LoRA and set up the model
-------------------- CHECKING GRADIENTS --------------------
Trainable parameters:
- base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.40.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.40.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.41.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.41.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
Total trainable parameters: 216072192
------------------------------------------------------------
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 1/8564 [00:02<6:41:24,  2.81s/ examples]Extracting prompt in train dataset:   0%|          | 10/8564 [00:03<44:02,  3.24 examples/s] Extracting prompt in train dataset:   3%|▎         | 250/8564 [00:03<01:14, 111.83 examples/s]Extracting prompt in train dataset:   5%|▌         | 440/8564 [00:04<00:37, 218.92 examples/s]Extracting prompt in train dataset:   8%|▊         | 680/8564 [00:04<00:20, 386.43 examples/s]Extracting prompt in train dataset:  10%|█         | 897/8564 [00:04<00:13, 559.30 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1120/8564 [00:04<00:09, 745.69 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1344/8564 [00:04<00:07, 965.45 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1620/8564 [00:04<00:06, 1142.49 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1870/8564 [00:04<00:05, 1228.75 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2041/8564 [00:04<00:05, 1299.25 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2310/8564 [00:05<00:03, 1584.32 examples/s]Extracting prompt in train dataset:  31%|███       | 2620/8564 [00:05<00:03, 1880.26 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2940/8564 [00:05<00:02, 1960.68 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3270/8564 [00:05<00:03, 1632.93 examples/s]Extracting prompt in train dataset:  41%|████      | 3483/8564 [00:05<00:03, 1645.62 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3710/8564 [00:05<00:02, 1768.11 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4002/8564 [00:05<00:02, 1793.51 examples/s]Extracting prompt in train dataset:  50%|█████     | 4310/8564 [00:06<00:02, 1817.41 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4510/8564 [00:06<00:02, 1828.57 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4730/8564 [00:06<00:02, 1846.21 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4930/8564 [00:06<00:01, 1822.98 examples/s]Extracting prompt in train dataset:  61%|██████    | 5230/8564 [00:06<00:01, 1835.56 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5460/8564 [00:06<00:01, 1936.68 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 5670/8564 [00:06<00:01, 1972.56 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5960/8564 [00:06<00:01, 1955.05 examples/s]Extracting prompt in train dataset:  74%|███████▎  | 6310/8564 [00:07<00:01, 2058.23 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6610/8564 [00:07<00:00, 2014.21 examples/s]Extracting prompt in train dataset:  80%|████████  | 6886/8564 [00:07<00:00, 1929.13 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7100/8564 [00:07<00:00, 1965.64 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7350/8564 [00:07<00:00, 2088.04 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7601/8564 [00:07<00:00, 1919.51 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7881/8564 [00:08<00:00, 1408.62 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8127/8564 [00:08<00:00, 1601.23 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8330/8564 [00:08<00:00, 1687.09 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 8554/8564 [00:08<00:00, 1778.97 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:08<00:00, 985.52 examples/s] 
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:02<6:49:23,  2.87s/ examples]Applying chat template to train dataset:   2%|▏         | 134/8564 [00:02<02:12, 63.40 examples/s]Applying chat template to train dataset:   3%|▎         | 250/8564 [00:03<01:02, 132.29 examples/s]Applying chat template to train dataset:   4%|▍         | 362/8564 [00:03<00:38, 213.95 examples/s]Applying chat template to train dataset:   5%|▌         | 469/8564 [00:03<00:26, 304.11 examples/s]Applying chat template to train dataset:   7%|▋         | 581/8564 [00:03<00:19, 410.73 examples/s]Applying chat template to train dataset:   8%|▊         | 713/8564 [00:03<00:14, 553.66 examples/s]Applying chat template to train dataset:  10%|█         | 892/8564 [00:03<00:11, 691.09 examples/s]Applying chat template to train dataset:  12%|█▏        | 1007/8564 [00:03<00:09, 777.38 examples/s]Applying chat template to train dataset:  13%|█▎        | 1122/8564 [00:03<00:08, 855.52 examples/s]Applying chat template to train dataset:  15%|█▌        | 1293/8564 [00:04<00:07, 943.40 examples/s]Applying chat template to train dataset:  16%|█▋        | 1407/8564 [00:04<00:07, 987.60 examples/s]Applying chat template to train dataset:  18%|█▊        | 1572/8564 [00:04<00:06, 1022.76 examples/s]Applying chat template to train dataset:  20%|█▉        | 1685/8564 [00:04<00:06, 1047.88 examples/s]Applying chat template to train dataset:  21%|██        | 1798/8564 [00:04<00:06, 1068.24 examples/s]Applying chat template to train dataset:  22%|██▏       | 1911/8564 [00:04<00:06, 1057.84 examples/s]Applying chat template to train dataset:  24%|██▎       | 2031/8564 [00:04<00:05, 1094.81 examples/s]Applying chat template to train dataset:  25%|██▌       | 2151/8564 [00:04<00:05, 1101.67 examples/s]Applying chat template to train dataset:  27%|██▋       | 2324/8564 [00:04<00:05, 1110.15 examples/s]Applying chat template to train dataset:  29%|██▊       | 2442/8564 [00:05<00:05, 1085.70 examples/s]Applying chat template to train dataset:  30%|███       | 2585/8564 [00:05<00:05, 1131.95 examples/s]Applying chat template to train dataset:  32%|███▏      | 2703/8564 [00:05<00:05, 1141.44 examples/s]Applying chat template to train dataset:  34%|███▎      | 2875/8564 [00:05<00:04, 1142.15 examples/s]Applying chat template to train dataset:  35%|███▍      | 2992/8564 [00:05<00:04, 1147.04 examples/s]Applying chat template to train dataset:  37%|███▋      | 3143/8564 [00:05<00:04, 1095.30 examples/s]Applying chat template to train dataset:  38%|███▊      | 3256/8564 [00:05<00:04, 1098.45 examples/s]Applying chat template to train dataset:  40%|████      | 3426/8564 [00:05<00:04, 1102.16 examples/s]Applying chat template to train dataset:  41%|████▏     | 3539/8564 [00:06<00:04, 1105.61 examples/s]Applying chat template to train dataset:  43%|████▎     | 3700/8564 [00:06<00:04, 1092.11 examples/s]Applying chat template to train dataset:  45%|████▍     | 3820/8564 [00:06<00:04, 1102.72 examples/s]Applying chat template to train dataset:  47%|████▋     | 3983/8564 [00:06<00:04, 1091.83 examples/s]Applying chat template to train dataset:  48%|████▊     | 4100/8564 [00:06<00:04, 1109.41 examples/s]Applying chat template to train dataset:  49%|████▉     | 4213/8564 [00:06<00:03, 1113.26 examples/s]Applying chat template to train dataset:  51%|█████     | 4330/8564 [00:06<00:03, 1126.49 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4478/8564 [00:06<00:03, 1223.97 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4622/8564 [00:06<00:03, 1272.33 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4792/8564 [00:07<00:03, 1217.37 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4999/8564 [00:07<00:02, 1239.19 examples/s]Applying chat template to train dataset:  60%|██████    | 5160/8564 [00:07<00:02, 1155.71 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5308/8564 [00:07<00:02, 1196.74 examples/s]Applying chat template to train dataset:  64%|██████▎   | 5439/8564 [00:07<00:02, 1221.42 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5585/8564 [00:07<00:02, 1282.40 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5716/8564 [00:07<00:02, 1288.17 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5904/8564 [00:07<00:02, 1252.90 examples/s]Applying chat template to train dataset:  71%|███████   | 6077/8564 [00:08<00:02, 1179.75 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6202/8564 [00:08<00:01, 1181.98 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6381/8564 [00:08<00:01, 1185.20 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6553/8564 [00:08<00:01, 1171.77 examples/s]Applying chat template to train dataset:  79%|███████▊  | 6744/8564 [00:08<00:01, 1177.52 examples/s]Applying chat template to train dataset:  81%|████████  | 6916/8564 [00:08<00:01, 1164.09 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7036/8564 [00:08<00:01, 1136.16 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7176/8564 [00:09<00:01, 1163.46 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7300/8564 [00:09<00:01, 1142.48 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7440/8564 [00:09<00:00, 1168.63 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7560/8564 [00:09<00:00, 1132.11 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7702/8564 [00:09<00:00, 1165.87 examples/s]Applying chat template to train dataset:  91%|█████████▏| 7825/8564 [00:09<00:00, 799.67 examples/s] Applying chat template to train dataset:  93%|█████████▎| 7942/8564 [00:09<00:00, 875.02 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8130/8564 [00:10<00:00, 1042.68 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8283/8564 [00:10<00:00, 1152.37 examples/s]Applying chat template to train dataset:  99%|█████████▊| 8450/8564 [00:10<00:00, 1269.66 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 826.45 examples/s] 
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 10/8564 [00:00<03:16, 43.58 examples/s]Tokenizing train dataset:   0%|          | 39/8564 [00:00<01:09, 123.23 examples/s]Tokenizing train dataset:   1%|          | 57/8564 [00:00<01:13, 115.49 examples/s]Tokenizing train dataset:   1%|          | 73/8564 [00:00<01:16, 111.51 examples/s]Tokenizing train dataset:   1%|          | 86/8564 [00:00<01:13, 114.65 examples/s]Tokenizing train dataset:   1%|          | 101/8564 [00:00<01:18, 108.21 examples/s]Tokenizing train dataset:   1%|▏         | 113/8564 [00:01<01:23, 101.44 examples/s]Tokenizing train dataset:   2%|▏         | 130/8564 [00:01<01:13, 115.29 examples/s]Tokenizing train dataset:   2%|▏         | 145/8564 [00:01<01:08, 123.48 examples/s]Tokenizing train dataset:   2%|▏         | 163/8564 [00:01<01:12, 116.08 examples/s]Tokenizing train dataset:   2%|▏         | 180/8564 [00:01<01:16, 109.72 examples/s]Tokenizing train dataset:   2%|▏         | 193/8564 [00:01<01:15, 111.42 examples/s]Tokenizing train dataset:   2%|▏         | 212/8564 [00:01<01:14, 111.92 examples/s]Tokenizing train dataset:   3%|▎         | 227/8564 [00:02<01:09, 119.28 examples/s]Tokenizing train dataset:   3%|▎         | 241/8564 [00:02<01:10, 118.34 examples/s]Tokenizing train dataset:   3%|▎         | 254/8564 [00:02<01:11, 116.28 examples/s]Tokenizing train dataset:   3%|▎         | 270/8564 [00:02<01:05, 126.49 examples/s]Tokenizing train dataset:   3%|▎         | 283/8564 [00:02<01:05, 125.94 examples/s]Tokenizing train dataset:   3%|▎         | 297/8564 [00:02<01:06, 123.69 examples/s]Tokenizing train dataset:   4%|▎         | 314/8564 [00:02<01:09, 118.57 examples/s]Tokenizing train dataset:   4%|▍         | 332/8564 [00:02<01:15, 109.25 examples/s]Tokenizing train dataset:   4%|▍         | 345/8564 [00:03<01:15, 108.80 examples/s]Tokenizing train dataset:   4%|▍         | 358/8564 [00:03<01:12, 113.33 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:03<01:14, 109.89 examples/s]Tokenizing train dataset:   4%|▍         | 384/8564 [00:03<01:13, 111.78 examples/s]Tokenizing train dataset:   5%|▍         | 400/8564 [00:03<01:17, 105.52 examples/s]Tokenizing train dataset:   5%|▍         | 414/8564 [00:03<01:13, 111.38 examples/s]Tokenizing train dataset:   5%|▌         | 429/8564 [00:03<01:12, 112.21 examples/s]Tokenizing train dataset:   5%|▌         | 443/8564 [00:03<01:22, 98.90 examples/s] Tokenizing train dataset:   5%|▌         | 454/8564 [00:04<01:23, 97.05 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:04<01:17, 104.95 examples/s]Tokenizing train dataset:   6%|▌         | 483/8564 [00:04<01:12, 111.72 examples/s]Tokenizing train dataset:   6%|▌         | 500/8564 [00:04<01:07, 119.43 examples/s]Tokenizing train dataset:   6%|▌         | 516/8564 [00:04<01:04, 125.49 examples/s]Tokenizing train dataset:   6%|▌         | 535/8564 [00:04<01:07, 118.49 examples/s]Tokenizing train dataset:   6%|▋         | 548/8564 [00:04<01:06, 120.59 examples/s]Tokenizing train dataset:   7%|▋         | 566/8564 [00:05<01:09, 114.57 examples/s]Tokenizing train dataset:   7%|▋         | 578/8564 [00:05<01:09, 114.15 examples/s]Tokenizing train dataset:   7%|▋         | 591/8564 [00:05<01:11, 111.62 examples/s]Tokenizing train dataset:   7%|▋         | 605/8564 [00:05<01:16, 104.44 examples/s]Tokenizing train dataset:   7%|▋         | 621/8564 [00:05<01:10, 112.22 examples/s]Tokenizing train dataset:   7%|▋         | 637/8564 [00:05<01:05, 121.33 examples/s]Tokenizing train dataset:   8%|▊         | 650/8564 [00:05<01:07, 117.20 examples/s]Tokenizing train dataset:   8%|▊         | 662/8564 [00:05<01:07, 116.77 examples/s]Tokenizing train dataset:   8%|▊         | 674/8564 [00:05<01:08, 115.56 examples/s]Tokenizing train dataset:   8%|▊         | 688/8564 [00:06<01:08, 115.37 examples/s]Tokenizing train dataset:   8%|▊         | 705/8564 [00:06<01:20, 97.33 examples/s] Tokenizing train dataset:   8%|▊         | 718/8564 [00:06<01:16, 103.13 examples/s]Tokenizing train dataset:   9%|▊         | 736/8564 [00:06<01:07, 116.74 examples/s]Tokenizing train dataset:   9%|▊         | 749/8564 [00:06<01:05, 119.47 examples/s]Tokenizing train dataset:   9%|▉         | 766/8564 [00:06<01:09, 112.23 examples/s]Tokenizing train dataset:   9%|▉         | 783/8564 [00:06<01:12, 107.67 examples/s]Tokenizing train dataset:   9%|▉         | 800/8564 [00:07<01:15, 103.05 examples/s]Tokenizing train dataset:   9%|▉         | 812/8564 [00:07<01:13, 106.09 examples/s]Tokenizing train dataset:  10%|▉         | 823/8564 [00:07<01:14, 103.31 examples/s]Tokenizing train dataset:  10%|▉         | 840/8564 [00:07<01:13, 105.65 examples/s]Tokenizing train dataset:  10%|▉         | 851/8564 [00:07<01:15, 102.07 examples/s]Tokenizing train dataset:  10%|█         | 865/8564 [00:07<01:11, 107.72 examples/s]Tokenizing train dataset:  10%|█         | 878/8564 [00:07<01:09, 110.99 examples/s]Tokenizing train dataset:  10%|█         | 893/8564 [00:07<01:04, 118.44 examples/s]Tokenizing train dataset:  11%|█         | 907/8564 [00:08<01:02, 123.07 examples/s]Tokenizing train dataset:  11%|█         | 921/8564 [00:08<01:09, 110.28 examples/s]Tokenizing train dataset:  11%|█         | 934/8564 [00:08<01:07, 113.75 examples/s]Tokenizing train dataset:  11%|█         | 950/8564 [00:08<01:10, 107.89 examples/s]Tokenizing train dataset:  11%|█▏        | 966/8564 [00:08<01:03, 119.69 examples/s]Tokenizing train dataset:  11%|█▏        | 981/8564 [00:08<01:10, 106.82 examples/s]Tokenizing train dataset:  12%|█▏        | 993/8564 [00:08<01:09, 108.33 examples/s]Tokenizing train dataset:  12%|█▏        | 1007/8564 [00:09<01:16, 98.29 examples/s]Tokenizing train dataset:  12%|█▏        | 1018/8564 [00:09<01:16, 98.91 examples/s]Tokenizing train dataset:  12%|█▏        | 1035/8564 [00:09<01:13, 102.11 examples/s]Tokenizing train dataset:  12%|█▏        | 1046/8564 [00:09<01:16, 98.77 examples/s] Tokenizing train dataset:  12%|█▏        | 1060/8564 [00:09<01:10, 107.19 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:09<01:06, 112.10 examples/s]Tokenizing train dataset:  13%|█▎        | 1096/8564 [00:09<00:56, 131.54 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:09<00:58, 128.52 examples/s]Tokenizing train dataset:  13%|█▎        | 1127/8564 [00:10<01:06, 112.63 examples/s]Tokenizing train dataset:  13%|█▎        | 1145/8564 [00:10<01:06, 112.33 examples/s]Tokenizing train dataset:  14%|█▎        | 1157/8564 [00:10<01:06, 111.73 examples/s]Tokenizing train dataset:  14%|█▎        | 1174/8564 [00:10<01:08, 107.18 examples/s]Tokenizing train dataset:  14%|█▍        | 1190/8564 [00:10<01:05, 113.33 examples/s]Tokenizing train dataset:  14%|█▍        | 1205/8564 [00:10<01:03, 116.48 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:10<01:06, 110.34 examples/s]Tokenizing train dataset:  14%|█▍        | 1233/8564 [00:11<01:05, 111.80 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:11<01:01, 119.03 examples/s]Tokenizing train dataset:  15%|█▍        | 1265/8564 [00:11<01:00, 120.78 examples/s]Tokenizing train dataset:  15%|█▍        | 1280/8564 [00:11<01:05, 111.09 examples/s]Tokenizing train dataset:  15%|█▌        | 1295/8564 [00:11<01:02, 115.52 examples/s]Tokenizing train dataset:  15%|█▌        | 1310/8564 [00:11<01:00, 119.61 examples/s]Tokenizing train dataset:  16%|█▌        | 1328/8564 [00:11<01:01, 118.18 examples/s]Tokenizing train dataset:  16%|█▌        | 1340/8564 [00:11<01:03, 114.29 examples/s]Tokenizing train dataset:  16%|█▌        | 1353/8564 [00:12<01:04, 111.72 examples/s]Tokenizing train dataset:  16%|█▌        | 1365/8564 [00:12<01:06, 107.56 examples/s]Tokenizing train dataset:  16%|█▌        | 1376/8564 [00:12<01:10, 102.18 examples/s]Tokenizing train dataset:  16%|█▌        | 1388/8564 [00:12<01:09, 103.66 examples/s]Tokenizing train dataset:  16%|█▋        | 1401/8564 [00:12<01:06, 107.50 examples/s]Tokenizing train dataset:  17%|█▋        | 1415/8564 [00:12<01:03, 113.10 examples/s]Tokenizing train dataset:  17%|█▋        | 1432/8564 [00:12<01:05, 109.08 examples/s]Tokenizing train dataset:  17%|█▋        | 1449/8564 [00:12<01:04, 109.68 examples/s]Tokenizing train dataset:  17%|█▋        | 1464/8564 [00:13<01:00, 117.94 examples/s]Tokenizing train dataset:  17%|█▋        | 1479/8564 [00:13<00:59, 118.74 examples/s]Tokenizing train dataset:  17%|█▋        | 1495/8564 [00:13<01:05, 108.21 examples/s]Tokenizing train dataset:  18%|█▊        | 1513/8564 [00:13<01:04, 108.73 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:13<01:00, 115.69 examples/s]Tokenizing train dataset:  18%|█▊        | 1542/8564 [00:13<01:00, 115.26 examples/s]Tokenizing train dataset:  18%|█▊        | 1559/8564 [00:13<01:02, 111.35 examples/s]Tokenizing train dataset:  18%|█▊        | 1574/8564 [00:14<01:05, 106.23 examples/s]Tokenizing train dataset:  19%|█▊        | 1586/8564 [00:14<01:04, 108.03 examples/s]Tokenizing train dataset:  19%|█▊        | 1599/8564 [00:14<01:02, 112.10 examples/s]Tokenizing train dataset:  19%|█▉        | 1611/8564 [00:14<01:03, 109.23 examples/s]Tokenizing train dataset:  19%|█▉        | 1626/8564 [00:14<00:58, 117.62 examples/s]Tokenizing train dataset:  19%|█▉        | 1641/8564 [00:14<00:57, 119.47 examples/s]Tokenizing train dataset:  19%|█▉        | 1655/8564 [00:14<00:58, 118.41 examples/s]Tokenizing train dataset:  19%|█▉        | 1669/8564 [00:14<00:57, 120.92 examples/s]Tokenizing train dataset:  20%|█▉        | 1683/8564 [00:15<00:56, 121.41 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:15<00:49, 138.88 examples/s]Tokenizing train dataset:  20%|██        | 1721/8564 [00:15<00:52, 130.66 examples/s]Tokenizing train dataset:  20%|██        | 1741/8564 [00:15<00:56, 120.53 examples/s]Tokenizing train dataset:  21%|██        | 1759/8564 [00:15<00:53, 126.54 examples/s]Tokenizing train dataset:  21%|██        | 1772/8564 [00:15<00:54, 125.19 examples/s]Tokenizing train dataset:  21%|██        | 1789/8564 [00:15<00:58, 115.60 examples/s]Tokenizing train dataset:  21%|██        | 1801/8564 [00:15<01:00, 111.47 examples/s]Tokenizing train dataset:  21%|██        | 1815/8564 [00:16<00:57, 117.02 examples/s]Tokenizing train dataset:  21%|██▏       | 1828/8564 [00:16<00:58, 114.83 examples/s]Tokenizing train dataset:  22%|██▏       | 1842/8564 [00:16<00:57, 116.14 examples/s]Tokenizing train dataset:  22%|██▏       | 1858/8564 [00:16<01:01, 108.46 examples/s]Tokenizing train dataset:  22%|██▏       | 1870/8564 [00:16<01:00, 109.92 examples/s]Tokenizing train dataset:  22%|██▏       | 1882/8564 [00:16<01:02, 106.22 examples/s]Tokenizing train dataset:  22%|██▏       | 1895/8564 [00:16<01:00, 110.55 examples/s]Tokenizing train dataset:  22%|██▏       | 1914/8564 [00:16<00:55, 120.03 examples/s]Tokenizing train dataset:  23%|██▎       | 1932/8564 [00:17<00:49, 133.93 examples/s]Tokenizing train dataset:  23%|██▎       | 1952/8564 [00:17<00:51, 129.33 examples/s]Tokenizing train dataset:  23%|██▎       | 1975/8564 [00:17<00:48, 136.58 examples/s]Tokenizing train dataset:  23%|██▎       | 1990/8564 [00:17<00:48, 134.97 examples/s]Tokenizing train dataset:  23%|██▎       | 2006/8564 [00:17<00:46, 139.78 examples/s]Tokenizing train dataset:  24%|██▎       | 2028/8564 [00:17<00:48, 134.36 examples/s]Tokenizing train dataset:  24%|██▍       | 2042/8564 [00:17<00:48, 135.16 examples/s]Tokenizing train dataset:  24%|██▍       | 2060/8564 [00:18<00:46, 139.94 examples/s]Tokenizing train dataset:  24%|██▍       | 2079/8564 [00:18<00:49, 131.09 examples/s]Tokenizing train dataset:  24%|██▍       | 2094/8564 [00:18<00:49, 129.87 examples/s]Tokenizing train dataset:  25%|██▍       | 2111/8564 [00:18<00:48, 131.87 examples/s]Tokenizing train dataset:  25%|██▍       | 2127/8564 [00:18<00:47, 134.43 examples/s]Tokenizing train dataset:  25%|██▌       | 2148/8564 [00:18<00:48, 131.26 examples/s]Tokenizing train dataset:  25%|██▌       | 2168/8564 [00:18<00:48, 131.04 examples/s]Tokenizing train dataset:  26%|██▌       | 2189/8564 [00:19<00:48, 131.87 examples/s]Tokenizing train dataset:  26%|██▌       | 2210/8564 [00:19<00:49, 127.39 examples/s]Tokenizing train dataset:  26%|██▌       | 2227/8564 [00:19<00:46, 135.47 examples/s]Tokenizing train dataset:  26%|██▌       | 2241/8564 [00:19<00:46, 135.61 examples/s]Tokenizing train dataset:  26%|██▋       | 2256/8564 [00:19<00:45, 138.02 examples/s]Tokenizing train dataset:  27%|██▋       | 2273/8564 [00:19<00:44, 142.85 examples/s]Tokenizing train dataset:  27%|██▋       | 2290/8564 [00:19<00:49, 127.95 examples/s]Tokenizing train dataset:  27%|██▋       | 2309/8564 [00:19<00:50, 125.08 examples/s]Tokenizing train dataset:  27%|██▋       | 2330/8564 [00:20<00:50, 123.03 examples/s]Tokenizing train dataset:  27%|██▋       | 2343/8564 [00:20<00:52, 119.13 examples/s]Tokenizing train dataset:  28%|██▊       | 2357/8564 [00:20<00:51, 121.06 examples/s]Tokenizing train dataset:  28%|██▊       | 2372/8564 [00:20<00:50, 122.81 examples/s]Tokenizing train dataset:  28%|██▊       | 2390/8564 [00:20<00:45, 135.58 examples/s]Tokenizing train dataset:  28%|██▊       | 2406/8564 [00:20<00:44, 138.87 examples/s]Tokenizing train dataset:  28%|██▊       | 2429/8564 [00:20<00:43, 141.99 examples/s]Tokenizing train dataset:  29%|██▊       | 2449/8564 [00:20<00:45, 134.70 examples/s]Tokenizing train dataset:  29%|██▉       | 2465/8564 [00:21<00:43, 139.15 examples/s]Tokenizing train dataset:  29%|██▉       | 2485/8564 [00:21<00:46, 131.53 examples/s]Tokenizing train dataset:  29%|██▉       | 2500/8564 [00:21<00:46, 130.79 examples/s]Tokenizing train dataset:  29%|██▉       | 2514/8564 [00:21<00:46, 130.60 examples/s]Tokenizing train dataset:  30%|██▉       | 2532/8564 [00:21<00:43, 138.22 examples/s]Tokenizing train dataset:  30%|██▉       | 2549/8564 [00:21<00:42, 140.69 examples/s]Tokenizing train dataset:  30%|██▉       | 2567/8564 [00:21<00:40, 147.59 examples/s]Tokenizing train dataset:  30%|███       | 2588/8564 [00:21<00:43, 138.73 examples/s]Tokenizing train dataset:  30%|███       | 2608/8564 [00:22<00:40, 148.83 examples/s]Tokenizing train dataset:  31%|███       | 2625/8564 [00:22<00:50, 117.95 examples/s]Tokenizing train dataset:  31%|███       | 2640/8564 [00:22<00:47, 123.94 examples/s]Tokenizing train dataset:  31%|███       | 2661/8564 [00:22<00:47, 123.92 examples/s]Tokenizing train dataset:  31%|███▏      | 2679/8564 [00:22<00:49, 118.82 examples/s]Tokenizing train dataset:  31%|███▏      | 2693/8564 [00:22<00:48, 121.98 examples/s]Tokenizing train dataset:  32%|███▏      | 2708/8564 [00:22<00:46, 126.20 examples/s]Tokenizing train dataset:  32%|███▏      | 2724/8564 [00:23<00:45, 127.77 examples/s]Tokenizing train dataset:  32%|███▏      | 2744/8564 [00:23<00:47, 122.70 examples/s]Tokenizing train dataset:  32%|███▏      | 2760/8564 [00:23<00:46, 124.63 examples/s]Tokenizing train dataset:  32%|███▏      | 2773/8564 [00:23<00:46, 125.45 examples/s]Tokenizing train dataset:  33%|███▎      | 2794/8564 [00:23<00:40, 141.39 examples/s]Tokenizing train dataset:  33%|███▎      | 2813/8564 [00:23<00:37, 153.23 examples/s]Tokenizing train dataset:  33%|███▎      | 2831/8564 [00:23<00:37, 154.54 examples/s]Tokenizing train dataset:  33%|███▎      | 2853/8564 [00:23<00:34, 165.75 examples/s]Tokenizing train dataset:  34%|███▎      | 2875/8564 [00:24<00:38, 146.65 examples/s]Tokenizing train dataset:  34%|███▍      | 2895/8564 [00:24<00:37, 149.30 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:24<00:32, 173.55 examples/s]Tokenizing train dataset:  34%|███▍      | 2945/8564 [00:24<00:34, 163.41 examples/s]Tokenizing train dataset:  35%|███▍      | 2963/8564 [00:24<00:34, 162.55 examples/s]Tokenizing train dataset:  35%|███▍      | 2982/8564 [00:24<00:33, 167.74 examples/s]Tokenizing train dataset:  35%|███▌      | 3005/8564 [00:24<00:36, 152.83 examples/s]Tokenizing train dataset:  35%|███▌      | 3027/8564 [00:25<00:37, 146.12 examples/s]Tokenizing train dataset:  36%|███▌      | 3046/8564 [00:25<00:40, 137.85 examples/s]Tokenizing train dataset:  36%|███▌      | 3066/8564 [00:25<00:41, 132.59 examples/s]Tokenizing train dataset:  36%|███▌      | 3082/8564 [00:25<00:39, 137.23 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:25<00:39, 137.14 examples/s]Tokenizing train dataset:  36%|███▋      | 3111/8564 [00:25<00:39, 136.62 examples/s]Tokenizing train dataset:  37%|███▋      | 3130/8564 [00:25<00:42, 127.29 examples/s]Tokenizing train dataset:  37%|███▋      | 3146/8564 [00:26<00:41, 131.24 examples/s]Tokenizing train dataset:  37%|███▋      | 3161/8564 [00:26<00:39, 135.31 examples/s]Tokenizing train dataset:  37%|███▋      | 3180/8564 [00:26<00:43, 123.55 examples/s]Tokenizing train dataset:  37%|███▋      | 3195/8564 [00:26<00:41, 129.55 examples/s]Tokenizing train dataset:  37%|███▋      | 3210/8564 [00:26<00:40, 131.04 examples/s]Tokenizing train dataset:  38%|███▊      | 3225/8564 [00:26<00:39, 134.22 examples/s]Tokenizing train dataset:  38%|███▊      | 3239/8564 [00:26<00:39, 135.34 examples/s]Tokenizing train dataset:  38%|███▊      | 3255/8564 [00:26<00:37, 140.33 examples/s]Tokenizing train dataset:  38%|███▊      | 3271/8564 [00:26<00:37, 141.66 examples/s]Tokenizing train dataset:  38%|███▊      | 3286/8564 [00:27<00:38, 136.65 examples/s]Tokenizing train dataset:  39%|███▊      | 3300/8564 [00:27<00:40, 129.23 examples/s]Tokenizing train dataset:  39%|███▊      | 3314/8564 [00:27<00:40, 130.64 examples/s]Tokenizing train dataset:  39%|███▉      | 3332/8564 [00:27<00:42, 122.13 examples/s]Tokenizing train dataset:  39%|███▉      | 3347/8564 [00:27<00:40, 127.59 examples/s]Tokenizing train dataset:  39%|███▉      | 3362/8564 [00:27<00:40, 127.19 examples/s]Tokenizing train dataset:  39%|███▉      | 3379/8564 [00:27<00:38, 136.41 examples/s]Tokenizing train dataset:  40%|███▉      | 3397/8564 [00:27<00:37, 139.38 examples/s]Tokenizing train dataset:  40%|███▉      | 3412/8564 [00:27<00:36, 141.47 examples/s]Tokenizing train dataset:  40%|████      | 3427/8564 [00:28<00:35, 143.12 examples/s]Tokenizing train dataset:  40%|████      | 3450/8564 [00:28<00:36, 140.70 examples/s]Tokenizing train dataset:  40%|████      | 3468/8564 [00:28<00:35, 142.95 examples/s]Tokenizing train dataset:  41%|████      | 3485/8564 [00:28<00:38, 131.52 examples/s]Tokenizing train dataset:  41%|████      | 3500/8564 [00:28<00:38, 132.41 examples/s]Tokenizing train dataset:  41%|████      | 3519/8564 [00:28<00:35, 141.69 examples/s]Tokenizing train dataset:  41%|████▏     | 3535/8564 [00:28<00:34, 145.10 examples/s]Tokenizing train dataset:  42%|████▏     | 3556/8564 [00:29<00:36, 138.76 examples/s]Tokenizing train dataset:  42%|████▏     | 3579/8564 [00:29<00:35, 139.15 examples/s]Tokenizing train dataset:  42%|████▏     | 3594/8564 [00:29<00:35, 140.87 examples/s]Tokenizing train dataset:  42%|████▏     | 3609/8564 [00:29<00:34, 141.61 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:29<00:35, 139.97 examples/s]Tokenizing train dataset:  43%|████▎     | 3646/8564 [00:29<00:38, 126.63 examples/s]Tokenizing train dataset:  43%|████▎     | 3660/8564 [00:29<00:39, 125.49 examples/s]Tokenizing train dataset:  43%|████▎     | 3673/8564 [00:29<00:39, 124.24 examples/s]Tokenizing train dataset:  43%|████▎     | 3687/8564 [00:30<00:39, 123.28 examples/s]Tokenizing train dataset:  43%|████▎     | 3700/8564 [00:30<00:39, 124.67 examples/s]Tokenizing train dataset:  43%|████▎     | 3719/8564 [00:30<00:34, 140.97 examples/s]Tokenizing train dataset:  44%|████▎     | 3740/8564 [00:30<00:36, 131.99 examples/s]Tokenizing train dataset:  44%|████▍     | 3757/8564 [00:30<00:34, 138.71 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:30<00:36, 131.55 examples/s]Tokenizing train dataset:  44%|████▍     | 3796/8564 [00:30<00:35, 132.53 examples/s]Tokenizing train dataset:  44%|████▍     | 3810/8564 [00:30<00:35, 132.21 examples/s]Tokenizing train dataset:  45%|████▍     | 3824/8564 [00:31<00:36, 128.25 examples/s]Tokenizing train dataset:  45%|████▍     | 3839/8564 [00:31<00:37, 125.87 examples/s]Tokenizing train dataset:  45%|████▍     | 3852/8564 [00:31<00:38, 121.88 examples/s]Tokenizing train dataset:  45%|████▌     | 3866/8564 [00:31<00:37, 125.37 examples/s]Tokenizing train dataset:  45%|████▌     | 3881/8564 [00:31<00:36, 129.79 examples/s]Tokenizing train dataset:  46%|████▌     | 3900/8564 [00:31<00:38, 122.16 examples/s]Tokenizing train dataset:  46%|████▌     | 3915/8564 [00:31<00:37, 124.91 examples/s]Tokenizing train dataset:  46%|████▌     | 3930/8564 [00:31<00:37, 122.00 examples/s]Tokenizing train dataset:  46%|████▌     | 3945/8564 [00:32<00:36, 125.40 examples/s]Tokenizing train dataset:  46%|████▌     | 3960/8564 [00:32<00:36, 127.13 examples/s]Tokenizing train dataset:  46%|████▋     | 3974/8564 [00:32<00:35, 129.12 examples/s]Tokenizing train dataset:  47%|████▋     | 3990/8564 [00:32<00:35, 127.37 examples/s]Tokenizing train dataset:  47%|████▋     | 4004/8564 [00:32<00:35, 130.09 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:32<00:33, 134.87 examples/s]Tokenizing train dataset:  47%|████▋     | 4044/8564 [00:32<00:33, 136.75 examples/s]Tokenizing train dataset:  47%|████▋     | 4061/8564 [00:32<00:35, 126.71 examples/s]Tokenizing train dataset:  48%|████▊     | 4075/8564 [00:33<00:40, 110.56 examples/s]Tokenizing train dataset:  48%|████▊     | 4088/8564 [00:33<00:39, 112.42 examples/s]Tokenizing train dataset:  48%|████▊     | 4103/8564 [00:33<00:39, 113.65 examples/s]Tokenizing train dataset:  48%|████▊     | 4120/8564 [00:33<00:36, 120.72 examples/s]Tokenizing train dataset:  48%|████▊     | 4138/8564 [00:33<00:37, 117.70 examples/s]Tokenizing train dataset:  48%|████▊     | 4152/8564 [00:33<00:37, 116.78 examples/s]Tokenizing train dataset:  49%|████▊     | 4169/8564 [00:33<00:35, 125.54 examples/s]Tokenizing train dataset:  49%|████▉     | 4183/8564 [00:33<00:34, 127.99 examples/s]Tokenizing train dataset:  49%|████▉     | 4200/8564 [00:34<00:31, 136.94 examples/s]Tokenizing train dataset:  49%|████▉     | 4220/8564 [00:34<00:33, 130.34 examples/s]Tokenizing train dataset:  49%|████▉     | 4234/8564 [00:34<00:33, 127.95 examples/s]Tokenizing train dataset:  50%|████▉     | 4247/8564 [00:34<00:34, 126.95 examples/s]Tokenizing train dataset:  50%|████▉     | 4262/8564 [00:34<00:34, 124.96 examples/s]Tokenizing train dataset:  50%|████▉     | 4277/8564 [00:34<00:33, 128.97 examples/s]Tokenizing train dataset:  50%|█████     | 4291/8564 [00:34<00:34, 124.70 examples/s]Tokenizing train dataset:  50%|█████     | 4309/8564 [00:34<00:32, 130.73 examples/s]Tokenizing train dataset:  51%|█████     | 4329/8564 [00:35<00:32, 131.05 examples/s]Tokenizing train dataset:  51%|█████     | 4348/8564 [00:35<00:34, 123.96 examples/s]Tokenizing train dataset:  51%|█████     | 4362/8564 [00:35<00:33, 126.41 examples/s]Tokenizing train dataset:  51%|█████     | 4380/8564 [00:35<00:35, 118.09 examples/s]Tokenizing train dataset:  51%|█████▏    | 4409/8564 [00:35<00:26, 156.21 examples/s]Tokenizing train dataset:  52%|█████▏    | 4426/8564 [00:35<00:26, 157.40 examples/s]Tokenizing train dataset:  52%|█████▏    | 4448/8564 [00:35<00:27, 152.22 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:36<00:28, 143.29 examples/s]Tokenizing train dataset:  52%|█████▏    | 4485/8564 [00:36<00:28, 143.78 examples/s]Tokenizing train dataset:  53%|█████▎    | 4503/8564 [00:36<00:31, 130.50 examples/s]Tokenizing train dataset:  53%|█████▎    | 4519/8564 [00:36<00:30, 130.80 examples/s]Tokenizing train dataset:  53%|█████▎    | 4533/8564 [00:36<00:30, 132.56 examples/s]Tokenizing train dataset:  53%|█████▎    | 4555/8564 [00:36<00:29, 136.22 examples/s]Tokenizing train dataset:  53%|█████▎    | 4569/8564 [00:36<00:30, 131.27 examples/s]Tokenizing train dataset:  54%|█████▎    | 4594/8564 [00:37<00:28, 140.54 examples/s]Tokenizing train dataset:  54%|█████▍    | 4609/8564 [00:37<00:27, 141.52 examples/s]Tokenizing train dataset:  54%|█████▍    | 4630/8564 [00:37<00:29, 135.15 examples/s]Tokenizing train dataset:  54%|█████▍    | 4644/8564 [00:37<00:31, 126.39 examples/s]Tokenizing train dataset:  54%|█████▍    | 4657/8564 [00:37<00:31, 125.57 examples/s]Tokenizing train dataset:  55%|█████▍    | 4673/8564 [00:37<00:33, 117.04 examples/s]Tokenizing train dataset:  55%|█████▍    | 4685/8564 [00:37<00:33, 115.67 examples/s]Tokenizing train dataset:  55%|█████▍    | 4701/8564 [00:37<00:35, 108.83 examples/s]Tokenizing train dataset:  55%|█████▌    | 4714/8564 [00:38<00:35, 109.03 examples/s]Tokenizing train dataset:  55%|█████▌    | 4727/8564 [00:38<00:34, 111.97 examples/s]Tokenizing train dataset:  55%|█████▌    | 4740/8564 [00:38<00:34, 112.36 examples/s]Tokenizing train dataset:  56%|█████▌    | 4754/8564 [00:38<00:33, 113.47 examples/s]Tokenizing train dataset:  56%|█████▌    | 4767/8564 [00:38<00:32, 116.22 examples/s]Tokenizing train dataset:  56%|█████▌    | 4779/8564 [00:38<00:34, 111.07 examples/s]Tokenizing train dataset:  56%|█████▌    | 4793/8564 [00:38<00:31, 118.33 examples/s]Tokenizing train dataset:  56%|█████▌    | 4813/8564 [00:38<00:27, 135.13 examples/s]Tokenizing train dataset:  57%|█████▋    | 4843/8564 [00:38<00:21, 174.82 examples/s]Tokenizing train dataset:  57%|█████▋    | 4864/8564 [00:39<00:20, 176.71 examples/s]Tokenizing train dataset:  57%|█████▋    | 4884/8564 [00:39<00:20, 180.09 examples/s]Tokenizing train dataset:  57%|█████▋    | 4912/8564 [00:39<00:18, 201.12 examples/s]Tokenizing train dataset:  58%|█████▊    | 4938/8564 [00:39<00:17, 209.93 examples/s]Tokenizing train dataset:  58%|█████▊    | 4962/8564 [00:39<00:17, 207.94 examples/s]Tokenizing train dataset:  58%|█████▊    | 4984/8564 [00:39<00:17, 205.38 examples/s]Tokenizing train dataset:  58%|█████▊    | 5007/8564 [00:39<00:17, 206.95 examples/s]Tokenizing train dataset:  59%|█████▊    | 5029/8564 [00:39<00:17, 202.42 examples/s]Tokenizing train dataset:  59%|█████▉    | 5050/8564 [00:39<00:17, 199.02 examples/s]Tokenizing train dataset:  59%|█████▉    | 5078/8564 [00:40<00:16, 208.63 examples/s]Tokenizing train dataset:  60%|█████▉    | 5104/8564 [00:40<00:15, 218.54 examples/s]Tokenizing train dataset:  60%|█████▉    | 5136/8564 [00:40<00:16, 206.33 examples/s]Tokenizing train dataset:  60%|██████    | 5166/8564 [00:40<00:15, 221.15 examples/s]Tokenizing train dataset:  61%|██████    | 5190/8564 [00:40<00:15, 223.97 examples/s]Tokenizing train dataset:  61%|██████    | 5223/8564 [00:40<00:16, 207.46 examples/s]Tokenizing train dataset:  61%|██████▏   | 5255/8564 [00:40<00:14, 228.02 examples/s]Tokenizing train dataset:  62%|██████▏   | 5286/8564 [00:40<00:13, 246.66 examples/s]Tokenizing train dataset:  62%|██████▏   | 5322/8564 [00:41<00:13, 237.71 examples/s]Tokenizing train dataset:  63%|██████▎   | 5356/8564 [00:41<00:12, 254.42 examples/s]Tokenizing train dataset:  63%|██████▎   | 5388/8564 [00:41<00:13, 239.51 examples/s]Tokenizing train dataset:  63%|██████▎   | 5427/8564 [00:41<00:13, 236.59 examples/s]Tokenizing train dataset:  64%|██████▎   | 5453/8564 [00:41<00:12, 240.30 examples/s]Tokenizing train dataset:  64%|██████▍   | 5482/8564 [00:41<00:12, 237.89 examples/s]Tokenizing train dataset:  64%|██████▍   | 5521/8564 [00:41<00:13, 233.94 examples/s]Tokenizing train dataset:  65%|██████▍   | 5549/8564 [00:42<00:12, 234.53 examples/s]Tokenizing train dataset:  65%|██████▌   | 5585/8564 [00:42<00:13, 228.33 examples/s]Tokenizing train dataset:  66%|██████▌   | 5620/8564 [00:42<00:12, 227.76 examples/s]Tokenizing train dataset:  66%|██████▌   | 5653/8564 [00:42<00:13, 221.90 examples/s]Tokenizing train dataset:  66%|██████▋   | 5678/8564 [00:42<00:12, 227.10 examples/s]Tokenizing train dataset:  67%|██████▋   | 5703/8564 [00:42<00:12, 228.30 examples/s]Tokenizing train dataset:  67%|██████▋   | 5727/8564 [00:42<00:12, 230.93 examples/s]Tokenizing train dataset:  67%|██████▋   | 5752/8564 [00:43<00:11, 235.57 examples/s]Tokenizing train dataset:  68%|██████▊   | 5783/8564 [00:43<00:11, 246.58 examples/s]Tokenizing train dataset:  68%|██████▊   | 5812/8564 [00:43<00:10, 257.45 examples/s]Tokenizing train dataset:  68%|██████▊   | 5846/8564 [00:43<00:11, 232.83 examples/s]Tokenizing train dataset:  69%|██████▊   | 5874/8564 [00:43<00:12, 216.47 examples/s]Tokenizing train dataset:  69%|██████▉   | 5897/8564 [00:43<00:12, 211.11 examples/s]Tokenizing train dataset:  69%|██████▉   | 5923/8564 [00:43<00:12, 217.99 examples/s]Tokenizing train dataset:  69%|██████▉   | 5948/8564 [00:43<00:11, 218.27 examples/s]Tokenizing train dataset:  70%|██████▉   | 5975/8564 [00:43<00:11, 230.09 examples/s]Tokenizing train dataset:  70%|███████   | 6007/8564 [00:44<00:18, 135.20 examples/s]Tokenizing train dataset:  70%|███████   | 6029/8564 [00:44<00:17, 147.62 examples/s]Tokenizing train dataset:  71%|███████   | 6057/8564 [00:44<00:14, 171.83 examples/s]Tokenizing train dataset:  71%|███████   | 6082/8564 [00:44<00:14, 166.95 examples/s]Tokenizing train dataset:  71%|███████▏  | 6108/8564 [00:44<00:13, 185.23 examples/s]Tokenizing train dataset:  72%|███████▏  | 6131/8564 [00:45<00:12, 189.02 examples/s]Tokenizing train dataset:  72%|███████▏  | 6160/8564 [00:45<00:11, 212.56 examples/s]Tokenizing train dataset:  72%|███████▏  | 6186/8564 [00:45<00:10, 216.35 examples/s]Tokenizing train dataset:  73%|███████▎  | 6216/8564 [00:45<00:09, 237.51 examples/s]Tokenizing train dataset:  73%|███████▎  | 6254/8564 [00:45<00:09, 241.95 examples/s]Tokenizing train dataset:  73%|███████▎  | 6280/8564 [00:45<00:09, 236.31 examples/s]Tokenizing train dataset:  74%|███████▍  | 6319/8564 [00:45<00:09, 241.45 examples/s]Tokenizing train dataset:  74%|███████▍  | 6355/8564 [00:45<00:09, 237.63 examples/s]Tokenizing train dataset:  75%|███████▍  | 6382/8564 [00:46<00:09, 237.13 examples/s]Tokenizing train dataset:  75%|███████▍  | 6409/8564 [00:46<00:09, 234.35 examples/s]Tokenizing train dataset:  75%|███████▌  | 6434/8564 [00:46<00:09, 234.86 examples/s]Tokenizing train dataset:  76%|███████▌  | 6469/8564 [00:46<00:09, 226.75 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [00:46<00:09, 214.10 examples/s]Tokenizing train dataset:  76%|███████▌  | 6518/8564 [00:46<00:09, 222.25 examples/s]Tokenizing train dataset:  76%|███████▋  | 6543/8564 [00:46<00:08, 226.79 examples/s]Tokenizing train dataset:  77%|███████▋  | 6575/8564 [00:46<00:09, 214.77 examples/s]Tokenizing train dataset:  77%|███████▋  | 6602/8564 [00:47<00:09, 198.83 examples/s]Tokenizing train dataset:  77%|███████▋  | 6632/8564 [00:47<00:10, 189.49 examples/s]Tokenizing train dataset:  78%|███████▊  | 6660/8564 [00:47<00:09, 204.32 examples/s]Tokenizing train dataset:  78%|███████▊  | 6691/8564 [00:47<00:08, 217.46 examples/s]Tokenizing train dataset:  78%|███████▊  | 6718/8564 [00:47<00:08, 228.44 examples/s]Tokenizing train dataset:  79%|███████▊  | 6742/8564 [00:47<00:07, 228.10 examples/s]Tokenizing train dataset:  79%|███████▉  | 6769/8564 [00:47<00:07, 238.23 examples/s]Tokenizing train dataset:  79%|███████▉  | 6804/8564 [00:47<00:07, 230.24 examples/s]Tokenizing train dataset:  80%|███████▉  | 6833/8564 [00:48<00:08, 210.45 examples/s]Tokenizing train dataset:  80%|████████  | 6857/8564 [00:48<00:08, 210.86 examples/s]Tokenizing train dataset:  80%|████████  | 6885/8564 [00:48<00:07, 217.93 examples/s]Tokenizing train dataset:  81%|████████  | 6915/8564 [00:48<00:07, 226.84 examples/s]Tokenizing train dataset:  81%|████████  | 6945/8564 [00:48<00:06, 243.78 examples/s]Tokenizing train dataset:  81%|████████▏ | 6978/8564 [00:48<00:06, 230.17 examples/s]Tokenizing train dataset:  82%|████████▏ | 7012/8564 [00:48<00:07, 210.50 examples/s]Tokenizing train dataset:  82%|████████▏ | 7036/8564 [00:49<00:07, 205.56 examples/s]Tokenizing train dataset:  82%|████████▏ | 7064/8564 [00:49<00:06, 220.64 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [00:49<00:06, 230.55 examples/s]Tokenizing train dataset:  83%|████████▎ | 7116/8564 [00:49<00:06, 234.84 examples/s]Tokenizing train dataset:  83%|████████▎ | 7150/8564 [00:49<00:06, 227.20 examples/s]Tokenizing train dataset:  84%|████████▍ | 7179/8564 [00:49<00:05, 241.82 examples/s]Tokenizing train dataset:  84%|████████▍ | 7205/8564 [00:49<00:05, 237.19 examples/s]Tokenizing train dataset:  85%|████████▍ | 7238/8564 [00:49<00:06, 219.77 examples/s]Tokenizing train dataset:  85%|████████▍ | 7262/8564 [00:50<00:05, 222.04 examples/s]Tokenizing train dataset:  85%|████████▌ | 7290/8564 [00:50<00:05, 226.80 examples/s]Tokenizing train dataset:  86%|████████▌ | 7324/8564 [00:50<00:05, 224.81 examples/s]Tokenizing train dataset:  86%|████████▌ | 7348/8564 [00:50<00:05, 227.67 examples/s]Tokenizing train dataset:  86%|████████▌ | 7374/8564 [00:50<00:05, 227.28 examples/s]Tokenizing train dataset:  86%|████████▋ | 7402/8564 [00:50<00:05, 208.12 examples/s]Tokenizing train dataset:  87%|████████▋ | 7436/8564 [00:50<00:04, 233.46 examples/s]Tokenizing train dataset:  87%|████████▋ | 7463/8564 [00:50<00:04, 241.41 examples/s]Tokenizing train dataset:  87%|████████▋ | 7490/8564 [00:51<00:05, 211.07 examples/s]Tokenizing train dataset:  88%|████████▊ | 7515/8564 [00:51<00:04, 216.63 examples/s]Tokenizing train dataset:  88%|████████▊ | 7542/8564 [00:51<00:04, 230.03 examples/s]Tokenizing train dataset:  88%|████████▊ | 7566/8564 [00:51<00:04, 231.53 examples/s]Tokenizing train dataset:  89%|████████▊ | 7595/8564 [00:51<00:03, 244.84 examples/s]Tokenizing train dataset:  89%|████████▉ | 7621/8564 [00:51<00:03, 247.80 examples/s]Tokenizing train dataset:  89%|████████▉ | 7649/8564 [00:51<00:04, 219.01 examples/s]Tokenizing train dataset:  90%|████████▉ | 7676/8564 [00:51<00:04, 202.62 examples/s]Tokenizing train dataset:  90%|████████▉ | 7701/8564 [00:51<00:04, 212.90 examples/s]Tokenizing train dataset:  90%|█████████ | 7724/8564 [00:52<00:04, 209.85 examples/s]Tokenizing train dataset:  90%|█████████ | 7747/8564 [00:52<00:03, 212.50 examples/s]Tokenizing train dataset:  91%|█████████ | 7774/8564 [00:52<00:04, 195.91 examples/s]Tokenizing train dataset:  91%|█████████ | 7795/8564 [00:52<00:03, 197.91 examples/s]Tokenizing train dataset:  91%|█████████▏| 7820/8564 [00:52<00:03, 204.45 examples/s]Tokenizing train dataset:  92%|█████████▏| 7849/8564 [00:52<00:03, 224.91 examples/s]Tokenizing train dataset:  92%|█████████▏| 7880/8564 [00:52<00:03, 207.75 examples/s]Tokenizing train dataset:  92%|█████████▏| 7909/8564 [00:52<00:02, 221.29 examples/s]Tokenizing train dataset:  93%|█████████▎| 7932/8564 [00:53<00:02, 221.82 examples/s]Tokenizing train dataset:  93%|█████████▎| 7955/8564 [00:53<00:02, 222.54 examples/s]Tokenizing train dataset:  93%|█████████▎| 7990/8564 [00:53<00:02, 219.07 examples/s]Tokenizing train dataset:  94%|█████████▎| 8018/8564 [00:53<00:02, 232.71 examples/s]Tokenizing train dataset:  94%|█████████▍| 8047/8564 [00:53<00:02, 210.54 examples/s]Tokenizing train dataset:  94%|█████████▍| 8073/8564 [00:53<00:02, 215.30 examples/s]Tokenizing train dataset:  95%|█████████▍| 8105/8564 [00:53<00:02, 210.40 examples/s]Tokenizing train dataset:  95%|█████████▍| 8132/8564 [00:54<00:02, 195.07 examples/s]Tokenizing train dataset:  95%|█████████▌| 8161/8564 [00:54<00:01, 215.56 examples/s]Tokenizing train dataset:  96%|█████████▌| 8187/8564 [00:54<00:01, 225.38 examples/s]Tokenizing train dataset:  96%|█████████▌| 8222/8564 [00:54<00:01, 216.79 examples/s]Tokenizing train dataset:  96%|█████████▋| 8245/8564 [00:54<00:01, 215.26 examples/s]Tokenizing train dataset:  97%|█████████▋| 8277/8564 [00:54<00:01, 240.44 examples/s]Tokenizing train dataset:  97%|█████████▋| 8306/8564 [00:54<00:01, 253.24 examples/s]Tokenizing train dataset:  97%|█████████▋| 8334/8564 [00:54<00:01, 227.12 examples/s]Tokenizing train dataset:  98%|█████████▊| 8362/8564 [00:55<00:00, 204.93 examples/s]Tokenizing train dataset:  98%|█████████▊| 8396/8564 [00:55<00:00, 234.50 examples/s]Tokenizing train dataset:  98%|█████████▊| 8425/8564 [00:55<00:00, 238.09 examples/s]Tokenizing train dataset:  99%|█████████▊| 8454/8564 [00:55<00:00, 220.67 examples/s]Tokenizing train dataset:  99%|█████████▉| 8485/8564 [00:55<00:00, 234.03 examples/s]Tokenizing train dataset:  99%|█████████▉| 8520/8564 [00:55<00:00, 232.36 examples/s]Tokenizing train dataset: 100%|█████████▉| 8553/8564 [00:55<00:00, 226.93 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:55<00:00, 153.20 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  70%|██████▉   | 663/953 [00:00<00:00, 6579.28 examples/s]Extracting prompt in train dataset:   3%|▎         | 263/8564 [00:00<00:03, 2488.28 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 6396.68 examples/s]
Extracting prompt in train dataset:   7%|▋         | 600/8564 [00:00<00:02, 2959.39 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1000/8564 [00:00<00:02, 3391.19 examples/s]Extracting prompt in train dataset:   0%|          | 10/8564 [00:00<04:34, 31.21 examples/s]Extracting prompt in train dataset:   0%|          | 10/8564 [00:00<05:41, 25.05 examples/s]Extracting prompt in train dataset:   3%|▎         | 220/8564 [00:00<00:12, 666.21 examples/s]Extracting prompt in train dataset:   3%|▎         | 244/8564 [00:00<00:13, 604.69 examples/s]Extracting prompt in train dataset:  16%|█▋        | 1401/8564 [00:00<00:02, 2442.67 examples/s]Extracting prompt in train dataset:   5%|▍         | 410/8564 [00:00<00:09, 892.32 examples/s]Extracting prompt in train dataset:   7%|▋         | 590/8564 [00:00<00:05, 1356.34 examples/s]Extracting prompt in train dataset:   7%|▋         | 564/8564 [00:00<00:07, 1057.05 examples/s]Extracting prompt in train dataset:  10%|▉         | 851/8564 [00:00<00:04, 1698.02 examples/s]Extracting prompt in train dataset:   9%|▊         | 730/8564 [00:00<00:06, 1216.99 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1680/8564 [00:00<00:04, 1606.79 examples/s]Extracting prompt in train dataset:  14%|█▍        | 1190/8564 [00:00<00:03, 1900.12 examples/s]Extracting prompt in train dataset:  10%|█         | 880/8564 [00:00<00:05, 1292.72 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  13%|█▎        | 1090/8564 [00:00<00:04, 1517.84 examples/s]Applying chat template to eval dataset:  29%|██▉       | 280/953 [00:00<00:00, 2775.91 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1911/8564 [00:01<00:04, 1583.73 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1485/8564 [00:01<00:04, 1675.01 examples/s]Extracting prompt in train dataset:  15%|█▍        | 1280/8564 [00:01<00:04, 1571.24 examples/s]Applying chat template to eval dataset:  70%|██████▉   | 666/953 [00:00<00:00, 3191.51 examples/s]Extracting prompt in train dataset:  25%|██▌       | 2180/8564 [00:01<00:03, 1597.79 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3326.33 examples/s]
Extracting prompt in train dataset:  20%|█▉        | 1710/8564 [00:01<00:04, 1598.18 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2410/8564 [00:01<00:03, 1666.82 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1521/8564 [00:01<00:05, 1400.62 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1981/8564 [00:01<00:03, 1838.55 examples/s]Extracting prompt in train dataset:  31%|███       | 2630/8564 [00:01<00:03, 1564.98 examples/s]Extracting prompt in train dataset:  20%|██        | 1744/8564 [00:01<00:04, 1392.41 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2190/8564 [00:01<00:03, 1817.52 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2830/8564 [00:01<00:03, 1647.42 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1951/8564 [00:01<00:04, 1388.14 examples/s]Extracting prompt in train dataset:  29%|██▊       | 2450/8564 [00:01<00:03, 1786.46 examples/s]Extracting prompt in train dataset:  35%|███▌      | 3030/8564 [00:01<00:03, 1720.85 examples/s]Extracting prompt in train dataset:  25%|██▌       | 2148/8564 [00:01<00:04, 1484.14 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3223/8564 [00:01<00:03, 1769.16 examples/s]Extracting prompt in train dataset:  31%|███▏      | 2682/8564 [00:01<00:03, 1706.70 examples/s]Extracting prompt in train dataset:  34%|███▎      | 2890/8564 [00:01<00:03, 1777.82 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2360/8564 [00:01<00:04, 1443.16 examples/s]Extracting prompt in train dataset:  41%|████      | 3480/8564 [00:01<00:02, 1737.32 examples/s]Extracting prompt in train dataset:  29%|██▉       | 2521/8564 [00:01<00:04, 1446.27 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3670/8564 [00:02<00:02, 1774.42 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3150/8564 [00:02<00:03, 1757.02 examples/s]Extracting prompt in train dataset:  31%|███▏      | 2690/8564 [00:02<00:03, 1497.60 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3860/8564 [00:02<00:02, 1800.91 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3340/8564 [00:02<00:02, 1782.88 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  33%|███▎      | 2867/8564 [00:02<00:03, 1567.03 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3590/8564 [00:02<00:02, 1733.41 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4110/8564 [00:02<00:02, 1686.87 examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:09, 100.41 examples/s]Extracting prompt in train dataset:  36%|███▌      | 3050/8564 [00:02<00:03, 1541.93 examples/s]Extracting prompt in train dataset:  45%|████▍     | 3820/8564 [00:02<00:02, 1866.41 examples/s]Tokenizing eval dataset:   2%|▏         | 23/953 [00:00<00:09, 97.57 examples/s] Extracting prompt in train dataset:  38%|███▊      | 3220/8564 [00:02<00:03, 1552.89 examples/s]Extracting prompt in train dataset:  51%|█████     | 4370/8564 [00:02<00:02, 1693.81 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:09, 97.91 examples/s]Extracting prompt in train dataset:  40%|███▉      | 3392/8564 [00:02<00:03, 1550.61 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4110/8564 [00:02<00:02, 1832.02 examples/s]Extracting prompt in train dataset:  54%|█████▎    | 4590/8564 [00:02<00:02, 1600.92 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3556/8564 [00:02<00:03, 1545.26 examples/s]Extracting prompt in train dataset:  50%|█████     | 4308/8564 [00:02<00:02, 1831.09 examples/s]Tokenizing eval dataset:   5%|▍         | 46/953 [00:00<00:09, 96.47 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4760/8564 [00:02<00:02, 1619.97 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3720/8564 [00:02<00:03, 1565.16 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4501/8564 [00:02<00:02, 1795.18 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4970/8564 [00:02<00:02, 1730.85 examples/s]Tokenizing eval dataset:   6%|▌         | 59/953 [00:00<00:10, 84.69 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 4700/8564 [00:02<00:02, 1832.90 examples/s]Extracting prompt in train dataset:  46%|████▌     | 3940/8564 [00:02<00:03, 1497.63 examples/s]Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:10, 84.68 examples/s]Extracting prompt in train dataset:  61%|██████    | 5232/8564 [00:02<00:01, 1701.41 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4900/8564 [00:02<00:02, 1809.59 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4120/8564 [00:03<00:02, 1571.90 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:09, 87.56 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 5090/8564 [00:03<00:01, 1822.88 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5517/8564 [00:03<00:01, 1714.50 examples/s]Extracting prompt in train dataset:  51%|█████     | 4360/8564 [00:03<00:02, 1532.22 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5279/8564 [00:03<00:01, 1837.01 examples/s]Tokenizing eval dataset:   9%|▉         | 90/953 [00:01<00:09, 86.53 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5773/8564 [00:03<00:01, 1694.78 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4521/8564 [00:03<00:02, 1540.38 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:01<00:10, 81.09 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 5570/8564 [00:03<00:01, 1866.43 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5955/8564 [00:03<00:01, 1674.86 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4760/8564 [00:03<00:02, 1519.84 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5760/8564 [00:03<00:01, 1833.25 examples/s]Tokenizing eval dataset:  12%|█▏        | 112/953 [00:01<00:09, 84.56 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6148/8564 [00:03<00:01, 1725.34 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4919/8564 [00:03<00:02, 1536.07 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5970/8564 [00:03<00:01, 1799.82 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6324/8564 [00:03<00:01, 1727.85 examples/s]Tokenizing eval dataset:  13%|█▎        | 124/953 [00:01<00:10, 77.92 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6160/8564 [00:03<00:01, 1811.72 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 6520/8564 [00:03<00:01, 1786.51 examples/s]Extracting prompt in train dataset:  60%|██████    | 5143/8564 [00:03<00:02, 1476.98 examples/s]Tokenizing eval dataset:  14%|█▍        | 134/953 [00:01<00:10, 80.13 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6354/8564 [00:03<00:01, 1784.97 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5316/8564 [00:03<00:02, 1532.73 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6760/8564 [00:03<00:01, 1672.68 examples/s]Tokenizing eval dataset:  15%|█▌        | 145/953 [00:01<00:09, 85.64 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 6540/8564 [00:03<00:01, 1759.23 examples/s]Extracting prompt in train dataset:  81%|████████  | 6950/8564 [00:03<00:00, 1725.67 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5560/8564 [00:03<00:01, 1518.88 examples/s]Tokenizing eval dataset:  16%|█▋        | 157/953 [00:01<00:09, 79.86 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6797/8564 [00:04<00:01, 1738.07 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5738/8564 [00:04<00:01, 1575.77 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7209/8564 [00:04<00:00, 1717.81 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5920/8564 [00:04<00:01, 1633.08 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 7039/8564 [00:04<00:00, 1659.51 examples/s]Extracting prompt in train dataset:  86%|████████▋ | 7400/8564 [00:04<00:00, 1749.31 examples/s]Tokenizing eval dataset:  18%|█▊        | 169/953 [00:02<00:10, 75.46 examples/s]Extracting prompt in train dataset:  71%|███████   | 6100/8564 [00:04<00:01, 1670.82 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 7250/8564 [00:04<00:00, 1762.61 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7630/8564 [00:04<00:00, 1666.04 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7510/8564 [00:04<00:00, 1927.52 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:02<00:11, 67.04 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6330/8564 [00:04<00:01, 1575.30 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 6530/8564 [00:04<00:01, 1619.52 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:02<00:11, 69.25 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7730/8564 [00:04<00:00, 1479.50 examples/s]Tokenizing eval dataset:  21%|██        | 198/953 [00:02<00:10, 70.81 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7920/8564 [00:04<00:00, 1306.32 examples/s]Extracting prompt in train dataset:  79%|███████▊  | 6740/8564 [00:04<00:01, 1623.71 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7910/8564 [00:04<00:00, 1539.80 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8102/8564 [00:04<00:00, 1403.29 examples/s]Extracting prompt in train dataset:  81%|████████  | 6920/8564 [00:04<00:00, 1662.84 examples/s]Tokenizing eval dataset:  22%|██▏       | 208/953 [00:02<00:10, 74.32 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8105/8564 [00:04<00:00, 1605.96 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8295/8564 [00:04<00:00, 1485.21 examples/s]Tokenizing eval dataset:  23%|██▎       | 219/953 [00:02<00:09, 77.68 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7185/8564 [00:04<00:00, 1619.57 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8280/8564 [00:04<00:00, 1609.69 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8500/8564 [00:04<00:00, 1587.35 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:02<00:06, 103.42 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7350/8564 [00:05<00:00, 1582.70 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 8540/8564 [00:05<00:00, 1849.92 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1680.53 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1676.74 examples/s]
Tokenizing eval dataset:  28%|██▊       | 263/953 [00:02<00:04, 139.91 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7520/8564 [00:05<00:00, 1584.34 examples/s]Tokenizing eval dataset:  31%|███       | 292/953 [00:03<00:03, 178.22 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7720/8564 [00:05<00:00, 1593.25 examples/s]Tokenizing eval dataset:  33%|███▎      | 312/953 [00:03<00:03, 177.52 examples/s]Tokenizing eval dataset:  35%|███▌      | 337/953 [00:03<00:03, 188.15 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7981/8564 [00:05<00:00, 1575.37 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8270/8564 [00:05<00:00, 1785.43 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:03<00:03, 174.06 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8470/8564 [00:05<00:00, 1826.64 examples/s]Tokenizing eval dataset:  40%|███▉      | 380/953 [00:03<00:03, 179.37 examples/s]Tokenizing eval dataset:  43%|████▎     | 408/953 [00:03<00:03, 175.51 examples/s]Tokenizing eval dataset:  47%|████▋     | 450/953 [00:03<00:02, 221.52 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:06<00:00, 1410.15 examples/s]
Tokenizing eval dataset:  50%|█████     | 477/953 [00:03<00:02, 231.14 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  54%|█████▍    | 516/953 [00:04<00:01, 266.45 examples/s]Tokenizing eval dataset:  59%|█████▉    | 562/953 [00:04<00:01, 313.92 examples/s]Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:04<00:00, 352.50 examples/s]Tokenizing eval dataset:  68%|██████▊   | 650/953 [00:04<00:00, 364.58 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:00<1:11:27,  2.00 examples/s]Tokenizing eval dataset:  73%|███████▎  | 692/953 [00:04<00:00, 375.87 examples/s]Applying chat template to train dataset:   2%|▏         | 200/8564 [00:00<00:18, 442.96 examples/s]Tokenizing eval dataset:  78%|███████▊  | 742/953 [00:04<00:00, 350.37 examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:00<1:46:37,  1.34 examples/s]Applying chat template to train dataset:   5%|▍         | 399/8564 [00:00<00:10, 814.28 examples/s]Applying chat template to train dataset:   1%|          | 80/8564 [00:00<01:06, 127.65 examples/s]Tokenizing eval dataset:  83%|████████▎ | 789/953 [00:04<00:00, 334.89 examples/s]Applying chat template to train dataset:   7%|▋         | 590/8564 [00:00<00:08, 913.34 examples/s]Applying chat template to train dataset:   2%|▏         | 206/8564 [00:00<00:25, 332.04 examples/s]Tokenizing eval dataset:  88%|████████▊ | 836/953 [00:04<00:00, 324.75 examples/s]Applying chat template to train dataset:   4%|▎         | 312/8564 [00:01<00:17, 480.96 examples/s]Applying chat template to train dataset:   9%|▊         | 729/8564 [00:01<00:08, 908.87 examples/s]Applying chat template to train dataset:   5%|▍         | 420/8564 [00:01<00:13, 599.21 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:05<00:00, 312.76 examples/s]Applying chat template to train dataset:  11%|█         | 903/8564 [00:01<00:07, 984.63 examples/s]Applying chat template to train dataset:   6%|▋         | 541/8564 [00:01<00:10, 745.00 examples/s]Tokenizing eval dataset:  98%|█████████▊| 930/953 [00:05<00:00, 310.79 examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:00<2:02:45,  1.16 examples/s]Applying chat template to train dataset:  12%|█▏        | 1050/8564 [00:01<00:07, 979.89 examples/s]Applying chat template to train dataset:   8%|▊         | 684/8564 [00:01<00:09, 812.47 examples/s]Applying chat template to train dataset:   1%|          | 107/8564 [00:00<00:58, 144.63 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 176.21 examples/s]
Applying chat template to train dataset:   9%|▉         | 794/8564 [00:01<00:08, 879.47 examples/s]Applying chat template to train dataset:  14%|█▍        | 1207/8564 [00:01<00:07, 926.20 examples/s]Applying chat template to train dataset:   2%|▏         | 195/8564 [00:01<00:32, 260.78 examples/s]Applying chat template to train dataset:  10%|█         | 896/8564 [00:01<00:08, 914.73 examples/s]Applying chat template to train dataset:   3%|▎         | 260/8564 [00:01<00:24, 332.49 examples/s]Applying chat template to train dataset:  16%|█▌        | 1330/8564 [00:01<00:08, 836.28 examples/s]Applying chat template to train dataset:  12%|█▏        | 1038/8564 [00:01<00:08, 880.99 examples/s]Applying chat template to train dataset:   4%|▍         | 327/8564 [00:01<00:20, 397.25 examples/s]Applying chat template to train dataset:  13%|█▎        | 1153/8564 [00:01<00:08, 908.32 examples/s]Applying chat template to train dataset:  17%|█▋        | 1449/8564 [00:01<00:08, 812.48 examples/s]Applying chat template to train dataset:   5%|▍         | 415/8564 [00:01<00:17, 468.36 examples/s]Applying chat template to train dataset:  15%|█▍        | 1257/8564 [00:02<00:07, 939.89 examples/s]Applying chat template to train dataset:   6%|▌         | 496/8564 [00:01<00:14, 546.77 examples/s]Applying chat template to train dataset:   7%|▋         | 569/8564 [00:01<00:13, 591.38 examples/s]Applying chat template to train dataset:  18%|█▊        | 1580/8564 [00:02<00:09, 715.80 examples/s]Applying chat template to train dataset:  16%|█▋        | 1411/8564 [00:02<00:07, 942.94 examples/s]Applying chat template to train dataset:  20%|█▉        | 1680/8564 [00:02<00:08, 768.19 examples/s]Applying chat template to train dataset:   8%|▊         | 659/8564 [00:01<00:14, 561.73 examples/s]Applying chat template to train dataset:  18%|█▊        | 1517/8564 [00:02<00:08, 827.84 examples/s]Applying chat template to train dataset:   9%|▉         | 770/8564 [00:01<00:11, 690.63 examples/s]Applying chat template to train dataset:  19%|█▉        | 1632/8564 [00:02<00:07, 900.10 examples/s]Applying chat template to train dataset:  21%|██        | 1802/8564 [00:02<00:09, 718.73 examples/s]Applying chat template to train dataset:  10%|█         | 860/8564 [00:02<00:10, 740.93 examples/s]Applying chat template to train dataset:  22%|██▏       | 1910/8564 [00:02<00:08, 788.80 examples/s]Applying chat template to train dataset:  21%|██        | 1760/8564 [00:02<00:08, 819.81 examples/s]Applying chat template to train dataset:  11%|█▏        | 976/8564 [00:02<00:09, 812.67 examples/s]Applying chat template to train dataset:  12%|█▏        | 1068/8564 [00:02<00:08, 839.64 examples/s]Applying chat template to train dataset:  24%|██▎       | 2026/8564 [00:02<00:08, 731.41 examples/s]Applying chat template to train dataset:  22%|██▏       | 1886/8564 [00:02<00:08, 756.73 examples/s]Applying chat template to train dataset:  14%|█▎        | 1165/8564 [00:02<00:08, 874.60 examples/s]Applying chat template to train dataset:  25%|██▍       | 2105/8564 [00:02<00:08, 728.39 examples/s]Applying chat template to train dataset:  15%|█▍        | 1260/8564 [00:02<00:08, 867.01 examples/s]Applying chat template to train dataset:  26%|██▌       | 2187/8564 [00:02<00:08, 722.71 examples/s]Applying chat template to train dataset:  23%|██▎       | 2000/8564 [00:03<00:09, 718.24 examples/s]Applying chat template to train dataset:  16%|█▌        | 1353/8564 [00:02<00:08, 883.03 examples/s]Applying chat template to train dataset:  27%|██▋       | 2270/8564 [00:03<00:08, 743.82 examples/s]Applying chat template to train dataset:  17%|█▋        | 1461/8564 [00:02<00:07, 933.45 examples/s]Applying chat template to train dataset:  25%|██▍       | 2116/8564 [00:03<00:09, 693.25 examples/s]Applying chat template to train dataset:  28%|██▊       | 2362/8564 [00:03<00:09, 688.06 examples/s]Applying chat template to train dataset:  26%|██▌       | 2236/8564 [00:03<00:07, 794.07 examples/s]Applying chat template to train dataset:  19%|█▊        | 1605/8564 [00:02<00:08, 866.51 examples/s]Applying chat template to train dataset:  29%|██▉       | 2490/8564 [00:03<00:07, 794.99 examples/s]Applying chat template to train dataset:  27%|██▋       | 2326/8564 [00:03<00:07, 814.37 examples/s]Applying chat template to train dataset:  20%|█▉        | 1698/8564 [00:02<00:07, 881.71 examples/s]Applying chat template to train dataset:  30%|███       | 2580/8564 [00:03<00:07, 819.30 examples/s]Applying chat template to train dataset:  21%|██        | 1790/8564 [00:03<00:07, 890.16 examples/s]Applying chat template to train dataset:  31%|███▏      | 2693/8564 [00:03<00:06, 888.28 examples/s]Applying chat template to train dataset:  29%|██▊       | 2446/8564 [00:03<00:08, 729.20 examples/s]Applying chat template to train dataset:  22%|██▏       | 1888/8564 [00:03<00:07, 913.06 examples/s]Applying chat template to train dataset:  30%|██▉       | 2551/8564 [00:03<00:07, 798.22 examples/s]Applying chat template to train dataset:  33%|███▎      | 2834/8564 [00:03<00:07, 775.38 examples/s]Applying chat template to train dataset:  23%|██▎       | 2001/8564 [00:03<00:08, 763.17 examples/s]Applying chat template to train dataset:  31%|███▏      | 2686/8564 [00:03<00:07, 803.39 examples/s]Applying chat template to train dataset:  34%|███▍      | 2950/8564 [00:03<00:06, 859.70 examples/s]Applying chat template to train dataset:  33%|███▎      | 2789/8564 [00:03<00:06, 854.21 examples/s]Applying chat template to train dataset:  24%|██▍       | 2091/8564 [00:03<00:09, 709.29 examples/s]Applying chat template to train dataset:  36%|███▌      | 3050/8564 [00:04<00:07, 748.48 examples/s]Applying chat template to train dataset:  34%|███▎      | 2880/8564 [00:04<00:06, 858.79 examples/s]Applying chat template to train dataset:  26%|██▌       | 2186/8564 [00:03<00:09, 676.20 examples/s]Applying chat template to train dataset:  37%|███▋      | 3153/8564 [00:04<00:06, 807.46 examples/s]Applying chat template to train dataset:  35%|███▍      | 2997/8564 [00:04<00:05, 937.90 examples/s]Applying chat template to train dataset:  38%|███▊      | 3262/8564 [00:04<00:06, 874.80 examples/s]Applying chat template to train dataset:  27%|██▋       | 2289/8564 [00:03<00:09, 650.16 examples/s]Applying chat template to train dataset:  39%|███▉      | 3364/8564 [00:04<00:05, 911.11 examples/s]Applying chat template to train dataset:  36%|███▌      | 3103/8564 [00:04<00:07, 775.76 examples/s]Applying chat template to train dataset:  38%|███▊      | 3222/8564 [00:04<00:06, 872.03 examples/s]Applying chat template to train dataset:  28%|██▊       | 2362/8564 [00:03<00:10, 602.40 examples/s]Applying chat template to train dataset:  41%|████      | 3510/8564 [00:04<00:05, 913.28 examples/s]Applying chat template to train dataset:  39%|███▉      | 3320/8564 [00:04<00:05, 880.43 examples/s]Applying chat template to train dataset:  29%|██▊       | 2450/8564 [00:04<00:09, 636.45 examples/s]Applying chat template to train dataset:  42%|████▏     | 3624/8564 [00:04<00:05, 954.72 examples/s]Applying chat template to train dataset:  40%|███▉      | 3423/8564 [00:04<00:05, 907.17 examples/s]Applying chat template to train dataset:  30%|██▉       | 2537/8564 [00:04<00:09, 620.63 examples/s]Applying chat template to train dataset:  44%|████▎     | 3730/8564 [00:04<00:05, 945.19 examples/s]Applying chat template to train dataset:  41%|████      | 3528/8564 [00:04<00:05, 942.95 examples/s]Applying chat template to train dataset:  31%|███       | 2658/8564 [00:04<00:07, 740.01 examples/s]Applying chat template to train dataset:  32%|███▏      | 2782/8564 [00:04<00:06, 855.04 examples/s]Applying chat template to train dataset:  43%|████▎     | 3650/8564 [00:04<00:05, 892.10 examples/s]Applying chat template to train dataset:  45%|████▌     | 3876/8564 [00:04<00:05, 819.15 examples/s]Applying chat template to train dataset:  46%|████▋     | 3973/8564 [00:05<00:05, 840.50 examples/s]Applying chat template to train dataset:  34%|███▎      | 2890/8564 [00:04<00:06, 856.59 examples/s]Applying chat template to train dataset:  44%|████▎     | 3743/8564 [00:05<00:06, 769.87 examples/s]Applying chat template to train dataset:  48%|████▊     | 4070/8564 [00:05<00:05, 869.31 examples/s]Applying chat template to train dataset:  35%|███▍      | 2989/8564 [00:04<00:06, 853.48 examples/s]Applying chat template to train dataset:  45%|████▍     | 3840/8564 [00:05<00:06, 720.15 examples/s]Applying chat template to train dataset:  49%|████▊     | 4164/8564 [00:05<00:04, 883.91 examples/s]Applying chat template to train dataset:  46%|████▌     | 3936/8564 [00:05<00:06, 763.20 examples/s]Applying chat template to train dataset:  50%|████▉     | 4270/8564 [00:05<00:04, 927.86 examples/s]Applying chat template to train dataset:  51%|█████     | 4370/8564 [00:05<00:04, 945.97 examples/s]Applying chat template to train dataset:  36%|███▌      | 3100/8564 [00:04<00:08, 621.01 examples/s]Applying chat template to train dataset:  47%|████▋     | 4034/8564 [00:05<00:05, 766.17 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4476/8564 [00:05<00:04, 962.31 examples/s]Applying chat template to train dataset:  38%|███▊      | 3216/8564 [00:05<00:07, 714.73 examples/s]Applying chat template to train dataset:  48%|████▊     | 4137/8564 [00:05<00:06, 678.75 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4580/8564 [00:05<00:04, 965.51 examples/s]Applying chat template to train dataset:  39%|███▊      | 3308/8564 [00:05<00:06, 758.07 examples/s]Applying chat template to train dataset:  40%|███▉      | 3420/8564 [00:05<00:06, 841.34 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4683/8564 [00:05<00:04, 945.12 examples/s]Applying chat template to train dataset:  49%|████▉     | 4220/8564 [00:05<00:06, 651.42 examples/s]Applying chat template to train dataset:  41%|████      | 3529/8564 [00:05<00:05, 883.37 examples/s]Applying chat template to train dataset:  50%|█████     | 4320/8564 [00:05<00:05, 723.69 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4810/8564 [00:05<00:04, 850.21 examples/s]Applying chat template to train dataset:  42%|████▏     | 3630/8564 [00:05<00:05, 909.01 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4430/8564 [00:06<00:05, 741.15 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4903/8564 [00:06<00:04, 864.64 examples/s]Applying chat template to train dataset:  44%|████▎     | 3735/8564 [00:05<00:05, 915.98 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4550/8564 [00:06<00:04, 824.95 examples/s]Applying chat template to train dataset:  45%|████▍     | 3839/8564 [00:05<00:04, 948.33 examples/s]Applying chat template to train dataset:  59%|█████▊    | 5014/8564 [00:06<00:04, 758.91 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4643/8564 [00:06<00:04, 850.72 examples/s]Applying chat template to train dataset:  46%|████▌     | 3944/8564 [00:05<00:04, 976.19 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4750/8564 [00:06<00:04, 906.69 examples/s]Applying chat template to train dataset:  47%|████▋     | 4048/8564 [00:05<00:04, 993.01 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5106/8564 [00:06<00:05, 655.31 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4903/8564 [00:06<00:03, 922.73 examples/s]Applying chat template to train dataset:  61%|██████    | 5206/8564 [00:06<00:04, 729.14 examples/s]Applying chat template to train dataset:  49%|████▉     | 4198/8564 [00:06<00:04, 922.87 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5315/8564 [00:06<00:04, 784.49 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5050/8564 [00:06<00:03, 939.17 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5401/8564 [00:06<00:03, 793.37 examples/s]Applying chat template to train dataset:  61%|██████    | 5199/8564 [00:06<00:03, 933.70 examples/s]Applying chat template to train dataset:  51%|█████     | 4328/8564 [00:06<00:05, 726.64 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5517/8564 [00:06<00:03, 886.68 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5300/8564 [00:06<00:03, 950.81 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4434/8564 [00:06<00:05, 794.18 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4533/8564 [00:06<00:04, 837.06 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5643/8564 [00:07<00:03, 787.16 examples/s]Applying chat template to train dataset:  64%|██████▎   | 5450/8564 [00:07<00:03, 966.64 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4631/8564 [00:06<00:04, 871.23 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5561/8564 [00:07<00:03, 1000.84 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5742/8564 [00:07<00:03, 708.33 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5670/8564 [00:07<00:02, 1021.12 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4775/8564 [00:06<00:04, 899.83 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4888/8564 [00:06<00:03, 955.51 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5858/8564 [00:07<00:03, 704.40 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5808/8564 [00:07<00:02, 948.44 examples/s] Applying chat template to train dataset:  69%|██████▉   | 5940/8564 [00:07<00:03, 707.27 examples/s]Applying chat template to train dataset:  59%|█████▊    | 5030/8564 [00:07<00:03, 949.97 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5919/8564 [00:07<00:02, 982.21 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5132/8564 [00:07<00:03, 965.41 examples/s]Applying chat template to train dataset:  70%|███████   | 6027/8564 [00:07<00:02, 1007.05 examples/s]Applying chat template to train dataset:  70%|███████   | 6035/8564 [00:07<00:03, 658.82 examples/s]Applying chat template to train dataset:  61%|██████▏   | 5247/8564 [00:07<00:03, 986.11 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6146/8564 [00:07<00:02, 1021.07 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6134/8564 [00:07<00:03, 637.20 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5354/8564 [00:07<00:03, 984.78 examples/s]Applying chat template to train dataset:  74%|███████▎  | 6299/8564 [00:07<00:02, 999.56 examples/s] Applying chat template to train dataset:  73%|███████▎  | 6210/8564 [00:07<00:03, 648.49 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5468/8564 [00:07<00:03, 1020.51 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6401/8564 [00:08<00:02, 1003.48 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5573/8564 [00:07<00:02, 1025.13 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6321/8564 [00:08<00:03, 665.59 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6560/8564 [00:08<00:02, 996.10 examples/s] Applying chat template to train dataset:  67%|██████▋   | 5718/8564 [00:07<00:02, 952.67 examples/s] Applying chat template to train dataset:  75%|███████▍  | 6416/8564 [00:08<00:03, 624.70 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6667/8564 [00:08<00:01, 995.11 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6529/8564 [00:08<00:02, 723.17 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5840/8564 [00:07<00:03, 861.84 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6771/8564 [00:08<00:02, 879.76 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5957/8564 [00:08<00:02, 915.15 examples/s]Applying chat template to train dataset:  80%|████████  | 6868/8564 [00:08<00:01, 892.15 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6620/8564 [00:08<00:02, 653.36 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6710/8564 [00:08<00:02, 706.78 examples/s]Applying chat template to train dataset:  71%|███████   | 6069/8564 [00:08<00:03, 786.17 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7023/8564 [00:08<00:01, 927.36 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6799/8564 [00:08<00:02, 749.77 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6181/8564 [00:08<00:02, 859.12 examples/s]Applying chat template to train dataset:  81%|████████  | 6918/8564 [00:08<00:01, 861.48 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7132/8564 [00:08<00:01, 789.90 examples/s]Applying chat template to train dataset:  74%|███████▎  | 6298/8564 [00:08<00:02, 887.02 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7017/8564 [00:08<00:01, 867.97 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6406/8564 [00:08<00:02, 934.11 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7228/8564 [00:09<00:01, 729.59 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7123/8564 [00:09<00:01, 909.33 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6509/8564 [00:08<00:02, 958.49 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7308/8564 [00:09<00:01, 721.56 examples/s]Applying chat template to train dataset:  85%|████████▍ | 7245/8564 [00:09<00:01, 992.82 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6610/8564 [00:08<00:02, 933.79 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7382/8564 [00:09<00:01, 953.52 examples/s]Applying chat template to train dataset:  86%|████████▋ | 7402/8564 [00:09<00:01, 666.25 examples/s]Applying chat template to train dataset:  79%|███████▊  | 6740/8564 [00:08<00:01, 1005.28 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7505/8564 [00:09<00:01, 1022.88 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6851/8564 [00:08<00:01, 997.76 examples/s] Applying chat template to train dataset:  87%|████████▋ | 7491/8564 [00:09<00:01, 636.44 examples/s]Applying chat template to train dataset:  81%|████████▏ | 6960/8564 [00:09<00:01, 1019.51 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7656/8564 [00:09<00:00, 988.79 examples/s] Applying chat template to train dataset:  88%|████████▊ | 7568/8564 [00:09<00:01, 622.89 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7070/8564 [00:09<00:01, 1040.15 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7639/8564 [00:09<00:01, 620.39 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7190/8564 [00:09<00:01, 920.08 examples/s] Applying chat template to train dataset:  91%|█████████ | 7813/8564 [00:09<00:00, 791.81 examples/s]Applying chat template to train dataset:  90%|█████████ | 7720/8564 [00:09<00:01, 612.77 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7297/8564 [00:09<00:01, 958.57 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7918/8564 [00:09<00:00, 842.38 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7408/8564 [00:09<00:01, 998.89 examples/s]Applying chat template to train dataset:  91%|█████████ | 7793/8564 [00:10<00:01, 517.81 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8034/8564 [00:10<00:00, 883.36 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7563/8564 [00:09<00:00, 1009.82 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8144/8564 [00:10<00:00, 931.56 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7873/8564 [00:10<00:01, 543.77 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7675/8564 [00:09<00:00, 1036.84 examples/s]Applying chat template to train dataset:  96%|█████████▋| 8252/8564 [00:10<00:00, 967.80 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7952/8564 [00:10<00:01, 563.27 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8360/8564 [00:10<00:00, 983.51 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8032/8564 [00:10<00:00, 582.47 examples/s]Applying chat template to train dataset:  91%|█████████ | 7802/8564 [00:09<00:00, 895.92 examples/s] Applying chat template to train dataset:  99%|█████████▉| 8465/8564 [00:10<00:00, 993.70 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7916/8564 [00:10<00:00, 953.58 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8105/8564 [00:10<00:00, 597.78 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 809.32 examples/s]
Applying chat template to train dataset:  94%|█████████▎| 8026/8564 [00:10<00:00, 973.72 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8208/8564 [00:10<00:00, 588.78 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8186/8564 [00:10<00:00, 981.54 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8276/8564 [00:10<00:00, 609.06 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8287/8564 [00:10<00:00, 987.84 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8351/8564 [00:10<00:00, 630.55 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8400/8564 [00:10<00:00, 1016.52 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8428/8564 [00:11<00:00, 655.85 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8518/8564 [00:11<00:00, 719.93 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8509/8564 [00:10<00:00, 864.61 examples/s] Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 793.26 examples/s]
Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:11<00:00, 757.96 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 19/8564 [00:00<00:48, 175.46 examples/s]Tokenizing train dataset:   0%|          | 41/8564 [00:00<01:02, 136.13 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 19/8564 [00:00<00:55, 155.36 examples/s]Tokenizing train dataset:   1%|          | 63/8564 [00:00<01:30, 93.77 examples/s] Tokenizing train dataset:   0%|          | 35/8564 [00:00<01:02, 135.74 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 20/8564 [00:00<00:54, 157.93 examples/s]Tokenizing train dataset:   1%|          | 77/8564 [00:00<01:47, 78.70 examples/s]Tokenizing train dataset:   1%|          | 54/8564 [00:00<01:23, 101.58 examples/s]Tokenizing train dataset:   0%|          | 40/8564 [00:00<01:07, 125.48 examples/s]Tokenizing train dataset:   1%|          | 70/8564 [00:00<01:14, 114.33 examples/s]Tokenizing train dataset:   1%|          | 87/8564 [00:01<01:58, 71.76 examples/s]Tokenizing train dataset:   1%|          | 56/8564 [00:00<01:17, 110.03 examples/s]Tokenizing train dataset:   1%|          | 88/8564 [00:00<01:16, 111.48 examples/s]Tokenizing train dataset:   1%|          | 96/8564 [00:01<02:03, 68.75 examples/s]Tokenizing train dataset:   1%|          | 70/8564 [00:00<01:13, 115.28 examples/s]Tokenizing train dataset:   1%|          | 101/8564 [00:00<01:23, 101.44 examples/s]Tokenizing train dataset:   1%|          | 106/8564 [00:01<02:06, 66.95 examples/s]Tokenizing train dataset:   1%|          | 82/8564 [00:00<01:16, 110.41 examples/s]Tokenizing train dataset:   1%|▏         | 113/8564 [00:01<02:15, 62.27 examples/s]Tokenizing train dataset:   1%|▏         | 116/8564 [00:01<01:24, 99.59 examples/s] Tokenizing train dataset:   1%|          | 99/8564 [00:00<01:21, 104.47 examples/s]Tokenizing train dataset:   1%|▏         | 123/8564 [00:01<02:02, 69.04 examples/s]Tokenizing train dataset:   1%|▏         | 110/8564 [00:00<01:21, 103.59 examples/s]Tokenizing train dataset:   2%|▏         | 136/8564 [00:01<01:47, 78.62 examples/s]Tokenizing train dataset:   2%|▏         | 130/8564 [00:01<01:43, 81.44 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:01<01:43, 81.07 examples/s]Tokenizing train dataset:   1%|▏         | 127/8564 [00:01<01:23, 101.39 examples/s]Tokenizing train dataset:   2%|▏         | 148/8564 [00:01<01:51, 75.80 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:01<01:21, 102.91 examples/s]Tokenizing train dataset:   2%|▏         | 160/8564 [00:02<01:42, 81.65 examples/s]Tokenizing train dataset:   2%|▏         | 150/8564 [00:01<01:51, 75.28 examples/s]Tokenizing train dataset:   2%|▏         | 153/8564 [00:01<01:19, 105.61 examples/s]Tokenizing train dataset:   2%|▏         | 160/8564 [00:01<01:47, 77.95 examples/s]Tokenizing train dataset:   2%|▏         | 170/8564 [00:02<01:52, 74.86 examples/s]Tokenizing train dataset:   2%|▏         | 167/8564 [00:01<01:25, 98.16 examples/s] Tokenizing train dataset:   2%|▏         | 170/8564 [00:01<01:59, 70.04 examples/s]Tokenizing train dataset:   2%|▏         | 183/8564 [00:02<01:48, 77.33 examples/s]Tokenizing train dataset:   2%|▏         | 181/8564 [00:01<01:28, 95.11 examples/s]Tokenizing train dataset:   2%|▏         | 180/8564 [00:02<01:50, 75.70 examples/s]Tokenizing train dataset:   2%|▏         | 195/8564 [00:02<01:55, 72.53 examples/s]Tokenizing train dataset:   2%|▏         | 190/8564 [00:02<01:44, 80.24 examples/s]Tokenizing train dataset:   2%|▏         | 195/8564 [00:01<01:24, 98.99 examples/s]Tokenizing train dataset:   2%|▏         | 201/8564 [00:02<01:39, 84.36 examples/s]Tokenizing train dataset:   2%|▏         | 207/8564 [00:01<01:24, 98.99 examples/s]Tokenizing train dataset:   2%|▏         | 208/8564 [00:02<02:00, 69.34 examples/s]Tokenizing train dataset:   2%|▏         | 214/8564 [00:02<01:30, 92.06 examples/s]Tokenizing train dataset:   3%|▎         | 220/8564 [00:02<01:22, 100.62 examples/s]Tokenizing train dataset:   3%|▎         | 218/8564 [00:02<01:53, 73.28 examples/s]Tokenizing train dataset:   3%|▎         | 227/8564 [00:02<01:24, 98.68 examples/s]Tokenizing train dataset:   3%|▎         | 235/8564 [00:02<01:19, 104.57 examples/s]Tokenizing train dataset:   3%|▎         | 229/8564 [00:02<01:47, 77.79 examples/s]Tokenizing train dataset:   3%|▎         | 239/8564 [00:02<01:23, 100.25 examples/s]Tokenizing train dataset:   3%|▎         | 250/8564 [00:02<01:26, 96.56 examples/s] Tokenizing train dataset:   3%|▎         | 251/8564 [00:02<01:29, 92.75 examples/s] Tokenizing train dataset:   3%|▎         | 243/8564 [00:03<01:48, 77.04 examples/s]Tokenizing train dataset:   3%|▎         | 263/8564 [00:02<01:22, 100.84 examples/s]Tokenizing train dataset:   3%|▎         | 254/8564 [00:03<01:47, 77.60 examples/s]Tokenizing train dataset:   3%|▎         | 267/8564 [00:02<01:35, 86.64 examples/s]Tokenizing train dataset:   3%|▎         | 280/8564 [00:02<01:15, 110.12 examples/s]Tokenizing train dataset:   3%|▎         | 263/8564 [00:03<01:58, 69.89 examples/s]Tokenizing train dataset:   3%|▎         | 277/8564 [00:02<01:36, 85.67 examples/s]Tokenizing train dataset:   3%|▎         | 293/8564 [00:03<01:16, 108.16 examples/s]Tokenizing train dataset:   3%|▎         | 275/8564 [00:03<01:49, 75.99 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:02<01:35, 86.33 examples/s]Tokenizing train dataset:   4%|▎         | 310/8564 [00:03<01:17, 106.98 examples/s]Tokenizing train dataset:   3%|▎         | 287/8564 [00:03<01:46, 77.37 examples/s]Tokenizing train dataset:   3%|▎         | 299/8564 [00:03<01:42, 80.80 examples/s]Tokenizing train dataset:   4%|▍         | 326/8564 [00:03<01:18, 105.17 examples/s]Tokenizing train dataset:   3%|▎         | 296/8564 [00:03<01:49, 75.71 examples/s]Tokenizing train dataset:   4%|▎         | 308/8564 [00:03<01:45, 78.43 examples/s]Tokenizing train dataset:   4%|▍         | 343/8564 [00:03<01:20, 102.34 examples/s]Tokenizing train dataset:   4%|▎         | 309/8564 [00:04<01:55, 71.25 examples/s]Tokenizing train dataset:   4%|▍         | 322/8564 [00:03<01:49, 74.94 examples/s]Tokenizing train dataset:   4%|▍         | 360/8564 [00:03<01:21, 101.14 examples/s]Tokenizing train dataset:   4%|▎         | 321/8564 [00:04<01:53, 72.59 examples/s]Tokenizing train dataset:   4%|▍         | 333/8564 [00:03<01:57, 70.18 examples/s]Tokenizing train dataset:   4%|▍         | 378/8564 [00:03<01:19, 102.89 examples/s]Tokenizing train dataset:   4%|▍         | 329/8564 [00:04<02:00, 68.56 examples/s]Tokenizing train dataset:   4%|▍         | 341/8564 [00:03<02:06, 64.81 examples/s]Tokenizing train dataset:   5%|▍         | 390/8564 [00:04<01:18, 104.59 examples/s]Tokenizing train dataset:   4%|▍         | 337/8564 [00:04<01:56, 70.40 examples/s]Tokenizing train dataset:   4%|▍         | 350/8564 [00:03<02:01, 67.80 examples/s]Tokenizing train dataset:   4%|▍         | 345/8564 [00:04<01:59, 69.03 examples/s]Tokenizing train dataset:   5%|▍         | 401/8564 [00:04<01:32, 88.21 examples/s] Tokenizing train dataset:   4%|▍         | 366/8564 [00:03<01:38, 83.27 examples/s]Tokenizing train dataset:   4%|▍         | 352/8564 [00:04<02:02, 67.03 examples/s]Tokenizing train dataset:   4%|▍         | 378/8564 [00:04<01:30, 90.26 examples/s]Tokenizing train dataset:   5%|▍         | 414/8564 [00:04<01:36, 84.34 examples/s]Tokenizing train dataset:   4%|▍         | 361/8564 [00:04<01:58, 69.02 examples/s]Tokenizing train dataset:   5%|▍         | 390/8564 [00:04<01:27, 93.71 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:04<02:03, 66.53 examples/s]Tokenizing train dataset:   5%|▍         | 428/8564 [00:04<01:39, 81.73 examples/s]Tokenizing train dataset:   5%|▍         | 400/8564 [00:04<01:28, 92.46 examples/s]Tokenizing train dataset:   4%|▍         | 380/8564 [00:05<01:53, 71.98 examples/s]Tokenizing train dataset:   5%|▍         | 412/8564 [00:04<01:28, 92.55 examples/s]Tokenizing train dataset:   5%|▌         | 438/8564 [00:04<01:50, 73.47 examples/s]Tokenizing train dataset:   5%|▍         | 389/8564 [00:05<01:51, 73.36 examples/s]Tokenizing train dataset:   5%|▌         | 447/8564 [00:04<01:47, 75.19 examples/s]Tokenizing train dataset:   5%|▍         | 428/8564 [00:04<01:30, 89.82 examples/s]Tokenizing train dataset:   5%|▍         | 399/8564 [00:05<01:58, 68.65 examples/s]Tokenizing train dataset:   5%|▌         | 460/8564 [00:04<01:36, 83.87 examples/s]Tokenizing train dataset:   6%|▌         | 472/8564 [00:05<01:27, 91.99 examples/s]Tokenizing train dataset:   5%|▍         | 411/8564 [00:05<02:02, 66.81 examples/s]Tokenizing train dataset:   5%|▌         | 440/8564 [00:04<01:53, 71.63 examples/s]Tokenizing train dataset:   6%|▌         | 488/8564 [00:05<01:27, 92.01 examples/s]Tokenizing train dataset:   5%|▍         | 418/8564 [00:05<02:10, 62.32 examples/s]Tokenizing train dataset:   5%|▌         | 450/8564 [00:05<02:01, 66.96 examples/s]Tokenizing train dataset:   6%|▌         | 500/8564 [00:05<01:29, 90.51 examples/s]Tokenizing train dataset:   5%|▌         | 430/8564 [00:05<01:52, 72.57 examples/s]Tokenizing train dataset:   5%|▌         | 462/8564 [00:05<01:46, 76.29 examples/s]Tokenizing train dataset:   6%|▌         | 510/8564 [00:05<01:28, 90.98 examples/s]Tokenizing train dataset:   6%|▌         | 476/8564 [00:05<01:34, 85.59 examples/s]Tokenizing train dataset:   5%|▌         | 441/8564 [00:06<02:05, 64.50 examples/s]Tokenizing train dataset:   6%|▌         | 525/8564 [00:05<01:30, 89.13 examples/s]Tokenizing train dataset:   6%|▌         | 487/8564 [00:05<01:32, 87.18 examples/s]Tokenizing train dataset:   5%|▌         | 450/8564 [00:06<02:07, 63.53 examples/s]Tokenizing train dataset:   6%|▋         | 540/8564 [00:05<01:19, 100.73 examples/s]Tokenizing train dataset:   6%|▌         | 500/8564 [00:05<01:25, 94.51 examples/s]Tokenizing train dataset:   5%|▌         | 461/8564 [00:06<01:59, 67.88 examples/s]Tokenizing train dataset:   6%|▋         | 555/8564 [00:05<01:22, 96.90 examples/s] Tokenizing train dataset:   6%|▌         | 511/8564 [00:05<01:41, 79.11 examples/s]Tokenizing train dataset:   6%|▌         | 473/8564 [00:06<01:52, 72.11 examples/s]Tokenizing train dataset:   7%|▋         | 566/8564 [00:06<01:21, 98.65 examples/s]Tokenizing train dataset:   6%|▌         | 523/8564 [00:05<01:40, 80.38 examples/s]Tokenizing train dataset:   7%|▋         | 578/8564 [00:06<01:20, 99.00 examples/s]Tokenizing train dataset:   6%|▌         | 481/8564 [00:06<02:17, 58.98 examples/s]Tokenizing train dataset:   6%|▌         | 534/8564 [00:06<01:42, 78.16 examples/s]Tokenizing train dataset:   7%|▋         | 590/8564 [00:06<01:22, 96.78 examples/s]Tokenizing train dataset:   6%|▌         | 491/8564 [00:06<02:05, 64.19 examples/s]Tokenizing train dataset:   6%|▋         | 544/8564 [00:06<01:43, 77.27 examples/s]Tokenizing train dataset:   7%|▋         | 605/8564 [00:06<01:26, 92.53 examples/s]Tokenizing train dataset:   6%|▌         | 503/8564 [00:06<02:03, 65.19 examples/s]Tokenizing train dataset:   6%|▋         | 553/8564 [00:06<01:51, 71.79 examples/s]Tokenizing train dataset:   7%|▋         | 618/8564 [00:06<01:18, 100.87 examples/s]Tokenizing train dataset:   7%|▋         | 562/8564 [00:06<01:48, 74.06 examples/s]Tokenizing train dataset:   6%|▌         | 511/8564 [00:07<02:06, 63.79 examples/s]Tokenizing train dataset:   7%|▋         | 636/8564 [00:06<01:08, 115.55 examples/s]Tokenizing train dataset:   7%|▋         | 570/8564 [00:06<01:56, 68.89 examples/s]Tokenizing train dataset:   6%|▌         | 523/8564 [00:07<02:00, 66.85 examples/s]Tokenizing train dataset:   8%|▊         | 654/8564 [00:06<01:10, 112.03 examples/s]Tokenizing train dataset:   6%|▌         | 534/8564 [00:07<01:54, 70.16 examples/s]Tokenizing train dataset:   7%|▋         | 579/8564 [00:06<02:11, 60.91 examples/s]Tokenizing train dataset:   8%|▊         | 669/8564 [00:07<01:19, 98.86 examples/s] Tokenizing train dataset:   6%|▋         | 547/8564 [00:07<01:42, 78.57 examples/s]Tokenizing train dataset:   7%|▋         | 592/8564 [00:06<01:48, 73.31 examples/s]Tokenizing train dataset:   8%|▊         | 680/8564 [00:07<01:21, 96.38 examples/s]Tokenizing train dataset:   7%|▋         | 558/8564 [00:07<01:35, 83.82 examples/s]Tokenizing train dataset:   7%|▋         | 601/8564 [00:07<02:00, 65.87 examples/s]Tokenizing train dataset:   8%|▊         | 692/8564 [00:07<01:29, 88.40 examples/s]Tokenizing train dataset:   7%|▋         | 568/8564 [00:07<01:39, 80.72 examples/s]Tokenizing train dataset:   7%|▋         | 578/8564 [00:07<01:33, 85.24 examples/s]Tokenizing train dataset:   7%|▋         | 614/8564 [00:07<02:04, 63.89 examples/s]Tokenizing train dataset:   8%|▊         | 704/8564 [00:07<01:36, 81.56 examples/s]Tokenizing train dataset:   7%|▋         | 590/8564 [00:08<01:34, 84.64 examples/s]Tokenizing train dataset:   7%|▋         | 628/8564 [00:07<01:41, 78.25 examples/s]Tokenizing train dataset:   8%|▊         | 716/8564 [00:07<01:39, 78.74 examples/s]Tokenizing train dataset:   7%|▋         | 600/8564 [00:08<01:33, 85.01 examples/s]Tokenizing train dataset:   7%|▋         | 639/8564 [00:07<01:33, 84.57 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:07<01:28, 88.98 examples/s]Tokenizing train dataset:   8%|▊         | 650/8564 [00:07<01:34, 83.80 examples/s]Tokenizing train dataset:   7%|▋         | 613/8564 [00:08<01:40, 79.30 examples/s]Tokenizing train dataset:   9%|▊         | 739/8564 [00:07<01:29, 87.09 examples/s]Tokenizing train dataset:   8%|▊         | 661/8564 [00:07<01:29, 88.05 examples/s]Tokenizing train dataset:   7%|▋         | 624/8564 [00:08<01:38, 80.25 examples/s]Tokenizing train dataset:   8%|▊         | 671/8564 [00:07<01:30, 87.25 examples/s]Tokenizing train dataset:   9%|▉         | 751/8564 [00:08<01:38, 79.34 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:08<01:35, 83.40 examples/s]Tokenizing train dataset:   8%|▊         | 685/8564 [00:07<01:21, 96.14 examples/s]Tokenizing train dataset:   9%|▉         | 761/8564 [00:08<01:50, 70.91 examples/s]Tokenizing train dataset:   8%|▊         | 645/8564 [00:08<01:45, 75.27 examples/s]Tokenizing train dataset:   8%|▊         | 698/8564 [00:08<01:29, 88.06 examples/s]Tokenizing train dataset:   9%|▉         | 769/8564 [00:08<01:50, 70.24 examples/s]Tokenizing train dataset:   8%|▊         | 655/8564 [00:08<01:40, 78.61 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:08<01:29, 88.06 examples/s]Tokenizing train dataset:   8%|▊         | 722/8564 [00:08<01:18, 99.86 examples/s]Tokenizing train dataset:   9%|▉         | 780/8564 [00:08<02:03, 63.16 examples/s]Tokenizing train dataset:   8%|▊         | 666/8564 [00:09<01:53, 69.70 examples/s]Tokenizing train dataset:   9%|▊         | 738/8564 [00:08<01:10, 110.79 examples/s]Tokenizing train dataset:   9%|▉         | 789/8564 [00:08<02:06, 61.71 examples/s]Tokenizing train dataset:   8%|▊         | 674/8564 [00:09<02:02, 64.23 examples/s]Tokenizing train dataset:   9%|▉         | 750/8564 [00:08<01:10, 110.46 examples/s]Tokenizing train dataset:   8%|▊         | 685/8564 [00:09<01:56, 67.63 examples/s]Tokenizing train dataset:   9%|▉         | 762/8564 [00:08<01:14, 104.21 examples/s]Tokenizing train dataset:   9%|▉         | 800/8564 [00:08<02:12, 58.53 examples/s]Tokenizing train dataset:   8%|▊         | 693/8564 [00:09<01:55, 68.20 examples/s]Tokenizing train dataset:   9%|▉         | 812/8564 [00:09<01:55, 66.95 examples/s]Tokenizing train dataset:   9%|▉         | 773/8564 [00:08<01:31, 84.77 examples/s] Tokenizing train dataset:   8%|▊         | 701/8564 [00:09<02:00, 65.34 examples/s]Tokenizing train dataset:   9%|▉         | 784/8564 [00:08<01:27, 88.44 examples/s]Tokenizing train dataset:  10%|▉         | 823/8564 [00:09<01:54, 67.48 examples/s]Tokenizing train dataset:   8%|▊         | 713/8564 [00:09<01:42, 76.58 examples/s]Tokenizing train dataset:  10%|▉         | 833/8564 [00:09<01:49, 70.83 examples/s]Tokenizing train dataset:   9%|▊         | 730/8564 [00:09<01:19, 98.66 examples/s]Tokenizing train dataset:   9%|▉         | 798/8564 [00:09<01:45, 73.44 examples/s]Tokenizing train dataset:   9%|▊         | 742/8564 [00:09<01:17, 100.99 examples/s]Tokenizing train dataset:  10%|▉         | 847/8564 [00:09<01:34, 81.28 examples/s]Tokenizing train dataset:   9%|▉         | 755/8564 [00:10<01:16, 102.51 examples/s]Tokenizing train dataset:  10%|█         | 860/8564 [00:09<01:29, 86.38 examples/s]Tokenizing train dataset:   9%|▉         | 810/8564 [00:09<01:49, 70.98 examples/s]Tokenizing train dataset:   9%|▉         | 766/8564 [00:10<01:15, 102.79 examples/s]Tokenizing train dataset:  10%|█         | 870/8564 [00:09<01:29, 85.85 examples/s]Tokenizing train dataset:  10%|▉         | 818/8564 [00:09<01:53, 68.13 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:09<01:19, 97.07 examples/s]Tokenizing train dataset:   9%|▉         | 782/8564 [00:10<01:22, 94.78 examples/s] Tokenizing train dataset:  11%|█         | 902/8564 [00:10<01:08, 111.48 examples/s]Tokenizing train dataset:  10%|▉         | 826/8564 [00:09<02:12, 58.52 examples/s]Tokenizing train dataset:   9%|▉         | 792/8564 [00:10<01:25, 90.61 examples/s]Tokenizing train dataset:  10%|▉         | 834/8564 [00:09<02:08, 59.95 examples/s]Tokenizing train dataset:   9%|▉         | 802/8564 [00:10<01:24, 91.98 examples/s]Tokenizing train dataset:  11%|█         | 917/8564 [00:10<01:14, 102.57 examples/s]Tokenizing train dataset:   9%|▉         | 813/8564 [00:10<01:23, 93.07 examples/s]Tokenizing train dataset:  10%|▉         | 843/8564 [00:10<02:04, 62.21 examples/s]Tokenizing train dataset:  11%|█         | 929/8564 [00:10<01:16, 99.29 examples/s] Tokenizing train dataset:  10%|▉         | 850/8564 [00:10<02:05, 61.52 examples/s]Tokenizing train dataset:  10%|▉         | 825/8564 [00:10<01:25, 90.87 examples/s]Tokenizing train dataset:  11%|█         | 945/8564 [00:10<01:16, 99.94 examples/s]Tokenizing train dataset:  10%|▉         | 839/8564 [00:10<01:15, 101.66 examples/s]Tokenizing train dataset:  10%|█         | 860/8564 [00:10<01:58, 65.04 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:11<01:19, 96.97 examples/s] Tokenizing train dataset:  10%|█         | 872/8564 [00:10<01:42, 75.13 examples/s]Tokenizing train dataset:  11%|█         | 958/8564 [00:10<01:30, 83.93 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:10<01:30, 85.05 examples/s]Tokenizing train dataset:  10%|█         | 860/8564 [00:11<01:24, 90.96 examples/s]Tokenizing train dataset:  11%|█▏        | 970/8564 [00:10<01:28, 85.35 examples/s]Tokenizing train dataset:  11%|█         | 902/8564 [00:10<01:12, 105.31 examples/s]Tokenizing train dataset:  11%|█▏        | 979/8564 [00:10<01:41, 74.94 examples/s]Tokenizing train dataset:  10%|█         | 872/8564 [00:11<01:41, 75.43 examples/s]Tokenizing train dataset:  11%|█         | 917/8564 [00:10<01:17, 98.33 examples/s] Tokenizing train dataset:  11%|█         | 930/8564 [00:10<01:15, 100.60 examples/s]Tokenizing train dataset:  12%|█▏        | 990/8564 [00:11<01:50, 68.59 examples/s]Tokenizing train dataset:  10%|█         | 890/8564 [00:11<01:37, 78.93 examples/s]Tokenizing train dataset:  11%|█         | 906/8564 [00:11<01:24, 90.48 examples/s]Tokenizing train dataset:  11%|█         | 945/8564 [00:11<01:20, 94.38 examples/s] Tokenizing train dataset:  12%|█▏        | 998/8564 [00:11<02:06, 59.77 examples/s]Tokenizing train dataset:  11%|█         | 955/8564 [00:11<01:25, 88.85 examples/s]Tokenizing train dataset:  12%|█▏        | 1010/8564 [00:11<01:50, 68.58 examples/s]Tokenizing train dataset:  11%|█         | 919/8564 [00:11<01:28, 86.34 examples/s]Tokenizing train dataset:  11%|█▏        | 965/8564 [00:11<01:27, 87.15 examples/s]Tokenizing train dataset:  12%|█▏        | 1020/8564 [00:11<01:44, 72.50 examples/s]Tokenizing train dataset:  11%|█         | 931/8564 [00:12<01:25, 89.51 examples/s]Tokenizing train dataset:  11%|█         | 942/8564 [00:12<01:21, 93.06 examples/s]Tokenizing train dataset:  12%|█▏        | 1030/8564 [00:11<01:41, 74.35 examples/s]Tokenizing train dataset:  11%|█▏        | 975/8564 [00:11<01:43, 73.03 examples/s]Tokenizing train dataset:  12%|█▏        | 1040/8564 [00:11<01:34, 79.70 examples/s]Tokenizing train dataset:  11%|█         | 955/8564 [00:12<01:29, 85.01 examples/s]Tokenizing train dataset:  12%|█▏        | 985/8564 [00:11<01:44, 72.64 examples/s]Tokenizing train dataset:  12%|█▏        | 1052/8564 [00:11<01:26, 87.10 examples/s]Tokenizing train dataset:  11%|█▏        | 968/8564 [00:12<01:20, 93.96 examples/s]Tokenizing train dataset:  12%|█▏        | 1063/8564 [00:12<01:21, 92.06 examples/s]Tokenizing train dataset:  12%|█▏        | 994/8564 [00:11<01:42, 73.76 examples/s]Tokenizing train dataset:  11%|█▏        | 979/8564 [00:12<01:28, 85.49 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:12<01:26, 86.97 examples/s]Tokenizing train dataset:  12%|█▏        | 1002/8564 [00:11<01:57, 64.45 examples/s]Tokenizing train dataset:  13%|█▎        | 1087/8564 [00:12<01:19, 94.16 examples/s]Tokenizing train dataset:  12%|█▏        | 1012/8564 [00:12<01:46, 70.96 examples/s]Tokenizing train dataset:  12%|█▏        | 994/8564 [00:12<01:30, 83.91 examples/s]Tokenizing train dataset:  12%|█▏        | 1003/8564 [00:12<01:31, 82.46 examples/s]Tokenizing train dataset:  13%|█▎        | 1103/8564 [00:12<01:20, 92.50 examples/s]Tokenizing train dataset:  12%|█▏        | 1022/8564 [00:12<01:55, 65.50 examples/s]Tokenizing train dataset:  12%|█▏        | 1014/8564 [00:12<01:25, 88.30 examples/s]Tokenizing train dataset:  12%|█▏        | 1030/8564 [00:12<01:51, 67.27 examples/s]Tokenizing train dataset:  13%|█▎        | 1117/8564 [00:12<01:28, 84.24 examples/s]Tokenizing train dataset:  12%|█▏        | 1040/8564 [00:12<01:43, 72.99 examples/s]Tokenizing train dataset:  12%|█▏        | 1026/8564 [00:13<01:32, 81.60 examples/s]Tokenizing train dataset:  13%|█▎        | 1126/8564 [00:12<01:33, 79.60 examples/s]Tokenizing train dataset:  12%|█▏        | 1050/8564 [00:12<01:38, 76.55 examples/s]Tokenizing train dataset:  12%|█▏        | 1037/8564 [00:13<01:35, 78.97 examples/s]Tokenizing train dataset:  12%|█▏        | 1063/8564 [00:12<01:23, 89.48 examples/s]Tokenizing train dataset:  13%|█▎        | 1140/8564 [00:13<01:40, 73.85 examples/s]Tokenizing train dataset:  12%|█▏        | 1046/8564 [00:13<01:41, 73.99 examples/s]Tokenizing train dataset:  13%|█▎        | 1074/8564 [00:12<01:19, 94.51 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:13<01:34, 78.51 examples/s]Tokenizing train dataset:  12%|█▏        | 1054/8564 [00:13<01:48, 69.34 examples/s]Tokenizing train dataset:  13%|█▎        | 1090/8564 [00:12<01:14, 100.42 examples/s]Tokenizing train dataset:  12%|█▏        | 1064/8564 [00:13<01:39, 75.34 examples/s]Tokenizing train dataset:  14%|█▎        | 1161/8564 [00:13<01:36, 76.97 examples/s]Tokenizing train dataset:  13%|█▎        | 1104/8564 [00:13<01:19, 93.56 examples/s] Tokenizing train dataset:  13%|█▎        | 1079/8564 [00:13<01:26, 86.79 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:13<01:43, 71.46 examples/s]Tokenizing train dataset:  13%|█▎        | 1114/8564 [00:13<01:24, 88.20 examples/s]Tokenizing train dataset:  13%|█▎        | 1092/8564 [00:13<01:20, 92.58 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:13<01:41, 72.53 examples/s]Tokenizing train dataset:  14%|█▍        | 1190/8564 [00:13<01:28, 83.17 examples/s]Tokenizing train dataset:  13%|█▎        | 1103/8564 [00:14<01:20, 93.13 examples/s]Tokenizing train dataset:  13%|█▎        | 1125/8564 [00:13<01:35, 78.06 examples/s]Tokenizing train dataset:  13%|█▎        | 1113/8564 [00:14<01:18, 94.61 examples/s]Tokenizing train dataset:  14%|█▍        | 1202/8564 [00:13<01:25, 86.23 examples/s]Tokenizing train dataset:  13%|█▎        | 1134/8564 [00:13<01:45, 70.19 examples/s]Tokenizing train dataset:  14%|█▍        | 1213/8564 [00:13<01:20, 90.90 examples/s]Tokenizing train dataset:  13%|█▎        | 1142/8564 [00:13<01:46, 69.42 examples/s]Tokenizing train dataset:  14%|█▍        | 1225/8564 [00:14<01:17, 94.39 examples/s]Tokenizing train dataset:  13%|█▎        | 1126/8564 [00:14<01:40, 73.66 examples/s]Tokenizing train dataset:  14%|█▍        | 1240/8564 [00:14<01:09, 104.71 examples/s]Tokenizing train dataset:  13%|█▎        | 1152/8564 [00:13<01:54, 65.02 examples/s]Tokenizing train dataset:  13%|█▎        | 1137/8564 [00:14<01:47, 69.22 examples/s]Tokenizing train dataset:  15%|█▍        | 1252/8564 [00:14<01:10, 103.10 examples/s]Tokenizing train dataset:  14%|█▎        | 1161/8564 [00:14<01:57, 63.24 examples/s]Tokenizing train dataset:  13%|█▎        | 1145/8564 [00:14<01:48, 68.32 examples/s]Tokenizing train dataset:  15%|█▍        | 1265/8564 [00:14<01:09, 105.74 examples/s]Tokenizing train dataset:  13%|█▎        | 1156/8564 [00:14<01:47, 68.60 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:14<02:06, 58.55 examples/s]Tokenizing train dataset:  15%|█▍        | 1280/8564 [00:14<01:13, 98.72 examples/s] Tokenizing train dataset:  14%|█▍        | 1183/8564 [00:14<01:43, 71.15 examples/s]Tokenizing train dataset:  14%|█▎        | 1164/8564 [00:15<01:49, 67.59 examples/s]Tokenizing train dataset:  15%|█▌        | 1291/8564 [00:14<01:13, 99.17 examples/s]Tokenizing train dataset:  14%|█▍        | 1198/8564 [00:14<01:23, 87.97 examples/s]Tokenizing train dataset:  14%|█▎        | 1171/8564 [00:15<01:52, 65.64 examples/s]Tokenizing train dataset:  15%|█▌        | 1302/8564 [00:14<01:24, 85.98 examples/s]Tokenizing train dataset:  14%|█▍        | 1183/8564 [00:15<01:36, 76.36 examples/s]Tokenizing train dataset:  14%|█▍        | 1209/8564 [00:14<01:27, 83.89 examples/s]Tokenizing train dataset:  14%|█▍        | 1199/8564 [00:15<01:19, 93.20 examples/s]Tokenizing train dataset:  15%|█▌        | 1313/8564 [00:14<01:26, 83.75 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:14<01:34, 77.55 examples/s]Tokenizing train dataset:  15%|█▌        | 1323/8564 [00:15<01:25, 84.95 examples/s]Tokenizing train dataset:  14%|█▍        | 1227/8564 [00:14<01:36, 76.35 examples/s]Tokenizing train dataset:  14%|█▍        | 1211/8564 [00:15<01:34, 78.09 examples/s]Tokenizing train dataset:  16%|█▌        | 1334/8564 [00:15<01:19, 90.40 examples/s]Tokenizing train dataset:  14%|█▍        | 1238/8564 [00:14<01:32, 78.96 examples/s]Tokenizing train dataset:  14%|█▍        | 1223/8564 [00:15<01:27, 84.11 examples/s]Tokenizing train dataset:  16%|█▌        | 1346/8564 [00:15<01:17, 93.14 examples/s]Tokenizing train dataset:  15%|█▍        | 1248/8564 [00:15<01:33, 78.37 examples/s]Tokenizing train dataset:  14%|█▍        | 1237/8564 [00:15<01:15, 96.68 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:15<01:23, 86.47 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:15<01:12, 101.13 examples/s]Tokenizing train dataset:  15%|█▍        | 1257/8564 [00:15<01:50, 66.37 examples/s]Tokenizing train dataset:  16%|█▌        | 1371/8564 [00:15<01:22, 87.28 examples/s]Tokenizing train dataset:  15%|█▍        | 1262/8564 [00:16<01:09, 105.16 examples/s]Tokenizing train dataset:  15%|█▍        | 1273/8564 [00:16<01:13, 99.29 examples/s] Tokenizing train dataset:  16%|█▌        | 1382/8564 [00:15<01:23, 86.08 examples/s]Tokenizing train dataset:  15%|█▍        | 1270/8564 [00:15<01:49, 66.40 examples/s]Tokenizing train dataset:  15%|█▍        | 1280/8564 [00:15<01:45, 69.18 examples/s]Tokenizing train dataset:  15%|█▌        | 1288/8564 [00:16<01:16, 94.88 examples/s]Tokenizing train dataset:  16%|█▋        | 1394/8564 [00:15<01:33, 76.41 examples/s]Tokenizing train dataset:  15%|█▌        | 1288/8564 [00:15<01:45, 68.93 examples/s]Tokenizing train dataset:  15%|█▌        | 1308/8564 [00:16<01:04, 111.84 examples/s]Tokenizing train dataset:  16%|█▋        | 1403/8564 [00:16<01:37, 73.74 examples/s]Tokenizing train dataset:  15%|█▌        | 1303/8564 [00:15<01:23, 86.99 examples/s]Tokenizing train dataset:  15%|█▌        | 1321/8564 [00:16<01:14, 96.72 examples/s] Tokenizing train dataset:  17%|█▋        | 1414/8564 [00:16<01:40, 71.14 examples/s]Tokenizing train dataset:  15%|█▌        | 1314/8564 [00:15<01:21, 89.03 examples/s]Tokenizing train dataset:  15%|█▌        | 1327/8564 [00:16<01:16, 94.37 examples/s]Tokenizing train dataset:  17%|█▋        | 1422/8564 [00:16<01:43, 68.71 examples/s]Tokenizing train dataset:  16%|█▌        | 1334/8564 [00:16<01:22, 87.51 examples/s]Tokenizing train dataset:  16%|█▌        | 1339/8564 [00:16<01:15, 95.79 examples/s]Tokenizing train dataset:  17%|█▋        | 1430/8564 [00:16<01:45, 67.39 examples/s]Tokenizing train dataset:  16%|█▌        | 1344/8564 [00:16<01:25, 84.45 examples/s]Tokenizing train dataset:  17%|█▋        | 1437/8564 [00:16<01:50, 64.45 examples/s]Tokenizing train dataset:  16%|█▌        | 1354/8564 [00:16<01:17, 93.14 examples/s]Tokenizing train dataset:  16%|█▌        | 1354/8564 [00:17<01:39, 72.38 examples/s]Tokenizing train dataset:  16%|█▌        | 1365/8564 [00:16<01:20, 88.98 examples/s]Tokenizing train dataset:  17%|█▋        | 1449/8564 [00:16<01:56, 60.86 examples/s]Tokenizing train dataset:  16%|█▌        | 1364/8564 [00:17<01:35, 75.50 examples/s]Tokenizing train dataset:  17%|█▋        | 1457/8564 [00:16<01:54, 61.86 examples/s]Tokenizing train dataset:  16%|█▌        | 1373/8564 [00:17<01:33, 77.17 examples/s]Tokenizing train dataset:  16%|█▌        | 1376/8564 [00:16<01:35, 75.19 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:17<01:24, 84.68 examples/s]Tokenizing train dataset:  17%|█▋        | 1466/8564 [00:17<01:51, 63.81 examples/s]Tokenizing train dataset:  16%|█▌        | 1387/8564 [00:16<01:33, 77.11 examples/s]Tokenizing train dataset:  17%|█▋        | 1473/8564 [00:17<01:49, 64.55 examples/s]Tokenizing train dataset:  16%|█▋        | 1399/8564 [00:17<01:18, 91.31 examples/s]Tokenizing train dataset:  17%|█▋        | 1482/8564 [00:17<01:41, 70.00 examples/s]Tokenizing train dataset:  16%|█▋        | 1398/8564 [00:17<01:38, 72.77 examples/s]Tokenizing train dataset:  17%|█▋        | 1415/8564 [00:17<01:21, 88.12 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:17<01:38, 72.45 examples/s]Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:17<01:52, 62.99 examples/s]Tokenizing train dataset:  17%|█▋        | 1426/8564 [00:17<01:18, 90.74 examples/s]Tokenizing train dataset:  17%|█▋        | 1416/8564 [00:17<01:36, 74.30 examples/s]Tokenizing train dataset:  17%|█▋        | 1497/8564 [00:17<01:52, 62.82 examples/s]Tokenizing train dataset:  17%|█▋        | 1436/8564 [00:18<01:18, 91.21 examples/s]Tokenizing train dataset:  17%|█▋        | 1426/8564 [00:17<01:41, 70.03 examples/s]Tokenizing train dataset:  18%|█▊        | 1506/8564 [00:17<01:56, 60.41 examples/s]Tokenizing train dataset:  17%|█▋        | 1446/8564 [00:18<01:24, 84.44 examples/s]Tokenizing train dataset:  17%|█▋        | 1434/8564 [00:17<01:43, 68.93 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:17<01:45, 66.77 examples/s]Tokenizing train dataset:  17%|█▋        | 1457/8564 [00:18<01:21, 86.69 examples/s]Tokenizing train dataset:  18%|█▊        | 1531/8564 [00:17<01:24, 82.82 examples/s]Tokenizing train dataset:  17%|█▋        | 1470/8564 [00:18<01:16, 92.21 examples/s]Tokenizing train dataset:  17%|█▋        | 1446/8564 [00:17<01:47, 66.11 examples/s]Tokenizing train dataset:  18%|█▊        | 1542/8564 [00:18<01:22, 85.27 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:18<01:16, 92.39 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:17<02:01, 58.47 examples/s]Tokenizing train dataset:  18%|█▊        | 1551/8564 [00:18<01:23, 84.09 examples/s]Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:18<01:21, 87.24 examples/s]Tokenizing train dataset:  17%|█▋        | 1462/8564 [00:18<01:51, 63.87 examples/s]Tokenizing train dataset:  18%|█▊        | 1562/8564 [00:18<01:17, 90.10 examples/s]Tokenizing train dataset:  18%|█▊        | 1500/8564 [00:18<01:26, 81.46 examples/s]Tokenizing train dataset:  17%|█▋        | 1474/8564 [00:18<01:36, 73.29 examples/s]Tokenizing train dataset:  18%|█▊        | 1573/8564 [00:18<01:17, 90.41 examples/s]Tokenizing train dataset:  17%|█▋        | 1483/8564 [00:18<01:32, 76.23 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:18<01:12, 96.19 examples/s]Tokenizing train dataset:  18%|█▊        | 1510/8564 [00:19<01:47, 65.66 examples/s]Tokenizing train dataset:  17%|█▋        | 1491/8564 [00:18<01:46, 66.59 examples/s]Tokenizing train dataset:  19%|█▉        | 1612/8564 [00:18<01:00, 115.56 examples/s]Tokenizing train dataset:  18%|█▊        | 1499/8564 [00:18<01:49, 64.50 examples/s]Tokenizing train dataset:  18%|█▊        | 1520/8564 [00:19<02:00, 58.50 examples/s]Tokenizing train dataset:  19%|█▉        | 1632/8564 [00:18<00:51, 134.44 examples/s]Tokenizing train dataset:  18%|█▊        | 1531/8564 [00:19<01:46, 65.86 examples/s]Tokenizing train dataset:  19%|█▉        | 1652/8564 [00:18<00:51, 133.40 examples/s]Tokenizing train dataset:  18%|█▊        | 1506/8564 [00:18<02:07, 55.38 examples/s]Tokenizing train dataset:  18%|█▊        | 1541/8564 [00:19<01:43, 67.84 examples/s]Tokenizing train dataset:  18%|█▊        | 1514/8564 [00:18<01:57, 60.19 examples/s]Tokenizing train dataset:  19%|█▉        | 1669/8564 [00:19<00:57, 120.77 examples/s]Tokenizing train dataset:  18%|█▊        | 1521/8564 [00:18<01:55, 60.72 examples/s]Tokenizing train dataset:  18%|█▊        | 1551/8564 [00:19<01:48, 64.64 examples/s]Tokenizing train dataset:  20%|█▉        | 1683/8564 [00:19<00:57, 120.26 examples/s]Tokenizing train dataset:  18%|█▊        | 1531/8564 [00:19<01:47, 65.50 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:19<00:52, 129.63 examples/s]Tokenizing train dataset:  18%|█▊        | 1560/8564 [00:19<01:45, 66.30 examples/s]Tokenizing train dataset:  18%|█▊        | 1539/8564 [00:19<01:48, 64.53 examples/s]Tokenizing train dataset:  18%|█▊        | 1568/8564 [00:19<01:45, 66.63 examples/s]Tokenizing train dataset:  20%|██        | 1715/8564 [00:19<00:53, 127.17 examples/s]Tokenizing train dataset:  18%|█▊        | 1548/8564 [00:19<01:47, 65.28 examples/s]Tokenizing train dataset:  18%|█▊        | 1578/8564 [00:20<01:47, 65.06 examples/s]Tokenizing train dataset:  20%|██        | 1730/8564 [00:19<01:00, 112.43 examples/s]Tokenizing train dataset:  18%|█▊        | 1557/8564 [00:19<01:48, 64.49 examples/s]Tokenizing train dataset:  19%|█▊        | 1585/8564 [00:20<01:51, 62.68 examples/s]Tokenizing train dataset:  20%|██        | 1742/8564 [00:19<01:02, 109.26 examples/s]Tokenizing train dataset:  18%|█▊        | 1566/8564 [00:19<01:46, 65.75 examples/s]Tokenizing train dataset:  21%|██        | 1759/8564 [00:19<00:58, 116.95 examples/s]Tokenizing train dataset:  19%|█▊        | 1597/8564 [00:20<01:49, 63.59 examples/s]Tokenizing train dataset:  21%|██        | 1772/8564 [00:20<00:59, 114.16 examples/s]Tokenizing train dataset:  18%|█▊        | 1575/8564 [00:19<01:53, 61.41 examples/s]Tokenizing train dataset:  19%|█▊        | 1605/8564 [00:20<01:47, 64.83 examples/s]Tokenizing train dataset:  18%|█▊        | 1583/8564 [00:19<01:57, 59.52 examples/s]Tokenizing train dataset:  21%|██        | 1788/8564 [00:20<01:03, 105.92 examples/s]Tokenizing train dataset:  19%|█▉        | 1614/8564 [00:20<01:45, 66.03 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:20<01:55, 60.54 examples/s]Tokenizing train dataset:  21%|██        | 1799/8564 [00:20<01:05, 103.14 examples/s]Tokenizing train dataset:  19%|█▉        | 1624/8564 [00:20<01:40, 69.17 examples/s]Tokenizing train dataset:  21%|██        | 1810/8564 [00:20<01:05, 103.60 examples/s]Tokenizing train dataset:  19%|█▊        | 1599/8564 [00:20<01:55, 60.07 examples/s]Tokenizing train dataset:  19%|█▉        | 1632/8564 [00:20<01:42, 67.52 examples/s]Tokenizing train dataset:  21%|██▏       | 1821/8564 [00:20<01:07, 100.02 examples/s]Tokenizing train dataset:  19%|█▉        | 1641/8564 [00:20<01:36, 71.44 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:20<01:50, 62.73 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:20<01:05, 103.42 examples/s]Tokenizing train dataset:  19%|█▉        | 1623/8564 [00:20<01:29, 77.26 examples/s]Tokenizing train dataset:  19%|█▉        | 1652/8564 [00:21<01:36, 71.47 examples/s]Tokenizing train dataset:  22%|██▏       | 1848/8564 [00:20<01:02, 107.49 examples/s]Tokenizing train dataset:  19%|█▉        | 1632/8564 [00:20<01:27, 79.36 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:21<01:32, 74.57 examples/s]Tokenizing train dataset:  20%|█▉        | 1673/8564 [00:21<01:25, 81.06 examples/s]Tokenizing train dataset:  22%|██▏       | 1863/8564 [00:21<01:14, 90.42 examples/s] Tokenizing train dataset:  19%|█▉        | 1644/8564 [00:20<01:34, 73.37 examples/s]Tokenizing train dataset:  19%|█▉        | 1654/8564 [00:20<01:34, 73.27 examples/s]Tokenizing train dataset:  20%|█▉        | 1685/8564 [00:21<01:34, 72.86 examples/s]Tokenizing train dataset:  22%|██▏       | 1875/8564 [00:21<01:22, 80.60 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:21<01:11, 96.17 examples/s]Tokenizing train dataset:  19%|█▉        | 1667/8564 [00:20<01:24, 81.79 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:21<01:26, 77.22 examples/s]Tokenizing train dataset:  20%|██        | 1715/8564 [00:21<01:10, 96.88 examples/s]Tokenizing train dataset:  20%|█▉        | 1680/8564 [00:21<01:18, 88.25 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:21<01:02, 109.57 examples/s]Tokenizing train dataset:  20%|██        | 1730/8564 [00:21<01:13, 93.33 examples/s]Tokenizing train dataset:  22%|██▏       | 1901/8564 [00:21<01:30, 73.91 examples/s]Tokenizing train dataset:  20%|██        | 1713/8564 [00:21<01:00, 113.67 examples/s]Tokenizing train dataset:  20%|██        | 1742/8564 [00:22<01:12, 93.90 examples/s]Tokenizing train dataset:  22%|██▏       | 1914/8564 [00:21<01:24, 78.95 examples/s]Tokenizing train dataset:  20%|██        | 1728/8564 [00:21<01:06, 102.98 examples/s]Tokenizing train dataset:  21%|██        | 1756/8564 [00:22<01:11, 95.01 examples/s]Tokenizing train dataset:  23%|██▎       | 1929/8564 [00:21<01:15, 87.73 examples/s]Tokenizing train dataset:  21%|██        | 1766/8564 [00:22<01:12, 93.86 examples/s]Tokenizing train dataset:  20%|██        | 1740/8564 [00:21<01:12, 93.88 examples/s] Tokenizing train dataset:  23%|██▎       | 1942/8564 [00:21<01:11, 93.24 examples/s]Tokenizing train dataset:  20%|██        | 1750/8564 [00:21<01:14, 92.07 examples/s]Tokenizing train dataset:  23%|██▎       | 1954/8564 [00:22<01:07, 97.45 examples/s]Tokenizing train dataset:  21%|██        | 1776/8564 [00:22<01:26, 78.65 examples/s]Tokenizing train dataset:  23%|██▎       | 1968/8564 [00:22<01:04, 102.01 examples/s]Tokenizing train dataset:  21%|██        | 1761/8564 [00:21<01:15, 90.49 examples/s]Tokenizing train dataset:  23%|██▎       | 1980/8564 [00:22<01:02, 106.00 examples/s]Tokenizing train dataset:  21%|██        | 1787/8564 [00:22<01:32, 73.21 examples/s]Tokenizing train dataset:  21%|██        | 1773/8564 [00:22<01:23, 81.46 examples/s]Tokenizing train dataset:  23%|██▎       | 1992/8564 [00:22<01:02, 105.52 examples/s]Tokenizing train dataset:  21%|██        | 1798/8564 [00:22<01:32, 72.91 examples/s]Tokenizing train dataset:  23%|██▎       | 2007/8564 [00:22<00:58, 112.97 examples/s]Tokenizing train dataset:  21%|██        | 1782/8564 [00:22<01:35, 70.78 examples/s]Tokenizing train dataset:  21%|██        | 1806/8564 [00:22<01:36, 70.11 examples/s]Tokenizing train dataset:  24%|██▎       | 2020/8564 [00:22<00:56, 115.46 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:23<01:34, 71.12 examples/s]Tokenizing train dataset:  21%|██        | 1790/8564 [00:22<01:43, 65.46 examples/s]Tokenizing train dataset:  24%|██▍       | 2034/8564 [00:22<00:55, 117.79 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:22<01:38, 68.89 examples/s]Tokenizing train dataset:  24%|██▍       | 2048/8564 [00:22<00:53, 121.59 examples/s]Tokenizing train dataset:  21%|██▏       | 1823/8564 [00:23<01:43, 64.98 examples/s]Tokenizing train dataset:  21%|██        | 1809/8564 [00:22<01:35, 71.08 examples/s]Tokenizing train dataset:  24%|██▍       | 2062/8564 [00:22<00:51, 126.19 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:23<01:38, 68.65 examples/s]Tokenizing train dataset:  24%|██▍       | 2078/8564 [00:23<00:56, 115.56 examples/s]Tokenizing train dataset:  22%|██▏       | 1843/8564 [00:23<01:36, 69.73 examples/s]Tokenizing train dataset:  21%|██▏       | 1822/8564 [00:22<01:39, 67.44 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:23<00:55, 116.15 examples/s]Tokenizing train dataset:  21%|██▏       | 1832/8564 [00:23<01:35, 70.25 examples/s]Tokenizing train dataset:  22%|██▏       | 1853/8564 [00:23<01:44, 63.97 examples/s]Tokenizing train dataset:  25%|██▍       | 2104/8564 [00:23<00:53, 120.49 examples/s]Tokenizing train dataset:  25%|██▍       | 2120/8564 [00:23<00:51, 126.35 examples/s]Tokenizing train dataset:  22%|██▏       | 1842/8564 [00:23<01:37, 68.62 examples/s]Tokenizing train dataset:  22%|██▏       | 1860/8564 [00:23<02:03, 54.24 examples/s]Tokenizing train dataset:  25%|██▍       | 2135/8564 [00:23<00:49, 129.55 examples/s]Tokenizing train dataset:  22%|██▏       | 1852/8564 [00:23<01:33, 71.96 examples/s]Tokenizing train dataset:  22%|██▏       | 1870/8564 [00:24<01:48, 61.45 examples/s]Tokenizing train dataset:  22%|██▏       | 1883/8564 [00:24<01:29, 74.59 examples/s]Tokenizing train dataset:  25%|██▌       | 2149/8564 [00:23<00:59, 107.06 examples/s]Tokenizing train dataset:  22%|██▏       | 1865/8564 [00:23<01:43, 64.48 examples/s]Tokenizing train dataset:  25%|██▌       | 2162/8564 [00:23<00:57, 110.43 examples/s]Tokenizing train dataset:  22%|██▏       | 1877/8564 [00:23<01:29, 75.12 examples/s]Tokenizing train dataset:  22%|██▏       | 1899/8564 [00:24<01:25, 78.05 examples/s]Tokenizing train dataset:  22%|██▏       | 1889/8564 [00:23<01:19, 84.05 examples/s]Tokenizing train dataset:  25%|██▌       | 2179/8564 [00:24<01:04, 99.41 examples/s] Tokenizing train dataset:  22%|██▏       | 1913/8564 [00:24<01:17, 86.25 examples/s]Tokenizing train dataset:  22%|██▏       | 1902/8564 [00:23<01:13, 91.12 examples/s]Tokenizing train dataset:  26%|██▌       | 2191/8564 [00:24<01:01, 103.40 examples/s]Tokenizing train dataset:  22%|██▏       | 1921/8564 [00:23<00:58, 114.29 examples/s]Tokenizing train dataset:  26%|██▌       | 2202/8564 [00:24<01:02, 101.13 examples/s]Tokenizing train dataset:  23%|██▎       | 1927/8564 [00:24<01:27, 76.06 examples/s]Tokenizing train dataset:  23%|██▎       | 1934/8564 [00:24<00:56, 116.56 examples/s]Tokenizing train dataset:  26%|██▌       | 2215/8564 [00:24<01:00, 105.37 examples/s]Tokenizing train dataset:  23%|██▎       | 1942/8564 [00:24<01:17, 85.36 examples/s]Tokenizing train dataset:  23%|██▎       | 1948/8564 [00:24<00:57, 115.41 examples/s]Tokenizing train dataset:  26%|██▌       | 2229/8564 [00:24<00:57, 109.33 examples/s]Tokenizing train dataset:  23%|██▎       | 1953/8564 [00:24<01:22, 79.65 examples/s]Tokenizing train dataset:  23%|██▎       | 1960/8564 [00:24<00:59, 110.19 examples/s]Tokenizing train dataset:  26%|██▌       | 2242/8564 [00:24<00:56, 111.36 examples/s]Tokenizing train dataset:  23%|██▎       | 1975/8564 [00:24<00:55, 118.67 examples/s]Tokenizing train dataset:  26%|██▋       | 2257/8564 [00:24<00:54, 115.71 examples/s]Tokenizing train dataset:  23%|██▎       | 1967/8564 [00:25<01:26, 76.44 examples/s]Tokenizing train dataset:  23%|██▎       | 1989/8564 [00:24<00:56, 117.25 examples/s]Tokenizing train dataset:  27%|██▋       | 2270/8564 [00:24<00:53, 117.71 examples/s]Tokenizing train dataset:  23%|██▎       | 1976/8564 [00:25<01:23, 78.74 examples/s]Tokenizing train dataset:  27%|██▋       | 2285/8564 [00:24<00:50, 125.58 examples/s]Tokenizing train dataset:  23%|██▎       | 2001/8564 [00:24<01:00, 107.71 examples/s]Tokenizing train dataset:  23%|██▎       | 1989/8564 [00:25<01:15, 86.74 examples/s]Tokenizing train dataset:  27%|██▋       | 2300/8564 [00:25<00:47, 130.52 examples/s]Tokenizing train dataset:  23%|██▎       | 2003/8564 [00:25<01:06, 98.28 examples/s]Tokenizing train dataset:  24%|██▎       | 2017/8564 [00:24<01:08, 95.20 examples/s] Tokenizing train dataset:  24%|██▎       | 2017/8564 [00:25<01:03, 103.90 examples/s]Tokenizing train dataset:  27%|██▋       | 2318/8564 [00:25<01:05, 95.66 examples/s] Tokenizing train dataset:  24%|██▎       | 2031/8564 [00:25<01:00, 107.89 examples/s]Tokenizing train dataset:  24%|██▎       | 2030/8564 [00:25<01:14, 87.95 examples/s]Tokenizing train dataset:  24%|██▍       | 2046/8564 [00:25<00:55, 116.98 examples/s]Tokenizing train dataset:  24%|██▍       | 2041/8564 [00:25<01:12, 89.50 examples/s]Tokenizing train dataset:  27%|██▋       | 2331/8564 [00:25<01:09, 89.71 examples/s]Tokenizing train dataset:  24%|██▍       | 2062/8564 [00:25<00:53, 121.68 examples/s]Tokenizing train dataset:  24%|██▍       | 2057/8564 [00:25<01:11, 90.91 examples/s]Tokenizing train dataset:  27%|██▋       | 2345/8564 [00:25<01:15, 82.26 examples/s]Tokenizing train dataset:  24%|██▍       | 2077/8564 [00:26<00:57, 112.08 examples/s]Tokenizing train dataset:  28%|██▊       | 2357/8564 [00:25<01:10, 88.05 examples/s]Tokenizing train dataset:  24%|██▍       | 2069/8564 [00:25<01:20, 81.06 examples/s]Tokenizing train dataset:  24%|██▍       | 2089/8564 [00:26<00:57, 112.72 examples/s]Tokenizing train dataset:  28%|██▊       | 2369/8564 [00:25<01:08, 89.98 examples/s]Tokenizing train dataset:  25%|██▍       | 2102/8564 [00:26<01:00, 107.57 examples/s]Tokenizing train dataset:  24%|██▍       | 2081/8564 [00:25<01:22, 78.57 examples/s]Tokenizing train dataset:  25%|██▍       | 2119/8564 [00:26<00:54, 118.18 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:25<01:22, 78.41 examples/s]Tokenizing train dataset:  28%|██▊       | 2383/8564 [00:26<01:12, 85.76 examples/s]Tokenizing train dataset:  25%|██▍       | 2100/8564 [00:25<01:22, 78.56 examples/s]Tokenizing train dataset:  25%|██▍       | 2138/8564 [00:26<00:53, 120.17 examples/s]Tokenizing train dataset:  28%|██▊       | 2395/8564 [00:26<01:11, 86.76 examples/s]Tokenizing train dataset:  25%|██▍       | 2113/8564 [00:26<01:17, 83.42 examples/s]Tokenizing train dataset:  28%|██▊       | 2407/8564 [00:26<01:11, 86.67 examples/s]Tokenizing train dataset:  25%|██▌       | 2155/8564 [00:26<00:55, 115.71 examples/s]Tokenizing train dataset:  25%|██▍       | 2123/8564 [00:26<01:15, 85.38 examples/s]Tokenizing train dataset:  28%|██▊       | 2419/8564 [00:26<01:05, 93.91 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:26<00:56, 113.61 examples/s]Tokenizing train dataset:  25%|██▍       | 2135/8564 [00:26<01:10, 90.93 examples/s]Tokenizing train dataset:  25%|██▌       | 2181/8564 [00:27<00:54, 118.19 examples/s]Tokenizing train dataset:  28%|██▊       | 2432/8564 [00:26<01:13, 83.75 examples/s]Tokenizing train dataset:  25%|██▌       | 2149/8564 [00:26<01:03, 100.98 examples/s]Tokenizing train dataset:  26%|██▌       | 2195/8564 [00:27<00:53, 119.57 examples/s]Tokenizing train dataset:  25%|██▌       | 2160/8564 [00:26<01:02, 101.69 examples/s]Tokenizing train dataset:  29%|██▊       | 2443/8564 [00:26<01:15, 81.07 examples/s]Tokenizing train dataset:  26%|██▌       | 2213/8564 [00:27<00:56, 111.70 examples/s]Tokenizing train dataset:  25%|██▌       | 2173/8564 [00:26<01:02, 101.91 examples/s]Tokenizing train dataset:  29%|██▊       | 2456/8564 [00:26<01:09, 88.51 examples/s]Tokenizing train dataset:  26%|██▌       | 2226/8564 [00:27<00:55, 114.04 examples/s]Tokenizing train dataset:  26%|██▌       | 2187/8564 [00:26<00:58, 108.95 examples/s]Tokenizing train dataset:  29%|██▉       | 2471/8564 [00:27<01:01, 98.81 examples/s]Tokenizing train dataset:  26%|██▌       | 2201/8564 [00:26<00:54, 116.90 examples/s]Tokenizing train dataset:  29%|██▉       | 2489/8564 [00:27<01:04, 94.65 examples/s]Tokenizing train dataset:  26%|██▌       | 2244/8564 [00:27<01:07, 93.26 examples/s] Tokenizing train dataset:  26%|██▌       | 2214/8564 [00:27<01:02, 102.05 examples/s]Tokenizing train dataset:  26%|██▋       | 2257/8564 [00:27<01:04, 98.13 examples/s]Tokenizing train dataset:  26%|██▌       | 2225/8564 [00:27<01:04, 97.98 examples/s] Tokenizing train dataset:  29%|██▉       | 2501/8564 [00:27<01:13, 81.99 examples/s]Tokenizing train dataset:  27%|██▋       | 2273/8564 [00:27<00:56, 111.40 examples/s]Tokenizing train dataset:  26%|██▌       | 2240/8564 [00:27<00:58, 107.83 examples/s]Tokenizing train dataset:  29%|██▉       | 2510/8564 [00:27<01:18, 77.26 examples/s]Tokenizing train dataset:  27%|██▋       | 2290/8564 [00:28<00:53, 116.63 examples/s]Tokenizing train dataset:  26%|██▋       | 2254/8564 [00:27<00:57, 110.59 examples/s]Tokenizing train dataset:  29%|██▉       | 2521/8564 [00:27<01:12, 83.12 examples/s]Tokenizing train dataset:  27%|██▋       | 2303/8564 [00:28<00:52, 119.23 examples/s]Tokenizing train dataset:  27%|██▋       | 2270/8564 [00:27<00:55, 112.70 examples/s]Tokenizing train dataset:  30%|██▉       | 2534/8564 [00:27<01:11, 84.22 examples/s]Tokenizing train dataset:  27%|██▋       | 2318/8564 [00:28<00:59, 105.64 examples/s]Tokenizing train dataset:  27%|██▋       | 2288/8564 [00:27<00:51, 121.65 examples/s]Tokenizing train dataset:  30%|██▉       | 2546/8564 [00:27<01:05, 91.32 examples/s]Tokenizing train dataset:  27%|██▋       | 2331/8564 [00:28<00:56, 110.40 examples/s]Tokenizing train dataset:  30%|██▉       | 2564/8564 [00:28<00:55, 108.05 examples/s]Tokenizing train dataset:  27%|██▋       | 2306/8564 [00:27<00:58, 106.19 examples/s]Tokenizing train dataset:  27%|██▋       | 2348/8564 [00:28<00:58, 106.63 examples/s]Tokenizing train dataset:  28%|██▊       | 2361/8564 [00:28<00:57, 107.48 examples/s]Tokenizing train dataset:  30%|███       | 2578/8564 [00:28<01:07, 89.34 examples/s] Tokenizing train dataset:  27%|██▋       | 2320/8564 [00:28<01:05, 94.95 examples/s] Tokenizing train dataset:  30%|███       | 2588/8564 [00:28<01:06, 89.76 examples/s]Tokenizing train dataset:  28%|██▊       | 2375/8564 [00:28<00:58, 105.91 examples/s]Tokenizing train dataset:  27%|██▋       | 2336/8564 [00:28<00:58, 106.14 examples/s]Tokenizing train dataset:  30%|███       | 2601/8564 [00:28<01:02, 95.37 examples/s]Tokenizing train dataset:  27%|██▋       | 2351/8564 [00:28<01:01, 100.80 examples/s]Tokenizing train dataset:  28%|██▊       | 2393/8564 [00:29<01:03, 96.91 examples/s] Tokenizing train dataset:  31%|███       | 2614/8564 [00:28<00:58, 100.89 examples/s]Tokenizing train dataset:  28%|██▊       | 2363/8564 [00:28<01:00, 102.72 examples/s]Tokenizing train dataset:  28%|██▊       | 2404/8564 [00:29<01:04, 96.22 examples/s]Tokenizing train dataset:  31%|███       | 2625/8564 [00:28<01:02, 94.74 examples/s] Tokenizing train dataset:  28%|██▊       | 2377/8564 [00:28<00:55, 111.30 examples/s]Tokenizing train dataset:  31%|███       | 2639/8564 [00:28<00:58, 100.85 examples/s]Tokenizing train dataset:  28%|██▊       | 2392/8564 [00:28<00:51, 120.02 examples/s]Tokenizing train dataset:  28%|██▊       | 2415/8564 [00:29<01:12, 84.49 examples/s]Tokenizing train dataset:  28%|██▊       | 2407/8564 [00:28<00:49, 123.17 examples/s]Tokenizing train dataset:  31%|███       | 2655/8564 [00:29<00:58, 101.86 examples/s]Tokenizing train dataset:  28%|██▊       | 2427/8564 [00:29<01:10, 86.73 examples/s]Tokenizing train dataset:  28%|██▊       | 2421/8564 [00:28<00:49, 124.81 examples/s]Tokenizing train dataset:  31%|███       | 2670/8564 [00:29<00:55, 106.24 examples/s]Tokenizing train dataset:  28%|██▊       | 2437/8564 [00:29<01:14, 82.52 examples/s]Tokenizing train dataset:  28%|██▊       | 2435/8564 [00:29<00:57, 106.79 examples/s]Tokenizing train dataset:  29%|██▊       | 2450/8564 [00:29<01:09, 88.11 examples/s]Tokenizing train dataset:  31%|███▏      | 2684/8564 [00:29<00:59, 99.28 examples/s] Tokenizing train dataset:  29%|██▊       | 2448/8564 [00:29<00:55, 109.39 examples/s]Tokenizing train dataset:  29%|██▉       | 2466/8564 [00:29<00:58, 103.48 examples/s]Tokenizing train dataset:  32%|███▏      | 2698/8564 [00:29<01:02, 93.31 examples/s]Tokenizing train dataset:  29%|██▉       | 2478/8564 [00:29<00:59, 102.52 examples/s]Tokenizing train dataset:  29%|██▊       | 2462/8564 [00:29<01:00, 100.87 examples/s]Tokenizing train dataset:  32%|███▏      | 2708/8564 [00:29<01:04, 90.47 examples/s]Tokenizing train dataset:  29%|██▉       | 2491/8564 [00:30<00:58, 103.49 examples/s]Tokenizing train dataset:  29%|██▉       | 2473/8564 [00:29<01:04, 93.98 examples/s] Tokenizing train dataset:  29%|██▉       | 2502/8564 [00:30<00:58, 103.60 examples/s]Tokenizing train dataset:  32%|███▏      | 2719/8564 [00:29<01:08, 85.07 examples/s]Tokenizing train dataset:  29%|██▉       | 2514/8564 [00:30<00:56, 106.85 examples/s]Tokenizing train dataset:  29%|██▉       | 2487/8564 [00:29<01:10, 85.62 examples/s]Tokenizing train dataset:  32%|███▏      | 2730/8564 [00:29<01:12, 80.01 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:30<00:51, 117.70 examples/s]Tokenizing train dataset:  29%|██▉       | 2499/8564 [00:29<01:17, 78.44 examples/s]Tokenizing train dataset:  30%|██▉       | 2544/8564 [00:30<00:50, 119.61 examples/s]Tokenizing train dataset:  32%|███▏      | 2741/8564 [00:30<01:23, 69.59 examples/s]Tokenizing train dataset:  30%|██▉       | 2561/8564 [00:30<00:47, 126.22 examples/s]Tokenizing train dataset:  29%|██▉       | 2514/8564 [00:30<01:14, 81.00 examples/s]Tokenizing train dataset:  32%|███▏      | 2751/8564 [00:30<01:22, 70.31 examples/s]Tokenizing train dataset:  30%|███       | 2575/8564 [00:30<00:46, 128.28 examples/s]Tokenizing train dataset:  30%|██▉       | 2532/8564 [00:30<01:02, 96.96 examples/s]Tokenizing train dataset:  32%|███▏      | 2761/8564 [00:30<01:21, 71.46 examples/s]Tokenizing train dataset:  30%|███       | 2594/8564 [00:30<00:48, 122.84 examples/s]Tokenizing train dataset:  30%|██▉       | 2546/8564 [00:30<00:58, 103.42 examples/s]Tokenizing train dataset:  32%|███▏      | 2770/8564 [00:30<01:21, 71.14 examples/s]Tokenizing train dataset:  30%|██▉       | 2564/8564 [00:30<00:51, 117.35 examples/s]Tokenizing train dataset:  30%|███       | 2609/8564 [00:31<00:51, 116.50 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:30<01:06, 86.37 examples/s]Tokenizing train dataset:  30%|███       | 2577/8564 [00:30<00:51, 116.86 examples/s]Tokenizing train dataset:  33%|███▎      | 2800/8564 [00:30<01:00, 95.44 examples/s]Tokenizing train dataset:  33%|███▎      | 2821/8564 [00:30<00:47, 121.66 examples/s]Tokenizing train dataset:  30%|███       | 2592/8564 [00:30<00:55, 106.85 examples/s]Tokenizing train dataset:  31%|███       | 2625/8564 [00:31<01:09, 85.62 examples/s] Tokenizing train dataset:  33%|███▎      | 2834/8564 [00:31<00:48, 118.70 examples/s]Tokenizing train dataset:  30%|███       | 2607/8564 [00:30<00:52, 112.61 examples/s]Tokenizing train dataset:  31%|███       | 2635/8564 [00:31<01:12, 81.57 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:30<00:58, 102.39 examples/s]Tokenizing train dataset:  33%|███▎      | 2853/8564 [00:31<00:50, 113.87 examples/s]Tokenizing train dataset:  31%|███       | 2646/8564 [00:31<01:13, 80.84 examples/s]Tokenizing train dataset:  31%|███       | 2632/8564 [00:31<00:59, 100.06 examples/s]Tokenizing train dataset:  34%|███▎      | 2870/8564 [00:31<00:53, 106.13 examples/s]Tokenizing train dataset:  31%|███       | 2659/8564 [00:31<01:15, 77.79 examples/s]Tokenizing train dataset:  31%|███       | 2648/8564 [00:31<00:54, 109.16 examples/s]Tokenizing train dataset:  34%|███▎      | 2885/8564 [00:31<00:50, 112.23 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:31<00:55, 106.91 examples/s]Tokenizing train dataset:  31%|███       | 2669/8564 [00:31<01:19, 73.89 examples/s]Tokenizing train dataset:  31%|███       | 2671/8564 [00:31<00:56, 103.56 examples/s]Tokenizing train dataset:  34%|███▍      | 2899/8564 [00:31<00:56, 100.74 examples/s]Tokenizing train dataset:  31%|███▏      | 2680/8564 [00:32<01:16, 76.96 examples/s]Tokenizing train dataset:  31%|███▏      | 2683/8564 [00:31<00:57, 102.96 examples/s]Tokenizing train dataset:  34%|███▍      | 2914/8564 [00:31<00:53, 105.81 examples/s]Tokenizing train dataset:  31%|███▏      | 2692/8564 [00:32<01:08, 85.46 examples/s]Tokenizing train dataset:  32%|███▏      | 2698/8564 [00:31<00:53, 109.67 examples/s]Tokenizing train dataset:  32%|███▏      | 2707/8564 [00:32<00:59, 98.22 examples/s]Tokenizing train dataset:  34%|███▍      | 2928/8564 [00:31<00:56, 100.56 examples/s]Tokenizing train dataset:  32%|███▏      | 2720/8564 [00:32<00:55, 104.85 examples/s]Tokenizing train dataset:  32%|███▏      | 2714/8564 [00:31<00:49, 118.07 examples/s]Tokenizing train dataset:  32%|███▏      | 2732/8564 [00:32<00:55, 105.51 examples/s]Tokenizing train dataset:  34%|███▍      | 2941/8564 [00:32<01:02, 89.79 examples/s] Tokenizing train dataset:  32%|███▏      | 2731/8564 [00:31<00:52, 110.58 examples/s]Tokenizing train dataset:  32%|███▏      | 2744/8564 [00:32<00:56, 102.73 examples/s]Tokenizing train dataset:  34%|███▍      | 2953/8564 [00:32<01:02, 89.15 examples/s]Tokenizing train dataset:  32%|███▏      | 2743/8564 [00:32<00:53, 108.39 examples/s]Tokenizing train dataset:  32%|███▏      | 2755/8564 [00:32<00:56, 102.53 examples/s]Tokenizing train dataset:  35%|███▍      | 2964/8564 [00:32<01:04, 87.04 examples/s]Tokenizing train dataset:  32%|███▏      | 2755/8564 [00:32<00:53, 109.08 examples/s]Tokenizing train dataset:  32%|███▏      | 2771/8564 [00:32<00:53, 107.84 examples/s]Tokenizing train dataset:  32%|███▏      | 2767/8564 [00:32<00:53, 108.32 examples/s]Tokenizing train dataset:  35%|███▍      | 2981/8564 [00:32<01:01, 91.43 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:33<00:52, 110.94 examples/s]Tokenizing train dataset:  35%|███▍      | 2995/8564 [00:32<00:55, 100.21 examples/s]Tokenizing train dataset:  32%|███▏      | 2783/8564 [00:32<00:55, 104.81 examples/s]Tokenizing train dataset:  33%|███▎      | 2799/8564 [00:33<00:49, 115.70 examples/s]Tokenizing train dataset:  35%|███▌      | 3007/8564 [00:32<00:54, 101.73 examples/s]Tokenizing train dataset:  33%|███▎      | 2816/8564 [00:33<00:46, 123.67 examples/s]Tokenizing train dataset:  33%|███▎      | 2794/8564 [00:32<01:03, 90.37 examples/s] Tokenizing train dataset:  35%|███▌      | 3020/8564 [00:32<00:52, 106.55 examples/s]Tokenizing train dataset:  33%|███▎      | 2830/8564 [00:33<00:47, 121.39 examples/s]Tokenizing train dataset:  33%|███▎      | 2806/8564 [00:32<01:02, 92.16 examples/s]Tokenizing train dataset:  35%|███▌      | 3033/8564 [00:33<00:51, 107.33 examples/s]Tokenizing train dataset:  33%|███▎      | 2819/8564 [00:32<00:59, 96.37 examples/s]Tokenizing train dataset:  33%|███▎      | 2849/8564 [00:33<00:48, 117.95 examples/s]Tokenizing train dataset:  36%|███▌      | 3045/8564 [00:33<00:51, 108.21 examples/s]Tokenizing train dataset:  36%|███▌      | 3056/8564 [00:33<00:51, 107.89 examples/s]Tokenizing train dataset:  33%|███▎      | 2830/8564 [00:33<01:08, 83.78 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:33<00:51, 110.21 examples/s]Tokenizing train dataset:  36%|███▌      | 3069/8564 [00:33<00:50, 108.82 examples/s]Tokenizing train dataset:  34%|███▎      | 2880/8564 [00:33<00:51, 110.42 examples/s]Tokenizing train dataset:  36%|███▌      | 3083/8564 [00:33<00:47, 115.38 examples/s]Tokenizing train dataset:  33%|███▎      | 2842/8564 [00:33<01:15, 75.70 examples/s]Tokenizing train dataset:  34%|███▍      | 2896/8564 [00:33<00:46, 120.92 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:33<00:46, 117.25 examples/s]Tokenizing train dataset:  33%|███▎      | 2850/8564 [00:33<01:17, 73.81 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:33<00:45, 119.44 examples/s]Tokenizing train dataset:  33%|███▎      | 2861/8564 [00:33<01:12, 78.69 examples/s]Tokenizing train dataset:  34%|███▍      | 2916/8564 [00:34<00:47, 119.52 examples/s]Tokenizing train dataset:  34%|███▎      | 2873/8564 [00:33<01:07, 84.16 examples/s]Tokenizing train dataset:  37%|███▋      | 3127/8564 [00:33<00:48, 110.97 examples/s]Tokenizing train dataset:  34%|███▍      | 2930/8564 [00:34<00:57, 98.73 examples/s] Tokenizing train dataset:  34%|███▎      | 2887/8564 [00:33<00:58, 97.15 examples/s]Tokenizing train dataset:  37%|███▋      | 3142/8564 [00:33<00:47, 114.46 examples/s]Tokenizing train dataset:  34%|███▍      | 2905/8564 [00:33<00:49, 113.94 examples/s]Tokenizing train dataset:  34%|███▍      | 2946/8564 [00:34<00:57, 97.21 examples/s]Tokenizing train dataset:  37%|███▋      | 3158/8564 [00:34<00:45, 119.96 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:33<00:45, 123.09 examples/s]Tokenizing train dataset:  37%|███▋      | 3173/8564 [00:34<00:47, 112.54 examples/s]Tokenizing train dataset:  35%|███▍      | 2961/8564 [00:34<01:01, 90.93 examples/s]Tokenizing train dataset:  34%|███▍      | 2936/8564 [00:34<00:45, 123.77 examples/s]Tokenizing train dataset:  37%|███▋      | 3187/8564 [00:34<00:47, 113.83 examples/s]Tokenizing train dataset:  35%|███▍      | 2971/8564 [00:34<01:01, 90.36 examples/s]Tokenizing train dataset:  34%|███▍      | 2953/8564 [00:34<00:43, 129.19 examples/s]Tokenizing train dataset:  37%|███▋      | 3200/8564 [00:34<00:45, 117.29 examples/s]Tokenizing train dataset:  35%|███▍      | 2969/8564 [00:34<00:43, 128.43 examples/s]Tokenizing train dataset:  35%|███▍      | 2988/8564 [00:34<00:57, 97.26 examples/s]Tokenizing train dataset:  38%|███▊      | 3214/8564 [00:34<00:45, 118.50 examples/s]Tokenizing train dataset:  35%|███▍      | 2987/8564 [00:34<00:39, 141.34 examples/s]Tokenizing train dataset:  38%|███▊      | 3229/8564 [00:34<00:43, 123.81 examples/s]Tokenizing train dataset:  35%|███▌      | 3001/8564 [00:35<01:02, 88.88 examples/s]Tokenizing train dataset:  35%|███▌      | 3004/8564 [00:34<00:44, 126.11 examples/s]Tokenizing train dataset:  38%|███▊      | 3243/8564 [00:34<00:43, 121.16 examples/s]Tokenizing train dataset:  35%|███▌      | 3017/8564 [00:35<01:02, 88.24 examples/s]Tokenizing train dataset:  38%|███▊      | 3256/8564 [00:34<00:44, 119.76 examples/s]Tokenizing train dataset:  35%|███▌      | 3022/8564 [00:34<00:45, 120.64 examples/s]Tokenizing train dataset:  38%|███▊      | 3270/8564 [00:35<00:44, 119.23 examples/s]Tokenizing train dataset:  35%|███▌      | 3027/8564 [00:35<01:07, 82.09 examples/s]Tokenizing train dataset:  35%|███▌      | 3035/8564 [00:34<00:45, 121.71 examples/s]Tokenizing train dataset:  38%|███▊      | 3288/8564 [00:35<00:45, 116.72 examples/s]Tokenizing train dataset:  35%|███▌      | 3038/8564 [00:35<01:11, 77.52 examples/s]Tokenizing train dataset:  36%|███▌      | 3054/8564 [00:34<00:47, 115.42 examples/s]Tokenizing train dataset:  39%|███▊      | 3301/8564 [00:35<00:47, 111.43 examples/s]Tokenizing train dataset:  36%|███▌      | 3047/8564 [00:35<01:11, 76.68 examples/s]Tokenizing train dataset:  36%|███▌      | 3067/8564 [00:35<00:46, 117.02 examples/s]Tokenizing train dataset:  36%|███▌      | 3058/8564 [00:35<01:08, 80.76 examples/s]Tokenizing train dataset:  36%|███▌      | 3082/8564 [00:35<00:46, 118.16 examples/s]Tokenizing train dataset:  39%|███▊      | 3314/8564 [00:35<00:52, 99.70 examples/s] Tokenizing train dataset:  36%|███▌      | 3070/8564 [00:35<01:02, 87.94 examples/s]Tokenizing train dataset:  36%|███▌      | 3096/8564 [00:35<00:44, 122.67 examples/s]Tokenizing train dataset:  39%|███▉      | 3326/8564 [00:35<00:57, 90.93 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:35<00:44, 123.16 examples/s]Tokenizing train dataset:  36%|███▌      | 3087/8564 [00:36<00:54, 100.39 examples/s]Tokenizing train dataset:  36%|███▌      | 3101/8564 [00:36<00:50, 108.53 examples/s]Tokenizing train dataset:  39%|███▉      | 3339/8564 [00:35<00:59, 87.68 examples/s]Tokenizing train dataset:  36%|███▋      | 3124/8564 [00:35<00:54, 100.64 examples/s]Tokenizing train dataset:  36%|███▋      | 3115/8564 [00:36<00:47, 115.16 examples/s]Tokenizing train dataset:  39%|███▉      | 3348/8564 [00:35<01:00, 86.47 examples/s]Tokenizing train dataset:  37%|███▋      | 3139/8564 [00:35<00:49, 108.88 examples/s]Tokenizing train dataset:  39%|███▉      | 3357/8564 [00:36<00:59, 87.13 examples/s]Tokenizing train dataset:  37%|███▋      | 3132/8564 [00:36<00:48, 111.09 examples/s]Tokenizing train dataset:  37%|███▋      | 3153/8564 [00:35<00:46, 115.25 examples/s]Tokenizing train dataset:  37%|███▋      | 3147/8564 [00:36<00:47, 113.60 examples/s]Tokenizing train dataset:  39%|███▉      | 3369/8564 [00:36<01:04, 80.30 examples/s]Tokenizing train dataset:  37%|███▋      | 3170/8564 [00:36<00:51, 105.61 examples/s]Tokenizing train dataset:  37%|███▋      | 3160/8564 [00:36<00:47, 113.44 examples/s]Tokenizing train dataset:  39%|███▉      | 3380/8564 [00:36<01:03, 81.52 examples/s]Tokenizing train dataset:  37%|███▋      | 3185/8564 [00:36<00:49, 108.77 examples/s]Tokenizing train dataset:  40%|███▉      | 3400/8564 [00:36<00:51, 100.79 examples/s]Tokenizing train dataset:  37%|███▋      | 3178/8564 [00:36<00:47, 112.51 examples/s]Tokenizing train dataset:  37%|███▋      | 3192/8564 [00:37<00:46, 115.16 examples/s]Tokenizing train dataset:  37%|███▋      | 3197/8564 [00:36<00:57, 93.61 examples/s] Tokenizing train dataset:  40%|███▉      | 3412/8564 [00:36<00:56, 91.32 examples/s] Tokenizing train dataset:  37%|███▋      | 3205/8564 [00:37<00:47, 113.71 examples/s]Tokenizing train dataset:  37%|███▋      | 3209/8564 [00:36<00:56, 94.10 examples/s]Tokenizing train dataset:  40%|███▉      | 3422/8564 [00:36<00:58, 87.81 examples/s]Tokenizing train dataset:  38%|███▊      | 3220/8564 [00:37<00:44, 119.62 examples/s]Tokenizing train dataset:  38%|███▊      | 3220/8564 [00:36<00:58, 90.85 examples/s]Tokenizing train dataset:  40%|████      | 3431/8564 [00:36<00:59, 86.46 examples/s]Tokenizing train dataset:  38%|███▊      | 3234/8564 [00:37<00:44, 119.61 examples/s]Tokenizing train dataset:  38%|███▊      | 3230/8564 [00:36<00:59, 89.47 examples/s]Tokenizing train dataset:  40%|████      | 3440/8564 [00:37<01:03, 81.06 examples/s]Tokenizing train dataset:  38%|███▊      | 3245/8564 [00:36<00:53, 98.62 examples/s]Tokenizing train dataset:  38%|███▊      | 3250/8564 [00:37<00:48, 110.43 examples/s]Tokenizing train dataset:  40%|████      | 3451/8564 [00:37<00:58, 87.43 examples/s]Tokenizing train dataset:  40%|████      | 3465/8564 [00:37<00:52, 96.56 examples/s]Tokenizing train dataset:  38%|███▊      | 3257/8564 [00:36<00:54, 96.52 examples/s]Tokenizing train dataset:  38%|███▊      | 3268/8564 [00:37<00:46, 112.79 examples/s]Tokenizing train dataset:  41%|████      | 3477/8564 [00:37<00:49, 102.24 examples/s]Tokenizing train dataset:  38%|███▊      | 3269/8564 [00:37<01:03, 83.83 examples/s]Tokenizing train dataset:  38%|███▊      | 3282/8564 [00:37<00:53, 99.03 examples/s] Tokenizing train dataset:  41%|████      | 3496/8564 [00:37<00:52, 95.66 examples/s] Tokenizing train dataset:  38%|███▊      | 3280/8564 [00:37<01:03, 82.63 examples/s]Tokenizing train dataset:  38%|███▊      | 3294/8564 [00:38<00:58, 89.42 examples/s]Tokenizing train dataset:  41%|████      | 3511/8564 [00:37<00:47, 105.90 examples/s]Tokenizing train dataset:  38%|███▊      | 3294/8564 [00:37<00:56, 92.50 examples/s]Tokenizing train dataset:  41%|████      | 3525/8564 [00:37<00:45, 110.38 examples/s]Tokenizing train dataset:  39%|███▊      | 3305/8564 [00:37<00:55, 93.97 examples/s]Tokenizing train dataset:  39%|███▊      | 3309/8564 [00:38<01:03, 83.03 examples/s]Tokenizing train dataset:  41%|████▏     | 3537/8564 [00:37<00:47, 106.59 examples/s]Tokenizing train dataset:  39%|███▉      | 3319/8564 [00:37<00:51, 101.22 examples/s]Tokenizing train dataset:  39%|███▊      | 3318/8564 [00:38<01:07, 77.49 examples/s]Tokenizing train dataset:  41%|████▏     | 3549/8564 [00:38<00:47, 105.51 examples/s]Tokenizing train dataset:  39%|███▉      | 3334/8564 [00:37<00:54, 96.68 examples/s] Tokenizing train dataset:  42%|████▏     | 3562/8564 [00:38<00:45, 109.55 examples/s]Tokenizing train dataset:  39%|███▉      | 3326/8564 [00:38<01:14, 70.77 examples/s]Tokenizing train dataset:  39%|███▉      | 3350/8564 [00:37<00:47, 109.28 examples/s]Tokenizing train dataset:  39%|███▉      | 3334/8564 [00:38<01:12, 71.77 examples/s]Tokenizing train dataset:  42%|████▏     | 3576/8564 [00:38<00:44, 111.83 examples/s]Tokenizing train dataset:  39%|███▉      | 3363/8564 [00:38<00:47, 110.39 examples/s]Tokenizing train dataset:  42%|████▏     | 3590/8564 [00:38<00:42, 118.26 examples/s]Tokenizing train dataset:  39%|███▉      | 3345/8564 [00:38<01:09, 75.40 examples/s]Tokenizing train dataset:  39%|███▉      | 3378/8564 [00:38<00:45, 113.88 examples/s]Tokenizing train dataset:  42%|████▏     | 3605/8564 [00:38<00:40, 122.00 examples/s]Tokenizing train dataset:  39%|███▉      | 3357/8564 [00:38<01:06, 78.22 examples/s]Tokenizing train dataset:  40%|███▉      | 3394/8564 [00:38<00:41, 123.11 examples/s]Tokenizing train dataset:  39%|███▉      | 3365/8564 [00:39<01:08, 76.13 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:38<00:40, 122.98 examples/s]Tokenizing train dataset:  40%|███▉      | 3409/8564 [00:38<00:41, 125.07 examples/s]Tokenizing train dataset:  39%|███▉      | 3376/8564 [00:39<01:02, 82.54 examples/s]Tokenizing train dataset:  43%|████▎     | 3644/8564 [00:38<00:41, 118.37 examples/s]Tokenizing train dataset:  40%|████      | 3426/8564 [00:38<00:42, 119.58 examples/s]Tokenizing train dataset:  40%|███▉      | 3390/8564 [00:39<01:01, 84.01 examples/s]Tokenizing train dataset:  40%|████      | 3441/8564 [00:38<00:42, 120.25 examples/s]Tokenizing train dataset:  43%|████▎     | 3660/8564 [00:38<00:44, 110.79 examples/s]Tokenizing train dataset:  40%|████      | 3457/8564 [00:38<00:41, 124.50 examples/s]Tokenizing train dataset:  40%|███▉      | 3405/8564 [00:39<00:59, 86.19 examples/s]Tokenizing train dataset:  43%|████▎     | 3677/8564 [00:39<00:44, 110.68 examples/s]Tokenizing train dataset:  41%|████      | 3470/8564 [00:38<00:41, 122.82 examples/s]Tokenizing train dataset:  40%|███▉      | 3418/8564 [00:39<01:01, 83.46 examples/s]Tokenizing train dataset:  43%|████▎     | 3690/8564 [00:39<00:49, 99.45 examples/s] Tokenizing train dataset:  41%|████      | 3487/8564 [00:39<00:43, 117.35 examples/s]Tokenizing train dataset:  40%|████      | 3430/8564 [00:39<00:58, 87.72 examples/s]Tokenizing train dataset:  43%|████▎     | 3701/8564 [00:39<00:52, 91.88 examples/s]Tokenizing train dataset:  41%|████      | 3500/8564 [00:39<00:44, 114.29 examples/s]Tokenizing train dataset:  40%|████      | 3440/8564 [00:39<00:58, 87.07 examples/s]Tokenizing train dataset:  41%|████      | 3519/8564 [00:39<00:38, 130.16 examples/s]Tokenizing train dataset:  43%|████▎     | 3711/8564 [00:39<00:54, 88.30 examples/s]Tokenizing train dataset:  40%|████      | 3452/8564 [00:40<01:00, 84.12 examples/s]Tokenizing train dataset:  41%|████▏     | 3537/8564 [00:39<00:41, 119.99 examples/s]Tokenizing train dataset:  44%|████▎     | 3727/8564 [00:39<00:55, 87.79 examples/s]Tokenizing train dataset:  40%|████      | 3465/8564 [00:40<00:57, 88.74 examples/s]Tokenizing train dataset:  41%|████▏     | 3550/8564 [00:39<00:43, 114.46 examples/s]Tokenizing train dataset:  41%|████      | 3474/8564 [00:40<00:59, 85.49 examples/s]Tokenizing train dataset:  44%|████▎     | 3743/8564 [00:39<00:57, 83.50 examples/s]Tokenizing train dataset:  41%|████      | 3486/8564 [00:40<00:55, 91.19 examples/s]Tokenizing train dataset:  44%|████▍     | 3758/8564 [00:40<00:51, 93.10 examples/s]Tokenizing train dataset:  42%|████▏     | 3568/8564 [00:39<00:51, 96.53 examples/s] Tokenizing train dataset:  41%|████      | 3499/8564 [00:40<00:57, 88.51 examples/s]Tokenizing train dataset:  42%|████▏     | 3582/8564 [00:39<00:47, 104.47 examples/s]Tokenizing train dataset:  41%|████      | 3510/8564 [00:40<00:54, 92.63 examples/s]Tokenizing train dataset:  44%|████▍     | 3773/8564 [00:40<00:51, 93.40 examples/s]Tokenizing train dataset:  42%|████▏     | 3598/8564 [00:40<00:43, 114.13 examples/s]Tokenizing train dataset:  44%|████▍     | 3784/8564 [00:40<00:51, 93.03 examples/s]Tokenizing train dataset:  41%|████      | 3527/8564 [00:40<00:49, 102.70 examples/s]Tokenizing train dataset:  42%|████▏     | 3611/8564 [00:40<00:42, 115.30 examples/s]Tokenizing train dataset:  44%|████▍     | 3797/8564 [00:40<00:49, 97.04 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:40<00:44, 110.05 examples/s]Tokenizing train dataset:  41%|████▏     | 3541/8564 [00:41<00:58, 85.74 examples/s] Tokenizing train dataset:  44%|████▍     | 3809/8564 [00:40<00:48, 97.62 examples/s]Tokenizing train dataset:  45%|████▍     | 3820/8564 [00:40<00:47, 98.92 examples/s]Tokenizing train dataset:  43%|████▎     | 3645/8564 [00:40<00:46, 104.90 examples/s]Tokenizing train dataset:  41%|████▏     | 3551/8564 [00:41<01:07, 74.32 examples/s]Tokenizing train dataset:  42%|████▏     | 3567/8564 [00:41<00:56, 88.48 examples/s]Tokenizing train dataset:  43%|████▎     | 3660/8564 [00:40<00:48, 100.64 examples/s]Tokenizing train dataset:  45%|████▍     | 3835/8564 [00:40<00:56, 83.50 examples/s]Tokenizing train dataset:  43%|████▎     | 3671/8564 [00:40<00:49, 99.56 examples/s] Tokenizing train dataset:  45%|████▍     | 3847/8564 [00:41<00:54, 87.31 examples/s]Tokenizing train dataset:  42%|████▏     | 3581/8564 [00:41<01:00, 82.66 examples/s]Tokenizing train dataset:  45%|████▌     | 3861/8564 [00:41<00:48, 96.79 examples/s]Tokenizing train dataset:  43%|████▎     | 3690/8564 [00:40<00:47, 101.68 examples/s]Tokenizing train dataset:  42%|████▏     | 3594/8564 [00:41<00:57, 86.23 examples/s]Tokenizing train dataset:  45%|████▌     | 3874/8564 [00:41<00:45, 103.75 examples/s]Tokenizing train dataset:  42%|████▏     | 3608/8564 [00:41<00:51, 96.68 examples/s]Tokenizing train dataset:  45%|████▌     | 3887/8564 [00:41<00:42, 109.66 examples/s]Tokenizing train dataset:  43%|████▎     | 3710/8564 [00:41<00:51, 95.09 examples/s] Tokenizing train dataset:  42%|████▏     | 3628/8564 [00:41<00:47, 103.24 examples/s]Tokenizing train dataset:  46%|████▌     | 3904/8564 [00:41<00:44, 105.31 examples/s]Tokenizing train dataset:  43%|████▎     | 3720/8564 [00:41<00:52, 91.89 examples/s]Tokenizing train dataset:  43%|████▎     | 3640/8564 [00:42<00:48, 101.51 examples/s]Tokenizing train dataset:  46%|████▌     | 3915/8564 [00:41<00:45, 101.69 examples/s]Tokenizing train dataset:  44%|████▎     | 3734/8564 [00:41<00:55, 86.42 examples/s]Tokenizing train dataset:  46%|████▌     | 3927/8564 [00:41<00:44, 105.24 examples/s]Tokenizing train dataset:  43%|████▎     | 3657/8564 [00:42<00:48, 101.67 examples/s]Tokenizing train dataset:  46%|████▌     | 3942/8564 [00:41<00:41, 110.81 examples/s]Tokenizing train dataset:  43%|████▎     | 3669/8564 [00:42<00:46, 104.66 examples/s]Tokenizing train dataset:  44%|████▍     | 3750/8564 [00:41<00:56, 85.58 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:42<00:48, 100.05 examples/s]Tokenizing train dataset:  44%|████▍     | 3765/8564 [00:41<00:49, 97.05 examples/s]Tokenizing train dataset:  46%|████▌     | 3959/8564 [00:42<00:46, 99.90 examples/s] Tokenizing train dataset:  43%|████▎     | 3695/8564 [00:42<00:44, 110.54 examples/s]Tokenizing train dataset:  43%|████▎     | 3711/8564 [00:42<00:40, 119.07 examples/s]Tokenizing train dataset:  46%|████▋     | 3970/8564 [00:42<00:50, 90.53 examples/s]Tokenizing train dataset:  44%|████▍     | 3782/8564 [00:41<00:51, 93.25 examples/s]Tokenizing train dataset:  46%|████▋     | 3980/8564 [00:42<00:49, 92.05 examples/s]Tokenizing train dataset:  44%|████▎     | 3726/8564 [00:42<00:44, 108.71 examples/s]Tokenizing train dataset:  44%|████▍     | 3797/8564 [00:42<00:54, 87.62 examples/s]Tokenizing train dataset:  47%|████▋     | 3994/8564 [00:42<00:50, 90.16 examples/s]Tokenizing train dataset:  44%|████▍     | 3810/8564 [00:42<00:51, 93.01 examples/s]Tokenizing train dataset:  44%|████▎     | 3740/8564 [00:43<00:51, 94.33 examples/s] Tokenizing train dataset:  47%|████▋     | 4005/8564 [00:42<00:48, 93.07 examples/s]Tokenizing train dataset:  45%|████▍     | 3823/8564 [00:42<00:47, 98.79 examples/s]Tokenizing train dataset:  44%|████▍     | 3755/8564 [00:43<00:46, 103.02 examples/s]Tokenizing train dataset:  47%|████▋     | 4017/8564 [00:42<00:46, 98.61 examples/s]Tokenizing train dataset:  45%|████▍     | 3836/8564 [00:42<00:45, 103.58 examples/s]Tokenizing train dataset:  47%|████▋     | 4031/8564 [00:42<00:41, 108.69 examples/s]Tokenizing train dataset:  45%|████▍     | 3847/8564 [00:42<00:46, 102.11 examples/s]Tokenizing train dataset:  44%|████▍     | 3771/8564 [00:43<00:50, 94.13 examples/s] Tokenizing train dataset:  47%|████▋     | 4043/8564 [00:43<00:51, 87.96 examples/s] Tokenizing train dataset:  45%|████▌     | 3858/8564 [00:42<00:48, 97.17 examples/s] Tokenizing train dataset:  44%|████▍     | 3786/8564 [00:43<00:46, 102.08 examples/s]Tokenizing train dataset:  45%|████▌     | 3872/8564 [00:42<00:44, 106.35 examples/s]Tokenizing train dataset:  44%|████▍     | 3799/8564 [00:43<00:44, 106.66 examples/s]Tokenizing train dataset:  47%|████▋     | 4053/8564 [00:43<00:55, 81.01 examples/s]Tokenizing train dataset:  45%|████▌     | 3884/8564 [00:43<00:45, 101.90 examples/s]Tokenizing train dataset:  47%|████▋     | 4066/8564 [00:43<00:49, 91.10 examples/s]Tokenizing train dataset:  45%|████▍     | 3816/8564 [00:43<00:43, 107.96 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:43<00:44, 99.76 examples/s]Tokenizing train dataset:  46%|████▌     | 3898/8564 [00:43<00:49, 94.89 examples/s] Tokenizing train dataset:  45%|████▍     | 3828/8564 [00:43<00:46, 102.49 examples/s]Tokenizing train dataset:  46%|████▌     | 3909/8564 [00:43<00:48, 95.09 examples/s]Tokenizing train dataset:  48%|████▊     | 4097/8564 [00:43<00:44, 101.11 examples/s]Tokenizing train dataset:  45%|████▍     | 3841/8564 [00:44<00:53, 88.57 examples/s] Tokenizing train dataset:  46%|████▌     | 3920/8564 [00:43<00:47, 97.21 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:43<00:41, 107.41 examples/s]Tokenizing train dataset:  46%|████▌     | 3933/8564 [00:43<00:45, 101.59 examples/s]Tokenizing train dataset:  48%|████▊     | 4123/8564 [00:43<00:42, 105.49 examples/s]Tokenizing train dataset:  45%|████▌     | 3854/8564 [00:44<00:57, 81.75 examples/s]Tokenizing train dataset:  46%|████▌     | 3947/8564 [00:43<00:42, 109.14 examples/s]Tokenizing train dataset:  48%|████▊     | 4134/8564 [00:43<00:41, 105.73 examples/s]Tokenizing train dataset:  45%|████▌     | 3863/8564 [00:44<00:56, 83.05 examples/s]Tokenizing train dataset:  46%|████▌     | 3960/8564 [00:43<00:40, 114.62 examples/s]Tokenizing train dataset:  48%|████▊     | 4149/8564 [00:44<00:40, 109.14 examples/s]Tokenizing train dataset:  45%|████▌     | 3873/8564 [00:44<00:58, 80.06 examples/s]Tokenizing train dataset:  46%|████▋     | 3972/8564 [00:43<00:40, 114.35 examples/s]Tokenizing train dataset:  45%|████▌     | 3883/8564 [00:44<00:58, 79.57 examples/s]Tokenizing train dataset:  49%|████▊     | 4167/8564 [00:44<00:40, 108.06 examples/s]Tokenizing train dataset:  47%|████▋     | 3990/8564 [00:43<00:41, 110.46 examples/s]Tokenizing train dataset:  49%|████▉     | 4182/8564 [00:44<00:37, 116.41 examples/s]Tokenizing train dataset:  45%|████▌     | 3894/8564 [00:44<01:02, 74.48 examples/s]Tokenizing train dataset:  47%|████▋     | 4004/8564 [00:44<00:40, 111.63 examples/s]Tokenizing train dataset:  49%|████▉     | 4197/8564 [00:44<00:36, 120.13 examples/s]Tokenizing train dataset:  46%|████▌     | 3902/8564 [00:44<01:06, 70.26 examples/s]Tokenizing train dataset:  47%|████▋     | 4020/8564 [00:44<00:38, 118.34 examples/s]Tokenizing train dataset:  49%|████▉     | 4211/8564 [00:44<00:37, 115.25 examples/s]Tokenizing train dataset:  46%|████▌     | 3910/8564 [00:45<01:08, 67.81 examples/s]Tokenizing train dataset:  47%|████▋     | 4036/8564 [00:44<00:36, 123.69 examples/s]Tokenizing train dataset:  49%|████▉     | 4225/8564 [00:44<00:37, 116.63 examples/s]Tokenizing train dataset:  46%|████▌     | 3920/8564 [00:45<01:07, 69.05 examples/s]Tokenizing train dataset:  47%|████▋     | 4054/8564 [00:44<00:37, 118.70 examples/s]Tokenizing train dataset:  49%|████▉     | 4239/8564 [00:44<00:37, 115.53 examples/s]Tokenizing train dataset:  46%|████▌     | 3929/8564 [00:45<01:02, 73.74 examples/s]Tokenizing train dataset:  47%|████▋     | 4067/8564 [00:44<00:37, 120.53 examples/s]Tokenizing train dataset:  50%|████▉     | 4257/8564 [00:44<00:37, 116.38 examples/s]Tokenizing train dataset:  46%|████▌     | 3938/8564 [00:45<01:04, 72.18 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:44<00:38, 117.18 examples/s]Tokenizing train dataset:  50%|████▉     | 4270/8564 [00:45<00:37, 114.87 examples/s]Tokenizing train dataset:  46%|████▌     | 3946/8564 [00:45<01:06, 69.44 examples/s]Tokenizing train dataset:  48%|████▊     | 4098/8564 [00:44<00:39, 113.39 examples/s]Tokenizing train dataset:  50%|█████     | 4284/8564 [00:45<00:36, 115.83 examples/s]Tokenizing train dataset:  46%|████▌     | 3956/8564 [00:45<01:02, 73.43 examples/s]Tokenizing train dataset:  48%|████▊     | 4113/8564 [00:45<00:38, 116.16 examples/s]Tokenizing train dataset:  50%|█████     | 4302/8564 [00:45<00:36, 115.93 examples/s]Tokenizing train dataset:  46%|████▋     | 3964/8564 [00:45<01:06, 69.47 examples/s]Tokenizing train dataset:  48%|████▊     | 4126/8564 [00:45<00:38, 114.41 examples/s]Tokenizing train dataset:  50%|█████     | 4315/8564 [00:45<00:35, 118.42 examples/s]Tokenizing train dataset:  46%|████▋     | 3975/8564 [00:45<01:01, 74.75 examples/s]Tokenizing train dataset:  51%|█████     | 4327/8564 [00:45<00:36, 115.64 examples/s]Tokenizing train dataset:  48%|████▊     | 4144/8564 [00:45<00:39, 112.09 examples/s]Tokenizing train dataset:  47%|████▋     | 3984/8564 [00:46<01:09, 66.28 examples/s]Tokenizing train dataset:  49%|████▊     | 4156/8564 [00:45<00:40, 108.86 examples/s]Tokenizing train dataset:  51%|█████     | 4341/8564 [00:45<00:43, 97.29 examples/s] Tokenizing train dataset:  47%|████▋     | 3998/8564 [00:46<00:55, 81.59 examples/s]Tokenizing train dataset:  49%|████▊     | 4167/8564 [00:45<00:41, 105.87 examples/s]Tokenizing train dataset:  51%|█████     | 4357/8564 [00:45<00:39, 106.87 examples/s]Tokenizing train dataset:  47%|████▋     | 4009/8564 [00:46<00:58, 78.23 examples/s]Tokenizing train dataset:  51%|█████     | 4372/8564 [00:45<00:35, 116.75 examples/s]Tokenizing train dataset:  49%|████▉     | 4183/8564 [00:45<00:43, 100.85 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:46<00:57, 79.67 examples/s]Tokenizing train dataset:  51%|█████     | 4385/8564 [00:46<00:37, 111.80 examples/s]Tokenizing train dataset:  49%|████▉     | 4201/8564 [00:45<00:37, 116.07 examples/s]Tokenizing train dataset:  47%|████▋     | 4036/8564 [00:46<00:48, 94.14 examples/s]Tokenizing train dataset:  51%|█████▏    | 4400/8564 [00:46<00:34, 119.47 examples/s]Tokenizing train dataset:  49%|████▉     | 4218/8564 [00:45<00:38, 111.79 examples/s]Tokenizing train dataset:  47%|████▋     | 4050/8564 [00:46<00:43, 103.47 examples/s]Tokenizing train dataset:  49%|████▉     | 4230/8564 [00:46<00:39, 108.88 examples/s]Tokenizing train dataset:  52%|█████▏    | 4415/8564 [00:46<00:41, 100.43 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:46<00:41, 107.96 examples/s]Tokenizing train dataset:  50%|████▉     | 4242/8564 [00:46<00:40, 106.30 examples/s]Tokenizing train dataset:  48%|████▊     | 4077/8564 [00:46<00:41, 108.78 examples/s]Tokenizing train dataset:  52%|█████▏    | 4430/8564 [00:46<00:45, 91.01 examples/s] Tokenizing train dataset:  50%|████▉     | 4257/8564 [00:46<00:37, 114.72 examples/s]Tokenizing train dataset:  48%|████▊     | 4090/8564 [00:47<00:40, 109.68 examples/s]Tokenizing train dataset:  52%|█████▏    | 4440/8564 [00:46<00:46, 88.16 examples/s]Tokenizing train dataset:  48%|████▊     | 4102/8564 [00:47<00:39, 112.32 examples/s]Tokenizing train dataset:  50%|████▉     | 4274/8564 [00:46<00:38, 112.81 examples/s]Tokenizing train dataset:  50%|█████     | 4288/8564 [00:46<00:36, 117.88 examples/s]Tokenizing train dataset:  48%|████▊     | 4116/8564 [00:47<00:38, 114.12 examples/s]Tokenizing train dataset:  52%|█████▏    | 4452/8564 [00:46<00:50, 81.94 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:46<00:37, 114.77 examples/s]Tokenizing train dataset:  48%|████▊     | 4129/8564 [00:47<00:39, 113.65 examples/s]Tokenizing train dataset:  52%|█████▏    | 4463/8564 [00:47<00:53, 76.41 examples/s]Tokenizing train dataset:  50%|█████     | 4315/8564 [00:46<00:36, 117.38 examples/s]Tokenizing train dataset:  48%|████▊     | 4146/8564 [00:47<00:39, 111.43 examples/s]Tokenizing train dataset:  52%|█████▏    | 4471/8564 [00:47<00:53, 75.83 examples/s]Tokenizing train dataset:  51%|█████     | 4327/8564 [00:46<00:36, 117.48 examples/s]Tokenizing train dataset:  49%|████▊     | 4158/8564 [00:47<00:40, 108.94 examples/s]Tokenizing train dataset:  52%|█████▏    | 4480/8564 [00:47<00:52, 77.60 examples/s]Tokenizing train dataset:  51%|█████     | 4339/8564 [00:47<00:36, 116.51 examples/s]Tokenizing train dataset:  49%|████▊     | 4172/8564 [00:47<00:38, 113.57 examples/s]Tokenizing train dataset:  52%|█████▏    | 4490/8564 [00:47<00:51, 78.56 examples/s]Tokenizing train dataset:  51%|█████     | 4352/8564 [00:47<00:39, 106.46 examples/s]Tokenizing train dataset:  49%|████▉     | 4188/8564 [00:47<00:36, 119.93 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:47<00:52, 78.03 examples/s]Tokenizing train dataset:  51%|█████     | 4366/8564 [00:47<00:36, 113.68 examples/s]Tokenizing train dataset:  49%|████▉     | 4203/8564 [00:48<00:36, 120.86 examples/s]Tokenizing train dataset:  53%|█████▎    | 4510/8564 [00:47<00:48, 82.84 examples/s]Tokenizing train dataset:  51%|█████     | 4379/8564 [00:47<00:35, 116.87 examples/s]Tokenizing train dataset:  53%|█████▎    | 4522/8564 [00:47<00:44, 90.79 examples/s]Tokenizing train dataset:  51%|█████▏    | 4394/8564 [00:47<00:35, 116.47 examples/s]Tokenizing train dataset:  49%|████▉     | 4219/8564 [00:48<00:44, 98.51 examples/s] Tokenizing train dataset:  53%|█████▎    | 4537/8564 [00:47<00:38, 105.49 examples/s]Tokenizing train dataset:  52%|█████▏    | 4412/8564 [00:47<00:39, 105.08 examples/s]Tokenizing train dataset:  49%|████▉     | 4230/8564 [00:48<00:49, 87.40 examples/s]Tokenizing train dataset:  53%|█████▎    | 4555/8564 [00:48<00:37, 105.82 examples/s]Tokenizing train dataset:  52%|█████▏    | 4425/8564 [00:47<00:37, 110.18 examples/s]Tokenizing train dataset:  53%|█████▎    | 4568/8564 [00:48<00:36, 110.14 examples/s]Tokenizing train dataset:  50%|████▉     | 4240/8564 [00:48<00:50, 84.81 examples/s]Tokenizing train dataset:  52%|█████▏    | 4437/8564 [00:47<00:38, 107.42 examples/s]Tokenizing train dataset:  50%|████▉     | 4250/8564 [00:48<00:50, 84.83 examples/s]Tokenizing train dataset:  54%|█████▎    | 4583/8564 [00:48<00:39, 100.72 examples/s]Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:48<00:38, 105.53 examples/s]Tokenizing train dataset:  50%|████▉     | 4262/8564 [00:48<00:48, 89.11 examples/s]Tokenizing train dataset:  52%|█████▏    | 4462/8564 [00:48<00:39, 104.21 examples/s]Tokenizing train dataset:  54%|█████▎    | 4600/8564 [00:48<00:38, 102.46 examples/s]Tokenizing train dataset:  50%|████▉     | 4274/8564 [00:48<00:51, 83.20 examples/s]Tokenizing train dataset:  52%|█████▏    | 4481/8564 [00:48<00:32, 125.26 examples/s]Tokenizing train dataset:  54%|█████▍    | 4611/8564 [00:48<00:43, 90.05 examples/s] Tokenizing train dataset:  50%|█████     | 4288/8564 [00:49<00:45, 93.19 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:48<00:34, 118.35 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:49<00:44, 96.50 examples/s]Tokenizing train dataset:  54%|█████▍    | 4625/8564 [00:48<00:44, 87.67 examples/s]Tokenizing train dataset:  53%|█████▎    | 4512/8564 [00:48<00:36, 112.11 examples/s]Tokenizing train dataset:  50%|█████     | 4313/8564 [00:49<00:41, 102.25 examples/s]Tokenizing train dataset:  53%|█████▎    | 4525/8564 [00:48<00:35, 113.54 examples/s]Tokenizing train dataset:  54%|█████▍    | 4634/8564 [00:48<00:52, 75.32 examples/s]Tokenizing train dataset:  51%|█████     | 4326/8564 [00:49<00:40, 104.88 examples/s]Tokenizing train dataset:  53%|█████▎    | 4540/8564 [00:48<00:33, 121.73 examples/s]Tokenizing train dataset:  54%|█████▍    | 4644/8564 [00:49<00:53, 73.53 examples/s]Tokenizing train dataset:  51%|█████     | 4339/8564 [00:49<00:41, 101.67 examples/s]Tokenizing train dataset:  53%|█████▎    | 4553/8564 [00:48<00:33, 119.91 examples/s]Tokenizing train dataset:  51%|█████     | 4353/8564 [00:49<00:39, 105.67 examples/s]Tokenizing train dataset:  53%|█████▎    | 4567/8564 [00:49<00:32, 124.40 examples/s]Tokenizing train dataset:  54%|█████▍    | 4655/8564 [00:49<00:56, 68.91 examples/s]Tokenizing train dataset:  51%|█████     | 4365/8564 [00:49<00:38, 109.03 examples/s]Tokenizing train dataset:  54%|█████▍    | 4663/8564 [00:49<00:58, 66.61 examples/s]Tokenizing train dataset:  51%|█████     | 4379/8564 [00:49<00:37, 112.64 examples/s]Tokenizing train dataset:  54%|█████▎    | 4582/8564 [00:49<00:37, 106.49 examples/s]Tokenizing train dataset:  55%|█████▍    | 4672/8564 [00:49<00:56, 68.30 examples/s]Tokenizing train dataset:  51%|█████▏    | 4394/8564 [00:49<00:34, 121.07 examples/s]Tokenizing train dataset:  54%|█████▎    | 4598/8564 [00:49<00:34, 113.48 examples/s]Tokenizing train dataset:  51%|█████▏    | 4407/8564 [00:50<00:34, 121.51 examples/s]Tokenizing train dataset:  55%|█████▍    | 4680/8564 [00:49<00:58, 66.00 examples/s]Tokenizing train dataset:  54%|█████▍    | 4611/8564 [00:49<00:34, 114.05 examples/s]Tokenizing train dataset:  52%|█████▏    | 4420/8564 [00:50<00:35, 117.06 examples/s]Tokenizing train dataset:  55%|█████▍    | 4687/8564 [00:49<01:02, 62.32 examples/s]Tokenizing train dataset:  54%|█████▍    | 4627/8564 [00:49<00:32, 119.55 examples/s]Tokenizing train dataset:  52%|█████▏    | 4433/8564 [00:50<00:34, 120.04 examples/s]Tokenizing train dataset:  55%|█████▍    | 4699/8564 [00:49<00:51, 75.10 examples/s]Tokenizing train dataset:  52%|█████▏    | 4447/8564 [00:50<00:34, 118.98 examples/s]Tokenizing train dataset:  55%|█████▍    | 4710/8564 [00:50<00:49, 78.63 examples/s]Tokenizing train dataset:  54%|█████▍    | 4640/8564 [00:49<00:44, 88.09 examples/s] Tokenizing train dataset:  55%|█████▌    | 4721/8564 [00:50<00:45, 84.35 examples/s]Tokenizing train dataset:  52%|█████▏    | 4464/8564 [00:50<00:36, 113.36 examples/s]Tokenizing train dataset:  55%|█████▌    | 4737/8564 [00:50<00:38, 98.76 examples/s]Tokenizing train dataset:  54%|█████▍    | 4654/8564 [00:50<00:49, 79.77 examples/s]Tokenizing train dataset:  52%|█████▏    | 4480/8564 [00:50<00:34, 118.67 examples/s]Tokenizing train dataset:  55%|█████▌    | 4748/8564 [00:50<00:38, 99.97 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:50<00:34, 119.41 examples/s]Tokenizing train dataset:  54%|█████▍    | 4665/8564 [00:50<00:52, 74.46 examples/s]Tokenizing train dataset:  56%|█████▌    | 4763/8564 [00:50<00:39, 95.32 examples/s]Tokenizing train dataset:  53%|█████▎    | 4512/8564 [00:51<00:36, 111.89 examples/s]Tokenizing train dataset:  55%|█████▍    | 4675/8564 [00:50<00:58, 66.95 examples/s]Tokenizing train dataset:  56%|█████▌    | 4773/8564 [00:50<00:41, 91.73 examples/s]Tokenizing train dataset:  53%|█████▎    | 4524/8564 [00:51<00:37, 108.11 examples/s]Tokenizing train dataset:  56%|█████▌    | 4784/8564 [00:50<00:40, 92.94 examples/s]Tokenizing train dataset:  55%|█████▍    | 4685/8564 [00:50<00:57, 67.01 examples/s]Tokenizing train dataset:  53%|█████▎    | 4540/8564 [00:51<00:33, 119.04 examples/s]Tokenizing train dataset:  53%|█████▎    | 4555/8564 [00:51<00:32, 122.35 examples/s]Tokenizing train dataset:  55%|█████▍    | 4696/8564 [00:50<00:54, 70.49 examples/s]Tokenizing train dataset:  56%|█████▌    | 4798/8564 [00:51<00:45, 83.05 examples/s]Tokenizing train dataset:  53%|█████▎    | 4568/8564 [00:51<00:33, 118.82 examples/s]Tokenizing train dataset:  56%|█████▌    | 4816/8564 [00:51<00:38, 96.30 examples/s]Tokenizing train dataset:  55%|█████▍    | 4708/8564 [00:50<00:59, 64.70 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:51<00:36, 108.96 examples/s]Tokenizing train dataset:  57%|█████▋    | 4840/8564 [00:51<00:29, 127.64 examples/s]Tokenizing train dataset:  55%|█████▌    | 4717/8564 [00:51<00:58, 65.70 examples/s]Tokenizing train dataset:  57%|█████▋    | 4860/8564 [00:51<00:25, 144.36 examples/s]Tokenizing train dataset:  54%|█████▎    | 4595/8564 [00:51<00:39, 99.25 examples/s] Tokenizing train dataset:  55%|█████▌    | 4725/8564 [00:51<00:57, 66.31 examples/s]Tokenizing train dataset:  57%|█████▋    | 4879/8564 [00:51<00:24, 150.19 examples/s]Tokenizing train dataset:  54%|█████▍    | 4606/8564 [00:51<00:43, 91.75 examples/s]Tokenizing train dataset:  55%|█████▌    | 4734/8564 [00:51<00:55, 69.36 examples/s]Tokenizing train dataset:  57%|█████▋    | 4896/8564 [00:51<00:24, 152.56 examples/s]Tokenizing train dataset:  54%|█████▍    | 4616/8564 [00:52<00:45, 87.36 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:51<00:57, 66.64 examples/s]Tokenizing train dataset:  57%|█████▋    | 4921/8564 [00:51<00:20, 173.58 examples/s]Tokenizing train dataset:  58%|█████▊    | 4943/8564 [00:51<00:19, 185.38 examples/s]Tokenizing train dataset:  55%|█████▌    | 4750/8564 [00:51<00:57, 65.95 examples/s]Tokenizing train dataset:  54%|█████▍    | 4626/8564 [00:52<00:49, 79.76 examples/s]Tokenizing train dataset:  56%|█████▌    | 4758/8564 [00:51<00:58, 65.32 examples/s]Tokenizing train dataset:  58%|█████▊    | 4969/8564 [00:51<00:20, 177.58 examples/s]Tokenizing train dataset:  54%|█████▍    | 4642/8564 [00:52<00:46, 84.96 examples/s]Tokenizing train dataset:  58%|█████▊    | 4998/8564 [00:52<00:17, 199.14 examples/s]Tokenizing train dataset:  56%|█████▌    | 4768/8564 [00:51<00:57, 66.10 examples/s]Tokenizing train dataset:  54%|█████▍    | 4652/8564 [00:52<00:46, 83.47 examples/s]Tokenizing train dataset:  54%|█████▍    | 4662/8564 [00:52<00:44, 86.94 examples/s]Tokenizing train dataset:  59%|█████▊    | 5027/8564 [00:52<00:18, 194.99 examples/s]Tokenizing train dataset:  56%|█████▌    | 4778/8564 [00:52<01:02, 60.88 examples/s]Tokenizing train dataset:  55%|█████▍    | 4673/8564 [00:52<00:43, 90.38 examples/s]Tokenizing train dataset:  59%|█████▉    | 5049/8564 [00:52<00:17, 198.59 examples/s]Tokenizing train dataset:  56%|█████▌    | 4788/8564 [00:52<00:57, 65.58 examples/s]Tokenizing train dataset:  59%|█████▉    | 5072/8564 [00:52<00:16, 206.07 examples/s]Tokenizing train dataset:  55%|█████▍    | 4685/8564 [00:52<00:41, 93.34 examples/s]Tokenizing train dataset:  56%|█████▌    | 4796/8564 [00:52<00:56, 67.21 examples/s]Tokenizing train dataset:  59%|█████▉    | 5093/8564 [00:52<00:16, 206.11 examples/s]Tokenizing train dataset:  55%|█████▍    | 4696/8564 [00:53<00:43, 87.91 examples/s]Tokenizing train dataset:  56%|█████▌    | 4810/8564 [00:52<00:47, 79.78 examples/s]Tokenizing train dataset:  60%|█████▉    | 5116/8564 [00:52<00:16, 203.56 examples/s]Tokenizing train dataset:  55%|█████▍    | 4706/8564 [00:53<00:43, 88.12 examples/s]Tokenizing train dataset:  60%|██████    | 5140/8564 [00:52<00:16, 207.48 examples/s]Tokenizing train dataset:  56%|█████▋    | 4830/8564 [00:52<00:36, 101.25 examples/s]Tokenizing train dataset:  60%|██████    | 5165/8564 [00:52<00:16, 210.79 examples/s]Tokenizing train dataset:  57%|█████▋    | 4849/8564 [00:52<00:31, 116.83 examples/s]Tokenizing train dataset:  55%|█████▌    | 4720/8564 [00:53<00:46, 82.09 examples/s]Tokenizing train dataset:  55%|█████▌    | 4736/8564 [00:53<00:40, 93.61 examples/s]Tokenizing train dataset:  61%|██████    | 5200/8564 [00:53<00:16, 204.79 examples/s]Tokenizing train dataset:  57%|█████▋    | 4869/8564 [00:52<00:32, 112.95 examples/s]Tokenizing train dataset:  55%|█████▌    | 4748/8564 [00:53<00:41, 92.82 examples/s]Tokenizing train dataset:  61%|██████    | 5225/8564 [00:53<00:15, 208.93 examples/s]Tokenizing train dataset:  57%|█████▋    | 4885/8564 [00:52<00:33, 109.73 examples/s]Tokenizing train dataset:  56%|█████▌    | 4758/8564 [00:53<00:41, 91.90 examples/s]Tokenizing train dataset:  61%|██████▏   | 5250/8564 [00:53<00:17, 188.33 examples/s]Tokenizing train dataset:  57%|█████▋    | 4906/8564 [00:53<00:28, 129.63 examples/s]Tokenizing train dataset:  56%|█████▌    | 4770/8564 [00:53<00:44, 85.71 examples/s]Tokenizing train dataset:  58%|█████▊    | 4929/8564 [00:53<00:24, 146.33 examples/s]Tokenizing train dataset:  62%|██████▏   | 5273/8564 [00:53<00:17, 183.20 examples/s]Tokenizing train dataset:  56%|█████▌    | 4780/8564 [00:53<00:43, 87.75 examples/s]Tokenizing train dataset:  58%|█████▊    | 4945/8564 [00:53<00:24, 147.91 examples/s]Tokenizing train dataset:  56%|█████▌    | 4792/8564 [00:54<00:40, 93.11 examples/s]Tokenizing train dataset:  58%|█████▊    | 4963/8564 [00:53<00:23, 155.68 examples/s]Tokenizing train dataset:  62%|██████▏   | 5306/8564 [00:53<00:19, 170.98 examples/s]Tokenizing train dataset:  56%|█████▌    | 4803/8564 [00:54<00:41, 90.95 examples/s]Tokenizing train dataset:  58%|█████▊    | 4989/8564 [00:53<00:21, 169.73 examples/s]Tokenizing train dataset:  62%|██████▏   | 5329/8564 [00:53<00:20, 155.85 examples/s]Tokenizing train dataset:  56%|█████▋    | 4821/8564 [00:54<00:33, 110.78 examples/s]Tokenizing train dataset:  59%|█████▊    | 5016/8564 [00:53<00:21, 163.86 examples/s]Tokenizing train dataset:  62%|██████▏   | 5349/8564 [00:53<00:19, 163.69 examples/s]Tokenizing train dataset:  56%|█████▋    | 4837/8564 [00:54<00:33, 112.72 examples/s]Tokenizing train dataset:  63%|██████▎   | 5368/8564 [00:54<00:18, 168.98 examples/s]Tokenizing train dataset:  57%|█████▋    | 4859/8564 [00:54<00:28, 132.00 examples/s]Tokenizing train dataset:  59%|█████▉    | 5034/8564 [00:53<00:27, 129.09 examples/s]Tokenizing train dataset:  63%|██████▎   | 5389/8564 [00:54<00:20, 154.09 examples/s]Tokenizing train dataset:  57%|█████▋    | 4874/8564 [00:54<00:30, 119.48 examples/s]Tokenizing train dataset:  59%|█████▉    | 5060/8564 [00:54<00:22, 153.90 examples/s]Tokenizing train dataset:  63%|██████▎   | 5407/8564 [00:54<00:19, 159.45 examples/s]Tokenizing train dataset:  59%|█████▉    | 5085/8564 [00:54<00:19, 174.17 examples/s]Tokenizing train dataset:  63%|██████▎   | 5437/8564 [00:54<00:16, 192.24 examples/s]Tokenizing train dataset:  57%|█████▋    | 4889/8564 [00:54<00:32, 113.49 examples/s]Tokenizing train dataset:  57%|█████▋    | 4910/8564 [00:54<00:27, 133.34 examples/s]Tokenizing train dataset:  60%|█████▉    | 5111/8564 [00:54<00:21, 159.86 examples/s]Tokenizing train dataset:  64%|██████▍   | 5464/8564 [00:54<00:17, 179.23 examples/s]Tokenizing train dataset:  60%|██████    | 5139/8564 [00:54<00:18, 185.62 examples/s]Tokenizing train dataset:  58%|█████▊    | 4927/8564 [00:55<00:28, 126.95 examples/s]Tokenizing train dataset:  64%|██████▍   | 5483/8564 [00:54<00:17, 180.13 examples/s]Tokenizing train dataset:  58%|█████▊    | 4943/8564 [00:55<00:27, 130.50 examples/s]Tokenizing train dataset:  64%|██████▍   | 5508/8564 [00:54<00:15, 192.98 examples/s]Tokenizing train dataset:  60%|██████    | 5168/8564 [00:54<00:20, 162.64 examples/s]Tokenizing train dataset:  58%|█████▊    | 4963/8564 [00:55<00:24, 144.38 examples/s]Tokenizing train dataset:  65%|██████▍   | 5530/8564 [00:54<00:15, 198.43 examples/s]Tokenizing train dataset:  61%|██████    | 5191/8564 [00:54<00:21, 158.72 examples/s]Tokenizing train dataset:  65%|██████▍   | 5555/8564 [00:55<00:16, 179.25 examples/s]Tokenizing train dataset:  58%|█████▊    | 4990/8564 [00:55<00:26, 133.74 examples/s]Tokenizing train dataset:  65%|██████▌   | 5580/8564 [00:55<00:16, 182.08 examples/s]Tokenizing train dataset:  59%|█████▊    | 5010/8564 [00:55<00:24, 142.89 examples/s]Tokenizing train dataset:  61%|██████    | 5220/8564 [00:55<00:23, 141.77 examples/s]Tokenizing train dataset:  65%|██████▌   | 5601/8564 [00:55<00:15, 186.14 examples/s]Tokenizing train dataset:  59%|█████▊    | 5026/8564 [00:55<00:25, 139.48 examples/s]Tokenizing train dataset:  61%|██████    | 5242/8564 [00:55<00:21, 152.71 examples/s]Tokenizing train dataset:  66%|██████▌   | 5630/8564 [00:55<00:14, 206.24 examples/s]Tokenizing train dataset:  59%|█████▉    | 5051/8564 [00:55<00:21, 161.64 examples/s]Tokenizing train dataset:  61%|██████▏   | 5260/8564 [00:55<00:21, 154.39 examples/s]Tokenizing train dataset:  66%|██████▌   | 5656/8564 [00:55<00:13, 215.85 examples/s]Tokenizing train dataset:  59%|█████▉    | 5079/8564 [00:56<00:18, 183.66 examples/s]Tokenizing train dataset:  62%|██████▏   | 5283/8564 [00:55<00:19, 169.69 examples/s]Tokenizing train dataset:  66%|██████▋   | 5682/8564 [00:55<00:14, 196.81 examples/s]Tokenizing train dataset:  60%|█████▉    | 5099/8564 [00:56<00:19, 181.41 examples/s]Tokenizing train dataset:  62%|██████▏   | 5305/8564 [00:55<00:20, 157.37 examples/s]Tokenizing train dataset:  60%|█████▉    | 5129/8564 [00:56<00:18, 185.16 examples/s]Tokenizing train dataset:  67%|██████▋   | 5704/8564 [00:55<00:16, 171.20 examples/s]Tokenizing train dataset:  60%|██████    | 5152/8564 [00:56<00:17, 195.39 examples/s]Tokenizing train dataset:  67%|██████▋   | 5726/8564 [00:56<00:15, 178.38 examples/s]Tokenizing train dataset:  62%|██████▏   | 5325/8564 [00:55<00:25, 127.79 examples/s]Tokenizing train dataset:  60%|██████    | 5178/8564 [00:56<00:16, 200.43 examples/s]Tokenizing train dataset:  67%|██████▋   | 5755/8564 [00:56<00:15, 180.47 examples/s]Tokenizing train dataset:  62%|██████▏   | 5340/8564 [00:55<00:24, 130.80 examples/s]Tokenizing train dataset:  61%|██████    | 5200/8564 [00:56<00:17, 195.00 examples/s]Tokenizing train dataset:  63%|██████▎   | 5358/8564 [00:55<00:22, 139.59 examples/s]Tokenizing train dataset:  67%|██████▋   | 5780/8564 [00:56<00:15, 183.27 examples/s]Tokenizing train dataset:  61%|██████    | 5220/8564 [00:56<00:18, 182.02 examples/s]Tokenizing train dataset:  68%|██████▊   | 5811/8564 [00:56<00:13, 205.31 examples/s]Tokenizing train dataset:  63%|██████▎   | 5380/8564 [00:56<00:24, 127.56 examples/s]Tokenizing train dataset:  61%|██████    | 5245/8564 [00:56<00:20, 164.84 examples/s]Tokenizing train dataset:  68%|██████▊   | 5842/8564 [00:56<00:13, 197.15 examples/s]Tokenizing train dataset:  63%|██████▎   | 5397/8564 [00:56<00:26, 119.69 examples/s]Tokenizing train dataset:  62%|██████▏   | 5272/8564 [00:57<00:18, 177.13 examples/s]Tokenizing train dataset:  63%|██████▎   | 5420/8564 [00:56<00:22, 142.37 examples/s]Tokenizing train dataset:  68%|██████▊   | 5864/8564 [00:56<00:16, 161.30 examples/s]Tokenizing train dataset:  62%|██████▏   | 5294/8564 [00:57<00:20, 160.00 examples/s]Tokenizing train dataset:  64%|██████▎   | 5448/8564 [00:56<00:18, 168.34 examples/s]Tokenizing train dataset:  69%|██████▉   | 5888/8564 [00:56<00:17, 153.32 examples/s]Tokenizing train dataset:  64%|██████▍   | 5473/8564 [00:56<00:19, 160.35 examples/s]Tokenizing train dataset:  62%|██████▏   | 5320/8564 [00:57<00:21, 147.81 examples/s]Tokenizing train dataset:  64%|██████▍   | 5495/8564 [00:56<00:17, 173.10 examples/s]Tokenizing train dataset:  69%|██████▉   | 5910/8564 [00:57<00:18, 145.44 examples/s]Tokenizing train dataset:  64%|██████▍   | 5514/8564 [00:56<00:17, 175.92 examples/s]Tokenizing train dataset:  62%|██████▏   | 5338/8564 [00:57<00:24, 132.98 examples/s]Tokenizing train dataset:  69%|██████▉   | 5928/8564 [00:57<00:18, 143.59 examples/s]Tokenizing train dataset:  65%|██████▍   | 5534/8564 [00:57<00:16, 179.17 examples/s]Tokenizing train dataset:  63%|██████▎   | 5356/8564 [00:57<00:23, 136.68 examples/s]Tokenizing train dataset:  69%|██████▉   | 5944/8564 [00:57<00:18, 143.97 examples/s]Tokenizing train dataset:  65%|██████▍   | 5562/8564 [00:57<00:16, 179.04 examples/s]Tokenizing train dataset:  70%|██████▉   | 5960/8564 [00:57<00:18, 141.80 examples/s]Tokenizing train dataset:  63%|██████▎   | 5374/8564 [00:57<00:24, 128.21 examples/s]Tokenizing train dataset:  65%|██████▌   | 5587/8564 [00:57<00:15, 191.02 examples/s]Tokenizing train dataset:  63%|██████▎   | 5390/8564 [00:58<00:23, 132.77 examples/s]Tokenizing train dataset:  65%|██████▌   | 5608/8564 [00:57<00:15, 186.12 examples/s]Tokenizing train dataset:  63%|██████▎   | 5406/8564 [00:58<00:24, 128.27 examples/s]Tokenizing train dataset:  63%|██████▎   | 5429/8564 [00:58<00:21, 145.49 examples/s]Tokenizing train dataset:  66%|██████▌   | 5631/8564 [00:57<00:17, 166.17 examples/s]Tokenizing train dataset:  64%|██████▎   | 5446/8564 [00:58<00:21, 145.50 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [00:58<00:32, 78.51 examples/s] Tokenizing train dataset:  66%|██████▌   | 5658/8564 [00:57<00:17, 162.84 examples/s]Tokenizing train dataset:  70%|███████   | 6004/8564 [00:58<00:25, 100.04 examples/s]Tokenizing train dataset:  64%|██████▍   | 5465/8564 [00:58<00:22, 137.39 examples/s]Tokenizing train dataset:  70%|███████   | 6023/8564 [00:58<00:22, 112.84 examples/s]Tokenizing train dataset:  66%|██████▋   | 5678/8564 [00:57<00:20, 143.17 examples/s]Tokenizing train dataset:  64%|██████▍   | 5483/8564 [00:58<00:22, 136.54 examples/s]Tokenizing train dataset:  71%|███████   | 6050/8564 [00:58<00:18, 139.22 examples/s]Tokenizing train dataset:  66%|██████▋   | 5694/8564 [00:58<00:20, 139.34 examples/s]Tokenizing train dataset:  64%|██████▍   | 5504/8564 [00:58<00:19, 153.60 examples/s]Tokenizing train dataset:  71%|███████   | 6072/8564 [00:58<00:16, 154.34 examples/s]Tokenizing train dataset:  67%|██████▋   | 5713/8564 [00:58<00:19, 143.62 examples/s]Tokenizing train dataset:  65%|██████▍   | 5527/8564 [00:58<00:18, 165.93 examples/s]Tokenizing train dataset:  71%|███████   | 6091/8564 [00:58<00:16, 148.85 examples/s]Tokenizing train dataset:  65%|██████▍   | 5549/8564 [00:59<00:17, 172.26 examples/s]Tokenizing train dataset:  71%|███████▏  | 6113/8564 [00:58<00:15, 160.03 examples/s]Tokenizing train dataset:  67%|██████▋   | 5740/8564 [00:58<00:20, 136.14 examples/s]Tokenizing train dataset:  65%|██████▌   | 5575/8564 [00:59<00:17, 171.82 examples/s]Tokenizing train dataset:  72%|███████▏  | 6141/8564 [00:58<00:13, 186.35 examples/s]Tokenizing train dataset:  67%|██████▋   | 5760/8564 [00:58<00:18, 147.99 examples/s]Tokenizing train dataset:  72%|███████▏  | 6170/8564 [00:58<00:11, 202.41 examples/s]Tokenizing train dataset:  68%|██████▊   | 5794/8564 [00:58<00:14, 186.28 examples/s]Tokenizing train dataset:  65%|██████▌   | 5603/8564 [00:59<00:17, 166.59 examples/s]Tokenizing train dataset:  68%|██████▊   | 5824/8564 [00:58<00:13, 206.67 examples/s]Tokenizing train dataset:  66%|██████▌   | 5624/8564 [00:59<00:16, 173.48 examples/s]Tokenizing train dataset:  72%|███████▏  | 6196/8564 [00:59<00:13, 179.81 examples/s]Tokenizing train dataset:  68%|██████▊   | 5851/8564 [00:58<00:14, 192.30 examples/s]Tokenizing train dataset:  66%|██████▌   | 5648/8564 [00:59<00:18, 159.08 examples/s]Tokenizing train dataset:  73%|███████▎  | 6219/8564 [00:59<00:13, 176.78 examples/s]Tokenizing train dataset:  73%|███████▎  | 6240/8564 [00:59<00:12, 183.29 examples/s]Tokenizing train dataset:  69%|██████▊   | 5878/8564 [00:59<00:14, 186.66 examples/s]Tokenizing train dataset:  66%|██████▌   | 5670/8564 [00:59<00:18, 157.89 examples/s]Tokenizing train dataset:  69%|██████▉   | 5898/8564 [00:59<00:14, 187.98 examples/s]Tokenizing train dataset:  73%|███████▎  | 6267/8564 [00:59<00:11, 193.65 examples/s]Tokenizing train dataset:  66%|██████▋   | 5690/8564 [00:59<00:17, 164.35 examples/s]Tokenizing train dataset:  69%|██████▉   | 5926/8564 [00:59<00:13, 200.19 examples/s]Tokenizing train dataset:  67%|██████▋   | 5715/8564 [01:00<00:17, 164.08 examples/s]Tokenizing train dataset:  73%|███████▎  | 6290/8564 [00:59<00:13, 167.55 examples/s]Tokenizing train dataset:  69%|██████▉   | 5949/8564 [00:59<00:12, 205.11 examples/s]Tokenizing train dataset:  70%|██████▉   | 5975/8564 [00:59<00:12, 212.16 examples/s]Tokenizing train dataset:  74%|███████▍  | 6317/8564 [00:59<00:13, 167.66 examples/s]Tokenizing train dataset:  67%|██████▋   | 5737/8564 [01:00<00:19, 146.29 examples/s]Tokenizing train dataset:  67%|██████▋   | 5760/8564 [01:00<00:17, 163.91 examples/s]Tokenizing train dataset:  74%|███████▍  | 6339/8564 [00:59<00:12, 172.20 examples/s]Tokenizing train dataset:  67%|██████▋   | 5778/8564 [01:00<00:16, 166.46 examples/s]Tokenizing train dataset:  74%|███████▍  | 6371/8564 [01:00<00:10, 202.32 examples/s]Tokenizing train dataset:  68%|██████▊   | 5800/8564 [01:00<00:15, 175.94 examples/s]Tokenizing train dataset:  70%|███████   | 6000/8564 [00:59<00:19, 132.75 examples/s]Tokenizing train dataset:  75%|███████▍  | 6401/8564 [01:00<00:10, 200.42 examples/s]Tokenizing train dataset:  68%|██████▊   | 5824/8564 [01:00<00:14, 191.62 examples/s]Tokenizing train dataset:  70%|███████   | 6020/8564 [01:00<00:18, 139.94 examples/s]Tokenizing train dataset:  68%|██████▊   | 5844/8564 [01:00<00:14, 191.94 examples/s]Tokenizing train dataset:  75%|███████▌  | 6424/8564 [01:00<00:12, 177.91 examples/s]Tokenizing train dataset:  75%|███████▌  | 6444/8564 [01:00<00:11, 178.89 examples/s]Tokenizing train dataset:  71%|███████   | 6044/8564 [01:00<00:19, 131.92 examples/s]Tokenizing train dataset:  69%|██████▊   | 5868/8564 [01:00<00:15, 170.31 examples/s]Tokenizing train dataset:  71%|███████   | 6064/8564 [01:00<00:18, 135.14 examples/s]Tokenizing train dataset:  69%|██████▉   | 5892/8564 [01:01<00:14, 184.63 examples/s]Tokenizing train dataset:  75%|███████▌  | 6465/8564 [01:00<00:13, 159.61 examples/s]Tokenizing train dataset:  69%|██████▉   | 5919/8564 [01:01<00:13, 200.71 examples/s]Tokenizing train dataset:  71%|███████   | 6080/8564 [01:00<00:19, 126.99 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [01:00<00:12, 161.24 examples/s]Tokenizing train dataset:  69%|██████▉   | 5944/8564 [01:01<00:12, 212.04 examples/s]Tokenizing train dataset:  71%|███████   | 6096/8564 [01:00<00:19, 128.73 examples/s]Tokenizing train dataset:  76%|███████▌  | 6510/8564 [01:00<00:12, 159.81 examples/s]Tokenizing train dataset:  71%|███████▏  | 6112/8564 [01:00<00:18, 130.15 examples/s]Tokenizing train dataset:  70%|██████▉   | 5973/8564 [01:01<00:13, 192.69 examples/s]Tokenizing train dataset:  76%|███████▋  | 6532/8564 [01:01<00:12, 167.63 examples/s]Tokenizing train dataset:  72%|███████▏  | 6132/8564 [01:00<00:17, 138.40 examples/s]Tokenizing train dataset:  72%|███████▏  | 6154/8564 [01:00<00:15, 157.19 examples/s]Tokenizing train dataset:  70%|███████   | 6003/8564 [01:01<00:15, 164.55 examples/s]Tokenizing train dataset:  77%|███████▋  | 6553/8564 [01:01<00:14, 136.60 examples/s]Tokenizing train dataset:  70%|███████   | 6023/8564 [01:01<00:14, 169.43 examples/s]Tokenizing train dataset:  77%|███████▋  | 6573/8564 [01:01<00:14, 138.50 examples/s]Tokenizing train dataset:  72%|███████▏  | 6177/8564 [01:01<00:17, 137.12 examples/s]Tokenizing train dataset:  71%|███████   | 6057/8564 [01:01<00:13, 185.54 examples/s]Tokenizing train dataset:  72%|███████▏  | 6200/8564 [01:01<00:15, 154.57 examples/s]Tokenizing train dataset:  77%|███████▋  | 6590/8564 [01:01<00:15, 123.76 examples/s]Tokenizing train dataset:  71%|███████   | 6077/8564 [01:02<00:13, 183.23 examples/s]Tokenizing train dataset:  73%|███████▎  | 6217/8564 [01:01<00:15, 153.60 examples/s]Tokenizing train dataset:  77%|███████▋  | 6605/8564 [01:01<00:15, 122.65 examples/s]Tokenizing train dataset:  71%|███████▏  | 6102/8564 [01:02<00:13, 175.89 examples/s]Tokenizing train dataset:  73%|███████▎  | 6234/8564 [01:01<00:15, 150.20 examples/s]Tokenizing train dataset:  71%|███████▏  | 6123/8564 [01:02<00:13, 178.33 examples/s]Tokenizing train dataset:  73%|███████▎  | 6252/8564 [01:01<00:14, 156.26 examples/s]Tokenizing train dataset:  77%|███████▋  | 6625/8564 [01:01<00:17, 112.37 examples/s]Tokenizing train dataset:  73%|███████▎  | 6269/8564 [01:01<00:14, 157.92 examples/s]Tokenizing train dataset:  72%|███████▏  | 6151/8564 [01:02<00:12, 195.99 examples/s]Tokenizing train dataset:  78%|███████▊  | 6645/8564 [01:02<00:15, 127.68 examples/s]Tokenizing train dataset:  72%|███████▏  | 6179/8564 [01:02<00:11, 215.33 examples/s]Tokenizing train dataset:  78%|███████▊  | 6660/8564 [01:02<00:14, 131.77 examples/s]Tokenizing train dataset:  73%|███████▎  | 6291/8564 [01:01<00:14, 151.72 examples/s]Tokenizing train dataset:  72%|███████▏  | 6202/8564 [01:02<00:10, 217.38 examples/s]Tokenizing train dataset:  78%|███████▊  | 6675/8564 [01:02<00:14, 129.19 examples/s]Tokenizing train dataset:  74%|███████▎  | 6312/8564 [01:02<00:14, 160.54 examples/s]Tokenizing train dataset:  73%|███████▎  | 6226/8564 [01:02<00:10, 222.63 examples/s]Tokenizing train dataset:  74%|███████▍  | 6335/8564 [01:02<00:12, 178.01 examples/s]Tokenizing train dataset:  78%|███████▊  | 6694/8564 [01:02<00:13, 135.22 examples/s]Tokenizing train dataset:  73%|███████▎  | 6250/8564 [01:02<00:10, 216.37 examples/s]Tokenizing train dataset:  74%|███████▍  | 6363/8564 [01:02<00:10, 203.75 examples/s]Tokenizing train dataset:  78%|███████▊  | 6715/8564 [01:02<00:12, 142.94 examples/s]Tokenizing train dataset:  73%|███████▎  | 6284/8564 [01:03<00:10, 209.83 examples/s]Tokenizing train dataset:  75%|███████▍  | 6397/8564 [01:02<00:10, 201.21 examples/s]Tokenizing train dataset:  79%|███████▊  | 6734/8564 [01:02<00:14, 127.68 examples/s]Tokenizing train dataset:  74%|███████▎  | 6306/8564 [01:03<00:10, 208.53 examples/s]Tokenizing train dataset:  75%|███████▌  | 6428/8564 [01:02<00:10, 198.27 examples/s]Tokenizing train dataset:  79%|███████▉  | 6753/8564 [01:02<00:13, 135.73 examples/s]Tokenizing train dataset:  74%|███████▍  | 6339/8564 [01:03<00:10, 207.51 examples/s]Tokenizing train dataset:  75%|███████▌  | 6451/8564 [01:02<00:10, 203.25 examples/s]Tokenizing train dataset:  79%|███████▉  | 6769/8564 [01:02<00:12, 141.28 examples/s]Tokenizing train dataset:  74%|███████▍  | 6370/8564 [01:03<00:09, 230.85 examples/s]Tokenizing train dataset:  76%|███████▌  | 6479/8564 [01:02<00:10, 189.88 examples/s]Tokenizing train dataset:  79%|███████▉  | 6791/8564 [01:03<00:12, 138.05 examples/s]Tokenizing train dataset:  75%|███████▍  | 6400/8564 [01:03<00:10, 206.49 examples/s]Tokenizing train dataset:  76%|███████▌  | 6500/8564 [01:02<00:10, 190.65 examples/s]Tokenizing train dataset:  80%|███████▉  | 6809/8564 [01:03<00:13, 126.56 examples/s]Tokenizing train dataset:  76%|███████▌  | 6520/8564 [01:03<00:11, 183.37 examples/s]Tokenizing train dataset:  80%|███████▉  | 6823/8564 [01:03<00:13, 127.32 examples/s]Tokenizing train dataset:  75%|███████▌  | 6430/8564 [01:03<00:11, 180.34 examples/s]Tokenizing train dataset:  76%|███████▋  | 6539/8564 [01:03<00:11, 170.75 examples/s]Tokenizing train dataset:  75%|███████▌  | 6452/8564 [01:03<00:11, 187.56 examples/s]Tokenizing train dataset:  80%|███████▉  | 6837/8564 [01:03<00:14, 120.21 examples/s]Tokenizing train dataset:  80%|███████▉  | 6851/8564 [01:03<00:14, 120.94 examples/s]Tokenizing train dataset:  77%|███████▋  | 6560/8564 [01:03<00:13, 148.47 examples/s]Tokenizing train dataset:  76%|███████▌  | 6481/8564 [01:04<00:11, 183.02 examples/s]Tokenizing train dataset:  80%|████████  | 6866/8564 [01:03<00:14, 115.51 examples/s]Tokenizing train dataset:  76%|███████▌  | 6501/8564 [01:04<00:11, 179.72 examples/s]Tokenizing train dataset:  77%|███████▋  | 6579/8564 [01:03<00:14, 139.45 examples/s]Tokenizing train dataset:  80%|████████  | 6889/8564 [01:03<00:11, 142.55 examples/s]Tokenizing train dataset:  76%|███████▌  | 6522/8564 [01:04<00:11, 182.03 examples/s]Tokenizing train dataset:  81%|████████  | 6914/8564 [01:03<00:09, 168.36 examples/s]Tokenizing train dataset:  77%|███████▋  | 6599/8564 [01:03<00:14, 131.34 examples/s]Tokenizing train dataset:  76%|███████▋  | 6543/8564 [01:04<00:12, 163.09 examples/s]Tokenizing train dataset:  81%|████████  | 6938/8564 [01:04<00:08, 186.41 examples/s]Tokenizing train dataset:  77%|███████▋  | 6613/8564 [01:03<00:16, 116.15 examples/s]Tokenizing train dataset:  77%|███████▋  | 6560/8564 [01:04<00:14, 142.06 examples/s]Tokenizing train dataset:  81%|████████▏ | 6969/8564 [01:04<00:09, 175.76 examples/s]Tokenizing train dataset:  77%|███████▋  | 6634/8564 [01:04<00:15, 128.26 examples/s]Tokenizing train dataset:  77%|███████▋  | 6576/8564 [01:04<00:14, 138.45 examples/s]Tokenizing train dataset:  82%|████████▏ | 6991/8564 [01:04<00:08, 177.78 examples/s]Tokenizing train dataset:  78%|███████▊  | 6658/8564 [01:04<00:12, 148.06 examples/s]Tokenizing train dataset:  78%|███████▊  | 6688/8564 [01:04<00:11, 168.08 examples/s]Tokenizing train dataset:  77%|███████▋  | 6601/8564 [01:04<00:14, 131.53 examples/s]Tokenizing train dataset:  82%|████████▏ | 7014/8564 [01:04<00:10, 149.45 examples/s]Tokenizing train dataset:  78%|███████▊  | 6709/8564 [01:04<00:10, 170.61 examples/s]Tokenizing train dataset:  77%|███████▋  | 6616/8564 [01:05<00:16, 118.42 examples/s]Tokenizing train dataset:  82%|████████▏ | 7042/8564 [01:04<00:09, 156.89 examples/s]Tokenizing train dataset:  79%|███████▊  | 6730/8564 [01:04<00:11, 154.00 examples/s]Tokenizing train dataset:  77%|███████▋  | 6631/8564 [01:05<00:15, 121.56 examples/s]Tokenizing train dataset:  82%|████████▏ | 7065/8564 [01:04<00:08, 171.30 examples/s]Tokenizing train dataset:  78%|███████▊  | 6650/8564 [01:05<00:14, 128.47 examples/s]Tokenizing train dataset:  83%|████████▎ | 7089/8564 [01:04<00:07, 184.59 examples/s]Tokenizing train dataset:  79%|███████▉  | 6755/8564 [01:04<00:12, 142.63 examples/s]Tokenizing train dataset:  79%|███████▉  | 6775/8564 [01:04<00:11, 150.81 examples/s]Tokenizing train dataset:  83%|████████▎ | 7117/8564 [01:05<00:08, 180.30 examples/s]Tokenizing train dataset:  78%|███████▊  | 6675/8564 [01:05<00:14, 130.92 examples/s]Tokenizing train dataset:  79%|███████▉  | 6801/8564 [01:04<00:10, 171.19 examples/s]Tokenizing train dataset:  78%|███████▊  | 6705/8564 [01:05<00:11, 166.51 examples/s]Tokenizing train dataset:  83%|████████▎ | 7145/8564 [01:05<00:08, 173.30 examples/s]Tokenizing train dataset:  80%|███████▉  | 6828/8564 [01:05<00:10, 171.49 examples/s]Tokenizing train dataset:  84%|████████▎ | 7165/8564 [01:05<00:07, 178.13 examples/s]Tokenizing train dataset:  79%|███████▊  | 6726/8564 [01:05<00:13, 137.35 examples/s]Tokenizing train dataset:  80%|███████▉  | 6847/8564 [01:05<00:10, 170.12 examples/s]Tokenizing train dataset:  84%|████████▍ | 7195/8564 [01:05<00:07, 194.68 examples/s]Tokenizing train dataset:  79%|███████▉  | 6745/8564 [01:05<00:12, 143.86 examples/s]Tokenizing train dataset:  80%|████████  | 6875/8564 [01:05<00:09, 184.55 examples/s]Tokenizing train dataset:  84%|████████▍ | 7216/8564 [01:05<00:07, 191.10 examples/s]Tokenizing train dataset:  79%|███████▉  | 6763/8564 [01:06<00:12, 144.29 examples/s]Tokenizing train dataset:  81%|████████  | 6898/8564 [01:05<00:08, 193.94 examples/s]Tokenizing train dataset:  85%|████████▍ | 7241/8564 [01:05<00:07, 179.27 examples/s]Tokenizing train dataset:  81%|████████  | 6919/8564 [01:05<00:08, 196.72 examples/s]Tokenizing train dataset:  79%|███████▉  | 6789/8564 [01:06<00:12, 144.88 examples/s]Tokenizing train dataset:  85%|████████▍ | 7261/8564 [01:05<00:07, 183.22 examples/s]Tokenizing train dataset:  81%|████████  | 6946/8564 [01:05<00:07, 215.26 examples/s]Tokenizing train dataset:  85%|████████▌ | 7285/8564 [01:06<00:06, 194.60 examples/s]Tokenizing train dataset:  79%|███████▉  | 6806/8564 [01:06<00:14, 122.15 examples/s]Tokenizing train dataset:  81%|████████▏ | 6969/8564 [01:05<00:08, 190.87 examples/s]Tokenizing train dataset:  85%|████████▌ | 7306/8564 [01:06<00:06, 194.54 examples/s]Tokenizing train dataset:  80%|███████▉  | 6822/8564 [01:06<00:13, 128.18 examples/s]Tokenizing train dataset:  86%|████████▌ | 7326/8564 [01:06<00:06, 194.01 examples/s]Tokenizing train dataset:  82%|████████▏ | 6989/8564 [01:05<00:09, 171.16 examples/s]Tokenizing train dataset:  80%|███████▉  | 6842/8564 [01:06<00:12, 137.52 examples/s]Tokenizing train dataset:  86%|████████▌ | 7346/8564 [01:06<00:06, 180.58 examples/s]Tokenizing train dataset:  80%|████████  | 6865/8564 [01:06<00:10, 158.78 examples/s]Tokenizing train dataset:  82%|████████▏ | 7014/8564 [01:06<00:09, 164.16 examples/s]Tokenizing train dataset:  86%|████████▌ | 7366/8564 [01:06<00:07, 169.52 examples/s]Tokenizing train dataset:  80%|████████  | 6885/8564 [01:06<00:10, 160.92 examples/s]Tokenizing train dataset:  82%|████████▏ | 7041/8564 [01:06<00:09, 162.68 examples/s]Tokenizing train dataset:  86%|████████▌ | 7386/8564 [01:06<00:07, 163.97 examples/s]Tokenizing train dataset:  81%|████████  | 6908/8564 [01:07<00:09, 171.63 examples/s]Tokenizing train dataset:  82%|████████▏ | 7065/8564 [01:06<00:09, 166.16 examples/s]Tokenizing train dataset:  87%|████████▋ | 7410/8564 [01:06<00:06, 168.81 examples/s]Tokenizing train dataset:  81%|████████  | 6928/8564 [01:07<00:10, 153.24 examples/s]Tokenizing train dataset:  83%|████████▎ | 7089/8564 [01:06<00:08, 175.38 examples/s]Tokenizing train dataset:  87%|████████▋ | 7435/8564 [01:06<00:06, 172.72 examples/s]Tokenizing train dataset:  81%|████████  | 6948/8564 [01:07<00:10, 158.24 examples/s]Tokenizing train dataset:  87%|████████▋ | 7457/8564 [01:07<00:06, 180.08 examples/s]Tokenizing train dataset:  83%|████████▎ | 7116/8564 [01:06<00:08, 167.25 examples/s]Tokenizing train dataset:  87%|████████▋ | 7478/8564 [01:07<00:05, 181.22 examples/s]Tokenizing train dataset:  81%|████████▏ | 6966/8564 [01:07<00:12, 132.05 examples/s]Tokenizing train dataset:  83%|████████▎ | 7142/8564 [01:06<00:09, 155.97 examples/s]Tokenizing train dataset:  88%|████████▊ | 7501/8564 [01:07<00:05, 190.99 examples/s]Tokenizing train dataset:  82%|████████▏ | 6985/8564 [01:07<00:11, 136.42 examples/s]Tokenizing train dataset:  88%|████████▊ | 7524/8564 [01:07<00:05, 200.05 examples/s]Tokenizing train dataset:  84%|████████▎ | 7164/8564 [01:07<00:09, 144.54 examples/s]Tokenizing train dataset:  82%|████████▏ | 7004/8564 [01:07<00:12, 124.76 examples/s]Tokenizing train dataset:  88%|████████▊ | 7548/8564 [01:07<00:04, 204.04 examples/s]Tokenizing train dataset:  84%|████████▍ | 7181/8564 [01:07<00:09, 147.88 examples/s]Tokenizing train dataset:  88%|████████▊ | 7571/8564 [01:07<00:04, 210.30 examples/s]Tokenizing train dataset:  82%|████████▏ | 7024/8564 [01:08<00:12, 121.80 examples/s]Tokenizing train dataset:  84%|████████▍ | 7197/8564 [01:07<00:09, 138.21 examples/s]Tokenizing train dataset:  89%|████████▊ | 7600/8564 [01:07<00:04, 199.70 examples/s]Tokenizing train dataset:  82%|████████▏ | 7041/8564 [01:08<00:12, 123.83 examples/s]Tokenizing train dataset:  84%|████████▍ | 7220/8564 [01:07<00:08, 151.73 examples/s]Tokenizing train dataset:  82%|████████▏ | 7060/8564 [01:08<00:11, 134.93 examples/s]Tokenizing train dataset:  85%|████████▍ | 7239/8564 [01:07<00:08, 153.51 examples/s]Tokenizing train dataset:  89%|████████▉ | 7628/8564 [01:07<00:05, 178.51 examples/s]Tokenizing train dataset:  83%|████████▎ | 7076/8564 [01:08<00:10, 137.62 examples/s]Tokenizing train dataset:  85%|████████▍ | 7257/8564 [01:07<00:08, 158.05 examples/s]Tokenizing train dataset:  83%|████████▎ | 7092/8564 [01:08<00:10, 138.76 examples/s]Tokenizing train dataset:  85%|████████▌ | 7285/8564 [01:07<00:07, 174.47 examples/s]Tokenizing train dataset:  89%|████████▉ | 7655/8564 [01:08<00:06, 150.25 examples/s]Tokenizing train dataset:  85%|████████▌ | 7307/8564 [01:07<00:06, 183.97 examples/s]Tokenizing train dataset:  83%|████████▎ | 7114/8564 [01:08<00:10, 136.85 examples/s]Tokenizing train dataset:  86%|████████▌ | 7327/8564 [01:08<00:06, 187.40 examples/s]Tokenizing train dataset:  83%|████████▎ | 7130/8564 [01:08<00:10, 135.01 examples/s]Tokenizing train dataset:  90%|████████▉ | 7682/8564 [01:08<00:06, 135.63 examples/s]Tokenizing train dataset:  86%|████████▌ | 7350/8564 [01:08<00:06, 190.06 examples/s]Tokenizing train dataset:  83%|████████▎ | 7148/8564 [01:08<00:10, 138.17 examples/s]Tokenizing train dataset:  86%|████████▌ | 7374/8564 [01:08<00:05, 200.92 examples/s]Tokenizing train dataset:  90%|████████▉ | 7704/8564 [01:08<00:06, 132.17 examples/s]Tokenizing train dataset:  84%|████████▍ | 7173/8564 [01:09<00:09, 144.26 examples/s]Tokenizing train dataset:  90%|█████████ | 7722/8564 [01:08<00:06, 140.24 examples/s]Tokenizing train dataset:  86%|████████▋ | 7401/8564 [01:08<00:06, 178.82 examples/s]Tokenizing train dataset:  84%|████████▍ | 7197/8564 [01:09<00:08, 164.52 examples/s]Tokenizing train dataset:  90%|█████████ | 7742/8564 [01:08<00:05, 150.63 examples/s]Tokenizing train dataset:  87%|████████▋ | 7420/8564 [01:08<00:06, 169.14 examples/s]Tokenizing train dataset:  84%|████████▍ | 7217/8564 [01:09<00:07, 172.29 examples/s]Tokenizing train dataset:  91%|█████████ | 7762/8564 [01:08<00:05, 151.77 examples/s]Tokenizing train dataset:  84%|████████▍ | 7235/8564 [01:09<00:07, 169.07 examples/s]Tokenizing train dataset:  87%|████████▋ | 7440/8564 [01:08<00:06, 167.57 examples/s]Tokenizing train dataset:  91%|█████████ | 7781/8564 [01:09<00:04, 158.71 examples/s]Tokenizing train dataset:  85%|████████▍ | 7257/8564 [01:09<00:07, 174.43 examples/s]Tokenizing train dataset:  91%|█████████ | 7801/8564 [01:09<00:04, 163.66 examples/s]Tokenizing train dataset:  87%|████████▋ | 7466/8564 [01:08<00:07, 155.93 examples/s]Tokenizing train dataset:  85%|████████▌ | 7283/8564 [01:09<00:06, 195.58 examples/s]Tokenizing train dataset:  91%|█████████▏| 7818/8564 [01:09<00:04, 158.66 examples/s]Tokenizing train dataset:  85%|████████▌ | 7305/8564 [01:09<00:06, 199.35 examples/s]Tokenizing train dataset:  92%|█████████▏| 7840/8564 [01:09<00:04, 173.62 examples/s]Tokenizing train dataset:  87%|████████▋ | 7487/8564 [01:09<00:07, 139.55 examples/s]Tokenizing train dataset:  86%|████████▌ | 7336/8564 [01:09<00:06, 200.00 examples/s]Tokenizing train dataset:  92%|█████████▏| 7860/8564 [01:09<00:04, 172.35 examples/s]Tokenizing train dataset:  88%|████████▊ | 7505/8564 [01:09<00:07, 134.55 examples/s]Tokenizing train dataset:  92%|█████████▏| 7886/8564 [01:09<00:03, 191.32 examples/s]Tokenizing train dataset:  86%|████████▌ | 7358/8564 [01:09<00:06, 198.21 examples/s]Tokenizing train dataset:  88%|████████▊ | 7524/8564 [01:09<00:07, 140.01 examples/s]Tokenizing train dataset:  86%|████████▌ | 7382/8564 [01:10<00:05, 206.80 examples/s]Tokenizing train dataset:  92%|█████████▏| 7920/8564 [01:09<00:03, 202.56 examples/s]Tokenizing train dataset:  88%|████████▊ | 7543/8564 [01:09<00:07, 145.36 examples/s]Tokenizing train dataset:  93%|█████████▎| 7941/8564 [01:09<00:03, 197.65 examples/s]Tokenizing train dataset:  88%|████████▊ | 7560/8564 [01:09<00:06, 145.89 examples/s]Tokenizing train dataset:  87%|████████▋ | 7410/8564 [01:10<00:06, 173.34 examples/s]Tokenizing train dataset:  93%|█████████▎| 7963/8564 [01:09<00:02, 202.09 examples/s]Tokenizing train dataset:  89%|████████▊ | 7586/8564 [01:09<00:05, 173.29 examples/s]Tokenizing train dataset:  87%|████████▋ | 7430/8564 [01:10<00:07, 161.49 examples/s]Tokenizing train dataset:  93%|█████████▎| 7987/8564 [01:10<00:02, 205.82 examples/s]Tokenizing train dataset:  89%|████████▉ | 7610/8564 [01:09<00:05, 170.87 examples/s]Tokenizing train dataset:  87%|████████▋ | 7453/8564 [01:10<00:06, 172.53 examples/s]Tokenizing train dataset:  94%|█████████▎| 8013/8564 [01:10<00:02, 213.57 examples/s]Tokenizing train dataset:  87%|████████▋ | 7474/8564 [01:10<00:06, 181.09 examples/s]Tokenizing train dataset:  89%|████████▉ | 7634/8564 [01:10<00:05, 157.34 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:10<00:02, 205.28 examples/s]Tokenizing train dataset:  88%|████████▊ | 7497/8564 [01:10<00:05, 182.98 examples/s]Tokenizing train dataset:  89%|████████▉ | 7655/8564 [01:10<00:06, 147.19 examples/s]Tokenizing train dataset:  88%|████████▊ | 7518/8564 [01:10<00:05, 189.45 examples/s]Tokenizing train dataset:  94%|█████████▍| 8071/8564 [01:10<00:02, 181.02 examples/s]Tokenizing train dataset:  88%|████████▊ | 7543/8564 [01:10<00:05, 197.87 examples/s]Tokenizing train dataset:  90%|████████▉ | 7671/8564 [01:10<00:07, 122.26 examples/s]Tokenizing train dataset:  95%|█████████▍| 8100/8564 [01:10<00:02, 180.22 examples/s]Tokenizing train dataset:  88%|████████▊ | 7570/8564 [01:11<00:05, 181.29 examples/s]Tokenizing train dataset:  90%|████████▉ | 7691/8564 [01:10<00:06, 136.98 examples/s]Tokenizing train dataset:  95%|█████████▍| 8124/8564 [01:10<00:02, 172.74 examples/s]Tokenizing train dataset:  90%|█████████ | 7717/8564 [01:10<00:05, 163.93 examples/s]Tokenizing train dataset:  89%|████████▊ | 7599/8564 [01:11<00:05, 174.18 examples/s]Tokenizing train dataset:  95%|█████████▌| 8151/8564 [01:10<00:02, 184.37 examples/s]Tokenizing train dataset:  95%|█████████▌| 8176/8564 [01:11<00:01, 197.63 examples/s]Tokenizing train dataset:  90%|█████████ | 7741/8564 [01:10<00:05, 149.68 examples/s]Tokenizing train dataset:  89%|████████▉ | 7620/8564 [01:11<00:05, 170.61 examples/s]Tokenizing train dataset:  96%|█████████▌| 8200/8564 [01:11<00:01, 206.27 examples/s]Tokenizing train dataset:  89%|████████▉ | 7640/8564 [01:11<00:06, 153.43 examples/s]Tokenizing train dataset:  91%|█████████ | 7767/8564 [01:11<00:06, 131.92 examples/s]Tokenizing train dataset:  96%|█████████▌| 8223/8564 [01:11<00:01, 183.05 examples/s]Tokenizing train dataset:  89%|████████▉ | 7657/8564 [01:11<00:05, 156.58 examples/s]Tokenizing train dataset:  91%|█████████ | 7790/8564 [01:11<00:05, 144.80 examples/s]Tokenizing train dataset:  96%|█████████▋| 8244/8564 [01:11<00:01, 177.44 examples/s]Tokenizing train dataset:  90%|████████▉ | 7676/8564 [01:11<00:05, 159.13 examples/s]Tokenizing train dataset:  91%|█████████ | 7806/8564 [01:11<00:05, 134.20 examples/s]Tokenizing train dataset:  90%|████████▉ | 7701/8564 [01:11<00:05, 171.73 examples/s]Tokenizing train dataset:  97%|█████████▋| 8275/8564 [01:11<00:01, 189.37 examples/s]Tokenizing train dataset:  90%|█████████ | 7727/8564 [01:12<00:04, 193.29 examples/s]Tokenizing train dataset:  91%|█████████▏| 7823/8564 [01:11<00:05, 132.14 examples/s]Tokenizing train dataset:  97%|█████████▋| 8296/8564 [01:11<00:01, 185.16 examples/s]Tokenizing train dataset:  92%|█████████▏| 7850/8564 [01:11<00:04, 161.65 examples/s]Tokenizing train dataset:  91%|█████████ | 7753/8564 [01:12<00:04, 180.93 examples/s]Tokenizing train dataset:  97%|█████████▋| 8318/8564 [01:11<00:01, 166.98 examples/s]Tokenizing train dataset:  92%|█████████▏| 7870/8564 [01:11<00:04, 163.86 examples/s]Tokenizing train dataset:  91%|█████████ | 7780/8564 [01:12<00:04, 174.31 examples/s]Tokenizing train dataset:  92%|█████████▏| 7894/8564 [01:11<00:03, 180.00 examples/s]Tokenizing train dataset:  97%|█████████▋| 8343/8564 [01:12<00:01, 144.19 examples/s]Tokenizing train dataset:  92%|█████████▏| 7914/8564 [01:11<00:03, 169.38 examples/s]Tokenizing train dataset:  91%|█████████ | 7800/8564 [01:12<00:05, 136.90 examples/s]Tokenizing train dataset:  98%|█████████▊| 8373/8564 [01:12<00:01, 154.63 examples/s]Tokenizing train dataset:  93%|█████████▎| 7932/8564 [01:12<00:03, 166.69 examples/s]Tokenizing train dataset:  91%|█████████▏| 7818/8564 [01:12<00:05, 136.81 examples/s]Tokenizing train dataset:  98%|█████████▊| 8393/8564 [01:12<00:01, 160.69 examples/s]Tokenizing train dataset:  98%|█████████▊| 8419/8564 [01:12<00:00, 182.29 examples/s]Tokenizing train dataset:  93%|█████████▎| 7958/8564 [01:12<00:04, 148.49 examples/s]Tokenizing train dataset:  92%|█████████▏| 7841/8564 [01:12<00:05, 134.13 examples/s]Tokenizing train dataset:  99%|█████████▊| 8445/8564 [01:12<00:00, 173.29 examples/s]Tokenizing train dataset:  93%|█████████▎| 7980/8564 [01:12<00:04, 144.73 examples/s]Tokenizing train dataset:  99%|█████████▉| 8468/8564 [01:12<00:00, 184.31 examples/s]Tokenizing train dataset:  92%|█████████▏| 7860/8564 [01:13<00:05, 119.41 examples/s]Tokenizing train dataset:  94%|█████████▎| 8010/8564 [01:12<00:03, 173.16 examples/s]Tokenizing train dataset:  94%|█████████▍| 8029/8564 [01:12<00:03, 176.65 examples/s]Tokenizing train dataset:  92%|█████████▏| 7880/8564 [01:13<00:05, 126.15 examples/s]Tokenizing train dataset:  99%|█████████▉| 8488/8564 [01:12<00:00, 162.58 examples/s]Tokenizing train dataset:  94%|█████████▍| 8048/8564 [01:12<00:02, 179.20 examples/s]Tokenizing train dataset:  92%|█████████▏| 7900/8564 [01:13<00:04, 137.60 examples/s]Tokenizing train dataset:  94%|█████████▍| 8069/8564 [01:12<00:02, 181.02 examples/s]Tokenizing train dataset:  99%|█████████▉| 8510/8564 [01:13<00:00, 142.60 examples/s]Tokenizing train dataset:  92%|█████████▏| 7915/8564 [01:13<00:04, 132.84 examples/s]Tokenizing train dataset:  95%|█████████▍| 8097/8564 [01:12<00:02, 180.85 examples/s]Tokenizing train dataset:  93%|█████████▎| 7933/8564 [01:13<00:04, 134.31 examples/s]Tokenizing train dataset: 100%|█████████▉| 8530/8564 [01:13<00:00, 136.12 examples/s]Tokenizing train dataset:  95%|█████████▍| 8116/8564 [01:13<00:02, 179.31 examples/s]Tokenizing train dataset: 100%|█████████▉| 8549/8564 [01:13<00:00, 140.32 examples/s]Tokenizing train dataset:  93%|█████████▎| 7951/8564 [01:13<00:05, 118.46 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:13<00:00, 116.49 examples/s]
Tokenizing train dataset:  95%|█████████▌| 8144/8564 [01:13<00:02, 172.54 examples/s]Tokenizing train dataset:  93%|█████████▎| 7976/8564 [01:13<00:04, 144.82 examples/s]Tokenizing train dataset:  95%|█████████▌| 8164/8564 [01:13<00:02, 168.02 examples/s]Tokenizing train dataset:  93%|█████████▎| 8003/8564 [01:14<00:03, 173.82 examples/s]Tokenizing train dataset:  96%|█████████▌| 8192/8564 [01:13<00:01, 194.30 examples/s]Tokenizing train dataset:  94%|█████████▎| 8026/8564 [01:14<00:02, 182.56 examples/s]Tokenizing train dataset:  96%|█████████▌| 8219/8564 [01:13<00:01, 188.16 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:14<00:03, 168.28 examples/s]Tokenizing train dataset:  96%|█████████▋| 8245/8564 [01:13<00:01, 204.18 examples/s]Tokenizing train dataset:  94%|█████████▍| 8068/8564 [01:14<00:03, 153.18 examples/s]Tokenizing train dataset:  97%|█████████▋| 8276/8564 [01:13<00:01, 228.39 examples/s]Tokenizing train dataset:  94%|█████████▍| 8087/8564 [01:14<00:03, 157.80 examples/s]Tokenizing train dataset:  97%|█████████▋| 8305/8564 [01:13<00:01, 239.10 examples/s]Tokenizing train dataset:  95%|█████████▍| 8108/8564 [01:14<00:02, 165.23 examples/s]Tokenizing train dataset:  97%|█████████▋| 8339/8564 [01:14<00:00, 226.08 examples/s]Tokenizing train dataset:  95%|█████████▍| 8126/8564 [01:14<00:02, 166.93 examples/s]Tokenizing train dataset:  95%|█████████▌| 8152/8564 [01:14<00:02, 183.24 examples/s]Tokenizing train dataset:  98%|█████████▊| 8364/8564 [01:14<00:00, 201.03 examples/s]Tokenizing train dataset:  98%|█████████▊| 8387/8564 [01:14<00:00, 207.65 examples/s]Tokenizing train dataset:  95%|█████████▌| 8177/8564 [01:15<00:02, 193.34 examples/s]Tokenizing train dataset:  98%|█████████▊| 8409/8564 [01:14<00:00, 207.61 examples/s]Tokenizing train dataset:  96%|█████████▌| 8200/8564 [01:15<00:01, 201.17 examples/s]Tokenizing train dataset:  96%|█████████▌| 8221/8564 [01:15<00:01, 198.56 examples/s]Tokenizing train dataset:  99%|█████████▊| 8440/8564 [01:14<00:00, 203.00 examples/s]Tokenizing train dataset:  96%|█████████▋| 8247/8564 [01:15<00:01, 214.84 examples/s]Tokenizing train dataset:  97%|█████████▋| 8274/8564 [01:15<00:01, 229.33 examples/s]Tokenizing train dataset:  99%|█████████▉| 8477/8564 [01:14<00:00, 208.34 examples/s]Tokenizing train dataset:  97%|█████████▋| 8304/8564 [01:15<00:01, 247.70 examples/s]Tokenizing train dataset:  99%|█████████▉| 8508/8564 [01:14<00:00, 205.91 examples/s]Tokenizing train dataset: 100%|█████████▉| 8532/8564 [01:15<00:00, 212.60 examples/s]Tokenizing train dataset:  97%|█████████▋| 8333/8564 [01:15<00:01, 217.67 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:15<00:00, 204.95 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:15<00:00, 113.80 examples/s]
Tokenizing train dataset:  98%|█████████▊| 8366/8564 [01:15<00:01, 190.09 examples/s]Tokenizing train dataset:  98%|█████████▊| 8390/8564 [01:16<00:00, 175.23 examples/s]Tokenizing train dataset:  98%|█████████▊| 8410/8564 [01:16<00:00, 160.22 examples/s]Tokenizing train dataset:  98%|█████████▊| 8431/8564 [01:16<00:00, 161.04 examples/s]Tokenizing train dataset:  99%|█████████▊| 8449/8564 [01:16<00:00, 164.21 examples/s]Tokenizing train dataset:  99%|█████████▉| 8470/8564 [01:16<00:00, 170.95 examples/s]Tokenizing train dataset:  99%|█████████▉| 8491/8564 [01:16<00:00, 177.62 examples/s]Tokenizing train dataset:  99%|█████████▉| 8514/8564 [01:16<00:00, 183.66 examples/s]Tokenizing train dataset: 100%|█████████▉| 8537/8564 [01:17<00:00, 162.02 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:17<00:00, 176.84 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:17<00:00, 110.97 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  34%|███▎      | 320/953 [00:00<00:00, 3162.39 examples/s]Extracting prompt in eval dataset:  65%|██████▌   | 622/953 [00:00<00:00, 6167.89 examples/s]Extracting prompt in eval dataset:  29%|██▉       | 277/953 [00:00<00:00, 2747.05 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5544.12 examples/s]
Extracting prompt in eval dataset:  70%|███████   | 669/953 [00:00<00:00, 3349.91 examples/s]Extracting prompt in eval dataset:  65%|██████▌   | 620/953 [00:00<00:00, 3135.97 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3285.81 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3183.46 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3110.02 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 9444.35 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  43%|████▎     | 406/953 [00:00<00:00, 4010.56 examples/s]Applying chat template to eval dataset:  95%|█████████▍| 904/953 [00:00<00:00, 4528.29 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4293.19 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  48%|████▊     | 460/953 [00:00<00:00, 4553.01 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4733.80 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   1%|          | 10/953 [00:00<00:09, 98.02 examples/s]Tokenizing eval dataset:   2%|▏         | 22/953 [00:00<00:08, 110.01 examples/s]Tokenizing eval dataset:   4%|▍         | 40/953 [00:00<00:09, 94.17 examples/s] Tokenizing eval dataset:   6%|▌         | 59/953 [00:00<00:07, 121.97 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:06, 143.34 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:  10%|█         | 97/953 [00:00<00:05, 147.56 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   1%|          | 10/953 [00:00<00:10, 88.31 examples/s]Tokenizing eval dataset:  12%|█▏        | 116/953 [00:00<00:05, 156.38 examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:09, 97.85 examples/s]Tokenizing eval dataset:   2%|▏         | 23/953 [00:00<00:09, 100.26 examples/s]Tokenizing eval dataset:  14%|█▍        | 133/953 [00:00<00:05, 157.76 examples/s]Tokenizing eval dataset:   3%|▎         | 24/953 [00:00<00:09, 100.40 examples/s]Tokenizing eval dataset:  16%|█▌        | 150/953 [00:01<00:05, 156.74 examples/s]Tokenizing eval dataset:   4%|▎         | 35/953 [00:00<00:09, 99.67 examples/s] Tokenizing eval dataset:   4%|▎         | 35/953 [00:00<00:08, 102.42 examples/s]Tokenizing eval dataset:  18%|█▊        | 169/953 [00:01<00:05, 155.98 examples/s]Tokenizing eval dataset:   5%|▍         | 47/953 [00:00<00:10, 89.86 examples/s]Tokenizing eval dataset:   5%|▌         | 50/953 [00:00<00:09, 92.58 examples/s] Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:07, 115.73 examples/s]Tokenizing eval dataset:   6%|▋         | 60/953 [00:00<00:10, 83.13 examples/s]Tokenizing eval dataset:  19%|█▉        | 185/953 [00:01<00:06, 115.16 examples/s]Tokenizing eval dataset:   8%|▊         | 73/953 [00:00<00:09, 93.14 examples/s]Tokenizing eval dataset:   9%|▉         | 87/953 [00:00<00:06, 125.21 examples/s]Tokenizing eval dataset:  21%|██        | 199/953 [00:01<00:06, 119.56 examples/s]Tokenizing eval dataset:   9%|▉         | 90/953 [00:00<00:08, 106.35 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:00<00:07, 116.23 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:01<00:05, 128.57 examples/s]Tokenizing eval dataset:  11%|█         | 102/953 [00:01<00:08, 103.90 examples/s]Tokenizing eval dataset:  27%|██▋       | 255/953 [00:01<00:04, 171.67 examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:01<00:07, 113.26 examples/s]Tokenizing eval dataset:  12%|█▏        | 113/953 [00:01<00:08, 99.56 examples/s] Tokenizing eval dataset:  31%|███       | 291/953 [00:01<00:03, 215.92 examples/s]Tokenizing eval dataset:  14%|█▍        | 138/953 [00:01<00:06, 117.05 examples/s]Tokenizing eval dataset:  34%|███▎      | 320/953 [00:01<00:02, 230.50 examples/s]Tokenizing eval dataset:  14%|█▎        | 131/953 [00:01<00:08, 102.68 examples/s]Tokenizing eval dataset:  16%|█▌        | 150/953 [00:01<00:06, 114.74 examples/s]Tokenizing eval dataset:  15%|█▌        | 144/953 [00:01<00:07, 107.25 examples/s]Tokenizing eval dataset:  37%|███▋      | 351/953 [00:02<00:02, 211.05 examples/s]Tokenizing eval dataset:  17%|█▋        | 162/953 [00:01<00:07, 111.93 examples/s]Tokenizing eval dataset:  16%|█▋        | 156/953 [00:01<00:07, 108.43 examples/s]Tokenizing eval dataset:  18%|█▊        | 176/953 [00:01<00:06, 113.82 examples/s]Tokenizing eval dataset:  40%|███▉      | 378/953 [00:02<00:02, 195.84 examples/s]Tokenizing eval dataset:  18%|█▊        | 172/953 [00:01<00:06, 119.71 examples/s]Tokenizing eval dataset:  42%|████▏     | 401/953 [00:02<00:02, 193.08 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:06, 122.60 examples/s]Tokenizing eval dataset:  20%|██        | 191/953 [00:01<00:07, 99.53 examples/s] Tokenizing eval dataset:  45%|████▍     | 425/953 [00:02<00:02, 193.80 examples/s]Tokenizing eval dataset:  22%|██▏       | 206/953 [00:01<00:05, 140.75 examples/s]Tokenizing eval dataset:  21%|██        | 202/953 [00:01<00:07, 101.05 examples/s]Tokenizing eval dataset:  47%|████▋     | 452/953 [00:02<00:02, 211.58 examples/s]Tokenizing eval dataset:  24%|██▍       | 232/953 [00:01<00:04, 171.84 examples/s]Tokenizing eval dataset:  29%|██▉       | 275/953 [00:02<00:02, 240.77 examples/s]Tokenizing eval dataset:  23%|██▎       | 219/953 [00:02<00:07, 97.45 examples/s] Tokenizing eval dataset:  50%|█████     | 478/953 [00:02<00:02, 193.75 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:02<00:02, 245.61 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:02<00:04, 146.92 examples/s]Tokenizing eval dataset:  54%|█████▎    | 511/953 [00:02<00:01, 225.05 examples/s]Tokenizing eval dataset:  35%|███▍      | 332/953 [00:02<00:02, 250.82 examples/s]Tokenizing eval dataset:  29%|██▊       | 273/953 [00:02<00:04, 157.49 examples/s]Tokenizing eval dataset:  57%|█████▋    | 541/953 [00:03<00:01, 235.30 examples/s]Tokenizing eval dataset:  39%|███▉      | 372/953 [00:02<00:02, 287.55 examples/s]Tokenizing eval dataset:  31%|███       | 295/953 [00:02<00:03, 168.00 examples/s]Tokenizing eval dataset:  59%|█████▉    | 566/953 [00:03<00:01, 234.30 examples/s]Tokenizing eval dataset:  35%|███▍      | 329/953 [00:02<00:02, 211.51 examples/s]Tokenizing eval dataset:  42%|████▏     | 401/953 [00:02<00:01, 276.11 examples/s]Tokenizing eval dataset:  63%|██████▎   | 602/953 [00:03<00:01, 234.73 examples/s]Tokenizing eval dataset:  47%|████▋     | 451/953 [00:02<00:01, 337.50 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:02<00:02, 199.64 examples/s]Tokenizing eval dataset:  52%|█████▏    | 491/953 [00:02<00:01, 349.53 examples/s]Tokenizing eval dataset:  66%|██████▋   | 633/953 [00:03<00:01, 210.05 examples/s]Tokenizing eval dataset:  40%|████      | 385/953 [00:02<00:02, 197.39 examples/s]Tokenizing eval dataset:  56%|█████▌    | 531/953 [00:02<00:01, 361.80 examples/s]Tokenizing eval dataset:  43%|████▎     | 407/953 [00:02<00:02, 200.24 examples/s]Tokenizing eval dataset:  61%|██████    | 577/953 [00:02<00:00, 382.48 examples/s]Tokenizing eval dataset:  70%|██████▉   | 664/953 [00:03<00:01, 206.05 examples/s]Tokenizing eval dataset:  45%|████▌     | 430/953 [00:02<00:02, 205.66 examples/s]Tokenizing eval dataset:  65%|██████▌   | 620/953 [00:03<00:00, 391.38 examples/s]Tokenizing eval dataset:  73%|███████▎  | 695/953 [00:03<00:01, 199.78 examples/s]Tokenizing eval dataset:  48%|████▊     | 459/953 [00:03<00:02, 221.30 examples/s]Tokenizing eval dataset:  69%|██████▉   | 661/953 [00:03<00:00, 394.63 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:03<00:01, 189.54 examples/s]Tokenizing eval dataset:  74%|███████▍  | 709/953 [00:03<00:00, 363.65 examples/s]Tokenizing eval dataset:  51%|█████     | 484/953 [00:03<00:02, 197.37 examples/s]Tokenizing eval dataset:  53%|█████▎    | 508/953 [00:03<00:02, 199.60 examples/s]Tokenizing eval dataset:  79%|███████▊  | 749/953 [00:03<00:00, 327.39 examples/s]Tokenizing eval dataset:  79%|███████▉  | 757/953 [00:04<00:01, 191.80 examples/s]Tokenizing eval dataset:  57%|█████▋    | 540/953 [00:03<00:01, 228.20 examples/s]Tokenizing eval dataset:  82%|████████▏ | 781/953 [00:04<00:00, 200.47 examples/s]Tokenizing eval dataset:  82%|████████▏ | 784/953 [00:03<00:00, 285.35 examples/s]Tokenizing eval dataset:  60%|██████    | 572/953 [00:03<00:01, 244.98 examples/s]Tokenizing eval dataset:  85%|████████▍ | 810/953 [00:04<00:00, 194.48 examples/s]Tokenizing eval dataset:  86%|████████▌ | 817/953 [00:03<00:00, 259.98 examples/s]Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:03<00:01, 234.89 examples/s]Tokenizing eval dataset:  88%|████████▊ | 836/953 [00:04<00:00, 207.31 examples/s]Tokenizing eval dataset:  68%|██████▊   | 646/953 [00:03<00:01, 267.62 examples/s]Tokenizing eval dataset:  89%|████████▉ | 850/953 [00:03<00:00, 269.98 examples/s]Tokenizing eval dataset:  71%|███████▏  | 681/953 [00:03<00:00, 280.82 examples/s]Tokenizing eval dataset:  93%|█████████▎| 882/953 [00:04<00:00, 248.72 examples/s]Tokenizing eval dataset:  90%|█████████ | 860/953 [00:04<00:00, 162.10 examples/s]Tokenizing eval dataset:  75%|███████▍  | 710/953 [00:04<00:00, 269.15 examples/s]Tokenizing eval dataset:  93%|█████████▎| 890/953 [00:04<00:00, 184.61 examples/s]Tokenizing eval dataset:  95%|█████████▌| 908/953 [00:04<00:00, 213.33 examples/s]Tokenizing eval dataset:  97%|█████████▋| 920/953 [00:05<00:00, 202.53 examples/s]Tokenizing eval dataset:  78%|███████▊  | 744/953 [00:04<00:00, 234.54 examples/s]Tokenizing eval dataset:  99%|█████████▊| 940/953 [00:04<00:00, 204.87 examples/s]Tokenizing eval dataset:  99%|█████████▉| 948/953 [00:05<00:00, 219.77 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 186.06 examples/s]
Tokenizing eval dataset:  81%|████████▏ | 776/953 [00:04<00:00, 253.99 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:04<00:00, 214.28 examples/s]
Tokenizing eval dataset:  84%|████████▍ | 804/953 [00:04<00:00, 257.97 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  88%|████████▊ | 840/953 [00:04<00:00, 279.60 examples/s]Tokenizing eval dataset:  92%|█████████▏| 874/953 [00:04<00:00, 290.32 examples/s]Tokenizing eval dataset:  95%|█████████▌| 908/953 [00:04<00:00, 297.35 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:04<00:00, 304.58 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:04<00:00, 192.56 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Time to load cpu_adam op: 4.431069374084473 seconds
Time to load cpu_adam op: 4.432035446166992 seconds
Time to load cpu_adam op: 4.436337232589722 seconds
Time to load cpu_adam op: 4.438681602478027 seconds
Parameter Offload: Total persistent parameters: 605696 in 169 params
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250530_221834-qehqx6c5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-3e-07_e-3_b-0.2
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/qehqx6c5
  0%|          | 0/1605 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
W0530 22:19:04.358000 3024035 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3024107 closing signal SIGTERM
W0530 22:19:04.446000 3024035 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3024108 closing signal SIGTERM
W0530 22:19:04.450000 3024035 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3024109 closing signal SIGTERM
E0530 22:19:07.879000 3024035 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -9) local_rank: 0 (pid: 3024106) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1182, in launch_command
    deepspeed_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 861, in deepspeed_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
train.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-30_22:19:04
  host      : pm5-nod66.vega.pri
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 3024106)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 3024106
========================================================
slurmstepd: error: Detected 1 oom_kill event in StepId=62067775.0. Some of the step tasks have been OOM Killed.
