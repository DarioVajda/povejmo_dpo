cpu-bind=MASK - gn29, task  1  0 [798887]: mask 0x1000000000000000000000000000000010000000000000000000000000000 set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn28
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 1     --main_process_ip gn28     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62066294     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-30 17:11:39,109] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0530 17:11:42.207000 798932 torch/distributed/run.py:792] 
W0530 17:11:42.207000 798932 torch/distributed/run.py:792] *****************************************
W0530 17:11:42.207000 798932 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0530 17:11:42.207000 798932 torch/distributed/run.py:792] *****************************************
[2025-05-30 17:12:14,475] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 17:12:14,480] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 17:12:14,517] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 17:12:14,535] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 2
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
[2025-05-30 17:12:25,980] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 17:12:26,003] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 17:12:26,021] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 4282
Eval steps: 2141
[2025-05-30 17:12:26,026] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
[2025-05-30 17:12:31,158] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 17:12:31,158] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 17:12:31,168] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 17:12:31,169] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:54<02:42, 54.19s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:54<02:42, 54.21s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:54<02:42, 54.20s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:54<02:42, 54.21s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:11<02:15, 67.60s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:11<02:15, 67.60s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:11<02:15, 67.60s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:11<02:15, 67.61s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:23<01:09, 69.60s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:23<01:09, 69.60s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:23<01:09, 69.60s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:23<01:09, 69.60s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:17<00:00, 63.61s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:17<00:00, 63.61s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:17<00:00, 64.40s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:17<00:00, 64.40s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [04:17<00:00, 63.61s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:17<00:00, 64.39s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [04:17<00:00, 63.61s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:17<00:00, 64.40s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Using LoRA and set up the model model
-------------------- CHECKING GRADIENTS --------------------
Trainable parameters:
- base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.40.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.40.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.41.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.41.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
Total trainable parameters: 216072192
------------------------------------------------------------
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 1/8564 [00:00<41:23,  3.45 examples/s]Extracting prompt in train dataset:   0%|          | 10/8564 [00:01<17:44,  8.04 examples/s]Extracting prompt in train dataset:   2%|▏         | 210/8564 [00:01<00:38, 217.89 examples/s]Extracting prompt in train dataset:   5%|▍         | 410/8564 [00:01<00:18, 441.64 examples/s]Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:01<00:13, 584.38 examples/s]Extracting prompt in train dataset:   9%|▉         | 789/8564 [00:01<00:08, 907.48 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1060/8564 [00:01<00:06, 1140.13 examples/s]Extracting prompt in train dataset:  14%|█▍        | 1240/8564 [00:01<00:05, 1261.25 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1456/8564 [00:02<00:04, 1428.97 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1674/8564 [00:02<00:04, 1608.54 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1903/8564 [00:02<00:03, 1751.66 examples/s]Extracting prompt in train dataset:  25%|██▌       | 2180/8564 [00:02<00:03, 1751.93 examples/s]Extracting prompt in train dataset:  29%|██▉       | 2472/8564 [00:02<00:03, 1809.48 examples/s]Extracting prompt in train dataset:  31%|███▏      | 2693/8564 [00:02<00:03, 1889.66 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2920/8564 [00:02<00:03, 1832.44 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3171/8564 [00:02<00:02, 1997.36 examples/s]Extracting prompt in train dataset:  40%|████      | 3446/8564 [00:03<00:02, 2188.07 examples/s]Extracting prompt in train dataset:  45%|████▍     | 3830/8564 [00:03<00:02, 2299.60 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4143/8564 [00:03<00:02, 2149.55 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4450/8564 [00:03<00:01, 2354.79 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 4710/8564 [00:03<00:01, 2059.22 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4930/8564 [00:03<00:01, 2085.85 examples/s]Extracting prompt in train dataset:  61%|██████    | 5240/8564 [00:03<00:01, 1861.89 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5470/8564 [00:04<00:01, 1895.13 examples/s]Extracting prompt in train dataset:  66%|██████▋   | 5690/8564 [00:04<00:01, 1963.84 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5916/8564 [00:04<00:01, 2031.87 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6222/8564 [00:04<00:01, 1977.02 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 6464/8564 [00:04<00:01, 2006.63 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6675/8564 [00:04<00:00, 2005.94 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 7000/8564 [00:04<00:00, 2315.08 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7320/8564 [00:04<00:00, 2239.89 examples/s]Extracting prompt in train dataset:  89%|████████▊ | 7595/8564 [00:05<00:00, 2029.56 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7912/8564 [00:05<00:00, 2041.81 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 8210/8564 [00:05<00:00, 2208.71 examples/s]Extracting prompt in train dataset:  99%|█████████▊| 8440/8564 [00:05<00:00, 2196.41 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1493.77 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 90/8564 [00:00<00:10, 824.24 examples/s]Applying chat template to train dataset:   2%|▏         | 210/8564 [00:00<00:08, 1035.44 examples/s]Applying chat template to train dataset:   4%|▍         | 341/8564 [00:00<00:08, 940.59 examples/s] Applying chat template to train dataset:   5%|▌         | 460/8564 [00:00<00:07, 1014.42 examples/s]Applying chat template to train dataset:   7%|▋         | 567/8564 [00:00<00:08, 986.22 examples/s] Applying chat template to train dataset:   8%|▊         | 667/8564 [00:00<00:08, 942.63 examples/s]Applying chat template to train dataset:   9%|▉         | 770/8564 [00:00<00:08, 938.13 examples/s]Applying chat template to train dataset:  11%|█         | 927/8564 [00:00<00:06, 1118.59 examples/s]Applying chat template to train dataset:  13%|█▎        | 1089/8564 [00:01<00:05, 1263.90 examples/s]Applying chat template to train dataset:  14%|█▍        | 1230/8564 [00:01<00:05, 1306.10 examples/s]Applying chat template to train dataset:  16%|█▋        | 1400/8564 [00:01<00:05, 1225.31 examples/s]Applying chat template to train dataset:  18%|█▊        | 1538/8564 [00:01<00:06, 1116.53 examples/s]Applying chat template to train dataset:  20%|██        | 1713/8564 [00:01<00:05, 1275.06 examples/s]Applying chat template to train dataset:  22%|██▏       | 1882/8564 [00:01<00:05, 1221.54 examples/s]Applying chat template to train dataset:  24%|██▍       | 2066/8564 [00:01<00:05, 1150.79 examples/s]Applying chat template to train dataset:  26%|██▌       | 2220/8564 [00:01<00:05, 1201.35 examples/s]Applying chat template to train dataset:  28%|██▊       | 2370/8564 [00:02<00:05, 1126.28 examples/s]Applying chat template to train dataset:  30%|██▉       | 2564/8564 [00:02<00:05, 1159.97 examples/s]Applying chat template to train dataset:  32%|███▏      | 2740/8564 [00:02<00:05, 1161.64 examples/s]Applying chat template to train dataset:  34%|███▍      | 2898/8564 [00:02<00:05, 1122.26 examples/s]Applying chat template to train dataset:  35%|███▌      | 3016/8564 [00:02<00:04, 1123.34 examples/s]Applying chat template to train dataset:  37%|███▋      | 3151/8564 [00:02<00:05, 990.19 examples/s] Applying chat template to train dataset:  38%|███▊      | 3260/8564 [00:02<00:05, 1010.84 examples/s]Applying chat template to train dataset:  39%|███▉      | 3370/8564 [00:03<00:05, 1001.53 examples/s]Applying chat template to train dataset:  41%|████      | 3489/8564 [00:03<00:04, 1041.72 examples/s]Applying chat template to train dataset:  42%|████▏     | 3601/8564 [00:03<00:04, 1040.89 examples/s]Applying chat template to train dataset:  43%|████▎     | 3712/8564 [00:03<00:04, 1031.63 examples/s]Applying chat template to train dataset:  45%|████▍     | 3822/8564 [00:03<00:04, 1049.67 examples/s]Applying chat template to train dataset:  46%|████▌     | 3947/8564 [00:03<00:04, 1065.06 examples/s]Applying chat template to train dataset:  48%|████▊     | 4134/8564 [00:03<00:04, 1078.30 examples/s]Applying chat template to train dataset:  50%|█████     | 4300/8564 [00:03<00:04, 1045.92 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4409/8564 [00:04<00:03, 1039.09 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4527/8564 [00:04<00:03, 1068.22 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4640/8564 [00:04<00:03, 1083.72 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4754/8564 [00:04<00:03, 1097.01 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4871/8564 [00:04<00:03, 1114.38 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4993/8564 [00:04<00:03, 1112.70 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5129/8564 [00:04<00:02, 1156.17 examples/s]Applying chat template to train dataset:  61%|██████    | 5245/8564 [00:04<00:02, 1155.30 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5392/8564 [00:04<00:02, 1087.76 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5514/8564 [00:05<00:02, 1121.56 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5674/8564 [00:05<00:02, 1100.07 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5792/8564 [00:05<00:02, 1118.98 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5952/8564 [00:05<00:02, 1057.62 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6115/8564 [00:05<00:02, 1035.42 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6224/8564 [00:05<00:02, 1037.67 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6348/8564 [00:05<00:02, 1054.77 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6470/8564 [00:05<00:01, 1061.40 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6630/8564 [00:06<00:01, 1060.74 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6767/8564 [00:06<00:01, 1084.67 examples/s]Applying chat template to train dataset:  80%|████████  | 6887/8564 [00:06<00:01, 1113.41 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7009/8564 [00:06<00:01, 1137.43 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7133/8564 [00:06<00:01, 1141.32 examples/s]Applying chat template to train dataset:  85%|████████▍ | 7250/8564 [00:06<00:01, 1144.56 examples/s]Applying chat template to train dataset:  86%|████████▋ | 7405/8564 [00:06<00:01, 1102.03 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7563/8564 [00:06<00:00, 1078.06 examples/s]Applying chat template to train dataset:  90%|█████████ | 7730/8564 [00:07<00:00, 1085.44 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7899/8564 [00:07<00:00, 994.33 examples/s] Applying chat template to train dataset:  94%|█████████▍| 8052/8564 [00:07<00:00, 999.61 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8165/8564 [00:07<00:00, 1027.11 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8276/8564 [00:07<00:00, 1045.95 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8387/8564 [00:07<00:00, 1053.78 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8498/8564 [00:07<00:00, 1024.91 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:07<00:00, 1080.83 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 1/8564 [00:00<26:10,  5.45 examples/s]Tokenizing train dataset:   0%|          | 24/8564 [00:00<01:23, 102.44 examples/s]Tokenizing train dataset:   0%|          | 41/8564 [00:00<01:10, 121.72 examples/s]Tokenizing train dataset:   1%|          | 58/8564 [00:00<01:19, 106.90 examples/s]Tokenizing train dataset:   1%|          | 79/8564 [00:00<01:17, 109.71 examples/s]Tokenizing train dataset:   1%|          | 92/8564 [00:00<01:27, 96.73 examples/s] Tokenizing train dataset:   1%|          | 105/8564 [00:01<01:29, 94.68 examples/s]Tokenizing train dataset:   1%|▏         | 119/8564 [00:01<01:30, 93.02 examples/s]Tokenizing train dataset:   2%|▏         | 130/8564 [00:01<01:31, 91.96 examples/s]Tokenizing train dataset:   2%|▏         | 149/8564 [00:01<01:14, 113.68 examples/s]Tokenizing train dataset:   2%|▏         | 164/8564 [00:01<01:19, 105.04 examples/s]Tokenizing train dataset:   2%|▏         | 180/8564 [00:01<01:20, 103.63 examples/s]Tokenizing train dataset:   2%|▏         | 196/8564 [00:02<01:30, 92.67 examples/s] Tokenizing train dataset:   2%|▏         | 211/8564 [00:02<01:35, 87.26 examples/s]Tokenizing train dataset:   3%|▎         | 229/8564 [00:02<01:21, 102.36 examples/s]Tokenizing train dataset:   3%|▎         | 244/8564 [00:02<01:15, 110.90 examples/s]Tokenizing train dataset:   3%|▎         | 260/8564 [00:02<01:17, 107.80 examples/s]Tokenizing train dataset:   3%|▎         | 277/8564 [00:02<01:10, 116.97 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:02<01:09, 119.23 examples/s]Tokenizing train dataset:   4%|▎         | 309/8564 [00:02<01:11, 115.72 examples/s]Tokenizing train dataset:   4%|▍         | 326/8564 [00:03<01:17, 106.78 examples/s]Tokenizing train dataset:   4%|▍         | 339/8564 [00:03<01:14, 110.14 examples/s]Tokenizing train dataset:   4%|▍         | 357/8564 [00:03<01:18, 104.39 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:03<01:18, 104.35 examples/s]Tokenizing train dataset:   5%|▍         | 386/8564 [00:03<01:10, 115.77 examples/s]Tokenizing train dataset:   5%|▍         | 401/8564 [00:03<01:16, 106.70 examples/s]Tokenizing train dataset:   5%|▍         | 418/8564 [00:03<01:09, 116.39 examples/s]Tokenizing train dataset:   5%|▌         | 432/8564 [00:04<01:08, 119.40 examples/s]Tokenizing train dataset:   5%|▌         | 447/8564 [00:04<01:15, 107.56 examples/s]Tokenizing train dataset:   5%|▌         | 461/8564 [00:04<01:14, 108.97 examples/s]Tokenizing train dataset:   6%|▌         | 474/8564 [00:04<01:12, 111.74 examples/s]Tokenizing train dataset:   6%|▌         | 489/8564 [00:04<01:15, 106.32 examples/s]Tokenizing train dataset:   6%|▌         | 504/8564 [00:04<01:19, 101.25 examples/s]Tokenizing train dataset:   6%|▌         | 517/8564 [00:04<01:17, 103.72 examples/s]Tokenizing train dataset:   6%|▌         | 531/8564 [00:05<01:12, 110.75 examples/s]Tokenizing train dataset:   6%|▋         | 546/8564 [00:05<01:10, 114.19 examples/s]Tokenizing train dataset:   7%|▋         | 564/8564 [00:05<01:04, 124.98 examples/s]Tokenizing train dataset:   7%|▋         | 578/8564 [00:05<01:06, 120.87 examples/s]Tokenizing train dataset:   7%|▋         | 594/8564 [00:05<01:02, 127.08 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:05<01:05, 122.21 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:05<01:02, 127.15 examples/s]Tokenizing train dataset:   8%|▊         | 647/8564 [00:06<01:10, 112.10 examples/s]Tokenizing train dataset:   8%|▊         | 663/8564 [00:06<01:06, 118.15 examples/s]Tokenizing train dataset:   8%|▊         | 682/8564 [00:06<01:11, 111.00 examples/s]Tokenizing train dataset:   8%|▊         | 696/8564 [00:06<01:12, 108.36 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:06<01:14, 105.49 examples/s]Tokenizing train dataset:   8%|▊         | 722/8564 [00:06<01:09, 112.73 examples/s]Tokenizing train dataset:   9%|▊         | 738/8564 [00:06<01:03, 123.34 examples/s]Tokenizing train dataset:   9%|▉         | 753/8564 [00:06<01:11, 109.34 examples/s]Tokenizing train dataset:   9%|▉         | 771/8564 [00:07<01:09, 111.48 examples/s]Tokenizing train dataset:   9%|▉         | 789/8564 [00:07<01:08, 113.03 examples/s]Tokenizing train dataset:   9%|▉         | 807/8564 [00:07<01:11, 107.91 examples/s]Tokenizing train dataset:  10%|▉         | 822/8564 [00:07<01:14, 104.20 examples/s]Tokenizing train dataset:  10%|▉         | 842/8564 [00:07<01:12, 106.35 examples/s]Tokenizing train dataset:  10%|▉         | 854/8564 [00:07<01:16, 101.23 examples/s]Tokenizing train dataset:  10%|█         | 865/8564 [00:08<01:15, 101.98 examples/s]Tokenizing train dataset:  10%|█         | 877/8564 [00:08<01:12, 105.31 examples/s]Tokenizing train dataset:  10%|█         | 891/8564 [00:08<01:08, 112.41 examples/s]Tokenizing train dataset:  11%|█         | 907/8564 [00:08<01:05, 117.14 examples/s]Tokenizing train dataset:  11%|█         | 919/8564 [00:08<01:14, 101.94 examples/s]Tokenizing train dataset:  11%|█         | 930/8564 [00:08<01:15, 100.50 examples/s]Tokenizing train dataset:  11%|█         | 948/8564 [00:08<01:14, 102.46 examples/s]Tokenizing train dataset:  11%|█         | 962/8564 [00:08<01:09, 109.80 examples/s]Tokenizing train dataset:  11%|█▏        | 981/8564 [00:09<00:59, 126.49 examples/s]Tokenizing train dataset:  12%|█▏        | 998/8564 [00:09<01:04, 117.02 examples/s]Tokenizing train dataset:  12%|█▏        | 1013/8564 [00:09<01:09, 108.49 examples/s]Tokenizing train dataset:  12%|█▏        | 1025/8564 [00:09<01:08, 109.73 examples/s]Tokenizing train dataset:  12%|█▏        | 1039/8564 [00:09<01:15, 99.82 examples/s] Tokenizing train dataset:  12%|█▏        | 1054/8564 [00:09<01:08, 110.20 examples/s]Tokenizing train dataset:  12%|█▏        | 1069/8564 [00:09<01:05, 115.23 examples/s]Tokenizing train dataset:  13%|█▎        | 1086/8564 [00:09<01:00, 124.31 examples/s]Tokenizing train dataset:  13%|█▎        | 1104/8564 [00:10<01:02, 118.92 examples/s]Tokenizing train dataset:  13%|█▎        | 1117/8564 [00:10<01:02, 118.97 examples/s]Tokenizing train dataset:  13%|█▎        | 1130/8564 [00:10<01:11, 104.03 examples/s]Tokenizing train dataset:  13%|█▎        | 1141/8564 [00:10<01:11, 104.22 examples/s]Tokenizing train dataset:  13%|█▎        | 1152/8564 [00:10<01:13, 100.96 examples/s]Tokenizing train dataset:  14%|█▎        | 1164/8564 [00:10<01:11, 103.64 examples/s]Tokenizing train dataset:  14%|█▎        | 1175/8564 [00:10<01:10, 105.13 examples/s]Tokenizing train dataset:  14%|█▍        | 1186/8564 [00:10<01:10, 105.21 examples/s]Tokenizing train dataset:  14%|█▍        | 1200/8564 [00:11<01:06, 111.37 examples/s]Tokenizing train dataset:  14%|█▍        | 1212/8564 [00:11<01:17, 94.96 examples/s] Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:11<01:20, 90.80 examples/s]Tokenizing train dataset:  14%|█▍        | 1239/8564 [00:11<01:09, 105.27 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:11<01:08, 106.32 examples/s]Tokenizing train dataset:  15%|█▍        | 1264/8564 [00:11<01:05, 111.60 examples/s]Tokenizing train dataset:  15%|█▍        | 1277/8564 [00:11<01:06, 110.36 examples/s]Tokenizing train dataset:  15%|█▌        | 1295/8564 [00:11<01:00, 121.00 examples/s]Tokenizing train dataset:  15%|█▌        | 1310/8564 [00:12<00:56, 127.41 examples/s]Tokenizing train dataset:  15%|█▌        | 1325/8564 [00:12<01:01, 117.03 examples/s]Tokenizing train dataset:  16%|█▌        | 1339/8564 [00:12<01:03, 113.54 examples/s]Tokenizing train dataset:  16%|█▌        | 1353/8564 [00:12<01:11, 100.47 examples/s]Tokenizing train dataset:  16%|█▌        | 1367/8564 [00:12<01:13, 97.57 examples/s] Tokenizing train dataset:  16%|█▌        | 1379/8564 [00:12<01:12, 99.02 examples/s]Tokenizing train dataset:  16%|█▌        | 1390/8564 [00:12<01:14, 96.65 examples/s]Tokenizing train dataset:  16%|█▋        | 1400/8564 [00:12<01:14, 95.83 examples/s]Tokenizing train dataset:  16%|█▋        | 1413/8564 [00:13<01:11, 100.56 examples/s]Tokenizing train dataset:  17%|█▋        | 1426/8564 [00:13<01:19, 89.94 examples/s] Tokenizing train dataset:  17%|█▋        | 1440/8564 [00:13<01:24, 84.34 examples/s]Tokenizing train dataset:  17%|█▋        | 1452/8564 [00:13<01:19, 89.81 examples/s]Tokenizing train dataset:  17%|█▋        | 1465/8564 [00:13<01:21, 86.63 examples/s]Tokenizing train dataset:  17%|█▋        | 1478/8564 [00:13<01:16, 92.35 examples/s]Tokenizing train dataset:  17%|█▋        | 1491/8564 [00:14<01:23, 84.25 examples/s]Tokenizing train dataset:  18%|█▊        | 1502/8564 [00:14<01:21, 86.49 examples/s]Tokenizing train dataset:  18%|█▊        | 1515/8564 [00:14<01:23, 84.15 examples/s]Tokenizing train dataset:  18%|█▊        | 1535/8564 [00:14<01:04, 108.21 examples/s]Tokenizing train dataset:  18%|█▊        | 1549/8564 [00:14<01:10, 100.10 examples/s]Tokenizing train dataset:  18%|█▊        | 1560/8564 [00:14<01:08, 102.08 examples/s]Tokenizing train dataset:  18%|█▊        | 1577/8564 [00:14<01:08, 102.38 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:15<01:13, 95.31 examples/s] Tokenizing train dataset:  19%|█▉        | 1611/8564 [00:15<00:58, 117.91 examples/s]Tokenizing train dataset:  19%|█▉        | 1630/8564 [00:15<01:00, 115.35 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:15<01:05, 106.06 examples/s]Tokenizing train dataset:  19%|█▉        | 1667/8564 [00:15<01:05, 105.76 examples/s]Tokenizing train dataset:  20%|█▉        | 1685/8564 [00:15<01:04, 107.24 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:15<01:00, 113.58 examples/s]Tokenizing train dataset:  20%|██        | 1713/8564 [00:16<01:00, 113.62 examples/s]Tokenizing train dataset:  20%|██        | 1729/8564 [00:16<01:03, 108.31 examples/s]Tokenizing train dataset:  20%|██        | 1741/8564 [00:16<01:02, 108.35 examples/s]Tokenizing train dataset:  20%|██        | 1753/8564 [00:16<01:02, 108.39 examples/s]Tokenizing train dataset:  21%|██        | 1768/8564 [00:16<00:58, 117.04 examples/s]Tokenizing train dataset:  21%|██        | 1783/8564 [00:16<01:01, 110.13 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:16<01:04, 104.60 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:17<01:04, 105.44 examples/s]Tokenizing train dataset:  21%|██▏       | 1831/8564 [00:17<00:56, 119.91 examples/s]Tokenizing train dataset:  22%|██▏       | 1847/8564 [00:17<01:02, 107.74 examples/s]Tokenizing train dataset:  22%|██▏       | 1862/8564 [00:17<01:14, 90.51 examples/s] Tokenizing train dataset:  22%|██▏       | 1880/8564 [00:17<01:10, 94.93 examples/s]Tokenizing train dataset:  22%|██▏       | 1895/8564 [00:17<01:04, 103.44 examples/s]Tokenizing train dataset:  22%|██▏       | 1914/8564 [00:17<00:58, 113.76 examples/s]Tokenizing train dataset:  23%|██▎       | 1928/8564 [00:18<00:58, 112.52 examples/s]Tokenizing train dataset:  23%|██▎       | 1942/8564 [00:18<00:57, 115.65 examples/s]Tokenizing train dataset:  23%|██▎       | 1965/8564 [00:18<00:52, 124.79 examples/s]Tokenizing train dataset:  23%|██▎       | 1984/8564 [00:18<00:47, 139.24 examples/s]Tokenizing train dataset:  23%|██▎       | 2006/8564 [00:18<00:41, 157.34 examples/s]Tokenizing train dataset:  24%|██▎       | 2027/8564 [00:18<00:44, 145.57 examples/s]Tokenizing train dataset:  24%|██▍       | 2050/8564 [00:18<00:44, 145.64 examples/s]Tokenizing train dataset:  24%|██▍       | 2070/8564 [00:19<00:46, 138.85 examples/s]Tokenizing train dataset:  24%|██▍       | 2088/8564 [00:19<00:44, 145.14 examples/s]Tokenizing train dataset:  25%|██▍       | 2108/8564 [00:19<00:42, 152.02 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:19<00:39, 164.15 examples/s]Tokenizing train dataset:  25%|██▌       | 2151/8564 [00:19<00:42, 149.72 examples/s]Tokenizing train dataset:  25%|██▌       | 2172/8564 [00:19<00:45, 141.20 examples/s]Tokenizing train dataset:  26%|██▌       | 2188/8564 [00:19<00:45, 139.37 examples/s]Tokenizing train dataset:  26%|██▌       | 2205/8564 [00:20<00:52, 121.79 examples/s]Tokenizing train dataset:  26%|██▌       | 2222/8564 [00:20<00:49, 127.15 examples/s]Tokenizing train dataset:  26%|██▌       | 2236/8564 [00:20<00:48, 129.34 examples/s]Tokenizing train dataset:  26%|██▋       | 2251/8564 [00:20<00:47, 133.12 examples/s]Tokenizing train dataset:  26%|██▋       | 2269/8564 [00:20<00:51, 121.43 examples/s]Tokenizing train dataset:  27%|██▋       | 2287/8564 [00:20<00:47, 131.14 examples/s]Tokenizing train dataset:  27%|██▋       | 2302/8564 [00:20<00:47, 131.84 examples/s]Tokenizing train dataset:  27%|██▋       | 2319/8564 [00:20<00:50, 124.20 examples/s]Tokenizing train dataset:  27%|██▋       | 2339/8564 [00:21<00:51, 121.74 examples/s]Tokenizing train dataset:  27%|██▋       | 2353/8564 [00:21<00:56, 109.84 examples/s]Tokenizing train dataset:  28%|██▊       | 2370/8564 [00:21<00:52, 118.39 examples/s]Tokenizing train dataset:  28%|██▊       | 2386/8564 [00:21<00:50, 123.49 examples/s]Tokenizing train dataset:  28%|██▊       | 2403/8564 [00:21<00:47, 129.58 examples/s]Tokenizing train dataset:  28%|██▊       | 2418/8564 [00:21<00:46, 130.95 examples/s]Tokenizing train dataset:  28%|██▊       | 2433/8564 [00:21<00:45, 134.56 examples/s]Tokenizing train dataset:  29%|██▊       | 2455/8564 [00:21<00:44, 137.80 examples/s]Tokenizing train dataset:  29%|██▉       | 2471/8564 [00:22<00:45, 133.81 examples/s]Tokenizing train dataset:  29%|██▉       | 2488/8564 [00:22<00:43, 140.75 examples/s]Tokenizing train dataset:  29%|██▉       | 2510/8564 [00:22<00:50, 119.14 examples/s]Tokenizing train dataset:  29%|██▉       | 2524/8564 [00:22<00:49, 122.61 examples/s]Tokenizing train dataset:  30%|██▉       | 2540/8564 [00:22<00:46, 129.93 examples/s]Tokenizing train dataset:  30%|██▉       | 2558/8564 [00:22<00:44, 136.09 examples/s]Tokenizing train dataset:  30%|███       | 2573/8564 [00:22<00:43, 138.43 examples/s]Tokenizing train dataset:  30%|███       | 2590/8564 [00:23<00:49, 120.45 examples/s]Tokenizing train dataset:  30%|███       | 2607/8564 [00:23<00:52, 112.80 examples/s]Tokenizing train dataset:  31%|███       | 2619/8564 [00:23<00:55, 108.04 examples/s]Tokenizing train dataset:  31%|███       | 2632/8564 [00:23<01:01, 97.18 examples/s] Tokenizing train dataset:  31%|███       | 2647/8564 [00:23<00:55, 106.43 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:23<00:54, 107.85 examples/s]Tokenizing train dataset:  31%|███       | 2676/8564 [00:23<00:55, 106.24 examples/s]Tokenizing train dataset:  31%|███▏      | 2690/8564 [00:24<00:54, 108.20 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:24<00:52, 112.19 examples/s]Tokenizing train dataset:  32%|███▏      | 2720/8564 [00:24<00:48, 120.24 examples/s]Tokenizing train dataset:  32%|███▏      | 2735/8564 [00:24<00:52, 111.03 examples/s]Tokenizing train dataset:  32%|███▏      | 2751/8564 [00:24<00:55, 104.66 examples/s]Tokenizing train dataset:  32%|███▏      | 2762/8564 [00:24<00:56, 102.65 examples/s]Tokenizing train dataset:  32%|███▏      | 2780/8564 [00:24<00:49, 117.13 examples/s]Tokenizing train dataset:  33%|███▎      | 2797/8564 [00:24<00:46, 124.75 examples/s]Tokenizing train dataset:  33%|███▎      | 2812/8564 [00:25<00:44, 129.57 examples/s]Tokenizing train dataset:  33%|███▎      | 2827/8564 [00:25<00:43, 130.56 examples/s]Tokenizing train dataset:  33%|███▎      | 2844/8564 [00:25<00:40, 140.14 examples/s]Tokenizing train dataset:  33%|███▎      | 2864/8564 [00:25<00:44, 127.54 examples/s]Tokenizing train dataset:  34%|███▎      | 2880/8564 [00:25<00:44, 128.89 examples/s]Tokenizing train dataset:  34%|███▍      | 2899/8564 [00:25<00:39, 142.11 examples/s]Tokenizing train dataset:  34%|███▍      | 2918/8564 [00:25<00:36, 152.87 examples/s]Tokenizing train dataset:  34%|███▍      | 2937/8564 [00:25<00:40, 138.51 examples/s]Tokenizing train dataset:  34%|███▍      | 2952/8564 [00:26<00:41, 135.84 examples/s]Tokenizing train dataset:  35%|███▍      | 2974/8564 [00:26<00:42, 133.06 examples/s]Tokenizing train dataset:  35%|███▍      | 2995/8564 [00:26<00:37, 150.50 examples/s]Tokenizing train dataset:  35%|███▌      | 3017/8564 [00:26<00:40, 136.97 examples/s]Tokenizing train dataset:  35%|███▌      | 3035/8564 [00:26<00:43, 127.07 examples/s]Tokenizing train dataset:  36%|███▌      | 3054/8564 [00:26<00:43, 126.33 examples/s]Tokenizing train dataset:  36%|███▌      | 3072/8564 [00:27<00:45, 119.44 examples/s]Tokenizing train dataset:  36%|███▌      | 3085/8564 [00:27<00:47, 115.52 examples/s]Tokenizing train dataset:  36%|███▌      | 3098/8564 [00:27<00:46, 116.78 examples/s]Tokenizing train dataset:  36%|███▋      | 3112/8564 [00:27<00:44, 121.49 examples/s]Tokenizing train dataset:  37%|███▋      | 3132/8564 [00:27<00:49, 110.40 examples/s]Tokenizing train dataset:  37%|███▋      | 3148/8564 [00:27<00:44, 120.96 examples/s]Tokenizing train dataset:  37%|███▋      | 3163/8564 [00:27<00:46, 117.08 examples/s]Tokenizing train dataset:  37%|███▋      | 3180/8564 [00:28<00:51, 104.24 examples/s]Tokenizing train dataset:  37%|███▋      | 3197/8564 [00:28<00:52, 101.51 examples/s]Tokenizing train dataset:  37%|███▋      | 3210/8564 [00:28<00:54, 98.44 examples/s] Tokenizing train dataset:  38%|███▊      | 3223/8564 [00:28<00:51, 104.00 examples/s]Tokenizing train dataset:  38%|███▊      | 3239/8564 [00:28<00:52, 101.14 examples/s]Tokenizing train dataset:  38%|███▊      | 3255/8564 [00:28<00:47, 111.29 examples/s]Tokenizing train dataset:  38%|███▊      | 3270/8564 [00:28<00:44, 118.77 examples/s]Tokenizing train dataset:  38%|███▊      | 3289/8564 [00:28<00:45, 117.01 examples/s]Tokenizing train dataset:  39%|███▊      | 3308/8564 [00:29<00:44, 119.28 examples/s]Tokenizing train dataset:  39%|███▉      | 3326/8564 [00:29<00:45, 115.52 examples/s]Tokenizing train dataset:  39%|███▉      | 3338/8564 [00:29<00:45, 113.77 examples/s]Tokenizing train dataset:  39%|███▉      | 3351/8564 [00:29<00:45, 114.80 examples/s]Tokenizing train dataset:  39%|███▉      | 3369/8564 [00:29<00:42, 122.60 examples/s]Tokenizing train dataset:  40%|███▉      | 3386/8564 [00:29<00:40, 127.09 examples/s]Tokenizing train dataset:  40%|███▉      | 3405/8564 [00:29<00:37, 138.23 examples/s]Tokenizing train dataset:  40%|███▉      | 3421/8564 [00:30<00:37, 137.68 examples/s]Tokenizing train dataset:  40%|████      | 3436/8564 [00:30<00:36, 139.71 examples/s]Tokenizing train dataset:  40%|████      | 3459/8564 [00:30<00:36, 138.53 examples/s]Tokenizing train dataset:  41%|████      | 3473/8564 [00:30<00:38, 131.96 examples/s]Tokenizing train dataset:  41%|████      | 3490/8564 [00:30<00:43, 116.40 examples/s]Tokenizing train dataset:  41%|████      | 3507/8564 [00:30<00:39, 127.96 examples/s]Tokenizing train dataset:  41%|████      | 3524/8564 [00:30<00:36, 137.90 examples/s]Tokenizing train dataset:  41%|████▏     | 3544/8564 [00:30<00:39, 125.65 examples/s]Tokenizing train dataset:  42%|████▏     | 3560/8564 [00:31<00:42, 118.63 examples/s]Tokenizing train dataset:  42%|████▏     | 3581/8564 [00:31<00:40, 123.48 examples/s]Tokenizing train dataset:  42%|████▏     | 3600/8564 [00:31<00:37, 131.18 examples/s]Tokenizing train dataset:  42%|████▏     | 3614/8564 [00:31<00:39, 125.85 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:31<00:37, 132.60 examples/s]Tokenizing train dataset:  43%|████▎     | 3644/8564 [00:31<00:38, 128.07 examples/s]Tokenizing train dataset:  43%|████▎     | 3662/8564 [00:31<00:41, 117.28 examples/s]Tokenizing train dataset:  43%|████▎     | 3682/8564 [00:32<00:42, 115.59 examples/s]Tokenizing train dataset:  43%|████▎     | 3707/8564 [00:32<00:34, 138.90 examples/s]Tokenizing train dataset:  44%|████▎     | 3726/8564 [00:32<00:32, 148.36 examples/s]Tokenizing train dataset:  44%|████▎     | 3746/8564 [00:32<00:35, 136.76 examples/s]Tokenizing train dataset:  44%|████▍     | 3761/8564 [00:32<00:34, 139.02 examples/s]Tokenizing train dataset:  44%|████▍     | 3783/8564 [00:32<00:34, 137.52 examples/s]Tokenizing train dataset:  44%|████▍     | 3806/8564 [00:32<00:36, 130.86 examples/s]Tokenizing train dataset:  45%|████▍     | 3820/8564 [00:33<00:37, 128.02 examples/s]Tokenizing train dataset:  45%|████▍     | 3838/8564 [00:33<00:34, 137.95 examples/s]Tokenizing train dataset:  45%|████▍     | 3853/8564 [00:33<00:37, 124.29 examples/s]Tokenizing train dataset:  45%|████▌     | 3869/8564 [00:33<00:37, 125.69 examples/s]Tokenizing train dataset:  45%|████▌     | 3888/8564 [00:33<00:37, 123.34 examples/s]Tokenizing train dataset:  46%|████▌     | 3902/8564 [00:33<00:39, 119.09 examples/s]Tokenizing train dataset:  46%|████▌     | 3915/8564 [00:33<00:40, 113.58 examples/s]Tokenizing train dataset:  46%|████▌     | 3928/8564 [00:34<00:42, 109.10 examples/s]Tokenizing train dataset:  46%|████▌     | 3940/8564 [00:34<00:45, 100.52 examples/s]Tokenizing train dataset:  46%|████▌     | 3952/8564 [00:34<00:45, 100.74 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:34<00:46, 98.36 examples/s] Tokenizing train dataset:  46%|████▋     | 3974/8564 [00:34<00:48, 93.96 examples/s]Tokenizing train dataset:  47%|████▋     | 3984/8564 [00:34<00:49, 92.94 examples/s]Tokenizing train dataset:  47%|████▋     | 3998/8564 [00:34<00:44, 102.73 examples/s]Tokenizing train dataset:  47%|████▋     | 4013/8564 [00:34<00:40, 112.39 examples/s]Tokenizing train dataset:  47%|████▋     | 4030/8564 [00:35<00:38, 118.20 examples/s]Tokenizing train dataset:  47%|████▋     | 4047/8564 [00:35<00:34, 129.94 examples/s]Tokenizing train dataset:  47%|████▋     | 4062/8564 [00:35<00:35, 126.72 examples/s]Tokenizing train dataset:  48%|████▊     | 4081/8564 [00:35<00:38, 117.05 examples/s]Tokenizing train dataset:  48%|████▊     | 4100/8564 [00:35<00:33, 132.68 examples/s]Tokenizing train dataset:  48%|████▊     | 4122/8564 [00:35<00:28, 153.33 examples/s]Tokenizing train dataset:  48%|████▊     | 4145/8564 [00:35<00:29, 147.31 examples/s]Tokenizing train dataset:  49%|████▊     | 4166/8564 [00:35<00:32, 135.73 examples/s]Tokenizing train dataset:  49%|████▉     | 4182/8564 [00:36<00:31, 137.33 examples/s]Tokenizing train dataset:  49%|████▉     | 4197/8564 [00:36<00:31, 139.88 examples/s]Tokenizing train dataset:  49%|████▉     | 4217/8564 [00:36<00:31, 136.85 examples/s]Tokenizing train dataset:  49%|████▉     | 4236/8564 [00:36<00:33, 128.82 examples/s]Tokenizing train dataset:  50%|████▉     | 4250/8564 [00:36<00:33, 126.90 examples/s]Tokenizing train dataset:  50%|████▉     | 4266/8564 [00:36<00:32, 132.62 examples/s]Tokenizing train dataset:  50%|█████     | 4285/8564 [00:36<00:33, 128.66 examples/s]Tokenizing train dataset:  50%|█████     | 4304/8564 [00:37<00:35, 120.63 examples/s]Tokenizing train dataset:  50%|█████     | 4317/8564 [00:37<00:35, 120.81 examples/s]Tokenizing train dataset:  51%|█████     | 4334/8564 [00:37<00:36, 116.19 examples/s]Tokenizing train dataset:  51%|█████     | 4347/8564 [00:37<00:48, 87.12 examples/s] Tokenizing train dataset:  51%|█████     | 4362/8564 [00:37<00:42, 98.37 examples/s]Tokenizing train dataset:  51%|█████     | 4377/8564 [00:37<00:39, 107.29 examples/s]Tokenizing train dataset:  51%|█████▏    | 4395/8564 [00:37<00:34, 119.19 examples/s]Tokenizing train dataset:  52%|█████▏    | 4414/8564 [00:38<00:34, 118.93 examples/s]Tokenizing train dataset:  52%|█████▏    | 4433/8564 [00:38<00:35, 116.96 examples/s]Tokenizing train dataset:  52%|█████▏    | 4446/8564 [00:38<00:34, 117.96 examples/s]Tokenizing train dataset:  52%|█████▏    | 4460/8564 [00:38<00:36, 112.53 examples/s]Tokenizing train dataset:  52%|█████▏    | 4476/8564 [00:38<00:33, 123.15 examples/s]Tokenizing train dataset:  52%|█████▏    | 4490/8564 [00:38<00:33, 121.17 examples/s]Tokenizing train dataset:  53%|█████▎    | 4508/8564 [00:38<00:33, 120.19 examples/s]Tokenizing train dataset:  53%|█████▎    | 4527/8564 [00:39<00:35, 114.24 examples/s]Tokenizing train dataset:  53%|█████▎    | 4541/8564 [00:39<00:33, 119.63 examples/s]Tokenizing train dataset:  53%|█████▎    | 4555/8564 [00:39<00:32, 123.40 examples/s]Tokenizing train dataset:  53%|█████▎    | 4572/8564 [00:39<00:34, 116.18 examples/s]Tokenizing train dataset:  54%|█████▎    | 4591/8564 [00:39<00:31, 125.08 examples/s]Tokenizing train dataset:  54%|█████▍    | 4605/8564 [00:39<00:30, 127.94 examples/s]Tokenizing train dataset:  54%|█████▍    | 4622/8564 [00:39<00:28, 138.18 examples/s]Tokenizing train dataset:  54%|█████▍    | 4640/8564 [00:39<00:32, 121.73 examples/s]Tokenizing train dataset:  54%|█████▍    | 4659/8564 [00:40<00:32, 121.31 examples/s]Tokenizing train dataset:  55%|█████▍    | 4680/8564 [00:40<00:32, 118.89 examples/s]Tokenizing train dataset:  55%|█████▍    | 4693/8564 [00:40<00:33, 115.91 examples/s]Tokenizing train dataset:  55%|█████▍    | 4707/8564 [00:40<00:36, 104.84 examples/s]Tokenizing train dataset:  55%|█████▌    | 4718/8564 [00:40<00:37, 101.69 examples/s]Tokenizing train dataset:  55%|█████▌    | 4730/8564 [00:40<00:36, 105.26 examples/s]Tokenizing train dataset:  55%|█████▌    | 4744/8564 [00:40<00:34, 112.15 examples/s]Tokenizing train dataset:  56%|█████▌    | 4759/8564 [00:41<00:37, 102.22 examples/s]Tokenizing train dataset:  56%|█████▌    | 4771/8564 [00:41<00:43, 87.26 examples/s] Tokenizing train dataset:  56%|█████▌    | 4782/8564 [00:41<00:42, 89.87 examples/s]Tokenizing train dataset:  56%|█████▌    | 4795/8564 [00:41<00:38, 98.40 examples/s]Tokenizing train dataset:  56%|█████▌    | 4816/8564 [00:41<00:30, 123.20 examples/s]Tokenizing train dataset:  57%|█████▋    | 4843/8564 [00:41<00:23, 160.70 examples/s]Tokenizing train dataset:  57%|█████▋    | 4863/8564 [00:41<00:21, 168.32 examples/s]Tokenizing train dataset:  57%|█████▋    | 4881/8564 [00:41<00:22, 166.38 examples/s]Tokenizing train dataset:  57%|█████▋    | 4909/8564 [00:42<00:19, 189.58 examples/s]Tokenizing train dataset:  58%|█████▊    | 4932/8564 [00:42<00:19, 188.78 examples/s]Tokenizing train dataset:  58%|█████▊    | 4954/8564 [00:42<00:19, 187.13 examples/s]Tokenizing train dataset:  58%|█████▊    | 4982/8564 [00:42<00:19, 183.39 examples/s]Tokenizing train dataset:  58%|█████▊    | 5008/8564 [00:42<00:20, 174.23 examples/s]Tokenizing train dataset:  59%|█████▊    | 5029/8564 [00:42<00:19, 180.33 examples/s]Tokenizing train dataset:  59%|█████▉    | 5050/8564 [00:42<00:19, 182.45 examples/s]Tokenizing train dataset:  59%|█████▉    | 5081/8564 [00:42<00:16, 207.84 examples/s]Tokenizing train dataset:  60%|█████▉    | 5112/8564 [00:43<00:16, 206.38 examples/s]Tokenizing train dataset:  60%|█████▉    | 5136/8564 [00:43<00:16, 209.94 examples/s]Tokenizing train dataset:  60%|██████    | 5162/8564 [00:43<00:15, 216.13 examples/s]Tokenizing train dataset:  61%|██████    | 5190/8564 [00:43<00:14, 228.85 examples/s]Tokenizing train dataset:  61%|██████    | 5218/8564 [00:43<00:14, 237.88 examples/s]Tokenizing train dataset:  61%|██████    | 5245/8564 [00:43<00:14, 234.10 examples/s]Tokenizing train dataset:  62%|██████▏   | 5289/8564 [00:43<00:11, 287.28 examples/s]Tokenizing train dataset:  62%|██████▏   | 5321/8564 [00:43<00:12, 257.12 examples/s]Tokenizing train dataset:  63%|██████▎   | 5356/8564 [00:44<00:13, 240.41 examples/s]Tokenizing train dataset:  63%|██████▎   | 5385/8564 [00:44<00:14, 220.68 examples/s]Tokenizing train dataset:  63%|██████▎   | 5412/8564 [00:44<00:15, 205.07 examples/s]Tokenizing train dataset:  64%|██████▎   | 5451/8564 [00:44<00:12, 243.07 examples/s]Tokenizing train dataset:  64%|██████▍   | 5486/8564 [00:44<00:14, 212.52 examples/s]Tokenizing train dataset:  64%|██████▍   | 5511/8564 [00:44<00:14, 217.03 examples/s]Tokenizing train dataset:  65%|██████▍   | 5538/8564 [00:44<00:15, 198.99 examples/s]Tokenizing train dataset:  65%|██████▍   | 5564/8564 [00:45<00:14, 205.29 examples/s]Tokenizing train dataset:  65%|██████▌   | 5592/8564 [00:45<00:13, 216.01 examples/s]Tokenizing train dataset:  66%|██████▌   | 5617/8564 [00:45<00:13, 223.47 examples/s]Tokenizing train dataset:  66%|██████▌   | 5642/8564 [00:45<00:13, 219.50 examples/s]Tokenizing train dataset:  66%|██████▋   | 5675/8564 [00:45<00:11, 244.05 examples/s]Tokenizing train dataset:  67%|██████▋   | 5710/8564 [00:45<00:10, 271.84 examples/s]Tokenizing train dataset:  67%|██████▋   | 5744/8564 [00:45<00:11, 243.88 examples/s]Tokenizing train dataset:  67%|██████▋   | 5779/8564 [00:45<00:11, 249.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 5812/8564 [00:46<00:11, 232.87 examples/s]Tokenizing train dataset:  68%|██████▊   | 5843/8564 [00:46<00:12, 220.16 examples/s]Tokenizing train dataset:  69%|██████▊   | 5868/8564 [00:46<00:13, 196.08 examples/s]Tokenizing train dataset:  69%|██████▉   | 5895/8564 [00:46<00:14, 187.86 examples/s]Tokenizing train dataset:  69%|██████▉   | 5923/8564 [00:46<00:13, 201.68 examples/s]Tokenizing train dataset:  69%|██████▉   | 5948/8564 [00:46<00:12, 211.27 examples/s]Tokenizing train dataset:  70%|██████▉   | 5972/8564 [00:46<00:11, 216.63 examples/s]Tokenizing train dataset:  70%|███████   | 6007/8564 [00:47<00:21, 120.77 examples/s]Tokenizing train dataset:  70%|███████   | 6029/8564 [00:47<00:19, 133.38 examples/s]Tokenizing train dataset:  71%|███████   | 6058/8564 [00:47<00:19, 126.56 examples/s]Tokenizing train dataset:  71%|███████   | 6082/8564 [00:47<00:17, 143.52 examples/s]Tokenizing train dataset:  71%|███████▏  | 6114/8564 [00:48<00:13, 175.31 examples/s]Tokenizing train dataset:  72%|███████▏  | 6144/8564 [00:48<00:12, 191.37 examples/s]Tokenizing train dataset:  72%|███████▏  | 6174/8564 [00:48<00:11, 214.43 examples/s]Tokenizing train dataset:  72%|███████▏  | 6199/8564 [00:48<00:10, 221.82 examples/s]Tokenizing train dataset:  73%|███████▎  | 6225/8564 [00:48<00:10, 230.24 examples/s]Tokenizing train dataset:  73%|███████▎  | 6259/8564 [00:48<00:10, 227.42 examples/s]Tokenizing train dataset:  73%|███████▎  | 6293/8564 [00:48<00:10, 224.02 examples/s]Tokenizing train dataset:  74%|███████▍  | 6317/8564 [00:48<00:10, 223.95 examples/s]Tokenizing train dataset:  74%|███████▍  | 6351/8564 [00:49<00:10, 219.51 examples/s]Tokenizing train dataset:  74%|███████▍  | 6380/8564 [00:49<00:09, 227.22 examples/s]Tokenizing train dataset:  75%|███████▍  | 6414/8564 [00:49<00:09, 217.17 examples/s]Tokenizing train dataset:  75%|███████▌  | 6441/8564 [00:49<00:09, 227.67 examples/s]Tokenizing train dataset:  76%|███████▌  | 6469/8564 [00:49<00:10, 208.92 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [00:49<00:10, 203.82 examples/s]Tokenizing train dataset:  76%|███████▌  | 6529/8564 [00:49<00:09, 207.03 examples/s]Tokenizing train dataset:  77%|███████▋  | 6560/8564 [00:50<00:10, 195.81 examples/s]Tokenizing train dataset:  77%|███████▋  | 6582/8564 [00:50<00:09, 199.95 examples/s]Tokenizing train dataset:  77%|███████▋  | 6604/8564 [00:50<00:11, 174.24 examples/s]Tokenizing train dataset:  77%|███████▋  | 6636/8564 [00:50<00:10, 175.59 examples/s]Tokenizing train dataset:  78%|███████▊  | 6663/8564 [00:50<00:09, 195.46 examples/s]Tokenizing train dataset:  78%|███████▊  | 6690/8564 [00:50<00:08, 210.99 examples/s]Tokenizing train dataset:  78%|███████▊  | 6717/8564 [00:50<00:08, 223.66 examples/s]Tokenizing train dataset:  79%|███████▉  | 6751/8564 [00:50<00:08, 212.01 examples/s]Tokenizing train dataset:  79%|███████▉  | 6788/8564 [00:51<00:08, 221.05 examples/s]Tokenizing train dataset:  80%|███████▉  | 6819/8564 [00:51<00:08, 211.72 examples/s]Tokenizing train dataset:  80%|███████▉  | 6850/8564 [00:51<00:08, 203.52 examples/s]Tokenizing train dataset:  80%|████████  | 6879/8564 [00:51<00:07, 220.63 examples/s]Tokenizing train dataset:  81%|████████  | 6908/8564 [00:51<00:07, 235.94 examples/s]Tokenizing train dataset:  81%|████████  | 6940/8564 [00:51<00:06, 254.10 examples/s]Tokenizing train dataset:  81%|████████▏ | 6975/8564 [00:51<00:07, 209.28 examples/s]Tokenizing train dataset:  82%|████████▏ | 7003/8564 [00:52<00:08, 189.35 examples/s]Tokenizing train dataset:  82%|████████▏ | 7032/8564 [00:52<00:08, 187.87 examples/s]Tokenizing train dataset:  82%|████████▏ | 7060/8564 [00:52<00:07, 198.78 examples/s]Tokenizing train dataset:  83%|████████▎ | 7088/8564 [00:52<00:07, 209.70 examples/s]Tokenizing train dataset:  83%|████████▎ | 7111/8564 [00:52<00:07, 204.89 examples/s]Tokenizing train dataset:  83%|████████▎ | 7137/8564 [00:52<00:07, 186.34 examples/s]Tokenizing train dataset:  84%|████████▎ | 7158/8564 [00:52<00:07, 177.50 examples/s]Tokenizing train dataset:  84%|████████▍ | 7185/8564 [00:53<00:07, 195.44 examples/s]Tokenizing train dataset:  84%|████████▍ | 7211/8564 [00:53<00:06, 209.73 examples/s]Tokenizing train dataset:  84%|████████▍ | 7236/8564 [00:53<00:06, 211.58 examples/s]Tokenizing train dataset:  85%|████████▍ | 7277/8564 [00:53<00:04, 262.87 examples/s]Tokenizing train dataset:  85%|████████▌ | 7307/8564 [00:53<00:04, 267.43 examples/s]Tokenizing train dataset:  86%|████████▌ | 7340/8564 [00:53<00:05, 230.96 examples/s]Tokenizing train dataset:  86%|████████▌ | 7380/8564 [00:53<00:04, 240.98 examples/s]Tokenizing train dataset:  87%|████████▋ | 7410/8564 [00:54<00:05, 205.53 examples/s]Tokenizing train dataset:  87%|████████▋ | 7440/8564 [00:54<00:05, 216.55 examples/s]Tokenizing train dataset:  87%|████████▋ | 7465/8564 [00:54<00:05, 217.59 examples/s]Tokenizing train dataset:  87%|████████▋ | 7493/8564 [00:54<00:04, 230.39 examples/s]Tokenizing train dataset:  88%|████████▊ | 7529/8564 [00:54<00:04, 238.22 examples/s]Tokenizing train dataset:  88%|████████▊ | 7565/8564 [00:54<00:04, 228.44 examples/s]Tokenizing train dataset:  89%|████████▊ | 7590/8564 [00:54<00:04, 228.48 examples/s]Tokenizing train dataset:  89%|████████▉ | 7621/8564 [00:54<00:03, 238.98 examples/s]Tokenizing train dataset:  89%|████████▉ | 7652/8564 [00:55<00:04, 208.78 examples/s]Tokenizing train dataset:  90%|████████▉ | 7674/8564 [00:55<00:04, 206.66 examples/s]Tokenizing train dataset:  90%|████████▉ | 7697/8564 [00:55<00:04, 212.05 examples/s]Tokenizing train dataset:  90%|█████████ | 7724/8564 [00:55<00:04, 195.93 examples/s]Tokenizing train dataset:  91%|█████████ | 7757/8564 [00:55<00:04, 195.15 examples/s]Tokenizing train dataset:  91%|█████████ | 7790/8564 [00:55<00:04, 186.13 examples/s]Tokenizing train dataset:  91%|█████████ | 7810/8564 [00:55<00:04, 184.81 examples/s]Tokenizing train dataset:  91%|█████████▏| 7830/8564 [00:56<00:03, 185.14 examples/s]Tokenizing train dataset:  92%|█████████▏| 7863/8564 [00:56<00:03, 217.60 examples/s]Tokenizing train dataset:  92%|█████████▏| 7894/8564 [00:56<00:02, 234.27 examples/s]Tokenizing train dataset:  93%|█████████▎| 7930/8564 [00:56<00:02, 225.78 examples/s]Tokenizing train dataset:  93%|█████████▎| 7963/8564 [00:56<00:02, 249.78 examples/s]Tokenizing train dataset:  93%|█████████▎| 7990/8564 [00:56<00:02, 252.88 examples/s]Tokenizing train dataset:  94%|█████████▍| 8030/8564 [00:56<00:01, 273.36 examples/s]Tokenizing train dataset:  94%|█████████▍| 8063/8564 [00:56<00:02, 247.59 examples/s]Tokenizing train dataset:  95%|█████████▍| 8099/8564 [00:57<00:01, 236.25 examples/s]Tokenizing train dataset:  95%|█████████▍| 8126/8564 [00:57<00:02, 214.95 examples/s]Tokenizing train dataset:  95%|█████████▌| 8150/8564 [00:57<00:01, 218.95 examples/s]Tokenizing train dataset:  96%|█████████▌| 8183/8564 [00:57<00:01, 211.13 examples/s]Tokenizing train dataset:  96%|█████████▌| 8207/8564 [00:57<00:01, 209.73 examples/s]Tokenizing train dataset:  96%|█████████▋| 8245/8564 [00:57<00:01, 220.81 examples/s]Tokenizing train dataset:  97%|█████████▋| 8276/8564 [00:57<00:01, 240.13 examples/s]Tokenizing train dataset:  97%|█████████▋| 8305/8564 [00:58<00:01, 250.78 examples/s]Tokenizing train dataset:  97%|█████████▋| 8339/8564 [00:58<00:00, 229.44 examples/s]Tokenizing train dataset:  98%|█████████▊| 8365/8564 [00:58<00:00, 199.85 examples/s]Tokenizing train dataset:  98%|█████████▊| 8387/8564 [00:58<00:00, 203.33 examples/s]Tokenizing train dataset:  98%|█████████▊| 8417/8564 [00:58<00:00, 192.77 examples/s]Tokenizing train dataset:  99%|█████████▊| 8438/8564 [00:58<00:00, 194.94 examples/s]Tokenizing train dataset:  99%|█████████▉| 8474/8564 [00:58<00:00, 206.22 examples/s]Tokenizing train dataset:  99%|█████████▉| 8509/8564 [00:59<00:00, 201.52 examples/s]Tokenizing train dataset: 100%|█████████▉| 8530/8564 [00:59<00:00, 199.43 examples/s]Tokenizing train dataset: 100%|█████████▉| 8563/8564 [00:59<00:00, 229.66 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:59<00:00, 144.30 examples/s]
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 172/8564 [00:00<00:05, 1669.78 examples/s]Extracting prompt in train dataset:   2%|▏         | 190/8564 [00:00<00:04, 1700.48 examples/s]Extracting prompt in train dataset:   2%|▏         | 160/8564 [00:00<00:05, 1479.27 examples/s]Extracting prompt in eval dataset:  31%|███       | 292/953 [00:00<00:00, 2354.43 examples/s]Extracting prompt in eval dataset:  64%|██████▍   | 614/953 [00:00<00:00, 2729.31 examples/s]Extracting prompt in train dataset:   4%|▍         | 330/8564 [00:00<00:05, 1510.94 examples/s]Extracting prompt in train dataset:   5%|▌         | 450/8564 [00:00<00:04, 1695.13 examples/s]Extracting prompt in train dataset:   5%|▌         | 430/8564 [00:00<00:05, 1531.58 examples/s]Extracting prompt in eval dataset:  96%|█████████▌| 915/953 [00:00<00:00, 2720.95 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2722.07 examples/s]
Extracting prompt in train dataset:   6%|▌         | 500/8564 [00:00<00:05, 1390.15 examples/s]Extracting prompt in train dataset:   7%|▋         | 620/8564 [00:00<00:04, 1592.62 examples/s]Extracting prompt in train dataset:   7%|▋         | 610/8564 [00:00<00:05, 1533.72 examples/s]Extracting prompt in train dataset:   9%|▉         | 780/8564 [00:00<00:04, 1590.48 examples/s]Extracting prompt in train dataset:   9%|▉         | 766/8564 [00:00<00:05, 1515.67 examples/s]Extracting prompt in train dataset:   9%|▊         | 740/8564 [00:00<00:05, 1552.27 examples/s]Extracting prompt in train dataset:  11%|█         | 940/8564 [00:00<00:04, 1528.90 examples/s]Extracting prompt in train dataset:  11%|█         | 950/8564 [00:00<00:04, 1613.78 examples/s]Extracting prompt in train dataset:  11%|█         | 940/8564 [00:00<00:04, 1686.63 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1140/8564 [00:00<00:04, 1694.29 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1150/8564 [00:00<00:04, 1591.18 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1140/8564 [00:00<00:04, 1707.57 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1350/8564 [00:00<00:04, 1793.49 examples/s]Extracting prompt in train dataset:  15%|█▌        | 1309/8564 [00:00<00:04, 1518.38 examples/s]Extracting prompt in train dataset:  16%|█▋        | 1400/8564 [00:00<00:04, 1705.45 examples/s]Extracting prompt in train dataset:  19%|█▊        | 1593/8564 [00:00<00:03, 1764.03 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1626/8564 [00:00<00:03, 1807.84 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1534/8564 [00:00<00:04, 1496.94 examples/s]Extracting prompt in train dataset:  21%|██        | 1790/8564 [00:01<00:03, 1771.14 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1872/8564 [00:01<00:03, 1721.77 examples/s]Extracting prompt in train dataset:  21%|██▏       | 1820/8564 [00:01<00:04, 1559.07 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1970/8564 [00:01<00:03, 1668.34 examples/s]Extracting prompt in train dataset:  25%|██▌       | 2150/8564 [00:01<00:03, 1678.78 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2130/8564 [00:01<00:03, 1784.65 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2120/8564 [00:01<00:04, 1599.01 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2332/8564 [00:01<00:03, 1775.17 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2380/8564 [00:01<00:03, 1827.79 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2361/8564 [00:01<00:03, 1573.19 examples/s]Extracting prompt in train dataset:  31%|███       | 2620/8564 [00:01<00:03, 1967.40 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  30%|██▉       | 2530/8564 [00:01<00:03, 1544.49 examples/s]Extracting prompt in train dataset:  30%|███       | 2580/8564 [00:01<00:03, 1649.31 examples/s]Applying chat template to eval dataset:  46%|████▋     | 443/953 [00:00<00:00, 3936.80 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2900/8564 [00:01<00:02, 1924.56 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2700/8564 [00:01<00:03, 1519.65 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2748/8564 [00:01<00:03, 1655.63 examples/s]Extracting prompt in train dataset:  34%|███▎      | 2870/8564 [00:01<00:03, 1543.47 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3760.11 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3753.30 examples/s]
Extracting prompt in train dataset:  34%|███▍      | 2930/8564 [00:01<00:03, 1649.73 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3150/8564 [00:01<00:03, 1576.65 examples/s]Extracting prompt in train dataset:  35%|███▌      | 3030/8564 [00:01<00:03, 1480.83 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3180/8564 [00:01<00:03, 1778.96 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3190/8564 [00:02<00:03, 1507.38 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3330/8564 [00:01<00:03, 1581.40 examples/s]Extracting prompt in train dataset:  40%|████      | 3456/8564 [00:02<00:03, 1687.16 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3375/8564 [00:02<00:03, 1554.63 examples/s]Extracting prompt in train dataset:  41%|████      | 3513/8564 [00:02<00:03, 1548.43 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3656/8564 [00:02<00:02, 1735.49 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3556/8564 [00:02<00:03, 1623.12 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3810/8564 [00:02<00:02, 1661.43 examples/s]Extracting prompt in train dataset:  46%|████▌     | 3910/8564 [00:02<00:02, 1703.58 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3794/8564 [00:02<00:03, 1515.07 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4020/8564 [00:02<00:02, 1722.36 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4092/8564 [00:02<00:02, 1693.45 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4200/8564 [00:02<00:02, 1664.76 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4130/8564 [00:02<00:02, 1749.64 examples/s]Extracting prompt in train dataset:  51%|█████     | 4380/8564 [00:02<00:02, 1688.45 examples/s]Extracting prompt in train dataset:  50%|█████     | 4320/8564 [00:02<00:02, 1566.98 examples/s]Extracting prompt in train dataset:  50%|█████     | 4310/8564 [00:02<00:02, 1761.40 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 4660/8564 [00:02<00:01, 1970.29 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4560/8564 [00:02<00:02, 1566.47 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4535/8564 [00:02<00:02, 1656.38 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4750/8564 [00:02<00:02, 1639.21 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4960/8564 [00:02<00:01, 1911.20 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4744/8564 [00:02<00:02, 1508.86 examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:10, 87.37 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4922/8564 [00:03<00:02, 1574.25 examples/s]Extracting prompt in train dataset:  61%|██████▏   | 5252/8564 [00:03<00:01, 1896.29 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4910/8564 [00:03<00:02, 1465.74 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 5090/8564 [00:03<00:02, 1599.22 examples/s]Tokenizing eval dataset:   3%|▎         | 25/953 [00:00<00:09, 93.85 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5496/8564 [00:03<00:01, 1775.85 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5358/8564 [00:03<00:01, 1855.61 examples/s]Extracting prompt in train dataset:  60%|██████    | 5160/8564 [00:03<00:02, 1505.89 examples/s]Tokenizing eval dataset:   4%|▍         | 36/953 [00:00<00:09, 97.95 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5740/8564 [00:03<00:01, 1718.45 examples/s]Tokenizing eval dataset:   5%|▍         | 46/953 [00:00<00:09, 94.72 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 5578/8564 [00:03<00:01, 1691.87 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5380/8564 [00:03<00:02, 1467.58 examples/s]Extracting prompt in train dataset:  71%|███████   | 6041/8564 [00:03<00:01, 2009.39 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5550/8564 [00:03<00:02, 1471.00 examples/s]Tokenizing eval dataset:   6%|▌         | 56/953 [00:00<00:11, 78.65 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5830/8564 [00:03<00:01, 1587.87 examples/s]Extracting prompt in train dataset:  74%|███████▎  | 6310/8564 [00:03<00:01, 1931.07 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5782/8564 [00:03<00:01, 1593.14 examples/s]Extracting prompt in train dataset:  70%|███████   | 6000/8564 [00:03<00:01, 1607.24 examples/s]Tokenizing eval dataset:   8%|▊         | 73/953 [00:00<00:10, 86.42 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6180/8564 [00:03<00:01, 1629.96 examples/s]Extracting prompt in train dataset:  70%|███████   | 6023/8564 [00:03<00:01, 1569.60 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6600/8564 [00:03<00:01, 1743.51 examples/s]Tokenizing eval dataset:   9%|▉         | 86/953 [00:00<00:09, 90.79 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6373/8564 [00:03<00:01, 1678.81 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6200/8564 [00:03<00:01, 1592.88 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6790/8564 [00:03<00:01, 1769.11 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7100/8564 [00:03<00:00, 2056.88 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6577/8564 [00:04<00:01, 1460.45 examples/s]Tokenizing eval dataset:  10%|█         | 97/953 [00:01<00:11, 72.99 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 6420/8564 [00:04<00:01, 1434.57 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7370/8564 [00:04<00:00, 2188.17 examples/s]Extracting prompt in train dataset:  79%|███████▊  | 6740/8564 [00:04<00:01, 1443.06 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 7690/8564 [00:04<00:00, 2442.76 examples/s]Tokenizing eval dataset:  11%|█▏        | 108/953 [00:01<00:12, 69.28 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6630/8564 [00:04<00:01, 1301.98 examples/s]Extracting prompt in train dataset:  81%|████████  | 6897/8564 [00:04<00:01, 1368.35 examples/s]Tokenizing eval dataset:  12%|█▏        | 116/953 [00:01<00:12, 66.56 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 6810/8564 [00:04<00:01, 1353.23 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7980/8564 [00:04<00:00, 1961.11 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7105/8564 [00:04<00:01, 1362.85 examples/s]Tokenizing eval dataset:  13%|█▎        | 123/953 [00:01<00:13, 63.39 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 7030/8564 [00:04<00:01, 1500.05 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7290/8564 [00:04<00:00, 1448.66 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 8200/8564 [00:04<00:00, 1781.68 examples/s]Tokenizing eval dataset:  14%|█▎        | 131/953 [00:01<00:12, 66.27 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7200/8564 [00:04<00:00, 1536.01 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7540/8564 [00:04<00:00, 1687.51 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7360/8564 [00:04<00:00, 1545.16 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:01<00:11, 71.16 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8480/8564 [00:04<00:00, 1800.13 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7730/8564 [00:04<00:00, 1518.64 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:04<00:00, 1780.53 examples/s]
Extracting prompt in train dataset:  89%|████████▊ | 7590/8564 [00:04<00:00, 1494.50 examples/s]Tokenizing eval dataset:  16%|█▌        | 150/953 [00:02<00:12, 65.08 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7900/8564 [00:04<00:00, 1562.62 examples/s]Tokenizing eval dataset:  17%|█▋        | 158/953 [00:02<00:11, 67.15 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8090/8564 [00:05<00:00, 1647.52 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7840/8564 [00:05<00:00, 1337.83 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8311/8564 [00:05<00:00, 1749.04 examples/s]Tokenizing eval dataset:  18%|█▊        | 171/953 [00:02<00:10, 72.06 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8505/8564 [00:05<00:00, 1479.32 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8037/8564 [00:05<00:00, 1174.70 examples/s]Tokenizing eval dataset:  19%|█▉        | 181/953 [00:02<00:11, 66.96 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1595.80 examples/s]
Extracting prompt in train dataset:  96%|█████████▋| 8260/8564 [00:05<00:00, 1286.16 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:02<00:11, 63.78 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8484/8564 [00:05<00:00, 1433.51 examples/s]Tokenizing eval dataset:  21%|██        | 201/953 [00:02<00:10, 73.01 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1512.14 examples/s]
Tokenizing eval dataset:  22%|██▏       | 210/953 [00:02<00:10, 73.40 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  23%|██▎       | 219/953 [00:02<00:09, 73.57 examples/s]Applying chat template to train dataset:   1%|          | 82/8564 [00:00<00:10, 810.75 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:03<00:07, 101.37 examples/s]Applying chat template to train dataset:   2%|▏         | 169/8564 [00:00<00:10, 836.32 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:03<00:06, 109.85 examples/s]Applying chat template to train dataset:   3%|▎         | 290/8564 [00:00<00:08, 951.05 examples/s]Tokenizing eval dataset:  29%|██▉       | 275/953 [00:03<00:04, 137.06 examples/s]Applying chat template to train dataset:   5%|▍         | 399/8564 [00:00<00:08, 970.81 examples/s]Tokenizing eval dataset:  31%|███       | 295/953 [00:03<00:04, 146.41 examples/s]Applying chat template to train dataset:   6%|▌         | 523/8564 [00:00<00:07, 1020.20 examples/s]Tokenizing eval dataset:  33%|███▎      | 315/953 [00:03<00:03, 160.06 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  35%|███▍      | 332/953 [00:03<00:03, 156.57 examples/s]Applying chat template to train dataset:   8%|▊         | 671/8564 [00:00<00:08, 955.60 examples/s] Applying chat template to train dataset:   1%|          | 57/8564 [00:00<00:15, 552.15 examples/s]Tokenizing eval dataset:  37%|███▋      | 355/953 [00:03<00:03, 169.06 examples/s]Applying chat template to train dataset:   9%|▉         | 770/8564 [00:00<00:08, 963.40 examples/s]Applying chat template to train dataset:   2%|▏         | 145/8564 [00:00<00:11, 740.09 examples/s]Tokenizing eval dataset:  39%|███▉      | 373/953 [00:03<00:03, 164.75 examples/s]Applying chat template to train dataset:  11%|█         | 913/8564 [00:00<00:07, 958.06 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 258/8564 [00:00<00:09, 859.76 examples/s]Tokenizing eval dataset:  41%|████      | 391/953 [00:03<00:03, 158.73 examples/s]Applying chat template to train dataset:   1%|          | 96/8564 [00:00<00:09, 882.68 examples/s]Applying chat template to train dataset:  12%|█▏        | 1035/8564 [00:01<00:08, 881.54 examples/s]Tokenizing eval dataset:  43%|████▎     | 408/953 [00:04<00:03, 158.84 examples/s]Applying chat template to train dataset:   4%|▍         | 366/8564 [00:00<00:10, 760.96 examples/s]Applying chat template to train dataset:   2%|▏         | 202/8564 [00:00<00:08, 948.82 examples/s]Tokenizing eval dataset:  45%|████▍     | 428/953 [00:04<00:03, 165.98 examples/s]Applying chat template to train dataset:   6%|▌         | 506/8564 [00:00<00:08, 913.22 examples/s]Applying chat template to train dataset:  14%|█▎        | 1163/8564 [00:01<00:09, 795.48 examples/s]Applying chat template to train dataset:   4%|▍         | 370/8564 [00:00<00:08, 1001.42 examples/s]Tokenizing eval dataset:  47%|████▋     | 451/953 [00:04<00:02, 180.40 examples/s]Applying chat template to train dataset:  15%|█▍        | 1260/8564 [00:01<00:08, 829.28 examples/s]Applying chat template to train dataset:   7%|▋         | 630/8564 [00:00<00:09, 855.94 examples/s]Applying chat template to train dataset:   6%|▌         | 508/8564 [00:00<00:07, 1077.51 examples/s]Tokenizing eval dataset:  50%|████▉     | 474/953 [00:04<00:02, 166.52 examples/s]Applying chat template to train dataset:  16%|█▌        | 1380/8564 [00:01<00:09, 791.28 examples/s]Applying chat template to train dataset:   9%|▊         | 745/8564 [00:00<00:09, 810.12 examples/s]Applying chat template to train dataset:   8%|▊         | 673/8564 [00:00<00:07, 1068.49 examples/s]Tokenizing eval dataset:  52%|█████▏    | 500/953 [00:04<00:02, 188.58 examples/s]Applying chat template to train dataset:  10%|▉         | 846/8564 [00:01<00:09, 824.34 examples/s]Tokenizing eval dataset:  55%|█████▌    | 528/953 [00:04<00:02, 210.95 examples/s]Applying chat template to train dataset:  18%|█▊        | 1507/8564 [00:01<00:08, 787.13 examples/s]Applying chat template to train dataset:  10%|▉         | 816/8564 [00:00<00:07, 1002.31 examples/s]Applying chat template to train dataset:  11%|█         | 938/8564 [00:01<00:09, 834.98 examples/s]Tokenizing eval dataset:  59%|█████▊    | 558/953 [00:04<00:01, 215.37 examples/s]Applying chat template to train dataset:  19%|█▊        | 1598/8564 [00:01<00:08, 792.79 examples/s]Applying chat template to train dataset:  11%|█         | 920/8564 [00:00<00:07, 990.44 examples/s] Applying chat template to train dataset:  12%|█▏        | 1038/8564 [00:01<00:08, 850.56 examples/s]Applying chat template to train dataset:  20%|█▉        | 1692/8564 [00:01<00:08, 797.11 examples/s]Applying chat template to train dataset:  12%|█▏        | 1028/8564 [00:01<00:07, 986.51 examples/s]Tokenizing eval dataset:  61%|██████    | 582/953 [00:04<00:02, 182.26 examples/s]Applying chat template to train dataset:  13%|█▎        | 1150/8564 [00:01<00:08, 875.15 examples/s]Applying chat template to train dataset:  21%|██▏       | 1833/8564 [00:02<00:07, 945.51 examples/s]Applying chat template to train dataset:  14%|█▎        | 1160/8564 [00:01<00:08, 905.52 examples/s]Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:05<00:01, 185.30 examples/s]Applying chat template to train dataset:  15%|█▌        | 1310/8564 [00:01<00:07, 920.80 examples/s]Applying chat template to train dataset:  15%|█▍        | 1260/8564 [00:01<00:07, 926.44 examples/s]Applying chat template to train dataset:  23%|██▎       | 1989/8564 [00:02<00:07, 866.53 examples/s]Applying chat template to train dataset:  16%|█▋        | 1410/8564 [00:01<00:07, 923.98 examples/s]Tokenizing eval dataset:  67%|██████▋   | 638/953 [00:05<00:01, 181.82 examples/s]Applying chat template to train dataset:  16%|█▋        | 1400/8564 [00:01<00:07, 917.43 examples/s]Applying chat template to train dataset:  18%|█▊        | 1506/8564 [00:01<00:08, 879.42 examples/s]Applying chat template to train dataset:  25%|██▍       | 2130/8564 [00:02<00:07, 862.20 examples/s]Tokenizing eval dataset:  69%|██████▉   | 661/953 [00:05<00:01, 179.95 examples/s]Applying chat template to train dataset:  19%|█▊        | 1605/8564 [00:01<00:07, 906.88 examples/s]Applying chat template to train dataset:  26%|██▌       | 2240/8564 [00:02<00:06, 912.54 examples/s]Applying chat template to train dataset:  18%|█▊        | 1529/8564 [00:01<00:08, 871.02 examples/s]Tokenizing eval dataset:  73%|███████▎  | 693/953 [00:05<00:01, 187.52 examples/s]Applying chat template to train dataset:  27%|██▋       | 2336/8564 [00:02<00:06, 919.33 examples/s]Applying chat template to train dataset:  20%|██        | 1723/8564 [00:02<00:07, 858.20 examples/s]Applying chat template to train dataset:  20%|█▉        | 1670/8564 [00:01<00:07, 889.16 examples/s]Tokenizing eval dataset:  75%|███████▍  | 712/953 [00:05<00:01, 187.06 examples/s]Applying chat template to train dataset:  21%|██        | 1819/8564 [00:02<00:08, 840.54 examples/s]Applying chat template to train dataset:  29%|██▉       | 2472/8564 [00:02<00:06, 893.89 examples/s]Applying chat template to train dataset:  21%|██        | 1770/8564 [00:01<00:07, 896.59 examples/s]Tokenizing eval dataset:  77%|███████▋  | 731/953 [00:05<00:01, 180.18 examples/s]Applying chat template to train dataset:  23%|██▎       | 1938/8564 [00:02<00:07, 901.42 examples/s]Applying chat template to train dataset:  22%|██▏       | 1870/8564 [00:01<00:07, 917.26 examples/s]Applying chat template to train dataset:  30%|███       | 2612/8564 [00:02<00:06, 905.62 examples/s]Tokenizing eval dataset:  79%|███████▉  | 754/953 [00:05<00:01, 165.22 examples/s]Applying chat template to train dataset:  24%|██▎       | 2030/8564 [00:02<00:07, 898.26 examples/s]Applying chat template to train dataset:  23%|██▎       | 1993/8564 [00:02<00:07, 860.17 examples/s]Applying chat template to train dataset:  32%|███▏      | 2752/8564 [00:03<00:06, 913.33 examples/s]Tokenizing eval dataset:  81%|████████  | 771/953 [00:06<00:01, 163.29 examples/s]Applying chat template to train dataset:  25%|██▍       | 2132/8564 [00:02<00:06, 929.90 examples/s]Applying chat template to train dataset:  25%|██▍       | 2108/8564 [00:02<00:07, 920.22 examples/s]Applying chat template to train dataset:  34%|███▎      | 2886/8564 [00:03<00:06, 875.51 examples/s]Tokenizing eval dataset:  83%|████████▎ | 790/953 [00:06<00:01, 148.26 examples/s]Applying chat template to train dataset:  27%|██▋       | 2274/8564 [00:02<00:06, 916.12 examples/s]Applying chat template to train dataset:  26%|██▋       | 2255/8564 [00:02<00:07, 882.13 examples/s]Applying chat template to train dataset:  35%|███▍      | 2984/8564 [00:03<00:06, 866.27 examples/s]Applying chat template to train dataset:  28%|██▊       | 2370/8564 [00:02<00:06, 902.35 examples/s]Tokenizing eval dataset:  85%|████████▌ | 812/953 [00:06<00:00, 146.34 examples/s]Applying chat template to train dataset:  27%|██▋       | 2354/8564 [00:02<00:06, 904.92 examples/s]Applying chat template to train dataset:  29%|██▉       | 2473/8564 [00:02<00:06, 904.78 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:06<00:00, 148.09 examples/s]Applying chat template to train dataset:  29%|██▉       | 2496/8564 [00:02<00:05, 1029.00 examples/s]Applying chat template to train dataset:  36%|███▌      | 3092/8564 [00:03<00:07, 699.63 examples/s]Tokenizing eval dataset:  89%|████████▉ | 847/953 [00:06<00:00, 149.66 examples/s]Applying chat template to train dataset:  31%|███       | 2626/8564 [00:03<00:06, 891.17 examples/s]Applying chat template to train dataset:  37%|███▋      | 3180/8564 [00:03<00:07, 735.36 examples/s]Applying chat template to train dataset:  31%|███       | 2640/8564 [00:02<00:06, 981.90 examples/s] Applying chat template to train dataset:  32%|███▏      | 2735/8564 [00:03<00:06, 932.92 examples/s]Applying chat template to train dataset:  38%|███▊      | 3269/8564 [00:03<00:06, 769.59 examples/s]Tokenizing eval dataset:  91%|█████████ | 869/953 [00:06<00:00, 142.42 examples/s]Applying chat template to train dataset:  33%|███▎      | 2834/8564 [00:03<00:06, 946.12 examples/s]Applying chat template to train dataset:  32%|███▏      | 2782/8564 [00:02<00:05, 968.70 examples/s]Applying chat template to train dataset:  39%|███▉      | 3360/8564 [00:03<00:06, 802.50 examples/s]Tokenizing eval dataset:  93%|█████████▎| 885/953 [00:06<00:00, 145.57 examples/s]Applying chat template to train dataset:  35%|███▍      | 2960/8564 [00:03<00:06, 897.72 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:06<00:00, 161.30 examples/s]Applying chat template to train dataset:  34%|███▍      | 2905/8564 [00:03<00:06, 917.95 examples/s]Applying chat template to train dataset:  41%|████      | 3483/8564 [00:04<00:06, 772.77 examples/s]Tokenizing eval dataset:  97%|█████████▋| 926/953 [00:07<00:00, 161.53 examples/s]Applying chat template to train dataset:  35%|███▌      | 3038/8564 [00:03<00:06, 889.02 examples/s]Applying chat template to train dataset:  42%|████▏     | 3612/8564 [00:04<00:06, 787.13 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:07<00:00, 178.30 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:07<00:00, 131.58 examples/s]
Applying chat template to train dataset:  36%|███▌      | 3093/8564 [00:03<00:07, 696.26 examples/s]Applying chat template to train dataset:  43%|████▎     | 3708/8564 [00:04<00:05, 812.24 examples/s]Applying chat template to train dataset:  38%|███▊      | 3255/8564 [00:03<00:06, 823.51 examples/s]Applying chat template to train dataset:  44%|████▍     | 3803/8564 [00:04<00:06, 736.36 examples/s]Applying chat template to train dataset:  37%|███▋      | 3148/8564 [00:03<00:08, 625.99 examples/s]Applying chat template to train dataset:  39%|███▉      | 3357/8564 [00:03<00:06, 858.50 examples/s]Applying chat template to train dataset:  45%|████▌     | 3888/8564 [00:04<00:06, 755.80 examples/s]Applying chat template to train dataset:  38%|███▊      | 3279/8564 [00:03<00:08, 641.98 examples/s]Applying chat template to train dataset:  41%|████      | 3481/8564 [00:04<00:06, 809.48 examples/s]Applying chat template to train dataset:  46%|████▋     | 3970/8564 [00:04<00:05, 765.84 examples/s]Applying chat template to train dataset:  48%|████▊     | 4071/8564 [00:04<00:05, 828.36 examples/s]Applying chat template to train dataset:  39%|███▉      | 3360/8564 [00:03<00:08, 642.73 examples/s]Applying chat template to train dataset:  42%|████▏     | 3584/8564 [00:04<00:06, 772.08 examples/s]Applying chat template to train dataset:  49%|████▊     | 4156/8564 [00:04<00:05, 832.88 examples/s]Applying chat template to train dataset:  40%|████      | 3431/8564 [00:04<00:08, 624.49 examples/s]Applying chat template to train dataset:  43%|████▎     | 3669/8564 [00:04<00:07, 682.39 examples/s]Applying chat template to train dataset:  50%|████▉     | 4279/8564 [00:05<00:04, 882.14 examples/s]Applying chat template to train dataset:  51%|█████     | 4378/8564 [00:05<00:04, 909.85 examples/s]Applying chat template to train dataset:  41%|████▏     | 3543/8564 [00:04<00:08, 606.39 examples/s]Applying chat template to train dataset:  44%|████▍     | 3770/8564 [00:04<00:07, 609.30 examples/s]Applying chat template to train dataset:  42%|████▏     | 3632/8564 [00:04<00:07, 662.38 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4487/8564 [00:05<00:05, 785.99 examples/s]Applying chat template to train dataset:  44%|████▎     | 3730/8564 [00:04<00:06, 700.06 examples/s]Applying chat template to train dataset:  45%|████▌     | 3856/8564 [00:04<00:07, 601.10 examples/s]Applying chat template to train dataset:  54%|█████▎    | 4592/8564 [00:05<00:04, 850.27 examples/s]Applying chat template to train dataset:  45%|████▍     | 3829/8564 [00:04<00:06, 762.65 examples/s]Applying chat template to train dataset:  46%|████▌     | 3926/8564 [00:04<00:07, 618.24 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4703/8564 [00:05<00:04, 916.31 examples/s]Applying chat template to train dataset:  47%|████▋     | 3991/8564 [00:04<00:07, 613.56 examples/s]Applying chat template to train dataset:  46%|████▌     | 3930/8564 [00:04<00:06, 739.59 examples/s]Applying chat template to train dataset:  56%|█████▋    | 4820/8564 [00:05<00:04, 922.88 examples/s]Applying chat template to train dataset:  47%|████▋     | 4030/8564 [00:04<00:05, 779.13 examples/s]Applying chat template to train dataset:  48%|████▊     | 4085/8564 [00:05<00:07, 595.22 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4954/8564 [00:05<00:04, 861.24 examples/s]Applying chat template to train dataset:  48%|████▊     | 4132/8564 [00:04<00:05, 807.78 examples/s]Applying chat template to train dataset:  49%|████▉     | 4190/8564 [00:05<00:06, 681.10 examples/s]Applying chat template to train dataset:  50%|████▉     | 4275/8564 [00:05<00:06, 711.34 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5050/8564 [00:06<00:04, 749.22 examples/s]Applying chat template to train dataset:  50%|████▉     | 4241/8564 [00:05<00:05, 766.37 examples/s]Applying chat template to train dataset:  60%|██████    | 5170/8564 [00:06<00:04, 822.01 examples/s]Applying chat template to train dataset:  51%|█████     | 4362/8564 [00:05<00:04, 849.49 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4394/8564 [00:05<00:06, 646.60 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4474/8564 [00:05<00:04, 913.98 examples/s]Applying chat template to train dataset:  61%|██████▏   | 5263/8564 [00:06<00:04, 791.30 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4490/8564 [00:05<00:05, 712.13 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4570/8564 [00:05<00:04, 922.01 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5373/8564 [00:06<00:04, 768.10 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4669/8564 [00:05<00:04, 924.90 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4606/8564 [00:05<00:05, 679.79 examples/s]Applying chat template to train dataset:  64%|██████▎   | 5453/8564 [00:06<00:04, 744.28 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4789/8564 [00:05<00:04, 877.10 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4690/8564 [00:05<00:05, 680.48 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5550/8564 [00:06<00:03, 768.66 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4790/8564 [00:06<00:05, 748.32 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5658/8564 [00:06<00:03, 793.70 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4919/8564 [00:05<00:04, 785.78 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5761/8564 [00:06<00:03, 837.50 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4931/8564 [00:06<00:04, 798.81 examples/s]Applying chat template to train dataset:  59%|█████▊    | 5010/8564 [00:05<00:04, 771.67 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5852/8564 [00:06<00:03, 855.38 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5053/8564 [00:06<00:04, 788.45 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5134/8564 [00:06<00:04, 754.63 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5947/8564 [00:07<00:03, 841.17 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5138/8564 [00:06<00:04, 760.55 examples/s]Applying chat template to train dataset:  61%|██████    | 5239/8564 [00:06<00:04, 820.30 examples/s]Applying chat template to train dataset:  61%|██████    | 5231/8564 [00:06<00:04, 774.13 examples/s]Applying chat template to train dataset:  71%|███████   | 6055/8564 [00:07<00:03, 698.64 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5359/8564 [00:06<00:04, 750.76 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5336/8564 [00:06<00:04, 801.56 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6138/8564 [00:07<00:03, 683.33 examples/s]Applying chat template to train dataset:  64%|██████▎   | 5458/8564 [00:06<00:04, 775.81 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6240/8564 [00:07<00:03, 747.97 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5436/8564 [00:06<00:04, 769.35 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6343/8564 [00:07<00:02, 813.43 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5579/8564 [00:06<00:03, 780.58 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5514/8564 [00:06<00:04, 745.03 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5677/8564 [00:06<00:03, 801.17 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6430/8564 [00:07<00:02, 791.11 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5625/8564 [00:07<00:04, 699.61 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5779/8564 [00:06<00:03, 853.14 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6560/8564 [00:07<00:02, 747.24 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5890/8564 [00:07<00:02, 904.14 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5720/8564 [00:07<00:04, 644.32 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6662/8564 [00:08<00:02, 804.13 examples/s]Applying chat template to train dataset:  70%|███████   | 6014/8564 [00:07<00:02, 990.56 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6770/8564 [00:08<00:02, 871.66 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6123/8564 [00:07<00:02, 974.30 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5829/8564 [00:07<00:04, 603.13 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6237/8564 [00:07<00:02, 1017.45 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5930/8564 [00:07<00:03, 669.24 examples/s]Applying chat template to train dataset:  81%|████████  | 6910/8564 [00:08<00:02, 822.31 examples/s]Applying chat template to train dataset:  70%|███████   | 6011/8564 [00:07<00:03, 687.30 examples/s]Applying chat template to train dataset:  82%|████████▏ | 6997/8564 [00:08<00:01, 808.15 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6366/8564 [00:07<00:02, 891.03 examples/s] Applying chat template to train dataset:  83%|████████▎ | 7090/8564 [00:08<00:01, 803.66 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6479/8564 [00:07<00:02, 900.27 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6149/8564 [00:07<00:03, 699.55 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6583/8564 [00:07<00:02, 935.09 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7180/8564 [00:08<00:01, 729.62 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6243/8564 [00:08<00:03, 700.88 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6683/8564 [00:07<00:02, 932.42 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6322/8564 [00:08<00:03, 709.44 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7280/8564 [00:08<00:01, 685.44 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6788/8564 [00:07<00:01, 927.69 examples/s]Applying chat template to train dataset:  80%|████████  | 6889/8564 [00:08<00:01, 946.67 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6419/8564 [00:08<00:03, 663.00 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7370/8564 [00:09<00:01, 656.48 examples/s]Applying chat template to train dataset:  82%|████████▏ | 6991/8564 [00:08<00:01, 932.39 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7460/8564 [00:09<00:01, 710.73 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6513/8564 [00:08<00:03, 605.60 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7134/8564 [00:08<00:01, 935.77 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7572/8564 [00:09<00:01, 701.31 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6608/8564 [00:08<00:02, 654.39 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7658/8564 [00:09<00:01, 734.70 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6690/8564 [00:08<00:02, 662.35 examples/s]Applying chat template to train dataset:  90%|█████████ | 7748/8564 [00:09<00:01, 766.09 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7286/8564 [00:08<00:01, 778.47 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7381/8564 [00:08<00:01, 797.06 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6807/8564 [00:08<00:02, 642.83 examples/s]Applying chat template to train dataset:  81%|████████  | 6922/8564 [00:09<00:02, 751.32 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7517/8564 [00:08<00:01, 777.24 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7860/8564 [00:09<00:01, 544.54 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7631/8564 [00:08<00:01, 853.11 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7963/8564 [00:09<00:00, 636.31 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7041/8564 [00:09<00:02, 690.84 examples/s]Applying chat template to train dataset:  90%|█████████ | 7733/8564 [00:09<00:00, 883.91 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8061/8564 [00:10<00:00, 706.54 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8161/8564 [00:10<00:00, 763.44 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7144/8564 [00:09<00:02, 610.02 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7848/8564 [00:09<00:00, 784.69 examples/s]Applying chat template to train dataset:  96%|█████████▋| 8261/8564 [00:10<00:00, 812.90 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7961/8564 [00:09<00:00, 862.00 examples/s]Applying chat template to train dataset:  85%|████████▍ | 7248/8564 [00:09<00:02, 638.52 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8364/8564 [00:10<00:00, 867.83 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8066/8564 [00:09<00:00, 880.56 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8471/8564 [00:10<00:00, 887.56 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7340/8564 [00:09<00:01, 624.77 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8174/8564 [00:09<00:00, 919.39 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 810.37 examples/s]
Applying chat template to train dataset:  97%|█████████▋| 8340/8564 [00:09<00:00, 1111.33 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7445/8564 [00:09<00:01, 631.21 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7551/8564 [00:10<00:01, 720.29 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8491/8564 [00:09<00:00, 1072.24 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7656/8564 [00:10<00:01, 780.37 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:09<00:00, 862.11 examples/s] 
Applying chat template to train dataset:  90%|█████████ | 7749/8564 [00:10<00:01, 779.21 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7844/8564 [00:10<00:01, 614.96 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7965/8564 [00:10<00:00, 737.66 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8070/8564 [00:10<00:00, 711.42 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8159/8564 [00:10<00:00, 704.20 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8272/8564 [00:11<00:00, 801.74 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8406/8564 [00:11<00:00, 912.60 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8553/8564 [00:11<00:00, 992.93 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:11<00:00, 758.34 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 8/8564 [00:00<02:19, 61.17 examples/s]Tokenizing train dataset:   0%|          | 26/8564 [00:00<01:12, 118.52 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 43/8564 [00:00<01:03, 133.89 examples/s]Tokenizing train dataset:   0%|          | 15/8564 [00:00<01:07, 126.50 examples/s]Tokenizing train dataset:   1%|          | 57/8564 [00:00<01:15, 112.15 examples/s]Tokenizing train dataset:   0%|          | 32/8564 [00:00<01:02, 137.03 examples/s]Tokenizing train dataset:   1%|          | 74/8564 [00:00<01:09, 122.46 examples/s]Tokenizing train dataset:   1%|          | 87/8564 [00:00<01:12, 117.08 examples/s]Tokenizing train dataset:   1%|          | 50/8564 [00:00<01:31, 92.82 examples/s] Tokenizing train dataset:   1%|          | 100/8564 [00:00<01:16, 110.96 examples/s]Tokenizing train dataset:   1%|          | 63/8564 [00:00<01:26, 98.55 examples/s]Tokenizing train dataset:   1%|▏         | 114/8564 [00:01<01:24, 99.73 examples/s] Tokenizing train dataset:   1%|          | 76/8564 [00:00<01:25, 99.81 examples/s]Tokenizing train dataset:   1%|          | 87/8564 [00:00<01:32, 91.35 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|▏         | 128/8564 [00:01<01:30, 93.29 examples/s]Tokenizing train dataset:   1%|          | 99/8564 [00:01<01:30, 93.91 examples/s]Tokenizing train dataset:   0%|          | 20/8564 [00:00<00:48, 176.12 examples/s]Tokenizing train dataset:   2%|▏         | 138/8564 [00:01<01:49, 77.28 examples/s]Tokenizing train dataset:   0%|          | 40/8564 [00:00<00:49, 171.40 examples/s]Tokenizing train dataset:   1%|▏         | 113/8564 [00:01<01:33, 90.29 examples/s]Tokenizing train dataset:   2%|▏         | 148/8564 [00:01<01:45, 79.61 examples/s]Tokenizing train dataset:   1%|          | 59/8564 [00:00<01:14, 114.18 examples/s]Tokenizing train dataset:   2%|▏         | 160/8564 [00:01<01:46, 78.56 examples/s]Tokenizing train dataset:   1%|▏         | 123/8564 [00:01<01:54, 73.45 examples/s]Tokenizing train dataset:   1%|          | 73/8564 [00:00<01:13, 115.31 examples/s]Tokenizing train dataset:   2%|▏         | 137/8564 [00:01<01:39, 85.05 examples/s]Tokenizing train dataset:   2%|▏         | 171/8564 [00:01<01:56, 72.28 examples/s]Tokenizing train dataset:   2%|▏         | 149/8564 [00:01<01:31, 92.29 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<01:18, 108.29 examples/s]Tokenizing train dataset:   2%|▏         | 160/8564 [00:01<01:33, 90.18 examples/s]Tokenizing train dataset:   2%|▏         | 184/8564 [00:02<02:03, 67.62 examples/s]Tokenizing train dataset:   1%|          | 106/8564 [00:00<01:25, 98.40 examples/s]Tokenizing train dataset:   2%|▏         | 172/8564 [00:01<01:41, 82.70 examples/s]Tokenizing train dataset:   2%|▏         | 195/8564 [00:02<02:00, 69.38 examples/s]Tokenizing train dataset:   2%|▏         | 182/8564 [00:02<01:37, 86.08 examples/s]Tokenizing train dataset:   1%|▏         | 121/8564 [00:01<01:27, 96.00 examples/s]Tokenizing train dataset:   2%|▏         | 203/8564 [00:02<02:04, 67.09 examples/s]Tokenizing train dataset:   2%|▏         | 133/8564 [00:01<01:23, 100.89 examples/s]Tokenizing train dataset:   2%|▏         | 196/8564 [00:02<01:29, 93.89 examples/s]Tokenizing train dataset:   2%|▏         | 210/8564 [00:02<02:07, 65.33 examples/s]Tokenizing train dataset:   2%|▏         | 147/8564 [00:01<01:21, 102.65 examples/s]Tokenizing train dataset:   2%|▏         | 207/8564 [00:02<01:36, 86.44 examples/s]Tokenizing train dataset:   3%|▎         | 226/8564 [00:02<01:42, 81.08 examples/s]Tokenizing train dataset:   2%|▏         | 163/8564 [00:01<01:23, 100.50 examples/s]Tokenizing train dataset:   3%|▎         | 222/8564 [00:02<01:23, 99.85 examples/s]Tokenizing train dataset:   3%|▎         | 235/8564 [00:02<01:54, 72.45 examples/s]Tokenizing train dataset:   3%|▎         | 233/8564 [00:02<01:29, 93.06 examples/s]Tokenizing train dataset:   2%|▏         | 174/8564 [00:01<01:34, 88.80 examples/s] Tokenizing train dataset:   3%|▎         | 247/8564 [00:02<01:44, 79.83 examples/s]Tokenizing train dataset:   3%|▎         | 258/8564 [00:03<01:37, 85.61 examples/s]Tokenizing train dataset:   2%|▏         | 187/8564 [00:01<01:30, 92.76 examples/s]Tokenizing train dataset:   3%|▎         | 247/8564 [00:02<01:39, 83.89 examples/s]Tokenizing train dataset:   3%|▎         | 275/8564 [00:03<01:18, 105.18 examples/s]Tokenizing train dataset:   2%|▏         | 198/8564 [00:01<01:34, 88.53 examples/s]Tokenizing train dataset:   3%|▎         | 256/8564 [00:02<01:50, 75.46 examples/s]Tokenizing train dataset:   3%|▎         | 288/8564 [00:03<01:19, 104.02 examples/s]Tokenizing train dataset:   2%|▏         | 208/8564 [00:02<01:34, 88.30 examples/s]Tokenizing train dataset:   3%|▎         | 270/8564 [00:03<01:43, 79.79 examples/s]Tokenizing train dataset:   3%|▎         | 220/8564 [00:02<01:29, 92.96 examples/s]Tokenizing train dataset:   4%|▎         | 302/8564 [00:03<01:24, 97.92 examples/s] Tokenizing train dataset:   3%|▎         | 231/8564 [00:02<01:27, 95.01 examples/s]Tokenizing train dataset:   4%|▎         | 313/8564 [00:03<01:24, 98.16 examples/s]Tokenizing train dataset:   3%|▎         | 280/8564 [00:03<01:54, 72.12 examples/s]Tokenizing train dataset:   3%|▎         | 244/8564 [00:02<01:24, 98.59 examples/s]Tokenizing train dataset:   4%|▍         | 327/8564 [00:03<01:19, 103.80 examples/s]Tokenizing train dataset:   3%|▎         | 289/8564 [00:03<01:54, 72.23 examples/s]Tokenizing train dataset:   3%|▎         | 259/8564 [00:02<01:16, 108.93 examples/s]Tokenizing train dataset:   3%|▎         | 297/8564 [00:03<01:55, 71.66 examples/s]Tokenizing train dataset:   4%|▍         | 341/8564 [00:03<01:25, 96.35 examples/s] Tokenizing train dataset:   3%|▎         | 274/8564 [00:02<01:10, 117.77 examples/s]Tokenizing train dataset:   4%|▍         | 352/8564 [00:03<01:26, 94.67 examples/s]Tokenizing train dataset:   3%|▎         | 287/8564 [00:02<01:11, 115.31 examples/s]Tokenizing train dataset:   4%|▎         | 309/8564 [00:03<02:02, 67.27 examples/s]Tokenizing train dataset:   4%|▍         | 363/8564 [00:04<01:28, 93.05 examples/s]Tokenizing train dataset:   4%|▍         | 322/8564 [00:03<01:51, 73.86 examples/s]Tokenizing train dataset:   4%|▎         | 300/8564 [00:02<01:21, 100.91 examples/s]Tokenizing train dataset:   4%|▍         | 375/8564 [00:04<01:37, 84.08 examples/s]Tokenizing train dataset:   4%|▍         | 332/8564 [00:03<01:47, 76.34 examples/s]Tokenizing train dataset:   4%|▎         | 312/8564 [00:03<01:21, 101.43 examples/s]Tokenizing train dataset:   4%|▍         | 341/8564 [00:04<01:44, 78.33 examples/s]Tokenizing train dataset:   5%|▍         | 386/8564 [00:04<01:39, 82.31 examples/s]Tokenizing train dataset:   4%|▍         | 327/8564 [00:03<01:23, 98.65 examples/s] Tokenizing train dataset:   4%|▍         | 349/8564 [00:04<01:46, 76.85 examples/s]Tokenizing train dataset:   4%|▍         | 367/8564 [00:04<01:20, 101.85 examples/s]Tokenizing train dataset:   4%|▍         | 341/8564 [00:03<01:27, 94.31 examples/s]Tokenizing train dataset:   5%|▍         | 398/8564 [00:04<01:53, 72.19 examples/s]Tokenizing train dataset:   5%|▍         | 412/8564 [00:04<01:36, 84.90 examples/s]Tokenizing train dataset:   4%|▍         | 381/8564 [00:04<01:18, 103.65 examples/s]Tokenizing train dataset:   4%|▍         | 351/8564 [00:03<01:43, 78.97 examples/s]Tokenizing train dataset:   5%|▍         | 426/8564 [00:04<01:28, 92.37 examples/s]Tokenizing train dataset:   5%|▍         | 394/8564 [00:04<01:34, 86.73 examples/s] Tokenizing train dataset:   5%|▌         | 437/8564 [00:04<01:26, 93.68 examples/s]Tokenizing train dataset:   4%|▍         | 364/8564 [00:03<01:46, 76.79 examples/s]Tokenizing train dataset:   5%|▌         | 449/8564 [00:05<01:32, 88.14 examples/s]Tokenizing train dataset:   4%|▍         | 372/8564 [00:03<01:55, 71.20 examples/s]Tokenizing train dataset:   5%|▍         | 405/8564 [00:04<01:51, 73.03 examples/s]Tokenizing train dataset:   4%|▍         | 384/8564 [00:03<01:41, 80.82 examples/s]Tokenizing train dataset:   5%|▍         | 416/8564 [00:04<01:45, 77.29 examples/s]Tokenizing train dataset:   5%|▌         | 462/8564 [00:05<01:37, 82.91 examples/s]Tokenizing train dataset:   5%|▍         | 394/8564 [00:04<01:42, 79.95 examples/s]Tokenizing train dataset:   5%|▍         | 426/8564 [00:05<01:47, 75.57 examples/s]Tokenizing train dataset:   6%|▌         | 473/8564 [00:05<01:36, 83.74 examples/s]Tokenizing train dataset:   5%|▍         | 403/8564 [00:04<01:43, 78.70 examples/s]Tokenizing train dataset:   5%|▍         | 416/8564 [00:04<01:34, 86.39 examples/s]Tokenizing train dataset:   5%|▌         | 437/8564 [00:05<01:58, 68.71 examples/s]Tokenizing train dataset:   6%|▌         | 483/8564 [00:05<01:52, 72.05 examples/s]Tokenizing train dataset:   5%|▍         | 426/8564 [00:04<01:33, 87.25 examples/s]Tokenizing train dataset:   6%|▌         | 492/8564 [00:05<01:48, 74.73 examples/s]Tokenizing train dataset:   5%|▌         | 450/8564 [00:05<01:54, 70.58 examples/s]Tokenizing train dataset:   6%|▌         | 505/8564 [00:05<01:37, 83.08 examples/s]Tokenizing train dataset:   5%|▌         | 436/8564 [00:04<01:39, 81.47 examples/s]Tokenizing train dataset:   5%|▌         | 462/8564 [00:05<01:41, 79.62 examples/s]Tokenizing train dataset:   6%|▌         | 472/8564 [00:05<01:37, 83.18 examples/s]Tokenizing train dataset:   6%|▌         | 519/8564 [00:05<01:35, 84.00 examples/s]Tokenizing train dataset:   5%|▌         | 449/8564 [00:04<01:50, 73.25 examples/s]Tokenizing train dataset:   6%|▌         | 534/8564 [00:06<01:33, 86.20 examples/s]Tokenizing train dataset:   6%|▌         | 487/8564 [00:05<01:39, 80.86 examples/s]Tokenizing train dataset:   5%|▌         | 457/8564 [00:04<01:59, 67.88 examples/s]Tokenizing train dataset:   6%|▋         | 545/8564 [00:06<01:33, 86.00 examples/s]Tokenizing train dataset:   6%|▌         | 498/8564 [00:05<01:36, 83.55 examples/s]Tokenizing train dataset:   5%|▌         | 465/8564 [00:05<02:02, 66.22 examples/s]Tokenizing train dataset:   6%|▌         | 507/8564 [00:06<01:35, 84.14 examples/s]Tokenizing train dataset:   6%|▌         | 475/8564 [00:05<01:55, 69.74 examples/s]Tokenizing train dataset:   7%|▋         | 557/8564 [00:06<01:42, 77.75 examples/s]Tokenizing train dataset:   6%|▌         | 518/8564 [00:06<01:35, 84.22 examples/s]Tokenizing train dataset:   7%|▋         | 566/8564 [00:06<01:47, 74.33 examples/s]Tokenizing train dataset:   6%|▌         | 485/8564 [00:05<02:05, 64.20 examples/s]Tokenizing train dataset:   6%|▌         | 532/8564 [00:06<01:25, 94.38 examples/s]Tokenizing train dataset:   7%|▋         | 576/8564 [00:06<01:45, 75.65 examples/s]Tokenizing train dataset:   6%|▌         | 497/8564 [00:05<01:53, 71.22 examples/s]Tokenizing train dataset:   6%|▋         | 545/8564 [00:06<01:37, 82.56 examples/s]Tokenizing train dataset:   6%|▌         | 507/8564 [00:05<01:46, 75.87 examples/s]Tokenizing train dataset:   7%|▋         | 585/8564 [00:06<01:50, 72.12 examples/s]Tokenizing train dataset:   6%|▋         | 555/8564 [00:06<01:40, 79.89 examples/s]Tokenizing train dataset:   6%|▌         | 517/8564 [00:05<01:39, 80.54 examples/s]Tokenizing train dataset:   7%|▋         | 594/8564 [00:06<01:47, 74.32 examples/s]Tokenizing train dataset:   7%|▋         | 566/8564 [00:06<01:37, 81.77 examples/s]Tokenizing train dataset:   6%|▌         | 528/8564 [00:05<01:38, 81.38 examples/s]Tokenizing train dataset:   7%|▋         | 603/8564 [00:07<01:49, 72.43 examples/s]Tokenizing train dataset:   7%|▋         | 576/8564 [00:06<01:39, 80.39 examples/s]Tokenizing train dataset:   7%|▋         | 614/8564 [00:07<01:41, 78.63 examples/s]Tokenizing train dataset:   6%|▋         | 540/8564 [00:06<01:38, 81.15 examples/s]Tokenizing train dataset:   7%|▋         | 586/8564 [00:07<01:40, 79.71 examples/s]Tokenizing train dataset:   7%|▋         | 625/8564 [00:07<01:39, 80.07 examples/s]Tokenizing train dataset:   6%|▋         | 551/8564 [00:06<01:52, 71.08 examples/s]Tokenizing train dataset:   7%|▋         | 595/8564 [00:07<01:38, 81.17 examples/s]Tokenizing train dataset:   7%|▋         | 637/8564 [00:07<01:35, 82.85 examples/s]Tokenizing train dataset:   7%|▋         | 560/8564 [00:06<01:52, 71.05 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:07<01:38, 80.95 examples/s]Tokenizing train dataset:   7%|▋         | 569/8564 [00:06<01:47, 74.39 examples/s]Tokenizing train dataset:   8%|▊         | 654/8564 [00:07<01:39, 79.43 examples/s]Tokenizing train dataset:   7%|▋         | 580/8564 [00:06<01:41, 78.70 examples/s]Tokenizing train dataset:   7%|▋         | 630/8564 [00:07<01:28, 89.48 examples/s]Tokenizing train dataset:   7%|▋         | 592/8564 [00:06<01:36, 82.24 examples/s]Tokenizing train dataset:   8%|▊         | 669/8564 [00:07<01:47, 73.40 examples/s]Tokenizing train dataset:   8%|▊         | 644/8564 [00:07<01:32, 85.38 examples/s]Tokenizing train dataset:   8%|▊         | 662/8564 [00:07<01:18, 100.51 examples/s]Tokenizing train dataset:   8%|▊         | 680/8564 [00:08<01:55, 68.14 examples/s]Tokenizing train dataset:   7%|▋         | 603/8564 [00:06<02:06, 62.99 examples/s]Tokenizing train dataset:   8%|▊         | 690/8564 [00:08<01:53, 69.24 examples/s]Tokenizing train dataset:   8%|▊         | 680/8564 [00:07<01:16, 103.08 examples/s]Tokenizing train dataset:   7%|▋         | 614/8564 [00:07<01:55, 68.91 examples/s]Tokenizing train dataset:   8%|▊         | 700/8564 [00:08<01:53, 69.52 examples/s]Tokenizing train dataset:   8%|▊         | 696/8564 [00:08<01:24, 93.43 examples/s] Tokenizing train dataset:   7%|▋         | 630/8564 [00:07<01:45, 75.48 examples/s]Tokenizing train dataset:   8%|▊         | 712/8564 [00:08<01:44, 75.49 examples/s]Tokenizing train dataset:   8%|▊         | 712/8564 [00:08<01:17, 101.48 examples/s]Tokenizing train dataset:   7%|▋         | 638/8564 [00:07<01:50, 71.43 examples/s]Tokenizing train dataset:   8%|▊         | 720/8564 [00:08<01:48, 72.59 examples/s]Tokenizing train dataset:   9%|▊         | 731/8564 [00:08<01:06, 117.84 examples/s]Tokenizing train dataset:   8%|▊         | 646/8564 [00:07<01:53, 70.03 examples/s]Tokenizing train dataset:   9%|▊         | 733/8564 [00:08<01:37, 79.98 examples/s]Tokenizing train dataset:   8%|▊         | 655/8564 [00:07<01:51, 70.63 examples/s]Tokenizing train dataset:   9%|▉         | 750/8564 [00:08<01:09, 113.06 examples/s]Tokenizing train dataset:   9%|▊         | 742/8564 [00:08<01:41, 77.24 examples/s]Tokenizing train dataset:   8%|▊         | 665/8564 [00:07<02:03, 63.95 examples/s]Tokenizing train dataset:   9%|▉         | 766/8564 [00:08<01:14, 104.02 examples/s]Tokenizing train dataset:   9%|▉         | 756/8564 [00:09<01:48, 71.99 examples/s]Tokenizing train dataset:   8%|▊         | 672/8564 [00:07<02:07, 62.14 examples/s]Tokenizing train dataset:   9%|▉         | 780/8564 [00:08<01:21, 95.80 examples/s] Tokenizing train dataset:   9%|▉         | 766/8564 [00:09<01:54, 67.88 examples/s]Tokenizing train dataset:   8%|▊         | 682/8564 [00:08<02:03, 63.65 examples/s]Tokenizing train dataset:   8%|▊         | 692/8564 [00:08<02:00, 65.55 examples/s]Tokenizing train dataset:   9%|▉         | 774/8564 [00:09<02:14, 58.10 examples/s]Tokenizing train dataset:   9%|▉         | 793/8564 [00:09<01:44, 74.57 examples/s]Tokenizing train dataset:   8%|▊         | 702/8564 [00:08<01:50, 71.47 examples/s]Tokenizing train dataset:   9%|▉         | 784/8564 [00:09<02:01, 63.81 examples/s]Tokenizing train dataset:   8%|▊         | 716/8564 [00:08<01:31, 86.01 examples/s]Tokenizing train dataset:   9%|▉         | 803/8564 [00:09<01:52, 69.20 examples/s]Tokenizing train dataset:   9%|▉         | 792/8564 [00:09<02:02, 63.20 examples/s]Tokenizing train dataset:   9%|▊         | 735/8564 [00:08<01:11, 109.10 examples/s]Tokenizing train dataset:   9%|▉         | 812/8564 [00:09<01:50, 70.39 examples/s]Tokenizing train dataset:   9%|▉         | 800/8564 [00:09<02:06, 61.52 examples/s]Tokenizing train dataset:   9%|▉         | 752/8564 [00:08<01:11, 108.55 examples/s]Tokenizing train dataset:   9%|▉         | 807/8564 [00:10<02:08, 60.25 examples/s]Tokenizing train dataset:  10%|▉         | 820/8564 [00:09<02:04, 62.29 examples/s]Tokenizing train dataset:   9%|▉         | 766/8564 [00:08<01:09, 112.09 examples/s]Tokenizing train dataset:  10%|▉         | 814/8564 [00:10<02:06, 61.15 examples/s]Tokenizing train dataset:   9%|▉         | 778/8564 [00:08<01:10, 111.08 examples/s]Tokenizing train dataset:  10%|▉         | 828/8564 [00:09<02:20, 55.18 examples/s]Tokenizing train dataset:   9%|▉         | 790/8564 [00:09<01:11, 108.06 examples/s]Tokenizing train dataset:  10%|▉         | 839/8564 [00:10<01:59, 64.71 examples/s]Tokenizing train dataset:  10%|▉         | 824/8564 [00:10<02:23, 53.86 examples/s]Tokenizing train dataset:   9%|▉         | 805/8564 [00:09<01:05, 117.82 examples/s]Tokenizing train dataset:  10%|▉         | 847/8564 [00:10<01:56, 66.01 examples/s]Tokenizing train dataset:  10%|▉         | 831/8564 [00:10<02:37, 49.20 examples/s]Tokenizing train dataset:  10%|▉         | 819/8564 [00:09<01:19, 97.94 examples/s] Tokenizing train dataset:  10%|▉         | 846/8564 [00:10<01:53, 67.87 examples/s]Tokenizing train dataset:  10%|█         | 860/8564 [00:10<02:04, 61.78 examples/s]Tokenizing train dataset:  10%|█         | 857/8564 [00:10<01:40, 76.64 examples/s]Tokenizing train dataset:  10%|█         | 870/8564 [00:10<01:52, 68.33 examples/s]Tokenizing train dataset:  10%|█         | 867/8564 [00:10<01:34, 81.02 examples/s]Tokenizing train dataset:  10%|▉         | 832/8564 [00:09<01:42, 75.79 examples/s]Tokenizing train dataset:  10%|█         | 880/8564 [00:10<01:42, 74.70 examples/s]Tokenizing train dataset:  10%|█         | 876/8564 [00:10<01:33, 82.65 examples/s]Tokenizing train dataset:  10%|█         | 899/8564 [00:10<01:16, 100.55 examples/s]Tokenizing train dataset:  10%|▉         | 843/8564 [00:09<01:41, 76.19 examples/s]Tokenizing train dataset:  10%|█         | 889/8564 [00:11<01:22, 92.89 examples/s]Tokenizing train dataset:  11%|█         | 905/8564 [00:11<01:09, 110.02 examples/s]Tokenizing train dataset:  10%|▉         | 852/8564 [00:09<01:51, 68.95 examples/s]Tokenizing train dataset:  11%|█         | 911/8564 [00:10<01:40, 75.87 examples/s] Tokenizing train dataset:  10%|█         | 861/8564 [00:10<01:55, 66.41 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:11<01:33, 81.49 examples/s] Tokenizing train dataset:  10%|█         | 870/8564 [00:10<02:05, 61.20 examples/s]Tokenizing train dataset:  11%|█         | 925/8564 [00:11<01:56, 65.64 examples/s]Tokenizing train dataset:  11%|█         | 933/8564 [00:11<01:24, 90.76 examples/s]Tokenizing train dataset:  11%|█         | 937/8564 [00:11<01:47, 70.98 examples/s]Tokenizing train dataset:  11%|█         | 946/8564 [00:11<01:18, 96.56 examples/s]Tokenizing train dataset:  10%|█         | 880/8564 [00:10<02:04, 61.51 examples/s]Tokenizing train dataset:  11%|█         | 958/8564 [00:11<01:16, 99.52 examples/s]Tokenizing train dataset:  10%|█         | 899/8564 [00:10<01:30, 84.87 examples/s]Tokenizing train dataset:  11%|█         | 946/8564 [00:11<01:47, 70.85 examples/s]Tokenizing train dataset:  11%|█▏        | 970/8564 [00:11<01:14, 102.31 examples/s]Tokenizing train dataset:  11%|█         | 913/8564 [00:10<01:23, 91.53 examples/s]Tokenizing train dataset:  11%|█         | 957/8564 [00:11<01:53, 66.76 examples/s]Tokenizing train dataset:  11%|█         | 925/8564 [00:10<01:29, 85.19 examples/s]Tokenizing train dataset:  11%|█▏        | 965/8564 [00:11<01:51, 67.98 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:12<01:35, 79.49 examples/s] Tokenizing train dataset:  11%|█         | 935/8564 [00:11<01:29, 85.67 examples/s]Tokenizing train dataset:  11%|█▏        | 974/8564 [00:11<02:03, 61.49 examples/s]Tokenizing train dataset:  11%|█         | 946/8564 [00:11<01:24, 90.57 examples/s]Tokenizing train dataset:  12%|█▏        | 994/8564 [00:12<01:54, 66.39 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:12<02:24, 52.41 examples/s]Tokenizing train dataset:  11%|█         | 957/8564 [00:11<01:44, 73.09 examples/s]Tokenizing train dataset:  12%|█▏        | 1003/8564 [00:12<02:07, 59.34 examples/s]Tokenizing train dataset:  12%|█▏        | 991/8564 [00:12<02:19, 54.43 examples/s]Tokenizing train dataset:  12%|█▏        | 1010/8564 [00:12<02:10, 57.88 examples/s]Tokenizing train dataset:  11%|█▏        | 969/8564 [00:11<01:48, 69.81 examples/s]Tokenizing train dataset:  12%|█▏        | 997/8564 [00:12<02:19, 54.25 examples/s]Tokenizing train dataset:  12%|█▏        | 1018/8564 [00:12<02:14, 56.10 examples/s]Tokenizing train dataset:  12%|█▏        | 1010/8564 [00:12<01:48, 69.42 examples/s]Tokenizing train dataset:  11%|█▏        | 980/8564 [00:11<01:52, 67.71 examples/s]Tokenizing train dataset:  12%|█▏        | 1024/8564 [00:13<02:28, 50.90 examples/s]Tokenizing train dataset:  12%|█▏        | 1018/8564 [00:12<02:01, 62.24 examples/s]Tokenizing train dataset:  12%|█▏        | 990/8564 [00:11<01:58, 63.83 examples/s]Tokenizing train dataset:  12%|█▏        | 1030/8564 [00:13<02:31, 49.58 examples/s]Tokenizing train dataset:  12%|█▏        | 1025/8564 [00:12<02:05, 60.12 examples/s]Tokenizing train dataset:  12%|█▏        | 998/8564 [00:12<02:00, 62.72 examples/s]Tokenizing train dataset:  12%|█▏        | 1039/8564 [00:13<02:18, 54.50 examples/s]Tokenizing train dataset:  12%|█▏        | 1007/8564 [00:12<01:57, 64.20 examples/s]Tokenizing train dataset:  12%|█▏        | 1037/8564 [00:13<02:05, 59.86 examples/s]Tokenizing train dataset:  12%|█▏        | 1048/8564 [00:13<02:06, 59.52 examples/s]Tokenizing train dataset:  12%|█▏        | 1015/8564 [00:12<01:52, 66.83 examples/s]Tokenizing train dataset:  12%|█▏        | 1046/8564 [00:13<01:56, 64.77 examples/s]Tokenizing train dataset:  12%|█▏        | 1056/8564 [00:13<02:05, 59.90 examples/s]Tokenizing train dataset:  12%|█▏        | 1025/8564 [00:12<01:48, 69.40 examples/s]Tokenizing train dataset:  12%|█▏        | 1059/8564 [00:13<01:35, 78.38 examples/s]Tokenizing train dataset:  12%|█▏        | 1064/8564 [00:13<02:00, 62.19 examples/s]Tokenizing train dataset:  12%|█▏        | 1035/8564 [00:12<01:43, 72.95 examples/s]Tokenizing train dataset:  12%|█▏        | 1068/8564 [00:13<01:41, 73.89 examples/s]Tokenizing train dataset:  13%|█▎        | 1075/8564 [00:13<01:48, 69.04 examples/s]Tokenizing train dataset:  12%|█▏        | 1044/8564 [00:12<01:46, 70.84 examples/s]Tokenizing train dataset:  13%|█▎        | 1091/8564 [00:13<01:26, 86.41 examples/s]Tokenizing train dataset:  13%|█▎        | 1085/8564 [00:13<01:34, 79.36 examples/s]Tokenizing train dataset:  12%|█▏        | 1054/8564 [00:12<01:54, 65.61 examples/s]Tokenizing train dataset:  13%|█▎        | 1100/8564 [00:14<01:27, 85.29 examples/s]Tokenizing train dataset:  13%|█▎        | 1100/8564 [00:13<01:22, 90.54 examples/s]Tokenizing train dataset:  13%|█▎        | 1111/8564 [00:14<01:22, 90.57 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:13<01:24, 88.66 examples/s]Tokenizing train dataset:  12%|█▏        | 1063/8564 [00:12<02:02, 61.42 examples/s]Tokenizing train dataset:  13%|█▎        | 1121/8564 [00:14<01:23, 89.24 examples/s]Tokenizing train dataset:  12%|█▏        | 1070/8564 [00:13<02:00, 62.05 examples/s]Tokenizing train dataset:  13%|█▎        | 1083/8564 [00:13<01:38, 76.20 examples/s]Tokenizing train dataset:  13%|█▎        | 1122/8564 [00:14<01:49, 68.19 examples/s]Tokenizing train dataset:  13%|█▎        | 1135/8564 [00:14<01:31, 81.08 examples/s]Tokenizing train dataset:  13%|█▎        | 1097/8564 [00:13<01:21, 91.45 examples/s]Tokenizing train dataset:  13%|█▎        | 1132/8564 [00:14<01:56, 63.94 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:13<01:20, 92.61 examples/s]Tokenizing train dataset:  13%|█▎        | 1144/8564 [00:14<01:51, 66.83 examples/s]Tokenizing train dataset:  13%|█▎        | 1144/8564 [00:14<01:42, 72.06 examples/s]Tokenizing train dataset:  13%|█▎        | 1156/8564 [00:14<01:42, 72.51 examples/s]Tokenizing train dataset:  13%|█▎        | 1120/8564 [00:13<01:35, 77.83 examples/s]Tokenizing train dataset:  14%|█▎        | 1168/8564 [00:14<01:31, 80.52 examples/s]Tokenizing train dataset:  13%|█▎        | 1154/8564 [00:14<01:52, 66.05 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:15<01:28, 83.39 examples/s]Tokenizing train dataset:  14%|█▎        | 1165/8564 [00:14<01:43, 71.33 examples/s]Tokenizing train dataset:  13%|█▎        | 1133/8564 [00:13<01:55, 64.61 examples/s]Tokenizing train dataset:  14%|█▍        | 1190/8564 [00:15<01:28, 83.39 examples/s]Tokenizing train dataset:  13%|█▎        | 1144/8564 [00:14<01:43, 71.77 examples/s]Tokenizing train dataset:  14%|█▍        | 1206/8564 [00:15<01:12, 101.09 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:14<01:49, 67.36 examples/s]Tokenizing train dataset:  13%|█▎        | 1156/8564 [00:14<01:37, 75.64 examples/s]Tokenizing train dataset:  14%|█▍        | 1186/8564 [00:15<01:46, 69.45 examples/s]Tokenizing train dataset:  14%|█▍        | 1220/8564 [00:15<01:17, 95.13 examples/s] Tokenizing train dataset:  14%|█▎        | 1166/8564 [00:14<01:33, 79.25 examples/s]Tokenizing train dataset:  14%|█▍        | 1197/8564 [00:15<01:47, 68.61 examples/s]Tokenizing train dataset:  14%|█▍        | 1235/8564 [00:15<01:12, 100.43 examples/s]Tokenizing train dataset:  14%|█▍        | 1179/8564 [00:14<01:37, 75.67 examples/s]Tokenizing train dataset:  14%|█▍        | 1208/8564 [00:15<01:39, 74.23 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:15<01:11, 102.26 examples/s]Tokenizing train dataset:  14%|█▍        | 1190/8564 [00:14<01:30, 81.15 examples/s]Tokenizing train dataset:  14%|█▍        | 1216/8564 [00:15<01:43, 71.07 examples/s]Tokenizing train dataset:  15%|█▍        | 1262/8564 [00:15<01:12, 100.36 examples/s]Tokenizing train dataset:  14%|█▍        | 1230/8564 [00:15<01:26, 85.01 examples/s]Tokenizing train dataset:  14%|█▍        | 1202/8564 [00:14<01:30, 81.57 examples/s]Tokenizing train dataset:  15%|█▍        | 1278/8564 [00:16<01:20, 90.85 examples/s] Tokenizing train dataset:  15%|█▍        | 1249/8564 [00:15<01:19, 91.90 examples/s]Tokenizing train dataset:  14%|█▍        | 1214/8564 [00:14<01:40, 73.29 examples/s]Tokenizing train dataset:  15%|█▌        | 1291/8564 [00:16<01:23, 87.11 examples/s]Tokenizing train dataset:  15%|█▍        | 1262/8564 [00:15<01:22, 88.98 examples/s]Tokenizing train dataset:  14%|█▍        | 1225/8564 [00:15<01:39, 73.79 examples/s]Tokenizing train dataset:  15%|█▌        | 1304/8564 [00:16<01:15, 95.66 examples/s]Tokenizing train dataset:  14%|█▍        | 1236/8564 [00:15<01:36, 75.92 examples/s]Tokenizing train dataset:  15%|█▍        | 1277/8564 [00:16<01:21, 89.95 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:16<01:18, 92.09 examples/s]Tokenizing train dataset:  15%|█▍        | 1247/8564 [00:15<01:35, 76.34 examples/s]Tokenizing train dataset:  15%|█▌        | 1289/8564 [00:16<01:27, 83.60 examples/s]Tokenizing train dataset:  16%|█▌        | 1337/8564 [00:16<01:07, 106.64 examples/s]Tokenizing train dataset:  15%|█▍        | 1258/8564 [00:15<01:30, 81.11 examples/s]Tokenizing train dataset:  15%|█▌        | 1299/8564 [00:16<01:28, 82.40 examples/s]Tokenizing train dataset:  15%|█▍        | 1272/8564 [00:15<01:17, 94.18 examples/s]Tokenizing train dataset:  16%|█▌        | 1349/8564 [00:16<01:17, 93.03 examples/s] Tokenizing train dataset:  15%|█▌        | 1309/8564 [00:16<01:31, 79.31 examples/s]Tokenizing train dataset:  15%|█▌        | 1285/8564 [00:15<01:12, 100.62 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:16<01:28, 81.60 examples/s]Tokenizing train dataset:  16%|█▌        | 1361/8564 [00:17<01:33, 76.68 examples/s]Tokenizing train dataset:  16%|█▌        | 1331/8564 [00:16<01:26, 83.97 examples/s]Tokenizing train dataset:  15%|█▌        | 1302/8564 [00:15<01:25, 84.96 examples/s] Tokenizing train dataset:  16%|█▌        | 1371/8564 [00:17<01:45, 68.47 examples/s]Tokenizing train dataset:  16%|█▌        | 1340/8564 [00:16<01:29, 80.49 examples/s]Tokenizing train dataset:  15%|█▌        | 1312/8564 [00:16<01:23, 87.28 examples/s]Tokenizing train dataset:  16%|█▌        | 1349/8564 [00:17<01:29, 81.04 examples/s]Tokenizing train dataset:  15%|█▌        | 1323/8564 [00:16<01:23, 86.48 examples/s]Tokenizing train dataset:  16%|█▌        | 1385/8564 [00:17<01:41, 70.56 examples/s]Tokenizing train dataset:  16%|█▋        | 1394/8564 [00:17<01:39, 71.72 examples/s]Tokenizing train dataset:  16%|█▌        | 1339/8564 [00:16<01:22, 87.51 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:17<01:50, 64.91 examples/s]Tokenizing train dataset:  16%|█▋        | 1405/8564 [00:17<01:33, 76.19 examples/s]Tokenizing train dataset:  16%|█▌        | 1368/8564 [00:17<01:47, 66.80 examples/s]Tokenizing train dataset:  16%|█▌        | 1351/8564 [00:16<01:28, 81.81 examples/s]Tokenizing train dataset:  16%|█▌        | 1379/8564 [00:17<01:35, 75.19 examples/s]Tokenizing train dataset:  17%|█▋        | 1418/8564 [00:17<01:39, 72.11 examples/s]Tokenizing train dataset:  16%|█▌        | 1364/8564 [00:16<01:24, 85.02 examples/s]Tokenizing train dataset:  17%|█▋        | 1429/8564 [00:17<01:31, 78.03 examples/s]Tokenizing train dataset:  16%|█▌        | 1390/8564 [00:17<01:43, 69.35 examples/s]Tokenizing train dataset:  16%|█▋        | 1403/8564 [00:17<01:30, 78.81 examples/s]Tokenizing train dataset:  17%|█▋        | 1438/8564 [00:18<01:42, 69.42 examples/s]Tokenizing train dataset:  16%|█▌        | 1377/8564 [00:16<01:45, 68.07 examples/s]Tokenizing train dataset:  17%|█▋        | 1418/8564 [00:17<01:21, 88.09 examples/s]Tokenizing train dataset:  16%|█▌        | 1387/8564 [00:17<01:40, 71.48 examples/s]Tokenizing train dataset:  17%|█▋        | 1446/8564 [00:18<01:49, 64.87 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:18<01:53, 62.68 examples/s]Tokenizing train dataset:  16%|█▋        | 1397/8564 [00:17<01:44, 68.83 examples/s]Tokenizing train dataset:  17%|█▋        | 1429/8564 [00:18<01:32, 77.39 examples/s]Tokenizing train dataset:  17%|█▋        | 1461/8564 [00:18<01:54, 61.93 examples/s]Tokenizing train dataset:  16%|█▋        | 1405/8564 [00:17<01:46, 67.07 examples/s]Tokenizing train dataset:  17%|█▋        | 1440/8564 [00:18<01:42, 69.66 examples/s]Tokenizing train dataset:  17%|█▋        | 1470/8564 [00:18<01:47, 65.91 examples/s]Tokenizing train dataset:  17%|█▋        | 1414/8564 [00:17<01:43, 69.24 examples/s]Tokenizing train dataset:  17%|█▋        | 1451/8564 [00:18<01:32, 76.86 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:18<01:39, 70.91 examples/s]Tokenizing train dataset:  17%|█▋        | 1424/8564 [00:17<01:35, 74.56 examples/s]Tokenizing train dataset:  17%|█▋        | 1432/8564 [00:17<01:38, 72.42 examples/s]Tokenizing train dataset:  17%|█▋        | 1492/8564 [00:18<01:30, 78.37 examples/s]Tokenizing train dataset:  17%|█▋        | 1462/8564 [00:18<01:43, 68.74 examples/s]Tokenizing train dataset:  18%|█▊        | 1503/8564 [00:19<01:25, 82.80 examples/s]Tokenizing train dataset:  17%|█▋        | 1472/8564 [00:18<01:41, 70.19 examples/s]Tokenizing train dataset:  17%|█▋        | 1442/8564 [00:17<01:52, 63.22 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:18<01:38, 72.11 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:17<01:39, 71.37 examples/s]Tokenizing train dataset:  18%|█▊        | 1514/8564 [00:19<01:44, 67.64 examples/s]Tokenizing train dataset:  17%|█▋        | 1495/8564 [00:18<01:21, 86.63 examples/s]Tokenizing train dataset:  17%|█▋        | 1461/8564 [00:18<01:39, 71.71 examples/s]Tokenizing train dataset:  18%|█▊        | 1524/8564 [00:19<01:37, 71.86 examples/s]Tokenizing train dataset:  18%|█▊        | 1505/8564 [00:19<01:20, 88.02 examples/s]Tokenizing train dataset:  17%|█▋        | 1470/8564 [00:18<01:35, 74.35 examples/s]Tokenizing train dataset:  18%|█▊        | 1535/8564 [00:19<01:36, 73.14 examples/s]Tokenizing train dataset:  18%|█▊        | 1519/8564 [00:19<01:23, 84.41 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:18<01:45, 67.38 examples/s]Tokenizing train dataset:  18%|█▊        | 1533/8564 [00:19<01:14, 94.81 examples/s]Tokenizing train dataset:  18%|█▊        | 1546/8564 [00:19<01:45, 66.68 examples/s]Tokenizing train dataset:  17%|█▋        | 1492/8564 [00:18<01:46, 66.28 examples/s]Tokenizing train dataset:  18%|█▊        | 1555/8564 [00:19<01:53, 61.81 examples/s]Tokenizing train dataset:  18%|█▊        | 1502/8564 [00:18<01:36, 73.48 examples/s]Tokenizing train dataset:  18%|█▊        | 1548/8564 [00:19<01:23, 84.38 examples/s]Tokenizing train dataset:  18%|█▊        | 1565/8564 [00:19<01:44, 67.26 examples/s]Tokenizing train dataset:  18%|█▊        | 1511/8564 [00:18<01:35, 74.06 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:19<01:36, 72.77 examples/s]Tokenizing train dataset:  18%|█▊        | 1527/8564 [00:18<01:20, 87.66 examples/s]Tokenizing train dataset:  18%|█▊        | 1577/8564 [00:20<01:58, 59.02 examples/s]Tokenizing train dataset:  18%|█▊        | 1541/8564 [00:19<01:13, 95.14 examples/s]Tokenizing train dataset:  18%|█▊        | 1573/8564 [00:19<01:37, 71.43 examples/s]Tokenizing train dataset:  18%|█▊        | 1582/8564 [00:20<01:35, 73.25 examples/s]Tokenizing train dataset:  19%|█▊        | 1587/8564 [00:20<02:00, 58.12 examples/s]Tokenizing train dataset:  18%|█▊        | 1555/8564 [00:19<01:16, 91.34 examples/s]Tokenizing train dataset:  19%|█▊        | 1592/8564 [00:20<01:30, 77.13 examples/s]Tokenizing train dataset:  18%|█▊        | 1566/8564 [00:19<01:16, 91.69 examples/s]Tokenizing train dataset:  19%|█▊        | 1598/8564 [00:20<01:53, 61.43 examples/s]Tokenizing train dataset:  19%|█▊        | 1604/8564 [00:20<01:20, 86.53 examples/s]Tokenizing train dataset:  19%|█▊        | 1605/8564 [00:20<02:03, 56.46 examples/s]Tokenizing train dataset:  19%|█▉        | 1617/8564 [00:20<01:17, 89.94 examples/s]Tokenizing train dataset:  18%|█▊        | 1579/8564 [00:19<01:31, 76.69 examples/s]Tokenizing train dataset:  19%|█▉        | 1617/8564 [00:20<01:41, 68.63 examples/s]Tokenizing train dataset:  19%|█▉        | 1629/8564 [00:20<01:29, 77.13 examples/s]Tokenizing train dataset:  19%|█▉        | 1630/8564 [00:20<01:25, 80.82 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:19<01:38, 71.00 examples/s]Tokenizing train dataset:  19%|█▉        | 1643/8564 [00:21<01:19, 87.24 examples/s]Tokenizing train dataset:  19%|█▉        | 1641/8564 [00:20<01:29, 77.57 examples/s]Tokenizing train dataset:  19%|█▊        | 1600/8564 [00:19<01:47, 65.04 examples/s]Tokenizing train dataset:  19%|█▉        | 1654/8564 [00:21<01:15, 91.35 examples/s]Tokenizing train dataset:  19%|█▉        | 1652/8564 [00:20<01:25, 80.81 examples/s]Tokenizing train dataset:  19%|█▉        | 1611/8564 [00:20<01:42, 68.10 examples/s]Tokenizing train dataset:  19%|█▉        | 1667/8564 [00:21<01:15, 91.02 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:21<01:24, 82.03 examples/s]Tokenizing train dataset:  19%|█▉        | 1620/8564 [00:20<01:40, 69.23 examples/s]Tokenizing train dataset:  20%|█▉        | 1672/8564 [00:21<01:18, 88.20 examples/s]Tokenizing train dataset:  20%|█▉        | 1680/8564 [00:21<01:14, 92.16 examples/s]Tokenizing train dataset:  20%|█▉        | 1699/8564 [00:21<00:59, 115.19 examples/s]Tokenizing train dataset:  20%|█▉        | 1686/8564 [00:21<01:12, 94.47 examples/s]Tokenizing train dataset:  19%|█▉        | 1632/8564 [00:20<01:40, 69.24 examples/s]Tokenizing train dataset:  20%|█▉        | 1710/8564 [00:21<00:54, 126.47 examples/s]Tokenizing train dataset:  19%|█▉        | 1640/8564 [00:20<01:41, 68.15 examples/s]Tokenizing train dataset:  20%|██        | 1713/8564 [00:21<01:04, 105.80 examples/s]Tokenizing train dataset:  19%|█▉        | 1652/8564 [00:20<01:28, 77.95 examples/s]Tokenizing train dataset:  20%|██        | 1725/8564 [00:21<01:02, 109.54 examples/s]Tokenizing train dataset:  20%|██        | 1727/8564 [00:21<01:10, 96.95 examples/s] Tokenizing train dataset:  19%|█▉        | 1663/8564 [00:20<01:43, 66.64 examples/s]Tokenizing train dataset:  20%|██        | 1740/8564 [00:21<01:10, 97.30 examples/s] Tokenizing train dataset:  20%|██        | 1742/8564 [00:22<01:11, 94.79 examples/s]Tokenizing train dataset:  20%|██        | 1753/8564 [00:22<01:11, 95.39 examples/s]Tokenizing train dataset:  20%|█▉        | 1673/8564 [00:20<01:46, 64.84 examples/s]Tokenizing train dataset:  21%|██        | 1768/8564 [00:22<01:05, 103.76 examples/s]Tokenizing train dataset:  21%|██        | 1756/8564 [00:21<01:19, 85.13 examples/s]Tokenizing train dataset:  20%|█▉        | 1682/8564 [00:21<01:41, 67.74 examples/s]Tokenizing train dataset:  21%|██        | 1766/8564 [00:22<01:21, 83.92 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:21<01:19, 86.09 examples/s]Tokenizing train dataset:  21%|██        | 1783/8564 [00:22<01:17, 87.97 examples/s] Tokenizing train dataset:  20%|█▉        | 1710/8564 [00:21<01:18, 87.11 examples/s]Tokenizing train dataset:  21%|██        | 1796/8564 [00:22<01:11, 94.65 examples/s]Tokenizing train dataset:  21%|██        | 1775/8564 [00:22<01:38, 68.91 examples/s]Tokenizing train dataset:  20%|██        | 1720/8564 [00:21<01:18, 87.23 examples/s]Tokenizing train dataset:  21%|██        | 1784/8564 [00:22<01:34, 71.55 examples/s]Tokenizing train dataset:  20%|██        | 1729/8564 [00:21<01:23, 81.92 examples/s]Tokenizing train dataset:  21%|██        | 1809/8564 [00:22<01:24, 80.15 examples/s]Tokenizing train dataset:  21%|██        | 1796/8564 [00:22<01:27, 77.08 examples/s]Tokenizing train dataset:  20%|██        | 1742/8564 [00:21<01:15, 90.68 examples/s]Tokenizing train dataset:  21%|██▏       | 1822/8564 [00:23<01:21, 82.76 examples/s]Tokenizing train dataset:  21%|██        | 1758/8564 [00:21<01:07, 100.98 examples/s]Tokenizing train dataset:  21%|██        | 1806/8564 [00:22<01:38, 68.89 examples/s]Tokenizing train dataset:  21%|██        | 1770/8564 [00:21<01:05, 103.24 examples/s]Tokenizing train dataset:  21%|██▏       | 1835/8564 [00:23<01:25, 78.90 examples/s]Tokenizing train dataset:  21%|██        | 1815/8564 [00:22<01:46, 63.34 examples/s]Tokenizing train dataset:  21%|██▏       | 1827/8564 [00:23<01:33, 71.79 examples/s]Tokenizing train dataset:  22%|██▏       | 1846/8564 [00:23<01:32, 72.61 examples/s]Tokenizing train dataset:  21%|██        | 1785/8564 [00:22<01:16, 88.44 examples/s] Tokenizing train dataset:  21%|██▏       | 1841/8564 [00:23<01:18, 85.45 examples/s]Tokenizing train dataset:  22%|██▏       | 1854/8564 [00:23<01:52, 59.75 examples/s]Tokenizing train dataset:  22%|██▏       | 1852/8564 [00:23<01:17, 86.96 examples/s]Tokenizing train dataset:  21%|██        | 1799/8564 [00:22<01:28, 76.14 examples/s]Tokenizing train dataset:  22%|██▏       | 1861/8564 [00:23<01:51, 60.30 examples/s]Tokenizing train dataset:  22%|██▏       | 1863/8564 [00:23<01:18, 84.97 examples/s]Tokenizing train dataset:  21%|██        | 1810/8564 [00:22<01:34, 71.19 examples/s]Tokenizing train dataset:  22%|██▏       | 1870/8564 [00:23<01:46, 62.65 examples/s]Tokenizing train dataset:  22%|██▏       | 1873/8564 [00:23<01:15, 88.16 examples/s]Tokenizing train dataset:  22%|██▏       | 1885/8564 [00:23<01:09, 95.56 examples/s]Tokenizing train dataset:  22%|██▏       | 1877/8564 [00:23<01:52, 59.30 examples/s]Tokenizing train dataset:  21%|██▏       | 1822/8564 [00:22<01:37, 69.00 examples/s]Tokenizing train dataset:  22%|██▏       | 1897/8564 [00:23<01:09, 96.31 examples/s]Tokenizing train dataset:  21%|██▏       | 1830/8564 [00:22<01:39, 67.54 examples/s]Tokenizing train dataset:  22%|██▏       | 1890/8564 [00:24<01:47, 62.24 examples/s]Tokenizing train dataset:  22%|██▏       | 1915/8564 [00:23<00:58, 114.11 examples/s]Tokenizing train dataset:  21%|██▏       | 1838/8564 [00:23<01:42, 65.30 examples/s]Tokenizing train dataset:  22%|██▏       | 1909/8564 [00:24<01:15, 88.09 examples/s]Tokenizing train dataset:  23%|██▎       | 1931/8564 [00:23<00:52, 125.26 examples/s]Tokenizing train dataset:  22%|██▏       | 1922/8564 [00:24<01:10, 94.80 examples/s]Tokenizing train dataset:  23%|██▎       | 1944/8564 [00:24<00:53, 123.26 examples/s]Tokenizing train dataset:  22%|██▏       | 1845/8564 [00:23<01:50, 60.85 examples/s]Tokenizing train dataset:  23%|██▎       | 1961/8564 [00:24<00:51, 129.16 examples/s]Tokenizing train dataset:  22%|██▏       | 1853/8564 [00:23<01:58, 56.87 examples/s]Tokenizing train dataset:  23%|██▎       | 1937/8564 [00:24<01:20, 81.99 examples/s]Tokenizing train dataset:  23%|██▎       | 1980/8564 [00:24<00:47, 138.87 examples/s]Tokenizing train dataset:  23%|██▎       | 1999/8564 [00:24<00:43, 151.47 examples/s]Tokenizing train dataset:  23%|██▎       | 1949/8564 [00:24<01:19, 83.34 examples/s]Tokenizing train dataset:  22%|██▏       | 1861/8564 [00:23<02:11, 50.99 examples/s]Tokenizing train dataset:  24%|██▎       | 2020/8564 [00:24<00:48, 136.05 examples/s]Tokenizing train dataset:  23%|██▎       | 1965/8564 [00:24<01:15, 86.88 examples/s]Tokenizing train dataset:  22%|██▏       | 1868/8564 [00:23<02:15, 49.57 examples/s]Tokenizing train dataset:  22%|██▏       | 1879/8564 [00:23<01:47, 61.97 examples/s]Tokenizing train dataset:  24%|██▍       | 2039/8564 [00:24<00:52, 123.20 examples/s]Tokenizing train dataset:  22%|██▏       | 1888/8564 [00:23<01:46, 62.74 examples/s]Tokenizing train dataset:  23%|██▎       | 1980/8564 [00:25<01:26, 75.68 examples/s]Tokenizing train dataset:  24%|██▍       | 2058/8564 [00:24<00:53, 121.72 examples/s]Tokenizing train dataset:  22%|██▏       | 1896/8564 [00:24<01:45, 62.98 examples/s]Tokenizing train dataset:  23%|██▎       | 1989/8564 [00:25<01:27, 75.31 examples/s]Tokenizing train dataset:  22%|██▏       | 1905/8564 [00:24<01:36, 68.94 examples/s]Tokenizing train dataset:  24%|██▍       | 2079/8564 [00:25<00:51, 124.80 examples/s]Tokenizing train dataset:  23%|██▎       | 1998/8564 [00:25<01:31, 72.04 examples/s]Tokenizing train dataset:  22%|██▏       | 1920/8564 [00:24<01:19, 84.06 examples/s]Tokenizing train dataset:  24%|██▍       | 2092/8564 [00:25<00:55, 116.77 examples/s]Tokenizing train dataset:  23%|██▎       | 2008/8564 [00:25<01:27, 74.78 examples/s]Tokenizing train dataset:  23%|██▎       | 1934/8564 [00:24<01:09, 96.00 examples/s]Tokenizing train dataset:  25%|██▍       | 2105/8564 [00:25<00:54, 117.58 examples/s]Tokenizing train dataset:  24%|██▎       | 2020/8564 [00:25<01:27, 74.71 examples/s]Tokenizing train dataset:  23%|██▎       | 1950/8564 [00:24<00:59, 111.95 examples/s]Tokenizing train dataset:  25%|██▍       | 2117/8564 [00:25<00:59, 108.73 examples/s]Tokenizing train dataset:  24%|██▍       | 2035/8564 [00:25<01:14, 87.55 examples/s]Tokenizing train dataset:  23%|██▎       | 1964/8564 [00:24<00:58, 112.81 examples/s]Tokenizing train dataset:  24%|██▍       | 2048/8564 [00:25<01:07, 96.87 examples/s]Tokenizing train dataset:  25%|██▍       | 2129/8564 [00:25<01:06, 96.82 examples/s] Tokenizing train dataset:  23%|██▎       | 1977/8564 [00:24<01:09, 94.49 examples/s] Tokenizing train dataset:  24%|██▍       | 2063/8564 [00:26<01:02, 103.88 examples/s]Tokenizing train dataset:  25%|██▍       | 2140/8564 [00:25<01:06, 97.31 examples/s]Tokenizing train dataset:  23%|██▎       | 1990/8564 [00:24<01:09, 93.92 examples/s]Tokenizing train dataset:  25%|██▌       | 2152/8564 [00:25<01:03, 101.08 examples/s]Tokenizing train dataset:  24%|██▍       | 2080/8564 [00:26<01:06, 97.46 examples/s] Tokenizing train dataset:  23%|██▎       | 2002/8564 [00:25<01:08, 95.93 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:26<01:10, 90.38 examples/s] Tokenizing train dataset:  24%|██▎       | 2015/8564 [00:25<01:05, 100.20 examples/s]Tokenizing train dataset:  24%|██▍       | 2094/8564 [00:26<01:13, 88.09 examples/s]Tokenizing train dataset:  25%|██▌       | 2178/8564 [00:26<01:12, 88.54 examples/s]Tokenizing train dataset:  24%|██▎       | 2029/8564 [00:25<01:05, 99.94 examples/s] Tokenizing train dataset:  25%|██▍       | 2106/8564 [00:26<01:10, 91.39 examples/s]Tokenizing train dataset:  26%|██▌       | 2190/8564 [00:26<01:10, 89.92 examples/s]Tokenizing train dataset:  25%|██▍       | 2119/8564 [00:26<01:09, 93.29 examples/s]Tokenizing train dataset:  24%|██▍       | 2042/8564 [00:25<01:10, 91.92 examples/s]Tokenizing train dataset:  26%|██▌       | 2202/8564 [00:26<01:05, 96.60 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:26<01:06, 96.48 examples/s]Tokenizing train dataset:  24%|██▍       | 2052/8564 [00:25<01:15, 86.69 examples/s]Tokenizing train dataset:  26%|██▌       | 2216/8564 [00:26<01:01, 102.51 examples/s]Tokenizing train dataset:  25%|██▌       | 2141/8564 [00:26<01:07, 95.59 examples/s]Tokenizing train dataset:  24%|██▍       | 2064/8564 [00:25<01:10, 92.04 examples/s]Tokenizing train dataset:  26%|██▌       | 2230/8564 [00:26<00:58, 107.84 examples/s]Tokenizing train dataset:  25%|██▌       | 2153/8564 [00:27<01:06, 96.43 examples/s]Tokenizing train dataset:  26%|██▌       | 2242/8564 [00:26<01:01, 103.61 examples/s]Tokenizing train dataset:  24%|██▍       | 2081/8564 [00:25<01:09, 93.47 examples/s]Tokenizing train dataset:  26%|██▋       | 2257/8564 [00:26<00:59, 106.83 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:27<01:14, 85.60 examples/s]Tokenizing train dataset:  24%|██▍       | 2093/8564 [00:26<01:10, 92.17 examples/s]Tokenizing train dataset:  25%|██▌       | 2180/8564 [00:27<01:07, 95.07 examples/s]Tokenizing train dataset:  27%|██▋       | 2276/8564 [00:27<00:51, 121.93 examples/s]Tokenizing train dataset:  25%|██▍       | 2106/8564 [00:26<01:12, 88.81 examples/s]Tokenizing train dataset:  26%|██▌       | 2194/8564 [00:27<01:03, 100.31 examples/s]Tokenizing train dataset:  27%|██▋       | 2289/8564 [00:27<00:59, 104.89 examples/s]Tokenizing train dataset:  25%|██▍       | 2115/8564 [00:26<01:17, 83.10 examples/s]Tokenizing train dataset:  27%|██▋       | 2301/8564 [00:27<01:00, 102.91 examples/s]Tokenizing train dataset:  25%|██▍       | 2127/8564 [00:26<01:11, 89.78 examples/s]Tokenizing train dataset:  26%|██▌       | 2210/8564 [00:27<01:08, 92.99 examples/s] Tokenizing train dataset:  27%|██▋       | 2319/8564 [00:27<01:00, 103.26 examples/s]Tokenizing train dataset:  25%|██▍       | 2137/8564 [00:26<01:18, 82.02 examples/s]Tokenizing train dataset:  26%|██▌       | 2223/8564 [00:27<01:12, 87.07 examples/s]Tokenizing train dataset:  27%|██▋       | 2331/8564 [00:27<00:58, 106.23 examples/s]Tokenizing train dataset:  25%|██▌       | 2150/8564 [00:26<01:12, 88.32 examples/s]Tokenizing train dataset:  26%|██▌       | 2233/8564 [00:27<01:16, 82.41 examples/s]Tokenizing train dataset:  25%|██▌       | 2160/8564 [00:26<01:11, 89.63 examples/s]Tokenizing train dataset:  26%|██▌       | 2244/8564 [00:28<01:12, 87.01 examples/s]Tokenizing train dataset:  25%|██▌       | 2172/8564 [00:26<01:07, 95.34 examples/s]Tokenizing train dataset:  27%|██▋       | 2346/8564 [00:27<01:16, 81.46 examples/s] Tokenizing train dataset:  26%|██▋       | 2254/8564 [00:28<01:14, 84.47 examples/s]Tokenizing train dataset:  26%|██▌       | 2184/8564 [00:27<01:02, 101.34 examples/s]Tokenizing train dataset:  28%|██▊       | 2356/8564 [00:27<01:13, 83.91 examples/s]Tokenizing train dataset:  26%|██▋       | 2269/8564 [00:28<01:16, 82.28 examples/s]Tokenizing train dataset:  28%|██▊       | 2370/8564 [00:28<01:08, 89.90 examples/s]Tokenizing train dataset:  26%|██▌       | 2195/8564 [00:27<01:14, 85.15 examples/s] Tokenizing train dataset:  27%|██▋       | 2287/8564 [00:28<01:02, 101.15 examples/s]Tokenizing train dataset:  28%|██▊       | 2388/8564 [00:28<01:05, 94.77 examples/s]Tokenizing train dataset:  27%|██▋       | 2302/8564 [00:28<00:56, 110.00 examples/s]Tokenizing train dataset:  26%|██▌       | 2210/8564 [00:27<01:25, 74.41 examples/s]Tokenizing train dataset:  28%|██▊       | 2405/8564 [00:28<00:56, 108.22 examples/s]Tokenizing train dataset:  26%|██▌       | 2222/8564 [00:27<01:16, 82.77 examples/s]Tokenizing train dataset:  28%|██▊       | 2420/8564 [00:28<00:55, 111.26 examples/s]Tokenizing train dataset:  27%|██▋       | 2315/8564 [00:28<01:11, 87.25 examples/s] Tokenizing train dataset:  27%|██▋       | 2329/8564 [00:28<01:04, 96.42 examples/s]Tokenizing train dataset:  26%|██▌       | 2235/8564 [00:27<01:20, 78.44 examples/s]Tokenizing train dataset:  28%|██▊       | 2434/8564 [00:28<01:03, 95.90 examples/s] Tokenizing train dataset:  27%|██▋       | 2341/8564 [00:29<01:02, 99.84 examples/s]Tokenizing train dataset:  29%|██▊       | 2446/8564 [00:28<01:02, 97.85 examples/s]Tokenizing train dataset:  26%|██▋       | 2250/8564 [00:27<01:19, 79.62 examples/s]Tokenizing train dataset:  27%|██▋       | 2353/8564 [00:29<01:08, 90.03 examples/s]Tokenizing train dataset:  26%|██▋       | 2262/8564 [00:28<01:17, 81.48 examples/s]Tokenizing train dataset:  28%|██▊       | 2365/8564 [00:29<01:04, 96.81 examples/s]Tokenizing train dataset:  29%|██▊       | 2459/8564 [00:29<01:11, 85.15 examples/s]Tokenizing train dataset:  27%|██▋       | 2277/8564 [00:28<01:10, 89.57 examples/s]Tokenizing train dataset:  28%|██▊       | 2378/8564 [00:29<01:02, 99.62 examples/s]Tokenizing train dataset:  29%|██▉       | 2470/8564 [00:29<01:12, 83.86 examples/s]Tokenizing train dataset:  27%|██▋       | 2290/8564 [00:28<01:08, 91.98 examples/s]Tokenizing train dataset:  29%|██▉       | 2481/8564 [00:29<01:10, 86.47 examples/s]Tokenizing train dataset:  28%|██▊       | 2393/8564 [00:29<01:04, 96.28 examples/s]Tokenizing train dataset:  27%|██▋       | 2304/8564 [00:28<01:02, 99.59 examples/s]Tokenizing train dataset:  29%|██▉       | 2493/8564 [00:29<01:06, 91.32 examples/s]Tokenizing train dataset:  28%|██▊       | 2404/8564 [00:29<01:04, 95.00 examples/s]Tokenizing train dataset:  27%|██▋       | 2315/8564 [00:28<01:02, 100.65 examples/s]Tokenizing train dataset:  29%|██▉       | 2505/8564 [00:29<01:02, 96.64 examples/s]Tokenizing train dataset:  28%|██▊       | 2415/8564 [00:29<01:08, 89.20 examples/s]Tokenizing train dataset:  27%|██▋       | 2329/8564 [00:28<00:58, 107.36 examples/s]Tokenizing train dataset:  29%|██▉       | 2515/8564 [00:29<01:06, 91.60 examples/s]Tokenizing train dataset:  28%|██▊       | 2426/8564 [00:30<01:09, 88.95 examples/s]Tokenizing train dataset:  27%|██▋       | 2340/8564 [00:28<01:04, 96.59 examples/s] Tokenizing train dataset:  30%|██▉       | 2529/8564 [00:29<01:03, 94.98 examples/s]Tokenizing train dataset:  28%|██▊       | 2439/8564 [00:30<01:02, 98.18 examples/s]Tokenizing train dataset:  27%|██▋       | 2350/8564 [00:28<01:04, 96.75 examples/s]Tokenizing train dataset:  30%|██▉       | 2539/8564 [00:29<01:03, 94.68 examples/s]Tokenizing train dataset:  28%|██▊       | 2363/8564 [00:29<01:04, 96.26 examples/s]Tokenizing train dataset:  29%|██▊       | 2453/8564 [00:30<01:09, 88.48 examples/s]Tokenizing train dataset:  30%|██▉       | 2552/8564 [00:30<01:06, 90.11 examples/s]Tokenizing train dataset:  29%|██▉       | 2467/8564 [00:30<01:04, 94.44 examples/s]Tokenizing train dataset:  28%|██▊       | 2377/8564 [00:29<01:04, 95.93 examples/s]Tokenizing train dataset:  30%|██▉       | 2566/8564 [00:30<01:09, 86.60 examples/s]Tokenizing train dataset:  29%|██▉       | 2477/8564 [00:30<01:04, 94.46 examples/s]Tokenizing train dataset:  28%|██▊       | 2389/8564 [00:29<01:11, 85.85 examples/s]Tokenizing train dataset:  29%|██▉       | 2490/8564 [00:30<01:00, 100.90 examples/s]Tokenizing train dataset:  30%|███       | 2578/8564 [00:30<01:08, 87.54 examples/s]Tokenizing train dataset:  28%|██▊       | 2402/8564 [00:29<01:06, 92.65 examples/s]Tokenizing train dataset:  30%|███       | 2591/8564 [00:30<01:04, 92.21 examples/s]Tokenizing train dataset:  28%|██▊       | 2413/8564 [00:29<01:03, 96.77 examples/s]Tokenizing train dataset:  29%|██▉       | 2501/8564 [00:30<01:18, 76.98 examples/s] Tokenizing train dataset:  30%|███       | 2603/8564 [00:30<01:00, 98.31 examples/s]Tokenizing train dataset:  28%|██▊       | 2427/8564 [00:29<00:57, 107.19 examples/s]Tokenizing train dataset:  29%|██▉       | 2510/8564 [00:31<01:19, 75.81 examples/s]Tokenizing train dataset:  31%|███       | 2614/8564 [00:30<01:01, 97.00 examples/s]Tokenizing train dataset:  29%|██▊       | 2441/8564 [00:29<01:03, 97.09 examples/s] Tokenizing train dataset:  29%|██▉       | 2521/8564 [00:31<01:13, 82.09 examples/s]Tokenizing train dataset:  31%|███       | 2624/8564 [00:30<01:17, 76.50 examples/s]Tokenizing train dataset:  30%|██▉       | 2532/8564 [00:31<01:12, 83.23 examples/s]Tokenizing train dataset:  29%|██▊       | 2457/8564 [00:30<01:06, 91.29 examples/s]Tokenizing train dataset:  31%|███       | 2633/8564 [00:31<01:19, 74.51 examples/s]Tokenizing train dataset:  30%|██▉       | 2544/8564 [00:31<01:10, 85.21 examples/s]Tokenizing train dataset:  29%|██▉       | 2469/8564 [00:30<01:06, 91.47 examples/s]Tokenizing train dataset:  31%|███       | 2644/8564 [00:31<01:16, 77.40 examples/s]Tokenizing train dataset:  30%|██▉       | 2555/8564 [00:31<01:10, 84.98 examples/s]Tokenizing train dataset:  29%|██▉       | 2482/8564 [00:30<01:14, 81.85 examples/s]Tokenizing train dataset:  30%|██▉       | 2567/8564 [00:31<01:09, 86.76 examples/s]Tokenizing train dataset:  31%|███       | 2659/8564 [00:31<01:17, 76.54 examples/s]Tokenizing train dataset:  29%|██▉       | 2494/8564 [00:30<01:10, 86.13 examples/s]Tokenizing train dataset:  30%|███       | 2578/8564 [00:31<01:06, 89.83 examples/s]Tokenizing train dataset:  31%|███       | 2667/8564 [00:31<01:18, 75.27 examples/s]Tokenizing train dataset:  30%|███       | 2590/8564 [00:31<01:04, 92.94 examples/s]Tokenizing train dataset:  29%|██▉       | 2506/8564 [00:30<01:12, 83.94 examples/s]Tokenizing train dataset:  31%|███       | 2675/8564 [00:31<01:19, 74.39 examples/s]Tokenizing train dataset:  29%|██▉       | 2520/8564 [00:30<01:04, 94.09 examples/s]Tokenizing train dataset:  31%|███▏      | 2686/8564 [00:31<01:22, 71.67 examples/s]Tokenizing train dataset:  30%|███       | 2602/8564 [00:32<01:16, 77.73 examples/s]Tokenizing train dataset:  30%|██▉       | 2537/8564 [00:30<00:55, 108.09 examples/s]Tokenizing train dataset:  31%|███▏      | 2696/8564 [00:31<01:20, 72.79 examples/s]Tokenizing train dataset:  30%|███       | 2612/8564 [00:32<01:16, 78.24 examples/s]Tokenizing train dataset:  30%|██▉       | 2556/8564 [00:31<00:55, 108.20 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:32<01:20, 72.68 examples/s]Tokenizing train dataset:  30%|███       | 2570/8564 [00:31<00:52, 113.67 examples/s]Tokenizing train dataset:  31%|███       | 2624/8564 [00:32<01:28, 66.98 examples/s]Tokenizing train dataset:  32%|███▏      | 2717/8564 [00:32<01:15, 77.34 examples/s]Tokenizing train dataset:  30%|███       | 2582/8564 [00:31<00:56, 106.78 examples/s]Tokenizing train dataset:  31%|███       | 2632/8564 [00:32<01:28, 67.15 examples/s]Tokenizing train dataset:  32%|███▏      | 2727/8564 [00:32<01:16, 76.35 examples/s]Tokenizing train dataset:  31%|███       | 2642/8564 [00:32<01:22, 71.54 examples/s]Tokenizing train dataset:  30%|███       | 2597/8564 [00:31<00:57, 102.99 examples/s]Tokenizing train dataset:  32%|███▏      | 2737/8564 [00:32<01:15, 77.32 examples/s]Tokenizing train dataset:  31%|███       | 2655/8564 [00:32<01:13, 80.23 examples/s]Tokenizing train dataset:  32%|███▏      | 2747/8564 [00:32<01:12, 80.25 examples/s]Tokenizing train dataset:  30%|███       | 2611/8564 [00:31<01:07, 88.67 examples/s] Tokenizing train dataset:  31%|███       | 2665/8564 [00:32<01:15, 78.37 examples/s]Tokenizing train dataset:  32%|███▏      | 2759/8564 [00:32<01:09, 84.09 examples/s]Tokenizing train dataset:  31%|███       | 2624/8564 [00:31<01:09, 85.74 examples/s]Tokenizing train dataset:  32%|███▏      | 2772/8564 [00:32<01:03, 91.66 examples/s]Tokenizing train dataset:  31%|███       | 2674/8564 [00:33<01:20, 72.78 examples/s]Tokenizing train dataset:  31%|███       | 2637/8564 [00:31<01:02, 94.74 examples/s]Tokenizing train dataset:  33%|███▎      | 2789/8564 [00:32<00:52, 110.00 examples/s]Tokenizing train dataset:  31%|███▏      | 2686/8564 [00:33<01:25, 68.48 examples/s]Tokenizing train dataset:  31%|███       | 2648/8564 [00:32<01:04, 91.61 examples/s]Tokenizing train dataset:  33%|███▎      | 2807/8564 [00:33<00:51, 111.15 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:32<01:00, 96.84 examples/s]Tokenizing train dataset:  32%|███▏      | 2700/8564 [00:33<01:18, 74.30 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:33<00:51, 111.29 examples/s]Tokenizing train dataset:  31%|███       | 2671/8564 [00:32<01:02, 94.91 examples/s]Tokenizing train dataset:  32%|███▏      | 2713/8564 [00:33<01:12, 80.30 examples/s]Tokenizing train dataset:  31%|███▏      | 2681/8564 [00:32<01:02, 93.41 examples/s]Tokenizing train dataset:  33%|███▎      | 2834/8564 [00:33<01:00, 94.19 examples/s] Tokenizing train dataset:  32%|███▏      | 2722/8564 [00:33<01:14, 78.22 examples/s]Tokenizing train dataset:  33%|███▎      | 2847/8564 [00:33<00:58, 97.67 examples/s]Tokenizing train dataset:  32%|███▏      | 2732/8564 [00:33<01:11, 81.06 examples/s]Tokenizing train dataset:  31%|███▏      | 2694/8564 [00:32<01:10, 83.35 examples/s]Tokenizing train dataset:  33%|███▎      | 2858/8564 [00:33<00:57, 99.27 examples/s]Tokenizing train dataset:  32%|███▏      | 2703/8564 [00:32<01:14, 79.06 examples/s]Tokenizing train dataset:  32%|███▏      | 2745/8564 [00:34<01:14, 77.99 examples/s]Tokenizing train dataset:  34%|███▎      | 2870/8564 [00:33<01:06, 86.17 examples/s]Tokenizing train dataset:  32%|███▏      | 2715/8564 [00:32<01:09, 84.32 examples/s]Tokenizing train dataset:  32%|███▏      | 2757/8564 [00:34<01:07, 86.48 examples/s]Tokenizing train dataset:  32%|███▏      | 2724/8564 [00:32<01:09, 84.55 examples/s]Tokenizing train dataset:  32%|███▏      | 2770/8564 [00:34<01:00, 95.74 examples/s]Tokenizing train dataset:  34%|███▎      | 2883/8564 [00:33<01:12, 78.82 examples/s]Tokenizing train dataset:  32%|███▏      | 2733/8564 [00:33<01:12, 80.98 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:34<00:55, 104.41 examples/s]Tokenizing train dataset:  33%|███▎      | 2798/8564 [00:34<00:53, 108.62 examples/s]Tokenizing train dataset:  32%|███▏      | 2742/8564 [00:33<01:13, 79.49 examples/s]Tokenizing train dataset:  34%|███▍      | 2898/8564 [00:34<01:14, 76.31 examples/s]Tokenizing train dataset:  32%|███▏      | 2752/8564 [00:33<01:15, 76.76 examples/s]Tokenizing train dataset:  34%|███▍      | 2909/8564 [00:34<01:10, 80.50 examples/s]Tokenizing train dataset:  33%|███▎      | 2815/8564 [00:34<00:57, 100.24 examples/s]Tokenizing train dataset:  32%|███▏      | 2762/8564 [00:33<01:13, 78.96 examples/s]Tokenizing train dataset:  34%|███▍      | 2924/8564 [00:34<01:01, 92.34 examples/s]Tokenizing train dataset:  33%|███▎      | 2829/8564 [00:34<00:54, 105.70 examples/s]Tokenizing train dataset:  32%|███▏      | 2776/8564 [00:33<01:01, 93.55 examples/s]Tokenizing train dataset:  33%|███▎      | 2843/8564 [00:34<00:54, 105.23 examples/s]Tokenizing train dataset:  33%|███▎      | 2791/8564 [00:33<00:55, 104.79 examples/s]Tokenizing train dataset:  34%|███▍      | 2939/8564 [00:34<01:10, 79.39 examples/s]Tokenizing train dataset:  33%|███▎      | 2856/8564 [00:34<00:52, 109.07 examples/s]Tokenizing train dataset:  35%|███▍      | 2958/8564 [00:34<00:56, 98.64 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:35<00:58, 96.88 examples/s] Tokenizing train dataset:  33%|███▎      | 2809/8564 [00:33<01:07, 85.52 examples/s] Tokenizing train dataset:  35%|███▍      | 2973/8564 [00:34<00:53, 104.12 examples/s]Tokenizing train dataset:  33%|███▎      | 2821/8564 [00:34<01:04, 89.31 examples/s]Tokenizing train dataset:  35%|███▍      | 2989/8564 [00:35<00:50, 110.34 examples/s]Tokenizing train dataset:  34%|███▎      | 2885/8564 [00:35<01:11, 79.41 examples/s]Tokenizing train dataset:  33%|███▎      | 2835/8564 [00:34<01:09, 82.60 examples/s]Tokenizing train dataset:  35%|███▌      | 3003/8564 [00:35<00:57, 96.74 examples/s] Tokenizing train dataset:  34%|███▍      | 2899/8564 [00:35<01:06, 84.68 examples/s]Tokenizing train dataset:  33%|███▎      | 2844/8564 [00:34<01:13, 78.05 examples/s]Tokenizing train dataset:  34%|███▍      | 2911/8564 [00:35<01:04, 88.33 examples/s]Tokenizing train dataset:  35%|███▌      | 3017/8564 [00:35<01:00, 91.00 examples/s]Tokenizing train dataset:  33%|███▎      | 2856/8564 [00:34<01:07, 84.80 examples/s]Tokenizing train dataset:  34%|███▍      | 2924/8564 [00:35<00:58, 97.10 examples/s]Tokenizing train dataset:  35%|███▌      | 3028/8564 [00:35<01:01, 90.52 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:34<01:04, 88.99 examples/s]Tokenizing train dataset:  34%|███▍      | 2939/8564 [00:35<00:53, 104.69 examples/s]Tokenizing train dataset:  34%|███▎      | 2878/8564 [00:34<01:02, 91.32 examples/s]Tokenizing train dataset:  35%|███▌      | 3039/8564 [00:35<01:09, 79.37 examples/s]Tokenizing train dataset:  35%|███▍      | 2955/8564 [00:36<00:48, 115.18 examples/s]Tokenizing train dataset:  34%|███▍      | 2896/8564 [00:34<00:51, 110.62 examples/s]Tokenizing train dataset:  36%|███▌      | 3048/8564 [00:35<01:09, 79.14 examples/s]Tokenizing train dataset:  34%|███▍      | 2910/8564 [00:34<00:48, 116.81 examples/s]Tokenizing train dataset:  36%|███▌      | 3058/8564 [00:35<01:07, 81.15 examples/s]Tokenizing train dataset:  35%|███▍      | 2969/8564 [00:36<00:59, 93.93 examples/s] Tokenizing train dataset:  36%|███▌      | 3070/8564 [00:36<01:04, 84.91 examples/s]Tokenizing train dataset:  35%|███▍      | 2984/8564 [00:36<00:56, 99.07 examples/s]Tokenizing train dataset:  34%|███▍      | 2926/8564 [00:35<00:55, 101.71 examples/s]Tokenizing train dataset:  36%|███▌      | 3083/8564 [00:36<00:59, 91.56 examples/s]Tokenizing train dataset:  35%|███▍      | 2996/8564 [00:36<00:56, 97.77 examples/s]Tokenizing train dataset:  34%|███▍      | 2937/8564 [00:35<00:59, 95.06 examples/s] Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:36<00:55, 97.77 examples/s]Tokenizing train dataset:  34%|███▍      | 2949/8564 [00:35<00:58, 95.34 examples/s]Tokenizing train dataset:  35%|███▌      | 3007/8564 [00:36<01:03, 87.37 examples/s]Tokenizing train dataset:  36%|███▋      | 3109/8564 [00:36<00:58, 93.44 examples/s]Tokenizing train dataset:  35%|███▍      | 2961/8564 [00:35<00:55, 100.90 examples/s]Tokenizing train dataset:  35%|███▌      | 3019/8564 [00:36<01:02, 88.81 examples/s]Tokenizing train dataset:  35%|███▍      | 2980/8564 [00:35<00:45, 121.62 examples/s]Tokenizing train dataset:  35%|███▌      | 3031/8564 [00:36<01:06, 82.98 examples/s]Tokenizing train dataset:  36%|███▋      | 3122/8564 [00:36<01:09, 77.99 examples/s]Tokenizing train dataset:  35%|███▍      | 2996/8564 [00:35<00:44, 124.06 examples/s]Tokenizing train dataset:  35%|███▌      | 3014/8564 [00:35<00:42, 130.58 examples/s]Tokenizing train dataset:  37%|███▋      | 3131/8564 [00:36<01:13, 73.43 examples/s]Tokenizing train dataset:  36%|███▌      | 3042/8564 [00:37<01:13, 74.99 examples/s]Tokenizing train dataset:  37%|███▋      | 3144/8564 [00:36<01:05, 82.47 examples/s]Tokenizing train dataset:  36%|███▌      | 3051/8564 [00:37<01:13, 75.52 examples/s]Tokenizing train dataset:  35%|███▌      | 3031/8564 [00:36<00:45, 120.50 examples/s]Tokenizing train dataset:  37%|███▋      | 3157/8564 [00:37<00:59, 90.97 examples/s]Tokenizing train dataset:  36%|███▌      | 3050/8564 [00:36<00:43, 126.71 examples/s]Tokenizing train dataset:  36%|███▌      | 3062/8564 [00:37<01:22, 66.67 examples/s]Tokenizing train dataset:  37%|███▋      | 3167/8564 [00:37<01:01, 88.15 examples/s]Tokenizing train dataset:  36%|███▌      | 3063/8564 [00:36<00:45, 120.17 examples/s]Tokenizing train dataset:  36%|███▌      | 3074/8564 [00:37<01:11, 76.43 examples/s]Tokenizing train dataset:  36%|███▌      | 3077/8564 [00:36<00:45, 120.97 examples/s]Tokenizing train dataset:  36%|███▌      | 3088/8564 [00:37<01:01, 89.44 examples/s]Tokenizing train dataset:  37%|███▋      | 3180/8564 [00:37<01:09, 76.94 examples/s]Tokenizing train dataset:  36%|███▌      | 3093/8564 [00:36<00:42, 129.89 examples/s]Tokenizing train dataset:  37%|███▋      | 3194/8564 [00:37<01:00, 89.13 examples/s]Tokenizing train dataset:  36%|███▌      | 3099/8564 [00:37<01:04, 84.78 examples/s]Tokenizing train dataset:  37%|███▋      | 3206/8564 [00:37<00:57, 92.74 examples/s]Tokenizing train dataset:  36%|███▋      | 3113/8564 [00:36<00:43, 126.03 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:37<01:04, 84.44 examples/s]Tokenizing train dataset:  38%|███▊      | 3220/8564 [00:37<00:55, 97.02 examples/s]Tokenizing train dataset:  36%|███▋      | 3121/8564 [00:38<01:03, 86.38 examples/s]Tokenizing train dataset:  37%|███▋      | 3132/8564 [00:36<00:50, 108.51 examples/s]Tokenizing train dataset:  38%|███▊      | 3232/8564 [00:37<00:54, 97.46 examples/s]Tokenizing train dataset:  37%|███▋      | 3131/8564 [00:38<01:08, 79.22 examples/s]Tokenizing train dataset:  38%|███▊      | 3246/8564 [00:37<00:51, 103.95 examples/s]Tokenizing train dataset:  37%|███▋      | 3147/8564 [00:37<00:53, 100.51 examples/s]Tokenizing train dataset:  38%|███▊      | 3260/8564 [00:38<00:47, 112.29 examples/s]Tokenizing train dataset:  37%|███▋      | 3142/8564 [00:38<01:10, 76.59 examples/s]Tokenizing train dataset:  37%|███▋      | 3152/8564 [00:38<01:08, 79.44 examples/s]Tokenizing train dataset:  37%|███▋      | 3163/8564 [00:37<00:57, 93.23 examples/s] Tokenizing train dataset:  38%|███▊      | 3274/8564 [00:38<00:52, 100.21 examples/s]Tokenizing train dataset:  37%|███▋      | 3162/8564 [00:38<01:16, 71.03 examples/s]Tokenizing train dataset:  38%|███▊      | 3288/8564 [00:38<00:59, 88.51 examples/s] Tokenizing train dataset:  37%|███▋      | 3176/8564 [00:37<01:09, 77.63 examples/s]Tokenizing train dataset:  37%|███▋      | 3170/8564 [00:38<01:24, 63.53 examples/s]Tokenizing train dataset:  37%|███▋      | 3190/8564 [00:37<01:03, 84.58 examples/s]Tokenizing train dataset:  37%|███▋      | 3180/8564 [00:38<01:19, 67.95 examples/s]Tokenizing train dataset:  39%|███▊      | 3301/8564 [00:38<01:09, 75.84 examples/s]Tokenizing train dataset:  37%|███▋      | 3204/8564 [00:37<01:02, 86.28 examples/s]Tokenizing train dataset:  37%|███▋      | 3193/8564 [00:39<01:06, 80.43 examples/s]Tokenizing train dataset:  39%|███▊      | 3312/8564 [00:38<01:05, 80.20 examples/s]Tokenizing train dataset:  38%|███▊      | 3216/8564 [00:37<00:59, 89.56 examples/s]Tokenizing train dataset:  37%|███▋      | 3205/8564 [00:39<01:01, 87.83 examples/s]Tokenizing train dataset:  39%|███▉      | 3323/8564 [00:38<01:08, 76.39 examples/s]Tokenizing train dataset:  38%|███▊      | 3229/8564 [00:38<00:55, 96.11 examples/s]Tokenizing train dataset:  38%|███▊      | 3216/8564 [00:39<00:58, 91.14 examples/s]Tokenizing train dataset:  38%|███▊      | 3242/8564 [00:38<00:52, 100.49 examples/s]Tokenizing train dataset:  39%|███▉      | 3335/8564 [00:39<01:12, 72.31 examples/s]Tokenizing train dataset:  38%|███▊      | 3230/8564 [00:39<01:02, 85.17 examples/s]Tokenizing train dataset:  38%|███▊      | 3255/8564 [00:38<00:50, 105.62 examples/s]Tokenizing train dataset:  39%|███▉      | 3344/8564 [00:39<01:09, 74.66 examples/s]Tokenizing train dataset:  38%|███▊      | 3240/8564 [00:39<01:03, 83.30 examples/s]Tokenizing train dataset:  38%|███▊      | 3268/8564 [00:38<00:49, 106.09 examples/s]Tokenizing train dataset:  39%|███▉      | 3356/8564 [00:39<01:04, 80.50 examples/s]Tokenizing train dataset:  38%|███▊      | 3254/8564 [00:39<00:55, 95.07 examples/s]Tokenizing train dataset:  39%|███▉      | 3366/8564 [00:39<01:02, 83.58 examples/s]Tokenizing train dataset:  38%|███▊      | 3282/8564 [00:38<00:55, 94.79 examples/s] Tokenizing train dataset:  38%|███▊      | 3265/8564 [00:39<00:55, 95.50 examples/s]Tokenizing train dataset:  39%|███▉      | 3382/8564 [00:39<00:51, 100.50 examples/s]Tokenizing train dataset:  38%|███▊      | 3295/8564 [00:38<00:53, 98.36 examples/s]Tokenizing train dataset:  40%|███▉      | 3399/8564 [00:39<00:45, 114.12 examples/s]Tokenizing train dataset:  38%|███▊      | 3277/8564 [00:40<01:02, 84.86 examples/s]Tokenizing train dataset:  39%|███▊      | 3308/8564 [00:38<00:52, 100.46 examples/s]Tokenizing train dataset:  40%|███▉      | 3414/8564 [00:39<00:42, 121.48 examples/s]Tokenizing train dataset:  38%|███▊      | 3287/8564 [00:40<01:06, 79.14 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:39<00:58, 89.73 examples/s] Tokenizing train dataset:  40%|████      | 3440/8564 [00:39<00:33, 151.38 examples/s]Tokenizing train dataset:  38%|███▊      | 3297/8564 [00:40<01:14, 71.02 examples/s]Tokenizing train dataset:  40%|████      | 3463/8564 [00:40<00:32, 156.12 examples/s]Tokenizing train dataset:  39%|███▉      | 3330/8564 [00:39<01:12, 71.79 examples/s]Tokenizing train dataset:  41%|████      | 3479/8564 [00:40<00:32, 154.41 examples/s]Tokenizing train dataset:  39%|███▊      | 3310/8564 [00:40<01:16, 68.96 examples/s]Tokenizing train dataset:  39%|███▉      | 3341/8564 [00:39<01:08, 76.76 examples/s]Tokenizing train dataset:  41%|████      | 3497/8564 [00:40<00:33, 150.50 examples/s]Tokenizing train dataset:  39%|███▊      | 3318/8564 [00:40<01:16, 68.71 examples/s]Tokenizing train dataset:  39%|███▉      | 3352/8564 [00:39<01:10, 73.55 examples/s]Tokenizing train dataset:  39%|███▉      | 3327/8564 [00:40<01:12, 72.57 examples/s]Tokenizing train dataset:  41%|████      | 3519/8564 [00:40<00:37, 134.49 examples/s]Tokenizing train dataset:  39%|███▉      | 3340/8564 [00:40<01:01, 84.27 examples/s]Tokenizing train dataset:  39%|███▉      | 3362/8564 [00:39<01:14, 69.69 examples/s]Tokenizing train dataset:  41%|████▏     | 3537/8564 [00:40<00:40, 123.26 examples/s]Tokenizing train dataset:  39%|███▉      | 3355/8564 [00:41<00:54, 95.47 examples/s]Tokenizing train dataset:  39%|███▉      | 3374/8564 [00:39<01:04, 80.16 examples/s]Tokenizing train dataset:  39%|███▉      | 3366/8564 [00:41<00:53, 96.60 examples/s]Tokenizing train dataset:  41%|████▏     | 3551/8564 [00:40<00:45, 109.11 examples/s]Tokenizing train dataset:  40%|███▉      | 3392/8564 [00:39<00:58, 88.92 examples/s]Tokenizing train dataset:  39%|███▉      | 3379/8564 [00:41<00:50, 101.95 examples/s]Tokenizing train dataset:  42%|████▏     | 3564/8564 [00:40<00:46, 108.44 examples/s]Tokenizing train dataset:  40%|███▉      | 3395/8564 [00:41<00:48, 106.00 examples/s]Tokenizing train dataset:  40%|███▉      | 3405/8564 [00:40<01:08, 75.58 examples/s]Tokenizing train dataset:  42%|████▏     | 3576/8564 [00:41<00:48, 103.45 examples/s]Tokenizing train dataset:  40%|███▉      | 3407/8564 [00:41<00:51, 100.99 examples/s]Tokenizing train dataset:  40%|███▉      | 3415/8564 [00:40<01:07, 76.33 examples/s]Tokenizing train dataset:  42%|████▏     | 3589/8564 [00:41<00:49, 100.09 examples/s]Tokenizing train dataset:  40%|███▉      | 3424/8564 [00:40<01:07, 76.38 examples/s]Tokenizing train dataset:  40%|███▉      | 3421/8564 [00:41<00:55, 93.03 examples/s] Tokenizing train dataset:  42%|████▏     | 3605/8564 [00:41<00:51, 96.55 examples/s] Tokenizing train dataset:  40%|████      | 3438/8564 [00:40<00:58, 87.79 examples/s]Tokenizing train dataset:  40%|████      | 3435/8564 [00:41<00:50, 101.42 examples/s]Tokenizing train dataset:  42%|████▏     | 3617/8564 [00:41<00:54, 90.70 examples/s]Tokenizing train dataset:  40%|████      | 3448/8564 [00:41<00:49, 103.20 examples/s]Tokenizing train dataset:  40%|████      | 3451/8564 [00:40<01:01, 82.75 examples/s]Tokenizing train dataset:  40%|████      | 3462/8564 [00:42<00:47, 107.78 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:41<00:54, 90.47 examples/s]Tokenizing train dataset:  40%|████      | 3462/8564 [00:40<01:00, 83.80 examples/s]Tokenizing train dataset:  41%|████      | 3475/8564 [00:42<00:48, 105.42 examples/s]Tokenizing train dataset:  43%|████▎     | 3640/8564 [00:41<00:55, 88.42 examples/s]Tokenizing train dataset:  41%|████      | 3472/8564 [00:41<01:10, 72.29 examples/s]Tokenizing train dataset:  43%|████▎     | 3649/8564 [00:41<00:57, 86.01 examples/s]Tokenizing train dataset:  41%|████      | 3488/8564 [00:42<00:56, 89.90 examples/s] Tokenizing train dataset:  43%|████▎     | 3661/8564 [00:42<00:53, 91.69 examples/s]Tokenizing train dataset:  41%|████      | 3482/8564 [00:41<01:09, 73.06 examples/s]Tokenizing train dataset:  41%|████      | 3500/8564 [00:42<00:56, 90.09 examples/s]Tokenizing train dataset:  43%|████▎     | 3671/8564 [00:42<00:54, 89.71 examples/s]Tokenizing train dataset:  41%|████      | 3491/8564 [00:41<01:09, 73.32 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:42<00:55, 88.71 examples/s]Tokenizing train dataset:  41%|████      | 3514/8564 [00:42<00:53, 93.83 examples/s]Tokenizing train dataset:  41%|████      | 3503/8564 [00:41<01:02, 80.51 examples/s]Tokenizing train dataset:  43%|████▎     | 3693/8564 [00:42<00:52, 93.11 examples/s]Tokenizing train dataset:  41%|████      | 3517/8564 [00:41<00:53, 93.97 examples/s]Tokenizing train dataset:  41%|████      | 3528/8564 [00:42<00:55, 90.57 examples/s]Tokenizing train dataset:  41%|████      | 3528/8564 [00:41<00:53, 93.47 examples/s]Tokenizing train dataset:  43%|████▎     | 3705/8564 [00:42<00:54, 89.61 examples/s]Tokenizing train dataset:  41%|████▏     | 3538/8564 [00:42<00:54, 92.27 examples/s]Tokenizing train dataset:  41%|████▏     | 3538/8564 [00:41<00:53, 93.84 examples/s]Tokenizing train dataset:  43%|████▎     | 3722/8564 [00:42<00:46, 104.28 examples/s]Tokenizing train dataset:  41%|████▏     | 3549/8564 [00:43<00:56, 89.41 examples/s]Tokenizing train dataset:  42%|████▏     | 3560/8564 [00:43<00:55, 90.86 examples/s]Tokenizing train dataset:  41%|████▏     | 3549/8564 [00:41<01:03, 79.44 examples/s]Tokenizing train dataset:  44%|████▎     | 3733/8564 [00:42<00:56, 86.05 examples/s] Tokenizing train dataset:  42%|████▏     | 3574/8564 [00:43<00:51, 96.21 examples/s]Tokenizing train dataset:  42%|████▏     | 3558/8564 [00:42<01:02, 79.53 examples/s]Tokenizing train dataset:  44%|████▎     | 3746/8564 [00:43<00:58, 82.30 examples/s]Tokenizing train dataset:  42%|████▏     | 3590/8564 [00:43<00:44, 110.99 examples/s]Tokenizing train dataset:  42%|████▏     | 3571/8564 [00:42<01:03, 78.68 examples/s]Tokenizing train dataset:  42%|████▏     | 3607/8564 [00:43<00:39, 125.21 examples/s]Tokenizing train dataset:  44%|████▍     | 3757/8564 [00:43<01:01, 77.69 examples/s]Tokenizing train dataset:  42%|████▏     | 3588/8564 [00:42<00:51, 96.03 examples/s]Tokenizing train dataset:  42%|████▏     | 3605/8564 [00:42<00:43, 112.79 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:43<00:42, 115.98 examples/s]Tokenizing train dataset:  44%|████▍     | 3767/8564 [00:43<01:05, 73.47 examples/s]Tokenizing train dataset:  42%|████▏     | 3617/8564 [00:42<00:46, 106.53 examples/s]Tokenizing train dataset:  44%|████▍     | 3776/8564 [00:43<01:04, 74.80 examples/s]Tokenizing train dataset:  43%|████▎     | 3645/8564 [00:43<00:42, 114.51 examples/s]Tokenizing train dataset:  42%|████▏     | 3633/8564 [00:42<00:41, 118.02 examples/s]Tokenizing train dataset:  43%|████▎     | 3657/8564 [00:43<00:46, 105.84 examples/s]Tokenizing train dataset:  44%|████▍     | 3789/8564 [00:43<01:04, 73.75 examples/s]Tokenizing train dataset:  43%|████▎     | 3650/8564 [00:42<00:45, 107.61 examples/s]Tokenizing train dataset:  44%|████▍     | 3800/8564 [00:43<01:04, 73.73 examples/s]Tokenizing train dataset:  43%|████▎     | 3670/8564 [00:44<00:53, 91.20 examples/s] Tokenizing train dataset:  44%|████▍     | 3808/8564 [00:43<01:04, 73.51 examples/s]Tokenizing train dataset:  43%|████▎     | 3665/8564 [00:43<00:51, 95.46 examples/s] Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:44<00:55, 87.32 examples/s]Tokenizing train dataset:  45%|████▍     | 3818/8564 [00:44<01:02, 75.38 examples/s]Tokenizing train dataset:  43%|████▎     | 3694/8564 [00:44<00:50, 96.87 examples/s]Tokenizing train dataset:  43%|████▎     | 3679/8564 [00:43<00:56, 85.85 examples/s]Tokenizing train dataset:  43%|████▎     | 3707/8564 [00:44<00:47, 103.01 examples/s]Tokenizing train dataset:  45%|████▍     | 3828/8564 [00:44<01:05, 71.87 examples/s]Tokenizing train dataset:  44%|████▎     | 3728/8564 [00:44<00:39, 123.88 examples/s]Tokenizing train dataset:  43%|████▎     | 3695/8564 [00:43<00:54, 88.81 examples/s]Tokenizing train dataset:  45%|████▍     | 3836/8564 [00:44<01:11, 66.28 examples/s]Tokenizing train dataset:  43%|████▎     | 3718/8564 [00:43<00:42, 113.67 examples/s]Tokenizing train dataset:  45%|████▍     | 3846/8564 [00:44<01:08, 68.52 examples/s]Tokenizing train dataset:  44%|████▍     | 3748/8564 [00:44<00:42, 114.06 examples/s]Tokenizing train dataset:  44%|████▎     | 3739/8564 [00:43<00:40, 119.31 examples/s]Tokenizing train dataset:  44%|████▍     | 3761/8564 [00:44<00:41, 116.71 examples/s]Tokenizing train dataset:  45%|████▍     | 3853/8564 [00:44<01:14, 63.33 examples/s]Tokenizing train dataset:  44%|████▍     | 3775/8564 [00:45<00:41, 116.37 examples/s]Tokenizing train dataset:  44%|████▍     | 3752/8564 [00:43<00:42, 113.08 examples/s]Tokenizing train dataset:  45%|████▌     | 3864/8564 [00:44<01:06, 70.24 examples/s]Tokenizing train dataset:  45%|████▌     | 3875/8564 [00:44<01:04, 72.76 examples/s]Tokenizing train dataset:  44%|████▍     | 3792/8564 [00:45<00:43, 110.11 examples/s]Tokenizing train dataset:  44%|████▍     | 3766/8564 [00:44<00:47, 101.81 examples/s]Tokenizing train dataset:  45%|████▌     | 3885/8564 [00:45<01:02, 74.84 examples/s]Tokenizing train dataset:  44%|████▍     | 3805/8564 [00:45<00:43, 110.16 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:44<00:52, 90.97 examples/s] Tokenizing train dataset:  45%|████▌     | 3893/8564 [00:45<01:07, 68.98 examples/s]Tokenizing train dataset:  45%|████▍     | 3818/8564 [00:45<00:45, 105.44 examples/s]Tokenizing train dataset:  44%|████▍     | 3790/8564 [00:44<00:53, 88.89 examples/s]Tokenizing train dataset:  46%|████▌     | 3902/8564 [00:45<01:11, 64.97 examples/s]Tokenizing train dataset:  45%|████▍     | 3829/8564 [00:45<00:50, 94.09 examples/s] Tokenizing train dataset:  44%|████▍     | 3803/8564 [00:44<00:49, 95.66 examples/s]Tokenizing train dataset:  45%|████▍     | 3814/8564 [00:44<00:50, 94.85 examples/s]Tokenizing train dataset:  46%|████▌     | 3910/8564 [00:45<01:19, 58.74 examples/s]Tokenizing train dataset:  45%|████▍     | 3840/8564 [00:45<00:59, 79.22 examples/s]Tokenizing train dataset:  46%|████▌     | 3921/8564 [00:45<01:08, 67.37 examples/s]Tokenizing train dataset:  45%|████▍     | 3824/8564 [00:44<00:54, 87.25 examples/s]Tokenizing train dataset:  45%|████▍     | 3853/8564 [00:46<01:02, 75.78 examples/s]Tokenizing train dataset:  46%|████▌     | 3933/8564 [00:45<00:59, 77.29 examples/s]Tokenizing train dataset:  45%|████▍     | 3835/8564 [00:44<00:52, 90.93 examples/s]Tokenizing train dataset:  46%|████▌     | 3943/8564 [00:45<00:57, 80.14 examples/s]Tokenizing train dataset:  45%|████▌     | 3864/8564 [00:46<01:01, 76.65 examples/s]Tokenizing train dataset:  45%|████▍     | 3847/8564 [00:44<00:53, 88.01 examples/s]Tokenizing train dataset:  46%|████▌     | 3956/8564 [00:45<00:52, 87.86 examples/s]Tokenizing train dataset:  45%|████▌     | 3873/8564 [00:46<01:03, 73.97 examples/s]Tokenizing train dataset:  45%|████▌     | 3861/8564 [00:45<00:55, 84.46 examples/s]Tokenizing train dataset:  46%|████▋     | 3967/8564 [00:46<00:50, 90.51 examples/s]Tokenizing train dataset:  45%|████▌     | 3882/8564 [00:46<01:03, 73.56 examples/s]Tokenizing train dataset:  45%|████▌     | 3870/8564 [00:45<00:56, 82.68 examples/s]Tokenizing train dataset:  46%|████▋     | 3982/8564 [00:46<00:46, 99.42 examples/s]Tokenizing train dataset:  45%|████▌     | 3893/8564 [00:46<00:59, 78.27 examples/s]Tokenizing train dataset:  47%|████▋     | 3996/8564 [00:46<00:41, 109.81 examples/s]Tokenizing train dataset:  46%|████▌     | 3902/8564 [00:46<00:58, 79.45 examples/s]Tokenizing train dataset:  45%|████▌     | 3884/8564 [00:45<00:58, 80.27 examples/s]Tokenizing train dataset:  47%|████▋     | 4009/8564 [00:46<00:40, 112.24 examples/s]Tokenizing train dataset:  46%|████▌     | 3919/8564 [00:46<00:47, 98.06 examples/s]Tokenizing train dataset:  45%|████▌     | 3895/8564 [00:45<01:00, 76.83 examples/s]Tokenizing train dataset:  46%|████▌     | 3935/8564 [00:46<00:41, 112.38 examples/s]Tokenizing train dataset:  46%|████▌     | 3907/8564 [00:45<00:55, 84.15 examples/s]Tokenizing train dataset:  47%|████▋     | 4030/8564 [00:46<00:48, 94.11 examples/s] Tokenizing train dataset:  46%|████▌     | 3953/8564 [00:47<00:44, 103.01 examples/s]Tokenizing train dataset:  46%|████▌     | 3920/8564 [00:45<01:00, 77.23 examples/s]Tokenizing train dataset:  47%|████▋     | 4046/8564 [00:46<00:48, 92.96 examples/s]Tokenizing train dataset:  46%|████▋     | 3964/8564 [00:47<00:46, 98.16 examples/s] Tokenizing train dataset:  46%|████▌     | 3933/8564 [00:46<00:53, 87.29 examples/s]Tokenizing train dataset:  47%|████▋     | 4057/8564 [00:46<00:49, 91.78 examples/s]Tokenizing train dataset:  46%|████▌     | 3946/8564 [00:46<00:51, 90.30 examples/s]Tokenizing train dataset:  48%|████▊     | 4068/8564 [00:47<00:48, 93.30 examples/s]Tokenizing train dataset:  46%|████▋     | 3979/8564 [00:47<00:51, 89.07 examples/s]Tokenizing train dataset:  46%|████▌     | 3960/8564 [00:46<00:45, 100.12 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:47<00:46, 95.49 examples/s]Tokenizing train dataset:  46%|████▋     | 3971/8564 [00:46<00:45, 100.74 examples/s]Tokenizing train dataset:  47%|████▋     | 3994/8564 [00:47<00:54, 84.00 examples/s]Tokenizing train dataset:  48%|████▊     | 4091/8564 [00:47<00:46, 97.20 examples/s]Tokenizing train dataset:  46%|████▋     | 3982/8564 [00:46<00:47, 96.23 examples/s] Tokenizing train dataset:  48%|████▊     | 4108/8564 [00:47<00:38, 115.34 examples/s]Tokenizing train dataset:  47%|████▋     | 4006/8564 [00:47<00:55, 81.91 examples/s]Tokenizing train dataset:  48%|████▊     | 4120/8564 [00:47<00:38, 116.16 examples/s]Tokenizing train dataset:  47%|████▋     | 3995/8564 [00:46<00:48, 94.71 examples/s]Tokenizing train dataset:  47%|████▋     | 4021/8564 [00:47<00:49, 92.05 examples/s]Tokenizing train dataset:  47%|████▋     | 4006/8564 [00:46<00:49, 92.75 examples/s]Tokenizing train dataset:  47%|████▋     | 4034/8564 [00:47<00:46, 98.28 examples/s]Tokenizing train dataset:  48%|████▊     | 4137/8564 [00:47<00:40, 108.54 examples/s]Tokenizing train dataset:  47%|████▋     | 4045/8564 [00:48<00:46, 96.57 examples/s]Tokenizing train dataset:  48%|████▊     | 4149/8564 [00:47<00:41, 105.89 examples/s]Tokenizing train dataset:  47%|████▋     | 4023/8564 [00:46<00:49, 91.92 examples/s]Tokenizing train dataset:  47%|████▋     | 4057/8564 [00:48<00:45, 98.46 examples/s]Tokenizing train dataset:  49%|████▊     | 4160/8564 [00:47<00:42, 103.01 examples/s]Tokenizing train dataset:  47%|████▋     | 4033/8564 [00:47<00:51, 88.35 examples/s]Tokenizing train dataset:  49%|████▊     | 4171/8564 [00:48<00:42, 103.37 examples/s]Tokenizing train dataset:  48%|████▊     | 4070/8564 [00:48<00:43, 103.85 examples/s]Tokenizing train dataset:  47%|████▋     | 4043/8564 [00:47<00:53, 84.36 examples/s]Tokenizing train dataset:  49%|████▉     | 4183/8564 [00:48<00:41, 105.93 examples/s]Tokenizing train dataset:  48%|████▊     | 4084/8564 [00:48<00:46, 97.03 examples/s] Tokenizing train dataset:  49%|████▉     | 4197/8564 [00:48<00:39, 109.91 examples/s]Tokenizing train dataset:  48%|████▊     | 4105/8564 [00:48<00:36, 122.61 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:47<00:58, 77.06 examples/s]Tokenizing train dataset:  47%|████▋     | 4066/8564 [00:47<00:58, 76.38 examples/s]Tokenizing train dataset:  48%|████▊     | 4123/8564 [00:48<00:37, 118.97 examples/s]Tokenizing train dataset:  49%|████▉     | 4211/8564 [00:48<00:47, 90.87 examples/s] Tokenizing train dataset:  48%|████▊     | 4141/8564 [00:48<00:38, 115.82 examples/s]Tokenizing train dataset:  49%|████▉     | 4228/8564 [00:48<00:45, 94.92 examples/s]Tokenizing train dataset:  48%|████▊     | 4081/8564 [00:47<01:01, 72.52 examples/s]Tokenizing train dataset:  49%|████▊     | 4157/8564 [00:49<00:36, 122.30 examples/s]Tokenizing train dataset:  50%|████▉     | 4240/8564 [00:48<00:45, 94.04 examples/s]Tokenizing train dataset:  48%|████▊     | 4090/8564 [00:47<01:05, 68.49 examples/s]Tokenizing train dataset:  49%|████▊     | 4174/8564 [00:49<00:38, 115.20 examples/s]Tokenizing train dataset:  48%|████▊     | 4099/8564 [00:48<01:02, 71.64 examples/s]Tokenizing train dataset:  50%|████▉     | 4251/8564 [00:48<00:52, 82.24 examples/s]Tokenizing train dataset:  48%|████▊     | 4113/8564 [00:48<00:54, 81.35 examples/s]Tokenizing train dataset:  49%|████▉     | 4190/8564 [00:49<00:41, 105.86 examples/s]Tokenizing train dataset:  50%|████▉     | 4264/8564 [00:49<00:50, 84.74 examples/s]Tokenizing train dataset:  48%|████▊     | 4125/8564 [00:48<00:50, 88.32 examples/s]Tokenizing train dataset:  50%|████▉     | 4274/8564 [00:49<00:53, 79.74 examples/s]Tokenizing train dataset:  49%|████▉     | 4206/8564 [00:49<00:45, 96.30 examples/s] Tokenizing train dataset:  48%|████▊     | 4138/8564 [00:48<00:50, 87.32 examples/s]Tokenizing train dataset:  50%|█████     | 4288/8564 [00:49<00:54, 78.91 examples/s]Tokenizing train dataset:  48%|████▊     | 4149/8564 [00:48<00:51, 85.88 examples/s]Tokenizing train dataset:  49%|████▉     | 4217/8564 [00:49<00:52, 83.44 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:49<00:49, 87.00 examples/s]Tokenizing train dataset:  49%|████▊     | 4158/8564 [00:48<00:52, 83.51 examples/s]Tokenizing train dataset:  49%|████▉     | 4228/8564 [00:49<00:52, 82.92 examples/s]Tokenizing train dataset:  50%|█████     | 4313/8564 [00:49<00:47, 89.25 examples/s]Tokenizing train dataset:  50%|████▉     | 4240/8564 [00:50<00:48, 89.08 examples/s]Tokenizing train dataset:  49%|████▊     | 4170/8564 [00:48<00:56, 77.42 examples/s]Tokenizing train dataset:  50%|█████     | 4323/8564 [00:49<00:46, 91.03 examples/s]Tokenizing train dataset:  50%|████▉     | 4250/8564 [00:50<00:48, 89.04 examples/s]Tokenizing train dataset:  51%|█████     | 4333/8564 [00:49<00:46, 91.69 examples/s]Tokenizing train dataset:  49%|████▉     | 4180/8564 [00:48<00:56, 77.73 examples/s]Tokenizing train dataset:  50%|████▉     | 4262/8564 [00:50<00:45, 95.11 examples/s]Tokenizing train dataset:  49%|████▉     | 4191/8564 [00:49<00:56, 77.59 examples/s]Tokenizing train dataset:  51%|█████     | 4347/8564 [00:50<00:46, 89.75 examples/s]Tokenizing train dataset:  50%|████▉     | 4274/8564 [00:50<00:43, 98.00 examples/s]Tokenizing train dataset:  49%|████▉     | 4203/8564 [00:49<00:52, 83.20 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:50<00:42, 97.88 examples/s]Tokenizing train dataset:  50%|█████     | 4287/8564 [00:50<00:40, 104.70 examples/s]Tokenizing train dataset:  51%|█████     | 4371/8564 [00:50<00:43, 96.84 examples/s]Tokenizing train dataset:  50%|█████     | 4302/8564 [00:50<00:36, 116.12 examples/s]Tokenizing train dataset:  49%|████▉     | 4213/8564 [00:49<01:00, 72.22 examples/s]Tokenizing train dataset:  50%|█████     | 4315/8564 [00:50<00:37, 114.57 examples/s]Tokenizing train dataset:  51%|█████     | 4382/8564 [00:50<00:44, 93.05 examples/s]Tokenizing train dataset:  49%|████▉     | 4223/8564 [00:49<00:58, 73.84 examples/s]Tokenizing train dataset:  51%|█████     | 4327/8564 [00:50<00:36, 114.64 examples/s]Tokenizing train dataset:  51%|█████▏    | 4393/8564 [00:50<00:47, 87.57 examples/s]Tokenizing train dataset:  51%|█████     | 4339/8564 [00:50<00:37, 112.99 examples/s]Tokenizing train dataset:  51%|█████▏    | 4405/8564 [00:50<00:44, 92.93 examples/s]Tokenizing train dataset:  49%|████▉     | 4236/8564 [00:49<01:01, 70.08 examples/s]Tokenizing train dataset:  51%|█████     | 4351/8564 [00:51<00:37, 112.29 examples/s]Tokenizing train dataset:  50%|████▉     | 4245/8564 [00:49<00:58, 73.69 examples/s]Tokenizing train dataset:  52%|█████▏    | 4416/8564 [00:50<00:50, 82.21 examples/s]Tokenizing train dataset:  51%|█████     | 4364/8564 [00:51<00:41, 100.94 examples/s]Tokenizing train dataset:  50%|████▉     | 4258/8564 [00:49<00:51, 84.40 examples/s]Tokenizing train dataset:  52%|█████▏    | 4426/8564 [00:50<00:49, 82.94 examples/s]Tokenizing train dataset:  51%|█████     | 4377/8564 [00:51<00:39, 105.93 examples/s]Tokenizing train dataset:  52%|█████▏    | 4439/8564 [00:51<00:44, 93.32 examples/s]Tokenizing train dataset:  50%|████▉     | 4270/8564 [00:50<00:54, 78.69 examples/s]Tokenizing train dataset:  51%|█████▏    | 4390/8564 [00:51<00:38, 108.70 examples/s]Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:51<00:43, 94.78 examples/s]Tokenizing train dataset:  50%|████▉     | 4280/8564 [00:50<00:54, 79.29 examples/s]Tokenizing train dataset:  51%|█████▏    | 4403/8564 [00:51<00:37, 109.78 examples/s]Tokenizing train dataset:  52%|█████▏    | 4461/8564 [00:51<00:45, 91.04 examples/s]Tokenizing train dataset:  52%|█████▏    | 4423/8564 [00:51<00:31, 130.55 examples/s]Tokenizing train dataset:  50%|█████     | 4290/8564 [00:50<00:55, 77.05 examples/s]Tokenizing train dataset:  52%|█████▏    | 4471/8564 [00:51<00:48, 84.82 examples/s]Tokenizing train dataset:  50%|█████     | 4311/8564 [00:50<00:39, 106.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 4440/8564 [00:51<00:35, 114.91 examples/s]Tokenizing train dataset:  50%|█████     | 4323/8564 [00:50<00:39, 108.40 examples/s]Tokenizing train dataset:  52%|█████▏    | 4482/8564 [00:51<00:49, 81.83 examples/s]Tokenizing train dataset:  51%|█████     | 4335/8564 [00:50<00:38, 109.53 examples/s]Tokenizing train dataset:  52%|█████▏    | 4491/8564 [00:51<00:51, 79.40 examples/s]Tokenizing train dataset:  52%|█████▏    | 4455/8564 [00:52<00:41, 98.18 examples/s] Tokenizing train dataset:  51%|█████     | 4350/8564 [00:50<00:38, 109.38 examples/s]Tokenizing train dataset:  53%|█████▎    | 4500/8564 [00:51<00:55, 72.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:52<00:44, 92.74 examples/s]Tokenizing train dataset:  53%|█████▎    | 4509/8564 [00:51<00:54, 73.90 examples/s]Tokenizing train dataset:  51%|█████     | 4364/8564 [00:51<00:43, 95.64 examples/s] Tokenizing train dataset:  52%|█████▏    | 4480/8564 [00:52<00:43, 93.07 examples/s]Tokenizing train dataset:  53%|█████▎    | 4518/8564 [00:52<00:55, 73.22 examples/s]Tokenizing train dataset:  51%|█████     | 4376/8564 [00:51<00:43, 95.40 examples/s]Tokenizing train dataset:  52%|█████▏    | 4491/8564 [00:52<00:42, 94.74 examples/s]Tokenizing train dataset:  53%|█████▎    | 4527/8564 [00:52<01:01, 65.91 examples/s]Tokenizing train dataset:  53%|█████▎    | 4508/8564 [00:52<00:42, 94.36 examples/s]Tokenizing train dataset:  51%|█████▏    | 4390/8564 [00:51<00:48, 86.09 examples/s]Tokenizing train dataset:  53%|█████▎    | 4540/8564 [00:52<00:52, 77.04 examples/s]Tokenizing train dataset:  51%|█████▏    | 4400/8564 [00:51<00:48, 85.04 examples/s]Tokenizing train dataset:  53%|█████▎    | 4521/8564 [00:52<00:46, 86.86 examples/s]Tokenizing train dataset:  53%|█████▎    | 4553/8564 [00:52<00:45, 88.69 examples/s]Tokenizing train dataset:  51%|█████▏    | 4409/8564 [00:51<00:49, 83.32 examples/s]Tokenizing train dataset:  53%|█████▎    | 4567/8564 [00:52<00:39, 101.30 examples/s]Tokenizing train dataset:  53%|█████▎    | 4534/8564 [00:52<00:47, 85.15 examples/s]Tokenizing train dataset:  52%|█████▏    | 4419/8564 [00:51<00:48, 84.90 examples/s]Tokenizing train dataset:  53%|█████▎    | 4581/8564 [00:52<00:41, 95.67 examples/s] Tokenizing train dataset:  53%|█████▎    | 4551/8564 [00:53<00:44, 89.88 examples/s]Tokenizing train dataset:  52%|█████▏    | 4428/8564 [00:51<00:59, 69.13 examples/s]Tokenizing train dataset:  54%|█████▎    | 4592/8564 [00:52<00:40, 97.62 examples/s]Tokenizing train dataset:  53%|█████▎    | 4564/8564 [00:53<00:42, 94.73 examples/s]Tokenizing train dataset:  52%|█████▏    | 4439/8564 [00:52<00:54, 75.22 examples/s]Tokenizing train dataset:  54%|█████▎    | 4603/8564 [00:52<00:40, 97.20 examples/s]Tokenizing train dataset:  52%|█████▏    | 4447/8564 [00:52<00:55, 74.16 examples/s]Tokenizing train dataset:  53%|█████▎    | 4575/8564 [00:53<00:47, 83.47 examples/s]Tokenizing train dataset:  54%|█████▍    | 4616/8564 [00:53<00:39, 99.93 examples/s]Tokenizing train dataset:  52%|█████▏    | 4456/8564 [00:52<00:55, 74.25 examples/s]Tokenizing train dataset:  54%|█████▍    | 4628/8564 [00:53<00:39, 100.83 examples/s]Tokenizing train dataset:  54%|█████▎    | 4584/8564 [00:53<00:54, 73.02 examples/s]Tokenizing train dataset:  54%|█████▍    | 4644/8564 [00:53<00:34, 112.30 examples/s]Tokenizing train dataset:  54%|█████▎    | 4596/8564 [00:53<00:48, 82.13 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:52<00:57, 71.56 examples/s]Tokenizing train dataset:  54%|█████▍    | 4609/8564 [00:53<00:43, 91.76 examples/s]Tokenizing train dataset:  54%|█████▍    | 4660/8564 [00:53<00:36, 107.04 examples/s]Tokenizing train dataset:  52%|█████▏    | 4480/8564 [00:52<00:55, 73.02 examples/s]Tokenizing train dataset:  54%|█████▍    | 4622/8564 [00:53<00:40, 96.90 examples/s]Tokenizing train dataset:  55%|█████▍    | 4672/8564 [00:53<00:37, 104.83 examples/s]Tokenizing train dataset:  52%|█████▏    | 4490/8564 [00:52<00:53, 76.84 examples/s]Tokenizing train dataset:  55%|█████▍    | 4683/8564 [00:53<00:36, 105.70 examples/s]Tokenizing train dataset:  54%|█████▍    | 4633/8564 [00:54<00:41, 95.62 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:52<00:51, 79.26 examples/s]Tokenizing train dataset:  53%|█████▎    | 4515/8564 [00:52<00:41, 98.05 examples/s]Tokenizing train dataset:  54%|█████▍    | 4645/8564 [00:54<00:45, 85.57 examples/s]Tokenizing train dataset:  53%|█████▎    | 4528/8564 [00:53<00:38, 104.62 examples/s]Tokenizing train dataset:  55%|█████▍    | 4698/8564 [00:53<00:47, 81.67 examples/s] Tokenizing train dataset:  53%|█████▎    | 4542/8564 [00:53<00:36, 110.39 examples/s]Tokenizing train dataset:  55%|█████▍    | 4710/8564 [00:54<00:43, 87.88 examples/s]Tokenizing train dataset:  54%|█████▍    | 4658/8564 [00:54<00:53, 73.56 examples/s]Tokenizing train dataset:  53%|█████▎    | 4556/8564 [00:53<00:36, 111.30 examples/s]Tokenizing train dataset:  55%|█████▌    | 4720/8564 [00:54<00:46, 81.83 examples/s]Tokenizing train dataset:  55%|█████▍    | 4673/8564 [00:54<00:51, 75.76 examples/s]Tokenizing train dataset:  55%|█████▌    | 4732/8564 [00:54<00:44, 86.98 examples/s]Tokenizing train dataset:  53%|█████▎    | 4571/8564 [00:53<00:43, 91.90 examples/s] Tokenizing train dataset:  55%|█████▍    | 4682/8564 [00:54<00:51, 74.75 examples/s]Tokenizing train dataset:  55%|█████▌    | 4744/8564 [00:54<00:41, 92.25 examples/s]Tokenizing train dataset:  55%|█████▍    | 4690/8564 [00:54<00:53, 72.68 examples/s]Tokenizing train dataset:  53%|█████▎    | 4581/8564 [00:53<00:49, 79.70 examples/s]Tokenizing train dataset:  56%|█████▌    | 4759/8564 [00:54<00:40, 93.33 examples/s]Tokenizing train dataset:  55%|█████▍    | 4698/8564 [00:54<00:54, 70.86 examples/s]Tokenizing train dataset:  56%|█████▌    | 4769/8564 [00:54<00:41, 91.58 examples/s]Tokenizing train dataset:  54%|█████▎    | 4591/8564 [00:53<00:53, 74.40 examples/s]Tokenizing train dataset:  55%|█████▍    | 4709/8564 [00:55<00:55, 69.84 examples/s]Tokenizing train dataset:  54%|█████▎    | 4601/8564 [00:53<00:55, 71.79 examples/s]Tokenizing train dataset:  56%|█████▌    | 4782/8564 [00:54<00:46, 81.18 examples/s]Tokenizing train dataset:  55%|█████▌    | 4720/8564 [00:55<00:51, 74.57 examples/s]Tokenizing train dataset:  54%|█████▍    | 4611/8564 [00:54<00:51, 76.77 examples/s]Tokenizing train dataset:  55%|█████▌    | 4732/8564 [00:55<00:45, 84.42 examples/s]Tokenizing train dataset:  56%|█████▌    | 4796/8564 [00:55<00:48, 77.08 examples/s]Tokenizing train dataset:  54%|█████▍    | 4624/8564 [00:54<00:48, 80.65 examples/s]Tokenizing train dataset:  55%|█████▌    | 4741/8564 [00:55<00:45, 83.80 examples/s]Tokenizing train dataset:  56%|█████▌    | 4811/8564 [00:55<00:42, 88.57 examples/s]Tokenizing train dataset:  55%|█████▌    | 4750/8564 [00:55<00:47, 80.18 examples/s]Tokenizing train dataset:  54%|█████▍    | 4633/8564 [00:54<00:52, 75.48 examples/s]Tokenizing train dataset:  56%|█████▋    | 4832/8564 [00:55<00:33, 112.96 examples/s]Tokenizing train dataset:  54%|█████▍    | 4643/8564 [00:54<00:51, 75.90 examples/s]Tokenizing train dataset:  56%|█████▌    | 4762/8564 [00:55<00:48, 77.69 examples/s]Tokenizing train dataset:  57%|█████▋    | 4858/8564 [00:55<00:25, 146.19 examples/s]Tokenizing train dataset:  56%|█████▌    | 4770/8564 [00:55<00:49, 77.22 examples/s]Tokenizing train dataset:  57%|█████▋    | 4875/8564 [00:55<00:25, 146.56 examples/s]Tokenizing train dataset:  54%|█████▍    | 4655/8564 [00:54<00:58, 66.90 examples/s]Tokenizing train dataset:  56%|█████▌    | 4780/8564 [00:55<00:47, 78.94 examples/s]Tokenizing train dataset:  57%|█████▋    | 4894/8564 [00:55<00:24, 148.28 examples/s]Tokenizing train dataset:  54%|█████▍    | 4664/8564 [00:54<00:59, 65.86 examples/s]Tokenizing train dataset:  57%|█████▋    | 4913/8564 [00:55<00:23, 158.61 examples/s]Tokenizing train dataset:  56%|█████▌    | 4788/8564 [00:56<00:55, 68.50 examples/s]Tokenizing train dataset:  58%|█████▊    | 4933/8564 [00:55<00:22, 164.13 examples/s]Tokenizing train dataset:  56%|█████▌    | 4800/8564 [00:56<00:49, 75.52 examples/s]Tokenizing train dataset:  55%|█████▍    | 4677/8564 [00:55<00:59, 65.19 examples/s]Tokenizing train dataset:  58%|█████▊    | 4950/8564 [00:56<00:21, 164.55 examples/s]Tokenizing train dataset:  56%|█████▌    | 4815/8564 [00:56<00:42, 87.87 examples/s]Tokenizing train dataset:  58%|█████▊    | 4969/8564 [00:56<00:21, 170.50 examples/s]Tokenizing train dataset:  55%|█████▍    | 4687/8564 [00:55<01:00, 63.97 examples/s]Tokenizing train dataset:  56%|█████▋    | 4830/8564 [00:56<00:36, 101.60 examples/s]Tokenizing train dataset:  58%|█████▊    | 4990/8564 [00:56<00:19, 179.05 examples/s]Tokenizing train dataset:  55%|█████▍    | 4696/8564 [00:55<00:57, 67.22 examples/s]Tokenizing train dataset:  59%|█████▊    | 5021/8564 [00:56<00:16, 215.27 examples/s]Tokenizing train dataset:  57%|█████▋    | 4842/8564 [00:56<00:36, 101.13 examples/s]Tokenizing train dataset:  55%|█████▍    | 4704/8564 [00:55<01:00, 63.39 examples/s]Tokenizing train dataset:  57%|█████▋    | 4869/8564 [00:56<00:26, 141.58 examples/s]Tokenizing train dataset:  59%|█████▉    | 5047/8564 [00:56<00:18, 186.00 examples/s]Tokenizing train dataset:  55%|█████▌    | 4716/8564 [00:55<00:51, 74.54 examples/s]Tokenizing train dataset:  57%|█████▋    | 4890/8564 [00:56<00:24, 150.02 examples/s]Tokenizing train dataset:  55%|█████▌    | 4727/8564 [00:55<00:48, 79.67 examples/s]Tokenizing train dataset:  59%|█████▉    | 5072/8564 [00:56<00:19, 174.89 examples/s]Tokenizing train dataset:  57%|█████▋    | 4912/8564 [00:56<00:22, 165.18 examples/s]Tokenizing train dataset:  55%|█████▌    | 4740/8564 [00:55<00:43, 87.79 examples/s]Tokenizing train dataset:  58%|█████▊    | 4933/8564 [00:57<00:21, 169.84 examples/s]Tokenizing train dataset:  60%|█████▉    | 5099/8564 [00:56<00:21, 162.46 examples/s]Tokenizing train dataset:  55%|█████▌    | 4750/8564 [00:55<00:44, 85.02 examples/s]Tokenizing train dataset:  58%|█████▊    | 4954/8564 [00:57<00:21, 171.33 examples/s]Tokenizing train dataset:  56%|█████▌    | 4760/8564 [00:56<00:45, 84.38 examples/s]Tokenizing train dataset:  58%|█████▊    | 4979/8564 [00:57<00:22, 158.49 examples/s]Tokenizing train dataset:  60%|█████▉    | 5123/8564 [00:57<00:25, 137.38 examples/s]Tokenizing train dataset:  56%|█████▌    | 4771/8564 [00:56<00:51, 73.33 examples/s]Tokenizing train dataset:  58%|█████▊    | 4996/8564 [00:57<00:23, 149.36 examples/s]Tokenizing train dataset:  60%|██████    | 5143/8564 [00:57<00:24, 140.49 examples/s]Tokenizing train dataset:  56%|█████▌    | 4780/8564 [00:56<00:52, 71.44 examples/s]Tokenizing train dataset:  60%|██████    | 5162/8564 [00:57<00:23, 143.76 examples/s]Tokenizing train dataset:  59%|█████▊    | 5015/8564 [00:57<00:24, 142.86 examples/s]Tokenizing train dataset:  61%|██████    | 5186/8564 [00:57<00:21, 159.76 examples/s]Tokenizing train dataset:  56%|█████▌    | 4792/8564 [00:56<00:48, 78.41 examples/s]Tokenizing train dataset:  59%|█████▉    | 5033/8564 [00:57<00:24, 146.78 examples/s]Tokenizing train dataset:  56%|█████▌    | 4804/8564 [00:56<00:43, 85.51 examples/s]Tokenizing train dataset:  61%|██████    | 5214/8564 [00:57<00:18, 180.00 examples/s]Tokenizing train dataset:  59%|█████▉    | 5059/8564 [00:57<00:20, 174.30 examples/s]Tokenizing train dataset:  59%|█████▉    | 5084/8564 [00:57<00:18, 192.74 examples/s]Tokenizing train dataset:  56%|█████▋    | 4820/8564 [00:56<00:37, 98.55 examples/s]Tokenizing train dataset:  61%|██████▏   | 5247/8564 [00:57<00:17, 187.87 examples/s]Tokenizing train dataset:  60%|█████▉    | 5111/8564 [00:58<00:18, 186.87 examples/s]Tokenizing train dataset:  62%|██████▏   | 5277/8564 [00:57<00:15, 213.40 examples/s]Tokenizing train dataset:  57%|█████▋    | 4840/8564 [00:56<00:33, 110.79 examples/s]Tokenizing train dataset:  60%|█████▉    | 5135/8564 [00:58<00:18, 184.82 examples/s]Tokenizing train dataset:  57%|█████▋    | 4854/8564 [00:57<00:36, 101.59 examples/s]Tokenizing train dataset:  62%|██████▏   | 5307/8564 [00:58<00:16, 197.52 examples/s]Tokenizing train dataset:  60%|██████    | 5156/8564 [00:58<00:20, 170.31 examples/s]Tokenizing train dataset:  57%|█████▋    | 4867/8564 [00:57<00:35, 105.50 examples/s]Tokenizing train dataset:  60%|██████    | 5181/8564 [00:58<00:18, 187.86 examples/s]Tokenizing train dataset:  57%|█████▋    | 4885/8564 [00:57<00:30, 122.58 examples/s]Tokenizing train dataset:  62%|██████▏   | 5336/8564 [00:58<00:21, 149.51 examples/s]Tokenizing train dataset:  57%|█████▋    | 4906/8564 [00:57<00:25, 141.74 examples/s]Tokenizing train dataset:  61%|██████    | 5207/8564 [00:58<00:17, 191.70 examples/s]Tokenizing train dataset:  63%|██████▎   | 5357/8564 [00:58<00:20, 158.22 examples/s]Tokenizing train dataset:  58%|█████▊    | 4926/8564 [00:57<00:23, 152.46 examples/s]Tokenizing train dataset:  61%|██████    | 5230/8564 [00:58<00:18, 178.91 examples/s]Tokenizing train dataset:  58%|█████▊    | 4944/8564 [00:57<00:23, 156.68 examples/s]Tokenizing train dataset:  63%|██████▎   | 5382/8564 [00:58<00:21, 150.07 examples/s]Tokenizing train dataset:  61%|██████▏   | 5249/8564 [00:58<00:19, 169.80 examples/s]Tokenizing train dataset:  58%|█████▊    | 4960/8564 [00:57<00:23, 151.98 examples/s]Tokenizing train dataset:  62%|██████▏   | 5280/8564 [00:59<00:16, 203.34 examples/s]Tokenizing train dataset:  63%|██████▎   | 5401/8564 [00:58<00:20, 152.98 examples/s]Tokenizing train dataset:  58%|█████▊    | 4977/8564 [00:57<00:29, 123.42 examples/s]Tokenizing train dataset:  63%|██████▎   | 5426/8564 [00:58<00:20, 155.30 examples/s]Tokenizing train dataset:  62%|██████▏   | 5304/8564 [00:59<00:18, 175.66 examples/s]Tokenizing train dataset:  58%|█████▊    | 5000/8564 [00:58<00:24, 145.21 examples/s]Tokenizing train dataset:  64%|██████▎   | 5443/8564 [00:59<00:20, 153.43 examples/s]Tokenizing train dataset:  59%|█████▊    | 5022/8564 [00:58<00:22, 154.25 examples/s]Tokenizing train dataset:  64%|██████▎   | 5459/8564 [00:59<00:21, 144.65 examples/s]Tokenizing train dataset:  62%|██████▏   | 5327/8564 [00:59<00:24, 131.52 examples/s]Tokenizing train dataset:  59%|█████▉    | 5040/8564 [00:58<00:23, 152.35 examples/s]Tokenizing train dataset:  64%|██████▍   | 5477/8564 [00:59<00:23, 129.37 examples/s]Tokenizing train dataset:  62%|██████▏   | 5347/8564 [00:59<00:23, 135.55 examples/s]Tokenizing train dataset:  59%|█████▉    | 5069/8564 [00:58<00:19, 176.15 examples/s]Tokenizing train dataset:  63%|██████▎   | 5364/8564 [00:59<00:23, 138.25 examples/s]Tokenizing train dataset:  64%|██████▍   | 5500/8564 [00:59<00:21, 139.72 examples/s]Tokenizing train dataset:  59%|█████▉    | 5092/8564 [00:58<00:22, 154.90 examples/s]Tokenizing train dataset:  63%|██████▎   | 5388/8564 [00:59<00:20, 154.90 examples/s]Tokenizing train dataset:  64%|██████▍   | 5518/8564 [00:59<00:21, 142.38 examples/s]Tokenizing train dataset:  65%|██████▍   | 5537/8564 [00:59<00:19, 152.65 examples/s]Tokenizing train dataset:  63%|██████▎   | 5407/8564 [00:59<00:20, 155.18 examples/s]Tokenizing train dataset:  60%|█████▉    | 5114/8564 [00:58<00:23, 148.72 examples/s]Tokenizing train dataset:  63%|██████▎   | 5432/8564 [01:00<00:17, 175.46 examples/s]Tokenizing train dataset:  60%|█████▉    | 5135/8564 [00:58<00:21, 161.04 examples/s]Tokenizing train dataset:  64%|██████▎   | 5451/8564 [01:00<00:18, 165.63 examples/s]Tokenizing train dataset:  65%|██████▍   | 5560/8564 [00:59<00:24, 121.48 examples/s]Tokenizing train dataset:  60%|██████    | 5160/8564 [00:59<00:22, 150.30 examples/s]Tokenizing train dataset:  65%|██████▌   | 5580/8564 [01:00<00:22, 135.33 examples/s]Tokenizing train dataset:  64%|██████▍   | 5472/8564 [01:00<00:20, 151.87 examples/s]Tokenizing train dataset:  61%|██████    | 5186/8564 [00:59<00:19, 171.67 examples/s]Tokenizing train dataset:  64%|██████▍   | 5492/8564 [01:00<00:19, 161.61 examples/s]Tokenizing train dataset:  65%|██████▌   | 5596/8564 [01:00<00:23, 125.96 examples/s]Tokenizing train dataset:  61%|██████    | 5209/8564 [00:59<00:18, 182.70 examples/s]Tokenizing train dataset:  66%|██████▌   | 5617/8564 [01:00<00:20, 140.79 examples/s]Tokenizing train dataset:  64%|██████▍   | 5509/8564 [01:00<00:21, 140.88 examples/s]Tokenizing train dataset:  61%|██████    | 5230/8564 [00:59<00:19, 168.36 examples/s]Tokenizing train dataset:  66%|██████▌   | 5640/8564 [01:00<00:18, 160.76 examples/s]Tokenizing train dataset:  65%|██████▍   | 5531/8564 [01:00<00:20, 151.36 examples/s]Tokenizing train dataset:  61%|██████▏   | 5251/8564 [00:59<00:19, 169.75 examples/s]Tokenizing train dataset:  66%|██████▌   | 5660/8564 [01:00<00:17, 168.89 examples/s]Tokenizing train dataset:  65%|██████▍   | 5548/8564 [01:00<00:20, 149.67 examples/s]Tokenizing train dataset:  62%|██████▏   | 5272/8564 [00:59<00:20, 159.89 examples/s]Tokenizing train dataset:  66%|██████▋   | 5680/8564 [01:00<00:17, 163.85 examples/s]Tokenizing train dataset:  62%|██████▏   | 5295/8564 [00:59<00:18, 175.44 examples/s]Tokenizing train dataset:  65%|██████▌   | 5570/8564 [01:01<00:21, 140.51 examples/s]Tokenizing train dataset:  67%|██████▋   | 5698/8564 [01:00<00:17, 159.56 examples/s]Tokenizing train dataset:  65%|██████▌   | 5592/8564 [01:01<00:19, 153.54 examples/s]Tokenizing train dataset:  67%|██████▋   | 5730/8564 [01:00<00:15, 188.30 examples/s]Tokenizing train dataset:  62%|██████▏   | 5320/8564 [01:00<00:20, 156.12 examples/s]Tokenizing train dataset:  67%|██████▋   | 5752/8564 [01:00<00:14, 195.42 examples/s]Tokenizing train dataset:  66%|██████▌   | 5617/8564 [01:01<00:20, 140.76 examples/s]Tokenizing train dataset:  62%|██████▏   | 5345/8564 [01:00<00:21, 150.98 examples/s]Tokenizing train dataset:  67%|██████▋   | 5772/8564 [01:01<00:15, 182.72 examples/s]Tokenizing train dataset:  66%|██████▌   | 5635/8564 [01:01<00:20, 143.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 5793/8564 [01:01<00:15, 182.69 examples/s]Tokenizing train dataset:  63%|██████▎   | 5364/8564 [01:00<00:22, 142.33 examples/s]Tokenizing train dataset:  66%|██████▌   | 5658/8564 [01:01<00:17, 162.10 examples/s]Tokenizing train dataset:  66%|██████▋   | 5686/8564 [01:01<00:15, 189.42 examples/s]Tokenizing train dataset:  68%|██████▊   | 5820/8564 [01:01<00:16, 167.08 examples/s]Tokenizing train dataset:  63%|██████▎   | 5383/8564 [01:00<00:24, 129.15 examples/s]Tokenizing train dataset:  67%|██████▋   | 5708/8564 [01:01<00:14, 193.80 examples/s]Tokenizing train dataset:  63%|██████▎   | 5402/8564 [01:00<00:23, 135.93 examples/s]Tokenizing train dataset:  68%|██████▊   | 5840/8564 [01:01<00:18, 148.84 examples/s]Tokenizing train dataset:  63%|██████▎   | 5430/8564 [01:00<00:18, 166.28 examples/s]Tokenizing train dataset:  67%|██████▋   | 5740/8564 [01:01<00:14, 196.64 examples/s]Tokenizing train dataset:  64%|██████▎   | 5451/8564 [01:00<00:17, 175.26 examples/s]Tokenizing train dataset:  67%|██████▋   | 5774/8564 [01:02<00:13, 203.81 examples/s]Tokenizing train dataset:  68%|██████▊   | 5863/8564 [01:01<00:21, 125.94 examples/s]Tokenizing train dataset:  64%|██████▍   | 5473/8564 [01:01<00:19, 157.03 examples/s]Tokenizing train dataset:  68%|██████▊   | 5809/8564 [01:02<00:11, 232.31 examples/s]Tokenizing train dataset:  69%|██████▊   | 5884/8564 [01:02<00:22, 121.41 examples/s]Tokenizing train dataset:  64%|██████▍   | 5492/8564 [01:01<00:19, 154.64 examples/s]Tokenizing train dataset:  68%|██████▊   | 5840/8564 [01:02<00:12, 222.08 examples/s]Tokenizing train dataset:  69%|██████▉   | 5900/8564 [01:02<00:21, 125.59 examples/s]Tokenizing train dataset:  69%|██████▊   | 5869/8564 [01:02<00:12, 207.76 examples/s]Tokenizing train dataset:  64%|██████▍   | 5515/8564 [01:01<00:21, 140.32 examples/s]Tokenizing train dataset:  69%|██████▉   | 5918/8564 [01:02<00:20, 129.62 examples/s]Tokenizing train dataset:  65%|██████▍   | 5543/8564 [01:01<00:18, 165.91 examples/s]Tokenizing train dataset:  69%|██████▉   | 5891/8564 [01:02<00:13, 199.62 examples/s]Tokenizing train dataset:  69%|██████▉   | 5938/8564 [01:02<00:20, 127.89 examples/s]Tokenizing train dataset:  65%|██████▍   | 5561/8564 [01:01<00:17, 167.86 examples/s]Tokenizing train dataset:  65%|██████▌   | 5587/8564 [01:01<00:15, 189.57 examples/s]Tokenizing train dataset:  69%|██████▉   | 5918/8564 [01:02<00:15, 172.41 examples/s]Tokenizing train dataset:  70%|██████▉   | 5966/8564 [01:02<00:18, 139.19 examples/s]Tokenizing train dataset:  66%|██████▌   | 5610/8564 [01:01<00:15, 191.91 examples/s]Tokenizing train dataset:  69%|██████▉   | 5940/8564 [01:03<00:17, 147.70 examples/s]Tokenizing train dataset:  66%|██████▌   | 5637/8564 [01:01<00:14, 202.12 examples/s]Tokenizing train dataset:  70%|██████▉   | 5961/8564 [01:03<00:16, 153.70 examples/s]Tokenizing train dataset:  66%|██████▌   | 5663/8564 [01:02<00:17, 163.24 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [01:03<00:22, 113.06 examples/s]Tokenizing train dataset:  66%|██████▋   | 5684/8564 [01:02<00:21, 135.24 examples/s]Tokenizing train dataset:  70%|███████   | 6020/8564 [01:03<00:15, 162.90 examples/s]Tokenizing train dataset:  70%|██████▉   | 5987/8564 [01:03<00:38, 66.80 examples/s] Tokenizing train dataset:  70%|███████   | 6003/8564 [01:03<00:33, 76.12 examples/s]Tokenizing train dataset:  67%|██████▋   | 5706/8564 [01:02<00:21, 131.66 examples/s]Tokenizing train dataset:  71%|███████   | 6045/8564 [01:03<00:15, 159.38 examples/s]Tokenizing train dataset:  70%|███████   | 6023/8564 [01:03<00:27, 92.48 examples/s]Tokenizing train dataset:  67%|██████▋   | 5724/8564 [01:02<00:20, 135.91 examples/s]Tokenizing train dataset:  71%|███████   | 6045/8564 [01:03<00:22, 111.16 examples/s]Tokenizing train dataset:  71%|███████   | 6072/8564 [01:04<00:16, 148.03 examples/s]Tokenizing train dataset:  67%|██████▋   | 5744/8564 [01:02<00:21, 130.76 examples/s]Tokenizing train dataset:  71%|███████   | 6065/8564 [01:03<00:19, 126.46 examples/s]Tokenizing train dataset:  68%|██████▊   | 5789/8564 [01:02<00:14, 197.26 examples/s]Tokenizing train dataset:  71%|███████   | 6094/8564 [01:04<00:18, 132.32 examples/s]Tokenizing train dataset:  71%|███████   | 6084/8564 [01:03<00:20, 120.26 examples/s]Tokenizing train dataset:  68%|██████▊   | 5814/8564 [01:03<00:13, 201.17 examples/s]Tokenizing train dataset:  71%|███████   | 6100/8564 [01:04<00:20, 121.79 examples/s]Tokenizing train dataset:  71%|███████▏  | 6113/8564 [01:04<00:19, 128.12 examples/s]Tokenizing train dataset:  68%|██████▊   | 5846/8564 [01:03<00:14, 189.84 examples/s]Tokenizing train dataset:  72%|███████▏  | 6140/8564 [01:04<00:15, 151.96 examples/s]Tokenizing train dataset:  71%|███████▏  | 6122/8564 [01:04<00:21, 114.40 examples/s]Tokenizing train dataset:  72%|███████▏  | 6173/8564 [01:04<00:14, 166.21 examples/s]Tokenizing train dataset:  69%|██████▊   | 5867/8564 [01:03<00:17, 154.43 examples/s]Tokenizing train dataset:  72%|███████▏  | 6157/8564 [01:04<00:16, 148.30 examples/s]Tokenizing train dataset:  72%|███████▏  | 6196/8564 [01:04<00:14, 160.18 examples/s]Tokenizing train dataset:  69%|██████▉   | 5892/8564 [01:03<00:17, 151.41 examples/s]Tokenizing train dataset:  72%|███████▏  | 6183/8564 [01:04<00:14, 166.91 examples/s]Tokenizing train dataset:  73%|███████▎  | 6213/8564 [01:04<00:11, 195.94 examples/s]Tokenizing train dataset:  69%|██████▉   | 5913/8564 [01:03<00:16, 156.18 examples/s]Tokenizing train dataset:  73%|███████▎  | 6225/8564 [01:05<00:14, 158.00 examples/s]Tokenizing train dataset:  73%|███████▎  | 6235/8564 [01:04<00:11, 201.15 examples/s]Tokenizing train dataset:  69%|██████▉   | 5931/8564 [01:03<00:16, 160.39 examples/s]Tokenizing train dataset:  73%|███████▎  | 6258/8564 [01:04<00:11, 207.42 examples/s]Tokenizing train dataset:  70%|██████▉   | 5954/8564 [01:03<00:14, 174.95 examples/s]Tokenizing train dataset:  73%|███████▎  | 6244/8564 [01:05<00:17, 134.45 examples/s]Tokenizing train dataset:  73%|███████▎  | 6280/8564 [01:04<00:11, 201.21 examples/s]Tokenizing train dataset:  70%|██████▉   | 5977/8564 [01:04<00:14, 181.94 examples/s]Tokenizing train dataset:  73%|███████▎  | 6263/8564 [01:05<00:16, 139.68 examples/s]Tokenizing train dataset:  70%|███████   | 6005/8564 [01:04<00:14, 175.62 examples/s]Tokenizing train dataset:  74%|███████▍  | 6319/8564 [01:05<00:11, 203.14 examples/s]Tokenizing train dataset:  73%|███████▎  | 6280/8564 [01:05<00:18, 122.21 examples/s]Tokenizing train dataset:  74%|███████▍  | 6356/8564 [01:05<00:10, 207.59 examples/s]Tokenizing train dataset:  70%|███████   | 6025/8564 [01:04<00:16, 149.99 examples/s]Tokenizing train dataset:  74%|███████▎  | 6299/8564 [01:05<00:17, 130.02 examples/s]Tokenizing train dataset:  71%|███████   | 6052/8564 [01:04<00:14, 171.31 examples/s]Tokenizing train dataset:  74%|███████▍  | 6319/8564 [01:05<00:16, 138.38 examples/s]Tokenizing train dataset:  75%|███████▍  | 6390/8564 [01:05<00:11, 188.87 examples/s]Tokenizing train dataset:  71%|███████   | 6074/8564 [01:04<00:14, 174.44 examples/s]Tokenizing train dataset:  74%|███████▍  | 6340/8564 [01:05<00:16, 133.21 examples/s]Tokenizing train dataset:  75%|███████▍  | 6410/8564 [01:05<00:11, 185.28 examples/s]Tokenizing train dataset:  71%|███████▏  | 6102/8564 [01:04<00:14, 172.31 examples/s]Tokenizing train dataset:  74%|███████▍  | 6364/8564 [01:06<00:14, 150.31 examples/s]Tokenizing train dataset:  75%|███████▌  | 6431/8564 [01:05<00:11, 180.99 examples/s]Tokenizing train dataset:  71%|███████▏  | 6122/8564 [01:04<00:13, 175.34 examples/s]Tokenizing train dataset:  74%|███████▍  | 6380/8564 [01:06<00:15, 144.88 examples/s]Tokenizing train dataset:  75%|███████▌  | 6456/8564 [01:05<00:11, 187.18 examples/s]Tokenizing train dataset:  72%|███████▏  | 6149/8564 [01:05<00:12, 197.85 examples/s]Tokenizing train dataset:  75%|███████▍  | 6395/8564 [01:06<00:14, 145.48 examples/s]Tokenizing train dataset:  72%|███████▏  | 6172/8564 [01:05<00:12, 190.70 examples/s]Tokenizing train dataset:  76%|███████▌  | 6483/8564 [01:06<00:12, 172.02 examples/s]Tokenizing train dataset:  75%|███████▍  | 6410/8564 [01:06<00:14, 144.77 examples/s]Tokenizing train dataset:  75%|███████▌  | 6427/8564 [01:06<00:14, 148.49 examples/s]Tokenizing train dataset:  72%|███████▏  | 6200/8564 [01:05<00:13, 170.80 examples/s]Tokenizing train dataset:  76%|███████▌  | 6504/8564 [01:06<00:13, 147.65 examples/s]Tokenizing train dataset:  75%|███████▌  | 6448/8564 [01:06<00:13, 162.35 examples/s]Tokenizing train dataset:  73%|███████▎  | 6220/8564 [01:05<00:13, 167.95 examples/s]Tokenizing train dataset:  76%|███████▌  | 6525/8564 [01:06<00:13, 154.84 examples/s]Tokenizing train dataset:  76%|███████▌  | 6467/8564 [01:06<00:13, 156.53 examples/s]Tokenizing train dataset:  73%|███████▎  | 6243/8564 [01:05<00:12, 180.33 examples/s]Tokenizing train dataset:  76%|███████▋  | 6546/8564 [01:06<00:13, 155.22 examples/s]Tokenizing train dataset:  76%|███████▌  | 6487/8564 [01:06<00:15, 136.58 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [01:06<00:12, 161.22 examples/s]Tokenizing train dataset:  73%|███████▎  | 6269/8564 [01:05<00:12, 181.12 examples/s]Tokenizing train dataset:  77%|███████▋  | 6584/8564 [01:06<00:12, 154.12 examples/s]Tokenizing train dataset:  73%|███████▎  | 6294/8564 [01:05<00:13, 172.02 examples/s]Tokenizing train dataset:  76%|███████▌  | 6504/8564 [01:07<00:17, 116.97 examples/s]Tokenizing train dataset:  76%|███████▌  | 6530/8564 [01:07<00:14, 142.29 examples/s]Tokenizing train dataset:  74%|███████▍  | 6316/8564 [01:06<00:13, 169.06 examples/s]Tokenizing train dataset:  77%|███████▋  | 6600/8564 [01:06<00:15, 123.56 examples/s]Tokenizing train dataset:  76%|███████▋  | 6547/8564 [01:07<00:14, 142.86 examples/s]Tokenizing train dataset:  74%|███████▍  | 6341/8564 [01:06<00:14, 151.81 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [01:07<00:13, 147.58 examples/s]Tokenizing train dataset:  77%|███████▋  | 6620/8564 [01:07<00:16, 115.08 examples/s]Tokenizing train dataset:  74%|███████▍  | 6368/8564 [01:06<00:13, 165.10 examples/s]Tokenizing train dataset:  77%|███████▋  | 6583/8564 [01:07<00:13, 149.85 examples/s]Tokenizing train dataset:  78%|███████▊  | 6640/8564 [01:07<00:15, 123.06 examples/s]Tokenizing train dataset:  78%|███████▊  | 6658/8564 [01:07<00:14, 133.67 examples/s]Tokenizing train dataset:  75%|███████▍  | 6396/8564 [01:06<00:12, 167.61 examples/s]Tokenizing train dataset:  77%|███████▋  | 6602/8564 [01:07<00:15, 124.61 examples/s]Tokenizing train dataset:  75%|███████▍  | 6420/8564 [01:06<00:12, 176.38 examples/s]Tokenizing train dataset:  78%|███████▊  | 6680/8564 [01:07<00:13, 143.54 examples/s]Tokenizing train dataset:  77%|███████▋  | 6620/8564 [01:07<00:14, 132.66 examples/s]Tokenizing train dataset:  75%|███████▌  | 6443/8564 [01:06<00:11, 181.67 examples/s]Tokenizing train dataset:  78%|███████▊  | 6705/8564 [01:07<00:11, 162.47 examples/s]Tokenizing train dataset:  78%|███████▊  | 6644/8564 [01:08<00:12, 154.15 examples/s]Tokenizing train dataset:  75%|███████▌  | 6462/8564 [01:06<00:11, 182.95 examples/s]Tokenizing train dataset:  78%|███████▊  | 6664/8564 [01:08<00:12, 157.03 examples/s]Tokenizing train dataset:  79%|███████▊  | 6729/8564 [01:07<00:13, 132.08 examples/s]Tokenizing train dataset:  76%|███████▌  | 6491/8564 [01:07<00:11, 180.80 examples/s]Tokenizing train dataset:  78%|███████▊  | 6683/8564 [01:08<00:12, 153.50 examples/s]Tokenizing train dataset:  79%|███████▉  | 6747/8564 [01:08<00:13, 134.29 examples/s]Tokenizing train dataset:  78%|███████▊  | 6706/8564 [01:08<00:11, 160.21 examples/s]Tokenizing train dataset:  76%|███████▌  | 6520/8564 [01:07<00:11, 171.72 examples/s]Tokenizing train dataset:  79%|███████▉  | 6767/8564 [01:08<00:13, 137.36 examples/s]Tokenizing train dataset:  79%|███████▊  | 6724/8564 [01:08<00:11, 157.46 examples/s]Tokenizing train dataset:  79%|███████▉  | 6783/8564 [01:08<00:12, 142.03 examples/s]Tokenizing train dataset:  76%|███████▋  | 6542/8564 [01:07<00:13, 150.35 examples/s]Tokenizing train dataset:  79%|███████▊  | 6744/8564 [01:08<00:11, 163.75 examples/s]Tokenizing train dataset:  79%|███████▉  | 6800/8564 [01:08<00:12, 140.08 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [01:07<00:12, 163.17 examples/s]Tokenizing train dataset:  79%|███████▉  | 6767/8564 [01:08<00:09, 179.85 examples/s]Tokenizing train dataset:  79%|███████▉  | 6786/8564 [01:08<00:10, 166.90 examples/s]Tokenizing train dataset:  77%|███████▋  | 6590/8564 [01:07<00:12, 160.24 examples/s]Tokenizing train dataset:  80%|███████▉  | 6819/8564 [01:08<00:14, 118.33 examples/s]Tokenizing train dataset:  77%|███████▋  | 6613/8564 [01:07<00:11, 166.04 examples/s]Tokenizing train dataset:  80%|███████▉  | 6812/8564 [01:09<00:10, 163.05 examples/s]Tokenizing train dataset:  80%|███████▉  | 6834/8564 [01:08<00:14, 116.41 examples/s]Tokenizing train dataset:  78%|███████▊  | 6641/8564 [01:07<00:10, 185.41 examples/s]Tokenizing train dataset:  80%|████████  | 6857/8564 [01:08<00:12, 137.56 examples/s]Tokenizing train dataset:  78%|███████▊  | 6663/8564 [01:08<00:09, 192.23 examples/s]Tokenizing train dataset:  80%|████████  | 6883/8564 [01:09<00:10, 161.05 examples/s]Tokenizing train dataset:  80%|███████▉  | 6834/8564 [01:09<00:14, 123.10 examples/s]Tokenizing train dataset:  78%|███████▊  | 6688/8564 [01:08<00:09, 206.12 examples/s]Tokenizing train dataset:  78%|███████▊  | 6720/8564 [01:08<00:08, 227.52 examples/s]Tokenizing train dataset:  80%|███████▉  | 6850/8564 [01:09<00:14, 117.37 examples/s]Tokenizing train dataset:  81%|████████  | 6905/8564 [01:09<00:11, 141.29 examples/s]Tokenizing train dataset:  79%|███████▉  | 6745/8564 [01:08<00:07, 231.80 examples/s]Tokenizing train dataset:  80%|████████  | 6875/8564 [01:09<00:12, 137.91 examples/s]Tokenizing train dataset:  81%|████████  | 6924/8564 [01:09<00:11, 149.05 examples/s]Tokenizing train dataset:  79%|███████▉  | 6769/8564 [01:08<00:07, 230.88 examples/s]Tokenizing train dataset:  81%|████████  | 6950/8564 [01:09<00:09, 173.00 examples/s]Tokenizing train dataset:  81%|████████  | 6896/8564 [01:09<00:12, 132.23 examples/s]Tokenizing train dataset:  81%|████████▏ | 6970/8564 [01:09<00:08, 178.73 examples/s]Tokenizing train dataset:  81%|████████  | 6911/8564 [01:09<00:12, 132.27 examples/s]Tokenizing train dataset:  79%|███████▉  | 6799/8564 [01:08<00:09, 183.72 examples/s]Tokenizing train dataset:  82%|████████▏ | 6992/8564 [01:09<00:08, 182.38 examples/s]Tokenizing train dataset:  81%|████████  | 6931/8564 [01:10<00:11, 138.22 examples/s]Tokenizing train dataset:  82%|████████▏ | 7011/8564 [01:09<00:08, 174.85 examples/s]Tokenizing train dataset:  81%|████████  | 6949/8564 [01:10<00:11, 139.38 examples/s]Tokenizing train dataset:  80%|███████▉  | 6826/8564 [01:08<00:11, 151.34 examples/s]Tokenizing train dataset:  82%|████████▏ | 7032/8564 [01:09<00:09, 161.56 examples/s]Tokenizing train dataset:  81%|████████▏ | 6965/8564 [01:10<00:12, 125.26 examples/s]Tokenizing train dataset:  82%|████████▏ | 7056/8564 [01:10<00:08, 177.19 examples/s]Tokenizing train dataset:  80%|████████  | 6853/8564 [01:09<00:12, 134.12 examples/s]Tokenizing train dataset:  83%|████████▎ | 7077/8564 [01:10<00:08, 184.51 examples/s]Tokenizing train dataset:  82%|████████▏ | 6985/8564 [01:10<00:12, 124.70 examples/s]Tokenizing train dataset:  80%|████████  | 6874/8564 [01:09<00:11, 142.07 examples/s]Tokenizing train dataset:  82%|████████▏ | 7000/8564 [01:10<00:12, 124.50 examples/s]Tokenizing train dataset:  83%|████████▎ | 7103/8564 [01:10<00:08, 165.99 examples/s]Tokenizing train dataset:  82%|████████▏ | 7019/8564 [01:10<00:11, 134.30 examples/s]Tokenizing train dataset:  81%|████████  | 6897/8564 [01:09<00:12, 133.95 examples/s]Tokenizing train dataset:  83%|████████▎ | 7121/8564 [01:10<00:09, 148.06 examples/s]Tokenizing train dataset:  82%|████████▏ | 7035/8564 [01:10<00:11, 131.40 examples/s]Tokenizing train dataset:  81%|████████  | 6912/8564 [01:09<00:12, 132.82 examples/s]Tokenizing train dataset:  83%|████████▎ | 7147/8564 [01:10<00:08, 170.56 examples/s]Tokenizing train dataset:  81%|████████  | 6930/8564 [01:09<00:11, 140.78 examples/s]Tokenizing train dataset:  82%|████████▏ | 7054/8564 [01:10<00:10, 138.27 examples/s]Tokenizing train dataset:  84%|████████▍ | 7180/8564 [01:10<00:07, 184.38 examples/s]Tokenizing train dataset:  81%|████████  | 6947/8564 [01:09<00:10, 147.07 examples/s]Tokenizing train dataset:  83%|████████▎ | 7070/8564 [01:11<00:11, 126.10 examples/s]Tokenizing train dataset:  84%|████████▍ | 7209/8564 [01:10<00:06, 204.28 examples/s]Tokenizing train dataset:  81%|████████▏ | 6966/8564 [01:10<00:12, 128.16 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [01:11<00:11, 132.95 examples/s]Tokenizing train dataset:  82%|████████▏ | 6989/8564 [01:10<00:10, 148.87 examples/s]Tokenizing train dataset:  85%|████████▍ | 7239/8564 [01:11<00:07, 178.52 examples/s]Tokenizing train dataset:  83%|████████▎ | 7105/8564 [01:11<00:10, 134.33 examples/s]Tokenizing train dataset:  82%|████████▏ | 7008/8564 [01:10<00:10, 152.17 examples/s]Tokenizing train dataset:  85%|████████▍ | 7259/8564 [01:11<00:07, 177.99 examples/s]Tokenizing train dataset:  83%|████████▎ | 7120/8564 [01:11<00:12, 118.77 examples/s]Tokenizing train dataset:  85%|████████▌ | 7280/8564 [01:11<00:07, 175.64 examples/s]Tokenizing train dataset:  83%|████████▎ | 7135/8564 [01:11<00:11, 120.31 examples/s]Tokenizing train dataset:  82%|████████▏ | 7031/8564 [01:10<00:11, 128.97 examples/s]Tokenizing train dataset:  84%|████████▎ | 7154/8564 [01:11<00:10, 131.66 examples/s]Tokenizing train dataset:  85%|████████▌ | 7307/8564 [01:11<00:07, 162.83 examples/s]Tokenizing train dataset:  82%|████████▏ | 7058/8564 [01:10<00:09, 157.97 examples/s]Tokenizing train dataset:  84%|████████▍ | 7182/8564 [01:11<00:08, 162.51 examples/s]Tokenizing train dataset:  83%|████████▎ | 7089/8564 [01:10<00:08, 170.97 examples/s]Tokenizing train dataset:  86%|████████▌ | 7330/8564 [01:11<00:08, 150.45 examples/s]Tokenizing train dataset:  84%|████████▍ | 7208/8564 [01:12<00:07, 172.20 examples/s]Tokenizing train dataset:  83%|████████▎ | 7111/8564 [01:10<00:08, 179.59 examples/s]Tokenizing train dataset:  86%|████████▌ | 7353/8564 [01:11<00:08, 144.06 examples/s]Tokenizing train dataset:  83%|████████▎ | 7135/8564 [01:10<00:07, 187.94 examples/s]Tokenizing train dataset:  86%|████████▌ | 7370/8564 [01:11<00:08, 141.40 examples/s]Tokenizing train dataset:  84%|████████▍ | 7232/8564 [01:12<00:10, 123.04 examples/s]Tokenizing train dataset:  84%|████████▎ | 7162/8564 [01:11<00:07, 176.76 examples/s]Tokenizing train dataset:  86%|████████▌ | 7385/8564 [01:12<00:08, 134.08 examples/s]Tokenizing train dataset:  84%|████████▍ | 7187/8564 [01:11<00:07, 188.63 examples/s]Tokenizing train dataset:  85%|████████▍ | 7251/8564 [01:12<00:10, 126.51 examples/s]Tokenizing train dataset:  86%|████████▋ | 7401/8564 [01:12<00:08, 129.24 examples/s]Tokenizing train dataset:  84%|████████▍ | 7214/8564 [01:11<00:06, 193.26 examples/s]Tokenizing train dataset:  85%|████████▍ | 7275/8564 [01:12<00:10, 126.70 examples/s]Tokenizing train dataset:  87%|████████▋ | 7421/8564 [01:12<00:08, 136.60 examples/s]Tokenizing train dataset:  85%|████████▍ | 7239/8564 [01:11<00:07, 174.39 examples/s]Tokenizing train dataset:  85%|████████▌ | 7293/8564 [01:12<00:09, 131.97 examples/s]Tokenizing train dataset:  87%|████████▋ | 7450/8564 [01:12<00:06, 165.03 examples/s]Tokenizing train dataset:  85%|████████▍ | 7260/8564 [01:11<00:07, 176.44 examples/s]Tokenizing train dataset:  87%|████████▋ | 7474/8564 [01:12<00:06, 175.39 examples/s]Tokenizing train dataset:  85%|████████▌ | 7313/8564 [01:12<00:09, 129.46 examples/s]Tokenizing train dataset:  85%|████████▌ | 7290/8564 [01:11<00:06, 202.27 examples/s]Tokenizing train dataset:  88%|████████▊ | 7496/8564 [01:12<00:05, 184.48 examples/s]Tokenizing train dataset:  85%|████████▌ | 7313/8564 [01:11<00:06, 205.24 examples/s]Tokenizing train dataset:  86%|████████▌ | 7330/8564 [01:13<00:11, 112.13 examples/s]Tokenizing train dataset:  88%|████████▊ | 7530/8564 [01:12<00:05, 198.03 examples/s]Tokenizing train dataset:  86%|████████▌ | 7355/8564 [01:13<00:09, 133.86 examples/s]Tokenizing train dataset:  86%|████████▌ | 7338/8564 [01:12<00:07, 174.47 examples/s]Tokenizing train dataset:  88%|████████▊ | 7553/8564 [01:13<00:05, 189.24 examples/s]Tokenizing train dataset:  86%|████████▌ | 7372/8564 [01:13<00:08, 141.31 examples/s]Tokenizing train dataset:  89%|████████▊ | 7580/8564 [01:13<00:04, 205.54 examples/s]Tokenizing train dataset:  86%|████████▌ | 7362/8564 [01:12<00:07, 162.69 examples/s]Tokenizing train dataset:  86%|████████▋ | 7396/8564 [01:13<00:08, 142.38 examples/s]Tokenizing train dataset:  89%|████████▉ | 7610/8564 [01:13<00:04, 194.83 examples/s]Tokenizing train dataset:  86%|████████▌ | 7380/8564 [01:12<00:07, 154.28 examples/s]Tokenizing train dataset:  87%|████████▋ | 7419/8564 [01:13<00:07, 161.35 examples/s]Tokenizing train dataset:  89%|████████▉ | 7634/8564 [01:13<00:04, 202.43 examples/s]Tokenizing train dataset:  87%|████████▋ | 7449/8564 [01:13<00:05, 189.27 examples/s]Tokenizing train dataset:  86%|████████▋ | 7400/8564 [01:12<00:08, 133.80 examples/s]Tokenizing train dataset:  87%|████████▋ | 7471/8564 [01:13<00:05, 196.28 examples/s]Tokenizing train dataset:  89%|████████▉ | 7658/8564 [01:13<00:05, 163.63 examples/s]Tokenizing train dataset:  87%|████████▋ | 7420/8564 [01:12<00:08, 136.23 examples/s]Tokenizing train dataset:  87%|████████▋ | 7492/8564 [01:13<00:05, 197.97 examples/s]Tokenizing train dataset:  88%|████████▊ | 7513/8564 [01:14<00:05, 195.53 examples/s]Tokenizing train dataset:  87%|████████▋ | 7438/8564 [01:12<00:08, 138.54 examples/s]Tokenizing train dataset:  90%|████████▉ | 7677/8564 [01:13<00:06, 144.47 examples/s]Tokenizing train dataset:  88%|████████▊ | 7534/8564 [01:14<00:05, 193.86 examples/s]Tokenizing train dataset:  87%|████████▋ | 7456/8564 [01:13<00:08, 137.31 examples/s]Tokenizing train dataset:  90%|████████▉ | 7701/8564 [01:13<00:05, 143.96 examples/s]Tokenizing train dataset:  87%|████████▋ | 7472/8564 [01:13<00:08, 135.19 examples/s]Tokenizing train dataset:  88%|████████▊ | 7565/8564 [01:14<00:05, 191.82 examples/s]Tokenizing train dataset:  90%|█████████ | 7717/8564 [01:14<00:06, 137.57 examples/s]Tokenizing train dataset:  89%|████████▊ | 7600/8564 [01:14<00:04, 230.63 examples/s]Tokenizing train dataset:  87%|████████▋ | 7490/8564 [01:13<00:08, 129.90 examples/s]Tokenizing train dataset:  89%|████████▉ | 7629/8564 [01:14<00:03, 235.72 examples/s]Tokenizing train dataset:  88%|████████▊ | 7505/8564 [01:13<00:08, 122.48 examples/s]Tokenizing train dataset:  90%|█████████ | 7741/8564 [01:14<00:06, 121.04 examples/s]Tokenizing train dataset:  88%|████████▊ | 7532/8564 [01:13<00:06, 153.69 examples/s]Tokenizing train dataset:  91%|█████████ | 7754/8564 [01:14<00:07, 115.22 examples/s]Tokenizing train dataset:  91%|█████████ | 7774/8564 [01:14<00:06, 128.97 examples/s]Tokenizing train dataset:  89%|████████▉ | 7659/8564 [01:14<00:05, 155.07 examples/s]Tokenizing train dataset:  88%|████████▊ | 7553/8564 [01:13<00:07, 141.62 examples/s]Tokenizing train dataset:  91%|█████████ | 7790/8564 [01:14<00:05, 131.41 examples/s]Tokenizing train dataset:  89%|████████▊ | 7585/8564 [01:13<00:05, 172.71 examples/s]Tokenizing train dataset:  91%|█████████ | 7806/8564 [01:14<00:05, 137.61 examples/s]Tokenizing train dataset:  90%|████████▉ | 7682/8564 [01:15<00:06, 135.70 examples/s]Tokenizing train dataset:  89%|████████▉ | 7607/8564 [01:14<00:06, 155.17 examples/s]Tokenizing train dataset:  91%|█████████▏| 7825/8564 [01:14<00:05, 140.64 examples/s]Tokenizing train dataset:  90%|████████▉ | 7703/8564 [01:15<00:06, 142.81 examples/s]Tokenizing train dataset:  89%|████████▉ | 7627/8564 [01:14<00:05, 162.66 examples/s]Tokenizing train dataset:  92%|█████████▏| 7852/8564 [01:15<00:04, 170.45 examples/s]Tokenizing train dataset:  90%|█████████ | 7721/8564 [01:15<00:05, 143.30 examples/s]Tokenizing train dataset:  92%|█████████▏| 7870/8564 [01:15<00:04, 166.57 examples/s]Tokenizing train dataset:  89%|████████▉ | 7650/8564 [01:14<00:05, 154.64 examples/s]Tokenizing train dataset:  92%|█████████▏| 7888/8564 [01:15<00:04, 166.69 examples/s]Tokenizing train dataset:  90%|█████████ | 7742/8564 [01:15<00:06, 130.99 examples/s]Tokenizing train dataset:  90%|████████▉ | 7676/8564 [01:14<00:05, 157.51 examples/s]Tokenizing train dataset:  92%|█████████▏| 7911/8564 [01:15<00:03, 175.16 examples/s]Tokenizing train dataset:  90%|████████▉ | 7699/8564 [01:14<00:05, 168.42 examples/s]Tokenizing train dataset:  93%|█████████▎| 7933/8564 [01:15<00:03, 179.89 examples/s]Tokenizing train dataset:  91%|█████████ | 7762/8564 [01:15<00:06, 115.76 examples/s]Tokenizing train dataset:  93%|█████████▎| 7968/8564 [01:15<00:03, 194.66 examples/s]Tokenizing train dataset:  91%|█████████ | 7778/8564 [01:15<00:06, 112.60 examples/s]Tokenizing train dataset:  90%|█████████ | 7725/8564 [01:14<00:05, 150.50 examples/s]Tokenizing train dataset:  93%|█████████▎| 7991/8564 [01:15<00:02, 200.79 examples/s]Tokenizing train dataset:  90%|█████████ | 7748/8564 [01:14<00:04, 166.70 examples/s]Tokenizing train dataset:  91%|█████████ | 7794/8564 [01:16<00:06, 115.53 examples/s]Tokenizing train dataset:  91%|█████████ | 7808/8564 [01:16<00:06, 120.12 examples/s]Tokenizing train dataset:  94%|█████████▎| 8020/8564 [01:15<00:02, 187.25 examples/s]Tokenizing train dataset:  91%|█████████ | 7768/8564 [01:15<00:05, 150.45 examples/s]Tokenizing train dataset:  91%|█████████▏| 7836/8564 [01:16<00:04, 155.37 examples/s]Tokenizing train dataset:  91%|█████████ | 7787/8564 [01:15<00:05, 154.34 examples/s]Tokenizing train dataset:  92%|█████████▏| 7859/8564 [01:16<00:04, 170.02 examples/s]Tokenizing train dataset:  94%|█████████▍| 8042/8564 [01:16<00:03, 157.27 examples/s]Tokenizing train dataset:  91%|█████████ | 7808/8564 [01:15<00:05, 145.40 examples/s]Tokenizing train dataset:  92%|█████████▏| 7884/8564 [01:16<00:04, 165.77 examples/s]Tokenizing train dataset:  91%|█████████▏| 7830/8564 [01:15<00:04, 160.80 examples/s]Tokenizing train dataset:  94%|█████████▍| 8063/8564 [01:16<00:03, 140.49 examples/s]Tokenizing train dataset:  92%|█████████▏| 7906/8564 [01:16<00:03, 178.75 examples/s]Tokenizing train dataset:  92%|█████████▏| 7854/8564 [01:15<00:04, 173.00 examples/s]Tokenizing train dataset:  94%|█████████▍| 8081/8564 [01:16<00:03, 128.70 examples/s]Tokenizing train dataset:  93%|█████████▎| 7933/8564 [01:16<00:03, 177.67 examples/s]Tokenizing train dataset:  93%|█████████▎| 7958/8564 [01:16<00:03, 194.60 examples/s]Tokenizing train dataset:  92%|█████████▏| 7877/8564 [01:15<00:04, 155.20 examples/s]Tokenizing train dataset:  95%|█████████▍| 8096/8564 [01:16<00:03, 119.26 examples/s]Tokenizing train dataset:  93%|█████████▎| 7979/8564 [01:17<00:03, 192.78 examples/s]Tokenizing train dataset:  92%|█████████▏| 7900/8564 [01:15<00:03, 166.79 examples/s]Tokenizing train dataset:  95%|█████████▍| 8110/8564 [01:16<00:03, 117.65 examples/s]Tokenizing train dataset:  92%|█████████▏| 7919/8564 [01:15<00:03, 172.31 examples/s]Tokenizing train dataset:  93%|█████████▎| 8000/8564 [01:17<00:03, 173.39 examples/s]Tokenizing train dataset:  95%|█████████▍| 8130/8564 [01:16<00:03, 118.44 examples/s]Tokenizing train dataset:  93%|█████████▎| 7940/8564 [01:16<00:03, 174.33 examples/s]Tokenizing train dataset:  93%|█████████▎| 7960/8564 [01:16<00:03, 177.42 examples/s]Tokenizing train dataset:  95%|█████████▌| 8146/8564 [01:17<00:03, 124.24 examples/s]Tokenizing train dataset:  94%|█████████▎| 8024/8564 [01:17<00:03, 140.83 examples/s]Tokenizing train dataset:  95%|█████████▌| 8167/8564 [01:17<00:02, 137.75 examples/s]Tokenizing train dataset:  93%|█████████▎| 7981/8564 [01:16<00:03, 169.30 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:17<00:03, 151.81 examples/s]Tokenizing train dataset:  93%|█████████▎| 8003/8564 [01:16<00:03, 161.13 examples/s]Tokenizing train dataset:  94%|█████████▍| 8063/8564 [01:17<00:03, 150.73 examples/s]Tokenizing train dataset:  96%|█████████▌| 8192/8564 [01:17<00:02, 133.26 examples/s]Tokenizing train dataset:  94%|█████████▎| 8023/8564 [01:16<00:03, 166.75 examples/s]Tokenizing train dataset:  94%|█████████▍| 8083/8564 [01:17<00:03, 158.66 examples/s]Tokenizing train dataset:  96%|█████████▌| 8207/8564 [01:17<00:02, 123.49 examples/s]Tokenizing train dataset:  95%|█████████▍| 8102/8564 [01:17<00:02, 164.49 examples/s]Tokenizing train dataset:  96%|█████████▌| 8221/8564 [01:17<00:02, 122.92 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:16<00:03, 145.79 examples/s]Tokenizing train dataset:  95%|█████████▍| 8120/8564 [01:17<00:02, 167.55 examples/s]Tokenizing train dataset:  96%|█████████▌| 8241/8564 [01:17<00:02, 139.46 examples/s]Tokenizing train dataset:  95%|█████████▌| 8140/8564 [01:18<00:02, 175.84 examples/s]Tokenizing train dataset:  94%|█████████▍| 8066/8564 [01:16<00:04, 122.37 examples/s]Tokenizing train dataset:  95%|█████████▌| 8166/8564 [01:18<00:02, 182.09 examples/s]Tokenizing train dataset:  96%|█████████▋| 8261/8564 [01:17<00:02, 129.03 examples/s]Tokenizing train dataset:  94%|█████████▍| 8083/8564 [01:17<00:03, 130.62 examples/s]Tokenizing train dataset:  97%|█████████▋| 8290/8564 [01:18<00:01, 164.37 examples/s]Tokenizing train dataset:  96%|█████████▌| 8193/8564 [01:18<00:02, 169.86 examples/s]Tokenizing train dataset:  97%|█████████▋| 8317/8564 [01:18<00:01, 184.87 examples/s]Tokenizing train dataset:  95%|█████████▍| 8101/8564 [01:17<00:03, 116.54 examples/s]Tokenizing train dataset:  96%|█████████▌| 8212/8564 [01:18<00:02, 165.41 examples/s]Tokenizing train dataset:  97%|█████████▋| 8340/8564 [01:18<00:01, 192.24 examples/s]Tokenizing train dataset:  96%|█████████▌| 8229/8564 [01:18<00:02, 154.60 examples/s]Tokenizing train dataset:  95%|█████████▍| 8120/8564 [01:17<00:04, 107.00 examples/s]Tokenizing train dataset:  98%|█████████▊| 8380/8564 [01:18<00:00, 208.80 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [01:18<00:01, 163.03 examples/s]Tokenizing train dataset:  95%|█████████▍| 8134/8564 [01:17<00:04, 107.14 examples/s]Tokenizing train dataset:  97%|█████████▋| 8269/8564 [01:18<00:01, 166.27 examples/s]Tokenizing train dataset:  98%|█████████▊| 8411/8564 [01:18<00:00, 197.95 examples/s]Tokenizing train dataset:  95%|█████████▌| 8151/8564 [01:17<00:03, 118.62 examples/s]Tokenizing train dataset:  97%|█████████▋| 8291/8564 [01:18<00:01, 170.59 examples/s]Tokenizing train dataset:  98%|█████████▊| 8433/8564 [01:18<00:00, 198.42 examples/s]Tokenizing train dataset:  95%|█████████▌| 8167/8564 [01:17<00:03, 123.94 examples/s]Tokenizing train dataset:  97%|█████████▋| 8318/8564 [01:19<00:01, 161.35 examples/s]Tokenizing train dataset:  96%|█████████▌| 8181/8564 [01:17<00:03, 121.68 examples/s]Tokenizing train dataset:  99%|█████████▉| 8461/8564 [01:18<00:00, 185.48 examples/s]Tokenizing train dataset:  99%|█████████▉| 8485/8564 [01:18<00:00, 193.36 examples/s]Tokenizing train dataset:  96%|█████████▌| 8200/8564 [01:18<00:02, 133.60 examples/s]Tokenizing train dataset:  97%|█████████▋| 8339/8564 [01:19<00:01, 142.63 examples/s]Tokenizing train dataset:  99%|█████████▉| 8513/8564 [01:19<00:00, 184.91 examples/s]Tokenizing train dataset:  96%|█████████▌| 8220/8564 [01:18<00:03, 111.60 examples/s]Tokenizing train dataset:  98%|█████████▊| 8355/8564 [01:19<00:01, 119.52 examples/s]Tokenizing train dataset: 100%|█████████▉| 8538/8564 [01:19<00:00, 197.46 examples/s]Tokenizing train dataset:  96%|█████████▋| 8243/8564 [01:18<00:02, 136.09 examples/s]Tokenizing train dataset: 100%|█████████▉| 8560/8564 [01:19<00:00, 202.06 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:19<00:00, 107.86 examples/s]
Tokenizing train dataset:  98%|█████████▊| 8373/8564 [01:19<00:01, 113.62 examples/s]Tokenizing train dataset:  97%|█████████▋| 8281/8564 [01:18<00:01, 191.50 examples/s]Tokenizing train dataset:  97%|█████████▋| 8309/8564 [01:18<00:01, 208.82 examples/s]Tokenizing train dataset:  98%|█████████▊| 8396/8564 [01:19<00:01, 132.03 examples/s]Tokenizing train dataset:  98%|█████████▊| 8420/8564 [01:19<00:00, 151.01 examples/s]Tokenizing train dataset:  97%|█████████▋| 8342/8564 [01:18<00:01, 203.09 examples/s]Tokenizing train dataset:  99%|█████████▊| 8441/8564 [01:20<00:00, 156.22 examples/s]Tokenizing train dataset:  98%|█████████▊| 8373/8564 [01:18<00:00, 194.80 examples/s]Tokenizing train dataset:  99%|█████████▉| 8475/8564 [01:20<00:00, 167.53 examples/s]Tokenizing train dataset:  98%|█████████▊| 8396/8564 [01:19<00:00, 192.59 examples/s]Tokenizing train dataset:  98%|█████████▊| 8420/8564 [01:19<00:00, 191.71 examples/s]Tokenizing train dataset:  99%|█████████▉| 8499/8564 [01:20<00:00, 147.15 examples/s]Tokenizing train dataset:  99%|█████████▊| 8440/8564 [01:19<00:00, 192.16 examples/s]Tokenizing train dataset:  99%|█████████▉| 8516/8564 [01:20<00:00, 145.00 examples/s]Tokenizing train dataset:  99%|█████████▉| 8475/8564 [01:19<00:00, 218.88 examples/s]Tokenizing train dataset: 100%|█████████▉| 8535/8564 [01:20<00:00, 131.26 examples/s]Tokenizing train dataset:  99%|█████████▉| 8500/8564 [01:19<00:00, 187.04 examples/s]Tokenizing train dataset: 100%|█████████▉| 8554/8564 [01:20<00:00, 142.19 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:20<00:00, 105.78 examples/s]
Tokenizing train dataset: 100%|█████████▉| 8526/8564 [01:19<00:00, 175.54 examples/s]Tokenizing train dataset: 100%|█████████▉| 8553/8564 [01:20<00:00, 148.19 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:20<00:00, 106.88 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  52%|█████▏    | 500/953 [00:00<00:00, 4952.26 examples/s]Extracting prompt in eval dataset:  30%|███       | 290/953 [00:00<00:00, 2607.13 examples/s]Extracting prompt in eval dataset:  36%|███▋      | 346/953 [00:00<00:00, 2579.44 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4576.98 examples/s]
Extracting prompt in eval dataset:  67%|██████▋   | 640/953 [00:00<00:00, 3094.06 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  69%|██████▉   | 660/953 [00:00<00:00, 2612.67 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3488.11 examples/s]
Extracting prompt in eval dataset:  99%|█████████▉| 947/953 [00:00<00:00, 2673.12 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2638.70 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  49%|████▊     | 464/953 [00:00<00:00, 4303.89 examples/s]Applying chat template to eval dataset:  49%|████▉     | 470/953 [00:00<00:00, 4268.24 examples/s]Applying chat template to eval dataset:  49%|████▉     | 470/953 [00:00<00:00, 3447.44 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4307.33 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4271.29 examples/s]
Applying chat template to eval dataset:  91%|█████████ | 868/953 [00:00<00:00, 3636.30 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3737.44 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3781.13 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3757.28 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:10, 90.74 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:08, 105.96 examples/s]Tokenizing eval dataset:   3%|▎         | 25/953 [00:00<00:09, 100.88 examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:10, 91.68 examples/s]Tokenizing eval dataset:   3%|▎         | 24/953 [00:00<00:08, 103.63 examples/s]Tokenizing eval dataset:   4%|▍         | 39/953 [00:00<00:08, 111.29 examples/s]Tokenizing eval dataset:   2%|▏         | 22/953 [00:00<00:09, 97.50 examples/s]Tokenizing eval dataset:   5%|▌         | 51/953 [00:00<00:08, 109.43 examples/s]Tokenizing eval dataset:   3%|▎         | 33/953 [00:00<00:09, 98.73 examples/s]Tokenizing eval dataset:   4%|▍         | 39/953 [00:00<00:09, 96.36 examples/s] Tokenizing eval dataset:   5%|▍         | 44/953 [00:00<00:09, 98.56 examples/s]Tokenizing eval dataset:   7%|▋         | 63/953 [00:00<00:08, 103.80 examples/s]Tokenizing eval dataset:   6%|▌         | 53/953 [00:00<00:08, 108.12 examples/s]Tokenizing eval dataset:   6%|▌         | 54/953 [00:00<00:09, 94.43 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:08, 107.91 examples/s]Tokenizing eval dataset:   7%|▋         | 67/953 [00:00<00:07, 110.97 examples/s]Tokenizing eval dataset:  10%|▉         | 95/953 [00:00<00:06, 125.80 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:08, 106.58 examples/s]Tokenizing eval dataset:   7%|▋         | 67/953 [00:00<00:10, 87.10 examples/s]Tokenizing eval dataset:  12%|█▏        | 113/953 [00:00<00:06, 138.85 examples/s]Tokenizing eval dataset:  10%|▉         | 94/953 [00:00<00:08, 96.60 examples/s] Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:10, 83.67 examples/s]Tokenizing eval dataset:  14%|█▎        | 130/953 [00:01<00:05, 143.48 examples/s]Tokenizing eval dataset:  11%|█         | 105/953 [00:01<00:08, 98.19 examples/s]Tokenizing eval dataset:   9%|▉         | 90/953 [00:01<00:10, 84.88 examples/s]Tokenizing eval dataset:  15%|█▌        | 147/953 [00:01<00:06, 123.92 examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:01<00:08, 98.32 examples/s]Tokenizing eval dataset:  11%|█         | 107/953 [00:01<00:08, 103.72 examples/s]Tokenizing eval dataset:  13%|█▎        | 122/953 [00:01<00:07, 113.24 examples/s]Tokenizing eval dataset:  17%|█▋        | 164/953 [00:01<00:07, 112.27 examples/s]Tokenizing eval dataset:  14%|█▎        | 130/953 [00:01<00:09, 90.71 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:01<00:06, 125.13 examples/s]Tokenizing eval dataset:  15%|█▍        | 142/953 [00:01<00:09, 83.09 examples/s]Tokenizing eval dataset:  19%|█▉        | 179/953 [00:01<00:08, 90.81 examples/s] Tokenizing eval dataset:  16%|█▋        | 157/953 [00:01<00:06, 114.67 examples/s]Tokenizing eval dataset:  16%|█▌        | 151/953 [00:01<00:09, 82.75 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:01<00:09, 83.05 examples/s]Tokenizing eval dataset:  17%|█▋        | 166/953 [00:01<00:08, 93.28 examples/s]Tokenizing eval dataset:  18%|█▊        | 171/953 [00:01<00:07, 101.35 examples/s]Tokenizing eval dataset:  22%|██▏       | 206/953 [00:01<00:07, 96.05 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:07, 98.09 examples/s] Tokenizing eval dataset:  19%|█▉        | 180/953 [00:01<00:09, 84.62 examples/s]Tokenizing eval dataset:  23%|██▎       | 220/953 [00:02<00:07, 101.06 examples/s]Tokenizing eval dataset:  21%|██        | 199/953 [00:02<00:07, 101.39 examples/s]Tokenizing eval dataset:  25%|██▌       | 240/953 [00:02<00:06, 118.05 examples/s]Tokenizing eval dataset:  21%|██        | 200/953 [00:02<00:08, 91.15 examples/s]Tokenizing eval dataset:  23%|██▎       | 215/953 [00:02<00:06, 113.50 examples/s]Tokenizing eval dataset:  28%|██▊       | 264/953 [00:02<00:04, 145.87 examples/s]Tokenizing eval dataset:  22%|██▏       | 210/953 [00:02<00:08, 89.83 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:02<00:03, 175.36 examples/s]Tokenizing eval dataset:  30%|███       | 290/953 [00:02<00:03, 166.99 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:02<00:07, 97.74 examples/s]Tokenizing eval dataset:  30%|██▉       | 283/953 [00:02<00:03, 201.87 examples/s]Tokenizing eval dataset:  33%|███▎      | 310/953 [00:02<00:03, 173.65 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:02<00:04, 143.31 examples/s]Tokenizing eval dataset:  32%|███▏      | 308/953 [00:02<00:03, 214.28 examples/s]Tokenizing eval dataset:  35%|███▍      | 332/953 [00:02<00:03, 184.90 examples/s]Tokenizing eval dataset:  29%|██▊       | 273/953 [00:02<00:04, 153.00 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:02<00:02, 229.08 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:02<00:03, 193.76 examples/s]Tokenizing eval dataset:  32%|███▏      | 309/953 [00:02<00:03, 205.90 examples/s]Tokenizing eval dataset:  39%|███▊      | 369/953 [00:02<00:02, 233.93 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:02<00:02, 195.76 examples/s]Tokenizing eval dataset:  35%|███▍      | 332/953 [00:02<00:03, 167.58 examples/s]Tokenizing eval dataset:  42%|████▏     | 400/953 [00:02<00:02, 208.64 examples/s]Tokenizing eval dataset:  47%|████▋     | 447/953 [00:03<00:01, 268.33 examples/s]Tokenizing eval dataset:  37%|███▋      | 355/953 [00:02<00:03, 177.94 examples/s]Tokenizing eval dataset:  46%|████▌     | 436/953 [00:03<00:02, 243.12 examples/s]Tokenizing eval dataset:  39%|███▉      | 375/953 [00:03<00:03, 176.52 examples/s]Tokenizing eval dataset:  50%|█████     | 478/953 [00:03<00:01, 241.65 examples/s]Tokenizing eval dataset:  50%|█████     | 478/953 [00:03<00:01, 287.33 examples/s]Tokenizing eval dataset:  42%|████▏     | 400/953 [00:03<00:02, 184.68 examples/s]Tokenizing eval dataset:  53%|█████▎    | 505/953 [00:03<00:01, 238.48 examples/s]Tokenizing eval dataset:  54%|█████▍    | 516/953 [00:03<00:01, 298.22 examples/s]Tokenizing eval dataset:  45%|████▍     | 428/953 [00:03<00:02, 202.66 examples/s]Tokenizing eval dataset:  57%|█████▋    | 539/953 [00:03<00:01, 224.15 examples/s]Tokenizing eval dataset:  58%|█████▊    | 555/953 [00:03<00:01, 276.06 examples/s]Tokenizing eval dataset:  47%|████▋     | 450/953 [00:03<00:02, 201.41 examples/s]Tokenizing eval dataset:  60%|██████    | 574/953 [00:03<00:01, 215.68 examples/s]Tokenizing eval dataset:  50%|████▉     | 476/953 [00:03<00:02, 189.47 examples/s]Tokenizing eval dataset:  62%|██████▏   | 595/953 [00:03<00:01, 218.92 examples/s]Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:03<00:01, 207.38 examples/s]Tokenizing eval dataset:  53%|█████▎    | 505/953 [00:03<00:02, 176.89 examples/s]Tokenizing eval dataset:  65%|██████▌   | 623/953 [00:03<00:01, 223.96 examples/s]Tokenizing eval dataset:  55%|█████▌    | 525/953 [00:03<00:02, 179.91 examples/s]Tokenizing eval dataset:  67%|██████▋   | 638/953 [00:04<00:01, 191.13 examples/s]Tokenizing eval dataset:  69%|██████▉   | 662/953 [00:03<00:01, 227.97 examples/s]Tokenizing eval dataset:  58%|█████▊    | 553/953 [00:03<00:02, 180.32 examples/s]Tokenizing eval dataset:  73%|███████▎  | 693/953 [00:04<00:01, 237.97 examples/s]Tokenizing eval dataset:  70%|██████▉   | 665/953 [00:04<00:01, 179.44 examples/s]Tokenizing eval dataset:  61%|██████    | 580/953 [00:04<00:02, 172.00 examples/s]Tokenizing eval dataset:  72%|███████▏  | 688/953 [00:04<00:01, 187.62 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:04<00:01, 209.35 examples/s]Tokenizing eval dataset:  64%|██████▍   | 611/953 [00:04<00:01, 196.47 examples/s]Tokenizing eval dataset:  75%|███████▍  | 714/953 [00:04<00:01, 177.96 examples/s]Tokenizing eval dataset:  67%|██████▋   | 637/953 [00:04<00:01, 198.12 examples/s]Tokenizing eval dataset:  79%|███████▊  | 750/953 [00:04<00:01, 184.44 examples/s]Tokenizing eval dataset:  77%|███████▋  | 735/953 [00:04<00:01, 154.06 examples/s]Tokenizing eval dataset:  81%|████████▏ | 776/953 [00:04<00:00, 182.39 examples/s]Tokenizing eval dataset:  70%|██████▉   | 667/953 [00:04<00:01, 194.53 examples/s]Tokenizing eval dataset:  72%|███████▏  | 690/953 [00:04<00:01, 197.98 examples/s]Tokenizing eval dataset:  80%|███████▉  | 759/953 [00:04<00:01, 150.35 examples/s]Tokenizing eval dataset:  85%|████████▍ | 809/953 [00:04<00:00, 184.02 examples/s]Tokenizing eval dataset:  82%|████████▏ | 779/953 [00:04<00:01, 158.94 examples/s]Tokenizing eval dataset:  75%|███████▌  | 717/953 [00:04<00:01, 187.45 examples/s]Tokenizing eval dataset:  88%|████████▊ | 840/953 [00:04<00:00, 205.58 examples/s]Tokenizing eval dataset:  84%|████████▍ | 799/953 [00:05<00:00, 160.38 examples/s]Tokenizing eval dataset:  91%|█████████ | 864/953 [00:04<00:00, 204.59 examples/s]Tokenizing eval dataset:  78%|███████▊  | 742/953 [00:04<00:01, 171.14 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:05<00:00, 193.05 examples/s]Tokenizing eval dataset:  90%|█████████ | 860/953 [00:05<00:00, 218.11 examples/s]Tokenizing eval dataset:  81%|████████  | 769/953 [00:05<00:00, 184.31 examples/s]Tokenizing eval dataset:  93%|█████████▎| 890/953 [00:05<00:00, 182.80 examples/s]Tokenizing eval dataset:  93%|█████████▎| 887/953 [00:05<00:00, 227.31 examples/s]Tokenizing eval dataset:  83%|████████▎ | 793/953 [00:05<00:00, 194.15 examples/s]Tokenizing eval dataset:  96%|█████████▌| 913/953 [00:05<00:00, 166.01 examples/s]Tokenizing eval dataset:  96%|█████████▌| 914/953 [00:05<00:00, 234.06 examples/s]Tokenizing eval dataset:  86%|████████▌ | 816/953 [00:05<00:00, 174.22 examples/s]Tokenizing eval dataset:  98%|█████████▊| 937/953 [00:05<00:00, 180.11 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:05<00:00, 236.04 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 169.60 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 172.03 examples/s]
Tokenizing eval dataset:  89%|████████▉ | 848/953 [00:05<00:00, 183.37 examples/s]Tokenizing eval dataset:  92%|█████████▏| 880/953 [00:05<00:00, 210.02 examples/s]Tokenizing eval dataset:  95%|█████████▌| 908/953 [00:05<00:00, 224.85 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:05<00:00, 210.74 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 159.38 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Loading extension module cpu_adam...
Time to load cpu_adam op: 6.608569860458374 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.793570041656494 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.2625763416290283 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.360464572906494 seconds
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
[rank4]:[E530 17:36:41.434567370 ProcessGroupNCCL.cpp:552] [Rank 4] Collective WorkNCCL(SeqNum=2578, OpType=_ALLGATHER_BASE, NumelIn=28672, NumelOut=229376, Timeout(ms)=1800000) raised the following async exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgress: Connection closed by remote peer vggn28.vega.pri<50998>
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6f7996c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7f6f27c211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7f6f27c2964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7f6f27c2b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7f6f27c2c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7f6f79dee5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7f6f7bea2ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7f6f7bf34a40 in /lib/x86_64-linux-gnu/libc.so.6)

[rank4]:[E530 17:36:42.055146712 ProcessGroupNCCL.cpp:2168] [PG ID 0 PG GUID 0(default_pg) Rank 4]  failure detected by watchdog at work sequence id: 2578 PG status: last enqueued work: 2578, last completed work: 2577
[rank4]:[E530 17:36:42.055183102 ProcessGroupNCCL.cpp:667] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.
[rank7]:[E530 17:36:45.555013413 ProcessGroupNCCL.cpp:552] [Rank 7] Collective WorkNCCL(SeqNum=2579, OpType=_ALLGATHER_BASE, NumelIn=28672, NumelOut=229376, Timeout(ms)=1800000) raised the following async exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgressOpt: Call to recv from 10.210.4.12<53719> failed : Broken pipe
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7ff8f376c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7ff8a1e211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7ff8a1e2964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7ff8a1e2b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7ff8a1e2c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7ff8f3eee5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7ff8f5faaac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7ff8f603ca40 in /lib/x86_64-linux-gnu/libc.so.6)

[rank7]:[E530 17:36:45.578067580 ProcessGroupNCCL.cpp:2168] [PG ID 0 PG GUID 0(default_pg) Rank 7]  failure detected by watchdog at work sequence id: 2579 PG status: last enqueued work: 2579, last completed work: 2578
[rank7]:[E530 17:36:45.578076790 ProcessGroupNCCL.cpp:667] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.
[rank4]:[E530 17:36:48.192404253 ProcessGroupNCCL.cpp:681] [Rank 4] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank4]:[E530 17:36:48.192446223 ProcessGroupNCCL.cpp:695] [Rank 4] To avoid data inconsistency, we are taking the entire process down.
[rank4]:[E530 17:36:48.192478314 ProcessGroupNCCL.cpp:1895] [PG ID 0 PG GUID 0(default_pg) Rank 4] Process group watchdog thread terminated with exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgress: Connection closed by remote peer vggn28.vega.pri<50998>
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6f7996c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7f6f27c211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7f6f27c2964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7f6f27c2b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7f6f27c2c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7f6f79dee5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7f6f7bea2ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7f6f7bf34a40 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 4] Process group watchdog thread terminated with exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgress: Connection closed by remote peer vggn28.vega.pri<50998>
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6f7996c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7f6f27c211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7f6f27c2964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7f6f27c2b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7f6f27c2c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7f6f79dee5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7f6f7bea2ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7f6f7bf34a40 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1901 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f6f7996c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5c6fc (0x7f6f278876fc in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x7f6f79dee5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x94ac3 (0x7f6f7bea2ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #4: <unknown function> + 0x126a40 (0x7f6f7bf34a40 in /lib/x86_64-linux-gnu/libc.so.6)

W0530 17:37:00.410000 798932 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 799005 closing signal SIGTERM
W0530 17:37:04.297000 798932 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 799006 closing signal SIGTERM
W0530 17:37:04.319000 798932 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 799007 closing signal SIGTERM
E0530 17:37:07.540000 798932 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -6) local_rank: 0 (pid: 799004) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1182, in launch_command
    deepspeed_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 861, in deepspeed_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
train.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-30_17:36:59
  host      : pm5-nod90.vega.pri
  rank      : 4 (local_rank: 0)
  exitcode  : -6 (pid: 799004)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 799004
=======================================================
