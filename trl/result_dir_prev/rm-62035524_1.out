cpu-bind=MASK - gn26, task  1  0 [3649331]: mask 0x1000000000000000000000000000000010000000000000000000000000000 set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn25
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 1     --main_process_ip gn25     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62035524     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-29 23:34:17,808] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0529 23:34:21.666000 3649373 torch/distributed/run.py:792] 
W0529 23:34:21.666000 3649373 torch/distributed/run.py:792] *****************************************
W0529 23:34:21.666000 3649373 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0529 23:34:21.666000 3649373 torch/distributed/run.py:792] *****************************************
[2025-05-29 23:34:49,339] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-29 23:34:49,394] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-29 23:34:49,499] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-29 23:34:49,546] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 1
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
[2025-05-29 23:35:00,413] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 8564
Eval steps: 4282
[2025-05-29 23:35:00,434] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-29 23:35:00,455] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-29 23:35:00,479] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
[2025-05-29 23:35:04,633] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-29 23:35:04,633] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-29 23:35:04,643] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-29 23:35:06,102] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
gn26:3649540:3649540 [0] NCCL INFO cudaDriverVersion 12070
gn26:3649540:3649540 [0] NCCL INFO Bootstrap : Using ib0:10.210.4.10<0>
gn26:3649540:3649540 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gn26:3649540:3649540 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gn26:3649540:3649540 [0] NCCL INFO NET/Plugin: Using internal network plugin.
gn26:3649543:3649543 [3] NCCL INFO cudaDriverVersion 12070
gn26:3649543:3649543 [3] NCCL INFO Bootstrap : Using ib0:10.210.4.10<0>
gn26:3649543:3649543 [3] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gn26:3649543:3649543 [3] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gn26:3649543:3649543 [3] NCCL INFO NET/Plugin: Using internal network plugin.
gn26:3649540:3649540 [0] NCCL INFO Comm config Blocking set to 1
gn26:3649543:3649543 [3] NCCL INFO Comm config Blocking set to 1
gn26:3649541:3649541 [1] NCCL INFO cudaDriverVersion 12070
gn26:3649541:3649541 [1] NCCL INFO Bootstrap : Using ib0:10.210.4.10<0>
gn26:3649541:3649541 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gn26:3649541:3649541 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gn26:3649541:3649541 [1] NCCL INFO NET/Plugin: Using internal network plugin.
gn26:3649542:3649542 [2] NCCL INFO cudaDriverVersion 12070
gn26:3649542:3649542 [2] NCCL INFO Bootstrap : Using ib0:10.210.4.10<0>
gn26:3649542:3649542 [2] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
gn26:3649542:3649542 [2] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
gn26:3649542:3649542 [2] NCCL INFO NET/Plugin: Using internal network plugin.
gn26:3649542:3649542 [2] NCCL INFO Comm config Blocking set to 1
gn26:3649541:3649541 [1] NCCL INFO Comm config Blocking set to 1
gn26:3649542:3650076 [2] NCCL INFO Failed to open libibverbs.so[.1]
gn26:3649542:3650076 [2] NCCL INFO NET/Socket : Using [0]ib0:10.210.4.10<0>
gn26:3649542:3650076 [2] NCCL INFO Using non-device net plugin version 0
gn26:3649542:3650076 [2] NCCL INFO Using network Socket
gn26:3649540:3650074 [0] NCCL INFO Failed to open libibverbs.so[.1]
gn26:3649540:3650074 [0] NCCL INFO NET/Socket : Using [0]ib0:10.210.4.10<0>
gn26:3649540:3650074 [0] NCCL INFO Using non-device net plugin version 0
gn26:3649540:3650074 [0] NCCL INFO Using network Socket
gn26:3649543:3650075 [3] NCCL INFO Failed to open libibverbs.so[.1]
gn26:3649543:3650075 [3] NCCL INFO NET/Socket : Using [0]ib0:10.210.4.10<0>
gn26:3649543:3650075 [3] NCCL INFO Using non-device net plugin version 0
gn26:3649543:3650075 [3] NCCL INFO Using network Socket
gn26:3649541:3650077 [1] NCCL INFO Failed to open libibverbs.so[.1]
gn26:3649541:3650077 [1] NCCL INFO NET/Socket : Using [0]ib0:10.210.4.10<0>
gn26:3649541:3650077 [1] NCCL INFO Using non-device net plugin version 0
gn26:3649541:3650077 [1] NCCL INFO Using network Socket
gn26:3649540:3650074 [0] NCCL INFO ncclCommInitRank comm 0x5609c2183850 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 3000 commId 0x60747fb73e14cebf - Init START
gn26:3649541:3650077 [1] NCCL INFO ncclCommInitRank comm 0x55686fb0a580 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 44000 commId 0x60747fb73e14cebf - Init START
gn26:3649542:3650076 [2] NCCL INFO ncclCommInitRank comm 0x55f63330fb20 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 84000 commId 0x60747fb73e14cebf - Init START
gn26:3649543:3650075 [3] NCCL INFO ncclCommInitRank comm 0x556d5626f9a0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId c4000 commId 0x60747fb73e14cebf - Init START
gn26:3649540:3650074 [0] NCCL INFO NVLS multicast support is not available on dev 0
gn26:3649541:3650077 [1] NCCL INFO NVLS multicast support is not available on dev 1
gn26:3649543:3650075 [3] NCCL INFO NVLS multicast support is not available on dev 3
gn26:3649542:3650076 [2] NCCL INFO Setting affinity for GPU 2 to 010000,00000000,00000000,00000000,00010000,00000000,00000000,00000000
gn26:3649542:3650076 [2] NCCL INFO NVLS multicast support is not available on dev 2
gn26:3649543:3650075 [3] NCCL INFO comm 0x556d5626f9a0 rank 7 nRanks 8 nNodes 2 localRanks 4 localRank 3 MNNVL 0
gn26:3649543:3650075 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
gn26:3649543:3650075 [3] NCCL INFO P2P Chunksize set to 131072
gn26:3649540:3650074 [0] NCCL INFO comm 0x5609c2183850 rank 4 nRanks 8 nNodes 2 localRanks 4 localRank 0 MNNVL 0
gn26:3649540:3650074 [0] NCCL INFO Trees [0] 5/-1/-1->4->0 [1] 5/0/-1->4->-1
gn26:3649540:3650074 [0] NCCL INFO P2P Chunksize set to 131072
gn26:3649541:3650077 [1] NCCL INFO comm 0x55686fb0a580 rank 5 nRanks 8 nNodes 2 localRanks 4 localRank 1 MNNVL 0
gn26:3649541:3650077 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
gn26:3649541:3650077 [1] NCCL INFO P2P Chunksize set to 131072
gn26:3649542:3650076 [2] NCCL INFO comm 0x55f63330fb20 rank 6 nRanks 8 nNodes 2 localRanks 4 localRank 2 MNNVL 0
gn26:3649542:3650076 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
gn26:3649542:3650076 [2] NCCL INFO P2P Chunksize set to 131072
gn26:3649540:3650074 [0] NCCL INFO Channel 00/0 : 3[3] -> 4[0] [receive] via NET/Socket/0
gn26:3649541:3650077 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gn26:3649543:3650075 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[0] [send] via NET/Socket/0
gn26:3649540:3650074 [0] NCCL INFO Channel 01/0 : 3[3] -> 4[0] [receive] via NET/Socket/0
gn26:3649540:3650074 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gn26:3649541:3650077 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gn26:3649542:3650076 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gn26:3649540:3650074 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gn26:3649543:3650075 [3] NCCL INFO Channel 01/0 : 7[3] -> 0[0] [send] via NET/Socket/0
gn26:3649542:3650076 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gn26:3649541:3650077 [1] NCCL INFO Connected all rings
gn26:3649540:3650074 [0] NCCL INFO Connected all rings
gn26:3649540:3650074 [0] NCCL INFO Channel 00/0 : 0[0] -> 4[0] [receive] via NET/Socket/0
gn26:3649541:3650077 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gn26:3649541:3650077 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gn26:3649540:3650074 [0] NCCL INFO Channel 01/0 : 0[0] -> 4[0] [receive] via NET/Socket/0
gn26:3649540:3650074 [0] NCCL INFO Channel 00/0 : 4[0] -> 0[0] [send] via NET/Socket/0
gn26:3649542:3650076 [2] NCCL INFO Connected all rings
gn26:3649543:3650075 [3] NCCL INFO Connected all rings
gn26:3649543:3650075 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gn26:3649540:3650074 [0] NCCL INFO Channel 01/0 : 4[0] -> 0[0] [send] via NET/Socket/0
gn26:3649542:3650076 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gn26:3649543:3650075 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gn26:3649542:3650076 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gn26:3649543:3650075 [3] NCCL INFO Connected all trees
gn26:3649543:3650075 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn26:3649543:3650075 [3] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn26:3649540:3650074 [0] NCCL INFO Connected all trees
gn26:3649541:3650077 [1] NCCL INFO Connected all trees
gn26:3649540:3650074 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn26:3649541:3650077 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn26:3649540:3650074 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn26:3649541:3650077 [1] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn26:3649542:3650076 [2] NCCL INFO Connected all trees
gn26:3649542:3650076 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn26:3649542:3650076 [2] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn26:3649541:3650077 [1] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gn26:3649543:3650075 [3] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gn26:3649541:3650077 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gn26:3649543:3650075 [3] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gn26:3649541:3650077 [1] NCCL INFO ncclCommInitRank comm 0x55686fb0a580 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 44000 commId 0x60747fb73e14cebf - Init COMPLETE
gn26:3649543:3650075 [3] NCCL INFO ncclCommInitRank comm 0x556d5626f9a0 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId c4000 commId 0x60747fb73e14cebf - Init COMPLETE
gn26:3649542:3650076 [2] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gn26:3649542:3650076 [2] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gn26:3649542:3650076 [2] NCCL INFO ncclCommInitRank comm 0x55f63330fb20 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 84000 commId 0x60747fb73e14cebf - Init COMPLETE
gn26:3649540:3650074 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
gn26:3649540:3650074 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
gn26:3649540:3650074 [0] NCCL INFO ncclCommInitRank comm 0x5609c2183850 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 3000 commId 0x60747fb73e14cebf - Init COMPLETE
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [01:06<03:19, 66.61s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [01:06<03:19, 66.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [01:06<03:19, 66.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [01:06<03:19, 66.61s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:12<02:12, 66.48s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:12<02:12, 66.48s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:12<02:12, 66.48s/it]Loading checkpoint shards:  50%|█████     | 2/4 [02:12<02:12, 66.48s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:18<01:06, 66.01s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:18<01:06, 66.01s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:18<01:06, 66.01s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [03:18<01:06, 66.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.19s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.18s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.19s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.12s/it]Loading checkpoint shards: 100%|██████████| 4/4 [04:24<00:00, 66.19s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
-------------------- CHECKING GRADIENTS --------------------
Trainable parameters:
- model.embed_tokens.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.0.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.1.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.2.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.3.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.4.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.5.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.6.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.7.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.8.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.9.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.10.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
- model.layers.11.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
- model.layers.11.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.11.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(

- model.layers.12.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
- model.layers.12.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.12.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.13.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.14.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.15.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.16.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.17.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.18.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.19.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.20.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.21.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.22.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.23.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.24.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.25.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.26.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.27.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.28.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.29.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.30.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.31.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.32.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.33.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.34.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.35.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.36.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.37.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.38.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.39.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.40.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.self_attn.q_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.self_attn.k_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.self_attn.v_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.self_attn.o_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.mlp.gate_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.mlp.up_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.mlp.down_proj.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.input_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.post_attention_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.pre_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.layers.41.post_feedforward_layernorm.weight (shape: torch.Size([0]), numel: 0)
- model.norm.weight (shape: torch.Size([0]), numel: 0)
Total trainable parameters: 0
CRITICAL ERROR: NO TRAINABLE PARAMETERS FOUND!
------------------------------------------------------------
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Using LoRA and set up the model model
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 1/8564 [00:00<56:28,  2.53 examples/s]Extracting prompt in train dataset:   0%|          | 10/8564 [00:01<16:44,  8.51 examples/s]Extracting prompt in train dataset:   3%|▎         | 260/8564 [00:01<00:29, 282.87 examples/s]Extracting prompt in train dataset:   5%|▌         | 460/8564 [00:01<00:16, 499.65 examples/s]Extracting prompt in train dataset:   9%|▉         | 771/8564 [00:01<00:08, 912.51 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1050/8564 [00:01<00:06, 1149.05 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1344/8564 [00:01<00:05, 1363.73 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1546/8564 [00:01<00:04, 1495.68 examples/s]Extracting prompt in train dataset:  21%|██▏       | 1820/8564 [00:02<00:04, 1566.32 examples/s]Extracting prompt in train dataset:  24%|██▎       | 2030/8564 [00:02<00:03, 1677.91 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2301/8564 [00:02<00:03, 1889.37 examples/s]Extracting prompt in train dataset:  31%|███       | 2665/8564 [00:02<00:02, 2044.71 examples/s]Extracting prompt in train dataset:  35%|███▍      | 2970/8564 [00:02<00:02, 2217.28 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3232/8564 [00:02<00:02, 2313.24 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3563/8564 [00:02<00:02, 2267.23 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3890/8564 [00:03<00:02, 2177.75 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4191/8564 [00:03<00:02, 2015.22 examples/s]Extracting prompt in train dataset:  51%|█████▏    | 4401/8564 [00:03<00:02, 2031.82 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4720/8564 [00:03<00:01, 2055.16 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 5046/8564 [00:03<00:01, 2335.08 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5400/8564 [00:03<00:01, 2337.39 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5737/8564 [00:03<00:01, 2074.59 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5980/8564 [00:04<00:01, 2094.14 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6240/8564 [00:04<00:01, 1976.22 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 6468/8564 [00:04<00:01, 1991.05 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6680/8564 [00:04<00:00, 2017.41 examples/s]Extracting prompt in train dataset:  80%|████████  | 6890/8564 [00:04<00:00, 2033.16 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 7242/8564 [00:04<00:00, 2047.52 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7449/8564 [00:04<00:00, 2038.15 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7660/8564 [00:04<00:00, 1977.59 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7950/8564 [00:05<00:00, 1510.42 examples/s]Extracting prompt in train dataset:  95%|█████████▌| 8164/8564 [00:05<00:00, 1619.23 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8391/8564 [00:05<00:00, 1761.28 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1498.61 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 69/8564 [00:00<00:14, 593.09 examples/s]Applying chat template to train dataset:   2%|▏         | 160/8564 [00:00<00:11, 729.95 examples/s]Applying chat template to train dataset:   3%|▎         | 276/8564 [00:00<00:09, 910.36 examples/s]Applying chat template to train dataset:   4%|▍         | 383/8564 [00:00<00:08, 970.24 examples/s]Applying chat template to train dataset:   6%|▌         | 529/8564 [00:00<00:08, 966.81 examples/s]Applying chat template to train dataset:   8%|▊         | 668/8564 [00:00<00:07, 1089.17 examples/s]Applying chat template to train dataset:  10%|▉         | 817/8564 [00:00<00:06, 1204.84 examples/s]Applying chat template to train dataset:  12%|█▏        | 992/8564 [00:00<00:05, 1364.98 examples/s]Applying chat template to train dataset:  14%|█▍        | 1198/8564 [00:00<00:04, 1570.67 examples/s]Applying chat template to train dataset:  16%|█▋        | 1410/8564 [00:01<00:05, 1305.31 examples/s]Applying chat template to train dataset:  18%|█▊        | 1576/8564 [00:01<00:05, 1240.26 examples/s]Applying chat template to train dataset:  20%|██        | 1741/8564 [00:01<00:05, 1141.82 examples/s]Applying chat template to train dataset:  22%|██▏       | 1917/8564 [00:01<00:05, 1117.19 examples/s]Applying chat template to train dataset:  25%|██▍       | 2100/8564 [00:01<00:05, 1115.62 examples/s]Applying chat template to train dataset:  26%|██▋       | 2261/8564 [00:02<00:05, 1089.00 examples/s]Applying chat template to train dataset:  28%|██▊       | 2431/8564 [00:02<00:05, 1091.37 examples/s]Applying chat template to train dataset:  30%|███       | 2597/8564 [00:02<00:05, 1089.43 examples/s]Applying chat template to train dataset:  32%|███▏      | 2730/8564 [00:02<00:05, 1114.88 examples/s]Applying chat template to train dataset:  34%|███▍      | 2896/8564 [00:02<00:05, 1063.40 examples/s]Applying chat template to train dataset:  35%|███▌      | 3010/8564 [00:02<00:05, 1077.65 examples/s]Applying chat template to train dataset:  37%|███▋      | 3150/8564 [00:02<00:06, 811.18 examples/s] Applying chat template to train dataset:  39%|███▊      | 3301/8564 [00:03<00:06, 853.40 examples/s]Applying chat template to train dataset:  40%|███▉      | 3417/8564 [00:03<00:05, 914.01 examples/s]Applying chat template to train dataset:  41%|████      | 3517/8564 [00:03<00:05, 932.19 examples/s]Applying chat template to train dataset:  42%|████▏     | 3620/8564 [00:03<00:05, 951.11 examples/s]Applying chat template to train dataset:  44%|████▎     | 3728/8564 [00:03<00:05, 955.04 examples/s]Applying chat template to train dataset:  45%|████▍     | 3832/8564 [00:03<00:05, 923.62 examples/s]Applying chat template to train dataset:  46%|████▌     | 3950/8564 [00:03<00:05, 873.91 examples/s]Applying chat template to train dataset:  47%|████▋     | 4050/8564 [00:03<00:05, 894.33 examples/s]Applying chat template to train dataset:  49%|████▊     | 4164/8564 [00:04<00:04, 955.96 examples/s]Applying chat template to train dataset:  50%|█████     | 4294/8564 [00:04<00:04, 921.55 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4418/8564 [00:04<00:04, 936.51 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4528/8564 [00:04<00:04, 912.72 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4640/8564 [00:04<00:04, 946.70 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4751/8564 [00:04<00:03, 953.81 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4868/8564 [00:04<00:03, 974.68 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4980/8564 [00:04<00:03, 987.02 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5103/8564 [00:04<00:03, 1041.00 examples/s]Applying chat template to train dataset:  61%|██████    | 5228/8564 [00:05<00:03, 1078.85 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5348/8564 [00:05<00:02, 1105.43 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5463/8564 [00:05<00:02, 1094.19 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5581/8564 [00:05<00:02, 1112.44 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5705/8564 [00:05<00:02, 1119.98 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5840/8564 [00:05<00:02, 1175.49 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5963/8564 [00:05<00:02, 1183.16 examples/s]Applying chat template to train dataset:  71%|███████   | 6097/8564 [00:05<00:02, 1057.06 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6214/8564 [00:05<00:02, 1079.05 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6366/8564 [00:06<00:01, 1176.46 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6506/8564 [00:06<00:01, 1205.70 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6670/8564 [00:06<00:01, 1155.15 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6796/8564 [00:06<00:01, 1130.69 examples/s]Applying chat template to train dataset:  81%|████████  | 6918/8564 [00:06<00:01, 1116.61 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7092/8564 [00:06<00:01, 1081.70 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7210/8564 [00:06<00:01, 1096.09 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7374/8564 [00:06<00:00, 1192.75 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7556/8564 [00:07<00:00, 1354.71 examples/s]Applying chat template to train dataset:  90%|█████████ | 7734/8564 [00:07<00:00, 1285.77 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7868/8564 [00:07<00:00, 791.89 examples/s] Applying chat template to train dataset:  93%|█████████▎| 7990/8564 [00:07<00:00, 836.31 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8093/8564 [00:07<00:00, 869.03 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8218/8564 [00:07<00:00, 948.17 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8360/8564 [00:07<00:00, 1059.78 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8516/8564 [00:08<00:00, 1006.08 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:08<00:00, 1043.91 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 24/8564 [00:00<00:37, 225.71 examples/s]Tokenizing train dataset:   1%|          | 50/8564 [00:00<00:53, 160.15 examples/s]Tokenizing train dataset:   1%|          | 69/8564 [00:00<00:59, 142.42 examples/s]Tokenizing train dataset:   1%|          | 87/8564 [00:00<01:14, 113.47 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:00<01:24, 100.34 examples/s]Tokenizing train dataset:   1%|▏         | 114/8564 [00:01<01:32, 91.11 examples/s] Tokenizing train dataset:   1%|▏         | 128/8564 [00:01<01:39, 84.46 examples/s]Tokenizing train dataset:   2%|▏         | 144/8564 [00:01<01:25, 98.08 examples/s]Tokenizing train dataset:   2%|▏         | 156/8564 [00:01<01:25, 98.49 examples/s]Tokenizing train dataset:   2%|▏         | 171/8564 [00:01<01:29, 93.89 examples/s]Tokenizing train dataset:   2%|▏         | 186/8564 [00:01<01:21, 102.40 examples/s]Tokenizing train dataset:   2%|▏         | 198/8564 [00:01<01:20, 103.98 examples/s]Tokenizing train dataset:   2%|▏         | 210/8564 [00:01<01:20, 103.57 examples/s]Tokenizing train dataset:   3%|▎         | 224/8564 [00:02<01:19, 105.40 examples/s]Tokenizing train dataset:   3%|▎         | 239/8564 [00:02<01:12, 115.22 examples/s]Tokenizing train dataset:   3%|▎         | 256/8564 [00:02<01:04, 128.91 examples/s]Tokenizing train dataset:   3%|▎         | 273/8564 [00:02<01:00, 136.66 examples/s]Tokenizing train dataset:   3%|▎         | 291/8564 [00:02<01:05, 125.40 examples/s]Tokenizing train dataset:   4%|▎         | 310/8564 [00:02<01:09, 119.50 examples/s]Tokenizing train dataset:   4%|▍         | 328/8564 [00:02<01:09, 118.40 examples/s]Tokenizing train dataset:   4%|▍         | 348/8564 [00:03<01:09, 118.72 examples/s]Tokenizing train dataset:   4%|▍         | 361/8564 [00:03<01:10, 115.98 examples/s]Tokenizing train dataset:   4%|▍         | 375/8564 [00:03<01:08, 119.22 examples/s]Tokenizing train dataset:   5%|▍         | 389/8564 [00:03<01:07, 121.45 examples/s]Tokenizing train dataset:   5%|▍         | 406/8564 [00:03<01:17, 105.18 examples/s]Tokenizing train dataset:   5%|▍         | 421/8564 [00:03<01:12, 112.69 examples/s]Tokenizing train dataset:   5%|▌         | 437/8564 [00:03<01:17, 104.66 examples/s]Tokenizing train dataset:   5%|▌         | 454/8564 [00:04<01:10, 115.12 examples/s]Tokenizing train dataset:   5%|▌         | 467/8564 [00:04<01:09, 115.87 examples/s]Tokenizing train dataset:   6%|▌         | 480/8564 [00:04<01:11, 112.44 examples/s]Tokenizing train dataset:   6%|▌         | 492/8564 [00:04<01:12, 111.14 examples/s]Tokenizing train dataset:   6%|▌         | 506/8564 [00:04<01:09, 115.98 examples/s]Tokenizing train dataset:   6%|▌         | 520/8564 [00:04<01:26, 92.65 examples/s] Tokenizing train dataset:   6%|▌         | 533/8564 [00:04<01:21, 98.07 examples/s]Tokenizing train dataset:   6%|▋         | 545/8564 [00:04<01:23, 95.57 examples/s]Tokenizing train dataset:   6%|▋         | 556/8564 [00:05<01:21, 98.38 examples/s]Tokenizing train dataset:   7%|▋         | 578/8564 [00:05<01:03, 125.27 examples/s]Tokenizing train dataset:   7%|▋         | 597/8564 [00:05<00:57, 139.04 examples/s]Tokenizing train dataset:   7%|▋         | 615/8564 [00:05<01:02, 126.61 examples/s]Tokenizing train dataset:   7%|▋         | 630/8564 [00:05<01:00, 130.42 examples/s]Tokenizing train dataset:   8%|▊         | 645/8564 [00:05<01:07, 117.49 examples/s]Tokenizing train dataset:   8%|▊         | 659/8564 [00:05<01:08, 116.14 examples/s]Tokenizing train dataset:   8%|▊         | 673/8564 [00:06<01:15, 104.32 examples/s]Tokenizing train dataset:   8%|▊         | 686/8564 [00:06<01:16, 103.23 examples/s]Tokenizing train dataset:   8%|▊         | 700/8564 [00:06<01:23, 93.68 examples/s] Tokenizing train dataset:   8%|▊         | 712/8564 [00:06<01:21, 95.87 examples/s]Tokenizing train dataset:   8%|▊         | 726/8564 [00:06<01:14, 105.24 examples/s]Tokenizing train dataset:   9%|▊         | 740/8564 [00:06<01:09, 112.68 examples/s]Tokenizing train dataset:   9%|▉         | 756/8564 [00:06<01:06, 118.02 examples/s]Tokenizing train dataset:   9%|▉         | 772/8564 [00:06<01:12, 107.87 examples/s]Tokenizing train dataset:   9%|▉         | 785/8564 [00:07<01:20, 96.32 examples/s] Tokenizing train dataset:   9%|▉         | 800/8564 [00:07<01:23, 92.64 examples/s]Tokenizing train dataset:   9%|▉         | 812/8564 [00:07<01:18, 98.20 examples/s]Tokenizing train dataset:  10%|▉         | 824/8564 [00:07<01:19, 97.50 examples/s]Tokenizing train dataset:  10%|▉         | 838/8564 [00:07<01:12, 106.67 examples/s]Tokenizing train dataset:  10%|▉         | 851/8564 [00:07<01:18, 98.22 examples/s] Tokenizing train dataset:  10%|█         | 862/8564 [00:07<01:17, 98.91 examples/s]Tokenizing train dataset:  10%|█         | 873/8564 [00:08<01:19, 96.29 examples/s]Tokenizing train dataset:  10%|█         | 890/8564 [00:08<01:09, 110.95 examples/s]Tokenizing train dataset:  11%|█         | 907/8564 [00:08<01:02, 122.70 examples/s]Tokenizing train dataset:  11%|█         | 921/8564 [00:08<01:11, 107.46 examples/s]Tokenizing train dataset:  11%|█         | 937/8564 [00:08<01:12, 105.86 examples/s]Tokenizing train dataset:  11%|█         | 951/8564 [00:08<01:10, 108.67 examples/s]Tokenizing train dataset:  11%|█▏        | 970/8564 [00:08<01:11, 106.86 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:09<01:18, 97.13 examples/s] Tokenizing train dataset:  12%|█▏        | 996/8564 [00:09<01:22, 91.52 examples/s]Tokenizing train dataset:  12%|█▏        | 1009/8564 [00:09<01:22, 91.70 examples/s]Tokenizing train dataset:  12%|█▏        | 1020/8564 [00:09<01:19, 94.47 examples/s]Tokenizing train dataset:  12%|█▏        | 1035/8564 [00:09<01:23, 90.41 examples/s]Tokenizing train dataset:  12%|█▏        | 1046/8564 [00:09<01:22, 90.80 examples/s]Tokenizing train dataset:  12%|█▏        | 1061/8564 [00:09<01:15, 99.29 examples/s]Tokenizing train dataset:  13%|█▎        | 1079/8564 [00:10<01:08, 109.97 examples/s]Tokenizing train dataset:  13%|█▎        | 1094/8564 [00:10<01:08, 109.48 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:10<01:09, 106.67 examples/s]Tokenizing train dataset:  13%|█▎        | 1121/8564 [00:10<01:11, 103.76 examples/s]Tokenizing train dataset:  13%|█▎        | 1132/8564 [00:10<01:14, 99.31 examples/s] Tokenizing train dataset:  13%|█▎        | 1143/8564 [00:10<01:13, 100.73 examples/s]Tokenizing train dataset:  13%|█▎        | 1154/8564 [00:10<01:14, 99.95 examples/s] Tokenizing train dataset:  14%|█▎        | 1165/8564 [00:10<01:15, 98.11 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:10<01:11, 103.51 examples/s]Tokenizing train dataset:  14%|█▍        | 1190/8564 [00:11<01:09, 105.57 examples/s]Tokenizing train dataset:  14%|█▍        | 1201/8564 [00:11<01:09, 106.60 examples/s]Tokenizing train dataset:  14%|█▍        | 1212/8564 [00:11<01:10, 105.01 examples/s]Tokenizing train dataset:  14%|█▍        | 1225/8564 [00:11<01:07, 108.17 examples/s]Tokenizing train dataset:  14%|█▍        | 1240/8564 [00:11<01:01, 118.51 examples/s]Tokenizing train dataset:  15%|█▍        | 1260/8564 [00:11<00:59, 121.77 examples/s]Tokenizing train dataset:  15%|█▍        | 1277/8564 [00:11<01:02, 116.59 examples/s]Tokenizing train dataset:  15%|█▌        | 1299/8564 [00:12<01:00, 120.94 examples/s]Tokenizing train dataset:  15%|█▌        | 1314/8564 [00:12<00:57, 125.10 examples/s]Tokenizing train dataset:  15%|█▌        | 1327/8564 [00:12<00:59, 121.89 examples/s]Tokenizing train dataset:  16%|█▌        | 1340/8564 [00:12<00:59, 122.30 examples/s]Tokenizing train dataset:  16%|█▌        | 1354/8564 [00:12<01:06, 108.62 examples/s]Tokenizing train dataset:  16%|█▌        | 1369/8564 [00:12<01:13, 98.08 examples/s] Tokenizing train dataset:  16%|█▌        | 1389/8564 [00:12<01:08, 105.31 examples/s]Tokenizing train dataset:  16%|█▋        | 1400/8564 [00:12<01:08, 105.27 examples/s]Tokenizing train dataset:  16%|█▋        | 1412/8564 [00:13<01:06, 108.22 examples/s]Tokenizing train dataset:  17%|█▋        | 1426/8564 [00:13<01:02, 113.71 examples/s]Tokenizing train dataset:  17%|█▋        | 1438/8564 [00:13<01:04, 110.32 examples/s]Tokenizing train dataset:  17%|█▋        | 1455/8564 [00:13<01:05, 107.93 examples/s]Tokenizing train dataset:  17%|█▋        | 1471/8564 [00:13<01:09, 102.59 examples/s]Tokenizing train dataset:  17%|█▋        | 1485/8564 [00:13<01:12, 98.29 examples/s] Tokenizing train dataset:  17%|█▋        | 1496/8564 [00:13<01:12, 97.45 examples/s]Tokenizing train dataset:  18%|█▊        | 1506/8564 [00:14<01:14, 94.81 examples/s]Tokenizing train dataset:  18%|█▊        | 1520/8564 [00:14<01:16, 92.40 examples/s]Tokenizing train dataset:  18%|█▊        | 1537/8564 [00:14<01:06, 106.03 examples/s]Tokenizing train dataset:  18%|█▊        | 1549/8564 [00:14<01:08, 102.79 examples/s]Tokenizing train dataset:  18%|█▊        | 1560/8564 [00:14<01:08, 102.85 examples/s]Tokenizing train dataset:  18%|█▊        | 1571/8564 [00:14<01:07, 104.05 examples/s]Tokenizing train dataset:  19%|█▊        | 1587/8564 [00:14<01:07, 103.17 examples/s]Tokenizing train dataset:  19%|█▊        | 1600/8564 [00:14<01:05, 106.51 examples/s]Tokenizing train dataset:  19%|█▉        | 1611/8564 [00:14<01:05, 106.60 examples/s]Tokenizing train dataset:  19%|█▉        | 1626/8564 [00:15<01:02, 110.83 examples/s]Tokenizing train dataset:  19%|█▉        | 1640/8564 [00:15<00:59, 116.61 examples/s]Tokenizing train dataset:  19%|█▉        | 1654/8564 [00:15<01:00, 113.30 examples/s]Tokenizing train dataset:  19%|█▉        | 1667/8564 [00:15<00:59, 116.20 examples/s]Tokenizing train dataset:  20%|█▉        | 1686/8564 [00:15<01:01, 112.31 examples/s]Tokenizing train dataset:  20%|█▉        | 1707/8564 [00:15<00:53, 127.64 examples/s]Tokenizing train dataset:  20%|██        | 1724/8564 [00:15<00:58, 117.74 examples/s]Tokenizing train dataset:  20%|██        | 1743/8564 [00:16<00:59, 115.31 examples/s]Tokenizing train dataset:  21%|██        | 1759/8564 [00:16<00:57, 118.62 examples/s]Tokenizing train dataset:  21%|██        | 1772/8564 [00:16<00:57, 118.73 examples/s]Tokenizing train dataset:  21%|██        | 1791/8564 [00:16<00:59, 113.85 examples/s]Tokenizing train dataset:  21%|██        | 1810/8564 [00:16<00:51, 130.65 examples/s]Tokenizing train dataset:  21%|██▏       | 1827/8564 [00:16<00:58, 115.47 examples/s]Tokenizing train dataset:  21%|██▏       | 1840/8564 [00:16<01:02, 107.76 examples/s]Tokenizing train dataset:  22%|██▏       | 1853/8564 [00:17<01:09, 96.69 examples/s] Tokenizing train dataset:  22%|██▏       | 1864/8564 [00:17<01:07, 99.12 examples/s]Tokenizing train dataset:  22%|██▏       | 1880/8564 [00:17<01:08, 97.18 examples/s]Tokenizing train dataset:  22%|██▏       | 1891/8564 [00:17<01:07, 98.99 examples/s]Tokenizing train dataset:  22%|██▏       | 1912/8564 [00:17<00:54, 122.83 examples/s]Tokenizing train dataset:  23%|██▎       | 1927/8564 [00:17<00:51, 127.69 examples/s]Tokenizing train dataset:  23%|██▎       | 1945/8564 [00:17<00:56, 118.03 examples/s]Tokenizing train dataset:  23%|██▎       | 1965/8564 [00:18<00:55, 119.00 examples/s]Tokenizing train dataset:  23%|██▎       | 1983/8564 [00:18<00:55, 118.05 examples/s]Tokenizing train dataset:  23%|██▎       | 1999/8564 [00:18<00:54, 121.22 examples/s]Tokenizing train dataset:  24%|██▎       | 2015/8564 [00:18<00:51, 127.95 examples/s]Tokenizing train dataset:  24%|██▎       | 2030/8564 [00:18<00:51, 126.34 examples/s]Tokenizing train dataset:  24%|██▍       | 2043/8564 [00:18<00:51, 126.21 examples/s]Tokenizing train dataset:  24%|██▍       | 2056/8564 [00:18<00:55, 118.02 examples/s]Tokenizing train dataset:  24%|██▍       | 2072/8564 [00:18<00:59, 109.48 examples/s]Tokenizing train dataset:  24%|██▍       | 2085/8564 [00:19<00:58, 110.38 examples/s]Tokenizing train dataset:  24%|██▍       | 2098/8564 [00:19<00:57, 112.04 examples/s]Tokenizing train dataset:  25%|██▍       | 2113/8564 [00:19<00:53, 121.16 examples/s]Tokenizing train dataset:  25%|██▍       | 2127/8564 [00:19<00:52, 123.58 examples/s]Tokenizing train dataset:  25%|██▍       | 2140/8564 [00:19<00:52, 123.06 examples/s]Tokenizing train dataset:  25%|██▌       | 2154/8564 [00:19<00:50, 126.60 examples/s]Tokenizing train dataset:  25%|██▌       | 2173/8564 [00:19<00:54, 116.52 examples/s]Tokenizing train dataset:  26%|██▌       | 2188/8564 [00:19<00:53, 119.99 examples/s]Tokenizing train dataset:  26%|██▌       | 2204/8564 [00:20<00:49, 129.25 examples/s]Tokenizing train dataset:  26%|██▌       | 2220/8564 [00:20<00:47, 134.34 examples/s]Tokenizing train dataset:  26%|██▌       | 2237/8564 [00:20<00:46, 136.03 examples/s]Tokenizing train dataset:  26%|██▋       | 2252/8564 [00:20<00:46, 134.55 examples/s]Tokenizing train dataset:  27%|██▋       | 2275/8564 [00:20<00:40, 154.17 examples/s]Tokenizing train dataset:  27%|██▋       | 2291/8564 [00:20<00:43, 144.57 examples/s]Tokenizing train dataset:  27%|██▋       | 2307/8564 [00:20<00:44, 141.35 examples/s]Tokenizing train dataset:  27%|██▋       | 2328/8564 [00:20<00:48, 129.58 examples/s]Tokenizing train dataset:  27%|██▋       | 2347/8564 [00:21<00:48, 127.09 examples/s]Tokenizing train dataset:  28%|██▊       | 2365/8564 [00:21<00:51, 119.39 examples/s]Tokenizing train dataset:  28%|██▊       | 2380/8564 [00:21<00:49, 124.70 examples/s]Tokenizing train dataset:  28%|██▊       | 2398/8564 [00:21<00:45, 137.01 examples/s]Tokenizing train dataset:  28%|██▊       | 2420/8564 [00:21<00:46, 133.51 examples/s]Tokenizing train dataset:  28%|██▊       | 2435/8564 [00:21<00:53, 113.82 examples/s]Tokenizing train dataset:  29%|██▊       | 2448/8564 [00:21<00:55, 111.18 examples/s]Tokenizing train dataset:  29%|██▊       | 2462/8564 [00:22<00:52, 117.19 examples/s]Tokenizing train dataset:  29%|██▉       | 2476/8564 [00:22<00:54, 111.57 examples/s]Tokenizing train dataset:  29%|██▉       | 2490/8564 [00:22<00:54, 112.13 examples/s]Tokenizing train dataset:  29%|██▉       | 2502/8564 [00:22<00:54, 111.77 examples/s]Tokenizing train dataset:  29%|██▉       | 2521/8564 [00:22<00:49, 122.69 examples/s]Tokenizing train dataset:  30%|██▉       | 2539/8564 [00:22<00:46, 130.21 examples/s]Tokenizing train dataset:  30%|██▉       | 2553/8564 [00:22<00:46, 129.70 examples/s]Tokenizing train dataset:  30%|███       | 2570/8564 [00:22<00:44, 135.01 examples/s]Tokenizing train dataset:  30%|███       | 2584/8564 [00:23<00:46, 129.67 examples/s]Tokenizing train dataset:  30%|███       | 2603/8564 [00:23<00:48, 123.15 examples/s]Tokenizing train dataset:  31%|███       | 2617/8564 [00:23<00:48, 123.87 examples/s]Tokenizing train dataset:  31%|███       | 2630/8564 [00:23<00:55, 107.51 examples/s]Tokenizing train dataset:  31%|███       | 2645/8564 [00:23<00:54, 108.28 examples/s]Tokenizing train dataset:  31%|███       | 2662/8564 [00:23<00:49, 119.02 examples/s]Tokenizing train dataset:  31%|███▏      | 2680/8564 [00:23<00:45, 128.96 examples/s]Tokenizing train dataset:  31%|███▏      | 2694/8564 [00:23<00:45, 128.20 examples/s]Tokenizing train dataset:  32%|███▏      | 2710/8564 [00:24<00:45, 129.71 examples/s]Tokenizing train dataset:  32%|███▏      | 2729/8564 [00:24<00:47, 123.99 examples/s]Tokenizing train dataset:  32%|███▏      | 2748/8564 [00:24<00:48, 119.63 examples/s]Tokenizing train dataset:  32%|███▏      | 2768/8564 [00:24<00:47, 121.39 examples/s]Tokenizing train dataset:  32%|███▏      | 2783/8564 [00:24<00:45, 126.00 examples/s]Tokenizing train dataset:  33%|███▎      | 2798/8564 [00:24<00:45, 127.67 examples/s]Tokenizing train dataset:  33%|███▎      | 2812/8564 [00:24<00:45, 125.08 examples/s]Tokenizing train dataset:  33%|███▎      | 2827/8564 [00:25<00:44, 128.49 examples/s]Tokenizing train dataset:  33%|███▎      | 2840/8564 [00:25<00:47, 121.16 examples/s]Tokenizing train dataset:  33%|███▎      | 2856/8564 [00:25<00:51, 111.40 examples/s]Tokenizing train dataset:  34%|███▎      | 2869/8564 [00:25<00:51, 110.77 examples/s]Tokenizing train dataset:  34%|███▎      | 2883/8564 [00:25<00:49, 113.68 examples/s]Tokenizing train dataset:  34%|███▍      | 2900/8564 [00:25<00:44, 126.43 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:25<00:40, 137.84 examples/s]Tokenizing train dataset:  34%|███▍      | 2940/8564 [00:25<00:42, 131.13 examples/s]Tokenizing train dataset:  35%|███▍      | 2960/8564 [00:26<00:38, 145.74 examples/s]Tokenizing train dataset:  35%|███▍      | 2981/8564 [00:26<00:36, 154.54 examples/s]Tokenizing train dataset:  35%|███▌      | 2998/8564 [00:26<00:36, 150.75 examples/s]Tokenizing train dataset:  35%|███▌      | 3014/8564 [00:26<00:37, 148.27 examples/s]Tokenizing train dataset:  35%|███▌      | 3032/8564 [00:26<00:41, 132.84 examples/s]Tokenizing train dataset:  36%|███▌      | 3050/8564 [00:26<00:45, 120.45 examples/s]Tokenizing train dataset:  36%|███▌      | 3070/8564 [00:26<00:46, 116.96 examples/s]Tokenizing train dataset:  36%|███▌      | 3086/8564 [00:27<00:45, 119.98 examples/s]Tokenizing train dataset:  36%|███▌      | 3100/8564 [00:27<00:46, 117.24 examples/s]Tokenizing train dataset:  36%|███▋      | 3117/8564 [00:27<00:45, 120.14 examples/s]Tokenizing train dataset:  37%|███▋      | 3130/8564 [00:27<00:44, 121.25 examples/s]Tokenizing train dataset:  37%|███▋      | 3145/8564 [00:27<00:42, 128.07 examples/s]Tokenizing train dataset:  37%|███▋      | 3160/8564 [00:27<00:43, 124.64 examples/s]Tokenizing train dataset:  37%|███▋      | 3178/8564 [00:27<00:44, 120.17 examples/s]Tokenizing train dataset:  37%|███▋      | 3199/8564 [00:27<00:43, 122.71 examples/s]Tokenizing train dataset:  38%|███▊      | 3215/8564 [00:28<00:42, 127.20 examples/s]Tokenizing train dataset:  38%|███▊      | 3228/8564 [00:28<00:41, 127.12 examples/s]Tokenizing train dataset:  38%|███▊      | 3246/8564 [00:28<00:39, 133.71 examples/s]Tokenizing train dataset:  38%|███▊      | 3262/8564 [00:28<00:38, 138.56 examples/s]Tokenizing train dataset:  38%|███▊      | 3280/8564 [00:28<00:41, 126.47 examples/s]Tokenizing train dataset:  38%|███▊      | 3294/8564 [00:28<00:42, 124.49 examples/s]Tokenizing train dataset:  39%|███▊      | 3308/8564 [00:28<00:42, 123.97 examples/s]Tokenizing train dataset:  39%|███▉      | 3324/8564 [00:28<00:47, 109.33 examples/s]Tokenizing train dataset:  39%|███▉      | 3341/8564 [00:29<00:43, 121.36 examples/s]Tokenizing train dataset:  39%|███▉      | 3355/8564 [00:29<00:41, 124.18 examples/s]Tokenizing train dataset:  39%|███▉      | 3370/8564 [00:29<00:40, 128.08 examples/s]Tokenizing train dataset:  40%|███▉      | 3387/8564 [00:29<00:37, 138.68 examples/s]Tokenizing train dataset:  40%|███▉      | 3405/8564 [00:29<00:35, 147.39 examples/s]Tokenizing train dataset:  40%|███▉      | 3423/8564 [00:29<00:39, 130.39 examples/s]Tokenizing train dataset:  40%|████      | 3439/8564 [00:29<00:38, 132.44 examples/s]Tokenizing train dataset:  40%|████      | 3459/8564 [00:29<00:39, 129.22 examples/s]Tokenizing train dataset:  41%|████      | 3477/8564 [00:30<00:40, 124.51 examples/s]Tokenizing train dataset:  41%|████      | 3494/8564 [00:30<00:38, 132.70 examples/s]Tokenizing train dataset:  41%|████      | 3513/8564 [00:30<00:35, 142.57 examples/s]Tokenizing train dataset:  41%|████      | 3529/8564 [00:30<00:35, 142.19 examples/s]Tokenizing train dataset:  41%|████▏     | 3545/8564 [00:30<00:39, 125.85 examples/s]Tokenizing train dataset:  42%|████▏     | 3560/8564 [00:30<00:46, 107.03 examples/s]Tokenizing train dataset:  42%|████▏     | 3572/8564 [00:30<00:47, 105.32 examples/s]Tokenizing train dataset:  42%|████▏     | 3587/8564 [00:31<00:46, 107.67 examples/s]Tokenizing train dataset:  42%|████▏     | 3603/8564 [00:31<00:48, 101.75 examples/s]Tokenizing train dataset:  42%|████▏     | 3618/8564 [00:31<00:46, 106.49 examples/s]Tokenizing train dataset:  42%|████▏     | 3633/8564 [00:31<00:42, 115.28 examples/s]Tokenizing train dataset:  43%|████▎     | 3652/8564 [00:31<00:43, 114.13 examples/s]Tokenizing train dataset:  43%|████▎     | 3664/8564 [00:31<00:43, 112.60 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:31<00:41, 117.07 examples/s]Tokenizing train dataset:  43%|████▎     | 3699/8564 [00:32<00:38, 127.65 examples/s]Tokenizing train dataset:  43%|████▎     | 3722/8564 [00:32<00:36, 131.63 examples/s]Tokenizing train dataset:  44%|████▎     | 3744/8564 [00:32<00:36, 132.18 examples/s]Tokenizing train dataset:  44%|████▍     | 3759/8564 [00:32<00:35, 135.07 examples/s]Tokenizing train dataset:  44%|████▍     | 3773/8564 [00:32<00:36, 129.69 examples/s]Tokenizing train dataset:  44%|████▍     | 3794/8564 [00:32<00:32, 145.78 examples/s]Tokenizing train dataset:  44%|████▍     | 3809/8564 [00:32<00:32, 144.12 examples/s]Tokenizing train dataset:  45%|████▍     | 3827/8564 [00:32<00:37, 125.73 examples/s]Tokenizing train dataset:  45%|████▍     | 3843/8564 [00:33<00:41, 114.14 examples/s]Tokenizing train dataset:  45%|████▌     | 3858/8564 [00:33<00:40, 116.14 examples/s]Tokenizing train dataset:  45%|████▌     | 3872/8564 [00:33<00:38, 121.09 examples/s]Tokenizing train dataset:  45%|████▌     | 3886/8564 [00:33<00:37, 124.51 examples/s]Tokenizing train dataset:  46%|████▌     | 3902/8564 [00:33<00:40, 115.35 examples/s]Tokenizing train dataset:  46%|████▌     | 3916/8564 [00:33<00:44, 104.19 examples/s]Tokenizing train dataset:  46%|████▌     | 3927/8564 [00:33<00:45, 102.32 examples/s]Tokenizing train dataset:  46%|████▌     | 3939/8564 [00:34<00:46, 98.74 examples/s] Tokenizing train dataset:  46%|████▌     | 3952/8564 [00:34<00:45, 101.16 examples/s]Tokenizing train dataset:  46%|████▋     | 3968/8564 [00:34<00:45, 100.60 examples/s]Tokenizing train dataset:  46%|████▋     | 3979/8564 [00:34<00:44, 101.91 examples/s]Tokenizing train dataset:  47%|████▋     | 3992/8564 [00:34<00:42, 107.64 examples/s]Tokenizing train dataset:  47%|████▋     | 4006/8564 [00:34<00:41, 109.08 examples/s]Tokenizing train dataset:  47%|████▋     | 4020/8564 [00:34<00:42, 106.69 examples/s]Tokenizing train dataset:  47%|████▋     | 4038/8564 [00:34<00:36, 124.62 examples/s]Tokenizing train dataset:  47%|████▋     | 4060/8564 [00:34<00:30, 146.58 examples/s]Tokenizing train dataset:  48%|████▊     | 4087/8564 [00:35<00:25, 175.72 examples/s]Tokenizing train dataset:  48%|████▊     | 4113/8564 [00:35<00:22, 194.55 examples/s]Tokenizing train dataset:  48%|████▊     | 4136/8564 [00:35<00:22, 196.61 examples/s]Tokenizing train dataset:  49%|████▊     | 4160/8564 [00:35<00:25, 175.07 examples/s]Tokenizing train dataset:  49%|████▉     | 4182/8564 [00:35<00:28, 155.26 examples/s]Tokenizing train dataset:  49%|████▉     | 4209/8564 [00:35<00:24, 180.06 examples/s]Tokenizing train dataset:  49%|████▉     | 4234/8564 [00:35<00:22, 188.59 examples/s]Tokenizing train dataset:  50%|████▉     | 4264/8564 [00:36<00:22, 189.27 examples/s]Tokenizing train dataset:  50%|█████     | 4290/8564 [00:36<00:21, 202.24 examples/s]Tokenizing train dataset:  50%|█████     | 4312/8564 [00:36<00:21, 194.19 examples/s]Tokenizing train dataset:  51%|█████     | 4334/8564 [00:36<00:26, 162.35 examples/s]Tokenizing train dataset:  51%|█████     | 4357/8564 [00:36<00:27, 151.82 examples/s]Tokenizing train dataset:  51%|█████     | 4376/8564 [00:36<00:29, 143.48 examples/s]Tokenizing train dataset:  51%|█████▏    | 4397/8564 [00:36<00:29, 141.16 examples/s]Tokenizing train dataset:  52%|█████▏    | 4412/8564 [00:37<00:34, 120.19 examples/s]Tokenizing train dataset:  52%|█████▏    | 4427/8564 [00:37<00:33, 125.17 examples/s]Tokenizing train dataset:  52%|█████▏    | 4449/8564 [00:37<00:31, 128.90 examples/s]Tokenizing train dataset:  52%|█████▏    | 4469/8564 [00:37<00:32, 126.15 examples/s]Tokenizing train dataset:  52%|█████▏    | 4487/8564 [00:37<00:34, 119.63 examples/s]Tokenizing train dataset:  53%|█████▎    | 4500/8564 [00:37<00:35, 114.92 examples/s]Tokenizing train dataset:  53%|█████▎    | 4518/8564 [00:38<00:35, 114.79 examples/s]Tokenizing train dataset:  53%|█████▎    | 4532/8564 [00:38<00:33, 120.16 examples/s]Tokenizing train dataset:  53%|█████▎    | 4552/8564 [00:38<00:30, 131.61 examples/s]Tokenizing train dataset:  53%|█████▎    | 4566/8564 [00:38<00:30, 130.86 examples/s]Tokenizing train dataset:  53%|█████▎    | 4581/8564 [00:38<00:34, 115.76 examples/s]Tokenizing train dataset:  54%|█████▎    | 4598/8564 [00:38<00:31, 126.75 examples/s]Tokenizing train dataset:  54%|█████▍    | 4617/8564 [00:38<00:33, 116.39 examples/s]Tokenizing train dataset:  54%|█████▍    | 4631/8564 [00:38<00:32, 119.89 examples/s]Tokenizing train dataset:  54%|█████▍    | 4648/8564 [00:39<00:34, 112.27 examples/s]Tokenizing train dataset:  54%|█████▍    | 4661/8564 [00:39<00:34, 111.85 examples/s]Tokenizing train dataset:  55%|█████▍    | 4679/8564 [00:39<00:34, 112.01 examples/s]Tokenizing train dataset:  55%|█████▍    | 4694/8564 [00:39<00:33, 115.90 examples/s]Tokenizing train dataset:  55%|█████▍    | 4709/8564 [00:39<00:32, 117.44 examples/s]Tokenizing train dataset:  55%|█████▌    | 4728/8564 [00:39<00:33, 114.39 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:39<00:34, 111.30 examples/s]Tokenizing train dataset:  56%|█████▌    | 4760/8564 [00:40<00:35, 106.23 examples/s]Tokenizing train dataset:  56%|█████▌    | 4773/8564 [00:40<00:38, 97.87 examples/s] Tokenizing train dataset:  56%|█████▌    | 4790/8564 [00:40<00:40, 93.98 examples/s]Tokenizing train dataset:  56%|█████▌    | 4809/8564 [00:40<00:34, 110.39 examples/s]Tokenizing train dataset:  56%|█████▋    | 4830/8564 [00:40<00:29, 126.98 examples/s]Tokenizing train dataset:  57%|█████▋    | 4855/8564 [00:40<00:23, 155.06 examples/s]Tokenizing train dataset:  57%|█████▋    | 4876/8564 [00:40<00:23, 155.91 examples/s]Tokenizing train dataset:  57%|█████▋    | 4903/8564 [00:41<00:19, 183.98 examples/s]Tokenizing train dataset:  58%|█████▊    | 4934/8564 [00:41<00:19, 190.22 examples/s]Tokenizing train dataset:  58%|█████▊    | 4956/8564 [00:41<00:18, 192.35 examples/s]Tokenizing train dataset:  58%|█████▊    | 4980/8564 [00:41<00:18, 196.70 examples/s]Tokenizing train dataset:  58%|█████▊    | 5002/8564 [00:41<00:18, 191.73 examples/s]Tokenizing train dataset:  59%|█████▊    | 5025/8564 [00:41<00:18, 196.29 examples/s]Tokenizing train dataset:  59%|█████▉    | 5047/8564 [00:41<00:18, 190.69 examples/s]Tokenizing train dataset:  59%|█████▉    | 5085/8564 [00:41<00:15, 230.60 examples/s]Tokenizing train dataset:  60%|█████▉    | 5115/8564 [00:42<00:16, 212.10 examples/s]Tokenizing train dataset:  60%|██████    | 5149/8564 [00:42<00:14, 239.29 examples/s]Tokenizing train dataset:  60%|██████    | 5180/8564 [00:42<00:13, 247.28 examples/s]Tokenizing train dataset:  61%|██████    | 5207/8564 [00:42<00:13, 245.86 examples/s]Tokenizing train dataset:  61%|██████    | 5233/8564 [00:42<00:13, 245.12 examples/s]Tokenizing train dataset:  61%|██████▏   | 5260/8564 [00:42<00:13, 240.20 examples/s]Tokenizing train dataset:  62%|██████▏   | 5286/8564 [00:42<00:13, 245.16 examples/s]Tokenizing train dataset:  62%|██████▏   | 5319/8564 [00:42<00:14, 224.99 examples/s]Tokenizing train dataset:  63%|██████▎   | 5359/8564 [00:43<00:14, 223.56 examples/s]Tokenizing train dataset:  63%|██████▎   | 5390/8564 [00:43<00:15, 211.39 examples/s]Tokenizing train dataset:  63%|██████▎   | 5423/8564 [00:43<00:14, 211.05 examples/s]Tokenizing train dataset:  64%|██████▎   | 5451/8564 [00:43<00:13, 223.80 examples/s]Tokenizing train dataset:  64%|██████▍   | 5495/8564 [00:43<00:14, 215.70 examples/s]Tokenizing train dataset:  65%|██████▍   | 5529/8564 [00:43<00:12, 240.65 examples/s]Tokenizing train dataset:  65%|██████▍   | 5560/8564 [00:44<00:15, 198.39 examples/s]Tokenizing train dataset:  65%|██████▌   | 5589/8564 [00:44<00:14, 207.90 examples/s]Tokenizing train dataset:  66%|██████▌   | 5616/8564 [00:44<00:13, 219.12 examples/s]Tokenizing train dataset:  66%|██████▌   | 5642/8564 [00:44<00:12, 227.01 examples/s]Tokenizing train dataset:  66%|██████▌   | 5668/8564 [00:44<00:12, 227.18 examples/s]Tokenizing train dataset:  67%|██████▋   | 5698/8564 [00:44<00:12, 237.56 examples/s]Tokenizing train dataset:  67%|██████▋   | 5724/8564 [00:44<00:12, 232.82 examples/s]Tokenizing train dataset:  67%|██████▋   | 5757/8564 [00:44<00:12, 224.77 examples/s]Tokenizing train dataset:  68%|██████▊   | 5784/8564 [00:45<00:12, 227.88 examples/s]Tokenizing train dataset:  68%|██████▊   | 5817/8564 [00:45<00:11, 248.82 examples/s]Tokenizing train dataset:  68%|██████▊   | 5853/8564 [00:45<00:11, 226.59 examples/s]Tokenizing train dataset:  69%|██████▊   | 5878/8564 [00:45<00:12, 218.67 examples/s]Tokenizing train dataset:  69%|██████▉   | 5918/8564 [00:45<00:11, 231.31 examples/s]Tokenizing train dataset:  69%|██████▉   | 5949/8564 [00:45<00:10, 241.49 examples/s]Tokenizing train dataset:  70%|██████▉   | 5976/8564 [00:45<00:10, 244.78 examples/s]Tokenizing train dataset:  70%|███████   | 6002/8564 [00:45<00:12, 204.89 examples/s]Tokenizing train dataset:  70%|███████   | 6031/8564 [00:46<00:12, 200.58 examples/s]Tokenizing train dataset:  71%|███████   | 6055/8564 [00:46<00:12, 209.07 examples/s]Tokenizing train dataset:  71%|███████   | 6082/8564 [00:46<00:12, 198.30 examples/s]Tokenizing train dataset:  71%|███████▏  | 6114/8564 [00:46<00:12, 200.76 examples/s]Tokenizing train dataset:  72%|███████▏  | 6143/8564 [00:46<00:10, 220.35 examples/s]Tokenizing train dataset:  72%|███████▏  | 6175/8564 [00:46<00:10, 230.66 examples/s]Tokenizing train dataset:  72%|███████▏  | 6202/8564 [00:46<00:09, 238.64 examples/s]Tokenizing train dataset:  73%|███████▎  | 6230/8564 [00:46<00:09, 248.74 examples/s]Tokenizing train dataset:  73%|███████▎  | 6269/8564 [00:47<00:09, 238.83 examples/s]Tokenizing train dataset:  74%|███████▎  | 6296/8564 [00:47<00:10, 211.07 examples/s]Tokenizing train dataset:  74%|███████▍  | 6322/8564 [00:47<00:10, 219.84 examples/s]Tokenizing train dataset:  74%|███████▍  | 6350/8564 [00:47<00:09, 232.42 examples/s]Tokenizing train dataset:  74%|███████▍  | 6377/8564 [00:47<00:09, 232.83 examples/s]Tokenizing train dataset:  75%|███████▍  | 6407/8564 [00:47<00:10, 215.24 examples/s]Tokenizing train dataset:  75%|███████▌  | 6430/8564 [00:47<00:10, 210.36 examples/s]Tokenizing train dataset:  75%|███████▌  | 6456/8564 [00:48<00:09, 222.04 examples/s]Tokenizing train dataset:  76%|███████▌  | 6490/8564 [00:48<00:09, 212.06 examples/s]Tokenizing train dataset:  76%|███████▌  | 6520/8564 [00:48<00:10, 202.07 examples/s]Tokenizing train dataset:  76%|███████▋  | 6546/8564 [00:48<00:09, 212.73 examples/s]Tokenizing train dataset:  77%|███████▋  | 6577/8564 [00:48<00:09, 200.83 examples/s]Tokenizing train dataset:  77%|███████▋  | 6604/8564 [00:48<00:10, 182.94 examples/s]Tokenizing train dataset:  77%|███████▋  | 6633/8564 [00:48<00:09, 199.25 examples/s]Tokenizing train dataset:  78%|███████▊  | 6663/8564 [00:49<00:09, 196.45 examples/s]Tokenizing train dataset:  78%|███████▊  | 6687/8564 [00:49<00:09, 201.30 examples/s]Tokenizing train dataset:  78%|███████▊  | 6716/8564 [00:49<00:08, 221.18 examples/s]Tokenizing train dataset:  79%|███████▉  | 6749/8564 [00:49<00:08, 213.68 examples/s]Tokenizing train dataset:  79%|███████▉  | 6780/8564 [00:49<00:08, 208.93 examples/s]Tokenizing train dataset:  79%|███████▉  | 6804/8564 [00:49<00:08, 215.87 examples/s]Tokenizing train dataset:  80%|███████▉  | 6834/8564 [00:49<00:08, 198.90 examples/s]Tokenizing train dataset:  80%|████████  | 6864/8564 [00:50<00:08, 197.97 examples/s]Tokenizing train dataset:  80%|████████  | 6885/8564 [00:50<00:09, 179.10 examples/s]Tokenizing train dataset:  81%|████████  | 6910/8564 [00:50<00:08, 193.38 examples/s]Tokenizing train dataset:  81%|████████  | 6940/8564 [00:50<00:07, 214.35 examples/s]Tokenizing train dataset:  81%|████████▏ | 6970/8564 [00:50<00:08, 193.04 examples/s]Tokenizing train dataset:  82%|████████▏ | 6994/8564 [00:50<00:08, 196.13 examples/s]Tokenizing train dataset:  82%|████████▏ | 7017/8564 [00:50<00:08, 179.59 examples/s]Tokenizing train dataset:  82%|████████▏ | 7043/8564 [00:51<00:07, 194.90 examples/s]Tokenizing train dataset:  83%|████████▎ | 7067/8564 [00:51<00:07, 204.93 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [00:51<00:07, 208.69 examples/s]Tokenizing train dataset:  83%|████████▎ | 7119/8564 [00:51<00:06, 225.28 examples/s]Tokenizing train dataset:  83%|████████▎ | 7144/8564 [00:51<00:06, 223.07 examples/s]Tokenizing train dataset:  84%|████████▎ | 7168/8564 [00:51<00:06, 220.14 examples/s]Tokenizing train dataset:  84%|████████▍ | 7193/8564 [00:51<00:06, 222.74 examples/s]Tokenizing train dataset:  84%|████████▍ | 7222/8564 [00:51<00:06, 203.59 examples/s]Tokenizing train dataset:  85%|████████▍ | 7257/8564 [00:51<00:06, 200.52 examples/s]Tokenizing train dataset:  85%|████████▌ | 7281/8564 [00:52<00:06, 202.92 examples/s]Tokenizing train dataset:  85%|████████▌ | 7313/8564 [00:52<00:06, 201.29 examples/s]Tokenizing train dataset:  86%|████████▌ | 7339/8564 [00:52<00:05, 204.39 examples/s]Tokenizing train dataset:  86%|████████▌ | 7371/8564 [00:52<00:05, 223.81 examples/s]Tokenizing train dataset:  86%|████████▋ | 7401/8564 [00:52<00:05, 207.78 examples/s]Tokenizing train dataset:  87%|████████▋ | 7424/8564 [00:52<00:05, 209.86 examples/s]Tokenizing train dataset:  87%|████████▋ | 7449/8564 [00:52<00:05, 218.17 examples/s]Tokenizing train dataset:  87%|████████▋ | 7478/8564 [00:53<00:05, 203.67 examples/s]Tokenizing train dataset:  88%|████████▊ | 7501/8564 [00:53<00:05, 207.22 examples/s]Tokenizing train dataset:  88%|████████▊ | 7534/8564 [00:53<00:04, 236.55 examples/s]Tokenizing train dataset:  88%|████████▊ | 7560/8564 [00:53<00:04, 240.29 examples/s]Tokenizing train dataset:  89%|████████▊ | 7590/8564 [00:53<00:03, 245.87 examples/s]Tokenizing train dataset:  89%|████████▉ | 7626/8564 [00:53<00:03, 238.29 examples/s]Tokenizing train dataset:  89%|████████▉ | 7654/8564 [00:53<00:04, 209.99 examples/s]Tokenizing train dataset:  90%|████████▉ | 7680/8564 [00:53<00:04, 193.88 examples/s]Tokenizing train dataset:  90%|█████████ | 7711/8564 [00:54<00:04, 187.70 examples/s]Tokenizing train dataset:  90%|█████████ | 7734/8564 [00:54<00:04, 190.49 examples/s]Tokenizing train dataset:  91%|█████████ | 7755/8564 [00:54<00:04, 193.58 examples/s]Tokenizing train dataset:  91%|█████████ | 7789/8564 [00:54<00:03, 197.13 examples/s]Tokenizing train dataset:  91%|█████████▏| 7815/8564 [00:54<00:04, 180.19 examples/s]Tokenizing train dataset:  92%|█████████▏| 7841/8564 [00:54<00:03, 196.62 examples/s]Tokenizing train dataset:  92%|█████████▏| 7863/8564 [00:54<00:03, 194.74 examples/s]Tokenizing train dataset:  92%|█████████▏| 7884/8564 [00:55<00:03, 196.42 examples/s]Tokenizing train dataset:  92%|█████████▏| 7910/8564 [00:55<00:03, 207.12 examples/s]Tokenizing train dataset:  93%|█████████▎| 7941/8564 [00:55<00:02, 227.09 examples/s]Tokenizing train dataset:  93%|█████████▎| 7967/8564 [00:55<00:02, 225.25 examples/s]Tokenizing train dataset:  93%|█████████▎| 7991/8564 [00:55<00:02, 222.85 examples/s]Tokenizing train dataset:  94%|█████████▎| 8016/8564 [00:55<00:02, 222.78 examples/s]Tokenizing train dataset:  94%|█████████▍| 8047/8564 [00:55<00:02, 213.94 examples/s]Tokenizing train dataset:  94%|█████████▍| 8070/8564 [00:55<00:02, 216.71 examples/s]Tokenizing train dataset:  95%|█████████▍| 8094/8564 [00:56<00:02, 180.91 examples/s]Tokenizing train dataset:  95%|█████████▍| 8116/8564 [00:56<00:02, 188.08 examples/s]Tokenizing train dataset:  95%|█████████▌| 8145/8564 [00:56<00:02, 185.46 examples/s]Tokenizing train dataset:  95%|█████████▌| 8172/8564 [00:56<00:01, 202.04 examples/s]Tokenizing train dataset:  96%|█████████▌| 8200/8564 [00:56<00:01, 211.56 examples/s]Tokenizing train dataset:  96%|█████████▌| 8230/8564 [00:56<00:01, 201.90 examples/s]Tokenizing train dataset:  97%|█████████▋| 8273/8564 [00:56<00:01, 251.77 examples/s]Tokenizing train dataset:  97%|█████████▋| 8307/8564 [00:56<00:00, 260.42 examples/s]Tokenizing train dataset:  97%|█████████▋| 8342/8564 [00:57<00:00, 237.89 examples/s]Tokenizing train dataset:  98%|█████████▊| 8370/8564 [00:57<00:00, 213.06 examples/s]Tokenizing train dataset:  98%|█████████▊| 8396/8564 [00:57<00:00, 215.00 examples/s]Tokenizing train dataset:  98%|█████████▊| 8422/8564 [00:57<00:00, 219.59 examples/s]Tokenizing train dataset:  99%|█████████▊| 8449/8564 [00:57<00:00, 201.37 examples/s]Tokenizing train dataset:  99%|█████████▉| 8478/8564 [00:57<00:00, 212.21 examples/s]Tokenizing train dataset:  99%|█████████▉| 8513/8564 [00:57<00:00, 216.20 examples/s]Tokenizing train dataset: 100%|█████████▉| 8540/8564 [00:58<00:00, 201.30 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:58<00:00, 191.10 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:58<00:00, 147.02 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   2%|▏         | 160/8564 [00:00<00:05, 1557.43 examples/s]Extracting prompt in eval dataset:  40%|███▉      | 380/953 [00:00<00:00, 3195.58 examples/s]Extracting prompt in train dataset:   2%|▏         | 150/8564 [00:00<00:05, 1465.65 examples/s]Extracting prompt in train dataset:   2%|▏         | 187/8564 [00:00<00:04, 1744.92 examples/s]Extracting prompt in train dataset:   4%|▎         | 320/8564 [00:00<00:05, 1568.19 examples/s]Extracting prompt in train dataset:   4%|▎         | 310/8564 [00:00<00:05, 1515.29 examples/s]Extracting prompt in eval dataset:  75%|███████▌  | 715/953 [00:00<00:00, 3103.02 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3209.30 examples/s]
Extracting prompt in train dataset:   5%|▍         | 422/8564 [00:00<00:05, 1517.17 examples/s]Extracting prompt in train dataset:   6%|▌         | 500/8564 [00:00<00:05, 1604.98 examples/s]Extracting prompt in train dataset:   6%|▋         | 551/8564 [00:00<00:05, 1477.16 examples/s]Extracting prompt in train dataset:   7%|▋         | 610/8564 [00:00<00:04, 1606.95 examples/s]Extracting prompt in train dataset:   8%|▊         | 678/8564 [00:00<00:05, 1553.19 examples/s]Extracting prompt in train dataset:   9%|▉         | 759/8564 [00:00<00:05, 1529.22 examples/s]Extracting prompt in train dataset:  10%|▉         | 852/8564 [00:00<00:05, 1538.68 examples/s]Extracting prompt in train dataset:   9%|▉         | 810/8564 [00:00<00:06, 1284.87 examples/s]Extracting prompt in train dataset:  12%|█▏        | 990/8564 [00:00<00:05, 1482.75 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1030/8564 [00:00<00:04, 1535.76 examples/s]Extracting prompt in train dataset:  11%|█▏        | 980/8564 [00:00<00:05, 1300.59 examples/s]Extracting prompt in train dataset:  14%|█▎        | 1160/8564 [00:00<00:04, 1492.14 examples/s]Extracting prompt in train dataset:  14%|█▍        | 1230/8564 [00:00<00:04, 1649.73 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1140/8564 [00:00<00:05, 1331.37 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1340/8564 [00:00<00:04, 1518.70 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1479/8564 [00:00<00:03, 1835.49 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1360/8564 [00:00<00:04, 1513.42 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1711/8564 [00:01<00:03, 1719.96 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1573/8564 [00:01<00:04, 1479.16 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1530/8564 [00:01<00:04, 1557.41 examples/s]Extracting prompt in train dataset:  21%|██▏       | 1820/8564 [00:01<00:04, 1674.43 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  21%|██        | 1760/8564 [00:01<00:04, 1536.68 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1980/8564 [00:01<00:03, 1688.56 examples/s]Applying chat template to eval dataset:  39%|███▉      | 370/953 [00:00<00:00, 3660.83 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1930/8564 [00:01<00:04, 1571.53 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2067/8564 [00:01<00:04, 1619.40 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2230/8564 [00:01<00:03, 1670.60 examples/s]Applying chat template to eval dataset:  79%|███████▊  | 750/953 [00:00<00:00, 3491.00 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2096/8564 [00:01<00:04, 1554.45 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3539.39 examples/s]
Extracting prompt in train dataset:  27%|██▋       | 2285/8564 [00:01<00:04, 1551.02 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2290/8564 [00:01<00:03, 1646.31 examples/s]Extracting prompt in train dataset:  29%|██▉       | 2490/8564 [00:01<00:03, 1641.70 examples/s]Extracting prompt in train dataset:  30%|██▉       | 2530/8564 [00:01<00:03, 1552.71 examples/s]Extracting prompt in train dataset:  30%|██▉       | 2559/8564 [00:01<00:03, 1639.57 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2720/8564 [00:01<00:03, 1555.61 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2700/8564 [00:01<00:03, 1544.84 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2752/8564 [00:01<00:03, 1712.22 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2901/8564 [00:01<00:03, 1609.27 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2921/8564 [00:01<00:03, 1514.75 examples/s]Extracting prompt in train dataset:  36%|███▋      | 3107/8564 [00:01<00:03, 1700.79 examples/s]Extracting prompt in train dataset:  35%|███▍      | 2960/8564 [00:01<00:03, 1442.11 examples/s]Extracting prompt in train dataset:  40%|███▉      | 3406/8564 [00:01<00:02, 2025.54 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3200/8564 [00:02<00:03, 1551.47 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3188/8564 [00:02<00:03, 1435.86 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3630/8564 [00:02<00:02, 1828.88 examples/s]Extracting prompt in train dataset:  40%|███▉      | 3390/8564 [00:02<00:03, 1577.11 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3374/8564 [00:02<00:03, 1502.30 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3590/8564 [00:02<00:02, 1661.75 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3870/8564 [00:02<00:02, 1652.43 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3610/8564 [00:02<00:02, 1681.05 examples/s]Extracting prompt in train dataset:  45%|████▍     | 3840/8564 [00:02<00:02, 1586.56 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4082/8564 [00:02<00:02, 1562.17 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  45%|████▌     | 3858/8564 [00:02<00:02, 1671.69 examples/s]Extracting prompt in train dataset:  50%|█████     | 4290/8564 [00:02<00:02, 1651.40 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4070/8564 [00:02<00:02, 1563.85 examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:12, 77.16 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4090/8564 [00:02<00:02, 1572.29 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4540/8564 [00:02<00:02, 1803.72 examples/s]Tokenizing eval dataset:   2%|▏         | 23/953 [00:00<00:09, 95.23 examples/s]Extracting prompt in train dataset:  50%|█████     | 4286/8564 [00:02<00:02, 1482.73 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4800/8564 [00:02<00:01, 1991.97 examples/s]Extracting prompt in train dataset:  50%|█████     | 4310/8564 [00:02<00:02, 1475.19 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4460/8564 [00:02<00:02, 1448.17 examples/s]Extracting prompt in train dataset:  59%|█████▊    | 5010/8564 [00:02<00:01, 1994.01 examples/s]Tokenizing eval dataset:   4%|▎         | 35/953 [00:00<00:11, 80.01 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4744/8564 [00:03<00:02, 1766.36 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4539/8564 [00:03<00:02, 1389.84 examples/s]Tokenizing eval dataset:   5%|▍         | 47/953 [00:00<00:12, 75.31 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 5070/8564 [00:03<00:01, 2108.47 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5281/8564 [00:03<00:02, 1620.97 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4758/8564 [00:03<00:02, 1329.37 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5366/8564 [00:03<00:01, 2223.09 examples/s]Tokenizing eval dataset:   6%|▌         | 56/953 [00:00<00:12, 71.65 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5520/8564 [00:03<00:01, 1573.39 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4932/8564 [00:03<00:02, 1371.09 examples/s]Tokenizing eval dataset:   7%|▋         | 69/953 [00:00<00:10, 81.86 examples/s]Extracting prompt in train dataset:  66%|██████▋   | 5680/8564 [00:03<00:01, 2124.02 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5710/8564 [00:03<00:01, 1633.36 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 5100/8564 [00:03<00:02, 1430.34 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:10, 84.91 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5910/8564 [00:03<00:01, 2111.10 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5940/8564 [00:03<00:01, 1696.39 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5320/8564 [00:03<00:02, 1412.55 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6133/8564 [00:03<00:01, 1719.21 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6190/8564 [00:03<00:01, 1963.02 examples/s]Tokenizing eval dataset:  10%|▉         | 91/953 [00:01<00:11, 74.06 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5471/8564 [00:03<00:02, 1370.97 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 6447/8564 [00:03<00:01, 2087.43 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6364/8564 [00:03<00:01, 1591.52 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 5640/8564 [00:03<00:02, 1445.25 examples/s]Tokenizing eval dataset:  10%|█         | 100/953 [00:01<00:12, 68.67 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5825/8564 [00:03<00:01, 1547.27 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6750/8564 [00:03<00:00, 2049.82 examples/s]Tokenizing eval dataset:  11%|█▏        | 109/953 [00:01<00:11, 72.59 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6600/8564 [00:03<00:01, 1538.65 examples/s]Extracting prompt in train dataset:  70%|███████   | 6030/8564 [00:04<00:01, 1677.11 examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:01<00:11, 72.25 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 7000/8564 [00:04<00:00, 1915.12 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6774/8564 [00:04<00:01, 1488.63 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6230/8564 [00:04<00:01, 1658.31 examples/s]Tokenizing eval dataset:  13%|█▎        | 126/953 [00:01<00:10, 76.03 examples/s]Extracting prompt in train dataset:  81%|████████  | 6950/8564 [00:04<00:01, 1540.56 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7280/8564 [00:04<00:00, 1855.63 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 6440/8564 [00:04<00:01, 1712.98 examples/s]Tokenizing eval dataset:  14%|█▍        | 137/953 [00:01<00:10, 80.72 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7113/8564 [00:04<00:00, 1562.19 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7490/8564 [00:04<00:00, 1904.41 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6710/8564 [00:04<00:01, 1739.24 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 7279/8564 [00:04<00:00, 1585.52 examples/s]Tokenizing eval dataset:  16%|█▌        | 149/953 [00:01<00:10, 75.83 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 7699/8564 [00:04<00:00, 1882.58 examples/s]Extracting prompt in train dataset:  81%|████████  | 6924/8564 [00:04<00:00, 1691.07 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7483/8564 [00:04<00:00, 1465.59 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:02<00:11, 71.80 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7979/8564 [00:04<00:00, 1776.15 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7120/8564 [00:04<00:00, 1727.91 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7640/8564 [00:04<00:00, 1461.86 examples/s]Tokenizing eval dataset:  18%|█▊        | 170/953 [00:02<00:10, 75.11 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7295/8564 [00:04<00:00, 1711.81 examples/s]Extracting prompt in train dataset:  96%|█████████▋| 8259/8564 [00:04<00:00, 1749.67 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7860/8564 [00:04<00:00, 1422.81 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7470/8564 [00:04<00:00, 1682.49 examples/s]Extracting prompt in train dataset:  99%|█████████▊| 8450/8564 [00:04<00:00, 1781.22 examples/s]Tokenizing eval dataset:  19%|█▉        | 179/953 [00:02<00:11, 68.00 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 8020/8564 [00:04<00:00, 1444.07 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7651/8564 [00:04<00:00, 1716.73 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:04<00:00, 1713.51 examples/s]
Extracting prompt in train dataset:  96%|█████████▌| 8230/8564 [00:05<00:00, 1546.09 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:02<00:11, 65.03 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7860/8564 [00:05<00:00, 1649.99 examples/s]Extracting prompt in train dataset:  95%|█████████▌| 8151/8564 [00:05<00:00, 1923.27 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8464/8564 [00:05<00:00, 1500.15 examples/s]Tokenizing eval dataset:  21%|██        | 200/953 [00:02<00:11, 66.87 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1617.74 examples/s]
Extracting prompt in train dataset:  98%|█████████▊| 8384/8564 [00:05<00:00, 2032.36 examples/s]Tokenizing eval dataset:  22%|██▏       | 212/953 [00:02<00:09, 76.03 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:02<00:09, 80.31 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:05<00:00, 1568.42 examples/s]
Tokenizing eval dataset:  25%|██▌       | 240/953 [00:03<00:07, 98.13 examples/s]Tokenizing eval dataset:  27%|██▋       | 261/953 [00:03<00:05, 121.50 examples/s]Tokenizing eval dataset:  30%|██▉       | 285/953 [00:03<00:04, 147.98 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:03<00:04, 156.50 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  34%|███▍      | 326/953 [00:03<00:03, 163.51 examples/s]Applying chat template to train dataset:   1%|          | 76/8564 [00:00<00:13, 608.98 examples/s]Tokenizing eval dataset:  37%|███▋      | 350/953 [00:03<00:03, 170.77 examples/s]Applying chat template to train dataset:   2%|▏         | 181/8564 [00:00<00:09, 843.38 examples/s]Tokenizing eval dataset:  39%|███▉      | 374/953 [00:03<00:03, 160.58 examples/s]Applying chat template to train dataset:   3%|▎         | 283/8564 [00:00<00:09, 867.37 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  41%|████▏     | 394/953 [00:03<00:03, 167.85 examples/s]Applying chat template to train dataset:   5%|▍         | 398/8564 [00:00<00:09, 851.71 examples/s]Applying chat template to train dataset:   1%|          | 107/8564 [00:00<00:08, 1050.80 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   7%|▋         | 559/8564 [00:00<00:07, 1087.32 examples/s]Tokenizing eval dataset:  44%|████▍     | 418/953 [00:04<00:03, 154.64 examples/s]Applying chat template to train dataset:   1%|          | 80/8564 [00:00<00:12, 694.48 examples/s]Applying chat template to train dataset:   3%|▎         | 240/8564 [00:00<00:09, 920.41 examples/s] Tokenizing eval dataset:  46%|████▌     | 439/953 [00:04<00:03, 165.64 examples/s]Applying chat template to train dataset:   2%|▏         | 167/8564 [00:00<00:10, 776.90 examples/s]Applying chat template to train dataset:   8%|▊         | 720/8564 [00:00<00:08, 927.12 examples/s] Tokenizing eval dataset:  49%|████▉     | 466/953 [00:04<00:02, 184.47 examples/s]Applying chat template to train dataset:   4%|▍         | 372/8564 [00:00<00:09, 871.09 examples/s]Applying chat template to train dataset:   3%|▎         | 264/8564 [00:00<00:09, 856.35 examples/s]Applying chat template to train dataset:  10%|█         | 859/8564 [00:00<00:08, 919.61 examples/s]Tokenizing eval dataset:  52%|█████▏    | 495/953 [00:04<00:02, 179.26 examples/s]Applying chat template to train dataset:   6%|▌         | 507/8564 [00:00<00:09, 836.43 examples/s]Applying chat template to train dataset:   5%|▍         | 400/8564 [00:00<00:09, 875.55 examples/s]Tokenizing eval dataset:  54%|█████▍    | 515/953 [00:04<00:02, 179.55 examples/s]Applying chat template to train dataset:   6%|▌         | 535/8564 [00:00<00:07, 1019.67 examples/s]Applying chat template to train dataset:  12%|█▏        | 988/8564 [00:01<00:08, 876.97 examples/s]Applying chat template to train dataset:   7%|▋         | 625/8564 [00:00<00:09, 797.35 examples/s]Applying chat template to train dataset:  13%|█▎        | 1083/8564 [00:01<00:08, 892.86 examples/s]Applying chat template to train dataset:   8%|▊         | 663/8564 [00:00<00:07, 1072.06 examples/s]Tokenizing eval dataset:  56%|█████▌    | 534/953 [00:04<00:02, 169.79 examples/s]Applying chat template to train dataset:   8%|▊         | 710/8564 [00:00<00:09, 789.42 examples/s]Applying chat template to train dataset:   9%|▉         | 801/8564 [00:00<00:06, 1130.03 examples/s]Tokenizing eval dataset:  59%|█████▊    | 558/953 [00:04<00:02, 185.88 examples/s]Applying chat template to train dataset:  14%|█▍        | 1192/8564 [00:01<00:08, 835.64 examples/s]Applying chat template to train dataset:   9%|▉         | 813/8564 [00:00<00:09, 815.37 examples/s]Applying chat template to train dataset:  15%|█▌        | 1326/8564 [00:01<00:07, 943.74 examples/s]Applying chat template to train dataset:  11%|█         | 937/8564 [00:00<00:07, 996.18 examples/s] Tokenizing eval dataset:  61%|██████    | 581/953 [00:05<00:02, 163.03 examples/s]Applying chat template to train dataset:  18%|█▊        | 1511/8564 [00:01<00:06, 1166.59 examples/s]Applying chat template to train dataset:  11%|█         | 931/8564 [00:01<00:11, 676.58 examples/s]Tokenizing eval dataset:  63%|██████▎   | 600/953 [00:05<00:02, 157.78 examples/s]Applying chat template to train dataset:  20%|█▉        | 1678/8564 [00:01<00:05, 1297.12 examples/s]Applying chat template to train dataset:  12%|█▏        | 1056/8564 [00:01<00:08, 854.28 examples/s]Applying chat template to train dataset:  12%|█▏        | 1017/8564 [00:01<00:10, 695.20 examples/s]Applying chat template to train dataset:  14%|█▍        | 1186/8564 [00:01<00:07, 931.40 examples/s]Tokenizing eval dataset:  65%|██████▌   | 620/953 [00:05<00:02, 145.42 examples/s]Applying chat template to train dataset:  13%|█▎        | 1111/8564 [00:01<00:10, 740.31 examples/s]Applying chat template to train dataset:  21%|██▏       | 1827/8564 [00:01<00:06, 1117.78 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:05<00:01, 156.70 examples/s]Applying chat template to train dataset:  14%|█▍        | 1207/8564 [00:01<00:09, 793.41 examples/s]Applying chat template to train dataset:  15%|█▌        | 1319/8564 [00:01<00:07, 915.64 examples/s]Applying chat template to train dataset:  23%|██▎       | 1972/8564 [00:01<00:06, 1061.01 examples/s]Applying chat template to train dataset:  15%|█▌        | 1313/8564 [00:01<00:08, 860.79 examples/s]Tokenizing eval dataset:  69%|██████▉   | 660/953 [00:05<00:01, 155.21 examples/s]Applying chat template to train dataset:  17%|█▋        | 1444/8564 [00:01<00:08, 888.24 examples/s]Applying chat template to train dataset:  17%|█▋        | 1420/8564 [00:01<00:07, 906.71 examples/s]Tokenizing eval dataset:  71%|███████▏  | 680/953 [00:05<00:01, 161.59 examples/s]Applying chat template to train dataset:  24%|██▍       | 2096/8564 [00:02<00:06, 973.12 examples/s] Applying chat template to train dataset:  18%|█▊        | 1519/8564 [00:01<00:07, 927.84 examples/s]Tokenizing eval dataset:  73%|███████▎  | 697/953 [00:05<00:01, 162.73 examples/s]Applying chat template to train dataset:  18%|█▊        | 1580/8564 [00:01<00:08, 870.87 examples/s]Applying chat template to train dataset:  26%|██▌       | 2229/8564 [00:02<00:06, 945.26 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:05<00:01, 187.85 examples/s]Applying chat template to train dataset:  20%|█▉        | 1671/8564 [00:01<00:07, 863.85 examples/s]Applying chat template to train dataset:  27%|██▋       | 2332/8564 [00:02<00:06, 963.44 examples/s]Applying chat template to train dataset:  19%|█▉        | 1649/8564 [00:02<00:07, 867.52 examples/s]Applying chat template to train dataset:  21%|██        | 1814/8564 [00:01<00:07, 886.52 examples/s]Applying chat template to train dataset:  21%|██        | 1756/8564 [00:02<00:07, 876.79 examples/s]Tokenizing eval dataset:  78%|███████▊  | 747/953 [00:06<00:01, 164.50 examples/s]Applying chat template to train dataset:  29%|██▊       | 2458/8564 [00:02<00:06, 897.99 examples/s]Tokenizing eval dataset:  81%|████████  | 769/953 [00:06<00:01, 173.41 examples/s]Applying chat template to train dataset:  23%|██▎       | 1951/8564 [00:02<00:07, 883.19 examples/s]Applying chat template to train dataset:  22%|██▏       | 1915/8564 [00:02<00:07, 914.94 examples/s]Applying chat template to train dataset:  30%|███       | 2585/8564 [00:02<00:07, 817.25 examples/s]Applying chat template to train dataset:  24%|██▍       | 2040/8564 [00:02<00:07, 873.44 examples/s]Applying chat template to train dataset:  24%|██▎       | 2020/8564 [00:02<00:07, 933.21 examples/s]Tokenizing eval dataset:  83%|████████▎ | 789/953 [00:06<00:01, 149.58 examples/s]Applying chat template to train dataset:  31%|███▏      | 2685/8564 [00:02<00:06, 851.14 examples/s]Applying chat template to train dataset:  25%|██▌       | 2142/8564 [00:02<00:07, 888.30 examples/s]Applying chat template to train dataset:  25%|██▌       | 2157/8564 [00:02<00:07, 902.24 examples/s]Applying chat template to train dataset:  32%|███▏      | 2779/8564 [00:02<00:06, 851.99 examples/s]Tokenizing eval dataset:  85%|████████▍ | 810/953 [00:06<00:00, 143.57 examples/s]Applying chat template to train dataset:  26%|██▌       | 2239/8564 [00:02<00:07, 886.25 examples/s]Applying chat template to train dataset:  26%|██▋       | 2261/8564 [00:02<00:06, 933.54 examples/s]Applying chat template to train dataset:  34%|███▎      | 2869/8564 [00:03<00:06, 863.33 examples/s]Tokenizing eval dataset:  87%|████████▋ | 826/953 [00:06<00:00, 146.43 examples/s]Applying chat template to train dataset:  28%|██▊       | 2356/8564 [00:02<00:06, 936.09 examples/s]Applying chat template to train dataset:  28%|██▊       | 2388/8564 [00:02<00:06, 888.00 examples/s]Applying chat template to train dataset:  35%|███▍      | 2970/8564 [00:03<00:06, 876.99 examples/s]Tokenizing eval dataset:  89%|████████▉ | 850/953 [00:06<00:00, 144.52 examples/s]Applying chat template to train dataset:  29%|██▉       | 2496/8564 [00:02<00:06, 906.92 examples/s]Applying chat template to train dataset:  29%|██▉       | 2477/8564 [00:02<00:06, 889.13 examples/s]Applying chat template to train dataset:  31%|███       | 2646/8564 [00:02<00:05, 1053.55 examples/s]Tokenizing eval dataset:  91%|█████████ | 866/953 [00:06<00:00, 137.49 examples/s]Applying chat template to train dataset:  36%|███▌      | 3096/8564 [00:03<00:07, 702.13 examples/s]Applying chat template to train dataset:  30%|███       | 2612/8564 [00:03<00:06, 884.77 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:07<00:00, 143.92 examples/s]Applying chat template to train dataset:  32%|███▏      | 2779/8564 [00:02<00:05, 992.82 examples/s] Applying chat template to train dataset:  32%|███▏      | 2741/8564 [00:03<00:06, 955.45 examples/s]Applying chat template to train dataset:  37%|███▋      | 3211/8564 [00:03<00:07, 703.43 examples/s]Tokenizing eval dataset:  94%|█████████▍| 900/953 [00:07<00:00, 141.41 examples/s]Applying chat template to train dataset:  33%|███▎      | 2853/8564 [00:03<00:05, 991.26 examples/s]Applying chat template to train dataset:  34%|███▍      | 2901/8564 [00:03<00:06, 922.57 examples/s]Applying chat template to train dataset:  39%|███▊      | 3302/8564 [00:03<00:07, 737.39 examples/s]Tokenizing eval dataset:  96%|█████████▌| 916/953 [00:07<00:00, 127.90 examples/s]Applying chat template to train dataset:  40%|███▉      | 3390/8564 [00:03<00:07, 729.16 examples/s]Applying chat template to train dataset:  36%|███▌      | 3044/8564 [00:03<00:05, 1080.18 examples/s]Applying chat template to train dataset:  35%|███▌      | 3010/8564 [00:03<00:06, 837.90 examples/s]Tokenizing eval dataset:  98%|█████████▊| 934/953 [00:07<00:00, 139.11 examples/s]Applying chat template to train dataset:  41%|████      | 3478/8564 [00:03<00:06, 737.28 examples/s]Applying chat template to train dataset:  36%|███▌      | 3102/8564 [00:03<00:07, 778.73 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:07<00:00, 138.11 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:07<00:00, 126.26 examples/s]
Applying chat template to train dataset:  42%|████▏     | 3579/8564 [00:04<00:06, 782.13 examples/s]Applying chat template to train dataset:  43%|████▎     | 3672/8564 [00:04<00:05, 819.28 examples/s]Applying chat template to train dataset:  37%|███▋      | 3205/8564 [00:03<00:06, 773.92 examples/s] Applying chat template to train dataset:  38%|███▊      | 3240/8564 [00:03<00:07, 755.08 examples/s]Applying chat template to train dataset:  44%|████▍     | 3771/8564 [00:04<00:05, 864.08 examples/s]Applying chat template to train dataset:  39%|███▊      | 3307/8564 [00:03<00:06, 816.36 examples/s]Applying chat template to train dataset:  39%|███▉      | 3334/8564 [00:03<00:07, 710.15 examples/s]Applying chat template to train dataset:  45%|████▌     | 3871/8564 [00:04<00:05, 899.60 examples/s]Applying chat template to train dataset:  40%|███▉      | 3410/8564 [00:03<00:05, 859.67 examples/s]Applying chat template to train dataset:  40%|███▉      | 3420/8564 [00:03<00:07, 722.55 examples/s]Applying chat template to train dataset:  41%|████      | 3519/8564 [00:04<00:06, 817.50 examples/s]Applying chat template to train dataset:  47%|████▋     | 4000/8564 [00:04<00:05, 822.69 examples/s]Applying chat template to train dataset:  41%|████      | 3511/8564 [00:04<00:06, 747.93 examples/s]Applying chat template to train dataset:  42%|████▏     | 3599/8564 [00:04<00:06, 770.92 examples/s]Applying chat template to train dataset:  43%|████▎     | 3640/8564 [00:04<00:06, 745.83 examples/s]Applying chat template to train dataset:  48%|████▊     | 4127/8564 [00:04<00:05, 756.08 examples/s]Applying chat template to train dataset:  43%|████▎     | 3680/8564 [00:04<00:06, 778.93 examples/s]Applying chat template to train dataset:  43%|████▎     | 3722/8564 [00:04<00:06, 725.45 examples/s]Applying chat template to train dataset:  49%|████▉     | 4220/8564 [00:04<00:05, 763.95 examples/s]Applying chat template to train dataset:  45%|████▍     | 3811/8564 [00:04<00:06, 754.25 examples/s]Applying chat template to train dataset:  44%|████▍     | 3794/8564 [00:04<00:07, 680.23 examples/s]Applying chat template to train dataset:  50%|█████     | 4314/8564 [00:04<00:05, 719.46 examples/s]Applying chat template to train dataset:  46%|████▌     | 3901/8564 [00:04<00:06, 736.45 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4390/8564 [00:05<00:05, 728.20 examples/s]Applying chat template to train dataset:  46%|████▌     | 3953/8564 [00:04<00:06, 732.40 examples/s]Applying chat template to train dataset:  47%|████▋     | 3991/8564 [00:04<00:06, 699.07 examples/s]Applying chat template to train dataset:  48%|████▊     | 4149/8564 [00:04<00:04, 990.18 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4494/8564 [00:05<00:06, 642.14 examples/s]Applying chat template to train dataset:  48%|████▊     | 4095/8564 [00:04<00:06, 669.39 examples/s]Applying chat template to train dataset:  50%|████▉     | 4260/8564 [00:04<00:04, 976.28 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4571/8564 [00:05<00:06, 634.10 examples/s]Applying chat template to train dataset:  49%|████▊     | 4170/8564 [00:05<00:06, 661.18 examples/s]Applying chat template to train dataset:  51%|█████     | 4366/8564 [00:04<00:04, 944.51 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4676/8564 [00:05<00:06, 630.95 examples/s]Applying chat template to train dataset:  50%|████▉     | 4250/8564 [00:05<00:07, 603.44 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4520/8564 [00:05<00:04, 957.12 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4747/8564 [00:05<00:06, 628.36 examples/s]Applying chat template to train dataset:  51%|█████     | 4352/8564 [00:05<00:06, 690.52 examples/s]Applying chat template to train dataset:  56%|█████▋    | 4826/8564 [00:05<00:05, 646.76 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4628/8564 [00:05<00:04, 863.26 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4448/8564 [00:05<00:05, 728.89 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4901/8564 [00:05<00:05, 637.86 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4728/8564 [00:05<00:04, 865.72 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4545/8564 [00:05<00:05, 785.73 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4872/8564 [00:05<00:03, 957.77 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4649/8564 [00:05<00:04, 851.72 examples/s]Applying chat template to train dataset:  58%|█████▊    | 5000/8564 [00:06<00:05, 607.47 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4975/8564 [00:05<00:03, 960.21 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5077/8564 [00:06<00:05, 618.46 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5099/8564 [00:05<00:03, 1018.87 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4780/8564 [00:05<00:05, 719.11 examples/s]Applying chat template to train dataset:  61%|██████    | 5183/8564 [00:06<00:04, 723.48 examples/s]Applying chat template to train dataset:  61%|██████    | 5229/8564 [00:05<00:03, 1090.41 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5282/8564 [00:06<00:04, 790.21 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4900/8564 [00:06<00:05, 705.14 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5370/8564 [00:06<00:03, 798.77 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5358/8564 [00:06<00:03, 875.92 examples/s] Applying chat template to train dataset:  58%|█████▊    | 4987/8564 [00:06<00:05, 681.37 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5474/8564 [00:06<00:03, 801.84 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5062/8564 [00:06<00:05, 661.76 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5585/8564 [00:06<00:03, 830.67 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5499/8564 [00:06<00:04, 749.98 examples/s]Applying chat template to train dataset:  60%|██████    | 5153/8564 [00:06<00:05, 674.13 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5604/8564 [00:06<00:03, 801.72 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5684/8564 [00:06<00:03, 744.89 examples/s]Applying chat template to train dataset:  61%|██████    | 5222/8564 [00:06<00:05, 642.17 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5800/8564 [00:07<00:03, 825.90 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5704/8564 [00:06<00:03, 725.23 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5300/8564 [00:06<00:05, 618.56 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5916/8564 [00:07<00:03, 806.80 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5827/8564 [00:06<00:03, 737.99 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5373/8564 [00:06<00:05, 570.83 examples/s]Applying chat template to train dataset:  70%|███████   | 6003/8564 [00:07<00:03, 820.93 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5910/8564 [00:06<00:03, 724.44 examples/s]Applying chat template to train dataset:  64%|██████▎   | 5449/8564 [00:07<00:05, 592.83 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6120/8564 [00:07<00:03, 791.47 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5541/8564 [00:07<00:04, 607.68 examples/s]Applying chat template to train dataset:  70%|███████   | 6003/8564 [00:07<00:04, 624.85 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6213/8564 [00:07<00:03, 771.43 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5631/8564 [00:07<00:04, 633.52 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6102/8564 [00:07<00:03, 691.20 examples/s]Applying chat template to train dataset:  74%|███████▎  | 6300/8564 [00:07<00:03, 737.49 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6186/8564 [00:07<00:03, 721.38 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5719/8564 [00:07<00:04, 643.16 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6385/8564 [00:07<00:03, 709.35 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6287/8564 [00:07<00:02, 762.50 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5810/8564 [00:07<00:04, 655.48 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6471/8564 [00:08<00:03, 691.74 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6379/8564 [00:07<00:02, 801.33 examples/s]Applying chat template to train dataset:  69%|██████▊   | 5885/8564 [00:07<00:04, 667.54 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6480/8564 [00:07<00:02, 846.31 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6588/8564 [00:08<00:02, 712.75 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5981/8564 [00:07<00:03, 717.11 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6683/8564 [00:08<00:02, 746.18 examples/s]Applying chat template to train dataset:  71%|███████   | 6076/8564 [00:07<00:03, 748.51 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6580/8564 [00:07<00:02, 730.46 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6789/8564 [00:08<00:02, 822.54 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6181/8564 [00:07<00:02, 826.52 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6660/8564 [00:07<00:02, 663.86 examples/s]Applying chat template to train dataset:  80%|████████  | 6890/8564 [00:08<00:01, 870.41 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6292/8564 [00:08<00:02, 903.29 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7012/8564 [00:08<00:01, 963.71 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6400/8564 [00:08<00:02, 924.53 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6760/8564 [00:08<00:02, 623.89 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7140/8564 [00:08<00:01, 913.52 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6837/8564 [00:08<00:02, 654.33 examples/s]Applying chat template to train dataset:  76%|███████▋  | 6534/8564 [00:08<00:02, 784.15 examples/s]Applying chat template to train dataset:  81%|████████  | 6936/8564 [00:08<00:02, 688.30 examples/s]Applying chat template to train dataset:  85%|████████▍ | 7268/8564 [00:08<00:01, 839.77 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6620/8564 [00:08<00:02, 741.26 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7030/8564 [00:08<00:02, 703.52 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7360/8564 [00:09<00:01, 802.16 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6715/8564 [00:08<00:02, 761.28 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7140/8564 [00:08<00:01, 781.68 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6814/8564 [00:08<00:02, 815.97 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7457/8564 [00:09<00:01, 764.73 examples/s]Applying chat template to train dataset:  81%|████████  | 6909/8564 [00:08<00:02, 823.40 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7552/8564 [00:09<00:01, 795.47 examples/s]Applying chat template to train dataset:  85%|████████▍ | 7270/8564 [00:08<00:01, 744.85 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7000/8564 [00:08<00:01, 843.55 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7365/8564 [00:08<00:01, 773.66 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7638/8564 [00:09<00:01, 755.45 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7468/8564 [00:08<00:01, 825.76 examples/s]Applying chat template to train dataset:  90%|█████████ | 7729/8564 [00:09<00:01, 766.56 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7139/8564 [00:09<00:01, 814.27 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7232/8564 [00:09<00:01, 839.08 examples/s]Applying chat template to train dataset:  89%|████████▊ | 7581/8564 [00:09<00:01, 758.11 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7344/8564 [00:09<00:01, 879.20 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7676/8564 [00:09<00:01, 802.04 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7470/8564 [00:09<00:01, 930.87 examples/s]Applying chat template to train dataset:  91%|█████████▏| 7832/8564 [00:09<00:01, 456.29 examples/s]Applying chat template to train dataset:  89%|████████▊ | 7584/8564 [00:09<00:01, 976.53 examples/s]Applying chat template to train dataset:  91%|█████████ | 7765/8564 [00:09<00:01, 566.64 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7898/8564 [00:10<00:01, 454.63 examples/s]Applying chat template to train dataset:  90%|█████████ | 7748/8564 [00:09<00:00, 1134.83 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7880/8564 [00:09<00:01, 666.76 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7979/8564 [00:10<00:01, 500.83 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7990/8564 [00:09<00:00, 758.99 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7911/8564 [00:09<00:00, 979.51 examples/s] Applying chat template to train dataset:  94%|█████████▍| 8045/8564 [00:10<00:00, 527.92 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8099/8564 [00:09<00:00, 835.35 examples/s]Applying chat template to train dataset:  94%|█████████▎| 8025/8564 [00:10<00:00, 1015.57 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8111/8564 [00:10<00:00, 542.94 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8194/8564 [00:09<00:00, 857.32 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8344/8564 [00:10<00:00, 1025.38 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8207/8564 [00:10<00:00, 564.95 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8146/8564 [00:10<00:00, 877.07 examples/s] Applying chat template to train dataset:  97%|█████████▋| 8310/8564 [00:10<00:00, 657.97 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8488/8564 [00:10<00:00, 961.80 examples/s] Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 834.14 examples/s]
Applying chat template to train dataset:  96%|█████████▋| 8258/8564 [00:10<00:00, 742.31 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8420/8564 [00:10<00:00, 716.26 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8387/8564 [00:10<00:00, 846.30 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8512/8564 [00:10<00:00, 724.84 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8498/8564 [00:10<00:00, 904.59 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:11<00:00, 776.83 examples/s]
Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 798.12 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 24/8564 [00:00<00:37, 230.69 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 14/8564 [00:00<01:11, 119.82 examples/s]Tokenizing train dataset:   1%|          | 53/8564 [00:00<00:58, 145.48 examples/s]Tokenizing train dataset:   0%|          | 31/8564 [00:00<01:10, 121.44 examples/s]Tokenizing train dataset:   1%|          | 70/8564 [00:00<01:10, 120.97 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 44/8564 [00:00<01:32, 91.75 examples/s] Tokenizing train dataset:   0%|          | 14/8564 [00:00<01:08, 123.95 examples/s]Tokenizing train dataset:   1%|          | 87/8564 [00:00<01:18, 107.72 examples/s]Tokenizing train dataset:   1%|          | 54/8564 [00:00<01:51, 75.99 examples/s]Tokenizing train dataset:   0%|          | 32/8564 [00:00<01:07, 126.92 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:00<01:27, 96.67 examples/s]Tokenizing train dataset:   1%|          | 64/8564 [00:00<01:51, 76.26 examples/s]Tokenizing train dataset:   1%|▏         | 111/8564 [00:01<01:28, 95.51 examples/s]Tokenizing train dataset:   1%|          | 45/8564 [00:00<01:31, 92.85 examples/s] Tokenizing train dataset:   1%|          | 73/8564 [00:00<02:02, 69.15 examples/s]Tokenizing train dataset:   1%|▏         | 122/8564 [00:01<01:33, 89.89 examples/s]Tokenizing train dataset:   1%|          | 84/8564 [00:01<01:48, 78.40 examples/s]Tokenizing train dataset:   1%|          | 60/8564 [00:00<01:48, 78.23 examples/s]Tokenizing train dataset:   1%|          | 95/8564 [00:01<01:43, 82.00 examples/s]Tokenizing train dataset:   2%|▏         | 138/8564 [00:01<01:38, 85.58 examples/s]Tokenizing train dataset:   1%|          | 70/8564 [00:00<01:57, 72.24 examples/s]Tokenizing train dataset:   1%|          | 104/8564 [00:01<01:48, 78.33 examples/s]Tokenizing train dataset:   2%|▏         | 148/8564 [00:01<01:40, 83.37 examples/s]Tokenizing train dataset:   1%|          | 81/8564 [00:00<01:53, 74.88 examples/s]Tokenizing train dataset:   1%|▏         | 113/8564 [00:01<01:52, 75.10 examples/s]Tokenizing train dataset:   2%|▏         | 157/8564 [00:01<01:42, 82.09 examples/s]Tokenizing train dataset:   2%|▏         | 167/8564 [00:01<01:38, 85.41 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:01<02:04, 68.10 examples/s]Tokenizing train dataset:   1%|▏         | 123/8564 [00:01<02:03, 68.17 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:01<02:05, 67.64 examples/s]Tokenizing train dataset:   2%|▏         | 179/8564 [00:01<01:44, 80.23 examples/s]Tokenizing train dataset:   2%|▏         | 134/8564 [00:01<02:01, 69.52 examples/s]Tokenizing train dataset:   2%|▏         | 197/8564 [00:01<01:21, 102.71 examples/s]Tokenizing train dataset:   2%|▏         | 145/8564 [00:01<01:49, 76.75 examples/s]Tokenizing train dataset:   1%|          | 107/8564 [00:01<02:23, 58.82 examples/s]Tokenizing train dataset:   2%|▏         | 208/8564 [00:02<01:23, 99.78 examples/s] Tokenizing train dataset:   2%|▏         | 155/8564 [00:01<01:46, 79.18 examples/s]Tokenizing train dataset:   1%|▏         | 114/8564 [00:01<02:21, 59.80 examples/s]Tokenizing train dataset:   2%|▏         | 164/8564 [00:02<01:43, 80.91 examples/s]Tokenizing train dataset:   1%|▏         | 123/8564 [00:01<02:16, 61.88 examples/s]Tokenizing train dataset:   3%|▎         | 225/8564 [00:02<01:31, 91.21 examples/s]Tokenizing train dataset:   2%|▏         | 178/8564 [00:02<01:44, 80.61 examples/s]Tokenizing train dataset:   3%|▎         | 235/8564 [00:02<01:29, 92.75 examples/s]Tokenizing train dataset:   2%|▏         | 134/8564 [00:01<02:18, 60.69 examples/s]Tokenizing train dataset:   2%|▏         | 189/8564 [00:02<01:40, 83.31 examples/s]Tokenizing train dataset:   3%|▎         | 247/8564 [00:02<01:36, 85.76 examples/s]Tokenizing train dataset:   2%|▏         | 146/8564 [00:02<01:56, 71.98 examples/s]Tokenizing train dataset:   2%|▏         | 198/8564 [00:02<01:45, 79.51 examples/s]Tokenizing train dataset:   3%|▎         | 258/8564 [00:02<01:33, 88.88 examples/s]Tokenizing train dataset:   2%|▏         | 154/8564 [00:02<01:57, 71.66 examples/s]Tokenizing train dataset:   3%|▎         | 272/8564 [00:02<01:26, 95.99 examples/s]Tokenizing train dataset:   2%|▏         | 212/8564 [00:02<01:48, 76.79 examples/s]Tokenizing train dataset:   2%|▏         | 164/8564 [00:02<02:16, 61.65 examples/s]Tokenizing train dataset:   3%|▎         | 286/8564 [00:02<01:24, 97.95 examples/s]Tokenizing train dataset:   3%|▎         | 225/8564 [00:02<01:46, 77.97 examples/s]Tokenizing train dataset:   2%|▏         | 171/8564 [00:02<02:34, 54.27 examples/s]Tokenizing train dataset:   3%|▎         | 237/8564 [00:02<01:42, 81.49 examples/s]Tokenizing train dataset:   3%|▎         | 297/8564 [00:03<01:42, 80.87 examples/s]Tokenizing train dataset:   2%|▏         | 181/8564 [00:02<02:12, 63.13 examples/s]Tokenizing train dataset:   4%|▎         | 306/8564 [00:03<01:48, 75.93 examples/s]Tokenizing train dataset:   2%|▏         | 194/8564 [00:02<01:50, 75.73 examples/s]Tokenizing train dataset:   3%|▎         | 250/8564 [00:03<01:51, 74.67 examples/s]Tokenizing train dataset:   2%|▏         | 205/8564 [00:02<01:39, 83.68 examples/s]Tokenizing train dataset:   3%|▎         | 259/8564 [00:03<01:52, 73.69 examples/s]Tokenizing train dataset:   4%|▎         | 320/8564 [00:03<01:51, 73.95 examples/s]Tokenizing train dataset:   3%|▎         | 216/8564 [00:02<01:37, 85.45 examples/s]Tokenizing train dataset:   3%|▎         | 270/8564 [00:03<01:46, 78.03 examples/s]Tokenizing train dataset:   4%|▍         | 328/8564 [00:03<01:54, 71.94 examples/s]Tokenizing train dataset:   3%|▎         | 227/8564 [00:03<01:32, 89.84 examples/s]Tokenizing train dataset:   3%|▎         | 279/8564 [00:03<01:49, 75.87 examples/s]Tokenizing train dataset:   4%|▍         | 336/8564 [00:03<01:57, 69.82 examples/s]Tokenizing train dataset:   3%|▎         | 239/8564 [00:03<01:27, 95.52 examples/s]Tokenizing train dataset:   3%|▎         | 288/8564 [00:03<01:56, 71.33 examples/s]Tokenizing train dataset:   3%|▎         | 257/8564 [00:03<01:16, 108.06 examples/s]Tokenizing train dataset:   4%|▍         | 344/8564 [00:03<02:12, 61.96 examples/s]Tokenizing train dataset:   4%|▎         | 302/8564 [00:03<01:36, 85.87 examples/s]Tokenizing train dataset:   3%|▎         | 271/8564 [00:03<01:18, 106.16 examples/s]Tokenizing train dataset:   4%|▍         | 352/8564 [00:04<02:13, 61.71 examples/s]Tokenizing train dataset:   4%|▎         | 314/8564 [00:03<01:29, 92.48 examples/s]Tokenizing train dataset:   4%|▍         | 363/8564 [00:04<02:09, 63.26 examples/s]Tokenizing train dataset:   4%|▍         | 325/8564 [00:04<01:33, 87.85 examples/s]Tokenizing train dataset:   3%|▎         | 283/8564 [00:03<01:42, 80.63 examples/s] Tokenizing train dataset:   4%|▍         | 376/8564 [00:04<01:52, 72.84 examples/s]Tokenizing train dataset:   3%|▎         | 295/8564 [00:03<01:37, 85.23 examples/s]Tokenizing train dataset:   4%|▍         | 339/8564 [00:04<01:43, 79.78 examples/s]Tokenizing train dataset:   5%|▍         | 389/8564 [00:04<01:36, 84.29 examples/s]Tokenizing train dataset:   5%|▍         | 398/8564 [00:04<01:36, 84.61 examples/s]Tokenizing train dataset:   4%|▎         | 308/8564 [00:04<01:47, 76.65 examples/s]Tokenizing train dataset:   4%|▍         | 348/8564 [00:04<01:59, 68.68 examples/s]Tokenizing train dataset:   4%|▎         | 320/8564 [00:04<01:41, 81.21 examples/s]Tokenizing train dataset:   5%|▍         | 411/8564 [00:04<01:40, 81.00 examples/s]Tokenizing train dataset:   4%|▍         | 360/8564 [00:04<01:46, 77.37 examples/s]Tokenizing train dataset:   4%|▍         | 332/8564 [00:04<01:33, 88.26 examples/s]Tokenizing train dataset:   4%|▍         | 372/8564 [00:04<01:44, 78.51 examples/s]Tokenizing train dataset:   5%|▍         | 421/8564 [00:04<01:59, 67.87 examples/s]Tokenizing train dataset:   4%|▍         | 344/8564 [00:04<01:32, 88.53 examples/s]Tokenizing train dataset:   5%|▌         | 432/8564 [00:05<01:47, 75.43 examples/s]Tokenizing train dataset:   4%|▍         | 385/8564 [00:04<01:51, 73.41 examples/s]Tokenizing train dataset:   4%|▍         | 357/8564 [00:04<01:40, 81.48 examples/s]Tokenizing train dataset:   5%|▌         | 444/8564 [00:05<01:37, 83.44 examples/s]Tokenizing train dataset:   5%|▍         | 393/8564 [00:05<02:02, 66.66 examples/s]Tokenizing train dataset:   4%|▍         | 368/8564 [00:04<01:36, 84.51 examples/s]Tokenizing train dataset:   5%|▌         | 458/8564 [00:05<01:28, 91.87 examples/s]Tokenizing train dataset:   5%|▍         | 401/8564 [00:05<02:06, 64.57 examples/s]Tokenizing train dataset:   4%|▍         | 381/8564 [00:04<01:29, 91.61 examples/s]Tokenizing train dataset:   5%|▌         | 470/8564 [00:05<01:24, 95.31 examples/s]Tokenizing train dataset:   5%|▍         | 391/8564 [00:04<01:29, 91.81 examples/s]Tokenizing train dataset:   6%|▌         | 486/8564 [00:05<01:18, 103.24 examples/s]Tokenizing train dataset:   5%|▍         | 410/8564 [00:05<02:11, 62.10 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:05<02:00, 67.47 examples/s]Tokenizing train dataset:   5%|▍         | 402/8564 [00:05<01:43, 78.70 examples/s]Tokenizing train dataset:   6%|▌         | 501/8564 [00:05<01:24, 95.46 examples/s] Tokenizing train dataset:   5%|▌         | 431/8564 [00:05<01:47, 75.84 examples/s]Tokenizing train dataset:   5%|▍         | 411/8564 [00:05<01:47, 75.99 examples/s]Tokenizing train dataset:   6%|▌         | 511/8564 [00:05<01:26, 93.04 examples/s]Tokenizing train dataset:   5%|▌         | 444/8564 [00:05<01:40, 81.06 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:05<01:51, 73.19 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:06<01:34, 84.92 examples/s]Tokenizing train dataset:   5%|▌         | 458/8564 [00:05<01:34, 86.20 examples/s]Tokenizing train dataset:   5%|▌         | 430/8564 [00:05<01:56, 69.68 examples/s]Tokenizing train dataset:   6%|▌         | 533/8564 [00:06<01:38, 81.54 examples/s]Tokenizing train dataset:   6%|▌         | 476/8564 [00:05<01:15, 107.16 examples/s]Tokenizing train dataset:   5%|▌         | 439/8564 [00:05<01:52, 72.29 examples/s]Tokenizing train dataset:   6%|▋         | 542/8564 [00:06<01:45, 75.74 examples/s]Tokenizing train dataset:   6%|▌         | 490/8564 [00:06<01:21, 99.20 examples/s] Tokenizing train dataset:   5%|▌         | 449/8564 [00:05<01:44, 77.55 examples/s]Tokenizing train dataset:   6%|▋         | 550/8564 [00:06<01:55, 69.39 examples/s]Tokenizing train dataset:   6%|▌         | 503/8564 [00:06<01:22, 97.50 examples/s]Tokenizing train dataset:   5%|▌         | 461/8564 [00:05<01:40, 80.26 examples/s]Tokenizing train dataset:   7%|▋         | 559/8564 [00:06<01:51, 71.51 examples/s]Tokenizing train dataset:   6%|▌         | 474/8564 [00:06<01:29, 90.06 examples/s]Tokenizing train dataset:   6%|▌         | 517/8564 [00:06<01:26, 93.15 examples/s]Tokenizing train dataset:   7%|▋         | 567/8564 [00:06<01:54, 69.85 examples/s]Tokenizing train dataset:   6%|▌         | 487/8564 [00:06<01:33, 86.78 examples/s]Tokenizing train dataset:   6%|▌         | 529/8564 [00:06<01:25, 93.92 examples/s]Tokenizing train dataset:   7%|▋         | 578/8564 [00:06<01:59, 66.73 examples/s]Tokenizing train dataset:   6%|▌         | 497/8564 [00:06<01:31, 87.81 examples/s]Tokenizing train dataset:   6%|▋         | 542/8564 [00:06<01:20, 100.12 examples/s]Tokenizing train dataset:   7%|▋         | 586/8564 [00:06<02:04, 64.06 examples/s]Tokenizing train dataset:   6%|▌         | 510/8564 [00:06<01:34, 85.42 examples/s]Tokenizing train dataset:   7%|▋         | 557/8564 [00:06<01:23, 96.36 examples/s] Tokenizing train dataset:   6%|▌         | 523/8564 [00:06<01:24, 94.95 examples/s]Tokenizing train dataset:   7%|▋         | 571/8564 [00:06<01:18, 101.84 examples/s]Tokenizing train dataset:   7%|▋         | 597/8564 [00:07<02:07, 62.67 examples/s]Tokenizing train dataset:   7%|▋         | 585/8564 [00:07<01:16, 104.78 examples/s]Tokenizing train dataset:   7%|▋         | 607/8564 [00:07<01:56, 68.37 examples/s]Tokenizing train dataset:   6%|▌         | 534/8564 [00:06<01:37, 82.29 examples/s]Tokenizing train dataset:   7%|▋         | 620/8564 [00:07<01:40, 78.77 examples/s]Tokenizing train dataset:   7%|▋         | 599/8564 [00:07<01:19, 99.74 examples/s] Tokenizing train dataset:   6%|▋         | 545/8564 [00:06<01:44, 77.06 examples/s]Tokenizing train dataset:   7%|▋         | 635/8564 [00:07<01:24, 93.73 examples/s]Tokenizing train dataset:   7%|▋         | 610/8564 [00:07<01:22, 96.07 examples/s]Tokenizing train dataset:   6%|▋         | 556/8564 [00:07<01:44, 76.64 examples/s]Tokenizing train dataset:   7%|▋         | 621/8564 [00:07<01:20, 98.59 examples/s]Tokenizing train dataset:   8%|▊         | 650/8564 [00:07<01:25, 93.06 examples/s]Tokenizing train dataset:   7%|▋         | 565/8564 [00:07<01:45, 75.82 examples/s]Tokenizing train dataset:   7%|▋         | 633/8564 [00:07<01:21, 97.39 examples/s]Tokenizing train dataset:   8%|▊         | 661/8564 [00:07<01:35, 82.86 examples/s]Tokenizing train dataset:   7%|▋         | 573/8564 [00:07<01:52, 71.18 examples/s]Tokenizing train dataset:   8%|▊         | 643/8564 [00:07<01:30, 87.93 examples/s]Tokenizing train dataset:   7%|▋         | 586/8564 [00:07<01:42, 77.46 examples/s]Tokenizing train dataset:   8%|▊         | 673/8564 [00:08<01:45, 75.05 examples/s]Tokenizing train dataset:   8%|▊         | 652/8564 [00:07<01:35, 83.19 examples/s]Tokenizing train dataset:   7%|▋         | 597/8564 [00:07<01:43, 76.84 examples/s]Tokenizing train dataset:   8%|▊         | 685/8564 [00:08<01:34, 83.02 examples/s]Tokenizing train dataset:   8%|▊         | 661/8564 [00:08<01:43, 76.24 examples/s]Tokenizing train dataset:   8%|▊         | 670/8564 [00:08<01:42, 76.79 examples/s]Tokenizing train dataset:   8%|▊         | 697/8564 [00:08<01:41, 77.54 examples/s]Tokenizing train dataset:   7%|▋         | 611/8564 [00:07<01:46, 74.34 examples/s]Tokenizing train dataset:   8%|▊         | 682/8564 [00:08<01:33, 84.12 examples/s]Tokenizing train dataset:   7%|▋         | 622/8564 [00:07<01:44, 75.87 examples/s]Tokenizing train dataset:   8%|▊         | 709/8564 [00:08<01:44, 75.40 examples/s]Tokenizing train dataset:   8%|▊         | 721/8564 [00:08<01:32, 84.37 examples/s]Tokenizing train dataset:   8%|▊         | 692/8564 [00:08<01:49, 72.03 examples/s]Tokenizing train dataset:   7%|▋         | 636/8564 [00:08<01:36, 82.22 examples/s]Tokenizing train dataset:   9%|▊         | 735/8564 [00:08<01:21, 95.56 examples/s]Tokenizing train dataset:   9%|▉         | 751/8564 [00:08<01:11, 108.75 examples/s]Tokenizing train dataset:   8%|▊         | 700/8564 [00:08<02:15, 58.04 examples/s]Tokenizing train dataset:   8%|▊         | 647/8564 [00:08<01:56, 67.95 examples/s]Tokenizing train dataset:   8%|▊         | 725/8564 [00:08<01:21, 96.15 examples/s]Tokenizing train dataset:   8%|▊         | 655/8564 [00:08<02:00, 65.63 examples/s]Tokenizing train dataset:   9%|▉         | 766/8564 [00:09<01:23, 93.56 examples/s] Tokenizing train dataset:   9%|▊         | 747/8564 [00:08<01:03, 123.32 examples/s]Tokenizing train dataset:   9%|▉         | 764/8564 [00:08<00:59, 131.83 examples/s]Tokenizing train dataset:   8%|▊         | 665/8564 [00:08<02:10, 60.68 examples/s]Tokenizing train dataset:   9%|▉         | 778/8564 [00:09<01:45, 73.84 examples/s]Tokenizing train dataset:   8%|▊         | 675/8564 [00:08<01:58, 66.67 examples/s]Tokenizing train dataset:   9%|▉         | 784/8564 [00:09<01:07, 114.78 examples/s]Tokenizing train dataset:   8%|▊         | 688/8564 [00:08<01:41, 77.67 examples/s]Tokenizing train dataset:   9%|▉         | 787/8564 [00:09<01:57, 66.39 examples/s]Tokenizing train dataset:   9%|▉         | 798/8564 [00:09<01:13, 105.30 examples/s]Tokenizing train dataset:   8%|▊         | 700/8564 [00:09<01:45, 74.42 examples/s]Tokenizing train dataset:   9%|▉         | 798/8564 [00:09<02:07, 60.86 examples/s]Tokenizing train dataset:   9%|▉         | 813/8564 [00:09<01:16, 101.02 examples/s]Tokenizing train dataset:   8%|▊         | 713/8564 [00:09<01:34, 83.14 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:09<01:19, 98.11 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:09<02:14, 57.71 examples/s]Tokenizing train dataset:  10%|▉         | 826/8564 [00:09<01:21, 94.81 examples/s] Tokenizing train dataset:   9%|▊         | 741/8564 [00:09<01:18, 99.69 examples/s]Tokenizing train dataset:  10%|▉         | 815/8564 [00:09<02:04, 62.43 examples/s]Tokenizing train dataset:  10%|▉         | 841/8564 [00:09<01:22, 93.76 examples/s]Tokenizing train dataset:   9%|▉         | 753/8564 [00:09<01:17, 100.55 examples/s]Tokenizing train dataset:  10%|▉         | 852/8564 [00:09<01:22, 93.30 examples/s]Tokenizing train dataset:  10%|▉         | 823/8564 [00:10<02:19, 55.65 examples/s]Tokenizing train dataset:   9%|▉         | 769/8564 [00:09<01:19, 98.01 examples/s] Tokenizing train dataset:  10%|█         | 865/8564 [00:10<01:17, 99.46 examples/s]Tokenizing train dataset:  10%|▉         | 831/8564 [00:10<02:12, 58.47 examples/s]Tokenizing train dataset:  10%|█         | 876/8564 [00:10<01:19, 97.07 examples/s]Tokenizing train dataset:  10%|▉         | 840/8564 [00:10<02:03, 62.70 examples/s]Tokenizing train dataset:   9%|▉         | 782/8564 [00:09<01:24, 92.52 examples/s]Tokenizing train dataset:  10%|█         | 892/8564 [00:10<01:10, 108.07 examples/s]Tokenizing train dataset:   9%|▉         | 792/8564 [00:09<01:25, 90.61 examples/s]Tokenizing train dataset:  10%|▉         | 847/8564 [00:10<02:20, 54.84 examples/s]Tokenizing train dataset:  11%|█         | 907/8564 [00:10<01:08, 112.43 examples/s]Tokenizing train dataset:   9%|▉         | 804/8564 [00:10<01:23, 93.45 examples/s]Tokenizing train dataset:  10%|█         | 857/8564 [00:10<02:01, 63.49 examples/s]Tokenizing train dataset:  10%|▉         | 814/8564 [00:10<01:21, 94.67 examples/s]Tokenizing train dataset:  11%|█         | 921/8564 [00:10<01:18, 97.85 examples/s] Tokenizing train dataset:  10%|█         | 867/8564 [00:10<02:20, 54.83 examples/s]Tokenizing train dataset:  11%|█         | 932/8564 [00:10<01:18, 96.86 examples/s]Tokenizing train dataset:  10%|▉         | 826/8564 [00:10<01:38, 78.67 examples/s]Tokenizing train dataset:  10%|█         | 878/8564 [00:11<01:59, 64.11 examples/s]Tokenizing train dataset:  11%|█         | 943/8564 [00:10<01:30, 83.92 examples/s]Tokenizing train dataset:  10%|█         | 894/8564 [00:11<01:34, 81.48 examples/s]Tokenizing train dataset:  10%|▉         | 841/8564 [00:10<01:40, 76.63 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:11<01:37, 78.35 examples/s]Tokenizing train dataset:  11%|█         | 908/8564 [00:11<01:21, 94.13 examples/s]Tokenizing train dataset:  10%|▉         | 852/8564 [00:10<01:33, 82.11 examples/s]Tokenizing train dataset:  11%|█         | 961/8564 [00:11<01:40, 75.47 examples/s]Tokenizing train dataset:  10%|█         | 865/8564 [00:10<01:27, 88.17 examples/s]Tokenizing train dataset:  11%|█         | 921/8564 [00:11<01:28, 86.77 examples/s]Tokenizing train dataset:  11%|█▏        | 969/8564 [00:11<01:45, 71.96 examples/s]Tokenizing train dataset:  10%|█         | 876/8564 [00:10<01:27, 87.43 examples/s]Tokenizing train dataset:  11%|█         | 931/8564 [00:11<01:26, 87.83 examples/s]Tokenizing train dataset:  10%|█         | 892/8564 [00:11<01:14, 102.91 examples/s]Tokenizing train dataset:  11%|█▏        | 980/8564 [00:11<01:52, 67.28 examples/s]Tokenizing train dataset:  11%|█         | 943/8564 [00:11<01:45, 72.44 examples/s]Tokenizing train dataset:  11%|█         | 907/8564 [00:11<01:22, 92.87 examples/s] Tokenizing train dataset:  12%|█▏        | 991/8564 [00:11<01:48, 69.50 examples/s]Tokenizing train dataset:  12%|█▏        | 1001/8564 [00:11<01:43, 73.02 examples/s]Tokenizing train dataset:  11%|█         | 955/8564 [00:11<01:50, 69.05 examples/s]Tokenizing train dataset:  11%|█         | 917/8564 [00:11<01:37, 78.72 examples/s]Tokenizing train dataset:  11%|█▏        | 966/8564 [00:12<01:43, 73.28 examples/s]Tokenizing train dataset:  11%|█         | 930/8564 [00:11<01:31, 83.56 examples/s]Tokenizing train dataset:  12%|█▏        | 1012/8564 [00:11<01:53, 66.72 examples/s]Tokenizing train dataset:  11%|█▏        | 976/8564 [00:12<01:41, 74.82 examples/s]Tokenizing train dataset:  12%|█▏        | 1023/8564 [00:12<01:46, 70.92 examples/s]Tokenizing train dataset:  11%|█         | 939/8564 [00:11<01:47, 70.64 examples/s]Tokenizing train dataset:  12%|█▏        | 1032/8564 [00:12<01:40, 74.68 examples/s]Tokenizing train dataset:  12%|█▏        | 985/8564 [00:12<01:54, 66.36 examples/s]Tokenizing train dataset:  11%|█         | 950/8564 [00:11<01:41, 75.27 examples/s]Tokenizing train dataset:  12%|█▏        | 994/8564 [00:12<01:49, 69.24 examples/s]Tokenizing train dataset:  12%|█▏        | 1041/8564 [00:12<01:50, 68.05 examples/s]Tokenizing train dataset:  12%|█▏        | 1003/8564 [00:12<01:49, 69.25 examples/s]Tokenizing train dataset:  11%|█         | 961/8564 [00:12<01:51, 68.47 examples/s]Tokenizing train dataset:  12%|█▏        | 1051/8564 [00:12<01:40, 74.45 examples/s]Tokenizing train dataset:  12%|█▏        | 1011/8564 [00:12<01:52, 67.20 examples/s]Tokenizing train dataset:  11%|█▏        | 970/8564 [00:12<01:50, 68.80 examples/s]Tokenizing train dataset:  12%|█▏        | 1062/8564 [00:12<01:35, 78.83 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:12<01:31, 82.22 examples/s]Tokenizing train dataset:  12%|█▏        | 1020/8564 [00:12<01:52, 67.22 examples/s]Tokenizing train dataset:  11%|█▏        | 980/8564 [00:12<02:00, 62.95 examples/s]Tokenizing train dataset:  13%|█▎        | 1085/8564 [00:12<01:23, 89.55 examples/s]Tokenizing train dataset:  12%|█▏        | 1027/8564 [00:13<02:01, 61.82 examples/s]Tokenizing train dataset:  12%|█▏        | 991/8564 [00:12<01:57, 64.36 examples/s]Tokenizing train dataset:  13%|█▎        | 1099/8564 [00:12<01:18, 94.54 examples/s]Tokenizing train dataset:  12%|█▏        | 1036/8564 [00:13<02:03, 60.78 examples/s]Tokenizing train dataset:  12%|█▏        | 1000/8564 [00:12<01:54, 66.18 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:13<01:23, 89.60 examples/s]Tokenizing train dataset:  12%|█▏        | 1010/8564 [00:12<01:45, 71.29 examples/s]Tokenizing train dataset:  12%|█▏        | 1047/8564 [00:13<02:03, 60.89 examples/s]Tokenizing train dataset:  12%|█▏        | 1056/8564 [00:13<01:55, 65.27 examples/s]Tokenizing train dataset:  13%|█▎        | 1120/8564 [00:13<01:43, 72.24 examples/s]Tokenizing train dataset:  12%|█▏        | 1022/8564 [00:12<01:41, 74.58 examples/s]Tokenizing train dataset:  12%|█▏        | 1067/8564 [00:13<01:42, 73.39 examples/s]Tokenizing train dataset:  13%|█▎        | 1132/8564 [00:13<01:42, 72.55 examples/s]Tokenizing train dataset:  12%|█▏        | 1031/8564 [00:13<01:49, 68.62 examples/s]Tokenizing train dataset:  13%|█▎        | 1144/8564 [00:13<01:34, 78.46 examples/s]Tokenizing train dataset:  12%|█▏        | 1039/8564 [00:13<01:49, 68.45 examples/s]Tokenizing train dataset:  13%|█▎        | 1079/8564 [00:13<01:58, 62.98 examples/s]Tokenizing train dataset:  13%|█▎        | 1155/8564 [00:13<01:33, 79.53 examples/s]Tokenizing train dataset:  12%|█▏        | 1046/8564 [00:13<01:57, 64.06 examples/s]Tokenizing train dataset:  13%|█▎        | 1090/8564 [00:13<01:47, 69.24 examples/s]Tokenizing train dataset:  14%|█▎        | 1164/8564 [00:13<01:35, 77.73 examples/s]Tokenizing train dataset:  12%|█▏        | 1055/8564 [00:13<01:52, 66.75 examples/s]Tokenizing train dataset:  13%|█▎        | 1098/8564 [00:14<01:49, 68.36 examples/s]Tokenizing train dataset:  12%|█▏        | 1067/8564 [00:13<01:38, 76.19 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:14<01:33, 78.70 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:14<01:46, 69.87 examples/s]Tokenizing train dataset:  13%|█▎        | 1080/8564 [00:13<01:27, 85.06 examples/s]Tokenizing train dataset:  14%|█▍        | 1191/8564 [00:14<01:24, 87.32 examples/s]Tokenizing train dataset:  13%|█▎        | 1120/8564 [00:14<01:45, 70.84 examples/s]Tokenizing train dataset:  13%|█▎        | 1092/8564 [00:13<01:21, 91.82 examples/s]Tokenizing train dataset:  14%|█▍        | 1202/8564 [00:14<01:27, 84.21 examples/s]Tokenizing train dataset:  13%|█▎        | 1128/8564 [00:14<01:46, 69.52 examples/s]Tokenizing train dataset:  13%|█▎        | 1104/8564 [00:13<01:21, 91.42 examples/s]Tokenizing train dataset:  14%|█▍        | 1214/8564 [00:14<01:33, 78.63 examples/s]Tokenizing train dataset:  13%|█▎        | 1114/8564 [00:14<01:25, 87.18 examples/s]Tokenizing train dataset:  13%|█▎        | 1140/8564 [00:14<01:51, 66.79 examples/s]Tokenizing train dataset:  14%|█▍        | 1226/8564 [00:14<01:26, 85.00 examples/s]Tokenizing train dataset:  13%|█▎        | 1149/8564 [00:14<01:49, 67.79 examples/s]Tokenizing train dataset:  14%|█▍        | 1240/8564 [00:14<01:19, 91.80 examples/s]Tokenizing train dataset:  13%|█▎        | 1126/8564 [00:14<01:48, 68.86 examples/s]Tokenizing train dataset:  13%|█▎        | 1156/8564 [00:14<01:57, 63.18 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:14<01:19, 91.74 examples/s]Tokenizing train dataset:  13%|█▎        | 1136/8564 [00:14<01:56, 64.00 examples/s]Tokenizing train dataset:  14%|█▎        | 1168/8564 [00:15<01:53, 65.12 examples/s]Tokenizing train dataset:  15%|█▍        | 1263/8564 [00:15<01:24, 85.97 examples/s]Tokenizing train dataset:  13%|█▎        | 1147/8564 [00:14<01:44, 71.03 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:15<01:42, 71.96 examples/s]Tokenizing train dataset:  15%|█▍        | 1273/8564 [00:15<01:23, 87.07 examples/s]Tokenizing train dataset:  14%|█▎        | 1158/8564 [00:14<01:45, 70.28 examples/s]Tokenizing train dataset:  14%|█▍        | 1191/8564 [00:15<01:34, 78.33 examples/s]Tokenizing train dataset:  15%|█▍        | 1282/8564 [00:15<01:27, 83.70 examples/s]Tokenizing train dataset:  14%|█▍        | 1200/8564 [00:15<01:31, 80.27 examples/s]Tokenizing train dataset:  14%|█▎        | 1167/8564 [00:14<01:45, 69.81 examples/s]Tokenizing train dataset:  15%|█▌        | 1292/8564 [00:15<01:28, 82.39 examples/s]Tokenizing train dataset:  14%|█▎        | 1176/8564 [00:15<01:47, 69.00 examples/s]Tokenizing train dataset:  14%|█▍        | 1211/8564 [00:15<01:34, 77.48 examples/s]Tokenizing train dataset:  15%|█▌        | 1304/8564 [00:15<01:26, 83.73 examples/s]Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:15<01:32, 79.09 examples/s]Tokenizing train dataset:  14%|█▍        | 1188/8564 [00:15<01:39, 74.10 examples/s]Tokenizing train dataset:  15%|█▌        | 1313/8564 [00:15<01:30, 80.11 examples/s]Tokenizing train dataset:  14%|█▍        | 1199/8564 [00:15<01:36, 76.70 examples/s]Tokenizing train dataset:  14%|█▍        | 1237/8564 [00:15<01:24, 86.77 examples/s]Tokenizing train dataset:  15%|█▌        | 1323/8564 [00:15<01:44, 69.02 examples/s]Tokenizing train dataset:  15%|█▍        | 1247/8564 [00:16<01:22, 89.23 examples/s]Tokenizing train dataset:  14%|█▍        | 1210/8564 [00:15<01:31, 80.68 examples/s]Tokenizing train dataset:  16%|█▌        | 1334/8564 [00:15<01:34, 76.15 examples/s]Tokenizing train dataset:  14%|█▍        | 1228/8564 [00:15<01:11, 102.13 examples/s]Tokenizing train dataset:  15%|█▍        | 1257/8564 [00:16<01:34, 77.50 examples/s]Tokenizing train dataset:  14%|█▍        | 1241/8564 [00:15<01:09, 105.91 examples/s]Tokenizing train dataset:  16%|█▌        | 1346/8564 [00:16<01:39, 72.37 examples/s]Tokenizing train dataset:  15%|█▍        | 1270/8564 [00:16<01:26, 84.36 examples/s]Tokenizing train dataset:  15%|█▍        | 1252/8564 [00:15<01:10, 104.20 examples/s]Tokenizing train dataset:  15%|█▍        | 1280/8564 [00:16<01:25, 85.65 examples/s]Tokenizing train dataset:  15%|█▍        | 1265/8564 [00:15<01:08, 106.05 examples/s]Tokenizing train dataset:  16%|█▌        | 1357/8564 [00:16<01:58, 60.94 examples/s]Tokenizing train dataset:  15%|█▌        | 1290/8564 [00:16<01:27, 83.15 examples/s]Tokenizing train dataset:  16%|█▌        | 1365/8564 [00:16<01:57, 61.46 examples/s]Tokenizing train dataset:  15%|█▍        | 1279/8564 [00:16<01:16, 95.77 examples/s] Tokenizing train dataset:  15%|█▌        | 1303/8564 [00:16<01:17, 93.25 examples/s]Tokenizing train dataset:  15%|█▌        | 1314/8564 [00:16<01:18, 91.95 examples/s]Tokenizing train dataset:  16%|█▌        | 1372/8564 [00:16<02:13, 53.77 examples/s]Tokenizing train dataset:  15%|█▌        | 1298/8564 [00:16<01:14, 97.48 examples/s]Tokenizing train dataset:  16%|█▌        | 1333/8564 [00:16<01:02, 114.98 examples/s]Tokenizing train dataset:  16%|█▌        | 1379/8564 [00:16<02:07, 56.21 examples/s]Tokenizing train dataset:  15%|█▌        | 1311/8564 [00:16<01:21, 88.95 examples/s]Tokenizing train dataset:  16%|█▌        | 1348/8564 [00:17<01:06, 108.52 examples/s]Tokenizing train dataset:  16%|█▌        | 1388/8564 [00:16<02:08, 55.93 examples/s]Tokenizing train dataset:  16%|█▋        | 1397/8564 [00:17<01:57, 61.03 examples/s]Tokenizing train dataset:  15%|█▌        | 1325/8564 [00:16<01:33, 77.59 examples/s]Tokenizing train dataset:  16%|█▌        | 1362/8564 [00:17<01:19, 90.67 examples/s] Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:17<01:57, 60.74 examples/s]Tokenizing train dataset:  16%|█▌        | 1372/8564 [00:17<01:21, 88.39 examples/s]Tokenizing train dataset:  16%|█▌        | 1337/8564 [00:16<01:36, 74.69 examples/s]Tokenizing train dataset:  17%|█▋        | 1416/8564 [00:17<01:50, 64.55 examples/s]Tokenizing train dataset:  16%|█▌        | 1385/8564 [00:17<01:16, 93.43 examples/s]Tokenizing train dataset:  16%|█▌        | 1346/8564 [00:17<01:45, 68.55 examples/s]Tokenizing train dataset:  16%|█▋        | 1400/8564 [00:17<01:24, 85.22 examples/s]Tokenizing train dataset:  17%|█▋        | 1428/8564 [00:17<02:01, 58.81 examples/s]Tokenizing train dataset:  16%|█▌        | 1354/8564 [00:17<01:58, 61.02 examples/s]Tokenizing train dataset:  17%|█▋        | 1437/8564 [00:17<01:54, 62.20 examples/s]Tokenizing train dataset:  16%|█▌        | 1361/8564 [00:17<01:59, 60.50 examples/s]Tokenizing train dataset:  16%|█▋        | 1413/8564 [00:17<01:31, 77.89 examples/s]Tokenizing train dataset:  17%|█▋        | 1448/8564 [00:17<01:44, 68.31 examples/s]Tokenizing train dataset:  16%|█▌        | 1370/8564 [00:17<02:06, 56.76 examples/s]Tokenizing train dataset:  17%|█▋        | 1422/8564 [00:18<01:41, 70.04 examples/s]Tokenizing train dataset:  17%|█▋        | 1456/8564 [00:17<01:41, 70.09 examples/s]Tokenizing train dataset:  16%|█▌        | 1377/8564 [00:17<02:03, 57.96 examples/s]Tokenizing train dataset:  17%|█▋        | 1433/8564 [00:18<01:34, 75.16 examples/s]Tokenizing train dataset:  17%|█▋        | 1464/8564 [00:18<01:42, 68.96 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:17<01:52, 63.98 examples/s]Tokenizing train dataset:  17%|█▋        | 1442/8564 [00:18<01:31, 77.85 examples/s]Tokenizing train dataset:  17%|█▋        | 1476/8564 [00:18<01:45, 67.00 examples/s]Tokenizing train dataset:  17%|█▋        | 1454/8564 [00:18<01:25, 83.52 examples/s]Tokenizing train dataset:  16%|█▋        | 1394/8564 [00:17<01:54, 62.70 examples/s]Tokenizing train dataset:  17%|█▋        | 1465/8564 [00:18<01:22, 85.99 examples/s]Tokenizing train dataset:  17%|█▋        | 1483/8564 [00:18<02:00, 58.71 examples/s]Tokenizing train dataset:  16%|█▋        | 1405/8564 [00:18<01:57, 60.75 examples/s]Tokenizing train dataset:  17%|█▋        | 1495/8564 [00:18<01:49, 64.62 examples/s]Tokenizing train dataset:  16%|█▋        | 1413/8564 [00:18<01:55, 61.84 examples/s]Tokenizing train dataset:  17%|█▋        | 1479/8564 [00:18<01:30, 78.04 examples/s]Tokenizing train dataset:  18%|█▊        | 1505/8564 [00:18<01:41, 69.67 examples/s]Tokenizing train dataset:  17%|█▋        | 1421/8564 [00:18<01:52, 63.59 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:18<01:30, 77.57 examples/s]Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:19<01:48, 65.50 examples/s]Tokenizing train dataset:  17%|█▋        | 1428/8564 [00:18<02:01, 58.60 examples/s]Tokenizing train dataset:  18%|█▊        | 1538/8564 [00:18<01:04, 108.13 examples/s]Tokenizing train dataset:  18%|█▊        | 1499/8564 [00:19<01:49, 64.55 examples/s]Tokenizing train dataset:  17%|█▋        | 1437/8564 [00:18<02:09, 55.06 examples/s]Tokenizing train dataset:  18%|█▊        | 1507/8564 [00:19<01:46, 66.01 examples/s]Tokenizing train dataset:  18%|█▊        | 1551/8564 [00:19<01:21, 86.05 examples/s] Tokenizing train dataset:  17%|█▋        | 1446/8564 [00:18<02:01, 58.46 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:19<01:40, 70.46 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:19<01:31, 76.38 examples/s]Tokenizing train dataset:  18%|█▊        | 1534/8564 [00:19<01:17, 90.90 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:18<02:14, 53.02 examples/s]Tokenizing train dataset:  17%|█▋        | 1462/8564 [00:19<01:58, 59.99 examples/s]Tokenizing train dataset:  18%|█▊        | 1573/8564 [00:19<01:37, 71.47 examples/s]Tokenizing train dataset:  18%|█▊        | 1547/8564 [00:19<01:26, 81.14 examples/s]Tokenizing train dataset:  17%|█▋        | 1473/8564 [00:19<01:41, 69.63 examples/s]Tokenizing train dataset:  18%|█▊        | 1581/8564 [00:19<01:42, 68.39 examples/s]Tokenizing train dataset:  17%|█▋        | 1481/8564 [00:19<01:39, 71.01 examples/s]Tokenizing train dataset:  18%|█▊        | 1558/8564 [00:19<01:36, 72.72 examples/s]Tokenizing train dataset:  17%|█▋        | 1491/8564 [00:19<01:31, 77.01 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:19<01:44, 66.60 examples/s]Tokenizing train dataset:  18%|█▊        | 1566/8564 [00:20<01:43, 67.81 examples/s]Tokenizing train dataset:  18%|█▊        | 1504/8564 [00:19<01:18, 90.48 examples/s]Tokenizing train dataset:  19%|█▊        | 1600/8564 [00:19<01:52, 61.79 examples/s]Tokenizing train dataset:  18%|█▊        | 1574/8564 [00:20<01:42, 68.04 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:19<01:15, 93.03 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:20<01:43, 67.47 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:19<01:09, 101.61 examples/s]Tokenizing train dataset:  19%|█▊        | 1586/8564 [00:20<01:42, 67.95 examples/s]Tokenizing train dataset:  18%|█▊        | 1541/8564 [00:19<01:08, 102.50 examples/s]Tokenizing train dataset:  19%|█▉        | 1619/8564 [00:20<01:44, 66.20 examples/s]Tokenizing train dataset:  19%|█▊        | 1598/8564 [00:20<01:29, 78.16 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:20<01:22, 84.37 examples/s]Tokenizing train dataset:  18%|█▊        | 1555/8564 [00:20<01:17, 90.20 examples/s] Tokenizing train dataset:  19%|█▉        | 1629/8564 [00:20<01:53, 61.10 examples/s]Tokenizing train dataset:  18%|█▊        | 1567/8564 [00:20<01:14, 93.88 examples/s]Tokenizing train dataset:  19%|█▉        | 1640/8564 [00:20<01:40, 68.92 examples/s]Tokenizing train dataset:  19%|█▉        | 1620/8564 [00:20<01:33, 74.04 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:20<01:32, 74.60 examples/s]Tokenizing train dataset:  18%|█▊        | 1580/8564 [00:20<01:18, 88.78 examples/s]Tokenizing train dataset:  19%|█▉        | 1630/8564 [00:20<01:38, 70.71 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:20<01:25, 80.88 examples/s]Tokenizing train dataset:  19%|█▊        | 1593/8564 [00:20<01:14, 93.20 examples/s]Tokenizing train dataset:  19%|█▉        | 1639/8564 [00:21<01:37, 71.24 examples/s]Tokenizing train dataset:  20%|█▉        | 1676/8564 [00:20<01:20, 85.78 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:20<01:06, 103.85 examples/s]Tokenizing train dataset:  19%|█▉        | 1649/8564 [00:21<01:35, 72.18 examples/s]Tokenizing train dataset:  20%|█▉        | 1687/8564 [00:21<01:15, 90.88 examples/s]Tokenizing train dataset:  19%|█▉        | 1658/8564 [00:21<01:32, 74.54 examples/s]Tokenizing train dataset:  20%|█▉        | 1704/8564 [00:21<01:02, 109.87 examples/s]Tokenizing train dataset:  19%|█▉        | 1626/8564 [00:20<01:17, 89.62 examples/s] Tokenizing train dataset:  20%|█▉        | 1670/8564 [00:21<01:21, 85.00 examples/s]Tokenizing train dataset:  20%|██        | 1721/8564 [00:21<01:02, 109.17 examples/s]Tokenizing train dataset:  19%|█▉        | 1636/8564 [00:20<01:20, 86.02 examples/s]Tokenizing train dataset:  20%|█▉        | 1680/8564 [00:21<01:24, 81.06 examples/s]Tokenizing train dataset:  19%|█▉        | 1649/8564 [00:21<01:14, 92.35 examples/s]Tokenizing train dataset:  20%|█▉        | 1696/8564 [00:21<01:09, 98.88 examples/s]Tokenizing train dataset:  20%|██        | 1737/8564 [00:21<01:09, 98.57 examples/s] Tokenizing train dataset:  19%|█▉        | 1659/8564 [00:21<01:19, 87.05 examples/s]Tokenizing train dataset:  20%|█▉        | 1709/8564 [00:21<01:11, 95.56 examples/s]Tokenizing train dataset:  20%|██        | 1749/8564 [00:21<01:09, 97.87 examples/s]Tokenizing train dataset:  19%|█▉        | 1669/8564 [00:21<01:17, 88.44 examples/s]Tokenizing train dataset:  21%|██        | 1760/8564 [00:21<01:11, 94.74 examples/s]Tokenizing train dataset:  20%|██        | 1720/8564 [00:21<01:25, 80.17 examples/s]Tokenizing train dataset:  20%|█▉        | 1681/8564 [00:21<01:15, 90.60 examples/s]Tokenizing train dataset:  21%|██        | 1770/8564 [00:21<01:11, 94.86 examples/s]Tokenizing train dataset:  20%|█▉        | 1691/8564 [00:21<01:18, 87.13 examples/s]Tokenizing train dataset:  20%|██        | 1729/8564 [00:22<01:35, 71.31 examples/s]Tokenizing train dataset:  21%|██        | 1783/8564 [00:21<01:08, 99.00 examples/s]Tokenizing train dataset:  20%|█▉        | 1708/8564 [00:21<01:05, 105.39 examples/s]Tokenizing train dataset:  21%|██        | 1795/8564 [00:22<01:06, 101.44 examples/s]Tokenizing train dataset:  20%|██        | 1737/8564 [00:22<01:38, 69.27 examples/s]Tokenizing train dataset:  20%|██        | 1722/8564 [00:21<01:08, 100.04 examples/s]Tokenizing train dataset:  20%|██        | 1747/8564 [00:22<01:36, 70.44 examples/s]Tokenizing train dataset:  21%|██        | 1811/8564 [00:22<01:05, 102.51 examples/s]Tokenizing train dataset:  21%|██        | 1757/8564 [00:22<01:32, 73.48 examples/s]Tokenizing train dataset:  20%|██        | 1736/8564 [00:21<01:12, 94.02 examples/s] Tokenizing train dataset:  21%|██▏       | 1827/8564 [00:22<01:09, 97.12 examples/s] Tokenizing train dataset:  20%|██        | 1751/8564 [00:22<01:05, 104.79 examples/s]Tokenizing train dataset:  21%|██        | 1766/8564 [00:22<01:45, 64.57 examples/s]Tokenizing train dataset:  21%|██▏       | 1839/8564 [00:22<01:10, 95.59 examples/s]Tokenizing train dataset:  21%|██        | 1768/8564 [00:22<01:00, 111.46 examples/s]Tokenizing train dataset:  21%|██        | 1775/8564 [00:22<01:55, 59.02 examples/s]Tokenizing train dataset:  22%|██▏       | 1853/8564 [00:22<01:13, 90.76 examples/s]Tokenizing train dataset:  21%|██        | 1785/8564 [00:22<01:06, 102.02 examples/s]Tokenizing train dataset:  22%|██▏       | 1864/8564 [00:22<01:13, 90.96 examples/s]Tokenizing train dataset:  21%|██        | 1782/8564 [00:23<02:00, 56.42 examples/s]Tokenizing train dataset:  21%|██        | 1798/8564 [00:22<01:06, 101.65 examples/s]Tokenizing train dataset:  21%|██        | 1790/8564 [00:23<01:51, 60.48 examples/s]Tokenizing train dataset:  22%|██▏       | 1876/8564 [00:23<01:23, 79.95 examples/s]Tokenizing train dataset:  21%|██        | 1809/8564 [00:22<01:06, 101.61 examples/s]Tokenizing train dataset:  21%|██        | 1799/8564 [00:23<01:43, 65.23 examples/s]Tokenizing train dataset:  21%|██▏       | 1820/8564 [00:22<01:08, 98.82 examples/s] Tokenizing train dataset:  21%|██        | 1806/8564 [00:23<01:44, 64.39 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:23<01:37, 68.53 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:22<01:06, 100.79 examples/s]Tokenizing train dataset:  21%|██        | 1817/8564 [00:23<01:34, 71.44 examples/s]Tokenizing train dataset:  22%|██▏       | 1899/8564 [00:23<01:35, 69.62 examples/s]Tokenizing train dataset:  21%|██▏       | 1830/8564 [00:23<01:21, 83.00 examples/s]Tokenizing train dataset:  22%|██▏       | 1848/8564 [00:23<01:17, 86.93 examples/s] Tokenizing train dataset:  22%|██▏       | 1850/8564 [00:23<01:00, 110.83 examples/s]Tokenizing train dataset:  22%|██▏       | 1910/8564 [00:23<01:29, 73.94 examples/s]Tokenizing train dataset:  22%|██▏       | 1868/8564 [00:23<00:59, 112.28 examples/s]Tokenizing train dataset:  22%|██▏       | 1921/8564 [00:23<01:31, 72.48 examples/s]Tokenizing train dataset:  22%|██▏       | 1859/8564 [00:23<01:36, 69.46 examples/s]Tokenizing train dataset:  23%|██▎       | 1934/8564 [00:23<01:20, 82.57 examples/s]Tokenizing train dataset:  22%|██▏       | 1886/8564 [00:24<01:01, 108.99 examples/s]Tokenizing train dataset:  22%|██▏       | 1867/8564 [00:23<01:40, 66.56 examples/s]Tokenizing train dataset:  23%|██▎       | 1947/8564 [00:23<01:12, 91.08 examples/s]Tokenizing train dataset:  23%|██▎       | 1959/8564 [00:24<01:08, 96.06 examples/s]Tokenizing train dataset:  22%|██▏       | 1877/8564 [00:23<01:44, 63.96 examples/s]Tokenizing train dataset:  22%|██▏       | 1900/8564 [00:24<01:11, 93.72 examples/s] Tokenizing train dataset:  23%|██▎       | 1972/8564 [00:24<01:04, 102.73 examples/s]Tokenizing train dataset:  22%|██▏       | 1915/8564 [00:24<01:05, 102.01 examples/s]Tokenizing train dataset:  22%|██▏       | 1888/8564 [00:23<01:47, 62.13 examples/s]Tokenizing train dataset:  23%|██▎       | 1988/8564 [00:24<01:06, 99.23 examples/s] Tokenizing train dataset:  23%|██▎       | 1934/8564 [00:24<01:03, 104.80 examples/s]Tokenizing train dataset:  22%|██▏       | 1895/8564 [00:23<01:49, 61.17 examples/s]Tokenizing train dataset:  23%|██▎       | 2000/8564 [00:24<01:06, 98.65 examples/s]Tokenizing train dataset:  22%|██▏       | 1912/8564 [00:24<01:23, 79.50 examples/s]Tokenizing train dataset:  24%|██▎       | 2014/8564 [00:24<01:01, 107.06 examples/s]Tokenizing train dataset:  23%|██▎       | 1948/8564 [00:24<01:12, 91.89 examples/s] Tokenizing train dataset:  22%|██▏       | 1922/8564 [00:24<01:28, 75.15 examples/s]Tokenizing train dataset:  24%|██▎       | 2031/8564 [00:24<00:56, 116.21 examples/s]Tokenizing train dataset:  23%|██▎       | 1960/8564 [00:24<01:18, 84.20 examples/s]Tokenizing train dataset:  23%|██▎       | 1936/8564 [00:24<01:15, 88.36 examples/s]Tokenizing train dataset:  24%|██▍       | 2046/8564 [00:24<00:53, 122.17 examples/s]Tokenizing train dataset:  23%|██▎       | 1946/8564 [00:24<01:13, 90.17 examples/s]Tokenizing train dataset:  23%|██▎       | 1969/8564 [00:25<01:21, 81.08 examples/s]Tokenizing train dataset:  24%|██▍       | 2059/8564 [00:24<00:53, 122.57 examples/s]Tokenizing train dataset:  23%|██▎       | 1957/8564 [00:24<01:11, 92.80 examples/s]Tokenizing train dataset:  23%|██▎       | 1978/8564 [00:25<01:22, 79.96 examples/s]Tokenizing train dataset:  24%|██▍       | 2072/8564 [00:24<00:54, 119.92 examples/s]Tokenizing train dataset:  24%|██▍       | 2088/8564 [00:25<00:51, 126.44 examples/s]Tokenizing train dataset:  23%|██▎       | 1970/8564 [00:24<01:15, 87.66 examples/s]Tokenizing train dataset:  23%|██▎       | 1988/8564 [00:25<01:29, 73.70 examples/s]Tokenizing train dataset:  25%|██▍       | 2101/8564 [00:25<00:51, 126.01 examples/s]Tokenizing train dataset:  23%|██▎       | 2001/8564 [00:25<01:16, 85.36 examples/s]Tokenizing train dataset:  23%|██▎       | 1980/8564 [00:24<01:18, 83.83 examples/s]Tokenizing train dataset:  25%|██▍       | 2115/8564 [00:25<00:58, 110.57 examples/s]Tokenizing train dataset:  24%|██▎       | 2016/8564 [00:25<01:13, 89.48 examples/s]Tokenizing train dataset:  23%|██▎       | 1989/8564 [00:25<01:28, 74.50 examples/s]Tokenizing train dataset:  25%|██▍       | 2127/8564 [00:25<00:58, 109.96 examples/s]Tokenizing train dataset:  24%|██▎       | 2027/8564 [00:25<01:10, 92.77 examples/s]Tokenizing train dataset:  23%|██▎       | 1999/8564 [00:25<01:27, 74.83 examples/s]Tokenizing train dataset:  24%|██▍       | 2040/8564 [00:25<01:05, 99.08 examples/s]Tokenizing train dataset:  25%|██▍       | 2140/8564 [00:25<01:09, 91.97 examples/s] Tokenizing train dataset:  23%|██▎       | 2008/8564 [00:25<01:28, 73.72 examples/s]Tokenizing train dataset:  24%|██▍       | 2056/8564 [00:25<01:01, 105.94 examples/s]Tokenizing train dataset:  25%|██▌       | 2150/8564 [00:25<01:13, 87.21 examples/s]Tokenizing train dataset:  24%|██▎       | 2019/8564 [00:25<01:25, 76.55 examples/s]Tokenizing train dataset:  24%|██▍       | 2067/8564 [00:26<01:02, 104.66 examples/s]Tokenizing train dataset:  25%|██▌       | 2160/8564 [00:25<01:15, 85.38 examples/s]Tokenizing train dataset:  24%|██▎       | 2029/8564 [00:25<01:23, 77.89 examples/s]Tokenizing train dataset:  25%|██▌       | 2176/8564 [00:26<01:02, 101.57 examples/s]Tokenizing train dataset:  24%|██▍       | 2079/8564 [00:26<01:14, 87.05 examples/s] Tokenizing train dataset:  24%|██▍       | 2044/8564 [00:25<01:13, 89.19 examples/s]Tokenizing train dataset:  24%|██▍       | 2092/8564 [00:26<01:07, 95.61 examples/s]Tokenizing train dataset:  24%|██▍       | 2059/8564 [00:25<01:03, 103.18 examples/s]Tokenizing train dataset:  26%|██▌       | 2190/8564 [00:26<01:11, 89.38 examples/s] Tokenizing train dataset:  25%|██▍       | 2104/8564 [00:26<01:03, 101.26 examples/s]Tokenizing train dataset:  24%|██▍       | 2076/8564 [00:25<01:02, 104.10 examples/s]Tokenizing train dataset:  25%|██▍       | 2121/8564 [00:26<00:54, 118.52 examples/s]Tokenizing train dataset:  24%|██▍       | 2091/8564 [00:26<00:59, 109.24 examples/s]Tokenizing train dataset:  26%|██▌       | 2201/8564 [00:26<01:29, 70.70 examples/s]Tokenizing train dataset:  25%|██▍       | 2109/8564 [00:26<00:51, 124.78 examples/s]Tokenizing train dataset:  25%|██▍       | 2140/8564 [00:26<01:01, 104.97 examples/s]Tokenizing train dataset:  25%|██▌       | 2161/8564 [00:26<00:50, 125.64 examples/s]Tokenizing train dataset:  26%|██▌       | 2213/8564 [00:26<01:37, 64.92 examples/s]Tokenizing train dataset:  25%|██▍       | 2126/8564 [00:26<00:56, 114.67 examples/s]Tokenizing train dataset:  26%|██▌       | 2225/8564 [00:26<01:25, 74.11 examples/s]Tokenizing train dataset:  25%|██▌       | 2180/8564 [00:27<00:53, 118.86 examples/s]Tokenizing train dataset:  26%|██▌       | 2236/8564 [00:26<01:18, 81.06 examples/s]Tokenizing train dataset:  25%|██▍       | 2139/8564 [00:26<01:07, 94.93 examples/s] Tokenizing train dataset:  26%|██▌       | 2199/8564 [00:27<00:48, 131.82 examples/s]Tokenizing train dataset:  26%|██▌       | 2246/8564 [00:27<01:14, 84.24 examples/s]Tokenizing train dataset:  25%|██▌       | 2155/8564 [00:26<01:08, 93.15 examples/s]Tokenizing train dataset:  26%|██▌       | 2218/8564 [00:27<00:49, 128.99 examples/s]Tokenizing train dataset:  26%|██▋       | 2256/8564 [00:27<01:16, 82.84 examples/s]Tokenizing train dataset:  25%|██▌       | 2168/8564 [00:26<01:05, 97.01 examples/s]Tokenizing train dataset:  26%|██▌       | 2232/8564 [00:27<00:49, 127.25 examples/s]Tokenizing train dataset:  26%|██▋       | 2268/8564 [00:27<01:12, 86.26 examples/s]Tokenizing train dataset:  25%|██▌       | 2180/8564 [00:26<01:05, 97.57 examples/s]Tokenizing train dataset:  27%|██▋       | 2278/8564 [00:27<01:15, 83.51 examples/s]Tokenizing train dataset:  26%|██▌       | 2200/8564 [00:27<00:54, 117.55 examples/s]Tokenizing train dataset:  26%|██▋       | 2250/8564 [00:27<01:00, 105.21 examples/s]Tokenizing train dataset:  27%|██▋       | 2289/8564 [00:27<01:13, 85.11 examples/s]Tokenizing train dataset:  26%|██▋       | 2263/8564 [00:27<00:57, 109.15 examples/s]Tokenizing train dataset:  27%|██▋       | 2300/8564 [00:27<01:10, 89.12 examples/s]Tokenizing train dataset:  26%|██▌       | 2217/8564 [00:27<01:00, 105.49 examples/s]Tokenizing train dataset:  27%|██▋       | 2280/8564 [00:27<00:52, 120.69 examples/s]Tokenizing train dataset:  27%|██▋       | 2316/8564 [00:27<01:09, 89.91 examples/s]Tokenizing train dataset:  26%|██▌       | 2233/8564 [00:27<01:04, 98.28 examples/s] Tokenizing train dataset:  27%|██▋       | 2300/8564 [00:28<00:53, 116.91 examples/s]Tokenizing train dataset:  27%|██▋       | 2330/8564 [00:27<01:03, 98.70 examples/s]Tokenizing train dataset:  26%|██▌       | 2246/8564 [00:27<01:09, 91.09 examples/s]Tokenizing train dataset:  27%|██▋       | 2344/8564 [00:28<00:59, 103.89 examples/s]Tokenizing train dataset:  27%|██▋       | 2315/8564 [00:28<01:02, 99.66 examples/s] Tokenizing train dataset:  28%|██▊       | 2357/8564 [00:28<00:59, 104.39 examples/s]Tokenizing train dataset:  26%|██▋       | 2260/8564 [00:27<01:14, 84.25 examples/s]Tokenizing train dataset:  28%|██▊       | 2370/8564 [00:28<00:57, 108.38 examples/s]Tokenizing train dataset:  27%|██▋       | 2330/8564 [00:28<01:07, 92.37 examples/s]Tokenizing train dataset:  27%|██▋       | 2273/8564 [00:27<01:11, 88.59 examples/s]Tokenizing train dataset:  28%|██▊       | 2388/8564 [00:28<00:56, 109.99 examples/s]Tokenizing train dataset:  27%|██▋       | 2342/8564 [00:28<01:13, 84.84 examples/s]Tokenizing train dataset:  27%|██▋       | 2289/8564 [00:28<01:10, 88.77 examples/s]Tokenizing train dataset:  28%|██▊       | 2401/8564 [00:28<00:55, 111.42 examples/s]Tokenizing train dataset:  27%|██▋       | 2300/8564 [00:28<01:10, 88.30 examples/s]Tokenizing train dataset:  27%|██▋       | 2354/8564 [00:28<01:22, 75.71 examples/s]Tokenizing train dataset:  28%|██▊       | 2413/8564 [00:28<00:58, 105.86 examples/s]Tokenizing train dataset:  28%|██▊       | 2428/8564 [00:28<00:53, 115.67 examples/s]Tokenizing train dataset:  28%|██▊       | 2365/8564 [00:28<01:24, 73.75 examples/s]Tokenizing train dataset:  27%|██▋       | 2311/8564 [00:28<01:25, 73.40 examples/s]Tokenizing train dataset:  29%|██▊       | 2448/8564 [00:28<00:46, 132.50 examples/s]Tokenizing train dataset:  28%|██▊       | 2379/8564 [00:29<01:13, 83.85 examples/s]Tokenizing train dataset:  29%|██▉       | 2468/8564 [00:29<00:42, 144.19 examples/s]Tokenizing train dataset:  27%|██▋       | 2321/8564 [00:28<01:30, 68.92 examples/s]Tokenizing train dataset:  28%|██▊       | 2391/8564 [00:29<01:10, 87.49 examples/s]Tokenizing train dataset:  27%|██▋       | 2331/8564 [00:28<01:23, 74.89 examples/s]Tokenizing train dataset:  29%|██▉       | 2487/8564 [00:29<00:46, 130.31 examples/s]Tokenizing train dataset:  28%|██▊       | 2402/8564 [00:29<01:09, 88.49 examples/s]Tokenizing train dataset:  27%|██▋       | 2342/8564 [00:28<01:25, 72.46 examples/s]Tokenizing train dataset:  29%|██▉       | 2506/8564 [00:29<00:51, 117.78 examples/s]Tokenizing train dataset:  28%|██▊       | 2420/8564 [00:29<01:16, 80.69 examples/s]Tokenizing train dataset:  28%|██▊       | 2357/8564 [00:29<01:13, 84.05 examples/s]Tokenizing train dataset:  28%|██▊       | 2438/8564 [00:29<01:01, 99.30 examples/s]Tokenizing train dataset:  28%|██▊       | 2370/8564 [00:29<01:12, 84.99 examples/s]Tokenizing train dataset:  29%|██▉       | 2521/8564 [00:29<01:01, 97.76 examples/s] Tokenizing train dataset:  29%|██▊       | 2462/8564 [00:29<00:48, 125.27 examples/s]Tokenizing train dataset:  28%|██▊       | 2381/8564 [00:29<01:09, 88.97 examples/s]Tokenizing train dataset:  30%|██▉       | 2532/8564 [00:29<01:03, 94.53 examples/s]Tokenizing train dataset:  29%|██▉       | 2479/8564 [00:29<00:48, 125.54 examples/s]Tokenizing train dataset:  30%|██▉       | 2544/8564 [00:29<01:02, 96.49 examples/s]Tokenizing train dataset:  28%|██▊       | 2396/8564 [00:29<01:10, 87.69 examples/s]Tokenizing train dataset:  29%|██▉       | 2493/8564 [00:30<00:49, 122.97 examples/s]Tokenizing train dataset:  28%|██▊       | 2410/8564 [00:29<01:04, 96.15 examples/s]Tokenizing train dataset:  30%|██▉       | 2556/8564 [00:29<01:04, 92.95 examples/s]Tokenizing train dataset:  29%|██▉       | 2508/8564 [00:30<00:53, 112.23 examples/s]Tokenizing train dataset:  28%|██▊       | 2426/8564 [00:29<00:56, 109.57 examples/s]Tokenizing train dataset:  30%|███       | 2570/8564 [00:30<01:05, 91.49 examples/s]Tokenizing train dataset:  28%|██▊       | 2438/8564 [00:29<00:56, 108.52 examples/s]Tokenizing train dataset:  29%|██▉       | 2521/8564 [00:30<01:00, 99.46 examples/s] Tokenizing train dataset:  30%|███       | 2580/8564 [00:30<01:06, 89.64 examples/s]Tokenizing train dataset:  29%|██▊       | 2452/8564 [00:29<00:54, 111.62 examples/s]Tokenizing train dataset:  29%|██▉       | 2474/8564 [00:30<00:45, 134.86 examples/s]Tokenizing train dataset:  30%|███       | 2591/8564 [00:30<01:15, 78.97 examples/s]Tokenizing train dataset:  30%|██▉       | 2534/8564 [00:30<01:10, 85.49 examples/s]Tokenizing train dataset:  30%|███       | 2606/8564 [00:30<01:03, 93.86 examples/s]Tokenizing train dataset:  30%|██▉       | 2546/8564 [00:30<01:07, 89.43 examples/s]Tokenizing train dataset:  29%|██▉       | 2492/8564 [00:30<00:51, 118.81 examples/s]Tokenizing train dataset:  31%|███       | 2617/8564 [00:30<01:02, 94.99 examples/s]Tokenizing train dataset:  30%|██▉       | 2561/8564 [00:30<01:15, 79.39 examples/s]Tokenizing train dataset:  29%|██▉       | 2510/8564 [00:30<00:54, 111.70 examples/s]Tokenizing train dataset:  31%|███       | 2628/8564 [00:30<01:17, 76.88 examples/s]Tokenizing train dataset:  30%|███       | 2575/8564 [00:31<01:07, 89.20 examples/s]Tokenizing train dataset:  30%|██▉       | 2528/8564 [00:30<00:53, 112.57 examples/s]Tokenizing train dataset:  31%|███       | 2639/8564 [00:30<01:12, 81.50 examples/s]Tokenizing train dataset:  30%|███       | 2589/8564 [00:31<01:06, 89.36 examples/s]Tokenizing train dataset:  31%|███       | 2653/8564 [00:31<01:13, 79.96 examples/s]Tokenizing train dataset:  30%|███       | 2601/8564 [00:31<01:03, 93.77 examples/s]Tokenizing train dataset:  30%|██▉       | 2544/8564 [00:30<01:02, 96.86 examples/s] Tokenizing train dataset:  31%|███       | 2666/8564 [00:31<01:08, 85.51 examples/s]Tokenizing train dataset:  31%|███       | 2614/8564 [00:31<01:01, 96.94 examples/s]Tokenizing train dataset:  30%|██▉       | 2558/8564 [00:30<00:59, 101.14 examples/s]Tokenizing train dataset:  30%|██▉       | 2569/8564 [00:31<01:00, 99.47 examples/s] Tokenizing train dataset:  31%|███       | 2625/8564 [00:31<01:09, 85.00 examples/s]Tokenizing train dataset:  31%|███▏      | 2677/8564 [00:31<01:19, 73.94 examples/s]Tokenizing train dataset:  31%|███       | 2637/8564 [00:31<01:04, 91.53 examples/s]Tokenizing train dataset:  30%|███       | 2583/8564 [00:31<01:07, 88.74 examples/s]Tokenizing train dataset:  31%|███▏      | 2687/8564 [00:31<01:19, 74.27 examples/s]Tokenizing train dataset:  31%|███       | 2647/8564 [00:31<01:06, 89.26 examples/s]Tokenizing train dataset:  31%|███▏      | 2696/8564 [00:31<01:20, 73.21 examples/s]Tokenizing train dataset:  30%|███       | 2598/8564 [00:31<01:11, 83.25 examples/s]Tokenizing train dataset:  31%|███       | 2658/8564 [00:32<01:11, 82.71 examples/s]Tokenizing train dataset:  32%|███▏      | 2708/8564 [00:31<01:13, 80.08 examples/s]Tokenizing train dataset:  30%|███       | 2608/8564 [00:31<01:11, 83.19 examples/s]Tokenizing train dataset:  32%|███▏      | 2720/8564 [00:32<01:07, 86.67 examples/s]Tokenizing train dataset:  31%|███       | 2670/8564 [00:32<01:13, 80.40 examples/s]Tokenizing train dataset:  32%|███▏      | 2731/8564 [00:32<01:03, 92.01 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:31<01:12, 82.24 examples/s]Tokenizing train dataset:  31%|███▏      | 2681/8564 [00:32<01:22, 71.42 examples/s]Tokenizing train dataset:  31%|███       | 2631/8564 [00:31<01:12, 82.32 examples/s]Tokenizing train dataset:  32%|███▏      | 2746/8564 [00:32<01:04, 89.81 examples/s]Tokenizing train dataset:  31%|███▏      | 2694/8564 [00:32<01:14, 79.11 examples/s]Tokenizing train dataset:  31%|███       | 2645/8564 [00:31<01:06, 89.08 examples/s]Tokenizing train dataset:  32%|███▏      | 2760/8564 [00:32<01:06, 87.63 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:32<01:10, 83.12 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:32<01:10, 83.89 examples/s]Tokenizing train dataset:  32%|███▏      | 2771/8564 [00:32<01:06, 86.97 examples/s]Tokenizing train dataset:  32%|███▏      | 2715/8564 [00:32<01:12, 80.17 examples/s]Tokenizing train dataset:  33%|███▎      | 2788/8564 [00:32<00:58, 98.05 examples/s]Tokenizing train dataset:  32%|███▏      | 2724/8564 [00:32<01:16, 76.44 examples/s]Tokenizing train dataset:  31%|███       | 2671/8564 [00:32<01:16, 76.53 examples/s]Tokenizing train dataset:  33%|███▎      | 2801/8564 [00:32<00:57, 100.15 examples/s]Tokenizing train dataset:  32%|███▏      | 2732/8564 [00:33<01:20, 72.41 examples/s]Tokenizing train dataset:  31%|███▏      | 2679/8564 [00:32<01:20, 73.19 examples/s]Tokenizing train dataset:  32%|███▏      | 2741/8564 [00:33<01:17, 74.76 examples/s]Tokenizing train dataset:  31%|███▏      | 2692/8564 [00:32<01:11, 82.43 examples/s]Tokenizing train dataset:  33%|███▎      | 2816/8564 [00:32<00:56, 101.20 examples/s]Tokenizing train dataset:  32%|███▏      | 2703/8564 [00:32<01:07, 86.59 examples/s]Tokenizing train dataset:  32%|███▏      | 2752/8564 [00:33<01:14, 77.99 examples/s]Tokenizing train dataset:  33%|███▎      | 2829/8564 [00:33<00:57, 100.36 examples/s]Tokenizing train dataset:  32%|███▏      | 2715/8564 [00:32<01:02, 93.31 examples/s]Tokenizing train dataset:  32%|███▏      | 2763/8564 [00:33<01:10, 82.61 examples/s]Tokenizing train dataset:  33%|███▎      | 2840/8564 [00:33<00:56, 101.49 examples/s]Tokenizing train dataset:  32%|███▏      | 2726/8564 [00:32<01:00, 96.53 examples/s]Tokenizing train dataset:  32%|███▏      | 2776/8564 [00:33<01:10, 81.84 examples/s]Tokenizing train dataset:  33%|███▎      | 2856/8564 [00:33<01:04, 88.43 examples/s] Tokenizing train dataset:  32%|███▏      | 2737/8564 [00:33<01:04, 91.01 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:33<01:10, 81.91 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:33<01:05, 87.18 examples/s]Tokenizing train dataset:  33%|███▎      | 2796/8564 [00:33<01:08, 84.09 examples/s]Tokenizing train dataset:  32%|███▏      | 2749/8564 [00:33<01:12, 80.30 examples/s]Tokenizing train dataset:  34%|███▎      | 2886/8564 [00:33<00:52, 107.45 examples/s]Tokenizing train dataset:  34%|███▍      | 2907/8564 [00:33<00:44, 126.03 examples/s]Tokenizing train dataset:  33%|███▎      | 2808/8564 [00:33<01:17, 74.75 examples/s]Tokenizing train dataset:  32%|███▏      | 2762/8564 [00:33<01:20, 72.25 examples/s]Tokenizing train dataset:  33%|███▎      | 2817/8564 [00:34<01:15, 75.81 examples/s]Tokenizing train dataset:  32%|███▏      | 2781/8564 [00:33<01:01, 93.75 examples/s]Tokenizing train dataset:  34%|███▍      | 2923/8564 [00:34<00:52, 106.96 examples/s]Tokenizing train dataset:  33%|███▎      | 2826/8564 [00:34<01:18, 73.03 examples/s]Tokenizing train dataset:  33%|███▎      | 2797/8564 [00:33<00:55, 104.51 examples/s]Tokenizing train dataset:  34%|███▍      | 2936/8564 [00:34<00:50, 111.62 examples/s]Tokenizing train dataset:  33%|███▎      | 2810/8564 [00:33<00:52, 109.90 examples/s]Tokenizing train dataset:  33%|███▎      | 2834/8564 [00:34<01:21, 70.06 examples/s]Tokenizing train dataset:  34%|███▍      | 2953/8564 [00:34<00:46, 119.69 examples/s]Tokenizing train dataset:  33%|███▎      | 2843/8564 [00:34<01:21, 70.29 examples/s]Tokenizing train dataset:  33%|███▎      | 2828/8564 [00:33<00:51, 111.85 examples/s]Tokenizing train dataset:  35%|███▍      | 2968/8564 [00:34<00:46, 119.67 examples/s]Tokenizing train dataset:  33%|███▎      | 2851/8564 [00:34<01:24, 67.27 examples/s]Tokenizing train dataset:  35%|███▍      | 2987/8564 [00:34<00:41, 134.87 examples/s]Tokenizing train dataset:  33%|███▎      | 2843/8564 [00:34<00:56, 100.70 examples/s]Tokenizing train dataset:  33%|███▎      | 2860/8564 [00:34<01:24, 67.60 examples/s]Tokenizing train dataset:  33%|███▎      | 2855/8564 [00:34<00:57, 100.15 examples/s]Tokenizing train dataset:  34%|███▎      | 2870/8564 [00:34<01:17, 73.94 examples/s]Tokenizing train dataset:  35%|███▌      | 3006/8564 [00:34<00:53, 103.19 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:34<00:57, 99.33 examples/s] Tokenizing train dataset:  34%|███▎      | 2881/8564 [00:35<01:16, 73.94 examples/s]Tokenizing train dataset:  35%|███▌      | 3019/8564 [00:34<00:52, 105.96 examples/s]Tokenizing train dataset:  34%|███▎      | 2880/8564 [00:34<00:56, 100.29 examples/s]Tokenizing train dataset:  35%|███▌      | 3032/8564 [00:34<00:51, 107.51 examples/s]Tokenizing train dataset:  34%|███▍      | 2894/8564 [00:35<01:08, 83.00 examples/s]Tokenizing train dataset:  34%|███▍      | 2899/8564 [00:34<00:47, 118.29 examples/s]Tokenizing train dataset:  36%|███▌      | 3045/8564 [00:35<00:51, 107.11 examples/s]Tokenizing train dataset:  34%|███▍      | 2906/8564 [00:35<01:06, 85.13 examples/s]Tokenizing train dataset:  34%|███▍      | 2914/8564 [00:34<00:46, 121.68 examples/s]Tokenizing train dataset:  34%|███▍      | 2929/8564 [00:34<00:45, 122.94 examples/s]Tokenizing train dataset:  36%|███▌      | 3065/8564 [00:35<00:50, 108.85 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:35<01:07, 83.44 examples/s]Tokenizing train dataset:  34%|███▍      | 2945/8564 [00:34<00:42, 131.34 examples/s]Tokenizing train dataset:  36%|███▌      | 3080/8564 [00:35<00:48, 112.28 examples/s]Tokenizing train dataset:  34%|███▍      | 2931/8564 [00:35<01:16, 73.60 examples/s]Tokenizing train dataset:  35%|███▍      | 2960/8564 [00:35<00:43, 129.60 examples/s]Tokenizing train dataset:  36%|███▌      | 3093/8564 [00:35<00:48, 111.79 examples/s]Tokenizing train dataset:  35%|███▍      | 2977/8564 [00:35<00:40, 137.48 examples/s]Tokenizing train dataset:  34%|███▍      | 2943/8564 [00:35<01:11, 78.29 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:35<00:47, 114.97 examples/s]Tokenizing train dataset:  34%|███▍      | 2954/8564 [00:35<01:10, 79.68 examples/s]Tokenizing train dataset:  35%|███▍      | 2991/8564 [00:35<00:49, 111.71 examples/s]Tokenizing train dataset:  37%|███▋      | 3126/8564 [00:35<00:53, 101.98 examples/s]Tokenizing train dataset:  35%|███▍      | 2964/8564 [00:36<01:10, 79.39 examples/s]Tokenizing train dataset:  35%|███▌      | 3008/8564 [00:35<00:53, 103.91 examples/s]Tokenizing train dataset:  37%|███▋      | 3137/8564 [00:35<00:54, 99.86 examples/s] Tokenizing train dataset:  35%|███▍      | 2980/8564 [00:36<00:58, 94.68 examples/s]Tokenizing train dataset:  35%|███▌      | 3022/8564 [00:35<00:51, 106.78 examples/s]Tokenizing train dataset:  35%|███▍      | 2995/8564 [00:36<00:53, 103.92 examples/s]Tokenizing train dataset:  37%|███▋      | 3150/8564 [00:36<01:03, 84.88 examples/s]Tokenizing train dataset:  35%|███▌      | 3035/8564 [00:35<00:49, 110.68 examples/s]Tokenizing train dataset:  35%|███▌      | 3008/8564 [00:36<00:51, 108.73 examples/s]Tokenizing train dataset:  36%|███▌      | 3047/8564 [00:35<00:50, 108.61 examples/s]Tokenizing train dataset:  37%|███▋      | 3163/8564 [00:36<01:00, 89.00 examples/s]Tokenizing train dataset:  35%|███▌      | 3020/8564 [00:36<00:51, 107.68 examples/s]Tokenizing train dataset:  36%|███▌      | 3060/8564 [00:36<00:49, 110.26 examples/s]Tokenizing train dataset:  35%|███▌      | 3033/8564 [00:36<00:52, 106.20 examples/s]Tokenizing train dataset:  36%|███▌      | 3072/8564 [00:36<00:49, 111.03 examples/s]Tokenizing train dataset:  37%|███▋      | 3174/8564 [00:36<01:16, 70.47 examples/s]Tokenizing train dataset:  36%|███▌      | 3047/8564 [00:36<01:01, 89.95 examples/s] Tokenizing train dataset:  36%|███▌      | 3086/8564 [00:36<00:49, 111.06 examples/s]Tokenizing train dataset:  37%|███▋      | 3185/8564 [00:36<01:13, 73.15 examples/s]Tokenizing train dataset:  36%|███▌      | 3099/8564 [00:36<00:50, 109.21 examples/s]Tokenizing train dataset:  37%|███▋      | 3195/8564 [00:36<01:12, 73.90 examples/s]Tokenizing train dataset:  36%|███▌      | 3060/8564 [00:37<01:06, 82.33 examples/s]Tokenizing train dataset:  36%|███▋      | 3112/8564 [00:36<00:49, 110.16 examples/s]Tokenizing train dataset:  37%|███▋      | 3206/8564 [00:36<01:09, 77.06 examples/s]Tokenizing train dataset:  36%|███▌      | 3074/8564 [00:37<01:01, 88.89 examples/s]Tokenizing train dataset:  38%|███▊      | 3221/8564 [00:37<00:59, 90.44 examples/s]Tokenizing train dataset:  36%|███▌      | 3084/8564 [00:37<01:01, 88.41 examples/s]Tokenizing train dataset:  37%|███▋      | 3126/8564 [00:36<00:59, 90.75 examples/s] Tokenizing train dataset:  38%|███▊      | 3234/8564 [00:37<00:53, 99.64 examples/s]Tokenizing train dataset:  37%|███▋      | 3136/8564 [00:36<01:01, 88.15 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:37<01:03, 85.70 examples/s]Tokenizing train dataset:  38%|███▊      | 3250/8564 [00:37<00:46, 113.57 examples/s]Tokenizing train dataset:  38%|███▊      | 3263/8564 [00:37<00:48, 110.09 examples/s]Tokenizing train dataset:  37%|███▋      | 3153/8564 [00:37<01:00, 90.12 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:37<01:10, 77.73 examples/s]Tokenizing train dataset:  38%|███▊      | 3277/8564 [00:37<00:46, 114.61 examples/s]Tokenizing train dataset:  37%|███▋      | 3167/8564 [00:37<01:05, 81.87 examples/s]Tokenizing train dataset:  36%|███▋      | 3123/8564 [00:37<01:10, 76.66 examples/s]Tokenizing train dataset:  38%|███▊      | 3289/8564 [00:37<00:54, 95.98 examples/s] Tokenizing train dataset:  37%|███▋      | 3177/8564 [00:37<01:05, 82.87 examples/s]Tokenizing train dataset:  37%|███▋      | 3138/8564 [00:37<01:02, 87.42 examples/s]Tokenizing train dataset:  37%|███▋      | 3189/8564 [00:37<00:59, 90.00 examples/s]Tokenizing train dataset:  37%|███▋      | 3151/8564 [00:38<00:57, 94.11 examples/s]Tokenizing train dataset:  39%|███▊      | 3300/8564 [00:37<01:05, 80.88 examples/s]Tokenizing train dataset:  37%|███▋      | 3205/8564 [00:37<00:51, 103.72 examples/s]Tokenizing train dataset:  37%|███▋      | 3169/8564 [00:38<00:48, 111.92 examples/s]Tokenizing train dataset:  39%|███▊      | 3309/8564 [00:37<01:05, 80.32 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:38<01:00, 86.83 examples/s]Tokenizing train dataset:  38%|███▊      | 3219/8564 [00:37<00:57, 92.65 examples/s] Tokenizing train dataset:  37%|███▋      | 3187/8564 [00:38<00:49, 109.54 examples/s]Tokenizing train dataset:  39%|███▉      | 3330/8564 [00:38<00:58, 89.13 examples/s]Tokenizing train dataset:  37%|███▋      | 3200/8564 [00:38<00:48, 110.12 examples/s]Tokenizing train dataset:  38%|███▊      | 3229/8564 [00:37<01:01, 87.33 examples/s]Tokenizing train dataset:  39%|███▉      | 3342/8564 [00:38<00:56, 91.70 examples/s]Tokenizing train dataset:  38%|███▊      | 3214/8564 [00:38<00:48, 110.30 examples/s]Tokenizing train dataset:  39%|███▉      | 3358/8564 [00:38<00:49, 105.14 examples/s]Tokenizing train dataset:  38%|███▊      | 3244/8564 [00:38<01:01, 86.20 examples/s]Tokenizing train dataset:  38%|███▊      | 3228/8564 [00:38<00:46, 115.95 examples/s]Tokenizing train dataset:  39%|███▉      | 3377/8564 [00:38<00:43, 118.87 examples/s]Tokenizing train dataset:  38%|███▊      | 3255/8564 [00:38<01:04, 81.72 examples/s]Tokenizing train dataset:  38%|███▊      | 3244/8564 [00:38<00:48, 109.35 examples/s]Tokenizing train dataset:  40%|███▉      | 3397/8564 [00:38<00:39, 131.43 examples/s]Tokenizing train dataset:  38%|███▊      | 3264/8564 [00:38<01:08, 77.77 examples/s]Tokenizing train dataset:  38%|███▊      | 3263/8564 [00:38<00:42, 125.27 examples/s]Tokenizing train dataset:  40%|███▉      | 3411/8564 [00:38<00:45, 114.00 examples/s]Tokenizing train dataset:  38%|███▊      | 3276/8564 [00:38<01:10, 75.46 examples/s]Tokenizing train dataset:  38%|███▊      | 3279/8564 [00:39<00:45, 117.04 examples/s]Tokenizing train dataset:  38%|███▊      | 3284/8564 [00:38<01:12, 72.84 examples/s]Tokenizing train dataset:  38%|███▊      | 3294/8564 [00:39<00:44, 118.90 examples/s]Tokenizing train dataset:  40%|███▉      | 3423/8564 [00:39<00:53, 96.48 examples/s] Tokenizing train dataset:  38%|███▊      | 3296/8564 [00:38<01:06, 78.94 examples/s]Tokenizing train dataset:  39%|███▊      | 3310/8564 [00:39<00:42, 124.25 examples/s]Tokenizing train dataset:  40%|████      | 3435/8564 [00:39<00:54, 94.61 examples/s]Tokenizing train dataset:  39%|███▊      | 3310/8564 [00:38<00:57, 90.71 examples/s]Tokenizing train dataset:  39%|███▉      | 3325/8564 [00:39<00:47, 111.33 examples/s]Tokenizing train dataset:  40%|████      | 3445/8564 [00:39<01:03, 80.68 examples/s]Tokenizing train dataset:  39%|███▉      | 3322/8564 [00:38<00:54, 96.02 examples/s]Tokenizing train dataset:  39%|███▉      | 3338/8564 [00:39<00:45, 114.68 examples/s]Tokenizing train dataset:  40%|████      | 3454/8564 [00:39<01:03, 80.09 examples/s]Tokenizing train dataset:  39%|███▉      | 3353/8564 [00:39<00:42, 122.29 examples/s]Tokenizing train dataset:  40%|████      | 3464/8564 [00:39<01:04, 79.18 examples/s]Tokenizing train dataset:  39%|███▉      | 3335/8564 [00:39<01:08, 75.98 examples/s]Tokenizing train dataset:  39%|███▉      | 3369/8564 [00:39<00:40, 128.49 examples/s]Tokenizing train dataset:  39%|███▉      | 3350/8564 [00:39<00:58, 88.90 examples/s]Tokenizing train dataset:  41%|████      | 3476/8564 [00:39<01:07, 75.89 examples/s]Tokenizing train dataset:  40%|███▉      | 3390/8564 [00:39<00:40, 128.39 examples/s]Tokenizing train dataset:  39%|███▉      | 3361/8564 [00:39<00:56, 91.58 examples/s]Tokenizing train dataset:  41%|████      | 3486/8564 [00:39<01:09, 73.27 examples/s]Tokenizing train dataset:  40%|███▉      | 3404/8564 [00:40<00:41, 125.58 examples/s]Tokenizing train dataset:  39%|███▉      | 3377/8564 [00:39<00:50, 101.79 examples/s]Tokenizing train dataset:  40%|███▉      | 3423/8564 [00:40<00:38, 135.04 examples/s]Tokenizing train dataset:  40%|███▉      | 3392/8564 [00:39<00:50, 102.07 examples/s]Tokenizing train dataset:  41%|████      | 3504/8564 [00:40<01:05, 77.73 examples/s]Tokenizing train dataset:  40%|████      | 3437/8564 [00:40<00:37, 135.93 examples/s]Tokenizing train dataset:  40%|███▉      | 3404/8564 [00:39<00:51, 100.12 examples/s]Tokenizing train dataset:  40%|████      | 3451/8564 [00:40<00:38, 132.51 examples/s]Tokenizing train dataset:  41%|████      | 3512/8564 [00:40<01:08, 73.69 examples/s]Tokenizing train dataset:  40%|███▉      | 3416/8564 [00:39<00:50, 101.08 examples/s]Tokenizing train dataset:  41%|████      | 3524/8564 [00:40<01:01, 81.58 examples/s]Tokenizing train dataset:  41%|████      | 3469/8564 [00:40<00:41, 122.57 examples/s]Tokenizing train dataset:  41%|████▏     | 3535/8564 [00:40<00:58, 86.01 examples/s]Tokenizing train dataset:  40%|████      | 3434/8564 [00:40<00:52, 97.99 examples/s] Tokenizing train dataset:  41%|████▏     | 3547/8564 [00:40<00:53, 92.92 examples/s]Tokenizing train dataset:  41%|████      | 3486/8564 [00:40<00:53, 95.15 examples/s] Tokenizing train dataset:  42%|████▏     | 3557/8564 [00:40<00:54, 92.46 examples/s]Tokenizing train dataset:  40%|████      | 3450/8564 [00:40<00:52, 98.26 examples/s]Tokenizing train dataset:  41%|████      | 3497/8564 [00:40<00:53, 94.43 examples/s]Tokenizing train dataset:  42%|████▏     | 3569/8564 [00:40<00:51, 96.44 examples/s]Tokenizing train dataset:  40%|████      | 3463/8564 [00:40<00:49, 102.47 examples/s]Tokenizing train dataset:  42%|████▏     | 3586/8564 [00:40<00:45, 108.86 examples/s]Tokenizing train dataset:  41%|████      | 3481/8564 [00:40<00:45, 111.61 examples/s]Tokenizing train dataset:  41%|████      | 3511/8564 [00:41<00:57, 88.52 examples/s]Tokenizing train dataset:  41%|████      | 3493/8564 [00:40<00:45, 112.29 examples/s]Tokenizing train dataset:  42%|████▏     | 3602/8564 [00:41<00:52, 95.33 examples/s] Tokenizing train dataset:  41%|████      | 3510/8564 [00:40<00:40, 125.84 examples/s]Tokenizing train dataset:  41%|████      | 3526/8564 [00:41<01:01, 81.89 examples/s]Tokenizing train dataset:  42%|████▏     | 3612/8564 [00:41<00:52, 94.59 examples/s]Tokenizing train dataset:  41%|████▏     | 3539/8564 [00:41<00:57, 87.84 examples/s]Tokenizing train dataset:  41%|████      | 3528/8564 [00:40<00:43, 116.05 examples/s]Tokenizing train dataset:  41%|████▏     | 3549/8564 [00:41<00:57, 87.76 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:41<00:56, 86.85 examples/s]Tokenizing train dataset:  41%|████▏     | 3543/8564 [00:41<00:46, 107.70 examples/s]Tokenizing train dataset:  42%|████▏     | 3560/8564 [00:41<00:55, 90.06 examples/s]Tokenizing train dataset:  42%|████▏     | 3638/8564 [00:41<01:02, 78.71 examples/s]Tokenizing train dataset:  42%|████▏     | 3573/8564 [00:41<00:50, 98.54 examples/s]Tokenizing train dataset:  42%|████▏     | 3566/8564 [00:41<00:44, 111.92 examples/s]Tokenizing train dataset:  42%|████▏     | 3584/8564 [00:41<00:49, 99.73 examples/s]Tokenizing train dataset:  43%|████▎     | 3648/8564 [00:41<01:09, 70.57 examples/s]Tokenizing train dataset:  42%|████▏     | 3581/8564 [00:41<00:43, 114.50 examples/s]Tokenizing train dataset:  42%|████▏     | 3595/8564 [00:42<00:52, 93.88 examples/s]Tokenizing train dataset:  42%|████▏     | 3598/8564 [00:41<00:41, 121.05 examples/s]Tokenizing train dataset:  43%|████▎     | 3658/8564 [00:41<01:09, 70.63 examples/s]Tokenizing train dataset:  42%|████▏     | 3605/8564 [00:42<00:54, 90.43 examples/s]Tokenizing train dataset:  43%|████▎     | 3672/8564 [00:42<01:06, 73.03 examples/s]Tokenizing train dataset:  42%|████▏     | 3620/8564 [00:42<00:49, 100.48 examples/s]Tokenizing train dataset:  42%|████▏     | 3615/8564 [00:41<00:50, 98.08 examples/s] Tokenizing train dataset:  42%|████▏     | 3636/8564 [00:42<00:43, 112.21 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:41<00:49, 100.65 examples/s]Tokenizing train dataset:  43%|████▎     | 3682/8564 [00:42<01:16, 64.14 examples/s]Tokenizing train dataset:  43%|████▎     | 3650/8564 [00:42<00:49, 98.90 examples/s] Tokenizing train dataset:  43%|████▎     | 3641/8564 [00:42<00:49, 99.53 examples/s] Tokenizing train dataset:  43%|████▎     | 3697/8564 [00:42<01:00, 80.05 examples/s]Tokenizing train dataset:  43%|████▎     | 3658/8564 [00:42<00:49, 99.80 examples/s]Tokenizing train dataset:  43%|████▎     | 3711/8564 [00:42<01:00, 80.37 examples/s]Tokenizing train dataset:  43%|████▎     | 3665/8564 [00:42<00:54, 89.57 examples/s]Tokenizing train dataset:  43%|████▎     | 3720/8564 [00:42<01:00, 80.13 examples/s]Tokenizing train dataset:  43%|████▎     | 3670/8564 [00:42<00:54, 89.10 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:42<00:55, 88.19 examples/s]Tokenizing train dataset:  43%|████▎     | 3700/8564 [00:43<00:45, 107.17 examples/s]Tokenizing train dataset:  44%|████▎     | 3731/8564 [00:42<01:09, 69.42 examples/s]Tokenizing train dataset:  43%|████▎     | 3692/8564 [00:42<00:48, 99.99 examples/s]Tokenizing train dataset:  43%|████▎     | 3712/8564 [00:43<00:47, 102.93 examples/s]Tokenizing train dataset:  44%|████▎     | 3739/8564 [00:43<01:10, 68.23 examples/s]Tokenizing train dataset:  43%|████▎     | 3707/8564 [00:42<00:44, 109.62 examples/s]Tokenizing train dataset:  43%|████▎     | 3725/8564 [00:42<00:39, 121.76 examples/s]Tokenizing train dataset:  44%|████▍     | 3750/8564 [00:43<01:05, 73.23 examples/s]Tokenizing train dataset:  44%|████▎     | 3728/8564 [00:43<00:49, 97.70 examples/s] Tokenizing train dataset:  44%|████▍     | 3763/8564 [00:43<01:02, 76.82 examples/s]Tokenizing train dataset:  44%|████▎     | 3742/8564 [00:42<00:42, 114.67 examples/s]Tokenizing train dataset:  44%|████▎     | 3744/8564 [00:43<00:53, 89.73 examples/s]Tokenizing train dataset:  44%|████▍     | 3754/8564 [00:43<00:41, 115.34 examples/s]Tokenizing train dataset:  44%|████▍     | 3777/8564 [00:43<01:05, 72.90 examples/s]Tokenizing train dataset:  44%|████▍     | 3773/8564 [00:43<00:42, 112.39 examples/s]Tokenizing train dataset:  44%|████▍     | 3760/8564 [00:43<00:55, 86.80 examples/s]Tokenizing train dataset:  44%|████▍     | 3788/8564 [00:43<00:59, 80.02 examples/s]Tokenizing train dataset:  44%|████▍     | 3787/8564 [00:43<00:41, 114.51 examples/s]Tokenizing train dataset:  44%|████▍     | 3800/8564 [00:43<00:53, 88.54 examples/s]Tokenizing train dataset:  44%|████▍     | 3770/8564 [00:43<00:56, 84.77 examples/s]Tokenizing train dataset:  45%|████▍     | 3814/8564 [00:43<00:47, 100.06 examples/s]Tokenizing train dataset:  44%|████▍     | 3801/8564 [00:43<00:41, 114.85 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:44<01:01, 78.22 examples/s]Tokenizing train dataset:  45%|████▍     | 3815/8564 [00:43<00:39, 119.65 examples/s]Tokenizing train dataset:  45%|████▍     | 3828/8564 [00:44<00:46, 101.36 examples/s]Tokenizing train dataset:  44%|████▍     | 3788/8564 [00:44<01:04, 74.27 examples/s]Tokenizing train dataset:  45%|████▍     | 3840/8564 [00:44<00:46, 101.80 examples/s]Tokenizing train dataset:  44%|████▍     | 3803/8564 [00:44<00:55, 85.76 examples/s]Tokenizing train dataset:  45%|████▍     | 3831/8564 [00:43<00:48, 97.03 examples/s] Tokenizing train dataset:  45%|████▍     | 3815/8564 [00:44<00:51, 91.85 examples/s]Tokenizing train dataset:  45%|████▌     | 3855/8564 [00:44<00:51, 92.28 examples/s] Tokenizing train dataset:  45%|████▍     | 3846/8564 [00:43<00:51, 91.92 examples/s]Tokenizing train dataset:  45%|████▍     | 3828/8564 [00:44<00:47, 99.65 examples/s]Tokenizing train dataset:  45%|████▌     | 3865/8564 [00:44<00:59, 79.26 examples/s]Tokenizing train dataset:  45%|████▍     | 3841/8564 [00:44<00:47, 99.09 examples/s]Tokenizing train dataset:  45%|████▌     | 3859/8564 [00:44<00:55, 84.54 examples/s]Tokenizing train dataset:  45%|████▌     | 3878/8564 [00:44<01:01, 75.62 examples/s]Tokenizing train dataset:  45%|████▌     | 3870/8564 [00:44<00:55, 85.07 examples/s]Tokenizing train dataset:  45%|████▌     | 3856/8564 [00:44<00:51, 90.71 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:44<00:59, 78.66 examples/s]Tokenizing train dataset:  45%|████▌     | 3881/8564 [00:44<00:55, 84.64 examples/s]Tokenizing train dataset:  45%|████▌     | 3868/8564 [00:45<00:51, 91.12 examples/s]Tokenizing train dataset:  45%|████▌     | 3892/8564 [00:44<00:53, 86.86 examples/s]Tokenizing train dataset:  45%|████▌     | 3878/8564 [00:45<00:52, 89.47 examples/s]Tokenizing train dataset:  46%|████▌     | 3903/8564 [00:45<01:00, 77.44 examples/s]Tokenizing train dataset:  46%|████▌     | 3902/8564 [00:44<00:52, 89.41 examples/s]Tokenizing train dataset:  46%|████▌     | 3915/8564 [00:45<00:54, 85.35 examples/s]Tokenizing train dataset:  45%|████▌     | 3892/8564 [00:45<00:52, 88.29 examples/s]Tokenizing train dataset:  46%|████▌     | 3912/8564 [00:44<00:51, 90.32 examples/s]Tokenizing train dataset:  46%|████▌     | 3928/8564 [00:45<00:49, 92.92 examples/s]Tokenizing train dataset:  46%|████▌     | 3925/8564 [00:44<00:47, 98.39 examples/s]Tokenizing train dataset:  46%|████▌     | 3902/8564 [00:45<01:01, 75.50 examples/s]Tokenizing train dataset:  46%|████▌     | 3939/8564 [00:45<00:54, 85.43 examples/s]Tokenizing train dataset:  46%|████▌     | 3938/8564 [00:45<00:46, 100.19 examples/s]Tokenizing train dataset:  46%|████▌     | 3911/8564 [00:45<01:04, 71.70 examples/s]Tokenizing train dataset:  46%|████▌     | 3951/8564 [00:45<00:51, 89.21 examples/s]Tokenizing train dataset:  46%|████▌     | 3919/8564 [00:45<01:07, 69.25 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:45<00:50, 90.91 examples/s]Tokenizing train dataset:  46%|████▌     | 3952/8564 [00:45<00:55, 82.43 examples/s] Tokenizing train dataset:  46%|████▌     | 3931/8564 [00:45<00:59, 78.48 examples/s]Tokenizing train dataset:  46%|████▋     | 3973/8564 [00:45<00:52, 87.21 examples/s]Tokenizing train dataset:  46%|████▋     | 3962/8564 [00:45<00:56, 81.26 examples/s]Tokenizing train dataset:  46%|████▌     | 3950/8564 [00:46<00:45, 100.88 examples/s]Tokenizing train dataset:  46%|████▋     | 3971/8564 [00:45<00:59, 77.68 examples/s]Tokenizing train dataset:  47%|████▋     | 3988/8564 [00:45<00:53, 85.51 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:46<00:42, 107.57 examples/s]Tokenizing train dataset:  47%|████▋     | 4002/8564 [00:46<00:47, 96.46 examples/s]Tokenizing train dataset:  46%|████▋     | 3982/8564 [00:45<01:04, 70.49 examples/s]Tokenizing train dataset:  46%|████▋     | 3975/8564 [00:46<00:49, 92.84 examples/s] Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:46<00:43, 104.11 examples/s]Tokenizing train dataset:  47%|████▋     | 3992/8564 [00:45<01:00, 75.58 examples/s]Tokenizing train dataset:  47%|████▋     | 4031/8564 [00:46<00:40, 110.77 examples/s]Tokenizing train dataset:  47%|████▋     | 3988/8564 [00:46<00:51, 88.97 examples/s]Tokenizing train dataset:  47%|████▋     | 4002/8564 [00:45<01:04, 71.17 examples/s]Tokenizing train dataset:  47%|████▋     | 3999/8564 [00:46<00:50, 90.33 examples/s]Tokenizing train dataset:  47%|████▋     | 4050/8564 [00:46<00:41, 109.71 examples/s]Tokenizing train dataset:  47%|████▋     | 4013/8564 [00:46<00:57, 78.90 examples/s]Tokenizing train dataset:  47%|████▋     | 4027/8564 [00:46<00:50, 89.89 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:46<00:44, 100.96 examples/s]Tokenizing train dataset:  47%|████▋     | 4014/8564 [00:46<00:56, 80.51 examples/s]Tokenizing train dataset:  47%|████▋     | 4039/8564 [00:46<00:47, 95.60 examples/s]Tokenizing train dataset:  47%|████▋     | 4025/8564 [00:46<00:55, 81.50 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:46<00:47, 94.82 examples/s] Tokenizing train dataset:  47%|████▋     | 4050/8564 [00:46<00:47, 95.63 examples/s]Tokenizing train dataset:  47%|████▋     | 4035/8564 [00:47<00:56, 79.63 examples/s]Tokenizing train dataset:  48%|████▊     | 4091/8564 [00:46<00:47, 93.71 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:46<00:50, 89.95 examples/s]Tokenizing train dataset:  47%|████▋     | 4044/8564 [00:47<00:55, 80.80 examples/s]Tokenizing train dataset:  48%|████▊     | 4104/8564 [00:47<00:45, 97.13 examples/s]Tokenizing train dataset:  47%|████▋     | 4058/8564 [00:47<00:50, 89.32 examples/s]Tokenizing train dataset:  48%|████▊     | 4081/8564 [00:46<00:49, 90.73 examples/s]Tokenizing train dataset:  48%|████▊     | 4070/8564 [00:47<00:46, 96.46 examples/s]Tokenizing train dataset:  48%|████▊     | 4115/8564 [00:47<00:53, 83.00 examples/s]Tokenizing train dataset:  48%|████▊     | 4092/8564 [00:46<00:47, 93.58 examples/s]Tokenizing train dataset:  48%|████▊     | 4126/8564 [00:47<00:50, 88.09 examples/s]Tokenizing train dataset:  48%|████▊     | 4081/8564 [00:47<00:49, 90.47 examples/s]Tokenizing train dataset:  48%|████▊     | 4105/8564 [00:47<00:55, 80.66 examples/s]Tokenizing train dataset:  48%|████▊     | 4139/8564 [00:47<00:55, 80.28 examples/s]Tokenizing train dataset:  48%|████▊     | 4094/8564 [00:47<00:54, 82.16 examples/s]Tokenizing train dataset:  48%|████▊     | 4115/8564 [00:47<00:53, 82.63 examples/s]Tokenizing train dataset:  48%|████▊     | 4149/8564 [00:47<00:56, 78.10 examples/s]Tokenizing train dataset:  48%|████▊     | 4105/8564 [00:47<00:53, 82.93 examples/s]Tokenizing train dataset:  48%|████▊     | 4124/8564 [00:47<00:56, 78.75 examples/s]Tokenizing train dataset:  49%|████▊     | 4158/8564 [00:47<00:57, 76.01 examples/s]Tokenizing train dataset:  48%|████▊     | 4116/8564 [00:47<00:53, 83.65 examples/s]Tokenizing train dataset:  48%|████▊     | 4133/8564 [00:47<00:58, 75.79 examples/s]Tokenizing train dataset:  49%|████▊     | 4168/8564 [00:47<00:57, 76.72 examples/s]Tokenizing train dataset:  48%|████▊     | 4126/8564 [00:48<00:55, 80.24 examples/s]Tokenizing train dataset:  48%|████▊     | 4141/8564 [00:47<00:59, 74.55 examples/s]Tokenizing train dataset:  49%|████▉     | 4179/8564 [00:48<00:53, 82.18 examples/s]Tokenizing train dataset:  48%|████▊     | 4135/8564 [00:48<00:54, 81.82 examples/s]Tokenizing train dataset:  48%|████▊     | 4152/8564 [00:47<00:56, 77.91 examples/s]Tokenizing train dataset:  49%|████▉     | 4193/8564 [00:48<00:45, 95.67 examples/s]Tokenizing train dataset:  48%|████▊     | 4146/8564 [00:48<00:50, 87.16 examples/s]Tokenizing train dataset:  49%|████▊     | 4161/8564 [00:47<00:57, 77.09 examples/s]Tokenizing train dataset:  49%|████▉     | 4207/8564 [00:48<00:40, 106.51 examples/s]Tokenizing train dataset:  49%|████▊     | 4160/8564 [00:48<00:45, 96.57 examples/s]Tokenizing train dataset:  49%|████▊     | 4170/8564 [00:47<01:01, 70.88 examples/s]Tokenizing train dataset:  49%|████▊     | 4172/8564 [00:48<00:43, 101.97 examples/s]Tokenizing train dataset:  49%|████▉     | 4223/8564 [00:48<00:41, 105.77 examples/s]Tokenizing train dataset:  49%|████▉     | 4183/8564 [00:48<00:43, 101.27 examples/s]Tokenizing train dataset:  49%|████▉     | 4182/8564 [00:48<00:55, 78.43 examples/s]Tokenizing train dataset:  49%|████▉     | 4237/8564 [00:48<00:40, 107.00 examples/s]Tokenizing train dataset:  49%|████▉     | 4197/8564 [00:48<00:39, 111.05 examples/s]Tokenizing train dataset:  49%|████▉     | 4197/8564 [00:48<00:55, 78.62 examples/s]Tokenizing train dataset:  50%|████▉     | 4249/8564 [00:48<00:46, 92.54 examples/s] Tokenizing train dataset:  49%|████▉     | 4210/8564 [00:48<00:47, 91.81 examples/s] Tokenizing train dataset:  49%|████▉     | 4207/8564 [00:48<00:55, 79.03 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:48<00:47, 89.88 examples/s]Tokenizing train dataset:  49%|████▉     | 4220/8564 [00:49<00:48, 89.00 examples/s]Tokenizing train dataset:  50%|████▉     | 4270/8564 [00:48<00:47, 90.23 examples/s]Tokenizing train dataset:  49%|████▉     | 4216/8564 [00:48<00:58, 74.16 examples/s]Tokenizing train dataset:  50%|████▉     | 4281/8564 [00:49<00:47, 90.87 examples/s]Tokenizing train dataset:  49%|████▉     | 4229/8564 [00:48<00:51, 84.85 examples/s]Tokenizing train dataset:  49%|████▉     | 4234/8564 [00:49<00:52, 82.36 examples/s]Tokenizing train dataset:  50%|████▉     | 4240/8564 [00:48<00:49, 86.56 examples/s]Tokenizing train dataset:  50%|█████     | 4291/8564 [00:49<00:50, 84.76 examples/s]Tokenizing train dataset:  50%|████▉     | 4244/8564 [00:49<00:54, 79.04 examples/s]Tokenizing train dataset:  50%|████▉     | 4252/8564 [00:48<00:46, 92.38 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:49<00:51, 82.55 examples/s]Tokenizing train dataset:  50%|████▉     | 4257/8564 [00:49<00:54, 79.31 examples/s]Tokenizing train dataset:  50%|████▉     | 4266/8564 [00:49<00:43, 99.53 examples/s]Tokenizing train dataset:  50%|█████     | 4309/8564 [00:49<00:54, 77.93 examples/s]Tokenizing train dataset:  50%|████▉     | 4278/8564 [00:49<00:42, 100.73 examples/s]Tokenizing train dataset:  50%|████▉     | 4266/8564 [00:49<00:56, 76.23 examples/s]Tokenizing train dataset:  50%|█████     | 4318/8564 [00:49<00:53, 79.24 examples/s]Tokenizing train dataset:  50%|████▉     | 4275/8564 [00:49<00:55, 76.89 examples/s]Tokenizing train dataset:  51%|█████     | 4332/8564 [00:49<00:45, 92.03 examples/s]Tokenizing train dataset:  50%|█████     | 4292/8564 [00:49<00:52, 81.84 examples/s] Tokenizing train dataset:  50%|█████     | 4284/8564 [00:49<00:56, 75.13 examples/s]Tokenizing train dataset:  51%|█████     | 4345/8564 [00:49<00:50, 83.36 examples/s]Tokenizing train dataset:  50%|█████     | 4306/8564 [00:49<00:45, 93.34 examples/s]Tokenizing train dataset:  50%|█████     | 4292/8564 [00:50<00:58, 72.61 examples/s]Tokenizing train dataset:  50%|█████     | 4301/8564 [00:50<01:00, 70.05 examples/s]Tokenizing train dataset:  50%|█████     | 4320/8564 [00:49<00:48, 88.02 examples/s]Tokenizing train dataset:  51%|█████     | 4360/8564 [00:50<00:52, 79.75 examples/s]Tokenizing train dataset:  51%|█████     | 4335/8564 [00:49<00:41, 100.86 examples/s]Tokenizing train dataset:  50%|█████     | 4313/8564 [00:50<00:56, 74.91 examples/s]Tokenizing train dataset:  51%|█████     | 4370/8564 [00:50<00:57, 72.32 examples/s]Tokenizing train dataset:  51%|█████     | 4327/8564 [00:50<00:51, 81.61 examples/s]Tokenizing train dataset:  51%|█████     | 4350/8564 [00:49<00:46, 90.77 examples/s] Tokenizing train dataset:  51%|█████     | 4380/8564 [00:50<00:56, 74.40 examples/s]Tokenizing train dataset:  51%|█████▏    | 4395/8564 [00:50<00:46, 88.81 examples/s]Tokenizing train dataset:  51%|█████     | 4337/8564 [00:50<00:54, 77.15 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:50<00:49, 85.60 examples/s]Tokenizing train dataset:  51%|█████▏    | 4405/8564 [00:50<00:46, 89.27 examples/s]Tokenizing train dataset:  51%|█████     | 4349/8564 [00:50<00:53, 78.34 examples/s]Tokenizing train dataset:  51%|█████     | 4372/8564 [00:50<00:51, 82.15 examples/s]Tokenizing train dataset:  52%|█████▏    | 4423/8564 [00:50<00:38, 106.54 examples/s]Tokenizing train dataset:  51%|█████     | 4383/8564 [00:50<00:48, 85.59 examples/s]Tokenizing train dataset:  51%|█████     | 4360/8564 [00:50<00:57, 72.56 examples/s]Tokenizing train dataset:  51%|█████▏    | 4398/8564 [00:50<00:41, 100.23 examples/s]Tokenizing train dataset:  51%|█████     | 4375/8564 [00:51<00:47, 88.36 examples/s]Tokenizing train dataset:  52%|█████▏    | 4439/8564 [00:50<00:44, 93.64 examples/s] Tokenizing train dataset:  51%|█████     | 4385/8564 [00:51<00:46, 90.35 examples/s]Tokenizing train dataset:  52%|█████▏    | 4413/8564 [00:50<00:43, 95.61 examples/s] Tokenizing train dataset:  52%|█████▏    | 4452/8564 [00:51<00:43, 93.82 examples/s]Tokenizing train dataset:  52%|█████▏    | 4430/8564 [00:50<00:38, 108.70 examples/s]Tokenizing train dataset:  52%|█████▏    | 4462/8564 [00:51<00:45, 90.97 examples/s]Tokenizing train dataset:  51%|█████▏    | 4400/8564 [00:51<00:51, 80.57 examples/s]Tokenizing train dataset:  52%|█████▏    | 4444/8564 [00:50<00:35, 115.46 examples/s]Tokenizing train dataset:  52%|█████▏    | 4475/8564 [00:51<00:42, 95.58 examples/s]Tokenizing train dataset:  51%|█████▏    | 4410/8564 [00:51<00:54, 76.80 examples/s]Tokenizing train dataset:  52%|█████▏    | 4460/8564 [00:51<00:37, 109.15 examples/s]Tokenizing train dataset:  52%|█████▏    | 4486/8564 [00:51<00:45, 90.28 examples/s]Tokenizing train dataset:  52%|█████▏    | 4422/8564 [00:51<00:51, 79.85 examples/s]Tokenizing train dataset:  52%|█████▏    | 4474/8564 [00:51<00:36, 112.23 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:51<00:50, 81.24 examples/s]Tokenizing train dataset:  52%|█████▏    | 4488/8564 [00:51<00:37, 109.57 examples/s]Tokenizing train dataset:  52%|█████▏    | 4437/8564 [00:51<00:52, 78.71 examples/s]Tokenizing train dataset:  53%|█████▎    | 4508/8564 [00:51<00:52, 77.52 examples/s]Tokenizing train dataset:  52%|█████▏    | 4446/8564 [00:52<00:53, 77.32 examples/s]Tokenizing train dataset:  53%|█████▎    | 4503/8564 [00:51<00:40, 101.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 4521/8564 [00:51<00:54, 74.62 examples/s]Tokenizing train dataset:  52%|█████▏    | 4455/8564 [00:52<00:53, 76.44 examples/s]Tokenizing train dataset:  53%|█████▎    | 4515/8564 [00:51<00:39, 102.56 examples/s]Tokenizing train dataset:  53%|█████▎    | 4536/8564 [00:52<00:46, 87.23 examples/s]Tokenizing train dataset:  53%|█████▎    | 4528/8564 [00:51<00:41, 97.41 examples/s] Tokenizing train dataset:  52%|█████▏    | 4471/8564 [00:52<00:48, 84.34 examples/s]Tokenizing train dataset:  53%|█████▎    | 4546/8564 [00:52<00:45, 87.52 examples/s]Tokenizing train dataset:  53%|█████▎    | 4538/8564 [00:51<00:41, 96.91 examples/s]Tokenizing train dataset:  52%|█████▏    | 4484/8564 [00:52<00:43, 93.57 examples/s]Tokenizing train dataset:  53%|█████▎    | 4552/8564 [00:51<00:38, 105.55 examples/s]Tokenizing train dataset:  53%|█████▎    | 4560/8564 [00:52<00:46, 86.43 examples/s]Tokenizing train dataset:  52%|█████▏    | 4495/8564 [00:52<00:50, 81.36 examples/s]Tokenizing train dataset:  53%|█████▎    | 4569/8564 [00:52<00:46, 86.10 examples/s]Tokenizing train dataset:  53%|█████▎    | 4566/8564 [00:52<00:37, 106.77 examples/s]Tokenizing train dataset:  53%|█████▎    | 4507/8564 [00:52<00:46, 87.01 examples/s]Tokenizing train dataset:  53%|█████▎    | 4579/8564 [00:52<00:41, 95.90 examples/s] Tokenizing train dataset:  53%|█████▎    | 4517/8564 [00:52<00:45, 88.13 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:52<00:56, 70.94 examples/s]Tokenizing train dataset:  53%|█████▎    | 4538/8564 [00:52<00:36, 110.07 examples/s]Tokenizing train dataset:  54%|█████▎    | 4592/8564 [00:52<00:43, 90.47 examples/s]Tokenizing train dataset:  54%|█████▎    | 4590/8564 [00:52<00:56, 69.75 examples/s]Tokenizing train dataset:  53%|█████▎    | 4551/8564 [00:53<00:37, 108.28 examples/s]Tokenizing train dataset:  54%|█████▎    | 4602/8564 [00:52<00:44, 88.32 examples/s]Tokenizing train dataset:  54%|█████▎    | 4600/8564 [00:52<00:54, 72.23 examples/s]Tokenizing train dataset:  53%|█████▎    | 4570/8564 [00:53<00:36, 108.53 examples/s]Tokenizing train dataset:  54%|█████▍    | 4613/8564 [00:53<00:48, 81.39 examples/s]Tokenizing train dataset:  54%|█████▍    | 4614/8564 [00:52<00:48, 80.66 examples/s]Tokenizing train dataset:  54%|█████▍    | 4627/8564 [00:53<00:42, 93.72 examples/s]Tokenizing train dataset:  54%|█████▍    | 4623/8564 [00:52<00:50, 77.77 examples/s]Tokenizing train dataset:  54%|█████▎    | 4590/8564 [00:53<00:36, 108.17 examples/s]Tokenizing train dataset:  54%|█████▍    | 4637/8564 [00:53<00:43, 91.03 examples/s]Tokenizing train dataset:  54%|█████▍    | 4631/8564 [00:52<00:51, 76.59 examples/s]Tokenizing train dataset:  54%|█████▎    | 4602/8564 [00:53<00:38, 103.22 examples/s]Tokenizing train dataset:  54%|█████▍    | 4647/8564 [00:53<00:43, 89.16 examples/s]Tokenizing train dataset:  54%|█████▍    | 4640/8564 [00:53<00:56, 69.23 examples/s]Tokenizing train dataset:  54%|█████▍    | 4617/8564 [00:53<00:37, 106.01 examples/s]Tokenizing train dataset:  54%|█████▍    | 4657/8564 [00:53<00:43, 89.13 examples/s]Tokenizing train dataset:  54%|█████▍    | 4630/8564 [00:53<00:35, 110.14 examples/s]Tokenizing train dataset:  54%|█████▍    | 4651/8564 [00:53<00:58, 66.53 examples/s]Tokenizing train dataset:  55%|█████▍    | 4672/8564 [00:53<00:43, 90.39 examples/s]Tokenizing train dataset:  54%|█████▍    | 4659/8564 [00:53<00:58, 66.68 examples/s]Tokenizing train dataset:  54%|█████▍    | 4643/8564 [00:53<00:40, 96.01 examples/s] Tokenizing train dataset:  55%|█████▍    | 4684/8564 [00:53<00:42, 91.77 examples/s]Tokenizing train dataset:  55%|█████▍    | 4696/8564 [00:53<00:40, 96.22 examples/s]Tokenizing train dataset:  54%|█████▍    | 4667/8564 [00:53<01:05, 59.07 examples/s]Tokenizing train dataset:  54%|█████▍    | 4655/8564 [00:54<00:48, 80.68 examples/s]Tokenizing train dataset:  55%|█████▍    | 4677/8564 [00:53<00:59, 64.80 examples/s]Tokenizing train dataset:  55%|█████▍    | 4710/8564 [00:54<00:42, 91.09 examples/s]Tokenizing train dataset:  55%|█████▍    | 4685/8564 [00:53<00:57, 66.93 examples/s]Tokenizing train dataset:  54%|█████▍    | 4666/8564 [00:54<00:53, 73.05 examples/s]Tokenizing train dataset:  55%|█████▌    | 4723/8564 [00:54<00:40, 95.19 examples/s]Tokenizing train dataset:  55%|█████▍    | 4676/8564 [00:54<00:50, 76.70 examples/s]Tokenizing train dataset:  55%|█████▍    | 4692/8564 [00:53<01:00, 63.82 examples/s]Tokenizing train dataset:  55%|█████▌    | 4738/8564 [00:54<00:36, 106.06 examples/s]Tokenizing train dataset:  55%|█████▍    | 4701/8564 [00:54<00:56, 68.53 examples/s]Tokenizing train dataset:  55%|█████▍    | 4686/8564 [00:54<00:55, 70.05 examples/s]Tokenizing train dataset:  55%|█████▌    | 4752/8564 [00:54<00:40, 95.04 examples/s] Tokenizing train dataset:  55%|█████▍    | 4695/8564 [00:54<00:54, 71.46 examples/s]Tokenizing train dataset:  55%|█████▌    | 4712/8564 [00:54<01:05, 58.67 examples/s]Tokenizing train dataset:  56%|█████▌    | 4764/8564 [00:54<00:44, 85.04 examples/s]Tokenizing train dataset:  55%|█████▌    | 4721/8564 [00:54<01:02, 61.18 examples/s]Tokenizing train dataset:  55%|█████▍    | 4707/8564 [00:54<00:56, 67.73 examples/s]Tokenizing train dataset:  56%|█████▌    | 4775/8564 [00:54<00:50, 74.94 examples/s]Tokenizing train dataset:  55%|█████▌    | 4732/8564 [00:54<00:56, 68.15 examples/s]Tokenizing train dataset:  55%|█████▌    | 4716/8564 [00:55<00:56, 68.21 examples/s]Tokenizing train dataset:  56%|█████▌    | 4785/8564 [00:54<00:48, 77.44 examples/s]Tokenizing train dataset:  55%|█████▌    | 4744/8564 [00:54<00:50, 76.09 examples/s]Tokenizing train dataset:  55%|█████▌    | 4727/8564 [00:55<00:52, 73.54 examples/s]Tokenizing train dataset:  56%|█████▌    | 4796/8564 [00:55<00:45, 83.09 examples/s]Tokenizing train dataset:  55%|█████▌    | 4738/8564 [00:55<00:47, 80.38 examples/s]Tokenizing train dataset:  55%|█████▌    | 4753/8564 [00:54<00:55, 69.12 examples/s]Tokenizing train dataset:  56%|█████▌    | 4813/8564 [00:55<00:36, 103.10 examples/s]Tokenizing train dataset:  55%|█████▌    | 4747/8564 [00:55<00:47, 80.72 examples/s]Tokenizing train dataset:  56%|█████▋    | 4829/8564 [00:55<00:34, 108.33 examples/s]Tokenizing train dataset:  56%|█████▌    | 4763/8564 [00:54<00:55, 68.21 examples/s]Tokenizing train dataset:  56%|█████▌    | 4771/8564 [00:55<01:00, 62.66 examples/s]Tokenizing train dataset:  57%|█████▋    | 4849/8564 [00:55<00:34, 109.14 examples/s]Tokenizing train dataset:  56%|█████▌    | 4758/8564 [00:55<01:00, 62.83 examples/s]Tokenizing train dataset:  56%|█████▌    | 4778/8564 [00:55<01:00, 62.12 examples/s]Tokenizing train dataset:  56%|█████▌    | 4769/8564 [00:55<00:54, 69.63 examples/s]Tokenizing train dataset:  57%|█████▋    | 4865/8564 [00:55<00:36, 101.55 examples/s]Tokenizing train dataset:  56%|█████▌    | 4785/8564 [00:55<01:04, 58.46 examples/s]Tokenizing train dataset:  56%|█████▌    | 4778/8564 [00:55<00:52, 71.50 examples/s]Tokenizing train dataset:  57%|█████▋    | 4879/8564 [00:55<00:34, 107.15 examples/s]Tokenizing train dataset:  56%|█████▌    | 4788/8564 [00:56<00:50, 75.11 examples/s]Tokenizing train dataset:  56%|█████▌    | 4800/8564 [00:55<00:49, 76.41 examples/s]Tokenizing train dataset:  57%|█████▋    | 4902/8564 [00:55<00:28, 130.69 examples/s]Tokenizing train dataset:  56%|█████▋    | 4830/8564 [00:55<00:29, 126.41 examples/s]Tokenizing train dataset:  57%|█████▋    | 4920/8564 [00:56<00:27, 131.43 examples/s]Tokenizing train dataset:  56%|█████▌    | 4798/8564 [00:56<00:56, 67.14 examples/s]Tokenizing train dataset:  57%|█████▋    | 4849/8564 [00:55<00:27, 135.97 examples/s]Tokenizing train dataset:  58%|█████▊    | 4943/8564 [00:56<00:24, 149.45 examples/s]Tokenizing train dataset:  56%|█████▌    | 4815/8564 [00:56<00:43, 85.35 examples/s]Tokenizing train dataset:  58%|█████▊    | 4963/8564 [00:56<00:22, 160.99 examples/s]Tokenizing train dataset:  57%|█████▋    | 4867/8564 [00:55<00:30, 122.72 examples/s]Tokenizing train dataset:  56%|█████▋    | 4830/8564 [00:56<00:39, 95.56 examples/s]Tokenizing train dataset:  58%|█████▊    | 4985/8564 [00:56<00:22, 161.11 examples/s]Tokenizing train dataset:  57%|█████▋    | 4857/8564 [00:56<00:27, 136.41 examples/s]Tokenizing train dataset:  57%|█████▋    | 4881/8564 [00:56<00:33, 109.67 examples/s]Tokenizing train dataset:  57%|█████▋    | 4882/8564 [00:56<00:25, 143.03 examples/s]Tokenizing train dataset:  57%|█████▋    | 4907/8564 [00:56<00:27, 135.10 examples/s]Tokenizing train dataset:  58%|█████▊    | 5007/8564 [00:56<00:24, 145.78 examples/s]Tokenizing train dataset:  57%|█████▋    | 4904/8564 [00:56<00:23, 154.23 examples/s]Tokenizing train dataset:  58%|█████▊    | 4931/8564 [00:56<00:26, 135.72 examples/s]Tokenizing train dataset:  59%|█████▊    | 5027/8564 [00:56<00:26, 133.88 examples/s]Tokenizing train dataset:  57%|█████▋    | 4924/8564 [00:56<00:22, 159.05 examples/s]Tokenizing train dataset:  58%|█████▊    | 4947/8564 [00:56<00:27, 133.66 examples/s]Tokenizing train dataset:  58%|█████▊    | 4943/8564 [00:57<00:21, 164.72 examples/s]Tokenizing train dataset:  59%|█████▉    | 5047/8564 [00:56<00:28, 121.91 examples/s]Tokenizing train dataset:  58%|█████▊    | 4963/8564 [00:57<00:21, 167.40 examples/s]Tokenizing train dataset:  58%|█████▊    | 4963/8564 [00:56<00:30, 118.31 examples/s]Tokenizing train dataset:  59%|█████▉    | 5071/8564 [00:57<00:23, 145.64 examples/s]Tokenizing train dataset:  58%|█████▊    | 4984/8564 [00:57<00:21, 167.15 examples/s]Tokenizing train dataset:  58%|█████▊    | 4980/8564 [00:56<00:28, 127.00 examples/s]Tokenizing train dataset:  59%|█████▉    | 5091/8564 [00:57<00:22, 155.35 examples/s]Tokenizing train dataset:  60%|█████▉    | 5116/8564 [00:57<00:20, 171.15 examples/s]Tokenizing train dataset:  58%|█████▊    | 4994/8564 [00:56<00:29, 122.03 examples/s]Tokenizing train dataset:  59%|█████▊    | 5010/8564 [00:57<00:24, 144.27 examples/s]Tokenizing train dataset:  60%|██████    | 5139/8564 [00:57<00:19, 180.12 examples/s]Tokenizing train dataset:  59%|█████▊    | 5013/8564 [00:57<00:28, 123.46 examples/s]Tokenizing train dataset:  59%|█████▊    | 5030/8564 [00:57<00:25, 139.37 examples/s]Tokenizing train dataset:  59%|█████▊    | 5026/8564 [00:57<00:30, 115.34 examples/s]Tokenizing train dataset:  60%|██████    | 5168/8564 [00:57<00:20, 164.77 examples/s]Tokenizing train dataset:  59%|█████▉    | 5055/8564 [00:57<00:22, 155.29 examples/s]Tokenizing train dataset:  59%|█████▉    | 5055/8564 [00:57<00:23, 146.47 examples/s]Tokenizing train dataset:  59%|█████▉    | 5086/8564 [00:57<00:18, 184.82 examples/s]Tokenizing train dataset:  61%|██████    | 5190/8564 [00:57<00:23, 141.01 examples/s]Tokenizing train dataset:  59%|█████▉    | 5074/8564 [00:58<00:25, 139.12 examples/s]Tokenizing train dataset:  61%|██████    | 5209/8564 [00:57<00:23, 143.32 examples/s]Tokenizing train dataset:  59%|█████▉    | 5095/8564 [00:58<00:23, 146.38 examples/s]Tokenizing train dataset:  60%|█████▉    | 5110/8564 [00:57<00:21, 163.33 examples/s]Tokenizing train dataset:  61%|██████    | 5225/8564 [00:58<00:23, 141.55 examples/s]Tokenizing train dataset:  60%|█████▉    | 5118/8564 [00:58<00:21, 160.07 examples/s]Tokenizing train dataset:  60%|█████▉    | 5131/8564 [00:57<00:22, 150.73 examples/s]Tokenizing train dataset:  60%|██████    | 5142/8564 [00:58<00:19, 177.18 examples/s]Tokenizing train dataset:  61%|██████    | 5240/8564 [00:58<00:24, 138.16 examples/s]Tokenizing train dataset:  60%|██████    | 5170/8564 [00:58<00:17, 195.88 examples/s]Tokenizing train dataset:  61%|██████▏   | 5259/8564 [00:58<00:23, 137.82 examples/s]Tokenizing train dataset:  60%|██████    | 5158/8564 [00:57<00:22, 150.84 examples/s]Tokenizing train dataset:  61%|██████    | 5192/8564 [00:58<00:17, 190.74 examples/s]Tokenizing train dataset:  62%|██████▏   | 5282/8564 [00:58<00:21, 155.55 examples/s]Tokenizing train dataset:  60%|██████    | 5180/8564 [00:58<00:20, 161.30 examples/s]Tokenizing train dataset:  61%|██████    | 5215/8564 [00:58<00:17, 195.21 examples/s]Tokenizing train dataset:  61%|██████    | 5205/8564 [00:58<00:18, 179.88 examples/s]Tokenizing train dataset:  62%|██████▏   | 5299/8564 [00:58<00:23, 139.38 examples/s]Tokenizing train dataset:  61%|██████    | 5236/8564 [00:58<00:18, 184.86 examples/s]Tokenizing train dataset:  61%|██████    | 5231/8564 [00:58<00:16, 197.13 examples/s]Tokenizing train dataset:  62%|██████▏   | 5326/8564 [00:58<00:20, 158.58 examples/s]Tokenizing train dataset:  61%|██████▏   | 5258/8564 [00:59<00:20, 160.87 examples/s]Tokenizing train dataset:  63%|██████▎   | 5355/8564 [00:58<00:17, 182.00 examples/s]Tokenizing train dataset:  62%|██████▏   | 5274/8564 [00:58<00:15, 212.35 examples/s]Tokenizing train dataset:  62%|██████▏   | 5298/8564 [00:58<00:15, 216.60 examples/s]Tokenizing train dataset:  62%|██████▏   | 5283/8564 [00:59<00:18, 175.24 examples/s]Tokenizing train dataset:  62%|██████▏   | 5322/8564 [00:58<00:14, 221.85 examples/s]Tokenizing train dataset:  62%|██████▏   | 5304/8564 [00:59<00:18, 179.83 examples/s]Tokenizing train dataset:  63%|██████▎   | 5380/8564 [00:59<00:22, 143.61 examples/s]Tokenizing train dataset:  63%|██████▎   | 5355/8564 [00:58<00:15, 207.14 examples/s]Tokenizing train dataset:  62%|██████▏   | 5326/8564 [00:59<00:21, 147.44 examples/s]Tokenizing train dataset:  63%|██████▎   | 5400/8564 [00:59<00:24, 127.23 examples/s]Tokenizing train dataset:  63%|██████▎   | 5420/8564 [00:59<00:22, 139.93 examples/s]Tokenizing train dataset:  62%|██████▏   | 5349/8564 [00:59<00:21, 146.98 examples/s]Tokenizing train dataset:  63%|██████▎   | 5384/8564 [00:59<00:17, 179.16 examples/s]Tokenizing train dataset:  64%|██████▎   | 5442/8564 [00:59<00:20, 151.58 examples/s]Tokenizing train dataset:  63%|██████▎   | 5365/8564 [00:59<00:23, 138.16 examples/s]Tokenizing train dataset:  63%|██████▎   | 5409/8564 [00:59<00:18, 170.93 examples/s]Tokenizing train dataset:  63%|██████▎   | 5436/8564 [00:59<00:16, 187.44 examples/s]Tokenizing train dataset:  64%|██████▍   | 5464/8564 [00:59<00:23, 132.74 examples/s]Tokenizing train dataset:  63%|██████▎   | 5388/8564 [00:59<00:24, 131.83 examples/s]Tokenizing train dataset:  64%|██████▍   | 5462/8564 [00:59<00:17, 179.77 examples/s]Tokenizing train dataset:  63%|██████▎   | 5402/8564 [01:00<00:26, 118.90 examples/s]Tokenizing train dataset:  64%|██████▍   | 5487/8564 [00:59<00:23, 128.37 examples/s]Tokenizing train dataset:  63%|██████▎   | 5417/8564 [01:00<00:25, 122.57 examples/s]Tokenizing train dataset:  64%|██████▍   | 5491/8564 [00:59<00:17, 172.36 examples/s]Tokenizing train dataset:  64%|██████▍   | 5510/8564 [01:00<00:23, 131.65 examples/s]Tokenizing train dataset:  63%|██████▎   | 5436/8564 [01:00<00:24, 127.46 examples/s]Tokenizing train dataset:  65%|██████▍   | 5530/8564 [01:00<00:21, 140.35 examples/s]Tokenizing train dataset:  64%|██████▍   | 5511/8564 [00:59<00:21, 143.65 examples/s]Tokenizing train dataset:  64%|██████▎   | 5457/8564 [01:00<00:21, 143.62 examples/s]Tokenizing train dataset:  65%|██████▍   | 5549/8564 [01:00<00:20, 149.98 examples/s]Tokenizing train dataset:  65%|██████▍   | 5533/8564 [00:59<00:19, 156.52 examples/s]Tokenizing train dataset:  64%|██████▍   | 5475/8564 [01:00<00:23, 130.39 examples/s]Tokenizing train dataset:  65%|██████▌   | 5568/8564 [01:00<00:21, 141.71 examples/s]Tokenizing train dataset:  64%|██████▍   | 5500/8564 [01:00<00:19, 153.69 examples/s]Tokenizing train dataset:  65%|██████▌   | 5585/8564 [01:00<00:20, 147.49 examples/s]Tokenizing train dataset:  65%|██████▍   | 5551/8564 [01:00<00:22, 134.55 examples/s]Tokenizing train dataset:  64%|██████▍   | 5519/8564 [01:00<00:19, 158.76 examples/s]Tokenizing train dataset:  65%|██████▌   | 5607/8564 [01:00<00:18, 161.80 examples/s]Tokenizing train dataset:  65%|██████▌   | 5568/8564 [01:00<00:22, 132.71 examples/s]Tokenizing train dataset:  65%|██████▍   | 5537/8564 [01:00<00:18, 161.35 examples/s]Tokenizing train dataset:  66%|██████▌   | 5630/8564 [01:00<00:16, 176.70 examples/s]Tokenizing train dataset:  65%|██████▌   | 5586/8564 [01:00<00:22, 130.96 examples/s]Tokenizing train dataset:  66%|██████▌   | 5659/8564 [01:00<00:14, 206.11 examples/s]Tokenizing train dataset:  65%|██████▍   | 5560/8564 [01:01<00:19, 156.36 examples/s]Tokenizing train dataset:  65%|██████▌   | 5608/8564 [01:00<00:22, 130.52 examples/s]Tokenizing train dataset:  65%|██████▌   | 5590/8564 [01:01<00:15, 189.75 examples/s]Tokenizing train dataset:  66%|██████▋   | 5689/8564 [01:01<00:15, 185.39 examples/s]Tokenizing train dataset:  66%|██████▌   | 5631/8564 [01:00<00:19, 148.01 examples/s]Tokenizing train dataset:  66%|██████▌   | 5610/8564 [01:01<00:15, 188.89 examples/s]Tokenizing train dataset:  66%|██████▌   | 5654/8564 [01:00<00:17, 166.49 examples/s]Tokenizing train dataset:  66%|██████▌   | 5631/8564 [01:01<00:15, 193.43 examples/s]Tokenizing train dataset:  67%|██████▋   | 5720/8564 [01:01<00:16, 176.36 examples/s]Tokenizing train dataset:  66%|██████▋   | 5675/8564 [01:00<00:16, 171.63 examples/s]Tokenizing train dataset:  66%|██████▌   | 5658/8564 [01:01<00:14, 201.05 examples/s]Tokenizing train dataset:  67%|██████▋   | 5743/8564 [01:01<00:17, 161.26 examples/s]Tokenizing train dataset:  66%|██████▋   | 5695/8564 [01:01<00:17, 166.71 examples/s]Tokenizing train dataset:  66%|██████▋   | 5682/8564 [01:01<00:16, 171.84 examples/s]Tokenizing train dataset:  67%|██████▋   | 5765/8564 [01:01<00:16, 170.79 examples/s]Tokenizing train dataset:  67%|██████▋   | 5715/8564 [01:01<00:17, 161.37 examples/s]Tokenizing train dataset:  68%|██████▊   | 5788/8564 [01:01<00:15, 183.59 examples/s]Tokenizing train dataset:  67%|██████▋   | 5701/8564 [01:01<00:17, 163.62 examples/s]Tokenizing train dataset:  68%|██████▊   | 5809/8564 [01:01<00:16, 172.04 examples/s]Tokenizing train dataset:  67%|██████▋   | 5738/8564 [01:01<00:19, 144.27 examples/s]Tokenizing train dataset:  67%|██████▋   | 5721/8564 [01:02<00:17, 160.28 examples/s]Tokenizing train dataset:  68%|██████▊   | 5832/8564 [01:01<00:15, 176.24 examples/s]Tokenizing train dataset:  67%|██████▋   | 5755/8564 [01:01<00:19, 141.22 examples/s]Tokenizing train dataset:  67%|██████▋   | 5743/8564 [01:02<00:19, 145.99 examples/s]Tokenizing train dataset:  67%|██████▋   | 5780/8564 [01:01<00:16, 164.64 examples/s]Tokenizing train dataset:  68%|██████▊   | 5852/8564 [01:02<00:17, 152.72 examples/s]Tokenizing train dataset:  67%|██████▋   | 5778/8564 [01:02<00:14, 186.50 examples/s]Tokenizing train dataset:  68%|██████▊   | 5800/8564 [01:01<00:18, 150.65 examples/s]Tokenizing train dataset:  68%|██████▊   | 5800/8564 [01:02<00:14, 193.37 examples/s]Tokenizing train dataset:  69%|██████▊   | 5870/8564 [01:02<00:18, 149.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 5826/8564 [01:01<00:16, 170.35 examples/s]Tokenizing train dataset:  68%|██████▊   | 5824/8564 [01:02<00:13, 199.74 examples/s]Tokenizing train dataset:  69%|██████▉   | 5891/8564 [01:02<00:19, 137.65 examples/s]Tokenizing train dataset:  68%|██████▊   | 5850/8564 [01:02<00:14, 188.04 examples/s]Tokenizing train dataset:  68%|██████▊   | 5850/8564 [01:02<00:17, 151.23 examples/s]Tokenizing train dataset:  69%|██████▉   | 5910/8564 [01:02<00:20, 131.32 examples/s]Tokenizing train dataset:  69%|██████▊   | 5873/8564 [01:02<00:16, 166.89 examples/s]Tokenizing train dataset:  69%|██████▊   | 5870/8564 [01:02<00:18, 142.32 examples/s]Tokenizing train dataset:  69%|██████▉   | 5926/8564 [01:02<00:19, 134.13 examples/s]Tokenizing train dataset:  69%|██████▉   | 5892/8564 [01:02<00:16, 166.68 examples/s]Tokenizing train dataset:  69%|██████▉   | 5891/8564 [01:02<00:17, 156.50 examples/s]Tokenizing train dataset:  69%|██████▉   | 5940/8564 [01:02<00:20, 130.42 examples/s]Tokenizing train dataset:  69%|██████▉   | 5930/8564 [01:03<00:12, 213.30 examples/s]Tokenizing train dataset:  69%|██████▉   | 5910/8564 [01:02<00:17, 151.79 examples/s]Tokenizing train dataset:  70%|██████▉   | 5956/8564 [01:02<00:20, 129.66 examples/s]Tokenizing train dataset:  70%|██████▉   | 5961/8564 [01:03<00:12, 203.37 examples/s]Tokenizing train dataset:  69%|██████▉   | 5926/8564 [01:02<00:20, 130.68 examples/s]Tokenizing train dataset:  69%|██████▉   | 5947/8564 [01:02<00:18, 140.20 examples/s]Tokenizing train dataset:  70%|██████▉   | 5966/8564 [01:02<00:18, 144.03 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [01:03<00:32, 80.49 examples/s] Tokenizing train dataset:  70%|██████▉   | 5990/8564 [01:03<00:21, 119.87 examples/s]Tokenizing train dataset:  70%|███████   | 5998/8564 [01:03<00:28, 91.50 examples/s]Tokenizing train dataset:  70%|██████▉   | 5987/8564 [01:03<00:22, 112.49 examples/s]Tokenizing train dataset:  70%|███████   | 6013/8564 [01:03<00:18, 134.84 examples/s]Tokenizing train dataset:  70%|███████   | 6012/8564 [01:03<00:26, 97.84 examples/s]Tokenizing train dataset:  70%|███████   | 6007/8564 [01:03<00:21, 118.78 examples/s]Tokenizing train dataset:  70%|███████   | 6024/8564 [01:03<00:25, 98.96 examples/s]Tokenizing train dataset:  70%|███████   | 6036/8564 [01:03<00:18, 136.20 examples/s]Tokenizing train dataset:  71%|███████   | 6039/8564 [01:03<00:23, 109.26 examples/s]Tokenizing train dataset:  70%|███████   | 6022/8564 [01:03<00:21, 117.04 examples/s]Tokenizing train dataset:  71%|███████   | 6054/8564 [01:04<00:17, 142.78 examples/s]Tokenizing train dataset:  71%|███████   | 6060/8564 [01:03<00:19, 130.86 examples/s]Tokenizing train dataset:  70%|███████   | 6035/8564 [01:03<00:21, 115.62 examples/s]Tokenizing train dataset:  71%|███████   | 6072/8564 [01:04<00:17, 140.33 examples/s]Tokenizing train dataset:  71%|███████   | 6080/8564 [01:04<00:17, 144.88 examples/s]Tokenizing train dataset:  71%|███████   | 6057/8564 [01:03<00:18, 133.05 examples/s]Tokenizing train dataset:  71%|███████   | 6096/8564 [01:04<00:16, 147.09 examples/s]Tokenizing train dataset:  71%|███████   | 6091/8564 [01:04<00:20, 118.87 examples/s]Tokenizing train dataset:  71%|███████▏  | 6116/8564 [01:04<00:15, 159.29 examples/s]Tokenizing train dataset:  71%|███████   | 6074/8564 [01:03<00:20, 118.76 examples/s]Tokenizing train dataset:  71%|███████▏  | 6108/8564 [01:04<00:21, 114.92 examples/s]Tokenizing train dataset:  72%|███████▏  | 6147/8564 [01:04<00:12, 187.33 examples/s]Tokenizing train dataset:  71%|███████   | 6094/8564 [01:04<00:18, 130.72 examples/s]Tokenizing train dataset:  72%|███████▏  | 6130/8564 [01:04<00:18, 134.76 examples/s]Tokenizing train dataset:  71%|███████▏  | 6120/8564 [01:04<00:15, 155.66 examples/s]Tokenizing train dataset:  72%|███████▏  | 6171/8564 [01:04<00:14, 164.14 examples/s]Tokenizing train dataset:  72%|███████▏  | 6157/8564 [01:04<00:15, 158.52 examples/s]Tokenizing train dataset:  72%|███████▏  | 6157/8564 [01:04<00:12, 196.26 examples/s]Tokenizing train dataset:  72%|███████▏  | 6194/8564 [01:04<00:11, 206.23 examples/s]Tokenizing train dataset:  72%|███████▏  | 6183/8564 [01:04<00:12, 197.27 examples/s]Tokenizing train dataset:  72%|███████▏  | 6196/8564 [01:04<00:16, 142.26 examples/s]Tokenizing train dataset:  73%|███████▎  | 6215/8564 [01:04<00:10, 220.52 examples/s]Tokenizing train dataset:  73%|███████▎  | 6222/8564 [01:05<00:12, 187.89 examples/s]Tokenizing train dataset:  73%|███████▎  | 6214/8564 [01:04<00:16, 146.06 examples/s]Tokenizing train dataset:  73%|███████▎  | 6243/8564 [01:04<00:09, 232.91 examples/s]Tokenizing train dataset:  73%|███████▎  | 6230/8564 [01:05<00:16, 139.45 examples/s]Tokenizing train dataset:  73%|███████▎  | 6245/8564 [01:05<00:13, 166.15 examples/s]Tokenizing train dataset:  73%|███████▎  | 6270/8564 [01:04<00:09, 241.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 6253/8564 [01:05<00:14, 158.46 examples/s]Tokenizing train dataset:  73%|███████▎  | 6268/8564 [01:05<00:13, 165.25 examples/s]Tokenizing train dataset:  74%|███████▎  | 6303/8564 [01:04<00:10, 222.26 examples/s]Tokenizing train dataset:  73%|███████▎  | 6276/8564 [01:05<00:13, 169.38 examples/s]Tokenizing train dataset:  73%|███████▎  | 6290/8564 [01:05<00:15, 150.70 examples/s]Tokenizing train dataset:  74%|███████▎  | 6300/8564 [01:05<00:13, 165.80 examples/s]Tokenizing train dataset:  74%|███████▍  | 6331/8564 [01:05<00:11, 202.95 examples/s]Tokenizing train dataset:  74%|███████▍  | 6322/8564 [01:05<00:12, 173.68 examples/s]Tokenizing train dataset:  74%|███████▍  | 6356/8564 [01:05<00:10, 207.93 examples/s]Tokenizing train dataset:  74%|███████▎  | 6312/8564 [01:05<00:16, 136.68 examples/s]Tokenizing train dataset:  74%|███████▍  | 6340/8564 [01:05<00:12, 172.98 examples/s]Tokenizing train dataset:  74%|███████▍  | 6378/8564 [01:05<00:10, 207.40 examples/s]Tokenizing train dataset:  74%|███████▍  | 6331/8564 [01:05<00:16, 131.62 examples/s]Tokenizing train dataset:  74%|███████▍  | 6376/8564 [01:05<00:10, 208.58 examples/s]Tokenizing train dataset:  75%|███████▍  | 6405/8564 [01:05<00:11, 183.42 examples/s]Tokenizing train dataset:  74%|███████▍  | 6352/8564 [01:06<00:15, 142.33 examples/s]Tokenizing train dataset:  75%|███████▍  | 6409/8564 [01:05<00:10, 205.66 examples/s]Tokenizing train dataset:  74%|███████▍  | 6370/8564 [01:06<00:15, 143.54 examples/s]Tokenizing train dataset:  75%|███████▌  | 6425/8564 [01:05<00:13, 157.44 examples/s]Tokenizing train dataset:  75%|███████▌  | 6435/8564 [01:06<00:09, 216.57 examples/s]Tokenizing train dataset:  75%|███████▌  | 6450/8564 [01:05<00:11, 176.83 examples/s]Tokenizing train dataset:  76%|███████▌  | 6467/8564 [01:06<00:10, 209.14 examples/s]Tokenizing train dataset:  75%|███████▍  | 6388/8564 [01:06<00:17, 122.01 examples/s]Tokenizing train dataset:  76%|███████▌  | 6476/8564 [01:05<00:11, 174.62 examples/s]Tokenizing train dataset:  75%|███████▍  | 6405/8564 [01:06<00:16, 130.01 examples/s]Tokenizing train dataset:  76%|███████▌  | 6490/8564 [01:06<00:10, 189.57 examples/s]Tokenizing train dataset:  76%|███████▌  | 6496/8564 [01:06<00:11, 178.63 examples/s]Tokenizing train dataset:  75%|███████▌  | 6429/8564 [01:06<00:15, 136.89 examples/s]Tokenizing train dataset:  76%|███████▌  | 6515/8564 [01:06<00:12, 170.29 examples/s]Tokenizing train dataset:  76%|███████▌  | 6519/8564 [01:06<00:13, 157.24 examples/s]Tokenizing train dataset:  75%|███████▌  | 6448/8564 [01:06<00:14, 147.55 examples/s]Tokenizing train dataset:  76%|███████▋  | 6535/8564 [01:06<00:11, 174.03 examples/s]Tokenizing train dataset:  76%|███████▋  | 6536/8564 [01:06<00:13, 148.68 examples/s]Tokenizing train dataset:  76%|███████▌  | 6471/8564 [01:06<00:14, 146.51 examples/s]Tokenizing train dataset:  77%|███████▋  | 6555/8564 [01:06<00:11, 176.00 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [01:07<00:13, 154.90 examples/s]Tokenizing train dataset:  77%|███████▋  | 6558/8564 [01:06<00:14, 139.17 examples/s]Tokenizing train dataset:  77%|███████▋  | 6580/8564 [01:06<00:11, 169.54 examples/s]Tokenizing train dataset:  76%|███████▌  | 6526/8564 [01:07<00:10, 196.47 examples/s]Tokenizing train dataset:  77%|███████▋  | 6579/8564 [01:06<00:15, 128.92 examples/s]Tokenizing train dataset:  77%|███████▋  | 6600/8564 [01:07<00:13, 148.50 examples/s]Tokenizing train dataset:  77%|███████▋  | 6555/8564 [01:07<00:10, 193.19 examples/s]Tokenizing train dataset:  77%|███████▋  | 6595/8564 [01:06<00:14, 134.61 examples/s]Tokenizing train dataset:  77%|███████▋  | 6616/8564 [01:07<00:15, 128.02 examples/s]Tokenizing train dataset:  77%|███████▋  | 6582/8564 [01:07<00:10, 181.94 examples/s]Tokenizing train dataset:  77%|███████▋  | 6616/8564 [01:06<00:14, 135.27 examples/s]Tokenizing train dataset:  77%|███████▋  | 6630/8564 [01:07<00:15, 124.82 examples/s]Tokenizing train dataset:  77%|███████▋  | 6634/8564 [01:07<00:13, 142.49 examples/s]Tokenizing train dataset:  77%|███████▋  | 6604/8564 [01:07<00:11, 164.95 examples/s]Tokenizing train dataset:  78%|███████▊  | 6645/8564 [01:07<00:15, 125.63 examples/s]Tokenizing train dataset:  78%|███████▊  | 6658/8564 [01:07<00:11, 161.88 examples/s]Tokenizing train dataset:  77%|███████▋  | 6628/8564 [01:07<00:11, 169.18 examples/s]Tokenizing train dataset:  78%|███████▊  | 6690/8564 [01:07<00:09, 190.78 examples/s]Tokenizing train dataset:  78%|███████▊  | 6664/8564 [01:07<00:15, 123.43 examples/s]Tokenizing train dataset:  78%|███████▊  | 6646/8564 [01:07<00:12, 148.30 examples/s]Tokenizing train dataset:  78%|███████▊  | 6715/8564 [01:07<00:09, 204.67 examples/s]Tokenizing train dataset:  78%|███████▊  | 6680/8564 [01:07<00:15, 124.28 examples/s]Tokenizing train dataset:  79%|███████▉  | 6745/8564 [01:07<00:08, 224.25 examples/s]Tokenizing train dataset:  78%|███████▊  | 6697/8564 [01:07<00:14, 129.81 examples/s]Tokenizing train dataset:  78%|███████▊  | 6669/8564 [01:08<00:13, 144.94 examples/s]Tokenizing train dataset:  78%|███████▊  | 6690/8564 [01:08<00:11, 156.88 examples/s]Tokenizing train dataset:  79%|███████▉  | 6777/8564 [01:07<00:08, 218.15 examples/s]Tokenizing train dataset:  78%|███████▊  | 6716/8564 [01:08<00:13, 132.07 examples/s]Tokenizing train dataset:  78%|███████▊  | 6715/8564 [01:08<00:10, 178.06 examples/s]Tokenizing train dataset:  79%|███████▉  | 6801/8564 [01:07<00:08, 211.62 examples/s]Tokenizing train dataset:  79%|███████▊  | 6732/8564 [01:08<00:15, 115.32 examples/s]Tokenizing train dataset:  79%|███████▊  | 6734/8564 [01:08<00:10, 169.87 examples/s]Tokenizing train dataset:  80%|███████▉  | 6828/8564 [01:07<00:09, 187.41 examples/s]Tokenizing train dataset:  79%|███████▉  | 6750/8564 [01:08<00:14, 125.48 examples/s]Tokenizing train dataset:  79%|███████▉  | 6762/8564 [01:08<00:09, 191.09 examples/s]Tokenizing train dataset:  79%|███████▉  | 6767/8564 [01:08<00:14, 124.28 examples/s]Tokenizing train dataset:  80%|███████▉  | 6848/8564 [01:08<00:10, 162.75 examples/s]Tokenizing train dataset:  79%|███████▉  | 6790/8564 [01:08<00:11, 155.77 examples/s]Tokenizing train dataset:  80%|████████  | 6872/8564 [01:08<00:10, 160.45 examples/s]Tokenizing train dataset:  79%|███████▉  | 6791/8564 [01:08<00:14, 125.60 examples/s]Tokenizing train dataset:  80%|███████▉  | 6810/8564 [01:08<00:11, 157.70 examples/s]Tokenizing train dataset:  80%|████████  | 6890/8564 [01:08<00:10, 159.33 examples/s]Tokenizing train dataset:  79%|███████▉  | 6808/8564 [01:08<00:13, 127.31 examples/s]Tokenizing train dataset:  80%|███████▉  | 6830/8564 [01:09<00:10, 161.96 examples/s]Tokenizing train dataset:  81%|████████  | 6913/8564 [01:08<00:10, 153.92 examples/s]Tokenizing train dataset:  80%|████████  | 6860/8564 [01:09<00:10, 168.87 examples/s]Tokenizing train dataset:  80%|███████▉  | 6824/8564 [01:09<00:16, 108.50 examples/s]Tokenizing train dataset:  81%|████████  | 6941/8564 [01:08<00:09, 179.92 examples/s]Tokenizing train dataset:  80%|████████  | 6884/8564 [01:09<00:09, 184.28 examples/s]Tokenizing train dataset:  80%|███████▉  | 6843/8564 [01:09<00:15, 109.46 examples/s]Tokenizing train dataset:  81%|████████▏ | 6962/8564 [01:08<00:09, 160.69 examples/s]Tokenizing train dataset:  80%|████████  | 6870/8564 [01:09<00:12, 140.74 examples/s]Tokenizing train dataset:  81%|████████  | 6905/8564 [01:09<00:10, 155.45 examples/s]Tokenizing train dataset:  80%|████████  | 6890/8564 [01:09<00:10, 153.03 examples/s]Tokenizing train dataset:  82%|████████▏ | 6982/8564 [01:09<00:10, 144.29 examples/s]Tokenizing train dataset:  81%|████████  | 6923/8564 [01:09<00:11, 137.49 examples/s]Tokenizing train dataset:  81%|████████  | 6911/8564 [01:09<00:10, 159.41 examples/s]Tokenizing train dataset:  82%|████████▏ | 7003/8564 [01:09<00:12, 127.55 examples/s]Tokenizing train dataset:  81%|████████  | 6945/8564 [01:09<00:11, 144.80 examples/s]Tokenizing train dataset:  81%|████████  | 6940/8564 [01:09<00:08, 181.51 examples/s]Tokenizing train dataset:  81%|████████▏ | 6962/8564 [01:09<00:11, 142.36 examples/s]Tokenizing train dataset:  82%|████████▏ | 7019/8564 [01:09<00:12, 124.08 examples/s]Tokenizing train dataset:  81%|████████▏ | 6959/8564 [01:09<00:10, 156.00 examples/s]Tokenizing train dataset:  82%|████████▏ | 6982/8564 [01:10<00:10, 154.64 examples/s]Tokenizing train dataset:  82%|████████▏ | 7033/8564 [01:09<00:13, 114.54 examples/s]Tokenizing train dataset:  82%|████████▏ | 6983/8564 [01:10<00:10, 149.94 examples/s]Tokenizing train dataset:  82%|████████▏ | 7057/8564 [01:09<00:11, 136.24 examples/s]Tokenizing train dataset:  82%|████████▏ | 7004/8564 [01:10<00:11, 141.47 examples/s]Tokenizing train dataset:  82%|████████▏ | 7002/8564 [01:10<00:09, 158.36 examples/s]Tokenizing train dataset:  83%|████████▎ | 7082/8564 [01:09<00:09, 161.36 examples/s]Tokenizing train dataset:  82%|████████▏ | 7020/8564 [01:10<00:13, 118.06 examples/s]Tokenizing train dataset:  83%|████████▎ | 7105/8564 [01:09<00:08, 169.94 examples/s]Tokenizing train dataset:  82%|████████▏ | 7023/8564 [01:10<00:10, 144.96 examples/s]Tokenizing train dataset:  82%|████████▏ | 7034/8564 [01:10<00:13, 117.17 examples/s]Tokenizing train dataset:  82%|████████▏ | 7048/8564 [01:10<00:09, 162.53 examples/s]Tokenizing train dataset:  82%|████████▏ | 7057/8564 [01:10<00:10, 140.47 examples/s]Tokenizing train dataset:  83%|████████▎ | 7133/8564 [01:10<00:09, 150.28 examples/s]Tokenizing train dataset:  83%|████████▎ | 7077/8564 [01:10<00:08, 169.66 examples/s]Tokenizing train dataset:  83%|████████▎ | 7150/8564 [01:10<00:09, 143.29 examples/s]Tokenizing train dataset:  83%|████████▎ | 7097/8564 [01:10<00:08, 175.32 examples/s]Tokenizing train dataset:  83%|████████▎ | 7085/8564 [01:10<00:10, 144.63 examples/s]Tokenizing train dataset:  84%|████████▎ | 7167/8564 [01:10<00:09, 140.64 examples/s]Tokenizing train dataset:  83%|████████▎ | 7127/8564 [01:10<00:08, 176.11 examples/s]Tokenizing train dataset:  83%|████████▎ | 7109/8564 [01:11<00:10, 137.28 examples/s]Tokenizing train dataset:  84%|████████▍ | 7187/8564 [01:10<00:09, 143.43 examples/s]Tokenizing train dataset:  83%|████████▎ | 7148/8564 [01:10<00:07, 180.41 examples/s]Tokenizing train dataset:  83%|████████▎ | 7126/8564 [01:11<00:10, 135.03 examples/s]Tokenizing train dataset:  84%|████████▍ | 7207/8564 [01:10<00:09, 150.57 examples/s]Tokenizing train dataset:  84%|████████▎ | 7170/8564 [01:11<00:08, 165.92 examples/s]Tokenizing train dataset:  83%|████████▎ | 7150/8564 [01:11<00:09, 152.70 examples/s]Tokenizing train dataset:  84%|████████▍ | 7224/8564 [01:10<00:09, 148.28 examples/s]Tokenizing train dataset:  84%|████████▍ | 7195/8564 [01:11<00:08, 168.72 examples/s]Tokenizing train dataset:  84%|████████▍ | 7174/8564 [01:11<00:08, 158.94 examples/s]Tokenizing train dataset:  85%|████████▍ | 7251/8564 [01:10<00:07, 166.56 examples/s]Tokenizing train dataset:  84%|████████▍ | 7216/8564 [01:11<00:07, 173.76 examples/s]Tokenizing train dataset:  85%|████████▍ | 7274/8564 [01:10<00:07, 181.13 examples/s]Tokenizing train dataset:  84%|████████▍ | 7196/8564 [01:11<00:08, 166.47 examples/s]Tokenizing train dataset:  85%|████████▌ | 7293/8564 [01:11<00:06, 182.41 examples/s]Tokenizing train dataset:  85%|████████▍ | 7246/8564 [01:11<00:07, 176.59 examples/s]Tokenizing train dataset:  85%|████████▌ | 7318/8564 [01:11<00:06, 192.60 examples/s]Tokenizing train dataset:  84%|████████▍ | 7216/8564 [01:11<00:10, 130.00 examples/s]Tokenizing train dataset:  86%|████████▌ | 7338/8564 [01:11<00:06, 184.83 examples/s]Tokenizing train dataset:  85%|████████▍ | 7273/8564 [01:11<00:07, 162.08 examples/s]Tokenizing train dataset:  84%|████████▍ | 7234/8564 [01:11<00:11, 117.62 examples/s]Tokenizing train dataset:  86%|████████▌ | 7362/8564 [01:11<00:06, 187.40 examples/s]Tokenizing train dataset:  85%|████████▌ | 7290/8564 [01:11<00:08, 153.15 examples/s]Tokenizing train dataset:  86%|████████▌ | 7383/8564 [01:11<00:06, 191.34 examples/s]Tokenizing train dataset:  85%|████████▍ | 7248/8564 [01:12<00:11, 116.11 examples/s]Tokenizing train dataset:  85%|████████▌ | 7307/8564 [01:11<00:08, 148.82 examples/s]Tokenizing train dataset:  85%|████████▍ | 7267/8564 [01:12<00:10, 129.58 examples/s]Tokenizing train dataset:  86%|████████▌ | 7324/8564 [01:12<00:08, 151.03 examples/s]Tokenizing train dataset:  85%|████████▌ | 7290/8564 [01:12<00:08, 150.77 examples/s]Tokenizing train dataset:  87%|████████▋ | 7411/8564 [01:11<00:07, 157.88 examples/s]Tokenizing train dataset:  85%|████████▌ | 7312/8564 [01:12<00:07, 166.33 examples/s]Tokenizing train dataset:  86%|████████▌ | 7342/8564 [01:12<00:09, 134.21 examples/s]Tokenizing train dataset:  87%|████████▋ | 7429/8564 [01:11<00:07, 159.27 examples/s]Tokenizing train dataset:  86%|████████▌ | 7332/8564 [01:12<00:07, 173.37 examples/s]Tokenizing train dataset:  86%|████████▌ | 7360/8564 [01:12<00:08, 136.66 examples/s]Tokenizing train dataset:  87%|████████▋ | 7447/8564 [01:12<00:07, 152.37 examples/s]Tokenizing train dataset:  86%|████████▌ | 7354/8564 [01:12<00:06, 180.47 examples/s]Tokenizing train dataset:  86%|████████▌ | 7375/8564 [01:12<00:08, 133.13 examples/s]Tokenizing train dataset:  86%|████████▌ | 7380/8564 [01:12<00:06, 194.69 examples/s]Tokenizing train dataset:  87%|████████▋ | 7466/8564 [01:12<00:08, 129.47 examples/s]Tokenizing train dataset:  86%|████████▋ | 7389/8564 [01:12<00:09, 129.78 examples/s]Tokenizing train dataset:  86%|████████▋ | 7403/8564 [01:12<00:06, 178.85 examples/s]Tokenizing train dataset:  86%|████████▋ | 7406/8564 [01:12<00:08, 130.85 examples/s]Tokenizing train dataset:  87%|████████▋ | 7486/8564 [01:12<00:08, 123.17 examples/s]Tokenizing train dataset:  87%|████████▋ | 7425/8564 [01:13<00:06, 183.43 examples/s]Tokenizing train dataset:  87%|████████▋ | 7422/8564 [01:12<00:08, 129.36 examples/s]Tokenizing train dataset:  88%|████████▊ | 7504/8564 [01:12<00:08, 127.85 examples/s]Tokenizing train dataset:  87%|████████▋ | 7450/8564 [01:13<00:05, 190.23 examples/s]Tokenizing train dataset:  87%|████████▋ | 7443/8564 [01:13<00:07, 141.32 examples/s]Tokenizing train dataset:  88%|████████▊ | 7524/8564 [01:12<00:07, 133.32 examples/s]Tokenizing train dataset:  87%|████████▋ | 7471/8564 [01:13<00:05, 187.22 examples/s]Tokenizing train dataset:  87%|████████▋ | 7464/8564 [01:13<00:06, 157.46 examples/s]Tokenizing train dataset:  88%|████████▊ | 7544/8564 [01:12<00:06, 146.90 examples/s]Tokenizing train dataset:  87%|████████▋ | 7490/8564 [01:13<00:06, 177.81 examples/s]Tokenizing train dataset:  88%|████████▊ | 7564/8564 [01:12<00:06, 154.43 examples/s]Tokenizing train dataset:  87%|████████▋ | 7488/8564 [01:13<00:07, 146.47 examples/s]Tokenizing train dataset:  89%|████████▊ | 7585/8564 [01:12<00:06, 162.29 examples/s]Tokenizing train dataset:  88%|████████▊ | 7513/8564 [01:13<00:06, 156.57 examples/s]Tokenizing train dataset:  88%|████████▊ | 7508/8564 [01:13<00:06, 152.48 examples/s]Tokenizing train dataset:  88%|████████▊ | 7534/8564 [01:13<00:06, 162.21 examples/s]Tokenizing train dataset:  88%|████████▊ | 7532/8564 [01:13<00:06, 162.14 examples/s]Tokenizing train dataset:  89%|████████▉ | 7610/8564 [01:13<00:06, 152.10 examples/s]Tokenizing train dataset:  88%|████████▊ | 7551/8564 [01:13<00:06, 168.16 examples/s]Tokenizing train dataset:  88%|████████▊ | 7553/8564 [01:13<00:06, 157.96 examples/s]Tokenizing train dataset:  89%|████████▉ | 7632/8564 [01:13<00:05, 164.14 examples/s]Tokenizing train dataset:  88%|████████▊ | 7573/8564 [01:13<00:05, 177.71 examples/s]Tokenizing train dataset:  88%|████████▊ | 7570/8564 [01:13<00:06, 155.01 examples/s]Tokenizing train dataset:  89%|████████▊ | 7596/8564 [01:13<00:05, 182.76 examples/s]Tokenizing train dataset:  89%|████████▊ | 7588/8564 [01:14<00:06, 151.12 examples/s]Tokenizing train dataset:  89%|████████▉ | 7657/8564 [01:13<00:06, 136.50 examples/s]Tokenizing train dataset:  90%|████████▉ | 7680/8564 [01:13<00:05, 152.82 examples/s]Tokenizing train dataset:  89%|████████▉ | 7609/8564 [01:14<00:06, 140.26 examples/s]Tokenizing train dataset:  89%|████████▉ | 7625/8564 [01:14<00:06, 153.65 examples/s]Tokenizing train dataset:  90%|████████▉ | 7703/8564 [01:13<00:05, 167.61 examples/s]Tokenizing train dataset:  89%|████████▉ | 7633/8564 [01:14<00:05, 157.07 examples/s]Tokenizing train dataset:  90%|█████████ | 7723/8564 [01:13<00:04, 175.07 examples/s]Tokenizing train dataset:  89%|████████▉ | 7655/8564 [01:14<00:05, 161.12 examples/s]Tokenizing train dataset:  89%|████████▉ | 7644/8564 [01:14<00:06, 131.95 examples/s]Tokenizing train dataset:  90%|█████████ | 7742/8564 [01:13<00:04, 176.21 examples/s]Tokenizing train dataset:  89%|████████▉ | 7660/8564 [01:14<00:07, 126.07 examples/s]Tokenizing train dataset:  90%|████████▉ | 7679/8564 [01:14<00:05, 155.37 examples/s]Tokenizing train dataset:  91%|█████████ | 7767/8564 [01:14<00:04, 161.93 examples/s]Tokenizing train dataset:  90%|████████▉ | 7696/8564 [01:14<00:05, 156.22 examples/s]Tokenizing train dataset:  90%|████████▉ | 7680/8564 [01:14<00:07, 122.76 examples/s]Tokenizing train dataset:  91%|█████████ | 7787/8564 [01:14<00:04, 166.32 examples/s]Tokenizing train dataset:  90%|█████████ | 7717/8564 [01:14<00:05, 166.88 examples/s]Tokenizing train dataset:  90%|████████▉ | 7693/8564 [01:14<00:07, 121.68 examples/s]Tokenizing train dataset:  91%|█████████ | 7808/8564 [01:14<00:04, 153.80 examples/s]Tokenizing train dataset:  90%|█████████ | 7708/8564 [01:14<00:06, 124.62 examples/s]Tokenizing train dataset:  90%|█████████ | 7742/8564 [01:15<00:05, 158.77 examples/s]Tokenizing train dataset:  91%|█████████▏| 7828/8564 [01:14<00:04, 159.33 examples/s]Tokenizing train dataset:  91%|█████████ | 7760/8564 [01:15<00:04, 162.36 examples/s]Tokenizing train dataset:  90%|█████████ | 7724/8564 [01:14<00:06, 125.62 examples/s]Tokenizing train dataset:  92%|█████████▏| 7859/8564 [01:14<00:03, 195.54 examples/s]Tokenizing train dataset:  92%|█████████▏| 7882/8564 [01:14<00:03, 201.56 examples/s]Tokenizing train dataset:  91%|█████████ | 7782/8564 [01:15<00:05, 146.48 examples/s]Tokenizing train dataset:  90%|█████████ | 7746/8564 [01:15<00:06, 125.56 examples/s]Tokenizing train dataset:  92%|█████████▏| 7905/8564 [01:14<00:03, 201.61 examples/s]Tokenizing train dataset:  91%|█████████ | 7764/8564 [01:15<00:05, 136.23 examples/s]Tokenizing train dataset:  91%|█████████ | 7798/8564 [01:15<00:05, 131.12 examples/s]Tokenizing train dataset:  93%|█████████▎| 7927/8564 [01:14<00:03, 205.52 examples/s]Tokenizing train dataset:  91%|█████████ | 7781/8564 [01:15<00:05, 142.88 examples/s]Tokenizing train dataset:  91%|█████████▏| 7822/8564 [01:15<00:05, 133.82 examples/s]Tokenizing train dataset:  91%|█████████ | 7801/8564 [01:15<00:05, 147.81 examples/s]Tokenizing train dataset:  93%|█████████▎| 7954/8564 [01:15<00:03, 193.56 examples/s]Tokenizing train dataset:  92%|█████████▏| 7841/8564 [01:15<00:05, 136.90 examples/s]Tokenizing train dataset:  93%|█████████▎| 7974/8564 [01:15<00:03, 181.49 examples/s]Tokenizing train dataset:  91%|█████████▏| 7823/8564 [01:15<00:05, 128.18 examples/s]Tokenizing train dataset:  92%|█████████▏| 7859/8564 [01:15<00:04, 145.25 examples/s]Tokenizing train dataset:  93%|█████████▎| 7994/8564 [01:15<00:03, 172.42 examples/s]Tokenizing train dataset:  92%|█████████▏| 7843/8564 [01:15<00:05, 135.12 examples/s]Tokenizing train dataset:  92%|█████████▏| 7880/8564 [01:16<00:04, 148.77 examples/s]Tokenizing train dataset:  94%|█████████▎| 8013/8564 [01:15<00:03, 163.15 examples/s]Tokenizing train dataset:  92%|█████████▏| 7902/8564 [01:16<00:04, 164.36 examples/s]Tokenizing train dataset:  92%|█████████▏| 7859/8564 [01:15<00:05, 131.50 examples/s]Tokenizing train dataset:  92%|█████████▏| 7920/8564 [01:16<00:04, 157.01 examples/s]Tokenizing train dataset:  92%|█████████▏| 7878/8564 [01:16<00:04, 140.05 examples/s]Tokenizing train dataset:  94%|█████████▍| 8042/8564 [01:15<00:03, 149.60 examples/s]Tokenizing train dataset:  92%|█████████▏| 7902/8564 [01:16<00:04, 154.82 examples/s]Tokenizing train dataset:  94%|█████████▍| 8064/8564 [01:15<00:03, 160.51 examples/s]Tokenizing train dataset:  93%|█████████▎| 7940/8564 [01:16<00:04, 137.98 examples/s]Tokenizing train dataset:  93%|█████████▎| 7923/8564 [01:16<00:04, 159.75 examples/s]Tokenizing train dataset:  93%|█████████▎| 7957/8564 [01:16<00:04, 138.57 examples/s]Tokenizing train dataset:  94%|█████████▍| 8084/8564 [01:15<00:03, 144.95 examples/s]Tokenizing train dataset:  93%|█████████▎| 7975/8564 [01:16<00:04, 140.93 examples/s]Tokenizing train dataset:  95%|█████████▍| 8104/8564 [01:16<00:03, 151.99 examples/s]Tokenizing train dataset:  93%|█████████▎| 7942/8564 [01:16<00:04, 134.13 examples/s]Tokenizing train dataset:  93%|█████████▎| 7995/8564 [01:16<00:03, 144.23 examples/s]Tokenizing train dataset:  95%|█████████▍| 8121/8564 [01:16<00:03, 146.71 examples/s]Tokenizing train dataset:  93%|█████████▎| 7960/8564 [01:16<00:04, 135.32 examples/s]Tokenizing train dataset:  95%|█████████▌| 8144/8564 [01:16<00:02, 158.97 examples/s]Tokenizing train dataset:  94%|█████████▎| 8013/8564 [01:16<00:03, 141.63 examples/s]Tokenizing train dataset:  93%|█████████▎| 7979/8564 [01:16<00:04, 137.45 examples/s]Tokenizing train dataset:  95%|█████████▌| 8164/8564 [01:16<00:02, 165.54 examples/s]Tokenizing train dataset:  94%|█████████▍| 8029/8564 [01:17<00:03, 136.69 examples/s]Tokenizing train dataset:  93%|█████████▎| 7997/8564 [01:16<00:04, 138.61 examples/s]Tokenizing train dataset:  96%|█████████▌| 8192/8564 [01:16<00:02, 174.18 examples/s]Tokenizing train dataset:  94%|█████████▎| 8019/8564 [01:17<00:03, 151.71 examples/s]Tokenizing train dataset:  94%|█████████▍| 8050/8564 [01:17<00:03, 140.41 examples/s]Tokenizing train dataset:  94%|█████████▍| 8041/8564 [01:17<00:03, 161.93 examples/s]Tokenizing train dataset:  94%|█████████▍| 8073/8564 [01:17<00:03, 142.54 examples/s]Tokenizing train dataset:  96%|█████████▌| 8214/8564 [01:16<00:02, 145.00 examples/s]Tokenizing train dataset:  94%|█████████▍| 8060/8564 [01:17<00:03, 165.86 examples/s]Tokenizing train dataset:  96%|█████████▌| 8236/8564 [01:16<00:02, 155.39 examples/s]Tokenizing train dataset:  95%|█████████▍| 8098/8564 [01:17<00:03, 134.37 examples/s]Tokenizing train dataset:  94%|█████████▍| 8079/8564 [01:17<00:03, 154.28 examples/s]Tokenizing train dataset:  96%|█████████▋| 8253/8564 [01:17<00:02, 149.72 examples/s]Tokenizing train dataset:  95%|█████████▍| 8115/8564 [01:17<00:03, 136.60 examples/s]Tokenizing train dataset:  97%|█████████▋| 8277/8564 [01:17<00:01, 163.76 examples/s]Tokenizing train dataset:  95%|█████████▍| 8101/8564 [01:17<00:03, 126.50 examples/s]Tokenizing train dataset:  95%|█████████▍| 8130/8564 [01:17<00:03, 128.96 examples/s]Tokenizing train dataset:  97%|█████████▋| 8300/8564 [01:17<00:01, 165.46 examples/s]Tokenizing train dataset:  95%|█████████▍| 8116/8564 [01:17<00:03, 123.16 examples/s]Tokenizing train dataset:  95%|█████████▌| 8149/8564 [01:17<00:03, 135.17 examples/s]Tokenizing train dataset:  97%|█████████▋| 8318/8564 [01:17<00:01, 158.51 examples/s]Tokenizing train dataset:  95%|█████████▍| 8130/8564 [01:17<00:03, 119.12 examples/s]Tokenizing train dataset:  95%|█████████▌| 8166/8564 [01:18<00:02, 133.90 examples/s]Tokenizing train dataset:  95%|█████████▌| 8150/8564 [01:18<00:03, 133.81 examples/s]Tokenizing train dataset:  96%|█████████▌| 8185/8564 [01:18<00:02, 143.67 examples/s]Tokenizing train dataset:  97%|█████████▋| 8342/8564 [01:17<00:01, 148.00 examples/s]Tokenizing train dataset:  96%|█████████▌| 8205/8564 [01:18<00:02, 156.23 examples/s]Tokenizing train dataset:  95%|█████████▌| 8174/8564 [01:18<00:02, 153.15 examples/s]Tokenizing train dataset:  96%|█████████▌| 8199/8564 [01:18<00:02, 169.64 examples/s]Tokenizing train dataset:  98%|█████████▊| 8366/8564 [01:17<00:01, 130.87 examples/s]Tokenizing train dataset:  96%|█████████▌| 8232/8564 [01:18<00:02, 162.29 examples/s]Tokenizing train dataset:  96%|█████████▋| 8259/8564 [01:18<00:01, 188.05 examples/s]Tokenizing train dataset:  98%|█████████▊| 8388/8564 [01:17<00:01, 143.31 examples/s]Tokenizing train dataset:  98%|█████████▊| 8410/8564 [01:18<00:00, 157.79 examples/s]Tokenizing train dataset:  96%|█████████▌| 8223/8564 [01:18<00:02, 135.84 examples/s]Tokenizing train dataset:  97%|█████████▋| 8287/8564 [01:18<00:01, 197.86 examples/s]Tokenizing train dataset:  98%|█████████▊| 8432/8564 [01:18<00:00, 170.99 examples/s]Tokenizing train dataset:  96%|█████████▋| 8243/8564 [01:18<00:02, 131.53 examples/s]Tokenizing train dataset:  97%|█████████▋| 8310/8564 [01:18<00:01, 163.82 examples/s]Tokenizing train dataset:  99%|█████████▉| 8459/8564 [01:18<00:00, 185.18 examples/s]Tokenizing train dataset:  96%|█████████▋| 8263/8564 [01:18<00:02, 138.38 examples/s]Tokenizing train dataset:  97%|█████████▋| 8330/8564 [01:18<00:01, 171.23 examples/s]Tokenizing train dataset:  99%|█████████▉| 8485/8564 [01:18<00:00, 199.30 examples/s]Tokenizing train dataset:  97%|█████████▋| 8282/8564 [01:18<00:01, 146.67 examples/s]Tokenizing train dataset:  99%|█████████▉| 8520/8564 [01:18<00:00, 205.21 examples/s]Tokenizing train dataset:  98%|█████████▊| 8353/8564 [01:19<00:01, 146.49 examples/s]Tokenizing train dataset:  97%|█████████▋| 8299/8564 [01:19<00:01, 133.25 examples/s]Tokenizing train dataset: 100%|█████████▉| 8551/8564 [01:18<00:00, 225.57 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:18<00:00, 108.73 examples/s]
Tokenizing train dataset:  97%|█████████▋| 8322/8564 [01:19<00:01, 154.00 examples/s]Tokenizing train dataset:  98%|█████████▊| 8373/8564 [01:19<00:01, 131.19 examples/s]Tokenizing train dataset:  97%|█████████▋| 8339/8564 [01:19<00:01, 157.09 examples/s]Tokenizing train dataset:  98%|█████████▊| 8392/8564 [01:19<00:01, 133.00 examples/s]Tokenizing train dataset:  98%|█████████▊| 8410/8564 [01:19<00:01, 140.02 examples/s]Tokenizing train dataset:  98%|█████████▊| 8359/8564 [01:19<00:01, 134.45 examples/s]Tokenizing train dataset:  98%|█████████▊| 8429/8564 [01:19<00:00, 147.46 examples/s]Tokenizing train dataset:  98%|█████████▊| 8374/8564 [01:19<00:01, 132.62 examples/s]Tokenizing train dataset:  99%|█████████▊| 8449/8564 [01:19<00:00, 159.17 examples/s]Tokenizing train dataset:  98%|█████████▊| 8389/8564 [01:19<00:01, 132.91 examples/s]Tokenizing train dataset:  99%|█████████▉| 8467/8564 [01:19<00:00, 160.19 examples/s]Tokenizing train dataset:  98%|█████████▊| 8404/8564 [01:19<00:01, 122.27 examples/s]Tokenizing train dataset:  99%|█████████▉| 8500/8564 [01:20<00:00, 204.05 examples/s]Tokenizing train dataset:  98%|█████████▊| 8417/8564 [01:19<00:01, 122.52 examples/s]Tokenizing train dataset: 100%|█████████▉| 8525/8564 [01:20<00:00, 215.60 examples/s]Tokenizing train dataset:  98%|█████████▊| 8430/8564 [01:20<00:01, 122.97 examples/s]Tokenizing train dataset:  99%|█████████▊| 8445/8564 [01:20<00:00, 121.57 examples/s]Tokenizing train dataset: 100%|█████████▉| 8551/8564 [01:20<00:00, 168.61 examples/s]Tokenizing train dataset:  99%|█████████▉| 8467/8564 [01:20<00:00, 140.71 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:20<00:00, 106.38 examples/s]
Tokenizing train dataset:  99%|█████████▉| 8489/8564 [01:20<00:00, 133.87 examples/s]Tokenizing train dataset:  99%|█████████▉| 8510/8564 [01:20<00:00, 147.81 examples/s]Tokenizing train dataset: 100%|█████████▉| 8534/8564 [01:20<00:00, 164.76 examples/s]Tokenizing train dataset: 100%|█████████▉| 8560/8564 [01:20<00:00, 155.68 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:20<00:00, 105.80 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  54%|█████▎    | 512/953 [00:00<00:00, 5054.15 examples/s]Extracting prompt in eval dataset:  31%|███▏      | 300/953 [00:00<00:00, 2739.43 examples/s]Extracting prompt in eval dataset:  36%|███▌      | 342/953 [00:00<00:00, 2517.35 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5285.92 examples/s]
Extracting prompt in eval dataset:  63%|██████▎   | 600/953 [00:00<00:00, 2729.14 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  74%|███████▎  | 702/953 [00:00<00:00, 3001.10 examples/s]Extracting prompt in eval dataset:  94%|█████████▍| 900/953 [00:00<00:00, 2839.66 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2893.93 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2766.40 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  43%|████▎     | 406/953 [00:00<00:00, 4031.85 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  39%|███▉      | 370/953 [00:00<00:00, 3664.00 examples/s]Applying chat template to eval dataset:  45%|████▌     | 430/953 [00:00<00:00, 4252.65 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3624.37 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3647.70 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3617.41 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3592.60 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3810.83 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3667.38 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   2%|▏         | 20/953 [00:00<00:04, 187.72 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   5%|▍         | 47/953 [00:00<00:05, 178.79 examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:09, 94.82 examples/s]Tokenizing eval dataset:   1%|          | 11/953 [00:00<00:09, 102.13 examples/s]Tokenizing eval dataset:   3%|▎         | 27/953 [00:00<00:07, 125.63 examples/s]Tokenizing eval dataset:   2%|▏         | 23/953 [00:00<00:09, 100.94 examples/s]Tokenizing eval dataset:   5%|▍         | 46/953 [00:00<00:06, 140.87 examples/s]Tokenizing eval dataset:   7%|▋         | 70/953 [00:00<00:07, 115.52 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:09, 99.75 examples/s] Tokenizing eval dataset:   9%|▉         | 87/953 [00:00<00:07, 119.13 examples/s]Tokenizing eval dataset:   5%|▌         | 52/953 [00:00<00:07, 121.26 examples/s]Tokenizing eval dataset:   7%|▋         | 66/953 [00:00<00:08, 104.76 examples/s]Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:07, 121.42 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:08, 106.60 examples/s]Tokenizing eval dataset:  11%|█         | 106/953 [00:00<00:08, 102.13 examples/s]Tokenizing eval dataset:   9%|▉         | 87/953 [00:00<00:06, 126.15 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:01<00:08, 94.26 examples/s] Tokenizing eval dataset:  10%|▉         | 91/953 [00:00<00:09, 88.44 examples/s] Tokenizing eval dataset:  11%|█         | 105/953 [00:00<00:06, 121.71 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:06, 125.67 examples/s]Tokenizing eval dataset:  14%|█▍        | 134/953 [00:01<00:09, 89.97 examples/s]Tokenizing eval dataset:  11%|█         | 107/953 [00:01<00:09, 88.12 examples/s]Tokenizing eval dataset:  14%|█▍        | 136/953 [00:01<00:07, 111.00 examples/s]Tokenizing eval dataset:  15%|█▌        | 146/953 [00:01<00:09, 84.14 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:01<00:09, 83.63 examples/s]Tokenizing eval dataset:  17%|█▋        | 159/953 [00:01<00:09, 83.84 examples/s]Tokenizing eval dataset:  14%|█▍        | 132/953 [00:01<00:10, 81.55 examples/s]Tokenizing eval dataset:  16%|█▌        | 151/953 [00:01<00:08, 90.01 examples/s] Tokenizing eval dataset:  18%|█▊        | 168/953 [00:01<00:10, 73.65 examples/s]Tokenizing eval dataset:  15%|█▌        | 145/953 [00:01<00:09, 81.32 examples/s]Tokenizing eval dataset:  17%|█▋        | 165/953 [00:01<00:09, 86.78 examples/s]Tokenizing eval dataset:  18%|█▊        | 176/953 [00:01<00:10, 73.44 examples/s]Tokenizing eval dataset:  17%|█▋        | 159/953 [00:01<00:10, 78.96 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:09, 78.26 examples/s]Tokenizing eval dataset:  19%|█▊        | 178/953 [00:01<00:10, 72.86 examples/s]Tokenizing eval dataset:  21%|██        | 199/953 [00:02<00:08, 84.87 examples/s]Tokenizing eval dataset:  18%|█▊        | 169/953 [00:01<00:10, 74.10 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:10, 70.01 examples/s]Tokenizing eval dataset:  19%|█▊        | 177/953 [00:02<00:10, 74.45 examples/s]Tokenizing eval dataset:  22%|██▏       | 209/953 [00:02<00:08, 83.56 examples/s]Tokenizing eval dataset:  20%|██        | 195/953 [00:02<00:10, 72.22 examples/s]Tokenizing eval dataset:  24%|██▎       | 225/953 [00:02<00:07, 101.42 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:02<00:10, 71.57 examples/s]Tokenizing eval dataset:  22%|██▏       | 205/953 [00:02<00:09, 75.21 examples/s]Tokenizing eval dataset:  26%|██▌       | 245/953 [00:02<00:06, 117.66 examples/s]Tokenizing eval dataset:  21%|██        | 197/953 [00:02<00:09, 77.13 examples/s]Tokenizing eval dataset:  28%|██▊       | 264/953 [00:02<00:05, 130.96 examples/s]Tokenizing eval dataset:  23%|██▎       | 216/953 [00:02<00:07, 102.94 examples/s]Tokenizing eval dataset:  23%|██▎       | 217/953 [00:02<00:09, 74.11 examples/s]Tokenizing eval dataset:  30%|███       | 287/953 [00:02<00:04, 152.02 examples/s]Tokenizing eval dataset:  26%|██▌       | 250/953 [00:02<00:04, 160.08 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:02<00:07, 92.21 examples/s]Tokenizing eval dataset:  30%|███       | 290/953 [00:02<00:03, 216.78 examples/s]Tokenizing eval dataset:  32%|███▏      | 308/953 [00:02<00:04, 158.12 examples/s]Tokenizing eval dataset:  27%|██▋       | 258/953 [00:02<00:05, 120.07 examples/s]Tokenizing eval dataset:  34%|███▍      | 324/953 [00:02<00:02, 247.16 examples/s]Tokenizing eval dataset:  35%|███▍      | 331/953 [00:02<00:03, 173.81 examples/s]Tokenizing eval dataset:  29%|██▉       | 280/953 [00:02<00:04, 137.58 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:02<00:02, 264.97 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:03<00:03, 183.19 examples/s]Tokenizing eval dataset:  31%|███▏      | 300/953 [00:02<00:04, 142.06 examples/s]Tokenizing eval dataset:  41%|████      | 392/953 [00:02<00:02, 278.49 examples/s]Tokenizing eval dataset:  40%|███▉      | 381/953 [00:03<00:03, 188.64 examples/s]Tokenizing eval dataset:  34%|███▍      | 324/953 [00:02<00:03, 158.14 examples/s]Tokenizing eval dataset:  42%|████▏     | 400/953 [00:03<00:02, 186.51 examples/s]Tokenizing eval dataset:  45%|████▍     | 425/953 [00:03<00:02, 251.27 examples/s]Tokenizing eval dataset:  36%|███▌      | 345/953 [00:03<00:03, 170.09 examples/s]Tokenizing eval dataset:  44%|████▍     | 420/953 [00:03<00:02, 187.21 examples/s]Tokenizing eval dataset:  48%|████▊     | 460/953 [00:03<00:02, 231.82 examples/s]Tokenizing eval dataset:  38%|███▊      | 364/953 [00:03<00:04, 140.77 examples/s]Tokenizing eval dataset:  47%|████▋     | 450/953 [00:03<00:02, 172.86 examples/s]Tokenizing eval dataset:  40%|████      | 383/953 [00:03<00:03, 146.46 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:03<00:02, 168.94 examples/s]Tokenizing eval dataset:  51%|█████▏    | 489/953 [00:03<00:02, 186.25 examples/s]Tokenizing eval dataset:  43%|████▎     | 411/953 [00:03<00:03, 170.68 examples/s]Tokenizing eval dataset:  51%|█████▏    | 490/953 [00:03<00:02, 170.24 examples/s]Tokenizing eval dataset:  54%|█████▎    | 511/953 [00:03<00:02, 184.81 examples/s]Tokenizing eval dataset:  46%|████▌     | 438/953 [00:03<00:02, 192.71 examples/s]Tokenizing eval dataset:  54%|█████▎    | 510/953 [00:03<00:02, 171.41 examples/s]Tokenizing eval dataset:  49%|████▊     | 464/953 [00:03<00:02, 197.75 examples/s]Tokenizing eval dataset:  57%|█████▋    | 542/953 [00:03<00:02, 177.78 examples/s]Tokenizing eval dataset:  55%|█████▌    | 528/953 [00:04<00:02, 172.12 examples/s]Tokenizing eval dataset:  59%|█████▉    | 563/953 [00:03<00:02, 182.49 examples/s]Tokenizing eval dataset:  58%|█████▊    | 550/953 [00:04<00:02, 179.53 examples/s]Tokenizing eval dataset:  52%|█████▏    | 491/953 [00:03<00:02, 184.19 examples/s]Tokenizing eval dataset:  60%|█████▉    | 570/953 [00:04<00:02, 182.46 examples/s]Tokenizing eval dataset:  62%|██████▏   | 595/953 [00:04<00:01, 190.47 examples/s]Tokenizing eval dataset:  54%|█████▎    | 512/953 [00:04<00:02, 183.97 examples/s]Tokenizing eval dataset:  62%|██████▏   | 590/953 [00:04<00:01, 182.16 examples/s]Tokenizing eval dataset:  65%|██████▌   | 622/953 [00:04<00:01, 200.45 examples/s]Tokenizing eval dataset:  57%|█████▋    | 540/953 [00:04<00:02, 181.95 examples/s]Tokenizing eval dataset:  64%|██████▍   | 610/953 [00:04<00:01, 185.30 examples/s]Tokenizing eval dataset:  68%|██████▊   | 644/953 [00:04<00:01, 204.59 examples/s]Tokenizing eval dataset:  59%|█████▉    | 564/953 [00:04<00:02, 188.01 examples/s]Tokenizing eval dataset:  66%|██████▋   | 632/953 [00:04<00:01, 193.50 examples/s]Tokenizing eval dataset:  61%|██████▏   | 585/953 [00:04<00:01, 192.58 examples/s]Tokenizing eval dataset:  71%|███████   | 672/953 [00:04<00:01, 191.02 examples/s]Tokenizing eval dataset:  70%|██████▉   | 664/953 [00:04<00:01, 227.65 examples/s]Tokenizing eval dataset:  73%|███████▎  | 697/953 [00:04<00:01, 200.39 examples/s]Tokenizing eval dataset:  64%|██████▍   | 608/953 [00:04<00:01, 186.06 examples/s]Tokenizing eval dataset:  73%|███████▎  | 692/953 [00:04<00:01, 231.50 examples/s]Tokenizing eval dataset:  66%|██████▌   | 631/953 [00:04<00:01, 193.16 examples/s]Tokenizing eval dataset:  76%|███████▌  | 721/953 [00:04<00:00, 241.90 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:04<00:01, 182.78 examples/s]Tokenizing eval dataset:  69%|██████▉   | 660/953 [00:04<00:01, 185.88 examples/s]Tokenizing eval dataset:  78%|███████▊  | 747/953 [00:05<00:00, 206.78 examples/s]Tokenizing eval dataset:  79%|███████▊  | 749/953 [00:04<00:01, 157.44 examples/s]Tokenizing eval dataset:  71%|███████▏  | 681/953 [00:04<00:01, 162.33 examples/s]Tokenizing eval dataset:  81%|████████  | 774/953 [00:05<00:00, 183.42 examples/s]Tokenizing eval dataset:  81%|████████  | 769/953 [00:05<00:01, 156.44 examples/s]Tokenizing eval dataset:  74%|███████▎  | 701/953 [00:05<00:01, 165.67 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:05<00:01, 152.14 examples/s]Tokenizing eval dataset:  84%|████████▎ | 796/953 [00:05<00:00, 164.54 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:05<00:01, 172.60 examples/s]Tokenizing eval dataset:  85%|████████▍ | 809/953 [00:05<00:00, 146.08 examples/s]Tokenizing eval dataset:  86%|████████▌ | 821/953 [00:05<00:00, 159.94 examples/s]Tokenizing eval dataset:  78%|███████▊  | 742/953 [00:05<00:01, 154.55 examples/s]Tokenizing eval dataset:  81%|████████  | 769/953 [00:05<00:01, 179.13 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:05<00:00, 139.96 examples/s]Tokenizing eval dataset:  89%|████████▉ | 846/953 [00:05<00:00, 157.45 examples/s]Tokenizing eval dataset:  89%|████████▉ | 850/953 [00:05<00:00, 143.02 examples/s]Tokenizing eval dataset:  83%|████████▎ | 790/953 [00:05<00:01, 158.38 examples/s]Tokenizing eval dataset:  91%|█████████ | 869/953 [00:05<00:00, 149.67 examples/s]Tokenizing eval dataset:  85%|████████▌ | 811/953 [00:05<00:00, 150.67 examples/s]Tokenizing eval dataset:  94%|█████████▍| 894/953 [00:06<00:00, 159.82 examples/s]Tokenizing eval dataset:  92%|█████████▏| 874/953 [00:05<00:00, 136.24 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:05<00:00, 158.05 examples/s]Tokenizing eval dataset:  94%|█████████▍| 898/953 [00:05<00:00, 156.37 examples/s]Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Tokenizing eval dataset:  96%|█████████▌| 915/953 [00:06<00:00, 143.98 examples/s]Tokenizing eval dataset:  96%|█████████▋| 918/953 [00:06<00:00, 163.86 examples/s]Tokenizing eval dataset:  89%|████████▉ | 848/953 [00:06<00:00, 153.23 examples/s]Tokenizing eval dataset:  98%|█████████▊| 937/953 [00:06<00:00, 159.34 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:06<00:00, 153.89 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:06<00:00, 147.94 examples/s]
Tokenizing eval dataset:  92%|█████████▏| 881/953 [00:06<00:00, 170.62 examples/s]Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Tokenizing eval dataset:  95%|█████████▌| 910/953 [00:06<00:00, 186.98 examples/s]Tokenizing eval dataset:  97%|█████████▋| 929/953 [00:06<00:00, 187.11 examples/s]Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:06<00:00, 145.97 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 5.119073867797852 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.513824462890625 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.538543939590454 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.385524272918701 seconds
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
gn26:3649542:3649542 [2] NCCL INFO Comm config Blocking set to 1
NCCL version 2.21.5+cuda12.4
gn26:3649540:3649540 [0] NCCL INFO Comm config Blocking set to 1
gn26:3649541:3649541 [1] NCCL INFO Comm config Blocking set to 1
gn26:3649543:3649543 [3] NCCL INFO Comm config Blocking set to 1
gn26:3649542:3651317 [2] NCCL INFO Using non-device net plugin version 0
gn26:3649542:3651317 [2] NCCL INFO Using network Socket
gn26:3649543:3651320 [3] NCCL INFO Using non-device net plugin version 0
gn26:3649543:3651320 [3] NCCL INFO Using network Socket
gn26:3649541:3651319 [1] NCCL INFO Using non-device net plugin version 0
gn26:3649541:3651319 [1] NCCL INFO Using network Socket
gn26:3649540:3651318 [0] NCCL INFO Using non-device net plugin version 0
gn26:3649540:3651318 [0] NCCL INFO Using network Socket
gn26:3649542:3651317 [2] NCCL INFO ncclCommInitRank comm 0x55f6a1d6ded0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 84000 commId 0x3ee3185416e97e0e - Init START
gn26:3649541:3651319 [1] NCCL INFO ncclCommInitRank comm 0x556921dea210 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 44000 commId 0x3ee3185416e97e0e - Init START
gn26:3649543:3651320 [3] NCCL INFO ncclCommInitRank comm 0x556de3a4f090 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c4000 commId 0x3ee3185416e97e0e - Init START
gn26:3649540:3651318 [0] NCCL INFO ncclCommInitRank comm 0x560a6aee3e50 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 3000 commId 0x3ee3185416e97e0e - Init START
gn26:3649540:3651318 [0] NCCL INFO NVLS multicast support is not available on dev 0
gn26:3649543:3651320 [3] NCCL INFO NVLS multicast support is not available on dev 3
gn26:3649542:3651317 [2] NCCL INFO Setting affinity for GPU 2 to 010000,00000000,00000000,00000000,00010000,00000000,00000000,00000000
gn26:3649542:3651317 [2] NCCL INFO NVLS multicast support is not available on dev 2
gn26:3649541:3651319 [1] NCCL INFO NVLS multicast support is not available on dev 1
gn26:3649540:3651318 [0] NCCL INFO comm 0x560a6aee3e50 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
gn26:3649540:3651318 [0] NCCL INFO Channel 00/24 :    0   1   2   3
gn26:3649540:3651318 [0] NCCL INFO Channel 01/24 :    0   1   3   2
gn26:3649540:3651318 [0] NCCL INFO Channel 02/24 :    0   2   3   1
gn26:3649540:3651318 [0] NCCL INFO Channel 03/24 :    0   2   1   3
gn26:3649540:3651318 [0] NCCL INFO Channel 04/24 :    0   3   1   2
gn26:3649540:3651318 [0] NCCL INFO Channel 05/24 :    0   3   2   1
gn26:3649540:3651318 [0] NCCL INFO Channel 06/24 :    0   1   2   3
gn26:3649540:3651318 [0] NCCL INFO Channel 07/24 :    0   1   3   2
gn26:3649540:3651318 [0] NCCL INFO Channel 08/24 :    0   2   3   1
gn26:3649540:3651318 [0] NCCL INFO Channel 09/24 :    0   2   1   3
gn26:3649540:3651318 [0] NCCL INFO Channel 10/24 :    0   3   1   2
gn26:3649540:3651318 [0] NCCL INFO Channel 11/24 :    0   3   2   1
gn26:3649540:3651318 [0] NCCL INFO Channel 12/24 :    0   1   2   3
gn26:3649540:3651318 [0] NCCL INFO Channel 13/24 :    0   1   3   2
gn26:3649540:3651318 [0] NCCL INFO Channel 14/24 :    0   2   3   1
gn26:3649540:3651318 [0] NCCL INFO Channel 15/24 :    0   2   1   3
gn26:3649540:3651318 [0] NCCL INFO Channel 16/24 :    0   3   1   2
gn26:3649540:3651318 [0] NCCL INFO Channel 17/24 :    0   3   2   1
gn26:3649540:3651318 [0] NCCL INFO Channel 18/24 :    0   1   2   3
gn26:3649540:3651318 [0] NCCL INFO Channel 19/24 :    0   1   3   2
gn26:3649540:3651318 [0] NCCL INFO Channel 20/24 :    0   2   3   1
gn26:3649540:3651318 [0] NCCL INFO Channel 21/24 :    0   2   1   3
gn26:3649540:3651318 [0] NCCL INFO Channel 22/24 :    0   3   1   2
gn26:3649540:3651318 [0] NCCL INFO Channel 23/24 :    0   3   2   1
gn26:3649540:3651318 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
gn26:3649540:3651318 [0] NCCL INFO P2P Chunksize set to 524288
gn26:3649541:3651319 [1] NCCL INFO comm 0x556921dea210 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
gn26:3649541:3651319 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
gn26:3649541:3651319 [1] NCCL INFO P2P Chunksize set to 524288
gn26:3649542:3651317 [2] NCCL INFO comm 0x55f6a1d6ded0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
gn26:3649542:3651317 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
gn26:3649542:3651317 [2] NCCL INFO P2P Chunksize set to 524288
gn26:3649543:3651320 [3] NCCL INFO comm 0x556de3a4f090 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
gn26:3649543:3651320 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
gn26:3649543:3651320 [3] NCCL INFO P2P Chunksize set to 524288
gn26:3649540:3651318 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Connected all rings
gn26:3649541:3651319 [1] NCCL INFO Connected all rings
gn26:3649540:3651318 [0] NCCL INFO Connected all rings
gn26:3649542:3651317 [2] NCCL INFO Connected all rings
gn26:3649540:3651318 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 08/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 10/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 11/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 20/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 21/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 20/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 22/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 23/0 : 3[3] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 22/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 23/0 : 0[0] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 15/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 14/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 21/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 17/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 22/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 23/0 : 2[2] -> 3[3] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 19/0 : 1[1] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 04/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 05/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 06/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 05/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 06/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 04/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 07/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 16/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 05/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 05/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 06/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 07/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 06/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 17/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 17/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 16/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 17/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 18/0 : 2[2] -> 0[0] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 18/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 18/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 17/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 19/0 : 3[3] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 18/0 : 1[1] -> 3[3] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 19/0 : 0[0] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 08/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 09/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 15/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 20/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 20/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Channel 21/0 : 0[0] -> 3[3] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 21/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649543:3651320 [3] NCCL INFO Channel 22/0 : 3[3] -> 2[2] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 21/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649541:3651319 [1] NCCL INFO Channel 22/0 : 1[1] -> 0[0] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 12/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 13/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 16/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 18/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649542:3651317 [2] NCCL INFO Channel 19/0 : 2[2] -> 1[1] via P2P/CUMEM/read
gn26:3649540:3651318 [0] NCCL INFO Connected all trees
gn26:3649542:3651317 [2] NCCL INFO Connected all trees
gn26:3649542:3651317 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn26:3649542:3651317 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gn26:3649540:3651318 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn26:3649540:3651318 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gn26:3649541:3651319 [1] NCCL INFO Connected all trees
gn26:3649541:3651319 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn26:3649541:3651319 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gn26:3649543:3651320 [3] NCCL INFO Connected all trees
gn26:3649543:3651320 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gn26:3649543:3651320 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
gn26:3649543:3651320 [3] NCCL INFO ncclCommInitRank comm 0x556de3a4f090 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c4000 commId 0x3ee3185416e97e0e - Init COMPLETE
gn26:3649541:3651319 [1] NCCL INFO ncclCommInitRank comm 0x556921dea210 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 44000 commId 0x3ee3185416e97e0e - Init COMPLETE
gn26:3649542:3651317 [2] NCCL INFO ncclCommInitRank comm 0x55f6a1d6ded0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 84000 commId 0x3ee3185416e97e0e - Init COMPLETE
gn26:3649540:3651318 [0] NCCL INFO ncclCommInitRank comm 0x560a6aee3e50 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 3000 commId 0x3ee3185416e97e0e - Init COMPLETE
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
gn26:3649543:3651450 [3] NCCL INFO Comm config Blocking set to 1
gn26:3649540:3651443 [0] NCCL INFO Comm config Blocking set to 1
gn26:3649542:3651441 [2] NCCL INFO Comm config Blocking set to 1
gn26:3649540:3651475 [0] NCCL INFO Using non-device net plugin version 0
gn26:3649540:3651475 [0] NCCL INFO Using network Socket
gn26:3649541:3651436 [1] NCCL INFO Comm config Blocking set to 1
gn26:3649543:3651474 [3] NCCL INFO Using non-device net plugin version 0
gn26:3649543:3651474 [3] NCCL INFO Using network Socket
gn26:3649542:3651476 [2] NCCL INFO Using non-device net plugin version 0
gn26:3649542:3651476 [2] NCCL INFO Using network Socket
gn26:3649541:3651477 [1] NCCL INFO Using non-device net plugin version 0
gn26:3649541:3651477 [1] NCCL INFO Using network Socket
gn26:3649541:3651477 [1] NCCL INFO ncclCommInitRank comm 0x7f5c0e2e6800 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 44000 commId 0xa659f5303d7f5fb3 - Init START
gn26:3649540:3651475 [0] NCCL INFO ncclCommInitRank comm 0x7f035caaa040 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 3000 commId 0xa659f5303d7f5fb3 - Init START
gn26:3649542:3651476 [2] NCCL INFO ncclCommInitRank comm 0x7effd22edac0 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 84000 commId 0xa659f5303d7f5fb3 - Init START
gn26:3649543:3651474 [3] NCCL INFO ncclCommInitRank comm 0x7f03faec1930 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId c4000 commId 0xa659f5303d7f5fb3 - Init START
gn26:3649540:3651475 [0] NCCL INFO NVLS multicast support is not available on dev 0
gn26:3649541:3651477 [1] NCCL INFO NVLS multicast support is not available on dev 1
gn26:3649543:3651474 [3] NCCL INFO NVLS multicast support is not available on dev 3
gn26:3649542:3651476 [2] NCCL INFO Setting affinity for GPU 2 to 010000,00000000,00000000,00000000,00010000,00000000,00000000,00000000
gn26:3649542:3651476 [2] NCCL INFO NVLS multicast support is not available on dev 2
gn26:3649543:3651474 [3] NCCL INFO comm 0x7f03faec1930 rank 7 nRanks 8 nNodes 2 localRanks 4 localRank 3 MNNVL 0
gn26:3649543:3651474 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6
gn26:3649543:3651474 [3] NCCL INFO P2P Chunksize set to 131072
gn26:3649541:3651477 [1] NCCL INFO comm 0x7f5c0e2e6800 rank 5 nRanks 8 nNodes 2 localRanks 4 localRank 1 MNNVL 0
gn26:3649540:3651475 [0] NCCL INFO comm 0x7f035caaa040 rank 4 nRanks 8 nNodes 2 localRanks 4 localRank 0 MNNVL 0
gn26:3649541:3651477 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4
gn26:3649540:3651475 [0] NCCL INFO Trees [0] 5/-1/-1->4->0 [1] 5/0/-1->4->-1
gn26:3649541:3651477 [1] NCCL INFO P2P Chunksize set to 131072
gn26:3649540:3651475 [0] NCCL INFO P2P Chunksize set to 131072
gn26:3649542:3651476 [2] NCCL INFO comm 0x7effd22edac0 rank 6 nRanks 8 nNodes 2 localRanks 4 localRank 2 MNNVL 0
gn26:3649542:3651476 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5
gn26:3649542:3651476 [2] NCCL INFO P2P Chunksize set to 131072
gn26:3649541:3651477 [1] NCCL INFO Channel 00/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gn26:3649541:3651477 [1] NCCL INFO Channel 01/0 : 5[1] -> 6[2] via P2P/CUMEM/read
gn26:3649542:3651476 [2] NCCL INFO Channel 00/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gn26:3649540:3651475 [0] NCCL INFO Channel 00/0 : 3[3] -> 4[0] [receive] via NET/Socket/0
gn26:3649542:3651476 [2] NCCL INFO Channel 01/0 : 6[2] -> 7[3] via P2P/CUMEM/read
gn26:3649543:3651474 [3] NCCL INFO Channel 00/0 : 7[3] -> 0[0] [send] via NET/Socket/0
gn26:3649540:3651475 [0] NCCL INFO Channel 01/0 : 3[3] -> 4[0] [receive] via NET/Socket/0
gn26:3649540:3651475 [0] NCCL INFO Channel 00/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gn26:3649543:3651474 [3] NCCL INFO Channel 01/0 : 7[3] -> 0[0] [send] via NET/Socket/0
gn26:3649540:3651475 [0] NCCL INFO Channel 01/0 : 4[0] -> 5[1] via P2P/CUMEM/read
gn26:3649541:3651477 [1] NCCL INFO Connected all rings
gn26:3649540:3651475 [0] NCCL INFO Connected all rings
gn26:3649540:3651475 [0] NCCL INFO Channel 00/0 : 0[0] -> 4[0] [receive] via NET/Socket/0
gn26:3649541:3651477 [1] NCCL INFO Channel 00/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gn26:3649540:3651475 [0] NCCL INFO Channel 01/0 : 0[0] -> 4[0] [receive] via NET/Socket/0
gn26:3649541:3651477 [1] NCCL INFO Channel 01/0 : 5[1] -> 4[0] via P2P/CUMEM/read
gn26:3649543:3651474 [3] NCCL INFO Connected all rings
gn26:3649543:3651474 [3] NCCL INFO Channel 00/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gn26:3649542:3651476 [2] NCCL INFO Connected all rings
gn26:3649540:3651475 [0] NCCL INFO Channel 00/0 : 4[0] -> 0[0] [send] via NET/Socket/0
gn26:3649543:3651474 [3] NCCL INFO Channel 01/0 : 7[3] -> 6[2] via P2P/CUMEM/read
gn26:3649540:3651475 [0] NCCL INFO Channel 01/0 : 4[0] -> 0[0] [send] via NET/Socket/0
gn26:3649542:3651476 [2] NCCL INFO Channel 00/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gn26:3649542:3651476 [2] NCCL INFO Channel 01/0 : 6[2] -> 5[1] via P2P/CUMEM/read
gn26:3649543:3651474 [3] NCCL INFO Connected all trees
gn26:3649543:3651474 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn26:3649543:3651474 [3] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn26:3649542:3651476 [2] NCCL INFO Connected all trees
gn26:3649542:3651476 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn26:3649542:3651476 [2] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn26:3649540:3651475 [0] NCCL INFO Connected all trees
gn26:3649540:3651475 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn26:3649540:3651475 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn26:3649541:3651477 [1] NCCL INFO Connected all trees
gn26:3649541:3651477 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
gn26:3649541:3651477 [1] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 1 p2p channels per peer
gn26:3649541:3651477 [1] NCCL INFO ncclCommInitRank comm 0x7f5c0e2e6800 rank 5 nranks 8 cudaDev 1 nvmlDev 1 busId 44000 commId 0xa659f5303d7f5fb3 - Init COMPLETE
gn26:3649543:3651474 [3] NCCL INFO ncclCommInitRank comm 0x7f03faec1930 rank 7 nranks 8 cudaDev 3 nvmlDev 3 busId c4000 commId 0xa659f5303d7f5fb3 - Init COMPLETE
gn26:3649542:3651476 [2] NCCL INFO ncclCommInitRank comm 0x7effd22edac0 rank 6 nranks 8 cudaDev 2 nvmlDev 2 busId 84000 commId 0xa659f5303d7f5fb3 - Init COMPLETE
gn26:3649540:3651475 [0] NCCL INFO ncclCommInitRank comm 0x7f035caaa040 rank 4 nranks 8 cudaDev 0 nvmlDev 0 busId 3000 commId 0xa659f5303d7f5fb3 - Init COMPLETE
