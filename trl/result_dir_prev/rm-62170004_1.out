cpu-bind=MASK - gn45, task  1  0 [3048625]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn41
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 1     --main_process_ip gn41     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62170004     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-06-01 12:22:43,983] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0601 12:22:45.324000 3048675 torch/distributed/run.py:792] 
W0601 12:22:45.324000 3048675 torch/distributed/run.py:792] *****************************************
W0601 12:22:45.324000 3048675 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0601 12:22:45.324000 3048675 torch/distributed/run.py:792] *****************************************
[2025-06-01 12:22:50,500] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-01 12:22:50,535] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-01 12:22:50,555] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-01 12:22:50,566] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 2
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
[2025-06-01 12:22:53,194] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-01 12:22:53,204] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 4282
Eval steps: 2141
[2025-06-01 12:22:53,215] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-01 12:22:53,217] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:17<00:53, 17.72s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.22s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:54, 18.21s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:18<00:55, 18.44s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:31<00:30, 15.45s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:32<00:31, 15.75s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:32<00:31, 15.83s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:32<00:31, 15.84s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:45<00:14, 14.75s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:46<00:14, 14.97s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:46<00:14, 14.91s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:46<00:14, 14.96s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 12.97s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 14.04s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 13.06s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 13.07s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 13.03s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 14.07s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 14.07s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:56<00:00, 14.08s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:00<00:01, 5375.37 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1113/8564 [00:00<00:01, 5494.32 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1670/8564 [00:00<00:01, 5512.43 examples/s][rank5]:[W601 12:23:53.559265155 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank7]:[W601 12:23:53.573095803 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:  26%|██▌       | 2240/8564 [00:00<00:01, 5562.27 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2810/8564 [00:00<00:01, 5596.45 examples/s][rank6]:[W601 12:23:53.728462166 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:  43%|████▎     | 3640/8564 [00:00<00:00, 5534.46 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4210/8564 [00:00<00:00, 5575.14 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4780/8564 [00:00<00:00, 5598.98 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5364/8564 [00:00<00:00, 5667.06 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5948/8564 [00:01<00:00, 5716.79 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 6532/8564 [00:01<00:00, 5735.99 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7114/8564 [00:01<00:00, 5759.12 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 7695/8564 [00:01<00:00, 5773.12 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8490/8564 [00:01<00:00, 5573.84 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5561.73 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 280/8564 [00:00<00:02, 2774.73 examples/s]Applying chat template to train dataset:   7%|▋         | 587/8564 [00:00<00:02, 2942.84 examples/s]Applying chat template to train dataset:  10%|█         | 891/8564 [00:00<00:02, 2981.71 examples/s]Applying chat template to train dataset:  14%|█▍        | 1198/8564 [00:00<00:02, 3011.82 examples/s]Applying chat template to train dataset:  18%|█▊        | 1500/8564 [00:00<00:02, 3008.40 examples/s]Applying chat template to train dataset:  21%|██        | 1808/8564 [00:00<00:02, 3030.65 examples/s]Applying chat template to train dataset:  25%|██▍       | 2116/8564 [00:00<00:02, 3043.76 examples/s]Applying chat template to train dataset:  28%|██▊       | 2425/8564 [00:00<00:02, 3053.89 examples/s]Applying chat template to train dataset:  32%|███▏      | 2735/8564 [00:00<00:01, 3060.39 examples/s]Applying chat template to train dataset:  36%|███▌      | 3045/8564 [00:01<00:01, 3065.97 examples/s]Applying chat template to train dataset:  41%|████      | 3489/8564 [00:01<00:01, 3017.82 examples/s]Applying chat template to train dataset:  44%|████▍     | 3796/8564 [00:01<00:01, 3028.92 examples/s]Applying chat template to train dataset:  48%|████▊     | 4105/8564 [00:01<00:01, 3037.81 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4412/8564 [00:01<00:01, 3043.09 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4719/8564 [00:01<00:01, 3047.53 examples/s]Applying chat template to train dataset:  59%|█████▊    | 5030/8564 [00:01<00:01, 3061.79 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5345/8564 [00:01<00:01, 3083.98 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5659/8564 [00:01<00:00, 3097.58 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5972/8564 [00:01<00:00, 3104.72 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6286/8564 [00:02<00:00, 3113.96 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6599/8564 [00:02<00:00, 3117.21 examples/s]Applying chat template to train dataset:  81%|████████  | 6911/8564 [00:02<00:00, 3116.47 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7225/8564 [00:02<00:00, 3119.84 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7539/8564 [00:02<00:00, 3123.27 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7965/8564 [00:02<00:00, 3010.23 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8280/8564 [00:02<00:00, 3042.31 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3049.85 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:20, 406.36 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:24, 340.84 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:26, 322.19 examples/s]Tokenizing train dataset:   2%|▏         | 184/8564 [00:00<00:27, 309.59 examples/s]Tokenizing train dataset:   3%|▎         | 218/8564 [00:00<00:26, 315.35 examples/s]Tokenizing train dataset:   3%|▎         | 252/8564 [00:00<00:25, 319.80 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:00<00:24, 332.95 examples/s]Tokenizing train dataset:   4%|▍         | 324/8564 [00:00<00:24, 331.76 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:01<00:25, 317.91 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:01<00:25, 316.49 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:25, 314.51 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:01<00:26, 304.20 examples/s]Tokenizing train dataset:   6%|▋         | 549/8564 [00:01<00:25, 317.51 examples/s]Tokenizing train dataset:   7%|▋         | 596/8564 [00:01<00:25, 308.70 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:01<00:24, 322.90 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:02<00:25, 314.10 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:02<00:25, 311.97 examples/s]Tokenizing train dataset:   9%|▉         | 763/8564 [00:02<00:24, 313.28 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:02<00:25, 300.30 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:02<00:26, 294.52 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:02<00:25, 302.55 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:02<00:24, 307.54 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:03<00:24, 305.78 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:03<00:25, 301.40 examples/s]Tokenizing train dataset:  12%|█▏        | 1027/8564 [00:03<00:25, 291.74 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:03<00:25, 293.57 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:03<00:24, 306.84 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:03<00:25, 294.64 examples/s]Tokenizing train dataset:  14%|█▍        | 1181/8564 [00:03<00:24, 295.69 examples/s]Tokenizing train dataset:  14%|█▍        | 1214/8564 [00:03<00:24, 300.03 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:04<00:23, 314.70 examples/s]Tokenizing train dataset:  15%|█▍        | 1282/8564 [00:04<00:23, 311.30 examples/s]Tokenizing train dataset:  15%|█▌        | 1316/8564 [00:04<00:22, 318.10 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:04<00:23, 307.03 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:04<00:23, 303.13 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:04<00:23, 299.82 examples/s]Tokenizing train dataset:  18%|█▊        | 1499/8564 [00:04<00:23, 297.27 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:04<00:23, 297.02 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:05<00:23, 297.80 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:05<00:23, 293.69 examples/s]Tokenizing train dataset:  19%|█▉        | 1627/8564 [00:05<00:22, 304.29 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:05<00:22, 312.40 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:05<00:20, 339.62 examples/s]Tokenizing train dataset:  20%|██        | 1753/8564 [00:05<00:20, 328.91 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:05<00:20, 322.31 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:05<00:20, 324.37 examples/s]Tokenizing train dataset:  22%|██▏       | 1880/8564 [00:06<00:21, 310.63 examples/s]Tokenizing train dataset:  22%|██▏       | 1921/8564 [00:06<00:19, 332.23 examples/s]Tokenizing train dataset:  23%|██▎       | 1958/8564 [00:06<00:19, 341.08 examples/s]Tokenizing train dataset:  23%|██▎       | 1994/8564 [00:06<00:19, 344.44 examples/s]Tokenizing train dataset:  24%|██▍       | 2035/8564 [00:06<00:18, 356.68 examples/s]Tokenizing train dataset:  24%|██▍       | 2091/8564 [00:06<00:17, 360.39 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:06<00:17, 365.97 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:06<00:17, 361.90 examples/s]Tokenizing train dataset:  26%|██▌       | 2204/8564 [00:06<00:17, 358.68 examples/s]Tokenizing train dataset:  26%|██▌       | 2244/8564 [00:07<00:17, 367.47 examples/s]Tokenizing train dataset:  27%|██▋       | 2281/8564 [00:07<00:17, 365.52 examples/s]Tokenizing train dataset:  27%|██▋       | 2318/8564 [00:07<00:17, 359.72 examples/s]Tokenizing train dataset:  28%|██▊       | 2371/8564 [00:07<00:17, 351.48 examples/s]Tokenizing train dataset:  28%|██▊       | 2413/8564 [00:07<00:16, 364.10 examples/s]Tokenizing train dataset:  29%|██▊       | 2453/8564 [00:07<00:16, 368.31 examples/s]Tokenizing train dataset:  29%|██▉       | 2507/8564 [00:07<00:16, 359.70 examples/s]Tokenizing train dataset:  30%|██▉       | 2550/8564 [00:07<00:16, 372.52 examples/s]Tokenizing train dataset:  30%|███       | 2588/8564 [00:07<00:15, 373.91 examples/s]Tokenizing train dataset:  31%|███       | 2638/8564 [00:08<00:16, 351.94 examples/s]Tokenizing train dataset:  31%|███▏      | 2688/8564 [00:08<00:17, 341.84 examples/s]Tokenizing train dataset:  32%|███▏      | 2727/8564 [00:08<00:16, 351.35 examples/s]Tokenizing train dataset:  32%|███▏      | 2776/8564 [00:08<00:16, 341.59 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:08<00:15, 360.33 examples/s]Tokenizing train dataset:  34%|███▎      | 2870/8564 [00:08<00:16, 343.67 examples/s]Tokenizing train dataset:  34%|███▍      | 2914/8564 [00:08<00:15, 365.80 examples/s]Tokenizing train dataset:  35%|███▍      | 2956/8564 [00:09<00:14, 378.46 examples/s]Tokenizing train dataset:  35%|███▌      | 2999/8564 [00:09<00:14, 389.67 examples/s]Tokenizing train dataset:  36%|███▌      | 3052/8564 [00:09<00:14, 373.17 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:09<00:14, 371.27 examples/s]Tokenizing train dataset:  37%|███▋      | 3165/8564 [00:09<00:14, 366.31 examples/s]Tokenizing train dataset:  38%|███▊      | 3220/8564 [00:09<00:14, 364.63 examples/s]Tokenizing train dataset:  38%|███▊      | 3261/8564 [00:09<00:14, 374.34 examples/s]Tokenizing train dataset:  39%|███▊      | 3314/8564 [00:09<00:14, 360.17 examples/s]Tokenizing train dataset:  39%|███▉      | 3370/8564 [00:10<00:14, 355.94 examples/s]Tokenizing train dataset:  40%|███▉      | 3414/8564 [00:10<00:13, 370.35 examples/s]Tokenizing train dataset:  40%|████      | 3452/8564 [00:10<00:13, 368.58 examples/s]Tokenizing train dataset:  41%|████      | 3512/8564 [00:10<00:13, 375.88 examples/s]Tokenizing train dataset:  42%|████▏     | 3564/8564 [00:10<00:13, 362.83 examples/s]Tokenizing train dataset:  42%|████▏     | 3606/8564 [00:10<00:13, 374.85 examples/s]Tokenizing train dataset:  43%|████▎     | 3658/8564 [00:10<00:13, 363.70 examples/s]Tokenizing train dataset:  43%|████▎     | 3712/8564 [00:11<00:13, 357.36 examples/s]Tokenizing train dataset:  44%|████▍     | 3752/8564 [00:11<00:13, 364.36 examples/s]Tokenizing train dataset:  44%|████▍     | 3790/8564 [00:11<00:13, 365.84 examples/s]Tokenizing train dataset:  45%|████▍     | 3842/8564 [00:11<00:13, 356.30 examples/s]Tokenizing train dataset:  45%|████▌     | 3880/8564 [00:11<00:13, 360.25 examples/s]Tokenizing train dataset:  46%|████▌     | 3931/8564 [00:11<00:13, 347.09 examples/s]Tokenizing train dataset:  46%|████▋     | 3970/8564 [00:11<00:13, 351.93 examples/s]Tokenizing train dataset:  47%|████▋     | 4027/8564 [00:11<00:12, 357.78 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:12<00:12, 358.22 examples/s]Tokenizing train dataset:  48%|████▊     | 4118/8564 [00:12<00:12, 356.40 examples/s]Tokenizing train dataset:  49%|████▊     | 4169/8564 [00:12<00:12, 348.60 examples/s]Tokenizing train dataset:  49%|████▉     | 4210/8564 [00:12<00:12, 356.07 examples/s]Tokenizing train dataset:  50%|████▉     | 4264/8564 [00:12<00:12, 352.24 examples/s]Tokenizing train dataset:  50%|█████     | 4301/8564 [00:12<00:12, 353.28 examples/s]Tokenizing train dataset:  51%|█████     | 4337/8564 [00:12<00:12, 352.19 examples/s]Tokenizing train dataset:  51%|█████     | 4373/8564 [00:12<00:11, 353.34 examples/s]Tokenizing train dataset:  52%|█████▏    | 4411/8564 [00:13<00:11, 357.41 examples/s]Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:13<00:11, 358.94 examples/s]Tokenizing train dataset:  52%|█████▏    | 4489/8564 [00:13<00:11, 362.90 examples/s]Tokenizing train dataset:  53%|█████▎    | 4542/8564 [00:13<00:11, 353.43 examples/s]Tokenizing train dataset:  54%|█████▎    | 4595/8564 [00:13<00:11, 349.83 examples/s]Tokenizing train dataset:  54%|█████▍    | 4631/8564 [00:13<00:11, 349.89 examples/s]Tokenizing train dataset:  55%|█████▍    | 4678/8564 [00:13<00:11, 333.45 examples/s]Tokenizing train dataset:  55%|█████▌    | 4727/8564 [00:13<00:11, 324.64 examples/s]Tokenizing train dataset:  56%|█████▌    | 4760/8564 [00:14<00:11, 321.47 examples/s]Tokenizing train dataset:  56%|█████▌    | 4793/8564 [00:14<00:11, 322.11 examples/s]Tokenizing train dataset:  57%|█████▋    | 4857/8564 [00:14<00:09, 402.46 examples/s]Tokenizing train dataset:  57%|█████▋    | 4912/8564 [00:14<00:08, 437.50 examples/s]Tokenizing train dataset:  58%|█████▊    | 4973/8564 [00:14<00:07, 484.24 examples/s]Tokenizing train dataset:  59%|█████▉    | 5032/8564 [00:14<00:06, 513.72 examples/s]Tokenizing train dataset:  60%|█████▉    | 5100/8564 [00:14<00:06, 560.29 examples/s]Tokenizing train dataset:  60%|██████    | 5170/8564 [00:14<00:05, 597.83 examples/s]Tokenizing train dataset:  61%|██████    | 5236/8564 [00:14<00:05, 613.19 examples/s]Tokenizing train dataset:  62%|██████▏   | 5309/8564 [00:15<00:05, 644.47 examples/s]Tokenizing train dataset:  63%|██████▎   | 5394/8564 [00:15<00:05, 608.75 examples/s]Tokenizing train dataset:  64%|██████▍   | 5462/8564 [00:15<00:04, 622.67 examples/s]Tokenizing train dataset:  65%|██████▍   | 5549/8564 [00:15<00:04, 604.82 examples/s]Tokenizing train dataset:  66%|██████▌   | 5616/8564 [00:15<00:04, 614.41 examples/s]Tokenizing train dataset:  66%|██████▋   | 5680/8564 [00:15<00:04, 619.34 examples/s]Tokenizing train dataset:  67%|██████▋   | 5745/8564 [00:15<00:04, 625.60 examples/s]Tokenizing train dataset:  68%|██████▊   | 5824/8564 [00:15<00:04, 667.58 examples/s]Tokenizing train dataset:  69%|██████▉   | 5907/8564 [00:15<00:04, 618.94 examples/s]Tokenizing train dataset:  70%|██████▉   | 5977/8564 [00:16<00:04, 630.42 examples/s]Tokenizing train dataset:  71%|███████   | 6058/8564 [00:16<00:04, 590.60 examples/s]Tokenizing train dataset:  72%|███████▏  | 6156/8564 [00:16<00:03, 605.10 examples/s]Tokenizing train dataset:  73%|███████▎  | 6230/8564 [00:16<00:03, 636.02 examples/s]Tokenizing train dataset:  74%|███████▍  | 6328/8564 [00:16<00:03, 635.26 examples/s]Tokenizing train dataset:  75%|███████▍  | 6398/8564 [00:16<00:03, 648.87 examples/s]Tokenizing train dataset:  76%|███████▌  | 6489/8564 [00:16<00:03, 631.59 examples/s]Tokenizing train dataset:  77%|███████▋  | 6577/8564 [00:17<00:03, 614.02 examples/s]Tokenizing train dataset:  78%|███████▊  | 6658/8564 [00:17<00:03, 583.54 examples/s]Tokenizing train dataset:  79%|███████▊  | 6728/8564 [00:17<00:03, 608.12 examples/s]Tokenizing train dataset:  79%|███████▉  | 6792/8564 [00:17<00:02, 613.01 examples/s]Tokenizing train dataset:  80%|████████  | 6883/8564 [00:17<00:02, 602.71 examples/s]Tokenizing train dataset:  81%|████████  | 6949/8564 [00:17<00:02, 616.09 examples/s]Tokenizing train dataset:  82%|████████▏ | 7029/8564 [00:17<00:02, 584.50 examples/s]Tokenizing train dataset:  83%|████████▎ | 7097/8564 [00:17<00:02, 606.31 examples/s]Tokenizing train dataset:  84%|████████▎ | 7160/8564 [00:18<00:02, 607.81 examples/s]Tokenizing train dataset:  84%|████████▍ | 7225/8564 [00:18<00:02, 612.58 examples/s]Tokenizing train dataset:  85%|████████▌ | 7290/8564 [00:18<00:02, 614.43 examples/s]Tokenizing train dataset:  86%|████████▌ | 7355/8564 [00:18<00:01, 618.52 examples/s]Tokenizing train dataset:  87%|████████▋ | 7450/8564 [00:18<00:01, 619.09 examples/s]Tokenizing train dataset:  88%|████████▊ | 7513/8564 [00:18<00:01, 617.27 examples/s]Tokenizing train dataset:  89%|████████▊ | 7586/8564 [00:18<00:01, 645.20 examples/s]Tokenizing train dataset:  90%|████████▉ | 7671/8564 [00:18<00:01, 612.33 examples/s]Tokenizing train dataset:  91%|█████████ | 7760/8564 [00:19<00:01, 600.44 examples/s]Tokenizing train dataset:  92%|█████████▏| 7849/8564 [00:19<00:01, 593.39 examples/s]Tokenizing train dataset:  93%|█████████▎| 7937/8564 [00:19<00:01, 589.71 examples/s]Tokenizing train dataset:  93%|█████████▎| 8004/8564 [00:19<00:00, 605.77 examples/s]Tokenizing train dataset:  94%|█████████▍| 8091/8564 [00:19<00:00, 588.78 examples/s]Tokenizing train dataset:  96%|█████████▌| 8181/8564 [00:19<00:00, 587.27 examples/s]Tokenizing train dataset:  96%|█████████▋| 8245/8564 [00:19<00:00, 597.40 examples/s]Tokenizing train dataset:  97%|█████████▋| 8322/8564 [00:19<00:00, 638.72 examples/s]Tokenizing train dataset:  98%|█████████▊| 8404/8564 [00:20<00:00, 597.88 examples/s]Tokenizing train dataset:  99%|█████████▉| 8497/8564 [00:20<00:00, 601.22 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 602.81 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 420.73 examples/s]
[rank4]:[W601 12:24:19.825880528 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11207.77 examples/s]
Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:00<00:01, 5430.56 examples/s]Extracting prompt in train dataset:   7%|▋         | 560/8564 [00:00<00:01, 5528.24 examples/s]Extracting prompt in train dataset:   7%|▋         | 565/8564 [00:00<00:01, 5552.28 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1103/8564 [00:00<00:01, 5486.98 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1123/8564 [00:00<00:01, 5566.31 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1124/8564 [00:00<00:01, 5560.35 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1665/8564 [00:00<00:01, 5546.13 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1690/8564 [00:00<00:01, 5581.05 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1690/8564 [00:00<00:01, 5578.92 examples/s]Extracting prompt in train dataset:  26%|██▋       | 2250/8564 [00:00<00:01, 5655.59 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2270/8564 [00:00<00:01, 5645.03 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2270/8564 [00:00<00:01, 5639.68 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  33%|███▎      | 2840/8564 [00:00<00:00, 5729.99 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2850/8564 [00:00<00:01, 5679.13 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2850/8564 [00:00<00:01, 5673.67 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13805.96 examples/s]
Extracting prompt in train dataset:  43%|████▎     | 3690/8564 [00:00<00:00, 5674.09 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3680/8564 [00:00<00:00, 5597.69 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3680/8564 [00:00<00:00, 5584.25 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4280/8564 [00:00<00:00, 5731.78 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4260/8564 [00:00<00:00, 5641.62 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4260/8564 [00:00<00:00, 5628.12 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4870/8564 [00:00<00:00, 5775.56 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4840/8564 [00:00<00:00, 5672.95 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4840/8564 [00:00<00:00, 5659.48 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5474/8564 [00:00<00:00, 5851.81 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5430/8564 [00:00<00:00, 5731.99 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5430/8564 [00:00<00:00, 5720.96 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 325.75 examples/s]Extracting prompt in train dataset:  71%|███████   | 6078/8564 [00:01<00:00, 5907.03 examples/s]Extracting prompt in train dataset:  70%|███████   | 6020/8564 [00:01<00:00, 5772.48 examples/s]Extracting prompt in train dataset:  70%|███████   | 6020/8564 [00:01<00:00, 5765.18 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 295.52 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6681/8564 [00:01<00:00, 5925.52 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6610/8564 [00:01<00:00, 5799.89 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6610/8564 [00:01<00:00, 5796.89 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7286/8564 [00:01<00:00, 5960.34 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7200/8564 [00:01<00:00, 5824.13 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7200/8564 [00:01<00:00, 5818.84 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:03, 277.50 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8098/8564 [00:01<00:00, 5745.89 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 8025/8564 [00:01<00:00, 5591.18 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 8024/8564 [00:01<00:00, 5570.17 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 268.07 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5728.67 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5638.73 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5627.16 examples/s]
Tokenizing eval dataset:  21%|██        | 196/953 [00:00<00:02, 257.59 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:00<00:02, 287.85 examples/s]Tokenizing eval dataset:  32%|███▏      | 303/953 [00:00<00:01, 386.60 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  38%|███▊      | 363/953 [00:01<00:01, 443.78 examples/s]Applying chat template to train dataset:   3%|▎         | 283/8564 [00:00<00:02, 2797.63 examples/s]Applying chat template to train dataset:   3%|▎         | 298/8564 [00:00<00:02, 2957.21 examples/s]Applying chat template to train dataset:   3%|▎         | 283/8564 [00:00<00:02, 2786.54 examples/s]Tokenizing eval dataset:  45%|████▌     | 432/953 [00:01<00:01, 508.25 examples/s]Applying chat template to train dataset:   7%|▋         | 590/8564 [00:00<00:02, 2951.04 examples/s]Applying chat template to train dataset:   7%|▋         | 621/8564 [00:00<00:02, 3113.87 examples/s]Applying chat template to train dataset:   7%|▋         | 589/8564 [00:00<00:02, 2942.97 examples/s]Tokenizing eval dataset:  52%|█████▏    | 500/953 [00:01<00:00, 552.77 examples/s]Applying chat template to train dataset:  10%|█         | 898/8564 [00:00<00:02, 3003.80 examples/s]Applying chat template to train dataset:  11%|█         | 945/8564 [00:00<00:02, 3167.15 examples/s]Applying chat template to train dataset:  10%|█         | 893/8564 [00:00<00:02, 2983.63 examples/s]Tokenizing eval dataset:  59%|█████▉    | 566/953 [00:01<00:00, 575.44 examples/s]Applying chat template to train dataset:  14%|█▍        | 1205/8564 [00:00<00:02, 3024.44 examples/s]Applying chat template to train dataset:  15%|█▍        | 1270/8564 [00:00<00:02, 3195.57 examples/s]Applying chat template to train dataset:  14%|█▍        | 1200/8564 [00:00<00:02, 3009.94 examples/s]Tokenizing eval dataset:  67%|██████▋   | 635/953 [00:01<00:00, 606.79 examples/s]Applying chat template to train dataset:  18%|█▊        | 1510/8564 [00:00<00:02, 3023.22 examples/s]Applying chat template to train dataset:  19%|█▊        | 1590/8564 [00:00<00:02, 3192.68 examples/s]Applying chat template to train dataset:  18%|█▊        | 1502/8564 [00:00<00:02, 3010.96 examples/s]Tokenizing eval dataset:  76%|███████▌  | 725/953 [00:01<00:00, 596.49 examples/s]Applying chat template to train dataset:  21%|██        | 1819/8564 [00:00<00:02, 3042.28 examples/s]Applying chat template to train dataset:  22%|██▏       | 1917/8564 [00:00<00:02, 3215.75 examples/s]Applying chat template to train dataset:  21%|██        | 1809/8564 [00:00<00:02, 3029.60 examples/s]Applying chat template to train dataset:  25%|██▍       | 2128/8564 [00:00<00:02, 3055.88 examples/s]Applying chat template to train dataset:  26%|██▌       | 2245/8564 [00:00<00:01, 3233.15 examples/s]Applying chat template to train dataset:  25%|██▍       | 2117/8564 [00:00<00:02, 3043.06 examples/s]Tokenizing eval dataset:  84%|████████▍ | 803/953 [00:01<00:00, 561.04 examples/s]Applying chat template to train dataset:  28%|██▊       | 2437/8564 [00:00<00:01, 3065.88 examples/s]Applying chat template to train dataset:  30%|███       | 2572/8564 [00:00<00:01, 3242.94 examples/s]Applying chat template to train dataset:  28%|██▊       | 2425/8564 [00:00<00:02, 3052.72 examples/s]Applying chat template to train dataset:  32%|███▏      | 2746/8564 [00:00<00:01, 3071.04 examples/s]Applying chat template to train dataset:  34%|███▍      | 2900/8564 [00:00<00:01, 3248.53 examples/s]Tokenizing eval dataset:  92%|█████████▏| 881/953 [00:01<00:00, 540.04 examples/s]Applying chat template to train dataset:  32%|███▏      | 2735/8564 [00:00<00:01, 3060.84 examples/s]Applying chat template to train dataset:  36%|███▌      | 3043/8564 [00:01<00:01, 3065.81 examples/s]Applying chat template to train dataset:  39%|███▉      | 3377/8564 [00:01<00:01, 3201.71 examples/s]Applying chat template to train dataset:  37%|███▋      | 3204/8564 [00:01<00:01, 3028.98 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 527.83 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 461.34 examples/s]
Applying chat template to train dataset:  41%|████      | 3511/8564 [00:01<00:01, 3039.09 examples/s]Applying chat template to train dataset:  43%|████▎     | 3704/8564 [00:01<00:01, 3214.95 examples/s]Applying chat template to train dataset:  41%|████      | 3485/8564 [00:01<00:01, 3015.35 examples/s]Applying chat template to train dataset:  47%|████▋     | 4030/8564 [00:01<00:01, 3225.35 examples/s]Applying chat template to train dataset:  45%|████▍     | 3820/8564 [00:01<00:01, 3048.27 examples/s]Applying chat template to train dataset:  44%|████▍     | 3792/8564 [00:01<00:01, 3027.48 examples/s]Applying chat template to train dataset:  51%|█████     | 4357/8564 [00:01<00:01, 3235.66 examples/s]Applying chat template to train dataset:  48%|████▊     | 4129/8564 [00:01<00:01, 3057.24 examples/s]Applying chat template to train dataset:  48%|████▊     | 4099/8564 [00:01<00:01, 3038.94 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4683/8564 [00:01<00:01, 3237.13 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4437/8564 [00:01<00:01, 3060.00 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4405/8564 [00:01<00:01, 3043.16 examples/s]Applying chat template to train dataset:  59%|█████▊    | 5014/8564 [00:01<00:01, 3254.82 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4744/8564 [00:01<00:01, 3060.34 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4711/8564 [00:01<00:01, 3046.33 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5059/8564 [00:01<00:01, 3081.46 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5350/8564 [00:01<00:00, 3279.58 examples/s]Applying chat template to train dataset:  59%|█████▊    | 5022/8564 [00:01<00:01, 3063.59 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5684/8564 [00:01<00:00, 3295.03 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5374/8564 [00:01<00:01, 3097.63 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5340/8564 [00:01<00:01, 3088.22 examples/s]Applying chat template to train dataset:  70%|███████   | 6020/8564 [00:01<00:00, 3309.45 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5693/8564 [00:01<00:00, 3121.08 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5658/8564 [00:01<00:00, 3111.76 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6357/8564 [00:01<00:00, 3325.25 examples/s]Applying chat template to train dataset:  70%|███████   | 6016/8564 [00:01<00:00, 3151.22 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5972/8564 [00:01<00:00, 3116.80 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6691/8564 [00:02<00:00, 3327.89 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6339/8564 [00:02<00:00, 3172.17 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6289/8564 [00:02<00:00, 3125.40 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7026/8564 [00:02<00:00, 3333.67 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6811/8564 [00:02<00:00, 3158.13 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6759/8564 [00:02<00:00, 3126.55 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7361/8564 [00:02<00:00, 3335.02 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7699/8564 [00:02<00:00, 3342.03 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7284/8564 [00:02<00:00, 3153.59 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7230/8564 [00:02<00:00, 3126.04 examples/s]Applying chat template to train dataset:  89%|████████▊ | 7600/8564 [00:02<00:00, 3151.08 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7545/8564 [00:02<00:00, 3129.50 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8141/8564 [00:02<00:00, 3186.72 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8469/8564 [00:02<00:00, 3209.00 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8065/8564 [00:02<00:00, 3043.01 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7964/8564 [00:02<00:00, 3009.61 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3236.17 examples/s]
Applying chat template to train dataset:  98%|█████████▊| 8381/8564 [00:02<00:00, 3068.29 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8279/8564 [00:02<00:00, 3044.06 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3069.00 examples/s]
Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3051.07 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/8564 [00:00<00:21, 399.05 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:20, 409.94 examples/s]Tokenizing train dataset:   1%|          | 89/8564 [00:00<00:25, 338.82 examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:21, 403.91 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:24, 343.08 examples/s]Tokenizing train dataset:   2%|▏         | 133/8564 [00:00<00:26, 313.76 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:25, 338.92 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:25, 324.42 examples/s]Tokenizing train dataset:   2%|▏         | 179/8564 [00:00<00:27, 304.90 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:26, 320.41 examples/s]Tokenizing train dataset:   2%|▏         | 212/8564 [00:00<00:26, 309.54 examples/s]Tokenizing train dataset:   2%|▏         | 184/8564 [00:00<00:26, 311.71 examples/s]Tokenizing train dataset:   2%|▏         | 183/8564 [00:00<00:27, 306.81 examples/s]Tokenizing train dataset:   3%|▎         | 248/8564 [00:00<00:25, 322.23 examples/s]Tokenizing train dataset:   3%|▎         | 218/8564 [00:00<00:26, 317.59 examples/s]Tokenizing train dataset:   3%|▎         | 218/8564 [00:00<00:26, 314.51 examples/s]Tokenizing train dataset:   3%|▎         | 283/8564 [00:00<00:25, 328.47 examples/s]Tokenizing train dataset:   3%|▎         | 252/8564 [00:00<00:25, 322.19 examples/s]Tokenizing train dataset:   3%|▎         | 252/8564 [00:00<00:26, 319.25 examples/s]Tokenizing train dataset:   4%|▎         | 318/8564 [00:00<00:25, 328.21 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:00<00:24, 335.42 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:00<00:24, 332.34 examples/s]Tokenizing train dataset:   4%|▍         | 324/8564 [00:00<00:24, 334.26 examples/s]Tokenizing train dataset:   4%|▍         | 366/8564 [00:01<00:25, 319.79 examples/s]Tokenizing train dataset:   4%|▍         | 324/8564 [00:00<00:24, 331.09 examples/s]Tokenizing train dataset:   5%|▍         | 399/8564 [00:01<00:25, 319.50 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:01<00:25, 320.27 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:01<00:25, 317.43 examples/s]Tokenizing train dataset:   5%|▌         | 432/8564 [00:01<00:25, 317.11 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:01<00:25, 318.69 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:01<00:25, 315.93 examples/s]Tokenizing train dataset:   6%|▌         | 478/8564 [00:01<00:26, 308.89 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:25, 316.67 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:25, 314.04 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:01<00:26, 305.79 examples/s]Tokenizing train dataset:   6%|▌         | 516/8564 [00:01<00:25, 310.22 examples/s]Tokenizing train dataset:   7%|▋         | 557/8564 [00:01<00:25, 310.83 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:01<00:26, 303.63 examples/s]Tokenizing train dataset:   6%|▋         | 550/8564 [00:01<00:25, 315.42 examples/s]Tokenizing train dataset:   7%|▋         | 597/8564 [00:01<00:27, 293.65 examples/s]Tokenizing train dataset:   6%|▋         | 549/8564 [00:01<00:25, 316.60 examples/s]Tokenizing train dataset:   7%|▋         | 596/8564 [00:01<00:25, 310.59 examples/s]Tokenizing train dataset:   7%|▋         | 636/8564 [00:02<00:25, 313.81 examples/s]Tokenizing train dataset:   7%|▋         | 596/8564 [00:01<00:25, 307.48 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:01<00:24, 324.73 examples/s]Tokenizing train dataset:   8%|▊         | 682/8564 [00:02<00:25, 306.23 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:01<00:24, 321.57 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:02<00:24, 315.87 examples/s]Tokenizing train dataset:   9%|▊         | 732/8564 [00:02<00:25, 309.36 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:02<00:25, 312.34 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:02<00:24, 313.91 examples/s]Tokenizing train dataset:   9%|▉         | 766/8564 [00:02<00:25, 311.07 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:02<00:25, 310.57 examples/s]Tokenizing train dataset:   9%|▉         | 763/8564 [00:02<00:24, 315.15 examples/s]Tokenizing train dataset:   9%|▉         | 762/8564 [00:02<00:24, 312.47 examples/s]Tokenizing train dataset:   9%|▉         | 810/8564 [00:02<00:26, 298.07 examples/s]Tokenizing train dataset:   9%|▉         | 808/8564 [00:02<00:25, 303.20 examples/s]Tokenizing train dataset:  10%|▉         | 854/8564 [00:02<00:26, 292.30 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:02<00:25, 298.82 examples/s]Tokenizing train dataset:  10%|▉         | 839/8564 [00:02<00:25, 300.37 examples/s]Tokenizing train dataset:  10%|█         | 891/8564 [00:02<00:24, 307.58 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:02<00:26, 293.35 examples/s]Tokenizing train dataset:  10%|█         | 887/8564 [00:02<00:25, 305.78 examples/s]Tokenizing train dataset:  11%|█         | 939/8564 [00:03<00:25, 304.43 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:02<00:25, 301.48 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:02<00:24, 307.08 examples/s]Tokenizing train dataset:  11%|█▏        | 971/8564 [00:03<00:24, 305.23 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:02<00:24, 306.75 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:03<00:24, 305.88 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:03<00:24, 305.01 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:03<00:25, 302.00 examples/s]Tokenizing train dataset:  12%|█▏        | 1012/8564 [00:03<00:25, 290.91 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:03<00:25, 300.58 examples/s]Tokenizing train dataset:  12%|█▏        | 1027/8564 [00:03<00:25, 293.17 examples/s]Tokenizing train dataset:  12%|█▏        | 1056/8564 [00:03<00:26, 288.40 examples/s]Tokenizing train dataset:  12%|█▏        | 1057/8564 [00:03<00:25, 292.85 examples/s]Tokenizing train dataset:  12%|█▏        | 1027/8564 [00:03<00:25, 291.28 examples/s]Tokenizing train dataset:  13%|█▎        | 1093/8564 [00:03<00:24, 304.05 examples/s]Tokenizing train dataset:  13%|█▎        | 1093/8564 [00:03<00:24, 308.36 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:03<00:25, 292.70 examples/s]Tokenizing train dataset:  13%|█▎        | 1135/8564 [00:03<00:25, 292.04 examples/s]Tokenizing train dataset:  13%|█▎        | 1135/8564 [00:03<00:25, 295.01 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:03<00:24, 305.86 examples/s]Tokenizing train dataset:  14%|█▎        | 1166/8564 [00:03<00:25, 293.00 examples/s]Tokenizing train dataset:  14%|█▎        | 1166/8564 [00:03<00:24, 296.22 examples/s]Tokenizing train dataset:  14%|█▍        | 1200/8564 [00:03<00:24, 304.04 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:03<00:25, 293.45 examples/s]Tokenizing train dataset:  14%|█▍        | 1202/8564 [00:03<00:23, 307.16 examples/s]Tokenizing train dataset:  14%|█▍        | 1232/8564 [00:04<00:24, 305.36 examples/s]Tokenizing train dataset:  14%|█▍        | 1181/8564 [00:03<00:25, 294.58 examples/s]Tokenizing train dataset:  14%|█▍        | 1236/8564 [00:03<00:23, 312.98 examples/s]Tokenizing train dataset:  15%|█▍        | 1269/8564 [00:04<00:22, 318.75 examples/s]Tokenizing train dataset:  14%|█▍        | 1214/8564 [00:03<00:24, 298.72 examples/s]Tokenizing train dataset:  15%|█▍        | 1270/8564 [00:04<00:23, 315.01 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:04<00:23, 312.91 examples/s]Tokenizing train dataset:  15%|█▌        | 1315/8564 [00:04<00:23, 312.02 examples/s]Tokenizing train dataset:  15%|█▌        | 1305/8564 [00:04<00:22, 320.03 examples/s]Tokenizing train dataset:  16%|█▌        | 1348/8564 [00:04<00:23, 313.61 examples/s]Tokenizing train dataset:  15%|█▌        | 1299/8564 [00:04<00:23, 314.38 examples/s]Tokenizing train dataset:  16%|█▌        | 1339/8564 [00:04<00:22, 322.05 examples/s]Tokenizing train dataset:  16%|█▌        | 1331/8564 [00:04<00:23, 313.20 examples/s]Tokenizing train dataset:  16%|█▌        | 1390/8564 [00:04<00:24, 294.68 examples/s]Tokenizing train dataset:  16%|█▌        | 1381/8564 [00:04<00:23, 301.55 examples/s]Tokenizing train dataset:  17%|█▋        | 1422/8564 [00:04<00:23, 299.48 examples/s]Tokenizing train dataset:  16%|█▌        | 1373/8564 [00:04<00:24, 297.22 examples/s]Tokenizing train dataset:  16%|█▋        | 1412/8564 [00:04<00:23, 301.95 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:04<00:23, 297.08 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:04<00:23, 303.36 examples/s]Tokenizing train dataset:  17%|█▋        | 1457/8564 [00:04<00:23, 299.35 examples/s]Tokenizing train dataset:  17%|█▋        | 1498/8564 [00:04<00:23, 294.66 examples/s]Tokenizing train dataset:  17%|█▋        | 1488/8564 [00:04<00:23, 298.38 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:04<00:23, 299.47 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:04<00:23, 294.93 examples/s]Tokenizing train dataset:  18%|█▊        | 1535/8564 [00:04<00:23, 300.09 examples/s]Tokenizing train dataset:  17%|█▋        | 1498/8564 [00:04<00:23, 296.62 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:05<00:23, 296.17 examples/s]Tokenizing train dataset:  18%|█▊        | 1567/8564 [00:05<00:23, 299.44 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:04<00:23, 296.46 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:05<00:23, 292.05 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:05<00:23, 297.49 examples/s]Tokenizing train dataset:  19%|█▊        | 1598/8564 [00:05<00:23, 297.62 examples/s]Tokenizing train dataset:  19%|█▉        | 1627/8564 [00:05<00:22, 303.45 examples/s]Tokenizing train dataset:  19%|█▉        | 1631/8564 [00:05<00:22, 304.12 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:05<00:23, 293.04 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:05<00:22, 311.55 examples/s]Tokenizing train dataset:  19%|█▉        | 1667/8564 [00:05<00:21, 314.85 examples/s]Tokenizing train dataset:  19%|█▉        | 1627/8564 [00:05<00:22, 303.70 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:05<00:20, 339.09 examples/s]Tokenizing train dataset:  20%|█▉        | 1710/8564 [00:05<00:20, 340.76 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:05<00:22, 311.71 examples/s]Tokenizing train dataset:  20%|██        | 1753/8564 [00:05<00:20, 327.86 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:05<00:20, 338.85 examples/s]Tokenizing train dataset:  21%|██        | 1762/8564 [00:05<00:20, 334.95 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:05<00:21, 321.25 examples/s]Tokenizing train dataset:  20%|██        | 1753/8564 [00:05<00:20, 327.92 examples/s]Tokenizing train dataset:  21%|██        | 1809/8564 [00:05<00:20, 323.34 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:05<00:20, 323.44 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:05<00:21, 321.47 examples/s]Tokenizing train dataset:  22%|██▏       | 1843/8564 [00:05<00:20, 323.43 examples/s]Tokenizing train dataset:  22%|██▏       | 1880/8564 [00:06<00:21, 309.39 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:05<00:20, 323.40 examples/s]Tokenizing train dataset:  22%|██▏       | 1888/8564 [00:06<00:21, 310.65 examples/s]Tokenizing train dataset:  22%|██▏       | 1920/8564 [00:06<00:20, 330.22 examples/s]Tokenizing train dataset:  23%|██▎       | 1932/8564 [00:06<00:19, 340.54 examples/s]Tokenizing train dataset:  22%|██▏       | 1880/8564 [00:06<00:21, 309.70 examples/s]Tokenizing train dataset:  23%|██▎       | 1958/8564 [00:06<00:19, 340.48 examples/s]Tokenizing train dataset:  22%|██▏       | 1920/8564 [00:06<00:20, 330.47 examples/s]Tokenizing train dataset:  23%|██▎       | 1969/8564 [00:06<00:19, 340.98 examples/s]Tokenizing train dataset:  23%|██▎       | 1994/8564 [00:06<00:19, 343.76 examples/s]Tokenizing train dataset:  23%|██▎       | 1958/8564 [00:06<00:19, 340.68 examples/s]Tokenizing train dataset:  23%|██▎       | 2008/8564 [00:06<00:18, 350.16 examples/s]Tokenizing train dataset:  24%|██▍       | 2034/8564 [00:06<00:18, 355.92 examples/s]Tokenizing train dataset:  23%|██▎       | 1994/8564 [00:06<00:19, 343.85 examples/s]Tokenizing train dataset:  24%|██▍       | 2048/8564 [00:06<00:18, 360.12 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:06<00:18, 358.23 examples/s]Tokenizing train dataset:  24%|██▍       | 2086/8564 [00:06<00:17, 364.61 examples/s]Tokenizing train dataset:  24%|██▍       | 2035/8564 [00:06<00:18, 356.09 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:06<00:17, 364.78 examples/s]Tokenizing train dataset:  25%|██▍       | 2126/8564 [00:06<00:17, 372.04 examples/s]Tokenizing train dataset:  24%|██▍       | 2091/8564 [00:06<00:18, 359.31 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:06<00:17, 361.26 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:06<00:17, 364.89 examples/s]Tokenizing train dataset:  25%|██▌       | 2180/8564 [00:06<00:17, 361.59 examples/s]Tokenizing train dataset:  26%|██▌       | 2217/8564 [00:07<00:18, 346.33 examples/s]Tokenizing train dataset:  26%|██▌       | 2217/8564 [00:06<00:17, 362.86 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:06<00:17, 361.06 examples/s]Tokenizing train dataset:  26%|██▋       | 2257/8564 [00:07<00:17, 354.71 examples/s]Tokenizing train dataset:  26%|██▋       | 2257/8564 [00:07<00:17, 367.61 examples/s]Tokenizing train dataset:  26%|██▌       | 2224/8564 [00:07<00:17, 365.32 examples/s]Tokenizing train dataset:  27%|██▋       | 2300/8564 [00:07<00:16, 372.03 examples/s]Tokenizing train dataset:  27%|██▋       | 2300/8564 [00:07<00:16, 382.84 examples/s]Tokenizing train dataset:  27%|██▋       | 2285/8564 [00:07<00:16, 375.19 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:07<00:17, 353.03 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:07<00:17, 360.14 examples/s]Tokenizing train dataset:  28%|██▊       | 2388/8564 [00:07<00:17, 360.85 examples/s]Tokenizing train dataset:  28%|██▊       | 2389/8564 [00:07<00:16, 367.46 examples/s]Tokenizing train dataset:  27%|██▋       | 2339/8564 [00:07<00:17, 362.82 examples/s]Tokenizing train dataset:  28%|██▊       | 2428/8564 [00:07<00:16, 368.58 examples/s]Tokenizing train dataset:  28%|██▊       | 2431/8564 [00:07<00:16, 374.06 examples/s]Tokenizing train dataset:  28%|██▊       | 2395/8564 [00:07<00:17, 362.63 examples/s]Tokenizing train dataset:  29%|██▉       | 2468/8564 [00:07<00:16, 373.50 examples/s]Tokenizing train dataset:  29%|██▉       | 2470/8564 [00:07<00:16, 376.04 examples/s]Tokenizing train dataset:  28%|██▊       | 2435/8564 [00:07<00:16, 367.19 examples/s]Tokenizing train dataset:  29%|██▉       | 2520/8564 [00:07<00:16, 360.32 examples/s]Tokenizing train dataset:  29%|██▉       | 2523/8564 [00:07<00:16, 363.81 examples/s]Tokenizing train dataset:  29%|██▉       | 2474/8564 [00:07<00:16, 371.92 examples/s]Tokenizing train dataset:  30%|██▉       | 2563/8564 [00:07<00:16, 374.92 examples/s]Tokenizing train dataset:  30%|██▉       | 2565/8564 [00:07<00:15, 376.34 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:07<00:16, 364.94 examples/s]Tokenizing train dataset:  30%|███       | 2604/8564 [00:07<00:15, 377.45 examples/s]Tokenizing train dataset:  31%|███       | 2618/8564 [00:08<00:16, 365.26 examples/s]Tokenizing train dataset:  30%|███       | 2571/8564 [00:07<00:15, 374.75 examples/s]Tokenizing train dataset:  31%|███       | 2654/8564 [00:08<00:17, 343.07 examples/s]Tokenizing train dataset:  31%|███       | 2665/8564 [00:08<00:17, 342.32 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:08<00:16, 352.47 examples/s]Tokenizing train dataset:  32%|███▏      | 2708/8564 [00:08<00:16, 347.11 examples/s]Tokenizing train dataset:  32%|███▏      | 2720/8564 [00:08<00:16, 344.51 examples/s]Tokenizing train dataset:  31%|███       | 2670/8564 [00:08<00:17, 343.91 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:08<00:17, 344.28 examples/s]Tokenizing train dataset:  32%|███▏      | 2759/8564 [00:08<00:16, 343.28 examples/s]Tokenizing train dataset:  32%|███▏      | 2772/8564 [00:08<00:17, 338.54 examples/s]Tokenizing train dataset:  32%|███▏      | 2740/8564 [00:08<00:17, 341.77 examples/s]Tokenizing train dataset:  33%|███▎      | 2798/8564 [00:08<00:16, 351.30 examples/s]Tokenizing train dataset:  33%|███▎      | 2814/8564 [00:08<00:16, 354.93 examples/s]Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:08<00:16, 342.37 examples/s]Tokenizing train dataset:  33%|███▎      | 2837/8564 [00:08<00:16, 357.60 examples/s]Tokenizing train dataset:  33%|███▎      | 2866/8564 [00:08<00:16, 348.56 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:08<00:15, 363.54 examples/s]Tokenizing train dataset:  34%|███▍      | 2893/8564 [00:08<00:15, 357.24 examples/s]Tokenizing train dataset:  34%|███▍      | 2908/8564 [00:08<00:15, 364.17 examples/s]Tokenizing train dataset:  34%|███▍      | 2934/8564 [00:08<00:15, 369.81 examples/s]Tokenizing train dataset:  34%|███▎      | 2870/8564 [00:08<00:16, 344.31 examples/s]Tokenizing train dataset:  34%|███▍      | 2949/8564 [00:09<00:14, 374.56 examples/s]Tokenizing train dataset:  35%|███▍      | 2980/8564 [00:08<00:14, 390.37 examples/s]Tokenizing train dataset:  34%|███▍      | 2914/8564 [00:08<00:15, 366.89 examples/s]Tokenizing train dataset:  35%|███▍      | 2991/8564 [00:09<00:14, 385.36 examples/s]Tokenizing train dataset:  35%|███▍      | 2957/8564 [00:09<00:14, 379.89 examples/s]Tokenizing train dataset:  35%|███▌      | 3036/8564 [00:09<00:14, 378.11 examples/s]Tokenizing train dataset:  36%|███▌      | 3046/8564 [00:09<00:14, 372.27 examples/s]Tokenizing train dataset:  35%|███▌      | 3000/8564 [00:09<00:14, 388.72 examples/s]Tokenizing train dataset:  36%|███▌      | 3092/8564 [00:09<00:14, 374.19 examples/s]Tokenizing train dataset:  36%|███▌      | 3100/8564 [00:09<00:14, 365.48 examples/s]Tokenizing train dataset:  36%|███▌      | 3054/8564 [00:09<00:14, 371.17 examples/s]Tokenizing train dataset:  37%|███▋      | 3148/8564 [00:09<00:14, 370.82 examples/s]Tokenizing train dataset:  37%|███▋      | 3157/8564 [00:09<00:14, 366.99 examples/s]Tokenizing train dataset:  36%|███▋      | 3111/8564 [00:09<00:14, 371.27 examples/s]Tokenizing train dataset:  37%|███▋      | 3204/8564 [00:09<00:14, 368.54 examples/s]Tokenizing train dataset:  37%|███▋      | 3211/8564 [00:09<00:14, 362.19 examples/s]Tokenizing train dataset:  37%|███▋      | 3166/8564 [00:09<00:14, 365.24 examples/s]Tokenizing train dataset:  38%|███▊      | 3245/8564 [00:09<00:14, 375.37 examples/s]Tokenizing train dataset:  38%|███▊      | 3253/8564 [00:09<00:14, 371.22 examples/s]Tokenizing train dataset:  37%|███▋      | 3203/8564 [00:09<00:14, 364.44 examples/s]Tokenizing train dataset:  39%|███▊      | 3299/8564 [00:09<00:14, 366.34 examples/s]Tokenizing train dataset:  38%|███▊      | 3243/8564 [00:09<00:14, 369.17 examples/s]Tokenizing train dataset:  39%|███▊      | 3305/8564 [00:10<00:14, 360.09 examples/s]Tokenizing train dataset:  39%|███▉      | 3352/8564 [00:10<00:14, 359.62 examples/s]Tokenizing train dataset:  39%|███▊      | 3298/8564 [00:09<00:14, 364.20 examples/s]Tokenizing train dataset:  39%|███▉      | 3361/8564 [00:10<00:14, 356.81 examples/s]Tokenizing train dataset:  40%|███▉      | 3394/8564 [00:10<00:13, 370.52 examples/s]Tokenizing train dataset:  40%|███▉      | 3404/8564 [00:10<00:13, 371.30 examples/s]Tokenizing train dataset:  39%|███▉      | 3350/8564 [00:10<00:14, 355.45 examples/s]Tokenizing train dataset:  40%|████      | 3435/8564 [00:10<00:13, 378.48 examples/s]Tokenizing train dataset:  40%|███▉      | 3394/8564 [00:10<00:14, 367.57 examples/s]Tokenizing train dataset:  40%|████      | 3463/8564 [00:10<00:13, 372.49 examples/s]Tokenizing train dataset:  41%|████      | 3489/8564 [00:10<00:13, 368.58 examples/s]Tokenizing train dataset:  40%|████      | 3435/8564 [00:10<00:13, 375.43 examples/s]Tokenizing train dataset:  41%|████      | 3523/8564 [00:10<00:13, 376.02 examples/s]Tokenizing train dataset:  41%|████      | 3531/8564 [00:10<00:13, 377.89 examples/s]Tokenizing train dataset:  41%|████      | 3489/8564 [00:10<00:13, 365.62 examples/s]Tokenizing train dataset:  42%|████▏     | 3576/8564 [00:10<00:13, 365.11 examples/s]Tokenizing train dataset:  42%|████▏     | 3589/8564 [00:10<00:13, 375.81 examples/s]Tokenizing train dataset:  41%|████      | 3531/8564 [00:10<00:13, 374.76 examples/s]Tokenizing train dataset:  42%|████▏     | 3615/8564 [00:10<00:13, 368.87 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:10<00:13, 376.49 examples/s]Tokenizing train dataset:  42%|████▏     | 3589/8564 [00:10<00:13, 372.86 examples/s]Tokenizing train dataset:  43%|████▎     | 3668/8564 [00:11<00:13, 359.59 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:10<00:13, 354.30 examples/s]Tokenizing train dataset:  42%|████▏     | 3628/8564 [00:10<00:13, 376.12 examples/s]Tokenizing train dataset:  43%|████▎     | 3724/8564 [00:11<00:12, 372.46 examples/s]Tokenizing train dataset:  44%|████▎     | 3726/8564 [00:11<00:13, 366.92 examples/s]Tokenizing train dataset:  43%|████▎     | 3676/8564 [00:11<00:13, 353.79 examples/s]Tokenizing train dataset:  44%|████▍     | 3764/8564 [00:11<00:13, 366.15 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:11<00:12, 371.05 examples/s]Tokenizing train dataset:  43%|████▎     | 3714/8564 [00:11<00:13, 358.24 examples/s]Tokenizing train dataset:  44%|████▍     | 3802/8564 [00:11<00:12, 366.88 examples/s]Tokenizing train dataset:  44%|████▍     | 3755/8564 [00:11<00:13, 365.51 examples/s]Tokenizing train dataset:  45%|████▍     | 3835/8564 [00:11<00:12, 366.23 examples/s]Tokenizing train dataset:  45%|████▍     | 3839/8564 [00:11<00:13, 361.48 examples/s]Tokenizing train dataset:  44%|████▍     | 3794/8564 [00:11<00:12, 368.61 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:11<00:12, 363.99 examples/s]Tokenizing train dataset:  45%|████▌     | 3893/8564 [00:11<00:13, 357.32 examples/s]Tokenizing train dataset:  45%|████▍     | 3848/8564 [00:11<00:13, 358.82 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:11<00:13, 353.83 examples/s]Tokenizing train dataset:  45%|████▌     | 3886/8564 [00:11<00:12, 361.25 examples/s]Tokenizing train dataset:  46%|████▌     | 3945/8564 [00:11<00:13, 349.08 examples/s]Tokenizing train dataset:  46%|████▋     | 3978/8564 [00:11<00:12, 355.72 examples/s]Tokenizing train dataset:  46%|████▌     | 3939/8564 [00:11<00:13, 351.78 examples/s]Tokenizing train dataset:  47%|████▋     | 4000/8564 [00:11<00:12, 352.39 examples/s]Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:11<00:12, 358.09 examples/s]Tokenizing train dataset:  46%|████▋     | 3975/8564 [00:11<00:13, 350.74 examples/s]Tokenizing train dataset:  47%|████▋     | 4040/8564 [00:12<00:12, 360.70 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:11<00:12, 366.03 examples/s]Tokenizing train dataset:  48%|████▊     | 4078/8564 [00:12<00:12, 362.24 examples/s]Tokenizing train dataset:  47%|████▋     | 4032/8564 [00:11<00:12, 356.19 examples/s]Tokenizing train dataset:  48%|████▊     | 4112/8564 [00:12<00:12, 363.79 examples/s]Tokenizing train dataset:  48%|████▊     | 4069/8564 [00:12<00:12, 357.22 examples/s]Tokenizing train dataset:  48%|████▊     | 4130/8564 [00:12<00:12, 352.74 examples/s]Tokenizing train dataset:  49%|████▊     | 4164/8564 [00:12<00:12, 354.00 examples/s]Tokenizing train dataset:  49%|████▊     | 4166/8564 [00:12<00:12, 350.40 examples/s]Tokenizing train dataset:  48%|████▊     | 4123/8564 [00:12<00:12, 353.76 examples/s]Tokenizing train dataset:  49%|████▉     | 4205/8564 [00:12<00:11, 366.65 examples/s]Tokenizing train dataset:  49%|████▉     | 4208/8564 [00:12<00:11, 363.77 examples/s]Tokenizing train dataset:  49%|████▉     | 4176/8564 [00:12<00:12, 349.22 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:12<00:12, 356.98 examples/s]Tokenizing train dataset:  50%|████▉     | 4262/8564 [00:12<00:12, 356.33 examples/s]Tokenizing train dataset:  49%|████▉     | 4215/8564 [00:12<00:12, 358.12 examples/s]Tokenizing train dataset:  50%|█████     | 4299/8564 [00:12<00:11, 362.19 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:12<00:11, 356.74 examples/s]Tokenizing train dataset:  50%|████▉     | 4270/8564 [00:12<00:12, 354.96 examples/s]Tokenizing train dataset:  51%|█████     | 4337/8564 [00:12<00:11, 354.19 examples/s]Tokenizing train dataset:  51%|█████     | 4353/8564 [00:12<00:11, 355.47 examples/s]Tokenizing train dataset:  50%|█████     | 4309/8564 [00:12<00:11, 358.52 examples/s]Tokenizing train dataset:  51%|█████     | 4374/8564 [00:12<00:11, 357.09 examples/s]Tokenizing train dataset:  51%|█████▏    | 4393/8564 [00:12<00:11, 362.76 examples/s]Tokenizing train dataset:  52%|█████▏    | 4411/8564 [00:13<00:11, 359.69 examples/s]Tokenizing train dataset:  52%|█████▏    | 4430/8564 [00:12<00:11, 361.61 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:12<00:11, 351.09 examples/s]Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:13<00:11, 361.32 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:13<00:11, 365.83 examples/s]Tokenizing train dataset:  51%|█████▏    | 4402/8564 [00:13<00:11, 363.06 examples/s]Tokenizing train dataset:  52%|█████▏    | 4490/8564 [00:13<00:11, 363.54 examples/s]Tokenizing train dataset:  53%|█████▎    | 4507/8564 [00:13<00:11, 359.76 examples/s]Tokenizing train dataset:  52%|█████▏    | 4439/8564 [00:13<00:11, 360.68 examples/s]Tokenizing train dataset:  53%|█████▎    | 4545/8564 [00:13<00:11, 359.49 examples/s]Tokenizing train dataset:  52%|█████▏    | 4476/8564 [00:13<00:11, 362.37 examples/s]Tokenizing train dataset:  53%|█████▎    | 4544/8564 [00:13<00:11, 357.60 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:13<00:11, 349.59 examples/s]Tokenizing train dataset:  54%|█████▎    | 4600/8564 [00:13<00:11, 356.25 examples/s]Tokenizing train dataset:  53%|█████▎    | 4529/8564 [00:13<00:11, 351.46 examples/s]Tokenizing train dataset:  54%|█████▍    | 4620/8564 [00:13<00:11, 356.57 examples/s]Tokenizing train dataset:  54%|█████▍    | 4636/8564 [00:13<00:11, 350.13 examples/s]Tokenizing train dataset:  53%|█████▎    | 4569/8564 [00:13<00:11, 358.34 examples/s]Tokenizing train dataset:  54%|█████▍    | 4666/8564 [00:13<00:11, 336.35 examples/s]Tokenizing train dataset:  55%|█████▍    | 4686/8564 [00:13<00:11, 338.88 examples/s]Tokenizing train dataset:  54%|█████▍    | 4622/8564 [00:13<00:11, 352.34 examples/s]Tokenizing train dataset:  55%|█████▌    | 4716/8564 [00:13<00:11, 329.15 examples/s]Tokenizing train dataset:  55%|█████▌    | 4737/8564 [00:13<00:11, 335.35 examples/s]Tokenizing train dataset:  55%|█████▍    | 4670/8564 [00:13<00:11, 338.19 examples/s]Tokenizing train dataset:  56%|█████▌    | 4764/8564 [00:14<00:11, 324.72 examples/s]Tokenizing train dataset:  56%|█████▌    | 4782/8564 [00:14<00:11, 321.09 examples/s]Tokenizing train dataset:  55%|█████▌    | 4718/8564 [00:13<00:11, 327.70 examples/s]Tokenizing train dataset:  56%|█████▌    | 4797/8564 [00:14<00:11, 324.14 examples/s]Tokenizing train dataset:  57%|█████▋    | 4840/8564 [00:14<00:09, 376.06 examples/s]Tokenizing train dataset:  56%|█████▌    | 4767/8564 [00:14<00:11, 323.37 examples/s]Tokenizing train dataset:  57%|█████▋    | 4862/8564 [00:14<00:09, 403.64 examples/s]Tokenizing train dataset:  57%|█████▋    | 4896/8564 [00:14<00:08, 420.81 examples/s]Tokenizing train dataset:  56%|█████▌    | 4804/8564 [00:14<00:11, 330.94 examples/s]Tokenizing train dataset:  57%|█████▋    | 4920/8564 [00:14<00:08, 447.47 examples/s]Tokenizing train dataset:  58%|█████▊    | 4960/8564 [00:14<00:07, 476.65 examples/s]Tokenizing train dataset:  57%|█████▋    | 4866/8564 [00:14<00:09, 400.50 examples/s]Tokenizing train dataset:  58%|█████▊    | 4984/8564 [00:14<00:07, 494.02 examples/s]Tokenizing train dataset:  59%|█████▊    | 5022/8564 [00:14<00:06, 513.06 examples/s]Tokenizing train dataset:  58%|█████▊    | 4931/8564 [00:14<00:07, 458.40 examples/s]Tokenizing train dataset:  59%|█████▉    | 5045/8564 [00:14<00:06, 522.69 examples/s]Tokenizing train dataset:  59%|█████▉    | 5088/8564 [00:14<00:06, 551.49 examples/s]Tokenizing train dataset:  58%|█████▊    | 4990/8564 [00:14<00:07, 489.23 examples/s]Tokenizing train dataset:  60%|█████▉    | 5113/8564 [00:14<00:06, 566.18 examples/s]Tokenizing train dataset:  60%|██████    | 5156/8564 [00:14<00:05, 584.10 examples/s]Tokenizing train dataset:  59%|█████▉    | 5053/8564 [00:14<00:06, 526.64 examples/s]Tokenizing train dataset:  61%|██████    | 5184/8564 [00:14<00:05, 605.59 examples/s]Tokenizing train dataset:  61%|██████    | 5228/8564 [00:14<00:05, 620.47 examples/s]Tokenizing train dataset:  60%|█████▉    | 5120/8564 [00:14<00:06, 561.22 examples/s]Tokenizing train dataset:  61%|██████▏   | 5258/8564 [00:14<00:05, 640.11 examples/s]Tokenizing train dataset:  62%|██████▏   | 5304/8564 [00:14<00:04, 657.01 examples/s]Tokenizing train dataset:  61%|██████    | 5193/8564 [00:14<00:05, 606.73 examples/s]Tokenizing train dataset:  62%|██████▏   | 5324/8564 [00:15<00:05, 642.67 examples/s]Tokenizing train dataset:  63%|██████▎   | 5389/8564 [00:14<00:05, 619.83 examples/s]Tokenizing train dataset:  62%|██████▏   | 5269/8564 [00:14<00:05, 645.00 examples/s]Tokenizing train dataset:  63%|██████▎   | 5410/8564 [00:15<00:05, 608.54 examples/s]Tokenizing train dataset:  64%|██████▎   | 5454/8564 [00:15<00:04, 623.01 examples/s]Tokenizing train dataset:  63%|██████▎   | 5362/8564 [00:15<00:05, 631.69 examples/s]Tokenizing train dataset:  64%|██████▍   | 5475/8564 [00:15<00:04, 618.12 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:15<00:04, 612.08 examples/s]Tokenizing train dataset:  64%|██████▎   | 5454/8564 [00:15<00:05, 619.09 examples/s]Tokenizing train dataset:  65%|██████▍   | 5564/8564 [00:15<00:04, 606.66 examples/s]Tokenizing train dataset:  66%|██████▌   | 5614/8564 [00:15<00:04, 625.15 examples/s]Tokenizing train dataset:  66%|██████▌   | 5635/8564 [00:15<00:04, 630.85 examples/s]Tokenizing train dataset:  66%|██████▋   | 5678/8564 [00:15<00:04, 626.20 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:15<00:04, 608.89 examples/s]Tokenizing train dataset:  67%|██████▋   | 5702/8564 [00:15<00:04, 638.85 examples/s]Tokenizing train dataset:  67%|██████▋   | 5744/8564 [00:15<00:04, 629.71 examples/s]Tokenizing train dataset:  66%|██████▌   | 5614/8564 [00:15<00:04, 620.83 examples/s]Tokenizing train dataset:  67%|██████▋   | 5774/8564 [00:15<00:04, 659.16 examples/s]Tokenizing train dataset:  68%|██████▊   | 5824/8564 [00:15<00:04, 674.06 examples/s]Tokenizing train dataset:  66%|██████▋   | 5677/8564 [00:15<00:04, 621.60 examples/s]Tokenizing train dataset:  68%|██████▊   | 5842/8564 [00:15<00:04, 660.45 examples/s]Tokenizing train dataset:  67%|██████▋   | 5743/8564 [00:15<00:04, 625.32 examples/s]Tokenizing train dataset:  69%|██████▉   | 5910/8564 [00:15<00:04, 627.16 examples/s]Tokenizing train dataset:  68%|██████▊   | 5822/8564 [00:15<00:04, 668.24 examples/s]Tokenizing train dataset:  69%|██████▉   | 5931/8564 [00:16<00:04, 628.55 examples/s]Tokenizing train dataset:  70%|██████▉   | 5978/8564 [00:15<00:04, 636.85 examples/s]Tokenizing train dataset:  69%|██████▉   | 5901/8564 [00:15<00:04, 613.66 examples/s]Tokenizing train dataset:  70%|███████   | 6015/8564 [00:16<00:04, 601.72 examples/s]Tokenizing train dataset:  71%|███████   | 6058/8564 [00:16<00:04, 599.61 examples/s]Tokenizing train dataset:  70%|██████▉   | 5971/8564 [00:16<00:04, 632.09 examples/s]Tokenizing train dataset:  71%|███████   | 6099/8564 [00:16<00:04, 586.67 examples/s]Tokenizing train dataset:  72%|███████▏  | 6156/8564 [00:16<00:03, 612.47 examples/s]Tokenizing train dataset:  71%|███████   | 6052/8564 [00:16<00:04, 593.51 examples/s]Tokenizing train dataset:  72%|███████▏  | 6174/8564 [00:16<00:03, 624.47 examples/s]Tokenizing train dataset:  73%|███████▎  | 6230/8564 [00:16<00:03, 642.01 examples/s]Tokenizing train dataset:  73%|███████▎  | 6242/8564 [00:16<00:03, 636.07 examples/s]Tokenizing train dataset:  72%|███████▏  | 6150/8564 [00:16<00:04, 602.80 examples/s]Tokenizing train dataset:  74%|███████▍  | 6329/8564 [00:16<00:03, 640.49 examples/s]Tokenizing train dataset:  74%|███████▎  | 6307/8564 [00:16<00:03, 638.91 examples/s]Tokenizing train dataset:  73%|███████▎  | 6222/8564 [00:16<00:03, 630.24 examples/s]Tokenizing train dataset:  75%|███████▍  | 6400/8564 [00:16<00:03, 652.27 examples/s]Tokenizing train dataset:  74%|███████▍  | 6380/8564 [00:16<00:03, 656.84 examples/s]Tokenizing train dataset:  73%|███████▎  | 6290/8564 [00:16<00:03, 641.81 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [00:16<00:03, 631.10 examples/s]Tokenizing train dataset:  74%|███████▍  | 6357/8564 [00:16<00:03, 647.40 examples/s]Tokenizing train dataset:  76%|███████▌  | 6471/8564 [00:16<00:03, 633.01 examples/s]Tokenizing train dataset:  77%|███████▋  | 6582/8564 [00:16<00:03, 616.27 examples/s]Tokenizing train dataset:  75%|███████▌  | 6452/8564 [00:16<00:03, 639.86 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [00:17<00:03, 622.89 examples/s]Tokenizing train dataset:  78%|███████▊  | 6667/8564 [00:17<00:03, 596.23 examples/s]Tokenizing train dataset:  76%|███████▋  | 6541/8564 [00:16<00:03, 621.22 examples/s]Tokenizing train dataset:  78%|███████▊  | 6646/8564 [00:17<00:03, 585.06 examples/s]Tokenizing train dataset:  79%|███████▊  | 6734/8564 [00:17<00:02, 610.34 examples/s]Tokenizing train dataset:  78%|███████▊  | 6718/8564 [00:17<00:03, 614.46 examples/s]Tokenizing train dataset:  77%|███████▋  | 6618/8564 [00:17<00:03, 580.34 examples/s]Tokenizing train dataset:  79%|███████▉  | 6803/8564 [00:17<00:02, 627.01 examples/s]Tokenizing train dataset:  79%|███████▉  | 6783/8564 [00:17<00:02, 622.26 examples/s]Tokenizing train dataset:  78%|███████▊  | 6683/8564 [00:17<00:03, 595.66 examples/s]Tokenizing train dataset:  80%|████████  | 6892/8564 [00:17<00:02, 612.70 examples/s]Tokenizing train dataset:  79%|███████▉  | 6755/8564 [00:17<00:02, 620.43 examples/s]Tokenizing train dataset:  80%|████████  | 6871/8564 [00:17<00:02, 603.92 examples/s]Tokenizing train dataset:  81%|████████▏ | 6959/8564 [00:17<00:02, 623.99 examples/s]Tokenizing train dataset:  81%|████████  | 6943/8564 [00:17<00:02, 631.62 examples/s]Tokenizing train dataset:  80%|███████▉  | 6838/8564 [00:17<00:02, 595.04 examples/s]Tokenizing train dataset:  82%|████████▏ | 7047/8564 [00:17<00:02, 601.96 examples/s]Tokenizing train dataset:  81%|████████  | 6906/8564 [00:17<00:02, 613.80 examples/s]Tokenizing train dataset:  82%|████████▏ | 7020/8564 [00:17<00:02, 582.44 examples/s]Tokenizing train dataset:  83%|████████▎ | 7116/8564 [00:17<00:02, 622.17 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [00:17<00:02, 611.69 examples/s]Tokenizing train dataset:  82%|████████▏ | 6998/8564 [00:17<00:02, 610.27 examples/s]Tokenizing train dataset:  84%|████████▍ | 7183/8564 [00:17<00:02, 631.51 examples/s]Tokenizing train dataset:  84%|████████▎ | 7154/8564 [00:18<00:02, 612.93 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [00:17<00:02, 609.79 examples/s]Tokenizing train dataset:  84%|████████▍ | 7221/8564 [00:18<00:02, 626.52 examples/s]Tokenizing train dataset:  85%|████████▍ | 7277/8564 [00:18<00:02, 621.72 examples/s]Tokenizing train dataset:  84%|████████▎ | 7153/8564 [00:18<00:02, 609.71 examples/s]Tokenizing train dataset:  85%|████████▌ | 7313/8564 [00:18<00:02, 614.27 examples/s]Tokenizing train dataset:  86%|████████▌ | 7374/8564 [00:18<00:01, 625.21 examples/s]Tokenizing train dataset:  84%|████████▍ | 7221/8564 [00:18<00:02, 624.85 examples/s]Tokenizing train dataset:  86%|████████▌ | 7378/8564 [00:18<00:01, 622.39 examples/s]Tokenizing train dataset:  87%|████████▋ | 7441/8564 [00:18<00:01, 630.09 examples/s]Tokenizing train dataset:  85%|████████▌ | 7313/8564 [00:18<00:02, 613.22 examples/s]Tokenizing train dataset:  87%|████████▋ | 7443/8564 [00:18<00:01, 625.54 examples/s]Tokenizing train dataset:  88%|████████▊ | 7539/8564 [00:18<00:01, 636.38 examples/s]Tokenizing train dataset:  86%|████████▌ | 7378/8564 [00:18<00:01, 621.29 examples/s]Tokenizing train dataset:  88%|████████▊ | 7543/8564 [00:18<00:01, 634.90 examples/s]Tokenizing train dataset:  89%|████████▉ | 7609/8564 [00:18<00:01, 648.99 examples/s]Tokenizing train dataset:  87%|████████▋ | 7443/8564 [00:18<00:01, 625.04 examples/s]Tokenizing train dataset:  89%|████████▉ | 7611/8564 [00:18<00:01, 643.38 examples/s]Tokenizing train dataset:  88%|████████▊ | 7506/8564 [00:18<00:01, 620.93 examples/s]Tokenizing train dataset:  90%|████████▉ | 7695/8564 [00:18<00:01, 617.62 examples/s]Tokenizing train dataset:  89%|████████▊ | 7581/8564 [00:18<00:01, 651.61 examples/s]Tokenizing train dataset:  90%|████████▉ | 7698/8564 [00:18<00:01, 618.20 examples/s]Tokenizing train dataset:  91%|█████████ | 7781/8564 [00:18<00:01, 600.02 examples/s]Tokenizing train dataset:  90%|████████▉ | 7665/8564 [00:18<00:01, 615.10 examples/s]Tokenizing train dataset:  91%|█████████ | 7784/8564 [00:19<00:01, 598.06 examples/s]Tokenizing train dataset:  92%|█████████▏| 7871/8564 [00:18<00:01, 596.62 examples/s]Tokenizing train dataset:  92%|█████████▏| 7847/8564 [00:19<00:01, 602.83 examples/s]Tokenizing train dataset:  91%|█████████ | 7755/8564 [00:18<00:01, 604.62 examples/s]Tokenizing train dataset:  93%|█████████▎| 7936/8564 [00:19<00:01, 606.16 examples/s]Tokenizing train dataset:  92%|█████████▏| 7908/8564 [00:19<00:01, 603.29 examples/s]Tokenizing train dataset:  93%|█████████▎| 8003/8564 [00:19<00:00, 620.40 examples/s]Tokenizing train dataset:  92%|█████████▏| 7843/8564 [00:19<00:01, 596.52 examples/s]Tokenizing train dataset:  93%|█████████▎| 7969/8564 [00:19<00:00, 604.09 examples/s]Tokenizing train dataset:  92%|█████████▏| 7905/8564 [00:19<00:01, 598.89 examples/s]Tokenizing train dataset:  94%|█████████▍| 8032/8564 [00:19<00:00, 609.24 examples/s]Tokenizing train dataset:  94%|█████████▍| 8092/8564 [00:19<00:00, 601.39 examples/s]Tokenizing train dataset:  93%|█████████▎| 7966/8564 [00:19<00:00, 600.60 examples/s]Tokenizing train dataset:  95%|█████████▍| 8120/8564 [00:19<00:00, 594.00 examples/s]Tokenizing train dataset:  96%|█████████▌| 8184/8564 [00:19<00:00, 602.91 examples/s]Tokenizing train dataset:  94%|█████████▍| 8032/8564 [00:19<00:00, 607.32 examples/s]Tokenizing train dataset:  96%|█████████▌| 8184/8564 [00:19<00:00, 603.18 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [00:19<00:00, 611.90 examples/s]Tokenizing train dataset:  95%|█████████▍| 8120/8564 [00:19<00:00, 592.00 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [00:19<00:00, 613.35 examples/s]Tokenizing train dataset:  97%|█████████▋| 8329/8564 [00:19<00:00, 645.99 examples/s]Tokenizing train dataset:  96%|█████████▌| 8184/8564 [00:19<00:00, 600.21 examples/s]Tokenizing train dataset:  97%|█████████▋| 8329/8564 [00:19<00:00, 650.10 examples/s]Tokenizing train dataset:  98%|█████████▊| 8417/8564 [00:19<00:00, 618.31 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [00:19<00:00, 610.09 examples/s]Tokenizing train dataset:  98%|█████████▊| 8413/8564 [00:20<00:00, 613.92 examples/s]Tokenizing train dataset:  99%|█████████▉| 8481/8564 [00:19<00:00, 618.36 examples/s]Tokenizing train dataset:  97%|█████████▋| 8328/8564 [00:19<00:00, 648.30 examples/s]Tokenizing train dataset:  99%|█████████▉| 8478/8564 [00:20<00:00, 619.78 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 614.18 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 425.72 examples/s]
Tokenizing train dataset:  98%|█████████▊| 8411/8564 [00:20<00:00, 607.38 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 613.93 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 421.51 examples/s]
Tokenizing train dataset:  99%|█████████▉| 8477/8564 [00:20<00:00, 617.17 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 610.15 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 421.61 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11438.07 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11160.51 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11130.00 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 12487.53 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13272.72 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13576.84 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 319.90 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 322.33 examples/s]Tokenizing eval dataset:   3%|▎         | 26/953 [00:00<00:03, 253.92 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 292.03 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 292.51 examples/s]Tokenizing eval dataset:   6%|▋         | 60/953 [00:00<00:03, 226.06 examples/s]Tokenizing eval dataset:   9%|▉         | 87/953 [00:00<00:03, 236.84 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:03, 274.42 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:03, 274.44 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:03, 219.34 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 265.58 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 265.42 examples/s]Tokenizing eval dataset:  15%|█▌        | 143/953 [00:00<00:03, 217.93 examples/s]Tokenizing eval dataset:  21%|██        | 196/953 [00:00<00:02, 255.79 examples/s]Tokenizing eval dataset:  21%|██        | 196/953 [00:00<00:02, 255.59 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:00<00:02, 286.24 examples/s]Tokenizing eval dataset:  18%|█▊        | 172/953 [00:00<00:03, 206.01 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:00<00:02, 286.08 examples/s]Tokenizing eval dataset:  32%|███▏      | 302/953 [00:00<00:01, 385.94 examples/s]Tokenizing eval dataset:  32%|███▏      | 302/953 [00:00<00:01, 385.87 examples/s]Tokenizing eval dataset:  21%|██▏       | 203/953 [00:00<00:03, 204.83 examples/s]Tokenizing eval dataset:  38%|███▊      | 363/953 [00:01<00:01, 442.12 examples/s]Tokenizing eval dataset:  38%|███▊      | 363/953 [00:01<00:01, 441.87 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:01<00:03, 231.14 examples/s]Tokenizing eval dataset:  45%|████▌     | 432/953 [00:01<00:01, 507.36 examples/s]Tokenizing eval dataset:  45%|████▌     | 433/953 [00:01<00:01, 508.91 examples/s]Tokenizing eval dataset:  31%|███       | 291/953 [00:01<00:02, 311.30 examples/s]Tokenizing eval dataset:  52%|█████▏    | 500/953 [00:01<00:00, 552.25 examples/s]Tokenizing eval dataset:  53%|█████▎    | 501/953 [00:01<00:00, 554.19 examples/s]Tokenizing eval dataset:  36%|███▌      | 341/953 [00:01<00:01, 360.83 examples/s]Tokenizing eval dataset:  59%|█████▉    | 566/953 [00:01<00:00, 574.62 examples/s]Tokenizing eval dataset:  59%|█████▉    | 566/953 [00:01<00:00, 574.04 examples/s]Tokenizing eval dataset:  41%|████      | 390/953 [00:01<00:01, 392.84 examples/s]Tokenizing eval dataset:  67%|██████▋   | 635/953 [00:01<00:00, 606.19 examples/s]Tokenizing eval dataset:  67%|██████▋   | 635/953 [00:01<00:00, 605.81 examples/s]Tokenizing eval dataset:  47%|████▋     | 450/953 [00:01<00:01, 446.81 examples/s]Tokenizing eval dataset:  76%|███████▌  | 725/953 [00:01<00:00, 596.36 examples/s]Tokenizing eval dataset:  76%|███████▌  | 725/953 [00:01<00:00, 596.41 examples/s]Tokenizing eval dataset:  54%|█████▍    | 513/953 [00:01<00:01, 432.10 examples/s]Tokenizing eval dataset:  84%|████████▍ | 803/953 [00:01<00:00, 560.84 examples/s]Tokenizing eval dataset:  59%|█████▊    | 558/953 [00:01<00:00, 428.64 examples/s]Tokenizing eval dataset:  84%|████████▍ | 803/953 [00:01<00:00, 559.49 examples/s]Tokenizing eval dataset:  64%|██████▎   | 606/953 [00:01<00:00, 440.10 examples/s]Tokenizing eval dataset:  92%|█████████▏| 881/953 [00:01<00:00, 540.55 examples/s]Tokenizing eval dataset:  92%|█████████▏| 881/953 [00:01<00:00, 538.54 examples/s]Tokenizing eval dataset:  70%|██████▉   | 667/953 [00:01<00:00, 418.82 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 527.97 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 459.95 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 525.70 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 459.49 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  76%|███████▌  | 725/953 [00:02<00:00, 405.70 examples/s]Tokenizing eval dataset:  82%|████████▏ | 781/953 [00:02<00:00, 390.73 examples/s]Tokenizing eval dataset:  87%|████████▋ | 831/953 [00:02<00:00, 365.93 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:02<00:00, 351.71 examples/s]Tokenizing eval dataset:  99%|█████████▉| 943/953 [00:02<00:00, 363.61 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 341.52 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.425265312194824 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.363765001296997 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.355984926223755 seconds
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4546780586242676 seconds
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Training complete
Saving model
[rank4]:[W601 15:23:41.051303825 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 1 ---
