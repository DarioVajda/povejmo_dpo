cpu-bind=MASK - gn22, task  0  0 [112280]: mask 0x1000000000000000000000000000000010000000000000000000000000000 set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn22
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 0     --main_process_ip gn22     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62055338     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-30 16:13:35,961] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0530 16:13:38.727000 112331 torch/distributed/run.py:792] 
W0530 16:13:38.727000 112331 torch/distributed/run.py:792] *****************************************
W0530 16:13:38.727000 112331 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0530 16:13:38.727000 112331 torch/distributed/run.py:792] *****************************************
[2025-05-30 16:14:05,933] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 16:14:05,939] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 16:14:06,007] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-30 16:14:06,038] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 1
[2025-05-30 16:14:15,362] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 8564
Eval steps: 4282
[2025-05-30 16:14:15,398] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 16:14:15,398] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-05-30 16:14:15,426] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-30 16:14:15,431] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
[2025-05-30 16:14:18,880] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 16:14:18,880] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 16:14:18,891] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-30 16:14:18,892] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
hpZeRO group size: 4
[2025-05-30 16:15:39,622] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 465, num_elems = 10.16B
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:50<02:31, 50.54s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:50<02:31, 50.59s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:50<02:31, 50.61s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:50<02:31, 50.62s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:45<01:46, 53.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:45<01:46, 53.06s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:45<01:46, 53.08s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:45<01:46, 53.10s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:42<00:54, 55.00s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:42<00:54, 54.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:42<00:54, 54.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:42<00:54, 54.99s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 49.87s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 49.88s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 49.88s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 49.88s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 51.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 51.19s/it]Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 51.19s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [03:24<00:00, 51.19s/it]

/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Using LoRA and set up the model model
-------------------- CHECKING GRADIENTS --------------------
Trainable parameters:
- base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.32.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.33.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.34.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.35.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.36.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.36.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.37.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.37.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.38.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.38.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.39.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.39.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.40.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.40.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.40.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.40.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.40.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.q_proj.lora_B.default.weight (shape: torch.Size([4096, 64]), numel: 262144)
- base_model.model.model.layers.41.self_attn.k_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.k_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.v_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.self_attn.v_proj.lora_B.default.weight (shape: torch.Size([2048, 64]), numel: 131072)
- base_model.model.model.layers.41.self_attn.o_proj.lora_A.default.weight (shape: torch.Size([64, 4096]), numel: 262144)
- base_model.model.model.layers.41.self_attn.o_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.gate_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.up_proj.lora_A.default.weight (shape: torch.Size([64, 3584]), numel: 229376)
- base_model.model.model.layers.41.mlp.up_proj.lora_B.default.weight (shape: torch.Size([14336, 64]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_A.default.weight (shape: torch.Size([64, 14336]), numel: 917504)
- base_model.model.model.layers.41.mlp.down_proj.lora_B.default.weight (shape: torch.Size([3584, 64]), numel: 229376)
Total trainable parameters: 216072192
------------------------------------------------------------
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 1/8564 [00:05<13:02:56,  5.49s/ examples]Extracting prompt in train dataset:   0%|          | 10/8564 [00:09<1:54:19,  1.25 examples/s]Extracting prompt in train dataset:   0%|          | 20/8564 [00:09<47:30,  3.00 examples/s]  Extracting prompt in train dataset:   0%|          | 30/8564 [00:09<26:25,  5.38 examples/s]Extracting prompt in train dataset:   0%|          | 40/8564 [00:09<16:38,  8.54 examples/s]Extracting prompt in train dataset:   1%|          | 50/8564 [00:09<11:17, 12.58 examples/s]Extracting prompt in train dataset:   1%|          | 60/8564 [00:10<08:07, 17.45 examples/s]Extracting prompt in train dataset:   1%|          | 80/8564 [00:10<04:39, 30.33 examples/s]Extracting prompt in train dataset:   1%|          | 101/8564 [00:10<02:58, 47.34 examples/s]Extracting prompt in train dataset:   1%|▏         | 120/8564 [00:10<02:58, 47.33 examples/s]Extracting prompt in train dataset:   2%|▏         | 149/8564 [00:10<01:57, 71.86 examples/s]Extracting prompt in train dataset:   2%|▏         | 170/8564 [00:11<01:39, 84.78 examples/s]Extracting prompt in train dataset:   2%|▏         | 190/8564 [00:11<01:26, 96.48 examples/s]Extracting prompt in train dataset:   3%|▎         | 232/8564 [00:11<00:56, 148.66 examples/s]Extracting prompt in train dataset:   3%|▎         | 270/8564 [00:11<00:44, 184.78 examples/s]Extracting prompt in train dataset:   4%|▎         | 300/8564 [00:11<00:41, 199.70 examples/s]Extracting prompt in train dataset:   4%|▍         | 336/8564 [00:11<00:35, 230.59 examples/s]Extracting prompt in train dataset:   4%|▍         | 370/8564 [00:11<00:34, 240.71 examples/s]Extracting prompt in train dataset:   5%|▍         | 412/8564 [00:11<00:29, 278.56 examples/s]Extracting prompt in train dataset:   5%|▌         | 443/8564 [00:12<00:29, 279.44 examples/s]Extracting prompt in train dataset:   6%|▌         | 476/8564 [00:12<00:29, 271.41 examples/s]Extracting prompt in train dataset:   6%|▌         | 520/8564 [00:12<00:26, 300.16 examples/s]Extracting prompt in train dataset:   7%|▋         | 557/8564 [00:12<00:25, 310.04 examples/s]Extracting prompt in train dataset:   7%|▋         | 600/8564 [00:12<00:27, 290.77 examples/s]Extracting prompt in train dataset:   7%|▋         | 640/8564 [00:12<00:27, 285.18 examples/s]Extracting prompt in train dataset:   8%|▊         | 670/8564 [00:12<00:28, 281.60 examples/s]Extracting prompt in train dataset:   8%|▊         | 700/8564 [00:12<00:31, 252.17 examples/s]Extracting prompt in train dataset:   9%|▊         | 730/8564 [00:13<00:30, 253.16 examples/s]Extracting prompt in train dataset:   9%|▉         | 770/8564 [00:13<00:27, 280.66 examples/s]Extracting prompt in train dataset:   9%|▉         | 811/8564 [00:13<00:25, 301.38 examples/s]Extracting prompt in train dataset:  10%|▉         | 850/8564 [00:13<00:24, 314.03 examples/s]Extracting prompt in train dataset:  10%|█         | 890/8564 [00:13<00:23, 328.59 examples/s]Extracting prompt in train dataset:  11%|█         | 930/8564 [00:13<00:22, 336.04 examples/s]Extracting prompt in train dataset:  11%|█▏        | 970/8564 [00:13<00:22, 344.85 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1020/8564 [00:13<00:20, 369.25 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1068/8564 [00:14<00:24, 303.80 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1104/8564 [00:14<00:24, 305.44 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1140/8564 [00:14<00:23, 311.78 examples/s]Extracting prompt in train dataset:  14%|█▎        | 1174/8564 [00:14<00:24, 302.20 examples/s]Extracting prompt in train dataset:  14%|█▍        | 1223/8564 [00:14<00:21, 341.14 examples/s]Extracting prompt in train dataset:  15%|█▍        | 1265/8564 [00:14<00:20, 349.87 examples/s]Extracting prompt in train dataset:  15%|█▌        | 1310/8564 [00:14<00:19, 368.35 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1349/8564 [00:14<00:20, 359.82 examples/s]Extracting prompt in train dataset:  16%|█▋        | 1397/8564 [00:15<00:22, 324.70 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1432/8564 [00:18<02:54, 40.87 examples/s] Extracting prompt in train dataset:  17%|█▋        | 1460/8564 [00:18<02:20, 50.49 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1507/8564 [00:18<01:37, 72.29 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1540/8564 [00:18<01:18, 89.20 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1580/8564 [00:18<01:00, 116.36 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1620/8564 [00:18<00:51, 135.50 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1649/8564 [00:18<00:45, 151.07 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1680/8564 [00:18<00:41, 166.67 examples/s]Extracting prompt in train dataset:  20%|██        | 1720/8564 [00:19<00:35, 194.99 examples/s]Extracting prompt in train dataset:  21%|██        | 1760/8564 [00:19<00:33, 200.70 examples/s]Extracting prompt in train dataset:  21%|██        | 1788/8564 [00:19<00:31, 212.75 examples/s]Extracting prompt in train dataset:  21%|██▏       | 1820/8564 [00:19<00:34, 196.57 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1845/8564 [00:19<00:33, 203.16 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1880/8564 [00:19<00:33, 197.10 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1912/8564 [00:20<00:31, 214.39 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1945/8564 [00:20<00:28, 230.83 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1970/8564 [00:20<00:29, 220.40 examples/s]Extracting prompt in train dataset:  23%|██▎       | 2000/8564 [00:20<00:28, 234.33 examples/s]Extracting prompt in train dataset:  24%|██▎       | 2029/8564 [00:20<00:27, 241.01 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2070/8564 [00:20<00:26, 243.06 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2100/8564 [00:20<00:27, 237.51 examples/s]Extracting prompt in train dataset:  25%|██▍       | 2140/8564 [00:20<00:24, 265.45 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2190/8564 [00:21<00:20, 310.54 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2240/8564 [00:21<00:18, 348.75 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2299/8564 [00:21<00:15, 400.50 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2370/8564 [00:21<00:15, 407.86 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2420/8564 [00:21<00:14, 420.25 examples/s]Extracting prompt in train dataset:  29%|██▉       | 2466/8564 [00:21<00:14, 420.43 examples/s]Extracting prompt in train dataset:  29%|██▉       | 2510/8564 [00:21<00:14, 412.40 examples/s]Extracting prompt in train dataset:  30%|██▉       | 2560/8564 [00:21<00:14, 425.24 examples/s]Extracting prompt in train dataset:  30%|███       | 2608/8564 [00:21<00:14, 414.98 examples/s]Extracting prompt in train dataset:  31%|███       | 2665/8564 [00:22<00:13, 444.48 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2729/8564 [00:22<00:13, 418.17 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2773/8564 [00:22<00:13, 416.36 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2820/8564 [00:22<00:13, 416.88 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2864/8564 [00:22<00:14, 404.29 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2912/8564 [00:22<00:13, 418.47 examples/s]Extracting prompt in train dataset:  35%|███▍      | 2960/8564 [00:22<00:13, 424.76 examples/s]Extracting prompt in train dataset:  35%|███▌      | 3011/8564 [00:22<00:12, 444.30 examples/s]Extracting prompt in train dataset:  36%|███▌      | 3072/8564 [00:23<00:13, 394.04 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3130/8564 [00:23<00:14, 382.39 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3171/8564 [00:23<00:14, 378.15 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3220/8564 [00:23<00:13, 394.96 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3276/8564 [00:23<00:12, 423.04 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3325/8564 [00:23<00:12, 413.62 examples/s]Extracting prompt in train dataset:  40%|███▉      | 3389/8564 [00:23<00:12, 404.21 examples/s]Extracting prompt in train dataset:  40%|████      | 3438/8564 [00:23<00:12, 413.90 examples/s]Extracting prompt in train dataset:  41%|████      | 3506/8564 [00:24<00:12, 411.48 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3556/8564 [00:24<00:12, 412.89 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3608/8564 [00:24<00:11, 425.40 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3675/8564 [00:24<00:11, 408.26 examples/s]Extracting prompt in train dataset:  44%|████▎     | 3727/8564 [00:24<00:11, 413.68 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3784/8564 [00:24<00:12, 386.80 examples/s]Extracting prompt in train dataset:  45%|████▍     | 3847/8564 [00:25<00:12, 385.05 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3890/8564 [00:25<00:12, 384.89 examples/s]Extracting prompt in train dataset:  46%|████▌     | 3935/8564 [00:25<00:11, 392.75 examples/s]Extracting prompt in train dataset:  47%|████▋     | 3990/8564 [00:25<00:12, 368.92 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4035/8564 [00:25<00:11, 379.14 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4075/8564 [00:25<00:12, 371.72 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4123/8564 [00:25<00:13, 333.17 examples/s]Extracting prompt in train dataset:  49%|████▊     | 4163/8564 [00:25<00:12, 339.25 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4213/8564 [00:26<00:11, 372.05 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4260/8564 [00:26<00:11, 386.94 examples/s]Extracting prompt in train dataset:  50%|█████     | 4315/8564 [00:26<00:10, 409.75 examples/s]Extracting prompt in train dataset:  51%|█████     | 4360/8564 [00:26<00:10, 407.53 examples/s]Extracting prompt in train dataset:  51%|█████▏    | 4404/8564 [00:26<00:10, 407.20 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4460/8564 [00:26<00:10, 383.68 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4510/8564 [00:26<00:09, 411.57 examples/s]Extracting prompt in train dataset:  54%|█████▎    | 4600/8564 [00:26<00:07, 519.15 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 4660/8564 [00:27<00:08, 440.50 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 4727/8564 [00:27<00:09, 408.85 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4792/8564 [00:27<00:10, 363.36 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4861/8564 [00:27<00:08, 417.85 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4916/8564 [00:27<00:08, 436.00 examples/s]Extracting prompt in train dataset:  59%|█████▊    | 5015/8564 [00:27<00:06, 533.25 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 5106/8564 [00:27<00:05, 621.35 examples/s]Extracting prompt in train dataset:  61%|██████    | 5200/8564 [00:28<00:05, 621.13 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5279/8564 [00:28<00:05, 644.03 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5370/8564 [00:28<00:05, 616.09 examples/s]Extracting prompt in train dataset:  64%|██████▎   | 5439/8564 [00:28<00:05, 614.96 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5510/8564 [00:28<00:05, 553.20 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 5585/8564 [00:28<00:05, 580.57 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 5657/8564 [00:28<00:04, 602.98 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5729/8564 [00:28<00:04, 632.08 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5819/8564 [00:29<00:03, 693.48 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5910/8564 [00:29<00:04, 645.12 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5983/8564 [00:29<00:03, 648.46 examples/s]Extracting prompt in train dataset:  71%|███████   | 6060/8564 [00:29<00:03, 655.85 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6131/8564 [00:29<00:03, 657.41 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6210/8564 [00:29<00:03, 690.28 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6286/8564 [00:29<00:03, 709.06 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6368/8564 [00:29<00:02, 735.72 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 6452/8564 [00:29<00:02, 743.44 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 6539/8564 [00:30<00:03, 660.85 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6620/8564 [00:30<00:03, 603.05 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6709/8564 [00:30<00:02, 668.96 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6808/8564 [00:30<00:02, 641.40 examples/s]Extracting prompt in train dataset:  81%|████████  | 6912/8564 [00:30<00:02, 646.39 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 6986/8564 [00:30<00:02, 665.59 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7090/8564 [00:30<00:02, 658.81 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7180/8564 [00:31<00:02, 612.99 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 7248/8564 [00:31<00:02, 615.81 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7313/8564 [00:31<00:02, 612.91 examples/s]Extracting prompt in train dataset:  86%|████████▋ | 7390/8564 [00:31<00:01, 635.69 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7455/8564 [00:31<00:01, 620.38 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7533/8564 [00:31<00:01, 641.83 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7615/8564 [00:31<00:01, 669.84 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7720/8564 [00:31<00:01, 647.88 examples/s]Extracting prompt in train dataset:  91%|█████████ | 7790/8564 [00:32<00:01, 486.13 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7877/8564 [00:32<00:01, 549.88 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7953/8564 [00:32<00:01, 577.26 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8041/8564 [00:32<00:00, 633.41 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8110/8564 [00:32<00:00, 630.36 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 8180/8564 [00:32<00:00, 611.80 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8279/8564 [00:32<00:00, 614.17 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8353/8564 [00:33<00:00, 638.67 examples/s]Extracting prompt in train dataset:  99%|█████████▊| 8453/8564 [00:33<00:00, 633.71 examples/s]Extracting prompt in train dataset: 100%|█████████▉| 8530/8564 [00:33<00:00, 650.63 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:34<00:00, 248.95 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:04<11:41:10,  4.91s/ examples]Applying chat template to train dataset:   1%|          | 94/8564 [00:05<05:20, 26.40 examples/s]  Applying chat template to train dataset:   2%|▏         | 207/8564 [00:05<02:00, 69.07 examples/s]Applying chat template to train dataset:   4%|▍         | 323/8564 [00:05<01:05, 126.19 examples/s]Applying chat template to train dataset:   5%|▌         | 450/8564 [00:05<00:39, 203.72 examples/s]Applying chat template to train dataset:   7%|▋         | 578/8564 [00:05<00:26, 296.78 examples/s]Applying chat template to train dataset:   8%|▊         | 705/8564 [00:05<00:19, 402.62 examples/s]Applying chat template to train dataset:  10%|▉         | 835/8564 [00:05<00:14, 516.36 examples/s]Applying chat template to train dataset:  11%|█         | 959/8564 [00:05<00:12, 624.07 examples/s]Applying chat template to train dataset:  13%|█▎        | 1075/8564 [00:05<00:10, 722.74 examples/s]Applying chat template to train dataset:  15%|█▍        | 1245/8564 [00:06<00:08, 831.05 examples/s]Applying chat template to train dataset:  16%|█▋        | 1408/8564 [00:06<00:08, 883.89 examples/s]Applying chat template to train dataset:  18%|█▊        | 1548/8564 [00:06<00:07, 944.85 examples/s]Applying chat template to train dataset:  20%|█▉        | 1672/8564 [00:06<00:06, 1009.61 examples/s]Applying chat template to train dataset:  21%|██        | 1788/8564 [00:06<00:06, 1044.91 examples/s]Applying chat template to train dataset:  22%|██▏       | 1905/8564 [00:06<00:06, 1075.91 examples/s]Applying chat template to train dataset:  24%|██▎       | 2025/8564 [00:06<00:05, 1108.42 examples/s]Applying chat template to train dataset:  25%|██▌       | 2145/8564 [00:06<00:05, 1095.20 examples/s]Applying chat template to train dataset:  26%|██▋       | 2264/8564 [00:06<00:05, 1120.34 examples/s]Applying chat template to train dataset:  28%|██▊       | 2425/8564 [00:07<00:05, 1141.12 examples/s]Applying chat template to train dataset:  30%|███       | 2593/8564 [00:07<00:05, 1131.76 examples/s]Applying chat template to train dataset:  32%|███▏      | 2710/8564 [00:07<00:05, 1140.26 examples/s]Applying chat template to train dataset:  34%|███▎      | 2869/8564 [00:07<00:05, 1110.60 examples/s]Applying chat template to train dataset:  35%|███▌      | 3035/8564 [00:07<00:05, 1092.88 examples/s]Applying chat template to train dataset:  37%|███▋      | 3168/8564 [00:07<00:05, 1006.24 examples/s]Applying chat template to train dataset:  38%|███▊      | 3294/8564 [00:07<00:05, 1022.45 examples/s]Applying chat template to train dataset:  40%|███▉      | 3401/8564 [00:08<00:05, 991.31 examples/s] Applying chat template to train dataset:  41%|████      | 3521/8564 [00:08<00:04, 1032.98 examples/s]Applying chat template to train dataset:  43%|████▎     | 3660/8564 [00:08<00:04, 1055.50 examples/s]Applying chat template to train dataset:  44%|████▍     | 3776/8564 [00:08<00:04, 1079.67 examples/s]Applying chat template to train dataset:  45%|████▌     | 3894/8564 [00:08<00:04, 1104.76 examples/s]Applying chat template to train dataset:  47%|████▋     | 4009/8564 [00:08<00:04, 1116.42 examples/s]Applying chat template to train dataset:  49%|████▊     | 4170/8564 [00:08<00:04, 1069.54 examples/s]Applying chat template to train dataset:  50%|█████     | 4298/8564 [00:08<00:03, 1122.18 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4463/8564 [00:08<00:03, 1113.33 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4648/8564 [00:09<00:03, 1151.63 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4810/8564 [00:09<00:03, 1126.40 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4979/8564 [00:09<00:03, 1085.19 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5098/8564 [00:09<00:03, 1106.25 examples/s]Applying chat template to train dataset:  61%|██████    | 5220/8564 [00:09<00:03, 1099.37 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5337/8564 [00:09<00:02, 1115.91 examples/s]Applying chat template to train dataset:  64%|██████▎   | 5452/8564 [00:09<00:02, 1123.79 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5570/8564 [00:09<00:02, 1137.86 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5693/8564 [00:10<00:02, 1149.56 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5811/8564 [00:10<00:02, 1157.35 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5933/8564 [00:10<00:02, 1169.43 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6105/8564 [00:10<00:02, 1156.88 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6223/8564 [00:10<00:02, 1162.75 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6351/8564 [00:10<00:01, 1193.40 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6526/8564 [00:10<00:01, 1181.64 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6650/8564 [00:10<00:01, 1163.91 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6770/8564 [00:10<00:01, 1170.72 examples/s]Applying chat template to train dataset:  81%|████████  | 6900/8564 [00:11<00:01, 1203.26 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7053/8564 [00:11<00:01, 1133.86 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7176/8564 [00:11<00:01, 1157.56 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7362/8564 [00:11<00:01, 1141.80 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7530/8564 [00:11<00:00, 1100.69 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7648/8564 [00:11<00:00, 1113.39 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7850/8564 [00:12<00:00, 948.69 examples/s] Applying chat template to train dataset:  93%|█████████▎| 7966/8564 [00:12<00:00, 989.99 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8080/8564 [00:12<00:00, 1022.53 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8219/8564 [00:12<00:00, 1083.92 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8400/8564 [00:12<00:00, 1226.23 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8540/8564 [00:12<00:00, 1241.31 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:12<00:00, 680.06 examples/s] 
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 1/8564 [00:00<1:22:39,  1.73 examples/s]Tokenizing train dataset:   0%|          | 10/8564 [00:01<18:58,  7.51 examples/s] Tokenizing train dataset:   0%|          | 32/8564 [00:01<04:58, 28.63 examples/s]Tokenizing train dataset:   1%|          | 45/8564 [00:01<03:40, 38.71 examples/s]Tokenizing train dataset:   1%|          | 56/8564 [00:01<02:57, 47.84 examples/s]Tokenizing train dataset:   1%|          | 71/8564 [00:01<02:12, 64.25 examples/s]Tokenizing train dataset:   1%|          | 89/8564 [00:02<01:50, 76.45 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:02<01:45, 80.36 examples/s]Tokenizing train dataset:   1%|▏         | 111/8564 [00:02<01:38, 85.82 examples/s]Tokenizing train dataset:   1%|▏         | 123/8564 [00:02<01:33, 90.08 examples/s]Tokenizing train dataset:   2%|▏         | 134/8564 [00:02<01:30, 93.07 examples/s]Tokenizing train dataset:   2%|▏         | 149/8564 [00:02<01:20, 104.21 examples/s]Tokenizing train dataset:   2%|▏         | 166/8564 [00:02<01:22, 101.83 examples/s]Tokenizing train dataset:   2%|▏         | 182/8564 [00:02<01:22, 101.59 examples/s]Tokenizing train dataset:   2%|▏         | 196/8564 [00:03<01:20, 104.42 examples/s]Tokenizing train dataset:   2%|▏         | 211/8564 [00:03<01:15, 110.49 examples/s]Tokenizing train dataset:   3%|▎         | 224/8564 [00:03<01:14, 111.58 examples/s]Tokenizing train dataset:   3%|▎         | 239/8564 [00:03<01:09, 119.67 examples/s]Tokenizing train dataset:   3%|▎         | 258/8564 [00:03<01:11, 116.47 examples/s]Tokenizing train dataset:   3%|▎         | 274/8564 [00:03<01:08, 121.58 examples/s]Tokenizing train dataset:   3%|▎         | 288/8564 [00:03<01:06, 124.09 examples/s]Tokenizing train dataset:   4%|▎         | 308/8564 [00:04<01:10, 117.73 examples/s]Tokenizing train dataset:   4%|▍         | 323/8564 [00:04<01:09, 117.97 examples/s]Tokenizing train dataset:   4%|▍         | 340/8564 [00:04<01:11, 115.54 examples/s]Tokenizing train dataset:   4%|▍         | 357/8564 [00:04<01:12, 112.70 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:04<01:13, 112.04 examples/s]Tokenizing train dataset:   4%|▍         | 385/8564 [00:04<01:11, 114.78 examples/s]Tokenizing train dataset:   5%|▍         | 399/8564 [00:04<01:11, 114.23 examples/s]Tokenizing train dataset:   5%|▍         | 416/8564 [00:05<01:15, 108.25 examples/s]Tokenizing train dataset:   5%|▌         | 431/8564 [00:05<01:11, 113.42 examples/s]Tokenizing train dataset:   5%|▌         | 444/8564 [00:05<01:21, 99.34 examples/s] Tokenizing train dataset:   5%|▌         | 457/8564 [00:05<01:22, 98.07 examples/s]Tokenizing train dataset:   5%|▌         | 470/8564 [00:05<01:17, 104.00 examples/s]Tokenizing train dataset:   6%|▌         | 484/8564 [00:05<01:24, 95.79 examples/s] Tokenizing train dataset:   6%|▌         | 500/8564 [00:05<01:16, 105.23 examples/s]Tokenizing train dataset:   6%|▌         | 517/8564 [00:06<01:15, 106.56 examples/s]Tokenizing train dataset:   6%|▌         | 530/8564 [00:06<01:14, 107.65 examples/s]Tokenizing train dataset:   6%|▋         | 545/8564 [00:06<01:11, 112.32 examples/s]Tokenizing train dataset:   7%|▋         | 558/8564 [00:06<01:09, 114.51 examples/s]Tokenizing train dataset:   7%|▋         | 571/8564 [00:06<01:12, 110.40 examples/s]Tokenizing train dataset:   7%|▋         | 587/8564 [00:06<01:14, 106.93 examples/s]Tokenizing train dataset:   7%|▋         | 598/8564 [00:06<01:17, 103.11 examples/s]Tokenizing train dataset:   7%|▋         | 611/8564 [00:06<01:15, 105.43 examples/s]Tokenizing train dataset:   7%|▋         | 624/8564 [00:06<01:15, 105.03 examples/s]Tokenizing train dataset:   7%|▋         | 642/8564 [00:07<01:04, 123.24 examples/s]Tokenizing train dataset:   8%|▊         | 657/8564 [00:07<01:02, 127.30 examples/s]Tokenizing train dataset:   8%|▊         | 671/8564 [00:07<01:14, 106.44 examples/s]Tokenizing train dataset:   8%|▊         | 684/8564 [00:07<01:11, 109.98 examples/s]Tokenizing train dataset:   8%|▊         | 698/8564 [00:07<01:21, 96.59 examples/s] Tokenizing train dataset:   8%|▊         | 710/8564 [00:07<01:18, 100.07 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:07<01:06, 118.05 examples/s]Tokenizing train dataset:   9%|▊         | 742/8564 [00:08<01:07, 116.09 examples/s]Tokenizing train dataset:   9%|▉         | 759/8564 [00:08<01:06, 118.22 examples/s]Tokenizing train dataset:   9%|▉         | 774/8564 [00:08<01:12, 108.01 examples/s]Tokenizing train dataset:   9%|▉         | 788/8564 [00:08<01:10, 110.01 examples/s]Tokenizing train dataset:   9%|▉         | 804/8564 [00:08<01:04, 120.14 examples/s]Tokenizing train dataset:  10%|▉         | 820/8564 [00:08<01:09, 110.82 examples/s]Tokenizing train dataset:  10%|▉         | 833/8564 [00:08<01:17, 100.33 examples/s]Tokenizing train dataset:  10%|▉         | 844/8564 [00:09<01:19, 97.41 examples/s] Tokenizing train dataset:  10%|█         | 861/8564 [00:09<01:09, 110.58 examples/s]Tokenizing train dataset:  10%|█         | 878/8564 [00:09<01:11, 107.04 examples/s]Tokenizing train dataset:  10%|█         | 894/8564 [00:09<01:04, 118.60 examples/s]Tokenizing train dataset:  11%|█         | 911/8564 [00:09<01:00, 127.52 examples/s]Tokenizing train dataset:  11%|█         | 927/8564 [00:09<01:05, 116.58 examples/s]Tokenizing train dataset:  11%|█         | 940/8564 [00:09<01:08, 111.09 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:09<01:08, 111.31 examples/s]Tokenizing train dataset:  11%|█▏        | 966/8564 [00:10<01:07, 112.82 examples/s]Tokenizing train dataset:  11%|█▏        | 978/8564 [00:10<01:08, 111.06 examples/s]Tokenizing train dataset:  12%|█▏        | 993/8564 [00:10<01:11, 105.38 examples/s]Tokenizing train dataset:  12%|█▏        | 1010/8564 [00:10<01:13, 103.14 examples/s]Tokenizing train dataset:  12%|█▏        | 1021/8564 [00:10<01:12, 103.68 examples/s]Tokenizing train dataset:  12%|█▏        | 1037/8564 [00:10<01:15, 99.64 examples/s] Tokenizing train dataset:  12%|█▏        | 1054/8564 [00:10<01:15, 99.30 examples/s]Tokenizing train dataset:  12%|█▏        | 1069/8564 [00:11<01:10, 106.80 examples/s]Tokenizing train dataset:  13%|█▎        | 1081/8564 [00:11<01:09, 107.54 examples/s]Tokenizing train dataset:  13%|█▎        | 1097/8564 [00:11<01:04, 115.87 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:11<01:07, 110.95 examples/s]Tokenizing train dataset:  13%|█▎        | 1124/8564 [00:11<01:12, 103.31 examples/s]Tokenizing train dataset:  13%|█▎        | 1137/8564 [00:11<01:16, 96.90 examples/s] Tokenizing train dataset:  13%|█▎        | 1150/8564 [00:11<01:11, 103.37 examples/s]Tokenizing train dataset:  14%|█▎        | 1161/8564 [00:11<01:14, 99.17 examples/s] Tokenizing train dataset:  14%|█▎        | 1173/8564 [00:12<01:14, 98.68 examples/s]Tokenizing train dataset:  14%|█▍        | 1189/8564 [00:12<01:05, 113.46 examples/s]Tokenizing train dataset:  14%|█▍        | 1201/8564 [00:12<01:04, 113.68 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:12<01:11, 103.02 examples/s]Tokenizing train dataset:  14%|█▍        | 1230/8564 [00:12<01:09, 105.48 examples/s]Tokenizing train dataset:  15%|█▍        | 1248/8564 [00:12<01:01, 119.25 examples/s]Tokenizing train dataset:  15%|█▍        | 1262/8564 [00:12<01:01, 118.61 examples/s]Tokenizing train dataset:  15%|█▍        | 1280/8564 [00:12<01:03, 114.32 examples/s]Tokenizing train dataset:  15%|█▌        | 1293/8564 [00:13<01:04, 112.45 examples/s]Tokenizing train dataset:  15%|█▌        | 1309/8564 [00:13<00:58, 123.02 examples/s]Tokenizing train dataset:  15%|█▌        | 1327/8564 [00:13<01:01, 116.84 examples/s]Tokenizing train dataset:  16%|█▌        | 1340/8564 [00:13<01:03, 113.99 examples/s]Tokenizing train dataset:  16%|█▌        | 1352/8564 [00:13<01:04, 112.30 examples/s]Tokenizing train dataset:  16%|█▌        | 1368/8564 [00:13<01:08, 105.28 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:13<01:10, 102.33 examples/s]Tokenizing train dataset:  16%|█▋        | 1399/8564 [00:14<01:12, 99.00 examples/s] Tokenizing train dataset:  16%|█▋        | 1410/8564 [00:14<01:11, 99.86 examples/s]Tokenizing train dataset:  17%|█▋        | 1425/8564 [00:14<01:15, 95.15 examples/s]Tokenizing train dataset:  17%|█▋        | 1435/8564 [00:14<01:14, 95.56 examples/s]Tokenizing train dataset:  17%|█▋        | 1448/8564 [00:14<01:09, 102.38 examples/s]Tokenizing train dataset:  17%|█▋        | 1461/8564 [00:14<01:15, 93.71 examples/s] Tokenizing train dataset:  17%|█▋        | 1476/8564 [00:14<01:06, 105.88 examples/s]Tokenizing train dataset:  17%|█▋        | 1492/8564 [00:15<01:09, 101.63 examples/s]Tokenizing train dataset:  18%|█▊        | 1504/8564 [00:15<01:09, 101.90 examples/s]Tokenizing train dataset:  18%|█▊        | 1517/8564 [00:15<01:13, 95.76 examples/s] Tokenizing train dataset:  18%|█▊        | 1536/8564 [00:15<01:02, 113.24 examples/s]Tokenizing train dataset:  18%|█▊        | 1548/8564 [00:15<01:03, 109.85 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:15<01:05, 107.61 examples/s]Tokenizing train dataset:  18%|█▊        | 1578/8564 [00:15<01:05, 105.90 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:15<01:05, 105.78 examples/s]Tokenizing train dataset:  19%|█▊        | 1601/8564 [00:16<01:07, 102.68 examples/s]Tokenizing train dataset:  19%|█▉        | 1617/8564 [00:16<01:02, 111.67 examples/s]Tokenizing train dataset:  19%|█▉        | 1630/8564 [00:16<01:00, 114.44 examples/s]Tokenizing train dataset:  19%|█▉        | 1644/8564 [00:16<01:00, 115.17 examples/s]Tokenizing train dataset:  19%|█▉        | 1658/8564 [00:16<00:59, 115.98 examples/s]Tokenizing train dataset:  20%|█▉        | 1670/8564 [00:16<00:59, 115.83 examples/s]Tokenizing train dataset:  20%|█▉        | 1686/8564 [00:16<00:56, 121.09 examples/s]Tokenizing train dataset:  20%|█▉        | 1705/8564 [00:16<00:49, 138.39 examples/s]Tokenizing train dataset:  20%|██        | 1721/8564 [00:17<00:54, 126.08 examples/s]Tokenizing train dataset:  20%|██        | 1734/8564 [00:17<00:56, 120.43 examples/s]Tokenizing train dataset:  20%|██        | 1748/8564 [00:17<00:54, 124.10 examples/s]Tokenizing train dataset:  21%|██        | 1761/8564 [00:17<00:54, 125.09 examples/s]Tokenizing train dataset:  21%|██        | 1779/8564 [00:17<00:58, 116.47 examples/s]Tokenizing train dataset:  21%|██        | 1798/8564 [00:17<00:58, 114.69 examples/s]Tokenizing train dataset:  21%|██        | 1810/8564 [00:17<00:59, 114.15 examples/s]Tokenizing train dataset:  21%|██▏       | 1827/8564 [00:17<01:03, 106.58 examples/s]Tokenizing train dataset:  21%|██▏       | 1841/8564 [00:18<01:00, 110.79 examples/s]Tokenizing train dataset:  22%|██▏       | 1853/8564 [00:18<00:59, 112.32 examples/s]Tokenizing train dataset:  22%|██▏       | 1865/8564 [00:18<01:00, 111.38 examples/s]Tokenizing train dataset:  22%|██▏       | 1881/8564 [00:18<01:03, 106.03 examples/s]Tokenizing train dataset:  22%|██▏       | 1897/8564 [00:18<00:58, 113.87 examples/s]Tokenizing train dataset:  22%|██▏       | 1917/8564 [00:18<00:50, 132.54 examples/s]Tokenizing train dataset:  23%|██▎       | 1932/8564 [00:18<00:48, 136.37 examples/s]Tokenizing train dataset:  23%|██▎       | 1951/8564 [00:18<00:50, 131.74 examples/s]Tokenizing train dataset:  23%|██▎       | 1969/8564 [00:19<00:52, 125.37 examples/s]Tokenizing train dataset:  23%|██▎       | 1990/8564 [00:19<00:53, 123.69 examples/s]Tokenizing train dataset:  23%|██▎       | 2007/8564 [00:19<00:51, 128.43 examples/s]Tokenizing train dataset:  24%|██▎       | 2025/8564 [00:19<00:53, 121.75 examples/s]Tokenizing train dataset:  24%|██▍       | 2040/8564 [00:19<00:51, 126.96 examples/s]Tokenizing train dataset:  24%|██▍       | 2058/8564 [00:19<00:48, 132.78 examples/s]Tokenizing train dataset:  24%|██▍       | 2077/8564 [00:19<00:50, 129.33 examples/s]Tokenizing train dataset:  24%|██▍       | 2091/8564 [00:20<00:49, 131.09 examples/s]Tokenizing train dataset:  25%|██▍       | 2111/8564 [00:20<00:49, 130.46 examples/s]Tokenizing train dataset:  25%|██▍       | 2128/8564 [00:20<00:47, 134.62 examples/s]Tokenizing train dataset:  25%|██▌       | 2142/8564 [00:20<00:49, 130.47 examples/s]Tokenizing train dataset:  25%|██▌       | 2162/8564 [00:20<00:50, 127.09 examples/s]Tokenizing train dataset:  25%|██▌       | 2176/8564 [00:20<00:50, 126.03 examples/s]Tokenizing train dataset:  26%|██▌       | 2190/8564 [00:20<00:49, 127.94 examples/s]Tokenizing train dataset:  26%|██▌       | 2210/8564 [00:20<00:51, 123.29 examples/s]Tokenizing train dataset:  26%|██▌       | 2226/8564 [00:21<00:48, 131.29 examples/s]Tokenizing train dataset:  26%|██▌       | 2240/8564 [00:21<00:47, 132.49 examples/s]Tokenizing train dataset:  26%|██▋       | 2254/8564 [00:21<00:47, 133.11 examples/s]Tokenizing train dataset:  26%|██▋       | 2269/8564 [00:21<00:46, 134.66 examples/s]Tokenizing train dataset:  27%|██▋       | 2285/8564 [00:21<00:44, 140.67 examples/s]Tokenizing train dataset:  27%|██▋       | 2303/8564 [00:21<00:43, 144.58 examples/s]Tokenizing train dataset:  27%|██▋       | 2318/8564 [00:21<00:49, 126.52 examples/s]Tokenizing train dataset:  27%|██▋       | 2332/8564 [00:21<00:48, 128.72 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:22<00:51, 119.83 examples/s]Tokenizing train dataset:  28%|██▊       | 2371/8564 [00:22<00:51, 121.26 examples/s]Tokenizing train dataset:  28%|██▊       | 2391/8564 [00:22<00:46, 134.08 examples/s]Tokenizing train dataset:  28%|██▊       | 2405/8564 [00:22<00:46, 133.42 examples/s]Tokenizing train dataset:  28%|██▊       | 2419/8564 [00:22<00:45, 134.19 examples/s]Tokenizing train dataset:  28%|██▊       | 2434/8564 [00:22<00:45, 135.02 examples/s]Tokenizing train dataset:  29%|██▊       | 2449/8564 [00:22<00:44, 136.37 examples/s]Tokenizing train dataset:  29%|██▉       | 2464/8564 [00:22<00:44, 137.35 examples/s]Tokenizing train dataset:  29%|██▉       | 2485/8564 [00:23<00:45, 133.76 examples/s]Tokenizing train dataset:  29%|██▉       | 2502/8564 [00:23<00:50, 121.05 examples/s]Tokenizing train dataset:  29%|██▉       | 2519/8564 [00:23<00:46, 130.08 examples/s]Tokenizing train dataset:  30%|██▉       | 2535/8564 [00:23<00:45, 132.74 examples/s]Tokenizing train dataset:  30%|██▉       | 2549/8564 [00:23<00:44, 134.43 examples/s]Tokenizing train dataset:  30%|██▉       | 2565/8564 [00:23<00:43, 138.82 examples/s]Tokenizing train dataset:  30%|███       | 2580/8564 [00:23<00:43, 137.44 examples/s]Tokenizing train dataset:  30%|███       | 2607/8564 [00:23<00:40, 147.79 examples/s]Tokenizing train dataset:  31%|███       | 2626/8564 [00:24<00:46, 127.12 examples/s]Tokenizing train dataset:  31%|███       | 2640/8564 [00:24<00:47, 124.46 examples/s]Tokenizing train dataset:  31%|███       | 2660/8564 [00:24<00:47, 125.48 examples/s]Tokenizing train dataset:  31%|███▏      | 2677/8564 [00:24<00:49, 118.03 examples/s]Tokenizing train dataset:  31%|███▏      | 2692/8564 [00:24<00:47, 122.60 examples/s]Tokenizing train dataset:  32%|███▏      | 2708/8564 [00:24<00:44, 130.96 examples/s]Tokenizing train dataset:  32%|███▏      | 2722/8564 [00:24<00:44, 131.63 examples/s]Tokenizing train dataset:  32%|███▏      | 2740/8564 [00:25<00:48, 119.47 examples/s]Tokenizing train dataset:  32%|███▏      | 2753/8564 [00:25<00:49, 116.66 examples/s]Tokenizing train dataset:  32%|███▏      | 2769/8564 [00:25<00:46, 124.03 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:25<00:45, 126.88 examples/s]Tokenizing train dataset:  33%|███▎      | 2802/8564 [00:25<00:44, 130.12 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:25<00:42, 136.21 examples/s]Tokenizing train dataset:  33%|███▎      | 2839/8564 [00:25<00:46, 123.66 examples/s]Tokenizing train dataset:  33%|███▎      | 2852/8564 [00:25<00:45, 124.50 examples/s]Tokenizing train dataset:  34%|███▎      | 2869/8564 [00:26<00:49, 115.62 examples/s]Tokenizing train dataset:  34%|███▎      | 2883/8564 [00:26<00:47, 119.62 examples/s]Tokenizing train dataset:  34%|███▍      | 2901/8564 [00:26<00:42, 133.46 examples/s]Tokenizing train dataset:  34%|███▍      | 2920/8564 [00:26<00:39, 142.09 examples/s]Tokenizing train dataset:  34%|███▍      | 2941/8564 [00:26<00:39, 140.58 examples/s]Tokenizing train dataset:  35%|███▍      | 2956/8564 [00:26<00:39, 142.54 examples/s]Tokenizing train dataset:  35%|███▍      | 2989/8564 [00:26<00:33, 168.34 examples/s]Tokenizing train dataset:  35%|███▌      | 3014/8564 [00:26<00:33, 163.58 examples/s]Tokenizing train dataset:  35%|███▌      | 3033/8564 [00:27<00:36, 150.44 examples/s]Tokenizing train dataset:  36%|███▌      | 3053/8564 [00:27<00:39, 140.73 examples/s]Tokenizing train dataset:  36%|███▌      | 3068/8564 [00:27<00:40, 136.22 examples/s]Tokenizing train dataset:  36%|███▌      | 3084/8564 [00:27<00:38, 140.75 examples/s]Tokenizing train dataset:  36%|███▌      | 3100/8564 [00:27<00:38, 143.56 examples/s]Tokenizing train dataset:  36%|███▋      | 3116/8564 [00:27<00:38, 141.00 examples/s]Tokenizing train dataset:  37%|███▋      | 3135/8564 [00:27<00:41, 131.05 examples/s]Tokenizing train dataset:  37%|███▋      | 3150/8564 [00:28<00:40, 133.76 examples/s]Tokenizing train dataset:  37%|███▋      | 3167/8564 [00:28<00:44, 120.81 examples/s]Tokenizing train dataset:  37%|███▋      | 3181/8564 [00:28<00:44, 120.96 examples/s]Tokenizing train dataset:  37%|███▋      | 3200/8564 [00:28<00:39, 136.80 examples/s]Tokenizing train dataset:  38%|███▊      | 3215/8564 [00:28<00:40, 131.14 examples/s]Tokenizing train dataset:  38%|███▊      | 3230/8564 [00:28<00:39, 133.92 examples/s]Tokenizing train dataset:  38%|███▊      | 3246/8564 [00:28<00:39, 133.29 examples/s]Tokenizing train dataset:  38%|███▊      | 3263/8564 [00:28<00:38, 136.11 examples/s]Tokenizing train dataset:  38%|███▊      | 3282/8564 [00:29<00:42, 123.65 examples/s]Tokenizing train dataset:  38%|███▊      | 3295/8564 [00:29<00:43, 121.54 examples/s]Tokenizing train dataset:  39%|███▊      | 3311/8564 [00:29<00:43, 120.66 examples/s]Tokenizing train dataset:  39%|███▉      | 3328/8564 [00:29<00:46, 112.68 examples/s]Tokenizing train dataset:  39%|███▉      | 3343/8564 [00:29<00:43, 120.45 examples/s]Tokenizing train dataset:  39%|███▉      | 3360/8564 [00:29<00:41, 126.66 examples/s]Tokenizing train dataset:  39%|███▉      | 3382/8564 [00:29<00:36, 140.55 examples/s]Tokenizing train dataset:  40%|███▉      | 3400/8564 [00:29<00:34, 149.44 examples/s]Tokenizing train dataset:  40%|███▉      | 3421/8564 [00:30<00:37, 138.53 examples/s]Tokenizing train dataset:  40%|████      | 3440/8564 [00:30<00:40, 127.72 examples/s]Tokenizing train dataset:  40%|████      | 3462/8564 [00:30<00:35, 145.04 examples/s]Tokenizing train dataset:  41%|████      | 3487/8564 [00:30<00:35, 143.55 examples/s]Tokenizing train dataset:  41%|████      | 3520/8564 [00:30<00:27, 181.02 examples/s]Tokenizing train dataset:  41%|████▏     | 3540/8564 [00:30<00:31, 158.99 examples/s]Tokenizing train dataset:  42%|████▏     | 3561/8564 [00:31<00:34, 146.61 examples/s]Tokenizing train dataset:  42%|████▏     | 3585/8564 [00:31<00:33, 149.06 examples/s]Tokenizing train dataset:  42%|████▏     | 3608/8564 [00:31<00:34, 144.13 examples/s]Tokenizing train dataset:  42%|████▏     | 3630/8564 [00:31<00:34, 141.33 examples/s]Tokenizing train dataset:  43%|████▎     | 3646/8564 [00:31<00:39, 123.94 examples/s]Tokenizing train dataset:  43%|████▎     | 3660/8564 [00:31<00:38, 126.63 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:32<00:41, 118.91 examples/s]Tokenizing train dataset:  43%|████▎     | 3695/8564 [00:32<00:39, 123.76 examples/s]Tokenizing train dataset:  43%|████▎     | 3708/8564 [00:32<00:41, 117.58 examples/s]Tokenizing train dataset:  44%|████▎     | 3727/8564 [00:32<00:37, 130.65 examples/s]Tokenizing train dataset:  44%|████▍     | 3749/8564 [00:32<00:36, 130.79 examples/s]Tokenizing train dataset:  44%|████▍     | 3764/8564 [00:32<00:36, 132.87 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:32<00:35, 133.33 examples/s]Tokenizing train dataset:  44%|████▍     | 3794/8564 [00:32<00:35, 133.76 examples/s]Tokenizing train dataset:  44%|████▍     | 3808/8564 [00:32<00:36, 130.37 examples/s]Tokenizing train dataset:  45%|████▍     | 3829/8564 [00:33<00:36, 128.68 examples/s]Tokenizing train dataset:  45%|████▍     | 3850/8564 [00:33<00:37, 126.24 examples/s]Tokenizing train dataset:  45%|████▌     | 3864/8564 [00:33<00:37, 126.50 examples/s]Tokenizing train dataset:  45%|████▌     | 3878/8564 [00:33<00:36, 129.18 examples/s]Tokenizing train dataset:  45%|████▌     | 3892/8564 [00:33<00:36, 127.10 examples/s]Tokenizing train dataset:  46%|████▌     | 3910/8564 [00:33<00:38, 120.99 examples/s]Tokenizing train dataset:  46%|████▌     | 3924/8564 [00:33<00:38, 121.76 examples/s]Tokenizing train dataset:  46%|████▌     | 3939/8564 [00:34<00:36, 127.72 examples/s]Tokenizing train dataset:  46%|████▌     | 3960/8564 [00:34<00:37, 124.34 examples/s]Tokenizing train dataset:  46%|████▋     | 3973/8564 [00:34<00:36, 124.66 examples/s]Tokenizing train dataset:  47%|████▋     | 3987/8564 [00:34<00:37, 120.63 examples/s]Tokenizing train dataset:  47%|████▋     | 4001/8564 [00:34<00:37, 121.02 examples/s]Tokenizing train dataset:  47%|████▋     | 4018/8564 [00:34<00:34, 131.56 examples/s]Tokenizing train dataset:  47%|████▋     | 4034/8564 [00:34<00:34, 132.52 examples/s]Tokenizing train dataset:  47%|████▋     | 4049/8564 [00:34<00:33, 136.70 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:34<00:34, 132.01 examples/s]Tokenizing train dataset:  48%|████▊     | 4078/8564 [00:35<00:33, 133.69 examples/s]Tokenizing train dataset:  48%|████▊     | 4094/8564 [00:35<00:38, 115.20 examples/s]Tokenizing train dataset:  48%|████▊     | 4112/8564 [00:35<00:35, 124.55 examples/s]Tokenizing train dataset:  48%|████▊     | 4127/8564 [00:35<00:35, 123.87 examples/s]Tokenizing train dataset:  48%|████▊     | 4145/8564 [00:35<00:36, 120.09 examples/s]Tokenizing train dataset:  49%|████▊     | 4159/8564 [00:35<00:36, 121.74 examples/s]Tokenizing train dataset:  49%|████▊     | 4172/8564 [00:35<00:35, 123.10 examples/s]Tokenizing train dataset:  49%|████▉     | 4190/8564 [00:36<00:33, 129.84 examples/s]Tokenizing train dataset:  49%|████▉     | 4207/8564 [00:36<00:31, 138.21 examples/s]Tokenizing train dataset:  49%|████▉     | 4228/8564 [00:36<00:33, 128.64 examples/s]Tokenizing train dataset:  50%|████▉     | 4245/8564 [00:36<00:35, 121.31 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:36<00:35, 122.36 examples/s]Tokenizing train dataset:  50%|████▉     | 4275/8564 [00:36<00:33, 128.58 examples/s]Tokenizing train dataset:  50%|█████     | 4290/8564 [00:36<00:33, 127.69 examples/s]Tokenizing train dataset:  50%|█████     | 4304/8564 [00:36<00:32, 129.88 examples/s]Tokenizing train dataset:  51%|█████     | 4325/8564 [00:37<00:33, 127.17 examples/s]Tokenizing train dataset:  51%|█████     | 4338/8564 [00:37<00:33, 125.45 examples/s]Tokenizing train dataset:  51%|█████     | 4351/8564 [00:37<00:34, 121.24 examples/s]Tokenizing train dataset:  51%|█████     | 4364/8564 [00:37<00:34, 122.94 examples/s]Tokenizing train dataset:  51%|█████     | 4380/8564 [00:37<00:31, 132.57 examples/s]Tokenizing train dataset:  51%|█████▏    | 4396/8564 [00:37<00:31, 134.45 examples/s]Tokenizing train dataset:  52%|█████▏    | 4416/8564 [00:37<00:31, 132.45 examples/s]Tokenizing train dataset:  52%|█████▏    | 4430/8564 [00:37<00:31, 132.04 examples/s]Tokenizing train dataset:  52%|█████▏    | 4446/8564 [00:37<00:31, 132.53 examples/s]Tokenizing train dataset:  52%|█████▏    | 4464/8564 [00:38<00:32, 127.02 examples/s]Tokenizing train dataset:  52%|█████▏    | 4480/8564 [00:38<00:31, 131.52 examples/s]Tokenizing train dataset:  53%|█████▎    | 4499/8564 [00:38<00:32, 126.21 examples/s]Tokenizing train dataset:  53%|█████▎    | 4519/8564 [00:38<00:34, 118.68 examples/s]Tokenizing train dataset:  53%|█████▎    | 4536/8564 [00:38<00:32, 122.48 examples/s]Tokenizing train dataset:  53%|█████▎    | 4553/8564 [00:38<00:30, 133.05 examples/s]Tokenizing train dataset:  53%|█████▎    | 4572/8564 [00:38<00:29, 136.60 examples/s]Tokenizing train dataset:  54%|█████▎    | 4587/8564 [00:39<00:32, 122.42 examples/s]Tokenizing train dataset:  54%|█████▎    | 4601/8564 [00:39<00:31, 125.28 examples/s]Tokenizing train dataset:  54%|█████▍    | 4616/8564 [00:39<00:32, 123.20 examples/s]Tokenizing train dataset:  54%|█████▍    | 4636/8564 [00:39<00:32, 119.66 examples/s]Tokenizing train dataset:  54%|█████▍    | 4652/8564 [00:39<00:30, 126.44 examples/s]Tokenizing train dataset:  55%|█████▍    | 4671/8564 [00:39<00:28, 138.79 examples/s]Tokenizing train dataset:  55%|█████▍    | 4687/8564 [00:39<00:27, 141.12 examples/s]Tokenizing train dataset:  55%|█████▍    | 4706/8564 [00:40<00:29, 131.32 examples/s]Tokenizing train dataset:  55%|█████▌    | 4725/8564 [00:40<00:27, 139.40 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:40<00:26, 144.57 examples/s]Tokenizing train dataset:  56%|█████▌    | 4761/8564 [00:40<00:32, 116.99 examples/s]Tokenizing train dataset:  56%|█████▌    | 4779/8564 [00:40<00:33, 113.40 examples/s]Tokenizing train dataset:  56%|█████▌    | 4793/8564 [00:40<00:31, 118.37 examples/s]Tokenizing train dataset:  56%|█████▌    | 4814/8564 [00:40<00:27, 138.10 examples/s]Tokenizing train dataset:  57%|█████▋    | 4847/8564 [00:40<00:20, 184.77 examples/s]Tokenizing train dataset:  57%|█████▋    | 4874/8564 [00:41<00:20, 179.94 examples/s]Tokenizing train dataset:  57%|█████▋    | 4896/8564 [00:41<00:19, 188.26 examples/s]Tokenizing train dataset:  57%|█████▋    | 4920/8564 [00:41<00:18, 199.91 examples/s]Tokenizing train dataset:  58%|█████▊    | 4943/8564 [00:41<00:17, 203.69 examples/s]Tokenizing train dataset:  58%|█████▊    | 4970/8564 [00:41<00:18, 193.49 examples/s]Tokenizing train dataset:  58%|█████▊    | 4997/8564 [00:41<00:16, 211.07 examples/s]Tokenizing train dataset:  59%|█████▊    | 5025/8564 [00:41<00:17, 199.47 examples/s]Tokenizing train dataset:  59%|█████▉    | 5050/8564 [00:41<00:16, 211.73 examples/s]Tokenizing train dataset:  59%|█████▉    | 5088/8564 [00:42<00:13, 249.29 examples/s]Tokenizing train dataset:  60%|█████▉    | 5125/8564 [00:42<00:13, 248.09 examples/s]Tokenizing train dataset:  60%|██████    | 5164/8564 [00:42<00:13, 244.16 examples/s]Tokenizing train dataset:  61%|██████    | 5190/8564 [00:42<00:13, 245.56 examples/s]Tokenizing train dataset:  61%|██████    | 5219/8564 [00:42<00:13, 255.09 examples/s]Tokenizing train dataset:  61%|██████▏   | 5260/8564 [00:42<00:12, 256.02 examples/s]Tokenizing train dataset:  62%|██████▏   | 5290/8564 [00:42<00:12, 257.84 examples/s]Tokenizing train dataset:  62%|██████▏   | 5325/8564 [00:43<00:13, 238.80 examples/s]Tokenizing train dataset:  62%|██████▏   | 5350/8564 [00:43<00:13, 239.17 examples/s]Tokenizing train dataset:  63%|██████▎   | 5375/8564 [00:43<00:15, 210.42 examples/s]Tokenizing train dataset:  63%|██████▎   | 5404/8564 [00:43<00:15, 200.28 examples/s]Tokenizing train dataset:  64%|██████▎   | 5443/8564 [00:43<00:12, 241.85 examples/s]Tokenizing train dataset:  64%|██████▍   | 5470/8564 [00:43<00:12, 243.96 examples/s]Tokenizing train dataset:  64%|██████▍   | 5505/8564 [00:43<00:12, 236.19 examples/s]Tokenizing train dataset:  65%|██████▍   | 5537/8564 [00:43<00:13, 228.14 examples/s]Tokenizing train dataset:  65%|██████▍   | 5564/8564 [00:44<00:13, 227.17 examples/s]Tokenizing train dataset:  65%|██████▌   | 5589/8564 [00:44<00:12, 229.04 examples/s]Tokenizing train dataset:  66%|██████▌   | 5616/8564 [00:44<00:12, 237.35 examples/s]Tokenizing train dataset:  66%|██████▌   | 5645/8564 [00:44<00:12, 228.59 examples/s]Tokenizing train dataset:  66%|██████▋   | 5680/8564 [00:44<00:11, 257.97 examples/s]Tokenizing train dataset:  67%|██████▋   | 5710/8564 [00:44<00:11, 256.53 examples/s]Tokenizing train dataset:  67%|██████▋   | 5742/8564 [00:44<00:12, 229.80 examples/s]Tokenizing train dataset:  67%|██████▋   | 5775/8564 [00:44<00:11, 251.05 examples/s]Tokenizing train dataset:  68%|██████▊   | 5816/8564 [00:45<00:10, 256.68 examples/s]Tokenizing train dataset:  68%|██████▊   | 5846/8564 [00:45<00:11, 229.07 examples/s]Tokenizing train dataset:  69%|██████▊   | 5870/8564 [00:45<00:13, 196.30 examples/s]Tokenizing train dataset:  69%|██████▉   | 5892/8564 [00:45<00:13, 198.14 examples/s]Tokenizing train dataset:  69%|██████▉   | 5922/8564 [00:45<00:11, 220.78 examples/s]Tokenizing train dataset:  69%|██████▉   | 5946/8564 [00:45<00:12, 217.76 examples/s]Tokenizing train dataset:  70%|██████▉   | 5977/8564 [00:45<00:11, 232.09 examples/s]Tokenizing train dataset:  70%|███████   | 6005/8564 [00:46<00:16, 151.77 examples/s]Tokenizing train dataset:  70%|███████   | 6025/8564 [00:46<00:15, 160.12 examples/s]Tokenizing train dataset:  71%|███████   | 6047/8564 [00:46<00:14, 171.68 examples/s]Tokenizing train dataset:  71%|███████   | 6070/8564 [00:46<00:13, 183.90 examples/s]Tokenizing train dataset:  71%|███████   | 6100/8564 [00:46<00:13, 182.38 examples/s]Tokenizing train dataset:  72%|███████▏  | 6124/8564 [00:46<00:12, 193.39 examples/s]Tokenizing train dataset:  72%|███████▏  | 6158/8564 [00:46<00:10, 226.01 examples/s]Tokenizing train dataset:  72%|███████▏  | 6187/8564 [00:47<00:10, 223.76 examples/s]Tokenizing train dataset:  73%|███████▎  | 6221/8564 [00:47<00:09, 245.18 examples/s]Tokenizing train dataset:  73%|███████▎  | 6261/8564 [00:47<00:09, 245.24 examples/s]Tokenizing train dataset:  73%|███████▎  | 6294/8564 [00:47<00:09, 235.29 examples/s]Tokenizing train dataset:  74%|███████▍  | 6320/8564 [00:47<00:09, 239.02 examples/s]Tokenizing train dataset:  74%|███████▍  | 6360/8564 [00:47<00:09, 242.03 examples/s]Tokenizing train dataset:  75%|███████▍  | 6388/8564 [00:47<00:08, 249.95 examples/s]Tokenizing train dataset:  75%|███████▌  | 6425/8564 [00:48<00:09, 230.59 examples/s]Tokenizing train dataset:  75%|███████▌  | 6451/8564 [00:48<00:08, 234.92 examples/s]Tokenizing train dataset:  76%|███████▌  | 6483/8564 [00:48<00:09, 220.16 examples/s]Tokenizing train dataset:  76%|███████▌  | 6512/8564 [00:48<00:09, 206.73 examples/s]Tokenizing train dataset:  76%|███████▋  | 6535/8564 [00:48<00:09, 208.80 examples/s]Tokenizing train dataset:  77%|███████▋  | 6560/8564 [00:48<00:09, 213.61 examples/s]Tokenizing train dataset:  77%|███████▋  | 6590/8564 [00:48<00:09, 198.16 examples/s]Tokenizing train dataset:  77%|███████▋  | 6619/8564 [00:49<00:10, 188.66 examples/s]Tokenizing train dataset:  78%|███████▊  | 6644/8564 [00:49<00:09, 198.87 examples/s]Tokenizing train dataset:  78%|███████▊  | 6678/8564 [00:49<00:09, 204.56 examples/s]Tokenizing train dataset:  78%|███████▊  | 6708/8564 [00:49<00:08, 225.85 examples/s]Tokenizing train dataset:  79%|███████▊  | 6742/8564 [00:49<00:08, 216.71 examples/s]Tokenizing train dataset:  79%|███████▉  | 6771/8564 [00:49<00:07, 227.78 examples/s]Tokenizing train dataset:  79%|███████▉  | 6804/8564 [00:49<00:08, 219.89 examples/s]Tokenizing train dataset:  80%|███████▉  | 6834/8564 [00:49<00:08, 208.84 examples/s]Tokenizing train dataset:  80%|████████  | 6867/8564 [00:50<00:08, 208.84 examples/s]Tokenizing train dataset:  80%|████████  | 6893/8564 [00:50<00:07, 214.59 examples/s]Tokenizing train dataset:  81%|████████  | 6919/8564 [00:50<00:07, 215.52 examples/s]Tokenizing train dataset:  81%|████████  | 6955/8564 [00:50<00:06, 243.52 examples/s]Tokenizing train dataset:  82%|████████▏ | 6989/8564 [00:50<00:06, 233.56 examples/s]Tokenizing train dataset:  82%|████████▏ | 7014/8564 [00:50<00:07, 210.34 examples/s]Tokenizing train dataset:  82%|████████▏ | 7046/8564 [00:50<00:07, 207.92 examples/s]Tokenizing train dataset:  83%|████████▎ | 7078/8564 [00:51<00:06, 225.76 examples/s]Tokenizing train dataset:  83%|████████▎ | 7102/8564 [00:51<00:06, 222.02 examples/s]Tokenizing train dataset:  83%|████████▎ | 7128/8564 [00:51<00:06, 228.33 examples/s]Tokenizing train dataset:  84%|████████▎ | 7160/8564 [00:51<00:06, 208.29 examples/s]Tokenizing train dataset:  84%|████████▍ | 7188/8564 [00:51<00:06, 224.32 examples/s]Tokenizing train dataset:  84%|████████▍ | 7214/8564 [00:51<00:06, 221.40 examples/s]Tokenizing train dataset:  85%|████████▍ | 7239/8564 [00:51<00:06, 202.36 examples/s]Tokenizing train dataset:  85%|████████▍ | 7270/8564 [00:51<00:06, 202.06 examples/s]Tokenizing train dataset:  85%|████████▌ | 7302/8564 [00:52<00:06, 203.62 examples/s]Tokenizing train dataset:  86%|████████▌ | 7324/8564 [00:52<00:06, 204.27 examples/s]Tokenizing train dataset:  86%|████████▌ | 7350/8564 [00:52<00:05, 215.56 examples/s]Tokenizing train dataset:  86%|████████▌ | 7375/8564 [00:52<00:05, 222.49 examples/s]Tokenizing train dataset:  87%|████████▋ | 7408/8564 [00:52<00:05, 214.27 examples/s]Tokenizing train dataset:  87%|████████▋ | 7439/8564 [00:52<00:04, 228.44 examples/s]Tokenizing train dataset:  87%|████████▋ | 7464/8564 [00:52<00:04, 231.74 examples/s]Tokenizing train dataset:  88%|████████▊ | 7499/8564 [00:52<00:04, 230.41 examples/s]Tokenizing train dataset:  88%|████████▊ | 7525/8564 [00:53<00:04, 228.64 examples/s]Tokenizing train dataset:  88%|████████▊ | 7551/8564 [00:53<00:04, 234.49 examples/s]Tokenizing train dataset:  89%|████████▊ | 7580/8564 [00:53<00:03, 248.13 examples/s]Tokenizing train dataset:  89%|████████▉ | 7612/8564 [00:53<00:04, 224.60 examples/s]Tokenizing train dataset:  89%|████████▉ | 7637/8564 [00:53<00:04, 224.85 examples/s]Tokenizing train dataset:  89%|████████▉ | 7664/8564 [00:53<00:04, 201.45 examples/s]Tokenizing train dataset:  90%|████████▉ | 7690/8564 [00:53<00:04, 205.56 examples/s]Tokenizing train dataset:  90%|█████████ | 7713/8564 [00:53<00:04, 210.28 examples/s]Tokenizing train dataset:  90%|█████████ | 7744/8564 [00:54<00:03, 207.68 examples/s]Tokenizing train dataset:  91%|█████████ | 7770/8564 [00:54<00:04, 189.94 examples/s]Tokenizing train dataset:  91%|█████████ | 7790/8564 [00:54<00:04, 188.86 examples/s]Tokenizing train dataset:  91%|█████████ | 7813/8564 [00:54<00:03, 197.64 examples/s]Tokenizing train dataset:  92%|█████████▏| 7839/8564 [00:54<00:03, 199.01 examples/s]Tokenizing train dataset:  92%|█████████▏| 7863/8564 [00:54<00:03, 207.50 examples/s]Tokenizing train dataset:  92%|█████████▏| 7886/8564 [00:54<00:03, 210.20 examples/s]Tokenizing train dataset:  93%|█████████▎| 7923/8564 [00:54<00:02, 243.91 examples/s]Tokenizing train dataset:  93%|█████████▎| 7960/8564 [00:55<00:02, 239.75 examples/s]Tokenizing train dataset:  93%|█████████▎| 7990/8564 [00:55<00:02, 254.63 examples/s]Tokenizing train dataset:  94%|█████████▎| 8017/8564 [00:55<00:02, 257.98 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [00:55<00:02, 230.26 examples/s]Tokenizing train dataset:  94%|█████████▍| 8076/8564 [00:55<00:02, 210.73 examples/s]Tokenizing train dataset:  95%|█████████▍| 8109/8564 [00:55<00:02, 209.16 examples/s]Tokenizing train dataset:  95%|█████████▍| 8133/8564 [00:55<00:02, 211.14 examples/s]Tokenizing train dataset:  95%|█████████▌| 8174/8564 [00:56<00:01, 252.58 examples/s]Tokenizing train dataset:  96%|█████████▌| 8205/8564 [00:56<00:01, 235.65 examples/s]Tokenizing train dataset:  96%|█████████▌| 8239/8564 [00:56<00:01, 260.38 examples/s]Tokenizing train dataset:  97%|█████████▋| 8297/8564 [00:56<00:00, 331.00 examples/s]Tokenizing train dataset:  97%|█████████▋| 8340/8564 [00:56<00:00, 304.99 examples/s]Tokenizing train dataset:  98%|█████████▊| 8373/8564 [00:56<00:00, 269.53 examples/s]Tokenizing train dataset:  98%|█████████▊| 8411/8564 [00:56<00:00, 260.65 examples/s]Tokenizing train dataset:  99%|█████████▊| 8445/8564 [00:57<00:00, 241.86 examples/s]Tokenizing train dataset:  99%|█████████▉| 8484/8564 [00:57<00:00, 245.54 examples/s]Tokenizing train dataset:  99%|█████████▉| 8517/8564 [00:57<00:00, 235.43 examples/s]Tokenizing train dataset: 100%|█████████▉| 8549/8564 [00:57<00:00, 222.36 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:57<00:00, 148.61 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  63%|██████▎   | 601/953 [00:00<00:00, 5926.15 examples/s]Extracting prompt in train dataset:   0%|          | 10/8564 [00:00<01:31, 92.99 examples/s]Extracting prompt in train dataset:   0%|          | 10/8564 [00:00<01:33, 91.15 examples/s]Extracting prompt in train dataset:   0%|          | 10/8564 [00:00<01:40, 85.13 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 5821.60 examples/s]
Extracting prompt in train dataset:   1%|          | 105/8564 [00:00<00:14, 576.19 examples/s]Extracting prompt in train dataset:   1%|▏         | 110/8564 [00:00<00:15, 560.59 examples/s]Extracting prompt in train dataset:   1%|▏         | 110/8564 [00:00<00:15, 547.95 examples/s]Extracting prompt in train dataset:   2%|▏         | 200/8564 [00:00<00:11, 733.66 examples/s]Extracting prompt in train dataset:   3%|▎         | 227/8564 [00:00<00:10, 807.25 examples/s]Extracting prompt in train dataset:   2%|▏         | 197/8564 [00:00<00:12, 679.58 examples/s]Extracting prompt in train dataset:   4%|▎         | 310/8564 [00:00<00:09, 866.30 examples/s]Extracting prompt in train dataset:   4%|▍         | 338/8564 [00:00<00:09, 895.02 examples/s]Extracting prompt in train dataset:   4%|▍         | 341/8564 [00:00<00:08, 947.29 examples/s]Extracting prompt in train dataset:   5%|▌         | 431/8564 [00:00<00:09, 891.56 examples/s]Extracting prompt in train dataset:   5%|▌         | 440/8564 [00:00<00:09, 871.88 examples/s]Extracting prompt in train dataset:   6%|▌         | 483/8564 [00:00<00:08, 914.49 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   6%|▋         | 545/8564 [00:00<00:08, 933.52 examples/s]Extracting prompt in train dataset:   7%|▋         | 560/8564 [00:00<00:08, 949.98 examples/s]Extracting prompt in train dataset:   7%|▋         | 596/8564 [00:00<00:08, 960.49 examples/s]Applying chat template to eval dataset:  83%|████████▎ | 790/953 [00:00<00:00, 7829.69 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 7751.46 examples/s]
Extracting prompt in train dataset:   8%|▊         | 668/8564 [00:00<00:07, 1006.17 examples/s]Extracting prompt in train dataset:   8%|▊         | 670/8564 [00:00<00:08, 951.20 examples/s]Extracting prompt in train dataset:   9%|▉         | 775/8564 [00:00<00:07, 1019.45 examples/s]Extracting prompt in train dataset:   9%|▊         | 730/8564 [00:00<00:08, 892.89 examples/s]Extracting prompt in train dataset:   9%|▉         | 770/8564 [00:00<00:08, 959.24 examples/s]Extracting prompt in train dataset:  11%|█         | 900/8564 [00:00<00:07, 1073.89 examples/s]Extracting prompt in train dataset:  10%|█         | 870/8564 [00:00<00:07, 1007.32 examples/s]Extracting prompt in train dataset:  10%|█         | 880/8564 [00:00<00:07, 992.39 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1010/8564 [00:01<00:07, 1077.54 examples/s]Extracting prompt in train dataset:  11%|█▏        | 980/8564 [00:01<00:07, 1024.41 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1020/8564 [00:01<00:06, 1104.67 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1126/8564 [00:01<00:06, 1096.92 examples/s]Extracting prompt in train dataset:  14%|█▎        | 1166/8564 [00:01<00:06, 1196.94 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1128/8564 [00:01<00:07, 988.83 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  15%|█▍        | 1280/8564 [00:01<00:05, 1216.75 examples/s]Extracting prompt in train dataset:  15%|█▍        | 1269/8564 [00:01<00:06, 1093.33 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1350/8564 [00:01<00:06, 1169.78 examples/s]Tokenizing eval dataset:   2%|▏         | 21/953 [00:00<00:04, 193.20 examples/s]Extracting prompt in train dataset:  16%|█▋        | 1410/8564 [00:01<00:06, 1163.65 examples/s]Tokenizing eval dataset:   5%|▍         | 43/953 [00:00<00:04, 200.49 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1420/8564 [00:01<00:08, 800.27 examples/s] Extracting prompt in train dataset:  17%|█▋        | 1496/8564 [00:01<00:07, 894.34 examples/s] Tokenizing eval dataset:   7%|▋         | 71/953 [00:00<00:04, 189.35 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1555/8564 [00:01<00:07, 909.38 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1620/8564 [00:01<00:07, 961.75 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1542/8564 [00:01<00:08, 812.30 examples/s] Extracting prompt in train dataset:  20%|██        | 1720/8564 [00:01<00:06, 1073.70 examples/s]Tokenizing eval dataset:  10%|█         | 97/953 [00:00<00:04, 178.30 examples/s]Extracting prompt in train dataset:  21%|██        | 1779/8564 [00:01<00:06, 1093.53 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1689/8564 [00:01<00:08, 836.13 examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:00<00:04, 177.64 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1870/8564 [00:01<00:06, 1039.26 examples/s]Extracting prompt in train dataset:  23%|██▎       | 1960/8564 [00:01<00:05, 1112.06 examples/s]Extracting prompt in train dataset:  21%|██        | 1814/8564 [00:01<00:07, 916.09 examples/s]Tokenizing eval dataset:  15%|█▌        | 143/953 [00:00<00:04, 171.11 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2080/8564 [00:02<00:05, 1097.01 examples/s]Extracting prompt in train dataset:  24%|██▎       | 2030/8564 [00:02<00:06, 1035.59 examples/s]Extracting prompt in train dataset:  22%|██▏       | 1920/8564 [00:02<00:07, 942.79 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2040/8564 [00:02<00:06, 991.64 examples/s]Tokenizing eval dataset:  18%|█▊        | 167/953 [00:00<00:04, 162.90 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2241/8564 [00:02<00:05, 1077.88 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2213/8564 [00:02<00:05, 1087.20 examples/s]Extracting prompt in train dataset:  25%|██▌       | 2168/8564 [00:02<00:06, 1042.69 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2380/8564 [00:02<00:05, 1211.76 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:05, 146.65 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2380/8564 [00:02<00:06, 1016.49 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2280/8564 [00:02<00:05, 1051.31 examples/s]Extracting prompt in train dataset:  30%|██▉       | 2560/8564 [00:02<00:04, 1329.85 examples/s]Extracting prompt in train dataset:  30%|███       | 2575/8564 [00:02<00:04, 1218.67 examples/s]Tokenizing eval dataset:  22%|██▏       | 209/953 [00:01<00:05, 145.28 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2737/8564 [00:02<00:04, 1424.26 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2706/8564 [00:02<00:04, 1220.93 examples/s]Extracting prompt in train dataset:  29%|██▊       | 2448/8564 [00:02<00:06, 929.37 examples/s] Tokenizing eval dataset:  25%|██▍       | 235/953 [00:01<00:04, 168.27 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2863/8564 [00:02<00:04, 1309.66 examples/s]Extracting prompt in train dataset:  31%|███       | 2618/8564 [00:02<00:05, 1094.89 examples/s]Tokenizing eval dataset:  28%|██▊       | 266/953 [00:01<00:03, 201.80 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2930/8564 [00:02<00:04, 1183.15 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2777/8564 [00:02<00:04, 1214.15 examples/s]Extracting prompt in train dataset:  35%|███▌      | 3000/8564 [00:02<00:04, 1125.72 examples/s]Tokenizing eval dataset:  32%|███▏      | 303/953 [00:01<00:02, 237.70 examples/s]Extracting prompt in train dataset:  36%|███▌      | 3100/8564 [00:02<00:04, 1101.18 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:01<00:02, 266.58 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3130/8564 [00:03<00:05, 1061.84 examples/s]Extracting prompt in train dataset:  34%|███▍      | 2913/8564 [00:03<00:05, 968.40 examples/s] Extracting prompt in train dataset:  38%|███▊      | 3290/8564 [00:03<00:04, 1267.61 examples/s]Tokenizing eval dataset:  39%|███▊      | 368/953 [00:01<00:02, 267.06 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3284/8564 [00:03<00:04, 1174.00 examples/s]Extracting prompt in train dataset:  40%|████      | 3465/8564 [00:03<00:03, 1376.44 examples/s]Tokenizing eval dataset:  42%|████▏     | 400/953 [00:01<00:01, 278.05 examples/s]Extracting prompt in train dataset:  40%|████      | 3460/8564 [00:03<00:03, 1315.23 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3631/8564 [00:03<00:03, 1442.08 examples/s]Extracting prompt in train dataset:  35%|███▌      | 3034/8564 [00:03<00:06, 801.19 examples/s]Tokenizing eval dataset:  45%|████▌     | 430/953 [00:02<00:01, 275.24 examples/s]Extracting prompt in train dataset:  42%|████▏     | 3632/8564 [00:03<00:03, 1412.44 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3805/8564 [00:03<00:03, 1506.21 examples/s]Tokenizing eval dataset:  49%|████▉     | 467/953 [00:02<00:01, 297.88 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3190/8564 [00:03<00:06, 845.14 examples/s]Extracting prompt in train dataset:  46%|████▋     | 3968/8564 [00:03<00:03, 1530.10 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3370/8564 [00:03<00:05, 1029.69 examples/s]Tokenizing eval dataset:  54%|█████▍    | 515/953 [00:02<00:01, 302.40 examples/s]Extracting prompt in train dataset:  44%|████▍     | 3781/8564 [00:03<00:04, 980.71 examples/s] Extracting prompt in train dataset:  49%|████▉     | 4203/8564 [00:03<00:02, 1536.89 examples/s]Extracting prompt in train dataset:  41%|████▏     | 3550/8564 [00:03<00:04, 1194.89 examples/s]Tokenizing eval dataset:  58%|█████▊    | 550/953 [00:02<00:01, 312.99 examples/s]Extracting prompt in train dataset:  51%|█████     | 4377/8564 [00:03<00:02, 1587.97 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3713/8564 [00:03<00:03, 1281.87 examples/s]Tokenizing eval dataset:  61%|██████▏   | 585/953 [00:02<00:01, 319.22 examples/s]Extracting prompt in train dataset:  46%|████▌     | 3946/8564 [00:03<00:05, 828.99 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3868/8564 [00:03<00:03, 1312.89 examples/s]Tokenizing eval dataset:  65%|██████▌   | 620/953 [00:02<00:01, 324.74 examples/s]Extracting prompt in train dataset:  54%|█████▎    | 4590/8564 [00:03<00:02, 1499.74 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4055/8564 [00:03<00:05, 875.55 examples/s]Tokenizing eval dataset:  69%|██████▉   | 657/953 [00:02<00:00, 336.37 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4040/8564 [00:04<00:03, 1224.79 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4780/8564 [00:04<00:02, 1412.34 examples/s]Extracting prompt in train dataset:  49%|████▊     | 4167/8564 [00:04<00:04, 924.50 examples/s]Tokenizing eval dataset:  73%|███████▎  | 695/953 [00:02<00:00, 346.79 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4277/8564 [00:04<00:04, 958.70 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4214/8564 [00:04<00:03, 1195.38 examples/s]Extracting prompt in train dataset:  58%|█████▊    | 4960/8564 [00:04<00:02, 1331.14 examples/s]Tokenizing eval dataset:  78%|███████▊  | 741/953 [00:02<00:00, 328.32 examples/s]Extracting prompt in train dataset:  51%|█████     | 4340/8564 [00:04<00:03, 1203.48 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 5131/8564 [00:04<00:02, 1369.89 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4414/8564 [00:04<00:04, 925.43 examples/s]Tokenizing eval dataset:  82%|████████▏ | 777/953 [00:03<00:00, 329.56 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5280/8564 [00:04<00:02, 1360.82 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4521/8564 [00:04<00:04, 951.31 examples/s]Extracting prompt in train dataset:  53%|█████▎    | 4527/8564 [00:04<00:03, 1206.92 examples/s]Tokenizing eval dataset:  86%|████████▋ | 824/953 [00:03<00:00, 316.60 examples/s]Extracting prompt in train dataset:  64%|██████▎   | 5440/8564 [00:04<00:02, 1395.58 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 4646/8564 [00:04<00:03, 1011.68 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 5601/8564 [00:04<00:02, 1417.07 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 4704/8564 [00:04<00:03, 1077.49 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4760/8564 [00:04<00:03, 1032.82 examples/s]Tokenizing eval dataset:  91%|█████████ | 864/953 [00:03<00:00, 295.69 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5834/8564 [00:04<00:01, 1659.22 examples/s]Extracting prompt in train dataset:  56%|█████▋    | 4836/8564 [00:04<00:03, 1127.31 examples/s]Tokenizing eval dataset:  95%|█████████▌| 906/953 [00:03<00:00, 286.39 examples/s]Extracting prompt in train dataset:  70%|███████   | 6010/8564 [00:04<00:01, 1666.48 examples/s]Extracting prompt in train dataset:  59%|█████▊    | 5015/8564 [00:04<00:02, 1273.97 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4872/8564 [00:04<00:04, 794.09 examples/s] Extracting prompt in train dataset:  61%|██████    | 5200/8564 [00:04<00:02, 1375.52 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 5040/8564 [00:04<00:03, 990.40 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:03<00:00, 265.13 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 254.53 examples/s]
Extracting prompt in train dataset:  63%|██████▎   | 5360/8564 [00:05<00:02, 1421.60 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6206/8564 [00:05<00:01, 1307.25 examples/s]Extracting prompt in train dataset:  61%|██████    | 5203/8564 [00:05<00:02, 1139.16 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6380/8564 [00:05<00:01, 1396.38 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5530/8564 [00:05<00:02, 1296.88 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5350/8564 [00:05<00:03, 1061.86 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5547/8564 [00:05<00:02, 1268.26 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5700/8564 [00:05<00:02, 1230.71 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 6537/8564 [00:05<00:01, 1113.53 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 5730/8564 [00:05<00:02, 1215.87 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5860/8564 [00:05<00:02, 1159.59 examples/s]Extracting prompt in train dataset:  79%|███████▊  | 6733/8564 [00:05<00:01, 1157.22 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5989/8564 [00:05<00:02, 1187.64 examples/s]Extracting prompt in train dataset:  80%|████████  | 6886/8564 [00:05<00:01, 1173.37 examples/s]Extracting prompt in train dataset:  69%|██████▊   | 5870/8564 [00:05<00:02, 991.07 examples/s] Extracting prompt in train dataset:  71%|███████▏  | 6120/8564 [00:05<00:02, 1200.28 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 7050/8564 [00:05<00:01, 1187.12 examples/s]Extracting prompt in train dataset:  71%|███████   | 6053/8564 [00:05<00:02, 1163.36 examples/s]Extracting prompt in train dataset:  84%|████████▍ | 7197/8564 [00:05<00:01, 1109.78 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6360/8564 [00:05<00:01, 1123.21 examples/s]Extracting prompt in train dataset:  73%|███████▎  | 6220/8564 [00:05<00:02, 1104.52 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7327/8564 [00:06<00:01, 1141.55 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 6500/8564 [00:06<00:01, 1168.12 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7471/8564 [00:06<00:00, 1183.26 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6640/8564 [00:06<00:01, 1207.50 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6380/8564 [00:06<00:02, 874.08 examples/s] Extracting prompt in train dataset:  89%|████████▉ | 7631/8564 [00:06<00:00, 1112.89 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6808/8564 [00:06<00:01, 1151.60 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6573/8564 [00:06<00:01, 1068.60 examples/s]Extracting prompt in train dataset:  81%|████████▏ | 6966/8564 [00:06<00:01, 1096.11 examples/s]Extracting prompt in train dataset:  80%|████████  | 6854/8564 [00:06<00:01, 1129.74 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7102/8564 [00:06<00:01, 1009.83 examples/s]Extracting prompt in train dataset:  91%|█████████ | 7803/8564 [00:06<00:00, 805.02 examples/s] Extracting prompt in train dataset:  82%|████████▏ | 7006/8564 [00:06<00:01, 1168.21 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7290/8564 [00:06<00:01, 1195.57 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8041/8564 [00:06<00:00, 970.83 examples/s]Extracting prompt in train dataset:  84%|████████▎ | 7161/8564 [00:06<00:01, 1089.50 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 8192/8564 [00:06<00:00, 1052.99 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7432/8564 [00:06<00:01, 995.32 examples/s] Extracting prompt in train dataset:  85%|████████▌ | 7286/8564 [00:06<00:01, 1082.17 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8333/8564 [00:07<00:00, 1063.51 examples/s]Extracting prompt in train dataset:  89%|████████▉ | 7660/8564 [00:07<00:00, 1250.89 examples/s]Extracting prompt in train dataset:  86%|████████▋ | 7400/8564 [00:07<00:01, 954.14 examples/s] Extracting prompt in train dataset:  99%|█████████▉| 8478/8564 [00:07<00:00, 1131.65 examples/s]Extracting prompt in train dataset:  89%|████████▊ | 7594/8564 [00:07<00:00, 1146.95 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:07<00:00, 1169.74 examples/s]
Extracting prompt in train dataset:  91%|█████████ | 7804/8564 [00:07<00:00, 932.88 examples/s] Extracting prompt in train dataset:  90%|█████████ | 7723/8564 [00:07<00:00, 1045.58 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 8009/8564 [00:07<00:00, 1143.79 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 7938/8564 [00:07<00:00, 1041.08 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 8180/8564 [00:07<00:00, 1070.64 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8386/8564 [00:07<00:00, 1269.94 examples/s]Extracting prompt in train dataset:  94%|█████████▍| 8070/8564 [00:07<00:00, 1054.82 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 8200/8564 [00:07<00:00, 1098.97 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:07<00:00, 1302.19 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:07<00:00, 1082.27 examples/s]
Extracting prompt in train dataset:  97%|█████████▋| 8340/8564 [00:07<00:00, 1162.21 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8512/8564 [00:08<00:00, 1268.75 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:08<00:00, 1051.63 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   1%|          | 80/8564 [00:00<00:15, 535.39 examples/s]Applying chat template to train dataset:   2%|▏         | 174/8564 [00:00<00:11, 732.79 examples/s]Applying chat template to train dataset:   3%|▎         | 276/8564 [00:00<00:10, 788.84 examples/s]Applying chat template to train dataset:   4%|▍         | 370/8564 [00:00<00:11, 713.82 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   5%|▌         | 466/8564 [00:00<00:12, 661.51 examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:00<15:08,  9.42 examples/s]Applying chat template to train dataset:   7%|▋         | 590/8564 [00:00<00:10, 757.49 examples/s]Applying chat template to train dataset:   1%|          | 100/8564 [00:00<00:18, 468.50 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   2%|▏         | 190/8564 [00:00<00:13, 602.62 examples/s]Applying chat template to train dataset:   8%|▊         | 692/8564 [00:01<00:11, 664.87 examples/s]Applying chat template to train dataset:   4%|▍         | 328/8564 [00:00<00:09, 825.05 examples/s]Applying chat template to train dataset:  10%|▉         | 851/8564 [00:01<00:08, 875.36 examples/s]Applying chat template to train dataset:   0%|          | 1/8564 [00:00<36:28,  3.91 examples/s]Applying chat template to train dataset:   5%|▍         | 410/8564 [00:00<00:10, 795.12 examples/s]Applying chat template to train dataset:  11%|█▏        | 975/8564 [00:01<00:08, 938.73 examples/s]Applying chat template to train dataset:   1%|          | 84/8564 [00:00<00:28, 299.51 examples/s]Applying chat template to train dataset:   6%|▌         | 510/8564 [00:00<00:09, 846.09 examples/s]Applying chat template to train dataset:  13%|█▎        | 1085/8564 [00:01<00:07, 978.71 examples/s]Applying chat template to train dataset:   2%|▏         | 190/8564 [00:00<00:18, 453.06 examples/s]Applying chat template to train dataset:   7%|▋         | 596/8564 [00:00<00:09, 826.92 examples/s]Applying chat template to train dataset:  14%|█▍        | 1207/8564 [00:01<00:07, 1002.84 examples/s]Applying chat template to train dataset:   4%|▎         | 312/8564 [00:00<00:12, 651.30 examples/s]Applying chat template to train dataset:   8%|▊         | 680/8564 [00:00<00:09, 805.85 examples/s]Applying chat template to train dataset:  16%|█▌        | 1370/8564 [00:01<00:07, 985.81 examples/s] Applying chat template to train dataset:   5%|▌         | 433/8564 [00:00<00:10, 807.77 examples/s]Applying chat template to train dataset:   9%|▉         | 770/8564 [00:01<00:10, 712.62 examples/s]Applying chat template to train dataset:  17%|█▋        | 1487/8564 [00:01<00:06, 1022.98 examples/s]Applying chat template to train dataset:   6%|▌         | 535/8564 [00:00<00:10, 739.84 examples/s]Applying chat template to train dataset:  19%|█▉        | 1650/8564 [00:01<00:05, 1177.22 examples/s]Applying chat template to train dataset:  10%|█         | 866/8564 [00:01<00:11, 650.57 examples/s]Applying chat template to train dataset:  21%|██▏       | 1825/8564 [00:01<00:05, 1299.28 examples/s]Applying chat template to train dataset:  11%|█         | 934/8564 [00:01<00:12, 632.73 examples/s]Applying chat template to train dataset:   7%|▋         | 640/8564 [00:01<00:12, 615.30 examples/s]Applying chat template to train dataset:  23%|██▎       | 1980/8564 [00:02<00:04, 1364.89 examples/s]Applying chat template to train dataset:  25%|██▌       | 2141/8564 [00:02<00:04, 1431.55 examples/s]Applying chat template to train dataset:  12%|█▏        | 1030/8564 [00:01<00:12, 621.30 examples/s]Applying chat template to train dataset:  27%|██▋       | 2309/8564 [00:02<00:04, 1501.16 examples/s]Applying chat template to train dataset:   9%|▊         | 730/8564 [00:01<00:15, 512.01 examples/s]Applying chat template to train dataset:  13%|█▎        | 1100/8564 [00:01<00:12, 608.44 examples/s]Applying chat template to train dataset:  10%|▉         | 850/8564 [00:01<00:12, 641.68 examples/s]Applying chat template to train dataset:  14%|█▍        | 1181/8564 [00:01<00:11, 627.99 examples/s]Applying chat template to train dataset:  29%|██▉       | 2500/8564 [00:02<00:04, 1330.40 examples/s]Applying chat template to train dataset:  11%|█         | 956/8564 [00:01<00:10, 730.25 examples/s]Applying chat template to train dataset:  15%|█▍        | 1282/8564 [00:01<00:11, 622.47 examples/s]Applying chat template to train dataset:  31%|███       | 2670/8564 [00:02<00:04, 1253.25 examples/s]Applying chat template to train dataset:  12%|█▏        | 1063/8564 [00:01<00:09, 808.78 examples/s]Applying chat template to train dataset:  16%|█▌        | 1378/8564 [00:02<00:10, 701.07 examples/s]Applying chat template to train dataset:  14%|█▍        | 1219/8564 [00:01<00:08, 883.14 examples/s]Applying chat template to train dataset:  33%|███▎      | 2809/8564 [00:02<00:05, 1038.25 examples/s]Applying chat template to train dataset:  17%|█▋        | 1454/8564 [00:02<00:10, 697.23 examples/s]Applying chat template to train dataset:  18%|█▊        | 1570/8564 [00:02<00:08, 810.63 examples/s]Applying chat template to train dataset:  15%|█▌        | 1327/8564 [00:02<00:09, 778.71 examples/s]Applying chat template to train dataset:  35%|███▍      | 2970/8564 [00:02<00:05, 1046.37 examples/s]Applying chat template to train dataset:  20%|█▉        | 1695/8564 [00:02<00:07, 918.57 examples/s]Applying chat template to train dataset:  17%|█▋        | 1414/8564 [00:02<00:10, 712.18 examples/s]Applying chat template to train dataset:  21%|██        | 1800/8564 [00:02<00:07, 946.91 examples/s]Applying chat template to train dataset:  18%|█▊        | 1543/8564 [00:02<00:08, 839.76 examples/s]Applying chat template to train dataset:  22%|██▏       | 1918/8564 [00:02<00:06, 1005.17 examples/s]Applying chat template to train dataset:  36%|███▋      | 3120/8564 [00:03<00:06, 791.46 examples/s] Applying chat template to train dataset:  38%|███▊      | 3221/8564 [00:03<00:06, 828.26 examples/s]Applying chat template to train dataset:  24%|██▍       | 2087/8564 [00:02<00:06, 1002.01 examples/s]Applying chat template to train dataset:  19%|█▉        | 1646/8564 [00:02<00:09, 719.30 examples/s]Applying chat template to train dataset:  39%|███▉      | 3330/8564 [00:03<00:05, 879.42 examples/s]Applying chat template to train dataset:  26%|██▌       | 2239/8564 [00:02<00:06, 1002.73 examples/s]Applying chat template to train dataset:  20%|██        | 1736/8564 [00:02<00:10, 673.58 examples/s]Applying chat template to train dataset:  40%|████      | 3450/8564 [00:03<00:06, 843.34 examples/s]Applying chat template to train dataset:  27%|██▋       | 2345/8564 [00:02<00:06, 989.35 examples/s] Applying chat template to train dataset:  21%|██▏       | 1823/8564 [00:02<00:09, 688.46 examples/s]Applying chat template to train dataset:  42%|████▏     | 3560/8564 [00:03<00:05, 898.56 examples/s]Applying chat template to train dataset:  22%|██▏       | 1910/8564 [00:02<00:09, 729.71 examples/s]Applying chat template to train dataset:  29%|██▉       | 2469/8564 [00:03<00:06, 1001.21 examples/s]Applying chat template to train dataset:  30%|███       | 2580/8564 [00:03<00:05, 1026.17 examples/s]Applying chat template to train dataset:  24%|██▎       | 2020/8564 [00:02<00:08, 796.16 examples/s]Applying chat template to train dataset:  43%|████▎     | 3695/8564 [00:03<00:06, 745.18 examples/s]Applying chat template to train dataset:  31%|███▏      | 2690/8564 [00:03<00:05, 1043.56 examples/s]Applying chat template to train dataset:  25%|██▍       | 2136/8564 [00:03<00:07, 861.75 examples/s]Applying chat template to train dataset:  44%|████▍     | 3804/8564 [00:04<00:05, 813.83 examples/s]Applying chat template to train dataset:  26%|██▌       | 2239/8564 [00:03<00:06, 904.93 examples/s]Applying chat template to train dataset:  33%|███▎      | 2802/8564 [00:03<00:06, 915.45 examples/s] Applying chat template to train dataset:  46%|████▌     | 3927/8564 [00:04<00:05, 886.48 examples/s]Applying chat template to train dataset:  34%|███▍      | 2920/8564 [00:03<00:05, 979.80 examples/s]Applying chat template to train dataset:  47%|████▋     | 4031/8564 [00:04<00:04, 921.84 examples/s]Applying chat template to train dataset:  27%|██▋       | 2352/8564 [00:03<00:08, 729.42 examples/s]Applying chat template to train dataset:  35%|███▌      | 3024/8564 [00:03<00:05, 974.55 examples/s]Applying chat template to train dataset:  48%|████▊     | 4132/8564 [00:04<00:04, 934.12 examples/s]Applying chat template to train dataset:  28%|██▊       | 2435/8564 [00:03<00:08, 738.26 examples/s]Applying chat template to train dataset:  37%|███▋      | 3158/8564 [00:03<00:06, 884.38 examples/s]Applying chat template to train dataset:  50%|█████     | 4282/8564 [00:04<00:04, 954.53 examples/s]Applying chat template to train dataset:  30%|██▉       | 2549/8564 [00:03<00:08, 687.94 examples/s]Applying chat template to train dataset:  51%|█████     | 4383/8564 [00:04<00:04, 965.28 examples/s]Applying chat template to train dataset:  38%|███▊      | 3262/8564 [00:03<00:05, 896.30 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4492/8564 [00:04<00:04, 982.14 examples/s]Applying chat template to train dataset:  40%|███▉      | 3385/8564 [00:04<00:05, 953.26 examples/s]Applying chat template to train dataset:  31%|███       | 2665/8564 [00:03<00:08, 685.58 examples/s]Applying chat template to train dataset:  41%|████      | 3499/8564 [00:04<00:05, 966.53 examples/s]Applying chat template to train dataset:  32%|███▏      | 2755/8564 [00:03<00:08, 721.50 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4613/8564 [00:04<00:04, 861.59 examples/s]Applying chat template to train dataset:  33%|███▎      | 2857/8564 [00:04<00:07, 790.34 examples/s]Applying chat template to train dataset:  42%|████▏     | 3612/8564 [00:04<00:05, 860.32 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4727/8564 [00:05<00:04, 783.93 examples/s]Applying chat template to train dataset:  35%|███▍      | 2971/8564 [00:04<00:06, 869.66 examples/s]Applying chat template to train dataset:  56%|█████▋    | 4823/8564 [00:05<00:04, 820.47 examples/s]Applying chat template to train dataset:  44%|████▍     | 3762/8564 [00:04<00:06, 767.98 examples/s]Applying chat template to train dataset:  36%|███▌      | 3100/8564 [00:04<00:07, 775.31 examples/s]Applying chat template to train dataset:  45%|████▌     | 3872/8564 [00:04<00:05, 836.66 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4934/8564 [00:05<00:04, 731.38 examples/s]Applying chat template to train dataset:  37%|███▋      | 3210/8564 [00:04<00:06, 847.11 examples/s]Applying chat template to train dataset:  46%|████▋     | 3977/8564 [00:04<00:05, 884.44 examples/s]Applying chat template to train dataset:  39%|███▊      | 3317/8564 [00:04<00:05, 901.15 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5052/8564 [00:05<00:04, 729.09 examples/s]Applying chat template to train dataset:  48%|████▊     | 4080/8564 [00:04<00:04, 917.51 examples/s]Applying chat template to train dataset:  40%|███▉      | 3416/8564 [00:04<00:05, 922.39 examples/s]Applying chat template to train dataset:  41%|████      | 3525/8564 [00:04<00:05, 966.99 examples/s]Applying chat template to train dataset:  60%|██████    | 5150/8564 [00:05<00:04, 691.94 examples/s]Applying chat template to train dataset:  49%|████▉     | 4223/8564 [00:05<00:04, 907.31 examples/s]Applying chat template to train dataset:  42%|████▏     | 3637/8564 [00:04<00:05, 958.80 examples/s]Applying chat template to train dataset:  51%|█████     | 4334/8564 [00:05<00:04, 940.31 examples/s]Applying chat template to train dataset:  61%|██████▏   | 5248/8564 [00:05<00:04, 664.33 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4440/8564 [00:05<00:04, 942.72 examples/s]Applying chat template to train dataset:  44%|████▍     | 3781/8564 [00:05<00:05, 951.84 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5325/8564 [00:05<00:04, 660.94 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4544/8564 [00:05<00:04, 942.30 examples/s]Applying chat template to train dataset:  45%|████▌     | 3884/8564 [00:05<00:05, 918.85 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5421/8564 [00:06<00:04, 646.09 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4677/8564 [00:05<00:04, 912.17 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5524/8564 [00:06<00:04, 712.98 examples/s]Applying chat template to train dataset:  47%|████▋     | 3986/8564 [00:05<00:05, 769.45 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4816/8564 [00:05<00:04, 915.93 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5610/8564 [00:06<00:04, 709.55 examples/s]Applying chat template to train dataset:  48%|████▊     | 4077/8564 [00:05<00:05, 787.93 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5719/8564 [00:06<00:03, 799.12 examples/s]Applying chat template to train dataset:  49%|████▉     | 4195/8564 [00:05<00:05, 786.18 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4951/8564 [00:05<00:04, 781.12 examples/s]Applying chat template to train dataset:  50%|█████     | 4295/8564 [00:05<00:05, 835.68 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5820/8564 [00:06<00:03, 706.85 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5039/8564 [00:06<00:04, 760.07 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4415/8564 [00:05<00:04, 917.86 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5940/8564 [00:06<00:03, 797.11 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4524/8564 [00:05<00:04, 929.29 examples/s]Applying chat template to train dataset:  71%|███████   | 6050/8564 [00:06<00:02, 869.69 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5131/8564 [00:06<00:05, 679.74 examples/s]Applying chat template to train dataset:  54%|█████▍    | 4631/8564 [00:06<00:04, 963.94 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6148/8564 [00:06<00:02, 897.27 examples/s]Applying chat template to train dataset:  61%|██████    | 5204/8564 [00:06<00:05, 665.64 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4741/8564 [00:06<00:03, 1000.21 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6260/8564 [00:07<00:02, 955.51 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5283/8564 [00:06<00:05, 651.52 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4847/8564 [00:06<00:03, 1014.08 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6362/8564 [00:07<00:02, 970.72 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5356/8564 [00:06<00:04, 642.92 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4950/8564 [00:06<00:03, 995.15 examples/s] Applying chat template to train dataset:  76%|███████▌  | 6470/8564 [00:07<00:02, 981.66 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5423/8564 [00:06<00:04, 648.02 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5056/8564 [00:06<00:03, 1012.32 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6574/8564 [00:07<00:01, 996.94 examples/s]Applying chat template to train dataset:  60%|██████    | 5160/8564 [00:06<00:03, 998.73 examples/s] Applying chat template to train dataset:  78%|███████▊  | 6682/8564 [00:07<00:01, 1000.82 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5520/8564 [00:06<00:04, 617.60 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5282/8564 [00:06<00:03, 1028.83 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6800/8564 [00:07<00:01, 1014.03 examples/s]Applying chat template to train dataset:  65%|██████▌   | 5587/8564 [00:06<00:04, 607.94 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5387/8564 [00:06<00:03, 1033.72 examples/s]Applying chat template to train dataset:  81%|████████  | 6908/8564 [00:07<00:01, 1009.52 examples/s]Applying chat template to train dataset:  66%|██████▋   | 5678/8564 [00:07<00:04, 602.88 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5502/8564 [00:06<00:02, 1045.77 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7013/8564 [00:07<00:01, 1019.77 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5616/8564 [00:06<00:02, 1072.64 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7120/8564 [00:07<00:01, 1031.64 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5750/8564 [00:07<00:04, 591.43 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7231/8564 [00:07<00:01, 1053.51 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5826/8564 [00:07<00:04, 618.70 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5770/8564 [00:07<00:02, 1051.94 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7340/8564 [00:08<00:01, 1042.69 examples/s]Applying chat template to train dataset:  69%|██████▊   | 5880/8564 [00:07<00:02, 1062.59 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5922/8564 [00:07<00:04, 592.51 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5992/8564 [00:07<00:02, 1076.38 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7510/8564 [00:08<00:01, 1028.57 examples/s]Applying chat template to train dataset:  70%|███████   | 6000/8564 [00:07<00:04, 589.33 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7617/8564 [00:08<00:00, 1010.28 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6133/8564 [00:07<00:02, 994.56 examples/s] Applying chat template to train dataset:  71%|███████   | 6069/8564 [00:07<00:04, 607.52 examples/s]Applying chat template to train dataset:  90%|█████████ | 7734/8564 [00:08<00:00, 1036.82 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6260/8564 [00:07<00:02, 1046.84 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6132/8564 [00:07<00:03, 608.48 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6201/8564 [00:07<00:03, 622.89 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6421/8564 [00:07<00:02, 1015.11 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6267/8564 [00:08<00:03, 610.76 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7856/8564 [00:08<00:00, 743.27 examples/s] Applying chat template to train dataset:  76%|███████▋  | 6535/8564 [00:07<00:01, 1038.34 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7965/8564 [00:08<00:00, 815.26 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6345/8564 [00:08<00:03, 615.46 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6700/8564 [00:08<00:01, 1040.68 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8087/8564 [00:08<00:00, 887.57 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6434/8564 [00:08<00:03, 602.27 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8200/8564 [00:09<00:00, 911.33 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6846/8564 [00:08<00:01, 908.65 examples/s] Applying chat template to train dataset:  76%|███████▋  | 6541/8564 [00:08<00:03, 663.63 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8317/8564 [00:09<00:00, 925.67 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6639/8564 [00:08<00:02, 740.86 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8426/8564 [00:09<00:00, 943.78 examples/s]Applying chat template to train dataset:  82%|████████▏ | 6992/8564 [00:08<00:01, 868.05 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7106/8564 [00:08<00:01, 923.12 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6757/8564 [00:08<00:02, 705.05 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8549/8564 [00:09<00:00, 793.94 examples/s]Applying chat template to train dataset:  80%|████████  | 6858/8564 [00:08<00:02, 772.25 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7232/8564 [00:08<00:01, 933.23 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:09<00:00, 898.73 examples/s]
Applying chat template to train dataset:  86%|████████▌ | 7336/8564 [00:08<00:01, 929.98 examples/s]Applying chat template to train dataset:  81%|████████  | 6948/8564 [00:09<00:02, 710.58 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7059/8564 [00:09<00:01, 785.62 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7441/8564 [00:08<00:01, 838.06 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7179/8564 [00:09<00:01, 870.21 examples/s]Applying chat template to train dataset:  85%|████████▌ | 7282/8564 [00:09<00:01, 910.66 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7567/8564 [00:09<00:01, 771.33 examples/s]Applying chat template to train dataset:  86%|████████▋ | 7397/8564 [00:09<00:01, 973.57 examples/s]Applying chat template to train dataset:  90%|████████▉ | 7680/8564 [00:09<00:01, 755.28 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7527/8564 [00:09<00:00, 1040.47 examples/s]Applying chat template to train dataset:  91%|█████████ | 7785/8564 [00:09<00:01, 775.92 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7660/8564 [00:09<00:01, 811.27 examples/s] Applying chat template to train dataset:  92%|█████████▏| 7904/8564 [00:09<00:00, 761.05 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8046/8564 [00:09<00:00, 905.44 examples/s]Applying chat template to train dataset:  91%|█████████ | 7765/8564 [00:09<00:01, 730.97 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8203/8564 [00:09<00:00, 976.68 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7878/8564 [00:10<00:00, 757.91 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8337/8564 [00:09<00:00, 1039.57 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:  94%|█████████▍| 8065/8564 [00:10<00:00, 875.71 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8470/8564 [00:10<00:00, 913.35 examples/s] Applying chat template to train dataset:  96%|█████████▋| 8248/8564 [00:10<00:00, 1079.58 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 839.71 examples/s]
Tokenizing train dataset:   0%|          | 10/8564 [00:00<04:02, 35.30 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8389/8564 [00:10<00:00, 1019.14 examples/s]Tokenizing train dataset:   0%|          | 34/8564 [00:00<01:28, 96.30 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8510/8564 [00:10<00:00, 913.32 examples/s] Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:10<00:00, 791.46 examples/s]
Tokenizing train dataset:   1%|          | 50/8564 [00:00<01:57, 72.31 examples/s]Tokenizing train dataset:   1%|          | 61/8564 [00:00<02:00, 70.60 examples/s]Tokenizing train dataset:   1%|          | 70/8564 [00:00<01:59, 71.09 examples/s]Tokenizing train dataset:   1%|          | 80/8564 [00:01<01:53, 74.53 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 91/8564 [00:01<02:18, 61.11 examples/s]Tokenizing train dataset:   0%|          | 21/8564 [00:00<00:57, 149.37 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:01<02:10, 64.86 examples/s]Tokenizing train dataset:   0%|          | 40/8564 [00:00<00:55, 153.12 examples/s]Tokenizing train dataset:   1%|▏         | 110/8564 [00:01<02:14, 62.94 examples/s]Tokenizing train dataset:   1%|          | 56/8564 [00:00<01:11, 119.66 examples/s]Tokenizing train dataset:   1%|▏         | 118/8564 [00:01<02:17, 61.40 examples/s]Tokenizing train dataset:   1%|          | 70/8564 [00:00<01:08, 124.34 examples/s]Tokenizing train dataset:   1%|▏         | 125/8564 [00:01<02:20, 59.91 examples/s]Tokenizing train dataset:   1%|          | 92/8564 [00:00<00:56, 149.01 examples/s]Tokenizing train dataset:   2%|▏         | 136/8564 [00:02<02:04, 67.48 examples/s]Tokenizing train dataset:   1%|▏         | 112/8564 [00:00<00:53, 158.85 examples/s]Tokenizing train dataset:   2%|▏         | 144/8564 [00:02<02:05, 67.27 examples/s]Tokenizing train dataset:   2%|▏         | 129/8564 [00:00<00:55, 151.22 examples/s]Tokenizing train dataset:   2%|▏         | 164/8564 [00:02<01:25, 98.50 examples/s]Tokenizing train dataset:   2%|▏         | 145/8564 [00:01<00:57, 147.47 examples/s]Tokenizing train dataset:   2%|▏         | 180/8564 [00:02<01:26, 96.52 examples/s]Tokenizing train dataset:   2%|▏         | 160/8564 [00:01<00:59, 142.05 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   2%|▏         | 177/8564 [00:01<00:56, 148.57 examples/s]Tokenizing train dataset:   2%|▏         | 193/8564 [00:02<01:37, 86.22 examples/s]Tokenizing train dataset:   2%|▏         | 200/8564 [00:01<00:49, 168.59 examples/s]Tokenizing train dataset:   3%|▎         | 226/8564 [00:01<00:43, 192.85 examples/s]Tokenizing train dataset:   2%|▏         | 206/8564 [00:02<01:48, 77.37 examples/s]Tokenizing train dataset:   0%|          | 1/8564 [00:00<46:21,  3.08 examples/s]Tokenizing train dataset:   3%|▎         | 249/8564 [00:01<00:44, 188.91 examples/s]Tokenizing train dataset:   3%|▎         | 274/8564 [00:01<00:40, 204.34 examples/s]Tokenizing train dataset:   3%|▎         | 217/8564 [00:02<01:51, 74.76 examples/s]Tokenizing train dataset:   3%|▎         | 297/8564 [00:01<00:40, 204.90 examples/s]Tokenizing train dataset:   3%|▎         | 231/8564 [00:03<01:39, 83.53 examples/s]Tokenizing train dataset:   4%|▎         | 320/8564 [00:01<00:39, 207.61 examples/s]Tokenizing train dataset:   3%|▎         | 240/8564 [00:03<01:41, 81.62 examples/s]Tokenizing train dataset:   4%|▍         | 350/8564 [00:02<00:41, 198.91 examples/s]Tokenizing train dataset:   3%|▎         | 249/8564 [00:03<01:48, 76.97 examples/s]Tokenizing train dataset:   4%|▍         | 372/8564 [00:02<00:40, 200.91 examples/s]Tokenizing train dataset:   3%|▎         | 257/8564 [00:03<01:52, 73.62 examples/s]Tokenizing train dataset:   5%|▍         | 396/8564 [00:02<00:38, 210.10 examples/s]Tokenizing train dataset:   3%|▎         | 267/8564 [00:03<01:45, 78.80 examples/s]Tokenizing train dataset:   0%|          | 10/8564 [00:01<14:33,  9.79 examples/s]Tokenizing train dataset:   3%|▎         | 280/8564 [00:03<01:36, 86.09 examples/s]Tokenizing train dataset:   0%|          | 33/8564 [00:01<04:04, 34.85 examples/s]Tokenizing train dataset:   5%|▍         | 418/8564 [00:02<00:49, 163.39 examples/s]Tokenizing train dataset:   3%|▎         | 295/8564 [00:03<01:26, 95.25 examples/s]Tokenizing train dataset:   1%|          | 43/8564 [00:01<03:21, 42.31 examples/s]Tokenizing train dataset:   4%|▎         | 307/8564 [00:03<01:25, 96.11 examples/s]Tokenizing train dataset:   5%|▌         | 437/8564 [00:02<01:00, 134.66 examples/s]Tokenizing train dataset:   4%|▎         | 317/8564 [00:04<01:27, 94.43 examples/s]Tokenizing train dataset:   1%|          | 54/8564 [00:01<03:04, 46.23 examples/s]Tokenizing train dataset:   4%|▍         | 329/8564 [00:04<01:22, 99.66 examples/s]Tokenizing train dataset:   5%|▌         | 453/8564 [00:02<01:09, 116.43 examples/s]Tokenizing train dataset:   1%|          | 66/8564 [00:01<02:46, 50.91 examples/s]Tokenizing train dataset:   5%|▌         | 470/8564 [00:03<01:12, 111.05 examples/s]Tokenizing train dataset:   4%|▍         | 344/8564 [00:04<01:33, 88.28 examples/s]Tokenizing train dataset:   1%|          | 79/8564 [00:01<02:15, 62.65 examples/s]Tokenizing train dataset:   1%|          | 91/8564 [00:01<01:58, 71.41 examples/s]Tokenizing train dataset:   6%|▌         | 487/8564 [00:03<01:15, 107.13 examples/s]Tokenizing train dataset:   4%|▍         | 354/8564 [00:04<01:51, 73.87 examples/s]Tokenizing train dataset:   1%|          | 100/8564 [00:02<02:07, 66.61 examples/s]Tokenizing train dataset:   4%|▍         | 367/8564 [00:04<01:39, 82.36 examples/s]Tokenizing train dataset:   6%|▌         | 501/8564 [00:03<01:24, 95.22 examples/s] Tokenizing train dataset:   4%|▍         | 380/8564 [00:04<01:28, 92.06 examples/s]Tokenizing train dataset:   1%|▏         | 108/8564 [00:02<02:13, 63.54 examples/s]Tokenizing train dataset:   6%|▌         | 517/8564 [00:03<01:24, 95.68 examples/s]Tokenizing train dataset:   5%|▍         | 392/8564 [00:04<01:26, 94.28 examples/s]Tokenizing train dataset:   6%|▌         | 529/8564 [00:03<01:20, 99.36 examples/s]Tokenizing train dataset:   1%|▏         | 118/8564 [00:02<02:15, 62.15 examples/s]Tokenizing train dataset:   5%|▍         | 403/8564 [00:05<01:25, 94.94 examples/s]Tokenizing train dataset:   6%|▋         | 542/8564 [00:03<01:16, 105.04 examples/s]Tokenizing train dataset:   1%|▏         | 127/8564 [00:02<02:10, 64.62 examples/s]Tokenizing train dataset:   5%|▍         | 416/8564 [00:05<01:22, 98.99 examples/s]Tokenizing train dataset:   2%|▏         | 136/8564 [00:02<02:03, 68.23 examples/s]Tokenizing train dataset:   5%|▍         | 427/8564 [00:05<01:20, 100.63 examples/s]Tokenizing train dataset:   6%|▋         | 554/8564 [00:04<01:33, 85.28 examples/s] Tokenizing train dataset:   2%|▏         | 145/8564 [00:02<02:01, 69.24 examples/s]Tokenizing train dataset:   2%|▏         | 156/8564 [00:02<01:48, 77.44 examples/s]Tokenizing train dataset:   5%|▌         | 440/8564 [00:05<01:35, 84.77 examples/s] Tokenizing train dataset:   7%|▋         | 566/8564 [00:04<01:36, 82.73 examples/s]Tokenizing train dataset:   2%|▏         | 167/8564 [00:03<01:40, 83.29 examples/s]Tokenizing train dataset:   7%|▋         | 577/8564 [00:04<01:34, 84.91 examples/s]Tokenizing train dataset:   5%|▌         | 450/8564 [00:05<01:55, 70.17 examples/s]Tokenizing train dataset:   2%|▏         | 176/8564 [00:03<01:40, 83.74 examples/s]Tokenizing train dataset:   5%|▌         | 461/8564 [00:05<01:47, 75.18 examples/s]Tokenizing train dataset:   2%|▏         | 187/8564 [00:03<01:38, 85.42 examples/s]Tokenizing train dataset:   7%|▋         | 591/8564 [00:04<01:44, 76.43 examples/s]Tokenizing train dataset:   5%|▌         | 470/8564 [00:05<01:48, 74.32 examples/s]Tokenizing train dataset:   2%|▏         | 199/8564 [00:03<01:34, 88.92 examples/s]Tokenizing train dataset:   2%|▏         | 210/8564 [00:03<01:29, 93.53 examples/s]Tokenizing train dataset:   7%|▋         | 604/8564 [00:04<01:56, 68.58 examples/s]Tokenizing train dataset:   6%|▌         | 480/8564 [00:06<01:59, 67.71 examples/s]Tokenizing train dataset:   3%|▎         | 222/8564 [00:03<01:27, 95.24 examples/s]Tokenizing train dataset:   7%|▋         | 615/8564 [00:04<01:47, 73.93 examples/s]Tokenizing train dataset:   6%|▌         | 491/8564 [00:06<01:51, 72.46 examples/s]Tokenizing train dataset:   3%|▎         | 234/8564 [00:03<01:22, 100.68 examples/s]Tokenizing train dataset:   7%|▋         | 630/8564 [00:05<01:37, 81.00 examples/s]Tokenizing train dataset:   3%|▎         | 245/8564 [00:03<01:26, 96.52 examples/s] Tokenizing train dataset:   6%|▌         | 504/8564 [00:06<01:54, 70.12 examples/s]Tokenizing train dataset:   7%|▋         | 640/8564 [00:05<01:44, 76.06 examples/s]Tokenizing train dataset:   3%|▎         | 256/8564 [00:03<01:24, 97.78 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:06<02:02, 65.92 examples/s]Tokenizing train dataset:   8%|▊         | 651/8564 [00:05<01:37, 81.29 examples/s]Tokenizing train dataset:   3%|▎         | 272/8564 [00:04<01:16, 108.22 examples/s]Tokenizing train dataset:   6%|▌         | 525/8564 [00:06<01:41, 79.38 examples/s]Tokenizing train dataset:   8%|▊         | 660/8564 [00:05<01:37, 81.27 examples/s]Tokenizing train dataset:   3%|▎         | 285/8564 [00:04<01:13, 112.04 examples/s]Tokenizing train dataset:   6%|▌         | 535/8564 [00:06<01:41, 79.36 examples/s]Tokenizing train dataset:   8%|▊         | 669/8564 [00:05<01:40, 78.58 examples/s]Tokenizing train dataset:   3%|▎         | 297/8564 [00:04<01:15, 109.56 examples/s]Tokenizing train dataset:   6%|▋         | 549/8564 [00:06<01:29, 89.60 examples/s]Tokenizing train dataset:   8%|▊         | 682/8564 [00:05<01:30, 87.07 examples/s]Tokenizing train dataset:   4%|▎         | 310/8564 [00:04<01:28, 92.95 examples/s] Tokenizing train dataset:   7%|▋         | 560/8564 [00:07<01:28, 90.72 examples/s]Tokenizing train dataset:   4%|▍         | 322/8564 [00:04<01:23, 98.58 examples/s]Tokenizing train dataset:   7%|▋         | 570/8564 [00:07<01:26, 92.68 examples/s]Tokenizing train dataset:   8%|▊         | 696/8564 [00:05<01:45, 74.58 examples/s]Tokenizing train dataset:   7%|▋         | 580/8564 [00:07<01:30, 88.47 examples/s]Tokenizing train dataset:   4%|▍         | 336/8564 [00:04<01:25, 95.71 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:06<01:47, 72.85 examples/s]Tokenizing train dataset:   7%|▋         | 594/8564 [00:07<01:24, 93.89 examples/s]Tokenizing train dataset:   4%|▍         | 347/8564 [00:04<01:34, 86.95 examples/s]Tokenizing train dataset:   8%|▊         | 722/8564 [00:06<01:32, 84.64 examples/s]Tokenizing train dataset:   7%|▋         | 604/8564 [00:07<01:26, 92.18 examples/s]Tokenizing train dataset:   9%|▊         | 739/8564 [00:06<01:19, 98.64 examples/s]Tokenizing train dataset:   7%|▋         | 616/8564 [00:07<01:21, 96.95 examples/s]Tokenizing train dataset:   4%|▍         | 360/8564 [00:05<01:41, 80.64 examples/s]Tokenizing train dataset:   9%|▉         | 750/8564 [00:06<01:18, 99.51 examples/s]Tokenizing train dataset:   7%|▋         | 635/8564 [00:07<01:08, 116.34 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:05<01:45, 77.32 examples/s]Tokenizing train dataset:   9%|▉         | 762/8564 [00:06<01:21, 95.93 examples/s]Tokenizing train dataset:   4%|▍         | 378/8564 [00:05<01:47, 76.08 examples/s]Tokenizing train dataset:   8%|▊         | 650/8564 [00:07<01:14, 106.09 examples/s]Tokenizing train dataset:   9%|▉         | 772/8564 [00:06<01:20, 96.52 examples/s]Tokenizing train dataset:   5%|▍         | 387/8564 [00:05<01:47, 76.17 examples/s]Tokenizing train dataset:   8%|▊         | 661/8564 [00:08<01:14, 105.76 examples/s]Tokenizing train dataset:   9%|▉         | 782/8564 [00:06<01:23, 93.23 examples/s]Tokenizing train dataset:   8%|▊         | 677/8564 [00:08<01:16, 103.04 examples/s]Tokenizing train dataset:   9%|▉         | 796/8564 [00:06<01:24, 92.33 examples/s]Tokenizing train dataset:   5%|▍         | 399/8564 [00:05<01:57, 69.49 examples/s]Tokenizing train dataset:   8%|▊         | 688/8564 [00:08<01:18, 100.30 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:07<01:25, 90.64 examples/s]Tokenizing train dataset:   5%|▍         | 412/8564 [00:05<02:05, 65.16 examples/s]Tokenizing train dataset:  10%|▉         | 820/8564 [00:07<01:28, 87.99 examples/s]Tokenizing train dataset:   8%|▊         | 699/8564 [00:08<01:36, 81.45 examples/s] Tokenizing train dataset:   5%|▍         | 426/8564 [00:06<01:45, 76.89 examples/s]Tokenizing train dataset:  10%|▉         | 830/8564 [00:07<01:26, 89.32 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:08<01:41, 77.47 examples/s]Tokenizing train dataset:   5%|▌         | 436/8564 [00:06<01:44, 78.10 examples/s]Tokenizing train dataset:  10%|▉         | 842/8564 [00:07<01:23, 92.32 examples/s]Tokenizing train dataset:   5%|▌         | 446/8564 [00:06<01:39, 81.46 examples/s]Tokenizing train dataset:   8%|▊         | 717/8564 [00:08<01:48, 72.61 examples/s]Tokenizing train dataset:  10%|▉         | 853/8564 [00:07<01:23, 92.66 examples/s]Tokenizing train dataset:   5%|▌         | 458/8564 [00:06<01:33, 86.69 examples/s]Tokenizing train dataset:   9%|▊         | 733/8564 [00:08<01:34, 82.67 examples/s]Tokenizing train dataset:  10%|█         | 865/8564 [00:07<01:18, 97.62 examples/s]Tokenizing train dataset:   5%|▌         | 470/8564 [00:06<01:28, 91.44 examples/s]Tokenizing train dataset:   9%|▊         | 743/8564 [00:09<01:31, 85.35 examples/s]Tokenizing train dataset:  10%|█         | 883/8564 [00:07<01:19, 97.22 examples/s]Tokenizing train dataset:   6%|▌         | 480/8564 [00:06<01:30, 89.11 examples/s]Tokenizing train dataset:   9%|▉         | 752/8564 [00:09<01:36, 81.00 examples/s]Tokenizing train dataset:  10%|█         | 894/8564 [00:07<01:21, 93.63 examples/s]Tokenizing train dataset:   9%|▉         | 761/8564 [00:09<01:34, 82.63 examples/s]Tokenizing train dataset:   6%|▌         | 490/8564 [00:06<01:36, 83.31 examples/s]Tokenizing train dataset:  11%|█         | 905/8564 [00:08<01:21, 93.96 examples/s]Tokenizing train dataset:   9%|▉         | 773/8564 [00:09<01:28, 87.62 examples/s]Tokenizing train dataset:   6%|▌         | 503/8564 [00:06<01:52, 71.36 examples/s]Tokenizing train dataset:   9%|▉         | 784/8564 [00:09<01:27, 88.43 examples/s]Tokenizing train dataset:  11%|█         | 916/8564 [00:08<01:35, 79.76 examples/s]Tokenizing train dataset:   9%|▉         | 794/8564 [00:09<01:29, 86.99 examples/s]Tokenizing train dataset:   6%|▌         | 516/8564 [00:07<01:49, 73.19 examples/s]Tokenizing train dataset:  11%|█         | 927/8564 [00:08<01:45, 72.28 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:09<01:26, 90.02 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:07<01:51, 71.96 examples/s]Tokenizing train dataset:  10%|▉         | 819/8564 [00:09<01:21, 94.53 examples/s]Tokenizing train dataset:   6%|▌         | 533/8564 [00:07<01:52, 71.30 examples/s]Tokenizing train dataset:  11%|█         | 937/8564 [00:08<01:56, 65.45 examples/s]Tokenizing train dataset:  11%|█         | 945/8564 [00:08<01:51, 68.31 examples/s]Tokenizing train dataset:  10%|▉         | 832/8564 [00:10<01:28, 87.78 examples/s]Tokenizing train dataset:   6%|▋         | 543/8564 [00:07<01:50, 72.33 examples/s]Tokenizing train dataset:  10%|▉         | 845/8564 [00:10<01:20, 96.29 examples/s]Tokenizing train dataset:   6%|▋         | 551/8564 [00:07<01:56, 69.05 examples/s]Tokenizing train dataset:  11%|█         | 954/8564 [00:08<02:03, 61.43 examples/s]Tokenizing train dataset:  10%|█         | 857/8564 [00:10<01:18, 97.66 examples/s]Tokenizing train dataset:   7%|▋         | 559/8564 [00:07<01:58, 67.75 examples/s]Tokenizing train dataset:  11%|█▏        | 966/8564 [00:09<01:50, 69.04 examples/s]Tokenizing train dataset:  10%|█         | 867/8564 [00:10<01:21, 94.67 examples/s]Tokenizing train dataset:   7%|▋         | 568/8564 [00:07<01:58, 67.72 examples/s]Tokenizing train dataset:  10%|█         | 879/8564 [00:10<01:17, 98.64 examples/s]Tokenizing train dataset:  11%|█▏        | 975/8564 [00:09<02:01, 62.25 examples/s]Tokenizing train dataset:   7%|▋         | 576/8564 [00:08<01:59, 66.76 examples/s]Tokenizing train dataset:  10%|█         | 897/8564 [00:10<01:04, 119.10 examples/s]Tokenizing train dataset:  11%|█▏        | 984/8564 [00:09<01:58, 63.77 examples/s]Tokenizing train dataset:   7%|▋         | 586/8564 [00:08<02:05, 63.49 examples/s]Tokenizing train dataset:  11%|█         | 911/8564 [00:10<01:12, 106.02 examples/s]Tokenizing train dataset:   7%|▋         | 595/8564 [00:08<01:56, 68.65 examples/s]Tokenizing train dataset:  12%|█▏        | 994/8564 [00:09<02:04, 60.78 examples/s]Tokenizing train dataset:   7%|▋         | 604/8564 [00:08<01:48, 73.35 examples/s]Tokenizing train dataset:  11%|█         | 926/8564 [00:11<01:28, 86.25 examples/s] Tokenizing train dataset:   7%|▋         | 617/8564 [00:08<01:31, 86.69 examples/s]Tokenizing train dataset:  12%|█▏        | 1007/8564 [00:09<02:01, 62.13 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:08<01:14, 105.96 examples/s]Tokenizing train dataset:  11%|█         | 937/8564 [00:11<01:41, 75.39 examples/s]Tokenizing train dataset:  12%|█▏        | 1017/8564 [00:09<02:03, 61.30 examples/s]Tokenizing train dataset:   8%|▊         | 654/8564 [00:08<01:12, 109.22 examples/s]Tokenizing train dataset:  11%|█         | 946/8564 [00:11<01:43, 73.44 examples/s]Tokenizing train dataset:  12%|█▏        | 1024/8564 [00:10<02:14, 56.08 examples/s]Tokenizing train dataset:  11%|█         | 959/8564 [00:11<01:34, 80.53 examples/s]Tokenizing train dataset:  12%|█▏        | 1031/8564 [00:10<02:21, 53.08 examples/s]Tokenizing train dataset:  11%|█▏        | 970/8564 [00:11<01:28, 85.74 examples/s]Tokenizing train dataset:   8%|▊         | 668/8564 [00:09<01:34, 83.91 examples/s] Tokenizing train dataset:  11%|█▏        | 980/8564 [00:11<01:26, 87.20 examples/s]Tokenizing train dataset:  12%|█▏        | 1040/8564 [00:10<02:21, 53.19 examples/s]Tokenizing train dataset:   8%|▊         | 678/8564 [00:09<01:35, 82.97 examples/s]Tokenizing train dataset:  12%|█▏        | 1049/8564 [00:10<02:06, 59.31 examples/s]Tokenizing train dataset:   8%|▊         | 688/8564 [00:09<01:32, 85.51 examples/s]Tokenizing train dataset:  12%|█▏        | 994/8564 [00:11<01:29, 84.92 examples/s]Tokenizing train dataset:  12%|█▏        | 1059/8564 [00:10<01:52, 66.65 examples/s]Tokenizing train dataset:  12%|█▏        | 1004/8564 [00:11<01:26, 87.77 examples/s]Tokenizing train dataset:   8%|▊         | 699/8564 [00:09<01:37, 80.55 examples/s]Tokenizing train dataset:  12%|█▏        | 1068/8564 [00:10<01:57, 64.03 examples/s]Tokenizing train dataset:   8%|▊         | 708/8564 [00:09<01:42, 76.79 examples/s]Tokenizing train dataset:  12%|█▏        | 1020/8564 [00:12<01:22, 91.29 examples/s]Tokenizing train dataset:  13%|█▎        | 1076/8564 [00:10<01:55, 64.84 examples/s]Tokenizing train dataset:   8%|▊         | 717/8564 [00:09<01:42, 76.53 examples/s]Tokenizing train dataset:  12%|█▏        | 1030/8564 [00:12<01:25, 88.27 examples/s]Tokenizing train dataset:  13%|█▎        | 1087/8564 [00:11<01:43, 72.08 examples/s]Tokenizing train dataset:   8%|▊         | 725/8564 [00:09<01:42, 76.41 examples/s]Tokenizing train dataset:  12%|█▏        | 1042/8564 [00:12<01:23, 89.89 examples/s]Tokenizing train dataset:   9%|▊         | 740/8564 [00:09<01:24, 92.82 examples/s]Tokenizing train dataset:  13%|█▎        | 1099/8564 [00:11<01:40, 73.91 examples/s]Tokenizing train dataset:  12%|█▏        | 1054/8564 [00:12<01:34, 79.26 examples/s]Tokenizing train dataset:   9%|▉         | 750/8564 [00:10<01:29, 87.31 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:11<01:38, 75.58 examples/s]Tokenizing train dataset:  13%|█▎        | 1120/8564 [00:11<01:35, 77.58 examples/s]Tokenizing train dataset:   9%|▉         | 759/8564 [00:10<01:44, 74.86 examples/s]Tokenizing train dataset:  12%|█▏        | 1067/8564 [00:12<01:41, 74.22 examples/s]Tokenizing train dataset:   9%|▉         | 767/8564 [00:10<01:55, 67.35 examples/s]Tokenizing train dataset:  13%|█▎        | 1131/8564 [00:11<01:45, 70.26 examples/s]Tokenizing train dataset:  13%|█▎        | 1079/8564 [00:12<01:46, 70.46 examples/s]Tokenizing train dataset:  13%|█▎        | 1139/8564 [00:11<01:46, 69.89 examples/s]Tokenizing train dataset:  13%|█▎        | 1090/8564 [00:13<01:37, 76.27 examples/s]Tokenizing train dataset:   9%|▉         | 780/8564 [00:10<01:59, 65.11 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:11<01:31, 80.76 examples/s]Tokenizing train dataset:  13%|█▎        | 1099/8564 [00:13<01:39, 74.97 examples/s]Tokenizing train dataset:   9%|▉         | 787/8564 [00:10<02:05, 62.18 examples/s]Tokenizing train dataset:  14%|█▎        | 1160/8564 [00:12<01:42, 71.89 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:13<01:40, 74.05 examples/s]Tokenizing train dataset:   9%|▉         | 795/8564 [00:10<01:59, 64.80 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:12<01:38, 74.85 examples/s]Tokenizing train dataset:  13%|█▎        | 1119/8564 [00:13<01:35, 78.14 examples/s]Tokenizing train dataset:   9%|▉         | 803/8564 [00:10<01:59, 64.68 examples/s]Tokenizing train dataset:  14%|█▍        | 1181/8564 [00:12<01:31, 80.62 examples/s]Tokenizing train dataset:   9%|▉         | 812/8564 [00:11<01:55, 67.06 examples/s]Tokenizing train dataset:  13%|█▎        | 1132/8564 [00:13<01:38, 75.49 examples/s]Tokenizing train dataset:  14%|█▍        | 1193/8564 [00:12<01:35, 76.93 examples/s]Tokenizing train dataset:  13%|█▎        | 1146/8564 [00:13<01:25, 87.00 examples/s]Tokenizing train dataset:  10%|▉         | 820/8564 [00:11<02:10, 59.31 examples/s]Tokenizing train dataset:  14%|█▍        | 1207/8564 [00:12<01:25, 85.68 examples/s]Tokenizing train dataset:  14%|█▎        | 1160/8564 [00:13<01:25, 86.10 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:12<01:23, 88.13 examples/s]Tokenizing train dataset:  10%|▉         | 831/8564 [00:11<02:10, 59.37 examples/s]Tokenizing train dataset:  14%|█▎        | 1170/8564 [00:14<01:26, 85.50 examples/s]Tokenizing train dataset:  14%|█▍        | 1230/8564 [00:12<01:18, 93.20 examples/s]Tokenizing train dataset:  10%|▉         | 840/8564 [00:11<02:04, 62.27 examples/s]Tokenizing train dataset:  14%|█▍        | 1182/8564 [00:14<01:18, 93.44 examples/s]Tokenizing train dataset:  15%|█▍        | 1246/8564 [00:12<01:07, 108.80 examples/s]Tokenizing train dataset:  10%|▉         | 849/8564 [00:11<02:03, 62.64 examples/s]Tokenizing train dataset:  14%|█▍        | 1194/8564 [00:14<01:14, 99.42 examples/s]Tokenizing train dataset:  10%|█         | 857/8564 [00:11<02:01, 63.38 examples/s]Tokenizing train dataset:  14%|█▍        | 1207/8564 [00:14<01:13, 100.14 examples/s]Tokenizing train dataset:  15%|█▍        | 1265/8564 [00:13<01:15, 96.75 examples/s] Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:14<01:14, 98.82 examples/s] Tokenizing train dataset:  10%|█         | 868/8564 [00:11<01:50, 69.59 examples/s]Tokenizing train dataset:  14%|█▍        | 1229/8564 [00:14<01:12, 100.96 examples/s]Tokenizing train dataset:  10%|█         | 879/8564 [00:12<01:42, 75.08 examples/s]Tokenizing train dataset:  15%|█▍        | 1278/8564 [00:13<01:25, 84.84 examples/s]Tokenizing train dataset:  15%|█▍        | 1246/8564 [00:14<01:04, 114.15 examples/s]Tokenizing train dataset:  10%|█         | 897/8564 [00:12<01:16, 99.74 examples/s]Tokenizing train dataset:  15%|█▌        | 1288/8564 [00:13<01:40, 72.73 examples/s]Tokenizing train dataset:  11%|█         | 910/8564 [00:12<01:17, 98.15 examples/s]Tokenizing train dataset:  15%|█▍        | 1264/8564 [00:14<01:09, 105.56 examples/s]Tokenizing train dataset:  15%|█▌        | 1300/8564 [00:13<01:32, 78.74 examples/s]Tokenizing train dataset:  11%|█         | 923/8564 [00:12<01:22, 92.94 examples/s]Tokenizing train dataset:  15%|█▍        | 1277/8564 [00:15<01:12, 100.91 examples/s]Tokenizing train dataset:  15%|█▌        | 1310/8564 [00:13<01:30, 80.29 examples/s]Tokenizing train dataset:  11%|█         | 936/8564 [00:12<01:21, 93.99 examples/s]Tokenizing train dataset:  15%|█▌        | 1293/8564 [00:15<01:13, 99.42 examples/s] Tokenizing train dataset:  11%|█         | 946/8564 [00:12<01:19, 95.37 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:13<01:43, 69.74 examples/s]Tokenizing train dataset:  15%|█▌        | 1308/8564 [00:15<01:06, 108.93 examples/s]Tokenizing train dataset:  11%|█         | 959/8564 [00:12<01:17, 97.94 examples/s]Tokenizing train dataset:  16%|█▌        | 1329/8564 [00:14<01:44, 69.05 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:15<01:12, 99.58 examples/s] Tokenizing train dataset:  11%|█▏        | 971/8564 [00:12<01:15, 100.78 examples/s]Tokenizing train dataset:  16%|█▌        | 1340/8564 [00:14<01:45, 68.64 examples/s]Tokenizing train dataset:  16%|█▌        | 1332/8564 [00:15<01:09, 103.69 examples/s]Tokenizing train dataset:  12%|█▏        | 985/8564 [00:13<01:21, 93.15 examples/s] Tokenizing train dataset:  16%|█▌        | 1348/8564 [00:14<01:44, 69.24 examples/s]Tokenizing train dataset:  16%|█▌        | 1346/8564 [00:15<01:10, 102.88 examples/s]Tokenizing train dataset:  12%|█▏        | 996/8564 [00:13<01:22, 92.28 examples/s]Tokenizing train dataset:  16%|█▌        | 1356/8564 [00:14<02:02, 58.81 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:15<01:16, 94.02 examples/s] Tokenizing train dataset:  12%|█▏        | 1008/8564 [00:13<01:21, 92.42 examples/s]Tokenizing train dataset:  16%|█▌        | 1365/8564 [00:14<01:56, 61.75 examples/s]Tokenizing train dataset:  16%|█▌        | 1371/8564 [00:16<01:18, 91.92 examples/s]Tokenizing train dataset:  12%|█▏        | 1019/8564 [00:13<01:21, 92.83 examples/s]Tokenizing train dataset:  16%|█▌        | 1384/8564 [00:16<01:14, 96.84 examples/s]Tokenizing train dataset:  12%|█▏        | 1029/8564 [00:13<01:23, 90.47 examples/s]Tokenizing train dataset:  16%|█▌        | 1373/8564 [00:14<02:05, 57.40 examples/s]Tokenizing train dataset:  16%|█▋        | 1394/8564 [00:16<01:14, 96.54 examples/s]Tokenizing train dataset:  16%|█▌        | 1383/8564 [00:14<01:55, 62.34 examples/s]Tokenizing train dataset:  12%|█▏        | 1039/8564 [00:13<01:37, 76.91 examples/s]Tokenizing train dataset:  16%|█▋        | 1408/8564 [00:16<01:11, 99.82 examples/s]Tokenizing train dataset:  16%|█▋        | 1397/8564 [00:15<01:36, 74.29 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:15<01:31, 78.64 examples/s]Tokenizing train dataset:  12%|█▏        | 1054/8564 [00:14<01:38, 76.03 examples/s]Tokenizing train dataset:  17%|█▋        | 1422/8564 [00:16<01:21, 87.26 examples/s]Tokenizing train dataset:  17%|█▋        | 1418/8564 [00:15<01:24, 84.29 examples/s]Tokenizing train dataset:  12%|█▏        | 1067/8564 [00:14<01:41, 74.12 examples/s]Tokenizing train dataset:  17%|█▋        | 1433/8564 [00:16<01:28, 80.77 examples/s]Tokenizing train dataset:  17%|█▋        | 1429/8564 [00:15<01:19, 89.35 examples/s]Tokenizing train dataset:  13%|█▎        | 1079/8564 [00:14<01:42, 73.20 examples/s]Tokenizing train dataset:  17%|█▋        | 1444/8564 [00:15<01:19, 89.19 examples/s]Tokenizing train dataset:  17%|█▋        | 1444/8564 [00:16<01:42, 69.40 examples/s]Tokenizing train dataset:  13%|█▎        | 1089/8564 [00:14<01:38, 76.27 examples/s]Tokenizing train dataset:  17%|█▋        | 1456/8564 [00:15<01:17, 91.86 examples/s]Tokenizing train dataset:  17%|█▋        | 1452/8564 [00:17<01:42, 69.65 examples/s]Tokenizing train dataset:  17%|█▋        | 1468/8564 [00:15<01:13, 96.55 examples/s]Tokenizing train dataset:  13%|█▎        | 1099/8564 [00:14<01:45, 70.94 examples/s]Tokenizing train dataset:  17%|█▋        | 1463/8564 [00:17<01:44, 68.14 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:15<01:15, 93.43 examples/s]Tokenizing train dataset:  13%|█▎        | 1110/8564 [00:14<01:49, 67.84 examples/s]Tokenizing train dataset:  17%|█▋        | 1472/8564 [00:17<01:42, 69.02 examples/s]Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:16<01:17, 90.88 examples/s]Tokenizing train dataset:  13%|█▎        | 1120/8564 [00:14<01:51, 66.48 examples/s]Tokenizing train dataset:  18%|█▊        | 1501/8564 [00:16<01:14, 94.78 examples/s]Tokenizing train dataset:  17%|█▋        | 1480/8564 [00:17<01:54, 61.93 examples/s]Tokenizing train dataset:  18%|█▊        | 1511/8564 [00:16<01:17, 91.58 examples/s]Tokenizing train dataset:  17%|█▋        | 1489/8564 [00:17<01:46, 66.33 examples/s]Tokenizing train dataset:  13%|█▎        | 1131/8564 [00:15<02:04, 59.69 examples/s]Tokenizing train dataset:  18%|█▊        | 1500/8564 [00:17<01:44, 67.58 examples/s]Tokenizing train dataset:  18%|█▊        | 1523/8564 [00:16<01:28, 79.89 examples/s]Tokenizing train dataset:  13%|█▎        | 1143/8564 [00:15<01:45, 70.48 examples/s]Tokenizing train dataset:  18%|█▊        | 1507/8564 [00:17<01:47, 65.40 examples/s]Tokenizing train dataset:  13%|█▎        | 1153/8564 [00:15<01:37, 76.25 examples/s]Tokenizing train dataset:  18%|█▊        | 1535/8564 [00:16<01:26, 80.94 examples/s]Tokenizing train dataset:  18%|█▊        | 1546/8564 [00:16<01:26, 81.40 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:18<01:58, 59.38 examples/s]Tokenizing train dataset:  14%|█▎        | 1167/8564 [00:15<01:34, 78.66 examples/s]Tokenizing train dataset:  14%|█▍        | 1178/8564 [00:15<01:29, 82.72 examples/s]Tokenizing train dataset:  18%|█▊        | 1527/8564 [00:18<01:46, 66.28 examples/s]Tokenizing train dataset:  18%|█▊        | 1555/8564 [00:16<01:39, 70.14 examples/s]Tokenizing train dataset:  14%|█▍        | 1192/8564 [00:15<01:20, 91.68 examples/s]Tokenizing train dataset:  18%|█▊        | 1538/8564 [00:18<01:40, 70.24 examples/s]Tokenizing train dataset:  18%|█▊        | 1565/8564 [00:17<01:39, 70.37 examples/s]Tokenizing train dataset:  14%|█▍        | 1206/8564 [00:15<01:14, 98.61 examples/s]Tokenizing train dataset:  18%|█▊        | 1548/8564 [00:18<01:43, 67.78 examples/s]Tokenizing train dataset:  18%|█▊        | 1573/8564 [00:17<01:47, 64.99 examples/s]Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:16<01:15, 97.34 examples/s]Tokenizing train dataset:  18%|█▊        | 1580/8564 [00:17<01:47, 65.14 examples/s]Tokenizing train dataset:  18%|█▊        | 1557/8564 [00:18<01:47, 65.04 examples/s]Tokenizing train dataset:  14%|█▍        | 1235/8564 [00:16<01:12, 101.68 examples/s]Tokenizing train dataset:  19%|█▊        | 1587/8564 [00:17<01:45, 65.99 examples/s]Tokenizing train dataset:  18%|█▊        | 1566/8564 [00:18<01:43, 67.42 examples/s]Tokenizing train dataset:  15%|█▍        | 1251/8564 [00:16<01:06, 109.54 examples/s]Tokenizing train dataset:  19%|█▊        | 1595/8564 [00:17<01:43, 67.26 examples/s]Tokenizing train dataset:  18%|█▊        | 1574/8564 [00:18<01:44, 66.80 examples/s]Tokenizing train dataset:  15%|█▍        | 1264/8564 [00:16<01:04, 113.65 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:17<01:26, 79.97 examples/s]Tokenizing train dataset:  18%|█▊        | 1583/8564 [00:19<01:47, 65.11 examples/s]Tokenizing train dataset:  15%|█▍        | 1277/8564 [00:16<01:07, 108.71 examples/s]Tokenizing train dataset:  19%|█▉        | 1621/8564 [00:17<01:22, 84.03 examples/s]Tokenizing train dataset:  19%|█▊        | 1592/8564 [00:19<01:51, 62.63 examples/s]Tokenizing train dataset:  15%|█▌        | 1292/8564 [00:16<01:10, 102.52 examples/s]Tokenizing train dataset:  19%|█▉        | 1630/8564 [00:17<01:30, 76.38 examples/s]Tokenizing train dataset:  19%|█▉        | 1606/8564 [00:19<01:32, 75.46 examples/s]Tokenizing train dataset:  15%|█▌        | 1308/8564 [00:16<01:04, 112.14 examples/s]Tokenizing train dataset:  19%|█▉        | 1643/8564 [00:18<01:18, 87.99 examples/s]Tokenizing train dataset:  19%|█▉        | 1653/8564 [00:18<01:18, 88.35 examples/s]Tokenizing train dataset:  19%|█▉        | 1617/8564 [00:19<01:37, 71.26 examples/s]Tokenizing train dataset:  15%|█▌        | 1324/8564 [00:17<01:07, 107.07 examples/s]Tokenizing train dataset:  19%|█▉        | 1664/8564 [00:18<01:17, 89.58 examples/s]Tokenizing train dataset:  16%|█▌        | 1335/8564 [00:17<01:07, 107.43 examples/s]Tokenizing train dataset:  19%|█▉        | 1626/8564 [00:19<01:45, 65.84 examples/s]Tokenizing train dataset:  20%|█▉        | 1677/8564 [00:18<01:10, 97.00 examples/s]Tokenizing train dataset:  16%|█▌        | 1346/8564 [00:17<01:08, 104.67 examples/s]Tokenizing train dataset:  19%|█▉        | 1640/8564 [00:19<01:25, 81.31 examples/s]Tokenizing train dataset:  20%|█▉        | 1690/8564 [00:18<01:09, 98.39 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:19<01:25, 80.41 examples/s]Tokenizing train dataset:  16%|█▌        | 1360/8564 [00:17<01:18, 92.33 examples/s] Tokenizing train dataset:  20%|█▉        | 1707/8564 [00:18<01:00, 112.74 examples/s]Tokenizing train dataset:  16%|█▌        | 1370/8564 [00:17<01:19, 90.10 examples/s]Tokenizing train dataset:  19%|█▉        | 1662/8564 [00:20<01:36, 71.81 examples/s]Tokenizing train dataset:  20%|██        | 1722/8564 [00:18<01:05, 104.93 examples/s]Tokenizing train dataset:  16%|█▌        | 1380/8564 [00:17<01:20, 89.74 examples/s]Tokenizing train dataset:  20%|█▉        | 1676/8564 [00:20<01:23, 82.56 examples/s]Tokenizing train dataset:  20%|██        | 1734/8564 [00:18<01:06, 103.27 examples/s]Tokenizing train dataset:  20%|█▉        | 1690/8564 [00:20<01:12, 95.22 examples/s]Tokenizing train dataset:  16%|█▋        | 1392/8564 [00:17<01:31, 78.26 examples/s]Tokenizing train dataset:  20%|██        | 1746/8564 [00:19<01:06, 103.20 examples/s]Tokenizing train dataset:  20%|█▉        | 1707/8564 [00:20<01:02, 109.06 examples/s]Tokenizing train dataset:  21%|██        | 1761/8564 [00:19<01:00, 113.17 examples/s]Tokenizing train dataset:  16%|█▋        | 1403/8564 [00:18<01:38, 72.67 examples/s]Tokenizing train dataset:  20%|██        | 1719/8564 [00:20<01:03, 108.50 examples/s]Tokenizing train dataset:  21%|██        | 1776/8564 [00:19<01:06, 102.54 examples/s]Tokenizing train dataset:  16%|█▋        | 1413/8564 [00:18<01:39, 71.94 examples/s]Tokenizing train dataset:  20%|██        | 1734/8564 [00:20<01:07, 100.50 examples/s]Tokenizing train dataset:  21%|██        | 1787/8564 [00:19<01:05, 103.84 examples/s]Tokenizing train dataset:  17%|█▋        | 1421/8564 [00:18<01:42, 69.54 examples/s]Tokenizing train dataset:  21%|██        | 1798/8564 [00:19<01:04, 104.95 examples/s]Tokenizing train dataset:  20%|██        | 1747/8564 [00:20<01:06, 102.28 examples/s]Tokenizing train dataset:  17%|█▋        | 1429/8564 [00:18<01:45, 67.72 examples/s]Tokenizing train dataset:  21%|██        | 1809/8564 [00:19<01:04, 104.80 examples/s]Tokenizing train dataset:  21%|██        | 1760/8564 [00:21<01:02, 108.04 examples/s]Tokenizing train dataset:  21%|██        | 1774/8564 [00:21<01:04, 105.34 examples/s]Tokenizing train dataset:  21%|██▏       | 1821/8564 [00:19<01:12, 92.99 examples/s] Tokenizing train dataset:  17%|█▋        | 1438/8564 [00:18<02:04, 57.17 examples/s]Tokenizing train dataset:  21%|██        | 1785/8564 [00:21<01:05, 102.78 examples/s]Tokenizing train dataset:  17%|█▋        | 1449/8564 [00:18<01:48, 65.36 examples/s]Tokenizing train dataset:  21%|██▏       | 1837/8564 [00:20<01:16, 87.89 examples/s]Tokenizing train dataset:  21%|██        | 1797/8564 [00:21<01:04, 105.10 examples/s]Tokenizing train dataset:  17%|█▋        | 1456/8564 [00:18<01:53, 62.85 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:21<01:06, 101.32 examples/s]Tokenizing train dataset:  17%|█▋        | 1464/8564 [00:19<01:49, 64.86 examples/s]Tokenizing train dataset:  22%|██▏       | 1849/8564 [00:20<01:26, 77.68 examples/s]Tokenizing train dataset:  17%|█▋        | 1471/8564 [00:19<01:50, 64.20 examples/s]Tokenizing train dataset:  21%|██▏       | 1830/8564 [00:21<01:07, 100.47 examples/s]Tokenizing train dataset:  22%|██▏       | 1859/8564 [00:20<01:36, 69.47 examples/s]Tokenizing train dataset:  17%|█▋        | 1479/8564 [00:19<01:50, 64.05 examples/s]Tokenizing train dataset:  22%|██▏       | 1843/8564 [00:21<01:03, 106.27 examples/s]Tokenizing train dataset:  22%|██▏       | 1867/8564 [00:20<01:38, 67.94 examples/s]Tokenizing train dataset:  22%|██▏       | 1858/8564 [00:21<01:08, 98.36 examples/s] Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:19<01:57, 60.45 examples/s]Tokenizing train dataset:  22%|██▏       | 1875/8564 [00:20<01:41, 66.12 examples/s]Tokenizing train dataset:  22%|██▏       | 1870/8564 [00:22<01:07, 98.64 examples/s]Tokenizing train dataset:  18%|█▊        | 1501/8564 [00:19<01:56, 60.51 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:20<01:40, 66.39 examples/s]Tokenizing train dataset:  22%|██▏       | 1881/8564 [00:22<01:10, 94.52 examples/s]Tokenizing train dataset:  22%|██▏       | 1894/8564 [00:20<01:44, 64.07 examples/s]Tokenizing train dataset:  18%|█▊        | 1509/8564 [00:19<02:02, 57.77 examples/s]Tokenizing train dataset:  22%|██▏       | 1893/8564 [00:22<01:06, 100.11 examples/s]Tokenizing train dataset:  22%|██▏       | 1909/8564 [00:21<01:25, 77.86 examples/s]Tokenizing train dataset:  22%|██▏       | 1912/8564 [00:22<00:56, 117.96 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:19<02:04, 56.56 examples/s]Tokenizing train dataset:  22%|██▏       | 1921/8564 [00:21<01:17, 86.24 examples/s]Tokenizing train dataset:  23%|██▎       | 1930/8564 [00:22<00:52, 127.17 examples/s]Tokenizing train dataset:  18%|█▊        | 1527/8564 [00:20<01:51, 63.08 examples/s]Tokenizing train dataset:  23%|██▎       | 1931/8564 [00:21<01:22, 80.03 examples/s]Tokenizing train dataset:  18%|█▊        | 1540/8564 [00:20<01:37, 71.90 examples/s]Tokenizing train dataset:  23%|██▎       | 1945/8564 [00:22<01:00, 109.37 examples/s]Tokenizing train dataset:  23%|██▎       | 1944/8564 [00:21<01:13, 90.48 examples/s]Tokenizing train dataset:  18%|█▊        | 1548/8564 [00:20<01:39, 70.33 examples/s]Tokenizing train dataset:  23%|██▎       | 1957/8564 [00:22<01:00, 109.81 examples/s]Tokenizing train dataset:  23%|██▎       | 1954/8564 [00:21<01:11, 92.42 examples/s]Tokenizing train dataset:  23%|██▎       | 1970/8564 [00:22<00:59, 110.49 examples/s]Tokenizing train dataset:  23%|██▎       | 1968/8564 [00:21<01:05, 100.11 examples/s]Tokenizing train dataset:  18%|█▊        | 1560/8564 [00:20<01:43, 67.95 examples/s]Tokenizing train dataset:  23%|██▎       | 1984/8564 [00:23<00:57, 113.78 examples/s]Tokenizing train dataset:  23%|██▎       | 1981/8564 [00:21<01:03, 103.21 examples/s]Tokenizing train dataset:  18%|█▊        | 1568/8564 [00:20<01:45, 66.26 examples/s]Tokenizing train dataset:  23%|██▎       | 1998/8564 [00:23<00:54, 119.66 examples/s]Tokenizing train dataset:  23%|██▎       | 1994/8564 [00:21<01:02, 105.33 examples/s]Tokenizing train dataset:  24%|██▎       | 2017/8564 [00:23<00:54, 120.35 examples/s]Tokenizing train dataset:  23%|██▎       | 2008/8564 [00:22<00:58, 112.70 examples/s]Tokenizing train dataset:  18%|█▊        | 1580/8564 [00:20<01:58, 58.83 examples/s]Tokenizing train dataset:  24%|██▎       | 2030/8564 [00:23<00:55, 117.09 examples/s]Tokenizing train dataset:  24%|██▎       | 2022/8564 [00:22<00:56, 115.15 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:20<01:44, 66.53 examples/s]Tokenizing train dataset:  24%|██▍       | 2039/8564 [00:22<00:52, 124.00 examples/s]Tokenizing train dataset:  24%|██▍       | 2048/8564 [00:23<00:58, 111.57 examples/s]Tokenizing train dataset:  19%|█▊        | 1600/8564 [00:21<01:41, 68.48 examples/s]Tokenizing train dataset:  24%|██▍       | 2052/8564 [00:22<00:54, 120.45 examples/s]Tokenizing train dataset:  19%|█▉        | 1610/8564 [00:21<01:34, 73.66 examples/s]Tokenizing train dataset:  24%|██▍       | 2063/8564 [00:23<00:57, 113.33 examples/s]Tokenizing train dataset:  24%|██▍       | 2068/8564 [00:22<00:58, 111.25 examples/s]Tokenizing train dataset:  24%|██▍       | 2075/8564 [00:23<00:58, 111.80 examples/s]Tokenizing train dataset:  19%|█▉        | 1621/8564 [00:21<01:35, 72.76 examples/s]Tokenizing train dataset:  24%|██▍       | 2081/8564 [00:22<00:58, 110.00 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:24<00:58, 110.85 examples/s]Tokenizing train dataset:  19%|█▉        | 1630/8564 [00:21<01:37, 70.97 examples/s]Tokenizing train dataset:  24%|██▍       | 2097/8564 [00:22<00:56, 113.70 examples/s]Tokenizing train dataset:  25%|██▍       | 2105/8564 [00:24<00:57, 112.80 examples/s]Tokenizing train dataset:  19%|█▉        | 1639/8564 [00:21<01:36, 71.61 examples/s]Tokenizing train dataset:  25%|██▍       | 2111/8564 [00:22<00:56, 114.84 examples/s]Tokenizing train dataset:  25%|██▍       | 2117/8564 [00:24<00:56, 113.53 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:21<01:28, 78.02 examples/s]Tokenizing train dataset:  25%|██▍       | 2126/8564 [00:23<00:54, 118.18 examples/s]Tokenizing train dataset:  25%|██▍       | 2132/8564 [00:24<00:55, 115.81 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:21<01:34, 73.16 examples/s]Tokenizing train dataset:  25%|██▌       | 2147/8564 [00:24<00:59, 107.34 examples/s]Tokenizing train dataset:  25%|██▌       | 2143/8564 [00:23<00:58, 109.08 examples/s]Tokenizing train dataset:  20%|█▉        | 1673/8564 [00:22<01:27, 79.20 examples/s]Tokenizing train dataset:  25%|██▌       | 2159/8564 [00:24<00:59, 106.88 examples/s]Tokenizing train dataset:  25%|██▌       | 2155/8564 [00:23<01:05, 98.39 examples/s] Tokenizing train dataset:  20%|█▉        | 1686/8564 [00:22<01:23, 82.80 examples/s]Tokenizing train dataset:  25%|██▌       | 2170/8564 [00:24<01:02, 103.12 examples/s]Tokenizing train dataset:  25%|██▌       | 2169/8564 [00:23<01:00, 105.11 examples/s]Tokenizing train dataset:  20%|█▉        | 1700/8564 [00:22<01:17, 88.82 examples/s]Tokenizing train dataset:  25%|██▌       | 2182/8564 [00:24<01:03, 100.08 examples/s]Tokenizing train dataset:  25%|██▌       | 2181/8564 [00:23<00:59, 107.98 examples/s]Tokenizing train dataset:  20%|██        | 1713/8564 [00:22<01:15, 90.34 examples/s]Tokenizing train dataset:  26%|██▌       | 2196/8564 [00:23<00:56, 113.19 examples/s]Tokenizing train dataset:  26%|██▌       | 2196/8564 [00:25<01:08, 93.04 examples/s] Tokenizing train dataset:  26%|██▌       | 2209/8564 [00:23<00:55, 114.02 examples/s]Tokenizing train dataset:  26%|██▌       | 2210/8564 [00:25<01:06, 95.65 examples/s]Tokenizing train dataset:  26%|██▌       | 2224/8564 [00:23<00:51, 122.34 examples/s]Tokenizing train dataset:  20%|██        | 1725/8564 [00:22<01:38, 69.55 examples/s]Tokenizing train dataset:  26%|██▌       | 2225/8564 [00:25<01:00, 105.45 examples/s]Tokenizing train dataset:  26%|██▌       | 2238/8564 [00:24<00:52, 120.01 examples/s]Tokenizing train dataset:  20%|██        | 1736/8564 [00:22<01:29, 76.15 examples/s]Tokenizing train dataset:  26%|██▋       | 2251/8564 [00:24<00:52, 121.28 examples/s]Tokenizing train dataset:  26%|██▌       | 2241/8564 [00:25<01:03, 99.00 examples/s] Tokenizing train dataset:  20%|██        | 1750/8564 [00:22<01:20, 85.05 examples/s]Tokenizing train dataset:  21%|██        | 1763/8564 [00:23<01:14, 91.34 examples/s]Tokenizing train dataset:  27%|██▋       | 2275/8564 [00:24<00:50, 123.56 examples/s]Tokenizing train dataset:  26%|██▋       | 2254/8564 [00:25<01:14, 84.58 examples/s]Tokenizing train dataset:  21%|██        | 1773/8564 [00:23<01:15, 89.72 examples/s]Tokenizing train dataset:  27%|██▋       | 2290/8564 [00:24<00:53, 117.93 examples/s]Tokenizing train dataset:  26%|██▋       | 2263/8564 [00:25<01:14, 84.62 examples/s]Tokenizing train dataset:  21%|██        | 1787/8564 [00:23<01:17, 87.55 examples/s]Tokenizing train dataset:  27%|██▋       | 2283/8564 [00:25<00:57, 109.00 examples/s]Tokenizing train dataset:  27%|██▋       | 2304/8564 [00:24<01:01, 102.07 examples/s]Tokenizing train dataset:  21%|██        | 1799/8564 [00:23<01:12, 92.75 examples/s]Tokenizing train dataset:  27%|██▋       | 2299/8564 [00:26<01:01, 101.91 examples/s]Tokenizing train dataset:  21%|██        | 1813/8564 [00:23<01:07, 100.25 examples/s]Tokenizing train dataset:  27%|██▋       | 2318/8564 [00:24<01:10, 88.46 examples/s] Tokenizing train dataset:  21%|██▏       | 1828/8564 [00:23<01:09, 96.75 examples/s] Tokenizing train dataset:  27%|██▋       | 2328/8564 [00:25<01:10, 88.15 examples/s]Tokenizing train dataset:  27%|██▋       | 2311/8564 [00:26<01:15, 82.36 examples/s] Tokenizing train dataset:  21%|██▏       | 1840/8564 [00:23<01:07, 99.22 examples/s]Tokenizing train dataset:  27%|██▋       | 2339/8564 [00:25<01:16, 80.89 examples/s]Tokenizing train dataset:  27%|██▋       | 2324/8564 [00:26<01:17, 80.14 examples/s]Tokenizing train dataset:  22%|██▏       | 1852/8564 [00:24<01:07, 99.41 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:25<01:14, 82.95 examples/s]Tokenizing train dataset:  27%|██▋       | 2337/8564 [00:26<01:15, 81.98 examples/s]Tokenizing train dataset:  22%|██▏       | 1867/8564 [00:24<01:09, 95.70 examples/s]Tokenizing train dataset:  28%|██▊       | 2358/8564 [00:25<01:26, 72.01 examples/s]Tokenizing train dataset:  27%|██▋       | 2348/8564 [00:26<01:23, 74.08 examples/s]Tokenizing train dataset:  22%|██▏       | 1881/8564 [00:24<01:11, 92.99 examples/s]Tokenizing train dataset:  28%|██▊       | 2369/8564 [00:25<01:19, 78.30 examples/s]Tokenizing train dataset:  22%|██▏       | 1894/8564 [00:24<01:07, 99.00 examples/s]Tokenizing train dataset:  28%|██▊       | 2358/8564 [00:26<01:23, 74.12 examples/s]Tokenizing train dataset:  28%|██▊       | 2379/8564 [00:25<01:27, 70.69 examples/s]Tokenizing train dataset:  28%|██▊       | 2370/8564 [00:27<01:17, 80.28 examples/s]Tokenizing train dataset:  22%|██▏       | 1913/8564 [00:24<01:00, 110.15 examples/s]Tokenizing train dataset:  28%|██▊       | 2395/8564 [00:25<01:09, 88.89 examples/s]Tokenizing train dataset:  28%|██▊       | 2380/8564 [00:27<01:15, 81.47 examples/s]Tokenizing train dataset:  28%|██▊       | 2408/8564 [00:25<01:05, 94.34 examples/s]Tokenizing train dataset:  23%|██▎       | 1928/8564 [00:24<01:06, 99.78 examples/s] Tokenizing train dataset:  28%|██▊       | 2392/8564 [00:27<01:12, 84.77 examples/s]Tokenizing train dataset:  28%|██▊       | 2420/8564 [00:26<01:02, 98.41 examples/s]Tokenizing train dataset:  23%|██▎       | 1940/8564 [00:24<01:05, 101.61 examples/s]Tokenizing train dataset:  28%|██▊       | 2407/8564 [00:27<01:02, 98.69 examples/s]Tokenizing train dataset:  23%|██▎       | 1951/8564 [00:25<01:07, 97.63 examples/s] Tokenizing train dataset:  28%|██▊       | 2419/8564 [00:27<01:01, 99.87 examples/s]Tokenizing train dataset:  28%|██▊       | 2436/8564 [00:26<01:09, 88.25 examples/s]Tokenizing train dataset:  28%|██▊       | 2430/8564 [00:27<01:00, 101.37 examples/s]Tokenizing train dataset:  23%|██▎       | 1961/8564 [00:25<01:19, 82.89 examples/s]Tokenizing train dataset:  29%|██▊       | 2448/8564 [00:26<01:06, 92.22 examples/s]Tokenizing train dataset:  29%|██▊       | 2446/8564 [00:27<00:54, 111.94 examples/s]Tokenizing train dataset:  29%|██▊       | 2462/8564 [00:26<00:59, 102.24 examples/s]Tokenizing train dataset:  23%|██▎       | 1972/8564 [00:25<01:18, 83.75 examples/s]Tokenizing train dataset:  29%|██▉       | 2463/8564 [00:27<00:57, 106.61 examples/s]Tokenizing train dataset:  29%|██▉       | 2476/8564 [00:26<00:58, 103.86 examples/s]Tokenizing train dataset:  23%|██▎       | 1988/8564 [00:25<01:08, 96.19 examples/s]Tokenizing train dataset:  23%|██▎       | 1999/8564 [00:25<01:06, 98.12 examples/s]Tokenizing train dataset:  29%|██▉       | 2487/8564 [00:26<01:01, 99.59 examples/s] Tokenizing train dataset:  29%|██▉       | 2474/8564 [00:28<01:05, 93.21 examples/s] Tokenizing train dataset:  29%|██▉       | 2498/8564 [00:26<01:00, 100.79 examples/s]Tokenizing train dataset:  29%|██▉       | 2488/8564 [00:28<01:01, 98.21 examples/s]Tokenizing train dataset:  24%|██▎       | 2014/8564 [00:25<01:14, 87.34 examples/s]Tokenizing train dataset:  29%|██▉       | 2500/8564 [00:28<01:02, 97.62 examples/s]Tokenizing train dataset:  29%|██▉       | 2512/8564 [00:27<01:08, 88.19 examples/s] Tokenizing train dataset:  24%|██▎       | 2026/8564 [00:25<01:13, 88.41 examples/s]Tokenizing train dataset:  29%|██▉       | 2513/8564 [00:28<00:58, 103.35 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:27<00:56, 107.14 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:28<00:50, 118.71 examples/s]Tokenizing train dataset:  24%|██▍       | 2040/8564 [00:26<01:17, 83.96 examples/s]Tokenizing train dataset:  30%|██▉       | 2546/8564 [00:27<00:59, 100.73 examples/s]Tokenizing train dataset:  30%|██▉       | 2545/8564 [00:28<00:50, 119.58 examples/s]Tokenizing train dataset:  24%|██▍       | 2050/8564 [00:26<01:17, 83.63 examples/s]Tokenizing train dataset:  30%|██▉       | 2562/8564 [00:27<00:54, 110.64 examples/s]Tokenizing train dataset:  30%|██▉       | 2561/8564 [00:28<00:48, 124.76 examples/s]Tokenizing train dataset:  24%|██▍       | 2061/8564 [00:26<01:15, 86.21 examples/s]Tokenizing train dataset:  30%|███       | 2578/8564 [00:27<00:50, 119.06 examples/s]Tokenizing train dataset:  30%|███       | 2576/8564 [00:28<00:46, 128.13 examples/s]Tokenizing train dataset:  24%|██▍       | 2072/8564 [00:26<01:23, 77.84 examples/s]Tokenizing train dataset:  30%|███       | 2598/8564 [00:27<00:50, 117.86 examples/s]Tokenizing train dataset:  30%|███       | 2593/8564 [00:29<00:49, 119.81 examples/s]Tokenizing train dataset:  24%|██▍       | 2086/8564 [00:26<01:20, 80.70 examples/s]Tokenizing train dataset:  31%|███       | 2613/8564 [00:27<00:48, 123.14 examples/s]Tokenizing train dataset:  30%|███       | 2607/8564 [00:29<00:51, 115.47 examples/s]Tokenizing train dataset:  24%|██▍       | 2095/8564 [00:26<01:23, 77.36 examples/s]Tokenizing train dataset:  31%|███       | 2628/8564 [00:28<00:53, 110.78 examples/s]Tokenizing train dataset:  25%|██▍       | 2106/8564 [00:26<01:19, 81.71 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:29<01:06, 88.91 examples/s] Tokenizing train dataset:  31%|███       | 2645/8564 [00:28<00:54, 108.61 examples/s]Tokenizing train dataset:  25%|██▍       | 2119/8564 [00:27<01:16, 84.23 examples/s]Tokenizing train dataset:  31%|███       | 2631/8564 [00:29<01:04, 92.27 examples/s]Tokenizing train dataset:  31%|███       | 2644/8564 [00:29<01:00, 98.26 examples/s]Tokenizing train dataset:  25%|██▍       | 2129/8564 [00:27<01:17, 83.26 examples/s]Tokenizing train dataset:  31%|███       | 2662/8564 [00:28<01:05, 90.00 examples/s] Tokenizing train dataset:  31%|███       | 2655/8564 [00:29<00:59, 99.76 examples/s]Tokenizing train dataset:  25%|██▍       | 2138/8564 [00:27<01:19, 81.16 examples/s]Tokenizing train dataset:  31%|███       | 2667/8564 [00:29<00:56, 103.98 examples/s]Tokenizing train dataset:  25%|██▌       | 2149/8564 [00:27<01:17, 82.96 examples/s]Tokenizing train dataset:  31%|███       | 2676/8564 [00:28<01:14, 79.57 examples/s]Tokenizing train dataset:  31%|███▏      | 2678/8564 [00:30<00:58, 99.90 examples/s] Tokenizing train dataset:  25%|██▌       | 2158/8564 [00:27<01:18, 81.39 examples/s]Tokenizing train dataset:  31%|███▏      | 2689/8564 [00:28<01:08, 85.58 examples/s]Tokenizing train dataset:  31%|███▏      | 2692/8564 [00:30<01:06, 87.95 examples/s]Tokenizing train dataset:  25%|██▌       | 2170/8564 [00:27<01:24, 75.54 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:28<01:01, 95.47 examples/s]Tokenizing train dataset:  32%|███▏      | 2703/8564 [00:30<01:05, 89.31 examples/s]Tokenizing train dataset:  25%|██▌       | 2180/8564 [00:27<01:23, 76.50 examples/s]Tokenizing train dataset:  32%|███▏      | 2720/8564 [00:29<00:56, 103.92 examples/s]Tokenizing train dataset:  32%|███▏      | 2715/8564 [00:30<01:04, 90.65 examples/s]Tokenizing train dataset:  26%|██▌       | 2194/8564 [00:27<01:12, 88.45 examples/s]Tokenizing train dataset:  32%|███▏      | 2732/8564 [00:29<00:56, 104.05 examples/s]Tokenizing train dataset:  32%|███▏      | 2743/8564 [00:29<00:55, 104.38 examples/s]Tokenizing train dataset:  26%|██▌       | 2206/8564 [00:28<01:09, 91.68 examples/s]Tokenizing train dataset:  32%|███▏      | 2727/8564 [00:30<01:07, 86.16 examples/s]Tokenizing train dataset:  26%|██▌       | 2220/8564 [00:28<01:01, 102.96 examples/s]Tokenizing train dataset:  32%|███▏      | 2756/8564 [00:29<00:54, 106.38 examples/s]Tokenizing train dataset:  32%|███▏      | 2737/8564 [00:30<01:16, 76.12 examples/s]Tokenizing train dataset:  26%|██▌       | 2233/8564 [00:28<00:59, 106.20 examples/s]Tokenizing train dataset:  32%|███▏      | 2770/8564 [00:29<00:54, 105.77 examples/s]Tokenizing train dataset:  26%|██▋       | 2249/8564 [00:28<00:56, 112.33 examples/s]Tokenizing train dataset:  33%|███▎      | 2786/8564 [00:29<00:49, 115.60 examples/s]Tokenizing train dataset:  32%|███▏      | 2750/8564 [00:30<01:18, 74.54 examples/s]Tokenizing train dataset:  26%|██▋       | 2264/8564 [00:28<00:54, 115.47 examples/s]Tokenizing train dataset:  33%|███▎      | 2799/8564 [00:29<00:50, 114.81 examples/s]Tokenizing train dataset:  32%|███▏      | 2759/8564 [00:31<01:22, 70.31 examples/s]Tokenizing train dataset:  33%|███▎      | 2812/8564 [00:29<00:48, 118.35 examples/s]Tokenizing train dataset:  27%|██▋       | 2282/8564 [00:28<00:49, 126.01 examples/s]Tokenizing train dataset:  32%|███▏      | 2769/8564 [00:31<01:19, 72.82 examples/s]Tokenizing train dataset:  33%|███▎      | 2826/8564 [00:29<00:46, 123.57 examples/s]Tokenizing train dataset:  27%|██▋       | 2299/8564 [00:28<00:48, 130.40 examples/s]Tokenizing train dataset:  32%|███▏      | 2777/8564 [00:31<01:23, 69.38 examples/s]Tokenizing train dataset:  33%|███▎      | 2840/8564 [00:30<00:56, 100.95 examples/s]Tokenizing train dataset:  33%|███▎      | 2789/8564 [00:31<01:12, 79.68 examples/s]Tokenizing train dataset:  27%|██▋       | 2318/8564 [00:28<00:55, 111.64 examples/s]Tokenizing train dataset:  33%|███▎      | 2798/8564 [00:31<01:14, 77.53 examples/s]Tokenizing train dataset:  27%|██▋       | 2331/8564 [00:29<00:54, 115.07 examples/s]Tokenizing train dataset:  33%|███▎      | 2854/8564 [00:30<01:02, 91.35 examples/s] Tokenizing train dataset:  33%|███▎      | 2809/8564 [00:31<01:11, 80.94 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:29<00:55, 111.00 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:31<01:07, 85.13 examples/s]Tokenizing train dataset:  33%|███▎      | 2866/8564 [00:30<01:14, 76.82 examples/s]Tokenizing train dataset:  28%|██▊       | 2369/8564 [00:29<00:54, 113.90 examples/s]Tokenizing train dataset:  33%|███▎      | 2829/8564 [00:31<01:11, 79.96 examples/s]Tokenizing train dataset:  34%|███▎      | 2875/8564 [00:30<01:19, 72.00 examples/s]Tokenizing train dataset:  28%|██▊       | 2384/8564 [00:29<00:52, 116.65 examples/s]Tokenizing train dataset:  34%|███▍      | 2891/8564 [00:30<01:03, 89.32 examples/s]Tokenizing train dataset:  33%|███▎      | 2840/8564 [00:32<01:18, 72.49 examples/s]Tokenizing train dataset:  34%|███▍      | 2908/8564 [00:30<00:53, 106.37 examples/s]Tokenizing train dataset:  28%|██▊       | 2400/8564 [00:29<00:56, 109.76 examples/s]Tokenizing train dataset:  33%|███▎      | 2851/8564 [00:32<01:13, 77.92 examples/s]Tokenizing train dataset:  34%|███▍      | 2924/8564 [00:31<00:52, 106.45 examples/s]Tokenizing train dataset:  33%|███▎      | 2864/8564 [00:32<01:11, 79.72 examples/s]Tokenizing train dataset:  28%|██▊       | 2413/8564 [00:29<01:08, 89.95 examples/s] Tokenizing train dataset:  34%|███▍      | 2936/8564 [00:31<00:53, 104.27 examples/s]Tokenizing train dataset:  34%|███▎      | 2877/8564 [00:32<01:03, 89.63 examples/s]Tokenizing train dataset:  28%|██▊       | 2426/8564 [00:30<01:08, 89.85 examples/s]Tokenizing train dataset:  34%|███▍      | 2949/8564 [00:31<00:52, 106.78 examples/s]Tokenizing train dataset:  34%|███▍      | 2892/8564 [00:32<00:55, 102.78 examples/s]Tokenizing train dataset:  28%|██▊       | 2438/8564 [00:30<01:04, 95.64 examples/s]Tokenizing train dataset:  34%|███▍      | 2905/8564 [00:32<00:56, 100.73 examples/s]Tokenizing train dataset:  35%|███▍      | 2962/8564 [00:31<00:59, 93.55 examples/s] Tokenizing train dataset:  29%|██▊       | 2450/8564 [00:30<01:01, 99.30 examples/s]Tokenizing train dataset:  34%|███▍      | 2919/8564 [00:32<00:51, 109.14 examples/s]Tokenizing train dataset:  35%|███▍      | 2975/8564 [00:31<00:58, 94.89 examples/s]Tokenizing train dataset:  29%|██▉       | 2466/8564 [00:30<00:55, 109.50 examples/s]Tokenizing train dataset:  29%|██▉       | 2480/8564 [00:30<00:52, 114.98 examples/s]Tokenizing train dataset:  34%|███▍      | 2940/8564 [00:33<00:49, 114.38 examples/s]Tokenizing train dataset:  35%|███▍      | 2990/8564 [00:31<00:55, 100.85 examples/s]Tokenizing train dataset:  34%|███▍      | 2954/8564 [00:33<00:55, 100.42 examples/s]Tokenizing train dataset:  35%|███▌      | 3005/8564 [00:31<01:01, 90.03 examples/s] Tokenizing train dataset:  29%|██▉       | 2495/8564 [00:30<01:12, 83.46 examples/s] Tokenizing train dataset:  35%|███▍      | 2971/8564 [00:33<00:49, 113.47 examples/s]Tokenizing train dataset:  35%|███▌      | 3015/8564 [00:32<01:07, 82.08 examples/s]Tokenizing train dataset:  29%|██▉       | 2507/8564 [00:30<01:09, 86.75 examples/s]Tokenizing train dataset:  35%|███▍      | 2986/8564 [00:33<00:49, 113.32 examples/s]Tokenizing train dataset:  35%|███▌      | 3030/8564 [00:32<00:59, 92.97 examples/s]Tokenizing train dataset:  35%|███▌      | 2999/8564 [00:33<00:50, 110.77 examples/s]Tokenizing train dataset:  29%|██▉       | 2522/8564 [00:31<01:10, 85.26 examples/s]Tokenizing train dataset:  35%|███▌      | 3040/8564 [00:32<01:06, 83.34 examples/s]Tokenizing train dataset:  30%|██▉       | 2537/8564 [00:31<01:01, 97.94 examples/s]Tokenizing train dataset:  36%|███▌      | 3053/8564 [00:32<01:04, 84.85 examples/s]Tokenizing train dataset:  35%|███▌      | 3017/8564 [00:33<00:59, 92.94 examples/s] Tokenizing train dataset:  30%|██▉       | 2552/8564 [00:31<00:58, 102.93 examples/s]Tokenizing train dataset:  30%|██▉       | 2565/8564 [00:31<00:56, 106.98 examples/s]Tokenizing train dataset:  36%|███▌      | 3062/8564 [00:32<01:09, 79.01 examples/s]Tokenizing train dataset:  35%|███▌      | 3029/8564 [00:34<01:03, 87.01 examples/s]Tokenizing train dataset:  30%|███       | 2578/8564 [00:31<00:55, 108.04 examples/s]Tokenizing train dataset:  36%|███▌      | 3074/8564 [00:32<01:04, 85.06 examples/s]Tokenizing train dataset:  35%|███▌      | 3039/8564 [00:34<01:03, 87.35 examples/s]Tokenizing train dataset:  36%|███▌      | 3083/8564 [00:32<01:07, 81.07 examples/s]Tokenizing train dataset:  36%|███▌      | 3053/8564 [00:34<00:56, 98.41 examples/s]Tokenizing train dataset:  30%|███       | 2591/8564 [00:31<01:04, 93.25 examples/s] Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:33<01:00, 89.94 examples/s]Tokenizing train dataset:  30%|███       | 2606/8564 [00:31<00:57, 102.73 examples/s]Tokenizing train dataset:  36%|███▌      | 3066/8564 [00:34<01:03, 87.04 examples/s]Tokenizing train dataset:  36%|███▋      | 3109/8564 [00:33<01:04, 83.99 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:32<01:05, 90.54 examples/s] Tokenizing train dataset:  36%|███▌      | 3083/8564 [00:34<01:01, 88.85 examples/s]Tokenizing train dataset:  36%|███▋      | 3119/8564 [00:33<01:04, 84.98 examples/s]Tokenizing train dataset:  36%|███▌      | 3099/8564 [00:34<00:58, 94.19 examples/s]Tokenizing train dataset:  31%|███       | 2635/8564 [00:32<01:08, 87.13 examples/s]Tokenizing train dataset:  37%|███▋      | 3138/8564 [00:33<01:00, 90.41 examples/s]Tokenizing train dataset:  31%|███       | 2646/8564 [00:32<01:05, 91.02 examples/s]Tokenizing train dataset:  36%|███▋      | 3111/8564 [00:34<00:58, 92.88 examples/s]Tokenizing train dataset:  31%|███       | 2656/8564 [00:32<01:04, 91.59 examples/s]Tokenizing train dataset:  37%|███▋      | 3151/8564 [00:33<01:03, 85.51 examples/s]Tokenizing train dataset:  37%|███▋      | 3127/8564 [00:35<00:58, 92.25 examples/s]Tokenizing train dataset:  31%|███       | 2669/8564 [00:32<00:58, 100.16 examples/s]Tokenizing train dataset:  37%|███▋      | 3161/8564 [00:33<01:03, 85.38 examples/s]Tokenizing train dataset:  37%|███▋      | 3141/8564 [00:35<00:53, 102.01 examples/s]Tokenizing train dataset:  31%|███▏      | 2685/8564 [00:32<01:00, 96.69 examples/s] Tokenizing train dataset:  37%|███▋      | 3156/8564 [00:35<00:48, 111.79 examples/s]Tokenizing train dataset:  37%|███▋      | 3172/8564 [00:34<01:14, 72.61 examples/s]Tokenizing train dataset:  37%|███▋      | 3170/8564 [00:35<00:47, 114.31 examples/s]Tokenizing train dataset:  32%|███▏      | 2701/8564 [00:32<01:00, 97.62 examples/s]Tokenizing train dataset:  37%|███▋      | 3184/8564 [00:34<01:12, 73.82 examples/s]Tokenizing train dataset:  37%|███▋      | 3184/8564 [00:35<00:44, 119.58 examples/s]Tokenizing train dataset:  32%|███▏      | 2713/8564 [00:33<01:03, 92.42 examples/s]Tokenizing train dataset:  37%|███▋      | 3196/8564 [00:34<01:07, 80.00 examples/s]Tokenizing train dataset:  37%|███▋      | 3199/8564 [00:35<00:51, 103.45 examples/s]Tokenizing train dataset:  32%|███▏      | 2725/8564 [00:33<01:01, 95.09 examples/s]Tokenizing train dataset:  37%|███▋      | 3210/8564 [00:34<01:06, 80.63 examples/s]Tokenizing train dataset:  32%|███▏      | 2735/8564 [00:33<01:04, 90.80 examples/s]Tokenizing train dataset:  38%|███▊      | 3227/8564 [00:34<00:57, 92.46 examples/s]Tokenizing train dataset:  38%|███▊      | 3217/8564 [00:35<00:57, 93.33 examples/s] Tokenizing train dataset:  32%|███▏      | 2745/8564 [00:33<01:04, 90.64 examples/s]Tokenizing train dataset:  38%|███▊      | 3231/8564 [00:36<00:51, 102.58 examples/s]Tokenizing train dataset:  32%|███▏      | 2759/8564 [00:33<01:00, 95.90 examples/s]Tokenizing train dataset:  38%|███▊      | 3247/8564 [00:34<00:52, 100.44 examples/s]Tokenizing train dataset:  38%|███▊      | 3246/8564 [00:36<00:48, 109.56 examples/s]Tokenizing train dataset:  38%|███▊      | 3261/8564 [00:36<00:44, 117.93 examples/s]Tokenizing train dataset:  38%|███▊      | 3262/8564 [00:34<00:55, 94.85 examples/s] Tokenizing train dataset:  32%|███▏      | 2773/8564 [00:33<01:08, 83.97 examples/s]Tokenizing train dataset:  33%|███▎      | 2789/8564 [00:33<00:57, 99.67 examples/s]Tokenizing train dataset:  38%|███▊      | 3277/8564 [00:36<00:46, 113.14 examples/s]Tokenizing train dataset:  38%|███▊      | 3276/8564 [00:35<01:02, 84.99 examples/s]Tokenizing train dataset:  33%|███▎      | 2807/8564 [00:33<00:52, 110.17 examples/s]Tokenizing train dataset:  38%|███▊      | 3290/8564 [00:36<00:48, 109.13 examples/s]Tokenizing train dataset:  33%|███▎      | 2821/8564 [00:34<00:49, 115.93 examples/s]Tokenizing train dataset:  38%|███▊      | 3289/8564 [00:35<01:08, 76.76 examples/s]Tokenizing train dataset:  39%|███▊      | 3309/8564 [00:36<00:48, 107.82 examples/s]Tokenizing train dataset:  33%|███▎      | 2838/8564 [00:34<00:53, 107.91 examples/s]Tokenizing train dataset:  39%|███▊      | 3302/8564 [00:35<01:08, 77.09 examples/s]Tokenizing train dataset:  39%|███▉      | 3324/8564 [00:36<00:55, 95.03 examples/s] Tokenizing train dataset:  39%|███▊      | 3316/8564 [00:35<01:01, 84.76 examples/s]Tokenizing train dataset:  33%|███▎      | 2855/8564 [00:34<00:57, 99.30 examples/s] Tokenizing train dataset:  39%|███▉      | 3334/8564 [00:37<00:56, 92.89 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:34<00:57, 98.40 examples/s]Tokenizing train dataset:  39%|███▉      | 3344/8564 [00:37<00:57, 90.61 examples/s]Tokenizing train dataset:  39%|███▉      | 3327/8564 [00:35<01:08, 77.00 examples/s]Tokenizing train dataset:  34%|███▎      | 2880/8564 [00:34<00:56, 101.50 examples/s]Tokenizing train dataset:  39%|███▉      | 3355/8564 [00:37<00:58, 88.67 examples/s]Tokenizing train dataset:  34%|███▍      | 2898/8564 [00:34<00:49, 115.61 examples/s]Tokenizing train dataset:  39%|███▉      | 3341/8564 [00:36<01:13, 71.04 examples/s]Tokenizing train dataset:  39%|███▉      | 3369/8564 [00:37<00:59, 86.93 examples/s]Tokenizing train dataset:  34%|███▍      | 2914/8564 [00:34<00:46, 121.18 examples/s]Tokenizing train dataset:  39%|███▉      | 3360/8564 [00:36<00:58, 89.22 examples/s]Tokenizing train dataset:  39%|███▉      | 3378/8564 [00:37<01:00, 85.12 examples/s]Tokenizing train dataset:  39%|███▉      | 3371/8564 [00:36<00:55, 93.02 examples/s]Tokenizing train dataset:  34%|███▍      | 2930/8564 [00:35<00:50, 112.48 examples/s]Tokenizing train dataset:  40%|███▉      | 3393/8564 [00:37<00:54, 94.81 examples/s]Tokenizing train dataset:  40%|███▉      | 3386/8564 [00:36<00:49, 105.05 examples/s]Tokenizing train dataset:  34%|███▍      | 2947/8564 [00:35<00:46, 121.97 examples/s]Tokenizing train dataset:  40%|███▉      | 3405/8564 [00:37<00:55, 92.64 examples/s]Tokenizing train dataset:  40%|███▉      | 3402/8564 [00:36<00:44, 116.50 examples/s]Tokenizing train dataset:  35%|███▍      | 2960/8564 [00:35<00:45, 122.27 examples/s]Tokenizing train dataset:  40%|███▉      | 3418/8564 [00:37<00:50, 101.27 examples/s]Tokenizing train dataset:  35%|███▍      | 2976/8564 [00:35<00:42, 131.13 examples/s]Tokenizing train dataset:  40%|███▉      | 3416/8564 [00:36<00:51, 100.51 examples/s]Tokenizing train dataset:  40%|████      | 3433/8564 [00:38<00:47, 108.53 examples/s]Tokenizing train dataset:  35%|███▍      | 2991/8564 [00:35<00:41, 133.31 examples/s]Tokenizing train dataset:  40%|████      | 3445/8564 [00:38<00:46, 110.04 examples/s]Tokenizing train dataset:  40%|████      | 3430/8564 [00:36<00:54, 94.03 examples/s] Tokenizing train dataset:  35%|███▌      | 3010/8564 [00:35<00:41, 135.44 examples/s]Tokenizing train dataset:  40%|████      | 3460/8564 [00:38<00:52, 97.36 examples/s] Tokenizing train dataset:  35%|███▌      | 3024/8564 [00:35<00:48, 113.93 examples/s]Tokenizing train dataset:  40%|████      | 3445/8564 [00:37<01:03, 80.71 examples/s]Tokenizing train dataset:  41%|████      | 3472/8564 [00:38<00:49, 101.92 examples/s]Tokenizing train dataset:  40%|████      | 3456/8564 [00:37<01:00, 84.55 examples/s]Tokenizing train dataset:  41%|████      | 3485/8564 [00:38<00:48, 104.91 examples/s]Tokenizing train dataset:  35%|███▌      | 3040/8564 [00:36<00:56, 97.66 examples/s] Tokenizing train dataset:  41%|████      | 3497/8564 [00:38<00:46, 108.54 examples/s]Tokenizing train dataset:  40%|████      | 3468/8564 [00:37<00:59, 85.86 examples/s]Tokenizing train dataset:  41%|████      | 3516/8564 [00:38<00:40, 124.33 examples/s]Tokenizing train dataset:  36%|███▌      | 3052/8564 [00:36<01:02, 88.17 examples/s]Tokenizing train dataset:  41%|████      | 3480/8564 [00:37<01:02, 80.97 examples/s]Tokenizing train dataset:  41%|████▏     | 3534/8564 [00:38<00:41, 121.50 examples/s]Tokenizing train dataset:  36%|███▌      | 3062/8564 [00:36<01:09, 78.64 examples/s]Tokenizing train dataset:  41%|████      | 3491/8564 [00:37<01:08, 74.17 examples/s]Tokenizing train dataset:  41%|████▏     | 3550/8564 [00:39<00:43, 114.20 examples/s]Tokenizing train dataset:  36%|███▌      | 3078/8564 [00:36<01:06, 82.07 examples/s]Tokenizing train dataset:  41%|████      | 3504/8564 [00:37<01:00, 83.91 examples/s]Tokenizing train dataset:  42%|████▏     | 3563/8564 [00:39<00:43, 114.92 examples/s]Tokenizing train dataset:  36%|███▌      | 3087/8564 [00:36<01:07, 80.64 examples/s]Tokenizing train dataset:  41%|████      | 3517/8564 [00:37<00:56, 89.24 examples/s]Tokenizing train dataset:  42%|████▏     | 3578/8564 [00:39<00:41, 121.48 examples/s]Tokenizing train dataset:  36%|███▌      | 3099/8564 [00:36<01:07, 80.85 examples/s]Tokenizing train dataset:  42%|████▏     | 3592/8564 [00:39<00:39, 125.38 examples/s]Tokenizing train dataset:  41%|████      | 3529/8564 [00:38<01:00, 83.31 examples/s]Tokenizing train dataset:  42%|████▏     | 3606/8564 [00:39<00:39, 125.63 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:37<01:07, 80.50 examples/s]Tokenizing train dataset:  41%|████▏     | 3542/8564 [00:38<01:01, 81.20 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:39<00:39, 124.45 examples/s]Tokenizing train dataset:  36%|███▋      | 3122/8564 [00:37<01:15, 72.19 examples/s]Tokenizing train dataset:  41%|████▏     | 3554/8564 [00:38<01:04, 77.27 examples/s]Tokenizing train dataset:  43%|████▎     | 3643/8564 [00:39<00:43, 114.08 examples/s]Tokenizing train dataset:  37%|███▋      | 3132/8564 [00:37<01:13, 73.87 examples/s]Tokenizing train dataset:  42%|████▏     | 3563/8564 [00:38<01:10, 70.81 examples/s]Tokenizing train dataset:  37%|███▋      | 3144/8564 [00:37<01:09, 77.63 examples/s]Tokenizing train dataset:  43%|████▎     | 3660/8564 [00:40<00:44, 110.16 examples/s]Tokenizing train dataset:  42%|████▏     | 3572/8564 [00:38<01:08, 72.51 examples/s]Tokenizing train dataset:  43%|████▎     | 3672/8564 [00:40<00:44, 109.36 examples/s]Tokenizing train dataset:  37%|███▋      | 3156/8564 [00:37<01:10, 76.97 examples/s]Tokenizing train dataset:  42%|████▏     | 3589/8564 [00:38<00:55, 89.19 examples/s]Tokenizing train dataset:  42%|████▏     | 3602/8564 [00:38<00:50, 98.44 examples/s]Tokenizing train dataset:  37%|███▋      | 3170/8564 [00:37<01:03, 84.85 examples/s]Tokenizing train dataset:  43%|████▎     | 3687/8564 [00:40<00:46, 104.86 examples/s]Tokenizing train dataset:  37%|███▋      | 3180/8564 [00:37<01:04, 83.73 examples/s]Tokenizing train dataset:  43%|████▎     | 3700/8564 [00:40<00:46, 104.08 examples/s]Tokenizing train dataset:  42%|████▏     | 3616/8564 [00:39<00:51, 95.40 examples/s]Tokenizing train dataset:  43%|████▎     | 3716/8564 [00:40<00:43, 112.74 examples/s]Tokenizing train dataset:  42%|████▏     | 3631/8564 [00:39<00:47, 104.47 examples/s]Tokenizing train dataset:  37%|███▋      | 3190/8564 [00:38<01:07, 79.68 examples/s]Tokenizing train dataset:  44%|████▎     | 3731/8564 [00:40<00:40, 118.27 examples/s]Tokenizing train dataset:  43%|████▎     | 3644/8564 [00:39<00:45, 108.23 examples/s]Tokenizing train dataset:  37%|███▋      | 3205/8564 [00:38<01:10, 75.96 examples/s]Tokenizing train dataset:  44%|████▍     | 3751/8564 [00:40<00:39, 121.54 examples/s]Tokenizing train dataset:  43%|████▎     | 3660/8564 [00:39<00:46, 104.43 examples/s]Tokenizing train dataset:  38%|███▊      | 3214/8564 [00:38<01:08, 77.89 examples/s]Tokenizing train dataset:  43%|████▎     | 3671/8564 [00:39<00:46, 104.79 examples/s]Tokenizing train dataset:  44%|████▍     | 3764/8564 [00:41<00:46, 103.30 examples/s]Tokenizing train dataset:  38%|███▊      | 3225/8564 [00:38<01:07, 79.62 examples/s]Tokenizing train dataset:  43%|████▎     | 3689/8564 [00:39<00:45, 106.07 examples/s]Tokenizing train dataset:  44%|████▍     | 3775/8564 [00:41<00:47, 100.26 examples/s]Tokenizing train dataset:  38%|███▊      | 3240/8564 [00:38<01:05, 81.20 examples/s]Tokenizing train dataset:  43%|████▎     | 3700/8564 [00:39<00:45, 105.91 examples/s]Tokenizing train dataset:  44%|████▍     | 3790/8564 [00:41<00:51, 93.23 examples/s] Tokenizing train dataset:  38%|███▊      | 3253/8564 [00:38<00:58, 90.40 examples/s]Tokenizing train dataset:  43%|████▎     | 3713/8564 [00:40<00:51, 94.58 examples/s] Tokenizing train dataset:  38%|███▊      | 3269/8564 [00:38<00:51, 102.39 examples/s]Tokenizing train dataset:  44%|████▍     | 3800/8564 [00:41<00:53, 88.68 examples/s]Tokenizing train dataset:  38%|███▊      | 3280/8564 [00:38<00:51, 103.25 examples/s]Tokenizing train dataset:  44%|████▎     | 3727/8564 [00:40<00:51, 94.26 examples/s]Tokenizing train dataset:  44%|████▍     | 3810/8564 [00:41<00:57, 82.95 examples/s]Tokenizing train dataset:  38%|███▊      | 3293/8564 [00:39<00:50, 105.06 examples/s]Tokenizing train dataset:  44%|████▎     | 3741/8564 [00:40<00:55, 86.90 examples/s]Tokenizing train dataset:  45%|████▍     | 3821/8564 [00:41<00:59, 79.26 examples/s]Tokenizing train dataset:  39%|███▊      | 3304/8564 [00:39<00:49, 105.44 examples/s]Tokenizing train dataset:  44%|████▍     | 3750/8564 [00:40<00:56, 85.34 examples/s]Tokenizing train dataset:  39%|███▉      | 3322/8564 [00:39<00:42, 124.04 examples/s]Tokenizing train dataset:  45%|████▍     | 3830/8564 [00:41<01:02, 76.10 examples/s]Tokenizing train dataset:  45%|████▍     | 3842/8564 [00:41<00:57, 82.75 examples/s]Tokenizing train dataset:  44%|████▍     | 3764/8564 [00:40<00:58, 82.45 examples/s]Tokenizing train dataset:  39%|███▉      | 3340/8564 [00:39<00:45, 115.79 examples/s]Tokenizing train dataset:  45%|████▌     | 3855/8564 [00:42<00:50, 92.83 examples/s]Tokenizing train dataset:  44%|████▍     | 3773/8564 [00:40<00:57, 82.74 examples/s]Tokenizing train dataset:  39%|███▉      | 3355/8564 [00:39<00:42, 122.89 examples/s]Tokenizing train dataset:  45%|████▌     | 3870/8564 [00:42<00:46, 101.58 examples/s]Tokenizing train dataset:  39%|███▉      | 3369/8564 [00:39<00:42, 122.22 examples/s]Tokenizing train dataset:  44%|████▍     | 3783/8564 [00:40<00:59, 79.97 examples/s]Tokenizing train dataset:  45%|████▌     | 3884/8564 [00:42<00:42, 108.90 examples/s]Tokenizing train dataset:  44%|████▍     | 3792/8564 [00:41<01:01, 77.10 examples/s]Tokenizing train dataset:  40%|███▉      | 3391/8564 [00:39<00:40, 126.73 examples/s]Tokenizing train dataset:  46%|████▌     | 3900/8564 [00:42<00:43, 106.30 examples/s]Tokenizing train dataset:  44%|████▍     | 3800/8564 [00:41<01:03, 75.02 examples/s]Tokenizing train dataset:  40%|███▉      | 3405/8564 [00:39<00:40, 128.96 examples/s]Tokenizing train dataset:  46%|████▌     | 3911/8564 [00:42<00:45, 102.51 examples/s]Tokenizing train dataset:  44%|████▍     | 3809/8564 [00:41<01:02, 76.13 examples/s]Tokenizing train dataset:  40%|███▉      | 3424/8564 [00:40<00:41, 123.45 examples/s]Tokenizing train dataset:  46%|████▌     | 3924/8564 [00:42<00:42, 108.55 examples/s]Tokenizing train dataset:  45%|████▍     | 3819/8564 [00:41<01:01, 77.49 examples/s]Tokenizing train dataset:  40%|████      | 3439/8564 [00:40<00:39, 128.25 examples/s]Tokenizing train dataset:  46%|████▌     | 3938/8564 [00:42<00:41, 111.98 examples/s]Tokenizing train dataset:  45%|████▍     | 3830/8564 [00:41<01:05, 72.25 examples/s]Tokenizing train dataset:  46%|████▌     | 3950/8564 [00:42<00:41, 110.61 examples/s]Tokenizing train dataset:  40%|████      | 3460/8564 [00:40<00:40, 125.24 examples/s]Tokenizing train dataset:  45%|████▍     | 3840/8564 [00:41<01:04, 73.47 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:43<00:41, 110.50 examples/s]Tokenizing train dataset:  41%|████      | 3473/8564 [00:40<00:42, 120.91 examples/s]Tokenizing train dataset:  46%|████▋     | 3975/8564 [00:43<00:40, 112.09 examples/s]Tokenizing train dataset:  41%|████      | 3486/8564 [00:40<00:41, 121.04 examples/s]Tokenizing train dataset:  45%|████▍     | 3852/8564 [00:41<01:07, 70.20 examples/s]Tokenizing train dataset:  47%|████▋     | 3988/8564 [00:43<00:40, 111.91 examples/s]Tokenizing train dataset:  41%|████      | 3502/8564 [00:40<00:39, 128.11 examples/s]Tokenizing train dataset:  45%|████▌     | 3861/8564 [00:42<01:05, 71.57 examples/s]Tokenizing train dataset:  47%|████▋     | 4001/8564 [00:43<00:41, 110.60 examples/s]Tokenizing train dataset:  41%|████      | 3516/8564 [00:40<00:38, 130.28 examples/s]Tokenizing train dataset:  45%|████▌     | 3877/8564 [00:42<00:53, 88.05 examples/s]Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:43<00:39, 114.27 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:42<00:49, 94.29 examples/s]Tokenizing train dataset:  47%|████▋     | 4031/8564 [00:43<00:36, 124.86 examples/s]Tokenizing train dataset:  41%|████      | 3531/8564 [00:41<00:49, 101.50 examples/s]Tokenizing train dataset:  46%|████▌     | 3902/8564 [00:42<00:48, 96.57 examples/s]Tokenizing train dataset:  47%|████▋     | 4050/8564 [00:43<00:37, 121.67 examples/s]Tokenizing train dataset:  46%|████▌     | 3916/8564 [00:42<00:45, 103.01 examples/s]Tokenizing train dataset:  41%|████▏     | 3544/8564 [00:41<00:59, 83.92 examples/s] Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:43<00:37, 121.00 examples/s]Tokenizing train dataset:  46%|████▌     | 3928/8564 [00:42<00:44, 104.69 examples/s]Tokenizing train dataset:  42%|████▏     | 3556/8564 [00:41<00:58, 86.27 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:42<00:43, 107.29 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:44<00:44, 101.12 examples/s]Tokenizing train dataset:  42%|████▏     | 3569/8564 [00:41<00:58, 85.56 examples/s]Tokenizing train dataset:  46%|████▌     | 3952/8564 [00:42<00:42, 107.94 examples/s]Tokenizing train dataset:  48%|████▊     | 4092/8564 [00:44<00:43, 102.41 examples/s]Tokenizing train dataset:  46%|████▋     | 3963/8564 [00:42<00:43, 105.92 examples/s]Tokenizing train dataset:  42%|████▏     | 3579/8564 [00:41<01:01, 81.07 examples/s]Tokenizing train dataset:  48%|████▊     | 4106/8564 [00:44<00:40, 110.30 examples/s]Tokenizing train dataset:  46%|████▋     | 3978/8564 [00:43<00:40, 113.76 examples/s]Tokenizing train dataset:  42%|████▏     | 3594/8564 [00:41<00:52, 94.65 examples/s]Tokenizing train dataset:  47%|████▋     | 3990/8564 [00:43<00:40, 113.25 examples/s]Tokenizing train dataset:  42%|████▏     | 3607/8564 [00:41<00:48, 102.54 examples/s]Tokenizing train dataset:  48%|████▊     | 4118/8564 [00:44<00:47, 93.44 examples/s] Tokenizing train dataset:  47%|████▋     | 4004/8564 [00:43<00:40, 113.97 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:42<00:44, 111.44 examples/s]Tokenizing train dataset:  48%|████▊     | 4130/8564 [00:44<00:54, 81.98 examples/s]Tokenizing train dataset:  47%|████▋     | 4020/8564 [00:43<00:36, 124.78 examples/s]Tokenizing train dataset:  43%|████▎     | 3644/8564 [00:42<00:45, 107.99 examples/s]Tokenizing train dataset:  47%|████▋     | 4034/8564 [00:43<00:36, 123.70 examples/s]Tokenizing train dataset:  48%|████▊     | 4144/8564 [00:44<00:54, 80.63 examples/s]Tokenizing train dataset:  47%|████▋     | 4050/8564 [00:43<00:35, 126.11 examples/s]Tokenizing train dataset:  43%|████▎     | 3660/8564 [00:42<00:46, 104.87 examples/s]Tokenizing train dataset:  47%|████▋     | 4064/8564 [00:43<00:37, 120.29 examples/s]Tokenizing train dataset:  49%|████▊     | 4157/8564 [00:45<00:58, 74.79 examples/s]Tokenizing train dataset:  43%|████▎     | 3673/8564 [00:42<00:45, 107.65 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:43<00:37, 118.97 examples/s]Tokenizing train dataset:  49%|████▊     | 4167/8564 [00:45<01:00, 72.80 examples/s]Tokenizing train dataset:  43%|████▎     | 3690/8564 [00:42<00:45, 106.85 examples/s]Tokenizing train dataset:  49%|████▉     | 4180/8564 [00:45<00:52, 83.78 examples/s]Tokenizing train dataset:  43%|████▎     | 3704/8564 [00:42<00:44, 109.30 examples/s]Tokenizing train dataset:  48%|████▊     | 4095/8564 [00:44<00:44, 100.66 examples/s]Tokenizing train dataset:  49%|████▉     | 4194/8564 [00:45<00:45, 95.82 examples/s]Tokenizing train dataset:  43%|████▎     | 3723/8564 [00:42<00:38, 127.16 examples/s]Tokenizing train dataset:  49%|████▉     | 4210/8564 [00:45<00:40, 106.58 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:44<00:47, 93.58 examples/s] Tokenizing train dataset:  49%|████▉     | 4222/8564 [00:45<00:43, 99.11 examples/s] Tokenizing train dataset:  48%|████▊     | 4123/8564 [00:44<00:45, 98.53 examples/s]Tokenizing train dataset:  44%|████▎     | 3740/8564 [00:43<00:47, 101.04 examples/s]Tokenizing train dataset:  49%|████▉     | 4233/8564 [00:45<00:45, 94.74 examples/s]Tokenizing train dataset:  48%|████▊     | 4138/8564 [00:44<00:42, 104.96 examples/s]Tokenizing train dataset:  44%|████▍     | 3755/8564 [00:43<00:51, 92.91 examples/s] Tokenizing train dataset:  48%|████▊     | 4149/8564 [00:44<00:42, 104.91 examples/s]Tokenizing train dataset:  50%|████▉     | 4243/8564 [00:45<00:46, 92.23 examples/s]Tokenizing train dataset:  44%|████▍     | 3768/8564 [00:43<00:50, 95.64 examples/s]Tokenizing train dataset:  50%|████▉     | 4255/8564 [00:46<00:44, 97.44 examples/s]Tokenizing train dataset:  49%|████▊     | 4160/8564 [00:44<00:47, 93.13 examples/s] Tokenizing train dataset:  44%|████▍     | 3783/8564 [00:43<00:48, 98.87 examples/s]Tokenizing train dataset:  49%|████▊     | 4172/8564 [00:44<00:45, 95.82 examples/s]Tokenizing train dataset:  50%|████▉     | 4269/8564 [00:46<00:45, 94.51 examples/s]Tokenizing train dataset:  44%|████▍     | 3794/8564 [00:43<00:48, 97.35 examples/s]Tokenizing train dataset:  49%|████▉     | 4188/8564 [00:44<00:39, 109.91 examples/s]Tokenizing train dataset:  50%|████▉     | 4280/8564 [00:46<00:48, 88.67 examples/s]Tokenizing train dataset:  49%|████▉     | 4203/8564 [00:45<00:37, 115.52 examples/s]Tokenizing train dataset:  44%|████▍     | 3809/8564 [00:43<00:53, 89.14 examples/s]Tokenizing train dataset:  50%|█████     | 4291/8564 [00:46<00:57, 74.84 examples/s]Tokenizing train dataset:  49%|████▉     | 4220/8564 [00:45<00:39, 110.36 examples/s]Tokenizing train dataset:  45%|████▍     | 3820/8564 [00:44<00:55, 86.06 examples/s]Tokenizing train dataset:  50%|█████     | 4304/8564 [00:46<00:49, 85.44 examples/s]Tokenizing train dataset:  49%|████▉     | 4232/8564 [00:45<00:40, 108.13 examples/s]Tokenizing train dataset:  45%|████▍     | 3832/8564 [00:44<00:52, 90.11 examples/s]Tokenizing train dataset:  50%|█████     | 4319/8564 [00:46<00:44, 95.84 examples/s]Tokenizing train dataset:  45%|████▍     | 3847/8564 [00:44<00:47, 98.87 examples/s]Tokenizing train dataset:  51%|█████     | 4330/8564 [00:46<00:43, 98.37 examples/s]Tokenizing train dataset:  50%|████▉     | 4247/8564 [00:45<00:52, 82.91 examples/s] Tokenizing train dataset:  45%|████▌     | 3859/8564 [00:44<00:53, 87.55 examples/s]Tokenizing train dataset:  51%|█████     | 4347/8564 [00:47<00:42, 99.67 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:45<00:49, 86.44 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:47<00:38, 107.90 examples/s]Tokenizing train dataset:  45%|████▌     | 3870/8564 [00:44<00:56, 82.41 examples/s]Tokenizing train dataset:  50%|████▉     | 4275/8564 [00:45<00:49, 86.66 examples/s]Tokenizing train dataset:  51%|█████     | 4377/8564 [00:47<00:37, 110.81 examples/s]Tokenizing train dataset:  45%|████▌     | 3882/8564 [00:44<00:53, 87.62 examples/s]Tokenizing train dataset:  50%|█████     | 4286/8564 [00:46<00:49, 86.96 examples/s]Tokenizing train dataset:  45%|████▌     | 3896/8564 [00:44<00:49, 93.83 examples/s]Tokenizing train dataset:  51%|█████▏    | 4391/8564 [00:47<00:44, 93.13 examples/s] Tokenizing train dataset:  50%|█████     | 4300/8564 [00:46<00:45, 93.08 examples/s]Tokenizing train dataset:  46%|████▌     | 3909/8564 [00:45<00:47, 97.22 examples/s]Tokenizing train dataset:  51%|█████▏    | 4403/8564 [00:47<00:42, 97.33 examples/s]Tokenizing train dataset:  50%|█████     | 4314/8564 [00:46<00:42, 99.86 examples/s]Tokenizing train dataset:  46%|████▌     | 3920/8564 [00:45<00:47, 97.20 examples/s]Tokenizing train dataset:  51%|█████     | 4326/8564 [00:46<00:41, 102.83 examples/s]Tokenizing train dataset:  52%|█████▏    | 4415/8564 [00:47<00:48, 85.86 examples/s]Tokenizing train dataset:  46%|████▌     | 3934/8564 [00:45<00:44, 103.69 examples/s]Tokenizing train dataset:  51%|█████     | 4337/8564 [00:46<00:41, 102.52 examples/s]Tokenizing train dataset:  46%|████▌     | 3948/8564 [00:45<00:42, 109.58 examples/s]Tokenizing train dataset:  52%|█████▏    | 4428/8564 [00:47<00:50, 81.25 examples/s]Tokenizing train dataset:  51%|█████     | 4349/8564 [00:46<00:40, 103.39 examples/s]Tokenizing train dataset:  46%|████▋     | 3962/8564 [00:45<00:42, 107.60 examples/s]Tokenizing train dataset:  52%|█████▏    | 4438/8564 [00:48<00:50, 82.25 examples/s]Tokenizing train dataset:  51%|█████     | 4364/8564 [00:46<00:39, 105.78 examples/s]Tokenizing train dataset:  46%|████▋     | 3977/8564 [00:45<00:40, 114.32 examples/s]Tokenizing train dataset:  52%|█████▏    | 4447/8564 [00:48<00:52, 79.10 examples/s]Tokenizing train dataset:  51%|█████     | 4379/8564 [00:46<00:37, 112.51 examples/s]Tokenizing train dataset:  47%|████▋     | 3990/8564 [00:45<00:42, 107.49 examples/s]Tokenizing train dataset:  51%|█████▏    | 4393/8564 [00:47<00:35, 118.66 examples/s]Tokenizing train dataset:  52%|█████▏    | 4456/8564 [00:48<00:57, 71.72 examples/s]Tokenizing train dataset:  47%|████▋     | 4005/8564 [00:45<00:41, 110.61 examples/s]Tokenizing train dataset:  52%|█████▏    | 4470/8564 [00:48<00:49, 83.12 examples/s]Tokenizing train dataset:  52%|█████▏    | 4412/8564 [00:47<00:35, 117.17 examples/s]Tokenizing train dataset:  47%|████▋     | 4017/8564 [00:46<00:41, 110.51 examples/s]Tokenizing train dataset:  52%|█████▏    | 4482/8564 [00:48<00:45, 89.71 examples/s]Tokenizing train dataset:  52%|█████▏    | 4426/8564 [00:47<00:35, 117.60 examples/s]Tokenizing train dataset:  47%|████▋     | 4031/8564 [00:46<00:45, 100.38 examples/s]Tokenizing train dataset:  52%|█████▏    | 4440/8564 [00:47<00:35, 117.03 examples/s]Tokenizing train dataset:  52%|█████▏    | 4495/8564 [00:48<00:50, 80.85 examples/s]Tokenizing train dataset:  52%|█████▏    | 4454/8564 [00:47<00:33, 121.90 examples/s]Tokenizing train dataset:  47%|████▋     | 4044/8564 [00:46<00:49, 91.23 examples/s] Tokenizing train dataset:  52%|█████▏    | 4469/8564 [00:47<00:33, 121.72 examples/s]Tokenizing train dataset:  53%|█████▎    | 4508/8564 [00:48<00:51, 78.55 examples/s]Tokenizing train dataset:  47%|████▋     | 4059/8564 [00:46<00:51, 88.03 examples/s]Tokenizing train dataset:  52%|█████▏    | 4488/8564 [00:47<00:34, 119.04 examples/s]Tokenizing train dataset:  53%|█████▎    | 4520/8564 [00:49<00:52, 76.83 examples/s]Tokenizing train dataset:  48%|████▊     | 4069/8564 [00:46<00:57, 77.74 examples/s]Tokenizing train dataset:  53%|█████▎    | 4529/8564 [00:49<00:53, 75.40 examples/s]Tokenizing train dataset:  53%|█████▎    | 4507/8564 [00:48<00:36, 109.96 examples/s]Tokenizing train dataset:  53%|█████▎    | 4538/8564 [00:49<00:51, 77.60 examples/s]Tokenizing train dataset:  48%|████▊     | 4081/8564 [00:46<00:57, 78.16 examples/s]Tokenizing train dataset:  53%|█████▎    | 4521/8564 [00:48<00:35, 113.27 examples/s]Tokenizing train dataset:  53%|█████▎    | 4546/8564 [00:49<00:53, 75.70 examples/s]Tokenizing train dataset:  48%|████▊     | 4090/8564 [00:46<00:57, 77.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 4535/8564 [00:48<00:34, 115.96 examples/s]Tokenizing train dataset:  53%|█████▎    | 4556/8564 [00:49<00:51, 78.52 examples/s]Tokenizing train dataset:  53%|█████▎    | 4547/8564 [00:48<00:34, 116.37 examples/s]Tokenizing train dataset:  48%|████▊     | 4100/8564 [00:47<01:02, 71.48 examples/s]Tokenizing train dataset:  53%|█████▎    | 4567/8564 [00:49<00:48, 82.67 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:47<00:59, 74.96 examples/s]Tokenizing train dataset:  53%|█████▎    | 4560/8564 [00:48<00:35, 111.47 examples/s]Tokenizing train dataset:  48%|████▊     | 4124/8564 [00:47<00:51, 86.23 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:49<00:55, 71.53 examples/s]Tokenizing train dataset:  53%|█████▎    | 4576/8564 [00:48<00:39, 101.07 examples/s]Tokenizing train dataset:  48%|████▊     | 4136/8564 [00:47<00:49, 89.98 examples/s]Tokenizing train dataset:  54%|█████▎    | 4592/8564 [00:50<00:50, 78.74 examples/s]Tokenizing train dataset:  48%|████▊     | 4148/8564 [00:47<00:48, 91.93 examples/s]Tokenizing train dataset:  54%|█████▎    | 4594/8564 [00:48<00:39, 100.95 examples/s]Tokenizing train dataset:  54%|█████▍    | 4604/8564 [00:50<00:47, 83.06 examples/s]Tokenizing train dataset:  54%|█████▍    | 4608/8564 [00:48<00:36, 108.61 examples/s]Tokenizing train dataset:  49%|████▊     | 4158/8564 [00:47<00:51, 84.93 examples/s]Tokenizing train dataset:  54%|█████▍    | 4620/8564 [00:50<00:41, 95.70 examples/s]Tokenizing train dataset:  54%|█████▍    | 4620/8564 [00:49<00:36, 109.33 examples/s]Tokenizing train dataset:  54%|█████▍    | 4631/8564 [00:50<00:40, 96.77 examples/s]Tokenizing train dataset:  49%|████▊     | 4169/8564 [00:47<00:58, 75.07 examples/s]Tokenizing train dataset:  54%|█████▍    | 4632/8564 [00:49<00:37, 106.16 examples/s]Tokenizing train dataset:  54%|█████▍    | 4646/8564 [00:50<00:40, 96.21 examples/s]Tokenizing train dataset:  54%|█████▍    | 4643/8564 [00:49<00:36, 105.98 examples/s]Tokenizing train dataset:  49%|████▉     | 4179/8564 [00:48<00:55, 78.37 examples/s]Tokenizing train dataset:  54%|█████▍    | 4657/8564 [00:50<00:40, 96.74 examples/s]Tokenizing train dataset:  54%|█████▍    | 4654/8564 [00:49<00:39, 100.11 examples/s]Tokenizing train dataset:  49%|████▉     | 4190/8564 [00:48<00:55, 79.08 examples/s]Tokenizing train dataset:  55%|█████▍    | 4669/8564 [00:50<00:39, 99.82 examples/s]Tokenizing train dataset:  54%|█████▍    | 4666/8564 [00:49<00:39, 98.23 examples/s] Tokenizing train dataset:  49%|████▉     | 4201/8564 [00:48<00:53, 81.12 examples/s]Tokenizing train dataset:  55%|█████▍    | 4679/8564 [00:49<00:37, 103.52 examples/s]Tokenizing train dataset:  55%|█████▍    | 4685/8564 [00:50<00:39, 97.55 examples/s]Tokenizing train dataset:  49%|████▉     | 4211/8564 [00:48<00:54, 80.53 examples/s]Tokenizing train dataset:  55%|█████▍    | 4690/8564 [00:49<00:37, 103.85 examples/s]Tokenizing train dataset:  55%|█████▍    | 4696/8564 [00:51<00:38, 100.11 examples/s]Tokenizing train dataset:  49%|████▉     | 4221/8564 [00:48<00:52, 82.92 examples/s]Tokenizing train dataset:  55%|█████▍    | 4707/8564 [00:51<00:39, 98.13 examples/s] Tokenizing train dataset:  55%|█████▍    | 4705/8564 [00:49<00:39, 98.37 examples/s] Tokenizing train dataset:  49%|████▉     | 4232/8564 [00:48<00:58, 73.79 examples/s]Tokenizing train dataset:  55%|█████▌    | 4718/8564 [00:51<00:39, 96.74 examples/s]Tokenizing train dataset:  55%|█████▌    | 4719/8564 [00:50<00:36, 105.34 examples/s]Tokenizing train dataset:  50%|████▉     | 4240/8564 [00:48<01:02, 68.66 examples/s]Tokenizing train dataset:  55%|█████▌    | 4735/8564 [00:51<00:34, 110.39 examples/s]Tokenizing train dataset:  55%|█████▌    | 4730/8564 [00:50<00:37, 101.76 examples/s]Tokenizing train dataset:  50%|████▉     | 4248/8564 [00:49<01:02, 69.27 examples/s]Tokenizing train dataset:  55%|█████▌    | 4748/8564 [00:51<00:34, 109.51 examples/s]Tokenizing train dataset:  55%|█████▌    | 4744/8564 [00:50<00:35, 107.60 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:49<00:52, 81.34 examples/s]Tokenizing train dataset:  50%|████▉     | 4274/8564 [00:49<00:44, 95.99 examples/s]Tokenizing train dataset:  56%|█████▌    | 4760/8564 [00:50<00:37, 101.83 examples/s]Tokenizing train dataset:  56%|█████▌    | 4760/8564 [00:51<00:46, 82.68 examples/s] Tokenizing train dataset:  50%|█████     | 4288/8564 [00:49<00:41, 103.68 examples/s]Tokenizing train dataset:  56%|█████▌    | 4775/8564 [00:50<00:38, 97.96 examples/s] Tokenizing train dataset:  50%|█████     | 4300/8564 [00:49<00:41, 103.39 examples/s]Tokenizing train dataset:  56%|█████▌    | 4772/8564 [00:52<00:51, 73.04 examples/s]Tokenizing train dataset:  56%|█████▌    | 4789/8564 [00:50<00:35, 107.01 examples/s]Tokenizing train dataset:  50%|█████     | 4316/8564 [00:49<00:40, 104.75 examples/s]Tokenizing train dataset:  56%|█████▌    | 4803/8564 [00:50<00:33, 112.66 examples/s]Tokenizing train dataset:  56%|█████▋    | 4825/8564 [00:50<00:26, 139.63 examples/s]Tokenizing train dataset:  56%|█████▌    | 4786/8564 [00:52<00:55, 68.62 examples/s]Tokenizing train dataset:  51%|█████     | 4327/8564 [00:49<00:43, 96.98 examples/s] Tokenizing train dataset:  57%|█████▋    | 4850/8564 [00:51<00:23, 160.47 examples/s]Tokenizing train dataset:  56%|█████▌    | 4797/8564 [00:52<00:54, 68.74 examples/s]Tokenizing train dataset:  51%|█████     | 4338/8564 [00:49<00:49, 86.04 examples/s]Tokenizing train dataset:  57%|█████▋    | 4870/8564 [00:51<00:22, 166.96 examples/s]Tokenizing train dataset:  56%|█████▌    | 4816/8564 [00:52<00:44, 84.82 examples/s]Tokenizing train dataset:  57%|█████▋    | 4889/8564 [00:51<00:21, 172.22 examples/s]Tokenizing train dataset:  51%|█████     | 4350/8564 [00:50<00:51, 82.12 examples/s]Tokenizing train dataset:  57%|█████▋    | 4842/8564 [00:52<00:32, 115.38 examples/s]Tokenizing train dataset:  57%|█████▋    | 4911/8564 [00:51<00:21, 169.17 examples/s]Tokenizing train dataset:  51%|█████     | 4359/8564 [00:50<00:56, 74.93 examples/s]Tokenizing train dataset:  57%|█████▋    | 4860/8564 [00:52<00:28, 128.22 examples/s]Tokenizing train dataset:  58%|█████▊    | 4930/8564 [00:51<00:21, 168.98 examples/s]Tokenizing train dataset:  51%|█████     | 4371/8564 [00:50<00:51, 80.64 examples/s]Tokenizing train dataset:  57%|█████▋    | 4879/8564 [00:52<00:26, 141.31 examples/s]Tokenizing train dataset:  57%|█████▋    | 4898/8564 [00:52<00:24, 152.26 examples/s]Tokenizing train dataset:  51%|█████     | 4383/8564 [00:50<00:51, 81.69 examples/s]Tokenizing train dataset:  58%|█████▊    | 4955/8564 [00:51<00:24, 147.22 examples/s]Tokenizing train dataset:  57%|█████▋    | 4920/8564 [00:53<00:22, 163.63 examples/s]Tokenizing train dataset:  51%|█████▏    | 4394/8564 [00:50<00:53, 77.93 examples/s]Tokenizing train dataset:  58%|█████▊    | 4944/8564 [00:53<00:20, 177.29 examples/s]Tokenizing train dataset:  58%|█████▊    | 4977/8564 [00:51<00:26, 135.73 examples/s]Tokenizing train dataset:  51%|█████▏    | 4407/8564 [00:50<00:46, 88.90 examples/s]Tokenizing train dataset:  58%|█████▊    | 4993/8564 [00:51<00:25, 140.62 examples/s]Tokenizing train dataset:  52%|█████▏    | 4421/8564 [00:50<00:43, 94.63 examples/s]Tokenizing train dataset:  59%|█████▊    | 5013/8564 [00:52<00:24, 147.32 examples/s]Tokenizing train dataset:  58%|█████▊    | 4967/8564 [00:53<00:25, 139.34 examples/s]Tokenizing train dataset:  52%|█████▏    | 4437/8564 [00:51<00:40, 103.17 examples/s]Tokenizing train dataset:  58%|█████▊    | 4984/8564 [00:53<00:25, 141.21 examples/s]Tokenizing train dataset:  59%|█████▊    | 5030/8564 [00:52<00:25, 137.23 examples/s]Tokenizing train dataset:  52%|█████▏    | 4452/8564 [00:51<00:58, 69.90 examples/s] Tokenizing train dataset:  58%|█████▊    | 5004/8564 [00:53<00:35, 99.78 examples/s] Tokenizing train dataset:  59%|█████▉    | 5057/8564 [00:52<00:32, 106.87 examples/s]Tokenizing train dataset:  52%|█████▏    | 4461/8564 [00:51<00:56, 72.72 examples/s]Tokenizing train dataset:  59%|█████▊    | 5017/8564 [00:54<00:35, 99.52 examples/s]Tokenizing train dataset:  59%|█████▉    | 5075/8564 [00:52<00:30, 114.22 examples/s]Tokenizing train dataset:  52%|█████▏    | 4477/8564 [00:51<00:46, 86.99 examples/s]Tokenizing train dataset:  59%|█████▉    | 5035/8564 [00:54<00:31, 112.40 examples/s]Tokenizing train dataset:  60%|█████▉    | 5097/8564 [00:52<00:25, 133.51 examples/s]Tokenizing train dataset:  59%|█████▉    | 5061/8564 [00:54<00:24, 141.95 examples/s]Tokenizing train dataset:  60%|█████▉    | 5118/8564 [00:52<00:23, 149.11 examples/s]Tokenizing train dataset:  52%|█████▏    | 4488/8564 [00:51<00:53, 76.24 examples/s]Tokenizing train dataset:  59%|█████▉    | 5087/8564 [00:54<00:20, 167.81 examples/s]Tokenizing train dataset:  60%|██████    | 5145/8564 [00:53<00:20, 170.48 examples/s]Tokenizing train dataset:  53%|█████▎    | 4498/8564 [00:51<00:50, 79.87 examples/s]Tokenizing train dataset:  60%|██████    | 5167/8564 [00:53<00:19, 174.81 examples/s]Tokenizing train dataset:  60%|█████▉    | 5114/8564 [00:54<00:20, 166.40 examples/s]Tokenizing train dataset:  61%|██████    | 5186/8564 [00:53<00:19, 175.77 examples/s]Tokenizing train dataset:  60%|█████▉    | 5138/8564 [00:54<00:18, 181.97 examples/s]Tokenizing train dataset:  53%|█████▎    | 4513/8564 [00:52<00:52, 77.78 examples/s]Tokenizing train dataset:  53%|█████▎    | 4525/8564 [00:52<00:46, 86.04 examples/s]Tokenizing train dataset:  61%|██████    | 5209/8564 [00:53<00:20, 167.34 examples/s]Tokenizing train dataset:  60%|██████    | 5160/8564 [00:54<00:20, 166.95 examples/s]Tokenizing train dataset:  53%|█████▎    | 4540/8564 [00:52<00:41, 96.35 examples/s]Tokenizing train dataset:  60%|██████    | 5179/8564 [00:54<00:20, 165.90 examples/s]Tokenizing train dataset:  61%|██████    | 5230/8564 [00:53<00:22, 151.21 examples/s]Tokenizing train dataset:  53%|█████▎    | 4555/8564 [00:52<00:38, 104.57 examples/s]Tokenizing train dataset:  61%|██████▏   | 5250/8564 [00:53<00:20, 158.32 examples/s]Tokenizing train dataset:  61%|██████    | 5200/8564 [00:55<00:21, 157.82 examples/s]Tokenizing train dataset:  53%|█████▎    | 4568/8564 [00:52<00:37, 106.41 examples/s]Tokenizing train dataset:  61%|██████    | 5225/8564 [00:55<00:19, 173.92 examples/s]Tokenizing train dataset:  62%|██████▏   | 5270/8564 [00:53<00:20, 157.48 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:52<00:43, 92.37 examples/s] Tokenizing train dataset:  61%|██████▏   | 5249/8564 [00:55<00:17, 188.87 examples/s]Tokenizing train dataset:  62%|██████▏   | 5295/8564 [00:53<00:18, 178.60 examples/s]Tokenizing train dataset:  62%|██████▏   | 5274/8564 [00:55<00:16, 202.20 examples/s]Tokenizing train dataset:  54%|█████▎    | 4590/8564 [00:52<00:44, 89.08 examples/s]Tokenizing train dataset:  62%|██████▏   | 5320/8564 [00:54<00:19, 170.65 examples/s]Tokenizing train dataset:  62%|██████▏   | 5300/8564 [00:55<00:15, 212.32 examples/s]Tokenizing train dataset:  54%|█████▎    | 4601/8564 [00:52<00:45, 86.32 examples/s]Tokenizing train dataset:  62%|██████▏   | 5339/8564 [00:54<00:21, 152.53 examples/s]Tokenizing train dataset:  62%|██████▏   | 5327/8564 [00:55<00:16, 190.93 examples/s]Tokenizing train dataset:  63%|██████▎   | 5355/8564 [00:54<00:21, 151.38 examples/s]Tokenizing train dataset:  54%|█████▍    | 4615/8564 [00:53<00:49, 79.12 examples/s]Tokenizing train dataset:  62%|██████▏   | 5350/8564 [00:55<00:16, 198.80 examples/s]Tokenizing train dataset:  54%|█████▍    | 4626/8564 [00:53<00:47, 83.69 examples/s]Tokenizing train dataset:  63%|██████▎   | 5375/8564 [00:55<00:17, 180.57 examples/s]Tokenizing train dataset:  63%|██████▎   | 5376/8564 [00:54<00:25, 126.13 examples/s]Tokenizing train dataset:  54%|█████▍    | 4639/8564 [00:53<00:47, 82.91 examples/s]Tokenizing train dataset:  63%|██████▎   | 5400/8564 [00:54<00:22, 137.88 examples/s]Tokenizing train dataset:  63%|██████▎   | 5400/8564 [00:56<00:18, 170.29 examples/s]Tokenizing train dataset:  54%|█████▍    | 4648/8564 [00:53<00:53, 72.99 examples/s]Tokenizing train dataset:  63%|██████▎   | 5420/8564 [00:56<00:18, 172.09 examples/s]Tokenizing train dataset:  63%|██████▎   | 5420/8564 [00:54<00:23, 136.06 examples/s]Tokenizing train dataset:  64%|██████▎   | 5441/8564 [00:56<00:17, 177.83 examples/s]Tokenizing train dataset:  54%|█████▍    | 4662/8564 [00:53<00:50, 77.94 examples/s]Tokenizing train dataset:  64%|██████▎   | 5446/8564 [00:55<00:20, 151.65 examples/s]Tokenizing train dataset:  64%|██████▍   | 5464/8564 [00:56<00:17, 179.23 examples/s]Tokenizing train dataset:  55%|█████▍    | 4671/8564 [00:53<00:51, 76.05 examples/s]Tokenizing train dataset:  64%|██████▍   | 5463/8564 [00:55<00:20, 154.96 examples/s]Tokenizing train dataset:  64%|██████▍   | 5483/8564 [00:56<00:19, 159.44 examples/s]Tokenizing train dataset:  55%|█████▍    | 4679/8564 [00:54<00:58, 66.42 examples/s]Tokenizing train dataset:  64%|██████▍   | 5491/8564 [00:55<00:19, 156.86 examples/s]Tokenizing train dataset:  64%|██████▍   | 5500/8564 [00:56<00:20, 152.80 examples/s]Tokenizing train dataset:  55%|█████▍    | 4688/8564 [00:54<00:54, 70.68 examples/s]Tokenizing train dataset:  64%|██████▍   | 5510/8564 [00:55<00:21, 142.25 examples/s]Tokenizing train dataset:  64%|██████▍   | 5521/8564 [00:56<00:18, 162.58 examples/s]Tokenizing train dataset:  55%|█████▍    | 4698/8564 [00:54<00:50, 76.52 examples/s]Tokenizing train dataset:  65%|██████▍   | 5531/8564 [00:55<00:19, 154.78 examples/s]Tokenizing train dataset:  55%|█████▍    | 4708/8564 [00:54<00:47, 81.60 examples/s]Tokenizing train dataset:  65%|██████▍   | 5543/8564 [00:57<00:20, 150.46 examples/s]Tokenizing train dataset:  55%|█████▌    | 4718/8564 [00:54<00:46, 82.30 examples/s]Tokenizing train dataset:  65%|██████▍   | 5555/8564 [00:55<00:19, 155.23 examples/s]Tokenizing train dataset:  65%|██████▍   | 5559/8564 [00:57<00:21, 139.06 examples/s]Tokenizing train dataset:  55%|█████▌    | 4730/8564 [00:54<00:44, 85.51 examples/s]Tokenizing train dataset:  65%|██████▌   | 5580/8564 [00:55<00:18, 164.84 examples/s]Tokenizing train dataset:  65%|██████▌   | 5579/8564 [00:57<00:19, 151.49 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:54<00:42, 90.81 examples/s]Tokenizing train dataset:  65%|██████▌   | 5601/8564 [00:55<00:17, 171.95 examples/s]Tokenizing train dataset:  65%|██████▌   | 5600/8564 [00:57<00:19, 153.18 examples/s]Tokenizing train dataset:  56%|█████▌    | 4758/8564 [00:54<00:42, 90.57 examples/s]Tokenizing train dataset:  66%|██████▌   | 5627/8564 [00:56<00:18, 162.49 examples/s]Tokenizing train dataset:  66%|██████▌   | 5616/8564 [00:57<00:19, 148.19 examples/s]Tokenizing train dataset:  66%|██████▌   | 5645/8564 [00:56<00:17, 162.66 examples/s]Tokenizing train dataset:  56%|█████▌    | 4768/8564 [00:55<00:43, 86.65 examples/s]Tokenizing train dataset:  66%|██████▌   | 5640/8564 [00:57<00:18, 157.29 examples/s]Tokenizing train dataset:  66%|██████▌   | 5667/8564 [00:56<00:16, 175.94 examples/s]Tokenizing train dataset:  56%|█████▌    | 4779/8564 [00:55<00:42, 90.05 examples/s]Tokenizing train dataset:  66%|██████▌   | 5663/8564 [00:57<00:20, 144.81 examples/s]Tokenizing train dataset:  56%|█████▌    | 4791/8564 [00:55<00:41, 91.41 examples/s]Tokenizing train dataset:  67%|██████▋   | 5696/8564 [00:56<00:15, 180.57 examples/s]Tokenizing train dataset:  66%|██████▋   | 5686/8564 [00:57<00:18, 159.75 examples/s]Tokenizing train dataset:  56%|█████▌    | 4802/8564 [00:55<00:39, 94.69 examples/s]Tokenizing train dataset:  67%|██████▋   | 5720/8564 [00:56<00:15, 187.78 examples/s]Tokenizing train dataset:  67%|██████▋   | 5703/8564 [00:58<00:17, 160.95 examples/s]Tokenizing train dataset:  56%|█████▌    | 4817/8564 [00:55<00:35, 104.26 examples/s]Tokenizing train dataset:  67%|██████▋   | 5750/8564 [00:56<00:15, 181.05 examples/s]Tokenizing train dataset:  67%|██████▋   | 5727/8564 [00:58<00:16, 169.69 examples/s]Tokenizing train dataset:  57%|█████▋    | 4839/8564 [00:55<00:29, 125.46 examples/s]Tokenizing train dataset:  67%|██████▋   | 5748/8564 [00:58<00:15, 178.72 examples/s]Tokenizing train dataset:  57%|█████▋    | 4858/8564 [00:55<00:26, 139.00 examples/s]Tokenizing train dataset:  67%|██████▋   | 5779/8564 [00:56<00:15, 178.21 examples/s]Tokenizing train dataset:  68%|██████▊   | 5781/8564 [00:58<00:14, 196.93 examples/s]Tokenizing train dataset:  68%|██████▊   | 5801/8564 [00:57<00:14, 185.13 examples/s]Tokenizing train dataset:  57%|█████▋    | 4873/8564 [00:55<00:28, 131.16 examples/s]Tokenizing train dataset:  68%|██████▊   | 5801/8564 [00:58<00:14, 196.56 examples/s]Tokenizing train dataset:  68%|██████▊   | 5825/8564 [00:57<00:14, 193.32 examples/s]Tokenizing train dataset:  57%|█████▋    | 4896/8564 [00:56<00:29, 126.32 examples/s]Tokenizing train dataset:  68%|██████▊   | 5821/8564 [00:58<00:14, 182.96 examples/s]Tokenizing train dataset:  68%|██████▊   | 5846/8564 [00:57<00:14, 190.89 examples/s]Tokenizing train dataset:  57%|█████▋    | 4910/8564 [00:56<00:37, 97.50 examples/s] Tokenizing train dataset:  68%|██████▊   | 5866/8564 [00:57<00:21, 122.94 examples/s]Tokenizing train dataset:  68%|██████▊   | 5847/8564 [00:58<00:21, 124.20 examples/s]Tokenizing train dataset:  58%|█████▊    | 4930/8564 [00:56<00:33, 108.47 examples/s]Tokenizing train dataset:  68%|██████▊   | 5864/8564 [00:59<00:20, 130.84 examples/s]Tokenizing train dataset:  58%|█████▊    | 4954/8564 [00:56<00:27, 132.03 examples/s]Tokenizing train dataset:  69%|██████▉   | 5889/8564 [00:57<00:22, 117.30 examples/s]Tokenizing train dataset:  58%|█████▊    | 4969/8564 [00:56<00:26, 133.47 examples/s]Tokenizing train dataset:  69%|██████▉   | 5888/8564 [00:59<00:20, 133.05 examples/s]Tokenizing train dataset:  69%|██████▉   | 5903/8564 [00:57<00:22, 115.82 examples/s]Tokenizing train dataset:  58%|█████▊    | 4993/8564 [00:56<00:23, 150.93 examples/s]Tokenizing train dataset:  69%|██████▉   | 5911/8564 [00:59<00:19, 132.99 examples/s]Tokenizing train dataset:  69%|██████▉   | 5922/8564 [00:58<00:21, 122.37 examples/s]Tokenizing train dataset:  59%|█████▊    | 5015/8564 [00:56<00:22, 161.05 examples/s]Tokenizing train dataset:  69%|██████▉   | 5941/8564 [00:58<00:19, 131.41 examples/s]Tokenizing train dataset:  59%|█████▉    | 5035/8564 [00:57<00:20, 170.32 examples/s]Tokenizing train dataset:  69%|██████▉   | 5930/8564 [00:59<00:20, 131.23 examples/s]Tokenizing train dataset:  59%|█████▉    | 5060/8564 [00:57<00:18, 186.99 examples/s]Tokenizing train dataset:  70%|██████▉   | 5961/8564 [00:58<00:19, 131.73 examples/s]Tokenizing train dataset:  69%|██████▉   | 5949/8564 [00:59<00:19, 131.37 examples/s]Tokenizing train dataset:  59%|█████▉    | 5085/8564 [00:57<00:17, 201.93 examples/s]Tokenizing train dataset:  70%|██████▉   | 5977/8564 [00:58<00:19, 130.56 examples/s]Tokenizing train dataset:  70%|██████▉   | 5969/8564 [00:59<00:18, 141.04 examples/s]Tokenizing train dataset:  60%|█████▉    | 5106/8564 [00:57<00:17, 194.23 examples/s]Tokenizing train dataset:  60%|█████▉    | 5132/8564 [00:57<00:17, 201.72 examples/s]Tokenizing train dataset:  60%|██████    | 5155/8564 [00:57<00:16, 207.43 examples/s]Tokenizing train dataset:  60%|██████    | 5179/8564 [00:57<00:16, 209.47 examples/s]Tokenizing train dataset:  70%|██████▉   | 5987/8564 [01:00<00:29, 88.37 examples/s] Tokenizing train dataset:  70%|███████   | 6005/8564 [00:58<00:26, 94.91 examples/s] Tokenizing train dataset:  61%|██████    | 5201/8564 [00:57<00:15, 210.76 examples/s]Tokenizing train dataset:  70%|███████   | 6023/8564 [00:59<00:23, 108.09 examples/s]Tokenizing train dataset:  70%|███████   | 6002/8564 [01:00<00:26, 95.45 examples/s]Tokenizing train dataset:  61%|██████    | 5225/8564 [00:57<00:15, 217.49 examples/s]Tokenizing train dataset:  71%|███████   | 6047/8564 [00:59<00:19, 132.11 examples/s]Tokenizing train dataset:  70%|███████   | 6018/8564 [01:00<00:24, 103.08 examples/s]Tokenizing train dataset:  61%|██████▏   | 5258/8564 [00:58<00:13, 240.45 examples/s]Tokenizing train dataset:  71%|███████   | 6068/8564 [00:59<00:17, 145.98 examples/s]Tokenizing train dataset:  70%|███████   | 6035/8564 [01:00<00:25, 100.37 examples/s]Tokenizing train dataset:  62%|██████▏   | 5287/8564 [00:58<00:13, 247.34 examples/s]Tokenizing train dataset:  71%|███████   | 6087/8564 [00:59<00:19, 129.57 examples/s]Tokenizing train dataset:  71%|███████   | 6058/8564 [01:00<00:20, 123.54 examples/s]Tokenizing train dataset:  71%|███████   | 6079/8564 [01:00<00:17, 141.68 examples/s]Tokenizing train dataset:  62%|██████▏   | 5318/8564 [00:58<00:17, 188.59 examples/s]Tokenizing train dataset:  71%|███████▏  | 6109/8564 [00:59<00:19, 125.22 examples/s]Tokenizing train dataset:  71%|███████▏  | 6105/8564 [01:01<00:16, 149.07 examples/s]Tokenizing train dataset:  72%|███████▏  | 6127/8564 [00:59<00:18, 134.66 examples/s]Tokenizing train dataset:  72%|███████▏  | 6125/8564 [01:01<00:15, 160.22 examples/s]Tokenizing train dataset:  62%|██████▏   | 5340/8564 [00:58<00:21, 151.71 examples/s]Tokenizing train dataset:  72%|███████▏  | 6156/8564 [00:59<00:14, 168.44 examples/s]Tokenizing train dataset:  72%|███████▏  | 6156/8564 [01:01<00:12, 196.46 examples/s]Tokenizing train dataset:  63%|██████▎   | 5358/8564 [00:58<00:20, 153.18 examples/s]Tokenizing train dataset:  72%|███████▏  | 6180/8564 [00:59<00:13, 178.34 examples/s]Tokenizing train dataset:  72%|███████▏  | 6180/8564 [01:01<00:11, 205.51 examples/s]Tokenizing train dataset:  72%|███████▏  | 6206/8564 [01:00<00:11, 196.58 examples/s]Tokenizing train dataset:  72%|███████▏  | 6206/8564 [01:01<00:10, 215.89 examples/s]Tokenizing train dataset:  63%|██████▎   | 5383/8564 [00:58<00:22, 139.42 examples/s]Tokenizing train dataset:  73%|███████▎  | 6235/8564 [01:00<00:11, 210.29 examples/s]Tokenizing train dataset:  73%|███████▎  | 6232/8564 [01:01<00:10, 226.78 examples/s]Tokenizing train dataset:  63%|██████▎   | 5407/8564 [00:59<00:22, 139.32 examples/s]Tokenizing train dataset:  73%|███████▎  | 6264/8564 [01:00<00:13, 168.85 examples/s]Tokenizing train dataset:  73%|███████▎  | 6261/8564 [01:01<00:11, 195.10 examples/s]Tokenizing train dataset:  64%|██████▎   | 5440/8564 [00:59<00:18, 173.15 examples/s]Tokenizing train dataset:  73%|███████▎  | 6290/8564 [01:00<00:12, 185.17 examples/s]Tokenizing train dataset:  64%|██████▍   | 5460/8564 [00:59<00:17, 176.90 examples/s]Tokenizing train dataset:  73%|███████▎  | 6290/8564 [01:01<00:13, 173.82 examples/s]Tokenizing train dataset:  64%|██████▍   | 5490/8564 [00:59<00:16, 182.65 examples/s]Tokenizing train dataset:  74%|███████▍  | 6316/8564 [01:00<00:13, 170.59 examples/s]Tokenizing train dataset:  64%|██████▍   | 5516/8564 [00:59<00:15, 191.54 examples/s]Tokenizing train dataset:  74%|███████▍  | 6344/8564 [01:00<00:13, 167.47 examples/s]Tokenizing train dataset:  74%|███████▍  | 6319/8564 [01:02<00:15, 144.83 examples/s]Tokenizing train dataset:  65%|██████▍   | 5537/8564 [00:59<00:15, 193.88 examples/s]Tokenizing train dataset:  74%|███████▍  | 6365/8564 [01:00<00:12, 171.69 examples/s]Tokenizing train dataset:  74%|███████▍  | 6343/8564 [01:02<00:13, 162.13 examples/s]Tokenizing train dataset:  65%|██████▍   | 5559/8564 [00:59<00:15, 193.74 examples/s]Tokenizing train dataset:  75%|███████▍  | 6387/8564 [01:01<00:12, 176.52 examples/s]Tokenizing train dataset:  65%|██████▌   | 5580/8564 [00:59<00:15, 193.39 examples/s]Tokenizing train dataset:  74%|███████▍  | 6372/8564 [01:02<00:12, 169.67 examples/s]Tokenizing train dataset:  75%|███████▍  | 6407/8564 [01:01<00:12, 174.96 examples/s]Tokenizing train dataset:  65%|██████▌   | 5604/8564 [01:00<00:14, 204.46 examples/s]Tokenizing train dataset:  75%|███████▌  | 6431/8564 [01:01<00:11, 184.50 examples/s]Tokenizing train dataset:  66%|██████▌   | 5631/8564 [01:00<00:14, 207.75 examples/s]Tokenizing train dataset:  75%|███████▍  | 6400/8564 [01:02<00:15, 142.71 examples/s]Tokenizing train dataset:  75%|███████▌  | 6457/8564 [01:01<00:11, 186.46 examples/s]Tokenizing train dataset:  66%|██████▌   | 5661/8564 [01:00<00:15, 191.63 examples/s]Tokenizing train dataset:  75%|███████▍  | 6420/8564 [01:02<00:15, 140.97 examples/s]Tokenizing train dataset:  76%|███████▌  | 6483/8564 [01:01<00:12, 167.08 examples/s]Tokenizing train dataset:  66%|██████▋   | 5681/8564 [01:00<00:16, 177.30 examples/s]Tokenizing train dataset:  75%|███████▌  | 6451/8564 [01:03<00:13, 152.22 examples/s]Tokenizing train dataset:  76%|███████▌  | 6504/8564 [01:01<00:12, 158.90 examples/s]Tokenizing train dataset:  76%|███████▌  | 6469/8564 [01:03<00:13, 155.76 examples/s]Tokenizing train dataset:  67%|██████▋   | 5703/8564 [01:00<00:17, 162.07 examples/s]Tokenizing train dataset:  76%|███████▋  | 6532/8564 [01:01<00:11, 176.23 examples/s]Tokenizing train dataset:  76%|███████▌  | 6487/8564 [01:03<00:13, 158.65 examples/s]Tokenizing train dataset:  67%|██████▋   | 5722/8564 [01:00<00:17, 161.40 examples/s]Tokenizing train dataset:  76%|███████▋  | 6551/8564 [01:02<00:11, 178.84 examples/s]Tokenizing train dataset:  76%|███████▌  | 6504/8564 [01:03<00:13, 152.19 examples/s]Tokenizing train dataset:  67%|██████▋   | 5740/8564 [01:00<00:20, 136.65 examples/s]Tokenizing train dataset:  76%|███████▋  | 6531/8564 [01:03<00:11, 179.52 examples/s]Tokenizing train dataset:  77%|███████▋  | 6579/8564 [01:02<00:11, 172.24 examples/s]Tokenizing train dataset:  67%|██████▋   | 5770/8564 [01:01<00:16, 171.21 examples/s]Tokenizing train dataset:  77%|███████▋  | 6560/8564 [01:03<00:11, 174.61 examples/s]Tokenizing train dataset:  68%|██████▊   | 5791/8564 [01:01<00:15, 175.11 examples/s]Tokenizing train dataset:  77%|███████▋  | 6602/8564 [01:02<00:13, 147.19 examples/s]Tokenizing train dataset:  77%|███████▋  | 6579/8564 [01:03<00:11, 175.54 examples/s]Tokenizing train dataset:  68%|██████▊   | 5812/8564 [01:01<00:15, 179.29 examples/s]Tokenizing train dataset:  77%|███████▋  | 6600/8564 [01:04<00:14, 140.14 examples/s]Tokenizing train dataset:  77%|███████▋  | 6623/8564 [01:02<00:17, 112.70 examples/s]Tokenizing train dataset:  68%|██████▊   | 5840/8564 [01:01<00:18, 144.31 examples/s]Tokenizing train dataset:  77%|███████▋  | 6628/8564 [01:04<00:13, 148.83 examples/s]Tokenizing train dataset:  78%|███████▊  | 6646/8564 [01:02<00:16, 113.73 examples/s]Tokenizing train dataset:  68%|██████▊   | 5859/8564 [01:01<00:20, 130.12 examples/s]Tokenizing train dataset:  78%|███████▊  | 6646/8564 [01:04<00:12, 153.56 examples/s]Tokenizing train dataset:  78%|███████▊  | 6663/8564 [01:03<00:15, 119.67 examples/s]Tokenizing train dataset:  78%|███████▊  | 6669/8564 [01:04<00:11, 166.45 examples/s]Tokenizing train dataset:  69%|██████▊   | 5876/8564 [01:01<00:22, 118.74 examples/s]Tokenizing train dataset:  78%|███████▊  | 6678/8564 [01:03<00:15, 121.78 examples/s]Tokenizing train dataset:  78%|███████▊  | 6696/8564 [01:04<00:09, 189.18 examples/s]Tokenizing train dataset:  78%|███████▊  | 6705/8564 [01:03<00:12, 152.39 examples/s]Tokenizing train dataset:  69%|██████▉   | 5892/8564 [01:02<00:23, 115.96 examples/s]Tokenizing train dataset:  78%|███████▊  | 6717/8564 [01:04<00:09, 193.94 examples/s]Tokenizing train dataset:  69%|██████▉   | 5916/8564 [01:02<00:18, 141.05 examples/s]Tokenizing train dataset:  79%|███████▊  | 6725/8564 [01:03<00:11, 153.63 examples/s]Tokenizing train dataset:  79%|███████▉  | 6755/8564 [01:04<00:08, 208.62 examples/s]Tokenizing train dataset:  69%|██████▉   | 5940/8564 [01:02<00:16, 158.87 examples/s]Tokenizing train dataset:  79%|███████▊  | 6743/8564 [01:03<00:11, 157.99 examples/s]Tokenizing train dataset:  79%|███████▉  | 6767/8564 [01:03<00:10, 174.34 examples/s]Tokenizing train dataset:  70%|██████▉   | 5961/8564 [01:02<00:16, 154.73 examples/s]Tokenizing train dataset:  79%|███████▉  | 6790/8564 [01:04<00:09, 187.71 examples/s]Tokenizing train dataset:  79%|███████▉  | 6787/8564 [01:03<00:10, 171.81 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [01:02<00:17, 148.79 examples/s]Tokenizing train dataset:  80%|███████▉  | 6819/8564 [01:05<00:09, 185.07 examples/s]Tokenizing train dataset:  70%|███████   | 6004/8564 [01:02<00:15, 164.26 examples/s]Tokenizing train dataset:  80%|███████▉  | 6810/8564 [01:03<00:11, 148.26 examples/s]Tokenizing train dataset:  70%|███████   | 6023/8564 [01:02<00:15, 168.25 examples/s]Tokenizing train dataset:  80%|███████▉  | 6847/8564 [01:05<00:09, 177.91 examples/s]Tokenizing train dataset:  71%|███████   | 6046/8564 [01:02<00:13, 183.23 examples/s]Tokenizing train dataset:  80%|████████  | 6869/8564 [01:05<00:09, 185.87 examples/s]Tokenizing train dataset:  80%|███████▉  | 6828/8564 [01:04<00:13, 130.62 examples/s]Tokenizing train dataset:  80%|████████  | 6893/8564 [01:05<00:08, 197.72 examples/s]Tokenizing train dataset:  71%|███████   | 6066/8564 [01:02<00:13, 181.02 examples/s]Tokenizing train dataset:  80%|███████▉  | 6850/8564 [01:04<00:13, 124.92 examples/s]Tokenizing train dataset:  71%|███████   | 6086/8564 [01:03<00:13, 179.14 examples/s]Tokenizing train dataset:  81%|████████  | 6924/8564 [01:05<00:08, 196.82 examples/s]Tokenizing train dataset:  80%|████████  | 6867/8564 [01:04<00:13, 129.11 examples/s]Tokenizing train dataset:  71%|███████▏  | 6106/8564 [01:03<00:13, 177.57 examples/s]Tokenizing train dataset:  81%|████████  | 6949/8564 [01:05<00:07, 204.39 examples/s]Tokenizing train dataset:  72%|███████▏  | 6129/8564 [01:03<00:12, 190.91 examples/s]Tokenizing train dataset:  80%|████████  | 6881/8564 [01:04<00:13, 127.80 examples/s]Tokenizing train dataset:  82%|████████▏ | 6980/8564 [01:05<00:08, 197.39 examples/s]Tokenizing train dataset:  72%|███████▏  | 6157/8564 [01:03<00:11, 206.55 examples/s]Tokenizing train dataset:  81%|████████  | 6898/8564 [01:04<00:12, 132.03 examples/s]Tokenizing train dataset:  72%|███████▏  | 6183/8564 [01:03<00:11, 210.23 examples/s]Tokenizing train dataset:  82%|████████▏ | 7008/8564 [01:06<00:08, 192.75 examples/s]Tokenizing train dataset:  81%|████████  | 6919/8564 [01:04<00:12, 132.07 examples/s]Tokenizing train dataset:  73%|███████▎  | 6209/8564 [01:03<00:10, 222.24 examples/s]Tokenizing train dataset:  81%|████████  | 6940/8564 [01:04<00:11, 143.51 examples/s]Tokenizing train dataset:  82%|████████▏ | 7032/8564 [01:06<00:08, 176.30 examples/s]Tokenizing train dataset:  73%|███████▎  | 6234/8564 [01:03<00:10, 227.39 examples/s]Tokenizing train dataset:  82%|████████▏ | 7056/8564 [01:06<00:08, 187.04 examples/s]Tokenizing train dataset:  73%|███████▎  | 6268/8564 [01:03<00:10, 223.72 examples/s]Tokenizing train dataset:  81%|████████▏ | 6960/8564 [01:05<00:13, 122.61 examples/s]Tokenizing train dataset:  83%|████████▎ | 7078/8564 [01:06<00:08, 183.81 examples/s]Tokenizing train dataset:  82%|████████▏ | 6980/8564 [01:05<00:11, 136.26 examples/s]Tokenizing train dataset:  74%|███████▎  | 6302/8564 [01:04<00:10, 213.09 examples/s]Tokenizing train dataset:  83%|████████▎ | 7107/8564 [01:06<00:08, 176.53 examples/s]Tokenizing train dataset:  74%|███████▍  | 6329/8564 [01:04<00:10, 220.97 examples/s]Tokenizing train dataset:  82%|████████▏ | 6997/8564 [01:05<00:13, 113.02 examples/s]Tokenizing train dataset:  83%|████████▎ | 7130/8564 [01:06<00:08, 177.70 examples/s]Tokenizing train dataset:  74%|███████▍  | 6353/8564 [01:04<00:09, 224.81 examples/s]Tokenizing train dataset:  82%|████████▏ | 7011/8564 [01:05<00:13, 113.02 examples/s]Tokenizing train dataset:  74%|███████▍  | 6377/8564 [01:04<00:09, 228.02 examples/s]Tokenizing train dataset:  84%|████████▎ | 7151/8564 [01:07<00:09, 153.48 examples/s]Tokenizing train dataset:  82%|████████▏ | 7031/8564 [01:05<00:13, 110.77 examples/s]Tokenizing train dataset:  75%|███████▍  | 6410/8564 [01:04<00:10, 214.43 examples/s]Tokenizing train dataset:  84%|████████▎ | 7171/8564 [01:07<00:08, 158.09 examples/s]Tokenizing train dataset:  82%|████████▏ | 7048/8564 [01:05<00:12, 119.60 examples/s]Tokenizing train dataset:  75%|███████▌  | 6444/8564 [01:04<00:10, 210.48 examples/s]Tokenizing train dataset:  84%|████████▍ | 7200/8564 [01:07<00:08, 162.18 examples/s]Tokenizing train dataset:  82%|████████▏ | 7062/8564 [01:06<00:12, 120.47 examples/s]Tokenizing train dataset:  76%|███████▌  | 6466/8564 [01:04<00:09, 210.78 examples/s]Tokenizing train dataset:  83%|████████▎ | 7083/8564 [01:06<00:11, 132.48 examples/s]Tokenizing train dataset:  84%|████████▍ | 7221/8564 [01:07<00:09, 138.52 examples/s]Tokenizing train dataset:  76%|███████▌  | 6492/8564 [01:05<00:10, 196.20 examples/s]Tokenizing train dataset:  83%|████████▎ | 7100/8564 [01:06<00:10, 133.64 examples/s]Tokenizing train dataset:  76%|███████▌  | 6513/8564 [01:05<00:10, 192.34 examples/s]Tokenizing train dataset:  85%|████████▍ | 7242/8564 [01:07<00:10, 130.11 examples/s]Tokenizing train dataset:  83%|████████▎ | 7119/8564 [01:06<00:10, 135.13 examples/s]Tokenizing train dataset:  76%|███████▋  | 6536/8564 [01:05<00:10, 194.73 examples/s]Tokenizing train dataset:  85%|████████▍ | 7258/8564 [01:07<00:09, 133.33 examples/s]Tokenizing train dataset:  83%|████████▎ | 7142/8564 [01:06<00:10, 133.12 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [01:05<00:10, 192.69 examples/s]Tokenizing train dataset:  85%|████████▍ | 7276/8564 [01:07<00:10, 126.49 examples/s]Tokenizing train dataset:  84%|████████▎ | 7160/8564 [01:06<00:10, 128.49 examples/s]Tokenizing train dataset:  85%|████████▌ | 7292/8564 [01:08<00:09, 130.54 examples/s]Tokenizing train dataset:  77%|███████▋  | 6590/8564 [01:05<00:11, 176.12 examples/s]Tokenizing train dataset:  84%|████████▍ | 7181/8564 [01:06<00:09, 142.37 examples/s]Tokenizing train dataset:  85%|████████▌ | 7311/8564 [01:08<00:09, 133.30 examples/s]Tokenizing train dataset:  77%|███████▋  | 6616/8564 [01:05<00:11, 173.04 examples/s]Tokenizing train dataset:  84%|████████▍ | 7200/8564 [01:06<00:09, 146.48 examples/s]Tokenizing train dataset:  86%|████████▌ | 7333/8564 [01:08<00:09, 132.01 examples/s]Tokenizing train dataset:  78%|███████▊  | 6644/8564 [01:05<00:10, 178.09 examples/s]Tokenizing train dataset:  84%|████████▍ | 7221/8564 [01:07<00:09, 136.78 examples/s]Tokenizing train dataset:  86%|████████▌ | 7357/8564 [01:08<00:07, 155.74 examples/s]Tokenizing train dataset:  78%|███████▊  | 6663/8564 [01:06<00:12, 152.15 examples/s]Tokenizing train dataset:  86%|████████▌ | 7379/8564 [01:08<00:07, 168.57 examples/s]Tokenizing train dataset:  85%|████████▍ | 7239/8564 [01:07<00:09, 138.03 examples/s]Tokenizing train dataset:  78%|███████▊  | 6690/8564 [01:06<00:10, 175.14 examples/s]Tokenizing train dataset:  85%|████████▍ | 7260/8564 [01:07<00:08, 149.17 examples/s]Tokenizing train dataset:  85%|████████▌ | 7285/8564 [01:07<00:07, 171.81 examples/s]Tokenizing train dataset:  86%|████████▋ | 7404/8564 [01:08<00:08, 139.31 examples/s]Tokenizing train dataset:  79%|███████▊  | 6726/8564 [01:06<00:09, 195.08 examples/s]Tokenizing train dataset:  85%|████████▌ | 7308/8564 [01:07<00:06, 179.47 examples/s]Tokenizing train dataset:  87%|████████▋ | 7422/8564 [01:08<00:08, 139.35 examples/s]Tokenizing train dataset:  79%|███████▉  | 6757/8564 [01:06<00:09, 197.95 examples/s]Tokenizing train dataset:  86%|████████▌ | 7330/8564 [01:07<00:06, 188.22 examples/s]Tokenizing train dataset:  87%|████████▋ | 7447/8564 [01:09<00:07, 150.50 examples/s]Tokenizing train dataset:  79%|███████▉  | 6782/8564 [01:06<00:08, 206.63 examples/s]Tokenizing train dataset:  86%|████████▌ | 7354/8564 [01:07<00:06, 174.54 examples/s]Tokenizing train dataset:  87%|████████▋ | 7471/8564 [01:09<00:06, 166.96 examples/s]Tokenizing train dataset:  79%|███████▉  | 6806/8564 [01:06<00:08, 207.30 examples/s]Tokenizing train dataset:  86%|████████▌ | 7376/8564 [01:07<00:06, 181.32 examples/s]Tokenizing train dataset:  87%|████████▋ | 7489/8564 [01:09<00:06, 167.34 examples/s]Tokenizing train dataset:  88%|████████▊ | 7511/8564 [01:09<00:06, 174.70 examples/s]Tokenizing train dataset:  86%|████████▋ | 7403/8564 [01:08<00:06, 176.00 examples/s]Tokenizing train dataset:  80%|███████▉  | 6828/8564 [01:06<00:11, 146.33 examples/s]Tokenizing train dataset:  88%|████████▊ | 7537/8564 [01:09<00:05, 196.03 examples/s]Tokenizing train dataset:  87%|████████▋ | 7429/8564 [01:08<00:05, 195.32 examples/s]Tokenizing train dataset:  80%|████████  | 6854/8564 [01:07<00:11, 149.78 examples/s]Tokenizing train dataset:  88%|████████▊ | 7567/8564 [01:09<00:05, 183.92 examples/s]Tokenizing train dataset:  87%|████████▋ | 7465/8564 [01:08<00:05, 207.09 examples/s]Tokenizing train dataset:  80%|████████  | 6875/8564 [01:07<00:11, 151.12 examples/s]Tokenizing train dataset:  89%|████████▊ | 7594/8564 [01:09<00:04, 204.19 examples/s]Tokenizing train dataset:  88%|████████▊ | 7496/8564 [01:08<00:05, 202.43 examples/s]Tokenizing train dataset:  80%|████████  | 6892/8564 [01:07<00:10, 153.97 examples/s]Tokenizing train dataset:  89%|████████▉ | 7627/8564 [01:09<00:04, 202.14 examples/s]Tokenizing train dataset:  81%|████████  | 6912/8564 [01:07<00:11, 149.09 examples/s]Tokenizing train dataset:  88%|████████▊ | 7533/8564 [01:08<00:04, 209.90 examples/s]Tokenizing train dataset:  81%|████████  | 6936/8564 [01:07<00:10, 160.67 examples/s]Tokenizing train dataset:  89%|████████▉ | 7654/8564 [01:10<00:05, 163.88 examples/s]Tokenizing train dataset:  88%|████████▊ | 7561/8564 [01:08<00:05, 196.41 examples/s]Tokenizing train dataset:  89%|████████▊ | 7581/8564 [01:09<00:05, 193.42 examples/s]Tokenizing train dataset:  81%|████████  | 6958/8564 [01:07<00:10, 147.69 examples/s]Tokenizing train dataset:  90%|████████▉ | 7680/8564 [01:10<00:05, 162.11 examples/s]Tokenizing train dataset:  90%|████████▉ | 7705/8564 [01:10<00:04, 175.21 examples/s]Tokenizing train dataset:  89%|████████▉ | 7604/8564 [01:09<00:05, 166.63 examples/s]Tokenizing train dataset:  82%|████████▏ | 6982/8564 [01:08<00:11, 136.56 examples/s]Tokenizing train dataset:  90%|█████████ | 7724/8564 [01:10<00:04, 174.33 examples/s]Tokenizing train dataset:  89%|████████▉ | 7624/8564 [01:09<00:05, 167.60 examples/s]Tokenizing train dataset:  90%|█████████ | 7744/8564 [01:10<00:04, 179.92 examples/s]Tokenizing train dataset:  82%|████████▏ | 7001/8564 [01:08<00:12, 125.65 examples/s]Tokenizing train dataset:  89%|████████▉ | 7645/8564 [01:09<00:06, 137.20 examples/s]Tokenizing train dataset:  91%|█████████ | 7771/8564 [01:10<00:04, 173.52 examples/s]Tokenizing train dataset:  82%|████████▏ | 7019/8564 [01:08<00:13, 115.80 examples/s]Tokenizing train dataset:  91%|█████████ | 7790/8564 [01:10<00:04, 175.54 examples/s]Tokenizing train dataset:  89%|████████▉ | 7662/8564 [01:09<00:06, 129.65 examples/s]Tokenizing train dataset:  82%|████████▏ | 7033/8564 [01:08<00:12, 118.53 examples/s]Tokenizing train dataset:  91%|█████████ | 7809/8564 [01:11<00:04, 177.84 examples/s]Tokenizing train dataset:  90%|████████▉ | 7678/8564 [01:09<00:06, 130.18 examples/s]Tokenizing train dataset:  82%|████████▏ | 7051/8564 [01:08<00:11, 126.99 examples/s]Tokenizing train dataset:  91%|█████████▏| 7830/8564 [01:11<00:03, 183.71 examples/s]Tokenizing train dataset:  83%|████████▎ | 7067/8564 [01:08<00:11, 130.59 examples/s]Tokenizing train dataset:  92%|█████████▏| 7854/8564 [01:11<00:03, 190.79 examples/s]Tokenizing train dataset:  90%|████████▉ | 7701/8564 [01:09<00:06, 131.31 examples/s]Tokenizing train dataset:  83%|████████▎ | 7082/8564 [01:08<00:11, 134.56 examples/s]Tokenizing train dataset:  92%|█████████▏| 7877/8564 [01:11<00:03, 190.96 examples/s]Tokenizing train dataset:  90%|█████████ | 7715/8564 [01:10<00:06, 127.13 examples/s]Tokenizing train dataset:  83%|████████▎ | 7097/8564 [01:08<00:10, 136.85 examples/s]Tokenizing train dataset:  92%|█████████▏| 7900/8564 [01:11<00:03, 199.42 examples/s]Tokenizing train dataset:  90%|█████████ | 7730/8564 [01:10<00:06, 122.91 examples/s]Tokenizing train dataset:  83%|████████▎ | 7113/8564 [01:09<00:10, 138.12 examples/s]Tokenizing train dataset:  90%|█████████ | 7744/8564 [01:10<00:06, 124.79 examples/s]Tokenizing train dataset:  93%|█████████▎| 7931/8564 [01:11<00:03, 199.54 examples/s]Tokenizing train dataset:  83%|████████▎ | 7130/8564 [01:09<00:10, 135.29 examples/s]Tokenizing train dataset:  91%|█████████ | 7760/8564 [01:10<00:06, 124.44 examples/s]Tokenizing train dataset:  93%|█████████▎| 7962/8564 [01:11<00:03, 194.20 examples/s]Tokenizing train dataset:  83%|████████▎ | 7148/8564 [01:09<00:10, 135.32 examples/s]Tokenizing train dataset:  91%|█████████ | 7774/8564 [01:10<00:06, 117.12 examples/s]Tokenizing train dataset:  93%|█████████▎| 7988/8564 [01:11<00:02, 200.91 examples/s]Tokenizing train dataset:  84%|████████▎ | 7162/8564 [01:09<00:11, 125.52 examples/s]Tokenizing train dataset:  91%|█████████ | 7789/8564 [01:10<00:06, 120.06 examples/s]Tokenizing train dataset:  94%|█████████▎| 8013/8564 [01:12<00:02, 203.79 examples/s]Tokenizing train dataset:  84%|████████▍ | 7181/8564 [01:09<00:09, 140.23 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:12<00:02, 205.79 examples/s]Tokenizing train dataset:  91%|█████████ | 7809/8564 [01:10<00:06, 114.21 examples/s]Tokenizing train dataset:  84%|████████▍ | 7208/8564 [01:09<00:09, 145.82 examples/s]Tokenizing train dataset:  91%|█████████▏| 7823/8564 [01:11<00:06, 117.64 examples/s]Tokenizing train dataset:  94%|█████████▍| 8077/8564 [01:12<00:02, 200.22 examples/s]Tokenizing train dataset:  84%|████████▍ | 7224/8564 [01:09<00:10, 130.65 examples/s]Tokenizing train dataset:  92%|█████████▏| 7837/8564 [01:11<00:05, 121.46 examples/s]Tokenizing train dataset:  95%|█████████▍| 8100/8564 [01:12<00:02, 175.37 examples/s]Tokenizing train dataset:  85%|████████▍ | 7241/8564 [01:10<00:11, 115.66 examples/s]Tokenizing train dataset:  92%|█████████▏| 7858/8564 [01:11<00:05, 123.57 examples/s]Tokenizing train dataset:  95%|█████████▍| 8130/8564 [01:12<00:02, 199.87 examples/s]Tokenizing train dataset:  85%|████████▍ | 7258/8564 [01:10<00:11, 116.74 examples/s]Tokenizing train dataset:  92%|█████████▏| 7874/8564 [01:11<00:05, 117.06 examples/s]Tokenizing train dataset:  95%|█████████▌| 8161/8564 [01:12<00:01, 222.33 examples/s]Tokenizing train dataset:  85%|████████▍ | 7276/8564 [01:10<00:10, 118.00 examples/s]Tokenizing train dataset:  92%|█████████▏| 7894/8564 [01:11<00:05, 122.13 examples/s]Tokenizing train dataset:  96%|█████████▌| 8200/8564 [01:12<00:01, 224.49 examples/s]Tokenizing train dataset:  92%|█████████▏| 7911/8564 [01:11<00:05, 121.55 examples/s]Tokenizing train dataset:  85%|████████▌ | 7292/8564 [01:10<00:11, 109.72 examples/s]Tokenizing train dataset:  96%|█████████▌| 8232/8564 [01:13<00:01, 235.53 examples/s]Tokenizing train dataset:  85%|████████▌ | 7317/8564 [01:10<00:09, 137.27 examples/s]Tokenizing train dataset:  93%|█████████▎| 7924/8564 [01:11<00:05, 119.52 examples/s]Tokenizing train dataset:  96%|█████████▋| 8257/8564 [01:13<00:01, 233.49 examples/s]Tokenizing train dataset:  86%|████████▌ | 7338/8564 [01:10<00:08, 151.43 examples/s]Tokenizing train dataset:  93%|█████████▎| 7940/8564 [01:11<00:04, 126.35 examples/s]Tokenizing train dataset:  97%|█████████▋| 8285/8564 [01:13<00:01, 241.98 examples/s]Tokenizing train dataset:  97%|█████████▋| 8310/8564 [01:13<00:01, 240.86 examples/s]Tokenizing train dataset:  93%|█████████▎| 7955/8564 [01:12<00:04, 126.37 examples/s]Tokenizing train dataset:  86%|████████▌ | 7362/8564 [01:10<00:07, 161.54 examples/s]Tokenizing train dataset:  93%|█████████▎| 7976/8564 [01:12<00:04, 145.62 examples/s]Tokenizing train dataset:  86%|████████▌ | 7382/8564 [01:11<00:07, 167.10 examples/s]Tokenizing train dataset:  97%|█████████▋| 8341/8564 [01:13<00:01, 214.09 examples/s]Tokenizing train dataset:  93%|█████████▎| 8000/8564 [01:12<00:03, 170.01 examples/s]Tokenizing train dataset:  86%|████████▋ | 7400/8564 [01:11<00:07, 151.82 examples/s]Tokenizing train dataset:  94%|█████████▎| 8021/8564 [01:12<00:03, 174.58 examples/s]Tokenizing train dataset:  98%|█████████▊| 8367/8564 [01:13<00:01, 195.46 examples/s]Tokenizing train dataset:  98%|█████████▊| 8388/8564 [01:13<00:00, 198.68 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [01:12<00:02, 186.94 examples/s]Tokenizing train dataset:  87%|████████▋ | 7421/8564 [01:11<00:08, 140.28 examples/s]Tokenizing train dataset:  98%|█████████▊| 8409/8564 [01:13<00:00, 198.27 examples/s]Tokenizing train dataset:  94%|█████████▍| 8065/8564 [01:12<00:02, 181.40 examples/s]Tokenizing train dataset:  87%|████████▋ | 7440/8564 [01:11<00:07, 145.70 examples/s]Tokenizing train dataset:  98%|█████████▊| 8431/8564 [01:14<00:00, 200.58 examples/s]Tokenizing train dataset:  87%|████████▋ | 7461/8564 [01:11<00:07, 147.71 examples/s]Tokenizing train dataset:  94%|█████████▍| 8086/8564 [01:12<00:02, 164.26 examples/s]Tokenizing train dataset:  99%|█████████▊| 8453/8564 [01:14<00:00, 189.51 examples/s]Tokenizing train dataset:  87%|████████▋ | 7479/8564 [01:11<00:07, 152.54 examples/s]Tokenizing train dataset:  95%|█████████▍| 8106/8564 [01:12<00:02, 171.94 examples/s]Tokenizing train dataset:  99%|█████████▉| 8478/8564 [01:14<00:00, 196.30 examples/s]Tokenizing train dataset:  88%|████████▊ | 7502/8564 [01:11<00:06, 162.71 examples/s]Tokenizing train dataset:  95%|█████████▍| 8125/8564 [01:13<00:02, 167.79 examples/s]Tokenizing train dataset:  99%|█████████▉| 8499/8564 [01:14<00:00, 197.53 examples/s]Tokenizing train dataset:  95%|█████████▌| 8151/8564 [01:13<00:02, 183.47 examples/s]Tokenizing train dataset:  88%|████████▊ | 7533/8564 [01:11<00:06, 170.20 examples/s]Tokenizing train dataset:  95%|█████████▌| 8174/8564 [01:13<00:01, 195.64 examples/s]Tokenizing train dataset:  99%|█████████▉| 8521/8564 [01:14<00:00, 169.82 examples/s]Tokenizing train dataset:  96%|█████████▌| 8199/8564 [01:13<00:01, 203.17 examples/s]Tokenizing train dataset:  88%|████████▊ | 7551/8564 [01:12<00:06, 146.42 examples/s]Tokenizing train dataset: 100%|█████████▉| 8544/8564 [01:14<00:00, 162.52 examples/s]Tokenizing train dataset:  88%|████████▊ | 7579/8564 [01:12<00:05, 174.86 examples/s]Tokenizing train dataset:  96%|█████████▌| 8229/8564 [01:13<00:01, 200.65 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:14<00:00, 148.74 examples/s]Tokenizing train dataset:  89%|████████▊ | 7599/8564 [01:12<00:05, 165.39 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:14<00:00, 114.25 examples/s]
Tokenizing train dataset:  96%|█████████▋| 8255/8564 [01:13<00:01, 209.18 examples/s]Tokenizing train dataset:  97%|█████████▋| 8291/8564 [01:13<00:01, 240.45 examples/s]Tokenizing train dataset:  89%|████████▉ | 7627/8564 [01:12<00:06, 156.04 examples/s]Tokenizing train dataset:  97%|█████████▋| 8318/8564 [01:13<00:01, 235.69 examples/s]Tokenizing train dataset:  89%|████████▉ | 7650/8564 [01:12<00:06, 142.36 examples/s]Tokenizing train dataset:  97%|█████████▋| 8342/8564 [01:14<00:01, 194.35 examples/s]Tokenizing train dataset:  90%|████████▉ | 7674/8564 [01:12<00:06, 136.19 examples/s]Tokenizing train dataset:  98%|█████████▊| 8370/8564 [01:14<00:01, 186.27 examples/s]Tokenizing train dataset:  98%|█████████▊| 8390/8564 [01:14<00:00, 182.80 examples/s]Tokenizing train dataset:  90%|████████▉ | 7695/8564 [01:13<00:06, 140.49 examples/s]Tokenizing train dataset:  98%|█████████▊| 8413/8564 [01:14<00:00, 185.75 examples/s]Tokenizing train dataset:  90%|█████████ | 7718/8564 [01:13<00:05, 153.93 examples/s]Tokenizing train dataset:  98%|█████████▊| 8433/8564 [01:14<00:00, 187.54 examples/s]Tokenizing train dataset:  90%|█████████ | 7740/8564 [01:13<00:04, 166.37 examples/s]Tokenizing train dataset:  99%|█████████▊| 8453/8564 [01:14<00:00, 183.83 examples/s]Tokenizing train dataset:  99%|█████████▉| 8483/8564 [01:14<00:00, 212.94 examples/s]Tokenizing train dataset:  91%|█████████ | 7763/8564 [01:13<00:06, 128.65 examples/s]Tokenizing train dataset:  99%|█████████▉| 8516/8564 [01:14<00:00, 209.37 examples/s]Tokenizing train dataset:  91%|█████████ | 7783/8564 [01:13<00:05, 142.21 examples/s]Tokenizing train dataset:  91%|█████████ | 7802/8564 [01:13<00:05, 151.93 examples/s]Tokenizing train dataset: 100%|█████████▉| 8546/8564 [01:15<00:00, 197.77 examples/s]Tokenizing train dataset:  91%|█████████▏| 7823/8564 [01:13<00:04, 158.89 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:15<00:00, 113.90 examples/s]
Tokenizing train dataset:  92%|█████████▏| 7854/8564 [01:14<00:03, 179.03 examples/s]Tokenizing train dataset:  92%|█████████▏| 7877/8564 [01:14<00:03, 183.43 examples/s]Tokenizing train dataset:  92%|█████████▏| 7902/8564 [01:14<00:03, 199.32 examples/s]Tokenizing train dataset:  93%|█████████▎| 7927/8564 [01:14<00:03, 203.77 examples/s]Tokenizing train dataset:  93%|█████████▎| 7951/8564 [01:14<00:03, 200.13 examples/s]Tokenizing train dataset:  93%|█████████▎| 7978/8564 [01:14<00:02, 208.74 examples/s]Tokenizing train dataset:  93%|█████████▎| 8007/8564 [01:14<00:02, 215.90 examples/s]Tokenizing train dataset:  94%|█████████▍| 8029/8564 [01:14<00:02, 203.57 examples/s]Tokenizing train dataset:  94%|█████████▍| 8050/8564 [01:15<00:02, 201.95 examples/s]Tokenizing train dataset:  94%|█████████▍| 8072/8564 [01:15<00:02, 202.21 examples/s]Tokenizing train dataset:  95%|█████████▍| 8100/8564 [01:15<00:02, 211.15 examples/s]Tokenizing train dataset:  95%|█████████▍| 8126/8564 [01:15<00:02, 195.64 examples/s]Tokenizing train dataset:  95%|█████████▌| 8148/8564 [01:15<00:02, 176.20 examples/s]Tokenizing train dataset:  95%|█████████▌| 8174/8564 [01:15<00:02, 194.16 examples/s]Tokenizing train dataset:  96%|█████████▌| 8199/8564 [01:15<00:01, 201.00 examples/s]Tokenizing train dataset:  96%|█████████▌| 8220/8564 [01:15<00:01, 200.76 examples/s]Tokenizing train dataset:  96%|█████████▋| 8246/8564 [01:15<00:01, 215.67 examples/s]Tokenizing train dataset:  97%|█████████▋| 8282/8564 [01:16<00:01, 249.42 examples/s]Tokenizing train dataset:  97%|█████████▋| 8315/8564 [01:16<00:00, 270.65 examples/s]Tokenizing train dataset:  97%|█████████▋| 8345/8564 [01:16<00:01, 189.65 examples/s]Tokenizing train dataset:  98%|█████████▊| 8376/8564 [01:16<00:01, 179.84 examples/s]Tokenizing train dataset:  98%|█████████▊| 8409/8564 [01:16<00:00, 176.61 examples/s]Tokenizing train dataset:  98%|█████████▊| 8430/8564 [01:16<00:00, 180.01 examples/s]Tokenizing train dataset:  99%|█████████▊| 8450/8564 [01:17<00:00, 184.20 examples/s]Tokenizing train dataset:  99%|█████████▉| 8475/8564 [01:17<00:00, 197.09 examples/s]Tokenizing train dataset:  99%|█████████▉| 8497/8564 [01:17<00:00, 200.27 examples/s]Tokenizing train dataset: 100%|█████████▉| 8522/8564 [01:17<00:00, 201.56 examples/s]Tokenizing train dataset: 100%|█████████▉| 8546/8564 [01:17<00:00, 210.92 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [01:17<00:00, 110.29 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  34%|███▍      | 323/953 [00:00<00:00, 3170.48 examples/s]Extracting prompt in eval dataset:  37%|███▋      | 354/953 [00:00<00:00, 3402.65 examples/s]Extracting prompt in eval dataset:  32%|███▏      | 307/953 [00:00<00:00, 3021.83 examples/s]Extracting prompt in eval dataset:  78%|███████▊  | 740/953 [00:00<00:00, 3636.99 examples/s]Extracting prompt in eval dataset:  76%|███████▌  | 724/953 [00:00<00:00, 3653.80 examples/s]Extracting prompt in eval dataset:  87%|████████▋ | 830/953 [00:00<00:00, 3290.56 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3592.39 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3604.69 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2142.05 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 9965.25 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  52%|█████▏    | 500/953 [00:00<00:00, 4965.21 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4961.96 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   2%|▏         | 21/953 [00:00<00:05, 184.27 examples/s]Applying chat template to eval dataset:  46%|████▌     | 440/953 [00:00<00:00, 4341.20 examples/s]Tokenizing eval dataset:   4%|▍         | 41/953 [00:00<00:04, 184.74 examples/s]Applying chat template to eval dataset:  99%|█████████▊| 939/953 [00:00<00:00, 4471.70 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4432.23 examples/s]
Tokenizing eval dataset:   7%|▋         | 64/953 [00:00<00:06, 132.04 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:07, 118.88 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:  10%|▉         | 95/953 [00:00<00:08, 105.30 examples/s]Tokenizing eval dataset:   2%|▏         | 23/953 [00:00<00:04, 215.41 examples/s]Tokenizing eval dataset:   5%|▍         | 45/953 [00:00<00:04, 210.69 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:08, 99.43 examples/s]Tokenizing eval dataset:   8%|▊         | 73/953 [00:00<00:04, 186.73 examples/s]Tokenizing eval dataset:  13%|█▎        | 123/953 [00:01<00:09, 89.32 examples/s]Tokenizing eval dataset:  10%|▉         | 93/953 [00:00<00:04, 182.53 examples/s]Tokenizing eval dataset:  14%|█▍        | 137/953 [00:01<00:08, 96.89 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:00<00:05, 166.56 examples/s]Tokenizing eval dataset:   1%|▏         | 12/953 [00:00<00:08, 116.80 examples/s]Tokenizing eval dataset:  16%|█▌        | 149/953 [00:01<00:09, 88.62 examples/s]Tokenizing eval dataset:  14%|█▍        | 135/953 [00:00<00:04, 168.10 examples/s]Tokenizing eval dataset:   3%|▎         | 24/953 [00:00<00:08, 104.24 examples/s]Tokenizing eval dataset:  17%|█▋        | 162/953 [00:01<00:09, 84.31 examples/s]Tokenizing eval dataset:  17%|█▋        | 162/953 [00:00<00:04, 165.77 examples/s]Tokenizing eval dataset:   4%|▍         | 36/953 [00:00<00:08, 103.17 examples/s]Tokenizing eval dataset:  18%|█▊        | 174/953 [00:01<00:09, 81.99 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:04, 161.01 examples/s]Tokenizing eval dataset:   5%|▌         | 50/953 [00:00<00:09, 96.82 examples/s] Tokenizing eval dataset:  22%|██▏       | 206/953 [00:01<00:04, 168.69 examples/s]Tokenizing eval dataset:  19%|█▉        | 185/953 [00:01<00:09, 78.88 examples/s]Tokenizing eval dataset:   6%|▋         | 61/953 [00:00<00:10, 85.28 examples/s]Tokenizing eval dataset:  24%|██▍       | 233/953 [00:01<00:03, 192.29 examples/s]Tokenizing eval dataset:  21%|██        | 198/953 [00:02<00:09, 79.34 examples/s]Tokenizing eval dataset:   8%|▊         | 72/953 [00:00<00:10, 86.47 examples/s]Tokenizing eval dataset:  29%|██▉       | 276/953 [00:01<00:02, 253.13 examples/s]Tokenizing eval dataset:   9%|▉         | 85/953 [00:00<00:09, 96.14 examples/s]Tokenizing eval dataset:  34%|███▎      | 321/953 [00:01<00:02, 304.31 examples/s]Tokenizing eval dataset:  22%|██▏       | 208/953 [00:02<00:09, 80.88 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:01<00:01, 326.00 examples/s]Tokenizing eval dataset:  23%|██▎       | 219/953 [00:02<00:08, 85.98 examples/s]Tokenizing eval dataset:  10%|█         | 96/953 [00:01<00:10, 84.03 examples/s]Tokenizing eval dataset:  42%|████▏     | 402/953 [00:01<00:01, 351.71 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:02<00:06, 106.50 examples/s]Tokenizing eval dataset:  11%|█         | 107/953 [00:01<00:09, 86.05 examples/s]Tokenizing eval dataset:  48%|████▊     | 455/953 [00:01<00:01, 400.06 examples/s]Tokenizing eval dataset:  27%|██▋       | 258/953 [00:02<00:05, 128.72 examples/s]Tokenizing eval dataset:  12%|█▏        | 118/953 [00:01<00:09, 85.56 examples/s]Tokenizing eval dataset:  30%|██▉       | 283/953 [00:02<00:04, 159.63 examples/s]Tokenizing eval dataset:  54%|█████▍    | 513/953 [00:01<00:01, 385.66 examples/s]Tokenizing eval dataset:  14%|█▎        | 130/953 [00:01<00:09, 90.66 examples/s]Tokenizing eval dataset:  32%|███▏      | 305/953 [00:02<00:03, 170.65 examples/s]Tokenizing eval dataset:  16%|█▌        | 149/953 [00:01<00:07, 112.37 examples/s]Tokenizing eval dataset:  35%|███▍      | 332/953 [00:02<00:03, 192.17 examples/s]Tokenizing eval dataset:  59%|█████▉    | 561/953 [00:02<00:01, 311.06 examples/s]Tokenizing eval dataset:  17%|█▋        | 166/953 [00:01<00:06, 126.41 examples/s]Tokenizing eval dataset:  37%|███▋      | 355/953 [00:02<00:03, 188.68 examples/s]Tokenizing eval dataset:  19%|█▉        | 182/953 [00:01<00:05, 130.46 examples/s]Tokenizing eval dataset:  63%|██████▎   | 602/953 [00:02<00:01, 268.20 examples/s]Tokenizing eval dataset:  40%|████      | 385/953 [00:03<00:02, 190.69 examples/s]Tokenizing eval dataset:  21%|██        | 200/953 [00:01<00:05, 141.73 examples/s]Tokenizing eval dataset:  43%|████▎     | 407/953 [00:03<00:02, 194.71 examples/s]Tokenizing eval dataset:  66%|██████▋   | 633/953 [00:02<00:01, 249.14 examples/s]Tokenizing eval dataset:  24%|██▎       | 224/953 [00:01<00:04, 164.37 examples/s]Tokenizing eval dataset:  45%|████▌     | 430/953 [00:03<00:02, 195.74 examples/s]Tokenizing eval dataset:  28%|██▊       | 265/953 [00:02<00:02, 231.01 examples/s]Tokenizing eval dataset:  70%|██████▉   | 665/953 [00:02<00:01, 230.95 examples/s]Tokenizing eval dataset:  48%|████▊     | 457/953 [00:03<00:02, 215.02 examples/s]Tokenizing eval dataset:  32%|███▏      | 309/953 [00:02<00:02, 287.57 examples/s]Tokenizing eval dataset:  37%|███▋      | 353/953 [00:02<00:01, 330.25 examples/s]Tokenizing eval dataset:  73%|███████▎  | 696/953 [00:02<00:01, 215.05 examples/s]Tokenizing eval dataset:  51%|█████     | 482/953 [00:03<00:02, 194.02 examples/s]Tokenizing eval dataset:  41%|████      | 392/953 [00:02<00:01, 343.79 examples/s]Tokenizing eval dataset:  53%|█████▎    | 506/953 [00:03<00:02, 202.09 examples/s]Tokenizing eval dataset:  76%|███████▌  | 726/953 [00:03<00:01, 199.34 examples/s]Tokenizing eval dataset:  46%|████▌     | 438/953 [00:02<00:01, 375.54 examples/s]Tokenizing eval dataset:  56%|█████▌    | 534/953 [00:03<00:02, 194.90 examples/s]Tokenizing eval dataset:  50%|█████     | 481/953 [00:02<00:01, 387.16 examples/s]Tokenizing eval dataset:  79%|███████▉  | 755/953 [00:03<00:01, 186.34 examples/s]Tokenizing eval dataset:  59%|█████▉    | 560/953 [00:03<00:01, 203.20 examples/s]Tokenizing eval dataset:  55%|█████▌    | 525/953 [00:02<00:01, 396.71 examples/s]Tokenizing eval dataset:  82%|████████▏ | 777/953 [00:03<00:00, 187.70 examples/s]Tokenizing eval dataset:  61%|██████▏   | 585/953 [00:04<00:01, 214.29 examples/s]Tokenizing eval dataset:  60%|█████▉    | 571/953 [00:02<00:01, 358.75 examples/s]Tokenizing eval dataset:  64%|██████▍   | 609/953 [00:04<00:01, 220.04 examples/s]Tokenizing eval dataset:  84%|████████▍ | 800/953 [00:03<00:00, 184.08 examples/s]Tokenizing eval dataset:  64%|██████▍   | 614/953 [00:02<00:00, 372.15 examples/s]Tokenizing eval dataset:  66%|██████▋   | 632/953 [00:04<00:01, 218.56 examples/s]Tokenizing eval dataset:  87%|████████▋ | 826/953 [00:03<00:00, 198.86 examples/s]Tokenizing eval dataset:  69%|██████▉   | 660/953 [00:04<00:01, 231.66 examples/s]Tokenizing eval dataset:  90%|████████▉ | 856/953 [00:03<00:00, 218.32 examples/s]Tokenizing eval dataset:  69%|██████▉   | 660/953 [00:03<00:01, 278.80 examples/s]Tokenizing eval dataset:  92%|█████████▏| 881/953 [00:03<00:00, 223.85 examples/s]Tokenizing eval dataset:  73%|███████▎  | 691/953 [00:04<00:01, 241.19 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:03<00:00, 232.20 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:04<00:00, 257.92 examples/s]Tokenizing eval dataset:  73%|███████▎  | 697/953 [00:03<00:01, 238.86 examples/s]Tokenizing eval dataset:  99%|█████████▊| 940/953 [00:04<00:00, 253.11 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:04<00:00, 233.74 examples/s]
Tokenizing eval dataset:  76%|███████▋  | 727/953 [00:03<00:00, 249.40 examples/s]Tokenizing eval dataset:  81%|████████  | 771/953 [00:04<00:00, 242.94 examples/s]Tokenizing eval dataset:  80%|████████  | 763/953 [00:03<00:00, 272.88 examples/s]Tokenizing eval dataset:  84%|████████▍ | 803/953 [00:04<00:00, 255.08 examples/s]Tokenizing eval dataset:  83%|████████▎ | 795/953 [00:03<00:00, 283.69 examples/s]Tokenizing eval dataset:  88%|████████▊ | 839/953 [00:05<00:00, 278.03 examples/s]Tokenizing eval dataset:  87%|████████▋ | 830/953 [00:03<00:00, 293.09 examples/s]Tokenizing eval dataset:  91%|█████████▏| 870/953 [00:05<00:00, 284.45 examples/s]Tokenizing eval dataset:  95%|█████████▍| 905/953 [00:05<00:00, 299.35 examples/s]Tokenizing eval dataset:  92%|█████████▏| 880/953 [00:03<00:00, 305.30 examples/s]Tokenizing eval dataset:  99%|█████████▊| 940/953 [00:05<00:00, 304.33 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 176.15 examples/s]
Tokenizing eval dataset:  98%|█████████▊| 931/953 [00:04<00:00, 313.57 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Tokenizing eval dataset: 100%|██████████| 953/953 [00:04<00:00, 225.99 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Loading extension module cpu_adam...
Loading extension module cpu_adam...Loading extension module cpu_adam...

Time to load cpu_adam op: 5.465916633605957 seconds
Time to load cpu_adam op: 5.460649251937866 seconds
Time to load cpu_adam op: 5.459872484207153 seconds
Time to load cpu_adam op: 5.5096635818481445 seconds
Parameter Offload: Total persistent parameters: 605696 in 169 params
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250530_162453-57k6lovm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-3e-07_e-3_b-0.2
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/57k6lovm
  0%|          | 0/1608 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
[rank0]:[E530 16:25:35.680050989 ProcessGroupNCCL.cpp:552] [Rank 0] Collective WorkNCCL(SeqNum=2578, OpType=_ALLGATHER_BASE, NumelIn=28672, NumelOut=229376, Timeout(ms)=1800000) raised the following async exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgress: Connection closed by remote peer vggn27.vega.pri<50710>
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f52a1b6c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7f52502211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7f525022964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7f525022b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7f525022c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7f52a22ee5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7f52a439eac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7f52a4430a40 in /lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[E530 16:25:35.881071524 ProcessGroupNCCL.cpp:2168] [PG ID 0 PG GUID 0(default_pg) Rank 0]  failure detected by watchdog at work sequence id: 2578 PG status: last enqueued work: 2578, last completed work: 2577
[rank0]:[E530 16:25:35.881101305 ProcessGroupNCCL.cpp:667] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.
W0530 16:25:35.275000 112331 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 112407 closing signal SIGTERM
W0530 16:25:35.321000 112331 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 112408 closing signal SIGTERM
W0530 16:25:35.323000 112331 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 112409 closing signal SIGTERM
E0530 16:25:38.694000 112331 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -9) local_rank: 3 (pid: 112410) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1182, in launch_command
    deepspeed_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 861, in deepspeed_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
train.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-30_16:25:35
  host      : pm5-nod63.vega.pri
  rank      : 3 (local_rank: 3)
  exitcode  : -9 (pid: 112410)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 112410
=======================================================
slurmstepd: error: Detected 1 oom_kill event in StepId=62055338.0. Some of the step tasks have been OOM Killed.
