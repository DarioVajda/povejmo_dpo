cpu-bind=MASK - gn36, task  0  0 [3323106]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn36
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 0     --main_process_ip gn36     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62501263     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=4e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-06-04 12:30:51,085] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0604 12:30:52.999000 3323156 torch/distributed/run.py:792] 
W0604 12:30:52.999000 3323156 torch/distributed/run.py:792] *****************************************
W0604 12:30:52.999000 3323156 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0604 12:30:52.999000 3323156 torch/distributed/run.py:792] *****************************************
[2025-06-04 12:30:58,199] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-04 12:30:58,233] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-04 12:30:58,246] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-04 12:30:58,257] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Created datasets
Created datasets
Created datasets
Number of training examples: Number of training examples: Number of training examples: Number of training examples: 10033
10033
10033
10033
Number of validation examples: Number of validation examples: Number of validation examples: Number of validation examples: 953
953
953
953
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
4e-07
4e-07
4e-07
4e-07
World size: [2025-06-04 12:31:02,883] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-04 12:31:02,930] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-04 12:31:02,957] [INFO] [comm.py:658:init_distributed] cdb=None
8
Setting gradient accumulation steps to: 2
Created datasets
Steps per epoch: 627
Eval steps: 313
[2025-06-04 12:31:03,694] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-04 12:31:03,698] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:21, 27.16s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:22, 27.63s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:22, 27.36s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:22, 27.44s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.78s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.83s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.94s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.95s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:25<00:28, 28.75s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:25<00:28, 28.83s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:25<00:28, 28.87s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:25<00:28, 28.90s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:46<00:00, 25.60s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:46<00:00, 26.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:46<00:00, 25.62s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:46<00:00, 25.60s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:46<00:00, 25.67s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:46<00:00, 26.72s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:46<00:00, 26.70s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:47<00:00, 26.77s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
Total Parameters: 9457.78M
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Total Parameters: 9457.78M
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Trainable Parameters (LoRA): 216.07M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Percentage of Trainable Params: 2.2846%
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
[rank2]:[W604 12:32:56.359670809 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W604 12:32:56.423953043 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank3]:[W604 12:32:56.587039221 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Extracting prompt in train dataset:   5%|▌         | 542/10033 [00:00<00:01, 5380.35 examples/s]Extracting prompt in train dataset:  11%|█▏        | 1140/10033 [00:00<00:02, 4425.36 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1785/10033 [00:00<00:01, 4357.44 examples/s]Extracting prompt in train dataset:  23%|██▎       | 2280/10033 [00:00<00:01, 4530.42 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2790/10033 [00:00<00:01, 4695.42 examples/s]Extracting prompt in train dataset:  35%|███▌      | 3536/10033 [00:00<00:01, 4794.36 examples/s]Extracting prompt in train dataset:  40%|████      | 4020/10033 [00:00<00:01, 4796.09 examples/s]Extracting prompt in train dataset:  46%|████▌     | 4598/10033 [00:01<00:01, 4373.62 examples/s]Extracting prompt in train dataset:  51%|█████     | 5100/10033 [00:01<00:01, 4536.09 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 5630/10033 [00:01<00:00, 4729.47 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 6200/10033 [00:01<00:01, 3743.38 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 6720/10033 [00:01<00:00, 4068.92 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 7400/10033 [00:01<00:00, 4216.40 examples/s]Extracting prompt in train dataset:  81%|████████  | 8101/10033 [00:01<00:00, 4353.77 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 8581/10033 [00:01<00:00, 4449.75 examples/s]Extracting prompt in train dataset:  91%|█████████ | 9120/10033 [00:02<00:00, 4671.83 examples/s]Extracting prompt in train dataset:  96%|█████████▋| 9680/10033 [00:02<00:00, 4906.45 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:02<00:00, 4423.91 examples/s]
Applying chat template to train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 290/10033 [00:00<00:03, 2863.57 examples/s]Applying chat template to train dataset:   6%|▌         | 582/10033 [00:00<00:03, 2893.29 examples/s]Applying chat template to train dataset:  10%|▉         | 974/10033 [00:00<00:03, 2734.19 examples/s]Applying chat template to train dataset:  13%|█▎        | 1276/10033 [00:00<00:03, 2828.83 examples/s]Applying chat template to train dataset:  17%|█▋        | 1687/10033 [00:00<00:02, 2787.52 examples/s]Applying chat template to train dataset:  21%|██        | 2124/10033 [00:00<00:02, 2830.09 examples/s]Applying chat template to train dataset:  25%|██▍       | 2479/10033 [00:00<00:02, 2665.69 examples/s]Applying chat template to train dataset:  28%|██▊       | 2831/10033 [00:01<00:02, 2555.90 examples/s]Applying chat template to train dataset:  31%|███       | 3111/10033 [00:01<00:02, 2612.56 examples/s]Applying chat template to train dataset:  34%|███▍      | 3413/10033 [00:01<00:02, 2715.34 examples/s]Applying chat template to train dataset:  38%|███▊      | 3841/10033 [00:01<00:02, 2759.41 examples/s]Applying chat template to train dataset:  42%|████▏     | 4222/10033 [00:01<00:02, 2683.94 examples/s]Applying chat template to train dataset:  45%|████▌     | 4545/10033 [00:01<00:02, 2246.62 examples/s]Applying chat template to train dataset:  49%|████▉     | 4903/10033 [00:01<00:02, 2286.10 examples/s]Applying chat template to train dataset:  51%|█████▏    | 5154/10033 [00:02<00:02, 2332.35 examples/s]Applying chat template to train dataset:  54%|█████▍    | 5460/10033 [00:02<00:01, 2503.87 examples/s]Applying chat template to train dataset:  58%|█████▊    | 5787/10033 [00:02<00:02, 2090.46 examples/s]Applying chat template to train dataset:  61%|██████    | 6087/10033 [00:02<00:01, 2287.74 examples/s]Applying chat template to train dataset:  64%|██████▍   | 6454/10033 [00:02<00:01, 2335.75 examples/s]Applying chat template to train dataset:  68%|██████▊   | 6782/10033 [00:02<00:01, 2206.24 examples/s]Applying chat template to train dataset:  70%|███████   | 7030/10033 [00:02<00:01, 2265.40 examples/s]Applying chat template to train dataset:  73%|███████▎  | 7314/10033 [00:02<00:01, 2401.68 examples/s]Applying chat template to train dataset:  76%|███████▌  | 7641/10033 [00:03<00:01, 2169.01 examples/s]Applying chat template to train dataset:  79%|███████▉  | 7913/10033 [00:03<00:00, 2259.93 examples/s]Applying chat template to train dataset:  81%|████████▏ | 8170/10033 [00:03<00:00, 2335.17 examples/s]Applying chat template to train dataset:  85%|████████▌ | 8540/10033 [00:03<00:00, 2373.57 examples/s]Applying chat template to train dataset:  88%|████████▊ | 8803/10033 [00:03<00:00, 2435.42 examples/s]Applying chat template to train dataset:  91%|█████████ | 9085/10033 [00:03<00:00, 2534.62 examples/s]Applying chat template to train dataset:  94%|█████████▍| 9443/10033 [00:03<00:00, 2479.25 examples/s]Applying chat template to train dataset:  97%|█████████▋| 9780/10033 [00:03<00:00, 2338.86 examples/s]Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:04<00:00, 2444.20 examples/s]
Tokenizing train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/10033 [00:00<00:24, 408.68 examples/s]Tokenizing train dataset:   1%|          | 92/10033 [00:00<01:05, 151.02 examples/s]Tokenizing train dataset:   1%|          | 122/10033 [00:00<01:03, 157.27 examples/s]Tokenizing train dataset:   2%|▏         | 157/10033 [00:00<01:03, 155.49 examples/s]Tokenizing train dataset:   2%|▏         | 180/10033 [00:01<00:58, 167.68 examples/s]Tokenizing train dataset:   2%|▏         | 217/10033 [00:01<00:55, 176.92 examples/s]Tokenizing train dataset:   2%|▏         | 245/10033 [00:01<00:49, 196.31 examples/s]Tokenizing train dataset:   3%|▎         | 277/10033 [00:01<00:43, 221.84 examples/s]Tokenizing train dataset:   3%|▎         | 313/10033 [00:01<00:46, 206.86 examples/s]Tokenizing train dataset:   3%|▎         | 338/10033 [00:01<00:45, 215.07 examples/s]Tokenizing train dataset:   4%|▎         | 370/10033 [00:01<00:45, 210.61 examples/s]Tokenizing train dataset:   4%|▍         | 402/10033 [00:02<00:47, 201.04 examples/s]Tokenizing train dataset:   4%|▍         | 436/10033 [00:02<00:49, 193.43 examples/s]Tokenizing train dataset:   5%|▍         | 458/10033 [00:02<00:48, 195.90 examples/s]Tokenizing train dataset:   5%|▍         | 481/10033 [00:02<00:47, 201.55 examples/s]Tokenizing train dataset:   5%|▌         | 503/10033 [00:02<00:46, 204.92 examples/s]Tokenizing train dataset:   5%|▌         | 527/10033 [00:02<00:44, 212.24 examples/s]Tokenizing train dataset:   6%|▌         | 557/10033 [00:02<00:40, 233.82 examples/s]Tokenizing train dataset:   6%|▌         | 587/10033 [00:02<00:37, 248.67 examples/s]Tokenizing train dataset:   6%|▌         | 617/10033 [00:03<00:36, 258.00 examples/s]Tokenizing train dataset:   7%|▋         | 654/10033 [00:03<00:32, 287.36 examples/s]Tokenizing train dataset:   7%|▋         | 686/10033 [00:03<00:37, 251.12 examples/s]Tokenizing train dataset:   7%|▋         | 732/10033 [00:03<00:34, 266.46 examples/s]Tokenizing train dataset:   8%|▊         | 768/10033 [00:03<00:36, 255.41 examples/s]Tokenizing train dataset:   8%|▊         | 795/10033 [00:03<00:44, 208.99 examples/s]Tokenizing train dataset:   8%|▊         | 825/10033 [00:04<00:50, 182.86 examples/s]Tokenizing train dataset:   9%|▊         | 853/10033 [00:04<00:45, 200.50 examples/s]Tokenizing train dataset:   9%|▉         | 891/10033 [00:04<00:47, 190.96 examples/s]Tokenizing train dataset:   9%|▉         | 913/10033 [00:04<00:46, 196.09 examples/s]Tokenizing train dataset:   9%|▉         | 948/10033 [00:04<00:44, 203.43 examples/s]Tokenizing train dataset:  10%|▉         | 979/10033 [00:04<00:45, 199.40 examples/s]Tokenizing train dataset:  10%|▉         | 1000/10033 [00:04<00:45, 197.62 examples/s]Tokenizing train dataset:  10%|█         | 1028/10033 [00:04<00:42, 213.25 examples/s]Tokenizing train dataset:  11%|█         | 1061/10033 [00:05<00:46, 192.93 examples/s]Tokenizing train dataset:  11%|█         | 1085/10033 [00:05<00:44, 201.02 examples/s]Tokenizing train dataset:  11%|█         | 1117/10033 [00:05<00:39, 225.87 examples/s]Tokenizing train dataset:  11%|█▏        | 1141/10033 [00:05<00:39, 227.80 examples/s]Tokenizing train dataset:  12%|█▏        | 1167/10033 [00:05<00:37, 233.45 examples/s]Tokenizing train dataset:  12%|█▏        | 1192/10033 [00:05<00:37, 236.34 examples/s]Tokenizing train dataset:  12%|█▏        | 1220/10033 [00:05<00:36, 244.25 examples/s]Tokenizing train dataset:  13%|█▎        | 1255/10033 [00:05<00:32, 271.15 examples/s]Tokenizing train dataset:  13%|█▎        | 1285/10033 [00:06<00:31, 273.59 examples/s]Tokenizing train dataset:  13%|█▎        | 1314/10033 [00:06<00:31, 277.94 examples/s]Tokenizing train dataset:  13%|█▎        | 1354/10033 [00:06<00:32, 270.02 examples/s]Tokenizing train dataset:  14%|█▍        | 1388/10033 [00:06<00:34, 251.40 examples/s]Tokenizing train dataset:  14%|█▍        | 1429/10033 [00:06<00:33, 255.56 examples/s]Tokenizing train dataset:  15%|█▍        | 1456/10033 [00:06<00:33, 257.12 examples/s]Tokenizing train dataset:  15%|█▍        | 1495/10033 [00:06<00:33, 254.52 examples/s]Tokenizing train dataset:  15%|█▌        | 1526/10033 [00:06<00:32, 263.23 examples/s]Tokenizing train dataset:  15%|█▌        | 1553/10033 [00:07<00:32, 264.47 examples/s]Tokenizing train dataset:  16%|█▌        | 1590/10033 [00:07<00:33, 254.84 examples/s]Tokenizing train dataset:  16%|█▌        | 1623/10033 [00:07<00:31, 268.28 examples/s]Tokenizing train dataset:  17%|█▋        | 1658/10033 [00:07<00:36, 232.36 examples/s]Tokenizing train dataset:  17%|█▋        | 1705/10033 [00:07<00:32, 253.41 examples/s]Tokenizing train dataset:  17%|█▋        | 1734/10033 [00:07<00:32, 258.35 examples/s]Tokenizing train dataset:  18%|█▊        | 1770/10033 [00:07<00:34, 241.78 examples/s]Tokenizing train dataset:  18%|█▊        | 1797/10033 [00:08<00:33, 246.13 examples/s]Tokenizing train dataset:  18%|█▊        | 1824/10033 [00:08<00:32, 249.25 examples/s]Tokenizing train dataset:  19%|█▊        | 1857/10033 [00:08<00:37, 219.03 examples/s]Tokenizing train dataset:  19%|█▉        | 1883/10033 [00:08<00:35, 227.34 examples/s]Tokenizing train dataset:  19%|█▉        | 1911/10033 [00:08<00:34, 238.85 examples/s]Tokenizing train dataset:  19%|█▉        | 1950/10033 [00:08<00:35, 227.69 examples/s]Tokenizing train dataset:  20%|█▉        | 1989/10033 [00:08<00:34, 233.61 examples/s]Tokenizing train dataset:  20%|██        | 2013/10033 [00:08<00:34, 233.90 examples/s]Tokenizing train dataset:  20%|██        | 2040/10033 [00:09<00:33, 240.22 examples/s]Tokenizing train dataset:  21%|██        | 2073/10033 [00:09<00:30, 261.26 examples/s]Tokenizing train dataset:  21%|██        | 2110/10033 [00:09<00:27, 283.91 examples/s]Tokenizing train dataset:  21%|██▏       | 2148/10033 [00:09<00:25, 305.64 examples/s]Tokenizing train dataset:  22%|██▏       | 2186/10033 [00:09<00:29, 269.50 examples/s]Tokenizing train dataset:  22%|██▏       | 2220/10033 [00:09<00:27, 285.11 examples/s]Tokenizing train dataset:  22%|██▏       | 2254/10033 [00:09<00:26, 297.43 examples/s]Tokenizing train dataset:  23%|██▎       | 2292/10033 [00:09<00:24, 317.45 examples/s]Tokenizing train dataset:  23%|██▎       | 2340/10033 [00:10<00:24, 313.72 examples/s]Tokenizing train dataset:  24%|██▍       | 2384/10033 [00:10<00:25, 304.36 examples/s]Tokenizing train dataset:  24%|██▍       | 2428/10033 [00:10<00:25, 297.73 examples/s]Tokenizing train dataset:  25%|██▍       | 2474/10033 [00:10<00:25, 298.46 examples/s]Tokenizing train dataset:  25%|██▌       | 2521/10033 [00:10<00:25, 298.98 examples/s]Tokenizing train dataset:  26%|██▌       | 2565/10033 [00:10<00:27, 270.52 examples/s]Tokenizing train dataset:  26%|██▌       | 2598/10033 [00:10<00:26, 280.26 examples/s]Tokenizing train dataset:  26%|██▋       | 2640/10033 [00:11<00:26, 276.97 examples/s]Tokenizing train dataset:  27%|██▋       | 2680/10033 [00:11<00:26, 272.59 examples/s]Tokenizing train dataset:  27%|██▋       | 2716/10033 [00:11<00:25, 290.31 examples/s]Tokenizing train dataset:  28%|██▊       | 2762/10033 [00:11<00:24, 292.01 examples/s]Tokenizing train dataset:  28%|██▊       | 2792/10033 [00:11<00:24, 291.30 examples/s]Tokenizing train dataset:  28%|██▊       | 2834/10033 [00:11<00:25, 283.99 examples/s]Tokenizing train dataset:  29%|██▊       | 2870/10033 [00:11<00:27, 264.79 examples/s]Tokenizing train dataset:  29%|██▉       | 2898/10033 [00:12<00:27, 263.22 examples/s]Tokenizing train dataset:  29%|██▉       | 2943/10033 [00:12<00:26, 271.77 examples/s]Tokenizing train dataset:  30%|██▉       | 2989/10033 [00:12<00:35, 197.78 examples/s]Tokenizing train dataset:  30%|███       | 3021/10033 [00:12<00:32, 217.09 examples/s]Tokenizing train dataset:  30%|███       | 3057/10033 [00:12<00:32, 214.09 examples/s]Tokenizing train dataset:  31%|███       | 3089/10033 [00:12<00:29, 232.30 examples/s]Tokenizing train dataset:  31%|███       | 3115/10033 [00:13<00:29, 236.86 examples/s]Tokenizing train dataset:  31%|███▏      | 3144/10033 [00:13<00:27, 248.07 examples/s]Tokenizing train dataset:  32%|███▏      | 3172/10033 [00:13<00:26, 254.69 examples/s]Tokenizing train dataset:  32%|███▏      | 3206/10033 [00:13<00:24, 275.62 examples/s]Tokenizing train dataset:  32%|███▏      | 3256/10033 [00:13<00:23, 292.11 examples/s]Tokenizing train dataset:  33%|███▎      | 3289/10033 [00:13<00:22, 299.65 examples/s]Tokenizing train dataset:  33%|███▎      | 3320/10033 [00:13<00:22, 301.30 examples/s]Tokenizing train dataset:  33%|███▎      | 3351/10033 [00:13<00:22, 301.67 examples/s]Tokenizing train dataset:  34%|███▍      | 3394/10033 [00:13<00:22, 292.97 examples/s]Tokenizing train dataset:  34%|███▍      | 3439/10033 [00:14<00:22, 292.15 examples/s]Tokenizing train dataset:  35%|███▍      | 3470/10033 [00:14<00:22, 294.01 examples/s]Tokenizing train dataset:  35%|███▌      | 3516/10033 [00:14<00:22, 295.02 examples/s]Tokenizing train dataset:  35%|███▌      | 3550/10033 [00:14<00:24, 260.67 examples/s]Tokenizing train dataset:  36%|███▌      | 3578/10033 [00:14<00:24, 264.43 examples/s]Tokenizing train dataset:  36%|███▌      | 3617/10033 [00:14<00:25, 250.94 examples/s]Tokenizing train dataset:  36%|███▋      | 3646/10033 [00:14<00:24, 256.59 examples/s]Tokenizing train dataset:  37%|███▋      | 3680/10033 [00:15<00:29, 214.45 examples/s]Tokenizing train dataset:  37%|███▋      | 3724/10033 [00:15<00:24, 257.27 examples/s]Tokenizing train dataset:  38%|███▊      | 3766/10033 [00:15<00:24, 258.41 examples/s]Tokenizing train dataset:  38%|███▊      | 3805/10033 [00:15<00:29, 211.59 examples/s]Tokenizing train dataset:  38%|███▊      | 3841/10033 [00:15<00:29, 209.81 examples/s]Tokenizing train dataset:  39%|███▊      | 3880/10033 [00:16<00:29, 208.58 examples/s]Tokenizing train dataset:  39%|███▉      | 3915/10033 [00:16<00:31, 192.90 examples/s]Tokenizing train dataset:  39%|███▉      | 3943/10033 [00:16<00:29, 207.80 examples/s]Tokenizing train dataset:  40%|███▉      | 3974/10033 [00:16<00:26, 226.46 examples/s]Tokenizing train dataset:  40%|███▉      | 4013/10033 [00:16<00:29, 204.81 examples/s]Tokenizing train dataset:  40%|████      | 4054/10033 [00:16<00:27, 214.69 examples/s]Tokenizing train dataset:  41%|████      | 4087/10033 [00:16<00:25, 236.26 examples/s]Tokenizing train dataset:  41%|████      | 4129/10033 [00:17<00:23, 247.80 examples/s]Tokenizing train dataset:  41%|████▏     | 4159/10033 [00:17<00:22, 258.87 examples/s]Tokenizing train dataset:  42%|████▏     | 4201/10033 [00:17<00:22, 263.62 examples/s]Tokenizing train dataset:  42%|████▏     | 4241/10033 [00:17<00:22, 262.36 examples/s]Tokenizing train dataset:  43%|████▎     | 4281/10033 [00:17<00:22, 258.96 examples/s]Tokenizing train dataset:  43%|████▎     | 4319/10033 [00:17<00:22, 255.04 examples/s]Tokenizing train dataset:  43%|████▎     | 4357/10033 [00:18<00:22, 247.38 examples/s]Tokenizing train dataset:  44%|████▎     | 4388/10033 [00:18<00:21, 259.08 examples/s]Tokenizing train dataset:  44%|████▍     | 4425/10033 [00:18<00:19, 280.76 examples/s]Tokenizing train dataset:  44%|████▍     | 4456/10033 [00:18<00:19, 285.30 examples/s]Tokenizing train dataset:  45%|████▍     | 4498/10033 [00:18<00:19, 279.59 examples/s]Tokenizing train dataset:  45%|████▌     | 4527/10033 [00:18<00:19, 280.33 examples/s]Tokenizing train dataset:  45%|████▌     | 4562/10033 [00:18<00:18, 294.10 examples/s]Tokenizing train dataset:  46%|████▌     | 4604/10033 [00:18<00:18, 286.93 examples/s]Tokenizing train dataset:  46%|████▋     | 4646/10033 [00:19<00:19, 280.60 examples/s]Tokenizing train dataset:  47%|████▋     | 4690/10033 [00:19<00:19, 280.48 examples/s]Tokenizing train dataset:  47%|████▋     | 4727/10033 [00:19<00:19, 265.79 examples/s]Tokenizing train dataset:  47%|████▋     | 4760/10033 [00:19<00:21, 246.22 examples/s]Tokenizing train dataset:  48%|████▊     | 4794/10033 [00:19<00:22, 234.85 examples/s]Tokenizing train dataset:  48%|████▊     | 4829/10033 [00:19<00:20, 258.48 examples/s]Tokenizing train dataset:  48%|████▊     | 4863/10033 [00:20<00:25, 206.53 examples/s]Tokenizing train dataset:  49%|████▉     | 4894/10033 [00:20<00:23, 216.36 examples/s]Tokenizing train dataset:  49%|████▉     | 4930/10033 [00:20<00:21, 238.92 examples/s]Tokenizing train dataset:  49%|████▉     | 4960/10033 [00:20<00:22, 226.27 examples/s]Tokenizing train dataset:  50%|████▉     | 5010/10033 [00:20<00:17, 286.46 examples/s]Tokenizing train dataset:  51%|█████     | 5072/10033 [00:20<00:13, 362.54 examples/s]Tokenizing train dataset:  51%|█████     | 5134/10033 [00:20<00:11, 427.26 examples/s]Tokenizing train dataset:  52%|█████▏    | 5182/10033 [00:20<00:11, 439.39 examples/s]Tokenizing train dataset:  52%|█████▏    | 5241/10033 [00:20<00:10, 479.02 examples/s]Tokenizing train dataset:  53%|█████▎    | 5308/10033 [00:21<00:08, 527.26 examples/s]Tokenizing train dataset:  54%|█████▎    | 5369/10033 [00:21<00:10, 448.10 examples/s]Tokenizing train dataset:  54%|█████▍    | 5454/10033 [00:21<00:09, 480.56 examples/s]Tokenizing train dataset:  55%|█████▍    | 5516/10033 [00:21<00:12, 368.28 examples/s]Tokenizing train dataset:  56%|█████▌    | 5591/10033 [00:21<00:11, 400.96 examples/s]Tokenizing train dataset:  56%|█████▋    | 5648/10033 [00:21<00:10, 434.35 examples/s]Tokenizing train dataset:  57%|█████▋    | 5703/10033 [00:21<00:09, 458.70 examples/s]Tokenizing train dataset:  58%|█████▊    | 5777/10033 [00:22<00:09, 438.21 examples/s]Tokenizing train dataset:  58%|█████▊    | 5845/10033 [00:22<00:10, 398.94 examples/s]Tokenizing train dataset:  59%|█████▉    | 5901/10033 [00:22<00:12, 336.58 examples/s]Tokenizing train dataset:  59%|█████▉    | 5969/10033 [00:22<00:10, 399.32 examples/s]Tokenizing train dataset:  60%|█████▉    | 6019/10033 [00:23<00:13, 290.91 examples/s]Tokenizing train dataset:  60%|██████    | 6065/10033 [00:23<00:12, 317.20 examples/s]Tokenizing train dataset:  61%|██████    | 6138/10033 [00:23<00:10, 360.78 examples/s]Tokenizing train dataset:  62%|██████▏   | 6210/10033 [00:23<00:10, 376.75 examples/s]Tokenizing train dataset:  62%|██████▏   | 6253/10033 [00:23<00:09, 386.13 examples/s]Tokenizing train dataset:  63%|██████▎   | 6319/10033 [00:23<00:09, 391.95 examples/s]Tokenizing train dataset:  64%|██████▎   | 6379/10033 [00:23<00:08, 434.95 examples/s]Tokenizing train dataset:  64%|██████▍   | 6450/10033 [00:23<00:08, 443.89 examples/s]Tokenizing train dataset:  65%|██████▍   | 6505/10033 [00:24<00:08, 407.92 examples/s]Tokenizing train dataset:  65%|██████▌   | 6565/10033 [00:24<00:07, 448.46 examples/s]Tokenizing train dataset:  66%|██████▌   | 6642/10033 [00:24<00:07, 464.80 examples/s]Tokenizing train dataset:  67%|██████▋   | 6696/10033 [00:24<00:06, 481.63 examples/s]Tokenizing train dataset:  67%|██████▋   | 6759/10033 [00:24<00:06, 513.04 examples/s]Tokenizing train dataset:  68%|██████▊   | 6815/10033 [00:24<00:06, 525.02 examples/s]Tokenizing train dataset:  69%|██████▊   | 6876/10033 [00:24<00:07, 434.53 examples/s]Tokenizing train dataset:  69%|██████▉   | 6944/10033 [00:24<00:06, 489.33 examples/s]Tokenizing train dataset:  70%|██████▉   | 7000/10033 [00:25<00:07, 389.98 examples/s]Tokenizing train dataset:  70%|███████   | 7066/10033 [00:25<00:07, 403.83 examples/s]Tokenizing train dataset:  71%|███████   | 7135/10033 [00:25<00:08, 358.79 examples/s]Tokenizing train dataset:  72%|███████▏  | 7204/10033 [00:25<00:07, 382.97 examples/s]Tokenizing train dataset:  72%|███████▏  | 7261/10033 [00:25<00:07, 379.95 examples/s]Tokenizing train dataset:  73%|███████▎  | 7318/10033 [00:26<00:06, 418.14 examples/s]Tokenizing train dataset:  74%|███████▎  | 7386/10033 [00:26<00:06, 423.96 examples/s]Tokenizing train dataset:  74%|███████▍  | 7432/10033 [00:26<00:06, 429.83 examples/s]Tokenizing train dataset:  75%|███████▍  | 7500/10033 [00:26<00:06, 389.39 examples/s]Tokenizing train dataset:  75%|███████▌  | 7553/10033 [00:26<00:05, 418.18 examples/s]Tokenizing train dataset:  76%|███████▌  | 7620/10033 [00:26<00:05, 473.64 examples/s]Tokenizing train dataset:  76%|███████▋  | 7673/10033 [00:26<00:05, 429.18 examples/s]Tokenizing train dataset:  77%|███████▋  | 7735/10033 [00:26<00:05, 417.02 examples/s]Tokenizing train dataset:  78%|███████▊  | 7790/10033 [00:27<00:07, 317.13 examples/s]Tokenizing train dataset:  78%|███████▊  | 7836/10033 [00:27<00:06, 342.25 examples/s]Tokenizing train dataset:  79%|███████▊  | 7900/10033 [00:27<00:06, 348.72 examples/s]Tokenizing train dataset:  79%|███████▉  | 7940/10033 [00:27<00:05, 354.59 examples/s]Tokenizing train dataset:  80%|███████▉  | 7995/10033 [00:27<00:05, 397.99 examples/s]Tokenizing train dataset:  80%|████████  | 8063/10033 [00:27<00:04, 411.22 examples/s]Tokenizing train dataset:  81%|████████  | 8120/10033 [00:28<00:04, 393.72 examples/s]Tokenizing train dataset:  82%|████████▏ | 8180/10033 [00:28<00:04, 438.48 examples/s]Tokenizing train dataset:  82%|████████▏ | 8262/10033 [00:28<00:03, 471.43 examples/s]Tokenizing train dataset:  83%|████████▎ | 8330/10033 [00:28<00:03, 519.40 examples/s]Tokenizing train dataset:  84%|████████▍ | 8404/10033 [00:28<00:03, 507.88 examples/s]Tokenizing train dataset:  84%|████████▍ | 8466/10033 [00:28<00:03, 416.31 examples/s]Tokenizing train dataset:  85%|████████▌ | 8531/10033 [00:28<00:03, 388.86 examples/s]Tokenizing train dataset:  86%|████████▌ | 8608/10033 [00:29<00:03, 464.62 examples/s]Tokenizing train dataset:  87%|████████▋ | 8715/10033 [00:29<00:02, 598.94 examples/s]Tokenizing train dataset:  88%|████████▊ | 8828/10033 [00:29<00:01, 725.44 examples/s]Tokenizing train dataset:  89%|████████▉ | 8917/10033 [00:29<00:01, 766.06 examples/s]Tokenizing train dataset:  90%|████████▉ | 9011/10033 [00:29<00:01, 809.60 examples/s]Tokenizing train dataset:  91%|█████████ | 9140/10033 [00:29<00:01, 703.64 examples/s]Tokenizing train dataset:  92%|█████████▏| 9230/10033 [00:29<00:01, 745.28 examples/s]Tokenizing train dataset:  93%|█████████▎| 9360/10033 [00:29<00:00, 756.13 examples/s]Tokenizing train dataset:  95%|█████████▍| 9500/10033 [00:30<00:00, 810.31 examples/s]Tokenizing train dataset:  96%|█████████▌| 9621/10033 [00:30<00:00, 769.38 examples/s]Tokenizing train dataset:  97%|█████████▋| 9732/10033 [00:30<00:00, 841.86 examples/s]Tokenizing train dataset:  98%|█████████▊| 9834/10033 [00:30<00:00, 882.46 examples/s]Tokenizing train dataset:  99%|█████████▉| 9929/10033 [00:30<00:00, 893.91 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:30<00:00, 888.21 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:30<00:00, 325.90 examples/s]
[rank0]:[W604 12:33:35.480030537 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Extracting prompt in train dataset:   5%|▌         | 530/10033 [00:00<00:01, 5208.91 examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5435.21 examples/s]Extracting prompt in train dataset:   5%|▌         | 526/10033 [00:00<00:01, 5220.40 examples/s]Extracting prompt in train dataset:   5%|▌         | 527/10033 [00:00<00:01, 5223.45 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4012.44 examples/s]
Extracting prompt in train dataset:  13%|█▎        | 1320/10033 [00:00<00:01, 5199.86 examples/s]Extracting prompt in train dataset:  11%|█         | 1080/10033 [00:00<00:02, 3199.06 examples/s]Extracting prompt in train dataset:  11%|█         | 1080/10033 [00:00<00:02, 3238.35 examples/s]Extracting prompt in train dataset:  19%|█▊        | 1873/10033 [00:00<00:01, 4341.09 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1600/10033 [00:00<00:02, 3853.67 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1591/10033 [00:00<00:02, 3862.65 examples/s]Extracting prompt in train dataset:  24%|██▍       | 2410/10033 [00:00<00:01, 4650.87 examples/s]Extracting prompt in train dataset:  21%|██        | 2100/10033 [00:00<00:01, 4215.68 examples/s]Extracting prompt in train dataset:  21%|██        | 2114/10033 [00:00<00:01, 4289.01 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  30%|██▉       | 2994/10033 [00:00<00:01, 4340.40 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2760/10033 [00:00<00:01, 4281.42 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2735/10033 [00:00<00:01, 4226.53 examples/s]Applying chat template to eval dataset:  33%|███▎      | 316/953 [00:00<00:00, 3130.34 examples/s]Extracting prompt in train dataset:  35%|███▍      | 3495/10033 [00:00<00:01, 4522.98 examples/s]Extracting prompt in train dataset:  33%|███▎      | 3290/10033 [00:00<00:01, 4001.38 examples/s]Extracting prompt in train dataset:  33%|███▎      | 3270/10033 [00:00<00:01, 3898.84 examples/s]Extracting prompt in train dataset:  40%|███▉      | 3975/10033 [00:00<00:01, 4599.37 examples/s]Applying chat template to eval dataset:  77%|███████▋  | 736/953 [00:00<00:00, 2897.46 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3850/10033 [00:00<00:01, 3742.49 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3840/10033 [00:01<00:01, 3200.34 examples/s]Extracting prompt in train dataset:  45%|████▌     | 4545/10033 [00:01<00:01, 3201.23 examples/s]Extracting prompt in train dataset:  44%|████▍     | 4410/10033 [00:01<00:01, 2953.23 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1241.23 examples/s]Extracting prompt in train dataset:  44%|████▍     | 4401/10033 [00:01<00:02, 2301.70 examples/s]Extracting prompt in train dataset:  51%|█████     | 5120/10033 [00:01<00:02, 2437.83 examples/s]
Extracting prompt in train dataset:  50%|████▉     | 4973/10033 [00:01<00:01, 2698.49 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4800/10033 [00:01<00:02, 2566.57 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 5562/10033 [00:01<00:01, 2763.10 examples/s]Extracting prompt in train dataset:  51%|█████     | 5140/10033 [00:01<00:01, 2714.83 examples/s]Extracting prompt in train dataset:  55%|█████▌    | 5530/10033 [00:01<00:01, 2774.92 examples/s]Extracting prompt in train dataset:  61%|██████▏   | 6150/10033 [00:01<00:01, 2989.45 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 5630/10033 [00:01<00:01, 3158.62 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  61%|██████    | 6110/10033 [00:01<00:01, 2744.69 examples/s]Extracting prompt in train dataset:  67%|██████▋   | 6740/10033 [00:01<00:01, 2985.47 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 6210/10033 [00:01<00:01, 3081.92 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 6581/10033 [00:02<00:01, 3087.92 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 327.23 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 7216/10033 [00:02<00:00, 3320.95 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 6610/10033 [00:02<00:01, 3267.41 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 7008/10033 [00:02<00:00, 3321.02 examples/s]Tokenizing eval dataset:   7%|▋         | 69/953 [00:00<00:03, 253.39 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 7730/10033 [00:02<00:00, 3265.92 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 7190/10033 [00:02<00:00, 3269.55 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 7634/10033 [00:02<00:00, 3571.93 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 8280/10033 [00:02<00:00, 3733.51 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:03, 257.36 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 7730/10033 [00:02<00:00, 3202.76 examples/s]Extracting prompt in train dataset:  81%|████████  | 8120/10033 [00:02<00:00, 3228.76 examples/s]Extracting prompt in train dataset:  89%|████████▊ | 8890/10033 [00:02<00:00, 3827.33 examples/s]Tokenizing eval dataset:  14%|█▍        | 137/953 [00:00<00:03, 218.16 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 8310/10033 [00:02<00:00, 3173.06 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 8700/10033 [00:02<00:00, 3326.30 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 9501/10033 [00:02<00:00, 3852.49 examples/s]Tokenizing eval dataset:  18%|█▊        | 170/953 [00:00<00:03, 213.85 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 8810/10033 [00:02<00:00, 3536.07 examples/s]Extracting prompt in train dataset:  91%|█████████ | 9123/10033 [00:02<00:00, 3514.73 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:02<00:00, 3853.36 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:02<00:00, 3593.41 examples/s]
Extracting prompt in train dataset:  93%|█████████▎| 9300/10033 [00:02<00:00, 3828.89 examples/s]Extracting prompt in train dataset:  95%|█████████▌| 9580/10033 [00:02<00:00, 3750.40 examples/s]Tokenizing eval dataset:  21%|██        | 202/953 [00:00<00:03, 212.09 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 9783/10033 [00:02<00:00, 4064.82 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:02<00:00, 3642.32 examples/s]Tokenizing eval dataset:  26%|██▌       | 246/953 [00:01<00:03, 228.12 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:02<00:00, 3345.60 examples/s]
Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:03<00:00, 3327.11 examples/s]Tokenizing eval dataset:  32%|███▏      | 301/953 [00:01<00:02, 298.70 examples/s]Applying chat template to train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]
Tokenizing eval dataset:  38%|███▊      | 363/953 [00:01<00:02, 255.62 examples/s]Applying chat template to train dataset:   3%|▎         | 283/10033 [00:00<00:03, 2792.62 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:01<00:02, 258.67 examples/s]Applying chat template to train dataset:   6%|▌         | 593/10033 [00:00<00:05, 1844.30 examples/s]Tokenizing eval dataset:  45%|████▌     | 433/953 [00:01<00:01, 276.54 examples/s]Applying chat template to train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing eval dataset:  50%|█████     | 479/953 [00:01<00:01, 316.58 examples/s]Applying chat template to train dataset:   9%|▉         | 937/10033 [00:00<00:04, 2040.17 examples/s]Applying chat template to train dataset:   3%|▎         | 289/10033 [00:00<00:03, 2866.36 examples/s]Applying chat template to train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing eval dataset:  54%|█████▍    | 516/953 [00:01<00:01, 328.38 examples/s]Applying chat template to train dataset:  12%|█▏        | 1159/10033 [00:00<00:04, 2090.59 examples/s]Applying chat template to train dataset:   6%|▌         | 610/10033 [00:00<00:03, 2367.54 examples/s]Tokenizing eval dataset:  60%|█████▉    | 570/953 [00:02<00:01, 380.17 examples/s]Applying chat template to train dataset:   3%|▎         | 283/10033 [00:00<00:03, 2793.52 examples/s]Applying chat template to train dataset:  15%|█▌        | 1510/10033 [00:00<00:03, 2184.95 examples/s]Applying chat template to train dataset:   9%|▊         | 870/10033 [00:00<00:03, 2456.98 examples/s]Tokenizing eval dataset:  66%|██████▋   | 633/953 [00:02<00:00, 444.73 examples/s]Applying chat template to train dataset:   7%|▋         | 675/10033 [00:00<00:03, 2662.19 examples/s]Applying chat template to train dataset:  18%|█▊        | 1780/10033 [00:00<00:03, 2319.29 examples/s]Applying chat template to train dataset:  12%|█▏        | 1194/10033 [00:00<00:03, 2282.18 examples/s]Tokenizing eval dataset:  73%|███████▎  | 697/953 [00:02<00:00, 435.69 examples/s]Applying chat template to train dataset:  21%|██        | 2058/10033 [00:00<00:03, 2445.07 examples/s]Applying chat template to train dataset:  11%|█         | 1068/10033 [00:00<00:03, 2636.23 examples/s]Applying chat template to train dataset:  23%|██▎       | 2336/10033 [00:01<00:03, 2535.12 examples/s]Applying chat template to train dataset:  16%|█▌        | 1562/10033 [00:00<00:03, 2347.20 examples/s]Tokenizing eval dataset:  81%|████████  | 770/953 [00:02<00:00, 449.80 examples/s]Applying chat template to train dataset:  15%|█▍        | 1467/10033 [00:00<00:03, 2642.37 examples/s]Applying chat template to train dataset:  26%|██▌       | 2609/10033 [00:01<00:02, 2589.66 examples/s]Applying chat template to train dataset:  19%|█▊        | 1857/10033 [00:00<00:03, 2509.41 examples/s]Tokenizing eval dataset:  88%|████████▊ | 839/953 [00:02<00:00, 451.18 examples/s]Applying chat template to train dataset:  29%|██▊       | 2880/10033 [00:01<00:02, 2619.52 examples/s]Applying chat template to train dataset:  21%|██        | 2126/10033 [00:00<00:03, 2556.49 examples/s]Applying chat template to train dataset:  19%|█▊        | 1861/10033 [00:00<00:03, 2633.71 examples/s]Tokenizing eval dataset:  93%|█████████▎| 890/953 [00:02<00:00, 353.94 examples/s]Applying chat template to train dataset:  32%|███▏      | 3177/10033 [00:01<00:03, 1742.87 examples/s]Applying chat template to train dataset:  24%|██▍       | 2447/10033 [00:01<00:04, 1746.07 examples/s]Applying chat template to train dataset:  22%|██▏       | 2179/10033 [00:01<00:04, 1784.73 examples/s]Applying chat template to train dataset:  34%|███▍      | 3421/10033 [00:01<00:03, 1889.36 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:02<00:00, 329.48 examples/s]Applying chat template to train dataset:  27%|██▋       | 2673/10033 [00:01<00:03, 1850.37 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 309.00 examples/s]
Applying chat template to train dataset:  25%|██▍       | 2491/10033 [00:01<00:04, 1786.18 examples/s]Applying chat template to train dataset:  37%|███▋      | 3739/10033 [00:01<00:03, 1913.61 examples/s]Applying chat template to train dataset:  30%|██▉       | 2995/10033 [00:01<00:03, 1807.00 examples/s]Applying chat template to train dataset:  28%|██▊       | 2806/10033 [00:01<00:05, 1443.82 examples/s]Applying chat template to train dataset:  40%|████      | 4056/10033 [00:02<00:04, 1474.92 examples/s]Applying chat template to train dataset:  33%|███▎      | 3300/10033 [00:01<00:04, 1449.61 examples/s]Applying chat template to train dataset:  31%|███       | 3100/10033 [00:01<00:05, 1366.05 examples/s]Applying chat template to train dataset:  44%|████▎     | 4372/10033 [00:02<00:04, 1278.08 examples/s]Applying chat template to train dataset:  32%|███▏      | 3257/10033 [00:01<00:05, 1329.17 examples/s]Applying chat template to train dataset:  36%|███▌      | 3627/10033 [00:02<00:05, 1276.98 examples/s]Applying chat template to train dataset:  45%|████▌     | 4530/10033 [00:02<00:05, 1065.09 examples/s]Applying chat template to train dataset:  34%|███▍      | 3412/10033 [00:02<00:06, 989.57 examples/s] Applying chat template to train dataset:  38%|███▊      | 3787/10033 [00:02<00:06, 991.22 examples/s] Applying chat template to train dataset:  47%|████▋     | 4687/10033 [00:02<00:05, 1021.29 examples/s]Applying chat template to train dataset:  36%|███▌      | 3571/10033 [00:02<00:06, 942.24 examples/s]Applying chat template to train dataset:  39%|███▉      | 3950/10033 [00:02<00:06, 932.32 examples/s]Applying chat template to train dataset:  48%|████▊     | 4846/10033 [00:02<00:04, 1061.81 examples/s]Applying chat template to train dataset:  38%|███▊      | 3800/10033 [00:02<00:05, 1158.93 examples/s]Applying chat template to train dataset:  42%|████▏     | 4226/10033 [00:02<00:04, 1201.64 examples/s]Applying chat template to train dataset:  50%|█████     | 5019/10033 [00:03<00:04, 1181.62 examples/s]Applying chat template to train dataset:  39%|███▉      | 3960/10033 [00:02<00:04, 1232.01 examples/s]Applying chat template to train dataset:  44%|████▍     | 4451/10033 [00:02<00:04, 1383.75 examples/s]Applying chat template to train dataset:  52%|█████▏    | 5182/10033 [00:03<00:03, 1270.66 examples/s]Applying chat template to train dataset:  41%|████▏     | 4162/10033 [00:02<00:04, 1396.84 examples/s]Applying chat template to train dataset:  47%|████▋     | 4716/10033 [00:02<00:03, 1635.47 examples/s]Applying chat template to train dataset:  54%|█████▍    | 5422/10033 [00:03<00:03, 1524.43 examples/s]Applying chat template to train dataset:  44%|████▍     | 4461/10033 [00:02<00:03, 1763.55 examples/s]Applying chat template to train dataset:  50%|████▉     | 4981/10033 [00:03<00:02, 1859.32 examples/s]Applying chat template to train dataset:  57%|█████▋    | 5746/10033 [00:03<00:02, 1708.56 examples/s]Applying chat template to train dataset:  48%|████▊     | 4779/10033 [00:02<00:03, 1710.92 examples/s]Applying chat template to train dataset:  53%|█████▎    | 5319/10033 [00:03<00:02, 1817.56 examples/s]Applying chat template to train dataset:  61%|██████    | 6070/10033 [00:03<00:02, 1826.05 examples/s]Applying chat template to train dataset:  51%|█████     | 5069/10033 [00:03<00:02, 1974.78 examples/s]Applying chat template to train dataset:  63%|██████▎   | 6307/10033 [00:03<00:01, 1948.26 examples/s]Applying chat template to train dataset:  57%|█████▋    | 5671/10033 [00:03<00:02, 1973.32 examples/s]Applying chat template to train dataset:  54%|█████▎    | 5392/10033 [00:03<00:02, 1858.99 examples/s]Applying chat template to train dataset:  66%|██████▌   | 6629/10033 [00:03<00:02, 1701.95 examples/s]Applying chat template to train dataset:  56%|█████▌    | 5628/10033 [00:03<00:02, 1966.96 examples/s]Applying chat template to train dataset:  60%|█████▉    | 6008/10033 [00:03<00:02, 1810.32 examples/s]Applying chat template to train dataset:  69%|██████▉   | 6930/10033 [00:04<00:01, 1706.54 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5929/10033 [00:03<00:02, 1857.51 examples/s]Applying chat template to train dataset:  63%|██████▎   | 6331/10033 [00:03<00:02, 1708.67 examples/s]Applying chat template to train dataset:  72%|███████▏  | 7252/10033 [00:04<00:01, 1820.26 examples/s]Applying chat template to train dataset:  62%|██████▏   | 6256/10033 [00:03<00:02, 1822.84 examples/s]Applying chat template to train dataset:  66%|██████▋   | 6668/10033 [00:03<00:01, 1798.24 examples/s]Applying chat template to train dataset:  75%|███████▌  | 7533/10033 [00:04<00:01, 2025.65 examples/s]Applying chat template to train dataset:  66%|██████▌   | 6583/10033 [00:03<00:01, 1872.33 examples/s]Applying chat template to train dataset:  70%|██████▉   | 7003/10033 [00:04<00:01, 1827.69 examples/s]Applying chat template to train dataset:  78%|███████▊  | 7810/10033 [00:04<00:01, 1962.15 examples/s]Applying chat template to train dataset:  69%|██████▉   | 6903/10033 [00:04<00:01, 1926.86 examples/s]Applying chat template to train dataset:  73%|███████▎  | 7336/10033 [00:04<00:01, 1433.79 examples/s]Applying chat template to train dataset:  81%|████████  | 8130/10033 [00:04<00:01, 1450.25 examples/s]Applying chat template to train dataset:  72%|███████▏  | 7228/10033 [00:04<00:01, 1671.92 examples/s]Applying chat template to train dataset:  75%|███████▍  | 7500/10033 [00:04<00:01, 1389.08 examples/s]Applying chat template to train dataset:  84%|████████▍ | 8456/10033 [00:05<00:01, 1478.98 examples/s]Applying chat template to train dataset:  75%|███████▌  | 7554/10033 [00:04<00:01, 1641.80 examples/s]Applying chat template to train dataset:  77%|███████▋  | 7750/10033 [00:04<00:01, 1551.24 examples/s]Applying chat template to train dataset:  87%|████████▋ | 8752/10033 [00:05<00:00, 1733.21 examples/s]Applying chat template to train dataset:  77%|███████▋  | 7774/10033 [00:04<00:01, 1741.90 examples/s]Applying chat template to train dataset:  80%|███████▉  | 7979/10033 [00:04<00:01, 1696.08 examples/s]Applying chat template to train dataset:  91%|█████████ | 9084/10033 [00:05<00:00, 1854.03 examples/s]Applying chat template to train dataset:  81%|████████  | 8100/10033 [00:04<00:01, 1855.68 examples/s]Applying chat template to train dataset:  83%|████████▎ | 8314/10033 [00:04<00:00, 1792.64 examples/s]Applying chat template to train dataset:  93%|█████████▎| 9320/10033 [00:05<00:00, 1954.49 examples/s]Applying chat template to train dataset:  84%|████████▍ | 8428/10033 [00:04<00:00, 1803.89 examples/s]Applying chat template to train dataset:  86%|████████▌ | 8650/10033 [00:05<00:00, 1727.54 examples/s]Applying chat template to train dataset:  96%|█████████▌| 9652/10033 [00:05<00:00, 1966.63 examples/s]Applying chat template to train dataset:  87%|████████▋ | 8757/10033 [00:05<00:00, 1702.75 examples/s]Applying chat template to train dataset:  90%|████████▉ | 8993/10033 [00:05<00:00, 1469.34 examples/s]Applying chat template to train dataset: 100%|█████████▉| 9984/10033 [00:05<00:00, 1525.35 examples/s]Applying chat template to train dataset:  91%|█████████ | 9090/10033 [00:05<00:00, 1745.28 examples/s]Applying chat template to train dataset:  92%|█████████▏| 9243/10033 [00:05<00:00, 1641.66 examples/s]Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:05<00:00, 1675.10 examples/s]
Applying chat template to train dataset:  94%|█████████▍| 9473/10033 [00:05<00:00, 1768.28 examples/s]Applying chat template to train dataset:  94%|█████████▍| 9425/10033 [00:05<00:00, 1826.74 examples/s]Applying chat template to train dataset:  98%|█████████▊| 9801/10033 [00:05<00:00, 2094.16 examples/s]Applying chat template to train dataset:  96%|█████████▌| 9638/10033 [00:05<00:00, 1884.93 examples/s]Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:05<00:00, 1703.34 examples/s]
Applying chat template to train dataset:  99%|█████████▉| 9970/10033 [00:05<00:00, 1886.53 examples/s]Tokenizing train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:05<00:00, 1680.22 examples/s]
Tokenizing train dataset:   0%|          | 42/10033 [00:00<00:24, 406.70 examples/s]Tokenizing train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 88/10033 [00:00<00:29, 334.05 examples/s]Tokenizing train dataset:   0%|          | 42/10033 [00:00<00:24, 408.93 examples/s]Tokenizing train dataset:   1%|▏         | 130/10033 [00:00<00:33, 298.88 examples/s]Tokenizing train dataset:   1%|          | 85/10033 [00:00<00:31, 320.09 examples/s]Tokenizing train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing train dataset:   2%|▏         | 164/10033 [00:00<00:39, 248.86 examples/s]Tokenizing train dataset:   1%|▏         | 126/10033 [00:00<00:33, 294.92 examples/s]Tokenizing train dataset:   0%|          | 40/10033 [00:00<00:26, 378.05 examples/s]Tokenizing train dataset:   2%|▏         | 202/10033 [00:00<00:40, 245.15 examples/s]Tokenizing train dataset:   2%|▏         | 168/10033 [00:00<00:34, 286.65 examples/s]Tokenizing train dataset:   2%|▏         | 231/10033 [00:00<00:38, 254.97 examples/s]Tokenizing train dataset:   1%|          | 80/10033 [00:00<00:33, 299.25 examples/s]Tokenizing train dataset:   2%|▏         | 200/10033 [00:00<00:39, 251.77 examples/s]Tokenizing train dataset:   3%|▎         | 277/10033 [00:01<00:36, 266.65 examples/s]Tokenizing train dataset:   1%|          | 122/10033 [00:00<00:41, 240.07 examples/s]Tokenizing train dataset:   2%|▏         | 239/10033 [00:00<00:44, 221.89 examples/s]Tokenizing train dataset:   1%|▏         | 150/10033 [00:00<00:40, 245.05 examples/s]Tokenizing train dataset:   3%|▎         | 313/10033 [00:01<00:41, 234.12 examples/s]Tokenizing train dataset:   3%|▎         | 272/10033 [00:01<00:40, 241.55 examples/s]Tokenizing train dataset:   2%|▏         | 176/10033 [00:00<00:45, 214.70 examples/s]Tokenizing train dataset:   3%|▎         | 346/10033 [00:01<00:44, 218.52 examples/s]Tokenizing train dataset:   3%|▎         | 300/10033 [00:01<00:39, 245.93 examples/s]Tokenizing train dataset:   2%|▏         | 214/10033 [00:00<00:43, 224.64 examples/s]Tokenizing train dataset:   4%|▍         | 381/10033 [00:01<00:45, 213.00 examples/s]Tokenizing train dataset:   3%|▎         | 336/10033 [00:01<00:44, 219.99 examples/s]Tokenizing train dataset:   2%|▏         | 244/10033 [00:01<00:40, 240.44 examples/s]Tokenizing train dataset:   4%|▍         | 406/10033 [00:01<00:44, 218.60 examples/s]Tokenizing train dataset:   4%|▎         | 372/10033 [00:01<00:43, 221.95 examples/s]Tokenizing train dataset:   3%|▎         | 281/10033 [00:01<00:40, 241.52 examples/s]Tokenizing train dataset:   4%|▍         | 436/10033 [00:01<00:40, 235.70 examples/s]Tokenizing train dataset:   4%|▍         | 405/10033 [00:01<00:44, 217.29 examples/s]Tokenizing train dataset:   3%|▎         | 313/10033 [00:01<00:46, 209.70 examples/s]Tokenizing train dataset:   5%|▍         | 469/10033 [00:02<00:48, 196.30 examples/s]Tokenizing train dataset:   4%|▍         | 440/10033 [00:01<00:51, 187.30 examples/s]Tokenizing train dataset:   3%|▎         | 344/10033 [00:01<00:53, 181.04 examples/s]Tokenizing train dataset:   5%|▍         | 501/10033 [00:02<00:52, 180.88 examples/s]Tokenizing train dataset:   5%|▍         | 470/10033 [00:02<00:46, 207.04 examples/s]Tokenizing train dataset:   4%|▎         | 371/10033 [00:01<00:48, 197.77 examples/s]Tokenizing train dataset:   5%|▌         | 525/10033 [00:02<00:49, 191.84 examples/s]Tokenizing train dataset:   5%|▍         | 501/10033 [00:02<00:50, 188.79 examples/s]Tokenizing train dataset:   4%|▍         | 402/10033 [00:01<00:52, 184.90 examples/s]Tokenizing train dataset:   6%|▌         | 561/10033 [00:02<00:49, 192.56 examples/s]Tokenizing train dataset:   5%|▌         | 524/10033 [00:02<00:48, 196.48 examples/s]Tokenizing train dataset:   4%|▍         | 430/10033 [00:01<00:47, 202.49 examples/s]Tokenizing train dataset:   6%|▌         | 587/10033 [00:02<00:46, 204.57 examples/s]Tokenizing train dataset:   5%|▌         | 549/10033 [00:02<00:45, 206.71 examples/s]Tokenizing train dataset:   6%|▌         | 614/10033 [00:02<00:43, 215.88 examples/s]Tokenizing train dataset:   5%|▍         | 465/10033 [00:02<00:45, 209.06 examples/s]Tokenizing train dataset:   6%|▌         | 576/10033 [00:02<00:42, 221.16 examples/s]Tokenizing train dataset:   6%|▋         | 647/10033 [00:02<00:38, 241.26 examples/s]Tokenizing train dataset:   5%|▍         | 495/10033 [00:02<00:47, 199.01 examples/s]Tokenizing train dataset:   6%|▌         | 605/10033 [00:02<00:53, 175.86 examples/s]Tokenizing train dataset:   7%|▋         | 678/10033 [00:03<00:52, 178.57 examples/s]Tokenizing train dataset:   5%|▌         | 526/10033 [00:02<00:52, 181.13 examples/s]Tokenizing train dataset:   6%|▌         | 626/10033 [00:02<00:52, 178.46 examples/s]Tokenizing train dataset:   7%|▋         | 705/10033 [00:03<00:55, 169.13 examples/s]Tokenizing train dataset:   6%|▌         | 560/10033 [00:02<00:55, 171.03 examples/s]Tokenizing train dataset:   7%|▋         | 660/10033 [00:03<00:55, 170.40 examples/s]Tokenizing train dataset:   7%|▋         | 737/10033 [00:03<00:46, 198.31 examples/s]Tokenizing train dataset:   6%|▌         | 580/10033 [00:02<00:54, 173.21 examples/s]Tokenizing train dataset:   7%|▋         | 690/10033 [00:03<00:54, 170.17 examples/s]Tokenizing train dataset:   6%|▌         | 605/10033 [00:02<00:50, 186.44 examples/s]Tokenizing train dataset:   8%|▊         | 769/10033 [00:03<00:49, 185.80 examples/s]Tokenizing train dataset:   7%|▋         | 725/10033 [00:03<00:55, 168.13 examples/s]Tokenizing train dataset:   6%|▌         | 625/10033 [00:03<01:00, 156.42 examples/s]Tokenizing train dataset:   8%|▊         | 798/10033 [00:03<01:11, 129.14 examples/s]Tokenizing train dataset:   7%|▋         | 744/10033 [00:03<01:09, 134.61 examples/s]Tokenizing train dataset:   6%|▋         | 643/10033 [00:03<01:16, 123.12 examples/s]Tokenizing train dataset:   8%|▊         | 823/10033 [00:04<01:02, 146.76 examples/s]Tokenizing train dataset:   8%|▊         | 766/10033 [00:03<01:02, 149.34 examples/s]Tokenizing train dataset:   7%|▋         | 665/10033 [00:03<01:06, 140.78 examples/s]Tokenizing train dataset:   8%|▊         | 849/10033 [00:04<00:55, 166.02 examples/s]Tokenizing train dataset:   8%|▊         | 790/10033 [00:03<00:55, 165.83 examples/s]Tokenizing train dataset:   7%|▋         | 690/10033 [00:03<00:57, 162.39 examples/s]Tokenizing train dataset:   9%|▊         | 876/10033 [00:04<00:49, 186.12 examples/s]Tokenizing train dataset:   8%|▊         | 819/10033 [00:04<00:47, 192.27 examples/s]Tokenizing train dataset:   7%|▋         | 717/10033 [00:03<00:50, 185.39 examples/s]Tokenizing train dataset:   9%|▉         | 899/10033 [00:04<00:50, 181.75 examples/s]Tokenizing train dataset:   7%|▋         | 739/10033 [00:03<00:56, 163.59 examples/s]Tokenizing train dataset:   8%|▊         | 850/10033 [00:04<00:55, 166.19 examples/s]Tokenizing train dataset:   9%|▉         | 930/10033 [00:04<00:49, 184.15 examples/s]Tokenizing train dataset:   8%|▊         | 771/10033 [00:04<00:52, 175.16 examples/s]Tokenizing train dataset:   9%|▉         | 885/10033 [00:04<00:52, 175.74 examples/s]Tokenizing train dataset:  10%|▉         | 965/10033 [00:04<00:46, 195.99 examples/s]Tokenizing train dataset:   8%|▊         | 798/10033 [00:04<00:55, 165.61 examples/s]Tokenizing train dataset:   9%|▉         | 907/10033 [00:04<00:52, 172.81 examples/s]Tokenizing train dataset:  10%|▉         | 992/10033 [00:04<00:51, 174.84 examples/s]Tokenizing train dataset:   8%|▊         | 825/10033 [00:04<01:05, 139.88 examples/s]Tokenizing train dataset:   9%|▉         | 936/10033 [00:04<01:03, 143.34 examples/s]Tokenizing train dataset:  10%|█         | 1022/10033 [00:05<00:55, 160.96 examples/s]Tokenizing train dataset:   8%|▊         | 841/10033 [00:04<01:09, 133.18 examples/s]Tokenizing train dataset:   9%|▉         | 953/10033 [00:05<01:05, 138.41 examples/s]Tokenizing train dataset:  10%|█         | 1052/10033 [00:05<00:55, 162.00 examples/s]Tokenizing train dataset:   9%|▊         | 861/10033 [00:04<01:03, 144.16 examples/s]Tokenizing train dataset:  10%|▉         | 972/10033 [00:05<01:01, 147.73 examples/s]Tokenizing train dataset:  11%|█         | 1069/10033 [00:05<01:04, 137.99 examples/s]Tokenizing train dataset:  11%|█         | 1090/10033 [00:05<01:02, 144.22 examples/s]Tokenizing train dataset:   9%|▉         | 898/10033 [00:05<01:09, 131.19 examples/s]Tokenizing train dataset:  10%|▉         | 1001/10033 [00:05<01:15, 119.80 examples/s]Tokenizing train dataset:  11%|█         | 1117/10033 [00:05<00:53, 167.78 examples/s]Tokenizing train dataset:   9%|▉         | 920/10033 [00:05<01:02, 145.06 examples/s]Tokenizing train dataset:  10%|█         | 1028/10033 [00:05<01:02, 144.93 examples/s]Tokenizing train dataset:  11%|█▏        | 1141/10033 [00:05<00:48, 183.36 examples/s]Tokenizing train dataset:   9%|▉         | 948/10033 [00:05<00:52, 171.46 examples/s]Tokenizing train dataset:  11%|█         | 1056/10033 [00:05<00:52, 170.86 examples/s]Tokenizing train dataset:  12%|█▏        | 1167/10033 [00:05<00:44, 200.07 examples/s]Tokenizing train dataset:  10%|▉         | 971/10033 [00:05<00:49, 183.64 examples/s]Tokenizing train dataset:  11%|█         | 1092/10033 [00:05<00:42, 209.77 examples/s]Tokenizing train dataset:  12%|█▏        | 1203/10033 [00:06<00:47, 186.00 examples/s]Tokenizing train dataset:  10%|▉         | 997/10033 [00:05<00:57, 157.65 examples/s]Tokenizing train dataset:  11%|█         | 1122/10033 [00:05<00:47, 188.24 examples/s]Tokenizing train dataset:  12%|█▏        | 1233/10033 [00:06<00:41, 210.69 examples/s]Tokenizing train dataset:  10%|█         | 1024/10033 [00:05<00:50, 178.59 examples/s]Tokenizing train dataset:  12%|█▏        | 1157/10033 [00:06<00:44, 198.88 examples/s]Tokenizing train dataset:  13%|█▎        | 1257/10033 [00:06<00:40, 217.53 examples/s]Tokenizing train dataset:  11%|█         | 1056/10033 [00:05<00:47, 187.50 examples/s]Tokenizing train dataset:  12%|█▏        | 1190/10033 [00:06<00:43, 203.73 examples/s]Tokenizing train dataset:  13%|█▎        | 1289/10033 [00:06<00:40, 213.78 examples/s]Tokenizing train dataset:  13%|█▎        | 1319/10033 [00:06<00:37, 233.92 examples/s]Tokenizing train dataset:  11%|█         | 1091/10033 [00:06<00:47, 187.08 examples/s]Tokenizing train dataset:  12%|█▏        | 1227/10033 [00:06<00:41, 213.64 examples/s]Tokenizing train dataset:  11%|█         | 1114/10033 [00:06<00:45, 195.24 examples/s]Tokenizing train dataset:  13%|█▎        | 1346/10033 [00:06<00:36, 240.70 examples/s]Tokenizing train dataset:  13%|█▎        | 1258/10033 [00:06<00:37, 233.08 examples/s]Tokenizing train dataset:  14%|█▎        | 1372/10033 [00:06<00:40, 213.77 examples/s]Tokenizing train dataset:  11%|█▏        | 1144/10033 [00:06<00:46, 193.21 examples/s]Tokenizing train dataset:  13%|█▎        | 1298/10033 [00:06<00:36, 238.52 examples/s]Tokenizing train dataset:  14%|█▍        | 1407/10033 [00:07<00:40, 210.81 examples/s]Tokenizing train dataset:  12%|█▏        | 1171/10033 [00:06<00:51, 171.25 examples/s]Tokenizing train dataset:  13%|█▎        | 1331/10033 [00:06<00:39, 219.47 examples/s]Tokenizing train dataset:  14%|█▍        | 1435/10033 [00:07<00:38, 224.47 examples/s]Tokenizing train dataset:  12%|█▏        | 1190/10033 [00:06<00:51, 173.09 examples/s]Tokenizing train dataset:  14%|█▎        | 1360/10033 [00:07<00:41, 207.64 examples/s]Tokenizing train dataset:  15%|█▍        | 1467/10033 [00:07<00:40, 210.02 examples/s]Tokenizing train dataset:  12%|█▏        | 1220/10033 [00:07<01:19, 111.24 examples/s]Tokenizing train dataset:  14%|█▍        | 1390/10033 [00:07<01:03, 136.04 examples/s]Tokenizing train dataset:  15%|█▍        | 1496/10033 [00:07<00:58, 145.64 examples/s]Tokenizing train dataset:  12%|█▏        | 1240/10033 [00:07<01:12, 121.63 examples/s]Tokenizing train dataset:  14%|█▍        | 1408/10033 [00:07<01:03, 136.44 examples/s]Tokenizing train dataset:  15%|█▌        | 1530/10033 [00:07<00:56, 149.33 examples/s]Tokenizing train dataset:  13%|█▎        | 1256/10033 [00:07<01:13, 119.10 examples/s]Tokenizing train dataset:  14%|█▍        | 1426/10033 [00:07<01:08, 126.55 examples/s]Tokenizing train dataset:  15%|█▌        | 1548/10033 [00:08<00:57, 147.72 examples/s]Tokenizing train dataset:  13%|█▎        | 1272/10033 [00:07<01:16, 114.67 examples/s]Tokenizing train dataset:  16%|█▌        | 1565/10033 [00:08<00:56, 149.10 examples/s]Tokenizing train dataset:  15%|█▍        | 1456/10033 [00:07<01:03, 135.12 examples/s]Tokenizing train dataset:  13%|█▎        | 1286/10033 [00:07<01:14, 117.27 examples/s]Tokenizing train dataset:  16%|█▌        | 1583/10033 [00:08<00:54, 154.59 examples/s]Tokenizing train dataset:  15%|█▍        | 1480/10033 [00:08<00:55, 153.71 examples/s]Tokenizing train dataset:  13%|█▎        | 1314/10033 [00:07<00:57, 150.55 examples/s]Tokenizing train dataset:  16%|█▌        | 1600/10033 [00:08<00:55, 152.72 examples/s]Tokenizing train dataset:  13%|█▎        | 1331/10033 [00:07<00:56, 153.84 examples/s]Tokenizing train dataset:  15%|█▌        | 1509/10033 [00:08<00:52, 163.17 examples/s]Tokenizing train dataset:  16%|█▌        | 1620/10033 [00:08<01:01, 136.97 examples/s]Tokenizing train dataset:  13%|█▎        | 1348/10033 [00:08<01:17, 111.82 examples/s]Tokenizing train dataset:  15%|█▌        | 1530/10033 [00:08<01:12, 117.79 examples/s]Tokenizing train dataset:  16%|█▋        | 1637/10033 [00:08<01:13, 114.87 examples/s]Tokenizing train dataset:  14%|█▎        | 1373/10033 [00:08<01:10, 123.23 examples/s]Tokenizing train dataset:  15%|█▌        | 1550/10033 [00:08<01:04, 130.58 examples/s]Tokenizing train dataset:  17%|█▋        | 1658/10033 [00:08<01:03, 132.68 examples/s]Tokenizing train dataset:  14%|█▍        | 1397/10033 [00:08<00:58, 146.46 examples/s]Tokenizing train dataset:  16%|█▌        | 1577/10033 [00:08<00:54, 155.93 examples/s]Tokenizing train dataset:  17%|█▋        | 1680/10033 [00:08<00:55, 149.94 examples/s]Tokenizing train dataset:  14%|█▍        | 1426/10033 [00:08<00:54, 158.57 examples/s]Tokenizing train dataset:  16%|█▌        | 1610/10033 [00:08<00:52, 159.72 examples/s]Tokenizing train dataset:  17%|█▋        | 1705/10033 [00:09<01:03, 130.69 examples/s]Tokenizing train dataset:  15%|█▍        | 1456/10033 [00:08<01:01, 138.64 examples/s]Tokenizing train dataset:  17%|█▋        | 1720/10033 [00:09<01:08, 120.55 examples/s]Tokenizing train dataset:  16%|█▋        | 1648/10033 [00:09<00:50, 164.64 examples/s]Tokenizing train dataset:  15%|█▍        | 1483/10033 [00:08<00:52, 161.72 examples/s]Tokenizing train dataset:  17%|█▋        | 1743/10033 [00:09<00:58, 141.16 examples/s]Tokenizing train dataset:  17%|█▋        | 1673/10033 [00:09<00:46, 179.49 examples/s]Tokenizing train dataset:  15%|█▌        | 1508/10033 [00:08<00:47, 178.69 examples/s]Tokenizing train dataset:  18%|█▊        | 1776/10033 [00:09<00:45, 182.52 examples/s]Tokenizing train dataset:  17%|█▋        | 1711/10033 [00:09<00:37, 221.50 examples/s]Tokenizing train dataset:  15%|█▌        | 1535/10033 [00:09<00:42, 198.21 examples/s]Tokenizing train dataset:  18%|█▊        | 1804/10033 [00:09<00:40, 204.80 examples/s]Tokenizing train dataset:  17%|█▋        | 1737/10033 [00:09<00:36, 228.62 examples/s]Tokenizing train dataset:  16%|█▌        | 1566/10033 [00:09<00:42, 198.18 examples/s]Tokenizing train dataset:  18%|█▊        | 1840/10033 [00:09<00:40, 202.50 examples/s]Tokenizing train dataset:  18%|█▊        | 1773/10033 [00:09<00:39, 210.62 examples/s]Tokenizing train dataset:  16%|█▌        | 1595/10033 [00:09<00:45, 186.67 examples/s]Tokenizing train dataset:  19%|█▊        | 1870/10033 [00:10<00:43, 186.82 examples/s]Tokenizing train dataset:  18%|█▊        | 1805/10033 [00:09<00:40, 200.93 examples/s]Tokenizing train dataset:  16%|█▌        | 1621/10033 [00:09<00:41, 202.69 examples/s]Tokenizing train dataset:  19%|█▉        | 1895/10033 [00:10<00:40, 199.10 examples/s]Tokenizing train dataset:  18%|█▊        | 1840/10033 [00:10<00:44, 183.98 examples/s]Tokenizing train dataset:  16%|█▋        | 1654/10033 [00:09<00:49, 168.78 examples/s]Tokenizing train dataset:  19%|█▉        | 1921/10033 [00:10<00:47, 169.05 examples/s]Tokenizing train dataset:  19%|█▊        | 1870/10033 [00:10<00:44, 183.89 examples/s]Tokenizing train dataset:  17%|█▋        | 1686/10033 [00:09<00:42, 196.53 examples/s]Tokenizing train dataset:  19%|█▉        | 1952/10033 [00:10<00:40, 197.21 examples/s]Tokenizing train dataset:  19%|█▉        | 1900/10033 [00:10<00:39, 204.63 examples/s]Tokenizing train dataset:  20%|█▉        | 1977/10033 [00:10<00:38, 207.39 examples/s]Tokenizing train dataset:  17%|█▋        | 1720/10033 [00:09<00:37, 223.34 examples/s]Tokenizing train dataset:  19%|█▉        | 1926/10033 [00:10<00:44, 184.21 examples/s]Tokenizing train dataset:  20%|██        | 2014/10033 [00:10<00:44, 180.62 examples/s]Tokenizing train dataset:  17%|█▋        | 1752/10033 [00:10<00:46, 178.47 examples/s]Tokenizing train dataset:  19%|█▉        | 1950/10033 [00:10<00:41, 194.32 examples/s]Tokenizing train dataset:  20%|██        | 2037/10033 [00:10<00:42, 189.12 examples/s]Tokenizing train dataset:  18%|█▊        | 1787/10033 [00:10<00:43, 190.51 examples/s]Tokenizing train dataset:  20%|█▉        | 1989/10033 [00:10<00:37, 212.86 examples/s]Tokenizing train dataset:  21%|██        | 2058/10033 [00:11<00:43, 184.12 examples/s]Tokenizing train dataset:  18%|█▊        | 1813/10033 [00:10<00:40, 203.47 examples/s]Tokenizing train dataset:  20%|██        | 2021/10033 [00:10<00:34, 235.45 examples/s]Tokenizing train dataset:  21%|██        | 2083/10033 [00:11<00:40, 197.77 examples/s]Tokenizing train dataset:  18%|█▊        | 1838/10033 [00:10<00:38, 211.96 examples/s]Tokenizing train dataset:  21%|██        | 2063/10033 [00:11<00:32, 246.26 examples/s]Tokenizing train dataset:  21%|██        | 2125/10033 [00:11<00:35, 223.07 examples/s]Tokenizing train dataset:  19%|█▊        | 1872/10033 [00:10<00:38, 212.42 examples/s]Tokenizing train dataset:  21%|██        | 2092/10033 [00:11<00:31, 253.84 examples/s]Tokenizing train dataset:  22%|██▏       | 2164/10033 [00:11<00:33, 232.99 examples/s]Tokenizing train dataset:  19%|█▉        | 1902/10033 [00:10<00:35, 231.00 examples/s]Tokenizing train dataset:  21%|██        | 2130/10033 [00:11<00:28, 282.15 examples/s]Tokenizing train dataset:  19%|█▉        | 1927/10033 [00:11<00:42, 189.60 examples/s]Tokenizing train dataset:  22%|██▏       | 2200/10033 [00:11<00:39, 197.30 examples/s]Tokenizing train dataset:  22%|██▏       | 2169/10033 [00:11<00:35, 219.45 examples/s]Tokenizing train dataset:  19%|█▉        | 1953/10033 [00:11<00:39, 203.63 examples/s]Tokenizing train dataset:  22%|██▏       | 2223/10033 [00:11<00:38, 202.92 examples/s]Tokenizing train dataset:  22%|██▏       | 2207/10033 [00:11<00:40, 194.18 examples/s]Tokenizing train dataset:  20%|█▉        | 1989/10033 [00:11<00:43, 186.65 examples/s]Tokenizing train dataset:  23%|██▎       | 2260/10033 [00:12<00:40, 191.67 examples/s]Tokenizing train dataset:  22%|██▏       | 2235/10033 [00:11<00:37, 209.16 examples/s]Tokenizing train dataset:  20%|██        | 2017/10033 [00:11<00:39, 204.81 examples/s]Tokenizing train dataset:  23%|██▎       | 2285/10033 [00:12<00:42, 182.85 examples/s]Tokenizing train dataset:  23%|██▎       | 2278/10033 [00:11<00:34, 227.46 examples/s]Tokenizing train dataset:  20%|██        | 2056/10033 [00:11<00:36, 220.50 examples/s]Tokenizing train dataset:  23%|██▎       | 2310/10033 [00:12<00:39, 194.67 examples/s]Tokenizing train dataset:  23%|██▎       | 2306/10033 [00:12<00:32, 235.95 examples/s]Tokenizing train dataset:  21%|██        | 2090/10033 [00:11<00:36, 218.03 examples/s]Tokenizing train dataset:  23%|██▎       | 2346/10033 [00:12<00:37, 202.54 examples/s]Tokenizing train dataset:  23%|██▎       | 2343/10033 [00:12<00:32, 237.77 examples/s]Tokenizing train dataset:  21%|██        | 2124/10033 [00:11<00:32, 244.85 examples/s]Tokenizing train dataset:  24%|██▍       | 2384/10033 [00:12<00:38, 197.98 examples/s]Tokenizing train dataset:  24%|██▎       | 2381/10033 [00:12<00:35, 214.85 examples/s]Tokenizing train dataset:  22%|██▏       | 2158/10033 [00:12<00:38, 203.80 examples/s]Tokenizing train dataset:  24%|██▍       | 2422/10033 [00:12<00:32, 234.04 examples/s]Tokenizing train dataset:  24%|██▍       | 2413/10033 [00:12<00:32, 233.72 examples/s]Tokenizing train dataset:  22%|██▏       | 2189/10033 [00:12<00:34, 224.84 examples/s]Tokenizing train dataset:  25%|██▍       | 2460/10033 [00:12<00:28, 264.03 examples/s]Tokenizing train dataset:  24%|██▍       | 2446/10033 [00:12<00:30, 252.44 examples/s]Tokenizing train dataset:  22%|██▏       | 2222/10033 [00:12<00:31, 245.15 examples/s]Tokenizing train dataset:  25%|██▍       | 2492/10033 [00:12<00:27, 274.28 examples/s]Tokenizing train dataset:  25%|██▍       | 2478/10033 [00:12<00:28, 265.76 examples/s]Tokenizing train dataset:  23%|██▎       | 2259/10033 [00:12<00:33, 235.27 examples/s]Tokenizing train dataset:  25%|██▌       | 2532/10033 [00:13<00:29, 250.61 examples/s]Tokenizing train dataset:  25%|██▌       | 2511/10033 [00:12<00:30, 246.67 examples/s]Tokenizing train dataset:  23%|██▎       | 2291/10033 [00:12<00:30, 253.49 examples/s]Tokenizing train dataset:  26%|██▌       | 2571/10033 [00:13<00:26, 281.76 examples/s]Tokenizing train dataset:  25%|██▌       | 2550/10033 [00:13<00:26, 277.90 examples/s]Tokenizing train dataset:  23%|██▎       | 2320/10033 [00:12<00:29, 259.29 examples/s]Tokenizing train dataset:  26%|██▌       | 2605/10033 [00:13<00:25, 294.62 examples/s]Tokenizing train dataset:  26%|██▌       | 2590/10033 [00:13<00:28, 262.57 examples/s]Tokenizing train dataset:  23%|██▎       | 2353/10033 [00:12<00:31, 241.37 examples/s]Tokenizing train dataset:  26%|██▋       | 2640/10033 [00:13<00:27, 265.89 examples/s]Tokenizing train dataset:  26%|██▌       | 2622/10033 [00:13<00:31, 237.42 examples/s]Tokenizing train dataset:  24%|██▍       | 2400/10033 [00:13<00:29, 261.74 examples/s]Tokenizing train dataset:  27%|██▋       | 2675/10033 [00:13<00:29, 251.86 examples/s]Tokenizing train dataset:  26%|██▋       | 2658/10033 [00:13<00:31, 236.48 examples/s]Tokenizing train dataset:  24%|██▍       | 2436/10033 [00:13<00:35, 212.04 examples/s]Tokenizing train dataset:  27%|██▋       | 2716/10033 [00:13<00:33, 218.46 examples/s]Tokenizing train dataset:  27%|██▋       | 2690/10033 [00:13<00:32, 224.97 examples/s]Tokenizing train dataset:  27%|██▋       | 2740/10033 [00:14<00:33, 219.45 examples/s]Tokenizing train dataset:  25%|██▍       | 2474/10033 [00:13<00:34, 222.29 examples/s]Tokenizing train dataset:  27%|██▋       | 2729/10033 [00:13<00:28, 258.21 examples/s]Tokenizing train dataset:  28%|██▊       | 2767/10033 [00:14<00:31, 228.61 examples/s]Tokenizing train dataset:  25%|██▌       | 2512/10033 [00:13<00:33, 227.90 examples/s]Tokenizing train dataset:  28%|██▊       | 2762/10033 [00:13<00:30, 239.93 examples/s]Tokenizing train dataset:  28%|██▊       | 2797/10033 [00:14<00:29, 244.92 examples/s]Tokenizing train dataset:  25%|██▌       | 2543/10033 [00:13<00:30, 243.68 examples/s]Tokenizing train dataset:  28%|██▊       | 2789/10033 [00:14<00:29, 244.75 examples/s]Tokenizing train dataset:  28%|██▊       | 2837/10033 [00:14<00:35, 202.80 examples/s]Tokenizing train dataset:  26%|██▌       | 2583/10033 [00:13<00:33, 225.66 examples/s]Tokenizing train dataset:  28%|██▊       | 2830/10033 [00:14<00:37, 191.75 examples/s]Tokenizing train dataset:  29%|██▊       | 2870/10033 [00:14<00:36, 194.55 examples/s]Tokenizing train dataset:  26%|██▌       | 2618/10033 [00:14<00:38, 193.17 examples/s]Tokenizing train dataset:  29%|██▊       | 2864/10033 [00:14<00:36, 199.03 examples/s]Tokenizing train dataset:  29%|██▉       | 2894/10033 [00:14<00:37, 191.91 examples/s]Tokenizing train dataset:  26%|██▋       | 2642/10033 [00:14<00:36, 200.55 examples/s]Tokenizing train dataset:  29%|██▉       | 2902/10033 [00:14<00:30, 233.49 examples/s]Tokenizing train dataset:  29%|██▉       | 2921/10033 [00:14<00:34, 205.02 examples/s]Tokenizing train dataset:  27%|██▋       | 2667/10033 [00:14<00:35, 209.99 examples/s]Tokenizing train dataset:  29%|██▉       | 2936/10033 [00:14<00:27, 255.07 examples/s]Tokenizing train dataset:  29%|██▉       | 2954/10033 [00:15<00:30, 231.65 examples/s]Tokenizing train dataset:  27%|██▋       | 2707/10033 [00:14<00:32, 225.15 examples/s]Tokenizing train dataset:  30%|██▉       | 2983/10033 [00:14<00:26, 261.92 examples/s]Tokenizing train dataset:  27%|██▋       | 2733/10033 [00:14<00:31, 231.22 examples/s]Tokenizing train dataset:  30%|██▉       | 2999/10033 [00:15<00:32, 219.02 examples/s]Tokenizing train dataset:  30%|███       | 3022/10033 [00:15<00:26, 260.27 examples/s]Tokenizing train dataset:  28%|██▊       | 2761/10033 [00:14<00:30, 240.12 examples/s]Tokenizing train dataset:  30%|███       | 3029/10033 [00:15<00:29, 235.19 examples/s]Tokenizing train dataset:  28%|██▊       | 2798/10033 [00:14<00:26, 270.34 examples/s]Tokenizing train dataset:  30%|███       | 3058/10033 [00:15<00:28, 246.39 examples/s]Tokenizing train dataset:  31%|███       | 3066/10033 [00:15<00:25, 268.38 examples/s]Tokenizing train dataset:  28%|██▊       | 2833/10033 [00:14<00:24, 288.04 examples/s]Tokenizing train dataset:  31%|███       | 3087/10033 [00:15<00:27, 254.86 examples/s]Tokenizing train dataset:  31%|███       | 3094/10033 [00:15<00:25, 270.43 examples/s]Tokenizing train dataset:  29%|██▊       | 2866/10033 [00:15<00:27, 258.66 examples/s]Tokenizing train dataset:  31%|███       | 3124/10033 [00:15<00:31, 218.58 examples/s]Tokenizing train dataset:  31%|███       | 3130/10033 [00:15<00:31, 217.04 examples/s]Tokenizing train dataset:  29%|██▉       | 2907/10033 [00:15<00:29, 241.33 examples/s]Tokenizing train dataset:  31%|███▏      | 3159/10033 [00:15<00:29, 231.19 examples/s]Tokenizing train dataset:  32%|███▏      | 3164/10033 [00:15<00:30, 228.40 examples/s]Tokenizing train dataset:  29%|██▉       | 2943/10033 [00:15<00:26, 267.19 examples/s]Tokenizing train dataset:  32%|███▏      | 3185/10033 [00:15<00:29, 235.93 examples/s]Tokenizing train dataset:  32%|███▏      | 3196/10033 [00:16<00:27, 246.09 examples/s]Tokenizing train dataset:  30%|██▉       | 2987/10033 [00:15<00:26, 266.05 examples/s]Tokenizing train dataset:  32%|███▏      | 3225/10033 [00:15<00:28, 237.43 examples/s]Tokenizing train dataset:  32%|███▏      | 3236/10033 [00:16<00:27, 249.90 examples/s]Tokenizing train dataset:  32%|███▏      | 3254/10033 [00:16<00:27, 247.60 examples/s]Tokenizing train dataset:  30%|███       | 3029/10033 [00:15<00:26, 266.94 examples/s]Tokenizing train dataset:  33%|███▎      | 3276/10033 [00:16<00:28, 235.89 examples/s]Tokenizing train dataset:  33%|███▎      | 3280/10033 [00:16<00:27, 248.98 examples/s]Tokenizing train dataset:  31%|███       | 3074/10033 [00:15<00:25, 273.19 examples/s]Tokenizing train dataset:  33%|███▎      | 3305/10033 [00:16<00:27, 246.29 examples/s]Tokenizing train dataset:  33%|███▎      | 3307/10033 [00:16<00:26, 252.48 examples/s]Tokenizing train dataset:  31%|███       | 3112/10033 [00:16<00:26, 257.52 examples/s]Tokenizing train dataset:  33%|███▎      | 3340/10033 [00:16<00:28, 235.37 examples/s]Tokenizing train dataset:  33%|███▎      | 3341/10033 [00:16<00:28, 231.19 examples/s]Tokenizing train dataset:  31%|███▏      | 3143/10033 [00:16<00:25, 265.85 examples/s]Tokenizing train dataset:  34%|███▎      | 3380/10033 [00:16<00:24, 267.41 examples/s]Tokenizing train dataset:  34%|███▎      | 3380/10033 [00:16<00:24, 266.30 examples/s]Tokenizing train dataset:  32%|███▏      | 3175/10033 [00:16<00:24, 278.14 examples/s]Tokenizing train dataset:  34%|███▍      | 3421/10033 [00:16<00:21, 300.65 examples/s]Tokenizing train dataset:  34%|███▍      | 3408/10033 [00:16<00:24, 268.33 examples/s]Tokenizing train dataset:  32%|███▏      | 3205/10033 [00:16<00:24, 282.67 examples/s]Tokenizing train dataset:  34%|███▍      | 3440/10033 [00:16<00:23, 278.99 examples/s]Tokenizing train dataset:  35%|███▍      | 3472/10033 [00:16<00:21, 311.57 examples/s]Tokenizing train dataset:  32%|███▏      | 3240/10033 [00:16<00:22, 298.31 examples/s]Tokenizing train dataset:  35%|███▍      | 3475/10033 [00:16<00:22, 297.09 examples/s]Tokenizing train dataset:  35%|███▌      | 3514/10033 [00:17<00:23, 282.79 examples/s]Tokenizing train dataset:  33%|███▎      | 3277/10033 [00:16<00:24, 274.29 examples/s]Tokenizing train dataset:  35%|███▌      | 3519/10033 [00:16<00:22, 292.04 examples/s]Tokenizing train dataset:  35%|███▌      | 3545/10033 [00:17<00:22, 287.23 examples/s]Tokenizing train dataset:  33%|███▎      | 3310/10033 [00:16<00:26, 250.28 examples/s]Tokenizing train dataset:  35%|███▌      | 3555/10033 [00:17<00:24, 265.73 examples/s]Tokenizing train dataset:  36%|███▌      | 3594/10033 [00:17<00:21, 298.41 examples/s]Tokenizing train dataset:  33%|███▎      | 3342/10033 [00:16<00:28, 236.71 examples/s]Tokenizing train dataset:  36%|███▌      | 3600/10033 [00:17<00:23, 274.43 examples/s]Tokenizing train dataset:  36%|███▌      | 3633/10033 [00:17<00:24, 257.13 examples/s]Tokenizing train dataset:  36%|███▌      | 3630/10033 [00:17<00:23, 275.05 examples/s]Tokenizing train dataset:  34%|███▎      | 3382/10033 [00:17<00:27, 243.78 examples/s]Tokenizing train dataset:  34%|███▍      | 3412/10033 [00:17<00:25, 254.70 examples/s]Tokenizing train dataset:  37%|███▋      | 3674/10033 [00:17<00:24, 260.08 examples/s]Tokenizing train dataset:  37%|███▋      | 3668/10033 [00:17<00:24, 264.92 examples/s]Tokenizing train dataset:  34%|███▍      | 3452/10033 [00:17<00:25, 255.25 examples/s]Tokenizing train dataset:  37%|███▋      | 3724/10033 [00:17<00:22, 276.86 examples/s]Tokenizing train dataset:  37%|███▋      | 3707/10033 [00:17<00:24, 259.49 examples/s]Tokenizing train dataset:  35%|███▍      | 3482/10033 [00:17<00:24, 263.57 examples/s]Tokenizing train dataset:  37%|███▋      | 3758/10033 [00:18<00:21, 287.79 examples/s]Tokenizing train dataset:  37%|███▋      | 3744/10033 [00:17<00:22, 282.36 examples/s]Tokenizing train dataset:  38%|███▊      | 3790/10033 [00:18<00:21, 291.19 examples/s]Tokenizing train dataset:  35%|███▌      | 3526/10033 [00:17<00:24, 271.07 examples/s]Tokenizing train dataset:  38%|███▊      | 3785/10033 [00:17<00:24, 255.19 examples/s]Tokenizing train dataset:  38%|███▊      | 3823/10033 [00:18<00:20, 297.62 examples/s]Tokenizing train dataset:  35%|███▌      | 3556/10033 [00:17<00:23, 275.39 examples/s]Tokenizing train dataset:  38%|███▊      | 3821/10033 [00:18<00:25, 241.92 examples/s]Tokenizing train dataset:  38%|███▊      | 3861/10033 [00:18<00:25, 244.32 examples/s]Tokenizing train dataset:  36%|███▌      | 3595/10033 [00:17<00:26, 238.49 examples/s]Tokenizing train dataset:  38%|███▊      | 3853/10033 [00:18<00:24, 255.39 examples/s]Tokenizing train dataset:  39%|███▉      | 3898/10033 [00:18<00:28, 218.24 examples/s]Tokenizing train dataset:  36%|███▌      | 3633/10033 [00:18<00:57, 111.55 examples/s]Tokenizing train dataset:  39%|███▉      | 3892/10033 [00:19<00:54, 113.53 examples/s]Tokenizing train dataset:  39%|███▉      | 3933/10033 [00:19<00:49, 122.11 examples/s]Tokenizing train dataset:  36%|███▋      | 3654/10033 [00:18<00:52, 122.42 examples/s]Tokenizing train dataset:  39%|███▉      | 3952/10033 [00:19<00:47, 128.36 examples/s]Tokenizing train dataset:  39%|███▉      | 3927/10033 [00:19<00:46, 131.17 examples/s]Tokenizing train dataset:  37%|███▋      | 3690/10033 [00:18<00:44, 144.01 examples/s]Tokenizing train dataset:  40%|███▉      | 3978/10033 [00:19<00:41, 147.09 examples/s]Tokenizing train dataset:  40%|███▉      | 3964/10033 [00:19<00:40, 151.01 examples/s]Tokenizing train dataset:  37%|███▋      | 3727/10033 [00:18<00:35, 176.67 examples/s]Tokenizing train dataset:  40%|███▉      | 4010/10033 [00:19<00:34, 175.68 examples/s]Tokenizing train dataset:  40%|███▉      | 3989/10033 [00:19<00:36, 165.60 examples/s]Tokenizing train dataset:  38%|███▊      | 3765/10033 [00:19<00:39, 158.88 examples/s]Tokenizing train dataset:  40%|████      | 4051/10033 [00:19<00:41, 143.45 examples/s]Tokenizing train dataset:  40%|████      | 4032/10033 [00:19<00:43, 136.50 examples/s]Tokenizing train dataset:  38%|███▊      | 3803/10033 [00:19<00:41, 150.90 examples/s]Tokenizing train dataset:  41%|████      | 4087/10033 [00:20<00:38, 153.75 examples/s]Tokenizing train dataset:  41%|████      | 4067/10033 [00:19<00:35, 165.91 examples/s]Tokenizing train dataset:  38%|███▊      | 3830/10033 [00:19<00:36, 168.00 examples/s]Tokenizing train dataset:  41%|████      | 4120/10033 [00:20<00:32, 181.28 examples/s]Tokenizing train dataset:  41%|████      | 4103/10033 [00:20<00:32, 181.75 examples/s]Tokenizing train dataset:  39%|███▊      | 3865/10033 [00:19<00:33, 183.00 examples/s]Tokenizing train dataset:  41%|████▏     | 4154/10033 [00:20<00:31, 185.63 examples/s]Tokenizing train dataset:  41%|████      | 4132/10033 [00:20<00:29, 200.00 examples/s]Tokenizing train dataset:  42%|████▏     | 4185/10033 [00:20<00:28, 207.95 examples/s]Tokenizing train dataset:  41%|████▏     | 4161/10033 [00:20<00:27, 217.33 examples/s]Tokenizing train dataset:  39%|███▉      | 3901/10033 [00:19<00:31, 195.64 examples/s]Tokenizing train dataset:  42%|████▏     | 4218/10033 [00:20<00:24, 233.47 examples/s]Tokenizing train dataset:  42%|████▏     | 4207/10033 [00:20<00:23, 243.37 examples/s]Tokenizing train dataset:  39%|███▉      | 3940/10033 [00:20<00:28, 210.24 examples/s]Tokenizing train dataset:  40%|███▉      | 3964/10033 [00:20<00:28, 214.37 examples/s]Tokenizing train dataset:  42%|████▏     | 4253/10033 [00:20<00:26, 215.54 examples/s]Tokenizing train dataset:  42%|████▏     | 4247/10033 [00:20<00:23, 248.32 examples/s]Tokenizing train dataset:  40%|███▉      | 3992/10033 [00:20<00:26, 228.42 examples/s]Tokenizing train dataset:  43%|████▎     | 4286/10033 [00:20<00:24, 238.23 examples/s]Tokenizing train dataset:  43%|████▎     | 4281/10033 [00:20<00:21, 266.29 examples/s]Tokenizing train dataset:  40%|████      | 4031/10033 [00:20<00:25, 231.35 examples/s]Tokenizing train dataset:  43%|████▎     | 4324/10033 [00:21<00:24, 229.10 examples/s]Tokenizing train dataset:  43%|████▎     | 4318/10033 [00:20<00:23, 245.23 examples/s]Tokenizing train dataset:  41%|████      | 4070/10033 [00:20<00:25, 237.64 examples/s]Tokenizing train dataset:  43%|████▎     | 4361/10033 [00:21<00:27, 206.77 examples/s]Tokenizing train dataset:  43%|████▎     | 4355/10033 [00:21<00:29, 191.48 examples/s]Tokenizing train dataset:  41%|████      | 4105/10033 [00:20<00:29, 203.33 examples/s]Tokenizing train dataset:  44%|████▍     | 4404/10033 [00:21<00:26, 213.54 examples/s]Tokenizing train dataset:  44%|████▎     | 4380/10033 [00:21<00:28, 201.12 examples/s]Tokenizing train dataset:  44%|████▍     | 4403/10033 [00:21<00:27, 205.58 examples/s]Tokenizing train dataset:  41%|████▏     | 4140/10033 [00:21<00:28, 204.99 examples/s]Tokenizing train dataset:  44%|████▍     | 4444/10033 [00:21<00:24, 225.46 examples/s]Tokenizing train dataset:  44%|████▍     | 4442/10033 [00:21<00:26, 213.43 examples/s]Tokenizing train dataset:  42%|████▏     | 4175/10033 [00:21<00:29, 200.06 examples/s]Tokenizing train dataset:  45%|████▍     | 4482/10033 [00:21<00:24, 227.81 examples/s]Tokenizing train dataset:  45%|████▍     | 4465/10033 [00:21<00:25, 215.64 examples/s]Tokenizing train dataset:  42%|████▏     | 4200/10033 [00:21<00:27, 209.52 examples/s]Tokenizing train dataset:  45%|████▌     | 4518/10033 [00:22<00:25, 212.15 examples/s]Tokenizing train dataset:  45%|████▍     | 4502/10033 [00:21<00:25, 220.10 examples/s]Tokenizing train dataset:  42%|████▏     | 4234/10033 [00:21<00:31, 184.51 examples/s]Tokenizing train dataset:  45%|████▌     | 4557/10033 [00:22<00:29, 185.07 examples/s]Tokenizing train dataset:  45%|████▌     | 4541/10033 [00:22<00:30, 177.52 examples/s]Tokenizing train dataset:  43%|████▎     | 4268/10033 [00:21<00:38, 149.40 examples/s]Tokenizing train dataset:  45%|████▌     | 4562/10033 [00:22<00:30, 176.88 examples/s]Tokenizing train dataset:  46%|████▌     | 4590/10033 [00:22<00:29, 182.31 examples/s]Tokenizing train dataset:  43%|████▎     | 4290/10033 [00:22<00:36, 159.28 examples/s]Tokenizing train dataset:  46%|████▌     | 4610/10033 [00:22<00:30, 175.19 examples/s]Tokenizing train dataset:  46%|████▌     | 4598/10033 [00:22<00:29, 184.17 examples/s]Tokenizing train dataset:  43%|████▎     | 4318/10033 [00:22<00:31, 180.85 examples/s]Tokenizing train dataset:  46%|████▌     | 4640/10033 [00:22<00:27, 197.63 examples/s]Tokenizing train dataset:  46%|████▌     | 4626/10033 [00:22<00:26, 202.30 examples/s]Tokenizing train dataset:  43%|████▎     | 4345/10033 [00:22<00:28, 197.46 examples/s]Tokenizing train dataset:  47%|████▋     | 4673/10033 [00:22<00:29, 182.34 examples/s]Tokenizing train dataset:  46%|████▋     | 4658/10033 [00:22<00:28, 187.50 examples/s]Tokenizing train dataset:  44%|████▎     | 4383/10033 [00:22<00:27, 201.86 examples/s]Tokenizing train dataset:  47%|████▋     | 4706/10033 [00:23<00:30, 175.22 examples/s]Tokenizing train dataset:  47%|████▋     | 4691/10033 [00:22<00:29, 183.28 examples/s]Tokenizing train dataset:  44%|████▍     | 4420/10033 [00:22<00:31, 180.66 examples/s]Tokenizing train dataset:  47%|████▋     | 4737/10033 [00:23<00:26, 198.84 examples/s]Tokenizing train dataset:  47%|████▋     | 4712/10033 [00:23<00:28, 187.40 examples/s]Tokenizing train dataset:  44%|████▍     | 4456/10033 [00:22<00:31, 175.02 examples/s]Tokenizing train dataset:  48%|████▊     | 4767/10033 [00:23<00:29, 177.99 examples/s]Tokenizing train dataset:  47%|████▋     | 4748/10033 [00:23<00:30, 173.88 examples/s]Tokenizing train dataset:  45%|████▍     | 4484/10033 [00:22<00:28, 192.72 examples/s]Tokenizing train dataset:  48%|████▊     | 4796/10033 [00:23<00:26, 198.34 examples/s]Tokenizing train dataset:  48%|████▊     | 4779/10033 [00:23<00:46, 112.86 examples/s]Tokenizing train dataset:  45%|████▌     | 4516/10033 [00:23<00:46, 118.56 examples/s]Tokenizing train dataset:  48%|████▊     | 4829/10033 [00:24<00:44, 117.28 examples/s]Tokenizing train dataset:  48%|████▊     | 4800/10033 [00:23<00:43, 121.16 examples/s]Tokenizing train dataset:  45%|████▌     | 4542/10033 [00:23<00:39, 137.54 examples/s]Tokenizing train dataset:  48%|████▊     | 4863/10033 [00:24<00:37, 136.81 examples/s]Tokenizing train dataset:  48%|████▊     | 4834/10033 [00:24<00:36, 141.90 examples/s]Tokenizing train dataset:  45%|████▌     | 4562/10033 [00:23<00:39, 136.99 examples/s]Tokenizing train dataset:  49%|████▉     | 4894/10033 [00:24<00:32, 159.10 examples/s]Tokenizing train dataset:  48%|████▊     | 4865/10033 [00:24<00:31, 166.67 examples/s]Tokenizing train dataset:  46%|████▌     | 4594/10033 [00:23<00:36, 149.49 examples/s]Tokenizing train dataset:  49%|████▉     | 4931/10033 [00:24<00:27, 185.94 examples/s]Tokenizing train dataset:  49%|████▉     | 4895/10033 [00:24<00:27, 185.71 examples/s]Tokenizing train dataset:  46%|████▌     | 4613/10033 [00:24<00:37, 145.15 examples/s]Tokenizing train dataset:  49%|████▉     | 4962/10033 [00:24<00:30, 167.11 examples/s]Tokenizing train dataset:  49%|████▉     | 4931/10033 [00:24<00:32, 155.08 examples/s]Tokenizing train dataset:  46%|████▌     | 4631/10033 [00:24<00:44, 121.23 examples/s]Tokenizing train dataset:  50%|████▉     | 4993/10033 [00:24<00:27, 182.76 examples/s]Tokenizing train dataset:  49%|████▉     | 4962/10033 [00:24<00:28, 177.12 examples/s]Tokenizing train dataset:  46%|████▋     | 4646/10033 [00:24<00:47, 113.41 examples/s]Tokenizing train dataset:  50%|█████     | 5025/10033 [00:25<00:27, 185.11 examples/s]Tokenizing train dataset:  50%|████▉     | 4993/10033 [00:24<00:25, 194.38 examples/s]Tokenizing train dataset:  47%|████▋     | 4667/10033 [00:24<00:40, 131.18 examples/s]Tokenizing train dataset:  51%|█████     | 5080/10033 [00:25<00:19, 254.82 examples/s]Tokenizing train dataset:  50%|█████     | 5033/10033 [00:24<00:21, 235.22 examples/s]Tokenizing train dataset:  47%|████▋     | 4686/10033 [00:24<00:37, 142.93 examples/s]Tokenizing train dataset:  51%|█████     | 5111/10033 [00:25<00:19, 248.54 examples/s]Tokenizing train dataset:  51%|█████     | 5075/10033 [00:25<00:20, 243.17 examples/s]Tokenizing train dataset:  51%|█████▏    | 5160/10033 [00:25<00:16, 301.84 examples/s]Tokenizing train dataset:  47%|████▋     | 4717/10033 [00:24<00:34, 154.92 examples/s]Tokenizing train dataset:  51%|█████     | 5112/10033 [00:25<00:18, 270.02 examples/s]Tokenizing train dataset:  52%|█████▏    | 5223/10033 [00:25<00:12, 379.26 examples/s]Tokenizing train dataset:  47%|████▋     | 4736/10033 [00:24<00:33, 160.43 examples/s]Tokenizing train dataset:  51%|█████▏    | 5148/10033 [00:25<00:17, 279.83 examples/s]Tokenizing train dataset:  53%|█████▎    | 5286/10033 [00:25<00:10, 442.13 examples/s]Tokenizing train dataset:  47%|████▋     | 4754/10033 [00:25<00:32, 163.47 examples/s]Tokenizing train dataset:  52%|█████▏    | 5186/10033 [00:25<00:16, 298.92 examples/s]Tokenizing train dataset:  48%|████▊     | 4778/10033 [00:25<00:28, 181.34 examples/s]Tokenizing train dataset:  53%|█████▎    | 5352/10033 [00:25<00:10, 437.86 examples/s]Tokenizing train dataset:  52%|█████▏    | 5248/10033 [00:25<00:12, 380.56 examples/s]Tokenizing train dataset:  48%|████▊     | 4821/10033 [00:25<00:21, 244.55 examples/s]Tokenizing train dataset:  53%|█████▎    | 5308/10033 [00:25<00:10, 438.60 examples/s]Tokenizing train dataset:  54%|█████▍    | 5436/10033 [00:25<00:09, 473.44 examples/s]Tokenizing train dataset:  48%|████▊     | 4865/10033 [00:25<00:17, 295.79 examples/s]Tokenizing train dataset:  53%|█████▎    | 5359/10033 [00:25<00:10, 455.11 examples/s]Tokenizing train dataset:  55%|█████▍    | 5501/10033 [00:26<00:09, 455.88 examples/s]Tokenizing train dataset:  49%|████▉     | 4928/10033 [00:25<00:16, 314.91 examples/s]Tokenizing train dataset:  54%|█████▍    | 5417/10033 [00:25<00:11, 415.27 examples/s]Tokenizing train dataset:  56%|█████▌    | 5570/10033 [00:26<00:09, 455.66 examples/s]Tokenizing train dataset:  49%|████▉     | 4964/10033 [00:25<00:15, 324.62 examples/s]Tokenizing train dataset:  55%|█████▍    | 5483/10033 [00:26<00:11, 409.67 examples/s]Tokenizing train dataset:  56%|█████▌    | 5620/10033 [00:26<00:09, 463.64 examples/s]Tokenizing train dataset:  50%|█████     | 5024/10033 [00:25<00:15, 332.81 examples/s]Tokenizing train dataset:  55%|█████▌    | 5547/10033 [00:26<00:11, 404.32 examples/s]Tokenizing train dataset:  57%|█████▋    | 5689/10033 [00:26<00:09, 436.10 examples/s]Tokenizing train dataset:  51%|█████     | 5072/10033 [00:25<00:13, 366.78 examples/s]Tokenizing train dataset:  56%|█████▌    | 5591/10033 [00:26<00:10, 411.35 examples/s]Tokenizing train dataset:  57%|█████▋    | 5743/10033 [00:26<00:09, 456.47 examples/s]Tokenizing train dataset:  51%|█████     | 5136/10033 [00:26<00:15, 319.25 examples/s]Tokenizing train dataset:  56%|█████▋    | 5661/10033 [00:26<00:11, 381.30 examples/s]Tokenizing train dataset:  58%|█████▊    | 5824/10033 [00:26<00:10, 410.53 examples/s]Tokenizing train dataset:  52%|█████▏    | 5172/10033 [00:26<00:16, 299.92 examples/s]Tokenizing train dataset:  57%|█████▋    | 5726/10033 [00:26<00:11, 377.84 examples/s]Tokenizing train dataset:  59%|█████▊    | 5889/10033 [00:26<00:09, 414.69 examples/s]Tokenizing train dataset:  52%|█████▏    | 5204/10033 [00:26<00:16, 300.05 examples/s]Tokenizing train dataset:  58%|█████▊    | 5803/10033 [00:26<00:10, 411.67 examples/s]Tokenizing train dataset:  52%|█████▏    | 5237/10033 [00:26<00:19, 248.05 examples/s]Tokenizing train dataset:  59%|█████▉    | 5957/10033 [00:27<00:11, 370.11 examples/s]Tokenizing train dataset:  58%|█████▊    | 5863/10033 [00:27<00:10, 385.07 examples/s]Tokenizing train dataset:  53%|█████▎    | 5291/10033 [00:26<00:15, 308.42 examples/s]Tokenizing train dataset:  60%|█████▉    | 6014/10033 [00:27<00:12, 315.89 examples/s]Tokenizing train dataset:  59%|█████▉    | 5928/10033 [00:27<00:12, 319.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 5351/10033 [00:26<00:17, 261.74 examples/s]Tokenizing train dataset:  61%|██████    | 6078/10033 [00:27<00:11, 340.73 examples/s]Tokenizing train dataset:  60%|█████▉    | 5975/10033 [00:27<00:11, 344.77 examples/s]Tokenizing train dataset:  54%|█████▍    | 5401/10033 [00:27<00:16, 276.97 examples/s]Tokenizing train dataset:  60%|█████▉    | 6019/10033 [00:27<00:11, 360.09 examples/s]Tokenizing train dataset:  61%|██████    | 6141/10033 [00:27<00:11, 352.57 examples/s]Tokenizing train dataset:  54%|█████▍    | 5441/10033 [00:27<00:15, 298.41 examples/s]Tokenizing train dataset:  62%|██████▏   | 6180/10033 [00:27<00:11, 333.55 examples/s]Tokenizing train dataset:  61%|██████    | 6085/10033 [00:27<00:10, 380.39 examples/s]Tokenizing train dataset:  55%|█████▍    | 5498/10033 [00:27<00:14, 321.83 examples/s]Tokenizing train dataset:  62%|██████▏   | 6220/10033 [00:28<00:11, 338.62 examples/s]Tokenizing train dataset:  55%|█████▌    | 5537/10033 [00:27<00:13, 334.49 examples/s]Tokenizing train dataset:  61%|██████▏   | 6156/10033 [00:27<00:09, 388.86 examples/s]Tokenizing train dataset:  62%|██████▏   | 6260/10033 [00:28<00:10, 350.37 examples/s]Tokenizing train dataset:  56%|█████▌    | 5579/10033 [00:27<00:12, 352.05 examples/s]Tokenizing train dataset:  62%|██████▏   | 6234/10033 [00:28<00:09, 393.86 examples/s]Tokenizing train dataset:  63%|██████▎   | 6322/10033 [00:28<00:11, 309.77 examples/s]Tokenizing train dataset:  56%|█████▋    | 5648/10033 [00:27<00:13, 318.70 examples/s]Tokenizing train dataset:  63%|██████▎   | 6360/10033 [00:28<00:11, 307.37 examples/s]Tokenizing train dataset:  63%|██████▎   | 6299/10033 [00:28<00:10, 369.69 examples/s]Tokenizing train dataset:  57%|█████▋    | 5686/10033 [00:27<00:13, 330.78 examples/s]Tokenizing train dataset:  64%|██████▎   | 6394/10033 [00:29<00:24, 150.00 examples/s]Tokenizing train dataset:  64%|██████▎   | 6375/10033 [00:28<00:17, 209.76 examples/s]Tokenizing train dataset:  57%|█████▋    | 5748/10033 [00:28<00:26, 162.48 examples/s]Tokenizing train dataset:  64%|██████▍   | 6424/10033 [00:29<00:24, 146.97 examples/s]Tokenizing train dataset:  64%|██████▍   | 6407/10033 [00:29<00:18, 201.22 examples/s]Tokenizing train dataset:  58%|█████▊    | 5789/10033 [00:28<00:22, 188.81 examples/s]Tokenizing train dataset:  64%|██████▍   | 6457/10033 [00:29<00:21, 162.69 examples/s]Tokenizing train dataset:  64%|██████▍   | 6438/10033 [00:29<00:17, 206.50 examples/s]Tokenizing train dataset:  58%|█████▊    | 5826/10033 [00:28<00:21, 199.27 examples/s]Tokenizing train dataset:  65%|██████▍   | 6487/10033 [00:29<00:19, 181.07 examples/s]Tokenizing train dataset:  64%|██████▍   | 6469/10033 [00:29<00:16, 219.45 examples/s]Tokenizing train dataset:  58%|█████▊    | 5859/10033 [00:29<00:19, 219.60 examples/s]Tokenizing train dataset:  65%|██████▌   | 6543/10033 [00:29<00:14, 248.90 examples/s]Tokenizing train dataset:  65%|██████▌   | 6526/10033 [00:29<00:12, 279.51 examples/s]Tokenizing train dataset:  59%|█████▊    | 5892/10033 [00:29<00:17, 236.77 examples/s]Tokenizing train dataset:  66%|██████▌   | 6590/10033 [00:29<00:11, 288.26 examples/s]Tokenizing train dataset:  59%|█████▉    | 5927/10033 [00:29<00:17, 237.83 examples/s]Tokenizing train dataset:  66%|██████▌   | 6582/10033 [00:29<00:12, 272.93 examples/s]Tokenizing train dataset:  59%|█████▉    | 5961/10033 [00:29<00:16, 252.07 examples/s]Tokenizing train dataset:  66%|██████▌   | 6646/10033 [00:30<00:12, 271.45 examples/s]Tokenizing train dataset:  66%|██████▌   | 6634/10033 [00:29<00:11, 284.90 examples/s]Tokenizing train dataset:  67%|██████▋   | 6709/10033 [00:30<00:09, 340.87 examples/s]Tokenizing train dataset:  60%|█████▉    | 6012/10033 [00:29<00:13, 300.17 examples/s]Tokenizing train dataset:  66%|██████▋   | 6668/10033 [00:30<00:12, 268.42 examples/s]Tokenizing train dataset:  67%|██████▋   | 6707/10033 [00:30<00:13, 254.05 examples/s]Tokenizing train dataset:  68%|██████▊   | 6774/10033 [00:30<00:11, 277.29 examples/s]Tokenizing train dataset:  61%|██████    | 6072/10033 [00:29<00:16, 241.19 examples/s]Tokenizing train dataset:  67%|██████▋   | 6766/10033 [00:30<00:10, 319.49 examples/s]Tokenizing train dataset:  68%|██████▊   | 6819/10033 [00:30<00:10, 304.37 examples/s]Tokenizing train dataset:  61%|██████    | 6125/10033 [00:30<00:16, 243.32 examples/s]Tokenizing train dataset:  68%|██████▊   | 6824/10033 [00:30<00:11, 291.36 examples/s]Tokenizing train dataset:  69%|██████▊   | 6883/10033 [00:30<00:14, 222.10 examples/s]Tokenizing train dataset:  61%|██████▏   | 6162/10033 [00:30<00:23, 166.59 examples/s]Tokenizing train dataset:  69%|██████▊   | 6886/10033 [00:31<00:16, 190.65 examples/s]Tokenizing train dataset:  69%|██████▉   | 6916/10033 [00:31<00:17, 179.34 examples/s]Tokenizing train dataset:  62%|██████▏   | 6199/10033 [00:30<00:23, 164.24 examples/s]Tokenizing train dataset:  69%|██████▉   | 6932/10033 [00:31<00:13, 225.23 examples/s]Tokenizing train dataset:  69%|██████▉   | 6950/10033 [00:31<00:15, 193.85 examples/s]Tokenizing train dataset:  62%|██████▏   | 6235/10033 [00:30<00:20, 188.41 examples/s]Tokenizing train dataset:  69%|██████▉   | 6966/10033 [00:31<00:12, 242.49 examples/s]Tokenizing train dataset:  70%|██████▉   | 6982/10033 [00:31<00:15, 194.31 examples/s]Tokenizing train dataset:  62%|██████▏   | 6269/10033 [00:31<00:19, 197.15 examples/s]Tokenizing train dataset:  70%|██████▉   | 7020/10033 [00:31<00:11, 257.28 examples/s]Tokenizing train dataset:  70%|██████▉   | 7010/10033 [00:31<00:14, 207.81 examples/s]Tokenizing train dataset:  63%|██████▎   | 6298/10033 [00:31<00:18, 206.16 examples/s]Tokenizing train dataset:  70%|███████   | 7070/10033 [00:31<00:09, 301.47 examples/s]Tokenizing train dataset:  70%|███████   | 7043/10033 [00:31<00:13, 229.06 examples/s]Tokenizing train dataset:  63%|██████▎   | 6340/10033 [00:31<00:14, 247.93 examples/s]Tokenizing train dataset:  71%|███████   | 7113/10033 [00:31<00:08, 326.58 examples/s]Tokenizing train dataset:  71%|███████   | 7089/10033 [00:31<00:10, 277.56 examples/s]Tokenizing train dataset:  64%|██████▎   | 6385/10033 [00:31<00:12, 292.11 examples/s]Tokenizing train dataset:  72%|███████▏  | 7182/10033 [00:31<00:07, 362.40 examples/s]Tokenizing train dataset:  71%|███████   | 7122/10033 [00:32<00:11, 258.88 examples/s]Tokenizing train dataset:  64%|██████▍   | 6448/10033 [00:31<00:11, 304.78 examples/s]Tokenizing train dataset:  71%|███████▏  | 7152/10033 [00:32<00:10, 262.10 examples/s]Tokenizing train dataset:  72%|███████▏  | 7241/10033 [00:31<00:07, 362.59 examples/s]Tokenizing train dataset:  65%|██████▍   | 6492/10033 [00:31<00:10, 329.72 examples/s]Tokenizing train dataset:  72%|███████▏  | 7220/10033 [00:32<00:07, 360.20 examples/s]Tokenizing train dataset:  73%|███████▎  | 7308/10033 [00:32<00:07, 385.40 examples/s]Tokenizing train dataset:  72%|███████▏  | 7262/10033 [00:32<00:07, 374.54 examples/s]Tokenizing train dataset:  65%|██████▌   | 6553/10033 [00:31<00:09, 352.39 examples/s]Tokenizing train dataset:  73%|███████▎  | 7361/10033 [00:32<00:06, 413.84 examples/s]Tokenizing train dataset:  73%|███████▎  | 7308/10033 [00:32<00:06, 396.86 examples/s]Tokenizing train dataset:  66%|██████▌   | 6602/10033 [00:32<00:11, 289.69 examples/s]Tokenizing train dataset:  74%|███████▍  | 7425/10033 [00:32<00:07, 335.69 examples/s]Tokenizing train dataset:  73%|███████▎  | 7373/10033 [00:32<00:08, 314.11 examples/s]Tokenizing train dataset:  66%|██████▋   | 6663/10033 [00:32<00:10, 319.82 examples/s]Tokenizing train dataset:  75%|███████▍  | 7479/10033 [00:32<00:06, 371.78 examples/s]Tokenizing train dataset:  74%|███████▍  | 7438/10033 [00:32<00:07, 332.34 examples/s]Tokenizing train dataset:  67%|██████▋   | 6701/10033 [00:32<00:12, 263.41 examples/s]Tokenizing train dataset:  75%|███████▌  | 7550/10033 [00:32<00:06, 354.72 examples/s]Tokenizing train dataset:  75%|███████▍  | 7504/10033 [00:33<00:07, 360.04 examples/s]Tokenizing train dataset:  67%|██████▋   | 6744/10033 [00:32<00:11, 294.28 examples/s]Tokenizing train dataset:  76%|███████▌  | 7622/10033 [00:33<00:06, 345.82 examples/s]Tokenizing train dataset:  76%|███████▌  | 7579/10033 [00:33<00:06, 352.72 examples/s]Tokenizing train dataset:  68%|██████▊   | 6806/10033 [00:32<00:11, 279.88 examples/s]Tokenizing train dataset:  76%|███████▋  | 7674/10033 [00:33<00:07, 305.09 examples/s]Tokenizing train dataset:  76%|███████▌  | 7641/10033 [00:33<00:07, 317.76 examples/s]Tokenizing train dataset:  68%|██████▊   | 6855/10033 [00:32<00:12, 257.40 examples/s]Tokenizing train dataset:  77%|███████▋  | 7708/10033 [00:33<00:14, 158.27 examples/s]Tokenizing train dataset:  77%|███████▋  | 7697/10033 [00:34<00:13, 177.75 examples/s]Tokenizing train dataset:  69%|██████▊   | 6890/10033 [00:33<00:23, 135.01 examples/s]Tokenizing train dataset:  77%|███████▋  | 7742/10033 [00:34<00:12, 177.89 examples/s]Tokenizing train dataset:  77%|███████▋  | 7746/10033 [00:34<00:10, 212.22 examples/s]Tokenizing train dataset:  69%|██████▉   | 6948/10033 [00:33<00:16, 184.41 examples/s]Tokenizing train dataset:  78%|███████▊  | 7781/10033 [00:34<00:10, 206.51 examples/s]Tokenizing train dataset:  78%|███████▊  | 7800/10033 [00:34<00:09, 229.67 examples/s]Tokenizing train dataset:  70%|██████▉   | 7000/10033 [00:33<00:14, 206.21 examples/s]Tokenizing train dataset:  78%|███████▊  | 7844/10033 [00:34<00:09, 237.42 examples/s]Tokenizing train dataset:  78%|███████▊  | 7854/10033 [00:34<00:07, 274.85 examples/s]Tokenizing train dataset:  70%|███████   | 7060/10033 [00:34<00:13, 219.87 examples/s]Tokenizing train dataset:  79%|███████▉  | 7906/10033 [00:34<00:09, 222.88 examples/s]Tokenizing train dataset:  71%|███████   | 7103/10033 [00:34<00:11, 250.99 examples/s]Tokenizing train dataset:  79%|███████▉  | 7916/10033 [00:34<00:08, 252.76 examples/s]Tokenizing train dataset:  79%|███████▉  | 7959/10033 [00:34<00:07, 268.76 examples/s]Tokenizing train dataset:  71%|███████▏  | 7166/10033 [00:34<00:10, 261.96 examples/s]Tokenizing train dataset:  80%|███████▉  | 7980/10033 [00:35<00:09, 228.02 examples/s]Tokenizing train dataset:  80%|███████▉  | 7995/10033 [00:35<00:09, 216.80 examples/s]Tokenizing train dataset:  72%|███████▏  | 7203/10033 [00:34<00:14, 190.96 examples/s]Tokenizing train dataset:  80%|███████▉  | 8016/10033 [00:35<00:10, 198.02 examples/s]Tokenizing train dataset:  80%|████████  | 8029/10033 [00:35<00:11, 167.59 examples/s]Tokenizing train dataset:  80%|████████  | 8047/10033 [00:35<00:10, 190.12 examples/s]Tokenizing train dataset:  72%|███████▏  | 7257/10033 [00:35<00:14, 196.18 examples/s]Tokenizing train dataset:  80%|████████  | 8063/10033 [00:35<00:11, 176.88 examples/s]Tokenizing train dataset:  81%|████████  | 8079/10033 [00:35<00:09, 198.98 examples/s]Tokenizing train dataset:  73%|███████▎  | 7290/10033 [00:35<00:13, 207.34 examples/s]Tokenizing train dataset:  81%|████████  | 8091/10033 [00:35<00:12, 160.80 examples/s]Tokenizing train dataset:  81%|████████  | 8107/10033 [00:36<00:10, 186.44 examples/s]Tokenizing train dataset:  73%|███████▎  | 7320/10033 [00:35<00:13, 194.34 examples/s]Tokenizing train dataset:  81%|████████  | 8120/10033 [00:35<00:10, 178.81 examples/s]Tokenizing train dataset:  81%|████████  | 8136/10033 [00:36<00:09, 204.18 examples/s]Tokenizing train dataset:  73%|███████▎  | 7354/10033 [00:35<00:12, 215.50 examples/s]Tokenizing train dataset:  81%|████████▏ | 8155/10033 [00:35<00:09, 206.46 examples/s]Tokenizing train dataset:  81%|████████▏ | 8172/10033 [00:36<00:09, 189.87 examples/s]Tokenizing train dataset:  74%|███████▎  | 7384/10033 [00:35<00:15, 168.86 examples/s]Tokenizing train dataset:  82%|████████▏ | 8190/10033 [00:36<00:13, 140.73 examples/s]Tokenizing train dataset:  82%|████████▏ | 8204/10033 [00:36<00:13, 133.53 examples/s]Tokenizing train dataset:  74%|███████▍  | 7416/10033 [00:36<00:18, 137.93 examples/s]Tokenizing train dataset:  82%|████████▏ | 8217/10033 [00:36<00:12, 145.09 examples/s]Tokenizing train dataset:  82%|████████▏ | 8240/10033 [00:36<00:11, 155.49 examples/s]Tokenizing train dataset:  74%|███████▍  | 7450/10033 [00:36<00:17, 149.56 examples/s]Tokenizing train dataset:  82%|████████▏ | 8253/10033 [00:36<00:11, 158.11 examples/s]Tokenizing train dataset:  83%|████████▎ | 8280/10033 [00:37<00:09, 175.34 examples/s]Tokenizing train dataset:  75%|███████▍  | 7479/10033 [00:36<00:16, 150.83 examples/s]Tokenizing train dataset:  83%|████████▎ | 8297/10033 [00:36<00:10, 170.68 examples/s]Tokenizing train dataset:  83%|████████▎ | 8318/10033 [00:37<00:09, 186.05 examples/s]Tokenizing train dataset:  75%|███████▍  | 7513/10033 [00:36<00:14, 169.78 examples/s]Tokenizing train dataset:  83%|████████▎ | 8330/10033 [00:37<00:09, 180.00 examples/s]Tokenizing train dataset:  83%|████████▎ | 8344/10033 [00:37<00:09, 176.12 examples/s]Tokenizing train dataset:  75%|███████▌  | 7548/10033 [00:36<00:15, 161.90 examples/s]Tokenizing train dataset:  83%|████████▎ | 8355/10033 [00:37<00:11, 148.94 examples/s]Tokenizing train dataset:  83%|████████▎ | 8373/10033 [00:37<00:10, 159.00 examples/s]Tokenizing train dataset:  76%|███████▌  | 7585/10033 [00:37<00:13, 187.26 examples/s]Tokenizing train dataset:  84%|████████▎ | 8388/10033 [00:37<00:09, 168.23 examples/s]Tokenizing train dataset:  84%|████████▍ | 8404/10033 [00:37<00:10, 154.11 examples/s]Tokenizing train dataset:  76%|███████▌  | 7617/10033 [00:37<00:14, 169.92 examples/s]Tokenizing train dataset:  84%|████████▍ | 8420/10033 [00:37<00:10, 154.46 examples/s]Tokenizing train dataset:  84%|████████▍ | 8434/10033 [00:38<00:09, 161.62 examples/s]Tokenizing train dataset:  76%|███████▌  | 7643/10033 [00:37<00:15, 158.10 examples/s]Tokenizing train dataset:  84%|████████▍ | 8449/10033 [00:37<00:09, 175.68 examples/s]Tokenizing train dataset:  84%|████████▍ | 8465/10033 [00:38<00:09, 167.98 examples/s]Tokenizing train dataset:  76%|███████▋  | 7670/10033 [00:37<00:14, 163.38 examples/s]Tokenizing train dataset:  85%|████████▍ | 8485/10033 [00:38<00:07, 199.61 examples/s]Tokenizing train dataset:  85%|████████▍ | 8519/10033 [00:38<00:06, 236.59 examples/s]Tokenizing train dataset:  77%|███████▋  | 7701/10033 [00:37<00:13, 174.83 examples/s]Tokenizing train dataset:  85%|████████▍ | 8517/10033 [00:38<00:07, 200.91 examples/s]Tokenizing train dataset:  85%|████████▌ | 8548/10033 [00:38<00:06, 234.76 examples/s]Tokenizing train dataset:  77%|███████▋  | 7743/10033 [00:37<00:10, 222.82 examples/s]Tokenizing train dataset:  85%|████████▌ | 8546/10033 [00:38<00:07, 195.98 examples/s]Tokenizing train dataset:  86%|████████▌ | 8601/10033 [00:38<00:09, 158.16 examples/s]Tokenizing train dataset:  77%|███████▋  | 7769/10033 [00:38<00:17, 126.46 examples/s]Tokenizing train dataset:  86%|████████▌ | 8600/10033 [00:38<00:09, 146.20 examples/s]Tokenizing train dataset:  86%|████████▋ | 8667/10033 [00:39<00:06, 215.22 examples/s]Tokenizing train dataset:  78%|███████▊  | 7795/10033 [00:38<00:15, 142.64 examples/s]Tokenizing train dataset:  86%|████████▋ | 8667/10033 [00:38<00:06, 212.60 examples/s]Tokenizing train dataset:  87%|████████▋ | 8732/10033 [00:39<00:04, 269.26 examples/s]Tokenizing train dataset:  78%|███████▊  | 7825/10033 [00:38<00:13, 158.63 examples/s]Tokenizing train dataset:  87%|████████▋ | 8732/10033 [00:39<00:04, 282.97 examples/s]Tokenizing train dataset:  88%|████████▊ | 8818/10033 [00:39<00:03, 374.06 examples/s]Tokenizing train dataset:  78%|███████▊  | 7859/10033 [00:38<00:11, 181.46 examples/s]Tokenizing train dataset:  88%|████████▊ | 8830/10033 [00:39<00:02, 413.69 examples/s]Tokenizing train dataset:  89%|████████▉ | 8923/10033 [00:39<00:02, 509.62 examples/s]Tokenizing train dataset:  79%|███████▉  | 7913/10033 [00:38<00:08, 252.85 examples/s]Tokenizing train dataset:  89%|████████▊ | 8900/10033 [00:39<00:02, 473.23 examples/s]Tokenizing train dataset:  90%|████████▉ | 9001/10033 [00:39<00:01, 568.99 examples/s]Tokenizing train dataset:  79%|███████▉  | 7963/10033 [00:38<00:06, 306.15 examples/s]Tokenizing train dataset:  89%|████████▉ | 8965/10033 [00:39<00:02, 463.81 examples/s]Tokenizing train dataset:  91%|█████████ | 9130/10033 [00:39<00:01, 539.06 examples/s]Tokenizing train dataset:  80%|████████  | 8029/10033 [00:39<00:07, 268.30 examples/s]Tokenizing train dataset:  90%|████████▉ | 9028/10033 [00:39<00:02, 389.98 examples/s]Tokenizing train dataset:  92%|█████████▏| 9197/10033 [00:39<00:01, 538.04 examples/s]Tokenizing train dataset:  81%|████████  | 8079/10033 [00:39<00:06, 311.61 examples/s]Tokenizing train dataset:  91%|█████████ | 9092/10033 [00:39<00:02, 419.07 examples/s]Tokenizing train dataset:  92%|█████████▏| 9262/10033 [00:40<00:01, 505.74 examples/s]Tokenizing train dataset:  81%|████████  | 8131/10033 [00:39<00:08, 236.62 examples/s]Tokenizing train dataset:  91%|█████████▏| 9161/10033 [00:40<00:02, 321.04 examples/s]Tokenizing train dataset:  93%|█████████▎| 9327/10033 [00:40<00:01, 378.06 examples/s]Tokenizing train dataset:  81%|████████▏ | 8165/10033 [00:39<00:07, 235.25 examples/s]Tokenizing train dataset:  92%|█████████▏| 9227/10033 [00:40<00:02, 321.16 examples/s]Tokenizing train dataset:  94%|█████████▎| 9390/10033 [00:40<00:01, 357.05 examples/s]Tokenizing train dataset:  82%|████████▏ | 8199/10033 [00:39<00:07, 244.23 examples/s]Tokenizing train dataset:  93%|█████████▎| 9291/10033 [00:40<00:02, 347.40 examples/s]Tokenizing train dataset:  94%|█████████▍| 9452/10033 [00:40<00:01, 325.95 examples/s]Tokenizing train dataset:  82%|████████▏ | 8264/10033 [00:40<00:07, 226.96 examples/s]Tokenizing train dataset:  93%|█████████▎| 9357/10033 [00:40<00:02, 310.36 examples/s]Tokenizing train dataset:  95%|█████████▍| 9517/10033 [00:40<00:01, 340.43 examples/s]Tokenizing train dataset:  83%|████████▎ | 8305/10033 [00:40<00:07, 233.36 examples/s]Tokenizing train dataset:  94%|█████████▍| 9419/10033 [00:40<00:02, 301.03 examples/s]Tokenizing train dataset:  95%|█████████▌| 9578/10033 [00:41<00:01, 315.55 examples/s]Tokenizing train dataset:  83%|████████▎ | 8332/10033 [00:40<00:08, 196.76 examples/s]Tokenizing train dataset:  95%|█████████▍| 9482/10033 [00:41<00:01, 341.37 examples/s]Tokenizing train dataset:  96%|█████████▌| 9640/10033 [00:41<00:01, 345.08 examples/s]Tokenizing train dataset:  83%|████████▎ | 8357/10033 [00:40<00:08, 205.43 examples/s]Tokenizing train dataset:  95%|█████████▌| 9547/10033 [00:41<00:01, 389.67 examples/s]Tokenizing train dataset:  97%|█████████▋| 9710/10033 [00:41<00:00, 410.31 examples/s]Tokenizing train dataset:  84%|████████▎ | 8395/10033 [00:40<00:06, 238.92 examples/s]Tokenizing train dataset:  96%|█████████▌| 9644/10033 [00:41<00:00, 508.51 examples/s]Tokenizing train dataset:  97%|█████████▋| 9769/10033 [00:41<00:00, 412.92 examples/s]Tokenizing train dataset:  84%|████████▍ | 8429/10033 [00:41<00:07, 222.85 examples/s]Tokenizing train dataset:  97%|█████████▋| 9704/10033 [00:41<00:00, 450.34 examples/s]Tokenizing train dataset:  98%|█████████▊| 9834/10033 [00:41<00:00, 442.59 examples/s]Tokenizing train dataset:  85%|████████▍ | 8479/10033 [00:41<00:05, 280.75 examples/s]Tokenizing train dataset:  97%|█████████▋| 9769/10033 [00:41<00:00, 492.46 examples/s]Tokenizing train dataset:  99%|█████████▉| 9911/10033 [00:41<00:00, 516.00 examples/s]Tokenizing train dataset:  98%|█████████▊| 9838/10033 [00:41<00:00, 538.05 examples/s]Tokenizing train dataset:  99%|█████████▉| 9971/10033 [00:41<00:00, 533.11 examples/s]Tokenizing train dataset:  85%|████████▌ | 8537/10033 [00:41<00:05, 299.06 examples/s]Tokenizing train dataset:  99%|█████████▊| 9898/10033 [00:41<00:00, 506.47 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:42<00:00, 331.74 examples/s]Tokenizing train dataset:  85%|████████▌ | 8578/10033 [00:41<00:07, 207.73 examples/s]Tokenizing train dataset:  99%|█████████▉| 9959/10033 [00:42<00:00, 370.94 examples/s]Tokenizing train dataset:  86%|████████▌ | 8642/10033 [00:42<00:06, 200.41 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:42<00:00, 235.25 examples/s]
Tokenizing train dataset: 100%|█████████▉| 10023/10033 [00:42<00:00, 269.91 examples/s]Tokenizing train dataset:  87%|████████▋ | 8706/10033 [00:42<00:05, 232.89 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:42<00:00, 233.54 examples/s]Tokenizing train dataset:  87%|████████▋ | 8772/10033 [00:42<00:06, 196.81 examples/s]
Tokenizing train dataset:  88%|████████▊ | 8836/10033 [00:42<00:05, 225.57 examples/s]Tokenizing train dataset:  89%|████████▊ | 8898/10033 [00:42<00:04, 278.55 examples/s]Tokenizing train dataset:  89%|████████▉ | 8960/10033 [00:43<00:05, 205.60 examples/s]Tokenizing train dataset:  90%|████████▉ | 9021/10033 [00:43<00:04, 252.95 examples/s]Tokenizing train dataset:  91%|█████████ | 9083/10033 [00:43<00:03, 308.18 examples/s]Tokenizing train dataset:  92%|█████████▏| 9197/10033 [00:43<00:01, 455.39 examples/s]Tokenizing train dataset:  92%|█████████▏| 9268/10033 [00:43<00:01, 506.33 examples/s]Tokenizing train dataset:  93%|█████████▎| 9379/10033 [00:43<00:01, 639.93 examples/s]Tokenizing train dataset:  95%|█████████▍| 9503/10033 [00:44<00:00, 684.37 examples/s]Tokenizing train dataset:  96%|█████████▌| 9622/10033 [00:44<00:00, 702.39 examples/s]Tokenizing train dataset:  97%|█████████▋| 9729/10033 [00:44<00:00, 783.39 examples/s]Tokenizing train dataset:  98%|█████████▊| 9858/10033 [00:44<00:00, 806.42 examples/s]Tokenizing train dataset:  99%|█████████▉| 9973/10033 [00:44<00:00, 740.03 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:44<00:00, 223.89 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5424.90 examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5428.22 examples/s]Extracting prompt in eval dataset:  56%|█████▌    | 530/953 [00:00<00:00, 5225.69 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1518.26 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1479.50 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1215.39 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  33%|███▎      | 311/953 [00:00<00:00, 3083.84 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  71%|███████▏  | 681/953 [00:00<00:00, 2656.72 examples/s]Applying chat template to eval dataset:  32%|███▏      | 301/953 [00:00<00:00, 2975.55 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2139.12 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2201.97 examples/s]
Applying chat template to eval dataset:  65%|██████▌   | 620/953 [00:00<00:00, 2038.05 examples/s]Applying chat template to eval dataset:  31%|███       | 294/953 [00:00<00:00, 2904.01 examples/s]Applying chat template to eval dataset:  96%|█████████▋| 919/953 [00:00<00:00, 2370.53 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2147.34 examples/s]
Applying chat template to eval dataset:  67%|██████▋   | 636/953 [00:00<00:00, 2473.52 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2347.79 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2210.08 examples/s]
Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 324.45 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:04, 192.31 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 320.65 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:04, 173.36 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:05, 171.54 examples/s]Tokenizing eval dataset:  14%|█▍        | 137/953 [00:00<00:05, 153.02 examples/s]Tokenizing eval dataset:   3%|▎         | 32/953 [00:00<00:03, 294.25 examples/s]Tokenizing eval dataset:  12%|█▏        | 113/953 [00:00<00:04, 184.76 examples/s]Tokenizing eval dataset:  17%|█▋        | 164/953 [00:00<00:05, 156.98 examples/s]Tokenizing eval dataset:   7%|▋         | 68/953 [00:00<00:03, 247.24 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:00<00:04, 181.51 examples/s]Tokenizing eval dataset:  20%|█▉        | 188/953 [00:01<00:04, 156.00 examples/s]Tokenizing eval dataset:  10%|█         | 97/953 [00:00<00:05, 163.42 examples/s]Tokenizing eval dataset:  17%|█▋        | 166/953 [00:01<00:06, 122.94 examples/s]Tokenizing eval dataset:  23%|██▎       | 219/953 [00:01<00:05, 127.63 examples/s]Tokenizing eval dataset:  13%|█▎        | 124/953 [00:00<00:05, 148.03 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:01<00:06, 120.64 examples/s]Tokenizing eval dataset:  27%|██▋       | 253/953 [00:01<00:04, 144.63 examples/s]Tokenizing eval dataset:  22%|██▏       | 207/953 [00:01<00:06, 122.32 examples/s]Tokenizing eval dataset:  30%|███       | 290/953 [00:01<00:03, 172.93 examples/s]Tokenizing eval dataset:  16%|█▌        | 152/953 [00:01<00:06, 124.02 examples/s]Tokenizing eval dataset:  25%|██▍       | 236/953 [00:01<00:04, 153.24 examples/s]Tokenizing eval dataset:  34%|███▍      | 324/953 [00:01<00:03, 195.85 examples/s]Tokenizing eval dataset:  17%|█▋        | 166/953 [00:01<00:06, 121.00 examples/s]Tokenizing eval dataset:  28%|██▊       | 268/953 [00:01<00:03, 182.87 examples/s]Tokenizing eval dataset:  38%|███▊      | 358/953 [00:02<00:03, 177.93 examples/s]Tokenizing eval dataset:  32%|███▏      | 303/953 [00:01<00:03, 187.83 examples/s]Tokenizing eval dataset:  20%|█▉        | 190/953 [00:01<00:07, 107.80 examples/s]Tokenizing eval dataset:  41%|████      | 388/953 [00:02<00:02, 196.43 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:02<00:03, 196.54 examples/s]Tokenizing eval dataset:  22%|██▏       | 206/953 [00:01<00:07, 98.33 examples/s] Tokenizing eval dataset:  44%|████▍     | 422/953 [00:02<00:03, 163.04 examples/s]Tokenizing eval dataset:  39%|███▊      | 369/953 [00:02<00:03, 166.22 examples/s]Tokenizing eval dataset:  23%|██▎       | 223/953 [00:01<00:07, 94.19 examples/s]Tokenizing eval dataset:  49%|████▉     | 465/953 [00:02<00:02, 200.23 examples/s]Tokenizing eval dataset:  42%|████▏     | 404/953 [00:02<00:03, 173.03 examples/s]Tokenizing eval dataset:  27%|██▋       | 254/953 [00:02<00:06, 114.18 examples/s]Tokenizing eval dataset:  52%|█████▏    | 494/953 [00:02<00:02, 185.20 examples/s]Tokenizing eval dataset:  46%|████▌     | 440/953 [00:02<00:02, 207.61 examples/s]Tokenizing eval dataset:  32%|███▏      | 309/953 [00:02<00:03, 190.79 examples/s]Tokenizing eval dataset:  55%|█████▌    | 527/953 [00:02<00:02, 201.96 examples/s]Tokenizing eval dataset:  50%|████▉     | 474/953 [00:02<00:02, 213.08 examples/s]Tokenizing eval dataset:  36%|███▌      | 344/953 [00:02<00:02, 216.09 examples/s]Tokenizing eval dataset:  59%|█████▉    | 564/953 [00:03<00:01, 208.29 examples/s]Tokenizing eval dataset:  53%|█████▎    | 508/953 [00:02<00:02, 212.03 examples/s]Tokenizing eval dataset:  64%|██████▍   | 611/953 [00:03<00:01, 260.49 examples/s]Tokenizing eval dataset:  42%|████▏     | 400/953 [00:02<00:02, 223.84 examples/s]Tokenizing eval dataset:  58%|█████▊    | 557/953 [00:02<00:01, 270.38 examples/s]Tokenizing eval dataset:  68%|██████▊   | 644/953 [00:03<00:01, 272.72 examples/s]Tokenizing eval dataset:  46%|████▌     | 439/953 [00:02<00:02, 254.09 examples/s]Tokenizing eval dataset:  62%|██████▏   | 593/953 [00:03<00:01, 288.92 examples/s]Tokenizing eval dataset:  71%|███████   | 675/953 [00:03<00:01, 244.12 examples/s]Tokenizing eval dataset:  50%|████▉     | 473/953 [00:02<00:02, 236.87 examples/s]Tokenizing eval dataset:  66%|██████▌   | 626/953 [00:03<00:01, 235.41 examples/s]Tokenizing eval dataset:  74%|███████▍  | 706/953 [00:03<00:01, 207.08 examples/s]Tokenizing eval dataset:  53%|█████▎    | 506/953 [00:02<00:02, 214.11 examples/s]Tokenizing eval dataset:  69%|██████▉   | 659/953 [00:03<00:01, 221.00 examples/s]Tokenizing eval dataset:  78%|███████▊  | 744/953 [00:03<00:00, 240.90 examples/s]Tokenizing eval dataset:  56%|█████▌    | 535/953 [00:03<00:01, 223.37 examples/s]Tokenizing eval dataset:  73%|███████▎  | 691/953 [00:03<00:01, 232.55 examples/s]Tokenizing eval dataset:  82%|████████▏ | 782/953 [00:03<00:00, 270.56 examples/s]Tokenizing eval dataset:  60%|█████▉    | 568/953 [00:03<00:01, 244.55 examples/s]Tokenizing eval dataset:  76%|███████▌  | 722/953 [00:03<00:01, 229.20 examples/s]Tokenizing eval dataset:  87%|████████▋ | 832/953 [00:04<00:00, 272.71 examples/s]Tokenizing eval dataset:  64%|██████▎   | 606/953 [00:03<00:01, 227.67 examples/s]Tokenizing eval dataset:  81%|████████▏ | 776/953 [00:04<00:00, 203.22 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:04<00:00, 232.95 examples/s]Tokenizing eval dataset:  67%|██████▋   | 634/953 [00:03<00:01, 166.55 examples/s]Tokenizing eval dataset:  84%|████████▍ | 800/953 [00:04<00:00, 161.50 examples/s]Tokenizing eval dataset:  98%|█████████▊| 937/953 [00:04<00:00, 188.90 examples/s]Tokenizing eval dataset:  70%|██████▉   | 664/953 [00:04<00:02, 126.64 examples/s]Tokenizing eval dataset:  87%|████████▋ | 827/953 [00:04<00:00, 144.63 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:04<00:00, 192.63 examples/s]
Tokenizing eval dataset:  73%|███████▎  | 695/953 [00:04<00:01, 138.25 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  90%|████████▉ | 853/953 [00:04<00:00, 131.64 examples/s]Tokenizing eval dataset:  76%|███████▌  | 724/953 [00:04<00:01, 159.01 examples/s]Tokenizing eval dataset:  92%|█████████▏| 880/953 [00:04<00:00, 145.74 examples/s]Tokenizing eval dataset:  78%|███████▊  | 748/953 [00:04<00:01, 149.68 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:05<00:00, 128.00 examples/s]Tokenizing eval dataset:  82%|████████▏ | 780/953 [00:04<00:01, 135.45 examples/s]Tokenizing eval dataset:  98%|█████████▊| 937/953 [00:05<00:00, 139.53 examples/s]Tokenizing eval dataset:  84%|████████▍ | 801/953 [00:05<00:01, 123.33 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 114.83 examples/s]Tokenizing eval dataset:  87%|████████▋ | 826/953 [00:05<00:00, 133.45 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 165.52 examples/s]Tokenizing eval dataset:  89%|████████▉ | 851/953 [00:05<00:00, 137.96 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  92%|█████████▏| 877/953 [00:05<00:00, 146.12 examples/s]Tokenizing eval dataset:  96%|█████████▌| 914/953 [00:05<00:00, 187.84 examples/s]Tokenizing eval dataset:  99%|█████████▉| 942/953 [00:05<00:00, 188.52 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:05<00:00, 164.47 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.359682559967041 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.764665126800537 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.6465747356414795 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.9637086391448975 seconds
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250604_123539-tsynghlz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-4e-07_e-3_b-0.2
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/tsynghlz
  0%|          | 0/1881 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/1881 [00:12<6:35:30, 12.62s/it]  0%|          | 2/1881 [00:20<4:58:44,  9.54s/it]  0%|          | 3/1881 [00:27<4:24:00,  8.43s/it]  0%|          | 4/1881 [00:33<4:03:50,  7.79s/it]  0%|          | 5/1881 [00:40<3:47:58,  7.29s/it]  0%|          | 6/1881 [00:46<3:37:39,  6.97s/it]  0%|          | 7/1881 [00:52<3:21:32,  6.45s/it]  0%|          | 8/1881 [00:59<3:35:26,  6.90s/it]  0%|          | 9/1881 [01:05<3:20:34,  6.43s/it]  1%|          | 10/1881 [01:10<3:12:20,  6.17s/it]                                                   {'loss': 0.7086, 'grad_norm': 54.22784423828125, 'learning_rate': 5.741626794258373e-09, 'rewards/chosen': -0.00852355919778347, 'rewards/rejected': 0.017816543579101562, 'rewards/accuracies': 0.23749999701976776, 'rewards/margins': -0.02637939527630806, 'logps/chosen': -239.9499969482422, 'logps/rejected': -147.1875, 'logits/chosen': -6.453125, 'logits/rejected': -6.668749809265137, 'epoch': 0.02}
  1%|          | 10/1881 [01:11<3:12:20,  6.17s/it]  1%|          | 11/1881 [01:18<3:21:25,  6.46s/it]  1%|          | 12/1881 [01:25<3:35:01,  6.90s/it]  1%|          | 13/1881 [01:31<3:23:52,  6.55s/it]  1%|          | 14/1881 [01:38<3:22:48,  6.52s/it]  1%|          | 15/1881 [01:44<3:24:11,  6.57s/it]  1%|          | 16/1881 [01:51<3:21:32,  6.48s/it]  1%|          | 17/1881 [01:56<3:09:50,  6.11s/it]  1%|          | 18/1881 [02:01<2:58:31,  5.75s/it]  1%|          | 19/1881 [02:10<3:27:12,  6.68s/it]  1%|          | 20/1881 [02:16<3:28:53,  6.73s/it]                                                   {'loss': 0.6993, 'grad_norm': 159.8247528076172, 'learning_rate': 1.2121212121212122e-08, 'rewards/chosen': 0.053354837000370026, 'rewards/rejected': 0.013644409365952015, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.03968505933880806, 'logps/chosen': -276.8999938964844, 'logps/rejected': -167.91250610351562, 'logits/chosen': -6.270312309265137, 'logits/rejected': -6.375, 'epoch': 0.03}
  1%|          | 20/1881 [02:17<3:28:53,  6.73s/it]  1%|          | 21/1881 [02:23<3:30:05,  6.78s/it]  1%|          | 22/1881 [02:28<3:12:43,  6.22s/it]  1%|          | 23/1881 [02:35<3:16:45,  6.35s/it]  1%|▏         | 24/1881 [02:44<3:41:18,  7.15s/it]  1%|▏         | 25/1881 [02:51<3:43:17,  7.22s/it]  1%|▏         | 26/1881 [02:56<3:23:45,  6.59s/it]  1%|▏         | 27/1881 [03:02<3:13:05,  6.25s/it]  1%|▏         | 28/1881 [03:09<3:22:26,  6.55s/it]  2%|▏         | 29/1881 [03:15<3:12:01,  6.22s/it]  2%|▏         | 30/1881 [03:21<3:17:13,  6.39s/it]                                                   {'loss': 0.7266, 'grad_norm': 46.48594665527344, 'learning_rate': 1.850079744816587e-08, 'rewards/chosen': 0.019570160657167435, 'rewards/rejected': 0.0412418358027935, 'rewards/accuracies': 0.4437499940395355, 'rewards/margins': -0.021689604967832565, 'logps/chosen': -249.3000030517578, 'logps/rejected': -161.52499389648438, 'logits/chosen': -6.306250095367432, 'logits/rejected': -6.553124904632568, 'epoch': 0.05}
  2%|▏         | 30/1881 [03:22<3:17:13,  6.39s/it]  2%|▏         | 31/1881 [03:29<3:25:46,  6.67s/it]  2%|▏         | 32/1881 [03:39<4:03:15,  7.89s/it]  2%|▏         | 33/1881 [03:49<4:19:09,  8.41s/it]  2%|▏         | 34/1881 [03:54<3:50:34,  7.49s/it]  2%|▏         | 35/1881 [04:01<3:39:08,  7.12s/it]  2%|▏         | 36/1881 [04:11<4:08:03,  8.07s/it]  2%|▏         | 37/1881 [04:19<4:11:31,  8.18s/it]  2%|▏         | 38/1881 [04:24<3:39:18,  7.14s/it]  2%|▏         | 39/1881 [04:35<4:18:09,  8.41s/it]  2%|▏         | 40/1881 [04:42<4:04:27,  7.97s/it]                                                   {'loss': 0.7261, 'grad_norm': 47.90799331665039, 'learning_rate': 2.4880382775119616e-08, 'rewards/chosen': -0.042154692113399506, 'rewards/rejected': -0.008362198248505592, 'rewards/accuracies': 0.4124999940395355, 'rewards/margins': -0.033773042261600494, 'logps/chosen': -306.92498779296875, 'logps/rejected': -171.16250610351562, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.573437690734863, 'epoch': 0.06}
  2%|▏         | 40/1881 [04:44<4:04:27,  7.97s/it]  2%|▏         | 41/1881 [04:51<4:09:20,  8.13s/it]  2%|▏         | 42/1881 [05:00<4:18:01,  8.42s/it]  2%|▏         | 43/1881 [05:07<4:00:15,  7.84s/it]  2%|▏         | 44/1881 [05:14<3:53:24,  7.62s/it]  2%|▏         | 45/1881 [05:20<3:44:20,  7.33s/it]  2%|▏         | 46/1881 [05:28<3:44:24,  7.34s/it]  2%|▏         | 47/1881 [05:34<3:39:10,  7.17s/it]  3%|▎         | 48/1881 [05:39<3:17:09,  6.45s/it]  3%|▎         | 49/1881 [05:49<3:43:15,  7.31s/it]  3%|▎         | 50/1881 [05:57<3:53:40,  7.66s/it]                                                   {'loss': 0.6852, 'grad_norm': 920.26708984375, 'learning_rate': 3.1259968102073366e-08, 'rewards/chosen': 0.0053161620162427425, 'rewards/rejected': -0.01780395582318306, 'rewards/accuracies': 0.4625000059604645, 'rewards/margins': 0.02309875562787056, 'logps/chosen': -398.5, 'logps/rejected': -180.9499969482422, 'logits/chosen': -6.214062690734863, 'logits/rejected': -6.579687595367432, 'epoch': 0.08}
  3%|▎         | 50/1881 [05:57<3:53:40,  7.66s/it]  3%|▎         | 51/1881 [06:07<4:10:42,  8.22s/it]  3%|▎         | 52/1881 [06:15<4:12:24,  8.28s/it]  3%|▎         | 53/1881 [06:25<4:25:13,  8.71s/it]  3%|▎         | 54/1881 [06:36<4:49:04,  9.49s/it]  3%|▎         | 55/1881 [06:46<4:56:14,  9.73s/it]  3%|▎         | 56/1881 [06:57<5:06:41, 10.08s/it]  3%|▎         | 57/1881 [07:04<4:36:10,  9.08s/it]  3%|▎         | 58/1881 [07:12<4:28:29,  8.84s/it]  3%|▎         | 59/1881 [07:18<4:00:58,  7.94s/it]  3%|▎         | 60/1881 [07:25<3:48:12,  7.52s/it]                                                   {'loss': 0.6955, 'grad_norm': 40.827247619628906, 'learning_rate': 3.763955342902711e-08, 'rewards/chosen': 0.021668244153261185, 'rewards/rejected': -0.0008144378662109375, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': 0.022600555792450905, 'logps/chosen': -210.03750610351562, 'logps/rejected': -153.8249969482422, 'logits/chosen': -6.449999809265137, 'logits/rejected': -6.446875095367432, 'epoch': 0.1}
  3%|▎         | 60/1881 [07:25<3:48:12,  7.52s/it]  3%|▎         | 61/1881 [07:34<4:05:03,  8.08s/it]  3%|▎         | 62/1881 [07:44<4:26:18,  8.78s/it]  3%|▎         | 63/1881 [07:52<4:12:52,  8.35s/it]  3%|▎         | 64/1881 [07:58<3:56:34,  7.81s/it]  3%|▎         | 65/1881 [08:05<3:43:48,  7.39s/it]  4%|▎         | 66/1881 [08:12<3:44:27,  7.42s/it]  4%|▎         | 67/1881 [08:18<3:26:31,  6.83s/it]  4%|▎         | 68/1881 [08:24<3:25:10,  6.79s/it]  4%|▎         | 69/1881 [08:32<3:35:13,  7.13s/it]  4%|▎         | 70/1881 [08:37<3:14:20,  6.44s/it]                                                   {'loss': 0.6942, 'grad_norm': 48.644771575927734, 'learning_rate': 4.401913875598086e-08, 'rewards/chosen': 0.03254089504480362, 'rewards/rejected': -0.0046371459029614925, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': 0.03728027269244194, 'logps/chosen': -275.8125, 'logps/rejected': -180.47500610351562, 'logits/chosen': -6.389062404632568, 'logits/rejected': -6.354687690734863, 'epoch': 0.11}
  4%|▎         | 70/1881 [08:37<3:14:20,  6.44s/it]  4%|▍         | 71/1881 [08:48<3:51:49,  7.68s/it]  4%|▍         | 72/1881 [09:01<4:40:23,  9.30s/it]  4%|▍         | 73/1881 [09:06<4:08:03,  8.23s/it]  4%|▍         | 74/1881 [09:10<3:29:51,  6.97s/it]  4%|▍         | 75/1881 [09:18<3:31:53,  7.04s/it]  4%|▍         | 76/1881 [09:25<3:34:23,  7.13s/it]  4%|▍         | 77/1881 [09:32<3:32:56,  7.08s/it]  4%|▍         | 78/1881 [09:43<4:08:43,  8.28s/it]  4%|▍         | 79/1881 [09:51<4:09:04,  8.29s/it]  4%|▍         | 80/1881 [10:04<4:50:08,  9.67s/it]                                                   {'loss': 0.7019, 'grad_norm': 52.0218620300293, 'learning_rate': 5.039872408293461e-08, 'rewards/chosen': 0.09146881103515625, 'rewards/rejected': 0.0377897247672081, 'rewards/accuracies': 0.4937500059604645, 'rewards/margins': 0.05379486083984375, 'logps/chosen': -278.75, 'logps/rejected': -213.25, 'logits/chosen': -6.379687309265137, 'logits/rejected': -6.704687595367432, 'epoch': 0.13}
  4%|▍         | 80/1881 [10:04<4:50:08,  9.67s/it]  4%|▍         | 81/1881 [10:13<4:39:00,  9.30s/it]  4%|▍         | 82/1881 [10:19<4:10:36,  8.36s/it]  4%|▍         | 83/1881 [10:24<3:41:09,  7.38s/it]  4%|▍         | 84/1881 [10:30<3:31:39,  7.07s/it]  5%|▍         | 85/1881 [10:40<3:55:33,  7.87s/it]  5%|▍         | 86/1881 [10:47<3:48:24,  7.64s/it]  5%|▍         | 87/1881 [10:56<3:59:09,  8.00s/it]  5%|▍         | 88/1881 [11:03<3:54:18,  7.84s/it]  5%|▍         | 89/1881 [11:11<3:50:12,  7.71s/it]  5%|▍         | 90/1881 [11:23<4:26:52,  8.94s/it]                                                   {'loss': 0.7097, 'grad_norm': 792.2376708984375, 'learning_rate': 5.677830940988836e-08, 'rewards/chosen': -0.00107574462890625, 'rewards/rejected': 0.0033363341353833675, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': -0.004376220516860485, 'logps/chosen': -192.5124969482422, 'logps/rejected': -143.83749389648438, 'logits/chosen': -6.525000095367432, 'logits/rejected': -6.435937404632568, 'epoch': 0.14}
  5%|▍         | 90/1881 [11:23<4:26:52,  8.94s/it]  5%|▍         | 91/1881 [11:29<4:06:33,  8.26s/it]  5%|▍         | 92/1881 [11:37<3:59:35,  8.04s/it]  5%|▍         | 93/1881 [11:43<3:38:17,  7.33s/it]  5%|▍         | 94/1881 [11:50<3:41:58,  7.45s/it]  5%|▌         | 95/1881 [11:57<3:34:06,  7.19s/it]  5%|▌         | 96/1881 [12:08<4:09:48,  8.40s/it]  5%|▌         | 97/1881 [12:20<4:37:39,  9.34s/it]  5%|▌         | 98/1881 [12:28<4:24:52,  8.91s/it]  5%|▌         | 99/1881 [12:37<4:28:23,  9.04s/it]  5%|▌         | 100/1881 [12:47<4:34:18,  9.24s/it]                                                    {'loss': 0.7086, 'grad_norm': 54.88836669921875, 'learning_rate': 6.31578947368421e-08, 'rewards/chosen': -0.007830810733139515, 'rewards/rejected': 0.01704711839556694, 'rewards/accuracies': 0.38749998807907104, 'rewards/margins': -0.02483215369284153, 'logps/chosen': -232.41250610351562, 'logps/rejected': -113.82499694824219, 'logits/chosen': -6.298437595367432, 'logits/rejected': -6.671875, 'epoch': 0.16}
  5%|▌         | 100/1881 [12:47<4:34:18,  9.24s/it]  5%|▌         | 101/1881 [12:52<4:03:52,  8.22s/it]  5%|▌         | 102/1881 [13:00<4:02:14,  8.17s/it]  5%|▌         | 103/1881 [13:14<4:46:22,  9.66s/it]  6%|▌         | 104/1881 [13:20<4:15:36,  8.63s/it]  6%|▌         | 105/1881 [13:27<4:06:52,  8.34s/it]  6%|▌         | 106/1881 [13:32<3:37:06,  7.34s/it]  6%|▌         | 107/1881 [13:39<3:33:57,  7.24s/it]  6%|▌         | 108/1881 [13:47<3:32:11,  7.18s/it]  6%|▌         | 109/1881 [13:58<4:12:33,  8.55s/it]  6%|▌         | 110/1881 [14:06<4:07:33,  8.39s/it]                                                    {'loss': 0.711, 'grad_norm': 53.00559997558594, 'learning_rate': 6.953748006379585e-08, 'rewards/chosen': 0.045113373547792435, 'rewards/rejected': 0.05824889987707138, 'rewards/accuracies': 0.45625001192092896, 'rewards/margins': -0.01311645470559597, 'logps/chosen': -221.0124969482422, 'logps/rejected': -160.2937469482422, 'logits/chosen': -6.514062404632568, 'logits/rejected': -6.7734375, 'epoch': 0.18}
  6%|▌         | 110/1881 [14:06<4:07:33,  8.39s/it]  6%|▌         | 111/1881 [14:14<3:59:53,  8.13s/it]  6%|▌         | 112/1881 [14:27<4:45:04,  9.67s/it]  6%|▌         | 113/1881 [14:36<4:38:29,  9.45s/it]  6%|▌         | 114/1881 [14:41<3:59:07,  8.12s/it]  6%|▌         | 115/1881 [14:48<3:46:21,  7.69s/it]  6%|▌         | 116/1881 [14:55<3:43:19,  7.59s/it]  6%|▌         | 117/1881 [15:03<3:41:55,  7.55s/it]  6%|▋         | 118/1881 [15:10<3:39:05,  7.46s/it]  6%|▋         | 119/1881 [15:15<3:23:19,  6.92s/it]  6%|▋         | 120/1881 [15:24<3:35:24,  7.34s/it]                                                    {'loss': 0.7077, 'grad_norm': 450.08013916015625, 'learning_rate': 7.59170653907496e-08, 'rewards/chosen': 0.008112335577607155, 'rewards/rejected': 0.0072006224654614925, 'rewards/accuracies': 0.41874998807907104, 'rewards/margins': 0.0010116577614098787, 'logps/chosen': -204.0, 'logps/rejected': -192.08749389648438, 'logits/chosen': -6.546875, 'logits/rejected': -6.815625190734863, 'epoch': 0.19}
  6%|▋         | 120/1881 [15:24<3:35:24,  7.34s/it]  6%|▋         | 121/1881 [15:35<4:11:00,  8.56s/it]  6%|▋         | 122/1881 [15:43<4:03:16,  8.30s/it]  7%|▋         | 123/1881 [15:51<4:01:47,  8.25s/it]  7%|▋         | 124/1881 [16:02<4:24:39,  9.04s/it]  7%|▋         | 125/1881 [16:10<4:12:57,  8.64s/it]  7%|▋         | 126/1881 [16:20<4:26:41,  9.12s/it]  7%|▋         | 127/1881 [16:32<4:55:50, 10.12s/it]  7%|▋         | 128/1881 [16:40<4:36:07,  9.45s/it]  7%|▋         | 129/1881 [16:46<4:01:35,  8.27s/it]  7%|▋         | 130/1881 [16:53<3:52:51,  7.98s/it]                                                    {'loss': 0.7126, 'grad_norm': 49.73390197753906, 'learning_rate': 8.229665071770334e-08, 'rewards/chosen': 0.025475312024354935, 'rewards/rejected': 0.013470458798110485, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.011766815558075905, 'logps/chosen': -225.7624969482422, 'logps/rejected': -187.6281280517578, 'logits/chosen': -6.5234375, 'logits/rejected': -6.645312309265137, 'epoch': 0.21}
  7%|▋         | 130/1881 [16:53<3:52:51,  7.98s/it]  7%|▋         | 131/1881 [17:04<4:23:35,  9.04s/it]  7%|▋         | 132/1881 [17:10<3:50:22,  7.90s/it]  7%|▋         | 133/1881 [17:17<3:45:50,  7.75s/it]  7%|▋         | 134/1881 [17:27<4:08:02,  8.52s/it]  7%|▋         | 135/1881 [17:36<4:10:50,  8.62s/it]  7%|▋         | 136/1881 [17:47<4:25:39,  9.13s/it]  7%|▋         | 137/1881 [17:53<4:00:01,  8.26s/it]  7%|▋         | 138/1881 [18:01<3:55:11,  8.10s/it]  7%|▋         | 139/1881 [18:10<4:09:55,  8.61s/it]  7%|▋         | 140/1881 [18:17<3:56:46,  8.16s/it]                                                    {'loss': 0.6879, 'grad_norm': 47.30158615112305, 'learning_rate': 8.867623604465709e-08, 'rewards/chosen': 0.1251014769077301, 'rewards/rejected': 0.06301651149988174, 'rewards/accuracies': 0.4124999940395355, 'rewards/margins': 0.06210937350988388, 'logps/chosen': -289.375, 'logps/rejected': -182.02499389648438, 'logits/chosen': -6.268750190734863, 'logits/rejected': -6.520312309265137, 'epoch': 0.22}
  7%|▋         | 140/1881 [18:18<3:56:46,  8.16s/it]  7%|▋         | 141/1881 [18:31<4:41:58,  9.72s/it]  8%|▊         | 142/1881 [18:40<4:38:57,  9.63s/it]  8%|▊         | 143/1881 [18:46<4:09:09,  8.60s/it]  8%|▊         | 144/1881 [18:53<3:54:31,  8.10s/it]  8%|▊         | 145/1881 [19:05<4:21:39,  9.04s/it]  8%|▊         | 146/1881 [19:10<3:51:17,  8.00s/it]  8%|▊         | 147/1881 [19:22<4:22:25,  9.08s/it]  8%|▊         | 148/1881 [19:29<4:04:29,  8.46s/it]  8%|▊         | 149/1881 [19:36<3:51:13,  8.01s/it]  8%|▊         | 150/1881 [19:46<4:10:34,  8.69s/it]                                                    {'loss': 0.6965, 'grad_norm': 50.32337188720703, 'learning_rate': 9.505582137161085e-08, 'rewards/chosen': 0.03150329738855362, 'rewards/rejected': 0.0008438110235147178, 'rewards/accuracies': 0.39375001192092896, 'rewards/margins': 0.03058929368853569, 'logps/chosen': -182.5, 'logps/rejected': -153.91250610351562, 'logits/chosen': -6.451562404632568, 'logits/rejected': -6.584374904632568, 'epoch': 0.24}
  8%|▊         | 150/1881 [19:46<4:10:34,  8.69s/it]  8%|▊         | 151/1881 [19:54<4:07:34,  8.59s/it]  8%|▊         | 152/1881 [20:02<3:57:44,  8.25s/it]  8%|▊         | 153/1881 [20:09<3:51:14,  8.03s/it]  8%|▊         | 154/1881 [20:15<3:31:50,  7.36s/it]  8%|▊         | 155/1881 [20:26<3:59:16,  8.32s/it]  8%|▊         | 156/1881 [20:33<3:53:17,  8.11s/it]  8%|▊         | 157/1881 [20:44<4:18:39,  9.00s/it]  8%|▊         | 158/1881 [20:51<4:00:18,  8.37s/it]  8%|▊         | 159/1881 [20:59<3:58:09,  8.30s/it]  9%|▊         | 160/1881 [21:10<4:19:57,  9.06s/it]                                                    {'loss': 0.6616, 'grad_norm': 64.57327270507812, 'learning_rate': 1.0143540669856459e-07, 'rewards/chosen': 0.26260679960250854, 'rewards/rejected': 0.05141792446374893, 'rewards/accuracies': 0.543749988079071, 'rewards/margins': 0.21128539741039276, 'logps/chosen': -358.875, 'logps/rejected': -211.1750030517578, 'logits/chosen': -6.118750095367432, 'logits/rejected': -6.2421875, 'epoch': 0.25}
  9%|▊         | 160/1881 [21:10<4:19:57,  9.06s/it]  9%|▊         | 161/1881 [21:18<4:09:46,  8.71s/it]  9%|▊         | 162/1881 [21:24<3:48:11,  7.97s/it]  9%|▊         | 163/1881 [21:30<3:24:52,  7.16s/it]  9%|▊         | 164/1881 [21:38<3:37:50,  7.61s/it]  9%|▉         | 165/1881 [21:45<3:33:23,  7.46s/it]  9%|▉         | 166/1881 [21:57<4:04:24,  8.55s/it]  9%|▉         | 167/1881 [22:02<3:34:38,  7.51s/it]  9%|▉         | 168/1881 [22:07<3:16:29,  6.88s/it]  9%|▉         | 169/1881 [22:14<3:18:59,  6.97s/it]  9%|▉         | 170/1881 [22:23<3:36:35,  7.60s/it]                                                    {'loss': 0.6724, 'grad_norm': 317.59881591796875, 'learning_rate': 1.0781499202551834e-07, 'rewards/chosen': 0.15321198105812073, 'rewards/rejected': 0.006564331240952015, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.14668579399585724, 'logps/chosen': -226.97500610351562, 'logps/rejected': -90.35624694824219, 'logits/chosen': -6.487500190734863, 'logits/rejected': -6.900000095367432, 'epoch': 0.27}
  9%|▉         | 170/1881 [22:23<3:36:35,  7.60s/it]  9%|▉         | 171/1881 [22:30<3:27:34,  7.28s/it]  9%|▉         | 172/1881 [22:35<3:08:47,  6.63s/it]  9%|▉         | 173/1881 [22:43<3:23:10,  7.14s/it]  9%|▉         | 174/1881 [22:49<3:14:08,  6.82s/it]  9%|▉         | 175/1881 [22:59<3:40:32,  7.76s/it]  9%|▉         | 176/1881 [23:10<4:03:36,  8.57s/it]  9%|▉         | 177/1881 [23:22<4:30:47,  9.54s/it]  9%|▉         | 178/1881 [23:27<3:53:32,  8.23s/it] 10%|▉         | 179/1881 [23:35<3:57:01,  8.36s/it] 10%|▉         | 180/1881 [23:41<3:32:52,  7.51s/it]                                                    {'loss': 0.6526, 'grad_norm': 43.46666717529297, 'learning_rate': 1.1419457735247209e-07, 'rewards/chosen': 0.406149297952652, 'rewards/rejected': 0.03320159763097763, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.37314337491989136, 'logps/chosen': -328.04998779296875, 'logps/rejected': -151.03750610351562, 'logits/chosen': -6.314062595367432, 'logits/rejected': -6.568749904632568, 'epoch': 0.29}
 10%|▉         | 180/1881 [23:41<3:32:52,  7.51s/it] 10%|▉         | 181/1881 [23:48<3:31:47,  7.47s/it] 10%|▉         | 182/1881 [24:00<4:10:27,  8.84s/it] 10%|▉         | 183/1881 [24:11<4:24:34,  9.35s/it] 10%|▉         | 184/1881 [24:16<3:50:13,  8.14s/it] 10%|▉         | 185/1881 [24:26<4:03:53,  8.63s/it] 10%|▉         | 186/1881 [24:34<4:00:35,  8.52s/it] 10%|▉         | 187/1881 [24:40<3:41:01,  7.83s/it] 10%|▉         | 188/1881 [24:50<3:56:49,  8.39s/it] 10%|█         | 189/1881 [25:02<4:25:17,  9.41s/it] 10%|█         | 190/1881 [25:10<4:10:11,  8.88s/it]                                                    {'loss': 0.6784, 'grad_norm': 46.892356872558594, 'learning_rate': 1.2057416267942584e-07, 'rewards/chosen': 0.2675414979457855, 'rewards/rejected': 0.11314849555492401, 'rewards/accuracies': 0.5062500238418579, 'rewards/margins': 0.15499496459960938, 'logps/chosen': -252.35000610351562, 'logps/rejected': -158.94375610351562, 'logits/chosen': -6.267187595367432, 'logits/rejected': -6.567187309265137, 'epoch': 0.3}
 10%|█         | 190/1881 [25:10<4:10:11,  8.88s/it] 10%|█         | 191/1881 [25:15<3:40:23,  7.82s/it] 10%|█         | 192/1881 [25:24<3:51:26,  8.22s/it] 10%|█         | 193/1881 [25:38<4:41:06,  9.99s/it] 10%|█         | 194/1881 [25:49<4:43:28, 10.08s/it] 10%|█         | 195/1881 [25:57<4:28:37,  9.56s/it] 10%|█         | 196/1881 [26:08<4:44:36, 10.13s/it] 10%|█         | 197/1881 [26:20<4:59:57, 10.69s/it] 11%|█         | 198/1881 [26:34<5:20:52, 11.44s/it] 11%|█         | 199/1881 [26:44<5:11:11, 11.10s/it] 11%|█         | 200/1881 [26:51<4:41:14, 10.04s/it]                                                    {'loss': 0.6509, 'grad_norm': 102.30337524414062, 'learning_rate': 1.2695374800637956e-07, 'rewards/chosen': 0.45774537324905396, 'rewards/rejected': 0.14734458923339844, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.309774786233902, 'logps/chosen': -320.26251220703125, 'logps/rejected': -213.3625030517578, 'logits/chosen': -6.439062595367432, 'logits/rejected': -6.489062309265137, 'epoch': 0.32}
 11%|█         | 200/1881 [26:51<4:41:14, 10.04s/it] 11%|█         | 201/1881 [27:03<4:51:42, 10.42s/it] 11%|█         | 202/1881 [27:11<4:30:19,  9.66s/it] 11%|█         | 203/1881 [27:16<3:56:01,  8.44s/it] 11%|█         | 204/1881 [27:22<3:37:26,  7.78s/it] 11%|█         | 205/1881 [27:30<3:34:59,  7.70s/it] 11%|█         | 206/1881 [27:36<3:23:16,  7.28s/it] 11%|█         | 207/1881 [27:46<3:47:49,  8.17s/it] 11%|█         | 208/1881 [27:52<3:26:04,  7.39s/it] 11%|█         | 209/1881 [27:59<3:21:34,  7.23s/it] 11%|█         | 210/1881 [28:09<3:42:01,  7.97s/it]                                                    {'loss': 0.6355, 'grad_norm': 42.471622467041016, 'learning_rate': 1.333333333333333e-07, 'rewards/chosen': 0.49948424100875854, 'rewards/rejected': 0.088775634765625, 'rewards/accuracies': 0.6625000238418579, 'rewards/margins': 0.41085511445999146, 'logps/chosen': -270.0249938964844, 'logps/rejected': -125.05000305175781, 'logits/chosen': -6.214062690734863, 'logits/rejected': -6.462500095367432, 'epoch': 0.33}
 11%|█         | 210/1881 [28:09<3:42:01,  7.97s/it] 11%|█         | 211/1881 [28:15<3:30:05,  7.55s/it] 11%|█▏        | 212/1881 [28:26<3:57:02,  8.52s/it] 11%|█▏        | 213/1881 [28:37<4:20:19,  9.36s/it] 11%|█▏        | 214/1881 [28:44<3:58:54,  8.60s/it] 11%|█▏        | 215/1881 [28:51<3:42:57,  8.03s/it] 11%|█▏        | 216/1881 [28:57<3:26:18,  7.43s/it] 12%|█▏        | 217/1881 [29:06<3:43:09,  8.05s/it] 12%|█▏        | 218/1881 [29:13<3:34:02,  7.72s/it] 12%|█▏        | 219/1881 [29:21<3:30:13,  7.59s/it] 12%|█▏        | 220/1881 [29:36<4:36:44, 10.00s/it]                                                    {'loss': 0.6755, 'grad_norm': 74.06922149658203, 'learning_rate': 1.3971291866028706e-07, 'rewards/chosen': 0.3017738461494446, 'rewards/rejected': 0.13806304335594177, 'rewards/accuracies': 0.518750011920929, 'rewards/margins': 0.16363219916820526, 'logps/chosen': -205.9499969482422, 'logps/rejected': -149.5812530517578, 'logits/chosen': -6.464062690734863, 'logits/rejected': -6.456250190734863, 'epoch': 0.35}
 12%|█▏        | 220/1881 [29:36<4:36:44, 10.00s/it] 12%|█▏        | 221/1881 [29:44<4:18:53,  9.36s/it] 12%|█▏        | 222/1881 [29:52<4:04:18,  8.84s/it] 12%|█▏        | 223/1881 [30:00<3:57:54,  8.61s/it] 12%|█▏        | 224/1881 [30:08<3:54:36,  8.50s/it] 12%|█▏        | 225/1881 [30:15<3:42:22,  8.06s/it] 12%|█▏        | 226/1881 [30:22<3:37:17,  7.88s/it] 12%|█▏        | 227/1881 [30:32<3:54:53,  8.52s/it] 12%|█▏        | 228/1881 [30:38<3:31:31,  7.68s/it] 12%|█▏        | 229/1881 [30:45<3:20:20,  7.28s/it] 12%|█▏        | 230/1881 [30:49<2:58:41,  6.49s/it]                                                    {'loss': 0.6591, 'grad_norm': 71.14396667480469, 'learning_rate': 1.4609250398724084e-07, 'rewards/chosen': 0.38123780488967896, 'rewards/rejected': 0.23551177978515625, 'rewards/accuracies': 0.606249988079071, 'rewards/margins': 0.14563599228858948, 'logps/chosen': -219.2624969482422, 'logps/rejected': -175.5124969482422, 'logits/chosen': -6.426562309265137, 'logits/rejected': -6.65625, 'epoch': 0.37}
 12%|█▏        | 230/1881 [30:50<2:58:41,  6.49s/it] 12%|█▏        | 231/1881 [30:56<2:58:06,  6.48s/it] 12%|█▏        | 232/1881 [31:02<2:57:38,  6.46s/it] 12%|█▏        | 233/1881 [31:12<3:27:56,  7.57s/it] 12%|█▏        | 234/1881 [31:23<3:53:30,  8.51s/it] 12%|█▏        | 235/1881 [31:34<4:14:53,  9.29s/it] 13%|█▎        | 236/1881 [31:45<4:30:10,  9.85s/it] 13%|█▎        | 237/1881 [31:52<4:03:27,  8.89s/it] 13%|█▎        | 238/1881 [32:01<4:01:42,  8.83s/it] 13%|█▎        | 239/1881 [32:12<4:26:52,  9.75s/it] 13%|█▎        | 240/1881 [32:20<4:05:37,  8.98s/it]                                                    {'loss': 0.6652, 'grad_norm': 37.01145935058594, 'learning_rate': 1.5247208931419459e-07, 'rewards/chosen': 0.2360992431640625, 'rewards/rejected': 0.06954994052648544, 'rewards/accuracies': 0.606249988079071, 'rewards/margins': 0.1667633056640625, 'logps/chosen': -160.5500030517578, 'logps/rejected': -118.42500305175781, 'logits/chosen': -6.496874809265137, 'logits/rejected': -6.504687309265137, 'epoch': 0.38}
 13%|█▎        | 240/1881 [32:20<4:05:37,  8.98s/it] 13%|█▎        | 241/1881 [32:28<4:00:51,  8.81s/it] 13%|█▎        | 242/1881 [32:38<4:13:06,  9.27s/it] 13%|█▎        | 243/1881 [32:44<3:39:23,  8.04s/it] 13%|█▎        | 244/1881 [32:51<3:37:48,  7.98s/it] 13%|█▎        | 245/1881 [33:02<3:55:55,  8.65s/it] 13%|█▎        | 246/1881 [33:14<4:28:53,  9.87s/it] 13%|█▎        | 247/1881 [33:22<4:14:41,  9.35s/it] 13%|█▎        | 248/1881 [33:28<3:44:49,  8.26s/it] 13%|█▎        | 249/1881 [33:40<4:11:58,  9.26s/it] 13%|█▎        | 250/1881 [33:47<3:52:43,  8.56s/it]                                                    {'loss': 0.6567, 'grad_norm': 44.8970947265625, 'learning_rate': 1.5885167464114834e-07, 'rewards/chosen': 0.55572509765625, 'rewards/rejected': 0.2039642333984375, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.3512634336948395, 'logps/chosen': -308.04998779296875, 'logps/rejected': -170.47500610351562, 'logits/chosen': -6.287499904632568, 'logits/rejected': -6.3125, 'epoch': 0.4}
 13%|█▎        | 250/1881 [33:47<3:52:43,  8.56s/it] 13%|█▎        | 251/1881 [33:53<3:34:19,  7.89s/it] 13%|█▎        | 252/1881 [34:02<3:39:14,  8.08s/it] 13%|█▎        | 253/1881 [34:08<3:28:44,  7.69s/it] 14%|█▎        | 254/1881 [34:15<3:23:36,  7.51s/it] 14%|█▎        | 255/1881 [34:26<3:50:54,  8.52s/it] 14%|█▎        | 256/1881 [34:36<4:04:27,  9.03s/it] 14%|█▎        | 257/1881 [34:42<3:36:00,  7.98s/it] 14%|█▎        | 258/1881 [34:51<3:47:16,  8.40s/it] 14%|█▍        | 259/1881 [34:58<3:32:25,  7.86s/it] 14%|█▍        | 260/1881 [35:05<3:28:31,  7.72s/it]                                                    {'loss': 0.6597, 'grad_norm': 49.08173370361328, 'learning_rate': 1.6523125996810209e-07, 'rewards/chosen': 0.1428401917219162, 'rewards/rejected': 0.051047515124082565, 'rewards/accuracies': 0.6312500238418579, 'rewards/margins': 0.09165038913488388, 'logps/chosen': -122.86250305175781, 'logps/rejected': -99.8125, 'logits/chosen': -6.559374809265137, 'logits/rejected': -6.832812309265137, 'epoch': 0.41}
 14%|█▍        | 260/1881 [35:05<3:28:31,  7.72s/it] 14%|█▍        | 261/1881 [35:15<3:39:43,  8.14s/it] 14%|█▍        | 262/1881 [35:23<3:43:00,  8.26s/it] 14%|█▍        | 263/1881 [35:36<4:16:53,  9.53s/it] 14%|█▍        | 264/1881 [35:43<3:59:55,  8.90s/it] 14%|█▍        | 265/1881 [35:50<3:44:00,  8.32s/it] 14%|█▍        | 266/1881 [35:58<3:39:16,  8.15s/it] 14%|█▍        | 267/1881 [36:09<4:06:46,  9.17s/it] 14%|█▍        | 268/1881 [36:17<3:55:53,  8.77s/it] 14%|█▍        | 269/1881 [36:24<3:44:19,  8.35s/it] 14%|█▍        | 270/1881 [36:32<3:40:25,  8.21s/it]                                                    {'loss': 0.6258, 'grad_norm': 41.30109786987305, 'learning_rate': 1.716108452950558e-07, 'rewards/chosen': 1.033166527748108, 'rewards/rejected': 0.3901428282260895, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.6413635015487671, 'logps/chosen': -379.13751220703125, 'logps/rejected': -215.1125030517578, 'logits/chosen': -6.206250190734863, 'logits/rejected': -6.521874904632568, 'epoch': 0.43}
 14%|█▍        | 270/1881 [36:32<3:40:25,  8.21s/it] 14%|█▍        | 271/1881 [36:40<3:35:00,  8.01s/it] 14%|█▍        | 272/1881 [36:50<3:51:52,  8.65s/it] 15%|█▍        | 273/1881 [36:57<3:41:06,  8.25s/it] 15%|█▍        | 274/1881 [37:03<3:16:26,  7.33s/it] 15%|█▍        | 275/1881 [37:10<3:19:54,  7.47s/it] 15%|█▍        | 276/1881 [37:16<3:01:47,  6.80s/it] 15%|█▍        | 277/1881 [37:22<3:00:09,  6.74s/it] 15%|█▍        | 278/1881 [37:29<2:59:36,  6.72s/it] 15%|█▍        | 279/1881 [37:35<2:53:47,  6.51s/it] 15%|█▍        | 280/1881 [37:47<3:35:25,  8.07s/it]                                                    {'loss': 0.6083, 'grad_norm': 52.04551315307617, 'learning_rate': 1.7799043062200956e-07, 'rewards/chosen': 0.769360363483429, 'rewards/rejected': 0.28695374727249146, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.4820190370082855, 'logps/chosen': -323.54376220703125, 'logps/rejected': -198.9375, 'logits/chosen': -6.318749904632568, 'logits/rejected': -6.556250095367432, 'epoch': 0.45}
 15%|█▍        | 280/1881 [37:47<3:35:25,  8.07s/it] 15%|█▍        | 281/1881 [37:52<3:13:48,  7.27s/it] 15%|█▍        | 282/1881 [38:00<3:18:53,  7.46s/it] 15%|█▌        | 283/1881 [38:07<3:17:27,  7.41s/it] 15%|█▌        | 284/1881 [38:15<3:23:30,  7.65s/it] 15%|█▌        | 285/1881 [38:22<3:12:05,  7.22s/it] 15%|█▌        | 286/1881 [38:29<3:09:32,  7.13s/it] 15%|█▌        | 287/1881 [38:36<3:09:31,  7.13s/it] 15%|█▌        | 288/1881 [38:50<4:10:28,  9.43s/it] 15%|█▌        | 289/1881 [38:56<3:41:35,  8.35s/it] 15%|█▌        | 290/1881 [39:09<4:14:04,  9.58s/it]                                                    {'loss': 0.6586, 'grad_norm': 56.10042953491211, 'learning_rate': 1.843700159489633e-07, 'rewards/chosen': 0.665026843547821, 'rewards/rejected': 0.2590270936489105, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.4056762754917145, 'logps/chosen': -265.8125, 'logps/rejected': -176.4499969482422, 'logits/chosen': -6.315625190734863, 'logits/rejected': -6.28125, 'epoch': 0.46}
 15%|█▌        | 290/1881 [39:09<4:14:04,  9.58s/it] 15%|█▌        | 291/1881 [39:14<3:37:20,  8.20s/it] 16%|█▌        | 292/1881 [39:19<3:11:26,  7.23s/it] 16%|█▌        | 293/1881 [39:31<3:47:52,  8.61s/it] 16%|█▌        | 294/1881 [39:41<4:01:44,  9.14s/it] 16%|█▌        | 295/1881 [39:48<3:46:44,  8.58s/it] 16%|█▌        | 296/1881 [39:59<4:05:45,  9.30s/it] 16%|█▌        | 297/1881 [40:05<3:35:42,  8.17s/it] 16%|█▌        | 298/1881 [40:12<3:25:30,  7.79s/it] 16%|█▌        | 299/1881 [40:23<3:52:11,  8.81s/it] 16%|█▌        | 300/1881 [40:30<3:40:44,  8.38s/it]                                                    {'loss': 0.6313, 'grad_norm': 61.26423263549805, 'learning_rate': 1.9074960127591706e-07, 'rewards/chosen': 0.29729002714157104, 'rewards/rejected': 0.060302734375, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.23664550483226776, 'logps/chosen': -134.7624969482422, 'logps/rejected': -92.2125015258789, 'logits/chosen': -6.487500190734863, 'logits/rejected': -6.721875190734863, 'epoch': 0.48}
 16%|█▌        | 300/1881 [40:30<3:40:44,  8.38s/it] 16%|█▌        | 301/1881 [40:37<3:28:00,  7.90s/it] 16%|█▌        | 302/1881 [40:48<3:50:21,  8.75s/it] 16%|█▌        | 303/1881 [40:52<3:15:24,  7.43s/it] 16%|█▌        | 304/1881 [40:57<2:55:21,  6.67s/it] 16%|█▌        | 305/1881 [41:05<3:10:16,  7.24s/it] 16%|█▋        | 306/1881 [41:17<3:46:34,  8.63s/it] 16%|█▋        | 307/1881 [41:27<3:52:51,  8.88s/it] 16%|█▋        | 308/1881 [41:35<3:44:29,  8.56s/it] 16%|█▋        | 309/1881 [41:43<3:46:32,  8.65s/it] 16%|█▋        | 310/1881 [41:52<3:43:42,  8.54s/it]                                                    {'loss': 0.6351, 'grad_norm': 59.730857849121094, 'learning_rate': 1.971291866028708e-07, 'rewards/chosen': 0.507153332233429, 'rewards/rejected': 0.08211364597082138, 'rewards/accuracies': 0.6625000238418579, 'rewards/margins': 0.42473143339157104, 'logps/chosen': -199.875, 'logps/rejected': -109.3812484741211, 'logits/chosen': -6.553124904632568, 'logits/rejected': -6.759375095367432, 'epoch': 0.49}
 16%|█▋        | 310/1881 [41:52<3:43:42,  8.54s/it] 17%|█▋        | 311/1881 [42:00<3:39:40,  8.40s/it] 17%|█▋        | 312/1881 [42:06<3:18:39,  7.60s/it] 17%|█▋        | 313/1881 [42:14<3:21:23,  7.71s/it]
  0%|          | 0/120 [00:00<?, ?it/s][A
  2%|▏         | 2/120 [00:01<01:23,  1.41it/s][A
  2%|▎         | 3/120 [00:03<02:04,  1.07s/it][A
  3%|▎         | 4/120 [00:04<02:23,  1.24s/it][A
  4%|▍         | 5/120 [00:06<02:36,  1.36s/it][A
  5%|▌         | 6/120 [00:07<02:40,  1.41s/it][A
  6%|▌         | 7/120 [00:10<03:49,  2.03s/it][A
  7%|▋         | 8/120 [00:13<03:50,  2.06s/it][A
  8%|▊         | 9/120 [00:17<04:51,  2.63s/it][A
  8%|▊         | 10/120 [00:18<04:16,  2.33s/it][A
  9%|▉         | 11/120 [00:20<03:48,  2.09s/it][A
 10%|█         | 12/120 [00:21<03:31,  1.96s/it][A
 11%|█         | 13/120 [00:25<04:14,  2.37s/it][A
 12%|█▏        | 14/120 [00:26<03:47,  2.14s/it][A
 12%|█▎        | 15/120 [00:29<04:00,  2.29s/it][A
 13%|█▎        | 16/120 [00:33<04:41,  2.71s/it][A
 14%|█▍        | 17/120 [00:36<05:14,  3.05s/it][A
 15%|█▌        | 18/120 [00:40<05:36,  3.30s/it][A
 16%|█▌        | 19/120 [00:43<05:19,  3.16s/it][A
 17%|█▋        | 20/120 [00:47<05:29,  3.29s/it][A
 18%|█▊        | 21/120 [00:48<04:39,  2.82s/it][A
 18%|█▊        | 22/120 [00:51<04:20,  2.66s/it][A
 19%|█▉        | 23/120 [00:55<04:53,  3.03s/it][A
 20%|██        | 24/120 [00:58<04:53,  3.06s/it][A
 21%|██        | 25/120 [01:01<04:57,  3.13s/it][A
 22%|██▏       | 26/120 [01:03<04:09,  2.66s/it][A
 22%|██▎       | 27/120 [01:06<04:35,  2.96s/it][A
 23%|██▎       | 28/120 [01:07<03:41,  2.41s/it][A
 24%|██▍       | 29/120 [01:09<02:58,  1.96s/it][A
 25%|██▌       | 30/120 [01:10<02:37,  1.75s/it][A
 26%|██▌       | 31/120 [01:10<02:03,  1.39s/it][A
 27%|██▋       | 32/120 [01:11<01:53,  1.29s/it][A
 28%|██▊       | 33/120 [01:12<01:36,  1.11s/it][A
 28%|██▊       | 34/120 [01:13<01:36,  1.12s/it][A
 29%|██▉       | 35/120 [01:14<01:30,  1.07s/it][A
 30%|███       | 36/120 [01:15<01:25,  1.02s/it][A
 31%|███       | 37/120 [01:16<01:27,  1.06s/it][A
 32%|███▏      | 38/120 [01:17<01:31,  1.12s/it][A
 32%|███▎      | 39/120 [01:19<01:31,  1.13s/it][A
 33%|███▎      | 40/120 [01:19<01:19,  1.01it/s][A
 34%|███▍      | 41/120 [01:21<01:36,  1.22s/it][A
 35%|███▌      | 42/120 [01:23<01:59,  1.53s/it][A
 36%|███▌      | 43/120 [01:25<01:52,  1.46s/it][A
 37%|███▋      | 44/120 [01:26<01:58,  1.56s/it][A
 38%|███▊      | 45/120 [01:27<01:47,  1.43s/it][A
 38%|███▊      | 46/120 [01:28<01:38,  1.33s/it][A
 39%|███▉      | 47/120 [01:30<01:32,  1.26s/it][A
 40%|████      | 48/120 [01:30<01:18,  1.09s/it][A
 41%|████      | 49/120 [01:31<01:20,  1.13s/it][A
 42%|████▏     | 50/120 [01:35<02:04,  1.78s/it][A
 42%|████▎     | 51/120 [01:36<01:55,  1.68s/it][A
 43%|████▎     | 52/120 [01:37<01:32,  1.35s/it][A
 44%|████▍     | 53/120 [01:38<01:19,  1.18s/it][A
 45%|████▌     | 54/120 [01:38<01:07,  1.02s/it][A
 46%|████▌     | 55/120 [01:39<01:04,  1.01it/s][A
 47%|████▋     | 56/120 [01:40<00:54,  1.17it/s][A
 48%|████▊     | 57/120 [01:40<00:46,  1.37it/s][A
 48%|████▊     | 58/120 [01:41<00:53,  1.15it/s][A
 49%|████▉     | 59/120 [01:43<01:07,  1.10s/it][A
 50%|█████     | 60/120 [01:44<01:08,  1.14s/it][A
 51%|█████     | 61/120 [01:45<00:57,  1.03it/s][A
 52%|█████▏    | 62/120 [01:46<01:06,  1.15s/it][A
 52%|█████▎    | 63/120 [01:47<00:57,  1.01s/it][A
 53%|█████▎    | 64/120 [01:50<01:35,  1.70s/it][A
 54%|█████▍    | 65/120 [01:54<01:59,  2.17s/it][A
 55%|█████▌    | 66/120 [01:55<01:41,  1.89s/it][A
 56%|█████▌    | 67/120 [01:56<01:22,  1.56s/it][A
 57%|█████▋    | 68/120 [01:57<01:09,  1.34s/it][A
 57%|█████▊    | 69/120 [01:57<01:01,  1.20s/it][A
 58%|█████▊    | 70/120 [01:59<01:03,  1.27s/it][A
 59%|█████▉    | 71/120 [02:01<01:04,  1.32s/it][A
 60%|██████    | 72/120 [02:01<00:55,  1.15s/it][A
 61%|██████    | 73/120 [02:02<00:46,  1.01it/s][A
 62%|██████▏   | 74/120 [02:02<00:40,  1.14it/s][A
 62%|██████▎   | 75/120 [02:03<00:40,  1.10it/s][A
 63%|██████▎   | 76/120 [02:05<00:48,  1.11s/it][A
 64%|██████▍   | 77/120 [02:06<00:48,  1.12s/it][A
 65%|██████▌   | 78/120 [02:07<00:44,  1.05s/it][A
 66%|██████▌   | 79/120 [02:09<00:52,  1.27s/it][A
 67%|██████▋   | 80/120 [02:10<00:45,  1.13s/it][A
 68%|██████▊   | 81/120 [02:13<01:08,  1.74s/it][A
 68%|██████▊   | 82/120 [02:13<00:51,  1.37s/it][A
 69%|██████▉   | 83/120 [02:15<00:55,  1.51s/it][A
 70%|███████   | 84/120 [02:16<00:54,  1.52s/it][A
 71%|███████   | 85/120 [02:17<00:43,  1.25s/it][A
 72%|███████▏  | 86/120 [02:18<00:39,  1.17s/it][A
 72%|███████▎  | 87/120 [02:19<00:41,  1.26s/it][A
 73%|███████▎  | 88/120 [02:21<00:41,  1.29s/it][A
 74%|███████▍  | 89/120 [02:23<00:43,  1.40s/it][A
 75%|███████▌  | 90/120 [02:23<00:34,  1.14s/it][A
 76%|███████▌  | 91/120 [02:27<00:54,  1.88s/it][A
 77%|███████▋  | 92/120 [02:28<00:50,  1.79s/it][A
 78%|███████▊  | 93/120 [02:30<00:47,  1.76s/it][A
 78%|███████▊  | 94/120 [02:31<00:40,  1.56s/it][A
 79%|███████▉  | 95/120 [02:32<00:33,  1.33s/it][A
 80%|████████  | 96/120 [02:33<00:29,  1.23s/it][A
 81%|████████  | 97/120 [02:34<00:30,  1.35s/it][A
 82%|████████▏ | 98/120 [02:37<00:34,  1.55s/it][A
 82%|████████▎ | 99/120 [02:38<00:32,  1.56s/it][A
 83%|████████▎ | 100/120 [02:42<00:45,  2.30s/it][A
 84%|████████▍ | 101/120 [02:44<00:39,  2.06s/it][A
 85%|████████▌ | 102/120 [02:45<00:34,  1.91s/it][A
 86%|████████▌ | 103/120 [02:46<00:25,  1.53s/it][A
 87%|████████▋ | 104/120 [02:47<00:23,  1.44s/it][A
 88%|████████▊ | 105/120 [02:48<00:20,  1.35s/it][A
 88%|████████▊ | 106/120 [02:49<00:17,  1.24s/it][A
 89%|████████▉ | 107/120 [02:51<00:17,  1.34s/it][A
 90%|█████████ | 108/120 [02:53<00:20,  1.71s/it][A
 91%|█████████ | 109/120 [02:54<00:15,  1.45s/it][A
 92%|█████████▏| 110/120 [02:55<00:12,  1.28s/it][A
 92%|█████████▎| 111/120 [02:57<00:12,  1.40s/it][A
 93%|█████████▎| 112/120 [02:58<00:10,  1.35s/it][A
 94%|█████████▍| 113/120 [02:59<00:09,  1.41s/it][A
 95%|█████████▌| 114/120 [03:02<00:11,  1.90s/it][A
 96%|█████████▌| 115/120 [03:04<00:08,  1.74s/it][A
 97%|█████████▋| 116/120 [03:05<00:05,  1.48s/it][A
 98%|█████████▊| 117/120 [03:06<00:04,  1.36s/it][A
 98%|█████████▊| 118/120 [03:07<00:02,  1.43s/it][A
 99%|█████████▉| 119/120 [03:08<00:01,  1.26s/it][A
100%|██████████| 120/120 [03:10<00:00,  1.37s/it][A                                                    
                                                 [A{'eval_loss': 0.5531178712844849, 'eval_runtime': 192.6404, 'eval_samples_per_second': 4.947, 'eval_steps_per_second': 0.623, 'eval_rewards/chosen': 1.0666778087615967, 'eval_rewards/rejected': 0.29777273535728455, 'eval_rewards/accuracies': 0.7760416865348816, 'eval_rewards/margins': 0.7680844664573669, 'eval_logps/chosen': -372.9333190917969, 'eval_logps/rejected': -150.6359405517578, 'eval_logits/chosen': -6.0528645515441895, 'eval_logits/rejected': -6.9513020515441895, 'epoch': 0.5}
 17%|█▋        | 313/1881 [45:26<3:21:23,  7.71s/it]
100%|██████████| 120/120 [03:11<00:00,  1.37s/it][A
                                                 [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 17%|█▋        | 314/1881 [45:48<30:21:58, 69.76s/it] 17%|█▋        | 315/1881 [45:58<22:35:39, 51.94s/it] 17%|█▋        | 316/1881 [46:04<16:33:23, 38.09s/it] 17%|█▋        | 317/1881 [46:12<12:34:51, 28.96s/it] 17%|█▋        | 318/1881 [46:18<9:32:36, 21.98s/it]  17%|█▋        | 319/1881 [46:25<7:41:41, 17.73s/it] 17%|█▋        | 320/1881 [46:36<6:44:10, 15.54s/it]                                                    {'loss': 0.6552, 'grad_norm': 60.94828414916992, 'learning_rate': 2.0350877192982456e-07, 'rewards/chosen': 0.789501965045929, 'rewards/rejected': 0.309439092874527, 'rewards/accuracies': 0.625, 'rewards/margins': 0.48096925020217896, 'logps/chosen': -264.7124938964844, 'logps/rejected': -222.71249389648438, 'logits/chosen': -6.349999904632568, 'logits/rejected': -6.604687690734863, 'epoch': 0.51}
 17%|█▋        | 320/1881 [46:36<6:44:10, 15.54s/it] 17%|█▋        | 321/1881 [46:43<5:39:55, 13.07s/it] 17%|█▋        | 322/1881 [46:49<4:43:16, 10.90s/it] 17%|█▋        | 323/1881 [46:57<4:24:26, 10.18s/it] 17%|█▋        | 324/1881 [47:05<4:06:59,  9.52s/it] 17%|█▋        | 325/1881 [47:12<3:40:29,  8.50s/it] 17%|█▋        | 326/1881 [47:19<3:29:52,  8.10s/it] 17%|█▋        | 327/1881 [47:32<4:08:02,  9.58s/it] 17%|█▋        | 328/1881 [47:38<3:44:51,  8.69s/it] 17%|█▋        | 329/1881 [47:46<3:34:56,  8.31s/it] 18%|█▊        | 330/1881 [47:53<3:25:23,  7.95s/it]                                                    {'loss': 0.6152, 'grad_norm': 40.370643615722656, 'learning_rate': 2.098883572567783e-07, 'rewards/chosen': 1.100439429283142, 'rewards/rejected': 0.3498641848564148, 'rewards/accuracies': 0.65625, 'rewards/margins': 0.7507537603378296, 'logps/chosen': -399.0625, 'logps/rejected': -218.9562530517578, 'logits/chosen': -6.395312309265137, 'logits/rejected': -6.4140625, 'epoch': 0.53}
 18%|█▊        | 330/1881 [47:53<3:25:23,  7.95s/it] 18%|█▊        | 331/1881 [48:04<3:52:09,  8.99s/it] 18%|█▊        | 332/1881 [48:14<4:01:06,  9.34s/it] 18%|█▊        | 333/1881 [48:25<4:09:13,  9.66s/it] 18%|█▊        | 334/1881 [48:30<3:37:00,  8.42s/it] 18%|█▊        | 335/1881 [48:38<3:30:35,  8.17s/it] 18%|█▊        | 336/1881 [48:43<3:09:48,  7.37s/it] 18%|█▊        | 337/1881 [48:49<2:54:04,  6.76s/it] 18%|█▊        | 338/1881 [48:57<3:03:00,  7.12s/it] 18%|█▊        | 339/1881 [49:04<3:06:48,  7.27s/it] 18%|█▊        | 340/1881 [49:09<2:47:57,  6.54s/it]                                                    {'loss': 0.5776, 'grad_norm': 38.188716888427734, 'learning_rate': 2.1626794258373206e-07, 'rewards/chosen': 0.864453136920929, 'rewards/rejected': 0.33766937255859375, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.526123046875, 'logps/chosen': -251.33749389648438, 'logps/rejected': -170.6999969482422, 'logits/chosen': -6.364062309265137, 'logits/rejected': -6.543749809265137, 'epoch': 0.54}
 18%|█▊        | 340/1881 [49:09<2:47:57,  6.54s/it] 18%|█▊        | 341/1881 [49:20<3:16:55,  7.67s/it] 18%|█▊        | 342/1881 [49:26<3:05:19,  7.22s/it] 18%|█▊        | 343/1881 [49:36<3:32:05,  8.27s/it] 18%|█▊        | 344/1881 [49:42<3:13:23,  7.55s/it] 18%|█▊        | 345/1881 [49:49<3:08:49,  7.38s/it] 18%|█▊        | 346/1881 [49:56<3:01:26,  7.09s/it] 18%|█▊        | 347/1881 [50:07<3:35:53,  8.44s/it] 19%|█▊        | 348/1881 [50:18<3:52:13,  9.09s/it] 19%|█▊        | 349/1881 [50:26<3:44:44,  8.80s/it] 19%|█▊        | 350/1881 [50:31<3:15:35,  7.67s/it]                                                    {'loss': 0.5653, 'grad_norm': 47.08973693847656, 'learning_rate': 2.226475279106858e-07, 'rewards/chosen': 0.736376941204071, 'rewards/rejected': 0.15957336127758026, 'rewards/accuracies': 0.7562500238418579, 'rewards/margins': 0.5773162841796875, 'logps/chosen': -226.25, 'logps/rejected': -146.21249389648438, 'logits/chosen': -6.378125190734863, 'logits/rejected': -6.770312309265137, 'epoch': 0.56}
 19%|█▊        | 350/1881 [50:31<3:15:35,  7.67s/it] 19%|█▊        | 351/1881 [50:38<3:09:15,  7.42s/it] 19%|█▊        | 352/1881 [50:45<3:02:51,  7.18s/it] 19%|█▉        | 353/1881 [50:56<3:32:24,  8.34s/it] 19%|█▉        | 354/1881 [51:08<4:02:19,  9.52s/it] 19%|█▉        | 355/1881 [51:19<4:17:08, 10.11s/it] 19%|█▉        | 356/1881 [51:26<3:49:46,  9.04s/it] 19%|█▉        | 357/1881 [51:32<3:30:18,  8.28s/it] 19%|█▉        | 358/1881 [51:40<3:23:03,  8.00s/it] 19%|█▉        | 359/1881 [51:48<3:24:56,  8.08s/it] 19%|█▉        | 360/1881 [51:55<3:14:43,  7.68s/it]                                                    {'loss': 0.6187, 'grad_norm': 50.58777618408203, 'learning_rate': 2.2902711323763953e-07, 'rewards/chosen': 0.9341796636581421, 'rewards/rejected': 0.276275634765625, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.657885730266571, 'logps/chosen': -257.7250061035156, 'logps/rejected': -184.1999969482422, 'logits/chosen': -6.439062595367432, 'logits/rejected': -6.381249904632568, 'epoch': 0.57}
 19%|█▉        | 360/1881 [51:55<3:14:43,  7.68s/it] 19%|█▉        | 361/1881 [52:03<3:22:17,  7.99s/it] 19%|█▉        | 362/1881 [52:11<3:17:11,  7.79s/it] 19%|█▉        | 363/1881 [52:21<3:38:36,  8.64s/it] 19%|█▉        | 364/1881 [52:27<3:11:39,  7.58s/it] 19%|█▉        | 365/1881 [52:34<3:12:27,  7.62s/it] 19%|█▉        | 366/1881 [52:46<3:40:22,  8.73s/it] 20%|█▉        | 367/1881 [52:52<3:21:52,  8.00s/it] 20%|█▉        | 368/1881 [53:02<3:37:42,  8.63s/it] 20%|█▉        | 369/1881 [53:14<4:02:01,  9.60s/it] 20%|█▉        | 370/1881 [53:27<4:31:49, 10.79s/it]                                                    {'loss': 0.5844, 'grad_norm': 48.77742385864258, 'learning_rate': 2.3540669856459328e-07, 'rewards/chosen': 1.599218726158142, 'rewards/rejected': 0.331298828125, 'rewards/accuracies': 0.6875, 'rewards/margins': 1.2678558826446533, 'logps/chosen': -414.2250061035156, 'logps/rejected': -225.9250030517578, 'logits/chosen': -6.256249904632568, 'logits/rejected': -6.329687595367432, 'epoch': 0.59}
 20%|█▉        | 370/1881 [53:27<4:31:49, 10.79s/it] 20%|█▉        | 371/1881 [53:35<4:10:01,  9.93s/it] 20%|█▉        | 372/1881 [53:42<3:45:12,  8.95s/it] 20%|█▉        | 373/1881 [53:57<4:27:37, 10.65s/it] 20%|█▉        | 374/1881 [54:08<4:31:41, 10.82s/it] 20%|█▉        | 375/1881 [54:15<4:07:20,  9.85s/it] 20%|█▉        | 376/1881 [54:28<4:28:53, 10.72s/it] 20%|██        | 377/1881 [54:39<4:32:55, 10.89s/it] 20%|██        | 378/1881 [54:45<3:56:20,  9.43s/it] 20%|██        | 379/1881 [54:53<3:39:14,  8.76s/it] 20%|██        | 380/1881 [55:03<3:53:39,  9.34s/it]                                                    {'loss': 0.6068, 'grad_norm': 48.548641204833984, 'learning_rate': 2.4178628389154703e-07, 'rewards/chosen': 1.438574194908142, 'rewards/rejected': 0.34600526094436646, 'rewards/accuracies': 0.6937500238418579, 'rewards/margins': 1.0907471179962158, 'logps/chosen': -381.5249938964844, 'logps/rejected': -210.0, 'logits/chosen': -6.259375095367432, 'logits/rejected': -6.240624904632568, 'epoch': 0.61}
 20%|██        | 380/1881 [55:04<3:53:39,  9.34s/it] 20%|██        | 381/1881 [55:09<3:23:17,  8.13s/it] 20%|██        | 382/1881 [55:14<3:01:13,  7.25s/it] 20%|██        | 383/1881 [55:24<3:20:59,  8.05s/it] 20%|██        | 384/1881 [55:36<3:55:37,  9.44s/it] 20%|██        | 385/1881 [55:47<4:03:29,  9.77s/it] 21%|██        | 386/1881 [55:54<3:42:48,  8.94s/it] 21%|██        | 387/1881 [56:02<3:38:03,  8.76s/it] 21%|██        | 388/1881 [56:13<3:55:25,  9.46s/it] 21%|██        | 389/1881 [56:28<4:31:54, 10.93s/it] 21%|██        | 390/1881 [56:38<4:25:57, 10.70s/it]                                                    {'loss': 0.5778, 'grad_norm': 46.97720718383789, 'learning_rate': 2.4816586921850075e-07, 'rewards/chosen': 1.060449242591858, 'rewards/rejected': 0.23412171006202698, 'rewards/accuracies': 0.6812499761581421, 'rewards/margins': 0.825695812702179, 'logps/chosen': -268.7124938964844, 'logps/rejected': -141.9375, 'logits/chosen': -6.479687690734863, 'logits/rejected': -6.640625, 'epoch': 0.62}
 21%|██        | 390/1881 [56:38<4:25:57, 10.70s/it] 21%|██        | 391/1881 [56:45<3:59:40,  9.65s/it] 21%|██        | 392/1881 [56:51<3:34:05,  8.63s/it] 21%|██        | 393/1881 [57:03<3:59:11,  9.64s/it] 21%|██        | 394/1881 [57:10<3:33:10,  8.60s/it] 21%|██        | 395/1881 [57:25<4:23:07, 10.62s/it] 21%|██        | 396/1881 [57:31<3:48:56,  9.25s/it] 21%|██        | 397/1881 [57:38<3:30:23,  8.51s/it] 21%|██        | 398/1881 [57:48<3:43:44,  9.05s/it] 21%|██        | 399/1881 [57:56<3:34:55,  8.70s/it] 21%|██▏       | 400/1881 [58:00<3:01:32,  7.35s/it]                                                    {'loss': 0.586, 'grad_norm': 35.30134582519531, 'learning_rate': 2.5454545454545453e-07, 'rewards/chosen': 1.104101538658142, 'rewards/rejected': 0.30117493867874146, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.804492175579071, 'logps/chosen': -306.70001220703125, 'logps/rejected': -177.7375030517578, 'logits/chosen': -6.442187309265137, 'logits/rejected': -6.381249904632568, 'epoch': 0.64}
 21%|██▏       | 400/1881 [58:00<3:01:32,  7.35s/it] 21%|██▏       | 401/1881 [58:06<2:51:06,  6.94s/it] 21%|██▏       | 402/1881 [58:14<3:00:57,  7.34s/it] 21%|██▏       | 403/1881 [58:21<2:58:25,  7.24s/it] 21%|██▏       | 404/1881 [58:29<3:01:59,  7.39s/it] 22%|██▏       | 405/1881 [58:39<3:22:09,  8.22s/it] 22%|██▏       | 406/1881 [58:48<3:27:56,  8.46s/it] 22%|██▏       | 407/1881 [59:00<3:50:42,  9.39s/it] 22%|██▏       | 408/1881 [59:05<3:18:34,  8.09s/it] 22%|██▏       | 409/1881 [59:11<3:01:29,  7.40s/it] 22%|██▏       | 410/1881 [59:19<3:08:47,  7.70s/it]                                                    {'loss': 0.613, 'grad_norm': 47.35227584838867, 'learning_rate': 2.609250398724083e-07, 'rewards/chosen': 0.80999755859375, 'rewards/rejected': 0.18049010634422302, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.6292144656181335, 'logps/chosen': -208.375, 'logps/rejected': -136.47500610351562, 'logits/chosen': -6.542187690734863, 'logits/rejected': -6.5390625, 'epoch': 0.65}
 22%|██▏       | 410/1881 [59:19<3:08:47,  7.70s/it] 22%|██▏       | 411/1881 [59:25<2:54:33,  7.12s/it] 22%|██▏       | 412/1881 [59:33<3:03:35,  7.50s/it] 22%|██▏       | 413/1881 [59:45<3:35:14,  8.80s/it] 22%|██▏       | 414/1881 [59:58<4:07:09, 10.11s/it] 22%|██▏       | 415/1881 [1:00:11<4:23:28, 10.78s/it] 22%|██▏       | 416/1881 [1:00:22<4:29:15, 11.03s/it] 22%|██▏       | 417/1881 [1:00:30<4:04:11, 10.01s/it] 22%|██▏       | 418/1881 [1:00:36<3:33:28,  8.75s/it] 22%|██▏       | 419/1881 [1:00:48<3:55:43,  9.67s/it] 22%|██▏       | 420/1881 [1:00:55<3:39:56,  9.03s/it]                                                      {'loss': 0.57, 'grad_norm': 47.70219421386719, 'learning_rate': 2.6730462519936203e-07, 'rewards/chosen': 1.6797363758087158, 'rewards/rejected': 0.36794739961624146, 'rewards/accuracies': 0.71875, 'rewards/margins': 1.3121337890625, 'logps/chosen': -397.4750061035156, 'logps/rejected': -188.0500030517578, 'logits/chosen': -6.170312404632568, 'logits/rejected': -6.390625, 'epoch': 0.67}
 22%|██▏       | 420/1881 [1:00:55<3:39:56,  9.03s/it] 22%|██▏       | 421/1881 [1:01:04<3:37:40,  8.95s/it] 22%|██▏       | 422/1881 [1:01:15<3:52:19,  9.55s/it] 22%|██▏       | 423/1881 [1:01:21<3:29:39,  8.63s/it] 23%|██▎       | 424/1881 [1:01:30<3:33:29,  8.79s/it] 23%|██▎       | 425/1881 [1:01:36<3:07:49,  7.74s/it] 23%|██▎       | 426/1881 [1:01:42<2:58:07,  7.35s/it] 23%|██▎       | 427/1881 [1:01:49<2:57:23,  7.32s/it] 23%|██▎       | 428/1881 [1:01:59<3:17:15,  8.15s/it] 23%|██▎       | 429/1881 [1:02:06<3:08:25,  7.79s/it] 23%|██▎       | 430/1881 [1:02:16<3:19:59,  8.27s/it]                                                      {'loss': 0.5737, 'grad_norm': 43.45869064331055, 'learning_rate': 2.736842105263158e-07, 'rewards/chosen': 0.8009277582168579, 'rewards/rejected': 0.296661376953125, 'rewards/accuracies': 0.7124999761581421, 'rewards/margins': 0.503649890422821, 'logps/chosen': -205.10000610351562, 'logps/rejected': -173.47500610351562, 'logits/chosen': -6.625, 'logits/rejected': -6.671875, 'epoch': 0.69}
 23%|██▎       | 430/1881 [1:02:16<3:19:59,  8.27s/it] 23%|██▎       | 431/1881 [1:02:23<3:14:26,  8.05s/it] 23%|██▎       | 432/1881 [1:02:29<2:58:06,  7.38s/it] 23%|██▎       | 433/1881 [1:02:34<2:39:05,  6.59s/it] 23%|██▎       | 434/1881 [1:02:41<2:44:49,  6.83s/it] 23%|██▎       | 435/1881 [1:02:51<3:07:07,  7.76s/it] 23%|██▎       | 436/1881 [1:02:59<3:04:40,  7.67s/it] 23%|██▎       | 437/1881 [1:03:06<2:58:57,  7.44s/it] 23%|██▎       | 438/1881 [1:03:19<3:45:35,  9.38s/it] 23%|██▎       | 439/1881 [1:03:25<3:18:22,  8.25s/it] 23%|██▎       | 440/1881 [1:03:31<3:03:08,  7.63s/it]                                                      {'loss': 0.6143, 'grad_norm': 44.5018196105957, 'learning_rate': 2.8006379585326953e-07, 'rewards/chosen': 0.7643066644668579, 'rewards/rejected': 0.29804307222366333, 'rewards/accuracies': 0.65625, 'rewards/margins': 0.466012567281723, 'logps/chosen': -187.8125, 'logps/rejected': -148.0749969482422, 'logits/chosen': -6.625, 'logits/rejected': -6.606249809265137, 'epoch': 0.7}
 23%|██▎       | 440/1881 [1:03:32<3:03:08,  7.63s/it] 23%|██▎       | 441/1881 [1:03:39<3:01:37,  7.57s/it] 23%|██▎       | 442/1881 [1:03:45<2:53:05,  7.22s/it] 24%|██▎       | 443/1881 [1:03:52<2:49:46,  7.08s/it] 24%|██▎       | 444/1881 [1:04:03<3:18:03,  8.27s/it] 24%|██▎       | 445/1881 [1:04:10<3:12:31,  8.04s/it] 24%|██▎       | 446/1881 [1:04:20<3:23:43,  8.52s/it] 24%|██▍       | 447/1881 [1:04:28<3:22:04,  8.45s/it] 24%|██▍       | 448/1881 [1:04:40<3:41:38,  9.28s/it] 24%|██▍       | 449/1881 [1:04:45<3:11:03,  8.01s/it] 24%|██▍       | 450/1881 [1:04:54<3:21:39,  8.46s/it]                                                      {'loss': 0.5427, 'grad_norm': 44.95859146118164, 'learning_rate': 2.864433811802233e-07, 'rewards/chosen': 0.9521484375, 'rewards/rejected': 0.07676391303539276, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 0.8743652105331421, 'logps/chosen': -209.5749969482422, 'logps/rejected': -137.1125030517578, 'logits/chosen': -6.490624904632568, 'logits/rejected': -6.612500190734863, 'epoch': 0.72}
 24%|██▍       | 450/1881 [1:04:54<3:21:39,  8.46s/it] 24%|██▍       | 451/1881 [1:05:03<3:26:01,  8.64s/it] 24%|██▍       | 452/1881 [1:05:10<3:13:54,  8.14s/it] 24%|██▍       | 453/1881 [1:05:18<3:10:33,  8.01s/it] 24%|██▍       | 454/1881 [1:05:24<2:59:46,  7.56s/it] 24%|██▍       | 455/1881 [1:05:34<3:14:37,  8.19s/it] 24%|██▍       | 456/1881 [1:05:46<3:41:59,  9.35s/it] 24%|██▍       | 457/1881 [1:05:58<3:59:13, 10.08s/it] 24%|██▍       | 458/1881 [1:06:05<3:34:38,  9.05s/it] 24%|██▍       | 459/1881 [1:06:11<3:15:38,  8.26s/it] 24%|██▍       | 460/1881 [1:06:17<3:03:04,  7.73s/it]                                                      {'loss': 0.561, 'grad_norm': 38.3361701965332, 'learning_rate': 2.9282296650717703e-07, 'rewards/chosen': 1.1820800304412842, 'rewards/rejected': 0.210784912109375, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.9732910394668579, 'logps/chosen': -296.54998779296875, 'logps/rejected': -157.6062469482422, 'logits/chosen': -6.248437404632568, 'logits/rejected': -6.496874809265137, 'epoch': 0.73}
 24%|██▍       | 460/1881 [1:06:18<3:03:04,  7.73s/it] 25%|██▍       | 461/1881 [1:06:24<2:57:20,  7.49s/it] 25%|██▍       | 462/1881 [1:06:33<3:04:31,  7.80s/it] 25%|██▍       | 463/1881 [1:06:40<2:56:41,  7.48s/it] 25%|██▍       | 464/1881 [1:06:45<2:42:42,  6.89s/it] 25%|██▍       | 465/1881 [1:06:57<3:16:53,  8.34s/it] 25%|██▍       | 466/1881 [1:07:05<3:14:40,  8.25s/it] 25%|██▍       | 467/1881 [1:07:12<3:07:40,  7.96s/it] 25%|██▍       | 468/1881 [1:07:23<3:29:53,  8.91s/it] 25%|██▍       | 469/1881 [1:07:30<3:10:37,  8.10s/it] 25%|██▍       | 470/1881 [1:07:39<3:17:17,  8.39s/it]                                                      {'loss': 0.5349, 'grad_norm': 41.38029098510742, 'learning_rate': 2.992025518341308e-07, 'rewards/chosen': 1.2958495616912842, 'rewards/rejected': 0.15913543105125427, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 1.1360352039337158, 'logps/chosen': -289.7749938964844, 'logps/rejected': -160.8000030517578, 'logits/chosen': -6.368750095367432, 'logits/rejected': -6.6796875, 'epoch': 0.75}
 25%|██▍       | 470/1881 [1:07:39<3:17:17,  8.39s/it] 25%|██▌       | 471/1881 [1:07:45<2:59:53,  7.66s/it] 25%|██▌       | 472/1881 [1:07:52<2:56:12,  7.50s/it] 25%|██▌       | 473/1881 [1:08:00<3:04:19,  7.85s/it] 25%|██▌       | 474/1881 [1:08:07<2:53:44,  7.41s/it] 25%|██▌       | 475/1881 [1:08:18<3:19:29,  8.51s/it] 25%|██▌       | 476/1881 [1:08:30<3:44:40,  9.59s/it] 25%|██▌       | 477/1881 [1:08:38<3:31:14,  9.03s/it] 25%|██▌       | 478/1881 [1:08:45<3:18:24,  8.49s/it] 25%|██▌       | 479/1881 [1:08:55<3:31:28,  9.05s/it] 26%|██▌       | 480/1881 [1:09:05<3:39:07,  9.38s/it]                                                      {'loss': 0.5512, 'grad_norm': 56.89042282104492, 'learning_rate': 3.055821371610845e-07, 'rewards/chosen': 1.542565941810608, 'rewards/rejected': 0.46174317598342896, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 1.079290747642517, 'logps/chosen': -321.0625, 'logps/rejected': -192.78750610351562, 'logits/chosen': -6.464062690734863, 'logits/rejected': -6.578125, 'epoch': 0.76}
 26%|██▌       | 480/1881 [1:09:06<3:39:07,  9.38s/it] 26%|██▌       | 481/1881 [1:09:12<3:20:23,  8.59s/it] 26%|██▌       | 482/1881 [1:09:18<3:02:08,  7.81s/it] 26%|██▌       | 483/1881 [1:09:25<2:54:17,  7.48s/it] 26%|██▌       | 484/1881 [1:09:34<3:08:07,  8.08s/it] 26%|██▌       | 485/1881 [1:09:41<2:55:24,  7.54s/it] 26%|██▌       | 486/1881 [1:09:48<2:54:22,  7.50s/it] 26%|██▌       | 487/1881 [1:09:57<3:02:41,  7.86s/it] 26%|██▌       | 488/1881 [1:10:07<3:16:31,  8.46s/it] 26%|██▌       | 489/1881 [1:10:16<3:23:14,  8.76s/it] 26%|██▌       | 490/1881 [1:10:22<3:06:19,  8.04s/it]                                                      {'loss': 0.5269, 'grad_norm': 65.45755004882812, 'learning_rate': 3.1196172248803825e-07, 'rewards/chosen': 0.752392590045929, 'rewards/rejected': 0.05454406887292862, 'rewards/accuracies': 0.737500011920929, 'rewards/margins': 0.6982177495956421, 'logps/chosen': -178.4250030517578, 'logps/rejected': -129.5, 'logits/chosen': -6.599999904632568, 'logits/rejected': -6.6875, 'epoch': 0.78}
 26%|██▌       | 490/1881 [1:10:23<3:06:19,  8.04s/it] 26%|██▌       | 491/1881 [1:10:30<3:05:33,  8.01s/it] 26%|██▌       | 492/1881 [1:10:40<3:13:45,  8.37s/it] 26%|██▌       | 493/1881 [1:10:46<3:03:16,  7.92s/it] 26%|██▋       | 494/1881 [1:10:54<3:02:43,  7.90s/it] 26%|██▋       | 495/1881 [1:11:02<3:00:48,  7.83s/it] 26%|██▋       | 496/1881 [1:11:08<2:49:55,  7.36s/it] 26%|██▋       | 497/1881 [1:11:15<2:43:49,  7.10s/it] 26%|██▋       | 498/1881 [1:11:23<2:52:03,  7.46s/it] 27%|██▋       | 499/1881 [1:11:29<2:44:54,  7.16s/it] 27%|██▋       | 500/1881 [1:11:35<2:36:46,  6.81s/it]                                                      {'loss': 0.5581, 'grad_norm': 38.33194351196289, 'learning_rate': 3.18341307814992e-07, 'rewards/chosen': 1.0458495616912842, 'rewards/rejected': 0.0714874267578125, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.976269543170929, 'logps/chosen': -216.72500610351562, 'logps/rejected': -135.1125030517578, 'logits/chosen': -6.817187309265137, 'logits/rejected': -6.887499809265137, 'epoch': 0.8}
 27%|██▋       | 500/1881 [1:11:36<2:36:46,  6.81s/it] 27%|██▋       | 501/1881 [1:11:41<2:29:35,  6.50s/it] 27%|██▋       | 502/1881 [1:11:48<2:32:00,  6.61s/it] 27%|██▋       | 503/1881 [1:11:57<2:44:37,  7.17s/it] 27%|██▋       | 504/1881 [1:12:05<2:49:54,  7.40s/it] 27%|██▋       | 505/1881 [1:12:12<2:53:01,  7.54s/it] 27%|██▋       | 506/1881 [1:12:18<2:42:12,  7.08s/it] 27%|██▋       | 507/1881 [1:12:25<2:38:44,  6.93s/it] 27%|██▋       | 508/1881 [1:12:32<2:42:09,  7.09s/it] 27%|██▋       | 509/1881 [1:12:40<2:43:40,  7.16s/it] 27%|██▋       | 510/1881 [1:12:44<2:26:10,  6.40s/it]                                                      {'loss': 0.5275, 'grad_norm': 37.16682052612305, 'learning_rate': 3.2472089314194575e-07, 'rewards/chosen': 1.3922851085662842, 'rewards/rejected': 0.23175659775733948, 'rewards/accuracies': 0.7250000238418579, 'rewards/margins': 1.159521460533142, 'logps/chosen': -277.5249938964844, 'logps/rejected': -167.39999389648438, 'logits/chosen': -6.704687595367432, 'logits/rejected': -6.606249809265137, 'epoch': 0.81}
 27%|██▋       | 510/1881 [1:12:45<2:26:10,  6.40s/it] 27%|██▋       | 511/1881 [1:12:48<2:10:24,  5.71s/it] 27%|██▋       | 512/1881 [1:12:57<2:31:19,  6.63s/it] 27%|██▋       | 513/1881 [1:13:05<2:39:00,  6.97s/it] 27%|██▋       | 514/1881 [1:13:12<2:42:19,  7.12s/it] 27%|██▋       | 515/1881 [1:13:22<2:56:06,  7.74s/it] 27%|██▋       | 516/1881 [1:13:35<3:35:27,  9.47s/it] 27%|██▋       | 517/1881 [1:13:43<3:26:57,  9.10s/it] 28%|██▊       | 518/1881 [1:13:49<2:59:37,  7.91s/it] 28%|██▊       | 519/1881 [1:13:59<3:15:34,  8.62s/it] 28%|██▊       | 520/1881 [1:14:05<2:56:36,  7.79s/it]                                                      {'loss': 0.4987, 'grad_norm': 41.014564514160156, 'learning_rate': 3.3110047846889953e-07, 'rewards/chosen': 0.839062511920929, 'rewards/rejected': 0.04287109524011612, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 0.795855700969696, 'logps/chosen': -164.0124969482422, 'logps/rejected': -110.0, 'logits/chosen': -6.689062595367432, 'logits/rejected': -6.71875, 'epoch': 0.83}
 28%|██▊       | 520/1881 [1:14:05<2:56:36,  7.79s/it] 28%|██▊       | 521/1881 [1:14:14<3:08:28,  8.31s/it] 28%|██▊       | 522/1881 [1:14:26<3:31:16,  9.33s/it] 28%|██▊       | 523/1881 [1:14:34<3:19:39,  8.82s/it] 28%|██▊       | 524/1881 [1:14:41<3:09:18,  8.37s/it] 28%|██▊       | 525/1881 [1:14:48<3:00:53,  8.00s/it] 28%|██▊       | 526/1881 [1:14:56<3:02:33,  8.08s/it] 28%|██▊       | 527/1881 [1:15:07<3:18:04,  8.78s/it] 28%|██▊       | 528/1881 [1:15:12<2:54:56,  7.76s/it] 28%|██▊       | 529/1881 [1:15:18<2:41:31,  7.17s/it] 28%|██▊       | 530/1881 [1:15:24<2:36:18,  6.94s/it]                                                      {'loss': 0.4876, 'grad_norm': 33.06938934326172, 'learning_rate': 3.3748006379585325e-07, 'rewards/chosen': 1.7318115234375, 'rewards/rejected': 0.12181167304515839, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.6098144054412842, 'logps/chosen': -310.3374938964844, 'logps/rejected': -177.71875, 'logits/chosen': -6.732812404632568, 'logits/rejected': -6.810937404632568, 'epoch': 0.84}
 28%|██▊       | 530/1881 [1:15:24<2:36:18,  6.94s/it] 28%|██▊       | 531/1881 [1:15:35<3:04:19,  8.19s/it] 28%|██▊       | 532/1881 [1:15:42<2:52:27,  7.67s/it] 28%|██▊       | 533/1881 [1:15:49<2:49:15,  7.53s/it] 28%|██▊       | 534/1881 [1:15:56<2:43:50,  7.30s/it] 28%|██▊       | 535/1881 [1:16:04<2:50:41,  7.61s/it] 28%|██▊       | 536/1881 [1:16:12<2:52:45,  7.71s/it] 29%|██▊       | 537/1881 [1:16:19<2:44:22,  7.34s/it] 29%|██▊       | 538/1881 [1:16:26<2:46:41,  7.45s/it] 29%|██▊       | 539/1881 [1:16:32<2:37:44,  7.05s/it] 29%|██▊       | 540/1881 [1:16:40<2:41:33,  7.23s/it]                                                      {'loss': 0.4769, 'grad_norm': 26.780813217163086, 'learning_rate': 3.43859649122807e-07, 'rewards/chosen': 1.4697265625, 'rewards/rejected': 0.28520506620407104, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.183691382408142, 'logps/chosen': -261.7124938964844, 'logps/rejected': -163.0437469482422, 'logits/chosen': -6.564062595367432, 'logits/rejected': -6.775000095367432, 'epoch': 0.86}
 29%|██▊       | 540/1881 [1:16:40<2:41:33,  7.23s/it] 29%|██▉       | 541/1881 [1:16:49<2:53:10,  7.75s/it] 29%|██▉       | 542/1881 [1:16:56<2:47:59,  7.53s/it] 29%|██▉       | 543/1881 [1:17:02<2:37:32,  7.06s/it] 29%|██▉       | 544/1881 [1:17:08<2:31:10,  6.78s/it] 29%|██▉       | 545/1881 [1:17:14<2:27:47,  6.64s/it] 29%|██▉       | 546/1881 [1:17:21<2:30:34,  6.77s/it] 29%|██▉       | 547/1881 [1:17:28<2:28:30,  6.68s/it] 29%|██▉       | 548/1881 [1:17:39<2:55:03,  7.88s/it] 29%|██▉       | 549/1881 [1:17:45<2:42:43,  7.33s/it] 29%|██▉       | 550/1881 [1:17:51<2:34:51,  6.98s/it]                                                      {'loss': 0.5199, 'grad_norm': 28.501850128173828, 'learning_rate': 3.5023923444976075e-07, 'rewards/chosen': 0.657519519329071, 'rewards/rejected': -0.14792481064796448, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.8047851324081421, 'logps/chosen': -130.85000610351562, 'logps/rejected': -101.875, 'logits/chosen': -6.768750190734863, 'logits/rejected': -6.635937690734863, 'epoch': 0.88}
 29%|██▉       | 550/1881 [1:17:51<2:34:51,  6.98s/it] 29%|██▉       | 551/1881 [1:17:58<2:37:19,  7.10s/it] 29%|██▉       | 552/1881 [1:18:04<2:27:42,  6.67s/it] 29%|██▉       | 553/1881 [1:18:11<2:27:24,  6.66s/it] 29%|██▉       | 554/1881 [1:18:16<2:20:29,  6.35s/it] 30%|██▉       | 555/1881 [1:18:23<2:25:00,  6.56s/it] 30%|██▉       | 556/1881 [1:18:31<2:32:17,  6.90s/it] 30%|██▉       | 557/1881 [1:18:41<2:51:44,  7.78s/it] 30%|██▉       | 558/1881 [1:18:47<2:41:16,  7.31s/it] 30%|██▉       | 559/1881 [1:18:59<3:12:16,  8.73s/it] 30%|██▉       | 560/1881 [1:19:07<3:09:04,  8.59s/it]                                                      {'loss': 0.5026, 'grad_norm': 37.103370666503906, 'learning_rate': 3.566188197767145e-07, 'rewards/chosen': 0.943798840045929, 'rewards/rejected': 0.04107666015625, 'rewards/accuracies': 0.7437499761581421, 'rewards/margins': 0.902178943157196, 'logps/chosen': -158.4375, 'logps/rejected': -130.5500030517578, 'logits/chosen': -6.987500190734863, 'logits/rejected': -6.923437595367432, 'epoch': 0.89}
 30%|██▉       | 560/1881 [1:19:08<3:09:04,  8.59s/it] 30%|██▉       | 561/1881 [1:19:14<3:00:01,  8.18s/it] 30%|██▉       | 562/1881 [1:19:23<3:01:04,  8.24s/it] 30%|██▉       | 563/1881 [1:19:29<2:48:46,  7.68s/it] 30%|██▉       | 564/1881 [1:19:37<2:50:14,  7.76s/it] 30%|███       | 565/1881 [1:19:46<3:00:07,  8.21s/it] 30%|███       | 566/1881 [1:19:54<2:58:31,  8.15s/it] 30%|███       | 567/1881 [1:20:03<3:03:58,  8.40s/it] 30%|███       | 568/1881 [1:20:09<2:46:59,  7.63s/it] 30%|███       | 569/1881 [1:20:14<2:30:52,  6.90s/it] 30%|███       | 570/1881 [1:20:25<2:55:05,  8.01s/it]                                                      {'loss': 0.4464, 'grad_norm': 34.06315612792969, 'learning_rate': 3.6299840510366825e-07, 'rewards/chosen': 1.1665527820587158, 'rewards/rejected': -0.11695556342601776, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 1.2822754383087158, 'logps/chosen': -211.58749389648438, 'logps/rejected': -131.8249969482422, 'logits/chosen': -6.673437595367432, 'logits/rejected': -6.935937404632568, 'epoch': 0.91}
 30%|███       | 570/1881 [1:20:25<2:55:05,  8.01s/it] 30%|███       | 571/1881 [1:20:34<2:59:13,  8.21s/it] 30%|███       | 572/1881 [1:20:41<2:55:04,  8.02s/it] 30%|███       | 573/1881 [1:20:51<3:03:31,  8.42s/it] 31%|███       | 574/1881 [1:20:58<2:58:20,  8.19s/it] 31%|███       | 575/1881 [1:21:07<3:02:36,  8.39s/it] 31%|███       | 576/1881 [1:21:14<2:54:58,  8.05s/it] 31%|███       | 577/1881 [1:21:22<2:52:30,  7.94s/it] 31%|███       | 578/1881 [1:21:31<2:59:05,  8.25s/it] 31%|███       | 579/1881 [1:21:37<2:46:02,  7.65s/it] 31%|███       | 580/1881 [1:21:44<2:36:30,  7.22s/it]                                                      {'loss': 0.4648, 'grad_norm': 20.836750030517578, 'learning_rate': 3.69377990430622e-07, 'rewards/chosen': 1.5199706554412842, 'rewards/rejected': 0.09021911770105362, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.4301269054412842, 'logps/chosen': -253.60000610351562, 'logps/rejected': -185.03750610351562, 'logits/chosen': -6.576562404632568, 'logits/rejected': -6.529687404632568, 'epoch': 0.92}
 31%|███       | 580/1881 [1:21:44<2:36:30,  7.22s/it] 31%|███       | 581/1881 [1:21:51<2:36:40,  7.23s/it] 31%|███       | 582/1881 [1:21:59<2:43:32,  7.55s/it] 31%|███       | 583/1881 [1:22:09<2:59:23,  8.29s/it] 31%|███       | 584/1881 [1:22:13<2:33:24,  7.10s/it] 31%|███       | 585/1881 [1:22:21<2:34:13,  7.14s/it] 31%|███       | 586/1881 [1:22:27<2:31:39,  7.03s/it] 31%|███       | 587/1881 [1:22:32<2:17:11,  6.36s/it] 31%|███▏      | 588/1881 [1:22:38<2:11:32,  6.10s/it] 31%|███▏      | 589/1881 [1:22:52<3:04:01,  8.55s/it] 31%|███▏      | 590/1881 [1:22:59<2:54:41,  8.12s/it]                                                      {'loss': 0.5037, 'grad_norm': 53.59603500366211, 'learning_rate': 3.7575757575757575e-07, 'rewards/chosen': 0.525634765625, 'rewards/rejected': -0.3102676272392273, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 0.835772693157196, 'logps/chosen': -98.1875, 'logps/rejected': -90.7249984741211, 'logits/chosen': -6.848437309265137, 'logits/rejected': -6.859375, 'epoch': 0.94}
 31%|███▏      | 590/1881 [1:22:59<2:54:41,  8.12s/it] 31%|███▏      | 591/1881 [1:23:10<3:10:24,  8.86s/it] 31%|███▏      | 592/1881 [1:23:17<2:58:05,  8.29s/it] 32%|███▏      | 593/1881 [1:23:24<2:52:49,  8.05s/it] 32%|███▏      | 594/1881 [1:23:31<2:42:27,  7.57s/it] 32%|███▏      | 595/1881 [1:23:42<3:07:48,  8.76s/it] 32%|███▏      | 596/1881 [1:23:52<3:17:53,  9.24s/it] 32%|███▏      | 597/1881 [1:24:05<3:40:28, 10.30s/it] 32%|███▏      | 598/1881 [1:24:12<3:19:32,  9.33s/it] 32%|███▏      | 599/1881 [1:24:18<2:55:59,  8.24s/it] 32%|███▏      | 600/1881 [1:24:25<2:47:21,  7.84s/it]                                                      {'loss': 0.4251, 'grad_norm': 39.32509231567383, 'learning_rate': 3.8213716108452947e-07, 'rewards/chosen': 1.1483886241912842, 'rewards/rejected': -0.22932128608226776, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 1.377832055091858, 'logps/chosen': -198.21249389648438, 'logps/rejected': -135.75, 'logits/chosen': -7.03125, 'logits/rejected': -7.057812690734863, 'epoch': 0.96}
 32%|███▏      | 600/1881 [1:24:25<2:47:21,  7.84s/it] 32%|███▏      | 601/1881 [1:24:36<3:06:23,  8.74s/it] 32%|███▏      | 602/1881 [1:24:43<2:58:31,  8.37s/it] 32%|███▏      | 603/1881 [1:24:50<2:48:50,  7.93s/it] 32%|███▏      | 604/1881 [1:24:59<2:53:09,  8.14s/it] 32%|███▏      | 605/1881 [1:25:06<2:46:17,  7.82s/it] 32%|███▏      | 606/1881 [1:25:14<2:49:56,  8.00s/it] 32%|███▏      | 607/1881 [1:25:20<2:37:40,  7.43s/it] 32%|███▏      | 608/1881 [1:25:26<2:28:45,  7.01s/it] 32%|███▏      | 609/1881 [1:25:33<2:27:54,  6.98s/it] 32%|███▏      | 610/1881 [1:25:40<2:27:34,  6.97s/it]                                                      {'loss': 0.4308, 'grad_norm': 34.93291091918945, 'learning_rate': 3.885167464114832e-07, 'rewards/chosen': 1.358373999595642, 'rewards/rejected': -0.3520874083042145, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.708105444908142, 'logps/chosen': -236.9875030517578, 'logps/rejected': -146.4250030517578, 'logits/chosen': -6.756249904632568, 'logits/rejected': -6.801562309265137, 'epoch': 0.97}
 32%|███▏      | 610/1881 [1:25:40<2:27:34,  6.97s/it] 32%|███▏      | 611/1881 [1:25:48<2:33:19,  7.24s/it] 33%|███▎      | 612/1881 [1:25:55<2:31:54,  7.18s/it] 33%|███▎      | 613/1881 [1:26:01<2:20:49,  6.66s/it] 33%|███▎      | 614/1881 [1:26:08<2:26:54,  6.96s/it] 33%|███▎      | 615/1881 [1:26:13<2:14:39,  6.38s/it] 33%|███▎      | 616/1881 [1:26:22<2:30:27,  7.14s/it] 33%|███▎      | 617/1881 [1:26:27<2:14:40,  6.39s/it] 33%|███▎      | 618/1881 [1:26:36<2:31:19,  7.19s/it] 33%|███▎      | 619/1881 [1:26:45<2:40:36,  7.64s/it] 33%|███▎      | 620/1881 [1:26:50<2:26:08,  6.95s/it]                                                      {'loss': 0.4383, 'grad_norm': 32.67171859741211, 'learning_rate': 3.9489633173843697e-07, 'rewards/chosen': 1.364501953125, 'rewards/rejected': -0.1053466796875, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 1.470703125, 'logps/chosen': -223.41250610351562, 'logps/rejected': -147.6374969482422, 'logits/chosen': -6.759375095367432, 'logits/rejected': -6.764062404632568, 'epoch': 0.99}
 33%|███▎      | 620/1881 [1:26:50<2:26:08,  6.95s/it] 33%|███▎      | 621/1881 [1:27:01<2:52:29,  8.21s/it] 33%|███▎      | 622/1881 [1:27:12<3:09:55,  9.05s/it] 33%|███▎      | 623/1881 [1:27:27<3:46:37, 10.81s/it] 33%|███▎      | 624/1881 [1:27:36<3:35:56, 10.31s/it] 33%|███▎      | 625/1881 [1:27:41<3:01:06,  8.65s/it] 33%|███▎      | 626/1881 [1:27:48<2:50:55,  8.17s/it]
  0%|          | 0/120 [00:00<?, ?it/s][A
  2%|▏         | 2/120 [00:01<01:25,  1.38it/s][A
  2%|▎         | 3/120 [00:03<02:05,  1.08s/it][A
  3%|▎         | 4/120 [00:04<02:24,  1.24s/it][A
  4%|▍         | 5/120 [00:06<02:36,  1.36s/it][A
  5%|▌         | 6/120 [00:07<02:41,  1.41s/it][A
  6%|▌         | 7/120 [00:11<04:04,  2.16s/it][A
  7%|▋         | 8/120 [00:13<04:01,  2.16s/it][A
  8%|▊         | 9/120 [00:17<04:50,  2.62s/it][A
  8%|▊         | 10/120 [00:19<04:17,  2.34s/it][A
  9%|▉         | 11/120 [00:20<03:48,  2.10s/it][A
 10%|█         | 12/120 [00:22<03:32,  1.96s/it][A
 11%|█         | 13/120 [00:25<04:15,  2.38s/it][A
 12%|█▏        | 14/120 [00:27<03:46,  2.14s/it][A
 12%|█▎        | 15/120 [00:29<03:58,  2.27s/it][A
 13%|█▎        | 16/120 [00:33<04:40,  2.70s/it][A
 14%|█▍        | 17/120 [00:36<05:01,  2.93s/it][A
 15%|█▌        | 18/120 [00:40<05:18,  3.12s/it][A
 16%|█▌        | 19/120 [00:43<05:03,  3.00s/it][A
 17%|█▋        | 20/120 [00:46<05:21,  3.21s/it][A
 18%|█▊        | 21/120 [00:48<04:33,  2.76s/it][A
 18%|█▊        | 22/120 [00:50<04:12,  2.58s/it][A
 19%|█▉        | 23/120 [00:54<04:44,  2.94s/it][A
 20%|██        | 24/120 [00:57<04:48,  3.01s/it][A
 21%|██        | 25/120 [01:00<04:50,  3.06s/it][A
 22%|██▏       | 26/120 [01:02<04:05,  2.61s/it][A
 22%|██▎       | 27/120 [01:05<04:28,  2.89s/it][A
 23%|██▎       | 28/120 [01:07<03:36,  2.36s/it][A
 24%|██▍       | 29/120 [01:08<02:58,  1.96s/it][A
 25%|██▌       | 30/120 [01:09<02:37,  1.75s/it][A
 26%|██▌       | 31/120 [01:09<02:03,  1.39s/it][A
 27%|██▋       | 32/120 [01:10<01:53,  1.29s/it][A
 28%|██▊       | 33/120 [01:11<01:36,  1.11s/it][A
 28%|██▊       | 34/120 [01:13<01:44,  1.22s/it][A
 29%|██▉       | 35/120 [01:13<01:35,  1.12s/it][A
 30%|███       | 36/120 [01:15<01:34,  1.12s/it][A
 31%|███       | 37/120 [01:16<01:34,  1.13s/it][A
 32%|███▏      | 38/120 [01:17<01:36,  1.17s/it][A
 32%|███▎      | 39/120 [01:19<01:42,  1.27s/it][A
 33%|███▎      | 40/120 [01:19<01:23,  1.05s/it][A
 34%|███▍      | 41/120 [01:20<01:27,  1.11s/it][A
 35%|███▌      | 42/120 [01:23<01:52,  1.45s/it][A
 36%|███▌      | 43/120 [01:24<01:48,  1.41s/it][A
 37%|███▋      | 44/120 [01:25<01:37,  1.28s/it][A
 38%|███▊      | 45/120 [01:26<01:33,  1.24s/it][A
 38%|███▊      | 46/120 [01:27<01:30,  1.22s/it][A
 39%|███▉      | 47/120 [01:28<01:25,  1.17s/it][A
 40%|████      | 48/120 [01:29<01:11,  1.01it/s][A
 41%|████      | 49/120 [01:30<01:12,  1.02s/it][A
 42%|████▏     | 50/120 [01:33<01:59,  1.71s/it][A
 42%|████▎     | 51/120 [01:35<01:52,  1.63s/it][A
 43%|████▎     | 52/120 [01:35<01:30,  1.33s/it][A
 44%|████▍     | 53/120 [01:36<01:17,  1.16s/it][A
 45%|████▌     | 54/120 [01:37<01:07,  1.02s/it][A
 46%|████▌     | 55/120 [01:38<01:05,  1.00s/it][A
 47%|████▋     | 56/120 [01:38<00:55,  1.16it/s][A
 48%|████▊     | 57/120 [01:39<00:48,  1.31it/s][A
 48%|████▊     | 58/120 [01:40<00:55,  1.12it/s][A
 49%|████▉     | 59/120 [01:42<01:08,  1.12s/it][A
 50%|█████     | 60/120 [01:43<01:07,  1.12s/it][A
 51%|█████     | 61/120 [01:43<00:56,  1.04it/s][A
 52%|█████▏    | 62/120 [01:45<01:06,  1.14s/it][A
 52%|█████▎    | 63/120 [01:45<00:57,  1.00s/it][A
 53%|█████▎    | 64/120 [01:48<01:12,  1.30s/it][A
 54%|█████▍    | 65/120 [01:52<01:52,  2.04s/it][A
 55%|█████▌    | 66/120 [01:53<01:37,  1.80s/it][A
 56%|█████▌    | 67/120 [01:53<01:19,  1.50s/it][A
 57%|█████▋    | 68/120 [01:54<01:07,  1.30s/it][A
 57%|█████▊    | 69/120 [01:55<00:53,  1.05s/it][A
 58%|█████▊    | 70/120 [01:56<00:58,  1.16s/it][A
 59%|█████▉    | 71/120 [01:58<01:03,  1.29s/it][A
 60%|██████    | 72/120 [01:58<00:50,  1.06s/it][A
 61%|██████    | 73/120 [01:59<00:42,  1.09it/s][A
 62%|██████▏   | 74/120 [01:59<00:36,  1.27it/s][A
 62%|██████▎   | 75/120 [02:00<00:33,  1.36it/s][A
 63%|██████▎   | 76/120 [02:02<00:43,  1.02it/s][A
 64%|██████▍   | 77/120 [02:03<00:44,  1.03s/it][A
 65%|██████▌   | 78/120 [02:03<00:39,  1.06it/s][A
 66%|██████▌   | 79/120 [02:05<00:46,  1.14s/it][A
 67%|██████▋   | 80/120 [02:06<00:41,  1.04s/it][A
 68%|██████▊   | 81/120 [02:09<01:11,  1.82s/it][A
 68%|██████▊   | 82/120 [02:10<00:53,  1.42s/it][A
 69%|██████▉   | 83/120 [02:12<00:54,  1.46s/it][A
 70%|███████   | 84/120 [02:13<00:53,  1.49s/it][A
 71%|███████   | 85/120 [02:14<00:43,  1.23s/it][A
 72%|███████▏  | 86/120 [02:15<00:39,  1.15s/it][A
 72%|███████▎  | 87/120 [02:16<00:41,  1.24s/it][A
 73%|███████▎  | 88/120 [02:18<00:45,  1.42s/it][A
 74%|███████▍  | 89/120 [02:19<00:45,  1.47s/it][A
 75%|███████▌  | 90/120 [02:20<00:35,  1.19s/it][A
 76%|███████▌  | 91/120 [02:23<00:54,  1.88s/it][A
 77%|███████▋  | 92/120 [02:25<00:50,  1.79s/it][A
 78%|███████▊  | 93/120 [02:27<00:47,  1.76s/it][A
 78%|███████▊  | 94/120 [02:28<00:40,  1.56s/it][A
 79%|███████▉  | 95/120 [02:29<00:33,  1.33s/it][A
 80%|████████  | 96/120 [02:29<00:27,  1.15s/it][A
 81%|████████  | 97/120 [02:31<00:28,  1.24s/it][A
 82%|████████▏ | 98/120 [02:33<00:36,  1.66s/it][A
 82%|████████▎ | 99/120 [02:35<00:34,  1.63s/it][A
 83%|████████▎ | 100/120 [02:38<00:42,  2.12s/it][A
 84%|████████▍ | 101/120 [02:40<00:36,  1.94s/it][A
 85%|████████▌ | 102/120 [02:42<00:32,  1.82s/it][A
 86%|████████▌ | 103/120 [02:42<00:26,  1.56s/it][A
 87%|████████▋ | 104/120 [02:44<00:23,  1.47s/it][A
 88%|████████▊ | 105/120 [02:45<00:20,  1.35s/it][A
 88%|████████▊ | 106/120 [02:46<00:17,  1.24s/it][A
 89%|████████▉ | 107/120 [02:47<00:17,  1.34s/it][A
 90%|█████████ | 108/120 [02:50<00:20,  1.72s/it][A
 91%|█████████ | 109/120 [02:51<00:16,  1.46s/it][A
 92%|█████████▏| 110/120 [02:52<00:12,  1.26s/it][A
 92%|█████████▎| 111/120 [02:53<00:12,  1.41s/it][A
 93%|█████████▎| 112/120 [02:54<00:10,  1.34s/it][A
 94%|█████████▍| 113/120 [02:56<00:09,  1.41s/it][A
 95%|█████████▌| 114/120 [02:59<00:11,  1.96s/it][A
 96%|█████████▌| 115/120 [03:01<00:08,  1.79s/it][A
 97%|█████████▋| 116/120 [03:02<00:06,  1.50s/it][A
 98%|█████████▊| 117/120 [03:02<00:03,  1.30s/it][A
 98%|█████████▊| 118/120 [03:04<00:03,  1.52s/it][A
 99%|█████████▉| 119/120 [03:05<00:01,  1.32s/it][A
100%|██████████| 120/120 [03:07<00:00,  1.41s/it][A                                                      
                                                 [A{'eval_loss': 0.45332425832748413, 'eval_runtime': 189.1191, 'eval_samples_per_second': 5.039, 'eval_steps_per_second': 0.635, 'eval_rewards/chosen': 2.1343791484832764, 'eval_rewards/rejected': 0.2586043179035187, 'eval_rewards/accuracies': 0.7833333611488342, 'eval_rewards/margins': 1.8755320310592651, 'eval_logps/chosen': -367.4750061035156, 'eval_logps/rejected': -150.83749389648438, 'eval_logits/chosen': -6.466145992279053, 'eval_logits/rejected': -7.221093654632568, 'epoch': 1.0}
 33%|███▎      | 626/1881 [1:30:58<2:50:55,  8.17s/it]
100%|██████████| 120/120 [03:08<00:00,  1.41s/it][A
                                                 [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 33%|███▎      | 627/1881 [1:31:21<24:12:09, 69.48s/it] 33%|███▎      | 628/1881 [1:31:23<17:11:03, 49.37s/it] 33%|███▎      | 629/1881 [1:31:30<12:46:42, 36.74s/it] 33%|███▎      | 630/1881 [1:31:38<9:42:13, 27.92s/it]                                                       {'loss': 0.435, 'grad_norm': 45.11014175415039, 'learning_rate': 3.999977405316378e-07, 'rewards/chosen': 1.6765007972717285, 'rewards/rejected': -0.01394171454012394, 'rewards/accuracies': 0.7960526347160339, 'rewards/margins': 1.6909950971603394, 'logps/chosen': -260.59210205078125, 'logps/rejected': -147.67434692382812, 'logits/chosen': -6.7302632331848145, 'logits/rejected': -6.8289475440979, 'epoch': 1.0}
 33%|███▎      | 630/1881 [1:31:38<9:42:13, 27.92s/it] 34%|███▎      | 631/1881 [1:31:43<7:20:05, 21.12s/it] 34%|███▎      | 632/1881 [1:31:51<5:57:16, 17.16s/it] 34%|███▎      | 633/1881 [1:31:58<4:53:55, 14.13s/it] 34%|███▎      | 634/1881 [1:32:04<4:02:07, 11.65s/it] 34%|███▍      | 635/1881 [1:32:11<3:36:14, 10.41s/it] 34%|███▍      | 636/1881 [1:32:19<3:17:48,  9.53s/it] 34%|███▍      | 637/1881 [1:32:29<3:19:16,  9.61s/it] 34%|███▍      | 638/1881 [1:32:34<2:54:23,  8.42s/it] 34%|███▍      | 639/1881 [1:32:41<2:46:52,  8.06s/it] 34%|███▍      | 640/1881 [1:32:49<2:44:53,  7.97s/it]                                                      {'loss': 0.4319, 'grad_norm': 50.19674301147461, 'learning_rate': 3.9991866509486533e-07, 'rewards/chosen': 1.4989502429962158, 'rewards/rejected': -0.2785888612270355, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 1.777441382408142, 'logps/chosen': -252.9250030517578, 'logps/rejected': -166.9499969482422, 'logits/chosen': -6.864062309265137, 'logits/rejected': -6.775000095367432, 'epoch': 1.02}
 34%|███▍      | 640/1881 [1:32:49<2:44:53,  7.97s/it] 34%|███▍      | 641/1881 [1:32:57<2:44:03,  7.94s/it] 34%|███▍      | 642/1881 [1:33:07<2:56:28,  8.55s/it] 34%|███▍      | 643/1881 [1:33:15<2:55:02,  8.48s/it] 34%|███▍      | 644/1881 [1:33:23<2:51:24,  8.31s/it] 34%|███▍      | 645/1881 [1:33:30<2:40:26,  7.79s/it] 34%|███▍      | 646/1881 [1:33:36<2:32:09,  7.39s/it] 34%|███▍      | 647/1881 [1:33:42<2:24:05,  7.01s/it] 34%|███▍      | 648/1881 [1:33:52<2:37:57,  7.69s/it] 35%|███▍      | 649/1881 [1:33:59<2:36:21,  7.61s/it] 35%|███▍      | 650/1881 [1:34:06<2:34:25,  7.53s/it]                                                      {'loss': 0.4324, 'grad_norm': 47.514896392822266, 'learning_rate': 3.997266729579969e-07, 'rewards/chosen': 1.59765625, 'rewards/rejected': -0.11340942233800888, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.707910180091858, 'logps/chosen': -270.0375061035156, 'logps/rejected': -164.6875, 'logits/chosen': -6.832812309265137, 'logits/rejected': -6.881249904632568, 'epoch': 1.04}
 35%|███▍      | 650/1881 [1:34:07<2:34:25,  7.53s/it] 35%|███▍      | 651/1881 [1:34:13<2:31:34,  7.39s/it] 35%|███▍      | 652/1881 [1:34:23<2:46:08,  8.11s/it] 35%|███▍      | 653/1881 [1:34:29<2:31:52,  7.42s/it] 35%|███▍      | 654/1881 [1:34:35<2:20:35,  6.88s/it] 35%|███▍      | 655/1881 [1:34:45<2:41:37,  7.91s/it] 35%|███▍      | 656/1881 [1:34:50<2:24:26,  7.07s/it] 35%|███▍      | 657/1881 [1:34:59<2:33:19,  7.52s/it] 35%|███▍      | 658/1881 [1:35:04<2:22:28,  6.99s/it] 35%|███▌      | 659/1881 [1:35:13<2:29:11,  7.33s/it] 35%|███▌      | 660/1881 [1:35:19<2:21:32,  6.96s/it]                                                      {'loss': 0.4133, 'grad_norm': 28.004610061645508, 'learning_rate': 3.9942188461502646e-07, 'rewards/chosen': 1.603002905845642, 'rewards/rejected': -0.2992919981479645, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 1.9000976085662842, 'logps/chosen': -245.96249389648438, 'logps/rejected': -151.02499389648438, 'logits/chosen': -6.993750095367432, 'logits/rejected': -7.03125, 'epoch': 1.05}
 35%|███▌      | 660/1881 [1:35:19<2:21:32,  6.96s/it] 35%|███▌      | 661/1881 [1:35:25<2:17:09,  6.75s/it] 35%|███▌      | 662/1881 [1:35:30<2:09:21,  6.37s/it] 35%|███▌      | 663/1881 [1:35:36<2:06:06,  6.21s/it] 35%|███▌      | 664/1881 [1:35:43<2:08:24,  6.33s/it] 35%|███▌      | 665/1881 [1:35:49<2:06:18,  6.23s/it] 35%|███▌      | 666/1881 [1:35:57<2:20:44,  6.95s/it] 35%|███▌      | 667/1881 [1:36:09<2:46:28,  8.23s/it] 36%|███▌      | 668/1881 [1:36:17<2:49:52,  8.40s/it] 36%|███▌      | 669/1881 [1:36:25<2:46:06,  8.22s/it] 36%|███▌      | 670/1881 [1:36:31<2:27:42,  7.32s/it]                                                      {'loss': 0.4404, 'grad_norm': 72.3606948852539, 'learning_rate': 3.990044913506876e-07, 'rewards/chosen': 1.958642601966858, 'rewards/rejected': -0.23808594048023224, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.195507764816284, 'logps/chosen': -279.23748779296875, 'logps/rejected': -163.75, 'logits/chosen': -6.9453125, 'logits/rejected': -6.948437690734863, 'epoch': 1.07}
 36%|███▌      | 670/1881 [1:36:31<2:27:42,  7.32s/it] 36%|███▌      | 671/1881 [1:36:42<2:51:52,  8.52s/it] 36%|███▌      | 672/1881 [1:36:47<2:33:22,  7.61s/it] 36%|███▌      | 673/1881 [1:36:53<2:24:02,  7.15s/it] 36%|███▌      | 674/1881 [1:37:04<2:42:00,  8.05s/it] 36%|███▌      | 675/1881 [1:37:09<2:26:55,  7.31s/it] 36%|███▌      | 676/1881 [1:37:18<2:33:51,  7.66s/it] 36%|███▌      | 677/1881 [1:37:27<2:41:17,  8.04s/it] 36%|███▌      | 678/1881 [1:37:32<2:24:54,  7.23s/it] 36%|███▌      | 679/1881 [1:37:37<2:12:36,  6.62s/it] 36%|███▌      | 680/1881 [1:37:46<2:28:36,  7.42s/it]                                                      {'loss': 0.4415, 'grad_norm': 41.269371032714844, 'learning_rate': 3.984747551204035e-07, 'rewards/chosen': 1.7773926258087158, 'rewards/rejected': -0.27104490995407104, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 2.05078125, 'logps/chosen': -255.8874969482422, 'logps/rejected': -198.52499389648438, 'logits/chosen': -6.837500095367432, 'logits/rejected': -7.026562690734863, 'epoch': 1.08}
 36%|███▌      | 680/1881 [1:37:47<2:28:36,  7.42s/it] 36%|███▌      | 681/1881 [1:38:00<3:08:12,  9.41s/it] 36%|███▋      | 682/1881 [1:38:07<2:50:01,  8.51s/it] 36%|███▋      | 683/1881 [1:38:14<2:40:24,  8.03s/it] 36%|███▋      | 684/1881 [1:38:21<2:35:19,  7.79s/it] 36%|███▋      | 685/1881 [1:38:32<2:51:46,  8.62s/it] 36%|███▋      | 686/1881 [1:38:41<2:57:17,  8.90s/it] 37%|███▋      | 687/1881 [1:38:50<2:57:02,  8.90s/it] 37%|███▋      | 688/1881 [1:38:57<2:44:46,  8.29s/it] 37%|███▋      | 689/1881 [1:39:02<2:25:13,  7.31s/it] 37%|███▋      | 690/1881 [1:39:08<2:19:53,  7.05s/it]                                                      {'loss': 0.3892, 'grad_norm': 33.68552780151367, 'learning_rate': 3.97833008385884e-07, 'rewards/chosen': 2.1138672828674316, 'rewards/rejected': 0.06831054389476776, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 2.0445313453674316, 'logps/chosen': -282.6875, 'logps/rejected': -235.1125030517578, 'logits/chosen': -6.717187404632568, 'logits/rejected': -6.737500190734863, 'epoch': 1.1}
 37%|███▋      | 690/1881 [1:39:09<2:19:53,  7.05s/it] 37%|███▋      | 691/1881 [1:39:16<2:21:41,  7.14s/it] 37%|███▋      | 692/1881 [1:39:23<2:22:59,  7.22s/it] 37%|███▋      | 693/1881 [1:39:33<2:36:38,  7.91s/it] 37%|███▋      | 694/1881 [1:39:38<2:18:57,  7.02s/it] 37%|███▋      | 695/1881 [1:39:45<2:23:31,  7.26s/it] 37%|███▋      | 696/1881 [1:39:55<2:36:20,  7.92s/it] 37%|███▋      | 697/1881 [1:40:04<2:41:42,  8.19s/it] 37%|███▋      | 698/1881 [1:40:10<2:28:22,  7.53s/it] 37%|███▋      | 699/1881 [1:40:18<2:36:17,  7.93s/it] 37%|███▋      | 700/1881 [1:40:27<2:40:18,  8.14s/it]                                                      {'loss': 0.4388, 'grad_norm': 46.58875274658203, 'learning_rate': 3.970796539064734e-07, 'rewards/chosen': 1.357275366783142, 'rewards/rejected': -0.27283936738967896, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 1.6296875476837158, 'logps/chosen': -230.1875, 'logps/rejected': -164.9187469482422, 'logits/chosen': -6.935937404632568, 'logits/rejected': -6.901562690734863, 'epoch': 1.11}
 37%|███▋      | 700/1881 [1:40:27<2:40:18,  8.14s/it] 37%|███▋      | 701/1881 [1:40:35<2:39:25,  8.11s/it] 37%|███▋      | 702/1881 [1:40:41<2:27:38,  7.51s/it] 37%|███▋      | 703/1881 [1:40:50<2:33:18,  7.81s/it] 37%|███▋      | 704/1881 [1:41:00<2:44:47,  8.40s/it] 37%|███▋      | 705/1881 [1:41:08<2:43:05,  8.32s/it] 38%|███▊      | 706/1881 [1:41:15<2:38:02,  8.07s/it] 38%|███▊      | 707/1881 [1:41:22<2:32:12,  7.78s/it] 38%|███▊      | 708/1881 [1:41:29<2:25:59,  7.47s/it] 38%|███▊      | 709/1881 [1:41:35<2:16:58,  7.01s/it] 38%|███▊      | 710/1881 [1:41:42<2:18:02,  7.07s/it]                                                      {'loss': 0.4088, 'grad_norm': 38.73302459716797, 'learning_rate': 3.962151644863788e-07, 'rewards/chosen': 1.326904296875, 'rewards/rejected': -0.29509276151657104, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.6220703125, 'logps/chosen': -210.4375, 'logps/rejected': -135.83749389648438, 'logits/chosen': -6.984375, 'logits/rejected': -7.078125, 'epoch': 1.13}
 38%|███▊      | 710/1881 [1:41:43<2:18:02,  7.07s/it] 38%|███▊      | 711/1881 [1:41:49<2:16:37,  7.01s/it] 38%|███▊      | 712/1881 [1:41:57<2:23:02,  7.34s/it] 38%|███▊      | 713/1881 [1:42:08<2:45:21,  8.49s/it] 38%|███▊      | 714/1881 [1:42:15<2:36:51,  8.07s/it] 38%|███▊      | 715/1881 [1:42:25<2:48:28,  8.67s/it] 38%|███▊      | 716/1881 [1:42:32<2:35:56,  8.03s/it] 38%|███▊      | 717/1881 [1:42:40<2:34:42,  7.97s/it] 38%|███▊      | 718/1881 [1:42:46<2:21:13,  7.29s/it] 38%|███▊      | 719/1881 [1:42:56<2:37:37,  8.14s/it] 38%|███▊      | 720/1881 [1:43:09<3:09:10,  9.78s/it]                                                      {'loss': 0.4282, 'grad_norm': 37.43132019042969, 'learning_rate': 3.952400826779394e-07, 'rewards/chosen': 0.7156127691268921, 'rewards/rejected': -0.59722900390625, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 1.313818335533142, 'logps/chosen': -127.0999984741211, 'logps/rejected': -118.8499984741211, 'logits/chosen': -7.176562309265137, 'logits/rejected': -6.959374904632568, 'epoch': 1.15}
 38%|███▊      | 720/1881 [1:43:09<3:09:10,  9.78s/it] 38%|███▊      | 721/1881 [1:43:22<3:26:57, 10.70s/it] 38%|███▊      | 722/1881 [1:43:28<2:56:12,  9.12s/it] 38%|███▊      | 723/1881 [1:43:33<2:36:07,  8.09s/it] 38%|███▊      | 724/1881 [1:43:40<2:29:25,  7.75s/it] 39%|███▊      | 725/1881 [1:43:47<2:24:48,  7.52s/it] 39%|███▊      | 726/1881 [1:43:58<2:43:10,  8.48s/it] 39%|███▊      | 727/1881 [1:44:05<2:37:07,  8.17s/it] 39%|███▊      | 728/1881 [1:44:14<2:40:29,  8.35s/it] 39%|███▉      | 729/1881 [1:44:25<2:53:43,  9.05s/it] 39%|███▉      | 730/1881 [1:44:32<2:45:48,  8.64s/it]                                                      {'loss': 0.4263, 'grad_norm': 35.925811767578125, 'learning_rate': 3.9415502044112085e-07, 'rewards/chosen': 1.990625023841858, 'rewards/rejected': -0.31999510526657104, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 2.3099608421325684, 'logps/chosen': -264.4624938964844, 'logps/rejected': -155.55624389648438, 'logits/chosen': -6.810937404632568, 'logits/rejected': -6.720312595367432, 'epoch': 1.16}
 39%|███▉      | 730/1881 [1:44:33<2:45:48,  8.64s/it] 39%|███▉      | 731/1881 [1:44:38<2:28:08,  7.73s/it] 39%|███▉      | 732/1881 [1:44:47<2:34:43,  8.08s/it] 39%|███▉      | 733/1881 [1:44:55<2:34:29,  8.07s/it] 39%|███▉      | 734/1881 [1:45:03<2:31:27,  7.92s/it] 39%|███▉      | 735/1881 [1:45:14<2:50:23,  8.92s/it] 39%|███▉      | 736/1881 [1:45:22<2:43:00,  8.54s/it] 39%|███▉      | 737/1881 [1:45:33<2:58:03,  9.34s/it] 39%|███▉      | 738/1881 [1:45:40<2:48:51,  8.86s/it] 39%|███▉      | 739/1881 [1:45:53<3:06:56,  9.82s/it] 39%|███▉      | 740/1881 [1:45:57<2:38:45,  8.35s/it]                                                      {'loss': 0.4384, 'grad_norm': 55.608177185058594, 'learning_rate': 3.929606587594505e-07, 'rewards/chosen': 1.2141602039337158, 'rewards/rejected': -0.618945300579071, 'rewards/accuracies': 0.762499988079071, 'rewards/margins': 1.8318359851837158, 'logps/chosen': -199.22500610351562, 'logps/rejected': -119.05000305175781, 'logits/chosen': -7.073437690734863, 'logits/rejected': -7.046875, 'epoch': 1.18}
 39%|███▉      | 740/1881 [1:45:58<2:38:45,  8.35s/it] 39%|███▉      | 741/1881 [1:46:03<2:22:24,  7.50s/it] 39%|███▉      | 742/1881 [1:46:15<2:47:31,  8.82s/it] 40%|███▉      | 743/1881 [1:46:23<2:44:46,  8.69s/it] 40%|███▉      | 744/1881 [1:46:32<2:42:20,  8.57s/it] 40%|███▉      | 745/1881 [1:46:41<2:48:15,  8.89s/it] 40%|███▉      | 746/1881 [1:46:55<3:14:49, 10.30s/it] 40%|███▉      | 747/1881 [1:47:05<3:14:48, 10.31s/it] 40%|███▉      | 748/1881 [1:47:12<2:55:35,  9.30s/it] 40%|███▉      | 749/1881 [1:47:22<3:01:34,  9.62s/it] 40%|███▉      | 750/1881 [1:47:32<3:00:17,  9.56s/it]                                                      {'loss': 0.3877, 'grad_norm': 37.70176696777344, 'learning_rate': 3.9165774721263273e-07, 'rewards/chosen': 1.886022925376892, 'rewards/rejected': -0.26787108182907104, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.1539063453674316, 'logps/chosen': -275.2250061035156, 'logps/rejected': -193.625, 'logits/chosen': -6.837500095367432, 'logits/rejected': -6.801562309265137, 'epoch': 1.19}
 40%|███▉      | 750/1881 [1:47:32<3:00:17,  9.56s/it] 40%|███▉      | 751/1881 [1:47:44<3:13:36, 10.28s/it] 40%|███▉      | 752/1881 [1:47:53<3:06:47,  9.93s/it] 40%|████      | 753/1881 [1:48:02<3:01:33,  9.66s/it] 40%|████      | 754/1881 [1:48:11<2:57:30,  9.45s/it] 40%|████      | 755/1881 [1:48:17<2:37:51,  8.41s/it] 40%|████      | 756/1881 [1:48:25<2:34:42,  8.25s/it] 40%|████      | 757/1881 [1:48:34<2:39:37,  8.52s/it] 40%|████      | 758/1881 [1:48:40<2:23:18,  7.66s/it] 40%|████      | 759/1881 [1:48:47<2:21:31,  7.57s/it] 40%|████      | 760/1881 [1:48:57<2:34:02,  8.24s/it]                                                      {'loss': 0.4642, 'grad_norm': 47.279293060302734, 'learning_rate': 3.902471035061142e-07, 'rewards/chosen': 1.7902100086212158, 'rewards/rejected': -0.2546630799770355, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 2.043872117996216, 'logps/chosen': -258.9750061035156, 'logps/rejected': -163.3249969482422, 'logits/chosen': -6.817187309265137, 'logits/rejected': -6.807812690734863, 'epoch': 1.21}
 40%|████      | 760/1881 [1:48:57<2:34:02,  8.24s/it] 40%|████      | 761/1881 [1:49:02<2:19:09,  7.45s/it] 41%|████      | 762/1881 [1:49:07<2:04:02,  6.65s/it] 41%|████      | 763/1881 [1:49:15<2:09:53,  6.97s/it] 41%|████      | 764/1881 [1:49:22<2:12:06,  7.10s/it] 41%|████      | 765/1881 [1:49:28<2:02:37,  6.59s/it] 41%|████      | 766/1881 [1:49:36<2:11:11,  7.06s/it] 41%|████      | 767/1881 [1:49:50<2:49:42,  9.14s/it] 41%|████      | 768/1881 [1:50:00<2:57:31,  9.57s/it] 41%|████      | 769/1881 [1:50:07<2:39:05,  8.58s/it] 41%|████      | 770/1881 [1:50:12<2:18:23,  7.47s/it]                                                      {'loss': 0.4195, 'grad_norm': 35.20169448852539, 'learning_rate': 3.8872961295789276e-07, 'rewards/chosen': 2.8399658203125, 'rewards/rejected': -0.08017577975988388, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.9205079078674316, 'logps/chosen': -330.875, 'logps/rejected': -184.2624969482422, 'logits/chosen': -6.778124809265137, 'logits/rejected': -6.724999904632568, 'epoch': 1.23}
 41%|████      | 770/1881 [1:50:12<2:18:23,  7.47s/it] 41%|████      | 771/1881 [1:50:21<2:28:02,  8.00s/it] 41%|████      | 772/1881 [1:50:27<2:18:52,  7.51s/it] 41%|████      | 773/1881 [1:50:34<2:13:58,  7.25s/it] 41%|████      | 774/1881 [1:50:41<2:13:26,  7.23s/it] 41%|████      | 775/1881 [1:50:51<2:28:46,  8.07s/it] 41%|████▏     | 776/1881 [1:51:00<2:35:59,  8.47s/it] 41%|████▏     | 777/1881 [1:51:08<2:31:16,  8.22s/it] 41%|████▏     | 778/1881 [1:51:14<2:20:33,  7.65s/it] 41%|████▏     | 779/1881 [1:51:19<2:03:02,  6.70s/it] 41%|████▏     | 780/1881 [1:51:26<2:08:08,  6.98s/it]                                                      {'loss': 0.3488, 'grad_norm': 39.2027587890625, 'learning_rate': 3.8710622794289304e-07, 'rewards/chosen': 2.586230516433716, 'rewards/rejected': -0.46586912870407104, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.0517578125, 'logps/chosen': -315.23748779296875, 'logps/rejected': -155.375, 'logits/chosen': -6.712500095367432, 'logits/rejected': -6.849999904632568, 'epoch': 1.24}
 41%|████▏     | 780/1881 [1:51:27<2:08:08,  6.98s/it] 42%|████▏     | 781/1881 [1:51:34<2:11:09,  7.15s/it] 42%|████▏     | 782/1881 [1:51:41<2:10:19,  7.11s/it] 42%|████▏     | 783/1881 [1:51:47<2:05:34,  6.86s/it] 42%|████▏     | 784/1881 [1:51:54<2:02:12,  6.68s/it] 42%|████▏     | 785/1881 [1:52:00<2:00:21,  6.59s/it] 42%|████▏     | 786/1881 [1:52:11<2:26:11,  8.01s/it] 42%|████▏     | 787/1881 [1:52:21<2:34:30,  8.47s/it] 42%|████▏     | 788/1881 [1:52:29<2:30:13,  8.25s/it] 42%|████▏     | 789/1881 [1:52:35<2:21:43,  7.79s/it] 42%|████▏     | 790/1881 [1:52:42<2:16:14,  7.49s/it]                                                      {'loss': 0.3941, 'grad_norm': 34.39303970336914, 'learning_rate': 3.853779672952577e-07, 'rewards/chosen': 1.542688012123108, 'rewards/rejected': -0.6195312738418579, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.1595702171325684, 'logps/chosen': -237.8249969482422, 'logps/rejected': -158.91250610351562, 'logits/chosen': -7.057812690734863, 'logits/rejected': -6.907812595367432, 'epoch': 1.26}
 42%|████▏     | 790/1881 [1:52:42<2:16:14,  7.49s/it] 42%|████▏     | 791/1881 [1:52:49<2:13:10,  7.33s/it] 42%|████▏     | 792/1881 [1:52:58<2:19:57,  7.71s/it] 42%|████▏     | 793/1881 [1:53:04<2:15:07,  7.45s/it] 42%|████▏     | 794/1881 [1:53:11<2:11:39,  7.27s/it] 42%|████▏     | 795/1881 [1:53:18<2:07:16,  7.03s/it] 42%|████▏     | 796/1881 [1:53:27<2:19:04,  7.69s/it] 42%|████▏     | 797/1881 [1:53:34<2:15:04,  7.48s/it] 42%|████▏     | 798/1881 [1:53:43<2:23:21,  7.94s/it] 42%|████▏     | 799/1881 [1:53:51<2:22:52,  7.92s/it] 43%|████▎     | 800/1881 [1:54:00<2:28:15,  8.23s/it]                                                      {'loss': 0.3823, 'grad_norm': 39.71744918823242, 'learning_rate': 3.835459156689281e-07, 'rewards/chosen': 1.6017577648162842, 'rewards/rejected': -0.578662097454071, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.179443359375, 'logps/chosen': -232.4250030517578, 'logps/rejected': -172.89999389648438, 'logits/chosen': -6.932812690734863, 'logits/rejected': -6.796875, 'epoch': 1.27}
 43%|████▎     | 800/1881 [1:54:00<2:28:15,  8.23s/it] 43%|████▎     | 801/1881 [1:54:07<2:24:55,  8.05s/it] 43%|████▎     | 802/1881 [1:54:15<2:24:19,  8.03s/it] 43%|████▎     | 803/1881 [1:54:24<2:28:43,  8.28s/it] 43%|████▎     | 804/1881 [1:54:31<2:22:36,  7.95s/it] 43%|████▎     | 805/1881 [1:54:44<2:48:03,  9.37s/it] 43%|████▎     | 806/1881 [1:54:52<2:37:01,  8.76s/it] 43%|████▎     | 807/1881 [1:55:01<2:39:38,  8.92s/it] 43%|████▎     | 808/1881 [1:55:11<2:43:51,  9.16s/it] 43%|████▎     | 809/1881 [1:55:21<2:50:18,  9.53s/it] 43%|████▎     | 810/1881 [1:55:27<2:34:00,  8.63s/it]                                                      {'loss': 0.3546, 'grad_norm': 25.95693016052246, 'learning_rate': 3.8161122285691737e-07, 'rewards/chosen': 1.7040283679962158, 'rewards/rejected': -0.5899413824081421, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.293750047683716, 'logps/chosen': -233.625, 'logps/rejected': -168.4499969482422, 'logits/chosen': -6.959374904632568, 'logits/rejected': -6.832812309265137, 'epoch': 1.29}
 43%|████▎     | 810/1881 [1:55:28<2:34:00,  8.63s/it] 43%|████▎     | 811/1881 [1:55:36<2:33:52,  8.63s/it] 43%|████▎     | 812/1881 [1:55:43<2:24:05,  8.09s/it] 43%|████▎     | 813/1881 [1:55:48<2:09:41,  7.29s/it] 43%|████▎     | 814/1881 [1:55:55<2:06:42,  7.13s/it] 43%|████▎     | 815/1881 [1:56:00<1:53:51,  6.41s/it] 43%|████▎     | 816/1881 [1:56:10<2:15:33,  7.64s/it] 43%|████▎     | 817/1881 [1:56:24<2:46:03,  9.36s/it] 43%|████▎     | 818/1881 [1:56:34<2:48:10,  9.49s/it] 44%|████▎     | 819/1881 [1:56:39<2:28:15,  8.38s/it] 44%|████▎     | 820/1881 [1:56:46<2:19:51,  7.91s/it]                                                      {'loss': 0.3374, 'grad_norm': 50.51556396484375, 'learning_rate': 3.795751030697018e-07, 'rewards/chosen': 1.7114989757537842, 'rewards/rejected': -0.706250011920929, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.4203124046325684, 'logps/chosen': -225.625, 'logps/rejected': -157.1062469482422, 'logits/chosen': -6.996874809265137, 'logits/rejected': -6.871874809265137, 'epoch': 1.31}
 44%|████▎     | 820/1881 [1:56:46<2:19:51,  7.91s/it] 44%|████▎     | 821/1881 [1:56:53<2:15:18,  7.66s/it] 44%|████▎     | 822/1881 [1:56:58<2:01:43,  6.90s/it] 44%|████▍     | 823/1881 [1:57:06<2:05:47,  7.13s/it] 44%|████▍     | 824/1881 [1:57:16<2:23:16,  8.13s/it] 44%|████▍     | 825/1881 [1:57:22<2:07:45,  7.26s/it] 44%|████▍     | 826/1881 [1:57:32<2:24:01,  8.19s/it] 44%|████▍     | 827/1881 [1:57:35<1:58:58,  6.77s/it] 44%|████▍     | 828/1881 [1:57:43<2:00:45,  6.88s/it] 44%|████▍     | 829/1881 [1:57:50<2:05:05,  7.13s/it] 44%|████▍     | 830/1881 [1:57:58<2:09:28,  7.39s/it]                                                      {'loss': 0.3594, 'grad_norm': 55.17513656616211, 'learning_rate': 3.7743883417318396e-07, 'rewards/chosen': 2.876174211502075, 'rewards/rejected': -0.24335937201976776, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.116015672683716, 'logps/chosen': -333.0249938964844, 'logps/rejected': -200.8249969482422, 'logits/chosen': -6.940625190734863, 'logits/rejected': -6.790625095367432, 'epoch': 1.32}
 44%|████▍     | 830/1881 [1:57:59<2:09:28,  7.39s/it] 44%|████▍     | 831/1881 [1:58:03<1:56:41,  6.67s/it] 44%|████▍     | 832/1881 [1:58:12<2:09:19,  7.40s/it] 44%|████▍     | 833/1881 [1:58:17<1:54:34,  6.56s/it] 44%|████▍     | 834/1881 [1:58:25<2:00:14,  6.89s/it] 44%|████▍     | 835/1881 [1:58:35<2:19:04,  7.98s/it] 44%|████▍     | 836/1881 [1:58:45<2:26:14,  8.40s/it] 44%|████▍     | 837/1881 [1:58:52<2:21:11,  8.11s/it] 45%|████▍     | 838/1881 [1:59:00<2:18:01,  7.94s/it] 45%|████▍     | 839/1881 [1:59:07<2:16:28,  7.86s/it] 45%|████▍     | 840/1881 [1:59:13<2:05:24,  7.23s/it]                                                      {'loss': 0.4215, 'grad_norm': 23.976591110229492, 'learning_rate': 3.7520375688670606e-07, 'rewards/chosen': 3.039093017578125, 'rewards/rejected': -0.12578125298023224, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 3.15997314453125, 'logps/chosen': -383.95001220703125, 'logps/rejected': -195.1125030517578, 'logits/chosen': -6.737500190734863, 'logits/rejected': -6.925000190734863, 'epoch': 1.34}
 45%|████▍     | 840/1881 [1:59:13<2:05:24,  7.23s/it] 45%|████▍     | 841/1881 [1:59:19<1:59:07,  6.87s/it] 45%|████▍     | 842/1881 [1:59:27<2:02:40,  7.08s/it] 45%|████▍     | 843/1881 [1:59:35<2:07:15,  7.36s/it] 45%|████▍     | 844/1881 [1:59:44<2:18:13,  8.00s/it] 45%|████▍     | 845/1881 [1:59:54<2:28:58,  8.63s/it] 45%|████▍     | 846/1881 [2:00:05<2:39:08,  9.23s/it] 45%|████▌     | 847/1881 [2:00:15<2:41:41,  9.38s/it] 45%|████▌     | 848/1881 [2:00:21<2:27:19,  8.56s/it] 45%|████▌     | 849/1881 [2:00:29<2:20:50,  8.19s/it] 45%|████▌     | 850/1881 [2:00:39<2:30:39,  8.77s/it]                                                      {'loss': 0.4039, 'grad_norm': 72.78425598144531, 'learning_rate': 3.7287127394161623e-07, 'rewards/chosen': 1.32232666015625, 'rewards/rejected': -0.797119140625, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 2.119335889816284, 'logps/chosen': -215.85000610351562, 'logps/rejected': -123.6875, 'logits/chosen': -6.946875095367432, 'logits/rejected': -7.079687595367432, 'epoch': 1.35}
 45%|████▌     | 850/1881 [2:00:39<2:30:39,  8.77s/it] 45%|████▌     | 851/1881 [2:00:45<2:16:47,  7.97s/it] 45%|████▌     | 852/1881 [2:00:54<2:24:33,  8.43s/it] 45%|████▌     | 853/1881 [2:01:02<2:19:33,  8.15s/it] 45%|████▌     | 854/1881 [2:01:09<2:13:52,  7.82s/it] 45%|████▌     | 855/1881 [2:01:16<2:11:12,  7.67s/it] 46%|████▌     | 856/1881 [2:01:24<2:11:09,  7.68s/it] 46%|████▌     | 857/1881 [2:01:35<2:31:28,  8.88s/it] 46%|████▌     | 858/1881 [2:01:45<2:32:46,  8.96s/it] 46%|████▌     | 859/1881 [2:01:53<2:30:37,  8.84s/it] 46%|████▌     | 860/1881 [2:02:02<2:32:25,  8.96s/it]                                                      {'loss': 0.3851, 'grad_norm': 30.513338088989258, 'learning_rate': 3.7044284920091647e-07, 'rewards/chosen': 1.910314917564392, 'rewards/rejected': -0.37739259004592896, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.291210889816284, 'logps/chosen': -245.8000030517578, 'logps/rejected': -177.6374969482422, 'logits/chosen': -7.076562404632568, 'logits/rejected': -6.912499904632568, 'epoch': 1.37}
 46%|████▌     | 860/1881 [2:02:03<2:32:25,  8.96s/it] 46%|████▌     | 861/1881 [2:02:09<2:19:37,  8.21s/it] 46%|████▌     | 862/1881 [2:02:15<2:10:57,  7.71s/it] 46%|████▌     | 863/1881 [2:02:29<2:38:43,  9.36s/it] 46%|████▌     | 864/1881 [2:02:36<2:30:04,  8.85s/it] 46%|████▌     | 865/1881 [2:02:46<2:33:54,  9.09s/it] 46%|████▌     | 866/1881 [2:02:56<2:37:23,  9.30s/it] 46%|████▌     | 867/1881 [2:03:02<2:21:49,  8.39s/it] 46%|████▌     | 868/1881 [2:03:08<2:11:48,  7.81s/it] 46%|████▌     | 869/1881 [2:03:20<2:31:07,  8.96s/it] 46%|████▋     | 870/1881 [2:03:28<2:23:47,  8.53s/it]                                                      {'loss': 0.3956, 'grad_norm': 33.28313064575195, 'learning_rate': 3.6792000674054407e-07, 'rewards/chosen': 2.954516649246216, 'rewards/rejected': 0.03359375149011612, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.9227538108825684, 'logps/chosen': -325.9375, 'logps/rejected': -215.5124969482422, 'logits/chosen': -6.904687404632568, 'logits/rejected': -6.946875095367432, 'epoch': 1.39}
 46%|████▋     | 870/1881 [2:03:28<2:23:47,  8.53s/it] 46%|████▋     | 871/1881 [2:03:35<2:18:47,  8.25s/it] 46%|████▋     | 872/1881 [2:03:44<2:22:59,  8.50s/it] 46%|████▋     | 873/1881 [2:03:50<2:09:45,  7.72s/it] 46%|████▋     | 874/1881 [2:03:57<2:06:40,  7.55s/it] 47%|████▋     | 875/1881 [2:04:04<2:04:04,  7.40s/it] 47%|████▋     | 876/1881 [2:04:14<2:12:45,  7.93s/it] 47%|████▋     | 877/1881 [2:04:19<2:01:56,  7.29s/it] 47%|████▋     | 878/1881 [2:04:28<2:07:52,  7.65s/it] 47%|████▋     | 879/1881 [2:04:38<2:18:29,  8.29s/it] 47%|████▋     | 880/1881 [2:04:46<2:16:02,  8.15s/it]                                                      {'loss': 0.3809, 'grad_norm': 40.61345291137695, 'learning_rate': 3.65304329892864e-07, 'rewards/chosen': 1.784936547279358, 'rewards/rejected': -0.7543090581893921, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.541210889816284, 'logps/chosen': -230.71249389648438, 'logps/rejected': -107.6500015258789, 'logits/chosen': -7.043749809265137, 'logits/rejected': -6.901562690734863, 'epoch': 1.4}
 47%|████▋     | 880/1881 [2:04:46<2:16:02,  8.15s/it] 47%|████▋     | 881/1881 [2:04:52<2:06:21,  7.58s/it] 47%|████▋     | 882/1881 [2:05:01<2:12:31,  7.96s/it] 47%|████▋     | 883/1881 [2:05:07<2:06:50,  7.63s/it] 47%|████▋     | 884/1881 [2:05:17<2:15:39,  8.16s/it] 47%|████▋     | 885/1881 [2:05:24<2:12:01,  7.95s/it] 47%|████▋     | 886/1881 [2:05:34<2:21:03,  8.51s/it] 47%|████▋     | 887/1881 [2:05:41<2:10:26,  7.87s/it] 47%|████▋     | 888/1881 [2:05:47<2:04:53,  7.55s/it] 47%|████▋     | 889/1881 [2:05:55<2:04:41,  7.54s/it] 47%|████▋     | 890/1881 [2:06:03<2:06:32,  7.66s/it]                                                      {'loss': 0.4193, 'grad_norm': 47.13238525390625, 'learning_rate': 3.625974602529714e-07, 'rewards/chosen': 1.2359130382537842, 'rewards/rejected': -0.8606933355331421, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.0950684547424316, 'logps/chosen': -191.9499969482422, 'logps/rejected': -144.1125030517578, 'logits/chosen': -7.09375, 'logits/rejected': -7.139062404632568, 'epoch': 1.42}
 47%|████▋     | 890/1881 [2:06:03<2:06:32,  7.66s/it] 47%|████▋     | 891/1881 [2:06:16<2:36:22,  9.48s/it] 47%|████▋     | 892/1881 [2:06:23<2:23:10,  8.69s/it] 47%|████▋     | 893/1881 [2:06:34<2:32:19,  9.25s/it] 48%|████▊     | 894/1881 [2:06:40<2:16:45,  8.31s/it] 48%|████▊     | 895/1881 [2:06:52<2:36:58,  9.55s/it] 48%|████▊     | 896/1881 [2:06:59<2:20:49,  8.58s/it] 48%|████▊     | 897/1881 [2:07:11<2:36:48,  9.56s/it] 48%|████▊     | 898/1881 [2:07:19<2:31:48,  9.27s/it] 48%|████▊     | 899/1881 [2:07:28<2:31:19,  9.25s/it] 48%|████▊     | 900/1881 [2:07:37<2:28:51,  9.10s/it]                                                      {'loss': 0.3827, 'grad_norm': 22.172582626342773, 'learning_rate': 3.5980109664842896e-07, 'rewards/chosen': 1.7870604991912842, 'rewards/rejected': -0.827441394329071, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.6156249046325684, 'logps/chosen': -241.6999969482422, 'logps/rejected': -153.46249389648438, 'logits/chosen': -6.9453125, 'logits/rejected': -7.032812595367432, 'epoch': 1.43}
 48%|████▊     | 900/1881 [2:07:38<2:28:51,  9.10s/it] 48%|████▊     | 901/1881 [2:07:45<2:22:50,  8.75s/it] 48%|████▊     | 902/1881 [2:07:53<2:19:44,  8.56s/it] 48%|████▊     | 903/1881 [2:08:02<2:18:19,  8.49s/it] 48%|████▊     | 904/1881 [2:08:14<2:38:14,  9.72s/it] 48%|████▊     | 905/1881 [2:08:21<2:23:25,  8.82s/it] 48%|████▊     | 906/1881 [2:08:27<2:11:02,  8.06s/it] 48%|████▊     | 907/1881 [2:08:35<2:08:00,  7.89s/it] 48%|████▊     | 908/1881 [2:08:40<1:56:50,  7.20s/it] 48%|████▊     | 909/1881 [2:08:47<1:53:09,  6.99s/it] 48%|████▊     | 910/1881 [2:08:55<1:59:12,  7.37s/it]                                                      {'loss': 0.3862, 'grad_norm': 41.22455978393555, 'learning_rate': 3.5691699407308544e-07, 'rewards/chosen': 1.67169189453125, 'rewards/rejected': -0.532958984375, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.206249952316284, 'logps/chosen': -231.6374969482422, 'logps/rejected': -171.77499389648438, 'logits/chosen': -6.987500190734863, 'logits/rejected': -6.870312690734863, 'epoch': 1.45}
 48%|████▊     | 910/1881 [2:08:55<1:59:12,  7.37s/it] 48%|████▊     | 911/1881 [2:09:05<2:12:13,  8.18s/it] 48%|████▊     | 912/1881 [2:09:13<2:08:58,  7.99s/it] 49%|████▊     | 913/1881 [2:09:18<1:56:56,  7.25s/it] 49%|████▊     | 914/1881 [2:09:24<1:52:13,  6.96s/it] 49%|████▊     | 915/1881 [2:09:30<1:45:08,  6.53s/it] 49%|████▊     | 916/1881 [2:09:42<2:10:16,  8.10s/it] 49%|████▉     | 917/1881 [2:09:49<2:08:35,  8.00s/it] 49%|████▉     | 918/1881 [2:09:58<2:09:43,  8.08s/it] 49%|████▉     | 919/1881 [2:10:08<2:22:22,  8.88s/it] 49%|████▉     | 920/1881 [2:10:14<2:04:09,  7.75s/it]                                                      {'loss': 0.334, 'grad_norm': 27.660688400268555, 'learning_rate': 3.539469625856436e-07, 'rewards/chosen': 2.495147705078125, 'rewards/rejected': -1.0119750499725342, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.505859375, 'logps/chosen': -287.38751220703125, 'logps/rejected': -171.4499969482422, 'logits/chosen': -6.717187404632568, 'logits/rejected': -6.684374809265137, 'epoch': 1.47}
 49%|████▉     | 920/1881 [2:10:14<2:04:09,  7.75s/it] 49%|████▉     | 921/1881 [2:10:18<1:46:27,  6.65s/it] 49%|████▉     | 922/1881 [2:10:30<2:12:24,  8.28s/it] 49%|████▉     | 923/1881 [2:10:36<2:01:56,  7.64s/it] 49%|████▉     | 924/1881 [2:10:44<2:03:10,  7.72s/it] 49%|████▉     | 925/1881 [2:10:57<2:29:53,  9.41s/it] 49%|████▉     | 926/1881 [2:11:09<2:39:26, 10.02s/it] 49%|████▉     | 927/1881 [2:11:16<2:28:56,  9.37s/it] 49%|████▉     | 928/1881 [2:11:22<2:09:35,  8.16s/it] 49%|████▉     | 929/1881 [2:11:33<2:26:15,  9.22s/it] 49%|████▉     | 930/1881 [2:11:38<2:04:03,  7.83s/it]                                                      {'loss': 0.3857, 'grad_norm': 55.15762710571289, 'learning_rate': 3.508928661736701e-07, 'rewards/chosen': 1.535009741783142, 'rewards/rejected': -0.8441406488418579, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.3792967796325684, 'logps/chosen': -200.97500610351562, 'logps/rejected': -124.55000305175781, 'logits/chosen': -7.032812595367432, 'logits/rejected': -7.175000190734863, 'epoch': 1.48}
 49%|████▉     | 930/1881 [2:11:38<2:04:03,  7.83s/it] 49%|████▉     | 931/1881 [2:11:48<2:12:28,  8.37s/it] 50%|████▉     | 932/1881 [2:11:55<2:07:01,  8.03s/it] 50%|████▉     | 933/1881 [2:12:06<2:20:38,  8.90s/it] 50%|████▉     | 934/1881 [2:12:17<2:33:15,  9.71s/it] 50%|████▉     | 935/1881 [2:12:25<2:24:23,  9.16s/it] 50%|████▉     | 936/1881 [2:12:37<2:35:52,  9.90s/it] 50%|████▉     | 937/1881 [2:12:45<2:28:22,  9.43s/it] 50%|████▉     | 938/1881 [2:12:51<2:10:53,  8.33s/it] 50%|████▉     | 939/1881 [2:12:59<2:10:29,  8.31s/it]
  0%|          | 0/120 [00:00<?, ?it/s][A
  2%|▏         | 2/120 [00:01<01:30,  1.30it/s][A
  2%|▎         | 3/120 [00:03<02:08,  1.10s/it][A
  3%|▎         | 4/120 [00:04<02:26,  1.26s/it][A
  4%|▍         | 5/120 [00:06<02:43,  1.42s/it][A
  5%|▌         | 6/120 [00:07<02:45,  1.45s/it][A
  6%|▌         | 7/120 [00:11<03:46,  2.01s/it][A
  7%|▋         | 8/120 [00:13<03:49,  2.05s/it][A
  8%|▊         | 9/120 [00:16<04:38,  2.51s/it][A
  8%|▊         | 10/120 [00:18<04:09,  2.27s/it][A
  9%|▉         | 11/120 [00:20<03:43,  2.05s/it][A
 10%|█         | 12/120 [00:21<03:28,  1.93s/it][A
 11%|█         | 13/120 [00:25<04:18,  2.42s/it][A
 12%|█▏        | 14/120 [00:26<03:50,  2.18s/it][A
 12%|█▎        | 15/120 [00:29<03:55,  2.24s/it][A
 13%|█▎        | 16/120 [00:32<04:31,  2.61s/it][A
 14%|█▍        | 17/120 [00:36<04:58,  2.90s/it][A
 15%|█▌        | 18/120 [00:40<05:23,  3.17s/it][A
 16%|█▌        | 19/120 [00:42<05:11,  3.09s/it][A
 17%|█▋        | 20/120 [00:46<05:25,  3.26s/it][A
 18%|█▊        | 21/120 [00:48<04:36,  2.79s/it][A
 18%|█▊        | 22/120 [00:50<04:09,  2.55s/it][A
 19%|█▉        | 23/120 [00:54<04:47,  2.96s/it][A
 20%|██        | 24/120 [00:57<04:51,  3.04s/it][A
 21%|██        | 25/120 [01:00<04:46,  3.01s/it][A
 22%|██▏       | 26/120 [01:02<04:05,  2.61s/it][A
 22%|██▎       | 27/120 [01:05<04:27,  2.88s/it][A
 23%|██▎       | 28/120 [01:06<03:41,  2.41s/it][A
 24%|██▍       | 29/120 [01:07<02:50,  1.87s/it][A
 25%|██▌       | 30/120 [01:08<02:32,  1.69s/it][A
 26%|██▌       | 31/120 [01:09<01:59,  1.35s/it][A
 27%|██▋       | 32/120 [01:10<01:50,  1.26s/it][A
 28%|██▊       | 33/120 [01:11<01:38,  1.13s/it][A
 28%|██▊       | 34/120 [01:12<01:37,  1.13s/it][A
 29%|██▉       | 35/120 [01:12<01:22,  1.03it/s][A
 30%|███       | 36/120 [01:13<01:11,  1.17it/s][A
 31%|███       | 37/120 [01:14<01:18,  1.05it/s][A
 32%|███▏      | 38/120 [01:15<01:25,  1.04s/it][A
 32%|███▎      | 39/120 [01:17<01:36,  1.19s/it][A
 33%|███▎      | 40/120 [01:18<01:19,  1.01it/s][A
 34%|███▍      | 41/120 [01:19<01:27,  1.10s/it][A
 35%|███▌      | 42/120 [01:21<01:54,  1.47s/it][A
 36%|███▌      | 43/120 [01:23<01:49,  1.42s/it][A
 37%|███▋      | 44/120 [01:24<02:00,  1.58s/it][A
 38%|███▊      | 45/120 [01:26<01:48,  1.45s/it][A
 38%|███▊      | 46/120 [01:27<01:39,  1.34s/it][A
 39%|███▉      | 47/120 [01:28<01:30,  1.24s/it][A
 40%|████      | 48/120 [01:28<01:15,  1.04s/it][A
 41%|████      | 49/120 [01:29<01:13,  1.04s/it][A
 42%|████▏     | 50/120 [01:33<02:16,  1.94s/it][A
 42%|████▎     | 51/120 [01:35<02:03,  1.79s/it][A
 43%|████▎     | 52/120 [01:35<01:35,  1.40s/it][A
 44%|████▍     | 53/120 [01:36<01:21,  1.21s/it][A
 45%|████▌     | 54/120 [01:37<01:09,  1.06s/it][A
 46%|████▌     | 55/120 [01:38<01:06,  1.02s/it][A
 47%|████▋     | 56/120 [01:38<00:55,  1.15it/s][A
 48%|████▊     | 57/120 [01:39<00:47,  1.34it/s][A
 48%|████▊     | 58/120 [01:40<00:54,  1.14it/s][A
 49%|████▉     | 59/120 [01:42<01:07,  1.11s/it][A
 50%|█████     | 60/120 [01:43<01:07,  1.12s/it][A
 51%|█████     | 61/120 [01:43<00:57,  1.03it/s][A
 52%|█████▏    | 62/120 [01:45<01:06,  1.15s/it][A
 52%|█████▎    | 63/120 [01:46<00:57,  1.01s/it][A
 53%|█████▎    | 64/120 [01:49<01:32,  1.65s/it][A
 54%|█████▍    | 65/120 [01:52<01:55,  2.10s/it][A
 55%|█████▌    | 66/120 [01:53<01:39,  1.84s/it][A
 56%|█████▌    | 67/120 [01:54<01:21,  1.53s/it][A
 57%|█████▋    | 68/120 [01:55<01:08,  1.32s/it][A
 57%|█████▊    | 69/120 [01:55<00:54,  1.07s/it][A
 58%|█████▊    | 70/120 [01:57<00:58,  1.17s/it][A
 59%|█████▉    | 71/120 [01:58<01:01,  1.25s/it][A
 60%|██████    | 72/120 [01:58<00:48,  1.02s/it][A
 61%|██████    | 73/120 [01:59<00:41,  1.13it/s][A
 62%|██████▏   | 74/120 [02:00<00:38,  1.20it/s][A
 62%|██████▎   | 75/120 [02:00<00:35,  1.25it/s][A
 63%|██████▎   | 76/120 [02:02<00:45,  1.03s/it][A
 64%|██████▍   | 77/120 [02:03<00:45,  1.06s/it][A
 65%|██████▌   | 78/120 [02:04<00:43,  1.02s/it][A
 66%|██████▌   | 79/120 [02:06<00:50,  1.24s/it][A
 67%|██████▋   | 80/120 [02:07<00:44,  1.10s/it][A
 68%|██████▊   | 81/120 [02:10<01:05,  1.67s/it][A
 68%|██████▊   | 82/120 [02:10<00:50,  1.32s/it][A
 69%|██████▉   | 83/120 [02:12<00:51,  1.40s/it][A
 70%|███████   | 84/120 [02:13<00:52,  1.45s/it][A
 71%|███████   | 85/120 [02:14<00:44,  1.29s/it][A
 72%|███████▏  | 86/120 [02:15<00:40,  1.19s/it][A
 72%|███████▎  | 87/120 [02:17<00:41,  1.27s/it][A
 73%|███████▎  | 88/120 [02:18<00:41,  1.30s/it][A
 74%|███████▍  | 89/120 [02:19<00:40,  1.30s/it][A
 75%|███████▌  | 90/120 [02:20<00:32,  1.07s/it][A
 76%|███████▌  | 91/120 [02:23<00:50,  1.76s/it][A
 77%|███████▋  | 92/120 [02:25<00:47,  1.70s/it][A
 78%|███████▊  | 93/120 [02:26<00:45,  1.70s/it][A
 78%|███████▊  | 94/120 [02:28<00:39,  1.52s/it][A
 79%|███████▉  | 95/120 [02:28<00:33,  1.32s/it][A
 80%|████████  | 96/120 [02:29<00:28,  1.20s/it][A
 81%|████████  | 97/120 [02:31<00:29,  1.29s/it][A
 82%|████████▏ | 98/120 [02:33<00:32,  1.46s/it][A
 82%|████████▎ | 99/120 [02:34<00:31,  1.49s/it][A
 83%|████████▎ | 100/120 [02:38<00:44,  2.25s/it][A
 84%|████████▍ | 101/120 [02:40<00:37,  1.99s/it][A
 85%|████████▌ | 102/120 [02:41<00:33,  1.86s/it][A
 86%|████████▌ | 103/120 [02:42<00:26,  1.58s/it][A
 87%|████████▋ | 104/120 [02:43<00:23,  1.48s/it][A
 88%|████████▊ | 105/120 [02:44<00:20,  1.36s/it][A
 88%|████████▊ | 106/120 [02:45<00:17,  1.25s/it][A
 89%|████████▉ | 107/120 [02:47<00:17,  1.34s/it][A
 90%|█████████ | 108/120 [02:50<00:20,  1.69s/it][A
 91%|█████████ | 109/120 [02:50<00:15,  1.43s/it][A
 92%|█████████▏| 110/120 [02:51<00:12,  1.20s/it][A
 92%|█████████▎| 111/120 [02:53<00:11,  1.32s/it][A
 93%|█████████▎| 112/120 [02:54<00:10,  1.27s/it][A
 94%|█████████▍| 113/120 [02:55<00:09,  1.36s/it][A
 95%|█████████▌| 114/120 [02:58<00:10,  1.82s/it][A
 96%|█████████▌| 115/120 [03:00<00:08,  1.70s/it][A
 97%|█████████▋| 116/120 [03:01<00:05,  1.45s/it][A
 98%|█████████▊| 117/120 [03:01<00:03,  1.28s/it][A
 98%|█████████▊| 118/120 [03:04<00:03,  1.56s/it][A
 99%|█████████▉| 119/120 [03:04<00:01,  1.34s/it][A
100%|██████████| 120/120 [03:06<00:00,  1.43s/it][A                                                      
                                                 [A{'eval_loss': 0.4041297435760498, 'eval_runtime': 188.3392, 'eval_samples_per_second': 5.06, 'eval_steps_per_second': 0.637, 'eval_rewards/chosen': 2.9122445583343506, 'eval_rewards/rejected': 0.08702163398265839, 'eval_rewards/accuracies': 0.8041666746139526, 'eval_rewards/margins': 2.823885202407837, 'eval_logps/chosen': -363.6166687011719, 'eval_logps/rejected': -151.72084045410156, 'eval_logits/chosen': -6.564453125, 'eval_logits/rejected': -7.2205729484558105, 'epoch': 1.5}
 50%|████▉     | 939/1881 [2:16:08<2:10:29,  8.31s/it]
100%|██████████| 120/120 [03:06<00:00,  1.43s/it][A
                                                 [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 50%|████▉     | 940/1881 [2:16:30<18:01:41, 68.97s/it]                                                       {'loss': 0.4045, 'grad_norm': 65.75701904296875, 'learning_rate': 3.4775662158375934e-07, 'rewards/chosen': 3.967529296875, 'rewards/rejected': 0.32373046875, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.64306640625, 'logps/chosen': -407.23748779296875, 'logps/rejected': -262.38751220703125, 'logits/chosen': -6.735937595367432, 'logits/rejected': -6.579687595367432, 'epoch': 1.5}
 50%|████▉     | 940/1881 [2:16:30<18:01:41, 68.97s/it] 50%|█████     | 941/1881 [2:16:37<13:08:03, 50.30s/it] 50%|█████     | 942/1881 [2:16:45<9:52:01, 37.83s/it]  50%|█████     | 943/1881 [2:16:51<7:22:49, 28.33s/it] 50%|█████     | 944/1881 [2:16:58<5:39:54, 21.77s/it] 50%|█████     | 945/1881 [2:17:06<4:34:05, 17.57s/it] 50%|█████     | 946/1881 [2:17:11<3:36:43, 13.91s/it] 50%|█████     | 947/1881 [2:17:17<2:58:32, 11.47s/it] 50%|█████     | 948/1881 [2:17:31<3:10:20, 12.24s/it] 50%|█████     | 949/1881 [2:17:38<2:48:31, 10.85s/it] 51%|█████     | 950/1881 [2:17:44<2:22:03,  9.16s/it]                                                      {'loss': 0.3475, 'grad_norm': 41.89426040649414, 'learning_rate': 3.445401971185865e-07, 'rewards/chosen': 0.77093505859375, 'rewards/rejected': -1.4093749523162842, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.1812500953674316, 'logps/chosen': -130.6999969482422, 'logps/rejected': -114.4124984741211, 'logits/chosen': -7.110937595367432, 'logits/rejected': -6.734375, 'epoch': 1.51}
 51%|█████     | 950/1881 [2:17:44<2:22:03,  9.16s/it] 51%|█████     | 951/1881 [2:17:52<2:18:34,  8.94s/it] 51%|█████     | 952/1881 [2:17:59<2:07:03,  8.21s/it] 51%|█████     | 953/1881 [2:18:09<2:17:40,  8.90s/it] 51%|█████     | 954/1881 [2:18:17<2:14:21,  8.70s/it] 51%|█████     | 955/1881 [2:18:28<2:23:22,  9.29s/it] 51%|█████     | 956/1881 [2:18:32<2:00:53,  7.84s/it] 51%|█████     | 957/1881 [2:18:38<1:50:41,  7.19s/it] 51%|█████     | 958/1881 [2:18:49<2:08:54,  8.38s/it] 51%|█████     | 959/1881 [2:18:58<2:09:15,  8.41s/it] 51%|█████     | 960/1881 [2:19:05<2:03:44,  8.06s/it]                                                      {'loss': 0.4199, 'grad_norm': 31.956796646118164, 'learning_rate': 3.412456114016029e-07, 'rewards/chosen': 0.4146484434604645, 'rewards/rejected': -1.1143066883087158, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 1.5294921398162842, 'logps/chosen': -110.1875, 'logps/rejected': -98.7125015258789, 'logits/chosen': -7.245312690734863, 'logits/rejected': -7.0, 'epoch': 1.53}
 51%|█████     | 960/1881 [2:19:05<2:03:44,  8.06s/it] 51%|█████     | 961/1881 [2:19:12<1:58:29,  7.73s/it] 51%|█████     | 962/1881 [2:19:18<1:49:47,  7.17s/it] 51%|█████     | 963/1881 [2:19:28<2:02:06,  7.98s/it] 51%|█████     | 964/1881 [2:19:34<1:54:45,  7.51s/it] 51%|█████▏    | 965/1881 [2:19:39<1:43:20,  6.77s/it] 51%|█████▏    | 966/1881 [2:19:49<1:58:16,  7.76s/it] 51%|█████▏    | 967/1881 [2:19:56<1:54:26,  7.51s/it] 51%|█████▏    | 968/1881 [2:20:02<1:48:05,  7.10s/it] 52%|█████▏    | 969/1881 [2:20:13<2:03:48,  8.15s/it] 52%|█████▏    | 970/1881 [2:20:21<2:03:09,  8.11s/it]                                                      {'loss': 0.4169, 'grad_norm': 48.982173919677734, 'learning_rate': 3.3787493211015133e-07, 'rewards/chosen': 1.435156226158142, 'rewards/rejected': -0.5894531011581421, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 2.0257811546325684, 'logps/chosen': -201.78750610351562, 'logps/rejected': -159.0812530517578, 'logits/chosen': -7.050000190734863, 'logits/rejected': -6.875, 'epoch': 1.55}
 52%|█████▏    | 970/1881 [2:20:21<2:03:09,  8.11s/it] 52%|█████▏    | 971/1881 [2:20:28<2:00:20,  7.93s/it] 52%|█████▏    | 972/1881 [2:20:34<1:50:36,  7.30s/it] 52%|█████▏    | 973/1881 [2:20:42<1:51:11,  7.35s/it] 52%|█████▏    | 974/1881 [2:20:48<1:47:30,  7.11s/it] 52%|█████▏    | 975/1881 [2:20:56<1:47:53,  7.14s/it] 52%|█████▏    | 976/1881 [2:21:03<1:48:34,  7.20s/it] 52%|█████▏    | 977/1881 [2:21:11<1:52:17,  7.45s/it] 52%|█████▏    | 978/1881 [2:21:18<1:49:20,  7.27s/it] 52%|█████▏    | 979/1881 [2:21:25<1:49:43,  7.30s/it] 52%|█████▏    | 980/1881 [2:21:30<1:40:25,  6.69s/it]                                                      {'loss': 0.3913, 'grad_norm': 34.611759185791016, 'learning_rate': 3.344302746777943e-07, 'rewards/chosen': 0.536700427532196, 'rewards/rejected': -1.0813782215118408, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 1.619531273841858, 'logps/chosen': -99.4749984741211, 'logps/rejected': -102.17500305175781, 'logits/chosen': -7.143750190734863, 'logits/rejected': -7.037499904632568, 'epoch': 1.56}
 52%|█████▏    | 980/1881 [2:21:30<1:40:25,  6.69s/it] 52%|█████▏    | 981/1881 [2:21:40<1:54:17,  7.62s/it] 52%|█████▏    | 982/1881 [2:21:48<1:53:45,  7.59s/it] 52%|█████▏    | 983/1881 [2:21:58<2:07:19,  8.51s/it] 52%|█████▏    | 984/1881 [2:22:06<2:02:13,  8.18s/it] 52%|█████▏    | 985/1881 [2:22:13<1:57:00,  7.84s/it] 52%|█████▏    | 986/1881 [2:22:19<1:48:10,  7.25s/it] 52%|█████▏    | 987/1881 [2:22:26<1:48:52,  7.31s/it] 53%|█████▎    | 988/1881 [2:22:33<1:45:04,  7.06s/it] 53%|█████▎    | 989/1881 [2:22:42<1:53:50,  7.66s/it] 53%|█████▎    | 990/1881 [2:22:52<2:04:02,  8.35s/it]                                                      {'loss': 0.428, 'grad_norm': 38.0832633972168, 'learning_rate': 3.3091380096667096e-07, 'rewards/chosen': 1.561010718345642, 'rewards/rejected': -0.7847656011581421, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.3453125953674316, 'logps/chosen': -203.3249969482422, 'logps/rejected': -145.5749969482422, 'logits/chosen': -7.0, 'logits/rejected': -6.873437404632568, 'epoch': 1.58}
 53%|█████▎    | 990/1881 [2:22:52<2:04:02,  8.35s/it] 53%|█████▎    | 991/1881 [2:22:57<1:50:52,  7.48s/it] 53%|█████▎    | 992/1881 [2:23:04<1:48:16,  7.31s/it] 53%|█████▎    | 993/1881 [2:23:10<1:42:00,  6.89s/it] 53%|█████▎    | 994/1881 [2:23:19<1:53:31,  7.68s/it] 53%|█████▎    | 995/1881 [2:23:26<1:47:20,  7.27s/it] 53%|█████▎    | 996/1881 [2:23:36<2:02:12,  8.29s/it] 53%|█████▎    | 997/1881 [2:23:47<2:14:05,  9.10s/it] 53%|█████▎    | 998/1881 [2:23:55<2:07:43,  8.68s/it] 53%|█████▎    | 999/1881 [2:24:03<2:03:27,  8.40s/it] 53%|█████▎    | 1000/1881 [2:24:13<2:13:14,  9.07s/it]                                                       {'loss': 0.4188, 'grad_norm': 48.823455810546875, 'learning_rate': 3.273277179107161e-07, 'rewards/chosen': 2.4217529296875, 'rewards/rejected': -0.583203136920929, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.999218702316284, 'logps/chosen': -276.3500061035156, 'logps/rejected': -197.6374969482422, 'logits/chosen': -6.926562309265137, 'logits/rejected': -6.764062404632568, 'epoch': 1.59}
 53%|█████▎    | 1000/1881 [2:24:13<2:13:14,  9.07s/it] 53%|█████▎    | 1001/1881 [2:24:27<2:32:28, 10.40s/it] 53%|█████▎    | 1002/1881 [2:24:37<2:29:34, 10.21s/it] 53%|█████▎    | 1003/1881 [2:24:46<2:26:30, 10.01s/it] 53%|█████▎    | 1004/1881 [2:24:53<2:10:00,  8.89s/it] 53%|█████▎    | 1005/1881 [2:25:00<2:03:22,  8.45s/it] 53%|█████▎    | 1006/1881 [2:25:07<1:55:24,  7.91s/it] 54%|█████▎    | 1007/1881 [2:25:15<1:56:12,  7.98s/it] 54%|█████▎    | 1008/1881 [2:25:21<1:50:14,  7.58s/it] 54%|█████▎    | 1009/1881 [2:25:35<2:14:35,  9.26s/it] 54%|█████▎    | 1010/1881 [2:25:46<2:22:23,  9.81s/it]                                                       {'loss': 0.4187, 'grad_norm': 41.8848991394043, 'learning_rate': 3.236742761305903e-07, 'rewards/chosen': 1.7318115234375, 'rewards/rejected': -0.544873058795929, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 2.2767577171325684, 'logps/chosen': -218.89999389648438, 'logps/rejected': -163.625, 'logits/chosen': -7.139062404632568, 'logits/rejected': -7.006249904632568, 'epoch': 1.61}
 54%|█████▎    | 1010/1881 [2:25:46<2:22:23,  9.81s/it] 54%|█████▎    | 1011/1881 [2:25:54<2:14:22,  9.27s/it] 54%|█████▍    | 1012/1881 [2:26:04<2:20:29,  9.70s/it] 54%|█████▍    | 1013/1881 [2:26:19<2:42:45, 11.25s/it] 54%|█████▍    | 1014/1881 [2:26:28<2:33:14, 10.60s/it] 54%|█████▍    | 1015/1881 [2:26:37<2:22:34,  9.88s/it] 54%|█████▍    | 1016/1881 [2:26:43<2:08:39,  8.92s/it] 54%|█████▍    | 1017/1881 [2:26:49<1:56:07,  8.06s/it] 54%|█████▍    | 1018/1881 [2:26:56<1:48:45,  7.56s/it] 54%|█████▍    | 1019/1881 [2:27:05<1:57:47,  8.20s/it] 54%|█████▍    | 1020/1881 [2:27:15<2:04:03,  8.64s/it]                                                       {'loss': 0.3592, 'grad_norm': 36.14842224121094, 'learning_rate': 3.1995576852119474e-07, 'rewards/chosen': 1.7160155773162842, 'rewards/rejected': -1.045312523841858, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.762500047683716, 'logps/chosen': -226.6750030517578, 'logps/rejected': -142.8125, 'logits/chosen': -7.012499809265137, 'logits/rejected': -6.909375190734863, 'epoch': 1.62}
 54%|█████▍    | 1020/1881 [2:27:15<2:04:03,  8.64s/it] 54%|█████▍    | 1021/1881 [2:27:22<1:58:40,  8.28s/it] 54%|█████▍    | 1022/1881 [2:27:30<1:55:33,  8.07s/it] 54%|█████▍    | 1023/1881 [2:27:37<1:51:17,  7.78s/it] 54%|█████▍    | 1024/1881 [2:27:44<1:47:14,  7.51s/it] 54%|█████▍    | 1025/1881 [2:27:51<1:44:57,  7.36s/it] 55%|█████▍    | 1026/1881 [2:27:56<1:34:28,  6.63s/it] 55%|█████▍    | 1027/1881 [2:28:02<1:33:23,  6.56s/it] 55%|█████▍    | 1028/1881 [2:28:13<1:48:56,  7.66s/it] 55%|█████▍    | 1029/1881 [2:28:19<1:45:06,  7.40s/it] 55%|█████▍    | 1030/1881 [2:28:25<1:38:57,  6.98s/it]                                                       {'loss': 0.3604, 'grad_norm': 20.926513671875, 'learning_rate': 3.161745288126531e-07, 'rewards/chosen': 1.62017822265625, 'rewards/rejected': -1.0416991710662842, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 2.663281202316284, 'logps/chosen': -198.64999389648438, 'logps/rejected': -141.1125030517578, 'logits/chosen': -6.959374904632568, 'logits/rejected': -6.957812309265137, 'epoch': 1.64}
 55%|█████▍    | 1030/1881 [2:28:25<1:38:57,  6.98s/it] 55%|█████▍    | 1031/1881 [2:28:36<1:56:12,  8.20s/it] 55%|█████▍    | 1032/1881 [2:28:43<1:47:01,  7.56s/it] 55%|█████▍    | 1033/1881 [2:28:55<2:06:38,  8.96s/it] 55%|█████▍    | 1034/1881 [2:28:59<1:48:21,  7.68s/it] 55%|█████▌    | 1035/1881 [2:29:09<1:54:15,  8.10s/it] 55%|█████▌    | 1036/1881 [2:29:19<2:03:18,  8.76s/it] 55%|█████▌    | 1037/1881 [2:29:28<2:06:44,  9.01s/it] 55%|█████▌    | 1038/1881 [2:29:35<1:54:35,  8.16s/it] 55%|█████▌    | 1039/1881 [2:29:49<2:20:00,  9.98s/it] 55%|█████▌    | 1040/1881 [2:29:57<2:11:26,  9.38s/it]                                                       {'loss': 0.3865, 'grad_norm': 111.94682312011719, 'learning_rate': 3.1233293010566586e-07, 'rewards/chosen': 2.9605712890625, 'rewards/rejected': -0.23652343451976776, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 3.187939405441284, 'logps/chosen': -302.125, 'logps/rejected': -202.2375030517578, 'logits/chosen': -6.871874809265137, 'logits/rejected': -6.729687690734863, 'epoch': 1.66}
 55%|█████▌    | 1040/1881 [2:29:57<2:11:26,  9.38s/it] 55%|█████▌    | 1041/1881 [2:30:04<2:01:29,  8.68s/it] 55%|█████▌    | 1042/1881 [2:30:10<1:52:13,  8.03s/it] 55%|█████▌    | 1043/1881 [2:30:17<1:44:56,  7.51s/it] 56%|█████▌    | 1044/1881 [2:30:24<1:45:32,  7.57s/it] 56%|█████▌    | 1045/1881 [2:30:30<1:37:35,  7.00s/it] 56%|█████▌    | 1046/1881 [2:30:38<1:40:48,  7.24s/it] 56%|█████▌    | 1047/1881 [2:30:42<1:28:17,  6.35s/it] 56%|█████▌    | 1048/1881 [2:30:50<1:34:31,  6.81s/it] 56%|█████▌    | 1049/1881 [2:30:56<1:31:05,  6.57s/it] 56%|█████▌    | 1050/1881 [2:31:04<1:35:25,  6.89s/it]                                                       {'loss': 0.4396, 'grad_norm': 36.287349700927734, 'learning_rate': 3.0843338338215554e-07, 'rewards/chosen': 1.719323754310608, 'rewards/rejected': -0.775317370891571, 'rewards/accuracies': 0.7875000238418579, 'rewards/margins': 2.493896484375, 'logps/chosen': -217.7624969482422, 'logps/rejected': -136.10000610351562, 'logits/chosen': -7.224999904632568, 'logits/rejected': -6.948437690734863, 'epoch': 1.67}
 56%|█████▌    | 1050/1881 [2:31:04<1:35:25,  6.89s/it] 56%|█████▌    | 1051/1881 [2:31:15<1:52:53,  8.16s/it] 56%|█████▌    | 1052/1881 [2:31:21<1:44:40,  7.58s/it] 56%|█████▌    | 1053/1881 [2:31:32<2:00:40,  8.74s/it] 56%|█████▌    | 1054/1881 [2:31:43<2:07:06,  9.22s/it] 56%|█████▌    | 1055/1881 [2:31:57<2:27:56, 10.75s/it] 56%|█████▌    | 1056/1881 [2:32:05<2:16:56,  9.96s/it] 56%|█████▌    | 1057/1881 [2:32:14<2:12:41,  9.66s/it] 56%|█████▌    | 1058/1881 [2:32:20<1:57:45,  8.58s/it] 56%|█████▋    | 1059/1881 [2:32:27<1:48:12,  7.90s/it] 56%|█████▋    | 1060/1881 [2:32:33<1:40:33,  7.35s/it]                                                       {'loss': 0.3722, 'grad_norm': 24.336711883544922, 'learning_rate': 3.0447833599213814e-07, 'rewards/chosen': 2.9079833030700684, 'rewards/rejected': -0.26629638671875, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.1722655296325684, 'logps/chosen': -323.95001220703125, 'logps/rejected': -212.3625030517578, 'logits/chosen': -7.089062690734863, 'logits/rejected': -6.907812595367432, 'epoch': 1.69}
 56%|█████▋    | 1060/1881 [2:32:33<1:40:33,  7.35s/it] 56%|█████▋    | 1061/1881 [2:32:39<1:35:57,  7.02s/it] 56%|█████▋    | 1062/1881 [2:32:45<1:32:03,  6.74s/it] 57%|█████▋    | 1063/1881 [2:32:51<1:28:24,  6.48s/it] 57%|█████▋    | 1064/1881 [2:33:01<1:45:24,  7.74s/it] 57%|█████▋    | 1065/1881 [2:33:11<1:50:36,  8.13s/it] 57%|█████▋    | 1066/1881 [2:33:17<1:42:57,  7.58s/it] 57%|█████▋    | 1067/1881 [2:33:26<1:48:05,  7.97s/it] 57%|█████▋    | 1068/1881 [2:33:34<1:50:11,  8.13s/it] 57%|█████▋    | 1069/1881 [2:33:41<1:45:14,  7.78s/it] 57%|█████▋    | 1070/1881 [2:33:51<1:55:18,  8.53s/it]                                                       {'loss': 0.3211, 'grad_norm': 32.70527267456055, 'learning_rate': 3.0047027011776947e-07, 'rewards/chosen': 1.961889624595642, 'rewards/rejected': -1.1897461414337158, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.1480469703674316, 'logps/chosen': -252.0625, 'logps/rejected': -166.5625, 'logits/chosen': -6.932812690734863, 'logits/rejected': -6.84375, 'epoch': 1.7}
 57%|█████▋    | 1070/1881 [2:33:52<1:55:18,  8.53s/it] 57%|█████▋    | 1071/1881 [2:33:56<1:39:09,  7.34s/it] 57%|█████▋    | 1072/1881 [2:34:06<1:50:48,  8.22s/it] 57%|█████▋    | 1073/1881 [2:34:13<1:44:27,  7.76s/it] 57%|█████▋    | 1074/1881 [2:34:20<1:42:20,  7.61s/it] 57%|█████▋    | 1075/1881 [2:34:31<1:53:17,  8.43s/it] 57%|█████▋    | 1076/1881 [2:34:37<1:43:27,  7.71s/it] 57%|█████▋    | 1077/1881 [2:34:44<1:42:55,  7.68s/it] 57%|█████▋    | 1078/1881 [2:34:52<1:41:27,  7.58s/it] 57%|█████▋    | 1079/1881 [2:35:08<2:15:47, 10.16s/it] 57%|█████▋    | 1080/1881 [2:35:15<2:05:06,  9.37s/it]                                                       {'loss': 0.3471, 'grad_norm': 45.556671142578125, 'learning_rate': 2.964117012155314e-07, 'rewards/chosen': 0.957812488079071, 'rewards/rejected': -1.1911132335662842, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.146289110183716, 'logps/chosen': -146.60000610351562, 'logps/rejected': -129.8000030517578, 'logits/chosen': -7.4140625, 'logits/rejected': -6.904687404632568, 'epoch': 1.72}
 57%|█████▋    | 1080/1881 [2:35:15<2:05:06,  9.37s/it] 57%|█████▋    | 1081/1881 [2:35:21<1:48:44,  8.16s/it] 58%|█████▊    | 1082/1881 [2:35:27<1:42:18,  7.68s/it] 58%|█████▊    | 1083/1881 [2:35:34<1:39:59,  7.52s/it] 58%|█████▊    | 1084/1881 [2:35:40<1:34:15,  7.10s/it] 58%|█████▊    | 1085/1881 [2:35:46<1:29:16,  6.73s/it] 58%|█████▊    | 1086/1881 [2:35:56<1:42:54,  7.77s/it] 58%|█████▊    | 1087/1881 [2:36:03<1:36:05,  7.26s/it] 58%|█████▊    | 1088/1881 [2:36:12<1:42:50,  7.78s/it] 58%|█████▊    | 1089/1881 [2:36:18<1:38:34,  7.47s/it] 58%|█████▊    | 1090/1881 [2:36:26<1:38:56,  7.50s/it]                                                       {'loss': 0.3398, 'grad_norm': 32.20956039428711, 'learning_rate': 2.923051764375345e-07, 'rewards/chosen': 1.4090149402618408, 'rewards/rejected': -1.2527344226837158, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 2.6597657203674316, 'logps/chosen': -221.16250610351562, 'logps/rejected': -130.4499969482422, 'logits/chosen': -7.106249809265137, 'logits/rejected': -7.128125190734863, 'epoch': 1.74}
 58%|█████▊    | 1090/1881 [2:36:26<1:38:56,  7.50s/it] 58%|█████▊    | 1091/1881 [2:36:37<1:51:57,  8.50s/it] 58%|█████▊    | 1092/1881 [2:36:44<1:46:30,  8.10s/it] 58%|█████▊    | 1093/1881 [2:36:50<1:38:05,  7.47s/it] 58%|█████▊    | 1094/1881 [2:36:57<1:38:28,  7.51s/it] 58%|█████▊    | 1095/1881 [2:37:08<1:48:58,  8.32s/it] 58%|█████▊    | 1096/1881 [2:37:14<1:42:44,  7.85s/it] 58%|█████▊    | 1097/1881 [2:37:26<1:58:21,  9.06s/it] 58%|█████▊    | 1098/1881 [2:37:31<1:41:57,  7.81s/it] 58%|█████▊    | 1099/1881 [2:37:37<1:34:57,  7.29s/it] 58%|█████▊    | 1100/1881 [2:37:42<1:23:33,  6.42s/it]                                                       {'loss': 0.3821, 'grad_norm': 53.89674758911133, 'learning_rate': 2.881532730329295e-07, 'rewards/chosen': 1.955102562904358, 'rewards/rejected': -0.965319812297821, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.918164014816284, 'logps/chosen': -240.4375, 'logps/rejected': -136.7062530517578, 'logits/chosen': -7.0859375, 'logits/rejected': -7.045312404632568, 'epoch': 1.75}
 58%|█████▊    | 1100/1881 [2:37:42<1:23:33,  6.42s/it] 59%|█████▊    | 1101/1881 [2:37:47<1:19:55,  6.15s/it] 59%|█████▊    | 1102/1881 [2:37:55<1:24:52,  6.54s/it] 59%|█████▊    | 1103/1881 [2:38:01<1:24:24,  6.51s/it] 59%|█████▊    | 1104/1881 [2:38:12<1:39:57,  7.72s/it] 59%|█████▊    | 1105/1881 [2:38:18<1:33:47,  7.25s/it] 59%|█████▉    | 1106/1881 [2:38:27<1:41:43,  7.88s/it] 59%|█████▉    | 1107/1881 [2:38:34<1:39:09,  7.69s/it] 59%|█████▉    | 1108/1881 [2:38:41<1:34:21,  7.32s/it] 59%|█████▉    | 1109/1881 [2:38:49<1:35:35,  7.43s/it] 59%|█████▉    | 1110/1881 [2:38:56<1:35:19,  7.42s/it]                                                       {'loss': 0.3286, 'grad_norm': 62.32469940185547, 'learning_rate': 2.8395859673042875e-07, 'rewards/chosen': 1.909814476966858, 'rewards/rejected': -1.2045409679412842, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.117968797683716, 'logps/chosen': -226.1999969482422, 'logps/rejected': -137.85000610351562, 'logits/chosen': -7.098437309265137, 'logits/rejected': -6.995312690734863, 'epoch': 1.77}
 59%|█████▉    | 1110/1881 [2:38:57<1:35:19,  7.42s/it] 59%|█████▉    | 1111/1881 [2:39:06<1:45:45,  8.24s/it] 59%|█████▉    | 1112/1881 [2:39:14<1:42:45,  8.02s/it] 59%|█████▉    | 1113/1881 [2:39:24<1:51:49,  8.74s/it] 59%|█████▉    | 1114/1881 [2:39:33<1:52:29,  8.80s/it] 59%|█████▉    | 1115/1881 [2:39:40<1:44:25,  8.18s/it] 59%|█████▉    | 1116/1881 [2:39:50<1:51:14,  8.73s/it] 59%|█████▉    | 1117/1881 [2:40:02<2:04:30,  9.78s/it] 59%|█████▉    | 1118/1881 [2:40:16<2:19:32, 10.97s/it] 59%|█████▉    | 1119/1881 [2:40:20<1:55:50,  9.12s/it] 60%|█████▉    | 1120/1881 [2:40:28<1:50:58,  8.75s/it]                                                       {'loss': 0.3519, 'grad_norm': 37.04381561279297, 'learning_rate': 2.7972378010295534e-07, 'rewards/chosen': 1.6227538585662842, 'rewards/rejected': -1.118554711341858, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.7408204078674316, 'logps/chosen': -222.0, 'logps/rejected': -155.46249389648438, 'logits/chosen': -7.012499809265137, 'logits/rejected': -7.032812595367432, 'epoch': 1.78}
 60%|█████▉    | 1120/1881 [2:40:29<1:50:58,  8.75s/it] 60%|█████▉    | 1121/1881 [2:40:35<1:44:48,  8.27s/it] 60%|█████▉    | 1122/1881 [2:40:40<1:31:56,  7.27s/it] 60%|█████▉    | 1123/1881 [2:40:48<1:34:32,  7.48s/it] 60%|█████▉    | 1124/1881 [2:40:59<1:47:04,  8.49s/it] 60%|█████▉    | 1125/1881 [2:41:11<2:00:25,  9.56s/it] 60%|█████▉    | 1126/1881 [2:41:19<1:53:11,  9.00s/it] 60%|█████▉    | 1127/1881 [2:41:27<1:47:45,  8.57s/it] 60%|█████▉    | 1128/1881 [2:41:34<1:43:17,  8.23s/it] 60%|██████    | 1129/1881 [2:41:45<1:51:50,  8.92s/it] 60%|██████    | 1130/1881 [2:41:55<1:57:34,  9.39s/it]                                                       {'loss': 0.3235, 'grad_norm': 54.58650588989258, 'learning_rate': 2.7545148091544337e-07, 'rewards/chosen': 2.9878692626953125, 'rewards/rejected': -0.14589843153953552, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.130078077316284, 'logps/chosen': -314.51251220703125, 'logps/rejected': -218.25, 'logits/chosen': -6.848437309265137, 'logits/rejected': -6.690625190734863, 'epoch': 1.8}
 60%|██████    | 1130/1881 [2:41:55<1:57:34,  9.39s/it] 60%|██████    | 1131/1881 [2:42:04<1:55:39,  9.25s/it] 60%|██████    | 1132/1881 [2:42:10<1:44:18,  8.36s/it] 60%|██████    | 1133/1881 [2:42:17<1:38:23,  7.89s/it] 60%|██████    | 1134/1881 [2:42:24<1:33:44,  7.53s/it] 60%|██████    | 1135/1881 [2:42:29<1:26:16,  6.94s/it] 60%|██████    | 1136/1881 [2:42:38<1:32:16,  7.43s/it] 60%|██████    | 1137/1881 [2:42:44<1:27:49,  7.08s/it] 60%|██████    | 1138/1881 [2:42:55<1:43:08,  8.33s/it] 61%|██████    | 1139/1881 [2:43:01<1:32:38,  7.49s/it] 61%|██████    | 1140/1881 [2:43:08<1:29:56,  7.28s/it]                                                       {'loss': 0.4364, 'grad_norm': 46.48891830444336, 'learning_rate': 2.711443804568286e-07, 'rewards/chosen': 0.90826416015625, 'rewards/rejected': -1.169348120689392, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.0771241188049316, 'logps/chosen': -131.27499389648438, 'logps/rejected': -117.13749694824219, 'logits/chosen': -7.387499809265137, 'logits/rejected': -7.103125095367432, 'epoch': 1.82}
 61%|██████    | 1140/1881 [2:43:08<1:29:56,  7.28s/it] 61%|██████    | 1141/1881 [2:43:19<1:45:58,  8.59s/it] 61%|██████    | 1142/1881 [2:43:26<1:40:21,  8.15s/it] 61%|██████    | 1143/1881 [2:43:32<1:30:54,  7.39s/it] 61%|██████    | 1144/1881 [2:43:39<1:29:29,  7.29s/it] 61%|██████    | 1145/1881 [2:43:50<1:40:54,  8.23s/it] 61%|██████    | 1146/1881 [2:43:55<1:31:55,  7.50s/it] 61%|██████    | 1147/1881 [2:44:06<1:43:55,  8.50s/it] 61%|██████    | 1148/1881 [2:44:14<1:43:05,  8.44s/it] 61%|██████    | 1149/1881 [2:44:21<1:35:04,  7.79s/it] 61%|██████    | 1150/1881 [2:44:27<1:29:32,  7.35s/it]                                                       {'loss': 0.3842, 'grad_norm': 57.037147521972656, 'learning_rate': 2.6680518185727573e-07, 'rewards/chosen': 3.733349561691284, 'rewards/rejected': -0.2556823790073395, 'rewards/accuracies': 0.78125, 'rewards/margins': 3.99365234375, 'logps/chosen': -378.13751220703125, 'logps/rejected': -217.6750030517578, 'logits/chosen': -6.907812595367432, 'logits/rejected': -6.584374904632568, 'epoch': 1.83}
 61%|██████    | 1150/1881 [2:44:27<1:29:32,  7.35s/it] 61%|██████    | 1151/1881 [2:44:32<1:21:54,  6.73s/it] 61%|██████    | 1152/1881 [2:44:40<1:24:07,  6.92s/it] 61%|██████▏   | 1153/1881 [2:44:45<1:17:43,  6.41s/it] 61%|██████▏   | 1154/1881 [2:44:51<1:15:48,  6.26s/it] 61%|██████▏   | 1155/1881 [2:44:59<1:22:40,  6.83s/it] 61%|██████▏   | 1156/1881 [2:45:13<1:47:45,  8.92s/it] 62%|██████▏   | 1157/1881 [2:45:22<1:47:02,  8.87s/it] 62%|██████▏   | 1158/1881 [2:45:32<1:52:21,  9.32s/it] 62%|██████▏   | 1159/1881 [2:45:42<1:55:44,  9.62s/it] 62%|██████▏   | 1160/1881 [2:45:48<1:42:03,  8.49s/it]                                                       {'loss': 0.3527, 'grad_norm': 16.42050552368164, 'learning_rate': 2.624366083916969e-07, 'rewards/chosen': 1.3722655773162842, 'rewards/rejected': -0.9390624761581421, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.3099608421325684, 'logps/chosen': -188.8125, 'logps/rejected': -160.9375, 'logits/chosen': -7.043749809265137, 'logits/rejected': -6.8046875, 'epoch': 1.85}
 62%|██████▏   | 1160/1881 [2:45:48<1:42:03,  8.49s/it] 62%|██████▏   | 1161/1881 [2:45:55<1:36:35,  8.05s/it] 62%|██████▏   | 1162/1881 [2:46:02<1:31:41,  7.65s/it] 62%|██████▏   | 1163/1881 [2:46:07<1:22:26,  6.89s/it] 62%|██████▏   | 1164/1881 [2:46:16<1:30:23,  7.56s/it] 62%|██████▏   | 1165/1881 [2:46:23<1:29:23,  7.49s/it] 62%|██████▏   | 1166/1881 [2:46:31<1:28:12,  7.40s/it] 62%|██████▏   | 1167/1881 [2:46:40<1:35:21,  8.01s/it] 62%|██████▏   | 1168/1881 [2:46:47<1:30:13,  7.59s/it] 62%|██████▏   | 1169/1881 [2:46:59<1:45:54,  8.93s/it] 62%|██████▏   | 1170/1881 [2:47:10<1:54:27,  9.66s/it]                                                       {'loss': 0.3791, 'grad_norm': 46.80363464355469, 'learning_rate': 2.58041401770629e-07, 'rewards/chosen': 1.6459839344024658, 'rewards/rejected': -1.1798827648162842, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.827343702316284, 'logps/chosen': -212.7624969482422, 'logps/rejected': -141.6999969482422, 'logits/chosen': -6.971875190734863, 'logits/rejected': -6.790625095367432, 'epoch': 1.86}
 62%|██████▏   | 1170/1881 [2:47:10<1:54:27,  9.66s/it] 62%|██████▏   | 1171/1881 [2:47:18<1:48:50,  9.20s/it] 62%|██████▏   | 1172/1881 [2:47:25<1:39:24,  8.41s/it] 62%|██████▏   | 1173/1881 [2:47:30<1:28:48,  7.53s/it] 62%|██████▏   | 1174/1881 [2:47:38<1:28:53,  7.54s/it] 62%|██████▏   | 1175/1881 [2:47:47<1:34:18,  8.01s/it] 63%|██████▎   | 1176/1881 [2:47:54<1:31:16,  7.77s/it] 63%|██████▎   | 1177/1881 [2:48:08<1:52:04,  9.55s/it] 63%|██████▎   | 1178/1881 [2:48:14<1:38:45,  8.43s/it] 63%|██████▎   | 1179/1881 [2:48:22<1:39:25,  8.50s/it] 63%|██████▎   | 1180/1881 [2:48:30<1:38:06,  8.40s/it]                                                       {'loss': 0.3614, 'grad_norm': 34.141231536865234, 'learning_rate': 2.536223204195397e-07, 'rewards/chosen': 2.797192335128784, 'rewards/rejected': -0.5097411870956421, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.309765577316284, 'logps/chosen': -298.4125061035156, 'logps/rejected': -201.8000030517578, 'logits/chosen': -7.110937595367432, 'logits/rejected': -7.015625, 'epoch': 1.88}
 63%|██████▎   | 1180/1881 [2:48:31<1:38:06,  8.40s/it] 63%|██████▎   | 1181/1881 [2:48:39<1:36:59,  8.31s/it] 63%|██████▎   | 1182/1881 [2:48:45<1:30:17,  7.75s/it] 63%|██████▎   | 1183/1881 [2:48:51<1:25:00,  7.31s/it] 63%|██████▎   | 1184/1881 [2:49:02<1:35:15,  8.20s/it] 63%|██████▎   | 1185/1881 [2:49:09<1:32:22,  7.96s/it] 63%|██████▎   | 1186/1881 [2:49:15<1:26:20,  7.45s/it] 63%|██████▎   | 1187/1881 [2:49:19<1:14:33,  6.45s/it] 63%|██████▎   | 1188/1881 [2:49:26<1:16:44,  6.64s/it] 63%|██████▎   | 1189/1881 [2:49:34<1:21:08,  7.04s/it] 63%|██████▎   | 1190/1881 [2:49:44<1:30:51,  7.89s/it]                                                       {'loss': 0.3531, 'grad_norm': 31.54421615600586, 'learning_rate': 2.4918213774764335e-07, 'rewards/chosen': 2.227635145187378, 'rewards/rejected': -0.964672863483429, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.1898436546325684, 'logps/chosen': -262.76251220703125, 'logps/rejected': -149.4250030517578, 'logits/chosen': -6.948437690734863, 'logits/rejected': -6.903124809265137, 'epoch': 1.9}
 63%|██████▎   | 1190/1881 [2:49:44<1:30:51,  7.89s/it] 63%|██████▎   | 1191/1881 [2:49:53<1:34:35,  8.23s/it] 63%|██████▎   | 1192/1881 [2:50:00<1:28:31,  7.71s/it] 63%|██████▎   | 1193/1881 [2:50:06<1:23:50,  7.31s/it] 63%|██████▎   | 1194/1881 [2:50:14<1:24:45,  7.40s/it] 64%|██████▎   | 1195/1881 [2:50:20<1:19:05,  6.92s/it] 64%|██████▎   | 1196/1881 [2:50:27<1:20:44,  7.07s/it] 64%|██████▎   | 1197/1881 [2:50:34<1:19:12,  6.95s/it] 64%|██████▎   | 1198/1881 [2:50:43<1:27:45,  7.71s/it] 64%|██████▎   | 1199/1881 [2:50:54<1:38:07,  8.63s/it] 64%|██████▍   | 1200/1881 [2:50:59<1:26:18,  7.60s/it]                                                       {'loss': 0.4109, 'grad_norm': 39.03866958618164, 'learning_rate': 2.447236404073135e-07, 'rewards/chosen': 2.029313564300537, 'rewards/rejected': -0.504443347454071, 'rewards/accuracies': 0.793749988079071, 'rewards/margins': 2.5357422828674316, 'logps/chosen': -230.3874969482422, 'logps/rejected': -192.1125030517578, 'logits/chosen': -6.876562595367432, 'logits/rejected': -6.824999809265137, 'epoch': 1.91}
 64%|██████▍   | 1200/1881 [2:50:59<1:26:18,  7.60s/it] 64%|██████▍   | 1201/1881 [2:51:08<1:31:41,  8.09s/it] 64%|██████▍   | 1202/1881 [2:51:16<1:30:23,  7.99s/it] 64%|██████▍   | 1203/1881 [2:51:24<1:28:26,  7.83s/it] 64%|██████▍   | 1204/1881 [2:51:35<1:41:42,  9.01s/it] 64%|██████▍   | 1205/1881 [2:51:41<1:28:50,  7.89s/it] 64%|██████▍   | 1206/1881 [2:51:48<1:25:37,  7.61s/it] 64%|██████▍   | 1207/1881 [2:51:57<1:31:54,  8.18s/it] 64%|██████▍   | 1208/1881 [2:52:05<1:31:55,  8.20s/it] 64%|██████▍   | 1209/1881 [2:52:12<1:26:00,  7.68s/it] 64%|██████▍   | 1210/1881 [2:52:19<1:24:50,  7.59s/it]                                                       {'loss': 0.3916, 'grad_norm': 26.163999557495117, 'learning_rate': 2.402496265451837e-07, 'rewards/chosen': 2.688232421875, 'rewards/rejected': -0.6513000726699829, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 3.3453125953674316, 'logps/chosen': -310.04998779296875, 'logps/rejected': -175.89999389648438, 'logits/chosen': -7.114062309265137, 'logits/rejected': -7.231249809265137, 'epoch': 1.93}
 64%|██████▍   | 1210/1881 [2:52:19<1:24:50,  7.59s/it] 64%|██████▍   | 1211/1881 [2:52:27<1:24:03,  7.53s/it] 64%|██████▍   | 1212/1881 [2:52:37<1:34:28,  8.47s/it] 64%|██████▍   | 1213/1881 [2:52:47<1:39:33,  8.94s/it] 65%|██████▍   | 1214/1881 [2:52:58<1:45:44,  9.51s/it] 65%|██████▍   | 1215/1881 [2:53:12<1:58:38, 10.69s/it] 65%|██████▍   | 1216/1881 [2:53:17<1:40:20,  9.05s/it] 65%|██████▍   | 1217/1881 [2:53:25<1:36:00,  8.68s/it] 65%|██████▍   | 1218/1881 [2:53:32<1:33:11,  8.43s/it] 65%|██████▍   | 1219/1881 [2:53:40<1:31:20,  8.28s/it] 65%|██████▍   | 1220/1881 [2:53:45<1:18:07,  7.09s/it]                                                       {'loss': 0.3607, 'grad_norm': 29.61026954650879, 'learning_rate': 2.3576290404603485e-07, 'rewards/chosen': 2.585681200027466, 'rewards/rejected': -0.579882800579071, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.1606078147888184, 'logps/chosen': -284.1000061035156, 'logps/rejected': -188.46249389648438, 'logits/chosen': -7.060937404632568, 'logits/rejected': -6.910937309265137, 'epoch': 1.94}
 65%|██████▍   | 1220/1881 [2:53:45<1:18:07,  7.09s/it] 65%|██████▍   | 1221/1881 [2:53:50<1:11:16,  6.48s/it] 65%|██████▍   | 1222/1881 [2:54:00<1:22:46,  7.54s/it] 65%|██████▌   | 1223/1881 [2:54:13<1:40:36,  9.17s/it] 65%|██████▌   | 1224/1881 [2:54:20<1:34:31,  8.63s/it] 65%|██████▌   | 1225/1881 [2:54:27<1:30:04,  8.24s/it] 65%|██████▌   | 1226/1881 [2:54:33<1:21:29,  7.46s/it] 65%|██████▌   | 1227/1881 [2:54:40<1:18:05,  7.16s/it] 65%|██████▌   | 1228/1881 [2:54:46<1:15:49,  6.97s/it] 65%|██████▌   | 1229/1881 [2:54:53<1:17:10,  7.10s/it] 65%|██████▌   | 1230/1881 [2:54:59<1:13:24,  6.77s/it]                                                       {'loss': 0.3531, 'grad_norm': 42.576534271240234, 'learning_rate': 2.312662887705702e-07, 'rewards/chosen': 1.764990210533142, 'rewards/rejected': -1.1582520008087158, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.923046827316284, 'logps/chosen': -195.5, 'logps/rejected': -125.9625015258789, 'logits/chosen': -6.942187309265137, 'logits/rejected': -6.926562309265137, 'epoch': 1.96}
 65%|██████▌   | 1230/1881 [2:55:00<1:13:24,  6.77s/it] 65%|██████▌   | 1231/1881 [2:55:06<1:13:03,  6.74s/it] 65%|██████▌   | 1232/1881 [2:55:12<1:09:36,  6.44s/it] 66%|██████▌   | 1233/1881 [2:55:21<1:17:32,  7.18s/it] 66%|██████▌   | 1234/1881 [2:55:28<1:16:30,  7.10s/it] 66%|██████▌   | 1235/1881 [2:55:35<1:18:20,  7.28s/it] 66%|██████▌   | 1236/1881 [2:55:43<1:19:16,  7.37s/it] 66%|██████▌   | 1237/1881 [2:55:55<1:32:34,  8.63s/it] 66%|██████▌   | 1238/1881 [2:56:05<1:39:05,  9.25s/it] 66%|██████▌   | 1239/1881 [2:56:12<1:31:24,  8.54s/it] 66%|██████▌   | 1240/1881 [2:56:20<1:30:39,  8.49s/it]                                                       {'loss': 0.409, 'grad_norm': 118.40398406982422, 'learning_rate': 2.2676260278818575e-07, 'rewards/chosen': 4.163720607757568, 'rewards/rejected': -0.4439453184604645, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 4.613671779632568, 'logps/chosen': -413.26251220703125, 'logps/rejected': -199.61874389648438, 'logits/chosen': -6.817187309265137, 'logits/rejected': -6.848437309265137, 'epoch': 1.98}
 66%|██████▌   | 1240/1881 [2:56:21<1:30:39,  8.49s/it] 66%|██████▌   | 1241/1881 [2:56:29<1:29:03,  8.35s/it] 66%|██████▌   | 1242/1881 [2:56:37<1:30:20,  8.48s/it] 66%|██████▌   | 1243/1881 [2:56:50<1:43:31,  9.74s/it] 66%|██████▌   | 1244/1881 [2:56:57<1:34:12,  8.87s/it] 66%|██████▌   | 1245/1881 [2:57:04<1:28:34,  8.36s/it] 66%|██████▌   | 1246/1881 [2:57:11<1:24:27,  7.98s/it] 66%|██████▋   | 1247/1881 [2:57:21<1:30:32,  8.57s/it] 66%|██████▋   | 1248/1881 [2:57:27<1:23:17,  7.89s/it] 66%|██████▋   | 1249/1881 [2:57:38<1:32:19,  8.76s/it] 66%|██████▋   | 1250/1881 [2:57:47<1:32:38,  8.81s/it]                                                       {'loss': 0.375, 'grad_norm': 35.53620529174805, 'learning_rate': 2.222546726058429e-07, 'rewards/chosen': 1.92620849609375, 'rewards/rejected': -0.6107422113418579, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.5414061546325684, 'logps/chosen': -222.33749389648438, 'logps/rejected': -186.21249389648438, 'logits/chosen': -7.040625095367432, 'logits/rejected': -6.892187595367432, 'epoch': 1.99}
 66%|██████▋   | 1250/1881 [2:57:47<1:32:38,  8.81s/it] 67%|██████▋   | 1251/1881 [2:57:53<1:22:10,  7.83s/it] 67%|██████▋   | 1252/1881 [2:58:05<1:36:00,  9.16s/it]
  0%|          | 0/120 [00:00<?, ?it/s][A
  2%|▏         | 2/120 [00:01<01:09,  1.70it/s][A
  2%|▎         | 3/120 [00:02<01:56,  1.00it/s][A
  3%|▎         | 4/120 [00:04<02:18,  1.19s/it][A
  4%|▍         | 5/120 [00:05<02:32,  1.33s/it][A
  5%|▌         | 6/120 [00:07<02:38,  1.39s/it][A
  6%|▌         | 7/120 [00:10<03:49,  2.03s/it][A
  7%|▋         | 8/120 [00:13<04:02,  2.16s/it][A
  8%|▊         | 9/120 [00:16<04:48,  2.60s/it][A
  8%|▊         | 10/120 [00:18<04:22,  2.38s/it][A
  9%|▉         | 11/120 [00:20<03:52,  2.13s/it][A
 10%|█         | 12/120 [00:21<03:34,  1.98s/it][A
 11%|█         | 13/120 [00:23<03:29,  1.96s/it][A
 12%|█▏        | 14/120 [00:26<03:37,  2.05s/it][A
 12%|█▎        | 15/120 [00:29<04:06,  2.34s/it][A
 13%|█▎        | 16/120 [00:32<04:43,  2.73s/it][A
 14%|█▍        | 17/120 [00:36<05:02,  2.94s/it][A
 15%|█▌        | 18/120 [00:40<05:20,  3.14s/it][A
 16%|█▌        | 19/120 [00:42<05:06,  3.03s/it][A
 17%|█▋        | 20/120 [00:46<05:26,  3.27s/it][A
 18%|█▊        | 21/120 [00:48<04:37,  2.80s/it][A
 18%|█▊        | 22/120 [00:50<04:12,  2.57s/it][A
 19%|█▉        | 23/120 [00:54<04:50,  2.99s/it][A
 20%|██        | 24/120 [00:57<04:59,  3.12s/it][A
 21%|██        | 25/120 [01:00<05:04,  3.21s/it][A
 22%|██▏       | 26/120 [01:02<04:15,  2.71s/it][A
 22%|██▎       | 27/120 [01:06<04:33,  2.94s/it][A
 23%|██▎       | 28/120 [01:07<03:40,  2.40s/it][A
 24%|██▍       | 29/120 [01:07<02:54,  1.91s/it][A
 25%|██▌       | 30/120 [01:09<02:34,  1.72s/it][A
 26%|██▌       | 31/120 [01:10<02:01,  1.37s/it][A
 27%|██▋       | 32/120 [01:10<01:52,  1.27s/it][A
 28%|██▊       | 33/120 [01:11<01:43,  1.19s/it][A
 28%|██▊       | 34/120 [01:13<01:47,  1.25s/it][A
 29%|██▉       | 35/120 [01:13<01:31,  1.08s/it][A
 30%|███       | 36/120 [01:14<01:21,  1.03it/s][A
 31%|███       | 37/120 [01:15<01:25,  1.03s/it][A
 32%|███▏      | 38/120 [01:17<01:30,  1.10s/it][A
 32%|███▎      | 39/120 [01:18<01:30,  1.11s/it][A
 33%|███▎      | 40/120 [01:18<01:15,  1.07it/s][A
 34%|███▍      | 41/120 [01:19<01:13,  1.07it/s][A
 35%|███▌      | 42/120 [01:22<02:07,  1.64s/it][A
 36%|███▌      | 43/120 [01:24<01:58,  1.54s/it][A
 37%|███▋      | 44/120 [01:25<01:47,  1.42s/it][A
 38%|███▊      | 45/120 [01:26<01:40,  1.34s/it][A
 38%|███▊      | 46/120 [01:27<01:33,  1.26s/it][A
 39%|███▉      | 47/120 [01:28<01:29,  1.23s/it][A
 40%|████      | 48/120 [01:29<01:14,  1.03s/it][A
 41%|████      | 49/120 [01:30<01:15,  1.07s/it][A
 42%|████▏     | 50/120 [01:34<02:16,  1.95s/it][A
 42%|████▎     | 51/120 [01:35<02:04,  1.80s/it][A
 43%|████▎     | 52/120 [01:36<01:33,  1.38s/it][A
 44%|████▍     | 53/120 [01:37<01:20,  1.20s/it][A
 45%|████▌     | 54/120 [01:38<01:16,  1.16s/it][A
 46%|████▌     | 55/120 [01:39<01:17,  1.19s/it][A
 47%|████▋     | 56/120 [01:39<01:03,  1.01it/s][A
 48%|████▊     | 57/120 [01:40<00:53,  1.18it/s][A
 48%|████▊     | 58/120 [01:41<00:59,  1.05it/s][A
 49%|████▉     | 59/120 [01:43<01:10,  1.16s/it][A
 50%|█████     | 60/120 [01:44<01:09,  1.15s/it][A
 51%|█████     | 61/120 [01:45<00:57,  1.02it/s][A
 52%|█████▏    | 62/120 [01:46<01:06,  1.15s/it][A
 52%|█████▎    | 63/120 [01:47<00:57,  1.02s/it][A
 53%|█████▎    | 64/120 [01:50<01:37,  1.75s/it][A
 54%|█████▍    | 65/120 [01:53<01:58,  2.15s/it][A
 55%|█████▌    | 66/120 [01:54<01:41,  1.87s/it][A
 56%|█████▌    | 67/120 [01:55<01:22,  1.56s/it][A
 57%|█████▋    | 68/120 [01:56<01:08,  1.32s/it][A
 57%|█████▊    | 69/120 [01:57<00:53,  1.06s/it][A
 58%|█████▊    | 70/120 [01:58<00:58,  1.17s/it][A
 59%|█████▉    | 71/120 [02:00<01:01,  1.25s/it][A
 60%|██████    | 72/120 [02:00<00:48,  1.01s/it][A
 61%|██████    | 73/120 [02:00<00:41,  1.13it/s][A
 62%|██████▏   | 74/120 [02:01<00:34,  1.33it/s][A
 62%|██████▎   | 75/120 [02:02<00:32,  1.39it/s][A
 63%|██████▎   | 76/120 [02:03<00:42,  1.03it/s][A
 64%|██████▍   | 77/120 [02:04<00:43,  1.02s/it][A
 65%|██████▌   | 78/120 [02:05<00:41,  1.02it/s][A
 66%|██████▌   | 79/120 [02:07<00:49,  1.20s/it][A
 67%|██████▋   | 80/120 [02:08<00:42,  1.07s/it][A
 68%|██████▊   | 81/120 [02:11<01:07,  1.74s/it][A
 68%|██████▊   | 82/120 [02:12<00:53,  1.41s/it][A
 69%|██████▉   | 83/120 [02:13<00:55,  1.50s/it][A
 70%|███████   | 84/120 [02:15<00:54,  1.52s/it][A
 71%|███████   | 85/120 [02:16<00:47,  1.35s/it][A
 72%|███████▏  | 86/120 [02:17<00:41,  1.23s/it][A
 72%|███████▎  | 87/120 [02:18<00:42,  1.30s/it][A
 73%|███████▎  | 88/120 [02:19<00:42,  1.32s/it][A
 74%|███████▍  | 89/120 [02:21<00:45,  1.48s/it][A
 75%|███████▌  | 90/120 [02:22<00:35,  1.20s/it][A
 76%|███████▌  | 91/120 [02:25<00:53,  1.85s/it][A
 77%|███████▋  | 92/120 [02:27<00:49,  1.77s/it][A
 78%|███████▊  | 93/120 [02:29<00:47,  1.75s/it][A
 78%|███████▊  | 94/120 [02:30<00:40,  1.55s/it][A
 79%|███████▉  | 95/120 [02:30<00:33,  1.33s/it][A
 80%|████████  | 96/120 [02:31<00:28,  1.20s/it][A
 81%|████████  | 97/120 [02:33<00:29,  1.29s/it][A
 82%|████████▏ | 98/120 [02:35<00:31,  1.43s/it][A
 82%|████████▎ | 99/120 [02:36<00:30,  1.47s/it][A
 83%|████████▎ | 100/120 [02:40<00:42,  2.13s/it][A
 84%|████████▍ | 101/120 [02:41<00:36,  1.93s/it][A
 85%|████████▌ | 102/120 [02:43<00:32,  1.82s/it][A
 86%|████████▌ | 103/120 [02:44<00:25,  1.51s/it][A
 87%|████████▋ | 104/120 [02:45<00:22,  1.43s/it][A
 88%|████████▊ | 105/120 [02:46<00:19,  1.33s/it][A
 88%|████████▊ | 106/120 [02:47<00:18,  1.29s/it][A
 89%|████████▉ | 107/120 [02:49<00:17,  1.37s/it][A
 90%|█████████ | 108/120 [02:51<00:20,  1.68s/it][A
 91%|█████████ | 109/120 [02:52<00:15,  1.40s/it][A
 92%|█████████▏| 110/120 [02:53<00:11,  1.19s/it][A
 92%|█████████▎| 111/120 [02:55<00:12,  1.41s/it][A
 93%|█████████▎| 112/120 [02:56<00:10,  1.37s/it][A
 94%|█████████▍| 113/120 [02:57<00:09,  1.43s/it][A
 95%|█████████▌| 114/120 [03:00<00:11,  1.93s/it][A
 96%|█████████▌| 115/120 [03:02<00:08,  1.76s/it][A
 97%|█████████▋| 116/120 [03:02<00:05,  1.40s/it][A
 98%|█████████▊| 117/120 [03:03<00:03,  1.21s/it][A
 98%|█████████▊| 118/120 [03:06<00:03,  1.72s/it][A
 99%|█████████▉| 119/120 [03:07<00:01,  1.45s/it][A
100%|██████████| 120/120 [03:09<00:00,  1.51s/it][A                                                       
                                                 [A{'eval_loss': 0.3976345360279083, 'eval_runtime': 191.1623, 'eval_samples_per_second': 4.985, 'eval_steps_per_second': 0.628, 'eval_rewards/chosen': 3.139331102371216, 'eval_rewards/rejected': -0.17556151747703552, 'eval_rewards/accuracies': 0.8031250238418579, 'eval_rewards/margins': 3.3120665550231934, 'eval_logps/chosen': -362.5062561035156, 'eval_logps/rejected': -153.08958435058594, 'eval_logits/chosen': -6.661198139190674, 'eval_logits/rejected': -7.266145706176758, 'epoch': 1.99}
 67%|██████▋   | 1252/1881 [3:01:16<1:36:00,  9.16s/it]
100%|██████████| 120/120 [03:09<00:00,  1.51s/it][A
                                                 [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 67%|██████▋   | 1253/1881 [3:01:32<11:57:52, 68.59s/it] 67%|██████▋   | 1254/1881 [3:01:40<8:45:26, 50.28s/it]  67%|██████▋   | 1255/1881 [3:01:50<6:39:24, 38.28s/it] 67%|██████▋   | 1256/1881 [3:01:54<4:51:32, 27.99s/it] 67%|██████▋   | 1257/1881 [3:02:06<4:00:38, 23.14s/it] 67%|██████▋   | 1258/1881 [3:02:13<3:11:40, 18.46s/it] 67%|██████▋   | 1259/1881 [3:02:21<2:36:54, 15.14s/it] 67%|██████▋   | 1260/1881 [3:02:26<2:06:26, 12.22s/it]                                                       {'loss': 0.361, 'grad_norm': 15.42738151550293, 'learning_rate': 2.1774532739415708e-07, 'rewards/chosen': 2.2014546394348145, 'rewards/rejected': -0.9682360291481018, 'rewards/accuracies': 0.8157894611358643, 'rewards/margins': 3.1641652584075928, 'logps/chosen': -261.1973571777344, 'logps/rejected': -177.42105102539062, 'logits/chosen': -7.009868621826172, 'logits/rejected': -6.847039699554443, 'epoch': 2.01}
 67%|██████▋   | 1260/1881 [3:02:26<2:06:26, 12.22s/it] 67%|██████▋   | 1261/1881 [3:02:33<1:48:22, 10.49s/it] 67%|██████▋   | 1262/1881 [3:02:39<1:35:51,  9.29s/it] 67%|██████▋   | 1263/1881 [3:02:46<1:29:25,  8.68s/it] 67%|██████▋   | 1264/1881 [3:02:56<1:32:53,  9.03s/it] 67%|██████▋   | 1265/1881 [3:03:10<1:47:40, 10.49s/it] 67%|██████▋   | 1266/1881 [3:03:19<1:42:53, 10.04s/it] 67%|██████▋   | 1267/1881 [3:03:33<1:54:45, 11.21s/it] 67%|██████▋   | 1268/1881 [3:03:40<1:40:55,  9.88s/it] 67%|██████▋   | 1269/1881 [3:03:47<1:32:40,  9.09s/it] 68%|██████▊   | 1270/1881 [3:03:52<1:19:32,  7.81s/it]                                                       {'loss': 0.3069, 'grad_norm': 37.86388397216797, 'learning_rate': 2.132373972118143e-07, 'rewards/chosen': 2.1658692359924316, 'rewards/rejected': -1.3585937023162842, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 3.5296874046325684, 'logps/chosen': -240.6374969482422, 'logps/rejected': -162.4812469482422, 'logits/chosen': -7.126562595367432, 'logits/rejected': -6.803124904632568, 'epoch': 2.02}
 68%|██████▊   | 1270/1881 [3:03:52<1:19:32,  7.81s/it] 68%|██████▊   | 1271/1881 [3:04:00<1:21:24,  8.01s/it] 68%|██████▊   | 1272/1881 [3:04:08<1:19:00,  7.78s/it] 68%|██████▊   | 1273/1881 [3:04:15<1:17:42,  7.67s/it] 68%|██████▊   | 1274/1881 [3:04:22<1:17:13,  7.63s/it] 68%|██████▊   | 1275/1881 [3:04:35<1:30:29,  8.96s/it] 68%|██████▊   | 1276/1881 [3:04:41<1:24:06,  8.34s/it] 68%|██████▊   | 1277/1881 [3:04:48<1:18:02,  7.75s/it] 68%|██████▊   | 1278/1881 [3:04:57<1:22:27,  8.20s/it] 68%|██████▊   | 1279/1881 [3:05:05<1:21:00,  8.07s/it] 68%|██████▊   | 1280/1881 [3:05:12<1:19:18,  7.92s/it]                                                       {'loss': 0.2936, 'grad_norm': 31.31134605407715, 'learning_rate': 2.087337112294298e-07, 'rewards/chosen': 3.570697069168091, 'rewards/rejected': -0.687817394733429, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.2587890625, 'logps/chosen': -362.4624938964844, 'logps/rejected': -205.35000610351562, 'logits/chosen': -6.982812404632568, 'logits/rejected': -6.732812404632568, 'epoch': 2.04}
 68%|██████▊   | 1280/1881 [3:05:12<1:19:18,  7.92s/it] 68%|██████▊   | 1281/1881 [3:05:22<1:24:19,  8.43s/it] 68%|██████▊   | 1282/1881 [3:05:27<1:15:02,  7.52s/it] 68%|██████▊   | 1283/1881 [3:05:37<1:21:51,  8.21s/it] 68%|██████▊   | 1284/1881 [3:05:45<1:19:49,  8.02s/it] 68%|██████▊   | 1285/1881 [3:05:52<1:18:36,  7.91s/it] 68%|██████▊   | 1286/1881 [3:05:58<1:12:39,  7.33s/it] 68%|██████▊   | 1287/1881 [3:06:06<1:13:48,  7.46s/it] 68%|██████▊   | 1288/1881 [3:06:13<1:13:08,  7.40s/it] 69%|██████▊   | 1289/1881 [3:06:26<1:29:33,  9.08s/it] 69%|██████▊   | 1290/1881 [3:06:38<1:35:34,  9.70s/it]                                                       {'loss': 0.3509, 'grad_norm': 50.232967376708984, 'learning_rate': 2.0423709595396517e-07, 'rewards/chosen': 1.9741699695587158, 'rewards/rejected': -0.8543456792831421, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.828125, 'logps/chosen': -226.2375030517578, 'logps/rejected': -171.4499969482422, 'logits/chosen': -7.243750095367432, 'logits/rejected': -7.025000095367432, 'epoch': 2.05}
 69%|██████▊   | 1290/1881 [3:06:38<1:35:34,  9.70s/it] 69%|██████▊   | 1291/1881 [3:06:45<1:29:26,  9.10s/it] 69%|██████▊   | 1292/1881 [3:06:53<1:25:18,  8.69s/it] 69%|██████▊   | 1293/1881 [3:06:58<1:13:22,  7.49s/it] 69%|██████▉   | 1294/1881 [3:07:06<1:16:54,  7.86s/it] 69%|██████▉   | 1295/1881 [3:07:16<1:22:42,  8.47s/it] 69%|██████▉   | 1296/1881 [3:07:22<1:14:30,  7.64s/it] 69%|██████▉   | 1297/1881 [3:07:30<1:14:14,  7.63s/it] 69%|██████▉   | 1298/1881 [3:07:39<1:19:39,  8.20s/it] 69%|██████▉   | 1299/1881 [3:07:48<1:20:10,  8.27s/it] 69%|██████▉   | 1300/1881 [3:07:59<1:30:14,  9.32s/it]                                                       {'loss': 0.3376, 'grad_norm': 16.073869705200195, 'learning_rate': 1.9975037345481628e-07, 'rewards/chosen': 1.014685034751892, 'rewards/rejected': -1.43212890625, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.4457030296325684, 'logps/chosen': -164.22500610351562, 'logps/rejected': -137.46249389648438, 'logits/chosen': -7.096875190734863, 'logits/rejected': -6.762499809265137, 'epoch': 2.07}
 69%|██████▉   | 1300/1881 [3:08:00<1:30:14,  9.32s/it] 69%|██████▉   | 1301/1881 [3:08:13<1:41:48, 10.53s/it] 69%|██████▉   | 1302/1881 [3:08:21<1:36:12,  9.97s/it] 69%|██████▉   | 1303/1881 [3:08:28<1:27:07,  9.04s/it] 69%|██████▉   | 1304/1881 [3:08:39<1:32:35,  9.63s/it] 69%|██████▉   | 1305/1881 [3:08:45<1:22:19,  8.58s/it] 69%|██████▉   | 1306/1881 [3:08:53<1:19:35,  8.31s/it] 69%|██████▉   | 1307/1881 [3:09:01<1:17:48,  8.13s/it] 70%|██████▉   | 1308/1881 [3:09:07<1:13:07,  7.66s/it] 70%|██████▉   | 1309/1881 [3:09:15<1:12:41,  7.62s/it] 70%|██████▉   | 1310/1881 [3:09:23<1:12:56,  7.66s/it]                                                       {'loss': 0.2555, 'grad_norm': 18.42123794555664, 'learning_rate': 1.9527635959268652e-07, 'rewards/chosen': 3.3307862281799316, 'rewards/rejected': -0.744824230670929, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 4.071875095367432, 'logps/chosen': -328.1000061035156, 'logps/rejected': -202.52499389648438, 'logits/chosen': -6.895312309265137, 'logits/rejected': -6.701562404632568, 'epoch': 2.09}
 70%|██████▉   | 1310/1881 [3:09:23<1:12:56,  7.66s/it] 70%|██████▉   | 1311/1881 [3:09:30<1:13:13,  7.71s/it] 70%|██████▉   | 1312/1881 [3:09:36<1:07:42,  7.14s/it] 70%|██████▉   | 1313/1881 [3:09:44<1:09:28,  7.34s/it] 70%|██████▉   | 1314/1881 [3:09:51<1:07:36,  7.15s/it] 70%|██████▉   | 1315/1881 [3:10:02<1:18:25,  8.31s/it] 70%|██████▉   | 1316/1881 [3:10:07<1:10:06,  7.44s/it] 70%|███████   | 1317/1881 [3:10:19<1:22:10,  8.74s/it] 70%|███████   | 1318/1881 [3:10:28<1:22:05,  8.75s/it] 70%|███████   | 1319/1881 [3:10:36<1:19:26,  8.48s/it] 70%|███████   | 1320/1881 [3:10:44<1:19:48,  8.54s/it]                                                       {'loss': 0.3602, 'grad_norm': 37.65898132324219, 'learning_rate': 1.9081786225235664e-07, 'rewards/chosen': 1.1623718738555908, 'rewards/rejected': -1.3796875476837158, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 2.541015625, 'logps/chosen': -178.3000030517578, 'logps/rejected': -152.08749389648438, 'logits/chosen': -7.356249809265137, 'logits/rejected': -7.243750095367432, 'epoch': 2.1}
 70%|███████   | 1320/1881 [3:10:45<1:19:48,  8.54s/it] 70%|███████   | 1321/1881 [3:10:56<1:29:28,  9.59s/it] 70%|███████   | 1322/1881 [3:11:03<1:20:42,  8.66s/it] 70%|███████   | 1323/1881 [3:11:11<1:18:19,  8.42s/it] 70%|███████   | 1324/1881 [3:11:18<1:14:48,  8.06s/it] 70%|███████   | 1325/1881 [3:11:26<1:13:40,  7.95s/it] 70%|███████   | 1326/1881 [3:11:36<1:20:50,  8.74s/it] 71%|███████   | 1327/1881 [3:11:43<1:14:12,  8.04s/it] 71%|███████   | 1328/1881 [3:11:51<1:15:26,  8.18s/it] 71%|███████   | 1329/1881 [3:11:58<1:11:54,  7.82s/it] 71%|███████   | 1330/1881 [3:12:04<1:06:54,  7.29s/it]                                                       {'loss': 0.2962, 'grad_norm': 28.056396484375, 'learning_rate': 1.8637767958046027e-07, 'rewards/chosen': 1.49658203125, 'rewards/rejected': -1.4521484375, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 2.9466795921325684, 'logps/chosen': -193.9499969482422, 'logps/rejected': -147.8625030517578, 'logits/chosen': -7.1328125, 'logits/rejected': -7.028124809265137, 'epoch': 2.12}
 71%|███████   | 1330/1881 [3:12:05<1:06:54,  7.29s/it] 71%|███████   | 1331/1881 [3:12:10<1:03:04,  6.88s/it] 71%|███████   | 1332/1881 [3:12:21<1:14:10,  8.11s/it] 71%|███████   | 1333/1881 [3:12:28<1:09:59,  7.66s/it] 71%|███████   | 1334/1881 [3:12:39<1:19:40,  8.74s/it] 71%|███████   | 1335/1881 [3:12:48<1:20:05,  8.80s/it] 71%|███████   | 1336/1881 [3:12:55<1:14:27,  8.20s/it] 71%|███████   | 1337/1881 [3:13:01<1:09:19,  7.65s/it] 71%|███████   | 1338/1881 [3:13:08<1:08:34,  7.58s/it] 71%|███████   | 1339/1881 [3:13:14<1:03:06,  6.99s/it] 71%|███████   | 1340/1881 [3:13:19<56:55,  6.31s/it]                                                       {'loss': 0.3191, 'grad_norm': 26.648347854614258, 'learning_rate': 1.8195859822937093e-07, 'rewards/chosen': 0.812518298625946, 'rewards/rejected': -1.6892578601837158, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.503124952316284, 'logps/chosen': -161.125, 'logps/rejected': -126.2125015258789, 'logits/chosen': -6.934374809265137, 'logits/rejected': -6.832812309265137, 'epoch': 2.13}
 71%|███████   | 1340/1881 [3:13:19<56:55,  6.31s/it] 71%|███████▏  | 1341/1881 [3:13:30<1:09:28,  7.72s/it] 71%|███████▏  | 1342/1881 [3:13:37<1:07:18,  7.49s/it] 71%|███████▏  | 1343/1881 [3:13:43<1:04:10,  7.16s/it] 71%|███████▏  | 1344/1881 [3:13:51<1:05:13,  7.29s/it] 72%|███████▏  | 1345/1881 [3:13:56<59:12,  6.63s/it]   72%|███████▏  | 1346/1881 [3:14:06<1:09:33,  7.80s/it] 72%|███████▏  | 1347/1881 [3:14:14<1:08:33,  7.70s/it] 72%|███████▏  | 1348/1881 [3:14:20<1:03:10,  7.11s/it] 72%|███████▏  | 1349/1881 [3:14:26<1:00:19,  6.80s/it] 72%|███████▏  | 1350/1881 [3:14:32<58:01,  6.56s/it]                                                       {'loss': 0.3086, 'grad_norm': 38.21879196166992, 'learning_rate': 1.7756339160830307e-07, 'rewards/chosen': 1.828222632408142, 'rewards/rejected': -1.5568358898162842, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.3851561546325684, 'logps/chosen': -199.6125030517578, 'logps/rejected': -128.1875, 'logits/chosen': -7.303124904632568, 'logits/rejected': -7.275000095367432, 'epoch': 2.15}
 72%|███████▏  | 1350/1881 [3:14:32<58:01,  6.56s/it] 72%|███████▏  | 1351/1881 [3:14:43<1:09:35,  7.88s/it] 72%|███████▏  | 1352/1881 [3:14:49<1:06:00,  7.49s/it] 72%|███████▏  | 1353/1881 [3:14:58<1:08:33,  7.79s/it] 72%|███████▏  | 1354/1881 [3:15:07<1:13:54,  8.41s/it] 72%|███████▏  | 1355/1881 [3:15:14<1:08:46,  7.85s/it] 72%|███████▏  | 1356/1881 [3:15:22<1:07:59,  7.77s/it] 72%|███████▏  | 1357/1881 [3:15:31<1:12:56,  8.35s/it] 72%|███████▏  | 1358/1881 [3:15:42<1:18:58,  9.06s/it] 72%|███████▏  | 1359/1881 [3:15:53<1:23:06,  9.55s/it] 72%|███████▏  | 1360/1881 [3:15:59<1:15:13,  8.66s/it]                                                       {'loss': 0.2788, 'grad_norm': 29.20688819885254, 'learning_rate': 1.7319481814272424e-07, 'rewards/chosen': 3.876708984375, 'rewards/rejected': -1.0623047351837158, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.933203220367432, 'logps/chosen': -382.75, 'logps/rejected': -205.64999389648438, 'logits/chosen': -6.923437595367432, 'logits/rejected': -6.856249809265137, 'epoch': 2.17}
 72%|███████▏  | 1360/1881 [3:16:00<1:15:13,  8.66s/it] 72%|███████▏  | 1361/1881 [3:16:16<1:35:18, 11.00s/it] 72%|███████▏  | 1362/1881 [3:16:23<1:26:34, 10.01s/it] 72%|███████▏  | 1363/1881 [3:16:35<1:30:32, 10.49s/it] 73%|███████▎  | 1364/1881 [3:16:41<1:18:43,  9.14s/it] 73%|███████▎  | 1365/1881 [3:16:49<1:14:34,  8.67s/it] 73%|███████▎  | 1366/1881 [3:16:59<1:18:59,  9.20s/it] 73%|███████▎  | 1367/1881 [3:17:05<1:10:42,  8.25s/it] 73%|███████▎  | 1368/1881 [3:17:14<1:12:45,  8.51s/it] 73%|███████▎  | 1369/1881 [3:17:22<1:11:13,  8.35s/it] 73%|███████▎  | 1370/1881 [3:17:30<1:10:31,  8.28s/it]                                                       {'loss': 0.3226, 'grad_norm': 53.182926177978516, 'learning_rate': 1.6885561954317132e-07, 'rewards/chosen': 2.1015868186950684, 'rewards/rejected': -1.1474120616912842, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.2470703125, 'logps/chosen': -240.8874969482422, 'logps/rejected': -183.77499389648438, 'logits/chosen': -7.184374809265137, 'logits/rejected': -7.1015625, 'epoch': 2.18}
 73%|███████▎  | 1370/1881 [3:17:31<1:10:31,  8.28s/it] 73%|███████▎  | 1371/1881 [3:17:38<1:09:21,  8.16s/it] 73%|███████▎  | 1372/1881 [3:17:45<1:04:49,  7.64s/it] 73%|███████▎  | 1373/1881 [3:17:52<1:04:36,  7.63s/it] 73%|███████▎  | 1374/1881 [3:18:04<1:16:02,  9.00s/it] 73%|███████▎  | 1375/1881 [3:18:13<1:13:37,  8.73s/it] 73%|███████▎  | 1376/1881 [3:18:20<1:11:30,  8.50s/it] 73%|███████▎  | 1377/1881 [3:18:29<1:11:50,  8.55s/it] 73%|███████▎  | 1378/1881 [3:18:36<1:06:25,  7.92s/it] 73%|███████▎  | 1379/1881 [3:18:42<1:02:24,  7.46s/it] 73%|███████▎  | 1380/1881 [3:18:50<1:03:51,  7.65s/it]                                                       {'loss': 0.3657, 'grad_norm': 66.99427795410156, 'learning_rate': 1.6454851908455668e-07, 'rewards/chosen': 3.1734375953674316, 'rewards/rejected': -1.1409180164337158, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 4.313281059265137, 'logps/chosen': -337.5, 'logps/rejected': -197.1125030517578, 'logits/chosen': -6.917187690734863, 'logits/rejected': -6.790625095367432, 'epoch': 2.2}
 73%|███████▎  | 1380/1881 [3:18:51<1:03:51,  7.65s/it] 73%|███████▎  | 1381/1881 [3:19:03<1:17:33,  9.31s/it] 73%|███████▎  | 1382/1881 [3:19:10<1:09:48,  8.39s/it] 74%|███████▎  | 1383/1881 [3:19:16<1:05:46,  7.93s/it] 74%|███████▎  | 1384/1881 [3:19:26<1:10:14,  8.48s/it] 74%|███████▎  | 1385/1881 [3:19:33<1:06:33,  8.05s/it] 74%|███████▎  | 1386/1881 [3:19:39<1:01:40,  7.48s/it] 74%|███████▎  | 1387/1881 [3:19:49<1:07:32,  8.20s/it] 74%|███████▍  | 1388/1881 [3:19:56<1:03:35,  7.74s/it] 74%|███████▍  | 1389/1881 [3:20:11<1:22:11, 10.02s/it] 74%|███████▍  | 1390/1881 [3:20:21<1:22:26, 10.08s/it]                                                       {'loss': 0.2935, 'grad_norm': 43.26662826538086, 'learning_rate': 1.6027621989704468e-07, 'rewards/chosen': 3.4775359630584717, 'rewards/rejected': -0.8130859136581421, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.29296875, 'logps/chosen': -343.7250061035156, 'logps/rejected': -173.4875030517578, 'logits/chosen': -6.9453125, 'logits/rejected': -6.735937595367432, 'epoch': 2.21}
 74%|███████▍  | 1390/1881 [3:20:22<1:22:26, 10.08s/it] 74%|███████▍  | 1391/1881 [3:20:29<1:16:43,  9.39s/it] 74%|███████▍  | 1392/1881 [3:20:36<1:10:11,  8.61s/it] 74%|███████▍  | 1393/1881 [3:20:40<59:53,  7.36s/it]   74%|███████▍  | 1394/1881 [3:20:47<58:44,  7.24s/it] 74%|███████▍  | 1395/1881 [3:20:54<57:38,  7.12s/it] 74%|███████▍  | 1396/1881 [3:21:05<1:06:27,  8.22s/it] 74%|███████▍  | 1397/1881 [3:21:12<1:03:29,  7.87s/it] 74%|███████▍  | 1398/1881 [3:21:19<1:01:37,  7.65s/it] 74%|███████▍  | 1399/1881 [3:21:28<1:04:12,  7.99s/it] 74%|███████▍  | 1400/1881 [3:21:33<57:25,  7.16s/it]                                                       {'loss': 0.2891, 'grad_norm': 24.32855224609375, 'learning_rate': 1.560414032695713e-07, 'rewards/chosen': 2.4395995140075684, 'rewards/rejected': -0.9512695074081421, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 3.392773389816284, 'logps/chosen': -244.5749969482422, 'logps/rejected': -163.125, 'logits/chosen': -7.151562690734863, 'logits/rejected': -6.996874809265137, 'epoch': 2.23}
 74%|███████▍  | 1400/1881 [3:21:33<57:25,  7.16s/it] 74%|███████▍  | 1401/1881 [3:21:41<58:49,  7.35s/it] 75%|███████▍  | 1402/1881 [3:21:46<53:11,  6.66s/it] 75%|███████▍  | 1403/1881 [3:21:53<52:48,  6.63s/it] 75%|███████▍  | 1404/1881 [3:22:00<55:06,  6.93s/it] 75%|███████▍  | 1405/1881 [3:22:07<55:05,  6.94s/it] 75%|███████▍  | 1406/1881 [3:22:15<55:58,  7.07s/it] 75%|███████▍  | 1407/1881 [3:22:24<1:00:54,  7.71s/it] 75%|███████▍  | 1408/1881 [3:22:34<1:06:57,  8.49s/it] 75%|███████▍  | 1409/1881 [3:22:42<1:04:46,  8.23s/it] 75%|███████▍  | 1410/1881 [3:22:53<1:12:47,  9.27s/it]                                                       {'loss': 0.2831, 'grad_norm': 33.38056564331055, 'learning_rate': 1.518467269670706e-07, 'rewards/chosen': 3.639941453933716, 'rewards/rejected': -0.819042980670929, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.455859184265137, 'logps/chosen': -333.0249938964844, 'logps/rejected': -210.8249969482422, 'logits/chosen': -7.298437595367432, 'logits/rejected': -6.948437690734863, 'epoch': 2.25}
 75%|███████▍  | 1410/1881 [3:22:54<1:12:47,  9.27s/it] 75%|███████▌  | 1411/1881 [3:23:02<1:11:51,  9.17s/it] 75%|███████▌  | 1412/1881 [3:23:10<1:08:04,  8.71s/it] 75%|███████▌  | 1413/1881 [3:23:16<1:01:38,  7.90s/it] 75%|███████▌  | 1414/1881 [3:23:23<58:51,  7.56s/it]   75%|███████▌  | 1415/1881 [3:23:28<52:42,  6.79s/it] 75%|███████▌  | 1416/1881 [3:23:35<53:54,  6.96s/it] 75%|███████▌  | 1417/1881 [3:23:43<56:03,  7.25s/it] 75%|███████▌  | 1418/1881 [3:23:47<49:10,  6.37s/it] 75%|███████▌  | 1419/1881 [3:23:54<50:21,  6.54s/it] 75%|███████▌  | 1420/1881 [3:24:02<51:49,  6.75s/it]                                                     {'loss': 0.2901, 'grad_norm': 30.831974029541016, 'learning_rate': 1.4769482356246555e-07, 'rewards/chosen': 1.964868187904358, 'rewards/rejected': -1.1628906726837158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.1292967796325684, 'logps/chosen': -214.4375, 'logps/rejected': -181.1875, 'logits/chosen': -7.128125190734863, 'logits/rejected': -6.826562404632568, 'epoch': 2.26}
 75%|███████▌  | 1420/1881 [3:24:02<51:49,  6.75s/it] 76%|███████▌  | 1421/1881 [3:24:08<50:57,  6.65s/it] 76%|███████▌  | 1422/1881 [3:24:17<57:13,  7.48s/it] 76%|███████▌  | 1423/1881 [3:24:29<1:07:22,  8.83s/it] 76%|███████▌  | 1424/1881 [3:24:36<1:01:42,  8.10s/it] 76%|███████▌  | 1425/1881 [3:24:44<1:01:43,  8.12s/it] 76%|███████▌  | 1426/1881 [3:24:53<1:03:31,  8.38s/it] 76%|███████▌  | 1427/1881 [3:25:01<1:01:51,  8.17s/it] 76%|███████▌  | 1428/1881 [3:25:06<56:14,  7.45s/it]   76%|███████▌  | 1429/1881 [3:25:12<52:28,  6.97s/it] 76%|███████▌  | 1430/1881 [3:25:19<51:07,  6.80s/it]                                                     {'loss': 0.3202, 'grad_norm': 50.21943664550781, 'learning_rate': 1.4358829878446863e-07, 'rewards/chosen': 2.0766358375549316, 'rewards/rejected': -1.25, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.32666015625, 'logps/chosen': -234.72500610351562, 'logps/rejected': -151.03750610351562, 'logits/chosen': -7.020312309265137, 'logits/rejected': -6.865624904632568, 'epoch': 2.28}
 76%|███████▌  | 1430/1881 [3:25:19<51:07,  6.80s/it] 76%|███████▌  | 1431/1881 [3:25:24<48:17,  6.44s/it] 76%|███████▌  | 1432/1881 [3:25:32<50:41,  6.77s/it] 76%|███████▌  | 1433/1881 [3:25:37<47:44,  6.39s/it] 76%|███████▌  | 1434/1881 [3:25:49<58:43,  7.88s/it] 76%|███████▋  | 1435/1881 [3:25:56<56:51,  7.65s/it] 76%|███████▋  | 1436/1881 [3:26:03<55:01,  7.42s/it] 76%|███████▋  | 1437/1881 [3:26:10<55:09,  7.45s/it] 76%|███████▋  | 1438/1881 [3:26:18<55:45,  7.55s/it] 77%|███████▋  | 1439/1881 [3:26:30<1:04:32,  8.76s/it] 77%|███████▋  | 1440/1881 [3:26:38<1:04:04,  8.72s/it]                                                       {'loss': 0.3508, 'grad_norm': 40.45664596557617, 'learning_rate': 1.3952972988223053e-07, 'rewards/chosen': 2.320239305496216, 'rewards/rejected': -1.372949242591858, 'rewards/accuracies': 0.8125, 'rewards/margins': 3.690624952316284, 'logps/chosen': -261.3125, 'logps/rejected': -150.0, 'logits/chosen': -7.123437404632568, 'logits/rejected': -6.935937404632568, 'epoch': 2.29}
 77%|███████▋  | 1440/1881 [3:26:38<1:04:04,  8.72s/it] 77%|███████▋  | 1441/1881 [3:26:47<1:03:21,  8.64s/it] 77%|███████▋  | 1442/1881 [3:26:55<1:02:17,  8.51s/it] 77%|███████▋  | 1443/1881 [3:27:03<1:01:26,  8.42s/it] 77%|███████▋  | 1444/1881 [3:27:10<59:05,  8.11s/it]   77%|███████▋  | 1445/1881 [3:27:17<55:58,  7.70s/it] 77%|███████▋  | 1446/1881 [3:27:25<55:10,  7.61s/it] 77%|███████▋  | 1447/1881 [3:27:32<54:40,  7.56s/it] 77%|███████▋  | 1448/1881 [3:27:40<54:50,  7.60s/it] 77%|███████▋  | 1449/1881 [3:27:49<57:44,  8.02s/it] 77%|███████▋  | 1450/1881 [3:28:03<1:10:06,  9.76s/it]                                                       {'loss': 0.2488, 'grad_norm': 21.908700942993164, 'learning_rate': 1.3552166400786186e-07, 'rewards/chosen': 1.729040503501892, 'rewards/rejected': -1.6104004383087158, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.33984375, 'logps/chosen': -218.78750610351562, 'logps/rejected': -157.22500610351562, 'logits/chosen': -7.15625, 'logits/rejected': -7.006249904632568, 'epoch': 2.31}
 77%|███████▋  | 1450/1881 [3:28:03<1:10:06,  9.76s/it] 77%|███████▋  | 1451/1881 [3:28:08<1:01:21,  8.56s/it] 77%|███████▋  | 1452/1881 [3:28:15<57:29,  8.04s/it]   77%|███████▋  | 1453/1881 [3:28:23<58:01,  8.13s/it] 77%|███████▋  | 1454/1881 [3:28:30<55:03,  7.74s/it] 77%|███████▋  | 1455/1881 [3:28:39<57:22,  8.08s/it] 77%|███████▋  | 1456/1881 [3:28:49<1:00:19,  8.52s/it] 77%|███████▋  | 1457/1881 [3:28:57<58:42,  8.31s/it]   78%|███████▊  | 1458/1881 [3:29:08<1:04:57,  9.22s/it] 78%|███████▊  | 1459/1881 [3:29:17<1:05:33,  9.32s/it] 78%|███████▊  | 1460/1881 [3:29:22<55:40,  7.94s/it]                                                       {'loss': 0.3351, 'grad_norm': 42.611900329589844, 'learning_rate': 1.315666166178444e-07, 'rewards/chosen': 2.169677734375, 'rewards/rejected': -1.0056641101837158, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.1742186546325684, 'logps/chosen': -238.9375, 'logps/rejected': -183.3249969482422, 'logits/chosen': -7.118750095367432, 'logits/rejected': -6.979687690734863, 'epoch': 2.33}
 78%|███████▊  | 1460/1881 [3:29:22<55:40,  7.94s/it] 78%|███████▊  | 1461/1881 [3:29:30<56:09,  8.02s/it] 78%|███████▊  | 1462/1881 [3:29:36<51:49,  7.42s/it] 78%|███████▊  | 1463/1881 [3:29:44<51:29,  7.39s/it] 78%|███████▊  | 1464/1881 [3:29:54<56:32,  8.14s/it] 78%|███████▊  | 1465/1881 [3:30:05<1:02:57,  9.08s/it] 78%|███████▊  | 1466/1881 [3:30:13<1:00:44,  8.78s/it] 78%|███████▊  | 1467/1881 [3:30:20<57:57,  8.40s/it]   78%|███████▊  | 1468/1881 [3:30:27<53:30,  7.77s/it] 78%|███████▊  | 1469/1881 [3:30:33<49:33,  7.22s/it] 78%|███████▊  | 1470/1881 [3:30:41<51:38,  7.54s/it]                                                     {'loss': 0.3694, 'grad_norm': 24.921173095703125, 'learning_rate': 1.2766706989433417e-07, 'rewards/chosen': 2.52734375, 'rewards/rejected': -1.0608398914337158, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.5914063453674316, 'logps/chosen': -277.9125061035156, 'logps/rejected': -163.75, 'logits/chosen': -6.8984375, 'logits/rejected': -6.870312690734863, 'epoch': 2.34}
 78%|███████▊  | 1470/1881 [3:30:41<51:38,  7.54s/it] 78%|███████▊  | 1471/1881 [3:30:48<50:29,  7.39s/it] 78%|███████▊  | 1472/1881 [3:30:56<51:04,  7.49s/it] 78%|███████▊  | 1473/1881 [3:31:03<51:10,  7.52s/it] 78%|███████▊  | 1474/1881 [3:31:09<46:35,  6.87s/it] 78%|███████▊  | 1475/1881 [3:31:22<58:40,  8.67s/it] 78%|███████▊  | 1476/1881 [3:31:28<54:50,  8.13s/it] 79%|███████▊  | 1477/1881 [3:31:34<49:59,  7.42s/it] 79%|███████▊  | 1478/1881 [3:31:41<48:56,  7.29s/it] 79%|███████▊  | 1479/1881 [3:31:48<47:33,  7.10s/it] 79%|███████▊  | 1480/1881 [3:31:57<51:46,  7.75s/it]                                                     {'loss': 0.3015, 'grad_norm': 24.553058624267578, 'learning_rate': 1.2382547118734685e-07, 'rewards/chosen': 1.657568335533142, 'rewards/rejected': -1.470703125, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.1244139671325684, 'logps/chosen': -196.1750030517578, 'logps/rejected': -144.78750610351562, 'logits/chosen': -7.135937690734863, 'logits/rejected': -7.1015625, 'epoch': 2.36}
 79%|███████▊  | 1480/1881 [3:31:57<51:46,  7.75s/it] 79%|███████▊  | 1481/1881 [3:32:05<51:54,  7.79s/it] 79%|███████▉  | 1482/1881 [3:32:15<57:17,  8.61s/it] 79%|███████▉  | 1483/1881 [3:32:23<54:02,  8.15s/it] 79%|███████▉  | 1484/1881 [3:32:28<49:01,  7.41s/it] 79%|███████▉  | 1485/1881 [3:32:35<48:22,  7.33s/it] 79%|███████▉  | 1486/1881 [3:32:44<51:16,  7.79s/it] 79%|███████▉  | 1487/1881 [3:32:51<49:06,  7.48s/it] 79%|███████▉  | 1488/1881 [3:33:01<53:04,  8.10s/it] 79%|███████▉  | 1489/1881 [3:33:09<52:52,  8.09s/it] 79%|███████▉  | 1490/1881 [3:33:14<47:27,  7.28s/it]                                                     {'loss': 0.2826, 'grad_norm': 14.102544784545898, 'learning_rate': 1.2004423147880523e-07, 'rewards/chosen': 2.208544969558716, 'rewards/rejected': -1.46337890625, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 3.670703172683716, 'logps/chosen': -236.1374969482422, 'logps/rejected': -134.22500610351562, 'logits/chosen': -7.074999809265137, 'logits/rejected': -6.807812690734863, 'epoch': 2.37}
 79%|███████▉  | 1490/1881 [3:33:14<47:27,  7.28s/it] 79%|███████▉  | 1491/1881 [3:33:21<46:23,  7.14s/it] 79%|███████▉  | 1492/1881 [3:33:30<49:37,  7.65s/it] 79%|███████▉  | 1493/1881 [3:33:36<47:49,  7.40s/it] 79%|███████▉  | 1494/1881 [3:33:45<50:18,  7.80s/it] 79%|███████▉  | 1495/1881 [3:33:54<52:29,  8.16s/it] 80%|███████▉  | 1496/1881 [3:34:00<48:30,  7.56s/it] 80%|███████▉  | 1497/1881 [3:34:10<51:58,  8.12s/it] 80%|███████▉  | 1498/1881 [3:34:19<54:34,  8.55s/it] 80%|███████▉  | 1499/1881 [3:34:29<56:11,  8.83s/it] 80%|███████▉  | 1500/1881 [3:34:37<54:38,  8.60s/it]                                                     {'loss': 0.2558, 'grad_norm': 34.29483413696289, 'learning_rate': 1.1632572386940975e-07, 'rewards/chosen': 3.211282253265381, 'rewards/rejected': -1.593377709388733, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.803515434265137, 'logps/chosen': -317.8374938964844, 'logps/rejected': -206.6875, 'logits/chosen': -6.876562595367432, 'logits/rejected': -6.8203125, 'epoch': 2.39}
 80%|███████▉  | 1500/1881 [3:34:37<54:38,  8.60s/it] 80%|███████▉  | 1501/1881 [3:34:44<50:41,  8.00s/it] 80%|███████▉  | 1502/1881 [3:34:54<55:10,  8.74s/it] 80%|███████▉  | 1503/1881 [3:35:00<50:04,  7.95s/it] 80%|███████▉  | 1504/1881 [3:35:06<46:23,  7.38s/it] 80%|████████  | 1505/1881 [3:35:14<47:30,  7.58s/it] 80%|████████  | 1506/1881 [3:35:20<43:13,  6.92s/it] 80%|████████  | 1507/1881 [3:35:25<40:48,  6.55s/it] 80%|████████  | 1508/1881 [3:35:38<51:40,  8.31s/it] 80%|████████  | 1509/1881 [3:35:49<57:23,  9.26s/it] 80%|████████  | 1510/1881 [3:35:59<59:15,  9.58s/it]                                                     {'loss': 0.3914, 'grad_norm': 21.83651351928711, 'learning_rate': 1.1267228208928396e-07, 'rewards/chosen': 1.618896484375, 'rewards/rejected': -1.1875, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 2.8070311546325684, 'logps/chosen': -202.1750030517578, 'logps/rejected': -149.0, 'logits/chosen': -7.209374904632568, 'logits/rejected': -6.962500095367432, 'epoch': 2.4}
 80%|████████  | 1510/1881 [3:36:00<59:15,  9.58s/it] 80%|████████  | 1511/1881 [3:36:07<54:59,  8.92s/it] 80%|████████  | 1512/1881 [3:36:14<52:13,  8.49s/it] 80%|████████  | 1513/1881 [3:36:20<47:44,  7.78s/it] 80%|████████  | 1514/1881 [3:36:27<44:28,  7.27s/it] 81%|████████  | 1515/1881 [3:36:31<39:41,  6.51s/it] 81%|████████  | 1516/1881 [3:36:40<42:53,  7.05s/it] 81%|████████  | 1517/1881 [3:36:45<40:19,  6.65s/it] 81%|████████  | 1518/1881 [3:36:56<47:43,  7.89s/it] 81%|████████  | 1519/1881 [3:37:07<53:01,  8.79s/it] 81%|████████  | 1520/1881 [3:37:19<57:55,  9.63s/it]                                                     {'loss': 0.2851, 'grad_norm': 22.07267951965332, 'learning_rate': 1.0908619903332898e-07, 'rewards/chosen': 2.078164577484131, 'rewards/rejected': -1.8678710460662842, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.950390577316284, 'logps/chosen': -213.96249389648438, 'logps/rejected': -113.4749984741211, 'logits/chosen': -7.245312690734863, 'logits/rejected': -7.095312595367432, 'epoch': 2.42}
 81%|████████  | 1520/1881 [3:37:19<57:55,  9.63s/it] 81%|████████  | 1521/1881 [3:37:25<51:55,  8.65s/it] 81%|████████  | 1522/1881 [3:37:33<50:03,  8.37s/it] 81%|████████  | 1523/1881 [3:37:46<58:58,  9.88s/it] 81%|████████  | 1524/1881 [3:37:55<56:42,  9.53s/it] 81%|████████  | 1525/1881 [3:37:59<47:11,  7.95s/it] 81%|████████  | 1526/1881 [3:38:11<53:44,  9.08s/it] 81%|████████  | 1527/1881 [3:38:18<49:35,  8.41s/it] 81%|████████  | 1528/1881 [3:38:28<53:10,  9.04s/it] 81%|████████▏ | 1529/1881 [3:38:41<59:12, 10.09s/it] 81%|████████▏ | 1530/1881 [3:38:49<55:40,  9.52s/it]                                                     {'loss': 0.2887, 'grad_norm': 48.9295654296875, 'learning_rate': 1.0556972532220578e-07, 'rewards/chosen': 1.8262145519256592, 'rewards/rejected': -1.8861815929412842, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.7109375, 'logps/chosen': -225.6374969482422, 'logps/rejected': -146.3874969482422, 'logits/chosen': -7.295312404632568, 'logits/rejected': -7.110937595367432, 'epoch': 2.44}
 81%|████████▏ | 1530/1881 [3:38:49<55:40,  9.52s/it] 81%|████████▏ | 1531/1881 [3:39:01<1:00:22, 10.35s/it] 81%|████████▏ | 1532/1881 [3:39:12<1:00:25, 10.39s/it] 81%|████████▏ | 1533/1881 [3:39:22<59:44, 10.30s/it]   82%|████████▏ | 1534/1881 [3:39:29<54:20,  9.40s/it] 82%|████████▏ | 1535/1881 [3:39:38<53:36,  9.30s/it] 82%|████████▏ | 1536/1881 [3:39:46<50:36,  8.80s/it] 82%|████████▏ | 1537/1881 [3:39:52<46:32,  8.12s/it] 82%|████████▏ | 1538/1881 [3:40:00<45:30,  7.96s/it] 82%|████████▏ | 1539/1881 [3:40:10<49:55,  8.76s/it] 82%|████████▏ | 1540/1881 [3:40:19<49:25,  8.70s/it]                                                     {'loss': 0.3769, 'grad_norm': 36.436954498291016, 'learning_rate': 1.0212506788984869e-07, 'rewards/chosen': 2.155566453933716, 'rewards/rejected': -0.8844238519668579, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.04345703125, 'logps/chosen': -227.28750610351562, 'logps/rejected': -173.8125, 'logits/chosen': -7.057812690734863, 'logits/rejected': -6.834374904632568, 'epoch': 2.45}
 82%|████████▏ | 1540/1881 [3:40:19<49:25,  8.70s/it] 82%|████████▏ | 1541/1881 [3:40:26<47:00,  8.30s/it] 82%|████████▏ | 1542/1881 [3:40:32<43:07,  7.63s/it] 82%|████████▏ | 1543/1881 [3:40:38<40:12,  7.14s/it] 82%|████████▏ | 1544/1881 [3:40:45<39:28,  7.03s/it] 82%|████████▏ | 1545/1881 [3:40:52<38:14,  6.83s/it] 82%|████████▏ | 1546/1881 [3:40:59<39:01,  6.99s/it] 82%|████████▏ | 1547/1881 [3:41:06<39:38,  7.12s/it] 82%|████████▏ | 1548/1881 [3:41:14<41:13,  7.43s/it] 82%|████████▏ | 1549/1881 [3:41:22<41:47,  7.55s/it] 82%|████████▏ | 1550/1881 [3:41:28<39:07,  7.09s/it]                                                     {'loss': 0.2316, 'grad_norm': 17.100433349609375, 'learning_rate': 9.875438859839706e-08, 'rewards/chosen': 1.6501953601837158, 'rewards/rejected': -1.416357398033142, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 3.06640625, 'logps/chosen': -173.52499389648438, 'logps/rejected': -126.4749984741211, 'logits/chosen': -7.237500190734863, 'logits/rejected': -7.084374904632568, 'epoch': 2.47}
 82%|████████▏ | 1550/1881 [3:41:28<39:07,  7.09s/it] 82%|████████▏ | 1551/1881 [3:41:40<46:23,  8.44s/it] 83%|████████▎ | 1552/1881 [3:41:47<43:41,  7.97s/it] 83%|████████▎ | 1553/1881 [3:41:55<43:51,  8.02s/it] 83%|████████▎ | 1554/1881 [3:42:00<38:41,  7.10s/it] 83%|████████▎ | 1555/1881 [3:42:07<39:18,  7.23s/it] 83%|████████▎ | 1556/1881 [3:42:15<39:04,  7.21s/it] 83%|████████▎ | 1557/1881 [3:42:22<39:42,  7.35s/it] 83%|████████▎ | 1558/1881 [3:42:30<39:45,  7.39s/it] 83%|████████▎ | 1559/1881 [3:42:42<46:58,  8.75s/it] 83%|████████▎ | 1560/1881 [3:42:49<45:21,  8.48s/it]                                                     {'loss': 0.2813, 'grad_norm': 23.96965217590332, 'learning_rate': 9.54598028814135e-08, 'rewards/chosen': 1.58642578125, 'rewards/rejected': -1.804296851158142, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 3.3910155296325684, 'logps/chosen': -199.1750030517578, 'logps/rejected': -132.4250030517578, 'logits/chosen': -7.114062309265137, 'logits/rejected': -6.957812309265137, 'epoch': 2.48}
 83%|████████▎ | 1560/1881 [3:42:50<45:21,  8.48s/it] 83%|████████▎ | 1561/1881 [3:42:56<41:23,  7.76s/it] 83%|████████▎ | 1562/1881 [3:43:02<39:29,  7.43s/it] 83%|████████▎ | 1563/1881 [3:43:11<41:22,  7.81s/it] 83%|████████▎ | 1564/1881 [3:43:20<43:22,  8.21s/it] 83%|████████▎ | 1565/1881 [3:43:31<47:38,  9.05s/it]
  0%|          | 0/120 [00:00<?, ?it/s][A
  2%|▏         | 2/120 [00:01<01:19,  1.48it/s][A
  2%|▎         | 3/120 [00:02<02:02,  1.05s/it][A
  3%|▎         | 4/120 [00:04<02:22,  1.23s/it][A
  4%|▍         | 5/120 [00:06<02:35,  1.35s/it][A
  5%|▌         | 6/120 [00:07<02:40,  1.41s/it][A
  6%|▌         | 7/120 [00:10<03:42,  1.97s/it][A
  7%|▋         | 8/120 [00:13<03:58,  2.13s/it][A
  8%|▊         | 9/120 [00:16<04:47,  2.59s/it][A
  8%|▊         | 10/120 [00:18<04:11,  2.29s/it][A
  9%|▉         | 11/120 [00:20<03:45,  2.07s/it][A
 10%|█         | 12/120 [00:21<03:29,  1.94s/it][A
 11%|█         | 13/120 [00:25<04:13,  2.37s/it][A
 12%|█▏        | 14/120 [00:26<03:52,  2.19s/it][A
 12%|█▎        | 15/120 [00:29<04:06,  2.35s/it][A
 13%|█▎        | 16/120 [00:33<04:44,  2.74s/it][A
 14%|█▍        | 17/120 [00:36<05:03,  2.95s/it][A
 15%|█▌        | 18/120 [00:40<05:22,  3.16s/it][A
 16%|█▌        | 19/120 [00:43<05:08,  3.06s/it][A
 17%|█▋        | 20/120 [00:46<05:24,  3.24s/it][A
 18%|█▊        | 21/120 [00:48<04:35,  2.79s/it][A
 18%|█▊        | 22/120 [00:50<04:04,  2.50s/it][A
 19%|█▉        | 23/120 [00:54<04:53,  3.03s/it][A
 20%|██        | 24/120 [00:57<04:48,  3.01s/it][A
 21%|██        | 25/120 [01:00<04:56,  3.12s/it][A
 22%|██▏       | 26/120 [01:02<04:09,  2.65s/it][A
 22%|██▎       | 27/120 [01:06<04:32,  2.93s/it][A
 23%|██▎       | 28/120 [01:07<03:39,  2.39s/it][A
 24%|██▍       | 29/120 [01:07<02:48,  1.85s/it][A
 25%|██▌       | 30/120 [01:09<02:30,  1.67s/it][A
 26%|██▌       | 31/120 [01:09<01:58,  1.34s/it][A
 27%|██▋       | 32/120 [01:10<01:50,  1.25s/it][A
 28%|██▊       | 33/120 [01:11<01:33,  1.07s/it][A
 28%|██▊       | 34/120 [01:12<01:32,  1.07s/it][A
 29%|██▉       | 35/120 [01:13<01:22,  1.03it/s][A
 30%|███       | 36/120 [01:14<01:21,  1.03it/s][A
 31%|███       | 37/120 [01:15<01:25,  1.03s/it][A
 32%|███▏      | 38/120 [01:16<01:29,  1.10s/it][A
 32%|███▎      | 39/120 [01:17<01:34,  1.16s/it][A
 33%|███▎      | 40/120 [01:18<01:17,  1.03it/s][A
 34%|███▍      | 41/120 [01:19<01:15,  1.05it/s][A
 35%|███▌      | 42/120 [01:20<01:23,  1.07s/it][A
 36%|███▌      | 43/120 [01:21<01:27,  1.14s/it][A
 37%|███▋      | 44/120 [01:24<01:53,  1.49s/it][A
 38%|███▊      | 45/120 [01:25<01:43,  1.39s/it][A
 38%|███▊      | 46/120 [01:26<01:36,  1.30s/it][A
 39%|███▉      | 47/120 [01:27<01:28,  1.21s/it][A
 40%|████      | 48/120 [01:27<01:13,  1.02s/it][A
 41%|████      | 49/120 [01:29<01:13,  1.04s/it][A
 42%|████▏     | 50/120 [01:32<02:07,  1.82s/it][A
 42%|████▎     | 51/120 [01:34<01:57,  1.71s/it][A
 43%|████▎     | 52/120 [01:34<01:32,  1.36s/it][A
 44%|████▍     | 53/120 [01:35<01:19,  1.18s/it][A
 45%|████▌     | 54/120 [01:36<01:11,  1.09s/it][A
 46%|████▌     | 55/120 [01:37<01:13,  1.12s/it][A
 47%|████▋     | 56/120 [01:38<01:00,  1.06it/s][A
 48%|████▊     | 57/120 [01:38<00:50,  1.26it/s][A
 48%|████▊     | 58/120 [01:39<00:56,  1.09it/s][A
 49%|████▉     | 59/120 [01:41<01:09,  1.14s/it][A
 50%|█████     | 60/120 [01:42<01:08,  1.14s/it][A
 51%|█████     | 61/120 [01:43<00:57,  1.03it/s][A
 52%|█████▏    | 62/120 [01:44<01:06,  1.15s/it][A
 52%|█████▎    | 63/120 [01:45<00:57,  1.01s/it][A
 53%|█████▎    | 64/120 [01:48<01:37,  1.74s/it][A
 54%|█████▍    | 65/120 [01:51<01:57,  2.14s/it][A
 55%|█████▌    | 66/120 [01:53<01:40,  1.86s/it][A
 56%|█████▌    | 67/120 [01:53<01:22,  1.55s/it][A
 57%|█████▋    | 68/120 [01:54<01:07,  1.30s/it][A
 57%|█████▊    | 69/120 [01:55<00:53,  1.06s/it][A
 58%|█████▊    | 70/120 [01:56<00:58,  1.17s/it][A
 59%|█████▉    | 71/120 [01:57<01:01,  1.25s/it][A
 60%|██████    | 72/120 [01:58<00:48,  1.02s/it][A
 61%|██████    | 73/120 [01:59<00:41,  1.13it/s][A
 62%|██████▏   | 74/120 [01:59<00:34,  1.33it/s][A
 62%|██████▎   | 75/120 [02:00<00:32,  1.38it/s][A
 63%|██████▎   | 76/120 [02:01<00:42,  1.03it/s][A
 64%|██████▍   | 77/120 [02:02<00:44,  1.02s/it][A
 65%|██████▌   | 78/120 [02:03<00:38,  1.10it/s][A
 66%|██████▌   | 79/120 [02:05<00:46,  1.14s/it][A
 67%|██████▋   | 80/120 [02:05<00:41,  1.03s/it][A
 68%|██████▊   | 81/120 [02:09<01:10,  1.81s/it][A
 68%|██████▊   | 82/120 [02:10<00:55,  1.46s/it][A
 69%|██████▉   | 83/120 [02:11<00:56,  1.53s/it][A
 70%|███████   | 84/120 [02:13<00:55,  1.54s/it][A
 71%|███████   | 85/120 [02:14<00:47,  1.34s/it][A
 72%|███████▏  | 86/120 [02:15<00:41,  1.23s/it][A
 72%|███████▎  | 87/120 [02:16<00:42,  1.30s/it][A
 73%|███████▎  | 88/120 [02:18<00:43,  1.36s/it][A
 74%|███████▍  | 89/120 [02:20<00:51,  1.65s/it][A
 75%|███████▌  | 90/120 [02:21<00:39,  1.32s/it][A
 76%|███████▌  | 91/120 [02:24<00:56,  1.95s/it][A
 77%|███████▋  | 92/120 [02:26<00:51,  1.83s/it][A
 78%|███████▊  | 93/120 [02:27<00:48,  1.79s/it][A
 78%|███████▊  | 94/120 [02:28<00:41,  1.58s/it][A
 79%|███████▉  | 95/120 [02:29<00:35,  1.40s/it][A
 80%|████████  | 96/120 [02:30<00:30,  1.27s/it][A
 81%|████████  | 97/120 [02:32<00:31,  1.36s/it][A
 82%|████████▏ | 98/120 [02:34<00:37,  1.71s/it][A
 82%|████████▎ | 99/120 [02:36<00:34,  1.66s/it][A
 83%|████████▎ | 100/120 [02:39<00:43,  2.16s/it][A
 84%|████████▍ | 101/120 [02:41<00:37,  1.96s/it][A
 85%|████████▌ | 102/120 [02:42<00:33,  1.83s/it][A
 86%|████████▌ | 103/120 [02:43<00:25,  1.50s/it][A
 87%|████████▋ | 104/120 [02:44<00:22,  1.43s/it][A
 88%|████████▊ | 105/120 [02:45<00:19,  1.33s/it][A
 88%|████████▊ | 106/120 [02:46<00:17,  1.22s/it][A
 89%|████████▉ | 107/120 [02:48<00:17,  1.32s/it][A
 90%|█████████ | 108/120 [02:50<00:18,  1.53s/it][A
 91%|█████████ | 109/120 [02:51<00:14,  1.30s/it][A
 92%|█████████▏| 110/120 [02:52<00:11,  1.17s/it][A
 92%|█████████▎| 111/120 [02:53<00:11,  1.30s/it][A
 93%|█████████▎| 112/120 [02:54<00:10,  1.28s/it][A
 94%|█████████▍| 113/120 [02:56<00:09,  1.37s/it][A
 95%|█████████▌| 114/120 [02:59<00:11,  1.89s/it][A
 96%|█████████▌| 115/120 [03:00<00:08,  1.74s/it][A
 97%|█████████▋| 116/120 [03:01<00:05,  1.48s/it][A
 98%|█████████▊| 117/120 [03:02<00:03,  1.29s/it][A
 98%|█████████▊| 118/120 [03:04<00:03,  1.54s/it][A
 99%|█████████▉| 119/120 [03:05<00:01,  1.33s/it][A
100%|██████████| 120/120 [03:07<00:00,  1.42s/it][A                                                     
                                                 [A{'eval_loss': 0.407297819852829, 'eval_runtime': 189.1927, 'eval_samples_per_second': 5.037, 'eval_steps_per_second': 0.634, 'eval_rewards/chosen': 3.232086658477783, 'eval_rewards/rejected': -0.33284708857536316, 'eval_rewards/accuracies': 0.8031250238418579, 'eval_rewards/margins': 3.564101219177246, 'eval_logps/chosen': -362.1354064941406, 'eval_logps/rejected': -153.84478759765625, 'eval_logits/chosen': -6.731901168823242, 'eval_logits/rejected': -7.3125, 'epoch': 2.49}
 83%|████████▎ | 1565/1881 [3:46:40<47:38,  9.05s/it]
100%|██████████| 120/120 [03:07<00:00,  1.42s/it][A
                                                 [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 83%|████████▎ | 1566/1881 [3:46:57<5:57:46, 68.15s/it] 83%|████████▎ | 1567/1881 [3:47:07<4:25:39, 50.76s/it] 83%|████████▎ | 1568/1881 [3:47:16<3:18:39, 38.08s/it] 83%|████████▎ | 1569/1881 [3:47:26<2:34:11, 29.65s/it] 83%|████████▎ | 1570/1881 [3:47:32<1:57:36, 22.69s/it]                                                       {'loss': 0.3046, 'grad_norm': 36.953460693359375, 'learning_rate': 9.224337841624062e-08, 'rewards/chosen': 1.5457031726837158, 'rewards/rejected': -1.1912109851837158, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 2.737109422683716, 'logps/chosen': -173.72500610351562, 'logps/rejected': -153.46249389648438, 'logits/chosen': -7.207812309265137, 'logits/rejected': -7.0, 'epoch': 2.5}
 83%|████████▎ | 1570/1881 [3:47:32<1:57:36, 22.69s/it] 84%|████████▎ | 1571/1881 [3:47:41<1:35:23, 18.46s/it] 84%|████████▎ | 1572/1881 [3:47:46<1:14:46, 14.52s/it] 84%|████████▎ | 1573/1881 [3:47:53<1:03:00, 12.28s/it] 84%|████████▎ | 1574/1881 [3:47:59<53:28, 10.45s/it]   84%|████████▎ | 1575/1881 [3:48:06<47:54,  9.40s/it] 84%|████████▍ | 1576/1881 [3:48:13<43:16,  8.51s/it] 84%|████████▍ | 1577/1881 [3:48:20<41:48,  8.25s/it] 84%|████████▍ | 1578/1881 [3:48:28<41:02,  8.13s/it] 84%|████████▍ | 1579/1881 [3:48:36<39:56,  7.94s/it] 84%|████████▍ | 1580/1881 [3:48:44<40:42,  8.12s/it]                                                     {'loss': 0.2697, 'grad_norm': 17.98773193359375, 'learning_rate': 8.910713382632988e-08, 'rewards/chosen': 2.5400452613830566, 'rewards/rejected': -1.3144652843475342, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.8519530296325684, 'logps/chosen': -265.98748779296875, 'logps/rejected': -186.64999389648438, 'logits/chosen': -7.150000095367432, 'logits/rejected': -6.920312404632568, 'epoch': 2.52}
 84%|████████▍ | 1580/1881 [3:48:44<40:42,  8.12s/it] 84%|████████▍ | 1581/1881 [3:48:54<43:39,  8.73s/it] 84%|████████▍ | 1582/1881 [3:49:05<45:39,  9.16s/it] 84%|████████▍ | 1583/1881 [3:49:11<41:35,  8.37s/it] 84%|████████▍ | 1584/1881 [3:49:16<36:00,  7.27s/it] 84%|████████▍ | 1585/1881 [3:49:23<35:49,  7.26s/it] 84%|████████▍ | 1586/1881 [3:49:32<37:38,  7.66s/it] 84%|████████▍ | 1587/1881 [3:49:43<43:24,  8.86s/it] 84%|████████▍ | 1588/1881 [3:49:54<46:14,  9.47s/it] 84%|████████▍ | 1589/1881 [3:50:00<40:29,  8.32s/it] 85%|████████▍ | 1590/1881 [3:50:06<36:35,  7.54s/it]                                                     {'loss': 0.3001, 'grad_norm': 32.05607986450195, 'learning_rate': 8.605303741435639e-08, 'rewards/chosen': 1.936254858970642, 'rewards/rejected': -1.588476538658142, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.524609327316284, 'logps/chosen': -207.21249389648438, 'logps/rejected': -142.75, 'logits/chosen': -7.204687595367432, 'logits/rejected': -6.949999809265137, 'epoch': 2.53}
 85%|████████▍ | 1590/1881 [3:50:06<36:35,  7.54s/it] 85%|████████▍ | 1591/1881 [3:50:11<33:49,  7.00s/it] 85%|████████▍ | 1592/1881 [3:50:19<35:08,  7.30s/it] 85%|████████▍ | 1593/1881 [3:50:26<33:25,  6.96s/it] 85%|████████▍ | 1594/1881 [3:50:33<33:40,  7.04s/it] 85%|████████▍ | 1595/1881 [3:50:44<40:00,  8.39s/it] 85%|████████▍ | 1596/1881 [3:50:52<39:27,  8.31s/it] 85%|████████▍ | 1597/1881 [3:50:59<36:12,  7.65s/it] 85%|████████▍ | 1598/1881 [3:51:05<34:58,  7.42s/it] 85%|████████▌ | 1599/1881 [3:51:14<36:57,  7.86s/it] 85%|████████▌ | 1600/1881 [3:51:20<33:55,  7.24s/it]                                                     {'loss': 0.2586, 'grad_norm': 36.95265579223633, 'learning_rate': 8.308300592691453e-08, 'rewards/chosen': 1.879638671875, 'rewards/rejected': -1.673437476158142, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.5542969703674316, 'logps/chosen': -195.8625030517578, 'logps/rejected': -160.97500610351562, 'logits/chosen': -7.214062690734863, 'logits/rejected': -6.717187404632568, 'epoch': 2.55}
 85%|████████▌ | 1600/1881 [3:51:20<33:55,  7.24s/it] 85%|████████▌ | 1601/1881 [3:51:32<40:06,  8.59s/it] 85%|████████▌ | 1602/1881 [3:51:40<38:48,  8.35s/it] 85%|████████▌ | 1603/1881 [3:51:46<35:23,  7.64s/it] 85%|████████▌ | 1604/1881 [3:51:52<33:49,  7.33s/it] 85%|████████▌ | 1605/1881 [3:52:01<35:46,  7.78s/it] 85%|████████▌ | 1606/1881 [3:52:07<32:40,  7.13s/it] 85%|████████▌ | 1607/1881 [3:52:12<30:46,  6.74s/it] 85%|████████▌ | 1608/1881 [3:52:20<31:10,  6.85s/it] 86%|████████▌ | 1609/1881 [3:52:29<34:43,  7.66s/it] 86%|████████▌ | 1610/1881 [3:52:38<36:15,  8.03s/it]                                                     {'loss': 0.3107, 'grad_norm': 37.05107116699219, 'learning_rate': 8.0198903351571e-08, 'rewards/chosen': 0.822174072265625, 'rewards/rejected': -1.899804711341858, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.7230467796325684, 'logps/chosen': -142.1125030517578, 'logps/rejected': -124.63749694824219, 'logits/chosen': -7.176562309265137, 'logits/rejected': -7.126562595367432, 'epoch': 2.56}
 86%|████████▌ | 1610/1881 [3:52:38<36:15,  8.03s/it] 86%|████████▌ | 1611/1881 [3:52:45<35:04,  7.79s/it] 86%|████████▌ | 1612/1881 [3:52:49<29:22,  6.55s/it] 86%|████████▌ | 1613/1881 [3:52:56<30:31,  6.83s/it] 86%|████████▌ | 1614/1881 [3:53:07<35:11,  7.91s/it] 86%|████████▌ | 1615/1881 [3:53:14<34:14,  7.72s/it] 86%|████████▌ | 1616/1881 [3:53:22<34:03,  7.71s/it] 86%|████████▌ | 1617/1881 [3:53:33<38:33,  8.76s/it] 86%|████████▌ | 1618/1881 [3:53:40<36:28,  8.32s/it] 86%|████████▌ | 1619/1881 [3:53:48<35:30,  8.13s/it] 86%|████████▌ | 1620/1881 [3:53:56<35:44,  8.22s/it]                                                     {'loss': 0.3284, 'grad_norm': 42.11882781982422, 'learning_rate': 7.740253974702867e-08, 'rewards/chosen': 4.897784233093262, 'rewards/rejected': 0.46357423067092896, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 4.434179782867432, 'logps/chosen': -426.5874938964844, 'logps/rejected': -293.7250061035156, 'logits/chosen': -7.176562309265137, 'logits/rejected': -7.0625, 'epoch': 2.58}
 86%|████████▌ | 1620/1881 [3:53:56<35:44,  8.22s/it] 86%|████████▌ | 1621/1881 [3:54:09<40:50,  9.43s/it] 86%|████████▌ | 1622/1881 [3:54:16<37:50,  8.77s/it] 86%|████████▋ | 1623/1881 [3:54:23<35:15,  8.20s/it] 86%|████████▋ | 1624/1881 [3:54:31<34:49,  8.13s/it] 86%|████████▋ | 1625/1881 [3:54:37<32:20,  7.58s/it] 86%|████████▋ | 1626/1881 [3:54:44<31:58,  7.52s/it] 86%|████████▋ | 1627/1881 [3:54:51<30:50,  7.29s/it] 87%|████████▋ | 1628/1881 [3:55:01<33:22,  7.92s/it] 87%|████████▋ | 1629/1881 [3:55:10<34:36,  8.24s/it] 87%|████████▋ | 1630/1881 [3:55:17<33:34,  8.03s/it]                                                     {'loss': 0.3207, 'grad_norm': 30.78542137145996, 'learning_rate': 7.469567010713604e-08, 'rewards/chosen': 2.48492431640625, 'rewards/rejected': -1.19921875, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.683789014816284, 'logps/chosen': -261.54998779296875, 'logps/rejected': -178.875, 'logits/chosen': -7.153124809265137, 'logits/rejected': -7.001562595367432, 'epoch': 2.6}
 87%|████████▋ | 1630/1881 [3:55:17<33:34,  8.03s/it] 87%|████████▋ | 1631/1881 [3:55:23<30:21,  7.29s/it] 87%|████████▋ | 1632/1881 [3:55:30<30:48,  7.42s/it] 87%|████████▋ | 1633/1881 [3:55:34<26:34,  6.43s/it] 87%|████████▋ | 1634/1881 [3:55:41<27:12,  6.61s/it] 87%|████████▋ | 1635/1881 [3:55:57<37:52,  9.24s/it] 87%|████████▋ | 1636/1881 [3:56:04<35:26,  8.68s/it] 87%|████████▋ | 1637/1881 [3:56:11<33:04,  8.14s/it] 87%|████████▋ | 1638/1881 [3:56:18<31:12,  7.71s/it] 87%|████████▋ | 1639/1881 [3:56:24<29:18,  7.27s/it] 87%|████████▋ | 1640/1881 [3:56:33<31:16,  7.79s/it]                                                     {'loss': 0.3101, 'grad_norm': 43.0748176574707, 'learning_rate': 7.207999325945589e-08, 'rewards/chosen': 2.435742139816284, 'rewards/rejected': -1.2822265625, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 3.7144532203674316, 'logps/chosen': -271.07501220703125, 'logps/rejected': -161.625, 'logits/chosen': -7.259375095367432, 'logits/rejected': -7.03125, 'epoch': 2.61}
 87%|████████▋ | 1640/1881 [3:56:33<31:16,  7.79s/it] 87%|████████▋ | 1641/1881 [3:56:42<32:18,  8.08s/it] 87%|████████▋ | 1642/1881 [3:56:47<29:04,  7.30s/it] 87%|████████▋ | 1643/1881 [3:57:02<37:22,  9.42s/it] 87%|████████▋ | 1644/1881 [3:57:07<31:47,  8.05s/it] 87%|████████▋ | 1645/1881 [3:57:17<34:13,  8.70s/it] 88%|████████▊ | 1646/1881 [3:57:24<31:56,  8.15s/it] 88%|████████▊ | 1647/1881 [3:57:31<31:05,  7.97s/it] 88%|████████▊ | 1648/1881 [3:57:41<33:08,  8.53s/it] 88%|████████▊ | 1649/1881 [3:57:51<34:23,  8.89s/it] 88%|████████▊ | 1650/1881 [3:58:03<38:00,  9.87s/it]                                                     {'loss': 0.324, 'grad_norm': 32.09638595581055, 'learning_rate': 6.95571507990835e-08, 'rewards/chosen': 1.372613549232483, 'rewards/rejected': -1.23046875, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 2.6009764671325684, 'logps/chosen': -169.4375, 'logps/rejected': -148.64999389648438, 'logits/chosen': -7.160937309265137, 'logits/rejected': -7.199999809265137, 'epoch': 2.63}
 88%|████████▊ | 1650/1881 [3:58:03<38:00,  9.87s/it] 88%|████████▊ | 1651/1881 [3:58:10<34:56,  9.11s/it] 88%|████████▊ | 1652/1881 [3:58:20<35:17,  9.25s/it] 88%|████████▊ | 1653/1881 [3:58:27<32:58,  8.68s/it] 88%|████████▊ | 1654/1881 [3:58:35<31:28,  8.32s/it] 88%|████████▊ | 1655/1881 [3:58:42<30:24,  8.07s/it] 88%|████████▊ | 1656/1881 [3:58:49<29:04,  7.75s/it] 88%|████████▊ | 1657/1881 [3:58:57<29:08,  7.81s/it] 88%|████████▊ | 1658/1881 [3:59:08<32:23,  8.72s/it] 88%|████████▊ | 1659/1881 [3:59:20<35:51,  9.69s/it] 88%|████████▊ | 1660/1881 [3:59:25<30:50,  8.37s/it]                                                     {'loss': 0.2904, 'grad_norm': 43.951725006103516, 'learning_rate': 6.712872605838377e-08, 'rewards/chosen': 2.0834717750549316, 'rewards/rejected': -1.6009399890899658, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.687695264816284, 'logps/chosen': -249.53750610351562, 'logps/rejected': -165.53750610351562, 'logits/chosen': -7.214062690734863, 'logits/rejected': -7.074999809265137, 'epoch': 2.64}
 88%|████████▊ | 1660/1881 [3:59:25<30:50,  8.37s/it] 88%|████████▊ | 1661/1881 [3:59:31<27:52,  7.60s/it] 88%|████████▊ | 1662/1881 [3:59:40<29:11,  8.00s/it] 88%|████████▊ | 1663/1881 [3:59:47<27:58,  7.70s/it] 88%|████████▊ | 1664/1881 [3:59:56<29:22,  8.12s/it] 89%|████████▊ | 1665/1881 [4:00:03<27:41,  7.69s/it] 89%|████████▊ | 1666/1881 [4:00:11<28:39,  8.00s/it] 89%|████████▊ | 1667/1881 [4:00:19<27:41,  7.77s/it] 89%|████████▊ | 1668/1881 [4:00:28<29:43,  8.37s/it] 89%|████████▊ | 1669/1881 [4:00:40<32:34,  9.22s/it] 89%|████████▉ | 1670/1881 [4:00:46<29:14,  8.32s/it]                                                     {'loss': 0.2771, 'grad_norm': 32.15736770629883, 'learning_rate': 6.479624311329397e-08, 'rewards/chosen': 2.892285108566284, 'rewards/rejected': -0.7525390386581421, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.648242235183716, 'logps/chosen': -290.7875061035156, 'logps/rejected': -200.5, 'logits/chosen': -7.035937309265137, 'logits/rejected': -6.801562309265137, 'epoch': 2.66}
 89%|████████▉ | 1670/1881 [4:00:46<29:14,  8.32s/it] 89%|████████▉ | 1671/1881 [4:00:56<31:35,  9.03s/it] 89%|████████▉ | 1672/1881 [4:01:04<30:05,  8.64s/it] 89%|████████▉ | 1673/1881 [4:01:11<27:54,  8.05s/it] 89%|████████▉ | 1674/1881 [4:01:17<26:15,  7.61s/it] 89%|████████▉ | 1675/1881 [4:01:23<24:28,  7.13s/it] 89%|████████▉ | 1676/1881 [4:01:31<24:28,  7.16s/it] 89%|████████▉ | 1677/1881 [4:01:38<24:09,  7.10s/it] 89%|████████▉ | 1678/1881 [4:01:45<23:46,  7.03s/it] 89%|████████▉ | 1679/1881 [4:01:51<23:15,  6.91s/it] 89%|████████▉ | 1680/1881 [4:01:57<22:28,  6.71s/it]                                                     {'loss': 0.2885, 'grad_norm': 46.35961151123047, 'learning_rate': 6.256116582681605e-08, 'rewards/chosen': 2.2493896484375, 'rewards/rejected': -1.6306641101837158, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.8812499046325684, 'logps/chosen': -239.14999389648438, 'logps/rejected': -160.39999389648438, 'logits/chosen': -7.014062404632568, 'logits/rejected': -6.885937690734863, 'epoch': 2.68}
 89%|████████▉ | 1680/1881 [4:01:57<22:28,  6.71s/it] 89%|████████▉ | 1681/1881 [4:02:03<21:30,  6.45s/it] 89%|████████▉ | 1682/1881 [4:02:13<24:54,  7.51s/it] 89%|████████▉ | 1683/1881 [4:02:21<24:49,  7.53s/it] 90%|████████▉ | 1684/1881 [4:02:29<24:59,  7.61s/it] 90%|████████▉ | 1685/1881 [4:02:40<28:39,  8.78s/it] 90%|████████▉ | 1686/1881 [4:02:47<26:45,  8.23s/it] 90%|████████▉ | 1687/1881 [4:02:54<25:44,  7.96s/it] 90%|████████▉ | 1688/1881 [4:03:01<24:11,  7.52s/it] 90%|████████▉ | 1689/1881 [4:03:08<23:15,  7.27s/it] 90%|████████▉ | 1690/1881 [4:03:14<22:14,  6.99s/it]                                                     {'loss': 0.2854, 'grad_norm': 36.278968811035156, 'learning_rate': 6.042489693029822e-08, 'rewards/chosen': 1.161279320716858, 'rewards/rejected': -1.853906273841858, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.0162110328674316, 'logps/chosen': -170.21249389648438, 'logps/rejected': -131.8249969482422, 'logits/chosen': -7.079687595367432, 'logits/rejected': -6.9140625, 'epoch': 2.69}
 90%|████████▉ | 1690/1881 [4:03:14<22:14,  6.99s/it] 90%|████████▉ | 1691/1881 [4:03:22<23:30,  7.42s/it] 90%|████████▉ | 1692/1881 [4:03:33<25:58,  8.25s/it] 90%|█████████ | 1693/1881 [4:03:40<25:18,  8.08s/it] 90%|█████████ | 1694/1881 [4:03:49<26:15,  8.43s/it] 90%|█████████ | 1695/1881 [4:03:59<27:20,  8.82s/it] 90%|█████████ | 1696/1881 [4:04:09<28:25,  9.22s/it] 90%|█████████ | 1697/1881 [4:04:19<28:37,  9.33s/it] 90%|█████████ | 1698/1881 [4:04:26<26:12,  8.59s/it] 90%|█████████ | 1699/1881 [4:04:33<25:13,  8.32s/it] 90%|█████████ | 1700/1881 [4:04:43<26:13,  8.70s/it]                                                     {'loss': 0.3137, 'grad_norm': 21.20969009399414, 'learning_rate': 5.8388777143082625e-08, 'rewards/chosen': 2.2529540061950684, 'rewards/rejected': -1.1833984851837158, 'rewards/accuracies': 0.875, 'rewards/margins': 3.438671827316284, 'logps/chosen': -253.16250610351562, 'logps/rejected': -161.5124969482422, 'logits/chosen': -7.096875190734863, 'logits/rejected': -6.957812309265137, 'epoch': 2.71}
 90%|█████████ | 1700/1881 [4:04:43<26:13,  8.70s/it] 90%|█████████ | 1701/1881 [4:04:54<28:03,  9.35s/it] 90%|█████████ | 1702/1881 [4:05:02<27:08,  9.10s/it] 91%|█████████ | 1703/1881 [4:05:08<23:33,  7.94s/it] 91%|█████████ | 1704/1881 [4:05:14<22:04,  7.49s/it] 91%|█████████ | 1705/1881 [4:05:21<21:36,  7.36s/it] 91%|█████████ | 1706/1881 [4:05:30<23:06,  7.92s/it] 91%|█████████ | 1707/1881 [4:05:38<22:52,  7.89s/it] 91%|█████████ | 1708/1881 [4:05:45<21:40,  7.52s/it] 91%|█████████ | 1709/1881 [4:05:56<24:20,  8.49s/it] 91%|█████████ | 1710/1881 [4:06:01<21:32,  7.56s/it]                                                     {'loss': 0.3274, 'grad_norm': 26.43328857421875, 'learning_rate': 5.6454084331071884e-08, 'rewards/chosen': 2.771563768386841, 'rewards/rejected': -1.259667992591858, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 4.031786918640137, 'logps/chosen': -282.23748779296875, 'logps/rejected': -166.75, 'logits/chosen': -7.278124809265137, 'logits/rejected': -6.978125095367432, 'epoch': 2.72}
 91%|█████████ | 1710/1881 [4:06:01<21:32,  7.56s/it] 91%|█████████ | 1711/1881 [4:06:08<20:48,  7.34s/it] 91%|█████████ | 1712/1881 [4:06:15<20:33,  7.30s/it] 91%|█████████ | 1713/1881 [4:06:27<24:25,  8.73s/it] 91%|█████████ | 1714/1881 [4:06:34<22:20,  8.03s/it] 91%|█████████ | 1715/1881 [4:06:41<21:26,  7.75s/it] 91%|█████████ | 1716/1881 [4:06:51<23:06,  8.40s/it] 91%|█████████▏| 1717/1881 [4:06:56<20:53,  7.64s/it] 91%|█████████▏| 1718/1881 [4:07:02<19:18,  7.11s/it] 91%|█████████▏| 1719/1881 [4:07:09<19:13,  7.12s/it] 91%|█████████▏| 1720/1881 [4:07:15<18:14,  6.80s/it]                                                     {'loss': 0.3405, 'grad_norm': 51.761905670166016, 'learning_rate': 5.4622032704742326e-08, 'rewards/chosen': 2.765380859375, 'rewards/rejected': -1.033380150794983, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.7978515625, 'logps/chosen': -301.3125, 'logps/rejected': -166.8000030517578, 'logits/chosen': -6.934374809265137, 'logits/rejected': -6.848437309265137, 'epoch': 2.74}
 91%|█████████▏| 1720/1881 [4:07:15<18:14,  6.80s/it] 91%|█████████▏| 1721/1881 [4:07:26<21:14,  7.96s/it] 92%|█████████▏| 1722/1881 [4:07:36<22:54,  8.64s/it] 92%|█████████▏| 1723/1881 [4:07:43<21:26,  8.14s/it] 92%|█████████▏| 1724/1881 [4:07:54<23:30,  8.98s/it] 92%|█████████▏| 1725/1881 [4:08:00<21:09,  8.14s/it] 92%|█████████▏| 1726/1881 [4:08:11<22:45,  8.81s/it] 92%|█████████▏| 1727/1881 [4:08:18<21:32,  8.39s/it] 92%|█████████▏| 1728/1881 [4:08:26<20:49,  8.16s/it] 92%|█████████▏| 1729/1881 [4:08:34<20:44,  8.19s/it] 92%|█████████▏| 1730/1881 [4:08:40<18:50,  7.49s/it]                                                     {'loss': 0.3385, 'grad_norm': 42.042415618896484, 'learning_rate': 5.2893772057106945e-08, 'rewards/chosen': 0.8389739990234375, 'rewards/rejected': -1.732031226158142, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 2.5726561546325684, 'logps/chosen': -157.83749389648438, 'logps/rejected': -151.8000030517578, 'logits/chosen': -7.134375095367432, 'logits/rejected': -6.853125095367432, 'epoch': 2.76}
 92%|█████████▏| 1730/1881 [4:08:40<18:50,  7.49s/it] 92%|█████████▏| 1731/1881 [4:08:47<18:35,  7.44s/it] 92%|█████████▏| 1732/1881 [4:08:52<16:45,  6.75s/it] 92%|█████████▏| 1733/1881 [4:09:04<20:12,  8.20s/it] 92%|█████████▏| 1734/1881 [4:09:11<19:06,  7.80s/it] 92%|█████████▏| 1735/1881 [4:09:17<17:54,  7.36s/it] 92%|█████████▏| 1736/1881 [4:09:30<22:01,  9.11s/it] 92%|█████████▏| 1737/1881 [4:09:38<21:00,  8.75s/it] 92%|█████████▏| 1738/1881 [4:09:48<21:32,  9.04s/it] 92%|█████████▏| 1739/1881 [4:09:54<18:57,  8.01s/it] 93%|█████████▎| 1740/1881 [4:10:03<19:28,  8.29s/it]                                                     {'loss': 0.3499, 'grad_norm': 39.452152252197266, 'learning_rate': 5.1270387042107255e-08, 'rewards/chosen': 1.2279541492462158, 'rewards/rejected': -1.175683617591858, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.403125047683716, 'logps/chosen': -156.7624969482422, 'logps/rejected': -137.64999389648438, 'logits/chosen': -7.229687690734863, 'logits/rejected': -6.974999904632568, 'epoch': 2.77}
 93%|█████████▎| 1740/1881 [4:10:03<19:28,  8.29s/it] 93%|█████████▎| 1741/1881 [4:10:12<19:52,  8.51s/it] 93%|█████████▎| 1742/1881 [4:10:18<18:17,  7.90s/it] 93%|█████████▎| 1743/1881 [4:10:31<21:29,  9.34s/it] 93%|█████████▎| 1744/1881 [4:10:42<22:45,  9.97s/it] 93%|█████████▎| 1745/1881 [4:10:54<23:51, 10.53s/it] 93%|█████████▎| 1746/1881 [4:11:00<20:49,  9.25s/it] 93%|█████████▎| 1747/1881 [4:11:09<20:14,  9.06s/it] 93%|█████████▎| 1748/1881 [4:11:14<17:04,  7.71s/it] 93%|█████████▎| 1749/1881 [4:11:22<17:22,  7.90s/it] 93%|█████████▎| 1750/1881 [4:11:29<16:31,  7.57s/it]                                                     {'loss': 0.2402, 'grad_norm': 30.009567260742188, 'learning_rate': 4.975289649388576e-08, 'rewards/chosen': 3.7862792015075684, 'rewards/rejected': -0.804394543170929, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.591015815734863, 'logps/chosen': -346.5874938964844, 'logps/rejected': -207.16250610351562, 'logits/chosen': -7.081250190734863, 'logits/rejected': -6.849999904632568, 'epoch': 2.79}
 93%|█████████▎| 1750/1881 [4:11:29<16:31,  7.57s/it] 93%|█████████▎| 1751/1881 [4:11:38<17:35,  8.12s/it] 93%|█████████▎| 1752/1881 [4:11:45<16:39,  7.75s/it] 93%|█████████▎| 1753/1881 [4:11:52<16:22,  7.67s/it] 93%|█████████▎| 1754/1881 [4:11:58<14:37,  6.91s/it] 93%|█████████▎| 1755/1881 [4:12:08<16:53,  8.04s/it] 93%|█████████▎| 1756/1881 [4:12:17<17:17,  8.30s/it] 93%|█████████▎| 1757/1881 [4:12:24<16:20,  7.91s/it] 93%|█████████▎| 1758/1881 [4:12:30<14:47,  7.21s/it] 94%|█████████▎| 1759/1881 [4:12:37<14:38,  7.20s/it] 94%|█████████▎| 1760/1881 [4:12:45<14:55,  7.40s/it]                                                     {'loss': 0.3167, 'grad_norm': 37.84810256958008, 'learning_rate': 4.8342252787367256e-08, 'rewards/chosen': 2.358691453933716, 'rewards/rejected': -1.180566430091858, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.544921875, 'logps/chosen': -235.2375030517578, 'logps/rejected': -149.16250610351562, 'logits/chosen': -7.065625190734863, 'logits/rejected': -7.071875095367432, 'epoch': 2.8}
 94%|█████████▎| 1760/1881 [4:12:45<14:55,  7.40s/it] 94%|█████████▎| 1761/1881 [4:12:50<13:32,  6.77s/it] 94%|█████████▎| 1762/1881 [4:12:59<14:55,  7.53s/it] 94%|█████████▎| 1763/1881 [4:13:10<16:52,  8.58s/it] 94%|█████████▍| 1764/1881 [4:13:17<15:21,  7.88s/it] 94%|█████████▍| 1765/1881 [4:13:27<16:39,  8.61s/it] 94%|█████████▍| 1766/1881 [4:13:35<15:55,  8.31s/it] 94%|█████████▍| 1767/1881 [4:13:42<15:23,  8.10s/it] 94%|█████████▍| 1768/1881 [4:13:49<14:33,  7.73s/it] 94%|█████████▍| 1769/1881 [4:13:55<13:20,  7.15s/it] 94%|█████████▍| 1770/1881 [4:14:04<14:08,  7.65s/it]                                                     {'loss': 0.3606, 'grad_norm': 41.35129928588867, 'learning_rate': 4.703934124054954e-08, 'rewards/chosen': 3.070321559906006, 'rewards/rejected': -0.33642578125, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.400195360183716, 'logps/chosen': -320.38751220703125, 'logps/rejected': -267.17498779296875, 'logits/chosen': -7.051562309265137, 'logits/rejected': -6.853125095367432, 'epoch': 2.82}
 94%|█████████▍| 1770/1881 [4:14:04<14:08,  7.65s/it] 94%|█████████▍| 1771/1881 [4:14:10<13:25,  7.32s/it] 94%|█████████▍| 1772/1881 [4:14:17<12:55,  7.12s/it] 94%|█████████▍| 1773/1881 [4:14:27<14:23,  7.99s/it] 94%|█████████▍| 1774/1881 [4:14:34<13:43,  7.70s/it] 94%|█████████▍| 1775/1881 [4:14:43<14:13,  8.05s/it] 94%|█████████▍| 1776/1881 [4:14:49<13:07,  7.50s/it] 94%|█████████▍| 1777/1881 [4:15:03<16:13,  9.36s/it] 95%|█████████▍| 1778/1881 [4:15:12<16:10,  9.42s/it] 95%|█████████▍| 1779/1881 [4:15:20<15:17,  8.99s/it] 95%|█████████▍| 1780/1881 [4:15:30<15:24,  9.15s/it]                                                     {'loss': 0.3886, 'grad_norm': 68.61543273925781, 'learning_rate': 4.584497955887915e-08, 'rewards/chosen': 1.484686255455017, 'rewards/rejected': -1.62255859375, 'rewards/accuracies': 0.8062499761581421, 'rewards/margins': 3.1048827171325684, 'logps/chosen': -200.5749969482422, 'logps/rejected': -124.36250305175781, 'logits/chosen': -7.184374809265137, 'logits/rejected': -7.162499904632568, 'epoch': 2.84}
 95%|█████████▍| 1780/1881 [4:15:30<15:24,  9.15s/it] 95%|█████████▍| 1781/1881 [4:15:37<14:27,  8.67s/it] 95%|█████████▍| 1782/1881 [4:15:45<13:34,  8.22s/it] 95%|█████████▍| 1783/1881 [4:15:49<11:47,  7.22s/it] 95%|█████████▍| 1784/1881 [4:15:55<10:53,  6.73s/it] 95%|█████████▍| 1785/1881 [4:16:04<12:03,  7.53s/it] 95%|█████████▍| 1786/1881 [4:16:17<14:24,  9.10s/it] 95%|█████████▌| 1787/1881 [4:16:28<15:01,  9.59s/it] 95%|█████████▌| 1788/1881 [4:16:35<13:33,  8.75s/it] 95%|█████████▌| 1789/1881 [4:16:41<12:18,  8.03s/it] 95%|█████████▌| 1790/1881 [4:16:47<11:03,  7.29s/it]                                                     {'loss': 0.304, 'grad_norm': 34.04011154174805, 'learning_rate': 4.475991732206059e-08, 'rewards/chosen': 3.8266358375549316, 'rewards/rejected': -0.648974597454071, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.474804878234863, 'logps/chosen': -383.79998779296875, 'logps/rejected': -260.04998779296875, 'logits/chosen': -6.9765625, 'logits/rejected': -6.939062595367432, 'epoch': 2.85}
 95%|█████████▌| 1790/1881 [4:16:47<11:03,  7.29s/it] 95%|█████████▌| 1791/1881 [4:16:53<10:43,  7.16s/it] 95%|█████████▌| 1792/1881 [4:17:02<11:13,  7.57s/it] 95%|█████████▌| 1793/1881 [4:17:08<10:30,  7.17s/it] 95%|█████████▌| 1794/1881 [4:17:15<10:10,  7.01s/it] 95%|█████████▌| 1795/1881 [4:17:21<09:52,  6.89s/it] 95%|█████████▌| 1796/1881 [4:17:31<10:49,  7.64s/it] 96%|█████████▌| 1797/1881 [4:17:38<10:21,  7.40s/it] 96%|█████████▌| 1798/1881 [4:17:44<09:45,  7.05s/it] 96%|█████████▌| 1799/1881 [4:17:54<10:54,  7.98s/it] 96%|█████████▌| 1800/1881 [4:18:05<12:03,  8.94s/it]                                                     {'loss': 0.2795, 'grad_norm': 29.72195816040039, 'learning_rate': 4.378483551362116e-08, 'rewards/chosen': 3.402392625808716, 'rewards/rejected': -0.956250011920929, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.352343559265137, 'logps/chosen': -300.6499938964844, 'logps/rejected': -189.47500610351562, 'logits/chosen': -7.134375095367432, 'logits/rejected': -7.032812595367432, 'epoch': 2.87}
 96%|█████████▌| 1800/1881 [4:18:05<12:03,  8.94s/it] 96%|█████████▌| 1801/1881 [4:18:16<12:44,  9.56s/it] 96%|█████████▌| 1802/1881 [4:18:24<11:48,  8.96s/it] 96%|█████████▌| 1803/1881 [4:18:30<10:25,  8.02s/it] 96%|█████████▌| 1804/1881 [4:18:37<09:53,  7.70s/it] 96%|█████████▌| 1805/1881 [4:18:45<09:50,  7.77s/it] 96%|█████████▌| 1806/1881 [4:18:54<10:10,  8.14s/it] 96%|█████████▌| 1807/1881 [4:19:01<09:56,  8.06s/it] 96%|█████████▌| 1808/1881 [4:19:13<11:09,  9.17s/it] 96%|█████████▌| 1809/1881 [4:19:19<09:54,  8.26s/it] 96%|█████████▌| 1810/1881 [4:19:26<09:12,  7.78s/it]                                                     {'loss': 0.3928, 'grad_norm': 35.13795852661133, 'learning_rate': 4.2920346093526606e-08, 'rewards/chosen': 3.3442015647888184, 'rewards/rejected': -0.24853515625, 'rewards/accuracies': 0.7749999761581421, 'rewards/margins': 3.590625047683716, 'logps/chosen': -340.42498779296875, 'logps/rejected': -205.125, 'logits/chosen': -7.050000190734863, 'logits/rejected': -7.035937309265137, 'epoch': 2.88}
 96%|█████████▌| 1810/1881 [4:19:26<09:12,  7.78s/it] 96%|█████████▋| 1811/1881 [4:19:33<08:53,  7.63s/it] 96%|█████████▋| 1812/1881 [4:19:40<08:32,  7.43s/it] 96%|█████████▋| 1813/1881 [4:19:48<08:39,  7.64s/it] 96%|█████████▋| 1814/1881 [4:19:56<08:26,  7.56s/it] 96%|█████████▋| 1815/1881 [4:20:06<09:04,  8.26s/it] 97%|█████████▋| 1816/1881 [4:20:16<09:37,  8.88s/it] 97%|█████████▋| 1817/1881 [4:20:22<08:36,  8.07s/it] 97%|█████████▋| 1818/1881 [4:20:28<07:54,  7.54s/it] 97%|█████████▋| 1819/1881 [4:20:34<07:07,  6.90s/it] 97%|█████████▋| 1820/1881 [4:20:44<08:00,  7.88s/it]                                                     {'loss': 0.2903, 'grad_norm': 25.989883422851562, 'learning_rate': 4.2166991614115957e-08, 'rewards/chosen': 2.65118408203125, 'rewards/rejected': -1.361230492591858, 'rewards/accuracies': 0.875, 'rewards/margins': 4.012499809265137, 'logps/chosen': -270.9624938964844, 'logps/rejected': -165.1374969482422, 'logits/chosen': -7.076562404632568, 'logits/rejected': -6.904687404632568, 'epoch': 2.9}
 97%|█████████▋| 1820/1881 [4:20:44<08:00,  7.88s/it] 97%|█████████▋| 1821/1881 [4:20:58<09:49,  9.82s/it] 97%|█████████▋| 1822/1881 [4:21:06<08:55,  9.08s/it] 97%|█████████▋| 1823/1881 [4:21:12<08:00,  8.28s/it] 97%|█████████▋| 1824/1881 [4:21:21<07:57,  8.37s/it] 97%|█████████▋| 1825/1881 [4:21:27<07:13,  7.75s/it] 97%|█████████▋| 1826/1881 [4:21:34<06:46,  7.40s/it] 97%|█████████▋| 1827/1881 [4:21:44<07:24,  8.23s/it] 97%|█████████▋| 1828/1881 [4:21:49<06:31,  7.38s/it] 97%|█████████▋| 1829/1881 [4:22:00<07:21,  8.50s/it] 97%|█████████▋| 1830/1881 [4:22:08<07:01,  8.27s/it]                                                     {'loss': 0.3407, 'grad_norm': 41.21394729614258, 'learning_rate': 4.15252448795965e-08, 'rewards/chosen': 1.2195556163787842, 'rewards/rejected': -1.890283226966858, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.1141600608825684, 'logps/chosen': -181.22500610351562, 'logps/rejected': -131.58749389648438, 'logits/chosen': -7.270312309265137, 'logits/rejected': -7.279687404632568, 'epoch': 2.91}
 97%|█████████▋| 1830/1881 [4:22:08<07:01,  8.27s/it] 97%|█████████▋| 1831/1881 [4:22:15<06:40,  8.02s/it] 97%|█████████▋| 1832/1881 [4:22:22<06:14,  7.64s/it] 97%|█████████▋| 1833/1881 [4:22:29<05:56,  7.42s/it] 98%|█████████▊| 1834/1881 [4:22:36<05:37,  7.19s/it] 98%|█████████▊| 1835/1881 [4:22:42<05:18,  6.92s/it] 98%|█████████▊| 1836/1881 [4:22:49<05:15,  7.02s/it] 98%|█████████▊| 1837/1881 [4:22:57<05:21,  7.31s/it] 98%|█████████▊| 1838/1881 [4:23:06<05:34,  7.78s/it] 98%|█████████▊| 1839/1881 [4:23:15<05:40,  8.11s/it] 98%|█████████▊| 1840/1881 [4:23:22<05:23,  7.90s/it]                                                     {'loss': 0.3402, 'grad_norm': 35.31200408935547, 'learning_rate': 4.0995508649312356e-08, 'rewards/chosen': 1.27069091796875, 'rewards/rejected': -1.986914038658142, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 3.257031202316284, 'logps/chosen': -184.9250030517578, 'logps/rejected': -133.72500610351562, 'logits/chosen': -7.157812595367432, 'logits/rejected': -6.884375095367432, 'epoch': 2.93}
 98%|█████████▊| 1840/1881 [4:23:22<05:23,  7.90s/it] 98%|█████████▊| 1841/1881 [4:23:28<04:45,  7.14s/it] 98%|█████████▊| 1842/1881 [4:23:39<05:29,  8.44s/it] 98%|█████████▊| 1843/1881 [4:23:46<04:57,  7.82s/it] 98%|█████████▊| 1844/1881 [4:23:51<04:21,  7.06s/it] 98%|█████████▊| 1845/1881 [4:23:58<04:15,  7.08s/it] 98%|█████████▊| 1846/1881 [4:24:09<04:47,  8.20s/it] 98%|█████████▊| 1847/1881 [4:24:18<04:49,  8.52s/it] 98%|█████████▊| 1848/1881 [4:24:23<04:01,  7.33s/it] 98%|█████████▊| 1849/1881 [4:24:30<03:59,  7.49s/it] 98%|█████████▊| 1850/1881 [4:24:40<04:06,  7.95s/it]                                                     {'loss': 0.3659, 'grad_norm': 39.3681526184082, 'learning_rate': 4.0578115384973505e-08, 'rewards/chosen': 0.9934448003768921, 'rewards/rejected': -1.4568359851837158, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 2.449023485183716, 'logps/chosen': -128.125, 'logps/rejected': -119.13749694824219, 'logits/chosen': -7.348437309265137, 'logits/rejected': -7.175000190734863, 'epoch': 2.95}
 98%|█████████▊| 1850/1881 [4:24:40<04:06,  7.95s/it] 98%|█████████▊| 1851/1881 [4:24:46<03:43,  7.46s/it] 98%|█████████▊| 1852/1881 [4:24:53<03:32,  7.31s/it] 99%|█████████▊| 1853/1881 [4:25:00<03:25,  7.34s/it] 99%|█████████▊| 1854/1881 [4:25:08<03:21,  7.47s/it] 99%|█████████▊| 1855/1881 [4:25:12<02:47,  6.45s/it] 99%|█████████▊| 1856/1881 [4:25:18<02:39,  6.36s/it] 99%|█████████▊| 1857/1881 [4:25:24<02:27,  6.16s/it] 99%|█████████▉| 1858/1881 [4:25:32<02:34,  6.73s/it] 99%|█████████▉| 1859/1881 [4:25:38<02:20,  6.40s/it] 99%|█████████▉| 1860/1881 [4:25:48<02:38,  7.57s/it]                                                     {'loss': 0.3185, 'grad_norm': 36.40462875366211, 'learning_rate': 4.0273327042003094e-08, 'rewards/chosen': 1.890960693359375, 'rewards/rejected': -1.01416015625, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.904296875, 'logps/chosen': -198.77499389648438, 'logps/rejected': -156.0625, 'logits/chosen': -7.298437595367432, 'logits/rejected': -7.139062404632568, 'epoch': 2.96}
 99%|█████████▉| 1860/1881 [4:25:48<02:38,  7.57s/it] 99%|█████████▉| 1861/1881 [4:25:53<02:16,  6.83s/it] 99%|█████████▉| 1862/1881 [4:26:01<02:15,  7.11s/it] 99%|█████████▉| 1863/1881 [4:26:07<02:05,  6.98s/it] 99%|█████████▉| 1864/1881 [4:26:14<01:55,  6.81s/it] 99%|█████████▉| 1865/1881 [4:26:21<01:51,  6.99s/it] 99%|█████████▉| 1866/1881 [4:26:29<01:48,  7.25s/it] 99%|█████████▉| 1867/1881 [4:26:37<01:43,  7.36s/it] 99%|█████████▉| 1868/1881 [4:26:44<01:34,  7.28s/it] 99%|█████████▉| 1869/1881 [4:26:50<01:23,  6.99s/it] 99%|█████████▉| 1870/1881 [4:26:57<01:16,  6.94s/it]                                                     {'loss': 0.2346, 'grad_norm': 17.995952606201172, 'learning_rate': 4.0081334905134677e-08, 'rewards/chosen': 1.1625487804412842, 'rewards/rejected': -1.8308594226837158, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 2.9888672828674316, 'logps/chosen': -137.0625, 'logps/rejected': -123.1875, 'logits/chosen': -7.199999809265137, 'logits/rejected': -7.020312309265137, 'epoch': 2.98}
 99%|█████████▉| 1870/1881 [4:26:57<01:16,  6.94s/it] 99%|█████████▉| 1871/1881 [4:27:03<01:07,  6.78s/it]100%|█████████▉| 1872/1881 [4:27:12<01:07,  7.47s/it]100%|█████████▉| 1873/1881 [4:27:19<00:56,  7.10s/it]100%|█████████▉| 1874/1881 [4:27:29<00:55,  7.94s/it]100%|█████████▉| 1875/1881 [4:27:36<00:46,  7.77s/it]100%|█████████▉| 1876/1881 [4:27:44<00:39,  7.92s/it]100%|█████████▉| 1877/1881 [4:27:54<00:34,  8.55s/it]100%|█████████▉| 1878/1881 [4:28:04<00:26,  8.79s/it]
  0%|          | 0/120 [00:00<?, ?it/s][A
  2%|▏         | 2/120 [00:01<01:32,  1.28it/s][A
  2%|▎         | 3/120 [00:03<02:10,  1.11s/it][A
  3%|▎         | 4/120 [00:04<02:26,  1.27s/it][A
  4%|▍         | 5/120 [00:06<02:38,  1.38s/it][A
  5%|▌         | 6/120 [00:07<02:42,  1.42s/it][A
  6%|▌         | 7/120 [00:09<03:03,  1.63s/it][A
  7%|▋         | 8/120 [00:12<03:49,  2.05s/it][A
  8%|▊         | 9/120 [00:16<04:48,  2.60s/it][A
  8%|▊         | 10/120 [00:18<04:10,  2.28s/it][A
  9%|▉         | 11/120 [00:19<03:44,  2.06s/it][A
 10%|█         | 12/120 [00:21<03:28,  1.93s/it][A
 11%|█         | 13/120 [00:24<04:07,  2.31s/it][A
 12%|█▏        | 14/120 [00:26<03:47,  2.14s/it][A
 12%|█▎        | 15/120 [00:29<04:05,  2.34s/it][A
 13%|█▎        | 16/120 [00:32<04:41,  2.71s/it][A
 14%|█▍        | 17/120 [00:36<05:03,  2.95s/it][A
 15%|█▌        | 18/120 [00:40<05:32,  3.26s/it][A
 16%|█▌        | 19/120 [00:43<05:19,  3.17s/it][A
 17%|█▋        | 20/120 [00:46<05:35,  3.36s/it][A
 18%|█▊        | 21/120 [00:48<04:43,  2.86s/it][A
 18%|█▊        | 22/120 [00:50<04:15,  2.61s/it][A
 19%|█▉        | 23/120 [00:54<04:43,  2.92s/it][A
 20%|██        | 24/120 [00:57<04:45,  2.97s/it][A
 21%|██        | 25/120 [01:00<04:46,  3.02s/it][A
 22%|██▏       | 26/120 [01:02<04:02,  2.58s/it][A
 22%|██▎       | 27/120 [01:05<04:33,  2.94s/it][A
 23%|██▎       | 28/120 [01:06<03:40,  2.39s/it][A
 24%|██▍       | 29/120 [01:07<02:48,  1.85s/it][A
 25%|██▌       | 30/120 [01:08<02:30,  1.67s/it][A
 26%|██▌       | 31/120 [01:09<01:58,  1.34s/it][A
 27%|██▋       | 32/120 [01:10<01:50,  1.25s/it][A
 28%|██▊       | 33/120 [01:11<01:32,  1.06s/it][A
 28%|██▊       | 34/120 [01:12<01:31,  1.06s/it][A
 29%|██▉       | 35/120 [01:12<01:20,  1.06it/s][A
 30%|███       | 36/120 [01:13<01:13,  1.15it/s][A
 31%|███       | 37/120 [01:14<01:19,  1.04it/s][A
 32%|███▏      | 38/120 [01:15<01:25,  1.05s/it][A
 32%|███▎      | 39/120 [01:17<01:33,  1.16s/it][A
 33%|███▎      | 40/120 [01:17<01:17,  1.03it/s][A
 34%|███▍      | 41/120 [01:19<01:28,  1.12s/it][A
 35%|███▌      | 42/120 [01:21<01:51,  1.43s/it][A
 36%|███▌      | 43/120 [01:22<01:47,  1.39s/it][A
 37%|███▋      | 44/120 [01:24<01:50,  1.45s/it][A
 38%|███▊      | 45/120 [01:25<01:41,  1.36s/it][A
 38%|███▊      | 46/120 [01:26<01:34,  1.28s/it][A
 39%|███▉      | 47/120 [01:27<01:26,  1.19s/it][A
 40%|████      | 48/120 [01:28<01:12,  1.00s/it][A
 41%|████      | 49/120 [01:29<01:11,  1.00s/it][A
 42%|████▏     | 50/120 [01:33<02:19,  2.00s/it][A
 42%|████▎     | 51/120 [01:34<02:06,  1.83s/it][A
 43%|████▎     | 52/120 [01:35<01:36,  1.42s/it][A
 44%|████▍     | 53/120 [01:36<01:22,  1.23s/it][A
 45%|████▌     | 54/120 [01:36<01:10,  1.06s/it][A
 46%|████▌     | 55/120 [01:37<01:06,  1.03s/it][A
 47%|████▋     | 56/120 [01:38<00:56,  1.14it/s][A
 48%|████▊     | 57/120 [01:39<00:53,  1.17it/s][A
 48%|████▊     | 58/120 [01:40<00:59,  1.05it/s][A
 49%|████▉     | 59/120 [01:41<01:11,  1.16s/it][A
 50%|█████     | 60/120 [01:43<01:09,  1.16s/it][A
 51%|█████     | 61/120 [01:43<00:59,  1.01s/it][A
 52%|█████▏    | 62/120 [01:45<01:08,  1.18s/it][A
 52%|█████▎    | 63/120 [01:45<00:58,  1.03s/it][A
 53%|█████▎    | 64/120 [01:48<01:28,  1.57s/it][A
 54%|█████▍    | 65/120 [01:52<01:53,  2.06s/it][A
 55%|█████▌    | 66/120 [01:53<01:37,  1.81s/it][A
 56%|█████▌    | 67/120 [01:54<01:20,  1.51s/it][A
 57%|█████▋    | 68/120 [01:54<01:04,  1.24s/it][A
 57%|█████▊    | 69/120 [01:55<00:49,  1.02it/s][A
 58%|█████▊    | 70/120 [01:56<00:55,  1.11s/it][A
 59%|█████▉    | 71/120 [01:58<01:09,  1.41s/it][A
 60%|██████    | 72/120 [01:59<00:54,  1.13s/it][A
 61%|██████    | 73/120 [01:59<00:45,  1.04it/s][A
 62%|██████▏   | 74/120 [02:00<00:37,  1.24it/s][A
 62%|██████▎   | 75/120 [02:00<00:32,  1.40it/s][A
 63%|██████▎   | 76/120 [02:02<00:42,  1.03it/s][A
 64%|██████▍   | 77/120 [02:03<00:43,  1.02s/it][A
 65%|██████▌   | 78/120 [02:04<00:42,  1.02s/it][A
 66%|██████▌   | 79/120 [02:06<00:52,  1.28s/it][A
 67%|██████▋   | 80/120 [02:06<00:45,  1.13s/it][A
 68%|██████▊   | 81/120 [02:09<01:05,  1.68s/it][A
 68%|██████▊   | 82/120 [02:10<00:50,  1.32s/it][A
 69%|██████▉   | 83/120 [02:12<00:52,  1.42s/it][A
 70%|███████   | 84/120 [02:13<00:52,  1.46s/it][A
 71%|███████   | 85/120 [02:14<00:45,  1.29s/it][A
 72%|███████▏  | 86/120 [02:15<00:40,  1.19s/it][A
 72%|███████▎  | 87/120 [02:16<00:42,  1.27s/it][A
 73%|███████▎  | 88/120 [02:18<00:41,  1.30s/it][A
 74%|███████▍  | 89/120 [02:20<00:44,  1.44s/it][A
 75%|███████▌  | 90/120 [02:20<00:35,  1.17s/it][A
 76%|███████▌  | 91/120 [02:23<00:52,  1.81s/it][A
 77%|███████▋  | 92/120 [02:25<00:48,  1.74s/it][A
 78%|███████▊  | 93/120 [02:27<00:46,  1.73s/it][A
 78%|███████▊  | 94/120 [02:28<00:39,  1.54s/it][A
 79%|███████▉  | 95/120 [02:29<00:33,  1.34s/it][A
 80%|████████  | 96/120 [02:30<00:29,  1.23s/it][A
 81%|████████  | 97/120 [02:31<00:29,  1.30s/it][A
 82%|████████▏ | 98/120 [02:33<00:32,  1.48s/it][A
 82%|████████▎ | 99/120 [02:35<00:31,  1.50s/it][A
 83%|████████▎ | 100/120 [02:38<00:41,  2.05s/it][A
 84%|████████▍ | 101/120 [02:39<00:34,  1.83s/it][A
 85%|████████▌ | 102/120 [02:41<00:31,  1.75s/it][A
 86%|████████▌ | 103/120 [02:41<00:24,  1.45s/it][A
 87%|████████▋ | 104/120 [02:43<00:23,  1.45s/it][A
 88%|████████▊ | 105/120 [02:44<00:20,  1.34s/it][A
 88%|████████▊ | 106/120 [02:45<00:17,  1.23s/it][A
 89%|████████▉ | 107/120 [02:47<00:17,  1.33s/it][A
 90%|█████████ | 108/120 [02:49<00:18,  1.53s/it][A
 91%|█████████ | 109/120 [02:50<00:15,  1.41s/it][A
 92%|█████████▏| 110/120 [02:51<00:12,  1.29s/it][A
 92%|█████████▎| 111/120 [02:52<00:12,  1.37s/it][A
 93%|█████████▎| 112/120 [02:53<00:10,  1.30s/it][A
 94%|█████████▍| 113/120 [02:55<00:09,  1.38s/it][A
 95%|█████████▌| 114/120 [02:58<00:11,  1.99s/it][A
 96%|█████████▌| 115/120 [03:00<00:08,  1.79s/it][A
 97%|█████████▋| 116/120 [03:00<00:05,  1.44s/it][A
 98%|█████████▊| 117/120 [03:01<00:03,  1.20s/it][A
 98%|█████████▊| 118/120 [03:03<00:02,  1.39s/it][A
 99%|█████████▉| 119/120 [03:04<00:01,  1.23s/it][A
100%|██████████| 120/120 [03:05<00:00,  1.35s/it][A                                                     
                                                 [A{'eval_loss': 0.4165184795856476, 'eval_runtime': 187.4033, 'eval_samples_per_second': 5.085, 'eval_steps_per_second': 0.64, 'eval_rewards/chosen': 3.2168517112731934, 'eval_rewards/rejected': -0.3858174681663513, 'eval_rewards/accuracies': 0.7885416746139526, 'eval_rewards/margins': 3.600451707839966, 'eval_logps/chosen': -362.2562561035156, 'eval_logps/rejected': -154.12916564941406, 'eval_logits/chosen': -6.757161617279053, 'eval_logits/rejected': -7.336979389190674, 'epoch': 2.99}
100%|█████████▉| 1878/1881 [4:31:11<00:26,  8.79s/it]
100%|██████████| 120/120 [03:05<00:00,  1.35s/it][A
                                                 [A/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
100%|█████████▉| 1879/1881 [4:31:29<02:15, 67.66s/it]100%|█████████▉| 1880/1881 [4:31:34<00:48, 48.92s/it]                                                     {'loss': 0.3034, 'grad_norm': 33.00493240356445, 'learning_rate': 4.0002259468362186e-08, 'rewards/chosen': 4.049902439117432, 'rewards/rejected': -0.78955078125, 'rewards/accuracies': 0.875, 'rewards/margins': 4.832812309265137, 'logps/chosen': -378.6000061035156, 'logps/rejected': -220.2624969482422, 'logits/chosen': -6.921875, 'logits/rejected': -6.946875095367432, 'epoch': 2.99}
100%|█████████▉| 1880/1881 [4:31:34<00:48, 48.92s/it]100%|██████████| 1881/1881 [4:31:41<00:00, 36.45s/it]                                                     {'train_runtime': 16323.0759, 'train_samples_per_second': 1.844, 'train_steps_per_second': 0.115, 'train_loss': 0.43607705606544733, 'epoch': 3.0}
100%|██████████| 1881/1881 [4:31:59<00:00, 36.45s/it]100%|██████████| 1881/1881 [4:31:59<00:00,  8.68s/it]
Training complete
Saving model
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mDPO_r-64_lr-4e-07_e-3_b-0.2[0m at: [34mhttps://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/tsynghlz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250604_123539-tsynghlz/logs[0m
[rank0]:[W604 17:07:44.069428012 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 0 ---
