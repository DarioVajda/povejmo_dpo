cpu-bind=MASK - gn23, task  1  0 [3246372]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn21
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 1     --main_process_ip gn21     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62083729     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-31 01:43:00,121] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0531 01:43:02.425000 3246419 torch/distributed/run.py:792] 
W0531 01:43:02.425000 3246419 torch/distributed/run.py:792] *****************************************
W0531 01:43:02.425000 3246419 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0531 01:43:02.425000 3246419 torch/distributed/run.py:792] *****************************************
[2025-05-31 01:43:12,421] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 01:43:12,467] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 01:43:12,486] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 01:43:12,496] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 2
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
[2025-05-31 01:43:15,868] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 4282
Eval steps: 2141
[2025-05-31 01:43:15,874] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 01:43:15,875] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 01:43:15,883] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
[2025-05-31 01:43:17,669] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-31 01:43:17,669] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-31 01:43:17,669] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-31 01:43:17,669] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.27s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.27s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.27s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.27s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:19<00:21, 10.67s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:19<00:21, 10.67s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:19<00:21, 10.68s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:19<00:21, 10.68s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:30<00:11, 11.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:30<00:11, 11.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:30<00:11, 11.05s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:30<00:11, 11.05s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.46s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.05s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.46s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.46s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.47s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.05s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.05s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:40<00:00, 10.05s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
Using LoRA and set up the model
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   6%|▌         | 530/8564 [00:00<00:01, 5241.67 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1079/8564 [00:00<00:01, 5367.37 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1620/8564 [00:00<00:01, 5363.69 examples/s]Extracting prompt in train dataset:  25%|██▌       | 2175/8564 [00:00<00:01, 5435.21 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2730/8564 [00:00<00:01, 5462.93 examples/s]Extracting prompt in train dataset:  41%|████▏     | 3540/8564 [00:00<00:00, 5405.90 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4100/8564 [00:00<00:00, 5446.54 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 4660/8564 [00:00<00:00, 5468.70 examples/s]Extracting prompt in train dataset:  61%|██████    | 5229/8564 [00:00<00:00, 5529.70 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5797/8564 [00:01<00:00, 5562.80 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6368/8564 [00:01<00:00, 5593.71 examples/s]Extracting prompt in train dataset:  81%|████████  | 6938/8564 [00:01<00:00, 5610.44 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7504/8564 [00:01<00:00, 5609.46 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8300/8564 [00:01<00:00, 5430.16 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5429.48 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 282/8564 [00:00<00:02, 2793.28 examples/s]Applying chat template to train dataset:   7%|▋         | 591/8564 [00:00<00:02, 2963.80 examples/s]Applying chat template to train dataset:  11%|█         | 901/8564 [00:00<00:02, 3024.24 examples/s]Applying chat template to train dataset:  14%|█▍        | 1212/8564 [00:00<00:02, 3053.96 examples/s]Applying chat template to train dataset:  18%|█▊        | 1520/8564 [00:00<00:02, 3053.48 examples/s]Applying chat template to train dataset:  21%|██▏       | 1832/8564 [00:00<00:02, 3071.41 examples/s]Applying chat template to train dataset:  25%|██▌       | 2146/8564 [00:00<00:02, 3091.46 examples/s]Applying chat template to train dataset:  29%|██▊       | 2460/8564 [00:00<00:01, 3100.51 examples/s]Applying chat template to train dataset:  32%|███▏      | 2772/8564 [00:00<00:01, 3104.07 examples/s]Applying chat template to train dataset:  38%|███▊      | 3228/8564 [00:01<00:01, 3068.02 examples/s]Applying chat template to train dataset:  41%|████▏     | 3540/8564 [00:01<00:01, 3078.14 examples/s]Applying chat template to train dataset:  45%|████▍     | 3852/8564 [00:01<00:01, 3089.40 examples/s]Applying chat template to train dataset:  49%|████▊     | 4165/8564 [00:01<00:01, 3097.42 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4478/8564 [00:01<00:01, 3102.64 examples/s]Applying chat template to train dataset:  56%|█████▌    | 4789/8564 [00:01<00:01, 3102.32 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5108/8564 [00:01<00:01, 3124.29 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5426/8564 [00:01<00:00, 3140.04 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5745/8564 [00:01<00:00, 3152.93 examples/s]Applying chat template to train dataset:  71%|███████   | 6064/8564 [00:01<00:00, 3159.88 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6382/8564 [00:02<00:00, 3163.84 examples/s]Applying chat template to train dataset:  78%|███████▊  | 6700/8564 [00:02<00:00, 3166.16 examples/s]Applying chat template to train dataset:  82%|████████▏ | 7020/8564 [00:02<00:00, 3168.79 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7340/8564 [00:02<00:00, 3174.08 examples/s]Applying chat template to train dataset:  89%|████████▉ | 7659/8564 [00:02<00:00, 3176.06 examples/s]Applying chat template to train dataset:  95%|█████████▍| 8094/8564 [00:02<00:00, 3064.73 examples/s]Applying chat template to train dataset:  98%|█████████▊| 8413/8564 [00:02<00:00, 3097.17 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3098.48 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:20, 408.09 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:24, 340.59 examples/s]Tokenizing train dataset:   2%|▏         | 138/8564 [00:00<00:26, 319.98 examples/s]Tokenizing train dataset:   2%|▏         | 182/8564 [00:00<00:27, 303.52 examples/s]Tokenizing train dataset:   3%|▎         | 217/8564 [00:00<00:26, 313.34 examples/s]Tokenizing train dataset:   3%|▎         | 251/8564 [00:00<00:26, 316.59 examples/s]Tokenizing train dataset:   3%|▎         | 289/8564 [00:00<00:24, 332.82 examples/s]Tokenizing train dataset:   4%|▍         | 337/8564 [00:01<00:25, 325.11 examples/s]Tokenizing train dataset:   5%|▍         | 387/8564 [00:01<00:25, 323.93 examples/s]Tokenizing train dataset:   5%|▌         | 434/8564 [00:01<00:25, 315.63 examples/s]Tokenizing train dataset:   6%|▌         | 480/8564 [00:01<00:26, 309.25 examples/s]Tokenizing train dataset:   6%|▌         | 527/8564 [00:01<00:26, 308.26 examples/s]Tokenizing train dataset:   7%|▋         | 561/8564 [00:01<00:25, 313.05 examples/s]Tokenizing train dataset:   7%|▋         | 605/8564 [00:01<00:26, 302.07 examples/s]Tokenizing train dataset:   8%|▊         | 644/8564 [00:02<00:24, 319.43 examples/s]Tokenizing train dataset:   8%|▊         | 690/8564 [00:02<00:25, 308.59 examples/s]Tokenizing train dataset:   8%|▊         | 722/8564 [00:02<00:25, 309.42 examples/s]Tokenizing train dataset:   9%|▉         | 759/8564 [00:02<00:24, 318.43 examples/s]Tokenizing train dataset:   9%|▉         | 802/8564 [00:02<00:25, 300.78 examples/s]Tokenizing train dataset:  10%|▉         | 847/8564 [00:02<00:25, 297.74 examples/s]Tokenizing train dataset:  10%|█         | 879/8564 [00:02<00:25, 298.25 examples/s]Tokenizing train dataset:  11%|█         | 916/8564 [00:02<00:24, 315.17 examples/s]Tokenizing train dataset:  11%|█         | 962/8564 [00:03<00:24, 305.93 examples/s]Tokenizing train dataset:  12%|█▏        | 1007/8564 [00:03<00:25, 297.58 examples/s]Tokenizing train dataset:  12%|█▏        | 1049/8564 [00:03<00:25, 290.39 examples/s]Tokenizing train dataset:  13%|█▎        | 1083/8564 [00:03<00:24, 300.69 examples/s]Tokenizing train dataset:  13%|█▎        | 1117/8564 [00:03<00:24, 306.13 examples/s]Tokenizing train dataset:  14%|█▎        | 1159/8564 [00:03<00:25, 292.58 examples/s]Tokenizing train dataset:  14%|█▍        | 1191/8564 [00:03<00:24, 297.48 examples/s]Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:03<00:24, 298.34 examples/s]Tokenizing train dataset:  15%|█▍        | 1258/8564 [00:04<00:23, 314.03 examples/s]Tokenizing train dataset:  15%|█▌        | 1309/8564 [00:04<00:22, 318.22 examples/s]Tokenizing train dataset:  16%|█▌        | 1342/8564 [00:04<00:22, 316.10 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:04<00:23, 301.72 examples/s]Tokenizing train dataset:  17%|█▋        | 1418/8564 [00:04<00:23, 301.94 examples/s]Tokenizing train dataset:  17%|█▋        | 1462/8564 [00:04<00:24, 294.83 examples/s]Tokenizing train dataset:  17%|█▋        | 1492/8564 [00:04<00:23, 294.71 examples/s]Tokenizing train dataset:  18%|█▊        | 1539/8564 [00:05<00:23, 297.65 examples/s]Tokenizing train dataset:  18%|█▊        | 1570/8564 [00:05<00:23, 295.33 examples/s]Tokenizing train dataset:  19%|█▊        | 1601/8564 [00:05<00:23, 294.78 examples/s]Tokenizing train dataset:  19%|█▉        | 1637/8564 [00:05<00:22, 307.43 examples/s]Tokenizing train dataset:  20%|█▉        | 1672/8564 [00:05<00:21, 317.76 examples/s]Tokenizing train dataset:  20%|██        | 1714/8564 [00:05<00:20, 338.51 examples/s]Tokenizing train dataset:  21%|██        | 1766/8564 [00:05<00:20, 335.92 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:05<00:20, 321.84 examples/s]Tokenizing train dataset:  22%|██▏       | 1848/8564 [00:05<00:20, 320.11 examples/s]Tokenizing train dataset:  22%|██▏       | 1893/8564 [00:06<00:21, 307.98 examples/s]Tokenizing train dataset:  23%|██▎       | 1938/8564 [00:06<00:19, 340.49 examples/s]Tokenizing train dataset:  23%|██▎       | 1975/8564 [00:06<00:19, 344.32 examples/s]Tokenizing train dataset:  24%|██▎       | 2013/8564 [00:06<00:18, 349.37 examples/s]Tokenizing train dataset:  24%|██▍       | 2052/8564 [00:06<00:18, 359.55 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:06<00:18, 358.50 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:06<00:17, 366.57 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:06<00:17, 362.45 examples/s]Tokenizing train dataset:  26%|██▌       | 2204/8564 [00:06<00:17, 358.96 examples/s]Tokenizing train dataset:  26%|██▌       | 2244/8564 [00:07<00:17, 368.11 examples/s]Tokenizing train dataset:  27%|██▋       | 2288/8564 [00:07<00:16, 384.50 examples/s]Tokenizing train dataset:  27%|██▋       | 2340/8564 [00:07<00:17, 361.85 examples/s]Tokenizing train dataset:  28%|██▊       | 2396/8564 [00:07<00:16, 363.47 examples/s]Tokenizing train dataset:  28%|██▊       | 2435/8564 [00:07<00:16, 367.79 examples/s]Tokenizing train dataset:  29%|██▉       | 2474/8564 [00:07<00:16, 372.17 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:07<00:16, 364.45 examples/s]Tokenizing train dataset:  30%|███       | 2571/8564 [00:07<00:15, 374.85 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:08<00:16, 353.16 examples/s]Tokenizing train dataset:  31%|███       | 2670/8564 [00:08<00:17, 344.68 examples/s]Tokenizing train dataset:  32%|███▏      | 2725/8564 [00:08<00:16, 348.04 examples/s]Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:08<00:16, 341.48 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:08<00:15, 359.08 examples/s]Tokenizing train dataset:  34%|███▎      | 2870/8564 [00:08<00:16, 342.99 examples/s]Tokenizing train dataset:  34%|███▍      | 2914/8564 [00:08<00:15, 363.94 examples/s]Tokenizing train dataset:  35%|███▍      | 2956/8564 [00:09<00:14, 376.75 examples/s]Tokenizing train dataset:  35%|███▌      | 2999/8564 [00:09<00:14, 387.79 examples/s]Tokenizing train dataset:  36%|███▌      | 3052/8564 [00:09<00:14, 372.36 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:09<00:14, 370.40 examples/s]Tokenizing train dataset:  37%|███▋      | 3164/8564 [00:09<00:14, 365.85 examples/s]Tokenizing train dataset:  38%|███▊      | 3220/8564 [00:09<00:14, 363.52 examples/s]Tokenizing train dataset:  38%|███▊      | 3261/8564 [00:09<00:14, 373.00 examples/s]Tokenizing train dataset:  39%|███▊      | 3314/8564 [00:09<00:14, 359.16 examples/s]Tokenizing train dataset:  39%|███▉      | 3370/8564 [00:10<00:14, 355.01 examples/s]Tokenizing train dataset:  40%|███▉      | 3414/8564 [00:10<00:13, 370.05 examples/s]Tokenizing train dataset:  40%|████      | 3452/8564 [00:10<00:13, 369.34 examples/s]Tokenizing train dataset:  41%|████      | 3512/8564 [00:10<00:13, 377.94 examples/s]Tokenizing train dataset:  42%|████▏     | 3564/8564 [00:10<00:13, 364.51 examples/s]Tokenizing train dataset:  42%|████▏     | 3606/8564 [00:10<00:13, 376.27 examples/s]Tokenizing train dataset:  43%|████▎     | 3658/8564 [00:10<00:13, 365.16 examples/s]Tokenizing train dataset:  43%|████▎     | 3712/8564 [00:11<00:13, 358.26 examples/s]Tokenizing train dataset:  44%|████▍     | 3752/8564 [00:11<00:13, 365.65 examples/s]Tokenizing train dataset:  44%|████▍     | 3790/8564 [00:11<00:13, 367.00 examples/s]Tokenizing train dataset:  45%|████▍     | 3842/8564 [00:11<00:13, 358.09 examples/s]Tokenizing train dataset:  45%|████▌     | 3880/8564 [00:11<00:12, 361.93 examples/s]Tokenizing train dataset:  46%|████▌     | 3931/8564 [00:11<00:13, 349.02 examples/s]Tokenizing train dataset:  46%|████▋     | 3970/8564 [00:11<00:12, 353.70 examples/s]Tokenizing train dataset:  47%|████▋     | 4006/8564 [00:11<00:12, 352.08 examples/s]Tokenizing train dataset:  47%|████▋     | 4046/8564 [00:12<00:12, 363.61 examples/s]Tokenizing train dataset:  48%|████▊     | 4098/8564 [00:12<00:12, 355.69 examples/s]Tokenizing train dataset:  48%|████▊     | 4134/8564 [00:12<00:12, 354.54 examples/s]Tokenizing train dataset:  49%|████▉     | 4189/8564 [00:12<00:12, 357.32 examples/s]Tokenizing train dataset:  49%|████▉     | 4229/8564 [00:12<00:12, 360.44 examples/s]Tokenizing train dataset:  50%|█████     | 4284/8564 [00:12<00:11, 359.77 examples/s]Tokenizing train dataset:  51%|█████     | 4337/8564 [00:12<00:11, 353.90 examples/s]Tokenizing train dataset:  51%|█████     | 4373/8564 [00:12<00:11, 355.24 examples/s]Tokenizing train dataset:  52%|█████▏    | 4411/8564 [00:13<00:11, 359.16 examples/s]Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:13<00:11, 360.95 examples/s]Tokenizing train dataset:  52%|█████▏    | 4489/8564 [00:13<00:11, 365.06 examples/s]Tokenizing train dataset:  53%|█████▎    | 4544/8564 [00:13<00:11, 356.57 examples/s]Tokenizing train dataset:  54%|█████▎    | 4598/8564 [00:13<00:11, 353.34 examples/s]Tokenizing train dataset:  54%|█████▍    | 4649/8564 [00:13<00:11, 343.89 examples/s]Tokenizing train dataset:  55%|█████▍    | 4697/8564 [00:13<00:11, 333.82 examples/s]Tokenizing train dataset:  55%|█████▌    | 4747/8564 [00:14<00:11, 329.72 examples/s]Tokenizing train dataset:  56%|█████▌    | 4794/8564 [00:14<00:11, 324.22 examples/s]Tokenizing train dataset:  57%|█████▋    | 4858/8564 [00:14<00:09, 391.77 examples/s]Tokenizing train dataset:  57%|█████▋    | 4913/8564 [00:14<00:08, 428.21 examples/s]Tokenizing train dataset:  58%|█████▊    | 4975/8564 [00:14<00:07, 475.87 examples/s]Tokenizing train dataset:  59%|█████▉    | 5033/8564 [00:14<00:07, 500.17 examples/s]Tokenizing train dataset:  60%|█████▉    | 5106/8564 [00:14<00:06, 556.40 examples/s]Tokenizing train dataset:  60%|██████    | 5177/8564 [00:14<00:05, 592.73 examples/s]Tokenizing train dataset:  61%|██████▏   | 5247/8564 [00:14<00:05, 621.95 examples/s]Tokenizing train dataset:  62%|██████▏   | 5319/8564 [00:15<00:05, 645.74 examples/s]Tokenizing train dataset:  63%|██████▎   | 5401/8564 [00:15<00:05, 604.63 examples/s]Tokenizing train dataset:  64%|██████▍   | 5467/8564 [00:15<00:05, 614.98 examples/s]Tokenizing train dataset:  65%|██████▍   | 5555/8564 [00:15<00:04, 602.77 examples/s]Tokenizing train dataset:  66%|██████▌   | 5623/8564 [00:15<00:04, 620.35 examples/s]Tokenizing train dataset:  66%|██████▋   | 5690/8564 [00:15<00:04, 627.43 examples/s]Tokenizing train dataset:  67%|██████▋   | 5756/8564 [00:15<00:04, 635.28 examples/s]Tokenizing train dataset:  68%|██████▊   | 5830/8564 [00:15<00:04, 660.28 examples/s]Tokenizing train dataset:  69%|██████▉   | 5916/8564 [00:15<00:04, 625.78 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [00:16<00:04, 592.95 examples/s]Tokenizing train dataset:  71%|███████   | 6042/8564 [00:16<00:04, 599.52 examples/s]Tokenizing train dataset:  71%|███████▏  | 6113/8564 [00:16<00:04, 547.06 examples/s]Tokenizing train dataset:  72%|███████▏  | 6188/8564 [00:16<00:03, 596.71 examples/s]Tokenizing train dataset:  73%|███████▎  | 6261/8564 [00:16<00:03, 629.10 examples/s]Tokenizing train dataset:  74%|███████▍  | 6360/8564 [00:16<00:03, 635.67 examples/s]Tokenizing train dataset:  75%|███████▌  | 6457/8564 [00:16<00:03, 630.87 examples/s]Tokenizing train dataset:  76%|███████▋  | 6548/8564 [00:17<00:03, 617.95 examples/s]Tokenizing train dataset:  77%|███████▋  | 6628/8564 [00:17<00:03, 585.39 examples/s]Tokenizing train dataset:  78%|███████▊  | 6695/8564 [00:17<00:03, 601.42 examples/s]Tokenizing train dataset:  79%|███████▉  | 6761/8564 [00:17<00:02, 614.06 examples/s]Tokenizing train dataset:  80%|███████▉  | 6847/8564 [00:17<00:02, 595.23 examples/s]Tokenizing train dataset:  81%|████████  | 6916/8564 [00:17<00:02, 614.87 examples/s]Tokenizing train dataset:  82%|████████▏ | 6982/8564 [00:17<00:02, 615.42 examples/s]Tokenizing train dataset:  83%|████████▎ | 7069/8564 [00:17<00:02, 600.77 examples/s]Tokenizing train dataset:  83%|████████▎ | 7136/8564 [00:17<00:02, 616.14 examples/s]Tokenizing train dataset:  84%|████████▍ | 7205/8564 [00:18<00:02, 633.61 examples/s]Tokenizing train dataset:  85%|████████▌ | 7292/8564 [00:18<00:02, 606.77 examples/s]Tokenizing train dataset:  86%|████████▌ | 7360/8564 [00:18<00:01, 618.57 examples/s]Tokenizing train dataset:  87%|████████▋ | 7457/8564 [00:18<00:01, 626.14 examples/s]Tokenizing train dataset:  88%|████████▊ | 7553/8564 [00:18<00:01, 628.68 examples/s]Tokenizing train dataset:  89%|████████▉ | 7626/8564 [00:18<00:01, 649.76 examples/s]Tokenizing train dataset:  90%|█████████ | 7708/8564 [00:18<00:01, 610.94 examples/s]Tokenizing train dataset:  91%|█████████ | 7791/8564 [00:19<00:01, 588.38 examples/s]Tokenizing train dataset:  92%|█████████▏| 7854/8564 [00:19<00:01, 593.26 examples/s]Tokenizing train dataset:  92%|█████████▏| 7916/8564 [00:19<00:01, 594.87 examples/s]Tokenizing train dataset:  93%|█████████▎| 7978/8564 [00:19<00:00, 599.74 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [00:19<00:00, 611.34 examples/s]Tokenizing train dataset:  95%|█████████▍| 8128/8564 [00:19<00:00, 583.60 examples/s]Tokenizing train dataset:  96%|█████████▌| 8198/8564 [00:19<00:00, 608.05 examples/s]Tokenizing train dataset:  96%|█████████▋| 8262/8564 [00:19<00:00, 613.39 examples/s]Tokenizing train dataset:  97%|█████████▋| 8331/8564 [00:19<00:00, 632.12 examples/s]Tokenizing train dataset:  98%|█████████▊| 8419/8564 [00:20<00:00, 611.33 examples/s]Tokenizing train dataset:  99%|█████████▉| 8510/8564 [00:20<00:00, 605.48 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 421.19 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 10828.66 examples/s]
Extracting prompt in train dataset:   6%|▌         | 535/8564 [00:00<00:01, 5301.59 examples/s]Extracting prompt in train dataset:   6%|▋         | 536/8564 [00:00<00:01, 5306.00 examples/s]Extracting prompt in train dataset:   6%|▋         | 540/8564 [00:00<00:01, 5325.36 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1080/8564 [00:00<00:01, 5385.74 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1080/8564 [00:00<00:01, 5369.36 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1093/8564 [00:00<00:01, 5441.63 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1643/8564 [00:00<00:01, 5465.88 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1630/8564 [00:00<00:01, 5419.43 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1630/8564 [00:00<00:01, 5404.49 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2205/8564 [00:00<00:01, 5519.13 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2193/8564 [00:00<00:01, 5486.78 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2191/8564 [00:00<00:01, 5467.03 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  32%|███▏      | 2769/8564 [00:00<00:01, 5561.50 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2751/8564 [00:00<00:01, 5517.22 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2750/8564 [00:00<00:01, 5501.13 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 12969.11 examples/s]
Extracting prompt in train dataset:  39%|███▉      | 3330/8564 [00:00<00:00, 5443.57 examples/s]Extracting prompt in train dataset:  41%|████▏     | 3553/8564 [00:00<00:00, 5441.48 examples/s]Extracting prompt in train dataset:  41%|████▏     | 3554/8564 [00:00<00:00, 5437.85 examples/s]Extracting prompt in train dataset:  45%|████▌     | 3891/8564 [00:00<00:00, 5496.25 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4112/8564 [00:00<00:00, 5482.87 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4111/8564 [00:00<00:00, 5473.61 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4453/8564 [00:00<00:00, 5533.62 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 4670/8564 [00:00<00:00, 5507.80 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 4670/8564 [00:00<00:00, 5502.20 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  59%|█████▊    | 5020/8564 [00:00<00:00, 5565.32 examples/s]Extracting prompt in train dataset:  61%|██████    | 5240/8564 [00:00<00:00, 5561.63 examples/s]Extracting prompt in train dataset:  61%|██████    | 5240/8564 [00:00<00:00, 5554.56 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 326.44 examples/s]Extracting prompt in train dataset:  65%|██████▌   | 5600/8564 [00:01<00:00, 5610.63 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5820/8564 [00:01<00:00, 5604.17 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5820/8564 [00:01<00:00, 5597.75 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 6180/8564 [00:01<00:00, 5641.80 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 295.57 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 6400/8564 [00:01<00:00, 5632.52 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 6390/8564 [00:01<00:00, 5626.90 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 6760/8564 [00:01<00:00, 5661.67 examples/s]Extracting prompt in train dataset:  81%|████████▏ | 6960/8564 [00:01<00:00, 5642.68 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 6980/8564 [00:01<00:00, 5655.20 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:03, 277.15 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 7340/8564 [00:01<00:00, 5676.23 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7540/8564 [00:01<00:00, 5657.15 examples/s]Extracting prompt in train dataset:  88%|████████▊ | 7560/8564 [00:01<00:00, 5668.50 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 267.39 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8120/8564 [00:01<00:00, 5460.28 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8310/8564 [00:01<00:00, 5426.60 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8330/8564 [00:01<00:00, 5432.86 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5506.28 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5480.29 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5470.79 examples/s]
Tokenizing eval dataset:  21%|██        | 198/953 [00:00<00:02, 258.75 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:00<00:02, 290.45 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:00<00:01, 385.09 examples/s]Tokenizing eval dataset:  39%|███▊      | 367/953 [00:01<00:01, 449.13 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  46%|████▌     | 436/953 [00:01<00:01, 513.59 examples/s]Applying chat template to train dataset:   3%|▎         | 288/8564 [00:00<00:02, 2847.13 examples/s]Applying chat template to train dataset:   3%|▎         | 287/8564 [00:00<00:02, 2835.75 examples/s]Applying chat template to train dataset:   3%|▎         | 286/8564 [00:00<00:02, 2827.36 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:01<00:00, 557.38 examples/s]Applying chat template to train dataset:   7%|▋         | 602/8564 [00:00<00:02, 3013.64 examples/s]Applying chat template to train dataset:   7%|▋         | 600/8564 [00:00<00:02, 2992.62 examples/s]Applying chat template to train dataset:   7%|▋         | 599/8564 [00:00<00:02, 3003.06 examples/s]Tokenizing eval dataset:  60%|█████▉    | 569/953 [00:01<00:00, 580.46 examples/s]Applying chat template to train dataset:  11%|█         | 919/8564 [00:00<00:02, 3077.37 examples/s]Applying chat template to train dataset:  11%|█         | 913/8564 [00:00<00:02, 3050.49 examples/s]Applying chat template to train dataset:  11%|█         | 912/8564 [00:00<00:02, 3056.05 examples/s]Applying chat template to train dataset:  14%|█▍        | 1235/8564 [00:00<00:02, 3107.84 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:01<00:00, 606.22 examples/s]Applying chat template to train dataset:  14%|█▍        | 1228/8564 [00:00<00:02, 3082.67 examples/s]Applying chat template to train dataset:  14%|█▍        | 1229/8564 [00:00<00:02, 3092.44 examples/s]Applying chat template to train dataset:  18%|█▊        | 1547/8564 [00:00<00:02, 3109.98 examples/s]Applying chat template to train dataset:  18%|█▊        | 1537/8564 [00:00<00:02, 3081.25 examples/s]Applying chat template to train dataset:  18%|█▊        | 1539/8564 [00:00<00:02, 3091.64 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 596.86 examples/s]Applying chat template to train dataset:  22%|██▏       | 1864/8564 [00:00<00:02, 3127.07 examples/s]Applying chat template to train dataset:  22%|██▏       | 1851/8564 [00:00<00:02, 3099.11 examples/s]Applying chat template to train dataset:  22%|██▏       | 1854/8564 [00:00<00:02, 3108.36 examples/s]Applying chat template to train dataset:  26%|██▌       | 2184/8564 [00:00<00:02, 3146.98 examples/s]Applying chat template to train dataset:  25%|██▌       | 2169/8564 [00:00<00:02, 3119.87 examples/s]Applying chat template to train dataset:  25%|██▌       | 2170/8564 [00:00<00:02, 3124.40 examples/s]Tokenizing eval dataset:  85%|████████▍ | 807/953 [00:01<00:00, 562.08 examples/s]Applying chat template to train dataset:  29%|██▉       | 2503/8564 [00:00<00:01, 3156.82 examples/s]Applying chat template to train dataset:  29%|██▉       | 2484/8564 [00:00<00:01, 3126.94 examples/s]Applying chat template to train dataset:  29%|██▉       | 2488/8564 [00:00<00:01, 3138.02 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:01<00:00, 540.93 examples/s]Applying chat template to train dataset:  33%|███▎      | 2823/8564 [00:00<00:01, 3165.47 examples/s]Applying chat template to train dataset:  33%|███▎      | 2800/8564 [00:00<00:01, 3132.86 examples/s]Applying chat template to train dataset:  33%|███▎      | 2804/8564 [00:00<00:01, 3143.73 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 529.35 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 462.33 examples/s]
Applying chat template to train dataset:  38%|███▊      | 3284/8564 [00:01<00:01, 3123.66 examples/s]Applying chat template to train dataset:  38%|███▊      | 3255/8564 [00:01<00:01, 3089.90 examples/s]Applying chat template to train dataset:  38%|███▊      | 3260/8564 [00:01<00:01, 3098.92 examples/s]Applying chat template to train dataset:  42%|████▏     | 3601/8564 [00:01<00:01, 3134.89 examples/s]Applying chat template to train dataset:  42%|████▏     | 3570/8564 [00:01<00:01, 3100.79 examples/s]Applying chat template to train dataset:  42%|████▏     | 3575/8564 [00:01<00:01, 3112.17 examples/s]Applying chat template to train dataset:  46%|████▌     | 3920/8564 [00:01<00:01, 3142.64 examples/s]Applying chat template to train dataset:  45%|████▌     | 3885/8564 [00:01<00:01, 3112.12 examples/s]Applying chat template to train dataset:  45%|████▌     | 3890/8564 [00:01<00:01, 3118.62 examples/s]Applying chat template to train dataset:  50%|████▉     | 4240/8564 [00:01<00:01, 3150.11 examples/s]Applying chat template to train dataset:  49%|████▉     | 4200/8564 [00:01<00:01, 3117.22 examples/s]Applying chat template to train dataset:  49%|████▉     | 4206/8564 [00:01<00:01, 3128.80 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4560/8564 [00:01<00:01, 3156.72 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4515/8564 [00:01<00:01, 3124.03 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4521/8564 [00:01<00:01, 3132.39 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4880/8564 [00:01<00:01, 3162.67 examples/s]Applying chat template to train dataset:  56%|█████▋    | 4830/8564 [00:01<00:01, 3124.92 examples/s]Applying chat template to train dataset:  56%|█████▋    | 4837/8564 [00:01<00:01, 3137.33 examples/s]Applying chat template to train dataset:  61%|██████    | 5206/8564 [00:01<00:01, 3188.88 examples/s]Applying chat template to train dataset:  60%|██████    | 5152/8564 [00:01<00:01, 3149.92 examples/s]Applying chat template to train dataset:  60%|██████    | 5160/8564 [00:01<00:01, 3158.73 examples/s]Applying chat template to train dataset:  65%|██████▍   | 5530/8564 [00:01<00:00, 3200.05 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5473/8564 [00:01<00:00, 3167.23 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5482/8564 [00:01<00:00, 3173.86 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5855/8564 [00:01<00:00, 3214.25 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5796/8564 [00:01<00:00, 3183.04 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5808/8564 [00:01<00:00, 3197.27 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6180/8564 [00:01<00:00, 3221.64 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6118/8564 [00:01<00:00, 3191.89 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6130/8564 [00:01<00:00, 3198.73 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6506/8564 [00:02<00:00, 3230.48 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6440/8564 [00:02<00:00, 3196.94 examples/s]Applying chat template to train dataset:  75%|███████▌  | 6454/8564 [00:02<00:00, 3209.67 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6830/8564 [00:02<00:00, 3230.32 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6763/8564 [00:02<00:00, 3202.48 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6776/8564 [00:02<00:00, 3212.08 examples/s]Applying chat template to train dataset:  84%|████████▎ | 7154/8564 [00:02<00:00, 3232.80 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7085/8564 [00:02<00:00, 3205.51 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7098/8564 [00:02<00:00, 3211.89 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7480/8564 [00:02<00:00, 3234.82 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7408/8564 [00:02<00:00, 3209.43 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7423/8564 [00:02<00:00, 3216.03 examples/s]Applying chat template to train dataset:  90%|█████████ | 7730/8564 [00:02<00:00, 3207.00 examples/s]Applying chat template to train dataset:  90%|█████████ | 7748/8564 [00:02<00:00, 3222.17 examples/s]Applying chat template to train dataset:  93%|█████████▎| 7926/8564 [00:02<00:00, 3129.28 examples/s]Applying chat template to train dataset:  96%|█████████▋| 8250/8564 [00:02<00:00, 3157.91 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8162/8564 [00:02<00:00, 3075.23 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8180/8564 [00:02<00:00, 3084.68 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3156.12 examples/s]
Applying chat template to train dataset:  99%|█████████▉| 8486/8564 [00:02<00:00, 3116.57 examples/s]Applying chat template to train dataset:  99%|█████████▉| 8503/8564 [00:02<00:00, 3121.83 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3131.91 examples/s]
Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3123.21 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:21, 403.45 examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:21, 403.97 examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:21, 405.37 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:25, 338.43 examples/s]Tokenizing train dataset:   1%|          | 92/8564 [00:00<00:30, 281.99 examples/s]Tokenizing train dataset:   1%|          | 92/8564 [00:00<00:29, 285.59 examples/s]Tokenizing train dataset:   2%|▏         | 138/8564 [00:00<00:26, 318.39 examples/s]Tokenizing train dataset:   2%|▏         | 136/8564 [00:00<00:29, 284.00 examples/s]Tokenizing train dataset:   2%|▏         | 138/8564 [00:00<00:28, 291.48 examples/s]Tokenizing train dataset:   2%|▏         | 182/8564 [00:00<00:27, 299.91 examples/s]Tokenizing train dataset:   2%|▏         | 167/8564 [00:00<00:29, 288.27 examples/s]Tokenizing train dataset:   2%|▏         | 182/8564 [00:00<00:29, 286.92 examples/s]Tokenizing train dataset:   3%|▎         | 217/8564 [00:00<00:26, 310.05 examples/s]Tokenizing train dataset:   2%|▏         | 199/8564 [00:00<00:28, 291.26 examples/s]Tokenizing train dataset:   3%|▎         | 217/8564 [00:00<00:27, 300.61 examples/s]Tokenizing train dataset:   3%|▎         | 251/8564 [00:00<00:26, 314.00 examples/s]Tokenizing train dataset:   3%|▎         | 236/8564 [00:00<00:26, 309.41 examples/s]Tokenizing train dataset:   3%|▎         | 251/8564 [00:00<00:27, 307.18 examples/s]Tokenizing train dataset:   3%|▎         | 289/8564 [00:00<00:25, 330.40 examples/s]Tokenizing train dataset:   3%|▎         | 272/8564 [00:00<00:25, 321.42 examples/s]Tokenizing train dataset:   3%|▎         | 289/8564 [00:00<00:25, 325.36 examples/s]Tokenizing train dataset:   4%|▎         | 305/8564 [00:00<00:25, 321.14 examples/s]Tokenizing train dataset:   4%|▍         | 337/8564 [00:01<00:25, 323.65 examples/s]Tokenizing train dataset:   4%|▍         | 337/8564 [00:01<00:25, 320.14 examples/s]Tokenizing train dataset:   4%|▍         | 351/8564 [00:01<00:26, 313.90 examples/s]Tokenizing train dataset:   5%|▍         | 387/8564 [00:01<00:25, 322.21 examples/s]Tokenizing train dataset:   5%|▍         | 387/8564 [00:01<00:25, 320.35 examples/s]Tokenizing train dataset:   5%|▍         | 387/8564 [00:01<00:25, 321.65 examples/s]Tokenizing train dataset:   5%|▌         | 434/8564 [00:01<00:25, 314.08 examples/s]Tokenizing train dataset:   5%|▌         | 434/8564 [00:01<00:25, 313.22 examples/s]Tokenizing train dataset:   5%|▌         | 434/8564 [00:01<00:25, 313.66 examples/s]Tokenizing train dataset:   6%|▌         | 480/8564 [00:01<00:26, 307.86 examples/s]Tokenizing train dataset:   6%|▌         | 480/8564 [00:01<00:26, 307.68 examples/s]Tokenizing train dataset:   6%|▌         | 480/8564 [00:01<00:26, 307.31 examples/s]Tokenizing train dataset:   6%|▌         | 527/8564 [00:01<00:26, 307.24 examples/s]Tokenizing train dataset:   6%|▌         | 527/8564 [00:01<00:26, 307.37 examples/s]Tokenizing train dataset:   6%|▌         | 527/8564 [00:01<00:26, 306.85 examples/s]Tokenizing train dataset:   7%|▋         | 561/8564 [00:01<00:25, 312.10 examples/s]Tokenizing train dataset:   7%|▋         | 561/8564 [00:01<00:25, 312.89 examples/s]Tokenizing train dataset:   7%|▋         | 561/8564 [00:01<00:25, 311.82 examples/s]Tokenizing train dataset:   7%|▋         | 605/8564 [00:01<00:26, 301.62 examples/s]Tokenizing train dataset:   7%|▋         | 605/8564 [00:01<00:26, 302.47 examples/s]Tokenizing train dataset:   7%|▋         | 605/8564 [00:01<00:26, 301.29 examples/s]Tokenizing train dataset:   8%|▊         | 644/8564 [00:02<00:24, 319.01 examples/s]Tokenizing train dataset:   8%|▊         | 644/8564 [00:02<00:24, 320.24 examples/s]Tokenizing train dataset:   8%|▊         | 644/8564 [00:02<00:24, 318.70 examples/s]Tokenizing train dataset:   8%|▊         | 690/8564 [00:02<00:25, 308.21 examples/s]Tokenizing train dataset:   8%|▊         | 689/8564 [00:02<00:25, 312.10 examples/s]Tokenizing train dataset:   8%|▊         | 689/8564 [00:02<00:25, 310.73 examples/s]Tokenizing train dataset:   8%|▊         | 722/8564 [00:02<00:25, 309.10 examples/s]Tokenizing train dataset:   9%|▉         | 759/8564 [00:02<00:24, 318.10 examples/s]Tokenizing train dataset:   9%|▊         | 740/8564 [00:02<00:24, 318.17 examples/s]Tokenizing train dataset:   9%|▊         | 740/8564 [00:02<00:24, 316.94 examples/s]Tokenizing train dataset:   9%|▉         | 785/8564 [00:02<00:25, 308.40 examples/s]Tokenizing train dataset:   9%|▉         | 802/8564 [00:02<00:25, 300.42 examples/s]Tokenizing train dataset:   9%|▉         | 785/8564 [00:02<00:25, 307.54 examples/s]Tokenizing train dataset:  10%|▉         | 847/8564 [00:02<00:25, 297.19 examples/s]Tokenizing train dataset:  10%|▉         | 827/8564 [00:02<00:26, 294.43 examples/s]Tokenizing train dataset:  10%|▉         | 827/8564 [00:02<00:26, 294.36 examples/s]Tokenizing train dataset:  10%|█         | 879/8564 [00:02<00:25, 297.77 examples/s]Tokenizing train dataset:  10%|█         | 860/8564 [00:02<00:25, 299.60 examples/s]Tokenizing train dataset:  10%|█         | 860/8564 [00:02<00:25, 299.78 examples/s]Tokenizing train dataset:  11%|█         | 916/8564 [00:02<00:24, 314.81 examples/s]Tokenizing train dataset:  10%|█         | 897/8564 [00:02<00:24, 315.07 examples/s]Tokenizing train dataset:  10%|█         | 897/8564 [00:02<00:24, 315.63 examples/s]Tokenizing train dataset:  11%|█         | 942/8564 [00:03<00:25, 304.69 examples/s]Tokenizing train dataset:  11%|█         | 962/8564 [00:03<00:24, 305.46 examples/s]Tokenizing train dataset:  11%|█         | 942/8564 [00:03<00:24, 305.24 examples/s]Tokenizing train dataset:  12%|█▏        | 986/8564 [00:03<00:25, 296.60 examples/s]Tokenizing train dataset:  12%|█▏        | 986/8564 [00:03<00:25, 297.18 examples/s]Tokenizing train dataset:  12%|█▏        | 1007/8564 [00:03<00:25, 297.57 examples/s]Tokenizing train dataset:  12%|█▏        | 1017/8564 [00:03<00:25, 294.57 examples/s]Tokenizing train dataset:  12%|█▏        | 1017/8564 [00:03<00:25, 295.19 examples/s]Tokenizing train dataset:  12%|█▏        | 1049/8564 [00:03<00:25, 290.55 examples/s]Tokenizing train dataset:  13%|█▎        | 1082/8564 [00:03<00:25, 298.90 examples/s]Tokenizing train dataset:  12%|█▏        | 1062/8564 [00:03<00:25, 290.61 examples/s]Tokenizing train dataset:  12%|█▏        | 1062/8564 [00:03<00:25, 291.02 examples/s]Tokenizing train dataset:  13%|█▎        | 1117/8564 [00:03<00:24, 306.20 examples/s]Tokenizing train dataset:  13%|█▎        | 1098/8564 [00:03<00:24, 304.94 examples/s]Tokenizing train dataset:  13%|█▎        | 1098/8564 [00:03<00:24, 305.25 examples/s]Tokenizing train dataset:  14%|█▎        | 1159/8564 [00:03<00:25, 291.90 examples/s]Tokenizing train dataset:  13%|█▎        | 1141/8564 [00:03<00:25, 295.16 examples/s]Tokenizing train dataset:  13%|█▎        | 1141/8564 [00:03<00:25, 295.36 examples/s]Tokenizing train dataset:  14%|█▍        | 1191/8564 [00:03<00:24, 296.97 examples/s]Tokenizing train dataset:  14%|█▍        | 1190/8564 [00:03<00:24, 297.68 examples/s]Tokenizing train dataset:  14%|█▍        | 1190/8564 [00:03<00:24, 297.62 examples/s]Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:03<00:24, 298.00 examples/s]Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:04<00:24, 299.43 examples/s]Tokenizing train dataset:  14%|█▍        | 1222/8564 [00:04<00:24, 299.30 examples/s]Tokenizing train dataset:  15%|█▍        | 1258/8564 [00:04<00:23, 313.50 examples/s]Tokenizing train dataset:  15%|█▍        | 1259/8564 [00:04<00:23, 313.64 examples/s]Tokenizing train dataset:  15%|█▍        | 1259/8564 [00:04<00:23, 313.43 examples/s]Tokenizing train dataset:  15%|█▌        | 1310/8564 [00:04<00:22, 316.52 examples/s]Tokenizing train dataset:  15%|█▌        | 1310/8564 [00:04<00:22, 316.52 examples/s]Tokenizing train dataset:  15%|█▌        | 1310/8564 [00:04<00:22, 316.24 examples/s]Tokenizing train dataset:  16%|█▌        | 1342/8564 [00:04<00:22, 315.22 examples/s]Tokenizing train dataset:  16%|█▌        | 1342/8564 [00:04<00:22, 315.26 examples/s]Tokenizing train dataset:  16%|█▌        | 1342/8564 [00:04<00:22, 315.19 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:04<00:23, 300.20 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:04<00:23, 301.22 examples/s]Tokenizing train dataset:  16%|█▌        | 1386/8564 [00:04<00:23, 301.37 examples/s]Tokenizing train dataset:  17%|█▋        | 1418/8564 [00:04<00:23, 300.57 examples/s]Tokenizing train dataset:  17%|█▋        | 1418/8564 [00:04<00:23, 301.35 examples/s]Tokenizing train dataset:  17%|█▋        | 1418/8564 [00:04<00:23, 301.68 examples/s]Tokenizing train dataset:  17%|█▋        | 1462/8564 [00:04<00:24, 293.41 examples/s]Tokenizing train dataset:  17%|█▋        | 1462/8564 [00:04<00:24, 294.41 examples/s]Tokenizing train dataset:  17%|█▋        | 1462/8564 [00:04<00:24, 294.81 examples/s]Tokenizing train dataset:  17%|█▋        | 1492/8564 [00:04<00:24, 293.59 examples/s]Tokenizing train dataset:  17%|█▋        | 1492/8564 [00:04<00:24, 294.39 examples/s]Tokenizing train dataset:  17%|█▋        | 1492/8564 [00:04<00:23, 294.75 examples/s]Tokenizing train dataset:  18%|█▊        | 1539/8564 [00:05<00:23, 296.35 examples/s]Tokenizing train dataset:  18%|█▊        | 1539/8564 [00:05<00:23, 297.54 examples/s]Tokenizing train dataset:  18%|█▊        | 1539/8564 [00:05<00:23, 297.43 examples/s]Tokenizing train dataset:  18%|█▊        | 1570/8564 [00:05<00:23, 293.77 examples/s]Tokenizing train dataset:  18%|█▊        | 1570/8564 [00:05<00:23, 295.19 examples/s]Tokenizing train dataset:  18%|█▊        | 1570/8564 [00:05<00:23, 294.95 examples/s]Tokenizing train dataset:  19%|█▊        | 1601/8564 [00:05<00:23, 293.18 examples/s]Tokenizing train dataset:  19%|█▊        | 1601/8564 [00:05<00:23, 294.80 examples/s]Tokenizing train dataset:  19%|█▊        | 1601/8564 [00:05<00:23, 294.38 examples/s]Tokenizing train dataset:  19%|█▉        | 1637/8564 [00:05<00:22, 305.87 examples/s]Tokenizing train dataset:  19%|█▉        | 1637/8564 [00:05<00:22, 307.50 examples/s]Tokenizing train dataset:  19%|█▉        | 1637/8564 [00:05<00:22, 306.95 examples/s]Tokenizing train dataset:  20%|█▉        | 1672/8564 [00:05<00:21, 316.06 examples/s]Tokenizing train dataset:  20%|█▉        | 1672/8564 [00:05<00:21, 317.75 examples/s]Tokenizing train dataset:  20%|█▉        | 1672/8564 [00:05<00:21, 317.29 examples/s]Tokenizing train dataset:  20%|██        | 1714/8564 [00:05<00:20, 336.62 examples/s]Tokenizing train dataset:  20%|██        | 1714/8564 [00:05<00:20, 338.75 examples/s]Tokenizing train dataset:  20%|██        | 1714/8564 [00:05<00:20, 338.25 examples/s]Tokenizing train dataset:  21%|██        | 1766/8564 [00:05<00:20, 334.24 examples/s]Tokenizing train dataset:  21%|██        | 1766/8564 [00:05<00:20, 336.29 examples/s]Tokenizing train dataset:  21%|██        | 1766/8564 [00:05<00:20, 335.41 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:05<00:21, 320.59 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:05<00:20, 322.68 examples/s]Tokenizing train dataset:  21%|██        | 1814/8564 [00:05<00:20, 321.76 examples/s]Tokenizing train dataset:  22%|██▏       | 1848/8564 [00:05<00:21, 318.89 examples/s]Tokenizing train dataset:  22%|██▏       | 1848/8564 [00:06<00:20, 320.92 examples/s]Tokenizing train dataset:  22%|██▏       | 1848/8564 [00:06<00:20, 320.07 examples/s]Tokenizing train dataset:  22%|██▏       | 1893/8564 [00:06<00:21, 306.90 examples/s]Tokenizing train dataset:  22%|██▏       | 1893/8564 [00:06<00:21, 308.69 examples/s]Tokenizing train dataset:  22%|██▏       | 1893/8564 [00:06<00:21, 308.10 examples/s]Tokenizing train dataset:  23%|██▎       | 1938/8564 [00:06<00:19, 339.32 examples/s]Tokenizing train dataset:  23%|██▎       | 1938/8564 [00:06<00:19, 341.07 examples/s]Tokenizing train dataset:  23%|██▎       | 1938/8564 [00:06<00:19, 340.55 examples/s]Tokenizing train dataset:  23%|██▎       | 1974/8564 [00:06<00:19, 342.05 examples/s]Tokenizing train dataset:  23%|██▎       | 1975/8564 [00:06<00:19, 344.35 examples/s]Tokenizing train dataset:  23%|██▎       | 1975/8564 [00:06<00:19, 344.10 examples/s]Tokenizing train dataset:  23%|██▎       | 2011/8564 [00:06<00:18, 347.24 examples/s]Tokenizing train dataset:  23%|██▎       | 2012/8564 [00:06<00:18, 350.04 examples/s]Tokenizing train dataset:  23%|██▎       | 2012/8564 [00:06<00:18, 349.91 examples/s]Tokenizing train dataset:  24%|██▍       | 2050/8564 [00:06<00:18, 356.87 examples/s]Tokenizing train dataset:  24%|██▍       | 2051/8564 [00:06<00:18, 356.99 examples/s]Tokenizing train dataset:  24%|██▍       | 2051/8564 [00:06<00:18, 356.70 examples/s]Tokenizing train dataset:  24%|██▍       | 2088/8564 [00:06<00:18, 359.53 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:06<00:18, 358.55 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:06<00:18, 358.22 examples/s]Tokenizing train dataset:  25%|██▍       | 2128/8564 [00:06<00:17, 367.16 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:06<00:17, 366.13 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:06<00:17, 365.79 examples/s]Tokenizing train dataset:  25%|██▌       | 2180/8564 [00:06<00:17, 359.01 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:06<00:17, 361.86 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:06<00:17, 361.89 examples/s]Tokenizing train dataset:  26%|██▌       | 2217/8564 [00:07<00:17, 359.83 examples/s]Tokenizing train dataset:  26%|██▌       | 2224/8564 [00:07<00:17, 366.06 examples/s]Tokenizing train dataset:  26%|██▌       | 2224/8564 [00:07<00:17, 366.31 examples/s]Tokenizing train dataset:  26%|██▋       | 2256/8564 [00:07<00:17, 366.55 examples/s]Tokenizing train dataset:  27%|██▋       | 2299/8564 [00:07<00:16, 380.23 examples/s]Tokenizing train dataset:  27%|██▋       | 2284/8564 [00:07<00:16, 376.36 examples/s]Tokenizing train dataset:  27%|██▋       | 2284/8564 [00:07<00:16, 376.89 examples/s]Tokenizing train dataset:  27%|██▋       | 2348/8564 [00:07<00:17, 356.25 examples/s]Tokenizing train dataset:  27%|██▋       | 2336/8564 [00:07<00:17, 364.13 examples/s]Tokenizing train dataset:  27%|██▋       | 2336/8564 [00:07<00:17, 364.13 examples/s]Tokenizing train dataset:  28%|██▊       | 2386/8564 [00:07<00:17, 359.93 examples/s]Tokenizing train dataset:  28%|██▊       | 2391/8564 [00:07<00:17, 362.34 examples/s]Tokenizing train dataset:  28%|██▊       | 2393/8564 [00:07<00:17, 361.86 examples/s]Tokenizing train dataset:  28%|██▊       | 2427/8564 [00:07<00:16, 370.64 examples/s]Tokenizing train dataset:  28%|██▊       | 2430/8564 [00:07<00:16, 367.18 examples/s]Tokenizing train dataset:  28%|██▊       | 2434/8564 [00:07<00:16, 368.46 examples/s]Tokenizing train dataset:  29%|██▉       | 2466/8564 [00:07<00:16, 371.31 examples/s]Tokenizing train dataset:  29%|██▉       | 2470/8564 [00:07<00:16, 370.95 examples/s]Tokenizing train dataset:  29%|██▉       | 2473/8564 [00:07<00:16, 371.15 examples/s]Tokenizing train dataset:  29%|██▉       | 2515/8564 [00:07<00:17, 354.02 examples/s]Tokenizing train dataset:  29%|██▉       | 2523/8564 [00:07<00:16, 359.76 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:07<00:16, 364.24 examples/s]Tokenizing train dataset:  30%|██▉       | 2558/8564 [00:07<00:16, 372.95 examples/s]Tokenizing train dataset:  30%|██▉       | 2565/8564 [00:07<00:16, 371.76 examples/s]Tokenizing train dataset:  30%|███       | 2572/8564 [00:07<00:15, 375.41 examples/s]Tokenizing train dataset:  30%|███       | 2596/8564 [00:08<00:16, 371.64 examples/s]Tokenizing train dataset:  30%|███       | 2604/8564 [00:08<00:16, 372.40 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:08<00:16, 351.65 examples/s]Tokenizing train dataset:  31%|███       | 2643/8564 [00:08<00:17, 346.74 examples/s]Tokenizing train dataset:  31%|███       | 2653/8564 [00:08<00:17, 339.29 examples/s]Tokenizing train dataset:  31%|███       | 2670/8564 [00:08<00:17, 343.36 examples/s]Tokenizing train dataset:  31%|███▏      | 2693/8564 [00:08<00:17, 336.93 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:08<00:17, 343.56 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:08<00:17, 340.28 examples/s]Tokenizing train dataset:  32%|███▏      | 2731/8564 [00:08<00:16, 344.90 examples/s]Tokenizing train dataset:  32%|███▏      | 2740/8564 [00:08<00:17, 341.11 examples/s]Tokenizing train dataset:  32%|███▏      | 2740/8564 [00:08<00:17, 338.65 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:08<00:16, 344.71 examples/s]Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:08<00:16, 341.93 examples/s]Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:08<00:17, 340.01 examples/s]Tokenizing train dataset:  33%|███▎      | 2825/8564 [00:08<00:16, 356.21 examples/s]Tokenizing train dataset:  33%|███▎      | 2818/8564 [00:08<00:15, 365.12 examples/s]Tokenizing train dataset:  33%|███▎      | 2818/8564 [00:08<00:15, 362.98 examples/s]Tokenizing train dataset:  34%|███▎      | 2873/8564 [00:08<00:16, 339.85 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:08<00:16, 347.64 examples/s]Tokenizing train dataset:  33%|███▎      | 2868/8564 [00:08<00:16, 346.21 examples/s]Tokenizing train dataset:  34%|███▍      | 2919/8564 [00:08<00:15, 368.35 examples/s]Tokenizing train dataset:  34%|███▍      | 2911/8564 [00:08<00:15, 366.37 examples/s]Tokenizing train dataset:  34%|███▍      | 2911/8564 [00:08<00:15, 364.78 examples/s]Tokenizing train dataset:  35%|███▍      | 2960/8564 [00:09<00:15, 372.09 examples/s]Tokenizing train dataset:  34%|███▍      | 2953/8564 [00:09<00:14, 375.81 examples/s]Tokenizing train dataset:  34%|███▍      | 2953/8564 [00:09<00:14, 374.31 examples/s]Tokenizing train dataset:  35%|███▌      | 3005/8564 [00:09<00:14, 387.79 examples/s]Tokenizing train dataset:  35%|███▍      | 2997/8564 [00:09<00:14, 390.55 examples/s]Tokenizing train dataset:  35%|███▍      | 2997/8564 [00:09<00:14, 388.93 examples/s]Tokenizing train dataset:  36%|███▌      | 3057/8564 [00:09<00:15, 366.09 examples/s]Tokenizing train dataset:  36%|███▌      | 3050/8564 [00:09<00:14, 372.83 examples/s]Tokenizing train dataset:  36%|███▌      | 3050/8564 [00:09<00:14, 371.27 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:09<00:14, 370.26 examples/s]Tokenizing train dataset:  36%|███▋      | 3106/8564 [00:09<00:14, 368.79 examples/s]Tokenizing train dataset:  36%|███▋      | 3106/8564 [00:09<00:14, 367.48 examples/s]Tokenizing train dataset:  37%|███▋      | 3150/8564 [00:09<00:14, 362.49 examples/s]Tokenizing train dataset:  37%|███▋      | 3162/8564 [00:09<00:14, 366.76 examples/s]Tokenizing train dataset:  37%|███▋      | 3162/8564 [00:09<00:14, 365.75 examples/s]Tokenizing train dataset:  37%|███▋      | 3205/8564 [00:09<00:14, 361.23 examples/s]Tokenizing train dataset:  38%|███▊      | 3217/8564 [00:09<00:14, 362.54 examples/s]Tokenizing train dataset:  38%|███▊      | 3217/8564 [00:09<00:14, 361.66 examples/s]Tokenizing train dataset:  38%|███▊      | 3247/8564 [00:09<00:14, 371.94 examples/s]Tokenizing train dataset:  38%|███▊      | 3259/8564 [00:09<00:14, 373.76 examples/s]Tokenizing train dataset:  38%|███▊      | 3259/8564 [00:09<00:14, 373.10 examples/s]Tokenizing train dataset:  39%|███▊      | 3300/8564 [00:10<00:14, 359.15 examples/s]Tokenizing train dataset:  39%|███▊      | 3311/8564 [00:10<00:14, 360.03 examples/s]Tokenizing train dataset:  39%|███▊      | 3311/8564 [00:10<00:14, 359.62 examples/s]Tokenizing train dataset:  39%|███▉      | 3355/8564 [00:10<00:14, 355.87 examples/s]Tokenizing train dataset:  39%|███▉      | 3365/8564 [00:10<00:14, 355.41 examples/s]Tokenizing train dataset:  39%|███▉      | 3364/8564 [00:10<00:14, 354.68 examples/s]Tokenizing train dataset:  40%|███▉      | 3396/8564 [00:10<00:14, 367.09 examples/s]Tokenizing train dataset:  40%|███▉      | 3408/8564 [00:10<00:13, 371.61 examples/s]Tokenizing train dataset:  40%|███▉      | 3408/8564 [00:10<00:13, 371.24 examples/s]Tokenizing train dataset:  40%|████      | 3437/8564 [00:10<00:13, 373.55 examples/s]Tokenizing train dataset:  40%|████      | 3446/8564 [00:10<00:13, 371.11 examples/s]Tokenizing train dataset:  40%|████      | 3446/8564 [00:10<00:13, 370.67 examples/s]Tokenizing train dataset:  41%|████      | 3491/8564 [00:10<00:13, 364.06 examples/s]Tokenizing train dataset:  41%|████      | 3504/8564 [00:10<00:13, 372.04 examples/s]Tokenizing train dataset:  41%|████      | 3504/8564 [00:10<00:13, 371.61 examples/s]Tokenizing train dataset:  41%|████▏     | 3533/8564 [00:10<00:13, 375.07 examples/s]Tokenizing train dataset:  41%|████▏     | 3542/8564 [00:10<00:13, 371.78 examples/s]Tokenizing train dataset:  41%|████▏     | 3542/8564 [00:10<00:13, 371.02 examples/s]Tokenizing train dataset:  42%|████▏     | 3592/8564 [00:10<00:13, 371.42 examples/s]Tokenizing train dataset:  42%|████▏     | 3598/8564 [00:10<00:13, 370.95 examples/s]Tokenizing train dataset:  42%|████▏     | 3598/8564 [00:10<00:13, 370.54 examples/s]Tokenizing train dataset:  42%|████▏     | 3631/8564 [00:10<00:13, 372.37 examples/s]Tokenizing train dataset:  42%|████▏     | 3636/8564 [00:10<00:13, 369.72 examples/s]Tokenizing train dataset:  42%|████▏     | 3636/8564 [00:10<00:13, 369.33 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:11<00:13, 350.83 examples/s]Tokenizing train dataset:  43%|████▎     | 3688/8564 [00:11<00:13, 355.86 examples/s]Tokenizing train dataset:  43%|████▎     | 3688/8564 [00:11<00:13, 356.09 examples/s]Tokenizing train dataset:  43%|████▎     | 3724/8564 [00:11<00:13, 368.98 examples/s]Tokenizing train dataset:  44%|████▎     | 3727/8564 [00:11<00:13, 363.45 examples/s]Tokenizing train dataset:  44%|████▎     | 3727/8564 [00:11<00:13, 363.71 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:11<00:12, 368.00 examples/s]Tokenizing train dataset:  44%|████▍     | 3765/8564 [00:11<00:13, 365.27 examples/s]Tokenizing train dataset:  44%|████▍     | 3765/8564 [00:11<00:13, 365.46 examples/s]Tokenizing train dataset:  44%|████▍     | 3803/8564 [00:11<00:13, 364.66 examples/s]Tokenizing train dataset:  44%|████▍     | 3803/8564 [00:11<00:13, 364.84 examples/s]Tokenizing train dataset:  45%|████▍     | 3834/8564 [00:11<00:13, 362.58 examples/s]Tokenizing train dataset:  45%|████▍     | 3840/8564 [00:11<00:13, 358.48 examples/s]Tokenizing train dataset:  45%|████▍     | 3840/8564 [00:11<00:13, 358.46 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:11<00:12, 361.01 examples/s]Tokenizing train dataset:  45%|████▌     | 3877/8564 [00:11<00:13, 358.29 examples/s]Tokenizing train dataset:  45%|████▌     | 3877/8564 [00:11<00:13, 358.14 examples/s]Tokenizing train dataset:  46%|████▌     | 3940/8564 [00:11<00:13, 350.91 examples/s]Tokenizing train dataset:  46%|████▌     | 3928/8564 [00:11<00:13, 349.16 examples/s]Tokenizing train dataset:  46%|████▌     | 3928/8564 [00:11<00:13, 348.79 examples/s]Tokenizing train dataset:  46%|████▋     | 3978/8564 [00:11<00:13, 352.70 examples/s]Tokenizing train dataset:  46%|████▋     | 3964/8564 [00:11<00:13, 349.38 examples/s]Tokenizing train dataset:  46%|████▋     | 3964/8564 [00:11<00:13, 349.07 examples/s]Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:11<00:12, 354.96 examples/s]Tokenizing train dataset:  47%|████▋     | 4002/8564 [00:11<00:12, 353.09 examples/s]Tokenizing train dataset:  47%|████▋     | 4002/8564 [00:11<00:12, 352.35 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:12<00:12, 363.62 examples/s]Tokenizing train dataset:  47%|████▋     | 4042/8564 [00:12<00:12, 363.87 examples/s]Tokenizing train dataset:  47%|████▋     | 4042/8564 [00:12<00:12, 362.72 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:12<00:12, 362.37 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:12<00:12, 361.16 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:12<00:12, 358.06 examples/s]Tokenizing train dataset:  48%|████▊     | 4132/8564 [00:12<00:12, 354.00 examples/s]Tokenizing train dataset:  48%|████▊     | 4132/8564 [00:12<00:12, 353.24 examples/s]Tokenizing train dataset:  49%|████▊     | 4162/8564 [00:12<00:12, 350.73 examples/s]Tokenizing train dataset:  49%|████▊     | 4169/8564 [00:12<00:12, 352.35 examples/s]Tokenizing train dataset:  49%|████▊     | 4169/8564 [00:12<00:12, 351.60 examples/s]Tokenizing train dataset:  49%|████▉     | 4203/8564 [00:12<00:12, 360.97 examples/s]Tokenizing train dataset:  49%|████▉     | 4210/8564 [00:12<00:12, 360.37 examples/s]Tokenizing train dataset:  49%|████▉     | 4210/8564 [00:12<00:12, 360.00 examples/s]Tokenizing train dataset:  50%|████▉     | 4257/8564 [00:12<00:12, 355.92 examples/s]Tokenizing train dataset:  50%|████▉     | 4264/8564 [00:12<00:12, 355.55 examples/s]Tokenizing train dataset:  50%|████▉     | 4264/8564 [00:12<00:12, 355.20 examples/s]Tokenizing train dataset:  50%|█████     | 4293/8564 [00:12<00:12, 354.61 examples/s]Tokenizing train dataset:  50%|█████     | 4301/8564 [00:12<00:11, 356.45 examples/s]Tokenizing train dataset:  50%|█████     | 4301/8564 [00:12<00:11, 355.77 examples/s]Tokenizing train dataset:  51%|█████     | 4330/8564 [00:12<00:11, 354.95 examples/s]Tokenizing train dataset:  51%|█████     | 4337/8564 [00:12<00:11, 355.09 examples/s]Tokenizing train dataset:  51%|█████     | 4337/8564 [00:12<00:11, 354.35 examples/s]Tokenizing train dataset:  51%|█████     | 4386/8564 [00:13<00:11, 358.16 examples/s]Tokenizing train dataset:  51%|█████     | 4375/8564 [00:12<00:11, 357.30 examples/s]Tokenizing train dataset:  51%|█████     | 4373/8564 [00:12<00:11, 355.79 examples/s]Tokenizing train dataset:  52%|█████▏    | 4425/8564 [00:13<00:11, 361.38 examples/s]Tokenizing train dataset:  52%|█████▏    | 4413/8564 [00:13<00:11, 361.05 examples/s]Tokenizing train dataset:  52%|█████▏    | 4411/8564 [00:13<00:11, 359.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:13<00:11, 362.09 examples/s]Tokenizing train dataset:  52%|█████▏    | 4450/8564 [00:13<00:11, 361.13 examples/s]Tokenizing train dataset:  52%|█████▏    | 4482/8564 [00:13<00:11, 361.24 examples/s]Tokenizing train dataset:  52%|█████▏    | 4489/8564 [00:13<00:11, 365.43 examples/s]Tokenizing train dataset:  52%|█████▏    | 4488/8564 [00:13<00:11, 360.60 examples/s]Tokenizing train dataset:  53%|█████▎    | 4530/8564 [00:13<00:11, 344.86 examples/s]Tokenizing train dataset:  53%|█████▎    | 4540/8564 [00:13<00:11, 354.70 examples/s]Tokenizing train dataset:  53%|█████▎    | 4540/8564 [00:13<00:11, 348.58 examples/s]Tokenizing train dataset:  53%|█████▎    | 4569/8564 [00:13<00:11, 352.50 examples/s]Tokenizing train dataset:  54%|█████▎    | 4593/8564 [00:13<00:11, 349.18 examples/s]Tokenizing train dataset:  54%|█████▎    | 4593/8564 [00:13<00:11, 345.56 examples/s]Tokenizing train dataset:  54%|█████▍    | 4621/8564 [00:13<00:11, 348.34 examples/s]Tokenizing train dataset:  54%|█████▍    | 4630/8564 [00:13<00:11, 351.84 examples/s]Tokenizing train dataset:  54%|█████▍    | 4630/8564 [00:13<00:11, 349.24 examples/s]Tokenizing train dataset:  55%|█████▍    | 4668/8564 [00:13<00:11, 334.68 examples/s]Tokenizing train dataset:  55%|█████▍    | 4676/8564 [00:13<00:11, 334.60 examples/s]Tokenizing train dataset:  55%|█████▍    | 4675/8564 [00:13<00:11, 331.65 examples/s]Tokenizing train dataset:  55%|█████▌    | 4716/8564 [00:13<00:11, 325.05 examples/s]Tokenizing train dataset:  55%|█████▌    | 4722/8564 [00:14<00:11, 323.61 examples/s]Tokenizing train dataset:  55%|█████▌    | 4722/8564 [00:14<00:11, 322.04 examples/s]Tokenizing train dataset:  55%|█████▌    | 4749/8564 [00:14<00:11, 324.69 examples/s]Tokenizing train dataset:  56%|█████▌    | 4770/8564 [00:14<00:11, 319.17 examples/s]Tokenizing train dataset:  56%|█████▌    | 4770/8564 [00:14<00:11, 317.88 examples/s]Tokenizing train dataset:  56%|█████▌    | 4797/8564 [00:14<00:11, 320.94 examples/s]Tokenizing train dataset:  56%|█████▌    | 4810/8564 [00:14<00:11, 337.57 examples/s]Tokenizing train dataset:  56%|█████▌    | 4811/8564 [00:14<00:11, 337.54 examples/s]Tokenizing train dataset:  57%|█████▋    | 4861/8564 [00:14<00:09, 395.50 examples/s]Tokenizing train dataset:  57%|█████▋    | 4874/8564 [00:14<00:08, 410.16 examples/s]Tokenizing train dataset:  57%|█████▋    | 4874/8564 [00:14<00:09, 408.81 examples/s]Tokenizing train dataset:  57%|█████▋    | 4920/8564 [00:14<00:08, 439.59 examples/s]Tokenizing train dataset:  58%|█████▊    | 4936/8564 [00:14<00:07, 460.73 examples/s]Tokenizing train dataset:  58%|█████▊    | 4936/8564 [00:14<00:07, 459.57 examples/s]Tokenizing train dataset:  58%|█████▊    | 4984/8564 [00:14<00:07, 485.22 examples/s]Tokenizing train dataset:  58%|█████▊    | 4995/8564 [00:14<00:07, 495.02 examples/s]Tokenizing train dataset:  58%|█████▊    | 4995/8564 [00:14<00:07, 493.89 examples/s]Tokenizing train dataset:  59%|█████▉    | 5045/8564 [00:14<00:06, 514.50 examples/s]Tokenizing train dataset:  59%|█████▉    | 5059/8564 [00:14<00:06, 532.17 examples/s]Tokenizing train dataset:  59%|█████▉    | 5060/8564 [00:14<00:06, 530.56 examples/s]Tokenizing train dataset:  60%|█████▉    | 5112/8564 [00:14<00:06, 556.82 examples/s]Tokenizing train dataset:  60%|█████▉    | 5125/8564 [00:14<00:06, 566.03 examples/s]Tokenizing train dataset:  60%|█████▉    | 5126/8564 [00:14<00:06, 564.73 examples/s]Tokenizing train dataset:  61%|██████    | 5183/8564 [00:14<00:05, 596.38 examples/s]Tokenizing train dataset:  61%|██████    | 5197/8564 [00:14<00:05, 608.32 examples/s]Tokenizing train dataset:  61%|██████    | 5199/8564 [00:14<00:05, 609.90 examples/s]Tokenizing train dataset:  61%|██████▏   | 5258/8564 [00:14<00:05, 633.20 examples/s]Tokenizing train dataset:  62%|██████▏   | 5273/8564 [00:14<00:05, 643.26 examples/s]Tokenizing train dataset:  62%|██████▏   | 5272/8564 [00:15<00:05, 641.47 examples/s]Tokenizing train dataset:  62%|██████▏   | 5324/8564 [00:15<00:05, 635.64 examples/s]Tokenizing train dataset:  63%|██████▎   | 5365/8564 [00:15<00:05, 627.54 examples/s]Tokenizing train dataset:  63%|██████▎   | 5364/8564 [00:15<00:05, 626.01 examples/s]Tokenizing train dataset:  63%|██████▎   | 5410/8564 [00:15<00:05, 602.38 examples/s]Tokenizing train dataset:  64%|██████▎   | 5459/8564 [00:15<00:04, 622.67 examples/s]Tokenizing train dataset:  64%|██████▍   | 5475/8564 [00:15<00:05, 612.03 examples/s]Tokenizing train dataset:  64%|██████▎   | 5455/8564 [00:15<00:05, 616.86 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:15<00:04, 605.98 examples/s]Tokenizing train dataset:  65%|██████▍   | 5564/8564 [00:15<00:04, 600.79 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:15<00:04, 605.65 examples/s]Tokenizing train dataset:  66%|██████▌   | 5611/8564 [00:15<00:04, 613.47 examples/s]Tokenizing train dataset:  66%|██████▌   | 5635/8564 [00:15<00:04, 624.14 examples/s]Tokenizing train dataset:  66%|██████▌   | 5638/8564 [00:15<00:04, 601.38 examples/s]Tokenizing train dataset:  66%|██████▋   | 5677/8564 [00:15<00:04, 621.39 examples/s]Tokenizing train dataset:  67%|██████▋   | 5701/8564 [00:15<00:04, 631.59 examples/s]Tokenizing train dataset:  67%|██████▋   | 5703/8564 [00:15<00:04, 607.89 examples/s]Tokenizing train dataset:  67%|██████▋   | 5743/8564 [00:15<00:04, 625.47 examples/s]Tokenizing train dataset:  67%|██████▋   | 5772/8564 [00:15<00:04, 649.70 examples/s]Tokenizing train dataset:  67%|██████▋   | 5777/8564 [00:15<00:04, 638.11 examples/s]Tokenizing train dataset:  68%|██████▊   | 5822/8564 [00:15<00:04, 668.72 examples/s]Tokenizing train dataset:  68%|██████▊   | 5842/8564 [00:15<00:04, 654.30 examples/s]Tokenizing train dataset:  68%|██████▊   | 5843/8564 [00:15<00:04, 640.04 examples/s]Tokenizing train dataset:  69%|██████▉   | 5901/8564 [00:16<00:04, 613.31 examples/s]Tokenizing train dataset:  69%|██████▉   | 5928/8564 [00:16<00:04, 622.19 examples/s]Tokenizing train dataset:  69%|██████▉   | 5930/8564 [00:16<00:04, 614.12 examples/s]Tokenizing train dataset:  70%|██████▉   | 5971/8564 [00:16<00:04, 631.42 examples/s]Tokenizing train dataset:  70%|███████   | 6014/8564 [00:16<00:04, 598.70 examples/s]Tokenizing train dataset:  70%|███████   | 6015/8564 [00:16<00:04, 594.41 examples/s]Tokenizing train dataset:  71%|███████   | 6052/8564 [00:16<00:04, 593.75 examples/s]Tokenizing train dataset:  71%|███████   | 6099/8564 [00:16<00:04, 585.32 examples/s]Tokenizing train dataset:  71%|███████   | 6099/8564 [00:16<00:04, 581.54 examples/s]Tokenizing train dataset:  72%|███████▏  | 6148/8564 [00:16<00:04, 602.95 examples/s]Tokenizing train dataset:  72%|███████▏  | 6173/8564 [00:16<00:03, 621.50 examples/s]Tokenizing train dataset:  72%|███████▏  | 6174/8564 [00:16<00:03, 619.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 6222/8564 [00:16<00:03, 630.18 examples/s]Tokenizing train dataset:  73%|███████▎  | 6241/8564 [00:16<00:03, 634.27 examples/s]Tokenizing train dataset:  73%|███████▎  | 6242/8564 [00:16<00:03, 632.15 examples/s]Tokenizing train dataset:  73%|███████▎  | 6290/8564 [00:16<00:03, 641.96 examples/s]Tokenizing train dataset:  74%|███████▎  | 6306/8564 [00:16<00:03, 637.03 examples/s]Tokenizing train dataset:  74%|███████▍  | 6357/8564 [00:16<00:03, 645.95 examples/s]Tokenizing train dataset:  74%|███████▍  | 6377/8564 [00:16<00:03, 655.91 examples/s]Tokenizing train dataset:  74%|███████▍  | 6340/8564 [00:16<00:03, 635.43 examples/s]Tokenizing train dataset:  75%|███████▍  | 6409/8564 [00:16<00:03, 647.00 examples/s]Tokenizing train dataset:  75%|███████▌  | 6452/8564 [00:16<00:03, 638.70 examples/s]Tokenizing train dataset:  76%|███████▌  | 6469/8564 [00:16<00:03, 637.30 examples/s]Tokenizing train dataset:  76%|███████▌  | 6501/8564 [00:17<00:03, 623.43 examples/s]Tokenizing train dataset:  76%|███████▋  | 6541/8564 [00:17<00:03, 620.83 examples/s]Tokenizing train dataset:  77%|███████▋  | 6560/8564 [00:17<00:03, 618.51 examples/s]Tokenizing train dataset:  77%|███████▋  | 6565/8564 [00:17<00:03, 620.67 examples/s]Tokenizing train dataset:  77%|███████▋  | 6613/8564 [00:17<00:03, 568.24 examples/s]Tokenizing train dataset:  78%|███████▊  | 6640/8564 [00:17<00:03, 583.16 examples/s]Tokenizing train dataset:  78%|███████▊  | 6642/8564 [00:17<00:03, 579.00 examples/s]Tokenizing train dataset:  78%|███████▊  | 6679/8564 [00:17<00:03, 588.47 examples/s]Tokenizing train dataset:  78%|███████▊  | 6710/8564 [00:17<00:03, 609.27 examples/s]Tokenizing train dataset:  78%|███████▊  | 6713/8564 [00:17<00:03, 609.74 examples/s]Tokenizing train dataset:  79%|███████▉  | 6749/8564 [00:17<00:02, 612.68 examples/s]Tokenizing train dataset:  79%|███████▉  | 6775/8564 [00:17<00:02, 612.86 examples/s]Tokenizing train dataset:  79%|███████▉  | 6776/8564 [00:17<00:02, 611.24 examples/s]Tokenizing train dataset:  80%|███████▉  | 6835/8564 [00:17<00:02, 596.90 examples/s]Tokenizing train dataset:  80%|████████  | 6861/8564 [00:17<00:02, 595.69 examples/s]Tokenizing train dataset:  80%|████████  | 6865/8564 [00:17<00:02, 594.55 examples/s]Tokenizing train dataset:  81%|████████  | 6900/8564 [00:17<00:02, 606.21 examples/s]Tokenizing train dataset:  81%|████████  | 6932/8564 [00:17<00:02, 622.47 examples/s]Tokenizing train dataset:  81%|████████  | 6939/8564 [00:17<00:02, 626.61 examples/s]Tokenizing train dataset:  81%|████████▏ | 6965/8564 [00:17<00:02, 610.15 examples/s]Tokenizing train dataset:  82%|████████▏ | 7015/8564 [00:17<00:02, 590.20 examples/s]Tokenizing train dataset:  82%|████████▏ | 7019/8564 [00:17<00:02, 585.79 examples/s]Tokenizing train dataset:  82%|████████▏ | 7057/8564 [00:17<00:02, 599.39 examples/s]Tokenizing train dataset:  83%|████████▎ | 7080/8564 [00:17<00:02, 603.56 examples/s]Tokenizing train dataset:  83%|████████▎ | 7087/8564 [00:17<00:02, 607.47 examples/s]Tokenizing train dataset:  83%|████████▎ | 7123/8564 [00:18<00:02, 610.28 examples/s]Tokenizing train dataset:  83%|████████▎ | 7145/8564 [00:18<00:02, 613.79 examples/s]Tokenizing train dataset:  83%|████████▎ | 7150/8564 [00:18<00:02, 603.26 examples/s]Tokenizing train dataset:  84%|████████▍ | 7190/8564 [00:18<00:02, 622.06 examples/s]Tokenizing train dataset:  84%|████████▍ | 7213/8564 [00:18<00:02, 630.26 examples/s]Tokenizing train dataset:  84%|████████▍ | 7220/8564 [00:18<00:02, 617.79 examples/s]Tokenizing train dataset:  85%|████████▍ | 7279/8564 [00:18<00:02, 611.12 examples/s]Tokenizing train dataset:  85%|████████▌ | 7296/8564 [00:18<00:02, 599.14 examples/s]Tokenizing train dataset:  85%|████████▌ | 7310/8564 [00:18<00:02, 607.71 examples/s]Tokenizing train dataset:  86%|████████▌ | 7361/8564 [00:18<00:01, 610.84 examples/s]Tokenizing train dataset:  86%|████████▌ | 7376/8564 [00:18<00:01, 612.84 examples/s]Tokenizing train dataset:  86%|████████▌ | 7374/8564 [00:18<00:01, 614.71 examples/s]Tokenizing train dataset:  87%|████████▋ | 7460/8564 [00:18<00:01, 623.88 examples/s]Tokenizing train dataset:  87%|████████▋ | 7442/8564 [00:18<00:01, 623.46 examples/s]Tokenizing train dataset:  87%|████████▋ | 7438/8564 [00:18<00:01, 617.48 examples/s]Tokenizing train dataset:  88%|████████▊ | 7504/8564 [00:18<00:01, 619.68 examples/s]Tokenizing train dataset:  88%|████████▊ | 7555/8564 [00:18<00:01, 625.50 examples/s]Tokenizing train dataset:  88%|████████▊ | 7538/8564 [00:18<00:01, 626.47 examples/s]Tokenizing train dataset:  88%|████████▊ | 7575/8564 [00:18<00:01, 642.58 examples/s]Tokenizing train dataset:  89%|████████▉ | 7627/8564 [00:18<00:01, 642.57 examples/s]Tokenizing train dataset:  89%|████████▉ | 7609/8564 [00:18<00:01, 641.20 examples/s]Tokenizing train dataset:  89%|████████▉ | 7663/8564 [00:18<00:01, 615.07 examples/s]Tokenizing train dataset:  90%|█████████ | 7710/8564 [00:18<00:01, 606.89 examples/s]Tokenizing train dataset:  90%|████████▉ | 7695/8564 [00:18<00:01, 609.03 examples/s]Tokenizing train dataset:  91%|█████████ | 7753/8564 [00:19<00:01, 596.88 examples/s]Tokenizing train dataset:  91%|█████████ | 7791/8564 [00:19<00:01, 582.09 examples/s]Tokenizing train dataset:  91%|█████████ | 7780/8564 [00:19<00:01, 591.27 examples/s]Tokenizing train dataset:  92%|█████████▏| 7853/8564 [00:19<00:01, 588.71 examples/s]Tokenizing train dataset:  92%|█████████▏| 7839/8564 [00:19<00:01, 584.84 examples/s]Tokenizing train dataset:  92%|█████████▏| 7868/8564 [00:19<00:01, 588.67 examples/s]Tokenizing train dataset:  92%|█████████▏| 7914/8564 [00:19<00:01, 589.40 examples/s]Tokenizing train dataset:  92%|█████████▏| 7901/8564 [00:19<00:01, 587.75 examples/s]Tokenizing train dataset:  93%|█████████▎| 7930/8564 [00:19<00:01, 590.98 examples/s]Tokenizing train dataset:  93%|█████████▎| 7975/8564 [00:19<00:01, 587.20 examples/s]Tokenizing train dataset:  93%|█████████▎| 7994/8564 [00:19<00:00, 599.42 examples/s]Tokenizing train dataset:  93%|█████████▎| 7994/8564 [00:19<00:00, 596.02 examples/s]Tokenizing train dataset:  94%|█████████▍| 8040/8564 [00:19<00:00, 602.96 examples/s]Tokenizing train dataset:  94%|█████████▍| 8055/8564 [00:19<00:00, 600.12 examples/s]Tokenizing train dataset:  94%|█████████▍| 8055/8564 [00:19<00:00, 597.26 examples/s]Tokenizing train dataset:  95%|█████████▍| 8121/8564 [00:19<00:00, 572.92 examples/s]Tokenizing train dataset:  95%|█████████▌| 8140/8564 [00:19<00:00, 579.62 examples/s]Tokenizing train dataset:  95%|█████████▌| 8140/8564 [00:19<00:00, 578.21 examples/s]Tokenizing train dataset:  96%|█████████▌| 8187/8564 [00:19<00:00, 593.77 examples/s]Tokenizing train dataset:  96%|█████████▌| 8204/8564 [00:19<00:00, 589.33 examples/s]Tokenizing train dataset:  96%|█████████▋| 8250/8564 [00:19<00:00, 600.07 examples/s]Tokenizing train dataset:  96%|█████████▌| 8204/8564 [00:19<00:00, 586.95 examples/s]Tokenizing train dataset:  97%|█████████▋| 8275/8564 [00:19<00:00, 618.04 examples/s]Tokenizing train dataset:  97%|█████████▋| 8274/8564 [00:19<00:00, 614.21 examples/s]Tokenizing train dataset:  97%|█████████▋| 8326/8564 [00:19<00:00, 635.69 examples/s]Tokenizing train dataset:  97%|█████████▋| 8340/8564 [00:20<00:00, 621.77 examples/s]Tokenizing train dataset:  97%|█████████▋| 8339/8564 [00:20<00:00, 621.60 examples/s]Tokenizing train dataset:  98%|█████████▊| 8405/8564 [00:20<00:00, 593.06 examples/s]Tokenizing train dataset:  98%|█████████▊| 8428/8564 [00:20<00:00, 605.25 examples/s]Tokenizing train dataset:  98%|█████████▊| 8425/8564 [00:20<00:00, 598.13 examples/s]Tokenizing train dataset:  99%|█████████▉| 8497/8564 [00:20<00:00, 596.41 examples/s]Tokenizing train dataset:  99%|█████████▉| 8487/8564 [00:20<00:00, 597.55 examples/s]Tokenizing train dataset:  99%|█████████▉| 8519/8564 [00:20<00:00, 601.80 examples/s]Tokenizing train dataset: 100%|█████████▉| 8558/8564 [00:20<00:00, 597.89 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 419.81 examples/s]
Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 419.92 examples/s]
Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 599.33 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 419.02 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11078.54 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 10953.20 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 10962.27 examples/s]

Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13000.37 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13219.60 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13071.67 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 327.04 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 326.00 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 327.32 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 296.11 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 295.92 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 297.28 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:03, 277.29 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:03, 277.41 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:02, 278.77 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 268.35 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 269.82 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 268.46 examples/s]Tokenizing eval dataset:  21%|██        | 198/953 [00:00<00:02, 259.46 examples/s]Tokenizing eval dataset:  21%|██        | 198/953 [00:00<00:02, 260.83 examples/s]Tokenizing eval dataset:  21%|██        | 198/953 [00:00<00:02, 259.82 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:00<00:02, 293.06 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:00<00:02, 291.59 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:00<00:02, 292.11 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:00<00:01, 387.85 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:00<00:01, 386.18 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:00<00:01, 387.05 examples/s]Tokenizing eval dataset:  39%|███▊      | 368/953 [00:01<00:01, 453.64 examples/s]Tokenizing eval dataset:  39%|███▊      | 368/953 [00:01<00:01, 452.03 examples/s]Tokenizing eval dataset:  39%|███▊      | 368/953 [00:01<00:01, 453.27 examples/s]Tokenizing eval dataset:  46%|████▌     | 437/953 [00:01<00:00, 517.88 examples/s]Tokenizing eval dataset:  46%|████▌     | 437/953 [00:01<00:00, 516.26 examples/s]Tokenizing eval dataset:  46%|████▌     | 437/953 [00:01<00:00, 517.42 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:01<00:00, 560.21 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:01<00:00, 558.37 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:01<00:00, 558.99 examples/s]Tokenizing eval dataset:  60%|█████▉    | 569/953 [00:01<00:00, 583.03 examples/s]Tokenizing eval dataset:  60%|█████▉    | 569/953 [00:01<00:00, 581.45 examples/s]Tokenizing eval dataset:  60%|█████▉    | 569/953 [00:01<00:00, 581.69 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:01<00:00, 608.76 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:01<00:00, 607.36 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:01<00:00, 607.15 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 599.11 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 597.76 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 596.92 examples/s]Tokenizing eval dataset:  85%|████████▍ | 807/953 [00:01<00:00, 563.24 examples/s]Tokenizing eval dataset:  85%|████████▍ | 807/953 [00:01<00:00, 561.89 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:01<00:00, 559.58 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:01<00:00, 542.02 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:01<00:00, 540.74 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:01<00:00, 539.96 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 529.97 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 464.53 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 529.36 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 463.13 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 528.44 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 463.02 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
[rank4]:[E531 01:45:58.601451344 ProcessGroupNCCL.cpp:552] [Rank 4] Collective WorkNCCL(SeqNum=2704, OpType=_ALLGATHER_BASE, NumelIn=28672, NumelOut=229376, Timeout(ms)=1800000) raised the following async exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgress: Connection closed by remote peer vggn21.vega.pri<52470>
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fc1d356c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7fc1818211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7fc18182964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7fc18182b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7fc18182c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7fc1d3c3b5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7fc1d5ae3ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7fc1d5b75a40 in /lib/x86_64-linux-gnu/libc.so.6)

[rank4]:[E531 01:45:58.602999940 ProcessGroupNCCL.cpp:2168] [PG ID 0 PG GUID 0(default_pg) Rank 4]  failure detected by watchdog at work sequence id: 2704 PG status: last enqueued work: 2742, last completed work: 2703
[rank4]:[E531 01:45:58.603019287 ProcessGroupNCCL.cpp:667] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.
[rank7]:[E531 01:45:59.302241911 ProcessGroupNCCL.cpp:552] [Rank 7] Collective WorkNCCL(SeqNum=2704, OpType=_ALLGATHER_BASE, NumelIn=28672, NumelOut=229376, Timeout(ms)=1800000) raised the following async exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgressOpt: Call to recv from 10.210.4.5<44763> failed : Broken pipe
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f224c16c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7f21fa4211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7f21fa42964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7f21fa42b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7f21fa42c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7f224c8355c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7f224e6ddac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7f224e76fa40 in /lib/x86_64-linux-gnu/libc.so.6)

[rank7]:[E531 01:45:59.304584326 ProcessGroupNCCL.cpp:2168] [PG ID 0 PG GUID 0(default_pg) Rank 7]  failure detected by watchdog at work sequence id: 2704 PG status: last enqueued work: 2742, last completed work: 2703
[rank7]:[E531 01:45:59.304591939 ProcessGroupNCCL.cpp:667] Stack trace of the failed collective not found, potentially because FlightRecorder is disabled. You can enable it by setting TORCH_NCCL_TRACE_BUFFER_SIZE to a non-zero value.
[rank4]:[E531 01:46:53.964503487 ProcessGroupNCCL.cpp:681] [Rank 4] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank4]:[E531 01:46:53.964553144 ProcessGroupNCCL.cpp:695] [Rank 4] To avoid data inconsistency, we are taking the entire process down.
[rank4]:[E531 01:46:53.964617538 ProcessGroupNCCL.cpp:1895] [PG ID 0 PG GUID 0(default_pg) Rank 4] Process group watchdog thread terminated with exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgress: Connection closed by remote peer vggn21.vega.pri<52470>
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fc1d356c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7fc1818211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7fc18182964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7fc18182b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7fc18182c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7fc1d3c3b5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7fc1d5ae3ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7fc1d5b75a40 in /lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [PG ID 0 PG GUID 0(default_pg) Rank 4] Process group watchdog thread terminated with exception: NCCL error: remote process exited or there was a network error, NCCL version 2.21.5
ncclRemoteError: A call failed possibly due to a network error or a remote process exiting prematurely.
Last error:
socketProgress: Connection closed by remote peer vggn21.vega.pri<52470>
Exception raised from checkForNCCLErrorsInternal at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:2363 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fc1d356c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::checkForNCCLErrorsInternal(std::shared_ptr<c10d::NCCLComm>&) + 0x220 (0x7fc1818211c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::WorkNCCL::checkAndSetException() + 0x7b (0x7fc18182964b in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::watchdogHandler() + 0x650 (0x7fc18182b590 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7fc18182c6ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x145c0 (0x7fc1d3c3b5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #6: <unknown function> + 0x94ac3 (0x7fc1d5ae3ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #7: <unknown function> + 0x126a40 (0x7fc1d5b75a40 in /lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1901 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fc1d356c1b6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5c6fc (0x7fc1814876fc in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0x145c0 (0x7fc1d3c3b5c0 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch.so)
frame #3: <unknown function> + 0x94ac3 (0x7fc1d5ae3ac3 in /lib/x86_64-linux-gnu/libc.so.6)
frame #4: <unknown function> + 0x126a40 (0x7fc1d5b75a40 in /lib/x86_64-linux-gnu/libc.so.6)

W0531 01:46:53.665000 3246419 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3246730 closing signal SIGTERM
W0531 01:46:53.666000 3246419 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3246731 closing signal SIGTERM
W0531 01:46:53.667000 3246419 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3246732 closing signal SIGTERM
E0531 01:46:54.364000 3246419 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -6) local_rank: 0 (pid: 3246729) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1182, in launch_command
    deepspeed_launcher(args)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 861, in deepspeed_launcher
    distrib_run.run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
train.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-05-31_01:46:53
  host      : pm5-nod66.vega.pri
  rank      : 4 (local_rank: 0)
  exitcode  : -6 (pid: 3246729)
  error_file: <N/A>
  traceback : Signal 6 (SIGABRT) received by PID 3246729
========================================================
