cpu-bind=MASK - gn37, task  1  0 [3896696]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn36
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 1     --main_process_ip gn36     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62501263     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=4e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-06-04 12:30:51,080] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0604 12:30:53.011000 3896749 torch/distributed/run.py:792] 
W0604 12:30:53.011000 3896749 torch/distributed/run.py:792] *****************************************
W0604 12:30:53.011000 3896749 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0604 12:30:53.011000 3896749 torch/distributed/run.py:792] *****************************************
[2025-06-04 12:30:58,901] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-04 12:30:59,575] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-04 12:30:59,776] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-04 12:30:59,780] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Created datasets
Created datasets
Created datasets
Number of training examples: Number of training examples: Number of training examples: Number of training examples: 10033
10033
10033
10033
Number of validation examples: Number of validation examples: Number of validation examples: Number of validation examples: 953
953
953
953
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
Namespace(rank=64, learning_rate=4e-07, total_epochs=3, beta=0.2)
4e-07
4e-07
4e-07
4e-07
World size: 8
Setting gradient accumulation steps to: 2[2025-06-04 12:31:04,878] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-04 12:31:04,930] [INFO] [comm.py:658:init_distributed] cdb=None

[2025-06-04 12:31:04,949] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 627
Eval steps: 313
[2025-06-04 12:31:05,571] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:24<01:13, 24.60s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:15, 25.29s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:15, 25.33s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:15, 25.28s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:52<00:53, 26.82s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:53<00:53, 27.00s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:53<00:54, 27.01s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:53<00:53, 26.99s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:22<00:28, 28.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:28, 28.24s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:28, 28.23s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:28, 28.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:43<00:00, 25.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:43<00:00, 25.24s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:43<00:00, 25.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:43<00:00, 25.23s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:44<00:00, 26.09s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:44<00:00, 26.10s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:44<00:00, 26.09s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:44<00:00, 26.09s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
Total Parameters: 9457.78M
Total Parameters: 9457.78M
Total Parameters: 9457.78MTotal Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Trainable Parameters (LoRA): 216.07M

Trainable Parameters (LoRA): 216.07MTrainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Percentage of Trainable Params: 2.2846%

Percentage of Trainable Params: 2.2846%Percentage of Trainable Params: 2.2846%

Using LoRA and set up the model
[rank6]:[W604 12:32:57.033556661 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank7]:[W604 12:32:57.211140932 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank5]:[W604 12:32:57.242289549 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Extracting prompt in train dataset:   5%|▌         | 540/10033 [00:00<00:01, 5307.65 examples/s]Extracting prompt in train dataset:  11%|█         | 1080/10033 [00:00<00:01, 5355.49 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1710/10033 [00:00<00:01, 4677.74 examples/s]Extracting prompt in train dataset:  22%|██▏       | 2248/10033 [00:00<00:01, 4914.99 examples/s]Extracting prompt in train dataset:  30%|██▉       | 2990/10033 [00:00<00:01, 4915.03 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3770/10033 [00:00<00:01, 5003.99 examples/s]Extracting prompt in train dataset:  43%|████▎     | 4360/10033 [00:00<00:01, 4026.77 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4838/10033 [00:01<00:01, 4187.53 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 5440/10033 [00:01<00:01, 4031.78 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 6012/10033 [00:01<00:00, 4413.38 examples/s]Extracting prompt in train dataset:  66%|██████▋   | 6671/10033 [00:01<00:00, 4403.86 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 7270/10033 [00:01<00:00, 3755.65 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 7830/10033 [00:01<00:00, 3740.64 examples/s]Extracting prompt in train dataset:  84%|████████▎ | 8395/10033 [00:01<00:00, 4149.96 examples/s]Extracting prompt in train dataset:  89%|████████▊ | 8881/10033 [00:02<00:00, 4315.98 examples/s]Extracting prompt in train dataset:  93%|█████████▎| 9370/10033 [00:02<00:00, 4453.66 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:02<00:00, 4595.03 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:02<00:00, 4111.72 examples/s]
Applying chat template to train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 284/10033 [00:00<00:03, 2788.97 examples/s]Applying chat template to train dataset:   6%|▌         | 573/10033 [00:00<00:03, 2844.03 examples/s]Applying chat template to train dataset:   9%|▉         | 889/10033 [00:00<00:04, 2094.11 examples/s]Applying chat template to train dataset:  12%|█▏        | 1161/10033 [00:00<00:03, 2289.17 examples/s]Applying chat template to train dataset:  14%|█▍        | 1440/10033 [00:00<00:03, 2437.57 examples/s]Applying chat template to train dataset:  17%|█▋        | 1721/10033 [00:00<00:03, 2548.86 examples/s]Applying chat template to train dataset:  20%|██        | 2043/10033 [00:00<00:03, 2302.43 examples/s]Applying chat template to train dataset:  23%|██▎       | 2340/10033 [00:01<00:04, 1757.17 examples/s]Applying chat template to train dataset:  26%|██▌       | 2607/10033 [00:01<00:03, 1949.35 examples/s]Applying chat template to train dataset:  29%|██▉       | 2905/10033 [00:01<00:03, 2187.80 examples/s]Applying chat template to train dataset:  32%|███▏      | 3208/10033 [00:01<00:03, 2051.91 examples/s]Applying chat template to train dataset:  36%|███▌      | 3590/10033 [00:01<00:02, 2205.51 examples/s]Applying chat template to train dataset:  39%|███▉      | 3913/10033 [00:01<00:03, 1758.78 examples/s]Applying chat template to train dataset:  41%|████▏     | 4144/10033 [00:02<00:03, 1863.14 examples/s]Applying chat template to train dataset:  45%|████▍     | 4466/10033 [00:02<00:03, 1412.63 examples/s]Applying chat template to train dataset:  47%|████▋     | 4758/10033 [00:02<00:03, 1664.53 examples/s]Applying chat template to train dataset:  50%|█████     | 5019/10033 [00:02<00:02, 1846.10 examples/s]Applying chat template to train dataset:  53%|█████▎    | 5350/10033 [00:02<00:02, 1867.69 examples/s]Applying chat template to train dataset:  57%|█████▋    | 5718/10033 [00:02<00:02, 2032.88 examples/s]Applying chat template to train dataset:  60%|██████    | 6050/10033 [00:03<00:01, 2038.08 examples/s]Applying chat template to train dataset:  64%|██████▎   | 6391/10033 [00:03<00:01, 2103.57 examples/s]Applying chat template to train dataset:  67%|██████▋   | 6722/10033 [00:03<00:01, 1995.04 examples/s]Applying chat template to train dataset:  70%|███████   | 7052/10033 [00:03<00:01, 1971.57 examples/s]Applying chat template to train dataset:  73%|███████▎  | 7291/10033 [00:03<00:01, 2055.75 examples/s]Applying chat template to train dataset:  76%|███████▌  | 7576/10033 [00:03<00:01, 2233.98 examples/s]Applying chat template to train dataset:  78%|███████▊  | 7855/10033 [00:03<00:01, 1805.90 examples/s]Applying chat template to train dataset:  81%|████████  | 8080/10033 [00:04<00:01, 1897.92 examples/s]Applying chat template to train dataset:  83%|████████▎ | 8298/10033 [00:04<00:00, 1962.54 examples/s]Applying chat template to train dataset:  86%|████████▋ | 8664/10033 [00:04<00:00, 2118.10 examples/s]Applying chat template to train dataset:  89%|████████▊ | 8887/10033 [00:04<00:00, 2143.44 examples/s]Applying chat template to train dataset:  92%|█████████▏| 9225/10033 [00:04<00:00, 1884.00 examples/s]Applying chat template to train dataset:  95%|█████████▌| 9570/10033 [00:04<00:00, 2004.28 examples/s]Applying chat template to train dataset:  99%|█████████▉| 9910/10033 [00:04<00:00, 1992.82 examples/s]Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:05<00:00, 1981.55 examples/s]
Tokenizing train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/10033 [00:00<00:24, 399.78 examples/s]Tokenizing train dataset:   1%|          | 89/10033 [00:00<00:46, 211.76 examples/s]Tokenizing train dataset:   1%|          | 120/10033 [00:00<00:48, 204.37 examples/s]Tokenizing train dataset:   2%|▏         | 154/10033 [00:00<01:15, 131.31 examples/s]Tokenizing train dataset:   2%|▏         | 179/10033 [00:01<01:05, 149.62 examples/s]Tokenizing train dataset:   2%|▏         | 210/10033 [00:01<00:54, 178.61 examples/s]Tokenizing train dataset:   2%|▏         | 247/10033 [00:01<00:57, 171.39 examples/s]Tokenizing train dataset:   3%|▎         | 277/10033 [00:01<00:50, 193.49 examples/s]Tokenizing train dataset:   3%|▎         | 309/10033 [00:01<00:44, 218.27 examples/s]Tokenizing train dataset:   3%|▎         | 340/10033 [00:01<00:41, 235.38 examples/s]Tokenizing train dataset:   4%|▎         | 372/10033 [00:01<00:52, 184.03 examples/s]Tokenizing train dataset:   4%|▍         | 405/10033 [00:02<00:52, 184.35 examples/s]Tokenizing train dataset:   4%|▍         | 432/10033 [00:02<00:48, 199.52 examples/s]Tokenizing train dataset:   5%|▍         | 469/10033 [00:02<00:46, 207.90 examples/s]Tokenizing train dataset:   5%|▌         | 503/10033 [00:02<00:44, 212.07 examples/s]Tokenizing train dataset:   5%|▌         | 538/10033 [00:02<00:54, 173.54 examples/s]Tokenizing train dataset:   6%|▌         | 568/10033 [00:02<00:48, 193.74 examples/s]Tokenizing train dataset:   6%|▌         | 598/10033 [00:03<00:49, 189.28 examples/s]Tokenizing train dataset:   6%|▋         | 637/10033 [00:03<00:48, 193.38 examples/s]Tokenizing train dataset:   7%|▋         | 668/10033 [00:03<00:55, 169.27 examples/s]Tokenizing train dataset:   7%|▋         | 691/10033 [00:03<00:52, 179.04 examples/s]Tokenizing train dataset:   7%|▋         | 713/10033 [00:03<00:50, 186.00 examples/s]Tokenizing train dataset:   7%|▋         | 737/10033 [00:03<00:47, 197.29 examples/s]Tokenizing train dataset:   8%|▊         | 762/10033 [00:03<00:44, 208.99 examples/s]Tokenizing train dataset:   8%|▊         | 790/10033 [00:04<00:51, 178.65 examples/s]Tokenizing train dataset:   8%|▊         | 810/10033 [00:04<00:50, 181.95 examples/s]Tokenizing train dataset:   8%|▊         | 834/10033 [00:04<00:47, 191.77 examples/s]Tokenizing train dataset:   9%|▊         | 860/10033 [00:04<00:44, 205.73 examples/s]Tokenizing train dataset:   9%|▉         | 899/10033 [00:04<00:52, 175.43 examples/s]Tokenizing train dataset:   9%|▉         | 930/10033 [00:05<00:59, 151.81 examples/s]Tokenizing train dataset:   9%|▉         | 950/10033 [00:05<00:57, 159.08 examples/s]Tokenizing train dataset:  10%|▉         | 978/10033 [00:05<00:49, 181.74 examples/s]Tokenizing train dataset:  10%|▉         | 1003/10033 [00:05<00:46, 195.15 examples/s]Tokenizing train dataset:  10%|█         | 1034/10033 [00:05<00:45, 197.30 examples/s]Tokenizing train dataset:  11%|█         | 1068/10033 [00:05<00:53, 167.71 examples/s]Tokenizing train dataset:  11%|█         | 1093/10033 [00:05<00:48, 182.88 examples/s]Tokenizing train dataset:  11%|█         | 1124/10033 [00:06<01:05, 136.08 examples/s]Tokenizing train dataset:  11%|█▏        | 1141/10033 [00:06<01:03, 140.53 examples/s]Tokenizing train dataset:  12%|█▏        | 1164/10033 [00:06<00:57, 154.63 examples/s]Tokenizing train dataset:  12%|█▏        | 1200/10033 [00:06<00:50, 175.99 examples/s]Tokenizing train dataset:  12%|█▏        | 1220/10033 [00:06<00:49, 178.49 examples/s]Tokenizing train dataset:  12%|█▏        | 1240/10033 [00:06<00:49, 178.62 examples/s]Tokenizing train dataset:  13%|█▎        | 1273/10033 [00:07<00:47, 185.85 examples/s]Tokenizing train dataset:  13%|█▎        | 1308/10033 [00:07<00:47, 184.07 examples/s]Tokenizing train dataset:  13%|█▎        | 1340/10033 [00:07<00:46, 187.16 examples/s]Tokenizing train dataset:  14%|█▎        | 1370/10033 [00:07<00:45, 189.17 examples/s]Tokenizing train dataset:  14%|█▍        | 1390/10033 [00:07<00:45, 189.19 examples/s]Tokenizing train dataset:  14%|█▍        | 1420/10033 [00:07<00:40, 211.41 examples/s]Tokenizing train dataset:  14%|█▍        | 1448/10033 [00:07<00:37, 226.03 examples/s]Tokenizing train dataset:  15%|█▍        | 1480/10033 [00:07<00:39, 214.31 examples/s]Tokenizing train dataset:  15%|█▌        | 1514/10033 [00:08<00:39, 216.43 examples/s]Tokenizing train dataset:  15%|█▌        | 1543/10033 [00:08<00:36, 233.02 examples/s]Tokenizing train dataset:  16%|█▌        | 1578/10033 [00:08<00:36, 230.49 examples/s]Tokenizing train dataset:  16%|█▌        | 1602/10033 [00:08<00:36, 231.86 examples/s]Tokenizing train dataset:  16%|█▋        | 1636/10033 [00:08<00:38, 215.67 examples/s]Tokenizing train dataset:  17%|█▋        | 1663/10033 [00:08<00:36, 226.30 examples/s]Tokenizing train dataset:  17%|█▋        | 1690/10033 [00:08<00:35, 235.15 examples/s]Tokenizing train dataset:  17%|█▋        | 1726/10033 [00:09<00:45, 182.88 examples/s]Tokenizing train dataset:  18%|█▊        | 1763/10033 [00:09<00:44, 185.50 examples/s]Tokenizing train dataset:  18%|█▊        | 1796/10033 [00:09<00:45, 179.50 examples/s]Tokenizing train dataset:  18%|█▊        | 1820/10033 [00:09<00:43, 188.91 examples/s]Tokenizing train dataset:  18%|█▊        | 1854/10033 [00:09<00:41, 196.55 examples/s]Tokenizing train dataset:  19%|█▉        | 1887/10033 [00:10<00:42, 190.54 examples/s]Tokenizing train dataset:  19%|█▉        | 1911/10033 [00:10<00:44, 181.00 examples/s]Tokenizing train dataset:  19%|█▉        | 1938/10033 [00:10<00:40, 199.32 examples/s]Tokenizing train dataset:  20%|█▉        | 1974/10033 [00:10<00:45, 177.70 examples/s]Tokenizing train dataset:  20%|██        | 2012/10033 [00:10<00:52, 151.92 examples/s]Tokenizing train dataset:  20%|██        | 2033/10033 [00:11<00:59, 135.20 examples/s]Tokenizing train dataset:  20%|██        | 2053/10033 [00:11<00:55, 143.06 examples/s]Tokenizing train dataset:  21%|██        | 2089/10033 [00:11<00:43, 181.84 examples/s]Tokenizing train dataset:  21%|██        | 2130/10033 [00:11<00:38, 206.08 examples/s]Tokenizing train dataset:  22%|██▏       | 2168/10033 [00:11<00:41, 187.71 examples/s]Tokenizing train dataset:  22%|██▏       | 2204/10033 [00:11<00:43, 180.60 examples/s]Tokenizing train dataset:  22%|██▏       | 2226/10033 [00:12<00:44, 174.76 examples/s]Tokenizing train dataset:  23%|██▎       | 2259/10033 [00:12<00:38, 203.99 examples/s]Tokenizing train dataset:  23%|██▎       | 2284/10033 [00:12<00:37, 207.28 examples/s]Tokenizing train dataset:  23%|██▎       | 2319/10033 [00:12<00:36, 208.82 examples/s]Tokenizing train dataset:  23%|██▎       | 2348/10033 [00:12<00:34, 225.81 examples/s]Tokenizing train dataset:  24%|██▍       | 2393/10033 [00:12<00:30, 246.45 examples/s]Tokenizing train dataset:  24%|██▍       | 2434/10033 [00:12<00:38, 198.71 examples/s]Tokenizing train dataset:  25%|██▍       | 2474/10033 [00:13<00:35, 212.55 examples/s]Tokenizing train dataset:  25%|██▍       | 2508/10033 [00:13<00:35, 213.61 examples/s]Tokenizing train dataset:  25%|██▌       | 2546/10033 [00:13<00:30, 245.25 examples/s]Tokenizing train dataset:  26%|██▌       | 2581/10033 [00:13<00:27, 266.31 examples/s]Tokenizing train dataset:  26%|██▌       | 2614/10033 [00:13<00:26, 278.34 examples/s]Tokenizing train dataset:  26%|██▋       | 2644/10033 [00:13<00:31, 237.46 examples/s]Tokenizing train dataset:  27%|██▋       | 2680/10033 [00:13<00:31, 236.89 examples/s]Tokenizing train dataset:  27%|██▋       | 2710/10033 [00:14<00:29, 249.40 examples/s]Tokenizing train dataset:  27%|██▋       | 2744/10033 [00:14<00:34, 210.14 examples/s]Tokenizing train dataset:  28%|██▊       | 2785/10033 [00:14<00:31, 227.16 examples/s]Tokenizing train dataset:  28%|██▊       | 2826/10033 [00:14<00:38, 186.12 examples/s]Tokenizing train dataset:  28%|██▊       | 2850/10033 [00:14<00:37, 193.63 examples/s]Tokenizing train dataset:  29%|██▉       | 2887/10033 [00:14<00:34, 206.77 examples/s]Tokenizing train dataset:  29%|██▉       | 2922/10033 [00:15<00:30, 234.22 examples/s]Tokenizing train dataset:  30%|██▉       | 2960/10033 [00:15<00:26, 265.39 examples/s]Tokenizing train dataset:  30%|██▉       | 2990/10033 [00:15<00:25, 272.34 examples/s]Tokenizing train dataset:  30%|███       | 3029/10033 [00:15<00:28, 249.61 examples/s]Tokenizing train dataset:  31%|███       | 3069/10033 [00:15<00:27, 251.99 examples/s]Tokenizing train dataset:  31%|███       | 3104/10033 [00:15<00:25, 272.89 examples/s]Tokenizing train dataset:  31%|███▏      | 3140/10033 [00:15<00:31, 220.32 examples/s]Tokenizing train dataset:  32%|███▏      | 3177/10033 [00:16<00:31, 218.28 examples/s]Tokenizing train dataset:  32%|███▏      | 3205/10033 [00:16<00:29, 229.33 examples/s]Tokenizing train dataset:  32%|███▏      | 3234/10033 [00:16<00:28, 240.43 examples/s]Tokenizing train dataset:  33%|███▎      | 3274/10033 [00:16<00:42, 157.50 examples/s]Tokenizing train dataset:  33%|███▎      | 3298/10033 [00:16<00:39, 169.16 examples/s]Tokenizing train dataset:  33%|███▎      | 3325/10033 [00:16<00:35, 186.73 examples/s]Tokenizing train dataset:  33%|███▎      | 3361/10033 [00:17<00:30, 220.78 examples/s]Tokenizing train dataset:  34%|███▍      | 3400/10033 [00:17<00:25, 256.09 examples/s]Tokenizing train dataset:  34%|███▍      | 3439/10033 [00:17<00:29, 224.15 examples/s]Tokenizing train dataset:  35%|███▍      | 3480/10033 [00:17<00:27, 234.47 examples/s]Tokenizing train dataset:  35%|███▌      | 3523/10033 [00:17<00:27, 239.68 examples/s]Tokenizing train dataset:  35%|███▌      | 3550/10033 [00:17<00:26, 242.79 examples/s]Tokenizing train dataset:  36%|███▌      | 3578/10033 [00:17<00:25, 249.47 examples/s]Tokenizing train dataset:  36%|███▌      | 3617/10033 [00:18<00:26, 243.56 examples/s]Tokenizing train dataset:  36%|███▋      | 3645/10033 [00:18<00:25, 248.25 examples/s]Tokenizing train dataset:  37%|███▋      | 3680/10033 [00:18<00:36, 173.73 examples/s]Tokenizing train dataset:  37%|███▋      | 3724/10033 [00:18<00:35, 178.83 examples/s]Tokenizing train dataset:  37%|███▋      | 3762/10033 [00:19<00:37, 167.72 examples/s]Tokenizing train dataset:  38%|███▊      | 3790/10033 [00:19<00:33, 185.76 examples/s]Tokenizing train dataset:  38%|███▊      | 3827/10033 [00:19<00:31, 197.52 examples/s]Tokenizing train dataset:  38%|███▊      | 3858/10033 [00:19<00:28, 216.84 examples/s]Tokenizing train dataset:  39%|███▉      | 3896/10033 [00:19<00:29, 209.73 examples/s]Tokenizing train dataset:  39%|███▉      | 3919/10033 [00:19<00:28, 211.00 examples/s]Tokenizing train dataset:  39%|███▉      | 3960/10033 [00:19<00:27, 221.71 examples/s]Tokenizing train dataset:  40%|███▉      | 4002/10033 [00:19<00:25, 235.45 examples/s]Tokenizing train dataset:  40%|████      | 4044/10033 [00:20<00:25, 236.59 examples/s]Tokenizing train dataset:  41%|████      | 4072/10033 [00:20<00:24, 244.80 examples/s]Tokenizing train dataset:  41%|████      | 4116/10033 [00:20<00:23, 255.63 examples/s]Tokenizing train dataset:  41%|████▏     | 4154/10033 [00:20<00:23, 250.91 examples/s]Tokenizing train dataset:  42%|████▏     | 4193/10033 [00:20<00:24, 233.76 examples/s]Tokenizing train dataset:  42%|████▏     | 4227/10033 [00:20<00:22, 254.30 examples/s]Tokenizing train dataset:  43%|████▎     | 4272/10033 [00:21<00:21, 264.92 examples/s]Tokenizing train dataset:  43%|████▎     | 4311/10033 [00:21<00:33, 169.56 examples/s]Tokenizing train dataset:  43%|████▎     | 4345/10033 [00:21<00:32, 173.97 examples/s]Tokenizing train dataset:  44%|████▎     | 4386/10033 [00:21<00:30, 186.48 examples/s]Tokenizing train dataset:  44%|████▍     | 4425/10033 [00:22<00:28, 193.83 examples/s]Tokenizing train dataset:  44%|████▍     | 4455/10033 [00:22<00:26, 211.38 examples/s]Tokenizing train dataset:  45%|████▍     | 4493/10033 [00:22<00:26, 210.13 examples/s]Tokenizing train dataset:  45%|████▌     | 4529/10033 [00:22<00:28, 191.28 examples/s]Tokenizing train dataset:  45%|████▌     | 4562/10033 [00:22<00:25, 214.80 examples/s]Tokenizing train dataset:  46%|████▌     | 4604/10033 [00:22<00:23, 230.69 examples/s]Tokenizing train dataset:  46%|████▌     | 4631/10033 [00:22<00:22, 237.15 examples/s]Tokenizing train dataset:  46%|████▋     | 4657/10033 [00:23<00:22, 239.44 examples/s]Tokenizing train dataset:  47%|████▋     | 4690/10033 [00:23<00:29, 183.36 examples/s]Tokenizing train dataset:  47%|████▋     | 4713/10033 [00:23<00:27, 190.55 examples/s]Tokenizing train dataset:  47%|████▋     | 4740/10033 [00:23<00:25, 204.18 examples/s]Tokenizing train dataset:  48%|████▊     | 4770/10033 [00:23<00:29, 179.56 examples/s]Tokenizing train dataset:  48%|████▊     | 4790/10033 [00:23<00:29, 179.64 examples/s]Tokenizing train dataset:  48%|████▊     | 4816/10033 [00:23<00:28, 184.86 examples/s]Tokenizing train dataset:  48%|████▊     | 4850/10033 [00:24<00:24, 210.76 examples/s]Tokenizing train dataset:  49%|████▉     | 4898/10033 [00:24<00:18, 275.01 examples/s]Tokenizing train dataset:  49%|████▉     | 4947/10033 [00:24<00:15, 328.82 examples/s]Tokenizing train dataset:  50%|████▉     | 4990/10033 [00:24<00:14, 354.83 examples/s]Tokenizing train dataset:  50%|█████     | 5055/10033 [00:24<00:13, 380.87 examples/s]Tokenizing train dataset:  51%|█████     | 5123/10033 [00:24<00:12, 400.06 examples/s]Tokenizing train dataset:  52%|█████▏    | 5197/10033 [00:24<00:11, 409.01 examples/s]Tokenizing train dataset:  52%|█████▏    | 5242/10033 [00:24<00:11, 417.20 examples/s]Tokenizing train dataset:  53%|█████▎    | 5289/10033 [00:25<00:11, 426.78 examples/s]Tokenizing train dataset:  53%|█████▎    | 5352/10033 [00:25<00:11, 404.21 examples/s]Tokenizing train dataset:  54%|█████▍    | 5394/10033 [00:25<00:11, 403.17 examples/s]Tokenizing train dataset:  54%|█████▍    | 5453/10033 [00:25<00:10, 444.77 examples/s]Tokenizing train dataset:  55%|█████▍    | 5516/10033 [00:25<00:11, 388.21 examples/s]Tokenizing train dataset:  56%|█████▌    | 5578/10033 [00:25<00:12, 365.40 examples/s]Tokenizing train dataset:  56%|█████▌    | 5622/10033 [00:25<00:11, 379.99 examples/s]Tokenizing train dataset:  57%|█████▋    | 5690/10033 [00:26<00:11, 380.38 examples/s]Tokenizing train dataset:  57%|█████▋    | 5761/10033 [00:26<00:10, 405.90 examples/s]Tokenizing train dataset:  58%|█████▊    | 5826/10033 [00:26<00:09, 456.22 examples/s]Tokenizing train dataset:  59%|█████▊    | 5891/10033 [00:26<00:09, 446.69 examples/s]Tokenizing train dataset:  59%|█████▉    | 5962/10033 [00:26<00:09, 439.66 examples/s]Tokenizing train dataset:  60%|█████▉    | 6019/10033 [00:26<00:09, 420.93 examples/s]Tokenizing train dataset:  61%|██████    | 6080/10033 [00:27<00:10, 384.57 examples/s]Tokenizing train dataset:  61%|██████▏   | 6148/10033 [00:27<00:12, 306.43 examples/s]Tokenizing train dataset:  62%|██████▏   | 6219/10033 [00:27<00:10, 371.68 examples/s]Tokenizing train dataset:  63%|██████▎   | 6290/10033 [00:27<00:11, 333.79 examples/s]Tokenizing train dataset:  63%|██████▎   | 6360/10033 [00:27<00:10, 363.90 examples/s]Tokenizing train dataset:  64%|██████▍   | 6424/10033 [00:28<00:09, 375.78 examples/s]Tokenizing train dataset:  65%|██████▍   | 6487/10033 [00:28<00:09, 386.06 examples/s]Tokenizing train dataset:  65%|██████▌   | 6549/10033 [00:28<00:08, 390.42 examples/s]Tokenizing train dataset:  66%|██████▌   | 6590/10033 [00:28<00:08, 386.74 examples/s]Tokenizing train dataset:  66%|██████▌   | 6646/10033 [00:28<00:10, 330.63 examples/s]Tokenizing train dataset:  67%|██████▋   | 6718/10033 [00:28<00:09, 340.35 examples/s]Tokenizing train dataset:  68%|██████▊   | 6784/10033 [00:29<00:08, 361.13 examples/s]Tokenizing train dataset:  68%|██████▊   | 6837/10033 [00:29<00:09, 341.05 examples/s]Tokenizing train dataset:  69%|██████▊   | 6880/10033 [00:29<00:08, 357.93 examples/s]Tokenizing train dataset:  69%|██████▉   | 6949/10033 [00:29<00:08, 373.82 examples/s]Tokenizing train dataset:  70%|██████▉   | 7009/10033 [00:29<00:08, 339.17 examples/s]Tokenizing train dataset:  70%|███████   | 7069/10033 [00:29<00:08, 334.74 examples/s]Tokenizing train dataset:  71%|███████   | 7127/10033 [00:29<00:07, 380.83 examples/s]Tokenizing train dataset:  72%|███████▏  | 7204/10033 [00:30<00:06, 415.79 examples/s]Tokenizing train dataset:  73%|███████▎  | 7275/10033 [00:30<00:06, 431.43 examples/s]Tokenizing train dataset:  73%|███████▎  | 7320/10033 [00:30<00:06, 433.09 examples/s]Tokenizing train dataset:  74%|███████▎  | 7385/10033 [00:30<00:07, 355.77 examples/s]Tokenizing train dataset:  74%|███████▍  | 7456/10033 [00:30<00:06, 371.31 examples/s]Tokenizing train dataset:  75%|███████▍  | 7519/10033 [00:31<00:07, 346.57 examples/s]Tokenizing train dataset:  76%|███████▌  | 7583/10033 [00:31<00:06, 400.27 examples/s]Tokenizing train dataset:  76%|███████▌  | 7643/10033 [00:31<00:06, 397.11 examples/s]Tokenizing train dataset:  77%|███████▋  | 7702/10033 [00:31<00:06, 379.92 examples/s]Tokenizing train dataset:  77%|███████▋  | 7768/10033 [00:31<00:05, 394.10 examples/s]Tokenizing train dataset:  78%|███████▊  | 7825/10033 [00:31<00:05, 379.58 examples/s]Tokenizing train dataset:  79%|███████▊  | 7880/10033 [00:31<00:05, 411.30 examples/s]Tokenizing train dataset:  79%|███████▉  | 7942/10033 [00:32<00:05, 363.57 examples/s]Tokenizing train dataset:  80%|███████▉  | 8013/10033 [00:32<00:05, 371.12 examples/s]Tokenizing train dataset:  80%|████████  | 8073/10033 [00:32<00:05, 326.82 examples/s]Tokenizing train dataset:  81%|████████  | 8126/10033 [00:32<00:06, 303.92 examples/s]Tokenizing train dataset:  81%|████████▏ | 8174/10033 [00:32<00:05, 334.30 examples/s]Tokenizing train dataset:  82%|████████▏ | 8220/10033 [00:32<00:05, 358.50 examples/s]Tokenizing train dataset:  82%|████████▏ | 8275/10033 [00:33<00:04, 399.87 examples/s]Tokenizing train dataset:  83%|████████▎ | 8340/10033 [00:33<00:04, 396.68 examples/s]Tokenizing train dataset:  84%|████████▍ | 8408/10033 [00:33<00:03, 413.13 examples/s]Tokenizing train dataset:  84%|████████▍ | 8464/10033 [00:33<00:03, 441.83 examples/s]Tokenizing train dataset:  85%|████████▍ | 8517/10033 [00:33<00:03, 459.62 examples/s]Tokenizing train dataset:  86%|████████▌ | 8598/10033 [00:33<00:03, 453.10 examples/s]Tokenizing train dataset:  86%|████████▋ | 8662/10033 [00:33<00:02, 481.37 examples/s]Tokenizing train dataset:  87%|████████▋ | 8728/10033 [00:34<00:03, 420.96 examples/s]Tokenizing train dataset:  88%|████████▊ | 8796/10033 [00:34<00:02, 450.66 examples/s]Tokenizing train dataset:  88%|████████▊ | 8861/10033 [00:34<00:02, 442.18 examples/s]Tokenizing train dataset:  89%|████████▉ | 8958/10033 [00:34<00:01, 558.82 examples/s]Tokenizing train dataset:  90%|████████▉ | 9021/10033 [00:34<00:01, 573.13 examples/s]Tokenizing train dataset:  91%|█████████ | 9085/10033 [00:34<00:02, 388.61 examples/s]Tokenizing train dataset:  91%|█████████ | 9152/10033 [00:35<00:02, 368.58 examples/s]Tokenizing train dataset:  92%|█████████▏| 9231/10033 [00:35<00:01, 446.94 examples/s]Tokenizing train dataset:  93%|█████████▎| 9337/10033 [00:35<00:01, 574.87 examples/s]Tokenizing train dataset:  94%|█████████▍| 9461/10033 [00:35<00:01, 557.77 examples/s]Tokenizing train dataset:  96%|█████████▌| 9585/10033 [00:35<00:00, 614.79 examples/s]Tokenizing train dataset:  97%|█████████▋| 9710/10033 [00:35<00:00, 672.50 examples/s]Tokenizing train dataset:  98%|█████████▊| 9846/10033 [00:35<00:00, 737.67 examples/s]Tokenizing train dataset:  99%|█████████▉| 9971/10033 [00:36<00:00, 761.68 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:36<00:00, 277.23 examples/s]
[rank4]:[W604 12:33:42.471152260 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Extracting prompt in train dataset:   5%|▌         | 540/10033 [00:00<00:01, 5356.36 examples/s]Extracting prompt in train dataset:   5%|▌         | 550/10033 [00:00<00:01, 5417.42 examples/s]Extracting prompt in eval dataset:  57%|█████▋    | 540/953 [00:00<00:00, 5283.76 examples/s]Extracting prompt in train dataset:   5%|▌         | 545/10033 [00:00<00:01, 5406.12 examples/s]Extracting prompt in train dataset:  12%|█▏        | 1160/10033 [00:00<00:01, 4486.74 examples/s]Extracting prompt in train dataset:  11%|█         | 1116/10033 [00:00<00:02, 3525.05 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 3135.02 examples/s]
Extracting prompt in train dataset:  11%|█         | 1104/10033 [00:00<00:02, 3313.64 examples/s]Extracting prompt in train dataset:  18%|█▊        | 1784/10033 [00:00<00:01, 4322.54 examples/s]Extracting prompt in train dataset:  15%|█▌        | 1540/10033 [00:00<00:02, 3767.69 examples/s]Extracting prompt in train dataset:  17%|█▋        | 1670/10033 [00:00<00:02, 3356.42 examples/s]Extracting prompt in train dataset:  23%|██▎       | 2340/10033 [00:00<00:01, 3886.83 examples/s]Extracting prompt in train dataset:  21%|██        | 2100/10033 [00:00<00:02, 3609.32 examples/s]Extracting prompt in train dataset:  21%|██        | 2120/10033 [00:00<00:02, 3088.23 examples/s]Extracting prompt in train dataset:  28%|██▊       | 2799/10033 [00:00<00:01, 4070.68 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2630/10033 [00:00<00:01, 4084.38 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  26%|██▌       | 2580/10033 [00:00<00:02, 3455.49 examples/s]Extracting prompt in train dataset:  32%|███▏      | 3232/10033 [00:00<00:01, 4143.02 examples/s]Extracting prompt in train dataset:  32%|███▏      | 3217/10033 [00:00<00:01, 4017.14 examples/s]Applying chat template to eval dataset:  32%|███▏      | 309/953 [00:00<00:00, 3058.26 examples/s]Extracting prompt in train dataset:  31%|███       | 3123/10033 [00:00<00:02, 3070.91 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3790/10033 [00:00<00:01, 3381.51 examples/s]Extracting prompt in train dataset:  38%|███▊      | 3790/10033 [00:01<00:01, 3457.65 examples/s]Applying chat template to eval dataset:  66%|██████▋   | 633/953 [00:00<00:00, 1654.33 examples/s]Extracting prompt in train dataset:  37%|███▋      | 3700/10033 [00:01<00:02, 2793.82 examples/s]Extracting prompt in train dataset:  43%|████▎     | 4350/10033 [00:01<00:01, 2938.83 examples/s]Extracting prompt in train dataset:  44%|████▎     | 4370/10033 [00:01<00:01, 3340.18 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1612.09 examples/s]Extracting prompt in train dataset:  43%|████▎     | 4280/10033 [00:01<00:01, 3000.47 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4910/10033 [00:01<00:01, 3136.25 examples/s]Extracting prompt in train dataset:  48%|████▊     | 4780/10033 [00:01<00:01, 3492.05 examples/s]Extracting prompt in train dataset:  46%|████▌     | 4620/10033 [00:01<00:01, 3076.93 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1161.75 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 5490/10033 [00:01<00:01, 2787.59 examples/s]
Extracting prompt in train dataset:  53%|█████▎    | 5367/10033 [00:01<00:01, 2634.29 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 5209/10033 [00:01<00:01, 2637.31 examples/s]Extracting prompt in train dataset:  60%|██████    | 6055/10033 [00:01<00:01, 2960.25 examples/s]Extracting prompt in train dataset:  55%|█████▍    | 5510/10033 [00:01<00:01, 2318.23 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 5957/10033 [00:01<00:01, 2575.74 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 6610/10033 [00:02<00:01, 2841.27 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 6000/10033 [00:02<00:01, 2787.31 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 6370/10033 [00:02<00:01, 2834.98 examples/s]Extracting prompt in train dataset:  72%|███████▏  | 7181/10033 [00:02<00:00, 3046.96 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  66%|██████▌   | 6590/10033 [00:02<00:01, 2857.60 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 6957/10033 [00:02<00:01, 2875.97 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 7671/10033 [00:02<00:00, 3394.55 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 321.20 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 6937/10033 [00:02<00:01, 2977.12 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 7556/10033 [00:02<00:00, 3160.02 examples/s]Extracting prompt in train dataset:  82%|████████▏ | 8180/10033 [00:02<00:00, 3387.13 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 8020/10033 [00:02<00:00, 3380.57 examples/s]Extracting prompt in train dataset:  75%|███████▌  | 7527/10033 [00:02<00:00, 3070.28 examples/s]Extracting prompt in train dataset:  86%|████████▌ | 8580/10033 [00:02<00:00, 3512.64 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:04, 204.43 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 8508/10033 [00:02<00:00, 3698.44 examples/s]Extracting prompt in train dataset:  79%|███████▉  | 7910/10033 [00:02<00:00, 3222.81 examples/s]Extracting prompt in train dataset:  90%|█████████ | 9040/10033 [00:02<00:00, 3754.92 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:04, 195.24 examples/s]Extracting prompt in train dataset:  91%|█████████▏| 9176/10033 [00:02<00:00, 3936.88 examples/s]Extracting prompt in train dataset:  85%|████████▍ | 8510/10033 [00:02<00:00, 3449.55 examples/s]Extracting prompt in train dataset:  96%|█████████▌| 9620/10033 [00:02<00:00, 3772.40 examples/s]Tokenizing eval dataset:  14%|█▍        | 137/953 [00:00<00:05, 149.62 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 9775/10033 [00:03<00:00, 3022.58 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:03<00:00, 2577.68 examples/s]Extracting prompt in train dataset:  91%|█████████ | 9111/10033 [00:03<00:00, 2633.40 examples/s]Tokenizing eval dataset:  17%|█▋        | 164/953 [00:00<00:05, 151.92 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:03<00:00, 3129.07 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:03<00:00, 3188.81 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 9713/10033 [00:03<00:00, 2767.45 examples/s]Tokenizing eval dataset:  20%|██        | 194/953 [00:01<00:04, 162.20 examples/s]

Extracting prompt in train dataset: 100%|█████████▉| 10020/10033 [00:03<00:00, 2403.58 examples/s]Tokenizing eval dataset:  24%|██▍       | 231/953 [00:01<00:04, 157.10 examples/s]Extracting prompt in train dataset: 100%|██████████| 10033/10033 [00:03<00:00, 2672.59 examples/s]
Tokenizing eval dataset:  28%|██▊       | 263/953 [00:01<00:04, 152.17 examples/s]Tokenizing eval dataset:  31%|███       | 297/953 [00:01<00:03, 179.67 examples/s]Applying chat template to train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing eval dataset:  37%|███▋      | 357/953 [00:01<00:02, 261.79 examples/s]Applying chat template to train dataset:   3%|▎         | 270/10033 [00:00<00:03, 2669.36 examples/s]Applying chat template to train dataset:   3%|▎         | 280/10033 [00:00<00:03, 2759.13 examples/s]Applying chat template to train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing eval dataset:  44%|████▍     | 420/953 [00:02<00:02, 262.87 examples/s]Applying chat template to train dataset:   7%|▋         | 670/10033 [00:00<00:03, 2649.58 examples/s]Tokenizing eval dataset:  50%|████▉     | 473/953 [00:02<00:01, 313.00 examples/s]Applying chat template to train dataset:   6%|▌         | 586/10033 [00:00<00:04, 2018.64 examples/s]Applying chat template to train dataset:   3%|▎         | 287/10033 [00:00<00:03, 2842.28 examples/s]Applying chat template to train dataset:  10%|█         | 1010/10033 [00:00<00:03, 2454.06 examples/s]Tokenizing eval dataset:  57%|█████▋    | 540/953 [00:02<00:01, 337.72 examples/s]Applying chat template to train dataset:   9%|▉         | 890/10033 [00:00<00:05, 1804.22 examples/s]Applying chat template to train dataset:   6%|▌         | 602/10033 [00:00<00:04, 1886.20 examples/s]Applying chat template to train dataset:  13%|█▎        | 1310/10033 [00:00<00:04, 2148.63 examples/s]Tokenizing eval dataset:  62%|██████▏   | 590/953 [00:02<00:00, 371.81 examples/s]Applying chat template to train dataset:  12%|█▏        | 1160/10033 [00:00<00:04, 2052.49 examples/s]Applying chat template to train dataset:   9%|▉         | 915/10033 [00:00<00:06, 1449.24 examples/s]Applying chat template to train dataset:  16%|█▌        | 1615/10033 [00:00<00:06, 1354.07 examples/s]Tokenizing eval dataset:  69%|██████▊   | 655/953 [00:02<00:01, 248.16 examples/s]Applying chat template to train dataset:  15%|█▍        | 1463/10033 [00:01<00:07, 1116.86 examples/s]Applying chat template to train dataset:  12%|█▏        | 1231/10033 [00:00<00:07, 1161.82 examples/s]Applying chat template to train dataset:  19%|█▉        | 1927/10033 [00:01<00:06, 1197.25 examples/s]Tokenizing eval dataset:  75%|███████▍  | 714/953 [00:03<00:01, 232.63 examples/s]Applying chat template to train dataset:  18%|█▊        | 1774/10033 [00:01<00:07, 1080.20 examples/s]Applying chat template to train dataset:  14%|█▍        | 1390/10033 [00:01<00:09, 868.71 examples/s] Applying chat template to train dataset:  21%|██        | 2085/10033 [00:01<00:07, 1009.99 examples/s]Tokenizing eval dataset:  81%|████████  | 770/953 [00:03<00:00, 201.12 examples/s]Applying chat template to train dataset:  19%|█▉        | 1930/10033 [00:01<00:09, 861.51 examples/s] Applying chat template to train dataset:  15%|█▌        | 1544/10033 [00:01<00:11, 743.35 examples/s]Applying chat template to train dataset:  22%|██▏       | 2243/10033 [00:01<00:09, 857.90 examples/s] Tokenizing eval dataset:  86%|████████▌ | 817/953 [00:03<00:00, 202.40 examples/s]Applying chat template to train dataset:  21%|██        | 2087/10033 [00:01<00:09, 822.15 examples/s]Applying chat template to train dataset:  17%|█▋        | 1705/10033 [00:01<00:10, 811.25 examples/s]Applying chat template to train dataset:  24%|██▍       | 2400/10033 [00:02<00:08, 849.50 examples/s]Tokenizing eval dataset:  89%|████████▊ | 844/953 [00:03<00:00, 203.82 examples/s]Applying chat template to train dataset:  22%|██▏       | 2243/10033 [00:02<00:08, 923.08 examples/s]Applying chat template to train dataset:  19%|█▊        | 1864/10033 [00:01<00:08, 919.81 examples/s]Applying chat template to train dataset:  26%|██▋       | 2656/10033 [00:02<00:06, 1113.58 examples/s]Tokenizing eval dataset:  91%|█████████ | 867/953 [00:03<00:00, 204.56 examples/s]Applying chat template to train dataset:  24%|██▍       | 2400/10033 [00:02<00:07, 976.12 examples/s]Applying chat template to train dataset:  20%|██        | 2024/10033 [00:02<00:09, 802.78 examples/s]Applying chat template to train dataset:  28%|██▊       | 2812/10033 [00:02<00:08, 888.41 examples/s] Tokenizing eval dataset:  94%|█████████▍| 894/953 [00:04<00:00, 147.91 examples/s]Applying chat template to train dataset:  25%|██▌       | 2555/10033 [00:02<00:10, 715.85 examples/s]Applying chat template to train dataset:  22%|██▏       | 2185/10033 [00:02<00:10, 760.25 examples/s]Applying chat template to train dataset:  30%|██▉       | 2966/10033 [00:02<00:08, 876.71 examples/s]Tokenizing eval dataset:  96%|█████████▌| 915/953 [00:04<00:00, 139.97 examples/s]Applying chat template to train dataset:  27%|██▋       | 2710/10033 [00:02<00:09, 770.05 examples/s]Applying chat template to train dataset:  23%|██▎       | 2347/10033 [00:02<00:09, 818.11 examples/s]Applying chat template to train dataset:  31%|███       | 3101/10033 [00:02<00:08, 849.26 examples/s]Tokenizing eval dataset: 100%|█████████▉| 949/953 [00:04<00:00, 172.09 examples/s]Applying chat template to train dataset:  29%|██▉       | 2887/10033 [00:02<00:07, 933.69 examples/s]Applying chat template to train dataset:  25%|██▌       | 2552/10033 [00:02<00:07, 1032.03 examples/s]Applying chat template to train dataset:  33%|███▎      | 3304/10033 [00:02<00:06, 1057.16 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:04<00:00, 195.24 examples/s]Applying chat template to train dataset:  30%|███       | 3042/10033 [00:02<00:08, 861.62 examples/s]Applying chat template to train dataset:  27%|██▋       | 2711/10033 [00:02<00:08, 913.03 examples/s] Applying chat template to train dataset:  35%|███▍      | 3463/10033 [00:03<00:07, 936.93 examples/s] 
Applying chat template to train dataset:  32%|███▏      | 3180/10033 [00:03<00:07, 947.79 examples/s]Applying chat template to train dataset:  29%|██▊       | 2874/10033 [00:02<00:06, 1037.52 examples/s]Applying chat template to train dataset:  36%|███▌      | 3622/10033 [00:03<00:06, 996.03 examples/s]Applying chat template to train dataset:  33%|███▎      | 3336/10033 [00:03<00:06, 1045.06 examples/s]Applying chat template to train dataset:  30%|███       | 3039/10033 [00:03<00:06, 1139.68 examples/s]Applying chat template to train dataset:  38%|███▊      | 3845/10033 [00:03<00:04, 1243.11 examples/s]Applying chat template to train dataset:  36%|███▌      | 3590/10033 [00:03<00:04, 1375.46 examples/s]Applying chat template to train dataset:  32%|███▏      | 3180/10033 [00:03<00:06, 1063.19 examples/s]Applying chat template to train dataset:  40%|███▉      | 4000/10033 [00:03<00:05, 1071.56 examples/s]Applying chat template to train dataset:  33%|███▎      | 3340/10033 [00:03<00:06, 1052.81 examples/s]Applying chat template to train dataset:  39%|███▉      | 3899/10033 [00:03<00:04, 1331.62 examples/s]Applying chat template to train dataset:  41%|████▏     | 4156/10033 [00:03<00:05, 1119.77 examples/s]Applying chat template to train dataset:  35%|███▍      | 3503/10033 [00:03<00:05, 1169.88 examples/s]Applying chat template to train dataset:  40%|████      | 4056/10033 [00:03<00:06, 954.02 examples/s] Applying chat template to train dataset:  43%|████▎     | 4311/10033 [00:03<00:07, 815.28 examples/s] Applying chat template to train dataset:  37%|███▋      | 3667/10033 [00:03<00:07, 887.54 examples/s] Applying chat template to train dataset:  42%|████▏     | 4211/10033 [00:03<00:05, 1040.66 examples/s]Applying chat template to train dataset:  45%|████▍     | 4500/10033 [00:04<00:05, 1001.61 examples/s]Applying chat template to train dataset:  39%|███▊      | 3866/10033 [00:03<00:05, 1097.06 examples/s]Applying chat template to train dataset:  45%|████▍     | 4491/10033 [00:04<00:04, 1375.99 examples/s]Applying chat template to train dataset:  46%|████▋     | 4651/10033 [00:04<00:04, 1080.94 examples/s]Applying chat template to train dataset:  40%|████      | 4030/10033 [00:03<00:05, 1126.81 examples/s]Applying chat template to train dataset:  48%|████▊     | 4806/10033 [00:04<00:04, 1164.45 examples/s]Applying chat template to train dataset:  48%|████▊     | 4799/10033 [00:04<00:03, 1505.93 examples/s]Applying chat template to train dataset:  42%|████▏     | 4193/10033 [00:04<00:04, 1204.81 examples/s]Applying chat template to train dataset:  50%|████▉     | 5005/10033 [00:04<00:03, 1357.89 examples/s]Applying chat template to train dataset:  50%|████▉     | 4995/10033 [00:04<00:03, 1600.09 examples/s]Applying chat template to train dataset:  43%|████▎     | 4357/10033 [00:04<00:05, 1056.42 examples/s]Applying chat template to train dataset:  51%|█████▏    | 5164/10033 [00:04<00:04, 1165.41 examples/s]Applying chat template to train dataset:  45%|████▌     | 4519/10033 [00:04<00:04, 1153.22 examples/s]Applying chat template to train dataset:  53%|█████▎    | 5310/10033 [00:04<00:03, 1477.85 examples/s]Applying chat template to train dataset:  54%|█████▎    | 5373/10033 [00:04<00:03, 1375.56 examples/s]Applying chat template to train dataset:  47%|████▋     | 4699/10033 [00:04<00:04, 1301.40 examples/s]Applying chat template to train dataset:  55%|█████▌    | 5537/10033 [00:04<00:03, 1307.41 examples/s]Applying chat template to train dataset:  49%|████▉     | 4900/10033 [00:04<00:03, 1474.74 examples/s]Applying chat template to train dataset:  56%|█████▌    | 5624/10033 [00:04<00:02, 1495.09 examples/s]Applying chat template to train dataset:  57%|█████▋    | 5700/10033 [00:04<00:03, 1309.55 examples/s]Applying chat template to train dataset:  51%|█████     | 5068/10033 [00:04<00:03, 1487.50 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5940/10033 [00:04<00:02, 1613.65 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5933/10033 [00:05<00:02, 1559.13 examples/s]Applying chat template to train dataset:  52%|█████▏    | 5235/10033 [00:04<00:03, 1481.33 examples/s]Applying chat template to train dataset:  61%|██████▏   | 6148/10033 [00:05<00:02, 1703.15 examples/s]Applying chat template to train dataset:  61%|██████▏   | 6162/10033 [00:05<00:02, 1745.80 examples/s]Applying chat template to train dataset:  54%|█████▍    | 5402/10033 [00:04<00:03, 1470.15 examples/s]Applying chat template to train dataset:  65%|██████▍   | 6473/10033 [00:05<00:01, 1837.99 examples/s]Applying chat template to train dataset:  56%|█████▌    | 5570/10033 [00:05<00:03, 1400.71 examples/s]Applying chat template to train dataset:  65%|██████▍   | 6488/10033 [00:05<00:02, 1641.06 examples/s]Applying chat template to train dataset:  67%|██████▋   | 6740/10033 [00:05<00:01, 2017.85 examples/s]Applying chat template to train dataset:  57%|█████▋    | 5739/10033 [00:05<00:03, 1331.35 examples/s]Applying chat template to train dataset:  68%|██████▊   | 6805/10033 [00:05<00:02, 1306.54 examples/s]Applying chat template to train dataset:  70%|███████   | 7059/10033 [00:05<00:02, 1268.07 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5907/10033 [00:05<00:04, 833.23 examples/s] Applying chat template to train dataset:  69%|██████▉   | 6968/10033 [00:05<00:02, 1212.21 examples/s]Applying chat template to train dataset:  73%|███████▎  | 7315/10033 [00:05<00:01, 1471.40 examples/s]Applying chat template to train dataset:  61%|██████    | 6074/10033 [00:05<00:04, 951.89 examples/s]Applying chat template to train dataset:  71%|███████   | 7130/10033 [00:06<00:02, 1082.41 examples/s]Applying chat template to train dataset:  62%|██████▏   | 6241/10033 [00:05<00:03, 1008.68 examples/s]Applying chat template to train dataset:  76%|███████▌  | 7630/10033 [00:06<00:01, 1442.59 examples/s]Applying chat template to train dataset:  74%|███████▍  | 7400/10033 [00:06<00:01, 1372.66 examples/s]Applying chat template to train dataset:  64%|██████▍   | 6408/10033 [00:06<00:04, 881.44 examples/s] Applying chat template to train dataset:  79%|███████▉  | 7906/10033 [00:06<00:01, 1276.25 examples/s]Applying chat template to train dataset:  66%|██████▌   | 6602/10033 [00:06<00:03, 1075.52 examples/s]Applying chat template to train dataset:  77%|███████▋  | 7724/10033 [00:06<00:01, 1237.46 examples/s]Applying chat template to train dataset:  80%|████████  | 8065/10033 [00:06<00:01, 1287.48 examples/s]Applying chat template to train dataset:  67%|██████▋   | 6770/10033 [00:06<00:02, 1187.86 examples/s]Applying chat template to train dataset:  80%|███████▉  | 7996/10033 [00:06<00:01, 1360.90 examples/s]Applying chat template to train dataset:  83%|████████▎ | 8289/10033 [00:06<00:01, 1459.84 examples/s]Applying chat template to train dataset:  70%|██████▉   | 7010/10033 [00:06<00:02, 1461.55 examples/s]Applying chat template to train dataset:  81%|████████▏ | 8156/10033 [00:06<00:01, 1389.03 examples/s]Applying chat template to train dataset:  86%|████████▌ | 8607/10033 [00:06<00:00, 1623.12 examples/s]Applying chat template to train dataset:  73%|███████▎  | 7343/10033 [00:06<00:01, 1699.46 examples/s]Applying chat template to train dataset:  83%|████████▎ | 8333/10033 [00:06<00:01, 1465.94 examples/s]Applying chat template to train dataset:  88%|████████▊ | 8877/10033 [00:06<00:00, 1846.65 examples/s]Applying chat template to train dataset:  77%|███████▋  | 7677/10033 [00:06<00:01, 1305.64 examples/s]Applying chat template to train dataset:  86%|████████▌ | 8652/10033 [00:07<00:01, 1105.63 examples/s]Applying chat template to train dataset:  92%|█████████▏| 9202/10033 [00:07<00:00, 1396.09 examples/s]Applying chat template to train dataset:  79%|███████▉  | 7972/10033 [00:07<00:01, 1464.48 examples/s]Applying chat template to train dataset:  89%|████████▉ | 8907/10033 [00:07<00:00, 1338.22 examples/s]Applying chat template to train dataset:  94%|█████████▎| 9404/10033 [00:07<00:00, 1504.20 examples/s]Applying chat template to train dataset:  82%|████████▏ | 8209/10033 [00:07<00:01, 1632.52 examples/s]Applying chat template to train dataset:  92%|█████████▏| 9238/10033 [00:07<00:00, 1520.50 examples/s]Applying chat template to train dataset:  97%|█████████▋| 9727/10033 [00:07<00:00, 1605.05 examples/s]Applying chat template to train dataset:  84%|████████▍ | 8431/10033 [00:07<00:00, 1754.95 examples/s]Applying chat template to train dataset:  95%|█████████▌| 9570/10033 [00:07<00:00, 1510.27 examples/s]Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:07<00:00, 1531.70 examples/s]Applying chat template to train dataset:  87%|████████▋ | 8769/10033 [00:07<00:00, 1613.90 examples/s]Applying chat template to train dataset:  99%|█████████▊| 9902/10033 [00:07<00:00, 1657.96 examples/s]Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:07<00:00, 1280.70 examples/s]Applying chat template to train dataset:  91%|█████████ | 9110/10033 [00:07<00:00, 1539.20 examples/s]
Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:08<00:00, 1251.63 examples/s]
Applying chat template to train dataset:  93%|█████████▎| 9282/10033 [00:07<00:00, 1331.78 examples/s]Applying chat template to train dataset:  94%|█████████▍| 9451/10033 [00:08<00:00, 1342.11 examples/s]Applying chat template to train dataset:  97%|█████████▋| 9715/10033 [00:08<00:00, 1598.85 examples/s]Tokenizing train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:08<00:00, 1640.07 examples/s]Applying chat template to train dataset: 100%|██████████| 10033/10033 [00:08<00:00, 1198.63 examples/s]
Tokenizing train dataset:   0%|          | 42/10033 [00:00<00:24, 405.14 examples/s]Tokenizing train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/10033 [00:00<00:24, 407.94 examples/s]Tokenizing train dataset:   1%|          | 92/10033 [00:00<00:39, 249.18 examples/s]Tokenizing train dataset:   1%|▏         | 136/10033 [00:00<00:37, 262.87 examples/s]Tokenizing train dataset:   1%|          | 96/10033 [00:00<00:33, 292.28 examples/s]Tokenizing train dataset:   0%|          | 0/10033 [00:00<?, ? examples/s]Tokenizing train dataset:   2%|▏         | 176/10033 [00:00<00:37, 261.37 examples/s]Tokenizing train dataset:   1%|▏         | 135/10033 [00:00<00:36, 274.74 examples/s]Tokenizing train dataset:   0%|          | 42/10033 [00:00<00:24, 410.80 examples/s]Tokenizing train dataset:   2%|▏         | 218/10033 [00:00<00:37, 264.93 examples/s]Tokenizing train dataset:   2%|▏         | 166/10033 [00:00<00:51, 191.98 examples/s]Tokenizing train dataset:   3%|▎         | 252/10033 [00:01<00:43, 224.90 examples/s]Tokenizing train dataset:   2%|▏         | 191/10033 [00:00<00:48, 203.83 examples/s]Tokenizing train dataset:   1%|          | 92/10033 [00:00<00:47, 207.98 examples/s]Tokenizing train dataset:   3%|▎         | 282/10033 [00:01<00:40, 239.52 examples/s]Tokenizing train dataset:   2%|▏         | 226/10033 [00:01<00:47, 207.70 examples/s]Tokenizing train dataset:   1%|▏         | 126/10033 [00:00<00:47, 210.17 examples/s]Tokenizing train dataset:   3%|▎         | 321/10033 [00:01<00:39, 243.88 examples/s]Tokenizing train dataset:   2%|▏         | 250/10033 [00:01<00:46, 212.64 examples/s]Tokenizing train dataset:   2%|▏         | 154/10033 [00:00<00:44, 223.26 examples/s]Tokenizing train dataset:   3%|▎         | 347/10033 [00:01<00:39, 244.36 examples/s]Tokenizing train dataset:   3%|▎         | 282/10033 [00:01<00:40, 238.42 examples/s]Tokenizing train dataset:   2%|▏         | 179/10033 [00:00<00:43, 228.20 examples/s]Tokenizing train dataset:   4%|▍         | 384/10033 [00:01<00:40, 240.40 examples/s]Tokenizing train dataset:   3%|▎         | 320/10033 [00:01<00:40, 241.99 examples/s]Tokenizing train dataset:   2%|▏         | 221/10033 [00:00<00:40, 243.52 examples/s]Tokenizing train dataset:   4%|▍         | 420/10033 [00:01<00:40, 236.53 examples/s]Tokenizing train dataset:   3%|▎         | 349/10033 [00:01<00:43, 221.38 examples/s]Tokenizing train dataset:   3%|▎         | 257/10033 [00:01<00:41, 237.48 examples/s]Tokenizing train dataset:   4%|▍         | 450/10033 [00:01<00:43, 221.96 examples/s]Tokenizing train dataset:   4%|▍         | 385/10033 [00:01<00:42, 226.27 examples/s]Tokenizing train dataset:   3%|▎         | 298/10033 [00:01<00:39, 246.93 examples/s]Tokenizing train dataset:   5%|▍         | 485/10033 [00:02<00:45, 211.37 examples/s]Tokenizing train dataset:   4%|▍         | 417/10033 [00:02<01:02, 152.79 examples/s]Tokenizing train dataset:   3%|▎         | 332/10033 [00:01<00:58, 165.37 examples/s]Tokenizing train dataset:   5%|▌         | 517/10033 [00:02<00:55, 170.95 examples/s]Tokenizing train dataset:   4%|▍         | 437/10033 [00:02<00:59, 159.95 examples/s]Tokenizing train dataset:   4%|▎         | 364/10033 [00:01<01:08, 140.75 examples/s]Tokenizing train dataset:   5%|▌         | 536/10033 [00:02<01:12, 130.98 examples/s]Tokenizing train dataset:   5%|▍         | 469/10033 [00:02<01:13, 130.59 examples/s]Tokenizing train dataset:   4%|▍         | 387/10033 [00:02<01:03, 152.80 examples/s]Tokenizing train dataset:   6%|▌         | 552/10033 [00:02<01:20, 117.69 examples/s]Tokenizing train dataset:   5%|▍         | 500/10033 [00:02<01:10, 136.00 examples/s]Tokenizing train dataset:   6%|▌         | 569/10033 [00:02<01:16, 123.59 examples/s]Tokenizing train dataset:   4%|▍         | 418/10033 [00:02<01:08, 140.92 examples/s]Tokenizing train dataset:   5%|▌         | 527/10033 [00:02<01:00, 155.95 examples/s]Tokenizing train dataset:   6%|▌         | 596/10033 [00:03<01:03, 149.65 examples/s]Tokenizing train dataset:   4%|▍         | 440/10033 [00:02<01:03, 152.18 examples/s]Tokenizing train dataset:   6%|▌         | 555/10033 [00:02<00:53, 177.24 examples/s]Tokenizing train dataset:   6%|▌         | 617/10033 [00:03<00:58, 160.44 examples/s]Tokenizing train dataset:   5%|▍         | 472/10033 [00:02<00:52, 181.88 examples/s]Tokenizing train dataset:   6%|▌         | 580/10033 [00:03<00:49, 190.33 examples/s]Tokenizing train dataset:   6%|▋         | 644/10033 [00:03<00:50, 184.41 examples/s]Tokenizing train dataset:   5%|▍         | 495/10033 [00:02<00:49, 191.04 examples/s]Tokenizing train dataset:   6%|▌         | 610/10033 [00:03<00:44, 213.17 examples/s]Tokenizing train dataset:   7%|▋         | 671/10033 [00:03<00:45, 204.02 examples/s]Tokenizing train dataset:   5%|▌         | 519/10033 [00:02<00:47, 200.35 examples/s]Tokenizing train dataset:   7%|▋         | 694/10033 [00:03<00:44, 209.99 examples/s]Tokenizing train dataset:   6%|▋         | 644/10033 [00:03<00:39, 239.95 examples/s]Tokenizing train dataset:   5%|▌         | 548/10033 [00:02<00:43, 218.74 examples/s]Tokenizing train dataset:   7%|▋         | 730/10033 [00:03<00:43, 215.26 examples/s]Tokenizing train dataset:   7%|▋         | 677/10033 [00:03<00:44, 208.82 examples/s]Tokenizing train dataset:   6%|▌         | 580/10033 [00:02<00:46, 205.36 examples/s]Tokenizing train dataset:   8%|▊         | 759/10033 [00:03<00:39, 231.87 examples/s]Tokenizing train dataset:   6%|▌         | 606/10033 [00:03<00:43, 217.58 examples/s]Tokenizing train dataset:   7%|▋         | 716/10033 [00:03<00:42, 219.99 examples/s]Tokenizing train dataset:   8%|▊         | 789/10033 [00:03<00:42, 216.07 examples/s]Tokenizing train dataset:   6%|▋         | 641/10033 [00:03<00:37, 249.69 examples/s]Tokenizing train dataset:   7%|▋         | 740/10033 [00:03<00:43, 211.58 examples/s]Tokenizing train dataset:   8%|▊         | 821/10033 [00:04<00:46, 199.32 examples/s]Tokenizing train dataset:   7%|▋         | 671/10033 [00:03<00:48, 192.95 examples/s]Tokenizing train dataset:   8%|▊         | 771/10033 [00:04<01:00, 152.38 examples/s]Tokenizing train dataset:   8%|▊         | 850/10033 [00:04<00:53, 172.78 examples/s]Tokenizing train dataset:   7%|▋         | 699/10033 [00:03<00:50, 184.85 examples/s]Tokenizing train dataset:   8%|▊         | 795/10033 [00:04<00:55, 166.82 examples/s]Tokenizing train dataset:   9%|▊         | 873/10033 [00:04<00:50, 182.51 examples/s]Tokenizing train dataset:   7%|▋         | 720/10033 [00:03<00:49, 188.67 examples/s]Tokenizing train dataset:   8%|▊         | 824/10033 [00:04<00:49, 187.92 examples/s]Tokenizing train dataset:   9%|▉         | 910/10033 [00:04<00:40, 222.84 examples/s]Tokenizing train dataset:   7%|▋         | 750/10033 [00:03<00:43, 213.70 examples/s]Tokenizing train dataset:   9%|▊         | 857/10033 [00:04<00:56, 163.70 examples/s]Tokenizing train dataset:   9%|▉         | 940/10033 [00:04<00:53, 168.55 examples/s]Tokenizing train dataset:   8%|▊         | 780/10033 [00:04<00:56, 162.48 examples/s]Tokenizing train dataset:   9%|▉         | 885/10033 [00:04<00:49, 183.15 examples/s]Tokenizing train dataset:  10%|▉         | 971/10033 [00:04<00:46, 194.56 examples/s]Tokenizing train dataset:   8%|▊         | 802/10033 [00:04<00:53, 172.66 examples/s]Tokenizing train dataset:   9%|▉         | 907/10033 [00:04<01:01, 148.42 examples/s]Tokenizing train dataset:   8%|▊         | 831/10033 [00:04<01:05, 141.26 examples/s]Tokenizing train dataset:  10%|▉         | 1000/10033 [00:05<00:59, 152.92 examples/s]Tokenizing train dataset:   9%|▉         | 926/10033 [00:04<00:58, 155.93 examples/s]Tokenizing train dataset:   9%|▊         | 860/10033 [00:04<00:54, 166.95 examples/s]Tokenizing train dataset:  10%|█         | 1025/10033 [00:05<00:53, 167.70 examples/s]Tokenizing train dataset:   9%|▉         | 950/10033 [00:05<00:53, 170.89 examples/s]Tokenizing train dataset:   9%|▉         | 899/10033 [00:04<01:02, 146.86 examples/s]Tokenizing train dataset:  11%|█         | 1056/10033 [00:05<01:24, 105.91 examples/s]Tokenizing train dataset:  10%|▉         | 980/10033 [00:05<01:27, 103.10 examples/s]Tokenizing train dataset:   9%|▉         | 930/10033 [00:05<01:17, 117.91 examples/s]Tokenizing train dataset:  11%|█         | 1073/10033 [00:05<01:27, 102.39 examples/s]Tokenizing train dataset:  10%|▉         | 996/10033 [00:05<01:34, 95.20 examples/s] Tokenizing train dataset:  10%|▉         | 959/10033 [00:05<01:04, 141.30 examples/s]Tokenizing train dataset:  11%|█         | 1093/10033 [00:06<01:19, 112.53 examples/s]Tokenizing train dataset:  10%|█         | 1011/10033 [00:05<01:35, 94.90 examples/s]Tokenizing train dataset:  11%|█         | 1110/10033 [00:06<01:19, 112.48 examples/s]Tokenizing train dataset:  10%|▉         | 988/10033 [00:05<01:05, 138.91 examples/s]Tokenizing train dataset:  10%|█         | 1028/10033 [00:06<01:25, 105.74 examples/s]Tokenizing train dataset:  11%|█         | 1124/10033 [00:06<01:16, 115.76 examples/s]Tokenizing train dataset:  10%|█         | 1008/10033 [00:05<01:00, 148.86 examples/s]Tokenizing train dataset:  10%|█         | 1045/10033 [00:06<01:17, 115.67 examples/s]Tokenizing train dataset:  11%|█▏        | 1139/10033 [00:06<01:16, 116.72 examples/s]Tokenizing train dataset:  10%|█         | 1037/10033 [00:05<01:00, 148.90 examples/s]Tokenizing train dataset:  11%|█         | 1063/10033 [00:06<01:22, 108.28 examples/s]Tokenizing train dataset:  12%|█▏        | 1155/10033 [00:06<01:12, 123.07 examples/s]Tokenizing train dataset:  11%|█         | 1062/10033 [00:06<00:54, 165.98 examples/s]Tokenizing train dataset:  11%|█         | 1093/10033 [00:06<01:01, 146.06 examples/s]Tokenizing train dataset:  12%|█▏        | 1182/10033 [00:06<00:56, 156.19 examples/s]Tokenizing train dataset:  11%|█         | 1093/10033 [00:06<00:46, 193.97 examples/s]Tokenizing train dataset:  12%|█▏        | 1202/10033 [00:06<00:57, 154.09 examples/s]Tokenizing train dataset:  11%|█         | 1124/10033 [00:06<00:58, 152.90 examples/s]Tokenizing train dataset:  11%|█         | 1117/10033 [00:06<00:43, 204.31 examples/s]Tokenizing train dataset:  12%|█▏        | 1227/10033 [00:06<00:49, 176.84 examples/s]Tokenizing train dataset:  11%|█▏        | 1147/10033 [00:06<00:52, 167.99 examples/s]Tokenizing train dataset:  13%|█▎        | 1259/10033 [00:07<00:41, 212.33 examples/s]Tokenizing train dataset:  11%|█▏        | 1146/10033 [00:06<00:44, 197.64 examples/s]Tokenizing train dataset:  12%|█▏        | 1178/10033 [00:06<00:53, 166.15 examples/s]Tokenizing train dataset:  13%|█▎        | 1298/10033 [00:07<00:39, 223.34 examples/s]Tokenizing train dataset:  12%|█▏        | 1181/10033 [00:06<00:42, 207.16 examples/s]Tokenizing train dataset:  12%|█▏        | 1199/10033 [00:07<00:54, 161.16 examples/s]Tokenizing train dataset:  13%|█▎        | 1331/10033 [00:07<00:42, 204.71 examples/s]Tokenizing train dataset:  12%|█▏        | 1214/10033 [00:06<00:45, 192.04 examples/s]Tokenizing train dataset:  12%|█▏        | 1224/10033 [00:07<00:49, 179.77 examples/s]Tokenizing train dataset:  14%|█▎        | 1356/10033 [00:07<00:40, 212.79 examples/s]Tokenizing train dataset:  12%|█▏        | 1239/10033 [00:06<00:43, 201.24 examples/s]Tokenizing train dataset:  12%|█▏        | 1250/10033 [00:07<00:44, 195.76 examples/s]Tokenizing train dataset:  14%|█▍        | 1387/10033 [00:07<00:46, 187.72 examples/s]Tokenizing train dataset:  13%|█▎        | 1273/10033 [00:07<00:47, 182.51 examples/s]Tokenizing train dataset:  13%|█▎        | 1285/10033 [00:07<00:49, 176.33 examples/s]Tokenizing train dataset:  14%|█▍        | 1410/10033 [00:07<00:44, 194.81 examples/s]Tokenizing train dataset:  13%|█▎        | 1293/10033 [00:07<00:47, 183.72 examples/s]Tokenizing train dataset:  13%|█▎        | 1308/10033 [00:07<00:46, 186.98 examples/s]Tokenizing train dataset:  14%|█▍        | 1440/10033 [00:08<00:49, 172.24 examples/s]Tokenizing train dataset:  13%|█▎        | 1328/10033 [00:07<00:49, 177.10 examples/s]Tokenizing train dataset:  13%|█▎        | 1340/10033 [00:07<00:52, 165.86 examples/s]Tokenizing train dataset:  15%|█▍        | 1465/10033 [00:08<00:45, 188.29 examples/s]Tokenizing train dataset:  14%|█▎        | 1359/10033 [00:07<00:48, 179.45 examples/s]Tokenizing train dataset:  14%|█▎        | 1371/10033 [00:08<00:49, 175.12 examples/s]Tokenizing train dataset:  15%|█▍        | 1495/10033 [00:08<00:44, 189.97 examples/s]Tokenizing train dataset:  14%|█▍        | 1390/10033 [00:07<00:51, 167.70 examples/s]Tokenizing train dataset:  14%|█▍        | 1403/10033 [00:08<00:59, 145.40 examples/s]Tokenizing train dataset:  15%|█▌        | 1530/10033 [00:08<00:56, 150.05 examples/s]Tokenizing train dataset:  14%|█▍        | 1422/10033 [00:07<00:52, 164.89 examples/s]Tokenizing train dataset:  14%|█▍        | 1420/10033 [00:08<00:58, 146.27 examples/s]Tokenizing train dataset:  15%|█▌        | 1553/10033 [00:08<00:51, 163.46 examples/s]Tokenizing train dataset:  14%|█▍        | 1448/10033 [00:08<00:47, 182.33 examples/s]Tokenizing train dataset:  14%|█▍        | 1450/10033 [00:08<00:57, 149.04 examples/s]Tokenizing train dataset:  16%|█▌        | 1586/10033 [00:08<00:52, 161.98 examples/s]Tokenizing train dataset:  15%|█▍        | 1480/10033 [00:08<00:49, 174.10 examples/s]Tokenizing train dataset:  15%|█▍        | 1477/10033 [00:08<00:49, 171.95 examples/s]Tokenizing train dataset:  16%|█▌        | 1605/10033 [00:09<00:50, 165.81 examples/s]Tokenizing train dataset:  15%|█▍        | 1498/10033 [00:08<00:47, 179.01 examples/s]Tokenizing train dataset:  15%|█▌        | 1510/10033 [00:08<00:47, 180.14 examples/s]Tokenizing train dataset:  16%|█▌        | 1630/10033 [00:09<00:46, 181.68 examples/s]Tokenizing train dataset:  15%|█▌        | 1526/10033 [00:08<00:42, 199.54 examples/s]Tokenizing train dataset:  15%|█▌        | 1539/10033 [00:08<00:42, 201.42 examples/s]Tokenizing train dataset:  16%|█▋        | 1650/10033 [00:09<00:46, 178.72 examples/s]Tokenizing train dataset:  16%|█▌        | 1559/10033 [00:09<00:41, 203.53 examples/s]Tokenizing train dataset:  16%|█▌        | 1570/10033 [00:08<00:51, 163.34 examples/s]Tokenizing train dataset:  16%|█▌        | 1591/10033 [00:08<00:49, 171.52 examples/s]Tokenizing train dataset:  17%|█▋        | 1686/10033 [00:09<00:58, 143.53 examples/s]Tokenizing train dataset:  16%|█▌        | 1590/10033 [00:09<00:50, 166.16 examples/s]Tokenizing train dataset:  16%|█▌        | 1623/10033 [00:08<00:41, 201.38 examples/s]Tokenizing train dataset:  17%|█▋        | 1720/10033 [00:09<00:47, 176.17 examples/s]Tokenizing train dataset:  16%|█▌        | 1610/10033 [00:09<00:54, 153.88 examples/s]Tokenizing train dataset:  16%|█▋        | 1650/10033 [00:09<00:38, 215.40 examples/s]Tokenizing train dataset:  17%|█▋        | 1749/10033 [00:09<00:41, 197.76 examples/s]Tokenizing train dataset:  16%|█▌        | 1627/10033 [00:09<00:56, 148.77 examples/s]Tokenizing train dataset:  17%|█▋        | 1686/10033 [00:09<00:39, 210.75 examples/s]Tokenizing train dataset:  18%|█▊        | 1783/10033 [00:09<00:41, 196.88 examples/s]Tokenizing train dataset:  16%|█▋        | 1646/10033 [00:09<00:59, 140.17 examples/s]Tokenizing train dataset:  17%|█▋        | 1710/10033 [00:09<00:38, 213.77 examples/s]Tokenizing train dataset:  17%|█▋        | 1661/10033 [00:09<01:04, 129.86 examples/s]Tokenizing train dataset:  18%|█▊        | 1816/10033 [00:10<00:45, 179.91 examples/s]Tokenizing train dataset:  17%|█▋        | 1692/10033 [00:10<00:49, 168.17 examples/s]Tokenizing train dataset:  17%|█▋        | 1742/10033 [00:09<00:47, 176.14 examples/s]Tokenizing train dataset:  18%|█▊        | 1850/10033 [00:10<00:44, 183.56 examples/s]Tokenizing train dataset:  17%|█▋        | 1713/10033 [00:10<00:46, 177.56 examples/s]Tokenizing train dataset:  18%|█▊        | 1769/10033 [00:09<00:42, 192.95 examples/s]Tokenizing train dataset:  19%|█▊        | 1880/10033 [00:10<00:44, 184.25 examples/s]Tokenizing train dataset:  17%|█▋        | 1745/10033 [00:10<00:45, 180.58 examples/s]Tokenizing train dataset:  18%|█▊        | 1800/10033 [00:09<00:43, 191.15 examples/s]Tokenizing train dataset:  19%|█▉        | 1923/10033 [00:10<00:41, 196.10 examples/s]Tokenizing train dataset:  18%|█▊        | 1766/10033 [00:10<00:55, 147.78 examples/s]Tokenizing train dataset:  19%|█▉        | 1944/10033 [00:10<00:40, 198.06 examples/s]Tokenizing train dataset:  18%|█▊        | 1834/10033 [00:10<00:50, 161.96 examples/s]Tokenizing train dataset:  18%|█▊        | 1789/10033 [00:10<00:50, 163.84 examples/s]Tokenizing train dataset:  20%|█▉        | 1972/10033 [00:10<00:37, 215.30 examples/s]Tokenizing train dataset:  19%|█▊        | 1860/10033 [00:10<00:46, 177.56 examples/s]Tokenizing train dataset:  18%|█▊        | 1816/10033 [00:10<00:43, 187.09 examples/s]Tokenizing train dataset:  20%|█▉        | 1999/10033 [00:10<00:35, 225.79 examples/s]Tokenizing train dataset:  19%|█▉        | 1889/10033 [00:10<00:40, 199.86 examples/s]Tokenizing train dataset:  18%|█▊        | 1847/10033 [00:10<00:37, 217.11 examples/s]Tokenizing train dataset:  19%|█▉        | 1926/10033 [00:10<00:34, 237.88 examples/s]Tokenizing train dataset:  20%|██        | 2040/10033 [00:11<00:33, 240.79 examples/s]Tokenizing train dataset:  19%|█▊        | 1873/10033 [00:10<00:36, 225.74 examples/s]Tokenizing train dataset:  19%|█▉        | 1956/10033 [00:10<00:32, 250.20 examples/s]Tokenizing train dataset:  21%|██        | 2070/10033 [00:11<00:31, 252.90 examples/s]Tokenizing train dataset:  19%|█▉        | 1920/10033 [00:11<00:32, 252.63 examples/s]Tokenizing train dataset:  21%|██        | 2096/10033 [00:11<00:31, 253.20 examples/s]Tokenizing train dataset:  20%|█▉        | 2000/10033 [00:10<00:30, 261.19 examples/s]Tokenizing train dataset:  19%|█▉        | 1949/10033 [00:11<00:31, 258.48 examples/s]Tokenizing train dataset:  21%|██▏       | 2136/10033 [00:11<00:31, 251.79 examples/s]Tokenizing train dataset:  20%|█▉        | 1980/10033 [00:11<00:30, 266.88 examples/s]Tokenizing train dataset:  20%|██        | 2048/10033 [00:10<00:28, 276.55 examples/s]Tokenizing train dataset:  22%|██▏       | 2175/10033 [00:11<00:36, 217.58 examples/s]Tokenizing train dataset:  20%|██        | 2020/10033 [00:11<00:35, 224.18 examples/s]Tokenizing train dataset:  21%|██        | 2088/10033 [00:11<00:33, 234.21 examples/s]Tokenizing train dataset:  22%|██▏       | 2212/10033 [00:11<00:37, 208.29 examples/s]Tokenizing train dataset:  21%|██        | 2062/10033 [00:11<00:36, 219.34 examples/s]Tokenizing train dataset:  21%|██        | 2125/10033 [00:11<00:35, 225.84 examples/s]Tokenizing train dataset:  22%|██▏       | 2249/10033 [00:12<00:32, 239.41 examples/s]Tokenizing train dataset:  21%|██        | 2092/10033 [00:11<00:33, 234.27 examples/s]Tokenizing train dataset:  21%|██▏       | 2151/10033 [00:11<00:33, 232.18 examples/s]Tokenizing train dataset:  23%|██▎       | 2285/10033 [00:12<00:29, 261.90 examples/s]Tokenizing train dataset:  21%|██▏       | 2134/10033 [00:12<00:32, 246.74 examples/s]Tokenizing train dataset:  22%|██▏       | 2188/10033 [00:11<00:33, 235.02 examples/s]Tokenizing train dataset:  23%|██▎       | 2320/10033 [00:12<00:35, 215.41 examples/s]Tokenizing train dataset:  22%|██▏       | 2172/10033 [00:12<00:37, 209.43 examples/s]Tokenizing train dataset:  22%|██▏       | 2224/10033 [00:11<00:40, 191.76 examples/s]Tokenizing train dataset:  23%|██▎       | 2349/10033 [00:12<00:33, 228.20 examples/s]Tokenizing train dataset:  22%|██▏       | 2250/10033 [00:11<00:38, 203.40 examples/s]Tokenizing train dataset:  22%|██▏       | 2212/10033 [00:12<00:35, 222.68 examples/s]Tokenizing train dataset:  24%|██▍       | 2392/10033 [00:12<00:33, 230.08 examples/s]Tokenizing train dataset:  23%|██▎       | 2283/10033 [00:12<00:33, 229.56 examples/s]Tokenizing train dataset:  22%|██▏       | 2241/10033 [00:12<00:33, 235.65 examples/s]Tokenizing train dataset:  24%|██▍       | 2434/10033 [00:12<00:36, 211.04 examples/s]Tokenizing train dataset:  23%|██▎       | 2317/10033 [00:12<00:41, 184.87 examples/s]Tokenizing train dataset:  23%|██▎       | 2339/10033 [00:12<00:40, 189.78 examples/s]Tokenizing train dataset:  23%|██▎       | 2284/10033 [00:12<00:43, 179.29 examples/s]Tokenizing train dataset:  25%|██▍       | 2475/10033 [00:13<00:34, 216.77 examples/s]Tokenizing train dataset:  24%|██▎       | 2373/10033 [00:12<00:38, 199.20 examples/s]Tokenizing train dataset:  23%|██▎       | 2319/10033 [00:13<00:40, 189.10 examples/s]Tokenizing train dataset:  25%|██▌       | 2510/10033 [00:13<00:35, 213.65 examples/s]Tokenizing train dataset:  25%|██▌       | 2534/10033 [00:13<00:34, 215.18 examples/s]Tokenizing train dataset:  24%|██▍       | 2412/10033 [00:12<00:35, 214.70 examples/s]Tokenizing train dataset:  23%|██▎       | 2354/10033 [00:13<00:39, 193.50 examples/s]Tokenizing train dataset:  26%|██▌       | 2577/10033 [00:13<00:32, 226.98 examples/s]Tokenizing train dataset:  24%|██▍       | 2450/10033 [00:12<00:36, 209.67 examples/s]Tokenizing train dataset:  24%|██▍       | 2395/10033 [00:13<00:38, 199.11 examples/s]Tokenizing train dataset:  26%|██▌       | 2604/10033 [00:13<00:31, 234.08 examples/s]Tokenizing train dataset:  25%|██▍       | 2483/10033 [00:13<00:32, 233.29 examples/s]Tokenizing train dataset:  24%|██▍       | 2432/10033 [00:13<00:33, 229.53 examples/s]Tokenizing train dataset:  25%|██▍       | 2466/10033 [00:13<00:30, 251.12 examples/s]Tokenizing train dataset:  26%|██▋       | 2638/10033 [00:13<00:32, 229.28 examples/s]Tokenizing train dataset:  25%|██▌       | 2528/10033 [00:13<00:29, 251.67 examples/s]Tokenizing train dataset:  25%|██▍       | 2500/10033 [00:13<00:31, 236.51 examples/s]Tokenizing train dataset:  27%|██▋       | 2672/10033 [00:13<00:33, 217.52 examples/s]Tokenizing train dataset:  26%|██▌       | 2568/10033 [00:13<00:29, 254.35 examples/s]Tokenizing train dataset:  25%|██▌       | 2542/10033 [00:13<00:35, 208.34 examples/s]Tokenizing train dataset:  27%|██▋       | 2712/10033 [00:14<00:38, 187.73 examples/s]Tokenizing train dataset:  26%|██▌       | 2602/10033 [00:13<00:40, 181.75 examples/s]Tokenizing train dataset:  26%|██▌       | 2577/10033 [00:14<00:31, 233.16 examples/s]Tokenizing train dataset:  27%|██▋       | 2746/10033 [00:14<00:38, 187.18 examples/s]Tokenizing train dataset:  26%|██▋       | 2637/10033 [00:13<00:38, 191.97 examples/s]Tokenizing train dataset:  26%|██▌       | 2618/10033 [00:14<00:30, 242.35 examples/s]Tokenizing train dataset:  28%|██▊       | 2781/10033 [00:14<00:33, 216.10 examples/s]Tokenizing train dataset:  27%|██▋       | 2670/10033 [00:13<00:40, 184.03 examples/s]Tokenizing train dataset:  26%|██▋       | 2648/10033 [00:14<00:34, 212.00 examples/s]Tokenizing train dataset:  28%|██▊       | 2823/10033 [00:14<00:31, 230.54 examples/s]Tokenizing train dataset:  27%|██▋       | 2694/10033 [00:14<00:37, 193.14 examples/s]Tokenizing train dataset:  27%|██▋       | 2684/10033 [00:14<00:33, 217.08 examples/s]Tokenizing train dataset:  28%|██▊       | 2857/10033 [00:14<00:31, 227.14 examples/s]Tokenizing train dataset:  27%|██▋       | 2716/10033 [00:14<00:38, 188.12 examples/s]Tokenizing train dataset:  27%|██▋       | 2714/10033 [00:14<00:31, 233.26 examples/s]Tokenizing train dataset:  29%|██▉       | 2893/10033 [00:14<00:28, 252.51 examples/s]Tokenizing train dataset:  27%|██▋       | 2739/10033 [00:14<00:37, 193.77 examples/s]Tokenizing train dataset:  29%|██▉       | 2924/10033 [00:15<00:26, 264.10 examples/s]Tokenizing train dataset:  27%|██▋       | 2753/10033 [00:14<00:30, 239.22 examples/s]Tokenizing train dataset:  28%|██▊       | 2773/10033 [00:14<00:37, 193.85 examples/s]Tokenizing train dataset:  30%|██▉       | 2969/10033 [00:15<00:25, 272.05 examples/s]Tokenizing train dataset:  28%|██▊       | 2791/10033 [00:15<00:31, 228.73 examples/s]Tokenizing train dataset:  28%|██▊       | 2808/10033 [00:14<00:31, 226.15 examples/s]Tokenizing train dataset:  30%|██▉       | 2999/10033 [00:15<00:25, 276.68 examples/s]Tokenizing train dataset:  28%|██▊       | 2828/10033 [00:15<00:28, 256.64 examples/s]Tokenizing train dataset:  28%|██▊       | 2843/10033 [00:14<00:33, 215.40 examples/s]Tokenizing train dataset:  30%|███       | 3036/10033 [00:15<00:28, 248.11 examples/s]Tokenizing train dataset:  29%|██▊       | 2860/10033 [00:15<00:30, 235.36 examples/s]Tokenizing train dataset:  29%|██▊       | 2866/10033 [00:14<00:33, 217.02 examples/s]Tokenizing train dataset:  31%|███       | 3072/10033 [00:15<00:34, 204.33 examples/s]Tokenizing train dataset:  29%|██▉       | 2900/10033 [00:15<00:36, 193.08 examples/s]Tokenizing train dataset:  29%|██▉       | 2906/10033 [00:15<00:38, 186.33 examples/s]Tokenizing train dataset:  31%|███       | 3109/10033 [00:15<00:29, 234.83 examples/s]Tokenizing train dataset:  29%|██▉       | 2924/10033 [00:16<01:14, 95.16 examples/s] Tokenizing train dataset:  29%|██▉       | 2947/10033 [00:15<01:11, 99.36 examples/s] Tokenizing train dataset:  29%|██▉       | 2946/10033 [00:16<01:08, 103.94 examples/s]Tokenizing train dataset:  31%|███▏      | 3144/10033 [00:16<01:09, 99.47 examples/s] Tokenizing train dataset:  30%|██▉       | 2967/10033 [00:16<01:07, 105.37 examples/s]Tokenizing train dataset:  30%|██▉       | 2974/10033 [00:16<00:55, 126.62 examples/s]Tokenizing train dataset:  32%|███▏      | 3165/10033 [00:16<01:03, 108.29 examples/s]Tokenizing train dataset:  30%|██▉       | 2990/10033 [00:16<00:58, 120.32 examples/s]Tokenizing train dataset:  30%|██▉       | 2997/10033 [00:16<00:54, 127.93 examples/s]Tokenizing train dataset:  30%|██▉       | 3009/10033 [00:16<01:01, 113.75 examples/s]Tokenizing train dataset:  32%|███▏      | 3203/10033 [00:17<00:57, 118.05 examples/s]Tokenizing train dataset:  30%|███       | 3016/10033 [00:16<00:56, 123.26 examples/s]Tokenizing train dataset:  30%|███       | 3028/10033 [00:16<01:00, 116.47 examples/s]Tokenizing train dataset:  32%|███▏      | 3223/10033 [00:17<00:55, 122.41 examples/s]Tokenizing train dataset:  30%|███       | 3034/10033 [00:17<01:00, 115.96 examples/s]Tokenizing train dataset:  30%|███       | 3045/10033 [00:16<01:00, 114.96 examples/s]Tokenizing train dataset:  32%|███▏      | 3246/10033 [00:17<00:54, 123.64 examples/s]Tokenizing train dataset:  30%|███       | 3053/10033 [00:17<00:56, 124.45 examples/s]Tokenizing train dataset:  31%|███       | 3068/10033 [00:16<00:51, 134.99 examples/s]Tokenizing train dataset:  33%|███▎      | 3276/10033 [00:17<00:44, 151.60 examples/s]Tokenizing train dataset:  31%|███       | 3083/10033 [00:17<00:43, 158.83 examples/s]Tokenizing train dataset:  31%|███       | 3088/10033 [00:16<00:48, 143.52 examples/s]Tokenizing train dataset:  33%|███▎      | 3305/10033 [00:17<00:38, 176.52 examples/s]Tokenizing train dataset:  31%|███       | 3114/10033 [00:17<00:36, 189.95 examples/s]Tokenizing train dataset:  31%|███       | 3112/10033 [00:17<00:42, 164.35 examples/s]Tokenizing train dataset:  33%|███▎      | 3332/10033 [00:17<00:34, 195.49 examples/s]Tokenizing train dataset:  31%|███▏      | 3142/10033 [00:17<00:32, 210.10 examples/s]Tokenizing train dataset:  34%|███▎      | 3367/10033 [00:17<00:29, 229.34 examples/s]Tokenizing train dataset:  31%|███▏      | 3150/10033 [00:17<00:36, 189.87 examples/s]Tokenizing train dataset:  32%|███▏      | 3173/10033 [00:17<00:29, 232.71 examples/s]Tokenizing train dataset:  34%|███▍      | 3407/10033 [00:17<00:24, 268.53 examples/s]Tokenizing train dataset:  32%|███▏      | 3176/10033 [00:17<00:33, 205.13 examples/s]Tokenizing train dataset:  32%|███▏      | 3215/10033 [00:17<00:27, 245.43 examples/s]Tokenizing train dataset:  34%|███▍      | 3447/10033 [00:18<00:27, 235.26 examples/s]Tokenizing train dataset:  32%|███▏      | 3214/10033 [00:17<00:34, 199.68 examples/s]Tokenizing train dataset:  32%|███▏      | 3259/10033 [00:17<00:26, 258.46 examples/s]Tokenizing train dataset:  35%|███▍      | 3485/10033 [00:18<00:27, 235.28 examples/s]Tokenizing train dataset:  32%|███▏      | 3253/10033 [00:17<00:32, 208.73 examples/s]Tokenizing train dataset:  33%|███▎      | 3294/10033 [00:18<00:28, 233.55 examples/s]Tokenizing train dataset:  35%|███▌      | 3528/10033 [00:18<00:26, 243.77 examples/s]Tokenizing train dataset:  33%|███▎      | 3288/10033 [00:17<00:34, 196.71 examples/s]Tokenizing train dataset:  35%|███▌      | 3555/10033 [00:18<00:26, 248.07 examples/s]Tokenizing train dataset:  33%|███▎      | 3328/10033 [00:18<00:33, 201.16 examples/s]Tokenizing train dataset:  33%|███▎      | 3350/10033 [00:18<00:32, 203.10 examples/s]Tokenizing train dataset:  33%|███▎      | 3321/10033 [00:18<00:34, 191.98 examples/s]Tokenizing train dataset:  36%|███▌      | 3601/10033 [00:18<00:24, 264.54 examples/s]Tokenizing train dataset:  34%|███▍      | 3388/10033 [00:18<00:27, 241.17 examples/s]Tokenizing train dataset:  33%|███▎      | 3354/10033 [00:18<00:30, 217.92 examples/s]Tokenizing train dataset:  36%|███▌      | 3635/10033 [00:18<00:22, 278.84 examples/s]Tokenizing train dataset:  34%|███▍      | 3430/10033 [00:18<00:27, 236.96 examples/s]Tokenizing train dataset:  34%|███▍      | 3394/10033 [00:18<00:29, 222.14 examples/s]Tokenizing train dataset:  37%|███▋      | 3670/10033 [00:18<00:25, 246.05 examples/s]Tokenizing train dataset:  35%|███▍      | 3470/10033 [00:18<00:30, 213.09 examples/s]Tokenizing train dataset:  34%|███▍      | 3433/10033 [00:18<00:34, 193.94 examples/s]Tokenizing train dataset:  37%|███▋      | 3707/10033 [00:19<00:30, 210.65 examples/s]Tokenizing train dataset:  35%|███▌      | 3512/10033 [00:19<00:31, 208.12 examples/s]Tokenizing train dataset:  35%|███▍      | 3469/10033 [00:18<00:33, 193.34 examples/s]Tokenizing train dataset:  37%|███▋      | 3749/10033 [00:19<00:31, 197.42 examples/s]Tokenizing train dataset:  35%|███▌      | 3548/10033 [00:19<00:30, 210.76 examples/s]Tokenizing train dataset:  35%|███▍      | 3508/10033 [00:18<00:31, 204.18 examples/s]Tokenizing train dataset:  38%|███▊      | 3781/10033 [00:19<00:28, 218.57 examples/s]Tokenizing train dataset:  36%|███▌      | 3581/10033 [00:19<00:27, 232.69 examples/s]Tokenizing train dataset:  35%|███▌      | 3545/10033 [00:19<00:31, 207.03 examples/s]Tokenizing train dataset:  36%|███▌      | 3615/10033 [00:19<00:25, 253.35 examples/s]Tokenizing train dataset:  38%|███▊      | 3820/10033 [00:19<00:28, 214.44 examples/s]Tokenizing train dataset:  36%|███▌      | 3582/10033 [00:19<00:32, 199.61 examples/s]Tokenizing train dataset:  36%|███▋      | 3651/10033 [00:19<00:29, 213.06 examples/s]Tokenizing train dataset:  38%|███▊      | 3858/10033 [00:19<00:31, 192.99 examples/s]Tokenizing train dataset:  36%|███▌      | 3611/10033 [00:19<00:29, 215.11 examples/s]Tokenizing train dataset:  39%|███▊      | 3885/10033 [00:20<00:29, 205.58 examples/s]Tokenizing train dataset:  37%|███▋      | 3691/10033 [00:19<00:28, 226.14 examples/s]Tokenizing train dataset:  36%|███▋      | 3643/10033 [00:19<00:26, 236.84 examples/s]Tokenizing train dataset:  37%|███▋      | 3720/10033 [00:20<00:26, 237.74 examples/s]Tokenizing train dataset:  39%|███▉      | 3919/10033 [00:20<00:29, 204.67 examples/s]Tokenizing train dataset:  37%|███▋      | 3680/10033 [00:19<00:26, 235.54 examples/s]Tokenizing train dataset:  37%|███▋      | 3747/10033 [00:20<00:25, 243.79 examples/s]Tokenizing train dataset:  39%|███▉      | 3960/10033 [00:20<00:29, 203.37 examples/s]Tokenizing train dataset:  37%|███▋      | 3722/10033 [00:19<00:26, 235.09 examples/s]Tokenizing train dataset:  38%|███▊      | 3786/10033 [00:20<00:25, 246.73 examples/s]Tokenizing train dataset:  40%|███▉      | 3992/10033 [00:20<00:26, 224.61 examples/s]Tokenizing train dataset:  37%|███▋      | 3755/10033 [00:19<00:24, 253.76 examples/s]Tokenizing train dataset:  38%|███▊      | 3830/10033 [00:20<00:24, 257.80 examples/s]Tokenizing train dataset:  40%|████      | 4034/10033 [00:20<00:25, 238.06 examples/s]Tokenizing train dataset:  38%|███▊      | 3792/10033 [00:20<00:25, 249.33 examples/s]Tokenizing train dataset:  39%|███▊      | 3864/10033 [00:20<00:22, 273.57 examples/s]Tokenizing train dataset:  41%|████      | 4069/10033 [00:20<00:22, 261.71 examples/s]Tokenizing train dataset:  38%|███▊      | 3824/10033 [00:20<00:23, 262.45 examples/s]Tokenizing train dataset:  39%|███▉      | 3900/10033 [00:21<00:41, 146.95 examples/s]Tokenizing train dataset:  41%|████      | 4105/10033 [00:21<00:40, 146.05 examples/s]Tokenizing train dataset:  38%|███▊      | 3859/10033 [00:20<00:45, 134.86 examples/s]Tokenizing train dataset:  39%|███▉      | 3934/10033 [00:21<00:40, 149.35 examples/s]Tokenizing train dataset:  41%|████▏     | 4141/10033 [00:21<00:41, 142.73 examples/s]Tokenizing train dataset:  39%|███▉      | 3895/10033 [00:21<00:45, 134.41 examples/s]Tokenizing train dataset:  40%|███▉      | 3972/10033 [00:21<00:38, 157.44 examples/s]Tokenizing train dataset:  42%|████▏     | 4170/10033 [00:21<00:35, 163.30 examples/s]Tokenizing train dataset:  39%|███▉      | 3920/10033 [00:21<00:40, 149.79 examples/s]Tokenizing train dataset:  42%|████▏     | 4192/10033 [00:21<00:36, 161.45 examples/s]Tokenizing train dataset:  40%|███▉      | 4010/10033 [00:21<00:35, 171.60 examples/s]Tokenizing train dataset:  40%|████      | 4033/10033 [00:21<00:34, 172.13 examples/s]Tokenizing train dataset:  39%|███▉      | 3959/10033 [00:21<00:39, 152.97 examples/s]Tokenizing train dataset:  42%|████▏     | 4230/10033 [00:22<00:33, 172.69 examples/s]Tokenizing train dataset:  40%|████      | 4053/10033 [00:21<00:35, 167.05 examples/s]Tokenizing train dataset:  40%|███▉      | 3994/10033 [00:21<00:38, 155.84 examples/s]Tokenizing train dataset:  41%|████      | 4083/10033 [00:22<00:31, 191.37 examples/s]Tokenizing train dataset:  43%|████▎     | 4267/10033 [00:22<00:33, 173.69 examples/s]Tokenizing train dataset:  40%|████      | 4026/10033 [00:21<00:33, 181.89 examples/s]Tokenizing train dataset:  41%|████      | 4114/10033 [00:22<00:27, 215.12 examples/s]Tokenizing train dataset:  43%|████▎     | 4287/10033 [00:22<00:37, 153.44 examples/s]Tokenizing train dataset:  40%|████      | 4062/10033 [00:21<00:32, 184.57 examples/s]Tokenizing train dataset:  43%|████▎     | 4308/10033 [00:22<00:35, 159.47 examples/s]Tokenizing train dataset:  41%|████▏     | 4149/10033 [00:22<00:31, 187.02 examples/s]Tokenizing train dataset:  43%|████▎     | 4329/10033 [00:22<00:33, 168.72 examples/s]Tokenizing train dataset:  41%|████      | 4097/10033 [00:22<00:30, 194.13 examples/s]Tokenizing train dataset:  42%|████▏     | 4177/10033 [00:22<00:28, 205.16 examples/s]Tokenizing train dataset:  43%|████▎     | 4361/10033 [00:22<00:28, 201.80 examples/s]Tokenizing train dataset:  41%|████      | 4128/10033 [00:22<00:27, 216.04 examples/s]Tokenizing train dataset:  42%|████▏     | 4210/10033 [00:22<00:25, 232.86 examples/s]Tokenizing train dataset:  44%|████▍     | 4396/10033 [00:22<00:23, 236.07 examples/s]Tokenizing train dataset:  41%|████▏     | 4154/10033 [00:22<00:26, 224.82 examples/s]Tokenizing train dataset:  42%|████▏     | 4240/10033 [00:22<00:23, 246.62 examples/s]Tokenizing train dataset:  44%|████▍     | 4435/10033 [00:23<00:23, 233.90 examples/s]Tokenizing train dataset:  42%|████▏     | 4191/10033 [00:22<00:25, 228.83 examples/s]Tokenizing train dataset:  43%|████▎     | 4280/10033 [00:22<00:23, 248.64 examples/s]Tokenizing train dataset:  45%|████▍     | 4470/10033 [00:23<00:21, 259.76 examples/s]Tokenizing train dataset:  42%|████▏     | 4226/10033 [00:22<00:22, 254.18 examples/s]Tokenizing train dataset:  43%|████▎     | 4313/10033 [00:22<00:21, 266.16 examples/s]Tokenizing train dataset:  45%|████▍     | 4507/10033 [00:23<00:23, 232.60 examples/s]Tokenizing train dataset:  42%|████▏     | 4260/10033 [00:22<00:26, 214.28 examples/s]Tokenizing train dataset:  43%|████▎     | 4348/10033 [00:23<00:27, 209.19 examples/s]Tokenizing train dataset:  45%|████▌     | 4541/10033 [00:23<00:21, 254.92 examples/s]Tokenizing train dataset:  43%|████▎     | 4290/10033 [00:22<00:24, 229.87 examples/s]Tokenizing train dataset:  44%|████▎     | 4375/10033 [00:23<00:25, 220.94 examples/s]Tokenizing train dataset:  43%|████▎     | 4320/10033 [00:22<00:23, 244.57 examples/s]Tokenizing train dataset:  46%|████▌     | 4581/10033 [00:23<00:21, 256.68 examples/s]Tokenizing train dataset:  44%|████▍     | 4413/10033 [00:23<00:25, 216.99 examples/s]Tokenizing train dataset:  43%|████▎     | 4363/10033 [00:23<00:22, 254.90 examples/s]Tokenizing train dataset:  46%|████▌     | 4622/10033 [00:23<00:20, 258.98 examples/s]Tokenizing train dataset:  44%|████▍     | 4450/10033 [00:23<00:27, 199.62 examples/s]Tokenizing train dataset:  44%|████▍     | 4403/10033 [00:23<00:28, 196.83 examples/s]Tokenizing train dataset:  46%|████▋     | 4654/10033 [00:24<00:29, 179.43 examples/s]Tokenizing train dataset:  45%|████▍     | 4489/10033 [00:23<00:27, 203.15 examples/s]Tokenizing train dataset:  44%|████▍     | 4433/10033 [00:23<00:25, 215.72 examples/s]Tokenizing train dataset:  47%|████▋     | 4684/10033 [00:24<00:26, 198.60 examples/s]Tokenizing train dataset:  45%|████▌     | 4523/10033 [00:24<00:26, 205.81 examples/s]Tokenizing train dataset:  45%|████▍     | 4470/10033 [00:23<00:25, 222.22 examples/s]Tokenizing train dataset:  47%|████▋     | 4716/10033 [00:24<00:29, 177.93 examples/s]Tokenizing train dataset:  45%|████▌     | 4545/10033 [00:24<00:28, 189.27 examples/s]Tokenizing train dataset:  45%|████▍     | 4505/10033 [00:23<00:27, 201.57 examples/s]Tokenizing train dataset:  47%|████▋     | 4743/10033 [00:24<00:27, 194.10 examples/s]Tokenizing train dataset:  46%|████▌     | 4569/10033 [00:24<00:27, 197.77 examples/s]Tokenizing train dataset:  45%|████▌     | 4530/10033 [00:23<00:26, 209.44 examples/s]Tokenizing train dataset:  48%|████▊     | 4773/10033 [00:24<00:29, 175.55 examples/s]Tokenizing train dataset:  46%|████▌     | 4604/10033 [00:24<00:30, 180.48 examples/s]Tokenizing train dataset:  46%|████▌     | 4568/10033 [00:24<00:27, 196.55 examples/s]Tokenizing train dataset:  48%|████▊     | 4793/10033 [00:24<00:30, 174.66 examples/s]Tokenizing train dataset:  46%|████▌     | 4623/10033 [00:24<00:37, 142.92 examples/s]Tokenizing train dataset:  48%|████▊     | 4822/10033 [00:25<00:32, 161.90 examples/s]Tokenizing train dataset:  46%|████▋     | 4641/10033 [00:24<00:36, 148.91 examples/s]Tokenizing train dataset:  46%|████▌     | 4600/10033 [00:24<00:32, 166.60 examples/s]Tokenizing train dataset:  48%|████▊     | 4859/10033 [00:25<00:25, 200.58 examples/s]Tokenizing train dataset:  46%|████▋     | 4658/10033 [00:24<00:35, 152.27 examples/s]Tokenizing train dataset:  46%|████▌     | 4620/10033 [00:24<00:32, 165.40 examples/s]Tokenizing train dataset:  49%|████▊     | 4886/10033 [00:25<00:26, 193.04 examples/s]Tokenizing train dataset:  47%|████▋     | 4675/10033 [00:25<00:38, 139.99 examples/s]Tokenizing train dataset:  49%|████▉     | 4930/10033 [00:25<00:20, 246.09 examples/s]Tokenizing train dataset:  46%|████▋     | 4650/10033 [00:24<00:33, 160.34 examples/s]Tokenizing train dataset:  47%|████▋     | 4695/10033 [00:25<00:35, 151.81 examples/s]Tokenizing train dataset:  49%|████▉     | 4960/10033 [00:25<00:21, 235.59 examples/s]Tokenizing train dataset:  47%|████▋     | 4682/10033 [00:24<00:35, 152.85 examples/s]Tokenizing train dataset:  50%|████▉     | 4990/10033 [00:25<00:25, 196.88 examples/s]Tokenizing train dataset:  47%|████▋     | 4727/10033 [00:25<00:43, 121.85 examples/s]Tokenizing train dataset:  47%|████▋     | 4698/10033 [00:25<00:37, 142.43 examples/s]Tokenizing train dataset:  50%|█████     | 5023/10033 [00:26<00:42, 117.36 examples/s]Tokenizing train dataset:  47%|████▋     | 4746/10033 [00:26<01:20, 65.75 examples/s] Tokenizing train dataset:  47%|████▋     | 4713/10033 [00:25<01:25, 62.18 examples/s] Tokenizing train dataset:  50%|█████     | 5055/10033 [00:26<00:43, 114.41 examples/s]Tokenizing train dataset:  47%|████▋     | 4761/10033 [00:26<01:15, 70.03 examples/s]Tokenizing train dataset:  47%|████▋     | 4743/10033 [00:26<01:00, 87.08 examples/s]Tokenizing train dataset:  51%|█████     | 5112/10033 [00:26<00:28, 174.32 examples/s]Tokenizing train dataset:  48%|████▊     | 4778/10033 [00:26<01:03, 82.48 examples/s]Tokenizing train dataset:  48%|████▊     | 4770/10033 [00:26<00:48, 109.62 examples/s]Tokenizing train dataset:  51%|█████▏    | 5147/10033 [00:26<00:26, 182.84 examples/s]Tokenizing train dataset:  48%|████▊     | 4797/10033 [00:26<00:57, 90.89 examples/s]Tokenizing train dataset:  48%|████▊     | 4789/10033 [00:26<00:43, 120.04 examples/s]Tokenizing train dataset:  52%|█████▏    | 5194/10033 [00:26<00:20, 230.85 examples/s]Tokenizing train dataset:  48%|████▊     | 4830/10033 [00:26<00:41, 126.71 examples/s]Tokenizing train dataset:  48%|████▊     | 4813/10033 [00:26<00:40, 130.38 examples/s]Tokenizing train dataset:  52%|█████▏    | 5244/10033 [00:27<00:16, 282.27 examples/s]Tokenizing train dataset:  48%|████▊     | 4863/10033 [00:26<00:31, 163.76 examples/s]Tokenizing train dataset:  48%|████▊     | 4849/10033 [00:26<00:30, 169.49 examples/s]Tokenizing train dataset:  53%|█████▎    | 5286/10033 [00:27<00:16, 284.72 examples/s]Tokenizing train dataset:  49%|████▉     | 4894/10033 [00:27<00:28, 182.92 examples/s]Tokenizing train dataset:  49%|████▊     | 4877/10033 [00:26<00:27, 189.43 examples/s]Tokenizing train dataset:  53%|█████▎    | 5324/10033 [00:27<00:15, 304.25 examples/s]Tokenizing train dataset:  49%|████▉     | 4945/10033 [00:27<00:20, 253.83 examples/s]Tokenizing train dataset:  49%|████▉     | 4906/10033 [00:26<00:26, 196.68 examples/s]Tokenizing train dataset:  53%|█████▎    | 5362/10033 [00:27<00:14, 322.24 examples/s]Tokenizing train dataset:  50%|████▉     | 4993/10033 [00:27<00:16, 304.36 examples/s]Tokenizing train dataset:  49%|████▉     | 4937/10033 [00:27<00:40, 124.39 examples/s]Tokenizing train dataset:  54%|█████▍    | 5421/10033 [00:28<00:30, 149.70 examples/s]Tokenizing train dataset:  50%|█████     | 5059/10033 [00:28<00:34, 145.15 examples/s]Tokenizing train dataset:  49%|████▉     | 4964/10033 [00:27<00:51, 97.69 examples/s] Tokenizing train dataset:  54%|█████▍    | 5455/10033 [00:28<00:30, 150.58 examples/s]Tokenizing train dataset:  51%|█████     | 5093/10033 [00:28<00:33, 148.96 examples/s]Tokenizing train dataset:  50%|████▉     | 4993/10033 [00:27<00:47, 106.03 examples/s]Tokenizing train dataset:  55%|█████▍    | 5483/10033 [00:28<00:28, 158.74 examples/s]Tokenizing train dataset:  51%|█████     | 5126/10033 [00:28<00:34, 141.28 examples/s]Tokenizing train dataset:  50%|█████     | 5024/10033 [00:28<00:45, 109.37 examples/s]Tokenizing train dataset:  55%|█████▍    | 5516/10033 [00:28<00:30, 149.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 5178/10033 [00:28<00:25, 190.80 examples/s]Tokenizing train dataset:  50%|█████     | 5057/10033 [00:28<00:39, 126.89 examples/s]Tokenizing train dataset:  55%|█████▌    | 5547/10033 [00:28<00:29, 152.21 examples/s]Tokenizing train dataset:  52%|█████▏    | 5215/10033 [00:28<00:24, 198.28 examples/s]Tokenizing train dataset:  51%|█████     | 5098/10033 [00:28<00:29, 169.80 examples/s]Tokenizing train dataset:  56%|█████▌    | 5596/10033 [00:29<00:21, 205.19 examples/s]Tokenizing train dataset:  53%|█████▎    | 5274/10033 [00:28<00:18, 264.04 examples/s]Tokenizing train dataset:  51%|█████▏    | 5147/10033 [00:28<00:21, 226.30 examples/s]Tokenizing train dataset:  56%|█████▋    | 5648/10033 [00:29<00:16, 262.79 examples/s]Tokenizing train dataset:  53%|█████▎    | 5322/10033 [00:28<00:15, 303.80 examples/s]Tokenizing train dataset:  52%|█████▏    | 5207/10033 [00:28<00:16, 300.57 examples/s]Tokenizing train dataset:  57%|█████▋    | 5714/10033 [00:29<00:12, 344.12 examples/s]Tokenizing train dataset:  54%|█████▎    | 5377/10033 [00:29<00:13, 356.16 examples/s]Tokenizing train dataset:  53%|█████▎    | 5281/10033 [00:28<00:15, 314.92 examples/s]Tokenizing train dataset:  58%|█████▊    | 5786/10033 [00:29<00:12, 346.13 examples/s]Tokenizing train dataset:  54%|█████▍    | 5443/10033 [00:29<00:13, 347.63 examples/s]Tokenizing train dataset:  53%|█████▎    | 5332/10033 [00:28<00:13, 353.51 examples/s]Tokenizing train dataset:  58%|█████▊    | 5852/10033 [00:29<00:11, 369.30 examples/s]Tokenizing train dataset:  55%|█████▍    | 5504/10033 [00:29<00:12, 362.83 examples/s]Tokenizing train dataset:  54%|█████▎    | 5388/10033 [00:28<00:11, 395.78 examples/s]Tokenizing train dataset:  59%|█████▉    | 5914/10033 [00:29<00:11, 351.12 examples/s]Tokenizing train dataset:  55%|█████▌    | 5562/10033 [00:29<00:13, 322.71 examples/s]Tokenizing train dataset:  54%|█████▍    | 5453/10033 [00:29<00:14, 326.06 examples/s]Tokenizing train dataset:  59%|█████▉    | 5965/10033 [00:29<00:10, 381.87 examples/s]Tokenizing train dataset:  56%|█████▌    | 5617/10033 [00:29<00:12, 365.31 examples/s]Tokenizing train dataset:  55%|█████▍    | 5510/10033 [00:29<00:13, 324.92 examples/s]Tokenizing train dataset:  60%|█████▉    | 6019/10033 [00:30<00:11, 349.18 examples/s]Tokenizing train dataset:  57%|█████▋    | 5683/10033 [00:29<00:11, 373.89 examples/s]Tokenizing train dataset:  55%|█████▌    | 5560/10033 [00:29<00:12, 356.90 examples/s]Tokenizing train dataset:  61%|██████    | 6081/10033 [00:30<00:11, 357.92 examples/s]Tokenizing train dataset:  57%|█████▋    | 5750/10033 [00:30<00:10, 389.94 examples/s]Tokenizing train dataset:  56%|█████▌    | 5631/10033 [00:29<00:11, 386.76 examples/s]Tokenizing train dataset:  61%|██████    | 6128/10033 [00:30<00:10, 380.71 examples/s]Tokenizing train dataset:  58%|█████▊    | 5827/10033 [00:30<00:09, 423.13 examples/s]Tokenizing train dataset:  57%|█████▋    | 5697/10033 [00:29<00:11, 392.66 examples/s]Tokenizing train dataset:  61%|██████▏   | 6170/10033 [00:30<00:17, 220.55 examples/s]Tokenizing train dataset:  59%|█████▊    | 5880/10033 [00:30<00:16, 257.82 examples/s]Tokenizing train dataset:  62%|██████▏   | 6206/10033 [00:31<00:28, 133.81 examples/s]Tokenizing train dataset:  57%|█████▋    | 5765/10033 [00:30<00:26, 162.31 examples/s]Tokenizing train dataset:  59%|█████▉    | 5946/10033 [00:31<00:22, 179.51 examples/s]Tokenizing train dataset:  62%|██████▏   | 6256/10033 [00:31<00:21, 173.70 examples/s]Tokenizing train dataset:  58%|█████▊    | 5827/10033 [00:30<00:20, 206.57 examples/s]Tokenizing train dataset:  60%|█████▉    | 5985/10033 [00:31<00:20, 201.44 examples/s]Tokenizing train dataset:  63%|██████▎   | 6311/10033 [00:31<00:16, 223.44 examples/s]Tokenizing train dataset:  59%|█████▊    | 5879/10033 [00:31<00:18, 229.73 examples/s]Tokenizing train dataset:  60%|██████    | 6020/10033 [00:31<00:19, 208.51 examples/s]Tokenizing train dataset:  64%|██████▎   | 6384/10033 [00:31<00:13, 271.78 examples/s]Tokenizing train dataset:  59%|█████▉    | 5918/10033 [00:31<00:16, 251.19 examples/s]Tokenizing train dataset:  60%|██████    | 6054/10033 [00:31<00:19, 203.79 examples/s]Tokenizing train dataset:  61%|██████    | 6087/10033 [00:31<00:17, 223.62 examples/s]Tokenizing train dataset:  64%|██████▍   | 6450/10033 [00:32<00:12, 275.76 examples/s]Tokenizing train dataset:  60%|█████▉    | 5980/10033 [00:31<00:16, 251.23 examples/s]Tokenizing train dataset:  61%|██████    | 6116/10033 [00:31<00:17, 220.53 examples/s]Tokenizing train dataset:  65%|██████▍   | 6507/10033 [00:32<00:12, 276.53 examples/s]Tokenizing train dataset:  60%|██████    | 6039/10033 [00:31<00:15, 266.00 examples/s]Tokenizing train dataset:  61%|██████▏   | 6157/10033 [00:32<00:19, 199.12 examples/s]Tokenizing train dataset:  65%|██████▌   | 6541/10033 [00:32<00:15, 224.45 examples/s]Tokenizing train dataset:  61%|██████    | 6072/10033 [00:31<00:19, 206.76 examples/s]Tokenizing train dataset:  62%|██████▏   | 6196/10033 [00:32<00:20, 191.44 examples/s]Tokenizing train dataset:  65%|██████▌   | 6570/10033 [00:32<00:15, 218.04 examples/s]Tokenizing train dataset:  62%|██████▏   | 6234/10033 [00:32<00:17, 217.29 examples/s]Tokenizing train dataset:  66%|██████▌   | 6595/10033 [00:32<00:15, 222.55 examples/s]Tokenizing train dataset:  61%|██████    | 6125/10033 [00:32<00:17, 217.33 examples/s]Tokenizing train dataset:  63%|██████▎   | 6275/10033 [00:32<00:14, 253.05 examples/s]Tokenizing train dataset:  61%|██████▏   | 6163/10033 [00:32<00:16, 234.88 examples/s]Tokenizing train dataset:  66%|██████▋   | 6650/10033 [00:32<00:13, 256.99 examples/s]Tokenizing train dataset:  63%|██████▎   | 6322/10033 [00:32<00:12, 298.31 examples/s]Tokenizing train dataset:  62%|██████▏   | 6200/10033 [00:32<00:16, 239.22 examples/s]Tokenizing train dataset:  67%|██████▋   | 6688/10033 [00:33<00:13, 244.68 examples/s]Tokenizing train dataset:  63%|██████▎   | 6360/10033 [00:32<00:14, 254.96 examples/s]Tokenizing train dataset:  62%|██████▏   | 6236/10033 [00:32<00:17, 221.56 examples/s]Tokenizing train dataset:  67%|██████▋   | 6725/10033 [00:33<00:13, 244.24 examples/s]Tokenizing train dataset:  64%|██████▍   | 6400/10033 [00:33<00:12, 283.76 examples/s]Tokenizing train dataset:  63%|██████▎   | 6281/10033 [00:32<00:14, 262.83 examples/s]Tokenizing train dataset:  67%|██████▋   | 6763/10033 [00:33<00:12, 270.92 examples/s]Tokenizing train dataset:  64%|██████▍   | 6462/10033 [00:33<00:11, 321.83 examples/s]Tokenizing train dataset:  68%|██████▊   | 6795/10033 [00:33<00:12, 264.33 examples/s]Tokenizing train dataset:  65%|██████▍   | 6507/10033 [00:33<00:10, 350.12 examples/s]Tokenizing train dataset:  63%|██████▎   | 6345/10033 [00:32<00:12, 295.80 examples/s]Tokenizing train dataset:  68%|██████▊   | 6846/10033 [00:33<00:09, 320.20 examples/s]Tokenizing train dataset:  65%|██████▌   | 6567/10033 [00:33<00:08, 408.77 examples/s]Tokenizing train dataset:  64%|██████▍   | 6401/10033 [00:32<00:10, 349.01 examples/s]Tokenizing train dataset:  69%|██████▉   | 6902/10033 [00:33<00:08, 377.58 examples/s]Tokenizing train dataset:  66%|██████▌   | 6615/10033 [00:33<00:10, 333.20 examples/s]Tokenizing train dataset:  69%|██████▉   | 6943/10033 [00:33<00:09, 330.57 examples/s]Tokenizing train dataset:  64%|██████▍   | 6462/10033 [00:33<00:12, 297.43 examples/s]Tokenizing train dataset:  67%|██████▋   | 6680/10033 [00:33<00:09, 338.21 examples/s]Tokenizing train dataset:  70%|██████▉   | 6998/10033 [00:34<00:10, 299.71 examples/s]Tokenizing train dataset:  65%|██████▌   | 6524/10033 [00:33<00:12, 286.22 examples/s]Tokenizing train dataset:  67%|██████▋   | 6718/10033 [00:33<00:10, 317.68 examples/s]Tokenizing train dataset:  65%|██████▌   | 6565/10033 [00:33<00:11, 307.06 examples/s]Tokenizing train dataset:  70%|███████   | 7058/10033 [00:34<00:09, 324.23 examples/s]Tokenizing train dataset:  67%|██████▋   | 6752/10033 [00:34<00:14, 224.08 examples/s]Tokenizing train dataset:  66%|██████▌   | 6613/10033 [00:33<00:14, 236.57 examples/s]Tokenizing train dataset:  68%|██████▊   | 6799/10033 [00:34<00:12, 266.27 examples/s]Tokenizing train dataset:  71%|███████   | 7125/10033 [00:34<00:11, 261.28 examples/s]Tokenizing train dataset:  66%|██████▌   | 6644/10033 [00:33<00:14, 241.09 examples/s]Tokenizing train dataset:  71%|███████▏  | 7156/10033 [00:34<00:11, 246.90 examples/s]Tokenizing train dataset:  68%|██████▊   | 6853/10033 [00:34<00:11, 279.11 examples/s]Tokenizing train dataset:  67%|██████▋   | 6677/10033 [00:34<00:13, 244.17 examples/s]Tokenizing train dataset:  72%|███████▏  | 7195/10033 [00:34<00:11, 249.55 examples/s]Tokenizing train dataset:  69%|██████▊   | 6890/10033 [00:34<00:12, 257.31 examples/s]Tokenizing train dataset:  67%|██████▋   | 6715/10033 [00:34<00:13, 250.54 examples/s]Tokenizing train dataset:  72%|███████▏  | 7225/10033 [00:34<00:10, 256.79 examples/s]Tokenizing train dataset:  69%|██████▉   | 6948/10033 [00:34<00:09, 319.04 examples/s]Tokenizing train dataset:  67%|██████▋   | 6746/10033 [00:34<00:13, 242.71 examples/s]Tokenizing train dataset:  72%|███████▏  | 7258/10033 [00:35<00:10, 262.77 examples/s]Tokenizing train dataset:  70%|██████▉   | 6990/10033 [00:34<00:08, 338.55 examples/s]Tokenizing train dataset:  68%|██████▊   | 6787/10033 [00:34<00:11, 278.49 examples/s]Tokenizing train dataset:  73%|███████▎  | 7292/10033 [00:35<00:10, 271.68 examples/s]Tokenizing train dataset:  70%|███████   | 7046/10033 [00:35<00:09, 322.61 examples/s]Tokenizing train dataset:  73%|███████▎  | 7325/10033 [00:35<00:09, 277.85 examples/s]Tokenizing train dataset:  68%|██████▊   | 6837/10033 [00:34<00:11, 283.91 examples/s]Tokenizing train dataset:  71%|███████   | 7082/10033 [00:35<00:09, 327.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 7361/10033 [00:35<00:09, 288.50 examples/s]Tokenizing train dataset:  68%|██████▊   | 6871/10033 [00:34<00:10, 294.32 examples/s]Tokenizing train dataset:  71%|███████   | 7120/10033 [00:35<00:08, 338.17 examples/s]Tokenizing train dataset:  74%|███████▎  | 7393/10033 [00:35<00:08, 295.50 examples/s]Tokenizing train dataset:  69%|██████▉   | 6903/10033 [00:34<00:10, 299.81 examples/s]Tokenizing train dataset:  72%|███████▏  | 7182/10033 [00:35<00:07, 406.94 examples/s]Tokenizing train dataset:  74%|███████▍  | 7456/10033 [00:35<00:06, 382.91 examples/s]Tokenizing train dataset:  69%|██████▉   | 6945/10033 [00:34<00:09, 329.44 examples/s]Tokenizing train dataset:  72%|███████▏  | 7241/10033 [00:35<00:07, 398.71 examples/s]Tokenizing train dataset:  75%|███████▍  | 7520/10033 [00:35<00:06, 367.02 examples/s]Tokenizing train dataset:  70%|██████▉   | 6998/10033 [00:35<00:09, 306.98 examples/s]Tokenizing train dataset:  73%|███████▎  | 7307/10033 [00:36<00:11, 232.35 examples/s]Tokenizing train dataset:  76%|███████▌  | 7592/10033 [00:36<00:10, 232.32 examples/s]Tokenizing train dataset:  70%|███████   | 7056/10033 [00:35<00:15, 192.65 examples/s]Tokenizing train dataset:  73%|███████▎  | 7350/10033 [00:36<00:10, 261.33 examples/s]Tokenizing train dataset:  76%|███████▌  | 7627/10033 [00:36<00:11, 211.29 examples/s]Tokenizing train dataset:  71%|███████   | 7090/10033 [00:35<00:17, 167.24 examples/s]Tokenizing train dataset:  76%|███████▋  | 7654/10033 [00:36<00:11, 214.20 examples/s]Tokenizing train dataset:  74%|███████▍  | 7413/10033 [00:36<00:11, 237.25 examples/s]Tokenizing train dataset:  71%|███████   | 7135/10033 [00:36<00:14, 206.17 examples/s]Tokenizing train dataset:  77%|███████▋  | 7698/10033 [00:36<00:09, 253.50 examples/s]Tokenizing train dataset:  74%|███████▍  | 7449/10033 [00:36<00:12, 215.08 examples/s]Tokenizing train dataset:  71%|███████▏  | 7165/10033 [00:36<00:15, 190.42 examples/s]Tokenizing train dataset:  77%|███████▋  | 7730/10033 [00:37<00:11, 199.99 examples/s]Tokenizing train dataset:  75%|███████▍  | 7480/10033 [00:36<00:11, 213.67 examples/s]Tokenizing train dataset:  72%|███████▏  | 7203/10033 [00:36<00:13, 203.82 examples/s]Tokenizing train dataset:  77%|███████▋  | 7760/10033 [00:37<00:10, 207.03 examples/s]Tokenizing train dataset:  75%|███████▍  | 7514/10033 [00:36<00:10, 231.63 examples/s]Tokenizing train dataset:  72%|███████▏  | 7258/10033 [00:36<00:11, 234.73 examples/s]Tokenizing train dataset:  78%|███████▊  | 7803/10033 [00:37<00:09, 247.50 examples/s]Tokenizing train dataset:  76%|███████▌  | 7575/10033 [00:37<00:08, 304.90 examples/s]Tokenizing train dataset:  73%|███████▎  | 7305/10033 [00:36<00:09, 278.27 examples/s]Tokenizing train dataset:  78%|███████▊  | 7836/10033 [00:37<00:08, 260.18 examples/s]Tokenizing train dataset:  76%|███████▌  | 7639/10033 [00:37<00:08, 291.72 examples/s]Tokenizing train dataset:  73%|███████▎  | 7365/10033 [00:36<00:09, 293.72 examples/s]Tokenizing train dataset:  78%|███████▊  | 7869/10033 [00:37<00:11, 181.72 examples/s]Tokenizing train dataset:  77%|███████▋  | 7695/10033 [00:37<00:09, 248.25 examples/s]Tokenizing train dataset:  74%|███████▍  | 7427/10033 [00:37<00:10, 257.76 examples/s]Tokenizing train dataset:  79%|███████▉  | 7902/10033 [00:37<00:11, 185.66 examples/s]Tokenizing train dataset:  77%|███████▋  | 7726/10033 [00:37<00:08, 257.93 examples/s]Tokenizing train dataset:  74%|███████▍  | 7465/10033 [00:37<00:09, 277.79 examples/s]Tokenizing train dataset:  79%|███████▉  | 7942/10033 [00:37<00:09, 223.82 examples/s]Tokenizing train dataset:  80%|███████▉  | 7977/10033 [00:38<00:08, 241.72 examples/s]Tokenizing train dataset:  78%|███████▊  | 7781/10033 [00:37<00:08, 273.56 examples/s]Tokenizing train dataset:  75%|███████▌  | 7530/10033 [00:37<00:08, 302.74 examples/s]Tokenizing train dataset:  80%|███████▉  | 8013/10033 [00:38<00:08, 251.24 examples/s]Tokenizing train dataset:  78%|███████▊  | 7841/10033 [00:38<00:07, 291.25 examples/s]Tokenizing train dataset:  76%|███████▌  | 7596/10033 [00:37<00:07, 310.38 examples/s]Tokenizing train dataset:  80%|████████  | 8046/10033 [00:38<00:08, 229.82 examples/s]Tokenizing train dataset:  76%|███████▌  | 7629/10033 [00:37<00:08, 298.83 examples/s]Tokenizing train dataset:  79%|███████▉  | 7905/10033 [00:38<00:07, 298.71 examples/s]Tokenizing train dataset:  81%|████████  | 8091/10033 [00:38<00:06, 277.59 examples/s]Tokenizing train dataset:  76%|███████▋  | 7670/10033 [00:37<00:07, 320.27 examples/s]Tokenizing train dataset:  79%|███████▉  | 7955/10033 [00:38<00:06, 334.87 examples/s]Tokenizing train dataset:  81%|████████  | 8151/10033 [00:38<00:06, 282.41 examples/s]Tokenizing train dataset:  77%|███████▋  | 7730/10033 [00:38<00:07, 308.95 examples/s]Tokenizing train dataset:  80%|███████▉  | 8025/10033 [00:38<00:07, 286.05 examples/s]Tokenizing train dataset:  82%|████████▏ | 8186/10033 [00:38<00:07, 235.79 examples/s]Tokenizing train dataset:  78%|███████▊  | 7785/10033 [00:38<00:07, 290.10 examples/s]Tokenizing train dataset:  80%|████████  | 8064/10033 [00:38<00:06, 300.54 examples/s]Tokenizing train dataset:  82%|████████▏ | 8236/10033 [00:39<00:06, 287.13 examples/s]Tokenizing train dataset:  78%|███████▊  | 7844/10033 [00:38<00:08, 260.46 examples/s]Tokenizing train dataset:  81%|████████  | 8119/10033 [00:39<00:07, 261.43 examples/s]Tokenizing train dataset:  82%|████████▏ | 8277/10033 [00:39<00:08, 203.82 examples/s]Tokenizing train dataset:  81%|████████  | 8151/10033 [00:39<00:08, 234.83 examples/s]Tokenizing train dataset:  79%|███████▉  | 7904/10033 [00:38<00:08, 259.52 examples/s]Tokenizing train dataset:  83%|████████▎ | 8314/10033 [00:39<00:08, 207.19 examples/s]Tokenizing train dataset:  82%|████████▏ | 8184/10033 [00:39<00:07, 250.92 examples/s]Tokenizing train dataset:  79%|███████▉  | 7940/10033 [00:38<00:07, 272.32 examples/s]Tokenizing train dataset:  83%|████████▎ | 8350/10033 [00:39<00:07, 231.96 examples/s]Tokenizing train dataset:  82%|████████▏ | 8213/10033 [00:39<00:07, 244.65 examples/s]Tokenizing train dataset:  79%|███████▉  | 7971/10033 [00:39<00:07, 260.91 examples/s]Tokenizing train dataset:  84%|████████▎ | 8378/10033 [00:39<00:07, 225.28 examples/s]Tokenizing train dataset:  82%|████████▏ | 8251/10033 [00:39<00:07, 251.02 examples/s]Tokenizing train dataset:  80%|███████▉  | 8007/10033 [00:39<00:07, 257.86 examples/s]Tokenizing train dataset:  84%|████████▍ | 8409/10033 [00:40<00:09, 173.01 examples/s]Tokenizing train dataset:  83%|████████▎ | 8297/10033 [00:39<00:08, 204.02 examples/s]Tokenizing train dataset:  80%|████████  | 8036/10033 [00:39<00:10, 192.67 examples/s]Tokenizing train dataset:  84%|████████▍ | 8441/10033 [00:40<00:08, 198.22 examples/s]Tokenizing train dataset:  83%|████████▎ | 8329/10033 [00:40<00:07, 221.95 examples/s]Tokenizing train dataset:  80%|████████  | 8064/10033 [00:39<00:10, 188.66 examples/s]Tokenizing train dataset:  85%|████████▍ | 8478/10033 [00:40<00:07, 205.91 examples/s]Tokenizing train dataset:  81%|████████  | 8101/10033 [00:39<00:08, 220.99 examples/s]Tokenizing train dataset:  84%|████████▎ | 8386/10033 [00:40<00:06, 243.63 examples/s]Tokenizing train dataset:  85%|████████▌ | 8530/10033 [00:40<00:05, 266.59 examples/s]Tokenizing train dataset:  81%|████████  | 8148/10033 [00:39<00:06, 272.73 examples/s]Tokenizing train dataset:  84%|████████▍ | 8440/10033 [00:40<00:05, 299.60 examples/s]Tokenizing train dataset:  86%|████████▌ | 8593/10033 [00:40<00:04, 347.27 examples/s]Tokenizing train dataset:  82%|████████▏ | 8180/10033 [00:40<00:08, 229.11 examples/s]Tokenizing train dataset:  84%|████████▍ | 8477/10033 [00:40<00:06, 252.19 examples/s]Tokenizing train dataset:  86%|████████▋ | 8658/10033 [00:40<00:04, 286.76 examples/s]Tokenizing train dataset:  82%|████████▏ | 8209/10033 [00:40<00:15, 116.87 examples/s]Tokenizing train dataset:  87%|████████▋ | 8722/10033 [00:41<00:07, 179.70 examples/s]Tokenizing train dataset:  85%|████████▌ | 8537/10033 [00:41<00:10, 143.72 examples/s]Tokenizing train dataset:  82%|████████▏ | 8244/10033 [00:40<00:13, 129.54 examples/s]Tokenizing train dataset:  88%|████████▊ | 8791/10033 [00:41<00:05, 221.13 examples/s]Tokenizing train dataset:  86%|████████▌ | 8580/10033 [00:41<00:08, 161.59 examples/s]Tokenizing train dataset:  83%|████████▎ | 8286/10033 [00:41<00:10, 160.97 examples/s]Tokenizing train dataset:  88%|████████▊ | 8873/10033 [00:41<00:03, 302.53 examples/s]Tokenizing train dataset:  86%|████████▌ | 8653/10033 [00:41<00:05, 234.20 examples/s]Tokenizing train dataset:  83%|████████▎ | 8320/10033 [00:41<00:09, 181.68 examples/s]Tokenizing train dataset:  89%|████████▉ | 8940/10033 [00:41<00:03, 352.93 examples/s]Tokenizing train dataset:  87%|████████▋ | 8717/10033 [00:41<00:04, 296.82 examples/s]Tokenizing train dataset:  83%|████████▎ | 8353/10033 [00:41<00:08, 207.81 examples/s]Tokenizing train dataset:  90%|█████████ | 9046/10033 [00:41<00:02, 483.20 examples/s]Tokenizing train dataset:  88%|████████▊ | 8829/10033 [00:41<00:02, 444.71 examples/s]Tokenizing train dataset:  84%|████████▎ | 8385/10033 [00:41<00:07, 227.52 examples/s]Tokenizing train dataset:  84%|████████▍ | 8414/10033 [00:41<00:07, 222.80 examples/s]Tokenizing train dataset:  91%|█████████▏| 9177/10033 [00:42<00:01, 526.56 examples/s]Tokenizing train dataset:  89%|████████▉ | 8957/10033 [00:41<00:02, 497.08 examples/s]Tokenizing train dataset:  84%|████████▍ | 8470/10033 [00:41<00:05, 297.30 examples/s]Tokenizing train dataset:  93%|█████████▎| 9300/10033 [00:42<00:01, 660.54 examples/s]Tokenizing train dataset:  90%|█████████ | 9069/10033 [00:42<00:01, 615.60 examples/s]Tokenizing train dataset:  85%|████████▍ | 8519/10033 [00:41<00:04, 342.09 examples/s]Tokenizing train dataset:  94%|█████████▎| 9404/10033 [00:42<00:00, 740.57 examples/s]Tokenizing train dataset:  91%|█████████▏| 9180/10033 [00:42<00:01, 720.17 examples/s]Tokenizing train dataset:  86%|████████▌ | 8585/10033 [00:41<00:03, 422.39 examples/s]Tokenizing train dataset:  95%|█████████▍| 9505/10033 [00:42<00:00, 801.98 examples/s]Tokenizing train dataset:  93%|█████████▎| 9325/10033 [00:42<00:00, 796.26 examples/s]Tokenizing train dataset:  87%|████████▋ | 8693/10033 [00:41<00:02, 595.41 examples/s]Tokenizing train dataset:  96%|█████████▌| 9628/10033 [00:42<00:00, 764.90 examples/s]Tokenizing train dataset:  87%|████████▋ | 8759/10033 [00:42<00:02, 524.60 examples/s]Tokenizing train dataset:  94%|█████████▍| 9447/10033 [00:42<00:00, 706.00 examples/s]Tokenizing train dataset:  97%|█████████▋| 9745/10033 [00:42<00:00, 639.26 examples/s]Tokenizing train dataset:  88%|████████▊ | 8822/10033 [00:42<00:03, 398.20 examples/s]Tokenizing train dataset:  95%|█████████▌| 9570/10033 [00:42<00:00, 591.46 examples/s]Tokenizing train dataset:  89%|████████▊ | 8885/10033 [00:42<00:02, 430.75 examples/s]Tokenizing train dataset:  98%|█████████▊| 9872/10033 [00:43<00:00, 603.50 examples/s]Tokenizing train dataset:  96%|█████████▋| 9670/10033 [00:42<00:00, 660.35 examples/s]Tokenizing train dataset:  89%|████████▉ | 8950/10033 [00:42<00:02, 405.37 examples/s]Tokenizing train dataset: 100%|█████████▉| 9991/10033 [00:43<00:00, 547.51 examples/s]Tokenizing train dataset:  98%|█████████▊| 9790/10033 [00:43<00:00, 520.97 examples/s]Tokenizing train dataset:  90%|████████▉ | 9011/10033 [00:42<00:03, 340.26 examples/s]Tokenizing train dataset:  98%|█████████▊| 9856/10033 [00:43<00:00, 402.41 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:43<00:00, 229.12 examples/s]Tokenizing train dataset:  90%|█████████ | 9070/10033 [00:43<00:03, 268.49 examples/s]Tokenizing train dataset:  99%|█████████▉| 9925/10033 [00:43<00:00, 443.99 examples/s]
Tokenizing train dataset:  91%|█████████ | 9136/10033 [00:43<00:02, 313.14 examples/s]Tokenizing train dataset: 100%|█████████▉| 9984/10033 [00:43<00:00, 468.82 examples/s]Tokenizing train dataset:  92%|█████████▏| 9200/10033 [00:43<00:02, 289.86 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:44<00:00, 227.59 examples/s]
Tokenizing train dataset:  92%|█████████▏| 9265/10033 [00:43<00:02, 343.82 examples/s]Tokenizing train dataset:  93%|█████████▎| 9363/10033 [00:43<00:01, 462.16 examples/s]Tokenizing train dataset:  94%|█████████▍| 9446/10033 [00:43<00:01, 538.96 examples/s]Tokenizing train dataset:  95%|█████████▌| 9571/10033 [00:44<00:00, 583.41 examples/s]Tokenizing train dataset:  97%|█████████▋| 9691/10033 [00:44<00:00, 586.97 examples/s]Tokenizing train dataset:  97%|█████████▋| 9765/10033 [00:44<00:00, 616.00 examples/s]Tokenizing train dataset:  99%|█████████▊| 9890/10033 [00:44<00:00, 675.68 examples/s]Tokenizing train dataset: 100%|█████████▉| 10011/10033 [00:44<00:00, 708.87 examples/s]Tokenizing train dataset: 100%|██████████| 10033/10033 [00:44<00:00, 224.18 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:  59%|█████▉    | 560/953 [00:00<00:00, 5502.26 examples/s]Extracting prompt in eval dataset:  58%|█████▊    | 550/953 [00:00<00:00, 5417.03 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset:  57%|█████▋    | 543/953 [00:00<00:00, 5387.74 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 4752.18 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1196.06 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1314.30 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  32%|███▏      | 302/953 [00:00<00:00, 2980.16 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  65%|██████▍   | 619/953 [00:00<00:00, 1461.39 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:  32%|███▏      | 301/953 [00:00<00:00, 2974.56 examples/s]Applying chat template to eval dataset:  98%|█████████▊| 933/953 [00:00<00:00, 1488.26 examples/s]Applying chat template to eval dataset:  32%|███▏      | 305/953 [00:00<00:00, 2990.58 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1508.83 examples/s]
Applying chat template to eval dataset:  65%|██████▌   | 620/953 [00:00<00:00, 2243.97 examples/s]Applying chat template to eval dataset:  80%|███████▉  | 758/953 [00:00<00:00, 3003.25 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 2822.34 examples/s]
Applying chat template to eval dataset:  99%|█████████▊| 940/953 [00:00<00:00, 1738.06 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 1568.81 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 325.99 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:04, 199.98 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 317.93 examples/s]Tokenizing eval dataset:   3%|▎         | 30/953 [00:00<00:03, 289.95 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:04, 179.85 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:03, 232.01 examples/s]Tokenizing eval dataset:  14%|█▍        | 134/953 [00:00<00:04, 192.35 examples/s]Tokenizing eval dataset:   6%|▋         | 60/953 [00:00<00:04, 222.81 examples/s]Tokenizing eval dataset:  11%|█▏        | 109/953 [00:00<00:04, 207.58 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:05, 156.76 examples/s]Tokenizing eval dataset:  10%|▉         | 91/953 [00:00<00:05, 160.30 examples/s]Tokenizing eval dataset:  14%|█▍        | 136/953 [00:00<00:04, 185.54 examples/s]Tokenizing eval dataset:  19%|█▉        | 180/953 [00:01<00:04, 162.06 examples/s]Tokenizing eval dataset:  12%|█▏        | 117/953 [00:00<00:05, 148.23 examples/s]Tokenizing eval dataset:  17%|█▋        | 162/953 [00:00<00:04, 165.15 examples/s]Tokenizing eval dataset:  22%|██▏       | 209/953 [00:01<00:04, 157.76 examples/s]Tokenizing eval dataset:  15%|█▌        | 143/953 [00:00<00:06, 125.53 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:01<00:05, 131.70 examples/s]Tokenizing eval dataset:  25%|██▍       | 235/953 [00:01<00:05, 129.35 examples/s]Tokenizing eval dataset:  18%|█▊        | 167/953 [00:01<00:06, 126.97 examples/s]Tokenizing eval dataset:  28%|██▊       | 271/953 [00:01<00:03, 170.54 examples/s]Tokenizing eval dataset:  23%|██▎       | 215/953 [00:01<00:05, 138.57 examples/s]Tokenizing eval dataset:  19%|█▉        | 183/953 [00:01<00:05, 132.28 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:01<00:03, 182.00 examples/s]Tokenizing eval dataset:  25%|██▌       | 242/953 [00:01<00:04, 158.27 examples/s]Tokenizing eval dataset:  22%|██▏       | 205/953 [00:01<00:05, 148.46 examples/s]Tokenizing eval dataset:  37%|███▋      | 355/953 [00:01<00:02, 248.27 examples/s]Tokenizing eval dataset:  31%|███       | 294/953 [00:01<00:02, 231.60 examples/s]Tokenizing eval dataset:  24%|██▍       | 233/953 [00:01<00:04, 178.26 examples/s]Tokenizing eval dataset:  40%|████      | 385/953 [00:01<00:02, 245.90 examples/s]Tokenizing eval dataset:  34%|███▍      | 327/953 [00:01<00:03, 176.45 examples/s]Tokenizing eval dataset:  28%|██▊       | 263/953 [00:01<00:04, 143.08 examples/s]Tokenizing eval dataset:  44%|████▍     | 419/953 [00:02<00:03, 160.56 examples/s]Tokenizing eval dataset:  38%|███▊      | 360/953 [00:02<00:03, 152.63 examples/s]Tokenizing eval dataset:  31%|███       | 295/953 [00:02<00:05, 130.29 examples/s]Tokenizing eval dataset:  48%|████▊     | 462/953 [00:02<00:02, 190.34 examples/s]Tokenizing eval dataset:  41%|████      | 391/953 [00:02<00:03, 175.95 examples/s]Tokenizing eval dataset:  35%|███▍      | 332/953 [00:02<00:03, 169.72 examples/s]Tokenizing eval dataset:  54%|█████▍    | 516/953 [00:02<00:01, 251.71 examples/s]Tokenizing eval dataset:  45%|████▌     | 432/953 [00:02<00:02, 217.32 examples/s]Tokenizing eval dataset:  38%|███▊      | 361/953 [00:02<00:03, 192.08 examples/s]Tokenizing eval dataset:  58%|█████▊    | 553/953 [00:02<00:01, 269.32 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:02<00:01, 245.48 examples/s]Tokenizing eval dataset:  41%|████      | 392/953 [00:02<00:02, 207.09 examples/s]Tokenizing eval dataset:  64%|██████▎   | 606/953 [00:02<00:01, 324.66 examples/s]Tokenizing eval dataset:  54%|█████▍    | 516/953 [00:02<00:01, 295.68 examples/s]Tokenizing eval dataset:  47%|████▋     | 452/953 [00:02<00:01, 295.26 examples/s]Tokenizing eval dataset:  58%|█████▊    | 552/953 [00:02<00:01, 310.71 examples/s]Tokenizing eval dataset:  70%|██████▉   | 667/953 [00:02<00:00, 344.62 examples/s]Tokenizing eval dataset:  52%|█████▏    | 491/953 [00:02<00:01, 317.13 examples/s]Tokenizing eval dataset:  65%|██████▍   | 616/953 [00:02<00:01, 319.22 examples/s]Tokenizing eval dataset:  76%|███████▌  | 726/953 [00:03<00:00, 339.40 examples/s]Tokenizing eval dataset:  59%|█████▊    | 558/953 [00:02<00:01, 342.21 examples/s]Tokenizing eval dataset:  71%|███████   | 674/953 [00:02<00:00, 377.88 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:03<00:00, 346.24 examples/s]Tokenizing eval dataset:  65%|██████▌   | 620/953 [00:02<00:00, 360.67 examples/s]Tokenizing eval dataset:  78%|███████▊  | 739/953 [00:03<00:00, 392.79 examples/s]Tokenizing eval dataset:  87%|████████▋ | 833/953 [00:03<00:00, 335.55 examples/s]Tokenizing eval dataset:  72%|███████▏  | 683/953 [00:03<00:00, 369.09 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:03<00:00, 410.09 examples/s]Tokenizing eval dataset:  93%|█████████▎| 887/953 [00:03<00:00, 323.83 examples/s]Tokenizing eval dataset:  77%|███████▋  | 734/953 [00:03<00:00, 337.81 examples/s]Tokenizing eval dataset:  88%|████████▊ | 839/953 [00:03<00:00, 362.43 examples/s]Tokenizing eval dataset:  99%|█████████▊| 940/953 [00:03<00:00, 323.96 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 244.83 examples/s]Tokenizing eval dataset:  82%|████████▏ | 786/953 [00:03<00:00, 306.94 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  93%|█████████▎| 889/953 [00:03<00:00, 291.70 examples/s]Tokenizing eval dataset:  86%|████████▌ | 820/953 [00:03<00:00, 310.53 examples/s]Tokenizing eval dataset:  99%|█████████▊| 939/953 [00:03<00:00, 329.83 examples/s]Tokenizing eval dataset:  90%|█████████ | 860/953 [00:03<00:00, 326.68 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 251.33 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:03<00:00, 355.43 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 323.18 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:03<00:00, 240.19 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.510906934738159 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.6434664726257324 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 3.099973201751709 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.9573049545288086 seconds
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Training complete
Saving model
[rank4]:[W604 17:07:59.450318574 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 1 ---
