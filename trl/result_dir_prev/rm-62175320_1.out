cpu-bind=MASK - gn05, task  1  0 [1222518]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 1 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn04
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 1     --main_process_ip gn04     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62175320     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-06-01 14:21:37,676] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0601 14:21:39.550000 1222572 torch/distributed/run.py:792] 
W0601 14:21:39.550000 1222572 torch/distributed/run.py:792] *****************************************
W0601 14:21:39.550000 1222572 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0601 14:21:39.550000 1222572 torch/distributed/run.py:792] *****************************************
[2025-06-01 14:21:45,041] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-01 14:21:45,107] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-01 14:21:45,118] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-06-01 14:21:45,120] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 2
[2025-06-01 14:21:48,291] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-01 14:21:48,295] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 535
Eval steps: 267
[2025-06-01 14:21:48,305] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-06-01 14:21:48,306] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:16, 25.54s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:18, 26.13s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:18, 26.13s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:18, 26.13s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:50<00:50, 25.06s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:50<00:50, 25.28s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:50<00:50, 25.28s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:50<00:50, 25.28s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.53s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.76s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.89s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.76s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.90s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.76s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.78s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.99s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 21.70s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.99s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.99s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Using LoRA and set up the model
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
Total Parameters: 9457.78M
Trainable Parameters (LoRA): 216.07M
Percentage of Trainable Params: 2.2846%
[rank6]:[W601 14:23:25.140299768 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 6]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loaded tokenizer
[rank7]:[W601 14:23:25.268318083 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 7]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank5]:[W601 14:23:25.269282190 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 5]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   7%|▋         | 557/8564 [00:00<00:01, 5523.84 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1120/8564 [00:00<00:01, 5563.48 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1680/8564 [00:00<00:01, 5574.35 examples/s]Extracting prompt in train dataset:  26%|██▋       | 2251/8564 [00:00<00:01, 5626.82 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2830/8564 [00:00<00:01, 5651.46 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3660/8564 [00:00<00:00, 5574.10 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4240/8564 [00:00<00:00, 5608.78 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4810/8564 [00:00<00:00, 5629.72 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5399/8564 [00:00<00:00, 5705.74 examples/s]Extracting prompt in train dataset:  70%|██████▉   | 5984/8564 [00:01<00:00, 5732.74 examples/s]Extracting prompt in train dataset:  77%|███████▋  | 6570/8564 [00:01<00:00, 5754.93 examples/s]Extracting prompt in train dataset:  84%|████████▎ | 7154/8564 [00:01<00:00, 5780.02 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 8020/8564 [00:01<00:00, 5587.52 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5516.56 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 289/8564 [00:00<00:02, 2858.47 examples/s]Applying chat template to train dataset:   7%|▋         | 603/8564 [00:00<00:02, 3021.75 examples/s]Applying chat template to train dataset:  11%|█         | 919/8564 [00:00<00:02, 3078.28 examples/s]Applying chat template to train dataset:  14%|█▍        | 1235/8564 [00:00<00:02, 3106.34 examples/s]Applying chat template to train dataset:  18%|█▊        | 1546/8564 [00:00<00:02, 3104.68 examples/s]Applying chat template to train dataset:  22%|██▏       | 1861/8564 [00:00<00:02, 3119.44 examples/s]Applying chat template to train dataset:  25%|██▌       | 2180/8564 [00:00<00:02, 3135.39 examples/s]Applying chat template to train dataset:  29%|██▉       | 2500/8564 [00:00<00:01, 3150.81 examples/s]Applying chat template to train dataset:  33%|███▎      | 2820/8564 [00:00<00:01, 3160.82 examples/s]Applying chat template to train dataset:  38%|███▊      | 3280/8564 [00:01<00:01, 3113.51 examples/s]Applying chat template to train dataset:  44%|████▎     | 3743/8564 [00:01<00:01, 3099.53 examples/s]Applying chat template to train dataset:  47%|████▋     | 4058/8564 [00:01<00:01, 3104.92 examples/s]Applying chat template to train dataset:  51%|█████     | 4370/8564 [00:01<00:01, 3103.12 examples/s]Applying chat template to train dataset:  56%|█████▋    | 4825/8564 [00:01<00:01, 3073.43 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5137/8564 [00:01<00:01, 3080.24 examples/s]Applying chat template to train dataset:  64%|██████▎   | 5449/8564 [00:01<00:01, 3087.83 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5760/8564 [00:01<00:00, 3088.47 examples/s]Applying chat template to train dataset:  71%|███████   | 6071/8564 [00:01<00:00, 3093.59 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6382/8564 [00:02<00:00, 3095.54 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6847/8564 [00:02<00:00, 3093.03 examples/s]Applying chat template to train dataset:  84%|████████▎ | 7157/8564 [00:02<00:00, 3092.18 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7467/8564 [00:02<00:00, 3091.17 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7910/8564 [00:02<00:00, 2998.58 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8235/8564 [00:02<00:00, 3059.55 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8560/8564 [00:02<00:00, 3106.61 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3086.09 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 41/8564 [00:00<00:21, 396.91 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:25, 337.15 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:26, 320.57 examples/s]Tokenizing train dataset:   2%|▏         | 183/8564 [00:00<00:27, 307.27 examples/s]Tokenizing train dataset:   3%|▎         | 218/8564 [00:00<00:26, 314.82 examples/s]Tokenizing train dataset:   3%|▎         | 251/8564 [00:00<00:26, 317.82 examples/s]Tokenizing train dataset:   3%|▎         | 289/8564 [00:00<00:24, 333.73 examples/s]Tokenizing train dataset:   4%|▍         | 337/8564 [00:01<00:25, 325.84 examples/s]Tokenizing train dataset:   5%|▍         | 387/8564 [00:01<00:25, 324.39 examples/s]Tokenizing train dataset:   5%|▌         | 434/8564 [00:01<00:25, 316.03 examples/s]Tokenizing train dataset:   6%|▌         | 480/8564 [00:01<00:26, 309.50 examples/s]Tokenizing train dataset:   6%|▌         | 516/8564 [00:01<00:28, 284.17 examples/s]Tokenizing train dataset:   6%|▋         | 550/8564 [00:01<00:27, 294.56 examples/s]Tokenizing train dataset:   7%|▋         | 580/8564 [00:01<00:27, 294.00 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:01<00:26, 297.60 examples/s]Tokenizing train dataset:   8%|▊         | 650/8564 [00:02<00:25, 314.18 examples/s]Tokenizing train dataset:   8%|▊         | 694/8564 [00:02<00:25, 303.23 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:02<00:25, 311.07 examples/s]Tokenizing train dataset:   9%|▉         | 762/8564 [00:02<00:24, 313.28 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:02<00:25, 298.44 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:02<00:26, 292.78 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:02<00:25, 301.44 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:02<00:24, 306.96 examples/s]Tokenizing train dataset:  11%|█▏        | 968/8564 [00:03<00:24, 310.00 examples/s]Tokenizing train dataset:  12%|█▏        | 1009/8564 [00:03<00:25, 296.00 examples/s]Tokenizing train dataset:  12%|█▏        | 1053/8564 [00:03<00:25, 290.89 examples/s]Tokenizing train dataset:  13%|█▎        | 1087/8564 [00:03<00:24, 299.71 examples/s]Tokenizing train dataset:  13%|█▎        | 1120/8564 [00:03<00:24, 302.06 examples/s]Tokenizing train dataset:  14%|█▎        | 1161/8564 [00:03<00:25, 289.23 examples/s]Tokenizing train dataset:  14%|█▍        | 1197/8564 [00:03<00:24, 304.10 examples/s]Tokenizing train dataset:  14%|█▍        | 1229/8564 [00:04<00:24, 304.29 examples/s]Tokenizing train dataset:  15%|█▍        | 1265/8564 [00:04<00:23, 314.68 examples/s]Tokenizing train dataset:  15%|█▌        | 1298/8564 [00:04<00:23, 313.17 examples/s]Tokenizing train dataset:  16%|█▌        | 1330/8564 [00:04<00:23, 313.52 examples/s]Tokenizing train dataset:  16%|█▌        | 1373/8564 [00:04<00:24, 296.54 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:04<00:23, 303.22 examples/s]Tokenizing train dataset:  17%|█▋        | 1453/8564 [00:04<00:23, 299.29 examples/s]Tokenizing train dataset:  18%|█▊        | 1499/8564 [00:04<00:23, 296.73 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:05<00:23, 296.58 examples/s]Tokenizing train dataset:  18%|█▊        | 1561/8564 [00:05<00:23, 297.17 examples/s]Tokenizing train dataset:  19%|█▊        | 1591/8564 [00:05<00:23, 292.87 examples/s]Tokenizing train dataset:  19%|█▉        | 1627/8564 [00:05<00:22, 303.60 examples/s]Tokenizing train dataset:  19%|█▉        | 1661/8564 [00:05<00:22, 311.63 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:05<00:20, 339.23 examples/s]Tokenizing train dataset:  20%|██        | 1753/8564 [00:05<00:20, 328.50 examples/s]Tokenizing train dataset:  21%|██        | 1800/8564 [00:05<00:20, 322.22 examples/s]Tokenizing train dataset:  21%|██▏       | 1834/8564 [00:05<00:20, 323.92 examples/s]Tokenizing train dataset:  22%|██▏       | 1880/8564 [00:06<00:21, 309.99 examples/s]Tokenizing train dataset:  22%|██▏       | 1920/8564 [00:06<00:20, 330.66 examples/s]Tokenizing train dataset:  23%|██▎       | 1958/8564 [00:06<00:19, 341.08 examples/s]Tokenizing train dataset:  23%|██▎       | 1994/8564 [00:06<00:19, 344.15 examples/s]Tokenizing train dataset:  24%|██▍       | 2035/8564 [00:06<00:18, 356.53 examples/s]Tokenizing train dataset:  24%|██▍       | 2091/8564 [00:06<00:17, 360.00 examples/s]Tokenizing train dataset:  25%|██▍       | 2130/8564 [00:06<00:17, 365.47 examples/s]Tokenizing train dataset:  25%|██▌       | 2167/8564 [00:06<00:17, 361.44 examples/s]Tokenizing train dataset:  26%|██▌       | 2224/8564 [00:07<00:17, 365.42 examples/s]Tokenizing train dataset:  27%|██▋       | 2285/8564 [00:07<00:16, 375.44 examples/s]Tokenizing train dataset:  27%|██▋       | 2339/8564 [00:07<00:17, 363.25 examples/s]Tokenizing train dataset:  28%|██▊       | 2395/8564 [00:07<00:16, 363.12 examples/s]Tokenizing train dataset:  28%|██▊       | 2435/8564 [00:07<00:16, 367.56 examples/s]Tokenizing train dataset:  29%|██▉       | 2474/8564 [00:07<00:16, 372.13 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:07<00:16, 364.70 examples/s]Tokenizing train dataset:  30%|███       | 2571/8564 [00:07<00:15, 374.59 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:08<00:16, 353.20 examples/s]Tokenizing train dataset:  31%|███       | 2670/8564 [00:08<00:17, 344.47 examples/s]Tokenizing train dataset:  32%|███▏      | 2705/8564 [00:08<00:16, 344.70 examples/s]Tokenizing train dataset:  32%|███▏      | 2740/8564 [00:08<00:17, 341.81 examples/s]Tokenizing train dataset:  32%|███▏      | 2775/8564 [00:08<00:16, 342.49 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:08<00:15, 363.14 examples/s]Tokenizing train dataset:  34%|███▎      | 2870/8564 [00:08<00:16, 344.03 examples/s]Tokenizing train dataset:  34%|███▍      | 2914/8564 [00:08<00:15, 366.83 examples/s]Tokenizing train dataset:  35%|███▍      | 2957/8564 [00:09<00:14, 379.89 examples/s]Tokenizing train dataset:  35%|███▌      | 3000/8564 [00:09<00:14, 389.11 examples/s]Tokenizing train dataset:  36%|███▌      | 3054/8564 [00:09<00:14, 371.74 examples/s]Tokenizing train dataset:  36%|███▌      | 3092/8564 [00:09<00:14, 371.97 examples/s]Tokenizing train dataset:  37%|███▋      | 3148/8564 [00:09<00:14, 367.98 examples/s]Tokenizing train dataset:  37%|███▋      | 3203/8564 [00:09<00:14, 365.00 examples/s]Tokenizing train dataset:  38%|███▊      | 3243/8564 [00:09<00:14, 369.44 examples/s]Tokenizing train dataset:  39%|███▊      | 3298/8564 [00:09<00:14, 364.42 examples/s]Tokenizing train dataset:  39%|███▉      | 3350/8564 [00:10<00:14, 355.78 examples/s]Tokenizing train dataset:  40%|███▉      | 3394/8564 [00:10<00:14, 367.75 examples/s]Tokenizing train dataset:  40%|████      | 3435/8564 [00:10<00:13, 375.47 examples/s]Tokenizing train dataset:  41%|████      | 3489/8564 [00:10<00:13, 365.84 examples/s]Tokenizing train dataset:  41%|████      | 3530/8564 [00:10<00:13, 374.93 examples/s]Tokenizing train dataset:  42%|████▏     | 3587/8564 [00:10<00:13, 373.17 examples/s]Tokenizing train dataset:  42%|████▏     | 3627/8564 [00:10<00:13, 375.88 examples/s]Tokenizing train dataset:  43%|████▎     | 3677/8564 [00:11<00:13, 354.81 examples/s]Tokenizing train dataset:  43%|████▎     | 3715/8564 [00:11<00:13, 360.51 examples/s]Tokenizing train dataset:  44%|████▍     | 3755/8564 [00:11<00:13, 365.77 examples/s]Tokenizing train dataset:  44%|████▍     | 3795/8564 [00:11<00:12, 368.94 examples/s]Tokenizing train dataset:  45%|████▍     | 3848/8564 [00:11<00:13, 358.96 examples/s]Tokenizing train dataset:  45%|████▌     | 3886/8564 [00:11<00:12, 361.79 examples/s]Tokenizing train dataset:  46%|████▌     | 3939/8564 [00:11<00:13, 351.99 examples/s]Tokenizing train dataset:  47%|████▋     | 3990/8564 [00:11<00:13, 345.33 examples/s]Tokenizing train dataset:  47%|████▋     | 4032/8564 [00:12<00:12, 358.79 examples/s]Tokenizing train dataset:  48%|████▊     | 4069/8564 [00:12<00:12, 359.10 examples/s]Tokenizing train dataset:  48%|████▊     | 4123/8564 [00:12<00:12, 355.25 examples/s]Tokenizing train dataset:  49%|████▉     | 4176/8564 [00:12<00:12, 350.66 examples/s]Tokenizing train dataset:  49%|████▉     | 4215/8564 [00:12<00:12, 359.34 examples/s]Tokenizing train dataset:  50%|████▉     | 4270/8564 [00:12<00:12, 356.08 examples/s]Tokenizing train dataset:  50%|█████     | 4309/8564 [00:12<00:11, 359.67 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:12<00:11, 352.51 examples/s]Tokenizing train dataset:  51%|█████▏    | 4402/8564 [00:13<00:11, 364.31 examples/s]Tokenizing train dataset:  52%|█████▏    | 4439/8564 [00:13<00:11, 361.93 examples/s]Tokenizing train dataset:  52%|█████▏    | 4476/8564 [00:13<00:11, 363.40 examples/s]Tokenizing train dataset:  53%|█████▎    | 4529/8564 [00:13<00:11, 352.48 examples/s]Tokenizing train dataset:  53%|█████▎    | 4569/8564 [00:13<00:11, 359.62 examples/s]Tokenizing train dataset:  54%|█████▍    | 4622/8564 [00:13<00:11, 353.71 examples/s]Tokenizing train dataset:  55%|█████▍    | 4670/8564 [00:13<00:11, 339.49 examples/s]Tokenizing train dataset:  55%|█████▌    | 4718/8564 [00:13<00:11, 328.60 examples/s]Tokenizing train dataset:  56%|█████▌    | 4767/8564 [00:14<00:11, 323.80 examples/s]Tokenizing train dataset:  56%|█████▌    | 4800/8564 [00:14<00:11, 322.32 examples/s]Tokenizing train dataset:  57%|█████▋    | 4865/8564 [00:14<00:09, 397.62 examples/s]Tokenizing train dataset:  58%|█████▊    | 4930/8564 [00:14<00:07, 459.36 examples/s]Tokenizing train dataset:  58%|█████▊    | 4989/8564 [00:14<00:07, 490.75 examples/s]Tokenizing train dataset:  59%|█████▉    | 5049/8564 [00:14<00:06, 519.09 examples/s]Tokenizing train dataset:  60%|█████▉    | 5116/8564 [00:14<00:06, 559.51 examples/s]Tokenizing train dataset:  61%|██████    | 5187/8564 [00:14<00:05, 598.01 examples/s]Tokenizing train dataset:  61%|██████▏   | 5261/8564 [00:14<00:05, 635.62 examples/s]Tokenizing train dataset:  63%|██████▎   | 5356/8564 [00:15<00:05, 632.83 examples/s]Tokenizing train dataset:  64%|██████▎   | 5451/8564 [00:15<00:04, 628.05 examples/s]Tokenizing train dataset:  65%|██████▍   | 5537/8564 [00:15<00:04, 607.48 examples/s]Tokenizing train dataset:  65%|██████▌   | 5601/8564 [00:15<00:04, 610.89 examples/s]Tokenizing train dataset:  66%|██████▌   | 5669/8564 [00:15<00:04, 625.94 examples/s]Tokenizing train dataset:  67%|██████▋   | 5772/8564 [00:15<00:04, 644.46 examples/s]Tokenizing train dataset:  68%|██████▊   | 5842/8564 [00:15<00:04, 650.51 examples/s]Tokenizing train dataset:  69%|██████▉   | 5931/8564 [00:16<00:04, 623.69 examples/s]Tokenizing train dataset:  70%|███████   | 6016/8564 [00:16<00:04, 601.37 examples/s]Tokenizing train dataset:  71%|███████   | 6077/8564 [00:16<00:04, 601.47 examples/s]Tokenizing train dataset:  72%|███████▏  | 6138/8564 [00:16<00:04, 601.58 examples/s]Tokenizing train dataset:  73%|███████▎  | 6210/8564 [00:16<00:03, 631.61 examples/s]Tokenizing train dataset:  73%|███████▎  | 6280/8564 [00:16<00:03, 641.85 examples/s]Tokenizing train dataset:  74%|███████▍  | 6347/8564 [00:16<00:03, 644.46 examples/s]Tokenizing train dataset:  75%|███████▍  | 6414/8564 [00:16<00:03, 643.45 examples/s]Tokenizing train dataset:  76%|███████▌  | 6504/8564 [00:16<00:03, 620.70 examples/s]Tokenizing train dataset:  77%|███████▋  | 6567/8564 [00:17<00:03, 621.27 examples/s]Tokenizing train dataset:  78%|███████▊  | 6646/8564 [00:17<00:03, 580.22 examples/s]Tokenizing train dataset:  78%|███████▊  | 6718/8564 [00:17<00:03, 611.65 examples/s]Tokenizing train dataset:  79%|███████▉  | 6783/8564 [00:17<00:02, 620.38 examples/s]Tokenizing train dataset:  80%|████████  | 6872/8564 [00:17<00:02, 603.27 examples/s]Tokenizing train dataset:  81%|████████  | 6944/8564 [00:17<00:02, 627.57 examples/s]Tokenizing train dataset:  82%|████████▏ | 7020/8564 [00:17<00:02, 582.20 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [00:17<00:02, 610.65 examples/s]Tokenizing train dataset:  84%|████████▎ | 7154/8564 [00:18<00:02, 611.81 examples/s]Tokenizing train dataset:  84%|████████▍ | 7221/8564 [00:18<00:02, 626.03 examples/s]Tokenizing train dataset:  85%|████████▌ | 7313/8564 [00:18<00:02, 613.43 examples/s]Tokenizing train dataset:  86%|████████▌ | 7378/8564 [00:18<00:01, 621.29 examples/s]Tokenizing train dataset:  87%|████████▋ | 7443/8564 [00:18<00:01, 624.87 examples/s]Tokenizing train dataset:  88%|████████▊ | 7543/8564 [00:18<00:01, 633.76 examples/s]Tokenizing train dataset:  89%|████████▉ | 7612/8564 [00:18<00:01, 642.62 examples/s]Tokenizing train dataset:  90%|████████▉ | 7697/8564 [00:18<00:01, 614.38 examples/s]Tokenizing train dataset:  91%|█████████ | 7783/8564 [00:19<00:01, 594.86 examples/s]Tokenizing train dataset:  92%|█████████▏| 7844/8564 [00:19<00:01, 596.01 examples/s]Tokenizing train dataset:  92%|█████████▏| 7905/8564 [00:19<00:01, 596.66 examples/s]Tokenizing train dataset:  93%|█████████▎| 7966/8564 [00:19<00:00, 598.56 examples/s]Tokenizing train dataset:  94%|█████████▍| 8032/8564 [00:19<00:00, 605.81 examples/s]Tokenizing train dataset:  95%|█████████▍| 8120/8564 [00:19<00:00, 590.43 examples/s]Tokenizing train dataset:  96%|█████████▌| 8184/8564 [00:19<00:00, 599.00 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [00:19<00:00, 608.86 examples/s]Tokenizing train dataset:  97%|█████████▋| 8328/8564 [00:19<00:00, 647.07 examples/s]Tokenizing train dataset:  98%|█████████▊| 8410/8564 [00:20<00:00, 606.95 examples/s]Tokenizing train dataset:  99%|█████████▉| 8474/8564 [00:20<00:00, 613.71 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 609.49 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 421.06 examples/s]
[rank4]:[W601 14:23:51.837775099 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 4]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11068.91 examples/s]
Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:00<00:01, 5462.42 examples/s]Extracting prompt in train dataset:   7%|▋         | 560/8564 [00:00<00:01, 5528.21 examples/s]Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:00<00:01, 5398.96 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1136/8564 [00:00<00:01, 5659.96 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1120/8564 [00:00<00:01, 5553.94 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1115/8564 [00:00<00:01, 5527.92 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1710/8564 [00:00<00:01, 5680.67 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1690/8564 [00:00<00:01, 5586.21 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1675/8564 [00:00<00:01, 5535.13 examples/s]Extracting prompt in train dataset:  27%|██▋       | 2298/8564 [00:00<00:01, 5755.51 examples/s]Extracting prompt in train dataset:  26%|██▋       | 2260/8564 [00:00<00:01, 5628.76 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2240/8564 [00:00<00:01, 5572.89 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13529.65 examples/s]
Extracting prompt in train dataset:  34%|███▎      | 2885/8564 [00:00<00:00, 5780.51 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2810/8564 [00:00<00:01, 5604.32 examples/s]Extracting prompt in train dataset:  33%|███▎      | 2840/8564 [00:00<00:01, 5660.10 examples/s]Extracting prompt in train dataset:  44%|████▎     | 3730/8564 [00:00<00:00, 5697.80 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3670/8564 [00:00<00:00, 5581.09 examples/s]Extracting prompt in train dataset:  43%|████▎     | 3640/8564 [00:00<00:00, 5535.57 examples/s]Extracting prompt in train dataset:  50%|█████     | 4320/8564 [00:00<00:00, 5741.41 examples/s]Extracting prompt in train dataset:  49%|████▉     | 4210/8564 [00:00<00:00, 5574.59 examples/s]Extracting prompt in train dataset:  50%|████▉     | 4250/8564 [00:00<00:00, 5621.29 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4909/8564 [00:00<00:00, 5783.60 examples/s]Extracting prompt in train dataset:  56%|█████▋    | 4820/8564 [00:00<00:00, 5640.89 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4780/8564 [00:00<00:00, 5594.60 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 327.04 examples/s]Extracting prompt in train dataset:  64%|██████▍   | 5501/8564 [00:00<00:00, 5821.64 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5406/8564 [00:00<00:00, 5703.59 examples/s]Extracting prompt in train dataset:  63%|██████▎   | 5362/8564 [00:00<00:00, 5656.86 examples/s]Extracting prompt in train dataset:  71%|███████   | 6100/8564 [00:01<00:00, 5867.73 examples/s]Extracting prompt in train dataset:  69%|██████▉   | 5944/8564 [00:01<00:00, 5703.06 examples/s]Extracting prompt in train dataset:  70%|███████   | 5996/8564 [00:01<00:00, 5745.03 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 297.77 examples/s]Extracting prompt in train dataset:  78%|███████▊  | 6697/8564 [00:01<00:00, 5881.68 examples/s]Extracting prompt in train dataset:  76%|███████▌  | 6530/8564 [00:01<00:00, 5738.14 examples/s]Extracting prompt in train dataset:  80%|███████▉  | 6840/8564 [00:01<00:00, 5693.72 examples/s]Extracting prompt in train dataset:  85%|████████▌ | 7291/8564 [00:01<00:00, 5896.66 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7111/8564 [00:01<00:00, 5755.26 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:02, 279.24 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 7683/8564 [00:01<00:00, 5666.24 examples/s]Extracting prompt in train dataset:  90%|████████▉ | 7693/8564 [00:01<00:00, 5772.77 examples/s]Extracting prompt in train dataset:  95%|█████████▍| 8104/8564 [00:01<00:00, 5707.71 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 270.17 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5735.23 examples/s]
Extracting prompt in train dataset:  99%|█████████▉| 8470/8564 [00:01<00:00, 5506.99 examples/s]Extracting prompt in train dataset:  99%|█████████▉| 8490/8564 [00:01<00:00, 5569.20 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5583.10 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 5572.14 examples/s]
Tokenizing eval dataset:  21%|██        | 199/953 [00:00<00:02, 262.01 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:00<00:02, 293.09 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:00<00:01, 387.65 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  39%|███▊      | 368/953 [00:01<00:01, 453.51 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 290/8564 [00:00<00:02, 2863.79 examples/s]Tokenizing eval dataset:  46%|████▌     | 437/953 [00:01<00:00, 517.17 examples/s]Applying chat template to train dataset:   3%|▎         | 279/8564 [00:00<00:03, 2756.28 examples/s]Applying chat template to train dataset:   3%|▎         | 280/8564 [00:00<00:02, 2761.66 examples/s]Applying chat template to train dataset:   7%|▋         | 605/8564 [00:00<00:02, 3025.27 examples/s]Applying chat template to train dataset:   7%|▋         | 583/8564 [00:00<00:02, 2917.53 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:01<00:00, 559.18 examples/s]Applying chat template to train dataset:   7%|▋         | 584/8564 [00:00<00:02, 2919.14 examples/s]Applying chat template to train dataset:  11%|█         | 920/8564 [00:00<00:02, 3069.31 examples/s]Applying chat template to train dataset:  10%|█         | 887/8564 [00:00<00:02, 2971.76 examples/s]Tokenizing eval dataset:  60%|█████▉    | 569/953 [00:01<00:00, 582.30 examples/s]Applying chat template to train dataset:  10%|█         | 886/8564 [00:00<00:02, 2961.43 examples/s]Applying chat template to train dataset:  14%|█▍        | 1236/8564 [00:00<00:02, 3103.50 examples/s]Applying chat template to train dataset:  14%|█▍        | 1194/8564 [00:00<00:02, 3000.70 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:01<00:00, 607.72 examples/s]Applying chat template to train dataset:  14%|█▍        | 1190/8564 [00:00<00:02, 2985.66 examples/s]Applying chat template to train dataset:  18%|█▊        | 1548/8564 [00:00<00:02, 3107.60 examples/s]Applying chat template to train dataset:  17%|█▋        | 1495/8564 [00:00<00:02, 3000.83 examples/s]Applying chat template to train dataset:  17%|█▋        | 1491/8564 [00:00<00:02, 2989.12 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 597.99 examples/s]Applying chat template to train dataset:  22%|██▏       | 1864/8564 [00:00<00:02, 3121.13 examples/s]Applying chat template to train dataset:  21%|██        | 1801/8564 [00:00<00:02, 3017.42 examples/s]Applying chat template to train dataset:  21%|██        | 1796/8564 [00:00<00:02, 3008.47 examples/s]Applying chat template to train dataset:  25%|██▌       | 2182/8564 [00:00<00:02, 3138.07 examples/s]Applying chat template to train dataset:  25%|██▍       | 2110/8564 [00:00<00:02, 3033.44 examples/s]Tokenizing eval dataset:  85%|████████▍ | 807/953 [00:01<00:00, 563.18 examples/s]Applying chat template to train dataset:  25%|██▍       | 2102/8564 [00:00<00:02, 3022.35 examples/s]Applying chat template to train dataset:  29%|██▉       | 2501/8564 [00:00<00:01, 3151.91 examples/s]Applying chat template to train dataset:  28%|██▊       | 2418/8564 [00:00<00:02, 3046.81 examples/s]Applying chat template to train dataset:  28%|██▊       | 2410/8564 [00:00<00:02, 3032.45 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:01<00:00, 541.88 examples/s]Applying chat template to train dataset:  33%|███▎      | 2820/8564 [00:00<00:01, 3159.30 examples/s]Applying chat template to train dataset:  32%|███▏      | 2725/8564 [00:00<00:01, 3052.44 examples/s]Applying chat template to train dataset:  32%|███▏      | 2717/8564 [00:00<00:01, 3041.56 examples/s]Applying chat template to train dataset:  35%|███▌      | 3033/8564 [00:01<00:01, 3059.56 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 530.62 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 464.57 examples/s]
Applying chat template to train dataset:  35%|███▌      | 3025/8564 [00:01<00:01, 3046.28 examples/s]Applying chat template to train dataset:  38%|███▊      | 3280/8564 [00:01<00:01, 3114.48 examples/s]Applying chat template to train dataset:  42%|████▏     | 3598/8564 [00:01<00:01, 3130.15 examples/s]Applying chat template to train dataset:  41%|████      | 3475/8564 [00:01<00:01, 3010.73 examples/s]Applying chat template to train dataset:  40%|████      | 3465/8564 [00:01<00:01, 2997.90 examples/s]Applying chat template to train dataset:  46%|████▌     | 3914/8564 [00:01<00:01, 3137.83 examples/s]Applying chat template to train dataset:  44%|████▍     | 3781/8564 [00:01<00:01, 3021.68 examples/s]Applying chat template to train dataset:  44%|████▍     | 3770/8564 [00:01<00:01, 3009.07 examples/s]Applying chat template to train dataset:  49%|████▉     | 4230/8564 [00:01<00:01, 3139.36 examples/s]Applying chat template to train dataset:  48%|████▊     | 4090/8564 [00:01<00:01, 3032.59 examples/s]Applying chat template to train dataset:  48%|████▊     | 4076/8564 [00:01<00:01, 3020.64 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4548/8564 [00:01<00:01, 3148.54 examples/s]Applying chat template to train dataset:  51%|█████▏    | 4403/8564 [00:01<00:01, 3058.90 examples/s]Applying chat template to train dataset:  51%|█████     | 4380/8564 [00:01<00:01, 3023.79 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4865/8564 [00:01<00:01, 3151.48 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4716/8564 [00:01<00:01, 3074.52 examples/s]Applying chat template to train dataset:  55%|█████▍    | 4685/8564 [00:01<00:01, 3028.57 examples/s]Applying chat template to train dataset:  61%|██████    | 5190/8564 [00:01<00:01, 3174.22 examples/s]Applying chat template to train dataset:  59%|█████▉    | 5033/8564 [00:01<00:01, 3100.25 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4993/8564 [00:01<00:01, 3042.19 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5514/8564 [00:01<00:00, 3192.22 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5353/8564 [00:01<00:01, 3128.96 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5308/8564 [00:01<00:01, 3066.44 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5839/8564 [00:01<00:00, 3208.12 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5673/8564 [00:01<00:00, 3145.62 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5620/8564 [00:01<00:00, 3077.24 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6162/8564 [00:01<00:00, 3211.91 examples/s]Applying chat template to train dataset:  70%|██████▉   | 5993/8564 [00:01<00:00, 3159.09 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5933/8564 [00:01<00:00, 3088.60 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6488/8564 [00:02<00:00, 3222.87 examples/s]Applying chat template to train dataset:  74%|███████▎  | 6314/8564 [00:02<00:00, 3172.16 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6248/8564 [00:02<00:00, 3098.77 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6813/8564 [00:02<00:00, 3223.05 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6634/8564 [00:02<00:00, 3177.27 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6560/8564 [00:02<00:00, 3098.70 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7137/8564 [00:02<00:00, 3226.58 examples/s]Applying chat template to train dataset:  81%|████████  | 6954/8564 [00:02<00:00, 3181.68 examples/s]Applying chat template to train dataset:  80%|████████  | 6871/8564 [00:02<00:00, 3098.90 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7461/8564 [00:02<00:00, 3226.13 examples/s]Applying chat template to train dataset:  85%|████████▍ | 7274/8564 [00:02<00:00, 3183.63 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7183/8564 [00:02<00:00, 3102.70 examples/s]Applying chat template to train dataset:  89%|████████▊ | 7595/8564 [00:02<00:00, 3188.20 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7495/8564 [00:02<00:00, 3105.76 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7911/8564 [00:02<00:00, 3109.54 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8236/8564 [00:02<00:00, 3144.77 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8062/8564 [00:02<00:00, 3057.62 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7917/8564 [00:02<00:00, 2983.99 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8560/8564 [00:02<00:00, 3166.39 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3147.43 examples/s]
Applying chat template to train dataset:  98%|█████████▊| 8376/8564 [00:02<00:00, 3078.48 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8229/8564 [00:02<00:00, 3018.05 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3071.33 examples/s]
Applying chat template to train dataset: 100%|█████████▉| 8541/8564 [00:02<00:00, 3044.10 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 3030.26 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:20, 406.26 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:21, 400.16 examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:20, 409.29 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:25, 337.97 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:24, 339.79 examples/s]Tokenizing train dataset:   1%|          | 90/8564 [00:00<00:24, 341.30 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:26, 319.63 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:26, 321.68 examples/s]Tokenizing train dataset:   2%|▏         | 139/8564 [00:00<00:26, 322.15 examples/s]Tokenizing train dataset:   2%|▏         | 176/8564 [00:00<00:29, 285.59 examples/s]Tokenizing train dataset:   2%|▏         | 184/8564 [00:00<00:27, 309.51 examples/s]Tokenizing train dataset:   2%|▏         | 210/8564 [00:00<00:28, 296.91 examples/s]Tokenizing train dataset:   2%|▏         | 184/8564 [00:00<00:27, 309.58 examples/s]Tokenizing train dataset:   3%|▎         | 218/8564 [00:00<00:26, 315.42 examples/s]Tokenizing train dataset:   3%|▎         | 245/8564 [00:00<00:26, 308.81 examples/s]Tokenizing train dataset:   3%|▎         | 218/8564 [00:00<00:26, 315.07 examples/s]Tokenizing train dataset:   3%|▎         | 252/8564 [00:00<00:25, 320.28 examples/s]Tokenizing train dataset:   3%|▎         | 282/8564 [00:00<00:25, 320.89 examples/s]Tokenizing train dataset:   3%|▎         | 252/8564 [00:00<00:25, 319.82 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:00<00:24, 333.39 examples/s]Tokenizing train dataset:   4%|▎         | 315/8564 [00:00<00:25, 319.35 examples/s]Tokenizing train dataset:   3%|▎         | 290/8564 [00:00<00:24, 332.86 examples/s]Tokenizing train dataset:   4%|▍         | 324/8564 [00:00<00:24, 332.18 examples/s]Tokenizing train dataset:   4%|▍         | 324/8564 [00:00<00:24, 331.43 examples/s]Tokenizing train dataset:   4%|▍         | 364/8564 [00:01<00:25, 317.29 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:01<00:25, 318.57 examples/s]Tokenizing train dataset:   5%|▍         | 397/8564 [00:01<00:25, 317.96 examples/s]Tokenizing train dataset:   4%|▍         | 370/8564 [00:01<00:25, 317.85 examples/s]Tokenizing train dataset:   5%|▌         | 430/8564 [00:01<00:25, 319.97 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:01<00:25, 317.02 examples/s]Tokenizing train dataset:   5%|▍         | 420/8564 [00:01<00:25, 316.53 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:25, 314.94 examples/s]Tokenizing train dataset:   6%|▌         | 476/8564 [00:01<00:26, 306.87 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:25, 314.77 examples/s]Tokenizing train dataset:   6%|▌         | 516/8564 [00:01<00:26, 308.22 examples/s]Tokenizing train dataset:   6%|▌         | 524/8564 [00:01<00:26, 304.88 examples/s]Tokenizing train dataset:   6%|▌         | 512/8564 [00:01<00:26, 304.62 examples/s]Tokenizing train dataset:   6%|▋         | 550/8564 [00:01<00:25, 313.46 examples/s]Tokenizing train dataset:   7%|▋         | 559/8564 [00:01<00:25, 310.61 examples/s]Tokenizing train dataset:   6%|▋         | 549/8564 [00:01<00:25, 317.66 examples/s]Tokenizing train dataset:   7%|▋         | 596/8564 [00:01<00:25, 308.95 examples/s]Tokenizing train dataset:   7%|▋         | 603/8564 [00:01<00:26, 302.57 examples/s]Tokenizing train dataset:   7%|▋         | 596/8564 [00:01<00:25, 308.79 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:01<00:24, 322.90 examples/s]Tokenizing train dataset:   7%|▋         | 641/8564 [00:02<00:24, 319.63 examples/s]Tokenizing train dataset:   7%|▋         | 634/8564 [00:01<00:24, 323.00 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:02<00:25, 313.97 examples/s]Tokenizing train dataset:   8%|▊         | 688/8564 [00:02<00:25, 312.35 examples/s]Tokenizing train dataset:   8%|▊         | 681/8564 [00:02<00:25, 313.84 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:02<00:25, 312.22 examples/s]Tokenizing train dataset:   9%|▊         | 739/8564 [00:02<00:24, 317.79 examples/s]Tokenizing train dataset:   9%|▊         | 729/8564 [00:02<00:25, 312.13 examples/s]Tokenizing train dataset:   9%|▉         | 763/8564 [00:02<00:24, 313.60 examples/s]Tokenizing train dataset:   9%|▉         | 784/8564 [00:02<00:25, 308.09 examples/s]Tokenizing train dataset:   9%|▉         | 762/8564 [00:02<00:24, 313.87 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:02<00:25, 300.54 examples/s]Tokenizing train dataset:  10%|▉         | 826/8564 [00:02<00:26, 295.27 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:02<00:25, 300.32 examples/s]Tokenizing train dataset:  10%|█         | 859/8564 [00:02<00:25, 301.34 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:02<00:26, 294.78 examples/s]Tokenizing train dataset:  10%|▉         | 850/8564 [00:02<00:26, 294.53 examples/s]Tokenizing train dataset:  10%|█         | 894/8564 [00:02<00:24, 309.94 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:02<00:25, 302.82 examples/s]Tokenizing train dataset:  10%|█         | 885/8564 [00:02<00:25, 302.57 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:02<00:24, 307.91 examples/s]Tokenizing train dataset:  11%|█         | 940/8564 [00:03<00:25, 303.90 examples/s]Tokenizing train dataset:  11%|█         | 920/8564 [00:02<00:24, 307.55 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:03<00:24, 306.12 examples/s]Tokenizing train dataset:  11%|█▏        | 972/8564 [00:03<00:24, 306.96 examples/s]Tokenizing train dataset:  11%|█         | 952/8564 [00:03<00:24, 305.69 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:03<00:25, 301.92 examples/s]Tokenizing train dataset:  11%|█▏        | 983/8564 [00:03<00:25, 301.35 examples/s]Tokenizing train dataset:  12%|█▏        | 1014/8564 [00:03<00:25, 291.47 examples/s]Tokenizing train dataset:  12%|█▏        | 1027/8564 [00:03<00:25, 292.64 examples/s]Tokenizing train dataset:  12%|█▏        | 1027/8564 [00:03<00:25, 292.06 examples/s]Tokenizing train dataset:  12%|█▏        | 1060/8564 [00:03<00:25, 292.15 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:03<00:25, 293.90 examples/s]Tokenizing train dataset:  13%|█▎        | 1096/8564 [00:03<00:24, 303.38 examples/s]Tokenizing train dataset:  13%|█▎        | 1073/8564 [00:03<00:25, 293.71 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:03<00:24, 307.01 examples/s]Tokenizing train dataset:  13%|█▎        | 1109/8564 [00:03<00:24, 307.29 examples/s]Tokenizing train dataset:  13%|█▎        | 1140/8564 [00:03<00:25, 293.92 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:03<00:25, 294.77 examples/s]Tokenizing train dataset:  13%|█▎        | 1151/8564 [00:03<00:25, 294.82 examples/s]Tokenizing train dataset:  14%|█▍        | 1188/8564 [00:03<00:24, 297.98 examples/s]Tokenizing train dataset:  14%|█▍        | 1183/8564 [00:03<00:25, 295.10 examples/s]Tokenizing train dataset:  14%|█▍        | 1183/8564 [00:03<00:24, 295.26 examples/s]Tokenizing train dataset:  14%|█▍        | 1220/8564 [00:03<00:24, 297.75 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:03<00:24, 303.47 examples/s]Tokenizing train dataset:  14%|█▍        | 1218/8564 [00:03<00:24, 303.69 examples/s]Tokenizing train dataset:  15%|█▍        | 1257/8564 [00:04<00:23, 311.61 examples/s]Tokenizing train dataset:  15%|█▍        | 1252/8564 [00:04<00:23, 311.47 examples/s]Tokenizing train dataset:  15%|█▍        | 1252/8564 [00:04<00:23, 311.48 examples/s]Tokenizing train dataset:  15%|█▌        | 1285/8564 [00:04<00:23, 311.16 examples/s]Tokenizing train dataset:  15%|█▌        | 1307/8564 [00:04<00:23, 314.91 examples/s]Tokenizing train dataset:  15%|█▌        | 1286/8564 [00:04<00:23, 309.01 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:04<00:22, 315.39 examples/s]Tokenizing train dataset:  16%|█▌        | 1340/8564 [00:04<00:23, 313.27 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:04<00:22, 316.12 examples/s]Tokenizing train dataset:  16%|█▌        | 1353/8564 [00:04<00:23, 312.23 examples/s]Tokenizing train dataset:  16%|█▌        | 1353/8564 [00:04<00:23, 312.90 examples/s]Tokenizing train dataset:  16%|█▌        | 1383/8564 [00:04<00:23, 300.94 examples/s]Tokenizing train dataset:  16%|█▋        | 1397/8564 [00:04<00:23, 302.28 examples/s]Tokenizing train dataset:  17%|█▋        | 1414/8564 [00:04<00:23, 299.36 examples/s]Tokenizing train dataset:  16%|█▋        | 1397/8564 [00:04<00:23, 302.87 examples/s]Tokenizing train dataset:  17%|█▋        | 1428/8564 [00:04<00:23, 301.82 examples/s]Tokenizing train dataset:  17%|█▋        | 1446/8564 [00:04<00:23, 298.81 examples/s]Tokenizing train dataset:  17%|█▋        | 1428/8564 [00:04<00:23, 302.48 examples/s]Tokenizing train dataset:  17%|█▋        | 1476/8564 [00:04<00:23, 295.88 examples/s]Tokenizing train dataset:  17%|█▋        | 1473/8564 [00:04<00:23, 297.41 examples/s]Tokenizing train dataset:  17%|█▋        | 1473/8564 [00:04<00:23, 297.90 examples/s]Tokenizing train dataset:  18%|█▊        | 1518/8564 [00:04<00:24, 286.45 examples/s]Tokenizing train dataset:  18%|█▊        | 1515/8564 [00:04<00:24, 289.10 examples/s]Tokenizing train dataset:  18%|█▊        | 1515/8564 [00:04<00:24, 289.42 examples/s]Tokenizing train dataset:  18%|█▊        | 1551/8564 [00:05<00:23, 294.68 examples/s]Tokenizing train dataset:  18%|█▊        | 1550/8564 [00:05<00:23, 297.68 examples/s]Tokenizing train dataset:  18%|█▊        | 1550/8564 [00:05<00:23, 297.72 examples/s]Tokenizing train dataset:  18%|█▊        | 1582/8564 [00:05<00:23, 297.12 examples/s]Tokenizing train dataset:  18%|█▊        | 1581/8564 [00:05<00:23, 296.71 examples/s]Tokenizing train dataset:  18%|█▊        | 1581/8564 [00:05<00:23, 296.90 examples/s]Tokenizing train dataset:  19%|█▉        | 1614/8564 [00:05<00:23, 301.79 examples/s]Tokenizing train dataset:  19%|█▉        | 1614/8564 [00:05<00:22, 302.18 examples/s]Tokenizing train dataset:  19%|█▉        | 1614/8564 [00:05<00:22, 302.55 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:05<00:21, 314.43 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:05<00:21, 314.54 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:05<00:21, 315.02 examples/s]Tokenizing train dataset:  20%|█▉        | 1686/8564 [00:05<00:21, 319.89 examples/s]Tokenizing train dataset:  20%|█▉        | 1686/8564 [00:05<00:21, 320.14 examples/s]Tokenizing train dataset:  20%|█▉        | 1686/8564 [00:05<00:21, 321.12 examples/s]Tokenizing train dataset:  20%|██        | 1724/8564 [00:05<00:20, 332.64 examples/s]Tokenizing train dataset:  20%|██        | 1725/8564 [00:05<00:20, 331.96 examples/s]Tokenizing train dataset:  20%|██        | 1725/8564 [00:05<00:20, 332.94 examples/s]Tokenizing train dataset:  21%|██        | 1760/8564 [00:05<00:20, 334.82 examples/s]Tokenizing train dataset:  21%|██        | 1760/8564 [00:05<00:20, 335.85 examples/s]Tokenizing train dataset:  21%|██        | 1760/8564 [00:05<00:20, 336.47 examples/s]Tokenizing train dataset:  21%|██        | 1807/8564 [00:05<00:21, 320.48 examples/s]Tokenizing train dataset:  21%|██        | 1807/8564 [00:05<00:21, 321.75 examples/s]Tokenizing train dataset:  21%|██        | 1807/8564 [00:05<00:20, 322.08 examples/s]Tokenizing train dataset:  21%|██▏       | 1841/8564 [00:05<00:20, 322.40 examples/s]Tokenizing train dataset:  21%|██▏       | 1841/8564 [00:05<00:20, 323.83 examples/s]Tokenizing train dataset:  21%|██▏       | 1841/8564 [00:05<00:20, 323.91 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:06<00:21, 308.36 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:06<00:21, 309.71 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:06<00:21, 309.87 examples/s]Tokenizing train dataset:  23%|██▎       | 1930/8564 [00:06<00:19, 337.58 examples/s]Tokenizing train dataset:  23%|██▎       | 1930/8564 [00:06<00:19, 338.66 examples/s]Tokenizing train dataset:  23%|██▎       | 1930/8564 [00:06<00:19, 338.97 examples/s]Tokenizing train dataset:  23%|██▎       | 1966/8564 [00:06<00:19, 339.62 examples/s]Tokenizing train dataset:  23%|██▎       | 1966/8564 [00:06<00:19, 340.74 examples/s]Tokenizing train dataset:  23%|██▎       | 1966/8564 [00:06<00:19, 341.31 examples/s]Tokenizing train dataset:  23%|██▎       | 2003/8564 [00:06<00:19, 343.94 examples/s]Tokenizing train dataset:  23%|██▎       | 2003/8564 [00:06<00:19, 345.06 examples/s]Tokenizing train dataset:  23%|██▎       | 2003/8564 [00:06<00:19, 345.25 examples/s]Tokenizing train dataset:  24%|██▍       | 2043/8564 [00:06<00:18, 356.26 examples/s]Tokenizing train dataset:  24%|██▍       | 2043/8564 [00:06<00:18, 357.52 examples/s]Tokenizing train dataset:  24%|██▍       | 2043/8564 [00:06<00:18, 357.62 examples/s]Tokenizing train dataset:  24%|██▍       | 2080/8564 [00:06<00:18, 357.67 examples/s]Tokenizing train dataset:  24%|██▍       | 2080/8564 [00:06<00:18, 358.16 examples/s]Tokenizing train dataset:  24%|██▍       | 2080/8564 [00:06<00:18, 358.71 examples/s]Tokenizing train dataset:  25%|██▍       | 2119/8564 [00:06<00:17, 363.85 examples/s]Tokenizing train dataset:  25%|██▍       | 2119/8564 [00:06<00:17, 364.84 examples/s]Tokenizing train dataset:  25%|██▍       | 2120/8564 [00:06<00:17, 363.69 examples/s]Tokenizing train dataset:  25%|██▌       | 2156/8564 [00:06<00:17, 363.44 examples/s]Tokenizing train dataset:  25%|██▌       | 2156/8564 [00:06<00:17, 364.38 examples/s]Tokenizing train dataset:  25%|██▌       | 2157/8564 [00:06<00:17, 364.26 examples/s]Tokenizing train dataset:  26%|██▌       | 2193/8564 [00:06<00:17, 361.31 examples/s]Tokenizing train dataset:  26%|██▌       | 2193/8564 [00:06<00:17, 362.62 examples/s]Tokenizing train dataset:  26%|██▌       | 2194/8564 [00:06<00:17, 364.03 examples/s]Tokenizing train dataset:  26%|██▌       | 2230/8564 [00:07<00:17, 361.01 examples/s]Tokenizing train dataset:  26%|██▌       | 2230/8564 [00:07<00:17, 362.29 examples/s]Tokenizing train dataset:  26%|██▌       | 2232/8564 [00:07<00:17, 364.93 examples/s]Tokenizing train dataset:  27%|██▋       | 2270/8564 [00:07<00:17, 369.46 examples/s]Tokenizing train dataset:  27%|██▋       | 2270/8564 [00:07<00:16, 370.56 examples/s]Tokenizing train dataset:  27%|██▋       | 2272/8564 [00:07<00:16, 372.66 examples/s]Tokenizing train dataset:  27%|██▋       | 2309/8564 [00:07<00:16, 369.03 examples/s]Tokenizing train dataset:  27%|██▋       | 2309/8564 [00:07<00:16, 370.41 examples/s]Tokenizing train dataset:  27%|██▋       | 2328/8564 [00:07<00:16, 368.92 examples/s]Tokenizing train dataset:  28%|██▊       | 2359/8564 [00:07<00:17, 351.23 examples/s]Tokenizing train dataset:  28%|██▊       | 2359/8564 [00:07<00:17, 352.02 examples/s]Tokenizing train dataset:  28%|██▊       | 2403/8564 [00:07<00:16, 371.70 examples/s]Tokenizing train dataset:  28%|██▊       | 2403/8564 [00:07<00:16, 372.47 examples/s]Tokenizing train dataset:  28%|██▊       | 2380/8564 [00:07<00:17, 357.31 examples/s]Tokenizing train dataset:  28%|██▊       | 2421/8564 [00:07<00:16, 368.42 examples/s]Tokenizing train dataset:  29%|██▊       | 2461/8564 [00:07<00:16, 375.06 examples/s]Tokenizing train dataset:  29%|██▊       | 2461/8564 [00:07<00:16, 375.22 examples/s]Tokenizing train dataset:  29%|██▊       | 2461/8564 [00:07<00:16, 375.89 examples/s]Tokenizing train dataset:  29%|██▉       | 2511/8564 [00:07<00:16, 356.43 examples/s]Tokenizing train dataset:  29%|██▉       | 2511/8564 [00:07<00:16, 356.78 examples/s]Tokenizing train dataset:  29%|██▉       | 2511/8564 [00:07<00:16, 356.46 examples/s]Tokenizing train dataset:  30%|██▉       | 2555/8564 [00:07<00:16, 372.17 examples/s]Tokenizing train dataset:  30%|██▉       | 2555/8564 [00:07<00:16, 372.68 examples/s]Tokenizing train dataset:  30%|██▉       | 2555/8564 [00:07<00:16, 372.62 examples/s]Tokenizing train dataset:  30%|███       | 2593/8564 [00:08<00:16, 370.88 examples/s]Tokenizing train dataset:  30%|███       | 2594/8564 [00:07<00:15, 373.22 examples/s]Tokenizing train dataset:  30%|███       | 2593/8564 [00:07<00:16, 371.38 examples/s]Tokenizing train dataset:  31%|███       | 2642/8564 [00:08<00:16, 349.24 examples/s]Tokenizing train dataset:  31%|███       | 2642/8564 [00:08<00:16, 349.60 examples/s]Tokenizing train dataset:  31%|███       | 2642/8564 [00:08<00:16, 349.32 examples/s]Tokenizing train dataset:  31%|███▏      | 2693/8564 [00:08<00:17, 339.63 examples/s]Tokenizing train dataset:  31%|███▏      | 2693/8564 [00:08<00:17, 340.28 examples/s]Tokenizing train dataset:  31%|███▏      | 2693/8564 [00:08<00:17, 339.55 examples/s]Tokenizing train dataset:  32%|███▏      | 2731/8564 [00:08<00:16, 346.87 examples/s]Tokenizing train dataset:  32%|███▏      | 2731/8564 [00:08<00:16, 347.63 examples/s]Tokenizing train dataset:  32%|███▏      | 2731/8564 [00:08<00:16, 347.24 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:08<00:16, 346.69 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:08<00:16, 347.12 examples/s]Tokenizing train dataset:  33%|███▎      | 2785/8564 [00:08<00:16, 347.27 examples/s]Tokenizing train dataset:  33%|███▎      | 2825/8564 [00:08<00:16, 358.22 examples/s]Tokenizing train dataset:  33%|███▎      | 2825/8564 [00:08<00:16, 358.63 examples/s]Tokenizing train dataset:  33%|███▎      | 2825/8564 [00:08<00:15, 358.77 examples/s]Tokenizing train dataset:  34%|███▎      | 2873/8564 [00:08<00:16, 341.98 examples/s]Tokenizing train dataset:  34%|███▎      | 2874/8564 [00:08<00:16, 344.27 examples/s]Tokenizing train dataset:  34%|███▎      | 2873/8564 [00:08<00:16, 342.58 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:08<00:15, 367.95 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:08<00:15, 367.73 examples/s]Tokenizing train dataset:  34%|███▍      | 2921/8564 [00:08<00:15, 368.63 examples/s]Tokenizing train dataset:  35%|███▍      | 2961/8564 [00:09<00:14, 374.14 examples/s]Tokenizing train dataset:  35%|███▍      | 2961/8564 [00:09<00:14, 374.39 examples/s]Tokenizing train dataset:  35%|███▍      | 2961/8564 [00:09<00:14, 375.07 examples/s]Tokenizing train dataset:  35%|███▌      | 3005/8564 [00:09<00:14, 390.04 examples/s]Tokenizing train dataset:  35%|███▌      | 3005/8564 [00:09<00:14, 390.27 examples/s]Tokenizing train dataset:  35%|███▌      | 3005/8564 [00:09<00:14, 390.78 examples/s]Tokenizing train dataset:  36%|███▌      | 3057/8564 [00:09<00:14, 368.00 examples/s]Tokenizing train dataset:  36%|███▌      | 3057/8564 [00:09<00:14, 368.65 examples/s]Tokenizing train dataset:  36%|███▌      | 3057/8564 [00:09<00:14, 368.73 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:09<00:14, 372.42 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:09<00:14, 373.35 examples/s]Tokenizing train dataset:  36%|███▌      | 3097/8564 [00:09<00:14, 373.17 examples/s]Tokenizing train dataset:  37%|███▋      | 3151/8564 [00:09<00:14, 364.77 examples/s]Tokenizing train dataset:  37%|███▋      | 3151/8564 [00:09<00:14, 366.15 examples/s]Tokenizing train dataset:  37%|███▋      | 3151/8564 [00:09<00:14, 365.75 examples/s]Tokenizing train dataset:  37%|███▋      | 3189/8564 [00:09<00:14, 361.41 examples/s]Tokenizing train dataset:  37%|███▋      | 3189/8564 [00:09<00:14, 362.94 examples/s]Tokenizing train dataset:  37%|███▋      | 3189/8564 [00:09<00:14, 362.37 examples/s]Tokenizing train dataset:  38%|███▊      | 3227/8564 [00:09<00:14, 367.12 examples/s]Tokenizing train dataset:  38%|███▊      | 3227/8564 [00:09<00:14, 365.66 examples/s]Tokenizing train dataset:  38%|███▊      | 3227/8564 [00:09<00:14, 366.69 examples/s]Tokenizing train dataset:  38%|███▊      | 3269/8564 [00:09<00:14, 374.76 examples/s]Tokenizing train dataset:  38%|███▊      | 3269/8564 [00:09<00:14, 373.26 examples/s]Tokenizing train dataset:  38%|███▊      | 3269/8564 [00:09<00:14, 374.39 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:10<00:14, 358.36 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:10<00:14, 357.34 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:10<00:14, 358.38 examples/s]Tokenizing train dataset:  39%|███▉      | 3357/8564 [00:10<00:14, 359.00 examples/s]Tokenizing train dataset:  39%|███▉      | 3357/8564 [00:10<00:14, 358.10 examples/s]Tokenizing train dataset:  39%|███▉      | 3357/8564 [00:10<00:14, 358.85 examples/s]Tokenizing train dataset:  40%|███▉      | 3397/8564 [00:10<00:14, 368.10 examples/s]Tokenizing train dataset:  40%|███▉      | 3397/8564 [00:10<00:14, 366.84 examples/s]Tokenizing train dataset:  40%|███▉      | 3397/8564 [00:10<00:14, 367.72 examples/s]Tokenizing train dataset:  40%|████      | 3437/8564 [00:10<00:13, 375.99 examples/s]Tokenizing train dataset:  40%|████      | 3437/8564 [00:10<00:13, 375.01 examples/s]Tokenizing train dataset:  40%|████      | 3437/8564 [00:10<00:13, 375.58 examples/s]Tokenizing train dataset:  41%|████      | 3491/8564 [00:10<00:13, 365.51 examples/s]Tokenizing train dataset:  41%|████      | 3491/8564 [00:10<00:13, 364.72 examples/s]Tokenizing train dataset:  41%|████      | 3491/8564 [00:10<00:13, 365.33 examples/s]Tokenizing train dataset:  41%|████▏     | 3533/8564 [00:10<00:13, 377.14 examples/s]Tokenizing train dataset:  41%|████▏     | 3533/8564 [00:10<00:13, 376.25 examples/s]Tokenizing train dataset:  41%|████▏     | 3533/8564 [00:10<00:13, 376.88 examples/s]Tokenizing train dataset:  42%|████▏     | 3592/8564 [00:10<00:13, 373.02 examples/s]Tokenizing train dataset:  42%|████▏     | 3592/8564 [00:10<00:13, 372.41 examples/s]Tokenizing train dataset:  42%|████▏     | 3592/8564 [00:10<00:13, 372.62 examples/s]Tokenizing train dataset:  42%|████▏     | 3631/8564 [00:10<00:13, 374.02 examples/s]Tokenizing train dataset:  42%|████▏     | 3631/8564 [00:10<00:13, 373.11 examples/s]Tokenizing train dataset:  42%|████▏     | 3631/8564 [00:10<00:13, 373.33 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:10<00:13, 352.02 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:11<00:13, 351.23 examples/s]Tokenizing train dataset:  43%|████▎     | 3680/8564 [00:10<00:13, 351.45 examples/s]Tokenizing train dataset:  43%|████▎     | 3724/8564 [00:11<00:13, 370.15 examples/s]Tokenizing train dataset:  43%|████▎     | 3724/8564 [00:11<00:13, 369.26 examples/s]Tokenizing train dataset:  43%|████▎     | 3724/8564 [00:11<00:13, 369.52 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:11<00:12, 368.90 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:11<00:13, 367.68 examples/s]Tokenizing train dataset:  44%|████▍     | 3780/8564 [00:11<00:12, 368.43 examples/s]Tokenizing train dataset:  45%|████▍     | 3834/8564 [00:11<00:13, 362.67 examples/s]Tokenizing train dataset:  45%|████▍     | 3834/8564 [00:11<00:13, 361.79 examples/s]Tokenizing train dataset:  45%|████▍     | 3834/8564 [00:11<00:13, 362.88 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:11<00:12, 361.03 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:11<00:12, 360.15 examples/s]Tokenizing train dataset:  45%|████▌     | 3890/8564 [00:11<00:12, 361.49 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:11<00:13, 350.74 examples/s]Tokenizing train dataset:  46%|████▌     | 3940/8564 [00:11<00:13, 350.33 examples/s]Tokenizing train dataset:  46%|████▌     | 3941/8564 [00:11<00:13, 351.46 examples/s]Tokenizing train dataset:  46%|████▋     | 3978/8564 [00:11<00:13, 352.47 examples/s]Tokenizing train dataset:  46%|████▋     | 3978/8564 [00:11<00:13, 351.84 examples/s]Tokenizing train dataset:  46%|████▋     | 3978/8564 [00:11<00:12, 353.02 examples/s]Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:11<00:12, 354.93 examples/s]Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:11<00:12, 354.06 examples/s]Tokenizing train dataset:  47%|████▋     | 4015/8564 [00:11<00:12, 355.15 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:12<00:12, 363.55 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:12<00:12, 362.65 examples/s]Tokenizing train dataset:  47%|████▋     | 4056/8564 [00:12<00:12, 363.33 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:12<00:12, 358.17 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:12<00:12, 357.28 examples/s]Tokenizing train dataset:  48%|████▊     | 4110/8564 [00:12<00:12, 357.84 examples/s]Tokenizing train dataset:  49%|████▊     | 4162/8564 [00:12<00:12, 351.34 examples/s]Tokenizing train dataset:  49%|████▊     | 4162/8564 [00:12<00:12, 350.30 examples/s]Tokenizing train dataset:  49%|████▊     | 4162/8564 [00:12<00:12, 351.04 examples/s]Tokenizing train dataset:  49%|████▉     | 4203/8564 [00:12<00:12, 361.58 examples/s]Tokenizing train dataset:  49%|████▉     | 4203/8564 [00:12<00:12, 360.76 examples/s]Tokenizing train dataset:  49%|████▉     | 4203/8564 [00:12<00:12, 361.03 examples/s]Tokenizing train dataset:  50%|████▉     | 4257/8564 [00:12<00:12, 357.06 examples/s]Tokenizing train dataset:  50%|████▉     | 4257/8564 [00:12<00:12, 355.67 examples/s]Tokenizing train dataset:  50%|████▉     | 4257/8564 [00:12<00:12, 356.17 examples/s]Tokenizing train dataset:  50%|█████     | 4293/8564 [00:12<00:12, 354.65 examples/s]Tokenizing train dataset:  50%|█████     | 4313/8564 [00:12<00:11, 358.81 examples/s]Tokenizing train dataset:  50%|█████     | 4293/8564 [00:12<00:12, 354.77 examples/s]Tokenizing train dataset:  51%|█████     | 4330/8564 [00:12<00:11, 354.92 examples/s]Tokenizing train dataset:  51%|█████     | 4330/8564 [00:12<00:11, 355.71 examples/s]Tokenizing train dataset:  51%|█████     | 4365/8564 [00:12<00:11, 353.18 examples/s]Tokenizing train dataset:  51%|█████     | 4386/8564 [00:13<00:11, 358.19 examples/s]Tokenizing train dataset:  51%|█████▏    | 4405/8564 [00:13<00:11, 360.34 examples/s]Tokenizing train dataset:  51%|█████     | 4386/8564 [00:12<00:11, 358.78 examples/s]Tokenizing train dataset:  52%|█████▏    | 4425/8564 [00:13<00:11, 360.84 examples/s]Tokenizing train dataset:  52%|█████▏    | 4444/8564 [00:13<00:11, 363.68 examples/s]Tokenizing train dataset:  52%|█████▏    | 4425/8564 [00:13<00:11, 361.32 examples/s]Tokenizing train dataset:  52%|█████▏    | 4482/8564 [00:13<00:11, 362.87 examples/s]Tokenizing train dataset:  52%|█████▏    | 4482/8564 [00:13<00:11, 361.04 examples/s]Tokenizing train dataset:  52%|█████▏    | 4482/8564 [00:13<00:11, 361.52 examples/s]Tokenizing train dataset:  53%|█████▎    | 4536/8564 [00:13<00:11, 357.06 examples/s]Tokenizing train dataset:  53%|█████▎    | 4536/8564 [00:13<00:11, 356.14 examples/s]Tokenizing train dataset:  53%|█████▎    | 4536/8564 [00:13<00:11, 356.81 examples/s]Tokenizing train dataset:  53%|█████▎    | 4572/8564 [00:13<00:11, 354.60 examples/s]Tokenizing train dataset:  53%|█████▎    | 4572/8564 [00:13<00:11, 353.81 examples/s]Tokenizing train dataset:  53%|█████▎    | 4572/8564 [00:13<00:11, 354.60 examples/s]Tokenizing train dataset:  54%|█████▍    | 4609/8564 [00:13<00:11, 354.75 examples/s]Tokenizing train dataset:  54%|█████▍    | 4609/8564 [00:13<00:11, 354.07 examples/s]Tokenizing train dataset:  54%|█████▍    | 4609/8564 [00:13<00:11, 354.80 examples/s]Tokenizing train dataset:  54%|█████▍    | 4660/8564 [00:13<00:11, 342.08 examples/s]Tokenizing train dataset:  54%|█████▍    | 4658/8564 [00:13<00:11, 341.59 examples/s]Tokenizing train dataset:  54%|█████▍    | 4660/8564 [00:13<00:11, 342.57 examples/s]Tokenizing train dataset:  55%|█████▍    | 4708/8564 [00:13<00:11, 329.81 examples/s]Tokenizing train dataset:  55%|█████▍    | 4705/8564 [00:13<00:11, 328.62 examples/s]Tokenizing train dataset:  55%|█████▍    | 4708/8564 [00:13<00:11, 330.38 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:13<00:11, 329.46 examples/s]Tokenizing train dataset:  55%|█████▌    | 4740/8564 [00:14<00:11, 328.78 examples/s]Tokenizing train dataset:  55%|█████▌    | 4742/8564 [00:13<00:11, 330.02 examples/s]Tokenizing train dataset:  56%|█████▌    | 4792/8564 [00:14<00:11, 323.76 examples/s]Tokenizing train dataset:  56%|█████▌    | 4788/8564 [00:14<00:11, 322.59 examples/s]Tokenizing train dataset:  56%|█████▌    | 4792/8564 [00:14<00:11, 324.32 examples/s]Tokenizing train dataset:  57%|█████▋    | 4852/8564 [00:14<00:09, 387.74 examples/s]Tokenizing train dataset:  57%|█████▋    | 4847/8564 [00:14<00:09, 385.44 examples/s]Tokenizing train dataset:  57%|█████▋    | 4853/8564 [00:14<00:09, 389.54 examples/s]Tokenizing train dataset:  57%|█████▋    | 4903/8564 [00:14<00:08, 428.11 examples/s]Tokenizing train dataset:  57%|█████▋    | 4911/8564 [00:14<00:08, 436.16 examples/s]Tokenizing train dataset:  57%|█████▋    | 4912/8564 [00:14<00:08, 432.66 examples/s]Tokenizing train dataset:  58%|█████▊    | 4965/8564 [00:14<00:07, 474.94 examples/s]Tokenizing train dataset:  58%|█████▊    | 4970/8564 [00:14<00:07, 473.23 examples/s]Tokenizing train dataset:  58%|█████▊    | 4974/8564 [00:14<00:07, 479.96 examples/s]Tokenizing train dataset:  59%|█████▊    | 5025/8564 [00:14<00:06, 506.36 examples/s]Tokenizing train dataset:  59%|█████▉    | 5033/8564 [00:14<00:06, 506.31 examples/s]Tokenizing train dataset:  59%|█████▉    | 5033/8564 [00:14<00:06, 505.46 examples/s]Tokenizing train dataset:  59%|█████▉    | 5091/8564 [00:14<00:06, 547.39 examples/s]Tokenizing train dataset:  60%|█████▉    | 5106/8564 [00:14<00:06, 561.44 examples/s]Tokenizing train dataset:  60%|█████▉    | 5106/8564 [00:14<00:06, 560.89 examples/s]Tokenizing train dataset:  60%|██████    | 5162/8564 [00:14<00:05, 589.85 examples/s]Tokenizing train dataset:  60%|██████    | 5177/8564 [00:14<00:05, 597.11 examples/s]Tokenizing train dataset:  60%|██████    | 5177/8564 [00:14<00:05, 596.99 examples/s]Tokenizing train dataset:  61%|██████    | 5230/8564 [00:14<00:05, 612.89 examples/s]Tokenizing train dataset:  61%|██████▏   | 5247/8564 [00:14<00:05, 625.03 examples/s]Tokenizing train dataset:  61%|██████▏   | 5247/8564 [00:14<00:05, 625.42 examples/s]Tokenizing train dataset:  62%|██████▏   | 5305/8564 [00:15<00:05, 651.61 examples/s]Tokenizing train dataset:  62%|██████▏   | 5319/8564 [00:14<00:05, 648.49 examples/s]Tokenizing train dataset:  62%|██████▏   | 5319/8564 [00:14<00:04, 649.27 examples/s]Tokenizing train dataset:  63%|██████▎   | 5391/8564 [00:15<00:05, 617.15 examples/s]Tokenizing train dataset:  63%|██████▎   | 5401/8564 [00:15<00:05, 606.40 examples/s]Tokenizing train dataset:  63%|██████▎   | 5402/8564 [00:15<00:05, 604.26 examples/s]Tokenizing train dataset:  64%|██████▎   | 5455/8564 [00:15<00:04, 622.24 examples/s]Tokenizing train dataset:  64%|██████▍   | 5467/8564 [00:15<00:05, 616.62 examples/s]Tokenizing train dataset:  64%|██████▍   | 5470/8564 [00:15<00:05, 617.49 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:15<00:04, 607.28 examples/s]Tokenizing train dataset:  65%|██████▍   | 5555/8564 [00:15<00:04, 604.04 examples/s]Tokenizing train dataset:  65%|██████▍   | 5533/8564 [00:15<00:04, 614.57 examples/s]Tokenizing train dataset:  66%|██████▌   | 5610/8564 [00:15<00:04, 612.95 examples/s]Tokenizing train dataset:  66%|██████▌   | 5623/8564 [00:15<00:04, 622.00 examples/s]Tokenizing train dataset:  65%|██████▌   | 5596/8564 [00:15<00:04, 610.60 examples/s]Tokenizing train dataset:  66%|██████▋   | 5677/8564 [00:15<00:04, 622.83 examples/s]Tokenizing train dataset:  66%|██████▋   | 5690/8564 [00:15<00:04, 628.83 examples/s]Tokenizing train dataset:  66%|██████▌   | 5666/8564 [00:15<00:04, 629.52 examples/s]Tokenizing train dataset:  67%|██████▋   | 5743/8564 [00:15<00:04, 626.10 examples/s]Tokenizing train dataset:  67%|██████▋   | 5756/8564 [00:15<00:04, 636.11 examples/s]Tokenizing train dataset:  67%|██████▋   | 5730/8564 [00:15<00:04, 624.07 examples/s]Tokenizing train dataset:  68%|██████▊   | 5822/8564 [00:15<00:04, 669.39 examples/s]Tokenizing train dataset:  68%|██████▊   | 5830/8564 [00:15<00:04, 662.33 examples/s]Tokenizing train dataset:  68%|██████▊   | 5802/8564 [00:15<00:04, 650.00 examples/s]Tokenizing train dataset:  69%|██████▉   | 5903/8564 [00:16<00:04, 616.02 examples/s]Tokenizing train dataset:  69%|██████▉   | 5916/8564 [00:15<00:04, 627.90 examples/s]Tokenizing train dataset:  69%|██████▉   | 5889/8564 [00:15<00:04, 616.74 examples/s]Tokenizing train dataset:  70%|██████▉   | 5971/8564 [00:16<00:04, 630.65 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [00:16<00:04, 592.25 examples/s]Tokenizing train dataset:  70%|██████▉   | 5954/8564 [00:16<00:04, 622.67 examples/s]Tokenizing train dataset:  71%|███████   | 6043/8564 [00:16<00:04, 600.69 examples/s]Tokenizing train dataset:  71%|███████   | 6052/8564 [00:16<00:04, 591.94 examples/s]Tokenizing train dataset:  71%|███████   | 6043/8564 [00:16<00:04, 588.56 examples/s]Tokenizing train dataset:  72%|███████▏  | 6133/8564 [00:16<00:04, 599.03 examples/s]Tokenizing train dataset:  72%|███████▏  | 6150/8564 [00:16<00:04, 601.04 examples/s]Tokenizing train dataset:  72%|███████▏  | 6133/8564 [00:16<00:04, 590.93 examples/s]Tokenizing train dataset:  73%|███████▎  | 6209/8564 [00:16<00:03, 638.27 examples/s]Tokenizing train dataset:  73%|███████▎  | 6224/8564 [00:16<00:03, 631.25 examples/s]Tokenizing train dataset:  73%|███████▎  | 6209/8564 [00:16<00:03, 630.31 examples/s]Tokenizing train dataset:  73%|███████▎  | 6278/8564 [00:16<00:03, 650.59 examples/s]Tokenizing train dataset:  73%|███████▎  | 6291/8564 [00:16<00:03, 634.50 examples/s]Tokenizing train dataset:  73%|███████▎  | 6279/8564 [00:16<00:03, 645.31 examples/s]Tokenizing train dataset:  74%|███████▍  | 6360/8564 [00:16<00:03, 647.20 examples/s]Tokenizing train dataset:  74%|███████▍  | 6379/8564 [00:16<00:03, 656.22 examples/s]Tokenizing train dataset:  74%|███████▍  | 6379/8564 [00:16<00:03, 651.56 examples/s]Tokenizing train dataset:  75%|███████▌  | 6457/8564 [00:16<00:03, 637.65 examples/s]Tokenizing train dataset:  76%|███████▌  | 6470/8564 [00:16<00:03, 632.44 examples/s]Tokenizing train dataset:  76%|███████▌  | 6470/8564 [00:16<00:03, 629.85 examples/s]Tokenizing train dataset:  76%|███████▋  | 6535/8564 [00:16<00:03, 627.80 examples/s]Tokenizing train dataset:  76%|███████▋  | 6548/8564 [00:17<00:03, 621.51 examples/s]Tokenizing train dataset:  76%|███████▋  | 6535/8564 [00:16<00:03, 625.62 examples/s]Tokenizing train dataset:  77%|███████▋  | 6613/8564 [00:17<00:03, 580.35 examples/s]Tokenizing train dataset:  77%|███████▋  | 6628/8564 [00:17<00:03, 585.89 examples/s]Tokenizing train dataset:  77%|███████▋  | 6613/8564 [00:17<00:03, 579.29 examples/s]Tokenizing train dataset:  78%|███████▊  | 6679/8564 [00:17<00:03, 598.77 examples/s]Tokenizing train dataset:  78%|███████▊  | 6695/8564 [00:17<00:03, 601.51 examples/s]Tokenizing train dataset:  78%|███████▊  | 6679/8564 [00:17<00:03, 597.40 examples/s]Tokenizing train dataset:  79%|███████▉  | 6749/8564 [00:17<00:02, 620.36 examples/s]Tokenizing train dataset:  79%|███████▉  | 6761/8564 [00:17<00:02, 613.41 examples/s]Tokenizing train dataset:  79%|███████▉  | 6749/8564 [00:17<00:02, 619.29 examples/s]Tokenizing train dataset:  80%|███████▉  | 6835/8564 [00:17<00:02, 602.01 examples/s]Tokenizing train dataset:  80%|███████▉  | 6847/8564 [00:17<00:02, 593.81 examples/s]Tokenizing train dataset:  80%|███████▉  | 6835/8564 [00:17<00:02, 601.03 examples/s]Tokenizing train dataset:  81%|████████  | 6900/8564 [00:17<00:02, 609.96 examples/s]Tokenizing train dataset:  81%|████████  | 6916/8564 [00:17<00:02, 614.04 examples/s]Tokenizing train dataset:  81%|████████  | 6900/8564 [00:17<00:02, 609.42 examples/s]Tokenizing train dataset:  81%|████████▏ | 6965/8564 [00:17<00:02, 613.80 examples/s]Tokenizing train dataset:  82%|████████▏ | 6982/8564 [00:17<00:02, 614.46 examples/s]Tokenizing train dataset:  81%|████████▏ | 6965/8564 [00:17<00:02, 613.60 examples/s]Tokenizing train dataset:  82%|████████▏ | 7057/8564 [00:17<00:02, 603.17 examples/s]Tokenizing train dataset:  83%|████████▎ | 7069/8564 [00:17<00:02, 599.32 examples/s]Tokenizing train dataset:  82%|████████▏ | 7058/8564 [00:17<00:02, 605.26 examples/s]Tokenizing train dataset:  83%|████████▎ | 7124/8564 [00:17<00:02, 614.74 examples/s]Tokenizing train dataset:  83%|████████▎ | 7136/8564 [00:18<00:02, 614.86 examples/s]Tokenizing train dataset:  83%|████████▎ | 7124/8564 [00:17<00:02, 614.94 examples/s]Tokenizing train dataset:  84%|████████▍ | 7192/8564 [00:18<00:02, 630.11 examples/s]Tokenizing train dataset:  84%|████████▍ | 7205/8564 [00:18<00:02, 632.64 examples/s]Tokenizing train dataset:  84%|████████▍ | 7193/8564 [00:18<00:02, 632.41 examples/s]Tokenizing train dataset:  85%|████████▌ | 7282/8564 [00:18<00:02, 613.68 examples/s]Tokenizing train dataset:  85%|████████▌ | 7292/8564 [00:18<00:02, 605.93 examples/s]Tokenizing train dataset:  85%|████████▌ | 7282/8564 [00:18<00:02, 614.62 examples/s]Tokenizing train dataset:  86%|████████▌ | 7360/8564 [00:18<00:01, 618.15 examples/s]Tokenizing train dataset:  86%|████████▌ | 7378/8564 [00:18<00:01, 617.94 examples/s]Tokenizing train dataset:  86%|████████▌ | 7379/8564 [00:18<00:01, 620.64 examples/s]Tokenizing train dataset:  87%|████████▋ | 7443/8564 [00:18<00:01, 621.65 examples/s]Tokenizing train dataset:  87%|████████▋ | 7457/8564 [00:18<00:01, 625.78 examples/s]Tokenizing train dataset:  87%|████████▋ | 7443/8564 [00:18<00:01, 622.63 examples/s]Tokenizing train dataset:  88%|████████▊ | 7506/8564 [00:18<00:01, 618.82 examples/s]Tokenizing train dataset:  88%|████████▊ | 7506/8564 [00:18<00:01, 620.04 examples/s]Tokenizing train dataset:  88%|████████▊ | 7553/8564 [00:18<00:01, 628.65 examples/s]Tokenizing train dataset:  89%|████████▊ | 7581/8564 [00:18<00:01, 648.67 examples/s]Tokenizing train dataset:  89%|████████▊ | 7581/8564 [00:18<00:01, 650.89 examples/s]Tokenizing train dataset:  89%|████████▉ | 7626/8564 [00:18<00:01, 650.59 examples/s]Tokenizing train dataset:  90%|████████▉ | 7665/8564 [00:18<00:01, 613.34 examples/s]Tokenizing train dataset:  90%|████████▉ | 7665/8564 [00:18<00:01, 615.49 examples/s]Tokenizing train dataset:  90%|█████████ | 7708/8564 [00:18<00:01, 612.13 examples/s]Tokenizing train dataset:  90%|█████████ | 7728/8564 [00:18<00:01, 615.76 examples/s]Tokenizing train dataset:  91%|█████████ | 7754/8564 [00:18<00:01, 607.38 examples/s]Tokenizing train dataset:  91%|█████████ | 7791/8564 [00:19<00:01, 589.53 examples/s]Tokenizing train dataset:  91%|█████████ | 7809/8564 [00:19<00:01, 583.21 examples/s]Tokenizing train dataset:  92%|█████████▏| 7854/8564 [00:19<00:01, 594.44 examples/s]Tokenizing train dataset:  92%|█████████▏| 7871/8564 [00:19<00:01, 590.69 examples/s]Tokenizing train dataset:  92%|█████████▏| 7841/8564 [00:19<00:01, 593.55 examples/s]Tokenizing train dataset:  92%|█████████▏| 7916/8564 [00:19<00:01, 596.36 examples/s]Tokenizing train dataset:  93%|█████████▎| 7936/8564 [00:19<00:01, 601.77 examples/s]Tokenizing train dataset:  92%|█████████▏| 7905/8564 [00:19<00:01, 599.87 examples/s]Tokenizing train dataset:  93%|█████████▎| 7978/8564 [00:19<00:00, 600.78 examples/s]Tokenizing train dataset:  93%|█████████▎| 8002/8564 [00:19<00:00, 615.56 examples/s]Tokenizing train dataset:  93%|█████████▎| 7966/8564 [00:19<00:00, 601.49 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [00:19<00:00, 612.33 examples/s]Tokenizing train dataset:  94%|█████████▍| 8032/8564 [00:19<00:00, 608.26 examples/s]Tokenizing train dataset:  94%|█████████▍| 8091/8564 [00:19<00:00, 597.04 examples/s]Tokenizing train dataset:  95%|█████████▍| 8128/8564 [00:19<00:00, 584.24 examples/s]Tokenizing train dataset:  95%|█████████▍| 8120/8564 [00:19<00:00, 592.07 examples/s]Tokenizing train dataset:  96%|█████████▌| 8181/8564 [00:19<00:00, 594.61 examples/s]Tokenizing train dataset:  96%|█████████▌| 8198/8564 [00:19<00:00, 608.99 examples/s]Tokenizing train dataset:  96%|█████████▌| 8184/8564 [00:19<00:00, 600.29 examples/s]Tokenizing train dataset:  96%|█████████▋| 8245/8564 [00:19<00:00, 605.28 examples/s]Tokenizing train dataset:  96%|█████████▋| 8263/8564 [00:19<00:00, 615.51 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [00:19<00:00, 609.97 examples/s]Tokenizing train dataset:  97%|█████████▋| 8324/8564 [00:19<00:00, 650.96 examples/s]Tokenizing train dataset:  97%|█████████▋| 8332/8564 [00:19<00:00, 633.50 examples/s]Tokenizing train dataset:  97%|█████████▋| 8328/8564 [00:19<00:00, 647.98 examples/s]Tokenizing train dataset:  98%|█████████▊| 8404/8564 [00:20<00:00, 604.93 examples/s]Tokenizing train dataset:  98%|█████████▊| 8420/8564 [00:20<00:00, 611.30 examples/s]Tokenizing train dataset:  98%|█████████▊| 8413/8564 [00:20<00:00, 610.22 examples/s]Tokenizing train dataset:  99%|█████████▉| 8497/8564 [00:20<00:00, 608.48 examples/s]Tokenizing train dataset:  99%|█████████▉| 8477/8564 [00:20<00:00, 616.25 examples/s]Tokenizing train dataset:  99%|█████████▉| 8511/8564 [00:20<00:00, 609.09 examples/s]Tokenizing train dataset: 100%|█████████▉| 8560/8564 [00:20<00:00, 607.61 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 422.37 examples/s]
Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 420.79 examples/s]
Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 609.63 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:20<00:00, 422.26 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11344.55 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 11080.20 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 10918.28 examples/s]
Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13705.47 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13557.92 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13192.99 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 326.97 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 326.01 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 296.64 examples/s]Tokenizing eval dataset:   8%|▊         | 79/953 [00:00<00:02, 295.35 examples/s]Tokenizing eval dataset:   3%|▎         | 24/953 [00:00<00:03, 233.83 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:02, 278.39 examples/s]Tokenizing eval dataset:  13%|█▎        | 120/953 [00:00<00:03, 276.82 examples/s]Tokenizing eval dataset:   6%|▌         | 57/953 [00:00<00:04, 215.99 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:03, 218.68 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 269.01 examples/s]Tokenizing eval dataset:  17%|█▋        | 160/953 [00:00<00:02, 267.71 examples/s]Tokenizing eval dataset:  12%|█▏        | 112/953 [00:00<00:03, 210.38 examples/s]Tokenizing eval dataset:  21%|██        | 198/953 [00:00<00:02, 260.24 examples/s]Tokenizing eval dataset:  21%|██        | 198/953 [00:00<00:02, 259.05 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:00<00:02, 292.50 examples/s]Tokenizing eval dataset:  25%|██▍       | 238/953 [00:00<00:02, 291.39 examples/s]Tokenizing eval dataset:  15%|█▍        | 140/953 [00:00<00:04, 198.20 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:00<00:01, 387.65 examples/s]Tokenizing eval dataset:  32%|███▏      | 304/953 [00:00<00:01, 385.93 examples/s]Tokenizing eval dataset:  39%|███▊      | 368/953 [00:01<00:01, 453.68 examples/s]Tokenizing eval dataset:  18%|█▊        | 170/953 [00:00<00:04, 189.70 examples/s]Tokenizing eval dataset:  39%|███▊      | 368/953 [00:01<00:01, 451.82 examples/s]Tokenizing eval dataset:  46%|████▌     | 437/953 [00:01<00:00, 517.42 examples/s]Tokenizing eval dataset:  46%|████▌     | 437/953 [00:01<00:00, 516.37 examples/s]Tokenizing eval dataset:  21%|██        | 200/953 [00:01<00:03, 192.27 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:01<00:00, 559.62 examples/s]Tokenizing eval dataset:  53%|█████▎    | 504/953 [00:01<00:00, 558.48 examples/s]Tokenizing eval dataset:  24%|██▍       | 233/953 [00:01<00:03, 222.82 examples/s]Tokenizing eval dataset:  60%|█████▉    | 569/953 [00:01<00:00, 582.14 examples/s]Tokenizing eval dataset:  60%|█████▉    | 569/953 [00:01<00:00, 581.08 examples/s]Tokenizing eval dataset:  30%|███       | 290/953 [00:01<00:02, 306.77 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:01<00:00, 607.84 examples/s]Tokenizing eval dataset:  67%|██████▋   | 640/953 [00:01<00:00, 606.67 examples/s]Tokenizing eval dataset:  36%|███▌      | 342/953 [00:01<00:01, 361.54 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:01<00:01, 406.20 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 595.87 examples/s]Tokenizing eval dataset:  77%|███████▋  | 730/953 [00:01<00:00, 594.69 examples/s]Tokenizing eval dataset:  49%|████▉     | 469/953 [00:01<00:00, 490.98 examples/s]Tokenizing eval dataset:  85%|████████▍ | 806/953 [00:01<00:00, 559.54 examples/s]Tokenizing eval dataset:  85%|████████▍ | 807/953 [00:01<00:00, 560.06 examples/s]Tokenizing eval dataset:  56%|█████▌    | 530/953 [00:01<00:00, 520.85 examples/s]Tokenizing eval dataset:  63%|██████▎   | 600/953 [00:01<00:00, 570.45 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:01<00:00, 540.57 examples/s]Tokenizing eval dataset:  93%|█████████▎| 883/953 [00:01<00:00, 539.30 examples/s]Tokenizing eval dataset:  69%|██████▉   | 662/953 [00:01<00:00, 581.40 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 529.91 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 463.74 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 528.37 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 462.31 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset:  78%|███████▊  | 743/953 [00:01<00:00, 565.30 examples/s]Tokenizing eval dataset:  86%|████████▌ | 821/953 [00:02<00:00, 542.19 examples/s]Tokenizing eval dataset:  94%|█████████▍| 895/953 [00:02<00:00, 523.82 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 511.81 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 396.50 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4564263820648193 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3680167198181152 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.356369972229004 seconds
Installed CUDA version 12.1 does not match the version torch was compiled with 12.4 but since the APIs are compatible, accepting this combination
Using /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /ceph/hpc/home/dv70648/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.365260601043701 seconds
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Training complete
Saving model
[rank4]:[W601 17:36:30.791031461 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Script finished on Node Rank: 1 ---
