cpu-bind=MASK - gn11, task  0  0 [372526]: mask 0xffff0000ffff0000ffffffffffffffffffff0000ffff0000ffffffffffffffff set
*******STARTING********
--- Running on Node Rank: 0 ---
Total Nodes: 2
--- CUDA_VISIBLE_DEVICES for this srun task: 0,1,2,3 ---
GPUs per Node: 4
Master Address: gn11
Master Port: 29500
-------------------------------------------
accelerate launch     --config_file /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/accelerate_config.yaml     --num_machines 2     --machine_rank 0     --main_process_ip gn11     --main_process_port 29500     --num_processes 8     --deepspeed_hostfile /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/result_dir/hostfile_62083723     --deepspeed_multinode_launcher standard     --rdzv_backend static     --same_network     --mixed_precision bf16     "train.py"     --rank=64 --learning_rate=3e-7 --total_epochs=3 --beta=0.2
-------------------------------------------
[2025-05-31 01:37:47,893] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
W0531 01:37:49.504000 372575 torch/distributed/run.py:792] 
W0531 01:37:49.504000 372575 torch/distributed/run.py:792] *****************************************
W0531 01:37:49.504000 372575 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0531 01:37:49.504000 372575 torch/distributed/run.py:792] *****************************************
[2025-05-31 01:37:54,608] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 01:37:54,648] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 01:37:54,658] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-05-31 01:37:54,668] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Created datasets
Number of training examples: 8564
Number of validation examples: 953
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
Namespace(rank=64, learning_rate=3e-07, total_epochs=3, beta=0.2)
3e-07
World size: 8
Setting gradient accumulation steps to: 2
[2025-05-31 01:37:57,483] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 01:37:57,529] [INFO] [comm.py:658:init_distributed] cdb=None
Created datasets
Steps per epoch: 4282
Eval steps: 2141
[2025-05-31 01:37:57,537] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-05-31 01:37:57,537] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-05-31 01:37:57,539] [INFO] [comm.py:658:init_distributed] cdb=None
Set up DPO configuration
[2025-05-31 01:37:58,141] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
hpZeRO group size: 4
[2025-05-31 01:37:58,503] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-31 01:37:58,581] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-31 01:37:58,585] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 8
[2025-05-31 01:38:12,876] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 465, num_elems = 10.16B
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:06<00:20,  6.86s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:12<00:12,  6.04s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:13<00:04,  4.63s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:17<00:05,  5.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.48s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.46s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.47s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.46s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.46s/it]
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/ceph/hpc/home/dv70648/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Loaded model
Input gradients enabled: True
Using LoRA and set up the model
Loaded tokenizer
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:00<00:01, 5406.63 examples/s]Extracting prompt in train dataset:  16%|█▌        | 1365/8564 [00:00<00:01, 5396.29 examples/s]Extracting prompt in train dataset:  25%|██▌       | 2170/8564 [00:00<00:01, 5372.50 examples/s]Extracting prompt in train dataset:  35%|███▍      | 2990/8564 [00:00<00:01, 5382.26 examples/s]Extracting prompt in train dataset:  44%|████▎     | 3740/8564 [00:00<00:00, 5218.66 examples/s]Extracting prompt in train dataset:  52%|█████▏    | 4440/8564 [00:00<00:00, 5016.13 examples/s]Extracting prompt in train dataset:  60%|█████▉    | 5125/8564 [00:01<00:00, 4856.65 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 5670/8564 [00:01<00:00, 4991.21 examples/s]Extracting prompt in train dataset:  75%|███████▍  | 6401/8564 [00:01<00:00, 4948.50 examples/s]Extracting prompt in train dataset:  84%|████████▎ | 7160/8564 [00:01<00:00, 4973.63 examples/s]Extracting prompt in train dataset:  92%|█████████▏| 7870/8564 [00:01<00:00, 4888.52 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8396/8564 [00:01<00:00, 4973.68 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 4894.51 examples/s]
Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   3%|▎         | 286/8564 [00:00<00:02, 2826.80 examples/s]Applying chat template to train dataset:   8%|▊         | 720/8564 [00:00<00:02, 2867.67 examples/s]Applying chat template to train dataset:  12%|█▏        | 1014/8564 [00:00<00:02, 2890.79 examples/s]Applying chat template to train dataset:  17%|█▋        | 1455/8564 [00:00<00:02, 2910.35 examples/s]Applying chat template to train dataset:  21%|██        | 1809/8564 [00:00<00:02, 2689.39 examples/s]Applying chat template to train dataset:  25%|██▍       | 2110/8564 [00:00<00:02, 2771.41 examples/s]Applying chat template to train dataset:  30%|██▉       | 2533/8564 [00:00<00:02, 2784.87 examples/s]Applying chat template to train dataset:  33%|███▎      | 2834/8564 [00:01<00:02, 2839.54 examples/s]Applying chat template to train dataset:  38%|███▊      | 3276/8564 [00:01<00:01, 2873.63 examples/s]Applying chat template to train dataset:  42%|████▏     | 3574/8564 [00:01<00:01, 2896.89 examples/s]Applying chat template to train dataset:  45%|████▌     | 3870/8564 [00:01<00:01, 2906.51 examples/s]Applying chat template to train dataset:  50%|████▉     | 4249/8564 [00:01<00:01, 2762.12 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4569/8564 [00:01<00:01, 2374.93 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4863/8564 [00:01<00:01, 2502.93 examples/s]Applying chat template to train dataset:  60%|██████    | 5167/8564 [00:01<00:01, 2635.06 examples/s]Applying chat template to train dataset:  64%|██████▍   | 5504/8564 [00:02<00:01, 2498.14 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5829/8564 [00:02<00:01, 2371.42 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6104/8564 [00:02<00:01, 2459.07 examples/s]Applying chat template to train dataset:  75%|███████▍  | 6402/8564 [00:02<00:00, 2587.98 examples/s]Applying chat template to train dataset:  80%|███████▉  | 6820/8564 [00:02<00:00, 2655.60 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7112/8564 [00:02<00:00, 2720.50 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7447/8564 [00:02<00:00, 2546.86 examples/s]Applying chat template to train dataset:  90%|█████████ | 7721/8564 [00:02<00:00, 2592.31 examples/s]Applying chat template to train dataset:  95%|█████████▌| 8142/8564 [00:03<00:00, 2662.95 examples/s]Applying chat template to train dataset: 100%|█████████▉| 8546/8564 [00:03<00:00, 2672.58 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2572.95 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 43/8564 [00:00<00:21, 403.43 examples/s]Tokenizing train dataset:   1%|          | 88/8564 [00:00<00:26, 323.90 examples/s]Tokenizing train dataset:   2%|▏         | 130/8564 [00:00<00:28, 295.25 examples/s]Tokenizing train dataset:   2%|▏         | 164/8564 [00:00<00:31, 262.99 examples/s]Tokenizing train dataset:   2%|▏         | 206/8564 [00:00<00:31, 265.58 examples/s]Tokenizing train dataset:   3%|▎         | 240/8564 [00:00<00:29, 283.20 examples/s]Tokenizing train dataset:   3%|▎         | 280/8564 [00:00<00:30, 273.20 examples/s]Tokenizing train dataset:   4%|▎         | 310/8564 [00:01<00:29, 278.02 examples/s]Tokenizing train dataset:   4%|▍         | 350/8564 [00:01<00:30, 269.35 examples/s]Tokenizing train dataset:   4%|▍         | 384/8564 [00:01<00:28, 283.05 examples/s]Tokenizing train dataset:   5%|▌         | 430/8564 [00:01<00:28, 287.01 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:29, 275.69 examples/s]Tokenizing train dataset:   6%|▌         | 510/8564 [00:01<00:29, 271.06 examples/s]Tokenizing train dataset:   6%|▋         | 540/8564 [00:01<00:29, 274.65 examples/s]Tokenizing train dataset:   7%|▋         | 578/8564 [00:02<00:30, 265.67 examples/s]Tokenizing train dataset:   7%|▋         | 619/8564 [00:02<00:29, 265.17 examples/s]Tokenizing train dataset:   8%|▊         | 654/8564 [00:02<00:28, 280.45 examples/s]Tokenizing train dataset:   8%|▊         | 686/8564 [00:02<00:33, 235.82 examples/s]Tokenizing train dataset:   8%|▊         | 722/8564 [00:02<00:33, 235.90 examples/s]Tokenizing train dataset:   9%|▉         | 755/8564 [00:02<00:30, 255.23 examples/s]Tokenizing train dataset:   9%|▉         | 789/8564 [00:02<00:32, 241.86 examples/s]Tokenizing train dataset:  10%|▉         | 824/8564 [00:03<00:32, 236.43 examples/s]Tokenizing train dataset:  10%|▉         | 853/8564 [00:03<00:31, 247.16 examples/s]Tokenizing train dataset:  10%|█         | 899/8564 [00:03<00:29, 261.83 examples/s]Tokenizing train dataset:  11%|█         | 930/8564 [00:03<00:31, 239.09 examples/s]Tokenizing train dataset:  11%|█▏        | 970/8564 [00:03<00:31, 243.14 examples/s]Tokenizing train dataset:  12%|█▏        | 999/8564 [00:03<00:33, 226.68 examples/s]Tokenizing train dataset:  12%|█▏        | 1023/8564 [00:03<00:32, 229.03 examples/s]Tokenizing train dataset:  12%|█▏        | 1064/8564 [00:04<00:31, 238.98 examples/s]Tokenizing train dataset:  13%|█▎        | 1090/8564 [00:04<00:31, 241.05 examples/s]Tokenizing train dataset:  13%|█▎        | 1117/8564 [00:04<00:30, 244.83 examples/s]Tokenizing train dataset:  13%|█▎        | 1149/8564 [00:04<00:32, 231.11 examples/s]Tokenizing train dataset:  14%|█▎        | 1174/8564 [00:04<00:31, 231.92 examples/s]Tokenizing train dataset:  14%|█▍        | 1203/8564 [00:04<00:30, 245.27 examples/s]Tokenizing train dataset:  14%|█▍        | 1231/8564 [00:04<00:29, 250.29 examples/s]Tokenizing train dataset:  15%|█▍        | 1265/8564 [00:04<00:26, 270.56 examples/s]Tokenizing train dataset:  15%|█▌        | 1310/8564 [00:05<00:26, 276.16 examples/s]Tokenizing train dataset:  16%|█▌        | 1339/8564 [00:05<00:26, 271.95 examples/s]Tokenizing train dataset:  16%|█▌        | 1378/8564 [00:05<00:27, 263.32 examples/s]Tokenizing train dataset:  16%|█▋        | 1407/8564 [00:05<00:26, 266.22 examples/s]Tokenizing train dataset:  17%|█▋        | 1436/8564 [00:05<00:26, 268.35 examples/s]Tokenizing train dataset:  17%|█▋        | 1476/8564 [00:05<00:26, 264.16 examples/s]Tokenizing train dataset:  18%|█▊        | 1509/8564 [00:05<00:28, 245.67 examples/s]Tokenizing train dataset:  18%|█▊        | 1537/8564 [00:05<00:27, 251.23 examples/s]Tokenizing train dataset:  18%|█▊        | 1564/8564 [00:06<00:27, 253.21 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:06<00:27, 251.59 examples/s]Tokenizing train dataset:  19%|█▉        | 1620/8564 [00:06<00:26, 264.09 examples/s]Tokenizing train dataset:  19%|█▉        | 1658/8564 [00:06<00:26, 257.85 examples/s]Tokenizing train dataset:  20%|█▉        | 1690/8564 [00:06<00:25, 272.14 examples/s]Tokenizing train dataset:  20%|██        | 1720/8564 [00:06<00:24, 277.13 examples/s]Tokenizing train dataset:  20%|██        | 1751/8564 [00:06<00:24, 281.77 examples/s]Tokenizing train dataset:  21%|██        | 1780/8564 [00:06<00:24, 282.54 examples/s]Tokenizing train dataset:  21%|██▏       | 1822/8564 [00:06<00:24, 277.63 examples/s]Tokenizing train dataset:  22%|██▏       | 1854/8564 [00:07<00:23, 283.24 examples/s]Tokenizing train dataset:  22%|██▏       | 1896/8564 [00:07<00:23, 279.12 examples/s]Tokenizing train dataset:  23%|██▎       | 1935/8564 [00:07<00:21, 304.16 examples/s]Tokenizing train dataset:  23%|██▎       | 1969/8564 [00:07<00:21, 307.29 examples/s]Tokenizing train dataset:  23%|██▎       | 2003/8564 [00:07<00:20, 313.69 examples/s]Tokenizing train dataset:  24%|██▍       | 2040/8564 [00:07<00:19, 328.87 examples/s]Tokenizing train dataset:  24%|██▍       | 2090/8564 [00:07<00:20, 322.12 examples/s]Tokenizing train dataset:  25%|██▍       | 2129/8564 [00:07<00:19, 335.09 examples/s]Tokenizing train dataset:  25%|██▌       | 2178/8564 [00:08<00:19, 329.30 examples/s]Tokenizing train dataset:  26%|██▌       | 2212/8564 [00:08<00:19, 328.99 examples/s]Tokenizing train dataset:  26%|██▋       | 2260/8564 [00:08<00:19, 319.17 examples/s]Tokenizing train dataset:  27%|██▋       | 2309/8564 [00:08<00:19, 319.20 examples/s]Tokenizing train dataset:  27%|██▋       | 2349/8564 [00:08<00:20, 297.23 examples/s]Tokenizing train dataset:  28%|██▊       | 2381/8564 [00:08<00:20, 300.61 examples/s]Tokenizing train dataset:  28%|██▊       | 2416/8564 [00:08<00:19, 312.30 examples/s]Tokenizing train dataset:  29%|██▊       | 2456/8564 [00:09<00:20, 291.37 examples/s]Tokenizing train dataset:  29%|██▉       | 2488/8564 [00:09<00:20, 295.36 examples/s]Tokenizing train dataset:  30%|██▉       | 2538/8564 [00:09<00:19, 307.16 examples/s]Tokenizing train dataset:  30%|███       | 2572/8564 [00:09<00:19, 314.33 examples/s]Tokenizing train dataset:  30%|███       | 2605/8564 [00:09<00:18, 316.51 examples/s]Tokenizing train dataset:  31%|███       | 2648/8564 [00:09<00:19, 304.01 examples/s]Tokenizing train dataset:  31%|███▏      | 2694/8564 [00:09<00:19, 300.88 examples/s]Tokenizing train dataset:  32%|███▏      | 2728/8564 [00:09<00:18, 308.09 examples/s]Tokenizing train dataset:  32%|███▏      | 2772/8564 [00:10<00:19, 296.53 examples/s]Tokenizing train dataset:  33%|███▎      | 2809/8564 [00:10<00:18, 310.43 examples/s]Tokenizing train dataset:  33%|███▎      | 2852/8564 [00:10<00:19, 300.08 examples/s]Tokenizing train dataset:  34%|███▍      | 2906/8564 [00:10<00:17, 315.73 examples/s]Tokenizing train dataset:  34%|███▍      | 2942/8564 [00:10<00:17, 325.25 examples/s]Tokenizing train dataset:  35%|███▍      | 2980/8564 [00:10<00:16, 336.94 examples/s]Tokenizing train dataset:  35%|███▌      | 3032/8564 [00:10<00:16, 337.65 examples/s]Tokenizing train dataset:  36%|███▌      | 3083/8564 [00:10<00:16, 336.41 examples/s]Tokenizing train dataset:  37%|███▋      | 3127/8564 [00:11<00:16, 320.25 examples/s]Tokenizing train dataset:  37%|███▋      | 3162/8564 [00:11<00:16, 324.28 examples/s]Tokenizing train dataset:  38%|███▊      | 3212/8564 [00:11<00:16, 323.94 examples/s]Tokenizing train dataset:  38%|███▊      | 3251/8564 [00:11<00:15, 335.39 examples/s]Tokenizing train dataset:  38%|███▊      | 3293/8564 [00:11<00:16, 314.47 examples/s]Tokenizing train dataset:  39%|███▉      | 3341/8564 [00:11<00:16, 310.81 examples/s]Tokenizing train dataset:  39%|███▉      | 3377/8564 [00:11<00:16, 321.87 examples/s]Tokenizing train dataset:  40%|███▉      | 3411/8564 [00:11<00:15, 325.19 examples/s]Tokenizing train dataset:  40%|████      | 3463/8564 [00:12<00:15, 329.20 examples/s]Tokenizing train dataset:  41%|████      | 3519/8564 [00:12<00:14, 341.61 examples/s]Tokenizing train dataset:  42%|████▏     | 3564/8564 [00:12<00:15, 327.47 examples/s]Tokenizing train dataset:  42%|████▏     | 3602/8564 [00:12<00:14, 338.01 examples/s]Tokenizing train dataset:  43%|████▎     | 3650/8564 [00:12<00:14, 328.00 examples/s]Tokenizing train dataset:  43%|████▎     | 3699/8564 [00:12<00:15, 324.26 examples/s]Tokenizing train dataset:  44%|████▍     | 3751/8564 [00:13<00:14, 329.26 examples/s]Tokenizing train dataset:  44%|████▍     | 3800/8564 [00:13<00:14, 325.18 examples/s]Tokenizing train dataset:  45%|████▍     | 3848/8564 [00:13<00:14, 319.42 examples/s]Tokenizing train dataset:  45%|████▌     | 3881/8564 [00:13<00:14, 321.05 examples/s]Tokenizing train dataset:  46%|████▌     | 3918/8564 [00:13<00:15, 292.31 examples/s]Tokenizing train dataset:  46%|████▋     | 3964/8564 [00:13<00:15, 295.44 examples/s]Tokenizing train dataset:  47%|████▋     | 3997/8564 [00:13<00:15, 301.81 examples/s]Tokenizing train dataset:  47%|████▋     | 4031/8564 [00:13<00:14, 306.63 examples/s]Tokenizing train dataset:  48%|████▊     | 4080/8564 [00:14<00:14, 309.32 examples/s]Tokenizing train dataset:  48%|████▊     | 4128/8564 [00:14<00:14, 307.14 examples/s]Tokenizing train dataset:  49%|████▉     | 4176/8564 [00:14<00:14, 307.70 examples/s]Tokenizing train dataset:  49%|████▉     | 4211/8564 [00:14<00:13, 315.52 examples/s]Tokenizing train dataset:  50%|████▉     | 4260/8564 [00:14<00:13, 315.18 examples/s]Tokenizing train dataset:  50%|█████     | 4293/8564 [00:14<00:13, 317.07 examples/s]Tokenizing train dataset:  51%|█████     | 4326/8564 [00:14<00:13, 318.32 examples/s]Tokenizing train dataset:  51%|█████     | 4361/8564 [00:14<00:13, 318.73 examples/s]Tokenizing train dataset:  51%|█████▏    | 4398/8564 [00:15<00:12, 328.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 4448/8564 [00:15<00:12, 325.94 examples/s]Tokenizing train dataset:  53%|█████▎    | 4498/8564 [00:15<00:12, 324.41 examples/s]Tokenizing train dataset:  53%|█████▎    | 4546/8564 [00:15<00:12, 319.86 examples/s]Tokenizing train dataset:  53%|█████▎    | 4580/8564 [00:15<00:12, 317.99 examples/s]Tokenizing train dataset:  54%|█████▍    | 4629/8564 [00:15<00:12, 319.45 examples/s]Tokenizing train dataset:  54%|█████▍    | 4666/8564 [00:15<00:13, 292.77 examples/s]Tokenizing train dataset:  55%|█████▍    | 4709/8564 [00:16<00:13, 287.74 examples/s]Tokenizing train dataset:  55%|█████▌    | 4748/8564 [00:16<00:13, 277.29 examples/s]Tokenizing train dataset:  56%|█████▌    | 4793/8564 [00:16<00:13, 279.10 examples/s]Tokenizing train dataset:  56%|█████▋    | 4822/8564 [00:16<00:14, 259.92 examples/s]Tokenizing train dataset:  57%|█████▋    | 4873/8564 [00:16<00:11, 315.49 examples/s]Tokenizing train dataset:  57%|█████▋    | 4912/8564 [00:16<00:11, 330.41 examples/s]Tokenizing train dataset:  58%|█████▊    | 4971/8564 [00:16<00:09, 391.57 examples/s]Tokenizing train dataset:  59%|█████▊    | 5030/8564 [00:16<00:08, 441.40 examples/s]Tokenizing train dataset:  59%|█████▉    | 5088/8564 [00:17<00:07, 477.16 examples/s]Tokenizing train dataset:  60%|██████    | 5174/8564 [00:17<00:06, 509.89 examples/s]Tokenizing train dataset:  61%|██████▏   | 5261/8564 [00:17<00:06, 528.63 examples/s]Tokenizing train dataset:  62%|██████▏   | 5320/8564 [00:17<00:06, 538.04 examples/s]Tokenizing train dataset:  63%|██████▎   | 5394/8564 [00:17<00:06, 515.43 examples/s]Tokenizing train dataset:  64%|██████▎   | 5454/8564 [00:17<00:05, 533.62 examples/s]Tokenizing train dataset:  65%|██████▍   | 5538/8564 [00:17<00:05, 537.45 examples/s]Tokenizing train dataset:  66%|██████▌   | 5624/8564 [00:18<00:05, 548.03 examples/s]Tokenizing train dataset:  67%|██████▋   | 5698/8564 [00:18<00:05, 526.90 examples/s]Tokenizing train dataset:  67%|██████▋   | 5757/8564 [00:18<00:05, 539.03 examples/s]Tokenizing train dataset:  68%|██████▊   | 5826/8564 [00:18<00:04, 573.83 examples/s]Tokenizing train dataset:  69%|██████▉   | 5905/8564 [00:18<00:04, 554.48 examples/s]Tokenizing train dataset:  70%|██████▉   | 5965/8564 [00:18<00:04, 561.88 examples/s]Tokenizing train dataset:  71%|███████   | 6043/8564 [00:18<00:04, 532.51 examples/s]Tokenizing train dataset:  72%|███████▏  | 6127/8564 [00:18<00:04, 536.58 examples/s]Tokenizing train dataset:  73%|███████▎  | 6219/8564 [00:19<00:04, 554.13 examples/s]Tokenizing train dataset:  73%|███████▎  | 6283/8564 [00:19<00:04, 569.67 examples/s]Tokenizing train dataset:  74%|███████▍  | 6376/8564 [00:19<00:03, 581.98 examples/s]Tokenizing train dataset:  75%|███████▌  | 6459/8564 [00:19<00:03, 568.64 examples/s]Tokenizing train dataset:  76%|███████▋  | 6535/8564 [00:19<00:03, 546.79 examples/s]Tokenizing train dataset:  77%|███████▋  | 6600/8564 [00:19<00:03, 505.91 examples/s]Tokenizing train dataset:  78%|███████▊  | 6683/8564 [00:20<00:03, 517.64 examples/s]Tokenizing train dataset:  79%|███████▊  | 6742/8564 [00:20<00:03, 532.53 examples/s]Tokenizing train dataset:  79%|███████▉  | 6800/8564 [00:20<00:03, 542.66 examples/s]Tokenizing train dataset:  80%|████████  | 6885/8564 [00:20<00:03, 543.13 examples/s]Tokenizing train dataset:  81%|████████  | 6943/8564 [00:20<00:02, 550.33 examples/s]Tokenizing train dataset:  82%|████████▏ | 7015/8564 [00:20<00:02, 524.95 examples/s]Tokenizing train dataset:  83%|████████▎ | 7078/8564 [00:20<00:02, 547.91 examples/s]Tokenizing train dataset:  83%|████████▎ | 7135/8564 [00:20<00:02, 550.99 examples/s]Tokenizing train dataset:  84%|████████▍ | 7195/8564 [00:20<00:02, 561.25 examples/s]Tokenizing train dataset:  85%|████████▍ | 7253/8564 [00:21<00:02, 462.73 examples/s]Tokenizing train dataset:  85%|████████▌ | 7310/8564 [00:21<00:02, 485.35 examples/s]Tokenizing train dataset:  86%|████████▌ | 7363/8564 [00:21<00:02, 493.18 examples/s]Tokenizing train dataset:  87%|████████▋ | 7417/8564 [00:21<00:02, 500.08 examples/s]Tokenizing train dataset:  87%|████████▋ | 7472/8564 [00:21<00:02, 510.75 examples/s]Tokenizing train dataset:  88%|████████▊ | 7540/8564 [00:21<00:02, 485.87 examples/s]Tokenizing train dataset:  89%|████████▉ | 7601/8564 [00:21<00:01, 515.83 examples/s]Tokenizing train dataset:  89%|████████▉ | 7657/8564 [00:21<00:01, 523.40 examples/s]Tokenizing train dataset:  90%|█████████ | 7740/8564 [00:22<00:01, 531.70 examples/s]Tokenizing train dataset:  91%|█████████ | 7810/8564 [00:22<00:01, 503.83 examples/s]Tokenizing train dataset:  92%|█████████▏| 7882/8564 [00:22<00:01, 493.13 examples/s]Tokenizing train dataset:  93%|█████████▎| 7945/8564 [00:22<00:01, 464.51 examples/s]Tokenizing train dataset:  93%|█████████▎| 7995/8564 [00:22<00:01, 470.61 examples/s]Tokenizing train dataset:  94%|█████████▍| 8062/8564 [00:22<00:01, 446.60 examples/s]Tokenizing train dataset:  95%|█████████▍| 8121/8564 [00:22<00:01, 425.46 examples/s]Tokenizing train dataset:  96%|█████████▌| 8179/8564 [00:23<00:00, 456.82 examples/s]Tokenizing train dataset:  96%|█████████▌| 8230/8564 [00:23<00:00, 469.45 examples/s]Tokenizing train dataset:  97%|█████████▋| 8297/8564 [00:23<00:00, 518.72 examples/s]Tokenizing train dataset:  98%|█████████▊| 8373/8564 [00:23<00:00, 508.10 examples/s]Tokenizing train dataset:  98%|█████████▊| 8429/8564 [00:23<00:00, 516.51 examples/s]Tokenizing train dataset:  99%|█████████▉| 8510/8564 [00:23<00:00, 522.43 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:23<00:00, 498.46 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:23<00:00, 359.85 examples/s]
Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:   6%|▋         | 550/8564 [00:00<00:01, 5359.11 examples/s]Extracting prompt in train dataset:   6%|▋         | 540/8564 [00:00<00:01, 5338.28 examples/s]Extracting prompt in train dataset:   6%|▋         | 540/8564 [00:00<00:01, 5304.60 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 7876.28 examples/s]
Extracting prompt in train dataset:  13%|█▎        | 1110/8564 [00:00<00:01, 4196.92 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1102/8564 [00:00<00:01, 4056.35 examples/s]Extracting prompt in train dataset:  13%|█▎        | 1130/8564 [00:00<00:01, 4358.31 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1661/8564 [00:00<00:02, 3398.91 examples/s]Extracting prompt in train dataset:  19%|█▉        | 1659/8564 [00:00<00:02, 3148.41 examples/s]Extracting prompt in train dataset:  20%|█▉        | 1680/8564 [00:00<00:02, 3237.76 examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  25%|██▍       | 2110/8564 [00:00<00:01, 3701.07 examples/s]Extracting prompt in train dataset:  24%|██▎       | 2025/8564 [00:00<00:01, 3281.61 examples/s]Extracting prompt in train dataset:  26%|██▌       | 2241/8564 [00:00<00:01, 3416.83 examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13007.48 examples/s]
Extracting prompt in train dataset:  31%|███▏      | 2680/8564 [00:00<00:01, 3550.64 examples/s]Extracting prompt in train dataset:  30%|███       | 2600/8564 [00:00<00:01, 3438.51 examples/s]Extracting prompt in train dataset:  32%|███▏      | 2780/8564 [00:00<00:01, 3911.02 examples/s]Extracting prompt in train dataset:  35%|███▌      | 3040/8564 [00:00<00:01, 3667.45 examples/s]Extracting prompt in train dataset:  39%|███▉      | 3330/8564 [00:00<00:01, 3793.31 examples/s]Extracting prompt in train dataset:  41%|████      | 3486/8564 [00:00<00:01, 4189.97 examples/s]Extracting prompt in train dataset:  41%|████      | 3479/8564 [00:00<00:01, 3856.48 examples/s]Extracting prompt in train dataset:  46%|████▌     | 3922/8564 [00:01<00:01, 3834.27 examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in train dataset:  49%|████▊     | 4158/8564 [00:01<00:01, 4286.40 examples/s]Extracting prompt in train dataset:  47%|████▋     | 4054/8564 [00:01<00:01, 3679.51 examples/s]Extracting prompt in train dataset:  51%|█████     | 4331/8564 [00:01<00:01, 3893.30 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 328.52 examples/s]Extracting prompt in train dataset:  56%|█████▌    | 4811/8564 [00:01<00:00, 4306.12 examples/s]Extracting prompt in train dataset:  54%|█████▍    | 4609/8564 [00:01<00:00, 4133.64 examples/s]Extracting prompt in train dataset:  57%|█████▋    | 4868/8564 [00:01<00:00, 4265.55 examples/s]Extracting prompt in train dataset:  62%|██████▏   | 5300/8564 [00:01<00:00, 4431.08 examples/s]Extracting prompt in train dataset:  59%|█████▉    | 5091/8564 [00:01<00:00, 4311.50 examples/s]Tokenizing eval dataset:   8%|▊         | 77/953 [00:00<00:03, 289.90 examples/s]Extracting prompt in train dataset:  65%|██████▍   | 5530/8564 [00:01<00:00, 4301.97 examples/s]Extracting prompt in train dataset:  68%|██████▊   | 5850/8564 [00:01<00:00, 4689.31 examples/s]Extracting prompt in train dataset:  66%|██████▌   | 5646/8564 [00:01<00:00, 4646.94 examples/s]Extracting prompt in train dataset:  70%|███████   | 6030/8564 [00:01<00:00, 4475.01 examples/s]Tokenizing eval dataset:  12%|█▏        | 118/953 [00:00<00:03, 276.00 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6380/8564 [00:01<00:00, 4838.28 examples/s]Extracting prompt in train dataset:  74%|███████▍  | 6330/8564 [00:01<00:00, 4604.70 examples/s]Extracting prompt in train dataset:  76%|███████▋  | 6550/8564 [00:01<00:00, 4649.33 examples/s]Tokenizing eval dataset:  16%|█▌        | 153/953 [00:00<00:03, 249.24 examples/s]Extracting prompt in train dataset:  83%|████████▎ | 7080/8564 [00:01<00:00, 4749.19 examples/s]Extracting prompt in train dataset:  81%|████████▏ | 6964/8564 [00:01<00:00, 4473.21 examples/s]Extracting prompt in train dataset:  84%|████████▎ | 7160/8564 [00:01<00:00, 4413.92 examples/s]Tokenizing eval dataset:  19%|█▉        | 182/953 [00:00<00:03, 226.33 examples/s]Extracting prompt in train dataset:  90%|█████████ | 7740/8564 [00:01<00:00, 4606.64 examples/s]Extracting prompt in train dataset:  87%|████████▋ | 7460/8564 [00:01<00:00, 4581.24 examples/s]Extracting prompt in train dataset:  91%|█████████ | 7810/8564 [00:01<00:00, 4385.00 examples/s]Tokenizing eval dataset:  23%|██▎       | 219/953 [00:00<00:03, 230.80 examples/s]Extracting prompt in train dataset:  98%|█████████▊| 8360/8564 [00:01<00:00, 4446.87 examples/s]Extracting prompt in train dataset:  94%|█████████▎| 8020/8564 [00:01<00:00, 4229.93 examples/s]Extracting prompt in train dataset:  97%|█████████▋| 8340/8564 [00:01<00:00, 4597.06 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:01<00:00, 4289.78 examples/s]
Tokenizing eval dataset:  29%|██▉       | 278/953 [00:00<00:02, 316.12 examples/s]Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 4158.93 examples/s]
Extracting prompt in train dataset: 100%|██████████| 8564/8564 [00:02<00:00, 4091.89 examples/s]
Tokenizing eval dataset:  35%|███▌      | 338/953 [00:01<00:01, 385.22 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:01<00:01, 431.01 examples/s]Tokenizing eval dataset:  48%|████▊     | 462/953 [00:01<00:00, 491.02 examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Applying chat template to train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing eval dataset:  56%|█████▋    | 538/953 [00:01<00:00, 495.20 examples/s]Applying chat template to train dataset:   3%|▎         | 287/8564 [00:00<00:02, 2830.94 examples/s]Applying chat template to train dataset:   3%|▎         | 285/8564 [00:00<00:02, 2820.17 examples/s]Applying chat template to train dataset:   3%|▎         | 286/8564 [00:00<00:02, 2822.77 examples/s]Tokenizing eval dataset:  63%|██████▎   | 600/953 [00:01<00:00, 524.15 examples/s]Applying chat template to train dataset:   8%|▊         | 676/8564 [00:00<00:02, 2666.35 examples/s]Applying chat template to train dataset:   8%|▊         | 708/8564 [00:00<00:02, 2811.55 examples/s]Applying chat template to train dataset:   8%|▊         | 699/8564 [00:00<00:02, 2770.66 examples/s]Tokenizing eval dataset:  71%|███████   | 679/953 [00:01<00:00, 521.54 examples/s]Applying chat template to train dataset:  11%|█▏        | 972/8564 [00:00<00:02, 2777.78 examples/s]Applying chat template to train dataset:  13%|█▎        | 1110/8564 [00:00<00:02, 2739.59 examples/s]Tokenizing eval dataset:  77%|███████▋  | 733/953 [00:01<00:00, 524.16 examples/s]Applying chat template to train dataset:  13%|█▎        | 1095/8564 [00:00<00:02, 2697.81 examples/s]Applying chat template to train dataset:  16%|█▌        | 1383/8564 [00:00<00:02, 2754.05 examples/s]Applying chat template to train dataset:  16%|█▋        | 1395/8564 [00:00<00:02, 2791.74 examples/s]Applying chat template to train dataset:  18%|█▊        | 1533/8564 [00:00<00:02, 2762.69 examples/s]Tokenizing eval dataset:  85%|████████▍ | 807/953 [00:01<00:00, 510.74 examples/s]Applying chat template to train dataset:  20%|█▉        | 1676/8564 [00:00<00:02, 2803.53 examples/s]Applying chat template to train dataset:  21%|██        | 1812/8564 [00:00<00:02, 2766.57 examples/s]Applying chat template to train dataset:  21%|██        | 1818/8564 [00:00<00:02, 2798.78 examples/s]Applying chat template to train dataset:  24%|██▍       | 2076/8564 [00:00<00:02, 2745.22 examples/s]Tokenizing eval dataset:  92%|█████████▏| 876/953 [00:02<00:00, 486.52 examples/s]Applying chat template to train dataset:  25%|██▍       | 2113/8564 [00:00<00:02, 2833.96 examples/s]Applying chat template to train dataset:  26%|██▌       | 2209/8564 [00:00<00:02, 2725.70 examples/s]Applying chat template to train dataset:  29%|██▉       | 2500/8564 [00:00<00:02, 2771.18 examples/s]Tokenizing eval dataset:  97%|█████████▋| 929/953 [00:02<00:00, 396.21 examples/s]Applying chat template to train dataset:  28%|██▊       | 2431/8564 [00:00<00:02, 2184.74 examples/s]Applying chat template to train dataset:  30%|██▉       | 2527/8564 [00:00<00:02, 2450.04 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 395.67 examples/s]
Applying chat template to train dataset:  34%|███▎      | 2886/8564 [00:01<00:02, 2699.95 examples/s]Applying chat template to train dataset:  32%|███▏      | 2728/8564 [00:01<00:02, 2367.54 examples/s]Applying chat template to train dataset:  34%|███▍      | 2923/8564 [00:01<00:02, 2508.82 examples/s]Applying chat template to train dataset:  35%|███▌      | 3018/8564 [00:01<00:02, 2500.48 examples/s]Applying chat template to train dataset:  38%|███▊      | 3273/8564 [00:01<00:01, 2659.33 examples/s]Applying chat template to train dataset:  37%|███▋      | 3208/8564 [00:01<00:02, 2560.27 examples/s]Applying chat template to train dataset:  39%|███▊      | 3301/8564 [00:01<00:02, 2585.52 examples/s]Applying chat template to train dataset:  42%|████▏     | 3575/8564 [00:01<00:01, 2742.90 examples/s]Applying chat template to train dataset:  41%|████      | 3473/8564 [00:01<00:01, 2579.83 examples/s]Applying chat template to train dataset:  42%|████▏     | 3605/8564 [00:01<00:01, 2707.77 examples/s]Applying chat template to train dataset:  45%|████▌     | 3877/8564 [00:01<00:01, 2810.33 examples/s]Applying chat template to train dataset:  44%|████▍     | 3751/8564 [00:01<00:01, 2628.92 examples/s]Applying chat template to train dataset:  46%|████▌     | 3907/8564 [00:01<00:01, 2792.14 examples/s]Applying chat template to train dataset:  50%|█████     | 4296/8564 [00:01<00:01, 2801.38 examples/s]Applying chat template to train dataset:  49%|████▉     | 4197/8564 [00:01<00:01, 2819.51 examples/s]Applying chat template to train dataset:  49%|████▊     | 4170/8564 [00:01<00:01, 2684.91 examples/s]Applying chat template to train dataset:  52%|█████▏    | 4489/8564 [00:01<00:01, 2846.39 examples/s]Applying chat template to train dataset:  55%|█████▌    | 4719/8564 [00:01<00:01, 2805.28 examples/s]Applying chat template to train dataset:  53%|█████▎    | 4566/8564 [00:01<00:01, 2664.68 examples/s]Applying chat template to train dataset:  57%|█████▋    | 4918/8564 [00:01<00:01, 2848.26 examples/s]Applying chat template to train dataset:  60%|█████▉    | 5137/8564 [00:01<00:01, 2796.37 examples/s]Applying chat template to train dataset:  58%|█████▊    | 4970/8564 [00:01<00:01, 2670.54 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5427/8564 [00:01<00:01, 2818.22 examples/s]Applying chat template to train dataset:  63%|██████▎   | 5357/8564 [00:01<00:01, 2874.25 examples/s]Applying chat template to train dataset:  62%|██████▏   | 5295/8564 [00:02<00:01, 2461.03 examples/s]Applying chat template to train dataset:  68%|██████▊   | 5782/8564 [00:02<00:01, 2662.07 examples/s]Applying chat template to train dataset:  67%|██████▋   | 5710/8564 [00:02<00:01, 2696.49 examples/s]Applying chat template to train dataset:  66%|██████▌   | 5639/8564 [00:02<00:01, 2407.71 examples/s]Applying chat template to train dataset:  72%|███████▏  | 6127/8564 [00:02<00:00, 2542.12 examples/s]Applying chat template to train dataset:  71%|███████▏  | 6109/8564 [00:02<00:00, 2681.54 examples/s]Applying chat template to train dataset:  69%|██████▉   | 5902/8564 [00:02<00:01, 2456.68 examples/s]Applying chat template to train dataset:  74%|███████▍  | 6380/8564 [00:02<00:00, 2687.55 examples/s]Applying chat template to train dataset:  76%|███████▌  | 6530/8564 [00:02<00:00, 2584.09 examples/s]Applying chat template to train dataset:  73%|███████▎  | 6283/8564 [00:02<00:00, 2480.28 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6797/8564 [00:02<00:00, 2602.55 examples/s]Applying chat template to train dataset:  79%|███████▉  | 6802/8564 [00:02<00:00, 2723.74 examples/s]Applying chat template to train dataset:  77%|███████▋  | 6608/8564 [00:02<00:00, 2375.34 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7121/8564 [00:02<00:00, 2319.89 examples/s]Applying chat template to train dataset:  83%|████████▎ | 7127/8564 [00:02<00:00, 2427.13 examples/s]Applying chat template to train dataset:  80%|████████  | 6891/8564 [00:02<00:00, 2478.79 examples/s]Applying chat template to train dataset:  86%|████████▌ | 7385/8564 [00:02<00:00, 2390.93 examples/s]Applying chat template to train dataset:  87%|████████▋ | 7453/8564 [00:02<00:00, 2247.38 examples/s]Applying chat template to train dataset:  84%|████████▍ | 7216/8564 [00:03<00:00, 1524.47 examples/s]Applying chat template to train dataset:  90%|█████████ | 7710/8564 [00:03<00:00, 1544.18 examples/s]Applying chat template to train dataset:  90%|█████████ | 7750/8564 [00:03<00:00, 1590.91 examples/s]Applying chat template to train dataset:  88%|████████▊ | 7505/8564 [00:03<00:00, 1754.45 examples/s]Applying chat template to train dataset:  92%|█████████▏| 7920/8564 [00:03<00:00, 1639.62 examples/s]Applying chat template to train dataset:  94%|█████████▎| 8009/8564 [00:03<00:00, 1760.88 examples/s]Applying chat template to train dataset:  90%|█████████ | 7750/8564 [00:03<00:00, 1844.87 examples/s]Applying chat template to train dataset:  96%|█████████▌| 8192/8564 [00:03<00:00, 1851.21 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8314/8564 [00:03<00:00, 2013.00 examples/s]Applying chat template to train dataset:  94%|█████████▍| 8030/8564 [00:03<00:00, 2045.99 examples/s]Applying chat template to train dataset:  99%|█████████▊| 8452/8564 [00:03<00:00, 2014.09 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2425.49 examples/s]
Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2059.14 examples/s]Applying chat template to train dataset:  97%|█████████▋| 8278/8564 [00:03<00:00, 2145.58 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2394.08 examples/s]
Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2173.03 examples/s]Applying chat template to train dataset: 100%|██████████| 8564/8564 [00:03<00:00, 2341.30 examples/s]
Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:21, 399.00 examples/s]Tokenizing train dataset:   0%|          | 0/8564 [00:00<?, ? examples/s]Tokenizing train dataset:   1%|          | 43/8564 [00:00<00:21, 405.58 examples/s]Tokenizing train dataset:   1%|          | 85/8564 [00:00<00:26, 319.08 examples/s]Tokenizing train dataset:   0%|          | 42/8564 [00:00<00:21, 404.45 examples/s]Tokenizing train dataset:   1%|          | 86/8564 [00:00<00:26, 320.37 examples/s]Tokenizing train dataset:   1%|▏         | 123/8564 [00:00<00:29, 281.57 examples/s]Tokenizing train dataset:   1%|          | 85/8564 [00:00<00:26, 314.73 examples/s]Tokenizing train dataset:   1%|▏         | 123/8564 [00:00<00:30, 279.28 examples/s]Tokenizing train dataset:   2%|▏         | 157/8564 [00:00<00:36, 230.27 examples/s]Tokenizing train dataset:   2%|▏         | 155/8564 [00:00<00:29, 287.61 examples/s]Tokenizing train dataset:   2%|▏         | 130/8564 [00:00<00:35, 239.98 examples/s]Tokenizing train dataset:   2%|▏         | 182/8564 [00:00<00:36, 231.98 examples/s]Tokenizing train dataset:   2%|▏         | 198/8564 [00:00<00:29, 282.82 examples/s]Tokenizing train dataset:   2%|▏         | 158/8564 [00:00<00:33, 247.64 examples/s]Tokenizing train dataset:   2%|▏         | 207/8564 [00:00<00:35, 234.75 examples/s]Tokenizing train dataset:   3%|▎         | 229/8564 [00:00<00:29, 286.41 examples/s]Tokenizing train dataset:   2%|▏         | 194/8564 [00:00<00:34, 243.47 examples/s]Tokenizing train dataset:   3%|▎         | 244/8564 [00:00<00:36, 230.59 examples/s]Tokenizing train dataset:   3%|▎         | 264/8564 [00:00<00:35, 231.64 examples/s]Tokenizing train dataset:   3%|▎         | 231/8564 [00:00<00:37, 225.09 examples/s]Tokenizing train dataset:   3%|▎         | 282/8564 [00:01<00:35, 231.86 examples/s]Tokenizing train dataset:   3%|▎         | 295/8564 [00:01<00:33, 247.59 examples/s]Tokenizing train dataset:   3%|▎         | 257/8564 [00:01<00:35, 230.99 examples/s]Tokenizing train dataset:   4%|▍         | 324/8564 [00:01<00:32, 257.24 examples/s]Tokenizing train dataset:   4%|▎         | 318/8564 [00:01<00:35, 230.17 examples/s]Tokenizing train dataset:   3%|▎         | 287/8564 [00:01<00:33, 245.83 examples/s]Tokenizing train dataset:   4%|▍         | 360/8564 [00:01<00:33, 246.85 examples/s]Tokenizing train dataset:   4%|▍         | 348/8564 [00:01<00:38, 214.36 examples/s]Tokenizing train dataset:   4%|▍         | 326/8564 [00:01<00:33, 246.34 examples/s]Tokenizing train dataset:   5%|▍         | 393/8564 [00:01<00:34, 237.80 examples/s]Tokenizing train dataset:   5%|▍         | 386/8564 [00:01<00:37, 219.97 examples/s]Tokenizing train dataset:   4%|▍         | 359/8564 [00:01<00:35, 232.59 examples/s]Tokenizing train dataset:   5%|▌         | 429/8564 [00:01<00:34, 234.28 examples/s]Tokenizing train dataset:   5%|▍         | 418/8564 [00:01<00:39, 208.42 examples/s]Tokenizing train dataset:   5%|▍         | 393/8564 [00:01<00:39, 206.69 examples/s]Tokenizing train dataset:   5%|▌         | 440/8564 [00:01<00:39, 206.55 examples/s]Tokenizing train dataset:   5%|▌         | 469/8564 [00:01<00:33, 241.72 examples/s]Tokenizing train dataset:   5%|▍         | 424/8564 [00:01<00:35, 227.03 examples/s]Tokenizing train dataset:   5%|▌         | 465/8564 [00:02<00:37, 214.58 examples/s]Tokenizing train dataset:   6%|▌         | 501/8564 [00:01<00:35, 227.51 examples/s]Tokenizing train dataset:   5%|▌         | 460/8564 [00:01<00:35, 227.24 examples/s]Tokenizing train dataset:   6%|▌         | 495/8564 [00:02<00:34, 232.16 examples/s]Tokenizing train dataset:   6%|▌         | 486/8564 [00:02<00:34, 233.35 examples/s]Tokenizing train dataset:   6%|▌         | 519/8564 [00:02<00:34, 233.12 examples/s]Tokenizing train dataset:   6%|▋         | 539/8564 [00:02<00:34, 234.36 examples/s]Tokenizing train dataset:   6%|▋         | 549/8564 [00:02<00:32, 249.36 examples/s]Tokenizing train dataset:   6%|▌         | 516/8564 [00:02<00:32, 244.98 examples/s]Tokenizing train dataset:   7%|▋         | 575/8564 [00:02<00:34, 233.05 examples/s]Tokenizing train dataset:   7%|▋         | 578/8564 [00:02<00:31, 257.61 examples/s]Tokenizing train dataset:   6%|▋         | 545/8564 [00:02<00:31, 254.01 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:02<00:33, 234.89 examples/s]Tokenizing train dataset:   7%|▋         | 612/8564 [00:02<00:32, 242.14 examples/s]Tokenizing train dataset:   7%|▋         | 577/8564 [00:02<00:37, 214.06 examples/s]Tokenizing train dataset:   7%|▋         | 640/8564 [00:02<00:32, 242.91 examples/s]Tokenizing train dataset:   8%|▊         | 643/8564 [00:02<00:30, 257.01 examples/s]Tokenizing train dataset:   7%|▋         | 603/8564 [00:02<00:35, 221.68 examples/s]Tokenizing train dataset:   8%|▊         | 665/8564 [00:02<00:32, 241.73 examples/s]Tokenizing train dataset:   8%|▊         | 671/8564 [00:02<00:30, 258.03 examples/s]Tokenizing train dataset:   7%|▋         | 640/8564 [00:02<00:31, 254.77 examples/s]Tokenizing train dataset:   8%|▊         | 690/8564 [00:02<00:33, 238.40 examples/s]Tokenizing train dataset:   8%|▊         | 698/8564 [00:02<00:30, 258.79 examples/s]Tokenizing train dataset:   8%|▊         | 719/8564 [00:02<00:31, 246.64 examples/s]Tokenizing train dataset:   8%|▊         | 682/8564 [00:02<00:30, 258.33 examples/s]Tokenizing train dataset:   9%|▊         | 739/8564 [00:03<00:32, 243.69 examples/s]Tokenizing train dataset:   9%|▉         | 757/8564 [00:03<00:32, 242.95 examples/s]Tokenizing train dataset:   8%|▊         | 716/8564 [00:02<00:32, 244.24 examples/s]Tokenizing train dataset:   9%|▉         | 771/8564 [00:03<00:34, 228.46 examples/s]Tokenizing train dataset:   9%|▉         | 788/8564 [00:03<00:34, 227.48 examples/s]Tokenizing train dataset:   9%|▉         | 756/8564 [00:03<00:31, 249.09 examples/s]Tokenizing train dataset:   9%|▉         | 806/8564 [00:03<00:34, 224.56 examples/s]Tokenizing train dataset:  10%|▉         | 825/8564 [00:03<00:33, 230.64 examples/s]Tokenizing train dataset:   9%|▉         | 794/8564 [00:03<00:31, 246.66 examples/s]Tokenizing train dataset:  10%|▉         | 849/8564 [00:03<00:33, 229.17 examples/s]Tokenizing train dataset:  10%|▉         | 842/8564 [00:03<00:33, 227.91 examples/s]Tokenizing train dataset:  10%|▉         | 821/8564 [00:03<00:31, 249.22 examples/s]Tokenizing train dataset:  10%|█         | 876/8564 [00:03<00:32, 234.54 examples/s]Tokenizing train dataset:  10%|█         | 868/8564 [00:03<00:32, 234.41 examples/s]Tokenizing train dataset:  10%|█         | 862/8564 [00:03<00:30, 254.23 examples/s]Tokenizing train dataset:  11%|█         | 911/8564 [00:03<00:29, 262.85 examples/s]Tokenizing train dataset:  10%|█         | 899/8564 [00:03<00:30, 249.69 examples/s]Tokenizing train dataset:  10%|█         | 893/8564 [00:03<00:28, 266.02 examples/s]Tokenizing train dataset:  11%|█         | 936/8564 [00:03<00:30, 247.06 examples/s]Tokenizing train dataset:  11%|█         | 953/8564 [00:03<00:28, 262.69 examples/s]Tokenizing train dataset:  11%|█         | 933/8564 [00:03<00:28, 263.89 examples/s]Tokenizing train dataset:  11%|█▏        | 970/8564 [00:04<00:33, 223.62 examples/s]Tokenizing train dataset:  11%|█▏        | 984/8564 [00:04<00:35, 212.56 examples/s]Tokenizing train dataset:  11%|█▏        | 968/8564 [00:03<00:31, 239.96 examples/s]Tokenizing train dataset:  12%|█▏        | 1001/8564 [00:04<00:35, 214.10 examples/s]Tokenizing train dataset:  12%|█▏        | 1019/8564 [00:04<00:34, 215.97 examples/s]Tokenizing train dataset:  12%|█▏        | 1002/8564 [00:04<00:32, 232.45 examples/s]Tokenizing train dataset:  12%|█▏        | 1025/8564 [00:04<00:34, 215.89 examples/s]Tokenizing train dataset:  12%|█▏        | 1028/8564 [00:04<00:31, 236.88 examples/s]Tokenizing train dataset:  12%|█▏        | 1056/8564 [00:04<00:33, 222.95 examples/s]Tokenizing train dataset:  12%|█▏        | 1049/8564 [00:04<00:34, 219.95 examples/s]Tokenizing train dataset:  12%|█▏        | 1053/8564 [00:04<00:31, 238.36 examples/s]Tokenizing train dataset:  13%|█▎        | 1084/8564 [00:04<00:32, 233.10 examples/s]Tokenizing train dataset:  13%|█▎        | 1080/8564 [00:04<00:31, 239.56 examples/s]Tokenizing train dataset:  13%|█▎        | 1081/8564 [00:04<00:30, 246.15 examples/s]Tokenizing train dataset:  13%|█▎        | 1119/8564 [00:04<00:33, 220.70 examples/s]Tokenizing train dataset:  13%|█▎        | 1111/8564 [00:04<00:28, 259.70 examples/s]Tokenizing train dataset:  13%|█▎        | 1116/8564 [00:04<00:32, 231.93 examples/s]Tokenizing train dataset:  13%|█▎        | 1150/8564 [00:04<00:34, 214.38 examples/s]Tokenizing train dataset:  13%|█▎        | 1140/8564 [00:04<00:32, 231.83 examples/s]Tokenizing train dataset:  13%|█▎        | 1144/8564 [00:04<00:34, 215.55 examples/s]Tokenizing train dataset:  14%|█▎        | 1174/8564 [00:04<00:33, 217.48 examples/s]Tokenizing train dataset:  14%|█▍        | 1180/8564 [00:04<00:30, 240.19 examples/s]Tokenizing train dataset:  14%|█▍        | 1183/8564 [00:05<00:32, 224.81 examples/s]Tokenizing train dataset:  14%|█▍        | 1207/8564 [00:04<00:30, 242.01 examples/s]Tokenizing train dataset:  14%|█▍        | 1211/8564 [00:04<00:28, 253.66 examples/s]Tokenizing train dataset:  14%|█▍        | 1208/8564 [00:05<00:32, 228.67 examples/s]Tokenizing train dataset:  14%|█▍        | 1236/8564 [00:05<00:29, 252.11 examples/s]Tokenizing train dataset:  15%|█▍        | 1250/8564 [00:05<00:33, 217.69 examples/s]Tokenizing train dataset:  15%|█▍        | 1247/8564 [00:05<00:36, 201.86 examples/s]Tokenizing train dataset:  15%|█▍        | 1270/8564 [00:05<00:37, 194.71 examples/s]Tokenizing train dataset:  15%|█▍        | 1270/8564 [00:05<00:35, 202.70 examples/s]Tokenizing train dataset:  15%|█▌        | 1286/8564 [00:05<00:32, 222.55 examples/s]Tokenizing train dataset:  15%|█▌        | 1293/8564 [00:05<00:36, 199.79 examples/s]Tokenizing train dataset:  15%|█▌        | 1299/8564 [00:05<00:32, 221.37 examples/s]Tokenizing train dataset:  15%|█▌        | 1320/8564 [00:05<00:29, 243.69 examples/s]Tokenizing train dataset:  15%|█▌        | 1327/8564 [00:05<00:31, 230.29 examples/s]Tokenizing train dataset:  16%|█▌        | 1332/8564 [00:05<00:34, 211.02 examples/s]Tokenizing train dataset:  16%|█▌        | 1353/8564 [00:05<00:35, 201.08 examples/s]Tokenizing train dataset:  16%|█▌        | 1359/8564 [00:05<00:32, 222.48 examples/s]Tokenizing train dataset:  16%|█▌        | 1357/8564 [00:05<00:38, 188.64 examples/s]Tokenizing train dataset:  16%|█▌        | 1383/8564 [00:05<00:35, 203.07 examples/s]Tokenizing train dataset:  16%|█▌        | 1387/8564 [00:06<00:30, 231.53 examples/s]Tokenizing train dataset:  16%|█▌        | 1391/8564 [00:05<00:33, 214.05 examples/s]Tokenizing train dataset:  17%|█▋        | 1417/8564 [00:06<00:37, 191.60 examples/s]Tokenizing train dataset:  17%|█▋        | 1420/8564 [00:06<00:36, 194.87 examples/s]Tokenizing train dataset:  17%|█▋        | 1425/8564 [00:06<00:35, 200.39 examples/s]Tokenizing train dataset:  17%|█▋        | 1441/8564 [00:06<00:35, 199.49 examples/s]Tokenizing train dataset:  17%|█▋        | 1456/8564 [00:06<00:34, 204.95 examples/s]Tokenizing train dataset:  17%|█▋        | 1457/8564 [00:06<00:35, 202.35 examples/s]Tokenizing train dataset:  17%|█▋        | 1466/8564 [00:06<00:34, 208.64 examples/s]Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:06<00:33, 210.34 examples/s]Tokenizing train dataset:  17%|█▋        | 1490/8564 [00:06<00:35, 200.69 examples/s]Tokenizing train dataset:  17%|█▋        | 1495/8564 [00:06<00:35, 200.93 examples/s]Tokenizing train dataset:  18%|█▊        | 1516/8564 [00:06<00:32, 218.88 examples/s]Tokenizing train dataset:  18%|█▊        | 1518/8564 [00:06<00:36, 195.29 examples/s]Tokenizing train dataset:  18%|█▊        | 1530/8564 [00:06<00:34, 202.13 examples/s]Tokenizing train dataset:  18%|█▊        | 1548/8564 [00:06<00:29, 239.33 examples/s]Tokenizing train dataset:  18%|█▊        | 1543/8564 [00:06<00:34, 205.85 examples/s]Tokenizing train dataset:  18%|█▊        | 1553/8564 [00:06<00:33, 206.69 examples/s]Tokenizing train dataset:  19%|█▊        | 1586/8564 [00:06<00:29, 238.21 examples/s]Tokenizing train dataset:  18%|█▊        | 1574/8564 [00:06<00:34, 203.92 examples/s]Tokenizing train dataset:  19%|█▊        | 1590/8564 [00:06<00:32, 217.11 examples/s]Tokenizing train dataset:  19%|█▊        | 1596/8564 [00:06<00:34, 203.64 examples/s]Tokenizing train dataset:  19%|█▉        | 1620/8564 [00:07<00:31, 220.34 examples/s]Tokenizing train dataset:  19%|█▉        | 1619/8564 [00:06<00:29, 232.23 examples/s]Tokenizing train dataset:  19%|█▉        | 1627/8564 [00:06<00:30, 226.93 examples/s]Tokenizing train dataset:  19%|█▉        | 1650/8564 [00:07<00:29, 233.32 examples/s]Tokenizing train dataset:  19%|█▉        | 1644/8564 [00:07<00:29, 231.92 examples/s]Tokenizing train dataset:  19%|█▉        | 1658/8564 [00:07<00:28, 244.46 examples/s]Tokenizing train dataset:  20%|█▉        | 1676/8564 [00:07<00:29, 237.39 examples/s]Tokenizing train dataset:  20%|█▉        | 1679/8564 [00:07<00:30, 229.10 examples/s]Tokenizing train dataset:  20%|█▉        | 1689/8564 [00:07<00:26, 259.30 examples/s]Tokenizing train dataset:  20%|█▉        | 1703/8564 [00:07<00:28, 244.13 examples/s]Tokenizing train dataset:  20%|█▉        | 1705/8564 [00:07<00:29, 235.98 examples/s]Tokenizing train dataset:  20%|██        | 1726/8564 [00:07<00:28, 242.52 examples/s]Tokenizing train dataset:  20%|██        | 1736/8564 [00:07<00:31, 213.83 examples/s]Tokenizing train dataset:  20%|██        | 1736/8564 [00:07<00:30, 222.37 examples/s]Tokenizing train dataset:  21%|██        | 1760/8564 [00:07<00:25, 263.39 examples/s]Tokenizing train dataset:  21%|██        | 1773/8564 [00:07<00:35, 189.37 examples/s]Tokenizing train dataset:  21%|██        | 1773/8564 [00:07<00:34, 199.02 examples/s]Tokenizing train dataset:  21%|██        | 1791/8564 [00:07<00:29, 227.08 examples/s]Tokenizing train dataset:  21%|██        | 1799/8564 [00:07<00:33, 201.58 examples/s]Tokenizing train dataset:  21%|██        | 1799/8564 [00:07<00:32, 208.65 examples/s]Tokenizing train dataset:  21%|██        | 1817/8564 [00:07<00:29, 232.45 examples/s]Tokenizing train dataset:  21%|██▏       | 1828/8564 [00:08<00:30, 218.83 examples/s]Tokenizing train dataset:  22%|██▏       | 1844/8564 [00:07<00:27, 241.48 examples/s]Tokenizing train dataset:  21%|██▏       | 1826/8564 [00:07<00:30, 220.49 examples/s]Tokenizing train dataset:  22%|██▏       | 1859/8564 [00:08<00:31, 210.59 examples/s]Tokenizing train dataset:  22%|██▏       | 1875/8564 [00:08<00:31, 213.55 examples/s]Tokenizing train dataset:  22%|██▏       | 1857/8564 [00:08<00:33, 202.74 examples/s]Tokenizing train dataset:  22%|██▏       | 1887/8564 [00:08<00:29, 223.73 examples/s]Tokenizing train dataset:  22%|██▏       | 1899/8564 [00:08<00:30, 217.81 examples/s]Tokenizing train dataset:  22%|██▏       | 1889/8564 [00:08<00:33, 202.23 examples/s]Tokenizing train dataset:  22%|██▏       | 1919/8564 [00:08<00:27, 244.56 examples/s]Tokenizing train dataset:  23%|██▎       | 1928/8564 [00:08<00:28, 233.29 examples/s]Tokenizing train dataset:  22%|██▏       | 1914/8564 [00:08<00:33, 197.90 examples/s]Tokenizing train dataset:  23%|██▎       | 1958/8564 [00:08<00:31, 208.09 examples/s]Tokenizing train dataset:  23%|██▎       | 1936/8564 [00:08<00:53, 123.44 examples/s]Tokenizing train dataset:  23%|██▎       | 1964/8564 [00:08<00:49, 132.81 examples/s]Tokenizing train dataset:  23%|██▎       | 1996/8564 [00:08<00:40, 161.23 examples/s]Tokenizing train dataset:  23%|██▎       | 1969/8564 [00:08<00:41, 157.32 examples/s]Tokenizing train dataset:  23%|██▎       | 1993/8564 [00:08<00:41, 156.91 examples/s]Tokenizing train dataset:  24%|██▎       | 2030/8564 [00:09<00:34, 189.71 examples/s]Tokenizing train dataset:  23%|██▎       | 2000/8564 [00:09<00:35, 185.76 examples/s]Tokenizing train dataset:  24%|██▎       | 2020/8564 [00:08<00:37, 175.63 examples/s]Tokenizing train dataset:  24%|██▍       | 2063/8564 [00:09<00:30, 215.68 examples/s]Tokenizing train dataset:  24%|██▎       | 2025/8564 [00:09<00:32, 198.71 examples/s]Tokenizing train dataset:  24%|██▍       | 2049/8564 [00:09<00:32, 197.76 examples/s]Tokenizing train dataset:  24%|██▍       | 2093/8564 [00:09<00:27, 232.14 examples/s]Tokenizing train dataset:  24%|██▍       | 2051/8564 [00:09<00:30, 211.09 examples/s]Tokenizing train dataset:  24%|██▍       | 2078/8564 [00:09<00:30, 216.13 examples/s]Tokenizing train dataset:  25%|██▍       | 2127/8564 [00:09<00:25, 254.80 examples/s]Tokenizing train dataset:  24%|██▍       | 2078/8564 [00:09<00:29, 222.68 examples/s]Tokenizing train dataset:  25%|██▍       | 2110/8564 [00:09<00:26, 240.19 examples/s]Tokenizing train dataset:  25%|██▌       | 2156/8564 [00:09<00:24, 261.69 examples/s]Tokenizing train dataset:  25%|██▍       | 2110/8564 [00:09<00:26, 243.24 examples/s]Tokenizing train dataset:  25%|██▌       | 2148/8564 [00:09<00:23, 272.98 examples/s]Tokenizing train dataset:  26%|██▌       | 2187/8564 [00:09<00:23, 271.82 examples/s]Tokenizing train dataset:  25%|██▌       | 2144/8564 [00:09<00:24, 265.41 examples/s]Tokenizing train dataset:  26%|██▌       | 2196/8564 [00:09<00:22, 287.92 examples/s]Tokenizing train dataset:  25%|██▌       | 2173/8564 [00:09<00:23, 270.60 examples/s]Tokenizing train dataset:  26%|██▌       | 2235/8564 [00:09<00:22, 287.12 examples/s]Tokenizing train dataset:  26%|██▌       | 2228/8564 [00:09<00:21, 291.97 examples/s]Tokenizing train dataset:  26%|██▌       | 2220/8564 [00:09<00:22, 283.06 examples/s]Tokenizing train dataset:  26%|██▋       | 2263/8564 [00:09<00:20, 305.36 examples/s]Tokenizing train dataset:  27%|██▋       | 2289/8564 [00:09<00:20, 309.81 examples/s]Tokenizing train dataset:  26%|██▋       | 2260/8564 [00:09<00:23, 268.81 examples/s]Tokenizing train dataset:  27%|██▋       | 2288/8564 [00:10<00:23, 269.79 examples/s]Tokenizing train dataset:  27%|██▋       | 2306/8564 [00:09<00:25, 240.96 examples/s]Tokenizing train dataset:  27%|██▋       | 2324/8564 [00:10<00:27, 226.72 examples/s]Tokenizing train dataset:  27%|██▋       | 2318/8564 [00:10<00:22, 276.23 examples/s]Tokenizing train dataset:  27%|██▋       | 2346/8564 [00:10<00:25, 244.22 examples/s]Tokenizing train dataset:  28%|██▊       | 2358/8564 [00:10<00:27, 225.17 examples/s]Tokenizing train dataset:  27%|██▋       | 2348/8564 [00:10<00:22, 281.33 examples/s]Tokenizing train dataset:  28%|██▊       | 2380/8564 [00:10<00:23, 263.73 examples/s]Tokenizing train dataset:  28%|██▊       | 2396/8564 [00:10<00:24, 255.11 examples/s]Tokenizing train dataset:  28%|██▊       | 2377/8564 [00:10<00:22, 280.91 examples/s]Tokenizing train dataset:  28%|██▊       | 2417/8564 [00:10<00:21, 287.75 examples/s]Tokenizing train dataset:  28%|██▊       | 2433/8564 [00:10<00:21, 279.26 examples/s]Tokenizing train dataset:  28%|██▊       | 2411/8564 [00:10<00:20, 295.00 examples/s]Tokenizing train dataset:  29%|██▊       | 2449/8564 [00:10<00:20, 294.51 examples/s]Tokenizing train dataset:  29%|██▉       | 2464/8564 [00:10<00:21, 286.31 examples/s]Tokenizing train dataset:  29%|██▊       | 2444/8564 [00:10<00:20, 302.18 examples/s]Tokenizing train dataset:  29%|██▉       | 2481/8564 [00:10<00:20, 298.03 examples/s]Tokenizing train dataset:  29%|██▉       | 2475/8564 [00:10<00:20, 301.85 examples/s]Tokenizing train dataset:  29%|██▉       | 2507/8564 [00:10<00:21, 283.23 examples/s]Tokenizing train dataset:  30%|██▉       | 2530/8564 [00:10<00:19, 305.16 examples/s]Tokenizing train dataset:  30%|██▉       | 2544/8564 [00:10<00:19, 302.62 examples/s]Tokenizing train dataset:  29%|██▉       | 2523/8564 [00:10<00:19, 306.25 examples/s]Tokenizing train dataset:  30%|██▉       | 2565/8564 [00:10<00:19, 314.10 examples/s]Tokenizing train dataset:  30%|███       | 2585/8564 [00:11<00:21, 280.48 examples/s]Tokenizing train dataset:  30%|███       | 2600/8564 [00:10<00:18, 316.93 examples/s]Tokenizing train dataset:  30%|██▉       | 2567/8564 [00:10<00:20, 288.97 examples/s]Tokenizing train dataset:  31%|███       | 2620/8564 [00:11<00:24, 246.76 examples/s]Tokenizing train dataset:  30%|███       | 2606/8564 [00:11<00:23, 249.46 examples/s]Tokenizing train dataset:  31%|███       | 2648/8564 [00:11<00:21, 271.15 examples/s]Tokenizing train dataset:  31%|███       | 2648/8564 [00:11<00:23, 252.48 examples/s]Tokenizing train dataset:  31%|███       | 2638/8564 [00:11<00:26, 226.95 examples/s]Tokenizing train dataset:  31%|███▏      | 2683/8564 [00:11<00:27, 213.81 examples/s]Tokenizing train dataset:  31%|███▏      | 2683/8564 [00:11<00:26, 217.83 examples/s]Tokenizing train dataset:  31%|███       | 2672/8564 [00:11<00:26, 223.87 examples/s]Tokenizing train dataset:  32%|███▏      | 2716/8564 [00:11<00:24, 235.63 examples/s]Tokenizing train dataset:  32%|███▏      | 2700/8564 [00:11<00:25, 234.19 examples/s]Tokenizing train dataset:  32%|███▏      | 2722/8564 [00:11<00:26, 222.82 examples/s]Tokenizing train dataset:  32%|███▏      | 2760/8564 [00:11<00:23, 249.76 examples/s]Tokenizing train dataset:  32%|███▏      | 2737/8564 [00:11<00:24, 235.11 examples/s]Tokenizing train dataset:  32%|███▏      | 2759/8564 [00:11<00:25, 224.40 examples/s]Tokenizing train dataset:  33%|███▎      | 2801/8564 [00:11<00:22, 252.55 examples/s]Tokenizing train dataset:  33%|███▎      | 2830/8564 [00:11<00:22, 259.61 examples/s]Tokenizing train dataset:  32%|███▏      | 2773/8564 [00:11<00:26, 215.38 examples/s]Tokenizing train dataset:  33%|███▎      | 2799/8564 [00:12<00:26, 215.09 examples/s]Tokenizing train dataset:  33%|███▎      | 2796/8564 [00:12<00:27, 211.95 examples/s]Tokenizing train dataset:  33%|███▎      | 2822/8564 [00:12<00:27, 208.69 examples/s]Tokenizing train dataset:  33%|███▎      | 2866/8564 [00:12<00:22, 251.62 examples/s]Tokenizing train dataset:  33%|███▎      | 2820/8564 [00:12<00:27, 209.69 examples/s]Tokenizing train dataset:  33%|███▎      | 2857/8564 [00:12<00:27, 210.09 examples/s]Tokenizing train dataset:  34%|███▍      | 2909/8564 [00:12<00:25, 222.88 examples/s]Tokenizing train dataset:  33%|███▎      | 2855/8564 [00:12<00:28, 198.38 examples/s]Tokenizing train dataset:  34%|███▍      | 2898/8564 [00:12<00:26, 211.54 examples/s]Tokenizing train dataset:  34%|███▎      | 2887/8564 [00:12<00:25, 223.70 examples/s]Tokenizing train dataset:  34%|███▍      | 2953/8564 [00:12<00:23, 239.15 examples/s]Tokenizing train dataset:  34%|███▍      | 2937/8564 [00:12<00:22, 247.14 examples/s]Tokenizing train dataset:  34%|███▍      | 2925/8564 [00:12<00:21, 258.47 examples/s]Tokenizing train dataset:  35%|███▍      | 2969/8564 [00:12<00:21, 260.49 examples/s]Tokenizing train dataset:  35%|███▌      | 2998/8564 [00:12<00:22, 248.45 examples/s]Tokenizing train dataset:  35%|███▍      | 2955/8564 [00:12<00:20, 267.58 examples/s]Tokenizing train dataset:  35%|███▌      | 3011/8564 [00:12<00:22, 247.36 examples/s]Tokenizing train dataset:  35%|███▌      | 3034/8564 [00:12<00:23, 231.19 examples/s]Tokenizing train dataset:  35%|███▌      | 2999/8564 [00:12<00:20, 265.11 examples/s]Tokenizing train dataset:  36%|███▌      | 3053/8564 [00:13<00:21, 254.13 examples/s]Tokenizing train dataset:  36%|███▌      | 3070/8564 [00:13<00:26, 205.78 examples/s]Tokenizing train dataset:  36%|███▌      | 3083/8564 [00:13<00:20, 261.74 examples/s]Tokenizing train dataset:  35%|███▌      | 3036/8564 [00:13<00:26, 210.81 examples/s]Tokenizing train dataset:  36%|███▌      | 3100/8564 [00:13<00:24, 220.64 examples/s]Tokenizing train dataset:  36%|███▋      | 3119/8564 [00:13<00:23, 236.60 examples/s]Tokenizing train dataset:  36%|███▌      | 3073/8564 [00:13<00:29, 185.59 examples/s]Tokenizing train dataset:  37%|███▋      | 3137/8564 [00:13<00:25, 210.42 examples/s]Tokenizing train dataset:  37%|███▋      | 3151/8564 [00:13<00:21, 254.29 examples/s]Tokenizing train dataset:  37%|███▋      | 3168/8564 [00:13<00:23, 229.96 examples/s]Tokenizing train dataset:  36%|███▋      | 3110/8564 [00:13<00:25, 216.85 examples/s]Tokenizing train dataset:  37%|███▋      | 3185/8564 [00:13<00:19, 272.47 examples/s]Tokenizing train dataset:  37%|███▋      | 3210/8564 [00:13<00:22, 240.87 examples/s]Tokenizing train dataset:  37%|███▋      | 3148/8564 [00:13<00:25, 212.36 examples/s]Tokenizing train dataset:  38%|███▊      | 3225/8564 [00:13<00:21, 244.86 examples/s]Tokenizing train dataset:  38%|███▊      | 3250/8564 [00:13<00:19, 272.01 examples/s]Tokenizing train dataset:  37%|███▋      | 3176/8564 [00:13<00:23, 224.94 examples/s]Tokenizing train dataset:  38%|███▊      | 3255/8564 [00:13<00:20, 254.72 examples/s]Tokenizing train dataset:  38%|███▊      | 3280/8564 [00:13<00:19, 274.97 examples/s]Tokenizing train dataset:  37%|███▋      | 3206/8564 [00:13<00:22, 240.71 examples/s]Tokenizing train dataset:  38%|███▊      | 3284/8564 [00:14<00:20, 260.19 examples/s]Tokenizing train dataset:  38%|███▊      | 3240/8564 [00:14<00:20, 260.63 examples/s]Tokenizing train dataset:  39%|███▉      | 3324/8564 [00:13<00:18, 279.91 examples/s]Tokenizing train dataset:  39%|███▊      | 3313/8564 [00:14<00:19, 265.15 examples/s]Tokenizing train dataset:  38%|███▊      | 3280/8564 [00:14<00:23, 227.51 examples/s]Tokenizing train dataset:  39%|███▉      | 3362/8564 [00:14<00:21, 237.05 examples/s]Tokenizing train dataset:  39%|███▉      | 3350/8564 [00:14<00:24, 211.44 examples/s]Tokenizing train dataset:  40%|███▉      | 3391/8564 [00:14<00:20, 247.31 examples/s]Tokenizing train dataset:  39%|███▉      | 3320/8564 [00:14<00:22, 236.08 examples/s]Tokenizing train dataset:  39%|███▉      | 3377/8564 [00:14<00:23, 221.48 examples/s]Tokenizing train dataset:  40%|███▉      | 3420/8564 [00:14<00:20, 255.22 examples/s]Tokenizing train dataset:  39%|███▉      | 3346/8564 [00:14<00:21, 239.41 examples/s]Tokenizing train dataset:  40%|███▉      | 3420/8564 [00:14<00:21, 238.18 examples/s]Tokenizing train dataset:  40%|████      | 3461/8564 [00:14<00:20, 253.59 examples/s]Tokenizing train dataset:  40%|███▉      | 3388/8564 [00:14<00:20, 250.62 examples/s]Tokenizing train dataset:  40%|████      | 3452/8564 [00:14<00:20, 253.81 examples/s]Tokenizing train dataset:  41%|████      | 3490/8564 [00:14<00:19, 261.75 examples/s]Tokenizing train dataset:  40%|███▉      | 3420/8564 [00:14<00:19, 264.17 examples/s]Tokenizing train dataset:  41%|████      | 3497/8564 [00:14<00:19, 265.56 examples/s]Tokenizing train dataset:  41%|████      | 3530/8564 [00:14<00:17, 292.66 examples/s]Tokenizing train dataset:  40%|████      | 3448/8564 [00:14<00:19, 265.95 examples/s]Tokenizing train dataset:  41%|████      | 3532/8564 [00:15<00:17, 284.92 examples/s]Tokenizing train dataset:  42%|████▏     | 3573/8564 [00:14<00:17, 288.78 examples/s]Tokenizing train dataset:  41%|████      | 3485/8564 [00:15<00:21, 233.41 examples/s]Tokenizing train dataset:  42%|████▏     | 3570/8564 [00:15<00:19, 252.67 examples/s]Tokenizing train dataset:  42%|████▏     | 3615/8564 [00:15<00:17, 284.11 examples/s]Tokenizing train dataset:  41%|████      | 3520/8564 [00:15<00:19, 256.56 examples/s]Tokenizing train dataset:  42%|████▏     | 3604/8564 [00:15<00:18, 270.86 examples/s]Tokenizing train dataset:  43%|████▎     | 3647/8564 [00:15<00:16, 289.95 examples/s]Tokenizing train dataset:  41%|████▏     | 3548/8564 [00:15<00:19, 258.65 examples/s]Tokenizing train dataset:  42%|████▏     | 3637/8564 [00:15<00:17, 284.08 examples/s]Tokenizing train dataset:  42%|████▏     | 3576/8564 [00:15<00:19, 262.31 examples/s]Tokenizing train dataset:  43%|████▎     | 3689/8564 [00:15<00:17, 283.86 examples/s]Tokenizing train dataset:  43%|████▎     | 3679/8564 [00:15<00:17, 278.38 examples/s]Tokenizing train dataset:  42%|████▏     | 3616/8564 [00:15<00:22, 221.95 examples/s]Tokenizing train dataset:  44%|████▎     | 3729/8564 [00:15<00:20, 241.51 examples/s]Tokenizing train dataset:  43%|████▎     | 3724/8564 [00:15<00:17, 269.86 examples/s]Tokenizing train dataset:  43%|████▎     | 3648/8564 [00:15<00:20, 241.84 examples/s]Tokenizing train dataset:  44%|████▍     | 3769/8564 [00:15<00:19, 247.16 examples/s]Tokenizing train dataset:  44%|████▍     | 3765/8564 [00:15<00:17, 267.49 examples/s]Tokenizing train dataset:  43%|████▎     | 3693/8564 [00:15<00:18, 256.99 examples/s]Tokenizing train dataset:  44%|████▍     | 3797/8564 [00:15<00:17, 276.91 examples/s]Tokenizing train dataset:  44%|████▍     | 3810/8564 [00:15<00:18, 252.01 examples/s]Tokenizing train dataset:  44%|████▎     | 3733/8564 [00:16<00:18, 255.22 examples/s]Tokenizing train dataset:  45%|████▍     | 3839/8564 [00:16<00:17, 270.43 examples/s]Tokenizing train dataset:  45%|████▍     | 3850/8564 [00:15<00:18, 254.45 examples/s]Tokenizing train dataset:  44%|████▍     | 3765/8564 [00:16<00:17, 267.37 examples/s]Tokenizing train dataset:  45%|████▌     | 3885/8564 [00:16<00:16, 277.50 examples/s]Tokenizing train dataset:  44%|████▍     | 3799/8564 [00:16<00:16, 280.70 examples/s]Tokenizing train dataset:  45%|████▌     | 3892/8564 [00:16<00:17, 261.25 examples/s]Tokenizing train dataset:  46%|████▌     | 3931/8564 [00:16<00:16, 283.34 examples/s]Tokenizing train dataset:  45%|████▍     | 3845/8564 [00:16<00:16, 285.65 examples/s]Tokenizing train dataset:  46%|████▌     | 3930/8564 [00:16<00:18, 256.14 examples/s]Tokenizing train dataset:  46%|████▋     | 3970/8564 [00:16<00:17, 256.75 examples/s]Tokenizing train dataset:  45%|████▌     | 3884/8564 [00:16<00:18, 249.08 examples/s]Tokenizing train dataset:  46%|████▋     | 3970/8564 [00:16<00:20, 229.31 examples/s]Tokenizing train dataset:  47%|████▋     | 3997/8564 [00:16<00:17, 257.87 examples/s]Tokenizing train dataset:  47%|████▋     | 4000/8564 [00:16<00:18, 241.74 examples/s]Tokenizing train dataset:  46%|████▌     | 3928/8564 [00:16<00:17, 259.07 examples/s]Tokenizing train dataset:  47%|████▋     | 4031/8564 [00:16<00:16, 274.05 examples/s]Tokenizing train dataset:  47%|████▋     | 4041/8564 [00:16<00:18, 248.85 examples/s]Tokenizing train dataset:  46%|████▋     | 3965/8564 [00:16<00:18, 246.33 examples/s]Tokenizing train dataset:  48%|████▊     | 4069/8564 [00:17<00:17, 253.89 examples/s]Tokenizing train dataset:  48%|████▊     | 4072/8564 [00:16<00:17, 260.94 examples/s]Tokenizing train dataset:  47%|████▋     | 3997/8564 [00:17<00:17, 260.53 examples/s]Tokenizing train dataset:  48%|████▊     | 4115/8564 [00:17<00:16, 265.71 examples/s]Tokenizing train dataset:  47%|████▋     | 4032/8564 [00:17<00:16, 278.95 examples/s]Tokenizing train dataset:  48%|████▊     | 4116/8564 [00:17<00:16, 266.96 examples/s]Tokenizing train dataset:  48%|████▊     | 4146/8564 [00:17<00:16, 272.82 examples/s]Tokenizing train dataset:  48%|████▊     | 4075/8564 [00:17<00:16, 280.21 examples/s]Tokenizing train dataset:  48%|████▊     | 4150/8564 [00:17<00:19, 225.27 examples/s]Tokenizing train dataset:  49%|████▉     | 4183/8564 [00:17<00:16, 263.58 examples/s]Tokenizing train dataset:  48%|████▊     | 4113/8564 [00:17<00:16, 266.26 examples/s]Tokenizing train dataset:  49%|████▉     | 4191/8564 [00:17<00:18, 233.41 examples/s]Tokenizing train dataset:  49%|████▉     | 4223/8564 [00:17<00:17, 249.40 examples/s]Tokenizing train dataset:  48%|████▊     | 4150/8564 [00:17<00:17, 257.43 examples/s]Tokenizing train dataset:  50%|████▉     | 4249/8564 [00:17<00:17, 250.60 examples/s]Tokenizing train dataset:  49%|████▉     | 4230/8564 [00:17<00:18, 232.89 examples/s]Tokenizing train dataset:  49%|████▉     | 4186/8564 [00:17<00:15, 279.18 examples/s]Tokenizing train dataset:  50%|█████     | 4286/8564 [00:17<00:15, 276.01 examples/s]Tokenizing train dataset:  50%|████▉     | 4267/8564 [00:17<00:20, 209.05 examples/s]Tokenizing train dataset:  49%|████▉     | 4226/8564 [00:17<00:17, 246.20 examples/s]Tokenizing train dataset:  50%|█████     | 4324/8564 [00:18<00:17, 237.96 examples/s]Tokenizing train dataset:  50%|█████     | 4300/8564 [00:17<00:18, 230.75 examples/s]Tokenizing train dataset:  50%|████▉     | 4266/8564 [00:18<00:17, 249.41 examples/s]Tokenizing train dataset:  51%|█████     | 4355/8564 [00:18<00:16, 251.39 examples/s]Tokenizing train dataset:  51%|█████     | 4337/8564 [00:18<00:19, 220.98 examples/s]Tokenizing train dataset:  50%|█████     | 4309/8564 [00:18<00:16, 256.13 examples/s]Tokenizing train dataset:  51%|█████▏    | 4395/8564 [00:18<00:16, 249.79 examples/s]Tokenizing train dataset:  51%|█████     | 4365/8564 [00:18<00:18, 232.01 examples/s]Tokenizing train dataset:  51%|█████     | 4338/8564 [00:18<00:16, 262.79 examples/s]Tokenizing train dataset:  52%|█████▏    | 4422/8564 [00:18<00:16, 250.48 examples/s]Tokenizing train dataset:  51%|█████▏    | 4402/8564 [00:18<00:15, 260.57 examples/s]Tokenizing train dataset:  51%|█████     | 4366/8564 [00:18<00:15, 266.15 examples/s]Tokenizing train dataset:  52%|█████▏    | 4448/8564 [00:18<00:16, 249.61 examples/s]Tokenizing train dataset:  52%|█████▏    | 4435/8564 [00:18<00:15, 274.50 examples/s]Tokenizing train dataset:  51%|█████▏    | 4403/8564 [00:18<00:14, 289.38 examples/s]Tokenizing train dataset:  52%|█████▏    | 4490/8564 [00:18<00:15, 257.74 examples/s]Tokenizing train dataset:  52%|█████▏    | 4484/8564 [00:18<00:14, 287.73 examples/s]Tokenizing train dataset:  52%|█████▏    | 4442/8564 [00:18<00:14, 277.04 examples/s]Tokenizing train dataset:  53%|█████▎    | 4521/8564 [00:18<00:15, 267.90 examples/s]Tokenizing train dataset:  52%|█████▏    | 4477/8564 [00:18<00:14, 291.10 examples/s]Tokenizing train dataset:  53%|█████▎    | 4529/8564 [00:18<00:13, 290.09 examples/s]Tokenizing train dataset:  53%|█████▎    | 4562/8564 [00:18<00:15, 254.11 examples/s]Tokenizing train dataset:  53%|█████▎    | 4510/8564 [00:18<00:15, 256.79 examples/s]Tokenizing train dataset:  53%|█████▎    | 4569/8564 [00:18<00:14, 274.89 examples/s]Tokenizing train dataset:  54%|█████▎    | 4593/8564 [00:19<00:15, 263.95 examples/s]Tokenizing train dataset:  53%|█████▎    | 4542/8564 [00:19<00:14, 268.75 examples/s]Tokenizing train dataset:  54%|█████▎    | 4600/8564 [00:18<00:14, 277.34 examples/s]Tokenizing train dataset:  54%|█████▍    | 4633/8564 [00:19<00:15, 259.84 examples/s]Tokenizing train dataset:  53%|█████▎    | 4572/8564 [00:19<00:14, 272.00 examples/s]Tokenizing train dataset:  54%|█████▍    | 4636/8564 [00:19<00:17, 222.33 examples/s]Tokenizing train dataset:  54%|█████▍    | 4666/8564 [00:19<00:17, 220.46 examples/s]Tokenizing train dataset:  54%|█████▍    | 4609/8564 [00:19<00:16, 236.98 examples/s]Tokenizing train dataset:  54%|█████▍    | 4662/8564 [00:19<00:17, 229.07 examples/s]Tokenizing train dataset:  55%|█████▍    | 4700/8564 [00:19<00:17, 219.18 examples/s]Tokenizing train dataset:  55%|█████▍    | 4687/8564 [00:19<00:16, 231.97 examples/s]Tokenizing train dataset:  54%|█████▍    | 4644/8564 [00:19<00:17, 227.97 examples/s]Tokenizing train dataset:  55%|█████▌    | 4730/8564 [00:19<00:16, 234.46 examples/s]Tokenizing train dataset:  55%|█████▌    | 4716/8564 [00:19<00:15, 243.05 examples/s]Tokenizing train dataset:  55%|█████▍    | 4684/8564 [00:19<00:16, 237.72 examples/s]Tokenizing train dataset:  56%|█████▌    | 4763/8564 [00:19<00:17, 223.47 examples/s]Tokenizing train dataset:  55%|█████▌    | 4750/8564 [00:19<00:17, 217.69 examples/s]Tokenizing train dataset:  55%|█████▌    | 4716/8564 [00:19<00:16, 228.98 examples/s]Tokenizing train dataset:  56%|█████▌    | 4779/8564 [00:19<00:16, 229.81 examples/s]Tokenizing train dataset:  56%|█████▌    | 4808/8564 [00:20<00:15, 244.19 examples/s]Tokenizing train dataset:  55%|█████▌    | 4744/8564 [00:19<00:15, 238.86 examples/s]Tokenizing train dataset:  56%|█████▌    | 4811/8564 [00:19<00:15, 250.07 examples/s]Tokenizing train dataset:  57%|█████▋    | 4849/8564 [00:20<00:13, 279.99 examples/s]Tokenizing train dataset:  56%|█████▌    | 4775/8564 [00:20<00:17, 220.26 examples/s]Tokenizing train dataset:  57%|█████▋    | 4862/8564 [00:20<00:11, 314.31 examples/s]Tokenizing train dataset:  57%|█████▋    | 4879/8564 [00:20<00:13, 265.94 examples/s]Tokenizing train dataset:  56%|█████▌    | 4810/8564 [00:20<00:15, 247.41 examples/s]Tokenizing train dataset:  57%|█████▋    | 4905/8564 [00:20<00:10, 343.20 examples/s]Tokenizing train dataset:  57%|█████▋    | 4921/8564 [00:20<00:12, 302.01 examples/s]Tokenizing train dataset:  57%|█████▋    | 4858/8564 [00:20<00:12, 300.65 examples/s]Tokenizing train dataset:  58%|█████▊    | 4962/8564 [00:20<00:10, 328.88 examples/s]Tokenizing train dataset:  58%|█████▊    | 4967/8564 [00:20<00:09, 365.96 examples/s]Tokenizing train dataset:  57%|█████▋    | 4908/8564 [00:20<00:10, 349.14 examples/s]Tokenizing train dataset:  59%|█████▊    | 5012/8564 [00:20<00:09, 372.69 examples/s]Tokenizing train dataset:  59%|█████▊    | 5031/8564 [00:20<00:09, 382.25 examples/s]Tokenizing train dataset:  58%|█████▊    | 4967/8564 [00:20<00:11, 326.07 examples/s]Tokenizing train dataset:  59%|█████▉    | 5080/8564 [00:20<00:10, 345.22 examples/s]Tokenizing train dataset:  60%|█████▉    | 5100/8564 [00:20<00:10, 342.30 examples/s]Tokenizing train dataset:  60%|█████▉    | 5129/8564 [00:20<00:09, 376.56 examples/s]Tokenizing train dataset:  59%|█████▊    | 5030/8564 [00:20<00:10, 332.48 examples/s]Tokenizing train dataset:  60%|██████    | 5162/8564 [00:20<00:08, 398.73 examples/s]Tokenizing train dataset:  61%|██████    | 5194/8564 [00:20<00:07, 442.90 examples/s]Tokenizing train dataset:  59%|█████▉    | 5086/8564 [00:20<00:09, 378.57 examples/s]Tokenizing train dataset:  61%|██████    | 5223/8564 [00:20<00:07, 441.55 examples/s]Tokenizing train dataset:  61%|██████    | 5245/8564 [00:21<00:07, 459.67 examples/s]Tokenizing train dataset:  60%|█████▉    | 5129/8564 [00:20<00:08, 390.46 examples/s]Tokenizing train dataset:  62%|██████▏   | 5291/8564 [00:20<00:06, 494.38 examples/s]Tokenizing train dataset:  62%|██████▏   | 5301/8564 [00:21<00:06, 484.97 examples/s]Tokenizing train dataset:  61%|██████    | 5204/8564 [00:21<00:08, 408.99 examples/s]Tokenizing train dataset:  63%|██████▎   | 5354/8564 [00:21<00:07, 456.27 examples/s]Tokenizing train dataset:  63%|██████▎   | 5360/8564 [00:21<00:08, 380.89 examples/s]Tokenizing train dataset:  62%|██████▏   | 5282/8564 [00:21<00:07, 442.10 examples/s]Tokenizing train dataset:  63%|██████▎   | 5423/8564 [00:21<00:06, 455.68 examples/s]Tokenizing train dataset:  63%|██████▎   | 5417/8564 [00:21<00:08, 377.47 examples/s]Tokenizing train dataset:  62%|██████▏   | 5345/8564 [00:21<00:07, 420.54 examples/s]Tokenizing train dataset:  64%|██████▍   | 5479/8564 [00:21<00:06, 479.61 examples/s]Tokenizing train dataset:  64%|██████▍   | 5466/8564 [00:21<00:07, 399.81 examples/s]Tokenizing train dataset:  63%|██████▎   | 5389/8564 [00:21<00:07, 423.14 examples/s]Tokenizing train dataset:  65%|██████▍   | 5547/8564 [00:21<00:06, 468.01 examples/s]Tokenizing train dataset:  65%|██████▍   | 5529/8564 [00:21<00:07, 379.86 examples/s]Tokenizing train dataset:  64%|██████▎   | 5455/8564 [00:21<00:07, 397.85 examples/s]Tokenizing train dataset:  66%|██████▌   | 5620/8564 [00:21<00:06, 470.85 examples/s]Tokenizing train dataset:  65%|██████▌   | 5591/8564 [00:22<00:08, 346.78 examples/s]Tokenizing train dataset:  64%|██████▍   | 5516/8564 [00:21<00:08, 359.51 examples/s]Tokenizing train dataset:  66%|██████▋   | 5689/8564 [00:21<00:06, 431.06 examples/s]Tokenizing train dataset:  66%|██████▌   | 5661/8564 [00:22<00:08, 340.93 examples/s]Tokenizing train dataset:  65%|██████▌   | 5578/8564 [00:22<00:08, 334.62 examples/s]Tokenizing train dataset:  67%|██████▋   | 5756/8564 [00:22<00:07, 379.46 examples/s]Tokenizing train dataset:  67%|██████▋   | 5703/8564 [00:22<00:08, 353.88 examples/s]Tokenizing train dataset:  66%|██████▌   | 5630/8564 [00:22<00:07, 368.44 examples/s]Tokenizing train dataset:  68%|██████▊   | 5827/8564 [00:22<00:06, 442.03 examples/s]Tokenizing train dataset:  67%|██████▋   | 5752/8564 [00:22<00:07, 381.78 examples/s]Tokenizing train dataset:  66%|██████▋   | 5681/8564 [00:22<00:07, 394.52 examples/s]Tokenizing train dataset:  69%|██████▊   | 5876/8564 [00:22<00:05, 451.78 examples/s]Tokenizing train dataset:  68%|██████▊   | 5822/8564 [00:22<00:06, 454.15 examples/s]Tokenizing train dataset:  67%|██████▋   | 5741/8564 [00:22<00:06, 440.36 examples/s]Tokenizing train dataset:  69%|██████▉   | 5928/8564 [00:22<00:05, 464.83 examples/s]Tokenizing train dataset:  68%|██████▊   | 5801/8564 [00:22<00:05, 478.81 examples/s]Tokenizing train dataset:  69%|██████▉   | 5892/8564 [00:22<00:05, 454.28 examples/s]Tokenizing train dataset:  70%|██████▉   | 5980/8564 [00:22<00:05, 451.09 examples/s]Tokenizing train dataset:  68%|██████▊   | 5853/8564 [00:22<00:05, 481.73 examples/s]Tokenizing train dataset:  70%|██████▉   | 5956/8564 [00:22<00:05, 496.39 examples/s]Tokenizing train dataset:  71%|███████   | 6045/8564 [00:22<00:06, 405.82 examples/s]Tokenizing train dataset:  69%|██████▉   | 5916/8564 [00:22<00:05, 447.86 examples/s]Tokenizing train dataset:  70%|███████   | 6015/8564 [00:22<00:05, 454.63 examples/s]Tokenizing train dataset:  71%|███████   | 6092/8564 [00:22<00:05, 420.29 examples/s]Tokenizing train dataset:  70%|██████▉   | 5977/8564 [00:22<00:05, 484.18 examples/s]Tokenizing train dataset:  71%|███████   | 6078/8564 [00:23<00:05, 417.53 examples/s]Tokenizing train dataset:  72%|███████▏  | 6169/8564 [00:22<00:05, 449.47 examples/s]Tokenizing train dataset:  71%|███████   | 6044/8564 [00:23<00:05, 463.69 examples/s]Tokenizing train dataset:  72%|███████▏  | 6127/8564 [00:23<00:05, 431.13 examples/s]Tokenizing train dataset:  73%|███████▎  | 6244/8564 [00:23<00:05, 463.24 examples/s]Tokenizing train dataset:  72%|███████▏  | 6179/8564 [00:23<00:05, 451.11 examples/s]Tokenizing train dataset:  71%|███████▏  | 6116/8564 [00:23<00:05, 467.57 examples/s]Tokenizing train dataset:  74%|███████▎  | 6298/8564 [00:23<00:04, 476.99 examples/s]Tokenizing train dataset:  73%|███████▎  | 6241/8564 [00:23<00:04, 490.12 examples/s]Tokenizing train dataset:  72%|███████▏  | 6185/8564 [00:23<00:04, 515.95 examples/s]Tokenizing train dataset:  74%|███████▍  | 6372/8564 [00:23<00:04, 451.89 examples/s]Tokenizing train dataset:  74%|███████▎  | 6307/8564 [00:23<00:05, 444.71 examples/s]Tokenizing train dataset:  73%|███████▎  | 6260/8564 [00:23<00:04, 466.29 examples/s]Tokenizing train dataset:  75%|███████▌  | 6427/8564 [00:23<00:04, 472.04 examples/s]Tokenizing train dataset:  74%|███████▍  | 6377/8564 [00:23<00:04, 501.64 examples/s]Tokenizing train dataset:  74%|███████▍  | 6331/8564 [00:23<00:04, 466.68 examples/s]Tokenizing train dataset:  76%|███████▌  | 6501/8564 [00:23<00:04, 476.36 examples/s]Tokenizing train dataset:  75%|███████▌  | 6462/8564 [00:23<00:04, 514.72 examples/s]Tokenizing train dataset:  75%|███████▍  | 6400/8564 [00:23<00:04, 512.96 examples/s]Tokenizing train dataset:  76%|███████▋  | 6551/8564 [00:23<00:04, 480.47 examples/s]Tokenizing train dataset:  76%|███████▋  | 6532/8564 [00:24<00:04, 494.69 examples/s]Tokenizing train dataset:  76%|███████▌  | 6471/8564 [00:23<00:04, 497.31 examples/s]Tokenizing train dataset:  77%|███████▋  | 6616/8564 [00:23<00:04, 460.23 examples/s]Tokenizing train dataset:  77%|███████▋  | 6583/8564 [00:24<00:03, 497.32 examples/s]Tokenizing train dataset:  76%|███████▌  | 6526/8564 [00:24<00:04, 505.49 examples/s]Tokenizing train dataset:  78%|███████▊  | 6669/8564 [00:24<00:03, 474.21 examples/s]Tokenizing train dataset:  78%|███████▊  | 6661/8564 [00:24<00:03, 499.44 examples/s]Tokenizing train dataset:  77%|███████▋  | 6595/8564 [00:24<00:04, 489.02 examples/s]Tokenizing train dataset:  79%|███████▊  | 6733/8564 [00:24<00:03, 512.59 examples/s]Tokenizing train dataset:  79%|███████▊  | 6728/8564 [00:24<00:03, 536.59 examples/s]Tokenizing train dataset:  78%|███████▊  | 6665/8564 [00:24<00:03, 479.15 examples/s]Tokenizing train dataset:  80%|███████▉  | 6812/8564 [00:24<00:03, 515.31 examples/s]Tokenizing train dataset:  79%|███████▉  | 6803/8564 [00:24<00:03, 521.65 examples/s]Tokenizing train dataset:  79%|███████▊  | 6738/8564 [00:24<00:03, 477.71 examples/s]Tokenizing train dataset:  80%|████████  | 6872/8564 [00:24<00:03, 474.38 examples/s]Tokenizing train dataset:  80%|████████  | 6876/8564 [00:24<00:03, 507.60 examples/s]Tokenizing train dataset:  79%|███████▉  | 6801/8564 [00:24<00:03, 509.67 examples/s]Tokenizing train dataset:  81%|████████  | 6939/8564 [00:24<00:03, 518.34 examples/s]Tokenizing train dataset:  81%|████████  | 6928/8564 [00:24<00:03, 509.32 examples/s]Tokenizing train dataset:  80%|████████  | 6881/8564 [00:24<00:03, 515.02 examples/s]Tokenizing train dataset:  82%|████████▏ | 7009/8564 [00:24<00:03, 498.11 examples/s]Tokenizing train dataset:  82%|████████▏ | 6986/8564 [00:24<00:03, 525.40 examples/s]Tokenizing train dataset:  81%|████████  | 6945/8564 [00:24<00:02, 542.42 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [00:24<00:02, 507.21 examples/s]Tokenizing train dataset:  82%|████████▏ | 7063/8564 [00:25<00:02, 517.67 examples/s]Tokenizing train dataset:  82%|████████▏ | 7019/8564 [00:25<00:02, 521.10 examples/s]Tokenizing train dataset:  84%|████████▎ | 7151/8564 [00:24<00:02, 524.81 examples/s]Tokenizing train dataset:  83%|████████▎ | 7131/8564 [00:25<00:03, 473.67 examples/s]Tokenizing train dataset:  83%|████████▎ | 7091/8564 [00:25<00:03, 428.01 examples/s]Tokenizing train dataset:  84%|████████▍ | 7221/8564 [00:25<00:03, 425.82 examples/s]Tokenizing train dataset:  84%|████████▍ | 7202/8564 [00:25<00:02, 469.15 examples/s]Tokenizing train dataset:  84%|████████▎ | 7156/8564 [00:25<00:03, 420.14 examples/s]Tokenizing train dataset:  85%|████████▌ | 7283/8564 [00:25<00:03, 407.93 examples/s]Tokenizing train dataset:  85%|████████▍ | 7258/8564 [00:25<00:03, 426.00 examples/s]Tokenizing train dataset:  84%|████████▍ | 7216/8564 [00:25<00:02, 454.21 examples/s]Tokenizing train dataset:  86%|████████▌ | 7329/8564 [00:25<00:02, 416.54 examples/s]Tokenizing train dataset:  85%|████████▌ | 7307/8564 [00:25<00:02, 438.00 examples/s]Tokenizing train dataset:  86%|████████▌ | 7373/8564 [00:25<00:02, 418.68 examples/s]Tokenizing train dataset:  85%|████████▌ | 7293/8564 [00:25<00:02, 469.03 examples/s]Tokenizing train dataset:  86%|████████▌ | 7382/8564 [00:25<00:02, 451.01 examples/s]Tokenizing train dataset:  87%|████████▋ | 7441/8564 [00:25<00:02, 427.25 examples/s]Tokenizing train dataset:  86%|████████▌ | 7361/8564 [00:25<00:02, 435.91 examples/s]Tokenizing train dataset:  87%|████████▋ | 7449/8564 [00:25<00:02, 444.04 examples/s]Tokenizing train dataset:  88%|████████▊ | 7500/8564 [00:25<00:02, 461.87 examples/s]Tokenizing train dataset:  87%|████████▋ | 7426/8564 [00:26<00:02, 406.44 examples/s]Tokenizing train dataset:  88%|████████▊ | 7514/8564 [00:26<00:02, 385.41 examples/s]Tokenizing train dataset:  88%|████████▊ | 7571/8564 [00:26<00:02, 428.00 examples/s]Tokenizing train dataset:  87%|████████▋ | 7471/8564 [00:26<00:02, 411.77 examples/s]Tokenizing train dataset:  88%|████████▊ | 7579/8564 [00:26<00:02, 438.18 examples/s]Tokenizing train dataset:  89%|████████▉ | 7621/8564 [00:26<00:02, 443.32 examples/s]Tokenizing train dataset:  88%|████████▊ | 7516/8564 [00:26<00:02, 418.81 examples/s]Tokenizing train dataset:  89%|████████▉ | 7634/8564 [00:26<00:02, 460.24 examples/s]Tokenizing train dataset:  90%|████████▉ | 7690/8564 [00:26<00:01, 446.08 examples/s]Tokenizing train dataset:  89%|████████▊ | 7586/8564 [00:26<00:02, 485.32 examples/s]Tokenizing train dataset:  90%|█████████ | 7710/8564 [00:26<00:01, 473.93 examples/s]Tokenizing train dataset:  90%|█████████ | 7742/8564 [00:26<00:01, 461.26 examples/s]Tokenizing train dataset:  89%|████████▉ | 7640/8564 [00:26<00:01, 494.48 examples/s]Tokenizing train dataset:  91%|█████████ | 7787/8564 [00:26<00:01, 482.32 examples/s]Tokenizing train dataset:  91%|█████████ | 7809/8564 [00:26<00:01, 453.76 examples/s]Tokenizing train dataset:  90%|█████████ | 7712/8564 [00:26<00:01, 486.97 examples/s]Tokenizing train dataset:  92%|█████████▏| 7877/8564 [00:26<00:01, 448.45 examples/s]Tokenizing train dataset:  92%|█████████▏| 7854/8564 [00:26<00:01, 463.80 examples/s]Tokenizing train dataset:  91%|█████████ | 7769/8564 [00:26<00:01, 440.08 examples/s]Tokenizing train dataset:  93%|█████████▎| 7931/8564 [00:26<00:01, 469.11 examples/s]Tokenizing train dataset:  93%|█████████▎| 7930/8564 [00:27<00:01, 472.74 examples/s]Tokenizing train dataset:  92%|█████████▏| 7841/8564 [00:26<00:01, 452.11 examples/s]Tokenizing train dataset:  93%|█████████▎| 7980/8564 [00:26<00:01, 473.15 examples/s]Tokenizing train dataset:  93%|█████████▎| 7982/8564 [00:27<00:01, 481.97 examples/s]Tokenizing train dataset:  92%|█████████▏| 7900/8564 [00:27<00:01, 479.29 examples/s]Tokenizing train dataset:  94%|█████████▍| 8029/8564 [00:26<00:01, 474.94 examples/s]Tokenizing train dataset:  94%|█████████▍| 8046/8564 [00:27<00:01, 513.25 examples/s]Tokenizing train dataset:  93%|█████████▎| 7955/8564 [00:27<00:01, 490.31 examples/s]Tokenizing train dataset:  94%|█████████▍| 8081/8564 [00:27<00:00, 485.47 examples/s]Tokenizing train dataset:  94%|█████████▎| 8021/8564 [00:27<00:01, 532.76 examples/s]Tokenizing train dataset:  95%|█████████▍| 8123/8564 [00:27<00:00, 509.89 examples/s]Tokenizing train dataset:  95%|█████████▌| 8165/8564 [00:27<00:00, 508.57 examples/s]Tokenizing train dataset:  95%|█████████▍| 8101/8564 [00:27<00:00, 530.20 examples/s]Tokenizing train dataset:  96%|█████████▌| 8198/8564 [00:27<00:00, 501.36 examples/s]Tokenizing train dataset:  96%|█████████▋| 8251/8564 [00:27<00:00, 525.60 examples/s]Tokenizing train dataset:  96%|█████████▋| 8259/8564 [00:27<00:00, 523.80 examples/s]Tokenizing train dataset:  96%|█████████▌| 8190/8564 [00:27<00:00, 545.89 examples/s]Tokenizing train dataset:  97%|█████████▋| 8315/8564 [00:27<00:00, 552.85 examples/s]Tokenizing train dataset:  97%|█████████▋| 8327/8564 [00:27<00:00, 561.36 examples/s]Tokenizing train dataset:  97%|█████████▋| 8286/8564 [00:27<00:00, 573.63 examples/s]Tokenizing train dataset:  98%|█████████▊| 8388/8564 [00:27<00:00, 528.02 examples/s]Tokenizing train dataset:  98%|█████████▊| 8405/8564 [00:27<00:00, 543.34 examples/s]Tokenizing train dataset:  99%|█████████▊| 8445/8564 [00:27<00:00, 534.39 examples/s]Tokenizing train dataset:  98%|█████████▊| 8367/8564 [00:27<00:00, 562.26 examples/s]Tokenizing train dataset:  99%|█████████▉| 8506/8564 [00:27<00:00, 552.28 examples/s]Tokenizing train dataset:  99%|█████████▉| 8497/8564 [00:28<00:00, 559.54 examples/s]Tokenizing train dataset:  98%|█████████▊| 8429/8564 [00:27<00:00, 569.64 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:27<00:00, 556.79 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:27<00:00, 306.18 examples/s]
Tokenizing train dataset: 100%|██████████| 8564/8564 [00:28<00:00, 549.18 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:28<00:00, 303.61 examples/s]
Tokenizing train dataset:  99%|█████████▉| 8504/8564 [00:28<00:00, 545.10 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:28<00:00, 546.40 examples/s]Tokenizing train dataset: 100%|██████████| 8564/8564 [00:28<00:00, 303.22 examples/s]
Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Extracting prompt in eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Set up DPO trainer
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 10739.66 examples/s]
Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 8884.56 examples/s]Extracting prompt in eval dataset: 100%|██████████| 953/953 [00:00<00:00, 9180.06 examples/s]

Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 13322.75 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 8488.56 examples/s]
Applying chat template to eval dataset: 100%|██████████| 953/953 [00:00<00:00, 10908.45 examples/s]
Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   0%|          | 0/953 [00:00<?, ? examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 326.54 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 328.82 examples/s]Tokenizing eval dataset:   4%|▎         | 34/953 [00:00<00:02, 326.50 examples/s]Tokenizing eval dataset:   8%|▊         | 73/953 [00:00<00:03, 269.15 examples/s]Tokenizing eval dataset:   7%|▋         | 69/953 [00:00<00:03, 260.51 examples/s]Tokenizing eval dataset:   8%|▊         | 80/953 [00:00<00:03, 218.97 examples/s]Tokenizing eval dataset:  12%|█▏        | 110/953 [00:00<00:03, 256.20 examples/s]Tokenizing eval dataset:  11%|█         | 103/953 [00:00<00:03, 240.02 examples/s]Tokenizing eval dataset:  12%|█▏        | 118/953 [00:00<00:03, 227.64 examples/s]Tokenizing eval dataset:  15%|█▌        | 145/953 [00:00<00:03, 244.87 examples/s]Tokenizing eval dataset:  14%|█▍        | 137/953 [00:00<00:03, 233.29 examples/s]Tokenizing eval dataset:  18%|█▊        | 173/953 [00:00<00:03, 220.92 examples/s]Tokenizing eval dataset:  16%|█▌        | 153/953 [00:00<00:03, 222.72 examples/s]Tokenizing eval dataset:  17%|█▋        | 164/953 [00:00<00:03, 208.60 examples/s]Tokenizing eval dataset:  22%|██▏       | 209/953 [00:00<00:03, 220.10 examples/s]Tokenizing eval dataset:  20%|█▉        | 186/953 [00:00<00:03, 217.24 examples/s]Tokenizing eval dataset:  21%|██        | 199/953 [00:00<00:03, 214.66 examples/s]Tokenizing eval dataset:  26%|██▌       | 246/953 [00:00<00:02, 255.26 examples/s]Tokenizing eval dataset:  24%|██▍       | 228/953 [00:00<00:03, 230.39 examples/s]Tokenizing eval dataset:  24%|██▍       | 227/953 [00:00<00:03, 232.05 examples/s]Tokenizing eval dataset:  32%|███▏      | 306/953 [00:01<00:01, 341.95 examples/s]Tokenizing eval dataset:  30%|███       | 287/953 [00:01<00:02, 320.58 examples/s]Tokenizing eval dataset:  31%|███       | 291/953 [00:01<00:02, 324.62 examples/s]Tokenizing eval dataset:  37%|███▋      | 355/953 [00:01<00:01, 379.27 examples/s]Tokenizing eval dataset:  36%|███▌      | 339/953 [00:01<00:01, 372.51 examples/s]Tokenizing eval dataset:  37%|███▋      | 354/953 [00:01<00:01, 396.90 examples/s]Tokenizing eval dataset:  43%|████▎     | 408/953 [00:01<00:01, 419.15 examples/s]Tokenizing eval dataset:  42%|████▏     | 396/953 [00:01<00:01, 420.66 examples/s]Tokenizing eval dataset:  43%|████▎     | 407/953 [00:01<00:01, 429.63 examples/s]Tokenizing eval dataset:  50%|████▉     | 476/953 [00:01<00:00, 491.43 examples/s]Tokenizing eval dataset:  49%|████▉     | 465/953 [00:01<00:00, 493.66 examples/s]Tokenizing eval dataset:  50%|████▉     | 473/953 [00:01<00:00, 489.95 examples/s]Tokenizing eval dataset:  56%|█████▌    | 536/953 [00:01<00:00, 518.98 examples/s]Tokenizing eval dataset:  54%|█████▍    | 518/953 [00:01<00:00, 502.81 examples/s]Tokenizing eval dataset:  63%|██████▎   | 600/953 [00:01<00:00, 550.17 examples/s]Tokenizing eval dataset:  58%|█████▊    | 552/953 [00:01<00:00, 500.25 examples/s]Tokenizing eval dataset:  61%|██████    | 577/953 [00:01<00:00, 526.94 examples/s]Tokenizing eval dataset:  64%|██████▎   | 606/953 [00:01<00:00, 509.64 examples/s]Tokenizing eval dataset:  67%|██████▋   | 634/953 [00:01<00:00, 537.67 examples/s]Tokenizing eval dataset:  72%|███████▏  | 687/953 [00:01<00:00, 559.35 examples/s]Tokenizing eval dataset:  72%|███████▏  | 689/953 [00:01<00:00, 523.65 examples/s]Tokenizing eval dataset:  75%|███████▍  | 710/953 [00:01<00:00, 521.90 examples/s]Tokenizing eval dataset:  80%|████████  | 764/953 [00:01<00:00, 536.86 examples/s]Tokenizing eval dataset:  81%|████████  | 769/953 [00:01<00:00, 523.06 examples/s]Tokenizing eval dataset:  82%|████████▏ | 783/953 [00:02<00:00, 504.29 examples/s]Tokenizing eval dataset:  87%|████████▋ | 831/953 [00:02<00:00, 503.66 examples/s]Tokenizing eval dataset:  88%|████████▊ | 839/953 [00:02<00:00, 497.17 examples/s]Tokenizing eval dataset:  90%|████████▉ | 853/953 [00:02<00:00, 485.42 examples/s]Tokenizing eval dataset:  95%|█████████▌| 907/953 [00:02<00:00, 498.97 examples/s]Tokenizing eval dataset:  95%|█████████▌| 908/953 [00:02<00:00, 478.65 examples/s]Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 409.32 examples/s]
Tokenizing eval dataset:  96%|█████████▌| 913/953 [00:02<00:00, 452.79 examples/s]No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 401.06 examples/s]
Tokenizing eval dataset: 100%|██████████| 953/953 [00:02<00:00, 387.37 examples/s]
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
Parameter Offload: Total persistent parameters: 605696 in 169 params
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: vajdadario (slolama) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
wandb: Tracking run with wandb version 0.19.7
wandb: Run data is saved locally in /ceph/hpc/data/s24o01-42-users/translation_optimization/trl/wandb/run-20250531_013956-mc98l3wf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DPO_r-64_lr-3e-07_e-3_b-0.2
wandb: ⭐️ View project at https://wandb.ai/slolama/GaMS-9B-Translation-DPO
wandb: 🚀 View run at https://wandb.ai/slolama/GaMS-9B-Translation-DPO/runs/mc98l3wf
  0%|          | 0/1605 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  0%|          | 1/1605 [00:17<7:53:18, 17.70s/it]                                                  {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 0.0, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -4416.0, 'logps/rejected': -3968.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.0}
  0%|          | 1/1605 [00:17<7:53:18, 17.70s/it]  0%|          | 2/1605 [00:24<5:08:13, 11.54s/it]                                                  {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 7.006071929005137e-11, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -4624.0, 'logps/rejected': -4800.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.0}
  0%|          | 2/1605 [00:24<5:08:13, 11.54s/it]  0%|          | 3/1605 [00:32<4:19:59,  9.74s/it]                                                  {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 1.4012143858010274e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5760.0, 'logps/rejected': -5488.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 3/1605 [00:32<4:19:59,  9.74s/it]  0%|          | 4/1605 [00:40<4:00:42,  9.02s/it]                                                  {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 2.1018215787015413e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5120.0, 'logps/rejected': -5120.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 4/1605 [00:40<4:00:42,  9.02s/it]  0%|          | 5/1605 [00:47<3:45:28,  8.46s/it]                                                  {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 2.802428771602055e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -4112.0, 'logps/rejected': -3936.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 5/1605 [00:48<3:45:28,  8.46s/it]  0%|          | 6/1605 [00:56<3:42:59,  8.37s/it]                                                  {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 3.5030359645025685e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -8368.0, 'logps/rejected': -6080.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 6/1605 [00:56<3:42:59,  8.37s/it]  0%|          | 7/1605 [01:03<3:36:56,  8.15s/it]                                                  {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 4.2036431574030827e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6624.0, 'logps/rejected': -4920.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 7/1605 [01:03<3:36:56,  8.15s/it]  0%|          | 8/1605 [01:11<3:34:08,  8.05s/it]                                                  {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 4.904250350303596e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6224.0, 'logps/rejected': -4712.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.01}
  0%|          | 8/1605 [01:11<3:34:08,  8.05s/it]  1%|          | 9/1605 [01:19<3:35:38,  8.11s/it]                                                  {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 5.60485754320411e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6544.0, 'logps/rejected': -5280.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.02}
  1%|          | 9/1605 [01:20<3:35:38,  8.11s/it]  1%|          | 10/1605 [01:27<3:35:01,  8.09s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 6.305464736104624e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6768.0, 'logps/rejected': -6112.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.02}
  1%|          | 10/1605 [01:27<3:35:01,  8.09s/it]  1%|          | 11/1605 [01:35<3:31:49,  7.97s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 7.006071929005137e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6096.0, 'logps/rejected': -5408.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.02}
  1%|          | 11/1605 [01:35<3:31:49,  7.97s/it]  1%|          | 12/1605 [01:43<3:28:51,  7.87s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 7.706679121905651e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5808.0, 'logps/rejected': -5872.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.02}
  1%|          | 12/1605 [01:43<3:28:51,  7.87s/it]  1%|          | 13/1605 [01:51<3:30:52,  7.95s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 8.407286314806165e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -6256.0, 'logps/rejected': -6032.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.02}
  1%|          | 13/1605 [01:51<3:30:52,  7.95s/it]  1%|          | 14/1605 [01:59<3:31:42,  7.98s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 9.107893507706679e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5904.0, 'logps/rejected': -5904.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.03}
  1%|          | 14/1605 [01:59<3:31:42,  7.98s/it]  1%|          | 15/1605 [02:07<3:28:30,  7.87s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 9.808500700607193e-10, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5648.0, 'logps/rejected': -5840.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.03}
  1%|          | 15/1605 [02:07<3:28:30,  7.87s/it]  1%|          | 16/1605 [02:14<3:24:16,  7.71s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 1.0509107893507706e-09, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -4464.0, 'logps/rejected': -3208.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.03}
  1%|          | 16/1605 [02:14<3:24:16,  7.71s/it]  1%|          | 17/1605 [02:21<3:20:58,  7.59s/it]                                                   {'loss': 0.6914, 'grad_norm': 0.0, 'learning_rate': 1.120971508640822e-09, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/chosen': -5024.0, 'logps/rejected': -5024.0, 'logits/chosen': 0.0, 'logits/rejected': 0.0, 'epoch': 0.03}
  1%|          | 17/1605 [02:21<3:20:58,  7.59s/it]slurmstepd: error: *** STEP 62083723.0 ON gn11 CANCELLED AT 2025-05-31T01:42:25 ***
